{"cell_type":{"4b36fce1":"code","094c27e1":"code","34b125a6":"code","b479bee4":"code","01d42de1":"code","2f5b13b8":"code","13d8fa4a":"code","9fceb2db":"code","53627c2b":"code","fb284173":"code","13b88bf6":"code","101f16f0":"code","1ea6a7d5":"code","a8c20135":"code","7ee47d97":"code","3bdd4fd4":"markdown"},"source":{"4b36fce1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","094c27e1":"#importing libraries\nimport spacy\nimport nltk\nfrom nltk.tokenize.toktok import ToktokTokenizer\n# nlp = spacy.load('en_core', parse=True, tag=True, entity=True)\ntokenizer = ToktokTokenizer()\nstopword_list = nltk.corpus.stopwords.words('english')\nstopword_list.remove('no')\nstopword_list.remove('not')\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing","34b125a6":"#importing files\ntest_df=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\ntrain_df=pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\nsubmission_df=pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')","b479bee4":"train_df.head()","01d42de1":"test_df.head()","2f5b13b8":"submission_df.head()","13d8fa4a":"# all_df=pd.concat([train_df,test_df])\n# all_df.head()\nall_df=[train_df,test_df]\n","9fceb2db":"# all_df.drop(columns=['keyword','location'],inplace=True)\n# all_df.head()\nfor df in all_df:\n    df.drop(columns=['keyword','location'],inplace=True)\n    \nprint(train_df.head())\nprint(test_df.head())","53627c2b":"count_vectorizer = feature_extraction.text.CountVectorizer()\ntrain_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\ntest_vectors = count_vectorizer.transform(test_df[\"text\"])","fb284173":"# all_df['text']=all_df['text'].apply(lambda x : x.split())\n# all_df.head()","13b88bf6":"clf = linear_model.RidgeClassifier()","101f16f0":"scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\nscores","1ea6a7d5":"clf.fit(train_vectors, train_df[\"target\"])","a8c20135":"submission_df[\"target\"] = clf.predict(test_vectors)\nsubmission_df.head()","7ee47d97":"submission_df.to_csv(\"submission.csv\", index=False)","3bdd4fd4":"# Importing Libraries and Files"}}