{"cell_type":{"614cdee4":"code","af6e2f75":"code","bffd9a99":"code","3582eeb2":"code","e61aed0a":"code","ca21e5c1":"code","82d608a4":"code","7582907f":"code","3feb3222":"code","53b0a3b9":"code","4a30a0da":"code","8e0e6160":"code","d4dad2fd":"code","424c77ee":"code","930707d6":"code","ef7a4477":"code","8507d835":"code","6940cafe":"code","090ecf79":"code","8d78e940":"code","48f8856e":"code","43cd388b":"code","80d08046":"code","a4e57465":"code","843aea10":"code","3ed58989":"code","3f9e041c":"code","e93bd6f5":"code","b992d4f9":"code","e2f1cf79":"code","30562f26":"code","c3feb967":"code","71a2c746":"code","8c9532f3":"code","bfff0759":"code","0aa72716":"markdown","97f7be56":"markdown"},"source":{"614cdee4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        print(filename)\nprint(\"start\")\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","af6e2f75":"train_data = pd.read_csv(\"\/kaggle\/input\/c\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/c\/titanic\/test.csv\")\ndata_all = pd.concat([train_data,test_data],axis=0).reset_index(drop=True)\ndata_all","bffd9a99":"data_all[\"Name_title1\"]=data_all['Name'].str.split(',').str[1]\ndata_all[\"Name_title1\"]\n","3582eeb2":"data_all[\"Name_title2\"]=data_all['Name_title1'].str.split('.').str[0]\ndata_all[\"Name_title2\"]","e61aed0a":"data_all[\"Name_title2\"].value_counts()","ca21e5c1":"train_data[\"Name_title1\"]=train_data['Name'].str.split(',').str[1]\ntrain_data[\"Name_title2\"]=train_data['Name_title1'].str.split('.').str[0]\ntrain_data[\"Name_title2\"].value_counts()","82d608a4":"train_data.info()","7582907f":"missing_values_count = train_data.isnull().sum()\nmissing_values_count\n","3feb3222":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n#b=data.dropna()\nage_median = train_data[(train_data['Age']>0) & (train_data['Age'].isnull() == False)]['Age'].median()\nprint('Median = {}'.format(age_median))\nfare_mode = train_data[(train_data['Fare']>0) & (train_data['Fare'].isnull() == False)]['Fare'].mode()\nprint('Median = {}'.format(fare_mode)) #fill ","53b0a3b9":"sns.distplot(train_data['Age'])","4a30a0da":"Miss = train_data[train_data['Name_title2'] == ' Miss'][[\"Age\"]].median()\nMiss","8e0e6160":"Mr = train_data[train_data['Name_title2'] == ' Mr'][[\"Age\"]].median()\nMr","d4dad2fd":"conditions = [\n    (train_data['Age'].isnull() == True) & (train_data['Name_title2'] == ' Mr') ,\n    (train_data['Age'].isnull() == True) & (train_data['Name_title2'] == ' Miss'),\n    (train_data['Age'].isnull() == True),\n    ]\nvalues = [Mr,Miss,age_median]\ntrain_data['Age'] = np.select(conditions, values)\n","424c77ee":"train_data['Fare']=train_data['Fare'].fillna(0)\ntrain_data[\"Cabin\"] = train_data[\"Cabin\"].replace( np.nan, 'dont_know', regex=True)","930707d6":"missing_values_count = train_data.isnull().sum()\nmissing_values_count\ntrain_data[\"Embarked\"]=train_data[\"Embarked\"].fillna(method='bfill', axis=0).fillna(0)","ef7a4477":"train_data[\"Cabin\"]=  train_data[\"Cabin\"].str[0]\n\n","8507d835":"y=train_data.Survived\ny","6940cafe":"train_data=train_data.drop(columns =[\"Name\",'Name_title1','PassengerId','Ticket','Name_title2','Survived'])\ntrain_data","090ecf79":"# train_data[\"Age\"]=train_data[\"Age\"].fillna(age_median)\n# test_data[\"Age\"]=test_data[\"Age\"].fillna(age_median)\n# train_data['Fare']=train_data['Fare'].fillna(0)\n# test_data['Fare']=test_data['Fare'].fillna(0)\n# train_data[\"Cabin\"] = train_data[\"Cabin\"].replace( np.nan, 'dont_know', regex=True)\n# test_data[\"Cabin\"] = test_data[\"Cabin\"].replace( np.nan, 'dont_know', regex=True)\n# train_data[\"Embarked\"]=train_data[\"Embarked\"].fillna(method='bfill', axis=0).fillna(0)\n# test_data[\"Embarked\"]=test_data[\"Embarked\"].fillna(method='bfill', axis=0).fillna(0)","8d78e940":"# train_data[\"Age\"]=train_data[\"Age\"].fillna(age_median)","48f8856e":"# data_clean=data.drop(columns=[\"PassengerId\",\"Name\"])\n# data_clean","43cd388b":"# data_clean.isnull().sum()","80d08046":"train_data","a4e57465":"categories=[\"Sex\",\"Cabin\",\"Embarked\"]\ncategories","843aea10":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder(handle_unknown='ignore')\ndf_working_data = train_data.copy()\nencoded = enc.fit_transform(df_working_data[categories]).toarray()\nencoded = pd.DataFrame(encoded, columns=enc.get_feature_names(categories))\nencoded\ndf_working_data = pd.concat([train_data,encoded],axis=1)\ndf_working_data\ndf_working_onehot = df_working_data.drop(columns=categories)\ndf_working_onehot\n  ","3ed58989":"# df_working_data2 =  pd.concat([encoded,df_number],axis=1)\n# df_working_data2","3f9e041c":"# pd.options.display.max_rows = 25\n# train_data_onehot =  df_working_data2.loc[:890,df_working_data2.columns]\n# train_data_onehot","e93bd6f5":"# test_data_onehot =  df_working_data2.loc[891:,df_working_data2.columns].reset_index(drop=True)\n# test_data_onehot","b992d4f9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df_working_onehot, y, test_size=0.2, random_state=42)\n","e2f1cf79":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nclassifier = RandomForestClassifier(n_estimators=5, max_depth=7, random_state=2)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\ny_pred1 = classifier.predict(X_train)\nprint(\"Accuracytrain: \", accuracy_score(y_train, y_pred1))\nprint(\"Accuracytest: \", accuracy_score(y_test, y_pred))\n# print(\"Accuracy: \", accuracy_score(y_train, y_pred))\n#print(\"Train set accuracy = \" + str(classifier.score(y_pred, y_test)))\n","30562f26":"def cleandata (dataset):\n    dataset[\"Name_title1\"]=dataset['Name'].str.split(',').str[1]\n    dataset[\"Name_title2\"]=dataset['Name_title1'].str.split('.').str[0]\n    age_median = dataset[(dataset['Age']>0) & (dataset['Age'].isnull() == False)]['Age'].median()\n    Miss = dataset[dataset['Name_title2'] == ' Miss'][[\"Age\"]].median()\n    Mr = dataset[dataset['Name_title2'] == ' Mr'][[\"Age\"]].median()\n    conditions = [\n    (dataset['Age'].isnull() == True) & (dataset['Name_title2'] == ' Mr') ,\n    (dataset['Age'].isnull() == True) & (dataset['Name_title2'] == ' Miss'),\n    (dataset['Age'].isnull() == True),\n    ]\n    values = [Mr,Miss,age_median]\n    dataset['Age'] = np.select(conditions, values)\n    dataset['Fare']=dataset['Fare'].fillna(0)\n    dataset[\"Cabin\"] = dataset[\"Cabin\"].replace( np.nan, 'dont_know', regex=True)\n    dataset[\"Cabin\"]=  dataset[\"Cabin\"].str[0]\n    dataset[\"Embarked\"]=dataset[\"Embarked\"].fillna(method='bfill', axis=0).fillna(0)\n    dataset=dataset.drop(columns =[\"Name\",'Name_title1','PassengerId','Ticket','Name_title2'])\n    categories=[\"Sex\",\"Cabin\",\"Embarked\"]\n    #enc = OneHotEncoder(handle_unknown='ignore')\n    df_working_data = dataset.copy()\n    encoded = enc.transform(df_working_data[categories]).toarray()\n    encoded = pd.DataFrame(encoded, columns=enc.get_feature_names(categories))\n    df_working_data = pd.concat([dataset,encoded],axis=1)\n    df_working_onehot = df_working_data.drop(columns=categories)\n    df_working_onehot\n    return(df_working_onehot)","c3feb967":"test= cleandata(test_data)\ntest","71a2c746":"predictions = classifier.predict(test)\npredictions ","8c9532f3":"output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","bfff0759":"# from sklearn.ensemble import RandomForestClassifier\n\n# y = train_data[\"Survived\"]\n\n# features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n# X = pd.get_dummies(train_data[features])\n# X_test = pd.get_dummies(test_data[features])\n\n# model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n# model.fit(X, y)\n# predictions = model.predict(X_test)\n\n# output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n# output.to_csv('submission.csv', index=False)\n# print(\"Your submission was successfully saved!\")","0aa72716":"encode_data","97f7be56":"clean data"}}