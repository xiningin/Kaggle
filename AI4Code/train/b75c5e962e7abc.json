{"cell_type":{"3c74cf7d":"code","4eb50594":"code","a5add68d":"code","a9774dba":"code","e97ccbff":"code","a4698c2d":"code","adedbb49":"code","2a8a7cb5":"code","612b102d":"code","56c15c06":"code","b25988ae":"code","3b2d2837":"code","4a2436e8":"code","fb7ac958":"code","18ea33e8":"code","2e5b10db":"code","ef1019e7":"code","cb58bf23":"code","0c7e96cd":"code","162827b8":"code","e0e95d29":"code","323b5820":"code","1f8b359d":"code","1d97b98f":"code","2d593ddd":"code","fd29c1de":"code","a54dc060":"code","491050a8":"code","b48afd83":"code","f2ddd9d5":"code","7ac6c848":"code","59dc2e73":"code","6a019368":"code","665b12e0":"code","28ed246c":"code","959532ef":"code","0f1a8361":"code","81fce173":"code","687e7957":"code","b2e3c5a0":"code","90747b1b":"code","cb4ddee3":"code","ef75254b":"code","cdaf46d0":"code","64a4f7de":"markdown","b5f7670a":"markdown","d35db5bb":"markdown","118ca9fe":"markdown","bb5db5f0":"markdown","deb1057c":"markdown","1e565a09":"markdown","c749def7":"markdown","bf38e783":"markdown","38053f46":"markdown","fc44f12f":"markdown","b84f36a0":"markdown","4a9b0f8a":"markdown","a67381fb":"markdown","aa0b5dea":"markdown"},"source":{"3c74cf7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4eb50594":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix,roc_auc_score\nfrom sklearn.linear_model import LogisticRegression,Lasso\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier","a5add68d":"data = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndata.head()","a9774dba":"data.isna().sum()","e97ccbff":"# Imputing the bmi feature with mean\ndata['bmi'].fillna(data['bmi'].mean(),inplace=True)","a4698c2d":"data.isna().sum()","adedbb49":"data.describe().T","2a8a7cb5":"fig,axs=plt.subplots(2,3,figsize=(15,12))\naxs[0,0].boxplot(data['id'])\naxs[0,0].set(xlabel='id')\naxs[0,1].boxplot(data['age'])\naxs[0,1].set(xlabel='age')\naxs[0,2].boxplot(data['hypertension'])\naxs[0,2].set(xlabel='hypertension')\naxs[1,0].boxplot(data['heart_disease'])\naxs[1,0].set(xlabel='heart_disease')\naxs[1,1].boxplot(data['avg_glucose_level'])\naxs[1,1].set(xlabel='avg_glucose_level')\naxs[1,2].boxplot(data['bmi'])\naxs[1,2].set(xlabel='bmi');","612b102d":"sns.pairplot(data,corner=True)","56c15c06":"plt.figure(figsize=(15,10))\nsns.heatmap(data.corr(),annot=True,cmap='Blues')","b25988ae":"# here we can see that data['id'] is trivial than the others. Hence we drop it.\ndata.drop('id',axis=1,inplace=True)","3b2d2837":"data.info()","4a2436e8":"encode=['gender','ever_married','work_type','Residence_type','smoking_status']","fb7ac958":"from sklearn.preprocessing import LabelEncoder\nfor i in encode:\n    l=LabelEncoder()\n    data[i]=l.fit_transform(data[i])","18ea33e8":"data.head(20)","2e5b10db":"x=data.drop(columns='stroke')\ny=data['stroke']","ef1019e7":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)","cb58bf23":"s=MinMaxScaler()\ns.fit(x_train)\nx_train=s.transform(x_train)\nx_test=s.transform(x_test)","0c7e96cd":"plt.hist(y_train);","162827b8":"# Training data is highly imbalanced...so, we use smote to balance the dataset","e0e95d29":"mod=SMOTE()\nx_train1,y_train1=mod.fit_resample(x_train,y_train)\nplt.hist(y_train1);","323b5820":"lg=LogisticRegression(max_iter=500,penalty='l1',solver='liblinear',C=3.0)\nlg.fit(x_train1,y_train1)\nsns.heatmap(confusion_matrix(y_test,lg.predict(x_test)),annot=True,fmt='.2f',xticklabels=['Not Stroke','Stroke'],yticklabels=['Not Stroke','Stroke'])","1f8b359d":"print(classification_report(y_test,lg.predict(x_test)))","1d97b98f":"d=DecisionTreeClassifier(criterion='gini',max_depth=11)\nd.fit(x_train1,y_train1)\nsns.heatmap(confusion_matrix(y_test,d.predict(x_test)),annot=True,fmt='.2f',xticklabels=['Not Stroke','Stroke'],yticklabels=['Not Stroke','Stroke'])","2d593ddd":"print(classification_report(y_test,d.predict(x_test)))","fd29c1de":"r=RandomForestClassifier(criterion='entropy',n_estimators=95)\nr.fit(x_train1,y_train1)\nsns.heatmap(confusion_matrix(y_test,r.predict(x_test)),annot=True,fmt='.2f',xticklabels=['Not Stroke','Stroke'],yticklabels=['Not Stroke','Stroke'])","a54dc060":"print(classification_report(y_test,r.predict(x_test)))","491050a8":"k=KNeighborsClassifier(n_neighbors= 1)\nk.fit(x_train1,y_train1)\nsns.heatmap(confusion_matrix(y_test,k.predict(x_test)),annot=True,fmt='.2f',xticklabels=['Not Stroke','Stroke'],yticklabels=['Not Stroke','Stroke'])","b48afd83":"print(classification_report(y_test,k.predict(x_test)))","f2ddd9d5":"n=GaussianNB()\nn.fit(x_train1,y_train1)\nsns.heatmap(confusion_matrix(y_test,n.predict(x_test)),annot=True,fmt='.2f',xticklabels=['Not Stroke','Stroke'],yticklabels=['Not Stroke','Stroke'])","7ac6c848":"print(classification_report(y_test,n.predict(x_test)))","59dc2e73":"from sklearn.metrics import roc_curve\nfpr,tpr,thresh=roc_curve(y_test,lg.predict_proba(x_test)[:,1])\nfpr1,tpr1,thresh1=roc_curve(y_test,d.predict_proba(x_test)[:,1])\nfpr2,tpr2,thresh2=roc_curve(y_test,r.predict_proba(x_test)[:,1])\nfpr3,tpr3,thresh3=roc_curve(y_test,k.predict_proba(x_test)[:,1])\nfpr4,tpr4,thresh4=roc_curve(y_test,n.predict_proba(x_test)[:,1])","6a019368":"plt.plot(fpr,tpr,color='blue',label='logistic')\nplt.plot(fpr1,tpr1,color='green',label='decision tree')\nplt.plot(fpr2,tpr2,color='red',label='random forest')\nplt.plot(fpr3,tpr3,color='yellow',label='knn')\nplt.plot(fpr4,tpr4,color='black',label='naive')\nplt.legend()\nplt.show()","665b12e0":"roc_auc_score(y_test,lg.predict(x_test))","28ed246c":"roc_auc_score(y_test,d.predict(x_test))","959532ef":"roc_auc_score(y_test,r.predict(x_test))","0f1a8361":"roc_auc_score(y_test,k.predict(x_test))","81fce173":"roc_auc_score(y_test,n.predict(x_test))","687e7957":"accuracy_score(y_test,lg.predict(x_test))","b2e3c5a0":"accuracy_score(y_test,d.predict(x_test))","90747b1b":"accuracy_score(y_test,r.predict(x_test))","cb4ddee3":"accuracy_score(y_test,k.predict(x_test))","ef75254b":"roc_auc_score(y_test,n.predict(x_test))","cdaf46d0":"#Logistic Regression is giving better predictions considering the highest auc_roc score.","64a4f7de":"# Modelling","b5f7670a":"# Feature split","d35db5bb":"# Logistic Regression","118ca9fe":"# Check for null values","bb5db5f0":"# EDA\n## Uni-variate Analysis\n## Bi-variate Analysis","deb1057c":"# Random Forest","1e565a09":"# Naive Baye's","c749def7":"# Check for imbalanced data","bf38e783":"# Decision Tree","38053f46":"# KNN","fc44f12f":"# Check for Outliers","b84f36a0":"# Scaling data","4a9b0f8a":"# Encoding the categorical features","a67381fb":"# train-test split","aa0b5dea":"### we have to reduce false negatives as predicting stroke as not stroke is very dangerous."}}