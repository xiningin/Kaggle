{"cell_type":{"e69a4a9e":"code","02aaf757":"code","d8d34cff":"code","63b610bb":"code","9820cd87":"code","f592d688":"code","0b3c6eb7":"code","747b7ae7":"code","25634de7":"code","781d5073":"code","75c8f331":"code","83f9e503":"code","5c282db6":"code","6ec0d556":"code","7019f7db":"code","827860f5":"code","53857eef":"code","8c3c3229":"code","a0bd9463":"code","d439a63a":"code","e96e7023":"code","1ec04eee":"code","2003524f":"code","6c615301":"code","0ce61b42":"code","15836be0":"code","318db796":"code","22092c49":"code","36747d08":"code","0eed2103":"code","d85a1496":"code","3e7ca29b":"code","3464c57f":"code","42247f4d":"code","9ca07e0e":"code","5213e376":"code","37534a1a":"code","2b71d847":"code","43c41b94":"markdown","d302b84d":"markdown","18f19f5f":"markdown","83a1caf2":"markdown","848157cb":"markdown","81349c39":"markdown","d95126d9":"markdown","75955424":"markdown","92eb33e7":"markdown","273d1452":"markdown","659c5c78":"markdown","d46acb03":"markdown","c2005011":"markdown","9c1b0e9c":"markdown"},"source":{"e69a4a9e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n#pd.options.display.max_rows = 9999\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nplt.style.use('ggplot')\n%matplotlib inline","02aaf757":"tweet_df = pd.read_csv('\/kaggle\/input\/tweet-sentiment\/twitter.csv')\ntweet_df.info()","d8d34cff":"tweet_df.head(10)","63b610bb":"tweet_df = tweet_df.drop('id', 1) #drop the 'id' column","9820cd87":"sns.heatmap(tweet_df.isnull(), yticklabels=False, cbar=False, cmap='Blues')","f592d688":"tweet_df.hist(bins=30, figsize=(13,5), color='r')","0b3c6eb7":"sns.countplot(tweet_df['label'], label='Count')","747b7ae7":"tweet_df['length'] = tweet_df['tweet'].apply(len)","25634de7":"tweet_df.head(10)","781d5073":"tweet_df.length.plot(bins=100, kind='hist')\nplt.xlabel('Length')\nplt.show()","75c8f331":"tweet_df.describe()","83f9e503":"tweet_df[tweet_df['length']==11]['tweet'].iloc[0]","5c282db6":"tweet_df[tweet_df['length']==84]['tweet'].iloc[0]","6ec0d556":"positive = tweet_df[tweet_df.label==0]\npositive.shape","7019f7db":"negative = tweet_df[tweet_df.label==1]\nnegative.shape","827860f5":"sentences = tweet_df.tweet.to_list()","53857eef":"sentences_as_one_string = \" \".join(sentences)","8c3c3229":"from wordcloud import WordCloud\n\nwordCloud = WordCloud(max_words=100, background_color=\"white\").generate(sentences_as_one_string)\nplt.figure(figsize=(15,15))\nplt.imshow(wordCloud, interpolation='bilinear')\nplt.axis('off')\n\n#to save the image\nwordCloud.to_file(\"first_review.png\")","a0bd9463":"negtive_sens_as_one_str = \" \".join(negative.tweet.to_list())\n\nwordCloud = WordCloud(max_words=100, background_color=\"white\").generate(negtive_sens_as_one_str)\nplt.figure(figsize=(15,15))\nplt.imshow(wordCloud, interpolation='bilinear')\nplt.axis('off')","d439a63a":"import string\n\nstring.punctuation","e96e7023":"test = 'Good morning!!!, guys :Vv. You are gonna have  a breakfast'","1ec04eee":"test_punc_removed = ''.join(ch for ch in [char for char in test if char not in string.punctuation])\ntest_punc_removed","2003524f":"from nltk.corpus import stopwords\n\nstopwords.words('english')[:10]","6c615301":"test_punc_removed_clean = [word for word in test_punc_removed.split()\n                            if word.lower() not in stopwords.words('english')]\ntest_punc_removed_clean","0ce61b42":"from sklearn.feature_extraction.text import CountVectorizer\n\nsample = ['This is the first paper', 'This paper is the second paper', 'And this is the third one',\n          'Is this the first paper?']\nvectorizer = CountVectorizer()\nX = vectorizer.fit_transform(sample)","15836be0":"vectorizer.get_feature_names()","318db796":"X.toarray()","22092c49":"import matplotlib.image as mpimg\n\nimg = mpimg.imread('..\/input\/tweet-sentiment\/Capture.PNG')\nplt.figure(figsize=(15,15))\nplt.axis('off')\nplt.imshow(img)","36747d08":"def tweet_cleaning(tweet):\n    tweet_punc_removed = ''.join(ch for ch in [char for char in tweet if char not in string.punctuation])\n    tweet_punc_removed_clean = [word for word in tweet_punc_removed.split() \n                                if word.lower() not in stopwords.words('english')]\n    return tweet_punc_removed_clean","0eed2103":"tweet_df_clean = tweet_df.tweet.apply(tweet_cleaning)\ntweet_df_clean[5]","d85a1496":"tweet_df.tweet[5]","3e7ca29b":"vectorizer = CountVectorizer(analyzer=tweet_cleaning)\ntweets_countvectorizer = CountVectorizer(analyzer=tweet_cleaning, dtype='uint8').fit_transform(np.array(tweet_df.tweet))","3464c57f":"tweets_countvectorizer.shape","42247f4d":"X = tweets_countvectorizer\ny = tweet_df['label']","9ca07e0e":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","5213e376":"from sklearn.naive_bayes import MultinomialNB\n\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)","37534a1a":"from sklearn.metrics import classification_report, confusion_matrix\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, square=True, fmt='d', linewidths=.2, cbar=0, cmap = \"Paired\")\nplt.ylabel('True labels')\nplt.xlabel('Predicted labels')","2b71d847":"print(classification_report(y_test, y_pred))","43c41b94":"**Plot a wordcloud**","d302b84d":"**Create a pipeline for all things we did above**","18f19f5f":"Add column 'length'","83a1caf2":"just wanna share my work","848157cb":"**Prepare data for modeling**","81349c39":"**image to explain count vectorizer:**","d95126d9":"*** *it can be seen that the data is quite imbalanced***","75955424":"Explore the data","92eb33e7":"# This code is original from [a course](https:\/\/www.coursera.org\/projects\/twitter-sentiment-analysis) on Coursera that I took.","273d1452":"The shortest tweet is 11 in length","659c5c78":"**Modeling**","d46acb03":"**Remove stopwords**","c2005011":"**Perform count vectorization**","9c1b0e9c":"**Remove punctuation**"}}