{"cell_type":{"9d896430":"code","f5790825":"code","29ecf25f":"code","61e09008":"code","0a3c5ac9":"code","9cb0309c":"code","f79d6f63":"code","833692a1":"code","7828f015":"code","248e5d79":"code","0780b909":"code","f84df435":"code","769745e5":"code","693badb7":"code","4e1bb8d9":"code","803bc77b":"code","352f9150":"code","bcda4d40":"code","6b59ea2d":"code","0bcdce03":"code","63dfebec":"code","e41632df":"code","e995a77b":"code","34902aa6":"code","58152af8":"code","32e33024":"code","5cc79615":"code","8dcfe5fd":"code","b3f922b8":"code","d96c0add":"code","65c49536":"code","a75b1f56":"code","677f9535":"code","c23ab08c":"code","aa0e24dd":"code","e75edd5e":"code","37270b3a":"code","fca90ca8":"code","0963a0cd":"code","a752c131":"code","1d7da5ee":"code","06c81072":"code","1b9134a4":"code","ba297dbf":"code","eed3b04b":"code","a5acc222":"code","0cda3905":"code","fd1fd128":"code","e9dedbd9":"code","79d51c91":"code","413b593d":"markdown","a5255a27":"markdown","2ddc4dee":"markdown","2b9c29f4":"markdown","3681df24":"markdown","02121c17":"markdown","7c487a2c":"markdown","a46da7ae":"markdown","7fcd3905":"markdown","34f95835":"markdown","ebdbdd88":"markdown","df5b2e28":"markdown","c3068239":"markdown","49e55074":"markdown","e1280f3e":"markdown","008305f1":"markdown","2cd8af6b":"markdown","2c82ba2e":"markdown","f80f6bf3":"markdown","324c85a3":"markdown","586fdbec":"markdown","94c74a33":"markdown","9352597b":"markdown","48d0ade9":"markdown","653567c5":"markdown","9d44d233":"markdown","c8d6a78d":"markdown","5632c7a1":"markdown","3f9449bc":"markdown","61d6d480":"markdown","508b4558":"markdown","2271e24c":"markdown","7cb7395a":"markdown","f983b66d":"markdown","bc81a8dc":"markdown","2ca75abc":"markdown"},"source":{"9d896430":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5790825":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport io\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import metrics\nfrom sklearn import neighbors\nfrom sklearn.svm import SVR\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import LinearRegression, Lasso, ElasticNet, Ridge\nfrom sklearn import model_selection \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt","29ecf25f":"#google colab \u00fczerinde \u00e7al\u0131\u015fanlar bu \u015fekilde veri setini i\u00e7eriye aktarabilir\n#uploaded = files.upload()        \n#df=pd.read_csv(io.BytesIO(uploaded['turkey_car_market.csv']))","61e09008":"df=pd.read_csv(\"\/kaggle\/input\/turkey-car-market-2020\/turkey_car_market.csv\")","0a3c5ac9":"df.shape","9cb0309c":"df.head()","f79d6f63":"df.isnull().sum()","833692a1":"df.info()","7828f015":"sns.catplot(x=\"Yak\u0131t Turu\", y=\"Fiyat\", kind=\"bar\", data=df);","248e5d79":"sns.catplot(x=\"Vites\", y=\"Fiyat\", kind=\"bar\", data=df, palette=\"ch:.25\");","0780b909":"sns.catplot(x=\"Durum\", y=\"Fiyat\", kind=\"bar\", data=df);","f84df435":"sns.catplot(x=\"Kimden\", y=\"Fiyat\", kind=\"bar\", data=df, palette=\"ch:.25\");","769745e5":"print(len(df['Marka'].unique()))               \nmarkalar=df['Marka'].unique()\nprint(markalar)","693badb7":"print(len(df['Arac Tip'].unique()))\ncar_type=df['Arac Tip'].unique()\nprint(car_type)","4e1bb8d9":"len(df[df['Arac Tip']=='-'])  ","803bc77b":"print(len(df['Yak\u0131t Turu'].unique()))\nyak\u0131t_type=df['Yak\u0131t Turu'].unique()\nyak\u0131t_type","352f9150":"print(len(df['Vites'].unique()))\nvites_type=df['Vites'].unique()\nvites_type","bcda4d40":"print('Farkl\u0131 CCM de\u011fer say\u0131s\u0131 : ', len(df['CCM'].unique()),'\\n')\nCCM_type=df['CCM'].unique()\nprint(CCM_type,'\\n')\nprint('Bilmiyorum de\u011feri girilmi\u015f CCM say\u0131s\u0131 : ', len(df[df['CCM']=='Bilmiyorum']))","6b59ea2d":"print('Farkl\u0131 Beygir gucu de\u011fer say\u0131s\u0131 : ', len(df['Beygir Gucu'].unique()),'\\n')\npower=df['Beygir Gucu'].unique()\nprint(power,'\\n')\nprint('Bilmiyorum de\u011feri girilmi\u015f Beygir Gucu say\u0131s\u0131 : ', len(df[df['Beygir Gucu']=='Bilmiyorum']))","0bcdce03":"df['car_age']=2020-df['Model Y\u0131l']     #modelin y\u0131l\u0131 yerine ya\u015f\u0131 ile i\u015flem yap\u0131ca\u011f\u0131z\ndf['car_age'].head()","63dfebec":"df.drop(['Model Y\u0131l'], axis=1,inplace=True)    #i\u015fimize yaramayan kolonlar\u0131 siliyoruz\ndf.drop(['\u0130lan Tarihi'],axis=1,inplace=True)\ndf.columns","e41632df":"df['Arac Tip']=df['Arac Tip'].str.replace('-','Diger')\nlen(df[df['Arac Tip']=='Diger'])","e995a77b":"CCM_drop=df[df['CCM']=='Bilmiyorum'].index\ndf.drop(CCM_drop,axis=0,inplace=True)","34902aa6":"df.shape","58152af8":"l_encoder1=LabelEncoder()\ndf['Marka']=l_encoder1.fit_transform(df['Marka'])","32e33024":"cars={}\ncar_name = list(l_encoder1.inverse_transform([i for i in range(35)]))\nfor i,x in enumerate(car_name):\n  if i not in cars.keys():\n    cars[i] =x","5cc79615":"pd.DataFrame(cars.items(), columns=['label_values', 'car_name']).head()","8dcfe5fd":"l_encoder = LabelEncoder()\ncolumns = ['Arac Tip Grubu', 'Arac Tip','Yak\u0131t Turu', 'Vites', 'CCM', 'Beygir Gucu', 'Renk', 'Kasa Tipi','Kimden', 'Durum']\nfor i in columns:\n  df[i]=l_encoder.fit_transform(df[i])","b3f922b8":"df.head()","d96c0add":"df.info()","65c49536":"df['Beygir Gucu']=df['Beygir Gucu'].replace(18,np.nan)  \ndf.isnull().sum()","a75b1f56":"imputer = KNNImputer(n_neighbors=5)\ndf['Beygir Gucu']=imputer.fit_transform(df[['Beygir Gucu']])\ndf.isnull().sum()","677f9535":"df['Beygir Gucu'] = round(df['Beygir Gucu'])   #doldururken float olarak b\u0131rakt\u0131\u011f\u0131 i\u00e7in tam de\u011fere yuvarl\u0131yorum","c23ab08c":"q1 = df[\"Fiyat\"].quantile(0.25)\nq3 = df[\"Fiyat\"].quantile(0.75)      \n\nIOC = q3 - q1\n\nalt_s\u0131n\u0131r = q1 - 1.5*IOC\n\u00fcst_s\u0131n\u0131r = q3 + 1.5*IOC\n\ns\u0131n\u0131r = (df[\"Fiyat\"] < alt_s\u0131n\u0131r) | (df[\"Fiyat\"] > \u00fcst_s\u0131n\u0131r)\ndf[\"Ayk\u0131r\u0131_Deger\"] = s\u0131n\u0131r\nprint('Ayk\u0131r\u0131 De\u011fer Say\u0131s\u0131 =>\\n',df[\"Ayk\u0131r\u0131_Deger\"].value_counts())\ndf = df.loc[df[\"Ayk\u0131r\u0131_Deger\"] == False]\ndel df[\"Ayk\u0131r\u0131_Deger\"]","aa0e24dd":"y=df['Fiyat']\nx=df.drop(['Fiyat'],axis=1)","e75edd5e":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)\nx_train.head()","37270b3a":"sc_X = StandardScaler()\nx_train = sc_X.fit_transform(x_train)\nx_test = sc_X.transform(x_test)","fca90ca8":"modeller=[]\nscores=[]\ndef compML(alg,x_train,y_train,x_test,y_test):\n    model=alg().fit(x_train,y_train)\n    y_pred=model.predict(x_test)\n    RMSE= np.sqrt(mean_squared_error(y_test,y_pred))\n    model_ismi= alg.__name__\n    model_score = model.score(x_test,y_test)\n    scores.append(model_score*100 if model_score > 0 else 0)\n    modeller.append(model_ismi)\n    print(model_ismi ,\" Modeli Test Hatas\u0131 => \", RMSE,' |  Model Score => ', model_score*100)\n\nmodels=[LGBMRegressor, Lasso,\n        XGBRegressor, LinearRegression,\n        GradientBoostingRegressor,\n        RandomForestRegressor, ElasticNet,\n        DecisionTreeRegressor, Ridge,\n        MLPRegressor,\n        KNeighborsRegressor, \n        SVR]\n\nfor i in models:\n    compML(i,x_train,y_train,x_test,y_test) ","0963a0cd":"plt.figure(figsize=(15,10))\nax = sns.barplot(x=scores, y=modeller, palette=\"ch:4.5,-.7,dark=.3\")\nax.set_title(\"Model-Skor Tablosu\")\nax.set_ylabel(\"Modeller\")\nax.set_ylabel(\"Score\")\nplt.show()","a752c131":"lgbm=LGBMRegressor()     \nlgbm.fit(x_train,y_train)\n\nlgbm_pred = lgbm.predict(x_test)\n\nmodel_score = lgbm.score(x_test,y_test)\nr2_skor = r2_score(y_test, lgbm_pred)\nhata_skor = np.sqrt(mean_squared_error(y_test, lgbm_pred))\nev = metrics.explained_variance_score(y_test, lgbm_pred)\n\nprint(\"Model Score: \", model_score*100)\nprint(\"R2_skoru: \", r2_skor)\nprint(\"Hata Kare: \", hata_skor)\nprint(\"Explained Variance : \", ev)","1d7da5ee":"lgbm_params={'learning_rate':[0.01, 0.1, 0.5],   \n            'n_estimators':[200,500,1000],\n            'max_depth':[5, 7, 10],\n             'colsample_bytree':[0.7, 0.9, 1.0],\n             'subsample': [0.4, 0.5, 0.6, 0.7]\n             }\nlgbm_cv_model=GridSearchCV(lgbm,lgbm_params,cv=10,n_jobs=-1,verbose=2).fit(x_train,y_train)","06c81072":"lgbm_cv_model.best_params_","1b9134a4":"lgbm_tuned=LGBMRegressor(learning_rate = lgbm_cv_model.best_params_['learning_rate'],\n                        max_depth = lgbm_cv_model.best_params_['max_depth'],\n                        n_estimators = lgbm_cv_model.best_params_['n_estimators'],\n                        colsample_bytree = lgbm_cv_model.best_params_['colsample_bytree'],\n                        subsample=lgbm_cv_model.best_params_['subsample']).fit(x_train,y_train)\n\ny_pred=lgbm_tuned.predict(x_test)\n\nmodel_score = lgbm_tuned.score(x_test,y_test)\nr2_skor = r2_score(y_test, y_pred)\nhata_skor = np.sqrt(mean_squared_error(y_test, y_pred))\nadjusted_r2_skor = 1 - (1-r2_skor)*(len(y_test)-1)\/(len(y_test)-x_test.shape[1]-1)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model scoru : \", model_score*100)\nprint(\"R2_skoru: \", r2_skor)\nprint(\"Hata Kare: \", hata_skor)\nprint(\"Adjusted_R2_skoru : \", adjusted_r2_skor)\nprint(\"Explained Variance : \", ev)","ba297dbf":"xgb=XGBRegressor()     \nxgb.fit(x_train,y_train)\n\nxgb_pred = xgb.predict(x_test)\n\nmodel_score = xgb.score(x_test,y_test)\nr2_skor = r2_score(y_test, xgb_pred)\nhata_skor = np.sqrt(mean_squared_error(y_test, xgb_pred))\nev = metrics.explained_variance_score(y_test, xgb_pred)\n\nprint(\"Model Score: \", model_score*100)\nprint(\"R2_skoru: \", r2_skor)\nprint(\"Hata Kare: \", hata_skor)\nprint(\"Explained Variance : \", ev)","eed3b04b":"xgb_params = {'learning_rate':[0.01, 0.1, 0.5],\n              'max_depth':[5, 7, 10],\n             'colsample_bytree':[0.7, 0.9, 1.0],\n             'subsample': [0.4, 0.5, 0.6, 0.7]}\nxgb_cv_model=GridSearchCV(xgb,xgb_params,cv=10,n_jobs=-1,verbose=2).fit(x_train,y_train)","a5acc222":"lgbm_cv_model.best_params_","0cda3905":"xgb_tuned=XGBRegressor(learning_rate = xgb_cv_model.best_params_['learning_rate'],\n                        max_depth = xgb_cv_model.best_params_['max_depth'],\n                        colsample_bytree = xgb_cv_model.best_params_['colsample_bytree'],\n                        subsample=xgb_cv_model.best_params_['subsample']).fit(x_train,y_train)\n\ny_pred=xgb_tuned.predict(x_test)\n\nmodel_score = xgb_tuned.score(x_test,y_test)\nr2_skor = r2_score(y_test, y_pred)\nhata_skor = np.sqrt(mean_squared_error(y_test, y_pred))\nadjusted_r2_skor = 1 - (1-r2_skor)*(len(y_test)-1)\/(len(y_test)-x_test.shape[1]-1)\nev = metrics.explained_variance_score(y_test, y_pred)\n\nprint(\"Model scoru : \", model_score*100)\nprint(\"R2_skoru: \", r2_skor)\nprint(\"Hata Kare: \", hata_skor)\nprint(\"Adjusted_R2_skoru : \", adjusted_r2_skor)\nprint(\"Explained Variance : \", ev)","fd1fd128":"sns.scatterplot(x=y_test,y=y_pred)","e9dedbd9":"sns.jointplot(x=y_test, y=y_pred,  kind='reg',\n                  joint_kws={'line_kws':{'color':'cyan'}})","79d51c91":"real_pred = pd.DataFrame({'Ger\u00e7ek Fiyat': np.array(y_test).flatten(), 'Tahmini Fiyat': y_pred.flatten(),'Fark':np.array(y_test).flatten()-y_pred.flatten()})\nreal_pred.Fark=round(real_pred.Fark)\nreal_pred.head(10)","413b593d":"#### \u0130ki farkl\u0131 model i\u00e7inde tuning i\u015flemini ger\u00e7ekle\u015ftirdik. En iyi de\u011ferler LightGBM modelinde olu\u015ftu. O y\u00fczden model se\u00e7imimiz LightGBM oluyor.","a5255a27":"Ara\u00e7lar\u0131n Model Y\u0131l\u0131 yerine ya\u015flar\u0131yla i\u015flem yapmak bize daha kolayl\u0131k sa\u011flayacakt\u0131r. Buna G\u00f6re bir kolon olu\u015ftural\u0131m","2ddc4dee":"## tahminler ve ger\u00e7ek de\u011ferler aras\u0131ndaki ili\u015fkiyi g\u00f6rselle\u015ftirelim ","2b9c29f4":"\u00d6ncelikle ara\u00e7 tipindeki '-' ile girilmi\u015f verileri d\u00fczenleyece\u011fiz. Bu \u015fekilde az say\u0131da veri var. Ancak bu kolonda \u00e7e\u015fitlilik \u00e7ok fazla oldu\u011fundan dolay\u0131 bu verileri silmek yerine 'di\u011fer' adl\u0131 bir de\u011fi\u015fkene ataca\u011f\u0131z. ","3681df24":"1- Yak\u0131t T\u00fcr\u00fcne G\u00f6re Ara\u00e7 Fiyatlar\u0131na bakal\u0131m","02121c17":"G\u00f6r\u00fcld\u00fc\u011f\u00fc \u00fczere 0 km ara\u00e7lar\u0131n fiyatlar\u0131nda \u00e7ok b\u00fcy\u00fck bir fark var. Bir de sat\u0131c\u0131ya g\u00f6re fiyatlar\u0131 inceleyelim","7c487a2c":"Ara\u00e7 Tipi Kolonunda oldu\u011fu gibi Beygir G\u00fcc\u00fc ve CCM kolonlar\u0131nda da uygun olmayan veriler mevcut. Bunlar\u0131nda say\u0131s\u0131n\u0131 \u00f6\u011frenelim.","a46da7ae":"## Ger\u00e7ek De\u011ferler ile Tahminler Aras\u0131ndaki 10 arac\u0131n tablosu","7fcd3905":"\u0130lk \u00f6nce Araba Markalar\u0131n\u0131 say\u0131sal forma d\u00f6nd\u00fcr\u00fcp daha sonra hangi say\u0131n\u0131n hangi modele denk geldi\u011fini tablo \u015feklinde g\u00f6sterece\u011fiz","34f95835":"NOT: Beygir G\u00fcc\u00fc kolonunda 5549 adet Bilmiyorum de\u011feri girilmi\u015f kolon bulunuyordu. Bu kolonlar\u0131 En yak\u0131n kom\u015fular\u0131na g\u00f6re(KNN) biraz sonra doldurma i\u015flemi yapaca\u011f\u0131z.","ebdbdd88":"Kolonlarlardaki benzersiz ka\u00e7 kategorik veri var bunlar\u0131 inceleyece\u011fiz","df5b2e28":"\u0130lkel E\u011fitim a\u015famas\u0131n\u0131 tamamlam\u0131\u015f olduk. Buna G\u00f6re En iyi sonu\u00e7lar\u0131 LightGBM ve XGBoost g\u00f6sterdi. Bu modeller \u00fczerinden ilerleyece\u011fiz ve model tuning i\u015flemi ger\u00e7ekle\u015ftirece\u011fiz. Ondan sonra son modelimize karar verece\u011fiz","c3068239":"\" - \" ile tan\u0131mlanm\u0131\u015f bir ara\u00e7 tipi var. Bu modelimiz i\u00e7in uygun bir veri de\u011fil. Bu veriden ka\u00e7 tane oldu\u011funu \u00f6\u011frenelim ve ilerleyen ad\u0131mlarda \u00fczerinde ona g\u00f6re i\u015flem yapal\u0131m","49e55074":"## Uygun olmayan Verileri Temizleme","e1280f3e":"## 2-XGBoost","008305f1":"2-Vites T\u00fcr\u00fcne G\u00f6re Ara\u00e7 Fiyatlar\u0131","2cd8af6b":"## 1-LightGBM","2c82ba2e":"## Verimizi G\u00f6rselle\u015ftirelim","f80f6bf3":"Ya\u015f de\u011fi\u015fkenini olu\u015fturdu\u011fumuz i\u00e7in Model Y\u0131l\u0131n\u0131 art\u0131k silebiliriz. B\u00fct\u00fcn ara\u00e7lar\u0131nda ayn\u0131 y\u0131l i\u00e7inde ilan verildi\u011fini d\u00fc\u015f\u00fcn\u00fcrsek i\u015flem kolayl\u0131\u011f\u0131 a\u00e7\u0131s\u0131ndan \u0130lan tarihinide silebiliriz","324c85a3":"Yukar\u0131da Bahsetti\u011fim Beygir G\u00fcc\u00fc Kolonunu doldurma zaman\u0131 geldi. \n","586fdbec":"Eksik veri Kontrol\u00fc yapal\u0131m","94c74a33":"Kategorik De\u011ferleri Modelimize vermek i\u00e7in say\u0131sal forma d\u00f6nd\u00fcrece\u011fiz\n## Label Encoder","9352597b":"## Ayk\u0131r\u0131 de\u011ferleri Silmek","48d0ade9":"## Kolonlar\u0131 inceleyelim","653567c5":"3- Ara\u00e7 Durumuna G\u00f6re Fiyatlar","9d44d233":"Modelimizi optimize etmek i\u00e7in bir \u00e7ok hiperparametre deneyece\u011fiz. Burada hangi de\u011fereri denemek istedi\u011fimizi bir dict format\u0131nda GridSearchCV fonksiyonuna veriyoruz","c8d6a78d":"Import The Necessary Packages","5632c7a1":"Verilerimizi say\u0131sal forma d\u00f6nd\u00fcrd\u00fck ancak hepsi farkl\u0131 aral\u0131klarda de\u011fer al\u0131yor. Bunlar\u0131 daha d\u00fczenli \u015fekilde modelimize vermeliyiz. Bu y\u00fczden kolonlar\u0131m\u0131za Standard Scaler i\u015flemi uygulayaca\u011f\u0131z","3f9449bc":"Model Tuning i\u015flemimiz tamamland\u0131. En iyi parametrelere ula\u015ft\u0131k. \u015fimdi bunlar\u0131 modelimize vererek tekrardan e\u011fitece\u011fiz. B\u00f6ylelikle optimize final modelimize ula\u015fm\u0131\u015f olaca\u011f\u0131z","61d6d480":"Label Encoder i\u015flemi uygulad\u0131\u011f\u0131m\u0131z i\u00e7in \u015fuanda ***\"Bilmiyorum\"*** de\u011ferine sahip verinin kar\u015f\u0131l\u0131\u011f\u0131 18. \u0130lk \u00f6nce Bunlar\u0131 NaN formuna d\u00f6nd\u00fcr\u00fcyoruz","508b4558":"Veri setimizi ay\u0131rd\u0131k. \u015fimdi modelimizi e\u011fitme s\u0131ras\u0131 geldi. ancak hangi modeli kullanarak e\u011fitice\u011fimize karar vermemiz gerekiyor. bu y\u00fczden t\u00fcm modelleri s\u0131rayla deneyen bir fonksiyon yaz\u0131yoruz. Bu fonksiyon d\u0131\u015fardan(verdi\u011fimiz listeden) ald\u0131\u011f\u0131 fonksiyonlar\u0131 tek tek deniyor ve ekrana model score ve mean squared error de\u011ferini yaz\u0131yor. Buradan elde edece\u011fimiz de\u011fere g\u00f6re hangi model \u00fczerinden ilerleyece\u011fimizi se\u00e7ece\u011fiz.","2271e24c":"## Ba\u011f\u0131ml\u0131 ve Ba\u011f\u0131ms\u0131z De\u011fi\u015fkenleri Ay\u0131rma","7cb7395a":"Te\u015fekk\u00fcrler :)\nLinkedin : https:\/\/www.linkedin.com\/in\/onur-y%C4%B1lmaz-9a58a11a2\/","f983b66d":"\u015eimdi de bu Nan De\u011fere sahip verileri KNNImputer kullanarak 5 kom\u015fu say\u0131s\u0131na g\u00f6re dolduraca\u011f\u0131z","bc81a8dc":"Kalan Di\u011fer De\u011fi\u015fkenlerede Label Encoder i\u015flemini uyguluyoruz","2ca75abc":"CCM kolonunda da 'Bilmiyorum' de\u011feri girilmi\u015f 108 tane verimiz bulunuyordu. Datasetimizin b\u00fcy\u00fckl\u00fc\u011f\u00fcn d\u00fc\u015f\u00fcn\u00fcrsek bu de\u011ferleri silmek modelimizi \u00e7ok fazla etkilemeyecektir. \u00c7e\u015fitlilik az oldu\u011fundan dolay\u0131 doldurma i\u015flemide yapmam\u0131z modelimizin ba\u015fka tarafa kaymas\u0131na sebep olabilir."}}