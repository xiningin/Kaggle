{"cell_type":{"9e80fd42":"code","109fa745":"code","8c0d3ccb":"code","9a3f8066":"code","3ce0ea23":"code","69762d84":"code","3dcb749b":"code","b4bfca08":"code","b72478f2":"code","7559bb79":"code","1a200092":"code","6273232a":"code","9b091f5f":"code","3f4975af":"code","473e9d80":"code","2abb615b":"code","d90ddec8":"code","91d3f8f7":"code","25783e4e":"code","36380608":"code","b7983f74":"code","ab5fe7a3":"code","c4b0614f":"code","e2f07562":"code","c3ca27fe":"code","953b7a28":"code","ded16aa1":"code","64136ff7":"code","5b97932a":"code","2ed1ee90":"code","cf48df1f":"code","9a3bf341":"code","fdc59a88":"code","be1e2bb2":"code","9c5d909e":"code","a31640c3":"code","d27ece3f":"code","7a7c0e3b":"code","9ee4d161":"code","ffdf1ce8":"code","d03f553f":"code","be450728":"code","149b80c4":"code","c53ed332":"code","08f31c97":"code","b1ed5009":"code","63036175":"code","dd55cd32":"code","07197b23":"code","a635f005":"code","98059924":"code","e5bfb4b3":"code","7ece8735":"code","bade978d":"code","bdd81163":"code","f91eecf5":"code","3dff907d":"code","94c1585e":"code","09c92df3":"code","01e6ac07":"code","1e4d49d2":"code","a21f69c8":"code","0138b163":"markdown","6e34df94":"markdown","6f9e53c4":"markdown","7c41f356":"markdown","61429632":"markdown","b7b30df6":"markdown","ca8bc1fb":"markdown","93cfa645":"markdown","afbe8f9f":"markdown","50bf55a4":"markdown","a0c706db":"markdown","fdc2ee49":"markdown","c3fbe364":"markdown","efc5de2c":"markdown","76557c98":"markdown","2b3bd11e":"markdown","a0987c87":"markdown","74082d3e":"markdown"},"source":{"9e80fd42":"import pandas as pd","109fa745":"df = pd.read_csv('..\/input\/fake-news\/train.csv')","8c0d3ccb":"df.head()","9a3f8066":"X = df.drop('label' ,axis=1)","3ce0ea23":"X.head()","69762d84":"y = df['label']","3dcb749b":"y.head()","b4bfca08":"df.shape","b72478f2":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer","7559bb79":"df = df.dropna() #removing NaN values","1a200092":"df.shape","6273232a":"df.head(20)","9b091f5f":"messages = df.copy() ","3f4975af":"messages","473e9d80":"messages.reset_index(inplace=True)","2abb615b":"messages # indexes for traversing","d90ddec8":"messages['title'][0] #index are useful","91d3f8f7":"from nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower() #lowercase\n    review = review.split() #splitting strings\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","25783e4e":"# corpus","36380608":"cv = CountVectorizer(max_features=5000, ngram_range=(1,3))\nX = cv.fit_transform(corpus).toarray()","b7983f74":"X.shape","ab5fe7a3":"y = messages['label']","c4b0614f":"#Divide the dataset into Train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)","e2f07562":"print(X.shape, X_train.shape, X_test.shape)","c3ca27fe":"cv.get_feature_names()[:20] # top 20 features","953b7a28":"count_df = pd.DataFrame(X_train, columns=cv.get_feature_names())","ded16aa1":"count_df.head()","64136ff7":"import matplotlib.pyplot as plt","5b97932a":"def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    if normalize:\n        cm = cm.astype('float')\/cm.sum(axis=1)[:, np.newaxis]\n        print('Normalized Confusion Matrix')\n    else:\n        print('Confusion Matrix, without normalization')\n    \n    thresh = cm.max()\/2\n    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i,j],\n                horizontalalignment='center',\n                color='white' if cm[i, j] > thresh else \"black\")\n        \n    plt.tight_layout()\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n","2ed1ee90":"from sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()","cf48df1f":"from sklearn import metrics\nimport numpy as np\nimport itertools","9a3bf341":"classifier.fit(X_train, y_train)\npred = classifier.predict(X_test)\nscore = metrics.accuracy_score(y_test,pred)*100\nprint('Accuracy: %0.3f'% score)\ncm = metrics.confusion_matrix(y_test, pred)\nplot_confusion_matrix(cm, classes=['FAKE', 'REAL'])","fdc59a88":"classifier.fit(X_train, y_train)\npred = classifier.predict(X_test)\nscore = metrics.accuracy_score(y_test, pred)*100\nscore","be1e2bb2":"y_train.shape","9c5d909e":"from sklearn.linear_model import PassiveAggressiveClassifier\nlinear_clf = PassiveAggressiveClassifier()","a31640c3":"linear_clf.fit(X_train, y_train)\npred = linear_clf.predict(X_test)\nscore = metrics.accuracy_score(y_test, pred)*100\nprint(\"Accuracy: %0.3f\"%score)\ncm = metrics.confusion_matrix(y_test, pred)\nplot_confusion_matrix(cm, classes=['FAKE Data', 'REAL Data'])","d27ece3f":"classifier = MultinomialNB(alpha=0.1)","7a7c0e3b":"previous_score = 0\nfor alpha in np.arange(0,1,0.1):\n    sub_classifier = MultinomialNB(alpha=alpha)\n    sub_classifier.fit(X_train, y_train)\n    y_pred = sub_classifier.predict(X_test)\n    score = metrics.accuracy_score(y_test, y_pred)\n    if score > previous_score:\n        classifier = sub_classifier\n    print(\"Alpha: {}, Score: {}\".format(alpha, score))","9ee4d161":"#Get Feature names\nfeature_names = cv.get_feature_names()","ffdf1ce8":"classifier.coef_[0]","d03f553f":"# Most Real\nsorted(zip(classifier.coef_[0], feature_names), reverse=True)[:20]","be450728":"# Most FAKE\nsorted(zip(classifier.coef_[0], feature_names))[:100]","149b80c4":"corpus[3]","c53ed332":"tfidf_v = TfidfVectorizer(max_features=5000, ngram_range=(1,3))\nX = tfidf_v.fit_transform(corpus).toarray()","08f31c97":"X.shape","b1ed5009":"y = messages['label']","63036175":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)","dd55cd32":"tfidf_v.get_feature_names()[:20]","07197b23":"# all things actully applied\ntfidf_v.get_params()","a635f005":"count_df = pd.DataFrame(X_train, columns=tfidf_v.get_feature_names())","98059924":"count_df.head()","e5bfb4b3":"def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    if normalize:\n        cm = cm.astype('float')\/cm.sum(axis=1)[:, np.newaxis]\n        print('Normalized Confusion Matrix')\n    else:\n        print('Confusion Matrix, without normalization')\n    \n    thresh = cm.max()\/2\n    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i,j],\n                horizontalalignment='center',\n                color='white' if cm[i, j] > thresh else \"black\")\n        \n    plt.tight_layout()\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n","7ece8735":"classifier = MultinomialNB()","bade978d":"classifier.fit(X_train, y_train)\npred = classifier.predict(X_test)\nscore = metrics.accuracy_score(y_test,pred)*100\nprint('Accuracy: %0.3f'% score)\ncm = metrics.confusion_matrix(y_test, pred)\nplot_confusion_matrix(cm, classes=['FAKE', 'REAL'])","bdd81163":"classifier.fit(X_train, y_train)\npred = classifier.predict(X_test)\nscore = metrics.accuracy_score(y_test, pred)*100\nscore","f91eecf5":"linear_clf.fit(X_train, y_train)\npred = linear_clf.predict(X_test)\nscore = metrics.accuracy_score(y_test, pred)*100\nprint(\"Accuracy: %0.3f\"%score)\ncm = metrics.confusion_matrix(y_test, pred)\nplot_confusion_matrix(cm, classes=['FAKE Data', 'REAL Data'])","3dff907d":"classifier = MultinomialNB(alpha=0.1)","94c1585e":"previous_score = 0\nfor alpha in np.arange(0,1,0.1):\n    sub_classifier = MultinomialNB(alpha=alpha)\n    sub_classifier.fit(X_train, y_train)\n    y_pred = sub_classifier.predict(X_test)\n    score = metrics.accuracy_score(y_test, y_pred)\n    if score > previous_score:\n        classifier = sub_classifier\n    print(\"Alpha: {}, Score: {}\".format(alpha, score))","09c92df3":"#Get Feature names\nfeature_names = cv.get_feature_names()","01e6ac07":"classifier.coef_[0]","1e4d49d2":"# Most Real\nsorted(zip(classifier.coef_[0], feature_names), reverse=True)[:20]","a21f69c8":"# Most FAKE\nsorted(zip(classifier.coef_[0], feature_names))[:100]","0138b163":"# Passive Agressive Classifier Algorithm","6e34df94":"# MultinomialNB Algorithm","6f9e53c4":"# Passive Aggressive Algorithm","7c41f356":"# TF-IDF Vectorizer","61429632":"### Creating the Bag of Words","b7b30df6":"Removing all stopwords, special characters, numbers, making whole data into lower case","ca8bc1fb":"# Multinomial Classifier with Hyerparameter","93cfa645":"# Import Librarires and Datasets","afbe8f9f":"# Making new Data Frame","50bf55a4":"# Multinomial Classifier with Hyerparameter","a0c706db":"# Vectorizing","fdc2ee49":"# Applying CountVectorizer","c3fbe364":"# GET INDEPEMDENT FEATURES","efc5de2c":"to save existence of 'df', for processing we are using 'messages'","76557c98":"# GET THE DEPENDENT FEATUERS","2b3bd11e":"# MultinomialNB Algorithm","a0987c87":"\n# Visualizing Confusion Matrix","74082d3e":"# Data Preprocessing"}}