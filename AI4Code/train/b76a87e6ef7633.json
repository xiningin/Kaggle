{"cell_type":{"d0b928da":"code","71427355":"code","9a4b7a9d":"code","4c577d84":"code","e0c19277":"code","494f461f":"code","27952076":"code","d71a3463":"code","37e3e447":"code","49e3e6c4":"code","18bdf04b":"code","fe315c4b":"code","aa6a3ecd":"code","ba2b5fd4":"code","3f8bef64":"code","fbc3c33b":"code","9c74722c":"code","0dbe2551":"code","205fa793":"code","7aec97b4":"markdown","35dd298d":"markdown","c9dc7e6c":"markdown","6241d0d3":"markdown","48336113":"markdown","209bdcbd":"markdown","47fa10a1":"markdown","df56560f":"markdown","e24461ac":"markdown","21a6ba72":"markdown","9e715d33":"markdown","786ffe63":"markdown","9d745c5e":"markdown"},"source":{"d0b928da":"# imports\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","71427355":"!ls ..\/input","9a4b7a9d":"train = torch.load('..\/input\/wustl-math450-spring-2021\/train.pt')\ntest = torch.load('..\/input\/wustl-math450-spring-2021\/test.pt')\n\ntrain_data, train_targets = train['data'], train['label']\ntest_data = test['data']","4c577d84":"# verifying the shapes\nprint(f\"The shapes of train data, train targets, test data are\\n {train_data.size()}, {train_targets.size()}, {test_data.size()}.\")","e0c19277":"fig, axes = plt.subplots(4,8, figsize=(20, 12))\naxes = axes.reshape(-1)\nnp.random.seed(1)\nidx = np.random.choice(len(train_data), size=32)\n\nfor i, ix in enumerate(idx):\n    axes[i].axis('off') # hide the axes ticks\n    axes[i].imshow(train_data[ix], cmap = 'gray')\n    axes[i].set_title(str(int(train_targets[ix])), color= 'black', fontsize=25)\nplt.show()","494f461f":"from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck\n\nclass MyResNet(ResNet):\n    def __init__(self,\n                 block=BasicBlock, \n                 layers=[2, 2, 2, 2],\n                 num_classes=10):\n        super(MyResNet, self).__init__(block, \n                                       layers, \n                                       num_classes=num_classes) \n        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3,bias=False)\n        \n        '''\n        you can modify the layers in this initialization of ResNet if you like\n        '''\n        \n# choose 1        \nresnet18 = {\n    \"block\": BasicBlock,\n    \"layers\": [2, 2, 2, 2]\n}\n\nresnet34 = {\n    \"block\": BasicBlock,\n    \"layers\": [3, 4, 6, 3]\n}\n\nresnet50 = {\n    \"block\": Bottleneck,\n    \"layers\": [3, 4, 6, 3]\n}\n\n\n\nmodel = MyResNet(**resnet18)","27952076":"!pip install torchsummary -q\nfrom torchsummary import summary # similar function to tensorflow\/keras summary for torch","d71a3463":"summary(model, (1,28,28), batch_size=128, device='cpu') # (color_channel, 28, 28)","37e3e447":"batch_size = 256\nX_tr, X_val, y_tr, y_val = train_test_split(train_data[:,None,:,:].float(), \n                                            train_targets.long(), \n                                            random_state=42, # experiment replicable\n                                            train_size=0.8, # 80% train data, 20% valid data\n                                           )\ntrain_set = TensorDataset(X_tr, y_tr)\ntrain_loader = DataLoader(train_set, batch_size=batch_size)\n\nvalid_set = TensorDataset(X_val, y_val)\nval_loader = DataLoader(valid_set, batch_size=batch_size)","49e3e6c4":"sample = next(iter(train_loader))\nprint(sample[0].size(), sample[1].size())","18bdf04b":"with torch.no_grad():\n    sample_output = model(sample[0]) # verifying the model is okay\n\nprint(sample_output.size()) # should be (batch_size, n_classes)","fe315c4b":"from torch.optim import Optimizer","aa6a3ecd":"class SGD(Optimizer):\n    \"\"\"\n      Implements the SGD with momentum simplified \n      from the torch official one for Math 450 WashU\n      \n      Args:\n          params (iterable): iterable of parameters to optimize or dicts defining\n              parameter groups\n          lr (float): learning rate\n          weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n          nesterov (bool, optional): whether to use Nesterov's momentum (default: False)\n      \n      For final project:\n          update a version with nesterov's momentum in it\n          \n      Example:\n          >>> optimizer = SGD(model.parameters(), lr=1e-2)\n          >>> optimizer.zero_grad()\n          >>> loss_fn(model(input), target).backward()\n          >>> optimizer.step()\n      \"\"\"\n\n    def __init__(self, params, lr=1e-3, \n                 momentum=0, # beta: momentum constant\n                 dampening=0, # no uses for dampening if nesterov is used\n                 weight_decay=0, # epsilon: weight decay constant\n                 nesterov=False, # nesterov by default is off\n                 ):\n      defaults = dict(lr=lr, \n                      momentum=momentum,\n                      dampening=dampening,\n                      weight_decay=weight_decay,\n                      nesterov=nesterov,\n                      )\n      super(SGD, self).__init__(params, defaults)\n      \n\n    def step(self, closure=None):\n\n        for group in self.param_groups:\n            weight_decay = group['weight_decay']\n            momentum = group['momentum']\n            dampening = group['dampening']\n            nesterov = group['nesterov']\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n\n                d_p = p.grad.data\n\n                if weight_decay != 0:\n                    d_p.add_(weight_decay, p.data)\n\n                if momentum != 0:\n                    param_state = self.state[p]\n                    if 'momentum_buffer' not in param_state:\n                        buffer = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n                    else:\n                        buffer = param_state['momentum_buffer']\n                        buffer.mul_(momentum).add_(1 - dampening, d_p)\n                    \n                    if nesterov:\n                        # NAG: refer to HW 5\n                        d_p = d_p.add(buf, alpha=momentum) \n                    else: \n                        d_p = buffer\n                # p = p - d_p * lr = p - (d_p + (buf * momentum + d_p) * momentum) * lr\n                p.data = p.data - group['lr']*d_p\n\n        return loss","ba2b5fd4":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device) # should be cuda if GPU is enabled","3f8bef64":"from tqdm.auto import tqdm\n\nlearning_rate = 1e-3\noptimizer = SGD(model.parameters(), \n                lr=learning_rate,\n                # momentum and nesterov here\n               )\nloss_func = nn.CrossEntropyLoss()\n\nmodel.to(device);","fbc3c33b":"epochs = 100\nacc_last_epoch = 0.0\n\nfor epoch in range(epochs):\n    \n    model.train()\n    \n    loss_vals = []\n    acc_on_valid = [0.0] # list the accuracy on validation dataset\n    acc_max = 0.0 # current maximum accuracy\n    \n    with tqdm(total=len(train_loader)) as pbar:\n        for x, targets in train_loader:\n            \n            x, targets = x.to(device), targets.to(device)\n            \n            # forward pass\n            outputs = model(x)\n            \n            # loss function\n            loss = loss_func(outputs, targets)\n            \n            # record loss function values\n            loss_vals.append(loss.item())\n            \n            # clean the gradient from last iteration\n            optimizer.zero_grad()\n            \n            # backprop\n            loss.backward()\n            \n            # gradient descent\n            optimizer.step()\n                \n            desc = f\"epoch: [{epoch+1}\/{epochs}] | loss: {np.mean(loss_vals):.4f}\"\n            desc += f\"| acc on valid: {acc_last_epoch:.2f}\"\n            pbar.set_description(desc)\n            pbar.update()\n\n    # check accuracy (simple validation)\n    with torch.no_grad():\n        for x_v, y_v in val_loader:\n            # x_v: validation image\n            # y_v: validation target\n            x_v, y_v = x_v.to(device), y_v.to(device)\n            yhat = model(x_v) # yhat is (batch_size, 10)\n            yhat = yhat.argmax(dim=-1) # yhat is (batch_size, )\n            acc = (yhat == y_v).float().mean() # checking accuracy for a batch\n            acc = acc.cpu().numpy()\n            acc_on_valid.append(acc)\n        acc_last_epoch = np.mean(acc_on_valid)\n\n        if acc_last_epoch > acc_max:\n            # np.mean(acc_on_valid): \n            # average accuracy for each batch in valid in current epoch\n            torch.save(model.state_dict(), f'my_model.pt')\n            acc_max = acc_last_epoch\n                ","9c74722c":"model.load_state_dict(torch.load('.\/my_model.pt', map_location=device))\nmodel.eval(); # this cannot be omitted due to dropout","0dbe2551":"test = TensorDataset(test_data[:,None,:,:].float())\ntest_loader = DataLoader(test, batch_size = batch_size, shuffle = False, drop_last=False)\n\ny_preds = []\nfor x in tqdm(test_loader):\n    with torch.no_grad():\n        x = x[0].to(device)\n        y_pred = model(x)\n        y_preds.append(y_pred.cpu().detach().numpy())\n        \ny_preds = np.concatenate(y_preds)\npreds = y_preds.argmax(axis=-1).astype(int)\nprint(preds.shape) # should be 30,000","205fa793":"len_test = test_data.size(0)\nsolutions = np.zeros((test_data.size(0), 2))\nsolutions[:,0] = np.arange(1,len_test+1)\nsolutions[:,1] = preds\nsolutions = solutions.astype(int)\nnp.savetxt(\"solutions-yournames.csv\", solutions, \n           fmt='%s', header = 'Id,Category', delimiter = ',', comments='')","7aec97b4":"![title](https:\/\/sites.wustl.edu\/scao\/files\/2021\/04\/math450-kaggle.png)","35dd298d":"# Final Project: write an optimizer\n\nWe will have 3 given CNN models as follows, and we will write our own optimizer(s) using `torch.optim` interface to optimize the given 3 models. You are free to use any techniques listed in the final project page to optimize the model. The goal is to optimize the model such that the model(s) trained performs good in the test set with unknown targets.\n\n\n## Models:\nThe 3 fixed models we can use are the famous first state-of-art image recognition CNN ResNet: ResNet 18, ResNet 34, and ResNet 509\\ [https:\/\/pytorch.org\/hub\/pytorch_vision_resnet\/](https:\/\/pytorch.org\/hub\/pytorch_vision_resnet\/). Their settings are in the next cell. \nThe `__init__()` has two parameters: \n- `block`: the first type is the `BasicBlock` used for building ResNet, defined in the file (`torchvision.models.resnet`). The other type is `Bottleneck` block, which has a more agressive dimension reduction mechanics.\n- `[2, 2, 2, 2]`: Each number denotes the number of `Bottleneck` or `BasicBlock` modules in a \"stage\". It depends on how deep you want the networks to be. For example, for ResNet18, it is `[2, 2, 2, 2]`; for ResNet34, it is `[3, 4, 6, 3]`.\n\nThe full code of ResNet is here: [https:\/\/github.com\/pytorch\/vision\/blob\/master\/torchvision\/models\/resnet.py](https:\/\/github.com\/pytorch\/vision\/blob\/master\/torchvision\/models\/resnet.py). We are just gonna import the `torchvision` implementation, and change the first convolutional layer to accept single channel input, and the stride of the first convolutional layer from 2 to 1.\n\n## New optimizer to try:\n\n#### RMSprop\nThe RMSprop algorithm (non stochastic version) is as follows:\n> Choose $w_0$, $\\alpha$, $\\gamma$, $\\epsilon$, and let $s_{-1} = 1$ <br><br>\n>    For $k=0,1,2, \\cdots, M$<br><br>\n>    &nbsp;&nbsp;&nbsp;&nbsp;  $s_{k} = \\gamma s_{k-1} + (1 - \\gamma)\\, \\left|\\nabla f(w_k)\\right|^2$<br><br>\n>    &nbsp;&nbsp;&nbsp;&nbsp;    $\\displaystyle w_{k+1} =  w_k -  \\frac{\\alpha} {\\sqrt{s_{k}+ \\epsilon}} \\nabla f(w_k)$  \nwhere $\\left|\\nabla f(w_k)\\right|$ denotes the magnitude of the gradient vector.\n\nAn optional optimizer to try would be to adapt RMSprop to the template we have. We are free to implement any from [An overview of gradient descent optimization algorithms](https:\/\/ruder.io\/optimizing-gradient-descent\/). Note that most of the algorithm have their built-in version in `torch.optim` submodule. If you are able to unwrap the official torch code to fit the template, you are welcome to do that as well.\n\n\n## Cross-validation:\n\nSince you do not have access to the target of the test set, to cross-validate your model, you should split the training samples to two sets using the techniques learned in class: one is training dataset, the other is your validation dataset (so that you have access to the targets of this set). This routine is usually used for Kaggle competitions and in the real world model deployment to ensure the trained model has generalizability to the unseen data. In this starter code, a simple `train_test_split` technique is used for this purpose. \n\n## Hyperparameter tuning:\nAside from writing our own optimizer, there are quite a few hyperparameter for us to tune to achieve better performance:\n- batch size\n- learning rate and\/or with a scheduler\n- dropout rate\n- early stop\n- other validation strategy based tuning\nIt is okay to use autoML package (H2O, Rapids, Optuna, fast.ai) if you know how to write a wrapper of them using the given model.","c9dc7e6c":"# Training\n\nMake sure the `cuda` is on by checking the setting on the right.\n```python\nif torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'\n```\n\n## A simple way to adjust the parameters in the optimizer amidst of training\n```python\nfor group in optimizer.param_groups:\n    group['lr'] *= 0.1\n    # group['momentum'] = 0.85\n    # ...\n```","6241d0d3":"# Team member(s):\n\nUpon submitting your code on Gradescope, please type the names of the team members here:","48336113":"# Predict the solution on the test set\n\nEvaluate the trained model and generate the `preds` variable, which is the index of the maximum entry of the 10 outputs for each sample.","209bdcbd":"A batch size of 1024 of float precision training needs about 4GB of RAM for the GPU.","47fa10a1":"# Export the solutions and submit to Kaggle\n\nThe result predicted by your model can be named to `preds`, and be exported to a `.csv` file using the following cell. The `y_pred` should be of a dimension `(30000,)` numpy array. \n\nRename the resulting `solutions-yournames.csv` by replacing `yournames` by your team members' initials connected by hyphen and then save the notebook on Kaggle.\n\nThen click the submit button below, the solution can be submitted directly from the output tab of a committed notebook (click `Save Version` blue button in the interactive kernel window).","df56560f":"# Prepare the train loader","e24461ac":"## Load the data from Kaggle\nThe data file in `.pt` format (a pickle format for PyTorch) from [our class's Kaggle competition website](https:\/\/www.kaggle.com\/c\/wustl-math450-spring-2021), put them in the same folder with this notebook. The following cells will load the file as torch tensors.\n\nIf you have already registered on Kaggle, then directly running this Kaggle kernel from cloud is better. Please click the **COPY and EDIT** button on the upper right corner.\n\n![](https:\/\/sites.wustl.edu\/scao\/files\/2020\/10\/Screen-Shot-2020-10-25-at-1.09.19-PM.png)\n\nThe dataset is already added to the path accessible to your notebook, and it is in locally `..\/input\/wustl-math450-spring-2021` directory. Using the following bash command hack will reveal. On the right there is GPU toggle by clicking the Accelerator button. Kaggle has a Tesla P100 GPU which is better than Colab, but we have only 40 hours of GPU computing time reseting per week.\n\n![](https:\/\/sites.wustl.edu\/scao\/files\/2021\/03\/Screenshot-from-2021-03-23-21-10-01.png)","21a6ba72":"# WashU Math 450 Sp21 Final project advanced starter\n\nThis is the advanced starter code for the final project. Please walk it through.\nYou can download this starter as a notebook and upload it to Colab, or directly run it on Kaggle.\nDo not attempt to run the code locally unless there is a GPU supporting CUDA.\nAll the given models are fairly large (> 10 million parameters) and we only about 40 GPU hours on Kaggle per week.\nSo please plan accordingly and do not start the final project in the last two weeks.\nThe due date for submitting the final project report is **May 15, 2021**.\n\n## Changes from the first starter:\n- A validation strategy is added: monitor the prediction accuracy on the test set.\n- The SGD is updated with Nesterov's Accelerated Gradient (NAG) formulation.\n- A template of adjusting optimizer's setting such as learning rate\/momentum constant is added.\n- Save and load model.\n\n## Things to try:\n- Tweak learning rate (toward what direction? think of the convergence theory of SGD) with a factor $\\gamma$ if the validation accuracy does not improve for a consecutive of $m$ epochs ($m, \\gamma$ are hyperparameters). \n- Try different momentum constant, or even cycle momentum constant between a maximum threshold and a minimum threshold.\n- Advanced multi-fold cross-validation strategy (the pipeline needs to be rewritten if this is to be tried, recommended for advanced players).\n\n## Q&A:\nFor questions you can post in the Piazza discussion board: [https:\/\/piazza.com\/class\/kkcyi2zgosr3wh](https:\/\/piazza.com\/class\/kkcyi2zgosr3wh)","9e715d33":"# Final project: write our own optimizer\n\nIn the following cells, we use the `torch.optim` interface to build our own optimizer.\nThe following code is simplified from [http:\/\/pytorch.org\/docs\/master\/_modules\/torch\/optim\/sgd.html#SGD](http:\/\/pytorch.org\/docs\/master\/_modules\/torch\/optim\/sgd.html#SGD)\n\nPlease refer to the final project page to see requirements of the implementation of a customized optimizer.","786ffe63":"## Visualizing samples\nNotice `train_data` and `test_data` are torch tensors with dimensions `(40000, 28, 28)` and `(30000, 28, 28)`, so that `train_data[i]` and `test_data[i]` represent images for training and testing, respectively. We can plot by randomly choosing 32 samples from the `train_data` (a 28x28 grayscale image), and we make the title as their label (which category they belong) as follows: for example, in the plotted images, the first image in the first row is of category 9.\n\nReference:\n\n| ID | Category |\n|---|-------|\n| 0 | \u304a |\n| 1 |  \u304d |\n| 2 | \u3059      |\n| 3 |   \u3064    |\n| 4 |    \u306a    |\n| 5 |  \u306f     |\n| 6 |   \u307e     |\n| 7 |   \u3084     |\n| 8 |  \u308c     |\n| 9 |  \u3092    |","9d745c5e":"The train set has data and targets given, yet test set has no targets. We have to train models based on the train data to achieve a high score on the leaderboard on the test set."}}