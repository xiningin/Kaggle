{"cell_type":{"92a8f306":"code","347d1c31":"code","0d863c86":"code","2378e5ab":"code","4e1e5f5a":"code","e4d8218e":"code","4aab6af8":"code","fe2f334b":"code","7fd0181c":"code","eda4950e":"code","bb498ded":"code","834ba021":"code","e4c79612":"code","23197849":"code","ef16d126":"code","22db0ae5":"code","2da5185c":"code","ff0d6090":"code","52437460":"markdown","49d3f365":"markdown","9e132787":"markdown","c8d34f74":"markdown","9e1b596f":"markdown","e23950e2":"markdown","213f35f3":"markdown","52ed5749":"markdown","f4b8250c":"markdown","333a07fd":"markdown","419493b7":"markdown","722b7d84":"markdown","7eaa68c3":"markdown","717a5b41":"markdown","54567bce":"markdown","32e9636c":"markdown","0df140e8":"markdown","37fab5ae":"markdown","d34990ab":"markdown","3370f710":"markdown","c2a4eb7f":"markdown","78991b7f":"markdown","9bb7d0e3":"markdown"},"source":{"92a8f306":"# Import tensorflow library\nimport tensorflow as tf\nprint(tf.version.VERSION)\nfrom tensorflow import keras\nimport numpy as np","347d1c31":"#Basic model with just 1 layer\nmodel = tf.keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])","0d863c86":"# Compile the model\nmodel.compile(optimizer='sgd', loss='mean_squared_error')","2378e5ab":"# Passing arrays as numpy array\nxs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\nys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)","4e1e5f5a":"# Fitting the model\nmodel.fit(xs, ys, epochs=500)","e4d8218e":"# Predicting on a new value\nprint(model.predict([10.0]))","4aab6af8":"# using the library\nfashion_mnist = keras.datasets.fashion_mnist","fe2f334b":"# Downloading data and saving it to four cariables\n(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()","7fd0181c":"model = keras.Sequential([\n    keras.layers.Flatten(input_shape=(28,28)),\n    keras.layers.Dense(128,activation=tf.nn.relu),\n    keras.layers.Dense(10,activation=tf.nn.softmax)\n])","eda4950e":"model.compile(optimizer=tf.optimizers.Adam(),\n              loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\n\nmodel.fit(train_images,train_labels,epochs=10)","bb498ded":"# evaluating on test dataset\nmodel.evaluate(test_images, test_labels)","834ba021":"# Prediction on test data\nclassifications = model.predict(test_images)\n\nprint(classifications[0])","e4c79612":"print(test_labels[0])","23197849":"import tensorflow as tf\n#print(tf.__version__)\n\nmnist = tf.keras.datasets.mnist\n\n(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n\n# normalizing the images\ntraining_images = training_images\/255.0\ntest_images = test_images\/255.0\n\nmodel = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n\nmodel.compile(optimizer = 'adam',\n              loss = 'sparse_categorical_crossentropy')\n\nmodel.fit(training_images, training_labels, epochs=5)\n\nmodel.evaluate(test_images, test_labels)\n\nclassifications = model.predict(test_images)\n\nprint(classifications[0])\nprint(test_labels[0])","ef16d126":"# Callbacks are very useful as they stop training when a particular accuracy is reached\n\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('loss')<0.4):\n      print(\"\\nReached 60% accuracy so cancelling training!\")\n      self.model.stop_training = True\n\ncallbacks = myCallback()\n\n# Defining the above model again\nmnist = tf.keras.datasets.fashion_mnist\n\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n\ntraining_images=training_images\/255.0\ntest_images=test_images\/255.0\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n])\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\nmodel.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n","22db0ae5":"mnist = tf.keras.datasets.fashion_mnist\n(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n\ntraining_images=training_images.reshape(60000, 28, 28, 1)\ntraining_images=training_images \/ 255.0\n\ntest_images = test_images.reshape(10000, 28, 28, 1)\ntest_images=test_images\/255.0\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\nmodel.fit(training_images, training_labels, epochs=5)\ntest_loss = model.evaluate(test_images, test_labels)","2da5185c":"# Classification\nprint(test_labels[:100])","ff0d6090":"import matplotlib.pyplot as plt\nf, axarr = plt.subplots(3,4)\nFIRST_IMAGE=2\nSECOND_IMAGE=7\nTHIRD_IMAGE=5\nCONVOLUTION_NUMBER = 3\nfrom tensorflow.keras import models\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\nfor x in range(0,4):\n    f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n    axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n    axarr[0,x].grid(False)\n    f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n    axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n    axarr[1,x].grid(False)\n    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n    axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n    axarr[2,x].grid(False)","52437460":"As you can see we predicted the value of Y to be **19** (i.e. 2*10 - 1) and we got a value which is very close.\n\nNow why is it in decimals..?\n\n\nThis is because we trained the model with with very few examples.. whereas neural networks are usually used for training where we have a large dataset. So, the model can predict with 100% accuracy for a small set of values","49d3f365":"##### Note: Just Check if vesion > 2","9e132787":"# Defining model","c8d34f74":"**It's the probability that this item is each of the 10 classes**\n\n","9e1b596f":"Consider the two arrays as-\n\nX = [-1.0,  0.0, 1.0, 2.0, 3.0, 4.0]\n\nY = [-3.0, -1.0, 1.0, 3.0, 5.0, 7.0]\n\nLooking at these values we can easily predict that relation between X and Y is: **Y = 2X-1**\n\nNow lets see how successfully neural networks will predict it","e23950e2":"#### Note: Callbacks are added as a parameter in *model.fit*","213f35f3":"# Working of the convolution","52ed5749":"# Importing Libraries","f4b8250c":"# Classification of Fashion-MNIST","333a07fd":"## Defining the model","419493b7":"**The 10th element on the list is the biggest, and the ankle boot is labelled 9.  Both the list and the labels are 0 based, so the ankle boot having label 9 means that it is the 10th of the 10 classes. The list having the 10th element being the highest value means that the Neural Network has predicted that the item it is classifying is most likely an ankle boot**","722b7d84":"After training for 500 epochs we can see that loss is almost negligible","7eaa68c3":"**Sequential**: That defines a SEQUENCE of layers in the neural network\n\n**Flatten**: our images are a square,(images are of size 28X28 pixels) Flatten just takes that square and turns it into a 1 dimensional set.\n\n**Dense**: Adds a layer of neurons\n\nEach layer of neurons need an **activation function** to tell them what to do. There's lots of options, but just use these for now. \n\n**Relu** effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n\n**Softmax** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!\n\nThe last layer has **10 neurons** in it because we have **ten classes of clothing in the dataset**. They should always match.","717a5b41":"# Using CNN","54567bce":"#### Now we know what a basic neural network is and how to train it. Now we will work with some real world dataset","32e9636c":"# Changing a few parameters","0df140e8":"# Training model","37fab5ae":"optimizer is stochastic gradient descent and loss is mean square error.. which can be directly defined as the above parameters in Tensorflow","d34990ab":"#### Fashion-MNIST is available as a data set with an API call in TensorFlow. We simply declare an object of type MNIST loading it from the Keras database. On this object, if we call the load data method, it will return four lists to us, which we save in images and labels as below","3370f710":"#### We will build a model to identify a relation between X and Y. I will provide two arrays as input and then for unknown X we will predict the value of Y","c2a4eb7f":"Units is 1 as I want only 1 node for small data.\ninput_shape is 1 as I will be passing a 1D array. We will change these values depending on new inputs futher","78991b7f":"### We are somewhat able to guess that it is an image of a shirt.\nSimilarly you can try by changing the values of images and check if the model predicts it correctly!\nThis is it for now!","9bb7d0e3":"### We'll have a deep dive by looking into different examples in my next notebook. If you find this useful do not forget to *upvote* and also if you have any queries feel free to ask in the comments below..\n## Thank You"}}