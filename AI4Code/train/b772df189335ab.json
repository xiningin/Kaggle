{"cell_type":{"27678e0a":"code","001ec7d2":"code","1873e237":"code","abb87b32":"code","ad1c9648":"code","e5453a74":"code","35ec2e2f":"code","0bb7c7a3":"code","109c6afb":"code","e05c466a":"code","69fbbcb3":"code","009e7679":"code","d6c0de2a":"code","d4ae83d9":"code","716961de":"code","9b447ad0":"code","55ab2e11":"code","8e7392bc":"code","29878fa7":"code","6e4fb9df":"code","7ee14fe6":"code","a074ebd7":"code","10214470":"code","c2a9f47b":"code","70477b86":"code","f6a474bd":"code","040d3971":"code","1b556994":"code","0c85bc9b":"code","907bf3c9":"code","7bb67329":"code","976104eb":"code","96b2be92":"code","847b6b5f":"code","e4294b9e":"code","687e2075":"code","b3198f96":"code","a5c66e0d":"code","995d4a13":"code","dc884069":"code","ebd870a4":"code","8e3d5053":"code","4d2c6b5a":"markdown","600e9fb3":"markdown","6cbc1054":"markdown","756233fc":"markdown","46507f86":"markdown","61d58f87":"markdown","e2c2e12d":"markdown","a68c6146":"markdown"},"source":{"27678e0a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","001ec7d2":"# Load the datasets\ntrain_raw = pd.read_csv(\"..\/input\/stanford-natural-language-inference-corpus\/snli_1.0_train.csv\")\neval_raw = pd.read_csv(\"..\/input\/stanford-natural-language-inference-corpus\/snli_1.0_dev.csv\")\ntest_raw = pd.read_csv(\"..\/input\/stanford-natural-language-inference-corpus\/snli_1.0_test.csv\")","1873e237":"train_raw.head(3)","abb87b32":"train_raw.describe()","ad1c9648":"eval_raw.describe()","e5453a74":"test_raw.describe()","35ec2e2f":"# Data shape and missing values\nprint('\u25a0 Train set: ' + str(train_raw.shape))\nprint(train_raw.isnull().sum())\n\nprint('\\n\u25a0 Evaluation set: ' + str(eval_raw.shape))\nprint(eval_raw.isnull().sum())\n\nprint('\\n\u25a0 Test set:' + str(test_raw.shape))\nprint(test_raw.isnull().sum())","0bb7c7a3":"# Make sure all datasets have the same labels\nprint(train_raw['gold_label'].unique())\nprint(eval_raw['gold_label'].unique())\nprint(test_raw['gold_label'].unique())","109c6afb":"# Propotion of gold labels (train only)\nratio_gold = train_raw['gold_label'].value_counts(normalize=True).sort_index(ascending=False).reset_index().set_index('index')\nratio_gold['gold_label'] = ratio_gold['gold_label'].apply(lambda x: round(x, 3))\nratio_gold","e05c466a":"# Visualize the propotion\ncolors = sns.color_palette('pastel')\nplt.pie(ratio_gold['gold_label'], labels=ratio_gold.index, colors=colors, autopct='%.1f%%', startangle=90)\nplt.title('Proportion of the gold labels')\nplt.show()","69fbbcb3":"# Lengths of sentenses (train only)\n# Sentense 1\ntrain_sent1 = train_raw['sentence1'].str.count(' ') + 1\ntrain_sent1 = train_sent1.apply(lambda x: int(x))\nprint('Sentence 1\\n', round(train_sent1.describe(), 2))\n\n# Sentense 2\ntrain_sent2 = train_raw['sentence2'].dropna().str.count(' ') + 1\ntrain_sent2 = train_sent2.apply(lambda x: int(x))\nprint('\\nSentence 2\\n', round(train_sent2.describe(), 2))","009e7679":"# Visualize the distribution of the lengths of sentences 1 and 2\ntrain_sentences = pd.DataFrame({'sentence1':train_sent1,\n                                'sentence2':train_sent2})\n\nbox = sns.boxplot(data=train_sentences, palette=colors)\nbox.set_ylabel('Words in a sentence')\nbox.set_title('Distribution of the lengths of sentences')\nplt.show()","d6c0de2a":"# Examples in sentence 1\n# Minimum count of words\nexample1_min = train_sent1[train_sent1 == train_sent1.min()].sample(1)\nprint('Min word count: ', train_sent1.min())\nprint('Example: ', train_raw['sentence1'].loc[example1_min.index])\nprint('\\n')\n\n# Maximum count of words\nexample1_max = train_sent1[train_sent1 == train_sent1.max()].sample(1)\nprint('Max word count: ', train_sent1.max())\nprint('Example: ', train_raw['sentence1'].loc[example1_max.index])","d4ae83d9":"# Examples in sentence 2\n# Minimum count of words\nexample2_min = train_sent2[train_sent2 == train_sent2.min()].sample(1)\nprint('Min word count: ', train_sent2.min())\nprint('Example: ', train_raw['sentence2'].loc[example2_min.index])\nprint('\\n')\n\n# Maximum count of words\nexample2_max = train_sent2[train_sent2 == train_sent2.max()].sample(1)\nprint('Max word count: ', train_sent2.max())\nprint('Example: ', train_raw['sentence2'].loc[example2_max.index])","716961de":"# Omit rows having the gold label \"-\" and irrelevant columns \ntrain = train_raw[['gold_label', 'sentence1', 'sentence2']][train_raw['gold_label'] != '-'].set_index(train_raw['pairID'][train_raw['gold_label'] != '-'])\neval = eval_raw[['gold_label', 'sentence1', 'sentence2']][eval_raw['gold_label'] != '-'].set_index(eval_raw['pairID'][eval_raw['gold_label'] != '-'])\ntest = test_raw[['gold_label', 'sentence1', 'sentence2']][test_raw['gold_label'] != '-'].set_index(test_raw['pairID'][test_raw['gold_label'] != '-'])\n\n# Minimize the datasets for quick trials\ntrain = train.iloc[:50000, :]\neval = eval.sample(100)\ntest = test.sample(100)\n\ntrain.head(3)","9b447ad0":"# Omit null indexes\ntrain.dropna(subset=['sentence2'], inplace=True)\n\n# Recheck the number of null values\nprint(train.isnull().sum())\nprint(eval.isnull().sum())\nprint(test.isnull().sum())","55ab2e11":"# Check sentences including URL\nprint(train['sentence1'][train['sentence1'].str.contains('http')].count())\nprint(train['sentence2'][train['sentence2'].str.contains('http')].count())\n\nprint(eval['sentence1'][eval['sentence1'].str.contains('http')].count())\nprint(eval['sentence2'][eval['sentence2'].str.contains('http')].count())\n\nprint(test['sentence1'][test['sentence1'].str.contains('http')].count())\nprint(test['sentence2'][test['sentence2'].str.contains('http')].count())","8e7392bc":"# Check URL-only sentences\ndropindex = train.index[train['sentence2'].str.contains('http')]\ntrain[train['sentence2'].str.contains('http')]","29878fa7":"# Omit URL-only sentences\ntrain.drop(index=dropindex, inplace=True)\nprint(train[train['sentence2'].str.contains('http')].count())","6e4fb9df":"# Dummy coding for gold labels\ntrain['gold_label'] = train['gold_label'].replace('neutral', 0).replace('entailment', 1).replace('contradiction', 2)\neval['gold_label'] = eval['gold_label'].replace('neutral', 0).replace('entailment', 1).replace('contradiction', 2)\ntest['gold_label'] = test['gold_label'].replace('neutral', 0).replace('entailment', 1).replace('contradiction', 2)\n\ntrain.head(3)","7ee14fe6":"import nltk as nlp\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import ngrams","a074ebd7":"nlp.download('popular')","10214470":"def tokenize(sentence):\n    # Tokenization\n    new_tokens = word_tokenize(sentence)\n    new_tokens = [t.lower() for t in new_tokens]\n    new_tokens = [t for t in new_tokens if t not in stopwords.words('english')]\n    new_tokens = [t for t in new_tokens if t.isalpha()]\n\n    # Lemmatization (become, becomes, becoming, became --> become)\n    lemmatizer = WordNetLemmatizer()\n    new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n    return new_tokens","c2a9f47b":"# Connect all sentences in the preprocessed training set\ntrain_sentence1 = \" \".join(train['sentence1'])\ntoken_s1 = tokenize(train_sentence1)\n\ntrain_sentence2 = \" \".join(train['sentence2'])\ntoken_s2 = tokenize(train_sentence2)","70477b86":"# Visualization of frequent words in the train dataset\n# Count the words\ncount_s1 = Counter(token_s1)\nword_freq_s1 = pd.DataFrame(count_s1.items(), columns=['Word','Frequency']).sort_values(by='Frequency', ascending=False)\n\ncount_s2 = Counter(token_s2)\nword_freq_s2 = pd.DataFrame(count_s2.items(), columns=['Word','Frequency']).sort_values(by='Frequency', ascending=False)\n\n# Create subplots\nnb_ranking = 15\nfig = plt.figure(figsize=(15, 3))\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2)\n\nsns.barplot(x='Frequency', y='Word', data=word_freq_s1.head(nb_ranking), ax=ax1).set(xlim=(0, 15000))\nax1.set_title('Top ' + str(nb_ranking) + ' frequent words in Sentence 1: n = ' + str(len(word_freq_s1)))\n\nsns.barplot(x='Frequency', y='Word', data=word_freq_s2.head(nb_ranking), ax=ax2).set(xlim=(0, 15000))\nax2.set_title('Top ' + str(nb_ranking) + ' frequent words in Sentence 2: n = ' + str(len(word_freq_s2)))\n\nplt.show()","f6a474bd":"# Specify ver 2.11.0 Later version may not work\n!pip install transformers~=2.11.0","040d3971":"import torch\nfrom torch.utils.data import TensorDataset, random_split\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer\nimport random\nimport gc","1b556994":"# Tokenization using BERT Tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n\n# Get maximum number of words\nmax_len = []\ntrain_s1 = train['sentence1'].values\ntrain_s2 = train['sentence2'].values\neval_s1 = eval['sentence1'].values\neval_s2 = eval['sentence2'].values\ntest_s1 = test['sentence1'].values\ntest_s2 = test['sentence2'].values\n\nfor sent1, sent2, sent3, sent4, sent5, sent6 in zip(train_s1, train_s2, eval_s1, eval_s2, test_s1, test_s2):\n    token_words_1 = tokenizer.tokenize(sent1)\n    token_words_2 = tokenizer.tokenize(sent2)\n    token_words_3 = tokenizer.tokenize(sent3)\n    token_words_4 = tokenizer.tokenize(sent4)\n    token_words_5 = tokenizer.tokenize(sent5)\n    token_words_6 = tokenizer.tokenize(sent6)\n\n    token_words_1.extend(token_words_2)\n    token_words_1.extend(token_words_3)\n    token_words_1.extend(token_words_4)\n    token_words_1.extend(token_words_5)\n    token_words_1.extend(token_words_6)\n\n    max_len.append(len(token_words_1))\n    \nmax_length = max(max_len) + 3 # max length = Word tokens + 3 special tokens(1 [CLS] and 2 [SEP])\n\nprint('Max words: ', max_length)","0c85bc9b":"# Function to get word ID and attention mask\ndef prep(sent1, sent2, label):\n  input_ids = []\n  attention_masks = []\n  sentence_ids = []\n  end_term = \"[SEP]\"\n  labels = label.values\n\n  for x , y in zip(sent1, sent2):\n    sent= x + end_term + y\n    \n    encoded_dict = tokenizer.encode_plus(\n        sent,\n        add_special_tokens = True, # Distinguish two sentences\n        max_length = max_length, # Padding\n        pad_to_max_length = True, # Padding\n        return_attention_mask = True, # Make attention mask\n        return_tensors = 'pt', # Return Pytorch tensors\n        )\n    \n    # Get word ID\n    input_ids.append(encoded_dict['input_ids'])\n    \n    # Get attention mask\n    attention_masks.append(encoded_dict['attention_mask'])\n\n    # Get token type ID (distinguish sentence 1 and 2)\n    sentence_ids.append(encoded_dict['token_type_ids'])\n    \n  # Concatenate listed tensor for vertical dimmention (dim=0)\n  input_ids = torch.cat(input_ids, dim=0)\n  attention_masks = torch.cat(attention_masks, dim=0)\n    \n  # Cast label list to tenosor\n  labels = torch.tensor(labels)\n\n  return input_ids, attention_masks, sentence_ids, labels\n","907bf3c9":"# Get word ID and attention mask\n# train\ntrain_ids, train_masks, sentence_ids, train_labels = prep(train_s1, train_s2, train['gold_label'])\n\n# evaluation\neval_ids, eval_masks, sentence_ids, eval_labels = prep(eval_s1, eval_s2, eval['gold_label'])\n\n# test\ntest_ids, test_masks, sentence_ids, test_labels = prep(test_s1, test_s2, test['gold_label'])\n","7bb67329":"# Sample tensor\nprint('Original sentence1: ', train_s1[0])\nprint('Original sentence2: ', train_s2[0])\nprint('Token IDs:', train_ids[0]) \nprint('Attention mask:', train_masks[0])","976104eb":"# Make tensor dataset\ntrain_tensor = TensorDataset(train_ids, train_masks, train_labels)\neval_tensor = TensorDataset(eval_ids, eval_masks, eval_labels)\ntest_tensor = TensorDataset(test_ids, test_masks, test_labels)\n\n# Data loader\nbatch_size = 50\n\n# Train data loader\ntrain_dataloader = DataLoader(\n            train_tensor,  \n            sampler = RandomSampler(train_tensor), # make batches randomly\n            batch_size = batch_size\n        )\n\n# Evaluation data loader\nvalidation_dataloader = DataLoader(\n            eval_tensor, \n            sampler = SequentialSampler(eval_tensor), # make batches in order\n            batch_size = batch_size \n        )\n\n# Test data loader\ntest_dataloader = DataLoader(\n            test_tensor, \n            sampler = SequentialSampler(test_tensor), # make batches in order\n            batch_size = batch_size\n        )","96b2be92":"from transformers import BertForSequenceClassification, AdamW, BertConfig\n\n# Enable GPU if possible\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Load a pre-traind BERT model\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\", # Specify a pre-trained model\n    num_labels = 3,\n    output_attentions = False, # Output attention vectors\n    output_hidden_states = False, # Output hidden layers\n).to(device)","847b6b5f":"# Measure computing time\nimport time\nimport datetime\n\ndef format_time(elapsed):\n    # Round to the nearest second\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","e4294b9e":"# Garbage collection to save memory\ngc.collect()","687e2075":"# Train and evaluation\nlr = 2e-5 # Learning rate\noptimizer = AdamW(model.parameters(), lr=lr)\n\nmax_epoch = 3\ntotal_t0 = time.time()\ntrain_loss_ = []\neval_loss_ = []\n\n# Set the seed value all over the place to make this reproducible.\nseed_val = 42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n\nfor epoch in range(max_epoch):\n    print('======== Epoch {:} \/ {:} ========'.format(epoch + 1, max_epoch))\n    # Training sequence\n    print('Training...')\n    t0 = time.time()\n    model.train()\n    train_loss = 0\n    for batch in train_dataloader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        optimizer.zero_grad()\n        # Loss means Cross Entropy Loss\n        # Logits means values to be input to the softmax function\n        loss, logits = model(b_input_ids, \n                             token_type_ids = None, \n                             attention_mask = b_input_mask, \n                             labels = b_labels)\n        train_loss += loss.item()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n    avg_train_loss = train_loss \/ len(train_dataloader)  \n    train_loss_.append(round(avg_train_loss, 2))\n    print('Epoch training loss: ', round(avg_train_loss, 2))\n    print('Epoch training time: ', format_time(time.time() - t0))\n    print('')\n\n    # Evaluation sequence\n    print('Evaluating...')\n    t0 = time.time()\n    model.eval()\n    val_loss = 0\n    for batch in validation_dataloader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        with torch.no_grad(): # don't compute grading\n          (loss, logits) = model(b_input_ids, \n                                 token_type_ids = None, \n                                 attention_mask = b_input_mask,\n                                 labels = b_labels)\n        val_loss += loss.item()\n\n    avg_val_loss = val_loss \/ len(validation_dataloader)\n    eval_loss_.append(round(avg_val_loss, 2))\n    print('Epoch evaluation loss: ', round(avg_val_loss, 2))\n    print('Epoch evaluation time: ', format_time(time.time() - t0))\n    print('')\n\nprint('Completed. Computation time: ', format_time(time.time() - total_t0))","b3198f96":"import matplotlib.ticker as ticker\n\n# Plot loss\nplt.plot(list(range(1, max_epoch+1)), train_loss_, color='red', marker='o')\nplt.plot(list(range(1, max_epoch+1)), eval_loss_, color='green', marker='^')\nplt.gca().get_xaxis().set_major_locator(ticker.MaxNLocator(integer=True))\nplt.title('Model loss\\nEpoch = ' + str(max_epoch))\nplt.legend(['Train loss', 'Evaluation loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Average cross entropy loss')\nplt.show()","a5c66e0d":"# Prediction\nprediction = []\ntrue_labels = []\n\n# Switch the data loader (use validation or test dataloader)\ndataloader_mode = validation_dataloader\n#dataloader_mode = test_dataloader\n\nmodel.eval() # Turn off training mode\nfor batch in dataloader_mode:\n    b_input_ids = batch[0].to(device)\n    b_input_mask = batch[1].to(device)\n    b_labels = batch[2].to(device)\n\n    with torch.no_grad():   \n        # Get prediction by trained model\n        preds = model(b_input_ids,\n                      token_type_ids=None,\n                      attention_mask=b_input_mask)\n        prediction.append(preds[0].detach().cpu().numpy())\n        true_labels.append(b_labels.detach().cpu().numpy())\n","995d4a13":"# Extract relevant information from prediction\n# Logits list\nresults = []\nfor i in range(len(prediction)):\n  for j in range(len(prediction[0])):\n    results.append(prediction[i][j])\n\nlogits_df = pd.DataFrame(results, columns=['logit_0', 'logit_1', 'logit_2'])\n\n# Predicted label list\npredicted_label = []\nfor i in results:\n  predicted_label.append(np.argmax(i, axis=0))\n\npred_df = pd.DataFrame(predicted_label, columns=['pred_label'])\n\n# True label list\ntrue_labels2 = []\nfor i in range(len(true_labels)):\n  for j in range(batch_size):\n    true_labels2.append(true_labels[i][j])\n\nlabel_df = pd.DataFrame(true_labels2, columns=['true_label'])","dc884069":"# Make a dataframe to calculate the performance of prediction\npreds_df = pd.concat([logits_df, pred_df, label_df], axis=1)\npreds_df.head()","ebd870a4":"# Performance score\nfrom sklearn.metrics import classification_report\n\ny_pred = preds_df.pred_label.values\ny_true = preds_df.true_label.values\n\nprint(classification_report(y_true, y_pred, digits=2))","8e3d5053":"# Visualize confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\ncf_matrix = confusion_matrix(y_true, y_pred)\nmatrix = sns.heatmap(cf_matrix, annot=True)\nmatrix.xaxis.set_ticks_position('top') \nmatrix.set(xlabel='prediction', ylabel='Gold label')\nplt.title('Confusion Matrix\\n0=Neutral, 1=Entailment, 2=Contradiction')\nplt.show()","4d2c6b5a":"## Frequency Analysis","600e9fb3":"## Tokenization","6cbc1054":"## Training and evaluation","756233fc":"# BERT","46507f86":"# Data check","61d58f87":"## Word embedding","e2c2e12d":"# Preprocessing","a68c6146":"## Prediction and model performance checking"}}