{"cell_type":{"ba403507":"code","b8fe5369":"code","013995df":"code","c4428735":"code","52ebf268":"code","a9c79aa8":"code","8a1ea162":"code","4f96ef3b":"code","46520ebe":"code","c1a9ed28":"code","545c4775":"code","1fd29edb":"code","4dbb24d7":"code","497eae04":"code","4877c7c0":"code","482e1148":"code","406cf37b":"code","00a109a0":"code","26db237a":"code","7f1194a1":"code","b0de121e":"code","f04b1276":"code","51bb77a8":"code","6ffa04cc":"code","47af7c32":"code","cfc98103":"code","1df61441":"code","6e4ef951":"code","5483eb98":"code","8386789a":"code","d86846b1":"code","fb3da546":"code","3816ab6d":"code","1ac33f42":"code","25cf790b":"code","8959cb23":"code","c3973659":"code","c143127e":"code","3f5d3665":"code","34f27f8b":"code","4c3dd734":"markdown","521b8442":"markdown","20b0fdc0":"markdown","96f220f2":"markdown","e0e289b6":"markdown","d5bf98be":"markdown","0162ca7e":"markdown","60c07673":"markdown","4f3a75a3":"markdown","2bd4d1f5":"markdown","5751c367":"markdown","67cec3eb":"markdown","b4dd46c5":"markdown","75725788":"markdown","ca1188cd":"markdown","adfa6a8c":"markdown","6ee59a52":"markdown","aa13ba1a":"markdown","1a85d994":"markdown","230fe92d":"markdown","5695b824":"markdown","1da19c99":"markdown","22f24e4b":"markdown","8476fb1a":"markdown","9d71d583":"markdown","ef869cca":"markdown","c70edeed":"markdown","03bda5ca":"markdown","7eadea9a":"markdown","f7b102dd":"markdown","08a2af30":"markdown","e854b20b":"markdown"},"source":{"ba403507":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt","b8fe5369":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\nvalid_df = pd.read_csv('..\/input\/titanic\/test.csv')\nall_df = [train_df,valid_df]","013995df":"train_df.head()","c4428735":"train_df.describe(include='all')","52ebf268":"def missing_calc(df):\n    num = df.isnull().sum().sort_values(ascending = False)\n    num_1 = num[num >0]\n    percentage = num_1\/len(df)*100\n    return pd.DataFrame({'total':num_1,'percentage':percentage})","a9c79aa8":"print('Train dataframe missing value :')\nmissing_calc(train_df)","8a1ea162":"Cabin_df = train_df[['Survived','Cabin']].copy()\nCabin_df['Is_cabin'] = Cabin_df.Cabin.notnull()\nsns.heatmap(Cabin_df.corr()[['Survived']].sort_values(by='Survived', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')","4f96ef3b":"for df in all_df :\n    df['Cabin'] = Cabin_df.Cabin.str[0]\n    df.Cabin.fillna('N',inplace= True)","46520ebe":"for df in all_df:\n    df['Title'] = train_df.Name.str.split(\".\",expand=True)[0].str.split(', ',expand=True)[1]\n\ntrain_df.Title.value_counts() ","c1a9ed28":"common_title = train_df.Title.value_counts()[train_df.Title.value_counts() > 10].index\n\ndef title_convert(title):\n    if title not in common_title:\n        title = 'uncommon'\n    else :\n        title = title\n    return title\n\ntrain_df.Title = train_df.Title.map(title_convert)\nvalid_df.Title = valid_df.Title.map(title_convert)","545c4775":"train_df.drop(['PassengerId','Ticket','Name'],axis=1,inplace = True)\n\nvalid_id = valid_df[['PassengerId']].copy()\nvalid_df.drop(['PassengerId','Ticket','Name'],axis=1,inplace = True)","1fd29edb":"from sklearn.preprocessing import OneHotEncoder,LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline","4dbb24d7":"from sklearn.model_selection import train_test_split\n\nX = train_df.drop(['Survived'],axis = 1)\ny = train_df['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state= 0 )\nprint('X_train size :',X_train.shape ,', X_test size :',X_test.shape)","497eae04":"X_train.head()","4877c7c0":"cat_attribs = ['Sex','Cabin','Embarked','Title']\n\ncat_pipeline = Pipeline([\n        ('imputer',SimpleImputer(strategy='most_frequent')),\n        ('encoder',OneHotEncoder(handle_unknown='ignore'))\n])","482e1148":"num_attribs = ['Age','SibSp', 'Parch', 'Fare']\n\nnum_pipeline = Pipeline([\n        ('imputer',SimpleImputer(strategy='median')),\n        ('std_scaler',StandardScaler())\n])","406cf37b":"Final_pipeline = ColumnTransformer([\n            ('num',num_pipeline,num_attribs),\n            ('cat',cat_pipeline,cat_attribs)\n])\n\n#train_test_split\nX_train = Final_pipeline.fit_transform(X_train)\nX_test = Final_pipeline.fit_transform(X_test)\n\n#Train, Valid df\nX = Final_pipeline.fit_transform(X)\nvalid_df = Final_pipeline.fit_transform(valid_df)\n","00a109a0":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nfrom sklearn.metrics import mean_absolute_error, accuracy_score\nfrom sklearn.model_selection import cross_val_score","26db237a":"lr = LogisticRegression(max_iter=1000)","7f1194a1":"cv_l = cross_val_score(lr,X,y,cv=5)\nprint(cv_l)\nprint(cv_l.mean())","b0de121e":"tc = DecisionTreeClassifier()","f04b1276":"cv_tc = cross_val_score(tc,X,y,cv=5)\nprint(cv_tc)\nprint(cv_tc.mean())","51bb77a8":"gnb = GaussianNB()","6ffa04cc":"cv_gnb = cross_val_score(gnb,X,y,cv=5)\nprint(cv_gnb)\nprint(cv_gnb.mean())","47af7c32":"knc = KNeighborsClassifier()","cfc98103":"cv_knc = cross_val_score(knc,X,y,cv=5)\nprint(cv_knc)\nprint(cv_knc.mean())","1df61441":"rfc = RandomForestClassifier()","6e4ef951":"cv_rfc = cross_val_score(rfc,X,y,cv=5)\nprint(cv_rfc)\nprint(cv_rfc.mean())","5483eb98":"xgb = XGBClassifier(use_label_encoder=False,eval_metric='mlogloss')","8386789a":"cv_xgb = cross_val_score(xgb,X,y,cv=5)\nprint(cv_xgb)\nprint(cv_xgb.mean())","d86846b1":"all_est = [('Logistic',lr),\n            ('Decision_Tree',tc),\n            ('Gaussian',gnb),\n            ('Kneighbors',knc),\n            ('Random_forest',rfc),\n            ('XGB',xgb)]\n\nfor e in all_est:\n    model = e[1]\n    cv_model = cross_val_score(model,X,y,cv=5)\n    print(e[0])\n    print('Cross val Scores :',cv_model)\n    print('Cross val mean score :',cv_model.mean())\n    print('--'*30)","fb3da546":"vote_hard = VotingClassifier(estimators= all_est,voting = 'hard')\nvote_soft = VotingClassifier(estimators=all_est,voting = 'soft')\n\n#Hard Vote\nhard_cv = cross_val_score(vote_hard,X,y,cv=5)\nprint('Hard Vote')\nprint('Scores :',hard_cv)\nprint('Mean Score',hard_cv.mean())\n\n#Soft Vote\nsoft_cv = cross_val_score(vote_soft,X,y,cv=5)\nprint('Soft Vote')\nprint('Scores :',soft_cv)\nprint('Mean Score :',soft_cv.mean())","3816ab6d":"from sklearn.model_selection import GridSearchCV","1ac33f42":"all_est = [('Logistic',lr),\n            ('Decision_Tree',tc),\n            ('Gaussian',gnb),\n            ('Kneighbors',knc),\n            ('Random_forest',rfc),\n            ('XGB',xgb)]\n\ngrid_param = [\n            #Logictic_Regression\n\n            [{'fit_intercept': [True,False],\n            'solver':['lbfgs', 'liblinear', 'sag', 'saga'],\n            'random_state': [0]}\n            ],\n\n            #Decision_Tree\n\n            [{\n            'max_depth' : [2,4,6,8,10,12,14],\n            'random_state': [0]\n            }\n            ],\n\n            #Gaussian\n\n            [{}],\n\n            #KneighborsClassifier\n\n            [{\n            'n_neighbors': [1,2,3,4,5,6,7],\n            'weights': ['uniform', 'distance'],\n            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n            }],\n\n            #RandomForestClassifier\n\n            [{\n            'n_estimators': [10,50,100,200,300],\n            'criterion': ['gini', 'entropy'],\n            'max_depth': [8,10,12],\n            'random_state': [0]\n             }],\n    \n            #XGBClassifier\n\n            [{\n            'learning_rate': [.01, .03, .05, .1, .25], \n            'max_depth': [1,2,4,6,8,10], \n            'n_estimators': [10,50,100,200,300], \n            'seed': [0]\n            }]\n            ]","25cf790b":"tuned_all_est = all_est.copy()\n\nfor model,param in zip (tuned_all_est,grid_param):\n    best_search = GridSearchCV(model[1],param_grid = param,cv = 5)\n    best_search.fit(X,y)\n    best_param = best_search.best_params_\n    model[1].set_params(**best_param) \n    print('[',model[0],']')\n    print('Best Score: ' + str(best_search.best_score_))\n    print('Best Parameters: ' + str(best_search.best_params_))\n    print('--'*30)","8959cb23":"vote_hard_tuned = VotingClassifier(estimators= tuned_all_est,voting = 'hard')\nvote_soft_tuned = VotingClassifier(estimators= tuned_all_est,voting = 'soft')\n\n#Hard Vote\nhard_cv = cross_val_score(vote_hard_tuned,X,y,cv=5)\nprint('Hard Vote (Tuned Model)')\nprint('Scores :',hard_cv)\nprint('Mean Score',hard_cv.mean())\n\n#Soft Vote\nsoft_cv = cross_val_score(vote_soft_tuned,X,y,cv=5)\nprint('Soft Vote (Tuned Model)')\nprint('Scores :',soft_cv)\nprint('Mean Score :',soft_cv.mean())","c3973659":"tuned_all_est_1 = tuned_all_est.copy()\ntuned_all_est_1.pop(2)\n\nvote_hard_tuned = VotingClassifier(estimators= tuned_all_est_1,voting = 'hard')\nvote_soft_tuned = VotingClassifier(estimators= tuned_all_est_1,voting = 'soft')\n\n#Hard Vote\nhard_cv_1 = cross_val_score(vote_hard_tuned,X,y,cv=5)\nprint('Hard Vote (Tuned Model)')\nprint('Scores :',hard_cv_1)\nprint('Mean Score',hard_cv_1.mean())\n\n#Soft Vote\nsoft_cv_1 = cross_val_score(vote_soft_tuned,X,y,cv=5)\nprint('Soft Vote (Tuned Model)')\nprint('Scores :',soft_cv_1)\nprint('Mean Score :',soft_cv_1.mean())","c143127e":"vote_hard_tuned.fit(X,y)\nvote_soft_tuned.fit(X,y)\n\n\n\nvalid_id['Survived_Hard'] = vote_hard_tuned.predict(valid_df).astype(int)\nvalid_id['Survived_Soft'] = vote_soft_tuned.predict(valid_df).astype(int)","3f5d3665":"check = valid_id['Survived_Hard'] == valid_id['Survived_Soft']\ncheck.value_counts()","34f27f8b":"submission_hard = valid_id[['PassengerId','Survived_Hard']]\nsubmission_hard.columns = ['PassengerId','Survived']\nsubmission_soft = valid_id[['PassengerId','Survived_Soft']]\nsubmission_soft.columns = ['PassengerId','Survived']\n\nsubmission_hard.to_csv('..\/working\/submission_hard',index=False)\nsubmission_soft.to_csv('..\/working\/submission_soft',index=False)","4c3dd734":"### Feature Scaling (Numerical Columns)","521b8442":"import libraries","20b0fdc0":"### 4.7 Voting Classifier","96f220f2":"### 4.2 Decision Tree Classifier","e0e289b6":"## 2.2 Simplify Data","d5bf98be":"### 4.3 Naive Bayes GaussianNB","0162ca7e":"Check how difference between each type of voting.","60c07673":"# Titanic Prediction","4f3a75a3":"### Encode Category Data (Sex, Cabin, Embarked, Title)","2bd4d1f5":"# 4. Train Models","5751c367":"### 4.6 XGBClassifier","67cec3eb":"#### Cabin column \n77 percent of Cabin column is missing which is quite high. It's quite resonable to remove the column. But anyways, let's look at the data.","b4dd46c5":"### 4.4 KNeighborsClassifier","75725788":"### Voting Classifier on Tuned Model","ca1188cd":"#### Title Column\ntitle that have less than 10 will be converted to 'uncommon' value.","adfa6a8c":"### Predict in Validation DataFrame","6ee59a52":"## Data Dictionary\n| Variable | Definition | Key |\n| --- | --- | --- |\n| Survival|Survival | 0 = No, 1 = Yes|\n|pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd|\n| sex | Sex | |\n|Age | Age in years |\n|sibsp | # of siblings \/ spouses aboard the Titanic | |\n| parch | # of parents \/ children aboard the Titanic | |\n|ticket | Ticket numer | |\n|fare | Passenger fare ||\n|cabin | Cabin number ||\n|embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southamton|\n\nVariable Notes\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","aa13ba1a":"Split dataframe to train and test.","1a85d994":"# 2.Data Preparation\/Cleaning ","230fe92d":"for age and embarked columns. We will deal with them later.","5695b824":"For above cells we can use for loop to do all work at once","1da19c99":"## 4.Tuning Model with GridSearchCV","22f24e4b":"### 4.5 Random Forest Classifier","8476fb1a":"## 2.1 Missing Values\n\nWe can deal the missing values with either remove the column or replace them with mean, mode or median of the feature.","9d71d583":"Try again without Gaussian model.","ef869cca":"### 4.1 Logistic Regression","c70edeed":"# 1.Data Preparation","03bda5ca":"#### Name Column","7eadea9a":"## 2.3 Remove Unnecesary Columns","f7b102dd":"there are some relation between them so replace null value with 'N' will be the case.","08a2af30":"###  Final Pipepline","e854b20b":"# 3.Pre-Modeling"}}