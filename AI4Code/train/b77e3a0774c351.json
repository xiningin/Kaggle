{"cell_type":{"828f188e":"code","2da2a7af":"code","3447f857":"code","7b8947b2":"code","c35ec8b6":"code","c57dbe1f":"code","10e60c92":"code","78d5f3c5":"code","22294b9c":"code","2f7efb3d":"code","43674570":"code","30ae11a1":"markdown","8c87ee2d":"markdown","6bf7e955":"markdown"},"source":{"828f188e":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head(10)\n        \n","2da2a7af":"#Looking at the numeric variables\ntrain_data.describe()","3447f857":"#notice that the age variable has missing data while the other columns have no missing data\n#the Name variable includes titles of the person. One approach to impute the age of missing data is to take\n#the average age of each group's title\n\ntrain_data[\"Name\"] = train_data[\"Name\"].str.split(',').str[1]\ntrain_data[\"Name\"] = train_data[\"Name\"].str.split('.').str[0]\ntrain_data[\"Name\"] = train_data[\"Name\"].str.strip()\n\nprint(train_data.head())\n","7b8947b2":"x = train_data.groupby('Name').agg(['count']).index.get_level_values('Name')\nx","c35ec8b6":"#The names are now transformed into titles.\n#Taking average age of each group to fill missing age data\ntrain_data[\"Age\"] = train_data.groupby(\"Name\").transform(lambda x: x.fillna(x.mean()))['Age']\n#changing sex to be 0 or 1 for female & male\ntrain_data['Sex'].replace({'female':0,'male':1},inplace=True)\ntrain_data.head()\n","c57dbe1f":"#Building a knn algorithm\n#Need to normalize data (min-max normalization)\n#selecting only numeric or categorical variable transformed to numeric variables\ntrain_data_knn = train_data.iloc[:,[False,False,True, False,True,True,True,True,False,True,False,False]]\ntrain_labels_knn = train_data.iloc[:,1]\nnormalized_data_train=(train_data_knn-train_data_knn.min())\/(train_data_knn.max()-train_data_knn.min())\nnormalized_data_train.head()\n\n","10e60c92":"#first need distance function (using Euclidean Distance)\n\ndef distance(df1,actual_labels,k):\n    closest_lst = []\n    labels = np.zeros(len(df1),dtype=int)\n    for i in range(len(df1)):\n        distance_df = ((df1.iloc[i,:] - df1.drop([i],axis=0))**2).sum(axis=1)\n        k_closest = ((df1.iloc[i,:] - df1.drop([i],axis=0))**2).sum(axis=1).nsmallest(n=k, keep='first')\n        closest_lst.append(k_closest)\n       \n\n    return closest_lst\n\n\ndef classify(big_list, labels,k):\n    predictions = np.zeros(len(big_list),dtype=int)\n    for i in range(len(big_list)):\n        summation = 0\n        for j in big_list[i].index:\n            summation += labels[j]\n        if summation\/k > .5:\n            predictions[i] = 1\n\n    return predictions\n\n\n\n###Try different K values on training set, see which is best\n\nfor j in range(1,15,2):\n    preds = distance(normalized_data_train,train_labels_knn,j)\n    predictions = classify(preds, train_labels_knn,j)\n    accuracy = 0\n    for i in range(len(predictions)):\n        if predictions[i] == train_labels_knn[i]:\n            accuracy +=1\n    print(\"For K=\", j,\":\")\n    print(\"Accuracy\",accuracy\/len(predictions))\n","78d5f3c5":"#Function for testing set\ndef distance(df1,df2,actual_labels,k):\n    closest_lst = []\n    labels = np.zeros(len(df1),dtype=int)\n    for i in range(len(df1)):\n        distance_df = ((df1.iloc[i,:] - df2)**2).sum(axis=1)\n        k_closest = ((df1.iloc[i,:] - df2)**2).sum(axis=1).nsmallest(n=k, keep='first')\n        closest_lst.append(k_closest)\n       \n\n    return closest_lst\n\npreds = distance(normalized_data_train,normalized_data_train,train_labels_knn,5)\n\ndef classify(big_list, labels,k):\n    predictions = np.zeros(len(big_list),dtype=int)\n    for i in range(len(big_list)):\n        summation = 0\n        for j in big_list[i].index:\n            summation += labels[j]\n        if summation\/k > .5:\n            predictions[i] = 1\n\n    return predictions\n    \npredictions = classify(preds, train_labels_knn,5)","22294b9c":"#Get testing data ready:\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\n\ntest_data[\"Name\"] = test_data[\"Name\"].str.split(',').str[1]\ntest_data[\"Name\"] = test_data[\"Name\"].str.split('.').str[0]\ntest_data[\"Name\"] = test_data[\"Name\"].str.strip()\ntest_data['Sex'].replace({'female':0,'male':1},inplace=True)\n\n\nx = test_data.groupby('Name').agg(['count']).index.get_level_values('Name')\ntest_data[\"Age\"] = test_data.groupby(\"Name\").transform(lambda x: x.fillna(x.mean()))['Age']\n\n\ntest_data_knn = test_data.iloc[:,[False,True,False,True,True,True,True,False,True,False,False]]\nnormalized_data_test=(test_data_knn-test_data_knn.min())\/(test_data_knn.max()-test_data_knn.min())","2f7efb3d":"preds = distance(normalized_data_test,normalized_data_train,train_labels_knn,5)\npredictions = classify(preds, train_labels_knn,5)","43674570":"data = {'PassengerId': test_data[\"PassengerId\"].values, 'Survived':predictions} \ndf_submission = pd.DataFrame(data)\n\ndf_submission.to_csv(\"submission5.csv\",index=False)","30ae11a1":"Two Versions of the Functions: One for training and the other for testing","8c87ee2d":"Using K = 5","6bf7e955":"# KNN Classifier: Vectorized Approach"}}