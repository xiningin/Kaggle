{"cell_type":{"05507ec9":"code","c1b1dd67":"code","0e319b84":"code","bac8ca81":"code","76e04aee":"code","ef711045":"code","8c50aa81":"code","cda767a5":"code","f5a20851":"code","5e5c3cb8":"code","3c58db99":"code","8be10334":"code","b2b225a0":"code","e6eae667":"code","b5cf48f4":"code","b59d5c2b":"code","2f3f5fd3":"code","9d390cec":"code","398fefb2":"code","36755c0e":"code","32168106":"code","38e4fa5e":"code","8d4a14b6":"code","d77e4bf8":"code","05a2a6e6":"code","6b3777b5":"code","f559cd9d":"code","f647b791":"code","73b80c19":"code","6f4a2f15":"code","ff1b1264":"code","66ba50a9":"code","6d045f53":"code","3a012e84":"code","22ee9cff":"code","f6a00488":"code","68bfbd54":"code","3022a2dd":"code","3a922ae7":"code","3848eebd":"code","65b60889":"code","14989ef2":"code","2b2f2577":"code","b93bf72a":"code","ca474186":"markdown","822c6823":"markdown","99bebc60":"markdown","9ec8bef1":"markdown","6575cef6":"markdown","1f4ed426":"markdown"},"source":{"05507ec9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c1b1dd67":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n# Styling \nplt.style.use('fivethirtyeight')\n\n# \n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n","0e319b84":"df=pd.read_csv('..\/input\/delhi-crime-data\/Delhi Accident Data.csv')\ndf.head()","bac8ca81":"df=df.drop([\"Unnamed: 7\",\"Unnamed: 8\",\"Unnamed: 9\"], axis=1)\n","76e04aee":"k= pd.DataFrame()\nk['df']= df.isnull().sum()\nk.T","ef711045":"df.columns.values","8c50aa81":"df['TYPE OF ACCIDENT'].value_counts()","cda767a5":"dff=df[df['TYPE OF ACCIDENT']!=\"NON INJURY\"]","f5a20851":"x=dff[['DISTRICT', 'TYPE OF ACCIDENT']]","5e5c3cb8":"x['DISTRICT'].value_counts()\/len(x['DISTRICT'])","3c58db99":"z=pd.DataFrame(x['TYPE OF ACCIDENT'].value_counts()\/len(x['TYPE OF ACCIDENT']))","8be10334":"z['Log-odds']=z['TYPE OF ACCIDENT']\/(1-z['TYPE OF ACCIDENT'])","b2b225a0":"z['sigmoid']=np.log(z['Log-odds'])","e6eae667":"z","b5cf48f4":"# log(z)=b0+b1*x\n# x=1 or 0 # 1 is fatality rate # 0 is none fatal.\n\n#z['sigmoid'][0]=b0+b1*0\nb0=z['sigmoid'][0]\nb1=z['sigmoid'][1]-b0\nprint(\"The intercept is :-\",b0)\nprint(\"The coefficient:-\",b1)","b59d5c2b":"x=[-1,1]\ny=[]\nfor i in x:\n    y.append(b0+b1*i)\n\nplt.plot(x, y)","2f3f5fd3":"x=dff[['DISTRICT', 'TYPE OF ACCIDENT']]","9d390cec":"districts={\"SOUTH EAST DELHI\":0.130623,\n\"NEW DELHI\":0.123161,\n\"NORTH DELHI(ROHINI)\":0.118555,\n\"CENTRAL DELHI\":0.107928,\n\"SOUTH WEST DELHI\":0.099254,\n\"WEST DELHI\":0.097328,\n\"NORTH WEST DELHI\":0.092816,\n\"EAST DELHI\":0.073932,\n\"SHAHDARA\":0.064625,\n\"SOUTH DELHI\":0.049445,\n\"NORTH EAST DELHI\":0.042091,\n\"UNK\":0.000229,\n\"OUTER\":0.000013}\n\n\nx['DISTRICT']=[districts[z] for z in x['DISTRICT']]","398fefb2":"type_of_accident={'SIMPLE ACCIDENT':0, 'FATAL ACCIDENT':1}\nx['TYPE OF ACCIDENT']=[type_of_accident[z] for z in x['TYPE OF ACCIDENT']]","36755c0e":"(df['YEAR'].value_counts()\/len(df)).values","32168106":"x['YEAR']=df['YEAR']","38e4fa5e":"x.head()","8d4a14b6":"year={2008:0.11383799 , 2009:0.11135608, 2010:0.10673549, 2011:0.09988383, 2012:0.09921054, \n      2013:0.09736231, 2014:0.09610815, 2015:0.09583091, 2016:0.09157998, 2017:0.08809474}\nx['YEAR']=[year[z] for z in x['YEAR']]","d77e4bf8":"x.head()","05a2a6e6":"X=x[['DISTRICT', 'YEAR']]\ny=x['TYPE OF ACCIDENT']\nX_train, x_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","6b3777b5":"from sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay","f559cd9d":"lr=LogisticRegression()\nlr.fit(X, y)","f647b791":"d=pd.crosstab(x['DISTRICT'], x['TYPE OF ACCIDENT'])","73b80c19":"import statsmodels.api as sm\nlr_model=sm.Logit(y, X)\nresult=lr_model.fit()\nprint(result.summary())","6f4a2f15":"y_pred=lr.predict(X_train)","ff1b1264":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","66ba50a9":"y_test_pred=lr.predict(x_test)","6d045f53":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","3a012e84":"cfm=confusion_matrix(y_test, y_test_pred)","22ee9cff":"disp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=lr.classes_)\ndisp.plot() ","f6a00488":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","68bfbd54":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","3022a2dd":"x['TYPE OF ACCIDENT'].value_counts()\/len(x)","3a922ae7":"y_test_pred_prob=lr.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","3848eebd":"metrics.roc_auc_score(y_test, y_test_pred_prob)","65b60889":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","14989ef2":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","2b2f2577":"# predict the test data and show the first 5 predictions\npredict=lr.predict(x_test)\npredict[1:6]","b93bf72a":"#Convert the numericalinto nominal value and check the few result\n\nprediction_nominal=['Simple' if x<0.1 else 'Fatal' for x in predict ]\nprediction_nominal[1:6]","ca474186":"# Observation\n* True prediction are given ","822c6823":"# To find the coefficient\n* b0 is intercept. \n* b1 is coefficients.","99bebc60":"# To Test of Individual Regression Coefficients\n* Hypothesis is stated as \n* Ho- bj=0\n* H1:- bj !=0\n* The test statistic for testing above hypothesis is t-test\n* \ud835\udc610 =(bj-0)\/s.e(bj)     * s.e is standard error","9ec8bef1":"# Logistic Regression","6575cef6":"# Obs\n* As we can see that both the coefficients are quite significant.\n* P-value is less than 0.05 which mean we reject our null hypothesis.\n* Both the coeeficients are significant to the log regressio.\n* Beside that we can get the confidance interval of both the coefficeients.\n","1f4ed426":"# Using Sklearn**"}}