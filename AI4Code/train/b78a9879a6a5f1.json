{"cell_type":{"2daf5561":"code","82e2032b":"code","29c4402a":"code","501255b8":"code","91637d94":"code","1e2ad342":"code","ad456699":"code","4a5dddfd":"code","a55635b2":"code","ceefe778":"code","d461599b":"code","c17812ab":"code","2bc7147a":"code","a23bfc38":"code","be90e815":"code","f15a9a14":"code","7e757847":"code","63211787":"code","7247c651":"code","919e5c19":"code","d9a0774a":"markdown","9afdcd7f":"markdown","79f5b8b2":"markdown","869832fa":"markdown","63f7f70e":"markdown","a23557ba":"markdown","96f0ff7c":"markdown"},"source":{"2daf5561":"import pandas as pd\nfrom pathlib import Path\nimport os\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom matplotlib import pyplot as plt, image as img\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    Conv2DTranspose,\n    MaxPool2D,\n    ReLU,\n    Flatten,\n    Dense,\n    UpSampling2D,\n    Dropout,\n    Input, \n    Concatenate,\n    GlobalAveragePooling2D, \n    GlobalMaxPooling2D,\n)\nfrom skimage.transform import resize\nfrom tensorflow import Tensor\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.layers import Input\nfrom tensorflow import Tensor\nfrom scipy.stats import mannwhitneyu\nfrom tabulate import tabulate\n\n!pip3 install progressbar\nimport progressbar\n\n# random seed generator\nnp.random.seed(3)\ntf.random.set_seed(7)","82e2032b":"def load_raw_data():\n\n    covid_path = \"..\/input\/large-covid19-ct-slice-dataset\/curated_data\/curated_data\/2COVID\"\n    non_covid_path = \"..\/input\/large-covid19-ct-slice-dataset\/curated_data\/curated_data\/1NonCOVID\"\n    cap_path = \"..\/input\/large-covid19-ct-slice-dataset\/curated_data\/curated_data\/3CAP\"\n\n    covid_images = list(Path(covid_path).glob(\"*.png\"))\n    non_covid_images = list(Path(non_covid_path).glob(\"*.png\"))\n    cap_images = list(Path(cap_path).glob(\"*.png\"))\n    \n    # To visualize the dataset\n    fig = plt.figure(figsize=(10, 10))\n    fig.add_subplot(1, 2, 1)\n    image = img.imread(covid_images[1])\n    plt.imshow(image)\n    plt.title(\"CT Scan of Covid Affected Lungs\")\n\n    fig.add_subplot(1, 2, 2)\n    image = img.imread(non_covid_images[1])\n    plt.imshow(image)\n    plt.title(\"CT Scan of Healthy Lungs\")\n    return covid_images, non_covid_images, cap_images","29c4402a":"covid_images, non_covid_images, cap_images = load_raw_data()\n\nprint(len(covid_images))\nprint(len(non_covid_images))\nprint(len(cap_images))","501255b8":"IMG_SIZE = 64\n\n# Three empty numpy arrays to store coverted images\npositive_npy = np.empty((len(covid_images), IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\nnegative_npy = np.empty((len(non_covid_images), IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\ncap_npy = np.empty((len(cap_images), IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\n\n# start a bar of show percentage of loading data \ncovid_bar = progressbar.ProgressBar(maxval=len(covid_images), widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\nnon_covid_bar = progressbar.ProgressBar(maxval=len(non_covid_images), widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\ncap_bar = progressbar.ProgressBar(maxval=len(cap_images), widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n","91637d94":"covid_bar.start()\n# Converting COVID dataset to .npy format\nfor i, _file in enumerate(covid_images):\n    try:\n        image_npy = img.imread(_file)\n        positive = resize(image_npy, (IMG_SIZE, IMG_SIZE, 1), anti_aliasing=True)\n        positive_npy[i] = positive\n    except:\n        pass\n    covid_bar.update(i+1)\n    \ncovid_bar.finish()\nprint(\"COVID images converting done\")","1e2ad342":"non_covid_bar.start()\n# Converting non-COVID dataset to .npy format\nfor i, _file in enumerate(non_covid_images):\n    try:\n        image_npy = img.imread(_file)\n        negative = resize(image_npy, (IMG_SIZE, IMG_SIZE, 1), anti_aliasing=True)\n        negative_npy[i] = negative\n    except:\n        print(\"cant open image \" + i + \"th\") \n        \n    non_covid_bar.update(i+1)\nnon_covid_bar.finish()\nprint(\"non covid images converting done\")     ","ad456699":"cap_bar.start()\n# Converting non-COVID dataset to .npy format\nfor i, _file in enumerate(cap_images):\n    try:\n        image_npy = img.imread(_file)\n        cap = resize(image_npy, (IMG_SIZE, IMG_SIZE, 1), anti_aliasing=True)\n        cap_npy[i] = cap\n    except:\n        print(\"cant open image \" + i + \"th\") \n        \n    cap_bar.update(i+1)\ncap_bar.finish()\nprint(\"cap images converting done\") ","4a5dddfd":"print(positive_npy.shape)\nprint(negative_npy.shape)\nprint(cap_npy.shape)","a55635b2":"# To load .npy datasets\ndef load_data():\n    cap = cap_npy\n    cap_labels = [2 for i in cap]\n    positive = positive_npy\n    positive_labels = [1 for i in positive]\n    negative = negative_npy\n    negative_labels = [0 for i in negative]\n\n    # Joining both datasets and labels\n    X = np.concatenate([positive, negative, cap])\n    y = np.concatenate([negative_labels, positive_labels, cap_labels])\n    return X, y","ceefe778":"# save x and y\nX, y = load_data()\nnp.savez('X', X)\nnp.savez('y', y)","d461599b":"print(X.shape)\nprint(y.shape)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\ny_train_hot = keras.utils.to_categorical(y_train, 3)\ny_test_hot =  keras.utils.to_categorical(y_test, 3)","c17812ab":"VGG = tf.keras.applications.VGG19(weights='imagenet', include_top=False)\nVGG.trainable =False\nfor i, layer in enumerate(VGG.layers):\n  print(i, layer.name)\n\nfor layer in VGG.layers[:-5]:\n   layer.trainable = False\nfor layer in VGG.layers[-5:]:\n   layer.trainable = True\nfor layer in VGG.layers:\n    print(layer, layer.trainable) \n\nVGG.summary()","2bc7147a":"def cnn(): \n    from tensorflow.keras.layers import Input, GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate\n    from tensorflow.keras.models import Model\n    VGG = tf.keras.applications.VGG19(weights='imagenet', include_top=False)\n    for layer in VGG.layers[:-5]:\n      layer.trainable = False\n    for layer in VGG.layers[-5:]:\n      layer.trainable = True\n    \n    input = Input(shape=(64, 64, 1))\n    x = Conv2D(3, (3, 3), padding='same')(input)\n    \n    x = VGG(x , training=False)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # multi output\n    output = Dense(3, activation=\"softmax\", name='root')(x)\n \n\n    # model\n    model = Model(input,output)\n    \n    optimizer = keras.optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    \n    return model","a23bfc38":"model = cnn()\nmodel.summary()\n\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n\ndatagen = ImageDataGenerator(rotation_range=180, # Degree range for random rotations\n                        width_shift_range=0.2, # Range for random horizontal shifts\n                        height_shift_range=0.2, # Range for random vertical shifts\n                        zoom_range=0.2, # Range for random zoom\n                        horizontal_flip=True, # Randomly flip inputs horizontally\n                        vertical_flip=True) # Randomly flip inputs vertically\nBATCH_SIZE = 64\ndatagen.fit(X_train)","be90e815":"history = model.fit(X_train, y_train_hot, batch_size=BATCH_SIZE,\n               epochs=200,\n               verbose=1,\n               callbacks=[annealer, checkpoint],\n               validation_data=(X_test, y_test_hot))","f15a9a14":"# accuracy plot \nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","7e757847":"# loss plot\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","63211787":"# for plot images and lable them in form of model prediction and the actual that it was\ndef plot_image(i, predictions_array, true_labels, images):\n    class_names = ['NON-COVID', 'COVID', 'PHENOMIA']\n    predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.imshow(img[...,0], cmap=plt.cm.binary)\n\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        color = 'blue'\n    else:\n        color = 'red'\n\n    plt.xlabel(\"{} {:2.0f}% (real is:{})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n    predictions_array, true_label = predictions_array[i], true_label[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1]) \n    predicted_label = np.argmax(predictions_array)\n\n    thisplot[predicted_label].set_color('white')\n    thisplot[true_label].set_color('black')","7247c651":"from sklearn.metrics import classification_report, confusion_matrix\ny_pred = model.predict(X_test)\npredicted = np.argmax(y_pred)\naccuracy = np.equal(y_test, predicted).mean()\naccuracy","919e5c19":"# Plot the first X test images, their predicted label, and the true label\n# Color correct predictions in blue, incorrect predictions in red\nnum_rows = 5\nnum_cols = 5\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    plot_image(i, y_pred, y_test, X_test)","d9a0774a":"# Plot images and label Predicted","9afdcd7f":"# Image Read and Resize Function","79f5b8b2":"# Import libraries","869832fa":"# VGG19 Freeze Last Block","63f7f70e":"# VGG Layers","a23557ba":"# Accuracy and Loss Curve","96f0ff7c":"# Data Augmentation and Fitting Model"}}