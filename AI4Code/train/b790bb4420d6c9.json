{"cell_type":{"772dd886":"code","348a3e48":"code","f65a9468":"code","627775f6":"code","c3c18dd5":"code","74023272":"code","d86748bb":"code","5a57c9c1":"code","578adfde":"code","aaf616f5":"code","1d3fc73e":"code","65135ee8":"code","dc9a008e":"code","f993bc49":"code","84c90b7a":"code","92cc509e":"code","83af2b05":"code","072459f7":"code","12811780":"code","7b839738":"code","d6ec606b":"code","0b4dc0e4":"markdown","45e3d6ee":"markdown","4028d4e9":"markdown","fb4c8996":"markdown","27362f7f":"markdown","df5b2f12":"markdown","c21bdab2":"markdown","e291d78f":"markdown","70f3ac29":"markdown","819dcfa7":"markdown","3b35ebf6":"markdown","20fe0c62":"markdown","a6f7299c":"markdown","a8c4a6fc":"markdown"},"source":{"772dd886":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","348a3e48":"from sklearn.preprocessing import LabelBinarizer , LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import SelectKBest , chi2 , f_classif\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss , hamming_loss\nfrom skmultilearn.adapt import MLkNN\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline","f65a9468":"train_features = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_targets_scored = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')\ntrain_targets_unscored = pd.read_csv('..\/input\/lish-moa\/train_targets_nonscored.csv')\ntest_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\nsample_sub = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')","627775f6":"def EncodeLabel(data , feature , binary=True):\n    if binary:\n        lb = LabelBinarizer()\n        temp = lb.fit_transform(data[feature])\n        data[feature]= temp\n    else:\n        le = LabelEncoder()\n        temp = le.fit_transform(data[feature])\n        data[feature] = temp","c3c18dd5":"print(len(train_targets_scored.columns))\nprint(train_targets_scored.columns)\n","74023272":"for c in train_targets_scored.columns[1:]:\n    print(train_targets_scored[c].value_counts())","d86748bb":"train_features.describe()","5a57c9c1":"train_features.isnull().sum().sum()","578adfde":"print(f'total number of samples = {train_features.shape[0]}')\nprint(f'total number of features = {len(train_features.columns[1:])}')\ngene_exp_features = [c for c in train_features.columns if c.startswith('g-')]\nprint(f'total number of gene expression features {gene_exp_features[0]} to {gene_exp_features[-1]} = {len(gene_exp_features)}')\ncell_viability = [c for c in train_features.columns if c.startswith('c-')]\nprint(f'total number of cell viability features {cell_viability[0]} to {cell_viability[-1]} = {len(cell_viability)}')\nother_features = [c for c in train_features.columns[1:] if c not in gene_exp_features and c not in cell_viability]\nprint('other features')\nfor c in other_features:\n    print(c)","aaf616f5":"print(f'dtype of g- = {train_features[gene_exp_features[0]].dtypes}')\nprint(f'dtype of c- = {train_features[cell_viability[0]].dtypes}')\nprint(f'dtype of {other_features[0]}={train_features[other_features[0]].dtypes}')\nprint(f'dtype of {other_features[1]}={train_features[other_features[1]].dtypes}')\nprint(f'dtype of {other_features[2]}={train_features[other_features[2]].dtypes}')","1d3fc73e":"for c in other_features:\n    print(f'no. of unique values for {c} = {train_features[c].nunique()}')","65135ee8":"EncodeLabel(train_features , 'cp_type')\nEncodeLabel(train_features , 'cp_dose')","dc9a008e":"X = train_features.drop(columns=['sig_id'])\nY = train_targets_scored.drop(columns=['sig_id'])","f993bc49":"train_x , val_x , train_y , val_y = train_test_split(X,Y, test_size=0.2)\nprint(f'shape of train_x = {train_x.shape}')\nprint(f'shape of train_y = {train_y.shape}')\nprint(f'shape of val_x = {val_x.shape}')\nprint(f'shape of val_y = {val_y.shape}')","84c90b7a":"classifier = MLkNN(k=3)\nclassifier.fit(np.array(train_x) ,np.array( train_y))\npreds = classifier.predict(np.array(val_x))\nloss = hamming_loss(val_y , preds)\nprint(loss)","92cc509e":"EncodeLabel(test_features , 'cp_type')\nEncodeLabel(test_features , 'cp_dose')","83af2b05":"x_test = np.array(test_features.drop(columns=['sig_id']))\ny_test = classifier.predict(x_test)","072459f7":"y_dense = y_test.todense()\nprint(y_dense.shape)\nprint(y_test.shape)\ny_dense","12811780":"pred_df = test_features[['sig_id']]\nfor i, d in enumerate(val_y.columns):\n    pred_df[d] = y_dense[:,i]\n    \npred_df.head()","7b839738":"pred_df.set_index('sig_id' , inplace=True)\npred_df","d6ec606b":"pred_df.to_csv('submission.csv')","0b4dc0e4":"### Lets look at features","45e3d6ee":"### Lets look at the dataset and target labels","4028d4e9":"Creating the submission","fb4c8996":"## Model\nI am going to use the adaptive algorithm MLkNN short Multi Learn k Nearest Neighbours\n\nnow one thing to remember is unlike sklearn skmultilearn can't handle dataframes so make sure you are passing numpy arrays","27362f7f":"submitting","df5b2f12":"# Multi label Classification using Scikit-multilearn\n---\nAs we know that problem of MoA classification is a multi label classifcation problem. There are different approaches and algorithm to solve this problem here I am going to give a demo scikit-multilearn which is complete all in one framework for solving multilabel problems in python\n\n[scikit-multilearn](http:\/\/scikit.ml\/userguide.html#)","c21bdab2":"Looking for any null values","e291d78f":"Lets Look at the other teachers","70f3ac29":"Encode Label function","819dcfa7":"loking at different type of feature groups","3b35ebf6":"## preparing the dataset to feed into the model\n","20fe0c62":"importing all the modules","a6f7299c":"skmultilearn outputs a predictions as sparse matrix so we need to convert it to a dense matrix in order to infer the result and make submission","a8c4a6fc":"loading the dataset"}}