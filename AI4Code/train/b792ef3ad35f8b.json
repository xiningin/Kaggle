{"cell_type":{"190a00f7":"code","31172a67":"code","452fd54a":"code","e0cb9cee":"code","328e6bce":"code","7be673b5":"code","03d57928":"code","a2a9540c":"code","0dc60e61":"code","d07e3ab9":"code","adf94cd9":"code","c7c3ee5b":"code","288794a2":"code","a2ec1ced":"code","9f7a2474":"code","22b4b4da":"code","f77e9877":"code","50858f99":"code","a3f83b59":"code","4bcd5f7a":"code","c22b85d6":"code","7af6b5e8":"code","a41e9a47":"code","1fc7978d":"code","bc54311c":"code","0f43b5a7":"code","6fede9d6":"code","460b997f":"code","f92e94a1":"code","f4061c2a":"code","76e7578b":"code","50ecbda6":"code","c7ef0717":"markdown","fcb41010":"markdown","28cde1d1":"markdown","e9e8c379":"markdown","bab08f88":"markdown","379b4dec":"markdown","43d8e181":"markdown","33e526de":"markdown","f0ff21c9":"markdown","3c65aff1":"markdown","df0dfa54":"markdown"},"source":{"190a00f7":"import numpy as np\nimport pandas as pd","31172a67":"from sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer","452fd54a":"df = pd.read_csv('..\/input\/nlp-in-python-1\/05\/tweets30k.csv')\ndf","e0cb9cee":"df['sentiment'].value_counts()","328e6bce":"def svm(data):\n    # 1 - Prepare data\n    # tfidf = TfidfVectorizer()\n    tfidf = TfidfVectorizer(norm='l1') # Optimized model\n\n    X = tfidf.fit_transform(data['tweet'])\n    y = data['sentiment']\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)\n    \n    # 2 - Create & Train model\n    cl = LinearSVC()\n    cl.fit(X_train, y_train)\n\n    # 3 - Test accuracy\n    # The prediction accuracy using tf-idf is limited with large datasets as it creates a huge vector and you'll run out of memory\n    # Best to use word2vec, BERT and other alternatives\n    y_pred = cl.predict(X_test)\n    print(classification_report(y_test, y_pred))\n    \n    return tfidf, cl","7be673b5":"tfidf, cl = svm(df)","03d57928":"x = 'I am really happy today'\ncl.predict(tfidf.transform([x]))","a2a9540c":"import dataproc","0dc60e61":"# 1 - convert to lowercase\ndf['tweet'] = df['tweet'].apply(lambda x: x.lower())","d07e3ab9":"dataproc","adf94cd9":"# 2 - expand the contractions - e.g. \"it's\" to \"it is\"\ndf['tweet'] = df['tweet'].apply(lambda x: dp.cont_exp(x))","c7c3ee5b":"# 3 - remove web specific stuff - email\/urls\/retweets\/htmltags\ndf['tweet'] = df['tweet'].apply(lambda x: dp.remove_emails(x))\ndf['tweet'] = df['tweet'].apply(lambda x: dp.remove_urls(x))\ndf['tweet'] = df['tweet'].apply(lambda x: dp.remove_rt(x))\ndf['tweet'] = df['tweet'].apply(lambda x: dp.remove_html_tags(x))","288794a2":"# 4 - remove special characters\ndf['tweet'] = df['tweet'].apply(lambda x: dp.remove_special_chars(x))","a2ec1ced":"df","9f7a2474":"tfidf, cl = svm(df)","22b4b4da":"x = 'I am really happy today'\ncl.predict(tfidf.transform([x]))","f77e9877":"import pickle","50858f99":"pickle.dump(cl, open('05\/output\/cl.pkl', 'wb')) # wb - write binary mode\npickle.dump(tfidf, open('05\/output\/tfidf.pkl', 'wb'))","a3f83b59":"cl = pickle.load(open('05\/output\/cl.pkl', 'rb')) # rb - read binary mode\ntfidf = pickle.load(open('05\/output\/tfidf.pkl', 'rb')) # rb - read binary mode","4bcd5f7a":"# tfidf.vocabulary_","c22b85d6":"x","7af6b5e8":"cl.predict(tfidf.transform([x]))","a41e9a47":"consumer_key = 'R7DGimRNkT11sbngA0MRqLmNE'\nconsumer_secret = 'w5Axtw43feejwgmPIhqPhPOt1aHso1Guw1yuFwlmijtlh0vguK'\naccess_token = '1279486577656295425-l3gaKqKuHQdKl44rPXUc0WYcc26wgq'\naccess_token_secret = '80dGAdcx6LuoWM1mSt669V5NESP0EOuX1dK8Mianjqxi2'","1fc7978d":"import tweepy\n\nauth = tweepy.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_token_secret)\n\napi = tweepy.API(auth)","bc54311c":"home_tweets = api.home_timeline()\n\ntype(home_tweets)","0f43b5a7":"home_tweets[0].text","6fede9d6":"for tweet in home_tweets:\n    print(tweet.text)","460b997f":"import json","f92e94a1":"from textblob import TextBlob\nimport dataprocutil as dp\nimport csv","f4061c2a":"sentiment_china = 0\nsentiment_usa = 0\n\nwith open('05\/output\/sentiment.csv', 'w') as file:\n    writer = csv.DictWriter(file, fieldnames=['usa', 'china'])\n    writer.writeheader()\n    \ndef predict_sentiment(tweet):\n    return cl.predict(tfidf.transform([tweet]))\n\ndef process_tweet(tweet):\n    t = str(tweet).lower()\n    t = dp.cont_exp(t)\n    t = dp.remove_emails(t)\n    t = dp.remove_urls(t)\n    t = dp.remove_rt(t)\n    t = dp.remove_html_tags(t)\n    t = dp.remove_special_chars(t)\n    \n    # blob = TextBlob(t)\n    # sent = blob.sentiment.polarity\n    sent = predict_sentiment(t)[0]\n    \n    global sentiment_china\n    global sentiment_usa\n    # print(sentiment_usa, sentiment_china)\n    \n    if 'usa' in t and 'china' not in t:\n        sentiment_usa += sent\n    elif 'china' in t and 'usa' not in t:\n        sentiment_china += sent\n        \n    \n    # Persist results to file\n    with open('05\/output\/sentiment.csv', 'a') as file:\n        writer = csv.DictWriter(file, fieldnames=['usa', 'china'])\n        writer.writerow({ 'usa': sentiment_usa, 'china': sentiment_china })\n        \n    # Update the plot\n        ","76e7578b":"class TweetStreamListener(tweepy.StreamListener):\n    def on_status(self, status):\n        print(status.text)\n    \n    def on_data(self, data):\n        result = json.loads(data)\n        try:\n            process_tweet(result['text'])\n        except:\n            pass\n        \n    def on_error(self, status_code):\n        if status_code == 420:\n            print('Error, closing stream')\n            return False # Close stream","50ecbda6":"# Create a stream listener\nsl = TweetStreamListener()\n\n# Attach tweets to the stream listener\ns = tweepy.Stream(auth=api.auth, listener=sl)\n\n# Filter \/ track only desired keywords\ns.filter(track=['usa', 'china'])","c7ef0717":"## Prepare Data for training & Create Classifier Model","fcb41010":"On our svm function, we can change the TfidfVectorizer params to fine-tune our model\n\n```python\ntfidf = TfidfVectorizer()\ntfidf = TfidfVectorizer(norm='l1', ngram_range=(1,2), analyzer='char', max_features=5000)\n\n# norm - select the normalization method\n# ngram-range - sepcify ngram range to use instead of unigrams\n# analyzer - analyzes by 'word', 'char' etc.\n# max_features - how many words to save in the dict\n```","28cde1d1":"# Saving and Loading Models","e9e8c379":"# Getting a Tweet Stream","bab08f88":"# Data Cleaning","379b4dec":"# Real-Time Twitter Sentiment Analysis","43d8e181":"# Getting Home Tweets","33e526de":"# Twitter Sentiment Analysis","f0ff21c9":"## Import and Inspect dataset","3c65aff1":"# Test Classifier","df0dfa54":"# Fine-Tuning Model"}}