{"cell_type":{"222fd4e8":"code","4527acaf":"code","36846c15":"code","fdd4977d":"code","16c93d14":"code","9d350c05":"code","8530f150":"code","be355795":"code","1bc5c6f8":"code","27248c04":"code","b1e0921a":"code","a3a0f0a3":"code","c02eba4b":"code","0bc3e541":"code","aba7bf7f":"code","bea74279":"code","b4556111":"code","af7d8754":"code","0f884bbc":"code","436edfce":"code","0cce3bde":"code","ceca718e":"code","78b16156":"code","e15a4c1e":"code","2e6bdd3c":"code","dd32e7af":"code","44c80b47":"code","5a3e66d2":"code","ef30320a":"code","09a5b6a2":"markdown","f3512cb3":"markdown","ff4d3e55":"markdown","b1011b5f":"markdown","488bf074":"markdown","7ad972b8":"markdown","a86f8d11":"markdown","bca599e5":"markdown","93ab3c9c":"markdown","0608e789":"markdown","e27f1de1":"markdown","c1a1c488":"markdown","2973c087":"markdown","f4eafa34":"markdown","c5a44d3d":"markdown","db831ebd":"markdown","8ee6b9ab":"markdown","53defb63":"markdown","759b08d3":"markdown","f4926ba5":"markdown","d0d0801e":"markdown","5479c984":"markdown","46205f63":"markdown","e241ee98":"markdown","0acc2299":"markdown","eaeab743":"markdown","db2a1de0":"markdown"},"source":{"222fd4e8":"import re,os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom colorama import Fore, Back, Style\n\nimport lightgbm as lgb # CLF1\nfrom sklearn.linear_model import LogisticRegression # CLF2\nfrom xgboost import XGBRegressor # CLF3\nfrom sklearn.naive_bayes import GaussianNB  # CLF4\nfrom sklearn.ensemble import RandomForestClassifier # CLF5\nfrom sklearn.linear_model import LinearRegression # CLF6\nfrom sklearn.linear_model import Lasso # CLF7\nfrom sklearn.linear_model import ElasticNet # CLF8\nfrom sklearn.neighbors import KNeighborsRegressor # CLF9\nfrom sklearn.tree import DecisionTreeRegressor # CLF10\nfrom sklearn.ensemble import GradientBoostingRegressor # CLF11\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis #CLF12\nfrom mlxtend.classifier import StackingClassifier # SCF\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.metrics import roc_auc_score,roc_curve\n\nimport warnings\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning, module='sklearn')\nwarnings.simplefilter('ignore')\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\n\ndef seed_everything(SEED):\n    np.random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)","4527acaf":"FOLDS = 3\nSEED = 123\nSetup_Parameters = True\nseed_everything(SEED)\nfile_add_list = [1,2,3,4,5]\npesudo_label = True\ntest_pipeline = True","36846c15":"BASE_PATH = '..\/input\/siim-isic-melanoma-classification'\ntrain_metadata = pd.read_csv(os.path.join(BASE_PATH, 'train.csv'))\ntest_metadata = pd.read_csv(os.path.join(BASE_PATH, 'test.csv'))\nsample_submission = pd.read_csv(os.path.join(BASE_PATH, 'sample_submission.csv'))\ntfrecord_number_df =  pd.read_csv('..\/input\/stacking-data\/Image_Name_TFRecord_number.csv')","fdd4977d":"print('Train data shape : ',train_metadata.shape)\nprint('Test data shape : ',test_metadata.shape)","16c93d14":"print('Unique values in column with frequency : ')\n\nprint('\\nsex : ', dict(train_metadata.sex.value_counts()))\nprint('\\nage_approx : ', dict(train_metadata.age_approx.value_counts()))\nprint('\\nanatom_site_general_challenge : ', dict(train_metadata.anatom_site_general_challenge.value_counts()))\nprint('\\ndiagnosis : ', dict(train_metadata.diagnosis.value_counts()))\nprint('\\nbenign_malignant : ', dict(train_metadata.benign_malignant.value_counts()))\nprint('\\ntarget : ', dict(train_metadata.target.value_counts()))","9d350c05":"print('Unique values in column with frequency : ')\n\nprint('\\nsex : ', dict(test_metadata.sex.value_counts()))\nprint('\\nage_approx : ', dict(test_metadata.age_approx.value_counts()))\nprint('\\nanatom_site_general_challenge : ', dict(test_metadata.anatom_site_general_challenge.value_counts()))","8530f150":"train = train_metadata.copy()\ntrain['age_approx'] = train['age_approx'].fillna(train.age_approx.mean())\nsex_code = pd.get_dummies(train.sex, prefix='sex')\nanatom_site_general_challenge_code = pd.get_dummies(train.anatom_site_general_challenge, prefix='anatom_site')\nage_aprox_normalized = (train.age_approx-train.age_approx.mean())\/train.age_approx.std()\ntrain_coded = pd.concat([train.image_name, sex_code, age_aprox_normalized, anatom_site_general_challenge_code , train.target], axis=1)\nprint('Shape : ',train_coded.shape)\ntrain_coded.tail()","be355795":"def add_OOF_pred(train_coded,num):\n    for n in file_add_list:\n        df_ = pd.read_csv(f'..\/input\/95-cv-oof-submission\/oof_{n}.csv')\n        train_coded = pd.merge(train_coded, df_[['image_name','pred']], on=\"image_name\",how='right')\n        train_coded.rename({'pred': f'pred_{n}'}, axis=1, inplace=True)\n    return train_coded\ntrain_coded = pd.merge(tfrecord_number_df, train_coded, on=\"image_name\",how='left')\ntrain_coded = add_OOF_pred(train_coded,5)\ntrain_coded.to_csv('train_coded.csv',index=False)\ntrain_coded.tail()","1bc5c6f8":"test = test_metadata.copy()\ntest['age_approx'] = test['age_approx'].fillna(test.age_approx.mean())\nsex_code = pd.get_dummies(test.sex, prefix='sex')\nanatom_site_general_challenge_code = pd.get_dummies(test.anatom_site_general_challenge, prefix='anatom_site')\nage_aprox_normalized = (test.age_approx-test.age_approx.mean())\/test.age_approx.std()\ntest_coded = pd.concat([test.image_name, sex_code, age_aprox_normalized , anatom_site_general_challenge_code], axis=1)\nprint('Shape : ',test_coded.shape)\ntest_coded.tail()","27248c04":"def add_submission_pred(test_coded,num):\n    for n in file_add_list:\n        df_ = pd.read_csv(f'..\/input\/95-cv-oof-submission\/submission_{n}.csv')\n        test_coded = pd.merge(test_coded, df_[['image_name','target']], on=\"image_name\",how='right')\n        test_coded.rename({'target': f'pred_{n}'}, axis=1, inplace=True)\n    return test_coded\ntest_coded = add_submission_pred(test_coded,5)\ntest_coded.to_csv('test_coded.csv',index=False)\ntest_coded.tail()","b1e0921a":"def crossValidate(CLF,X=train_coded,X_test=test_coded,FOLDS = 5,SEED = 123,show_roc_curve = False,pesudo_label = False):\n    print(Fore.YELLOW)\n    print('#'*60)\n    model_name = type(CLF).__name__\n    print('#### ',model_name)\n    print('#'*60,Style.RESET_ALL)\n    \n    CV_Score = []\n    Val_preds = []\n    Val_imagenames = []\n    val_targets = []\n    \n    CV_Score_pesudo = []\n    Val_preds_pesudo = []\n    Val_imagenames_pesudo = []\n    val_targets_pesudo = []\n    \n    skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\n\n    for fold,(idxT,idxV) in enumerate(skf.split(np.arange(15))):\n\n        idxT, idxV = X.tfrecord.isin(idxT), X.tfrecord.isin(idxV)\n\n        X_train_main, y_train_main = X[idxT], X[idxT]\n        X_val_main, y_val_main = X[idxV], X[idxV]\n        print(Fore.MAGENTA)\n        print('#'*60,Style.RESET_ALL)\n        print(Fore.BLUE)\n        print('FOLD : ',fold)\n        print('Train TFrecords : ',X_train_main.tfrecord.unique())\n        print('Validation TFrecords : ',X_val_main.tfrecord.unique())\n        image_names = list(X_val_main['image_name'])\n        \n        X_train = X_train_main.drop(['target','tfrecord'],axis=1).iloc[:,1:]\n        y_train = y_train_main['target']\n        \n        X_val = X_val_main.drop(['target','tfrecord'],axis=1).iloc[:,1:]\n        y_val = y_val_main['target']\n        \n        CLF_pesudo = CLF\n        CLF.fit(X_train, y_train)\n        \n        try:\n            y_train_pred  = CLF.predict_proba(X_train)[:,1]\n        except:\n            y_train_pred = CLF.predict(X_train)\n            \n        print('Train AUC : ', roc_auc_score(y_train,y_train_pred))\n        try:\n            Val_pred  = CLF.predict_proba(X_val)[:,1]\n        except:\n            Val_pred = CLF.predict(X_val)\n            \n        Val_auc = roc_auc_score(y_val,Val_pred)\n        print('Val AUC : ', Val_auc)\n        \n        CV_Score.append(Val_auc)\n        Val_preds.append(Val_pred)\n        Val_imagenames.append(image_names)\n        val_targets.append(list(y_val))\n        \n        if pesudo_label:\n            \n            train2_Pesudo = X_train_main.copy()\n            train2_Pesudo['target_label'] = y_train_main['target']\n            test2_Pesudo = X_val_main.copy()\n            test2_Pesudo['target_label'] = Val_pred\n            \n            test2_Pesudo = test2_Pesudo[ (test2_Pesudo['target_label'] >= 0.99) |  \n                                            (test2_Pesudo['target_label'] >= 0.01)]\n            test2_Pesudo.loc[ test2_Pesudo['target_label']>=0.5, 'target_label' ] = 1\n            test2_Pesudo.loc[ test2_Pesudo['target_label']<0.5, 'target_label' ] = 0\n            \n            print(Fore.CYAN)\n            print('Number of Pesudo Labeled Data added : ',len(test2_Pesudo))\n            print('target_label = 1 : ',len(test2_Pesudo[test2_Pesudo['target_label'] == 1]))\n            print('target_label = 0 : ',len(test2_Pesudo[test2_Pesudo['target_label'] == 0]))\n            \n            train_pesudo = pd.concat([train2_Pesudo,test2_Pesudo],axis=0)\n            \n            X_train_pesudo = train_pesudo.drop(['target_label','target','tfrecord'],axis=1).iloc[:,1:]\n            y_train_pesudo = train_pesudo['target_label']\n            \n            CLF_pesudo.fit(X_train_pesudo, y_train_pesudo)\n            \n            try:\n                y_train_pred_pesudo  = CLF_pesudo.predict_proba(X_train_pesudo)[:,1]\n            except:\n                y_train_pred_pesudo = CLF_pesudo.predict(X_train_pesudo)\n\n            print('Pesudo Train AUC : ', roc_auc_score(y_train_pesudo,y_train_pred_pesudo))\n            try:\n                Val_pred_pesudo  = CLF_pesudo.predict_proba(X_val)[:,1]\n            except:\n                Val_pred_pesudo = CLF_pesudo.predict(X_val)\n            \n            Val_auc_pesudo = roc_auc_score(y_val,Val_pred_pesudo)\n            print('Pesudo Val AUC : ', Val_auc_pesudo)\n            print(Style.RESET_ALL)\n            \n            CV_Score_pesudo.append(Val_auc_pesudo)\n            Val_preds_pesudo.append(Val_pred_pesudo)\n            Val_imagenames_pesudo.append(image_names)\n            val_targets_pesudo.append(list(y_val))\n            \n    valtargets = np.concatenate(val_targets)\n    valpreds = np.concatenate(Val_preds)\n    valimagenames = np.concatenate(Val_imagenames)\n    \n    auc_score = roc_auc_score(valtargets,valpreds)\n    \n    print(Fore.YELLOW)\n    print('#'*60)\n    print('\\nCV(auc_score) : ',auc_score)\n    print(f'Mean CV : {np.mean(CV_Score)} +\/- {np.std(CV_Score)}\\n')\n    \n    \n    oof = pd.DataFrame()\n    oof['image_name'] = valimagenames\n    oof['pred'] = valpreds\n    oof['target'] = valtargets\n    \n    \n    ## Test data Prediction\n    Test_imagenames = X_test['image_name']\n    X_test = X_test.iloc[:,1:]\n    try:\n        test_pred = CLF.predict_proba(X_test)[:,1]\n    except:\n        test_pred = CLF.predict(X_test)\n        \n    submission = pd.DataFrame()\n    submission['image_name'] = Test_imagenames\n    submission['target'] = test_pred\n    \n    if pesudo_label:\n        valtargets_pesudo = np.concatenate(val_targets_pesudo)\n        valpreds_pesudo = np.concatenate(Val_preds_pesudo)\n        valimagenames_pesudo = np.concatenate(Val_imagenames_pesudo)\n        \n        auc_score_pesudo = roc_auc_score(valtargets_pesudo,valpreds_pesudo)\n        \n        print('Pesudo CV(auc_score) : ',auc_score_pesudo)\n        print(f'Pesudo Mean CV : {np.mean(CV_Score_pesudo)} +\/- {np.std(CV_Score_pesudo)}\\n')\n        \n        oof_pesudo = pd.DataFrame()\n        oof_pesudo['image_name'] = valimagenames_pesudo\n        oof_pesudo['pred'] = valpreds_pesudo\n        oof_pesudo['target'] = valtargets_pesudo\n        \n        ## Test data Prediction (Pesudo)\n        try:\n            test_pred_pesudo = CLF_pesudo.predict_proba(X_test)[:,1]\n        except:\n            test_pred_pesudo = CLF_pesudo.predict(X_test)\n\n        submission_pesudo = pd.DataFrame()\n        submission_pesudo['image_name'] = Test_imagenames\n        submission_pesudo['target'] = test_pred_pesudo\n        \n    \n    print('#'*60,Style.RESET_ALL)\n    if show_roc_curve:\n        fpr, tpr, _ = roc_curve(valtargets,valpreds)\n        if pesudo_label:\n            fpr_p, tpr_p, _ = roc_curve(valtargets_pesudo,valpreds_pesudo)\n            \n        plt.figure()\n        lw = 2\n        if pesudo_label:\n            plt.plot(fpr_p, tpr_p, color='red',\n                 lw=lw, label=f'Pesudo ROC curve (area = {auc_score_pesudo:0.4f})')\n            \n        plt.plot(fpr, tpr, color='darkorange',\n                 lw=lw, label=f'ROC curve (area = {auc_score:0.4f})')\n        \n        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(f'ROC Curve by : {model_name}')\n        plt.legend(loc=\"lower right\")\n        plt.show()\n    \n    if pesudo_label:\n        return oof , submission, auc_score, model_name, oof_pesudo, submission_pesudo, auc_score_pesudo, str(model_name) + '_Pesudo'\n    return oof , submission, auc_score, model_name","a3a0f0a3":"clf1 = lgb.LGBMClassifier(max_depth=5, \n                          metric=\"auc\", \n                          n_estimators=100, \n                          num_leaves=5, \n                          boosting_type=\"gbdt\", \n                          learning_rate=0.1, \n                          feature_fraction=0.05, \n                          colsample_bytree=0.1, \n                          bagging_fraction=0.8, \n                          bagging_freq=2, \n                          reg_lambda=0.2)","c02eba4b":"clf2 = LogisticRegression(\n            C= 1.0,\n            class_weight=None,\n            dual= False,\n            fit_intercept= True,\n            intercept_scaling= 1,\n            l1_ratio= None,\n            max_iter= 100,\n            multi_class= 'auto',\n            n_jobs= None,\n            penalty= 'l2',\n            random_state= None,\n            solver= 'lbfgs',\n            tol= 0.0001,\n            verbose= 0,\n            warm_start= False)","0bc3e541":"clf3 = XGBRegressor(base_score=0.5, \n                    booster=None, \n                    colsample_bylevel=1,\n                    colsample_bynode=1, \n                    colsample_bytree=0.8, \n                    gamma=1, \n                    gpu_id=-1,\n                    importance_type='gain', \n                    interaction_constraints=None,\n                    learning_rate=0.002, \n                    max_delta_step=0, \n                    max_depth=10,\n                    min_child_weight=1, \n                    missing=None, \n                    monotone_constraints=None,\n                    n_estimators=700, \n                    n_jobs=-1, \n                    nthread=-1, \n                    num_parallel_tree=1,\n                    objective='binary:logistic', \n                    random_state=0,\n                    reg_alpha=0, \n                    reg_lambda=1, \n                    scale_pos_weight=1,\n                    subsample=0.8,\n                    tree_method=None, \n                    validate_parameters=False, \n                    verbosity=None)","aba7bf7f":"clf4 = GaussianNB(\n    priors= None, \n    var_smoothing= 1e-09)","bea74279":"clf5 = RandomForestClassifier(\n        bootstrap= True,\n        ccp_alpha= 0.0,\n        class_weight= None,\n        criterion= 'gini',\n        max_depth= 5,\n        max_features= 'auto',\n        max_leaf_nodes= 30,\n        max_samples= None,\n        min_impurity_decrease= 0.0,\n        min_impurity_split= None,\n        min_samples_leaf= 2,\n        min_samples_split= 100,\n        min_weight_fraction_leaf= 0.0,\n        n_estimators= 300,\n        n_jobs= None,\n        oob_score= False,\n        random_state= None,\n        verbose= 0,\n        warm_start= False)","b4556111":"# clf6 = LinearRegression()","af7d8754":"# clf7 = Lasso()","0f884bbc":"# clf8 = ElasticNet()","436edfce":"clf9 = KNeighborsRegressor(algorithm= 'auto',\n                            leaf_size= 30,\n                            metric= 'minkowski',\n                            metric_params= None,\n                            n_jobs= None,\n                            n_neighbors= 10,\n                            p= 5,\n                            weights= 'uniform')","0cce3bde":"clf10 = DecisionTreeRegressor(ccp_alpha= 0.0,\n                             criterion= 'mse',\n                             max_depth= 5,\n                             max_features= 'auto',\n                             max_leaf_nodes= 30,\n                             min_impurity_decrease= 0.0,\n                             min_impurity_split= None,\n                             min_samples_leaf= 2,\n                             min_samples_split= 100,\n                             min_weight_fraction_leaf= 0.0,\n                             presort= 'deprecated',\n                             random_state= SEED,\n                             splitter= 'best')","ceca718e":"clf11 = GradientBoostingRegressor()","78b16156":"SCF = StackingClassifier(classifiers=[clf1, clf5], \n                         meta_classifier=clf2,\n                         use_probas=True,\n                         average_probas=True)","e15a4c1e":"if test_pipeline:\n    pipelines = []\n    pipelines.append(('LGBMClassifier', Pipeline([('LGBMClassifier',clf1)])))\n    pipelines.append(('LogisticRegression', Pipeline([('LogisticRegression',clf2)])))\n    pipelines.append(('XGBRegressor', Pipeline([('XGBRegressor',clf3)])))\n    pipelines.append(('GaussianNB', Pipeline([('GaussianNB',clf4)])))\n    pipelines.append(('RandomForestClassifier', Pipeline([('RandomForestClassifier',clf5)])))\n    # pipelines.append(('LinearRegression', Pipeline([('LinearRegression',clf6)])))\n    # pipelines.append(('Lasso', Pipeline([('Lasso', clf7)])))\n    # pipelines.append(('ElasticNet', Pipeline([('ElasticNet', clf8)])))\n    pipelines.append(('KNeighborsRegressor', Pipeline([('KNeighborsRegressor', clf9)])))\n    pipelines.append(('DecisionTreeRegressor', Pipeline([('DecisionTreeRegressor', clf10)])))\n    pipelines.append(('GradientBoostingRegressor', Pipeline([('GradientBoostingRegressor', clf11)])))\n    pipelines.append(('StackingClassifier', Pipeline([('StackingClassifier', SCF)])))\n\n    X_train = train_coded.drop('target',axis=1).iloc[:,1:]\n    y_train = train_coded['target']\n\n    M_name = []\n    M_auc_score = []\n    for name, model in pipelines:\n        cv_results = cross_val_score(model, X_train, y_train, cv=FOLDS, scoring='roc_auc')\n        M_auc_score.append(np.mean(cv_results))\n        M_name.append(name)\n        print(\"%s: %f +\/- %f\" % (name, cv_results.mean(), cv_results.std()))","2e6bdd3c":"if test_pipeline:\n    fig, ax = plt.subplots(figsize=(7,7))\n\n    # Save the chart so we can loop through the bars below.\n    bars = ax.bar(\n        x=M_name,\n        height=M_auc_score,\n        tick_label=M_name\n    )\n\n    # Axis formatting.\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_color('#DDDDDD')\n    ax.tick_params(bottom=False, left=False)\n    ax.set_axisbelow(True)\n    ax.yaxis.grid(True, color='#EEEEEE')\n    ax.xaxis.grid(False)\n\n    bar_color = bars[0].get_facecolor()\n    plt.xticks(rotation=90)\n\n    for bar in bars:\n        ax.text(\n          bar.get_x() + bar.get_width() \/ 2,\n          bar.get_height() + 0.05,\n          round(bar.get_height(), 4),\n          horizontalalignment='center',\n          color=bar_color,\n          weight='bold'\n        )\n\n    fig.tight_layout()","dd32e7af":"select_classifier = clf2\nselect_classifier.get_params()","44c80b47":"if Setup_Parameters:\n\n    X_train = train_coded.drop('target',axis=1).iloc[:,1:]\n    y_train = train_coded['target']\n\n    params = dict(\n        C = [0.001, 0.01, 0.1, 1, 10],\n        max_iter = [100,150,50]\n    )\n\n    grid = GridSearchCV(estimator=select_classifier,\n                        param_grid=params, \n                        cv=FOLDS,\n                        scoring='roc_auc',\n                        refit='AUC',\n                        n_jobs = -1)\n\n    grid.fit(X_train, y_train)\n\n    for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n        print(\"AUC : %0.5f +\/- %0.5f %r\"\n              % (grid.cv_results_['mean_test_score'][r],\n                 grid.cv_results_['std_test_score'][r] \/ 2.0,\n                 grid.cv_results_['params'][r]))\n\n    print(f'\\nBest parameters: {grid.best_params_}')\n\n    oof, submission, auc_score, model_name = crossValidate(grid,X=train_coded,X_test=test_coded,FOLDS=FOLDS,SEED=SEED,show_roc_curve=True)","5a3e66d2":"M_name = []\nM_auc_score = []\nfor CLF in [clf1,clf2,clf4,clf5,clf10,clf11,SCF]:\n    if pesudo_label:\n        oof, submission, auc_score, model_name, \\\n        pesudo_oof, pesudo_submission, pesudo_auc_score, pesudo_model_name = crossValidate(CLF,X=train_coded,\n                                                                                           X_test=test_coded,\n                                                                                           FOLDS=FOLDS,SEED=SEED,\n                                                                                           show_roc_curve=True,\n                                                                                           pesudo_label=True)\n    else:\n        oof, submission, auc_score, model_name = crossValidate(CLF,X=train_coded,X_test=test_coded,FOLDS=FOLDS,SEED=SEED,show_roc_curve=True,pesudo_label=False)\n    \n    oof.to_csv(f'oof_{model_name}_{auc_score:0.4f}.csv',index=False)\n    submission.to_csv(f'submission_{model_name}_{auc_score:0.4f}.csv',index=False)\n    M_name.append(model_name)\n    M_auc_score.append(auc_score)\n    \n    if pesudo_label:\n        pesudo_oof.to_csv(f'Pesudo_oof_{model_name}_{pesudo_auc_score:0.4f}.csv',index=False)\n        pesudo_submission.to_csv(f'Pesudo_submission_{model_name}_{pesudo_auc_score:0.4f}.csv',index=False)\n        M_name.append(pesudo_model_name)\n        M_auc_score.append(pesudo_auc_score)","ef30320a":"fig, ax = plt.subplots(figsize=(15,7))\n\n# Save the chart so we can loop through the bars below.\nbars = ax.bar(\n    x=M_name,\n    height=M_auc_score,\n    tick_label=M_name\n)\n\n# Axis formatting.\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['bottom'].set_color('#DDDDDD')\nax.tick_params(bottom=False, left=False)\nax.set_axisbelow(True)\nax.yaxis.grid(True, color='#EEEEEE')\nax.xaxis.grid(False)\n\nbar_color = bars[0].get_facecolor()\nplt.xticks(rotation=90)\n\nfor bar in bars:\n    ax.text(\n      bar.get_x() + bar.get_width() \/ 2,\n      bar.get_height() + 0.05,\n      round(bar.get_height(), 5),\n      horizontalalignment='center',\n      color=bar_color,\n      weight='bold'\n    )\n\nfig.tight_layout()","09a5b6a2":"## Add Submission Target Value to Test Metadata","f3512cb3":"## StackingClassifier","ff4d3e55":"## LogisticRegression","b1011b5f":"## One-Hot encode Testing Data","488bf074":"## GradientBoostingRegressor","7ad972b8":"## Add OOF Prediction Value to Train Metadata","a86f8d11":"## Classifier Performance","bca599e5":"##  DecisionTreeRegressor","93ab3c9c":"## Import Metadata","0608e789":"## Import Libraries","e27f1de1":"## LinearRegression","c1a1c488":"### Metadata-values [test_metadata]","2973c087":"## GaussianNB","f4eafa34":"## LGBMClassifier","c5a44d3d":"## KNeighborsRegressor","db831ebd":"## Lasso","8ee6b9ab":"## ElasticNet","53defb63":"### Metadata-values [train_metadata]","759b08d3":"### Metadata-Size","f4926ba5":"![Model.png](attachment:Model.png)","d0d0801e":"## Training and Predictions","5479c984":"## RandomForestClassifier","46205f63":"## Strategy\n\n1. Split the train set in k folds [we have used [Chris Deotte](https:\/\/www.kaggle.com\/cdeotte)'s TFrecords Id for spliting data]\n2. Fit a first stage model on k-1 folds and predict the kth fold\n3. Repeat 2) to predict each fold\n4. We now have the (out-of-folds) prediction of the k folds\n5. Split these out-of folds predictions in p folds\n6. Fit a second stage (stacker) model on p-1 folds and predict the pth fold\n7. Repeat 6) to predict each fold\n8. The CV error of the second stage is calculated on each predicted fold\n\n[reference](https:\/\/www.kaggle.com\/general\/18793)","e241ee98":"## Setup Parameters With GridSearchCV","0acc2299":"## One-Hot encode Training Data","eaeab743":"## XGBRegressor","db2a1de0":"# **Classifiers**"}}