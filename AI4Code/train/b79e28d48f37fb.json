{"cell_type":{"2d8b2ceb":"code","4643d9b5":"code","6ca62aaa":"code","56ef19c4":"code","2dec2ddd":"code","14284983":"code","9d324f90":"code","78468461":"code","3af6068a":"code","e61aeb87":"code","645d7618":"code","c814aa5c":"code","7fbaafbc":"code","ae500c8e":"code","a6d0a991":"code","2781fd0c":"code","5c86019e":"code","5ff46f9a":"code","f793946c":"code","02099a88":"code","91c5463a":"code","0674b2da":"code","0b69216e":"code","f75bd7e2":"code","74cde847":"code","3e4ba948":"code","e2144f57":"code","0bbe03c5":"code","63490a51":"code","23ef68b2":"code","568960dc":"code","c5ff20cc":"code","e567949d":"code","91772bb4":"code","9fa75ddd":"code","ad8b54ed":"code","0d8226b7":"code","7a6c293e":"code","24d08067":"code","74abdcdc":"code","4bb6e116":"code","0a9b58d3":"code","4a964e06":"code","7ed4ea5c":"code","91677df8":"code","907d8f45":"markdown","6977f064":"markdown","75fcdbd8":"markdown","2a2e1454":"markdown","df3bbfd4":"markdown","4d6ef581":"markdown","f7e855e4":"markdown","eb98d075":"markdown","6b032d10":"markdown","1165a1ed":"markdown","9bdba316":"markdown","5a41b2b6":"markdown","a5e5f50b":"markdown","dd44282f":"markdown","cc10ff0c":"markdown","c35e3b5d":"markdown","20222c34":"markdown","41d257dd":"markdown","61031b3d":"markdown","53d557f8":"markdown","9c8c8768":"markdown","8f82ce5b":"markdown","446ba0f1":"markdown","e43da0c4":"markdown","21ea5d2e":"markdown","f8c658d7":"markdown","2edaa891":"markdown","89a7292a":"markdown","029edb99":"markdown","33f263e6":"markdown","9d9765ff":"markdown"},"source":{"2d8b2ceb":"try:\n    import pandas as pd\n    import numpy as np \n        \n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n    sns.set(color_codes=True)\n    \n    print(\"all loaded\")\nexcept:\n    print(\"error\")","4643d9b5":"# Loading data from train.csv file\ntrain_df = pd.read_csv(\"train.csv\")\ntrain_df.head(5)","6ca62aaa":"# Loading data from test.csv file\ntest_df = pd.read_csv(\"test.csv\")\ntest_df.head(5)","56ef19c4":"print(train_df.shape)\ntest_df.shape","2dec2ddd":"train_df.info()","14284983":"train_df.isnull().sum()","9d324f90":"test_df.isnull().sum()","78468461":"train_df = train_df.fillna(\"None\")\ntest_df = test_df.fillna(\"None\")","3af6068a":"train_df.duplicated().sum()","e61aeb87":"# train_t = train_df.T\n# train_t.shape\n# print(train_t.duplicated().sum())","645d7618":"sns.boxplot(data=train_df)\nplt.show","c814aa5c":"sns.scatterplot(data=train_df[\"Avg_Account_Balance\"])\nplt.show()","7fbaafbc":"train_df = train_df.drop(\"ID\",axis=1)","ae500c8e":"train = train_df.drop([\"Is_Lead\"],axis=1)\ny = train_df[\"Is_Lead\"]\ntest = test_df","a6d0a991":"#We have 2 types of data in our dataset : int64 and object\n\ntrain_categorical = train.select_dtypes(exclude = ['int64'])\ntest_categorical = test.select_dtypes(exclude = ['int64'])\n\ntrain_numerical = train.select_dtypes(include = ['int64'])\ntest_numerical = test.select_dtypes(include = ['int64'])\n","2781fd0c":"numcol_names_train = train_numerical.columns.values\nnumcol_names_test = test_numerical.columns.values\n\nnumcol_names_train","5c86019e":"#Converting these to list from array\n\nnumcol_names_train.tolist()\nnumcol_names_test.tolist()","5ff46f9a":"sns.kdeplot(train_numerical['Avg_Account_Balance'], bw=0.5)    #bw is smoothing parameter\nplt.show()","f793946c":"sns.kdeplot(train_numerical['Age'], bw=0.5)","02099a88":"sns.kdeplot(train_numerical['Vintage'],bw=0.5)","91c5463a":"sns.kdeplot(test_numerical['Avg_Account_Balance'], bw=0.5)    #bw is smoothing parameter\nplt.show()","0674b2da":"train_numerical['Avg_Account_Balance'] = np.log(train_numerical['Avg_Account_Balance'])\nsns.kdeplot(train_numerical['Avg_Account_Balance'])\nplt.show()","0b69216e":"test_numerical['Avg_Account_Balance'] = np.log(test_numerical['Avg_Account_Balance'])\nsns.kdeplot(test_numerical['Avg_Account_Balance'])\nplt.show","f75bd7e2":"train_numerical.agg(['skew', 'kurtosis'])","74cde847":"#Histograms for numerical Columns\ntrain_numerical.hist(figsize=(15, 10), bins=50, xlabelsize=8, ylabelsize=8);","3e4ba948":"from sklearn.preprocessing import StandardScaler\n\n#Using standard scaler\nscaler = StandardScaler()\ntrain_numerical = scaler.fit_transform(train_numerical.values)\ntrain_numerical = pd.DataFrame(train_numerical, columns = numcol_names_train)\n\ntest_numerical = scaler.fit_transform(test_numerical.values)\ntest_numerical = pd.DataFrame(test_numerical, columns = numcol_names_test)","e2144f57":"from sklearn.preprocessing import LabelEncoder\n\ntrain_categorical = train_categorical.apply(LabelEncoder().fit_transform)\ntest_categorical = test_categorical.apply(LabelEncoder().fit_transform)","0bbe03c5":"pd.DataFrame(train_categorical)","63490a51":"train_new = pd.concat([train_categorical,train_numerical,y],axis=1)\ntest_new = pd.concat([test_categorical,test_numerical],axis=1)","23ef68b2":"#For coplete Database\n\ncorr_train = train_new.corr()\nplt.figure(figsize=(13,5)) \n\n\nax = sns.heatmap(corr_train,annot=True)\nplt.show\n","568960dc":"imp = train_new.drop(\"Is_Lead\", axis=1).apply(lambda x: x.corr(train_new.Is_Lead))\nprint(imp)","c5ff20cc":"indices = np.argsort(imp)\nprint(imp[indices])     #Sorted in ascending order","e567949d":"for i in range(0, len(indices)):\n    if np.abs(imp[i])>0.02:\n        print(train_new.columns[i])","91772bb4":"# train_new1 = train_new.drop([\"Occupation\"],axis=1)","9fa75ddd":"# import matplotlib.pyplot as plt\n\n# names=['cylinders','displacement','horsepower','weight','acceleration','model year', 'name']\n# plt.title('Miles Per Gallon')\n\n# #Plotting horizontal bar graph\n# plt.barh(range(len(indices)), imp[indices], color='g', align='center')\n# plt.yticks(range(len(indices)), [names[i] for i in indices])\n# plt.xlabel('Relative Importance')\n# plt.show()","ad8b54ed":"for i in range(0,len(train_new1.columns)):\n    for j in  range(0,len(train_new1.columns)):\n        if i!=j:\n            corr_1=np.abs(train_new1[train_new1.columns[i]].corr(train_new1[train_new1.columns[j]]))\n            if corr_1 <0.3:\n                print( train_new1.columns[i] , \" is not correlated  with \", train_new1.columns[j])\n            elif corr_1>0.75:\n                print( train_new1.columns[i] , \" is highly  correlated  with \", train_new1.columns[j])","0d8226b7":"from sklearn.feature_selection import mutual_info_regression\n\ncol = train_new.drop([\"Is_Lead\"],axis=1)\n       \nmig = mutual_info_regression(col, y);\nmig","7a6c293e":"mig = pd.Series(mig)\nmig.index = col.columns\nmig","24d08067":"#Plotting the mutual information\n\nmig.sort_values(ascending=False).plot.bar(figsize=(10, 4))","74abdcdc":"# Split the Train data into predictors and target\n\nX = train_new.drop(['Is_Lead'],axis=1)\npredictor_test = test_new.drop(['ID'], axis =1)\ny = train_new['Is_Lead']","4bb6e116":"predictor_test.columns","0a9b58d3":"X.columns","4a964e06":"# Model Evaluation Metric & Cross Validation Libraries\nfrom sklearn.metrics import *\n# Boosting Algorithm Librarie\nimport xgboost\nfrom lightgbm import LGBMClassifier","7ed4ea5c":"model = LGBMClassifier(metric = 'auc', \n                       n_estimators=50000,    \n                       bagging_fraction=0.95, \n                       subsample_freq = 2, \n                       objective =\"binary\",\n                       importance_type = \"gain\",\n                       verbosity = -1,\n                       random_state=294,\n                       num_leaves = 300,\n                       boosting_type = 'gbdt',\n                       learning_rate=0.15,\n                       max_depth=4, \n                       scale_pos_weight=2,\n                       n_jobs=-1 \n                      )","91677df8":"from sklearn.model_selection import StratifiedKFold\n\naccuracy = []\nskf = StratifiedKFold(n_splits=10,shuffle=True)\n\nskf.get_n_splits(X,y)   #this will return train_index and test_index\n\nfor train_index,test_index in skf.split(X,y):\n    print(\"Train\",train_index,\"Validation:\",test_index)\n    print(train_index.shape,test_index.shape)\n    \n    X_train,X_test = X.iloc[train_index],X.iloc[test_index]\n    y_train,y_test = y.iloc[train_index],y.iloc[test_index]\n    \n    model.fit(X_train,y_train,eval_set=[(X_train, y_train),(X_test, y_test)],early_stopping_rounds=100 ,verbose=100)\n    pred = model.predict(X_test)\n    \n    score = accuracy_score(pred,y_test)\n    \n    accuracy.append(score)\n    print(np.array(accuracy).mean())\n    \n    \n    rocauc = []\n    \n\n    roc_auc = roc_auc_score(y_test,model.predict_proba(X_test)[:, 1])\n    rocauc.append(roc_auc)\n   \n    print(np.array(roc_auc).mean())","907d8f45":"#### a) Finding Oultiers Using Boxplot:  Boxplot Outliers only for Numerical Variables and not categorical","6977f064":"#### For test Data ","75fcdbd8":"#### Duplicate Rows:","2a2e1454":"### Encoding Categorical Data","df3bbfd4":"Thus there exist no such great correlation mong our variables. Great news!","4d6ef581":"### Find Mutual Information OR Information Gain","f7e855e4":"#### Both skew and kurtosis can be analyzed through descriptive statistics. Acceptable values of skewness fall between \u2212 3 and + 3, and kurtosis is appropriate from a range of \u2212 10 to + 10","eb98d075":"#### b) Finding Outliers Using Scatterplot","6b032d10":"#### Differentiating Numericala and Categorical Data for further processing","1165a1ed":"There is skewness in Avg Account Balance Column for bith train and test data.","9bdba316":"#### Combining the Numnerical and Categorical Database","5a41b2b6":"Can drop occupation and Id","a5e5f50b":"### STEP 1: Dealing with Null values","dd44282f":"No duplicate values thus are present","cc10ff0c":"#### For Train Data","c35e3b5d":"### Importing Library","20222c34":"#### Checking Predictors Co-relation With each other","41d257dd":"### Checking Skewness and Kurtosis for Numerical Columns","61031b3d":"#### Defining column names for numerical data","53d557f8":"### DATA PROCESSING","9c8c8768":"#### Checking Variable Correlation with Target Variable:","8f82ce5b":"### Modelling","446ba0f1":"### Normalinzing and Scaling","e43da0c4":"### Checking For Correlations:","21ea5d2e":"### Step 3: Handling Outliers","f8c658d7":"#### Removing Variable with Low correlation with Target Variables","2edaa891":"#### Duplicate Columns:","89a7292a":"### Step 2 : Dealing with Duplicated Values","029edb99":"#### Defining Target Variable","33f263e6":"### Loading Dataset","9d9765ff":"#### Dealing with Skewness Using Log Transformation"}}