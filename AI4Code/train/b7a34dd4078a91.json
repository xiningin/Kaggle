{"cell_type":{"d0188d87":"code","ae7e08a2":"code","bd46cf4e":"code","9ec21acb":"code","5f03429a":"code","06112560":"code","8680f502":"code","36a9911d":"code","88ca36bf":"code","dc44b312":"code","35b312f2":"code","1f65a309":"code","54a17093":"code","24532d0e":"code","fbda6d82":"code","c5aac2ef":"code","32bb9e14":"code","7cdef33a":"code","57ab8e8f":"code","a6df3cd2":"code","6eacd0da":"code","6ff65ba3":"markdown","a295acbe":"markdown","d08d6611":"markdown","43f69d50":"markdown","bf39a969":"markdown","6ea5448e":"markdown","b4ca82dc":"markdown","d399fdcd":"markdown","1c7f41e0":"markdown","a582eb1d":"markdown","40cdb956":"markdown","523ac163":"markdown"},"source":{"d0188d87":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy.spatial import distance_matrix\nfrom tqdm import tqdm_notebook\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport os\nprint(os.listdir(\"..\/input\"))\n\ndatadir = \"..\/input\/\"","ae7e08a2":"train = pd.read_csv(datadir + 'champs-scalar-coupling\/train.csv')\ntest = pd.read_csv(datadir + 'champs-scalar-coupling\/test.csv')\nstructures = pd.read_csv(datadir + 'champs-scalar-coupling\/structures.csv')","bd46cf4e":"train_bonds = pd.read_csv(datadir + 'predicting-molecular-properties-bonds\/train_bonds.csv')\ntest_bonds = pd.read_csv(datadir + 'predicting-molecular-properties-bonds\/test_bonds.csv')","9ec21acb":"train_bonds.head()","5f03429a":"angs = pd.read_csv(datadir + \"angle-and-dihedral-for-the-champs-structures\/angles.csv\")\n","06112560":"angs.head()","8680f502":"#why not standard scaler??\n#scale_min  = train['scalar_coupling_constant'].min()\n#scale_max  = train['scalar_coupling_constant'].max()\n#scale_mid = (scale_max + scale_min)\/2\n#scale_norm = scale_max - scale_mid\n\n#train['scalar_coupling_constant'] = (train['scalar_coupling_constant'] - scale_mid)\/scale_norm\ntrain['scalar_coupling_constant']=(train['scalar_coupling_constant']-train['scalar_coupling_constant'].min())\/(train['scalar_coupling_constant'].max()-train['scalar_coupling_constant'].min())\n\n# One hot encoding gets  too big for Kaggle, let's try label\n# use npz now, back to OH\ntrain[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']] =  pd.get_dummies(train['type'])\ntest[['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']]  =  pd.get_dummies(test['type'])\n\n#le = preprocessing.LabelEncoder()\n#le.fit(['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN'])\n#train['l_type'] = (le.transform(train['type']) + 1)\/8.\n#test['l_type'] = (le.transform(test['type']) + 1)\/8.","36a9911d":"train['scalar_coupling_constant'].hist()","88ca36bf":"structures[['C', 'F' ,'H', 'N', 'O']] = pd.get_dummies(structures['atom'])\n#why not standard scaler??\n#normalized_df=(df-df.min())\/(df.max()-df.min())\n#structures[['x', 'y', 'z']] = structures[['x', 'y', 'z']]\/10.\nstructures[['x', 'y', 'z']]=(structures[['x', 'y', 'z']]-structures[['x', 'y', 'z']].min())\/(structures[['x', 'y', 'z']].max()-structures[['x', 'y', 'z']].min())\nnuclear_charge = {'H':1.0, 'C':6.0, 'N':7.0, 'O':8.8, 'F':9.0}\nstructures['nuclear_charge'] = [nuclear_charge[x] for x in structures['atom'].values]\nstructures['nuclear_charge'] = structures['nuclear_charge'] \/ 9.0\n#structures['nuclear_charge']=(structures['nuclear_charge']-structures['nuclear_charge'].min())\/(structures['nuclear_charge'].max()-structures['nuclear_charge'].min())\n","dc44b312":"structures[['x', 'y', 'z']].hist()","35b312f2":"test_bonds[['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']] = pd.get_dummies(test_bonds['nbond'])#test_bonds['nbond']\/3\ntrain_bonds[['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']] = pd.get_dummies(train_bonds['nbond'])#train_bonds['nbond']\/3\n","1f65a309":"angs['dihedral'] = angs['dihedral']\/np.pi\n# Should I rather one-hot this?\nangs['shortest_path_n_bonds'] = angs['shortest_path_n_bonds']\/6.0\nangs = angs.fillna(0)","54a17093":"train_mol_names = train['molecule_name'].unique()\ntrain_mol_names, valid_mol_names = train_test_split(train_mol_names, test_size=0.2, random_state=42)\nprint(train_mol_names.shape)\nprint(valid_mol_names.shape)\n\nvalid = train.loc[train['molecule_name'].isin(valid_mol_names)]\ntrain = train.loc[train['molecule_name'].isin(train_mol_names)]\n\nvalid_bonds = train_bonds.loc[train_bonds['molecule_name'].isin(valid_mol_names)]\ntrain_bonds = train_bonds.loc[train_bonds['molecule_name'].isin(train_mol_names)]\n\nprint(train.shape)\nprint(valid.shape)\n\ntest_mol_names  = test['molecule_name'].unique()\n\ntrain_structures = structures.loc[structures['molecule_name'].isin(train_mol_names)]\nvalid_structures = structures.loc[structures['molecule_name'].isin(valid_mol_names)]\ntest_structures = structures.loc[structures['molecule_name'].isin(test_mol_names)]\n\ntrain_struct_group = train_structures.groupby('molecule_name')\nvalid_struct_group = valid_structures.groupby('molecule_name')\ntest_struct_group  = test_structures.groupby('molecule_name')\n\ntrain_group = train.groupby('molecule_name')\nvalid_group = valid.groupby('molecule_name')\ntest_group  = test.groupby('molecule_name')\n\ntrain_bond_group = train_bonds.groupby('molecule_name')\nvalid_bond_group = valid_bonds.groupby('molecule_name')\ntest_bond_group  = test_bonds.groupby('molecule_name')\n\ntrain_angs = angs.loc[angs['molecule_name'].isin(train_mol_names)]\nvalid_angs = angs.loc[angs['molecule_name'].isin(valid_mol_names)]\ntest_angs = angs.loc[angs['molecule_name'].isin(test_mol_names)]\n\ntrain_angs_group = train_angs.groupby('molecule_name')\nvalid_angs_group = valid_angs.groupby('molecule_name')\ntest_angs_group  = test_angs.groupby('molecule_name')\n\n# Find max nodes in graph:\nmax_size = train_struct_group.size().max()","24532d0e":"# Values our nodes will have\nnode_vals = ['C', 'F' ,'H', 'N', 'O','nuclear_charge'] \n#Values our edges will have (minus distance, for now)\nbond_vals = ['nbond_1', 'nbond_1.5', 'nbond_2', 'nbond_3']\nj_coup_vals = ['1JHC', '1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN']\n#j_coup_vals = ['2JHC', '2JHN','2JHH']\nang_vals = ['shortest_path_n_bonds','cosinus','dihedral']\nedge_vals = j_coup_vals + bond_vals + ang_vals\n\n# Find amount of training molecules\nn_train_mols = len(train_mol_names)\nn_valid_mols = len(valid_mol_names)\nn_test_mols = len(test_mol_names)\n\n# Find dim of edges and nodes\nbond_dim  = len(bond_vals)\nj_coup_dim= len(j_coup_vals)\nang_dim   = len(ang_vals)\nnode_dim  = len(node_vals)\nedge_dim  = len(edge_vals) \n\n# Additional edge dims for distances \nadd_edge_dim = 1\n\nprint(node_dim)\nprint(bond_dim)\nprint(ang_dim)\nprint(edge_dim)\nprint(j_coup_dim)\nprint(j_coup_vals)","fbda6d82":"train_nodes_array     = np.zeros((n_train_mols, max_size, node_dim), dtype=np.float32) \ntrain_in_edges_array  = np.zeros((n_train_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) \ntrain_out_edges_array = np.zeros((n_train_mols, max_size, max_size, 1),dtype=np.float32)\n\nvalid_nodes_array     = np.zeros((n_valid_mols, max_size, node_dim), dtype=np.float32) \nvalid_in_edges_array  = np.zeros((n_valid_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) \nvalid_out_edges_array = np.zeros((n_valid_mols, max_size, max_size, 1),dtype=np.float32)\n\ntest_nodes_array     = np.zeros((n_test_mols, max_size, node_dim), dtype=np.float32) \ntest_in_edges_array  = np.zeros((n_test_mols, max_size, max_size, edge_dim + add_edge_dim),dtype=np.float32) \nprint(len(valid_group))","c5aac2ef":"#how can we parallize this?\ndef make_arrs(val_group, struct_group, bond_group, ang_group, mode='train'):\n    debug=False\n    i = 0\n    maxit = 2\n    for values, structs, bonds, angles in tqdm_notebook(zip(val_group, struct_group, bond_group, ang_group),total=len(val_group)):\n        if i>maxit and debug: break\n        # Calculate distances\n        distances = np.zeros((max_size, max_size, add_edge_dim))\n        coords = structs[1][['x','y','z']].values\n        \n        dists  = distance_matrix(coords, coords)\n        #can we bin distances here?\n        \n        distances[:dists.shape[0],:dists.shape[1], 0] = dists\n        \n        # Create nodes\n        if debug:\n            print(structs)\n            print(structs[1])\n        mol_info = structs[1][node_vals].values\n        nodes = np.zeros((max_size, node_dim))\n        nodes[:mol_info.shape[0], :mol_info.shape[1]] = mol_info\n\n        # Create edges\n        # in_feats is type descriptos one_hot_encoded -> use it to filter on type later on\n        in_feats = np.zeros((max_size, max_size, j_coup_dim))\n        ind = values[1][['atom_index_0', 'atom_index_1' ]].values\n        in_feats[ind[:,0], ind[:,1], 0:j_coup_dim] = values[1][j_coup_vals].values\n        in_feats[ind[:,1], ind[:,0], 0:j_coup_dim] = in_feats[ind[:,0], ind[:,1], 0:j_coup_dim]\n                  \n        # Create bonds\n        in_bonds = np.zeros((max_size, max_size, bond_dim))\n        ind_bonds = bonds[1][['atom_index_0', 'atom_index_1' ]].values\n        in_bonds[ind_bonds[:,0], ind_bonds[:,1]] = bonds[1][bond_vals].values\n        in_bonds[ind_bonds[:,1], ind_bonds[:,0]] = in_bonds[ind_bonds[:,0], ind_bonds[:,1]]\n        \n        # Create angles\n        ind_angs = angles[1][['atom_index_0', 'atom_index_1' ]].values\n        ang_mat  = np.zeros((max_size, max_size, ang_dim))\n        ang_mat[ind_angs[:,0], ind_angs[:,1]]  = angles[1][ang_vals]\n        ang_mat[ind_angs[:,1], ind_angs[:,0]]  = ang_mat[ind_angs[:,0], ind_angs[:,1]]\n        \n        # concat all edge values\n        if debug:\n            print(\"edges:\")\n            print(in_feats.shape)\n            print(in_bonds.shape)\n            print(ang_mat.shape)\n            print(distances.shape)\n        in_edges = np.concatenate((in_feats, in_bonds, ang_mat, distances),axis=2)\n  \n        if not mode=='test':           \n            out_edges = np.zeros((max_size, max_size, 1))\n            \n            # set irrelevant coupling values to zero\n            idx = values[1]['type'].isin(j_coup_vals)\n            values[1]['scalar_coupling_constant'].loc[~idx] = 0.0\n            \n            out_edges[ind[:,0], ind[:,1], 0] = values[1]['scalar_coupling_constant'].values\n            out_edges[ind[:,1], ind[:,0], 0] = out_edges[ind[:,0], ind[:,1], 0]\n            if debug:\n                print(idx)\n                print(values[1])\n                print(out_edges.shape)\n                print(out_edges)\n                input()\n            if mode == 'train':\n                train_nodes_array[i]      = nodes\n                train_in_edges_array[i]   = in_edges\n                train_out_edges_array[i]  = out_edges\n                \n            if mode == 'valid':\n                valid_nodes_array[i]      = nodes\n                valid_in_edges_array[i]   = in_edges\n                valid_out_edges_array[i]  = out_edges\n        else:\n            test_nodes_array[i]      = nodes\n            test_in_edges_array[i]   = in_edges\n        i = i + 1\n","32bb9e14":"make_arrs(train_group, train_struct_group, train_bond_group, train_angs_group, mode = 'train')","7cdef33a":"#check distances\nprint(train_in_edges_array.shape)\n#distance matrix first molecule\nprint(train_in_edges_array[0,:,:,15])","57ab8e8f":"make_arrs(valid_group, valid_struct_group, valid_bond_group, valid_angs_group, mode = 'valid')","a6df3cd2":"make_arrs(test_group, test_struct_group, test_bond_group, test_angs_group, mode = 'test')","6eacd0da":"np.savez_compressed(\"train_mol_names.npz\" , train_mol_names)\nnp.savez_compressed(\"valid_mol_names.npz\" , valid_mol_names)\n\nnp.savez_compressed(\"nodes_train.npz\" , train_nodes_array)\nnp.savez_compressed(\"in_edges_train.npz\" , train_in_edges_array)\nnp.savez_compressed(\"out_edges_train.npz\" , train_out_edges_array)\n\nnp.savez_compressed(\"nodes_valid.npz\" , valid_nodes_array)\nnp.savez_compressed(\"in_edges_valid.npz\" , valid_in_edges_array)\nnp.savez_compressed(\"out_edges_valid.npz\" , valid_out_edges_array)\n\nnp.savez_compressed(\"nodes_test.npz\" , test_nodes_array)\nnp.savez_compressed(\"in_edges_test.npz\" , test_in_edges_array)","6ff65ba3":"## Reads from angles file\nTaken from: https:\/\/www.kaggle.com\/soerendip\/calculate-angles-and-dihedrals-with-networkx\n(thanks Rakete!)","a295acbe":"Forked from https:\/\/www.kaggle.com\/fnands\/makegraphinput\n\nintroducing a validation set for use in MPNN\n\n# **Graph creator**\n\nA graph is a relativly natural way of representing molecules, and many method make use of structuring the data in this way.\n\nThis kernel shows a basic example of one can structure our data as a graph.   \n\nHere we will create an array for our node values, and an adjacency matrix for our edge values. \n\n\n(**Note**: One can argue whether an adjacency matrix is really the best way to go here as we have an undirected graph, and it is therefore a bit innefficienct ( n^2 as opposed to n(n-1)\/2 ), but it is easy to work with)\n\nThis is by no means the fastest way of doing this, but it is straightforward and only has to be run once, and the output can then be used. ","d08d6611":"## Read in bonds files\nTaken from:   https:\/\/www.kaggle.com\/asauve\/dataset-with-number-of-bonds-between-atoms  \n(thanks Alexandre Sauv\u00e9!)","43f69d50":"## Define node and edge values","bf39a969":"## Process bonds","6ea5448e":"# Process angles","b4ca82dc":"## Pre-process the structures by one-hot encoding the atom types, and normalize distances to have around max of 1","d399fdcd":"## Normalize targets so they have are centered around 0 and have max of 1, and one-hot encode coupling types","1c7f41e0":"## Save as numpy arrays","a582eb1d":"## Pre-allocate arrays that we will fill later\n","40cdb956":"## Find training and testing molecules, and split structrues into test and train. Then group by molecule\n","523ac163":"## Read in train, test and structures files"}}