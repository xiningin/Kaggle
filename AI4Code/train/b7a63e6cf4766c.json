{"cell_type":{"10fb0a65":"code","7d97ff82":"code","786d2f7b":"code","b862b6a3":"code","5497f2d4":"code","d22ba997":"code","fa6e7b61":"code","e72a36a9":"code","5541eca5":"code","cd867ff2":"code","75db1e58":"markdown"},"source":{"10fb0a65":"!pip -q install youtube_dl","7d97ff82":"!pip install moviepy","786d2f7b":"from transformers import Wav2Vec2Tokenizer, Wav2Vec2ForCTC\nfrom IPython.display import Audio\nfrom IPython.display import Video\n\nimport moviepy.editor as mp\nimport torch\nimport librosa\nimport os","b862b6a3":"tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook\/wav2vec2-base-960h\")\nmodel = Wav2Vec2ForCTC.from_pretrained(\"facebook\/wav2vec2-base-960h\")","5497f2d4":"Video('..\/input\/video-file\/video.mp4')","d22ba997":"clip = mp.VideoFileClip('..\/input\/video-file\/video.mp4')\nend = 13\nend = min(clip.duration,end)\n\n# Save the paths for later\nclip_paths = []\n\n# Extract Audio-only from mp4\nfor i in range(0, int(end), 10):\n  sub_end = min(i+10, end)\n  sub_clip = clip.subclip(i,sub_end)\n\n  sub_clip.audio.write_audiofile(\"audio_\" + str(i) + \".mp3\")\n  clip_paths.append(\"audio_\" + str(i) + \".mp3\")","fa6e7b61":"Audio(clip_paths[0])","e72a36a9":"Audio(clip_paths[1])","5541eca5":"cc = \"\"\n\nfor path in clip_paths:\n    # Load the audio with the librosa library\n    input_audio, _ = librosa.load(path, \n                                sr=16000)\n\n    # Tokenize the audio\n    input_values = tokenizer(input_audio, return_tensors=\"pt\", padding=\"longest\").input_values\n\n    # Feed it through Wav2Vec & choose the most probable tokens\n    with torch.no_grad():\n      logits = model(input_values).logits\n      predicted_ids = torch.argmax(logits, dim=-1)\n\n    # Decode & add to our caption string\n    transcription = tokenizer.batch_decode(predicted_ids)[0]\n    cc += transcription + \" \"","cd867ff2":"print(cc)","75db1e58":"print(cc)"}}