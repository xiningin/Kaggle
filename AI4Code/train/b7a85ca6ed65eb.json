{"cell_type":{"25f1ebba":"code","faf878b7":"code","4a16eb8c":"code","f453040a":"code","374dea0f":"code","f54cd055":"code","851e83b0":"code","3fd10062":"code","3454bd70":"code","7ea5a2e7":"code","cdcb9cec":"code","c7908f4b":"code","6f0876db":"code","55011f63":"code","0a4041dd":"code","3e80cc7f":"code","767ed9f7":"code","fb2a2c51":"code","2272c266":"code","2223da22":"code","5500ddeb":"code","90fd7b9a":"code","109ba2e2":"code","f57c4ddd":"code","c6731bf5":"code","7e700df2":"code","a0a0566a":"code","75d0f6eb":"code","b14f7df4":"code","1d0e9adc":"code","a628d092":"code","81681712":"code","f5c65ce4":"code","40bb6986":"code","03b97d29":"code","957de91b":"code","0e816d6a":"code","c28923d3":"code","ad6d2988":"code","5cba45c7":"code","8471d62a":"code","d092ff72":"code","8479c1fb":"code","8c570940":"code","c8d826de":"code","6652251d":"code","a399f12c":"code","1ea0b934":"code","68a2db2c":"markdown","e177395c":"markdown","f0b2cafb":"markdown","68073e7e":"markdown","70c8449d":"markdown","a5994285":"markdown","6c5629d0":"markdown","5d3d583d":"markdown","1521b1a0":"markdown","988b987e":"markdown","f8c285a5":"markdown","939bb0d2":"markdown","ee77e20a":"markdown","b3145891":"markdown","38a95a8d":"markdown","aa500d35":"markdown","991e15c7":"markdown","57b5e59f":"markdown","f528c529":"markdown","f7efc8da":"markdown","1629b39a":"markdown","96aa85b1":"markdown","84bb86fc":"markdown","ea6768ef":"markdown","5adb9342":"markdown","b7784d30":"markdown","bf0ba2fe":"markdown","08a0314b":"markdown","0f7cf572":"markdown","5b9ff346":"markdown","e935ff70":"markdown","62d43183":"markdown","9c76d227":"markdown","31676f7a":"markdown","716887d6":"markdown","de076551":"markdown","e7cb8027":"markdown","50cedfc4":"markdown","82d61022":"markdown","5544d8be":"markdown"},"source":{"25f1ebba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","faf878b7":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd #To hand with data \nimport numpy as np #To math \nimport seaborn as sns #to visualization\nimport matplotlib.pyplot as plt # to plot the graphs\nimport matplotlib.gridspec as gridspec # to do the grid of plots #  gridspec work same as plt.subplots\n\ndf = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","4a16eb8c":"print(df.shape)\ndf.head(2)","f453040a":"df.info()","374dea0f":"#For now I will look the \"normal\" columns\ndf[[\"Time\",\"Amount\",\"Class\"]].describe()","f54cd055":"#Lets start looking the difference by Normal and Fraud transactions\nprint(\"Distribuition of Normal(0) and Frauds(1): \")\nprint(df[\"Class\"].value_counts())\n\nplt.figure(figsize=(7,5))\nsns.countplot(df['Class'])\nplt.title(\"Class Count\", fontsize=18)\nplt.xlabel(\"Is fraud?\", fontsize=15)\nplt.ylabel(\"Count\", fontsize=15)\nplt.show()","851e83b0":"df.Time","3fd10062":"timedelta = pd.to_timedelta(df['Time'], unit='s')\ndf['Time_min'] = (timedelta.dt.components.minutes).astype(int)\ndf['Time_hour'] = (timedelta.dt.components.hours).astype(int)","3454bd70":"#Exploring the distribuition by Class types throught hours and minutes\nplt.figure(figsize=(12,5))\nsns.distplot(df[df['Class'] == 0][\"Time_hour\"], \n             color='g')\nsns.distplot(df[df['Class'] == 1][\"Time_hour\"], \n             color='r')\nplt.title('Fraud x Normal Transactions by Hours', fontsize=17)\nplt.xlim([-1,25])\nplt.show()","7ea5a2e7":"#Exploring the distribuition by Class types throught hours and minutes\nplt.figure(figsize=(12,5))\nsns.distplot(df[df['Class'] == 0][\"Time_min\"], \n             color='g')\nsns.distplot(df[df['Class'] == 1][\"Time_min\"], \n             color='r')\nplt.title('Fraud x Normal Transactions by minutes', fontsize=17)\nplt.xlim([-1,61])\nplt.show()","cdcb9cec":"#To clearly the data of frauds and no frauds\ndf_fraud = df[df['Class'] == 1]\ndf_normal = df[df['Class'] == 0]\n\nprint(\"Fraud transaction statistics\")\nprint(df_fraud[\"Amount\"].describe())\nprint(\"\\nNormal transaction statistics\")\nprint(df_normal[\"Amount\"].describe())","c7908f4b":"#Feature engineering to a better visualization of the values\ndf['Amount_log'] = np.log(df.Amount + 0.01)","6f0876db":"plt.figure(figsize=(14,6))\n#I will explore the Amount by Class and see the distribuition of Amount transactions\nplt.subplot(121)\nax = sns.boxplot(x =\"Class\",y=\"Amount\",\n                 data=df)\nax.set_title(\"Class x Amount\", fontsize=20)\nax.set_xlabel(\"Is Fraud?\", fontsize=16)\nax.set_ylabel(\"Amount(US)\", fontsize = 16)\n\nplt.subplot(122)\nax1 = sns.boxplot(x =\"Class\",y=\"Amount_log\", data=df)\nax1.set_title(\"Class x Amount\", fontsize=20)\nax1.set_xlabel(\"Is Fraud?\", fontsize=16)\nax1.set_ylabel(\"Amount(Log)\", fontsize = 16)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.8)\n\nplt.show()","55011f63":"#Looking the Amount and time distribuition of FRAUD transactions\nax = sns.lmplot(y=\"Amount\", x=\"Time_min\", fit_reg=False,aspect=1.8,\n                data=df, hue='Class')\nplt.title(\"Amounts by Minutes of Frauds and Normal Transactions\",fontsize=16)\nplt.show()","0a4041dd":"ax = sns.lmplot(y=\"Amount\", x=\"Time_hour\", fit_reg=False,aspect=1.8,\n                data=df, hue='Class')\nplt.title(\"Amounts by Hour of Frauds and Normal Transactions\", fontsize=16)\n\nplt.show()","3e80cc7f":"#Looking the V's features\ncolumns = df.iloc[:,1:29].columns\n\nfrauds = df.Class == 1\nnormals = df.Class == 0\n\ngrid = gridspec.GridSpec(14, 2)\nplt.figure(figsize=(10,15*4))\n\nfor n, col in enumerate(df[columns]):\n    ax = plt.subplot(grid[n])\n    sns.distplot(df[col][frauds], bins = 50, color='g') #Will receive the \"semi-salmon\" violin\n    sns.distplot(df[col][normals], bins = 50, color='r') #Will receive the \"ocean\" color\n    ax.set_ylabel('Density')\n    ax.set_title(str(col))\n    ax.set_xlabel('')\nplt.show()","767ed9f7":"colormap = plt.cm.Blues\n\nplt.figure(figsize=(14,12))\n\nsns.heatmap(df.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap = colormap, linecolor='white')\nplt.show()","fb2a2c51":"#I will select the variables where fraud class have a interesting behavior and might can help us predict\n\ndf_credit = df.copy()\ndf_credit.drop(['V13','V15','V22','V23','V24','V25','V26','Time_min','Time'], axis = 1, inplace = True)","2272c266":"from sklearn import preprocessing\nse = preprocessing.StandardScaler()\ndf_credit[['Amount','Time_hour']] = se.fit_transform(df_credit[['Amount','Time_hour']])","2223da22":"df_credit","5500ddeb":"from sklearn import model_selection\ndf_train,df_test = model_selection.train_test_split(df_credit, test_size = 0.25, stratify = df_credit.Class, random_state = 42)","90fd7b9a":"print(df_train.Class.value_counts())\nprint(df_test.Class.value_counts())","109ba2e2":"len(df_train.columns[df_train.columns != 'Class'])","f57c4ddd":"import matplotlib.pyplot as plt\nimport seaborn as sns\nrows = 12\ncols = 2\nindex = 0\nfig, ax = plt.subplots(nrows=rows, ncols=cols, figsize = (10,30))\ncolumns = df_train.columns[df_train.columns != 'Class']\nfor i in  range(rows):\n    for j in range(cols):\n        sns.boxplot(df_credit.Class,columns[index], data=df_train, ax=ax[i,j])\n        index = index + 1 \n        \n        \nplt.tight_layout()   ","c6731bf5":"\nX_train = df_train.iloc[:, df_train.columns != 'Class']\ny_train = df_train.Class\nX_test = df_test.iloc[:, df_train.columns != 'Class']\ny_test = df_test.Class","7e700df2":"print(y_train.value_counts())\nprint(y_test.value_counts())\nprint(X_train.shape)\nprint(X_test.shape)","a0a0566a":"from sklearn import metrics \nfrom sklearn import linear_model \nclassifier  = linear_model.LogisticRegression()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\nprint(metrics.classification_report(y_test,y_pred))","75d0f6eb":"from sklearn.model_selection import train_test_split\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.over_sampling import ADASYN\nfrom imblearn.pipeline import Pipeline # Inorder to avoid testing model on sampled data\n\n\n# Define the resampling method\nundersample = RandomUnderSampler(random_state=0)\noversample = RandomOverSampler(random_state=0)\nsmote = SMOTE(random_state=0)\nborderlinesmote = BorderlineSMOTE(kind='borderline-2',random_state=0)\nadasyn = ADASYN(random_state=88)\n","b14f7df4":"# resample the training data\nX_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)\n\nX_under, y_under = undersample.fit_sample(X_train,y_train)\nX_over, y_over = oversample.fit_sample(X_train,y_train)\nX_smote, y_smote = smote.fit_sample(X_train,y_train)\nX_borderlinesmote, y_borderlinesmote = borderlinesmote.fit_sample(X_train,y_train)","1d0e9adc":"from sklearn import metrics\ndef  f1_positive_(y_true, y_pred):\n    matrix = confusion_matrix(y_true,y_pred)\n    recall = matrix[1,1]\/(matrix[1,1]+matrix[1,0])\n    precision = matrix[1,1]\/(matrix[1,1]+matrix[0,1])\n    f1_score_positive = 2*(precision*recall)\/(precision+recall)\n    return(f1_score_positive)\n\ndef pr_auc(y_true, probas_pred):\n    p, r, _ = metrics.precision_recall_curve(y_true, probas_pred) # here probas_pred only accepting the positive class inthe case of binary class\n   \n    return metrics.auc(r, p)\n\nf1_positive = metrics.make_scorer(f1_positive_, greater_is_better=True)\npr_auc = metrics.make_scorer(pr_auc, greater_is_better = True, needs_proba=True)\n\n\n# we can also use kappa for imbalanced dataset","a628d092":"from sklearn.metrics import roc_curve,roc_auc_score, precision_recall_curve, average_precision_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\ndef evaluation(model):\n    y_predicted = model.predict(X_test)\n    y_probs = model.predict_proba(X_test)[:,1]\n    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n    area = metrics.auc(recall, precision)\n    print(\"Precision Recall area :\", area)\n    tpr, fpr, _ = metrics.roc_curve(y_test, y_probs)\n    print(\"roc auc:\", metrics.auc(tpr, fpr))\n    \n\n    # Define a precision_recall_curve function\n    def plot_pr_curve(recall, precision, area):\n        plt.step(recall, precision, color='b', alpha=0.2, where='post')\n        plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.ylim([0.0, 1.05])\n        plt.xlim([0.0, 1.0])\n        plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(area))\n        plt.show()\n\n    # Print the classifcation report and confusion matrix\n    print('Classification report:\\n', classification_report(y_test, y_predicted))\n    print('Confusion matrix:\\n',confusion_matrix(y_true = y_test, y_pred = y_predicted))\n    plot_pr_curve(recall, precision, area)\n","81681712":"from sklearn import metrics\nmetrics.SCORERS.keys()","f5c65ce4":"from sklearn import model_selection\nkf = model_selection.StratifiedKFold(n_splits=5)","40bb6986":"from sklearn import metrics, linear_model, ensemble, tree, model_selection,svm\nimport xgboost as xgb\nmodels = {\n     'logistic_regression':linear_model.LogisticRegression(),\n    'Extra_tree_classifier':ensemble.ExtraTreesClassifier(),\n    'Decision_tree_classifier':tree.DecisionTreeClassifier(),\n    'Random_forest_classifier':ensemble.RandomForestClassifier(),\n    'Xgboost_classifier': xgb.XGBClassifier(tree_method = 'gpu_hist')\n    \n}\n    \nscores = []\nover_sampling = RandomOverSampler(random_state=0)\nfor model_names,model in models.items():\n    pipeline = Pipeline([('resampling', over_sampling), ('model', model)])\n\n    \n    val_score_base = np.mean(model_selection.cross_val_score(pipeline,X_train[:50000],y_train[:50000], cv = kf, n_jobs = -1, scoring =f1_positive))\n   \n\n    \n    \n    scores.append({\n            'model':model_names,\n            'Base': val_score_base,\n    })\n    \n    \npd.DataFrame(scores, columns=['model','Base'])","03b97d29":"from imblearn.pipeline import Pipeline \nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import ADASYN\n\nscores = []\nmodel = []\n\nxgbc = xgb.XGBClassifier(n_jobs = -1,tree_method = 'gpu_hist', random_state = 42)\n\n\n\ndata_dict = {\n    'smote':SMOTE(random_state = 0),\n    'border_line_smote': BorderlineSMOTE(kind='borderline-2',random_state=0),\n    'adasyn': ADASYN(random_state=88),\n    'undersample':RandomUnderSampler(random_state=0),\n    'oversample': RandomOverSampler(random_state=0)\n    \n}\n\nfor model_name, data_model in data_dict.items():\n    pipeline = Pipeline([('resampling', data_model), ('XGBOOST',xgbc)])\n    score =  np.mean(model_selection.cross_val_score(pipeline, X_train,y_train, cv = kf, scoring = pr_auc, n_jobs = -1))\n    scores.append(score)\n    model.append(model_name)\n    \n    \npd.DataFrame({'model_name':model,'scores':scores})    \n","957de91b":"y_test.value_counts()","0e816d6a":"def plot_learning_curve(estimator1, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    f,ax1 = plt.subplots(1,1, figsize=(10,7), sharey=True)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    # First Estimator\n    train_sizes, train_scores, test_scores = model_selection.learning_curve(\n        estimator1, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,scoring = pr_auc)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"#ff9124\")\n    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n    ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n             label=\"Training score\")\n    ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n             label=\"Cross-validation score\")\n    ax1.set_title(\"XGBoost Classifier Learning Curve\", fontsize=14)\n    ax1.set_xlabel('Training size (m)')\n    ax1.set_ylabel('Score')\n    ax1.grid(True)\n    ax1.legend(loc=\"best\")\n    ","c28923d3":"xgbc = xgb.XGBClassifier(tree_method = 'gpu_hist',random_state = 42)\nplot_learning_curve(xgbc, X_train,y_train, cv = kf)\n","ad6d2988":"import xgboost as xgb\nxgbc = xgb.XGBClassifier(tree_method = 'gpu_hist',random_state = 42)\nxgbc.fit(X_over,y_over)\nevaluation(xgbc)\n","5cba45c7":"model = xgb.XGBClassifier(n_jobs = -1,tree_method = 'gpu_hist')\noversampling = RandomOverSampler(random_state=0)\npipeline = Pipeline([('oversampling', oversampling), ('xgboost', model)])\nscore = np.mean(model_selection.cross_val_score(pipeline,X_train[:130000],y_train[:130000],cv = kf, n_jobs = -1,scoring = 'roc_auc'))\nprint(\"f1 for positive class is :\",score)\n\n\n# our goal to improve f1 for positive class ","8471d62a":"import optuna\nfrom optuna import Trial, visualization\n\nfrom optuna.samplers import TPESampler","d092ff72":"import xgboost as xgb\ndef objective(trial):\n    weights = [1,2,3,4,5,6,7,8,9, 10,15,20, 25] # using some weights to improve weights more \n   \n    param = {\n                \"n_estimators\" : trial.suggest_int('n_estimators',300, 700),\n                'max_depth':trial.suggest_int('max_depth', 8, 17),\n                'reg_alpha':trial.suggest_uniform('reg_alpha',0,10),\n                'reg_lambda':trial.suggest_uniform('reg_lambda',0,10),\n                'min_child_weight':trial.suggest_int('min_child_weight',0,6),\n                'gamma':trial.suggest_uniform('gamma', 0, 2),\n                'learning_rate':trial.suggest_loguniform('learning_rate',0.08,0.8),\n                'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.3,0.9),\n                'subsample':trial.suggest_uniform('subsample',0.4,0.9),\n#                 'scale_pos_weight':trial.suggest_categorical('scale_pos_weight',weights),\n                'nthread' : -1\n            }\n    model = xgb.XGBClassifier(**param, n_jobs = -1,tree_method = 'gpu_hist', random_state = 42)\n    oversampling = RandomOverSampler(random_state=0)\n\n    \n\n    pipeline = Pipeline([('oversampling', oversampling), ('xgboost', model)])\n    score = np.mean(model_selection.cross_val_score(pipeline,X_train[:130000],y_train[:130000],cv = kf, n_jobs = -1,scoring = pr_auc))\n    return(score)","8479c1fb":"# calling the optuna study\nstudy_ext = optuna.create_study(direction='maximize',sampler=TPESampler())\nstudy_ext.optimize(objective, n_trials= 180)","8c570940":"study_ext.best_params","c8d826de":"xgb_tuned = xgb.XGBClassifier(**study_ext.best_params,random_state = 42,tree_method = 'gpu_hist')\nxgb_tuned.fit(X_over, y_over)\nevaluation(xgb_tuned)","6652251d":"filename = '\/kaggle\/working\/xgb_tuned.sav'\npickle.dump(xgb_tuned, open(filename, 'wb'))","a399f12c":"# load the model from disk\nfilename = '\/kaggle\/working\/xgb_tuned.sav'\n\nloaded_model = pickle.load(open(filename, 'rb'))\n","1ea0b934":"evaluation(loaded_model)","68a2db2c":"* We can see a slightly difference in log amount of our two Classes.\n* The IQR of fraudulent transactions are higher than normal transactions, but normal transactions have highest values","e177395c":"* #### here we can see that the normal oversampling method outperforming other method ","f0b2cafb":"#### Drawing distribution to figure out the features ","68073e7e":"# Resampling by taking all technique","70c8449d":"#### Time_hour vs Amount Distribution","a5994285":"## Creating Cross validation Fold","6c5629d0":"### Saving the model ","5d3d583d":"### Looking the statistics of our Amount class frauds and normal transactions\nunderstanding the normal vs fraud transaction","1521b1a0":"# features selection","988b987e":"## Loading the model","f8c285a5":"### As we know before, features V1-V28 have been transformed by PCA and scaled already. Whereas feature \"Time\" and \"Amount\" have not. And considering that we will analyze these two features with other V1-V28, they should better be scaled before we train our model using various algorithms. Here is why and how.\n\n### We will first explore three columns [Time, Amount, Class] and then PCA's features ","939bb0d2":"* here minutes doesn't look meaningful","ee77e20a":"#### Looking a scatter plot of the Time_min distribuition by Amount\n","b3145891":"### Now comparing the method of oversampling","38a95a8d":"#### Time Feature","aa500d35":"#### ,V2,V3,V4,V9,V10,V11,V12,V14,V16,V17,V18,V19,V27 features have different distributions for fraud and legitimate transaction","991e15c7":"* here we can see that on our base model random_forest and extraa tree classifier working well \n* #### this is our first test on base data","57b5e59f":"1. **Borderline-SMOTE2 not only generates synthetic examples from each example in DANGER and its positive nearest neighbors in P, but also does that from its nearest negative neighbor in N.\n\n* **\n* ### Whenever we apply any kind of data tretment (resample, skewness_removal, outliers_removal) we only apply on train dataset","f528c529":"* #### we can clearly see that we dont have much outliers since all features (V1-V28) generated by PCA","f7efc8da":"## Credit Card Fraud Detection by - Abhishek Jaiswal\n## What will we learn from this notebook\n* ### Data Preprocessing \n* ### Feature Engineering , feature scaling , visualisation, PCA generated features\n* ### Feature Selection\n* ### Creating our own custom Scorer\n* ### Metrics trap in imbalanced data \n* ### Handling with  Outliers (check if our data has outliers )\n* ### Handling big data in less time \n* ### Learning Curve (understanding learning curves ) (check overfitting and underfitting )\n* ### Handling Class Imbalance with various methods\n* ### Using XGBOOSt with  GPU\n* ### Tuning XGBOOST with OPTUNA (bayesian optimised TPE sampler)\n* ### Class Weights adjustment \n* ### Saving and loading our model by pickle\n* ### Adjusting threshold according to our problem question","1629b39a":"## Now split the dataset ","96aa85b1":"# Feature Selection","84bb86fc":"## A VIsualisation function to see performance of our model ","ea6768ef":"* ## from here we have selected that we will go with random  over sample our data","5adb9342":"## checking outliers in our training dataset","b7784d30":"in our data features are generated by pca thats why they need not to be removed outliers or we dont need Robust Scaler Here ","bf0ba2fe":"### Lets make a base model to understand our objective","08a0314b":"# EDA - analysing columns","0f7cf572":"* from here we can take away that xgboost and extra tree classifier working onthis data well\n* so we will move ahead with these models\n* Data is too big so we will first try XGBOOst with the help of gpu","5b9ff346":"## Comparing the different models to choose best model base model","e935ff70":"## Custom Scoring Function according to our need","62d43183":"* higher transactions are tending to be fraud","9c76d227":"\ndoing some formalities to check if our data have any null values","31676f7a":"> # Now lets tune our model with data with XGBOOSt ","716887d6":"#### We have a clearly imbalanced data.\n#### It's very common when treating of frauds...\n\n#### First I will do some explore through the Time and Amount.\n#### Second I will explore the V's Features, that are PCA's","de076551":"### Before tuning lets first see the base model score \n","e7cb8027":"### Please, if you think that I can do something in a better way, I will be very greatful for your feedback.\n","50cedfc4":"### Learning Curve to check the performance vs Data Size","82d61022":"# Module 2: Resampling the imbalanced data\nThere are two types of resampling methods to deal with imbalanced data, one is **under sampling** and another one is **over sampling**. \n* Under sampling: you take ramdom draws from non-fraud observations to match the amount of fraud observations.  But you're randomly throwing away a lot of data and infromation. aka: Random Under Sampling\n* Over sampling: you take ramdom draws from frad cases and copy these observations to increase to amount of fraud samples in your data. But you are traning your model many many duplicates. aka: Random Over Sampling & SMOTE\n* Synthetic Minority Oversampling Technique(SMOTE): Adjust the data imbalance by oversampling the monority observations(fraud cases) using nearest neighbors of fraud cases to create new synthetic fraud cases instead of just coping the monority samples. \n* There is a common mistake when doing resampling, that is testing your model on the oversampled or undersampled dataset. If we want to implement cross validation, remember to split your data into training and testing before oversample or undersample and then just oversample or undersample the training part.   \nAnother way to avoid this is to use **\"Pipeline\"** method. ","5544d8be":"### From here we can see that if we increase the amount of data our score will increase"}}