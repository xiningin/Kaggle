{"cell_type":{"a13ce58b":"code","63157ec3":"code","246c5992":"code","c2678667":"code","27746a40":"code","2b3d3b16":"code","c61984d7":"code","8cf37e38":"markdown","0cff3788":"markdown","9bd23057":"markdown","2ad9c280":"markdown","4d2cdd02":"markdown","0f0cd950":"markdown","f4cb38ec":"markdown"},"source":{"a13ce58b":"import os\nimport torch\nimport torch.nn as nn","63157ec3":"def double_conv(in_c, out_c):\n    \n    conv= nn.Sequential(\n        nn.Conv2d(in_c, out_c, kernel_size= 3),\n        nn.ReLU(inplace= True),\n        nn.Conv2d(out_c, out_c, kernel_size= 3),\n        nn.ReLU(inplace= True)\n    )\n    return conv","246c5992":"def cropimg(start_tensor, end_tensor):\n    ssize= start_tensor.size()[2]\n    esize= end_tensor.size()[2]\n    \n    delta= ssize-esize\n    delta= delta\/\/2\n    \n    return start_tensor[:,:,delta:ssize-delta, delta:ssize-delta]","c2678667":"class UNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.maxpool_2x2 = nn.MaxPool2d(kernel_size= 2, stride= 2)\n        self.dconv1= double_conv(1,64)\n        self.dconv2= double_conv(64,128)\n        self.dconv3= double_conv(128,256)\n        self.dconv4= double_conv(256,512)\n        self.dconv5= double_conv(512,1024)\n        \n        #Now, the first up convolution is performed followed by a double convolution to alter the number of channels of feature map.\n        self.uptrans1= nn.ConvTranspose2d(\n            in_channels= 1024,\n            out_channels= 512,\n            kernel_size= 2,\n            stride= 2\n        )\n        \n        self.upconv1= double_conv(1024,512)\n        \n        self.uptrans2= nn.ConvTranspose2d(\n            in_channels= 512,\n            out_channels= 256,\n            kernel_size= 2,\n            stride= 2\n        )\n        \n        self.upconv2= double_conv(512, 256)\n        \n        self.uptrans3= nn.ConvTranspose2d(\n            in_channels= 256,\n            out_channels= 128,\n            kernel_size= 2,\n            stride= 2\n        )\n        \n        self.upconv3= double_conv(256,128)\n        \n        self.uptrans4= nn.ConvTranspose2d(\n            in_channels= 128,\n            out_channels= 64,\n            kernel_size= 2,\n            stride= 2\n        )\n        \n        self.upconv4= double_conv(128,64)\n        \n        self.out= nn.Conv2d(\n            in_channels= 64,\n            out_channels= 1,\n            kernel_size= 1\n            )\n    \n    def forward(self, image):\n        \n        #encoder\n        x1= self.dconv1(image)\n        x2= self.maxpool_2x2(x1)\n        x3= self.dconv2(x2)\n        x4= self.maxpool_2x2(x3)\n        x5= self.dconv3(x4)\n        x6= self.maxpool_2x2(x5)\n        x7= self.dconv4(x6)\n        x8= self.maxpool_2x2(x7)\n        x9= self.dconv5(x8)\n        \n        #decoder\n        x= self.uptrans1(x9)\n        y= cropimg(x7,x)\n        x= self.upconv1(torch.cat([x,y],1))\n        \n        x= self.uptrans2(x)\n        y= cropimg(x5,x)\n        x= self.upconv2(torch.cat([x,y],1))\n        \n        x= self.uptrans3(x)\n        y= cropimg(x3,x)\n        x= self.upconv3(torch.cat([x,y],1))\n        \n        x= self.uptrans4(x)\n        y= cropimg(x1,x)\n        x= self.upconv4(torch.cat([x,y],1))\n        \n        x= self.out(x)\n        print(x.size())\n        return x","27746a40":"if __name__== '__main__':\n    image= torch.rand((1,1,572,572))\n    model= UNet()\n    x= model(image)","2b3d3b16":"x= x.reshape(388,388)\nx.size()\nx= x.detach().numpy()\nimage= image.reshape(572,572)\nimage= image.detach().numpy()","c61984d7":"import matplotlib.pyplot as plt\n\nf,ax= plt.subplots(1,2, constrained_layout=True, figsize= (10,10))\n\nax[0].set_title('Input Image')\nax[0].imshow(image)\n\nax[1].set_title('Output Image')\nax[1].imshow(x)","8cf37e38":"In the UNet paper, while building the decoder part of UNet, the **N**th level feature map of decoder is concatenated with the corresponding level feature map from encoder side. Since the feature map on encoder side is consistently larger than the corresponding level feature map on decoder size, we define a crop image function to crop the encoder feature map.","0cff3788":"### This is the crux of the whole code...Cover all the bases and get charged!!\nAt this step, the basic UNet model is defined. Encoder and Decoder parts are defined using Down Convolution and UpConvolution. ","9bd23057":"## Hey guys!!\n\n### I got really captivated the way GM Abhishek Thakur developed the UNet architecture in [this](https:\/\/www.youtube.com\/watch?v=u1loyDCoGbE) video and thus I also tried to follow and implement the same.\n\n### I have explained the steps in between for better understanding and have concluded with an example.\n\n### Paper can be found [here](https:\/\/arxiv.org\/pdf\/1505.04597.pdf)","2ad9c280":"### We can conclude that the output image has reduced noice and thus is more clear.","4d2cdd02":"For plotting the images, we now convert the tensors into numpy arrays for matplot to work","0f0cd950":"### Doing the dishes now...","f4cb38ec":"Double Conv function is used to perform Two-stepped convolution at once. It is merely a two convolutional layer network taking the input in form of Number of Channels and gives away the modified channelled image."}}