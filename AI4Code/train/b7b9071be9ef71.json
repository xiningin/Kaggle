{"cell_type":{"4116bc22":"code","a839bb6f":"code","9d35789f":"code","f648ca13":"code","f072aa58":"code","8bebdbf7":"code","6f82b06a":"code","71db9bbe":"code","8670f35a":"code","9bee528c":"code","9f7324fd":"code","4deb137e":"code","f0f993e0":"code","85fcb54c":"code","cb2d944e":"markdown"},"source":{"4116bc22":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n#from keras_tuner import RandomSearch\n#from keras_tuner.engine.hyperparameters import HyperParameters\nimport matplotlib.pyplot as plt","a839bb6f":"trainData = pd.read_csv('..\/input\/assignment4new\/train.csv')\ntestData = pd.read_csv('..\/input\/assignment4new\/eval.csv')","9d35789f":"X = trainData.drop(['label','id'], axis=1)\ny = trainData['label']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)","f648ca13":"#print(X_train.shape)\n#print(X_test.shape)","f072aa58":"#X_train = X_train.values.reshape(48000,28,28)\n#X_test = X_test.values.reshape(12000,28,28)\n#X_train.shape","8bebdbf7":"#plt.gray()\n#plt.imshow(X_train[1])\n","6f82b06a":"X_train = X_train.values.reshape(42000,28,28,1)\nX_test = X_test.values.reshape(18000,28,28,1)","71db9bbe":"#X_train = X_train \/ 255\n#X_test = X_test \/ 255\n#y_train = y_train.to_numpy()\n#y_train.shape\n#y_train","8670f35a":"model = Sequential()\n\nmodel.add(Conv2D(32, (3,3), input_shape = (28,28,1), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.35))\n\nmodel.add(Conv2D(64, (3,3), padding = 'same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.35))\n\nmodel.add(Conv2D(128, (3,3), padding = 'same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.35))\n\nmodel.add(Conv2D(256, (3,3), padding = 'same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.35))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1024, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(10, activation = 'softmax'))","9bee528c":"checkpoint = ModelCheckpoint('test_model5.h5', monitor='val_accuracy', save_best_only = True)","9f7324fd":"model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) \nhistory = model.fit(X_train, y_train, epochs = 150, validation_data=(X_test, y_test), callbacks=[checkpoint], batch_size = 80) #increase batch size and see if it works","4deb137e":"testDataShaped = testData.drop(['id'], axis=1).values.reshape(10000,28,28,1)\n\nmodel.load_weights('.\/test_model5.h5')\n\nprint(model.evaluate(X_test, y_test))\n\nmodelPreds = model.predict(testDataShaped, verbose=0)\nmodelPreds.shape","f0f993e0":"labels = [np.argmax(x) for x in modelPreds]\noutput = pd.DataFrame({\n    'id': testData['id'],\n    'label': labels\n})","85fcb54c":"output.to_csv('94.csv', index=False)\nprint(output.to_string())","cb2d944e":"# Assignment 4\n* Julian Boaz\n* CAP4611\n* Due 11\/21\/2021\n---"}}