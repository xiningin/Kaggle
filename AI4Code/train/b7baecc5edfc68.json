{"cell_type":{"f90ef66e":"code","c9caabbf":"code","f8cfc1b7":"code","e5cadcf9":"code","d26debc3":"code","223f531e":"code","cf6812c0":"code","facafbd3":"code","3c8eaa4b":"code","1e4b4437":"code","cc3060bb":"code","b07703ab":"code","c4124203":"code","bad46f2a":"code","d6b254ce":"code","223f16f3":"code","21cc3ebb":"code","673bfbf7":"code","9465507c":"code","ebd1934e":"code","05cb4c06":"code","7b21351a":"code","2ee1bf67":"code","c148ac73":"code","3ab5bad8":"code","5bc577df":"code","cd85ace1":"code","3d253531":"code","8dce75f2":"code","3f3e90ab":"code","72804419":"code","17d40560":"code","aefc8553":"code","a7f33edd":"code","4051ea23":"code","2dbd7c14":"code","aefca84f":"code","f55e3b90":"code","54d28dfd":"code","87bb9b5e":"code","0058a578":"code","73650677":"code","50e54176":"code","ec3f1ca5":"code","5272ae36":"code","71196728":"code","8087440b":"code","821c057f":"markdown","9c95e6d4":"markdown","13bc7dfd":"markdown","879039f7":"markdown","3e8ebf01":"markdown","e5a1d87e":"markdown","e94be3b2":"markdown","11c54dc3":"markdown","ba46b8ea":"markdown","ecdaa677":"markdown","551f85e4":"markdown","875121f9":"markdown","a7efeefa":"markdown","84b30524":"markdown","fd8bdfbd":"markdown","d279c277":"markdown","c5162e59":"markdown"},"source":{"f90ef66e":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport matplotlib.pyplot as plt","c9caabbf":"train_adult = pd.read_csv(\"\/kaggle\/input\/adult-data-5\/train_data.csv\" ,names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\ntest_adult =  pd.read_csv(\"\/kaggle\/input\/adult-data-5\/test_data.csv\" ,names=[\n        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital Status\",\n        \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital Gain\", \"Capital Loss\",\n        \"Hours per week\", \"Country\", \"Target\"],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")","f8cfc1b7":"train_adult.shape","e5cadcf9":"test_adult.shape","d26debc3":"train_adult.head()","223f531e":"train_adult[\"Education\"].value_counts()","cf6812c0":"train_adult[\"Relationship\"].value_counts().plot(kind=\"bar\")","facafbd3":"ntrain = train_adult.dropna()\nntrain","3c8eaa4b":"ntest = test_adult.dropna()\nntest","1e4b4437":"xtrain = ntrain[[\"Age\",\"Education-Num\",\"Capital Gain\", \"Capital Loss\", \"Hours per week\"]]\nytrain = ntrain.Target","cc3060bb":"xtest = ntest[[\"Age\",\"Education-Num\",\"Capital Gain\", \"Capital Loss\", \"Hours per week\"]]\nytest = ntest.Target","b07703ab":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nytrain = le.fit_transform(ytrain)","c4124203":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","bad46f2a":"rf = RandomForestClassifier(n_estimators = 800)","d6b254ce":"%%time\nrf.fit(xtrain, ytrain)","223f16f3":"%%time\nscores = cross_val_score(rf, xtrain, ytrain, cv=6)\nprint(scores)","21cc3ebb":"rf = RandomForestClassifier(n_estimators = 80)","673bfbf7":"%%time\nrf.fit(xtrain, ytrain);","9465507c":"%%time\nscores = cross_val_score(rf, xtrain, ytrain, cv=8)\nprint(scores)","ebd1934e":"numtrain = ntrain.apply(preprocessing.LabelEncoder().fit_transform)\nnumtest = ntest.apply(preprocessing.LabelEncoder().fit_transform)","05cb4c06":"Xtrain = numtrain.iloc[:,0:14]\nXtest = numtest.iloc[:,0:14]","7b21351a":"Ytrain = numtrain.Target\nYtest = numtest.Target","2ee1bf67":"%%time\nrf.fit(Xtrain, Ytrain)\nYtestPred = rf.predict(Xtest);","c148ac73":"print(confusion_matrix(Ytest,YtestPred))","3ab5bad8":"accuracy_score(Ytest, YtestPred)","5bc577df":"print(classification_report(Ytest, YtestPred))","cd85ace1":"from sklearn.svm import SVC","3d253531":"svc = SVC(gamma='auto', cache_size=7000)  # cache_size=7000 decreases execution time","8dce75f2":"%%time\nsvc.fit(xtrain, ytrain)","3f3e90ab":"%%time\nscores = cross_val_score(svc, xtrain, ytrain, cv=5, n_jobs=3)\nprint(scores)","72804419":"from sklearn.decomposition import PCA\n# Make an instance of the Model\npca = PCA(.95)  # chooses the minimum number of principal components such that 95% of the variance is retained.","17d40560":"pca.fit(Xtrain)","aefc8553":"Newtrain = pca.transform(Xtrain)\nNewtest = pca.transform(Xtest)","a7f33edd":"%%time\nsvc.fit(Newtrain, Ytrain)","4051ea23":"%%time\nscores = cross_val_score(svc, Newtrain, Ytrain, cv=5, n_jobs=3)\nprint(scores)","2dbd7c14":"%%time\nYtestPred = svc.predict(Newtest)","aefca84f":"print(confusion_matrix(Ytest,YtestPred))","f55e3b90":"accuracy_score(Ytest, YtestPred)","54d28dfd":"print(classification_report(Ytest, YtestPred))","87bb9b5e":"from sklearn.naive_bayes import GaussianNB","0058a578":"nb = GaussianNB()","73650677":"%%time\nnb.fit(xtrain, ytrain)","50e54176":"%%time\nscores = cross_val_score(nb, xtrain, ytrain, cv=10)\nprint(scores)","ec3f1ca5":"%%time\nnb.fit(Xtrain, Ytrain)\nYtestPred = nb.predict(Xtest);","5272ae36":"print(confusion_matrix(Ytest,YtestPred))","71196728":"accuracy_score(Ytest, YtestPred)","8087440b":"print(classification_report(Ytest, YtestPred))","821c057f":"## PMR3508 - Aprendizado de M\u00e1quina e Reconhecimento de Padr\u00f5es - Tarefa 2\n\nTestando 3 m\u00e9todos de classifica\u00e7\u00e3o com a base adult obtida no UCI repository. Iniciando com carregamento da base e com an\u00e1lise b\u00e1sica da base e dos atributos.\n\n__Importar bibliotecas__","9c95e6d4":"__Teste com todos dados__","13bc7dfd":"__Iniciando o modelo com 800 \u00e1rvores e treinando__","879039f7":"__Transformando labels n\u00e3o num\u00e9ricas em num\u00e9ricas__","3e8ebf01":"__Remover dados faltantes__","e5a1d87e":"__Passando todos os dados n\u00e3o-num\u00e9ricos para valores num\u00e9ricos, e fazendo alguns testes com v\u00e1rios conjuntos de atributos__\n<br>Pode-se perceber que os resultados para 80 e 800 \u00e1rvores foram muito pr\u00f3ximos, sendo assim seguimos com 80 \u00e1rvores pela velocidade e custo computacional.","e94be3b2":"<div class=\"alert alert-block alert-info\">\n    <b>Support Vector Machines (SVMs)<\/b>\n<\/div>","11c54dc3":"__Bases de treino e teste Adult__","ba46b8ea":"O primeiro m\u00e9todo testado foi o __Random Forests__, o qual apresentou acur\u00e1cia de 84%. \u00c9 um pouco demorado para treinar e percebeu-se mudando o n\u00famero de \u00e1rvores de 800 para 80 que isso pouco afeta os scores, por\u00e9m diminui consideravelmente o tempo de execu\u00e7\u00e3o do algoritmo.\n\nO segundo m\u00e9todo empregado foi __Support Vector Machines(SVMs)__, que exprimiu acur\u00e1cia de 70%. \u00c9 o mais demorado para treinar, tornando seu uso n\u00e3o aconselh\u00e1vel para o caso. A valida\u00e7\u00e3o cruzada foi feita com 5 camadas para diminuir o tempo de execu\u00e7\u00e3o, mas ainda continua alto. Foi aplicado o PCA(Principal Component Analysis) para redu\u00e7\u00e3o do tempo, por\u00e9m resultou em uma diminui\u00e7\u00e3o da acur\u00e1cia. \n\nO Terceiro m\u00e9todo utilizado foi __Naive Bayes__, cuja acur\u00e1cia foi de 81%. Sua execu\u00e7\u00e3o foi muito mais r\u00e1pida que os anteriores, sendo um m\u00e9todo relativamente acurado e muito eficiente.","ecdaa677":"__Primeiro teste com atributos num\u00e9ricos__","551f85e4":"<div class=\"alert alert-block alert-info\">\n    <b>Naive Bayes<\/b>\n<\/div>","875121f9":"<div class=\"alert alert-block alert-success\">\n    <b>Coment\u00e1rios<\/b>\n<\/div>","a7efeefa":"__Separando atributos num\u00e9ricos para primeiro teste__ ","84b30524":"__Primeiro teste com atributos num\u00e9ricos__","fd8bdfbd":"__Testando modelo com 80 \u00e1rvores e treinando__","d279c277":"<div class=\"alert alert-block alert-info\">\n    <b>Random Forests<\/b>\n<\/div>","c5162e59":"__Teste com todos dados__"}}