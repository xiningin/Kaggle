{"cell_type":{"ffe2fe60":"code","3483cb87":"code","00ff0380":"code","ae8316ed":"code","46aee604":"code","f3ce77c0":"code","fa511486":"code","caf6d830":"code","d6d79e00":"code","11e5ca55":"code","0931cfc7":"code","c1a93d38":"code","4e1e7a47":"code","1df8285a":"code","d78b079e":"markdown","92dc771d":"markdown","70a98520":"markdown","48fbd34d":"markdown","36ee1536":"markdown","55d70a18":"markdown","3f5d8163":"markdown"},"source":{"ffe2fe60":"%matplotlib inline\nimport os\nimport sys\nimport cv2\nimport numpy as np\nimport torch\nimport torch.utils.data as data\nfrom torch.autograd import Variable\nimport torch.nn as nn\nfrom torchvision import datasets, transforms\nfrom glob import glob\nimport pandas as pd\nimport matplotlib.pyplot as plt","3483cb87":"TEST_SPLIT = 0.25\nepochs = 10\nbatch_size = 64\nMICRO_DATA = False # very small subset (just 3 groups)\nSAMPLE_TRAINING = False # make train set smaller for faster iteration\nIMG_SIZE = (224, 224)\nLEARNING_RATE = 4e-3\nuse_gpu = True","00ff0380":"device = torch.device(\"cuda\" if use_gpu else \"cpu\")\ntorch.manual_seed(42) # try and make the results more reproducible\nBASE_PATH = os.path.join('..', 'input')","ae8316ed":"all_img_df = pd.DataFrame({'path':\n                           glob(os.path.join(BASE_PATH, 'images', '*', '*.jpg'))})\nall_img_df['category'] = all_img_df['path'].map(lambda x: \n                                                os.path.split(os.path.dirname(x))[-1].replace('_', ' '))\nif MICRO_DATA:\n    all_img_df = all_img_df[all_img_df['category'].isin(['samosa', 'gnocchi', 'hot dog'])]","46aee604":"from sklearn.preprocessing import LabelEncoder\ncat_enc = LabelEncoder()\nall_img_df['cat_idx'] = cat_enc.fit_transform(all_img_df['category'])\nN_CLASSES = len(cat_enc.classes_)\nprint(N_CLASSES, 'classes')\nall_img_df.sample(5)","f3ce77c0":"class DataWrapper(data.Dataset):\n    ''' Data wrapper for pytorch's data loader function '''\n    def __init__(self, image_df, resize):\n        self.dataset = image_df\n        self.resize = resize\n\n    def __getitem__(self, index):\n        c_row = self.dataset.iloc[index]\n        image_path, target = c_row['path'], c_row['cat_idx']  #image and target\n        #read as rgb image, resize and convert to range 0 to 1\n        image = cv2.imread(image_path, 1)\n        if self.resize:\n            image = cv2.resize(image, IMG_SIZE)\/255.0 \n        else:\n            image = image\/255.0\n        image = (torch.from_numpy(image.transpose(2,0,1))).float() #NxCxHxW\n        return image, int(target)\n\n    def __len__(self):\n        return self.dataset.shape[0] ","fa511486":"from sklearn.model_selection import train_test_split\ntrain_df, test_df = train_test_split(all_img_df, \n                                     test_size=TEST_SPLIT, \n                                     random_state=42,\n                                     stratify=all_img_df['category'])\n\nif SAMPLE_TRAINING: # make train smaller for faster testing\n    train_df = train_df.\\\n        groupby('category').\\\n        apply(lambda x: x.sample(50)).\\\n        reset_index(drop=True).\\\n        sample(frac=1).\\\n        reset_index(drop=True)\nprint('train', train_df.shape[0], 'test', test_df.shape[0])","caf6d830":"train_dataset = DataWrapper(train_df, True)\ntrain_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True, \n            batch_size=batch_size, pin_memory=False)#, num_workers=4)\n\ntest_dataset = DataWrapper(test_df, True)\ntest_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True, \n            batch_size=batch_size, pin_memory=False) #num_workers=1)","d6d79e00":"class ConvBnReLu(nn.Module):\n    '''Repetitive block of conv->batch norm->relu'''\n    def __init__(self,in_planes,out_planes,drop=0.0,kernel=3,padding=1,stride=1):\n        super(ConvBnReLu, self).__init__()\n        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=3, \n                                          stride=stride, padding=1)\n        self.bn = nn.BatchNorm2d(out_planes)\n        self.relu = nn.ReLU()\n        self.drop = nn.Dropout(p=drop)\n\n    def forward(self,x):\n        x = self.conv(x)\n        x = self.bn(x)\n        return self.drop(self.relu(x))\n    \n\ndef conv3x3(in_planes, out_planes, stride=1):\n    '''Simple 3x3 convolution'''\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, \n                              stride=stride, padding=1)\n\nclass VGGNet(nn.Module):\n    def __init__(self,num_feat=16,num_class=N_CLASSES):\n        \"\"\"Define the components of a VGG 11 model\"\"\"\n        super(VGGNet, self).__init__()     \n        self.num_feat = num_feat\n        self.conv_1 = conv3x3(3,num_feat)\n        self.conv_2 = conv3x3(num_feat,2*num_feat)\n        self.conv_3_1 = conv3x3(2*num_feat,4*num_feat)\n        self.conv_3_2 = conv3x3(4*num_feat,4*num_feat)\n        self.conv_4_1 = conv3x3(4*num_feat,8*num_feat)\n        self.conv_4_2 = conv3x3(8*num_feat,8*num_feat)\n        self.conv_5_1 = conv3x3(8*num_feat,8*num_feat)\n        self.conv_5_2 = conv3x3(8*num_feat,2*num_feat)\n\n        self.fc1 = nn.Linear((2*num_feat)*7*7,512)\n        self.fc2 = nn.Linear(512,256)\n        self.pred = nn.Linear(256,num_class)\n\n        self.relu = nn.ReLU(inplace=True)\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self,x):\n        \"\"\"Input x is expected to be a 4d tensor (N x C X H x W)\n           N - Number of images in minibatch\n           C - Number of channels\n           H,W  - Height and Width of image, respectively \"\"\"\n\n        conv_1 = self.conv_1(x)\n        relu_1 = self.relu(conv_1)\n        pool_1 = self.max_pool(relu_1)\n\n        conv_2 = self.conv_2(pool_1)\n        relu_2 = self.relu(conv_2)\n        pool_2 = self.max_pool(relu_2)\n\n        conv_3_1 = self.conv_3_1(pool_2)\n        relu_3_1 = self.relu(conv_3_1)\n        conv_3_2 = self.conv_3_2(relu_3_1)\n        relu_3_2 = self.relu(conv_3_2)\n        pool_3 = self.max_pool(relu_3_2)\n\n        conv_4_1 = self.conv_4_1(pool_3)\n        relu_4_1 = self.relu(conv_4_1)\n        conv_4_2 = self.conv_4_2(relu_4_1)\n        relu_4_2 = self.relu(conv_4_2)\n        pool_4 = self.max_pool(relu_4_2)\n\n        conv_5_1 = self.conv_5_1(pool_4)\n        relu_5_1 = self.relu(conv_5_1)\n        conv_5_2 = self.conv_5_2(relu_5_1)\n        relu_5_2 = self.relu(conv_5_2)\n        pool_5 = self.max_pool(relu_5_2)\n\n        fc1 = self.relu(self.fc1(pool_5.view(-1,(2*self.num_feat)*7*7)))\n        fc2 = self.relu(self.fc2(fc1))\n\n        return self.pred(fc2)","11e5ca55":"model = VGGNet().to(device) #VGG style model\ncriterion = nn.CrossEntropyLoss() #Use cross entropy loss","0931cfc7":"optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)","c1a93d38":"# nice wait bars\nfrom tqdm import tqdm_notebook, tnrange","4e1e7a47":"from collections import defaultdict\nfrom IPython.display import clear_output, display\ntrain_results = defaultdict(list)\ntrain_iter, test_iter, best_acc = 0,0,0\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize = (10, 10))\nax1.set_title('Train Loss')\nax2.set_title('Train Accuracy')\nax3.set_title('Test Loss')\nax4.set_title('Test Accuracy')\n\nfor i in tnrange(epochs, desc='Epochs'):\n    clear_output(wait=True)\n    display(fig)\n    print(\"Epoch \",i)\n    ## Train Phase\n    #Model switches to train phase\n    model.train() \n    \n    # Running through all mini batches in the dataset\n    count, loss_val, correct, total = train_iter, 0, 0, 0\n    for data, target in tqdm_notebook(train_loader, desc='Training'):    \n        if use_gpu: #Using GPU & Cuda\n            data, target = data.to(device), target.to(device)\n\n        output = model(data) #FWD prop\n        loss = criterion(output, target) #Cross entropy loss\n        c_loss = loss.data.item()\n        ax1.plot(count, c_loss, 'r.')\n        loss_val += c_loss\n\n        optimizer.zero_grad() #Zero out any cached gradients\n        loss.backward() #Backward pass\n        optimizer.step() #Update the weights\n\n        #Compute accuracy\n        predicted = output.data.max(1)[1] #get index of max\n        total += target.size(0) #total samples in mini batch\n        c_acc = (predicted == target).sum().item()\n        ax2.plot(count, c_acc\/target.size(0), 'r.')\n        correct += c_acc\n        count +=1\n    train_loss_val, train_iter, train_acc = loss_val\/len(train_loader.dataset), count, correct\/float(total)\n    \n    print(\"Training loss: \", train_loss_val, \" train acc: \",train_acc)    \n    ## Test Phase\n    \n    #Model switches to test phase\n    model.eval()\n\n    #Running through all mini batches in the dataset\n    count, correct, total, lost_val = test_iter, 0, 0, 0\n    for data, target in tqdm_notebook(test_loader, desc='Testing'):\n        if use_gpu: #Using GPU & Cuda\n            data, target = data.to(device), target.to(device)\n        output = model(data)\n        loss = criterion(output, target) #Cross entropy loss\n        c_loss = loss.data.item()\n        ax3.plot(count, c_loss, 'b.')\n        loss_val += c_loss\n        #Compute accuracy\n        predicted = output.data.max(1)[1] #get index of max\n        total += target.size(0) #total samples in mini batch\n        c_acc = (predicted == target).sum().item()\n        ax4.plot(count, c_acc\/target.size(0), 'b.')\n        correct += c_acc\n        count += 1\n\n    #Accuracy over entire dataset\n    test_acc, test_iter, test_loss_val = correct\/float(total), count, loss_val\/len(test_loader.dataset)\n    print(\"Epoch: \",i,\" test set accuracy: \",test_acc)\n    \n    train_results['epoch'].append(i)\n    train_results['train_loss'].append(train_loss_val)\n    train_results['train_acc'].append(train_acc)\n    train_results['train_iter'].append(train_iter)\n    \n    train_results['test_loss'].append(test_loss_val)\n    train_results['test_acc'].append(test_acc)\n    train_results['test_iter'].append(test_iter)\n    \n    #Save model with best accuracy\n    if test_acc > best_acc:\n        best_acc = test_acc\n        torch.save(model.state_dict(), 'best_model.pth') \nplt.show()\nfig.savefig('train.png')","1df8285a":"train_results_df = pd.DataFrame(train_results)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\ntrain_results_df.plot('epoch', ['train_loss', 'test_loss'], ax=ax1)\nax1.set_title('Loss')\ntrain_results_df.plot('epoch', ['train_acc', 'test_acc'], ax=ax2)\nax2.set_title('Accuracy')\nfig.savefig('epochs.png')","d78b079e":"# Build and Train","92dc771d":"## Parameters\nTry to keep the model parameters and configurations all in one cell to make it easier to keep track of (and automate later)","70a98520":"## Split data into a train\/test group\nWe can also shrink the size of the training group to make it quicker","48fbd34d":"# Train for given number of epochs","36ee1536":"# Data Loading Classes\nHere are the classes to load the data","55d70a18":"## Create Dataset\nHere we find all of the files and organize them into categories","3f5d8163":"# Build the VGG Model"}}