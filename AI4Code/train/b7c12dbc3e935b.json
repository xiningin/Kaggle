{"cell_type":{"37650bce":"code","8cf54aed":"code","8ed92778":"code","a83eea88":"code","8aad1134":"code","9504f6b2":"code","bf7fc497":"code","bef059a9":"code","f4f3ccc1":"code","bb865db1":"code","9ea740f8":"code","9e843402":"code","7bdb6c5f":"code","b4a6193c":"code","3e1d01fd":"code","88b4bf11":"code","53ead6bf":"code","65d2b21b":"code","f3d5fd1f":"code","5b105dbe":"code","d8c229b2":"code","425aafce":"code","27522bf7":"code","cb65e7c2":"code","a331b343":"code","21f315f5":"code","10343519":"code","fafc0255":"code","5f507bcb":"code","01a56bc3":"code","5f866ad9":"code","e624502a":"code","c59872d2":"code","4edc252d":"code","81fedaad":"markdown","c4df3ec9":"markdown","8f0927e7":"markdown","1582c04e":"markdown","3c48c8f6":"markdown","8ca321dc":"markdown","2c72b36e":"markdown","73e5e746":"markdown"},"source":{"37650bce":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport os\nimport re\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nfrom tqdm import tqdm\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import backend as k\nfrom keras.utils import to_categorical\nimport transformers","8cf54aed":"DEVICE = 'TPU'","8ed92778":"if DEVICE == 'TPU':\n    print('Connecting to TPU...')\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU :',tpu.master())\n    except ValueError:\n        print('Could not connect to TPU')\n        tpu = None\n        \n    if tpu:\n        try:\n            print('Initializing TPU...')\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print('TPU initialized!')\n            \n        except _:\n            print('Failed to initialized TPU')\n            \n    else:\n        DEVICE='GPU'\n\nif DEVICE != 'TPU':\n    print('Using default strategy for CPU and single GPU')\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == 'GPU':\n    print('Num GPUs available : ',len(tf.config.experimental.list_physical_devices('GPU')))\n    \nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint('REPLICAS : ',REPLICAS)","a83eea88":"Batch_size = 16 * strategy.num_replicas_in_sync\nepochs = 13\nAUTO = tf.data.experimental.AUTOTUNE\n\nMODEL = 'jplu\/tf-xlm-roberta-large'","8aad1134":"train = pd.read_csv(r'..\/input\/contradictory-my-dear-watson\/train.csv')\ntest = pd.read_csv(r'..\/input\/contradictory-my-dear-watson\/test.csv')\nsubmission = pd.read_csv(r'..\/input\/contradictory-my-dear-watson\/sample_submission.csv')","9504f6b2":"train.head()","bf7fc497":"test.head()","bef059a9":"num_lang = train.groupby('language')['id'].count().sort_values(ascending=False).reset_index()\nnum_lang = pd.DataFrame(num_lang)\nnum_lang['count'] = num_lang['id']\nnum_lang = num_lang.drop('id',axis=1)\nnum_lang_data = num_lang.style.background_gradient(cmap='Greens')\nnum_lang_data","f4f3ccc1":"test_num_lang = test.groupby('language')['id'].count().sort_values(ascending=False).reset_index()\ntest_num_lang = pd.DataFrame(test_num_lang)\ntest_num_lang['count'] = test_num_lang['id']\ntest_num_lang = test_num_lang.drop('id',axis=1)\ntest_num_lang_data = test_num_lang.style.background_gradient(cmap='Oranges')\ntest_num_lang_data","bb865db1":"fig = px.pie(num_lang,values='count',names='language',title='Language and their percentage in the train data :',color_discrete_sequence=px.colors.sequential.GnBu)\nfig.update_traces(hoverinfo='label+percent', textfont_size=14,\n                  marker=dict(line=dict(color='#000000', width=1.2)))\nfig.show()\n\nfig = px.pie(test_num_lang,values='count',names='language',title='Language and their percentage in the test data :',color_discrete_sequence=px.colors.sequential.RdBu)\nfig.update_traces(hoverinfo='label+percent', textfont_size=14,\n                  marker=dict(line=dict(color='#000000', width=1.2)))\nfig.show()","9ea740f8":"fig = px.bar(num_lang,x='language',y='count')\nfig.update_traces(marker_color='ivory', marker_line_color='black',\n                  marker_line_width=1.3, opacity=0.5)\nfig.update_layout(title_text='Languages and their count in the data')\nfig.show()\n\nfig = px.bar(test_num_lang,x='language',y='count')\nfig.update_traces(marker_color='darkturquoise', marker_line_color='black',\n                  marker_line_width=1.3, opacity=0.5)\nfig.update_layout(title_text='Languages and their count in the data')\nfig.show()","9e843402":"num_words_train_h = [None] * len(train)\nfor i in range(len(train)):\n    num_words_train_h[i] = len(train['hypothesis'][i])\nnum_words_train_p = [None] * len(train)\nfor i in range(len(train)):\n    num_words_train_p[i] = len(train['premise'][i])\n    \nnum_words_test_h = [None] * len(test)\nfor i in range(len(test)):\n    num_words_test_h[i] = len(test['hypothesis'][i])\nnum_words_test_p = [None] * len(test)\nfor i in range(len(test)):\n    num_words_test_p[i] = len(test['premise'][i])","7bdb6c5f":"print('Maximum and minimum number of words in a single sentence in hypothesis in the train data :',(max(num_words_train_h),min(num_words_train_h)))\nprint('Maximum and minimum number of words in a single sentence in hypothesis in the test data :',(max(num_words_test_h),min(num_words_test_h)))\nprint('Maximum and minimum number of words in a single sentence in premise in the train data :',(max(num_words_train_p),min(num_words_train_p)))\nprint('Maximum and minimum number of words in a single sentence in premise in the test data :',(max(num_words_test_p),min(num_words_test_p)))","b4a6193c":"train['num_words_hypothesis'] = num_words_train_h\ntrain['num_words_premise'] = num_words_train_p\ntest['num_words_hypothesis'] = num_words_test_h\ntest['num_words_premise'] = num_words_test_p","3e1d01fd":"english_train = train[train['language']=='English']\nenglish_test = test[test['language']=='English']\n\n\nhist_data = [english_train['num_words_hypothesis'],english_train['num_words_premise']]\ngroup_labels = ['hypothesis','premise']\nfig = ff.create_distplot(hist_data,group_labels,colors=['ivory','teal'])\nfig.update_layout(title_text='Number of words for English Language in train data')\nfig.show()\n\nhist_data = [english_test['num_words_hypothesis'],english_test['num_words_premise']]\ngroup_labels = ['hypothesis','premise']\nfig = ff.create_distplot(hist_data,group_labels,colors=['red','greenyellow'])\nfig.update_layout(title_text='Number of words for English Language in test data')\nfig.show()","88b4bf11":"labels = train['label'].sort_values().value_counts().reset_index()\nlabels = pd.DataFrame(labels)\nlabels.columns = ['label','count']\nlabels_ = labels.style.background_gradient(cmap='Blues')\nlabels_","53ead6bf":"target = train['label']\ntrain = train.drop('label',axis=1)\ntrain_text = [None] * len(train)\ntest_text = [None] * len(test)\nfor i in range(len(train)):\n    train_text[i] = train['premise'][i] + ' ' + train['hypothesis'][i]\nfor i in range(len(test)):\n    test_text[i] = test['premise'][i] + ' ' + test['hypothesis'][i]","65d2b21b":"tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL)","f3d5fd1f":"def roberta_encode(texts, maxlen=512):\n    enc_di = tokenizer.batch_encode_plus(\n        texts,  \n        pad_to_max_length=True,\n        max_length=maxlen\n    )\n    \n    return np.array(enc_di['input_ids'])","5b105dbe":"train_input_ids = roberta_encode(train_text,maxlen=100)\ntest_input_ids = roberta_encode(test_text,maxlen=100)","d8c229b2":"from sklearn.model_selection import train_test_split\ntrain_input_ids,validation_input_ids,train_labels,validation_labels = train_test_split(train_input_ids,target,test_size=0.2)","425aafce":"train_input_ids[7]","27522bf7":"validation_input_ids[1]","cb65e7c2":"test_input_ids[3]","a331b343":"validation_labels","21f315f5":"train_labels","10343519":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_input_ids,train_labels))\n    .repeat()\n    .shuffle(2048)\n    .batch(Batch_size)\n    .prefetch(AUTO)\n)\n\nvalidation_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((validation_input_ids, validation_labels))\n    .batch(Batch_size)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_input_ids)\n    .batch(Batch_size)\n)","fafc0255":"def create_model(bert_model):\n    input_ids = tf.keras.Input(shape=(100,),dtype='int32')\n  \n    output = bert_model(input_ids)[0]\n    output = output[:,0,:]\n    output = tf.keras.layers.Dense(3,activation='softmax')(output)\n    model = tf.keras.models.Model(inputs = input_ids,outputs = output)\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model","5f507bcb":"with strategy.scope():\n    bert_model = (\n        \n        transformers.TFAutoModel  \n        .from_pretrained(MODEL)    \n    )\n    model = create_model(bert_model)   ","01a56bc3":"model.summary()","5f866ad9":"history = model.fit(train_dataset,\n                    validation_data = validation_dataset,\n                    epochs = epochs,   \n                    batch_size = Batch_size,\n                    steps_per_epoch = len(train_input_ids)\/\/Batch_size\n                   )","e624502a":"plt.figure(figsize=(10,8))\nplt.plot(history.history['accuracy'],color='orange')\nplt.plot(history.history['val_accuracy'],color='green')\nplt.legend(loc='best',shadow=True)\nplt.grid()\nplt.show()","c59872d2":"plt.figure(figsize=(10,8))\nplt.plot(history.history['loss'],color='orange')\nplt.plot(history.history['val_loss'],color='green')\nplt.legend(loc='best',shadow=True)\nplt.grid()\nplt.show()","4edc252d":"pred = model.predict(test_dataset,verbose=1)\nprint(len(pred))\npred = pred.argmax(axis=1)\nsubmission.prediction = pred      \nsubmission.to_csv('submission.csv',index=False)    \nsubmission.head()","81fedaad":"<h1 style='color:teal'><strong>Data Visualisation :","c4df3ec9":"<h1 style='color:red'><strong>Importing Libraries :","8f0927e7":"<h1 style='color:magenta'><strong>Reading Data :","1582c04e":"<h1 style='color:orange'><strong>Train-Test Split :","3c48c8f6":"<h1 style='color:orange'><strong>TPU Initialization :","8ca321dc":"<h1 style='color:red'><strong>Data Modeling :","2c72b36e":"<h1 style='color:gray'><strong>Predictions :","73e5e746":"<h1 style='color:brown'><strong>XLM-Roberta Model :"}}