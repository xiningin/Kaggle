{"cell_type":{"4bb74cd3":"code","daaf4ff5":"code","e261e68a":"code","8e5cde5e":"code","87c2eef3":"code","51dd01aa":"code","9e8b6534":"code","7a72f7f4":"code","a23cceee":"code","acdbe826":"code","3c01be9d":"code","51edb27b":"code","7566414f":"code","16eb0c98":"code","65cee866":"code","c5065428":"code","9ad68d08":"code","0e338c03":"code","ac859e38":"code","fce0b9d5":"code","6d1c4c1e":"code","3b1fe226":"code","6a89d4ed":"code","2d53b53d":"code","af166fbd":"code","7db066fb":"code","9a1f5483":"code","fa1c7606":"code","153e8d88":"code","03929d1b":"code","d5bee0dc":"code","6c3e143b":"code","6ba3d5ed":"code","4ef05122":"code","0c5aed5e":"code","38572076":"code","b529b1d9":"markdown","5e14f153":"markdown","abfa0587":"markdown","356e86dd":"markdown","7b538cf9":"markdown","175cca43":"markdown"},"source":{"4bb74cd3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom pathlib import Path","daaf4ff5":"!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html","e261e68a":"!pip install -Uqq fastbook     # FastAI v2\nimport fastbook\nfastbook.setup_book()","8e5cde5e":"from fastbook import *","87c2eef3":"import torch\ntorch.cuda.is_available()","51dd01aa":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(42)","9e8b6534":"path = Path(\"..\/input\/facial-keypoints-68-dataset\")\npath.ls()","7a72f7f4":"train_df = pd.read_csv(path\/\"training_frames_keypoints.csv\")\ntrain_df.rename(columns = {\"Unnamed: 0\": \"fnames\"}, inplace=True)\nprint(train_df.shape)\ntrain_df.head()","a23cceee":"test_df = pd.read_csv(path\/\"test_frames_keypoints.csv\")\ntest_df.rename(columns = {\"Unnamed: 0\": \"fnames\"}, inplace=True)\nprint(test_df.shape)\ntest_df.head()","acdbe826":"fpath = \"..\/input\/facial-keypoints-68-dataset\/\"\ntrain_df['fnames'] = train_df['fnames'].apply(lambda x: fpath +\"training\/\" + x )\ntrain_df.head()","3c01be9d":"test_df['fnames'] = test_df['fnames'].apply(lambda x: fpath +\"test\/\" + x )\ntest_df.head()","51edb27b":"row = train_df.iloc[0,:]\nimg = Image.open(row[0])\nimg","7566414f":"pts = row[1:]\nn = 2\npts = [pts[i: i+n]  for i in range(0, len(pts), n)]   # Convert the list to sublist with size of 2 for X and Y coordindates","16eb0c98":"pnt_img = TensorImage(img)\npnts = np.array(pts, dtype = 'f')\ntfm = Transform(TensorPoint.create)\ntpnts = tfm(pnts)","65cee866":"ctx = pnt_img.show(figsize=(5,5), cmap='Greys')\ntpnts.show(ctx=ctx);","c5065428":"# Helper function for the DataBlock\n\ndef get_x(r): return r[\"fnames\"]\n\n\ndef get_y(r):\n    pts = r[1:]\n    n = 2\n    pts = [pts[i: i+n]  for i in range(0, len(pts), n)]   # Convert the list to sublist with size of 2\n    pnts = np.array(pts, dtype = 'f')\n    return pnts","9ad68d08":"faces = DataBlock(blocks = (ImageBlock, PointBlock),\n                 get_x = get_x,\n                 get_y = get_y,\n                 splitter = RandomSplitter(valid_pct = 0.2, seed= 42),\n                 item_tfms = Resize(512, 512),\n                 batch_tfms = aug_transforms(size = (512,512)))\n","0e338c03":"faces.summary(train_df, bs = 8, show_batch=True)    # Check whether datablock is working correctly","ac859e38":"dls = faces.dataloaders(train_df)\ndls.show_batch(max_n = 9, figsize=(8,6))","fce0b9d5":"xb,yb = dls.one_batch()\nxb.shape,yb.shape","6d1c4c1e":"dls.loss_func                # This looks correct","3b1fe226":"# from torchvision.models import densenet121\nARCH = resnet18     # densenet121, resnet34","6a89d4ed":"learn = cnn_learner(dls, ARCH, y_range = (-1,1))","2d53b53d":"learn.lr_find()","af166fbd":"lr = 2e-2\nlearn.fine_tune(15, lr)     # Train more epochs","7db066fb":"learn.show_results(ds_idx=1, nrows=3, figsize=(6,8))","9a1f5483":"lr = 2e-2\nlearn.fine_tune(15, lr)     # Train more epochs","fa1c7606":"learn.show_results(ds_idx=1, nrows=3, figsize=(6,8))","153e8d88":"# Save the model\n\nlearn.save(\"stage-1\")\nlearn = learn.load(\"stage-1\")","03929d1b":"learn.unfreeze()\nlearn.fit_one_cycle(15, slice(1e-4, 1e-3))    # go more epochs","d5bee0dc":"learn.fit_one_cycle(15, slice(1e-5, 1e-4))    ","6c3e143b":"learn.show_results(ds_idx=1, nrows=3, figsize=(6,8))","6ba3d5ed":"learn.save(\"stage-2\")\nlearn.export(\"\/kaggle\/working\/models\/export.pkl\")","4ef05122":"test_dl = dls.test_dl(test_df)","0c5aed5e":"test_preds, _ = learn.get_preds(dl=test_dl)","38572076":"test_preds.shape","b529b1d9":"There are 3462 images in the Train data 770 images in the Test data.","5e14f153":"Make predictions for test data","abfa0587":"Let's visualize a single image.","356e86dd":"Let's create the DataBlock","7b538cf9":"Train the model","175cca43":"At this stage the model is not improving much. <br>\nLet's check the predictions."}}