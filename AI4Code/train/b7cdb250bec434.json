{"cell_type":{"692642a1":"code","110b4483":"code","78d6a065":"code","db8c2943":"code","1c2ce605":"code","ffce2043":"code","803e9e73":"code","f06305c7":"code","e94d269c":"code","8f1ffb89":"code","e2d1e3dc":"code","492026fa":"code","641a2a8d":"code","f442e15c":"code","7c66be14":"code","4dcda6ec":"code","70b03c9a":"code","00c75ab2":"code","41fe4579":"code","13582d9d":"code","59166c58":"code","fcac21a8":"code","ff5e135e":"code","0b0fee90":"code","dd52f34f":"code","cce23346":"markdown","cbc4295c":"markdown","35dd613e":"markdown","b5a4730c":"markdown","3f78724d":"markdown","44982468":"markdown","07799136":"markdown","2611bb05":"markdown","c4166d4f":"markdown"},"source":{"692642a1":"import os\nimport imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport shutil\nfrom PIL import Image\nfrom timeit import default_timer as timer\n%matplotlib inline\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom keras.utils import plot_model\n\nimport scipy.ndimage as ndi\nimport keras\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom keras.utils import plot_model\nimport keras.backend as tfback\nfrom keras.regularizers import l1, l2\nfrom keras.utils.vis_utils import plot_model\nfrom keras.models import Model, Sequential\nfrom keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport tensorflow as tf\n\n#Kaggle notebook input directory\ninput_path = '\/kaggle\/input\/intel-image-classification\/'\ndst_path = '..\/working\/'","110b4483":"fig, ax = plt.subplots(2, 3, figsize=(14, 10))\nax=ax.ravel()\nplt.setp(ax, xticks=[], yticks=[])\nplt.subplots_adjust(hspace=0.1)\nplt.tight_layout()\n# grid = plt.GridSpec(2, 3, wspace = .2, hspace = .5)\n\ntrain_folder=os.path.join(input_path, 'seg_train\/', 'seg_train\/')\n\nfor i,_dir in enumerate(['buildings\/', 'forest\/', 'glacier\/', 'mountain\/', 'sea\/', 'street\/']):\n    im_file = os.listdir(train_folder+_dir)[0]\n    full_path = train_folder+_dir+im_file\n    ax[i].imshow(plt.imread(full_path), cmap='gray')\n    ax[i].set_title('Condition: {}'.format(_dir[:-1]))\n\nplt.savefig('sample_example.jpg')\nplt.show()","78d6a065":"train_folder=os.path.join(input_path, 'seg_train\/', 'seg_train\/')\nn_sizes={}\n\nfor i,_dir in enumerate(['buildings\/', 'forest\/', 'glacier\/', 'mountain\/', 'sea\/', 'street\/']):\n    size=len(os.listdir(train_folder+_dir))\n    n_sizes[_dir[:-1]]=size\n    \nplt.figure(figsize=(10,5))\nsns.barplot(list(n_sizes.keys()), list(n_sizes.values()))\n\nplt.xlabel('Views')\nplt.ylabel('Samples')\nplt.title('Number of samples by class in train folder')\nplt.grid()\nplt.savefig('samples_dist.jpg')\nplt.show()","db8c2943":"for row in n_sizes.items():\n    print(\"View: \" + row[0] + \" , number of samples: \" + str(row[1]))","1c2ce605":"# Data visualization for pixel distribution \n\nfig, ax = plt.subplots(4, 3, figsize=(15, 7))\nax=ax.ravel()\nplt.subplots_adjust(hspace=0.4, )\n\nfor i,_dir in enumerate(['buildings\/', 'forest\/', 'glacier\/', 'mountain\/', 'sea\/', 'street\/']):\n    im_file = os.listdir(train_folder+_dir)[0]\n    full_path = train_folder+_dir+im_file\n    im=imageio.imread(full_path)\n    hist=ndi.histogram(im, min=0, max=255, bins=256)\n    cdf = hist.cumsum() \/ hist.sum()\n    ax[i].plot(hist)\n    ax[i].set_title('Histogram {}'.format(_dir[:-1]))\n    ax[i].grid()\n    ax[i+6].plot(cdf, 'g')\n    ax[i+6].set_title('Cum. Dist. Function {}'.format(_dir[:-1]))\n    ax[i+6].grid()\n    \n\nplt.savefig('pixel_dist.jpg')\nplt.show()","ffce2043":"for img in os.listdir(train_folder + 'forest\/')[:10]:\n    final_path=os.path.join(train_folder, 'forest\/', img)\n    img_sample = Image.open(final_path)\n    display(img_sample.size)","803e9e73":"def move_folder(input_folder, group_data):\n    counter=0\n    final_dst=os.path.join(dst_path, group_data)\n    if not os.path.exists(final_dst):\n        os.makedirs(final_dst)\n    for group in os.listdir(input_folder):\n        group_path = os.path.join(input_folder, group)\n        group_dst = os.path.join(final_dst, group)\n        if not os.path.exists(group_dst):\n            os.makedirs(group_dst)\n        for img in os.listdir(group_path):\n            counter+=1\n            shutil.copy2(group_path+'\/'+img, group_dst+'\/'+img)\n    print(str(counter) + \"files were replaced\")","f06305c7":"move_folder(train_folder, 'train')","e94d269c":"test_folder=os.path.join(input_path, 'seg_test\/', 'seg_test\/')\nmove_folder(test_folder, 'test')","8f1ffb89":"### Pipeline Pre processing and training","e2d1e3dc":"# Defining some constant variables to use in the preprocessor\n\ntrain_path  = '..\/working\/train'\ntest_path =  '..\/working\/test'\nIMAGE_SIZE    = (128, 128)  ##(heigth, width, rgb channels)\nBATCH_SIZE    = 64\nNUM_EPOCHS    = 100","492026fa":"def get_pipeline_prepro(train_path, test_path, img_size, batch_size):\n\n    #Train datagen here is a preprocessor\n    train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                       horizontal_flip = True ,\n                                       vertical_flip = True ,\n                                       validation_split = 0.25,\n                                       featurewise_center=True,\n                                       rotation_range=20,\n                                       samplewise_center=True,\n                                       zca_whitening=True\n                                      )\n    \n    train_batches = train_datagen.flow_from_directory(train_path,\n                                                      target_size=img_size,\n                                                      shuffle=True,\n                                                      subset = \"training\",\n                                                      batch_size=batch_size,\n                                                      color_mode=\"rgb\",\n                                                      class_mode=\"categorical\"\n                                                      )\n\n    valid_batches = train_datagen.flow_from_directory(test_path,\n                                                      target_size=img_size,\n                                                      shuffle=True,\n                                                      subset = \"validation\",\n                                                      batch_size=batch_size,\n                                                      color_mode=\"rgb\",\n                                                      class_mode=\"categorical\"\n                                                      )\n    \n    return train_batches, valid_batches","641a2a8d":"class TimingCallback(keras.callbacks.Callback):\n    def __init__(self, logs={}):\n        self.logs=[]\n    def on_epoch_begin(self, epoch, logs={}):\n        self.starttime = timer()\n    def on_epoch_end(self, epoch, logs={}):\n        self.logs.append(timer()-self.starttime)\n        \ncb = TimingCallback()","f442e15c":"def get_cnn_model(train_batches, valid_batches, callbacks, num_epochs, optimizer):\n    # define model\n    model = Sequential()\n\n    #Convolve block\n    model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same', input_shape=(128, 128, 3)))\n    model.add(Conv2D(32, kernel_size=(5, 5), padding='same', activation='relu'))\n    model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same'))\n    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    \n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='valid'))\n    model.add(Conv2D(64, kernel_size=(3, 3), padding='valid', activation='relu'))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    model.add(Dropout(0.3))\n    \n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    model.add(Dropout(0.3))\n\n    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'))\n    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n    \n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(6, activation='softmax'))\n    \n    # compile model    \n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n        \n    # fit model\n    STEP_SIZE_TRAIN=train_batches.n\/\/train_batches.batch_size\n    STEP_SIZE_VALID=valid_batches.n\/\/valid_batches.batch_size\n    result=model.fit_generator(train_batches,\n                        steps_per_epoch = STEP_SIZE_TRAIN,\n                        validation_data = valid_batches,\n                        validation_steps = STEP_SIZE_VALID,\n                        callbacks = callbacks,\n                        epochs = num_epochs                     \n                       )\n    \n    return model, result","7c66be14":"def plot_accs(result, epochs, img_name):\n    acc = result.history['accuracy']\n    loss = result.history['loss']\n    val_acc = result.history['val_accuracy']\n    val_loss = result.history['val_loss']\n    plt.figure(figsize=(15, 5))\n    plt.subplot(121)\n    plt.plot(range(1,epochs), acc[1:], label='Train_acc')\n    plt.plot(range(1,epochs), val_acc[1:], label='Test_acc')\n    plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\n    plt.legend()\n    plt.grid(True)\n    plt.subplot(122)\n    plt.plot(range(1,epochs), loss[1:], label='Train_loss')\n    plt.plot(range(1,epochs), val_loss[1:], label='Test_loss')\n    plt.title('Loss over ' + str(epochs) + ' Epochs', size=15)\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(img_name)\n    plt.show()","4dcda6ec":"opt=tf.keras.optimizers.Adam(\n    learning_rate=0.001,\n)\ncheckpoint = ModelCheckpoint(filepath='IIC_BS64.hdf5', save_best_only=True, save_weights_only=True)\nearly_stop = EarlyStopping(patience=20, monitor='val_accuracy')\n\ncallbacks=[checkpoint, early_stop, cb]\n\ntrain_batches, valid_batches = get_pipeline_prepro(train_path, test_path, IMAGE_SIZE, BATCH_SIZE)","70b03c9a":"model_adam, results_adam=get_cnn_model(train_batches, valid_batches, callbacks, NUM_EPOCHS, opt)","00c75ab2":"plot_accs(results_adam, 65, 'adam_01.jpg')","41fe4579":"cb_1_total=np.sum(cb.logs)\ncb_1_total","13582d9d":"cb_1_mean=np.mean(cb.logs)\ncb_1_mean","59166c58":"np.max(results_adam.history['val_accuracy'])","fcac21a8":"STEP_SIZE_TEST=valid_batches.n\/\/valid_batches.batch_size","ff5e135e":"validations=[]\nfor i in range(10):\n    valid=model_adam.evaluate_generator(generator=valid_batches, steps=STEP_SIZE_TEST)\n    validations.append(valid[1])\n\nfinal_eval=np.sum(validations)\/10\nprint(\"A acur\u00e1cia foi de: \" + str(final_eval))","0b0fee90":"model_adam.summary()","dd52f34f":"plot_model(model_adam, show_shapes=True, show_layer_names=True)","cce23346":"### Visualization","cbc4295c":"#### Plot some images of each class in train segment folder","35dd613e":"### Adam optimizer","b5a4730c":"> The histograma of intensity pixels and the cumulative distribution function help us to understand how the intensity pixels are spread in the image.","3f78724d":"#### Loss Function and how it decays\n    The model will save the best weigths in training process\n    If ten epochs in sequence don't improve accuracy the model stops train -> means overfitting","44982468":"### Pre processing pipeline.\n    Important operations:\n        - Horizontal and vertical rotation\n        - Featurewise center\n        - Samplewise_center\n        - zca_whitening","07799136":"#### Images are matrix (n1xn2) where n means the resolution of it. We can open it as numpy array and then check the resolution we are working","2611bb05":"#### Move folder from input directory to working dir. The data was already splitted on test, train and pred samples.","c4166d4f":"## Pre Processing"}}