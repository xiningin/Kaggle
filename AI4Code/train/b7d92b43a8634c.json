{"cell_type":{"da55d8d3":"code","aaf3aa72":"code","c26de1d5":"code","a58290ee":"code","4e4c99ba":"code","4706fd7a":"code","dd43b0f3":"code","e4555186":"code","3c106389":"code","1a0e6a2f":"code","c1ed0191":"code","eeff9055":"code","ae10bf1a":"code","9d75c82c":"code","c93890d3":"code","d2ae4a02":"code","b381cec8":"code","2a3715c4":"code","27a48e52":"code","c2b6d7a8":"code","dcc811a7":"code","4d373a3a":"code","f3d1dad6":"code","937c8994":"code","8ee33b3d":"code","8b57a042":"code","69e97d29":"code","6b3314ab":"code","f650e265":"code","86d9a6dd":"code","579c352f":"code","e40b96fc":"code","1fbe6255":"code","59e19a80":"code","40997d50":"code","f369d2f0":"code","f322d46a":"code","8ec265ba":"code","b36f727d":"code","8d00992f":"code","1f7192d8":"code","763de67f":"code","230e7e07":"code","ec579f18":"code","38c411ac":"code","1050aee4":"code","70edfc57":"code","2dbe27e6":"code","8a5266bf":"code","17c3a652":"code","5f440f08":"markdown","ab693f6c":"markdown","a599c394":"markdown","2d50a32f":"markdown","049bfe7c":"markdown","60aac28b":"markdown","69b0e4aa":"markdown","7c03d9b3":"markdown","f110b15a":"markdown","25ea1303":"markdown","f522bb39":"markdown","7f2618f6":"markdown","9dee4467":"markdown","250eae6c":"markdown","2004f560":"markdown"},"source":{"da55d8d3":"# We have gone over this a bunch of times =)\n%matplotlib inline\n%reload_ext autoreload\n%autoreload 2","aaf3aa72":"# Download data.\n!wget http:\/\/pjreddie.com\/media\/files\/cifar.tgz\n!tar -xzf cifar.tgz","c26de1d5":"%%bash\ncd cifar\nmkdir train_\nmkdir test_\npwd","a58290ee":"%%bash\ncd cifar\ncd train_\nmkdir airplane automobile bird cat deer dog frog horse ship truck\ncd ..\npwd\nfunction copytrain { for arg in $@; do cp $(find train -name '*'$arg'.png') train_\/$arg\/; done; };\ncopytrain $(ls train_ | grep -o \"[a-z]*\")\ncd test_\nmkdir airplane automobile bird cat deer dog frog horse ship truck\ncd ..\nfunction copytest { for arg in $@; do cp $(find test -name '*'$arg'.png') test_\/$arg\/; done; };\ncopytest $(ls test_ | grep -o \"[a-z]*\")\nrm -rf train\nrm -rf test\nmv train_ train\nmv test_ test","4e4c99ba":"#import libraries\nfrom fastai.conv_learner import *","4706fd7a":"#define dataset path\nPATH = \"\/kaggle\/working\/cifar\/\"\nos.makedirs(PATH,exist_ok=True)\n!ls {PATH}\/train","dd43b0f3":"classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\nstats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))","e4555186":"def get_data(sz,bs):\n    tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomFlip()], pad=sz\/\/8)\n    return ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)","3c106389":"data = get_data(32, 4)","1a0e6a2f":"x, y= next(iter(data.trn_dl))","c1ed0191":"x.size()","eeff9055":"plt.imshow(data.trn_ds.denorm(x)[0]);","ae10bf1a":"plt.imshow(data.trn_ds.denorm(x)[2]);","9d75c82c":"# full model training\nbs = 256\ndata = get_data(32, bs)\nlr = 1e-2","c93890d3":"class SimpleMLP_Cifar(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layers = nn.ModuleList([nn.Linear(32*32*3, 40), nn.Linear(40, 10)])\n        \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        for l in self.layers:\n            x = F.relu(l(x))\n        return F.log_softmax(x, -1)     \n        ","d2ae4a02":"learn = ConvLearner.from_model_data(SimpleMLP_Cifar(), data)","b381cec8":"learn.fit(lr, 2)","2a3715c4":"learn.summary()","27a48e52":"class SimpleNet(nn.Module):\n    def __init__(self, layers):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n        \n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        for l in self.layers:\n            l_x = l(x)\n            x = F.relu(l_x)\n        return F.log_softmax(l_x, dim=-1)\n    \n# Something wrong here?? Can you find out??\n# If found, check your hypothesis if it works better.","c2b6d7a8":"learn = ConvLearner.from_model_data(SimpleNet([32*32*3, 40,10]), data)","dcc811a7":"learn.summary()","4d373a3a":"learn.lr_find()","f3d1dad6":"learn.sched.plot()","937c8994":"%time learn.fit(lr, 2)","8ee33b3d":"%time learn.fit(lr, 2, cycle_len=1)","8b57a042":"layers = [32*32*3, 100, 50, 10]\n# Module list takes a list of layers--> [nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)]\nfor i in range(len(layers) - 1):\n    print(nn.Linear(layers[i], layers[i+1]))\n# if I wanna use this model, what should I change in the forward function?","69e97d29":"# Create class convnet and train","6b3314ab":"#Compare parameters vs accuracy trade-off for MLP and CNN.\n# No max pool, why??","f650e265":"class ConvLayer(nn.Module):\n    def __init__(self, ni, nf):\n        super().__init__()\n        self.conv = nn.Conv2d(ni, nf, kernel_size=3, stride=2, padding=1)\n        \n    def forward(self, x): return F.relu(self.conv(x))","86d9a6dd":"class ConvNet(nn.Module):\n    def __init__(self, layers, c):\n        super().__init__()\n        self.layers = nn.ModuleList([ConvLayer(layers[i], layers[i + 1])\n            for i in range(len(layers) - 1)])\n        self.out = nn.Linear(layers[-1], c)\n        \n    def forward(self, x):\n        for l in self.layers: x = l(x)\n        x = F.adaptive_max_pool2d(x, 1)\n        x = x.view(x.size(0), -1)\n        return F.log_softmax(self.out(x), dim=-1)","579c352f":"learn = ConvLearner.from_model_data(ConvNet([3, 30, 60, 90], 10), data)","e40b96fc":"learn.lr_find()","1fbe6255":"learn.sched.plot()","59e19a80":"learn.fit(lr, 2)","40997d50":"learn.summary()","f369d2f0":"# We are creating a single batch norm layer. IMP!!!\nclass BnLayer(nn.Module):\n    def __init__(self, ni, nf, stride=2, kernel_size=3):\n        super().__init__()\n        # ni --> no of input feature maps, nf --> no. of output feature maps.\n        self.conv = nn.Conv2d(ni, nf, kernel_size=kernel_size, \n                              stride=stride, bias=False, padding=1)\n        #Notice, a single parameter for each channel.\n        self.a = nn.Parameter(torch.zeros(nf,1,1))\n        #Notice, a single parameter for each channel.\n        self.m = nn.Parameter(torch.ones(nf,1,1))\n        \n    def forward(self, x):\n        x = F.relu(self.conv(x))\n        #Get each channel seperately. Notice, x.size(1).. IMP!!\n        x_chan = x.transpose(0,1).contiguous().view(x.size(1), -1)\n        #For training it keeps 'changing' for each iteration, not beacuse we are changing, but why??\n        #So, regularization... yes!! That means we can ignore other techniques.\n        if self.training:\n            # While testing, we don't wanna change this cause, it may change the meaning of the model.\n            self.means = x_chan.mean(1)[:,None,None]\n            self.stds  = x_chan.std (1)[:,None,None]\n        #What are we learning here?\n        return (x-self.means) \/ self.stds *self.m + self.a","f322d46a":"# Create ConvBatchNet","8ec265ba":"# Refactored ConvBnet\n# Notice we aren't passing input no. of channels, becoming more modular.\nclass ConvBnNet(nn.Module):\n    def __init__(self, layers, c):\n        super().__init__()\n        # Modern Approaches start with a larger kernel. To save quality features.\n        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, stride=1, padding=2)\n        self.layers = nn.ModuleList([BnLayer(layers[i], layers[i+1])\n            for i in range(len(layers) - 1)])\n        self.layers2 = nn.ModuleList([BnLayer(layers[i+1], layers[i + 1], 1)\n            for i in range(len(layers) - 1)])\n        self.out = nn.Linear(layers[-1], c)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        #zip ?? google it !, or try to extrapolate using previous approaches.\n        for l,l2 in zip(self.layers, self.layers2):\n            x = l(x)\n            x = l2(x)\n        x = F.adaptive_max_pool2d(x, 1)\n        x = x.view(x.size(0), -1)\n        return F.log_softmax(self.out(x), dim=-1)","b36f727d":"model = ConvLearner.from_model_data(ConvBnNet([10, 20, 40, 80, 160], 10), data)","8d00992f":"model.lr_find()","1f7192d8":"model.sched.plot()","763de67f":"model.fit(lr, 3)","230e7e07":"# Create a ResLayer by inherithig from the BnLayer Module\nclass ResLayer(BnLayer):\n    def forward(self, x):\n        return x + super().forward(x)","ec579f18":"ResLayer(10, 20, 1)","38c411ac":"# Notice, we increased the size of features and added dropout.\n\nclass ResnetFull(nn.Module):\n    def __init__(self, layers, c, p=0.5):\n        super().__init__()\n        self.conv1 = BnLayer(3, 16, stride=1, kernel_size=7)\n        self.layers = nn.ModuleList([BnLayer(layers[i], layers[i+1])\n            for i in range(len(layers) - 1)])\n        self.layers2 = nn.ModuleList([ResLayer(layers[i+1], layers[i + 1], 1)\n            for i in range(len(layers) - 1)])\n        self.layers3 = nn.ModuleList([ResLayer(layers[i+1], layers[i + 1], 1)\n            for i in range(len(layers) - 1)])\n        self.out = nn.Linear(layers[-1], c)\n        self.drop = nn.Dropout(p)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        for l,l2,l3 in zip(self.layers, self.layers2, self.layers3):\n            x = l3(l2(l(x)))\n        x = F.adaptive_max_pool2d(x, 1)\n        x = x.view(x.size(0), -1)\n        x = self.drop(x)\n        return F.log_softmax(self.out(x), dim=-1)","1050aee4":"learn = ConvLearner.from_model_data(ResnetFull([16, 32, 64, 128, 256], 10), data)","70edfc57":"learn.lr_find()","2dbe27e6":"learn.sched.plot()","8a5266bf":"lr = 2*1e-2","17c3a652":"learn.summary()","5f440f08":"### Visualise the data","ab693f6c":"##### understanding module list !\nWhen to use module list --> [link](https:\/\/discuss.pytorch.org\/t\/when-should-i-use-nn-modulelist-and-when-should-i-use-nn-sequential\/5463)","a599c394":" ##### Use the fastai v1 code to complete the above process. (Home-work)","2d50a32f":"What all changes did you notice from last time??","049bfe7c":"- The full ResNet does two convolutions before it gets added back to the original input.\n- There is also a stardard stride 2 conv in between\n- A ResBlock\n- Check out the paper\n![](https:\/\/raw.githubusercontent.com\/torch\/torch.github.io\/master\/blog\/_posts\/images\/resnets_1.png)","60aac28b":"## BatchNorm\n### Why batch norm?\nThe last model, when we tried to add more layers, we had trouble training. The reason we had trouble training was that if we used larger learning rates, it would go off to infinity (NaN) and if we used smaller learning rate, it would be very slow to train, and doesn\u2019t have a chance to explore properly\u200a.  \n[Research Paper](https:\/\/arxiv.org\/pdf\/1502.03167.pdf)  \n[AndrewNG](https:\/\/www.youtube.com\/watch?v=-7scQpJT7uo)  ","69b0e4aa":"`A simple note on why it works : \n\nIf it wants to scale the layer up, it does not have to scale up every single value in the channel. It can control the scaling using(updating) `self.m` , if it wants to shift it all up or down a bit, it does not have to shift the entire channel, they can just shift this `self.a`. So, We are normalizing the data and then we are saying you can then shift it and scale it using far fewer parameters than would have been necessary if it were to actually shift and scale the entire set of convolutional filters.","7c03d9b3":"## Resnet layer\n\nIf its more than 12-15 layers deep even batch norm gives up at that point. Here residual blocks come to the rescue :)\n![](https:\/\/i.stack.imgur.com\/xIJXy.png)\n\n- Easy pass through gradients\n- calculating the residual after each block\n-  Where, we have a fn which tires to predict the error at intervals in the deep network.","f110b15a":"**Thank you**, hope it was useful :)","25ea1303":"### Model :  simple multi-layer preceptron ","f522bb39":"#### Question : We normalized before, when and whats the difference between them ?","7f2618f6":"SimpleNet ---> From [this notebook](https:\/\/github.com\/KeremTurgutlu\/deeplearning\/blob\/master\/Exploring%20Optimizers.ipynb) by  Kerem Turgutlu:","9dee4467":"#### Refactor CNN (more readable)\n1. Create a ConvLayer module\n2. Create a CnnNet by usinf ConLayer module.","250eae6c":"## CIFAR 10 (Resnet from scratch)\n##### [Full Description](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html)","2004f560":"#### Make sure the data directory is in the correct format."}}