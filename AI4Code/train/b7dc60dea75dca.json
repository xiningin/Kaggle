{"cell_type":{"26620087":"code","46f5d85e":"code","379f3e26":"code","dc555f27":"code","4fde3866":"code","89c80669":"code","caf47e66":"code","0d833e3b":"code","82468268":"code","55370d46":"code","6bf724ca":"code","88fff1b3":"code","6d52485a":"code","91c968b2":"code","8f8c00e9":"code","60ef5e15":"code","a7b84b86":"code","1ae6431a":"code","96f82a70":"code","42b235d2":"code","8953af7b":"code","87207555":"code","76d2ee8e":"code","db7c9597":"code","40bdc3e8":"code","22dea587":"code","5f99ea3e":"code","0f8ad94f":"code","abae9624":"code","c5487fd2":"code","915d209c":"code","07c59930":"code","80df4828":"code","4f26520b":"code","5bcd2e60":"code","1f78406b":"code","1f8e2726":"code","140db7cf":"code","ae02a1e7":"code","f2089fd4":"code","a13f8d9a":"code","25c2d054":"code","f0776904":"code","065b7656":"code","51da7fba":"code","c065c457":"code","180ba3a8":"code","2568145a":"markdown","76f314d4":"markdown","fe4271aa":"markdown","b8899a4f":"markdown","47d77139":"markdown","18cba76b":"markdown","8083d2b0":"markdown","ce4657f9":"markdown","1909d237":"markdown","d1b588ca":"markdown","c411c1b3":"markdown","fef6b866":"markdown","438b64c5":"markdown","84651724":"markdown","e5652f60":"markdown","a99d6e8e":"markdown","34e418a3":"markdown","a1b28a48":"markdown","d3d958f6":"markdown","ffedd086":"markdown","4e8fa147":"markdown","ffa73728":"markdown"},"source":{"26620087":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\n\nsns.set(rc={'figure.figsize':(12, 10)})","46f5d85e":"data = pd.read_csv('..\/input\/titanic\/train.csv')","379f3e26":"data.head(10)","dc555f27":"data.info()","4fde3866":"data.isnull().sum()","89c80669":"data.describe()","caf47e66":"\nplt.figure(figsize=(12, 10))\nheatmap = sns.heatmap(data[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\",\"Sex\"]].corr(), annot=True)","0d833e3b":"data['SibSp'].nunique()","82468268":"data['SibSp'].unique()","55370d46":"bargraph_sibsp = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = data, kind = \"bar\", size = 8)\nbargraph_sibsp = bargraph_sibsp.set_ylabels(\"survival probability\")","6bf724ca":"age_visual = sns.FacetGrid(data, col = 'Survived', size=7)\nage_visual = age_visual.map(sns.distplot, \"Age\")\nage_visual = age_visual.set_ylabels(\"survival probability\")","88fff1b3":"import matplotlib.pyplot as plt\nplt.figure(figsize=(12, 10))\nage_plot = sns.barplot(x = \"Sex\",y = \"Survived\", data = data)\nage_plot = age_plot.set_ylabel(\"Survival Probability\")","6d52485a":"data[[\"Sex\",\"Survived\"]].groupby('Sex').mean()","91c968b2":"pclass = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = data, kind = \"bar\", size = 8)\npclass = pclass.set_ylabels(\"survival probability\")","8f8c00e9":"g = sns.factorplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data, size=6, kind=\"bar\")\ng = g.set_ylabels(\"survival probability\")","60ef5e15":"data[\"Embarked\"].isnull().sum()","a7b84b86":"data[\"Embarked\"].value_counts()","1ae6431a":"#Fill Embarked with 'S' i.e. the most frequent values\ndata[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\")","96f82a70":"g = sns.factorplot(x=\"Embarked\", y=\"Survived\", data=data, size=7, kind=\"bar\")\ng = g.set_ylabels(\"survival probability\")","42b235d2":"# Explore Pclass vs Embarked \ng = sns.factorplot(\"Pclass\", col=\"Embarked\",  data=data, size=7, kind=\"count\")\ng.despine(left=True)\ng = g.set_ylabels(\"Count\")","8953af7b":"pd.read_csv('..\/input\/titanic\/test.csv')","87207555":"data.head()","76d2ee8e":"data.info()","db7c9597":"mean = data[\"Age\"].mean()\nstd = data[\"Age\"].std()\nis_null = data[\"Age\"].isnull().sum()\n\nrand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    \n\nage_slice = data[\"Age\"].copy()\nage_slice[np.isnan(age_slice)] = rand_age\ndata[\"Age\"] = age_slice","40bdc3e8":"data[\"Age\"].isnull().sum()","22dea587":"data.info()","5f99ea3e":"data[\"Embarked\"].isnull().sum()","0f8ad94f":"#Fill Embarked with 'S' i.e. the most frequent values\ndata[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\")","abae9624":"col_to_drop = ['PassengerId','Cabin', 'Ticket','Name']\ndata.drop(col_to_drop, axis=1, inplace = True)","c5487fd2":"data.head()","915d209c":"genders = {\"male\": 0, \"female\": 1}\ndata['Sex'] = data['Sex'].map(genders)","07c59930":"data.head()","80df4828":"ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n\ndata['Embarked'] = data['Embarked'].map(ports)","4f26520b":"data.head()","5bcd2e60":"data.info()","1f78406b":"# input and output data\n\nx = data.drop(data.columns[[0]], axis = 1)\ny = data['Survived']","1f8e2726":"x.head()","140db7cf":"y.head()","ae02a1e7":"# splitting into training and testing data\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.30, random_state =0)","f2089fd4":"from sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nxtrain = sc_x.fit_transform(xtrain) \nxtest = sc_x.transform(xtest)","a13f8d9a":"logreg = LogisticRegression()\nsvc_classifier = SVC()\ndt_classifier = DecisionTreeClassifier()\nknn_classifier = KNeighborsClassifier(5)\nrf_classifier = RandomForestClassifier(n_estimators=1000)\nnaivebayes_classifier = GaussianNB()","25c2d054":"logreg.fit(xtrain, ytrain)\nsvc_classifier.fit(xtrain, ytrain)\ndt_classifier.fit(xtrain, ytrain)\nknn_classifier.fit(xtrain, ytrain)\nrf_classifier.fit(xtrain, ytrain)\nnaivebayes_classifier.fit(xtrain, ytrain)","f0776904":"logreg_ypred = logreg.predict(xtest)\nsvc_classifier_ypred = svc_classifier.predict(xtest)\ndt_classifier_ypred = dt_classifier.predict(xtest)\nknn_classifier_ypred = knn_classifier.predict(xtest)\nrf_classifier_ypred = rf_classifier.predict(xtest)\nnaivebayes_y_pred = naivebayes_classifier.predict(xtest)","065b7656":"\nfrom sklearn.metrics import accuracy_score\n\nlogreg_acc = accuracy_score(ytest, logreg_ypred)\nsvc_classifier_acc = accuracy_score(ytest, svc_classifier_ypred)\ndt_classifier_acc = accuracy_score(ytest, dt_classifier_ypred)\nknn_classifier_acc = accuracy_score(ytest, knn_classifier_ypred)\nrf_classifier_acc = accuracy_score(ytest, rf_classifier_ypred)\nnaivebayes_acc = accuracy_score(ytest, naivebayes_y_pred)","51da7fba":"print (\"Logistic Regression : \", round(logreg_acc*100, 2))\nprint (\"Support Vector      : \", round(svc_classifier_acc*100, 2))\nprint (\"Decision Tree       : \", round(dt_classifier_acc*100, 2))\nprint (\"K-NN Classifier     : \", round(knn_classifier_acc*100, 2))\nprint (\"Random Forest       : \", round(rf_classifier_acc*100, 2))\nprint (\"Naive Bayes         : \", round(naivebayes_acc*100, 2))","c065c457":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(ytest, naivebayes_y_pred)","180ba3a8":"cm\n","2568145a":"VARIABLE       DESCRIPTION            KEY\n\nsurvival \t   Survival \t          0 = No, 1 = Yes\npclass \t       Ticket class \t      1 = 1st, 2 = 2nd, 3 = 3rd\nsex \t       Sex \t\nAge \t       Age in years \t\nsibsp \t       # of siblings \/ spouses aboard the Titanic \t\nparch \t       # of parents \/ children aboard the Titanic \t\nticket \t       Ticket number \t\nfare \t       Passenger fare \t\ncabin \t       Cabin number \t\nembarked \t   Port of Embarkation \t  C = Cherbourg, Q = Queenstown, S = Southampton\n\n\n\nVariable Notes\n\npclass: A proxy for socio-economic status (SES)\n1st    = Upper\n2nd    = Middle\n3rd    = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","76f314d4":"## <font color = \"green\">Sex<\/font>","fe4271aa":"Cherbourg passengers are mostly in first class which have the highest survival rate.\n<br\/>\nSouthampton (S) and Queenstown (Q) passangers are mostly in third class.","b8899a4f":"Passenger coming from Cherbourg (C) have more chance to survive.","47d77139":"\nAge distribution seems to be a tailed distribution, maybe a gaussian distribution.\n\nWe notice that age distributions are not the same in the survived and not survived subpopulations. Indeed, there is a peak corresponding to young passengers, that have survived. We also see that passengers between 60-80 have less survived. \n\nSo, even if \"Age\" is not correlated with \"Survived\", we can see that there is age categories of passengers that of have more or less chance to survive.\n\nIt seems that very young passengers have more chance to survive.\n","18cba76b":"**Overview**\n\nThe sinking of the **RMS Titanic** is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we target to complete the analysis of what sorts of people were likely to survive.","8083d2b0":"## <font color = \"green\">Feature Scaling<\/font>","ce4657f9":"## <font color = \"green\">Pclass vs Survived by Sex<\/font>","1909d237":"It seems that passengers having a lot of siblings\/spouses have less chance to survive.\n<br \/>\nSingle passengers (0 SibSP) or with two other persons (SibSP 1 or 2) have more chance to survive.","d1b588ca":"**Types of Features :** \n- **Categorical**  - Sex, and Embarked.\n- **Continuous **  - Age, Fare\n- **Discrete**     - SibSp, Parch.\n- **Alphanumeric** - Cabin","c411c1b3":"## <font color = 'green'>Numerical Value Analysis<\/font>","fef6b866":"## <font color = \"green\">Embarked <\/font>","438b64c5":"### Importing Libraries","84651724":"## <font color = \"green\"> Classification<\/font>","e5652f60":"## <font color = \"green\"> Age <\/font>","a99d6e8e":"# <font color = \"green\">Preparing data<\/font>","34e418a3":"**Conclusion : **\n\nOnly Fare feature seems to have a significative correlation with the survival probability.\n\nIt doesn't mean that the other features are not usefull. Subpopulations in these features can be correlated with the survival. To determine this, we need to explore in detail these features","a1b28a48":"## <font color = \"green\">sibsp - Number of siblings \/ spouses aboard the Titanic <\/font>","d3d958f6":"### Loading Dataset","ffedd086":"## <font color = \"green\">PClass<\/font>","4e8fa147":"## <font color = \"green\">Splitting data<\/font>","ffa73728":"### Let's find the reason"}}