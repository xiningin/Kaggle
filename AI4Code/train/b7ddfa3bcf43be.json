{"cell_type":{"e9f754be":"code","29bf115d":"code","8662eacd":"code","679b8d11":"code","f456dea2":"code","0ae32245":"code","8b535190":"code","eb41f54b":"code","28a96165":"code","767b1363":"code","79406557":"code","cad8afc1":"code","f3e96e15":"code","8fe2b260":"code","d5b3bcad":"code","3109ac63":"code","4441534a":"markdown"},"source":{"e9f754be":"from fastai import *\nfrom fastai.vision import *","29bf115d":"import matplotlib.pyplot as plt\nfrom matplotlib.backend_bases import RendererBase\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom scipy.fftpack import fft\nimport pandas as pd\n\nimport os, glob, numpy as np\nfrom PIL import Image","8662eacd":"audio_path = '..\/input\/environmental-sound-classification-50\/audio\/audio\/44100\/'\nlabel_csv = '..\/input\/environmental-sound-classification-50\/esc50.csv'","679b8d11":"waves = glob.glob(audio_path+'*.wav');\nprint(len(waves))","f456dea2":"df = pd.read_csv(label_csv, usecols=['filename', 'target', 'category'], index_col=['filename'])\ndf.head()","0ae32245":"def create_dir(dirname):\n    if os.path.exists(dirname):\n        pass\n    else:\n        os.makedirs(dirname)","8b535190":"def save_spectogram(file, output, figsize=(4,4)):\n\n    freq, sound = wavfile.read(file)\n    freq, time, specto = signal.spectrogram(sound)\n    specto = 10*np.log(specto.astype(np.float32))\n    \n    fig = plt.figure(figsize=figsize, frameon=False) # make images 288x288\n    ax = plt.Axes(fig, [0.,0.,1.,1.])\n    ax.set_axis_off()\n    fig.add_axes(ax)\n    ax.pcolormesh(time\/100, freq, specto)\n    fig.savefig(output, dpi=100)\n    plt.close()","eb41f54b":"import matplotlib\nmatplotlib.use('Agg') #stop display output in ipython\n\nfor item in waves:\n    name=item.split('\/')[-1]\n#     print(name)\n    dirname='.\/prep\/' + df.loc[name].category\n    create_dir(dirname)\n    out_file = dirname+ '\/' + name.split('.wav')[0] + '.jpg'\n    save_spectogram(item, out_file)\n    \nprint('done')","28a96165":"tfms = get_transforms(do_flip=False, max_rotate=0.)\ndata = ImageDataBunch.from_folder('.\/prep\/', valid_pct=0.1, ds_tfms=tfms, size=224)\ndata.normalize()","767b1363":"#from Settings(on the right panel) Turn on Internet to download resnet50 pretrained\nlearner_model = cnn_learner(data, models.resnet50, metrics=error_rate)","79406557":"learner_model.fit_one_cycle(4)","cad8afc1":"learner_model.unfreeze()\nlearner_model.fit_one_cycle(4, max_lr=slice(1e-5, 1e-2))","f3e96e15":"interp = ClassificationInterpretation.from_learner(learner_model)\n%matplotlib inline","8fe2b260":"interp.plot_top_losses(9, figsize=(15,15))","d5b3bcad":"interp.plot_confusion_matrix(figsize=(15,15))","3109ac63":"interp.most_confused(min_val=2)","4441534a":"[My Github](https:\/\/github.com\/pykeras\/fastai)  \n*I'm a tensorflow(keras) user and try to learn how fastai library work, but prefer to do it on realworld datasets*"}}