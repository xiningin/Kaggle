{"cell_type":{"5d47f49a":"code","4b67bd0b":"code","6f6a29eb":"code","b403de7f":"code","915b684a":"code","8e422f0a":"code","db05ed5b":"code","0a34060a":"code","884f8aac":"code","0f87f34c":"code","787a6e05":"markdown"},"source":{"5d47f49a":"import torch\n#import torch.nn as nn\nfrom torch import nn\nfrom torch import optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import random_split, DataLoader","4b67bd0b":"torch.randn(5)\n#torch.randn(5).cuda()","6f6a29eb":"model0 = nn.Sequential(\nnn.Linear(28*28,64),\n    nn.ReLU(),\n    nn.Linear(64,64),\n    nn.ReLU(),\n    nn.Linear(64,10)\n)","b403de7f":"model0","915b684a":"class ResNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1=nn.Linear(28*28,64)\n        self.l2=nn.Linear(64,64)        \n        self.l3=nn.Linear(64,10)\n        self.do=nn.Dropout(0.1)   \n    \n    def forward(self,x):\n        h1=nn.functional.relu(self.l1(x))\n        h2=nn.functional.relu(self.l2(h1))\n        do=self.do(h2+h1)\n        logits=self.l3(do)\n        return logits\n    \nmodel=ResNet()  ","8e422f0a":"model","db05ed5b":"params=model.parameters()\noptimizer=optim.SGD(model.parameters(),lr=1e-2)","0a34060a":"loss=nn.CrossEntropyLoss()","884f8aac":"train_data=datasets.MNIST('data',train=True,download=True,transform=transforms.ToTensor())\ntrain,val=random_split(train_data,[55000,5000])\ntrain_loader=DataLoader(train,batch_size=32)\nval_loader=DataLoader(val,batch_size=32)","0f87f34c":"nb_epochs=5\n\nfor epoch in range(nb_epochs):\n    losses1=list()\n    accuracy1=list()\n    for batch in train_loader:\n        x,y=batch\n        b=x.size(0)\n        x=x.view(b,-1)\n        logits=model(x)\n        J=loss(logits,y)\n        model.zero_grad()\n        J.backward()\n        optimizer.step()\n        losses1.append(J.item())\n        accuracy1.append(y.eq(logits.detach().argmax(dim=1)).float().mean()) \n        \n    print(f'Epoch {epoch+1}, train loss: {torch.tensor(losses1).mean():.2f}, train acc: {torch.tensor(accuracy1).mean():.2f}') \n\n    losses2=list()\n    accuracy2=list()\n    for batch in val_loader:\n        x,y=batch\n        b=x.size(0)\n        x=x.view(b,-1)\n        with torch.no_grad():\n            logits=model(x)\n        J=loss(logits,y)\n        losses2.append(J.item())\n        accuracy2.append(y.eq(logits.detach().argmax(dim=1)).float().mean()) \n        \n    print(f'Epoch {epoch+1}, valid loss: {torch.tensor(losses2).mean():.2f}, valid acc: {torch.tensor(accuracy2).mean():.2f}') \n    print()","787a6e05":"# MNIST Pytorch Linear Sample\nfrom 'Pytorch Lightning' YouTube Channel, 'Episode 1: Training a classification model on MNIST with PyTorch'<br\/>\nhttps:\/\/youtu.be\/OMDn66kM9Qc"}}