{"cell_type":{"45454dea":"code","b8064639":"code","a2669257":"code","ae160126":"code","6579dafe":"code","587b414f":"code","e275548b":"code","76542bdb":"code","766e4326":"code","8e0a4eac":"code","4105312e":"code","64d11b51":"code","b59a13bd":"code","833646ee":"code","dce2f83f":"markdown","9b8d6a0d":"markdown"},"source":{"45454dea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b8064639":"df = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf","a2669257":"df.describe()","ae160126":"df['diagnosis'] = (df['diagnosis'] == 'M').astype(int)","6579dafe":"df","587b414f":"df['diagnosis'].value_counts()","e275548b":"#We train the model, taking two features\n\nX = df[['compactness_mean','area_mean']]\ny = df[['diagnosis']]","76542bdb":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state =1)","766e4326":"import seaborn as sns\nsns.scatterplot(x='area_mean', y='compactness_mean', hue='diagnosis', data=X_test.join(y_test, how='outer') )","8e0a4eac":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score","4105312e":"accuracies = pd.DataFrame(columns=['neighbors','accuracy'])\naccuracies","64d11b51":"#Loop to iterate through the number of neighbours. We need to find out which number gives the best accuracy!\n\nfor i in range(1, 10):\n    \n    knn = KNeighborsClassifier(n_neighbors = i, metric='euclidean')\n    \n    knn.fit(X_train, y_train.values.ravel())\n    \n    pred = knn.predict(X_test)\n    \n    acc = accuracy_score(pred, y_test)\n    \n    new_row = {'neighbors':i, 'accuracy':acc}\n    \n    accuracies = accuracies.append(new_row, ignore_index=True)","b59a13bd":"accuracies","833646ee":"#Plotting neighbours against accuracy\n\nimport matplotlib.pyplot as plt\nplt.plot(accuracies.neighbors, accuracies.accuracy)","dce2f83f":" <div class=\"alert alert-info\" role=\"alert\">\n    \n It would be optimal to use n_neighbors=6 or n_neighors=8, if dealing with test data with the same features, in order to get the most accurate classification.\n \n <\/div>","9b8d6a0d":" <div class=\"alert alert-info\" role=\"alert\">\n    \n Here, we can see that our model's accuracy of classifying the cancer as malignant or benign is at its highest(0.867133) when the number of neighbours is 6 or 8.\n \n <\/div>"}}