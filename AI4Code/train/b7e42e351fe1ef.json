{"cell_type":{"0620cc81":"code","81e1ce52":"code","bf56d71c":"code","b9bcfe87":"code","3a584966":"code","aef49fbc":"code","3462743d":"code","d87b131f":"code","e251223f":"code","8850f4df":"code","17089b17":"markdown"},"source":{"0620cc81":"# Importing core libraries\nimport numpy as np\nimport pandas as pd\nfrom time import time\nimport pprint\nimport joblib\nfrom functools import partial\n\n# Suppressing warnings because of skopt verbosity\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Regressors\nimport lightgbm as lgb\n\n# Model selection\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\n# Metrics\nfrom sklearn.metrics import mean_squared_error\n\n# Data processing\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer","81e1ce52":"# Loading data \nX = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\")\nX_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")","bf56d71c":"# Preparing data as a tabular matrix\ny = X.target\nX = X.set_index('id').drop('target', axis='columns')\nX_test = X_test.set_index('id')","b9bcfe87":"# Stratifying the target\ny_stratified = pd.cut(y, bins=10, labels=False)","3a584966":"# Processing categoricals with frequency encoding\ncategoricals = [item for item in X.columns if 'cat' in item]\n\nfor cat in categoricals:\n    counts = dict(X[cat].value_counts() \/ len(X))\n    X[cat+'_freq'] = X[cat].replace(counts)\n    X_test[cat+'_freq'] = X_test[cat].replace(counts)\n    \nfrequencies = [cat+'_freq' for cat in categoricals]","aef49fbc":"# Dealing with categorical data\ncategoricals = [item for item in X.columns if 'cat' in item]\nordinal_encoder = OrdinalEncoder()\nX[categoricals] = ordinal_encoder.fit_transform(X[categoricals])\nX_test[categoricals] = ordinal_encoder.transform(X_test[categoricals])","3462743d":"# Transferring the best parameters to our basic regressor\n\nbest_params = dict([('colsample_bytree', 0.45),\n                    ('learning_rate', 0.01),\n                    ('max_depth', 8),\n                    ('min_child_samples', 83),\n                    ('min_child_weight', 8.7),\n                    ('n_estimators', 2700),\n                    ('num_leaves', 512),\n                    ('objective', 'tweedie'),\n                    ('reg_alpha', 0.005),\n                    ('reg_lambda', 1e-09),\n                    ('subsample', 0.46),\n                    ('subsample_freq', 2)])\n\n\nreg = lgb.LGBMRegressor(boosting_type='gbdt',\n                        verbose=-1,\n                        random_state=0,\n                        **best_params)","d87b131f":"# Cross-validation prediction\nfolds = 10\nskf = StratifiedKFold(n_splits=folds,\n                      shuffle=True, \n                      random_state=0)\n\npredictions = np.zeros(len(X_test))\nfor k, (train_idx, val_idx) in enumerate(skf.split(X, y_stratified)):\n    reg.fit(X.iloc[train_idx, :], y[train_idx])\n    val_preds = reg.predict(X.iloc[val_idx, :])\n    val_rmse = mean_squared_error(y_true=y[val_idx], y_pred=val_preds, squared=False)\n    print(f\"Fold {k} RMSE: {val_rmse:0.5f}\")\n    predictions += reg.predict(X_test).ravel()\n    \npredictions \/= folds","e251223f":"# Preparing the submission\nsubmission = pd.DataFrame({'id':X_test.index, \n                           'target': predictions})\n\nsubmission.to_csv(\"submission.csv\", index = False)","8850f4df":"submission","17089b17":"Another smart feature enginering is to encode your categorical using a raw or normalized frequency count (to be done only on the train set). This helps all algorithms in spotting rare feature levels and all the combinations that involve them. \n\nUsing frequency encoding your models will be able to estimate by themselves the confidence of using specific feature levels in their predictions."}}