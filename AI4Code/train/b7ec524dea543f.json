{"cell_type":{"15298be6":"code","25b86144":"code","69c53103":"code","640d2f00":"code","58f2c7ff":"code","8fc694ed":"code","bf946700":"code","15984c56":"code","ce220128":"code","d39c1872":"code","e08502be":"code","cab25651":"code","c5f18a1d":"code","d8ff3647":"code","fff35dc2":"code","3857d0de":"code","e4768cc3":"code","35aee1ee":"code","d9a45304":"code","ef77d071":"code","ee6d8935":"code","9d2f71f2":"code","39b8fac2":"code","7debf7c5":"code","423e9f92":"code","172e375b":"code","6fb392ee":"code","44ebdbf5":"code","2111b46e":"code","08979c2a":"code","1df893db":"code","a1eefba2":"code","4d52a4d3":"code","1fe4440f":"code","c96aafe7":"code","264aea25":"code","d16725e8":"code","84d8f461":"code","cf9b8305":"code","167b1873":"code","cadbfc5d":"code","7dd9e55d":"code","1b2d69d9":"code","6ce5f833":"code","9cf7479e":"code","cc1eb91c":"code","68a62b41":"code","df71717f":"code","f4e0a160":"code","0acd9e8d":"code","77aeb0b6":"code","14c463e5":"markdown","550c54e0":"markdown","53de56c8":"markdown","3768a31f":"markdown","bd0b1c44":"markdown","5f5e14b5":"markdown","29052c4a":"markdown","049f6d61":"markdown","571edb2c":"markdown","76869c47":"markdown","7d183167":"markdown","0b1cba78":"markdown","006443d4":"markdown","17b7cae6":"markdown","1995d27c":"markdown","89932d7c":"markdown","3109f3ef":"markdown","07c9d172":"markdown","6eb7314e":"markdown","62dbbb92":"markdown","3428d366":"markdown","d3c96828":"markdown","d672c540":"markdown","9f118c71":"markdown","bc1630ca":"markdown","d37c49d6":"markdown","fa150009":"markdown","561c912b":"markdown","f7b5c3a6":"markdown","3b6a44ef":"markdown","d926dff4":"markdown","1a5c2427":"markdown","6df580ab":"markdown","2f35ffad":"markdown","1ee9bdf4":"markdown","8924d87d":"markdown","ea3627f5":"markdown","c586a65c":"markdown","fdb6c442":"markdown","32700fb1":"markdown","45452fce":"markdown","e8c03acd":"markdown","38663ed6":"markdown","05ab15d4":"markdown","88f323f1":"markdown","b53f1500":"markdown","0c2a05a7":"markdown","0c050825":"markdown","ab540171":"markdown"},"source":{"15298be6":"# Import libraries\nimport os\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n\n# Read data from file,skip 2nd row which contains the decription\ndf = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\",skiprows=lambda x: x in [1]) \n\n#Store column names\ncol_df=df.columns\n\n#Creation of Segment variable based on Age group\ndf['Segment']= np.where(((df['Q1'] =='18-21') | (df['Q1'] =='22-24')), 'Gen Z', \n                        np.where(((df['Q1'] =='25-29') | (df['Q1'] =='30-34') | (df['Q1'] =='35-39')),'Gen Y',\n                        np.where(((df['Q1'] =='40-44') | (df['Q1'] =='45-49') | (df['Q1'] =='50-54')),'Gen X','Baby Boomers')))\n\n#Renaming th evalues of Q25 since output values in dataframe loses $ symbol\ndf['Q25']= np.where(df['Q25'] =='$0 ($USD)', '0 USD',\n                          np.where(df['Q25'] =='$1-$99','1 USD to 99 USD',\n                                   np.where(df['Q25'] =='$100-$999','100 USD to 9999 USD',\n                                           np.where(df['Q25'] =='$1000-$9,999','1000 USD to 9999 USD',\n                                                   np.where(df['Q25'] =='$10,000-$99,999','10K USD to 99999 USD',\n                                                           np.where(df['Q25'] =='$100,000 or more ($USD)','More than 100K USD',None))))))\n\n\n","25b86144":"#Data Preprocessing\n\n#There are two kinds of questions,questions with single choice selection and questions with multiple choice selection.\n\n#Single choice selection  questions are named as Non-Underscore columns(unscr_cols).For e.g Q1,Q2,etc\n#Multiple choice selection questions are named as Underscore columns(unscr_cols) For e.g (Q7_Part_1,Q7_Part_2,etc)\n#Supplemetary questions are names as supp_cols\n\nunscr_cols=[]\nfor i in col_df:\n    if i.find('_')>0:\n        unscr_pos=i.find('_')#Identifying Multiple choice question\n        cols=i[:unscr_pos]\n        unscr_cols.append(cols)\n\n#Remove duplicates\nfinal_unscr_cols = [] \nfor i in unscr_cols: \n    if i not in final_unscr_cols: \n        final_unscr_cols.append(i)\n\nnon_unscr_cols=[]\nfor i in col_df:\n    if i.find('_')<0 and len(i)<=4:#Identifying Single choice question where underscore won't be present and negative value be returned\n        cols=i\n        non_unscr_cols.append(cols) \n\n#Remove duplicates\nfinal_non_unscr_cols = [] \nfor i in non_unscr_cols: \n    if i not in final_non_unscr_cols: \n        final_non_unscr_cols.append(i) \n\n#All unique columns\nall_cols=final_non_unscr_cols+final_unscr_cols\n\n#Sort columns\nall_cols.sort(key=len)\n\nsupp_cols=[]\nfor i in col_df:\n    if i.find('_B_')>0:\n        cols=i\n        supp_cols.append(cols)  \n\nsupp_unscr_cols=[]\nfor i in df.columns:\n    if i.find('_B')>0:#Identifying supplementary column\n        supp_unscr_pos=i.find('_B')\n        cols=i[:supp_unscr_pos]\n        supp_unscr_cols.append(cols)\n        \n#Remove Supplementary column duplicates\nfinal_supp_unscr_cols = [] \nfor i in supp_unscr_cols: \n    if i not in final_supp_unscr_cols: \n        final_supp_unscr_cols.append(i)\n\n#Non Supplementary\nnon_supp_cols = [item for item in col_df if item not in supp_cols]\n\nstr1=\"df\"\nstr2=\"ovr_df\"\nstr3=\"seg_df\"\nstr4='cols'\nall_cols_df = [\"{}{}{}\".format(i,'_',str1) for i in all_cols]\nall_ovr_cols_df = [\"{}{}{}\".format(i,'_',str2) for i in all_cols]\nall_seg_cols_df = [\"{}{}{}\".format(i,'_',str3) for i in all_cols]\n\nnon_unscr_cols_list = [\"{}{}{}\".format(i,'_',str1) for i in final_non_unscr_cols]\nnon_unscr_ovr_cols_list = [\"{}{}{}\".format(i,'_',str2) for i in final_non_unscr_cols]\nnon_unscr_seg_cols_list = [\"{}{}{}\".format(i,'_',str3) for i in final_non_unscr_cols]\n\nunscr_cols_list = [\"{}{}{}\".format(i,'_',str1) for i in final_unscr_cols]\nunscr_ovr_cols_list = [\"{}{}{}\".format(i,'_',str2) for i in final_unscr_cols]\nunscr_seg_cols_list = [\"{}{}{}\".format(i,'_',str3) for i in final_unscr_cols]\n\n\nunscr_subs_cols_list = [\"{}{}\".format(i,'_') for i in final_unscr_cols]\nunscr_col_names_list = [\"{}{}{}\".format(i,'_',str4) for i in final_unscr_cols]\n\nsupp_unscr_subs_cols_list = [\"{}{}\".format(i,'_B_') for i in final_supp_unscr_cols]\nsupp_unscr_col_names_list = [\"{}{}{}\".format(i,'_B_',str4) for i in final_supp_unscr_cols]\n\nsupp_unscr_cols_list = [\"{}{}{}\".format(i,'_B_',str1) for i in final_supp_unscr_cols]\nsupp_unscr_ovr_cols_list = [\"{}{}{}\".format(i,'_B_',str2) for i in final_supp_unscr_cols]\nsupp_unscr_seg_cols_list = [\"{}{}{}\".format(i,'_B_',str3) for i in final_supp_unscr_cols]\n\n#Setting caption for the output tables for each question\nnon_unscr_desc={'Q1':'Age',\n                'Q2':'Gender',\n                'Q3':'Country',\n                'Q4':'Education',\n                'Q5':'Current Role',\n                'Q6':'Code Experience',\n                'Q8':'Recommended Programming Language',\n                'Q11':'Current Computing Platform',\n                'Q13':'Current TPU Usage Frequency',\n                'Q15':'Machine Learning Experience',\n                'Q20':'Size of The Company',\n                'Q21':'Data Science Team Size',\n                'Q22':'Machine Learning Adoption',\n                'Q24':'Current Yearly Compensation',\n                'Q25':'ML\/Cloud Computing Investment Past 5 years',\n                'Q30':'Current Big Data Usage',\n                'Q32':'Current BI Tool Usage',\n                'Q38':'Primary Tool for Data Analysis'\n                }\n\nunscr_desc= {   'Q7':'Regular Programming Language',\n                'Q9':'Regular IDE',\n                'Q10':'Regular Notebook Products',\n                'Q12':'Reguar Specialized Hardware',\n                'Q14':'Regular Visualization Tools\/Libraries',\n                'Q16':'Regular Machine Learning Frameworks',\n                'Q17':'Regular Machine Learning Algorithms',\n                'Q18':'Regular Computer Vision Methods',\n                'Q19':'Regular Natural Language Processing Methods',\n                'Q23':'Work Activities',\n                'Q26':'Regular Computing Platforms',\n                'Q27':'Regular Cloud Computing Products',\n                'Q28':'Regular Machine Learning Products',\n                'Q29':'Regular Big Data Products',\n                'Q31':'Regular BI Tools',\n                'Q33':'Regular AutoML Tools',\n                'Q34':'Regular AutoML Tools',\n                'Q35':'Tools to help ML Experiments',\n                'Q36':'Deploy Platform',\n                'Q37':'Datascience Courses Learning',\n                'Q39':'Favorite Media Sources'\n                }\n\nsupp_unscr_desc= { \n                'Q26':'Next 2 years Cloud Computing Platform',\n                'Q27':'Next 2 years Cloud Computing Products',\n                'Q28':'Next 2 years ML Products',\n                'Q29':'Next 2 years Big Data Products',\n                'Q31':'Next 2 years BI Tools',\n                'Q33':'Next 2 years AutoML Category Tools',\n                'Q34':'Next 2 years AutoML Specific Tools',\n                'Q35':'Next 2 years Manage ML Experiment Tools'\n                }","69c53103":"#Non-Underscore Columns Preprocessing(Single Choice Questions)\n\n#Overall Non Underscore columns\nnon_unscr_ovr_cols_df=pd.DataFrame(non_unscr_ovr_cols_list ,columns=['col'])\nnon_unscr_ovr_cols_dict = {elem : pd.DataFrame() for elem in non_unscr_ovr_cols_list}\n\nfor key in non_unscr_ovr_cols_dict.keys():\n    non_unscr_ovr_cols_dict[key] = non_unscr_ovr_cols_df[:][non_unscr_ovr_cols_df.col == key]\n\nfor key,i in zip(non_unscr_ovr_cols_dict.keys(),non_unscr_cols):\n    non_unscr_ovr_cols_dict[key]=df[i].value_counts(normalize=True,dropna=True).round(3).reset_index()\n    non_unscr_ovr_cols_dict[key].columns = [i,'Overall']       \n\n#Segment Non Underscore columns\nnon_unscr_seg_cols_df=pd.DataFrame(non_unscr_seg_cols_list,columns=['col'])\n\nnon_unscr_seg_cols_dict = {elem : pd.DataFrame() for elem in non_unscr_seg_cols_list}\n\nfor key in non_unscr_seg_cols_dict.keys():\n    non_unscr_seg_cols_dict[key] = non_unscr_seg_cols_df[:][non_unscr_seg_cols_df.col == key]\n\nfor key,i in zip(non_unscr_seg_cols_dict.keys(),non_unscr_cols):\n    non_unscr_seg_cols_dict[key]=pd.crosstab(df[i], df.Segment,dropna=True).apply(lambda r: (r\/r.sum()), axis=0).round(2).reset_index()\n\n#Combine Overall and Segment Non Underscore columns\nnon_unscr_cols_df=pd.DataFrame(non_unscr_cols_list,columns=['col'])\nnon_unscr_cols_dict = {elem : pd.DataFrame() for elem in non_unscr_cols_list}\nfor key in non_unscr_cols_dict.keys():\n    non_unscr_cols_dict[key] = non_unscr_cols_df[:][non_unscr_cols_df.col == key]\n    \nfor key,i,key_ovr,key_seg in zip(non_unscr_cols_dict.keys(),non_unscr_cols,non_unscr_ovr_cols_dict.keys(),non_unscr_seg_cols_dict.keys()):\n    non_unscr_cols_dict[key]=pd.merge(non_unscr_ovr_cols_dict[key_ovr], non_unscr_seg_cols_dict[key_seg],how='inner',on=i)\n\n#Final Non Underscore column\nnon_unscr_col_names_dict = {elem : [] for elem in final_non_unscr_cols}\nfor key,key2,val in zip(non_unscr_cols_dict.keys(),non_unscr_col_names_dict.keys(),non_unscr_desc.values()):\n    non_unscr_col_names_dict[key2]=non_unscr_cols_dict[key].style\\\n    .format({'Overall': \"{:.0%}\",'Baby Boomers': \"{:.0%}\",'Gen X': \"{:.0%}\",'Gen Y': \"{:.0%}\",'Gen Z': \"{:.0%}\"})\\\n    .background_gradient(cmap='Blues',axis=1)\\\n    .set_properties(**{'text-align': 'center'})\\\n    .set_caption(val)\\\n    .set_table_styles([{\n        'selector': 'caption',\n        'props': [\n        ('color', 'black'),\n        ('font-size', '18px')\n        ]\n        }])\\\n    .hide_index()","640d2f00":"#Underscore Columns Preprocessing(Multiple choice questions)\n\n#Storing Underscore column names in the dict\nunscr_subs_col_names_dict = {elem : [] for elem in unscr_col_names_list}\nfor key,i in zip(unscr_subs_col_names_dict.keys(),unscr_subs_cols_list):\n    unscr_subs_col_names_dict[key] = [col for col in non_supp_cols if i in col]\n\n#Overall Underscore columns\nunscr_ovr_cols_dict = {elem : pd.DataFrame() for elem in unscr_ovr_cols_list}\nfor key,value,j in zip(unscr_ovr_cols_dict.keys(),unscr_subs_col_names_dict.values(),final_unscr_cols) :\n    for i in value:\n        tmp=pd.DataFrame(df[i].value_counts().rename_axis(j).reset_index(name='Overall'))\n        unscr_ovr_cols_dict[key]=pd.concat([unscr_ovr_cols_dict[key],tmp],ignore_index=True)\n        unscr_ovr_cols_dict[key]=unscr_ovr_cols_dict[key].sort_values(by=['Overall'], ascending=False)\n    unscr_ovr_cols_dict[key]['Overall']=(unscr_ovr_cols_dict[key]['Overall']\/len(df))\n    \n#Segment Underscore columns\nunscr_seg_cols_dict = {i : pd.DataFrame(columns=[j,'Baby Boomers','Gen X','Gen Y','Gen Z']) for i,j in zip(unscr_seg_cols_list,final_unscr_cols)}\n\nfor key,value,j in zip(unscr_seg_cols_dict.keys(),unscr_subs_col_names_dict.values(),final_unscr_cols) :\n    for i in value:\n        tmp=pd.crosstab(df[i],df['Segment']).rename_axis(j).reset_index()\n        unscr_seg_cols_dict[key]=pd.concat([unscr_seg_cols_dict[key],tmp],ignore_index=True)\n\ncols = ['Baby Boomers','Gen X','Gen Y','Gen Z']\nfor key in unscr_seg_cols_dict.keys():\n    for i in cols:\n        unscr_seg_cols_dict[key][i]  = (unscr_seg_cols_dict[key][i]\/(len(df[df.Segment== i]))).apply(pd.to_numeric, errors='coerce')\n\n#Combine Overall and Segment Underscore columns\nunscr_cols_dict = {elem : pd.DataFrame() for elem in unscr_cols_list}\nfor key,i,key_ovr,key_seg in zip(unscr_cols_dict.keys(),final_unscr_cols,unscr_ovr_cols_dict.keys(),unscr_seg_cols_dict.keys()):\n    unscr_cols_dict[key]=pd.merge(unscr_ovr_cols_dict[key_ovr], unscr_seg_cols_dict[key_seg],how='inner',on=i)\n\n#Final Underscore Columns Non Supplementary\nunscr_col_names_dict = {elem : [] for elem in final_unscr_cols}\nfor key,key2,val in zip(unscr_cols_dict.keys(),unscr_col_names_dict.keys(),unscr_desc.values()):\n    unscr_col_names_dict[key2]=unscr_cols_dict[key].style\\\n    .format({'Overall': \"{:.0%}\",'Baby Boomers': \"{:.0%}\",'Gen X': \"{:.0%}\",'Gen Y': \"{:.0%}\",'Gen Z': \"{:.0%}\"})\\\n    .background_gradient(cmap='Blues',axis=1)\\\n    .set_properties(**{'text-align': 'center'})\\\n    .set_caption(val)\\\n    .set_table_styles([{\n        'selector': 'caption',\n        'props': [\n        ('color', 'black'),\n        ('font-size', '18px')\n        ]\n        }])\\\n    .hide_index()","58f2c7ff":"#Supplementary columns Pre-processing\n\n#Storing Supplementary column names in the dict\nsupp_unscr_subs_col_names_dict = {elem : [] for elem in supp_unscr_col_names_list}\nfor key,i in zip(supp_unscr_subs_col_names_dict.keys(),supp_unscr_subs_cols_list):\n    #print(key,i)\n    supp_unscr_subs_col_names_dict[key] = [col for col in supp_cols if i in col]\n\n#Overall Underscore Supplementary columns\nsupp_unscr_ovr_cols_dict = {elem : pd.DataFrame() for elem in supp_unscr_ovr_cols_list}\n\nfor key,value,j in zip(supp_unscr_ovr_cols_dict.keys(),supp_unscr_subs_col_names_dict.values(),final_supp_unscr_cols) :\n    for i in value:\n        tmp=pd.DataFrame(df[i].value_counts().rename_axis(j).reset_index(name='Overall'))\n        supp_unscr_ovr_cols_dict[key]=pd.concat([supp_unscr_ovr_cols_dict[key],tmp],ignore_index=True)\n        supp_unscr_ovr_cols_dict[key]=supp_unscr_ovr_cols_dict[key].sort_values(by=['Overall'], ascending=False)\n    supp_unscr_ovr_cols_dict[key]['Overall']=(supp_unscr_ovr_cols_dict[key]['Overall']\/len(df))\n\n#Segment Underscore Supplementary columns\nsupp_unscr_seg_cols_dict = {i : pd.DataFrame(columns=[j,'Baby Boomers','Gen X','Gen Y','Gen Z']) for i,j in zip(supp_unscr_seg_cols_list,final_supp_unscr_cols)}\n\nfor key,value,j in zip(supp_unscr_seg_cols_dict.keys(),supp_unscr_subs_col_names_dict.values(),final_supp_unscr_cols) :\n    for i in value:\n        tmp=pd.crosstab(df[i],df['Segment']).rename_axis(j).reset_index()\n        supp_unscr_seg_cols_dict[key]=pd.concat([supp_unscr_seg_cols_dict[key],tmp],ignore_index=True)\n\ncols = ['Baby Boomers','Gen X','Gen Y','Gen Z']\nfor key in supp_unscr_seg_cols_dict.keys():\n    for i in cols:\n        supp_unscr_seg_cols_dict[key][i]  = (supp_unscr_seg_cols_dict[key][i]\/(len(df[df.Segment== i]))).apply(pd.to_numeric, errors='coerce')\n\n#Combine Overall and Segment Underscore Supplementary columns\nsupp_unscr_cols_dict = {elem : pd.DataFrame() for elem in supp_unscr_cols_list}\nfor key,i,key_ovr,key_seg in zip(supp_unscr_cols_dict.keys(),final_supp_unscr_cols,supp_unscr_ovr_cols_dict.keys(),supp_unscr_seg_cols_dict.keys()):\n    supp_unscr_cols_dict[key]=pd.merge(supp_unscr_ovr_cols_dict[key_ovr], supp_unscr_seg_cols_dict[key_seg],how='inner',on=i)\n\n#Final Supplementary columns\nsupp_unscr_col_names_dict = {elem : [] for elem in final_supp_unscr_cols}\nfor key,key2,val in zip(supp_unscr_cols_dict.keys(),supp_unscr_col_names_dict.keys(),supp_unscr_desc.values()):\n    supp_unscr_col_names_dict[key2]=supp_unscr_cols_dict[key].style\\\n    .format({'Overall': \"{:.0%}\",'Baby Boomers': \"{:.0%}\",'Gen X': \"{:.0%}\",'Gen Y': \"{:.0%}\",'Gen Z': \"{:.0%}\"})\\\n    .background_gradient(cmap='Blues',axis=1)\\\n    .set_properties(**{'text-align': 'center'})\\\n    .set_caption(val)\\\n    .set_table_styles([{\n        'selector': 'caption',\n        'props': [\n        ('color', 'black'),\n        ('font-size', '18px')\n        ]\n        }])\\\n    .hide_index()","8fc694ed":"g=sns.color_palette(\"Blues_r\")\nax = sns.countplot(y=\"Segment\", data=df,order = df['Segment'].value_counts().index,palette=g)\n#\"#3498db\"\n\n#plt.title('Generation Distribution')\n#plt.xlabel('Segment')\nsns.set(rc={'figure.figsize':(13,5)})\ntotal = len(df['Segment'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\nsns.set_style(\"white\")\nsns.despine()\n\nplt.show()","bf946700":"display(non_unscr_col_names_dict['Q2'])","15984c56":"non_unscr_col_names_dict['Q3']","ce220128":"non_unscr_col_names_dict['Q4']","d39c1872":"non_unscr_col_names_dict['Q5']","e08502be":"non_unscr_col_names_dict['Q6']","cab25651":"non_unscr_col_names_dict['Q24']","c5f18a1d":"unscr_col_names_dict['Q36']","d8ff3647":"unscr_col_names_dict['Q37']","fff35dc2":"unscr_col_names_dict['Q39']","3857d0de":"unscr_col_names_dict['Q7']","e4768cc3":"non_unscr_col_names_dict['Q8']","35aee1ee":"unscr_col_names_dict['Q9']","d9a45304":"unscr_col_names_dict['Q10']","ef77d071":"non_unscr_col_names_dict['Q11']","ee6d8935":"unscr_col_names_dict['Q12']","9d2f71f2":"non_unscr_col_names_dict['Q13']","39b8fac2":"unscr_col_names_dict['Q14']","7debf7c5":"non_unscr_col_names_dict['Q15']","423e9f92":"unscr_col_names_dict['Q16']","172e375b":"unscr_col_names_dict['Q17']","6fb392ee":"unscr_col_names_dict['Q18']","44ebdbf5":"unscr_col_names_dict['Q19']","2111b46e":"unscr_col_names_dict['Q26']","08979c2a":"unscr_col_names_dict['Q27']","1df893db":"unscr_col_names_dict['Q28']","a1eefba2":"unscr_col_names_dict['Q29']","4d52a4d3":"non_unscr_col_names_dict['Q30']","1fe4440f":"unscr_col_names_dict['Q31']","c96aafe7":"non_unscr_col_names_dict['Q32']","264aea25":"unscr_col_names_dict['Q33']","d16725e8":"unscr_col_names_dict['Q34']","84d8f461":"unscr_col_names_dict['Q35']","cf9b8305":"non_unscr_col_names_dict['Q38']","167b1873":"supp_unscr_col_names_dict['Q26']","cadbfc5d":"supp_unscr_col_names_dict['Q27']","7dd9e55d":"supp_unscr_col_names_dict['Q28']","1b2d69d9":"supp_unscr_col_names_dict['Q29']","6ce5f833":"supp_unscr_col_names_dict['Q31']","9cf7479e":"supp_unscr_col_names_dict['Q33']","cc1eb91c":"supp_unscr_col_names_dict['Q34']","68a62b41":"supp_unscr_col_names_dict['Q35']","df71717f":"non_unscr_col_names_dict['Q20']","f4e0a160":"non_unscr_col_names_dict['Q21']","0acd9e8d":"non_unscr_col_names_dict['Q22']","77aeb0b6":"non_unscr_col_names_dict['Q25']","14c463e5":"1. Men in Baby Boomer's Segment is over-indexed(more compared to Overall) whereas Women are under-indexed (are very less compared to Overall).\n1. Women in Gen Z are more interested in ML & DS when compared to Overall ","550c54e0":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTableau,PowerBI and Google data studio are the career goals of the non-professionals in the next 2 years in Big Data Products.","53de56c8":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nSeaborn and Matplotlib are the mostly used Visualization libraries followed by Plotly and GGplot\n","3768a31f":"\n# Demographics","bd0b1c44":"Gen Z is more interested in GPUs and Baby boomers are not much inclined towards GPU","5f5e14b5":"# Generation Distribution","29052c4a":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n1. Kaggle,Youtube and Blogs are the top three favorite Media Sources by Users\n1. Baby Boomers are versatile as they are over indexed in learning from media sources such as Kaggle,Email newsletters,Journals,Forums\n","049f6d61":"The age group of each generation mostly correlates with the years of ML experience with each Segment","571edb2c":"Gen Y((Age group: 25 to 39) composition is the highest compared to any other segments","76869c47":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. Gen Z-Jupyter,Visual Studio Code, Pycharm and Spyder are over indexed compared to overall which indicates that Gen Z are more into Python\n2. Baby Boomer-R Studio,Notepad++ and Visual Studio are over indexed  compared to overall\n\nHypothesis:\nYounger generation inclined towards Python and Older generation inclined towards Non-Python languages","7d183167":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTableau is the most regulary used BI tool","0b1cba78":"None is highly over indexed for Baby Boomer which has association in Other Programming language,might be the reason for choosing None ","006443d4":"# Usage","17b7cae6":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n1. Github,Kaggle and Colab are the mostly shared platforms by users\n1. Gen X and Gen Y are over indexed in platforms-Github and Kaggle.\n1. Baby boomers are quite closed in terms of sharing","1995d27c":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. AWS,GCP and Microsoft Azure are the career goals of the non-professionals in the next 2 years\n1. Gen Z is over indexed here as they are hungry to learn everything","89932d7c":"Overall 36%,No-Investment has been done in ML or Cloud computing","3109f3ef":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nGen X is over-indexing in most of the cloud computing products.\n\nHypothesis:\nGen X is cloud centric","07c9d172":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTensorBoard is one of the major tools used to help ML experiments","6eb7314e":"Overall ML Usage is less(17%+16%=33%) and most of them involved in Non-ML usecases in their type of work","62dbbb92":"****Objective:**** \nTo study the behavior of various ^generations such as\n* Baby Boomers(Age group: 55 to 70+)\n* Gen X(Age group: 40 to 54)\n* Gen Y(Age group: 25 to 39)\n* Gen Z(Age group: 18 to 24)\n\nwith respect to\n\n1. Demographics\n2. User Profile\n3. Usage\n4. Data Science and ML Career Goal\n5. Organisation\n\n****Reference:****\nThe segmentation of age groups to various generation names has no thumb rule but has been inspired from the link ^[here](https:\/\/www.kasasa.com\/articles\/generations\/gen-x-gen-y-gen-z).\n","3428d366":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. Python is the most recommended programming language\n1. Baby boomers are more incllined in recommending R","d3c96828":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. Baby boomers-Over indexed in CNN,Bayesian Approaches and RNN,this migh be becsause of engagement in Deep Learning\n2. Gen X-Over indexed in Linear\/Logistic Regression,Decision Tree\/Random Forest,GBM","d672c540":"\n1. In India,Gen Z is highly over indexed and Baby Boomers are under indexed which indicates that young age group from India are highly interested in ML & DS whereas the Senior most citizens are less inclined\n2. In US,unlike India Baby Boomers are more interested in ML & DS whereas Gen Z is not much inclined.\n\nHypotheses:\n* Gen Z of India more interested in DS & ML compared to Gen Z of US\n* Marketing Campaigns of Data Science and ML to lure Gen Z of India is more compared to Gen Z of US\n* More diversified opportunities for Gen Z in US compared to less diversified opportunites to Gen Z in India","9f118c71":"1. Users with less than $1000 is 20% which is quite higher than any of the income groups.\n1. Gen Z comprises the youngest age group so it is obvious that they reside in the lowest income group.","bc1630ca":"1. Gen Z-Over indexed in MySQL and Mongodb \n2. Gen X-Over indexed in PostgresSQL and Oracle Database\n3. Baby Boomer-Over indexed in Microsoft SQl server and DB2","d37c49d6":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nGoogle cloud computing products are the  career goals of the non-professionals in the next 2 years.\n\nHypothesis:\nSkill updated with AWS so planning to upgrade skills to Google's products\n","fa150009":"Scikit-learn is the most regular machine learin framework","561c912b":"1. Gen Z higher indexed in 0-49 employees size company\n2. Gen X higher indexed in 10,000 or more employees size company","f7b5c3a6":"The age group of each generation mostly correlates with the years of code experience with each Segment","3b6a44ef":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\n1. Gen Z is over-indexed in Python,C++,Java and C compared to Overall\n2. Gen X is over-indexed in R, SQL and Bash compared to Overall\n3. Baby boomers is over-indexed in R and highly over indexed in Other,would be interesting to know what are the other programming languages,SAS,SPSS are not mentioned so Others might be becasue of that","d926dff4":"1. Master's degree education of Gen Y is over indexed compared to Overall\n2. Gen Z is the youngest group so it is logical that Bachelor's degree is more in that segment\n3. Doctoral degree education of Baby Boomer is over indexed compared to Overall","1a5c2427":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n1. Coursera,Kaggle and Udemy are the top three learning platforms utilized by Users\n1. Baby boomers over indexed in edX specifically","6df580ab":"# Data Science and Machine Learning Career Goal","2f35ffad":"CNN architectures are the most regular Computer vision methods used","1ee9bdf4":"# Organization","8924d87d":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTPU usage is still in nascent stage as most of the segments have never used it","ea3627f5":"Word embeddings\/vectors are the most regular Computer vision methods used","c586a65c":"MySQL, PostgresSQL and Micrsoft SQl are the most used big data products\n\nHive SQL,Teradata not present in options?","fdb6c442":"# Summary\n\n**Baby Boomers:**\n* Men involved in ML &DS is higher whereas Women in the same segment is least involved\n* People with Other Job role and Unemployed are interested in ML & DS\n* In India, they are under indexed which indicates that the Senior most citizens are less inclined towards ML &DS\n* In US, unlike India, they are more interested in ML & DS \n* Doctoral degree education is over indexed compared to Overall, which indicates that most of them are highly qualified\n* Quite closed in terms of sharing\n* Their choice of learning platform in edX is highly indexed\n* They are over indexed in learning from media sources such as Kaggle, Email newsletters, Journals, Forums.\n* Baby boomers are more inclined in recommending R\n* They don\u2019t use regular Notebook Products as they are mainly R users and would work in localR Studio environment\n* They are not much inclined towards GPU\n* Over indexed in engagement in Deep Learning\n* Over indexed in Big data products- Microsoft SQL server and DB2\n* Some respondents of Baby boomers are Over indexed in Statistical Softwares(SPSS,SAS) and under indexed in Local development environments\n\n**Gen X:**\n* Software Engineers of Gen X is more inclined towards ML & DS when compared to Overall\n* Over indexed in platforms-Github and Kaggle\n* over-indexed in R, SQL and Bash compared to Overall\n* Over indexed in Linear\/Logistic Regression, Decision Tree\/Random Forest,GBM\n* Over-indexing in most of the cloud computing products, which shows that they are cloud centric\n* Over indexed in PostgresSQL and Oracle Database\n* Over indexed in 10,000 or more employees size company\n\n\n**Gen Y:**\n* Highest composition of the segment in the survey and these folks are **Millennials**\n* Master's degree education of Gen Y is over indexed compared to Overall\n* Over indexed in platforms-Github and Kaggle\n* The %response of Gen Y with respect to questions mostly aligns with Overall%, that is the reason they are neither over indexed nor under indexed\n\n**Gen Z:**\n* Women in Gen Z are more interested in ML & DS when compared to Overall\n* In India, Gen Z is highly over indexed which indicates that young age group from India are highly interested in ML & DS\n* In US, they are not much inclined towards ML & DS\n* It is the youngest group so it is logical to find more of them either pursuing\/completed Bachelor's degree \n* They are the youngest age group with little experience so it is obvious that they reside in the lowest income group\n* Over-indexed in Programming Languages-Python, C++, Java and C\n* Jupyter,Visual Studio Code, Pycharm and Spyder are over indexed compared to overall which indicates that Gen Z are more into Python\n* More interested in GPUs\n* Over indexed in MySQL and Mongodb\n* Over indexed in all the technologies present in \u201cNext 2 years Cloud Computing Platform\u201d as they are hungry to learn everything\n* Google cloud computing products are the career goals of the non-professionals in the next 2 years.\n* Over indexed in 0-49 employees size company\n\n","32700fb1":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nMySQL,Mongodb and PostgresSQL are the career goals of the non-professionals in the next 2 years in Big Data Products.","45452fce":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nAWS,GCP and Azure are the regulary used computing platforms","e8c03acd":"The overall data science team size is 0 which indicates that most of them could be Independent contributors","38663ed6":"AutoML tools are not being used majorly","05ab15d4":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nTableau and Microsoft power BI are mostly the currently used BI Tools","88f323f1":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nPersonal laptop\/computer is majorly used as the current computing platform","b53f1500":"1. Local development environment and Basic Statistical software are mostly the primary tool used for data analysis\n1. Baby Boomers over indexed in Stastical Softwares(SPSS,SAS) and under indexed in Local development environments ","0c2a05a7":"1. Software Engineers of Gen X is more inclined towards Ml & DS when compared to Overall\n2. People with Other Job role and Unemployed of Baby Boomers are interested in ML & DS","0c050825":"*Please Note the columns wouldn't add to 100% as multiple choices can be selected by a respondent*.\n\nNo regular machine learing products used by the Segments","ab540171":"# User Profile"}}