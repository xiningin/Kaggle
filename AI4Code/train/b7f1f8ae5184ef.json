{"cell_type":{"b5acc41a":"code","cd70b677":"code","d46bd37e":"code","74c24ebd":"code","75222958":"code","c62a7914":"code","0ed424db":"code","99ddf495":"code","111e3a05":"code","f8f962ce":"code","1d61fc85":"code","4bd4858c":"code","fc748c7a":"code","8763aa0e":"code","cd24aa43":"code","7de89149":"code","d54c569e":"code","dc9d4b6e":"code","b6048916":"code","71e85677":"code","11293f04":"code","4dfec949":"code","252d200c":"code","3620a0ec":"code","8d617932":"code","42b3682d":"code","4d67aff5":"code","d96e9ba4":"code","f54e35cc":"code","08e63ada":"code","1461ce99":"code","457beb56":"code","c8d8b8d5":"code","5bffcae3":"code","ef6b86fe":"code","d58985fe":"code","d122482d":"code","8cc3d204":"code","77bc1284":"code","9ccfc261":"code","8bc6d6a8":"code","c58f76a8":"code","8fe64fd2":"code","abb48bad":"code","89d52dbc":"code","3702ee26":"code","dd525778":"code","69263ebe":"code","dd227033":"code","82e0b8f5":"code","aa66903d":"code","6af816cb":"code","0c0c4d08":"code","e0929cda":"code","795bc4b0":"code","6598114d":"code","5637ea48":"code","4f1dfaff":"code","c22eaf1d":"code","732b616f":"code","3afa2ed4":"code","4e16bbad":"code","1362b0c4":"code","fd1897a2":"code","c687f78c":"code","ba4aa848":"code","74b41c3e":"markdown","7fbd8306":"markdown","6339d2ac":"markdown","17d22490":"markdown","695e4b32":"markdown","8a222729":"markdown","886ddf9d":"markdown","a995ab21":"markdown","b80a2489":"markdown","5ec0f138":"markdown","355741b6":"markdown","e4b6c8b4":"markdown","5abafcdb":"markdown"},"source":{"b5acc41a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cd70b677":"import pandas as pd\nfrom pandas import DataFrame, Series\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\n\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n","d46bd37e":"df1 = pd.read_csv('..\/input\/chocolate-bar-ratings\/flavors_of_cacao.csv')","74c24ebd":"df1.head(10)","75222958":"df1.columns","c62a7914":"#renaming the column\ndf1.rename({'Company\\xa0\\n(Maker-if known)':'Company','Specific Bean Origin\\nor Bar Name':'Bar_Origin','Review\\nDate':'Review_Year','Cocoa\\nPercent':'Cocoa_Percent','Company\\nLocation':'Company_Location','Bean\\nType':'Bean_Type','Broad Bean\\nOrigin':'Bean_Origin'},axis=1,inplace=True)\ndf1.head()","0ed424db":"df1.shape","99ddf495":"df1.info()","111e3a05":"df1.drop_duplicates()","f8f962ce":"# And modify data types\n\ndf1.Cocoa_Percent=df1.Cocoa_Percent.str.replace('%','')\ndf1.Cocoa_Percent=df1.Cocoa_Percent.astype('float64')\ndf1.Cocoa_Percent = (df1.Cocoa_Percent.values)\/100   \n\n#Alternative \n#df1['Cocoa_Percent'] = df1['Cocoa_Percent'].str.replace('%','').astype(float)\/100\n\ndf1.head()\n","1d61fc85":"#categorical features\ncategorical = df1.select_dtypes(include =[np.object])\nprint(\"Categorical Features in Train Set:\",categorical.shape[1])\n\n#numerical features\nnumerical= df1.select_dtypes(include =[np.float64,np.int64])\nprint(\"Numerical Features in Train Set:\",numerical.shape[1])","4bd4858c":"df1['Rating'].unique()","fc748c7a":"df1['Rating'].value_counts()","8763aa0e":"#Rounding the Rating\n\ndef rounded(rating):\n    if (rating < 1 ):\n        return 0\n    elif (rating > 0 ) and (rating < 2 ):\n        return 1\n    elif (rating >= 2 ) and (rating < 3 ):\n        return 2\n    elif (rating >= 3 ) and (rating < 4 ):\n        return 3\n    elif (rating >= 4 ) and (rating < 5 ):\n        return 4\n    else:\n        return 5\n    \ndf1['Rating']=df1['Rating'].map(rounded)\n\nprint(df1['Rating'].unique())","cd24aa43":"df1['Rating'].value_counts()","7de89149":"# Data cleaning the Company column\n\nprint(df1['Company'].unique())","d54c569e":"df1['Company'].replace('Na\ufffdve','Naive',inplace=True)\nprint(df1['Company'].unique())","dc9d4b6e":"# Data cleaning the Company_Location column\n\nprint(df1['Company_Location'].unique())","b6048916":"df1['Company_Location'].replace({'Domincan Republic':'Dominican Republic','Niacragua':'Nicaragua','Eucador':'Ecuador'},inplace=True)\nprint(df1['Company_Location'].unique())","71e85677":"# Data cleaning the Bar Origin column\n\nprint(df1['Bar_Origin'].unique())","11293f04":"df1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split(',')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('\/')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('*')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('.')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('+')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split(';')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('-')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('(')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('#')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('1')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('2')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('3')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('4')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('5')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('6')[0])\ndf1['Bar_Origin'] = df1['Bar_Origin'].map(lambda x: x.split('7')[0])\nprint (df1['Bar_Origin'].unique())","4dfec949":"# Data cleaning the Bean Type column\n\nprint(df1['Bean_Type'].unique())","252d200c":"df1['Bean_Type'].replace('Forastero (Arriba) ASSS', 'Forastero',inplace=True)\ndf1['Bean_Type'].replace('Forastero (Arriba) ASS', 'Forastero',inplace=True)\ndf1['Bean_Type'].replace('Forastero (Arriba)', 'Forastero',inplace=True)\ndf1['Bean_Type'].replace('Forastero (Nacional)', 'Forastero',inplace=True)\ndf1['Bean_Type'].replace('Criollo, +','Criollo',inplace=True)\ndf1['Bean_Type'].replace('Blend-Forastero,Criollo','Blend',inplace=True)\ndf1['Bean_Type'].replace('Forastero(Arriba, CCN)','Forastero',inplace=True)\ndf1['Bean_Type'].replace('Forastero (Amelonado)','Forastero',inplace=True)\ndf1['Bean_Type'].replace('Trinitario, Nacional','Trinitario',inplace=True)\ndf1['Bean_Type'].replace('Trinitario (Amelonado)','Trinitario',inplace=True)\ndf1['Bean_Type'].replace('Trinitario, TCGA','Trinitario',inplace=True)\ndf1['Bean_Type'].replace('Criollo (Amarru)','Criollo',inplace=True)\ndf1['Bean_Type'].replace('Criollo, Trinitario','Blend',inplace=True)\ndf1['Bean_Type'].replace('Criollo (Porcelana)','Criollo',inplace=True)\ndf1['Bean_Type'].replace('Trinitario (85% Criollo)','Blend',inplace=True)\ndf1['Bean_Type'].replace('Forastero (Catongo)','Forastero',inplace=True)\ndf1['Bean_Type'].replace('Forastero (Parazinho)','Forastero',inplace=True)\ndf1['Bean_Type'].replace('Trinitario, Criollo','Blend',inplace=True)\ndf1['Bean_Type'].replace('Criollo (Ocumare)','Criollo',inplace=True)\ndf1['Bean_Type'].replace('Criollo (Ocumare 61)','Criollo',inplace=True)\ndf1['Bean_Type'].replace('Criollo (Ocumare 77)','Criollo',inplace=True)\ndf1['Bean_Type'].replace('Criollo (Ocumare 67)','Criollo',inplace=True)\ndf1['Bean_Type'].replace('Criollo (Wild)','Criollo',inplace=True)\ndf1['Bean_Type'].replace('Trinitario, Forastero','Blend',inplace=True)\ndf1['Bean_Type'].replace('Trinitario (Scavina)','Trinitario',inplace=True)\ndf1['Bean_Type'].replace('Criollo, Forastero','Blend',inplace=True)\ndf1['Bean_Type'].replace('Forastero, Trinitario','Blend',inplace=True)\ndf1.replace('\\xa0','Unkown',inplace=True)\ndf1['Bean_Type'].replace(np.nan,'Unkown',inplace=True)\n\nprint (df1['Bean_Type'].unique())","3620a0ec":"def bean_type(bean):\n    if bean =='Unkown':\n        return 'Unkown'\n    elif bean == 'Criollo':\n        return 'Criollo'\n    elif bean == 'Trinitario':\n        return 'Trinitario'\n    elif bean == 'Forastero':\n        return 'Forastero'\n    elif bean =='Blend':\n        return 'Blend'\n    else:\n        return 'Other'\n\ndf1['Bean_Type']=df1['Bean_Type'].map(bean_type)\ndf1['Bean_Type'].unique()","8d617932":"# Data cleaning the Bean Origin column\n\nprint(df1['Bean_Origin'].unique())","42b3682d":"df1['Bean_Type'].value_counts()","4d67aff5":"df1['Bean_Origin'] = df1['Bean_Origin'].replace('Domincan Republic', 'Dominican Republic')\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace('Carribean(DR\/Jam\/Tri)', 'Carribean')\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace('Trinidad-Tobago', 'Trinidad, Tobago')\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"Peru, Mad., Dom. Rep.\", \"Peru, Madagascar, Dominican Republic\")\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"Central and S. America\", \"Central and South America\")\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"PNG, Vanuatu, Mad\", \"Papua New Guinea, Vanuatu, Madagascar\")\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"Ven., Trinidad, Mad.\", \"Venezuela, Trinidad, Madagascar\")\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"Ven.,Ecu.,Peru,Nic.\", \"Venezuela, Ecuador, Peru, Nicaragua\")\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"Ven, Trinidad, Ecuador\",\"Venezuela, Trinidad, Ecuador\")\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"Ghana, Domin. Rep\", \"Ghana, Dominican Republic\")\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"Ecuador, Mad., PNG\",\"Ecuador, Madagascar, Papua New Guinea\")\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"Mad., Java, PNG\",\"Madagascar, Java, Papua New Guinea\")\ndf1['Bean_Origin'] = df1['Bean_Origin'].replace(\"Gre., PNG, Haw., Haiti, Mad\", \"Grenada, Papua New Guinea, Hawaii, Haiti, Madagascar\")\nprint (df1['Bean_Origin'].unique())","d96e9ba4":"df1['Bean_Origin'].value_counts()","f54e35cc":"#checking the null value\n\ndf1.replace({'Unkown':np.nan,},inplace=True)","08e63ada":"df1.isnull().sum()","1461ce99":"# filling the missing values with most frequent values in beanType Country\ndf1.Bean_Type.fillna(df1.Bean_Type.mode()[0], inplace=True)\ndf1.Bean_Origin.fillna(df1.Bean_Origin.mode()[0], inplace=True)\n","457beb56":"df1.isnull().sum()","c8d8b8d5":"df1.skew()","5bffcae3":"df1.head()","ef6b86fe":"plt.figure(figsize=(10,6))\n\nsns.countplot(x = df1['Review_Year'])\nplt.plot()","d58985fe":"plt.figure(figsize=(15,4))\nsns.countplot('Cocoa_Percent', data=df1, palette='ocean')\nplt.show()","d122482d":"sns.distplot(df1.Cocoa_Percent)\nplt.show()","8cc3d204":"sns.boxplot(x=df1.Cocoa_Percent)\nplt.show()\n","77bc1284":"plt.figure(figsize=(8,4))\nsns.countplot('Rating', data=df1, palette='ocean')\nplt.show()","9ccfc261":"plt.figure(figsize=(8,4))\nsns.countplot('Review_Year', data=df1, palette='ocean')\nplt.show()","8bc6d6a8":"sns.distplot(df1.Review_Year)\nplt.show()","c58f76a8":"sns.boxplot(x=df1.Review_Year)\nplt.show()\n","8fe64fd2":"sns.countplot(df1['Bean_Type'])\nplt.show()","abb48bad":"plt.figure(figsize=(20,30))\ndf1['Bean_Origin'].value_counts().plot(kind='barh')\nplt.xticks(rotation=90)\nplt.xlabel('Count')\nplt.title(\"Bean Origin\")\nplt.show()","89d52dbc":"df1.hist()\nplt.show()","3702ee26":"sns.pairplot(df1,hue='Rating')\nplt.show()","dd525778":"plt.figure(figsize=(8,4))\nsns.heatmap(df1.corr(),annot=True)\nplt.show()","69263ebe":"df1.head()","dd227033":"#By Using labelEncoder for Train\n\nfrom sklearn.preprocessing import LabelEncoder\ncol = ['Company', 'Bar_Origin', 'Company_Location', 'Bean_Type', 'Bean_Origin']\nle = LabelEncoder()\nfor LE in col:\n    df1[LE] = le.fit_transform(df1[LE])\n    \n\n","82e0b8f5":"df1.head()","aa66903d":"plt.figure(figsize=(10,6))\nsns.heatmap(df1.corr(),annot=True)\nplt.show()","6af816cb":"#dependent and independent variables\n\nX=df1.drop(['Rating'],axis=1)      #independent variable\n\ny=df1['Rating']                    #dependent variable\n\nX.head()","0c0c4d08":"#Scaling the independent variable to bring data in one range \n\nfrom sklearn.preprocessing import StandardScaler\nSS=StandardScaler()","e0929cda":"X=SS.fit_transform(X)\nX","795bc4b0":"#splitting the data into train(75%) and test(25%) for model\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)","6598114d":"X_train.shape","5637ea48":"y_train.shape","4f1dfaff":"X_test.shape","c22eaf1d":"y_test.shape","732b616f":"# Using RandomForestClassifier \n\nfrom sklearn.ensemble import RandomForestClassifier\nRf=RandomForestClassifier(random_state=42)\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [50,100,150]\n\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nfrom pprint import pprint\npprint(random_grid)\n","3afa2ed4":"from sklearn.model_selection import RandomizedSearchCV\nRF=RandomizedSearchCV(estimator=Rf, param_distributions=random_grid,\n                              n_iter = 100, scoring='neg_mean_absolute_error', \n                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n                              return_train_score=True)","4e16bbad":"RF.fit(X_train,y_train)","1362b0c4":"#prediction\n\ny_pred=RF.predict(X_test)\ny_pred[0:5]","fd1897a2":"y_test[0:5]","c687f78c":"#evaluation of model\n\nfrom sklearn import metrics\naccuracy=metrics.accuracy_score(y_test,y_pred)\nprint('Accuracy of model is :',accuracy)","ba4aa848":"from sklearn.metrics import classification_report\nprint('Classification report:','\\n',classification_report(y_test,y_pred))","74b41c3e":"#### 3. Data Preprocessing & EDA","7fbd8306":"#### 1. Load Libraries","6339d2ac":"* **Observation** - Cocoa percent in chocolate bars is around 70-80% and the distribution is slightly positively distributed and there are a lot of outliers in the data\n\n   Data less than 0.53 and more than 0.95 we consider outliers and rest of the data seems to be so close with values so no  need to remove them\n\n","17d22490":"#### 4. Data Scaling & Data Splitting","695e4b32":"* **Data Preprocessing**","8a222729":"#### 5. Machine Learning Model","886ddf9d":"* ****Data Cleaning****","a995ab21":"* **EDA**","b80a2489":"* **Observation** - In review year column distribution is left skewed more than the average and there are no outliers\n\n","5ec0f138":"* **About Dataset**\n\n\n* **1.** 5 = **Elite** (Transcending beyond the ordinary limits)\n \n\n* **2.** 4 = **Premium** (Superior flavor development, character, and style)\n\n\n* **3.** 3 = **Satisfactory(3.0) to praiseworthy(3.75)** (well made with special qualities)\n\n\n* **4.** 2 = **Disappointing** (Passable but contains at least one significant flaw)\n\n\n* **5.** 1 = **Unpleasant** (mostly unpalatable)","355741b6":"* **Observation -** From the pairplot we can say that the bean with cocoa percent 65-75 is given highest rating and above it is given lowest rating.\nAlso there is linear relationship between review and ref feature.","e4b6c8b4":"#### 2. Data Mining & Inpsection","5abafcdb":"* **Conclusion :**\n    \n1)The best correlation is between review_date and ref feature.\n\n2)There is no specific relationship between the cocoa percent and rating.Beans with 70% cocoa is given highest rating,can also be said as bars with 70% cocoa in it gets highest rating.\n\n3)The best bean are grown in countries like Venezuela,Peru,Madagascar,Dominican Republic,Grenada,Papua,New Guinea,Hawaii,Haiti,Bolivia.\n\n4)The highest rated bars are produced in Italy followed by Switzerland,Chile,philippines,Finland.\n\n5)Most of the bars have rating around 3.75\n\n6)Most commonly used beans are Trinitario followed by Criollo,Forastero."}}