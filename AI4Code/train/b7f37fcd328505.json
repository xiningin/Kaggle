{"cell_type":{"92d7e65b":"code","9090d3c0":"code","832404a0":"code","cddaaaee":"code","f984992d":"code","e0ea9e6e":"code","ed5b37a3":"code","df2709a9":"code","8f8ef2d7":"code","d7de7a0a":"code","3fd6736c":"code","7e07dc9d":"code","730184db":"code","f26c287b":"code","3a60fa46":"code","4908dc3e":"markdown","7c5acfa1":"markdown","bf4bdf0c":"markdown","3b4a5e16":"markdown","ebf7e5c3":"markdown","dd171902":"markdown","6f342852":"markdown","4892f3b1":"markdown","d9544979":"markdown","82a39d51":"markdown","164a4a0c":"markdown","9131e01e":"markdown"},"source":{"92d7e65b":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\n\ndef plot_series(time, series, format=\"-\", start=0, end=None):\n    plt.plot(time[start:end], series[start:end], format)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    plt.grid(True)\n\ndef trend(time, slope=0):\n    return slope * time\n\n\"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\ndef seasonal_pattern(season_time):\n    return np.where(season_time < 0.4,np.cos(season_time * 2 * np.pi),1 \/ np.exp(3 * season_time))\n\n\"\"\"Repeats the same pattern at each period\"\"\"\ndef seasonality(time, period, amplitude=1, phase=0):\n    season_time = ((time + phase) % period) \/ period\n    return amplitude * seasonal_pattern(season_time)\n\ndef noise(time, noise_level=1, seed=None):\n    rnd = np.random.RandomState(seed)\n    return rnd.randn(len(time)) * noise_level\n\ntime = np.arange(4 * 365 + 1, dtype=\"float32\")\nbaseline = 10\nseries = trend(time, 0.1)  \nbaseline = 10\namplitude = 40\nslope = 0.05\nnoise_level = 5\n\nseries = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude) # Create the series\nseries += noise(time, noise_level, seed=42) # Update with noise\n\nplt.figure(figsize=(10, 6))\nplot_series(time, series)\nplt.show()","9090d3c0":"split_time = 1000\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]\n\nplt.figure(figsize=(10, 6))\nplot_series(time_train, x_train)\nplt.show()\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplt.show()","832404a0":"naive_forecast = series[split_time - 1:-1]","cddaaaee":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, naive_forecast)","f984992d":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid, start=0, end=150)\nplot_series(time_valid, naive_forecast, start=1, end=151)","e0ea9e6e":"print(keras.metrics.mean_squared_error(x_valid, naive_forecast).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, naive_forecast).numpy())","ed5b37a3":"\"\"\"Forecasts the mean of the last few values. If window_size=1, then this is equivalent to naive forecast\"\"\"\ndef moving_average_forecast(series, window_size):    \n    forecast = []\n    for time in range(len(series) - window_size):\n        forecast.append(series[time:time + window_size].mean())\n    return np.array(forecast)","df2709a9":"moving_avg = moving_average_forecast(series, 30)[split_time - 30:]\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, moving_avg)","8f8ef2d7":"print(keras.metrics.mean_squared_error(x_valid, moving_avg).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, moving_avg).numpy())","d7de7a0a":"diff_series = (series[365:] - series[:-365])\ndiff_time = time[365:]\n\nplt.figure(figsize=(10, 6))\nplot_series(diff_time, diff_series)\nplt.show()","3fd6736c":"diff_moving_avg = moving_average_forecast(diff_series, 50)[split_time - 365 - 50:]\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, diff_series[split_time - 365:])\nplot_series(time_valid, diff_moving_avg)\nplt.show()","7e07dc9d":"diff_moving_avg_plus_past = series[split_time - 365:-365] + diff_moving_avg\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, diff_moving_avg_plus_past)\nplt.show()","730184db":"print(keras.metrics.mean_squared_error(x_valid, diff_moving_avg_plus_past).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, diff_moving_avg_plus_past).numpy())","f26c287b":"diff_moving_avg_plus_smooth_past = moving_average_forecast(series[split_time - 370:-360], 10) + diff_moving_avg\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, diff_moving_avg_plus_smooth_past)\nplt.show()","3a60fa46":"print(keras.metrics.mean_squared_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())\nprint(keras.metrics.mean_absolute_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())","4908dc3e":"PART 01: different time series attributes https:\/\/www.kaggle.com\/salazarslytherin\/time-series-01-different-ts-attributes\n\nPART 02: naive forecasting https:\/\/www.kaggle.com\/salazarslytherin\/time-series-02-naive-forecasting\n\nPART 03: preparing features labels https:\/\/www.kaggle.com\/salazarslytherin\/time-series-03-preparing-features-labels\n\nPART 04: linear regression https:\/\/www.kaggle.com\/salazarslytherin\/time-series-04-linear-regression\n\nPART 05: DNN with callbacks https:\/\/www.kaggle.com\/salazarslytherin\/time-series-05-dnn-with-callbacks\n\nPART 06: RNN https:\/\/www.kaggle.com\/salazarslytherin\/time-series-06-rnn\n\nPART 07: LSTM https:\/\/www.kaggle.com\/salazarslytherin\/time-series-07-lstm\n\nPART 08: CNN + LSTM https:\/\/www.kaggle.com\/salazarslytherin\/time-series-08-cnn-lstm\n\nPART 09: Sunspots dataset CNN https:\/\/www.kaggle.com\/salazarslytherin\/time-series-09-sunspots-dataset-cnn\n\nPART 10: Sunspots dataset DNN https:\/\/www.kaggle.com\/salazarslytherin\/time-series-10-sunspots-dataset-dnn\/edit","7c5acfa1":"Better than naive forecast, good. However the forecasts look a bit too random, because we're just adding past values, which were noisy. Let's use a moving averaging on past values to remove some of the noise:","bf4bdf0c":"That's our baseline, now let's try a moving average:","3b4a5e16":"this code block will set up the time series with seasonality, trend and a bit of noise. ","ebf7e5c3":"Now let's bring back the trend and seasonality by adding the past values from t \u2013 365:","dd171902":"Let's zoom in on the start of the validation period:","6f342852":"That's worse than naive forecast! The moving average does not anticipate trend or seasonality, so let's try to remove them by using differencing. Since the seasonality period is 365 days, we will subtract the value at time *t* \u2013 365 from the value at time *t*.","4892f3b1":"Now that we have the time series, let's split it so we can start forecasting","d9544979":"Now let's compute the mean squared error and the mean absolute error between the forecasts and the predictions in the validation period:","82a39d51":"Great, the trend and seasonality seem to be gone, so now we can use the moving average:","164a4a0c":"# Naive Forecast","9131e01e":"we can see that the naive forecast lags 1 step behind the time series."}}