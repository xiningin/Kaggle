{"cell_type":{"a785ab66":"code","f992915e":"code","314228ad":"code","02e15981":"code","224e8f24":"code","7d7ee82b":"code","02896a37":"code","2bf60345":"code","821d721a":"code","2cf2054c":"code","356d90b8":"code","9db86a45":"code","de689821":"code","fa755094":"code","29dbd72c":"code","f406cb36":"code","d1d97980":"code","8723ac86":"code","26103514":"code","88fa6a86":"code","fe52304f":"code","56d0e9e5":"code","b0decc89":"code","4e8bb3bf":"code","ab2d7cd1":"code","c756c553":"code","a0b09ce2":"code","c0d774f9":"code","f19782a6":"code","a2dfb792":"code","24c25dad":"code","adc312fd":"code","c992ea3b":"code","72c4ccf4":"code","2c6e2cfe":"code","e8b55a37":"code","12b68706":"code","88bd5e70":"code","2db81594":"code","d429efd1":"code","0ed7d3b0":"code","50bd3e26":"code","7c620416":"code","5e8dae4a":"code","2eb039e9":"code","6d266d75":"code","84a70b6f":"code","2b0f6610":"code","d6b2b802":"code","21ccb533":"code","31e82ca1":"code","20900334":"code","f1005fa1":"code","1ee1865d":"code","dda090b3":"markdown","dc83cd82":"markdown","832517d5":"markdown","ff8a959c":"markdown","9161ae93":"markdown","dc1d6048":"markdown","09532fc2":"markdown","eeab8b99":"markdown","f1374239":"markdown","d368318f":"markdown","3cba0358":"markdown","54e70dda":"markdown","d4ec3ef5":"markdown","1c6698be":"markdown","d94b1ab9":"markdown","1efc6d8b":"markdown","c2409d8a":"markdown","b44e8e7e":"markdown","3a6a73de":"markdown"},"source":{"a785ab66":"# Set seeds for reproducibility.\nfrom numpy.random import seed\nseed(12345)\nfrom tensorflow.random import set_seed\nset_seed(67890)","f992915e":"# Import initial libraries and modules.\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","314228ad":"# Load dataset. \ndf = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","02e15981":"# Preview data.\n# Elements V1-V28 are abstract variables obtained from the dataset originators using PCA to protect card user data.\ndf.head(10)","224e8f24":"# Perform dropna to see if any rows with NA values exist.\ncount_1_pd = df.shape[0]\ndf = df.dropna()\ncount_2_pd = df.shape[0]\nprint('Rows before: {}'.format(count_1_pd))\nprint('Rows after: {}'.format(count_2_pd))","7d7ee82b":"# Drop time column as it was identified by other Kaggle users to be unimportant.\n# Split the data into train and test datasets.\ndf = df.drop(columns=['Time'])\nX = df.drop(columns=['Class'])\ny = df['Class']\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=12345)","02896a37":"# Scale the numeric data in X_train.\nscaler = MinMaxScaler()\nX_train = pd.DataFrame(scaler.fit_transform(X_train))\n# Preview scaled X_train.\nX_train.head()","2bf60345":"# Save scaler model for later use on test data.\npickle.dump(scaler, open(\"scaler.pkl\", 'wb'))","821d721a":"# Create model evaluation functions.\ndef get_y_pred(model, x_test):\n    return model.predict(x_test)\n\ndef get_confusion_matrix(y_test, y_predict):\n    cf = confusion_matrix(y_test, y_predict)\n    return cf\n\ndef get_metrics(cf):\n    print(\"True positive: {}\".format(cf[0][0]))\n    print(\"True negative: {}\".format(cf[1][1]))\n    print(\"False positive\/Type I error: {}\".format(cf[1][0]))\n    print(\"False negative\/Type II error: {}\".format(cf[0][1]))\n    print(\"Sensitivity: {}\".format(cf[0][0]\/(cf[0][0]+cf[0][1])))\n    print(\"Specificity: {}\".format(cf[1][1]\/(cf[1][1]+cf[1][0])))\n    print(\"Precision: {}\".format(cf[0][0]\/(cf[0][0]+cf[1][0])))\n    print(\"Negative predictive value: {}\".format(cf[1][1]\/(cf[1][1]+cf[0][1])))\n    print(\"False positive rate: {}\".format(1 - cf[0][0]\/(cf[0][0]+cf[0][1])))\n    print(\"False negative rate: {}\".format(1 - cf[1][1]\/(cf[1][1]+cf[1][0])))\n    print(\"Accuracy: {}\".format((cf[0][0]+cf[1][1])\/(cf[0][0]+cf[1][1]+cf[1][0]+cf[0][1])))\n    \ndef get_roc_auc_score(y_test, y_model_predict):\n    return print(\"ROC_AUC score: \",roc_auc_score(y_test, y_model_predict))","2cf2054c":"# Reload MinMaxScaler and apply to test data.\nscalerObj = pickle.load(open(\"scaler.pkl\", 'rb'))\nX_test = pd.DataFrame(scalerObj.transform(X_test))","356d90b8":"# Import logistic regression classifier, other helpful modules.\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, plot_confusion_matrix\n# Fit model.\nmodel_logistic_regression = LogisticRegression(max_iter=10000).fit(X_train, y_train)","9db86a45":"# Get predicted labels.\ny_pred_logistic_regression = get_y_pred(model_logistic_regression, X_test)\n# Get confusion matrix.\ncf_logistic_regression = confusion_matrix(y_test, y_pred_logistic_regression)\nprint(cf_logistic_regression)","de689821":"# Show confusion matrix derivations.\nget_metrics(cf_logistic_regression)\nget_roc_auc_score(y_test, y_pred_logistic_regression)","fa755094":"# Replace 0 and 1 with 'No Fraud' and 'Fraud'.\nlabels = ['No Fraud', 'Fraud']\n# Plot confusion matrix.\nplot_confusion_matrix(model_logistic_regression, \n                      X_test, \n                      y_test, \n                      display_labels=labels, \n                      cmap=plt.cm.Oranges)\nplt.title(\"Confusion matrix: Logistic Regression\")\nplt.show()","29dbd72c":"# Additional Logistic Regression analysis - feature importance via model coefficients.\n# Get importance.\nimportance = abs(model_logistic_regression.coef_).squeeze()\n# Get variable names.\nfeatures = list(df.columns[:-1])\n# Plot feature importance.\nfig, ax = plt.subplots()\nx_pos = np.arange(len(features))\nhbars = ax.bar(x_pos, importance, align='center')\nax.set_xticks(x_pos)\nax.set_xticklabels(features)\nax.set_xlabel('Features')\nax.set_title('Feature importance')\n\nplt.xticks(rotation=90)\nplt.show()","f406cb36":"# Import random forest classifier.\nfrom sklearn.ensemble import RandomForestClassifier\n# Fit model.\nmodel_random_forest = RandomForestClassifier(max_depth=20)\nmodel_random_forest.fit(X_train, y_train)","d1d97980":"# Get predicted labels.\ny_pred_random_forest = get_y_pred(model_random_forest, X_test)\n# Get confusion matrix.\ncf_random_forest = confusion_matrix(y_test, y_pred_random_forest)\nprint(cf_random_forest)","8723ac86":"# Show confusion matrix derivations.\nget_metrics(cf_random_forest)\nget_roc_auc_score(y_test, y_pred_random_forest)","26103514":"# Plot confusion matrix.\nplot_confusion_matrix(model_random_forest, \n                      X_test, \n                      y_test, \n                      display_labels=labels, \n                      cmap=plt.cm.Oranges)\nplt.title(\"Confusion matrix: Random Forest\")\nplt.show()","88fa6a86":"# Import extra modules.\nfrom collections import Counter\nfrom imblearn.over_sampling import SMOTE","fe52304f":"# Select optimal oversampling strategy.\noversampling_parameters = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]","56d0e9e5":"oversampling_list = []\nfor p in oversampling_parameters:\n    smt = SMOTE(sampling_strategy=p)\n    X_train_SMT, y_train_SMT = smt.fit_resample(X_train, y_train)\n    model_rf_SMT = RandomForestClassifier(max_depth=20).fit(X_train_SMT, y_train_SMT)\n    model_rf_predict = model_rf_SMT.predict(X_test)\n    oversampling_list.append(list([p, roc_auc_score(y_test, model_rf_predict), model_rf_SMT]))","b0decc89":"for i in range(len(oversampling_list)):\n    print(\"Parameter:\", oversampling_list[i][0])\n    print(\"AUC score:\", oversampling_list[i][1])\n    print(\"\\n\")","4e8bb3bf":"# Select parameter with the highest roc_auc_score.\nmax_auc = 0\nfor i in range(len(oversampling_list)):\n    if oversampling_list[i][1] > max_auc:\n        max_auc = oversampling_list[i][1]\n        max_auc_index = i\n    else:\n        pass\nsampling_strategy_over = oversampling_list[max_auc_index][2]\nmodel_random_forest_SMOTE = oversampling_list[max_auc_index][2]\nprint(oversampling_list[max_auc_index][0:2])","ab2d7cd1":"# Get predicted labels.\ny_pred_random_forest_SMOTE = get_y_pred(model_random_forest_SMOTE, X_test)\n# Get confusion matrix.\ncf_random_forest_SMOTE = confusion_matrix(y_test, y_pred_random_forest_SMOTE)\nprint(cf_random_forest_SMOTE)","c756c553":"# Show confusion matrix derivations.\nget_metrics(cf_random_forest_SMOTE)\nget_roc_auc_score(y_test, y_pred_random_forest_SMOTE)","a0b09ce2":"# Plot confusion matrix.\nplot_confusion_matrix(model_random_forest_SMOTE, \n                      X_test, \n                      y_test, \n                      display_labels=labels, \n                      cmap=plt.cm.YlGnBu)\nplt.title(\"Confusion matrix: Random Forest w\/ Oversampling\")\nplt.show()","c0d774f9":"# Import modules for undersampling and pipeline.\nfrom imblearn.pipeline import Pipeline \nfrom imblearn.under_sampling import RandomUnderSampler","f19782a6":"undersampling_parameters = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]","a2dfb792":"# Select optimal oversampling and undersampling strategy.\noverundersampling_list = []\nfor r in oversampling_parameters:\n    for s in undersampling_parameters:\n        smt = SMOTE(sampling_strategy=r)\n        us = RandomUnderSampler(sampling_strategy=s)\n        model_rf_pipe = RandomForestClassifier(max_depth=20)\n        pl = Pipeline([\n            ('over', smt), \n            ('under', us), \n            ('model', model_rf_pipe)\n        ])\n        pl.fit(X_train, y_train)\n        model_rf_predict_overunder = model_rf_pipe.predict(X_test)\n        overundersampling_list.append(list([r, s, roc_auc_score(y_test, model_rf_predict_overunder), model_rf_pipe]))","24c25dad":"# Select parameter combination with the highest roc_auc_score.\nax_auc = 0\nfor i in range(len(overundersampling_list)):\n    if overundersampling_list[i][2] > max_auc:\n        max_auc = overundersampling_list[i][2]\n        max_auc_index = i\n    else:\n        pass\noversamp_param_2 = overundersampling_list[max_auc_index][0]\nundersamp_param = overundersampling_list[max_auc_index][1]\npipeline_overunder = overundersampling_list[max_auc_index][3]\nprint(overundersampling_list[max_auc_index])","adc312fd":"# Get predicted labels.\ny_pred_random_forest_pipe = get_y_pred(pipeline_overunder, X_test)\n# Get confusion matrix.\ncf_random_forest_pipe = confusion_matrix(y_test, y_pred_random_forest_pipe)\nprint(cf_random_forest_pipe)","c992ea3b":"# Show confusion matrix derivations.\nget_metrics(cf_random_forest_pipe)\nget_roc_auc_score(y_test, y_pred_random_forest_pipe)","72c4ccf4":"# Plot confusion matrix.\nplot_confusion_matrix(pipeline_overunder, \n                      X_test, \n                      y_test, \n                      display_labels=labels, \n                      cmap=plt.cm.Greens)\nplt.title(\"Confusion matrix: Random Forest \\nw\/ Oversampling and Undersampling\")\nplt.show()","2c6e2cfe":"# Import OneClassSVM.\nfrom sklearn.svm import OneClassSVM","e8b55a37":"outliers_list = []\nsmt = SMOTE(sampling_strategy=oversamp_param_2)\nX_train_over, y_train_over = smt.fit_resample(X_train, y_train)\nus = RandomUnderSampler(sampling_strategy=s)\nX_train_overunder, y_train_overunder = us.fit_resample(X_train_over, y_train_over)\n# Select optimal OneClassSVM hyperparameters.\nkernel_parameters = ['linear', 'poly', 'rbf', 'sigmoid']\nnu_parameters = [0.001, 0.005, 0.01, 0.05, 0.1]\nfor k in kernel_parameters:\n    for n in nu_parameters:\n        ou = OneClassSVM(kernel=k, nu=n)\n        yh = ou.fit_predict(X_train_overunder)\n        # Make y_train_SMOTE a pandas dataframe.\n        X_train_ou = X_train_overunder\n        y_train_ou = pd.DataFrame(y_train_overunder)\n        # Attach y-hat to training data.\n        X_train_ou['remove_row'] = yh\n        y_train_ou['remove_row'] = yh\n        # Remove outliers.\n        X_train_ou = X_train_ou[X_train_ou['remove_row'] != -1]\n        y_train_ou = y_train_ou[y_train_ou['remove_row'] != -1]\n        # Drop remove_row column from training data.\n        del X_train_ou['remove_row']\n        y_train_ou = y_train_ou['Class']\n        # Setup, fit pipeline.\n        model_rf_ou = RandomForestClassifier(max_depth=20).fit(X_train_ou, y_train_ou)\n        rf_ou_predict = model_rf_ou.predict(X_test)\n        outliers_list.append(list([k, n, roc_auc_score(y_test, rf_ou_predict), model_rf_ou]))","12b68706":"# Select best outlier removal parameters.\nmax_auc = 0\nfor i in range(len(outliers_list)):\n    if outliers_list[i][2] > max_auc:\n        max_auc = outliers_list[i][2]\n        max_auc_index = i\n    else:\n        pass\noutlier_kernel = outliers_list[max_auc_index][0]\noutlier_nu = outliers_list[max_auc_index][1]\nmodel_random_forest_outliers = outliers_list[max_auc_index][3]\nprint(outliers_list[max_auc_index][0:3])","88bd5e70":"# Get predicted labels.\ny_pred_random_forest_outliers = get_y_pred(model_random_forest_outliers, X_test)\n# Get confusion matrix.\ncf_random_forest_outliers = confusion_matrix(y_test, y_pred_random_forest_outliers)\nprint(cf_random_forest_outliers)","2db81594":"# Show confusion matrix derivations.\nget_metrics(cf_random_forest_outliers)\nget_roc_auc_score(y_test, y_pred_random_forest_outliers)","d429efd1":"# Plot confusion matrix.\nplot_confusion_matrix(model_random_forest_outliers, \n                      X_test, \n                      y_test, \n                      display_labels=labels, \n                      cmap=plt.cm.Blues)\nplt.title(\"Confusion matrix: Random Forest \\nw\/ Oversampling, Undersampling, \\nand Outlier removal\")\nplt.show()","0ed7d3b0":"# Import TensorFlow libraries.\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy","50bd3e26":"# Prep training data.\noutliers = OneClassSVM(kernel=outlier_kernel, nu=outlier_nu)\nyhat = outliers.fit_predict(X_train_overunder)\n# Make y_train_SMOTE a pandas dataframe.\nX_train_outliers = X_train_overunder\ny_train_outliers = pd.DataFrame(y_train_overunder)\n# Attach y-hat to training data.\nX_train_outliers['remove_row'] = yh\ny_train_outliers['remove_row'] = yh\n# Remove outliers.\nX_train_outliers = X_train_outliers[X_train_outliers.remove_row != -1]\ny_train_outliers = y_train_outliers[y_train_outliers.remove_row != -1]\n# Drop remove_row column from training data.\ndel X_train_outliers['remove_row']\ny_train_outliers = y_train_outliers['Class']","7c620416":"# Create oversampling neural network.\nn_inputs = X_train_outliers.shape[1]\n\nmodel_tf = Sequential([\n    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(15, activation='relu'),\n    Dense(2, activation='sigmoid')\n])\nmodel_tf.summary()","5e8dae4a":"# Compile model.\nmodel_tf.compile(Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","2eb039e9":"# Fit TensorFlow model.\nhistory = model_tf.fit(X_train_outliers,\n             y_train_outliers,\n             validation_split=0.2,\n             batch_size=25, \n             epochs=30, \n             shuffle=True, \n             verbose=0)","6d266d75":"# Plot learning history: Accuracy\nplt.plot(history.history['accuracy'], label='Accuracy (training data)')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy (validation data)')\nplt.title('Accuracy for Credit Card Fraud DNN Model')\nplt.ylabel('Accuracy')\nplt.xlabel('No. epochs')\nplt.legend(loc=\"lower right\")\nplt.ylim(0, 1)\nplt.show()","84a70b6f":"# Get predicted values.\ny_pred_tf_raw = model_tf.predict(X_test, batch_size=200, verbose=0)","2b0f6610":"y_pred_tf = []\nfor i in y_pred_tf_raw:\n    if i[0] > i[1]:\n        y_pred_tf.append(0)\n    else:\n        y_pred_tf.append(1)\ny_pred_tf = np.array(y_pred_tf, dtype=int)","d6b2b802":"# Get confusion matrix.\ncf_tf = confusion_matrix(y_test, y_pred_tf)\nprint(cf_tf)","21ccb533":"# Show confusion matrix derivations.\nget_metrics(cf_tf)\nget_roc_auc_score(y_test, y_pred_tf)","31e82ca1":"fig, ax = plt.subplots()\nax.matshow(cf_tf, cmap=plt.cm.PuRd)\nfor i in range(cf_tf.shape[0]):\n    for j in range(cf_tf.shape[1]):\n        ax.text(x=j, y=i,s=cf_tf[i, j], va='center', ha='center', size='xx-large')\nplt.title('Confusion Matrix - DNN')\nplt.show()","20900334":"# ROC curves, area-under-curve (AUC) scores for all models using oversampling and outlier removal.\\\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import cross_val_score","f1005fa1":"# Generate curves.\nrandom_forest_fpr, random_forest_tpr, random_forest_thresold = roc_curve(y_test, y_pred_random_forest_outliers)\nDNN_fpr, DNN_tpr, DNN_threshold = roc_curve(y_test, y_pred_tf)\n# Plot ROC curves and roc-AUC-scores\/\nplt.figure(figsize=(16,8))\nplt.plot(random_forest_fpr, random_forest_tpr, label='Random Forest Classifier Score: {:.4f}'.format(roc_auc_score(y_test, y_pred_random_forest_outliers)))\nplt.plot(DNN_fpr, DNN_tpr, label='Deep Neural Network Classifier Score: {:.4f}'.format(roc_auc_score(y_test, y_pred_tf)))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.axis([-0.01, 1, 0, 1])\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC Curve - Top 2 Classifiers', fontsize=18)\nplt.legend()","1ee1865d":"# Save model.\nmodel_tf.save('credit-card-fraud-detection-model')","dda090b3":"# GOAL: Create a machine learning model to accurately detect fraudulent credit card transactions.","dc83cd82":"Accuracy and validation accuracy improved little over the 30 epochs.","832517d5":"Let's compare performance of both models.","ff8a959c":"## Compare models: Random Forest, TensorFlow DNN.","9161ae93":"# Model 6 - Keras Deep Neural Net w\/ Oversampling, Undersampling, and Outlier removal.","dc1d6048":"Nearly all of the abstracted features are more important than the amount spent in the transaction.","09532fc2":"# Model 4 - Random Forest w\/ Oversampling and Undersampling.","eeab8b99":"Specificity for the Random Forest is at 81.379% - much better than the Logistic Regression's 51.034%.\n\nAccuracy increased from 99.902% to 99.963%.\n\nSensitivity\/recall increased from 99.986% to 99.994%.\n\nAUC increased from 0.75510 to 0.90687.<br><br>\n\nLet's try to ensure the ratio of actual legitimate to actual fraudulent payments is equal across train and test datasets. The dataset is imbalanced as is, with less than 2% of transactions being fraudulent.","f1374239":"AUC score and specificity were further improved by introducing oversampling, but sensitivity dipped.","d368318f":"# Model 5 - Random Forest w\/ Oversampling, Undersampling, and Outlier removal.","3cba0358":"While specificity increased, overall accuracy decreased due to another drop in sensitivity. False fraud detection could annoy customers and disrupt their non-fraudulent purchases too often. \n\nAUC score increased, so we will keep the pipeline method of over and undersampling with the same optimal sampling strategy parameters, as it is the preferred metric to be optimized (vs. accuracy) for binary classification models.","54e70dda":"<b>Dataset citations:<\/b>\n\n\nAndrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n\nDal Pozzolo, Andrea; Caelen, Olivier; Le Borgne, Yann-Ael; Waterschoot, Serge; Bontempi, Gianluca. Learned lessons in credit card fraud detection from a practitioner perspective, Expert systems with applications,41,10,4915-4928,2014, Pergamon\n\nDal Pozzolo, Andrea; Boracchi, Giacomo; Caelen, Olivier; Alippi, Cesare; Bontempi, Gianluca. Credit card fraud detection: a realistic modeling and a novel learning strategy, IEEE transactions on neural networks and learning systems,29,8,3784-3797,2018,IEEE\n\nDal Pozzolo, Andrea Adaptive Machine learning for credit card fraud detection ULB MLG PhD thesis (supervised by G. Bontempi)\n\nCarcillo, Fabrizio; Dal Pozzolo, Andrea; Le Borgne, Yann-A\u00ebl; Caelen, Olivier; Mazzer, Yannis; Bontempi, Gianluca. Scarff: a scalable framework for streaming credit card fraud detection with Spark, Information fusion,41, 182-194,2018,Elsevier\n\nCarcillo, Fabrizio; Le Borgne, Yann-A\u00ebl; Caelen, Olivier; Bontempi, Gianluca. Streaming active learning strategies for real-life credit card fraud detection: assessment and visualization, International Journal of Data Science and Analytics, 5,4,285-300,2018,Springer International Publishing\n\nBertrand Lebichot, Yann-A\u00ebl Le Borgne, Liyun He, Frederic Obl\u00e9, Gianluca Bontempi Deep-Learning Domain Adaptation Techniques for Credit Cards Fraud Detection, INNSBDDL 2019: Recent Advances in Big Data and Deep Learning, pp 78-88, 2019\n\nFabrizio Carcillo, Yann-A\u00ebl Le Borgne, Olivier Caelen, Frederic Obl\u00e9, Gianluca Bontempi Combining Unsupervised and Supervised Learning in Credit Card Fraud Detection Information Sciences, 2019\n\nYann-A\u00ebl Le Borgne, Gianluca Bontempi Machine Learning for Credit Card Fraud Detection - Practical Handbook","d4ec3ef5":"<b>Sources:<\/b>\n1. https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud\n2. https:\/\/www.kaggle.com\/janiobachmann\/credit-fraud-dealing-with-imbalanced-datasets\n3. https:\/\/towardsdatascience.com\/how-to-deal-with-imbalanced-data-in-python-f9b71aba53eb\n4. https:\/\/machinelearningmastery.com\/model-based-outlier-detection-and-removal-in-python\/\n5. https:\/\/machinelearningmastery.com\/reproducible-results-neural-networks-keras\/\n6. https:\/\/machinelearningmastery.com\/calculate-feature-importance-with-python\/\n","1c6698be":"Removing outliers in the training data led to a better model. We will try this training data now on a deep neural network.","d94b1ab9":"# Model 2 - Random Forest.","1efc6d8b":"# Model 1 - Logistic Regression.","c2409d8a":"The sensitivity\/recall is pretty good at 99.986%. \n\nWhile the model is over 99.9% accurate, it's not that impressive considering the imbalance in the data labels.\n\nThe specificity is too low. About half of the fraudulent transactions were flagged as legitimate.","b44e8e7e":"The best model from a ROC-AUC perspective is the <b>deep neural net<\/b>. ","3a6a73de":"# Model 3 - Random Forest w\/ Oversampling."}}