{"cell_type":{"9fd9cff8":"code","6683b815":"code","db6413ef":"code","2b311311":"code","6e84a615":"code","c3369f1d":"code","dfcb8203":"code","f7aed2d7":"code","d7d8b6c6":"code","23476aa6":"code","27c0b41c":"code","ed60056a":"code","26615e88":"code","b05ed706":"code","423494c9":"code","73a09657":"code","40b5b6c6":"code","dde7e0ab":"code","32085619":"code","f386a50e":"code","d36ec417":"code","3115d081":"code","3f50f455":"code","a8e7afb2":"code","26b85f52":"code","9317acf5":"code","a024b19f":"code","0f916817":"code","2c7659cb":"code","db1f8abb":"code","d918c757":"code","c7f6cc0a":"code","892e6980":"code","6fc9d3cf":"code","adf49bdd":"code","9bf1fa45":"code","bbc389ae":"code","a8a4abab":"code","ecf686c6":"code","5731cc33":"code","2391f890":"code","a3131856":"code","dced7995":"code","305d631d":"code","3e18137d":"code","529b2736":"code","512452c6":"code","ea8c32d0":"code","175e4700":"code","77edce22":"code","89165e18":"code","0d312a5c":"code","92aa23d2":"code","77b7ebd6":"code","e575e2ef":"code","30c9b7e6":"code","d28ff836":"code","ef1f469d":"code","fd57da40":"code","ad8c7b11":"code","d772776c":"code","a6fab377":"code","a94a1542":"code","d69365a5":"code","3b7bfa73":"code","dcd463c0":"code","4ba85c94":"code","d852cc38":"code","96400220":"code","ec52d574":"code","f1636f78":"code","f1e7e44a":"code","adb2c931":"code","b086e3a2":"code","8969b73a":"code","5c866de7":"code","19b72399":"code","4dc01726":"code","cfd4d7b7":"code","a834a1d8":"code","856e0ebc":"code","18348fae":"code","5aa24970":"code","48fec8ba":"code","2849329e":"code","b1de0398":"code","740d5dfe":"code","2e7f95a1":"code","8e43ea33":"code","0e8d4e7d":"code","a100512e":"code","65334c04":"code","304a8094":"code","c19931f3":"code","581e8820":"code","f124564f":"code","f8acfad7":"code","c3203547":"code","08878cc6":"code","052b440e":"code","61941366":"code","dcfb069c":"code","47970023":"code","bb8059b1":"code","9e207017":"code","6c1f2ab6":"code","45f8221a":"code","254384b3":"code","d38a26c2":"code","5da6d34d":"code","02a67b43":"code","48ec6056":"code","694ead1f":"code","1b2fda94":"code","0ef068f7":"code","64f0e08a":"code","1571064f":"code","5283423a":"code","9cc02fa9":"code","fc1bc756":"code","906e1758":"code","cc12a9fe":"code","dfe1cc4d":"code","2f959f45":"code","0cf59e9d":"code","48bf32e7":"code","28c81477":"code","1ae18e7b":"code","e2f9e264":"code","25f802cd":"code","78617ffc":"code","7138c4e6":"code","155e8515":"code","496c0de8":"markdown","e8994d2a":"markdown","2349eb4d":"markdown","fec6ec3f":"markdown","a47d8252":"markdown","9a3c41ee":"markdown","e18b59f3":"markdown","95f7be02":"markdown","2f19fddc":"markdown","10d1a5a6":"markdown","fc5d661c":"markdown","9b5e4eb4":"markdown","261133e5":"markdown","5a429777":"markdown","001a73ad":"markdown","95841446":"markdown","48b03737":"markdown","00018cb8":"markdown","914dd2f9":"markdown","4e2ebb8f":"markdown","5b31fdb7":"markdown","6776c820":"markdown","173dfb07":"markdown","f0576108":"markdown","f8bf8ead":"markdown","20731e57":"markdown","913853e3":"markdown","be77bf70":"markdown","1791a722":"markdown","fc09fb59":"markdown","da003426":"markdown","d1e2508b":"markdown","b1f5288e":"markdown","53b6b9d9":"markdown","487a28fd":"markdown","64f00283":"markdown","3877e3e5":"markdown","c44a12eb":"markdown"},"source":{"9fd9cff8":"import numpy as np\nimport pandas\nimport seaborn\nimport matplotlib.pyplot as plt","6683b815":"df = pandas.read_csv('..\/input\/nyse\/prices.csv')","db6413ef":"df.head()","2b311311":"print(df.shape)","6e84a615":"print(df[df['symbol'] == 'AAPL'].shape)\nprint(df[df['symbol'] =='GOOGL'].shape)\nprint(df[df['symbol'] == 'AMZN'].shape)","c3369f1d":"main_df = df[(df['symbol'] == 'AAPL') | (df['symbol'] == 'GOOGL') | (df['symbol'] == 'AMZN')].reset_index(drop = True)","dfcb8203":"print('Number of missing values : ' + str(main_df.isna().sum().sum()))","f7aed2d7":"main_df.head(9)","d7d8b6c6":"print(main_df['date'].min())\nprint(main_df['date'].max())","23476aa6":"main_df = pandas.get_dummies(main_df, columns = ['symbol'])","27c0b41c":"main_df.head(9)","ed60056a":"from tabulate import tabulate\ninfo = [[col, main_df[col].count(), main_df[col].max(), main_df[col].min()] for col in main_df.columns]\nprint(tabulate(info, headers = ['Feature', 'Count', 'Maximum', 'Minimum'], tablefmt= 'orgtbl'))","26615e88":"main_df = main_df.drop(['date'], axis = 1)","b05ed706":"seaborn.pairplot(main_df.drop(['symbol_AAPL', 'symbol_AMZN', 'symbol_GOOGL'], axis = 1))","423494c9":"plt.figure(figsize = (15,15))\nmat = main_df.drop(['symbol_AAPL', 'symbol_AMZN', 'symbol_GOOGL'], axis = 1).corr()\nseaborn.heatmap(mat, annot = True, square = True)","73a09657":"info = ['open', 'close', 'low', 'high', 'volume']","40b5b6c6":"plt.figure(figsize = (20,10))\n\nfor i in range(4) :\n    plt.subplot(2,2,i+1)\n    \n    plt.plot(main_df[main_df['symbol_AAPL'] == 1][info[i]].values)\n    plt.plot(main_df[main_df['symbol_GOOGL']== 1][info[i]].values)\n    plt.plot(main_df[main_df['symbol_AMZN'] == 1][info[i]].values)\n    plt.xlabel('time' )\n    plt.ylabel(info[i])\n    plt.legend(['Apple', 'Google', 'Amazon'])\n    plt.title(info[i] + ' vs time')\nplt.show()","dde7e0ab":"info = [[col, main_df[col].count(), main_df[col].max(), main_df[col].min()] for col in main_df.columns]\nprint(tabulate(info, headers = ['Feature', 'Count', 'Maximum', 'Minimum'], tablefmt = 'orgtbl'))","32085619":"X = np.array(main_df.drop(['close', 'low', 'high'], axis = 1))\ny = np.array(main_df['close'])","f386a50e":"print(X.shape)\nprint(y.shape)","d36ec417":"print(X[:3])","3115d081":"from sklearn.preprocessing import MinMaxScaler\nX = MinMaxScaler().fit_transform(X)","3f50f455":"print(X[:3])","a8e7afb2":"print(y.min())\nprint(y.max())","26b85f52":"temp = MinMaxScaler().fit_transform(np.reshape(y, (len(y),1)))\ny = temp.reshape(-1)","9317acf5":"print(y.min())\nprint(y.max())","a024b19f":"print(X.min())\nprint(X.max())","0f916817":"print(y[3:6])","2c7659cb":"length = 300                         # 100 days * 3 companies\n\nX_res = []\ny_res = []\n\nfor i in range(length,len(X)-2) :\n    X_res.append(X[i-length:i])      # contains features for past 100 days for 3 companies.\n    y_res.append(y[i:i+3])           # the next three closing prices for AAPL, AMZN, GOOGL.\n\nX_res = np.array(X_res)\ny_res = np.array(y_res)","db1f8abb":"print(X_res.shape)\nprint(y_res.shape)","d918c757":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test  = train_test_split(X_res, y_res, test_size = 0.3, shuffle = False)","c7f6cc0a":"print(X_train.shape)\nprint(y_train.shape)","892e6980":"print(X_test.shape)\nprint(y_test.shape)","6fc9d3cf":"from keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Bidirectional\nfrom keras.layers import BatchNormalization\n\nfrom keras.layers import Input","adf49bdd":"def lstm_layer (hiddenx) :\n    \n    model = Sequential()\n    \n    model.add(Bidirectional(LSTM(hiddenx, activation = 'tanh', return_sequences = True)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    return model","9bf1fa45":"def rnn (hidden1, hidden2, hidden3) :\n    \n    model = Sequential()\n    \n    # Input Block\n    model.add(Input((length, 5,)))\n    \n    # LSTM Block\n    model.add(lstm_layer(hidden1))\n    model.add(lstm_layer(hidden2))\n    model.add(Bidirectional(LSTM(hidden3, activation = 'tanh', return_sequences = False)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    # Output Block\n    model.add(Dense(3, activation = 'linear'))\n    \n    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n    return model","bbc389ae":"model = rnn(128, 128, 32)\nmodel.summary()","a8a4abab":"from keras.callbacks import ModelCheckpoint\ncheckp = ModelCheckpoint('.\/result_model.h5', monitor = 'val_loss', save_best_only = True, verbose = 1)","ecf686c6":"history = model.fit(X_train, y_train, epochs = 200, batch_size = 32, validation_data = (X_test, y_test), callbacks = [checkp])","5731cc33":"plt.figure(figsize = (20, 5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['train_loss', 'validation_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Losses')\nplt.title('Losses vs Epochs')\nplt.show()","2391f890":"from keras.models import load_model\nmodel = load_model('.\/result_model.h5')","a3131856":"pred = model.predict(X_test)","dced7995":"print(pred.shape)","305d631d":"from sklearn.metrics import mean_squared_error, r2_score\nprint('mean squared error : ' + str(mean_squared_error(y_test, pred)))\nprint('r2_score : ' + str(r2_score(y_test, pred)))","3e18137d":"plt.figure(figsize = (20,15))\n\nplt.subplot(3,1,1)\nplt.plot(y_test[:200,0])\nplt.plot(pred[:200,0])\nplt.xlabel('Period')\nplt.ylabel('Closing Prices')\nplt.legend(['testing price','predicted price'])\nplt.title('Comparison in closing prices for Apple', fontsize = 15)\n\n\nplt.subplot(3,1,2)\nplt.plot(y_test[:200,1])\nplt.plot(pred[:200,1])\nplt.xlabel('Period')\nplt.ylabel('Closing Prices')\nplt.legend(['testing price','predicted price'])\nplt.title('Comparison in closing prices for Amazon',fontsize = 15)\n\n\nplt.subplot(3,1,3)\nplt.plot(y_test[:200,2])\nplt.plot(pred[:200,2])\nplt.xlabel('Period')\nplt.ylabel('Closing Prices')\nplt.legend(['testing price','predicted price'])\nplt.title('Comparison in closing prices for Google',fontsize = 15)","529b2736":"import pandas\nimport numpy as np\nimport matplotlib.pyplot as plt","512452c6":"df = pandas.read_csv('..\/input\/nyse\/prices.csv')","ea8c32d0":"df.head()","175e4700":"df = df[df['symbol'] == 'GOOGL'].reset_index(drop = True)","77edce22":"df.head()","89165e18":"df = df.drop(['symbol'], axis = 1)","0d312a5c":"print('Starting date : ' + str(df['date'].min()))\nprint('Lasting date  : ' + str(df['date'].max()))","92aa23d2":"print('Number of missing values : ' + str(df.isna().sum().sum()))\nprint(df.shape)","77b7ebd6":"from tabulate import tabulate","e575e2ef":"info = [[col, df[col].count(), df[col].max(), df[col].min()] for col in df.columns]\nprint(tabulate(info, headers = ['Feature', 'Count', 'Maximum', 'Minimum'], tablefmt = 'orgtbl'))","30c9b7e6":"X = np.array(df.drop(['date', 'high', 'low', 'close'], axis = 1))\ny = np.array(df['close'])","d28ff836":"print(X.shape)\nprint(y.shape)","ef1f469d":"from sklearn.preprocessing import MinMaxScaler","fd57da40":"X = MinMaxScaler().fit_transform(X)","ad8c7b11":"t = np.reshape(y, (len(y),1))\nt = MinMaxScaler().fit_transform(t)\ny = t.reshape(-1)","d772776c":"print(X.max())\nprint(X.min())","a6fab377":"print(y.max())\nprint(y.min())","a94a1542":"length = 300\n\nX_res = []\ny_res = []\n\nfor i in range(length , len(X)) :\n    X_res.append(X[i-length:i])\n    y_res.append(y[i])\n\nX_res = np.array(X_res)\ny_res = np.array(y_res)","d69365a5":"print(X_res.shape)\nprint(y_res.shape)","3b7bfa73":"from sklearn.model_selection import train_test_split","dcd463c0":"X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.2, shuffle = False)","4ba85c94":"print(X_train.shape)\nprint(y_train.shape)","d852cc38":"print(X_test.shape)\nprint(y_test.shape)","96400220":"from keras.models import Sequential\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import Bidirectional\nfrom keras.layers import BatchNormalization","ec52d574":"'''\ndef lstm_layer (hiddenx) :\n    \n    model = Sequential()\n    \n    model.add(Bidirectional(LSTM(hiddenx, activation = 'tanh', return_sequences = True)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    return model\n'''\n\ndef mod (hidden1, hidden2, hidden3) :\n    \n    model = Sequential()\n    \n    # Input layer\n    model.add(Input((length, 2,)))\n    \n    # lstm layer\n    model.add(lstm_layer(hidden1))\n    model.add(lstm_layer(hidden2))\n    model.add(Bidirectional(LSTM(hidden3, activation = 'tanh', return_sequences = False)))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    # output layer\n    model.add(Dense(1, activation = 'linear'))\n    \n    model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n    \n    return model","f1636f78":"model = mod(128, 64, 64)\nmodel.summary()","f1e7e44a":"from keras.callbacks import ModelCheckpoint\ncheckp = ModelCheckpoint('.\/transfer_model.h5', monitor = 'val_loss', verbose = 1, save_best_only = True)","adb2c931":"history = model.fit(X_train, y_train, epochs = 200, batch_size = 32, callbacks = [checkp], validation_data = (X_test, y_test))","b086e3a2":"plt.figure(figsize = (20,5))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['Training loss', 'Validation loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Losses')\nplt.title('Losses vs Epochs')","8969b73a":"from keras.models import load_model\nmodel = load_model('.\/transfer_model.h5')","5c866de7":"pred = model.predict(X_test)","19b72399":"print(pred.shape)","4dc01726":"pred = pred.reshape(-1)","cfd4d7b7":"from sklearn.metrics import mean_squared_error, r2_score","a834a1d8":"print('Mean squared error : ' + str(mean_squared_error(y_test, pred)))\nprint('r2_score : ' + str(r2_score(y_test, pred)))","856e0ebc":"plt.figure(figsize = (20,5))\n\nplt.plot(y_test[:100])\nplt.plot(pred[:100])\nplt.legend(['Testing values', 'predicted values'])\nplt.xlabel('Time Period')\nplt.ylabel('Closing prices')\nplt.title('Comparison b\/w predicted and real closing prices (Google)')","18348fae":"df = pandas.read_csv('..\/input\/nyse\/prices.csv')","5aa24970":"apple = df[df['symbol'] == 'AAPL'].reset_index(drop = True)\namazn = df[df['symbol'] == 'AMZN'].reset_index(drop = True)","48fec8ba":"apple.head()","2849329e":"amazn.head()","b1de0398":"print('Apple,')\nprint('Number of missing values : ' + str(apple.isna().sum().sum()))\nprint(apple.shape)\n\nprint('Amazon')\nprint('Number of missing values : ' + str(amazn.isna().sum().sum()))\nprint(amazn.shape)","740d5dfe":"apple = apple.drop(['date', 'symbol'], axis = 1)\namazn = amazn.drop(['date', 'symbol'], axis = 1)","2e7f95a1":"info = [[col, apple[col].count(), apple[col].max(), apple[col].min()] for col in apple.columns]\nprint(tabulate(info, headers = ['Feature', 'Count', 'Max', 'Min'], tablefmt = 'orgtbl'))","8e43ea33":"info = [[col, amazn[col].count(), amazn[col].max(), amazn[col].min()] for col in amazn.columns]\nprint(tabulate(info, headers = ['Feature', 'Count', 'Max', 'Min'], tablefmt = 'orgtbl'))","0e8d4e7d":"X_apple = np.array(apple.drop(['close', 'low', 'high'], axis = 1))\ny_apple = np.array(apple['close'])\n\nX_amazn = np.array(amazn.drop(['close', 'low', 'high'], axis = 1))\ny_amazn = np.array(amazn['close'])","a100512e":"print(X_apple.shape)\nprint(y_apple.shape)","65334c04":"print(X_amazn.shape)\nprint(y_amazn.shape)","304a8094":"X_apple = MinMaxScaler().fit_transform(X_apple)\nX_amazn = MinMaxScaler().fit_transform(X_amazn)","c19931f3":"t = np.reshape(y_apple, (len(y_apple),1))\nt = MinMaxScaler().fit_transform(t)\ny_apple = t.reshape(-1)","581e8820":"t = np.reshape(y_amazn, (len(y_amazn),1))\nt = MinMaxScaler().fit_transform(t)\ny_amazn = t.reshape(-1)","f124564f":"print(X_apple.max())\nprint(X_apple.min())","f8acfad7":"print(y_apple.max())\nprint(y_apple.min())","c3203547":"print(X_amazn.max())\nprint(X_amazn.min())","08878cc6":"print(y_amazn.max())\nprint(y_amazn.min())","052b440e":"print(X_apple.shape)\nprint(y_apple.shape)","61941366":"print(X_amazn.shape)\nprint(y_amazn.shape)","dcfb069c":"length = 300\n\nX_res_apple = []\ny_res_apple = []\n\nX_res_amazn = []\ny_res_amazn = []","47970023":"for i in range(length, len(X_apple)) :\n    \n    X_res_apple.append(X_apple[i-length:i])            # take 300 prior data for apple stock\n    y_res_apple.append(y_apple[i])                     # next day closing price\n    \n    X_res_amazn.append(X_amazn[i-length:i])            # take 300 prior data for Amazonstock\n    y_res_amazn.append(y_amazn[i])                     # next day closing price\n\nX_res_apple, y_res_apple = np.array(X_res_apple), np.array(y_res_apple)\nX_res_amazn, y_res_amazn = np.array(X_res_amazn), np.array(y_res_amazn)","bb8059b1":"print(X_res_apple.shape)\nprint(y_res_apple.shape)","9e207017":"print(X_res_amazn.shape)\nprint(y_res_amazn.shape)","6c1f2ab6":"from sklearn.utils import shuffle","45f8221a":"from keras.models import load_model\nmodel = load_model('.\/transfer_model.h5')","254384b3":"for i, layer in enumerate(model.layers) :\n    if i < 5 :\n        layer.trainable = False","d38a26c2":"print(model.summary())","5da6d34d":"X_apple_train, X_apple_test, y_apple_train, y_apple_test = train_test_split(X_res_apple, y_res_apple, test_size = 0.2, shuffle = False)","02a67b43":"print(X_apple_train.shape)\nprint(y_apple_train.shape)","48ec6056":"print(X_apple_test.shape)\nprint(y_apple_test.shape)","694ead1f":"checkp = ModelCheckpoint('.\/best_apple_model.h5', save_best_only = True, monitor = 'val_loss', verbose = 1)","1b2fda94":"history = model.fit(X_apple_train, y_apple_train, epochs = 50, batch_size = 32, validation_data = (X_apple_test, y_apple_test), callbacks = [checkp])","0ef068f7":"model = load_model('.\/best_apple_model.h5')\ny_apple_pred = model.predict(X_apple_test)","64f0e08a":"print(y_apple_pred.shape)","1571064f":"y_apple_pred = y_apple_pred.reshape(-1)","5283423a":"print('Apple,')\nprint('Mean squared error : ' + str(mean_squared_error(y_apple_test, y_apple_pred)))\nprint('r2 score : ' + str(r2_score(y_apple_test, y_apple_pred)))","9cc02fa9":"plt.figure(figsize = (20,5))\n\nplt.plot(y_apple_test[100:200])\nplt.plot(y_apple_pred[100:200])\n\nplt.xlabel('Time period')\nplt.ylabel('Closing prices')\nplt.legend(['Actual Price', 'Predicted price'])\nplt.title('Closing price comparison for Apple dataset', fontsize = 15)","fc1bc756":"model = load_model('.\/transfer_model.h5')","906e1758":"for i, layer in enumerate(model.layers) :\n    if i < 5 :\n        layer.trainable = False","cc12a9fe":"print(model.summary())","dfe1cc4d":"X_amazn_train,  X_amazn_test, y_amazn_train, y_amazn_test = train_test_split(X_res_amazn, y_res_amazn, test_size = 0.2, shuffle = False)","2f959f45":"print(X_amazn_train.shape)\nprint(y_amazn_train.shape)","0cf59e9d":"print(X_amazn_test.shape)\nprint(y_amazn_test.shape)","48bf32e7":"from keras.callbacks import ModelCheckpoint\ncheckp = ModelCheckpoint('.\/best_amazn_model.h5', monitor = 'val_loss', save_best_only = True, verbose = 1)","28c81477":"history = model.fit(X_amazn_train, y_amazn_train, epochs = 100, batch_size = 32, validation_data = (X_amazn_test, y_amazn_test), callbacks = [checkp])","1ae18e7b":"model = load_model('.\/best_amazn_model.h5')","e2f9e264":"y_amazn_pred = model.predict(X_amazn_test)","25f802cd":"print(y_amazn_pred.shape)","78617ffc":"y_amazn_pred = y_amazn_pred.reshape(-1)","7138c4e6":"print('Mean_sqaured_error : ' + str(mean_squared_error(y_amazn_test, y_amazn_pred)))\nprint('r2_score : ' + str(r2_score(y_amazn_test, y_amazn_pred)))","155e8515":"plt.figure(figsize = (20,5))\n\nplt.plot(y_amazn_test[100:200])\nplt.plot(y_amazn_pred[100:200])\n\nplt.xlabel('Time period')\nplt.ylabel('Closing prices')\nplt.legend(['Actual Price', 'Predicted price'])\nplt.title('Closing price comparison for Amazon dataset', fontsize = 15)","496c0de8":"# Predict for apple stock data","e8994d2a":"### Visualization","2349eb4d":"# Exploratory Data Analysis","fec6ec3f":"# Model creation\n### Recurrent Neural Network\nVanilla neural networks do not have a memory and so they do not take into account any past event for predictions. But this kind of model is poor when working with time series data, where there is dependency accross time. This is where RNN come in. A RNN model has **memory**, which can help in retaining past data and so the predictions are made on those basis.\n\n### Long Short Term Memory\nSimple RNN models have a **short term memory** and are not able to retain dependencies that occured long before the current state. So LSTM or **long short term memory** is used to retain those dependencies as well, using something called gated units. More info can be found [here](https:\/\/medium.com\/x8-the-ai-community\/understanding-recurrent-neural-networks-in-6-minutes-967ab51b94fe).","a47d8252":"# Scaling the columns","9a3c41ee":"# Plot the Prediction and Test value","e18b59f3":"# Transfer learning","95f7be02":"# Scale","2f19fddc":"# Dataset : [NYSE Kaggle](https:\/\/www.kaggle.com\/dgawlik\/nyse)","10d1a5a6":"# Prediction on test data","fc5d661c":"# One hot encode the symbols","9b5e4eb4":"# Model training","261133e5":"# Now let's evaluate model's performance on stock data of Amazon and Apple.","5a429777":"So we have data from **4th of January, 2010** to **30th of December, 2016**","001a73ad":"# Filtering out the dataset\nOur aim will be limited to predicting **Apple, Google and Amazon stocks**. Ticker symbol for the respective companies are AAPL, GOOGL and AMZN.","95841446":"# Verify the shapes","48b03737":"# Convert to time series data","00018cb8":"# Taking stock price data of Google","914dd2f9":"# Build the model","4e2ebb8f":"# Creating the actual time series based numpy array\nAn **important** point to note is that we will have three outputs or target labels in y. These are the three closing prices, each for AAPL, AMAZN and GOOGL respectively.","5b31fdb7":"# Train\/test split","6776c820":"# Performance Metrics\n#### Mean Squared Error\nSum of squares of differences between actual value and predicted value, divided by the total number of samples. This is an **absolute measure**.\n#### R-squared score\nBasically this metric evaluates how well the model performs compared to predicting mean for every sample. This is a **relative measure**.","173dfb07":"### Visualization","f0576108":"### Training","f8bf8ead":"Since open price, low price, and high price are linearly correlated with closing price, only one of them will be selected to feed the model, to avoid overfitting. And the second feature will be **volume traded**.","20731e57":"So the we have data from **04th January, 2010 to 30th December, 2016**.","913853e3":"# Create timesteps of size 300","be77bf70":"# Aim :\n## Predicting Stock prices of Apple, Google and Amazon\nOur first aim is to predict the next day closing stock price for Apple, Google and Amazon. **For this we will train the model that learns from the data of all the 3 companies.**\n## Experiment with Transfer Learning\nAfter this we will see if we can design a model that only learns from the data of a single company (**Google**), but predicts well for the other two (**Apple and Amazon**) also. This is called **Transfer Learning**.","1791a722":"# Predict for amazon stock data","fc09fb59":"### Train on the last layer","da003426":"# Create arrays\nOnly use **open price and volume traded**, as other features are correlated with closing price.","d1e2508b":"# Create the dataset\nWe will use past 300 days data to predict future stock prices, 100 days of stock data for each company. We will use three fields, apart from **opening price and volume traded** to symbolize the company to which the data belongs to.","b1f5288e":"# Starting and ending duration","53b6b9d9":"# Train test split","487a28fd":"### Use the 'best_amazn_model.h5' for prediction","64f00283":"# Scale","3877e3e5":"It has already been observed that features **open, close, low and high** are highly correlated, so we must drop two of them (**low and high**) and **date** column. The other feature will be **volume traded**.","c44a12eb":"# Prediction"}}