{"cell_type":{"1b791656":"code","4f2a3fed":"code","0a5b5ad7":"code","de932bf9":"code","6b0aece1":"code","65ac0406":"code","37f7a152":"code","8023b45e":"code","1d6f1460":"code","8c3f89aa":"code","7c2beeae":"code","e6380438":"code","e951b09a":"code","6dc16e1c":"code","6ac2b2aa":"code","8e83d017":"code","6c3e2638":"code","d6c6217d":"code","2703c81e":"code","8430745b":"code","b9fc070d":"code","bbb4951f":"code","85cef8c0":"code","23e4b1c1":"code","ab8434f8":"code","8fefbdd6":"code","61cdff54":"code","8194a89c":"code","28a77c85":"code","1c09b836":"code","20dc06d1":"code","c6219c94":"code","68091b70":"code","cc86cd8f":"code","1883917e":"code","5871a536":"code","ed371921":"code","4bdb83eb":"code","cfb5e6ad":"code","82cf4ccb":"code","65724e6b":"code","5f4d3115":"code","8d3b487d":"code","f88cd582":"code","8fffc62e":"markdown","c1e10ec4":"markdown","74d58742":"markdown","0459b2cd":"markdown","d126e91a":"markdown","9e9e8067":"markdown","87cadc1c":"markdown","61ed6406":"markdown","f61005d6":"markdown","dadf504f":"markdown","c4f095d8":"markdown","be62a9cd":"markdown","50344faa":"markdown","e981ea39":"markdown","4ec12f88":"markdown","a7e7be3a":"markdown","9d5b3e71":"markdown","8ad8dbf2":"markdown","98d5862b":"markdown","249d9597":"markdown","d2fdeef1":"markdown"},"source":{"1b791656":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(\"Setup Complete.\")\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f2a3fed":"# Importing Libraries\nimport matplotlib.pyplot as plt\nplt.style.use('default')\nimport seaborn as sns\nimport plotly.figure_factory as ff\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,roc_auc_score,classification_report,f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom mlxtend.classifier import StackingCVClassifier\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Library Setup Complete.\")","0a5b5ad7":"# Reading Data\nheart_filepath =  \"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\"\nheart_data = pd.read_csv(heart_filepath)\nprint(\"Read Complete.\")","de932bf9":"# Examining Data\nheart_data.head()","6b0aece1":"# Examining Data\nheart_data.tail()","65ac0406":"# Determining size\nheart_data.shape","37f7a152":"# Examining statistics\nheart_data.describe()","8023b45e":"# Determining data types\nheart_data.dtypes","1d6f1460":"# Looking for unfilled values\nheart_data.isnull().sum()","8c3f89aa":"# Age distribution\nplt.figure(figsize=(20, 10))\nplt.title(\"Age of Patients\")\nplt.xlabel(\"Age\")\nsns.countplot(x=heart_data[\"age\"])","7c2beeae":"# Sex distribution\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsex_labels = ['Male', 'Female']\nsex_explode = (0.1, 0.1)\nplt.pie(heart_data['sex'].value_counts(), labels = sex_labels, startangle=90, shadow=True, explode= sex_explode, autopct='%1.1f%%', colors = ['blue', 'pink'])\nplt.title(\"Sex of Patients\")\nplt.legend(loc = \"lower right\")\nplt.subplot(1,2,2)\nheart_data['sex'].value_counts().plot(kind= 'bar',color=['blue', 'pink'])\nplt.ylabel(\"Count\")\nplt.xticks()","e6380438":"# Assigning meaning to chest pain values\ncp_data = heart_data[\"cp\"].value_counts().reset_index()\ncp_data\ncp_data['index'][0] = 'asymptomatic'\ncp_data['index'][1] = 'non-anginal'\ncp_data['index'][2] = 'atypical'\ncp_data['index'][3] = 'typical'\ncp_data","e951b09a":"# Chest pain distribution\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\ncp_labels = ['asymptomatic', 'non-anginal', 'atypical', 'typical']\ncp_explode = (0.1, 0.1, 0.1, 0.1)\nplt.pie(heart_data['cp'].value_counts(), labels = cp_labels, startangle= 90, shadow= True, explode= cp_explode, autopct='%1.1f%%')\nplt.title(\"Type of Chest Pain\")\nplt.legend(loc = 'lower left')\nplt.subplot(1,2,2)\nsns.barplot(x=cp_data[\"index\"],y=cp_data[\"cp\"])\nplt.xticks(rotation=0)\nplt.ylabel(\"Count\")\nplt.xlabel(\"\")","6dc16e1c":"# Blood pressure and heart rate distribution\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsns.distplot(heart_data['trtbps'], kde=True, color = 'magenta')\nplt.xlabel(\"Resting Blood Pressure (mmHg)\")\nplt.subplot(1,2,2)\nsns.distplot(heart_data['thalachh'], kde=True, color = 'teal')\nplt.xlabel(\"Maximum Heart Rate Achieved (bpm)\")","6ac2b2aa":"# Cholesterol and fasting blood sugar distribution\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsns.distplot(heart_data['chol'], kde=True, color = 'Gold')\n\nplt.xlabel(\"Cholesterol (mg\/dL)\")\nplt.subplot(1,2,2)\nfbs_labels = ['False', 'True']\nfbs_explode = (0.1, 0.1)\nfbs_colors = ['lime', 'grey']\nplt.pie(heart_data['fbs'].value_counts(), labels = fbs_labels, startangle=90, shadow=True, explode= fbs_explode, autopct='%1.1f%%', colors = fbs_colors)\nplt.title(\"Fasting Blood Sugar > 120 mg\/dL\")\nplt.legend(loc = \"lower right\")","8e83d017":"# Exercise angina and ST Depression distribution\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nexng_labels = ['No', 'Yes']\nexng_explode = (0.1, 0.1)\nexng_colors = ['yellow', 'purple']\nplt.pie(heart_data['exng'].value_counts(), labels = exng_labels, startangle=90, shadow=True, explode= exng_explode, autopct='%1.1f%%', colors = exng_colors)\nplt.title(\"Exercise Induced Angina\")\nplt.legend(loc = \"lower right\")\nplt.subplot(1,2,2)\nsns.kdeplot(heart_data['oldpeak'], color = 'cyan', shade = True)\nplt.xlabel(\"ST Depression Induced by Exercise Relative to Rest\")\n","6c3e2638":"# Assigning meaning to ECG values\necg_data = heart_data[\"restecg\"].value_counts().reset_index()\necg_data['index'][0] = 'normal'\necg_data['index'][1] = 'hypertrophy'\necg_data['index'][2] = 'ST-T abnormality'\necg_data","d6c6217d":"# Assigning meaning to slope of ST-segment values\nslp_data = heart_data[\"slp\"].value_counts().reset_index()\nslp_data['index'][0]= 'upsloping'\nslp_data['index'][1]= 'flat'\nslp_data['index'][2]= 'downsloping'\nslp_data","2703c81e":"# ECG and ST-segment distribution\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsns.barplot(x=ecg_data[\"index\"],y=ecg_data[\"restecg\"], palette = 'bright')\nplt.xticks(rotation=0)\nplt.ylabel(\"Count\")\nplt.xlabel(\"Resting Electrocardiographic Results\")\nplt.subplot(1,2,2)\nsns.barplot(x=slp_data[\"index\"],y=slp_data[\"slp\"], palette = 'CMRmap_r')\nplt.xticks(rotation=0)\nplt.ylabel(\"Count\")\nplt.xlabel(\"Slope of the Peak Exercise ST Segment\")","8430745b":"# Assigning unknown to missing major vessel values \ncaa_data = heart_data[\"caa\"].value_counts().reset_index()\ncaa_data['index'][4] = \"unknown\"\ncaa_data","b9fc070d":"# Assigning unknown to missing Thalassemia values \nthall_data = heart_data[\"thall\"].value_counts().reset_index()\nthall_data['index'][3] = \"unknown\"\nthall_data","bbb4951f":"# Major vessels and Thalassemia\nplt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nsns.barplot(x=caa_data[\"index\"],y=caa_data[\"caa\"], palette = 'gist_ncar')\nplt.xticks(rotation=0)\nplt.ylabel(\"Count\")\nplt.xlabel(\"Number of Major Vessels Colored by Flourosopy\")\nplt.subplot(1,2,2)\nsns.barplot(x = thall_data['index'], y=thall_data[\"thall\"], palette = 'brg', order = [1,2,3,'unknown'])\nplt.xticks(rotation=0)\nplt.ylabel(\"Count\")\nplt.xlabel(\"Form of Thalassemia\")","85cef8c0":"# Heatmap\nplt.figure(figsize=(20,10))\nsns.heatmap(heart_data.corr(),annot=True,cmap=\"jet\")","23e4b1c1":"# Pairplot\nplt.figure(figsize=(20,10))\nsns.pairplot(heart_data, hue= 'output')","ab8434f8":"# Analysis of continuous features with respect to output\nff_age = ff.create_distplot([heart_data[heart_data.output==1].age,heart_data[heart_data.output==0].age],[\"Heart Disease\",\"No Heart Disease\"], colors = ['red', 'blue'])\nff_age.update_layout(title=\"Distribution of Heart Disease with Respect to Age\", xaxis_title=\"Age\")\nff_age.show()\nff_bp = ff.create_distplot([heart_data[heart_data.output==1].trtbps,heart_data[heart_data.output==0].trtbps],[\"Heart Disease\",\"No Heart Disease\"], colors = ['red', 'blue'])\nff_bp.update_layout(title=\"Distribution of Heart Disease with Respect to Blood Pressure (mmHg)\", xaxis_title=\"Blood Pressure (mmHg)\")\nff_bp.show()\nff_hr = ff.create_distplot([heart_data[heart_data.output==1].thalachh,heart_data[heart_data.output==0].thalachh],[\"Heart Disease\",\"No Heart Disease\"], colors = ['red', 'blue'])\nff_hr.update_layout(title=\"Distribution of Heart Disease with Respect to Maxiumum Heart Rate Achieved (bpm)\", xaxis_title=\"Maxiumum Heart Rate Achieved (bpm)\")\nff_hr.show()\nff_chol = ff.create_distplot([heart_data[heart_data.output==1].chol,heart_data[heart_data.output==0].chol],[\"Heart Disease\",\"No Heart Disease\"], colors = ['red', 'blue'])\nff_chol.update_layout(title=\"Distribution of Heart Disease with Respect to Cholesterol (mg\/dL)\", xaxis_title=\"Cholesterol\")\nff_chol.show()\nff_op = ff.create_distplot([heart_data[heart_data.output==1].oldpeak,heart_data[heart_data.output==0].oldpeak],[\"Heart Disease\",\"No Heart Disease\"], colors = ['red', 'blue'])\nff_op.update_layout(title=\"Distribution of Heart Disease with Respect to Exercise induced ST segment depression\", xaxis_title=\"ST segment depression\")\nff_op.show()","8fefbdd6":"# Analysis of categorical features with respect to output\nsex_data = heart_data[['sex','output']]\nsex_data['sex'] = sex_data['sex'].replace([1],'male')\nsex_data['sex'] = sex_data['sex'].replace([0],'female')\nsex_data['output'] = sex_data['output'].replace([0],'no heart disease')\nsex_data['output'] = sex_data['output'].replace([1],'heart disease')\ncp_data = heart_data[['cp','output']]\ncp_data['cp'] = cp_data['cp'].replace([0],'asymptomatic')\ncp_data['cp'] = cp_data['cp'].replace([1],'atypical')\ncp_data['cp'] = cp_data['cp'].replace([2],'non-anginal')\ncp_data['cp'] = cp_data['cp'].replace([3],'typical')\ncp_data['output'] = cp_data['output'].replace([0],'no heart disease')\ncp_data['output'] = cp_data['output'].replace([1],'heart disease')\nfbs_data = heart_data[['fbs','output']]\nfbs_data['fbs'] = fbs_data['fbs'].replace([0],'<= 120 mg\/dl')\nfbs_data['fbs'] = fbs_data['fbs'].replace([1],'> 120 mg\/dl')\nfbs_data['output'] = fbs_data['output'].replace([0],'no heart disease')\nfbs_data['output'] = fbs_data['output'].replace([1],'heart disease')                   \necg_data = heart_data[['restecg','output']]           \necg_data['restecg'] = ecg_data['restecg'].replace([0],'normal')\necg_data['restecg'] = ecg_data['restecg'].replace([1],'hypertrophy')\necg_data['restecg'] = ecg_data['restecg'].replace([2],'ST-T abnormality')\necg_data['output'] = ecg_data['output'].replace([0],'no heart disease')\necg_data['output'] = ecg_data['output'].replace([1],'heart disease')\nexng_data = heart_data[['exng','output']]                 \nexng_data['exng'] = exng_data['exng'].replace([0],'No')\nexng_data['exng'] = exng_data['exng'].replace([1],'Yes')\nslp_data = heart_data[['slp','output']]  \nslp_data['slp'] = slp_data['slp'].replace([0],'normal')\nslp_data['slp'] = slp_data['slp'].replace([1],'upsloping')\nslp_data['slp'] = slp_data['slp'].replace([2],'downsloping')\nslp_data['output'] = slp_data['output'].replace([0],'no heart disease')\nslp_data['output'] = slp_data['output'].replace([1],'heart disease')\nsns.catplot(x=\"sex\", data=sex_data, kind=\"count\", hue=\"output\")\nsns.catplot(x=\"cp\", data=cp_data, kind=\"count\", hue=\"output\")\nsns.catplot(x=\"fbs\", data=fbs_data, kind=\"count\", hue=\"output\")\nsns.catplot(x=\"restecg\", data=ecg_data, kind=\"count\", hue=\"output\")\nsns.catplot(x=\"exng\", data=exng_data, kind=\"count\", hue=\"output\")\nsns.catplot(x=\"slp\", data=slp_data, kind=\"count\", hue=\"output\")\nsns.catplot(x=\"caa\", data=heart_data, kind=\"count\", hue=\"output\")\nsns.catplot(x=\"thall\", data=heart_data, kind=\"count\", hue=\"output\")","61cdff54":"# Assigning variables\ny = heart_data['output']\nX = heart_data.drop('output', axis=1)","8194a89c":"# train-test-split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 0)","28a77c85":"# Scaling data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","1c09b836":"# Dummy classifier (expected baseline accuracy)\ndummy_clf = DummyClassifier(strategy=\"stratified\")\ndummy_clf.fit(X_train, y_train)\nDummyClassifier(strategy='stratified')\ndummy_clf.predict(X_test)\ndummy_score = dummy_clf.score(X_test, y_test)\nprint(\"The expected success rate from guessing is\", dummy_score)","20dc06d1":"# Logistic Regression Model\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\nlr_predict = lr.predict(X_test)\nlr_conf_matrix = confusion_matrix(y_test, lr_predict)\nlr_acc_score = accuracy_score(y_test, lr_predict)\nprint(\"Logistic Regression Confussion Matrix:\")\nprint(lr_conf_matrix)\nprint('\\n')\nprint(\"Accuracy of Logistic Regression:\")\nprint(lr_acc_score*100, '%')","c6219c94":"# Support Vector Classifier Model \nsvc =  SVC(kernel='rbf', C=2)\nsvc.fit(X_train, y_train)\nsvc_predict = svc.predict(X_test)\nsvc_conf_matrix = confusion_matrix(y_test, svc_predict)\nsvc_acc_score = accuracy_score(y_test, svc_predict)\nprint(\"Support Vector Classifier Confussion Matrix:\")\nprint(svc_conf_matrix)\nprint('\\n')\nprint(\"Accuracy of Support Vector Classifier:\")\nprint(svc_acc_score*100, '%')","68091b70":"# K-Nearest Neighbor Model\nknn = KNeighborsClassifier(n_neighbors=10)\nknn.fit(X_train, y_train)\nknn_predict = knn.predict(X_test)\nknn_conf_matrix = confusion_matrix(y_test, knn_predict)\nknn_acc_score = accuracy_score(y_test, knn_predict)\nprint(\"K-Nearest Neighbors Confussion Matrix\")\nprint(knn_conf_matrix)\nprint('\\n')\nprint(\"Accuracy of K-Nearest Neighbors Model:\")\nprint(knn_acc_score*100, '%')","cc86cd8f":"# Naive Bayes Model\nnb = GaussianNB()\nnb.fit(X_train,y_train)\nnb_predict = nb.predict(X_test)\nnb_conf_matrix = confusion_matrix(y_test,nb_predict)\nnb_acc_score = accuracy_score(y_test, nb_predict)\nprint(\"Naive Bayes Confussion Matrix\")\nprint(nb_conf_matrix)\nprint('\\n')\nprint(\"Accuracy of Naive Bayes Model:\")\nprint(nb_acc_score*100, '%')","1883917e":"# Decision Tree Model\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\ndtc_predict = dtc.predict(X_test)\ndtc_conf_matrix = confusion_matrix(y_test, dtc_predict)\ndtc_acc_score = accuracy_score(y_test, dtc_predict)\nprint(\"Decision Tree Classifier Confussion Matrix\")\nprint(dtc_conf_matrix)\nprint('\\n')\nprint(\"Accuracy of Decision Tree Classifier Model:\")\nprint(dtc_acc_score*100, '%')","5871a536":"# Random Forest Model\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\nrfc_predict = rfc.predict(X_test)\nrfc_conf_matrix = confusion_matrix(y_test, rfc_predict)\nrfc_acc_score = accuracy_score(y_test, rfc_predict)\nprint(\"Random Forest Classifier Confussion Matrix\")\nprint(rfc_conf_matrix)\nprint('\\n')\nprint(\"Accuracy of Random Forest Classifier Model:\")\nprint(rfc_acc_score*100, '%')","ed371921":"# Extreme Gradient Boost Model\nxgb = XGBClassifier(learning_rate=0.01, n_estimators= 100, max_depth=10, booster='dart',use_label_encoder= False)\nxgb.fit(X_train, y_train)\nxgb_predict = xgb.predict(X_test)\nxgb_conf_matrix = confusion_matrix(y_test, xgb_predict)\nxgb_acc_score = accuracy_score(y_test, xgb_predict)\nprint(\"Extreme Gradient Boosting Confussion Matrix\")\nprint(xgb_conf_matrix)\nprint('\\n')\nprint(\"Accuracy of Extreme Gradient Boosting Model:\")\nprint(xgb_acc_score*100, '%')","4bdb83eb":"# Creating Dataframe of Model Accuracies\nmodel_ev = pd.DataFrame({'Model': ['Logistic Regression', 'Support Vector Classifier','K-Nearest Neighbour','Naive Bayes','Decision Tree','Random Forest','Extreme Gradient Boost'],\n                         'Accuracy': [lr_acc_score*100, svc_acc_score*100, knn_acc_score*100,nb_acc_score*100, dtc_acc_score*100, rfc_acc_score*100, xgb_acc_score*100]})\nmodel_ev","cfb5e6ad":"#Stacking CV Classifier (Ensemble) Model of two best models\nscv=StackingCVClassifier(classifiers=[svc,knn],meta_classifier= svc, random_state= 25)\nscv.fit(X_train,y_train)\nscv_predict = scv.predict(X_test)\nscv_conf_matrix = confusion_matrix(y_test, scv_predict)\nscv_acc_score = accuracy_score(y_test, scv_predict)\nprint(\"Stacking CV Classifier Confusion Matrix\")\nprint(scv_conf_matrix)\nprint(\"\\n\")\nprint(\"Accuracy of Stacking CV Classifier Model:\",scv_acc_score*100,'\\n')","82cf4ccb":"# Feature importance of Extreme Gradient Boost Model\nxgb_imp_feature = pd.DataFrame({'Feature': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal'], 'Importance': (((xgb.feature_importances_ * 100) \/ (xgb.feature_importances_.max() * 100) *100))})\nxgb_imp_feature.sort_values(by = 'Importance', inplace=True)\nplt.figure(figsize=(10,4))\nplt.title(\"Gradient Boost Feature Importance\")\nplt.xlabel(\"importance \")\nplt.ylabel(\"features\")\nplt.barh(xgb_imp_feature['Feature'],xgb_imp_feature['Importance'])\nplt.show()","65724e6b":"# Feature importance of Logistic Regression Model\nlog_imp_feature = pd.DataFrame({'Feature': ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n       'exang', 'oldpeak', 'slope', 'ca', 'thal'], 'Importance': (abs(lr.coef_[0] * 100))\/(abs(lr.coef_[0] * 100)).max()*100})\nlog_imp_feature.sort_values('Importance', inplace = True)\nplt.figure(figsize=(10,4))\nplt.title(\"Logistic Regression Feature Importance\")\nplt.xlabel(\"importance \")\nplt.ylabel(\"features\")\nplt.barh(log_imp_feature['Feature'],log_imp_feature['Importance'])\nplt.show()","5f4d3115":"# Plotting accuracy of various classification models\ncolors = ['red','yellow','blue','orange','green','purple','grey',]\nplt.figure(figsize=(20,8))\nplt.title(\"Accuracy of Various Classification Models\")\nplt.xlabel(\"Model\")\nplt.ylabel(\"Accuracy (%)\")\nplt.bar(model_ev['Model'],model_ev['Accuracy'],color = colors)\nplt.show()","8d3b487d":"# ROC curves of models\nfpr_lr, tpr_lr, thr_lr = roc_curve(y_test, lr_predict)\nfpr_svc, tpr_svc, thr_log = roc_curve(y_test, svc_predict)\nfpr_knn, tpr_knn, thr_knn = roc_curve(y_test, knn_predict)\nfpr_nb, tpr_nb, thr_log = roc_curve(y_test, nb_predict)\nfpr_dtc, tpr_dtc, thr_dtc = roc_curve(y_test, dtc_predict)\nfpr_rfc, tpr_rfc, thr_rfc = roc_curve(y_test, rfc_predict)\nfpr_xgb, tpr_xgb, thr_log = roc_curve(y_test, xgb_predict)\nfpr_scv, tpr_scv, thr_scv = roc_curve(y_test, scv_predict)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.plot(fpr_lr, tpr_lr,label = 'LR')\nplt.plot(fpr_knn, tpr_knn,label = 'KNN')\nplt.plot(fpr_dtc, tpr_dtc,label = 'DTC')\nplt.plot(fpr_rfc, tpr_rfc,label = 'RFC')\nplt.plot(fpr_xgb,tpr_xgb,label= 'XGB')\nplt.plot(fpr_nb,tpr_nb,label= 'NB')\nplt.plot(fpr_svc,tpr_svc,label= 'SVC')\nplt.plot(fpr_scv, tpr_scv,label = 'SCV')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc = 'lower right')\nplt.title('ROC Curve')\nplt.show()","f88cd582":"# Confusion Matrix of Ensemble Model enlarged\noptions = [\"Disease\", 'No Disease']\n\nfig, ax = plt.subplots()\nim = ax.imshow(scv_conf_matrix, cmap= 'Set3', interpolation='nearest')\n\n# We want to show all ticks...\nax.set_xticks(np.arange(len(options)))\nax.set_yticks(np.arange(len(options)))\n# ... and label them with the respective list entries\nax.set_xticklabels(options)\nax.set_yticklabels(options)\n\n# Rotate the tick labels and set their alignment.\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n         rotation_mode=\"anchor\")\n\n# Loop over data dimensions and create text annotations.\nfor i in range(len(options)):\n    for j in range(len(options)):\n        text = ax.text(j, i, scv_conf_matrix[i, j],\n                       ha=\"center\", va=\"center\", color=\"black\")\n\nax.set_title(\"Confusion Matrix of Ensemble Model\")\nfig.tight_layout()\nplt.xlabel('Model Prediction')\nplt.ylabel('Actual Result')\nplt.show()","8fffc62e":"***","c1e10ec4":"The leading cause of death in the United States is heart disease, which is responsible for approximately 25% of all deaths in the country. This dataset details the vitals, conditions, and demographics of various patients, including whether or not they have heart disease. By analyzing the data and examining these features, it is possible to create classification models that can predict wheter or not a patient has heart disease. This notebook focuses on analyzing the dataset and creating a classification model with high accuracy in order to predict the likelihood of a future patient having heart disease.","74d58742":"***","0459b2cd":"***","d126e91a":"***","9e9e8067":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#FF0000;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Importing Libraries<\/h1>\n\n\n<\/div>","87cadc1c":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#FF0000;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Model Preparation<\/h1>\n\n\n<\/div>","61ed6406":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#FF0000;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Conclusion<\/h1>\n\n\n<\/div>","f61005d6":"In conclusion, we were able to successfully analyze the data and create a classification model that is able to predict whether or not a patient has heart disease with 90% accuracy. This was accomplished by using an ensemble method that combined two of our best classification models.\n\nThank you for taking the time to read through this notebook! I am a college student trying to get more invovled in the data science community by publishing some of my work online. I am studying biology and data science, so this project seemed like the perfect way to marry my interests. Please let me know if you have any suggestions or criticism as I look to improve my work. [This is my LinkedIn if you would like to connect!](linkedin.com\/in\/hassan-shah-0b1984205) \n\nLet me know if you have any suggestions for future projects!","dadf504f":"***","c4f095d8":"![Stay Home](https:\/\/www.deccanherald.com\/sites\/dh\/files\/styles\/article_detail\/public\/article_images\/2019\/11\/20\/heart-attack-1574189524.jpg?itok=brZDaNY7)\n[Source](https:\/\/www.deccanherald.com\/opinion\/panorama\/the-rising-threat-of-heart-disease-777809.html)","be62a9cd":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:110%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#FF0000;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Heart Disease Dataset Exploratory Data Analysis & Classification Project<\/h1>\n\n<\/div>","50344faa":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#FF0000;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Classification Models<\/h1>\n\n\n<\/div>","e981ea39":"***","4ec12f88":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#FF0000;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Bivariate Analysis<\/h1>\n\n\n<\/div>","a7e7be3a":"***","9d5b3e71":"***","8ad8dbf2":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#FF0000;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Reading & Examining Data<\/h1>\n\n\n<\/div>","98d5862b":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#FF0000;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Univariate Analysis<\/h1>\n\n\n<\/div>","249d9597":"<div style=\"color:white;\n           display:fill;\n           border-radius:10px;\n           font-size:90%;\n           font-family:serif;\n           letter-spacing:0.5px;\n           background-color:#FF0000;\n           color:GhostWhite;\n           font-family:Sans-serif;\n            padding:5px 5px 5px 5px;\n           \">\n<h1 style=\"text-align:center;font-weight: bold;\">Model Analysis<\/h1>\n\n\n<\/div>","d2fdeef1":"***"}}