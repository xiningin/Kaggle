{"cell_type":{"2198b8de":"code","90bfd4de":"code","2cd6f04e":"code","316f07f6":"code","a7c3aa9c":"code","41c063c8":"code","efbba11d":"code","758ab69f":"code","899e24fb":"code","6a7882c5":"code","f3b6e226":"code","852141fc":"code","8a788577":"code","810591e9":"code","0a4b466e":"code","83d65924":"code","dd0572e3":"code","5321eb04":"code","839dd1ea":"code","5440efb1":"code","4eeeebf0":"code","946b5322":"code","77ac6849":"code","5eeab97a":"code","3e07b2a2":"code","60cfeda1":"code","f3670de9":"code","8fdb346a":"code","78488fd9":"code","27384c9c":"code","3f5d8a21":"code","2edc1e18":"code","39d1f2b4":"code","a3c9c084":"code","bf09e9a9":"code","10987c2b":"code","efea4cb6":"code","eaf525db":"code","67f7579d":"code","bf7d1e85":"code","63129953":"code","6e10f14e":"code","ab46a6c5":"code","247bd19f":"code","9c086464":"code","8916782f":"code","61c0c0cf":"code","f96f679e":"code","a44b684b":"code","c0749041":"code","0e3f18a8":"code","fd7d613b":"code","afcd6b08":"code","3306d8f0":"code","499a7a96":"code","636f52b0":"code","fffc4173":"code","509cf0e4":"code","f0bce55b":"code","bd651951":"code","c6180e65":"code","0cd63183":"code","da948405":"code","d920f5f8":"code","b8930c46":"code","5c55f81e":"code","5ba215f0":"code","05246b85":"code","0ebbdb77":"code","9049cb3e":"code","12c9910d":"code","40f3bf6e":"code","dc69ef99":"code","18ca6b1f":"code","2d36275e":"code","af232538":"code","f4895993":"code","b95cfac5":"code","f89fbaa3":"code","259376ad":"code","5618b166":"code","0e12b753":"code","02d1a30f":"code","9042f3ad":"code","704c8cf6":"code","40d5452c":"code","9fda7392":"code","c28dfe21":"code","26e985c2":"code","110ff65b":"code","26e0c1d1":"code","bb53e4d8":"code","69d5e8ce":"code","c9ca6acb":"code","73b7d2d5":"code","2d5f3d46":"code","f7fa6cfa":"code","27af0d85":"code","12b9e42e":"code","58a7697c":"code","84e83e02":"code","9da02630":"code","28ae91da":"code","e8f3a1b9":"code","292aae1d":"code","84a269b2":"code","c3167eb5":"code","e8f7f05b":"code","62d2efaa":"code","feceecc7":"code","fd10002f":"code","8ee4cbf9":"code","18a58a77":"code","fb1ebfa6":"code","37c0ddc7":"code","b32073a6":"code","d0b63323":"code","cffb6199":"code","fbc5ceef":"code","f513c68d":"code","581d4b50":"code","5409a782":"code","96d3d013":"code","c1338274":"code","8bf4f4f7":"code","cbc8ead6":"code","51adba87":"code","64edac96":"code","7fbeb366":"code","2fe0bb3d":"code","3a556bbf":"code","7bd3d450":"markdown"},"source":{"2198b8de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","90bfd4de":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt ","2cd6f04e":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","316f07f6":"train.head()","a7c3aa9c":"def getNullsCols(data):\n    drop_cols = []\n    for col in data.columns :\n        nans = data[col].isna().sum()\n        if nans > len(data)*0.30:\n            drop_cols.append(col)\n    return drop_cols","41c063c8":"train_dr_cols = getNullsCols(train)","efbba11d":"test_dr_cols = getNullsCols(test)","758ab69f":"train_dr_cols, test_dr_cols","899e24fb":"#dropping the columns as the have the null values more than 30 %\n\ntrain.drop(['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], inplace = True, axis = 1)\ntest.drop(['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'], inplace = True, axis = 1)","6a7882c5":"train.head()","f3b6e226":"##Filling Na ","852141fc":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndigitcols_data_train = train.select_dtypes(numerics).columns","8a788577":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndigitcols_data_test = test.select_dtypes(numerics).columns","810591e9":"digitcols_data_train, digitcols_data_test","0a4b466e":"\nlen(digitcols_data_train),len(digitcols_data_test)","83d65924":"def fillNaForNumerCols(data, cols):\n    for col in cols :\n        if data[col].isna().sum() > 0.0 :\n            print(data[col].mean())\n            data[col].fillna(data[col].mean(), inplace = True)\n    return data","dd0572e3":"trian = fillNaForNumerCols(train, digitcols_data_test)","5321eb04":"train[digitcols_data_test].isna().sum()","839dd1ea":"test = fillNaForNumerCols(test, digitcols_data_test)","5440efb1":"test[digitcols_data_test].isna().sum()","4eeeebf0":"def fillNaForObjCols(data):\n    obj_cols = data.select_dtypes(['object','category'])\n    for col in obj_cols:\n        if data[col].isna().sum() > 0:\n            data[col].fillna(data[col].mode()[0], inplace = True)\n    return data","946b5322":"train_t","77ac6849":"train_t = fillNaForObjCols(train)","5eeab97a":"test_t = fillNaForObjCols(train)","3e07b2a2":"for i in train_t.isna().sum() > 0:\n    if i == True : \n        print(i)","60cfeda1":"for i in test_t.isna().sum() > 0:\n    if i == True : \n        print(i)","f3670de9":"test_t = fillNaForObjCols(test)","8fdb346a":"train = train_t","78488fd9":"test = test_t","27384c9c":"train.head()","3f5d8a21":"test.head()","2edc1e18":"def getNonUnqCols(data, thresh):\n    obj_cols = data.select_dtypes(['object', 'category'])\n    unq = []\n    for i in obj_cols:\n        unq_no = len(data[i].unique())\n        if unq_no > thresh:\n            unq.append(i)\n        \n    return unq\n","39d1f2b4":"nonUnq_train = getNonUnqCols(train, 6)\nnonUnq_test = getNonUnqCols(test, 6)","a3c9c084":"nonUnq_train, nonUnq_test","bf09e9a9":"nonUnq_train = getNonUnqCols(train, 9)\nnonUnq_test = getNonUnqCols(test, 9)","10987c2b":"nonUnq_train, nonUnq_test","efea4cb6":"nonUnq_train = getNonUnqCols(train, 5)\nnonUnq_test = getNonUnqCols(test, 5)\nnonUnq_train, nonUnq_test","eaf525db":"#The condition2 doesnt even have the same uniq values in the test data , i dont think its usefull therefore drop it \n#Drop = ['Condition2']","67f7579d":"#dropping the columns as the have the null values more than 30 %\n\ntrain.drop(['Condition2'], inplace = True, axis = 1)\ntest.drop(['Condition2'], inplace = True, axis = 1)","bf7d1e85":"nonUnq_train = getNonUnqCols(train, 7)\nnonUnq_test = getNonUnqCols(test, 7)\nnonUnq_train, nonUnq_test","63129953":"#dropping the columns as the have the null values more than 30 %\n\ntrain.drop(['HouseStyle'], inplace = True, axis = 1)\ntest.drop(['HouseStyle'], inplace = True, axis = 1)","6e10f14e":"#dropping the columns as the have the null values more than 30 %\n\ntrain.drop(['RoofMatl'], inplace = True, axis = 1)\ntest.drop(['RoofMatl'], inplace = True, axis = 1)","ab46a6c5":"nonUnq_train = getNonUnqCols(train, 7)\nnonUnq_test = getNonUnqCols(test, 7)\nnonUnq_train, nonUnq_test","247bd19f":"nonUnq_train = getNonUnqCols(train, 10)\nnonUnq_test = getNonUnqCols(test, 10)\nnonUnq_train, nonUnq_test","9c086464":"#how  the cols 'Condition1', 'SaleType' are affecting the SalePrice","8916782f":"#drop the cols more than 10 distinct values ","61c0c0cf":"#dropping the columns as the have the null values more than 30 %\n\ntrain.drop(['Neighborhood', 'Exterior1st', 'Exterior2nd'], inplace = True, axis = 1)\ntest.drop(['Neighborhood', 'Exterior1st', 'Exterior2nd'], inplace = True, axis = 1)","f96f679e":"import seaborn as sns","a44b684b":"sns.catplot(x = 'Condition1', y = 'SalePrice', data = train)","c0749041":"train['Condition1'].unique()","0e3f18a8":"sum(train['Condition1'] == 'RRNe'), sum(train['Condition1'] == 'PosA'), \nsum(train['Condition1'] == 'RRNn'), sum(train['Condition1'] == 'RRAe')","fd7d613b":"train.replace({'Condition1': {'RRNe': 'condLow', 'PosA': 'condLow'}}, inplace= True)","afcd6b08":"train.replace({'Condition1': {'RRAe': 'condLow'}}, inplace= True)","3306d8f0":"test.replace({'Condition1': {'RRNe': 'condLow', 'PosA': 'condLow','RRAe': 'condLow'}}, inplace= True)","499a7a96":"train['Condition1'].unique()","636f52b0":"test['Condition1'].unique()","fffc4173":"sns.catplot(x = 'SaleType', y = 'SalePrice', data = train)","509cf0e4":"train['SaleType'].unique()","f0bce55b":"#make the cols :- Con, CWD  as SaleType_1\n               # 'Oth', 'ConLw','ConLI','ConLD'   as SaleType_2 ","bd651951":"train.replace({'SaleType': {'Con': 'SaleType_1', 'CWD': 'SaleType_1'}}, inplace= True)\ntest.replace({'SaleType': {'Con': 'SaleType_1', 'CWD': 'SaleType_1'}}, inplace= True)","c6180e65":"train.replace({'SaleType': {'Oth': 'SaleType_2', 'ConLw': 'SaleType_2',\n                            'ConLI': 'SaleType_2','ConLD': 'SaleType_2'}}, inplace= True)\ntest.replace({'SaleType': {'Oth': 'SaleType_2', 'ConLw': 'SaleType_2',\n                            'ConLI': 'SaleType_2','ConLD': 'SaleType_2'}}, inplace= True)","0cd63183":"train['SaleType'].unique()","da948405":"test['SaleType'].unique()","d920f5f8":"#dropping the high correlated values ","b8930c46":"train.corr()['SalePrice']","5c55f81e":"#dropping the OverallQual as it has close 80 % correlated to the SalePrice ","5ba215f0":"#dropping the columns as the have the null values more than 30 %\n\ntrain.drop(['OverallQual'], inplace = True, axis = 1)\ntest.drop(['OverallQual'], inplace = True, axis = 1)","05246b85":"train.head()","0ebbdb77":"test.head()","9049cb3e":"#Seems like the data has lot of zeros in it ","12c9910d":"sum(train['EnclosedPorch'] == 0)","40f3bf6e":"sum(test['EnclosedPorch'] == 0)","dc69ef99":"len(train)*0.30","18ca6b1f":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncheck_zero_cols = test.select_dtypes(numerics).columns","2d36275e":"for col in check_zero_cols:\n    l = len(train)\n    if sum(train[col] == 0) > (l*0.40):\n        print(col)","af232538":"for col in check_zero_cols:\n    l = len(test)\n    if sum(test[col] == 0) > (l*0.40):\n        print('\\''+col+'\\',')","f4895993":"#dropping the columns as the have the null values more than 30 %\n\ntrain.drop(['MasVnrArea',\n'BsmtFinSF2',\n'2ndFlrSF',\n'LowQualFinSF',\n'BsmtFullBath',\n'BsmtHalfBath',\n'HalfBath',\n'Fireplaces',\n'WoodDeckSF',\n'OpenPorchSF',\n'EnclosedPorch',\n'3SsnPorch',\n'ScreenPorch',\n'PoolArea',\n'MiscVal'], inplace = True, axis = 1)\ntest.drop(['MasVnrArea',\n'BsmtFinSF2',\n'2ndFlrSF',\n'LowQualFinSF',\n'BsmtFullBath',\n'BsmtHalfBath',\n'HalfBath',\n'Fireplaces',\n'WoodDeckSF',\n'OpenPorchSF',\n'EnclosedPorch',\n'3SsnPorch',\n'ScreenPorch',\n'PoolArea',\n'MiscVal'], inplace = True, axis = 1)","b95cfac5":"train.head()","f89fbaa3":"test.head()","259376ad":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ncheck_zero_cols = test.select_dtypes(numerics).columns","5618b166":"for col in check_zero_cols:\n    l = len(train)\n    if sum(train[col] == 0) < (l*0.40) and sum(train[col] == 0) > (l*0.10):\n        print('\\''+col+'\\',')","0e12b753":"mean_train_BSMT  = train['BsmtFinSF1'].mean()","02d1a30f":"mean_test_BSMT  = test['BsmtFinSF1'].mean()","9042f3ad":"train.replace({'BsmtFinSF1': {0: mean_train_BSMT}}, inplace= True)\ntest.replace({'BsmtFinSF1': {0: mean_test_BSMT}}, inplace= True)","704c8cf6":"train.head()","40d5452c":"test.head()","9fda7392":"for col in check_zero_cols:\n    l = len(train)\n    if sum(train[col] == 0) < (l*0.40) and sum(train[col] == 0) > 0:\n        print('\\''+col+'\\',')","c28dfe21":"sum(train['TotalBsmtSF'] ==0)","26e985c2":"plt.scatter(train['TotalBsmtSF'] , train['SalePrice'] )","110ff65b":"plt.scatter(train['FullBath'] , train['SalePrice'] )","26e0c1d1":"plt.scatter(train['BsmtUnfSF'] , train['SalePrice'] )","bb53e4d8":"plt.scatter(train['BedroomAbvGr'] , train['SalePrice'] )","69d5e8ce":"plt.scatter(train['KitchenAbvGr'] , train['SalePrice'] )","c9ca6acb":"plt.scatter(train['GarageCars'] , train['SalePrice'] )","73b7d2d5":"plt.scatter(train['GarageArea'] , train['SalePrice'] )","2d5f3d46":"#Change the Dtypes of the Classifies columns such as \n# FullBath, GarageCars, KitchenAbvGr, BedroomAbvGr ","f7fa6cfa":"train['FullBath'] = train['FullBath'].astype('object')\ntrain['GarageCars'] = train['GarageCars'].astype('object')\ntrain['KitchenAbvGr'] = train['KitchenAbvGr'].astype('object')\ntrain['BedroomAbvGr'] = train['BedroomAbvGr'].astype('object')","27af0d85":"test['FullBath'] = test['FullBath'].astype('object')\ntest['GarageCars'] = test['GarageCars'].astype('object')\ntest['KitchenAbvGr'] = test['KitchenAbvGr'].astype('object')\ntest['BedroomAbvGr'] = test['BedroomAbvGr'].astype('object')","12b9e42e":"#Ajust some mean value in the 'GarageArea' as it is separated from the other values \n#adjust to the rangeof 200 to 400 like 260 which gives the same result as for the 0 Garbase area ","58a7697c":"train.replace({'GarageArea': {0: 260}}, inplace= True)\ntest.replace({'GarageArea': {0: 260}}, inplace= True)","84e83e02":"X  = train.iloc[:, :-1]","9da02630":"X.head()","28ae91da":"Y = pd.DataFrame(train.iloc[:, -1], columns={'SalePrice'})","e8f3a1b9":"Y","292aae1d":"X.drop(['Id'], inplace=True, axis = 1)","84a269b2":"test_ids = pd.DataFrame(test['Id'], columns={'Id'})","c3167eb5":"test.drop(['Id'], inplace=True, axis = 1)","e8f7f05b":"X_dumm = pd.get_dummies(X, drop_first=True)","62d2efaa":"X_dumm","feceecc7":"X_dumm.columns.values","fd10002f":"test_dumm = pd.get_dummies(test, drop_first=True)","8ee4cbf9":"test_dumm","18a58a77":"test_dumm.columns.values","fb1ebfa6":"for cols in X_dumm.columns.values:\n    if cols not in test_dumm.columns.values:\n        print(cols)","37c0ddc7":"for cols in test_dumm.columns.values:\n    if cols not in X_dumm.columns.values:\n        print(cols)","b32073a6":"#drop column in the test data are \n#'FullBath_4', 'GarageCars_1.7661179698216736', 'GarageCars_5.0'","d0b63323":"test_dumm.drop(['FullBath_4', 'GarageCars_1.7661179698216736', 'GarageCars_5.0'], inplace = True, axis = 1)","cffb6199":"for cols in test_dumm.columns.values:\n    if cols not in X_dumm.columns.values:\n        print(cols)","fbc5ceef":"test_dumm.rename(columns={\"GarageCars_1.0\": \"GarageCars_1\", \"GarageCars_2.0\": \"GarageCars_2\",\n                         \"GarageCars_3.0\": \"GarageCars_3\",\"GarageCars_4.0\": \"GarageCars_4\"}, inplace=True)","f513c68d":"for cols in test_dumm.columns.values:\n    if cols not in X_dumm.columns.values:\n        print(cols)","581d4b50":"for cols in X_dumm.columns.values:\n    if cols not in test_dumm.columns.values:\n        print('\\''+cols+'\\',')","5409a782":"#dropping these are they are not in the test \n#'Utilities_NoSeWa',\n'Heating_GasA',\n'Heating_OthW',\n'Electrical_Mix',\n'BedroomAbvGr_8',\n'KitchenAbvGr_3',\n'GarageQual_Fa',","96d3d013":"X_dumm.drop(['Utilities_NoSeWa',\n'Heating_GasA',\n'Heating_OthW',\n'Electrical_Mix',\n'BedroomAbvGr_8',\n'KitchenAbvGr_3',\n'GarageQual_Fa'], inplace = True, axis = 1)","c1338274":"X_dumm.head()","8bf4f4f7":"test_dumm.head()","cbc8ead6":"for cols in X_dumm.columns.values:\n    if cols not in test_dumm.columns.values:\n        print('\\''+cols+'\\',')","51adba87":"#All the coolumns have become equal and ready to model ","64edac96":"from sklearn.model_selection import GridSearchCV\n","7fbeb366":"from sklearn.ensemble import GradientBoostingRegressor","2fe0bb3d":"boosting = GradientBoostingRegressor()\nparams = {\n    'criterion':['mse'],\n    \"n_estimators\" : [50,100,200,400,350 ],\n    \"max_depth\" : [ 4,6]\n}\ncv = GridSearchCV(boosting, params, cv = 10)\ncv.fit(X_dumm, Y)","3a556bbf":"boost_res = cv.predict(test_dumm)\nfinal_deep = pd.concat([test_ids, pd.DataFrame(boost_res, columns={'SalePrice'})], axis=1)\nfinal_deep.to_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/submission.csv', index=False)","7bd3d450":"The RMSE is almost 1.4* which is not that perfect, the model should be trained in even better way...."}}