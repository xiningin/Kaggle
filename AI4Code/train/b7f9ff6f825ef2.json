{"cell_type":{"e2d4a0e7":"code","ef8a4f0e":"code","b2407225":"code","d3cbc498":"code","a05be131":"code","afaa07d1":"code","69e4b88c":"code","6af4fec9":"code","a9c1f429":"code","6e0a12cc":"markdown","949a807b":"markdown","db1dc2e5":"markdown","78ee07b6":"markdown","fb259569":"markdown","29a69bad":"markdown","9b804aaf":"markdown","1abda1ec":"markdown","edbde7b5":"markdown"},"source":{"e2d4a0e7":"#Importing libraries\n##Used to measure the runtime of algorithms\nimport time\n\n##Used to help predict errors\nimport typing\n\n##Numerical & plotting libb\nimport numpy as np\nimport matplotlib.pyplot as plt","ef8a4f0e":"def dot(x, y):\n    return sum([i * j for (i,j) in zip(x,y)])\n\ndef x_dot_x(x):\n    return dot(x, x)\n\ndef A_dot_x (A, x):\n    return [dot(a,x) for a, i in zip(A,x)]\n\ndef A_dot_A (A):\n    res = []\n    for i in range(len(A)):\n        a = []\n        for j in range(len(A)):\n            col = [A[k][j] for k in range(len(A))]\n            a.append( dot( A[i], col) )\n        res.append(a)\n    return res\n\ndef x_dot_A_dot_x (A,x):\n    return dot(x, A_dot_x(A, x) )","b2407225":"assert( x_dot_x( [1,2] ) == 5)\nassert( A_dot_x( [ [1,2], [2,1] ], [0,1] ) == [2,1] )\nassert( A_dot_A( [ [1,1], [2,0] ] ) == [ [3,1], [2,2] ])\nassert( x_dot_A_dot_x( [ [1,0], [0,1] ], [2,1] ) == 5)","d3cbc498":"def run_time(num_runs: int, f: typing.Callable, *args) -> float:\n    times = [None] * num_runs\n    \n    for i in range(num_runs):\n        start = time.time()\n        f(*args)\n        end = time.time()\n        times[i] = end - start\n    \n    return sum(times) \/ num_runs\n\ndef rand_vector(dim):\n    return np.random.rand(dim)\n\ndef rand_matrix(dim):\n    return np.random.rand(dim,dim)\n\ndef compare_runtime(dim: int, num_runs: int) -> (list, list):\n    \n    #Initializing\n    x = rand_vector(dim)\n    A = rand_matrix(dim)\n    \n    #Defining the Numpy functions we want to test\n    func_list = [np.dot, np.dot, np.dot, np.dot]\n    arg_list = [[x,x], [A,x], [A,x], [A,x]]\n    \n    #Computes the runtimes for each function with the appropriate arguments\n    np_results = [ run_time(num_runs, func, *args) for func, args in zip(func_list, arg_list)]\n    \n    #Not sure why this is necessary, maybe a somatic thing\n    x = x.tolist()\n    A = A.tolist()\n    \n    #Defining the above matrix operations\n    func_list = [x_dot_x, A_dot_x, A_dot_A, x_dot_A_dot_x]\n    arg_list = [[x], [A,x], [A], [A,x]]\n    \n    #Computes the runtimes for each function with the appropriate arguments\n    results = [run_time(num_runs, func, *args) for func, args in zip(func_list, arg_list)]\n    \n    return results, np_results","a05be131":"#Initialize the times \ntimes = []\nnp_times = []\n\n#Specify the dimesions that we want to use\ninput_size = [ 2**i for i in range(4,11) ]\n\nfor i in input_size:\n    #Computes the times for a given input size\n    results, np_results = compare_runtime(i, 3)\n    #Appends to times\n    times.append(results)\n    np_times.append(np_results)","afaa07d1":"#At the moment times is a list as long as input_size where each element has the times for each function at a \n#fixed input size\n\n#This step takes the ith element of each element in times and makes a list, therefore a list of times for one\n#function at different input sizes (eqivalent to a transpose)\ntable = [list(i) for i in zip(*times)]\nnp_table = [list(i) for i in zip(*np_times)]\n\n#Define the functions so we can include them in a plot\nfunc_names = [\"x_dot_x\", \"A_dot_x\", \"A_dot_A\", \"x_dot_A_dot_x\"]\n\n\n\n#Plots for each function\nfor t, np_t, name in  zip(table, np_table, func_names):\n    plt.plot(input_size, t, label=\"Raw python\")\n    plt.plot(input_size, np_t, label=\"NumPy\")\n    plt.title(f\"A graphic comparing the runtime of {name} against the Numpy library.\", y=1.05)\n    plt.legend()\n    plt.xlabel(\"Input size\")\n    plt.ylabel(\"Run time (s)\")\n    plt.show()","69e4b88c":"#taking the log of table and np_table\nscale = 2\n\nscale_t = np.log10( table )\nscale_np_t = np.log10( np_table )\nscale_x = np.log10( np.dot( scale, input_size))\n\n\n\n#Colors for the plot\ncolors = [\"red\", \"green\", \"blue\", \"black\"]\n\n#Plotting the log\n\nfor t, np_t, name, col in  zip(scale_t, scale_np_t, func_names, colors):\n    plt.plot(scale_x, t, \"-\", label = name, color = col)\n    plt.plot(scale_x, np_t, \"--\", label=\"NumPy\", color = col)\n    plt.title(\"A graphic comparing the runtime of raw python code against the Numpy library.\", y=1.05)\nplt.legend()\nplt.xlabel(\"Input size\")\nplt.ylabel(\"Run time (s)\")\nplt.show()","6af4fec9":"Num_CPU = 4\nFlop = Num_CPU * 16 * 2.2e9\n\n\nFlop = \"{:.2e}\".format(Flop)\n\nprint(f\"Theoretical: {Flop} FLOPS\")","a9c1f429":"#Calculates the number of floating point operations for each input size for A_dot_x\nreal_FLOP = [2* n **2 - n  for n in input_size] \n\n#Takes times for matix multiplication, numpy and raw python\nmy_times = table[1]\nnp_times = np_table[1]\n\n\n#Calculates FLOPS for algorithm for both numpy and raw python\nmy_FLOPS = [ flop\/time for flop, time in zip( real_FLOP, my_times) ]\nnp_FLOPS = [ flop\/time for flop, time in zip( real_FLOP, np_times) ]\n\n\nmy_FLOPS =  \"{:.2e}\".format( sum(my_FLOPS)\/( len(my_FLOPS) ) )\nnp_FLOPS =  \"{:.2e}\".format( sum(np_FLOPS)\/( len(np_FLOPS) ) )\n\n#Print the FLOPS for raw python and numpy\nprint(f\"Measured raw python: {my_FLOPS} FLOPS\")\nprint(f\"Measured Numpy: {np_FLOPS} FLOPS\")","6e0a12cc":"Let's consider matrix multiplication. The computational complexity of matrix vector multiplication is $n (2n - 1) = 2n^2 - n$ which makes it of order $\\mathcal{O}(n^2)$.","949a807b":"# Why is Numpy so fast?\n\nWe will implement different matrix operations by hand, test the implementation and compare the speed with the optimized numpy library. We will also study the computational complexity of these matrix operations, and estimate the performance of our computer.","db1dc2e5":"Now we can compare the run times of the raw python code with the built-in Numpy functions for different input sizes.","78ee07b6":"## Measurement and Visualization of Run-Time \n\nFor each of the implemented matrix operations, I measure the execution\ntime as a function of $n$ (input size), up to execution times on the order of one \nsecond. Compare the execution times of your implementation with a\ndedicated matrix library, e.g. the numpy package within python. Plot\nthe execution times for all matrix operations and both\nimplementations.\n\nBelow I define some functions that will be necessary to compare Numpy with my matrix operators defined above using raw python code. The first function function run_time takes in a function and computes how long it takes to execute the function, the input num_runs tells the function how many times to run the function and takes an average. The second two functions generate random inputs of varying sizes given by dim. The final function outputs the times taken for a function to run with an input of dimension size dim (it also computes the times for the corresponding Numpy functions)","fb259569":"## Matrix operations in raw python\n\nBelow we implement the matrix operations $\\mathbf{{x}}^T\\mathbf{{x}}$, $\\mathbf{{A}}\\mathbf{{x}}$, $\\mathbf{{A}}\\mathbf{{A}}$ and $\\mathbf{{x}}^T\\mathbf{{A}}\\mathbf{{x}}$ in Python without using the numpy package. Verify your implementation. It will be useful to define the dot product of two vectors $\\bf{x}$ and $\\bf{y}$ since all the following operations consist of different combinations of dot products.\n\nThis is the first time I've encountered the zip() function, the zip() function takes n arguments and returns an iterator and allows for easy indexing in loops","29a69bad":"Tests to see if the matrix operations above are doing the jobs","9b804aaf":"So as mentioned earlier, NumPy is about 3 orders of magnitude faster than raw python code. All of which are far less than the theoretical prediction of my hardware. This is due to memory access.","1abda1ec":"So from the above plots you can see that Numpy is considerably faster than raw python code. We will need to adjust our analysis in order to tell you \"how much faster\". Consider the following argument\n\nWe will use a $log_{10}$ plot to scale the varible so that the relationship between them becomes more clear. The runtime for all the above matrix operations and there numpy counterparts are given in a single plot.","edbde7b5":"## So how fast is Numpy?\n\nHow do the runtimes of the implementation in pure Python and numpy compare? What are the differences?\n\nNumPy is about 3 orders of magnitude faster that raw python code (1000 times faster). This is due to NumPy using compiled C code rather than using pure python code. This avoids the interpreting step performed by python making NumPy considerably faster. Complied languages are considerably faster than intepreted langauges although this makes them less flexiable and more difficult to debug.\n\nThe dot product has time complexity $\\mathcal{O}(n)$ which can be seen in its linear shape.\nThe multiplication of a matrix and a vector has time complexity $\\mathcal{O}(n^2)$ and this can be seen by the non-linear shape of the `A_dot_x()` function. Since matrix multiplication in `A_dot_A()` involves a matrix of dimension $n$ this increases the complexity of the algorithm by a factor of $n$ to make it $\\mathcal{O}(n^3)$. Therefore `x_A_dot_x()` has a complexity of $\\mathcal{O}(n^4)$.\n\nHow many floating point operations per second do the algorithms achieve? On which hardware did I execute the tests? Are your results in line with the FLOPS of your computer?\n\nMy Mac has a 2,2 GHz Quad-Core Intel Core i7 CPU. Therefore at 16 floating point operations per cycle we have"}}