{"cell_type":{"9d48d9c5":"code","74bf2936":"code","ae01e600":"code","64682b59":"code","dbc1ce83":"code","6dd9b77b":"code","a15b7a5c":"code","ac0ab03e":"code","0aeeb58c":"code","7c3d45f4":"code","c0abf2d0":"code","f7be45db":"code","052602cc":"code","f54ca495":"code","594fb897":"code","28576d33":"code","069fe2cd":"code","eb71651a":"code","59b3af61":"markdown","5b7f9c1f":"markdown","9b2d06ac":"markdown","7cd35344":"markdown","15461776":"markdown","efb27deb":"markdown","839100f9":"markdown","70bdd4a5":"markdown","b37a3f81":"markdown","64bcd847":"markdown","0ad20a94":"markdown","a7b82980":"markdown","4423f6e7":"markdown","4dc89d3d":"markdown","2acf385a":"markdown","0b3577e6":"markdown","4e438e55":"markdown","b1710df4":"markdown","63402cbd":"markdown","a370c8cf":"markdown"},"source":{"9d48d9c5":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","74bf2936":"train_df = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/test.csv')","ae01e600":"train_df['Cover_Type'].unique()","64682b59":"sns.set(color_codes=True)\nfig, ax = plt.subplots(figsize=(10,6))\nsns.countplot(x='Cover_Type', data=train_df, ax=ax)","dbc1ce83":"stat = pd.DataFrame(train_df['Cover_Type'].value_counts())\nstat['percent_type'] = stat['Cover_Type'] \/ stat['Cover_Type'].sum()\nstat.style.bar(subset=[\"percent_type\"], color='orange')\\\n    .format('{:.2%}', subset=[\"percent_type\"])","6dd9b77b":"from imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler","a15b7a5c":"train_df = train_df[train_df['Cover_Type'] < 4]","ac0ab03e":"X, y = train_df.drop(['Id', 'Cover_Type'], axis=1), train_df['Cover_Type']","0aeeb58c":"sns.set(color_codes=True)\nfig, ax = plt.subplots(figsize=(10,6))\nsns.countplot(y, ax=ax)","7c3d45f4":"oversample = RandomOverSampler(sampling_strategy='all', random_state=42)\nX_over, y_over = oversample.fit_resample(X, y)","c0abf2d0":"sns.set(color_codes=True)\nfig, ax = plt.subplots(figsize=(10,6))\nsns.countplot(y_over, ax=ax)","f7be45db":"print(f'sample size after oversampling: {y_over.shape[0]}')","052602cc":"undersample = RandomUnderSampler(sampling_strategy='all', random_state=42)\nX_under, y_under = undersample.fit_resample(X, y)","f54ca495":"sns.set(color_codes=True)\nfig, ax = plt.subplots(figsize=(10,6))\nsns.countplot(y_under, ax=ax)","594fb897":"print(f'sample size after oversampling: {y_under.shape[0]}')","28576d33":"from imblearn.under_sampling import TomekLinks\n\ntomek = TomekLinks(sampling_strategy='majority')\nX_tomek, y_tomek = tomek.fit_resample(X, y)","069fe2cd":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(sampling_strategy='majority')\nX_smote, y_smote = smote.fit_resample(X, y)","eb71651a":"from imblearn.combine import SMOTETomek\n\nST = SMOTETomek(sampling_strategy='auto')\nX_st, y_st = ST.fit_resample(X, y)","59b3af61":"Initial sample of the three major classes.","5b7f9c1f":"![image.png](attachment:c860ae6a-3b40-40d6-b3b7-6243370560a4.png)","9b2d06ac":"This method has some sampling strategies:\n* minority: resample only the minority class;\n* not minority: resample all classes but the minority class;\n* not majority: resample all classes but the majority class;\n* all: resample all classes;\n* auto: equivalent to 'not majority'  \nTry to use 'all'","7cd35344":"RandomOverSampler picks samples at random with replacement","15461776":"Some useful links:  \n**TOMEK:** https:\/\/imbalanced-learn.org\/stable\/references\/generated\/imblearn.under_sampling.TomekLinks.html  \n**SMOTE:** https:\/\/imbalanced-learn.org\/stable\/references\/generated\/imblearn.over_sampling.SMOTE.html  \n**SMOTETomek:** https:\/\/imbalanced-learn.org\/dev\/references\/generated\/imblearn.combine.SMOTETomek.html  ","efb27deb":"# Naive methods","839100f9":"# More advanced techniques","70bdd4a5":"On the other hand, SMOTE (Synthetic Minority Oversampling Technique) syntesizes the elements of minor classes. This technique uses the k-neighbors for indetification k similar elements and creates new, between this k-nearest elements.","b37a3f81":"More, we may use shrinkage param for smoothed bootstrap. New generated elements will be closer with increasing parameter shrinkage.","64bcd847":"**Thanks for reading my humble notebook. Good luck in TPS!**","0ad20a94":"**Cover types 4, 5, 6 are too few to classify.**","a7b82980":"The same way with Undersampling. Picking sampling_strategy='all' we'll expect the balance in three classes but with the less sample size","4423f6e7":"Try to resample the first three major classes.","4dc89d3d":"**However we may try to pay alghoritm attention to small classes in different ways.**\n**Let's take a look at the classes 1, 2 and 3. The sample is strongly unbalanced.**\nImbalanced classification is the problem of classification when there is an unequal distribution of classes in the training dataset.\nOne of the possible decisions is resampling.\nTwo widely spread technique are under- and over- sampling","2acf385a":"# <center> Unbalanced data <\/center>\n## <center> Hello everyone! Here I give some info about unbalanced data pre-processing. <\/center>","0b3577e6":"Tomek is an interesting method. The key idea of the method is that the algorithm removes from the selection those examples of the majority class that are too similar to examples of other classes, thereby making their separability more easy for classification.","4e438e55":"**There are 7 cover types. Needs to figure out the frequency of classes.**","b1710df4":"**Cover type 5 has only one sample, that isn't enough to classify this type. The same issue with the classes 4 and 6.**\nIt is pretty clear that sample imbalance leads to the metric trap. Accuracy score with true pred for class 1 and 2 and false pred for other classes will be close to ideal because shares of class 1 and 2 in sample are high enough. But we may also check F-score, presicion, recall and use confusion matrix.","63402cbd":"**That were classical or naive methods of resampling. But in addition, it should be said about Tomek and SMOT as under- and over- sampling strategies respectively.**","a370c8cf":"Evenmore, you may use SMOTE and Tomek together as a over-sampling after under-sampling with the SMOTETomek method"}}