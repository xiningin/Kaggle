{"cell_type":{"26bd2a33":"code","19c35b4e":"code","4ecd7bab":"code","5e5c0903":"code","c1cc7c73":"code","bf2bd379":"code","05900f4b":"code","4b0d8506":"code","c371f845":"code","db600f18":"code","55f413ab":"code","a8c3589d":"code","482f4aba":"code","463ae17e":"code","b8489328":"code","689175b4":"code","cf2f2ec0":"code","7889c786":"code","bb3ae85c":"code","3ecc45c2":"markdown","ed438f50":"markdown","8a2f9647":"markdown","20e2d9ac":"markdown"},"source":{"26bd2a33":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dropout, Dense, Input","19c35b4e":"df = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","4ecd7bab":"print('Info: ')\nprint(df.info())\n\nprint('\\n\\n\\nDescribe: ')\nprint(df.describe().round(2).transpose())","5e5c0903":"df = df.drop('Unnamed: 32', axis = 1)\ndf['diagnosis'] = df['diagnosis'].apply(lambda x: 1 if x == 'M' else 0)","c1cc7c73":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.countplot(data = df, x = 'diagnosis')\nplt.show()","bf2bd379":"plt.figure(figsize = (12, 6), dpi = 100)\nsns.heatmap(df.corr());","05900f4b":"X = df.drop('diagnosis', axis = 1).values\ny = df['diagnosis'].values","4b0d8506":"# 80-20 Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)","c371f845":"scaler = MinMaxScaler()\nX_train= scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","db600f18":"i = Input(shape=(None, 455, 31))\n\nx = Dense(16, activation='relu')(i)\nx = Dropout(0.5)(x)\n\nx = Dense(32, activation='relu')(i)\nx = Dropout(0.5)(x)\n\nx = Dense(64, activation='relu')(x)\nx = Dropout(0.5)(x)\n\nx = Dense(32, activation='relu')(x)\nx = Dropout(0.5)(x)\n\nx = Dense(16, activation='relu')(x)\nx = Dropout(0.5)(x)\n\ny = Dense(1, activation='sigmoid')(x)\n\nmodel_adam = Model(inputs=i, outputs=y)","55f413ab":"model_adam.compile(optimizer='adam', \n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])\n\nmodel_adam.summary()","a8c3589d":"early_stopping = EarlyStopping(monitor='val_loss', patience=25)\n\nhistory_adam = model_adam.fit(x=X_train, y=y_train,\n                             validation_data=(X_test, y_test),\n                             epochs=500,\n                             callbacks=[early_stopping])","482f4aba":"acc = history_adam.history['accuracy']\nval_acc = history_adam.history['val_accuracy']\n\nloss = history_adam.history['loss']\nval_loss = history_adam.history['val_loss']\n\nplt.figure(figsize=(12, 10))\nplt.subplot(2, 1, 1)\n\nplt.plot(acc, label='Training Accuracy', color='r')\nplt.plot(val_acc, label='Validation Accuracy', color='b')\n\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='lower right', fontsize=13)\nplt.ylabel('Accuracy', fontsize=16, weight='bold')\nplt.title('Adam', fontsize=16, weight='bold')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss', color='r')\nplt.plot(val_loss, label='Validation Loss', color='b')\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='upper right', fontsize=13)\nplt.ylabel('Cross Entropy', fontsize=16, weight='bold')\nplt.title('Adam - Training & Validation Loss', fontsize=16, weight='bold')\nplt.xlabel('Epoch', fontsize=15, weight='bold')\nplt.show()","463ae17e":"from sklearn.metrics import classification_report\n\nY_pred = model_adam.predict(X_test)\ny_pred = np.round(Y_pred).astype(int)\n\nprint(classification_report(y_test, y_pred))","b8489328":"import itertools\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(10, 10))\nplot_confusion_matrix(cnf_matrix, classes=['Malignant', 'Benign'],normalize=True,\n                      title='Normalized Confusion Matrix - Adam')\nplt.show()","689175b4":"model_rmsprop = Model(inputs=i, outputs=y)\n\nmodel_rmsprop.compile(optimizer='rmsprop', \n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])\n\nhistory_rmsprop = model_rmsprop.fit(x=X_train, y=y_train,\n                             validation_data=(X_test, y_test),\n                             epochs=500,\n                             callbacks=[early_stopping])","cf2f2ec0":"acc = history_rmsprop.history['accuracy']\nval_acc = history_rmsprop.history['val_accuracy']\n\nloss = history_rmsprop.history['loss']\nval_loss = history_rmsprop.history['val_loss']\n\nplt.figure(figsize=(12, 10))\nplt.subplot(2, 1, 1)\n\nplt.plot(acc, label='Training Accuracy', color='r')\nplt.plot(val_acc, label='Validation Accuracy', color='b')\n\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='lower right', fontsize=13)\nplt.ylabel('Accuracy', fontsize=16, weight='bold')\nplt.title('RMSProp', fontsize=16, weight='bold')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss', color='r')\nplt.plot(val_loss, label='Validation Loss', color='b')\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.legend(loc='upper right', fontsize=13)\nplt.ylabel('Cross Entropy', fontsize=16, weight='bold')\nplt.title('RMSProp - Training & Validation Loss', fontsize=16, weight='bold')\nplt.xlabel('Epoch', fontsize=15, weight='bold')\nplt.show()","7889c786":"from sklearn.metrics import classification_report\n\nY_pred_r = model_rmsprop.predict(X_test)\ny_pred_r = np.round(Y_pred_r).astype(int)\n\nprint(classification_report(y_test, y_pred_r))","bb3ae85c":"import itertools\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, weight='bold', fontsize=16)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, fontsize=14)\n    plt.yticks(tick_marks, classes, fontsize=14)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\", fontsize=12, weight='bold',\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label', fontsize=16, weight='bold')\n    plt.xlabel('Predicted label', fontsize=16, weight='bold')\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred_r)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure(figsize=(10, 10))\nplot_confusion_matrix(cnf_matrix, classes=['Malignant', 'Benign'],normalize=True,\n                      title='Normalized Confusion Matrix - Adam')\nplt.show()","3ecc45c2":"## **RMSProp**","ed438f50":"# Data Preparation","8a2f9647":"# **Conclution**\n#### **Adam Optimizer is the best choice here**\n#### **Results: 98% Accurcay**\n* **Adam: 98% Accurcay**\n* **RMSProp: 97% Accurcay**\n\n","20e2d9ac":"# Model Building"}}