{"cell_type":{"b8da21a7":"code","ef7db384":"code","97f018fb":"code","8189fd4f":"code","d36567dc":"code","9d5103f7":"code","26818a0e":"code","4201dd42":"code","3147bc7d":"code","44a8170b":"code","59d1d8c4":"code","505d61a3":"code","74258fb7":"code","eaaec700":"code","e535e58f":"code","2b1380fc":"code","0de5b6d5":"code","c38da007":"code","4c95e55f":"code","20bedee6":"code","0bdbea70":"code","33a364fd":"code","bd43b022":"code","50828433":"code","82e0cc75":"code","58f158f7":"code","23d32535":"code","5fbd7369":"code","34d4cca9":"code","0744dcfa":"code","fb39c870":"code","359f6c04":"code","9d180f2d":"markdown","abc40d1b":"markdown","e40dd6df":"markdown","d62b1bae":"markdown","00a9cff3":"markdown","3779e470":"markdown","00cc17fe":"markdown","e8dc9884":"markdown","306f5061":"markdown","1f7fb24b":"markdown","86dbdba1":"markdown"},"source":{"b8da21a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef7db384":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelBinarizer\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPooling2D , Flatten , Dropout \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix, accuracy_score","97f018fb":"df_train = pd.read_csv(\"\/kaggle\/input\/sign_mnist_train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/sign_mnist_test.csv\")","8189fd4f":"print(df_train.shape)\nprint(df_test.shape)","d36567dc":"(df_train['label'].unique())","9d5103f7":"df_train.head()","26818a0e":"df_test.head()","4201dd42":"plt.figure(figsize=(11,5))\nsns.countplot(df_train['label'])","3147bc7d":"y = df_train['label'].values\nx = df_train.values","44a8170b":"df_train.drop('label', axis = 1, inplace = True)","59d1d8c4":"# Label binarizer\nlabel_binrizer = LabelBinarizer()\nlabels = label_binrizer.fit_transform(y)","505d61a3":"labels.shape","74258fb7":"x = df_train.values\nx = np.array([np.reshape(i, (28, 28)) for i in x])\nx = np.array([i.flatten() for i in x])","eaaec700":"plt.imshow(x[2].reshape(28,28))","e535e58f":"plt.imshow(x[2].reshape(28,28))\nprint(labels[2])\n# letter C","2b1380fc":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, labels, test_size = 0.3, random_state = 101)\n","0de5b6d5":"x_train = x_train \/ 255\nx_test = x_test \/ 255","c38da007":"x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","4c95e55f":"x_train.shape","20bedee6":"#learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)","0bdbea70":"model = Sequential()\nmodel.add(Conv2D(64, (3,3), activation = 'relu', input_shape=(28, 28 ,1) ))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.20))\n\nmodel.add(Dense(24, activation = 'softmax'))\n","33a364fd":"model.summary()","bd43b022":"model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.RMSprop(), metrics=['accuracy'])","50828433":"history = model.fit(x_train, y_train, validation_data=(x_test,y_test),epochs=50, batch_size=128)","82e0cc75":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title(\"Accuracy\")\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend(['train','test'])\n\nplt.show()","58f158f7":"test_labels = df_test['label']","23d32535":"df_test.drop('label', axis = 1, inplace = True)","5fbd7369":"test_images = df_test.values\ntest_images = np.array([np.reshape(i, (28, 28)) for i in test_images])\ntest_images = np.array([i.flatten() for i in test_images])","34d4cca9":"test_labels = label_binrizer.fit_transform(test_labels)","0744dcfa":"test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)","fb39c870":"y_pred = model.predict(test_images)","359f6c04":"accuracy_score(test_labels, y_pred.round())","9d180f2d":"Plot for Label to identify class imbalance","abc40d1b":"Read datasets","e40dd6df":"Dropping the dimension 'label' to make as input to labelBinarizer","d62b1bae":"Getting Dimensions of dataframes","00a9cff3":"Building up model","3779e470":"Applying Prediction","00cc17fe":"Apparently this is the best accuracy we got !","e8dc9884":"The original MNIST image dataset of handwritten digits is a popular benchmark for image-based machine learning methods but researchers have renewed efforts to update it and develop drop-in replacements that are more challenging for computer vision and original for real-world applications. As noted in one recent replacement called the Fashion-MNIST dataset, the Zalando researchers quoted the startling claim that \"Most pairs of MNIST digits (784 total pixels per sample) can be distinguished pretty well by just one pixel\". To stimulate the community to develop more drop-in replacements, the Sign Language MNIST is presented here and follows the same CSV format with labels and pixel values in single rows. The American Sign Language letter database of hand gestures represent a multi-class problem with 24 classes of letters (excluding J and Z which require motion).","306f5061":"Working on Test Data","1f7fb24b":"Importing libraries","86dbdba1":"Displaying random image"}}