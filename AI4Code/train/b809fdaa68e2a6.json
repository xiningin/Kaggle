{"cell_type":{"f1b86c12":"code","d4cc0cfa":"code","9595cb43":"code","b68fb0c3":"code","b3f13943":"code","d071f02c":"code","8166c1e8":"code","6a0ff033":"code","f10ccdbc":"code","f45c65c3":"code","a34b3140":"code","bd634659":"code","ddfff09d":"code","82b3c7b2":"code","a248aafb":"code","f1e9d9c2":"code","568608df":"code","1dfff26f":"code","a1d9652c":"code","5012b88a":"code","90159cbc":"code","a2bb9a57":"code","1340ed2c":"code","7468728a":"code","88b2a4f2":"code","c791d4e3":"code","7f60ea50":"code","4dfadb83":"code","f91051c1":"code","71c4ad07":"code","53c96ba3":"markdown","426e0a5e":"markdown","d19b943f":"markdown","2bcf0377":"markdown","79a080f3":"markdown","bcb32622":"markdown","b311d911":"markdown","472707f8":"markdown","02d9e3bc":"markdown","dc21d32f":"markdown","39836405":"markdown","2393628d":"markdown","a2c3943a":"markdown","1189c33b":"markdown","bdc6755f":"markdown","c981475b":"markdown","576c551b":"markdown","7171b77a":"markdown","6d4403be":"markdown","6c1ab179":"markdown","44d41028":"markdown","9e926e02":"markdown","1f215bda":"markdown","b574e9ea":"markdown","66f49d48":"markdown","03545a46":"markdown","59a23761":"markdown","6f9b594b":"markdown"},"source":{"f1b86c12":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d4cc0cfa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # this is used for the plot the graph \nimport seaborn as sns # used for plot interactive graph.\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom sklearn.svm import SVC\n%matplotlib inline","9595cb43":"df=pd.read_csv('..\/input\/heart.csv')\ndf.head(5)","b68fb0c3":"df.describe()","b3f13943":"df.info()","d071f02c":"plt.figure(figsize=(14,10))\nsns.heatmap(df.corr(),annot=True,cmap='hsv',fmt='.3f',linewidths=2)\nplt.show()","8166c1e8":"df.groupby('cp',as_index=False)['target'].mean()","6a0ff033":"df.groupby('slope',as_index=False)['target'].mean()","f10ccdbc":"df.groupby('thal',as_index=False)['target'].mean()","f45c65c3":"df.groupby('target').mean()","a34b3140":"sns.distplot(df['target'],rug=True)\nplt.show()","bd634659":"pd.crosstab(df.age,df.target).plot(kind=\"bar\",figsize=(25,8),color=['gold','brown' ])\nplt.title('Heart Disease Frequency for Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()","ddfff09d":"pd.crosstab(df.sex,df.target).plot(kind=\"bar\",figsize=(10,5),color=['cyan','coral' ])\nplt.xlabel('Sex (0 = Female, 1 = Male)')\nplt.xticks(rotation=0)\nplt.legend([\"Haven't Disease\", \"Have Disease\"])\nplt.ylabel('Frequency')\nplt.show()","82b3c7b2":"plt.figure(figsize=(12,8))\nsns.boxplot(df['target'], df['trestbps'], palette = 'rainbow')\nplt.title('Relation of tresbps with target', fontsize = 10)","a248aafb":"sns.pairplot(data=df)","f1e9d9c2":"pd.crosstab(df.cp,df.target).plot(kind=\"bar\",figsize=(10,5),color=['tomato','indigo' ])\nplt.xlabel('Chest Pain Type')\nplt.xticks(rotation = 0)\nplt.ylabel('Frequency of Disease or Not')\nplt.show()\n","568608df":"plt.figure(figsize=(16,8))\nplt.subplot(2,2,1)\nplt.scatter(x=df.age[df.target==1],y=df.thalach[df.target==1],c='blue')\nplt.scatter(x=df.age[df.target==0],y=df.thalach[df.target==0],c='black')\nplt.xlabel('Age')\nplt.ylabel('Max Heart Rate')\nplt.legend(['Disease','No Disease'])\n\nplt.subplot(2,2,2)\nplt.scatter(x=df.age[df.target==1],y=df.chol[df.target==1],c='red')\nplt.scatter(x=df.age[df.target==0],y=df.chol[df.target==0],c='green')\nplt.xlabel('Age')\nplt.ylabel('Cholesterol')\nplt.legend(['Disease','No Disease'])\n\nplt.subplot(2,2,3)\nplt.scatter(x=df.age[df.target==1],y=df.trestbps[df.target==1],c='cyan')\nplt.scatter(x=df.age[df.target==0],y=df.trestbps[df.target==0],c='fuchsia')\nplt.xlabel('Age')\nplt.ylabel('Resting Blood Pressure')\nplt.legend(['Disease','No Disease'])\n\nplt.subplot(2,2,4)\nplt.scatter(x=df.age[df.target==1],y=df.oldpeak[df.target==1],c='grey')\nplt.scatter(x=df.age[df.target==0],y=df.oldpeak[df.target==0],c='navy')\nplt.xlabel('Age')\nplt.ylabel('ST depression')\nplt.legend(['Disease','No Disease'])\nplt.show()","1dfff26f":"chest_pain=pd.get_dummies(df['cp'],prefix='cp',drop_first=True)\ndf=pd.concat([df,chest_pain],axis=1)\ndf.drop(['cp'],axis=1,inplace=True)\nsp=pd.get_dummies(df['slope'],prefix='slope')\nth=pd.get_dummies(df['thal'],prefix='thal')\nrest_ecg=pd.get_dummies(df['restecg'],prefix='restecg')\nframes=[df,sp,th,rest_ecg]\ndf=pd.concat(frames,axis=1)\ndf.drop(['slope','thal','restecg'],axis=1,inplace=True)","a1d9652c":"df.head(5)","5012b88a":"X = df.drop(['target'], axis = 1)\ny = df.target.values","90159cbc":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","a2bb9a57":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","1340ed2c":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport warnings","7468728a":"classifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim = 11, init = 'uniform', activation = 'relu', input_dim = 22))\n\n# Adding the second hidden layer\nclassifier.add(Dense(output_dim = 11, init = 'uniform', activation = 'relu'))\n\n# Adding the output layer\nclassifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","88b2a4f2":"classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)","c791d4e3":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)","7f60ea50":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred.round())\nsns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False)\n#accuracy score\nfrom sklearn.metrics import accuracy_score\nac=accuracy_score(y_test, y_pred.round())\nprint('accuracy of the model: ',ac)","4dfadb83":"from sklearn.ensemble import RandomForestClassifier\nrdf_c=RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)\nrdf_c.fit(X_train,y_train)\nrdf_pred=rdf_c.predict(X_test)\nrdf_cm=confusion_matrix(y_test,rdf_pred)\nrdf_ac=accuracy_score(rdf_pred,y_test)\nplt.title(\"rdf_cm\")\nsns.heatmap(rdf_cm,annot=True,fmt=\"d\",cbar=False)\nprint('RandomForest_accuracy:',rdf_ac)","f91051c1":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\n%matplotlib inline\ndef plotting(true,pred):\n    fig,ax=plt.subplots(1,2,figsize=(10,5))\n    precision,recall,threshold = precision_recall_curve(true,pred[:,1])\n    ax[0].plot(recall,precision,'g--')\n    ax[0].set_xlabel('Recall')\n    ax[0].set_ylabel('Precision')\n    ax[0].set_title(\"Average Precision Score : {}\".format(average_precision_score(true,pred[:,1])))\n    fpr,tpr,threshold = roc_curve(true,pred[:,1])\n    ax[1].plot(fpr,tpr)\n    ax[1].set_title(\"AUC Score is: {}\".format(auc(fpr,tpr)))\n    ax[1].plot([0,1],[0,1],'k--')\n    ax[1].set_xlabel('False Positive Rate')\n    ax[1].set_ylabel('True Positive Rate')\nplotting(y_test,rdf_c.predict_proba(X_test))\nplt.figure()   \n    ","71c4ad07":"model_accuracy = pd.Series(data=[rdf_ac,ac], \n        index=['RandomForest','Neural Network'])\nfig= plt.figure(figsize=(8,8))\nmodel_accuracy.sort_values().plot.barh()\nplt.title('Model Accracy')","53c96ba3":"Neurons are the basic unit of a neural network. ... When the artificial neuron activates, it computes its state, by adding all the incoming inputs multiplied by its corresponding connection weight. But neurons always have one extra input, the bias, which is always 1, and has its own connection weight.","426e0a5e":"## Initialising the ANN","d19b943f":"Backpropagation (backward propagation) is an important mathematical tool for improving the accuracy of predictions in data mining and machine learning. Essentially, backpropagation is an algorithm used to calculate derivatives quickly.\nArtificial neural networks use backpropagation as a learning algorithm to compute a gradient descent with respect to weights. Desired outputs are compared to achieved system outputs, and then the systems are tuned by adjusting connection weights to narrow the difference between the two as much as possible. The algorithm gets its name because the weights are updated backwards, from output towards input.","2bcf0377":"## Creating Dummy Variables","79a080f3":"It's a clean, easy to understand set of data. However, the meaning of some of the column headers are not obvious. Here's what they mean,\n\n1.age: The person's age in years\n\n2.sex: The person's sex (1 = male, 0 = female)\n\n3.cp: The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n\n4.trestbps: The person's resting blood pressure (mm Hg on admission to the hospital)\n\n5.chol: The person's cholesterol measurement in mg\/dl\n\n6.fbs: The person's fasting blood sugar (> 120 mg\/dl, 1 = true; 0 = false)\n\n7.restecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n\n8.thalach: The person's maximum heart rate achieved\n\n9.exang: Exercise induced angina (1 = yes; 0 = no)\n\n10.oldpeak: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)\n\n11.slope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n\n12.ca: The number of major vessels (0-3)\n\n13.thal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n\n14.target: Heart disease (0 = no, 1 = yes)\n","bcb32622":"## Importing the Keras libraries and packages","b311d911":"# Introduction","472707f8":"## Keras neural network","02d9e3bc":"# Fitting the model","dc21d32f":"Keras is a powerful easy-to-use Python library for developing and evaluating deep learning models. It wraps the efficient numerical computation libraries Theano and TensorFlow and allows you to define and train neural network models in a few short lines of code\n\n<img src=\"https:\/\/miro.medium.com\/max\/932\/1*eJ36Jpf-DE9q5nKk67xT0Q.jpeg\" style=\"width: 450px;\"\/>","39836405":"### Choose the number of epochs\nThis is the number of times the dataset will pass through the network, each time updating the weights. As the number of epochs increases, the network becomes better and better at predicting the targets in the training set. You'll need to choose enough epochs to train the network well but not too many or you'll be overfitting.","2393628d":"<img src=\"http:\/\/barrymonaghan.com\/wp-content\/uploads\/2016\/10\/Barry-Monaghan-Performance-Newry-Triathlon-and-Cycling-Coaching-Resting-Heart-Rate.jpg\" style=\"width: 650px;\"\/>","a2c3943a":"## Neuron","1189c33b":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/1600\/0*rBQI7uBhBKE8KT-X.png\" style=\"width: 450px;\"\/>","bdc6755f":"## Effect of parameters on Heart Disease based on Age","c981475b":"### Corelation","576c551b":"<img src=\"https:\/\/www.researchgate.net\/profile\/Rozaida_Ghazali\/publication\/234005707\/figure\/fig2\/AS:667830315917314@1536234563135\/The-structure-of-single-hidden-layer-MLP-with-Backpropagation-algorithm.png\" style=\"width: 450px;\"\/>","7171b77a":"Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.","6d4403be":"Below you'll build your network. We've built out the structure and the backwards pass. You'll implement the forward pass through the network. You'll also set the hyperparameters: the learning rate, the number of hidden units, and the number of training passes.\n\nThe network has two layers, a hidden layer and an output layer. The hidden layer will use the sigmoid function for activations. The output layer has only one node and is used for the regression, the output of the node is the same as the input of the node. That is, the activation function is $f(x)=x$. A function that takes the input signal and generates an output signal, but takes into account the threshold, is called an activation function. We work through each layer of our network calculating the outputs for each neuron. All of the outputs from one layer become inputs to the neurons on the next layer. This process is called forward propagation.\n\nWe use the weights to propagate signals forward from the input to the output layers in a neural network. We use the weights to also propagate error backwards from the output back into the network to update our weights. This is called backpropagation.","6c1ab179":"## Gradient Decent ","44d41028":"## Backpropagation","9e926e02":"## I hope this kernel is helpfull for you -->> upvote will appreciate me for further work.","1f215bda":"The plot clearly suggests that the patients who are most likely to not suffer from the disease have a slighly greater blood pressure than the patients who have heart diseases.","b574e9ea":"<img src=\"https:\/\/sds-platform-private.s3-us-east-2.amazonaws.com\/uploads\/47_blog_image_2.png\" style=\"width: 450px;\"\/>","66f49d48":"#                   **KEEP THE BEAT**","03545a46":"* This dataset gives a number of variables along with a target condition of having or not having heart disease.\n*  We will try to use this data to create a model which tries predict if a patient has this disease or not.\n* The \"**goal**\" field refers to the presence of heart disease in the patient.","59a23761":"# Loading appropriate libraries","6f9b594b":"The **ROC curve**. In a Receiver Operating Characteristic (ROC) curve the true positive rate (Sensitivity) is plotted in function of the false positive rate (100-Specificity) for different cut-off points. Each point on the ROC curve represents a sensitivity\/specificity pair corresponding to a particular decision threshold.\n\nAs the area under an ROC curve is a measure of the usefulness of a test in general, where a greater area means a more useful test, the areas under ROC curves are used to compare the usefulness of tests. The term ROC stands for Receiver Operating Characteristic."}}