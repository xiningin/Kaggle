{"cell_type":{"3d6f2137":"code","0d90dcfc":"code","6f069569":"code","1ad13059":"code","ea50bc84":"code","e73787b7":"code","ce01e416":"code","0f112c24":"code","604c108b":"code","cbc0e787":"code","8e75384a":"code","6ccb4451":"code","e9e55767":"code","1c2e0127":"code","fed2f4ef":"code","fb67854d":"code","f30077aa":"code","7143b7d2":"markdown","76f9e80b":"markdown","cf3f4cd8":"markdown","14f64b13":"markdown","d02905c8":"markdown","cdd384f4":"markdown","0af8b49b":"markdown","34878861":"markdown","e58203b3":"markdown","ad75d9a6":"markdown","5a54cc2c":"markdown","532ea656":"markdown"},"source":{"3d6f2137":"import os\nimport json\nimport numpy as np\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom matplotlib import animation, rc\nfrom IPython.display import HTML\n\nrc('animation', html='jshtml')\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","0d90dcfc":"data_path = Path('\/kaggle\/input\/abstraction-and-reasoning-challenge')\ntrain_path = data_path \/ 'training'\nvalid_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'\n\ntrain_tasks = { task.stem: json.load(task.open()) for task in train_path.iterdir() } \nvalid_tasks = { task.stem: json.load(task.open()) for task in valid_path.iterdir() } ","6f069569":"cmap = colors.ListedColormap(\n        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\nnorm = colors.Normalize(vmin=0, vmax=9)\n    \ndef plot_pictures(pictures, labels):\n    fig, axs = plt.subplots(1, len(pictures), figsize=(2*len(pictures),32))\n    for i, (pict, label) in enumerate(zip(pictures, labels)):\n        axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n        axs[i].set_title(label)\n    plt.show()\n    \ndef plot_sample(sample, predict=None):\n    if predict is None:\n        plot_pictures([sample['input'], sample['output']], ['Input', 'Output'])\n    elif 'output' in sample:\n        plot_pictures([sample['input'], sample['output'], predict], ['Input', 'Output', 'Predict'])\n    else:\n        plot_pictures([sample['input'], predict], ['Input', 'Predict'])\n        \ndef inp2img(inp):\n    inp = np.array(inp)\n    img = np.full((10, inp.shape[0], inp.shape[1]), 0, dtype=np.uint8)\n    for i in range(10):\n        img[i] = (inp==i)\n    return img\n\ndef input_output_shape_is_same(task):\n    return all([np.array(el['input']).shape == np.array(el['output']).shape for el in task['train']])\n\n\ndef calk_score(task_test, predict):\n    return [int(np.equal(sample['output'], pred).all()) for sample, pred in zip(task_test, predict)]","1ad13059":"task = train_tasks[\"db3e9e38\"][\"train\"]\nfor sample in task:\n    plot_sample(sample)","ea50bc84":"class CAModel(nn.Module):\n    def __init__(self, num_states):\n        super(CAModel, self).__init__()\n        self.transition = nn.Sequential(\n            nn.Conv2d(num_states, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, num_states, kernel_size=1)\n        )\n        \n    def forward(self, x, steps=1):\n        for _ in range(steps):\n            x = self.transition(torch.softmax(x, dim=1))\n        return x","e73787b7":"import math\nimport random\n\ndef solve_task(task, max_steps=12):\n    model = CAModel(10).to(device)\n    num_epochs = 100\n    num_repeat = 25\n    criterion = nn.CrossEntropyLoss()\n    losses = np.zeros((num_repeat - 1) * num_epochs)\n\n    for i in range(1, num_repeat):\n        if i > num_repeat-4:\n            num_steps = max_steps\n        else:\n            num_steps = random.randint(1, max_steps)\n        optimizer = torch.optim.Adam(model.parameters(), lr=(0.04 \/ i))\n        \n        for e in range(num_epochs):\n            optimizer.zero_grad()\n            loss = 0.0\n\n            for sample in task:\n                # predict output from input\n                x = torch.from_numpy(inp2img(sample[\"input\"])).unsqueeze(0).float().to(device)\n                y = torch.tensor(sample[\"output\"]).long().unsqueeze(0).to(device)\n                y_pred = model(x, num_steps)\n                loss += criterion(y_pred, y)\n                \n                # predit output from output\n                # enforces stability after solution is reached\n                y_in = torch.from_numpy(inp2img(sample[\"output\"])).unsqueeze(0).float().to(device)\n                y_pred = model(y_in, 1) \n                loss += criterion(y_pred, y)\n\n            loss.backward()\n            optimizer.step()\n            losses[(i - 1) * num_epochs + e] = loss.item()\n    return model, num_steps, losses\n                \n@torch.no_grad()\ndef predict(model, task):\n    predictions = []\n    for sample in task:\n        x = torch.from_numpy(inp2img(sample[\"input\"])).unsqueeze(0).float().to(device)\n        pred = model(x, 200).argmax(1).squeeze().cpu().numpy()\n        predictions.append(pred)\n    return predictions\n    \ntask = train_tasks[\"db3e9e38\"][\"train\"]\nmodel, num_steps, losses = solve_task(task)","ce01e416":"plt.plot(losses)","0f112c24":"predictions = predict(model, task)\nfor i in range(len(task)):\n    plot_sample(task[i], predictions[i])","604c108b":"test = train_tasks[\"db3e9e38\"][\"test\"]\npredictions = predict(model, test)\nfor i in range(len(test)):\n    plot_sample(test[i], predictions[i])","cbc0e787":"def animate_solution(model, sample):\n    x = torch.from_numpy(inp2img(sample[\"input\"])).unsqueeze(0).float().to(device)\n\n    @torch.no_grad()\n    def animate(i):\n        pred = model(x, i)\n        im.set_data(pred.argmax(1).squeeze().cpu().numpy())\n\n    fig, ax = plt.subplots()\n    im = ax.imshow(x.argmax(1).squeeze().cpu().numpy(), cmap=cmap, norm=norm)\n    return animation.FuncAnimation(fig, animate, frames=100, interval=120)\n    \nanim = animate_solution(model, train_tasks[\"db3e9e38\"][\"test\"][0])\nHTML(anim.to_jshtml())","8e75384a":"def evaluate(tasks):\n    result = []\n    predictions = []\n    for idx, task in tqdm(tasks.items()):\n        if input_output_shape_is_same(task):\n            model, _, _ = solve_task(task[\"train\"])\n            pred = predict(model, task[\"test\"])\n            score = calk_score(task[\"test\"], pred)\n        else:\n            pred = [el[\"input\"] for el in task[\"test\"]]\n            score = [0] * len(task[\"test\"])\n\n        predictions.append(pred)\n        result.append(score)\n    return result, predictions","6ccb4451":"train_result, train_predictions = evaluate(train_tasks)\ntrain_solved = [any(score) for score in train_result]\n\ntotal = sum([len(score) for score in train_result])\nprint(f\"solved : {sum(train_solved)} from {total} ({sum(train_solved)\/total})\")","e9e55767":"for task, prediction, solved in tqdm(zip(train_tasks.values(), train_predictions, train_solved)):\n    if solved:\n        for i in range(len(task['train'])):\n            plot_sample(task['train'][i])\n            \n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], prediction[i])","1c2e0127":"import pandas as pd","fed2f4ef":"submission = pd.read_csv(data_path \/ 'sample_submission.csv', index_col='output_id')\ndisplay(submission.head())","fb67854d":"def flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred","f30077aa":"for output_id in tqdm(submission.index):\n    task_id = output_id.split('_')[0]\n    pair_id = int(output_id.split('_')[1])\n    f = str(test_path \/ str(task_id + '.json'))\n    with open(f, 'r') as read_file:\n        task = json.load(read_file)\n    if input_output_shape_is_same(task):\n        print(task_id)\n        model, _, _ = solve_task(task[\"train\"])\n        pred = predict(model, task[\"train\"])\n        for i in range(len(task['train'])):\n            plot_sample(task['train'][i], pred[i])\n        \n        pred = predict(model, task[\"test\"])\n        \n        for i in range(len(task['test'])):\n            plot_sample(task['test'][i], pred[i])\n        pred = flattener(pred[pair_id].tolist())\n        \n    else:\n        # skipping over the training examples, since this will be naive predictions\n        # we will use the test input grid as the base, and make some modifications\n        data = task['test'][pair_id]['input'] # test pair input\n        # for the first guess, predict that output is unchanged\n        pred_1 = flattener(data)\n        # for the second guess, change all 0s to 5s\n        data = [[5 if i==0 else i for i in j] for j in data]\n        pred_2 = flattener(data)\n        # for the last gues, change everything to 0\n        data = [[0 for i in j] for j in data]\n        pred_3 = flattener(data)\n        # concatenate and add to the submission output\n        pred = pred_1 + ' ' + pred_2 + ' ' + pred_3 + ' ' \n    submission.loc[output_id, 'output'] = pred\n\nsubmission.to_csv('submission.csv')","7143b7d2":"## The Model\n\nThe model consists of a single 3x3 convolutional layer, followed by a 1x1 convolutional layer, just like my last notebook. Here `num_states` represents how many values a single cell could have; in this case 10, one for each color. Down the road, we may want to add a hidden state, concatinating it to the input, then removing it from the output.\n\nThe foward pass of the model will repeatedly pass the grid state through the CA transition for `steps` number of times.","76f9e80b":"## Solved Tasks","cf3f4cd8":"We can see that the CA quickly gets to a solution and then stabilizes.","14f64b13":"Our works :\n* Copy this [notebook](https:\/\/www.kaggle.com\/teddykoker\/training-cellular-automata-part-ii-learning-tasks)\n* Edit training process.\nInstead of iterating $num\\_steps$, we do a fixed number of iteration and use a random $num\\_steps \\in [1, max\\_steps]$\n","d02905c8":"# Making submission","cdd384f4":"It works! Now lets see if it generalized to the test question:","0af8b49b":"Fantastic! The coolest part now is that we can animate our solution to see the CA in action:","34878861":"## Training\n\nThis \"recurrent CNN\" can be quite to difficult to train. After trying a few ideas, this seemed to be the best approach that I encountered:\n\n* For every value $n$ = $1, ..., N$:\n    1. Train the model with $n$ `steps` to produce the output from input\n    2. Train the model with 1 `steps` to produce output from output\n        * This enforces that the CA stabilizes after reaching a solution\n        \nIn this way the model will try to get as close to a solution as possible in 1 step, then try to get closer in the next step, and so on until $N$ steps. For now I will use $N = 10$ = `max_steps`. I will also set the learning rate to decay with each additional step: $LR = 0.1 \/ (n * 2) $","e58203b3":"$n$ is incremented every 100 epochs, so we can see that it reaches a good solution after 3 steps (epoch 300).","ad75d9a6":"Now lets see if it at least correctly outputs the training set.","5a54cc2c":"## First Task: db3e9e38\n\nThe task we'll first try is relitively straight foward; given a central orange \"pillar\", form stairs of alternating blue and orange in each direction. `arseny-n` showed that this could be solved with a CA consisting of three rules.","532ea656":"## More Tasks\n\nNow that we know we can train a CA for one task, will it work on others?"}}