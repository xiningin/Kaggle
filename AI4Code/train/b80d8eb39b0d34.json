{"cell_type":{"d1dea451":"code","1fd17c02":"code","7bff483f":"code","9d25aae6":"code","be3bf6ac":"code","eee38850":"code","2e2d45d8":"code","31968697":"code","dfc47247":"code","cde1891a":"code","cc19777c":"markdown","578613bc":"markdown"},"source":{"d1dea451":"from keras import Sequential\nfrom keras.layers import Conv2D ,MaxPooling2D, Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img\nimport matplotlib.pyplot as plt\nfrom glob import glob","1fd17c02":"train_path = \"..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Training\"\ntest_paht = \"..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Test\"","7bff483f":"img = load_img(train_path + \"\/Apple Braeburn\/100_100.jpg\")\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()","9d25aae6":"x = img_to_array(img)\nprint(x.shape)","be3bf6ac":"className = glob(train_path + \"\/*\")\nnumer_of_class = len(className)\nprint(\"number of class = \",numer_of_class)","eee38850":"model = Sequential()\n\nmodel.add(Conv2D(32,(3,3),input_shape= x.shape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(32,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(numer_of_class))\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss = \"categorical_crossentropy\",\n             optimizer = \"rmsprop\",\n             metrics = [\"accuracy\"])\n\nbatch_size = 32\n\n","2e2d45d8":"#data genration train test\ntrain_data_gen = ImageDataGenerator(rescale = 1.\/255,\n                  shear_range = 0.3,\n                  horizontal_flip= True,\n                  zoom_range=0.3\n                  )\ntest_data_gen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_data_gen.flow_from_directory(train_path,\n                                                     target_size=x.shape[:2],\n                                                    batch_size=batch_size,\n                                                    color_mode=\"rgb\",\n                                                    class_mode=\"categorical\")\ntest_generator = test_data_gen.flow_from_directory(test_paht,\n                                                  target_size=x.shape[:2],\n                                                  batch_size=batch_size,\n                                                  color_mode= \"rgb\",\n                                                  class_mode=\"categorical\")\n\nhist=model.fit_generator(\n                    generator=train_generator,\n                    steps_per_epoch = 1600\/\/batch_size,\n                    epochs=80,\n                    validation_data=test_generator,\n                    validation_steps=800\/\/batch_size)\n","31968697":"model.save_weights(\"deneme.h5\")","dfc47247":"print(hist.history.keys())\nplt.plot(hist.history[\"loss\"],label = \"Train lost\")\nplt.plot(hist.history[\"val_loss\"],label = \"validation loss\")\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(hist.history[\"accuracy\"],label = \"train acc\")\nplt.plot(hist.history[\"val_accuracy\"],label = \"Validation acc\")\nplt.legend()\nplt.show()\n\n","cde1891a":"import codecs\nimport json \nwith open(\"deneme.json\",\"w\") as f:\n    json.dump(hist.history,f)\n  \n\nwith codecs.open(\"deneme.json\",\"r\",encoding = \"utf-8\") as f :\n    h = json.loads(f.read())\nplt.plot(h.history[\"loss\"],label = \"Train lost\")\nplt.plot(h.history[\"val_loss\"],label = \"validation loss\")\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(h.history[\"accuracy\"],label = \"train acc\")\nplt.plot(h.history[\"val_accuracy\"],label = \"Validation acc\")\nplt.legend()\nplt.show()       \n\n\n    \n      ","cc19777c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","578613bc":"import codecs \nwith codecs.open(\"cnn_fruit.json\",\"r\",encoder = \"utf-8\") as f :\n    h = json.load(hist.history,f)\nplt.plot(h.history[\"loss\"],label = \"Train lost\")\nplt.plot(h.history[\"val_loss\"],label = \"validation loss\")\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(h.history[\"accuracy\"],label = \"train acc\")\nplt.plot(h.history[\"val_accuracy\"],label = \"Validation acc\")\nplt.legend()\nplt.show()    "}}