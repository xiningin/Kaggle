{"cell_type":{"3de5ec9e":"code","5e5b6432":"code","96213c60":"code","c74ca6b2":"code","d45b2ef7":"code","8c4b8179":"code","5f8aeca7":"code","5b05b5de":"code","18b38643":"code","b19bec47":"code","1213531b":"code","7cbfca73":"code","6ab050df":"code","3d350e10":"code","83aedc44":"code","9c03600e":"code","4f259935":"code","f41af298":"code","5bb47139":"code","3bb32e77":"code","536e301a":"code","44181ab8":"code","ea60cf15":"code","9ea1cc8e":"code","49d164d0":"code","5cd0e9ac":"code","91b1a742":"code","cfb147f2":"code","9d1e7d94":"code","44bc4816":"code","d6bde2f4":"code","542ef5d9":"code","8670e149":"markdown","f729ae77":"markdown","87ae6f7f":"markdown","a8d8e9aa":"markdown","3508442e":"markdown","622f84fe":"markdown","b09818a0":"markdown","d9c3ec54":"markdown"},"source":{"3de5ec9e":"import numpy as np\nimport seaborn as sns\nfrom keras.preprocessing.image import load_img,img_to_array\nimport matplotlib.pyplot as plt\nimport os\n\npic_size = 48\n\nbase_path = \"\/kaggle\/input\/facial-recognition-dataset\/\"\n\nplt.figure(0, figsize=(12,20))\ncpt = 0\n\nfor expression in os.listdir(base_path + \"Training\/Training\/\"):\n    for i in range(1,6):\n        cpt += 1\n        plt.subplot(7,5,cpt)\n        img = load_img(base_path+'Training\/Training\/'+expression+\"\/\"+os.listdir(base_path+\"Training\/Training\/\"+expression)[i],target_size=(pic_size,pic_size))\n        plt.imshow(img,cmap=\"gray\")\n        pass\n    pass\n\nplt.tight_layout()\nplt.show()","5e5b6432":"for expression in os.listdir(base_path+\"Training\/Training\/\"):\n    print(str(len(os.listdir(base_path+\"Training\/Training\/\"+expression)))+\" \"+expression+\" images\")\n    pass","96213c60":"datasets = ['..\/input\/facial-recognition-dataset\/Training\/Training','..\/input\/facial-recognition-dataset\/Testing\/Testing']\n\noutput = []\n\nclass_names = ['Angry','Disgust','Fear','Happy','Neutral','Sad','Suprise']\n\nclass_name_labels = {class_name:j for j,class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\nclass_name_labels","c74ca6b2":"from tqdm import tqdm\nimport cv2\n\ndef load_dataset():\n    \n    for dataset in datasets:\n        \n        print(\"Loading {}\".format(dataset))\n        images,labels = [],[]\n        \n        for folder in os.listdir(dataset):\n            label = class_name_labels[folder]\n            \n            for file in tqdm(os.listdir(os.path.join(dataset,folder))):\n                \n                img_path = os.path.join(os.path.join(dataset,folder),file)\n                \n                img = cv2.imread(img_path)\n                img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n                img = cv2.resize(img,(48,48))\n                \n                images.append(img)\n                labels.append(label)\n                pass\n            pass\n        \n        images = np.array(images,dtype=np.float32)\n        labels = np.array(labels,dtype=np.float32)\n        \n        output.append((images,labels))\n        pass\n    \n    return output\n    pass","d45b2ef7":"(train_images,train_labels),(test_images,test_labels) = load_dataset()","8c4b8179":"import pandas as pd\n\nn_train = train_labels.shape[0]\nn_test = test_labels.shape[0]\n\n_, train_count = np.unique(train_labels,return_counts=True)\n_, test_count = np.unique(test_labels,return_counts=True)\n\ndf = pd.DataFrame(data = (train_count,test_count))\ndf = df.T\ndf['Name'] = class_names\ndf","5f8aeca7":"plt.figure()\ndf.set_index('Name').plot.bar(rot=0)","5b05b5de":"plt.pie(train_count,\n       explode=(0,0,0,0,0,0,0),\n       labels=class_names,\n       autopct = '%1.1f%%')\nplt.axis('equal')\nplt.title(\"Proportion of train data\")\nplt.show()","18b38643":"plt.pie(test_count,\n       explode=(0,0,0,0,0,0,0),\n       labels=class_names,\n       autopct = '%1.1f%%')\nplt.axis('equal')\nplt.title(\"Proportion of test data\")\nplt.show()","b19bec47":"from keras.preprocessing.image import ImageDataGenerator\n\nbatch_size = 64\n\ndatagen_train = ImageDataGenerator(rescale = 1.\/255)\ndatagen_test = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = datagen_train.flow_from_directory(base_path + \"Training\/Training\",\n                                                   target_size = (pic_size,pic_size),\n                                                   color_mode=\"grayscale\",\n                                                   batch_size=batch_size,\n                                                   class_mode = \"categorical\",\n                                                   shuffle=True)\ntest_generator = datagen_test.flow_from_directory(base_path + \"Testing\/Testing\",\n                                                 target_size = (pic_size,pic_size),\n                                                 color_mode = \"grayscale\",\n                                                 batch_size = batch_size,\n                                                 class_mode = \"categorical\",\n                                                 shuffle=True)","1213531b":"train_generator.class_indices","7cbfca73":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Sequential,Input,Model\n\nfrom keras.initializers import *","6ab050df":"def identity_block(X,k,filters,stage,block):\n    \n    conv_name_base = 'res_'+str(stage)+block+'_branch'\n    bn_name_base = 'bn_'+str(stage)+block+'_branch'\n    \n    F1,F2,F3 = filters\n    \n    X_shortcut = X\n    \n    # First Component of Main Path\n    X = Conv2D(filters=F1,kernel_size=(3,3),strides=(1,1),\n               padding='same',name=conv_name_base+'2a',\n               kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(name=bn_name_base+'2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second Component of Main Path\n    X = Conv2D(filters=F2,kernel_size=(k,k),strides=(1,1),\n              padding='same',name=conv_name_base+'2b',\n              kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(name=bn_name_base+'2b')(X)\n    X = Activation('relu')(X)\n    \n    # Third Component of Main Path\n    X = Conv2D(filters=F3,kernel_size=(3,3),strides=(1,1),\n              padding='same',name=conv_name_base+'2c',\n              kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(name=bn_name_base+'2c')(X)\n    \n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n    pass","3d350e10":"def convolutional_block(X,k,filters,stage,block,s=2):\n    \n    conv_base_name = 'res_' + str(stage) + block + '_branch'\n    bn_base_name = 'bn_' + str(stage) + block + '_branch'\n    \n    F1,F2,F3 = filters\n    \n    X_shortcut = X\n    \n    ### MAIN PATH ###\n    # First component of main path\n    X = Conv2D(filters=F1,kernel_size=(3,3),strides=(s,s),\n              padding='same',name=conv_base_name+'2a',\n              kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(name=bn_base_name+'2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second Component of main path\n    X = Conv2D(filters=F2,kernel_size=(k,k),strides=(1,1),\n              padding='same',name=conv_base_name+'2b',\n              kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(name=bn_base_name+'2b')(X)\n    X = Activation('relu')(X)\n    \n    # Third Component of main path\n    X = Conv2D(filters=F3,kernel_size=(3,3),strides=(1,1),\n              padding='same',name=conv_base_name+'2c',\n              kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(name=bn_base_name+'2c')(X)\n    \n    # Shortcut path\n    X_shortcut = Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),\n                       padding='same',name=conv_base_name+'1',\n                       kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(name=bn_base_name+'1')(X_shortcut)\n    \n    X = Add()([X,X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X\n    pass","83aedc44":"def ResNet(input_shape,classes):\n    \n    X_input = Input(input_shape)\n    \n    X = ZeroPadding2D((3,3))(X_input)\n    \n    # Stage 1\n    X = Conv2D(64,(3,3),strides=(2,2),name='conv1',kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(name='bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3,3))(X)\n    \n    \n    # Stage 2\n    X = convolutional_block(X,k=3,filters=[32,32,64],stage=2,block='A',s=1)\n    X = identity_block(X,k=3,filters=[32,32,64],stage=2,block='B')\n    X = identity_block(X,k=3,filters=[32,32,64],stage=2,block='C')\n    \n    # Stage 3\n    X = convolutional_block(X,k=3,filters=[64,64,128],stage=3,block='A',s=1)\n    X = identity_block(X,k=5,filters=[64,64,128],stage=3,block='B')\n    X = identity_block(X,k=3,filters=[64,64,128],stage=3,block='C')\n    X = identity_block(X,k=5,filters=[64,64,128],stage=3,block='D')\n    \n    # Stage 4\n    X = convolutional_block(X,k=5,filters=[128,128,256],stage=4,block='A',s=1)\n    X = identity_block(X,k=3,filters=[128,128,256],stage=4,block='B')\n    X = identity_block(X,k=3,filters=[128,128,256],stage=4,block='C')\n    \n    X = AveragePooling2D((2,2),name='avg_pooling1')(X)\n    \n    X = Flatten()(X)\n    X = Dense(classes,activation='softmax',name='fc'+str(classes),\n              kernel_initializer=glorot_uniform(seed=0))(X)\n    \n    model = Model(inputs=X_input,outputs=X,name='ResNet')\n    \n    return model\n    pass","9c03600e":"model = ResNet(input_shape=(48,48,1),classes=7)","4f259935":"model.summary()","f41af298":"opt = Adam(lr=0.003)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])","5bb47139":"# from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n# from keras.models import Sequential,Model\n# from keras.optimizers import Adam,SGD\n\n# n_classes = 7\n\n# # Initialising the CNN\n# model = Sequential(name='expresion_recog')\n\n# # First Convolutional Layer\n# model.add(Conv2D(32,(3,3), padding=\"same\", input_shape=(48,48,1)))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.3))\n\n# # 2nd convolutional Layer\n# model.add(Conv2D(64,(5,5), padding=\"same\"))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.3))\n\n# # 3rd Convolutional Layer\n# model.add(Conv2D(128,(3,3),padding=\"same\"))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.3))\n\n# # 4th convolution layer\n# model.add(Conv2D(256,(3,3),padding='same'))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.3))\n\n# # Flattening\n# model.add(Flatten())\n\n# # Connected to first layer\n# model.add(Dense(128))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(Dropout(0.3))\n\n# # Connected to second layer\n# model.add(Dense(256))\n# model.add(BatchNormalization())\n# model.add(Activation('relu'))\n# model.add(Dropout(0.3))\n\n# model.add(Dense(n_classes,activation='softmax'))\n\n# opt = Adam(lr=0.003)\n# model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])","3bb32e77":"from keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\"model_weights.h5\",monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')\ncallbacks_list=[checkpoint]","536e301a":"epochs = 25\n# batch_size = 128\n\nhistory = model.fit_generator(generator=train_generator,\n                             steps_per_epoch=train_generator.n\/\/train_generator.batch_size,\n                             epochs=epochs,\n                             validation_data=test_generator,\n                             validation_steps = test_generator.n\/\/test_generator.batch_size,\n                             callbacks=callbacks_list)","44181ab8":"model_json = model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)","ea60cf15":"import matplotlib.pyplot as plt\n\n# plt.figure(figsize=(20,20))\n# plt.subplot(1,2,1)\n# plt.suptitle('Optimizer: Adam',fontsize=18)\nplt.figure()\nplt.ylabel('Loss',fontsize=16)\nplt.plot(history.history['loss'],label='Training Loss')\nplt.plot(history.history['val_loss'],label='Testing loss')\nplt.legend(loc='upper right')\n\n# plt.subplot(1,2,2)\nplt.figure()\nplt.ylabel('Accuracy',fontsize=16)\nplt.plot(history.history['accuracy'],label='Training Accuracy')\nplt.plot(history.history['val_accuracy'],label='Testing Accuracy')\nplt.legend(loc='lower right')\n\nplt.show()","9ea1cc8e":"predictions = model.predict_generator(generator=test_generator)\ny_pred = [np.argmax(probas) for probas in predictions]\ny_test = test_generator.classes\nclass_names = test_generator.class_indices.keys()\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm,classes,title='Confusion matirx',cmap=plt.cm.Blues):\n    cm = cm.astype('float')\/cm.sum(axis=1)[:,np.newaxis]\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks=np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    \n    fmt = '.2f'\n    thresh = cm.max()\/2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n        \n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    pass\n\ncnf_mat = confusion_matrix(y_test,y_pred)\nnp.set_printoptions(precision=2)\n\nplt.figure()\nplot_confusion_matrix(cnf_mat, classes=class_names, title='Normalized Confusion Matrix')\nplt.show()","49d164d0":"test_acc = model.evaluate_generator(test_generator)\nprint(\"Test accuracy: \",test_acc[1])","5cd0e9ac":"pred_generator = datagen_test.flow_from_directory(base_path + \"Testing\/Testing\",\n                                                 target_size = (pic_size,pic_size),\n                                                 color_mode = \"grayscale\",\n                                                 batch_size = batch_size,\n                                                 class_mode = \"categorical\",\n                                                 shuffle=False)","91b1a742":"pred_generator.reset()\npred_class = model.predict_generator(pred_generator,verbose=1,steps=len(pred_generator))","cfb147f2":"labels = pred_generator.class_indices\nlabels = dict((v,k) for k,v in labels.items())\nlabels","9d1e7d94":"pred_class = np.argmax(pred_class,axis=1)\n\npred_class = [labels[k] for k in pred_class]\n\nfilenames = pred_generator.filenames\nactual_class = [labels[h] for h in pred_generator.classes]\n\npred_result = pd.DataFrame({\"Filename\":filenames,\n                           \"Predictions\":pred_class,\n                           \"Actual Values\":actual_class})\n\npred_result.head()","44bc4816":"pred_class_result = pred_result[\"Filename\"].groupby(pred_result[\"Predictions\"]).count()\n\nplt.figure()\npred_results_visualisations = pred_class_result.plot(kind='bar')\n\nplt.title(\"Number of images per class\")\nplt.xlabel(\"Class label\")\nplt.ylabel(\"Total Number of Predictions per Class\")\n\nplt.show()","d6bde2f4":"_,result_count = np.unique(pred_class,return_counts=True)\n\nplt.pie(result_count,\n       explode=(0,0,0,0,0,0,0),\n       labels = class_names,\n       autopct = '%1.1f%%')\nplt.axis('equal')\nplt.title('Proportion of labels in validation dataset')\nplt.show()","542ef5d9":"from random import randint\n\nl = len(filenames)\nbase_path = \"\/kaggle\/input\/facial-recognition-dataset\/Testing\/Testing\/\"\nfor i in range(10):\n    \n    rnd_number = randint(0,l-1)\n    filename,pred_class,actual_class = pred_result.loc[rnd_number]\n    \n    img_path = os.path.join(base_path,filename)\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.title(\"Predicted Class: {} {} Actual Class: {}\".format(pred_class,'\\n',actual_class))\n    plt.show()\n    pass","8670e149":"For a much better model the disgust data can be removed from the dataset and training on the remaining data, or obtain more data for the disgust dataset.","f729ae77":"This give a more accurate picture of the class imabalance present in the dataset. The highest is occupied by `Happy` with 25.1% and lowest with `Disgust` at an astonishingly low percantage of 1.5.","87ae6f7f":"### This notebook was made for recognising facial expressions of a person.\n\nTraditional convolutional layers are used with \"Relu\" as the activation function. \n\nThe most optimal model parameters are stored in a model_weights.h5 file, while the model overall is stored in a json file for reproducing the model without repetitive training.","a8d8e9aa":"It is evident the model overfits. This may be a side effect of the class imbalance.","3508442e":"As it can be seen that there is major class imbalance, there are very few disgust images present in the database.\n\nA way for countering this is by using reducing the training set for the remaining images, especially in `Happy`.","622f84fe":"This slightly better than pure random chance. *Not a good dataset.*","b09818a0":"Even in the test dataset, there is a similar class imbalance present. Though there is no overall difference in percentage of images between the train and test datasets.","d9c3ec54":"Due to `Happy` having a high number of images in both the datasets the model is heavily inclinde towards it. This can be mitigated by reducing the number of images of that particular class.\n\nIn the next version of the dataset, `Disgust` class is being removed until more images of that particular class can be obtained."}}