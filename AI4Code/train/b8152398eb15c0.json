{"cell_type":{"33aea37a":"code","45d70a90":"code","521ddd4e":"code","b80419db":"code","7963bbb6":"code","3b8a8f18":"code","b49f9095":"code","c0237b92":"code","3ebfd736":"code","c89fb2e8":"code","76cad865":"code","9fa69332":"code","1756a557":"code","49ac5a26":"code","7f7e40d1":"code","e4af045c":"code","9df7bc31":"code","5b20c207":"code","ec86a0d8":"code","102e95f6":"markdown","1a060f56":"markdown","5014be5a":"markdown","12e9da4b":"markdown","325b11f2":"markdown","166814bd":"markdown","33edb7b9":"markdown","15924a84":"markdown","eab2342b":"markdown","dbb8578f":"markdown","71b16d0a":"markdown","b7d43969":"markdown","5fb9ef83":"markdown"},"source":{"33aea37a":"import numpy as np\nimport pandas as pd\n\n%matplotlib inline\nimport plotly.figure_factory as ff\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","45d70a90":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/train.csv\", index_col=0)\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-sep-2021\/test.csv\", index_col=0)\nsample_submission = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")","521ddd4e":"train.hist(figsize=(20,15), grid=False, ylabelsize=5, xlabelsize=5)\nplt.show()","b80419db":"corrs = train.corr()\ncorrs = corrs.sort_values(by=['claim'],ascending=False)","7963bbb6":"fig = plt.figure(figsize = (15,20))\nsns.barplot(y=corrs.index[1:], x=corrs['claim'].values[1:], orient=\"h\")\nplt.title(\"Correlation Between Feature Columns and Target Column (Claim)\")\nplt.xlabel(\"Correlation with Target\")\nplt.ylabel(\"Feature Columns\")\nplt.show()","3b8a8f18":"feature_cols = [col for col in test.columns.tolist()]\n\nscaler = StandardScaler()\n\ntrain[feature_cols] = scaler.fit_transform(train[feature_cols])\ntest[feature_cols] = scaler.transform(test[feature_cols])","b49f9095":"def add_feature(df):\n    df['n_nans'] = df[feature_cols].isnull().sum(axis=1)\n    df['std']    = df[feature_cols].std(axis=1)\n    df['mean']   = df[feature_cols].mean(axis=1)\n    df['max']    = df[feature_cols].max(axis=1)\n    df['skew']   = df[feature_cols].skew(axis=1)\n    df['sum']    = df[feature_cols].sum(axis=1)\n    df['var']    = df[feature_cols].var(axis=1)\n    return df\n        \ntrain = add_feature(train).copy()\ntest = add_feature(test).copy()\n\nfeature_cols += ['n_nans', 'std', 'mean', 'max', 'skew', 'sum', 'var']","c0237b92":"corrs = train.corr()\ncorrs = corrs.sort_values(by=['claim'],ascending=False)","3ebfd736":"fig = go.Figure(go.Bar(x=np.flip(corrs['claim'].values[1:11]), y=np.flip(corrs.index[1:11]), orientation='h'))\nfig.update_layout(\n    title=\"Top 10 Positive Correlation Between Feature Columns and Claim Column\",\n    xaxis_title=\"Correlation with Claim\",\n    yaxis_title=\"Feature Columns\",\n    colorway=[\"blue\"]\n)\nfig.show()","c89fb2e8":"train[\"kfold\"] = -1\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_indicies, valid_indicies) in enumerate(kf.split(train,train[\"claim\"])):\n    train.loc[valid_indicies, \"kfold\"] = fold","76cad865":"final_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\ncats = []\n\nfor fold in range(5):\n    x_train = train[train.kfold != fold].copy()\n    x_valid = train[train.kfold == fold].copy()\n    x_test  = test.copy()\n    \n    y_train = x_train['claim']\n    y_valid = x_valid['claim']\n    \n    x_train = x_train[feature_cols]\n    x_valid = x_valid[feature_cols]\n    \n    valid_ids = x_valid.index\n\n    cat_params = {\n        'iterations': 15000, \n        'random_seed': 42,\n        'loss_function': 'Logloss', \n        'depth': 8, \n        'task_type' : 'GPU',\n        'use_best_model': True,\n        'eval_metric': 'AUC',\n        'early_stopping_rounds': 1000,\n        'learning_rate': 0.03,\n        'border_count': 32,\n        'l2_leaf_reg': 3,\n        'verbose': False,\n    }\n    # train model\n    cat_model = CatBoostClassifier(**cat_params)\n    cat_model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)])\n    cats.append(cat_model)\n    # predict values\n    preds_valid = cat_model.predict_proba(x_valid)[:, 1]\n    preds_test  = cat_model.predict_proba(test)[:, 1]\n    # store predicted values\n    final_test_predictions.append(preds_test)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    # measure metrics\n    auc = roc_auc_score(y_valid, preds_valid)\n    print(\"Fold\",fold, \", AUC:\", auc)\n    scores.append(auc)\n    \nprint(\"AVG AUC:\",np.mean(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_cb\"]\nfinal_valid_predictions.to_csv(\"train_pred_cb.csv\", index=False)\n\nss = sample_submission.copy()\nss['claim'] = np.mean(np.column_stack(final_test_predictions), axis=1)\nss.columns = [\"id\", \"pred_cb\"]\nss.to_csv(\"test_pred_cb.csv\", index=False)\n\ncb_test_preds_folds = final_test_predictions","9fa69332":"final_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nxgbs = []\n\nfor fold in range(5):\n    x_train = train[train.kfold != fold].copy()\n    x_valid = train[train.kfold == fold].copy()\n    x_test  = test.copy()\n    \n    y_train = x_train['claim']\n    y_valid = x_valid['claim']\n    \n    x_train = x_train[feature_cols]\n    x_valid = x_valid[feature_cols]\n    \n    valid_ids = x_valid.index\n    xgb_params = {\n          'max_depth': 2, \n          'learning_rate': 0.021537077920105466, \n          'n_estimators': 10606, \n          'min_child_weight': 150, \n          'gamma': 0.11611920725914951, \n          'alpha': 0.0021839958087869794, \n          'lambda': 0.0018567979557499344, \n          'colsample_bytree': 0.7139742731494992, \n          'subsample': 0.6258627743440968,\n          'tree_method': 'gpu_hist',\n          'booster': 'gbtree',\n          'seed': 42,\n          'use_label_encoder': False,\n          'eval_metric': 'auc'\n    }\n    \n    xgb_model = XGBClassifier(**xgb_params)\n    xgb_model.fit(x_train, y_train, eval_set=[(x_valid, y_valid)], verbose=False)\n    xgbs.append(xgb_model)\n    # predict values\n    preds_valid = xgb_model.predict_proba(x_valid)[:,1]\n    preds_test  = xgb_model.predict_proba(test)[:,1]\n    # store predicted values\n    final_test_predictions.append(preds_test)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    # measure metrics\n    auc = roc_auc_score(y_valid, preds_valid)\n    print(\"Fold\",fold, \", AUC:\", auc)\n    scores.append(auc)\n    \n    \nprint(\"AVG AUC:\",np.mean(scores))\n\nfinal_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_xgb\"]\nfinal_valid_predictions.to_csv(\"train_pred_xgb.csv\", index=False)\n\nss = sample_submission.copy()\nss['claim'] = np.mean(np.column_stack(final_test_predictions), axis=1)\nss.columns = [\"id\", \"pred_xgb\"]\nss.to_csv(\"test_pred_xgb.csv\", index=False)\n\nxgb_test_preds_folds = final_test_predictions","1756a557":"test_preds_folds = cb_test_preds_folds + xgb_test_preds_folds\nlabels = [f'CatBoost fold {i}' if i < 5 else f'XGBoost fold {i-5}' for i in range(10)]\n\nfig = ff.create_distplot(test_preds_folds, labels, bin_size=.3, show_hist=False, show_rug=False)\nfig.show()","49ac5a26":"df = train.copy()\ndf_test = test.copy()\n\ndf1 = pd.read_csv(\"train_pred_cb.csv\")\ndf2 = pd.read_csv(\"train_pred_xgb.csv\")\n\ndf_test1 = pd.read_csv(\"test_pred_cb.csv\")\ndf_test2 = pd.read_csv(\"test_pred_xgb.csv\")\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\n\ndf.head()","7f7e40d1":"corrs = df.drop(columns=[\"kfold\"]).corr()\ncorrs = corrs.sort_values(by=['claim'],ascending=False)","e4af045c":"fig = go.Figure(go.Bar(x=np.flip(corrs['claim'].values[1:11]), y=np.flip(corrs.index[1:11]), orientation='h'))\nfig.update_layout(\n    title=\"Top 10 Positive Correlation Between Feature Columns and Claim Column\",\n    xaxis_title=\"Correlation with Claim\",\n    yaxis_title=\"Feature Columns\",\n    colorway=[\"blue\"]\n)\nfig.show()","9df7bc31":"useful_features = [\"n_nans\", \"pred_cb\", \"pred_xgb\"]\ndf_test = df_test[useful_features]\n\nfinal_predictions = []\nscores = []\nfor fold in range(5):\n    x_train = df[df.kfold != fold].copy()\n    x_valid = df[df.kfold == fold].copy()\n    x_test = df_test.copy()\n\n    y_train = x_train['claim']\n    y_valid = x_valid['claim']\n    \n    x_train = x_train[useful_features]\n    x_valid = x_valid[useful_features]\n    params = {\n          'max_depth': 2, \n          'learning_rate': 0.021537077920105466, \n          'n_estimators': 10606, \n          'min_child_weight': 150, \n          'gamma': 0.11611920725914951, \n          'alpha': 0.0021839958087869794, \n          'lambda': 0.0018567979557499344, \n          'colsample_bytree': 0.7139742731494992, \n          'subsample': 0.6258627743440968,\n          'tree_method': 'gpu_hist',\n          'booster': 'gbtree',\n          'seed': 42,\n          'use_label_encoder': False,\n          'eval_metric': 'auc'\n    }\n    model = XGBClassifier(**params)\n    model.fit(x_train, y_train)\n    \n    preds_valid = model.predict_proba(x_valid)[:,1]\n    test_preds = model.predict_proba(x_test)[:,1]\n    final_predictions.append(test_preds)\n    auc = roc_auc_score(y_valid, preds_valid)\n    print(\"Fold\",fold, \", AUC:\", auc)\n    scores.append(auc)\n\nprint(\"AVG AUC:\",np.mean(scores))\nsample_submission['claim'] = np.mean(np.column_stack(final_predictions), axis=1)","5b20c207":"data = [df_test1.pred_cb, df_test2.pred_xgb, sample_submission.claim]\n\nlabels = ['CatBoost', 'XGBoost', 'Blending']\n\nfig = ff.create_distplot(data, labels, bin_size=.3, show_hist=False, show_rug=False)\nfig.show()","ec86a0d8":"sample_submission.to_csv(\"submission.csv\", index=False)","102e95f6":"# Plot Data","1a060f56":"# Plot Test Set Predictions","5014be5a":"# Correlation with Predicted Values","12e9da4b":"# Plot Test Set Predictions","325b11f2":"## Load Data","166814bd":"# Correlation with Claim","33edb7b9":"# CatBoost","15924a84":"# Blending","eab2342b":"# Scale Data","dbb8578f":"# XGBoost","71b16d0a":"# Add Feature","b7d43969":"## Submission","5fb9ef83":"# KFold Data"}}