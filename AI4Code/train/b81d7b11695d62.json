{"cell_type":{"26dbe9f7":"code","aa45e586":"code","e1805b1b":"code","fd4a2db4":"code","10f1aa97":"code","dbf12472":"code","0191d759":"code","6b3e4f75":"code","211301b5":"code","be267847":"code","3d8722e6":"code","6b35daa6":"markdown","b828740d":"markdown","7ba94f6c":"markdown","77e8c142":"markdown","ef59275f":"markdown","396d71b7":"markdown","3095d29e":"markdown","87e5fe0b":"markdown","bf4eb753":"markdown"},"source":{"26dbe9f7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nrandom.seed(11112111311114)\n# Keras libs import for preprocesssing, objects to build model will be imported later\nfrom keras.preprocessing import image\nfrom keras import backend as K\nK.tensorflow_backend._get_available_gpus()\n# visualisation libs import\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","aa45e586":"pos_img_path = \"\/kaggle\/input\/cell_images\/cell_images\/Parasitized\/C100P61ThinF_IMG_20150918_144104_cell_162.png\"\nneg_img_path = \"\/kaggle\/input\/cell_images\/cell_images\/Uninfected\/C100P61ThinF_IMG_20150918_144104_cell_128.png\"\npos_img = image.load_img(pos_img_path, target_size=(224, 224, 1))\nneg_img = image.load_img(neg_img_path, target_size=(224, 224, 1))\nx = image.img_to_array(pos_img)\ny = image.img_to_array(neg_img)\nprint(\"test result evidence: positive\")\nplt.imshow(x\/255.)\nplt.show()\nprint(\"test result evidence: negative\")\nplt.imshow(y\/255.)\nplt.show()","e1805b1b":"extension = \"png\"\n\npositive_img_set = []\npositive_set_folder = \"\/kaggle\/input\/cell_images\/cell_images\/Parasitized\/\"\nfor roots,dir,files in os.walk(positive_set_folder+\".\"):\n    positive_img_set = list(map(lambda x:image.img_to_array(\n        image.load_img(positive_set_folder+x, target_size=(224, 224)))\/255.,  ##watch out for this normalisation value 255. its really important\n                                filter(lambda x: x.endswith('.' + extension),files[:2000])))\n    random.shuffle(positive_img_set)\nprint(len(positive_img_set))\n\nnegative_img_set = []\nnegative_set_folder = \"\/kaggle\/input\/cell_images\/cell_images\/Uninfected\/\"\nfor roots,dir,files in os.walk(negative_set_folder+\".\"):\n    negative_img_set = list(map(lambda x:image.img_to_array(\n        image.load_img(negative_set_folder+x, target_size=(224, 224)))\/255., ##watch out for this normalisation value 255. its really important\n                                filter(lambda x: x.endswith('.' + extension),files[:2000])))\n    random.shuffle(negative_img_set)\nprint(len(negative_img_set))\npositive_test_set = positive_img_set[1800:]\nnegative_test_set = negative_img_set[1800:]\npositive_train_set =  positive_img_set[:1800]\nnegative_train_set = negative_img_set[:1800]\n\ntrain_X = positive_train_set + negative_train_set\ntrain_y = [1]*len(positive_train_set) + [0]*len(negative_train_set)\ntemp = list(zip(train_X,train_y))\nrandom.shuffle(temp)\ntrain_X,train_y = np.array([x[0] for x in temp]), np.array([x[1] for x in temp])\n\n#del temp\ndel positive_img_set\ndel negative_img_set","fd4a2db4":"print(train_y)\nprint([[1,0] if int(x) is 1 else [0,1] for x in train_y])","10f1aa97":"#firsly the imports\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\nfrom keras.losses import binary_crossentropy\nfrom keras.optimizers import SGD, Adam\n\n#create model\nmodel = Sequential()\n\n#add model layers\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=((224,224,3)),padding='same'))\nmodel.add(Conv2D(64, kernel_size=3, activation='relu',  padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n#optimizer inilisation\nadam = Adam(lr=0.000001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n#sgd = SGD()\n\n#compile model using accuracy to measure model performance\nmodel.compile(optimizer=adam, loss=binary_crossentropy, metrics=['accuracy'])\n\n#train the model\nmodel.fit(train_X, train_y,batch_size=32,epochs=150,validation_split=0.2)\n","dbf12472":"#generate metrics on the above model\n#positive_accuracy = len(list(filter(lambda x: x>0.5,model.predict(np.array(positive_test_set)))))\/len(positive_test_set)\n#negative_accuracy = len(list(filter(lambda x: x<0.5,model.predict(np.array(negative_test_set)))))\/len(negative_test_set)\ny_true = [1]*len(positive_test_set)+[0]*len(negative_test_set)\ny_predicted = np.append(model.predict(np.array(positive_test_set)),model.predict(np.array(negative_test_set)))\nprint(y_predicted)\nfpr, tpr, thresholds = metrics.roc_curve(y_true, y_predicted, pos_label=2)\n#print(positive_accuracy, negative_accuracy)\nprint(fpr,tpr,thresholds)","0191d759":"import torch\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef outputSize(in_size, kernel_size, stride, padding):\n    output = int((in_size - kernel_size + 2*(padding)) \/ stride) + 1\n    return(output)\n\nmodel = torch.nn.Sequential(\n          torch.nn.Conv2d(3,64,3,padding=2),\n          torch.nn.ReLU(),\n          torch.nn.Conv2d(64,64,3,padding=2),\n          torch.nn.ReLU(),\n          torch.nn.MaxPool2d(2,2),\n          torch.nn.Conv2d(64,128,3),\n          torch.nn.ReLU(),\n          torch.nn.Conv2d(128,128,3),\n          torch.nn.ReLU(),\n          torch.nn.MaxPool2d(2,2),\n          \n        )\nFC1 = torch.nn.ReLU(torch.nn.Linear(55*55*128,512))\nFC2 = torch.nn.ReLU(torch.nn.Linear(512,256))\nFC3 = torch.nn.ReLU(torch.nn.Linear(256,2))\nFC4 = torch.nn.Softmax(FC3)\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nX = DataLoader([(torch.tensor(np.transpose(x[0],(2,0,1))),torch.tensor(x[1])) for x in temp], batch_size=1,num_workers=4)\nprint(X)\ncriterion = torch.nn.CrossEntropyLoss()\nfor t in range(150):\n    #for j in range(len(train_X)):\n    for j, data in enumerate(X,0):\n      optimizer.zero_grad()\n      y_pred = FC3(FC2(FC1(model(data[0]).flatten())))\n      print(torch.tensor(data[1],dtype=torch.float32))\n      print(y_pred.view(1,2))\n      loss = criterion(y_pred.view(1,2), torch.tensor(data[1],dtype=torch.long))\n      print(t, loss.item())\n      loss.backward()\n      optimizer.step()","6b3e4f75":"import torch\nimport time\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass PrepareData(Dataset):\n    \n    def __init__(self, X, y):\n        if not torch.is_tensor(X):\n            self.X = torch.from_numpy(X)\n        if not torch.is_tensor(y):\n            self.y = torch.from_numpy(y)\n\n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n    \n\nclass simpleCNN(torch.nn.Module):\n    def __init__(self):\n        super(simpleCNN, self).__init__()\n        \n        #Input channels = 3, output channels = 18\n        self.conv1 = torch.nn.Conv2d(3,64,3,padding=2)\n        self.conv2 = torch.nn.Conv2d(64,64,3,padding=2)\n        self.pool = torch.nn.MaxPool2d(2,2)\n        self.conv3 = torch.nn.Conv2d(64,128,3)\n        self.conv4 = torch.nn.Conv2d(128,128,3)\n        self.FC1 = torch.nn.Linear(55*55*128,512)\n        self.FC2 = torch.nn.Linear(512,256)\n        self.FC3 = torch.nn.Linear(256,2)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = self.pool(x)\n        x = x.view(-1,55*55*128)\n        x = F.relu(self.FC1(x))\n        x = F.relu(self.FC2(x))\n        x = F.relu(self.FC3(x))\n        x = F.softmax(x)\n        return(x)\n\ncnn = simpleCNN()\ncnn.cuda()\nlearning_rate = 1e-4\noptimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\nds = PrepareData(np.array([np.transpose(x,(2,0,1)) for x in train_X]),np.array(train_y))\nX = DataLoader(ds, batch_size=32,num_workers=10)\nprint(X)\ncriterion = torch.nn.CrossEntropyLoss()\nfor t in range(150):\n    verbose = \"Epoch:{}, Loss of last element:{}\"\n    temp_loss = None\n    tm = time.time()\n    for j, data in enumerate(X,0):\n      optimizer.zero_grad()\n      y_pred = cnn(data[0].cuda())\n      loss = criterion(y_pred, torch.tensor(data[1],dtype=torch.long).cuda())\n      temp_loss = loss.item()\n      loss.backward()\n      optimizer.step()\n      if (j%100==0):\n          print(j)\n    print(verbose.format(t,temp_loss))\n    print(\"this epoch took:\",str(time.time()-tm))\n    ","211301b5":"positive_test_tensors = torch.tensor(list(map(lambda x: np.transpose(np.array(x),(2,0,1)),positive_test_set)))\nnegative_test_tensors = torch.tensor(list(map(lambda x: np.transpose(np.array(x),(2,0,1)),negative_test_set)))\ny_true = [1]*len(positive_test_set)+[0]*len(negative_test_set)\ny_predicted = np.append(cnn(positive_test_tensors.cuda()),cnn(negative_test_tensors.cuda()))\nprint(y_predicted)\nfpr, tpr, thresholds = metrics.roc_curve(y_true, y_predicted, pos_label=2)\n#print(positive_accuracy, negative_accuracy)\nprint(fpr,tpr,thresholds)","be267847":"import tensorflow as tf\nimport time\nclass simpleCNN_tf:\n    def __init__(self):\n        return\n    \n    def build(self, rgb):\n        \"\"\"\n        load variable from npy to build the VGG\n\n        :param rgb: rgb image [batch, height, width, 3] values scaled [0, 1]\n        \"\"\"\n\n        start_time = time.time()\n        print(\"build model started\")\n        rgb_scaled = rgb * 255.0\n\n        # Convert RGB to BGR\n        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=rgb_scaled)\n        assert red.get_shape().as_list()[1:] == [224, 224, 1]\n        assert green.get_shape().as_list()[1:] == [224, 224, 1]\n        assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n        bgr = tf.concat(axis=3, values=[\n            blue,\n            green,\n            red\n        ])\n        assert bgr.get_shape().as_list()[1:] == [224, 224, 3]\n\n        self.conv1_1 = self.conv_layer(bgr, [5, 5, 3, 64], \"conv1_1\")\n        self.conv1_2 = self.conv_layer(self.conv1_1, [5, 5, 64, 64],\"conv1_2\")\n        self.pool1 = self.max_pool(self.conv1_2, 'pool1')\n        self.conv2_1 = self.conv_layer(self.pool1, [5, 5, 64, 64], \"conv1_1\")\n        self.conv2_2 = self.conv_layer(self.conv2_1,[5, 5, 64, 64],\"conv1_2\")\n        self.pool2 = self.max_pool(self.conv2_2, 'pool1')\n        self.fc6 = self.fc_layer(self.pool2,512)\n        assert self.fc6.get_shape().as_list()[1:] == [512]\n        self.relu6 = tf.nn.relu(self.fc6)\n        self.fc7 = self.fc_layer(self.relu6,256)\n        self.relu7 = tf.nn.relu(self.fc7)\n        self.fc8 = self.fc_layer(self.relu7,2)\n        self.relu8 = tf.nn.relu(self.fc8)\n        self.prob = tf.nn.softmax(self.relu8, name=\"prob\")\n        self.data_dict = None\n        print((\"build model finished: %ds\" % (time.time() - start_time)))\n\n    def avg_pool(self, bottom, name):\n        return tf.nn.avg_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n\n    def max_pool(self, bottom, name):\n        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n\n    def conv_layer(self, bottom,filter_dim,name):\n        with tf.variable_scope(name):\n            kernel = tf.Variable(tf.random_normal(filter_dim))\n            conv = tf.nn.conv2d(bottom, kernel, [1, 1, 1, 1], padding='SAME')\n            relu = tf.nn.relu(conv)\n            return relu\n\n    def fc_layer(self, bottom, output_dim):\n        shape = bottom.get_shape().as_list()\n        dim = 1\n        for d in shape[1:]:\n            dim *= d\n        x = tf.reshape(bottom, [-1, dim])\n        fc = tf.layers.dense(x, output_dim)\n        return fc\n\n    def get_conv_filter(self, name):\n        return tf.layers.dense(self.data_dict[name][0], name=\"filter\")\n\n    def get_bias(self, name):\n        return tf.layers.dense(self.data_dict[name][1], name=\"biases\")\n\n    def get_fc_weight(self, name):\n        return tf.constant(self.data_dict[name][0], name=\"weights\")","3d8722e6":"\ntrain_y_tf = [[1,0] if int(x) is 1 else [0,1] for x in train_y]\n\nbatch_size = 32\nepochs = 150\nprint(len(train_X))\nwith tf.device('\/gpu:0'):\n    sess = tf.Session()\n\n    images = tf.placeholder(tf.float32, [batch_size, 224, 224, 3])\n    true_out = tf.placeholder(tf.float32, [batch_size, 2])\n    train_mode = tf.placeholder(tf.bool)\n\n    cnn = simpleCNN_tf()\n    cnn.build(images)\n\n    # print number of variables used: 143667240 variables, i.e. ideal size = 548MB\n    #print(vgg.get_var_count())\n\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(epochs):\n        i=0\n        a = time.time()\n        while(i<len(train_X)):\n            print(epoch)\n            if len(train_X)-i < batch_size:\n                i = i+batch_size\n                continue\n            batch = train_X[i:i+batch_size]\n            true_val = train_y[i:i+batch_size]\n            i = i+batch_size\n            prob = sess.run(cnn.prob, feed_dict={images: batch, train_mode: True})\n            #print(prob)\n            cost = tf.losses.softmax_cross_entropy(true_out,cnn.prob)\n            train = tf.train.GradientDescentOptimizer(0.0001).minimize(cost)\n            sess.run(train, feed_dict={images: batch, true_out: true_val, train_mode: True})\n        print(epoch)\n        print(time.time()-a)\n            \n        \n","6b35daa6":"Now as you can see, its a little more work we need to do with pytorch, But at the same time wit provides much more flexibility. Why? Think when you are building an arachitecture where the model gets divided into two parallel path for example while training for multiple task, Pytorch gives much more flexibility then keras.","b828740d":"Now you will see the ancient one (ok not ancient but still it got the feels so bear with me, I am doing this for you). Keras is actually the layer over this. Tensorflow is actually built in c\/c++ with seamless integration wth python (ok not so seamless but good enough). Now if keras is already built, u should ask why tensorflow, why dont we forget it like we forget what goes on behind pythons sort function ( not that I have forgotten i remember that language on the tip of my fingers! all hail coreman). The point is Keras is great for POC(s) and fast experimentation but when you think production worthy Keras might hold u onto it. Tensorflow gives you flexibility to modify and optimize according to ur requirements and costs","7ba94f6c":"**Sample images in the Data-set**","77e8c142":"**Now lets work with pytorch which is about as easy to write as the above keras implementation and good point its all in python :) **","ef59275f":"**Our Aim is to classify the above two images thus detecting weather the cell is infected with malaria or not.**","396d71b7":"But in the above cell, One key thing is missing, mini batches, you need to see that I have given the mini batch count =1 (Try changing it to 2 and see what happens). The problem is there isn't any Flatten() layer provided by pytorch alone. you can do it to a tensor but it cannot be a part of architecture. Hence when you pass a batch tensor.flatten(), it wiill flatten all the batches into a 1D matrix. Hence to be able to use mini_batches we need to write code in the following fashion.\n","3095d29e":"**Let's start with Keras ease of POC. Just a few lines and you can have your eureka moment!!!**","87e5fe0b":"**In this kernel we will experiment a few different ways of image classification technique.**\n*     **Image Classification using traditional image processing and openCV**\n*     **Image Classification using Deep Learing and Keras** \n*     **Image Classification using Deep Learning and PyTorch**","bf4eb753":"## Next is Tensorflow :) "}}