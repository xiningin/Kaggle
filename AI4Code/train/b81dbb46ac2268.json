{"cell_type":{"aacbe457":"code","7f7d0fec":"code","476c1782":"code","fe61c11c":"code","78c8bb50":"markdown","1a367a40":"markdown","8fa97004":"markdown","84749bf6":"markdown","2f141698":"markdown"},"source":{"aacbe457":"## pip install numpy\nimport numpy as np\n\n## pip install matplotlib\nimport matplotlib.image as mpimg  # mpimg.imread(path)\nimport matplotlib.pyplot as plt  # plt.imshow(np.array)\n\n## pip install scipy scikit-image\nfrom scipy.ndimage import generic_filter, convolve\n\n## pip install opencv-python\n\nimport cv2  # cv2.kmeans and prebuilt computer vision functions ie grayscale","7f7d0fec":"## Convolution Example\ncat = mpimg.imread('..\/input\/cat-images\/cat3.jpg')\n\n# for the convolutions to work, the image should be normalized \n# to [0, 1] as opposed to the standard [0, 255]!\n# this is for math reasons\ncat = cat \/ 255\nprint(f\"Cat image value range, [{np.min(cat)}, {np.max(cat)}]\")\n\nplt.imshow(cat)\nplt.show()\n\n## Blurred\n# This kernel is for a 3 channel image.\nblur_kernel = [[\n    [.1, .4, .1], \n    [.4, .8, .4], \n    [.1, .4, .1]]]\n\nblur_kernel = np.array(blur_kernel)\nblur_kernel \/= np.sum(blur_kernel)  # ensure kernel sums to ~1\n\nblur_kernel_sum = np.sum(blur_kernel)\nassert blur_kernel_sum <= 1.01 and blur_kernel_sum >= .99, f\"This is bad math yo, {blur_kernel_sum}\"\n\nblurred = convolve(cat, blur_kernel)\nplt.imshow(blurred)\nplt.show()\n\n## Basic edge detection\n# This kernel is for a 1 channel image, but you can still find the \n# edges w\/ a 3 channel image w\/ less information loss\nedge_kernel = [\n    [-1, -1, -1], \n    [-1, 8, -1], \n    [-1, -1, -1]]\n\nedge_kernel = np.array(edge_kernel)\n\ngrayscale_cat = np.mean(cat, axis=2)\n\nedges = convolve(grayscale_cat, edge_kernel)\nbinarized_edges = np.where(edges > .25, 1, 0)\n\nplt.imshow(binarized_edges, cmap='gray')\nplt.show()\n\n## Appling edge information to original image\ntest_cat = np.copy(cat)\ntest_cat[np.where(binarized_edges)] = np.array([0., 0., 1.])\n\nplt.imshow(test_cat)\nplt.show()\n\n# you can probably do something useful with this\n# large kernel blur w\/ .5 threshold on binarized == object detection?","476c1782":"## Generic Filters\n# https:\/\/github.com\/coledie\/1D-Automaton\/blob\/master\/wolfram_automaton.py\n# Here I am using generic filters to generate the next iteration of a\n# cellular automaton rule. Line 0 in the image is iteration 0.\n\ndef wolfram_1d(rule, init_state=None, iterations=125, show=True):\n    \"\"\"\n    Generates 1D Wolfram automaton states over a number iterations.\n    Parameters\n    ----------\n    rule: int [0, 255]\n        Number associated with the next state rule.\n    init_state: ndarray[0.\/1.], any size, default=[0, ... 1, ... 0]\n        State to start simualation with.\n    iterations: int, default=500\n        Number of new states to solve for.\n    show: bool, default=True\n        Use opencv to display states or not.\n    Returns\n    -------\n    ndarray[iterations+1, len(init_state] All calculated states, stacked.\n    \"\"\"\n    def rule_map(rule):\n        \"\"\"\n        Generate the map for the cell and its neighbors to the new cell state based\n        on the given rule number.\n        Parameters\n        ----------\n        rule: int\n            Number associated with the next state rule.\n        Returns\n        -------\n        dict, {'': 1\/0 for all permutations of cell and neighbors.}\n        \"\"\"\n        STATES = ['1', '0']\n        reverse_binary = [x + y + z for x in STATES for y in STATES for z in STATES]\n\n        rule_binary = []\n        for i in range(7, -1, -1):\n            rule_binary += [int(rule \/ 2**i >= 1)]\n            rule %= 2**i\n\n        return dict(zip(reverse_binary, rule_binary))\n\n    state = np.zeros(shape=251); state[state.size \/\/ 2 + 1] = 1\n    if init_state is not None:\n        state = init_state\n\n    image = state.copy()\n\n    state_map = rule_map(rule)\n\n    RULE = lambda neighbors: state_map[\"\".join([str(int(v)) for v in neighbors])]\n\n    footprint = np.ones(shape=(3))\n\n    for _ in range(iterations):\n        state = generic_filter(state, RULE, footprint=footprint)\n\n        image = np.vstack((image, state))\n\n    if show:\n        print(f\"Wolfram 1D, Rule: {rule}\")\n        plt.imshow(image, cmap='gray')\n        plt.show()\n\n    return image\n\nwolfram_1d(184, init_state=np.where(np.random.uniform(0, 1, size=220) > .5, 1., 0.))\nwolfram_1d(90)  ## Serpinski Triangle\nwolfram_1d(30)  ## Chaos\nwolfram_1d(135)  ## Inverse of 30\n\n1 + 1","fe61c11c":"## K Means Clustering\ufffc\n# https:\/\/docs.opencv.org\/2.4\/modules\/core\/doc\/clustering.html\nimage = mpimg.imread('..\/input\/cat-images\/cat.jpg')\nplt.imshow(image)\nplt.show()\n\n## K Means Clustering Color Data\n# List of arbitrary data values, in this case (R, G, B) \n# - any data can be added that the algorithm will be able to use\nvectorized = image.reshape((-1, 3))\nvectorized = np.float32(vectorized)\n\ntermination_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n\nK = 3\n_, label, center = cv2.kmeans(vectorized, K, bestLabels=None, criteria=termination_criteria, attempts=10, flags=0)\n# label is the group number for every vector in vectorized\n# center is the centroid poisition of every group\n\n# Color code pixels based on their class and the centroid color of their class\nresult_image = np.uint8(center)[label.flatten()]\nresult_image = result_image.reshape((image.shape))\n\nplt.imshow(result_image)\nplt.show()\n\n## K Means Clustering Color and Location Data\n# (R, G, B, X, Y)\nvectorized = image.reshape((-1, 3))\n\n# add x, y data to vectorized\nidxs = np.array([idx for idx, _ in np.ndenumerate(np.mean(image, axis=2))])\nvectorized = np.hstack((vectorized, idxs))\n\ntermination_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n\nK = 3\n_, label, center = cv2.kmeans(np.float32(vectorized), K, bestLabels=None, criteria=termination_criteria, attempts=10, flags=0)\n\ncenter = np.uint8(center)[:, :3]\n\nresult_image = center[label.flatten()]\nresult_image = result_image.reshape((image.shape))\n\nplt.imshow(result_image)\nplt.show()\n\nprint(\"Vectorized Data, (R, G, B, X, Y)\")\nprint(vectorized)","78c8bb50":"# Generic Filter \/ Kernel w\/ Scipy\nhttps:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.ndimage.generic_filter.html#scipy.ndimage.generic_filter\n\nGeneric filters are like convolutions but instead of the output specifically being the dot product of the data in the sliding matrix and the kernel, the output is dictated by an arbitrary function on the sliding window.\n\nThis allows the creation of arbitrary filters to act on any type of signal.","1a367a40":"# Computer Vision pt 2\nConvolutions, Filters and Clustering","8fa97004":"# K Means Clustering\nhttps:\/\/en.wikipedia.org\/wiki\/K-means_clustering\n\nhttps:\/\/docs.opencv.org\/2.4\/modules\/core\/doc\/clustering.html\n\nK Means Clustering is an unsupervised clustering algorithms, it attempts to classify points based on their proximity in state space without the need to tell the model anything but how many classes to look for, just give it a dataset and it will solve. In an image, the state space for pixels is an axis for each color and two more axes for the X and Y axis(?) thus, each pixel in the image has a different location in this state space.\n\nK Means is a clustering algorithm that attempts to split points in the dataset into K distinct groups. This is useful for image segmentation.","84749bf6":"# Scikit-Image\nhttps:\/\/docs.scipy.org\/doc\/scipy\/reference\/ndimage.html\n\nBook: Elegant Scipy","2f141698":"# Convolutions w\/ Scipy\nhttps:\/\/docs.scipy.org\/doc\/scipy-0.15.1\/reference\/generated\/scipy.ndimage.filters.convolve.html\n\n\"Convolution is the process of adding each element of the image to its local neighbors, weighted by the kernel.\"(https:\/\/en.wikipedia.org\/wiki\/Kernel_(image_processing)#Convolution)\n\nApplications include blurring, sharpening, detecting edges & shapes or generic feature recognizers."}}