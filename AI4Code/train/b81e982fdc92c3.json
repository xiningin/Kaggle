{"cell_type":{"36689a25":"code","1fdc7c4c":"code","d9b3cb0f":"code","57dcd099":"code","49199d0e":"code","b35c0e0c":"code","e09d79f3":"markdown"},"source":{"36689a25":"import os\nimport time\nimport librosa\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom tqdm import tqdm\nfrom functools import partial\nimport multiprocessing","1fdc7c4c":"!mkdir -p ..\/data\/train\/curated\n!unzip -q \/kaggle\/input\/freesound-audio-tagging-2019\/train_curated.zip -d ..\/data\/train\/curated\/wav\n\n# Takes very long and a lot of memory\n# !mkdir -p ..\/data\/train\/noisy\n# !unzip -q \/kaggle\/input\/freesound-audio-tagging-2019\/train_noisy.zip -d ..\/data\/train\/noisy\/wav\n\n!mkdir -p ..\/data\/test\n!unzip -q \/kaggle\/input\/freesound-audio-tagging-2019\/test.zip -d ..\/data\/test\/wav","d9b3cb0f":"def load_train_data_df(mode='curated'):\n    # Load training data filenames and labels (raw -> multilabels are represented as a string with comma separated values)\n    data_folder = '\/kaggle\/input\/freesound-audio-tagging-2019' \n    csv_path = f'{data_folder}\/train_{mode}.csv'\n    raw_df = pd.read_csv(csv_path, index_col='fname')\n        \n    # Extract list of expected labels\n    sub = pd.read_csv('\/kaggle\/input\/freesound-audio-tagging-2019\/sample_submission.csv', index_col='fname')\n    labels_list = sub.columns.values \n\n    # Encode multi-labels in a binary vector\n    splitted_labels = [ labels.split(',') for labels in raw_df['labels'].values ]\n    encoder = MultiLabelBinarizer()\n    encoded_labels = encoder.fit_transform(splitted_labels)\n\n    # Create a new pandas Dataframe to represent training labels as binary vectors\n    labels_df = pd.DataFrame(data=encoded_labels, index=list(raw_df.index), columns=labels_list)\n    \n    return labels_df\n\ndef extract_mfcc(sample, n_mfcc=20, sr=44100):\n    \"\"\" Return a matrix of shape (n_mfcc, int(seconds*sr\/1024)). \"\"\"\n    mfccs = librosa.feature.mfcc(sample, sr=sr, n_mfcc=n_mfcc)\n    return mfccs.astype(np.float32)\n\ndef extract_log_mel(sample, n_mels=128, sr=44100, hop=347):\n    mel = librosa.feature.melspectrogram(sample, sr=sr, n_fft=20*n_mels, hop_length=hop, n_mels=n_mels, fmin=20, fmax=sr\/\/2)\n    logmel = librosa.core.power_to_db(mel, ref=1.0, amin=1e-10, top_db=None)\n    return logmel.astype(np.float32)\n\ndef extract_features(path, save_folder='..\/data\/train\/curated', feat_type='logmel', n_feats=128, hop=347, sr=44100, save=False):\n    start_time = time.time()\n\n    sample, _ = librosa.load(path, sr=None)\n    x, _ = librosa.effects.trim(sample)\n\n    if feat_type == 'mfcc':\n        x = extract_mfcc(x, n_feats, sr)\n    elif feat_type == 'logmel':\n        x = extract_log_mel(x, n_feats, sr, hop)\n        \n    if save:\n        if not os.path.exists(f'{save_folder}\/{feat_type}'):\n            os.makedirs(f'{save_folder}\/{feat_type}')\n        filename = path.split('\/')[-1].split('.')[0]\n        np.save(f\"{save_folder}\/{feat_type}\/{filename}.npy\", x)\n    \ndef extract_serie(wav_paths, save_folder='..\/data\/train\/curated', feat_type='logmel', n_feats=128, hop=347, sr=44100, save=False):\n    start_time = time.time()\n    \n    with tqdm(total=len(curated_train_wav_paths)) as bar:\n        for path in wav_paths:\n            extract_features(path, save_folder, feat_type, n_feats, hop, sr, save)\n            bar.update(1)\n            \n    print(f'Successfully extracted {feat_type} features in {save_folder} ! (took {time.time() - start_time:.2f}s).')\n    \ndef extract_parallel(wav_paths, save_folder='..\/data\/train\/curated', feat_type='logmel', n_feats=128, hop=347, sr=44100, save=False):\n    start_time = time.time()\n    \n    n_cores = multiprocessing.cpu_count()\n    print(f'Extracting {feat_type} using {n_cores} cores...')\n    \n    with tqdm(total=len(wav_paths)) as bar, multiprocessing.Pool(processes=n_cores) as pool:\n        function = partial(extract_features, save_folder=save_folder, feat_type=feat_type, n_feats=n_feats, hop=hop, sr=sr, save=save)\n        for _ in pool.map(function, wav_paths):        \n            bar.update(1)\n        \n    print(f'Successfully extracted {feat_type} features in {save_folder} ! (took {time.time() - start_time:.2f}s).')","57dcd099":"# Load data filenames and labels\ncurated_train_labels = load_train_data_df(mode='curated')\nnoisy_train_labels = load_train_data_df(mode='noisy')\ntest_labels = pd.read_csv('\/kaggle\/input\/freesound-audio-tagging-2019\/sample_submission.csv', index_col='fname')\n\n# Main info about the training\/testing sets\nprint(f'{curated_train_labels.shape[1]} possible classes.')\nprint(f'{curated_train_labels.shape[0]} curated training samples.')\nprint(f'{noisy_train_labels.shape[0]} noisy training samples.')\nprint(f'{test_labels.shape[0]} test samples.')\n\ncurated_train_wav_paths = '..\/data\/train\/curated\/wav\/' + curated_train_labels.index.values\nnoisy_train_wav_paths = '..\/data\/train\/noisy\/wav\/' + noisy_train_labels.index.values\ntest_wav_paths = '..\/data\/test\/wav\/' + test_labels.index.values\n\nuse_parallel = True\n\nif use_parallel:\n    extract_parallel(curated_train_wav_paths, save_folder='..\/data\/train\/curated', save=True)\n#     extract_parallel(noisy_train_wav_paths, save_folder='..\/data\/train\/noisy', save=True)\n    extract_parallel(test_wav_paths, save_folder='..\/data\/test', save=True)   \nelse:\n    extract_serie(curated_train_wav_paths, save_folder='..\/data\/train\/curated', save=True)\n#     extract_serie(noisy_train_wav_paths, save_folder='..\/data\/train\/noisy', save=True)\n    extract_serie(test_wav_paths, save_folder='..\/data\/test', save=True)","49199d0e":"!zip -rq curated_train_logmel.zip ..\/data\/train\/curated\/logmel\n# !zip -r noisy_train_logmel.zip ..\/data\/train\/noisy\/logmel\n!zip -rq test_logmel.zip ..\/data\/test\/logmel","b35c0e0c":"!du -m curated_train_logmel.zip\n# !du -m noisy_train_logmel.zip\n!du -m test_logmel.zip","e09d79f3":"Handling the noisy train dataset on Google Colab:\nhttps:\/\/colab.research.google.com\/drive\/1uTEdXfazhonVHxP4vmuYAgG2BexzHfcu?usp=sharing"}}