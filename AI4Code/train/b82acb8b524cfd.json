{"cell_type":{"8a88f20b":"code","5d51d1f8":"code","f52b9e74":"code","0a895b88":"code","6268ebda":"code","29001282":"code","24d172f0":"code","435fce92":"code","5a84545c":"code","727ecf71":"code","42acd302":"code","e4b69ba4":"code","2fd1b518":"code","f8b61b58":"code","9a7fb2f1":"code","25910019":"code","110346af":"code","73631295":"code","d853a580":"code","d3fd39ec":"code","25ba4713":"code","60045370":"code","61c9dc4c":"code","8b09f559":"markdown","11ae19cc":"markdown","8db8a3ac":"markdown","b38eaf89":"markdown","20a2bda9":"markdown","06fed360":"markdown","34037413":"markdown","5e190d44":"markdown","318418ac":"markdown","1e1e6bed":"markdown","97b9f72e":"markdown","5517fb6e":"markdown","b2d10913":"markdown"},"source":{"8a88f20b":"###############################################################################################################################\n#\n#\tVariational Auto Encoder Built using Keras and celebA dataset is used \n#\tfor training.\n#\t\n#\tCreated by : B V P Sai Kumar \n#\tgithub : https:\/\/github.com\/kumararduino\n#\twebsite : https:\/\/kumarbasaveswara.in\n#\tlinkedin : https:\/\/www.linkedin.com\/in\/kumar15412304\/\n#\n#\n#\tCredits:\n#\tDataset : https:\/\/www.kaggle.com\/jessicali9530\/celeba-dataset\n#\tArticle : https:\/\/towardsdatascience.com\/intuitively-understanding-variational-autoencoders-1bfe67eb5daf\n#\t\tThis Article gave me a clear glance about how Variational_Auto_Encoders work\n# Article on KL_Divergence : https:\/\/www.countbayesie.com\/blog\/2017\/5\/9\/kullback-leibler-divergence-explained\n#\t\n#\n#\n###############################################################################################################################","5d51d1f8":"import gc\nimport psutil\nimport multiprocessing as mp\nimport copy\nmp.cpu_count()\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport keras\nfrom keras.models import Model,Sequential\nfrom keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,BatchNormalization,Lambda,Activation,Input,Flatten,Reshape,Conv2DTranspose\nimport keras.backend as K\nfrom keras.layers.merge import add\nfrom sklearn.model_selection import train_test_split\nimport os\nimport glob\nfrom time import time,asctime\nfrom random import randint as r\nimport random","f52b9e74":"# os.chdir(\"faces\")\nimgs = glob.glob(\"..\/input\/img_align_celeba\/img_align_celeba\/*.jpg\")\nprint(len(imgs))","0a895b88":"imgs[0]","6268ebda":"train_y = []\ntrain_y2 = []\nfor _ in range(0,100000):\n  if _%20000 == 0:\n    print(\"{} \/ 100000\".format(_))\n  img = cv2.imread(imgs[_])\n  img = cv2.resize(img,(32,32),interpolation = cv2.INTER_AREA)\n  train_y.append(img.astype(\"float32\")\/255.0)\nfor _ in range(100000,200000):\n  if _%20000 == 0:\n    print(\"{} \/ 200000\".format(_))\n  img = cv2.imread(imgs[_])\n  img = cv2.resize(img,(32,32),interpolation = cv2.INTER_AREA)\n  train_y2.append(img.astype(\"float32\")\/255.0)\ntrain_y = np.array(train_y)\ntrain_y2 = np.array(train_y2)\nY_data = np.vstack((train_y,train_y2))\nprint(psutil.virtual_memory())\ndel train_y,train_y2\ngc.collect()\nprint(psutil.virtual_memory())\nZ_data = copy.deepcopy(Y_data)\nZ_data = (Z_data - Z_data.mean())\/Z_data.std()","29001282":"test_Y = []\nfor _ in range(200000,202599):\n  if _%5000 == 0:\n    print(\"{} \/ 100000\".format(_))\n  img = cv2.imread(imgs[_])\n  img = cv2.resize(img,(32,32),interpolation = cv2.INTER_AREA)\n  test_Y.append(img.astype(\"float32\")\/255.0)\n  \ntest_Y = np.array(test_Y)\nmean = test_Y.mean()\nstd = test_Y.std()\ntest_Z = (test_Y - mean)\/std","24d172f0":"def sampler(layers):\n  std_norm = K.random_normal(shape=(K.shape(layers[0])[0], 128), mean=0, stddev=1)\n  return layers[0] + layers[1]*std_norm","435fce92":"stride = 2\ninp = Input(shape = (32,32,3))\nx = inp\nx = Conv2D(32,(2,2),strides = stride,activation = \"relu\",padding = \"same\")(x)\nx = Conv2D(64,(2,2),strides = stride,activation = \"relu\",padding = \"same\")(x)\nx = Conv2D(128,(2,2),strides = stride,activation = \"relu\",padding = \"same\")(x)\nshape = K.int_shape(x)\nx = Flatten()(x)\nx = Dense(256,activation = \"relu\")(x)\nmean_layer = Dense(128,activation = \"relu\")(x)\nsd_layer = Dense(128,activation = \"relu\")(x)\nlatent_vector = Lambda(sampler)([mean_layer,sd_layer])\nencoder = Model(inp,latent_vector,name = \"VAE_Encoder\")\nencoder.summary()\n","5a84545c":"decoder_inp = Input(shape = (128,))\nx = decoder_inp\nx = Dense(shape[1]*shape[2]*shape[3],activation = \"relu\")(x)\nx = Reshape((shape[1],shape[2],shape[3]))(x)\nx = (Conv2DTranspose(32,(3,3),strides = stride,activation = \"relu\",padding = \"same\"))(x)\nx = (Conv2DTranspose(16,(3,3),strides = stride,activation = \"relu\",padding = \"same\"))(x)\nx = (Conv2DTranspose(8,(3,3),strides = stride,activation = \"relu\",padding = \"same\"))(x)\noutputs = Conv2DTranspose(3, (3,3), activation = 'sigmoid', padding = 'same', name = 'decoder_output')(x)\ndecoder = Model(decoder_inp,outputs,name = \"VAE_Decoder\")\ndecoder.summary()","727ecf71":"autoencoder = Model(inp,decoder(encoder(inp)),name = \"Variational_Auto_Encoder\")\nautoencoder.summary()","42acd302":"def vae_loss(input_img, output):\n\t# compute the average MSE error, then scale it up, ie. simply sum on all axes\n\treconstruction_loss = K.sum(K.square(output-input_img))\n\t# compute the KL loss\n\tkl_loss = - 0.5 * K.sum(1 + sd_layer - K.square(mean_layer) - K.square(K.exp(sd_layer)), axis=-1)\n\t# return the average loss over all images in batch\n\ttotal_loss = K.mean(reconstruction_loss + kl_loss)    \n\treturn total_loss","e4b69ba4":"autoencoder.compile(optimizer = \"adam\",loss = vae_loss,metrics = [\"accuracy\"])","2fd1b518":"autoencoder.fit(Z_data,Y_data,batch_size = 200,epochs = 15,validation_split = 0.5)","f8b61b58":"autoencoder.fit(Z_data,Y_data,batch_size = 32,epochs = 30,validation_split = 0.5)","9a7fb2f1":"autoencoder.fit(Z_data,Y_data,batch_size = 200,epochs = 100,validation_split = 0.35)","25910019":"autoencoder.fit(Z_data,Y_data,batch_size = 150,epochs = 30,validation_split = 0)","110346af":"autoencoder.fit(Z_data,Y_data,batch_size = 32,epochs = 200,validation_split = 0)","73631295":"autoencoder.fit(Z_data,Y_data,batch_size = 200,epochs = 2000,validation_split = 0)","d853a580":"pred = autoencoder.predict(test_Z)","d3fd39ec":"temp = r(0,2599)\nprint(temp)\nplt.subplot(1,3,1)\nplt.imshow(test_Y[temp])\nplt.subplot(1,3,2)\nplt.imshow(test_Z[temp])\nplt.subplot(1,3,3)\nplt.imshow(pred[temp])","25ba4713":"gen = np.random.normal(size = (1,32,32,3))\ngen_sample = autoencoder.predict(gen)\nplt.subplot(1,2,1)\nplt.imshow(gen[0])\nplt.subplot(1,2,2)\nplt.imshow(gen_sample[0])","60045370":"autoencoder.save_weights(\"VAE-weights-\"+str(r(0,3653))+\".h5\")","61c9dc4c":"for _ in range(10):\n    img = np.random.normal(size = (9,32,32,3))\n    pred = autoencoder.predict(img)\n    op = np.vstack((np.hstack((pred[0],pred[1],pred[2])),np.hstack((pred[3],pred[4],pred[5])),np.hstack((pred[6],pred[7],pred[8]))))\n    print(op.shape)\n    op = cv2.resize(op,(288,288),interpolation = cv2.INTER_AREA)\n    cv2.imwrite(\"generated\"+str(r(0,9999))+\".jpg\",(op*255).astype(\"uint8\"))","8b09f559":"Training the VAE","11ae19cc":"Connecting the Encoder and Decoder to make the **Auto Encoder**","8db8a3ac":"Generating a new face by passing a random normal sample of size (32,32,3) and observing the output","b38eaf89":"create Input vector of 200000 images each of shape (32,32,3) and scale them by dividing them by 255.save this as Y_data and also normalize the Y_data and save it as Z_data to train.","20a2bda9":"Load file names of all pics","06fed360":"Import Necessary packages","34037413":"Building the **Encoder** part","5e190d44":"This is the loss function used by the VAE.It is calculating KL_Divergence loss.KL-Divergence is explained clearly in this article\n[KL-Divergence](https:\/\/www.countbayesie.com\/blog\/2017\/5\/9\/kullback-leibler-divergence-explained)","318418ac":"This is the test data","1e1e6bed":"Building the **Decoder** part","97b9f72e":"Variational Auto Encoder has a sampler \nIn VAE, the encoder outputs two vectors.one is mean and the other is standard_deviation.sample from these two\nare taken as a final vector that can be done using the **sampler** function.","5517fb6e":"Displaying the input,normalized input,VAE output ","b2d10913":"Saving the model weights"}}