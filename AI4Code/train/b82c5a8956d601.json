{"cell_type":{"005b3699":"code","6c378990":"code","652ea1fb":"code","6dff149a":"code","cf36d94b":"code","01101334":"code","9d170738":"code","a5b5fd41":"code","c37eb15d":"code","4607ae54":"code","e30d4c68":"code","d1ef6de0":"code","639aac63":"code","daf98aeb":"code","7d852a29":"code","8a4a3570":"code","6c6bd65f":"code","f8efde01":"code","c4bb1d7c":"code","fc887c58":"code","7cab03d1":"code","465dffa3":"code","ab56bf5e":"code","ec2bcda9":"code","f8ff97f9":"code","3f13c3f9":"code","9ac145cf":"code","ff705cc2":"code","0c09a140":"code","66b5b883":"code","2abcb680":"code","2dace262":"code","657a0c68":"code","3b7dec06":"code","01d061a9":"code","f15ba7ec":"code","474fba90":"code","cddecae6":"markdown","9e9acd1f":"markdown","6a9e7268":"markdown","34e98c4b":"markdown","63cd47dd":"markdown","1f156ab9":"markdown","0aa71db6":"markdown","bac6119a":"markdown","9d4f3037":"markdown","48711a5c":"markdown","8f33c017":"markdown","d57e6c16":"markdown","748f7b7e":"markdown","7402da71":"markdown","cac38dcc":"markdown","82586c55":"markdown","0314a2b6":"markdown","52bc1ef2":"markdown","2750498a":"markdown","4373536f":"markdown","1013e083":"markdown","2dbe3ea2":"markdown","1f430c87":"markdown","717ef691":"markdown","a59437bd":"markdown","15f8cfdc":"markdown","30af7289":"markdown","434df352":"markdown","ceac1161":"markdown","aa3bbfd4":"markdown"},"source":{"005b3699":"# loading required libraries for cancer treament analysis\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# To ignore warinings\nimport warnings\nwarnings.filterwarnings('ignore')","6c378990":"# let's check in which directory our data is available so that it will be easy to pull from specific source location\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","652ea1fb":"# loading datasets\ntrain_variants = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/training_variants')\ntest_variants = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/test_variants')\ntrain_text = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\ntest_text = pd.read_csv('..\/input\/msk-redefining-cancer-treatment\/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])","6dff149a":"train_variants.head()","cf36d94b":"train_text.head()","01101334":"train_merge = pd.merge(train_variants,train_text,how='left',on='ID')\n# let's pull train merge dataset and do the analysis on this\ntrain_merge.head()","9d170738":"# Let's understand the type of values present in each column of our dataframe 'train_merge' dataframe.\ntrain_merge.info()","a5b5fd41":"# Histogram : To check class distribution\nplt.figure(figsize=(12,8))\nsns.countplot(x='Class',data=train_variants)\nplt.ylabel('Frequency-Counts', fontsize=15)\nplt.xlabel('Class',fontsize=13)\nplt.xticks(rotation='vertical')\nplt.title('Class Counts',fontsize=15)\nplt.show()","c37eb15d":"train_merge[\"Text_num_words\"] = train_merge[\"Text\"].apply(lambda x: len(str(x).split()) )\ntrain_merge[\"Text_num_chars\"] = train_merge[\"Text\"].apply(lambda x: len(str(x)) )","4607ae54":"plt.figure(figsize=(12, 8))\nsns.distplot(train_merge.Text_num_words.values, bins=50, kde=False, color='red')\nplt.xlabel('Number of words in text', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.title(\"Frequency of number of words\", fontsize=15)\nplt.show()","e30d4c68":"plt.figure(figsize=(12, 8))\nsns.distplot(train_merge.Text_num_chars.values, bins=50, kde=False, color='brown')\nplt.xlabel('Number of characters in text', fontsize=12)\nplt.ylabel('log of Count', fontsize=12)\nplt.title(\"Frequency of Number of characters\", fontsize=15)\nplt.show()","d1ef6de0":"plt.figure(figsize=(12,8))\nsns.boxplot(x='Class', y='Text_num_words', data=train_merge)\nplt.xlabel('Class', fontsize=12)\nplt.ylabel('Text - Number of words', fontsize=12)\nplt.show()","639aac63":"train_merge.describe()","daf98aeb":"# putting respon variable to y\n#y = train_merge['Class'].values\n#train_merge = train_merge.drop('Class',axis=1)","7d852a29":"train_merge.head(3)","8a4a3570":"#y","6c6bd65f":"test_merge = pd.merge(test_variants,test_text,how='left',on='ID')\ntest_merge.head(3)","f8efde01":"pid = test_merge['ID'].values\npid","c4bb1d7c":"test_merge.describe()","fc887c58":"# check total number of null\/missing value present in whole datasets\ntrain_merge.isnull().sum()","7cab03d1":"# find out percentage of \"?\" value present across the dataset\npercent_missing = train_merge.isnull().sum() * 100 \/ len(train_merge)\npercent_missing","465dffa3":"# droping missing values\ntrain_merge.dropna(inplace=True)\n\n# let's check again whether we have any further missing values\ntrain_merge.isnull().sum()","ab56bf5e":"test_merge.isnull().sum()","ec2bcda9":"# dropping missing values\ntest_merge.dropna(inplace=True)\n\n# check if our data is clean or not\ntest_merge.isnull().sum()","f8ff97f9":"from sklearn.model_selection import train_test_split\ntrain,test = train_test_split(train_merge,test_size=0.2)\nnp.random.seed(0)\ntrain","3f13c3f9":"X_train = train['Text'].values\nX_test = test['Text'].values\ny_train = train['Class'].values\ny_test = test['Class'].values","9ac145cf":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn import svm","ff705cc2":"text_classifier = Pipeline([('vect', CountVectorizer()),\n                     ('tfidf', TfidfTransformer()),\n                     ('clf', svm.LinearSVC())\n])\ntext_classifier = text_classifier.fit(X_train,y_train)","0c09a140":"y_test_predicted = text_classifier.predict(X_test)\nnp.mean(y_test_predicted == y_test)","66b5b883":"X_test_final = test_merge['Text'].values\n#X_test_final","2abcb680":"predicted_class = text_classifier.predict(X_test_final)","2dace262":"test_merge['predicted_class'] = predicted_class","657a0c68":"test_merge.head(5)","3b7dec06":"onehot = pd.get_dummies(test_merge['predicted_class'])\ntest_merge = test_merge.join(onehot)","01d061a9":"test_merge.head(5)","f15ba7ec":"submission_df = test_merge[[\"ID\",1,2,3,4,5,6,7,8,9]]\nsubmission_df.columns = ['ID', 'class1','class2','class3','class4','class5','class6','class7','class8','class9']\nsubmission_df.head(5)","474fba90":"submission_df.to_csv('submission.csv', index=False)","cddecae6":"## Work in Progress.....","9e9acd1f":"    - Ohh Ok, We have only 5 missing values present in text feature\n    - Let's remove those since it's only 5 missing in number if we see the percentage of missing values it's like only 0.1% . Since it's very less number we can remove those.","6a9e7268":"### Similarlly let's pull top 5 rows value fromtrain text data","34e98c4b":"```Use Case Details:```\n\nA lot has been said during the past several years about how precision medicine and, more concretely, how genetic testing is going to disrupt the way diseases like cancer are treated.\n\nBut this is only partially happening due to the huge amount of manual work still required. Memorial Sloan Kettering Cancer Center (MSKCC) launched this competition, accepted by the NIPS 2017 Competition Track,  because we need your help to take personalized medicine to its full potential.\n\n\n\nOnce sequenced, a cancer tumor can have thousands of genetic mutations. But the challenge is distinguishing the mutations that contribute to tumor growth (drivers) from the neutral mutations (passengers). \n\nCurrently this interpretation of genetic mutations is being done manually. This is a very time-consuming task where a clinical pathologist has to manually review and classify every single genetic mutation based on evidence from text-based clinical literature.\n\nFor this competition MSKCC is making available an expert-annotated knowledge base where world-class researchers and oncologists have manually annotated thousands of mutations.\n\nWe need your help to develop a Machine Learning algorithm that, using this knowledge base as a baseline, automatically classifies genetic variations.\n\n\nKaggle is excited to partner with research groups to push forward the frontier of machine learning. Research competitions make use of Kaggle's platform and experience, but are largely organized by the research group's data science team. Any questions or concerns regarding the competition data, quality, or topic will be addressed by them.","63cd47dd":"- Awesome we are good to model builing. let's do this.","1f156ab9":"## **If you found this notebook helpful or you just liked it , some upvotes would be very much appreciated - That's will keep me motivated :)**","0aa71db6":"## Let's have a quick look whether we have balance data or not in our test datasets","bac6119a":"### Let's pull the top 5 rows value from train variants","9d4f3037":"## Let's check whether the data is balance or not","48711a5c":"- Appended the predicted class values to the testing data","8f33c017":"## Missing Value Analysis\n\n- Check for missing values in both training and testing data columns","d57e6c16":"## Now let's merge the test datasets(variants & text) together to one dataset","748f7b7e":"### Now Let's explore the text column and see the text distribution\n","7402da71":"## Importing and Loading Datasets","cac38dcc":"## Onehot encoding to get the predicted class values as columns","82586c55":"- Predicting values for test data","0314a2b6":"- Looks like data is pretty balanced since we didn't see any random pick value. We are good to go for further analysis","52bc1ef2":"### Check test data is clean or not","2750498a":"**- Let's look at the distribution of number of words in the text column.**","4373536f":"- Awesome our data is cleaned! Good to go for model building","1013e083":"- Awesome! Our test dataset is looks fine. ","2dbe3ea2":"## Now let's draw a histogram\/count plot to see how the classes are distributed","1f430c87":"``` The peak is around 4000 words.``` \n\n- Now let us look at character level.","717ef691":"**More to come. Stay tuned.!**","a59437bd":"\n# Splitting Datasets into Training and Testing sets\n**- Splitting Datasets into Training & Testing sets by using scikit learn library**\n","15f8cfdc":"- Okay, We have only 1 missing value in text data. let's remove it.","30af7289":"- Set pipeline to build a complete text processing model with Vectorizer, Transformer and LinearSVC","434df352":"### Merging Train variants and Train text into one trai dataset","ceac1161":"- check if we could use the number of words in the text has predictive power.","aa3bbfd4":"## Preparing submission data"}}