{"cell_type":{"b426acf2":"code","dce883fc":"code","917b29a0":"code","89517e67":"code","eabe5257":"code","f581b5c2":"code","0515b6c3":"code","1d5a90c1":"code","24d9f010":"code","05eabe85":"code","f611dd45":"code","10ea0053":"code","debef3c0":"code","6e8aad87":"code","78aed47b":"code","fd26a223":"code","2a4da487":"code","f83dd6de":"code","fe67d35f":"code","1b87f7a5":"code","aed69d51":"code","09751d78":"code","d1b4d298":"code","dd283e1a":"code","0a7072d2":"code","c2e6066e":"code","8cc993a7":"markdown"},"source":{"b426acf2":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display\nimport random\nimport math\nimport tensorflow as tf\nfrom keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.utils import plot_model \nfrom tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation,Concatenate\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import to_categorical \nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras import backend, models\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow.keras.applications import VGG16, MobileNet\nfrom keras.applications.vgg16 import preprocess_input","dce883fc":"data_dir = '\/kaggle\/input\/100-bird-species'\ntrain_dir = '..\/input\/100-bird-species\/train'\nvalid_dir = '..\/input\/100-bird-species\/valid'\ntest_dir = '..\/input\/100-bird-species\/test'","917b29a0":"categories = os.listdir(train_dir)\nprint(str(len(categories)),'CATEGORIES are ', categories)\n\nCategory_count = len(categories)","89517e67":"len(categories)","eabe5257":"image = load_img(\"\/kaggle\/input\/100-bird-species\/train\/ANNAS HUMMINGBIRD\/030.jpg\")\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()\n\nimagedata = img_to_array(image)\nshape = imagedata.shape\nprint('Figures are ', shape)","f581b5c2":"datagen = ImageDataGenerator(rescale=1.\/255, )\n","0515b6c3":"train_data =datagen.flow_from_directory(train_dir, target_size=(224,224),batch_size=64)\nvalidation_data = datagen.flow_from_directory(valid_dir, target_size=(224,224),batch_size=64)\ntest_data = datagen.flow_from_directory(test_dir, target_size=(224,224),batch_size=64)\n","1d5a90c1":"train_data.class_indices","24d9f010":"Train_groups = len(train_data)\nValid_groups = len(validation_data)\n","05eabe85":"def label_images2(DIR, dataset):\n    label = []\n    image = []\n    j=0\n    for i in range (0,30):\n        j = random.randint(0, len(dataset.filenames))\n        label.append(dataset.filenames[j].split('\/')[0])\n        image.append(DIR + '\/' + dataset.filenames[j])\n    return [label,image]\n\n#plot the random images.\ny,x = label_images2(test_dir, test_data)\n\nfor i in range(0,6):\n    X = load_img(x[i])\n    plt.subplot(2,3,+1 + i)\n    plt.axis(False)\n    plt.title(y[i], fontsize=8)\n    plt.imshow(X)\nplt.show()","f611dd45":"model = Sequential()\n\nmodel.add(Conv2D(64, (3, 3), padding='same',input_shape=shape)) \nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3, 3))) \nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.35))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization()) \n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.35)) #64 --> 42\n\nmodel.add(Conv2D(64, (3, 3), padding='same')) \nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten()) \nmodel.add(Dropout(0.5)) \nmodel.add(Dense(512)) \nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(310)) \nmodel.add(Activation('softmax'))\n\nmodel.summary()","10ea0053":"model.compile(optimizer = 'adam',\n               loss = 'categorical_crossentropy',\n               metrics = ['accuracy'])","debef3c0":"Augment_datagen = ImageDataGenerator(rescale=1.\/255,\n    rotation_range=40, \n    width_shift_range=0.2, \n    height_shift_range=0.2, \n    zoom_range=0.2,  \n    horizontal_flip=True,\n    fill_mode='nearest') \nAugmentation_train = Augment_datagen.flow_from_directory(train_dir, target_size=(224,224))","6e8aad87":"history = model.fit_generator( \n    Augmentation_train, \n    epochs = 50,\n    validation_data = validation_data,\n    steps_per_epoch = Train_groups,\n    validation_steps = Valid_groups,\n    verbose = 1,\n    callbacks=[EarlyStopping(monitor = 'val_accuracy', patience = 4),\n               ReduceLROnPlateau(monitor = 'val_loss',\n                                 patience = 4, verbose = 1)]) ","78aed47b":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","fd26a223":"model.evaluate(test_data, verbose=1)\n","2a4da487":"dic=train_data.class_indices\nicd={k:v for v,k in dic.items()}\ndef output(location):\n    img=load_img(location,target_size=(224,224,3))\n    img=img_to_array(img)\n    img=img\/255\n    img=np.expand_dims(img,[0])\n    answer=np.argmax(model.predict(img), axis=-1)\n\n    \n    print (icd[answer[0]])","f83dd6de":"img='..\/input\/100-bird-species\/train\/ALBATROSS\/001.jpg'\npic=load_img('..\/input\/100-bird-species\/train\/ALBATROSS\/001.jpg',target_size=(224,224,3))\nplt.imshow(pic)\noutput(img)","fe67d35f":"vgg_model=VGG16(input_shape=shape , weights='imagenet' , include_top=False)","1b87f7a5":"for layer in vgg_model.layers:\n    layer.trainable  = False","aed69d51":"vgg_model.summary()","09751d78":"model = Sequential()\nmodel.add(vgg_model)\n\nmodel.add(Flatten()) \nmodel.add(Activation('relu'))\nmodel.add(Dense(310)) \nmodel.add(Activation('softmax'))\n\n\n\nmodel.summary()\n","d1b4d298":"model.compile(optimizer = 'adam',\n               loss = 'categorical_crossentropy',\n               metrics = ['accuracy'])","dd283e1a":"history = model.fit_generator( \n    Augmentation_train, \n    epochs = 50,\n    validation_data = validation_data,\n    steps_per_epoch = Train_groups,\n    validation_steps = Valid_groups,\n    verbose = 1,\n    callbacks=[EarlyStopping(monitor = 'val_accuracy', patience = 5)]) ","0a7072d2":"model.evaluate(test_data, verbose=1)\n","c2e6066e":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","8cc993a7":"# vgg16"}}