{"cell_type":{"78bbb738":"code","05c45ac4":"code","775777e8":"code","3924ebc4":"code","7587d44f":"code","964f92f8":"code","dffb4196":"code","a9a65150":"code","06c3f5d6":"code","d68177bf":"code","da5baf2b":"code","840c4971":"code","4e7743a4":"code","f2061e2a":"code","f6c0e6f8":"code","5853d4a8":"code","c764defd":"code","b12b5603":"code","f09613ea":"code","c4316ac5":"code","e443a5e6":"code","b98fdb13":"markdown","d93f168a":"markdown","5e2cefc4":"markdown","7094a8fd":"markdown","2e58a2e8":"markdown","0fca27b5":"markdown","5beb97c7":"markdown","3687f8b7":"markdown","775aae14":"markdown","24281f80":"markdown","badecf20":"markdown","b30c8a18":"markdown","52c16d01":"markdown"},"source":{"78bbb738":"import numpy as np\nimport pandas as pd \n\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nimport os \nimport cv2\nimport random \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","05c45ac4":"from IPython.core.display import display, HTML\ndisplay(HTML(\"<style>div.output_scroll { height: 70em; }<\/style>\"))","775777e8":"sns.set(style= 'darkgrid', \n       color_codes=True,\n       font = 'Arial',\n       font_scale= 1.5,\n       rc={'figure.figsize':(12,8)})","3924ebc4":"os.listdir(\"..\/input\/petfinder-pawpularity-score\/\")","7587d44f":"len(os.listdir(\"..\/input\/petfinder-pawpularity-score\/train\"))","964f92f8":"len(os.listdir(\"..\/input\/petfinder-pawpularity-score\/test\"))","dffb4196":"train = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\nss = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')","a9a65150":"test.shape","06c3f5d6":"train.shape","d68177bf":"ss.shape","da5baf2b":"train.head()","840c4971":"ss.head()","4e7743a4":" \n_, axs = plt.subplots( 2, 2, figsize=(15, 12))\n\naxs = axs.flatten()\ncol = train.columns.tolist() \n\nfor a, ax in zip(train.sample(4).iterrows(), axs):\n    img = cv2.imread(f'..\/input\/petfinder-pawpularity-score\/train\/{a[1][0]}.jpg')\n    img = cv2. resize(img, (600, 600))\n    other_info = [ col[i] for i in range(13) if a[1][i] == 1 ]\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(img)\n    ax.set_title(f'Id: {a[0]}, Pawpularity : {a[1][13]}, ' + \", \".join(other_info), fontsize= 12, fontweight='bold' )\n    \nplt.show()\n","f2061e2a":"sns.distplot(train[\"Pawpularity\"])\nplt.title(\"Distribution of Pawpularity\")","f6c0e6f8":"_, axs = plt.subplots( 3,4 , figsize=(15, 15))\n\naxs = axs.flatten()\ncol = train.columns.tolist() \n\nfor a, ax in zip(train[train[\"Pawpularity\"] >= 95].sample(6).append(train[train[\"Pawpularity\"] <= 5].sample(6)).iterrows(), axs):\n    img = cv2.imread(f'..\/input\/petfinder-pawpularity-score\/train\/{a[1][0]}.jpg')\n    img = cv2. resize(img, (600, 600))\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow(img)\n    ax.set_title(f'Id: {a[0]}, Pawpularity : {a[1][13]}', fontsize= 12, fontweight='bold' )\n    \nplt.show()","5853d4a8":"high = train[train[\"Pawpularity\"] > 80 ].sample(500)\nlow = train[train[\"Pawpularity\"] < 20 ].sample(500)","c764defd":"high.shape == low.shape","b12b5603":"def plot_counts(df):\n    data = dict()\n    for c in df.columns.tolist()[1:-1]:\n        data[c] = df[c].sum()\n    return data ","f09613ea":"plot_counts(high)","c4316ac5":"k = [\"High Pawpularity\" , \"Low Pawpularity\"]\nfor D,i, ax in zip([plot_counts(high), plot_counts(low)], range(2),  axs):\n    plt.figure(figsize= (17, 6))\n    plt.bar(range(len(D)), list(D.values()), align='center')\n    plt.xticks(range(len(D)), list(D.keys()) )\n    plt.title(\"Count of individual features for \" +  k[i], fontsize= 20, fontweight='bold' )\n    plt.show()\n","e443a5e6":"plt.figure(figsize= (15, 15))\nsns.heatmap(train.corr(), annot=True, fmt='.1g' )\nplt.title('Correlation Matrix', fontweight='bold', fontsize=20)\nplt.show()","b98fdb13":"### C. Output\/dependent variable i.e Pawpularity","d93f168a":"#### What is the difference between low Pawpularity and High Pawpularity images ? ","5e2cefc4":"### Setting up the Notebook ","7094a8fd":"### Brif problem description: \n\nPetFinder.my uses a basic Cuteness Meter to rank pet photos. It analyzes picture composition and other factors compared to the performance of thousands of pet profiles. While this basic tool is helpful, it's still in an experimental stage and the algorithm could be improved. The participants needs to build an AI model using provided data to help make the tool better.  \n\n**Task** \n\nThe task is to predict engagement with a pet's profile( **Pawpularity** ) based on the photograph for that profile. \n\n**Data** \n\nThe dataset for this competition comprises both images and tabular data(hand-labelled metadata for each photo). \n\nThe train set contains 9912 pet photos \n\nThe test set contains 8 pet photos\n> NOTE: The actual test data comprises about **6800** pet photos similar to the training set photos. \n\n#### **The goal of this notebook is to:** \n\n1. Understand the structure of the data. ( image and tabular ) \n2. Understand the relation between image and tabular data. \n3. Understand the impact of image and tabular data deciding Pawpularity score. \n\n","2e58a2e8":" \n from the above images, I think it is difficult to say what is the main reason for high \"Pawpularity\".. \n \n lets have a look at the data(train.csv) to find the difference between high Pawpularity and low Pawpularity images  \n","0fca27b5":" \n#### The distribution of values is also nearly same, maybe correlation with respect to data can give us some insights \n","5beb97c7":" \nthe distribution of Pawpularity looks like a normal distribution, which means the data spectrum is good. \n","3687f8b7":"#### A.1 Features in train and test data .csv files \n\nEach feature can take vale 1(YES) or 0 (NO):   \n\n1. Focus - Pet stands out against uncluttered background, not too close \/ far.\n2. Eyes - Both eyes are facing front or near-front, with at least 1 eye \/ pupil decently clear.\n3. Face - Decently clear face, facing front or near-front.\n4. Near - Single pet taking up significant portion of photo (roughly over 50% of photo width or height).\n5. Action - Pet in the middle of an action (e.g., jumping).\n6. Accessory - Accompanying physical or digital accessory \/ prop (i.e. toy, digital sticker), excluding collar and leash.\n7. Group - More than 1 pet in the photo.\n8. Collage - Digitally-retouched photo (i.e. with digital photo frame, combination of multiple photos).\n9. Human - Human in the photo.\n10. Occlusion - Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are considered occlusion.\n11. Info - Custom-added text or labels (i.e. pet name, description).\n12. Blur - Noticeably out of focus or noisy, especially for the pet\u2019s eyes and face. For Blur entries, \u201cEyes\u201d column is always set to 0.","775aae14":"\nThe feature \"group\" shows the highest positive correlation with the dependent variable \"Pawpularity\". But overall, the features  in the dataset do not seem to give us much information about the Pawpularity.  ","24281f80":" \n### B. Relation between information given in train.csv and train images ","badecf20":"### A. Dataset structure and Features provided train.csv file ","b30c8a18":"### D. Correlation","52c16d01":" #### Here we will take random train images and their corresponding features( whose value is = 1(YES) ). "}}