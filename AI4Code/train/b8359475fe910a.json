{"cell_type":{"74a6e351":"code","56d53fee":"code","1d6289c0":"code","94927483":"code","34adb483":"code","c6a0eb2a":"code","7a3620a3":"code","9a1d570f":"code","d72bfe9e":"code","abd40c17":"code","bb53836c":"code","0c2b2483":"markdown","19c72050":"markdown","a045c096":"markdown"},"source":{"74a6e351":"#load necessary libraries\nimport pandas as pd\nimport urllib.request\nfrom bs4 import BeautifulSoup\nimport requests","56d53fee":"#URLs can be fetched using the Python module urllib.request.\n\nlink = 'https:\/\/www.mohfw.gov.in\/'\npage = urllib.request.urlopen(link)\nsoup=BeautifulSoup(page)\n#print (soup.prettify) #can be used to structure the data\n","1d6289c0":"#get the data using Request and parse it\npage = \"https:\/\/www.worldometers.info\/coronavirus\/\"\ndata = requests.get(page)\nsoup = BeautifulSoup(data.content, \"html.parser\")\n#print (soup)","94927483":"#view any required HTML tag content\nprint (\"Page title is \\n\",soup.title)\n#print (\"Tables in the page are \\n\",soup.find_all('table'))","34adb483":"#Get all links in the page\nallinks=soup.find_all(\"a\")\nfor link in allinks:\n    links=link.get(\"href\")\n   ","c6a0eb2a":"table=soup.find_all('table',class_='main_table_countries')\n","7a3620a3":"#get required content from the table\n\n# get the table head\n\nthead = soup.table.find('thead')\n#print(thead)\n\n# get all the rows in table head\nhead = thead.find_all('tr')\n#print(head)\n\n# get the table body content\n\ntbody = soup.table.find('tbody')\n#print(tbody)\n\n# get all the rows in table body\n\nbody = tbody.find_all('tr')\n#print(body)\n\n","9a1d570f":"#iterate over the table contents and store it in list\n\n# column title\nhead_column = []\n# table contents\nrowvalues = []\n\n# loop through the head and append each row to head\nfor tr in head:\n    td = tr.find_all(['th', 'td'])\n    row = [i.text for i in td]\n    head_column.append(row)\n#print(head_column)\n\n# loop through the body and append each row to body\nfor tr in body:\n    td = tr.find_all(['th', 'td'])\n    row = [i.text for i in td]\n    rowvalues.append(row)\n#print(rowvalues)","d72bfe9e":"#Store the list content in a DataFrame\n\ncovidglobal = pd.DataFrame(rowvalues,columns=head_column[0])         \n\ncovidglobal.head(15)","abd40c17":"#Cleaning the data for preprocessing\n\ncovid=covidglobal.copy()\ncovid.drop(['#','1 Caseevery X ppl','1 Deathevery X ppl','1 Testevery X ppl'], axis=1, inplace=True)\ncovid=covid[7:]\n","bb53836c":"covid=covid.reset_index()\ncovid.drop('index',axis=1,inplace=True)\ncovid.rename(columns={'Country,Other':'Country'}, inplace=True)","0c2b2483":"# # There are several ways to retrieve data from websites. Many websites such as Twitter and Facebook provides APIs for this purpose.\n# Web scraping transforms unstructured data into structured data. I will be showing you the method using the popular Python library known as BeautifulSoup as it's easy to use. You can extract various elements of the webpage such as tables, lists, and links.\n\nI will extract real-time Covid19 data from https:\/\/www.worldometers.info\/coronavirus\/. Once this data is scraped and cleaned, it can be used to build dashboard and draw insights.","19c72050":"**Now you have the data in a tabular format scraped from the website that can be used for analysing the Covid19 crisis globally. For more information on using BeautifulSoup see** https:\/\/www.crummy.com\/software\/BeautifulSoup\/bs4\/doc\/\n\nYou can also build a live dashboard using this data, refer https:\/\/www.kaggle.com\/krrai77\/create-covid-dashboard-deploy-using-dash-heroku","a045c096":"**From the webpage if you have to extract a specific table then first select the table, right click and select Inspect option (in the Chrome browser). Check the class the table belongs to as it's required to extract the data from the table.**"}}