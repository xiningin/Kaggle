{"cell_type":{"6c63453b":"code","222d9e7a":"code","1a769a3d":"code","97c6e782":"code","ab9b54b2":"code","ee81cdd1":"code","911aaf7b":"code","b28fcfc6":"code","75172a37":"code","bbba04e0":"code","d1ab4daa":"code","a20ea0f6":"code","1b7e7d80":"code","606d6b17":"code","fa1c2b89":"code","357cbdbc":"code","1fb2d62f":"code","7f575b0e":"code","7b2f8b5f":"code","478294bf":"code","e01b129d":"code","155132f6":"code","ddc891c9":"code","823dadec":"markdown","a76da731":"markdown","9f720ea2":"markdown","1e04a016":"markdown","cbc1818b":"markdown","5166596b":"markdown","964c63c6":"markdown","0a49e653":"markdown","2cc4c090":"markdown","3049813b":"markdown"},"source":{"6c63453b":"!pip install caer canaro","222d9e7a":"import os\nimport caer\nimport canaro\nimport pandas as pd\nimport numpy as np\nimport cv2 as cv\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')","1a769a3d":"# All image size\nIMAGE_SIZE = (80,80)\nchannels = 1\nchar_path = r'..\/input\/the-simpsons-characters-dataset\/simpsons_dataset'","97c6e782":"# Creating a character dictionary, sorting it in descending order\nchar_dict = {}\nfor char in os.listdir(char_path):\n    char_dict[char] = len(os.listdir(os.path.join(char_path, char)))\n\n# Sort in descending order\n\nchar_dict = caer.sort_dict(char_dict, descending=True)\n\n# print a dict\nchar_dict","ab9b54b2":"#  Getting the first 10 categories with the most number of images\ncharacters = []\ncount = 0\nfor i in char_dict:\n    characters.append(i[0])\n    count += 1\n    if count >= 10:\n        break\ncharacters","ee81cdd1":"train = caer.preprocess_from_dir(char_path, characters, channels= channels, IMG_SIZE = IMAGE_SIZE, isShuffle=True, verbose=0)","911aaf7b":"len(train) # Number of training samples","b28fcfc6":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(15,10))\nplt.imshow(train[0][0], cmap = 'gray')\nplt.show()","75172a37":"featureSet, labels = caer.sep_train(train, IMG_SIZE=IMAGE_SIZE)","bbba04e0":"from tensorflow.keras.utils import to_categorical\n\nfeatureSet = caer.normalize(featureSet)\nlabels = to_categorical(labels, len(characters))\n","d1ab4daa":"import sklearn.model_selection as skm \nX_train, X_val, y_train, y_val = skm.train_test_split(featureSet, labels, test_size=.2)","a20ea0f6":"# X_train, X_val, y_train, y_val = caer.train_val_split(np.array(item) for item in split_data)","1b7e7d80":"# Not used variable delete\ndel train\ndel featureSet\ndel labels\ngc.collect()","606d6b17":"BATCH_SIZE = 32\nEPOCHS = 10","fa1c2b89":"datagen = canaro.generators.imageDataGenerator()\ntrain_gen = datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)","357cbdbc":"model = canaro.models.createSimpsonsModel(IMG_SIZE=IMAGE_SIZE, channels=channels, output_dim=len(characters), \n                                         loss='binary_crossentropy', decay=1e-7, learning_rate=0.001, momentum=0.9,\n                                         nesterov=True)","1fb2d62f":"model.summary()","7f575b0e":"from tensorflow.keras.callbacks import LearningRateScheduler\ncallbacks_list = [LearningRateScheduler(canaro.lr_schedule)]\ntraining = model.fit(train_gen,\n                    steps_per_epoch=len(X_train)\/\/BATCH_SIZE,\n                    epochs=EPOCHS,\n                    validation_data=(X_val,y_val),\n                    validation_steps=len(y_val)\/\/BATCH_SIZE, \n                    callbacks = callbacks_list)","7b2f8b5f":"characters","478294bf":"test_path = r'..\/input\/the-simpsons-characters-dataset\/kaggle_simpson_testset\/kaggle_simpson_testset\/charles_montgomery_burns_0.jpg'\n\nimg = cv.imread(test_path)\n\nplt.imshow(img)\nplt.show()","e01b129d":"def prepare(image):\n    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n    image = cv.resize(image, IMAGE_SIZE)\n    image = caer.reshape(image, IMAGE_SIZE, 1)\n    return image","155132f6":"predictions = model.predict(prepare(img))","ddc891c9":"# Getting class with the highest probability\nprint(characters[np.argmax(predictions[0])])","823dadec":"### Training the model","a76da731":"### Separate the training set into the features and labels.","9f720ea2":"### Create our training and validation data","1e04a016":"### Visualizing the data (OpenCV doesn't display well in Jupyter notebooks)","cbc1818b":"#### Normalize the featureSet","5166596b":"## Create a Training data","964c63c6":"## Import the requirement Libraries","0a49e653":"## Testing","2cc4c090":"### Image data generator","3049813b":"### Creating the Model"}}