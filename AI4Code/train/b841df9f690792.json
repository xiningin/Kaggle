{"cell_type":{"70842e54":"code","e285486f":"code","a733066b":"code","e7df9436":"code","7c472a42":"code","68ddf6da":"code","2a910968":"code","5bbe7be9":"code","ca68a75f":"code","522287ea":"code","4316e93e":"code","b0b86c21":"code","8b0745d8":"code","c2b622d5":"code","aa920d62":"code","155229ae":"code","ab1695fa":"code","62319071":"code","7ae6a0d0":"code","945457c3":"code","f252c269":"code","4ee74fd8":"code","35c451e7":"code","a0314ccf":"code","710f6df4":"code","6d43b629":"code","d9ecfbfc":"code","93e18ec7":"code","662444c2":"code","c817146a":"code","e77194fc":"code","d42d48c1":"code","c47133f7":"code","830e94e9":"code","053d4b57":"code","0dd93d9b":"code","22b476c7":"code","995b8f7b":"markdown","fa8838ec":"markdown","5c236894":"markdown","22f90260":"markdown","02b36f9e":"markdown","5e4ebcaf":"markdown","6c11fbde":"markdown","9a0c0e18":"markdown","c612c951":"markdown","8fc06032":"markdown","09b70d60":"markdown","5b69a56f":"markdown","a256f2fb":"markdown","9064126f":"markdown","1876cd0f":"markdown","68e300d8":"markdown","8edf7a4a":"markdown","dcae3373":"markdown","63299bce":"markdown","d3d8a4e3":"markdown","70d23c54":"markdown","c92ca848":"markdown"},"source":{"70842e54":"import pandas as pd\n\n# Data path\ndata_path = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","e285486f":"train.shape, test.shape","a733066b":"train.head()","e7df9436":"test.head()","7c472a42":"submission.head()","68ddf6da":"# Extract data for each target value\nhealthy = train.loc[train['healthy']==1]\nmultiple_diseases = train.loc[train['multiple_diseases']==1]\nrust = train.loc[train['rust']==1]\nscab = train.loc[train['scab']==1]","2a910968":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nmpl.rc('font', size=15)\nplt.figure(figsize=(7, 7))\n\nlabel = ['healthy', 'multiple diseases', 'rust', 'scab'] # Target Value Value\n# Target value distribution pie chart\nplt.pie([len(healthy), len(multiple_diseases), len(rust), len(scab)], \n        labels=label, \n        autopct='%1.1f%%');","5bbe7be9":"import matplotlib.gridspec as gridspec\nimport cv2 # OpenCV Library\n\ndef show_image(img_ids, rows=4, cols=3): \n    assert len(img_ids) <= rows*cols # Raise Error if number of images exceed row\/column count\n\n    plt.figure(figsize=(15, 15)) # Set total Figure size\n    grid = gridspec.GridSpec(rows, cols) \n\n    # \uc774\ubbf8\uc9c0 \ucd9c\ub825\n    for idx, img_id in enumerate(img_ids):\n        img_path = f'{data_path}\/images\/{img_id}.jpg' # Image File Path\n        image = cv2.imread(img_path) # Read Image File\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert Image Color\n        ax = plt.subplot(grid[idx])\n        ax.imshow(image) # Print Image","ca68a75f":"# image_id for each target value (last 12)\nlast_healthy_img_ids = healthy['image_id'][-12:]\nlast_multiple_diseases_img_ids = multiple_diseases['image_id'][-12:]\nlast_rust_img_ids = rust['image_id'][-12:]\nlast_scab_img_ids = scab['image_id'][-12:]","522287ea":"show_image(last_healthy_img_ids) # Healthy Leaf Output","4316e93e":"show_image(last_multiple_diseases_img_ids) # Leaf output with various diseases","b0b86c21":"show_image(last_rust_img_ids) # Leaf Output with Rust Disease","8b0745d8":"show_image(last_scab_img_ids) # Leaves infected with Scab disease","c2b622d5":"import torch # Pytorch\nimport random\nimport numpy as np\nimport os\n\n# Fix Seed \nseed = 10\n\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","aa920d62":"# Set Device\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","155229ae":"from sklearn.model_selection import train_test_split\n\n# Split train data and valid data\n_, valid = train_test_split(train, \n                            test_size=0.1,\n                            stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n                            random_state=10)","ab1695fa":"import cv2\nfrom torch.utils.data import Dataset # Class for data generation\nimport numpy as np\n\nclass ImageDataset(Dataset):\n    # Initialization method\n    def __init__(self, df, img_dir='.\/', transform=None, is_test=False):\n        super().__init__() # Call the __init__() method of the inherited Dataset class\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n    \n    # Dataset size return method\n    def __len__(self):\n        return len(self.df)\n    \n    # Data return method corresponding to index(idx)\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0] # Image ID\n        img_path = self.img_dir + img_id + '.jpg' # Image file path\n        image = cv2.imread(img_path) # Reda Image file\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert Image color\n        # Transform Image\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        # If test data, return image data only; otherwise, return target values(label) as well.\n        if self.is_test:\n            return image\n        else:\n            # Index of the largest of the four target values\n            label = np.argmax(self.df.iloc[idx, 1:5]) \n            return image, label","62319071":"# Module for Image Transformations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Transformer for train data\ntransform_train = A.Compose([\n    A.Resize(400, 600), # Resize image\n    # \ubc1d\uae30 \ubc0f \ub300\ube44 \uc870\uc808 \n    A.RandomBrightnessContrast(brightness_limit=0.1, \n                               contrast_limit=0.1, p=0.5),\n    A.VerticalFlip(p=0.5), # Vertical Symmetric Conversion\n    A.HorizontalFlip(p=0.5), # Horizontal Symmetric Conversion\n    # shift, Scale, Rotational Transformation\n    A.ShiftScaleRotate(\n        shift_limit=0.1,\n        scale_limit=0.2,\n        rotate_limit=25, p=0.7),\n    # Embossed, sharp, blur effect\n    A.OneOf([A.Emboss(p=1),\n             A.Sharpen(p=1),\n             A.Blur(p=1)], p=0.5),\n    A.PiecewiseAffine(p=0.5), # Affine Transformation \n    A.Normalize(), # Normalize Transformation \n    ToTensorV2() # Convert to Tensor\n])\n\n# Transformer for valid and test data\ntransform_test = A.Compose([\n    A.Resize(400, 600),\n    A.Normalize(),\n    ToTensorV2()\n])","7ae6a0d0":"img_dir = '\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/'\n\ndataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\ndataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)","945457c3":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \ng = torch.Generator()\ng.manual_seed(0)","f252c269":"from torch.utils.data import DataLoader # Class for creating data loaders\n\nbatch_size = 4\n\nloader_train = DataLoader(dataset_train, batch_size=batch_size, \n                          shuffle=True, worker_init_fn=seed_worker,\n                          generator=g)\nloader_valid = DataLoader(dataset_valid, batch_size=batch_size, \n                          shuffle=False, worker_init_fn=seed_worker,\n                          generator=g)","4ee74fd8":"!pip install efficientnet-pytorch==0.7.1","35c451e7":"from efficientnet_pytorch import EfficientNet # EfficientNet Model\n\n# Load pre-trained efficientnet-b7 model\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4) \n\nmodel = model.to(device) # Assign device","a0314ccf":"import torch.nn as nn # Neural Network module\n\n# Loss function\ncriterion = nn.CrossEntropyLoss()","710f6df4":"# Optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00007, weight_decay=0.0001)","6d43b629":"from transformers import get_cosine_schedule_with_warmup\n\nepochs = 38 # Number of total epochs\n\n# Scheduler\nscheduler = get_cosine_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=len(loader_train)*5, \n                                            num_training_steps=len(loader_train)*epochs)","d9ecfbfc":"from sklearn.metrics import roc_auc_score # ROC AUC Score Calculation Function\nfrom tqdm.notebook import tqdm # Progress Bar\n\n# Training as much as epochs.\nfor epoch in range(epochs):\n    model.train() # Set Model to Training State\n    epoch_train_loss = 0 # Initialize loss values by epoch (for train data)\n    # Repeat 'Repeatation Counts' to extract data by mini-batch size\n    for images, labels in tqdm(loader_train):\n        # Assign image, label (target value) data mini-position to device\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Grad Initialization in optimizer\n        optimizer.zero_grad()\n        # Calculate output values using image data as input values for neural network models\n        outputs = model(images)\n        # Use the loss function to calculate loss of outputs and labels\n        loss = criterion(outputs, labels)\n        loss.backward() # Perform Backpropagation\n        optimizer.step() # Update Weight\n        scheduler.step() # Update Scheduler Learning Rate\n        epoch_train_loss += loss.item() # Add loss in current deployment (for training data)\n    # Print Training data loss\n    print(f'Epoch [{epoch+1}\/{epochs}] - Train data loss : {epoch_train_loss\/len(loader_train):.4f}')\n    \n    model.eval() # Set Model to Evaluation State\n    epoch_valid_loss = 0 # Initialize loss values by epoch (for valid data)\n    preds_list = [] # Initialize the list for storing predicted probability values\n    true_onehot_list = [] # Initialize the list for storing true target values\n    \n    with torch.no_grad(): # Inactivate grad calculation\n        for images, labels in loader_valid:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            epoch_valid_loss += loss.item()\n            \n            preds = torch.softmax(outputs.cpu(), dim=1).numpy() # Predicted Probability Value\n            true_onehot = torch.eye(4)[labels].cpu().numpy() # True value (in one-hot encoding format)\n            # Store predicted probability values and true values\n            preds_list.extend(preds)\n            true_onehot_list.extend(true_onehot)\n        # Print validation data loss values and ROC AUC scores\n        print(f'Epochs [{epoch+1}\/{epochs}] - Valid data loss : {epoch_valid_loss\/len(loader_valid):.4f} \/ Valid data ROC AUC : {roc_auc_score(true_onehot_list, preds_list):.4f}')  ","93e18ec7":"# Test Datasets and Data Loaders\ndataset_test = ImageDataset(test, img_dir=img_dir, \n                            transform=transform_test, is_test=True)\nloader_test = DataLoader(dataset_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g)\n\n# TTA Datasets and Data Loaders\ndataset_TTA = ImageDataset(test, img_dir=img_dir, \n                           transform=transform_train, is_test=True)\nloader_TTA = DataLoader(dataset_TTA, batch_size=batch_size, \n                        shuffle=False, worker_init_fn=seed_worker,\n                        generator=g)","662444c2":"model.eval() # Set model to evaluation state\n\npreds_test = np.zeros((len(test), 4)) # Initialize Array for Store Predicted Values\n\nwith torch.no_grad():\n    for i, images in enumerate(loader_test):\n        images = images.to(device)\n        outputs = model(images)\n        # Target Prediction Probability\n        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n        preds_test[i*batch_size:(i+1)*batch_size] += preds_part","c817146a":"submission_test = submission.copy() # Copy Submission Sample\n\nsubmission_test[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_test","e77194fc":"num_TTA = 5 # Numver of TTA\n\npreds_tta = np.zeros((len(test), 4)) # Initialize Array for Store Predicted Values (TTA)\n\n# Use TTA to predict\nfor i in range(num_TTA):\n    with torch.no_grad():\n        for i, images in enumerate(loader_TTA):\n            images = images.to(device)\n            outputs = model(images)\n            # Target Prediction Probability\n            preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n            preds_tta[i*batch_size:(i+1)*batch_size] += preds_part","d42d48c1":"preds_tta \/= num_TTA ","c47133f7":"submission_tta = submission.copy() \n\nsubmission_tta[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_tta","830e94e9":"submission_test.to_csv('submission_test.csv', index=False)\nsubmission_tta.to_csv('submission_tta.csv', index=False)","053d4b57":"def apply_label_smoothing(df, target, alpha, threshold):\n    # Copy Target Value\n    df_target = df[target].copy()\n    k = len(target) # Number of Target Value\n    \n    for idx, row in df_target.iterrows():\n        if (row > threshold).any(): # Determine if the target value is above the threshold\n            row = (1 - alpha)*row + alpha\/k # Apply Label Smoothing\n            df_target.iloc[idx] = row # Convert to Value Applied Label Smoothing\n    return df_target # Return target value with label smoothing","0dd93d9b":"alpha = 0.01 # Label Smoothing Strength\nthreshold = 0.99 # Threshold to which label smoothing applies\n\n# Copy DataFrame to apply label smoothing\nsubmission_test_ls = submission_test.copy()\nsubmission_tta_ls = submission_tta.copy()\ntarget = ['healthy', 'multiple_diseases', 'rust', 'scab'] # Target Value Column Name\n\n# Apply Label Smoothing\nsubmission_test_ls[target] = apply_label_smoothing(submission_test_ls, target, \n                                                   alpha, threshold)\nsubmission_tta_ls[target] = apply_label_smoothing(submission_tta_ls, target, \n                                                  alpha, threshold)\n\nsubmission_test_ls.to_csv('submission_test_ls.csv', index=False)\nsubmission_tta_ls.to_csv('submission_tta_ls.csv', index=False)","22b476c7":"path = '.\/' # Model Storing Path\n\ntorch.save({\n    'model': model.state_dict(),\n    'optimizer': optimizer.state_dict()\n    }, path + 'EfficientNet-B7.tar')","995b8f7b":"### Split train data and valid data","fa8838ec":"### Train and Validate an Model","5c236894":"### Loss Function, Optimizer, and Scheduler","22f90260":"### Prediction","02b36f9e":"## Data Visualization","5e4ebcaf":"### This is Top 1.9% modeling code (25 Rank). If you think it's helpful, please upvote my code \ud83d\udc40\n## Upvote Is FREE !","6c11fbde":"## Look around Data","9a0c0e18":"### Create Model","c612c951":"## Create and Train Model, Model Peformance Validation","8fc06032":"### Target Value Distribution","09b70d60":"### Define DataSet","5b69a56f":"### Create Datasets and Data Loaders","a256f2fb":"### Define Image Transformations for Data Augmentation","9064126f":"## TTA and Label Smoothing for Performance Improvements","1876cd0f":"### Print Image","68e300d8":"# 1) EDA","8edf7a4a":"## Fixe seed values and device settings","dcae3373":"# 2) Modeling","63299bce":"# Plant Pathology 2020 - FGVC7\n### Identify the category of foliar diseases in apple trees\n- [Competiton Link](https:\/\/www.kaggle.com\/c\/plant-pathology-2020-fgvc7)\n- [Modeling Reference Link](https:\/\/www.kaggle.com\/akasharidas\/plant-pathology-2020-in-pytorch)","d3d8a4e3":"## Prepare Data","70d23c54":"### Submission","c92ca848":"## Prediction and Submission"}}