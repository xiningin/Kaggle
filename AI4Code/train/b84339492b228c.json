{"cell_type":{"cc061759":"code","4018abb5":"code","2e648a09":"code","4cd00084":"code","0bf031e0":"code","6fbc98a1":"code","39872ee2":"code","d3a1d61c":"code","a8045654":"code","723b7f9f":"code","a39a9e28":"code","1c828ad8":"code","cc99217c":"code","5906a9e5":"code","230e8e0e":"markdown","40c3a397":"markdown","4385e148":"markdown","007e627c":"markdown","dce108b3":"markdown","fd988b7a":"markdown","09c6a649":"markdown","8066a918":"markdown","60e53d1b":"markdown"},"source":{"cc061759":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Dropout , Lambda, Flatten\nfrom keras.optimizers import Adam ,RMSprop\nimport keras.layers.core as core\nimport keras.layers.convolutional as conv\nimport keras.models as models\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n# one-hot-encoding convertion\nfrom keras.utils.np_utils import to_categorical \nimport keras.utils.np_utils as kutils\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.layers import BatchNormalization, Convolution2D , MaxPooling2D\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\n# Set seed\nseed = 5\nnp.random.seed(seed)","4018abb5":"#read data files into pandas dataframe\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n#does some basic data quality checking\nprint(train.shape, test.shape)\ntrain.tail()","2e648a09":"#any empty values?\n# train.isnull().sum()\ntrain.isnull().any().describe()","4cd00084":"#test.isnull().sum()\ntest.isnull().any().describe()","0bf031e0":"# ensure traing data using correct data type. \n# note: use 16bits could potentially save more GPU memory space\nX_train = (train.iloc[:,1:].values).astype('float32') \ny_train = train.iloc[:,0].values.astype('int32') \n\n# change train datset format to keras format \nX_train = X_train.reshape(-1, 28, 28,1)\n# normalize the data to grayscale to reduce effect of illumination's diffencens\nX_train = X_train \/ 255.0\nprint(X_train.shape , y_train.shape)\n\n#make same update for test data\ntest = test.values.reshape(-1, 28, 28, 1)\ntest = test.astype(float)\n# normalize the data to grayscale to reduce effect of illumination's diffencens\ntest \/= 255.0\nprint (test.shape)","6fbc98a1":"# one-hot vector for training labels classes\nfrom keras.utils.np_utils import to_categorical\ny_train= to_categorical(y_train)\nnum_classes = y_train.shape[1]\nprint (\"Number of classes: \",num_classes)","39872ee2":"# split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, y_train, test_size = 0.15, random_state=seed)\nprint (\"Shapes of train, validation dataset \")\nprint(X_train.shape , Y_train.shape)\nprint(X_val.shape , Y_val.shape)","d3a1d61c":"# view few example data\nfor i in range(1,5):\n    plt.subplot(2,2,i)\n    g = plt.imshow(X_train[i][:,:,0], cmap=plt.get_cmap('gray'))\nplt.show()","a8045654":"# adj parameters\nfilters_1 = 32 \nfilters_2 = 64 \nfilters_3 = 128 \n\n# Create model\nmodel = models.Sequential()\nmodel.add(conv.Convolution2D(filters_1, (3,3),  activation=\"relu\", input_shape=(28, 28, 1), border_mode='same'))\nmodel.add(conv.Convolution2D(filters_1, (3,3), activation=\"relu\", border_mode='same'))\nmodel.add(conv.MaxPooling2D(strides=(2,2)))\nmodel.add(conv.Convolution2D(filters_2,(3,3), activation=\"relu\", border_mode='same'))\nmodel.add(conv.Convolution2D(filters_2, (3,3), activation=\"relu\", border_mode='same'))\nmodel.add(conv.MaxPooling2D(strides=(2,2)))\nmodel.add(core.Flatten())\nmodel.add(core.Dropout(0.2))\nmodel.add(core.Dense(128, activation=\"relu\"))\nmodel.add(core.Dense(10, activation=\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nmodel.summary()","723b7f9f":"%%time\n# best practice tips\nprint (\"apply augumentation or data noisy...\")\n# apply data augmentation to create noisy on data which increase accuracy\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(X_train)\n\nprint (\"training started...\")\n# Train\nepochs = 15 \nbatch_size = 128\n# callback checkpoint\ncheckpoint = ModelCheckpoint('model-best-trained.h5', verbose=0, monitor='loss',save_best_only=True, mode='auto')  \n# callback learning rate reducer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, verbose=1, factor=0.5, min_lr=0.00001)\n# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction,checkpoint])\nprint (\"training finished!\")","a39a9e28":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)\n\nscore = model.evaluate(X_val, Y_val, verbose=0)\nprint(\"model evaluation score: %s: %.2f%%\" % (model.metrics_names[1], score[1]*100))","1c828ad8":"# Predict\nprint (\"Running prediction test....\")\npredictions = model.predict_classes(test,verbose=1)\nprint (\"done\")","cc99217c":"# save file using numpy\nnp.savetxt('digits-mnist-cnn-3.csv', np.c_[range(1,len(predictions)+1),predictions], delimiter=',', header = 'ImageId,Label', comments = '', fmt='%d')\nprint (\"saved prediction to file\")\nsub = pd.read_csv(\"digits-mnist-cnn-3.csv\")\nsub.tail(10)","5906a9e5":"# save file using data-frame\n#submission_result_file=\"digits-mnist-cnn-4.csv\"\n#submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\"Label\": predictions})\n#submissions.to_csv(submission_result_file, index=False, header=True)\n#print (\"saved prediction to file\")\n#submissions.tail(10)","230e8e0e":"![](http:\/\/)**Build a CNN model**  CNNs are extremely efficient for images and proven.\n\nthe Keras Sequential API, to add one layer at a time, starting from the input.\n First convolutional (Conv2D) layer which is a set of 32 learnable filters follow by another 64 filters for the last two layers. with Convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image, add a dropout then follow by 2 fully connected layers. \n \n  [ Convolution2D -> Convolution2D -> Max Pool --> Convolution2D--> Convolution2D --> Max Pool--> Flatten --> [DropOut] --> Dense --> Dense ]\n  \n  Note:\n  Dropout is a regularization method, where a proportion of nodes in the layer are randomly ignored (setting their wieghts to zero) for each training.\n  However, this value can not be too small, less than 20% may be get ignored or not effect. ","40c3a397":"Thanks for reading! \nWelcome any comments or suggestion.  thanks!","4385e148":"**Run Prediction**","007e627c":"### Check if any empty values exist in both train and test file","dce108b3":"![](http:\/\/)**Data Preparation**\nthis is usually the most important part of modelling, ensure the data is correct first before do any modelling work.","fd988b7a":"**Load train and test data from disk**","09c6a649":"**Train Model**","8066a918":"**Save result to file**","60e53d1b":"## Hand Writing Digit Recognition in Deep Learning\n\nThis notebook attempt to develop a hand writing image recognition solution by using deep learning - CNN framework.  \nSolving MNIST handwritten digits images to their correct label with high accuracy is the goal of this solution..\n\nThis notebook is inspired from many deep learning fans and practionairers best practices and other training materials."}}