{"cell_type":{"e5da821d":"code","a5255844":"code","ed9eb01b":"code","d35d6384":"code","2c0f4947":"code","fe263b3e":"code","eb76d19a":"code","a2a33565":"code","1c327914":"code","65a4f0c6":"code","64c81765":"code","1e4117c7":"code","3a0eadf5":"code","448c5074":"code","0a1b94e0":"code","ab41e429":"code","4e8655a7":"code","70c78d78":"markdown","c1752fa7":"markdown","940b6da9":"markdown"},"source":{"e5da821d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\nimport os","a5255844":"test_path='..\/input\/test\/'\n# Files in test folder\nlen(os.listdir(test_path))","ed9eb01b":"# Load the training set\ntrain_path='..\/input\/train.csv'\ntrain=pd.read_csv(train_path,dtype={'acoustic_data':np.int16,'time_to_failure':np.float32})","d35d6384":"train.head(10)","2c0f4947":"ad_sample=train.acoustic_data.values[::100]\nttf_sample=train.time_to_failure.values[::100]","fe263b3e":"fig,ax1=plt.subplots(figsize=(12,8))\nplt.title(\"Acoustic data and time to failure\")\nplt.plot(ad_sample,color='green')\nplt.ylabel('Acoustic data',color='green')\nplt.legend(['acoustic data'],loc=(0.01,0.95))\nax2=ax1.twinx()\nplt.plot(ttf_sample,color='blue')\nplt.ylabel('Time to Failure',color='blue')\nplt.legend(['time to failure'],loc=(0.01,0.9))\nplt.grid(True)\n\ndel ad_sample\ndel ttf_sample","eb76d19a":"ad_sample=train.acoustic_data.values[:6000000]\nttf_sample=train.time_to_failure.values[:6000000]\nfig,ax1=plt.subplots(figsize=(12,8))\nplt.title(\"Acoustic data and time to failure\")\nplt.plot(ad_sample,color='green')\nplt.ylabel('Acoustic data',color='green')\nplt.legend(['acoustic data'],loc=(0.01,0.95))\nax2=ax1.twinx()\nplt.plot(ttf_sample,color='blue')\nplt.ylabel('Time to Failure',color='blue')\nplt.legend(['time to failure'],loc=(0.01,0.9))\nplt.grid(True)\n\ndel ad_sample\ndel ttf_sample","a2a33565":"rows = 150000\nsegments = int(np.floor(train.shape[0] \/ rows))\n\nX_train = pd.DataFrame(index = range(segments),dtype = np.float32,columns = ['mean','std','99quat','50quat','25quat','1quat'])\ny_train = pd.DataFrame(index = range(segments),dtype = np.float32,columns = ['time_to_failure'])","1c327914":"for segment in tqdm(range(segments)):\n    x = train.iloc[segment*rows:segment*rows+rows]\n    y = x['time_to_failure'].values[-1]\n    x = x['acoustic_data'].values\n    X_train.loc[segment,'mean'] = np.mean(x)\n    X_train.loc[segment,'std']  = np.std(x)\n    X_train.loc[segment,'99quat'] = np.quantile(x,0.99)\n    X_train.loc[segment,'50quat'] = np.quantile(x,0.5)\n    X_train.loc[segment,'25quat'] = np.quantile(x,0.25)\n    X_train.loc[segment,'1quat'] =  np.quantile(x,0.01)\n    y_train.loc[segment,'time_to_failure'] = y\n    ","65a4f0c6":"from keras.layers import Dense\nfrom keras.models import Sequential \nfrom sklearn.preprocessing import StandardScaler\nimport gc\ngc.collect()","64c81765":"model = Sequential()\nmodel.add(Dense(32,input_shape = (6,),activation = 'relu'))\nmodel.add(Dense(32,activation = 'relu'))\nmodel.add(Dense(32,activation = 'relu'))\nmodel.add(Dense(1))\nmodel.compile(loss = 'mae',optimizer = 'adam',metrics=['accuracy'])","1e4117c7":"scaler = StandardScaler()\nX_scaler = scaler.fit_transform(X_train)\ny_train=y_train.values.flatten()","3a0eadf5":"history=model.fit(X_scaler,y_train,epochs = 100)","448c5074":"plt.plot(history.history['loss'])","0a1b94e0":"sub_data = pd.read_csv('..\/input\/sample_submission.csv',index_col = 'seg_id')\nX_test = pd.DataFrame(columns = X_train.columns,dtype = np.float32,index = sub_data.index)\n\nfor seq in tqdm(X_test.index):\n    test_data = pd.read_csv('..\/input\/test\/'+seq+'.csv')\n    x = test_data['acoustic_data'].values\n    X_test.loc[seq,'mean'] = np.mean(x)\n    X_test.loc[seq,'std']  = np.std(x)\n    X_test.loc[seq,'99quat'] = np.quantile(x,0.99)\n    X_test.loc[seq,'50quat'] = np.quantile(x,0.5)\n    X_test.loc[seq,'25quat'] = np.quantile(x,0.25)\n    X_test.loc[seq,'1quat'] =  np.quantile(x,0.01)\n    ","ab41e429":"X_test_scaler = scaler.transform(X_test)\npred = model.predict(X_test_scaler)","4e8655a7":"sub_data.to_csv('sub_earthquake.csv',index = False)","70c78d78":"# LANL Earthquake Prediction\n    \n    1. Import libs and dataset\n    2. Prepare the data\n    3. Analysis of Data\n    4. Feature Engineering\n    5. Make a Neural Network model\n    6. Fill submission file\n    \n# 1. Import Libs and dataset","c1752fa7":"# Explore the data","940b6da9":"# Visualize Acoustic- Time to Failure data"}}