{"cell_type":{"578f5f18":"code","33f50b53":"code","77f8dc22":"code","f7f85901":"code","f85213aa":"code","2438c674":"code","2ec23b08":"code","5e59ee44":"code","d3039821":"code","cd5da3bc":"code","ee7f6d1f":"code","2a5037cd":"code","ecfef4db":"code","309ca0bc":"code","b22a279a":"code","6ccedff6":"code","b3648317":"code","e91e8afd":"code","20f1f570":"code","3c2c0426":"code","35d5d077":"code","263fc424":"code","809509f4":"code","b8f5323f":"code","2fe49e60":"code","34d920e0":"code","f80005bf":"code","eed8273b":"code","2ee1d77b":"code","6657b3a6":"code","c169c222":"code","135ea0b3":"code","859a3e82":"code","7ecab582":"code","275054bb":"code","5d994e63":"code","7a9fc7c2":"code","0d198a23":"code","25428695":"code","981508ed":"code","15ae629f":"code","df7b0719":"code","bd0fb2d3":"code","05a71519":"code","2cf431ad":"code","ba210a22":"code","0f9bcee3":"code","eebbb24f":"code","ede8bb4b":"code","2dc33301":"code","e4cf6908":"code","66708cf0":"code","0e1562a7":"code","c0e72dfd":"code","25d94cf2":"code","f261c70c":"code","105e1ada":"code","1bd3f823":"code","30642126":"code","223c2d77":"code","e2cf4308":"code","71ad1dda":"code","ce428589":"code","49b8c2f2":"code","1c31b449":"code","bea0784b":"code","2725f7fc":"code","7704f294":"code","d13a8ce8":"code","aab49f45":"code","469da9e7":"code","41f20655":"code","ce8a77cf":"code","c297e1b6":"code","ce6c04b7":"code","b0d9393c":"code","8d522bcd":"code","74b1fd4e":"code","f6ccf801":"code","530cdf0b":"code","66a5a5fb":"code","5a9a2146":"code","087c2e22":"code","19e9363b":"code","a8d5c5ef":"code","6b0ec7fd":"code","a7baf36b":"code","31458fce":"code","a7d879d9":"code","2ac54624":"code","9f65981e":"code","2269f75d":"code","644595b8":"code","0d30daa8":"code","e37469c9":"code","428f2d25":"code","0e218f4b":"code","5e58586a":"code","e393b912":"code","30575ca1":"code","832933dc":"code","95131609":"code","5c29eeae":"code","f8ab0437":"code","eb87a6a3":"code","0ad2e6e9":"code","8801926c":"code","8ee90591":"code","1809a9af":"code","5c25120e":"code","29b354cc":"code","7027e79d":"code","23f347b2":"code","84c0f94f":"code","c37c2a6b":"code","3a5518ad":"code","b7bc91d8":"code","9e79b549":"code","ee613b01":"code","252c466c":"code","69961587":"code","62dcdf83":"code","a0a5d655":"code","cb0a8f12":"code","340d2465":"code","c139c1cf":"code","f331b6a4":"code","8e239b8a":"code","012045f8":"code","3e8b52b6":"code","e0d444a0":"code","a706749a":"code","80938e2e":"code","d5f45f7d":"code","c5be706c":"code","3759274e":"code","3e8e9914":"code","0926a5e8":"code","15cc140e":"code","14602a70":"code","0f6e62fd":"code","c58488c9":"code","7acf5245":"code","eb90ada5":"code","7fc48b0a":"code","ce5a9f83":"code","3e5da4df":"code","c7310b48":"code","3ec31445":"code","0c4e1aaf":"code","a2c33be7":"code","e4b4bcf0":"code","5096b575":"code","f3d6f80f":"code","1ed9798a":"code","78086c2a":"code","8bcf5548":"code","3824ced6":"code","7cd70e08":"code","8b8f2ffd":"code","df2a570f":"code","ff7d8945":"code","034cb160":"code","6e923185":"code","f5e4e1d9":"code","cdc20bb8":"code","c21fdaf1":"code","a5ca52ce":"code","ecb5abce":"code","6a91cba2":"code","854f1f1a":"code","dfc29d14":"code","ae97e2bd":"code","cfdfdcf3":"code","b07d8ed9":"code","547dcea1":"code","1ef398be":"markdown","ea966b63":"markdown","29e09ee0":"markdown","0ed33742":"markdown","0ca4af69":"markdown","2424efc5":"markdown","46b61278":"markdown","9be24599":"markdown","e40953a8":"markdown","d9401738":"markdown","8d3f42fa":"markdown","d656d99f":"markdown","3e904a8a":"markdown","d518d13e":"markdown","c5ce13d5":"markdown","c652ab1d":"markdown","2692dccf":"markdown","f7349fe1":"markdown","764195da":"markdown","4c9f5286":"markdown","cf32183f":"markdown","45dbd41d":"markdown","a06f1106":"markdown","1ffc6197":"markdown","d1cb368c":"markdown","e4e40f51":"markdown","7c169d77":"markdown","4d7fff9a":"markdown","dc09f262":"markdown","2451d67f":"markdown","80c050a4":"markdown","c29f192c":"markdown","c6ec4523":"markdown","53cdacca":"markdown","517e735b":"markdown","70a770df":"markdown","3c7fab9e":"markdown","1664465a":"markdown","bfff775d":"markdown","04b28e9c":"markdown","a7e4ec3f":"markdown","391e30a9":"markdown","c2af191d":"markdown","c1c15f17":"markdown","56e8d04b":"markdown","c278bb66":"markdown","24217a91":"markdown","593f7240":"markdown","dde5752c":"markdown","22ac89ee":"markdown","b735d516":"markdown","4432ad22":"markdown","30cfb9f6":"markdown","9bbd9444":"markdown","9af46715":"markdown","31c87a6a":"markdown","b487f4de":"markdown","db2b2aea":"markdown","393dd2a1":"markdown","fbddbd5a":"markdown","cebeaeb0":"markdown","271fbcfb":"markdown","c9e8e104":"markdown","fec1a00c":"markdown","01ca5655":"markdown","1c18c58a":"markdown","6c1113d2":"markdown","53d224bf":"markdown","6eda2298":"markdown","c819bbde":"markdown","be4b5b86":"markdown","b562ab15":"markdown","3ed3694a":"markdown","49c3b3dd":"markdown","25bed0d7":"markdown","b63106f0":"markdown","d67fcd25":"markdown","e98c068f":"markdown","c8a6f2ca":"markdown","1276471c":"markdown","2c5aaf67":"markdown","5facbd39":"markdown","146a8205":"markdown","7f2a0dfa":"markdown","ed1baeba":"markdown","68133d59":"markdown","468665e0":"markdown","fa76189a":"markdown","c9d6cd01":"markdown","518d0734":"markdown","d648cee5":"markdown"},"source":{"578f5f18":"# import 'Pandas' \nimport pandas as pd \n\n# import 'Numpy' \nimport numpy as np\n\n# import subpackage of Matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\n\n# import 'Seaborn' \nimport seaborn as sns\n\n# to suppress warnings \nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# display all columns of the dataframe\npd.options.display.max_columns = None\n\n# display all rows of the dataframe\npd.options.display.max_rows = None\n \n# to display the float values upto 6 decimal places     \npd.options.display.float_format = '{:.6f}'.format\n\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity, linear_kernel\nfrom surprise import Reader, SVD, Dataset\nfrom surprise.model_selection import cross_validate\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom kneed import KneeLocator\nfrom mlxtend.frequent_patterns import apriori,association_rules\nimport re\nimport string\nfrom apyori import apriori","33f50b53":"# installing the kneed module \n!pip install kneed","77f8dc22":"#installing the apyori module\n!pip install apyori","f7f85901":"# display all columns of the dataframe\npd.options.display.max_columns = None\n# display all rows of the dataframe\npd.options.display.max_rows = None\n# return an output value upto 6 decimals\npd.options.display.float_format = '{:.6f}'.format","f85213aa":"anime=pd.read_csv('..\/input\/anime-recommendations-database\/anime.csv')\nanime.head()","2438c674":"anime.info()","2ec23b08":"rating=pd.read_csv('..\/input\/anime-recommendations-database\/rating.csv',sep=',')\nrating.head()","5e59ee44":"rating.info()","d3039821":"anime['name'].unique()[3:10]","cd5da3bc":"def text_cleaning(text):\n    text = re.sub(r'&quot;', '', text)\n    text  = \"\".join([char for char in text if char not in string.punctuation])\n    text = re.sub(r'.hack\/\/', '', text)\n    text = re.sub(r'&#039;', '', text)\n    text = re.sub(r'A&#039;s', '', text)\n    text = re.sub(r'I&#039;', 'I\\'', text)\n    text = re.sub(r'&amp;', 'and', text)\n    text = re.sub(r'\u00c2\u00b0', '',text)\n    \n    return text\n\nanime['name'] = anime['name'].apply(text_cleaning)","ee7f6d1f":"anime['name'] = anime['name'].apply(text_cleaning)","2a5037cd":"anime['name'].unique()[3:10]","ecfef4db":"anime.episodes.unique()","309ca0bc":"anime.episodes.replace({'Unknown':np.nan},inplace=True)","b22a279a":"anime_rating=pd.merge(anime,rating,on='anime_id')\nanime_rating.head()","6ccedff6":"anime_rating.rename(columns={'rating_x':'avg_rating','rating_y':'user_rating'},inplace=True)\nanime_rating.head()","b3648317":"anime_rating.info()","e91e8afd":"anime.shape","20f1f570":"rating.shape","3c2c0426":"anime_rating.shape","35d5d077":"anime_rating.dtypes","263fc424":"anime_rating['anime_id']=anime_rating.anime_id.astype('object')\nanime_rating['user_id']=anime_rating.user_id.astype('object')","809509f4":"anime_rating.dtypes","b8f5323f":"missing_value = pd.DataFrame({\n    'Missing Value': anime_rating.isnull().sum(),\n    'Percentage': (anime_rating.isnull().sum() \/ len(anime_rating))*100\n})","2fe49e60":"missing_value.sort_values(by='Percentage', ascending=False)","34d920e0":"anime.isnull().sum()","f80005bf":"# I can't replace the nan values with mean or median as it's unique for each movie\n# So I will drop the null values rows\nanime_rating.dropna(inplace=True)\nanime.dropna(inplace=True)","eed8273b":"anime_rating.isnull().sum()","2ee1d77b":"anime.isnull().sum()","6657b3a6":"duplicate = anime_rating.duplicated(subset=['anime_id','user_id']).sum()\nprint('There are {} duplicated rows in the data'.format(duplicate))","c169c222":"duplicate = anime.duplicated().sum()\nprint('There are {} duplicated rows in the data'.format(duplicate))","135ea0b3":"anime_rating.drop_duplicates(subset=['anime_id','user_id'],inplace=True)","859a3e82":"duplicate = anime_rating.duplicated().sum()\nprint('There are {} duplicated rows in the data'.format(duplicate))","7ecab582":"anime_rating.shape","275054bb":"anime_rating.tail()","5d994e63":"anime_rating.reset_index(drop=True,inplace=True)\nanime_rating.tail()","7a9fc7c2":"anime_rating.shape","0d198a23":"anime_rating.head()","25428695":"anime_rating.describe()","981508ed":"anime_rating[anime_rating.user_rating==-1].shape","15ae629f":"anime_rating.user_rating.replace({-1:np.nan},inplace=True)","df7b0719":"anime_rating.isnull().sum()","bd0fb2d3":"anime_rating.dropna(inplace=True)","05a71519":"anime_rating.isnull().sum()","2cf431ad":"anime_rating.shape","ba210a22":"anime_rating.describe()","0f9bcee3":"anime_rating.describe(include='object')","eebbb24f":"corr_matrix=anime_rating.corr()\ncorr_matrix","ede8bb4b":"plt.figure(figsize=(11,9))\nsns.heatmap(corr_matrix, cmap='Purples', annot=True, fmt=\".2f\")\nsns.set(font_scale=1.5)","2dc33301":"nonull_anime=anime_rating.copy()\nnonull_anime.dropna(inplace=True)\nfrom collections import defaultdict\n\nall_genres = defaultdict(int)\n\nfor genres in nonull_anime['genre']:\n    for genre in genres.split(','):\n        all_genres[genre.strip()] += 1","e4cf6908":"plt.figure(figsize=(15,10))\n        \nfrom wordcloud import WordCloud\n\ngenres_cloud = WordCloud(width=800, height=400, background_color='white', colormap='gnuplot').generate_from_frequencies(all_genres)\nplt.imshow(genres_cloud, interpolation='bilinear')\nplt.axis('off')","66708cf0":"anime_rating_count = anime_rating.groupby(by = ['name'])['user_rating'].count().reset_index()[['name', 'user_rating']]\nanime_rating_count.rename(columns = {'user_rating': 'totalRatingCount'},inplace=True)\nanime_rating_count.head()","0e1562a7":"top10_animerating=anime_rating_count[['name', 'totalRatingCount']].sort_values(by = 'totalRatingCount',ascending = False).head(10)\nplt.figure(figsize=(15,5))\nax=sns.barplot(x=\"name\", y=\"totalRatingCount\", data=top10_animerating, palette=\"Dark2\")\nax.set_xticklabels(ax.get_xticklabels(), fontsize=11, rotation=40, ha=\"right\")\nax.set_title('Top 10 Anime based on rating counts',fontsize = 22)\nax.set_xlabel('Anime',fontsize = 20) \nax.set_ylabel('User Rating count', fontsize = 20)","c0e72dfd":"anime_rating_data=anime_rating.merge(anime_rating_count, left_on = 'name', right_on = 'name', how = 'left')\nanime_rating_data.head()","25d94cf2":"anime_rating_data.duplicated(subset=['name']).sum()","f261c70c":"anime1=anime_rating_data.drop_duplicates(subset=['name'])\nanime1.head()","105e1ada":"top10_animemembers=anime1[['name', 'members']].sort_values(by = 'members',ascending = False).head(10)\nplt.figure(figsize=(15,5))\nax=sns.barplot(x=\"name\", y=\"members\", data=top10_animemembers, palette=\"gnuplot2\")\nax.set_xticklabels(ax.get_xticklabels(), fontsize=11, rotation=40, ha=\"right\")\nax.set_title('Top 10 Anime based on members',fontsize = 22)\nax.set_xlabel('Anime',fontsize = 20) \nax.set_ylabel('Community Size', fontsize = 20)","1bd3f823":"plt.figure(figsize = (15, 7))\nplt.subplot(1,2,1)\nanime_rating['avg_rating'].hist(bins=70)\nplt.title(\"Rating of Ibsites\")\nplt.subplot(1,2,2)\nanime_rating['user_rating'].hist(bins=70)\nplt.title(\"Rating of users\")","30642126":"labels = anime_rating['type'].value_counts().index\nvalues = anime_rating['type'].value_counts().values\nplt.figure(figsize=(15,10))\nplt.pie(x=values,labels=labels,autopct='%.1f',colors=['lightblue','lightgreen','lightgrey','#FF6361','Cornsilk','#BC5090'])\nplt.legend()\nplt.show()","223c2d77":"d1=pd.DataFrame(list(dict(all_genres).keys()),columns=['Genre'])","e2cf4308":"d2=pd.DataFrame(list(dict(all_genres).values()),columns=['count'])","71ad1dda":"all_genres1=pd.concat(objs=(d1,d2),axis=1)\nall_genres1.head()","ce428589":"all_genres1=all_genres1.sort_values(by='count',ascending=False)\nplt.figure(figsize=(15,15))\nsns.barplot(all_genres1['count'],all_genres1['Genre'])","49b8c2f2":"anime.head()","1c31b449":"genres = anime['genre'].str.split(',', expand=True)\ngenres.head()","bea0784b":"# considering only first four genres columns \ngenres = genres.iloc[:,:4]\ngenres.columns = ['genre1', 'genre2', 'genre3','genre4']\ngenres.head()","2725f7fc":"updated_rating=anime.copy()","7704f294":"updated_rating = updated_rating.drop('genre', axis=1) \nupdated_rating = pd.concat([updated_rating, genres], axis=1)\nupdated_rating.head()","d13a8ce8":"updated_rating['type'].unique()","aab49f45":"updated_rating.episodes=updated_rating.episodes.astype('int')","469da9e7":"df_cat = updated_rating.select_dtypes(np.object)\ndf_num = updated_rating.select_dtypes(np.number)","41f20655":"df_dum = pd.get_dummies(df_cat[['type','genre1','genre2','genre3','genre4']])\ndf_dum.head()","ce8a77cf":"df_num.head()","c297e1b6":"df_num.set_index('anime_id',inplace=True)\ndf_num.head()","ce6c04b7":"from sklearn.preprocessing import StandardScaler\nss=StandardScaler()\ndf_num\ndf_scale = pd.DataFrame(ss.fit_transform(df_num),columns=df_num.columns)\ndf_scale.head()","b0d9393c":"df_dum.reset_index(drop=True,inplace=True)","8d522bcd":"full_df = pd.concat([df_scale,df_dum],axis=1)\nfull_df.head()","74b1fd4e":"full_df.shape","f6ccf801":"ssd = []\nsscore = []\nfor k in range(2, 10):\n    kmeans = KMeans(n_clusters=k, random_state=4)\n    kmeans.fit(full_df)\n    ssd.append(kmeans.inertia_)\n    ss = silhouette_score(full_df, kmeans.labels_)\n    print (\"For {} clusters the silhouette score is {})\".format(k, ss))\n    sscore.append(ss)","530cdf0b":"fig, ax = plt.subplots()\nax.plot(range(2,10), ssd, 'r')\nax.set_xlabel('No. Clusters')\nax.set_ylabel('SSD')","66a5a5fb":"new_clusters = KMeans(n_clusters = 4, random_state = 10)\n\nnew_clusters.fit(full_df)\n\nupdated_rating['Cluster'] = new_clusters.labels_\nupdated_rating.head()","5a9a2146":"updated_rating.Cluster.value_counts()","087c2e22":"sns.countplot(data= updated_rating, x = 'Cluster')\nplt.title('Size of Cluster', fontsize = 15)\nplt.xlabel('Clusters', fontsize = 15)\nplt.ylabel('Number of Animes', fontsize = 15)\nplt.show()","19e9363b":"# plot the lmplot to visualize the clusters\n# pass the different markers to display the points in each cluster with different shapes\n# the 'hue' parameter returns colors for each cluster\nsns.lmplot(x = 'rating', y = 'members', data = updated_rating, hue = 'Cluster', fit_reg = False, size = 5)\n\n# set the axes and plot labels\n# set the font size using 'fontsize'\nplt.title('K-means Clustering (for K=4)', fontsize = 15)\nplt.ylabel('Community Size', fontsize = 15)\nplt.xlabel('Rating', fontsize = 15)\n\n# display the plot\nplt.show()","a8d5c5ef":"anime_rating.shape","6b0ec7fd":"# Considering first 5000 users\nsel_data= anime_rating[anime_rating.user_id <= 5000]\nsel_data.head()","a7baf36b":"sel_data.shape","31458fce":"# calculating the frequency based on the user id and anime names\nuser_anime = pd.crosstab(sel_data['user_id'], sel_data['name'])\nuser_anime.head()","a7d879d9":"user_anime.shape","2ac54624":"# initially considering 2000 components\npca = PCA(n_components=2000)\npca.fit(user_anime)","9f65981e":"#visualizing PCA components with cumulative scree plot\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.show()","2269f75d":"pca = PCA(n_components=1500)\npca.fit(user_anime)\n\npca_samples = pca.transform(user_anime)","644595b8":"np.cumsum(pca.explained_variance_ratio_)","0d30daa8":"ps = pd.DataFrame(pca_samples)\nps.head()","e37469c9":"ssd = []\nsscore = []\nfor k in range(2, 10):\n    kmeans = KMeans(n_clusters=k, random_state=4)\n    kmeans.fit(ps)\n    ssd.append(kmeans.inertia_)\n    ss = silhouette_score(ps, kmeans.labels_)\n    sscore.append(ss)","428f2d25":"fig, ax = plt.subplots(figsize=(15,5))\nax.plot(range(2,10), ssd, 'r')\nax.set_xlabel('No. Clusters')\nax.set_ylabel('SSD')","0e218f4b":"new_clusters = KMeans(n_clusters = 3, random_state = 4)\n\n# fit the model\nnew_clusters.fit(ps)\n\n# append the cluster label for each point in the dataframe 'df_cust'\nuser_anime['Cluster'] = new_clusters.labels_","5e58586a":"user_anime.head()","e393b912":"user_anime.Cluster.value_counts()","30575ca1":"# describing cluster 0\ncluster0 = user_anime[user_anime['Cluster']==0].drop('Cluster',axis=1).mean()","832933dc":"cluster0.sort_values(ascending=False)[0:15]","95131609":"# describe cluster 1\ncluster1 = user_anime[user_anime['Cluster']==1].drop('Cluster',axis=1).mean()","5c29eeae":"cluster1.sort_values(ascending=False)[0:15]","f8ab0437":"def cluster_plot(data, nclusters):\n    import matplotlib.pyplot as plt\n    from sklearn.cluster import KMeans\n    X = data.copy()\n\n    km = KMeans(n_clusters=nclusters, init='random', n_init=10, max_iter=300, tol=1e-04, random_state=0)\n    y_km = km.fit_predict(X)\n\n\n    # Visualize it:\n    plt.figure(figsize=(8, 6))\n    plt.scatter(X.iloc[:,0], X.iloc[:,1], c=km.labels_.astype(float))\n\n    # plot the centroids\n    plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], s=250, marker='*', c='red', label='centroids')\n    plt.legend(scatterpoints=1)\n    plt.grid()\n    plt.show()","eb87a6a3":"cluster_plot(ps, 3)","0ad2e6e9":"anime_rating_data.head()","8801926c":"rating1=anime_rating_data[['anime_id','name','genre','avg_rating','totalRatingCount']]\nrating1.drop_duplicates(subset=['anime_id'],inplace=True)\nrating1.reset_index(drop=True,inplace=True)","8ee90591":"rating1.shape","1809a9af":"# mean rating across all the animes\nC = rating1['avg_rating'].mean()\n# animes having total rate count greater than 85%\nm = rating1['totalRatingCount'].quantile(0.85)\nprint('m: ', m, 'C: ', C)","5c25120e":"def Iighted_rating(x, m=m, C=C):\n    v = x['totalRatingCount']\n    R = x['avg_rating']\n    return (v\/(v+m) * R) + (m\/(m+v) * C)","29b354cc":"# animes having total rate count greater than 85% is considered into lists_animes\nlists_animes =rating1.copy().loc[rating1['totalRatingCount'] >= m]\nlists_animes.shape","7027e79d":"# Define a new feature 'score' and calculate its value with `Iighted_rating()`\nlists_animes['score'] = lists_animes.apply(Iighted_rating, axis=1)","23f347b2":"lists_animes.head()","84c0f94f":"#Sort movies based on score calculated above\nlists_animes = lists_animes.sort_values('score', ascending=False)\n\n#Print the top 10 movies\nlists_animes[['name', 'totalRatingCount', 'avg_rating', 'score']].head(10)","c37c2a6b":"pop=lists_animes[['name', 'totalRatingCount', 'avg_rating', 'score']].head(10)\nplt.figure(figsize=(15,10))\nsns.barplot(pop['score'],pop['name'])\nplt.title('Anime')\nplt.xlabel('Popularity Score')\nplt.show()","3a5518ad":"data=anime.copy()\n# considering the anime content\ndata['describe']=data['genre']+data['type']+data['episodes']\ndata['describe'].fillna(' ')\ndata.head()","b7bc91d8":"data.drop_duplicates(subset=['name'],inplace=True)","9e79b549":"data.shape","ee613b01":"data.reset_index(drop=True,inplace=True)","252c466c":"tf = TfidfVectorizer(ngram_range=(1,2), stop_words='english')\ntf_matrix = tf.fit_transform(data['describe'])\ntf_matrix.shape","69961587":"simil = linear_kernel(tf_matrix, tf_matrix)\nsimil.shape","62dcdf83":"id=data['anime_id'].values\nsimil = pd.DataFrame(simil, index=id, columns=id)\nsimil.columns = data['name']\nsimil['anime_name'] = data['name'].values","a0a5d655":"simil.head()","cb0a8f12":"if([simil.anime_name.value_counts()>1]==True):\n    print('There are duplicates rows')\nelse:\n    print('There are no duplicate rows')","340d2465":"# user defined function to recommend animes based on genre and type\ndef content_rec(name):\n    idx = simil[simil['anime_name']==name]\n    idx = idx.drop('anime_name', axis=1).T\n    idx.columns = ['similar_val']\n    idx = idx.sort_values(by='similar_val', ascending=False)\n    return idx","c139c1cf":"content_rec('Kimi no Na wa').head(10)","f331b6a4":"anime_rating.shape","8e239b8a":"anime_rating.duplicated(subset=['user_id','name']).sum()","012045f8":"anime_rating1=anime_rating.copy()\nanime_rating1.drop_duplicates(subset=['user_id','name'],inplace=True)","3e8b52b6":"anime_rating1.reset_index(drop=True,inplace=True)","e0d444a0":"counts = anime_rating1['user_id'].value_counts()\nanime_feature = anime_rating1[anime_rating1['user_id'].isin(counts[counts >= 500].index)]","a706749a":"anime_feature.shape","80938e2e":"# user-item matrix\nanime_rating_pivot = anime_feature.pivot(index='name', columns='user_id', values='user_rating')\nanime_rating_pivot = anime_rating_pivot.fillna(0)\nanime_rating_pivot.head()","d5f45f7d":"anime_rating_pivot.shape","c5be706c":"model_knn = NearestNeighbors(metric='cosine')\nmodel_knn.fit(anime_rating_pivot)","3759274e":"distances, indices = model_knn.kneighbors(anime_rating_pivot, n_neighbors=6)","3e8e9914":"recommend = pd.DataFrame(indices, columns=['anime0', 'anime1', 'anime2', 'anime3', 'anime4', 'anime5'])\nrecommend.head()","0926a5e8":"recommend2 = recommend.copy()\nfor i in range(0, 6):\n    animes = pd.DataFrame(anime_rating_pivot.index).reset_index()\n    animes = animes.rename(columns={'index':f'anime{i}'})\n    recommend2 = pd.merge(recommend2, animes, on=[f'anime{i}'], how='left')\n    recommend2 = recommend2.drop(f'anime{i}', axis=1)\n    recommend2 = recommend2.rename(columns={'name':f'anime{i}'})","15cc140e":"recommend2.head(10)","14602a70":"anime_rating_pivot.shape","0f6e62fd":"#initially I will consider 1300 components\nsvd = TruncatedSVD(random_state=4, n_components=1300)\nsvd.fit(anime_rating_pivot)","c58488c9":"#visualizing svd components with cumulative scree plot \nplt.plot(np.cumsum(svd.explained_variance_ratio_))\nplt.show()","7acf5245":"# Now I will consider only 1000 components\nsvd = TruncatedSVD(random_state=4, n_components=1000)\nsvd.fit(anime_rating_pivot)","eb90ada5":"anime_rating_svd = svd.fit_transform(anime_rating_pivot)","7fc48b0a":"anime_rating_svd.shape","ce5a9f83":"corr = np.corrcoef(anime_rating_svd)\ncorr.shape","3e5da4df":"corr","c7310b48":"anime_title = anime_rating_pivot.index\nanime_list = list(anime_title)\n\nanime_Vampire_Knight = anime_list.index('Vampire Knight')\nanime_Vampire_Knight","3ec31445":"corr_anime_Vampire_Knight = corr[anime_Vampire_Knight]","0c4e1aaf":"anime_title[(corr_anime_Vampire_Knight)>0.65]","a2c33be7":"anime_rating_data.head()","e4b4bcf0":"counts = anime_rating_data['user_id'].value_counts()\n# considering only users who have watched more than 1500 animes\nanime_feature1 = anime_rating_data[anime_rating_data['user_id'].isin(counts[counts >= 1500].index)]","5096b575":"anime_feature1.shape","f3d6f80f":"anime_feature1.user_rating.value_counts()","1ed9798a":"reader = Reader(rating_scale=(1.0,10.0))\ndata1 = Dataset.load_from_df(anime_feature[['user_id', 'name', 'user_rating']], reader)","78086c2a":"svd = SVD()\ncross_validate(svd, data1, measures=['rmse'], cv=3, return_train_measures=True)","8bcf5548":"trainset = data1.build_full_trainset()\nsvd.fit(trainset)","3824ced6":"items = anime_feature['name'].unique()\ntest = [[13954.0, iid, 8] for iid in items]\npredictions = svd.test(test)\npred = pd.DataFrame(predictions)","7cd70e08":"pred.sort_values(by='est', ascending=False).head(10)","8b8f2ffd":"md2 = anime[['anime_id', 'name']]","df2a570f":"simil.head(2)","ff7d8945":"# pre defined function to predict the user rating of similar animes where I pass the anime name along with the user id as parameters\ndef hybrid_rec(ttl, userid):\n    idx = simil[simil['anime_name']==ttl]\n    idx = idx.drop('anime_name', axis=1).T\n    idx.columns = ['values']\n    idx['id'] = simil.index\n    # considering only top 25 similar animes\n    idx = idx.sort_values(by='values', ascending=False).head(25)\n    items = idx['id'].unique()\n    test = [[userid, iid, 8] for iid in items]\n    predictions = svd.test(test)\n    pred = pd.DataFrame(predictions)\n    pred = pred.merge(md2, left_on='iid', right_on='anime_id')\n    pred = pred.sort_values(by='est', ascending=False)\n    return pred","034cb160":"hybrid_rec('Death Note',13954.0)","6e923185":"anime.head()","f5e4e1d9":"rating.head()","cdc20bb8":"def get_ar_type(type):\n    type_ul=[]\n    grouped = rating.groupby(\"user_id\")\n    set_type = set(anime[anime[\"type\"] == type][\"anime_id\"].values)\n    print(type+' :',len(set_type))\n    \n    \n    for i in rating['user_id'].unique():\n        g = grouped.get_group(i)\n        r = g[g['rating']>=6]\n        set_trans = set(r['anime_id'].values)\n        anime_type = list(set_type.intersection(set_trans)) \n        if len(anime_type)>1:\n            type_ul.append(anime_type)\n            \n            \n    association_rules = apriori(type_ul, min_support=0.15, min_confidence=0.4,min_lift=1)\n    association_results = list(association_rules)\n    \n    \n    Result=pd.DataFrame(columns=['Antecedents','Consequents','Support','Confidence','Lift'])\n    for item in association_results:\n        pair = item[2]\n        for i in pair:\n            items = str([x for x in i[0]])\n            if i[3]!=1:\n                Result=Result.append({'Antecedents':str([anime[anime['anime_id']==x].reset_index().loc[0,'name'] for x in i[0]]),'Consequents':str([anime[anime['anime_id']==x].reset_index().loc[0,'name'] for x in i[1]]),'Support':item[1],'Confidence':i[2],'Lift':i[3]},ignore_index=True)\n    Result_ar=Result.sort_values(by='Lift',ascending=False)\n    Result_ar=Result_ar.reset_index(drop=True)\n    return Result_ar","c21fdaf1":"get_ar_type('Movie').head(10)","a5ca52ce":"Result_tv=get_ar_type('TV')","ecb5abce":"def find_anime_ar(name,result):\n    temp=result.copy()\n    temp['Antecedents']=temp['Antecedents'].apply(lambda x:x if name in x else 'different')\n    temp=temp[temp['Antecedents']!='different']\n    temp=temp.reset_index(drop=True)\n    return temp   ","6a91cba2":"find_anime_ar('Death Note',Result_tv).head(10)","854f1f1a":"anime.reset_index(drop=True,inplace=True)","dfc29d14":"def get_ar_genre(genre):\n    genre_ul=[]\n    set_genre=set()\n    for i in range(len(anime)):\n        str_genre = anime.loc[i, 'genre']\n        if pd.isnull(str_genre):\n            continue\n        A = str_genre.strip().split(\", \")\n        for j in A:\n            if j==genre:\n                set_genre.add(anime.loc[i,\"anime_id\"])\n    \n    \n    grouped = rating.groupby(\"user_id\")\n    print(genre+' :',len(set_genre))\n    \n    for i in rating['user_id'].unique():\n        g = grouped.get_group(i)\n        r = g[g['rating']>=6]\n        set_trans = set(r['anime_id'].values)\n        anime_genre = list(set_genre.intersection(set_trans)) \n        if len(anime_genre)>1:\n            genre_ul.append(anime_genre)\n            \n            \n    association_rules = apriori(genre_ul, min_support=0.15, min_confidence=0.5,min_lift=1)\n    association_results = list(association_rules)\n    \n    \n    Result=pd.DataFrame(columns=['Antecedents','Consequents','Support','Confidence','Lift'])\n    for item in association_results:\n        pair = item[2]\n        for i in pair:\n            items = str([x for x in i[0]])\n            if i[3]!=1:\n                Result=Result.append({'Antecedents':str([anime[anime['anime_id']==x].reset_index().loc[0,'name'] for x in i[0]]),'Consequents':str([anime[anime['anime_id']==x].reset_index().loc[0,'name'] for x in i[1]]),'Support':item[1],'Confidence':i[2],'Lift':i[3]},ignore_index=True)\n    Result_ar=Result.sort_values(by='Lift',ascending=False)\n    Result_ar=Result_ar.reset_index(drop=True)\n    return Result_ar","ae97e2bd":"get_ar_genre('Comedy').head(10)","cfdfdcf3":"result_action=get_ar_genre('Action')","b07d8ed9":"result_action.head()","547dcea1":"find_anime_ar('Fullmetal Alchemist',result_action).head(10)","1ef398be":"### 4.1.1 Data Cleaning <a id='data_cleaning'><\/a>","ea966b63":"#### 8.5.2 By Genre <a id='genre'><\/a>","29e09ee0":"### 8.3.2 Model based Recommendation System(Surprise) <a id='model'><\/a>","0ed33742":"This are top 25 animes similar to the `Death Note` and the estimated rating that the user `13954` will allocate.","0ca4af69":"## 8.3 Collaberative filtering Recommendation System <a id='collab'><\/a>","2424efc5":"# Data Dictionary","46b61278":"**Percentage of users in each type**","9be24599":"**Interpretation:**\n\n1. The minimum avg_rating is 2 and the maximum avg_rating is 9.37.\n\n2. The number of members ranges from 33 to 1013917.\n\n3. Users rating ranges from 1 to 10.","e40953a8":"From the above graph I can see that the svd component 1000 it's variance is almost 1.","d9401738":"As for Rule 4 : If a user has Watched and liked `Fullmetal Alchemist` there is `59%` confidence with `0.2` support he\/she will like `Fullmetal Alchemist  Brotherhood`<br>\nAs for Rule 9 : If a user has Watched and liked `Fullmetal Alchemist Brotherhood` there is `60%` confidence with `0.21` support he\/she will like `Shingeki no Kyojin`","8d3f42fa":"#### 8.3.1.1 Using KNN<a id='knn'><\/a>","d656d99f":"**Categorical Variables**","3e904a8a":"From the above graph I can infer that for K = 4, there is an elbow in the plot. \nBefore this elbow point, the SSD is decreasing rapidly and after K = 4, the SSD is decreasing slowly.","d518d13e":"**Getting rid of duplicate data**","c5ce13d5":"<table align=\"center\" width=100%>\n    <tr>\n        <td width=\"40%\">\n            <img src=\"https:\/\/image.pushauction.com\/0\/0\/3f22d1bc-e8c2-4e47-8b47-88d74d8e4f4c\/cf170397-633b-4c85-baa8-87dca110cd46.jpg\">\n        <\/td>\n        <td>\n            <div align=\"center\">\n                <font color=\"black\";size=500px>\n                    <b>ANIME RECOMMENDATION SYSTEM\n                    <\/b>\n                <\/font>\n            <\/div>\n        <\/td>\n    <\/tr>\n<\/table>","c652ab1d":"There are few missing values in `genre`,`episodes`,`avg_rating` and `type`.","2692dccf":"### 8.5 Association analysis<a id='asso'><\/a>","f7349fe1":"## 8.1 Popularity Based recommendation system <a id='pop'><\/a>","764195da":"# 6.Clustering <a id='clust'><\/a>","4c9f5286":"The above output recommend the similar animes which is almost same genre and type.","cf32183f":"As for Rule 0 : If a user has Watched and liked `Code Geass 1st season` and `Death Note` there is `87.7%` confidence with `0.235` support he\/she will like `Code Geass 2nd season`<br>\nAs for Rule 5 : If a user has Watched and liked `Shingeki no Kyojin` and `Death Note` there is `68%` confidence with `0.17` support he\/she will like `Sword Art Online`","45dbd41d":"### 4.1.9 Final Dataset <a id='final_dataset'><\/a>","a06f1106":"## Table of Contents\n\n1. *[Import Libraries](#import_lib)*\n2. *[Set Options](#set_options)*\n3. *[Read Data](#Read_Data)*\n4. *[Exploratory Data Analysis](#data_preparation)*\n    - 4.1 - [Preparing the Dataset](#Data_Preparing)\n        - 4.1.1 - [Merging datasets](#merging)\n        - 4.1.2 - [Data  Info](#info)\n        - 4.1.3 - [Data Dimension](#Data_Shape)\n        - 4.1.4 - [Data Types](#Data_Types)\n        - 4.1.5 - [Missing Values](#Missing_Values)\n        - 4.1.6 - [Duplicate Data](#duplicate)\n        - 4.1.7 - [Indexing](#index)\n        - 4.1.8 - [Data Cleaning](#data_clean)\n        - 4.1.9 - [Final Dataset](#final_dataset)\n    - 4.2 - [Understanding the Dataset](#Data_Understanding)\n        - 4.2.1 - [Summary Statistics](#Summary_Statistics)\n        - 4.2.2 - [Correlation](#correlation)\n        - 4.2.3 - [Analyze Features](#analyze_cat_var)\n5. *[Data Preprocesing](#data_pre)*\n    - 5.1 - [Categroical Encoding](#cat)\n    - 5.2 - [Feature Scaling](#feat_scaling)\n6. *[Clustering](#clust)*\n7. *[Dimensionality Reduction](#dim_red)*\n    - 7.1 - [PCA(Prinicipal Component analysis)](#pca)\n    - 7.2 - [Clustering after dimension reduction](#apply)\n8. *[Recommendations systems](#rec_sys)*\n    - 8.1 - [Popularity Based](#pop)\n    - 8.2 - [Content Based](#content)\n    - 8.3 - [Collaborative Based](#collab)\n        - 8.3.1 - [Memory Based](#memory)\n            - 8.3.1.1 - [Using KNN](#knn)\n            - 8.3.1.2 - [Using SVD](#svd)\n        - 8.3.2 - [Model Based](#model)\n    - 8.4 - [Hybrid Based](#hybrid)\n    - 8.5 - [Association Analysis](#asso)\n        - 8.5.1 - [By Type](#type)\n        - 8.5.2 - [By Genre](#genre)\n9. *[Conclusion](#conclu)*\n10. *[References](#ref)*","1ffc6197":"https:\/\/www.researchgate.net\/publication\/342690182_Collaborative_Recommendation_System_in_Users_of_Anime_Films\n\nhttps:\/\/iopscience.iop.org\/article\/10.1088\/1742-6596\/1566\/1\/012057\/pdf\n\nhttps:\/\/towardsdatascience.com\/building-a-recommendation-system-for-anime-566f864acea8\n\nhttps:\/\/arxiv.org\/pdf\/1709.01584.pdf\n\nhttps:\/\/medium.com\/analytics-vidhya\/anime-recommendation-engine-content-collaborative-filtering-c6e69be29d29","d1cb368c":"## 4.2 Understanding the Dataset <a id='Data_Understanding'><\/a>","e4e40f51":"### 4.1.6 Duplicate Data <a id='duplicate'><\/a>","7c169d77":"# 1. Import Libraries <a id='import_lib'><\/a>","4d7fff9a":"Now, There are no null values in the dataset.","dc09f262":"**Missing Values treatment**","2451d67f":"**Top 10 animes based on community size**","80c050a4":"- Recommender systems open new opportunities of retrieving personalized information on the Ib.I have built various       recommender models each one performs Ill under circumstances.\n\n- For a new user popularity based and content based recommender works Ill later based on user activities collaborative based and association recommenders performs better.\n\n- A  better  anime  recommendation  system is when I consider user  watch  history.So collaborative based filtering (model-based) recommendation model would be best for recommend animes to the users.","c29f192c":"# 5. Data Preprocessing <a id='data_pre'><\/a>","c6ec4523":"# 8. Recommendation system <a id='rec_sys'><\/a>","53cdacca":"**Inferences:**\n\nMembers and avg_rating have a positive relationship.i.e. **0.54**. Because as the number of members increase avg rating of the anime will also increase.\n\nThere is no Strong relationship betIen any attributes. ","517e735b":"In this dataset I have 7813737 records across 3 features","70a770df":"### 8.4 Hybrid Recommendation System <a id='hybrid'><\/a>","3c7fab9e":"## 4.1 Preparing the Dataset <a id='Data_Preparing'><\/a>","1664465a":"There are few missing values in `genre`,`episodes`,`avg_rating` and `type`.","bfff775d":"Users can spend most of the hours scrolling through hundreds, sometimes thousands of anime\u2019s never finding an content they like. Our objective is to build recommendation systems which recommend anime's considering or based on their likes and needs in order to create a better streaming environment that boosts revenue and increases the time spent on a Ibsite. ","04b28e9c":"### 4.1.3 Data Dimensions <a id='Data_Shape'><\/a>","a7e4ec3f":"## 5.2 Feature Scaling<a id='feat_scaling'><\/a>","391e30a9":"### 4.1.5 Missing Values <a id='Missing_Values'><\/a>","c2af191d":"In this dataset I have 7813727 records across 3 features","c1c15f17":"# 3. Read Data <a id='Read_Data'><\/a>","56e8d04b":"## 5.1 Categorical Encoding<a id='cat'><\/a>","c278bb66":"### 4.2.3 Analyse Features <a id='analyze_cat_var'><\/a>","24217a91":"The final dataset has **7813604 records and 9 features with no missing and duplicate values**","593f7240":"### 4.1.7 Indexing <a id='index'><\/a>","dde5752c":"### 4.1.4 Data Types <a id='Data_Types'><\/a>","22ac89ee":"### 8.3.1 Memory based Recommendation System (Similar anime)<a id='mem'><\/a>","b735d516":"### 4.2.2 Correlation <a id='correlation'><\/a>","4432ad22":"# 4. Exploratory Data Analysis <a id='data_preparation'><\/a>","30cfb9f6":"#### 8.5.1 By Type<a id='type'><\/a>","9bbd9444":"From the plot I can infer that most of the animes watched belongs to comedy genre, next to that action and romance are most watched.","9af46715":"As for Rule 0 : If a user has Watched and liked `Clannad` there is `61%` confidence with `0.18` support he\/she will like `Toradora`<br>\nAs for Rule 2 : If a user has Watched and liked `No Game No Life` there is `65%` confidence with `0.16` support he\/she will like `Angel Beats`","31c87a6a":"The above table shows the 5 similar animes for each anime.","b487f4de":"## 8.2 Content based Recommendation System <a id='content'><\/a>","db2b2aea":"From the above table , I can infer:\n\n1. The minimum avg_rating is 1.67 and the maximum avg_rating is 9.5.\n\n2. The number of members ranges from 29 to 1013917.\n\n3. Users rating ranges from -1 to 10. So, I will replace -1 with NaN and drop the rows.","393dd2a1":"From the above graph I can see that from the principle components 1500 the variance is almost 1.","fbddbd5a":"**Interpretation:**\n\n68.9% of the anime's Ire aired on TV folloId by 13.3% through Movie.\n\n9.7% of anime's are streamed as OVA which is greater than ONA(1.1%).","cebeaeb0":"There are 4 `objects`, 1 `float` and 4 `int` data types attributes.\n\nAs anime_id and user_id are unique values I need to convert it into `object` data type.","271fbcfb":"In this dataset I have 12294 records across 7 features","c9e8e104":"<table align=\"center\" width=50%>\n    <tr>\n        <td width=\"50%\">\n            <img src=\"https:\/\/thumbs.gfycat.com\/EqualAfraidAntelope-max-1mb.gif\">\n        <\/td>\n    <\/tr>\n<\/table>","fec1a00c":"**Numeric Variables**","01ca5655":"# 10. Reference <a id='ref'><\/a>","1c18c58a":"### 7.2  Clustering after dimension reduction<a id='apply'><\/a>","6c1113d2":"**The last 5 index values range from 7813722-7813726 but I have only 7813604 records thus the indexes need to be reset**","53d224bf":"**Top 10 anime based on rating counts**","6eda2298":"**Interpretation:**\n    \n`Death Note` as the huge community size folloId by `Shingeki no kyojin` and `Sword Art Online`.","c819bbde":"### Distribution of rating <a id='analyze_tar_var'><\/a>","be4b5b86":"From the graph I can infer:\n    \nBased on the user rating I can see that`Death Note` have been rated the most folloId by `Sword Art Online` and `Shingeki no Kyojin`.","b562ab15":"# 9. Conclusion<a id='conclu'><\/a>","3ed3694a":"**Interpretation:**\n\nMost of the ratings are spread betIen 6-10.\n\nThe mode of the distribution is around 7.5-8.0.\n\nBoth the distribution are left skeId.","49c3b3dd":"### 4.1.2 Data Info<a id='info'><\/a>","25bed0d7":"### 7.1 PCA (Principal Component Analysis)<a id='pca'><\/a>","b63106f0":"As for Rule 0 : If a user has Watched and liked `Howl no Ugoku Shiro` and `Sen to Chihiro no Kamikakushi` there is `57%` confidence with `0.15` support he\/she will like `Tonari no Totoro`<br>\nAs for Rule 7 : If a user has Watched and liked `Mononoke Hime` there is `59%` confidence with `0.18` support he\/she will like `Sen to Chihiro no Kamikakushi`and `Howl no Ugoku Shiro`","d67fcd25":"**Count of genres**","e98c068f":"From the above table, I can infer:\n    \n1. There are `9892` unique anime_id and the most watched anime id is `1535` with frequency `34226`.\n\n2. There are `9892` anime names and the most watched anime name is `Death Note`and `34226` users have been watched.\n\n3. There are `3048` unique genres and `Comedy, School, Slice of Life` is the most repeated genre with frequency `49850`.\n\n4. There are `6` unique values in type attribute and most of type is `TV` with frequency `4364293`.\n\n5. Episodes specify the episode number of that particular anime.\n\n6. There are `69600` users and the user with user_id `42635` is the top most user who have watched most of the animes.i.e. `3747` animes. ","c8a6f2ca":"# 7. Dimensionality Reduction <a id='dim_red'><\/a>","1276471c":"# 2. Set Options <a id='set_options'><\/a>","2c5aaf67":"Now there are 6 `objects`, 2 `int` and 1 `float` attributes.","5facbd39":"# Problem Statement:","146a8205":"There are `7813604` records after removing missing values and duplicates.","7f2a0dfa":"From the above plot I can see the elbow point is at 3.","ed1baeba":"The above output are the predicted rating that a user may give for the respective animes. ","68133d59":"### 4.1.2 Merging the datasets<a id='merging'><\/a>","468665e0":"**Checking for duplicate data after removal of duplicates**","fa76189a":"#### 8.3.1.2 Using SVD<a id='svd'><\/a>","c9d6cd01":"The above plot shows top 10 animes which can be recommended based on trend.","518d0734":"**1) anime_data:**\n\n`anime_id` - unique id identifying an anime.\n\n`name` - full name of anime.\n\n`genre` - comma separated list of genres for this anime.\n\n`type` - movie, TV, OVA, etc.\n\n`episodes` - how many episodes in this show. (1 if movie).\n\n`rating` - average rating out of 10 for this anime.\n\n`members` - number of community members that are in this anime's \"group\".\n\n**2) rating_data:**\n\n`user_id` - non identifiable randomly generated user id.\n\n`anime_id` - the anime that this user has rated.\n\n`rating` - rating out of 10 this user has assigned (-1 if the user watched it but didn't assign a rating).","d648cee5":"### 4.2.1 Summary Statistics <a id='Summary_Statistics'><\/a>"}}