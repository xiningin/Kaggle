{"cell_type":{"356101a0":"code","2cd65d2b":"code","053d8fba":"code","52357efa":"code","fe0d514e":"code","98308ff6":"code","40a71f5e":"code","725055e2":"code","2d4a9775":"code","d9eb3618":"code","fbb8a8ac":"code","6fc7f25e":"markdown","68b811e5":"markdown","07eaeef4":"markdown","7cab43be":"markdown","636b3b92":"markdown","411792ca":"markdown","c480e076":"markdown","c540740a":"markdown"},"source":{"356101a0":"# Libraries \nimport os  \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import confusion_matrix, classification_report","2cd65d2b":"# Train\/test\/validation path\ntrain_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nvalidation_path = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'","053d8fba":"# lets plot some images from the training set\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_path)\nplt.figure(figsize=(10,10))\nfor images, labels in train_data.take(1):\n    for i in range(12): \n        plt.subplot(3, 4, i + 1)\n        plt.imshow(np.squeeze(images[i].numpy().astype('uint8')))\n        plt.title(train_data.class_names[labels[i]])\n        plt.axis(\"off\")","52357efa":"# Image Data Generator API \ntrain_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1.0\/255.0)\n\nvalid_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1.0\/255.0)\n\ntest_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\nrescale = 1.0 \/ 255.0)","fe0d514e":"# Call Keras's flow from directory method\ntrain_set = train_data_generator.flow_from_directory(\n    train_path,\n    target_size = (224, 224),\n    class_mode = 'binary',\n    color_mode = 'grayscale',\n    batch_size = 32,\n    shuffle = True\n)\n\nvalidation_set = test_data_generator.flow_from_directory(\n    validation_path,\n    target_size = (224, 224),\n    class_mode = 'binary',\n    color_mode = 'grayscale',\n    batch_size = 32,\n    shuffle = True\n)\n\n\ntest_set = test_data_generator.flow_from_directory(\n    test_path,\n    target_size = (224, 224),\n    class_mode = 'binary',\n    color_mode = 'grayscale',\n    batch_size = 32,\n    shuffle = False\n)","98308ff6":"# Sequential API\nmodel = tf.keras.Sequential([\n    layers.Conv2D(32, 3,activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3,activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(1, activation = 'sigmoid')\n])","40a71f5e":"# Configure hyperparameters and accuracy metrics\nmodel.compile(\noptimizer = 'adam',\nloss = 'binary_crossentropy',\nmetrics = ['accuracy',                     \n           tf.keras.metrics.AUC(name = 'AUC'),\n           tf.keras.metrics.Precision(name = 'Precision'),\n           tf.keras.metrics.Recall(name = 'Recall')])\n\n# Train the model \nmodel_base = model.fit(\n    train_set,\n    batch_size = 32,\n    validation_data = validation_set,\n    epochs = 10,)","725055e2":"pd.DataFrame(model_base.history).plot(figsize = (10,7), xlabel=\"epochs\")","2d4a9775":"# Model Results on the Test set\ndef result():\n    \n    results = model_base.model.evaluate(test_set, verbose = 0)\n    accuracy = results[1]\n    auc = results[2]\n    precision = results[3]\n    recall = results[4]\n    print(\"Accuracy:  {:.2f}\".format(accuracy))\n    print(\"AUC:  {:.2f}\".format(auc))\n    print(\"Precision:  {:.2f}\".format(precision))\n    print(\"Recall:  {:.2f}\".format(recall))\n    return result\n\nresult()","d9eb3618":"# Confusion Matrix\ndef model_evaluation(model, test_data):\n    \n    y_pred = np.squeeze((model_base.model.predict(test_set) >= 0.5).astype(np.int))\n    cm = confusion_matrix(test_set.labels, y_pred)\n    names = ['True Neg','False Pos','False Neg','True Pos']\n    count = [\"{0:0.2f}\".format(value) for value in cm.flatten()]\n    percentages = [\"{0:5%}\".format(value) for value in cm.flatten()\/np.sum(cm)]\n    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(names,count,percentages)]\n    labels = np.asarray(labels).reshape(2,2)\n    \n\n    plt.figure(figsize=(7, 7))\n    sns.heatmap(cm, annot=labels, fmt='', vmin=0, cmap='Blues', cbar=False)\n    plt.xticks(ticks=np.arange(2) + 0.5, labels=[\"Negative\", \"Positive\"])\n    plt.yticks(ticks=np.arange(2) + 0.5, labels=[\"Negative\", \"Positive\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    \n    clr = classification_report(test_set.labels, y_pred, target_names=[\"NEGATIVE\", \"POSITIVE\"])\n    print(\"Classification Report:\\n\\n\", clr)","fbb8a8ac":"model_evaluation(model, test_set)","6fc7f25e":"The model misclassifies patients to have pneumonia when infact they do not (false positive). However, given the nature of the application, a high rate of false negatives would be a cause for greater concern. Nonetheless, the reason why the model doesn't perform well in detecting false positives is because we are using an unbalanced dataset. We could potentially perform data augmentation or reorganize the dataset to create balanced classes. However, I'll conclude this analysis here for now.","68b811e5":"# 4. Model Evaluation","07eaeef4":"# Content\n\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children\u2019s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients\u2019 routine clinical care.\n\nFor the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for processing. In order to account for any grading errors, the evaluation set was also checked by a third expert.\n\n# Data\n\nThe dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia\/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia\/Normal). \n\n# Business Challenge\n\nTraditionally, the diagnosis of bactarial\/viral pneuomonia takes place when a radiologist examines an xray and makes a diagnosis. However, the use of deep lerning techniques to detect pneumonia can add a layer of objectivity in this diagnostic process. Deploying machine learning systems in the healthcare industry can facilitate early disease detection and reduce the presence of false positives and false negatives. \n\n# Ackowledgements \n\nhttps:\/\/data.mendeley.com\/datasets\/rscbjbr9sj\/2\n\n","7cab43be":"# 1. Importing Data & Libraries","636b3b92":"# 2. Data Preprocessing","411792ca":"The model clearly seems to be overfitting. The low precision indicates high presence of false positives. This is understandable as the dataset is unbalanced. Lets plot a confusion matrix to confirm this observation.","c480e076":"# 5. Conclusion\n\nThis notebook performed data preprocessing, predictive modelling and evaluation. Machine learning algorithms can improve healthcare decision support systems by aiding accurate and timely diagnosis. The integration of deep learning systems can add value in the healthcare industry. ","c540740a":"# 3. Model Preprocessing & Deployment"}}