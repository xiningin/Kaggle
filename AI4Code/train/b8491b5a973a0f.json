{"cell_type":{"62ab385c":"code","cbe4e168":"code","b4044fd0":"code","bd7e98d1":"code","57503409":"code","75dc0b8b":"code","dd9a821a":"code","45acd066":"code","9319e61a":"code","6521efc9":"code","d335c1bd":"code","eeba3917":"code","7ab6da95":"code","d67b28a5":"code","7fea82d7":"code","3ed9a49f":"code","06c26f4b":"code","edaba376":"code","4ea89e21":"code","c2d7f5fc":"code","416960f7":"markdown","fa22b1eb":"markdown","2c321c55":"markdown","9a301642":"markdown","1a4906f9":"markdown","08762d82":"markdown","b5c81c9b":"markdown","57103838":"markdown"},"source":{"62ab385c":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom IPython.display import display\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","cbe4e168":"data = pd.read_csv('\/kaggle\/input\/amazon-data-science-book-reviews\/reviews.csv')","b4044fd0":"data.head()","bd7e98d1":"data.shape","57503409":"data.loc[0].comment","75dc0b8b":"data.drop(['book_url'], axis=1, inplace=True)","dd9a821a":"data.stars.hist()","45acd066":"data.stars.value_counts()","9319e61a":"data[data.comment.apply(len)<50].stars.value_counts()","6521efc9":"data = data.drop(data[data.comment.apply(len)<50][data.stars==5.0].index)\ndata.stars.value_counts()","d335c1bd":"import nltk\n# from nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\n# from sklearn.feature_extraction import DictVectorizer\nfrom sklearn.model_selection import train_test_split","eeba3917":"X_train, X_test, y_train, y_test = train_test_split(data.comment, data.stars, test_size=0.3, random_state=37)","7ab6da95":"from sklearn import metrics  # \u043f\u043e\u0434\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043c\u0435\u0442\u0440\u0438\u043a\u0438\ndef mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\ndef dataframe_metrics(y_test,y_pred):\n    stats = [\n       metrics.mean_absolute_error(y_test, y_pred),\n       np.sqrt(metrics.mean_squared_error(y_test, y_pred)),\n       metrics.r2_score(y_test, y_pred),\n       mean_absolute_percentage_error(y_test, y_pred)\n    ]\n    return stats\nmeasured_metrics = pd.DataFrame({\"error_type\":[\"MAE\", \"RMSE\", \"R2\", \"MAPE\"]})","d67b28a5":"y_mean = np.median(y_train)\ny_pred_naive = np.ones(len(y_test)) * y_mean\nmeasured_metrics[\"naive\"] = dataframe_metrics(y_test, y_pred_naive)\nmeasured_metrics","7fea82d7":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words='english',\n                             norm=None,\n                             max_features=1500,\n                             min_df=0,\n                             max_df=0.2,\n                             ngram_range=(1,2))\n\nfeatures_train = vectorizer.fit_transform(X_train).todense()\nfeatures_test = vectorizer.transform(X_test).todense()\n\ntrain_matrix = pd.DataFrame(\n    features_train, \n    columns=vectorizer.get_feature_names()\n)\n\ntest_matrix = pd.DataFrame(\n    features_test, \n    columns=vectorizer.get_feature_names()\n)","3ed9a49f":"len(vectorizer.vocabulary_)","06c26f4b":"features_train.shape, features_test.shape","edaba376":"train_matrix.head(10)","4ea89e21":"from sklearn.linear_model import LassoCV\n\nlasso_cv = LassoCV(cv=10, n_jobs=-1)\nlasso_cv.fit(train_matrix, y_train)\n\ny_pred_lasso = lasso_cv.predict(test_matrix)\n\nmeasured_metrics[\"tf-idf\"] = dataframe_metrics(y_test, y_pred_lasso)\nmeasured_metrics","c2d7f5fc":"featureImportance = pd.DataFrame({\"feature\": train_matrix.columns[abs(lasso_cv.coef_)>0.04], \n                                  \"importance\": lasso_cv.coef_[abs(lasso_cv.coef_)>0.04]})\n\nfeatureImportance.set_index('feature', inplace=True)\nfeatureImportance.sort_values([\"importance\"], ascending=False, inplace=True)\nfeatureImportance[\"importance\"].plot.bar(figsize=(25,15));","416960f7":"### Let's write a simple quick-start notebook to work with this dataset","fa22b1eb":"Well, it seems, that if it is \"amazing\", then it is really amazing. \n\nBut if it is \"ok\" it is not ok :) \n\nHope you like the dataset and notebook. Have fun!","2c321c55":"Use the mean as a simple baseline:","9a301642":"The dataset is a bit unbalaced: most of the reviews are 5-star reviews. Let's fix it partially by removing all 5 star short reviews","1a4906f9":"Simple TF-IDF works better than our baseline (as expected).\nLet's see the most important features (words):","08762d82":"## 2. NLP","b5c81c9b":"Split the data to train\/test sets","57103838":"## 1. Data Preparation\n\nLet's load our data and make simple EDA"}}