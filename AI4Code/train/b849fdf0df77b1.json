{"cell_type":{"f9ed288e":"code","483f449d":"code","f586c4fa":"code","8c432e2a":"code","6091f1b8":"code","cedf61dc":"code","92e8d132":"code","9b5a50ae":"code","9f4d2f30":"code","293f058a":"code","6da4aa5e":"code","568929ec":"code","701e6dba":"code","ce8cd201":"code","2da76b08":"code","0b6379a8":"code","bea85320":"code","c5eb7e62":"code","d420b970":"code","a566fb45":"code","a8568667":"code","f1034e36":"code","005146a8":"code","0e5eebf9":"code","3d3bc0a6":"code","9187d0d8":"code","8aed5826":"code","2fe6cae4":"code","1474c5c9":"code","0c0a7f77":"code","dc9cb80b":"code","08d7c61f":"code","47291482":"code","04743803":"code","4f967bc4":"code","8638a080":"code","75bc550f":"code","89ca51d4":"code","726d0feb":"code","793d4ef1":"code","3ccef706":"code","0588fda1":"code","db822cdf":"code","8a439540":"code","66a2f7dc":"code","d4b7677e":"code","c08f9ed1":"code","53732cec":"code","5ef2a79f":"code","b83b2ce7":"code","3b74cac5":"code","f243c58f":"code","5825be8b":"code","adeedb7a":"code","25832528":"code","2c7b7205":"code","15f4516c":"code","36b2ae21":"markdown","a9196e1b":"markdown","7ba13847":"markdown","0be9031f":"markdown","676b6509":"markdown","6881f77e":"markdown","37e9dd2e":"markdown","01cb00d4":"markdown","2b764953":"markdown","a1eaaad8":"markdown","4d21a9d1":"markdown","9ee7db81":"markdown","2edc2e82":"markdown","e8037ebe":"markdown"},"source":{"f9ed288e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","483f449d":"from sklearn.preprocessing import MinMaxScaler\nimport pandas as pd\n\ndata=[[-1,2],[-0.5,6],[0,10],[1,18]]\npd.DataFrame(data)","f586c4fa":"scaler=MinMaxScaler()\nscaler=scaler.fit(data) # min(x),max(x)\nresult=scaler.transform(data)\nresult","8c432e2a":"# simple way to fit & transform\nresult_=scaler.fit_transform(data)\nresult_","6091f1b8":"scaler.inverse_transform(result)# reverse the result to original","cedf61dc":"# change the feature range to [0,1]\nscaler=MinMaxScaler(feature_range=[5,10])\nresult=scaler.fit_transform(data)\nresult","92e8d132":"# if there is some error can't excute the fit as the big size of the data, \n# we can use partial_fit\n#scaler=scaler.partial_fit(data)","9b5a50ae":"import numpy as np\nx=np.array([[-1,2],[-0.5,6],[0,10],[1,18]])\nx","9f4d2f30":"x.min(axis=1)# min of each row","293f058a":"x_nor=(x-x.min(axis=0))\/(x.max(axis=0)-x.min(axis=0))\nx_nor","6da4aa5e":"# reverse\nx_return=x_nor * (x.max(axis=0)-x.min(axis=0))+ x.min(axis=0)\nx_return","568929ec":"from sklearn.preprocessing import StandardScaler\n\ndata=[[-1,2],[-0.5,6],[0,10],[1,18]]\nscaler=StandardScaler()\nscaler.fit(data)","701e6dba":"scaler.mean_","ce8cd201":"scaler.var_","2da76b08":"x_std=scaler.transform(data)\nx_std","0b6379a8":"# utilize standardization will beocme Normal distribution with mean=0,variance 1","bea85320":"x_std.mean()","c5eb7e62":"x_std.std()","d420b970":"data=pd.read_csv('..\/input\/titanic-data\/train.csv',index_col=0)\ndata=data[['Age','Sex','Embarked','Survived']].reset_index()\ndata.head(2)","a566fb45":"data.info()","a8568667":"# parameter\n# missing_values =np.nan (null value)\n# strategy =constant or most_frequency\n# fill_value=0 or 'NONE' (int or Str)\n# copy=True Do not directly fill missing values into the feature matrix","f1034e36":"Age=data.loc[:,'Age'].values.reshape(-1,1)  \nAge[:20]\n#series  : means all of the rows, 'Age' means the columns of age\n# Raise one-dimensional data to two-dimensional data","005146a8":"from sklearn.impute import SimpleImputer\nimp_mean=SimpleImputer()\nimp_median=SimpleImputer(strategy='median')\nimp_0=SimpleImputer(strategy='constant',fill_value=0)\n","0e5eebf9":"imp_mean=imp_mean.fit_transform(Age)\nimp_median=imp_median.fit_transform(Age)\nimp_0=imp_0.fit_transform(Age)","3d3bc0a6":"imp_mean[:20]","9187d0d8":"imp_median[:20]","8aed5826":"imp_0[:20]","2fe6cae4":"# fillna\ndata.loc[:,'Age']=imp_median\ndata.info()","1474c5c9":"Embarked=data.loc[:,'Embarked'].values.reshape(-1,1)","0c0a7f77":"imp_mode=SimpleImputer(strategy='most_frequent')\ndata.loc[:,'Embarked']=imp_mode.fit_transform(Embarked)\ndata.info()","dc9cb80b":"data_=pd.read_csv('..\/input\/titanic-data\/train.csv',index_col=0)\ndata_=data_[['Age','Sex','Embarked','Survived']].reset_index()\ndata_.info()","08d7c61f":"data_.loc[:,'Age']=data_.loc[:,'Age'].fillna(data_.loc[:,'Age'].median())\ndata_.loc[:,'Age'][:20]","47291482":"data_.dropna(axis=0,inplace=True)\n# dropna(axis=0) drop row contains null, dropna(axis=1) drop  columns contains null\ndata_.info()","04743803":"from sklearn.preprocessing import LabelEncoder\n# data.iloc[:,-2]=LabelEncoder().fit_transform(data.iloc[:,-2]) # directly write\ndata1=data.copy()\ny=data1.iloc[:,-2]# import label not matrix,so it is allow to be 1-dimension","4f967bc4":"le=LabelEncoder()\nle=le.fit(y)\nlabel=le.transform(y)\n#le.fit_transform(y)","8638a080":"label","75bc550f":"le.classes_ # identify the details of category in label","89ca51d4":"le.inverse_transform(label)# return the label","726d0feb":"data1.iloc[:,-2]=label\ndata1.head()","793d4ef1":"from sklearn.preprocessing import OrdinalEncoder\ndata_","3ccef706":"OrdinalEncoder().fit(data_.iloc[:,2:]).categories_\n# iloc[:,2:3]='SEX',we also can use iloc[:,2:] to change the result of category to values\n# .categories_  identify the details of category in label\n# C\uff0cQ\uff0cS is Nominal variable 0,1,2 is meaningless,so we need to chang it to one-hot encoder","0588fda1":"data_.iloc[:,2:]=OrdinalEncoder().fit_transform(data_.iloc[:,2:])\ndata_.head()","db822cdf":"data.head()","8a439540":"from sklearn.preprocessing import OneHotEncoder\nx=data.iloc[:,2:-1]","66a2f7dc":"enc=OneHotEncoder(categories='auto').fit(x)\nresult=enc.transform(x).toarray()\nresult\n# OneHotEncoder(categories='auto').fit_transform(x).toarray() #directly write","d4b7677e":"# return to the original data\npd.DataFrame(enc.inverse_transform(result))","c08f9ed1":"enc.get_feature_names()","53732cec":"# axies=1,Connect the left and right tables\nnewdata=pd.concat([data,pd.DataFrame(result)],axis=1)\nnewdata.head()","5ef2a79f":"newdata.drop(['Sex','Embarked','PassengerId'],axis=1,inplace=True)\nnewdata.head()","b83b2ce7":"newdata.columns=['Age','Survived','Female','Male','Embarked_C','Embarked_Q','Embarked_S']\nnewdata.head()","3b74cac5":"data_2=newdata.copy()\nfrom sklearn.preprocessing import Binarizer","f243c58f":"X=data_2.iloc[:,0].values.reshape(-1,1)\n#The class is dedicated to features, so one-dimensional arrays cannot be used","5825be8b":"transformer=Binarizer(threshold=30).fit_transform(X) # The value >=30 will changed to 1\ndata_2.iloc[:,0]=transformer\ndata_2.head()","adeedb7a":"# parameter n_bins\n# Assume the parameter of n_bins=5, which means all of the features will set into 5 categories, \n# so please input the features one by one to avoid this issue.\n\n# parameter strategy\n# uniform: Equal value partition   (max(value)-min(value))\/n_bins\n# quantile: Equal sample partition\n# Kmeans","25832528":"from sklearn.preprocessing import KBinsDiscretizer\ndata_3=newdata.copy()\n\nX_3=data_3.iloc[:,0].values.reshape(-1,1)\n#The class is dedicated to features, so one-dimensional arrays cannot be used","2c7b7205":"est=KBinsDiscretizer(n_bins=3,encode='ordinal',strategy='uniform')\nset(est.fit_transform(X_3).ravel())","15f4516c":"est=KBinsDiscretizer(n_bins=3,encode='onehot',strategy='uniform') # shift + Tab to know the function\nest.fit_transform(X_3).toarray()","36b2ae21":"# preprocessing labelEncoder","a9196e1b":"## method2 use pandas to fill missing value","7ba13847":"# impute simpleimpute","0be9031f":"# Binarization and segmentation\n#### Divide continuous variables into two categories","676b6509":"# Missing value","6881f77e":"# one-hot encoder\n####  Nominal variable like C\uff0cQ\uff0cS should be use this, as it is no meaning between each data.\n#### Other category like \u5c0f\u5b66\uff0c\u4e2d\u5b66\uff0c\u5927\u5b66\uff0cwhich have sequency can use label encoder.","37e9dd2e":"# Preprocessing.OrdinalEncoder \n### converting categorical features into categorical values","01cb00d4":"### Normalization also called Min-MAX scalling Converges to 0-1 \uff0cdifferent with regularization","2b764953":"## Zero-centered  , Subtract a fixed value to make the data shift\n## Scale  , Remove a fixed value so that the data is in a fixed range","a1eaaad8":"# Normalization","4d21a9d1":"# KBinsDiscretizer\n#### Divide continuous variables into multiple categories","9ee7db81":"### *For most situation, we will choose standardscaler than minmaxscaler ,as minmaxscaler is sensitive to outliers.","2edc2e82":"# Standardization also called Z-score normalization\n### x=(x-u)\/\u03b1  ,will beocme Normal distribution with mean=0,variance 1","e8037ebe":"## the second way to normalization"}}