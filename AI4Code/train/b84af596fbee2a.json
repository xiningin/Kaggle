{"cell_type":{"b858bd86":"code","59103f60":"code","c77e8359":"code","1a9ad816":"code","ea7f4d8e":"code","ddf83c9c":"code","839b2a98":"code","646861bb":"code","f1032fc4":"code","ec62792f":"code","088859e0":"code","77ce863a":"code","54d958af":"code","ad2214b9":"code","33b32d95":"code","c0b81311":"code","1a8508bc":"code","f6280425":"code","b9efabec":"markdown","033cf4f0":"markdown","f0520f84":"markdown","4d1f1dd0":"markdown","2a3dedec":"markdown","c8632e12":"markdown","c9d51f0c":"markdown","0c0ecb60":"markdown","a629f3fb":"markdown","2eaef190":"markdown","db9ad562":"markdown","44f6b90c":"markdown","55495bc4":"markdown","2a0e4adf":"markdown","33a60661":"markdown","ff960f2f":"markdown","1351531a":"markdown","1db34490":"markdown","295de961":"markdown","2ee4a0ed":"markdown","c7a0dde7":"markdown","fc5c5033":"markdown","e209c1e8":"markdown","7514beb3":"markdown","5d86193e":"markdown","745f860a":"markdown"},"source":{"b858bd86":"import numpy as np\n\n# This is John's data\ndata = np.array([[0, 1, 5, 1, 0],  # record of John's 1st food delivery\n                [1, 0, 7, 0, 1],   # record of John's 2nd food delivery\n                [0, 1, 2, 1, 0],   # record of John's 3rd food delivery\n                [1, 1, 4.2, 1, 0], # record of John's 4th food delivery\n                [0, 0, 7.8, 0, 1], # ...\n                [1, 0, 3.9, 1, 0],\n                [0, 1, 4, 1, 0],\n                [1, 1, 2, 0, 0],\n                [0, 0, 3.5, 0, 1],\n                [1, 0, 2.6, 1, 0],\n                [0, 0, 4.1, 0, 1],\n                [0, 1, 1.5, 0, 1],\n                [1, 1, 1.75, 1, 0],\n                [1, 0, 1.3, 0, 0],\n                [1, 1, 2.1, 0, 0],\n                [1, 1, 0.2, 1, 0],\n                [1, 1, 5.2, 0, 1],\n                [0, 1, 2, 1, 0],\n                [1, 0, 5.5, 0, 1],\n                [0, 0, 2, 1, 0],\n                [1, 1, 1.7, 0, 0],\n                [0, 1, 3, 1, 1],\n                [1, 1, 1.9, 1, 0],\n                [0, 1, 3.1, 0, 1],\n                [0, 1, 2.3, 0, 0],\n                [0, 0, 1.1, 1, 0],\n                [1, 1, 2.5, 1, 1],\n                [1, 1, 5, 0, 1],\n                [1, 0, 7.5, 1, 1],\n                [0, 0, 0.5, 1, 0],\n                [0, 0, 1.5, 1, 0],\n                [1, 0, 3.2, 1, 0],\n                [0, 0, 2.15, 1, 0],\n                [1, 1, 4.2, 0, 1],\n                [1, 0, 6.5, 0, 1],\n                [1, 0, 0.5, 0, 0],\n                [0, 0, 3.5, 0, 1],\n                [0, 0, 1.75, 0, 0],\n                [1, 1, 5, 0, 1],\n                [0, 0, 2, 1, 0],\n                [0, 1, 1.3, 1, 1],\n                [0, 1, 0.2, 0, 0],\n                [1, 1, 2.2, 0, 0],\n                [0, 1, 1.2, 1, 0],\n                [1, 1, 4.2, 0, 1]])\n\nprint(data)","59103f60":"import pandas as pd\n\n# Create the dataframe with this data, labeling the columns\ndelivery_data = pd.DataFrame(data, columns=[\"bad_weather\", \"is_rush_hour\", \"mile_distance\", \"urban_address\", \"late\"])\n","c77e8359":"# Print the first 5 rows\ndelivery_data.head(15)","1a9ad816":"input_data = delivery_data[[\"bad_weather\", \"is_rush_hour\", \"mile_distance\", \"urban_address\"]]\ntarget = delivery_data[\"late\"]","ea7f4d8e":"from sklearn.neighbors import KNeighborsClassifier\n\n# Use n_neighbors = 1\n# This means the KNN will consider the \"closest\" record to make a decision.\nclassifier = KNeighborsClassifier(n_neighbors = 1)\n\n# Fit the model to our data\nclassifier.fit(input_data, target)","ddf83c9c":"import numpy as np\n\nsome_data = np.array([[0, 0, 2.1, 1]]) # bad_weather->0, is_rush_hour->0, mile_distance->2.1 and urban_address->1\n\n# Use the fitted model to make predictions on new data\nprint(classifier.predict(some_data))","839b2a98":"import numpy as np\n\nsome_data = np.array([[0, 0, 2.1, 1], # bad_weather->0, is_rush_hour->0, mile_distance->2.1 and urban_address->1\n                 [0, 1, 5, 0],   # bad_weather->0, is_rush_hour->1, mile_distance->5.0 and urban_address->0\n                 [1, 1, 3.1, 1]  # bad_weather->1, is_rush_hour->1, mile_distance->3.1 and urban_address->1\n                ])\n\n# Use the fitted model to make predictions on more new data\nprint(classifier.predict(some_data))","646861bb":"# Use the fitted model to make predictions on our training dataset\npredictions = classifier.predict(input_data)\n","f1032fc4":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(target, predictions))","ec62792f":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nprint(classification_report(target, predictions))\n\nprint(\"Accuracy:\", accuracy_score(target, predictions))\n","088859e0":"delivery_data.shape","77ce863a":"# Let's split our data into two sets: Training (85%) and Test (15%)\n# This gives us 38 training records and 7 test records (total 45 records)\n\ntraining_data = delivery_data.iloc[:38, :] # First 38\ntest_data = delivery_data.iloc[38:, :] # Remaining\n\n# Print the first 5 rows\ntraining_data.head()","54d958af":"from sklearn.neighbors import KNeighborsClassifier\n\nX_train = training_data[[\"bad_weather\", \"is_rush_hour\", \"mile_distance\", \"urban_address\"]].values\ny_train = training_data[\"late\"].values\n\n# Use n_neighbors = 1\n# This means the KNN will consider two other \"closest\" records to make a decision.\nclassifier = KNeighborsClassifier(n_neighbors = 1)\n\n# Fit the model to our training data\nclassifier.fit(X_train, y_train)","ad2214b9":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\n# Use the fitted model to make predictions on the same dataset we trained the model on\ntrain_predictions = classifier.predict(X_train)\n\nprint('Model evaluation on the training set: \\n')\nprint(confusion_matrix(y_train, train_predictions))\nprint(classification_report(y_train, train_predictions))\nprint(\"Training accuracy:\", accuracy_score(y_train, train_predictions))\n","33b32d95":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\nX_test = test_data[[\"bad_weather\", \"is_rush_hour\", \"mile_distance\", \"urban_address\"]].values\ny_test = test_data[\"late\"].tolist()\n\n# Use the fitted model to make predictions on the test dataset\ntest_predictions = classifier.predict(X_test)\n\nprint('Model evaluation on the training set: \\n')\nprint(confusion_matrix(y_test, test_predictions))\nprint(classification_report(y_test, test_predictions))\nprint(\"Training accuracy:\", accuracy_score(y_test, test_predictions))\n","c0b81311":"# Let's further split our training data into two sets: Training (80%) and Validation (20%)\n# This gives us 30 training records and 8 test records \n\ntrain_data = training_data.iloc[:30, :] # First 30\nval_data = training_data.iloc[30:, :] # Remaining\n\nX_train = train_data[[\"bad_weather\", \"is_rush_hour\", \"mile_distance\", \"urban_address\"]].values\ny_train = train_data[\"late\"].tolist()\n\nX_val = val_data[[\"bad_weather\", \"is_rush_hour\", \"mile_distance\", \"urban_address\"]].values\ny_val =val_data[\"late\"].tolist()\n","1a8508bc":"K_values = [1, 2, 3, 4, 5, 6]\n\nfor K in K_values:\n    classifier = KNeighborsClassifier(n_neighbors = K)\n    classifier.fit(X_train, y_train)\n    val_predictions = classifier.predict(X_val)\n    print(\"K=%d, Validation accuracy score: %f\" % (K, accuracy_score(y_val, val_predictions)))","f6280425":"classifier = KNeighborsClassifier(n_neighbors = 4)\nclassifier.fit(X_train, y_train)\ntest_predictions = classifier.predict(X_test)\nprint(\"Test accuracy score: %f\" % (accuracy_score(y_test, test_predictions)))","b9efabec":"## 5. <a name=\"5\">Model evaluation<\/a>\n<a href=\"#0\">Go to top<\/a>\n\n__How do we know whether our predictions were good or bad predictions?__ <br\/>\nIf we don't have the correct label for this input, we won't know. Similarly, we won't have any idea about how good this model is. \n\nOne thing we can do is to test the model with the data we used to train it, and use sklearn's metrics functions to examine the performance of the classifier.","033cf4f0":"And now, let's check the accuracy on the test data.","f0520f84":"## 3. <a name=\"3\">Train a classifier<\/a>\n<a href=\"#0\">Go to top<\/a>\n\n\nLet's fit a K Nearest Neighbors (KNN) model to our data. We use the sklearn library's [KNeighborsClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html) here.","4d1f1dd0":"On this dataset containing samples of each of the two possible classes, we fit an estimator from the __sklearn__ library to best capture the relationship between the input and the output, and further explore that learned relationship to predict the classes to which unseen samples belong.\n\nIn __sklearn__, an estimator is a Python object that implements the methods __.fit()__ and __.predict()__. The estimator\u2019s constructor takes as arguments the model\u2019s parameters.\n","2a3dedec":"Looking at our dataset as a dataframe:","c8632e12":"Dataframes are not just more meaningful to look at, are also powerful, expressive and flexible data structures that make data manipulation and analysis much easier. ","c9d51f0c":"## 4. <a name=\"4\">Use the trained classifier to make predictions<\/a>\n<a href=\"#0\">Go to top<\/a>\n\nLet's make some prediction with our fitted model. Assume we have the following data:","0c0ecb60":"## 6. <a name=\"6\">Training and test datasets<\/a>\n<a href=\"#0\">Go to top<\/a>\n\nJohn's model worked with 100% accuracy on the whole dataset. This might seem promising, but this doesn't tell us anything about performance on future orders. One way to test whether this model works on new \"unseen\" orders, is to reserve some data from out original dataset for test purposes. \n\n__Let's split our data into two sets: Training (85%) and Test (15%)__. This will give us 38 training records and 7 test records (of the total 45 records).","a629f3fb":"We can also predict multiple records, as shown below.","2eaef190":"Let's check the accuracy on the training data.","db9ad562":"__Jupiter notebooks environment__: \n* Jupiter notebooks allow creating and sharing documents that contain both code and rich text element, such as equations. If you are not familiar with Jupiter notebooks, read more [here](https:\/\/jupyter-notebook-beginner-guide.readthedocs.io\/en\/latest\/what_is_jupyter.html). \n* This is a quick-start demo to bring you up to speed on coding and experimenting with machine learning. Move through the notebook from top to bottom. Run each code cell to see its output. To run a cell, click within the cell and press __Shift__+__Enter__, or click __Run__ at the top of the page. ","44f6b90c":"Looks like K = 3 or K = 4 or K = 5 are optimal choices for K. Let's choose K = 4 to build the classifier, train on the train set, and finally test on the test set.","55495bc4":"Indeed, accuracy on the test set improved from 71% to 86%, reducing the generalization gap.","2a0e4adf":"## 1. <a name=\"1\">The dataset<\/a>\n<a href=\"#0\">Go to top<\/a>\n\nLet's enter John's food deliveries dataset here, using the __numpy__ high-performance array-processing package. ","33a60661":"## 7. <a name=\"7\">Overfitting<\/a>\n<a href=\"#0\">Go to top<\/a>\n\n### This doesn't look good! \nWe only achieved 71% accuracy on data that the model hasn't seen before. <br\/>\nCan we trust this model? Probably not.\n\n### Let's explain what happened here. \nWe experienced a common problem called __\"Overfitting\"__. This means our model \"over-learned\" or memorized our training data, and failed on the new data it hasn't seen before.\n\nExperienced people would have spotted the problem even before fitting the classifier, the K parameter we chose as 1 here looks at the closest one record and assign the class of that record. This doesn't generalize well to our overall dataset and \"overfits\" the dataset.\n\n### Where is the validation subset?\n\nIf we want to optimize the performance of our algorithm, and therefore reduce the so-called *generalization gap*, we need to look for the best performing K value, using a validation set. We pick the K value that results in the best validation performance metric of our choice, and then we finally check model performance on the test dataset.","ff960f2f":"Let's now write our toy dataset into a __pandas__ dataframe, labeling the columns for easier access. ","1351531a":"Fitting the KNN on training dataset this time.","1db34490":"__Confusion matrix__: The diagonals show us correct classifications. Each row and column belongs to a class (late and on time). The first column and row correspond to \"on time\" case, the second column-rows are \"late\" cases.\n","295de961":"We predicted this delivery to be on time.","2ee4a0ed":"Indeed, we predicted all outcomes with 100% accuracy!","c7a0dde7":"### Trying different K values.\n\nLet's try different K values and see how the model performs with each one, on the validation set.\n","fc5c5033":"This notebook is based on the Machine Learning Accelerated Playlist on Youtube by Amazon.\n\nI have worked on some mind-maps for this below sheet. \nCheck them out here - [Coggle](https:\/\/coggle.it\/diagram\/Xz0Y18ZTxkPErkPY\/t\/ml-model-development\/400f32df6111459ebe6c00b511d3f6f1b441fbce28dfc4eb616bb4e19f3dacfc)","e209c1e8":"# <a name=\"0\">Machine Learning Accelerator - Tabular Data - Lecture 1<\/a>\n\n\n## ML Model Development\n\nIn this notebook we start from a simple machine learning problem, John's food delivery problem, and shape a machine learning solution with __sklearn__ library. Given John's dataset of food delivery recordings, the task is to predict whether an order will be on time or delayed. \n\n1. <a href=\"#1\">The dataset<\/a>\n2. <a href=\"#2\">Select features to build the model<\/a>\n3. <a href=\"#3\">Train a  classifier<\/a> ([__K Nearest Neighbors Classifier__](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html))\n4. <a href=\"#4\">Use the trained classifier to make predictions<\/a>\n5. <a href=\"#5\">Model evaluation<\/a>\n6. <a href=\"#6\">Training and test datasets<\/a>\n7. <a href=\"#7\">Overfitting<\/a>\n","7514beb3":"The last delivery is predicted to be late. The first two will be on time (Hopefully!)","5d86193e":"When we look at the confusion matrix, we can quickly see that all predictions were correct, so our classifier should have a high score.\n\n__Classification metrics__: We use here the __accuracy__ metric, that measures how correctly the trained model predicts the late or not late outcomes. Let's look at the classification report and the accuracy score below.","745f860a":"## 2. <a name=\"2\">Select features to build the model<\/a>\n<a href=\"#0\">Go to top<\/a>\n\nLet's start using the dataframe, by first grabing the input and output of our machine learning problem."}}