{"cell_type":{"de0e0c55":"code","a69a44da":"code","1bdc1015":"code","f231893e":"code","e528a186":"code","e0332aad":"code","d01be399":"code","dd9d1121":"code","7304aec0":"code","e8151037":"code","06b6bb59":"code","473df424":"code","b4546f79":"code","dcf17739":"code","75b1b842":"code","c1e012cd":"code","f163564e":"code","6b10af6b":"code","a6aa7e29":"markdown","95a4b418":"markdown","02410156":"markdown","3806732d":"markdown"},"source":{"de0e0c55":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a69a44da":"#Import package that will be use\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.stats.api as sms\nimport statsmodels.api as sm","1bdc1015":"from statsmodels.formula.api import ols\nfrom scipy.stats import shapiro\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","f231893e":"#Open data set mtcars\nmtcars = pd.read_csv('https:\/\/gist.githubusercontent.com\/ZeccaLehn\/4e06d2575eb9589dbe8c365d61cb056c\/raw\/898a40b035f7c951579041aecbfb2149331fa9f6\/mtcars.csv')","e528a186":"#I want to see head of data so i know the columns names\npd.DataFrame(mtcars).head()","e0332aad":"#First Iteration for backward regression\nmodel = ols('mpg~cyl+disp+hp+drat+wt+qsec+vs+am+gear+carb', data = mtcars).fit()\nprint(model.summary())","d01be399":"#We can see that p value of cyl is higher than other independent variable and p value is higher than 0.05, \n#so i exclude for next iteration\n\n#Second Iteration for backward regression\nmodel = ols('mpg~disp+hp+drat+wt+qsec+vs+am+gear+carb', data = mtcars).fit()\nprint(model.summary())","dd9d1121":"#We can see that p value of vs is higher than other independent variable and p value is higher than 0.05, \n#so i exclude for next iteration\n\n#Third Iteration for backward regression\nmodel = ols('mpg~disp+hp+drat+wt+qsec+am+gear+carb', data = mtcars).fit()\nprint(model.summary())","7304aec0":"#We can see that p value of carb is higher than other independent variable and p value is higher than 0.05, \n#so i exclude for next iteration\n\n#Third Iteration for backward regression\nmodel = ols('mpg~disp+hp+drat+wt+qsec+am+gear', data = mtcars).fit()\nprint(model.summary())","e8151037":"#We can see that p value of gear is higher than other independent variable and p value is higher than 0.05, \n#so i exclude for next iteration\n\n#Fourth Iteration for backward regression\nmodel = ols('mpg~disp+hp+drat+wt+qsec+am', data = mtcars).fit()\nprint(model.summary())","06b6bb59":"#We can see that p value of drat is higher than other independent variable and p value is higher than 0.05, \n#so i exclude for next iteration\n\n#Fifth Iteration for backward regression\nmodel = ols('mpg~disp+hp+wt+qsec+am', data = mtcars).fit()\nprint(model.summary())","473df424":"#We can see that p value of disp is higher than other independent variable and p value is higher than 0.05, \n#so i exclude for next iteration\n\n#sixth Iteration for backward regression\nmodel = ols('mpg~hp+wt+qsec+am', data = mtcars).fit()\nprint(model.summary())","b4546f79":"#We can see that p value of hp is higher than other independent variable and p value is higher than 0.05, \n#so i exclude for next iteration\n\n#Seventh Iteration for backward regression\nmodel = ols('mpg~wt+qsec+am', data = mtcars).fit()\nprint(model.summary())","dcf17739":"#The prediction value fo dependent variable(mpg)\nfitted = model.predict()\nfitted","75b1b842":"#Residual or error value from my model regression\nresidual = model.resid","c1e012cd":"#Check linearity and homogenity with scatter plot of predicted value vs residual\nplt.scatter(fitted, residual)\nplt.title(\"fitted vs residual\")\nplt.xlabel(\"fitted\")\nplt.ylabel(\"residual\")\nplt.show()","f163564e":"#Check normality of residual\nshapiro(residual)","6b10af6b":"#Check multicolinearity\nx_model = mtcars[['wt', 'qsec', 'am']]\nx_new = sm.add_constant(x_model)\n  \n# VIF dataframe\nvif_data = pd.DataFrame()\nvif_data[\"feature\"] = x_new.columns\n  \n# calculating VIF for each feature\nvif_data[\"VIF\"] = [variance_inflation_factor(x_new.values, i)\n                          for i in range(len(x_new.columns))]\n  \nprint(vif_data[1:])","a6aa7e29":"We can see that the value of VIF from all independent variable are lower tha 10, so there is no multicolinearity from the model","95a4b418":"P value is higher than 0.05, so the residual is normal distribution","02410156":"We can see that scatter plot is not patterned, so the model are linear and variance of error is constant","3806732d":"We can see that p value of am is higher than other independent variable and p value is lower than 0.05, so i have some independent variable that impact for dependent variable(mpg). The model from my regression process is:\nmpg = 9.6178-3.9165wt+1.2259qsec+2.9358am\n\nAfter that, i should check all of assume linear regression, such as linearity, homogenity, normality, and multicolinearity."}}