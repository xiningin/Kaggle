{"cell_type":{"68aa2384":"code","2660f4a3":"code","33fc33d5":"code","4ad86dcc":"code","49a0e1ce":"code","27c45fba":"code","f87b56bd":"code","758ad2cd":"code","25ff9ef4":"code","1888af40":"code","06878825":"code","88907b22":"code","0b5f51ce":"code","a334120c":"code","92780a89":"code","d7f768e4":"code","cdb8cf20":"code","90e16d15":"code","a6319de0":"code","211faa5e":"code","1d51790d":"code","c5e0663f":"code","13ff0202":"code","988ccfbd":"code","1cd9a69d":"code","9cb6ed06":"code","fda0c79f":"code","af0f5f18":"code","0f4e887e":"code","2d8b3337":"code","a919229e":"code","d5e941c8":"code","3800c4cd":"code","fe6fba5e":"code","3827d39c":"code","ac133c5c":"code","4b2c09e7":"code","03d30ee0":"code","d751d793":"code","4cd6b705":"code","56f2491a":"code","e789adf6":"code","8c01eabb":"code","f7e5c484":"code","fe215215":"code","fc6b080e":"code","8d015467":"code","9df857ca":"code","c5760305":"code","8acb67b3":"code","9317d5c7":"code","95a494cf":"code","86b3bbbf":"code","44d24eea":"code","134ccc9f":"code","4732128b":"code","ddc0d76f":"code","5e506d74":"code","235d06be":"code","1574c6b3":"code","e988fd7e":"markdown","e320d5cc":"markdown","9e8d97a9":"markdown","a0941082":"markdown","f4327425":"markdown","263dcce5":"markdown","d6f938f6":"markdown","447babf0":"markdown","ca266cb8":"markdown","6f19967a":"markdown","d24a09c4":"markdown","d8c7adec":"markdown","32bf9668":"markdown"},"source":{"68aa2384":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2660f4a3":"df=pd.read_excel(\"\/kaggle\/input\/bank-loan-modelling\/Bank_Personal_Loan_Modelling.xlsx\",'Data')","33fc33d5":"df.head(5)","4ad86dcc":"df=df.drop(['ID'],axis=1)","49a0e1ce":"df.head(5)","27c45fba":"#Find Null values in the data set:\ndf.isnull().sum()","f87b56bd":"#Finding of the duplicate values:\ndf.duplicated().sum()","758ad2cd":"#Since all the features in the data set are numerical hence describing the data:\ndf.describe().transpose()","25ff9ef4":"import seaborn as sns\nimport matplotlib.pyplot as plt","1888af40":"df.columns","06878825":"col=['Age', 'Experience', 'Income', 'CCAvg','Mortgage']\n\ni=3\nj=0\nplt.figure(figsize=(14,12))\nfor k in col :\n    plt.subplot(i,i,i*(j+1)\/\/i)\n    sns.distplot(df[k])\n    j=j+1\nplt.show()","88907b22":"# Replacing negative experience values with the median value in the Experience column:\nnegexp=df[df['Experience']<0]","0b5f51ce":"negexp['Experience'].value_counts()","a334120c":"negval=[-3, -2, -1]\n\nfor i in negval:\n    df['Experience']=df['Experience'].replace(negval,np.median(df['Experience']))","92780a89":"df['Experience'].describe()","d7f768e4":"# Finding Corelation between the features:\ncor=df.corr()","cdb8cf20":"# Heatmap for Corelation:\nplt.figure(figsize=(10,8))\nplt.title(\"Corelation Plot\")\nsns.heatmap(cor,annot=True)\nplt.show()","90e16d15":"plt.figure(figsize=(10,8))\nplt.title(\"Scatter plot for Experience & Age\")\nsns.scatterplot(x='Age',y='Experience', hue='Personal Loan', data=df)\nplt.show()","a6319de0":"df=df.drop(['Experience'],axis=1)","211faa5e":"# Plotting Scatter plot for multivariate features:\ncol=['Income','CCAvg','Mortgage']\nplt.figure(figsize=(14,12))\nj=3\nk=0\nfor i in col:\n    plt.subplot(1,j,j*(k+1)\/\/j)\n    sns.scatterplot(x='Age',y=i,hue='Personal Loan', data=df)\n    k=k+1\nplt.show()","1d51790d":"# Plotting Counts plot for Categorical features:\ncol=['Securities Account','CD Account','Online','CreditCard']\nplt.figure(figsize=(14,12))\nj=2\nk=0\nfor i in col:\n    plt.subplot(2,j,j*(k+1)\/\/j)\n    sns.countplot(x=i,hue='Personal Loan', data=df)\n    k=k+1\n    plt.grid(True)\nplt.show()","c5e0663f":"df.columns","13ff0202":"plt.figure(figsize=(9,7))\nsns.boxplot(x='Family',y='Income',hue='Personal Loan', data=df)\nplt.show()","988ccfbd":"plt.figure(figsize=(12,10))\nsns.boxplot(x='Education',y='CCAvg',hue='Personal Loan', data=df)\nplt.show()","1cd9a69d":"df.columns","9cb6ed06":"df=df.drop(['ZIP Code'],axis=1)","fda0c79f":"df1=df","af0f5f18":"df1['Personal Loan'].value_counts()","0f4e887e":"df.head(5)","2d8b3337":"# Checking class balance for Personal Loan:\ndf['Personal Loan'].value_counts()","a919229e":"# Class label has imbalanced data, so this feature needs to be re-balanced using upsample method:\n# Splitting major & minor class data frames:\ndf_majority=df[df['Personal Loan']==0]\ndf_minority=df[df['Personal Loan']==1]","d5e941c8":"print(\"Majority calss shape {}\".format(df_majority.shape))\nprint(\"Minority calss shape {}\".format(df_minority.shape))","3800c4cd":"# Upsampling:\nfrom sklearn.utils import resample\ndf_minority_upsample=resample(df_minority,n_samples=4520)","fe6fba5e":"df=pd.concat([df_majority,df_minority_upsample])","3827d39c":"df['Personal Loan'].value_counts()","ac133c5c":"# Model Building:\nx=df.drop(['Personal Loan'],axis=1)\ny=df['Personal Loan']","4b2c09e7":"# Splitting of Data:\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)","03d30ee0":"# Decision Tree Model Prediction\nfrom sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()","d751d793":"dt.fit(x_train,y_train)","4cd6b705":"y_pred_base=dt.predict(x_test)","56f2491a":"# Finding Accuracy:\nfrom sklearn.metrics import accuracy_score\nacc=accuracy_score(y_test,y_pred_base)\nprint(acc)","e789adf6":"# Model validation:\nfrom sklearn.metrics import confusion_matrix,classification_report\nconfusion_matrix(y_test,y_pred_base)","8c01eabb":"#Classification Report:\nclf_report=classification_report(y_test,y_pred_base)\nprint(clf_report)","f7e5c484":"# Hyper Parameter Tuning:\nfrom sklearn.model_selection import GridSearchCV\nparameters={'criterion':['gini','entropy'],'max_depth':np.arange(1,50),'min_samples_leaf':[1,2,3,6,9,4]}\ngrid=GridSearchCV(dt,parameters)","fe215215":"model=grid.fit(x_train,y_train)","fc6b080e":"grid.best_score_","8d015467":"grid.best_params_","9df857ca":"clf_best=grid.best_estimator_","c5760305":"clf_best.fit(x_train,y_train)","8acb67b3":"y_pred_best=clf_best.predict(x_test)","9317d5c7":"accuracy_score(y_test,y_pred_best)","95a494cf":"# Cross Validation:\nfrom sklearn.model_selection import cross_val_score","86b3bbbf":"cross_val=cross_val_score(clf_best,x,y,cv=10)\nprint(cross_val)","44d24eea":"np.mean(cross_val)","134ccc9f":"# Visualizg the Tree:\nfrom sklearn import tree\nplt.figure(figsize=(16,14))\ntree.plot_tree(clf_best)\nplt.show()","4732128b":"# For the imbalance data set:\nx_imbal=df1.drop(['Personal Loan'],axis=1)\ny_imbal=df1['Personal Loan']","ddc0d76f":"x_train_imbal,x_test_imbal,y_train_imbal,y_test_imbal=train_test_split(x_imbal,y_imbal,test_size=0.3)","5e506d74":"clf_best.fit(x_train_imbal,y_train_imbal)","235d06be":"y_pred_imbal=clf_best.predict(x_test_imbal)","1574c6b3":"accuracy_score(y_test_imbal,y_pred_imbal)","e988fd7e":"Analysis: There is a junk value in the 'Experience' column since there is a minimum value of '-3' which is an incorrect information.\nBefore correcting the junk data in the data set let us plot the distribution.","e320d5cc":"**Age v\/s Income**: People with more income (>100$) seems to have opted for Personal Loan.\n\n**Age v\/s CCAvg**: Also people with high CCAvg seems to have opted for Personal Loan.\n\n**Age v\/s Mortgage**: People who have opted for Personal Loan are not much related with higher Mortgage value but people with Mortgage value greater than 400$ seems to have taken Personal Loan.","9e8d97a9":"**Accuracy**: (TP+TN)\/(TP+TN+FP+FN)\n\n**Classification Error**: (FP+FN)\/(TP+TN+FP+FN) or 1-Accuracy\n\n**Sensitivity**: When the actual value is positive, how often is the prediction correct. TP\/FN+TP\n\n**Specificity**: When the actual value is neagative, how often is the prediction correct. TN\/TN+FP\n\n**Precision**: When the positive value is predicted, how often is the prediction correct. TP\/TP+FP","a0941082":"**Age**: Mean value of age is 45.33 and the distribution is even across mean and hence normally distributed.\n\n**Experience**: Even distribution across mean and hence normally distributed.\n\n**Income**: Positively skewed that is median is lesser than the mean value.\n\n**CCAvg**: Positively skewed that is median is lesser than the mean value.\n\n**Mortgage**: Positively skewed that is median is lesser than the mean value.","f4327425":"Personal Loan: This feature is considered as target which describes who has opted for the loan (0) and who has not opted for the loan (1)\nSince ID feature doesn't much contribute to the data set, hence removed from the data set.","263dcce5":"Irrespective of Education, people who have good CCAvg > 2.5 seems to have opted out for the Personal Loan.","d6f938f6":"Experience & Age are highly positively co-related and so Experience can be dropped.","447babf0":"People with high Income irrespective of the Family size seems to have opted for Personal Loan.","ca266cb8":"People without the CD Accounts tend to have taken more Personal Loan.\nPeople with more Online accounts seem to take more Personal Loan, where as very minimal number of people who have Securities Account have opted the Personal Loan.\nMost of the people with the CreditCard seems to have not taken the Personal Loan.","6f19967a":"None of the columns in the data set have Null values.","d24a09c4":"None of the duplicate values are available in the data set.","d8c7adec":"Experience and Age are highly positively corelated with eachother and hence one feature can be removed to avoid multi-colinearity issue.","32bf9668":"Negative values in the Experience column in the data set are replaced with the median value."}}