{"cell_type":{"04f43045":"code","ce26098e":"code","566f9d66":"code","fe7a4b03":"code","e3d7ba7f":"code","88492a2b":"code","4fc62396":"code","77a889c9":"code","150a6ceb":"code","1769c2af":"code","4ce5ef5e":"code","a59fceb5":"code","02834df0":"code","ff20d15a":"code","2a4ab3ee":"code","9861260a":"code","2b2e3324":"markdown"},"source":{"04f43045":"from keras.datasets.fashion_mnist import load_data\n# load the images into memory\n(trainX, trainy), (testX, testy) = load_data()\n# summarize the shape of the dataset\nprint('Train', trainX.shape, trainy.shape)\nprint('Test', testX.shape, testy.shape)","ce26098e":"# plot raw pixel data\nfrom matplotlib import pyplot\n# plot images from the training dataset\nfor i in range(100):\n\t# define subplot\n\tpyplot.subplot(10, 10, 1 + i)\n\t# turn off axis\n\tpyplot.axis('off')\n\t# plot raw pixel data\n\tpyplot.imshow(trainX[i], cmap='gray_r')\npyplot.show()","566f9d66":"#training an unconditional gan on the fashion mnist dataset\nfrom numpy import expand_dims\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom keras.datasets.fashion_mnist import load_data\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout","fe7a4b03":"# define the standalone discriminator model\ndef define_discriminator(in_shape=(28,28,1)):\n\tmodel = Sequential()\n\t# downsample\n\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=in_shape))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# downsample\n\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# classifier\n\tmodel.add(Flatten())\n\tmodel.add(Dropout(0.4))\n\tmodel.add(Dense(1, activation='sigmoid'))\n\t# compile model\n\topt = Adam(lr=0.0002, beta_1=0.5)\n\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n\treturn model","e3d7ba7f":"# define the standalone generator model\ndef define_generator(latent_dim):\n\tmodel = Sequential()\n\t# foundation for 7x7 image\n\tn_nodes = 128 * 7 * 7\n\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\tmodel.add(Reshape((7, 7, 128)))\n\t# upsample to 14x14\n\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# upsample to 28x28\n\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n\tmodel.add(LeakyReLU(alpha=0.2))\n\t# generate\n\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same'))\n\treturn model","88492a2b":"# define the combined generator and discriminator model, for updating the generator\ndef define_gan(generator, discriminator):\n\t# make weights in the discriminator not trainable\n\tdiscriminator.trainable = False\n\t# connect them\n\tmodel = Sequential()\n\t# add generator\n\tmodel.add(generator)\n\t# add the discriminator\n\tmodel.add(discriminator)\n\t# compile model\n\topt = Adam(lr=0.0002, beta_1=0.5)\n\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n\treturn model\n","4fc62396":"# load fashion mnist images\ndef load_real_samples():\n\t# load dataset\n\t(trainX, _), (_, _) = load_data()\n\t# expand to 3d, e.g. add channels\n\tX = expand_dims(trainX, axis=-1)\n\t# convert from ints to floats\n\tX = X.astype('float32')\n\t# scale from [0,255] to [-1,1]\n\tX = (X - 127.5) \/ 127.5\n\treturn X","77a889c9":"# select real samples\ndef generate_real_samples(dataset, n_samples):\n\t# choose random instances\n\tix = randint(0, dataset.shape[0], n_samples)\n\t# select images\n\tX = dataset[ix]\n\t# generate class labels\n\ty = ones((n_samples, 1))\n\treturn X, y","150a6ceb":"# generate points in latent space as input for the generator\ndef generate_latent_points(latent_dim, n_samples):\n\t# generate points in the latent space\n\tx_input = randn(latent_dim * n_samples)\n\t# reshape into a batch of inputs for the network\n\tx_input = x_input.reshape(n_samples, latent_dim)\n\treturn x_input","1769c2af":"# use the generator to generate n fake examples, with class labels\ndef generate_fake_samples(generator, latent_dim, n_samples):\n\t# generate points in latent space\n\tx_input = generate_latent_points(latent_dim, n_samples)\n\t# predict outputs\n\tX = generator.predict(x_input)\n\t# create class labels\n\ty = zeros((n_samples, 1))\n\treturn X, y","4ce5ef5e":"# train the generator and discriminator\ndef train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=128):\n\tbat_per_epo = int(dataset.shape[0] \/ n_batch)\n\thalf_batch = int(n_batch \/ 2)\n\t# manually enumerate epochs\n\tfor i in range(n_epochs):\n\t\t# enumerate batches over the training set\n\t\tfor j in range(bat_per_epo):\n\t\t\t# get randomly selected 'real' samples\n\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n\t\t\t# update discriminator model weights\n\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n\t\t\t# generate 'fake' examples\n\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n\t\t\t# update discriminator model weights\n\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n\t\t\t# prepare points in latent space as input for the generator\n\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n\t\t\t# create inverted labels for the fake samples\n\t\t\ty_gan = ones((n_batch, 1))\n\t\t\t# update the generator via the discriminator's error\n\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n\t\t\t# summarize loss on this batch\n\t\t\tprint('>%d, %d\/%d, d1=%.3f, d2=%.3f g=%.3f' %\n\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n\t# save the generator model\n\tg_model.save('generator.h5')\n","a59fceb5":"# size of the latent space\nlatent_dim = 100\n# create the discriminator\ndiscriminator = define_discriminator()\n# create the generator\ngenerator = define_generator(latent_dim)\n# create the gan\ngan_model = define_gan(generator, discriminator)\n# load image data\ndataset = load_real_samples()\n# train model\ntrain(generator, discriminator, gan_model, dataset, latent_dim)\n","02834df0":"from keras.models import load_model\nfrom numpy.random import randn\nfrom matplotlib import pyplot","ff20d15a":"# generate points in latent space as input for the generator\ndef generate_latent_points(latent_dim, n_samples):\n\t# generate points in the latent space\n\tx_input = randn(latent_dim * n_samples)\n\t# reshape into a batch of inputs for the network\n\tx_input = x_input.reshape(n_samples, latent_dim)\n\treturn x_input","2a4ab3ee":"# create and save a plot of generated images (reversed grayscale)\ndef show_plot(examples, n):\n\t# plot images\n\tfor i in range(n * n):\n\t\t# define subplot\n\t\tpyplot.subplot(n, n, 1 + i)\n\t\t# turn off axis\n\t\tpyplot.axis('off')\n\t\t# plot raw pixel data\n\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n\tpyplot.show()","9861260a":"# load model\nmodel = load_model('generator.h5')\n# generate images\nlatent_points = generate_latent_points(100, 100)\n# generate images\nX = model.predict(latent_points)\n# plot the result\nshow_plot(X, 10)","2b2e3324":"10. Construct a GAN model which can learn to generate fake images for MNIST fashion dataset"}}