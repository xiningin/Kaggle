{"cell_type":{"9350ecb0":"code","d5380303":"code","453834ed":"code","38aaf306":"code","9ba3dd02":"code","a95a3d77":"code","3b8b34d9":"code","53110c2c":"markdown","6abf14de":"markdown"},"source":{"9350ecb0":"match = 0\nnonmatch = 0","d5380303":"import os\nimport random","453834ed":"tot_size = len(os.listdir('\/kaggle\/input\/captcha-images\/'))\nprint(tot_size)\nnum = random.randint(0, tot_size)\nprint(num)","38aaf306":"import random\nrandomlist = []\nfor i in range(0, 500):\n    n = random.randint(0,tot_size)\n    randomlist.append(n)\nprint(randomlist)","9ba3dd02":"for m in randomlist:\n    import os\n    import torch\n    import pandas as pd\n    import numpy as np\n    from torch.utils.data import Dataset, random_split, DataLoader\n    from PIL import Image\n    import torchvision.models as models\n    from tqdm.notebook import tqdm\n    import torchvision.transforms as T\n    from sklearn.metrics import f1_score\n    import torch.nn.functional as F\n    import torch.nn as nn\n    from torchvision.utils import make_grid\n    from torchvision.datasets import ImageFolder\n    import random\n    import PIL\n\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n\n\n\n    def seed_everything(seed=2020):\n        random.seed(seed)\n        os.environ['PYTHONHASHSEED'] = str(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n\n    seed_everything(42)\n    print('ENVIRONMENT READY')\n\n\n    dataset = ImageFolder(root='\/kaggle\/input\/captchas-segmented\/data')\n\n    dataset_size = len(dataset)\n    dataset_size\n\n    # Data augmentation\n    imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\n    train_tfms = T.Compose([\n        T.RandomCrop(128, padding=8, padding_mode='reflect'),\n         #T.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n        T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n        T.Resize((128, 128)),\n        T.RandomHorizontalFlip(), \n        T.RandomRotation(10),\n        T.ToTensor(), \n         T.Normalize(*imagenet_stats,inplace=True), \n        #T.RandomErasing(inplace=True)\n    ])\n\n    valid_tfms = T.Compose([\n         T.Resize((128, 128)), \n        T.ToTensor(), \n         T.Normalize(*imagenet_stats)\n    ])\n\n    def get_default_device():\n        \"\"\"Pick GPU if available, else CPU\"\"\"\n        if torch.cuda.is_available():\n            return torch.device('cuda')\n        else:\n            return torch.device('cpu')\n\n    def to_device(data, device):\n        \"\"\"Move tensor(s) to chosen device\"\"\"\n        if isinstance(data, (list,tuple)):\n            return [to_device(x, device) for x in data]\n        return data.to(device, non_blocking=True)\n\n    class DeviceDataLoader():\n        \"\"\"Wrap a dataloader to move data to a device\"\"\"\n        def __init__(self, dl, device):\n            self.dl = dl\n            self.device = device\n\n        def __iter__(self):\n            \"\"\"Yield a batch of data after moving it to device\"\"\"\n            for b in self.dl: \n                yield to_device(b, self.device)\n\n        def __len__(self):\n            \"\"\"Number of batches\"\"\"\n            return len(self.dl)\n\n    device = get_default_device()\n    device\n\n\n    test_size = 200\n    nontest_size = len(dataset) - test_size\n\n    nontest_df, test_df = random_split(dataset, [nontest_size, test_size])\n    len(nontest_df), len(test_df)\n\n    val_size = 200\n    train_size = len(nontest_df) - val_size\n\n    train_df, val_df = random_split(nontest_df, [train_size, val_size])\n    len(train_df), len(val_df)\n\n    test_df.dataset.transform = valid_tfms\n    val_df.dataset.transform = valid_tfms\n\n    train_df.dataset.transform = train_tfms\n\n\n    batch_size = 64\n\n    train_dl = DataLoader(train_df, batch_size, shuffle=True, \n                          num_workers=3, pin_memory=True)\n    val_dl = DataLoader(val_df, batch_size*2, \n                        num_workers=2, pin_memory=True)\n    test_dl = DataLoader(test_df, batch_size*2, \n                        num_workers=2, pin_memory=True)\n\n\n    train_dl = DeviceDataLoader(train_dl, device)\n    val_dl = DeviceDataLoader(val_dl, device)\n    test_dl = DeviceDataLoader(test_dl, device)\n\n\n\n    diction = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A',\n           11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K',\n           21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U',\n           31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e',\n           41: 'f', 42: 'g', 43: 'h', 44: 'i', 45: 'j', 46: 'k', 47: 'l', 48: 'm', 49: 'n', 50: 'o', \n           51: 'p', 52: 'q', 53: 'r', 54: 's', 55: 't', 56: 'u', 57: 'v', 58: 'w', 59: 'x', 60: 'y',\n           61: 'z'}\n\n\n\n    def accuracy(outputs, labels):\n        _, preds = torch.max(outputs, dim=1)\n        return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\n\n    class ImageClassificationBase(nn.Module):\n        def training_step(self, batch):\n            images, labels = batch \n            out = self(images)                  # Generate predictions\n            loss = F.cross_entropy(out, labels) # Calculate loss\n            return loss\n\n        def validation_step(self, batch):\n            images, labels = batch \n            out = self(images)                    # Generate predictions\n            loss = F.cross_entropy(out, labels)   # Calculate loss\n            acc = accuracy(out, labels)           # Calculate accuracy\n            return {'val_loss': loss.detach(), 'val_acc': acc}\n\n        def validation_epoch_end(self, outputs):\n            batch_losses = [x['val_loss'] for x in outputs]\n            epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n            batch_accs = [x['val_acc'] for x in outputs]\n            epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n            return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\n        def epoch_end(self, epoch, result):\n            print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n                epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n\n    class CnnModel2(ImageClassificationBase):\n        def __init__(self):\n            super().__init__()\n            # Use a pretrained model\n            self.network = models.wide_resnet101_2(pretrained=True)\n            # Replace last layer\n            num_ftrs = self.network.fc.in_features\n            self.network.fc = nn.Linear(num_ftrs,62)\n\n        def forward(self, xb):\n            return torch.sigmoid(self.network(xb))\n\n    model = to_device(CnnModel2(), device)\n    @torch.no_grad()\n    def evaluate(model, val_loader):\n        model.eval()\n        outputs = [model.validation_step(batch) for batch in val_loader]\n        return model.validation_epoch_end(outputs)\n\n    model = to_device(CnnModel2(), device)\n    model.load_state_dict(torch.load('\/kaggle\/input\/captcha-solver-ml\/captcha.pth'))\n\n    print(evaluate(model, val_dl)['val_acc'])\n\n    def predict_image(img, model):\n        xb = to_device(img.unsqueeze(0), device)\n        yb = model(xb)\n        _, preds  = torch.max(yb, dim=1)\n        return preds[0].item()\n\n    import cv2\n    import os\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import random\n\n\n\n\n    import os\n    import torch\n    import pandas as pd\n    import numpy as np\n    from torch.utils.data import Dataset, random_split, DataLoader\n    from PIL import Image\n    import torchvision.models as models\n    from tqdm.notebook import tqdm\n    import torchvision.transforms as T\n    from sklearn.metrics import f1_score\n    import torch.nn.functional as F\n    import torch.nn as nn\n    from torchvision.utils import make_grid\n    from torchvision.datasets import ImageFolder\n    import random\n    import PIL\n\n    import matplotlib.pyplot as plt\n    %matplotlib inline\n\n\n\n\n    # Data augmentation\n    imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\n    train_tfms = T.Compose([\n        T.RandomCrop(128, padding=8, padding_mode='reflect'),\n         #T.RandomResizedCrop(256, scale=(0.5,0.9), ratio=(1, 1)), \n        T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n        T.Resize((128, 128)),\n        T.RandomHorizontalFlip(), \n        T.RandomRotation(10),\n        T.ToTensor(), \n         T.Normalize(*imagenet_stats,inplace=True), \n        #T.RandomErasing(inplace=True)\n    ])\n\n    valid_tfms = T.Compose([\n         T.Resize((128, 128)), \n        T.ToTensor(), \n         T.Normalize(*imagenet_stats)\n    ])\n\n\n\n    diction = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A',\n           11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K',\n           21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U',\n           31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e',\n           41: 'f', 42: 'g', 43: 'h', 44: 'i', 45: 'j', 46: 'k', 47: 'l', 48: 'm', 49: 'n', 50: 'o', \n           51: 'p', 52: 'q', 53: 'r', 54: 's', 55: 't', 56: 'u', 57: 'v', 58: 'w', 59: 'x', 60: 'y',\n           61: 'z'}\n\n\n    alli = list(os.listdir('\/kaggle\/input\/captcha-images\/'))\n    file = alli[m]\n    #print(file)\n    try:\n        solution = file.split('.')[0]\n        hi = cv2.imread('\/kaggle\/input\/captcha-images\/' + file)\n        # convert to RGB\n\n        #plt.imshow(hi, cmap=\"gray\")\n        #plt.show()\n\n        # convert to RGB\n        image = cv2.cvtColor(hi, cv2.COLOR_BGR2RGB)\n        # convert to grayscale\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n        # create a binary thresholded image\n        _, binary = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)\n        # show it\n        #plt.imshow(binary, cmap=\"gray\")\n        #plt.show()\n\n        # find the contours from the thresholded image\n        contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        # draw all contours\n        image = cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n\n        # show the image with the drawn contours\n        #plt.imshow(image)\n        #plt.show()\n\n        x = {}\n        for m in range(len(contours)):\n            mini = 1000\n            for k in range(len(contours[m])):\n                first = contours[m][k][0][0]\n                if first < mini:\n                    mini = first\n            mini1 = mini\n            #print(mini1)\n\n            mini = 1000\n            for k in range(len(contours[m])):\n                first = contours[m][k][0][1]\n                if first < mini:\n                    mini = first\n            mini2 = mini\n            #print(mini2)\n\n            maxi = 0\n            for k in range(len(contours[m])):\n                first = contours[m][k][0][1]\n                if first > maxi:\n                    maxi = first\n            maxi2 = maxi\n            #print(maxi2)\n\n            maxi = 0\n            for k in range(len(contours[m])):\n                first = contours[m][k][0][0]\n                if first > maxi:\n                    maxi = first\n            maxi1 = maxi\n            #print(maxi1)\n            x[m] = maxi2 - mini2\n\n        biggie = sorted(x, key=x.get)\n\n        s = {}\n        def plotting(num):\n            m = biggie[num]\n            mini = 1000\n            for k in range(len(contours[m])):\n                first = contours[m][k][0][0]\n                if first < mini:\n                    mini = first\n            mini1 = mini\n            #print(mini1)\n\n            mini = 1000\n            for k in range(len(contours[m])):\n                first = contours[m][k][0][1]\n                if first < mini:\n                    mini = first\n            mini2 = mini\n           # print(mini2)\n\n            maxi = 0\n            for k in range(len(contours[m])):\n                first = contours[m][k][0][1]\n                if first > maxi:\n                    maxi = first\n            maxi2 = maxi\n            #print(maxi2)\n\n            maxi = 0\n            for k in range(len(contours[m])):\n                first = contours[m][k][0][0]\n                if first > maxi:\n                    maxi = first\n            maxi1 = maxi\n            #print(maxi1)\n            ret = [mini2, maxi2, mini1, maxi1]\n            s[num] = mini1\n            return ret\n\n        fig, axs = plt.subplots(2, 5)\n        wow = plotting(-1)\n        # axs[0, 0].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[0,0].axis('off')\n        wow = plotting(-2)\n        # axs[0, 1].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[0,1].axis('off')\n        wow = plotting(-3)\n        #axs[0,2].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[0,2].axis('off')\n        wow = plotting(-4)\n        #axs[0,3].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[0,3].axis('off')\n        wow = plotting(-5)\n        #axs[0,4].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[0,4].axis('off')\n        wow = plotting(-6)\n        # axs[1,0].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[1,0].axis('off')\n        wow = plotting(-7)\n        #axs[1,1].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[1,1].axis('off')\n        wow = plotting(-8)\n        #axs[1,2].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[1,2].axis('off')\n        wow = plotting(-9)\n        #axs[1,3].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[1,3].axis('off')\n        wow = plotting(-10)\n        #axs[1,4].imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n        axs[1,4].axis('off')\n        wow = plotting(-11)\n\n\n        siggie = sorted(s, key=s.get)\n\n        def checkforerror(wow):\n            white = cv2.countNonZero(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2])\n            total = (binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2]).shape[0] * (binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2]).shape[1]\n            div = white\/total\n            if div > 0.63: \n                if (wow[1] - wow[0]) - (wow[3] - wow[2]) > -5:\n                    return True\n            elif div < 0.29:\n                return True\n\n            else: return False\n        def checkforerrorout(wow):\n            white = cv2.countNonZero(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2])\n            total = (binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2]).shape[0] * (binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2]).shape[1]\n            div = white\/total\n            return div\n        def checkfordoubles(wow):\n            if (wow[1] - wow[0]) - (wow[3] - wow[2]) < -4: \n                if checkforerrorout(wow) < 0.56: return True\n            elif (wow[1] - wow[0]) - (wow[3] - wow[2]) < 1:\n                if checkforerrorout(wow) < 0.40: return True\n            else: return False\n\n\n\n\n        pos = 0\n        a = 0\n        im = 0\n        desired = 10\n        fig, axs = plt.subplots(2, 5)\n        first = False\n        while a < desired:\n            try:\n                idx = pos\n                #print('*' * 40)\n                #print('pos', pos, 'true value is ', solution[pos])\n\n                foldername = str('\/kaggle\/working\/%s' % pos)\n                #print(idx, foldername)\n                if os.path.isdir(foldername) == False:\n                    os.mkdir(foldername)\n                #print('a = ', a, 'desired = ', desired)\n\n                n1 = pos \/\/ 5\n                n2 = pos % 5\n                #print('using position', n1, n2)\n                wow = plotting(siggie[im])\n                #print('trying to plot ', im, 'checking for errors...')\n                err = checkforerror(wow)\n                errs = checkfordoubles(wow)\n                #print('% = ', checkforerrorout(wow))\n                print(err, errs)\n                if err:\n                    #print('Error 1 at', a)\n                    #plt.imshow(binary[wow[0]-2:wow[1] + 2, wow[2]-2:wow[2] + half +7], cmap = 'gray')\n                    #inp = str(input('Skip this image? '))\n                    im += 1\n                    #print('im bumped to', im)\n                    wow = plotting(siggie[im])\n                    #print('trying to plot ', im, 'checking for errors...')\n                    err = checkforerror(wow)\n                    errs = checkfordoubles(wow)\n                    #print('% = ', checkforerrorout(wow))\n                    if errs:\n\n\n                        #print('Error 2 at bumped image')\n                        if first == False:\n                            fig = plt.figure()\n                            half = abs(wow[0] - wow[1]) \/\/ 2\n                            plt.imshow(binary[wow[0]-2:wow[1] + 2, wow[2]-2:wow[2] + half +7], cmap = 'gray')\n\n                            plt.axis('off')\n                            fig.savefig('\/kaggle\/working\/%s\/%s.png' %(pos, idx), dpi=fig.dpi, bbox_inches='tight', pad_inches=0, transparent=True)\n\n                            im -= 1\n                            first = True\n                        else:\n                            fig = plt.figure()\n                            half = abs(wow[0] - wow[1]) \/\/ 2\n                            plt.imshow(binary[wow[0]-2:wow[1] + 2, wow[2] + half + 7:wow[3]+2], cmap = 'gray')\n\n                            plt.axis('off')\n                            fig.savefig('\/kaggle\/working\/%s\/%s.png' %(pos, idx), dpi=fig.dpi, bbox_inches='tight', pad_inches=0, transparent=True)\n                            first = False\n\n\n\n                    else:\n                        #print('No errors in bumped image')\n                        fig = plt.figure()\n                        plt.imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n\n                        plt.axis('off')\n                        fig.savefig('\/kaggle\/working\/%s\/%s.png' %(pos, idx), dpi=fig.dpi, bbox_inches='tight', pad_inches=0, transparent=True)\n                elif errs:\n                    #print('Error 2 at', a)\n                    if first == False:\n                        fig = plt.figure()\n                        half = abs(wow[0] - wow[1]) \/\/ 2\n                        plt.imshow(binary[wow[0]-2:wow[1] + 2, wow[2]-2:wow[2] + half +8], cmap = 'gray')\n\n                        plt.axis('off')\n                        fig.savefig('\/kaggle\/working\/%s\/%s.png' %(pos, idx), dpi=fig.dpi, bbox_inches='tight', pad_inches=0, transparent=True)\n                        im -= 1\n                        first = True\n                    else:\n                        fig = plt.figure()\n\n                        plt.imshow(binary[wow[0]-2:wow[1] + 2, wow[2] + half + 8:wow[3]+2], cmap = 'gray')\n\n                        plt.axis('off')\n                        fig.savefig('\/kaggle\/working\/%s\/%s.png' %(pos, idx), dpi=fig.dpi, bbox_inches='tight', pad_inches=0, transparent=True)\n                        xx = predict_image(fig, model)\n                        print(xx)\n\n                        first = False\n\n                else:\n                   # print('No errors found!')\n                    fig = plt.figure()\n                    plt.imshow(binary[wow[0]-2:wow[1]+2, wow[2]-2:wow[3]+2], cmap = 'gray')\n                    plt.axis('off')\n                    fig.savefig('\/kaggle\/working\/%s\/%s.png' %(pos, idx), dpi=fig.dpi, bbox_inches='tight', pad_inches=0, transparent=True)\n                    #xx = predict_image(fig, model)\n                    #print(xx)\n                    #print('DONE PLOTTING - im', im)\n\n\n                a += 1\n                pos += 1\n               # print('bumped pos to ', pos)\n                im += 1\n            except:\n               # print('fail case')\n                a += 1\n                continue\n        plt.show()\n\n\n        test_dataset = ImageFolder(root='\/kaggle\/working\/', transform = valid_tfms)\n\n        test_dataset_size = len(test_dataset)\n        test_dataset_size\n\n\n        predicted = ''\n\n        for k in range(10):\n            img_seed = k\n            img = test_dataset[img_seed][0]\n            label = solution[img_seed]\n            plt.imshow(img[0], cmap='gray')\n            #print(img.shape)\n            #print('Label:', label, ', Predicted:', diction[predict_image(img, model)])\n            predicted += (diction[predict_image(img, model)])\n\n        plt.imshow(hi, cmap=\"gray\")\n        plt.show()\n\n        #print(predicted, solution)\n        \n    except: \n        predicted = 'isuck'\n\n    if predicted == solution:\n        match += 1\n    else: nonmatch += 1","a95a3d77":"match, nonmatch","3b8b34d9":"print('The final accuracy is', match\/500)","53110c2c":"### Conclusion\n\nOverall, although the accuracy for solving any single CAPTCHA correctly is approximately 25%, considering CAPTCHA systems will give you an indefinite number of retries, an accuracy of 25% is actually very good. This means that within 10 attempts, there is a 94.4% chance of successfully bypassing the CAPTCHA. \n\nThank you for all who made it through all four notebooks! As always please leave an upvote on this notebook if you enjoyed my work, I really appreciate it! I had a great time developing this program. If you want to stay updated on my future work, be sure to follow me on Kaggle. \nCheers,\nSergei Issaev","6abf14de":"# Captchas Evaluation\n## By Sergei Issaev\n### Introduction\n\nThis notebook is part of a pipeline tha  takes in CAPTCHA images and outputs the solution. This is the fourth notebook in the four part series. In this notebook, we set up a loop over 500 random CAPTCHAS, and add up the number of correctly solved puzzles to determine an accuracy percentage. For a more complete description, please see my article published at: https:\/\/medium.com\/@sergei740.\n### Import Libraries \ud83d\udcda\u2b07\n"}}