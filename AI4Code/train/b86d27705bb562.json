{"cell_type":{"9bbf51be":"code","d71b7d9f":"code","36f9677e":"code","2c81eeab":"code","84df7305":"code","4d9f71a3":"code","a876a2ba":"code","292c1fa2":"code","541fd14e":"code","30e49b0f":"code","1a6c997a":"code","a202e99e":"code","2c9e6616":"code","d3b709a6":"code","c201e2a5":"code","1b91e3a9":"code","a494f1e4":"code","a157ec2c":"code","84bad20f":"code","d5bc9d4e":"code","7ac19258":"code","61ca810f":"code","07a30612":"code","971fa97e":"code","6b66d2ff":"code","18eb072f":"code","5359966b":"code","c4457d63":"code","d5c3c1cc":"code","31bce995":"code","81b03fe7":"code","1d227154":"code","29ab81cd":"code","8b50061b":"code","0721e5ab":"code","842606d4":"code","05caba3c":"code","dab08fcb":"code","04fd4a5c":"code","675d84fd":"code","e84516e5":"code","028f9b43":"code","2febaf5e":"code","a0dae116":"code","50c619b3":"code","4ff102e9":"code","b727e297":"code","30958e1e":"code","cb6ee551":"code","2dd09ae3":"markdown","4e16ff15":"markdown","65a269d6":"markdown","8bbe7af1":"markdown","a5c2d751":"markdown","e57448b4":"markdown","bdb1c7af":"markdown","b63d4c57":"markdown","8fa24da7":"markdown","88891dd3":"markdown","2af339c1":"markdown","13376cd6":"markdown","1892f262":"markdown"},"source":{"9bbf51be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d71b7d9f":"import pandas as pd\nfrom sklearn.datasets import load_iris\niris= load_iris()","36f9677e":"iris.feature_names","2c81eeab":"iris.target_names","84df7305":"df=pd.DataFrame(iris.data, columns=iris.feature_names)\ndf.head()","4d9f71a3":"df.shape","a876a2ba":"df['target']=iris.target\ndf.head()","292c1fa2":"df[df.target==1]","541fd14e":"df[df.target==2]","30e49b0f":"df['flowername']=df.target.apply(lambda x: iris.target_names[x])\ndf.head()","1a6c997a":"df0 = df[:50]\ndf1 = df[50:100]\ndf2 = df[100:]","a202e99e":"import matplotlib.pyplot as plt\n%matplotlib inline","2c9e6616":"#Sepal length vs Sepal Width\nplt.figure(figsize=(15,7))\nplt.xlabel('Sepal Length')\nplt.ylabel('Sepal Width')\nplt.scatter(df0['sepal length (cm)'], df0['sepal width (cm)'],color=\"green\",marker='+',label='setosa')\nplt.scatter(df1['sepal length (cm)'], df1['sepal width (cm)'],color=\"blue\",marker='.',label='versicolor')\nplt.scatter(df2['sepal length (cm)'],df1['sepal width (cm)'], color='red',marker='*',label='virginica')\nplt.legend()\nplt.show()","d3b709a6":"#Petal length vs Pepal Width \nplt.figure(figsize=(15,7))\nplt.xlabel('Petal Length')\nplt.ylabel('Petal Width')\nplt.scatter(df0['petal length (cm)'], df0['petal width (cm)'],color=\"green\",marker='+', label='setosa')\nplt.scatter(df1['petal length (cm)'], df1['petal width (cm)'],color=\"blue\",marker='.', label='versicolor')\nplt.scatter(df2['petal length (cm)'], df2['petal width (cm)'], color= 'red',marker='*',label='virginica')\nplt.legend()\nplt.show()","c201e2a5":"from sklearn.model_selection import train_test_split","1b91e3a9":"X= df.drop(['target','flowername'],axis='columns')\ny= df.target","a494f1e4":"X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2, random_state=3)","a157ec2c":"X_train.shape\n","84bad20f":"y_train.shape","d5bc9d4e":"from sklearn.neighbors import KNeighborsClassifier\nknn= KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train,y_train)\n","7ac19258":"knn.score(X_test,y_test)","61ca810f":"from sklearn.metrics import confusion_matrix\ny_pred=knn.predict(X_test)\nmatrix= confusion_matrix(y_test, y_pred)#confusion_matrix(truth, prediction)\nmatrix","07a30612":"import seaborn as sns\nplt.figure(figsize=(10,8))\nsns.heatmap(matrix, annot= True)\nplt.xlabel('predict')\nplt.ylabel('truth')","971fa97e":"from sklearn.metrics import classification_report\nprint( classification_report(y_test,y_pred))","6b66d2ff":"from sklearn.datasets import load_digits\ndigits=load_digits()","18eb072f":"#print yhe keys and DECR of the dataset:\nprint(digits.keys())","5359966b":"print(digits.DESCR)","c4457d63":"# print the shape of the images and data keys:\nprint(digits.images.shape)","d5c3c1cc":"print(digits.data.shape)","31bce995":"#display digit 1010\nplt.imshow(digits.images[1010], cmap=plt.cm.gray_r,interpolation='nearest')\nplt.show()","81b03fe7":"digits.feature_names","1d227154":"digits.target_names","29ab81cd":"df=pd.DataFrame(digits.data, columns=digits.feature_names)\ndf.head()","8b50061b":"df['target']=digits.target\ndf.head()","0721e5ab":"from sklearn.model_selection import train_test_split","842606d4":"X=df.drop('target',axis='columns')","05caba3c":"y= df['target']","dab08fcb":"X_train, X_test,y_train, y_test =train_test_split(X,y, test_size= 0.3, random_state= 3)","04fd4a5c":"X_train.shape","675d84fd":"y_train.shape","e84516e5":"from sklearn.neighbors import KNeighborsClassifier\nknn= KNeighborsClassifier(n_neighbors=7)","028f9b43":"knn.fit(X_train,y_train)","2febaf5e":"knn.score(X_test,y_test)","a0dae116":"import numpy as np\nneighbors=np.arange(1,9)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))","50c619b3":"#loop over different values of k\nfor i, k in enumerate(neighbors):\n    # set up a KNN Classifier with k neighbors: knn\n    knn= KNeighborsClassifier(n_neighbors=k)\n    # fit the classifier to the training data:\n    knn.fit(X_train, y_train)\n    # compute accuracy on the training set:\n    train_accuracy[i]= knn.score(X_train, y_train)\n    # compute accuracy on the testing set:\n    test_accuracy[i] = knn.score(X_test, y_test)\n# Generate plot:\nplt.title('KNN: Varying Number of Neighbor')\nplt.plot(neighbors, test_accuracy, label='Test Accuracy')\nplt.plot(neighbors, train_accuracy, label='Training Accuracy')\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accurary')\nplt. show()\n    ","4ff102e9":"neighbor= np.arrange(1,9)\n","b727e297":"from sklearn.metrics import confusion_matrix\ny_pred= knn.predict(X_test)\nmatrix=confusion_matrix(y_test,y_pred)\nmatrix","30958e1e":"plt.figure(figsize=(15,7))\nsns.heatmap(matrix,annot=True)\nplt.xlabel('Predicted')\nplt.ylabel('Truth')\nplt.show()","cb6ee551":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","2dd09ae3":"# ConFusion Matrix","4e16ff15":"## Credit: DataCamp & Codebasics","65a269d6":"# Print Classification Report","8bbe7af1":"# OverFitting and UnderFitting Model","a5c2d751":"# Create K Nearest Neighbor Classification (KNN)","e57448b4":"Interpretation:\n\nThere are 10 times the machine predicts the species is setora ( 0) and it's correct.\n\nThere are 9 times the machine predicts the species is versicolor( 1) and it's correct.\n\nThere are 10 times the machine predicts the species is virginica (2) and it's correct.\n\nThere are 1 time tha machine predict the species is virginica(2) and the true species is versiscolor(1)\n","bdb1c7af":"# Case Study 2: Digits Data Set","b63d4c57":"# KNN ( K Nearest Neighbors) Classification: Machine Tutorial Using Python Sklearn","8fa24da7":"# Train Test Split Data","88891dd3":"# Plot Confusion Matrix","2af339c1":"# Case Study 1: Iris Data","13376cd6":"# Create KNN","1892f262":"## Classification report"}}