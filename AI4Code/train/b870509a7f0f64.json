{"cell_type":{"5d445024":"code","c9c12958":"code","87db21be":"code","e9414849":"code","f7b39463":"code","4dd84c37":"code","00947bb0":"code","22ad89af":"code","7ee3ec78":"code","3ed7c707":"code","2ddb0e4d":"code","baf516d3":"code","54deba0e":"code","cb008313":"code","5e5a9ae1":"code","e6c0cc91":"code","9142025e":"code","1243e258":"code","464db0cd":"code","e54f3015":"code","ca93f5df":"code","4f28cfa6":"code","57f88997":"code","3c9670f2":"code","700c8bc8":"code","6208593b":"code","dc3c3142":"code","11e63421":"code","525b40aa":"code","efa6954e":"code","55352437":"code","bcc0263b":"code","bac2563d":"code","a8353241":"code","dcc2c8a7":"code","af67113b":"code","648514d2":"markdown","c92304a7":"markdown","841c52f0":"markdown","bc314233":"markdown","a0bf5dd8":"markdown","a6a15b94":"markdown","152e4d3a":"markdown","0ffb46e3":"markdown","ba534f9d":"markdown","d7f858e3":"markdown","3a821f9c":"markdown","a4f26d81":"markdown","0f497cb7":"markdown","9ebf6bc1":"markdown","de2d00bb":"markdown","88802898":"markdown","f017d2a1":"markdown","3464b6c9":"markdown","0fc714a4":"markdown","3c88c697":"markdown"},"source":{"5d445024":"# some basic imports\nimport pandas as pd\nimport numpy as np\nimport os\nimport cv2\n# visualization\nimport matplotlib.pyplot as plt\n# plotly offline imports\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, iplot\nfrom plotly import subplots\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.graph_objs import *\nfrom plotly.graph_objs.layout import Margin, YAxis, XAxis\ninit_notebook_mode()\n# frequent pattern mining\nfrom mlxtend.frequent_patterns import fpgrowth\n# path where all the training images are\nimg_path = '..\/input\/train_images\/'","c9c12958":"pd.read_csv('..\/input\/train.csv').head()","87db21be":"# load full data and label no mask as -1\ntrain_df = pd.read_csv('..\/input\/train.csv').fillna(-1)","e9414849":"# image id and class id are two seperate entities and it makes it easier to split them up in two columns\ntrain_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntrain_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n# lets create a dict with class id and encoded pixels and group all the defaults per image\ntrain_df['ClassId_EncodedPixels'] = train_df.apply(lambda row: (row['ClassId'], row['EncodedPixels']), axis = 1)\ngrouped_EncodedPixels = train_df.groupby('ImageId')['ClassId_EncodedPixels'].apply(list)","f7b39463":"print('Total number of images: %s' % len(train_df['ImageId'].unique()))\nprint('Images with at least one label: %s' % len(train_df[train_df['EncodedPixels'] != -1]['ImageId'].unique()))\nprint('Total instance or examples of defects: %s' % len(train_df[train_df['EncodedPixels'] != -1]))","4dd84c37":"# picking up 10 examples with at two faults for visualization\nexamples = []\nfor r in grouped_EncodedPixels.iteritems():\n    if (len([x[1] for x in r[1] if x[1] != -1]) == 2) and (len(examples) < 10):\n        examples.append(r[0])","00947bb0":"# from https:\/\/www.kaggle.com\/robertkag\/rle-to-mask-converter\ndef rle_to_mask(rle_string, height, width):\n    '''\n    convert RLE(run length encoding) string to numpy array\n\n    Parameters: \n    rle_string (str): string of rle encoded mask\n    height (int): height of the mask\n    width (int): width of the mask \n\n    Returns: \n    numpy.array: numpy array of the mask\n    '''\n    \n    rows, cols = height, width\n    \n    if rle_string == -1:\n        return np.zeros((height, width))\n    else:\n        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n        img = np.zeros(rows*cols, dtype=np.uint8)\n        for index, length in rle_pairs:\n            index -= 1\n            img[index:index+length] = 255\n        img = img.reshape(cols,rows)\n        img = img.T\n        return img","22ad89af":"# visualize steel image with four classes of faults in seperate columns\ndef viz_two_class_from_path(img_path, img_id, encoded_masks):\n    '''\n    visualize an image with two types of defects by plotting them on two columns\n    with the defect overlayed on top of the original image.\n\n    Parameters: \n    img_path (str): path of images\n    img_id (str): image id or filename of the path\n    encoded_masks (list): a list of strings of encoded masks \n    \n    Returns: \n    matplotlib image plot in columns for two classes iwth defect\n    '''\n    \n    img = cv2.imread(os.path.join(img_path, img_id))\n    fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(20,10))\n    cmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n    axid = 0\n    for idx, encoded_mask in enumerate(encoded_masks):\n        class_id = idx + 1\n        if encoded_mask == -1:\n            pass\n        else:\n            mask_decoded = rle_to_mask(encoded_mask, 256, 1600)\n            ax[axid].get_xaxis().set_ticks([])\n            ax[axid].get_yaxis().set_ticks([])\n            ax[axid].text(0.25, 0.25, 'Image Id: %s - Class Id: %s' % (img_id, class_id), fontsize=12)\n            ax[axid].imshow(img)\n            ax[axid].imshow(mask_decoded, alpha=0.15, cmap=cmaps[idx])\n            axid += 1","7ee3ec78":"# visualize the image we picked up earlier with mask\nfor example in examples:\n    img_id = examples\n    mask_1, mask_2, mask_3, mask_4 = grouped_EncodedPixels[example]\n    masks = [mask_1[1], mask_2[1], mask_3[1], mask_4[1]]\n    viz_two_class_from_path(img_path, example, masks)","3ed7c707":"# visualize steel image with four classes of faults in seperate columns\ndef viz_one_class_from_path(img_path, img_id, mask, class_id, text=None):\n    '''\n    visualize an image with two types of defects by plotting them on two columns\n    with the defect overlayed on top of the original image.\n\n    Parameters: \n    img_path (str): path of images\n    img_id (str): image id or filename of the path\n    encoded_mask (str): RLE mask\n    class_id (str): class id of the defect\n    \n    Returns: \n    matplotlib image plot in columns for two classes with defect\n    '''\n    img = cv2.imread(os.path.join(img_path, img_id))\n    mask_decoded = rle_to_mask(mask, 256, 1600)\n    fig, ax = plt.subplots(figsize=(20,10))\n    cmaps = [\"Reds\", \"Blues\", \"Greens\", \"Purples\"]\n    ax.get_xaxis().set_ticks([])\n    ax.get_yaxis().set_ticks([])\n    if text: \n        ax.text(0.25, 0.25, text, fontsize=12)\n    ax.imshow(img)\n    ax.imshow(mask_decoded, alpha=0.15, cmap=cmaps[int(class_id)-1])\n\ndef viz_per_class(train_df, class_id, sample_size=5):\n    class_samples = train_df[(train_df['ClassId']==class_id)&(train_df['EncodedPixels']!=-1)].sample(sample_size)\n    class_img_ids = class_samples['ImageId'].values\n    class_encoded_masks = class_samples['EncodedPixels'].values\n    \n    for img_id, mask in zip(class_img_ids, class_encoded_masks):\n        viz_one_class_from_path(img_path, img_id, mask, class_id)","2ddb0e4d":"viz_per_class(train_df, '1', 2)","baf516d3":"viz_per_class(train_df, '2', 2)","54deba0e":"#### Class 3","cb008313":"viz_per_class(train_df, '3', 2)","5e5a9ae1":"viz_per_class(train_df, '4', 2)","e6c0cc91":"# calculate sum of the pixels for the mask per class id\ntrain_df['mask_pixel_sum'] = train_df.apply(lambda x: rle_to_mask(x['EncodedPixels'], width=1600, height=256).sum(), axis=1)","9142025e":"# calculate the number of pictures without any label what so ever\nannotation_count = grouped_EncodedPixels.apply(lambda x: 1 if len([1 for y in x if y[1] != -1]) > 0 else 0).value_counts()\nannotation_count_labels = ['No Label' if x == 0 else 'Label' for x in annotation_count.index]\n# calculate number of defects per image \ndefects_count_df = grouped_EncodedPixels.apply(lambda x: len([1 for y in x if y[1] != -1]))\ndefect_count_per_image = defects_count_df.value_counts()\ndefect_count_labels = defect_count_per_image.index","1243e258":"trace0 = Bar(x=annotation_count_labels, y=annotation_count, name = 'Labeled vs Not Labeled')\ntrace1 = Bar(x=defect_count_labels, y=defect_count_per_image, name = 'Defects Per Image')\nfig = subplots.make_subplots(rows=1, cols=2)\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 2)\nfig['layout'].update(height=400, width=900, title='Defect Labels and Defect Frequency Per Image')\niplot(fig)","464db0cd":"# print ten samples of instances without any labels\nten_rand_samples = defects_count_df[defects_count_df == 0].sample(10).index\nfor samp in ten_rand_samples:\n    viz_one_class_from_path(img_path, samp, -1, 0)","e54f3015":"class_ids = ['1','2','3','4']\nmask_count_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0)]['mask_pixel_sum'].count() for class_id in class_ids]\npixel_sum_per_class = [train_df[(train_df['ClassId']==class_id)&(train_df['mask_pixel_sum']!=0)]['mask_pixel_sum'].sum() for class_id in class_ids]","ca93f5df":"# Create subplots: use 'domain' type for Pie subplot\nfig = subplots.make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(Pie(labels=class_ids, values=mask_count_per_class, name=\"Mask Count\"), 1, 1)\nfig.add_trace(Pie(labels=class_ids, values=pixel_sum_per_class, name=\"Pixel Count\"), 1, 2)\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Steel Defect Mask & Pixel Count\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Mask', x=0.18, y=0.5, font_size=20, showarrow=False),\n                 dict(text='Pixel', x=0.80, y=0.5, font_size=20, showarrow=False)])\nfig.show()","4f28cfa6":"# plot a histogram and boxplot combined of the mask pixel sum per class Id\nfig = px.histogram(train_df[train_df['mask_pixel_sum']!=0][['ClassId','mask_pixel_sum']], \n                   x=\"mask_pixel_sum\", y=\"ClassId\", color=\"ClassId\", marginal=\"box\")\n\nfig['layout'].update(title='Histogram and Boxplot of Sum of Mask Pixels Per Class')\n\nfig.show()","57f88997":"def count_segments(mask):\n    \"\"\"Given a mask, count the number of regions.\n\n    Parameters:\n    mask (numpy.array): numpy array of the mask\n\n    Returns:\n    int: number of segments\n    \"\"\"\n    # if the mask is empty return zero\n    if mask.sum() == 0:\n        return 0\n    else:\n        # use open cv and threshold mechanism to calculate contours\n        _, threshold = cv2.threshold(mask, 240, 255, cv2.THRESH_BINARY)\n        _, contours = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        \n        # get the segment count\n        for c in contours:\n            segments_count = len(c)\n\n        return segments_count","3c9670f2":"# use the count_segments function to conver encoded mask to mask and count the number of segments per defect\ntrain_df['segments'] = train_df.apply(lambda r: count_segments(rle_to_mask(r['EncodedPixels'], height=256, width=1600)),axis=1)","700c8bc8":"# use the count_segments function to conver encoded mask to mask and count the number of segments per defect\ntrain_df['avg_mask_per_seg'] = (train_df['mask_pixel_sum'] \/ train_df['segments']).fillna(0)","6208593b":"# lets print out a few examples and visually inspect if our function is working\nfor segments in range(0,6):\n    samp = train_df[train_df['segments']==segments].sample(1)\n    encoded_pixels = samp['EncodedPixels'].values[0]\n    image_id = samp['ImageId'].values[0]\n    class_id = samp['ClassId'].values[0]\n    segments = samp['segments'].values[0]\n    viz_one_class_from_path(img_path, image_id, encoded_pixels, class_id, text='Number of Segments: %s' % segments)","dc3c3142":"fig = px.scatter(train_df[train_df['mask_pixel_sum']!=0], x=\"mask_pixel_sum\", y=\"segments\", color=\"ClassId\", size=\"avg_mask_per_seg\", hover_data=[\"avg_mask_per_seg\"])\nfig.show()","11e63421":"fig = px.scatter(train_df[train_df['mask_pixel_sum']!=0], x=\"mask_pixel_sum\", y=\"segments\", color=\"ClassId\", marginal_y=\"rug\", marginal_x=\"histogram\")\nfig.show()","525b40aa":"segment_labels_per_class = []\nsegment_values_per_class = []\n\nfor class_id in ['1','2','3','4']:\n    segments_value_count = train_df[(train_df['mask_pixel_sum']!=0) & (train_df['ClassId']==class_id)]['segments'].value_counts()\n    segments_value_count = segments_value_count.reset_index()\n    segments_value_count.columns = ['segments','segments_count']\n    segments_5_10_count = segments_value_count[(segments_value_count['segments']>=5)&(segments_value_count['segments']<=10)]['segments_count'].sum()\n    segments_10_plus_count = segments_value_count[segments_value_count['segments']>10]['segments_count'].sum()\n    segment_keys = list(segments_value_count[segments_value_count['segments'] < 5]['segments'].values)\n    segment_keys.append('5 - 10')\n    segment_keys.append('10 +')\n    segments_values = list(segments_value_count[segments_value_count['segments'] < 5]['segments_count'].values)\n    segments_values.append(segments_5_10_count)\n    segments_values.append(segments_10_plus_count)\n    segment_labels_per_class.append(segment_keys)\n    segment_values_per_class.append(segments_values)","efa6954e":"# Create subplots: use 'domain' type for Pie subplot\nfig = subplots.make_subplots(rows=1, cols=4, specs=[[{'type':'domain'}, {'type':'domain'},{'type':'domain'}, {'type':'domain'}]])\n\nfig.add_trace(Pie(labels=segment_labels_per_class[0], values=segment_values_per_class[0], name=\"Class Id 1\"), 1, 1)\nfig.add_trace(Pie(labels=segment_labels_per_class[1], values=segment_values_per_class[1], name=\"Class Id 2\"), 1, 2)\nfig.add_trace(Pie(labels=segment_labels_per_class[2], values=segment_values_per_class[2], name=\"Class Id 3\"), 1, 3)\nfig.add_trace(Pie(labels=segment_labels_per_class[3], values=segment_values_per_class[3], name=\"Class Id 4\"), 1, 4)\n# Use `hole` to create a donut-like pie chart\nfig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n\nfig.update_layout(\n    title_text=\"Steel Defect Segments Count\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='1', x=0.1, y=0.5, font_size=20, showarrow=False),\n                 dict(text='2', x=0.37, y=0.5, font_size=20, showarrow=False),\n                 dict(text='3', x=0.63, y=0.5, font_size=20, showarrow=False),\n                 dict(text='4', x=0.91, y=0.5, font_size=20, showarrow=False)])\nfig.show()","55352437":"# create a series with fault classes\nclass_per_image = grouped_EncodedPixels.apply(lambda encoded_list: [x[0] for x in encoded_list if x[1] != -1])","bcc0263b":"# create a list of dict with count of each fault class\nclass_per_image_list = []\nfor r in class_per_image.iteritems():\n    class_count = {'1':0,'2':0,'3':0,'4':0}\n    # go over each class and \n    for image_class in r[1]:\n        class_count[image_class] = 1\n    class_per_image_list.append(class_count)","bac2563d":"# do FP calculation with all image\nclass_per_image_df = pd.DataFrame(class_per_image_list)\nclass_fp_df = fpgrowth(class_per_image_df, use_colnames=True, min_support=0.001)\nclass_fp_df = class_fp_df.sort_values(by=['support'])","a8353241":"# subset to images with at least one mask\nclass_per_fault_image_df = class_per_image_df[(class_per_image_df.T != 0).any()]\nclass_fp_faulty_df = fpgrowth(class_per_fault_image_df, use_colnames=True, min_support=0.001)\nclass_fp_faulty_df = class_fp_faulty_df.sort_values(by=['support'])","dcc2c8a7":"# a simple function to do horizontal barplot\ndef bar_plot_h(x, y, title, x_label, y_label):\n    y_pos = np.arange(len(y))\n    plt.barh(y_pos, x)\n    plt.yticks(y_pos, y)\n    plt.title(title)\n    plt.ylabel(y_label)\n    plt.xlabel(x_label)","af67113b":"plt.figure(figsize=(15,5))\n# plot for FP for all images\nplt.subplot(1,2,1)\ncombinations = [', '.join(x) for x in class_fp_df['itemsets'].values]\nsupport = class_fp_df['support'].values\nbar_plot_h(support, combinations, 'Fault Classes Appearing Frequently - All Samples', 'Fault Classes', 'Support')\n# plot for FP for images with at least one fault\nplt.subplot(1,2,2)\ncombinations = [', '.join(x) for x in class_fp_faulty_df['itemsets'].values]\nsupport = class_fp_faulty_df['support'].values\nbar_plot_h(support, combinations, 'Fault Classes Appearing Frequently - Faulty Samples Only', 'Fault Classes', 'Support')","648514d2":"*ps: The graph above is interactive. You can click on the class ID \/ legend to turn different classes on and off.*\n#### Observations\n\n* From the box plot we can reconfirm our previous observation of class 4 are generally larger in size than class 3, and of course class 1 and 2.\n* Defect class 3 has a lot of outliers. Even though class 4 is generally bigger in size, the outlier values in class 3 can be a lot larger than the ones in class 4!","c92304a7":"Okay guys! This is just a start and hopefully a good start. Also, check out my other Kernel for this competition: [ResUNet-a Baseline on TensorFlow\n](https:\/\/www.kaggle.com\/ekhtiar\/resunet-a-baseline-on-tensorflow). \n\n**If you like my work please upvote this Kernel. This encourages or motivates people like me, who contributes to Kaggle on their own time with the intention to share knowledge, to continue the effort. Furthermore, if I made a mistake or can do something more, please leave a comment in the comments section to help me out. Many thanks in advance!**","841c52f0":"#### Observations\nHopefully the information and chart presented above isn't too much to take in. I will try my best to list a few observations below. However, please help me add more:\n* **Class 1** Tends to be small in size and in many fragments. It has the highest percentage of more than 5 segments and very small total defect area. Also it is the only class with considerable percentage of 10+ segment count.\n* **Class 2** Tends to be small in size but not in many fragments. It doesn't have any 5+ segments per defect. Mostly comes in one or two segments.\n* **Class 3** Fair amount of variation in terms of the number of segments per defect and also the area. However, more than 3 segments per defect is more frequent in class 3 than 4.","bc314233":"The picture above gives us some idea about how defects of more than one class. Visually and logically we can understand that the different classes of Mask doesn't overlap one another. Now let's zoom into three images from each types of defects to understand their patterns a little bit better.","a0bf5dd8":"#### Observations\n* There are a lot of images without any defect masks. I am not sure if they are examples of instances without any defect, or there are missing labels. Anyhow, I will print ten random of such instances below and let you find out more.\n* Often times two types of defects are reported per image. However, most of the time, there is only one type of defect per image. And we only have two instances where there are three types of defect in a single image.","a6a15b94":"#### Class 4","152e4d3a":"## Frequent Pattern Mining\n\nAs each image can have more than one class of faults, it brings an interesting question of how frequent different kind of faults occur at once. We will use an algorithm called FP (Frequent Pattern) growth to examine which types of faults occur in pairs. You can read more about FP mining in this [medium article](https:\/\/medium.com\/@ciortanmadalina\/an-introduction-to-frequent-pattern-mining-research-564f239548e). ","0ffb46e3":"#### Class 2 Defects","ba534f9d":"## Missing Labels & Defect Per Image\nIn this section we will look into how frequently each class is labeled in our dataset. We also noticed a large amount of dataset without any labels, so we will do a count of data with and without labels.","d7f858e3":"## Visualizing The Images & The Mask\nIn this section we will visualize the images on which we have to predict the defect on. We will also decode the encoded masks, which shows the area of defect, on top of these images.","3a821f9c":"## Introduction & Understanding The Data\n\nWhether we realize it or not, without steel our modern society would be very different! Infrastructure built with steel is resilient to heavy stress from human and nature, and therefore the production of steel is an important process. This competition asks us to help make the production process of steel more efficient by identifying defects. \n\nIn this notebook, I will do an exploratory data analysis and visualization to get me and you familiar with the dataset for this competition. In another kernel, [ResUNet-a Baseline on TensorFlow\n](https:\/\/www.kaggle.com\/ekhtiar\/resunet-a-baseline-on-tensorflow), we focus on the model to predict the faults.\n\n**If you like my work please upvote this Kernel. This encourages or motivates people like me, who contributes to Kaggle on their own time with the intention to share knowledge, to continue the effort. Furthermore, if I made a mistake or can do something more, please leave a comment in the comments section to help me out. Many thanks in advance!**","a4f26d81":"Now we have our modified train.csv, we answer a few basic questions below:","0f497cb7":"Looks like our function is working beautifully! Now let's do a scatter plot between the number of segments and total area of defect for each of the defect types with help of our friend plot.ly!","9ebf6bc1":"It's interesting to see that the masks are often exaggerated, specially for small defects.","de2d00bb":"## Mask Size Per Defect Class\nSince we have binary mask, we will count the number of pixels we have in our mask to get some sort of approximation for the size of defect per class, and look how this varies from class to class.","88802898":"This competition is about **semantic segmentation**. That is there are possibly four class of defects in one image and we need to identify each type of defects. In the train file, the first column has the image id and class id seperated by a underscore. For example, in the cell below the image 0002cc93b.jpg has a fault class 1 and the mask for this fault is given. There are four fault classes and so each image appears four times in the train.csv dataset. ","f017d2a1":"#### Class 1 Defects","3464b6c9":"## Segments Per Defect Type\nWhen we visualize the defects, we can see that per defect we can have multiple regions in our image with the same kind of defect. In this section we find out the number of segments behave for different class of defects.","0fc714a4":"#### Observations\n\n* Obviously we have a lot of samples from class 3 and dataset is highly imbalanced. Almost 73% of the all defects are of class 3. \n* Although class 4 defect are 11.3% of the all defect, if you consider from the total area of defect perspective, they have almost 17% of real-estate. This means that typically defect of class 4 are larger in size.\n* As defect size for 2 is very small, and class 1 is very very small. Class 1 and 2 represents 12.6% and 3.48% of the total defects respectively. However, in terms of pixel count of the defect mask, they only make up 2.39% and 0.51% of the total mask respectively. In terms of sample and specially in terms of area, \n* *Our network may have a hard time finding class 1 and 2 two because of their small size*.","3c88c697":"#### Observations\n* From the FP chart above, we can see that the frequency of an image with single fault of 3, 1, and 4 is the most frequent scenario. \n* The combination of 3 and 4 is actually more frequent than class 2 appearing alone. This is even more interesting as class 3 and 1 is the more frequent sample in the dataset. \n* The combination 3 and 1 is significantly less frequent than 3 and 4. However the support for them is below 10%, so I am not sure how significant this information is anyhow.\n* We really need to have to do some augmentation and increase the number of examples for class 2."}}