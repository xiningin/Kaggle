{"cell_type":{"aedf7d96":"code","22360307":"code","100c7f15":"code","c42027a2":"code","74ad0ce5":"code","a4a80138":"code","1a69d4f5":"code","156adeb0":"code","9b819d0b":"code","b7fa7c24":"code","c9c87dea":"code","66df119f":"markdown","0937248d":"markdown","e7cbde4e":"markdown","0cb97112":"markdown"},"source":{"aedf7d96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22360307":"df = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ndf.head()","100c7f15":"df=df[['age', 'ejection_fraction', 'serum_creatinine', 'serum_sodium', 'time','DEATH_EVENT']]","c42027a2":"df['Old'] = 0\ndf.loc[df.age >= 80.0 , 'Old'] = 1\ndf.drop(['age'],axis= 1,inplace=True)","74ad0ce5":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score","a4a80138":"X = df.drop(['DEATH_EVENT'],axis = 1)\ny = df['DEATH_EVENT']\n","1a69d4f5":"from sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_pipeline\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\nsvm_pipeline = make_pipeline(StandardScaler(),SVC())\nscore = cross_val_score(svm_pipeline, X_train, y_train, cv=5)\nprint(\"Accuracy: %f \" % (score.mean()))","156adeb0":"from sklearn.tree import DecisionTreeClassifier\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\nDT_pipeline = make_pipeline(StandardScaler(),DecisionTreeClassifier())\nscores = cross_val_score(svm_pipeline, X_train, y_train, cv=30)\nprint(\"Accuracy: %f \" % (scores.mean()))","9b819d0b":"best = 0;\nfor i in range(3,21):    \n    model = KNeighborsClassifier(n_neighbors = i)\n    model.fit(X_train,y_train)\n#    print(model.score(X_test,y_test))\n    if model.score(X_test,y_test) > best:\n        best = model.score(X_test,y_test)\n        best_n = i\nprint(\"Best Score and N_neigbors:\")\nprint(best,\",\",best_n)","b7fa7c24":"KNN_mod = KNeighborsClassifier(n_neighbors = best_n)\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\nKNN_pipeline = make_pipeline(StandardScaler(),DecisionTreeClassifier())\nscores = cross_val_score(svm_pipeline, X_train, y_train, cv=30)\nprint(\"Accuracy: %f \" % (scores.mean()))","c9c87dea":"from sklearn.linear_model import LogisticRegression\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)\nKNN_pipeline = make_pipeline(StandardScaler(),LogisticRegression())\nscores = cross_val_score(svm_pipeline, X_train, y_train, cv=30)\nprint(\"Accuracy: %f \" % (scores.mean()))","66df119f":"# **K-Nearest Neighbors**","0937248d":"# **Decision Tree**","e7cbde4e":"# **Logistic Regression**","0cb97112":"# **Support Vector Machine (SVM)**"}}