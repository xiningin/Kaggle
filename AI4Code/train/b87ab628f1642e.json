{"cell_type":{"a92b1b99":"code","eaa60867":"code","a7749ffc":"code","dcc2cb55":"code","87300a9b":"code","7171618f":"code","c29d9dc5":"code","ac654380":"code","a7430efe":"code","0c6d32df":"code","78bd1c7f":"code","130ad18e":"code","75c4ea2e":"code","d4d3926a":"code","d2523357":"code","1f8a9d16":"code","00040331":"code","9fb307ff":"code","5c4cf4f6":"code","638e56c6":"code","247f4c1f":"code","542c1fbd":"code","e214d131":"code","76fb6f62":"code","fc529ffc":"code","a0f748b1":"code","a9d9e99b":"code","70d4ec5d":"code","3c604790":"code","f40f3f64":"code","dea370d6":"code","bc5f5212":"code","133a9f3c":"code","5ce10885":"code","27656713":"code","046eae40":"code","0d22a74d":"code","5f91d1cc":"code","6e5b323e":"code","a100a02b":"code","6c37b374":"code","1c1daf6b":"code","a8bef28b":"markdown","5e672fee":"markdown","ae204a31":"markdown","eab1fc63":"markdown","d1f17bda":"markdown","ed669e53":"markdown"},"source":{"a92b1b99":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eaa60867":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain.shape","a7749ffc":"train.head()","dcc2cb55":"train.dtypes","87300a9b":"#Categorical\nsorted(train['Survived'].unique())","7171618f":"#Categorical\nsorted(train['Pclass'].unique())","c29d9dc5":"#Categorical\nlen(train['Name'].unique())","ac654380":"#Categorical\ntrain['Sex'].unique()","a7430efe":"#Numerical\ntrain['Age'].describe()","0c6d32df":"#Numerical\ntrain['SibSp'].describe()","78bd1c7f":"#Numerical\ntrain['Parch'].describe()","130ad18e":"#TicketID\n\"Num of unique tickets = \"+str(len(train['Ticket'].unique()))","75c4ea2e":"#Numerical\ntrain[\"Fare\"].describe()","d4d3926a":"#CabinID\n\"Num of unique cabins = \" + str(len(train['Cabin'].unique()))","d2523357":"#Categorical\ntrain['Embarked'].unique()","1f8a9d16":"#Cabin has a lot of nan values\ntrain.isna().sum()","00040331":"#Drop nan values and some of columns\ntrain = train.drop(columns=['Ticket', 'Cabin', 'Name'], errors = 'ignore').dropna()\ntrain.shape","9fb307ff":"print(\"Survived: {}%\".format(train[train['Survived']!=0][\"Age\"].count()\/train[\"Age\"].count()*100))","5c4cf4f6":"train[\"sex_encoded\"] = train['Sex'].replace({'male':0,'female':1})\ntrain[\"embarked_encoded\"] = train[\"Embarked\"].replace({'S':0,'C':1,'Q':2})\ntrain.shape","638e56c6":"#train = train.drop(columns = [\"Sex\", \"Embarked\"], errors = \"ignore\")\ntrain.head(2)","247f4c1f":"train_cov = train.drop(columns = [\"PassengerId\"], errors = \"ignore\").cov()\ntrain_cov","542c1fbd":"train_corr = train.drop(columns = [\"PassengerId\"], errors = \"ignore\").corr()\ntrain_corr","e214d131":"fig = plt.figure(figsize=(10,7))\nsns.heatmap(train_corr, annot = True)\nfig.show()","76fb6f62":"fare = train[[\"Survived\",\"Fare\", \"sex_encoded\"]]","fc529ffc":"#Likelyhood of extreme events are very high \nfare['Fare'].kurtosis()","a0f748b1":"#Highly, positively skewed\nfare['Fare'].skew()","a9d9e99b":"#We definetely have outliers in a dataset :D\n#Positively skewed\n#We have some extra peaks around 25,55,80 values, need to dig deeper\nfig = plt.figure(figsize=(10,8))\nfig.title = (\"KDE plot of Fare\")\nsns.distplot(fare['Fare'], rug = True, kde = True, hist = False)","70d4ec5d":"sns.FacetGrid(fare, hue=\"Survived\", height = 8).map(sns.distplot,\"Fare\")\nplt.axvline(fare['Fare'].mean(), color = \"g\", label = 'mean')\nplt.axvline(fare['Fare'].median(), color = \"r\", label = 'median')\nplt.legend()","3c604790":"fig = plt.figure(figsize = (10,15))\nsns.boxplot(x = \"Survived\", y = \"Fare\", data = train, hue = 'Sex')","f40f3f64":"fare_without_outliers = fare[fare['Fare']<200]\nfare_without_outliers.describe()","dea370d6":"#Positively skewed\nfare_without_outliers['Fare'].skew()","bc5f5212":"#Extreme events likelyhood is slightly bigger, than a normal distribution without outlier\nfare_without_outliers['Fare'].kurtosis()","133a9f3c":"#Distribution without outlier\nfig = plt.figure(figsize=(10,8))\nsns.distplot(fare_without_outliers['Fare'], rug = True, kde = True, hist = False)\nplt.axvline(fare_without_outliers['Fare'].mean(), color = \"g\", label = 'mean')\nplt.axvline(fare_without_outliers['Fare'].median(), color = \"r\", label = 'median')\nplt.legend()","5ce10885":"fig = plt.figure(figsize=(10,15))\nsns.violinplot(x = \"Survived\", y = \"Fare\", data = fare_without_outliers, inner = None)\nsns.swarmplot(x = \"Survived\", y = \"Fare\", data = fare_without_outliers, color = 'w')","27656713":"#Have extra pick\nsns.distplot(train['Age'], rug=True,kde=True,hist=False)","046eae40":"sns.FacetGrid(train, hue=\"Sex\").map(sns.distplot, 'Age').add_legend()","0d22a74d":"sns.boxplot(x=\"Survived\", y=\"Age\", hue=\"Sex\", data=train)","5f91d1cc":"fig, ax = plt.subplots(2, 2, figsize = (15,15))\nfig.tight_layout(pad=2.5)\nfig.suptitle(\"Age\")\n#taking all people's age and averaging. Sorting by index i.e. [0,1,...20,80]\ndata = train['Age'].value_counts().sort_index()\n#survived\ndata_survived = train[train['Survived']!=0][\"Age\"].value_counts().sort_index()\ndata_dead = train[train['Survived']!=1][\"Age\"].value_counts().sort_index()\n\n#Plot frequency chart of all ages\nax[0][0].bar(data.index, data.values)\nax[0][0].set_title(\"Frequency of each individual age\")\nax[0][0].set_ylim([0,data.max()])\n#Plot frequency chart of all survived \nax[1][0].bar(data_dead.index, data_dead.values, label = \"died\")\nax[1][0].bar(data_survived.index, data_survived.values, label = 'survived')\nax[1][0].set_title(\"Survived over dead\")\nax[1][0].legend()\nax[1][0].set_ylim([0,data.max()])\n#Plot percentage of survivors in lines\nax[0][1].plot(data.index, data.values, label = \"all\")\nax[0][1].plot(data_survived.index, data_survived.values, label = \"survived\")\nax[0][1].set_title(\"Num of survivals at certain age\")\nax[0][1].legend()\n#Plot them all together\nax[1][1].bar(data.index, data.values, label = 'all')\nax[1][1].bar(data_survived.index, data_survived.values, label = 'survived')\nax[1][1].plot(data.index, data.values, label = \"all\",color = 'r')\nax[1][1].plot(data_survived.index, data_survived.values, label = \"survived\", color = 'b')\nax[1][1].set_xlim([0,train['Age'].max()])\nax[1][1].set_title(\"Putting all together\")\nax[1][1].legend()\n\n#d = (train[train['Survived']!=0][\"Age\"].dropna().value_counts().sort_index()\/train[\"Age\"].dropna().value_counts().sort_index())\n#Filling gaps of None with mask\n#s1mask = np.isfinite(d.values)\n#ax[2][0].plot(d.index[s1mask], d.values[s1mask])\n#ax[2][0].set_title(\"Percenile of survival at certain age\")\n\n#d2 = (train[train['Survived']!=1][\"Age\"].dropna().value_counts().sort_index()\/train[\"Age\"].dropna().value_counts().sort_index())\n#s2mask = np.isfinite(d2.values)\n#ax[2][1].plot(d2.index[s2mask], d2.values[s2mask], label = \"dead\")\n#ax[2][1].plot(d.index[s1mask], d.values[s1mask], label = 'alive')\n#ax[2][1].legend()\n#ax[2][1].set_title(\"Percenile of death at certain age\")","6e5b323e":"plt.figure(figsize=(5,5))\nsns.countplot(train[\"Sex\"])\nplt.show()","a100a02b":"plt.figure(figsize=(5,5))\nsns.countplot(train[\"Sex\"], hue = train[\"Survived\"])\nplt.show()","6c37b374":"gender_and_age = train[[\"Survived\", \"Sex\", \"Age\"]].replace({'female':0, 'male':1}).round(0).groupby(['Age', 'Sex', 'Survived']).size()\ncolors = {0:'r', 1:'b'}\ntitles = {0:'female', 1:'male'}\nfg,ax = plt.subplots(1,2)\nfg.suptitle(\"Female and male (red - female, blue - male)\")\nax[0].set_title(\"Survived\")\n\nax[1].set_title(\"Died\")\nfor age, sex, survived in gender_and_age.index:\n    num = gender_and_age[age][sex][survived]\n    colored = colors[sex]\n    titled = titles[sex]\n    if survived:\n        ax[0].scatter(age, num, color = colored)\n    else:\n        ax[1].scatter(age, num, color = colored)","1c1daf6b":"x_train = train.drop(columns=[\"PassengerId\", \"Survived\"])\ny_train = train[[\"PassengerId\", \"Survived\"]]","a8bef28b":"# Lets see, if there are any dependencies in gender\n**After analizing first and second plots, I made strong prediction, that women had significantly more chances to survive!**","5e672fee":"# **Analyzing Age**\n**After analizing plots, I made some predictions:**\n* People at the age of 0-15 could have more chances to survive;\n* People at the age of 15-50 had the smallest chances to survive.\n* People at the age of 50-80 had 50% to survive;\n\nBiggest amount of survived were at the age of 20-50, because there were many more people at that age.\n\n*There is no straight correlation in data[\"Age\"], so we need to keep analyzing*","ae204a31":"**Getting to know the data**","eab1fc63":"# **Covarience and correlation matrices. HeatMap**\nOn the plot we can see, that there is positive relationship between columns Sex, Fare and Survived. And negative relationship between Pclass and Survived","d1f17bda":"# **Encoding categorical values**\nSex and Embarked have to be encoded","ed669e53":"# **Analyzing Fare**\n* Dataset is normally distributed\n* Original dataset have outlier (>500). Need to drop outlier to normalize dataset.\n* Dataset is positevely skewed. \n* Likelyhood of extreme evens is bigger, than in a normal distribution\n* Dataset have some extra peaks"}}