{"cell_type":{"a113f715":"code","2df513ff":"code","86ab6c32":"code","a5636a44":"code","cd3615bd":"code","5b886c1c":"code","6ab9ee6f":"code","22416863":"code","4a079eb0":"code","00d637ae":"code","89cb1fd9":"code","25272dbf":"code","c8d49172":"code","e104aa0f":"markdown","751de0b0":"markdown","5095d308":"markdown"},"source":{"a113f715":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2df513ff":"import pandas as pd\nimport numpy as np\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Activation,InputLayer\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n","86ab6c32":"#reading csvs and storing as data frames\ntrain_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","a5636a44":"#dropping unnecessary columns and storing passenger IDs for predictions\ntrain_df = train_df.drop(columns=['PassengerId', 'Ticket', 'Cabin', 'Name'])\ntest_Ids = test_df['PassengerId']\ntest_df = test_df.drop(columns=['PassengerId', 'Ticket', 'Cabin', 'Name'])","cd3615bd":"#iterating through columns finding NAN values\nfor cols in train_df:\n    print(\"col : {} -- {}= {}\".format(type(train_df[cols][0]),cols,train_df[cols].isnull().sum()))","5b886c1c":"for cols in train_df:\n    print(\"col : {} -- {}= {}\".format(type(train_df[cols][0]),cols,train_df[cols].isnull().sum()))","6ab9ee6f":"#filling NAN values in columns\ntrain_df = train_df.fillna(train_df['Age'].mean())\ntrain_df = train_df.fillna(train_df['Embarked'].mode())\n\ntest_df = test_df.fillna(test_df['Age'].mean())\ntest_df = test_df.fillna(test_df['Fare'].mean())","22416863":"#label encoder changes strings to integer representation\nencoder = LabelEncoder()\ntrain_df['Sex'] = encoder.fit_transform(train_df['Sex'].astype(str))\ntrain_df['Embarked'] = encoder.fit_transform(train_df['Embarked'].astype(str))\n\ntest_df['Sex'] = encoder.fit_transform(test_df['Sex'].astype(str))\ntest_df['Embarked'] = encoder.fit_transform(test_df['Embarked'].astype(str))","4a079eb0":"#train test split to get training features, validation labels, test data and test validation labels\nx_train, x_val, y_train, y_val = train_test_split(train_df.drop('Survived', axis=1), train_df['Survived'], \n                                                 test_size=0.25, random_state=42)","00d637ae":"#Makes values passable into a neural network\ntrain_df=pd.get_dummies(train_df)\ntest_df= pd.get_dummies(test_df)\n\ntrain_df.head()","89cb1fd9":"#Simple neural network\nt_model = Sequential()\n\nt_model.add(InputLayer(input_shape=(7,)))\nt_model.add(Dense(1024, activation='relu'))\nt_model.add(Dense(512, activation='relu'))\nt_model.add(Dense(256, activation='relu'))\nt_model.add(Dense(128, activation='relu'))\nt_model.add(Dense(64, activation='relu'))\n\nt_model.add(Dense(32, activation='relu'))\nt_model.add(Dense(1, activation='sigmoid'))\n\nt_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","25272dbf":"#training the model\nt_model.fit(train_df.drop('Survived',axis=1),train_df[\"Survived\"], epochs=100, batch_size=10,verbose=1)","c8d49172":"preds= t_model.predict(test_df)\npredictions= [0 if pred < 0.5 else 1 for pred in preds]\noutput = pd.DataFrame({'PassengerId': test_Ids, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","e104aa0f":"**Retrieving Training and Test Data**","751de0b0":"**Importing Necessary Libraries**","5095d308":"**Building Neural Networks**"}}