{"cell_type":{"b1aea402":"code","e8fda5f9":"code","0251a195":"code","408a345e":"code","4c852857":"code","6056bbfe":"code","e21ac868":"code","0b505430":"code","29b54fdf":"code","55d8ed74":"code","123847fa":"code","ab58eeac":"code","93ed0465":"code","51b2a819":"code","446b5fe1":"code","d4f5958d":"code","2a343206":"code","5c9dd5b1":"code","756b83da":"code","3d65287c":"code","b0dc75f7":"code","415446ca":"code","30ca155c":"code","5b5423b1":"code","443ccb9d":"code","074a5589":"code","50a7a024":"code","21bdbdd3":"code","0a14b763":"code","75493ccf":"markdown"},"source":{"b1aea402":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport cv2\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical ,Sequence\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adadelta, Nadam ,Adam\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TensorBoard\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom glob import glob\nfrom pathlib import Path\nimport shutil\nfrom tqdm import tqdm_notebook\nfrom random import sample, choice\n\n# Any results you write to the current directory are saved as output.","e8fda5f9":"dataset_path = Path(\"..\/input\/camvid\/CamVid\/\")\nlist(dataset_path.iterdir())","0251a195":"def tree(directory):\n    print(f'+ {directory}')\n    for path in sorted(directory.rglob('*')):\n        depth = len(path.relative_to(directory).parts)\n        spacer = '    ' * depth\n        print(f'{spacer}+ {path.name}')       \n#tree(dataset_path)","408a345e":"train_imgs = list((dataset_path \/ \"train\").glob(\"*.png\"))\ntrain_labels = list((dataset_path \/ \"train_labels\").glob(\"*.png\"))\nval_imgs = list((dataset_path \/ \"val\").glob(\"*.png\"))\nval_labels = list((dataset_path \/ \"val_labels\").glob(\"*.png\"))\ntest_imgs = list((dataset_path \/ \"test\").glob(\"*.png\"))\ntest_labels = list((dataset_path \/ \"test_labels\").glob(\"*.png\"))\n\n(len(train_imgs),len(train_labels)), (len(val_imgs),len(val_labels)) , (len(test_imgs),len(test_labels))\n\nimg_size = 512","4c852857":"assert len(train_imgs) == len(train_labels), \"No of Train images and label mismatch\"\nassert len(val_imgs) == len(val_labels), \"No of Train images and label mismatch\"\nassert len(test_imgs) == len(test_labels), \"No of Train images and label mismatch\"\n\nsorted(train_imgs), sorted(train_labels), sorted(val_imgs), sorted(val_labels), sorted(test_imgs), sorted(test_labels);","6056bbfe":"for im in train_imgs:\n    assert dataset_path \/ \"train_labels\" \/ (im.stem +\"_L.png\") in train_labels , \"{im} not there in label folder\"\nfor im in val_imgs:\n    assert dataset_path \/ \"val_labels\" \/ (im.stem +\"_L.png\") in val_labels , \"{im} not there in label folder\"\nfor im in test_imgs:\n    assert dataset_path \/ \"test_labels\" \/ (im.stem +\"_L.png\") in test_labels , \"{im} not there in label folder\"","e21ac868":"def make_pair(img,label,dataset):\n    pairs = []\n    for im in img:\n        pairs.append((im , dataset \/ label \/ (im.stem +\"_L.png\")))\n    \n    return pairs","0b505430":"train_pair = make_pair(train_imgs, \"train_labels\", dataset_path)\nval_pair = make_pair(val_imgs, \"val_labels\", dataset_path)\ntest_pair = make_pair(test_imgs, \"test_labels\", dataset_path)","29b54fdf":"temp = choice(train_pair)\nimg = img_to_array(load_img(temp[0], target_size=(img_size,img_size)))\nmask = img_to_array(load_img(temp[1], target_size = (img_size,img_size)))\nplt.figure(figsize=(10,10))\nplt.subplot(121)\nplt.imshow(img\/255)\nplt.subplot(122)\nplt.imshow(mask\/255)","55d8ed74":"class_map_df = pd.read_csv(dataset_path \/ \"class_dict.csv\")","123847fa":"class_map = []\nfor index,item in class_map_df.iterrows():\n    class_map.append(np.array([item['r'], item['g'], item['b']]))\n    \nlen(class_map)","ab58eeac":"def assert_map_range(mask,class_map):\n    mask = mask.astype(\"uint8\")\n    for j in range(img_size):\n        for k in range(img_size):\n            assert mask[j][k] in class_map , tuple(mask[j][k])","93ed0465":"def form_2D_label(mask,class_map):\n    mask = mask.astype(\"uint8\")\n    label = np.zeros(mask.shape[:2],dtype= np.uint8)\n    \n    for i, rgb in enumerate(class_map):\n        label[(mask == rgb).all(axis=2)] = i\n    \n    return label","51b2a819":"lab = form_2D_label(mask,class_map)\nnp.unique(lab,return_counts=True)","446b5fe1":"class DataGenerator(Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, pair, class_map, batch_size=16, dim=(224,224,3), shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.pair = pair\n        self.class_map = class_map\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.pair) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [k for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.pair))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        batch_imgs = list()\n        batch_labels = list()\n\n        # Generate data\n        for i in list_IDs_temp:\n            # Store sample\n            img = load_img(self.pair[i][0] ,target_size=self.dim)\n            img = img_to_array(img)\/255.\n            batch_imgs.append(img)\n\n            label = load_img(self.pair[i][1],target_size=self.dim)\n            label = img_to_array(label)\n            label = form_2D_label(label,self.class_map)\n            label = to_categorical(label , num_classes = 32)\n            batch_labels.append(label)\n            \n        return np.array(batch_imgs) ,np.array(batch_labels)","d4f5958d":"train_generator = DataGenerator(train_pair+test_pair,class_map,batch_size=4, dim=(img_size,img_size,3) ,shuffle=True)\ntrain_steps = train_generator.__len__()\ntrain_steps","2a343206":"X,y = train_generator.__getitem__(1)\ny.shape","5c9dd5b1":"val_generator = DataGenerator(val_pair, class_map, batch_size=4, dim=(img_size,img_size,3) ,shuffle=True)\nval_steps = val_generator.__len__()\nval_steps","756b83da":"def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n\n\ndef deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n    y = concatenate([y, residual], axis=3)\n    y = conv_block(y, nfilters)\n    return y\n\n\ndef Unet(h, w, filters):\n# down\n    input_layer = Input(shape=(h, w, 3), name='image_input')\n    conv1 = conv_block(input_layer, nfilters=filters)\n    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = conv_block(conv1_out, nfilters=filters*2)\n    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = conv_block(conv2_out, nfilters=filters*4)\n    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = conv_block(conv3_out, nfilters=filters*8)\n    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n    conv4_out = Dropout(0.5)(conv4_out)\n    conv5 = conv_block(conv4_out, nfilters=filters*16)\n    conv5 = Dropout(0.5)(conv5)\n# up\n    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n    deconv6 = Dropout(0.5)(deconv6)\n    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n    deconv7 = Dropout(0.5)(deconv7) \n    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n    output_layer = Conv2D(filters=32, kernel_size=(1, 1), activation='softmax')(deconv9)\n\n    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n    return model","3d65287c":"model = Unet(img_size , img_size , 64)\nmodel.summary()","b0dc75f7":"model.compile(optimizer='adam', loss='categorical_crossentropy' ,metrics=['accuracy'])","415446ca":"mc = ModelCheckpoint(mode='max', filepath='top-weights.h5', monitor='val_acc',save_best_only='True', save_weights_only='True', verbose=1)\nes = EarlyStopping(mode='max', monitor='val_acc', patience=10, verbose=0)\ntb = TensorBoard(log_dir=\"logs\/\", histogram_freq=0, write_graph=True, write_images=False)\nrl = ReduceLROnPlateau(monitor='val_acc',factor=0.1,patience=5,verbose=1,mode=\"max\",min_lr=0.0001)\ncv = CSVLogger(\"logs\/log.csv\" , append=True , separator=',')","30ca155c":"results = model.fit_generator(train_generator , steps_per_epoch=train_steps ,epochs=30,\n                              validation_data=val_generator,validation_steps=val_steps,callbacks=[mc,es,tb,rl,cv])","5b5423b1":"img_mask = choice(val_pair)\nimg= img_to_array(load_img(img_mask[0] , target_size= (img_size,img_size)))\ngt_img = img_to_array(load_img(img_mask[1] , target_size= (img_size,img_size)))","443ccb9d":"def make_prediction(model,img_path,shape):\n    img= img_to_array(load_img(img_path , target_size= shape))\/255.\n    img = np.expand_dims(img,axis=0)\n    labels = model.predict(img)\n    labels = np.argmax(labels[0],axis=2)\n    return labels","074a5589":"pred_label = make_prediction(model, img_mask[0], (img_size,img_size,3))\npred_label.shape","50a7a024":"def form_colormap(prediction,mapping):\n    h,w = prediction.shape\n    color_label = np.zeros((h,w,3),dtype=np.uint8)    \n    color_label = mapping[prediction]\n    color_label = color_label.astype(np.uint8)\n    return color_label","21bdbdd3":"pred_colored = form_colormap(pred_label,np.array(class_map))","0a14b763":"plt.figure(figsize=(15,15))\nplt.subplot(131);plt.title('Original Image')\nplt.imshow(img\/255.)\nplt.subplot(132);plt.title('True labels')\nplt.imshow(gt_img\/255.)\nplt.subplot(133)\nplt.imshow(pred_colored\/255.);plt.title('predicted labels')","75493ccf":"## EDA"}}