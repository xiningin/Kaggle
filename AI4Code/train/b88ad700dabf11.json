{"cell_type":{"8f41199c":"code","0d9bc2f4":"code","ae3cc35f":"code","a40d75f1":"code","2ea453c0":"code","18e3fe92":"code","8e8414ed":"code","96591bd9":"code","5817db79":"code","8237174e":"code","1cf3a6e0":"code","17849b23":"markdown","c7d542be":"markdown","1e8799f6":"markdown","c543c8b1":"markdown","956d4bf7":"markdown","fd095ddd":"markdown","6a36c625":"markdown","b3399949":"markdown","6a7fa1c8":"markdown"},"source":{"8f41199c":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.axes_style(\"darkgrid\")\nfrom sklearn.model_selection import KFold,StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import  train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')","0d9bc2f4":"df_t = pd.read_csv('..\/input\/train.csv')\ndf_tst = pd.read_csv('..\/input\/test.csv')","ae3cc35f":"frac_sample =1\ndf_train = df_t.copy().sample(frac=(frac_sample))\ndf_test = df_tst.copy().sample(frac=(frac_sample))\nX = df_train.iloc[:,2:]\ny = df_train['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\nprint('Train : ' , X_train.shape)\nprint('Test : ' , X_test.shape)","a40d75f1":"#Model LGBM \nparam = {\n    'bagging_freq': 8, #handling overfitting\n    'bagging_fraction': 0.4, #handling overfitting - adding some noise\n    'boost_from_average':True,\n    'boost': 'gbdt',\n    'feature_fraction': 0.4, #handling overfitting\n    'learning_rate': 0.01, #the changes between one auc and a better one gets really small thus a small learning rate performs better\n    'max_depth': 2,  #smaller trees less overfitting\n    'metric':'auc',\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': 0\n    }\n\nlgbm_X = X_train\nlgbm_y = y_train\nlgbm_test_x = X_test\nlgbm_test_y = y_test\nval_pred = []\nimportand_folds = np.zeros(lgbm_X.shape[1])\ntest_pred_lgbm = []\ntarget_pred = []\nkf = KFold(n_splits=23,random_state=1346)\nfor _fold, (trn_idx, val_idx) in enumerate(kf.split(lgbm_X.values, lgbm_y.values)):\n            Xtrn, ytrn = lgbm_X.iloc[trn_idx], lgbm_y.iloc[trn_idx]\n            Xval, y_val = lgbm_X.iloc[val_idx], lgbm_y.iloc[val_idx]\n            #-----------------------------------------\n            print('Fold: ', _fold)\n            dtrain = lgb.Dataset(Xtrn,label=ytrn)\n            dval = lgb.Dataset(Xval,label=y_val)\n            clf = lgb.train(param,dtrain,num_boost_round=5000,valid_sets=(dtrain,dval),valid_names=['train','valid'],\n                      verbose_eval=500,\n                     early_stopping_rounds=250)\n            #----------------------------------------\n            importand_folds += clf.feature_importance()\n            #validation score\n            val_pred.append(clf.best_score['valid']['auc'])\n            #save the test prediction per fold\n            test_pred_lgbm.append(clf.predict(lgbm_test_x))\n            print('-'*50)\n            target_pred.append(clf.predict(df_test.iloc[:,1:]))","2ea453c0":"from sklearn.preprocessing import MinMaxScaler \ndef weight_pred(preds,vals,n_splits,range_features =(0.9,1) ):\n    ## Setting Up predictions dataframe\n    df_pred = pd.DataFrame(preds)\n    df_pred.columns = ['pred_'+str(x) for x in range(df_pred.shape[1])]\n    \n    \n    #Min Max scaling for the max fold validation values\n    #the feature range plays the role of a hyper-parameter to balance the effect of the validation set on the test set\n    scaler = MinMaxScaler(feature_range=range_features).fit(np.array([vals]).T)\n    val_scaled = scaler.transform(np.array([vals]))\n    \n    #multiply scaled values by  each row in the dataframe which represent a fold\n    df_scaled = df_pred.mul(val_scaled.tolist()[0],axis=0)\n    \n    #sum and divide\n    df_pred_final = df_pred.sum(axis=0) \/ n_splits\n    df_scaled_final = df_scaled.sum(axis=0) \/ n_splits\n    return df_pred,df_scaled,df_pred_final,df_scaled_final","18e3fe92":"#testing predictions\ndf_pred,df_scaled,df_pred_final,df_scaled_final = weight_pred(test_pred_lgbm,val_pred,kf.n_splits)\n\n#target predictions\n_1,_2,df_test_pred_final,df_test_scaled_final = weight_pred(target_pred,val_pred,kf.n_splits)","8e8414ed":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(20,12))\nfor fold in range(df_pred.shape[0]):\n    sns.distplot(df_pred.iloc[fold],label='fold_'+str(fold) + 'val-score: {:.2}'.format(val_pred[fold]),ax=ax1, hist=False)\n    sns.distplot(df_scaled.iloc[fold],label='fold: '+str(fold) + '  val_score: {:.2}'.format(val_pred[fold]),ax=ax2,hist=False)\nax1.set_title('Non-Weigted Predictions')\nax2.set_title('Weigted Predictions')\nplt.tight_layout()\nplt.legend()\nplt.show()","96591bd9":"#Scores\nnormal_score = roc_auc_score(y_test,df_pred_final.values)\nweighted_score = roc_auc_score(y_test,df_scaled_final.values)\nprint('Test Scores')\nprint('-'*50)\nprint('Normal Score :   {:.10}'.format(normal_score))\nprint('Weighted Score : {:.10}'.format(weighted_score))","5817db79":"#let check the test scores difference depending on the range given\nrng  = [(0.5,1),(0.6,1),(0.7,1),(0.8,1),(0.9,1),(0.5,0.8),(0.6,0.8),(0.2,0.8)]\nwt_scores = []\nnon_wt_scores =  []\nfor r in rng:\n    df_pred,df_scaled,df_pred_final,df_scaled_final = weight_pred(test_pred_lgbm,val_pred,kf.n_splits,range_features = r)\n    non_wt_scores.append(roc_auc_score(y_test,df_pred_final.values))\n    wt_scores.append(roc_auc_score(y_test,df_scaled_final.values))","8237174e":"plt.figure(figsize=(12,9))\nsns.lineplot(x=range(len(non_wt_scores)),y=non_wt_scores,label='Non-Weighted')\nsns.lineplot(x=range(len(wt_scores)),y=wt_scores,label='Weighted')\nplt.legend()\nplt.show()","1cf3a6e0":"def sub_pred(preds,df_test,name='submission.csv'):\n    sub_df = pd.DataFrame({'ID_code':df_test['ID_code'],'target':preds})\n    sub_df.to_csv(name, index=False)\n\n    \nsub_file = 'scaled_pred.csv'\nsub_pred(df_test_scaled_final.values,df_test,name=sub_file)\nprint(sub_file+'-submitted successfully')\n\nsub_file = 'non_scaled_pred.csv'\nsub_pred(df_test_pred_final.values,df_test,name=sub_file)\nprint(sub_file+'-submitted successfully')","17849b23":"# Short Intro to Weighted Cross-Validation","c7d542be":"# Predictions DistPlot Comparison","1e8799f6":"We can see the extra noise the weighting applies in the right plot","c543c8b1":"This can also prove to have better performance when dealing with a larger distributed range for predictions, and that's why we can see only a minor improvement regarding the prediction for this dataset. ","956d4bf7":"Thank you ! Any Feedback Appreciated ","fd095ddd":"# LGBM Model","6a36c625":"# Evaluation\n\nThe Evaluation should be run on multiple prediction samples, but this is an intro so I'm excused :D\n\nOr.....you can try it yourself.....that also works :D","b3399949":"- \nFor the sake of just introducting the approach we will be using a fast lgbm model with a sample from the dataset","6a7fa1c8":"#### This kernel is introducing a weighted approach to Cross-validation which oddly I don't see many kagglers using or maybe revealing.\n\n## Formulation: \n    The final predictions are weighted according to the scores of the validation set per fold\n$\\textbf{v} = MinMax\\;(\\;vector \\; of max \\; validation\\; scores\\; per\\; fold\\;)$ range = [min=0,max=1] <br> \n$\\textbf{p} = matrix \\;(\\;n\\_folds,\\; n\\_predictions\\;)$<br> \n$\\textbf{R} =  \\frac{1}{n\\_folds} \\sum_i (\\textbf{v}  \\circ  \\textbf{p})_i$ <br> \n\n\n\n\n"}}