{"cell_type":{"6b27d0b2":"code","69fde874":"code","5f7f19b1":"code","9b83168a":"code","cad7508d":"code","d8740a68":"code","fc271fe2":"code","557608f5":"code","f357b388":"code","6d9bd50d":"code","b12b0fa6":"code","8975bfac":"code","5ac7bf46":"code","80498167":"code","5138cd0a":"markdown","2f8204a0":"markdown","749322be":"markdown","739b431f":"markdown","48e7dbfe":"markdown","97893b89":"markdown","d1b0b1ae":"markdown","84429a09":"markdown","2e365e92":"markdown","ff785a7c":"markdown","a2ae98b4":"markdown","f4d5497b":"markdown","d8602e06":"markdown","57efbba1":"markdown","dad5583e":"markdown","ffc9a06f":"markdown"},"source":{"6b27d0b2":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport time\nimport glob\nimport imageio\nfrom IPython import display\nimport cv2\nimport pathlib\nimport zipfile\nimport torch\nimport sys\nimport pandas as pd \n\nimport torchvision\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset, TensorDataset\nfrom torchvision.utils import make_grid\nimport torch.optim as optim\nfrom torchvision.datasets import MNIST\n\nfrom skimage import io, transform\n\n!pip install torchsummary\nfrom torchsummary import summary","69fde874":"# Decide which device we want to run on\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","5f7f19b1":"class Generator(nn.Module):\n\n    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n        super(Generator, self).__init__()\n        \n        self.z_dim = z_dim\n        \n        self.gen = nn.Sequential(\n            \n            self.get_generator_block(z_dim, \n                                     hidden_dim * 4,\n                                     kernel_size=3, \n                                     stride=2),\n            \n            self.get_generator_block(hidden_dim * 4, \n                                     hidden_dim * 2,\n                                     kernel_size=4,\n                                     stride = 1),\n            \n            self.get_generator_block(hidden_dim * 2,\n                                     hidden_dim ,\n                                     kernel_size=3,\n                                     stride = 2,\n                                    ),\n\n            self.get_generator_final_block(hidden_dim,\n                                           im_chan,\n                                           kernel_size=4,\n                                           stride=2)\n            \n\n        )\n        \n        \n    def get_generator_block(self, input_channel, output_channel, kernel_size, stride = 1, padding = 0):\n        return nn.Sequential(\n                nn.ConvTranspose2d(input_channel, output_channel, kernel_size, stride, padding),\n                nn.BatchNorm2d(output_channel),\n                nn.ReLU(inplace=True),\n        )\n    \n    \n    def get_generator_final_block(self, input_channel, output_channel, kernel_size, stride = 1, padding = 0):\n        return  nn.Sequential(\n                nn.ConvTranspose2d(input_channel, output_channel, kernel_size, stride, padding),\n                nn.Tanh()\n            )\n    \n    \n    def forward(self, noise):\n        x = noise.view(len(noise), self.z_dim, 1, 1)\n        return self.gen(x)\n    \n    \n    \nsummary(Generator(100).to(device), (100,))","9b83168a":"class Discriminator(nn.Module):\n\n    def __init__(self, im_chan=1, hidden_dim=16):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            self.get_discriminator_block(im_chan,\n                                         hidden_dim * 4,\n                                         kernel_size=4,\n                                         stride=2),\n            \n            self.get_discriminator_block(hidden_dim * 4,\n                                         hidden_dim * 2,\n                                         kernel_size=4,\n                                         stride=2,),\n            \n            self.get_discriminator_final_block(hidden_dim * 2,\n                                               1,\n                                               kernel_size=4,\n                                               stride=2,),\n\n        )\n\n        \n    def get_discriminator_block(self, input_channel, output_channel, kernel_size, stride = 1, padding = 0):\n        return nn.Sequential(\n                nn.Conv2d(input_channel, output_channel, kernel_size, stride, padding),\n                nn.BatchNorm2d(output_channel),\n                nn.LeakyReLU(0.2, inplace=True)\n        )\n    \n    \n    def get_discriminator_final_block(self, input_channel, output_channel, kernel_size, stride = 1, padding = 0):\n        return  nn.Sequential(\n                nn.Conv2d(input_channel, output_channel, kernel_size, stride, padding),\n            )\n    \n    def forward(self, image):\n        return self.disc(image)\n    \nsummary(Discriminator().to(device) , (1,28,28))","cad7508d":"def get_noise(n_samples, z_dim, device='cpu'):\n    return torch.randn(n_samples,z_dim,device=device)","d8740a68":"z_dim = 100\nbatch_size = 128\n\nfixed_noise = get_noise(batch_size, z_dim, device=device)\n\ntrain_transform = transforms.Compose([\n    transforms.ToTensor(),\n])\n\ndataloader = DataLoader(\n    MNIST('.', download=True, transform=train_transform),\n    batch_size=batch_size,\n    shuffle=True)","fc271fe2":"start = time.time()\ndataiter = iter(dataloader)\nimages,labels = dataiter.next()\nprint ('Time is {} sec'.format(time.time()-start))\n\nplt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\nplt.imshow(np.transpose(make_grid(images.to(device), padding=2, normalize=True).cpu(),(1,2,0)))\n\nprint('Shape of loading one batch:', images.shape)\nprint('Total no. of batches present in trainloader:', len(dataloader))","557608f5":"lr = 0.0002\nbeta_1 = 0.5 \nbeta_2 = 0.999\n\ndef weights_init(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n    if isinstance(m, nn.BatchNorm2d):\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n        torch.nn.init.constant_(m.bias, 0)\n\n        \ncriterion = nn.BCEWithLogitsLoss()\n\ngen = Generator(z_dim).to(device)\ngen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n\ndisc = Discriminator().to(device) \ndisc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n\ngen = gen.apply(weights_init)\ndisc = disc.apply(weights_init)        ","f357b388":"def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), show_fig=False, epoch=0):\n    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n    plt.axis('off')\n    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n    if show_fig:\n        plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n        \n    plt.show()","6d9bd50d":"n_epochs = 200\ncur_step = 0\nmean_generator_loss = 0\ntotal_steps = 0\nstart_time = time.time()\nmean_discriminator_loss = 0\ngen_loss = False\n\nG_losses = []\nD_losses = []\nD_mean_losses = []\nG_mean_losses = []\n\n\nfor epoch in range(n_epochs):\n    cur_step = 0\n    start = time.time()\n    for real, _ in dataloader:\n        \n        cur_batch_size = len(real)\n        \n        real = real.to(device)\n\n        ## Update discriminator ##\n        disc_opt.zero_grad()\n        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n        fake = gen(fake_noise)\n        disc_fake_pred = disc(fake.detach())\n        disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n        disc_real_pred = disc(real)\n        disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n        disc_loss = (disc_fake_loss + disc_real_loss) \/ 2\n        \n        disc_loss.backward(retain_graph=True)\n        disc_opt.step()\n\n        ## Update generator ##\n        gen_opt.zero_grad()\n        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n        fake_2 = gen(fake_noise_2)\n        disc_fake_pred = disc(fake_2)\n        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n        \n        gen_loss.backward()\n        gen_opt.step()\n\n\n        # Keep track of the average discriminator loss\n        mean_discriminator_loss += disc_loss.item() \n\n        # Keep track of the average generator loss\n        mean_generator_loss += gen_loss.item() \n        \n        cur_step += 1\n        total_steps += 1\n        \n        D_losses.append(disc_loss.item())\n        G_losses.append(gen_loss.item())\n        \n        \n        print_val = f\"Epoch: {epoch}\/{n_epochs} Steps:{cur_step}\/{len(dataloader)}\\t\"\n        print_val += f\"Epoch_Run_Time: {(time.time()-start):.6f}\\t\"\n        print_val += f\"Loss_D : {disc_loss.item():.6f}\\t\"\n        print_val += f\"Loss_G : {gen_loss.item():.6f}\\t\"  \n        print(print_val, end='\\r',flush = True)\n       \n    \n    print()\n    loss_D_mean = mean_discriminator_loss \/ cur_step\n    loss_G_mean = mean_generator_loss \/ cur_step\n    print_val = f\"Epoch: {epoch}\/{n_epochs} Total Steps:{total_steps}\\t\"\n    print_val += f\"Total_Time : {(time.time() - start_time):.6f}\\t\"\n    print_val += f\"Loss_D : {disc_loss.item():.6f}\\t\"\n    print_val += f\"Loss_G : {gen_loss.item():.6f}\\t\"\n    print_val += f\"Loss_D_Mean : {loss_D_mean:.6f}\\t\"\n    print_val += f\"Loss_G_Mean : {loss_G_mean:.6f}\\t\"\n    print(print_val, end='\\r',flush = True)\n    \n    D_mean_losses.append(loss_D_mean)\n    G_mean_losses.append(loss_G_mean)\n    \n    fake_noise = fixed_noise\n    fake = gen(fake_noise)\n    show_tensor_images(fake, show_fig=True,epoch=epoch)\n    mean_generator_loss = 0\n    mean_discriminator_loss = 0","b12b0fa6":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_losses,label=\"G-Loss\")\nplt.plot(D_losses,label=\"D-Loss\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","8975bfac":"plt.figure(figsize=(10,5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(G_mean_losses,label=\"G-loss-mean\")\nplt.plot(D_mean_losses,label=\"D-loss-mean\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","5ac7bf46":"anim_file = 'DCGAN-GAN.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  for filename in filenames:\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\n\n!pip install -q git+https:\/\/github.com\/tensorflow\/docs\nimport tensorflow_docs.vis.embed as embed\nembed.embed_file(anim_file)\n","80498167":"def show_new_gen_images(tensor_img, num_img=25):\n    tensor_img = (tensor_img + 1) \/ 2\n    unflat_img = tensor_img.detach().cpu()\n    img_grid = make_grid(unflat_img[:num_img], nrow=5)\n    plt.imshow(img_grid.permute(1, 2, 0).squeeze(),cmap='gray')\n    plt.show()\n\nnum_image = 25\nnoise = get_noise(num_image, z_dim, device=device)\nwith torch.no_grad():\n    fake_img = gen(noise)\n\nshow_new_gen_images(fake_img.reshape(num_image,1,28,28))","5138cd0a":"# MNIST Dataset Load","2f8204a0":"# Important Resources\n\n[MNIST Database](http:\/\/yann.lecun.com\/exdb\/mnist\/)\n\n[The DCGAN Paper ( Alec Radford, Luke Metz, Soumith Chintala )](https:\/\/arxiv.org\/abs\/1511.06434)\n\n[A Closer Look at Transposed Convolutions](https:\/\/distill.pub\/2016\/deconv-checkerboard\/)\n\n<!-- [GANs for Video](https:\/\/colab.research.google.com\/github\/https-deeplearning-ai\/GANs-Public\/blob\/master\/C1W2_Video_Generation_(Optional).ipynb) -->\n\n","749322be":"# Loaded Data Visualization","739b431f":"# Noise Creator Function","48e7dbfe":"# Animated GIF Create & Show","97893b89":"# Generator","d1b0b1ae":"# Model Training Process","84429a09":"# DCGAN ","2e365e92":"# Import Packages","ff785a7c":"# Testing DCGAN","a2ae98b4":"# Loss Function & Optimizer","f4d5497b":"# After Tranning Loss Visualization","d8602e06":"# <center> <H1> -- Thank You -- <\/h1>  <\/center>","57efbba1":"# Discriminator","dad5583e":"## Table of Contents\n\n* **[Import Packages](#Import-Packages)**\n\n* **[Device Mode](#Device-Mode)**\n\n* **[Generator](#Generator)**\n\n* **[Discriminator](#Discriminator)**\n\n* **[Noise Creator Function](#Noise-Creator-Function)**\n\n* **[MNIST Dataset Load](#MNIST-Dataset-Load)**\n\n* **[Loaded Data Visualization](#Loaded-Data-Visualization)**\n\n* **[Loss Function & Optimizer](#Loss-Function-&-Optimizer)**\n\n* **[Model Training Process](#Model-Training-Process)**\n\n* **[After Tranning Loss Visualization](#After-Tranning-Loss-Visualization)**\n\n* **[Animated GIF Create & Show](#Animated-GIF-Create-&-Show)**\n\n* **[Testing DCGAN](#Testing-DCGAN)**\n\n* **[Important Resources](#Important-Resources)**\n\n","ffc9a06f":"# Device Mode"}}