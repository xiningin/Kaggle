{"cell_type":{"9a5a26b3":"code","82885b52":"code","901bf634":"code","1238fec7":"code","a0eb5215":"code","e36ae821":"code","775b2c42":"code","1c656f0d":"code","a98e1f64":"code","b9bbbc51":"code","32438f0b":"code","87d2b4fe":"code","196849e5":"code","1844b3c3":"code","87c5c6ad":"code","efc856b9":"code","0978485c":"code","7b48909b":"code","29642aa6":"code","d1e402da":"code","1cb1dfa6":"code","ce866f42":"code","024ab014":"code","6446d21c":"code","592d21b1":"code","95a339ad":"code","10204775":"code","09056b29":"code","02e5fc83":"code","e0b36280":"code","d6b34a77":"code","7ba7d8d4":"code","4703e356":"code","1c970d37":"code","8167a27c":"code","94e28bd9":"code","faff8bbb":"code","61921508":"code","7ef4a147":"code","9af9a14e":"code","79bd1ddb":"code","f6dab452":"code","1872edae":"code","8f923b53":"code","6025bb62":"code","0b51671b":"code","10b01242":"code","02c27bd1":"code","dd573ec7":"code","292b89e8":"code","6403378f":"markdown","414456c3":"markdown","72821344":"markdown","e30911dc":"markdown","c7fc527d":"markdown","45aaf5d6":"markdown","93fd8ccb":"markdown"},"source":{"9a5a26b3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option(\"display.max_columns\", 999)\npd.set_option(\"display.max_rows\", 999)\n%matplotlib inline\nimport warnings\nwarnings.simplefilter(action = \"ignore\")","82885b52":"df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","901bf634":"df.head()","1238fec7":"df.columns","a0eb5215":"df.shape","e36ae821":"#almost 81 columns are there.\n#first we need to see the nan values there or not","775b2c42":"null_lst = []\nnull_percen = []\nnull_count = []\nfor i in df.columns:\n    count = 0\n    if df[i].isnull().sum()>=1:\n        null_lst.append(i)\n        count = df[i].isnull().sum()\n        null_count.append(count)\n        percentage = (count\/len(df))*100\n        null_percen.append(percentage)","1c656f0d":"null_dict = {\"null_lst\" : null_lst, \"null_percentage\" : null_percen, \"null_count\" : null_count}\nnull_df = pd.DataFrame.from_dict(null_dict)","a98e1f64":"null_df","b9bbbc51":"fig = plt.figure(figsize = (20,5))\nsns.barplot(x = \"null_lst\", y = \"null_percentage\", data = null_df)","32438f0b":"#Need to see the plot based on null values:\nfor i in null_lst:\n    fig = plt.figure()\n    df[i + '_null_feature'] = np.where(df[i].isnull(), 1, 0)\n    sns.barplot(x = df[i + '_null_feature'], y = df['SalePrice'], data = df)\n    df.drop(columns = [i + \"_null_feature\"], inplace = True)\n    plt.show()","87d2b4fe":"#split the cata(nominal and ordinal based on the description) and num variables\ncategorical_features = df.select_dtypes(include = \"object\")\nnumerical_features = df.select_dtypes(exclude = \"object\")\n\nordinal_categorical_features = df[['MSZoning', 'LotShape', 'LandSlope', 'HouseStyle', 'BldgType', 'ExterQual', 'ExterCond','BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageFinish', 'GarageCond', 'PoolQC']].columns\nnominal_categorical_features = []\nfor i in categorical_features:\n    if i not in ordinal_categorical_features:\n        nominal_categorical_features.append(i)","196849e5":"print(categorical_features.shape)\nlen(ordinal_categorical_features) + len(nominal_categorical_features)","1844b3c3":"null_cata = []\nnull_nom_cata = []\nnull_ord_cata = []\nnull_num = []\nfor i in null_lst:\n    if i in categorical_features:\n        null_cata.append(i)\n        if i in nominal_categorical_features:\n            null_nom_cata.append(i)\n        elif i in ordinal_categorical_features:\n            null_ord_cata.append(i)\n    elif i in numerical_features:\n        null_num.append(i)","87c5c6ad":"for i in null_ord_cata:\n    print(i, null_df[null_df[\"null_lst\"] == i])","efc856b9":"df['BsmtCond'].value_counts()","0978485c":"#perform label encoding on the cata's\nQual_dict = {np.nan : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4}\ncond_dict = {np.nan : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, 'Ex' : 5}\nExposure_dict = {np.nan : 0, \"No\" : 1, \"Mn\" : 2, \"Av\" : 3, \"Gd\" : 4}\nFintype_dict = {np.nan : 0, \"Unf\" : 1, \"LwQ\" : 2, \"Rec\" : 3, \"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6}\nFire_dict = {np.nan : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5}\nGarage_dict = {np.nan : 0, \"Unf\" : 1, \"RFn\" : 2, \"Fin\" : 3}","7b48909b":"df['BsmtQual'] = df['BsmtQual'].map(Qual_dict)\ndf['BsmtCond'] = df['BsmtCond'].map(cond_dict)\ndf['GarageQual'] = df['GarageQual'].map(cond_dict)\ndf['GarageCond'] = df['GarageCond'].map(cond_dict)\ndf['PoolQC'] = df['PoolQC'].map(Qual_dict)\n\ndf['BsmtExposure'] = df['BsmtExposure'].map(Exposure_dict)\n\ndf['BsmtFinType1'] = df['BsmtFinType1'].map(Fintype_dict)\n\ndf['BsmtFinType2'] = df['BsmtFinType2'].map(Fintype_dict)\n\ndf['FireplaceQu'] = df[\"FireplaceQu\"].map(Fire_dict)\n\ndf['GarageFinish'] = df[\"GarageFinish\"].map(Garage_dict)\n\n","29642aa6":"for i in null_ord_cata:\n    print(df[i].isnull().sum())","d1e402da":"#now need to work on nomical categories:","1cb1dfa6":"for i in null_nom_cata:\n    print(i, null_df[null_df[\"null_lst\"] == i])","ce866f42":"#replace than all nan's with another category:\nfor i in null_nom_cata:\n    df[i] = df[i].fillna(\"missed\")","024ab014":"for i in null_cata:\n    val = df[i].isnull().sum()\n    if val > 0 :\n        print(\"Still i am null!!\")\n    elif val == 0:\n        print(i , \"I am fine!\")","6446d21c":"for i in null_num:\n    print(i, null_df[null_df[\"null_lst\"] == i])","592d21b1":"#fill all na's in num with median except lotfrontage and fill that with random values\ndef random_val_for_cata(df,var):\n    random_sample = df[var].dropna().sample(df[i].isnull().sum(), random_state = 0)\n    random_sample.index = df[df[var].isnull()].index\n    df.loc[df[var].isnull(), var] = random_sample\nfor i in null_num:\n    if i == \"LotFrontage\":\n        #function is taken for fillin random values.\n        random_val_for_cata(df,i)\n    else:\n        df[i] = df[i].fillna(np.median(df[i]))","95a339ad":"for i in df.columns:\n    if df[i].isnull().sum()>0:\n        print(i, df[i].isnull().sum())","10204775":"#df['GarageYrBlt'] #year is having null value's \n#replace this with highest value\ndf['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['GarageYrBlt'].value_counts().index.max())\ndf['MasVnrArea'] = df['MasVnrArea'].fillna(int(df['MasVnrArea'].mean()))","09056b29":"#Now all na's are removed.","02e5fc83":"for i in categorical_features:\n    print(i, df[i].unique())","e0b36280":"for i in ordinal_categorical_features:\n    print(i, df[i].unique())","d6b34a77":"mszone_dict = {\"C (all)\" : 1, \"FV\" : 2, \"RL\" : 3,'RM' : 4, 'RH' : 5}\nlotshape_dict = {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4}\nlandslope_dict = {\"Gtl\" : 1, \"Mod\" : 2, \"Sev\" : 3}\nhouse_dict = {\"1Story\" : 1, \"1.5Fin\" : 2, \"1.5Unf\" : 3, \"2Story\" : 4, \"2.5Fin\" : 5, \"2.5Unf\" : 6, \"SFoyer\" : 7, \"SLvl\" : 8}\nblgd_dict = {\"1Fam\" : 1, \"2fmCon\" : 2, \"Duplex\" : 3, \"TwnhsE\": 4, \"Twnhs\" : 5}\nqual_dict = {\"Po\":1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\": 5}","7ba7d8d4":"def label_encoding(df,var, dic):\n    df[var] = df[var].map(dic)","4703e356":"label_encoding(df,\"MSZoning\", mszone_dict)\nlabel_encoding(df,\"LotShape\", lotshape_dict)\nlabel_encoding(df,\"LandSlope\", landslope_dict)\nlabel_encoding(df,\"HouseStyle\", house_dict)\n\nlabel_encoding(df,\"BldgType\", blgd_dict)\nlabel_encoding(df,\"ExterQual\",qual_dict)\nlabel_encoding(df,\"ExterCond\",qual_dict)\nlabel_encoding(df,\"HeatingQC\",qual_dict)\nlabel_encoding(df,\"KitchenQual\",qual_dict)","1c970d37":"for i in ordinal_categorical_features:\n    print(i, df[i].unique())","8167a27c":"less_norm_catas = []\nfor i in nominal_categorical_features:\n    if df[i].nunique()<4:\n        less_norm_catas.append(i)\nprint(less_norm_catas)","94e28bd9":"#for less cata's, we create dummy's\nStreet = pd.get_dummies(df['Street'], drop_first = True)\nAlley = pd.get_dummies(df['Alley'], drop_first = True)\nStreet = pd.get_dummies(df['Street'], drop_first = True)\nUtilities = pd.get_dummies(df['Utilities'], drop_first = True)\nCentralAir = pd.get_dummies(df['CentralAir'], drop_first = True)\nPavedDrive = pd.get_dummies(df['PavedDrive'], drop_first = True)","faff8bbb":"df = pd.concat([df,Street, Alley, Utilities, CentralAir, PavedDrive], axis=1)","61921508":"df.drop(columns = less_norm_catas , inplace = True)","7ef4a147":"#now work on cata's having more number of categories\nmore_norm_cata = []\nfor i in categorical_features:\n    if i not in less_norm_catas:\n            more_norm_cata.append(i)","9af9a14e":"more_norm_cata","79bd1ddb":"#replace the cate with their mean based on the saleprice.\nfor i in more_norm_cata:\n    dic = (df.groupby([i])['SalePrice'].mean()\/len(df)).to_dict()\n    df[i] = df[i].map(dic)","f6dab452":"df","1872edae":"for i in numerical_features:\n    colors = \"#\" + str(np.random.randint(100000,999999))\n    plt.hist(df[i], color = colors, label = i)\n\n    plt.legend()\n    plt.show()","8f923b53":"Y = df[['SalePrice']]\ndf.drop(columns = ['SalePrice'], inplace = True)","6025bb62":"#here i am not going to apply any transformations\n#Apply minmaxscalar\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()","0b51671b":"scaled_data = scaler.fit_transform(df)","10b01242":"df = pd.DataFrame(scaled_data, columns = df.columns)","02c27bd1":"df","dd573ec7":"df.drop(\"Id\", axis = 1, inplace = True)","292b89e8":"final_df = pd.concat([df, Y], axis = 1)","6403378f":"Now work on nominal categorial variables","414456c3":"## Steps we have to follow:\n1) data analysis\n\n2) Work on Null Values\n\n3) Work on Categorical Features:\n    i) Nominal and then\n    ii) Ordinal\n\n4) Transformations","72821344":"Now all null values are cleared for cata's and go for num's","e30911dc":"first we need to focus on ordinal categorical features","c7fc527d":"#### incase of ordinal cata having null values. we need to consider that by not removing.\n","45aaf5d6":"# Advance House Prediction","93fd8ccb":"Next step is to go for encoding for catalabels"}}