{"cell_type":{"20eb2b20":"code","7e5330de":"code","eea5bad7":"code","80516b09":"code","f84acf05":"code","9146e922":"code","e6752115":"code","a96a0648":"code","4364cd40":"code","9781d700":"code","1f883b11":"code","4f756d64":"code","a7d28e59":"code","986bbc39":"code","1c215519":"code","37e3817d":"code","42cbad61":"code","80e9e0c3":"code","ad41ca98":"code","f068d1ea":"code","5f8b8d85":"code","43814c00":"code","10a5ac18":"code","7ad5c52c":"code","f560f1d0":"code","37a1553b":"code","5e57ebbf":"code","20aa09c2":"code","41ce6e6e":"code","182aaec0":"code","06dac593":"code","c2090f2f":"code","8fcd4cc2":"code","bea28749":"code","0072028f":"code","be49c023":"code","9648c482":"markdown","3ce58194":"markdown","2ea934c4":"markdown","8b6dd47e":"markdown","60af5ecd":"markdown","1a6699d1":"markdown","96b8905b":"markdown","2df17871":"markdown","b35d8811":"markdown","4334dff2":"markdown","7999436c":"markdown","51be3c69":"markdown"},"source":{"20eb2b20":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7e5330de":"import zipfile\n\nfiles=['\/kaggle\/input\/word2vec-nlp-tutorial\/labeledTrainData.tsv.zip',\n       '\/kaggle\/input\/word2vec-nlp-tutorial\/testData.tsv.zip',\n       '\/kaggle\/input\/word2vec-nlp-tutorial\/unlabeledTrainData.tsv.zip']\n\nfor file in files :\n    zip = zipfile.ZipFile(file,'r')\n    zip.extractall()\n    zip.close()","eea5bad7":"train=pd.read_csv('\/kaggle\/working\/labeledTrainData.tsv', delimiter=\"\\t\")\ntest=pd.read_csv('\/kaggle\/working\/testData.tsv', delimiter=\"\\t\")","80516b09":"sub=pd.read_csv('\/kaggle\/input\/word2vec-nlp-tutorial\/sampleSubmission.csv')","f84acf05":"train.head()","9146e922":"print('the train data is : {} line'.format(len(train)))\nprint('the test data is : {} line'.format(len(test)))","e6752115":"train_len=train['review'].apply(len)\ntest_len=test['review'].apply(len)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot((train_len),color='red')\n\nfig.add_subplot(1,2,2)\nsns.distplot((test_len),color='blue')","a96a0648":"train['word_n'] = train['review'].apply(lambda x : len(x.split(' ')))\ntest['word_n'] = test['review'].apply(lambda x : len(x.split(' ')))\n\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot(train['word_n'],color='red')\n\nfig.add_subplot(1,2,2)\nsns.distplot(test['word_n'],color='blue')\n","4364cd40":"train['length']=train['review'].apply(len)\ntrain['length'].describe()","9781d700":"train['word_n'].describe()","1f883b11":"from wordcloud import WordCloud\ncloud=WordCloud(width=800, height=600).generate(\" \".join(train['review'])) # join function can help merge all words into one string. \" \" means space can be a sep between words.\nplt.figure(figsize=(15,10))\nplt.imshow(cloud)\nplt.axis('off')","4f756d64":"fig, axe = plt.subplots(1,3, figsize=(23,5))\nsns.countplot(train['sentiment'], ax=axe[0])\nsns.boxenplot(x=train['sentiment'], y=train['length'], data=train, ax=axe[1])\nsns.boxenplot(x=train['sentiment'], y=train['word_n'], data=train, ax=axe[2])","a7d28e59":"print('the review with question mark is {}'.format(np.mean(train['review'].apply(lambda x : '?' in x))))\nprint('the review with fullstop mark is {}'.format(np.mean(train['review'].apply(lambda x : '.' in x))))\nprint('the ratio of the first capital letter is {}'.format(np.mean(train['review'].apply(lambda x : x[0].isupper()))))\nprint('the ratio with the capital letter is {}'.format(np.mean(train['review'].apply(lambda x : max(y.isupper() for y in x)))))\nprint('the ratio with the number is {}'.format(np.mean(train['review'].apply(lambda x : max(y.isdigit() for y in x)))))","986bbc39":"import re\nimport json\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer","1c215519":"train['review']=train['review'].apply(lambda x: BeautifulSoup(x,\"html5lib\").get_text())\ntest['review']=test['review'].apply(lambda x: BeautifulSoup(x,\"html5lib\").get_text())","37e3817d":"train['review']=train['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \",x))\ntest['review']=test['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \",x))","42cbad61":"train.head(3)","80e9e0c3":"stops = set(stopwords.words(\"english\"))\n\nfor i in range(0,25000) : \n    review = train.iloc[i,2] # review column : 2 \n    review = review.lower().split()\n    words = [r for r in review if not r in stops]\n    clean_review = ' '.join(words)\n    train.iloc[i,2] = clean_review","ad41ca98":"for i in range(0,25000) : \n    review = test.iloc[i,1] # review column : 1\n    review = review.lower().split()\n    words = [r for r in review if not r in stops]\n    clean_review = ' '.join(words)\n    test.iloc[i,1] = clean_review","f068d1ea":"train['word_n_2'] = train['review'].apply(lambda x : len(x.split(' ')))\ntest['word_n_2'] = test['review'].apply(lambda x : len(x.split(' ')))\n\nfig, axe = plt.subplots(1,1, figsize=(7,5))\nsns.boxenplot(x=train['sentiment'], y=train['word_n_2'], data=train)","5f8b8d85":"from keras.preprocessing.text import Tokenizer\ntk = Tokenizer()\ntk.fit_on_texts(list(train['review'])+list(test['review']))\ntext_seq_tr=tk.texts_to_sequences(train['review'])\ntext_seq_te=tk.texts_to_sequences(test['review'])\nword_ind=tk.word_index","43814c00":"print('Total word count is :',len(word_ind))","10a5ac18":"data_info={}\ndata_info['word_ind']=word_ind\ndata_info['word_len']=len(word_ind)+1","7ad5c52c":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig=plt.figure(figsize=(15,4))\nfig.add_subplot(1,2,1)\nsns.distplot(pd.Series(text_seq_tr).apply(lambda x : len(x)))\nfig.add_subplot(1,2,2)\nsns.distplot(pd.Series(text_seq_te).apply(lambda x : len(x)))","f560f1d0":"from keras.preprocessing.sequence import pad_sequences\npad_train=pad_sequences(text_seq_tr, maxlen=400) \npad_test=pad_sequences(text_seq_te, maxlen=400) ","37a1553b":"from sklearn.model_selection import train_test_split\nx_train, x_valid, y_train, y_valid = train_test_split(pad_train, train['sentiment'], random_state=77, test_size=0.07, stratify=train['sentiment'])","5e57ebbf":"len(tk.word_index)","20aa09c2":"from keras import Sequential\nfrom keras.layers import Dense, Embedding, Flatten\n\nmodel=Sequential()\nmodel.add(Embedding(101247,65, input_length=400))\nmodel.add(Flatten())\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['acc'] )","41ce6e6e":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nes=EarlyStopping(patience=4) \nmc=ModelCheckpoint('best.h5',save_best_only=True)\nmodel.fit(x_train,y_train, batch_size=128, epochs=10, validation_data=[x_valid,y_valid], callbacks=[es,mc]) ","182aaec0":"model.load_weights('best.h5')","06dac593":"res=model.predict(pad_test, batch_size=128)","c2090f2f":"res","8fcd4cc2":"sub['sentiment_pro']=res[:,1]","bea28749":"sub.loc[sub['sentiment_pro']>=0.5,\"sentiment\"]=1\nsub.loc[sub['sentiment_pro']<0.5,\"sentiment\"]=0","0072028f":"sub=sub[['id','sentiment']]","be49c023":"sub.to_csv('result.csv',index=False)","9648c482":"- use validation set, when we make a model. test_size is set in between 5% to 10%, to use more data","3ce58194":"## 1. EDA of review texts\n1. `Character distriubtion` of each review\n1. `Word distriubtion` of each review\n1. `Word cloud` of each word\n1. Distribution by `Sentiment class`\n1. Ratio with `special characters`","2ea934c4":"- Usiung keras, tokenization and mapping to numbers are done\n- When fitting, `use all data from train and text data set`, which prevents model from errors","8b6dd47e":"## 2. Preprocessing\n1. Remove `HTML tags` such as `<br>` using BeautifulSoup\n1. Only `english character` will remain using regular expression\n1. By NLTK, `stopwords` will be eliminated","60af5ecd":"- `Distribution of words in one review` is similar both in train and test set\n- The `mean words` count is 233 and `std` is 173 words\n- The character count seems to show similar distribution with word count","1a6699d1":"- `max length` is set, if length more than max length, `zero value` will replace that place","96b8905b":"- The distribution of sentiment is `half and half` between zero and one\n- The review length distribution by sentiment is similar but if somebody feels harshly dissatisfied, the reveiw tends to be wordy (more outliers)","2df17871":"- `br` is the most frequent one. But br is a sort of HTML tag, Thus it should be removed.\n- `movie` or `film` is the theme which all reviews share. Thus I suppose `idf(inverse document frequency)` shoul be close to zero","b35d8811":"![Imgur](https:\/\/i.imgur.com\/iy82iZq.png)","4334dff2":"## 3. Modeling\n1. *`sequential model`* using adam optimizer\n1. set `early stopping` and `model checkpoint` (patient option)","7999436c":"- Use *`0.5 as thereshold`* to specify one or zero","51be3c69":"- After preprocessing, the distribution by sentiment in train data is `not so different` from previous state `except total counts`"}}