{"cell_type":{"91ecc316":"code","8c88f10a":"code","1446c25e":"code","01244ea8":"code","3602589b":"code","9ef59f84":"code","29136d5c":"code","328ded8e":"code","43f5f555":"code","8211d0e1":"code","f3f31f38":"code","988e0f56":"code","645f384b":"markdown","c1a38a83":"markdown","4a1cdaea":"markdown","eb09da8e":"markdown","2b2ea593":"markdown"},"source":{"91ecc316":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport os\n\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler,StandardScaler,OneHotEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error,auc\n\nimport warnings\nwarnings.filterwarnings('ignore')","8c88f10a":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2021\/sample_submission.csv')","1446c25e":"train.head()","01244ea8":"def rmse(y_true, y_pred):\n    return mean_squared_error(y_true, y_pred)","3602589b":"train_df = train.drop('id', axis = 1)\ntest_df = test.drop('id', axis=1)","9ef59f84":"X = train_df.drop('target', axis = 1)\ny = train_df['target']","29136d5c":"lasso = Lasso(alpha=0.0005, random_state = 1,max_iter=100)\n\nENet = ElasticNet(alpha = 0.0005, l1_ratio=0.9, random_state = 3,max_iter=100)\n\nGBoost = GradientBoostingRegressor(n_estimators = 100,learning_rate=0.05,\n                                   max_depth = 10, random_state=5)\n\nmodel_rf = RandomForestRegressor(max_depth=17,n_estimators=100)","328ded8e":"models = [lasso,ENet,GBoost,model_rf]\nscores={}\nfor model in models:\n    print(model)\n    model.fit(X,y)\n    tr_pred = model.predict(X)\n    scores[model] = rmse(y,tr_pred)\n    print(scores[model])","43f5f555":"class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=3):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # We again fit the data on clones of the original models\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        # Train cloned base models then create out-of-fold predictions\n        # that are needed to train the cloned meta-model\n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X.iloc[train_index], y[train_index])\n                y_pred = instance.predict(X.iloc[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Do the predictions of all base models on the test data and use the averaged predictions as \n    #meta-features for the final prediction which is done by the meta-model\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)","8211d0e1":"stacked_averaged_models = StackingAveragedModels(base_models = (ENet, GBoost, model_rf),\n                                                 meta_model = lasso)\n\n\nstacked_averaged_models.fit(X, y)\n\nstacked_train_pred = stacked_averaged_models.predict(X)\n# stacked_pred = np.expm1(stacked_averaged_models.predict(test_))\nprint(rmse(y, stacked_train_pred))","f3f31f38":"test_pred = stacked_averaged_models.predict(test)\ntest_pred","988e0f56":"submission['target'] = test_pred\nsubmission.to_csv('submission.csv', index=False)","645f384b":"# Building Different Models","c1a38a83":"# Stacked regressor","4a1cdaea":"Predicting for the test data","eb09da8e":"# Loading the Dataset","2b2ea593":"# Importing libraries\n\nImporting all the necessary libraries"}}