{"cell_type":{"fa40b06b":"code","f474cab0":"code","2ae8988b":"code","3d805d73":"code","877b2b88":"code","69d88d71":"code","aebc56cb":"code","2143c88c":"code","74ea6c26":"code","8ae88727":"code","40985c93":"code","2d123293":"code","a96214eb":"code","f560b043":"code","4071a49e":"code","3e14dd8f":"code","2e1f208a":"code","411aa4b3":"code","235bd16d":"code","4f30aa9d":"code","a1561a51":"code","cd50ebdd":"code","cd0271bf":"code","71a79de5":"code","3a235f42":"code","64b3ffca":"code","0c79e58b":"code","b9cc92fb":"code","0ec35fa9":"code","1889f595":"code","63361079":"code","ff0338ea":"code","750a7a34":"code","34eb3e3b":"code","83e49465":"code","27652aa9":"code","13194093":"code","c3acb90f":"code","faca0442":"code","cf5c5844":"code","62dc0c32":"code","76695c79":"code","d4f2cdc7":"code","2835df7c":"code","e3ed391a":"code","5c1087ab":"code","fa07fee3":"code","621acc67":"markdown","bc6ae1ec":"markdown","b6e809c9":"markdown","01df3dea":"markdown","380d7111":"markdown","281d0909":"markdown","49fd3f5a":"markdown","f346c522":"markdown","be4615e0":"markdown","77b5e809":"markdown","f268d77b":"markdown","49f82eff":"markdown","33623cd3":"markdown","24dd5efa":"markdown","f1113b3e":"markdown","73b0602a":"markdown","9baedebb":"markdown","b8e6047f":"markdown","14a21404":"markdown","ac9e6b1e":"markdown","3aa6e5c8":"markdown","eecb1f26":"markdown","7165b7f4":"markdown"},"source":{"fa40b06b":"%matplotlib inline","f474cab0":"import os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns","2ae8988b":"#Load the trainig data csv file and make the data frame out of it\ntrain_df = pd.read_csv('..\/input\/train.csv')\n#Load the test data csv file and make the data frame out of it\ntest_df = pd.read_csv('..\/input\/test.csv')","3d805d73":"#display the first five rows of train_df\ntrain_df.head()","877b2b88":"print(\"The train data has {} rows and {} columns\".format(train_df.shape[0],train_df.shape[1]))","69d88d71":"#display the first five rows of test_df\ntest_df.head()","aebc56cb":"print(\"The test data has {} rows and {} columns\".format(test_df.shape[0],test_df.shape[1]))","2143c88c":"#check column wise null and missing values\ntrain_df.apply(lambda x: sum(x.isnull()))","74ea6c26":"#display information of train dataframe\ntrain_df.info()","8ae88727":"#display 5 number summary of train dataframe\ntrain_df.describe()","40985c93":"print(\"Percent of missing Age records is {}%\".format((177\/891)*100))","2d123293":"#display distribution of age column\nax = train_df[\"Age\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\ntrain_df[\"Age\"].plot(kind='density', color='teal')\nax.set(xlabel='Age')\nplt.xlim(-10,85)\nplt.show()","a96214eb":"print(\"Percent of missing Cabin records is {}%\".format((687\/891)*100))","f560b043":"print(\"Percent of missing Embarked records is {}%\".format((2\/891)*100))","4071a49e":"#from data set we know C==Cherbourg,Q=Queens,S=Southampton\nprint(\"Boarded passengers are grouped by port of Embark(C==Cherbourg,Q=Queens,S=Southampton)\")\nprint(train_df['Embarked'].value_counts())","3e14dd8f":"sns.countplot(train_df['Embarked'])","2e1f208a":"train_data = train_df.copy()","411aa4b3":"train_data['Age'].fillna(train_df['Age'].median(),inplace=True)\ntrain_data['Embarked'].fillna(train_df['Embarked'].value_counts().idxmax(),inplace=True)\ntrain_data.drop('Cabin',axis=1,inplace=True)","235bd16d":"#check now null values are there in new dataframe\ntrain_data.apply(lambda x: sum(x.isnull()))","4f30aa9d":"#comaprison of Age distibution before and after adjustment\nplt.figure(figsize=(15,10))\nax = train_df['Age'].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\ntrain_df['Age'].plot(kind='density', color='teal')\nax = train_data['Age'].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.5)\ntrain_data['Age'].plot(kind='density', color='orange')\nax.legend(['Age Before Adjustment','Age After Adjustment'])\nax.set(xlabel='Age')\nplt.xlim(-10,85)\nplt.show()","a1561a51":"train_data['TravelAlone'] = np.where((train_data['SibSp']+train_data['Parch'])>0, 0, 1)\ntrain_data.drop('SibSp',axis=1,inplace=True)\ntrain_data.drop('Parch',axis=1,inplace=True)","cd50ebdd":"training = pd.get_dummies(train_data,columns=[\"Pclass\",\"Embarked\",\"Sex\"])","cd0271bf":"training.drop('Sex_female', axis=1, inplace=True)\ntraining.drop('PassengerId', axis=1, inplace=True)\ntraining.drop('Name', axis=1, inplace=True)\ntraining.drop('Ticket', axis=1, inplace=True)\nfinal_train = training\nfinal_train.head()","71a79de5":"test_df.apply(lambda x : sum(x.isnull()))","3a235f42":"#display the 5 number summary of test dataframe\ntest_df.describe()","64b3ffca":"test_data = test_df.copy()\ntest_data['Age'].fillna(train_df['Age'].median(),inplace=True)\ntest_data['Fare'].fillna(train_df['Fare'].median(),inplace=True)\ntest_data.drop('Cabin',axis=1,inplace=True)","0c79e58b":"#now check null values are there in test dataframe\ntest_data.apply(lambda x : sum(x.isnull()))","b9cc92fb":"test_data['TravelAlone']=np.where((test_data[\"SibSp\"]+test_data[\"Parch\"])>0, 0, 1)\ntest_data.drop('SibSp', axis=1, inplace=True)\ntest_data.drop('Parch', axis=1, inplace=True)","0ec35fa9":"testing = pd.get_dummies(test_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\ntesting.drop('Sex_female', axis=1, inplace=True)\ntesting.drop('PassengerId', axis=1, inplace=True)\ntesting.drop('Name', axis=1, inplace=True)\ntesting.drop('Ticket', axis=1, inplace=True)","1889f595":"final_test = testing\nfinal_test.head()","63361079":"plt.figure(figsize=(15,10))\nax = sns.kdeplot(final_train['Age'][final_train['Survived']==1],color='Teal',shade=True)\nsns.kdeplot(final_train['Age'][final_train['Survived']==0],color='lightcoral',shade=True)\nplt.legend(['Survived','Died'])\nplt.title(\"Density plot of Age for surviving people and died people\")\nax.set(xlabel='Age')\nplt.xlim(-10,85)","ff0338ea":"final_train['IsMinor']=np.where(final_train['Age']<=16, 1, 0)\n\nfinal_test['IsMinor']=np.where(final_test['Age']<=16, 1, 0)","750a7a34":"plt.figure(figsize=(15,10))\navg_survival_by_age = final_train[['Age','Survived']].groupby(['Age'],as_index=False).mean()\nsns.barplot(x='Age',y='Survived',data=avg_survival_by_age)","34eb3e3b":"plt.figure(figsize=(15,10))\nax = sns.kdeplot(final_train['Fare'][final_train['Survived']==1],color='Teal',shade=True)\nsns.kdeplot(final_train['Fare'][final_train['Survived']==0],color='lightcoral',shade=True)\nplt.legend(['Survived','Died'])\nplt.title(\"Density plot of Fare for surviving people and died people\")\nax.set(xlabel='Fare')\nplt.xlim(-20,200)","83e49465":"sns.barplot('Pclass','Survived',data=train_df)","27652aa9":"sns.barplot('Embarked','Survived',data=train_df)","13194093":"sns.barplot('TravelAlone','Survived',data=final_train)","c3acb90f":"sns.barplot('Sex','Survived',data=train_df)","faca0442":"final_train.columns","cf5c5844":"plt.figure(figsize=(10,10))\nsns.heatmap(final_train.corr(),annot=True)","62dc0c32":"from sklearn.linear_model import LogisticRegression","76695c79":"from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\nX = final_train.drop('Survived',axis=1)\ny = final_train['Survived']","d4f2cdc7":"# use train\/test split with different random_state values\n# we can change the random_state values that changes the accuracy scores\n# the scores change a lot, this is why testing scores is a high-variance estimate\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)","2835df7c":"# check classification scores of logistic regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\ny_pred = logreg.predict(X_test)\ny_pred_proba = logreg.predict_proba(X_test)[:, 1]\nprint('Train\/Test split results:')\nprint(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\nprint(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))","e3ed391a":"final_test.info()","5c1087ab":"test_pred = logreg.predict(final_test)","fa07fee3":"test_pred.shape","621acc67":"so from above we can see most people embarked from Southampton port. so we can fill null values of Embarked Column with S (Southampton)","bc6ae1ec":"so from above we can see that only 0.22%(2) Embarked records are missing. so we can just impute with most occurring value in this column.","b6e809c9":"so from above we can see that Age,Fare and Cabin column are having missing values.","01df3dea":"Now we have new data frame called train_data. we will make changes to this dataframe.","380d7111":"people who are travelling alone has less survival than who are travelling with family.","281d0909":"Based on my assessment of the missing values in the dataset, I'll make the following changes to the data:\n\nIf \"Age\" is missing for a given row, I'll impute with 28 (median age).\nIf \"Embarked\" is missing for a riven row, I'll impute with \"S\" (the most common boarding port).\nI'll ignore \"Cabin\" as a variable. There are too many missing values for imputation. Based on the information available, it appears that this value is associated with the passenger's class and fare paid.","49fd3f5a":"so from above we can see that only 19.86% Age records are missing.","f346c522":"As the distributions are clearly different for the fares of survivors vs. deceased, it's likely that this would be a significant predictor in our final model. Passengers who paid lower fare appear to have been less likely to survive. ","be4615e0":"from above we can see that Age,Cabin and Embarked column has null values.","77b5e809":"from above we can see that Age is right skewed because long tail is at the right side(i.e.mean>median). then replacing null values with mean is not good. we will fill null values with median.","f268d77b":"So from above graph we can compare Age distribution before and after adjustment.After adjustment Age looks like normally distributed.","49f82eff":"now check the null values in test dataframe","33623cd3":"people who embarked from Cherbourg port appear to have highest survival rate.","24dd5efa":"I'll also create categorical variables for Passenger Class (\"Pclass\"), Gender (\"Sex\"), and Port Embarked (\"Embarked\").","f1113b3e":"so from above we can see that 77% Cabin records are missing.so imputing values and using this column is not useful. so, we will drop this column.","73b0602a":"As we can see that in test dataframe only 11 columns are there.(Survival column is missing). so our taget column is survival and we are going to predict the survival via Logistic Regression.","9baedebb":"from above it looks like first class passengers has highest survival rate.","b8e6047f":"so from above we can see that now no null values are there.","14a21404":"So, we will apply the same changes to test dataframe what we apply to train dataframe.","ac9e6b1e":"The age distribution for survivors and died people is actually very similar. One notable difference is that, of the survivors, a larger proportion were children.means belowe 16 year age people are survived more than died","3aa6e5c8":"Make another dataframe from train dataframe and make above changes to new dataframe.","eecb1f26":"females survival is more than males","7165b7f4":"According to the dataset, both SibSp and Parch relate to traveling with family. For simplicity's sake (and to account for possible multicollinearity), I'll combine the effect of these variables into one categorical predictor: whether or not that individual was traveling alone"}}