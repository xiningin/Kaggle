{"cell_type":{"8cc5cd43":"code","beb075da":"code","2017f220":"code","ab3fcfb2":"code","0a01a174":"code","474f0e7f":"code","76b170ab":"code","d33aeab6":"code","367ed0db":"code","42b39593":"code","07c3ee1f":"code","be13fb0f":"code","892af9ac":"code","8478d4e2":"code","f6c268dd":"code","d5562fb2":"code","c09e7e64":"code","9e6540f6":"code","c02700d2":"code","b8aa820f":"code","8f6813fb":"code","cec5e2ef":"code","7f6c0925":"code","cb0485c3":"code","4a7bdf8d":"code","91b4fd59":"code","817dc1dc":"code","70c511d7":"code","397c4422":"code","d38e3089":"code","e8356c81":"code","ac4585e7":"code","8300dc1a":"code","ba66611a":"code","49859084":"code","41655659":"code","e8660aed":"code","b9733d06":"code","1a5df521":"code","3bef9a5e":"code","fa835a0e":"code","7e881578":"code","46f45763":"code","e1a3cd6c":"code","c7a3726e":"code","217f5be6":"code","04ba6f55":"code","2013635e":"code","6ed7566a":"markdown","408484b6":"markdown","fae39439":"markdown","8d7bcd8e":"markdown","81048442":"markdown","20eca2fa":"markdown","a4034891":"markdown","70a69b81":"markdown","d03f26d8":"markdown","d6a971d4":"markdown","e09e7c29":"markdown","6cf3b751":"markdown","3353cbfa":"markdown","1b1c256a":"markdown","c939b76f":"markdown","b1c26fe3":"markdown"},"source":{"8cc5cd43":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","beb075da":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score","2017f220":"dataset = pd.read_csv('\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\ndataset.head()","ab3fcfb2":"dataset.describe(include = 'all')","0a01a174":"dataset.info()","474f0e7f":"dataset.isnull().sum()","76b170ab":"dataset['is_Stroke'] = ' '\nfor i in range(len(dataset)):\n    if dataset['stroke'][i] == 1:\n        dataset['is_Stroke'][i] = 'Yes'\n    else:\n        dataset['is_Stroke'][i] = 'No'","d33aeab6":"plt.figure(figsize = (10, 7))\nsns.countplot(x = dataset['gender'])\nplt.title('Gender', fontsize = 20)\nplt.xlabel('Gender')\nplt.ylabel('Count')\nplt.show()","367ed0db":"plt.figure(figsize = (10, 7))\nsns.countplot(x = dataset['is_Stroke'])\nplt.title('Stroke', fontsize = 20)\nplt.xlabel('Stroke')\nplt.ylabel('Count')\nplt.show()","42b39593":"plt.figure(figsize = (10, 7))\nsns.countplot(x = dataset['heart_disease'])\nplt.title('Heart Disease', fontsize = 20)\nplt.xlabel('Heart Disease')\nplt.ylabel('Count')\nplt.show()","07c3ee1f":"plt.figure(figsize = (10, 7))\nsns.countplot(x = dataset['hypertension'])\nplt.title('Hyper Tension', fontsize = 20)\nplt.xlabel('Hyper Tension')\nplt.ylabel('Count')\nplt.show()","be13fb0f":"plt.figure(figsize = (10, 7))\nsns.countplot(x = dataset['ever_married'])\nplt.title('Married or Not?', fontsize = 20)\nplt.xlabel('Married')\nplt.ylabel('Count')\nplt.show()","892af9ac":"plt.figure(figsize = (10, 7))\nsns.countplot(x = dataset['work_type'])\nplt.title('Type of Work', fontsize = 20)\nplt.xlabel('Work')\nplt.ylabel('Count')\nplt.show()","8478d4e2":"plt.figure(figsize = (10, 7))\nsns.countplot(x = dataset['Residence_type'])\nplt.title('Area of Residence', fontsize = 20)\nplt.xlabel('Area')\nplt.ylabel('Count')\nplt.show()","f6c268dd":"plt.figure(figsize = (10, 7))\nsns.countplot(x = dataset['smoking_status'])\nplt.title('Smoking Status', fontsize = 20)\nplt.xlabel('Somking')\nplt.ylabel('Count')\nplt.show()","d5562fb2":"plt.figure(figsize = (10, 7))\nsns.barplot(x = dataset['gender'], y = dataset['heart_disease'], hue = dataset['work_type'])\nplt.legend(loc = 'upper right')\nplt.title('Gender vs. Heart Disease based on Type of Job', fontsize = 20)\nplt.xlabel('Gender')\nplt.ylabel('Heart Disease')\nplt.show()","c09e7e64":"plt.figure(figsize = (10, 7))\nsns.barplot(x = dataset['gender'], y = dataset['heart_disease'], hue = dataset['smoking_status'])\nplt.legend(loc = 'upper right')\nplt.title('Gender vs. Heart Disease based on Smoking', fontsize = 20)\nplt.xlabel('Gender')\nplt.ylabel('Heart Disease')\nplt.show()","9e6540f6":"plt.figure(figsize = (10, 7))\nsns.barplot(x = dataset['gender'], y = dataset['heart_disease'], hue = dataset['is_Stroke'])\nplt.legend(loc = 'upper right')\nplt.title('Gender vs. Heart Disease based on Stroke', fontsize = 20)\nplt.xlabel('Gender')\nplt.ylabel('Heart Disease')\nplt.show()","c02700d2":"sns.pairplot(dataset)\nplt.show()","b8aa820f":"colors = ['mediumturquoise', 'darkorange', 'lightgreen']\nfig = go.Figure(data = [go.Pie(labels = dataset['gender'])])\nfig.update_traces(textfont_size = 20, marker = dict(colors = colors, line = dict(color = '#000000', width = 2)))\nfig.update_layout(title_text = 'Gender')\nfig.show()","8f6813fb":"colors = ['darkorange', 'lightgreen']\nfig = go.Figure(data = [go.Pie(labels = dataset['ever_married'])])\nfig.update_traces(textfont_size = 20, marker = dict(colors = colors, line = dict(color = '#000000', width = 2)))\nfig.update_layout(title_text = 'Maritial Status')\nfig.show()","cec5e2ef":"colors = ['darkorange', 'lightgreen']\nfig = go.Figure(data = [go.Pie(labels = dataset['work_type'])])\nfig.update_traces(textfont_size = 20, marker = dict(line = dict(color = '#000000', width = 2)))\nfig.update_layout(title_text = 'Working Status')\nfig.show()","7f6c0925":"colors = ['orange', 'seagreen', 'gold', 'red']\nfig = go.Figure(data = [go.Pie(labels = dataset['smoking_status'])])\nfig.update_traces(textfont_size = 20, marker = dict(colors = colors, line=dict(color = '#000000', width = 2)))\nfig.update_layout(title_text = 'Smoking Status')\nfig.show()","cb0485c3":"df = pd.DataFrame(dataset['smoking_status'].value_counts())\npx.bar(x = df.index, y = df.smoking_status, height = 400, text = df.smoking_status, labels = {'x':'Status', 'y': 'Count'},\n      title = 'Smoking Status vs. Count')","4a7bdf8d":"px.bar(data_frame = dataset, x = 'smoking_status', y = 'heart_disease', color = 'is_Stroke', height = 400,\n       labels = {'smoking_status':'Smoking Status', 'heart_disease':'Heart Disease'}, title = 'Smoking Status vs. Heart Disease based on Stroke')","91b4fd59":"counts, bins = np.histogram(dataset.bmi, bins=range(0, 100, 5))\nbins = 0.5 * (bins[:-1] + bins[1:])\n\nfig = px.bar(x = bins, y = counts, labels = {'x':'BMI', 'y':'Count'}, title = 'BMI Distribution')\nfig.show()","817dc1dc":"counts, bins = np.histogram(dataset.age, bins=range(0, 90, 5))\nbins = 0.5 * (bins[:-1] + bins[1:])\n\nfig = px.bar(x = bins, y = counts, labels = {'x':'Age', 'y':'Count'}, title = 'Age Distribution')\nfig.show()","70c511d7":"px.histogram(data_frame = dataset, x = 'age', color = 'is_Stroke', height = 400,\n             marginal = 'box', labels = {'age':'Age', 'count': 'Count'}, title = 'Age vs. Count based on Stroke')","397c4422":"px.box(x = dataset['bmi'], y = dataset['work_type'], color = dataset['Residence_type'], labels = {'x': 'BMI', 'y':'Work Type'},\n      title = 'BMI vs. Work Type based on Residence Type')","d38e3089":"px.box(x = dataset['bmi'], y = dataset['work_type'], color = dataset['gender'], labels = {'x': 'BMI', 'y':'Work Type'},\n      title = 'BMI vs. Work Type based on Gender')","e8356c81":"px.density_contour(data_frame = dataset, x = 'bmi', color = 'heart_disease', labels = {'bmi': 'BMI', 'index':''},\n                  title = 'Density Contour plot of BMI based on Heart Disease')","ac4585e7":"px.density_contour(data_frame = dataset, x = 'age', color = 'heart_disease', labels = {'age': 'Age', 'index':''},\n                  title = 'Density Contour plot of Age based on Heart Disease')","8300dc1a":"dataset.drop(['is_Stroke', 'id'], axis = 1, inplace = True)\ndataset.head()","ba66611a":"gender = pd.get_dummies(dataset['gender'], drop_first = True)\nmarried = pd.get_dummies(dataset['ever_married'], drop_first = True)\nwork = pd.get_dummies(dataset['work_type'], drop_first = True)\nresidence = pd.get_dummies(dataset['Residence_type'], drop_first = True)\nsmoking = pd.get_dummies(dataset['smoking_status'], drop_first = True)\ndataset = pd.concat([gender, married, work, residence, smoking, dataset], axis = 1)","49859084":"dataset.drop(['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'], axis = 1, inplace = True)\ndataset.head()","41655659":"from sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors = 5)\ndataset = pd.DataFrame(imputer.fit_transform(dataset), columns = dataset.columns)","e8660aed":"dataset.isnull().sum()","b9733d06":"dataset.rename(columns = {'Yes': 'ever_married'}, inplace = True)\ndataset.head()","1a5df521":"plt.figure(figsize = (12, 8))\nsns.heatmap(dataset.corr(), linecolor = 'white', linewidths = 1, annot = True)\nplt.show()","3bef9a5e":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","fa835a0e":"print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n  \n# import SMOTE module from imblearn library  \nfrom imblearn.combine import SMOTEENN \nsm = SMOTEENN(random_state = 0) \nX_train_res, y_train_res = sm.fit_resample(X_train, y_train) \n  \nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape)) \nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n  \nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1))) \nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))","7e881578":"from sklearn.linear_model import LogisticRegression\nlog = LogisticRegression(max_iter = 300)\nlog.fit(X_train_res, y_train_res)\n\ny_pred_log = log.predict(X_test)","46f45763":"print(\"The Training Score of Logistic Regression is: {}%\".format(log.score(X_train_res, y_train_res)*100))\nprint(\"The Accuracy Score of Logistic Regression is: {}%\".format(accuracy_score(y_test, y_pred_log)*100))\nprint(\"The Confusion Matrix for Logistic Regression is: \\n{}\\n\".format(confusion_matrix(y_test, y_pred_log)))\nprint('\\n')\nprint(classification_report(y_test, y_pred_log))","e1a3cd6c":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\ndt.fit(X_train_res, y_train_res)\n\ny_pred_dt = dt.predict(X_test)","c7a3726e":"print(\"The Training Score of Decision Tree is: {}%\".format(dt.score(X_train_res, y_train_res)*100))\nprint(\"The Accuracy Score of Decision Tree is: {}%\".format(accuracy_score(y_test, y_pred_dt)*100))\nprint(\"The Confusion Matrix for Decision Tree is: \\n{}\\n\".format(confusion_matrix(y_test, y_pred_dt)))\nprint('\\n')\nprint(classification_report(y_test, y_pred_dt))","217f5be6":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators = 300, criterion = 'entropy')\nrf.fit(X_train_res, y_train_res)\n\ny_pred_rf = rf.predict(X_test)","04ba6f55":"print(\"The Training Score of Random Forest is: {}%\".format(rf.score(X_train_res, y_train_res)*100))\nprint(\"The Accuracy Score of Random Forest is: {}%\".format(accuracy_score(y_test, y_pred_rf)*100))\nprint(\"The Confusion Matrix for Random Forest is: \\n{}\\n\".format(confusion_matrix(y_test, y_pred_rf)))\nprint('\\n')\nprint(classification_report(y_test, y_pred_rf))","2013635e":"print(\"F1 Score for Logistic Regression is: {}\".format(f1_score(y_test, y_pred_log)))\nprint(\"F1 Score for Decision Tree is: {}\".format(f1_score(y_test, y_pred_dt)))\nprint(\"F1 Score for Random Forest is: {}\".format(f1_score(y_test, y_pred_rf)))","6ed7566a":"# Importing the Libraries","408484b6":"### Encoding all the necessary columns","fae39439":"### Dropping all the unecessary columns","8d7bcd8e":"## Context\nAccording to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.\nThis dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.\n\n## Attribute Information\n1) id: unique identifier\n\n2) gender: \"Male\", \"Female\" or \"Other\"\n\n3) age: age of the patient\n\n4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n\n5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n\n6) ever_married: \"No\" or \"Yes\"\n\n7) work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n\n8) Residence_type: \"Rural\" or \"Urban\"\n\n9) avg_glucose_level: average glucose level in blood\n\n10) bmi: body mass index\n\n11) smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n\n12) stroke: 1 if the patient had a stroke or 0 if not\n\n***Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient***","81048442":"# Feature Engineering (Data Preprocessing)","20eca2fa":"### Filling the Missing values of BMI (Using KNN Imputation) ","a4034891":"### Appyling SMOTEENN Algorithm to handle the unbalanced 'stroke' column","70a69b81":"### Determining the Correlation between various Columns","d03f26d8":"# Classification Model","d6a971d4":"# Thank You :)","e09e7c29":"### Splitting the Dataset into Training and Test set","6cf3b751":"# Basic Data Wrangling","3353cbfa":"### Decision Tree","1b1c256a":"### Logistic Regression","c939b76f":"### Random Forest","b1c26fe3":"# Exploratory Data Analysis"}}