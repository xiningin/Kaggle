{"cell_type":{"76cc5847":"code","df7721d1":"code","eab02ad0":"code","d7d050c6":"code","020703e3":"code","5507a250":"code","c705a42b":"code","dac77279":"markdown","16e36337":"markdown"},"source":{"76cc5847":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","df7721d1":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()","eab02ad0":"test_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head()","d7d050c6":"women = train_data.loc[train_data.Sex == 'female']['Survived']\nrate_women = sum(women)\/len(women)\n\nprint('rate of survival number',  rate_women)","020703e3":"men = train_data.loc[train_data.Sex == 'male']['Survived']\nrate_men = sum(men)\/len(men)\n\nprint('rate pf survival number', rate_men)","5507a250":"from tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport math\n\ny = train_data['Survived'].to_numpy()\ny_1 = y\nfeatures = ['Pclass', 'Sex', 'SibSp', 'Parch']\nx_train = pd.get_dummies(train_data[features]).to_numpy()\nx_train_1 = x_train\nx_test = pd.get_dummies(test_data[features]).to_numpy()\nratio = math.trunc(len(x_train)*0.8)\nx_train = x_train[:ratio]\nx_valid = x_train_1[ratio:]\ny_train = y[:ratio]\ny_valid = y_1[ratio:]\n\nmodel = Sequential([\n    Dense(1024, input_shape = (5,), activation = 'relu'),\n    Dropout(0.5),\n    Dense(512, activation = 'relu'),\n    Dropout(0.5),\n    Dense(256, activation = 'relu'),\n    Dropout(0.5),\n    Dense(256, activation = 'relu'),\n    Dense(128, activation = 'relu'),\n    Dropout(0.5),\n    Dense(64, activation = 'relu'),\n    Dense(32, activation = 'relu'),\n    Dropout(0.5),\n    Dense(16, activation = 'relu'),\n    Dense(1, activation = 'sigmoid')\n])\nmodel.compile(optimizer = 'adam', loss='binary_crossentropy', metrics = ['acc'])\nc_path = 'check.ckpt'\ncheckpoint = ModelCheckpoint(filepath = c_path,\n                             save_weights_only=True,\n                             verbose=1,\n                             save_best_only = True,\n                             monitor = 'val_loss'\n                            )\nmodel.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=100,\n          callbacks=[checkpoint], verbose = 1)\nmodel.load_weights(c_path)\npredictions = model.predict(x_test)\n\nprint(predictions)","c705a42b":"pre_label = []\nfor i in range(len(predictions)):\n    if predictions[i][0] >= 0.5:\n        pre_label.append(1)\n    elif predictions[i][0] < 0.5:\n        pre_label.append(0)\noutput = pd.DataFrame({'PassengerId' : test_data.PassengerId,\n                      'Survived' : pre_label})\nprint(output)\n# output.to_csv('my_submission_2.csv', index=False)","dac77279":"### I got values of 'predictions' from 0 to 1.\n#### I need to convert these values to Survived value by own basis (prediction which is larger than 0.5 \u2192 save Survived value to 1)","16e36337":"# **Simple Titanic Model Using Tensorflow**\n## **Used Library**\n* **Tensorflow**\n* **numpy**\n* **pandas**\n\n### **This is my first competition & notebook!**\n#### **Recently, I got interested in Machine-Learning & Deep-Learning**\n* ****\u2193\u2193\u2193 Visit my first project using NEAT Algorithm!! \u2193\u2193\u2193****\n* [My Github Homepage](https:\/\/github.com\/JunHyeok-Navy\/NEAT_Ship_Simulator)\n\n#### Reference\n* Titanic Tutorial\n* Youtube\n"}}