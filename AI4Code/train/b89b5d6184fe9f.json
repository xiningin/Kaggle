{"cell_type":{"e31c93f2":"code","75e60b27":"code","1cf7c34b":"code","35957c6f":"code","baa692c4":"code","da199fb1":"code","cc8fe80e":"code","df345183":"code","67cec30d":"code","8ecfae1d":"code","2f234748":"code","7ad97690":"code","868b8b45":"code","ef256146":"code","94d40648":"code","ab4fcc1a":"code","9d4f5406":"code","f9eeac69":"code","8be10914":"code","e5e9bdc5":"code","f49a2b06":"code","9e0929c1":"code","cfc695c8":"code","be320712":"code","a052b58c":"code","f339822e":"code","ef830477":"code","da5edbcd":"code","2c08f5c2":"code","d4a035c8":"code","42374591":"code","b23ad9fc":"code","e89310d2":"code","cf715763":"code","7e420255":"code","8ca68859":"code","d84626e7":"code","4fc7991c":"code","2e2b1637":"code","1f84fd1d":"code","f7d3ac6d":"code","3763af0c":"code","9bcea660":"code","b40a645f":"code","2fd5d61e":"code","65c50565":"code","5fc01bc7":"code","ae03ed52":"code","fc9db1be":"code","39e7ea2c":"code","147f7882":"code","5fc4b079":"code","89c38e01":"code","4f28c7da":"code","0472cba2":"code","7caf0ba2":"code","cc60d6e1":"code","8a90609c":"code","4651b23e":"markdown","0d5e3dd6":"markdown","109982bc":"markdown","610d2635":"markdown","6ca5e08f":"markdown","060988e4":"markdown","dd0323a4":"markdown","5f51da21":"markdown","ab7f33d5":"markdown","ca81fdb4":"markdown","1ba49d14":"markdown","7bef7ac0":"markdown","d9359eb7":"markdown","7dda4029":"markdown","dd0ba6eb":"markdown","6b49725f":"markdown","6e0d2773":"markdown","562c177f":"markdown","6732d4fe":"markdown","4edb4610":"markdown","f96e0d07":"markdown","2e15afbb":"markdown","ba9ba72b":"markdown","ad1fbc7b":"markdown","58c690dc":"markdown","479e255c":"markdown","94547f30":"markdown","ef1594ae":"markdown","77bf3790":"markdown","bdc93602":"markdown"},"source":{"e31c93f2":"%matplotlib inline\n!pip install --upgrade pip\nimport pandas as pd\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\n! pip install -q scikit-plot\nfrom sklearn.tree import DecisionTreeRegressor\nimport scikitplot as skplt\nsns.set(style=\"white\")\nsns.set(style=\"whitegrid\", color_codes=True)\ndf = pd.read_csv('..\/input\/bci-final\/bci_final.csv')\ndata=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.info())\nfeatures = list(data.columns.values)\nprint(features)\nprint(df.head())\nintact=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\n\ncorr = data.corr() \nplt.figure(figsize=(12, 10))\n\nsns.heatmap(corr[(corr >= 0.0) | (corr <= -0.0)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);\n# Plottinf correlation above or below 0.5\ncorr = data.corr() # We already examined SalePrice correlations\nplt.figure(figsize=(12, 10))\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.5)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);\n\n\nimport seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","75e60b27":"data.info()","1cf7c34b":"print(data.head())\nreg_evaluation = pd.DataFrame({'Model': [],\n                           'Details':[],\n                           'RMSE(train)':[],\n                           'R-squared (train)':[],\n                           'Adj R-squared (train)':[],\n                           'MAE (train)':[],\n                           'RMSE (test)':[],\n                           'R-squared (test)':[],\n                           'Adj R-squared (test)':[],\n                           'MAE(test)':[],\n                           '10-Fold Cross Validation':[]})\n\nreg_evaluation2 = pd.DataFrame({'Model': [],\n                           'Test':[],\n                           '1':[],\n                           '2':[],\n                           '3':[],\n                           '4':[],\n                           '5':[],\n                           '6':[],\n                           '7':[],\n                           '8':[],\n                           '9':[],\n                           '10':[],\n                           'Mean':[]})\n\nclassification_evaluation = pd.DataFrame({'Model': [],\n                           'Accuracy(train)':[],\n                           'Precision(train)':[],\n                           'Recall(train)':[],\n                           'F1_score(train)':[],\n                           'Accuracy(test)':[],\n                           'Precision(test)':[],\n                           'Recalll(test)':[],\n                           'F1_score(test)':[]})\n\nclassification_evaluation2 = pd.DataFrame({'Model': [],\n                           'Test':[],\n                           '1':[],\n                           '2':[],\n                           '3':[],\n                           '4':[],\n                           '5':[],\n                           '6':[],\n                           '7':[],\n                           '8':[],\n                           '9':[],\n                           '10':[],\n                           'Mean':[]})\nprint(data.info())","35957c6f":"# from imblearn.over_sampling import SMOTE\n\n# # for reproducibility purposes\n# seed = 100\n# # SMOTE number of neighbors\n# k = 1\n\n# #df = pd.read_csv('df_imbalanced.csv', encoding='utf-8', engine='python')\n# # make a new df made of all the columns, except the target class\n# X = df.loc[:, df.columns != 'state']\n# y = df.state\n# sm = SMOTE(sampling_strategy='auto', k_neighbors=1, random_state=seed)\n# X_res, y_res = sm.fit_resample(X, y)\n\n# # plt.title('base')\n# # plt.xlabel('x')\n# # plt.ylabel('y')\n# # plt.scatter(X_res[:, 0], X_res[:, 1], marker='o', c=y_res,\n# #            s=25, edgecolor='k', cmap=plt.cm.coolwarm)\n# # plt.show()\n\n# df = pd.concat([pd.DataFrame(X_res), pd.DataFrame(y_res)], axis=1)\n# # rename the columns\n# #df.columns = ['e1\/do']+['e2\/do']+['fu\/fy']+['fmx\/fndt']+['type']\n# df.to_csv('df_smoted.csv', index=False, encoding='utf-8')\n# df.head()\n# data=df\n# print(data.shape)","baa692c4":"data.head()","da199fb1":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\nfrom sklearn.svm import SVR\ncomplex_model_1=SVR()\nfrom sklearn.tree import DecisionTreeRegressor\ncomplex_model_1= DecisionTreeRegressor(random_state=0)\n\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['SVR','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('SVR_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('SVR_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('SVR_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('SVR_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('SVR_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('SVR_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\nprint(intact)\ndata['beat-per-15 sec']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)","cc8fe80e":"# df['bpm']=MLR_y_pred_entire_data\nX = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score\nclf =svm.SVC(kernel='rbf',degree=100)\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['SVM',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('SVM_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('SVM_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('SVM_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('SVM_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('SVM_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('SVM_entire_actual.csv', y, delimiter=',', fmt='%s')\n\ndata['state']=MLR_y_pred_entire_data\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\n\np=y_train\nq=y_test\ny_train=y_train.replace([0,1], [\"Unconcerned\",\"Engaged\"])\npred_train=clf.predict(X_train)\npred_train=pd.DataFrame(pred_train)\n\npred_train=pred_train.replace([0,1], [\"Unconcerned\",\"Engaged\"])\n\npred_test=clf.predict(X_test)\ny_test=y_test.replace([0,1], [\"Unconcerned\",\"Engaged\"])\npred_test=pd.DataFrame(pred_test)\n\npred_test=pred_test.replace([0,1], [\"Unconcerned\",\"Engaged\"])\n\nskplt.metrics.plot_confusion_matrix(\n    y_train, \n    pred_train,\n    figsize=(8,7),\n    title_fontsize='20',\n    text_fontsize='20',\n    )\n\nskplt.metrics.plot_confusion_matrix(\n    y_test, \n    pred_test,\n    figsize=(8,7),\n    title_fontsize='20',\n    text_fontsize='20',\n    )\ny_train=p\ny_test=q\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","df345183":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","67cec30d":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","8ecfae1d":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\nfrom sklearn.ensemble import RandomForestRegressor\ncomplex_model_1 = RandomForestRegressor(n_estimators= 136, min_samples_split= 2,\n                                        min_samples_leaf= 1, max_features= 'auto',  bootstrap= 'True')\n\nfrom sklearn.tree import DecisionTreeRegressor\ncomplex_model_1= DecisionTreeRegressor(random_state=0)\n\n\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['RF_reg','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('RF_reg_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('RF_reg_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('RF_reg_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('RF_reg_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('RF_reg_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('RF_reg_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\ndata['beat-per-15 sec']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)","2f234748":"X","7ad97690":"features=['alphaLow','alphaHigh','betaLow','betaHigh','state']","868b8b45":"RF_model=complex_model_1\n# Extract single tree\n# estimator = RF_model.estimators_[5]\n\nfrom sklearn.tree import export_graphviz\n# Export as dot file\nexport_graphviz(complex_model_1,out_file='tree.dot', \n                feature_names = features,\n                class_names = features,\n                rounded = True, proportion = False, \n                precision = 2, filled = True)\n\n# Convert to png using system command (requires Graphviz)\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\n# Display in jupyter notebook\nfrom IPython.display import Image\nImage(filename = 'tree.png')","ef256146":"\n\n# df['bpm']=MLR_y_pred_entire_data\nX = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(X_train.head())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nclf =RandomForestClassifier()\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['RF_Classification',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('RF_Classification_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('RF_Classification_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('RF_Classification_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('RF_Classification_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('RF_Classification_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('RF_Classification_entire_actual.csv', y, delimiter=',', fmt='%s')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nfeatures = list(X.columns.values)\nimportances = clf.feature_importances_\nimport numpy as np\nindices = np.argsort(importances)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\nprint(importances)\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","94d40648":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","ab4fcc1a":"# test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\n# test.head()\n# print(\"actual result\")\n# print(test['state'])\n# lst=test['state']\n# test= test.loc[:, test.columns != 'state']\n# test = scaler.fit_transform(test)\n# test_result = complex_model_1.predict(test)\n# print(\"predicted result\")\n# print(test_result)","9d4f5406":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","f9eeac69":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\n# complex_model_1 = xgb.XGBRegressor(n_estimators=1000, learning_rate=0.02, gamma=0, subsample=0.75)\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\ncomplex_model_1 = xgb.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n                           colsample_bytree=1, max_depth=10)\n\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['XgBoost_reg','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('XgBoost_reg_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('XgBoost_reg_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('XgBoost_reg_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('XgBoost_reg_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('XgBoost_reg_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('XgBoost_reg_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\ndata['beat-per-15 sec']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)","8be10914":"\n# df['bpm']=MLR_y_pred_entire_data\nX = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(X_train.head())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nclf =xgb.XGBClassifier(random_state=700)\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['XgBoost_Classification',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('XgBoost_Classification_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('XgBoost_Classification_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('XgBoost_Classification_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('XgBoost_Classification_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('XgBoost_Classification_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('XgBoost_Classification_entire_actual.csv', y, delimiter=',', fmt='%s')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nfeatures = list(X.columns.values)\nimportances = clf.feature_importances_\nimport numpy as np\nindices = np.argsort(importances)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\nprint(importances)\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","e5e9bdc5":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","f49a2b06":"# test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\n# test.head()\n# print(\"actual result\")\n# print(test['state'])\n# lst=test['state']\n# test= test.loc[:, test.columns != 'state']\n# test = scaler.fit_transform(test)\n# test_result = complex_model_1.predict(test)\n# print(\"predicted result\")\n# print(test_result)","9e0929c1":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","cfc695c8":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom sklearn.ensemble import AdaBoostRegressor\ncomplex_model_1 = AdaBoostRegressor()\ncomplex_model_1= DecisionTreeRegressor(random_state=0)\n\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['AdaBoost_reg','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('AdaBoost_reg_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('AdaBoost_reg_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('AdaBoost_reg_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('AdaBoost_reg_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('AdaBoost_reg_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('AdaBoost_reg_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\ndata['beat-per-15 sec']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)","be320712":"\n# df['bpm']=MLR_y_pred_entire_data\nX = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(X_train.head())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\n#n_estimators=10000, \nclf = AdaBoostClassifier()\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['AdaBoost_Classification',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('AdaBoost_Classification_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('AdaBoost_Classification_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('AdaBoost_Classification_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('AdaBoost_Classification_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('AdaBoost_Classification_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('AdaBoost_Classification_entire_actual.csv', y, delimiter=',', fmt='%s')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nfeatures = list(X.columns.values)\nimportances = clf.feature_importances_\nimport numpy as np\nindices = np.argsort(importances)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\nprint(importances)\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","a052b58c":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","f339822e":"# test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\n# test.head()\n# print(\"actual result\")\n# print(test['state'])\n# lst=test['state']\n# test= test.loc[:, test.columns != 'state']\n# test = scaler.fit_transform(test)\n# test_result = complex_model_1.predict(test)\n# print(\"predicted result\")\n# print(test_result)","ef830477":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","da5edbcd":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\n!pip install CatBoost\nfrom catboost import CatBoostRegressor\n# iterations=700,learning_rate=0.02,depth=12,eval_metric='RMSE',random_seed = 23,bagging_temperature = 0.2,od_type='Iter',\n#                              metric_period = 75,\n#                              od_wait=100\n        \ncomplex_model_1 = CatBoostRegressor()\ncomplex_model_1= DecisionTreeRegressor(random_state=0)\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['CB_reg','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('CB_reg_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('CB_reg_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('CB_reg_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('CB_reg_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('CB_reg_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('CB_reg_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\ndata['beat-per-15 sec']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)","2c08f5c2":"# df['bpm']=MLR_y_pred_entire_data\nX = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(X_train.head())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\n!pip install catboost\nfrom catboost import CatBoostClassifier\n\nclf = CatBoostClassifier(\n    iterations=1000, \n    learning_rate=0.1, \n    #verbose=5,\n    #loss_function='CrossEntropy'\n)\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['CB_Classification',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('CB_Classification_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('CB_Classification_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('CB_Classification_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('CB_Classification_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('CB_Classification_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('CB_Classification_entire_actual.csv', y, delimiter=',', fmt='%s')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nfeatures = list(X.columns.values)\nimportances = clf.feature_importances_\nimport numpy as np\nindices = np.argsort(importances)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\nprint(importances)\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","d4a035c8":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","42374591":"# test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\n# test.head()\n# print(\"actual result\")\n# print(test['state'])\n# lst=test['state']\n# test= test.loc[:, test.columns != 'state']\n# test = scaler.fit_transform(test)\n# test_result = complex_model_1.predict(test)\n# print(\"predicted result\")\n# print(test_result)","b23ad9fc":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","e89310d2":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\nfrom sklearn.neural_network import MLPRegressor\n\ncomplex_model_1 = MLPRegressor(random_state=42, max_iter=500)\n\n\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['ANN_reg','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('ANN_reg_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('ANN_reg_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('ANN_reg_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('ANN_reg_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('ANN_reg_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('ANN_reg_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\ndata['beat-per-15 sec']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)","cf715763":"# df['bpm']=MLR_y_pred_entire_data\nX = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(X_train.head())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\n!pip install catboost\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.neural_network import MLPClassifier\nclf =MLPClassifier(solver='lbfgs', alpha=1e-5,\n                     hidden_layer_sizes=(16, 16), random_state=100)\n\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['ANN_Classification',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('ANN_Classification_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('ANN_Classification_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('ANN_Classification_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('ANN_Classification_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('ANN_Classification_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('ANN_Classification_entire_actual.csv', y, delimiter=',', fmt='%s')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\n# features = list(X.columns.values)\n# importances = clf.feature_importances_\n# import numpy as np\n# indices = np.argsort(importances)\n# plt.title('Feature Importances')\n# plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n# plt.yticks(range(len(indices)), [features[i] for i in indices])\n# plt.xlabel('Relative Importance')\n# plt.show()\n\nprint(importances)\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","7e420255":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","8ca68859":"# test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\n# test.head()\n# print(\"actual result\")\n# print(test['state'])\n# lst=test['state']\n# test= test.loc[:, test.columns != 'state']\n# test = scaler.fit_transform(test)\n# test_result = complex_model_1.predict(test)\n# print(\"predicted result\")\n# print(test_result)","d84626e7":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","4fc7991c":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.tree import DecisionTreeRegressor\ncomplex_model_1= DecisionTreeRegressor(random_state=0)\n\n\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['KNN_reg','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('KNN_reg_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('KNN_reg_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('KNN_reg_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('KNN_reg_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('KNN_reg_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('KNN_reg_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\ndata['beat-per-15 sec']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)","2e2b1637":"# df['bpm']=MLR_y_pred_entire_data\nX = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(X_train.head())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nclf =KNeighborsClassifier(n_neighbors=1)\n\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['KNN_Classification',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('KNN_Classification_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('KNN_Classification_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('KNN_Classification_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('KNN_Classification_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('KNN_Classification_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('KNN_Classification_entire_actual.csv', y, delimiter=',', fmt='%s')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\n# features = list(X.columns.values)\n# importances = clf.feature_importances_\n# import numpy as np\n# indices = np.argsort(importances)\n# plt.title('Feature Importances')\n# plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n# plt.yticks(range(len(indices)), [features[i] for i in indices])\n# plt.xlabel('Relative Importance')\n# plt.show()\n\nprint(importances)\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","1f84fd1d":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","f7d3ac6d":"# test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\n# test.head()\n# print(\"actual result\")\n# print(test['state'])\n# lst=test['state']\n# test= test.loc[:, test.columns != 'state']\n# test = scaler.fit_transform(test)\n# test_result = complex_model_1.predict(test)\n# print(\"predicted result\")\n# print(test_result)","3763af0c":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","9bcea660":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom sklearn.tree import DecisionTreeRegressor\ncomplex_model_1= DecisionTreeRegressor(random_state=0)\n\ncomplex_model_1.fit(X_train, y_train)\n\n\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['DT_reg','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('DT_reg_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('DT_reg_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('DT_reg_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('DT_reg_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('DT_reg_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('DT_reg_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\ndata['beat-per-15 sec']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)","b40a645f":"X = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(X_train.head())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb\nfrom sklearn import tree\nclf = tree.DecisionTreeClassifier()\n\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['DT_Classification',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('DT_Classification_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('DT_Classification_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('DT_Classification_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('DT_Classification_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('DT_Classification_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('DT_Classification_entire_actual.csv', y, delimiter=',', fmt='%s')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nfeatures = list(X.columns.values)\nimportances = clf.feature_importances_\nimport numpy as np\nindices = np.argsort(importances)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\nprint(importances)\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","2fd5d61e":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","65c50565":"# test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\n# test.head()\n# print(\"actual result\")\n# print(test['state'])\n# lst=test['state']\n# test= test.loc[:, test.columns != 'state']\n# test = scaler.fit_transform(test)\n# test_result = complex_model_1.predict(test)\n# print(\"predicted result\")\n# print(test_result)","5fc01bc7":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","ae03ed52":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom sklearn.tree import DecisionTreeRegressor\ncomplex_model_1= LinearRegression()\ncomplex_model_1.fit(X_train, y_train)\n\n\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['Linear_reg','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('Linear_reg_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('Linear_reg_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('Linear_reg_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('Linear_reg_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('Linear_reg_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('Linear_reg_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\ndata['bpm']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)\n","fc9db1be":"\n#equation for Linear Regression\nprint('Intercept: {}'.format(complex_model_1.intercept_))\nprint('Coefficients: {}'.format(complex_model_1.coef_))","39e7ea2c":"X = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(X_train.head())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb\nfrom sklearn import tree\nclf = GradientBoostingClassifier(random_state=1000, learning_rate=0.1,n_estimators=500)\n\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['GB_Classification',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('GB_Classification_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('GB_Classification_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('GB_Classification_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('GB_Classification_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('GB_Classification_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('GB_Classification_entire_actual.csv', y, delimiter=',', fmt='%s')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nfeatures = list(X.columns.values)\nimportances = clf.feature_importances_\nimport numpy as np\nindices = np.argsort(importances)\nplt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()\n\nprint(importances)\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","147f7882":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","5fc4b079":"# test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\n# test.head()\n# print(\"actual result\")\n# print(test['state'])\n# lst=test['state']\n# test= test.loc[:, test.columns != 'state']\n# test = scaler.fit_transform(test)\n# test_result = complex_model_1.predict(test)\n# print(\"predicted result\")\n# print(test_result)","89c38e01":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","4f28c7da":"data=pd.read_csv('..\/input\/bci-final\/bci_final.csv')\nprint(data.head())\nX = data.loc[:, data.columns != 'beat-per-15 sec']\ny=data['beat-per-15 sec']\nX.head()\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\ndef adjustedR2(r2,n,k):\n    return r2-(k-1)\/(n-k)*(1-r2)\n\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom sklearn.tree import DecisionTreeRegressor\ncomplex_model_1= LinearRegression()\ncomplex_model_1.fit(X_train, y_train)\n\n\ncomplex_model_1.fit(X_train, y_train)\n\npred = complex_model_1.predict(X_test)\nrmse_train = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_train), y_train)),'.3f'))\nr2_train = float(format(complex_model_1.score(X_train, y_train),'.3f'))\nar2_train = float(format(adjustedR2(complex_model_1.score(X_train, y_train),X_train.shape[0],len(features)),'.3f'))\nmae_train=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_train), y_train)),'.3f'))\n\nrmse_test = float(format(np.sqrt(metrics.mean_squared_error(complex_model_1.predict(X_test), y_test)),'.3f'))\nr2_test = float(format(complex_model_1.score(X_test, y_test),'.3f'))\nar2_test = float(format(adjustedR2(complex_model_1.score(X_test, y_test),X_test.shape[0],len(features)),'.3f'))\nmae_test=float(format((metrics.mean_absolute_error(complex_model_1.predict(X_test), y_test)),'.3f'))\n\ncv = float(format(cross_val_score(complex_model_1,X_train, y_train,cv=10).mean(),'.3f'))\nr = reg_evaluation.shape[0]\nreg_evaluation.loc[r] = ['Linear_reg','All features',rmse_train,r2_train,ar2_train,mae_train,rmse_test,r2_test,ar2_test,mae_test,cv]\n\n\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('Linear_reg_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('Linear_reg_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('Linear_reg_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('Linear_reg_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('Linear_reg_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('Linear_reg_entire_actual.csv', y, delimiter=',', fmt='%s')\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\nprint(MLR_y_pred_entire_data)\ndata['beat-per-15 sec']=MLR_y_pred_entire_data\nprint(data)\nreg_evaluation.sort_values(by = '10-Fold Cross Validation', ascending=False)\n","0472cba2":"X = data.loc[:, data.columns != 'state']\ny=data['state']\nX.head()\n\nfrom sklearn.naive_bayes import GaussianNB\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nprint(X_train.head())\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb\nfrom sklearn import tree\nclf =GaussianNB()\n\nclf.fit(X_train, y_train)\n\nacc_train=format(accuracy_score(clf.predict(X_train), y_train),'.3f')\nprecision_train=format(precision_score(y_train, clf.predict(X_train), average='macro'),'.3f')\nrecall_train=format(recall_score(y_train,clf.predict(X_train), average='macro'),'.3f')\nf1_train=format(f1_score(y_train,clf.predict(X_train), average='macro'),'.3f')\n\n\nacc_test=format(accuracy_score(clf.predict(X_test), y_test),'.3f')\nprecision_test=format(precision_score(y_test, clf.predict(X_test), average='macro'),'.3f')\nrecall_test=format(recall_score(y_test,clf.predict(X_test), average='macro'),'.3f')\nf1_test=format(f1_score(y_test,clf.predict(X_test), average='macro'),'.3f')\n\nr = classification_evaluation.shape[0]\nclassification_evaluation.loc[r] = ['NB_Classification',acc_train,precision_train,recall_train,f1_train,acc_test,precision_test,recall_test,f1_test]\n\n\ncomplex_model_1=clf\n# Print the predicted and actual value for the test set\nMLR_y_test_prediction= complex_model_1.predict(X_test)\nnp.savetxt('NB_Classification_test_prediction.csv', MLR_y_test_prediction, delimiter=',', fmt='%s')\nnp.savetxt('NB_Classification_test_actual.csv', y_test, delimiter=',', fmt='%s')\n\n# Print the predicted and actual value for the traing set\nMLR_y_train_prediction= complex_model_1.predict(X_train)\nnp.savetxt('NB_Classification_train_prediction.csv', MLR_y_train_prediction, delimiter=',', fmt='%s')\nnp.savetxt('NB_Classification_train_actual.csv', y_train, delimiter=',', fmt='%s')\n\nX_standardized = scaler.transform(X)\nMLR_y_pred_entire_data = complex_model_1.predict(X_standardized)\nnp.savetxt('NB_Classification_entire_prediction.csv', MLR_y_pred_entire_data, delimiter=',', fmt='%s')\nnp.savetxt('NB_Classification_entire_actual.csv', y, delimiter=',', fmt='%s')\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(y, MLR_y_pred_entire_data,  'ro')\nplt.ylabel('Predicted data')\nplt.xlabel('Actual data')\nplt.show()\n\n# features = list(X.columns.values)\n# importances = clf.feature_importances_\n# import numpy as np\n# indices = np.argsort(importances)\n# plt.title('Feature Importances')\n# plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n# plt.yticks(range(len(indices)), [features[i] for i in indices])\n# plt.xlabel('Relative Importance')\n# plt.show()\n\nprint(importances)\nclassification_evaluation.sort_values(by = 'Accuracy(test)', ascending=False)","7caf0ba2":"import seaborn as sns\nquantitative_features_list1 = data.columns.values\n#quantitative_features_list1 = ['a\/d', 'p', 'sqrt(fc)', 'lf\/df', 'Vf', 'F', 'Type', 'Vu']\ndata_plot_data=data_mod_num = data[quantitative_features_list1]\nsns.pairplot(data_plot_data)","cc60d6e1":"# test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\n# test.head()\n# print(\"actual result\")\n# print(test['state'])\n# lst=test['state']\n# test= test.loc[:, test.columns != 'state']\n# test = scaler.fit_transform(test)\n# test_result = complex_model_1.predict(test)\n# print(\"predicted result\")\n# print(test_result)","8a90609c":"test=pd.read_csv('..\/input\/experimental-design\/experimental_design.csv')\nct=test\n# print(test.head())\n# print(\"actual result\")\n# print(test['state'])\nlst=test['state']\ntest= test.loc[:, test.columns != 'state']\ntest = scaler.fit_transform(test)\ntest_result = complex_model_1.predict(test)\n#print(\"predicted result\")\n#print(test_result)\n\n        \n\n\nct['actual']=ct['state']\nct['predicted']=test_result\nct['beat-per-15 sec']=ct['beat-per-15 sec']\/10\nct=ct.drop(columns=['alphaLow','alphaHigh','betaLow','betaHigh','state'])\nct.head()\nct.plot(kind='bar',figsize=(25, 10),alpha=1,fontsize=18,stacked=False)\n\nactual=0\npredicted=0\ntotal=len(ct['actual'])\nfor i in range(len(ct['actual'])):\n    if (ct['actual'][i]==1):\n        actual=actual+1\n    if (ct['predicted'][i]==1):\n        predicted=predicted+1\nprint(\"Percentage of ENGAGED in actual data: {}\".format((actual\/total)*100))\nprint(\"Percentage of ENGAGED in predicted data: {}\".format((predicted\/total)*100))\nprint()\nprint(\"Percentage of UNCONCERNED in actual data: {}\".format(((total-actual)\/total)*100))\nprint(\"Percentage of UNCONCERNED in predicted data: {}\".format(((total-predicted)\/total)*100))","4651b23e":"Building 1st Model","0d5e3dd6":"# ANN","109982bc":"Building 2nd Model","610d2635":"Build 1st model","6ca5e08f":"Building 1st model","060988e4":"# RF","dd0323a4":"Build 2nd model","5f51da21":"Building 2nd model","ab7f33d5":"Buidling 2nd Model","ca81fdb4":"Building 1st model","1ba49d14":"# AdaBoost","7bef7ac0":"Building 1st model","d9359eb7":"Building 2nd model","7dda4029":"Building 1st Model","dd0ba6eb":"Building 2nd model","6b49725f":"# KNN","6e0d2773":"Building first model","562c177f":"# Decision Tree","6732d4fe":"# ****SVM****","4edb4610":"# 1st model: Linear Regression, 2nd model : Gradient Boosting ","f96e0d07":"Building 1st Model","2e15afbb":"Building 2nd Model","ba9ba72b":"# 1st model: Linear Regression, 2nd model : Naive Bayes ","ad1fbc7b":"# CatBoost","58c690dc":"Building 1st model","479e255c":"Building 2nd model","94547f30":"Building 1st Model","ef1594ae":"# XgBoost","77bf3790":"Building 2nd Model","bdc93602":"Buidling second model"}}