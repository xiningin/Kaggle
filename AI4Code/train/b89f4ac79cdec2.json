{"cell_type":{"54a42de7":"code","6d62db25":"code","ca5c1bfc":"code","fdf8e804":"code","b933c53f":"code","43c44b9f":"code","1df2a1bb":"code","f7346f53":"code","1ae1beeb":"code","6fc501f4":"code","06fff83c":"code","a658bd7a":"code","7d918196":"code","6f687bbb":"code","942f624f":"code","2a511893":"code","a228ef64":"code","c16a5e40":"code","c524f361":"code","72b63366":"code","c80c62a3":"code","06c71e90":"code","8d10195a":"code","588c9c69":"code","dd80d0f7":"code","888982f6":"code","ee1139bd":"code","48550e9f":"code","73b6a34a":"code","c66829e2":"code","e75bc11a":"code","78c6aa65":"code","73321539":"code","460bd619":"code","ae725bb6":"code","c17e751e":"code","fc8aa1f4":"markdown","8a62f0c8":"markdown","587aba43":"markdown","9e9999f9":"markdown","51a04d2a":"markdown"},"source":{"54a42de7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6d62db25":"train_data = pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","ca5c1bfc":"train_data.head()","fdf8e804":"train_data.columns","b933c53f":"train_data.shape","43c44b9f":"train_data.info()","1df2a1bb":"#converting date string to datetime\n\ntrain_data['Date'] = pd.to_datetime(train_data['Date'])","f7346f53":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","1ae1beeb":"#Analysing null values in the entire data\n\nplt.figure(figsize=(15,6))\nsns.heatmap(train_data.isnull())","6fc501f4":"#percentage of null values in each column\n\n(train_data.isnull().sum()\/len(train_data))*100","06fff83c":"#separating numeric and non numeric columns\n\ncontin = []\ncategory = []\n\nfor col in train_data.columns:\n    if train_data[col].dtype == 'object':\n        category.append(col)\n    \n    else:\n        contin.append(col)","a658bd7a":"#imputing numeric columns with the mean of every column \n\nfor item in contin:\n    if train_data[item].isnull().any:\n        train_data[item] = train_data[item].fillna(train_data[item].mean())\n    else:\n        pass","7d918196":"train_data['RainToday'].value_counts()","6f687bbb":"#Encoding columns with yes and no to 0 and 1\n\ntrain_data['RainToday'] = train_data['RainToday'].map({'Yes': 1,'No': 0})","942f624f":"train_data['RainToday'].unique()","2a511893":"train_data['RainTomorrow'] = train_data['RainTomorrow'].map({'Yes': 1,'No': 0})","a228ef64":"#imputing categorical columns with the mode of every column \n\nfor col in category:\n    \n    train_data[col] = train_data[col].fillna(train_data[col].mode()[0])","c16a5e40":"train_data['RainTomorrow'].fillna(0,inplace=True)","c524f361":"train_data.isnull().sum()","72b63366":"#let's label encode the object columns\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()","c80c62a3":"for col in category:\n    train_data[col] = le.fit_transform(train_data[col])","06c71e90":"train_data.head()","8d10195a":"plt.figure(figsize=(13,7))\n\nsns.heatmap(train_data.corr(),annot=True)","588c9c69":"plt.figure(figsize=(11,7))\nsns.jointplot(x='MinTemp',y='Temp9am',kind='scatter',data=train_data,palette='viridis',hue='RainToday')","dd80d0f7":"sns.kdeplot(x='MaxTemp',y='Temp3pm',data=train_data,fill=True,weights=1,hue='RainToday')","888982f6":"#dropping the highly correlated and unnecessary columns\n\ntrain_data.drop(['Temp3pm','Temp9am','Date','Location'],axis=1,inplace=True)","ee1139bd":"X = train_data.drop('RainTomorrow',axis=1)\ny = train_data['RainTomorrow']","48550e9f":"from sklearn.model_selection import train_test_split","73b6a34a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","c66829e2":"from sklearn.ensemble import RandomForestClassifier","e75bc11a":"rfc = RandomForestClassifier(n_estimators=400)","78c6aa65":"rfc.fit(X_train,y_train)","73321539":"pred = rfc.predict(X_test)","460bd619":"from sklearn.metrics import classification_report,confusion_matrix","ae725bb6":"print(confusion_matrix(y_test,pred))","c17e751e":"print(classification_report(y_test,pred))","fc8aa1f4":"# Lets visualize some trends in the dataset","8a62f0c8":"train_data['RainToday'].fillna(0,inplace=True)","587aba43":"# Model building","9e9999f9":"# Importing and understanding data","51a04d2a":"# Data cleaning"}}