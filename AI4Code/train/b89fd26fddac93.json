{"cell_type":{"4d3e25fc":"code","d8488bcf":"code","7a300ba1":"code","52ffb6a2":"code","c9cb0ff9":"code","74d7b21c":"code","0c735248":"code","68e8b3ee":"code","b1568865":"code","fdf731ea":"markdown","80d9599b":"markdown"},"source":{"4d3e25fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d8488bcf":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\nfrom collections import Counter","7a300ba1":"path_of_file = '..\/input\/200000-abstracts-for-seq-sentence-classification\/200k_abstracts\/dev.txt'\ntext = open(path_of_file, 'r').read()","52ffb6a2":"text[:2000]","c9cb0ff9":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef read_docu(file):\n    \n    all_words = []\n    \n    with open(file, \"r\", encoding = \"utf-8\") as input_file:\n        for line in input_file:\n            line = line.lower()\n            line = line.strip().split()\n            all_words += line\n        return(all_words)","74d7b21c":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef word_counter(all_words):\n    \n    word_count = Counter()\n    for word in all_words:\n        word_count[word] += 1\n    return(word_count.values())","0c735248":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef draw_zipfian_curve(word_count):\n    plt.plot(sorted(word_count, reverse = True), marker = \"o\")\n    plt.xscale(\"log\")\n    plt.yscale(\"log\")\n    plt.xlabel(\"log(Rank)\")\n    plt.ylabel(\"log(Frequency)\")\n    plt.show()","68e8b3ee":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef zipfian_plot(file):\n    word_corpus = read_docu(file)\n    counts = word_counter(word_corpus)\n    draw_zipfian_curve(counts)","b1568865":"zipfian_plot(\"..\/input\/200000-abstracts-for-seq-sentence-classification\/200k_abstracts\/dev.txt\")","fdf731ea":"https:\/\/www.kaggle.com\/anshulmehtakaggl\/abstract-segmentation-nlp","80d9599b":"#Since I got RegistryError  in Spacy : Unknown function registry: 'scorers'.\n\nAvailable names: architectures, augmenters, batchers, callbacks, cli, datasets, displacy_colors, factories, initializers, languages, layers, lemmatizers, loggers, lookups, losses, misc, models, ops, optimizers, readers, schedules, tokenizers\n\nI went to Zipfian snippets above."}}