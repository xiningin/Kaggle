{"cell_type":{"22fb93b4":"code","ff44d411":"code","07c7abd7":"code","221db997":"code","4a70762f":"code","ff62f5f0":"code","83f42f1c":"code","b569758d":"code","0da0b5eb":"code","4d28dc0b":"code","5f667f98":"code","3dc18305":"code","0561db99":"code","fcd4ec4f":"code","ef37ec1b":"code","3464ee58":"code","3f0619ec":"code","66ae52c8":"code","66d35071":"code","7d4d5230":"code","6713b11c":"code","e3b534b9":"code","bad0f2c8":"code","397a1369":"code","4e469e1f":"code","b41b8f92":"code","32838842":"code","57570373":"code","45c12781":"code","34efba0b":"code","29da6b33":"code","44551217":"code","45b0d779":"code","0f5d75e9":"code","abf8cadf":"code","c0cda485":"code","4916f673":"code","15949abd":"code","40877c07":"code","cb114f5f":"code","aca03cde":"code","ac8da3c7":"code","bc88e5bd":"markdown","82f778b9":"markdown","30792f09":"markdown","fd72a54d":"markdown","ae3e8ed9":"markdown","45c978b9":"markdown","91c697b9":"markdown"},"source":{"22fb93b4":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom numpy import loadtxt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport keras\nimport pandas as pd\nimport numpy as np\nimport riiideducation\nimport matplotlib.pyplot as plt\nfrom keras.callbacks import EarlyStopping","ff44d411":"#%%time\ntrain = pd.read_feather('..\/input\/riiid-feather-dataset\/train.feather')\nquestions = pd.read_feather('..\/input\/riiid-feather-dataset\/questions.feather')\nlectures = pd.read_feather('..\/input\/riiid-feather-dataset\/lectures.feather')\nexample_test = pd.read_feather('..\/input\/riiid-feather-dataset\/example_test.feather')\nexample_sample_submission = pd.read_feather('..\/input\/riiid-feather-dataset\/example_sample_submission.feather')","07c7abd7":"\ntrain = train.sample(frac=0.001)\ntrain.shape","221db997":"questions.columns","4a70762f":"questions.tags.value_counts()","ff62f5f0":"questions.part.value_counts()","83f42f1c":"train.columns","b569758d":"#df = train[\"user_id\",\"content_id\",\"answered_correctly\"]\n\n# ERFAN: Try to use\/make different features user_id and content_id are probably not super informative to models.\n#df = train[['user_id','content_id','answered_correctly']]\n","0da0b5eb":"def prepare_features(col_name):\n    df = train[train.content_type_id==0][[col_name,'answered_correctly']].groupby(col_name).agg(['count','sum'])\n    if col_name == 'content_id':\n        col_name = 'question'\n        #TODO: Add question_entropy\n        # try decomposition methods?\n        \n    elif col_name == 'user_id':\n        col_name = 'student'\n        # TODO: user choice entropy\n        \n    df.columns=[col_name + '_total', col_name + '_correct']\n    df = df.astype('uint64')\n    df[col_name +'_incorrect'] = df[col_name + '_total'] - df[ col_name + '_correct']\n    df[col_name +'_correct_ratio'] = df[ col_name + '_correct']\/df[col_name + '_total']\n    return df\n    ","4d28dc0b":"questions_dataframe = prepare_features('content_id')\nquestions_dataframe['content_id'] = list(questions_dataframe.index)\nquestions_dataframe = questions_dataframe.rename_axis(\"question_index\")\nquestions_dataframe","5f667f98":"users_dataframe = prepare_features('user_id')\nusers_dataframe['user_id'] = list(users_dataframe.index)\nusers_dataframe = users_dataframe.rename_axis(\"user_index\")\nusers_dataframe","3dc18305":"df = pd.merge(train,users_dataframe,how = 'inner',on = 'user_id')\ndf = pd.merge(df,questions_dataframe,how = 'inner',on = 'content_id')\ndf.head()","0561db99":"df = df[df['answered_correctly'] != -1]","fcd4ec4f":"df.shape\n","ef37ec1b":"df['prior_question_elapsed_time'].fillna(-1,inplace = True)\ndf['prior_question_had_explanation'].fillna(-1,inplace = True)","3464ee58":"df['prior_question_had_explanation'] *= 1 # convert from boolean to numbers","3f0619ec":"#use this in presentation\n\ncols = list(df.columns.values) #Make a list of all of the columns in the df\ncols.pop(cols.index('answered_correctly')) #Remove b from list\ndf = df[cols+['answered_correctly']] #Create new dataframe with columns in the order you want\nf = plt.figure(figsize=(19, 15))\nplt.matshow(df.corr(), fignum=f.number)\nplt.xticks(range(df.shape[1]), df.columns, fontsize=14, rotation=45)\nplt.yticks(range(df.shape[1]), df.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\n# TODO FIX GRAPH ","66ae52c8":"df.corr()['answered_correctly']","66d35071":"df['prior_question_elapsed_time'].value_counts()","7d4d5230":"df['prior_question_had_explanation'].value_counts()","6713b11c":"df['answered_correctly'].value_counts()","e3b534b9":"from sklearn.decomposition import PCA\npca = PCA(n_components=5, svd_solver='full')\npca.fit(df[[i for i in df.columns if i!= 'answered_correctly']])\nprint(pca.explained_variance_ratio_)\npca_featurelist = pca.transform(df[[i for i in df.columns if i!= 'answered_correctly']])\npca_featurelist","bad0f2c8":"pca_featurelist.shape","397a1369":"import scipy.stats\nscipy.stats.spearmanr(pca_featurelist[:,0], df['answered_correctly'])\n","4e469e1f":"feature_list = ['content_id','prior_question_elapsed_time','prior_question_had_explanation', 'question_correct_ratio','student_correct_ratio']\nX = df[feature_list].to_numpy()\n\ny = df['answered_correctly'].to_numpy()","b41b8f92":"X = X.astype(float)\n","32838842":"y = y.astype(float)","57570373":"y.dtype","45c12781":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n","34efba0b":"X_train.shape","29da6b33":"# ERFAN: This structure needs revision - I dont think it's super good for this task.\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=len(feature_list), activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","44551217":"optimizer = keras.optimizers.Adam(lr=0.001)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=9)# ERFAN: stops when it reaches a plateau in validation loss\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[tf.keras.metrics.AUC(),'accuracy']) #ERFAN: added auc since that's what we are optimizing for - loss seems static.","45b0d779":"model.fit(X_train, y_train, epochs=30, batch_size=50,validation_data=(X_test, y_test),verbose=1, callbacks=[es]) #Erfan: AUC seems static, loss decreases when batch_size < 100. Why do we want a bigger batchsize?","0f5d75e9":"predictions = model.predict_classes(X_test)","abf8cadf":"predictions","c0cda485":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nclf = RandomForestClassifier(max_depth=35, random_state=0)\n\nclf.fit(X_train,y_train)\nrf_predictions = clf.predict(X_test)","4916f673":"fpr, tpr, thresholds = metrics.roc_curve(y_test, rf_predictions, pos_label=1)\nmetrics.auc(fpr,tpr)","15949abd":"def prepare_train_features(df,col_name):\n    df = df[df.content_type_id==0][[col_name,'answered_correctly']].groupby(col_name).agg(['count','sum'])\n    if col_name == 'content_id':\n        col_name = 'question'\n        #TODO: Add question_entropy\n        # try decomposition methods?\n        \n    elif col_name == 'user_id':\n        col_name = 'student'\n        # TODO: user choice entropy\n        \n    df.columns=[col_name + '_total', col_name + '_correct']\n    df = df.astype('ufloat64')\n    df[col_name +'_incorrect'] = df[col_name + '_total'] - df[ col_name + '_correct']\n    df[col_name +'_correct_ratio'] = df[ col_name + '_correct']\/df[col_name + '_total']\n    return df","40877c07":"def prepare_train_df(df):\n    questions_dataframe = prepare_train_features(df,'content_id')\n    questions_dataframe['content_id'] = list(questions_dataframe.index)\n    questions_dataframe = questions_dataframe.rename_axis(\"question_index\")\n    users_dataframe = prepare_train_features(df,'user_id')\n    users_dataframe['user_id'] = list(users_dataframe.index)\n    users_dataframe = users_dataframe.rename_axis(\"user_index\")\n    df = pd.merge(df,users_dataframe,how = 'inner',on = 'user_id')\n    df = pd.merge(df,questions_dataframe,how = 'inner',on = 'content_id')\n    df = df[df['answered_correctly'] != -1]\n    df['prior_question_elapsed_time'].fillna(-1,inplace = True)\n    df['prior_question_had_explanation'].fillna(-1,inplace = True)\n    df['prior_question_had_explanation'] *= 1 # convert from boolean to numbers\n    return df\n    \n    \n    ","cb114f5f":"def prepare_test_features(df,test_df,feature_list):\n    #['content_id','prior_question_elapsed_time','prior_question_had_explanation', 'question_correct_ratio','student_correct_ratio']\n    \n        \n    test_df = pd.merge(test_df,questions_dataframe[['content_id', 'question_correct_ratio']],how='left',on='content_id')\n    test_df = pd.merge(test_df,users_dataframe[['user_id','student_correct_ratio']],how='left',on='user_id')\n    test_df['prior_question_elapsed_time'].fillna(-1,inplace = True)\n    test_df['prior_question_had_explanation'] *= 1 # convert from boolean to numbers\n    test_df['prior_question_had_explanation'].fillna(-1,inplace = True)\n    test_df.fillna(-1,inplace = True)\n    return test_df[feature_list].to_numpy().astype(float)","aca03cde":"env = riiideducation.make_env()\niter_test = env.iter_test()","ac8da3c7":"for (test_df, sample_prediction_df) in iter_test:\n#     test_questions = test_df['content_id'].to_numpy()\n#     test_users = test_df['user_id'].to_numpy()\n    test_set = prepare_test_features(df,test_df,feature_list)\n    answered_correctly = model.predict(test_set)\n    answered_correctly = clf.predict(test_set)\n    test_df['answered_correctly'] = answered_correctly\n    env.predict(test_df.loc[test_df['content_type_id']==0,['row_id','answered_correctly']])","bc88e5bd":"For each batch in <code>test_df<\/code>, we will predict the probability of answering correctly (<code>nb.predict<\/code>) and then we will send the resulting data back to the environment. This last part is done in <code>env.predict<\/code>. Notice that we must not create any <code>submission.csv<\/code> file, this is done automatically by <code>env.predict<\/code>.","82f778b9":"## Read the data\n<p>I read the data in feather format from this notebook https:\/\/www.kaggle.com\/aralai\/riiid-feather-dataset. It's much faster! \nIf you don't want to use feather, you can just replace the following lines with the csv format reading.","30792f09":"The initial purpose of this notebook was to make a very simple baseline for my own usage to better understand the data and the submission process. As I got a fairly decent score (given the simplicity of the model) I decided to share the notebook in case it can be helpful to someone else. This model could be improved by adding more features.","fd72a54d":"# Riiid classification using NN & Random Forest","ae3e8ed9":"# Replace Null values","45c978b9":"# Random Forest","91c697b9":"## Submission<p>\n<code>example_test<\/code> contains just a few dummy rows that can be used for development. The real submission must be made by using <code>riiideducation<\/code> package. To do that, we must create an environment and then loop through all the batches provided by <code>iter_test<\/code>."}}