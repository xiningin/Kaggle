{"cell_type":{"4439f16e":"code","8052fc62":"code","4466369e":"code","221f16a3":"code","f604b0ea":"code","18e9f006":"code","c04b7d91":"code","b2d61d3e":"code","1c74c929":"code","2844b160":"code","1aba233b":"code","2912a603":"code","c448b77a":"code","f3bac47c":"code","91b2b557":"code","057aa0c8":"code","0e054b8a":"code","7b50a04b":"code","7c290892":"code","16348695":"code","208d4a0a":"code","be29abad":"code","45278a02":"code","2851ffc1":"code","a63730e6":"code","18425d92":"code","88b94f99":"code","5e527883":"code","6fe1489e":"code","fcc89840":"code","897bc34a":"code","70ca2a8a":"code","79bc92bb":"markdown","d4849e54":"markdown","7fc92e33":"markdown","b3b4a1c6":"markdown","195766da":"markdown","08835b08":"markdown","cfa2a5a3":"markdown"},"source":{"4439f16e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nfrom sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n                             roc_curve, recall_score, classification_report, f1_score,\n                             precision_recall_fscore_support, roc_auc_score)\n\n\n\nsns.set_style('dark')\nsns.set_context('talk')# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option('display.max_colwidth', -1)\n        # Any results you write to the current directory are saved as output.","8052fc62":"df = pd.read_csv('\/kaggle\/input\/spam.csv', encoding = 'latin1')\ndf.info()","4466369e":"df.head()","221f16a3":"# last 3 cols have most values Nans. Dropping them\ndf.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace = True)","f604b0ea":"# Renaming columns\ndf.columns = ['label', 'text']","18e9f006":"pd.set_option('display.width', 1000)","c04b7d91":"df.head()","b2d61d3e":"df['length'] = df['text'].apply(lambda row: len(row))","1c74c929":"sns.distplot(df['length'])\nplt.show()","2844b160":"sns.countplot(df['label'])","1aba233b":"# Encoding label to 0,1\ndf['label'] = df['label'].map({'spam' : 1, 'ham' :0})","2912a603":"df.head()","c448b77a":"df[df.label == 1].text","f3bac47c":"df.label.value_counts()","91b2b557":"words = ['free', 'winner', 'prize', 'won', 'win']\ndef count_words(row):\n    count = 0\n    for word in words:\n        if word in row.lower():\n            count +=1\n    return count","057aa0c8":"df['bad_words'] = df['text'].apply(count_words )","0e054b8a":"df.head()","7b50a04b":"df.groupby(['bad_words', 'label']).count()","7c290892":"sns.heatmap(df.corr(), annot = True)\nplt.show()","16348695":"X = df.drop(['label'], axis=1)\ny = df['label']","208d4a0a":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","be29abad":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=12)","45278a02":"print(X_train.shape, len(y_train))\nprint(X_test.shape, len(y_test))","2851ffc1":"vectorizer = TfidfVectorizer(lowercase=True, min_df=20, use_idf=True, )","a63730e6":"train_tfidf = vectorizer.fit_transform(X_train.text)\ntest_tfidf = vectorizer.transform(X_test.text)","18425d92":"print(train_tfidf.shape)\nprint(test_tfidf.shape)","88b94f99":"clf = RandomForestClassifier(n_estimators=10, n_jobs=-1, class_weight='balanced')","5e527883":"clf.fit(train_tfidf, y_train)","6fe1489e":"y_pred = clf.predict_proba(test_tfidf)[:,1]\ny_pred_binary = clf.predict(test_tfidf)","fcc89840":"fpr, tpr, thres = roc_curve(y_test, y_pred)\nplt.plot(fpr, tpr, label = 'AUC') \nplt.plot([0,1], [0,1], ':', label = 'Random') \nplt.legend() \nplt.grid() \nplt.ylabel(\"TPR\") \nplt.xlabel(\"FPR\") \nplt.title('ROC') \nplt.show()","897bc34a":"LABELS = ['Ham', 'Spam']\nconf_matrix = confusion_matrix(y_test, y_pred_binary)\ncm = conf_matrix.astype('float') \/ conf_matrix.sum(axis=1)[:, np.newaxis]\nsns.heatmap(cm, xticklabels=LABELS, yticklabels=LABELS, annot=True, cmap='Greens');\nplt.title(\"Confusion matrix\")\nplt.ylabel('True class')\nplt.xlabel('Predicted class')\nplt.show()","70ca2a8a":"print(\"F1-Score : {:.2f}\".format(f1_score(y_test, y_pred_binary)))\nprint(\"AUC-ROC  : {:.2f}\".format(roc_auc_score(y_test, y_pred_binary)))","79bc92bb":"## Metrics: ","d4849e54":"## Feature Modeling:\nTesting if the length as any relation with label","7fc92e33":"## Data Modeling:","b3b4a1c6":"## Training Model:","195766da":"So some words like Free, Winner, Prize etc are definitely in the spam messages, so if we test for these words first. ","08835b08":"## Reading Data:","cfa2a5a3":"This means words like them those have some relation with being spam or not. This means using frequency based word encoding will work here. "}}