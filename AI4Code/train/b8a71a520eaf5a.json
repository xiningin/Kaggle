{"cell_type":{"b076e4ab":"code","ffdeb2bf":"code","1071d3d1":"code","0eb96617":"code","94629e41":"code","da03bd7b":"code","d5c9eca7":"code","00f1ba11":"code","a666e381":"code","1073a27b":"code","3514643c":"code","f450d598":"code","962b34d2":"code","41c5a6d4":"code","d483c9aa":"code","10b62bd0":"code","68d3afd5":"code","c647e449":"code","f5b618b7":"markdown","14ed8abc":"markdown","59799252":"markdown","de311b7b":"markdown","f1d3090d":"markdown","321db409":"markdown"},"source":{"b076e4ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ffdeb2bf":"!ls \/kaggle\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba","1071d3d1":"from os import listdir\nfrom numpy import asarray\nfrom PIL import Image\nfrom matplotlib import pyplot\n\n# load an image as an rgb numpy array\ndef load_image(filename):\n    image= Image.open(filename)\n    image = image.convert('RGB')\n    pixels = asarray(image)\n    return pixels\n\n# load images and extract faces for all images in a directory\ndef load_faces(directory, n_faces):\n    faces = list()\n    # enumerate files\n    for filename in listdir(directory):\n        # load the image\n        pixels = load_image(directory + filename)\n        # store\n        faces.append(pixels)\n        # stop once we have enough\n        if len(faces) >= n_faces:\n            break\n    return asarray(faces)\n \n# plot a list of loaded faces\ndef plot_faces(faces, n):\n    for i in range(n * n):\n        # define subplot\n        pyplot.subplot(n, n, 1 + i)\n        # turn off axis\n        pyplot.axis('off')\n        # plot raw pixel data\n        pyplot.imshow(faces[i])\n    pyplot.show()\n \n# directory that contains all images\ndirectory = '\/kaggle\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\/'\n# load and extract all faces\nfaces = load_faces(directory, 25)\nprint('Loaded: ', faces.shape)\n# plot faces\nplot_faces(faces, 5)\n\n\n","0eb96617":" !pip install mtcnn","94629e41":"from os import listdir\nfrom numpy import asarray\nfrom numpy import savez_compressed\nfrom PIL import Image\nfrom mtcnn.mtcnn import MTCNN\nfrom matplotlib import pyplot\n\n# load an image as an rgb numpy array\ndef load_image(filename):\n\t# load image from file\n\timage = Image.open(filename)\n\t# convert to RGB, if needed\n\timage = image.convert('RGB')\n\t# convert to array\n\tpixels = asarray(image)\n\treturn pixels\n\n# extract the face from a loaded image and resize\ndef extract_face(model, pixels, required_size=(80, 80)):\n\t# detect face in the image\n\tfaces = model.detect_faces(pixels)\n\t# skip cases where we could not detect a face\n\tif len(faces) == 0:\n\t\treturn None\n\t# extract details of the face\n\tx1, y1, width, height = faces[0]['box']\n\t# force detected pixel values to be positive (bug fix)\n\tx1, y1 = abs(x1), abs(y1)\n\t# convert into coordinates\n\tx2, y2 = x1 + width, y1 + height\n\t# retrieve face pixels\n\tface_pixels = pixels[y1:y2, x1:x2]\n\t# resize pixels to the model size\n\timage = Image.fromarray(face_pixels)\n\timage = image.resize(required_size)\n\tface_array = asarray(image)\n\treturn face_array\n\n# load images and extract faces for all images in a directory\ndef load_faces(directory, n_faces):\n\t# prepare model\n\tmodel = MTCNN()\n\tfaces = list()\n\t# enumerate files\n\tfor filename in listdir(directory):\n\t\t# load the image\n\t\tpixels = load_image(directory + filename)\n\t\t# get face\n\t\tface = extract_face(model, pixels)\n\t\tif face is None:\n\t\t\tcontinue\n\t\t# store\n\t\tfaces.append(face)\n\t\tprint(len(faces), face.shape)\n\t\t# stop once we have enough\n\t\tif len(faces) >= n_faces:\n\t\t\tbreak\n\treturn asarray(faces)\n\n\ndirectory = '\/kaggle\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\/'\n\n# load and extract all faces\nall_faces = load_faces(directory, 50000)\nprint('Loaded: ', all_faces.shape)\n# save in compressed format\nsavez_compressed('img_align_celeba.npz', all_faces)","da03bd7b":"from numpy import load\n# load the face dataset\ndata = load('img_align_celeba.npz')\nfaces = data['arr_0']\nprint('Loaded: ', faces.shape)","d5c9eca7":"from numpy import load\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Reshape\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Conv2DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Dropout\nfrom matplotlib import pyplot","00f1ba11":"def define_discriminator(in_shape=(80,80,3)):\n    model = Sequential()\n    # normal\n    model.add(Conv2D(128, (5,5), padding='same', input_shape=in_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 40x40\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 20x30\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 10x10\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # downsample to 5x5\n    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    # classifier\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation='sigmoid'))\n    # compile model\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    \n    return model","a666e381":"def define_generator(latent_dim):\n    \n    model=Sequential()\n    n_nodes= 128*5*5\n    \n    model.add(Dense(n_nodes,input_dim=latent_dim))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Reshape((5,5,128)))\n    #upsample to 10,10\n    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    #upsample to 20,20\n    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    #upsample to 40,40\n    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    #upsample to 80,80\n    model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Conv2D(3,(5,5),activation='tanh',padding='same'))\n    \n    return model\n    \n    ","1073a27b":"def define_gan(g_model,d_model):\n    d_model.trainable=False\n    model =Sequential()\n    model.add(g_model)\n    model.add(d_model)\n    \n    opt = Adam(lr=0.0002,beta_1=0.5)\n    model.compile(loss='binary_crossentropy',optimizer=opt)\n    return model","3514643c":"def load_real_samples():\n    data = load('img_align_celeba.npz')\n    X = data['arr_0']\n    # convert from unsigned ints to floats\n    X = X.astype('float32')\n    # scale from [0,255] to [-1,1]\n    X = (X - 127.5) \/ 127.5\n    return X\n    ","f450d598":"def generate_real_samples(dataset,n_samples):\n    #select random no from 0 to _  size n_samples\n    ix = randint(0,dataset.shape[0],n_samples)\n    X = dataset[ix]\n    y=ones((n_samples,1))    \n    return X,y","962b34d2":"def generate_latent_points(latent_dim,n_samples):\n    \n    x_input =randn(latent_dim * n_samples)\n    x_input = x_input.reshape(n_samples,latent_dim)\n    \n    return x_input","41c5a6d4":"def generate_fake_samples(g_model,latent_dim,n_samples):\n    x_input=generate_latent_points(latent_dim,n_samples)\n    X = g_model.predict(x_input)\n    y=zeros((n_samples,1))\n    return X,y\n","d483c9aa":"def save_plot(examples, epoch, n=10):\n\t# scale from [-1,1] to [0,1]\n\texamples = (examples + 1) \/ 2.0\n\t# plot images\n\tfor i in range(n * n):\n\t\t# define subplot\n\t\tpyplot.subplot(n, n, 1 + i)\n\t\t# turn off axis\n\t\tpyplot.axis('off')\n\t\t# plot raw pixel data\n\t\tpyplot.imshow(examples[i])\n\t# save plot to file\n\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n\tpyplot.savefig(filename)\n\tpyplot.close()\n \n# evaluate the discriminator, plot generated images, save generator model\ndef summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n\t# prepare real samples\n\tX_real, y_real = generate_real_samples(dataset, n_samples)\n\t# evaluate discriminator on real examples\n\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n\t# prepare fake examples\n\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n\t# evaluate discriminator on fake examples\n\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n\t# summarize discriminator performance\n\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n\t# save plot\n\tsave_plot(x_fake, epoch)\n\t# save the generator model tile file\n\tfilename = 'generator_model_%03d.h5' % (epoch+1)\n\tg_model.save(filename)\n \n# train the generator and discriminator\ndef train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n\tbat_per_epo = int(dataset.shape[0] \/ n_batch)\n\thalf_batch = int(n_batch \/ 2)\n\t# manually enumerate epochs\n\tfor i in range(n_epochs):\n\t\t# enumerate batches over the training set\n\t\tfor j in range(bat_per_epo):\n\t\t\t# get randomly selected 'real' samples\n\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n\t\t\t# update discriminator model weights\n\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n\t\t\t# generate 'fake' examples\n\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n\t\t\t# update discriminator model weights\n\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n\t\t\t# prepare points in latent space as input for the generator\n\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n\t\t\t# create inverted labels for the fake samples\n\t\t\ty_gan = ones((n_batch, 1))\n\t\t\t# update the generator via the discriminator's error\n\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n\t\t\t# summarize loss on this batch\n\t\t\tprint('>%d, %d\/%d, d1=%.3f, d2=%.3f g=%.3f' %\n\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n\t\t# evaluate the model performance, sometimes\n\t\tif (i+1) % 10 == 0:\n\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)\n \n# size of the latent space\nlatent_dim = 100\n# create the discriminator\nd_model = define_discriminator()\n# create the generator\ng_model = define_generator(latent_dim)\n# create the gan\ngan_model = define_gan(g_model, d_model)\n# load image data\ndataset = load_real_samples()\n# train model\ntrain(g_model, d_model, gan_model, dataset, latent_dim)","10b62bd0":"6","68d3afd5":"\n\t\n# example of loading the generator model and generating images\nfrom numpy import asarray\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom keras.models import load_model\nfrom matplotlib import pyplot\n \n# generate points in latent space as input for the generator\ndef generate_latent_points(latent_dim, n_samples, n_classes=10):\n    # generate points in the latent space\n    x_input = randn(latent_dim * n_samples)\n    # reshape into a batch of inputs for the network\n    z_input = x_input.reshape(n_samples, latent_dim)\n    return z_input\n \n# create a plot of generated images\ndef plot_generated(examples, n):\n    # plot images\n    for i in range(n * n):\n        # define subplot\n        pyplot.subplot(n, n, 1 + i)\n        # turn off axis\n        pyplot.axis('off')\n        # plot raw pixel data\n        pyplot.imshow(examples[i, :, :])\n    pyplot.show()\n \n# load model\nmodel = load_model('generator_model_030.h5')\n# generate images\nlatent_points = generate_latent_points(100, 25)\n# generate images\nX  = model.predict(latent_points)\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n# plot the result\nplot_generated(X, 5)","c647e449":"from numpy import asarray\nfrom numpy.random import randn\nfrom numpy.random import randint\nfrom numpy import linspace\nfrom keras.models import load_model\nfrom matplotlib import pyplot\n \n# generate points in latent space as input for the generator\ndef generate_latent_points(latent_dim, n_samples, n_classes=10):\n    # generate points in the latent space\n    x_input = randn(latent_dim * n_samples)\n    # reshape into a batch of inputs for the network\n    z_input = x_input.reshape(n_samples, latent_dim)\n    return z_input\n \n# uniform interpolation between two points in latent space\ndef interpolate_points(p1, p2, n_steps=10):\n    # interpolate ratios between the points\n    ratios = linspace(0, 1, num=n_steps)\n    # linear interpolate vectors\n    vectors = list()\n    for ratio in ratios:\n        v = (1.0 - ratio) * p1 + ratio * p2\n        vectors.append(v)\n    return asarray(vectors)\n \n# create a plot of generated images\ndef plot_generated(examples, n):\n    # plot images\n    for i in range(n):\n        # define subplot\n        pyplot.subplot(1, n, 1 + i)\n        # turn off axis\n        pyplot.axis('off')\n        # plot raw pixel data\n        pyplot.imshow(examples[i, :, :])\n    pyplot.show()\n \n# load model\nmodel = load_model('generator_model_080.h5')\n# generate points in latent space\npts = generate_latent_points(100, 2)\n# interpolate points in latent space\ninterpolated = interpolate_points(pts[0], pts[1])\n# generate images\nX = model.predict(interpolated)\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n# plot the result\nplot_generated(X, len(interpolated))","f5b618b7":"Load Model and Generate Faces","14ed8abc":"we can perform face detection and extract only the face before resizing the result to a fixed size using mtcnn","59799252":"The discriminator model takes as input one 80\u00d780 color image an outputs a binary prediction as to whether the image is real (class=1) or fake (class=0). ","de311b7b":"Since We will require one batch (or a half) batch of real images from the dataset each update to the GAN model. A simple way to achieve this is to select a random sample of images from the dataset each time\nclass is 1 becz all all real img","f1d3090d":"### Prepare celebA dataset","321db409":"\n\nThe generator model takes as input a point in the latent space and outputs a single 80\u00d780 color image."}}