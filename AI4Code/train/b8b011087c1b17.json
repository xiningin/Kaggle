{"cell_type":{"ec49af2e":"code","38ba312c":"code","42c7148a":"code","3cb08518":"code","229f3798":"code","5916c1b9":"code","0b62a1ea":"code","864fed77":"code","8bbaed36":"code","35c9b969":"code","3952e755":"code","33f782a6":"code","8a38ef38":"code","f53cf07c":"code","f5a55052":"code","4db8eae6":"code","cfb2544e":"code","850d2b98":"code","9c7e4712":"code","835e654d":"code","20216c0a":"code","202ce491":"code","c0966ffc":"markdown","34584a13":"markdown","0374ebe3":"markdown","19ff958d":"markdown","bdc5fdf9":"markdown","1aad8c7e":"markdown","3a31a54a":"markdown","1870d014":"markdown","f48cb614":"markdown","e5b2e3b3":"markdown","2ce4253d":"markdown"},"source":{"ec49af2e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","38ba312c":"!pip install jcopdl #install jcopdl","42c7148a":"import numpy as np\nimport matplotlib.pyplot as plt","3cb08518":"import torch\nfrom torch import nn, optim\nfrom jcopdl.callback import Callback, set_config\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","229f3798":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader","5916c1b9":"bs = 64\ncrop_size = 224\n\ndata_train = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/\"\ndata_test = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test\/\"\ndata_val = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val\/\"\n\ntrain_transform = transforms.Compose([\n    transforms.RandomRotation(10),\n    transforms.RandomResizedCrop(crop_size, scale=(0.7, 1)),\n    transforms.ColorJitter(brightness=0.3,contrast=0.3),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(230),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_set = datasets.ImageFolder(data_train, transform=train_transform)\ntrainloader = DataLoader(train_set, batch_size=bs, shuffle=True, num_workers=4)\n\ntest_set = datasets.ImageFolder(data_test, transform=test_transform)\ntestloader = DataLoader(test_set, batch_size=bs, shuffle=True)","0b62a1ea":"feature, target = next(iter(trainloader))\nfeature.shape","864fed77":"label2cat = train_set.classes\nlabel2cat","8bbaed36":"from torchvision.models import mobilenet_v2\n\nmnet = mobilenet_v2(pretrained=True) #Load pretrained model # pretrained = True | mendownload model berserta weightnya\n\nfor param in mnet.parameters(): # Freeze semua weight feature ekstraktornya\n    param.requires_grad = False ","35c9b969":"mnet.classifier = nn.Sequential(\n        nn.Linear(1280, 256),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n    \n        nn.Linear(256,2),\n        nn.LogSoftmax()\n)","3952e755":"mnet","33f782a6":"class CustomMobilenetV2(nn.Module):\n    def __init__(self, output_size):\n        super().__init__()\n        self.mnet = mobilenet_v2(pretrained=True)\n        self.freeze()\n        self.mnet.classifier = nn.Sequential(\n        nn.Linear(1280, 256),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n    \n        nn.Linear(256,2),\n        nn.LogSoftmax()\n)\n        \n    def forward(self, x):\n        return self.mnet(x)\n\n    def freeze(self):\n        for param in self.mnet.parameters():\n            param.requires_grad = False\n            \n    def unfreeze(self):        \n        for param in self.mnet.parameters():\n            param.requires_grad = True","8a38ef38":"config = set_config({\n    \"output_size\": len(train_set.classes),\n    \"batch_size\": bs,\n    \"crop_size\": crop_size\n})","f53cf07c":"model = CustomMobilenetV2(config.output_size).to(device)\ncriterion = nn.NLLLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.001)\ncallback = Callback(model, config, early_stop_patience=2, outdir=\"model\")","f5a55052":"from tqdm.auto import tqdm\n\ndef loop_fn(mode, dataset, dataloader, model, criterion, optimizer, device):\n    if mode == \"train\":\n        model.train()\n    elif mode == \"test\":\n        model.eval()\n    cost = correct = 0\n    for feature, target in tqdm(dataloader, desc=mode.title()):\n        feature, target = feature.to(device), target.to(device)\n        output = model(feature)\n        loss = criterion(output, target)\n        \n        if mode == \"train\":\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        \n        cost += loss.item() * feature.shape[0]\n        correct += (output.argmax(1) == target).sum().item()\n    cost = cost \/ len(dataset)\n    acc = correct \/ len(dataset)\n    return cost, acc","4db8eae6":"while True:\n    train_cost, train_score = loop_fn(\"train\", train_set, trainloader, model, criterion, optimizer, device)\n    with torch.no_grad():\n        test_cost, test_score = loop_fn(\"test\", test_set, testloader, model, criterion, optimizer, device)\n    \n    # Logging\n    callback.log(train_cost, test_cost, train_score, test_score)\n\n    # Checkpoint\n    callback.save_checkpoint()\n        \n    # Runtime Plotting\n    callback.cost_runtime_plotting()\n    callback.score_runtime_plotting()\n    \n    # Early Stopping\n    if callback.early_stopping(model, monitor=\"test_score\"):\n        callback.plot_cost()\n        callback.plot_score()\n        break","cfb2544e":"model.unfreeze()\noptimizer = optim.AdamW(model.parameters(), lr=1e-5)\n\ncallback.reset_early_stop()\ncallback.early_stop_patience = 5","850d2b98":"while True:\n    train_cost, train_score = loop_fn(\"train\", train_set, trainloader, model, criterion, optimizer, device)\n    with torch.no_grad():\n        test_cost, test_score = loop_fn(\"test\", test_set, testloader, model, criterion, optimizer, device)\n    \n    # Logging\n    callback.log(train_cost, test_cost, train_score, test_score)\n\n    # Checkpoint\n    callback.save_checkpoint()\n        \n    # Runtime Plotting\n    callback.cost_runtime_plotting()\n    callback.score_runtime_plotting()\n    \n    # Early Stopping\n    if callback.early_stopping(model, monitor=\"test_score\"):\n        callback.plot_cost()\n        callback.plot_score()\n        break","9c7e4712":"feature, target = next(iter(testloader))\nfeature, target = feature.to(device), target.to(device)","835e654d":"with torch.no_grad():\n    model.eval()\n    output = model(feature)\n    preds = output.argmax(1)\npreds","20216c0a":"def convert_to_label(x):\n    return [label for pred, label in zip(x, label2cat) if pred==1]\n\ndef inverse_norm(img):\n    img[0, :, :] = img[0, :, :] * 0.229 + 0.485\n    img[1, :, :] = img[1, :, :] * 0.224 + 0.456\n    img[2, :, :] = img[2, :, :] * 0.225 + 0.406\n    return img ","202ce491":"fig, axes = plt.subplots(6, 6, figsize=(24, 24))\nfor img, label, pred, ax in zip(feature, target, preds, axes.flatten()):\n    ax.imshow(inverse_norm(img).permute(1, 2, 0).cpu())\n    font = {\"color\": 'r'} if (pred != label).any() else {\"color\": 'g'}        \n    label, pred = convert_to_label(label), convert_to_label(pred)\n    ax.set_title(f\"Label: {label}\\nPred: {pred}\", fontdict=font);\n    ax.axis('off');","c0966ffc":" # Import Packages","34584a13":"## Model: MobilenetV2","0374ebe3":"## Sanity Check","19ff958d":"# Fase 1: Adaptasi ( learning rate standard + patience kecil )","bdc5fdf9":"## Custom Classifier","1aad8c7e":"## Prediksi","3a31a54a":"## Config","1870d014":"# Dataset dan Dataloader","f48cb614":"# Arsitektur dan Config","e5b2e3b3":"# Fase 2: Fine tuning ( learning rate dikecilkan + patience ditambah )","2ce4253d":"## Custom Class"}}