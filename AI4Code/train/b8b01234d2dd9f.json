{"cell_type":{"e8832a7c":"code","bd7c9dd4":"code","fad006ce":"code","39e6993b":"code","e64f95b0":"code","6d79de82":"code","192af8b6":"code","dd81a09f":"code","d33e8f38":"code","ea646eb0":"code","975465d8":"code","5bd859dd":"code","1add7bd7":"code","d42a04db":"markdown","29a85ed5":"markdown","16021fa8":"markdown","f994348d":"markdown","7e7720a2":"markdown","997c8693":"markdown"},"source":{"e8832a7c":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport os\nimport math\nimport keras\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.layers import Dense, Activation\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\n%matplotlib inline","bd7c9dd4":"'''Pulling the photos from folders with their paths'''\n\npath_0 = []\ntrain_path_0 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/0\/\"                #zero\nfor path in os.listdir(train_path_0):\n    if '.JPG' in path:\n        path_0.append(os.path.join(train_path_0, path))\n        \npath_1 = []\ntrain_path_1 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/1\/\"                #one\nfor path in os.listdir(train_path_1):\n    if '.JPG' in path:\n        path_1.append(os.path.join(train_path_1, path))\n        \npath_2 = []\ntrain_path_2 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/2\/\"                #two\nfor path in os.listdir(train_path_2):\n    if '.JPG' in path:\n        path_2.append(os.path.join(train_path_2, path))\n\npath_3 = []\ntrain_path_3 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/3\/\"                #three\nfor path in os.listdir(train_path_3):\n    if '.JPG' in path:\n        path_3.append(os.path.join(train_path_3, path))\n        \npath_4 = []\ntrain_path_4 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/4\/\"                #four\nfor path in os.listdir(train_path_4):\n    if '.JPG' in path:\n        path_4.append(os.path.join(train_path_4, path))\n        \npath_5 = []\ntrain_path_5 = \"..\/input\/hand-sign-language-digit-dataset-for-0-5\/5\/\"                #five\nfor path in os.listdir(train_path_5):\n    if '.JPG' in path:\n        path_5.append(os.path.join(train_path_5, path))\n\nprint(\"Number of pics for each digit:\")\nprint((len(path_0), len(path_1), len(path_2), len(path_3), len(path_4), len(path_5)))\n\nprint(\"Total pics in the dataset: \" + str(len(path_0) + len(path_1) + len(path_2) + len(path_3) + len(path_4) + len(path_5)))","fad006ce":"'''Load training set'''\n\n'''total pics in training set =  1237\n    training_set = 1230 --- 205 for each digit'''\n\ntrain_set_orig = np.zeros((1230, 64, 64, 3), dtype='float32')\n\nfor i in range(205):                                                                #loading \"zero\"\n    image = Image.open(path_0[i])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n    \nfor i in range(205, 410):                                                           #loading \"one\"\n    image = Image.open(path_1[i - 205])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(410, 615):                                                           #loading \"two\"\n    image = Image.open(path_2[i - 410])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(615, 820):                                                           #loading \"three\"\n    image = Image.open(path_3[i - 615])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n    \nfor i in range(820, 1025):                                                           #loading \"four\"\n    image = Image.open(path_4[i - 820])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(1025, 1230):                                                          #loading \"five\"\n    image = Image.open(path_5[i - 1025])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)","39e6993b":"'''Labelling the training set having 6-dimensional vector of o's and 1's with 1 where index = digit and zero otherwise'''\n\ntrain_y_ = np.zeros((1230, 6))\n\nfor i in range(205):                                                               #labelling \"zero\"\n    train_y_[i, 0] = 1\n\nfor i in range(205, 410):                                                          #labelling \"one\"\n    train_y_[i, 1] = 1\n        \nfor i in range(410, 615):                                                          #labelling \"two\"\n    train_y_[i, 2] = 1\n        \nfor i in range(615, 820):                                                          #labelling \"three\"\n    train_y_[i, 3] = 1\n    \nfor i in range(820, 1025):                                                          #labelling \"four\"\n    train_y_[i, 4] = 1\n    \nfor i in range(1025, 1230):                                                         #labelling \"five\"\n    train_y_[i, 5] = 1","e64f95b0":"m_train = train_set_orig.shape[0]\nnum_px = train_set_orig.shape[1]\n\nprint(\"SUMMARY OF DATASET:\")\nprint (\"Number of training examples: m_train = \" + str(m_train))\nprint (\"Height\/Width of each image: num_px = \" + str(num_px))\nprint (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\nprint (\"train_set_x shape: \" + str(train_set_orig.shape))\nprint (\"train_set_y shape: \" + str(train_y_.shape))","6d79de82":"''''Suffling training set pics'''\n\nnp.random.seed(0)\nm_train = train_set_orig.shape[0]\npermutation = list(np.random.permutation(m_train))\ntrain_set_x = train_set_orig[permutation, :]\ntrain_y = train_y_[permutation, :]","192af8b6":"train_x = train_set_x.reshape(1230,-1)\nprint (\"train_set_x_flatten shape: \" + str(train_x.shape))\nprint (\"train_set_y shape: \" + str(train_y.shape))","dd81a09f":"'''Standardizing dataset'''\n\ntrain_x = train_x \/255","d33e8f38":"'''Example of an image'''\n\nindex = 20\nplt.imshow(np.uint8(train_set_x[index]), interpolation='nearest')\nplt.show()\nprint(np.where(train_y[index] == 1)[0])","ea646eb0":"'''Making sequential deep learning model using keras\n   input layer: shape -- (12288, number of examples)\n   layer 1: shape -- (128, number of examples) with \"relu\" activation\n   layer 2: shape -- (64, number of examples) with \"relu\" activation\n   layer 3: shape -- (32, number of examples) with \"relu\" activation\n   layer 4: shape -- (6, number of examples) with \"softmax\" activation. This layer is the ouput layer'''\n\nmodel = Sequential()\n\nmodel.add(Dense(input_shape = (12288, ), units = 128, activation = \"relu\"))\nmodel.add(Dense(units = 64, activation = \"relu\"))\nmodel.add(Dense(units = 32, activation = \"relu\"))\nmodel.add(Dense(units = 6, activation = \"softmax\"))\n\n'''using \"Adam\" optimizer'''\n\nopt = keras.optimizers.Adam(learning_rate = 0.0001)\n\n'''Compiling the model using the \"categorical_crossentropy\" loss function'''\n\nmodel.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","975465d8":"'''Fitting the model using training set'''\n\nlanguage = model.fit(train_x, train_y, epochs = 150, validation_split = 0.05)","5bd859dd":"print(\"Training set accurarcy: \" + str((language.history[\"accuracy\"])[-1]*100) + \"%\")\nprint(\"Validation set accurarcy: \" + str((language.history[\"val_accuracy\"])[-1]*100) + \"%\")","1add7bd7":"plt.figure(figsize=(15, 5))\n\nplt.subplot(1,2,1)\n\nplt.plot(language.history[\"accuracy\"], label = \"training set\")\nplt.plot(language.history[\"val_accuracy\"], label = \"validation set\")\nplt.title(\"accuracy versus epochs curve\")\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend(loc='best')\n\nplt.subplot(1,2,2)\n\nplt.plot(language.history[\"loss\"], label = \"training set\")\nplt.plot(language.history[\"val_loss\"], label = \"validation set\")\nplt.title(\"loss versus epochs curve\")\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend(loc='best')\n\nplt.show()","d42a04db":"# *Learning curves of the model*","29a85ed5":"# *Train\/Validation set accuracy*","16021fa8":"# *Preprocessing training data*","f994348d":"# *Visualizing an image from training data*","7e7720a2":"# *Deep learning model*","997c8693":"# *Reading images data from the folder named \"hand-sign-language-digit-dataset-for-0-5\"*"}}