{"cell_type":{"8f4d4490":"code","73b3cd2b":"code","51c04d23":"code","5b20863d":"code","f3333f97":"code","bc4b0593":"code","d08c958c":"code","7a683278":"code","904f4312":"code","635329ab":"code","790f5303":"code","284622bc":"code","1b917da5":"code","1aeb7822":"code","cabba06a":"code","a0d06ea7":"code","f496db80":"code","9aa7ce6f":"code","fc88128b":"code","5e0923e8":"code","0df6b408":"code","c486d58e":"code","7292aacf":"code","670221b8":"code","a91142bb":"markdown","ddb19181":"markdown","9e331c8e":"markdown","35c86a80":"markdown"},"source":{"8f4d4490":"import os\nimport gc\nimport itertools\nfrom pprint import pprint\nimport random\n\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import transforms\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.autograd import Variable","73b3cd2b":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"..\/input\/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input\/gan-getting-started\/monet_jpg'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51c04d23":"# set numpy seed to always get the same 30 style images\nnp.random.seed(0)\ntorch.random.manual_seed(0)\nrandom.seed(0)\n\ndef sample_images(paths, n_samples=30):\n    idxs = np.sort(np.random.choice(len(paths), n_samples, replace=False))\n\n    return paths[idxs]","5b20863d":"def load_images(path, image_shape=(256,256)):\n    monet_path = os.path.join(path, 'monet_jpg')\n    photo_path = os.path.join(path, 'photo_jpg')\n\n    style_images_paths = np.array(list(os.listdir(monet_path)))\n    content_images_paths = np.array(list(os.listdir(photo_path)))\n\n    sampled_style_images_paths = sample_images(style_images_paths)\n    sampled_content_images_paths = sample_images(content_images_paths, n_samples=7000)\n\n    return sampled_style_images_paths, sampled_content_images_paths\n\n# dataset path\ntrain_path = '\/kaggle\/input\/gan-getting-started'\nstyle_imgs, content_imgs = load_images(train_path)\n\nprint(content_imgs.shape)\nprint(style_imgs.shape)\npprint(style_imgs)","f3333f97":"!git clone https:\/\/github.com\/nspitzern\/kaggle-monet-competition.git\n    \n!mkdir \/kaggle\/temp\n!mv \/kaggle\/working\/kaggle-monet-competition \/kaggle\/temp\/kaggle-monet-competition","bc4b0593":"kaggle_working_dir = '\/kaggle\/working'\nkaggle_working_output_dir = '\/kaggle\/working\/output'\nos.mkdir(kaggle_working_output_dir)\n\nkaggle_my_files = '\/kaggle\/temp\/kaggle-monet-competition'\n\nwith open(os.path.join(kaggle_my_files, 'style_files_path.npy'), 'rb') as f:\n    style_imgs = np.load(f)","d08c958c":"fig = plt.figure(figsize=(20, 20))\ncolumns = 6\nrows = 5\nfor i in range(1, columns*rows +1):\n    img = Image.open(os.path.join(train_path, 'monet_jpg', style_imgs[i - 1]))\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","7a683278":"class MonetSampledDataset(Dataset):\n    def __init__(self, root_path, content_root_path, style_root_path, content_paths, style_paths, style_transforms):\n        self.root_path = root_path\n        self.content_root_path = content_root_path\n        self.style_root_path = style_root_path\n        self.content_paths = content_paths\n        self.style_paths = style_paths\n        self.style_transforms = style_transforms\n        self.to_tensor = transforms.Compose([\n                transforms.ToTensor(), \n                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # normalize the image\n        ])\n\n    def __getitem__(self, content_idx):\n        # get the current content image\n        content_image_path = self.content_paths[content_idx]\n        content_image = Image.open(os.path.join(self.root_path, self.content_root_path, content_image_path))\n\n        # sample a style image\n        style_idx = np.random.choice(len(self.style_paths))\n        style_image_path = self.style_paths[style_idx]\n        style_image = Image.open(os.path.join(self.root_path,  self.style_root_path, style_image_path))\n\n        # convert to tensors\n        content_image = self.to_tensor(content_image)\n        original_style_image = self.to_tensor(style_image.copy())\n        style_image = self.style_transforms(style_image)\n\n        return {'photo': content_image, 'monet': original_style_image, 'monet_aug': style_image}\n\n    def __len__(self):\n        return len(self.content_paths)\n    \n    def resample_content_images(self):\n        photo_path = os.path.join(self.root_path, self.content_root_path)\n        content_images_paths = np.array(list(os.listdir(photo_path)))\n        self.content_paths = sample_images(content_images_paths, n_samples=1000)","904f4312":"style_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),\n#     transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n    transforms.RandomResizedCrop((256, 256)),\n    transforms.ToTensor(), # numpy array to tensor\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # normalize the image between [-1,1]              \n])","635329ab":"tensor2img = transforms.Compose([transforms.Normalize((-1, -1, -1), (2, 2 ,2)), # normalize the image between [0, 1]\n                                 transforms.ToPILImage()])\n\ndef tensor2image(image):\n    return tensor2img(image)","790f5303":"# define dataset\nmonet_dataset = MonetSampledDataset(root_path=train_path,\n                                    content_root_path='photo_jpg',\n                                    style_root_path='monet_jpg',\n                                    content_paths=content_imgs,\n                                    style_paths=style_imgs,\n                                    style_transforms=style_transforms)","284622bc":"print(len(monet_dataset))\nprint(monet_dataset[0]['photo'].shape)\nprint(monet_dataset[0]['monet'].shape)","1b917da5":"class ResidualBlock(nn.Module):\n    def __init__(self, in_features):\n        super(ResidualBlock, self).__init__()\n\n        self.conv_block = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features),\n            nn.ReLU(inplace=True),\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(in_features, in_features, 3),\n            nn.InstanceNorm2d(in_features)\n        )\n\n    def forward(self, x):\n        return x + self.conv_block(x)","1aeb7822":"class Generator(nn.Module):\n    def __init__(self, input_size, output_size, n_residual_blocks=9):\n        super(Generator, self).__init__()\n\n        # Initial convolution block\n        model = [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(input_size, 64, kernel_size=7),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True)\n        ]\n\n        # Downsampling\n        in_features = 64\n        out_features = in_features * 2\n\n        for _ in range(2):\n            model += [\n                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n\n            in_features = out_features\n            out_features = in_features * 2\n\n        # Residual blocks\n        for _ in range(n_residual_blocks):\n            model += [\n                ResidualBlock(in_features=in_features)\n            ]\n\n        # Upsampling\n        out_features = in_features \/\/ 2\n        for _ in range(2):\n            model += [\n                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1),\n                nn.InstanceNorm2d(out_features),\n                nn.ReLU(inplace=True)\n            ]\n\n            in_features = out_features\n            out_features = in_features \/\/ 2\n\n        # Output layer\n        model += [\n                  nn.ReflectionPad2d(3),\n                  nn.Conv2d(64, output_size, 7),\n                  nn.Tanh()\n        ]\n\n        self.model = nn.Sequential(*model)\n\n    def forward(self, x):\n        return self.model(x)","cabba06a":"def load_model(path, generator_photo2monet, device):\n    generator_photo2monet.load_state_dict(torch.load(os.path.join(path, 'generator_photo2monet.pth')))\n\n    generator_photo2monet.to(device)","a0d06ea7":"in_channels = 3\nout_channels = 3\ndevice = 'cuda' if torch.cuda.is_available else 'cpu'\n\ngenerator_photo2monet = Generator(in_channels, out_channels).to(device)\nload_model(os.path.join(kaggle_my_files, 'pretrain_train\/models'), generator_photo2monet, device)","f496db80":"BATCH_SIZE = 1\n\n# dataset loader\nmonet_dataloder = DataLoader(monet_dataset, batch_size=1, shuffle=False)","9aa7ce6f":"def save_image(output_path, image, i):\n    output_path = os.path.join(output_path, f'{i}.jpg')\n    image.save(output_path)","fc88128b":"# for l in os.listdir(kaggle_working_dir):\n#     if l.endswith('.jpg'):\n#         os.remove(os.path.join(kaggle_working_dir, l))","5e0923e8":"results = []\n\ngenerator_photo2monet.eval()\n\n\nTensor = torch.cuda.FloatTensor if torch.cuda.is_available else torch.Tensor\ninput_photo = Tensor(BATCH_SIZE, in_channels, 256, 256).to(device)\n\nfor i, batch in enumerate(monet_dataloder):\n    real_photo = Variable(input_photo.copy_(batch['photo'])).to(device)\n    \n    fake_monet = generator_photo2monet(real_photo).cpu().squeeze().detach()\n    \n    fake_monet = fake_monet.cpu().detach()\n    fake_monet = tensor2image(fake_monet)\n    \n    save_image(kaggle_working_output_dir, fake_monet, i)\n    \n    print(f'Image #{i} created...')","0df6b408":"import shutil\n\nshutil.rmtree(kaggle_my_files)","c486d58e":"from zipfile import ZipFile\n\nwith ZipFile('images.zip', 'w') as zip:\n    for file in os.listdir(kaggle_working_output_dir):\n        if file.endswith('.jpg'):\n            zip.write(os.path.join(kaggle_working_output_dir, file), file)\n    print('zip created')","7292aacf":"shutil.rmtree(kaggle_working_output_dir)\n# os.listdir(kaggle_working_output_dir)","670221b8":"# os.remove('images.zip')","a91142bb":"## Create Dataset and Dataloader","ddb19181":"# Create Fake images","9e331c8e":"# Load the images paths","35c86a80":"# Define Generator"}}