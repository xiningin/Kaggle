{"cell_type":{"88d657df":"code","68af0229":"code","3422ffb9":"code","24d346cc":"code","c193a6ba":"code","b2174cb4":"code","9f0181b5":"code","5d22dda2":"code","026cf307":"code","42de46f1":"code","49b8ae48":"code","d7f4b8ac":"code","8b438770":"code","21c6b47e":"code","f07d762d":"code","7d4f44fe":"code","f3074eb3":"code","e22dbc5e":"code","ec8a5e2b":"markdown","29624cb6":"markdown","da75b18e":"markdown","6fe07c5b":"markdown","d834735d":"markdown","a1a3bd50":"markdown","368ac216":"markdown","a6282b82":"markdown"},"source":{"88d657df":"# import libraries\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2","68af0229":"image_size = (128,128)\n\nbase_dir = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/'\n\n\ntrain_gen = keras.preprocessing.image.ImageDataGenerator(\n    horizontal_flip=True,\n    rescale=1.\/255\n)\n\nval_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntest_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntrain_ds = train_gen.flow_from_directory(base_dir+'Train',target_size=image_size,seed=42)\nval_ds = val_gen.flow_from_directory(base_dir+'Validation',target_size=image_size,seed=42)\ntest_ds = test_gen.flow_from_directory(base_dir+'Test',target_size=image_size,seed=42)","3422ffb9":"class_names = {v:k for k,v in train_ds.class_indices.items()}\nimages,labels = next(iter(train_ds))\n\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.imshow(images[i])\n    plt.xticks([])\n    plt.yticks([])\n    plt.xlabel(class_names[labels[i][1]])\n\nplt.show()","24d346cc":"# we use VGG19 model for mask detection\n\nbase_model = keras.applications.VGG19(include_top=False,input_shape=image_size+(3,))\nbase_model.trainable = False\n\nmodel = keras.Sequential([\n    base_model,\n    layers.Flatten(),\n    layers.Dense(2,activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(),\n    loss=keras.losses.BinaryCrossentropy(),\n    metrics=[keras.metrics.BinaryAccuracy()]\n)","c193a6ba":"# View network architecture\nmodel.summary()","b2174cb4":"# Using EarlyStopping, end training when val_accuracy is not improved for 4 consecutive times\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy',mode='max',\n                                patience=4,restore_best_weights=True)\n\n# Using ReduceLROnPlateau, the learning rate is reduced by half when val_accuracy is not improved for 2 consecutive times\nlr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_binary_accuracy',factor=0.5,\n                                patience=2,verbose=1)\n\n# training\nhistory = model.fit(train_ds,batch_size=32,epochs=30,\n        validation_data=val_ds,callbacks=[early_stopping,lr_scheduler])","9f0181b5":"acc = history.history['binary_accuracy']\nval_acc = history.history['val_binary_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","5d22dda2":"# test model\nmodel.evaluate(test_ds)","026cf307":"# unfreeze all the layers\nbase_model.trainable = True\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(lr=0.00001),\n    loss=keras.losses.BinaryCrossentropy(),\n    metrics=[keras.metrics.BinaryAccuracy()]\n)","42de46f1":"# Using EarlyStopping, end training when val_accuracy is not improved for 4 consecutive times\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy',mode='max',\n                                patience=4,restore_best_weights=True)\n\n# Using ReduceLROnPlateau, the learning rate is reduced by half when val_accuracy is not improved for 2 consecutive times\nlr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_binary_accuracy',factor=0.5,\n                                patience=2,verbose=1)\n\n# training\nhistory = model.fit(train_ds,batch_size=32,epochs=30,\n        validation_data=val_ds,callbacks=[early_stopping,lr_scheduler])","49b8ae48":"# test model \nmodel.evaluate(test_ds)\n\n# Our model achieved 99.89% accuracy on test data.","d7f4b8ac":"# save model\nmodel.save('VGG19-Face Mask Detection.h5')","8b438770":"# loading haarcascade_frontalface_default.xml\nface_model = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')","21c6b47e":"mask_label = {0:'MASK',1:'NO MASK'}\ndist_label = {0:(0,255,0),1:(255,0,0)} # rectangle color","f07d762d":"def plot_image(image,subplot):\n    plt.subplot(*subplot)\n    plt.imshow(image)\n    plt.xticks([])\n    plt.yticks([])\n    plt.show\n\ndef predict_image(image_dir):\n    img = cv2.imread(image_dir)\n    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n    \n    #returns a list of (x,y,w,h) tuples\n    faces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n    \n    out_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\n    plt.figure(figsize=(20,20))\n    plot_image(out_img,(1,2,1))\n    \n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = out_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(128,128))\n        crop = np.reshape(crop,[1,128,128,3])\/255.0\n        mask_result = model.predict(crop).argmax()\n        cv2.rectangle(out_img,(x,y),(x+w,y+h),dist_label[mask_result],1)\n    \n    plot_image(out_img,(1,2,2))","7d4f44fe":"predict_image('..\/input\/face-mask-detection\/images\/maksssksksss244.png')","f3074eb3":"predict_image('..\/input\/face-mask-detection\/images\/maksssksksss174.png')","e22dbc5e":"predict_image('..\/input\/face-mask-detection\/images\/maksssksksss388.png')","ec8a5e2b":"## Using haar cascade to detect faces\nObject Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images. We'll be using a Haar Cascade Model trained to detect faces in order to obtain the bounding box coordinates of faces in an image.","29624cb6":"\n# Load data","da75b18e":"* Fine tuning  \n","6fe07c5b":"# Build model","d834735d":"* Show some images","a1a3bd50":"We now take crops of the faces detected in the image and use the model trained in the above section to determine whether the individual faces have a mask or not. Those who do not wear masks are marked in red and those who do are marked in green","368ac216":"# Predict","a6282b82":"* Draw the learning curve"}}