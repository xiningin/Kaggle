{"cell_type":{"ffb95272":"code","4428d002":"code","5da280a3":"code","8792bed4":"code","9063abc7":"code","ca3911c0":"code","3a5b93f9":"code","120f592b":"code","ab0e140d":"code","de996bd2":"code","795dd478":"code","19c30c43":"code","95491492":"code","44c25336":"code","88188174":"code","7156acc3":"code","9f75312a":"code","0e45f346":"code","b9c196d9":"code","56b77343":"code","341a5f7b":"code","df003b9c":"code","6a007a4a":"code","687c116c":"markdown","794843ab":"markdown","6acc8a84":"markdown","259542ac":"markdown","4f3e4644":"markdown","bf285a95":"markdown","26996ca3":"markdown","317df78b":"markdown","eca1798a":"markdown","56339014":"markdown","dfe779f8":"markdown","33a738b0":"markdown","150e8e69":"markdown","103e658f":"markdown","7b33a517":"markdown"},"source":{"ffb95272":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))","4428d002":"data_train = pd.read_csv('..\/input\/train.csv')\ndisplay(data_train.head())\ndisplay(data_train.info())\ndisplay(data_train.describe())","5da280a3":"import matplotlib.pyplot as plt\nplt.hist(data_train['Survived'] )\nprint(\"Number of survived people: {} \\nNumber of not survived people: {}\".format(len(data_train[data_train['Survived'] == 1]),len(data_train[data_train['Survived'] == 0])))","8792bed4":"plt.figure(figsize = (12,6))\ns = plt.scatter(data_train['Age'], data_train['Pclass'], c = data_train['Survived'], alpha = 0.5, cmap = 'binary')\nplt.colorbar(s)\nplt.xlabel('Age')\nplt.ylabel('Passenger Class')\nplt.legend('Survived',loc='best')","9063abc7":"plt.figure(figsize = (12,6))\ns = plt.scatter(data_train['Age'], data_train['Sex'], c = data_train['Survived'], alpha = 0.5, cmap = 'binary')\nplt.colorbar(s)\nplt.xlabel('Age')\nplt.ylabel('Gender')\nplt.legend('Survived',loc='best')","ca3911c0":"def transformer(data_train = data_train):\n    from numpy import array\n\n    names = ''\n    for i in data_train['Name']:\n        names += ' '+i\n\n    import re\n    pattern = re.compile(r',\\s\\w+')\n    matches = pattern.finditer(names)\n    salutations = []\n    for match in matches:\n        if(match.group().lstrip(', ') not in salutations):\n            salutations.append(match.group().lstrip(', '))\n\n    print(salutations)\n\n    salutationDF = []\n    for sal in data_train['Name']:\n        salutationDF.append(re.search(r',\\s\\w+',sal).group().lstrip(', '))\n \n    print(len(salutationDF))\n\n\n    ageDF = pd.DataFrame(salutationDF)\n    ageDF['Age'] = data_train['Age']\n    ageDF.columns = ['Salutation','Age']\n    a = ageDF['Salutation'].value_counts()\n\n    means = []\n    for sal in salutations:\n        means.append(array(ageDF[ageDF['Salutation'] == sal]['Age'].dropna()).mean())\n    print(means)\n\n    dict_sal = {}\n    c = 0\n    for sal in salutations:\n        dict_sal[sal] = means[c]\n        c+=1\n    dict_sal    \n\n    for sal in salutations:\n        ageDF.ix[ageDF.Salutation == sal, 'Age'] = ageDF[ageDF['Salutation'] == sal]['Age'].fillna(dict_sal[sal])\n\n    ageDF.describe()\n\n    data_train['Age'] = ageDF['Age']\n    display(data_train.describe())\n    display(data_train.info())\n    dataTrain = data_train.drop(columns = ['PassengerId','SibSp','Name','Ticket','Cabin','Embarked'])\n    \n    from sklearn.preprocessing import LabelEncoder\n    encoder = LabelEncoder()\n    dataTrain['Sex'] = encoder.fit_transform(dataTrain['Sex'])\n    \n    return dataTrain","3a5b93f9":"dataTrain = transformer(data_train)\nlabels = dataTrain['Survived']\ndataTrain = dataTrain.drop(columns = ['Survived'])\ndisplay(dataTrain.info())","120f592b":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndataTrainScaled = scaler.fit_transform(dataTrain)\ndataTrainScaled = pd.DataFrame(dataTrainScaled)\ndisplay(dataTrainScaled.head())","ab0e140d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(dataTrainScaled, labels, test_size = 0.2)","de996bd2":"from sklearn.svm import SVC\nsvc = SVC(C = 10)\nsvc.fit(X_train, y_train)\npredictions_train = svc.predict(X_test)\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, confusion_matrix, roc_auc_score","795dd478":"def metricsPrint(predictions_train, y_test):\n    accuracyTrain = accuracy_score(y_test, predictions_train)\n    precisionTrain = precision_score(y_test, predictions_train)\n    recallTrain = recall_score(y_test, predictions_train)\n    print(\"Accuracy {} Precision {} Recall {}\".format(accuracyTrain,precisionTrain, recallTrain))","19c30c43":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier()\nforest.fit(X_train, y_train)\npredictions_train2 = forest.predict(X_test)","95491492":"metricsPrint(predictions_train, y_test)\nmetricsPrint(predictions_train2, y_test)","44c25336":"#from sklearn.model_selection import GridSearchCV\n#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-1,1e-2],\n                     #'C': [100, 500, 1000, 2000]},\n                    #{'kernel': ['linear'], 'C': [100, 500, 1000, 2000]}]\n#gcvSVM = GridSearchCV(svc, param_grid = tuned_parameters)\n#gcvSVM.fit(X_train, y_train)\n#params = gcvSVM.best_params_\n#print(params)","88188174":"svcT = SVC(C = 2000, gamma = 0.01, kernel = 'rbf')\nsvcT.fit(X_train, y_train)\npredNew = svcT.predict(X_test)\nmetricsPrint(y_test, predNew)","7156acc3":"#tuned_parameters2 = {'n_estimators': [10,100,500,1000], 'max_depth': [1,10,100,1000],\n                     #'min_samples_split': [2, 10, 100, 1000]}\n                   \n#gcvDT = GridSearchCV(forest, param_grid = tuned_parameters2)\n#gcvDT.fit(X_train, y_train)\n#print(gcvDT.best_params_)","9f75312a":"forestT = RandomForestClassifier(max_depth = 10, min_samples_split = 10, n_estimators = 100)\nforestT.fit(X_train, y_train)\npredNew2 = forestT.predict(X_test)\nmetricsPrint(y_test, predNew2)","0e45f346":"from numpy import array\ndata_test = pd.read_csv('..\/input\/test.csv')\ndata_testTransformed = transformer(data_test)\ndisplay(data_test.head())\ndata_testTransformed['Age'] = data_testTransformed['Age'].fillna((array(data_testTransformed.loc[data_testTransformed['Age'].isna() == False, 'Age'])).mean())\ndata_testTransformed['Fare'] = data_testTransformed['Fare'].fillna((array(data_testTransformed.loc[data_testTransformed['Fare'].isna() == False, 'Fare'])).mean())\ndisplay(data_testTransformed.info())","b9c196d9":"display(data_testTransformed.head())","56b77343":"dataTestScaled = scaler.fit_transform(data_testTransformed)\ndataTestScaled = pd.DataFrame(dataTestScaled)\npredictionsTest = forestT.predict(dataTestScaled)\npredictionsTest2 = svcT.predict(dataTestScaled)","341a5f7b":"results = pd.DataFrame(predictionsTest)\nresults2 = pd.DataFrame(predictionsTest2)\nresults['PassengerId'] = data_test['PassengerId']\nresults2['PassengerId'] = data_test['PassengerId']\nresults.columns = ['Survived','PassengerId']\nresults2.columns = ['Survived','PassengerId']\nresults = results[['PassengerId','Survived']]\nresults2 = results2[['PassengerId','Survived']]\nresults.to_csv('SUBMISSION11.CSV', index = False)\nresults2.to_csv('SUBMISSION22.CSV', index = False)","df003b9c":"def rocCurve(fpr,tpr,fpr2,tpr2):\n    plt.plot(fpr,tpr,'b-', label = 'svc')\n    plt.plot(fpr2,tpr2,'r-', label = 'tree')\n    plt.plot([0,1],[0,1], 'g--')\n    plt.legend(loc = 'best')\nfrom sklearn.model_selection import cross_val_predict\nconfidenceValues = cross_val_predict(svcT, X_test, y_test, cv = 3, method = 'decision_function')\nconfidenceValues2 = cross_val_predict(forestT, X_test, y_test, cv = 3, method = 'predict_proba')\n\nfpr, tpr, thresholds = roc_curve(y_test, confidenceValues)\nfpr2, tpr2, thresholds2 = roc_curve(y_test, confidenceValues2[:,1])\n\nrocCurve(fpr,tpr,fpr2,tpr2)\n\nrocScore1 = roc_auc_score(y_test, confidenceValues)\nrocScore2 = roc_auc_score(y_test, confidenceValues2[:,1])\nprint(\"ROC AUC Score for 1. SVC {}\\n2. TREE {}\".format(rocScore1,rocScore2))","6a007a4a":"conMat = confusion_matrix(y_test,predictions_train)\nimport seaborn as sn\ndf_cm = pd.DataFrame(conMat, index = [i for i in [0,1]],\n                  columns = [i for i in [0,1]])\nplt.figure(figsize = (12,7))\nsn.heatmap(df_cm, annot=True)","687c116c":"**Standard metrics to evaluate the results**","794843ab":"In the second plot we observe that women, irrespective of their age had more chance of survival than men. Only children in Male category seems to survive significantly.","6acc8a84":"***Hyperparameter tuning using GreadSearchCV to find best parameters*** (SVC)","259542ac":"**Visualising the relationship between Survival and few features such as Age, Gender and PassengerClass**\n\nIn first plot we notice that the first class passengers of any age had good chance to survive as compared to the third class passengers where only few younger people survived.","4f3e4644":"***Hyperparameter tuning using GreadSearchCV to find best parameters*** (Random Forest)","bf285a95":"**Scaling the data**\n\nWe use standard scaler to scale the data","26996ca3":"**ROC curve score (Area under curve)**","317df78b":"**Transforming the test just like training set**","eca1798a":"**Basic overview of data**\n\nNotice that some missing values specifically in Age, Cabin and Embarked are observed. We have some data that is in 'text' form and needs to be encoded numerically (most importantly the 'Sex' or Gender column that is binary).","56339014":"**Frequency distribution of the labels (Survived column)**\n\nWe see that we are not dealing with a skewed classes as there is an appreciable amount of data from both labels (0 and 1).","dfe779f8":"**TITANIC Dataset**\n\nObjective: To predict if a person survived the titanic disaster or not, provided information about him\/her.","33a738b0":"**Transforming the dataset, Dealing with Age feature having missing data**\n\nWe use regular expression to gather the salutation such as 'Mr.', 'Ms.', 'Mrs.' from the Name feature and group them. To predict the age, we don't take the mean of every non-NaN example but we look at the salutation and then we compute the mean age for each salutation and assign it to the respective NaN value.","150e8e69":"**Random Forest Classifier**","103e658f":"**Splitting the training and test set**","7b33a517":"**Support Vector Classifier**"}}