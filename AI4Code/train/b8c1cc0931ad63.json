{"cell_type":{"8aeb33b8":"code","aa2b4556":"code","6377bba6":"code","89f95cbe":"code","7f29a2b5":"code","7b1ebed4":"code","5d90c23a":"code","3987beb7":"code","bb2d92b0":"code","d731157c":"code","a0104c52":"code","547d6989":"code","32e78b93":"markdown","8750855a":"markdown","794a0e9d":"markdown","3fcae123":"markdown","8c5f984b":"markdown","a655cf22":"markdown","63fa3a7a":"markdown","1f3fb8d8":"markdown","eaad0a49":"markdown","bd0b71df":"markdown","bbccf1fb":"markdown","9d411d2a":"markdown","b1ff2f84":"markdown","0458a3fa":"markdown","79249456":"markdown"},"source":{"8aeb33b8":"import numpy as np \nimport pandas as pd\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\nfrom sklearn.svm import LinearSVC\nfrom sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVC\nimport json\n","aa2b4556":"train = pd.read_json('..\/input\/train.json')\ntest = pd.read_json('..\/input\/test.json')\nsub = pd.read_csv('..\/input\/sample_submission.csv')","6377bba6":"print('size of train data',train.shape)\nprint('size of test data',test.shape)","89f95cbe":"train.head()","7f29a2b5":"test.head()","7b1ebed4":"# checking missing data\ntotal = train.isnull().sum().sort_values(ascending = False)\npercent = (train.isnull().sum()\/train.isnull().count()*100).sort_values(ascending = False)\nmissing_train_data  = pd.concat([total, percent], axis=1, keys=['Total missing', 'Percent missing'])\nmissing_train_data.head(20)","5d90c23a":"# checking missing data\ntotal = test.isnull().sum().sort_values(ascending = False)\npercent = (test.isnull().sum()\/test.isnull().count()*100).sort_values(ascending = False)\nmissing_test_data  = pd.concat([total, percent], axis=1, keys=['Total missing', 'Percent missing'])\nmissing_test_data.head(20)","3987beb7":"temp = train['cuisine'].value_counts()\ntrace = go.Bar(\n    y=temp.index[::-1],\n    x=(temp \/ temp.sum() * 100)[::-1],\n    orientation = 'h',\n    marker=dict(\n        color='blue',\n    ),\n)\n\nlayout = go.Layout(\n    title = \"Top cuisine\",\n    xaxis=dict(\n        title='Recipe count',\n        tickfont=dict(size=14,)),\n    yaxis=dict(\n        title='Cuisine',\n        titlefont=dict(size=16),\n        tickfont=dict(\n            size=14)),\n    margin=dict(\n    l=200,\n),\n    \n)\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","bb2d92b0":"n=6714 # total ingredients in train data\ntop = Counter([item for sublist in train.ingredients for item in sublist]).most_common(n)\ntemp= pd.DataFrame(top)\ntemp.columns = ['ingredient','total_count']\ntemp = temp.head(20)\ntrace = go.Bar(\n    y=temp.ingredient[::-1],\n    x=temp.total_count[::-1],\n    orientation = 'h',\n    marker=dict(\n        color='green',\n    ),\n)\n\nlayout = go.Layout(\n    title = \"Top ingredients\",\n    xaxis=dict(\n        title='ingredient count',\n        tickfont=dict(size=14,)),\n    yaxis=dict(\n        title='ingredient',\n        titlefont=dict(size=16),\n        tickfont=dict(\n            size=14)),\n    margin=dict(\n    l=200,\n),\n    \n)\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","d731157c":"def read_dataset(path):\n\treturn json.load(open(path)) \ntrain = read_dataset('..\/input\/train.json')\ntest = read_dataset('..\/input\/test.json')\n\ndef generate_text(data):\n\ttext_data = [\" \".join(doc['ingredients']).lower() for doc in data]\n\treturn text_data \n\ntrain_text = generate_text(train)\ntest_text = generate_text(test)\ntarget = [doc['cuisine'] for doc in train]\n","a0104c52":"tfidf = TfidfVectorizer(binary=True)\ndef tfidf_features(txt, flag):\n    if flag == \"train\":\n    \tx = tfidf.fit_transform(txt)\n    else:\n\t    x = tfidf.transform(txt)\n    x = x.astype('float16')\n    return x \nX = tfidf_features(train_text, flag=\"train\")\nX_test = tfidf_features(test_text, flag=\"test\")","547d6989":"lb = LabelEncoder()\ny = lb.fit_transform(target)\n\n# Model Training \nclassifier = SVC(C=100, # penalty parameter\n\t \t\t\t kernel='rbf', # kernel type, rbf working fine here\n\t \t\t\t degree=3, # default value\n\t \t\t\t gamma=1, # kernel coefficient\n\t \t\t\t coef0=1, # change to 1 from default value of 0.0\n\t \t\t\t shrinking=True, # using shrinking heuristics\n\t \t\t\t tol=0.001, # stopping criterion tolerance \n\t      \t\t probability=False, # no need to enable probability estimates\n\t      \t\t cache_size=200, # 200 MB cache size\n\t      \t\t class_weight=None, # all classes are treated equally \n\t      \t\t verbose=False, # print the logs \n\t      \t\t max_iter=-1, # no limit, let it run\n          \t\t decision_function_shape=None, # will use one vs rest explicitly \n          \t\t random_state=None)\nmodel = OneVsRestClassifier(classifier, n_jobs=4)\nmodel.fit(X, y)\n\n# Predictions \ny_test = model.predict(X_test)\ny_pred = lb.inverse_transform(y_test)\n\n# Submission\ntest_id = [doc['id'] for doc in test]\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\nsub.to_csv('sub1.csv', index=False)","32e78b93":"**missing training data**","8750855a":"**missing test data**","794a0e9d":"# <a id='6'>6. Feature Engineering<\/a>","3fcae123":"![](http:\/\/clipground.com\/images\/when-cooking-clipart-20.jpg)","8c5f984b":"# <a id='2'>2. Glimpse of Data<\/a>","a655cf22":"# <a id='1'>1. Loading Packages and Data<\/a>","63fa3a7a":"**train data**","1f3fb8d8":"**test data**","eaad0a49":"## <a id='4-2'>4.2 Top ingredients<\/a>","bd0b71df":"## <a id='4-1'>4.1 Top cuisine<\/a>","bbccf1fb":"# <a id='6'>6. Modeling<\/a>","9d411d2a":"# <a id='3'> 3. Check for missing data<\/a>","b1ff2f84":"- <a href='#1'>1. Loading Packages and Data<\/a>\n- <a href='#2'>2. Glimpse of Data<\/a>\n- <a href='#3'> 3. Check for missing data<\/a>\n- <a href='#4'>4. Data Exploration<\/a>\n    - <a href='#4-1'>4.1 Top cuisine<\/a>\n    - <a href='#4-2'>4.2 Top ingredients<\/a>\n- <a href='#5'>5. Pre-processing<\/a>\n- <a href='#6'>6. Feature Engineering<\/a>\n- <a href='#7'>7. Modeling<\/a>\n\n\nWork inspired looking at: \nhttps:\/\/www.kaggle.com\/codename007\/cooking-cooking-cooking and \nhttps:\/\/www.kaggle.com\/shivamb\/tf-idf-with-ovr-svm-what-s-cooking","0458a3fa":"# <a id='5'>5. Pre-processing<\/a>","79249456":"# <a id='4'>4. Data Exploration<\/a>"}}