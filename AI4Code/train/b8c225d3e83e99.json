{"cell_type":{"cb29564d":"code","63227a8d":"code","adecf225":"code","272b5d4c":"code","0edf91df":"code","863acbb6":"code","9cd14a17":"code","791cf2df":"code","d2a0b1f6":"code","7e674353":"code","e88754ab":"code","738cd74a":"code","b7f13865":"code","7cfc939b":"code","1cf35fc0":"code","22a39c67":"code","9a70ac88":"code","31086164":"code","60be07ba":"code","51f02632":"code","b2e9716f":"code","ef1ce2ee":"code","45a9ab76":"code","ee6fdfd7":"code","14608dbd":"code","5fb6a40e":"code","ef310f7e":"code","0588236b":"code","97555fe9":"code","dabb2766":"code","3d8e645c":"code","47e4d596":"code","fcf717b6":"code","49896e5d":"code","34ed6a01":"code","c428d0ff":"code","bf58e971":"code","0f3b9edb":"code","113f7418":"code","4d121dd3":"code","10dc1f08":"code","1d72be68":"code","10c4b96d":"code","018e116e":"code","11c7bf25":"code","a4becff1":"code","cbe3d52f":"code","1b94e63b":"code","d8d4740f":"code","b192563f":"code","8d5d355d":"markdown","2af1f473":"markdown","ef434133":"markdown","3f392eb3":"markdown","af5550d0":"markdown","084563e4":"markdown","c4e1c296":"markdown","53cd4375":"markdown","2b1ef9d7":"markdown","07bbacda":"markdown","3ef39131":"markdown","ead6536e":"markdown","673dc5df":"markdown","59669a4c":"markdown"},"source":{"cb29564d":"# Data Import\nimport pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv', engine='python')\ntest = pd.read_csv('..\/input\/titanic\/test.csv', engine='python')\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv', engine='python')","63227a8d":"print(np.shape(train), np.shape(test))","adecf225":"train.head()","272b5d4c":"test.head()","0edf91df":"submission.head()","863acbb6":"train.info()","9cd14a17":"# drop name, ticket,  column - seems to have no impact on whether he\/she is survived or not\n\ntrain.drop(['Name', 'Ticket'], axis=1, inplace=True)\ntest.drop(['Name', 'Ticket'], axis=1, inplace=True)","791cf2df":"# Check missing values\ntrain.isnull().sum()","d2a0b1f6":"test.isnull().sum()","7e674353":"# Embarked column \uc0b4\ud3b4\ubcf4\uae30\ntrain['Embarked'].unique()","e88754ab":"# since there are only two null rows, for embarked variable, drop them.\n\n## Manual\n# null_emb_idx = train.isnull()[train.isnull()['Embarked'] == True].index\n# train.drop(null_emb_idx, axis=0, inplace=True)\n# train.isnull().sum()\n\n# Use Pd method\ntrain.dropna(subset=['Embarked'], inplace=True)\ntrain.isnull().sum()","738cd74a":"# check Cabin column\nprint(train['Cabin'].unique())\nprint(test['Cabin'].unique())","b7f13865":"# Cabin(\uc120\uc2e4)\uc758 \uacbd\uc6b0 \uc5ec\ub7ec \uc120\uc2e4 \ubc88\ud638\uac00 \ud568\uaed8 \uc788\ub294 \uac12\uc740 \uc11c\ub85c \uac19\uc740 \uc120\uc2e4\ub07c\ub9ac \ubb36\uc5ec\uc788\uc73c\ubbc0\ub85c, \uccab \ubc88\uc9f8 element\uc758 \uccab \ubc88\uc9f8 \uae00\uc790\ub9cc \ucde8\ud55c \ub2e4\uc74c\n# Label Encoding\ud574\uc900\ub2e4 - Nan\uc740 X\ub85c \ucc98\ub9ac\nfrom sklearn.preprocessing import LabelEncoder\n\ndef separate(x):\n    try:\n        x = x.split(' ')[0]\n        first = x[0]\n        return first\n    except:\n        return 'X'\n\ncabin_tr = train['Cabin'].copy()\ncabin_tr_rep = cabin_tr.map(separate)\n\ncabin_te = test['Cabin'].copy()\ncabin_te_rep = cabin_te.map(separate)\n\nle = LabelEncoder()\n# preprocessing should only be fitted on the training data\nle.fit(cabin_tr_rep)\n# then transform both the training set and the test set\nle_cabin_train = le.transform(cabin_tr_rep)\nle_cabin_test = le.transform(cabin_te_rep)\n\ntrain['Cabin'] = le_cabin_train\ntest['Cabin'] = le_cabin_test","7cfc939b":"# import matplotlib.pyplot as plt\n# plt.hist(train['Age'], bins=40)","1cf35fc0":"# \ub9c8\uc9c0\ub9c9\uc73c\ub85c Age, Fare\uc758 \uacb0\uce21\uce58\ub294 \ud3c9\uade0\uac12\uc73c\ub85c \ub300\uccb4\ud55c\ub2e4\ntrain_age_mean = np.mean(train['Age'])\ntest_age_mean = np.mean(test['Age'])\n\ntrain['Age'].fillna(train_age_mean, inplace=True)\ntest['Age'].fillna(test_age_mean, inplace=True)\n\ntrain_fare_mean = np.mean(train['Fare'])\ntest_fare_mean = np.mean(test['Fare'])\n\ntrain['Fare'].fillna(train_fare_mean, inplace=True)\ntest['Fare'].fillna(test_fare_mean, inplace=True)","22a39c67":"train.isnull().sum()","9a70ac88":"test.isnull().sum()","31086164":"# Gender Encoding\ntrain_sex = train['Sex'].copy()\ntest_sex = test['Sex'].copy()\n\nle_sex = LabelEncoder()\nle_sex.fit(train_sex)\ntrain_sex_encoded = le_sex.transform(train_sex)\ntest_sex_encoded = le_sex.transform(test_sex)\n\ntrain['Sex'] = train_sex_encoded\ntest['Sex'] = test_sex_encoded","60be07ba":"# Embarked Encoding\ntrain_emb = train['Embarked'].copy()\ntest_emb = test['Embarked'].copy()\n\nle_emb = LabelEncoder()\nle_emb.fit(train_emb)\ntrain_emb_encoded = le_emb.transform(train_emb)\ntest_emb_encoded = le_emb.transform(test_emb)\n\ntrain['Embarked'] = train_emb_encoded\ntest['Embarked'] = test_emb_encoded","51f02632":"train_des = train.copy()\ntrain_des.describe()","b2e9716f":"# correlation matrix\ntrain.corr()","ef1ce2ee":"# float \ucc98\ub9ac\ub41c Age, Fare\uc5d0 \ub300\ud574\uc11c \ub85c\uadf8 \uc2a4\ucf00\uc77c \ubcc0\ud658\ntrain['Age'] = np.log1p(train['Age'])\ntest['Age'] = np.log1p(test['Age'])\n\ntrain['Fare'] = np.log1p(train['Fare'])\ntest['Fare'] = np.log1p(test['Fare'])","45a9ab76":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier","ee6fdfd7":"# print(help(XGBClassifier))","14608dbd":"# \uc0ac\uc6a9\ud560 \ubaa8\ub378\ub4e4\nlr = LogisticRegression()\ndtree = DecisionTreeClassifier()\nrf = RandomForestClassifier()\nada = AdaBoostClassifier()\nknn = KNeighborsClassifier()\nxgb = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)","5fb6a40e":"# X, y \ubd84\ub9ac\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import roc_auc_score, f1_score, make_scorer\n\nX_train = train.drop(['PassengerId', 'Survived'], axis=1)\ny_train = train[['PassengerId', 'Survived']]\ny = y_train['Survived']\n\nX_test = test.drop(['PassengerId'], axis=1)\n\n# training - validation \ubd84\ub9ac\ntrain_x, val_x, train_y, val_y = train_test_split(X_train, y, test_size=0.3, shuffle=True, random_state=42)\n\n# model list\nmodels = [lr, dtree, rf, ada, knn, xgb]","ef310f7e":"# time conversion function - Training time \ubcf4\uae30\uc88b\uac8c \ub9cc\ub4e4\uae30 \uc704\ud568\nfrom datetime import datetime\n\ndef delta2str(delta):\n    year = delta.days \/\/ 365\n    month = (delta.days % 365) \/\/ 30\n    days = (delta.days % 365) % 30\n    \n    hour = (delta.seconds \/\/ 3600)\n    mins = (delta.seconds % 3600) \/\/ 60\n    sec = (delta.seconds % 3600) % 60\n    msec = float('0.' + str(delta.microseconds))\n    \n    if days > 0:\n        msg = '{0} year(s) {1} month(s) {2} day(s) {3} hour(s) {4} minute(s) {5} seconds'.format(year, month, days, hour, mins, (sec + msec))\n    else:\n        msg = '{0} hour(s) {1} minute(s) {2} seconds'.format(hour, mins, (sec + msec))\n    \n    return msg","0588236b":"# # hold-out validation\n\n# for m in models:\n#     name = m.__class__.__name__\n#     start = datetime.now()\n#     clf = m.fit(train_x, train_y)\n#     end = datetime.now()\n#     pred_y = clf.predict(val_x)\n#     pred_proba_y = clf.predict_proba(val_x)[:, 1]\n    \n#     f1 = f1_score(val_y, pred_y)\n#     auc = roc_auc_score(val_y, pred_proba_y)\n#     time = end - start\n    \n#     print('Model {0} - F1 score: {1}, AUC: {2}, Training time: {3}'.format(name, f1, auc, delta2str(time)))","97555fe9":"# help(cross_val_score)","dabb2766":"# make custom scorer - cross_val_score\uc5d0\uc11c\ub294 custom scorer \uc0ac\uc6a9\ud560 \uc218 \uc788\uace0, \ub300\uccb4\ub85c true, predict \uac12\uc744 \ubc1b\ub294 \ud568\uc218\ub85c \uad6c\uc131\ndef val_score(y_true, y_pred):\n    return f1_score(y_true, y_pred)\n\n# \uc815\uc758\ud55c custom scorer\ub97c \uc2e4\uc81c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \ud615\ud0dc\ub85c \ubc14\uafd4\uc8fc\ub294 \ud568\uc218\ncustom_score = make_scorer(val_score, greater_is_better=True)\n\n# cross-validation\uc73c\ub85c \ubaa8\ub378 \ud3c9\uac00\nfor m in models:\n    name = m.__class__.__name__\n    start = datetime.now()\n    auc_cv = cross_val_score(m, train_x, train_y, cv=5, scoring=custom_score)\n    accuracy = cross_val_score(m, train_x, train_y, cv=5, scoring='accuracy')\n    end = datetime.now()\n    time = end - start\n    print('Model {0} - F1: {1}, Accuracy: {2}, Training time: {3}'.format(name, np.mean(auc_cv), np.mean(accuracy), delta2str(time)))","3d8e645c":"# help(GridSearchCV)","47e4d596":"# \uc5ec\uae30\uc11c\ub294 cross-validation\uc5d0 \ub530\ub77c\uc11c RandomForest\uc5d0 \ub300\ud574\uc11c GridSearch \uc9c4\ud589\nparams = {\n    'n_estimators': [10, 20, 50, 100],\n    'min_samples_split': [2, 3, 4],\n    'random_state': [42],\n    'criterion': ['gini', 'entropy']\n}\n\nrf_search = RandomForestClassifier()\n\nsearch = GridSearchCV(rf_search, param_grid=params, cv=5,\n                      scoring=custom_score, n_jobs=-1)\n\nstart = datetime.now()\nsearch.fit(train_x, train_y)\nend = datetime.now()\n\nprint('Best params: {0}, Best F1 score: {1}, Search time: {2}'.format(search.best_params_, \n                                                                        search.best_score_,\n                                                                       delta2str(end - start)))","fcf717b6":"# Fitting and Prediction\nbest_model = RandomForestClassifier(**search.best_params_)\nbest_model.fit(X_train, y)\ny_pred = best_model.predict(X_test)\n\n# submit\nsubmission['y_pred'] = y_pred","49896e5d":"submission","34ed6a01":"accuracy = submission['Survived'] == submission['y_pred']\nprint('accuracy on the test data: {}'.format(np.sum(accuracy) \/ len(accuracy)))","c428d0ff":"# # \uc2dc\ud5d8\ud658\uacbd \uc138\ud305 (\ucf54\ub4dc \ubcc0\uacbd X)\n# import pandas as pd\n# df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n\n# from sklearn.model_selection import train_test_split\n# X_train, X_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=2021)\n# y_train = X_train[['PassengerId', 'Survived']]\n# X_train = X_train.drop(columns=['PassengerId', 'Survived'])\n# y_test = X_test[['PassengerId', 'Survived']]\n# X_test = X_test.drop(columns=['PassengerId', 'Survived'])\n\n# X_train.shape, y_train.shape, X_test.shape, y_test.shape","bf58e971":"# # \ub77c\uc774\ube0c\ub7ec\ub9ac \ubd88\ub7ec\uc624\uae30\n# import pandas as pd","0f3b9edb":"# # \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30 (\uc0dd\ub7b5)\n# X_train.shape, y_train.shape, X_test.shape","113f7418":"# X_train.head()","4d121dd3":"# float64(2), int64(3), object(5)\n# X_train.info()","10dc1f08":"# y_train.head()","1d72be68":"# \uc0dd\uc874 \ube44\uc728\n# y_train['Survived'].value_counts()","10c4b96d":"# y = y_train[\"Survived\"]\n\n# # sex\ub9cc \uc6d0\ud56b\uc778\ucf54\ub529 \ub428\n# features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n# X_train = pd.get_dummies(X_train[features])\n# X_test = pd.get_dummies(X_test[features])","018e116e":"# X_train.shape, X_test.shape","11c7bf25":"# X_train.head()","a4becff1":"# from sklearn.ensemble import RandomForestClassifier\n# model = RandomForestClassifier(n_estimators=200, max_depth=7, random_state=2021)\n# model.fit(X_train, y)\n# predictions = model.predict(X_test)","cbe3d52f":"# model.score(X_train, y)","1b94e63b":"# output = pd.DataFrame({'PassengerId': y_test.PassengerId, 'Survived': predictions})\n# output.head()","d8d4740f":"# # \uc218\ud5d8\ubc88\ud638.csv\ub85c \ucd9c\ub825\n# output.to_csv('1234567.csv', index=False)","b192563f":"# model.score(X_test, y_test['Survived'])","8d5d355d":"## \uc0dd\uc874\uc5ec\ubd80 \uc608\uce21\ubaa8\ub378 \ub9cc\ub4e4\uae30\n### \ud559\uc2b5\uc6a9 \ub370\uc774\ud130 (X_train, y_train)\uc744 \uc774\uc6a9\ud558\uc5ec \uc0dd\uc874 \uc608\uce21 \ubaa8\ud615\uc744 \ub9cc\ub4e0 \ud6c4, \uc774\ub97c \ud3c9\uac00\uc6a9 \ub370\uc774\ud130(X_test)\uc5d0 \uc801\uc6a9\ud558\uc5ec \uc5bb\uc740 \uc608\uce21\uac12\uc744 \ub2e4\uc74c\uacfc \uac19\uc740 \ud615\uc2dd\uc758 CSV\ud30c\uc77c\ub85c \uc0dd\uc131\ud558\uc2dc\uc624(\uc81c\ucd9c\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 accuracy \ud3c9\uac00\uc9c0\ud45c\uc5d0 \ub530\ub77c \ucc44\uc810)\n\n(\uac00) \uc81c\uacf5 \ub370\uc774\ud130 \ubaa9\ub85d\n- y_train: \uc0dd\uc874\uc5ec\ubd80(\ud559\uc2b5\uc6a9)\n- X_trian, X_test : \uc2b9\uac1d \uc815\ubcf4 (\ud559\uc2b5\uc6a9 \ubc0f \ud3c9\uac00\uc6a9)\n\n(\ub098) \ub370\uc774\ud130 \ud615\uc2dd \ubc0f \ub0b4\uc6a9\n- y_trian (712\uba85 \ub370\uc774\ud130)\n\n**\uc2dc\ud5d8\ud658\uacbd \uc138\ud305\uc740 \uc608\uc2dc\ubb38\uc81c\uc640 \ub3d9\uc77c\ud55c \ud615\ud0dc\uc758 X_train, y_train, X_test \ub370\uc774\ud130\ub97c \ub9cc\ub4e4\uae30 \uc704\ud568\uc784**\n\n### \uc720\uc758\uc0ac\ud56d\n- \uc131\ub2a5\uc774 \uc6b0\uc218\ud55c \uc608\uce21\ubaa8\ud615\uc744 \uad6c\ucd95\ud558\uae30 \uc704\ud574\uc11c\ub294 \uc801\uc808\ud55c \ub370\uc774\ud130 \uc804\ucc98\ub9ac, \ud53c\ucc98\uc5d4\uc9c0\ub2c8\uc5b4\ub9c1, \ubd84\ub958\uc54c\uace0\ub9ac\uc998, \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd, \ubaa8\ud615 \uc559\uc0c1\ube14 \ub4f1\uc774 \uc218\ubc18\ub418\uc5b4\uc57c \ud55c\ub2e4.\n- \uc218\ud5d8\ubc88\ud638.csv\ud30c\uc77c\uc774 \ub9cc\ub4e4\uc5b4\uc9c0\ub3c4\ub85d \ucf54\ub4dc\ub97c \uc81c\ucd9c\ud55c\ub2e4.\n- \uc81c\ucd9c\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 accuracy\ub85c \ud3c9\uac00\ud568\n\ncsv \ucd9c\ub825\ud615\ud0dc\n\n![image.png](attachment:de1920de-121e-47c3-a61f-e905386713bf.png)","2af1f473":"## \ub370\uc774\ud130 \uc804\ucc98\ub9ac","ef434133":"## Missing Value \ucc98\ub9ac","3f392eb3":"## Correlation, Scaling and Encoding","af5550d0":"## EDA","084563e4":"## \ub77c\uc774\ube0c\ub7ec\ub9ac \ubc0f \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30","c4e1c296":"# Final Prediction on Test Data","53cd4375":"## Start","2b1ef9d7":"## \ubaa8\ub378 \ubc0f \ud3c9\uac00","07bbacda":"# Hyper-parameter Tuning","3ef39131":"# Data Import","ead6536e":"# Model Selection","673dc5df":"# EDA","59669a4c":"## \uacb0\uacfc \uccb4\uc810 (\uc218\ud5d8\uc790\ub294 \uc54c \uc218 \uc5c6\ub294 \ubd80\ubd84\uc784)"}}