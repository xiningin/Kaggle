{"cell_type":{"6a0591dc":"code","7f5ca583":"code","8890119d":"code","667fc64e":"code","f142c827":"code","663d9ecd":"code","989050e8":"code","cd36a21f":"code","b68686ff":"code","b18a0a33":"code","354b1cd0":"code","8046d26f":"code","1c921064":"code","1483233a":"code","c6c1c84b":"code","b4a92609":"code","58e84ff5":"code","c7e11efc":"code","888f75d1":"code","6b36ed71":"code","c468123b":"code","fc30692c":"code","f6b20989":"code","d4e47a84":"code","d6baf6dc":"code","85ceaec6":"code","88a06b88":"code","fc648580":"code","01f1c5fa":"code","87534caa":"code","7e73b127":"code","41c4d167":"markdown","f3559986":"markdown","d826f26a":"markdown"},"source":{"6a0591dc":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","7f5ca583":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D ,LSTM ,RepeatVector,TimeDistributed\n","8890119d":"df=pd.read_csv('..\/input\/dataset-combined\/file.csv')\ndf.head(5)","667fc64e":"df.isna().sum()\n","f142c827":"print(\"Type:\\n\",type(df))\nprint(\"Information about the dataframe:\\n\",df.info)\nprint(\"Shape of the dataframe :\\n\",df.shape)\ndf.drop_duplicates()\nprint(df.shape)\nprint(\"Columns of the dataframe:\\n\",df.columns)","663d9ecd":"df.dtypes","989050e8":"num_cols = df._get_numeric_data().columns\n\ncate_cols = list(set(df.columns)-set(num_cols))\n\ncate_cols","cd36a21f":"df.drop(['Flow ID', 'Src IP' ,'Dst IP' ,'Timestamp','Src Port','Dst Port','Protocol'], inplace=True,axis = 1)\ndf.shape\n","b68686ff":"\ndf = df.dropna('columns')# drop columns with NaN\n\ndf = df[[col for col in df if df[col].nunique() > 1]]# keep columns where there are more than 1 unique values\n\ncorr = df.corr()\n\nplt.figure(figsize=(15,12))\n\nsns.heatmap(corr)\n\nplt.show()","b18a0a33":"print(\"Shape after removal of socket information and columns having unique value <=1 :\\n\",df.shape)\ndf.columns","354b1cd0":"df['Label'].value_counts()","8046d26f":"#Encoding categorical data i.e Label\npmap = {'Normal':0,'Probe ':1,'DDoS':1,'DoS':1,'BFA':1,'Web-Attack':1,'BOTNET':1,'U2R':1,'DDoS':1}\ndf['Label'] = df['Label'].map(pmap)\n","1c921064":"# one_hot_encoded_data = pd.get_dummies(df, columns = ['Label'])\n# print(one_hot_encoded_data)","1483233a":"df['Label'].value_counts()","c6c1c84b":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix, accuracy_score","b4a92609":"min_col = {}\nmax_col = {}\nbalance = {}\nfor col in df:\n    max_col[col]= df[col].max()\n    min_col[col]= df[col].min()\n    plt.hist(df[col])\n    plt.show()\n    balance[col]= max_col[col] + min_col[col]\n\nresult = pd.DataFrame([min_col, max_col, balance], index=['min', 'max', 'balance'])\nprint(result)    ","58e84ff5":"# Target variable and train set\nY = df[['Label']]\nX = df.drop(['Label',], axis=1)\n\nsc = MinMaxScaler(feature_range = (0, 1))\nX = sc.fit_transform(X)\n","c7e11efc":"print(X)\nprint(Y)","888f75d1":"# find the proportion of outliers we expect (aka where `attack == -1`). because \n# target is a series, we just compare against itself rather than a column.\n# target=df['Label']\n# outliers = target[target == 1]  \n# print(\"outliers.shape\", outliers.shape)  \n# print(\"outlier fraction\", outliers.shape[0]\/target.shape[0])","6b36ed71":"# drop label columns from the dataframe. we're doing this so we can do \n# unsupervised training with unlabelled data. we've already copied the label\n# out into the target series so we can compare against it later.\n# df.drop(['Label'], axis=1, inplace=True)","c468123b":"# from sklearn.model_selection import train_test_split  \n# train_data, test_data, train_target, test_target = train_test_split(df, target, train_size = 0.8)  \n# train_data.shape  ","fc30692c":"# from sklearn import svm\n\n# # set nu (which should be the proportion of outliers in our dataset)\n# nu = outliers.shape[0] \/ target.shape[0]  \n# print(\"nu\", nu)\n","f6b20989":"\n# model = svm.OneClassSVM(nu=nu, kernel='rbf', gamma=0.00005)  \n# model.fit(train_data) \n\n","d4e47a84":"# from sklearn import metrics  \n# preds = model.predict(train_data)  \n# targs = train_target\n\n# print(\"accuracy: \", metrics.accuracy_score(targs, preds))  \n# print(\"precision: \", metrics.precision_score(targs, preds))  \n# print(\"recall: \", metrics.recall_score(targs, preds))  \n# print(\"f1: \", metrics.f1_score(targs, preds))  \n# print(\"area under curve (auc): \", metrics.roc_auc_score(targs, preds))\n\n","d6baf6dc":"# preds = model.predict(test_data)  \n# targs = test_target\n\n# print(\"accuracy: \", metrics.accuracy_score(targs, preds))  \n# print(\"precision: \", metrics.precision_score(targs, preds))  \n# print(\"recall: \", metrics.recall_score(targs, preds))  \n# print(\"f1: \", metrics.f1_score(targs, preds))  \n# print(\"area under curve (auc): \", metrics.roc_auc_score(targs, preds)) ","85ceaec6":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\nprint(X_train.shape, X_test.shape)\nprint(Y_train.shape, Y_test.shape)","88a06b88":"X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\nprint(\"Training data shape:\", X_train.shape)\nX_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\nprint(\"Test data shape:\", X_test.shape)","fc648580":"# def autoencoder_model(X):\n#     inputs = Input(shape=(X.shape[1], X.shape[2]))\n#     L1 = LSTM(16, activation='relu', return_sequences=True, \n#               kernel_regularizer=regularizers.l2(0.00))(inputs)\n#     L2 = LSTM(4, activation='relu', return_sequences=False)(L1)\n#     L3 = RepeatVector(X.shape[1])(L2)\n#     L4 = LSTM(4, activation='relu', return_sequences=True)(L3)\n#     L5 = LSTM(16, activation='relu', return_sequences=True)(L4)\n#     output = TimeDistributed(Dense(X.shape[2]))(L5)    \n#     model = Model(inputs=inputs, outputs=output)\n#     return model","01f1c5fa":"model = Sequential()\nmodel.add(LSTM(128, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\nmodel.add(LSTM(64, activation='tanh', return_sequences=True))\nmodel.add(LSTM(32,activation='tanh', return_sequences=True))\nmodel.add(LSTM(16,activation='tanh', return_sequences=False))\nmodel.add(RepeatVector(X_train.shape[1]))\nmodel.add(LSTM(16, activation='tanh', return_sequences=True))\nmodel.add(LSTM(32, activation='tanh', return_sequences=True))\nmodel.add(LSTM(64, activation='tanh', return_sequences=True))\nmodel.add(LSTM(128, activation='tanh', return_sequences=True))\nmodel.add(TimeDistributed(Dense(X_train.shape[2])))\nmodel.compile(optimizer='adam', loss='mse')\nmodel.summary()","87534caa":"#nb_epochs = 100\nnb_epochs=35\nbatch_size = 32\nhistory = model.fit(X_train, X_train, epochs=nb_epochs, batch_size=batch_size,\n                    validation_split=0.05).history","7e73b127":"fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\nax.plot(history['loss'], 'b', label='Train', linewidth=2)\nax.plot(history['val_loss'], 'r', label='Validation', linewidth=2)\nax.set_title('Model loss', fontsize=16)\nax.set_ylabel('Loss (mae)')\nax.set_xlabel('Epoch')\nax.legend(loc='upper right')\nplt.show()","41c4d167":"#  One-Class SVM","f3559986":"# Importing dataset and analysing its structure","d826f26a":"# Class Imbalance"}}