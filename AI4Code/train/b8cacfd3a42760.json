{"cell_type":{"839c8db0":"code","447d06ce":"code","40bab6cd":"code","9e2fa459":"code","63483bac":"code","4593447b":"code","f2166ffa":"code","05b73b2a":"code","995255ff":"code","83740ad1":"code","a22b1a41":"code","87c3e5df":"code","5558b83e":"code","c358c3d3":"code","50f44eb0":"code","26cc1bc9":"code","10ba38e9":"code","b1a3e1fa":"code","5b607864":"code","ee2bab84":"code","3143873f":"code","43fbe5be":"code","1ee23506":"code","0a0caa3f":"code","f3a69a3a":"code","b1a8f38b":"code","9558c45c":"code","34b47a57":"code","37526408":"code","1c496279":"code","d0ddb9ec":"code","7444bc7b":"code","37e95a75":"code","3a3ba122":"code","4c48c1d3":"code","6533a876":"code","84d978f9":"code","ce415fc0":"code","6ef33b1c":"code","7e46c346":"code","85915e30":"code","221373f4":"code","2e029c20":"code","12c8825f":"code","6c05a5a8":"code","d3a42620":"code","d63b5f36":"code","3d6bfc55":"code","ca538fce":"code","e39fce72":"code","c0575d78":"code","135a1fd6":"code","0a19c8f9":"code","60ddbe9f":"code","65d84f55":"code","5a533d2c":"code","cdb9489d":"code","32032bf1":"code","2e1e0138":"code","45eb7dc3":"code","09e81df3":"code","75c1e618":"code","acb2a683":"code","c4c8f7a8":"code","ffe9cbd1":"code","fc66fea5":"code","40fd81d3":"code","994eee0a":"code","c1f8e07d":"code","a55a0dae":"code","1fdff523":"code","487948a6":"code","b58508f8":"markdown","26342bbd":"markdown","3e63f5f5":"markdown","9e5a1cf8":"markdown","e8c90e26":"markdown","174e21c3":"markdown","2c7e42c7":"markdown","69d3b843":"markdown","0c272400":"markdown","1fb0fed4":"markdown","3e303964":"markdown","4ee6177e":"markdown","e05d63da":"markdown","75d9c53a":"markdown","60905a83":"markdown","539d8c00":"markdown","eb49354a":"markdown","d386de7f":"markdown","5b9cdb54":"markdown","59d21770":"markdown","740d85d8":"markdown","8b93605b":"markdown","dfc73160":"markdown","75828161":"markdown","282b74e4":"markdown","95390db7":"markdown","de8e3250":"markdown","def77b49":"markdown","fc00f1ec":"markdown","fd953566":"markdown","8d28c580":"markdown","fc362646":"markdown","f510ea0d":"markdown","177b0639":"markdown","e366b454":"markdown","82019ef1":"markdown","f7e59e24":"markdown","171f4114":"markdown","cbb31cc0":"markdown","935473d2":"markdown","eb131c51":"markdown","a63310aa":"markdown","196a6956":"markdown","095fb8cb":"markdown","83238dd4":"markdown","8fe0fd1a":"markdown","35c1367e":"markdown","e3982ea8":"markdown","62cb5684":"markdown","09a3d4d3":"markdown","312ea1bd":"markdown","5cde098f":"markdown","c8dc0128":"markdown","3db3b9b0":"markdown","5ca4b321":"markdown","6baa752c":"markdown","78501d24":"markdown","3e413211":"markdown","f9aa0371":"markdown","7bb5aaad":"markdown","e743a7ef":"markdown","76f16dad":"markdown","61f18e86":"markdown","879d9c2e":"markdown","03d01fb5":"markdown","c4d6e218":"markdown","6dd15307":"markdown","5b769e5b":"markdown"},"source":{"839c8db0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2, venn3\nfrom matplotlib import gridspec\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom plotly import tools\npy.init_notebook_mode(connected=True)\nfrom wordcloud import WordCloud, STOPWORDS\n\nimport warnings\nwarnings.filterwarnings('ignore')\n#plt.style.use('fivethirtyeight') #fivethirtyeight\nplt.rcParams.update({'font.size':12,\n                    'xtick.labelsize':14,\n                    'ytick.labelsize':14})","447d06ce":"path = '..\/input\/'\n#path = 'dataset\/'\ndf_2018 = pd.read_csv(path+ 'multipleChoiceResponses.csv',) #header=[0,1])\nresponse = pd.read_csv(path + 'freeFormResponses.csv',) #header=[0,1])\nschema = pd.read_csv(path+ 'SurveySchema.csv')\nprint('Number of rows and columns in multipleChoiceResponses 2018 dataset:', df_2018.shape)\nprint('Number of rows and columns in freeFormResponses  dataset:', response.shape)\nprint('Number of rows and columns in schema dataset:', schema.shape)\ndf = df_2018[1:]","40bab6cd":"df.head()","9e2fa459":"def Horizontal_bar_plot(df, column, name='',title='', limit=None , colorscale = 'Picnic',width = 900, height = 500):\n    tmp = df[column].value_counts()[:limit]\n    #tmp = tmp.sort_values()\n    tmp_per = round(tmp * 100\/ tmp.sum() , 2)\n    tmp_per = [str(v)+' %' for v in tmp_per]\n    # Plot\n    trace1 = go.Bar(y = tmp.values, x = tmp.index, name=name,orientation='v',\n        marker=dict(color=tmp.values, colorscale = colorscale, line=dict(color='rgb( 127, 140, 141)',width=2),),\n        text = tmp_per, textposition='outside',\n    )\n    #Layout\n    layout = dict(\n        title=title,\n        width = width,height = height,\n        yaxis=dict(automargin=True,),\n        paper_bgcolor='rgb(251, 252, 252)',\n        plot_bgcolor='rgb(251, 252, 252)'\n    )\n    fig = {'data':[trace1], 'layout':layout}\n    py.iplot(fig)","63483bac":"def Horitontal_Multi_Barplot(df, column, column_filter,title ='', height = 600, width = 850,\n                             name = ['Student','Data Scientist','Data Analyst'],limit = None,):\n    \"\"\" Bar plot\"\"\"\n    colors = ['rgb (240,128,128)','rgb(0,255,255)','rgb(186,85,211)','rgb(210,105,30)','rgb(0,0,205)',\n              'rgb(124,252,0)','rgb(255,99,71)',]\n    # Layout\n    fig = tools.make_subplots(rows= len(name), cols=1, #subplot_titles= tuple(name),\n                              vertical_spacing = 0.05, horizontal_spacing = 0.05,\n                              print_grid= False,shared_xaxes = True)\n    \n    fig['layout'].update(dict( \n        showlegend =False,\n        height = height,\n        width = width,\n        title = title,\n        paper_bgcolor='rgb(251, 252, 252)',\n        plot_bgcolor='rgb(250, 250, 255)'))\n\n    # Multi Plot\n    for i, c in enumerate(name):\n        #tmp = df[column].value_counts()[:limit]\n        tmp = df[df[column_filter] == c][column].value_counts()[:limit]\n        tmp_per = round(tmp * 100\/ tmp.sum() , 2)\n        tmp_per = [str(v)+' %' for v in tmp_per]\n        \n        # Plot\n        trace1 = go.Bar(y = tmp.values, x = tmp.index, name= c,orientation='v',\n            marker=dict(color = colors[i],line=dict(color='rgb( 127, 140, 141)',width=2),),\n            text = tmp_per, textposition='auto', textfont = dict(size =13,family = 'Droid')\n        )\n        \n        fig.append_trace(trace1, i+1,1)\n        fig.layout[f'yaxis{i+1}'].update(title = c)\n\n    # Final plot\n    py.iplot(fig)","4593447b":"# 4 Pie plot\ndef Pie_plot_agg(filter_column = '',column = '',name = [], title = '', width = 1000, height= 600):\n    \n    \"\"\"Draw four pie plot of\n    filter_column is to filter out the perticual category mentioned in name variable\n    column: This target column upon which pie plot is drwan\n    name: Four different category of filter_column\n    \"\"\"\n    # trace1\n    tmp = (df[df[filter_column] == name[0]][column])\n    tmp = tmp.value_counts(ascending = True)\n    trace1 = go.Pie(labels= tmp.index, values= tmp.values, hoverinfo='label+percent+name', \n                    name = name[0],hole= .5, domain= dict(x = [0, 0.46], y = [0.54, 1]))\n    \n    # trace2\n    tmp = (df[df[filter_column] == name[1]][column])\n    tmp = tmp.value_counts(ascending = True)\n    trace2= go.Pie(labels= tmp.index, values= tmp.values, hoverinfo='label+percent+name', \n                    name = name[1],hole= .5, domain= dict(x = [0.54,1],y = [0.54, 1]))\n    #trace3\n    tmp = (df[df[filter_column] == name[2]][column])\n    tmp = tmp.value_counts(ascending = True)\n    trace3 = go.Pie(labels= tmp.index, values= tmp.values, hoverinfo='label+percent+name', \n                    name = name[2],hole= .5, domain= dict(x = [0, 0.46],y = [0, 0.46]))\n    #trace4\n    tmp = (df[df[filter_column] == name[3]][column])\n    tmp = tmp.value_counts(ascending = True)\n    trace4 = go.Pie(labels= tmp.index, values= tmp.values, hoverinfo='label+percent+name', \n                    name = name[3],hole= .5, domain= dict(x = [0.54, 1],y = [0, 0.46]))\n\n    # Layout\n    layout = go.Layout(title = title, width = width, height = height,\n                       annotations = [dict(font = dict(size=20)),\n                                      dict(showarrow =False, text=name[0],x = 0.18, y=0.78),\n                                      dict(font = dict(size=20)),\n                                      dict(showarrow= False, text=name[1],x = 0.82, y=0.78),\n                                      dict(font = dict(size=20)),\n                                      dict(showarrow= False, text=name[2],x = 0.17, y=0.2),\n                                      dict(font = dict(size=20)),\n                                      dict(showarrow= False, text=name[3],x = 0.82, y=0.2),\n                                ])\n    fig = go.Figure(data = [trace1, trace2, trace3, trace4], layout= layout)\n    py.iplot(fig)","f2166ffa":"# Venn diagram\ndef Venn2_diagram(df,columns):\n    \"\"\" Venn diagram of 2 sets\"\"\"\n    # Subset count\n    label = df[columns].mode().values[0]\n    subsets = (\n        len(df[(df[columns[0]] == label[0]) & (df[columns[1]] != label[1])]), #A\n        len(df[(df[columns[0]] != label[0]) & (df[columns[1]] == label[1])]), #B\n        len(df[(df[columns[0]] == label[0]) & (df[columns[1]] == label[1])]), #A.B\n             )\n    return venn2(subsets = subsets, set_labels= label)\n\ndef Venn3_diagram(df,columns):\n    \"\"\" Venn diagram of 3 sets\"\"\"\n    # Subset count\n    label = df[columns].mode().values[0]\n    subsets = (\n        len(df[(df[columns[0]] == label[0]) & (df[columns[1]] != label[1]) & (df[columns[2]] != label[2])]), #A\n        len(df[(df[columns[0]] != label[0]) & (df[columns[1]] == label[1]) & (df[columns[2]] != label[2])]), #B\n        len(df[(df[columns[0]] == label[0]) & (df[columns[1]] == label[1]) & (df[columns[2]] != label[2])]), #A.B\n        len(df[(df[columns[0]] != label[0]) & (df[columns[1]] != label[1]) & (df[columns[2]] == label[2])]), #C\n        len(df[(df[columns[0]] == label[0]) & (df[columns[1]] != label[1]) & (df[columns[2]] == label[2])]), #A.C\n        len(df[(df[columns[0]] != label[0]) & (df[columns[1]] == label[1]) & (df[columns[2]] == label[2])]), #B.C\n        len(df[(df[columns[0]] == label[0]) & (df[columns[1]] == label[1]) & (df[columns[2]] == label[2])]), #A.B.C\n             )\n    return venn3(subsets = subsets, set_labels= label)","05b73b2a":"#\ntmp = df['Time from Start to Finish (seconds)'].astype('int')\/60\ntmp = tmp[tmp<100]\nprint('Mean time to anwser the quetions is:',round(np.mean(tmp),2), 'minutes')\n\n# Plot\ntrace1 = go.Histogram(x = tmp, #nbinsx= 30, \n                      marker= dict(color='rgb(255, 65, 54)', line=dict(color='rgb( 127, 140, 141)',width=0.5)))\nlayout = dict(\n        title='Duration in minute',\n        width = 800,\n        height = 400,\n        xaxis = dict(autorange=True),\n        yaxis=dict(automargin=True),\n        paper_bgcolor='rgb(251, 252, 252)',\n        plot_bgcolor='rgb(251, 252, 252)'\n        )\nfig = {'data':[trace1], 'layout':layout}\npy.iplot(fig)","995255ff":"def Map(tmp, title = '', colorscale = 'Viridis',):\n    \"\"\" Geo map:\"\"\"\n    data =  dict( type = 'choropleth',\n                locations = tmp.index,\n                z = tmp.values,\n                text = tmp.index,\n                locationmode = 'country names',\n                colorscale = colorscale,\n                autocolorscale = False,\n                reversescale = True,\n                marker = dict( line = dict (\n                        color = 'rgb(180,180,180)',width = 0.3\n                    ) ),\n                colorbar = dict( autotick = False,\n                    title = 'Response'),\n          ) \n\n    layout = dict(\n        title = title,\n        geo = dict(showland = True,\n                   landcolor = \"rgb(250, 250, 250)\",\n            showframe = False,\n            showcoastlines = True,\n            projection = dict( type = 'Mercator')\n        ))\n\n    fig = dict( data=[data], layout=layout )\n\n    py.iplot( fig, validate=False, filename='world-map' )","83740ad1":"print(df_2018['Q3'][0])\ntmp = df['Q3'].value_counts()\ntitle = '2018 Kaggle Survey - Response'\nMap(tmp, title = title, colorscale= 'Viridis')","a22b1a41":"print(df_2018['Q3'][0])\nHorizontal_bar_plot(df, column= 'Q3',\n                   title = 'Top 20 Countries Response', limit = 20)\ndf['Q3'].nunique()","87c3e5df":"print(df_2018['Q6'][0])\ntitle = 'Current Role'\nHorizontal_bar_plot(df, column = 'Q6', title = title, colorscale= 'Rainbow')","5558b83e":"print(df_2018['Q3'][0],'\\n',df_2018['Q6'][0],)\ntitle = 'Country Vs Current Role'\nPie_plot_agg(filter_column= 'Q3',\n            column = 'Q6',\n            title = title,\n            name = ['United States of America','India', 'China', 'Russia'],\n            width = 1000, height =800)","c358c3d3":"print(df_2018['Q7'][0])\ncolumn = 'In what industry is your current employer\/contract (or your most recent employer if retired)? - Selected Choice'\ntitle = 'Current Employer'\nHorizontal_bar_plot(df, column= 'Q7', title = title)","50f44eb0":"title = 'Current Industry'\nHoritontal_Multi_Barplot(df, column= 'Q7', column_filter= 'Q6',title = title,limit=None, width= 1000)","26cc1bc9":"title = 'Work Experience'\nHorizontal_bar_plot(df, column= 'Q8', name='Year',title= title, limit=None, )","10ba38e9":"title = 'Work Experience of Data Professionals'\nHoritontal_Multi_Barplot(df, column= 'Q8', column_filter= 'Q6',title = title,limit=None, width= 1000)","b1a3e1fa":"# Role, Industry, Country\n#print(df_2018['Q3'])\n#df.groupby().agg({column[2]:'count'}).rename(columns={column[2]:'count'}).reset_index()","5b607864":"print(df_2018['Q1'][0],'\\n',df_2018['Q2'][0],)\ntmp = df['Q1'].value_counts(sort =True)\ntmp_per = round(tmp\/df.shape[0] * 100, 2)\ntmp_per = [str(v)+' %' for v in tmp_per]\ntrace1 = go.Bar(x = tmp.index, y = tmp.values, name='People',\n               marker = dict(color = 'rgb(93, 164, 214)',line = dict(color = 'rgb( 127, 140, 141)', width =2)),\n                text= tmp_per, textposition='auto')\n\ntmp = df['Q2'].value_counts(sort =False)\ntmp = tmp.sort_index()\ntmp_per = round(tmp\/df.shape[0] * 100,2)\ntmp_per = [str(v)+' %' for v in tmp_per]\ntrace2 = go.Bar(x = tmp.index, y = tmp.values, name = 'People',\n                marker = dict(color = 'rgb(255, 65, 54)',line = dict(color = 'rgb( 127, 140, 141)', width =2)),\n               text = tmp_per, textposition='auto')\n\nfig  = tools.make_subplots(rows= 1, cols=2, subplot_titles = ('Gender', 'Age'))\nfig.append_trace(trace1, 1,1)\nfig.append_trace(trace2, 1,2)\nfig.layout.showlegend =False\nfig.layout.height = 500\npy.iplot(fig)","ee2bab84":"male = (df\n       .loc[(df['Q1'] == 'Male') ]\n      .groupby(['Q2'])\n       .agg({'Q2':'count'})\n      .rename(columns={'Q2':'count'})\n      .reset_index()\n      ) \n\nfemale = (df\n       .loc[(df['Q1'] == 'Female') ]\n      .groupby(['Q2'])\n       .agg({'Q2':'count'})\n      .rename(columns={'Q2':'count'})\n      .reset_index()\n      ) \n\n# Plot\nvalues = male['count'].values \/(male['count'].values + female['count'].values)\ntrace1 = go.Bar(x = male['Q2'], y = values,name = 'Male')\n\nvalues = female['count'].values \/(male['count'].values + female['count'].values)\ntrace2 = go.Bar(x = female['Q2'], y = values, name = 'Female')\n\nlayout = go.Layout(barmode= 'stack', height =300 ,title = 'Percentage male and female by age')\nfig = go.Figure(data = [trace1, trace2], layout= layout)\npy.iplot(fig)","3143873f":"title = 'Gender'\nHoritontal_Multi_Barplot(df, column= 'Q1', column_filter= 'Q6',title = title,height=500)","43fbe5be":"title = 'Age'\nHoritontal_Multi_Barplot(df, column= 'Q2', column_filter= 'Q6',title = title)","1ee23506":"print(df_2018['Q5'][0])\ntitle = 'Graduate Major'\nHorizontal_bar_plot(df, column= 'Q5', name='Year',title= title, height= 500)","0a0caa3f":"title = 'Graduate Major'\nHoritontal_Multi_Barplot(df, column= 'Q5', column_filter= 'Q6',title = title,)","f3a69a3a":"Pie_plot_agg(filter_column= 'Q3',\n            column = 'Q5',\n             title = 'Graduate major from top 4 countries',\n            name = ['United States of America','India', 'China', 'Russia'],\n            width = 1100, height =800)","b1a8f38b":"print(df_2018['Q4'][0])\ntitle = 'Highest Level Of Education'\nHorizontal_bar_plot(df, column= 'Q4', name='Year',title= title)","9558c45c":"title = 'Highest level of education'\nHoritontal_Multi_Barplot(df, column= 'Q4', column_filter= 'Q6',title = title,)","34b47a57":"print(df_2018['Q9'][0])\ntmp = df['Q9'].value_counts()\n#tmp = tmp.sort_index()\nindex = ['I do not wish to disclose my approximate yearly compensation', '0-10,000', '10-20,000', \n         '20-30,000', '30-40,000', '40-50,000', '50-60,000',  '60-70,000', '70-80,000', \n         '80-90,000', '90-100,000', '100-125,000', '125-150,000',  '150-200,000', '200-250,000', \n         '250-300,000', '300-400,000', '400-500,000', '500,000+']\ntmp = tmp.reindex(index[::-1])\ntmp_per = round(tmp * 100\/ tmp.sum() , 2)\ntmp_per = [str(v)+' %' for v in tmp_per]\ntmp = tmp.rename(index={'I do not wish to disclose my approximate yearly compensation': \"Don't Disclose\"})\n# Plot\ntrace1 = go.Bar(\n    x = tmp.values, y = tmp.index,\n    marker = dict(color = 'rgb(255, 65, 54)',line = dict(color = 'rgb( 127, 140, 141)', width =2)),\n    name='$',orientation='h',\n    text = tmp_per, textposition='inside'\n)\n#Layout\nlayout = dict(\n    title='Current yearly compensation in $',\n    width = 900,height = 700,\n    yaxis=dict(automargin=True),\n    paper_bgcolor='rgba(245,245,245,0.4)',\n    plot_bgcolor='rgba(255,250,250,0.5)'\n    )\nfig = {'data':[trace1], 'layout':layout}\npy.iplot(fig)","37526408":"title = 'Current Yearly Compensation in USD $'\nHoritontal_Multi_Barplot(df, column= 'Q9', column_filter= 'Q6',title = title)","1c496279":"print(df_2018['Q10'][0])\ntmp = df['Q10'].value_counts(ascending = True)\ntrace1 = go.Pie(labels= tmp.index, values= tmp.values, hoverinfo='label+percent+name', \n                    marker = dict(colors =['magma']), name = 'Employer',\n                    hole= .5, domain= dict(x = [0, 0.38], ))\n# Layout\nlayout = go.Layout(title = 'Incorporate machine learning methods into business', width = 900, height = 500, \n                   annotations = [dict(font = dict(size=20)),\n                                  dict(showarrow =False, text= 'Deploy ML',x = 0.15, y=0.5),\n                            ])\nfig = go.Figure(data = [trace1], layout= layout)\npy.iplot(fig)","d0ddb9ec":"#column_filter = 'Select the title most similar to your current role (or most recent title if retired): - Selected Choice'\n#column = 'Does your current employer incorporate machine learning methods into their business?'\n#title = '' \n#Horitontal_Stacked_barplot(df, column= column, column_filter= column_filter,title = title)","7444bc7b":"def Selection_choice_bar_plot(column_start = '', title = '', color = 'rgb(255, 65, 54)',width= 1000, height=400):\n    \"\"\"Selection_choice_bar_plot: For Multplie choice questions\"\"\"\n    columns = df.columns[df.columns.str.startswith(column_start)]\n\n    # Count options\n    option_count = pd.DataFrame()\n    for c in columns[:-1]:\n        value = df[c].value_counts()\n        option_count = pd.concat([option_count,value])\n\n    option_count = option_count.rename(columns={0:'Count'})\n    option_count = option_count.sort_values(by='Count')\n    tmp_per = round(option_count * 100\/ option_count.sum(), 2)\n    tmp_per = [str(v)+' %' for v in  tmp_per['Count']]\n    \n    # Bar Plot\n    trace1 = go.Bar(x = option_count['Count'].values, y = option_count.index, orientation='h',\n                    text = tmp_per, textposition='inside',\n                    marker=dict(color= option_count['Count'].values, colorscale = 'Rainbow', \n                               line=dict(color='rgb( 127, 140, 141)',width=2),)\n                   )\n    \n    # Layout\n    layout = dict(\n            title=title,\n            width = width,\n            height = height,\n            yaxis = dict(\n                automargin=True,\n                showticklabels=True,\n            ),\n            paper_bgcolor='rgb(251, 252, 252)',\n            plot_bgcolor='rgb(251, 252, 252)'\n            )\n    fig = {'data':[trace1], 'layout':layout}\n    py.iplot(fig)","37e95a75":"def Selection_choice_Pie_plot(column_start, title = '', text = '', width= 900, height= 500):\n    \n    columns = df.columns[df.columns.str.startswith(column_start)]\n    # Count options\n    option_count = pd.DataFrame()\n    for c in columns[:-1]:\n        value = df[c].value_counts()\n        option_count = pd.concat([option_count,value])\n\n    option_count = option_count.rename(columns={0:'Count'})\n    option_count = option_count.sort_values(by='Count')\n    \n    # Plot\n    trace1 = go.Pie(labels= option_count.index, values= option_count['Count'].values, \n                    hoverinfo='label+percent+name', marker = dict(colors =['magma']), name = '',\n                        hole= .5, domain= dict(x = [0, 0.5], ))\n    \n    # Layout\n    layout = go.Layout(title = title, width = width, height = height, \n                       annotations = [dict(font = dict(size=20)),\n                                      dict(showarrow =False, text=text,x = 0.2, y=0.5),\n                                ])\n    fig = go.Figure(data = [trace1], layout= layout)\n    py.iplot(fig)","3a3ba122":"def Barplot_of_Q_Regular_MostOften(df, column1 ='', column2 = '', title = '', height = 500, width=900):\n    \"\"\" Barplot of Most often and Regualar \"\"\"\n    columns = df.columns[df.columns.str.startswith(column1)]\n\n    fig  = tools.make_subplots(rows= 1, cols=2, subplot_titles = ('Regular', 'Most Often'),\n                               print_grid= False)\n\n    # Count options\n    option_count = pd.DataFrame()\n    for c in columns[:-1]:\n        value = df[c].value_counts()\n        option_count = pd.concat([option_count,value])\n\n    option_count = option_count.rename(columns={0:'Count'})\n    option_count = option_count.sort_values(by='Count')\n    tmp_per = round(option_count * 100\/ option_count.sum(), 2)\n    tmp_per = [str(v)+' %' for v in  tmp_per['Count']]\n\n    # Bar Plot 1\n    trace1 = go.Bar(x = option_count['Count'].values, y = option_count.index, orientation='h', name = '',\n                    text = tmp_per, textposition='inside',\n                   marker = dict(color = 'rgb(65,105,225)', line = dict(color = 'rgb( 127, 140, 141)', width =2)))\n    # Bar Plot 2\n    #column= 'Q17'\n    tmp = df[column2].value_counts(ascending = True)\n    tmp_per = round(tmp * 100\/ tmp.sum(), 2)\n    tmp_per = [str(v)+' %' for v in tmp_per]\n    trace2 = go.Bar(x = tmp.values, y = tmp.index, orientation='h', name = '',\n                    text = tmp_per, textposition='inside',\n                   marker = dict(color = 'rgb(255, 65, 54)', line = dict(color = 'rgb( 127, 140, 141)', width =2)))\n\n    fig.append_trace(trace1, 1,1)\n    fig.append_trace(trace2, 1,2)\n    fig['layout'].update(dict( \n            showlegend =False,\n            height = height,\n            width = width,\n            title = title,\n            paper_bgcolor='rgb(251, 252, 252)',\n            plot_bgcolor='rgb(250, 250, 255)'))\n\n    py.iplot(fig)","4c48c1d3":"title = \"Integrated Development Environments (IDE's)\"\ncolumn_start = 'Q13_Part'\nSelection_choice_bar_plot(column_start= column_start, title=title, width=1000, height= 600, \n                          color= 'rgb(65,105,225)')","6533a876":"columns = ['Q13_Part_1','Q13_Part_2','Q13_Part_9']\nfilter_label = ['Student', 'Data Scientist', 'Data Analyst']\n\nplt.figure(figsize = (14,10))\ngs = gridspec.GridSpec(3,3)\n\n# Make Venn diagram\nax = plt.subplot(gs[0:2,:])\nVenn3_diagram(df, columns)\nplt.title(\"Integrated Development Environments (IDE's): Total\")\n\n# bottom 3 plot\nfor i, c in enumerate(filter_label):\n    tmp = df[df['Q6'] == filter_label[i]]\n    ax = plt.subplot(gs[2,i])\n    Venn3_diagram(tmp, columns)\n    plt.title(filter_label[i])","84d978f9":"print(df_2018['Q16_Part_1'][0][:100])\ntitle = 'Programming Laguage preference'\nBarplot_of_Q_Regular_MostOften(df, column1='Q16_Part', column2= 'Q17', title=title,height=700)","ce415fc0":"columns = ['Q16_Part_1','Q16_Part_2','Q16_Part_3']\nfilter_label = ['Student', 'Data Scientist', 'Data Analyst']\n\nplt.figure(figsize = (14,10))\ngs = gridspec.GridSpec(3,3)\n\n# Make Venn diagram\nax = plt.subplot(gs[0:2,:])\nVenn3_diagram(df, columns)\nplt.title(\"Programming Laguage preference: Total\")\n\n# bottom 3 plot\nfor i, c in enumerate(filter_label):\n    tmp = df[df['Q6'] == filter_label[i]]\n    ax = plt.subplot(gs[2,i])\n    Venn3_diagram(tmp, columns)\n    plt.title(filter_label[i])\nplt.savefig('language.png')","6ef33b1c":"tmp = df['Q18'].value_counts(ascending = True)\n\n# Plot\ntrace1 = go.Pie(labels= tmp.index, values= tmp.values, hoverinfo='label+percent+name', \n                    marker = dict(colors =['magma']), name = 'Language',\n                    hole= .5, domain= dict(x = [0, 1]))\n\n# Layout\nlayout = go.Layout(title = 'Programming Language', width = 900, height = 500, \n                   annotations = [dict(font = dict(size=20)),\n                                  dict(showarrow =False, text= 'Language',x = 0.5, y=0.5),\n                            ])\nfig = go.Figure(data = [trace1], layout= layout)\npy.iplot(fig)","7e46c346":"print(df_2018['Q19_Part_1'][0][:100])\ntitle = 'Machine Learnig Libraries'\nBarplot_of_Q_Regular_MostOften(df, column1='Q19_Part', column2= 'Q20', title=title,height=700)","85915e30":"columns = ['Q19_Part_2','Q19_Part_3','Q19_Part_4']\nfilter_label = ['Student', 'Data Scientist', 'Data Analyst']\n\nplt.figure(figsize = (14,10))\ngs = gridspec.GridSpec(3,3)\n\n# Make Venn diagram\nax = plt.subplot(gs[0:2,:])\nVenn3_diagram(df, columns)\nplt.title(\"Deep Learnig Library: Total\")\n\n# bottom 3 plot\nfor i, c in enumerate(filter_label):\n    tmp = df[df['Q6'] == filter_label[i]]\n    ax = plt.subplot(gs[2,i])\n    Venn3_diagram(tmp, columns)\n    plt.title(filter_label[i])","221373f4":"print(df_2018['Q21_Part_1'][0][:100])\ntitle = 'Machine Learnig Libraries'\nBarplot_of_Q_Regular_MostOften(df, column1='Q21_Part', column2= 'Q22', title=title,height=600)","2e029c20":"columns = ['Q21_Part_8','Q21_Part_2','Q21_Part_1']\nfilter_label = ['Student', 'Data Scientist', 'Data Analyst']\n\nplt.figure(figsize = (14,10))\ngs = gridspec.GridSpec(3,3)\n\n# Make Venn diagram\nax = plt.subplot(gs[0:2,:])\nVenn3_diagram(df, columns)\nplt.title(\"Data visualization: Total\")\n\n# bottom 3 plot\nfor i, c in enumerate(filter_label):\n    tmp = df[df['Q6'] == filter_label[i]]\n    ax = plt.subplot(gs[2,i])\n    Venn3_diagram(tmp, columns)\n    plt.title(filter_label[i])","12c8825f":"columns = ['Q23','Q24','Q25','Q26']\nprint(df_2018[columns].iloc[0].values)\n\nname = ['Coding','Analyze Data','ML in School', 'Data Scientist?']\ntitle = ''\n\n# Plot\ntrace = []\nfor c in columns:\n    tmp = df[c].value_counts(sort = True)\n    tmp_per = round(tmp *100 \/ tmp.sum(),2)\n    trace1 = go.Bar(x = tmp.index, y = tmp.values, text = tmp_per.values, textposition = 'outside', name = '',\n                   marker=dict(color= tmp.values, colorscale = 'Rainbow', \n                               line=dict(color='rgb( 127, 140, 141)',width=2))\n                   )\n    trace.append(trace1)\n\n# Layout\nfig  = tools.make_subplots(rows= 2, cols=2, subplot_titles = ('Coding in school','Analyze Data',\n                                                              'ML in School', 'Data Scientist?'))\nfig.append_trace(trace[0], 1,1)\nfig.append_trace(trace[1], 1,2)\nfig.append_trace(trace[2], 2,1)\nfig.append_trace(trace[3], 2,2)\nfig.layout.showlegend =False\nfig.layout.height = 1000\nfig.layout.xaxis.automargin = True\npy.iplot(fig)\n","6c05a5a8":"print(df_2018['Q33_Part_1'][0])\ntitle = 'Public data resource'\ntext = 'Data Repository'\nSelection_choice_Pie_plot(column_start= 'Q33_Part', title = title, text=text,height = 500, width= 900)","d3a42620":"columns = df.columns[df.columns.str.startswith('Q34_Part')]\n#print(df_2018[columns].iloc[0].values)\n\n# Plot\ntrace = []\nname = pd.Series(df_2018[columns].iloc[0].values).str.split('-').apply(lambda x: x[1])\nfor c in columns:\n    tmp = df[c]\n    trace1 = go.Histogram(x = tmp, nbinsx= 20, name = '',\n                      marker = dict(color='rgb(255, 65, 54)',\n                                    line = dict(color='rgb( 127, 140, 141)',width=1)))\n    trace.append(trace1)\n\n# Layout\nfig  = tools.make_subplots(rows= 2, cols=3, subplot_titles = (name.values[:-1]))\nfig.append_trace(trace[0], 1,1)\nfig.append_trace(trace[1], 1,2)\nfig.append_trace(trace[2], 1,3)\nfig.append_trace(trace[3], 2,1)\nfig.append_trace(trace[4], 2,2)\nfig.append_trace(trace[5], 2,3)\nfig.layout.showlegend =False\nfig.layout.height = 600\nfig.layout.width = 1200\nfig.layout.xaxis.automargin = False\npy.iplot(fig)","d63b5f36":"print(df_2018['Q36_Part_1'][0][:100])\ntitle = 'Machine Learnig Libraries'\nBarplot_of_Q_Regular_MostOften(df, column1='Q36_Part', column2= 'Q37', title=title,height=600)","3d6bfc55":"columns = ['Q36_Part_2','Q36_Part_1','Q36_Part_6']\nfilter_label = ['Student', 'Data Scientist', 'Data Analyst']\n\nplt.figure(figsize = (14,10))\ngs = gridspec.GridSpec(3,3)\n\n# Make Venn diagram\nax = plt.subplot(gs[0:2,:])\nVenn3_diagram(df, columns)\nplt.title(\"MOOC: Total\")\n\n# bottom 3 plot\nfor i, c in enumerate(filter_label):\n    tmp = df[df['Q6'] == filter_label[i]]\n    ax = plt.subplot(gs[2,i])\n    Venn3_diagram(tmp, columns)\n    plt.title(filter_label[i])","ca538fce":"# What percentage of your current machine learning\/data science training falls under each category?\ncolumns = df.columns[df.columns.str.startswith('Q35_Part')]\n\nname = pd.Series(df_2018[columns].iloc[0].values).str.split(')').apply(lambda x: x[1])\n\n# Plot\ntrace = []\nfor i,c in enumerate(columns):\n    tmp = df[c]\n    #tmp = tmp[tmp>0]\n    trace1 = go.Histogram(x = tmp, nbinsx= 20, name = name[i],\n                     marker = dict(color='rgb(65,105,225)',line = dict(color='rgb( 127, 140, 141)',width=1)))\n    trace.append(trace1)\n\n# Layout\nfig  = tools.make_subplots(rows= 2, cols=3, subplot_titles = tuple(name.values))\nfig.append_trace(trace[0], 1,1)\nfig.append_trace(trace[1], 1,2)\nfig.append_trace(trace[2], 1,3)\nfig.append_trace(trace[3], 2,1)\nfig.append_trace(trace[4], 2,2)\nfig.append_trace(trace[5], 2,3)\n\nfig.layout.showlegend =False\nfig.layout.height = 600\nfig.layout.xaxis.automargin = False\npy.iplot(fig)","e39fce72":"#column_start= 'How do you perceive the quality of online learning plcolumns = df.columns[df.columns.str.startswith(column_start)'\n#title = 'Quality of MOOC vs Traditional Institution'\n#Selection_choice_Pie_plot(column_start= column_start, title= title,width=900, height=500)","c0575d78":"columns = df.columns[df.columns.str.startswith('Q39_Part')]\ntitle = 'Quality of MOOC vs Traditional Institution'\n\n# Count options\noption_count = pd.DataFrame()\nfor c in columns[:-1]:\n    value = df[c].value_counts()\n    option_count = pd.concat([option_count,value])\n\noption_count = option_count.rename(columns={0:'Count'})\noption_count = option_count.sort_values(by='Count')\n\n# Plot\ntrace1 = go.Pie(labels= option_count.index, values= option_count['Count'].values, \n                hoverinfo='label+percent+name', marker = dict(colors =['magma']), name = 'Language',\n                hole= .5, domain= dict(x = [0, 1]))\n\nlayout = go.Layout(title = title, width = 900, height = 500, \n                   annotations = [dict(font = dict(size=20)),\n                                  dict(showarrow =False, text='',x = 0.2, y=0.5),\n                            ])\nfig = go.Figure(data = [trace1], layout= layout)\npy.iplot(fig)","135a1fd6":"title = 'Top Data Science Blog'\nSelection_choice_bar_plot(column_start='Q38_Part',title = title, height = 600)","0a19c8f9":"columns = df.columns[df.columns.str.startswith('Q38')]\ndf[columns].mode()","60ddbe9f":"columns = ['Q38_Part_4','Q38_Part_18','Q38_Part_11']\nfilter_label = ['Student', 'Data Scientist', 'Data Analyst']\n\nplt.figure(figsize = (14,10))\ngs = gridspec.GridSpec(3,3)\n\n# Make Venn diagram\nax = plt.subplot(gs[0:2,:])\nVenn3_diagram(df, columns)\nplt.title(\"Machine Learnig Blog: Total\")\n\n# bottom 3 plot\nfor i, c in enumerate(filter_label):\n    tmp = df[df['Q6'] == filter_label[i]]\n    ax = plt.subplot(gs[2,i])\n    Venn3_diagram(tmp, columns)\n    plt.title(filter_label[i])","65d84f55":"print(df_2018['Q15_Part_1'][0])\ntitle = 'Cloud Computing for Machine Learning Work'\ntext = 'Cloud'\nSelection_choice_Pie_plot(column_start='Q15_Part',title= title, text = text, width=800, height=400)","5a533d2c":"# ML frame work\nprint(df_2018['Q27_Part_1'][0])\ncolumn_start= 'Q27'\ntitle = 'Cloud'\ncolumns = df.columns[df.columns.str.startswith(column_start)]\n\n# Count options\noption_count = pd.DataFrame()\nfor c in columns[:-1]:\n    value = df[c].value_counts()\n    option_count = pd.concat([option_count,value])\n\noption_count = option_count.rename(columns={0:'Count'})\noption_count = option_count.sort_values(by='Count')\ntmp_per = round(option_count * 100\/ option_count.sum(), 2)\n\n# Bar Plot 1\ntrace1 = go.Bar(x = option_count['Count'].values, y = option_count.index, orientation='h', name = '',\n                text = tmp_per['Count'].values, textposition='inside',\n               marker = dict(color = 'rgb(65,105,225)', line = dict(color = 'rgb( 127, 140, 141)', width =2)))\n\n# Ploting library\nprint(df_2018['Q28_Part_1'][0])\ncolumn_start= 'Q28_Part'\n#title = 'Programming Laguage preference'\ncolumns = df.columns[df.columns.str.startswith(column_start)]\n\n# Count options\noption_count = pd.DataFrame()\nfor c in columns[:-1]:\n    value = df[c].value_counts()\n    option_count = pd.concat([option_count,value])\n\noption_count = option_count.rename(columns={0:'Count'})\noption_count = option_count.sort_values(by='Count')\ntmp_per = round(option_count * 100\/ option_count.sum(), 2)\n\n# Bar Plot 1\ntrace2 = go.Bar(x = option_count['Count'].values, y = option_count.index, orientation='h', name = '',\n                text = tmp_per['Count'].values, textposition='inside',\n               marker = dict(color = 'rgb(255, 65, 54)', line = dict(color = 'rgb( 127, 140, 141)', width =2)))\n\nfig  = tools.make_subplots(rows= 1, cols=2, subplot_titles = ('Cloud Resource', 'Machine Learning Product'))\nfig.append_trace(trace1, 1,1)\nfig.append_trace(trace2, 1,2)\nfig.layout.showlegend =False\nfig.layout.yaxis.automargin = True\nfig.layout.height = 800\nfig.layout.width = 1100\npy.iplot(fig)","cdb9489d":"# ML frame work\ncolumn_start= 'Which of the following relational database products have you used at work or school in the last 5 years?'\ntitle = 'Cloud'\ncolumns = df.columns[df.columns.str.startswith('Q29_Part')]\n\n# Count options\noption_count = pd.DataFrame()\nfor c in columns[:-1]:\n    value = df[c].value_counts()\n    option_count = pd.concat([option_count,value])\n\noption_count = option_count.rename(columns={0:'Count'})\noption_count = option_count.sort_values(by='Count')\ntmp_per = round(option_count * 100\/ option_count.sum(), 2)\n\n# Bar Plot 1\ntrace1 = go.Bar(x = option_count['Count'].values, y = option_count.index, orientation='h', name = '',\n                text = tmp_per['Count'].values, textposition='inside',\n               marker = dict(color = 'rgb(65,105,225)', line = dict(color = 'rgb( 127, 140, 141)', width =2)))\n\n# Ploting library\ncolumn_start= 'Which of the following big data and analytics products have you used at work or school in the last 5 years?'\n#title = 'Programming Laguage preference'\ncolumns = df.columns[df.columns.str.startswith('Q30_Part')]\n\n# Count options\noption_count = pd.DataFrame()\nfor c in columns[:-1]:\n    value = df[c].value_counts()\n    option_count = pd.concat([option_count,value])\n\noption_count = option_count.rename(columns={0:'Count'})\noption_count = option_count.sort_values(by='Count')\ntmp_per = round(option_count * 100\/ option_count.sum(), 2)\n\n# Bar Plot 1\ntrace2 = go.Bar(x = option_count['Count'].values, y = option_count.index, orientation='h', name = '',\n                text = tmp_per['Count'].values, textposition='inside',\n               marker = dict(color = 'rgb(255, 65, 54)', line = dict(color = 'rgb( 127, 140, 141)', width =2)))\n\nfig  = tools.make_subplots(rows= 1, cols=2, subplot_titles = ('Relational database management system', \n                                                              'Big Data'))\nfig.append_trace(trace1, 1,1)\nfig.append_trace(trace2, 1,2)\nfig.layout.showlegend =False\nfig.layout.yaxis.automargin = True\nfig.layout.height = 700\nfig.layout.width = 1000\npy.iplot(fig)","32032bf1":"title = 'Hosted Notebooks'\ntext = 'Site'\nprint(df_2018['Q14_Part_1'][0])\nSelection_choice_Pie_plot(column_start= 'Q14_Part', title = title, text=text,height = 500, width= 900)","2e1e0138":"print(df_2018['Q42_Part_1'].iloc[0])\n\ntitle = 'The metric to determine Model Performance'\ntext = 'Model Performance Metric'\nSelection_choice_Pie_plot(column_start= 'Q42_Part', title= title,text =text)","45eb7dc3":"print(df_2018['Q11_Part_1'].iloc[0][:100])\ntitle = 'Select any activities that make up an important part of your role at work'\ntext = 'Activity'\nSelection_choice_Pie_plot(column_start= 'Q11_Part', title= title, text= text, width = 1100)","09e81df3":"tmp = (df['Q43'].value_counts())\n\n# Plot\ntrace1 = go.Bar(x = tmp.index, y = tmp.values, \n                marker= dict(color='rgb(220,20,60)', line=dict(color='rgb( 0, 0, 20)',width=2)))\nlayout = dict(\n        title='Exploring unfair bias',\n        width = 600,\n        height = 400,\n        xaxis = dict(autorange=True),\n        yaxis=dict(automargin=True),\n         paper_bgcolor='rgba(245,245,245,0.4)',\n        plot_bgcolor='rgba(255,250,250,0.5)'\n        )\nfig = {'data':[trace1], 'layout':layout}\npy.iplot(fig)","75c1e618":"print(df_2018['Q44_Part_1'].iloc[0][:90])\ntitle = 'Difficulty in analyzing algorithm is fair and unbiased' \ntext = ''\nSelection_choice_Pie_plot(column_start= 'Q44_Part', title= title, width= 1000,)","acb2a683":"print(df_2018['Q45_Part_1'][0][:95])\ntitle = 'Model interpretion' \ntext = 'Model interpretion'\nSelection_choice_Pie_plot(column_start=  'Q45_Part', title= title, width= 900,)","c4c8f7a8":"tmp = (df['Q46'].value_counts(sort = True))\n\n# Plot\ntrace1 = go.Bar(x = tmp.index, y = tmp.values, \n                marker= dict(color='rgb(220,20,60)', line=dict(color='rgb( 0, 0, 20)',width=2)))\nlayout = dict(\n        title='Exporing model insights',\n        width = 600,\n        height = 400,\n        xaxis = dict(autorange=True),\n        yaxis=dict(automargin=True),\n         paper_bgcolor='rgba(245,245,245,0.4)',\n        plot_bgcolor='rgba(255,250,250,0.5)'\n        )\nfig = {'data':[trace1], 'layout':layout}\npy.iplot(fig)","ffe9cbd1":"print(df_2018['Q47_Part_1'][0])\ntitle = 'Evaluation Metirc'\nSelection_choice_bar_plot(column_start= 'Q47_Part',title = title, width = 900, height = 600)","fc66fea5":"print(df_2018['Q49_Part_1'][0])\nSelection_choice_Pie_plot(column_start='Q49_Part',width= 1200)","40fd81d3":"column_start = 'What barriers prevent you from making your work even easier to reuse and reproduce?'\ntitle = 'Barriers in reuse and reproduce the previous work'\ntext = ''\nSelection_choice_Pie_plot(column_start= 'Q50_Part', title= title,text =text, width= 800, height= 400)","994eee0a":"#column_start = 'Do you consider ML models to be \"black boxes\" with outputs that are difficult or impossible to explain?'\n#Selection_choice_Pie_plot(column_start= column_start,)","c1f8e07d":"tmp = (df['Q48'].value_counts())\ntrace1 = go.Bar(x = tmp.values, y = tmp.index, orientation= 'h',\n               marker = dict(color = 'rgb(10,30,231)'),\n               text = tmp.values, textposition='outside')\nlayout = dict(\n        title=' Is ML model Black boxes or White boxes',\n        width = 1300,\n        height = 400,\n        yaxis=dict(automargin=True),\n         paper_bgcolor='rgba(245,245,245,0.4)',\n        plot_bgcolor='rgba(255,250,250,0.5)'\n        )\nfig = {'data':[trace1], 'layout':layout}\npy.iplot(fig)","a55a0dae":"columns = df.columns[df.columns.str.startswith('Q12')]\nprint(df_2018['Q12_MULTIPLE_CHOICE'][0])\n# Count options\noption_count = pd.DataFrame()\nfor c in columns:\n    value = df[c].value_counts()\n    option_count = pd.concat([option_count,value])\n\noption_count = option_count.rename(columns={0:'Count'})\noption_count = option_count.sort_values(by='Count')\noption_count = option_count.loc[['Business intelligence software (Salesforce, Tableau, Spotfire, etc.)',\n                'Cloud-based data software & APIs (AWS, GCP, Azure, etc.)',\n                 'Advanced statistical software (SPSS, SAS, etc.)',\n                 'Other',\n                 'Basic statistical software (Microsoft Excel, Google Sheets, etc.)',\n                 'Local or hosted development environments (RStudio, JupyterLab, etc.)']]\n# Plot\ntrace1 = go.Pie(labels= option_count.index, values= option_count['Count'].values, \n                hoverinfo='label+percent+name', marker = dict(colors =['magma']), name = '',\n                    hole= .5, domain= dict(x = [0, 0.5], ))\n\n# Layout\nlayout = go.Layout(title = 'Primary tool to analyze dataset', width = 800, height = 500, \n                   annotations = [dict(font = dict(size=20)),\n                                  dict(showarrow =False, text='Tools',x = 0.2, y=0.5),\n                            ])\nfig = go.Figure(data = [trace1], layout= layout)\npy.iplot(fig)","1fdff523":"# other than above type mentioned\ncolumn_start = 'Q12_OTHER_TEXT'\nwc = (WordCloud(height=400,width=1400, max_words=1000, stopwords=STOPWORDS,\n                colormap='rainbow',background_color='White'\n              ).generate(' '.join(response[column_start].dropna().astype(str))))\n\nplt.figure(figsize=(16,6))\nplt.imshow(wc)\nplt.savefig('wc.png')\nplt.axis('off')\nplt.title('Activity');","487948a6":"#pd.crosstab(df['Q6'],df['Q5']).style.background_gradient(cmap='cool')","b58508f8":"Inference:\n* About 23% of respondents have not disclosed their compensation, it also includes students not only professionals. \n* There are 21% of respondents have compensation 0-10000 USD. It may also include students as well. We are considering the salary of all respondent across global, so salary varies from countries to countries, based on their economic condition and labour policy.","26342bbd":"### Hosted Notebooks\nHosted notebook means running notebooks in cloud with setting up any OS or software.","3e63f5f5":"### Incorporate machine learning methods into business","9e5a1cf8":"Inference:\n* Respondents regularly use Python, SQL and R for development. About 28 %, 14%, and 12 %of developers regular use Python, SQL and R respectively.\n* When we look at the second plot 53% of respondents most often use Python and 13% of them use for development. Here Python is the most prefered language choice.","e8c90e26":"> Thank you for visiting","174e21c3":"* We find that there are python user's, they prefer to use Jupyter\/IPython for development. The Jupyter Notebook App is a server-client application that allows editing and running notebook documents via a web browser.\n* RStudio is second most popular IDE used by developers follwed by Notepad++. Here many developers using Notepad++ indicated many Windows user. There few specialized IDE specificaly for Python developers such as Jupyter, Spyder, PyCharm. ","2c7e42c7":"## Exporatory Data analysis","69d3b843":"> Country Vs Current Role","0c272400":"Inference:\n* About 75% of respondents recommended learning Python compared to all other languages, only 12% recommend to learn R for aspiring data scientist.\n* SAS and MATLAB require the licence to install in the computer, MATLAB is especially used by Research \/ Academic people for development.","1fb0fed4":"### Highest Level Of Education","3e303964":"### Time Duration\nTime duration of respondents","4ee6177e":"### The metric to determine Model Performance","e05d63da":"Data Scientist\n* The most of Data Scientists are with experience less than 1 year, about 32% professional mention their work experience is less than a year. About 23% of respondent have 1-2 year of experience working as a Data Scientist. So most of Data Scientists are young and new to the field. More than 65% of Data scientists have the only 0-3 year experience.\n* About 8% of Data scientist have 5-10 year experience.\n\nData Analyst:\n* About 34% of Data Analyst have less than a year of experience and 19% of them have 1-2 year experience. So most data analyst are new to the data science field. It shows that 68% of Data Analyst experience is 0-3 years.\n* About 10% of data analyst have 5-10 year experience\n\nStudent:\n* About 42% of student have 0-1 year experience, it means they did not have any experience in the industry. There are respondents left the job and continuing studies.","75d9c53a":"### Exploring unfair bias in dataset and\/or algorithm","60905a83":"### Data science project involvement","539d8c00":"Inference:\n* Highest level of education is Master's degree follwed by Bachelor's degree, 10k participants have Master's compares to 7k Bachelor's degree holders.\n* Third position in the survey is result is Doctaral degree scholars with 3k observations.","eb49354a":"###  Integrated Development Environments (IDE's)\nAn integrated development environment (IDE) is a software suite that consolidates basic tools required to write and test software.\n\nDevelopers use numerous tools throughout software code creation, building and testing. Development tools often include text editors, code libraries, compilers and test platforms. Without an IDE, a developer must select, deploy, integrate and manage all of these tools separately. An IDE brings many of those development-related tools together as a single framework, application or service. The integrated toolset is designed to simplify software development and can identify and minimize coding mistakes and typos.","d386de7f":"Inference:\n* *USA, India* and *China* are among the top response obtained. Information technology is the most popular among these countries and the population of these countries are much higher compared to other countries.\n*  There 56 countries respondents in this survey apart these counties few of the participants don't want to disclose their national identity and top 4th place in the result is from *\"other\"* countries, it means many countries are also part of Kaggle. This survey received good response from compared to previous year survey, this time 147 countries are part of the survey, many countries with few responses are given tag as *\"other\"*.","5b9cdb54":"Inference\n* About 72% of students are in studying and reset are working in the different industry, 13% of them are in Academics\/ Education and 8% of them are in Computers\/IT industry.\n* About 31% of Data Scientist is in computers\/IT industry, reset of the data scientist are working in a different industry. 30 data scientist are working in NGO, which is the least in the category. Here we can see 281 data scientist has left the job and continuing their studies.\n* There are 412 Data analyst are in IT industry, 185 data analyst have left the job and continuing their studies.","59d21770":">  Kaggle Data Science Survey 2018\n\nKaggle is the world's largest community of data scientists and machine learners, owned by Google, Inc. Kaggle got its start by offering machine learning competitions and now also offers a public data platform, a cloud-based workbench for data science, and short form AI education.\n\nMachine learning, an approach and set of technologies that use AI concepts, is directly related to pattern recognition and computational learning. It\u2019s an old concept, first defined in 1959 as giving computers the capacity to learn without reprogramming.\n\nMachine learning is really about the study of algorithms that have the ability to learn through patterns and, based on that, make predictions against patterns of data. It\u2019s a better alternative to leveraging static program instructions and instead making data-driven predictions or decisions that will improve over time without human intervention and additional programming.\n\n<center><img src='https:\/\/cdn-images-1.medium.com\/max\/1600\/1*0mOv-6h9-5oM_BAoWpjAnw.png'> <center>","740d85d8":"Inference:\n* As we look at the gender participants plot, 19k male participants when compared to 4k female participants \n* The most participants are male followed by female, few participants have'nt diclosed there gender identity. In data science industry gender inequality is one of the major problem, there are around 80% male compare to 20% female participants.\n* There are 16% female participants bettween age 18-21, when we look at age between 22-24, 25-29, 30-34 there are 20%, 18% and  16% female participants. It clearly shows that as age incease the female participants gradually decreases. The female age group 18-21 less into kaggle survey compare to age group between 22-24.\n* When we look age group between 34-59 minimum female on a average 12% female participants.","8b93605b":"### Primary tool to analyze dataset","dfc73160":"### Is ML model Black boxes or White boxes","75828161":"### Top Data Science Blog\nWho\/what are your favorite media sources that report on data science topics?","282b74e4":"### Evaluation Metirc","95390db7":"### tools and methods do you use to make your work easy to reproduce","de8e3250":"### Machine Learning Frame Work","def77b49":"Inference:\n* We find that the current role of respondents is student followed by Data scientist among the list, with 22% of and 18% of respondent respectively.\n* There 13% of respondents are currently the software engineer, they willing to build their career in data science domain. So they are building their portfolio by participating in different kaggle competition and kernel.\n* There are 8% of respondents are currently working as Data analyst.\n* There are 3.5% of respondents are not employed.","fc00f1ec":"### Current Employer","fd953566":"## Machine Learning Cloud Resource\nMachine learning was once out of the reach of most enterprise budgets, but today, public cloud providers\u2019 ability to offer machine-learning services makes this technology affordable.\nIn this step let us look into different type of cloud resourse available, Big data and Hosted Notebooks","8d28c580":"### Data Visualization Library","fc362646":"## Import libray and dataset","f510ea0d":"## Learning Tools and Resource","177b0639":"Inference:\n* There are few outlier in the dataset\n* The mean time taken to to anwser survey questions is 18 minutes.","e366b454":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-libray-and-dataset\" data-toc-modified-id=\"Import-libray-and-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Import libray and dataset<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Import-library\" data-toc-modified-id=\"Import-library-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;<\/span>Import library<\/a><\/span><\/li><li><span><a href=\"#Import-dataset\" data-toc-modified-id=\"Import-dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;<\/span>Import dataset<\/a><\/span><\/li><li><span><a href=\"#Glimpse-dataset\" data-toc-modified-id=\"Glimpse-dataset-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;<\/span>Glimpse dataset<\/a><\/span><\/li><li><span><a href=\"#Usefull-functions\" data-toc-modified-id=\"Usefull-functions-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;<\/span>Usefull functions<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Exporatory-Data-analysis\" data-toc-modified-id=\"Exporatory-Data-analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Exporatory Data analysis<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Time-Duration\" data-toc-modified-id=\"Time-Duration-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;<\/span>Time Duration<\/a><\/span><\/li><li><span><a href=\"#In-which-country-do-you-currently-reside?\" data-toc-modified-id=\"In-which-country-do-you-currently-reside?-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;<\/span>In which country do you currently reside?<\/a><\/span><\/li><li><span><a href=\"#Current-Role\" data-toc-modified-id=\"Current-Role-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;<\/span>Current Role<\/a><\/span><\/li><li><span><a href=\"#Current-Employer\" data-toc-modified-id=\"Current-Employer-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;<\/span>Current Employer<\/a><\/span><\/li><li><span><a href=\"#Work-Experience-of-Data-Professionals\" data-toc-modified-id=\"Work-Experience-of-Data-Professionals-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;<\/span>Work Experience of Data Professionals<\/a><\/span><\/li><li><span><a href=\"#Gender-and-Age\" data-toc-modified-id=\"Gender-and-Age-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;<\/span>Gender and Age<\/a><\/span><\/li><li><span><a href=\"#Graduate-Major\" data-toc-modified-id=\"Graduate-Major-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;<\/span>Graduate Major<\/a><\/span><\/li><li><span><a href=\"#Highest-Level-Of-Education\" data-toc-modified-id=\"Highest-Level-Of-Education-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;<\/span>Highest Level Of Education<\/a><\/span><\/li><li><span><a href=\"#Current-yearly-compensation\" data-toc-modified-id=\"Current-yearly-compensation-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;<\/span>Current yearly compensation<\/a><\/span><\/li><li><span><a href=\"#Incorporate-machine-learning-methods-into-business\" data-toc-modified-id=\"Incorporate-machine-learning-methods-into-business-2.10\"><span class=\"toc-item-num\">2.10&nbsp;&nbsp;<\/span>Incorporate machine learning methods into business<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Learning-Tools-and-Resource\" data-toc-modified-id=\"Learning-Tools-and-Resource-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Learning Tools and Resource<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Integrated-Development-Environments-(IDE's)\" data-toc-modified-id=\"Integrated-Development-Environments-(IDE's)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;<\/span>Integrated Development Environments (IDE's)<\/a><\/span><\/li><li><span><a href=\"#Programming-Lannguage\" data-toc-modified-id=\"Programming-Lannguage-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;<\/span>Programming Lannguage<\/a><\/span><\/li><li><span><a href=\"#Programming-Laguage-Recommended-for-Aspiring-Data-Scientist\" data-toc-modified-id=\"Programming-Laguage-Recommended-for-Aspiring-Data-Scientist-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;<\/span>Programming Laguage Recommended for Aspiring Data Scientist<\/a><\/span><\/li><li><span><a href=\"#Machine-Learning-Frame-Work\" data-toc-modified-id=\"Machine-Learning-Frame-Work-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;<\/span>Machine Learning Frame Work<\/a><\/span><\/li><li><span><a href=\"#Data-Visualization-Library\" data-toc-modified-id=\"Data-Visualization-Library-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;<\/span>Data Visualization Library<\/a><\/span><\/li><li><span><a href=\"#Coding-Skill-and-Experience\" data-toc-modified-id=\"Coding-Skill-and-Experience-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;<\/span>Coding Skill and Experience<\/a><\/span><\/li><li><span><a href=\"#Public-data-resource\" data-toc-modified-id=\"Public-data-resource-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;<\/span>Public data resource<\/a><\/span><\/li><li><span><a href=\"#Data-science-project-involvement\" data-toc-modified-id=\"Data-science-project-involvement-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;<\/span>Data science project involvement<\/a><\/span><\/li><li><span><a href=\"#Massive-open-online-course-(MOOC)\" data-toc-modified-id=\"Massive-open-online-course-(MOOC)-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;<\/span>Massive open online course (MOOC)<\/a><\/span><\/li><li><span><a href=\"#Data-Science-Training\" data-toc-modified-id=\"Data-Science-Training-3.10\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;<\/span>Data Science Training<\/a><\/span><\/li><li><span><a href=\"#Quality-of-MOOC-vs-Traditional-Institution\" data-toc-modified-id=\"Quality-of-MOOC-vs-Traditional-Institution-3.11\"><span class=\"toc-item-num\">3.11&nbsp;&nbsp;<\/span>Quality of MOOC vs Traditional Institution<\/a><\/span><\/li><li><span><a href=\"#Top-Data-Science-Blog\" data-toc-modified-id=\"Top-Data-Science-Blog-3.12\"><span class=\"toc-item-num\">3.12&nbsp;&nbsp;<\/span>Top Data Science Blog<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Machine-Learning-Cloud-Resource\" data-toc-modified-id=\"Machine-Learning-Cloud-Resource-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Machine Learning Cloud Resource<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Cloud-Computing-for-Machine-Learning-Work\" data-toc-modified-id=\"Cloud-Computing-for-Machine-Learning-Work-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;<\/span>Cloud Computing for Machine Learning Work<\/a><\/span><\/li><li><span><a href=\"#Relational-database-management-system-(RDBMS)-&amp;-Big-Data\" data-toc-modified-id=\"Relational-database-management-system-(RDBMS)-&amp;-Big-Data-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;<\/span>Relational database management system (RDBMS) &amp; Big Data<\/a><\/span><\/li><li><span><a href=\"#Hosted-Notebooks\" data-toc-modified-id=\"Hosted-Notebooks-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;<\/span>Hosted Notebooks<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Machine-Learning-Algorithom-Analysis\" data-toc-modified-id=\"Machine-Learning-Algorithom-Analysis-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>Machine Learning Algorithom Analysis<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#The-metric-to-determine-Model-Performance\" data-toc-modified-id=\"The-metric-to-determine-Model-Performance-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>The metric to determine Model Performance<\/a><\/span><\/li><li><span><a href=\"#Select-any-activities-that-make-up-an-important-part-of-your-role-at-work:\" data-toc-modified-id=\"Select-any-activities-that-make-up-an-important-part-of-your-role-at-work:-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>Select any activities that make up an important part of your role at work:<\/a><\/span><\/li><li><span><a href=\"#Exploring-unfair-bias-in-dataset-and\/or-algorithm\" data-toc-modified-id=\"Exploring-unfair-bias-in-dataset-and\/or-algorithm-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;<\/span>Exploring unfair bias in dataset and\/or algorithm<\/a><\/span><\/li><li><span><a href=\"#Evaluation-Metirc\" data-toc-modified-id=\"Evaluation-Metirc-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;<\/span>Evaluation Metirc<\/a><\/span><\/li><li><span><a href=\"#tools-and-methods-do-you-use-to-make-your-work-easy-to-reproduce\" data-toc-modified-id=\"tools-and-methods-do-you-use-to-make-your-work-easy-to-reproduce-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;<\/span>tools and methods do you use to make your work easy to reproduce<\/a><\/span><\/li><li><span><a href=\"#What-barriers-prevent-you-from-making-your-work-even-easier-to-reuse-and-reproduce\" data-toc-modified-id=\"What-barriers-prevent-you-from-making-your-work-even-easier-to-reuse-and-reproduce-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;<\/span>What barriers prevent you from making your work even easier to reuse and reproduce<\/a><\/span><\/li><li><span><a href=\"#Is-ML-model-Black-boxes-or-White-boxes\" data-toc-modified-id=\"Is-ML-model-Black-boxes-or-White-boxes-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;<\/span>Is ML model Black boxes or White boxes<\/a><\/span><\/li><li><span><a href=\"#Primary-tool-to-analyze-dataset\" data-toc-modified-id=\"Primary-tool-to-analyze-dataset-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;<\/span>Primary tool to analyze dataset<\/a><\/span><\/li><\/ul><\/li><\/ul><\/div>","82019ef1":"### Massive open online course (MOOC)","f7e59e24":"### Glimpse dataset\nLet's look top five rows in the dataset","171f4114":"### Select any activities that make up an important part of your role at work:","cbb31cc0":"* Kaggle Kernels, Google Colab, Azure Notebook.. ect are Jupyter notebook environment that requires no setup and runs entirely in the cloud. As many as 7000 respondents are not using any of the hosted notebooks. Kaggle Kernels, JupyterHub, Google Colab are top in the list.","935473d2":"### Cloud Computing for Machine Learning Work\nEnter cloud-based machine-learning solutions from the big three public cloud providers: Google, AWS, and Microsoft. They are very different from each other but share some commonality, advantages, and limitations.","eb131c51":"Inference:\n* Top data visualization libraries are used by Python user's are Matplotlib, Seaborn, Plotly and by R user's are ggplot2, shiny. GGplot2 is one best library for visualization widely used by R, it can also be used by Python user by installing plotnine or ggplot python version. Plotly is a javascript backend library available for both Python and R user. It is gaining popularity nowadays. It has beautiful interactive capabilities.","a63310aa":"### Current yearly compensation \n(approximate '$USD')","196a6956":"Inference:\n* Top Machine learning library is Scikit Learn, random Forest, Xgboost, Caret, lightgbm ...etc are used nowadays widely in the industry. Top deep learning libraries are TensorFlow, Keras, PyTorch, ..etc are used nowadays widely in the industry.","095fb8cb":"Inference:\n* In Industry type of respondent 25% of mention there working industry as Computers\/Technology and 21% of mentioned that they are students. This is bit misleading when we compare to the current role, where 22% and 18% of respondents are students, Data scientist respectively. It clearly says that few students mentioned as Computer\/Technology as their industry instead of mentioning has *\" I am student\"*\n* About 12% respondent are working in the education sector, it clearly indicates that after Computer\/ IT industry education sectors is deploying Machine learning Technique.\n* Around 5% of respondents all combine together working in the manufacturing, Energy, Mining and Defense industry. ","83238dd4":"Inference:\n* Computer science under graduate domnated in the survey participants followed by engineering(non - computer focused).\n* The third and fourth position of undergraduate major is Math or Stats and A business disciple.\n* It is realy interesting to see varity of diffirent major people such as Fine arts, Environmental science, Social science, Humanities in kaggle community.","8fe0fd1a":"### Data Science Training\nWhat percentage of your current machine learning\/data science training falls under each category?","35c1367e":"United States Of America:\n* Computer science Engineering major accounts for 26% respondents and Engineering(Non-computer) accounts for 16% respondents of respondents in the survey. Around 42% of respondents are engineering disciplines. There are 15% Math or Stats major in survey result. \n* In the USA there is wast diversity of Education among the data professionals compared to other top 3 countries. \n\nIndia:\n* There is 55% respondents are Computer science major, followed by 24% of respondents have Non-Computer focused Engineering  disciplines. Among the top 4 countries, we clearly see engineering is preferred choice compared to other types of undergraduate major. Around 79% of respondents major is engineering disciplines in India.\n* Math or Stats accounts for 6% respondent, which least among the 3 countries. Very fewer people are in data science profession compared to other top countries.\n\nChina:\n* There is 46% and 14% of respondents are Computer science and Non-computer focused Engineering undergraduate major.  Around 60% of respondents are engineering major. \n* Information technology, Networking is the top respondent in China compared to other top countries.\n* There are 11% of respondents are Math or Stats major when compared to India is only 6% respondents.\n\nRusia:\n* It is really interesting to see undergraduate major disciple when compared to other countries. There is 18% respondents are Math or Stats major which is top among the other 3 countries. \n* There is 42% respondents are computer science major, followed by 8% of respondents are Engineering (Non-computer focused). It is least compared to other top 3 countries.","e3982ea8":"Inference:\n* Most of the respondent have 0-1 year of experience followed by 1-2 years of experience in the industry. Less than 2% of the respondent has more than 20 years of experience in the industry.","62cb5684":"### What barriers prevent you from making your work even easier to reuse and reproduce","09a3d4d3":"### Work Experience of Data Professionals","312ea1bd":"### Programming Lannguage","5cde098f":"### Gender and Age\nLet's look at gender and age of participants","c8dc0128":"Inference:\n* Most of data scientist and data analyst from age group 25-29. ","3db3b9b0":"Inference:\n* If want to be a Data Scientist there is 55% change that you should have Master's Degree when compared to 20% change of that you have Bachelor's Degree. There are 18% of Data Scientist have PhD (Doctoral Degree).\n* About 51% of Data Analyst have Master degree and 33% of them have Bachelor's Degree, Only 6% of them have Phd (Doctoral degree).\n* We find that Master's Degree is prefered choice to start career as Data Analyst \/ Data Scientist \/ Data Engineer. More than 50% of professional have Master's Degree.","5ca4b321":"### Quality of MOOC vs Traditional Institution\nHow do you perceive the quality of online learning platforms and in-person bootcamps as compared to the quality of the education provided by traditional brick and mortar institutions?","6baa752c":"### Coding Skill and Experience","78501d24":"### Programming Laguage Recommended for Aspiring Data Scientist\nLet's look at programmming language recommandation for Machine Learning development.","3e413211":"### Relational database management system (RDBMS) & Big Data\nA relational database management system (RDBMS) is a collection of programs and capabilities that enable IT teams and others to create, update, administer and otherwise interact with a relational database. Most commercial RDBMSes use Structured Query Language (SQL) to access the database.\n\nBig data is a term that describes the large volume of data \u2013 both structured and unstructured \u2013 that inundates a business on a day-to-day basis. But it\u2019s not the amount of data that\u2019s important. It\u2019s what organizations do with the data that matters. Big data can be analyzed for insights that lead to better decisions and strategic business moves.","f9aa0371":"> Graduate major from top 4 countries\n\nLet's look at graduates from top4 countries","7bb5aaad":"### Current Role\n","e743a7ef":"### Public data resource","76f16dad":"Inference\n*  Multiple Choice Response dataset consists of 395 columns. When we look at the survey Schema dataset there are around 50 Questions. There is a lot of missing value in the dataset.\n* The column names is itself question in the dataset, so the column names are very long. The first row is skipped while importing dataset.\n* There are 35 different types of response apart from the Multiple choice response. This majorly contains text information.","61f18e86":"## Machine Learning Algorithom Analysis\nIn order to evaluate the machine learning models, you will have to know the basic performance metrics of models. For example, accuracy, precision, recall, F1-score, or AUC values are important measures for classifiers and Mean Square Error, RMSE, MAE, R Square for regression model.","879d9c2e":"###  Graduate Major","03d01fb5":"\n### In which country do you currently reside?\nLet's look at the response from different part of the world.","c4d6e218":"### Usefull functions","6dd15307":"### Import library","5b769e5b":"### Import dataset\nThere are three different datasets provide by the kaggle. multipleChoiceResponses.csv dataset consist of survey participants response and freeFormResponses.csv dataset consist of response other than the Multiple choice options. SurveySchema.csv consist of all questions and options."}}