{"cell_type":{"b85773ab":"code","2edb77ab":"code","db85fdab":"code","c302d3cb":"code","5d2aa117":"code","a9e80249":"code","8ade6a92":"code","53317b09":"code","c6615c2b":"code","c3b6a931":"code","3323add6":"code","2e0e1e0c":"code","0905c9a7":"code","30f1a143":"code","2d1491e1":"code","c73e8ea0":"code","a4ea13bd":"code","6ed9cf5b":"code","6850fbef":"code","45677755":"code","c77cd679":"code","6ec416a6":"code","5af39f1a":"code","b36bdcaa":"code","2d3e9e3e":"code","8b50953f":"code","be93e823":"code","cbce8dad":"code","69a07b6b":"code","80beba5e":"code","9e0a99df":"code","47f4c2fc":"code","7bc9ab47":"code","519bb4ee":"code","c495cf18":"code","024c3043":"code","8d0fbb86":"markdown","792fe0b3":"markdown","3aa31cff":"markdown","70025827":"markdown","828f272e":"markdown","bf65e093":"markdown","ebb534c1":"markdown","7df092d9":"markdown","971dc8d2":"markdown","71dbeae6":"markdown"},"source":{"b85773ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2edb77ab":"sample = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nshops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nitems = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cat = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nsales = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')","db85fdab":"def EDA(data):\n    print(\"-----------Top-5-Record---------\")\n    print(data.head(5))\n    print(\"-----------Information---------\")\n    print(data.info())\n    print(\"-----------Data types---------\")\n    print(data.dtypes)\n    print(\"-----------Missingvalue---------\")\n    print(data.isnull().sum())\n    print(\"-----------Null value---------\")\n    print(data.isna().sum())\n    print(\"-----------shape of data---------\")\n    print(data.shape)\n          \ndef graph_insight(data):\n    print(set(data.dtypes.tolist()))\n    df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num.hist(figsize = (16,16), bins=50, xlabelsize = 8, ylabelsize = 8)\n\ndef drop_duplicate(data, subset):\n    print('Before drop shape:', data.shape)\n    before = data.shape[0]\n    data.drop_duplicates(subset, keep ='first', inplace = True)\n    # subset is list of columns for duplicate check\n    data.reset_index(drop = True, inplace = True)\n    print('After drop shape:', data.shape)\n    after= data.shape[0]\n    print('Total Duplicate:', before-after)","c302d3cb":"EDA(sales)","5d2aa117":"sales.columns","a9e80249":"graph_insight(sales)","8ade6a92":"# Drop duplicate data\nsubset = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_cnt_day']\ndrop_duplicate(sales, subset =subset)","53317b09":"EDA(test)\ngraph_insight(test)","c6615c2b":"EDA(items)\ngraph_insight(items)","c3b6a931":"EDA(item_cat)\ngraph_insight(item_cat)","3323add6":"def unreasonable_data(data):\n    print(\"min value:\", data.min())\n    print('max value:', data.max())\n    print('average value: ', data.mean())\n    print('center point of data:', data.median())","2e0e1e0c":"unreasonable_data(sales)","0905c9a7":"print(sales['item_price'].mean())\nprint(sales['item_price'].std())","30f1a143":"# -1 and 307980 looks like outliers, let's delete them\nprint('before sales shape:', sales.shape)\nsales = sales[(sales.item_price > 0) & (sales.item_price < 300000)]\nprint('after sales shape:', sales.shape )","2d1491e1":"sales.info()","c73e8ea0":"sales.head()","a4ea13bd":"plt.figure(figsize=(20,4))\nsales.groupby('date_block_num').sum()['item_cnt_day'].plot()","6ed9cf5b":"sales.groupby('date_block_num').sum()['item_cnt_day'].hist(figsize = (20, 4))\nplt.title('sales per month histogram')\nplt.xlabel('Price')\nplt.figure(figsize = (20,4))\nsns.lineplot(x =sales.date_block_num.unique() , y = sales.groupby('date_block_num').sum()['item_cnt_day'])\nplt.title('sales per month')\nplt.xlabel('Price')","6850fbef":"unreasonable_data(sales['item_price'])","45677755":"count_price = sales.item_price.value_counts().sort_index(ascending = False)\nplt.subplot(221)\ncount_price.hist(figsize = (20,6))\nplt.xlabel('Item Price', fontsize =20)\nplt.title('Original Distribution')\n\nplt.subplot(222)\nsales.item_price.map(np.log1p).hist(figsize = (20,6))\nplt.xlabel('Item Price')\nplt.title('log1p Transformation')\nsales.loc[:, 'item_price'] = sales.item_price.map(np.log1p)","c77cd679":"unreasonable_data(sales.date_block_num)","6ec416a6":"count_price = sales.date_block_num.value_counts().sort_index(ascending = False)\nplt.subplot(221)\ncount_price.hist(figsize = (20,5))\nplt.xlabel('Date Block')\nplt.title('Original Distribution')\n\ncount_price = sales.shop_id.value_counts().sort_index(ascending = False)\nplt.subplot(222)\ncount_price.hist(figsize = (20,5))\nplt.xlabel('shop_id')\nplt.title('original distribution')\n\ncount_price = sales.item_id.value_counts().sort_index(ascending = False)\nplt.subplot(223)\ncount_price.hist(figsize=(20,5))\nplt.xlabel('item_id')\nplt.title('original distribution')","5af39f1a":"l = list(item_cat.item_category_name)\nl_cat = l\n\nfor ind in range(1,8):\n    l_cat[ind] = 'Access'\n    \nfor ind in range(10,18):\n    l_cat[ind] = 'Consoles'\n\nfor ind in range(18,25):\n    l_cat[ind] = 'Consoles Games'\n\nfor ind in range(26,28):\n    l_cat[ind] = 'phone games'\n\nfor ind in range(28,32):\n    l_cat[ind] = 'CD games'\n\nfor ind in range(32,37):\n    l_cat[ind] = 'Card'\n\nfor ind in range(37,43):\n    l_cat[ind] = 'Movie'\n\nfor ind in range(43,55):\n    l_cat[ind] = 'Books'\n\nfor ind in range(55,61):\n    l_cat[ind] = 'Music'\n\nfor ind in range(61,73):\n    l_cat[ind] = 'Gifts'\n\nfor ind in range(73,79):\n    l_cat[ind] = 'Soft'\n\n\nitem_cat['cats'] = l_cat\nitem_cat.head()\n","b36bdcaa":"sales['date'] = pd.to_datetime(sales.date, format = '%d.%m.%Y')\nsales.head()","2d3e9e3e":"p_df = sales.pivot_table(index = ['shop_id', 'item_id'], columns ='date_block_num', values ='item_cnt_day', aggfunc = 'sum').fillna(0.0)\np_df","8b50953f":"# join with categories\nsales_cleaned_df = p_df.reset_index()\nsales_cleaned_df['shop_id'] = sales_cleaned_df.shop_id.astype('str')\nitem_to_cat_df = items.merge(item_cat[['item_category_id', 'cats']], how = 'inner', on = 'item_category_id')[['item_id', 'cats']]\n#item_to_cat_df[['item_id']] = item_to_cat_df.item_id.astype('str')\nsales_cleaned_df = sales_cleaned_df.merge(item_to_cat_df, how = 'inner', on = 'item_id')\n\n# Encode Categories\nfrom sklearn import preprocessing\n\nnumber = preprocessing.LabelEncoder()\nsales_cleaned_df[['cats']] = number.fit_transform(sales_cleaned_df.cats)\nsales_cleaned_df = sales_cleaned_df[['shop_id', 'item_id', 'cats'] + list(range(34))]\nsales_cleaned_df.head()","be93e823":"import xgboost as xgb\nparam = {'max_depth':10,\n        'subsample': 1,\n        'min_child_weight': 0.5,\n        'eta': 0.3,\n        'num_round': 1000,\n        'seed': 1, \n        'silend': 0,\n        'eval_metric': 'rmse'}\nprogress = dict()\nxgbtrain = xgb.DMatrix(sales_cleaned_df.iloc[:, (sales_cleaned_df.columns != 33)].values, sales_cleaned_df.iloc[:, sales_cleaned_df.columns == 33].values)\nwatchlist = [(xgbtrain, 'train-rmse')]\n\nbst = xgb.train(param, xgbtrain)\npreds = bst.predict(xgb.DMatrix(sales_cleaned_df.iloc[:,(sales_cleaned_df.columns != 33)].values))\n\nfrom sklearn.metrics import mean_squared_error\nrmse = np.sqrt(mean_squared_error(preds, sales_cleaned_df.iloc[:, sales_cleaned_df.columns == 33].values))\nprint(rmse)","cbce8dad":"xgb.plot_importance(bst)","69a07b6b":"test.info()","80beba5e":"sales_cleaned_df.info()","9e0a99df":"apply_df = test\napply_df['shop_id'] = apply_df.shop_id.astype('str')\napply_df['item_id'] = apply_df.item_id.astype('str')\nsales_cleaned_df['shop_id'] = sales_cleaned_df.shop_id.astype('str')\nsales_cleaned_df['item_id'] = sales_cleaned_df.item_id.astype('str')\napply_df = test.merge(sales_cleaned_df, how = 'left', on = ['shop_id', 'item_id']).fillna(0.0)\napply_df.head()","47f4c2fc":"# move to one month front\nd = dict(zip(apply_df.columns[4:], list(np.array(list(apply_df.columns[4:])) -1)))\n\napply_df = apply_df.rename(d, axis = 1)\n         ","7bc9ab47":"apply_df.head()","519bb4ee":"preds = bst.predict(xgb.DMatrix(apply_df.iloc[:, (apply_df.columns != 'ID') & (apply_df.columns != -1)].values))","c495cf18":"# normalize prediction to [0-20]\npreds = list(map(lambda x: min(20, max(x,0)), list(preds)))\n\nsub_df = pd.DataFrame({'ID': apply_df.ID, 'item_cnt_month': preds})\nsub_df.describe()","024c3043":"sub_df.to_csv('Submission_Predict Sales.csv', index = False)","8d0fbb86":"# Map the Items","792fe0b3":"# ****EDA****","3aa31cff":"# Sales per month count","70025827":"# Distribution checking","828f272e":"# Model Building","bf65e093":"**Functions**","ebb534c1":"item","7df092d9":"Convert Date Column data type from object to date","971dc8d2":"item category","71dbeae6":"****2. Test Data****"}}