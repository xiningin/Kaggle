{"cell_type":{"510b6fa9":"code","88dab4ef":"code","681eb841":"code","48ab7456":"code","2c8af85e":"code","45a5ee3b":"code","2a2e1677":"code","c7cfec5e":"code","b96e76dd":"code","4ccefc3f":"code","f53b0e43":"code","ad5795cb":"code","485c71c4":"code","6dac2b0b":"code","79613ae2":"code","53494517":"code","4e90ef76":"code","162bd125":"code","daffec6a":"code","8d89f054":"code","d3a0269c":"code","a0ed4e94":"code","ef2f55ef":"code","f95c66f4":"code","eff744d4":"code","5f09d5af":"code","cd8e2319":"code","b109d46b":"markdown","536f6bb8":"markdown","435268b8":"markdown"},"source":{"510b6fa9":"import numpy as np\nimport pandas as pn\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\n\nimport tensorflow_datasets as tfds\n\nfrom transformers import BertTokenizer\nfrom transformers import TFBertForSequenceClassification","88dab4ef":"dataset, info = tfds.load(name='imdb_reviews', as_supervised=True, with_info=True)\n\ntrain_ds = dataset['train']\ntest_ds = dataset['test']","681eb841":"bert_name = 'bert-base-cased'\n\ntokenizer = BertTokenizer.from_pretrained(bert_name,\n                                          add_special_tokens=True, \n                                          do_lower_case=False, \n                                          max_length=150, \n                                          pad_to_max_length=True)","48ab7456":"tokenizer.encode_plus(\" Don't be lured\", \n                      add_special_tokens=True, \n                      max_length=15, padding='max_length',\n                      pad_to_max_length=True,\n                      return_attention_mask=True,\n                      return_token_type_ids=True)","2c8af85e":"def bert_encoder(review):\n    text = review.numpy().decode('utf-8')\n    encoded = tokenizer.encode_plus(text, add_special_tokens=True,\n                                    max_length=150,\n                                    padding='max_length',\n                                    truncation=True,\n                                    return_attention_mask=True,\n                                    return_token_type_ids=True)\n    \n    return encoded['input_ids'], encoded['token_type_ids'], encoded['attention_mask']","45a5ee3b":"# prepare training dataset\n\nbert_train = [bert_encoder(review) for review, label in train_ds]\nbert_train = np.array(bert_train)\n\nbert_train_label = np.array([label for _, label in train_ds])\nbert_train_label = keras.utils.to_categorical(bert_train_label, num_classes=2)","2a2e1677":"# split training data into training and validation sets\n\nX_train, X_valid, y_train, y_valid = train_test_split(bert_train, \n                                                      bert_train_label, \n                                                      test_size=0.2, \n                                                      random_state=101)\n\nX_train.shape, y_train.shape","c7cfec5e":"# X_train[0]","b96e76dd":"train_reviews, train_segments, train_masks = np.split(X_train, 3, axis=1)\nvalid_reviews, valid_segments, valid_masks = np.split(X_valid, 3, axis=1)\n\ntrain_reviews = train_reviews.squeeze()\ntrain_segments = train_segments.squeeze()\ntrain_masks = train_masks.squeeze()\n\nvalid_reviews = valid_reviews.squeeze()\nvalid_segments = valid_segments.squeeze()\nvalid_masks = valid_masks.squeeze()","4ccefc3f":"# train_reviews[0], train_segments[0], train_masks[0]","f53b0e43":"def example_to_feature(input_ids, attention_masks, token_type_ids, y):\n    data= {\"input_ids\":input_ids,\n           \"attention_masks\":attention_masks,\n           \"token_type_ids\":token_type_ids}\n    return data, y","ad5795cb":"train_ds = tf.data.Dataset.from_tensor_slices((train_reviews, train_masks, train_segments, y_train))\ntrain_ds = train_ds.map(example_to_feature).shuffle(100).batch(16)\n\nvalid_ds = tf.data.Dataset.from_tensor_slices((valid_reviews, valid_masks, valid_segments, y_valid))\nvalid_ds = valid_ds.map(example_to_feature).shuffle(100).batch(16)","485c71c4":"bert_model = TFBertForSequenceClassification.from_pretrained(bert_name)\n\n\noptimizer = keras.optimizers.Adam(learning_rate=2e-5)\nloss = keras.losses.BinaryCrossentropy(from_logits=True)\n\nbert_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n\nbert_model.summary()","6dac2b0b":"history = bert_model.fit(train_ds, epochs=3, validation_data=valid_ds)","79613ae2":"## Prepare testing data\n\nbert_test = np.array([bert_encoder(review) for review, _ in test_ds])\nbert_test_label = np.array([label for _, label in test_ds])\nbert_test_label = keras.utils.to_categorical(bert_test_label, num_classes=2)\n\n\ntest_reviews, test_segments, test_masks = np.split(bert_test, 3, axis=1)\ntest_reviews = test_reviews.squeeze()\ntest_segments = test_segments.squeeze()\ntest_masks = test_masks.squeeze()\n\n\ntest_ds = tf.data.Dataset.from_tensor_slices((test_reviews, test_masks, test_segments, bert_test_label))\ntest_ds = test_ds.map(example_to_feature).shuffle(100).batch(16)","53494517":"bert_model.evaluate(test_ds)","4e90ef76":"from transformers import TFBertModel","162bd125":"bert_name = 'bert-base-cased'\nbert = TFBertModel.from_pretrained(bert_name)\nbert.summary()","daffec6a":"max_seq_len = 150\ninp_ids = Input((max_seq_len,), dtype=tf.int64, name=\"input_ids\")\natt_masks = Input((max_seq_len,), dtype=tf.int64, name=\"attention_mask\")\nseg_ids = Input((max_seq_len,), dtype=tf.int64, name=\"token_type_ids\")\n\n# Above names need to be matched with the dictionary ddefined in training and testing dataset\n\ntrain_ds.element_spec","8d89f054":"inp_dict = {\"input_ids\":inp_ids,\n           \"attention_masks\":att_masks,\n           \"token_type_ids\":seg_ids}\n\noutputs = bert(inp_dict)\n\n# see the output structure\noutputs","d3a0269c":"x = Dropout(0.2)(outputs[1])\nx = Dense(200, activation='relu')(x)\nx = Dropout(0.2)(x)\nx = Dense(2, activation='sigmoid')(x)\n\ncustom_model = Model(inputs=inp_dict, outputs=x)","a0ed4e94":"optimizer = keras.optimizers.Adam(learning_rate=2e-5)\nloss = keras.losses.BinaryCrossentropy(from_logits=True)\n\ncustom_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n\ncustom_model.summary()","ef2f55ef":"custom_history = custom_model.fit(train_ds, epochs=3, validation_data=valid_ds)","f95c66f4":"custom_model.evaluate(test_ds)","eff744d4":"bert.trainable = False\n\noptimizer = keras.optimizers.Adam(learning_rate=2e-5)\nloss = keras.losses.BinaryCrossentropy(from_logits=True)\n\ncustom_model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n\ncustom_model.summary()","5f09d5af":"custom_history = custom_model.fit(train_ds, epochs=5, validation_data=valid_ds)","cd8e2319":"custom_model.evaluate(test_ds)","b109d46b":"### Freezing BERT layers","536f6bb8":"## Custom Model with BERT","435268b8":"## Pre-bulid BERT Classification Model"}}