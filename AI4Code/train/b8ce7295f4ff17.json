{"cell_type":{"61a9fbaf":"code","24bb44f0":"code","a9e4bbef":"code","404921dc":"code","48dfe966":"code","a84d353f":"code","a39b34aa":"code","f24c17f7":"code","aa4dca7a":"code","ffac7051":"code","8aa1390f":"code","a4c7e524":"code","e7bbb6ed":"code","bf5920ac":"code","d355de62":"code","0e5adda3":"code","755965d2":"code","f56eaaba":"code","0d857418":"code","cfde6591":"code","e3082bf2":"code","381aa790":"code","ccca0bb4":"code","3bad32da":"code","28131081":"code","2cede695":"code","05957dca":"code","6a18f49b":"code","b735a336":"code","d9781834":"code","2d6e26d5":"code","d3148722":"code","8c8bb86d":"code","6ca6cc15":"code","5f3bc9ca":"code","f04d85d1":"code","16ae01f5":"code","9fe53778":"code","4846f193":"code","a16dee1a":"code","d2ec27a2":"code","9cb03acc":"code","6bd61d54":"code","12e340d6":"code","4ea62fd7":"code","0f0f62e3":"code","9ad231e9":"code","aeebeb91":"code","7209f2b1":"code","fd8d8b8c":"code","a665c2a7":"code","215b76ef":"code","1db40372":"code","93fc1e76":"code","d3eb361d":"code","2e35561c":"code","dcb941f5":"code","122a5497":"code","db3c996b":"code","a5609608":"code","15b2ac56":"code","4a3dcaa5":"code","f4b88d04":"code","f99785d3":"code","9d932eb8":"code","3ef0f521":"code","c0e84d62":"code","afdcc162":"code","fb0d4895":"code","01a3e0ad":"code","bb1862d0":"code","6d00371f":"code","c5f9305e":"code","12d51940":"code","506bbabb":"code","87f67432":"code","5ca962c2":"code","1d90f676":"code","86c03f41":"code","c72bf212":"code","76d9bcf4":"code","56bda785":"code","70277e78":"code","260edfbc":"code","4859535e":"code","c70ced74":"code","0ce3741f":"code","475bbb73":"code","4b024894":"code","8874a8f0":"code","a5111a40":"code","b3c2f5cf":"code","0bd40310":"code","64e6220f":"code","8be96ebb":"code","3d6c15c2":"code","0f81d1fe":"code","ac4a89f0":"code","a7b82047":"code","b653597b":"code","19446a39":"code","a81e3264":"code","052ff373":"code","4faaca24":"code","ad5296ad":"code","b8e3e536":"code","fc66f342":"code","d5c1333e":"code","809fa7de":"code","01311ed0":"code","25bfc795":"code","63419193":"code","a62724eb":"code","76926871":"code","8cabda4d":"code","8e2ec238":"code","4774f273":"code","fbc52a32":"code","da917dbb":"code","29fab6f5":"code","81366a7b":"code","6e947e93":"code","b60ece84":"code","9de5ab88":"code","2c8485cb":"code","2722d92c":"code","274c3cbc":"code","7a3b4bab":"code","03b9738b":"code","0292c47d":"code","27bd7016":"code","df76f196":"code","b9aae1e0":"code","517b4a74":"code","048a9d09":"code","cae2550c":"code","ada1da24":"code","2e2982b5":"code","b09110cb":"code","8a044711":"code","88cb555c":"code","09176ed6":"code","2ff63604":"code","2535eca8":"code","fd2a512e":"code","a41af27d":"code","7c70ce9f":"code","8c0ae493":"code","edbba685":"code","5db41f49":"code","a21a79fe":"code","40a89f2d":"code","db544da7":"code","0ce57541":"code","de2b3b46":"code","80c0b63c":"code","1f87d673":"code","5daa6a48":"code","384d6ce7":"code","38abbc47":"code","213036d4":"code","23a73ed3":"code","26116754":"code","0f928706":"code","90ae38ba":"code","0c800de0":"code","8a29a337":"code","2e701846":"code","1350a72f":"code","9522cf65":"code","9656df51":"code","6b78aa23":"code","b1139bc0":"markdown","107b0a30":"markdown","223bda10":"markdown","a95cd784":"markdown","b6dc8fa0":"markdown","5806786c":"markdown","f470c4f6":"markdown","778fe449":"markdown","055ec13a":"markdown","64dad40f":"markdown","d9471276":"markdown","9afc3721":"markdown","63881261":"markdown","57c085a0":"markdown","ecadd1d4":"markdown","f34878b0":"markdown","8e37b06e":"markdown","b51ca108":"markdown","b1bd1418":"markdown","405532f4":"markdown","e461ed7d":"markdown","5d165945":"markdown","cdc5a305":"markdown","4507476d":"markdown","c75bb79d":"markdown","1280c6dc":"markdown","82980c4d":"markdown","587713ee":"markdown","840b7dbc":"markdown","88ece645":"markdown","007bdbd9":"markdown","df41d6d0":"markdown","102ff482":"markdown","f0465a9f":"markdown","e71d77e6":"markdown","6ab30859":"markdown","ea15b678":"markdown","f718c76a":"markdown","a5682f0c":"markdown","f4e16ba4":"markdown","fdfd051b":"markdown","452d62c1":"markdown","2fc6d8c6":"markdown","b1a95ca8":"markdown","93e55309":"markdown","8be482dd":"markdown","487d5a74":"markdown","af05afb1":"markdown","d5ee23d5":"markdown","4dc77dc1":"markdown","b85b5872":"markdown","a5e51b01":"markdown","a19a43e2":"markdown","02ac4254":"markdown","b82c916f":"markdown","395ce4c8":"markdown","95afb1c0":"markdown","51883869":"markdown","701f8f18":"markdown","b4f7a631":"markdown","534fef73":"markdown","a842ec74":"markdown","480fe9b1":"markdown","308711cb":"markdown","e1471534":"markdown","fdad79fb":"markdown","a8f46748":"markdown","82889b4d":"markdown","ae8370e4":"markdown","33d7d57e":"markdown","6db1a16a":"markdown","f0074e71":"markdown"},"source":{"61a9fbaf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport warnings\nwarnings.filterwarnings('ignore')","24bb44f0":"import seaborn as sns\nfrom scipy.stats import spearmanr, chi2_contingency, mannwhitneyu, shapiro\nfrom sklearn.preprocessing import scale \nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve\nimport matplotlib.pyplot as plt\nimport missingno as msn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","a9e4bbef":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","404921dc":"test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","48dfe966":"train.head()","a84d353f":"train[\"Survived\"].value_counts()","a39b34aa":"test.head()","f24c17f7":"dataset=pd.concat([train, test], ignore_index=True)","aa4dca7a":"dataset.info()","ffac7051":"dataset.Pclass.value_counts()","8aa1390f":"dataset.Sex.value_counts()","a4c7e524":"dataset.SibSp.value_counts()","e7bbb6ed":"dataset.Parch.value_counts()","bf5920ac":"dataset.Ticket.value_counts()","d355de62":"dataset.Cabin.value_counts()","0e5adda3":"dataset.Embarked.value_counts()","755965d2":"train.isnull().any()","f56eaaba":"msn.matrix(train);","0d857418":"msn.heatmap(train);","cfde6591":"train.Age.isnull().sum()","e3082bf2":"print(train.Age.skew())\nprint(train.Age.kurtosis())","381aa790":"train.Age.fillna(train.Age.median(), inplace=True)","ccca0bb4":"train.Embarked.value_counts()","3bad32da":"train.Embarked.isnull().sum()","28131081":"train.Embarked.fillna(\"S\", inplace=True)","2cede695":"train.Cabin.isnull().sum()","05957dca":"train.Cabin.value_counts()","6a18f49b":"train.Cabin=np.where(train.Cabin.isnull(), \"unknown\", train.Cabin)","b735a336":"train.isnull().any()","d9781834":"train.head()","2d6e26d5":"test.isnull().any()","d3148722":"msn.matrix(test);","8c8bb86d":"msn.heatmap(test);","6ca6cc15":"test.select_dtypes(exclude=\"object\").describe().T","5f3bc9ca":"test.Age.isnull().sum()","f04d85d1":"print(test.Age.skew())\nprint(test.Age.kurtosis())","16ae01f5":"test.Age.fillna(test.Age.median(), inplace=True)","9fe53778":"test.Fare.isnull().sum()","4846f193":"test.Fare.fillna(test.Fare.median(), inplace=True)","a16dee1a":"test.Cabin.isnull().sum()","d2ec27a2":"test.Cabin=np.where(test.Cabin.isnull(), \"unknown\", test.Cabin)","9cb03acc":"test.isnull().any()","6bd61d54":"test.head()","12e340d6":"train.head()","4ea62fd7":"train.select_dtypes(exclude=\"object\").describe().T","0f0f62e3":"sns.set(rc={'figure.figsize': (8, 8)})\nsns.boxplot(x=train.Fare,orient=\"v\");","9ad231e9":"Q1=train.Fare.quantile(0.25)\nQ3=train.Fare.quantile(0.75)\nIQR=Q3-Q1\n\nlower_limit=Q1-1.5*IQR\nupper_limit=Q3+1.5*IQR\nIQR,lower_limit,upper_limit","aeebeb91":"freq_outliers = ((train.Fare < lower_limit) | (train.Fare > upper_limit)).value_counts()\nfreq_outliers","7209f2b1":"outliers_bool = ((train.Fare < lower_limit) | (train.Fare > upper_limit))\noutliers_bool.head()","fd8d8b8c":"outliers=train.Fare[outliers_bool]","a665c2a7":"outliers.head()","215b76ef":"train.Fare[outliers_bool]=train.Fare.median()\ntrain.Fare[outliers_bool]","1db40372":"train.describe().T","93fc1e76":"train[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]].corr(method=\"spearman\")","d3eb361d":"spearmanr(train.SibSp, train.Fare)","2e35561c":"spearmanr(train.Fare, train.Parch)","dcb941f5":"spearmanr(train.SibSp, train.Parch)","122a5497":"X=train.copy()","db3c996b":"import time\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor    \nfrom joblib import Parallel, delayed\n\n# Defining the function that you will run later\ndef calculate_vif_(X, thresh=5.0):\n    variables = [X.columns[i] for i in range(X.shape[1])]\n    dropped=True\n    while dropped:\n        dropped=False\n        print(len(variables))\n        vif = Parallel(n_jobs=-1,verbose=0)(delayed(variance_inflation_factor)(X[variables].values, ix) for ix in range(len(variables)))\n\n        maxloc = vif.index(max(vif))\n        if max(vif) > thresh:\n            print(time.ctime() + ' dropping \\'' + X[variables].columns[maxloc] + '\\' at index: ' + str(maxloc))\n            variables.pop(maxloc)\n            dropped=True\n\n    print('Remaining variables:')\n    print([variables])\n    return X[[i for i in variables]]\n\nX = X[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]] # Selecting your data\n\nX2 = calculate_vif_(X,5) # Actually running the function","a5609608":"pd.crosstab(train.Survived, train.Pclass, margins=True, margins_name=\"Total\")","15b2ac56":"obs=np.matrix(pd.crosstab(train.Survived, train.Pclass))","4a3dcaa5":"chi2_contingency(obs)","f4b88d04":"pd.crosstab(train.Survived, train.Sex, margins=True, margins_name=\"Total\")","f99785d3":"obs=np.matrix(pd.crosstab(train.Survived, train.Sex))","9d932eb8":"chi2_contingency(obs)","3ef0f521":"pd.crosstab(train.Survived, train.SibSp, margins=True, margins_name=\"Total\")","c0e84d62":"obs=np.matrix(pd.crosstab(train.Survived, train.SibSp))","afdcc162":"chi2_contingency(obs)","fb0d4895":"pd.crosstab(train.Survived, train.Parch, margins=True, margins_name=\"Total\")","01a3e0ad":"obs=np.matrix(pd.crosstab(train.Survived, train.Parch))","bb1862d0":"chi2_contingency(obs)","6d00371f":"train[\"Cabin\"]=train[\"Cabin\"].map(lambda x: str(x)[:1])","c5f9305e":"pd.crosstab(train.Survived, train.Cabin, margins=True, margins_name=\"Total\")","12d51940":"obs=np.matrix(pd.crosstab(train.Survived, train.Cabin))","506bbabb":"chi2_contingency(obs)","87f67432":"pd.crosstab(train.Survived, [train.Pclass, train.Cabin], margins=True, margins_name=\"Total\")","5ca962c2":"pd.crosstab(train.Survived, train.Embarked, margins=True, margins_name=\"Total\")","1d90f676":"obs=np.matrix(pd.crosstab(train.Survived, train.Embarked))","86c03f41":"chi2_contingency(obs)","c72bf212":"train.groupby(\"Survived\")[\"Age\"].describe()","76d9bcf4":"plt.figure(figsize=(10,8))\n\nsns.boxplot(x=train.Survived, y=train.Age);","56bda785":"Age_0=train[train[\"Survived\"]==0][\"Age\"]","70277e78":"Age_1=train[train[\"Survived\"]==1][\"Age\"]","260edfbc":"shapiro(Age_0)","4859535e":"shapiro(Age_1)","c70ced74":"mannwhitneyu(Age_0, Age_1)","0ce3741f":"train.groupby(\"Survived\")[\"Fare\"].describe()","475bbb73":"plt.figure(figsize=(10,8))\n\nsns.boxplot(x=train.Survived, y=train.Fare);","4b024894":"Fare_0=train[train[\"Survived\"]==0][\"Fare\"]","8874a8f0":"Fare_1=train[train[\"Survived\"]==1][\"Fare\"]","a5111a40":"shapiro(Fare_0)","b3c2f5cf":"shapiro(Fare_1)","0bd40310":"mannwhitneyu(Fare_0, Fare_0)","64e6220f":"train.head()","8be96ebb":"test.head()","3d6c15c2":"# dataset is updated \n\ndataset=pd.concat([train, test])\ndataset = dataset[[train, test][0].columns]","0f81d1fe":"dataset.head()","ac4a89f0":"dataset[\"Pclass\"]=np.where(dataset[\"Pclass\"]==1, \"1st\", dataset[\"Pclass\"])","a7b82047":"dataset[\"Pclass\"]=np.where(dataset[\"Pclass\"]==\"2\", \"2nd\", dataset[\"Pclass\"])","b653597b":"dataset[\"Pclass\"]=np.where(dataset[\"Pclass\"]==\"3\", \"3th\", dataset[\"Pclass\"])","19446a39":"dataset[\"Cabin\"]=dataset[\"Cabin\"].map(lambda x: str(x)[:1])","a81e3264":"dataset.drop([\"Name\", \"Ticket\"], axis=1, inplace=True)","052ff373":"dataset.head(10)","4faaca24":"df=dataset.copy()","ad5296ad":"dms=pd.get_dummies(df[['Pclass', 'Sex', 'Cabin', 'Embarked']])","b8e3e536":"dms.head()","fc66f342":"y=df[\"Survived\"]","d5c1333e":"y.dropna(inplace=True)","809fa7de":"y.isnull().sum()","01311ed0":"y.shape","25bfc795":"df.head()","63419193":"X=df.drop([\"Survived\", \"PassengerId\", 'Pclass', 'Sex', 'Cabin','Embarked'], axis=1).astype(\"float64\")","a62724eb":"x = pd.concat([X, dms[['Pclass_2nd', \"Pclass_3th\", 'Sex_female',\"Cabin_B\",\"Cabin_C\",\"Cabin_D\", \"Cabin_E\",\"Cabin_F\", \"Cabin_G\" ,\"Cabin_T\", \"Cabin_u\", 'Embarked_S', \"Embarked_C\"]]], axis=1)","76926871":"x.head()","8cabda4d":"x_scaled=scale(x)","8e2ec238":"x_sc=pd.DataFrame(x_scaled, columns=['Age', 'SibSp', 'Parch', 'Fare',\n       'Pclass_2nd', 'Pclass_3th', 'Sex_female', 'Cabin_B', 'Cabin_C',\n       'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_T', 'Cabin_u',\n       'Embarked_S', 'Embarked_C'])","4774f273":"x_sc.head()","fbc52a32":"train_data=x_sc[0:len(train)]","da917dbb":"test_data=x_sc[len(train):]","29fab6f5":"test_data.reset_index(drop=True, inplace=True)","81366a7b":"train_data.tail()","6e947e93":"test_data.head()","b60ece84":"x_train, x_test, y_train, y_test = train_test_split(train_data, y, \n                                                    test_size = 0.30, \n                                                    random_state = 42)","9de5ab88":"loj = LogisticRegression(solver = \"liblinear\")\nloj_model = loj.fit(x_train,y_train)\nloj_model","2c8485cb":"y_pred=loj_model.predict(x_test)","2722d92c":"accuracy_score(y_test, loj_model.predict(x_test))","274c3cbc":"cross_val_score(loj_model, x_test, y_test, cv = 10).mean()","7a3b4bab":"nb = GaussianNB()\nnb_model = nb.fit(x_train, y_train)\nnb_model","03b9738b":"y_pred = nb_model.predict(x_test)\nprint(accuracy_score(y_test, y_pred))\ncross_val_score(nb_model, x_test, y_test, cv = 10).mean()","0292c47d":"knn = KNeighborsClassifier(23)\nknn_tuned = knn.fit(x_train, y_train)","27bd7016":"knn_tuned","df76f196":"y_pred = knn_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","b9aae1e0":"svc_tuned_linear=SVC(kernel = \"linear\", C = 1, probability=True, random_state=1)","517b4a74":"svc_tuned_linear.fit(x_train, y_train)","048a9d09":"y_pred = svc_tuned_linear.predict(x_test)\naccuracy_score(y_test, y_pred)","cae2550c":"svc_tuned=SVC(C = 1, gamma = 0.1, probability=True,random_state=1)","ada1da24":"svc_tuned.fit(x_train, y_train)","2e2982b5":"y_pred=svc_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","b09110cb":"mlpc_tuned = MLPClassifier(activation = \"relu\", \n                           alpha = 0.0001, \n                           hidden_layer_sizes = (100, 100, 100),\n                           solver = \"sgd\", random_state=1)","8a044711":"mlpc_tuned.fit(x_train, y_train)","88cb555c":"y_pred = mlpc_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","09176ed6":"cart = tree.DecisionTreeClassifier(max_depth = 6, min_samples_split = 3, random_state=1)\ncart_tuned = cart.fit(x_train, y_train)","2ff63604":"cart_tuned","2535eca8":"y_pred = cart_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","fd2a512e":"rf_tuned = RandomForestClassifier(max_depth = 8, \n                                  max_features = 5, \n                                  min_samples_split = 2,\n                                  n_estimators = 1000, random_state=1)\n\nrf_tuned.fit(x_train, y_train)","a41af27d":"y_pred = rf_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","7c70ce9f":"gbm = GradientBoostingClassifier(learning_rate = 0.1, \n                                 max_depth = 3,\n                                min_samples_split = 5,\n                                n_estimators = 100, random_state=1)","8c0ae493":"gbm_tuned =  gbm.fit(x_train,y_train)","edbba685":"gbm_tuned","5db41f49":"y_pred = gbm_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","a21a79fe":"xgb = XGBClassifier(learning_rate = 0.02, \n                    max_depth = 3,\n                    min_samples_split = 2,\n                    n_estimators = 2000,\n                    subsample = 1)","40a89f2d":"xgb_tuned =  xgb.fit(x_train,y_train)","db544da7":"xgb_tuned","0ce57541":"y_pred = xgb_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","de2b3b46":"lgbm = LGBMClassifier(learning_rate = 0.02, \n                       max_depth = 4,\n                       subsample = 0.6,\n                       n_estimators = 500,\n                       min_child_samples = 20,random_state=1)","80c0b63c":"lgbm_tuned = lgbm.fit(x_train,y_train)","1f87d673":"lgbm_tuned","5daa6a48":"y_pred = lgbm_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","384d6ce7":"catb = CatBoostClassifier(iterations = 200, \n                          learning_rate = 0.1, \n                          depth = 5, verbose=False, random_seed=1)\n\ncatb_tuned = catb.fit(x_train, y_train)","38abbc47":"catb_tuned","213036d4":"y_pred = catb_tuned.predict(x_test)\naccuracy_score(y_test, y_pred)","23a73ed3":"models_importance = [\n{\n    'label': 'DecisionTreeClassifier',\n    'model': cart_tuned,\n},\n{\n    'label': 'RandomForestClassifier',\n    'model': rf_tuned,\n},\n{\n    'label': 'GradientBoostingClassifier',\n    'model': gbm_tuned,\n},\n{\n    'label': 'XGBClassifier',\n    'model': xgb_tuned,\n},\n{\n    'label': 'LGBMClassifier',\n    'model': lgbm_tuned,\n},\n{\n    'label': 'CatBoostClassifier',\n    'model': catb_tuned,\n}\n]\n\nfor model in models_importance:\n    names = model['label']\n    model = model[\"model\"]    \n    model_imp=pd.DataFrame(model.feature_importances_, index = x_train.columns)\n    model_imp.columns=[\"imp\"]\n    model_imp.sort_values(by = \"imp\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n    plt.title(names)\n    plt.xlabel(\"Importance Values\")","26116754":"models_importance = [\n{\n    'label': 'LogisticRegression',\n    'model': loj_model,\n},\n{\n    'label': 'SVC_LINEAR',\n    'model': svc_tuned_linear,\n}\n]\n\n\nfor model in models_importance:\n    names = model['label']\n    model = model[\"model\"]\n    coef=np.array(model.coef_)\n    model_imp=pd.DataFrame(coef.flatten(), index = x_train.columns)\n    model_imp.columns=[\"imp\"]\n    model_imp.sort_values(by = \"imp\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n    plt.title(names)\n    plt.xlabel(\"Importance Values\")","0f928706":"models = [\n{\n    'label': 'KNeighborsClassifier',\n    'model': knn_tuned,\n},\n{\n    'label': 'LogisticRegression',\n    'model': loj_model,\n},\n{\n    'label': 'SVC_LINEAR',\n    'model': svc_tuned_linear,\n},\n{\n    'label': 'SVC_RBF',\n    'model': svc_tuned,\n},\n{\n    'label': 'GaussianNB',\n    'model': nb_model,\n},\n{\n    'label': 'MLPClassifier',\n    'model': mlpc_tuned,\n},\n{\n    'label': 'DecisionTreeClassifier',\n    'model': cart_tuned,\n},\n{\n    'label': 'RandomForestClassifier',\n    'model': rf_tuned,\n},\n{\n    'label': 'GradientBoostingClassifier',\n    'model': gbm_tuned,\n},\n{\n    'label': 'XGBClassifier',\n    'model': xgb_tuned,\n},\n{\n    'label': 'LGBMClassifier',\n    'model': lgbm_tuned,\n},\n{\n    'label': 'CatBoostClassifier',\n    'model': catb_tuned,\n}\n]\n\nfor model in models:\n    names = model['label']\n    model = model[\"model\"]\n    y_pred = model.predict(x_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    confusionmatrix=confusion_matrix(y_test, y_pred)\n    (TN, FP, FN, TP) = confusionmatrix.ravel()\n    TPR = TP\/(TP+FN) \n    TNR = TN\/(TN+FP)\n    PPV = TP\/(TP+FP)\n    NPV = TN\/(TN+FN)\n    FPR = FP\/(FP+TN)\n    FNR = FN\/(TP+FN)\n    print(\"-\"*28)\n    print(names + \":\" )\n    print(\"Accuracy: {:.4%}\".format(accuracy))\n    print(\"TPR     : {:.4%}\".format(TPR))\n    print(\"TNR     : {:.4%}\".format(TNR))\n    print(\"PPV     : {:.4%}\".format(PPV))\n    print(\"NPV     : {:.4%}\".format(NPV))\n    print(\"FPR     : {:.4%}\".format(FPR))\n    print(\"FNR     : {:.4%}\".format(FNR))","90ae38ba":"result = []\n\nresults = pd.DataFrame(columns= [\"Models\",\"Accuracy\"])\n\nfor model in models:\n    names = model['label']\n    model = model[\"model\"]\n    y_pred = model.predict(x_test)\n    accuracy = accuracy_score(y_test, y_pred)    \n    result = pd.DataFrame([[names, accuracy*100]], columns= [\"Models\",\"Accuracy\"])\n    results = results.append(result)\n\n\n    \nresults=results.sort_values(by=\"Accuracy\", ascending=False).reset_index()\nresults.drop([\"index\"], axis=1, inplace=True)\ng=sns.barplot(x= 'Accuracy', y = 'Models', data=results, color=\"r\")\ng.set_xlabel(\"Accuracy\",fontsize=20)\ng.set_ylabel(\"Models\",fontsize=20)\n\nfor index, row in results.iterrows():\n    g.text(row.Accuracy, row.name, round(row.Accuracy,2), color='black', horizontalalignment='left', fontsize=13)\n\nplt.xlabel('Accuracy %')\nplt.title('Accuracy Scores of Models');  ","0c800de0":"from sklearn import metrics\nimport matplotlib.pyplot as plt\n\nplt.figure()\n\n\n# Below for loop iterates through your models list\nfor m in models:\n    model = m['model'] # select the model\n# Compute False postive rate, and True positive rate\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n# Calculate Area under the curve to display on the plot\n    auc = metrics.roc_auc_score(y_test,model.predict(x_test))\n# Now, plot the computed values\n    plt.plot(fpr, tpr, label='%s ROC (AUC = %0.4f)' % (m['label'], auc))\n# Custom settings for the plot \nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('1-Specificity(False Positive Rate)')\nplt.ylabel('Sensitivity(True Positive Rate)')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc='center left', bbox_to_anchor=(1, 0.5) , fontsize=15)\nfig = plt.gcf()\nfig.set_size_inches(15, 10)\nplt.show()   # Display","8a29a337":"from sklearn import metrics\n\nplt.figure()\n\n# Add the models to the list that you want to view on the ROC plot\nmodelsROC = [\n{\n    'label': 'LogisticRegression',\n    'model': loj_model,\n},\n{\n    'label': 'GradientBoostingClassifier',\n    'model': gbm_tuned,\n}\n]\n\n# Below for loop iterates through your models list\nfor m in modelsROC:\n    model = m['model'] # select the model\n# Compute False postive rate, and True positive rate\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, model.predict_proba(x_test)[:,1])\n# Calculate Area under the curve to display on the plot\n    auc = metrics.roc_auc_score(y_test,model.predict(x_test))\n# Now, plot the computed values\n    plt.plot(fpr, tpr, label='%s ROC (AUC = %0.4f)' % (m['label'], auc))\n# Custom settings for the plot \nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.xlabel('1-Specificity(False Positive Rate)')\nplt.ylabel('Sensitivity(True Positive Rate)')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc='right corner', fontsize=15)\nfig = plt.gcf()\nfig.set_size_inches(12, 8)\nplt.show()   # Display","2e701846":"test_data_y_pred=gbm_tuned.predict(test_data)","1350a72f":"survived=pd.concat([test[\"PassengerId\"], (pd.DataFrame(test_data_y_pred, columns=[\"Survived\"]))], axis=1)","9522cf65":"survived[\"Survived\"]=survived[\"Survived\"].astype(\"int64\")","9656df51":"survived","6b78aa23":"survived.to_csv(\"Survived_Prediction.csv\")","b1139bc0":"# Sex","107b0a30":"knn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, knn_params, cv=10)\nknn_cv.fit(x_train, y_train)","223bda10":"# XGBoost","a95cd784":"# Train - Test Data missing value","b6dc8fa0":"# Importance","5806786c":"catb_params = {\n    'iterations': [200,500],\n    'learning_rate': [0.01,0.05, 0.1],\n    'depth': [3,5,8] }","f470c4f6":"# CART","778fe449":"cart = tree.DecisionTreeClassifier()\ncart_cv = GridSearchCV(cart, cart_grid, cv = 10, n_jobs = -1, verbose = 2)\ncart_cv_model = cart_cv.fit(x_train, y_train)","055ec13a":"svc_params = {\"C\": np.arange(1,10)}\n\nsvc = SVC(kernel = \"linear\")\n\nsvc_cv_model = GridSearchCV(svc,svc_params, \n                            cv = 10, \n                            n_jobs = -1, \n                            verbose = 2)\n\nsvc_cv_model.fit(x_train, y_train)","64dad40f":"# Preprocess of whole dataset","d9471276":"# Test verisi","9afc3721":"lgbm = LGBMClassifier()\n\nlgbm_cv_model = GridSearchCV(lgbm, lgbm_params, \n                             cv = 10, \n                             n_jobs = -1, \n                             verbose = 2)","63881261":"xgb_cv_model.fit(x_train, y_train)","57c085a0":"# Machine Learning","ecadd1d4":"# Difference of categories of Pclass, Sex, Cabin, Embarked, Parch, Sibsp are statistically significant between dead and alive however Age and Fare are not statistically significant between dead and alive people.","f34878b0":"print(\"best params: \" + str(cart_cv_model.best_params_))","8e37b06e":"# RBF SVC","b51ca108":"# Distribution of dependent variables in variable \"Survived\" ","b1bd1418":"# SVC","405532f4":"# Light GBM","e461ed7d":"# Data Union","5d165945":"# CatBoost","cdc5a305":"print(\"best params: \" + str(knn_cv.best_params_))","4507476d":"xgb_params = {\n        'n_estimators': [100, 500, 1000, 2000],\n        'subsample': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5,6],\n        'learning_rate': [0.1,0.01,0.02,0.05],\n        \"min_samples_split\": [2,5,10]}","c75bb79d":"# Cabin\/unknown is higher within deads so Pclass 3rd maybe related with this?","1280c6dc":"mlpc = MLPClassifier()\nmlpc_cv_model = GridSearchCV(mlpc, mlpc_params, \n                         cv = 10, \n                         n_jobs = -1,\n                         verbose = 2)\n\nmlpc_cv_model.fit(x_train, y_train)","82980c4d":"# LOGISTIC REGRESSION","587713ee":"# Outlier Detection for Variable \"Fare\"","840b7dbc":"# Train Data","88ece645":"# Age","007bdbd9":"# Fare","df41d6d0":"gbm_cv.fit(x_train, y_train)","102ff482":"# Questioning of multicollinearity","f0465a9f":"# SibSp","e71d77e6":"# Imputation of Fare with median","6ab30859":"xgb_cv_model.best_params_","ea15b678":"mlpc_params = {\"alpha\": [0.1, 0.01, 0.02, 0.005, 0.0001,0.00001],\n              \"hidden_layer_sizes\": [(10,10,10),\n                                     (100,100,100),\n                                     (100,100),\n                                     (3,5), \n                                     (5, 3)],\n              \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\n              \"activation\": [\"relu\",\"logistic\"]}","f718c76a":"# Random Forests","a5682f0c":"print(\"best params: \" + str(gbm_cv.best_params_))","f4e16ba4":"# ROC Curve","fdfd051b":"# ANN MLP","452d62c1":"catb = CatBoostClassifier()\ncatb_cv_model = GridSearchCV(catb, catb_params, cv=5, n_jobs = -1, verbose = 2)\ncatb_cv_model.fit(x_train, y_train)","2fc6d8c6":"# Calculation of VIF","b1a95ca8":"catb_cv_model.best_params_","93e55309":"cart_grid = {\"max_depth\": range(1,10),\n            \"min_samples_split\" : list(range(2,50)) }","8be482dd":"# Pclass","487d5a74":"# Train Data Exploratory data analysis","af05afb1":"lgbm_cv_model.best_params_","d5ee23d5":"lgbm_params = {\n        'n_estimators': [100, 500, 1000, 2000],\n        'subsample': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5,6],\n        'learning_rate': [0.1,0.01,0.02,0.05],\n        \"min_child_samples\": [5,10,20]}","4dc77dc1":"rf_cv_model.fit(x_train, y_train)","b85b5872":"# KNN","a5e51b01":"gbm = GradientBoostingClassifier()\n\ngbm_cv = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 2)","a19a43e2":"print(\"best params: \" + str(rf_cv_model.best_params_))","02ac4254":"# GBM","b82c916f":"rf_params = {\"max_depth\": [2,5,8,10],\n            \"max_features\": [2,5,8],\n            \"n_estimators\": [10,500,1000],\n            \"min_samples_split\": [2,5,10]}","395ce4c8":"knn_params = {\"n_neighbors\": np.arange(1,50)}","95afb1c0":"# Comparison of All Models","51883869":"rf_model = RandomForestClassifier()\n\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 10, \n                           n_jobs = -1, \n                           verbose = 2) ","701f8f18":"svc = SVC()\nsvc_cv_model = GridSearchCV(svc, svc_params, \n                         cv = 10, \n                         n_jobs = -1,\n                         verbose = 2)\n\nsvc_cv_model.fit(x_train, y_train)","b4f7a631":"# OneHotEncoder for dataset","534fef73":"# Parch","a842ec74":"print(\"best params: \" + str(svc_cv_model.best_params_))","480fe9b1":"# Embarked","308711cb":"# NAIVE BAYES","e1471534":"xgb = XGBClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","fdad79fb":"svc_params = {\"C\": [0.0001, 0.001, 0.1, 1, 5, 10 ,50 ,100],\n             \"gamma\": [0.0001, 0.001, 0.1, 1, 5, 10 ,50 ,100]}","a8f46748":"lgbm_cv_model.fit(x_train, y_train)","82889b4d":"gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n             \"n_estimators\": [100,500,100],\n             \"max_depth\": [3,5,10],\n             \"min_samples_split\": [2,5,10]}","ae8370e4":"# Test Data Predictions","33d7d57e":"# Cabin","6db1a16a":"print(\"best params: \" + str(mlpc_cv_model.best_params_))","f0074e71":"print(\"best params: \" + str(svc_cv_model.best_params_))"}}