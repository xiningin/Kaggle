{"cell_type":{"b3f41b52":"code","d003ce38":"code","81c922a6":"code","9eaf6814":"code","00578420":"code","99c8df5f":"code","cb8bf6aa":"code","67432134":"code","c011dab3":"code","3f9e16f3":"code","f0aeacf7":"code","68f13a3c":"code","381a7e5b":"code","e3fb53fa":"code","ce0383c5":"code","5fdf3080":"code","ae26ecb5":"code","ae5273e7":"markdown","250f0e59":"markdown","0fb76bd8":"markdown"},"source":{"b3f41b52":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d003ce38":"# Reading Data and selecting required columns\ntest = pd.read_csv('\/kaggle\/input\/tweet-files-for-gender-guessing\/twitgen_test_201906011956.csv')\ntest = test.loc[:,['text','male']]\ntest.head()","81c922a6":"train = pd.read_csv('\/kaggle\/input\/tweet-files-for-gender-guessing\/twitgen_train_201906011956.csv')\ntrain = train.loc[:,['text','male']]\n\nval = pd.read_csv('\/kaggle\/input\/tweet-files-for-gender-guessing\/twitgen_valid_201906011956.csv')\nval = val.loc[:,['text','male']]","9eaf6814":"print(train.shape)\nprint(val.shape)","00578420":"# Mergin train and val data\nmaster = pd.concat([train,val], axis=0)\nmaster.shape","99c8df5f":"# Checking for nulls in data\nmaster.isnull().sum()","cb8bf6aa":"test.isnull().sum()","67432134":"master.male.unique()","c011dab3":"master.dtypes","3f9e16f3":"# Mapping target Column\nmaster.male = master.male.map({True:1, False:0})\ntest.male = test.male.map({True:1, False:0})\nmaster.head()","f0aeacf7":"master.male.value_counts()","68f13a3c":"# Defining train and test sets\nX_train, y_train = master['text'], master['male']\nX_test, y_test = test['text'], test['male']\nX_train.head()","381a7e5b":"# Importing and defining Stratified K-Fold\nfrom sklearn.model_selection import StratifiedKFold\n\nX_trainCV = np.array(X_train)\ny_trainCV = np.array(y_train)\n\nSKF = StratifiedKFold(n_splits=20, random_state=100, shuffle=True)\n\nSKF.get_n_splits(X_trainCV,y_trainCV)","e3fb53fa":"folds = SKF.split(X_trainCV, y_trainCV)\nfolds","ce0383c5":"# Importing Count Vectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer(stop_words='english')\nvectorizer","5fdf3080":"# Importing Multinomial Naive Bayes and Metrics for calculating scores\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix","ae26ecb5":"# Running Loop for each of the fold and training model\n# Printing various metrics of model\nfoldCount=0\n\nfor trainIndex, testIndex in folds:\n    \n    X_trainCF, y_trainCF = X_trainCV[trainIndex], y_trainCV[trainIndex]\n    X_testCF, y_testCF = X_trainCV[testIndex], y_trainCV[testIndex]\n    \n    X_train_transformed = vectorizer.fit_transform(X_trainCF)\n    X_test_transformed = vectorizer.transform(X_testCF)\n    \n    model = MultinomialNB()\n    \n    model.fit(X_train_transformed,y_trainCF)\n    \n    y_testCF_predicted = model.predict(X_test_transformed)\n    \n    # Predicting accuracy of model\n    accuracy = accuracy_score(y_testCF, y_testCF_predicted)\n    confusionMX = confusion_matrix(y_testCF, y_testCF_predicted)\n    \n    TN = confusionMX[0,0]\n    FP = confusionMX[0,1]\n    FN = confusionMX[1,0]\n    TP = confusionMX[1,1]\n    \n    sensitivity = TP\/(FN+TP)\n    specificity = TN\/(TN+FP)\n    precision = TP\/(FP+TP)\n    \n    print(\"Fold Index: \"+str(foldCount))\n    print(\"-------------------------\")\n    print(\"Model's Accuracy: \"+str(round(accuracy,2)))\n    print(\"Model's Sensitivity: \"+str(round(sensitivity,2)))\n    print(\"Model's Specificity: \"+str(round(specificity,2)))\n    print(\"Model's Precision: \"+str(round(precision,2)))\n    print(\"\\n\")\n    print(\"..................................................................\")\n    \n    foldCount+=1","ae5273e7":"# Reading Datasets","250f0e59":"# Data Preparation","0fb76bd8":"# Model Building"}}