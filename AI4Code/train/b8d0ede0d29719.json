{"cell_type":{"58c16f70":"code","04aa4ef1":"code","3cc08c7d":"code","140d261a":"code","172be30b":"code","d7a84774":"code","e403331f":"code","a25e5fd7":"code","2265b1e5":"code","ee50e719":"code","264243d7":"code","629b3e2d":"code","e2c7c26d":"markdown"},"source":{"58c16f70":"#Importing libraries:\nimport torch \nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\n\n#Defining Net class based on nn.Module superclass\nclass Net(nn.Module):\n    #Constructor of the Net class: \n    def __init__(self,inputsize,hiddensize,outputsize):\n        super(Net, self).__init__()\n        #Initializes two linear functions based on the constructor parameters\n        self.fc1=nn.Linear(inputsize,hiddensize)\n        self.fc2=nn.Linear(hiddensize,outputsize)\n        \n        #fc1 transforms m x inputsize matrix into m x hiddensize \n        #fc2 transforms m x hiddensize matrix into m x outputsize\n    \n    #Forward propagation function:\n    def forward(self,x):\n        out = self.fc1(x)\n        out = self.fc2(out)\n\n        return out","04aa4ef1":"#Defining the train function:\ndef trainNN(model,input,target,alpha,maxit,Xtest,Ytest):\n    \n    #Using GPU to do calculations:\n    input = input.cuda()\n    target = target.cuda()\n    Xtest=Xtest.cuda()\n    Ytest=Ytest.cuda()\n    \n    \n    #Zeroing values of cost histories\n    costHistory=np.zeros(maxit);\n    testHistory=np.zeros(maxit);\n\n    \n    for i in range (0,maxit):\n\n        #Chossing the optimizer and resetting the gradient from previous iteration\n        optimizer = optim.SGD(model.parameters(), lr=alpha)\n        optimizer.zero_grad()\n        \n        #Calculating lose based on MSE error between target and output of network\n        loss = nn.MSELoss()\n        output = model.forward(input)\n        cost=loss(output, target)\n        \n        #Adding the costs values to the history variables\n        costHistory[i]=cost;\n        testHistory[i]=loss(model.forward(Xtest),Ytest)\n        \n        #Performing a gradient decend step\n        cost.backward()\n        optimizer.step()\n        \n        #Print progress notification\n        if((i\/maxit*100)%5==0):\n            print(\"Training completed in \",i\/maxit*100,\" %.\")\n            \n        #If cost is increasing than divide learning rate by 3    \n        if(i>0):\n            if(costHistory[i-1]<costHistory[i]):\n                alpha=alpha\/3\n                print(\"Decreasing learning rate to\",alpha)\n        \n        \n    #Return the information about changes in Cost History for further analysis    \n    return costHistory,testHistory","3cc08c7d":"#---------------------------------------------Training the model ------------------------------------------------------------","140d261a":"#Load the train set data. Train.csv must be located in the same folder as this file.\ntrain=pd.read_csv(\"train.csv\")\n#Shuffle the data set\ntrain=train.sample(frac=1)\n#Convert data to numpy object from pandas object\ntrain=np.array(train)\n\n#Create a train set X,Y out of 75% of data\n#Columns 0 and 1 are discarded\nX=train[0:12000,3:]\nY=train[0:12000,2]\n#Ensure X and Y are matrix objects \nY=np.matrix(Y,dtype=np.float32)\nX=np.matrix(X,dtype=np.float32)\n#Changing X and Y to PyTorch objects from numpy objects\nX=torch.tensor(X)\nY=torch.tensor(Y)\n#Ensure that Y is treated as a 2D array with dimension size of 1 in second axis and not as a 1D vector\nY=Y.view(-1,1)\n\n#Create a test set Xtest,Ytest out of 25% of data\n#Columns 0 and 1 are discarded\nXtest=train[12000:,3:]\nYtest=train[12000:,2]\n#Ensure Xtest and Ytest are matrix objects \nXtest=np.matrix(Xtest,dtype=np.float32)\nYtest=np.matrix(Ytest,dtype=np.float32)\n#Changing Xtest and Ytest to PyTorch objects from numpy objects\nXtest=torch.tensor(Xtest)\nYtest=torch.tensor(Ytest)\n#Ensure that Ytest is treated as a 2D array with dimension size of 1 in second axis and not as a 1D vector\nYtest=Ytest.view(-1,1)\n\n#Perform feature normalization\nX=F.normalize(X,dim=0)\nXtest=F.normalize(Xtest,dim=0)","172be30b":"#WARNING: This cell resets the model and will undo all the learning\n\n#Creating network object of Net class\n\n#The best size for hidden layes was found to be 1 and that is the value set as default in the code.\n#To change the size of hidden layer change the second input parameter to Net constructor.\nnetwork=Net(18,1,1) \n\n#Using GPU to perfmorm operations on network\nnetwork.cuda()\n#Reseting cost Hisotry for both train and test set\ncostHistory=None\ntestHistory=None\n","d7a84774":"#Run learning function and save the returned cost history variables\n\n#The best initial learning rate was found to be 0.0000001\n#The best reults of learning on the test set occur after around 4800 iterations\n#After that model starts to overfit\n(costHistory_more,testHistory_more)=trainNN(network,X,Y,0.0000001,4800,Xtest,Ytest)\n\n#Merge the returned cost history variables and global cost history variables\ncostHistory=np.append(costHistory,costHistory_more)\ntestHistory=np.append(testHistory,testHistory_more)","e403331f":"#Visulaize cost Hisotry over iterations\nplt.plot(costHistory)\nplt.plot(testHistory)","a25e5fd7":"#This cell finds the iteration for which the cost was lowest on test set\n#It also prints that cost\nfor i in range (0,np.size(testHistory)):\n    if np.amin(testHistory[1:])==testHistory[i]:\n        print(i)\nprint(np.amin(testHistory[1:]))","2265b1e5":"#This cells prints the cost of currently loaded model for test set\ninput=network.forward(Xtest.cuda())\noutput=Ytest.cuda()\nloss=nn.MSELoss()\nCVcost=loss(input,output)\nprint(CVcost)","ee50e719":"#--------------------------------Making Predictions--------------------------------------------------------------------------","264243d7":"#Load the data for the submision test set (following the same procedure as beofre)\ninput=pd.read_csv(\"test.csv\")\ninput=np.array(input)\nX_input=input[:,2:]\nX_input=np.matrix(X_input,dtype=np.float32)\nX_input=torch.tensor(X_input)\nX_input=X_input.cuda()\nX_input=F.normalize(X_input,dim=0)","629b3e2d":"#Predict prizes and save to a csv file\n\n(m,n)=np.shape(X_input)\n\n#Predict Y based on X_input\nh=network.forward(X_input)\n\n#Change hypotesis h to numpy object\nh=h.cpu().detach().numpy()\n\n#Create the id table needed for submission\nid=np.zeros((m,1))\nfor i in range(0,m):\n    id[i][0]=i+45129\n#Ensure the right data type for id table and hypotesis (int 32)    \nid=np.matrix(id,dtype=np.int32)\nh=np.matrix(h,dtype=np.int32)\n\n#Join hypotesis and id table together\nh=np.concatenate((h,id),axis=1)\n\n#Convert result to pandas DataFrame\nresult=pd.DataFrame(h,columns=['price','id'])\n\n#Save pandas data frame as sub.csv\nresult.to_csv('sub.csv',index = False)","e2c7c26d":"USAIS competition vol.1 - House price prediction \nHouse price predictor code \nAuthor: Juliusz Ziomek \n\nNotes:\nThis program requires Python 3 with Pythorch, Pandas, Numpy and Matplotlib to be installed.\nIt requires test set to be saved as \"test.csv\" and train set as \"train.csv\" in the same folder as this file\nThe prediction for test set will be saved in \"sub.csv\".\nThis program's output can score around 375,000 - 387,000 of error on Kaggle"}}