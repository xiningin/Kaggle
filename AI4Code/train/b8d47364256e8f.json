{"cell_type":{"81a5f743":"code","85c3b743":"code","e95a03ea":"code","8c7a12dc":"code","70b7c176":"code","61a6e5a7":"code","5f27bb90":"code","36c78106":"code","9b47a6ba":"code","1ebd37c6":"code","d92f0315":"code","3b3f9b4c":"code","93abcf29":"code","ee337ff7":"markdown","d9a170b5":"markdown","ed3c42d3":"markdown"},"source":{"81a5f743":"# Install pytorch-lightning\n!pip install ..\/input\/pytorch-lightening\/tensorboard-2.2.0-py3-none-any.whl -q\n!pip install ..\/input\/pytorch-lightening\/pytorch_lightning-0.9.0-py3-none-any.whl -q","85c3b743":"import pandas as pd\nimport pytorch_lightning as pl\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nfrom  torch import nn\nimport torch\nimport numpy as np","e95a03ea":"class MoATestDataset(Dataset):\n    \n    def __init__(self, features):\n        self.features = features\n        \n    def __len__(self):\n        return self.features.shape[0]\n        \n    def __getitem__(self, index):\n        return {\n            \"x\": torch.tensor(self.features[index, :], dtype=torch.float)\n        }","8c7a12dc":"LR = 0.001\nF_DROPOUT = 0.45\nLAYERS = [4096, 2048, 1024, 512]\nLABEL_SMOOTHING = 0.001\n\nclass Model(nn.Module):\n    def __init__(self, num_features, num_targets):\n        super().__init__()\n        layers = []\n        \n        # Intermediate layers\n        in_size = num_features   \n        for i in range(len(LAYERS)):\n            out_size = LAYERS[i]\n            layers.append(torch.nn.Linear(in_size, out_size, bias=False))\n            layers.append(nn.BatchNorm1d(out_size))\n            layers.append(nn.Dropout(F_DROPOUT))\n            layers.append(nn.PReLU())\n            in_size = out_size\n\n        # Final layer\n        layers.append(torch.nn.Linear(in_size, num_targets))    \n        self.model = torch.nn.Sequential(*layers)        \n        \n        # Initialize weights\n        self.model.apply(self._init_weights)\n        \n    def _init_weights(self, m):\n        if type(m) == nn.Linear:\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias != None:\n                m.bias.data.fill_(0.01)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","70b7c176":"class PLitMoAModule(pl.LightningModule):\n    def __init__(self, hparams, model):\n        super(PLitMoAModule, self).__init__()\n        self.hparams = hparams\n        self.model = model\n        self.criterion = nn.BCEWithLogitsLoss()\n        \n    def forward(self, x):\n        return self.model(x)\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.hparams[\"lr\"])\n        scheduler = {\"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, threshold=0.00001, mode='min', verbose=True),\n                      \"interval\": \"epoch\",\n                      \"monitor\": \"val_loss\"}\n        return [optimizer], [scheduler]\n    \n    def training_step(self, batch, batch_index):\n        features = batch['x']\n        targets = batch['y']\n        out = self(features)\n        loss = self.criterion(out, targets)\n        logs = {\"train_loss\" : loss}\n        return {\"loss\": loss, \"log\": logs, \"progress_bar\": logs}\n    \n    def training_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n        logs = {\"train_loss\": avg_loss}\n        return {\"log\": logs, \"progress_bar\": logs}\n            \n    def validation_step(self, batch, batch_index):\n        features = batch['x']\n        targets = batch['y']\n        out = self(features)\n        loss = self.criterion(out, targets)\n        logs = {\"val_loss\" : loss}\n        return {\"loss\": loss, \"log\": logs, \"progress_bar\": logs}\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n        logs = {\"val_loss\": avg_loss}\n        return {\"log\": logs, \"progress_bar\": logs}","61a6e5a7":"sample_submission = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')\ntest_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')","5f27bb90":"sample_submission.shape, test_features.shape","36c78106":"# Convert categorical features into OHE\ntest_features = pd.concat([test_features, pd.get_dummies(test_features['cp_time'], prefix='cp_time')], axis=1)\ntest_features = pd.concat([test_features, pd.get_dummies(test_features['cp_dose'], prefix='cp_dose')], axis=1)\ntest_features = pd.concat([test_features, pd.get_dummies(test_features['cp_type'], prefix='cp_type')], axis=1)\n# Delete original categorical features\ntest_features = test_features.drop(['cp_time', 'cp_dose', 'cp_type'], axis=1)","9b47a6ba":"batch_size=1024\ntestDataSet = MoATestDataset(test_features.iloc[:, 1:].values)\ntestDataLoader = DataLoader(testDataSet, batch_size=batch_size, num_workers=4, shuffle=False)\nnet = Model(879, 206) # Input Features, Output Targets\n# pylitModel = PLitMoAModule(hparams={\"lr\":1e-3}, model=net)\ntrainer = pl.Trainer()","1ebd37c6":"# Empty array with as many rows\npredictions = np.zeros((test_features.shape[0], 206))\nmodel_path = '..\/input\/optuna-moa-pytorch-lightning-kfold\/models\/'\nfor modelFileName in os.listdir(model_path):\n    # Load each K-Fold model\n    model = PLitMoAModule.load_from_checkpoint(checkpoint_path=f\"{model_path}{modelFileName}\", model=net)\n    for index, batch in enumerate(testDataLoader):\n        # Sigmoid is used to convert eact predictions into a range between 0 and 1 (probability)\n        batch_predictions = torch.sigmoid(model(batch['x'])).detach().cpu().numpy()\n        start_index = index*batch_size\n        end_index = index*batch_size + batch_predictions.shape[0]\n        predictions[start_index:end_index] = predictions[start_index:end_index] + batch_predictions\n\n# Average predictions across KFolds\npredictions = np.true_divide(predictions, 5)","d92f0315":"sample_submission.iloc[:, 1:] = predictions","3b3f9b4c":"# https:\/\/www.kaggle.com\/c\/lish-moa\/discussion\/180165 \nvehicle_indices = test_features[test_features[\"cp_type_ctl_vehicle\"]==1].index.tolist()\nsample_submission.iloc[vehicle_indices, 1:] = np.zeros((1, 206))","93abcf29":"sample_submission.to_csv('submission.csv', index=False)","ee337ff7":"### Inference","d9a170b5":"### Training from\nhttps:\/\/www.kaggle.com\/krisho007\/moa-pytorch-lightning-kfold","ed3c42d3":"### Post Processing\n"}}