{"cell_type":{"12dfe50c":"code","53e0419d":"code","09b4dde9":"code","cf6959f1":"code","6de24268":"code","60b3bd0f":"code","4f6b4ff8":"code","9239adb6":"code","cb5f75e6":"code","f7e92b8b":"code","489f1299":"code","e0472b34":"code","53770a70":"code","c18ce6bf":"code","80385f36":"code","b1bcc101":"code","aca0066d":"code","529ea32c":"code","36588ee8":"code","26e59a70":"code","dbc37351":"code","11554522":"code","5f85863c":"code","f5057d76":"code","84f5f23c":"markdown","2cd6a9c0":"markdown","7f513f80":"markdown","59dbcf0f":"markdown","2e3e6e2a":"markdown","2743688b":"markdown","9a0cf06c":"markdown","14ac1843":"markdown","7ba7224e":"markdown","3d424173":"markdown","dde7cdeb":"markdown","018a0d48":"markdown","b8ff9960":"markdown","ea3bb45f":"markdown","c42713f4":"markdown"},"source":{"12dfe50c":"!pip3 install yfinance sklego\n!pip3 install --ignore-installed numpy","53e0419d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nimport yfinance as yf\nfrom matplotlib import rc\nfrom pandas.plotting import register_matplotlib_converters\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nimport requests\nimport json\nfrom sklego.preprocessing import RepeatingBasisFunction","09b4dde9":"fb   = yf.Ticker(\"FB\")\ndata = fb.history(period=\"730d\", interval='1h')\ndata = data.drop(['Dividends','Stock Splits'],axis=1)","cf6959f1":"plt.figure(figsize=(9,9))\ng = sns.heatmap(data.corr(),annot=True,cmap=\"RdYlGn\")","6de24268":"fig,(ax1,ax2) = plt.subplots(1,2,figsize=(20, 10))\nsns.distplot(data['High'], color='r', bins=100, hist_kws={'alpha': 0.4},ax=ax1);\nsns.distplot(np.log1p(data['High']+2), color='g', bins=100, hist_kws={'alpha': 0.4},ax=ax2);\nax1.set_title('Original High Price')\nax2.set_title('Log-Transform High Price')","60b3bd0f":"data['High'] = np.log1p(data['High'])","4f6b4ff8":"## Create new dataframe for convenience\ndf_ = pd.DataFrame({\n    \"high\" : data[\"High\"].astype(float).values,\n}, index=pd.DatetimeIndex(data.index))\n\ndf = df_.copy()","9239adb6":"def rbf_function(df,column_name,N_PERIODS):\n  rbf = RepeatingBasisFunction(n_periods=N_PERIODS,\n                              remainder='drop',\n                              column=column_name,\n                              input_range=(df[column_name].min() ,df[column_name].max()))\n  rbf.fit(df)\n  data_period = rbf.transform(df)\n  return data_period\n","cb5f75e6":"df['day_year'] = df.index.dayofyear\ndf['day_month'] = df.index.day\ndf['day_week'] = df.index.dayofweek","f7e92b8b":"plt.figure(figsize=(20,5))\nrbf_year = rbf_function(df,'day_year',5)\nplt.plot(rbf_year)","489f1299":"plt.figure(figsize=(20,5))\nrbf_month = rbf_function(df,'day_month',5)\nplt.plot(rbf_month[:200])","e0472b34":"plt.figure(figsize=(20,5))\nrbf_week= rbf_function(df,'day_week',5)\nplt.plot(rbf_week[:200])","53770a70":"def df_rbf(data,column_name):\n  df_period = pd.DataFrame(data=\n                                {\n                                    \"rbf_{}_1\".format(column_name) : data[:,0],\n                                    \"rbf_{}_2\".format(column_name) : data[:,1],\n                                    \"rbf_{}_3\".format(column_name) : data[:,2],\n                                    \"rbf_{}_4\".format(column_name) : data[:,3],\n                                    \"rbf_{}_5\".format(column_name) : data[:,4],                                  \n                           \n                                })\n  df_period.index = df.index\n  return df_period\n\ndf_rbf_week = df_rbf(rbf_week,'rbf_week')\ndf_rbf_month = df_rbf(rbf_month,'rbf_month')\ndf_rbf_year = df_rbf(rbf_year,'rbf_year')","c18ce6bf":"\ndf_data = df.drop(['day_week','day_month','day_year'],axis=1)\ndf_data = pd.concat([df_data,df_rbf_week,df_rbf_month,df_rbf_year],axis=1)","80385f36":"df_data.head()","b1bcc101":"train_size = int(len(df_data) * 0.9)\ntest_size = len(df_data) - train_size\ntrain, test = df_data.iloc[0:train_size], df_data.iloc[train_size:len(df_data)]\nprint(len(train), len(test))","aca0066d":"def create_dataset(X, y, u=\"test\",time_steps=1):\n    Xs, ys = [], []\n    for i in range(0,np.int(len(X)\/time_steps)):\n        v = X.iloc[i*time_steps:(i*time_steps + time_steps)].values\n        Xs.append(v) \n\n    for i in range(1,np.int(len(X)\/time_steps)):\n\n        ys.append(y.iloc[(i*time_steps) : (i+1)*time_steps ].values)\n    if u == \"train\":\n\n      return np.array(Xs)[:-1], np.array(ys)\n    else:\n      return np.array(Xs)[:-1], np.array(ys),np.array(Xs)[-1]\n","529ea32c":"from sklearn.preprocessing import minmax_scale\nf_columns = df_data.columns.values.tolist()\n\ntarget = 'high'\ntime_steps= 5\n\n\nX_train, y_train = create_dataset(train.loc[:, f_columns],\n                                  train[target],\n                                  \"train\",\n                                  time_steps)\n\nX_test, y_test,last_window = create_dataset(test.loc[:, f_columns],\n                                            test[target],\n                                            \"test\",\n                                            time_steps)\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","36588ee8":"import numpy as np\nfrom sklearn.linear_model import Ridge,LinearRegression\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nX_train_ = X_train.reshape(-1,time_steps*len(f_columns))\nreg = LinearRegression().fit(X_train_, y_train)\nreg.score(X_train_, y_train)\n\n","26e59a70":"y_pred_reg = reg.predict(X_test.reshape(-1,time_steps*len(f_columns)))\nprint(\"Mean squared error on the test set {}\".format(mean_squared_error(y_pred_reg.flatten(),y_test.flatten())))\n","dbc37351":"y_test_inv = np.expm1(y_test.flatten().reshape(-1,1))\ny_pred_reg_inv = np.expm1(y_pred_reg.flatten().reshape(-1,1))\n","11554522":"y_pred_future = reg.predict(last_window.reshape(-1,time_steps*len(f_columns)))\ny_pred_reg_inv_future = np.expm1(y_pred_future.reshape(-1,1))","5f85863c":"plt.figure(figsize=(30,5))\nplt.plot(np.arange(0,y_pred_reg_inv.shape[0]),y_pred_reg_inv, label=\"predicted values\")\nplt.plot(np.arange(1,y_pred_reg_inv.shape[0]+1),y_test_inv,label= \"true values\")\nplt.legend()","f5057d76":"plt.figure(figsize=(20,5))\nplt.plot(np.arange(0,20),y_test_inv[-20:],label=\"last values\")\nplt.plot(np.arange(19,19+time_steps),y_pred_reg_inv_future, c='r',label=\"forecasted values\")\nplt.axvline(19,color='green'),plt.axvline(19+time_steps-1,color='green')\nplt.legend()","84f5f23c":"## Radial Basis Function ( RBF )","2cd6a9c0":"With this model we can predict the next next N highest values that will occurs on the next N hours, hour per hour.","7f513f80":"This is the main idea of the forecasting.\n\nBasically, we're using the first window of size N to predict the next window of same size N with no overlap, meaning that the input $y_{i}$ is equal to $x_{i+1}$.\n\nThis choice of windowing suffers from having too little points because of the absence of overlap between the window, but this choice allows to forecast as much point as the length of the window.","59dbcf0f":"## Target Transformation","2e3e6e2a":"#### Split data into train and validation set","2743688b":"# Preprocessing","9a0cf06c":"![](https:\/\/user-images.githubusercontent.com\/55285736\/132108752-963d3942-0ac4-4f97-96ed-9ea232a7e92a.png)","14ac1843":"# Linear Regression","7ba7224e":"Because Linear Regression can deal only with 2D data. We flatten the two last dimensions in order to correctly fed the algorithm.","3d424173":"## Forecasting","dde7cdeb":"# Stocks Forecasting using Linear Regression that uses sliding window with no Overlap ","018a0d48":"Some variables are of a circular nature. For example, the days of the year, 1-Jan-2019 (day 1) is just as close to 2-Jan-2019 (day 2) as it is to 31-Dec-2018 (day 365). If you would encode day of year numerically you would lose this information, as 1 close 2 to but far from 365. The repeating basis function transformer can remedy this problem.\n\nThe transformer selects a column and transforms it with a given number of repeating (radial) basis functions, which have a bell curve shape. The basis functions are equally spaced over the input range. The key feature of repeating basis functions is that they are continuous when moving from the max to the min of the input range. As a result these repeating basis functions can capture how close each datapoint is to the center of each repeating basis function, even when the input data has a circular nature.\n\nsource: [sklego link](https:\/\/scikit-lego.readthedocs.io\/en\/latest\/preprocessing.html#Repeating-Basis-Function-Transformer)","b8ff9960":"We can see that the target `high` is too correlated with `Low, Open, Close` variable, and uncorrelated with `Volume`.\n\nSo, we'll get ride of this redundancy by deleting them.","ea3bb45f":"In this notebook, we are interested in predicting the next K highest points that can be reached in a stock market.\nWe considered the `high` variable as the target, because we think that estimating the highest value is a fair choice, because it will allow the trader to know the maximum limit that can be reached, and thus invest in a much more reasonable way. The estimated value can be seen as the **take profit** in a trade.","c42713f4":"\n\nWith this information we can see that the prices are skewed right.\nTherefore, a log transformation can map the skewed distribution of the target to  be normal as much as possible, allowing the model a better learning stage.\n"}}