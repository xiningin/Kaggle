{"cell_type":{"5918b943":"code","375899b6":"code","b4dbcf8b":"code","92e3b4b0":"code","0fe61bd1":"code","6e9498e5":"code","0f66f68e":"code","5e84f966":"code","18904892":"code","52d98ec6":"code","0770d912":"code","49992391":"code","bf5488eb":"code","fc993896":"code","b236ea77":"code","a12d083a":"code","e6b59a13":"code","332e0d8c":"code","7e23ffc4":"code","2b99a3e8":"code","199d031a":"code","0c4f86f7":"code","ac755f51":"code","25847d46":"code","0477afc1":"code","c66169df":"code","a2f6e732":"code","3e2e0d6c":"code","b5920a7f":"code","2af68df7":"code","f16ae65c":"code","8ad28435":"code","5fc32bb2":"code","51dc237c":"code","c350c5f4":"code","3393ef9b":"code","f31372a2":"code","354267d1":"code","e05ec481":"code","1212bf08":"code","9d6fc5fb":"code","536eae8c":"code","3df5636e":"code","f039cb4f":"code","14fd4e26":"code","884154a5":"markdown","badff1a2":"markdown"},"source":{"5918b943":"! pip install -q pyspark","375899b6":"from pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nimport pyspark.sql.types as T","b4dbcf8b":"spark = SparkSession.builder.getOrCreate()","92e3b4b0":"spark","0fe61bd1":"df = spark.read.csv('..\/input\/fraud-detection\/synth_composite.csv', header=True, inferSchema=True)","6e9498e5":"df.show(2)","0f66f68e":"df.printSchema()","5e84f966":"df = df.select('type','amount','oldbalanceOrg','newbalanceOrig','isFraud')","18904892":"df.show(2)","52d98ec6":"df.filter('isFraud==1').count()","0770d912":"df.filter('isFraud==0').count()","49992391":"train,test = df.randomSplit([0.8,0.2], seed=48)","bf5488eb":"print(f\"Train Length {train.count()}\")\nprint(f\"Test Length {test.count()}\")","fc993896":"# Find Categorical columns and Num Columns\ncatCols = [x for (x, dataType) in train.dtypes if dataType == 'string']\nnumCols = [x for (x, dataType) in train.dtypes if ((dataType=='double')&(x != 'isFraud'))]","b236ea77":"catCols","a12d083a":"numCols","e6b59a13":"# Find Unique data in type Columns\ntrain.agg(F.countDistinct('type')).show()","332e0d8c":"train.groupBy('type').count().show()","7e23ffc4":"from pyspark.ml.feature import OneHotEncoder, StringIndexer","2b99a3e8":"str_index = [StringIndexer(inputCol=x, outputCol=x+'_strIndex',handleInvalid='skip') for x in catCols]","199d031a":"ohc_index = [OneHotEncoder(inputCols=[f\"{x}_strIndex\" for x in catCols], outputCols=[f\"{x}_ohc\" for x in catCols])] ","0c4f86f7":"from pyspark.ml.feature import VectorAssembler","ac755f51":"assembler = [x for x in numCols]\nassembler += [f\"{x}_ohc\" for x in catCols]","25847d46":"assembler","0477afc1":"vector_assembler = VectorAssembler(inputCols=assembler, outputCol='independent_feature')","c66169df":"stages = []\nstages += str_index\nstages += ohc_index\nstages += [vector_assembler]","a2f6e732":"stages","3e2e0d6c":"# Create Pipeline\nfrom pyspark.ml import Pipeline\n\npipeline = Pipeline().setStages(stages)\nmodel = pipeline.fit(train)\nmodel_train = model.transform(train)\n\nmodel_test = model.transform(test)","b5920a7f":"model_test.select('type','amount','oldbalanceOrg','newbalanceOrig','independent_feature').show(5,truncate=False)","2af68df7":"from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.classification import RandomForestClassifier","f16ae65c":"data_train = model_train.select(\nF.col('independent_feature').alias('features'),\nF.col('isFraud').alias('label'))","8ad28435":"data_test = model_test.select(\nF.col('independent_feature').alias('features'),\nF.col('isFraud').alias('label'))","5fc32bb2":"data_train.show(5)","51dc237c":"data_train.filter('label==1').show(5)","c350c5f4":"model = LogisticRegression().fit(data_train)","3393ef9b":"model.summary.areaUnderROC","f31372a2":"pred = model.evaluate(data_test)","354267d1":"pred.truePositiveRateByLabel","e05ec481":"pred.accuracy","1212bf08":"model_rf = RandomForestClassifier(labelCol=\"label\", seed=42, leafCol=\"leafId\")","9d6fc5fb":"model_rf = model_rf.fit(data_train)","536eae8c":"model_rf.summary.areaUnderROC","3df5636e":"pred_rf = model_rf.evaluate(data_test)","f039cb4f":"dir(pred_rf)","14fd4e26":"pred_rf.accuracy","884154a5":"## Radom Forest","badff1a2":"## Logistic Regression"}}