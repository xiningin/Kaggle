{"cell_type":{"0937f555":"code","b0d0837c":"code","82e708c3":"code","2d0690ac":"code","df04571f":"code","709c8e16":"code","139f9fbc":"code","1573e2af":"code","45903478":"code","8fc45f55":"code","53d94c4b":"code","0f1b0477":"code","35c7544f":"code","8322678d":"code","aa77b672":"code","5217ae6f":"code","8a01e69f":"code","fb849df5":"code","950b1136":"code","1ddd970f":"code","5fe82889":"code","8b652f5d":"markdown","103aaf42":"markdown","df563b9e":"markdown","177c2b61":"markdown","eae5b6da":"markdown"},"source":{"0937f555":"import warnings; warnings.filterwarnings('ignore')\nimport numpy as np,pandas as pd,pylab as pl\nimport h5py,tensorflow_hub as th\nimport tensorflow as tf\nimport skimage.transform as st\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Dense,Dropout\nfrom keras.layers import Flatten,Input,BatchNormalization\nfrom keras.layers import Conv2D,MaxPooling2D,GlobalMaxPooling2D\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping","b0d0837c":"fpath2='..\/input\/classification-of-handwritten-letters\/'\nfw='weights.syn.hdf5'\ndef img_rotate(image,size):\n        angle=np.random.randint(-15,15)\n        img=st.rotate(image,angle,resize=True)\n        img=st.resize(img,(size,size))\n        return np.array(img*255,dtype=np.uint8)\ndef label5symbols(label,symbol):\n    length=len(label)\n    if length>=5:\n        return label\n    else:\n        no_labels=np.full((5-length),symbol)\n        res=np.concatenate((no_labels,label),axis=0)\n        return np.array(res,dtype=np.uint8)\ndef concat5symbols(i,rx,y,size,symbol):\n    k=np.random.randint(1,6)\n    img=rx[i]; label=y[i]\n    for j in range(1,k):\n        img=np.concatenate((img,rx[i+j]),axis=1)\n        label=np.concatenate((label,y[i+j]),axis=0)\n    if k!=5:\n        w1=np.random.randint(0,size*5-img.shape[1])\n        w2=size*5-img.shape[1]-w1        \n        img=np.concatenate((np.zeros((size,w1)),img,\n                            np.zeros((size,w2))),axis=1)\n    img=np.array(img,dtype=np.uint8)\n    label=label5symbols(label,symbol)\n    return [img,label,k]","82e708c3":"(x_train1,y_train1),(x_test1,y_test1)=\\\ntf.keras.datasets.mnist.load_data()\ny_train1=y_train1.reshape(-1,1)\ny_test1=y_test1.reshape(-1,1)\npd.DataFrame([[x_train1.shape,x_test1.shape,x_train1.dtype],\n              [y_train1.shape,y_test1.shape,y_train1.dtype]],\n             columns=['train','test','dtype'],\n             index=['images','labels'])","2d0690ac":"rx_train1=np.array([img_rotate(x_train1[i],28)\n                    for i in range(x_train1.shape[0])])\nrx_test1=np.array([img_rotate(x_test1[i],28)\n                   for i in range(x_test1.shape[0])])","df04571f":"pl.figure(figsize=(3,3))\npl.imshow(rx_train1[100],cmap=pl.cm.summer)\npl.title('example of rotated images \\n %s'%y_train1[100]);","709c8e16":"sx_train1=np.empty([rx_train1.shape[0],28,140])\nsy_train1=np.empty([y_train1.shape[0],5])\ni=0; c=0\nwhile i<rx_train1.shape[0]-5:\n    [image,label,k]=\\\n    concat5symbols(i,rx_train1,y_train1,28,10)\n    sx_train1[c]=image; sy_train1[c]=label\n    c+=1; i+=k\nsx_train1=np.array(sx_train1[:c],dtype=np.uint8)\nsy_train1=np.array(sy_train1[:c],dtype=np.uint8)\n[sx_train1.shape,sy_train1.shape]","139f9fbc":"pl.imshow(sx_train1[100],cmap=pl.cm.summer);\npl.title('example of concatenated images \\n %s'%\\\n         sy_train1[100]);","1573e2af":"sx_test1=np.empty([rx_test1.shape[0],28,140])\nsy_test1=np.empty([y_test1.shape[0],5])\ni=0; c=0\nwhile i<rx_test1.shape[0]-5:\n    [image,label,k]=\\\n    concat5symbols(i,rx_test1,y_test1,28,10)\n    sx_test1[c]=image; sy_test1[c]=label\n    c+=1; i+=k\nsx_test1=np.array(sx_test1[:c],dtype=np.uint8)\nsy_test1=np.array(sy_test1[:c],dtype=np.uint8)\n[sx_test1.shape,sy_test1.shape]","45903478":"sx_train1=sx_train1.reshape(-1,28,28*5,1)\nsx_test1=sx_test1.reshape(-1,28,28*5,1)\nn=int(len(sx_test1)\/2)\nsx_valid1,sy_valid1=sx_test1[:n],sy_test1[:n]\nsx_test1,sy_test1=sx_test1[n:],sy_test1[n:]\nsy_train1_list=[sy_train1[:,i] for i in range(5)]\nsy_valid1_list=[sy_valid1[:,i] for i in range(5)]\nsy_test1_list=[sy_test1[:,i] for i in range(5)]\nprint('Reshape the train set for models')\nprint(sx_train1.shape,sy_train1_list[0].shape)","8fc45f55":"f=h5py.File(fpath2+'LetterColorImages_123.h5','r') \nkeys=list(f.keys())\nletters=u'\u0430\u0431\u0432\u0433\u0434\u0435\u0451\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044a\u044b\u044c\u044d\u044e\u044f'\nimages=np.array(f[keys[1]])\/255\nimages=.7-np.dot(images[...,:3],[.299,.587,.114])**2\nimages=np.array(images*255,dtype=np.uint8)\nlabels=np.array(f[keys[2]],dtype=np.uint8).reshape(-1,1)-1\nx_train2,x_test2,y_train2,y_test2=\\\ntrain_test_split(images,labels,test_size=.2,random_state=1)\npd.DataFrame([[x_train2.shape,x_test2.shape,x_train2.dtype],\n              [y_train2.shape,y_test2.shape,y_train2.dtype]],\n             columns=['train','test','dtype'],\n             index=['images','labels'])","53d94c4b":"pl.figure(figsize=(3,3))\npl.imshow(x_train2[100],cmap=pl.cm.summer)\npl.title('example of images \\n %s'%\\\n         letters[y_train2[100][0]]);","0f1b0477":"sx_train2=np.empty([x_train2.shape[0],32,160])\nsy_train2=np.empty([y_train2.shape[0],5])\ni=0; c=0\nwhile i<x_train2.shape[0]-5:\n    [image,label,k]=\\\n    concat5symbols(i,x_train2,y_train2,32,33)\n    sx_train2[c]=image; sy_train2[c]=label\n    c+=1; i+=k\nsx_train2=np.array(sx_train2[:c],dtype=np.uint8)\nsy_train2=np.array(sy_train2[:c],dtype=np.uint8)\n[sx_train2.shape,sy_train2.shape]","35c7544f":"pl.imshow(sx_train2[100],cmap=pl.cm.summer);\npl.title('example of concatenated images \\n %s'%\\\n         sy_train2[100]);","8322678d":"sx_test2=np.empty([x_test2.shape[0],32,160])\nsy_test2=np.empty([y_test2.shape[0],5])\ni=0; c=0\nwhile i<x_test2.shape[0]-5:\n    [image,label,k]=\\\n    concat5symbols(i,x_test2,y_test2,32,33)\n    sx_test2[c]=image; sy_test2[c]=label\n    c+=1; i+=k\nsx_test2=np.array(sx_test2[:c],dtype=np.uint8)\nsy_test2=np.array(sy_test2[:c],dtype=np.uint8)\n[sx_test2.shape,sy_test2.shape]","aa77b672":"sx_train2=sx_train2.reshape(-1,32,32*5,1)\nsx_test2=sx_test2.reshape(-1,32,32*5,1)\nn=int(len(sx_test2)\/2)\nsx_valid2,sy_valid2=sx_test2[:n],sy_test2[:n]\nsx_test2,sy_test2=sx_test2[n:],sy_test2[n:]\nsy_train2_list=[sy_train2[:,i] for i in range(5)]\nsy_valid2_list=[sy_valid2[:,i] for i in range(5)]\nsy_test2_list=[sy_test2[:,i] for i in range(5)]\nprint('Reshape the train set for models')\nprint(sx_train2.shape,sy_train2_list[0].shape)","5217ae6f":"def syn_model1(size,n):    \n    model_input=Input(shape=(size,size*5,1))\n    x=BatchNormalization()(model_input)        \n    x=Conv2D(32,(5,5),activation='relu',\n             padding='same')(model_input)\n    x=MaxPooling2D(pool_size=(2,2))(x)     \n    x=Conv2D(32,(5,5),activation='relu',\n             padding='same')(x)\n    x=MaxPooling2D(pool_size=(2,2))(x)    \n    x=Dropout(.25)(x)\n    x=BatchNormalization()(x)\n    x=Conv2D(196,(5,5),activation='relu',\n             padding='same')(x) \n    x=MaxPooling2D(pool_size=(2,2))(x) \n    x=Dropout(.25)(x)    \n    x=Conv2D(196,(5,5),activation='relu',\n             padding='same')(x)\n    x=MaxPooling2D(pool_size=(2,2))(x) \n    x=Dropout(.25)(x)              \n    x=Flatten()(x)    \n    x=Dense(512,activation='relu')(x)    \n    x=Dropout(.25)(x)    \n    y=[Dense(n,activation='softmax')(x)\n       for i in range(5)]\n    model=Model(input=model_input,output=y)\n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='adam',metrics=['accuracy'])\n    return model","8a01e69f":"syn_model1=syn_model1(28,11)\ncheckpointer=ModelCheckpoint(filepath=fw,verbose=2,\n                             save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,\n                               verbose=2,factor=.5)\nsyn_model1.fit(sx_train1,sy_train1_list, \n               validation_data=(sx_valid1,sy_valid1_list), \n               epochs=30,batch_size=128,verbose=2,\n               callbacks=[checkpointer,lr_reduction])","fb849df5":"syn_model1.load_weights(fw)\nsyn_scores1=syn_model1.evaluate(sx_test1,sy_test1_list,verbose=0)\nprint(\"Scores: \\n\" ,(syn_scores1))\nprint(\"First digit. Accuracy: %.2f%%\"%(syn_scores1[6]*100))\nprint(\"Second digit. Accuracy: %.2f%%\"%(syn_scores1[7]*100))\nprint(\"Third digit. Accuracy: %.2f%%\"%(syn_scores1[8]*100))\nprint(\"Fourth digit. Accuracy: %.2f%%\"%(syn_scores1[9]*100))\nprint(\"Fifth digit. Accuracy: %.2f%%\"%(syn_scores1[10]*100))\navg_accuracy1=sum([syn_scores1[i] for i in range(6,11)])\/5\nprint(\"Synthetic MNIST. Average Accuracy: %.2f%%\"%(avg_accuracy1*100))","950b1136":"def syn_model2(size,n):    \n    model_input=Input(shape=(size,size*5,1))\n    x=BatchNormalization()(model_input)        \n    x=Conv2D(32,(5,5),activation='relu',\n             padding='same')(model_input)\n    x=MaxPooling2D(pool_size=(2,2))(x)     \n    x=Conv2D(32,(5,5),activation='relu',\n             padding='same')(x)\n    x=MaxPooling2D(pool_size=(2,2))(x)    \n    x=Dropout(.25)(x)\n    x=BatchNormalization()(x)\n    x=Conv2D(256,(5,5),activation='relu',\n             padding='same')(x) \n    x=MaxPooling2D(pool_size=(2,2))(x) \n    x=Dropout(.25)(x)    \n    x=Conv2D(256,(5,5),activation='relu',\n             padding='same')(x)\n    x=MaxPooling2D(pool_size=(2,2))(x) \n    x=Dropout(.25)(x)              \n    x=Flatten()(x)    \n    x=Dense(1024,activation='relu')(x)    \n    x=Dropout(.25)(x)    \n    y=[Dense(n,activation='softmax')(x)\n       for i in range(5)]\n    model=Model(input=model_input,output=y)\n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='adam',metrics=['accuracy'])\n    return model","1ddd970f":"syn_model2=syn_model2(32,34)\ncheckpointer=ModelCheckpoint(filepath=fw,verbose=2,\n                             save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',patience=5,\n                               verbose=2,factor=.5)\nestopping=EarlyStopping(monitor='val_loss',patience=20,verbose=2)\nsyn_model2.fit(sx_train2,sy_train2_list, \n               validation_data=(sx_valid2,sy_valid2_list), \n               epochs=100,batch_size=64,verbose=2,\n               callbacks=[checkpointer,lr_reduction,estopping])","5fe82889":"syn_model2.load_weights(fw)\nsyn_scores2=syn_model2.evaluate(sx_test2,sy_test2_list,verbose=0)\nprint(\"Scores: \\n\" ,(syn_scores2))\nprint(\"First letter. Accuracy: %.2f%%\"%(syn_scores2[6]*100))\nprint(\"Second letter. Accuracy: %.2f%%\"%(syn_scores2[7]*100))\nprint(\"Third letter. Accuracy: %.2f%%\"%(syn_scores2[8]*100))\nprint(\"Fourth letter. Accuracy: %.2f%%\"%(syn_scores2[9]*100))\nprint(\"Fifth letter. Accuracy: %.2f%%\"%(syn_scores2[10]*100))\navg_accuracy2=sum([syn_scores2[i] for i in range(6,11)])\/5\nprint(\"Synthetic Letters. Average Accuracy: %.2f%%\"%(avg_accuracy2*100))","8b652f5d":"## Synthetic Data #2","103aaf42":"## Synthetic Data #1","df563b9e":"## CNN\n### Synthetic Data #1","177c2b61":"### Synthetic Data #2","eae5b6da":"## Modules & Helpful Functions"}}