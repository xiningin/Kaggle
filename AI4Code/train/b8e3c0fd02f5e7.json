{"cell_type":{"608bab10":"code","64e38115":"code","e7df245e":"code","a7fbaddd":"code","032a9edc":"code","f432d3be":"code","d05faeb1":"code","39675318":"code","edc7ba5c":"code","be66ec95":"code","86cae651":"code","6c4956f0":"code","669bff14":"code","65298d27":"code","51d58905":"code","1644da06":"code","d6da344d":"code","c2415608":"code","37934c65":"code","30b258c0":"code","f5e493ec":"markdown","47bf52aa":"markdown","1fa9b49f":"markdown","d994131a":"markdown","cc3b6746":"markdown","d12f73bc":"markdown","43d31728":"markdown","d72dd572":"markdown","2dd5599a":"markdown","3155b8b4":"markdown"},"source":{"608bab10":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\n%matplotlib inline","64e38115":"my_data_dir = r'\/kaggle\/input\/03-keypoint-movenet-v2\/'","e7df245e":"os.listdir(my_data_dir)","a7fbaddd":"#Loading data from previous notebook\ntrain_df = pd.read_csv(my_data_dir + 'train_df.csv', index_col = 0)\ntest_df = pd.read_csv(my_data_dir + 'test_df.csv', index_col = 0)\nval_df = pd.read_csv(my_data_dir + 'val_df.csv', index_col = 0)\ntrain_df.shape, test_df.shape, val_df.shape","032a9edc":"train_df.head()","f432d3be":"train_df = train_df.drop(['image_name','keypoint'], axis = 1)\ntest_df = test_df.drop(['image_name','keypoint'], axis = 1)\nval_df = val_df.drop(['image_name','keypoint'], axis = 1)","d05faeb1":"train_df.shape, test_df.shape, val_df.shape","39675318":"X_train, y_train = train_df.drop('category', axis = 1), train_df['category']\nX_test, y_test = test_df.drop('category', axis = 1), test_df['category']\nX_val, y_val = val_df.drop('category', axis = 1), val_df['category']","edc7ba5c":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils\n# encode class values as integers\nencoder = LabelEncoder()\n\n# Onehot encoding steps\nencoder.fit(y_train)\nencoded_y_train = encoder.transform(y_train)\n# convert integers to dummy variables (i.e. one hot encoded)\ny_train = np_utils.to_categorical(encoded_y_train)\n\nencoder.fit(y_test)\nencoded_y_test = encoder.transform(y_test)\n# convert integers to dummy variables (i.e. one hot encoded)\ny_test = np_utils.to_categorical(encoded_y_test)\n\nencoder.fit(y_val)\nencoded_y_val = encoder.transform(y_val)\n# convert integers to dummy variables (i.e. one hot encoded)\ny_val = np_utils.to_categorical(encoded_y_val)","be66ec95":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout\nfrom tensorflow.keras.constraints import max_norm","86cae651":"num_classes = len(train_df['category'].unique())\nnum_classes","6c4956f0":"model = Sequential()\n# https:\/\/stats.stackexchange.com\/questions\/181\/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n# input layer\nmodel.add(Dense(51,  input_dim=51, activation='relu'))\nmodel.add(Dropout(0.2))\n# hidden layer\nmodel.add(Dense(40, activation='relu'))\nmodel.add(Dropout(0.2))\n# hidden layer\nmodel.add(Dense(30, activation='relu'))\nmodel.add(Dropout(0.2))\n# hidden layer\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dropout(0.2))\n# output layer\nmodel.add(Dense(units=num_classes,activation='softmax'))\n\n# Compile model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","669bff14":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(\n    min_delta=0.005, \n    patience=5, \n    restore_best_weights=True\n)\n\nmodel.fit(x=X_train, \n          y=y_train, \n          epochs=25,\n          batch_size=256,\n          validation_data=(X_test, y_test), \n          callbacks = [early_stopping]\n          )","65298d27":"model.evaluate(x=X_val,y = y_val)","51d58905":"model = Sequential()\n# https:\/\/stats.stackexchange.com\/questions\/181\/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n# input layer\nmodel.add(Dense(51,  input_dim=51, activation='relu'))\nmodel.add(Dropout(0.4))\n# hidden layer\nmodel.add(Dense(40, activation='relu'))\nmodel.add(Dropout(0.5))\n# output layer\nmodel.add(Dense(units=num_classes,activation='softmax'))\n\n# Compile model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","1644da06":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(\n    min_delta=0.005, \n    patience=5, \n    restore_best_weights=True\n)\n\nmodel.fit(x=X_train, \n          y=y_train, \n          epochs=25,\n          batch_size=256,\n          validation_data=(X_test, y_test), \n          callbacks = [early_stopping]\n          )","d6da344d":"from sklearn.metrics import classification_report,confusion_matrix","c2415608":"predictions = model.predict(X_train)\nclass_labels_prediction_train = np.argmax(predictions, axis=1)\nclass_labels_train_data = np.argmax(y_train, axis=1)\nprint(classification_report(class_labels_train_data,class_labels_prediction_train))","37934c65":"predictions = model.predict(X_test)\nclass_labels_prediction_test = np.argmax(predictions, axis=1)\nclass_labels_test_data = np.argmax(y_test, axis=1)\nprint(classification_report(class_labels_test_data,class_labels_prediction_test))","30b258c0":"predictions = model.predict(X_val)\nclass_labels_prediction_val = np.argmax(predictions, axis=1)\nclass_labels_val_data = np.argmax(y_val, axis=1)\nprint(classification_report(class_labels_val_data,class_labels_prediction_val))","f5e493ec":"# 1. Importing keypoint data from previous notebook","47bf52aa":"# 3. Preprocessing the data to build an ANN model","1fa9b49f":"We found that the model is still overfitting, so this approach might not work well.  Let's try extracting more features from the keypoint data.","d994131a":"# 2. Setting up train\/test\/validation dataframes","cc3b6746":"# DAAN570 - Final Project - RSI Prevention by Yoga - Modelling notebook\n<br>Team: 11: Suradech Kongkiatpaiboon and Burq Latif\nCourse: DAAN 570 \u2013 Deep Learning (Fall, 2021) - Penn State World Campus\n\n> Problem statement : Repetitive stress injury is extremely prevalent for anyone who works at the same spot for a long length of time, especially with the development of COVID-19 and the increase in work from home trend. We've identified certain flaws in traditional RSI prevention software on the market, and we've noted that yoga's popularity is growing by the day. The reason for this is the numerous physical, mental, and spiritual advantages that yoga may provide. Many people are following this trend and practice yoga without the help of a professional. However, doing yoga incorrectly or without adequate instruction can lead to serious health problems such as strokes and nerve damage. As a result, adhering to appropriate yoga poses is a vital consideration.\nIn this work, we present a method for identifying the user's postures and providing visual guidance to the user. In order to be more engaging with the user, this procedure is done in real-time and utilizes the traditional webcam on the laptop\/desktop to run the application.\n\nKeywords : Yoga, posture, classification, movenet, keypoint\n\nData Collection:\nWe took some images from open source yoga posture dataset from three following sites and applied basic data cleaning manually (e.g. remove corrupted images, remove misclassified yoga posture images).\n1. Open source dataset from https:\/\/www.kaggle.com\/general\/192938\n2. 3D synthetic dataset from https:\/\/laurencemoroney.com\/2021\/08\/23\/yogapose-dataset.html\n3. Yoga-82 dataset from https:\/\/sites.google.com\/view\/yoga-82\/home","d12f73bc":"# 4. Model building","43d31728":"This is the 5th notebook of total 5 notebooks in this series listed as following:\n1. EDA and image augmentation note books >> https:\/\/www.kaggle.com\/suradechk\/01-eda-and-image-augmentation-v2\n2. Setting up a baseline model using CNN >> https:\/\/www.kaggle.com\/suradechk\/02-baseline-model-using-cnn-v2\n3. Keypoint generation using movenet >> https:\/\/www.kaggle.com\/suradechk\/03-keypoint-movenet-v2\n4. Classification keypoint output using classical ML >> https:\/\/www.kaggle.com\/suradechk\/04-classification-using-keypoints-output-v2\n5. Classification keypoint output using ANN >> https:\/\/www.kaggle.com\/suradechk\/05-classification-using-ann-v2","d72dd572":"# 5. Viewing output in confusion matrix","2dd5599a":"It appears that our model can be easily overfitted with the training data. Let's try fewer layers with more dropouts.","3155b8b4":"# Getting accuracy of validation set"}}