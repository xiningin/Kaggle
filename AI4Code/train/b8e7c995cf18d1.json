{"cell_type":{"4c7bac4f":"code","d2fb8995":"code","3c700379":"code","e817eeb2":"code","6653e902":"code","caaa1703":"code","b5c56c7b":"code","85e208b5":"code","1d5296b0":"code","6e00fa0a":"code","d1d42e67":"code","d7008927":"code","5a798c9a":"code","c4b65264":"code","8c05d1a5":"code","6199b7d9":"code","ad5788e8":"code","daeaa60f":"code","ed639e87":"code","7fa1a3d2":"code","6d385fba":"code","c2acae4d":"code","251921ed":"code","4115c072":"code","2898414a":"code","2852a1c9":"code","7a34a303":"code","7f701ecc":"code","6bfe899b":"code","15ef50d7":"code","80c20bb4":"code","c0cb78cd":"code","b9e569fe":"code","9e24ebd6":"code","baa75c49":"code","5ff25396":"code","485e8601":"markdown","e707c896":"markdown","6b0b9c73":"markdown","4eb7a071":"markdown","0b8f3aef":"markdown","1cbc5218":"markdown","e5b4e67e":"markdown","d89a7595":"markdown","36408ba0":"markdown","109b0e1c":"markdown","f3e8b50b":"markdown","cffc9765":"markdown","96572f64":"markdown","911664d9":"markdown","f07446a4":"markdown","c09d54a0":"markdown","6c76978d":"markdown","1d99fe3a":"markdown","615bc65e":"markdown","0bdee9bd":"markdown","b2aa5706":"markdown","b55c4761":"markdown","c69d5bfb":"markdown","46f90f72":"markdown","f7ef56ff":"markdown","d572f481":"markdown"},"source":{"4c7bac4f":"# Import the required libraries \nimport scipy as sp\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport os\nprint(os.listdir(\"..\/input\"))","d2fb8995":"# Load CSV data\nspam_df = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv', encoding='latin-1')\nspam_df.head()","3c700379":"# Only get the label and text feature\nspam_df = spam_df[['v1','v2']]\nspam_df.columns = ['label','text']\n\n# Convert spam\/ham label into binary output\nclass_labels = [\"ham\",'spam']\nspam_df['label'] = spam_df['label'].apply(class_labels.index)\n\nspam_df.head()","e817eeb2":"# Check class distrubtion of target - About 14% spam and 86% ham\nspam_df.label.value_counts() ","6653e902":"# Plot the class distribution\nspam_df[\"label\"].value_counts().plot(kind = 'pie', explode = [0, 0.1], figsize = (6, 6), shadow = True)\nplt.ylabel(\"Spam vs Ham\")\nplt.legend([\"Ham\", \"Spam\"])\nplt.show()","caaa1703":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(spam_df,spam_df['label'],test_size=0.20, random_state=123, stratify=spam_df['label'])","b5c56c7b":"# Examine the text reviews\ntext1 = x_train['text'][100]\ntext1","85e208b5":"from nltk.tokenize import word_tokenize\ntokens = word_tokenize(text1)\nprint(tokens)","1d5296b0":"# Load Stemming Library (PorterStemmer)\nfrom nltk.stem.porter import PorterStemmer\n# Load TFIDFVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","6e00fa0a":"porter = PorterStemmer()\nx_train['text'] = x_train['text'].apply(porter.stem)","d1d42e67":"from sklearn.feature_extraction.text import TfidfVectorizer\n# Initialize TFIDFVectorizer with stop word removal and lowercasing of text\ncv = TfidfVectorizer(stop_words='english', lowercase=True)","d7008927":"x_train_CV = cv.fit_transform(x_train['text'])","5a798c9a":"# A function that cleans and performs a TFIDF transformation to our text data\ntfidf = TfidfVectorizer(stop_words='english', lowercase=True)\ndef tfidf_pipeline(txt, flag):\n    if flag == \"train\":\n        txt = txt.apply(porter.stem) # Apply Stemming on train set\n        x = tfidf.fit_transform(txt) # Apply Vectorizer, Stopword Removal, & Lowercasing on train set\n    else:\n        txt = txt.apply(porter.stem) # Apply Stemming on test set\n        x = tfidf.transform(txt) # Apply Vectorizer, Stopword Removal, & Lowercasing on test set\n    return x ","c4b65264":"x_train_TFIDF = tfidf_pipeline(x_train['text'], flag=\"train\")\nx_test_TFIDF = tfidf_pipeline(x_test['text'], flag=\"test\")","8c05d1a5":"#original vs preprocessed data\noriginal = x_train.shape\npreprocessed = x_train_TFIDF.shape\nprint (\"Our original training set shape: \" + str(original))\nprint (\"Our preprocessed training set shape: \" + str(preprocessed))","6199b7d9":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_fscore_support as score","ad5788e8":"rf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\nrf_model = rf.fit(x_train_TFIDF,y_train)","daeaa60f":"rf_result = cross_val_score(rf_model, x_train_TFIDF, y_train, cv=5, scoring='accuracy')\nrf_result.mean()","ed639e87":"y_pred = rf_model.predict(x_test_TFIDF)\nprecision_1, recall_1, fscore_1, support_1 = score(y_test, y_pred, pos_label=1, average ='binary')\nprint('Classification Report (With Only Text) | Precision : {} \/ Recall : {} \/ fscore : {} \/ Accuracy: {}'.format(round(precision_1,3),round(recall_1,3),round(fscore_1,3),round((y_pred==y_test).sum()\/len(y_test),3)))","7fa1a3d2":"confusion_matrix(y_test, y_pred)","6d385fba":"# Import additional libraries\nfrom scipy.sparse import csr_matrix, hstack\n# Examine New Dataset with 'length' feature\n# Add a column for the lenght of the SMS text\nspam_df['length'] = spam_df['text'].str.len()\nspam_df.head()","c2acae4d":"# Plot the distribution of text length (spam vs ham)\nplt.figure(figsize=(15,6))\nplt.hist(spam_df[spam_df['label']==1]['length'],bins = np.linspace(0,200,num=40),alpha=0.4,label='spam',normed=True)\nplt.hist(spam_df[spam_df['label']==0]['length'],bins = np.linspace(0,200,num=40),alpha =0.4,label ='ham', normed=True)\nplt.legend(loc ='upper left')\nplt.title('Length Distribution of Spam VS Ham')\nplt.show()","251921ed":"x_train2, x_test2, y_train2, y_test2 = train_test_split(spam_df,spam_df['label'],test_size=0.20, random_state=123, stratify=spam_df['label'])","4115c072":"# Get TFIDF Transformed Matrix on 'text'\nx_train_TFIDF = tfidf_pipeline(x_train2['text'], flag=\"train\")\nx_test_TFIDF = tfidf_pipeline(x_test2['text'], flag=\"test\")\n\n# Convert length column into csr_matrix\nx_train_len = csr_matrix(x_train2[['length']])\nx_test_len =  csr_matrix(x_test2[['length']])\n\n# Merge matrices together\nx_train_merge = hstack((x_train_TFIDF, x_train_len)).tocsr()\nx_test_merge = hstack((x_test_TFIDF, x_test_len)).tocsr()","2898414a":"rf_model2 = rf.fit(x_train_merge,y_train2)","2852a1c9":"# Apply 10-Fold Cross Validation and Examine Accuracy Score\nrf_result2 = cross_val_score(rf_model2, x_train_merge, y_train2, cv=10, scoring='accuracy')\nrf_result2.mean()","7a34a303":"y_pred2 = rf_model2.predict(x_test_merge)\nprecision_2, recall_2, fscore_2, support_2 = score(y_test2, y_pred2, pos_label=1, average ='binary')","7f701ecc":"print(' Classification Report (With Text) \\n Precision : {} \/ Recall : {} \/ fscore : {} \/ Accuracy: {}'.format(round(precision_1,3),round(recall_1,3),round(fscore_1,3),round((y_pred==y_test).sum()\/len(y_test),3)))\nprint('\\n Classification Report (With Text & Length)\\n Precision : {} \/ Recall : {} \/ fscore : {} \/ Accuracy: {}'.format(round(precision_2,3),round(recall_2,3),round(fscore_2,3),round((y_pred2==y_test2).sum()\/len(y_test2),3)))","6bfe899b":"print('Confusion Matrix (With Text)')\nprint(confusion_matrix(y_test, y_pred))\nprint('Confusion Matrix (With Text & Length)')\nprint(confusion_matrix(y_test2, y_pred2))\nprint(\"Made 6 less false negative errors\")","15ef50d7":"# Examine misclassified SMS text \nmissclassified = np.nonzero(y_pred2!=y_test2)[0]\nind_miss = y_test2.index[missclassified]\nspam_df.iloc[ind_miss,:]","80c20bb4":"alexa_df = pd.read_csv('..\/input\/amazon-alexa-reviews\/amazon_alexa.tsv', sep = '\\t')\nalexa_df = alexa_df[['date']]\nalexa_df.head()","c0cb78cd":"# Convert the column into a date time object\nalexa_df['date'] = pd.to_datetime(alexa_df['date'])\n\n# Create a new 'year' feature by extracting the year value from date\nalexa_df['year'] = alexa_df.date.dt.year\n\n# Create a new 'month' feature by extracting the month value from date\nalexa_df['month'] = alexa_df.date.dt.month\n\n# Create a new 'day' feature by extracting the day value from date\nalexa_df['day'] = alexa_df.date.dt.day\n\n# Create a new 'Qtr' feature by extracting the monthly quarter from date\nalexa_df['Qtr'] = alexa_df.date.dt.quarter","b9e569fe":"# Examine new data frame\nalexa_df.head()","9e24ebd6":"# Create holiday dates\nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\ncal = calendar()\nholidays = cal.holidays()\n\n# Examine holiday dates\ncal.holidays()","baa75c49":"# Create New Column 'Holiday'\nalexa_df['Holiday'] = alexa_df['date'].isin(holidays)\nalexa_df.tail()","5ff25396":"def calculate_xmas(date):\n    xmas = pd.to_datetime(pd.Series('2018-12-25'))\n    diff = xmas - date\n    return diff\n\nalexa_df['days_before_xmas'] = alexa_df.date.apply(calculate_xmas)\nalexa_df.head()","485e8601":"** Random Forest model to the new data**\n","e707c896":"**2. Stopword Removal & Lowercasing**","6b0b9c73":"**Text Pre-Process Pipeline**","4eb7a071":"**1. Stemming Words**","0b8f3aef":"**Evaluate**","1cbc5218":"**10-Fold Cross Validation**","e5b4e67e":"**Modeling**","d89a7595":"**Examine misclassified SMS Text**","36408ba0":"**Feature Engineering with Dates**","109b0e1c":"**3. Apply TFIDF**","f3e8b50b":"**Feature Engineering with Text & Dates**\n* Tokenization, stemming, and normalizing of text\n* TFIDF Vectorization\n* Feature engineering (length of SMS text)\n* Training classification model using Random Forest\n* Evaluating and Compare Performance of the trained classification model","cffc9765":"**Extracting Holidays**","96572f64":"**Train and Test Split of the new dataframe**\n","911664d9":"**Train\/Test Split**","f07446a4":"**Confusion Matrix**","c09d54a0":"**Calculating Days Before Two Given Dates**","6c76978d":"**Cross Validiation**\n\nApply 10-Fold Cross Validation","1d99fe3a":"**Extracting Date, Month, Year, and Quarter**","615bc65e":"**Text Pre-Processing Pipeline**\n","0bdee9bd":"**Feature Engineering**","b2aa5706":"**Classification Report**","b55c4761":"**Confusion Matrix**","c69d5bfb":"**Pre-Processing Pipeline**\n* Tokenization\n* Lower casing\n* Stopword removal\n* Stemming\n* Transformmation (TFIDFVectorizer)","46f90f72":"**Transform and Merge into one matrix**\n","f7ef56ff":"**Logistic Regression Model**","d572f481":"**Tokenization**"}}