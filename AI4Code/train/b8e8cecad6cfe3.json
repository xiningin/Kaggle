{"cell_type":{"29e52b43":"code","833b76b5":"code","79fc4701":"code","e51e08e2":"code","c0254a92":"code","19f80bf0":"code","a9faf239":"code","831415a5":"code","33e4cbae":"code","7eac5b56":"code","9e7232b5":"code","7d4eabc6":"code","0b493b01":"code","2dbd4564":"code","f2e73f0c":"code","c89fad50":"code","77e46009":"code","ed0da2df":"code","1bf47bdf":"code","a4349647":"code","0c535934":"code","40e1e9e7":"code","8cf240a3":"code","d7768c2b":"code","ae682ec3":"code","a755ec57":"code","a30aa1bc":"code","b5ec652d":"code","8f5c21b2":"code","5c8f64dc":"code","7302e0d4":"code","40c2eb90":"code","fc44043a":"code","e81a97da":"code","e0ffaed9":"code","be1001c5":"code","91312e00":"code","d88ecf55":"code","23bbd531":"code","8dfabe62":"code","0cb954c7":"code","4a6d4b7b":"code","cb7ac3c8":"code","6ed75dab":"markdown","a98c12f1":"markdown","75c4d18f":"markdown","bdf44751":"markdown","c03d1bf3":"markdown","97562f1b":"markdown","60040329":"markdown","7144fd2b":"markdown","500c9f64":"markdown","6111684c":"markdown","4f166496":"markdown","7d3fef3c":"markdown","f45ed57c":"markdown","be68f362":"markdown","54acffa1":"markdown","54ad4637":"markdown","bee3069a":"markdown","4a0e1b5a":"markdown","9d0ac1c4":"markdown","60971ad3":"markdown","37d0d91f":"markdown","449f2e54":"markdown","8989f481":"markdown","d7320a9d":"markdown","d5f3571e":"markdown","efed1612":"markdown","f4ee2050":"markdown","1cf17969":"markdown","f6c2adac":"markdown","311941a0":"markdown","9d516fbe":"markdown","733ef935":"markdown","36c91194":"markdown","7b8e9273":"markdown","9234b1e2":"markdown","e5517fea":"markdown","4b59006e":"markdown","ce912536":"markdown","9f617a55":"markdown","df62d842":"markdown","4fced501":"markdown","2abd3898":"markdown"},"source":{"29e52b43":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","833b76b5":"# Data Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","79fc4701":"pd.set_option(\"display.max_columns\", 100)\n\n# load train data\ndata = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/train.csv\", index_col=\"Id\")\n\n","e51e08e2":"data.shape","c0254a92":"data.head()","19f80bf0":"categorical_cols = data.select_dtypes(include=['object']).columns\nnumberical_cols = data.select_dtypes(exclude=['object']).columns\nprint(\"Numberical columns: \", len(numberical_cols))\nprint(\"Categorical columns: \", len(categorical_cols))","a9faf239":"data[numberical_cols].describe()","831415a5":"data[categorical_cols].describe()","33e4cbae":"fig = plt.figure(figsize=(30,1))\nnumberical_col_corr = data[numberical_cols].corr().loc[[\"SalePrice\"],:].sort_values(by=\"SalePrice\",axis=1)\nsns.heatmap(data=numberical_col_corr, annot=True)","7eac5b56":"weak_corr_threadhold = 0.2\nweak_numberical_cols = list(numberical_col_corr[abs(numberical_col_corr) < weak_corr_threadhold].dropna(axis=1))\nprint(\"There are %d weak correlated(< %.2f) variables with SalePrice:\" % (len(weak_numberical_cols), weak_corr_threadhold))\nprint(weak_numberical_cols)","9e7232b5":"strong_numberical_cols = numberical_col_corr.columns[len(weak_numberical_cols):-1][::-1]\nstrong_cols_num = len(strong_numberical_cols)\n\nprint(\"There are %d strong correlated(> %.2f) variables with SalePrice:\" % (strong_cols_num-1, weak_corr_threadhold))\nprint(list(strong_numberical_cols))","7d4eabc6":"numberical_null_count = data[numberical_cols].isnull().sum()\nprint(\"Missing values: \")\nprint(numberical_null_count[numberical_null_count>0])","0b493b01":"plt.rcParams.update({'font.size': 14})\n\ndef explore_variable(col_name):\n    strong_crr_cols = find_high_corelated_variables(col_name)\n    draw_variable([col_name] + strong_crr_cols)\n\n\ndef draw_variable(col_names):\n    num_cols = len(col_names)\n    fig = plt.figure(figsize=(8, num_cols*4))\n    i = 0\n    for col in col_names:\n        fig.add_subplot(num_cols, 2, 2*i+1)\n        sns.regplot(x=data[col], y=data[\"SalePrice\"])\n        plt.xlabel(col)\n        plt.title('Corr to SalePrice = %.2f'% numberical_col_corr[col])\n        fig.add_subplot(num_cols, 2, 2*i+2)\n        sns.distplot(data[col].dropna())\n        plt.xlabel(col)\n        i += 1\n        \n    plt.tight_layout()\n\n        \n\n\nvariable_corr = data[list(set(numberical_cols)-set([\"SalePrice\"]))].corr()\nhigh_corr_threadhold = 0.7\n\ndef find_high_corelated_variables(col_name):\n    corr = variable_corr.loc[[col_name],:]\n    strong_corr = corr[(corr>=high_corr_threadhold) & (corr<1)].dropna(axis=1)\n    print(\"Strong corelated variables:\")\n    print(strong_corr)\n    return list(strong_corr.columns)","2dbd4564":"explore_variable(\"OverallQual\")","f2e73f0c":"explore_variable(\"GrLivArea\")","c89fad50":"data[\"GrLivArea\"].describe()","77e46009":"data[\"GrLivArea\"].sort_values().tail()","ed0da2df":"explore_variable(\"GarageCars\")","1bf47bdf":"explore_variable(\"1stFlrSF\")","a4349647":"explore_variable(\"TotalBsmtSF\")","0c535934":"explore_variable(\"TotRmsAbvGrd\")","40e1e9e7":"explore_variable(\"YearBuilt\")","8cf240a3":"explore_variable(\"YearRemodAdd\")\n\n","d7768c2b":"explore_variable(\"GarageYrBlt\")","ae682ec3":"explore_variable(\"MasVnrArea\")","a755ec57":"explore_variable(\"Fireplaces\")","a30aa1bc":"explore_variable(\"BsmtFinSF1\")","b5ec652d":"explore_variable(\"LotFrontage\")","8f5c21b2":"explore_variable(\"WoodDeckSF\")","5c8f64dc":"explore_variable(\"2ndFlrSF\")","7302e0d4":"explore_variable(\"OpenPorchSF\")","40c2eb90":"explore_variable(\"HalfBath\")","fc44043a":"explore_variable(\"LotArea\")\n","e81a97da":"explore_variable(\"BsmtFullBath\")\n","e0ffaed9":"explore_variable(\"BsmtUnfSF\")","be1001c5":"fig = plt.figure(figsize=(6,12))\nsns.lmplot(x=\"MasVnrArea\", y=\"SalePrice\", hue=\"KitchenQual\", data=data) ","91312e00":"fig = plt.figure(figsize=(6,12))\nsns.lmplot(x=\"2ndFlrSF\", y=\"SalePrice\", hue=\"KitchenQual\", data=data) ","d88ecf55":"unique_val_num_dict = {col:len(data[col].unique())  for col in categorical_cols}\nsorted(unique_val_num_dict.items(), key=lambda x: x[1])","23bbd531":"null_count = data[categorical_cols].isnull().sum()\nnull_count[null_count>0].dropna(axis=0)\n","8dfabe62":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n\nmedian_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('std_scaler', StandardScaler()),\n])\n\nzero_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n    ('std_scaler', StandardScaler()),\n])\n#zero_transformer = SimpleImputer(strategy='constant', fill_value=0)\n#median_transformer = SimpleImputer(strategy='median')\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n","0cb954c7":"drop_cols =  ['Alley', 'PoolQC', 'Fence', 'MiscFeature'] + ['TotalBsmtSF', 'GarageYrBlt'] + ['KitchenAbvGr', 'EnclosedPorch', 'MSSubClass', 'OverallCond', 'YrSold', 'LowQualFinSF', 'MiscVal', 'BsmtHalfBath', 'BsmtFinSF2', '3SsnPorch', 'MoSold', 'PoolArea', 'ScreenPorch', 'BedroomAbvGr']\nzero_fill_cols  = ['MasVnrArea', 'Fireplaces', 'WoodDeckSF', '2ndFlrSF', 'OpenPorchSF', 'HalfBath', 'BsmtFullBath']\nmedian_fill_cols =  ['OverallQual', 'GrLivArea', 'GarageCars', '1stFlrSF', 'TotRmsAbvGrd', 'BsmtFinSF1', 'LotFrontage', 'LotArea', 'BsmtUnfSF']\n\npreprocessor = ColumnTransformer(\n                transformers=[\n                    ('num_zero', zero_transformer, zero_fill_cols),\n                    ('median_zero', median_transformer, median_fill_cols),\n                    ('cat', categorical_transformer, list(set(categorical_cols) - set(['Alley', 'PoolQC', 'Fence', 'MiscFeature'])))\n                ])\n\ntrain_data = data.copy()\ntrain_data.drop(drop_cols, axis=1, inplace=True)\ntrain_data.drop(train_data[(train_data['GrLivArea'] > 4500) |\n                (train_data['1stFlrSF'] > 5000) |\n                (train_data['BsmtFinSF1'] > 4000) |\n                (train_data['LotFrontage'] > 300)].index\n                ,axis=0, inplace=True)\n\ny = train_data.SalePrice\nX = train_data.drop('SalePrice', axis=1)\nfeature_cols = list(X.columns)","4a6d4b7b":"X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\n#plt.figure(figsize=(6,6))\n#sns.distplot(X_valid_full[\"OverallQual\"])\n#sns.distplot(test_data[\"OverallQual\"])\n#plt.legend([\"OverallQual valid\", \"OverallQual test\"])","cb7ac3c8":"\nmodel = XGBRegressor(n_estimators=1000,\n                         learning_rate=0.05, \n                         early_stopping_rounds=20, \n                         eval_set=[(X_valid_full, y_valid)],\n                         random_state=0)\n\n#model = XGBRegressor(n_estimators=1000,learning_rate = 0.01,random_state=0)\n\nmy_pipeline = Pipeline([\n    ('preprocess', preprocessor),\n    ('model', model)])\n\nmy_pipeline.fit(X_train_full,y_train)\n\nmae = mean_absolute_error(y_valid, my_pipeline.predict(X_valid_full))\nprint(\"MAE:\" ,mae)\n\n\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/test.csv\", index_col=\"Id\")\npredict_result = my_pipeline.predict(test_data[feature_cols])\noutput = pd.DataFrame({'Id':test_data.index, \n                        'SalePrice':predict_result})\noutput.to_csv('submission.csv', index=False)","6ed75dab":"### LotFrontage\n- Left skew distribution\n- 2 outliers( >300)\n- Missing values can be filled by median()","a98c12f1":"## 1.1 Data overview","75c4d18f":"As show bellow, by addition of KitchenQual, the price ranges are seperated quite clearly.\n\nBasically, we will use all categorical columns and using One Hot Encoding but with large number of unique value we can consider to use LabelEncoder, CountEncoder, TargetEncoder or CatBoostEncoder.\n\nWe also need to remove un-useful columns, which has large number of missing values.","bdf44751":"### BsmtFinSF1\n- Left skew distribution. Almost values are 0.\n- 1 outlier(>4000)\n- Missing value can be filled by median()","c03d1bf3":"Here is some sample rows","97562f1b":"Let see scatter plot and distribution of each variables","60040329":"### HalfBath\n- ? distribution\n- No outlier\n- Missing value can be fill as 0( most frequent value)","7144fd2b":"# 3. Modeling","500c9f64":"Now is time for modeling","6111684c":"# 1.3 Exploring categorical variables","4f166496":"The numberical columns have following characteristics:","7d3fef3c":"### YearRemodAdd\n- ? distribution\n- At the first look, maybe some outlier where the price went too high. However go back to OverallQual scatter plot, these house has OverallQual 10. It's resonable. -> No oulier\n- Missing value should be fill by YearBuilt value. However, in both train and test dataset there is no null value of YearRemodAdd, so we don't need to fill this variavle.","f45ed57c":"### 2ndFlrSF\n- Left skew distribution. Most values are 0\n- No outliers\n- Missing value can be filled by 0","be68f362":"### 1stFlrSF\n- Left skew of distribution\n- 1 outlier (>5000)\n- The missing value can be filled by median()\n- We can remove strong related variable TotalBsmtSF ","54acffa1":"### OpenPorchSF\n- Left skew distribution. Most values are 0\n- No outlier\n- Missing values can be filled by 0","54ad4637":"### BsmtFullBath\n- ? distribution\n- No outlier\n- Missing value can be filled by 0(most frequent value)","bee3069a":"### MasVnrArea\n- Left skew distribution. Almost values = 0\n- No outlier\n- Missing value can be filled by 0","4a0e1b5a":"### Fireplaces\n- ? distribution\n- No outlier\n- Missing value can be filled as 0 (No Fireplaces-most_frequent_value)","9d0ac1c4":"## Look at correations with SalePrice\n\n","60971ad3":"### LotArea\n- Left skew distribution\n- No outlier\n- Missing values can be filled by median()","37d0d91f":"The categorical columns have following characteristics:","449f2e54":"# 1.2 Exploring numberical variables\n","8989f481":"We have 80 columns(included the target) and 1460 rows of training data.\nSo we have 79 potential features or variables.","d7320a9d":"### TotalBsmtSF\n- We will remove it and use 1stFlrSF.","d5f3571e":"# Overview\nI am trying to lear Data Science. After finish some [kaggle's micro courses](https:\/\/www.kaggle.com\/learn\/overview), this is my first kernel on kaggle.\nIf you have any advice for me, please left me a comment. It would be greatly appreciated.\n\n\n* 1. Data exploring\n    * 1.1 Data overview\n    * 1.2 Exploring numberical columns\n    * 1.3 Exploring categorical columns\n\n* 2. Data clean and preprocess\n  \n* 3. Modeling","efed1612":"The number of unique values each variable are show as bellow.\nNot much of variable so we will apply One Hot Encoding for all categorical variables.","f4ee2050":"I divide dataset to 2 parts(0.8\/0.2).\nBelow is the distribution of SalePrice each part.","1cf17969":"### YearBuilt\n- Right skew distribution\n- No outlier\n- This is basic infomation of a hourse, so the columns should not has any missing values.\n- We can remove strong related variable GarageYrBlt","f6c2adac":"### GarageYrBlt\nWe will remove it and use YearBuilt","311941a0":"- Find out low correlated variable with SalePrice. We will not using them.\n- Find out strong correlations which we will use for modeling. And look closer.\n    - Because outliers can influence heavily the correlation, we need to detect ouliers(distribution, scatter plot) them remove these rows\n    - Find out missing value and find strategy(constant, mean, median) to fill\n    - Find strong corelated variables(similar feature). We can consider use one of them.","9d516fbe":"## 2. Data clean and preprocess","733ef935":"Following [kaggle micro course](https:\/\/www.kaggle.com\/learn\/intermediate-machine-learning) , I only know how to use DecisionTree, RandomForest and XGBoost.\nXGBoost gets the best accuracy so I use XGBoost. (I will try apply model turing after learn more about ML Algorithms)","36c91194":"### TotRmsAbvGrd\n- Slightly left skew distribution\n- No outlier\n- The missing values can be filled by median()\n- Keep both TotRmsAbvGrd and TotRmsAbvGrd","7b8e9273":"## Numberical columns\n\n* Drop columns: \n    * Have strong corelated with other variables:\n        * ['TotalBsmtSF', 'GarageYrBlt']\n    * Weak corelation with SalePrice: \n        * ['KitchenAbvGr', 'EnclosedPorch', 'MSSubClass', 'OverallCond', 'YrSold', 'LowQualFinSF', 'MiscVal', 'BsmtHalfBath', 'BsmtFinSF2', '3SsnPorch', 'MoSold', 'PoolArea', 'ScreenPorch', 'BedroomAbvGr']\n\n\n* Fill missing values\n    * by zero:\n        * ['MasVnrArea', 'Fireplaces', 'WoodDeckSF', '2ndFlrSF', 'OpenPorchSF', 'HalfBath', 'BsmtFullBath']\n    * by median:\n        * ['OverallQual', 'GrLivArea', 'GarageCars', '1stFlrSF', 'TotRmsAbvGrd', 'BsmtFinSF1', 'LotFrontage', 'LotArea', 'BsmtUnfSF']\n\n\n* Remove Outliers:\n    * GrLivArea 2 outliers(> 4500)\n    * 1stFlrSF 1 outlier (>5000)\n    * BsmtFinSF1 1 outlier(>4000)\n    * LotFrontage 2 outliers( >300)\n## Numberical columns\n* Drop columns: \n    * ['Alley', 'PoolQC', 'Fence', 'MiscFeature']\n    ","9234b1e2":"### GarageCars\n- Good shape of  distribution\n- no outliers\n- The missing values can be filled by mean() or median()\n- Keep both GarageCars and GarageArea","e5517fea":"### OverallQual\n- Good shape of distribution\n- no outlier\n- The missing value cand be fill by mean() or median()","4b59006e":"# 1. Data exploring","ce912536":"### GrLivArea\n- Slightly left skew distribution but still in good shape.\n- 2 outliers(> 4500)\n- The missing values can be filled by median()\n- Keep both GrLivArea and TotRmsAbvGrd\n","9f617a55":"Bellow is the number of null values.\n\nWe will drop Alley, PoolQC, Fence, MiscFeature.\n\nThe other missing values will be fill up by SimpleImputer-most_frequent value","df62d842":"### WoodDeckSF\n- Left skew distribution. Almost values = 0\n- No outlier\n- Missing value can be filled by 0","4fced501":"### BsmtUnfSF\n- Left skew distribution\n- No outlier\n- Missing values can be filled by median()\n","2abd3898":"There are 3 of 37 columns has missing value.\nBelow are the missing values.(1460 rows in total)"}}