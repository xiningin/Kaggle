{"cell_type":{"4ce97d80":"code","fcd33c26":"code","2626ba70":"code","694554e9":"code","94561a92":"code","1841652a":"code","086c949f":"code","1c34212a":"code","6b120025":"code","2b92fe01":"code","44374706":"code","9ab017e2":"code","cc8571a2":"code","69614188":"code","3ffcc1a9":"code","430d1f00":"code","71b80f0e":"code","94b31e9c":"code","cff9e2f9":"code","b6e63d6a":"code","37742ecf":"markdown","a4ebe3e0":"markdown","e2a8daf1":"markdown","46ea47c1":"markdown","dc5677bc":"markdown","b96ec140":"markdown","07951124":"markdown","f08c8b82":"markdown","dc36fcc2":"markdown","56ebea3f":"markdown","d63c25c2":"markdown","e91f4217":"markdown","3c3737dc":"markdown","52fba063":"markdown","bf6ffdc5":"markdown","fdb8c33a":"markdown","f77a905f":"markdown","114b14b0":"markdown","222a9861":"markdown"},"source":{"4ce97d80":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport xgboost as xgb\nimport re\nimport shap\nfrom skopt import dummy_minimize\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score,accuracy_score,recall_score,classification_report\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier,VotingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression","fcd33c26":"#Read dataframe\ndf = pd.read_excel(\"..\/input\/covid19\/dataset.xlsx\")\ndf.head()","2626ba70":"#Define target \ndf['ward_semi_intensive'] = np.where(df['Patient addmited to regular ward (1=yes, 0=no)']\n                          + df['Patient addmited to semi-intensive unit (1=yes, 0=no)']\n                          + df['Patient addmited to intensive care unit (1=yes, 0=no)']>=1,1,0)\n\ndf = df.drop(['Patient addmited to regular ward (1=yes, 0=no)','Patient addmited to semi-intensive unit (1=yes, 0=no)','Patient addmited to intensive care unit (1=yes, 0=no)','Patient ID'], axis = 1)","694554e9":"#Filter columns with percentage of null >= 99%\ndf_missing = (df.isna().sum()\/len(df)).to_frame()\ndf_missing =df_missing.rename(columns={0: 'percentage of null'})\nprint(df_missing[df_missing['percentage of null'] >0.99])\n\n#Drop columns\ndrop = list(df_missing[df_missing['percentage of null'] >0.99].index)\ndf = df.drop(drop, axis = 1)","94561a92":"#Target variable\nsns.countplot(x=df['ward_semi_intensive'], alpha=0.7, data=df)","1841652a":"#Plot numerics features \nnumerics = ['float32', 'float64']\ndf2 = df[df['ward_semi_intensive']==0].select_dtypes(include=numerics)\ndf3 = df[df['ward_semi_intensive']==1].select_dtypes(include=numerics)\nfig, ax = plt.subplots(16,3,figsize=(22, 100))\nfor i, col in enumerate(df2):\n    plt.subplot(16,3,i+1)\n    plt.xlabel(col, fontsize=10)\n    sns.kdeplot(df2[col].values, bw=0.5,label='N\u00e3o')\n    sns.kdeplot(df3[col].values, bw=0.5,label='Sim')\nplt.show() \n\n#Drop null colunms\ndrop = ['Myeloblasts']\ndf = df.drop(drop, axis = 1)","086c949f":"numerics = ['float32', 'float64']\ndf2 = df[df['ward_semi_intensive']==0].select_dtypes(include=numerics)\ndf2['ward_semi_intensive'] = 0\ndf3 = df[df['ward_semi_intensive']==1].select_dtypes(include=numerics)\ndf3['ward_semi_intensive'] = 1\nx = pd.concat([df2,df3])\nx = x.groupby('ward_semi_intensive').count()\nx['ward_semi_intensive'] = x.index\n\nfig, axes = plt.subplots(round(len(x.columns) \/ 4), 4, figsize=(20, 50))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(x.columns):\n        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=35)\n        sns.countplot(x=x.columns[i], data=x,ax=ax,hue='ward_semi_intensive')\nfig.tight_layout()\n","1c34212a":"categorics = ['object']\nc1 = df[df['ward_semi_intensive']==0].select_dtypes(include=categorics)\nc1['ward_semi_intensive'] = 'N\u00e3o'\nc2 = df[df['ward_semi_intensive']==1].select_dtypes(include=categorics)\nc2['ward_semi_intensive'] = 'Sim'\n\nc3 = pd.concat([c1,c2])\nfig, axes = plt.subplots(round(len(c3.columns) \/ 4), 4, figsize=(20, 45))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(c3.columns):\n        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=35)\n        sns.countplot(x=c3.columns[i], alpha=0.7, data=c3, ax=ax,hue=\"ward_semi_intensive\")\n\nfig.tight_layout()\n\n#Drop columns \ndrop = ['Adenovirus','Bordetella pertussis', 'Metapneumovirus','Chlamydophila pneumoniae','Inf A H1N1 2009','Urine - Urobilinogen','Urine - Crystals','Urine - Aspect']\ndf= df.drop(drop,axis=1)","6b120025":"def detect(x):\n    df[x] = np.where(df[x] == \"detected\",1,0)\n    return df[x]   \n\ndef positive(x):\n    df[x] = np.where(df[x] == \"positive\",1,0)\n    return df[x] \n\ndef absent(x):\n    df[x] = np.where(df[x] == \"absent\",1,0)\n    return df[x] \n\ndef present(x):\n    df[x] = np.where(df[x] == \"present\",1,0)\n    return df[x] \n\n#Age quantile\ndf['age_quantile'] = df['Patient age quantile']\ndf = df.drop('Patient age quantile',axis=1)\n\n#Detected Respiratory Syncytial Virus'\ndf['Respiratory Syncytial Virus'] = detect('Respiratory Syncytial Virus')\n\n#Detected rhinovirus\/Enterovirus\ndf['Rhinovirus\/Enterovirus'] = detect('Rhinovirus\/Enterovirus')\n\n#Detected Influenza A or Influenza B\ndf['Influenza A'] = detect('Influenza A')\ndf['Influenza B'] = detect('Influenza B')\ndf['Influenza A, rapid test'] = positive('Influenza A, rapid test')\ndf['Influenza B, rapid test'] = positive('Influenza B, rapid test')\ndf['Influenza_A_or_B'] = np.where((df['Influenza A'] + df['Influenza B'] + df['Influenza A, rapid test'] + df['Influenza B, rapid test']) >= 1,1,0)\ndf = df.drop(['Influenza A','Influenza B','Influenza A, rapid test','Influenza B, rapid test'],axis=1)\n\n#Positive strepto\ndf['Strepto A'] = positive('Strepto A')\n\n#Detected any Parainfluenza \ndf['Parainfluenza 1'] = detect('Parainfluenza 1')\ndf['Parainfluenza 2'] = detect('Parainfluenza 2')\ndf['Parainfluenza 3'] = detect('Parainfluenza 3')\ndf['Parainfluenza 4'] = detect('Parainfluenza 4')\ndf['Parainflu_detected'] = np.where((df['Parainfluenza 1']+ df['Parainfluenza 2'] + df['Parainfluenza 3']\n                                   + df['Parainfluenza 4']) >= 1,1,0)\ndf = df.drop(['Parainfluenza 1','Parainfluenza 2','Parainfluenza 3','Parainfluenza 4'],axis=1)\n\n#Detected Alpha coronavirus (Coronavirus229E or CoronavirusNL63)\ndf['Coronavirus229E'] = detect('Coronavirus229E')\ndf['CoronavirusNL63'] = detect('CoronavirusNL63')\ndf['Alpha_coronavirus'] = np.where((df['Coronavirus229E'] + df['CoronavirusNL63'] >= 1),1,0)\ndf = df.drop(['Coronavirus229E','CoronavirusNL63'],axis=1)\n\n#Detected Beta coronavirus (Coronavirus HKU1 or CoronavirusOC43)\ndf['Coronavirus HKU1'] = detect('Coronavirus HKU1')\ndf['CoronavirusOC43'] = detect('CoronavirusOC43')\ndf['Beta_coronavirus'] = np.where((df['CoronavirusOC43'] + df['Coronavirus HKU1'] >= 1),1,0)\ndf = df.drop(['CoronavirusOC43','Coronavirus HKU1'],axis=1)\n\n#Positive crovid-19\ndf['SARS-Cov-2 exam result'] = positive('SARS-Cov-2 exam result')\n\n#Remove text of Urine-Ph columns\ndf['Urine - pH'] = np.where(df['Urine - pH']=='N\u00e3o Realizado',np.nan,df['Urine - pH'])\ndf['Urine - pH'] = df['Urine - pH'].astype(float)\n\n#Absent Urine - Bile pigments\ndf['Urine_Bile_pigments_absent'] = absent('Urine - Bile pigments')\ndf = df.drop('Urine - Bile pigments',axis=1)\n\n#Absent 'Urine - Ketone Bodies'\ndf['Urine_Ketone_Bodies_absent'] = absent('Urine - Ketone Bodies')\ndf = df.drop('Urine - Ketone Bodies',axis=1)\n\n#Absent  'Urine - Hyaline cylinders'\ndf['Urine_Hyaline_cylinders_absent'] = absent('Urine - Hyaline cylinders')\ndf = df.drop('Urine - Hyaline cylinders',axis=1)\n\n#Absent 'Urine - Yeasts'\ndf['Urine_Yeasts_absent'] = absent('Urine - Yeasts')\ndf = df.drop('Urine - Yeasts',axis=1)\n\n#Absent 'Urine - Protein'\ndf['Urine_Protein_absent'] = absent('Urine - Protein')\ndf = df.drop('Urine - Protein',axis=1)\n\n#Absent 'Urine - Esterase'\ndf['Urine_Esterase_absent'] = absent('Urine - Esterase')\ndf = df.drop('Urine - Esterase',axis=1)\n\n#Absent 'Urine -  Granular cylinders'\ndf['Urine_Granular_cylinders_absent'] = absent('Urine - Granular cylinders')\ndf = df.drop('Urine - Granular cylinders',axis=1)\n\n#Urine - Leukocytes\ndf['Urine - Leukocytes'].replace('<', '', regex = True,inplace=True)\ndf['Urine - Leukocytes'] = df['Urine - Leukocytes'].astype(float)\n\n#Urine - Hemoglobin present and ausent\ndf['Urine_Hemoglobin_present'] = present('Urine - Hemoglobin')\ndf['Urine_Hemoglobin_present'] = absent('Urine - Hemoglobin')\ndf = df.drop('Urine - Hemoglobin',axis=1)\n\n#Urine yellow or light yellow\ndf['Urine_yellow']= np.where(df['Urine - Color']=='yellow',1,0)\ndf['Urine_light_yellow']= np.where(df['Urine - Color']=='light_yellow',1,0)\ndf['Urine_color_yellow'] = np.where(df['Urine_yellow'] + df['Urine_light_yellow'] >=1,1,0)\ndf = df.drop(['Urine - Color','Urine_yellow','Urine_light_yellow'],axis=1)\n\n#code to fix columns name\nregex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\ndf.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in df.columns.values]\n\n#Input median in null values \nnumerics = ['float32', 'float64']\ndf2 = df.select_dtypes(include=numerics).apply(lambda x: x.fillna(x.median()),axis=0)\n\ndrop_columns = []\nfor i in df2.columns:\n    drop_columns.append(i)\ndf = df.drop(drop_columns, axis = 1) \n\ndf = pd.concat([df, df2], axis=1, sort=False)\ndf.head(5)\n","2b92fe01":"#Check and print the correlation between features and target variable1 (top 10 positive correlations)\n#Weak positive correlation\ndf.corr(method='spearman')['ward_semi_intensive'].sort_values(ascending=False).head(11)","44374706":"#Split feature x and target y \nx = df.drop('ward_semi_intensive',axis=1)\ny = df['ward_semi_intensive']\n\n#30% test e 70% train\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)","9ab017e2":"rf = RandomForestClassifier(max_depth=5, random_state=42,n_estimators=100,class_weight = 'balanced')\nrf.fit(x_train,y_train)\np2 = rf.predict(x_test)\nprint('accuracy:' , accuracy_score(p2,y_test))\nprint('f1_score:' , f1_score(p2,y_test,average='weighted'))","cc8571a2":"lr = LogisticRegression(class_weight = 'balanced', solver = 'liblinear',penalty=\"l1\")\nlr.fit(x_train,y_train)\np3 = lr.predict(x_test)\nprint('accuracy:' , accuracy_score(p3,y_test))\nprint('f1_score:' , f1_score(p3,y_test,average='weighted'))","69614188":"svm = SVC(gamma='auto',random_state=42)\nsvm.fit(x_train, y_train)\np5 = svm.predict(x_test)\nprint('f1_score:' , f1_score(p5,y_test,average='weighted'))\nprint('accuracy:' , accuracy_score(p5,y_test))\n","3ffcc1a9":"#Using Xgboost to predict admission to general ward, semi-intensive unit or intensive care \nxgboost = xgb.XGBClassifier(learning_rate = 0.2\n                            ,max_depth = 5\n                            ,colsample_bytree = 0.9\n                            ,n_estimators = 100\n                            ,random_state=42\n                            ,class_weight='balanced'\n                           )\n\nxgboost.fit(x_train,y_train)\np = xgboost.predict(x_test)\nprint('f1_score:' , f1_score(p,y_test,average='weighted'))\nprint('accuracy:' , accuracy_score(p,y_test))","430d1f00":"#Filter feauture with importance > 0.015\nfeature = []\naux= []\nfor feature in zip(x_train, xgboost.feature_importances_):\n    if feature[1] > 0.015:\n        aux.append(feature[0])\n        print(feature)","71b80f0e":"x_train = x_train[aux] \nx_test  = x_test[aux]\ndef train_model(params):\n    learning_rate = params[0]\n    num_leaves = params[1]\n    min_child_samples = params[2]\n    colsample_bytree = params[3]\n    n_estimators = params[4]\n    \n    \n    xgboost = xgb.XGBClassifier(learning_rate=learning_rate\n                                , num_leaves=num_leaves\n                                , min_child_samples=min_child_samples\n                                , colsample_bytree=colsample_bytree\n                                , n_estimators =  n_estimators\n                                , random_state=42\n                                ,class_weight='balanced')\n    \n    xgboost.fit(x_train,y_train)\n    \n    p = xgboost.predict(x_test)\n    \n    return -f1_score(p,y_test,average='weighted')\n\nspace = [(1e-3, 1e-1, 'log-uniform'), #learning rate\n         (2, 50), # num_leaves\n         (1, 100), # min_child_samples\n         (0.1, 1.0),# colsample bytree\n         (100,300)] #n_estimator\n\nresult = dummy_minimize(train_model, space, random_state=0, n_calls=100)\n\n#Print Hiper-parameters\nprint(result.x)","94b31e9c":"#New Xgboost \nxgboost = xgb.XGBClassifier(learning_rate = 0.002237781857878498\n                            ,num_leaves= 29\n                            ,min_child_samples = 52\n                            ,colsample_bytree = 0.5168351799911199\n                            ,n_estimators = 118\n                            ,random_state=42\n                            ,max_depth = 5\n                            ,class_weight='balanced'\n                           )\n\nxgboost.fit(x_train,y_train)\np3 = xgboost.predict(x_test)\nprint('f1_score:' , f1_score(p3,y_test,average='weighted'))\nprint('accuracy:' , accuracy_score(p3,y_test))\nprint(classification_report(p3,y_test))\nexplainer = shap.TreeExplainer(xgboost)\nshap_values = explainer.shap_values(x_train)\nshap.summary_plot(shap_values, x_train)","cff9e2f9":"stacking = VotingClassifier(estimators=[\n    ('rf', rf), ('lr',lr),('xgboost',xgboost),('svm',svm)], voting='hard')\nstacking.fit(x_train, y_train)\np4 = stacking.predict(x_test)\nprint('f1_score:' , f1_score(p4,y_test,average='weighted'))\nprint('accuracy:' , accuracy_score(p4,y_test))\nprint(classification_report(p4,y_test))","b6e63d6a":"print('f1_score:' , f1_score(p4,y_test,average='weighted'))\nprint('accuracy:' , accuracy_score(p4,y_test))","37742ecf":"# Data Processing","a4ebe3e0":"## Plotting target distribution   ","e2a8daf1":"### 4.1) Tuning Xgboost model \n+ Feature selection\n+ Tuning hiper-parameters\n","46ea47c1":"# Plotting the distribution of numerics features  ","dc5677bc":"Steps:\n\nImport Data\n\nExploratory Data Analysis\n\nData Preparation + Feature Enginnering\n\nSplit data in train and test\n\nTest some Machine Learning models\n\nTuning hiper-parameters using Random Search\n\nChoose the best model","b96ec140":"### Train\/Test Split","07951124":"##### Tuning xgboost hiper-parameters with Random Search","f08c8b82":"### 4) Xgboost","dc36fcc2":"### Imports","56ebea3f":"##### Feature selection","d63c25c2":"### 5) Stacking with VotingClassifier","e91f4217":"### 3) Support Vector machine","3c3737dc":"# Plotting the frequency of categorics features  ","52fba063":"### 1) Random Forest","bf6ffdc5":"### 2) Logistic Regression ","fdb8c33a":"# Plotting the frequency of numerics features","f77a905f":"# Exploratory Data Analysis","114b14b0":"### 6)  final machine learning model: Stacking","222a9861":"# TASK 2\nPredict admission to general ward, semi-intensive unit or intensive care unit among confirmed COVID-19 cases.\n\n"}}