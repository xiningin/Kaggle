{"cell_type":{"57838c43":"code","f77352da":"code","12acceaf":"code","3dd95351":"code","8c16f637":"code","8dd5326d":"code","0c2cdb50":"code","744d3b01":"code","61498bbf":"code","d11d6ca5":"code","97294754":"code","0e7834e4":"code","cd33505a":"code","4f7a7ede":"code","9ded14c5":"code","d6fbb5d9":"code","9df2afaf":"code","0577b256":"code","ba4cda5e":"code","5ff18d55":"code","836a8a03":"code","032431da":"code","caca196f":"code","567de135":"code","0d09d41c":"code","1d483b46":"code","dab00425":"code","a6eb1940":"code","a231af59":"code","fc13b5ea":"code","fe605d5d":"code","ffef836a":"code","1a425c27":"code","71e043f7":"code","4bd9c66d":"code","1c054683":"code","635e369d":"code","46f1545b":"code","9fea4834":"code","b84c6af0":"code","e8988875":"code","226a18bd":"code","4af68490":"code","400706a9":"code","8103910c":"code","0dd7e0ab":"code","000bae67":"code","6aa22118":"code","97ef77a5":"code","52df1279":"code","cafd791e":"code","994f0f8d":"markdown","5ed35356":"markdown","62223e93":"markdown","d993155a":"markdown","dc1f888a":"markdown","f0ec783e":"markdown","86d7c52c":"markdown","1ed11a5e":"markdown","5a5032fd":"markdown","e7e492ff":"markdown","0177601e":"markdown","3dc93395":"markdown","8da51659":"markdown","1a9e8f36":"markdown"},"source":{"57838c43":"!pip install num2words\n!pip install fasttext","f77352da":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport string\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nfrom num2words import num2words\nimport os\nimport fasttext\nimport fasttext.util\nfrom sklearn.svm import SVC\nfrom sklearn import metrics","12acceaf":"!wget https:\/\/dl.fbaipublicfiles.com\/fasttext\/vectors-crawl\/cc.en.300.bin.gz","3dd95351":"!gzip -d .\/cc.en.300.bin.gz","8c16f637":"ft = fasttext.load_model('cc.en.300.bin')","8dd5326d":"stemmer = PorterStemmer()\nlemmatizer= WordNetLemmatizer()","0c2cdb50":"def remove_url(x):\n    \n    x = re.sub(r'@\\w+','',x)\n    x = re.sub(r'\\w+:\\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\\/[^\\s\/]*))*', '', x)\n    \n    return x","744d3b01":"def remove_stopwords(x):\n    stop_words = set(stopwords.words('english')) \n    return [word for word in x if word not in stop_words]","61498bbf":"def number_remove(tokens): # Alternatif olarak numeric de\u011ferler kelimelerede cevrilebilir.\n        \n    return [word for word in tokens if word.isalpha()]","d11d6ca5":"def steming(tokens):\n        \n    return [stemmer.stem(word) for word in tokens]","97294754":"def lemmetizing(tokens):\n        \n    return [lemmatizer.lemmatize(word) for word in tokens]","0e7834e4":"def number_to_word(tokens):\n           \n    return [num2words(word) if word.isdigit() else word for word in tokens]","cd33505a":"def list_to_str(tokens):\n    return ' '.join([str(item) for item in tokens ])","4f7a7ede":"def preprocess_ft_vector(df):\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_url)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.lower())\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n    df['OriginalTweet'] = df['OriginalTweet'].apply(word_tokenize)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_stopwords)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(number_to_word)\n    df = df[~df['OriginalTweet'].str.len().eq(0)]\n    df['OriginalTweet'] = df['OriginalTweet'].apply(list_to_str)\n    df['fasttext'] = df['OriginalTweet'].apply(ft.get_sentence_vector)\n    return df","9ded14c5":"def preprocess_fasttext(df):\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_url)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.lower())\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n    df['OriginalTweet'] = df['OriginalTweet'].apply(word_tokenize)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_stopwords)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(number_to_word)\n    df = df[~df['OriginalTweet'].str.len().eq(0)]\n    df['OriginalTweet'] = df['OriginalTweet'].apply(list_to_str)\n    df['Sentiment'] = df['Sentiment'].apply(lambda x : '__label__' + str(x))\n    return df","d6fbb5d9":"def preprocess_lstm(df):\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_url)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.lower())\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x : x.translate(str.maketrans('', '', string.punctuation)))\n    df['OriginalTweet'] = df['OriginalTweet'].apply(word_tokenize)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(remove_stopwords)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(number_remove)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(steming)\n    df['OriginalTweet'] = df['OriginalTweet'].apply(lemmetizing)\n    df = df[~df['OriginalTweet'].str.len().eq(0)]\n    return df","9df2afaf":"df_train = pd.read_csv('\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv', \n                        encoding = 'latin-1')\n\ndf_test = pd.read_csv('\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv', \n                        encoding = 'latin-1')","0577b256":"filtered_df_train = df_train[['Sentiment', 'OriginalTweet']]\nfiltered_df_test = df_test[['Sentiment', 'OriginalTweet']]","ba4cda5e":"encoding = {'Extremely Negative': 'Negative',\n            'Negative': 'Negative',\n            'Neutral': 'Neutral',\n            'Positive':'Positive',\n            'Extremely Positive': 'Positive'\n           }\n\nfiltered_df_train['Sentiment'].replace(encoding, inplace=True)\nfiltered_df_test['Sentiment'].replace(encoding, inplace=True)","5ff18d55":"filtered_df_train = preprocess_fasttext(filtered_df_train)\nfiltered_df_test = preprocess_fasttext(filtered_df_test)","836a8a03":"filtered_df_train.to_csv('train.txt', header=False, index=False, sep=' ')","032431da":"filtered_df_test.to_csv('test.txt', header=False, index=False, sep=' ')","caca196f":"ft_model = fasttext.train_supervised(input='train.txt', epoch=5, dim=200)","567de135":"ft_scores = ft_model.test('test.txt')\nft_scores[1]","0d09d41c":"filtered_df_train = df_train[['OriginalTweet', 'Sentiment']]\nfiltered_df_test = df_test[['OriginalTweet', 'Sentiment']]","1d483b46":"encoding = {'Extremely Negative': 0,\n            'Negative': 0,\n            'Neutral': 1,\n            'Positive':2,\n            'Extremely Positive': 2\n           }\n\nfiltered_df_train['Sentiment'].replace(encoding, inplace=True)\nfiltered_df_test['Sentiment'].replace(encoding, inplace=True)","dab00425":"filtered_df_train = preprocess_ft_vector(filtered_df_train)\nfiltered_df_test = preprocess_ft_vector(filtered_df_test)","a6eb1940":"X_train = np.stack(filtered_df_train['fasttext'])\ny_train = np.array(filtered_df_train['Sentiment'])","a231af59":"X_test = np.stack(filtered_df_test['fasttext'])\ny_test = np.array(filtered_df_test['Sentiment'])","fc13b5ea":"svm = SVC()","fe605d5d":"svm.fit(X_train, y_train)","ffef836a":"svm_pred= svm.predict(X_test)","1a425c27":"svm_score = metrics.accuracy_score(y_test, svm_pred)\nsvm_score","71e043f7":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf","4bd9c66d":"tokenizer = Tokenizer()","1c054683":"filtered_df_train = df_train[['OriginalTweet', 'Sentiment']]\nfiltered_df_test = df_test[['OriginalTweet', 'Sentiment']]","635e369d":"encoding = {'Extremely Negative': 0,\n            'Negative': 0,\n            'Neutral': 1,\n            'Positive':2,\n            'Extremely Positive': 2\n           }\n\nfiltered_df_train['Sentiment'].replace(encoding, inplace=True)\nfiltered_df_test['Sentiment'].replace(encoding, inplace=True)","46f1545b":"filtered_df_train = preprocess_lstm(filtered_df_train)\nfiltered_df_test = preprocess_lstm(filtered_df_test)","9fea4834":"tokenizer.fit_on_texts(filtered_df_train['OriginalTweet'])\nvocab_len = len(tokenizer.word_index) + 1\n\nmax_len = np.max(filtered_df_train['OriginalTweet'].apply(lambda x :len(x)))\nprint(vocab_len, max_len)","b84c6af0":"X_train = tokenizer.texts_to_sequences(filtered_df_train['OriginalTweet'])\nX_test = tokenizer.texts_to_sequences(filtered_df_test['OriginalTweet'])\n\ny_train = filtered_df_train['Sentiment']\ny_test = filtered_df_test['Sentiment']","e8988875":"X_train = pad_sequences(X_train, maxlen= max_len, padding='post')\nX_test = pad_sequences(X_test, maxlen= max_len, padding='post')","226a18bd":"from tensorflow.keras.utils import to_categorical\ny_train = to_categorical(y_train, 3)\ny_test = to_categorical(y_test, 3)","4af68490":"import tensorflow.keras.layers as layers\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.optimizers import Adam","400706a9":"embedding_dim = 200\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_len, embedding_dim, input_length=X_train.shape[1]),\n    tf.keras.layers.LSTM(128, return_sequences=True),\n    tf.keras.layers.LSTM(128, return_sequences=True),\n    tf.keras.layers.LSTM(128, return_sequences=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(3, activation='softmax')\n])","8103910c":"model.compile(loss='categorical_crossentropy',\n              optimizer='Adam',metrics=['accuracy'])","0dd7e0ab":"model.summary()","000bae67":"model.fit(X_train, y_train, epochs=10, batch_size=32)","6aa22118":"lstm_score = model.evaluate(X_test, y_test)\nlstm_score","97ef77a5":"scores = pd.DataFrame({'Model' : ['LSTM', 'SVM', 'Fasttext'],\n          'Score' : [lstm_score[1], svm_score, ft_scores[1]]})","52df1279":"import matplotlib.pyplot as plt\nimport seaborn as sns","cafd791e":"fig = plt.figure(figsize=(5,5))\nax = sns.barplot(x=\"Model\", y=\"Score\", data=scores)\n\nfor index, row in scores.iterrows():\n    ax.text(index, row.Score, round(row.Score,3), color='black', ha=\"center\")\n    \nplt.title(\"Accuracy Score Table\")\nplt.show()","994f0f8d":"### Fasttext classification with pre-trained vectors","5ed35356":"Load pre-trained model from fasttext","62223e93":"### What is Fasttext?\n\nFastText is an open-source, free, lightweight library that allows users to learn text representations and text classifiers. It works on standard, generic hardware. Models can later be reduced in size to even fit on mobile devices.","d993155a":"Vectorize tweets with fasttext pre-trained model","dc1f888a":"### LSTM Classification","f0ec783e":"### Fasttext classification","86d7c52c":"Preprocess functions","1ed11a5e":"Stemming and lemmetizing are good preprocessing for the lstm model, although not good for fasttext","5a5032fd":"# Fasttext vs LSTM\n\n![fasttext](https:\/\/opendatascience.com\/wp-content\/uploads\/2021\/01\/ogimage-e1610396279996-300x89.png)","e7e492ff":"### Comparision of Scores","0177601e":"### What is LSTM?\n\nLong-Short-Term Memory (LSTM) is a special kind of recurrent neural network capable of learning long-term dependencies, remembering information for long periods as its default behaviour. There are three steps in an LSTM network:\n- Step 1: The network decides what to forget and what to remember.\n- Step 2: It selectively updates cell state values.\n- Step 3: The network decides what part of the current state makes it to the output.","3dc93395":"Add label for fasttext train without pre-trained","8da51659":"Returns dataframes into txt files to train with fasttext","1a9e8f36":"Use Support Vector Classification for vectorized tweets"}}