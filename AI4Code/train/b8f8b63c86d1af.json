{"cell_type":{"ea04b325":"code","36eec788":"code","29f13c3d":"code","972c7618":"code","4792f9cd":"code","1486d793":"code","8a3e3dd8":"code","4a838a92":"code","79d68e7c":"code","85311781":"code","93d38f08":"code","40b03bfb":"code","45991c26":"code","e891f7d1":"code","4e3043ae":"code","963bf17d":"code","20f3fc63":"code","6e7e42c3":"code","a6eed1df":"markdown","366362bc":"markdown","7f4eea2e":"markdown","457cf570":"markdown","106d60dc":"markdown","b320e7a2":"markdown","0b544e41":"markdown"},"source":{"ea04b325":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport ast\nimport os\nfrom glob import glob\nfrom tqdm import tqdm\nfrom dask import bag\nfrom PIL import Image, ImageDraw \nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, DepthwiseConv2D, BatchNormalization, ZeroPadding2D\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, AveragePooling2D \nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.metrics import top_k_categorical_accuracy\nimport os\nfrom tqdm import tqdm #for\ubb38 \ucc98\ub9ac\uacfc\uc815 \ud655\uc778 \ud568\uc218 ","36eec788":"rd=np.random.randint(340)#340\uae4c\uc9c0\uc758 \uc218 \uc911\uc5d0 \ub09c\uc218\uc0dd\uc131\npath = os.listdir('\/kaggle\/input\/quickdraw-doodle-recognition\/train_simplified') \n# df = pd.read_csv('\/kaggle\/input\/quickdraw-doodle-recognition\/train_simplified\/'+path[rd])\n# print (df)","29f13c3d":"height = 64\nwidth = 64","972c7618":"def draw_to_img(strokes):\n    BASE_SIZE = 256\n    image = Image.new(\"P\", (BASE_SIZE,BASE_SIZE), color=255) \n    image_draw = ImageDraw.Draw(image)\n    for each in ast.literal_eval(strokes):\n        for i in range(len(each[0])-1):\n            p1 = each[0][i],each[1][i]\n            p2 = each[0][i+1],each[1][i+1]\n            image_draw.line([p1,p2],width=5)\n    img = image.resize((height,width))\n    return np.array(img)\/255.","4792f9cd":"# tmp = df['drawing'][20]\n# tmp2 = df['word'][20]\n# df['word']= df['word'].replace(' ','_',regex = True)\n# img = np.array(draw_to_img(tmp))\n# #\ub370\uc774\ud130 \ud615\ud0dc\ud655\uc778\n# print(tmp)\n# print(' ')\n# print(tmp2)\n# plt.imshow(img)\n\n","1486d793":"#test\nran=np.random.randint(340)#340\uae4c\uc9c0\uc758 \uc218 \uc911\uc5d0 \ub09c\uc218\uc0dd\uc131\nnums2names={i : v[:-4].replace(' ','_') for i , v in enumerate(path)}#\ubd88\ub7ec\uc628 \ub370\uc774\ud130\uc5d0 index \ubc88\ud638\ubd99\uc774\uae30\nranclass=nums2names[ran]# 340\uae4c\uc9c0\uc758 \uc218\uc911\uc5d0 \ub79c\ub364\uc73c\ub85c \ubd88\ub7ec\uc624\uae30  \nranclass=ranclass.replace('_',' ')# \ubd84\ub958 \uc81c\ubaa9\uc744 _\uc744 ' '\ub85c \ubc14\uafd4\uc8fc\uae30\nrdpath='\/kaggle\/input\/quickdraw-doodle-recognition\/train_simplified\/'+ranclass+'.csv' #\ub79c\ub364\uc73c\ub85c \ud558\ub098\uc758 \ud074\ub798\uc2a4 \uacbd\ub85c\uc124\uc815\none=pd.read_csv(rdpath,usecols=['drawing','recognized','word'],nrows=10) #10\uac1c \ud589\uc758 drawing recognized word \ubd88\ub7ec\uc624\uae30\none=one[one.recognized==True].head(2)#\uadf8\ub9bc \uc911 true\uc778\uac83 2\uac1c\ub9cc\ubd88\ub7ec\uc624\uae30\nname=one['word'].head(1)#one\uc758 \uccab\ubc88\uc9f8 word \nstrk=one['drawing']# one \uc758 drawing #2\uac1c\nname=name.values\n","8a3e3dd8":"train_grand=[]\nnum_class = 340\nper_class = 800","4a838a92":"class_paths = glob('\/kaggle\/input\/quickdraw-doodle-recognition\/train_simplified\/*.csv')\nfor i , c in enumerate(tqdm(class_paths[0:num_class])): \n    train=pd.read_csv(c,usecols=['drawing','recognized'],nrows=per_class*1.5)\n    train=train[train.recognized==True].head(per_class)\n    imagebag=bag.from_sequence(train.drawing.values).map(draw_to_img)\n    train_array=np.array(imagebag.compute())#unmpy \ud615\uc2dd\n    train_array=np.reshape(train_array,(per_class,-1))  #2000  -1\ub85c reshpae\ub85c \ud589\ub82c \ud615\uc2dd \ubcc0\uacbd \uadf8\ub9bc\ud615\uc2dd \n    label_array=np.full((train.shape[0],1),i)# label \ubd99\uc5ec\uc8fc\uae30 , train.shape[0] = 2000\n    train_array=np.concatenate((label_array,train_array),axis=1)\n    train_grand.append(train_array)\n    del train_array\n    del label_array\n","79d68e7c":"train_grand=np.array([train_grand.pop() for i in np.arange(num_class)]) #\ub370\uc774\ud130 \uc138\ud305","85311781":"train_grand=train_grand.reshape((-1,(height*width+1))) #64*64\ub85c \ubc30\uc5f4 \ubcc0\uacbd\nprint(train_grand)","93d38f08":"specific = 0.1 \nsequence_length = 50\ncut = int(specific * train_grand.shape[0])\nprint(cut)\n\nnp.random.shuffle(train_grand)\ny_train, X_train = train_grand[cut: , 0], train_grand[cut: , 1:]\ny_val, X_val = train_grand[0:cut, 0], train_grand[0:cut, 1:]\n\n# del train_grand\n\nx_train=X_train.reshape(X_train.shape[0],height,width,1)\nx_val=X_val.reshape(X_val.shape[0],height,width,1)\n\n\ny_train2 = keras.utils.to_categorical(y_train, num_class)\n\n\nprint(y_train.shape, \"\\n\",\n      x_train.shape, \"\\n\",\n      y_val.shape, \"\\n\",\n      x_val.shape)\n\n","40b03bfb":"leaky_relu = tf.nn.leaky_relu","45991c26":"model = Sequential()\nmodel.add(ZeroPadding2D(padding=(1, 1),input_shape=(height,width,1)))\nmodel.add(Conv2D(32,kernel_size=(3,3),padding='same',activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2))) \nmodel.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(ZeroPadding2D(padding=(1, 1)))\nmodel.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation=leaky_relu))\nmodel.add(AveragePooling2D(pool_size=(2,2)))\nmodel.add(ZeroPadding2D(padding=(1, 1)))\nmodel.add(Activation('relu'))\nmodel.add(DepthwiseConv2D(64, padding='same',activation='relu' ))\nmodel.add(AveragePooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(128,kernel_size=(3,3),padding='same',activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(num_class*5, activation='relu'))\nmodel.add(Dense(num_class,activation='softmax'))\nmodel.summary()","e891f7d1":"def top_3_accuracy(x, y):\n    return top_k_categorical_accuracy(x, y, k=3)","4e3043ae":"reduceLROnPlat=ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=3,\n                                 verbose=1,mode='auto',min_delta=0.005,\n                                 cooldown=5,min_lr=0.0001)\ncallbacks=[reduceLROnPlat]\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',\n              metrics=['accuracy',top_3_accuracy])\n\nhistory=model.fit(x=x_train,y=y_train,batch_size=32,epochs=20,\n                  validation_data=(x_val,y_val),callbacks=callbacks,verbose=1)","963bf17d":"acc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss= history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(1,len(acc)+1)\n\nplt.plot(epochs,acc,label='Training acc')\nplt.plot(epochs,val_acc,label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs,loss,label='Training loss')\nplt.plot(epochs,val_loss,label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","20f3fc63":"list=[]\nreader=pd.read_csv('\/kaggle\/input\/quickdraw-doodle-recognition\/test_simplified.csv',index_col=['key_id'],chunksize=2048)\nfor chunk in tqdm(reader,total=55):\n    imagebag=bag.from_sequence(chunk.drawing.values).map(draw_to_img)\n    testarray=np.array(imagebag.compute())\n    testarray=np.reshape(testarray,(testarray.shape[0],height,width,1))\n    testpreds=model.predict(testarray,verbose=0)\n    s=np.argsort(-testpreds)[:,0:3]\n    list.append(s)\narray=np.concatenate(list)\npred_df=pd.DataFrame({'first': array[:,0],'second':array[:,1],'third':array[:,2]})\npred_df=pred_df.replace(nums2names)\npred_df['words']=pred_df['first']+' '+pred_df['second']+' '+pred_df['third']\n\nsub=pd.read_csv('\/kaggle\/input\/quickdraw-doodle-recognition\/sample_submission.csv',index_col=['key_id'])\nsub['word']=pred_df.words.values\nsub.to_csv('result_of_mission.csv')","6e7e42c3":"sub.head()","a6eed1df":"word\uc5d0 \ub744\uc5b4\uc4f0\uae30  '_' \ub85c\ubcc0\uacbd\ud558\uae30 \ntmp\uc124\uc815\ud6c4 \uc774\ubbf8\uc9c0\ud655\uc778","366362bc":"\uae30\uc874 Quick, Draw! \ub370\uc774\ud130 \uc138\ud2b8\uc5d0 \ub300\ud55c \ub354 \ub098\uc740 \ubd84\ub958\uc790\ub97c \ub9cc\ub4dc\ub294 \uac83\uc774 \uacfc\uc81c\uc774\ub2e4. Kaggler\ub294 \uc774 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0\uc11c \ubaa8\ub378\uc744 \ubc1c\uc804\uc2dc\ud0b4\uc73c\ub85c\uc368 \ud328\ud134 \uc778\uc2dd \uc194\ub8e8\uc158\uc744 \ubcf4\ub2e4 \uad11\ubc94\uc704\ud558\uac8c \uac1c\uc120\ud560 \uc218 \uc788\ub2e4. ","7f4eea2e":"setting to ( training set :  test set ) =  ( 9 : 1  )","457cf570":"\ub370\uc774\ud130 \ucd94\uac00 \ud558\uae30 ","106d60dc":"\uce90\uae00 \uacfc\uc81c \uc124\uba85\n**\uc81c\ucd9c \ud30c\uc77c\n\ud14c\uc2a4\ud2b8 \uc138\ud2b8\uc758 \uac01 key_id\uc5d0 \ub300\ud574 \ucd5c\ub300 3\uac1c\uc758 \uc6cc\ub4dc \uac12\uc744 \uc608\uce21\ud574\uc57c \ud55c\ub2e4. \ud30c\uc77c\uc5d0\ub294 \ud5e4\ub354\uac00 \ud3ec\ud568\ub418\uc5b4\uc57c \ud558\uba70 \ub2e4\uc74c\uacfc \uac19\uc740 \ud615\uc2dd\uc774 \uc788\uc5b4\uc57c \ud55c\ub2e4 \uc911\uc694: \uc5b4\ub5a4 \"\ub2e8\uc5b4\"\ub294 \ud55c \ub2e8\uc5b4 \uc774\uc0c1 \uad50\uc721 \ub370\uc774\ud130\ub294 \uc774\uc804\uc5d0 \ucd9c\uc2dc\ub41c Quick Draw \ub370\uc774\ud130 \uc138\ud2b8\uc640 \uc815\ub82c\ub418\uba70, \uacf5\ubc31\uc73c\ub85c \ub2e4\uc911 \ub2e8\uc5b4 \ub808\uc774\ube14\uc744 \uad6c\ubd84\ud55c\ub2e4. \uc774 \uacbd\uae30\uc758 \uce74\uae00 \uba54\ud2b8\ub9ad\uc5d0\ub294 \uacf5\ubc31\uc774 \uc5c6\ub294 \ub77c\ubca8\uc774 \ud544\uc694\ud558\ubbc0\ub85c \uacf5\uac04\uc744 \ubc11\uc904\ub85c \ub300\uccb4\ud558\uae30 \uc704\ud574 \ub77c\ubca8 \uc608\uce21\uc744 \uc870\uc815\ud574\uc57c \ud55c\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \"\ub864\ub7ec \ucf54\uc2a4\ud130\"\ub294 \"\ub864\ub7ec_\ucf54\uc2a4\ud130\"\ub85c \uc608\uce21\ud574\uc57c \ud55c\ub2e4.**","b320e7a2":"**import \ud544\uc694 \ubaa8\ub4c8**\n\ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30 \ubc0f \ud655\uc778","0b544e41":"open_cv\ub97c \uc774\uc6a9 \uc774\ubbf8\uc9c0 \uadf8\ub824\uc8fc\uae30\n"}}