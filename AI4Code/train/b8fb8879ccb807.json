{"cell_type":{"f806b2bb":"code","7f857967":"code","a0f4e682":"code","dd4fb118":"code","b39ff8cc":"code","65c77641":"code","87ea37b0":"code","ab0729aa":"code","9586f684":"code","a727c62d":"code","e098b6b8":"code","469cc94e":"code","6ee523b1":"code","f8070e9c":"code","32a5730b":"code","c032260c":"code","1da6ef22":"code","53ceaf7d":"code","5eb75ac4":"code","d33473f2":"code","9f56348d":"code","61d80104":"code","211f164b":"markdown","b2815370":"markdown","128af54d":"markdown","521575d0":"markdown","35faa3a2":"markdown","aecce929":"markdown","ddfe3efe":"markdown","fdf1fc28":"markdown","0d402b22":"markdown","6469ea4e":"markdown","5335aaec":"markdown","74ae789f":"markdown"},"source":{"f806b2bb":"# Import libraries\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.pyplot import xticks\nfrom sklearn import preprocessing\nimport numpy as np\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","7f857967":"# path = '\/content\/drive\/MyDrive\/Bishkek\/'\npath = '\/kaggle\/input\/pro-data-2020-real-estate-prediction\/'\n\ntrain = pd.read_csv(path + 'new_train.csv')\ntest = pd.read_csv(path + 'new_test.csv')\n\nprint(\"Train size:\", train.shape)\nprint(\"Test size:\", test.shape)\n\n# we need to predict Price of estate ('\u0426\u0435\u043d\u0430'), \n# so delete NaN values in train data\n\nprint('Number of NaN values:', train['\u0426\u0435\u043d\u0430'].isnull().sum())\ntrain = train[train['\u0426\u0435\u043d\u0430'].notnull()]\nprint(\"Train size after removing:\", train.shape)","a0f4e682":"print('Train >25000', train[train['\u0426\u0435\u043d\u0430']>25000].shape)\nprint('Train >50000', train[train['\u0426\u0435\u043d\u0430']>50000].shape)\nprint('Train >100000', train[train['\u0426\u0435\u043d\u0430']>100000].shape)\nplt.figure(figsize=(6,5))\nplt.scatter(range(train.shape[0]), np.sort(train['\u0426\u0435\u043d\u0430'].values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('Price', fontsize=12)\nplt.show()","dd4fb118":"print('We can see that data > 25000 is less, so take data with Price <25000')\ntrain = train[train['\u0426\u0435\u043d\u0430']<25000]\nplt.figure(figsize=(6,5))\nplt.scatter(range(train.shape[0]), np.sort(train['\u0426\u0435\u043d\u0430'].values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('Price', fontsize=12)\nplt.show()","b39ff8cc":"plt.figure(figsize=(6,4))\nsns.distplot(train['\u0426\u0435\u043d\u0430'].values, bins=50, kde=True)\nplt.xlabel('price', fontsize=12)\nplt.ylabel('density', fontsize=12)\nplt.show()","65c77641":"def plot_miss_data(X):\n    missing_df = X.isnull().sum(axis=0).reset_index()\n    missing_df.columns = ['column_name', 'missing_count']\n    missing_df = missing_df[missing_df['missing_count']>=0]\n    ind = np.arange(missing_df.shape[0])\n    width = 0.8\n    fig, ax = plt.subplots(figsize=(4,6))\n    rects = ax.barh(ind, missing_df.missing_count.values, color='y')\n    ax.set_yticks(ind)\n    ax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\n    ax.set_xlabel(\"Count of missing values\")\n    ax.set_title(\"Number of missing values in each column\")\n    plt.show()\nplot_miss_data(train)","87ea37b0":"X = train.copy()\nY = test.copy()\n\nnames = ['\u0417\u0435\u043c\u0435\u043b\u044c\u043d\u044b\u0439 \u0443\u0447\u0430\u0441\u0442\u043e\u043a', '\u041f\u0430\u0448\u043d\u044f \u043e\u0440\u043e\u0448\u0430\u0435\u043c\u0430\u044f', '\u041f\u0430\u0448\u043d\u044f \u0431\u043e\u0433\u0430\u0440\u043d\u0430\u044f', \n             '\u041f\u0430\u0448\u043d\u044f', '\u0411\u043e\u0433\u0430\u0440\u043d\u0430\u044f \u043f\u0430\u0448\u043d\u044f', '\u041c\u043d\u043e\u0433\u043e\u043b\u0435\u0442\u043d\u0438\u0435 \u043d\u0430\u0441\u0430\u0436\u0434\u0435\u043d\u0438\u044f', \n             '\u0421\u0435\u043d\u043e\u043a\u043e\u0441', '\u041a\u043e\u0448\u0430\u0440\u0430', '\u041c\u043d\u043e\u0433.\u043d\u0430\u0441\u0430\u0436\u0434\u0435\u043d\u0438\u044f', '\u0417\u0435\u043c\u0435\u043b\u044c\u043d\u0430\u044f \u0434\u043e\u043b\u044f',]\n\ndef fill_nan(X):\n    # These columns have most NaN values and do not have approach for filling\n    X = X.drop(['\u041f\u043e\u0441\u0435\u043b. \u0440\u0430\u0439\u043e\u043d', '\u041e\u043a\u0440\u0443\u0433', '\u0423\u043b\u0438\u0446\u0430',], axis=1)\n    \n    # Date of registration\n    X['DateRegistr'] = X['\u0414\u0430\u0442\u0430 \u0440\u0435\u0433\u0438\u0441\u0442\u0440\u0430\u0446\u0438\u0438'].apply(lambda x: x[:4]+x[5:7])\n    X['DateRegistr'] = X['DateRegistr'].astype(int)\n    \n    # Number of rooms, \n    # if more than 13 or NaN -> equal to median number\n    # for some NaN look at form of usage, if it havenot rooms at all, like arable lands -> equal to 0\n    X['\u041a\u043e\u043b-\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442'] = X['\u041a\u043e\u043b-\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442'].round()\n    median_room_number = X['\u041a\u043e\u043b-\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442'].median()\n    \n    X.loc[X['\u041a\u043e\u043b-\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442'] > 13, '\u041a\u043e\u043b-\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442'] = median_room_number\n    tmp_df = X[X['\u041a\u043e\u043b-\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442'].isnull()]\n        \n    for i in names:\n        idx = X[X['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f']==i].index\n        X.loc[idx, '\u041a\u043e\u043b-\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442'] = 0\n        \n    X.loc[X['\u041a\u043e\u043b-\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442'].isnull(), '\u041a\u043e\u043b-\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442'] = median_room_number\n    \n    # Processing with code, maybe separate into categories by price\n    X[['Code0', 'Code1','Code2', 'Code3', 'Code4', 'Code5', 'Code6']] = X['\u041a\u043e\u0434'].str.split('-', expand=True)\n    \n    # Floor, HouseFloor, \n    # if more than 15(18) or NaN -> equal to median number\n    # for some NaN look at form of usage, if it havenot rooms at all, like arable lands -> equal to 0\n    X['\u042d\u0442\u0430\u0436'] = X['\u042d\u0442\u0430\u0436'].round()\n    X['\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'] = X['\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'].round()\n    \n    median_floor = X['\u042d\u0442\u0430\u0436'].median()\n    median_housefloor = X['\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'].median()\n    \n    X.loc[X['\u042d\u0442\u0430\u0436']>15, '\u042d\u0442\u0430\u0436'] = median_floor\n    X.loc[X['\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438']>18, '\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'] = median_housefloor\n\n    for i in names:\n        idx = X[X['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f']==i].index\n        X.loc[idx, '\u042d\u0442\u0430\u0436'] = 0\n        X.loc[idx, '\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'] = 0\n        \n    X.loc[X['\u042d\u0442\u0430\u0436'].isnull(), '\u042d\u0442\u0430\u0436'] = X.loc[X['\u042d\u0442\u0430\u0436'].isnull(), '\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438']\n    X.loc[X['\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'].isnull(), '\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'] = X.loc[X['\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'].isnull(), '\u042d\u0442\u0430\u0436']\n    X.loc[X['\u042d\u0442\u0430\u0436'].isnull(), '\u042d\u0442\u0430\u0436'] = median_floor\n    X.loc[X['\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'].isnull(), '\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'] = median_housefloor\n    X.loc[X['\u042d\u0442\u0430\u0436'] > X['\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'], '\u042d\u0442\u0430\u0436'] = X.loc[X['\u042d\u0442\u0430\u0436'] > X['\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438'], '\u041a\u043e\u043b-\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0437\u0434\u0430\u043d\u0438\u0438']\n    \n    # Year built, for arable lands and other lands give current year\n    median_year = X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'].median()\n    X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] = X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'].replace(0, 2020)\n    X.loc[X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438']<1905, '\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] = median_year\n    X.loc[X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438']>2020, '\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] = 2020\n\n    for i in names:\n        idx = X[X['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f']==i].index\n        X.loc[idx, '\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] = 2020\n        \n    X.loc[X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'].isnull(), '\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] = median_year\n    \n    # Building area (for lands it's equal 0)\n    square_median = X['\u041f\u043b\u043e\u0449\u0430\u0434\u044c \u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f'].median()\n    \n    for i in names:\n        idx = X[X['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f']==i].index\n        X.loc[idx, '\u041f\u043b\u043e\u0449\u0430\u0434\u044c \u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f'] = 0\n\n    X.loc[X['\u041f\u043b\u043e\u0449\u0430\u0434\u044c \u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f'].isnull(), '\u041f\u043b\u043e\u0449\u0430\u0434\u044c \u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f'] = square_median\n    \n    # Land area\n    land_median = X['\u041f\u043b\u043e\u0449\u0430\u0434\u044c \u0437\u0435\u043c.\u0443\u0447\u0430\u0441\u0442\u043a\u0430'].median()\n    land_names = ['\u041a\u0432\u0430\u0440\u0442\u0438\u0440\u0430', '\u041f\u0430\u0440\u043a\u043e\u0432\u043e\u0447\u043d\u043e\u0435 \u043c\u0435\u0441\u0442\u043e', '\u041d\u0435\u0436\u0438\u043b\u043e\u0435 \u043f\u043e\u043c\u0435\u0449\u0435\u043d\u0438\u0435', '\u041e\u0444\u0438\u0441', '\u041f\u043e\u0434\u0432\u0430\u043b']\n\n    for i in land_names:\n        idx = X[X['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f']==i].index\n        X.loc[idx, '\u041f\u043b\u043e\u0449\u0430\u0434\u044c \u0437\u0435\u043c.\u0443\u0447\u0430\u0441\u0442\u043a\u0430'] = 0\n    X.loc[X['\u041f\u043b\u043e\u0449\u0430\u0434\u044c \u0437\u0435\u043c.\u0443\u0447\u0430\u0441\u0442\u043a\u0430'].isnull(), '\u041f\u043b\u043e\u0449\u0430\u0434\u044c \u0437\u0435\u043c.\u0443\u0447\u0430\u0441\u0442\u043a\u0430'] = land_median\n    \n    # Terr. unit\n    X['\u0422\u0435\u0440\u0440. \u0435\u0434\u0438\u043d\u0438\u0446\u0430'] = X['\u0422\u0435\u0440\u0440. \u0435\u0434\u0438\u043d\u0438\u0446\u0430'].fillna('XXXX1')\n#     lbl = preprocessing.LabelEncoder()\n#     lbl.fit(list(X['\u0422\u0435\u0440\u0440. \u0435\u0434\u0438\u043d\u0438\u0446\u0430'].values)) \n#     X['\u0422\u0435\u0440\u0440. \u0435\u0434\u0438\u043d\u0438\u0446\u0430'] = lbl.transform(list(X['\u0422\u0435\u0440\u0440. \u0435\u0434\u0438\u043d\u0438\u0446\u0430'].values))\n    \n    # Terr. disctrict\n    X['\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d'] = X['\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d'].fillna('XXXX2')\n#     lbl = preprocessing.LabelEncoder()\n#     lbl.fit(list(X['\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d'].values)) \n#     X['\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d'] = lbl.transform(list(X['\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d'].values))\n    \n    # Form of Ownership\n    X['\u0424\u043e\u0440\u043c\u0430 \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438'] = X['\u0424\u043e\u0440\u043c\u0430 \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438'].fillna('\u0414\u0440\u0443\u0433\u0430\u044f')\n#     lbl = preprocessing.LabelEncoder()\n#     lbl.fit(list(train['\u0424\u043e\u0440\u043c\u0430 \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438'].values)) \n#     X['\u0424\u043e\u0440\u043c\u0430 \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438'] = lbl.transform(list(X['\u0424\u043e\u0440\u043c\u0430 \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438'].values))\n    \n    # Purpose, Walls material, Cover type\n    other_names = ['\u041d\u0430\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435', '\u041c\u0430\u0442\u0435\u0440. \u0421\u0442\u0435\u043d', '\u0422\u0438\u043f \u043a\u0440\u043e\u0432\u043b\u0438', '\u041e\u0442\u043e\u043f\u043b\u0435\u043d\u0438\u0435']\n    for i in other_names:\n        X[i] = X[i].fillna('\u0414\u0440\u0443\u0433\u043e\u0435')\n#         lbl = preprocessing.LabelEncoder()\n#         lbl.fit(list(train[i].values)) \n#         X[i] = lbl.transform(list(X[i].values))\n    \n    # Form os Usage\n    X['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f'] = X['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f'].fillna('\u0414\u0440\u0443\u0433\u043e\u0435')\n    \n    # Object type\n    X['\u041e\u0431\u044a\u0435\u043a\u0442'] = X['\u041e\u0431\u044a\u0435\u043a\u0442'].fillna('XXXX3')\n    \n    # Gas\n    X['\u0413\u0430\u0437\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f'] = X['\u0413\u0430\u0437\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f'].replace(to_replace=['N', 'Y'], value=[0, 1])\n    X['\u0413\u0430\u0437\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f'] = X['\u0413\u0430\u0437\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f'].fillna(0)\n    X['\u0413\u0430\u0437\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f'] = X['\u0413\u0430\u0437\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f'].astype(int)\n    \n    # Bath\/Sauna\n    X['\u041d\u0430\u043b\u0438\u0447\u0438\u0435 \u0431\u0430\u043d\u0438\/\u0441\u0430\u0443\u043d\u044b'] = X['\u041d\u0430\u043b\u0438\u0447\u0438\u0435 \u0431\u0430\u043d\u0438\/\u0441\u0430\u0443\u043d\u044b'].replace(to_replace=['N', 'Y'], value=[0, 1])\n    X['\u041d\u0430\u043b\u0438\u0447\u0438\u0435 \u0431\u0430\u043d\u0438\/\u0441\u0430\u0443\u043d\u044b'] = X['\u041d\u0430\u043b\u0438\u0447\u0438\u0435 \u0431\u0430\u043d\u0438\/\u0441\u0430\u0443\u043d\u044b'].fillna(0)\n    X['\u041d\u0430\u043b\u0438\u0447\u0438\u0435 \u0431\u0430\u043d\u0438\/\u0441\u0430\u0443\u043d\u044b'] = X['\u041d\u0430\u043b\u0438\u0447\u0438\u0435 \u0431\u0430\u043d\u0438\/\u0441\u0430\u0443\u043d\u044b'].astype(int)\n    \n    # Address\n    df_X = X['\u0410\u0434\u0440\u0435\u0441'].str.split('-', expand=True)\n    df_X[1] =df_X[1].fillna('XYXY')\n    df_X = df_X[[0,1]]\n    df_X = df_X.rename(columns={0:'Address0', 1:'Address1'})\n    X = pd.concat([X, df_X], axis=1)\n    X = X.drop('\u0410\u0434\u0440\u0435\u0441', axis=1)\n    \n    \n    X = X.drop(['\u041a\u043e\u0434', 'Code3', 'Code4', 'Code5', 'Code6', '\u0414\u0430\u0442\u0430 \u0440\u0435\u0433\u0438\u0441\u0442\u0440\u0430\u0446\u0438\u0438', '\u041f\u043e\u0441\u0435\u043b\u0435\u043d\u0438\u0435'], axis=1)\n    return X\n\nX = fill_nan(X)\nY = fill_nan(Y)","ab0729aa":"def Encoding(X, Y): # train, test\n    lbl = preprocessing.LabelEncoder()\n       \n    other_names = ['\u0422\u0435\u0440\u0440. \u0435\u0434\u0438\u043d\u0438\u0446\u0430', '\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d', '\u0424\u043e\u0440\u043c\u0430 \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438', 'Code0', \n                   'Code1', 'Code2', 'Address0',\n                   '\u041d\u0430\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435', '\u041c\u0430\u0442\u0435\u0440. \u0421\u0442\u0435\u043d', '\u0422\u0438\u043f \u043a\u0440\u043e\u0432\u043b\u0438', '\u041e\u0442\u043e\u043f\u043b\u0435\u043d\u0438\u0435', ]\n    \n    for i in other_names:\n        lbl.fit(list(X[i].values)) \n        X[i] = lbl.transform(list(X[i].values))\n        Y[i] = lbl.transform(list(Y[i].values))\n    \n    \n    return X, Y\n\nX, Y = Encoding(X, Y)","9586f684":"group_df = X.groupby('Code0')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'Code0_price'})\nX = X.merge(group_df, on=['Code0'], how='left')\nY = Y.merge(group_df, on=['Code0'], how='left')\ndef Code0_to_cat(X):\n    X['Code0_cat'] = np.nan\n    X.loc[X['Code0_price'] < 1000, 'Code0_cat'] = 1\n    X.loc[(X['Code0_price'] >= 1000) & (X['Code0_price'] <= 2000), 'Code0_cat'] = 2\n    X.loc[(X['Code0_price'] > 2000), 'Code0_cat'] = 3\n    return X\n\nX, Y = Code0_to_cat(X), Code0_to_cat(Y)\n\ngroup_df = X.groupby('Code1')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'Code1_price'})\nX = X.merge(group_df, on=['Code1'], how='left')\nY = Y.merge(group_df, on=['Code1'], how='left')\ndef Code1_to_cat(X):\n    X['Code1_cat'] = np.nan\n    X.loc[X['Code1_price'] < 1500, 'Code1_cat'] = 1\n    X.loc[(X['Code1_price'] >= 1500) & (X['Code1_price'] <= 3000), 'Code1_cat'] = 2\n    X.loc[(X['Code1_price'] > 3000), 'Code1_cat'] = 3\n    return X\n\nX, Y = Code1_to_cat(X), Code1_to_cat(Y)\n\ngroup_df = X.groupby('Code2')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'Code2_price'})\nX = X.merge(group_df, on=['Code2'], how='left')\nY = Y.merge(group_df, on=['Code2'], how='left')\ndef Code2_to_cat(X):\n    X['Code2_cat'] = np.nan\n    X.loc[X['Code2_price'] < 1500, 'Code2_cat'] = 1\n    X.loc[(X['Code2_price'] >= 1500) & (X['Code2_price'] <= 3000), 'Code2_cat'] = 2\n    X.loc[(X['Code2_price'] > 3000), 'Code2_cat'] = 3\n    return X\n\nX, Y = Code2_to_cat(X), Code2_to_cat(Y)","a727c62d":"group_df = X.groupby('\u041e\u0431\u044a\u0435\u043a\u0442')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'Object_price'})\nX = X.merge(group_df, on=['\u041e\u0431\u044a\u0435\u043a\u0442'], how='left')\nY = Y.merge(group_df, on=['\u041e\u0431\u044a\u0435\u043a\u0442'], how='left')\ndef Object_to_cat(X):\n    X['object_cat'] = np.nan\n    X.loc[X['Object_price'] < 1000, 'object_cat'] = 1\n    X.loc[(X['Object_price']>= 1000) & (X['Object_price'] <= 2000), 'object_cat'] = 2\n    X.loc[(X['Object_price'] > 2000) & (X['Object_price'] <= 4000), 'object_cat'] = 3\n    X.loc[(X['Object_price'] > 4000) & (X['Object_price'] <= 6000), 'object_cat'] = 4\n    X.loc[(X['Object_price'] > 6000) & (X['Object_price'] <= 8000), 'object_cat'] = 5\n    X.loc[(X['Object_price'] > 8000), 'object_cat'] = 6\n    return X\n\nX, Y = Object_to_cat(X), Object_to_cat(Y)\n\nY.loc[Y['Object_price'].isnull(), 'Object_price'] = X['\u0426\u0435\u043d\u0430'].median()\nY.loc[Y['object_cat'].isnull(), 'object_cat'] = 3\nX, Y = X.drop('\u041e\u0431\u044a\u0435\u043a\u0442', axis=1), Y.drop('\u041e\u0431\u044a\u0435\u043a\u0442', axis=1)","e098b6b8":"# group_df = X.groupby('\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'UsageForm_price'})\n# plt.figure(figsize=(9,6))\n# sns.barplot(group_df['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f'].values, group_df['UsageForm_price'].values, alpha=0.8)\n# plt.ylabel('Median Price', fontsize=12)\n# plt.xlabel('Form', fontsize=12)\n# plt.xticks(rotation='vertical')\n# plt.show()","469cc94e":"group_df = X.groupby('\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'UsageForm_price'})\nX = X.merge(group_df, on=['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f'], how='left')\nY = Y.merge(group_df, on=['\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f'], how='left')\n\ndef UsageForm_to_cat(X):\n    X['usageform_cat'] = np.nan\n    X.loc[X['UsageForm_price'] < 1000, 'usageform_cat'] = 1\n    X.loc[(X['UsageForm_price'] >= 1000) & (X['UsageForm_price'] <= 2000), 'usageform_cat'] = 2\n    X.loc[(X['UsageForm_price'] > 2000) & (X['UsageForm_price'] <= 4000), 'usageform_cat'] = 3\n    X.loc[(X['UsageForm_price'] > 4000) & (X['UsageForm_price'] <= 6000), 'usageform_cat'] = 4\n    X.loc[(X['UsageForm_price'] > 6000) & (X['UsageForm_price'] <= 8000), 'usageform_cat'] = 5\n    X.loc[(X['UsageForm_price'] > 8000), 'usageform_cat'] = 6\n    return X\n\nX = UsageForm_to_cat(X)\nY = UsageForm_to_cat(Y)\nY.loc[Y['UsageForm_price'].isnull(), 'UsageForm_price'] = X['\u0426\u0435\u043d\u0430'].median()\nY.loc[Y['usageform_cat'].isnull(), 'usageform_cat'] = 3\nX = X.drop('\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f', axis=1)\nY = Y.drop('\u0424\u043e\u0440\u043c\u0430 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f', axis=1)","6ee523b1":"group_df = X.groupby('Address0')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'Address0_price'})\nX = X.merge(group_df, on=['Address0'], how='left')\nY = Y.merge(group_df, on=['Address0'], how='left')\ndef Address0_to_cat(X):\n    X['Address0_cat'] = np.nan\n    X.loc[X['Address0_price'] < 1000, 'Address0_cat'] = 1\n    X.loc[(X['Address0_price'] >= 1000) & (X['Address0_price'] <= 2000), 'Address0_cat'] = 2\n    X.loc[(X['Address0_price'] > 2000), 'Address0_cat'] = 3\n    return X\nX = Address0_to_cat(X)\nY = Address0_to_cat(Y)\n\nX = X.drop(['Address1', '\u0422\u0438\u043f \u0441\u0430\u043d\u0443\u0437\u043b\u0430','\u0421\u0435\u0440\u0438\u044f \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b'],  axis=1)\nY = Y.drop(['Address1', '\u0422\u0438\u043f \u0441\u0430\u043d\u0443\u0437\u043b\u0430','\u0421\u0435\u0440\u0438\u044f \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b'], axis=1)","f8070e9c":"group_df = X.groupby('\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'terr_raion_byprice'})\nX = X.merge(group_df, on=['\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d'], how='left')\nY = Y.merge(group_df, on=['\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d'], how='left')\nX['terrraoin_cat_price'] = X['terr_raion_byprice'].apply(lambda x: 1 if x < 1000 \n                                                            else (2 if 1000<=x<2000 \n                                                                  else 3))\nY['terrraoin_cat_price'] = Y['terr_raion_byprice'].apply(lambda x: 1 if x < 1000 \n                                                            else (2 if 1000<=x<2000 \n                                                                  else 3))","32a5730b":"group_df = X.groupby('DateRegistr')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'Price_date'})\nX = X.merge(group_df, on=['DateRegistr'], how='left')\nY = Y.merge(group_df, on=['DateRegistr'], how='left')\ndef date_to_cat(X):\n    X['Price_date_cat'] = np.nan\n    X.loc[X['Price_date'] < 2500, 'Price_date_cat'] = 1\n    X.loc[(X['Price_date'] >= 2500) & (X['Price_date'] <= 2700), 'Price_date_cat'] = 2\n    X.loc[(X['Price_date'] > 2700), 'Price_date_cat'] = 3        \n    return X\ndef year_to_cat(X):\n    X['year_cat'] = np.nan\n    X.loc[X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] < 1921, 'year_cat'] = 1\n    X.loc[(X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] >= 1921) & (X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] <= 1930), 'year_cat'] = 2\n    X.loc[(X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] > 1930) & (X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] <= 1950), 'year_cat'] = 3\n    X.loc[(X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] > 1950) & (X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] <= 1990), 'year_cat'] = 4\n    X.loc[(X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] > 1990) & (X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] <= 2005), 'year_cat'] = 5\n    X.loc[(X['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'] > 2005), 'year_cat'] = 6\n    return X\nyear_group = X.groupby('\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438')['\u0426\u0435\u043d\u0430'].aggregate(np.median).reset_index().rename(columns={'\u0426\u0435\u043d\u0430':'Year_byprice'})\nX = X.merge(year_group, on=['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'], how='left')\nY = Y.merge(year_group, on=['\u0413\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438'], how='left')\nX['year_price_cat'] = X['Year_byprice'].apply(lambda x: 1 if x < 2000 \n                                                            else (2 if 2000<=x<=4000 \n                                                                  else (3 if 4000<x<=6000\n                                                                        else 4)))\nY['year_price_cat'] = Y['Year_byprice'].apply(lambda x: 1 if x < 2000 \n                                                            else (2 if 2000<=x<=4000 \n                                                                  else (3 if 4000<x<=6000\n                                                                        else 4)))\nX, Y = date_to_cat(X), date_to_cat(Y)\nX, Y = year_to_cat(X), year_to_cat(Y)","c032260c":"sum(X.isnull().sum()), sum(Y.isnull().sum())","1da6ef22":"from sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error as mse, r2_score","53ceaf7d":"train_data = X.drop('\u0426\u0435\u043d\u0430', axis=1)\ntrain_y = X['\u0426\u0435\u043d\u0430']\ntest_data = Y\n\ncolumns = ['Price_date', 'Price_date_cat', '\u0424\u043e\u0440\u043c\u0430 \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438',\n           'Code0_cat', '\u041d\u0430\u043b\u0438\u0447\u0438\u0435 \u0431\u0430\u043d\u0438\/\u0441\u0430\u0443\u043d\u044b', 'Address0_cat',\n           'Code0', '\u0422\u0435\u0440\u0440. \u0435\u0434\u0438\u043d\u0438\u0446\u0430', 'Code2_cat', 'Code0', 'year_price_cat',\n#            '\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d',\n            ]\n\ntrain_data = train_data.drop(columns, axis=1)\ntest_data = test_data.drop(columns, axis=1)\n\n\n### SCALER USAGE\n# col_names = [\n#             #  '\u0422\u0435\u0440\u0440. \u0435\u0434\u0438\u043d\u0438\u0446\u0430', '\u0422\u0435\u0440\u0440. \u0440\u0430\u0439\u043e\u043d', '\u0424\u043e\u0440\u043c\u0430 \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u0438', \n#              '\u041d\u0430\u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435', '\u041c\u0430\u0442\u0435\u0440. \u0421\u0442\u0435\u043d', '\u0422\u0438\u043f \u043a\u0440\u043e\u0432\u043b\u0438',\n#              '\u041e\u0442\u043e\u043f\u043b\u0435\u043d\u0438\u0435', 'Code1', 'Code2', \n#             #  'Code0_cat', 'Code1_cat', 'Code2_cat',\n#              'object_cat', 'usageform_cat', \n#             #  'Address0_cat', \n#              'terrraoin_cat_price',\n#             #  'year_price_cat',\t'Price_date_cat',\t\n#              'year_cat']\n# rest_cols = train_data.columns.drop(col_names)\n# scaler = StandardScaler()\n# stand_features = scaler.fit_transform(train_data[rest_cols])\n# # df = pd.DataFrame(stand_features, columns=train_data.columns)\n# df = pd.DataFrame(stand_features, columns=rest_cols)\n# df = pd.concat([df, train_data[col_names]], axis=1)\n# test_stand_feat = scaler.transform(test_data[rest_cols])\n# # test_df = pd.DataFrame(test_stand_feat, columns=test_data.columns)\n# test_df = pd.DataFrame(test_stand_feat, columns=rest_cols)\n# test_df = pd.concat([test_df, test_data[col_names]], axis=1)\n# X_train, X_valid, y_train, y_valid = train_test_split(df, train_y, test_size=0.2, shuffle=True, random_state=4)\n\nX_train, X_valid, y_train, y_valid = train_test_split(train_data, train_y, test_size=0.2, shuffle=True, random_state=4)","5eb75ac4":"from catboost import CatBoostRegressor\nfrom sklearn.model_selection import train_test_split\nfrom catboost import Pool, CatBoostRegressor, cv\n\ncbr = CatBoostRegressor(\n    n_estimators = 1500,\n    loss_function = 'RMSE',\n    eval_metric = 'R2', \n    learning_rate=0.01, \n    depth=9, \n    l2_leaf_reg=9, #9\n    )\n\ncbr.fit(X_train, y_train)\nprint('Train', r2_score(y_train, cbr.predict(X_train)))\nprint('Valid', r2_score(y_valid, cbr.predict(X_valid)))","d33473f2":"# Drop unnecessary columns\ncbr.fit(X_train, y_train)\nprint('Train', r2_score(y_train, cbr.predict(X_train)))\nprint('Valid', r2_score(y_valid, cbr.predict(X_valid)))","9f56348d":"def plot_feature_importances(importances, X):\n    indices = np.argsort(importances)[::-1]\n    plt.figure(figsize=(20, 6))\n    plt.title(\"Feature importances\", fontsize=16)\n    plt.bar(range(X.shape[1]), importances[indices] \/ importances.sum(),\n            color=\"darkblue\", align=\"center\")\n    plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90, fontsize=14)\n    plt.xlim([-1, X.shape[1]])\n\n    plt.tight_layout()\n    plt.show()\n\nplot_feature_importances(importances=cbr.feature_importances_, X=X_train)","61d80104":"cbr.fit(train_data, train_y)\ny_pred = cbr.predict(test_data)\nsubmission = pd.DataFrame({'Id': test_data.index, 'Predicted': y_pred})\nsubmission.to_csv('submit_cbr_final.csv', index=False)","211f164b":"**Run CatBoostRegressor finding with GridSearch best params ant use feature importance**","b2815370":"# Fill NaN values","128af54d":"Categorize objects","521575d0":"# Categorize by price","35faa3a2":"**Processing Address**","aecce929":"# Model","ddfe3efe":"Categorize Codes ","fdf1fc28":"Separate district by price","0d402b22":"Categorize built year and date of registration by price","6469ea4e":"# Predict on test data","5335aaec":"Categorize Form of Usage","74ae789f":"# **Number of missing values**\n\n**There are vast number of missing values, lets fill rows**"}}