{"cell_type":{"2a47b09a":"code","82d7bf02":"code","2ef81a9c":"code","e15a513d":"code","e1a3f86c":"code","fd48a5fd":"code","e7c15003":"code","c6220724":"code","4fdde24a":"code","216ec40c":"code","d1289474":"code","087362bd":"code","93d14b87":"code","a4c821be":"code","35519a80":"code","95825152":"code","2185a8f5":"code","51057414":"code","b737ee56":"markdown","0791c0ea":"markdown","f6f9d9f6":"markdown","cb192754":"markdown","f0732195":"markdown"},"source":{"2a47b09a":"# Imports\n\nimport os\nfrom tqdm.notebook import tqdm\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras","82d7bf02":"# Setting the path\n\nPATH = \"..\/input\/petfinder-pawpularity-score\/\"","2ef81a9c":"# Reading in data\n\ntrain = pd.read_csv(\"\".join([PATH,\"train.csv\"]))\ntest = pd.read_csv(\"\".join([PATH,\"test.csv\"]))\nsubmission = pd.read_csv(\"\".join([PATH,\"sample_submission.csv\"]))","e15a513d":"# Viewing the first few rows\n\ntrain.head()","e1a3f86c":"# Viewing the shape\n\ntrain.shape","fd48a5fd":"# Viewing the info of the data\n\ntrain.info()","e7c15003":"# Setting the file path of each image\n\ntrain[\"path\"] = train[\"Id\"].apply(lambda x: \"..\/input\/petfinder-pawpularity-score\/train\/\" + x + \".jpg\")\ntest[\"path\"] = test[\"Id\"].apply(lambda x: \"..\/input\/petfinder-pawpularity-score\/test\/\" + x + \".jpg\")","c6220724":"# Functions reading and converting data into Tensorflow datasets\n# source: https:\/\/www.kaggle.com\/ekaterinadranitsyna\/pretrained-feature-model-kera\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 64\nIMG_SIZE = 224\ntarget = 'Pawpularity'\nseed = 0\n\ndef set_seed(seed=seed):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef id_to_path(img_id: str, dir: str):\n    \"\"\"Function returns a path to an image file.\n    :param img_id: Image Id\n    :param dir: Path to the directory with images\n    :return: Image file path\n    \"\"\"\n    return os.path.join(dir, f'{img_id}.jpg')\n\n\n@tf.function\ndef get_image(path: str) -> tf.Tensor:\n    \"\"\"Function loads image from a file and preprocesses it.\n    :param path: Path to image file\n    :return: Tensor with preprocessed image\n    \"\"\"\n    print(f\"IMAGE PROCESSING {str}\")\n    ## Decoding the image\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n\n    ## Resizing image\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.int32)\n\n    return image\n\n\n@tf.function\ndef process_dataset(path: str, label: int) -> tuple:\n    \"\"\"Function returns preprocessed image and label.\n    :param path: Path to image file\n    :param label: Class label\n    :return: tf.Tensor with preprocessed image, numeric label\n    \"\"\"\n    return get_image(path), label\n\n\n@tf.function\ndef get_dataset(x, y=None) -> tf.data.Dataset:\n    \"\"\"Function creates batched optimized dataset for the model\n    out of an array of file paths and (optionally) class labels.\n    :param x: Input data for the model (array of file paths)\n    :param y: Target values for the model (array of class indexes)\n    :return TensorFlow Dataset object\n    \"\"\"\n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        return ds.map(process_dataset, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses and metrics\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    rmse = hist.history['root_mean_squared_error']\n    val_rmse = hist.history['val_root_mean_squared_error']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(loss) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n\n    ax1.plot(x_axis, loss, 'bo', label='Training')\n    ax1.plot(x_axis, val_loss, 'ro', label='Validation', alpha=0.3)\n    ax1.set_title('MSE Loss')\n    ax1.legend()\n\n    ax2.plot(x_axis, rmse, 'bo', label='Training')\n    ax2.plot(x_axis, val_rmse, 'ro', label='Validation', alpha=0.3)\n    ax2.set_title('Root Mean Squared Error')\n    ax2.set_xlabel('Epochs')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","4fdde24a":"# Splitting train into train and validation sets\n\ntrain_subset, valid_subset = train_test_split(\n    train[['path', target]],\n    test_size=.2, shuffle=True, random_state=0\n)","216ec40c":"# Creating TensorFlow datasets\n\ntrain_ds = get_dataset(x=train_subset['path'], y=train_subset[target])\nvalid_ds = get_dataset(x=valid_subset['path'], y=valid_subset[target])\ntest_ds = get_dataset(x=test['path'])","d1289474":"# Creating the model\n\ndef get_model():\n    \n    ## Setting the Inputs\n    inputs = keras.Input(shape=(224, 224, 3))\n    x = inputs\n    \n    ## Preprocessing Layers\n    \n    ### Rescaling\n    x = keras.layers.experimental.preprocessing.Rescaling(1.\/255)(x)\n    \n    ## Data Augmentation\n    x = keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\")(x)\n    x = keras.layers.experimental.preprocessing.RandomRotation(0.2)(x)\n    x = keras.layers.experimental.preprocessing.RandomTranslation(0.2,0.2)(x)\n    \n    ## Convolutional Layers\n    \n    ### First CNN layer\n    x = keras.layers.Conv2D(filters=96, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.MaxPool2D(2)(x)\n\n    ### Second CNN layer\n    x = keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.MaxPool2D(2)(x)\n    \n    ### Third CNN layer\n    x = keras.layers.Conv2D(filters=256, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.MaxPool2D(2)(x)\n\n    ## Flattening the layer\n    x = keras.layers.Flatten()(x)\n    \n    ## Fully Connected (Dense) Layers\n    \n    ### First Fully Connected layer w\/ Dropout\n    x = keras.layers.Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n    x = keras.layers.Dropout(0.2)(x)\n    \n    ## Output layer\n    output = keras.layers.Dense(1)(x)\n\n    ## Returning the model\n    return keras.Model(inputs=inputs, outputs=output)","087362bd":"# Fitting the model\n\ndef compile_and_fit(model):\n    \n    # Creating an exponential decay for learning rate\n\n    LEARNING_RATE = 1e-2\n    DECAY_STEPS = 100\n    DECAY_RATE = 0.99\n\n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=LEARNING_RATE,\n        decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n        staircase=True\n    )\n    \n    # Creating an early stopper\n\n    early_stop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss', patience=5, restore_best_weights=True\n    )\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n        loss=tf.keras.losses.MeanSquaredError(),\n        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n    )\n    \n    history = model.fit(\n        train_ds, \n        validation_data=valid_ds,\n        epochs=50,\n        use_multiprocessing=True, workers=-1,\n        callbacks=[early_stop]\n    )\n    \n    return model, history","93d14b87":"# # Applying K-Fold\n\n# from sklearn.model_selection import KFold\n# from sklearn.metrics import mean_squared_error\n\n# kf = KFold(5)\n\n# scores = []\n\n# for train_index, valid_index in kf.split(train_subset):\n#     print(\"TRAIN:\", train_index, \"TEST:\", valid_index)\n    \n#     X_train, X_valid = train_subset.iloc[train_index], train_subset.iloc[valid_index]\n    \n#     train_ds = get_dataset(x=X_train['path'], y=X_train[target])\n#     valid_ds = get_dataset(x=X_valid['path'], y=X_valid[target])\n    \n#     model = get_model()\n    \n#     model, history = compile_and_fit(model)\n    \n#     predictions = model.predict(valid_ds, use_multiprocessing=True, workers=os.cpu_count())\n    \n#     rmse = mean_squared_error(X_valid[target], predictions, squared=False)\n#     print(rmse)\n    \n#     scores.append(rmse)\n\n# # Printing the results of K-Fold\n\n# print(f\"Mean: {np.mean(scores)}, Std: {np.std(scores)}\")","a4c821be":"# Getting the model\n\nkeras.backend.clear_session()\n\nmodel = get_model()\nmodel.summary()","35519a80":"# Fitting the model\n\nmodel, history = compile_and_fit(model)\n# predictions = model.predict(valid_ds, use_multiprocessing=True, workers=os.cpu_count())","95825152":"# Plotting accuracy and loss of model\n\nplot_history(history)","2185a8f5":"# Using the model to predict on the test data\n\ntest[target] = model.predict(\n    test_ds, use_multiprocessing=True, workers=os.cpu_count()\n)","51057414":"# Saving the submission file\n\ntest[['Id', target]].to_csv('submission.csv', index=False)\ntest[['Id', target]].head()","b737ee56":"To-Do's\n* save model\n* remove Duplicate images\n* augment the data more\n* add Transfer Learning\n* add meta data","0791c0ea":"## Inference","f6f9d9f6":"V2 Updates:\n* made CNN deeper\n* tweaked parameters\n* added some image augmentation to the model\n* added some documentation","cb192754":"Sources:\n* https:\/\/www.kaggle.com\/ekaterinadranitsyna\/pretrained-feature-model-keras \n    * used it to load data and convert it to TF Datasets\n* removed the Transfer Learning part for simplicity\n* converted Sequential API -> Functional API","f0732195":"# Creating a Baseline Tensorflow Model to Predict Pet Popularity"}}