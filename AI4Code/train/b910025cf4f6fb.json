{"cell_type":{"25565334":"code","e2206cb9":"code","aea08e7a":"code","2b716b80":"code","fab983bc":"code","62fd4e72":"code","0beccd06":"code","0d164896":"code","5ed3750f":"code","7d98aef9":"code","4a88f4f5":"code","59ccd2a6":"code","ebfd6a05":"code","cf213965":"code","5b9c7fab":"code","0757fbf6":"code","f1dfec5f":"code","5fee2593":"code","ca987fb6":"code","f081b230":"code","6eda0295":"code","22c6d84c":"code","4224b731":"code","bbb3954a":"code","d4367b5a":"code","ea6d9808":"code","69c7d8de":"code","807feb36":"code","ad7af9f7":"markdown","084b67c0":"markdown","0610becb":"markdown","10e4b614":"markdown","8092f457":"markdown","49a28d82":"markdown","ae269b08":"markdown","622b6827":"markdown","04c5dc94":"markdown","2af15940":"markdown","987d06a4":"markdown"},"source":{"25565334":"# Basic library\nimport numpy as np \nimport pandas as pd \nimport os\nimport glob\n\n# Data preprocessing\nimport cv2 # Open cv\n\n# Visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# Machine learning library\nimport keras\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, Activation, Input\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Validation\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score","e2206cb9":"print(\"train\",os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"))\nprint(\"val\",os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"))\nprint(\"test\",os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"))","aea08e7a":"# train_data_set\n# Normal\ntrain_data_nor = pd.DataFrame({})\ntrain_data_nor[\"data_id\"] = os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\")\ntrain_data_nor[\"flg\"] = 0\n\n# Pneumonia\ntrain_data_pne = pd.DataFrame({})\ntrain_data_pne[\"data_id\"] = os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\")\ntrain_data_pne[\"flg\"] = 1","2b716b80":"# val_data_set\n# Normal\nval_data_nor = pd.DataFrame({})\nval_data_nor[\"data_id\"] = os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\")\nval_data_nor[\"flg\"] = 0\n\n# Pneumonia\nval_data_pne = pd.DataFrame({})\nval_data_pne[\"data_id\"] = os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\")\nval_data_pne[\"flg\"] = 1","fab983bc":"# test_data_set\n# Normal\ntest_data_nor = pd.DataFrame({})\ntest_data_nor[\"data_id\"] = os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\")\ntest_data_nor[\"flg\"] = 0\n\n# Pneumonia\ntest_data_pne = pd.DataFrame({})\ntest_data_pne[\"data_id\"] = os.listdir(\"..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\")\ntest_data_pne[\"flg\"] = 1","62fd4e72":"# data shape\nprint(\"train data normal:{}\".format(train_data_nor.shape), \"train_data_pneumonia:{}\".format(train_data_pne.shape))\nprint(\"val data normal:{}\".format(val_data_nor.shape), \"val_data_pneumonia:{}\".format(val_data_pne.shape))\nprint(\"test data normal:{}\".format(test_data_nor.shape), \"test_data_pneumonia:{}\".format(test_data_pne.shape))","0beccd06":"# Combine data frame\ntrain_data = pd.concat([train_data_nor, train_data_pne])\nval_data = pd.concat([val_data_nor, val_data_pne])\ntest_data = pd.concat([test_data_nor, test_data_pne])\n\n# data shape\nprint(\"train data:{}\".format(train_data.shape))\nprint(\"val data:{}\".format(val_data.shape))\nprint(\"test data:{}\".format(test_data.shape))","0d164896":"# data size\nsize = 128\n\n# train_data_nor\ntrain_image_nor = []\n\n# loading\nfor _id in train_data_nor[\"data_id\"]:\n    path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    train_image_nor.append(image)","5ed3750f":"# train_data_pne\ntrain_image_pne = []\n\n# loading\nfor _id in train_data_pne[\"data_id\"]:\n    path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    train_image_pne.append(image)","7d98aef9":"# val_data_nor\nval_image_nor = []\n\n# loading\nfor _id in val_data_nor[\"data_id\"]:\n    path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    val_image_nor.append(image)","4a88f4f5":"# val_data_pne\nval_image_pne = []\n\n# loading\nfor _id in val_data_pne[\"data_id\"]:\n    path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    val_image_nor.append(image)","59ccd2a6":"# test_data_nor\ntest_image_nor = []\n\n# loading\nfor _id in test_data_nor[\"data_id\"]:\n    path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    test_image_nor.append(image)","ebfd6a05":"# test_data_pne\ntest_image_pne = []\n\n# loading\nfor _id in test_data_pne[\"data_id\"]:\n    path = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/\"+_id+''\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    test_image_pne.append(image)","cf213965":"fig, ax = plt.subplots(4, 4, figsize=(20,20))\n\nfor i in range(4):\n    ax[0,i].imshow(train_image_nor[i])\n    ax[0,i].set_title(\"train_image_normal\")\n    \n    ax[1,i].imshow(train_image_pne[i])\n    ax[1,i].set_title(\"train_image_pneumonia\")\n    \n    ax[2,i].imshow(test_image_nor[i])\n    ax[2,i].set_title(\"test_image_normal\")\n    \n    ax[3,i].imshow(test_image_pne[i])\n    ax[3,i].set_title(\"test_image_pneumonia\")","5b9c7fab":"train_image = train_image_nor + train_image_pne\nval_image = val_image_nor + val_image_pne\ntest_image = test_image_nor + test_image_pne","0757fbf6":"# Training data\n# data dimension\nX_train = np.ndarray(shape=(len(train_image), size, size, 3), dtype=np.float32)\n\n# change to np.ndarray\ni = 0\n\nfor image in train_image:\n    X_train[i] = train_image[i]\n    i=i+1\n    \n# Scaling\nX_train = X_train\/255\n\n# Checking dimension\nprint(\"Train shape:{}\".format(X_train.shape))","f1dfec5f":"# Val data\n# data dimension\nX_val = np.ndarray(shape=(len(val_image), size, size, 3), dtype=np.float32)\n\n# change to np.ndarray\ni = 0\n\nfor image in val_image:\n    X_val[i] = val_image[i]\n    i=i+1\n    \n# Scaling\nX_val = X_val\/255\n\n# Checking dimension\nprint(\"val shape:{}\".format(X_val.shape))","5fee2593":"# Test data\n# data dimension\nX_Test = np.ndarray(shape=(len(test_image), size, size, 3), dtype=np.float32)\n\n# change to np.ndarray\ni = 0\n\nfor image in test_image:\n    X_Test[i] = test_image[i]\n    i=i+1\n    \n# Scaling\nX_Test = X_Test\/255\n\n# Checking dimension\nprint(\"Test shape:{}\".format(X_Test.shape))","ca987fb6":"# train target data\ny_train = train_data[\"flg\"]\n\n# change to np.array\ny_train = np.array(y_train.values)\nprint(\"y_train shape:{}\".format(y_train.shape))","f081b230":"# val target data\ny_val = val_data[\"flg\"]\n\n# change to np.array\ny_val = np.array(y_val.values)\nprint(\"y_val shape:{}\".format(y_val.shape))","6eda0295":"# test target data\ny_test = test_data[\"flg\"]\n\n# change to np.array\ny_test = np.array(y_test.values)\nprint(\"y shape:{}\".format(y_test.shape))","22c6d84c":"def define_model():\n    model = Sequential()\n    # 1st layer block\n    model.add(BatchNormalization(input_shape=(size, size, 3)))\n    model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    # 2nd layer block\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(filters=128, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    # 3rd layer block\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    # 4th layer block\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(filters=512, kernel_size=(3,3), strides=(1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    # Flatten\n    model.add(Flatten())\n    \n    # Dense layer\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(2, activation='softmax'))\n    \n    # model\n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer=Adam(lr=0.0001, decay=0.000001),\n                  metrics=[\"accuracy\"])\n    return model","4224b731":"# Data augmentation\ndatagen = ImageDataGenerator(rotation_range=15, \n                             width_shift_range=0.2, \n                             height_shift_range=0.2,\n                             horizontal_flip=True)\n\ndatagen.fit(X_train)\n\n# Model check point\nmc = ModelCheckpoint(\"cnn_model_01.h5\",\n                     monitor='val_loss',\n                     save_best_only=True,\n                     verbose=1)\n\nes = EarlyStopping(monitor='val_loss',\n                   patience=5)","bbb3954a":"# Calculation\nmodel = define_model()\n\n# Training\nbatch_size= 12\nepochs = 100\nvalid_samples = 100\ntrain_samples = len(X_train) - valid_samples\n\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n                    steps_per_epoch = train_samples \/ batch_size,\n                    epochs = epochs,\n                    callbacks = [mc, es],\n                    validation_data = datagen.flow(X_val, y_val, batch_size=batch_size),\n                    validation_steps = valid_samples \/ batch_size )","d4367b5a":"train_loss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nplt.figure(figsize=(8, 4))\nplt.plot(range(len(train_loss)), train_loss, label='train_loss')\nplt.plot(range(len(val_loss)), val_loss, label='valid_loss')\nplt.xlabel('epoch', fontsize=16)\nplt.ylabel('loss', fontsize=16)\nplt.yscale(\"log\")\nplt.legend(fontsize=16)\nplt.show()\n\ntrain_loss = history.history[\"accuracy\"]\nval_loss = history.history[\"val_accuracy\"]\n\nplt.figure(figsize=(8, 4))\nplt.plot(range(len(train_loss)), train_loss, label='accuracy')\nplt.plot(range(len(val_loss)), val_loss, label='val_accuracy')\nplt.xlabel('epoch', fontsize=16)\nplt.ylabel('accuracy', fontsize=16)\nplt.legend(fontsize=16)\nplt.show()","ea6d9808":"# Loading best model\nmodel = load_model('cnn_model_01.h5')\n\n# Best model accuracy and loss\nevaluation = model.evaluate(X_Test, y_test)\nprint('test_loss:%.3f' % evaluation[0])\nprint('test_accuracy:%.3f' % evaluation[1])","69c7d8de":"# predict label\ny_pred = model.predict_classes(X_Test)\n\n# Confusion matrix\ncnf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n\n# Visualization\nfig, ax = plt.subplots(figsize=(6, 6))\nax.matshow(cnf_matrix, cmap=plt.cm.Blues, alpha=0.3)\nfor i in range(cnf_matrix.shape[0]): \n    for j in range(cnf_matrix.shape[1]): \n        ax.text(x=j, y=i, s=cnf_matrix[i,j], va='center', ha='center')\nplt.xlabel(\"predicted label\")\nplt.ylabel(\"true label\")\nplt.show()","807feb36":"print(\"accuracy = %.3f\" % accuracy_score(y_true=y_test, y_pred=y_pred))\nprint(\"precision = %.3f\" % precision_score(y_true=y_test, y_pred=y_pred))\nprint(\"recall = %.3f\" % recall_score(y_true=y_test, y_pred=y_pred))\nprint(\"f1_score = %.3f\" % f1_score(y_true=y_test, y_pred=y_pred))","ad7af9f7":"I tried to study, Chest Xray pneumonia with CNN.","084b67c0":"### image data check","0610becb":"## dataset loading & create dataframe","10e4b614":"## Evaluation training","8092f457":"Combine list data","49a28d82":"# Preprocessing","ae269b08":"# Test data prediction","622b6827":"Image data loading, This time, I decide the data size=64\u00d764.","04c5dc94":"## Fitting model","2af15940":"## Difinition CNN model","987d06a4":"# Chest Xray pneumonia, study with CNN"}}