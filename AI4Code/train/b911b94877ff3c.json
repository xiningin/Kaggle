{"cell_type":{"6135634c":"code","a6f2b268":"code","803645f9":"code","b9afa691":"code","1cb4b328":"code","3d7a9dd7":"code","8e72ae05":"code","747b4b69":"code","39512f48":"code","bb3107c2":"code","8885c950":"code","c69040d7":"code","a2d76d27":"code","6c007263":"code","33a32e03":"code","3be026a1":"code","4a1e0e9e":"code","36fd849d":"code","844f7657":"code","017dec3f":"markdown"},"source":{"6135634c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\"\"\"\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a6f2b268":"import cv2                 \nimport numpy as np         \nimport os                  \nfrom random import shuffle\nimport tensorflow as tf \nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob as gb\nfrom tensorflow.keras.utils import to_categorical","803645f9":"#read DataSet\ntrain_image=\"\/kaggle\/input\/chest-xray-covid19-pneumonia\/Data\/train\/\"\ntest_image=\"\/kaggle\/input\/chest-xray-covid19-pneumonia\/Data\/test\/\"","b9afa691":"print(train_image)\nprint(test_image)","1cb4b328":"#to get all image names in train file\npneumona_images = os.listdir(train_image + \"\/PNEUMONIA\")\nnormal_images = os.listdir(train_image + \"\/NORMAL\")\ncovid_images = os.listdir(train_image + \"\/COVID19\")","3d7a9dd7":"#plot to show the size of some image\n#plot PNEUMONIA\nplt.figure(figsize=(20,10))\nfor i in range(6):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(plt.imread(os.path.join(train_image + \"\/PNEUMONIA\",pneumona_images[i])),cmap='gray')\n    plt.title(\"PNEUMONIA\")\n    \nplt.show()\n#plot NORMAL\nplt.figure(figsize=(20,10))\nfor i in range(6):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(plt.imread(os.path.join(train_image + \"\/NORMAL\",normal_images[i])),cmap='gray')\n    plt.title(\"NORMAL\")\n\nplt.show()\n#plot \nplt.figure(figsize=(20,10))\nfor i in range(6):\n    plt.subplot(3, 3, i + 1)\n    plt.imshow(plt.imread(os.path.join(train_image + \"\/COVID19\",covid_images[i])),cmap='gray')\n    plt.title(\"COVID19\")","8e72ae05":"train_datagen = ImageDataGenerator(\n      horizontal_flip=True,\n      rotation_range=10,\n      zoom_range=0.4)\n\ntrain_generator =train_datagen.flow_from_directory(\n     train_image,\n     batch_size= 256,\n     shuffle=shuffle,\n     target_size=(256, 256))\n\ntest_generator =train_datagen.flow_from_directory(\n     test_image,\n     batch_size= 50,\n     shuffle=shuffle,\n     target_size=(256, 256)) ","747b4b69":"train_shape=train_generator.__getitem__(0)[0].shape\ntest_shape=test_generator.__getitem__(0)[0].shape\n#Shape of Data\nprint(\"Train Shape \\n\",train_shape)\nprint(\"Test Shape \\n\",test_shape)","39512f48":"Labels={'NORMAL':0,'PNEUMONIA':1,'COVID19':2}\n\n# convert label to code\ndef getCode(label):\n    return Labels[label]\n\n\n# convert code to label \ndef getLabel(n):\n    for x,c in Labels.items():\n        if n==c:\n            return x   \n        \n#Test        \nprint(getCode('COVID19'))\nprint(getLabel(1))","bb3107c2":"#Reading image data\nimport glob as gb\nimport cv2  \nsize_image=256 # to resize the all image as same size\n\n#to read all images from directory\ndef getData(Dir,size_image):\n    X=[]\n    y=[]\n    for folder in  os.listdir(Dir) : #to get the file name \n        files = gb.glob(pathname= str( Dir  +\"\/\" +folder+ '\/\/*.jpg' )) # to get the images\n        for file in files:\n                picture=cv2.imread(file) #  or plt.imread(file)\n                imageArray=cv2.resize(picture,(size_image,size_image))\n                X.append(list(imageArray))\n                y.append(getCode(folder))\n    X=np.array(X)\n    y=np.array(y)\n    return X,y","8885c950":"#get train data\nX_train, y_train = getData(train_image,size_image)\n# get test data\nX_test , y_test = getData(test_image,size_image)","c69040d7":"print(\"X_train Shape        \",X_train.shape)\nprint(\"X_test Shape         \",X_test.shape)","a2d76d27":"# #Convert y_train to categorical\ny_train=to_categorical(y_train,3)\nprint(\"y_train \",y_train.shape)\n\n#Convert y_train to categorical\ny_test=to_categorical(y_test,3)\nprint(\"y_test \",y_test.shape)","6c007263":"from tensorflow.keras import Model\nfrom tensorflow.keras.layers import LeakyReLU #, Dense, Dropout, Flatten\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score","33a32e03":"def disease_prediction_model(pre_trained_model,file_name):\n    for layer in pre_trained_model.layers:\n        layer.trainable = False  #to make the layers to Freeze Weights\n    pre_trained_model.summary()\n    \n    \n    \"\"\"\n    model = Sequential()\n    model.add(Flatten(pre_trained_model.output))\n    #Full Connected Layers\n    model.add(Dense(512))\n    model.add(LeakyReLU(alpha=0.1))\n    #Add dropout to avoid Overfit\n    model.add(Dropout(0.2))\n    model.add(Dense(256))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dense(128))\n    model.add(LeakyReLU(alpha=0.1))\n    \n    #Add dropout to avoid Overfit\n    model.add(Dropout(0.4))\n    model.add(Dense(64))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dense(3, activation='softmax'))\n    #x=tf.keras.layers.Dense(3 , activation='softmax')(x) # Softmax\n\n    \"\"\"\n    \n    x = tf.keras.layers.Flatten()(pre_trained_model.output)\n\n    #Full Connected Layers\n    x = tf.keras.layers.Dense(512, activation=LeakyReLU(alpha=0.01))(x)\n    #Add dropout to avoid Overfit\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = tf.keras.layers.Dense(256, activation=LeakyReLU(alpha=0.01))(x) # Leaky ReLu\n    x = tf.keras.layers.Dense(128, activation=LeakyReLU(alpha=0.01))(x) # Leaky ReLu\n    #Add dropout to avoid Overfit\n    x = tf.keras.layers.Dropout(0.4)(x)\n    x = tf.keras.layers.Dense(64, activation=LeakyReLU(alpha=0.01))(x) # Leaky ReLu\n\n\n    x=tf.keras.layers.Dense(3 , activation='softmax')(x) # Softmax\n    \n    model = Model( pre_trained_model.input, x) \n\n    print(model.summary())\n    model.compile(optimizer='adam', loss=\"categorical_crossentropy\",metrics=['accuracy'])\n    \n    epochs = 30\n    history = model.fit_generator(train_generator, steps_per_epoch=2, epochs=epochs)\n    \n    plt.plot(history.history['accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train'], loc='upper left')\n    plt.show()\n    \n    #Evaluate Model\n    model.evaluate(test_generator)\n\n    model.save(file_name+\".h5\")\n\n    #prediction\n    pred=model.predict(test_generator)\n    print(len(pred))\n\n    y_test=[]\n    for i in range(26):\n        y_test.extend(test_generator.__getitem__(i)[1])\n        \n    print(len(y_test))\n    y_test=np.array(y_test)\n\n    y_test=np.argmax(y_test,axis=1)\n    pred= np.argmax(pred,axis=1)\n\n    print(\"pred \\n\",len(pred))\n    print(\"y_test \\n\",len(y_test))\n    \n    print(\"y_test \\n\",y_test)\n    print(\"predicted \\n\",pred)\n    \n    cm=confusion_matrix(pred,y_test)\n    print(cm)\n    \n    \"\"\"\n    plt.figure(figsize=(20,10))\n    for i in range(0,9):\n\n        plt.subplot(3, 3, i + 1)\n\n        plt.imshow(test_generator.__getitem__(0)[0][i],cmap='gray')\n        plt.title(f\"   Real: {getLabel(y_test[i])   } Vs  Predict: {getLabel(pred[i])}\")\n\n    \"\"\"\n    \n    precision = precision_score(y_test,pred, average=\"weighted\")\n    print('Precision: %f' % precision)\n    recall = recall_score(y_test,pred,average=\"weighted\")\n    print('Recall: %f' % recall)\n    f1 = f1_score(y_test,pred,average=\"weighted\")\n    print('F1 score: %f' % f1)\n    \n    pass","3be026a1":"from tensorflow.keras.applications import InceptionV3 as InceptionV3\nfrom tensorflow.keras.applications import Xception as Xception\nfrom tensorflow.keras.applications import ResNet50 as ResNet","4a1e0e9e":"pre_trained_model = InceptionV3(\n    include_top=False, weights='imagenet', input_tensor=None,\n    input_shape=(size_image,size_image,3), pooling=None, classes=3,\n    classifier_activation='softmax'\n)\n\ndisease_prediction_model(pre_trained_model,'Covid19-inception')","36fd849d":"pre_trained_model = Xception(\n    include_top=False, weights='imagenet', input_tensor=None,\n    input_shape=(size_image,size_image,3), pooling=None, classes=3,\n    classifier_activation='softmax'\n)\n\ndisease_prediction_model(pre_trained_model,'covid19-xception')","844f7657":"pre_trained_model = ResNet(\n    include_top=False, weights='imagenet', input_tensor=None,\n    input_shape=(size_image,size_image,3), pooling=None, classes=3,\n    classifier_activation='softmax'\n)\n\ndisease_prediction_model(pre_trained_model,'covid19-resnet')","017dec3f":"# Generalized Model "}}