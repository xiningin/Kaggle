{"cell_type":{"1b3f0e51":"code","8e3c4d18":"code","9da3d980":"code","52e78b17":"code","4fbe4bb9":"code","1fb7d78a":"code","e359b8bb":"code","21ab65dd":"code","18a295e8":"code","919259ea":"code","186139cc":"code","9617f033":"code","38dd44d0":"code","055547d7":"code","6d2d4352":"code","747c6493":"code","30b0d616":"code","75591cc9":"code","2374761d":"code","ccda667d":"code","8e90cf3d":"code","2cdba9f5":"code","a7678c01":"code","55e84d05":"code","fbbdc6cc":"code","1c49f76d":"code","9c22a13f":"code","941b1dde":"code","ccf08f17":"code","b24fbbc9":"code","5ae8508f":"code","d622fc0d":"code","08eb14dd":"code","1453e626":"code","90793648":"code","5948a5be":"code","13df5df1":"code","27853c12":"code","2dc8e0e9":"code","c0a836bc":"code","eca0a4db":"code","947f96be":"markdown","36ed42e4":"markdown","5d7096c4":"markdown","898f3523":"markdown","788a150d":"markdown","f41a38f2":"markdown","c87b5b6f":"markdown","0bcaeb24":"markdown","4ee26cc5":"markdown","2e725b1d":"markdown","405b8fea":"markdown","769e5fb8":"markdown","2e1d4ac8":"markdown","a21fc619":"markdown","fcd35b55":"markdown","91cfe201":"markdown","31c5285a":"markdown","709e3552":"markdown","15b85480":"markdown","140e5d83":"markdown","806d5647":"markdown","67508431":"markdown","aad632c8":"markdown","907ff737":"markdown","0b2dc589":"markdown","6851a30b":"markdown","3b8d0031":"markdown","4a908c2d":"markdown","9b8088a0":"markdown","6ab434c8":"markdown","6b0a521e":"markdown","f0e1c593":"markdown","86e7903f":"markdown","a3679d12":"markdown","b2c0a784":"markdown","3861f972":"markdown","8b92883a":"markdown","9ba6d4eb":"markdown","f0b65610":"markdown","a9eebbb9":"markdown","be408ef1":"markdown","e71a70ba":"markdown","40179786":"markdown","f583d716":"markdown","1f75743c":"markdown"},"source":{"1b3f0e51":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport matplotlib.ticker as ticker\nfrom matplotlib.ticker import FormatStrFormatter\n\n\nsns.set_theme(style=\"whitegrid\")","8e3c4d18":"# Getting urls from drive\ntest_url='https:\/\/drive.google.com\/file\/d\/1voPMZ-66QbUHHO6XR53TCan6emWFPfBB\/view?usp=sharing'\ntest_url2='https:\/\/drive.google.com\/uc?id=' + test_url.split('\/')[-2]\n\nshops_url = 'https:\/\/drive.google.com\/file\/d\/1L_vHYXH_JPqB5cwvDD0tyb7XBSLYy_IZ\/view?usp=sharing'\nshops_url2='https:\/\/drive.google.com\/uc?id=' + shops_url.split('\/')[-2]\n\ntrain_url = 'https:\/\/drive.google.com\/file\/d\/1yIpuw-YaV2i0zq86hFjoe_xnv33dNH6e\/view?usp=sharing'\ntrain_url2='https:\/\/drive.google.com\/uc?id=' + train_url.split('\/')[-2]\n\nitems = 'https:\/\/drive.google.com\/file\/d\/1VgEsLxOJoa7LK8VWkCFmvbwVtDo1awPg\/view?usp=sharing'\nitems2='https:\/\/drive.google.com\/uc?id=' + items.split('\/')[-2]\n\nitem_categories_url = 'https:\/\/drive.google.com\/file\/d\/10d0c83jQBp3IlW6inlH6IkiUKV4wEf3_\/view?usp=sharing'\nitem_categories_url2='https:\/\/drive.google.com\/uc?id=' + item_categories_url.split('\/')[-2]\n\n# Reading csv files\ntest = pd.read_csv(test_url2)\ntrain = pd.read_csv(train_url2)\nshops = pd.read_csv(shops_url2)\nitems = pd.read_csv(items2)\nitem_categories = pd.read_csv(item_categories_url2)","9da3d980":"dfs = {'Test': test, 'Train': train, 'Shops': shops, 'Items': items, 'Item_Categories': item_categories} # Dict of dataframes","52e78b17":"for k, v in dfs.items():\n    print(k)\n    display(v.head(5))","4fbe4bb9":"for k, v in dfs.items():\n    print('\\n', k)\n    display(v.isnull().sum())","1fb7d78a":"for k, v in dfs.items():\n    print('\\n', k)\n    dtypes = v.dtypes\n    display(dtypes)","e359b8bb":"for k, v in dfs.items():\n    print('\\n', k)\n    display(v.nunique())","21ab65dd":"categories_c1 = items.groupby(['item_id']).agg({'item_category_id' : 'count'})\ncategories_c1[categories_c1['item_category_id'] > 1]","18a295e8":"#Getting the price for each\nitem_prices = pd.merge(items['item_id'], train[['item_id', 'shop_id', 'item_price']], on='item_id')\n\n# This query groups the item_id by shops and tell us how many different prices has had this item on the respective shop.\nitem_prices_count_distinct_prices = item_prices.groupby(['item_id', 'shop_id']).agg({'item_price' : 'nunique'})\n\n# Is there more than one price for any item on the same shop?\nprint('There is multiple prices for the same item and same shop') if any(item_prices_count_distinct_prices['item_price'] > 1) else print('You are safe')\n\ndisplay(item_prices_count_distinct_prices)","919259ea":"most_changes_inprice_item_id = (item_prices_count_distinct_prices['item_price'].idxmax())[0]\nmost_changes_inprice_shop_id = (item_prices_count_distinct_prices['item_price'].idxmax())[1]\n\nprint('Prices historial for item:', most_changes_inprice_item_id, 'and shop:', most_changes_inprice_shop_id)\ndisplay(train[ (train['item_id'] == most_changes_inprice_item_id) & (train['shop_id'] == most_changes_inprice_shop_id) ][['date', 'item_price']])","186139cc":"train_items = pd.merge(train, items, how='inner', on='item_id')\ntrain_complete1 = pd.merge(train_items, item_categories, how='inner', on='item_category_id')\ntrain_complete = train_complete1.drop(columns=['item_name', 'item_category_name']) # All merged in this variable. We don't need names for analysis\n\ndisplay(train_complete)","9617f033":"train_complete['date'] = pd.to_datetime(train_complete['date']) # Change date column to pandas date time\ntrain_complete","38dd44d0":"top_items = train_complete.groupby(['item_id'], as_index = False).agg({'item_cnt_day': 'sum', 'item_price' : 'mean'})\ntop_items['total_sales'] = top_items['item_price'] * top_items['item_cnt_day'] # Adding total sales: item sold * item price\n\nsortby_nitems = top_items.sort_values(by = ['item_cnt_day'], ascending = False).head(10) # Order by number of items sold\nsortby_price = top_items.sort_values(by = ['total_sales'], ascending = False).head(10) # Order by total sales (item sold * item price)\n\nfig, ax = plt.subplots(2, figsize = (30, 30))\n\ng_nitems = sns.barplot(\n    data = sortby_nitems,\n    x = 'item_id',\n    y = 'item_cnt_day',\n    label='Total items sold',\n    ax=ax[0])\n\nax[0].set_xlabel('Item', fontsize=25)\nax[0].set_ylabel('Total sold (number of items)', fontsize=25)\nax[0].set_title('Top 10 items sold', fontsize = 40)\nax[0].set_yticks(np.linspace(0, sortby_nitems['item_cnt_day'].max(), 20))\nax[0].tick_params(axis='x', labelsize=20)\nax[0].tick_params(axis='y', labelsize=20)\n\n\n\ng_price = sns.barplot(\n    data = sortby_price,\n    x = 'item_id',\n    y = 'total_sales',\n    label='Total items sold',\n    ax=ax[1])\n\nax[1].set_xlabel('Item', fontsize=25)\nax[1].set_ylabel('Total sales', fontsize=25)\nax[1].set_title('Top 10 items sold by sales', fontsize = 40)\nax[1].set_yticks(np.linspace(0, sortby_price['total_sales'].max(), 20))\nax[1].tick_params(axis='x', labelsize=20)\nax[1].tick_params(axis='y', labelsize=20)\n\n\nplt.tight_layout()\nplt.show()\nplt.close()","055547d7":"top_categories = train_complete.groupby(['item_category_id'], as_index = False).agg({'item_cnt_day' : 'sum', 'item_price' : 'mean'})\ntop_categories['total_sales'] = top_categories['item_price'] * top_categories['item_cnt_day'] # Adding total sales: item sold * item price\n\nsortby_ncategories = top_categories.sort_values(by = ['item_cnt_day'], ascending = False).reset_index(drop=True).head(10) # Order by number of items sold\nsortby_price_cat = top_categories.sort_values(by = ['total_sales'], ascending = False).reset_index(drop=True).head(10) # Order by total sales (item sold * item price)\n\nfig, ax = plt.subplots(2, figsize = (30, 30))\n\ng_nitems = sns.barplot(\n    data = sortby_ncategories,\n    x = 'item_category_id',\n    y = 'item_cnt_day',\n    label = 'Total items sold',\n    ax = ax[0])\n\nax[0].set_xlabel('Item', fontsize=25)\nax[0].set_ylabel('Total sold (number of items)', fontsize=25)\nax[0].set_title('Top 10 items sold', fontsize = 40)\nax[0].set_yticks(np.linspace(0, sortby_ncategories['item_cnt_day'].max(), 20))\nax[0].tick_params(axis='x', labelsize=20)\nax[0].tick_params(axis='y', labelsize=20)\n\n\ng_price = sns.barplot(\n    data = sortby_price_cat,\n    x = 'item_category_id',\n    y = 'total_sales',\n    label='Total items sold',\n    ax = ax[1])\n\nax[1].set_xlabel('Item', fontsize=25)\nax[1].set_ylabel('Total sales', fontsize=25)\nax[1].set_title('Top 10 items sold by sales', fontsize = 40)\nax[1].set_yticks(np.linspace(0, sortby_price_cat['total_sales'].max(), 20))\nax[1].tick_params(axis='x', labelsize=20)\nax[1].tick_params(axis='y', labelsize=20)\n\n\nplt.tight_layout()\nplt.show()\nplt.close()\n\ndisplay(sortby_ncategories.head(10))","6d2d4352":"categories_item = train_complete.groupby(['item_category_id'], as_index = False).item_id.nunique()\n\nfig, ax = plt.subplots(figsize = (30, 50))\n\nax = sns.barplot(\n    data = categories_item,\n    x = 'item_category_id',\n    y = 'item_id')\n\nax.set_xlabel('Category', fontsize=25)\nax.set_ylabel('Total items', fontsize=25)\nax.set_title('Items per category', fontsize = 40)\nax.set_yticks(np.linspace(0, categories_item['item_id'].max(), 20))\nax.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n\nplt.show()\nplt.close()","747c6493":"categories_shop = train_complete.groupby(['shop_id'], as_index = False).item_category_id.nunique()\n\nfig, ax = plt.subplots(figsize = (30, 10))\n\nax = sns.barplot(\n    data = categories_shop,\n    x = 'shop_id',\n    y = 'item_category_id')\n\nax.set_xlabel('Shop', fontsize=25)\nax.set_ylabel('Total categories', fontsize=25)\nax.set_title('Categories per shop', fontsize = 40)\nax.set_yticks(np.linspace(0, categories_shop['item_category_id'].max(), 20))\nax.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\nax.tick_params(axis='x', labelsize=20)\nax.tick_params(axis='y', labelsize=20)\n\nplt.show()\nplt.close()\n","30b0d616":"shop_total_sold = train_complete.groupby('shop_id', as_index=False).agg({'item_cnt_day': 'sum'})\n\nshop_total_item = train_complete.groupby('shop_id', as_index=False).agg({'item_id': 'count'})\n\nfig, ax = plt.subplots(figsize = (30, 10))\n\nax = sns.barplot(\n    data = shop_total_sold,\n    x = 'shop_id',\n    y = 'item_cnt_day',\n    label='Total items sold',\n    color = 'yellowgreen')\n\nax = sns.barplot(\n    data = shop_total_item,\n    x = 'shop_id',\n    y = 'item_id',\n    color = 'salmon',\n    label = 'Total diffrent items',)\n\nax.set_xlabel('Shop', fontsize=25)\nax.set_ylabel('Total sold (number of items)', fontsize=25)\nax.set_title('Items sold per shop', fontsize = 40)\nax.set_yticks(np.linspace(0, shop_total_sold['item_cnt_day'].max(), 20))\nax.tick_params(axis='x', labelsize=20)\nax.tick_params(axis='y', labelsize=20)\n\nplt.legend()\n\nplt.setp(ax.get_legend().get_texts(), fontsize='22')\nplt.setp(ax.get_legend().get_title(), fontsize='32')\n\nplt.show()\nplt.close()","75591cc9":"sells_year = train_complete.groupby(train_complete['date'].dt.year).agg({'item_cnt_day': 'sum'}).reset_index()\n\nfig, ax = plt.subplots(figsize = (20, 10))\n\nax = sns.barplot(\n    data = sells_year,\n    x = 'date',\n    y = 'item_cnt_day'\n)\n\nax.set_xlabel('Year', fontsize=25)\nax.set_ylabel('Total sold (number of items)', fontsize=25)\nax.set_title('Items sold per year', fontsize = 40)\nax.tick_params(axis='x', labelsize=20)\nax.tick_params(axis='y', labelsize=20)\n\nplt.show()\nplt.close()","2374761d":"sells_month = train_complete.groupby([train_complete.date.dt.year.rename('year'), train_complete.date.dt.month.rename('month')]).agg({'item_cnt_day': 'sum'}).reset_index()\n\nsells_month['date'] = sells_month['month'].astype(str) + '-' +  sells_month['year'].astype(str)\nsells_month = sells_month.drop(['month', 'year'], axis = 1)\n\nfig, ax = plt.subplots(figsize = (30, 10))\n\nax = sns.barplot(\n    data = sells_month,\n    x = 'date',\n    y = 'item_cnt_day'\n)\n\nax.set_xlabel('Month', fontsize=25)\nax.set_ylabel('Total sold (number of items)', fontsize=25)\nax.set_title('Items sold per month', fontsize = 40)\nax.tick_params(axis='x', labelsize=20, rotation = 40)\nax.tick_params(axis='y', labelsize=20)\n\nplt.show()\nplt.close()","ccda667d":"def draw_it(data, x, y, xlabel, title, col):\n    \"\"\"\n    This function draws a the lineplot of 'data'\n    \"\"\"\n    fig, ax = plt.subplots(figsize = (30, 50))\n\n    ax = sns.lineplot(\n        data=data,\n        palette='tab10',\n        x = x,\n        y = y,\n        hue = col,\n        style = col,\n        linewidth=2.5)\n\n    ax.set_xlabel(xlabel, fontsize=25)\n    ax.set_ylabel('Total sold (number of items)', fontsize=25)\n    ax.set_title(title, fontsize = 40)\n    ax.set_xticks(data[x].values)\n    ax.tick_params(axis='x', labelsize=20)\n    ax.tick_params(axis='y', labelsize=20)\n\n    plt.setp(ax.get_legend().get_texts(), fontsize='22')\n    plt.setp(ax.get_legend().get_title(), fontsize='32')\n\n    fig.tight_layout()\n    plt.show()\n    plt.close()","8e90cf3d":"def fill_empty_dates(olddf, col, dates):\n    \"\"\"\n    Return a new df where all 'uniques' values got a 0 in 'item_cnt_day' for all missing 'date_block_num' rows\n    \"\"\"\n    newdf = olddf.copy()\n    for date in newdf[dates].unique():\n        for element in newdf[col].unique():\n            if not(((newdf[dates] == date) & (newdf[col] == element)).any()):\n                new_row = {dates:date, col:element, 'item_cnt_day':0}\n                newdf = newdf.append(new_row, ignore_index=True)\n    return newdf","2cdba9f5":"items_sold_month = train_complete.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_day': 'sum'}).reset_index()\ndisplay(items_sold_month.head(10))\n\ndraw_it(items_sold_month, 'date_block_num', 'item_cnt_day', 'Month', 'Items sold per month by shop', 'shop_id')","a7678c01":"items_sold_month_2 = fill_empty_dates(items_sold_month, 'shop_id', 'date_block_num')","55e84d05":"draw_it(items_sold_month_2, 'date_block_num', 'item_cnt_day', 'Month', 'Items sold per month by shop', 'shop_id')","fbbdc6cc":"items_sold_year = train_complete.groupby([train_complete['date'].dt.year, 'shop_id']).agg({'item_cnt_day': 'sum'}).reset_index()\ndisplay(items_sold_year.head(10))\n\ndraw_it(items_sold_year, 'date', 'item_cnt_day', 'Year', 'Items sold per year by shop', 'shop_id')","1c49f76d":"items_sold_year_2 = fill_empty_dates(items_sold_year, 'shop_id', 'date')","9c22a13f":"draw_it(items_sold_year_2, 'date', 'item_cnt_day', 'Year', 'Items sold per year by shop', 'shop_id')","941b1dde":"items_sold_month_category = train_complete.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_day': 'sum'}).reset_index()\ndisplay(items_sold_month_category)\n\ndraw_it(items_sold_month_category, 'date_block_num', 'item_cnt_day', 'Month', 'Items sold per month by category', 'item_category_id')\n","ccf08f17":"items_sold_month_category2 = fill_empty_dates(items_sold_month_category, 'item_category_id', 'date_block_num')\n\nitems_sold_month_category2.head(10)","b24fbbc9":"draw_it(items_sold_month_category2, 'date_block_num', 'item_cnt_day', 'Month', 'Items sold per month by category', 'item_category_id')","5ae8508f":"items_sold_year_category = train_complete.groupby([train_complete['date'].dt.year, 'item_category_id']).agg({'item_cnt_day': 'sum'}).reset_index()\ndisplay(items_sold_year_category.head(10))\n\ndraw_it(items_sold_year_category, 'date', 'item_cnt_day', 'Year', 'Items sold per year by category', 'item_category_id')","d622fc0d":"items_sold_year_category2 = fill_empty_dates(items_sold_year_category, 'item_category_id', 'date')\nitems_sold_year_category2.head(10)","08eb14dd":"draw_it(items_sold_year_category2, 'date', 'item_cnt_day', 'Year', 'Items sold per year by category', 'item_category_id')","1453e626":"items_sold_month_total = train_complete.groupby(['date_block_num', 'item_id']).agg({'item_cnt_day': 'sum'}).sort_values(by=['item_cnt_day'], ascending=False).reset_index()\n\nitems_sold_month_total_10 = pd.merge(sortby_nitems[['item_id']], items_sold_month_total[['item_id', 'item_cnt_day','date_block_num']], how = 'left', on = 'item_id')\ndisplay(items_sold_month_total_10)\n\ndraw_it(items_sold_month_total_10, 'date_block_num', 'item_cnt_day', 'Month', 'Total number of items sold per month ', 'item_id')","90793648":"items_sold_month_total_2 = fill_empty_dates(items_sold_month_total_10, 'item_id', 'date_block_num')\nitems_sold_month_total_2.head(10)","5948a5be":"draw_it(items_sold_month_total_2, 'date_block_num', 'item_cnt_day', 'Month', 'Total number of items sold per month ', 'item_id')","13df5df1":"items_sold_year_total = train_complete.groupby([train_complete['date'].dt.year, 'item_id']).agg({'item_cnt_day': 'sum'}).sort_values(by=['item_cnt_day'], ascending=False).reset_index()\n\nitems_sold_year_total_10 = pd.merge(sortby_nitems[['item_id']], items_sold_year_total[['item_id', 'item_cnt_day','date']], how = 'left', on = 'item_id')\ndisplay(items_sold_year_total_10)\n\ndraw_it(items_sold_year_total_10, 'date', 'item_cnt_day', 'Year', 'Total number of items sold per year ', 'item_id')","27853c12":"items_sold_year_total_2 = fill_empty_dates(items_sold_year_total_10, 'item_id', 'date')\nitems_sold_year_total_2","2dc8e0e9":"draw_it(items_sold_year_total_2, 'date', 'item_cnt_day', 'Year', 'Total number of items sold per year ', 'item_id')","c0a836bc":"train_copy = train.copy()\n\n# Getting the mean month price for every item on every shop\nmean_price_month = train_copy.groupby(['shop_id', 'item_id', 'date_block_num']).agg({'item_price':'mean'}).reset_index()\nmean_price_month = mean_price_month.rename(columns={'item_price': 'Mean_month'})\nprint('Mean month price per item and shop for every month')\ndisplay(mean_price_month)\n\ntotal_mean_price = mean_price_month.groupby(['shop_id', 'item_id']).agg({'Mean_month':'mean'}).reset_index()\nprint('Mean month price per item and shop for all months')\ndisplay(total_mean_price)\n\n# Same example as in previous section\ndf1 = mean_price_month[(mean_price_month['shop_id'] == 12) & (mean_price_month['item_id'] == 11373)]\n\ndisplay(df1)\n\nsns.lineplot(\n        data=df1,\n        palette='tab10',\n        x = 'date_block_num',\n        y = 'Mean_month',\n        linewidth=2.5).set_title('Item 11373 | Shop 12')\n\nplt.show()","eca0a4db":"test['date_block_num'] = 34\ntest = pd.merge(test, total_mean_price[['shop_id', 'item_id', 'Mean_month']], on=['shop_id', 'item_id'], how='left')\ntest = test.rename(columns={'Mean_month': 'item_price'})\ntest = test.fillna(test.mean())\ntest","947f96be":"Building two new columns on test dataframe where 'date_block_month' = 34 and 'item_price' = total_mean_price['Mean_month'].\n\nIn case of NaN values we fill it with the mean value of every item","36ed42e4":"### Prices prediction","5d7096c4":"### Basic information:\n- NaN values\n- Types\n- Unique values","898f3523":"We can observe this item has too many differente prices in the same shop.\n\nThis means we have **to make a regression model over the prices to predict the price every item will have in the month block '34'** and then we'll create **another model to predict the amount of items the shops will sell on that monht block**","788a150d":"#### Top 10 categories sold | by total items & price","f41a38f2":"Let's do the same with unexisted values for some years","c87b5b6f":"##### By year","0bcaeb24":"#### Preprocessing datasets\n\nFirst of all we need to predict the prices for the products the \"month block\" 34. We'll be doing these steps:\n\n- Calculate the month mean price of every item for every shop\n- Predict the (item & shop) mean price for the month block '34' by mean of all previous prices","4ee26cc5":"#### Train processing & split","2e725b1d":"Modifying date type to datetime","405b8fea":"No :).","769e5fb8":"#### Top 10 items sold | by total items & price","2e1d4ac8":"Filling empty values","a21fc619":"##### By year","fcd35b55":"Filling missed values","91cfe201":"Does any item has more than one category?","31c5285a":"Unique values:","709e3552":"Yes :(. Let's check for example the diferent prices that the item with most changes has had over these past years:","15b85480":"##### By month","140e5d83":"Imports","806d5647":"Does any item has more than one price?","67508431":"Now, let's build our regression model to predict 'item_cnt_day'","aad632c8":"#### Items sold per shop | Month & Year","907ff737":"#### Top 10 items sold | Month & Year","0b2dc589":"Filling missing values","6851a30b":"Let's complete the dataframe with unexisted values","3b8d0031":"#### Total sales per year & month","4a908c2d":"### Dataset visualization","9b8088a0":"Checking data types","6ab434c8":"There is a lot of shops that didn't have any values for some months. Let's fill out these rows with '0' items sold:","6b0a521e":"Checking NaN values","f0e1c593":"## <center> Datasets analysis: <center>","86e7903f":"#### Number of items per category","a3679d12":"#### Items sold per category | Month & Year","b2c0a784":"##### For the next sections these function will be used:","3861f972":"#### Number of categories per shop","8b92883a":"# <center> Sales prediction<\/center>\n---\n","9ba6d4eb":"### Sales prediction\n\nTo make predictions over the next month on every item we need to calculate first the mean month price for every item and shop and add this new column to the train dataset.\n\nWe'll train our model with:\n- item_id and shop_id as keys\n- The independient variables will be date_block_num and item_price\n- The dependient variable will be item_cnt_day","f0b65610":"Loading datasets","a9eebbb9":"##### By month","be408ef1":"##### By month","e71a70ba":"#### Total items & Total sales | By Shop","40179786":"##### By year","f583d716":"## <center> Predictions <center>\n---","1f75743c":"### Merging datasets:\n\nThese datasets contain all the information in separated tables. Let's merge them and create new complex dataset"}}