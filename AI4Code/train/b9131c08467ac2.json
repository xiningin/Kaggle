{"cell_type":{"8f4872cb":"code","2611c348":"code","a048d7df":"code","edb86254":"code","9f11c9f4":"code","4f70b29a":"code","8bf0156a":"code","c6e96837":"code","0b797db2":"markdown","019f64f2":"markdown","adf53206":"markdown","de09dc0f":"markdown","7ebdd544":"markdown","b4d08b5a":"markdown","0db4b35f":"markdown","cdf1cb40":"markdown","0a4430d8":"markdown","ba15e8eb":"markdown"},"source":{"8f4872cb":"import pandas as pd\nimport numpy as np\nimport cv2\nimport glob\nimport matplotlib.pyplot as plt\nimport PIL\nfrom PIL import Image\nimport os\nfrom os import listdir\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(os.path.join(dirname))","2611c348":"data_dir = \"..\/input\/captcha-version-2-images\/samples\/\"\n\ndef getDes(Im, tool):\n    if tool == 'BRISK':\n        source = cv2.BRISK_create()\n        print(\"BRISK Mode..\")\n    elif tool == 'SIFT':\n        source = cv2.SIFT_create()\n        print(\"SIFT Mode..\")\n    elif tool == 'KAZE':\n        source = cv2.KAZE_create()\n        print(\"KAZE Mode..\")\n    else:\n        print(\"Select a Mode!!\")\n\n    if Im.endswith('.png'):\n        img = cv2.imread(os.path.join(data_dir + Im ))\n        kp, des = source.detectAndCompute(img, None)\n        imgKP = cv2.drawKeypoints(img, kp, None, color=(0,255,0), flags=0)\n        \n        plt.figure(figsize=(10, 10))\n        plt.axis('off')\n        plt.imshow(imgKP); plt.show()\n    return(des)","a048d7df":"getDes('25m6p.png', 'SIFT')","edb86254":"getDes('226md.png', 'BRISK')","9f11c9f4":"getDes('2g7nm.png', 'KAZE')","4f70b29a":"path = \"..\/input\/captcha-version-2-images\/samples\/\"","8bf0156a":"imgH = cv2.imread(os.path.join(path + '243mm.png'))\ngrayH = cv2.cvtColor(imgH,cv2.COLOR_BGR2GRAY)\ngrayH = np.float32(grayH)\ndst = cv2.cornerHarris(grayH,2,5,0.1)\ndst = cv2.dilate(dst,None, iterations=2)\nimgH[dst>0.01*dst.max()]=[0,255,0]\n\nplt.figure(figsize=(15, 15))\nplt.axis('off')\nplt.imshow(imgH); plt.show()","c6e96837":"imgG = cv2.imread(os.path.join(path + '25257.png'))\ngrayG = cv2.cvtColor(imgG,cv2.COLOR_BGR2GRAY)\ngrayG = np.float32(grayG)\ncorners = cv2.goodFeaturesToTrack(grayG,100, 0.01, 10)\ncorners = np.int0(corners)\nfor i in corners:\n    x,y = i.ravel()\n    cv2.circle(imgG,(x,y),1,255,0,-1)\n    \nplt.figure(figsize=(15, 15))\nplt.axis('off')\nplt.imshow(imgG); plt.show()","0b797db2":"<a id = \"2\"><\/a><br>\n**1) SIFT Feature Extraction**\n\nIn the [SIFT](https:\/\/people.eecs.berkeley.edu\/~malik\/cs294\/lowe-ijcv04.pdf) feature extraction algorithm, images invariant by translation, scaling, and rotation.\nSIFT consists of four major stages; scale-space detection, keypoint localization, orientation assignment and keypoint descriptor.","019f64f2":"\ud83d\udccc <font color = 'red'>\nContent: \n\n1. [Feature Extraction](#1)\n    * [SIFT](#2)\n    * [BRISK](#3)\n    * [KAZE](#4)\n1. [Corner Detection](#5)\n    * [Harris Corner Detector](#6) \n    * [Shi-Tomasi Corner Detector](#7)  \n\n\n\n\n\n\nIn the character recognition system, **feature extraction** can be made after the preprocessing stage. The primary task of character recognition is to take an input and assign it correctly as one of the possible output classes. This process can be divided into two general stages: Feature selection and Classification. Feature selection is critical for the entire process as the classifier cannot recognize it from poorly selected features.\n\nThe main purpose of **feature extraction** is to extract the most relevant information from the original data. **Feature extraction** helps to get the best feature from these large data sets by selecting variables and combining them with properties, we kind of reduce the amount of data.","adf53206":"<a id = \"3\"><\/a><br>\n**2) BRISK Feature Extraction**\n\nThe BRISK algorithm includes three main modules: keypoint detection, keypoint annotation, and identifier matching. Initially, the scale area pyramid is created and the stable endpoints of sub-pixel sensitivity in the continuous scale space are extracted by the adaptive corner detection operator.\nThe BRISK algorithm detects feature points in the multi scale pyramid model to ensure descriptors with scale invariance. Method is slow and has a large memory requirement.","de09dc0f":"<a id = \"1\"><\/a><br>\n#  Feature Extraction ","7ebdd544":"<div style=\"color:white;\n           display:fill;\n           border-radius:3px;\n           background-color:#0BB718;\n           font-size:150%;\n           font-family:Cambria;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 5px;\n              color:white;\">If you find it useful, I will get a upvote :)\n<\/p>\n<\/div> ","b4d08b5a":"<a id = \"4\"><\/a><br>\n**3) KAZE Feature Extraction**\n\nThe main steps involved in the KAZE feature extraction algorithm are: Creating a nonlinear scaled space pyramid of the original image, determining key points using Hessian determinants and multidimensional derivatives in the nonlinear scale space and computing the orientation and descriptor vectors for all key points. By making blur in images locally adaptable to feature points, it reduces noise and simultaneously preserves the boundaries of regions in images.","0db4b35f":"<a id = \"5\"><\/a><br>\n# Corner Detection\n\n\n* The intersection of the two sides represents a point where the directions of these two sides change. Therefore, the slope of the image has a high variation that can be used to detect it.\n* Corners are regions where differences occur between intensity.","cdf1cb40":"<a id = \"6\"><\/a><br>\n**1. Harris Corner Detector**\n\n\n*cornerHarris*\n\n(img, blockSize, ksize, k)\n* img - Input image, it should be grayscale and float32 type.\n* blockSize - It is the size of neighbourhood considered for corner detection\n* ksize - Aperture parameter of Sobel derivative used.\n* k - Harris detector free parameter in the equation.","0a4430d8":"\n\n\ud83d\udccc **Thank you for reading!** ","ba15e8eb":"<a id = \"7\"><\/a><br>\n**2. Shi-Tomasi Corner Detector**\n\n*goodFeaturesToTrack*\n\n* If the difference of the two points is greater than the specified threshold value, that point is considered a corner."}}