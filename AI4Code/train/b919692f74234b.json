{"cell_type":{"bd6c5658":"code","c25c776e":"code","6065dc4b":"code","0f033631":"code","c4f7fdd7":"code","57e30527":"code","26c4c917":"code","b1db5151":"code","b54fd94a":"code","0550cf9b":"code","1c3a6e92":"code","5e422483":"code","f5ef89f1":"code","3b413cec":"code","195cd7a8":"code","f3b5fb4c":"code","e5e3c3fa":"code","2ed71815":"code","b386425b":"code","d8c293dd":"code","c3599f13":"code","0adac918":"markdown","7e973d5d":"markdown","f4b5309c":"markdown","44775763":"markdown","03e7263c":"markdown","4adfb2c4":"markdown","90be6063":"markdown","1728d333":"markdown","e60ccd53":"markdown","ff7dd408":"markdown"},"source":{"bd6c5658":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport librosa.display\nfrom librosa.feature import melspectrogram\nimport librosa\nimport random\nfrom tqdm import tqdm_notebook\nimport random\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","c25c776e":"# Train labels can be found in this CSV\ntrain_labels = pd.read_csv('..\/input\/lanl-earthquake-spectrogram-images\/training_labels.csv')\ntrain_labels.head()","6065dc4b":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(20, 10))\nimg1 = mpimg.imread('..\/input\/lanl-earthquake-spectrogram-images\/train_images_no_overlap\/train_images_v3\/train_0.png')\nimg2 = mpimg.imread('..\/input\/lanl-earthquake-spectrogram-images\/train_images_no_overlap\/train_images_v3\/train_100.png')\nimg3 = mpimg.imread('..\/input\/lanl-earthquake-spectrogram-images\/train_images_no_overlap\/train_images_v3\/train_200.png')\nimg4 = mpimg.imread('..\/input\/lanl-earthquake-spectrogram-images\/train_images_no_overlap\/train_images_v3\/train_300.png')\nimg5 = mpimg.imread('..\/input\/lanl-earthquake-spectrogram-images\/train_images_no_overlap\/train_images_v3\/train_400.png')\nax1.imshow(img1)\nax1.set_title('TTF - {:0.4f}'.format(train_labels.loc[train_labels['seg_id'] == 'train_0']['target'].values[0]), fontsize=25)\nax2.imshow(img2)\nax2.set_title('TTF - {:0.4f}'.format(train_labels.loc[train_labels['seg_id'] == 'train_100']['target'].values[0]), fontsize=25)\nax3.imshow(img3)\nax3.set_title('TTF - {:0.4f}'.format(train_labels.loc[train_labels['seg_id'] == 'train_200']['target'].values[0]), fontsize=25)\nax4.imshow(img4)\nax4.set_title('TTF - {:0.4f}'.format(train_labels.loc[train_labels['seg_id'] == 'train_300']['target'].values[0]), fontsize=25)\nax5.imshow(img5)\nax5.set_title('TTF - {:0.4f}'.format(train_labels.loc[train_labels['seg_id'] == 'train_400']['target'].values[0]), fontsize=25)\nax1.axis('off')\nax2.axis('off')\nax3.axis('off')\nax4.axis('off')\nax5.axis('off')\nplt.tight_layout()\nplt.show()","0f033631":"seg_00030f = pd.read_csv('..\/input\/LANL-Earthquake-Prediction\/test\/seg_00030f.csv')\ny = seg_00030f['acoustic_data'].astype('float').values","c4f7fdd7":"def plot_spectrogram(y, imgdir=None, imgname=None, plot=True, sr=10000, n_mels=1000, log_tf=True, vmin=-100, vmax=0):\n    # Let's make and display a mel-scaled power (energy-squared) spectrogram\n    #y = np.array([float(x) for x in df['acoustic_data'].values])\n    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=n_mels)\n\n    # Convert to log scale (dB). We'll use the peak power (max) as reference.\n    if log_tf:\n        S = librosa.power_to_db(S, ref=np.max)\n    \n    if plot:\n        # Make a new figure\n        plt.figure(figsize=(15,5))\n        plt.imshow(S)\n        # draw a color bar\n        plt.colorbar(format='%+02.0f dB')\n        # Make the figure layout compact\n        plt.tight_layout()\n        plt.axis('off')\n    if imgname is not None:\n        plt.imsave('{}\/{}.png'.format(imgdir, imgname), S)\n        plt.clf()\n        plt.close()\n    return","57e30527":"# Plot an example using this function.\nplot_spectrogram(y)","26c4c917":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n# I personally hate that fastai encourages using `import *`\n# That is how it is taught in the course\nfrom fastai import *\nfrom fastai.vision import *","b1db5151":"bs = 10\ntrain_labels['path'] = '..\/input\/lanl-earthquake-spectrogram-images\/train_images_no_overlap\/train_images_v3\/' + train_labels['seg_id'] + '.png'\n#valid_idx = train_labels[:10000].loc[train_labels['quake_number'].isin([1, 5, 8])].index\n#train_idx = train_labels[:10000].loc[~train_labels['quake_number'].isin([1, 5, 8])].index\ndata = (ImageList.from_df(train_labels[:-1], path='.\/', cols='path')\n        #.split_by_idxs(train_idx=train_idx, valid_idx=valid_idx)\n        .split_by_rand_pct(0.1)\n        .label_from_df('target', label_cls=FloatList)\n        #.transform(get_transforms(), size=255)\n        .databunch(bs=bs))","b54fd94a":"data.show_batch(rows=3, figsize=(7,6))","0550cf9b":"def mean_absolute_error(pred:Tensor, targ:Tensor)->Rank0Tensor:\n    \"Mean absolute error between `pred` and `targ`.\"\n    pred,targ = flatten_check(pred,targ)\n    return torch.abs(targ - pred).mean()\n\nlearn = cnn_learner(data, models.resnet50, metrics=mean_absolute_error)\nlearn.fit_one_cycle(4, 0.01)","1c3a6e92":"# Plot train vs valid loss\nfig = learn.recorder.plot_losses(return_fig=True)\nfig.set_size_inches(15,5)","5e422483":"# Unfreeze the model and search for a good learning rate\nlearn.unfreeze()\nlearn.lr_find()\nfig = learn.recorder.plot(return_fig=True)\nfig.set_size_inches(15,5)","f5ef89f1":"learn.fit_one_cycle(2, slice(1e-6, 3e-3\/10))\nlearn.save('cnn-step1')","3b413cec":"# Export the model\nlearn.export()","195cd7a8":"# We can see there is now an export.pkl file that we've saved\n!ls -l","f3b5fb4c":"ss = pd.read_csv('..\/input\/LANL-Earthquake-Prediction\/sample_submission.csv')\ntest = ImageList.from_df(ss, '..\/input\/lanl-earthquake-spectrogram-images\/test_images\/test_images_v3\/', cols='seg_id', suffix='.png')\nlearn = load_learner('.\/', test=test)\nlearn.load('cnn-step1')\npreds = learn.get_preds(ds_type=DatasetType.Test)","e5e3c3fa":"# Save the time to failure\nss['time_to_failure'] = [float(x) for x in preds[0]]","2ed71815":"ss.head()","b386425b":"# Cap the minimum and maximum time to failure values\nss.loc[ss['time_to_failure'] < 0, 'time_to_failure'] = 0\nss.loc[ss['time_to_failure'] > 12, 'time_to_failure'] = 12","d8c293dd":"ss.plot(kind='hist', bins=100, figsize=(15, 5), title='Distribution of predictions on the Test Set')\nplt.show()","c3599f13":"# Save our predictions\nss.to_csv('submission.csv', index=False)","0adac918":"# Using Deep Learning to \"learn\" the images of earthquake audio data.\n\nI wanted to expand my knowledge of deep learning and specifically using fastai. This kernel explores how I converted the acoustic data from the LANL Earthquake competition into melspectogram images. After converting audio to images we can train an image regression model using the fastai library.\n\nSo far I haven't been able to get outstanding performance out of this approach, but I am new to deep learning and the fastai\/pytorch library. Hopefully this will be helpful for others interested in learning more about deep learning.","7e973d5d":"## Loading the training labels and exploring the images","f4b5309c":"## Create a fastai databunch of training images and labels.\n- You can use a random split, or provide train and valid indexes for determining the train\/valid split.\n- I disabled transforms on the image but this may be useful when doing transfer learning.\n- label_cls must be set to FloatList as we are using the images to predict a float number (Time to failure)","44775763":"## Example of how the images were created\n- We use the `librosa` package which converts audio into melspectograms.\n- I tweaked the sample rate `sr` number of mels `n_mels` and used a log scale `power_to_db`. The values I chose were mainly based off of what I thought made the images look unique and detailed. A more scientific approach to creating the melspectrograms may yield better results.\n","03e7263c":"# Predicting on the test set\n- We load our sample submission file and create an imagelist based off of the seg_id\n- We point this imagelist at the images we've creates for the test set.\n- Load the trained model and call the prediction method on this imagelist.","4adfb2c4":"# Create the Fastai resnet50 model\n- Make sure you have GPU turned on or this will be very slow.\n- We are using mean_absolute_error as our evaluation metric","90be6063":"# Modeling with Fastai Library\nhttps:\/\/www.fast.ai\/ is a great resource for those interested in learning more about deep learning. After watching a few of the fastai tutorial videos I felt comfortable creating a baseline model.","1728d333":"## Checking the images in a databunch batch","e60ccd53":"Validation MAE ~ 2.08 isn't that great and we are starting to overfit. Using a better cross validation technique may be necessary.\n\nI'm sure you can do better than I have here, but this should be enough to get you started.","ff7dd408":"I hope this can be helpful to others. Please let me know if you have any suggestions on how I could improve it."}}