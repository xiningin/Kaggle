{"cell_type":{"0c55f960":"code","f3681879":"code","c65f05c8":"code","0b6b2c5c":"code","80d44528":"code","9c00650a":"code","2fd08011":"code","c875f4fc":"code","dac0009c":"code","cbc6e605":"code","77712a49":"code","e857986c":"code","3e2f36ab":"code","380bc52d":"code","78b8bac5":"code","6b7e084a":"code","78dbd998":"code","89c725a2":"code","8d9a236a":"code","195202b1":"code","b73846a5":"code","ec7e2ce0":"code","3814db72":"code","54544eeb":"code","759f9280":"code","4ddf2ada":"code","d0eef183":"code","059eb11c":"code","5bb942b6":"code","6c23ac2e":"code","c410a039":"code","4791b946":"code","9a8e8593":"code","6742dcbd":"code","25672b57":"code","3f44aeb8":"code","d083249a":"code","e247aaf8":"code","a9104a01":"code","a9a0ea32":"code","ed244e85":"markdown","f9e05f9c":"markdown","700845ef":"markdown","f1195e1d":"markdown","ee4c2250":"markdown","40a2350c":"markdown","7c83bbb3":"markdown","42b79f79":"markdown","ce4d4cd4":"markdown","d040ec70":"markdown","a1ed6851":"markdown","27314a59":"markdown","20a9a17b":"markdown","6878d077":"markdown","29ae7ca5":"markdown","eb7d32ea":"markdown","95ff6324":"markdown"},"source":{"0c55f960":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f3681879":"movies = pd.read_csv('\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv')\ncredits = pd.read_csv('\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv') ","c65f05c8":"movies.head(2)\nmovies.shape","0b6b2c5c":"credits.head(2)\ncredits.shape","80d44528":"movies = movies.merge(credits, on='title')\nmovies.shape","9c00650a":"movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]\nmovies.head(1)","2fd08011":"movies.isnull().sum()","c875f4fc":"movies.dropna(inplace=True)\nmovies.isnull().sum()","dac0009c":"import ast","cbc6e605":"def convert(text):\n    L = []\n    for i in ast.literal_eval(text):\n        L.append(i['name']) \n    return L ","77712a49":"movies['genres'] = movies['genres'].apply(convert)\nmovies.head()","e857986c":"movies['keywords'] = movies['keywords'].apply(convert)\nmovies.head()","3e2f36ab":"def convert_cast(text):\n    counter = 0\n    L = []\n    for i in ast.literal_eval(text):\n      if counter != 3:\n        L.append(i['name'])\n        counter+=1\n      else:\n        break\n    return L ","380bc52d":"movies['cast'] = movies['cast'].apply(convert_cast)\nmovies.head()","78b8bac5":"def extract_director(text):\n    L = []\n    for i in ast.literal_eval(text):\n      if i['job'] == 'Director':\n        L.append(i['name'])\n        break\n    return L ","6b7e084a":"movies['crew'] = movies['crew'].apply(extract_director)\nmovies.head()","78dbd998":"movies['overview'][0]","89c725a2":"movies['overview'] = movies['overview'].apply(lambda x: x.split())\nmovies.head()","8d9a236a":"def collapse(L):\n    L1 = []\n    for i in L:\n        L1.append(i.replace(\" \",\"\"))\n    return L1","195202b1":"movies['cast'] = movies['cast'].apply(collapse)\nmovies['crew'] = movies['crew'].apply(collapse)\nmovies['genres'] = movies['genres'].apply(collapse)\nmovies['keywords'] = movies['keywords'].apply(collapse)","b73846a5":"movies.head()","ec7e2ce0":"movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\nmovies.head()","3814db72":"new_movies = movies.drop(columns=['overview','genres','keywords','cast','crew'])\nnew_movies.head()","54544eeb":"new_movies['tags'] = new_movies['tags'].apply(lambda x: \" \".join(x))","759f9280":"new_movies['tags'] = new_movies['tags'].apply(lambda x: x.lower())","4ddf2ada":"new_movies.head()","d0eef183":"import nltk\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()","059eb11c":"def stem(text):\n  L = []\n  for i in text.split():\n    L.append(ps.stem(i))\n  return \" \".join(L)","5bb942b6":"new_movies['tags'] = new_movies['tags'].apply(stem)","6c23ac2e":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=5000, stop_words='english')","c410a039":"vectors = cv.fit_transform(new_movies['tags']).toarray()","4791b946":"from sklearn.metrics.pairwise import cosine_similarity\nsimilarity = cosine_similarity(vectors)","9a8e8593":"similarity","6742dcbd":"# ennumerate function is used to add index to each record, so that while sorting we donot loss the index.\n# reverse sorting the distances and picking the top 5 similar movies.","25672b57":"def recommend(movie):\n  movie_index = new_movies[new_movies['title'] == movie].index[0]\n  distances = similarity[movie_index]\n  movies_list = sorted(list(enumerate(distances)),reverse=True,key = lambda x: x[1])[1:6]\n\n  for i in movies_list:\n    print(new_movies.iloc[i[0]].title)","3f44aeb8":"recommend('Gandhi')","d083249a":"import pickle","e247aaf8":"pickle.dump(new_movies, open('movies.pkl', 'wb'))","a9104a01":"pickle.dump(new_movies.to_dict(), open('movies_dict.pkl', 'wb'))","a9a0ea32":"pickle.dump(similarity, open('similarity.pkl', 'wb'))","ed244e85":"#### Droping other columns ","f9e05f9c":"### Selecting useful features:\n\n*   Id\n*   Title\n*   Overview\n*   Genres\n*   Keywords\n*   Cast\n*   Crew\n\n\n\n\n","700845ef":"### This is a simple content based recommender system build by me. I used the approach of vectorization, bag of words technique.\n### I have extracted tags from the whole dataset for each movie, and based on the tags the movies are being recommended.","f1195e1d":"#### Preparing the tags column by adding other 5 columns","ee4c2250":"### Codes for deployement","40a2350c":"#### Converting tags column from list to a string and converting it to lowercase.","7c83bbb3":"### Getting the overview column in nice format","42b79f79":"### Function to extract useful data from the genres, keywords column.","ce4d4cd4":"### Function to extract first 3 actor name from the cast.","d040ec70":"#### Building the recommend function","a1ed6851":"### Function to extract director's name from the crew.","27314a59":"#### Stemming words in tags column to avoid repeatation (play, playing, played)","20a9a17b":"### Checking for null values, duplicate data and dropping those records","6878d077":"### Applying text vectorization - Bag of Words(BoW) Term Frequency","29ae7ca5":"#### Removing spaces from the words in each column","eb7d32ea":"#### Calculating cosine similarities between every pair of movies","95ff6324":"### Preparing tags column"}}