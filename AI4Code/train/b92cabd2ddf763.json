{"cell_type":{"db183496":"code","45a836df":"code","f424eb81":"code","a3330de5":"code","d6b667da":"code","9a0ee801":"code","c38e2cae":"code","359fe52b":"code","9c2e653a":"code","e766c323":"code","f96645c1":"code","751fa841":"code","63687d1d":"code","36a36e15":"code","b8ff574e":"code","f53e34f3":"code","8088a0c3":"markdown","ebbd571a":"markdown","0d7035b3":"markdown","46c89fa5":"markdown","5ec8b598":"markdown","90e232f0":"markdown","722cf62d":"markdown","96a12edc":"markdown","b29a8249":"markdown","2a09865f":"markdown","34c6c628":"markdown","f56c984c":"markdown","82b11061":"markdown","240de2fe":"markdown","48962c5b":"markdown","02ec800f":"markdown","37b02ae3":"markdown","1e903e3a":"markdown","4b62dffe":"markdown","e627fa9b":"markdown","10eaf29d":"markdown","59a67975":"markdown","fd02a705":"markdown","f01d9731":"markdown","50f79e88":"markdown","0921ca16":"markdown","b787b3ee":"markdown"},"source":{"db183496":"from keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, LSTM","45a836df":"model = Sequential()\n\n#Specify the input size of the first layer\n#input_shape = (3, ) - Our input size is 3\n#(Dense(5,..... - The number of neuron of our first hiddeen layer will be 5\n\nmodel.add(Dense(5, activation = 'relu', input_shape = (3, )))\n\n#Output layer\n\nmodel.add(Dense(2, activation = 'softmax'))","f424eb81":"model.summary()","a3330de5":"model = Sequential()\n\n#1st hidden layer\nmodel.add(Dense(100, activation = 'relu', input_shape = (50, )))\n\n#2nd hidden layer\nmodel.add(Dense(1, activation = 'relu'))\n\n#3rd hidden layer\nmodel.add(Dense(100, activation = 'relu'))\n\n#Output layer\nmodel.add(Dense(50, activation = 'softmax'))","d6b667da":"model.summary()","9a0ee801":"model = Sequential()\n\n#Here, (3,3) is the kernel size\nmodel.add(Conv2D(1, (3,3), input_shape = (5, 5, 1)))","c38e2cae":"model.summary()","359fe52b":"model = Sequential()\n\n#Here, (3,3) is the kernel size\nmodel.add(Conv2D(1, (3,3), input_shape = (50, 50, 1)))","9c2e653a":"model.summary()","e766c323":"model = Sequential()\n\n#Here, (3,3) is the kernel size\nmodel.add(Conv2D(1, (3,3), input_shape = (5, 5, 1), use_bias = False))","f96645c1":"model.summary()","751fa841":"model = Sequential()\n\nmodel.add(Conv2D(3, (2,2), input_shape = (5, 5, 1)))\n\nmodel.summary()","63687d1d":"model = Sequential()\n\n#input_shape = (5, 5, 3) - here 3 stands as RGB is used\nmodel.add(Conv2D(1, (2,2), input_shape = (5, 5, 3)))\n\nmodel.summary()","36a36e15":"model = Sequential()\n\n#input_shape = (5, 5, 2) - here 2 stands as RG is used\nmodel.add(Conv2D(3, (2,2), input_shape = (5, 5, 2)))\n\nmodel.summary()","b8ff574e":"model = Sequential()\n\nmodel.add(Conv2D(5, (5,5), input_shape = (5, 5, 3)))\n\nmodel.summary()","f53e34f3":"model = Sequential()\n\nmodel.add(LSTM(units = 2, input_dim = 3, input_length = 6))\n\nmodel.summary()","8088a0c3":"### 1.Greyscale - kernel = (3,3) - output layer = 1","ebbd571a":"**How 15 came up?**  \n3 x 4 + 3 = 15  \nHere,  \nbias = 3, As there are 3 channels  ","0d7035b3":"### 3.Model without bias","46c89fa5":"**How 48 came up?**  \n4[(2 + 3) x 2 + 2] = 48","5ec8b598":"**How 13 came up?**  \n3 x 4 + 1 = 15  \nHere,  \nbias = 1, As there is only 1 channel","90e232f0":"**How 380 came up?**  \n(5 x 5 x 3 + 1) x 5 = 380","722cf62d":"<br\/>\n\n### 8.RGB - kernel = 5X5 - channel of input = 3 - want to have output 5","96a12edc":"<br\/>\n<br\/>\n\nGratitude: Binod Sumon\n<br\/>\n\n### Looking forward to hearing your thoughts. And if you find it helpful, please upvote. It will keep me motivated. Thanks!","b29a8249":"<br\/>\n<br\/>\n\n### 2.let's look at another architecture","2a09865f":"**As this time, our bias value is 0**","34c6c628":"**Betweeen Input and First Hidden Layer:**  \n    3 x 5 = 15  \n    bias = 5  \n    Total = 15 + 5 = 20  \n    \n**Betweeen First Hidden Layer and Output:**  \n    5 x 2 = 10  \n    bias = 2  \n    Total = 12  \n    \n**The total param:**  \n    20 + 12 = 32","f56c984c":"## Importing necessary libraries","82b11061":"<br\/>\n\n# Feed Forward Neural Network\n<br\/>","240de2fe":"#### How did the 10 come as total params?","48962c5b":"**Note:**  \nIn CNN, the input size has no impact on the total params.  \nWhat matters here is the kernel size.  \n\n<br\/>\n\n### 2.Let's have a look changing the input size","02ec800f":"#### Model summary","37b02ae3":"**3 x 3 + 1 = 10**  \nHere,  \n1st 3 - kernel height  \n2nd 3 - kernel weight  \n1 - bias","1e903e3a":"### 1. Model architecture","4b62dffe":"### 1.LSTM with 2 hidden units and input dimension 3","e627fa9b":"**Note :  \nwe have always used kernel size in square, but in can also be (2, 3) or (3, 2) or like this.**","10eaf29d":"<br\/>\n\n### 4.Gray image - 3 channels - kernel size = (2, 2)","59a67975":"<br\/>\n<br\/>\n<br\/>\n\n# Convolutional Neural Network\n<br\/>\n<br\/>\n\n## Formula of total params of CNN:  \n**(width of the filter * height of the filter * number of filters in the previous layer + 1) x number of filters**  \n<br\/>\nHere,  \nnumber of filters in the previous layer  = Channel of input  \nnumber of filters = number of output\n\n<br\/>\n<br\/>","fd02a705":"#### Let's calculate it manually","f01d9731":"<br\/>\n<br\/>\n\n### 5. This time, RGB image- output of 1 channel - kerenl\/filter size = (2, 2)","50f79e88":"**How 27 came up?**  \n(2 x 2 x 2 + 1) x 3 = 27","0921ca16":"<br\/>\n<br\/>\n<br\/>\n\n# Long Short Term Memory Neural Network (LSTM)\n<br\/>\n<br\/>\n\nHidden input = h  \ninput dim = i \noutput dim = h  \nbias = h  \n1st layer = (h+1) x h + bias = (h+i) x h + h  \nNumber of total params = 4[(h+i) x h + h]  \n<br\/>\nEach LSTM cells has:  \n    1 forget gate  \n    2 input or unit gate  \n    1 output gate\n<br\/>\n<br\/>","b787b3ee":"<br\/>\n\n### 6.RG - 2x2 filter - output of 3 channels"}}