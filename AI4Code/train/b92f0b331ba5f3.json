{"cell_type":{"b706132f":"code","04db5927":"code","4e01e94c":"code","ee202a30":"code","9d03e0b3":"code","79f88cf5":"code","315cd219":"code","584f6098":"code","8f710104":"code","98dc91dc":"code","dccecbc5":"code","5f9b3c3f":"code","f1eb3fbb":"code","af9afb9a":"code","06a81de4":"code","3d04eebb":"code","8bcef851":"code","75de4747":"code","0911bf50":"code","2b9c08e0":"code","a14250d6":"code","74c72ddd":"code","33446e12":"code","8372ea6b":"code","69579950":"code","feacab58":"code","33bd8337":"code","f5e1f063":"markdown","f9a5614c":"markdown","ca306c3c":"markdown","32edf9d9":"markdown","0a6e9feb":"markdown","0db041cf":"markdown","d7533848":"markdown","79684c78":"markdown","33b3ea76":"markdown","2e897494":"markdown","6d8aa2d1":"markdown","f6f1eeaa":"markdown","43ab23ad":"markdown","d233985e":"markdown","1f0aedf9":"markdown","d986dc6e":"markdown","49031a0d":"markdown","90313349":"markdown","80ade83b":"markdown","13270517":"markdown","a9d66bb8":"markdown","a0de3e4b":"markdown","8c4dfdb9":"markdown","402abee5":"markdown","c46b7adf":"markdown","6a2c14d9":"markdown"},"source":{"b706132f":"import numpy as np \nimport pandas as pd \n\n#dataframe\ndf = pd.read_csv(\"..\/input\/atpdata\/ATP.csv\")\n","04db5927":"null_percent = df.isnull().sum() * 100 \/ len(df)\nmissing_value_df = pd.DataFrame({'column_name': df.columns,\n                                 'percent_missing': null_percent})\nprint(missing_value_df.reset_index().drop(columns=['index']))","4e01e94c":"df = df.drop(columns=['score','tourney_name','winner_name','tourney_date','loser_name','minutes'])","ee202a30":"df = df[df['surface'].notna()]\ndf = df[df.surface != 'None']","9d03e0b3":"df = df.rename(columns={\"loser_age\": \"P1_age\",\\\n                        \"loser_entry\": \"P1_entry\",\\\n                        \"loser_hand\": \"P1_hand\",\\\n                        \"loser_ht\": \"P1_ht\",\\\n                        \"loser_id\": \"P1_id\",\\\n                        \"loser_ioc\": \"P1_ioc\",\\\n                        \"loser_rank\": \"P1_rank\",\\\n                        \"loser_rank_points\": \"P1_rank_points\",\\\n                        \"loser_seed\": \"P1_seed\",\\\n                        'l_1stIn': 'P1_1stIn',\\\n                        'l_1stWon':'P1_1stWon',\\\n                        'l_2ndWon': 'P1_2ndWon',\\\n                        'l_SvGms': 'P1_SvGms',\\\n                        'l_ace': 'P1_ace',\\\n                        'l_bpFaced': 'P1_bpFaced',\\\n                        'l_bpSaved': 'P1_bpSaved',\\\n                        'l_df': 'P1_df',\\\n                        'l_svpt': 'P1_svpt',\\\n                        \"winner_age\": \"P2_age\",\\\n                        \"winner_entry\": \"P2_entry\",\\\n                        \"winner_hand\": \"P2_hand\",\\\n                        \"winner_ht\": \"P2_ht\",\\\n                        \"winner_id\": \"P2_id\",\\\n                        \"winner_ioc\": \"P2_ioc\",\\\n                        \"winner_rank\": \"P2_rank\",\\\n                        \"winner_rank_points\": \"P2_rank_points\",\\\n                        \"winner_seed\": \"P2_seed\",\\\n                        'w_1stIn': 'P2_1stIn',\\\n                        'w_1stWon':'P2_1stWon',\\\n                        'w_2ndWon': 'P2_2ndWon',\\\n                        'w_SvGms': 'P2_SvGms',\\\n                        'w_ace': 'P2_ace',\\\n                        'w_bpFaced': 'P2_bpFaced',\\\n                        'w_bpSaved': 'P2_bpSaved',\\\n                        'w_df': 'P2_df',\\\n                        'w_svpt': 'P2_svpt'},)","79f88cf5":"df_mirror = df.copy()\ndf_mirror[[ 'P1_age','P1_entry','P1_hand','P1_ht','P1_id','P1_ioc','P1_rank','P1_rank_points','P1_seed',\\\n            'P1_1stIn','P1_1stWon','P1_2ndWon','P1_SvGms','P1_ace','P1_bpFaced','P1_bpSaved','P1_df','P1_svpt',\\\n            'P2_age','P2_entry','P2_hand','P2_ht','P2_id','P2_ioc','P2_rank','P2_rank_points','P2_seed',\\\n            'P2_1stIn','P2_1stWon','P2_2ndWon','P2_SvGms','P2_ace','P2_bpFaced','P2_bpSaved','P2_df','P2_svpt']]\\\n=df_mirror[['P2_age','P2_entry','P2_hand','P2_ht','P2_id','P2_ioc','P2_rank','P2_rank_points','P2_seed',\\\n            'P2_1stIn','P2_1stWon','P2_2ndWon','P2_SvGms','P2_ace','P2_bpFaced','P2_bpSaved','P2_df','P2_svpt',\\\n            'P1_age','P1_entry','P1_hand','P1_ht','P1_id','P1_ioc','P1_rank','P1_rank_points','P1_seed',\\\n            'P1_1stIn','P1_1stWon','P1_2ndWon','P1_SvGms','P1_ace','P1_bpFaced','P1_bpSaved','P1_df','P1_svpt']]\n\n\n#Ajout de la colonne winner player qui correspond \u00e0 notre target.\nwinner_player2 = [1 for a in range(df.shape[0])]\ndf.insert(df.shape[1], \"Winner_player\", winner_player2, True)\n\nwinner_player1 = [-1 for a in range(df_mirror.shape[0])]\ndf_mirror.insert(df_mirror.shape[1], \"Winner_player\", winner_player1, True)\n\ndf = df.append(df_mirror)\ndf = df.reset_index().drop(columns=['index'])\ndf","315cd219":"df.info()","584f6098":"from sklearn.preprocessing import LabelEncoder\ndf['P2_entry'] = LabelEncoder().fit_transform(df['P2_entry'].astype(str))\ndf['P2_hand'] = LabelEncoder().fit_transform(df['P2_hand'].astype(str))\ndf['P2_ioc'] = LabelEncoder().fit_transform(df['P2_ioc'].astype(str))\ndf['round'] = LabelEncoder().fit_transform(df['round'].astype(str))\ndf['surface'] = LabelEncoder().fit_transform(df['surface'].astype(str))\ndf['tourney_level'] = LabelEncoder().fit_transform(df['tourney_level'].astype(str))\ndf['tourney_id'] = LabelEncoder().fit_transform(df['tourney_id'].astype(str))\ndf['P1_entry'] = LabelEncoder().fit_transform(df['P1_entry'].astype(str))\ndf['P1_hand'] = LabelEncoder().fit_transform(df['P1_hand'].astype(str))\ndf['P1_ioc'] = LabelEncoder().fit_transform(df['P1_ioc'].astype(str))\ndf.info()","8f710104":"from sklearn.impute import SimpleImputer\ndf2 = pd.DataFrame(SimpleImputer().fit_transform(df))\ndf2.columns = df.columns\ndf2.index = df.index\ndf_imputed = df2.copy()","98dc91dc":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(30,30))\nsns.heatmap(df_imputed.corr(), annot= True, linewidth=0.1, cmap= 'Blues')","dccecbc5":"import numpy as np\ncount, division = np.histogram(df_imputed)\n\ndf_imputed.hist(figsize=(30,30))","5f9b3c3f":"df_imputed_deleted_columns = df_imputed.copy()","f1eb3fbb":"df_imputed_deleted_columns = df_imputed_deleted_columns.drop(columns=['P2_1stIn','P2_1stWon','P2_2ndWon','P2_ace','P2_bpFaced','P2_bpSaved','P2_df','P2_svpt',\\\n            'P1_1stIn','P1_1stWon','P1_2ndWon','P1_ace','P1_bpFaced','P1_bpSaved','P1_df','P1_svpt'])\n","af9afb9a":"df_final = df_imputed_deleted_columns.copy()","06a81de4":"plt.figure(figsize=(30,30))\nsns.heatmap(df_final.corr(), annot= True, linewidth=0.1, cmap= 'Blues')","3d04eebb":"df_final = df_final.drop(columns=['P1_SvGms','P2_SvGms'])","8bcef851":"from sklearn.preprocessing import LabelBinarizer\n\njobs_encoder = LabelBinarizer()\njobs_encoder.fit(df_final['surface'])\ntransformed = jobs_encoder.transform(df_final['surface'])\ntransform_df = pd.DataFrame(transformed)\ndf_final.tail()\ndf_final = pd.concat([df_final, transform_df], axis=1).drop(['surface'], axis=1)\n\n","75de4747":"df_final.sample(frac=1).reset_index(drop=True)","0911bf50":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(df_final.drop(columns=[\"Winner_player\"]), df_final[\"Winner_player\"], test_size=0.20)\n","2b9c08e0":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection","a14250d6":"XGB_model = XGBClassifier()\nXGB_model.fit(x_train,y_train)\nscore = XGB_model.score(x_test,y_test)\n\nprint(\"XGBoost score: \", score)\n","74c72ddd":"score = XGB_model.score(x_train,y_train)\n\nprint(\"XGBoost score: \", score)","33446e12":"#\u00e9valuation en validation crois\u00e9e : 10 cross-validation\nsucces = model_selection.cross_val_score(XGB_model,df_final.drop(columns=[\"Winner_player\"]), df_final[\"Winner_player\"],cv=10,scoring='accuracy')\n#moyenne des taux de succ\u00e8s\nprint(succes.mean())","8372ea6b":"KNN_model = KNeighborsClassifier()\nKNN_model.fit(x_train,y_train)\nscore = KNN_model.score(x_test,y_test)\n\n\nprint(\"KNN score: \", score)","69579950":"#\u00e9valuation en validation crois\u00e9e :\nsucces = model_selection.cross_val_score(KNN_model,df_final.drop(columns=[\"Winner_player\"]), df_final[\"Winner_player\"],cv=10,scoring='accuracy')\n#moyenne des taux de succ\u00e8s\nprint(succes.mean())","feacab58":"RandomForest_model = RandomForestClassifier(n_estimators=100)\nRandomForest_model.fit(x_train,y_train)\nscore = RandomForest_model.score(x_test,y_test)\n\n\nprint(\"RandomForest score: \", score)","33bd8337":"#\u00e9valuation en validation crois\u00e9e :\nsucces = model_selection.cross_val_score(RandomForest_model,df_final.drop(columns=[\"Winner_player\"]), df_final[\"Winner_player\"],cv=10,scoring='accuracy')\n#moyenne des taux de succ\u00e8s\nprint(succes.mean())","f5e1f063":"A partir de ces diff\u00e8rentes explorations de donn\u00e9es, on est arriv\u00e9 \u00e0 d\u00e9terminer que certaines features sont trop corr\u00e9l\u00e9es entre elles, donc ne doivent pas \u00eatre gard\u00e9es lors de la phase de pr\u00e9diction.\n\nAinsi en appliquant ces deux m\u00e9thodes de visualisation on arrive \u00e0 d\u00e9terminer les colonnes \u00e0 \u00e9liminer afin d'am\u00e9liorer les performances de notre mod\u00e8le.","f9a5614c":"En employant notre m\u00e9thode le nombre de lignes double dans notre dataset, c'est le prix \u00e0 payer pour cette solution.\n\nVerification du type de donn\u00e9es \u00e0 transformer","ca306c3c":"# - XGBoost","32edf9d9":"Afin der\u00e9soudre notre probl\u00e8me d'inexistence de la colonne target on va tout d'abord ajouter une colonne que l'on nommera \"Winner_player\" celle-ci sera \u00e9gale \u00e0 -1 chaque fois que le Player 1 gagne la partie.\n\nEnsuite on va \u00e9tablir un nouveau dataframe que l'on nommera mirroir qui va contenir le pivot du dataset pr\u00e9c\u00e8dent, ainsi on aura le configuration suivante au niveau de la target:1 correspondra \u00e0 la victoire du Player 2\n\n-1 correspondra \u00e0 la victoire du Player 1\n\nProc\u00e9dure suivie:\n\n# Exemple\n\n\n# Donn\u00e9es de depart\n\n-   loser     |   winner          \n\n- 1 Nadal     |   Federer              \n- 2 Murray    |   Djokovic     \n\n------------------------\n\n# Etape 1 de preprocessing:\n\najout de la colonne winner player laquelle sera notre target\n\n-   p1         |  p2        | winner_player\n\n- 1 Nadal      |   Federer  |    1            \n- 2 Murray     |   Djokovic |    1\n------------------------\n\n# Etape 2 de preprocessing:\n\najout des lignes miroirs \n\n-   p1         |  p2        | winner_player\n\n- 1 Nadal      |  Federer   |    1     \n- 2 Murray     |  Djokovic  |    1\n- 3 Federer    |  Nadal     |   -1     \n- 4 Djokovic   |  Murray    |   -1\n\n","0a6e9feb":"Avec plus de temps il aurait \u00e9t\u00e9 int\u00e9ressant de creuser d'autres pistes en l'occurence\n\n  - On pourrait proposer de faire des pronostiques pendant le match, c'est \u00e0 dire en temps r\u00e9el et dans ce cas certaines donn\u00e9es seront conserv\u00e9es pour l'entrainement du mod\u00e8le comme le nombre de fautes durant le match, ou encore le nombre de set actuel\n \n  - Aussi il serait avis\u00e9 de jouer sur le tuning des hyperparametres des classifieurs, afin d'am\u00e9liorer le score finale\n\nEnfin concernant le temps que j'ai pass\u00e9 pour l'elaboration ce notebook, je l'estime entre entre 5h et 6h.","0db041cf":"D'apr\u00e8s la matrice de corr\u00e9lation la feature P1_svGms et P2_svGms sont fortement corr\u00e9l\u00e9es, dans ce cas on peut en garder une seule des deux.\n\nCela dit ceci nous indique finalement que c'est bien une donn\u00e9e issue d'un match bien pr\u00e9cis et donc non connue \u00e0 l'avance, ce qui \u00e9t\u00e9 pas tr\u00e8s clair au d\u00e9part.\n\nConclusion : on supprime les deux colonnes, comme on avait raisonn\u00e9 plut\u00f4t pour des features tels que match_duration etc ...","d7533848":"Afin de r\u00e9ussir \u00e0 pr\u00e9dire des r\u00e9sultats de matches de Tennis \u00e0 partir des donn\u00e9es actuelles, quelques changements s'imposent :\n\nCommen\u00e7ons par renommer nos features :\nsoit loser == Player 1 et winner == Player 2\n\nToutes les variables sufix\u00e9es loser devienent P1 et winner devienent P2\n\n- loser_ devienent P1_\n- winner_ devienent P2_","79684c78":"Les Features qu'on va devoir supprimer de notre \u00e9tude afin de r\u00e9aliser le mod\u00e8le de pr\u00e9diction sont : \n\n\n- P?_1stIn : Le nom n'est pas tr\u00e8s clair pas assez explicite, est-ce pour toute la carri\u00e8re du joueur ? ou pendant le match en question ? mais si on assume que c'est le \"pourcentage de 1er service pendant le match\" => Donn\u00e9e indisponible avant le match\n\n- P?_1stWon : Le nom n'est pas tr\u00e8s clair pas assez explicite, est-ce pour toute la carri\u00e8re du joueur ? ou pendant le match en question ? mais si on assume que c'est le \"pourcentage de 1er service gagnant pendant le match\" => Donn\u00e9e indisponible avant le match\n\n- P?_2ndWon : Le nom n'est pas tr\u00e8s clair pas assez explicite, est-ce pour toute la carri\u00e8re du joueur ? ou pendant le match en question ? mais si on assume que c'est le \"pourcentage de 2\u00e8me service gagnant pendant le match\" => Donn\u00e9e indisponible avant le match\n\n- P?_ace : Nombre de \"ace\" du joueur pendant un match => Donn\u00e9e indisponible avant le match\n\n- P?_bpFaced : Nombre de \"Balles de break auxquelles \u00e0 fait face le joueur\" pendant un match => Donn\u00e9e indisponible avant le match\n\n- P?_bpSaved : Nombre de \"Balles de break sauv\u00e9es\" pendant un match par le joueur => Donn\u00e9e indisponible avant le match\n\n- P?_df : Nombre de \"double fautes\" du joueur pendant un match => Donn\u00e9e indisponible avant le match\n\n- P?_svpt : Le nom n'est pas tr\u00e8s clair pas assez explicite, est-ce pour toute la carri\u00e8re du joueur ? ou pendant le match en question ? si on assume que c'est le \"pourcentage de services pendant le match\" => Donn\u00e9e indisponible avant le match\n\n? \u00e9tant joueur 1 ou 2.\n\n\n\nRemarque : L'histogramme ici est tr\u00e8s utile pour avoir une id\u00e9e de si c'est des valeurs rapport\u00e9es sur toute la carri\u00e8re des joueurs, ou bien pendant un match bien pr\u00e9cis. Dans le premier cas on les garde, dans le second on supprime cette donn\u00e9e car elle est indisponible avant le match et donc \u00e0 ne pas pr\u00e9senter au mod\u00e8le pour ne pas fausser nos r\u00e9sultats de pr\u00e9diction\/pronostique.","33b3ea76":"Sachant que la surface est un param\u00e8tre d\u00e9terminant pour les matches de Tennis il serait int\u00e9ressant d'encoder la feature surface comme suit.","2e897494":"# - RandomForest","6d8aa2d1":"# Exploration des donn\u00e9es","f6f1eeaa":"Rq : en gardant les donn\u00e9es supprim\u00e9es en premi\u00e8re partie (qui sont impossible \u00e0 obtenir avant le d\u00e9but d'un match) on obtient un score de 76% ce qui confirme qu'en rajoutant , mais sinon pour am\u00e9liorer il faudrait approffondir la partie pr\u00e9processing des donn\u00e9es.","43ab23ad":"Il reste \u00e0 g\u00e9rer les valeurs manquantes, pour cela on utilisera le labelEncoder.\n\nRq : on aurait pu utiliser juste un fonction m\u00e9dian pour remplir les \u00e9l\u00e9ments null mais j'ai pr\u00e9f\u00e9r\u00e9 utiliser un simple imputer car avec un peu de recule (mes anciens projets), j'ai remarqu\u00e9 que cela offre de meilleurs r\u00e9sultats lors de l'entrainement.","d233985e":"# Nettoyage des donn\u00e9es\n\nOn proc\u00e8de \u00e0 la suppression des features qui sont redondantes, et celles qui sont \u00e9videment non disponible avant un match \u00e0 pronostiquer.\n\nEn particulier (winner_name&loser_name) car elles sont quasiment redondante et rempla\u00e7able par respectivement (winner_id&loser_id)\n\nLes features minutes et score (car ne peuvent \u00eatre connues \u00e0 l'avance), ainsi que tourney_date et tourney_name, qui n'ont pas vraiment d'int\u00e9r\u00eat \u00e0 \u00eatre conserv\u00e9es pour la construction de notre mod\u00e8le.\n\nRemarque : Score pourrait d\u00e9tenir une information int\u00e9ressante, dans la perspective o\u00f9 on chercherait \u00e0 savoir si tel ou tel joueur \u00e0 tendance \u00e0 gagner ses matches avec une grande diff\u00e9rence de sets ...","1f0aedf9":"Tout d'abord on va s'int\u00e9resser au pourcentage de valeurs null","d986dc6e":"Les algorithmes avec la meilleure pr\u00e9diction des vainqueurs de matches de tennis sont XG Boost ainsi que Random Forest.\n","49031a0d":"On remarque qu'il y a 10 clonnes qui sont de type objet que l'on doit num\u00e9riser, pour cela on utilisera le labelEncoder","90313349":"Dans un soucis de r\u00e9duction du nombre de feature d'apr\u00e8s la matrice de corr\u00e9lation ci-dessus, on d\u00e9duit que d'apr\u00e8s les relations par paires de notre ensemble de donn\u00e9es il serait avis\u00e9 de supprimer certaines colonnes \n\nEx: appliquer une suppression sur l'une des deux colonne P2_1stWon ou P2_1stin, car elles sont relativement corr\u00e9l\u00e9es entre elles.","80ade83b":"Comme on peut le voir le pourcentage de donn\u00e9es ayant des valeurs null est relativement \u00e9lev\u00e9.\n\nEn effet il semble que ces donn\u00e9es \u00e9taient assez mal collect\u00e9es, cependant le plus frappant est le fait qu'il n'y a pas r\u00e9ellement de target qui sort du lot en survolant notre jeu de donn\u00e9es, score \u00e9tant \u00e0 priori pas facilement exploitable.\n\nVoyons ce qu'on peut faire :","13270517":"# Partitionnement des donn\u00e9es\n\npartitionnement du jeu de donn\u00e9es sous forme de donn\u00e9es d'entrainement et de donn\u00e9es de teste","a9d66bb8":"# Perspectives","a0de3e4b":"# Pr\u00e9diction du joueur gagnant\n\nLe but est d'\u00e9tablir un modele de pr\u00e9diction de pronostiques de resultats de matches de Tennis, uniquement \u00e0 partir des donn\u00e9es trouv\u00e9es dans le jeu ATP.csv, qui comprennent un historique de matches de Tennis depuis 1968.\n\n\n# Etapes\n\n - Explorer nos donn\u00e9es qui comprend la Visualisation et le Pr\u00e9traitement :\n     - On va d'abord chercher \u00e0 comprendre quelles sont les donn\u00e9es propos\u00e9es dans ATP.csv\n     - Extraire et d\u00e9finir la donn\u00e9e \u00e0 predire \u00e0 partir du jeu propos\u00e9\n     - Determiner lesquelles des features sont \u00e0 priori disponibles\/pertinentes avant chaque match pour faire des pronostiques de match\n     - Etude des correlations.\n     - Nettoyer et\/ou se d\u00e9lester des donn\u00e9es non pertinantes, traitement des valeurs manquantes, suppression ou non de certaines lignes et\/ou features et enfin normalisation des donn\u00e9es.\n     \n\n- Apprentissage et test de Mod\u00e9les de pr\u00e9diction\n    - Suite \u00e0 cela on va partager notre jeu de don\u00e9e sous forme de donn\u00e9es d'entrainement et de donn\u00e9es de test \n    - Enfin on appliquera un entrainement de 3 differents classifieurs de donn\u00e9es -KNN -RandomForest -XGBoost\n    - On notera les differentes performences des mod\u00e9les\n\nAvec plus de temps :\n- Faire de l'it\u00e9ration sur les donn\u00e9es \u00e0 utiliser\/garder\/transformer pour am\u00e9liorer les performances, (PCA, Forward\/Backward\/Stepward selection )\n- Faire des mod\u00e9les permettant de pr\u00e9dire des resultats de matches en temps r\u00e9el (prenant en compte des donn\u00e9es du match en cours - Aces, fautes, doubles fautes, s\u00e9rvices gagnants, temps du match, nombre de sets en cours ...)","8c4dfdb9":"On supprime les lignes qui ne contienent pas d'information sur la surface, car cette feature est importante pour l'issue des matches dans l'absolu\n\nExemple (Nadal vs Federer) : la surface impacte tr\u00e8s fortement le r\u00e9sultat.","402abee5":"# - KNN","c46b7adf":"# Apprentissage et d\u00e9termination de la performence de nos mod\u00e8les\n\nEntrainement de 3 diff\u00e8rents classifieurs de donn\u00e9es, Le mod\u00e8le bas\u00e9 sur la r\u00e9gression logistique prenant trop de temps de d'ex\u00e9cution, j'ai pr\u00e9f\u00e9r\u00e9 le laisser de c\u00f4t\u00e9 pour ce run.\n\n    - XGBoost\n    - KNN \n    - RandomForest\n\n\n","6a2c14d9":"Dans la lign\u00e9e des \u00e9tapes pr\u00e9c\u00e9dentes, pour approfondir notre connaissances des donn\u00e9es (voir les plus pertinentes pour l'\u00e9laboration de notre mod\u00e8le et les possibilit\u00e9s de simplification), il est int\u00e9ressant de g\u00e9n\u00e9rer la matrice de corr\u00e9lation, celle-ci va nous permettre de visualiser les liens entre les diff\u00e9rentes features, il est donc important d'avoir un aper\u00e7u de la matrice de corr\u00e9lation."}}