{"cell_type":{"7877e7ff":"code","0935ae30":"code","8f4a705e":"code","0042e67d":"code","fe412cfe":"code","169d866c":"code","135c70e2":"code","bc2e5df4":"code","e6494858":"code","9a3ac475":"code","69b5aefd":"code","bffe89e8":"code","dc409c97":"code","bbef735f":"code","9d035db5":"code","1ec51a65":"code","c13b22ec":"code","395fa88b":"code","07783dde":"code","63d58638":"code","9871f084":"code","d4eac4a1":"code","fd56cfb9":"code","1c02deb4":"code","a1076283":"code","e90e3cc8":"code","ec302986":"code","8005e8fa":"code","b77bcb32":"code","8cec20d1":"code","c27b2e88":"code","56149812":"code","b753c812":"code","546430b4":"markdown","4d676810":"markdown","37c28c16":"markdown","206665c1":"markdown","af5a285b":"markdown","a5bf3339":"markdown","ed6100c4":"markdown","d3c6064e":"markdown","6bc321b3":"markdown","ed3ee407":"markdown","bb214e21":"markdown","49376ff9":"markdown","aef4cbe9":"markdown","92b877f6":"markdown","3aa00a43":"markdown","975ebabb":"markdown","772717f3":"markdown","f43cedb4":"markdown","cb800846":"markdown","c247ac99":"markdown","a767b61e":"markdown","de6a00e3":"markdown"},"source":{"7877e7ff":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"..\/input\/dataset\"))","0935ae30":"print(tf.__version__)","8f4a705e":"train = pd.read_csv(\"..\/input\/dataset\/train.csv\")\n","0042e67d":"train = train.drop(columns=\"Unnamed: 0\")","fe412cfe":"# shuffle the DataFrame rows \n#train = train.sample(frac = 1) ","169d866c":"print(train.shape)\ntrain.head()","135c70e2":"# read test \ntest= pd.read_csv(\"..\/input\/dataset\/test.csv\")\n","bc2e5df4":"test = test.drop(columns=\"Unnamed: 0\")","e6494858":"print(test.shape)\ntest.head()","9a3ac475":"# put labels into y_train variable\nY_train = train[\"label\"]\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) ","69b5aefd":"# visualize number of digits classes\nplt.figure(figsize=(15,7))\ng = sns.countplot(Y_train, palette=\"icefire\")\nplt.title(\"Classification of Mushrooms\")\nY_train.value_counts()","bffe89e8":"plt.figure(figsize=(10,8))\nimg = np.array(X_train.iloc[3]).reshape(64,64)\nplt.imshow(img)\nplt.show()","dc409c97":"plt.figure(figsize=(10,8))\nimg = np.array(X_train.iloc[1]).reshape(64,64)\nplt.imshow(img)\nplt.show()","bbef735f":"plt.figure(figsize=(10,8))\nimg = np.array(X_train.iloc[2]).reshape(64,64)\nplt.imshow(img)\nplt.show()","9d035db5":"X_train = X_train \/ 255.0\ntest = test \/ 255.0\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","1ec51a65":"X_train = X_train.values.reshape(-1,64,64,1)\ntest = test.values.reshape(-1,64,64,1)\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","c13b22ec":"# Label Encoding \nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nY_train = to_categorical(Y_train, num_classes = 10)","395fa88b":"# Split the train and the validation set for the fitting\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)","07783dde":"# Some examples\nplt.imshow(X_train[3][:,:,0],cmap='gray')\nplt.show()","63d58638":"# Some examples\nplt.imshow(X_val[3][:,:,0],cmap='gray')\nplt.show()","9871f084":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n#\nmodel.add(Conv2D(filters = 8, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu', input_shape = (64,64,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu', input_shape = (64,64,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# fully connected\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","d4eac4a1":"# Define the optimizer\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","fd56cfb9":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","1c02deb4":"epochs = 250\nbatch_size = 256","a1076283":"# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=15,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.1, # Randomly zoom image 10%\n        width_shift_range=0.1,  # randomly shift images horizontally 10%\n        height_shift_range=0.1,  # randomly shift images vertically 10%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","e90e3cc8":"\n\n# Fit the model\nhistory = model.fit_generator(\n    datagen.flow(X_train,Y_train, batch_size=batch_size),                          \n    epochs = epochs,\n    validation_data = (X_val,Y_val), \n    steps_per_epoch=X_train.shape[0] \/\/ batch_size)","ec302986":"history.history","8005e8fa":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","b77bcb32":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'], '')\nplt.xlabel(\"Epochs\")\nplt.ylabel('Accuracy')\nplt.title('Change of Accuracy over Epochs')\nplt.legend(['accuracy', 'val_accuracy'])\nplt.show()","8cec20d1":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'], '')\nplt.xlabel(\"Epochs\")\nplt.ylabel('Loss')\nplt.title('Change of Loss over Epochs')\nplt.legend(['loss', 'val_loss'])\nplt.show()","c27b2e88":"keras_model=\"keras_mdl.h5\"\nkeras.models.save_model(model,keras_model)","56149812":"!ls","b753c812":"# Convert the model.\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n  f.write(tflite_model)","546430b4":"* Verileri tren ve test setlerine ay\u0131r\u0131yoruz.\n* test boyutu% 10'dur.\n* tren boyutu% 90'd\u0131r.","4d676810":"# Optimizer'\u0131 Tan\u0131mlay\u0131n\n\n* Adam optimizer: \u00d6\u011frenme oran\u0131n\u0131 de\u011fi\u015ftirin","37c28c16":"# Modeli de\u011ferlendirin\n\n* Test Kayb\u0131 g\u00f6rselle\u015ftirme\n* Kar\u0131\u015f\u0131kl\u0131k matrisi","206665c1":"# ****Train Test Split****","af5a285b":"* Evri\u015fim katman\u0131na sahip olduktan sonra, do\u011frusall\u0131\u011f\u0131 k\u0131rmak i\u00e7in ReLU kullan\u0131yoruz. Do\u011frusal olmay\u0131\u015f\u0131 art\u0131r\u0131n. \u00c7\u00fcnk\u00fc g\u00f6r\u00fcnt\u00fcler do\u011frusal de\u011fildir.","a5bf3339":"# Tam Ba\u011flant\u0131\n\n* Tamamen ba\u011fl\u0131 bir katmandaki n\u00f6ronlar\u0131n \u00f6nceki katmandaki t\u00fcm aktivasyonlarla ba\u011flant\u0131lar\u0131 vard\u0131r.\n* Yapay Sinir A\u011f\u0131","ed6100c4":"# Same Padding\n\n* As we keep applying conv layers, the size of the volume will decrease faster than we would like. In the early layers of our network, we want to preserve as much information about the original input volume so that we can extract those low level features.\n* input size and output size are same.","d3c6064e":"0: Zehirsiz. 1: Zehirli mantarlar\u0131 ifade ediyor.","6bc321b3":"# Modeli s\u0131\u011fd\u0131r","ed3ee407":"# confusion matrix\nimport seaborn as sns\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","bb214e21":"* Normalle\u015ftirme :\n Ayd\u0131nlatman\u0131n farkl\u0131l\u0131klar\u0131n\u0131n etkisini azaltmak i\u00e7in gri tonlamal\u0131 normalle\u015ftirme yap\u0131yoruz.\n Normalle\u015ftirme yaparsak CNN daha h\u0131zl\u0131 \u00e7al\u0131\u015f\u0131r.\n* Yeniden \u015fekillendir\n Resimleri e\u011fitin ve test edin (64 x 64)\n T\u00fcm verileri 64x64x1 3D matrislere yeniden \u015fekillendiriyoruz.\n Keras'\u0131n sonunda kanallara kar\u015f\u0131l\u0131k gelen fazladan bir boyuta ihtiyac\u0131 vard\u0131r. G\u00f6rsellerimiz gri \u00f6l\u00e7eklidir, bu nedenle yaln\u0131zca bir kanal kullan\u0131r.\n* Etiket Kodlama\n Etiketleri tek bir s\u0131cak vekt\u00f6r olarak kodlay\u0131n\n2 => [0,0,1,0,0,0,0,0,0,0]\n4 => [0,0,0,0,1,0,0,0,0,0]","49376ff9":"# Veri B\u00fcy\u00fctme\n\n* A\u015f\u0131r\u0131 uyum sorununu \u00f6nlemek i\u00e7in, el yaz\u0131s\u0131yla yaz\u0131lm\u0131\u015f rakam veri setimizi yapay olarak geni\u015fletmemiz gerekiyor.\n* Rakam varyasyonlar\u0131n\u0131 yeniden olu\u015fturmak i\u00e7in e\u011fitim verilerini k\u00fc\u00e7\u00fck d\u00f6n\u00fc\u015f\u00fcmlerle de\u011fi\u015ftirin.\n* \u00d6rne\u011fin say\u0131 ortalanmam\u0131\u015f. \u00d6l\u00e7ek ayn\u0131 de\u011fil (baz\u0131lar\u0131 b\u00fcy\u00fck \/ k\u00fc\u00e7\u00fck say\u0131larla yazanlar) G\u00f6r\u00fcnt\u00fc d\u00f6nd\u00fcr\u00fcl\u00fcr.","aef4cbe9":"# Maksimum Havuzlama\n\n* A\u015fa\u011f\u0131 \u00f6rnekleme veya alt \u00f6rnekleme yapar (Parametre say\u0131s\u0131n\u0131 azalt\u0131r)\n* \u00d6zelliklerin alg\u0131lanmas\u0131n\u0131 \u00f6l\u00e7eklendirmeye veya y\u00f6nelim de\u011fi\u015fikliklerine g\u00f6re de\u011fi\u015fmez hale getirir.\n* A\u011fdaki parametre ve hesaplama miktar\u0131n\u0131 azalt\u0131r ve dolay\u0131s\u0131yla a\u015f\u0131r\u0131 uyumu da kontrol eder.","92b877f6":"# Model Olu\u015ftur\n\n* d\u00f6n\u00fc\u015f\u00fcm => maksimum havuz => b\u0131rakma => d\u00f6n\u00fc\u015f\u00fcm => maksimum havuz => b\u0131rakma => tamamen ba\u011fl\u0131 (2 katman)\n* B\u0131rakma: E\u011fitim s\u0131ras\u0131nda rastgele se\u00e7ilen n\u00f6ronlar\u0131n g\u00f6z ard\u0131 edildi\u011fi bir tekniktir.","3aa00a43":"# **Convolutional Neural Network**","975ebabb":"Shuffle yani verimizi kar\u0131\u015ft\u0131r\u0131yoruz.","772717f3":"# Epochs and Batch Size\n\n","f43cedb4":"# Veri K\u00fcmesini Y\u00fckleme\n* Bu b\u00f6l\u00fcmde verileri y\u00fckleyip g\u00f6rselle\u015ftiriyoruz.","cb800846":"# Derleme Modeli\n\n* kategorik \u00e7aprazentropi\n* \u00d6nceki b\u00f6l\u00fcmlerde ve makine \u00f6\u011frenimi e\u011fitiminde ikili \u00e7apraz entropi yap\u0131yoruz\n* \u015eu anda kategorik \u00e7aprazentropi kullan\u0131yoruz. Bu, \u00e7ok s\u0131n\u0131f\u0131m\u0131z oldu\u011fu anlam\u0131na gelir.","c247ac99":"# Evri\u015fim \u0130\u015flemi nedir?\n\n* Baz\u0131 g\u00f6r\u00fcnt\u00fc ve \u00f6zellik alg\u0131lay\u0131c\u0131m\u0131z var (3 * 3)\n* \u00d6zellik dedekt\u00f6r\u00fcn\u00fcn 3'e 3 matris olmas\u0131 gerekmez. 5'e 5 veya 7'ye 7 olabilir.\n* \u00d6zellik alg\u0131lay\u0131c\u0131 = \u00e7ekirdek = filtre\n* \u00d6zellik detekt\u00f6r\u00fc, kenarlar veya d\u0131\u015fb\u00fckey \u015fekiller gibi \u00f6zellikleri alg\u0131lar. \u00d6rne\u011fin, \u00e7\u0131k\u0131\u015f giri\u015fi k\u00f6pek ise, \u00f6zellik alg\u0131lay\u0131c\u0131 k\u00f6pe\u011fin kula\u011f\u0131 veya kuyru\u011fu gibi \u00f6zellikleri alg\u0131layabilir.\n* \u00f6zellik haritas\u0131 = d\u00f6n\u00fc\u015f\u00fcm (giri\u015f resmi, \u00f6zellik alg\u0131lay\u0131c\u0131). Matrislerin eleman bilge \u00e7arp\u0131m\u0131.\n* \u00f6zellik haritas\u0131 = k\u0131vr\u0131ml\u0131 \u00f6zellik\n* Ad\u0131m = giri\u015f g\u00f6r\u00fcnt\u00fcs\u00fcnde gezinme.\n* G\u00f6r\u00fcnt\u00fcn\u00fcn boyutunu k\u00fc\u00e7\u00fclt\u00fcyoruz. Bu \u00f6nemlidir. Bc kodu daha h\u0131zl\u0131 \u00e7al\u0131\u015f\u0131r. Ancak bilgileri kaybettik.\n* Birden \u00e7ok \u00f6zellik haritas\u0131 olu\u015fturuyoruz, bc \u00e7oklu \u00f6zellik alg\u0131lay\u0131c\u0131lar\u0131 (filtreler) kullan\u0131yoruz.\n* Hadi gimp'e bakal\u0131m. Kenar alg\u0131lama: [0,10,0], [10, -4,10], [0,10,0]","a767b61e":"# **Normalle\u015ftirme, Yeniden \u015eekillendirme ve Etiket Kodlama**","de6a00e3":"* CNN, g\u00f6r\u00fcnt\u00fc s\u0131n\u0131fland\u0131rma, nesne alg\u0131lama i\u00e7in kullan\u0131l\u0131r"}}