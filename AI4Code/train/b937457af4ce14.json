{"cell_type":{"640150cf":"code","eb43b544":"code","fe67e72c":"code","dc993988":"code","4a5ccbbd":"code","77d82247":"code","aa2af7b9":"code","bb8eca55":"code","85cb6430":"code","6d891b12":"code","6a2316dc":"code","3db2a2a9":"code","f4af5558":"code","15db664d":"code","0d554e6e":"code","e4a0d47c":"code","9a358864":"code","6765e7c2":"code","417d0ffd":"code","1400939f":"code","4c050f23":"code","8913f1cd":"code","5acd2abd":"code","4c28b237":"code","0ba934c8":"code","7a860b2d":"code","efe928ab":"code","8a37819d":"code","e01672b5":"code","435268d0":"code","30f62b1a":"code","c514485e":"code","acf6c25a":"code","cef6a143":"code","f592cf00":"code","f7af0d7e":"code","20fefcaa":"code","60ab320f":"code","f2d325d2":"markdown","3d58676e":"markdown","b25ee063":"markdown","baaa116d":"markdown","1c33a8a3":"markdown","9ccc83d6":"markdown","047748ec":"markdown","3708defb":"markdown","7a5487bd":"markdown","b188e25a":"markdown","55291fe4":"markdown","1136b993":"markdown","0dfb392d":"markdown","7e8cdb49":"markdown","6a1ada24":"markdown","39d2d302":"markdown","431a2978":"markdown","80281db9":"markdown","38a345cc":"markdown","c3cbeef2":"markdown","ce790475":"markdown"},"source":{"640150cf":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn import preprocessing, model_selection, ensemble, metrics, pipeline, compose, impute\nimport xgboost as xgb\nimport category_encoders as ce\nimport matplotlib.pyplot as plt\nimport re\n\n# import training dataset\ntrain = pd.read_csv('..\/input\/train.csv')\n\n# import test dataset\ntest = pd.read_csv('..\/input\/test.csv')","eb43b544":"train.head()","fe67e72c":"missing = pd.isnull(train).sum() \/ len(train)\nmissing = missing[missing > 0]\nprint(missing)","dc993988":"# Pclass\nsns.distplot(train['Pclass'])","4a5ccbbd":"sns.countplot(x = 'Survived', hue = 'Pclass', data = train)","77d82247":"sns.catplot(x = 'Survived', hue = 'Pclass', col = 'Sex', data = train, kind = 'count')","aa2af7b9":"# creating a transform function to use later\ndef transform_1_Sex(data):\n    '''\n    data should be entire dataframe. Changes data inplace.\n    '''\n    data['Sex'] = np.vectorize(lambda x: 1 if x == 'female' else 0)(data['Sex'])\n    data['Sex_male'] = [0 if x == 1 else 1 for x in data['Sex']]\n\n#transform_1_Sex(train)","bb8eca55":"# Age\nsns.distplot(train['Age'][pd.isna(train['Age']) == False])","85cb6430":"print('Median of actual age: ' + str(np.median(train['Age'][pd.isna(train['Age'])== False])))\nprint('Quantiles: ' + str(np.quantile(train['Age'][~pd.isna(train['Age'])], [x \/ 100 for x in range(0, 101, 5)])))\n# let's create ranges and check survival\nmissing = pd.isna(train['Age'])\nbrackets = np.digitize(train['Age'], np.quantile(train['Age'][~missing], [x \/ 100 for x in range(0, 101, 5)]))\nbrackets[missing] = 22 # so that 21 is max, and missing are 22;the function np.digitize treats NaN as out of range(22 here)\n_, axes = plt.subplots(1, 2, figsize = (15,7))\nsns.countplot(x = brackets, hue = train['Survived'], ax = axes[0])\nsns.countplot(x = brackets, hue = train['Sex'], ax = axes[1])","6d891b12":"for i in range(1, 23):\n    occurences = train['Survived'][brackets == i]\n    print('Survived Percent per age group: ' + str(i) + '\\t' + str(sum(occurences) \/ len(occurences)))","6a2316dc":"# create age transformer\ndef transform_age(x):\n    if pd.isna(x):\n        return 0\n    elif (x < 4) or ((x >= 25) and (x < 27)) or ((x >= 31.8) and (x < 34)) or (x >= 56):\n        return 1\n    else:\n        return 0\n\ndef transform_2_Age(data):\n    '''\n    data should be entire dataframe. Changes data inplace.\n    '''\n    data['Age'] = np.vectorize(transform_age)(data['Age'])\n    data['Age_low_survival'] = [0 if x == 1 else 1 for x in data['Age']]\n#transform_2_Age(train)","3db2a2a9":"_, axes = plt.subplots(1, 2, figsize = (15, 7))\nsns.distplot(train['SibSp'], ax = axes[0])\nsns.distplot(train['Parch'], ax = axes[1])","f4af5558":"_, axes = plt.subplots(1, 2, figsize = (15, 7))\nsns.countplot(x = train['SibSp'], hue = train['Survived'], ax = axes[0])\nsns.countplot(train['Parch'], hue = train['Survived'], ax = axes[1])","15db664d":"# create another transformer based on two variables\ndef transform_3_Parch_SibSp(data):\n    '''\n    data should be the entire dataframe. Changes data inplace.\n    '''\n    data['TotalFamilyMembers'] = np.add(data['Parch'], data['SibSp'])\n    data['IsAlone'] = np.vectorize(lambda x: 1 if x == 0 else 0)(data['TotalFamilyMembers'])\n    data['IsNotAlone'] = [0 if x == 1 else 1 for x in data['IsAlone']]\n#transform_3_Parch_SibSp(train)","0d554e6e":"def transform_4_Cabin(data):\n    '''\n    data should be entire dataframe. Changes data inplace.\n    '''\n    data['Cabin'] = np.vectorize(lambda x: 0 if pd.isna(x) else 1)(data['Cabin'])\n    data['Cabin_non'] = [0 if x == 1 else 1 for x in data['Cabin']]\n#transform_4_Cabin(train)","e4a0d47c":"def transform_5_Embarked(data):\n    '''\n    data should be entire dataframe. Returns a dataframe which should be assigned.\n    '''\n    # get mode\n    mode = data['Embarked'].value_counts().index[0]\n    # give mode\n    data.loc[pd.isna(data['Embarked']), ['Embarked']] = mode\n    # create columns\n    return ce.OneHotEncoder(cols = ['Embarked'], use_cat_names = True).fit_transform(data)\n#train = transform_5_Embarked(train)","9a358864":"sns.distplot(train['Fare'])","6765e7c2":"fare = preprocessing.power_transform(np.array(train['Fare']).reshape(-1, 1), method = 'yeo-johnson')\nsns.distplot(fare)\n# looks better\ndef transform_6_Fare(data):\n    '''\n    data should be entire dataframe. Changes data inplace.\n    '''\n    data['Fare'] = preprocessing.power_transform(np.array(data['Fare']).reshape(-1, 1), method = 'yeo-johnson')\n#transform_6_Fare(train)","417d0ffd":"np.unique(train['Ticket'])\n# how about dividing it in numbers and letters?","1400939f":"def transform_7_Ticket(data):\n    '''\n    data should be entire dataframe. Changes data inplace.\n    '''\n    data['Ticket'] = np.vectorize(lambda x: 1 if re.match('[0-9]+', x) is None else 0)(data['Ticket'])\n    # 1 if letter, 0 otherwise\n    data['Ticket_non_letter'] = [0 if x == 1 else 1 for x in data['Ticket']]\n#transform_7_Ticket(train)","4c050f23":"# coming back to Pclass, it may be better to categorically encode the variables for better distinction\ndef transform_8_Pclass(data):\n    '''\n    data should be entire dataframe. Use this function and assign value again.\n    '''\n    return ce.OneHotEncoder(cols = ['Pclass'], use_cat_names=True).fit_transform(data)","8913f1cd":"train['Name']","5acd2abd":"# seems safe to take away first word and comma\nsalutation = train['Name'].str.split(', ', expand = True)[1].str.split('. ', expand = True)[0]\nsignificant = salutation.value_counts() > 9 #(10% of train)\nsignificant = significant.index[significant]\nchange_to_misc = np.vectorize(lambda x: 'Misc' if x not in significant else x)(salutation)\nnp.unique(change_to_misc, return_counts=True)","4c28b237":"def transform_9_Name(data):\n    '''\n    data should be entire dataframe. Assign value after return.\n    '''\n    # the significant ones are Mr, Mrs, Miss, Master, rest Misc\n    salutation = data['Name'].str.split(', ', expand = True)[1].str.split('. ', expand = True)[0]\n    significant = salutation.value_counts() > 9 #(10% of train)\n    significant = significant.index[significant]\n    change_to_misc = np.vectorize(lambda x: 'Misc' if x not in significant else x)(salutation)\n    data['Title'] = change_to_misc\n    return ce.OneHotEncoder(cols = ['Title'], use_cat_names=True).fit_transform(data)","0ba934c8":"def apply_transformations(df: pd.DataFrame):\n    '''\n    Applies all transformations. The returned dataframe will contain the dependent variable if it was passed.\n    '''\n    data = df.copy()\n    transform_1_Sex(data)\n    transform_2_Age(data)\n    transform_3_Parch_SibSp(data)\n    transform_4_Cabin(data)\n    data = transform_5_Embarked(data)\n    transform_6_Fare(data)\n    transform_7_Ticket(data)\n    data = transform_8_Pclass(data)\n    data = transform_9_Name(data)\n    # take out name\n    p_id = data['PassengerId']\n    # survived might still be in there\n    return (data.drop(['Name', 'PassengerId'], axis = 1), p_id)","7a860b2d":"X, _ = apply_transformations(train)\ny = X['Survived']\nX.drop('Survived', axis = 1, inplace = True)","efe928ab":"X.loc[1:10, :]","8a37819d":"X.columns","e01672b5":"kfold = model_selection.KFold(10, shuffle = True, random_state = 0)","435268d0":"rf = ensemble.RandomForestClassifier(n_estimators=100, bootstrap=False, n_jobs=6, random_state=0, verbose=0)\nfor k, (train_index, test_index) in enumerate(kfold.split(X, y)):\n    rf.fit(X.loc[train_index, :], y[train_index])\n    print(metrics.accuracy_score(y[test_index], rf.predict(X.loc[test_index, :])))","30f62b1a":"xgb_data = xgb.DMatrix(X, label = y)","c514485e":"params = {'eta': 0.2, 'lambda': 0.2, 'alpha': 0, 'eval_metric': 'error', 'objective': 'binary:hinge',\n         'max_depth': 10, 'min_child_weight': 2, 'base_score': 0.38}\nfor k, (train_index, test_index) in enumerate(kfold.split(X, y)):\n    xgb_model_1 = xgb.train(dtrain = xgb_data.slice(train_index), evals = [(xgb_data.slice(test_index), 'eval'), \n                                                             (xgb_data.slice(train_index), 'train')],\n             early_stopping_rounds = 5, verbose_eval=True, params=params, num_boost_round=100)","acf6c25a":"params = {'eta': 0.1, 'lambda': 0.0, 'alpha': 0, 'eval_metric': 'error', 'objective': 'binary:hinge',\n         'max_depth': 5, 'min_child_weight': 3}\nfor k, (train_index, test_index) in enumerate(kfold.split(X, y)):\n    xgb_model_2 = xgb.train(dtrain = xgb_data.slice(train_index), evals = [(xgb_data.slice(test_index), 'eval'), \n                                                             (xgb_data.slice(train_index), 'train')],\n             early_stopping_rounds = 5, verbose_eval=True, params=params, num_boost_round=100, xgb_model=xgb_model_1)","cef6a143":"params = {'eta': 0.005, 'lambda': 0.0, 'alpha': 0, 'eval_metric': 'error', 'objective': 'binary:hinge',\n         'max_depth': 10, 'min_child_weight': 2}\nfor k, (train_index, test_index) in enumerate(kfold.split(X, y)):\n    xgb_model_3 = xgb.train(dtrain = xgb_data.slice(train_index), evals = [(xgb_data.slice(test_index), 'eval'), \n                                                             (xgb_data.slice(train_index), 'train')],\n             early_stopping_rounds = 5, verbose_eval=True, params=params, num_boost_round=100, xgb_model = xgb_model_2)\n    print('\\n\\nNEW ROUND\\n\\n')","f592cf00":"X_test, p_id = apply_transformations(test)\nprint(X_test.columns)","f7af0d7e":"X_test.loc[1:10, X.columns]","20fefcaa":"xgb_test_data = xgb.DMatrix(X_test.loc[:, X.columns])\ny_pred = xgb_model_3.predict(xgb_test_data)","60ab320f":"pd.DataFrame({'PassengerId':p_id,\n              'Survived':y_pred}).to_csv('x_3.csv', header = True, index = False)\ny_pred = xgb_model_2.predict(xgb_test_data)\npd.DataFrame({'PassengerId':p_id,\n              'Survived':y_pred}).to_csv('x_2.csv', header = True, index = False)\ny_pred = xgb_model_1.predict(xgb_test_data)\npd.DataFrame({'PassengerId':p_id,\n              'Survived':y_pred}).to_csv('x_1.csv', header = True, index = False)","f2d325d2":"Next are SibSp and Parch. They do not have any missing values. However, these allow a unique opportunity: creation of new variables. The two I think of are TotalFamilyMembers and IsAlone.","3d58676e":"Now let's see the columns.","b25ee063":"The final task is to predict the 'Survived' variable. It is seen that Name, Sex, Ticket, Cabin, and Embarked are the categorical variables. Before tackling each, let's check missing.","baaa116d":"# Now train models.","1c33a8a3":"Most of the passengers are from third class. How does the surviability change based on class?","9ccc83d6":"For all age groups, except the first two and number 10, the passengers who survived were lower than tho who did not. However, there are some groups where the survived were far lower than those who did not. Since the variable seems cyclical (low age - high survival, middle age - low survival, high age - high survival, NaN - low survival), categorical encoding might work well.","047748ec":"Last is Ticket. What does it look like?","3708defb":"### This notebook will make use of the Titanic dataset on Kaggle which can be viewed here, https:\/\/www.kaggel.com\/c\/titanic.\n### The task is to predict the Survived variable based on several independent variables.","7a5487bd":"Now let's look at Age where 20% of values are missing.","b188e25a":"How does survival change?","55291fe4":"Two anomalies: the number of third class passengers who did not survive, and the number of second class passengers being fewer than the number of third class passengers who did survived. It is probably explained through other variables, like Sex.","1136b993":"Interestingly a lot of the fare is around 0, also this column is heavily skewed.","0dfb392d":"#### Now it's time to prepare the data. All transformations are ready to be used.","7e8cdb49":"Left are Ticket, Fare, Cabin and Embarked. Cabin has a lot of missing values (~77%). So, encode it as 1 if the passenger had a cabin versus 0 if they did not.","6a1ada24":"Finally, analysis of Name.","39d2d302":"Next Embarked has two very little missing values. Give it mode.","431a2978":"How does the Survive variable change when age changes?","80281db9":"If the percentage is above 0.5 (arbitrary), then code it as 1, otherwise 0. So, that would be: 1, 2, 10, 14, 21. Those correspond to groups:\n<br>1: 0 - 0.42\n<br>2: 0.42 - 4\n<br>10: 25 - 27\n<br>14: 31.8 - 34\n<br>21: 56 - max","38a345cc":"Considering just the third class who survived, the number is higher than second class' total survival because of more females in the group.","c3cbeef2":"Quick analysis of Fare.","ce790475":"It seems a higher number means better chances of survival with Parch, however results are mixed with SibSp, with value of 1 being only one where number of survived were higher than those who did not."}}