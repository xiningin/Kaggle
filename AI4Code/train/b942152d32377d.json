{"cell_type":{"a17d44d8":"code","71c73cbb":"code","89645510":"code","ac2e29f9":"code","f437ddc2":"code","076b5dc5":"code","9bdfaf57":"code","978cb825":"code","e7a2595a":"code","b6cb0b7f":"code","018ad041":"code","7454a642":"code","967f35a0":"code","81040dfd":"code","f2451bee":"code","36669155":"code","e60209d9":"code","23a47802":"code","9e6ef891":"code","3b0f49ff":"code","8f2569d4":"code","4257e6db":"code","e3eca92c":"markdown","f279bdd7":"markdown","5efcaaee":"markdown","376e272e":"markdown"},"source":{"a17d44d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","71c73cbb":"import numpy as np              # linear algebra\nimport pandas as pd             # data processing, CSV file I\/O (e.g. pd.read_csv)\n                                \nimport matplotlib.pyplot as plt # data visualization\nimport seaborn as sns           # data visualization","89645510":"sample_submission = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-dec-2021\/sample_submission.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-dec-2021\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-dec-2021\/test.csv\")","ac2e29f9":"sample_submission.shape","f437ddc2":"train.shape","076b5dc5":"train.info()","9bdfaf57":"test.shape","978cb825":"test.info()","e7a2595a":"data = pd.concat([train, test], sort = False)\ndata.shape","b6cb0b7f":"data.info()","018ad041":"data.head()","7454a642":"null_cols = [col for col in data.iloc[: , : -1].columns if data[col].isnull().sum() != 0]\nnull_cols","967f35a0":"TARGET = 'Cover_Type'\nFEATURES = [col for col in train.columns if col not in ['id', TARGET]]\n\ncat_features = [col for col in FEATURES if data[col].nunique() < 25]\ncont_features = [col for col in FEATURES if data[col].nunique() >= 25]\n\ndel data\nprint(f'Total number of features: {len(FEATURES)}')\nprint(f'Number of categorical features: {len(cat_features)}')\nprint(f'Number of continuos features: {len(cont_features)}')\n\nplt.pie([len(cat_features), len(cont_features)], \n        labels=['Categorical', 'Continuos'],\n        colors=['#76D7C4', '#F5B7B1'],\n        textprops={'fontsize': 13},\n        autopct='%1.1f%%')\nplt.show()","81040dfd":"train.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\\\n                     .style.background_gradient(cmap='GnBu')\\\n                     .bar(subset=[\"max\"], color='#BB0000')\\\n                     .bar(subset=[\"mean\",], color='green')","f2451bee":"plt.figure(figsize=(10,8))\nsns.countplot(x='Cover_Type', data=train, palette='icefire');","36669155":"# predictor\nX = train.drop(columns=['Id','Cover_Type','Soil_Type7','Soil_Type15'])\n\n# target\ny = train['Cover_Type']\n\ndel train\n\n# test data \ntest_df = test.drop(columns=['Id','Soil_Type7','Soil_Type15'])\ndel test","e60209d9":"# train-test split\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\nimport optuna\n\ndef objective(trial):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, random_state = 123, shuffle = True)\n\n    param = {\n        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02, 0.03, 0.05, 0.1, 0.2, 0.3]),\n        'n_estimators': 1000,\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n        'random_state': trial.suggest_categorical('random_state', [0, 24, 48,2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n    }\n    \n    model = XGBClassifier(**param)  \n    \n    model.fit(X_train, y_train, eval_set=[(X_val,y_val)], early_stopping_rounds = 20, verbose = False)\n    \n    y_pred = model.predict(X_val)\n    \n    result = accuracy_score(y_val, y_pred)\n    \n    return result\n\n\nstudy = optuna.create_study(direction = 'maximize', sampler = optuna.samplers.RandomSampler(seed = 0))\n\nstudy.optimize(objective, n_trials = 10)","23a47802":"param = {\n        'tree_method': 'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n        'lambda': study.best_params['lambda'],\n        'alpha': study.best_params['alpha'],\n        'colsample_bytree': study.best_params['colsample_bytree'],\n        'subsample': study.best_params['subsample'],\n        'learning_rate': study.best_params['learning_rate'],\n        'n_estimators': 500,\n        'max_depth': study.best_params['max_depth'],\n        'random_state': study.best_params['random_state'],\n        'min_child_weight': study.best_params['min_child_weight'],\n    }\n\n\nmodel = XGBClassifier(**param)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15, random_state = 123, shuffle = True)\ndel X, y\n\nmodel.fit(X_train, y_train, eval_set=[(X_val,y_val)], early_stopping_rounds = 20, verbose = False)","9e6ef891":"# validation prediction\ny_pred = model.predict(X_val)","3b0f49ff":"# validation accuracy\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy Score : ',accuracy_score(y_val, y_pred))","8f2569d4":"# test prediction\ny_pred = model.predict(test_df)","4257e6db":"# submission\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv')\nsubmission['Cover_Type'] = y_pred\nsubmission.to_csv(\"submission.csv\",index=False)\nsubmission.head()","e3eca92c":"# Preprocessing","f279bdd7":"# Data Preparation\n\n---\n\n## Data Extraction","5efcaaee":"## Null Check","376e272e":"## Data Concatenation"}}