{"cell_type":{"f2443ecb":"code","1d44f632":"code","d366ce1f":"code","9d012a31":"code","4c559855":"code","505a0e93":"code","01a6fb5c":"code","f27c534a":"code","1f1b1dbc":"code","1b15d046":"code","c7eb4930":"code","39d91269":"code","40f5db48":"code","4778e731":"code","91d68e7c":"code","a6003acc":"code","4ecaadd0":"code","52302fa8":"code","5ad0e182":"code","90e1ae1e":"code","73d66217":"code","320e6968":"code","0a9578f1":"code","858795bf":"code","3fd455de":"code","de44d73a":"code","922f060a":"code","85536b63":"code","cf455c8f":"code","9afd287a":"code","70aae072":"code","9ebf411d":"code","90628f58":"code","def2a8d7":"code","c292a3b4":"code","9b83d92b":"code","200a3c8f":"code","22515fbe":"code","0d006d80":"code","c0fd6e1b":"code","39766d64":"code","b60d7a6c":"code","7a27c002":"code","b4201788":"code","f655c3a1":"code","df70d68d":"code","2c90401d":"code","608a501b":"code","81eff573":"code","abec2d6b":"code","de622761":"code","552ca4f1":"code","74b41a9c":"code","a60866ea":"code","c29646c0":"code","8c117e52":"markdown","07468ca5":"markdown","89a325e2":"markdown","260cb284":"markdown","cf859f88":"markdown","6194b6cb":"markdown","6eb00186":"markdown"},"source":{"f2443ecb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.functional as F\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,BatchNormalization\n#from tensorflow.keras.callbacks import EarlyStopping\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1d44f632":"df=pd.read_csv('\/kaggle\/input\/age-gender-and-ethnicity-face-data-csv\/age_gender.csv')","d366ce1f":"df.head()","9d012a31":"len(df.pixels)","4c559855":"X=np.zeros(shape=(23705,2304))\n\nfor i in range(len(df.pixels)):\n    df.pixels[i]=np.array(df.pixels[i].split(),dtype='float32')\n    X[i]=df.pixels[i]\n    \n    \n    ","505a0e93":"X.shape # my image pixels were stored  in this array","01a6fb5c":"X_reshaped=X.reshape(-1,48,48,1)","f27c534a":"X_reshaped.shape","1f1b1dbc":"X_reshaped[0].shape","1b15d046":"#print random images\n\nindex=np.random.randint(0,23704,25)\n\n\nplt.figure(figsize=(16,16))\n\nfor i in range(len(index)):\n    plt.subplot(5,5,(i%25)+1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_reshaped[index[i]].reshape(48,48))\n    plt.xlabel(\n        \"Age:\"+str(df['age'].iloc[index[i]])+\n        \" Ethnicity:\"+str(df['ethnicity'].iloc[index[i]])+\n        \" Gender:\"+str(df['gender'].iloc[index[i]])\n    )\n    \nplt.show()","c7eb4930":"plt.figure(figsize=(40,5))\n\nsns.countplot(x='age',hue='gender',data=df)\nplt.xlabel('Age')\nplt.title('Age of people according to their gender')","39d91269":"plt.figure(figsize=(20,5))\n\nsns.countplot(x='ethnicity',hue='gender',data=df)\nplt.xlabel('Ethnicity')\nplt.title('Ethnicity of people according to their gender')","40f5db48":"plt.figure(figsize=(20,5))\n\nsns.countplot(x='ethnicity',data=df)\nplt.xlabel('Ethnicity')\nplt.title('Ethnicity of people') # Unbalanced","4778e731":"plt.figure(figsize=(20,5))\n\nsns.countplot(x='age',data=df)\nplt.xlabel('Age')\nplt.title('Age of people') ","91d68e7c":"plt.figure(figsize=(20,5))\n\nsns.countplot(x='gender',data=df)\nplt.xlabel('Gender')\nplt.title('Gender of people') ","a6003acc":"df.gender=df.gender.astype('object')\ndf.ethnicity=df.ethnicity.astype('object')\n","4ecaadd0":"# Labels for images\nfrom keras.utils import to_categorical\n\nY_age=np.array([df.age]).T\nY_Gender=np.array(to_categorical(df.gender))\nY_Ethnic=np.array(to_categorical(df.ethnicity))","52302fa8":"from sklearn.preprocessing import LabelEncoder\n\nle =LabelEncoder()\n\nY_Gender2=le.fit_transform(df.gender)","5ad0e182":"print(\"Shape of Age Labels:\",Y_age.shape)\nprint(\"Shape of Gender Labels:\",Y_Gender.shape)\nprint(\"Shape of Ethnicity Labels:\",Y_Ethnic.shape)","90e1ae1e":"Y_Gender[:5] #male==[1,0],female==[0,1]","73d66217":"Y_Ethnic[:5]","320e6968":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nX_train, X_test, y_train, y_test = train_test_split(X_reshaped, Y_Gender, test_size=0.3, random_state=42,shuffle=True)","0a9578f1":"print('Shape of X_train:',X_train.shape)\nprint('Shape of X_test:',X_test.shape)\nprint('Shape of y_train:',y_train.shape)\nprint('Shape of y_test:',y_test.shape)","858795bf":"X_test, X_for_pred, y_test, y_for_pred = train_test_split(X_test, y_test, test_size=0.1, random_state=42,shuffle=True)","3fd455de":"print('Shape of X_test:',X_test.shape) # I use this for my model training\nprint('Shape of X_for_pred:',X_for_pred.shape) # I this them for prediction \nprint('Shape of y_test:',y_test.shape) #I use this for my model training\nprint('Shape of y_for_pred:',y_for_pred.shape) # I this them for prediction ","de44d73a":"X_train=X_train\/255.0\nX_test=X_test\/255.0\nX_for_pred=X_for_pred\/255.0","922f060a":"model=Sequential()\n\nmodel.add(Conv2D(32,(3,3),input_shape=(48,48,1),padding='same',activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPool2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n\nmodel.add(Dense(256, activation='relu')),\nmodel.add(BatchNormalization()),\nmodel.add(Dropout(0.5)),\nmodel.add(Dense(2, activation='sigmoid'))\n\nmodel.summary()\n          \n\n\n","85536b63":"batch_size=128\nepochs=12\n\nfrom tensorflow.keras.optimizers import Adam\n\nopt=Adam(lr=0.001)\n\nmodel.compile(optimizer = opt,\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy'])","cf455c8f":"history = model.fit(X_train,y_train,batch_size=batch_size,epochs = epochs, validation_data = (X_test,y_test))","9afd287a":"print(\"Accuracy of the model on Training Data is - \" , model.evaluate(X_train,y_train)[1]*100 , \"%\")\nprint(\"Accuracy of the model on Testing Data is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")","70aae072":"%matplotlib inline\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","9ebf411d":"y_pred=model.predict(X_for_pred)\ny_pred[:5]","90628f58":"Y_pred_classes = np.argmax(y_pred,axis = 1)  # convert predictions to one hot vectors","def2a8d7":"Y_pred=['male' if i==0 else 'female' for i in Y_pred_classes]","c292a3b4":"Y_pred[:5]","9b83d92b":"index=np.random.randint(0,712,25) # predicted label and their images\n\nplt.figure(figsize=(16,16))\n\nfor i in range(len(index)):\n    plt.subplot(5,5,(i%25)+1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_for_pred[index[i]].reshape(48,48))\n    plt.xlabel(\"Predicted Gender:\"+str(Y_pred[index[i]])\n    )\n    \nplt.show()","200a3c8f":"#Confusion Matrix\n\nY_true = np.argmax(y_for_pred,axis = 1) \n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","22515fbe":"from sklearn.metrics import classification_report\n\nprint(classification_report(Y_true, Y_pred_classes)) ","0d006d80":"X.shape #I use this for Pytorch","c0fd6e1b":"X_new=X.reshape(23705,1,48,48)","39766d64":"Y_Gender2.shape","b60d7a6c":"X_train, X_test, y_train, y_test = train_test_split(X_new, Y_Gender2, test_size=0.3, random_state=42,shuffle=True)\nX_test, X_for_pred, y_test, y_for_pred = train_test_split(X_test, y_test, test_size=0.1, random_state=42,shuffle=True)","7a27c002":"x_train_tensor=torch.from_numpy(X_train)\nprint(\"x_train tensor size:\",x_train_tensor.size())\n\ny_train_label=torch.from_numpy(y_train)\nprint(\"y_train_label size:\",y_train_label.size())\n","b4201788":"x_test_tensor=torch.from_numpy(X_test)\nprint(\"x_test tensor size:\",x_test_tensor.size())\n\ny_test_label=torch.from_numpy(y_test)\nprint(\"y_test_ label size:\",y_test_label.size())","f655c3a1":"x_for_pred_tensor=torch.from_numpy(X_for_pred)\nprint(\"x_test tensor size:\",x_for_pred_tensor.size())\n\ny_for_pred_label=torch.from_numpy(y_for_pred)\nprint(\"y_test_ label size:\",y_for_pred_label.size())","df70d68d":"batch_size = 100\nn_iters = 200\nnum_epochs = n_iters \/ (len(X_test) \/ batch_size)\nnum_epochs = int(num_epochs)","2c90401d":"num_epochs","608a501b":"train=torch.utils.data.TensorDataset(x_train_tensor,y_train_label) # x ve y train birle\u015ftirildi\ntrainloader=torch.utils.data.DataLoader(train,batch_size=batch_size,shuffle=True) # data ya \u00e7eviriyoruz e\u011fitime uygun hale geldi\n\n    \ntest=torch.utils.data.TensorDataset(x_test_tensor,y_test_label) # x ve y train birle\u015ftirildi\ntestloader=torch.utils.data.DataLoader(test,batch_size=batch_size,shuffle=False)\n\nfor_pred=torch.utils.data.TensorDataset(x_for_pred_tensor,y_for_pred_label)\nfor_pred_loader=torch.utils.data.DataLoader(for_pred,batch_size=batch_size,shuffle=False)","81eff573":"\n\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n        self.relu = nn.ReLU()\n\n        # Max pool 1\n        self.maxpool = nn.MaxPool2d(kernel_size=2)\n        \n        self.Batch1=nn.BatchNorm2d(16)\n        self.Batch2=nn.BatchNorm2d(32)\n        self.Batch3=nn.BatchNorm2d(64)\n        self.Batch4=nn.BatchNorm2d(128)\n        \n        self.Drop1=nn.Dropout(0.2)\n        self.Drop2=nn.Dropout(0.5)\n\n\n        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n        self.cnn3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n        self.cnn4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n        \n        \n\n        # Fully connected 1 (readout)\n        self.fc1 = nn.Linear(128 * 1 * 1, 128) \n        self.fc2=nn.Linear(128,256)\n        self.fc3=nn.Linear(256,2)\n\n    def forward(self, x):\n \n        out = self.cnn1(x) \n        out = self.relu(out)\n        out = self.maxpool(out)\n        out=self.Batch1(out)\n        out=self.Drop1(out)\n \n        out = self.cnn2(out)\n        out = self.relu(out)\n        out = self.maxpool(out)\n        out=self.Batch2(out)\n        out=self.Drop1(out)\n        \n        out = self.cnn3(out)\n        out = self.relu(out)\n        out = self.maxpool(out)\n        out=self.Batch3(out)\n        out=self.Drop1(out)\n        \n        out = self.cnn4(out)\n        out = self.relu(out)\n        out = self.maxpool(out)\n        out=self.Batch4(out)\n        out=self.Drop1(out)\n        \n\n        # Resize\n        # Original size: (100, 32, 7, 7)\n        # out.size(0): 100\n        # New out size: (100, 32*7*7)\n        out = out.view(out.size(0), -1)\n\n        # Linear function (readout)\n        out = self.fc1(out)\n        \n        out=self.Drop2(out)\n        \n        out=self.fc2(out)\n        \n        out=self.Drop2(out)\n        \n        out=self.fc3(out)\n        \n        \n\n        return out","abec2d6b":"model = CNNModel()\n\nlearning_rate=0.001\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","de622761":"print(model.parameters())\n\nprint(len(list(model.parameters())))\n\n# Convolution 1: 16 Kernels\nprint(list(model.parameters())[0].size())\n\n# Convolution 1 Bias: 16 Kernels\nprint(list(model.parameters())[1].size())\n\n# Convolution 2: 32 Kernels with depth = 16\nprint(list(model.parameters())[2].size())\n\n# Convolution 2 Bias: 32 Kernels with depth = 16\nprint(list(model.parameters())[3].size())\n\n# Fully Connected Layer 1\nprint(list(model.parameters())[4].size())\n\n# Fully Connected Layer Bias\nprint(list(model.parameters())[5].size())","552ca4f1":"loss_list=[]\naccuracy_list=[]\niter_list=[]\n\niter = 0\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(trainloader):\n        # Load images\n        images = images.requires_grad_()\n\n        # Clear gradients w.r.t. parameters\n        optimizer.zero_grad()\n\n        # Forward pass to get output\/logits\n        outputs = model(images.float())\n\n        # Calculate Loss: softmax --> cross entropy loss\n        loss = criterion(outputs, labels)\n\n        # Getting gradients w.r.t. parameters\n        loss.backward()\n\n        # Updating parameters\n        optimizer.step()\n\n        iter += 1\n\n        if iter % 10 == 0:\n            # Calculate Accuracy         \n            correct = 0\n            total = 0\n            # Iterate through test dataset\n            for images, labels in testloader:\n                # Load images\n                images = images.requires_grad_()\n\n                # Forward pass only to get logits\/output\n                outputs = model(images.float())\n\n                # Get predictions from the maximum value\n                _, predicted = torch.max(outputs.data, 1)\n\n                # Total number of labels\n                total += labels.size(0)\n\n                # Total correct predictions\n                correct += (predicted == labels).sum()\n\n            accuracy = 100 * correct \/\/ total\n\n            # Print Loss\n            accuracy_list.append(accuracy)\n            loss_list.append(loss.item())\n            iter_list.append(iter)\n            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))","74b41a9c":"%matplotlib inline\nacc = accuracy_list\nloss = loss_list\niteration=iter_list\n\nplt.plot(iteration, acc, 'r', label='Model accuracy')\nplt.plot(iteration, loss, 'b', label='Model Loss')\nplt.title('Accuracy and Loss')\nplt.legend()\nplt.figure()\n\n","a60866ea":"plt.plot(iteration, acc, 'r', label='Model accuracy')\n#plt.plot(iteration, loss, 'b', label='Model Loss')\nplt.title('Accuracy and Loss')\nplt.legend()\nplt.figure()","c29646c0":"#plt.plot(iteration, acc, 'r', label='Model accuracy')\nplt.plot(iteration, loss, 'b', label='Model Loss')\nplt.title('Accuracy and Loss')\nplt.legend()\nplt.figure()","8c117e52":"## Building Model","07468ca5":"I will use y_for_pred data for rediction later please upvote","89a325e2":"* Male==0\n* Female==1\n\nAccording to pictures of people(I dont have much idea what this numbers refer to which ethnics)\n\n* 0==White\n* 1==Black\n* 2==Asian\n* 3==\u0130ndian\n* 4==Latin\n","260cb284":"## Gender Prediction","cf859f88":"## Gender Classification(Pytorch)","6194b6cb":"70 false prediction","6eb00186":"## Building Model(Keras)"}}