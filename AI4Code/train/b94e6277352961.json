{"cell_type":{"1440cf45":"code","9d0957ee":"code","5ae152c2":"code","8eabe538":"code","258b6af2":"code","4219dceb":"code","1b5a2826":"code","35ccbc8f":"code","801d1483":"code","2a6b645b":"code","a3d113b2":"code","61da16bf":"code","3cafdda0":"code","628b9103":"code","59291b05":"code","b1c4263c":"code","a8cf2a33":"code","a243268e":"code","e35b983b":"code","246ab657":"code","41e29278":"code","2ec96415":"markdown","397ac09d":"markdown"},"source":{"1440cf45":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9d0957ee":"from keras.preprocessing import image\n\nimg1 = image.load_img(\"..\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\/000001.jpg\", target_size = (128, 128))\nimg1_arr = image.img_to_array(img1, dtype = 'int64')\nimg1_arr = np.asarray(img1_arr)","5ae152c2":"img1_arr","8eabe538":"import matplotlib.pyplot as plt\nplt.imshow(img1_arr)\nplt.show()","258b6af2":"# Load all the images from the dataset\n\npath = \"..\/input\/celeba-dataset\/img_align_celeba\/img_align_celeba\"\ndef load_image_data(path):\n    \n    ''' Reads the images from the path and returns the images in to form of numpy array.'''\n    \n    img_folder = os.listdir(path)\n    \n    # Create an Image data list\n    img_data = []\n    \n    # Iterate over each image load it using image.load_img and then convert it using img_to_array\n    for img in img_folder[:5000]:\n        \n        # load the img\n        ith_img = image.load_img(os.path.join(path,img), target_size = (128, 128))\n        ith_img_arr = image.img_to_array(ith_img, dtype = 'int64')\n        \n        # append into the list\n        img_data.append(ith_img_arr)\n        \n    return img_data","4219dceb":"len(os.listdir(path))","1b5a2826":"images = load_image_data(path)","35ccbc8f":"# Plot first 10 images\nplt.figure(figsize = (10, 10))\nfor i in range(10):\n    \n    plt.subplot(2, 5, i+1)\n    plt.imshow(images[i])","801d1483":"images[0].shape","2a6b645b":"images_arr = np.asarray(images)","a3d113b2":"images_arr = (images_arr.astype('float32') - 127.5)\/127.5","61da16bf":"np.max(images_arr), np.min(images_arr)","3cafdda0":"images_arr.shape[0]","628b9103":"from keras.layers import *\nfrom keras.models import Model, Sequential\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.optimizers import Adam","59291b05":"epochs = 50\nbatch_size = 256\nhalf_batch_size = 128\nno_of_batches = int(images_arr.shape[0]\/batch_size)\nnoise_dim = 100\nadam = Adam(lr = 2e-4, beta_1 = 0.5)","b1c4263c":"images_arr.shape","a8cf2a33":"# Define the Generator\n\ngenerator = Sequential()\ngenerator.add(Dense(16*16*128, input_shape = (noise_dim, )))\ngenerator.add(Reshape((16,16,128)))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n# Double the activation sie 32 X 32 X 64\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(64, kernel_size = (5,5), padding = 'same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n# Double the activation sie 64 X 64 X 32\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(32, kernel_size = (5,5), padding = 'same'))\ngenerator.add(LeakyReLU(0.2))\ngenerator.add(BatchNormalization())\n\n# Double the activation sie 128 X 128 X 3\ngenerator.add(UpSampling2D())\ngenerator.add(Conv2D(3,activation = 'tanh', kernel_size = (5,5), padding = 'same'))\n\n\n# Compile the model\ngenerator.compile(loss='binary_crossentropy', optimizer = adam)\ngenerator.summary()\n","a243268e":"# Build a Discriminator\ndiscriminator = Sequential()\n\n# Input layer with shape 128 X 128 X 3\ndiscriminator.add(Conv2D(32, (5,5), strides = (2,2), padding = 'same', input_shape =(128,128,3)))\ndiscriminator.add(LeakyReLU(0.2))\n\n# Reduce the size from 64 X 64 X 32 to 32 X 32 X 64\ndiscriminator.add(Conv2D(64, (5,5), strides = (2,2), padding = 'same'))\ndiscriminator.add(LeakyReLU(0.2))\n\n# Reduce the size further from 32 X 32 X 64 to 16 X 16 X 128\ndiscriminator.add(Conv2D(128, (5,5), strides = (2,2), padding = 'same'))\ndiscriminator.add(LeakyReLU(0.2))\n\n# Flatten the layer\ndiscriminator.add(Flatten())\ndiscriminator.add(Dense(1, activation = 'sigmoid'))\n\n# Compile the model\ndiscriminator.compile(loss = 'binary_crossentropy', optimizer = adam)\ndiscriminator.summary()\n","e35b983b":"discriminator.trainable = False\ngan_input = Input(shape = (noise_dim,))\ngenerated_img = generator(gan_input)\ngan_output = discriminator(generated_img)\n\n# Functional API\nmodel = Model(gan_input, gan_output)\nmodel.compile(loss = 'binary_crossentropy', optimizer = adam)\n","246ab657":"def plot_imgs(epoch, samples = 100):\n    \n    noise = np.random.normal(0,1, size = (samples, noise_dim))\n    generated_imgs = generator.predict(noise)\n    generated_imgs = generated_imgs.reshape(samples, 128, 128, 3)\n    \n    # Plot the generated images\n    plt.figure(figsize = (20, 20))\n    for i in range(samples):\n        \n        plt.subplot(10, 10, i+1)\n        plt.imshow(generated_imgs[i], interpolation = 'nearest')\n        plt.axis(\"off\")\n        \n    plt.tight_layout()\n    plt.show()\n    \n    ","41e29278":"# Training Loop\nfor epoch in range(epochs):\n    \n    epoch_d_loss = 0.\n    epoch_g_loss = 0.\n    \n    # Mini bathc SGD\n    for step in range(no_of_batches):\n        \n        # Step 1 train discriminator: 50% real data + 50% Fake images\n        \n        # Real Data\n        idx = np.random.randint(0, 5000, half_batch_size)\n        real_imgs = images_arr[idx]\n        \n        # Fake Data\n        noise = np.random.normal(0,1, size = (half_batch_size, noise_dim))\n        fake_imgs = generator.predict(noise)\n        \n        # Labels\n        real_y = np.ones((half_batch_size,1))*0.9\n        fake_y = np.zeros((half_batch_size,1))\n        \n        # Train our discriminator\n        d_real_loss = discriminator.train_on_batch(real_imgs, real_y)\n        d_fake_loss = discriminator.train_on_batch(fake_imgs, fake_y)\n        \n        d_loss = 0.5*d_real_loss + 0.5*d_fake_loss\n        \n        epoch_d_loss += d_loss\n        \n        # Train the generator (Considering Generator as frozen)\n        noise = np.random.normal(0,1, size = (batch_size, noise_dim))\n        ground_truth_y = np.ones((batch_size, 1))\n        \n        g_loss = model.train_on_batch(noise, ground_truth_y)\n        \n        epoch_g_loss =+ g_loss\n    \n    print(\"Epoch %d Disc. loss %.4f Generator Loss %.4f\"%((epoch+1), epoch_d_loss\/no_of_batches, epoch_g_loss\/no_of_batches))\n    if (epoch + 1)%5 == 0:\n        \n        plot_imgs(epoch)","2ec96415":"# Training the GANs","397ac09d":"# Building a DCGAN"}}