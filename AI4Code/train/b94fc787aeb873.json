{"cell_type":{"d22eea3b":"code","1005b1b3":"code","dcd59c0d":"code","98486ac4":"code","c90e053c":"code","c46e4cb8":"code","fcfd2d20":"code","cf1dc718":"code","93ebd647":"code","3674ad49":"code","178c5d19":"code","72a05375":"code","f0078039":"code","7ba0d266":"code","6fbc0585":"code","e15cf7aa":"code","1b752da9":"code","941948fb":"code","b3d54f17":"code","8c4cc9e9":"code","67f0959f":"code","d441480b":"code","b96992a1":"code","992136a9":"code","fda5c15a":"code","d9093c24":"code","3ae4c484":"code","f334ba4a":"code","5d73f8de":"markdown"},"source":{"d22eea3b":"# import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os","1005b1b3":"base_dir = \"..\/input\/new-plant-diseases-dataset\/new plant diseases dataset(augmented)\/New Plant Diseases Dataset(Augmented)\"\nimage_size = 224","dcd59c0d":"# train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255.0,\n#                                                             shear_range = 0.2,\n#                                                             zoom_range = 0.2,\n#                                                             width_shift_range = 0.2,\n#                                                             height_shift_range = 0.2,\n#                                                             fill_mode=\"nearest\")\n# batch_size = 32\n# train_data = train_datagen.flow_from_directory(os.path.join(base_dir,\"train\"),\n#                                                target_size=(image_size,image_size),\n#                                                batch_size=batch_size,\n#                                                class_mode=\"categorical\"                                               \n#                                               )","98486ac4":"# test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255.0)\n# test_data = test_datagen.flow_from_directory(os.path.join(base_dir,\"valid\"),\n#                                                target_size=(image_size,image_size),\n#                                                batch_size=batch_size,\n#                                                class_mode=\"categorical\"                                               \n#                                               )","c90e053c":"# categories = list(train_data.class_indices.keys())\n# print(categories)","c46e4cb8":"# train_data.image_shape","fcfd2d20":"!pip install tflite-model-maker","cf1dc718":"import os\n\nimport numpy as np\n\nimport tensorflow as tf\n#assert tf.__version__.startswith('2')\n\nfrom tflite_model_maker import model_spec\nfrom tflite_model_maker import image_classifier\nfrom tflite_model_maker.config import ExportFormat\nfrom tflite_model_maker.config import QuantizationConfig\nfrom tflite_model_maker.image_classifier import DataLoader\n\nimport matplotlib.pyplot as plt","93ebd647":"data = DataLoader.from_folder(os.path.join(base_dir,\"train\"))\nt_data = DataLoader.from_folder(os.path.join(base_dir,\"valid\")) ","3674ad49":"model = image_classifier.create(train_data = data, model_spec='efficientnet_lite1', validation_data=t_data, batch_size=64, epochs=2, train_whole_model=True)","178c5d19":"loss, accuracy = model.evaluate(t_data)","72a05375":"model.export(export_dir='effbmodel_1\/', tflite_filename='model_effb1.tflite', label_filename='model_effb1.txt')","f0078039":"model.export(export_dir='mobilebert\/', export_format=[ExportFormat.LABEL])","7ba0d266":"import sys\nsys.path.append('..\/input\/efficientnet-v2\/efficientnetv2')\n\nimport effnetv2_model","6fbc0585":"ls","e15cf7aa":"!pip install -q efficientnet >> \/dev\/null\nimport efficientnet.tfkeras as efn\nEFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]","1b752da9":"# base_model = keras.applications.ResNet50(weights=\"imagenet\",include_top=False,input_shape=(image_size,image_size,3))\n# base_model = effnetv2_model.get_model('efficientnetv2-b1', include_top=False, pretrained=True)\nbase_model = EFNS[1](input_shape= (image_size,image_size,3),weights='imagenet',include_top=False)","941948fb":"import keras\nimage_size = 224\nbase_model.trainable = True\ninputs = keras.Input(shape=(image_size,image_size,3))\nx = base_model(inputs)\nx = keras.layers.GlobalAveragePooling2D()(x)\nx = keras.layers.Dropout(0.2)(x)\nx = keras.layers.Dense(38,activation=\"softmax\")(x)\nmodel = keras.Model(inputs=inputs, outputs=x, name=\"LeafDisease_MobileNet\")","b3d54f17":"model.summary()","8c4cc9e9":"\noptimizer = keras.optimizers.Adam()\nloss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.01) \n#model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\nmodel.compile(optimizer=optimizer,loss=loss,metrics=['AUC', keras.metrics.CategoricalAccuracy()])","67f0959f":"history = model.fit(train_data,\n          validation_data=test_data,\n          epochs=10,\n                       \n          validation_steps=100\n         )","d441480b":"model.evaluate(test_data)","b96992a1":"model.save('plant_disease_effb1')","992136a9":"# Convert the model.\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model_effb1.tflite', 'wb') as f:\n    f.write(tflite_model)","fda5c15a":"# Convert the model\nconverter = tf.lite.TFLiteConverter.from_saved_model('\/kaggle\/working\/plant_disease_effb1\/') # path to the SavedModel directory\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n    f.write(tflite_model)","d9093c24":"converter = tf.lite.TFLiteConverter.from_saved_model('\/kaggle\/working\/plant_disease_effb1\/')\ntflite_model = converter.convert()\nopen(\"model_quantize.tflite\", \"wb\").write(tflite_model)\n#converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\nconverter.post_training_quantize=True\ntflite_quantized_model=converter.convert()\nopen(\"quantized_model.tflite\", \"wb\").write(tflite_quantized_model)","3ae4c484":"custom_opdef = \"\"\"name: 'TFLiteAwesomeCustomOp' input_arg:\n{ name: 'In' type: DT_FLOAT } output_arg: { name: 'Out' type: DT_FLOAT }\nattr : { name: 'a1' type: 'float'} attr : { name: 'a2' type: 'list(float)'}\"\"\"\n\n# Register custom opdefs before the invocation of converter API.\ntf.lite.python.convert.register_custom_opdefs([custom_opdef])\n\nconverter = tf.lite.TFLiteConverter.from_saved_model('\/kaggle\/working\/plant_disease_effb1\/')\nconverter.allow_custom_ops = True\ntflite_model = converter.convert()\n\nwith open('model_ops.tflite', 'wb') as f:\n    f.write(tflite_model)","f334ba4a":"acc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\n\nepochs = range(len(acc))\n\nfig = plt.figure(figsize=(10,6))\nplt.plot(epochs,acc,c=\"red\",label=\"Training\")\nplt.plot(epochs,val_acc,c=\"blue\",label=\"Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()","5d73f8de":"## Creating DataGenerator"}}