{"cell_type":{"f9fa9576":"code","49fa6886":"code","247332f0":"code","3c77f86c":"code","69ffa305":"code","2f423640":"code","55708496":"code","05b621c2":"code","c2f76cfd":"code","cdef28d3":"code","6109c59c":"code","998e7472":"code","6c7bd487":"code","203695c7":"code","efe55047":"code","34396175":"code","0f30bd1e":"code","44b65fea":"code","a7165b61":"code","31bcb10d":"code","49cc76aa":"code","fca31e66":"code","de710fd0":"code","842bb3bf":"code","6986d1fb":"code","f0cdcfb5":"code","986eeea5":"code","095c9a58":"markdown","1e3771d9":"markdown","28cf0ca4":"markdown","ea9fc7f1":"markdown","7c6191f3":"markdown"},"source":{"f9fa9576":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.utils import check_array\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.metrics import mean_absolute_error\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\n","49fa6886":"df = pd.read_csv('..\/input\/goodreadsbooks\/books.csv', error_bad_lines=False)\ndf.head()","247332f0":"# missing_val_count_by_column = (df.isnull().sum())\n# print(missing_val_count_by_column[missing_val_count_by_column > 0])\ndf.isnull().sum()","3c77f86c":"df.duplicated().unique()","69ffa305":"df.isna().sum()","2f423640":"s = (df.dtypes == 'object')\nobject_cols = list(s[s].index) \n# s returns True or False for each column, \n# s[s] returns only Trues, \n# s[s].index returns 'Index' list of columns with dtype = object\n# list(s[s].index) returns normal list of columns with dtype = object\nobject_cols\n","55708496":"for i in object_cols:\n    print(f'Unique values for \"{i}\" column: {len(df[i].unique())}')","05b621c2":"df.columns","c2f76cfd":"y = df.average_rating\nX = df[['title', 'authors', '  num_pages', 'ratings_count', 'text_reviews_count', 'publisher']] # 'language_code', 'publication_date'","cdef28d3":"corr = df.corr()\nsns.heatmap(corr, \n        xticklabels=corr.columns,\n        yticklabels=corr.columns)","6109c59c":"df.describe()","998e7472":"train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)","6c7bd487":"print(f'Length of training set: {len(train_X)}')\nprint(f'Length of testing set: {len(val_X)}')","203695c7":"s = (X.dtypes == 'object')\nobject_cols = list(s[s].index) \nobject_cols","efe55047":"print(f'Columns number for train_X: {len(train_X.columns)}')\nprint(f'Columns number for val_X: {len(val_X.columns)}')","34396175":"OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[object_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = train_X.index\nOH_cols_valid.index = val_X.index\n\n# One-hot encoding didn't assign column names for new added columns; put them using get_feature_names\nOH_cols_train.columns = OH_encoder.get_feature_names(object_cols)\nOH_cols_valid.columns = OH_encoder.get_feature_names(object_cols)\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_train_X = train_X.drop(object_cols, axis=1)\nnum_val_X = val_X.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_train_X = pd.concat([num_train_X, OH_cols_train], axis=1)\nOH_val_X = pd.concat([num_val_X, OH_cols_valid], axis=1)","0f30bd1e":"def mean_absolute_percentage_error(y_true, y_pred):\n    y_true = y_true.copy()\n    y_true[y_true == 0] = 0.00000000000001\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs(np.divide((y_true - y_pred), y_true)))*100","44b65fea":"regressor = KNeighborsRegressor(n_neighbors=5, weights='distance')\nregressor.fit(OH_train_X, train_y)","a7165b61":"prediction = regressor.predict(OH_val_X)","31bcb10d":"mae_regressor = mean_absolute_error(prediction, val_y)\n#print(f'KNeighborsRegressor MAPE: {mean_absolute_percentage_error(val_y, prediction)}')","49cc76aa":"pd.DataFrame(data={'predicted average rate': prediction, 'average rate': val_y})","fca31e66":"mlr = LinearRegression()\nmlr.fit(OH_train_X, train_y) ","de710fd0":"prediction = mlr.predict(OH_val_X)\nmae_mlr = mean_absolute_error(prediction, val_y)\n#print(f'KNeighborsRegressor MAPE: {mean_absolute_percentage_error(val_y, prediction)}')","842bb3bf":"pd.DataFrame(data={'predicted average rate': prediction, 'average rate': val_y})","6986d1fb":"rand = RandomForestRegressor(n_estimators=50, random_state=0)\nrand.fit(OH_train_X, train_y) ","f0cdcfb5":"prediction = mlr.predict(OH_val_X)\nmae_rand = mean_absolute_error(prediction, val_y)","986eeea5":"print(f'KNeighborsRegressor MAE: {mae_regressor}')\nprint(f'Multiple Linear Regression MAE: {mae_mlr}')\nprint(f'Random Forest Regressor MAE: {mae_rand}')","095c9a58":"a. KNeighborsRegressor","1e3771d9":"1. Missing values","28cf0ca4":"2. Categorical data","ea9fc7f1":"b. Multiple Linear Regression","7c6191f3":"c. Random Forest Regressor"}}