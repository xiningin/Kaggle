{"cell_type":{"91e40088":"code","151c2003":"code","723c395f":"code","2c9b07bd":"code","f276870d":"code","bb45a1e2":"code","dbb40749":"code","dc20e531":"code","f0b49904":"code","de736052":"code","786e6840":"code","5187eb9c":"code","51d13e95":"code","45d9c57a":"code","5019c91e":"code","b20fc873":"code","e7b172d5":"code","5f43694a":"code","bf8af98e":"markdown"},"source":{"91e40088":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","151c2003":"df = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()\nX = df.iloc[:,2:32]\nY = df.iloc[:,1]","723c395f":"Y = Y.map({'M' : 0 , 'B' : 1})\nY = Y[:,np.newaxis]\nY.shape","2c9b07bd":"from sklearn.model_selection import train_test_split\nx,x_t,y,y_t = train_test_split(X,Y,random_state = 3,test_size = 0.2)\nx,x_t,y,y_t = x.T,x_t.T,y.T,y_t.T","f276870d":"x = (x - np.min(x))\/(np.max(x) - np.min(x)).values ","bb45a1e2":"def sigmoid(z):\n    return 1\/(1 + np.exp(-z))","dbb40749":"def costFunction(theta,x,y):\n    z = np.dot(theta.T,x)\n    pred = sigmoid(z)\n    cost = -y*np.log(pred) - (1-y)*np.log(1-pred)\n    loss = np.sum(cost)\/x.shape[1]\n    return loss\n    ","dc20e531":"def gradient(theta,x,y):\n    z = np.dot(theta.T,x)\n    pred = sigmoid(z)\n    grad = np.sum(np.dot(x,(pred-y).T))\n    return grad\/x.shape[1]","f0b49904":"def gradientDescent(theta,x,y,a,iter_max):\n    J_hist = []\n    for _ in range(iter_max):\n        grad = gradient(theta,x,y)\n        theta -= a*grad\n        J_hist.append(costFunction(theta,x,y))\n    \n    plt.plot(J_hist,range(iter_max))\n    plt.show()\n    return theta","de736052":"def predict(theta,x):\n    z = np.dot(theta.T,x)\n    pred = sigmoid(z)\n    res = [1 if i > 0.5 else 0 for i in pred[0] ]\n    return res","786e6840":"def accuracy(y_hat,y_true):\n    acc = np.sum(y_hat == y_true)\/len(y_true)\n    return acc","5187eb9c":"a = 0.01\ni = 1000\ntheta = np.zeros(x.shape[0]).reshape((x.shape[0],1))\nitheta = theta\ntheta.shape","51d13e95":"costFunction(theta,x,y)","45d9c57a":"theta = gradientDescent(theta,x,y,a,i)","5019c91e":"costFunction(theta,x,y)","b20fc873":"x_t = (x_t - np.min(x_t))\/(np.max(x_t) - np.min(x_t)).values ","e7b172d5":"y_hat = predict(theta,x_t)","5f43694a":"accuracy(y_hat,y_t)","bf8af98e":"import scipy.optimize as opt\nout = opt.fmin_cg(f = costFunction, x0 = itheta, fprime = gradient, args = (x,y.flatten()), maxiter = 400)"}}