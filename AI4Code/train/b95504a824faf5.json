{"cell_type":{"0577bd5a":"code","aedca2f1":"code","57e5545f":"code","e9b617e0":"code","d034da6e":"code","1e837da5":"code","4ac8b24f":"code","391ce35d":"code","1128cba4":"code","150abe4b":"code","5b7635aa":"code","c96f77a5":"code","28444651":"code","9b9f0f6c":"code","80fbc1b4":"code","3cbeb51d":"code","64d4aeb9":"code","ca3726fa":"code","8d6fefa6":"code","a958d4c9":"code","dd41a181":"code","12f024a6":"code","8ffcf944":"code","b68a7a84":"code","d57f033f":"code","472aac70":"code","e87f0542":"code","8fbeb3ae":"code","fe43047c":"code","a2e8bac3":"code","0cdf49b1":"code","bd7bffe4":"code","324b4c90":"code","8957a2fc":"code","f92c62b4":"code","fc64b38f":"code","b049ded1":"code","59016a4e":"code","e142051a":"code","a83ee6b2":"code","947d5700":"code","f4387a5c":"code","f3ec9fb7":"code","29136406":"code","dc7bafc9":"code","bb5dfbcd":"code","cce07e9d":"code","f9ede9e4":"code","cc205bbc":"code","c5f1cebb":"code","df335c24":"code","abf03580":"code","ac17618a":"code","fd579483":"code","93df5abb":"code","c10dbea3":"code","53716d2a":"code","3774f779":"code","6fae933c":"code","874d83c8":"code","92c1cae7":"code","d3012c37":"code","9b9efa23":"code","b9d3b7a3":"code","513af29e":"code","9143be0b":"code","7f299805":"code","02490cc2":"code","d6001547":"code","4b00d85f":"code","32a5260f":"code","c8d1f9d3":"markdown","67c5136e":"markdown","761c208a":"markdown","51d9b136":"markdown","82aeed6a":"markdown","154cf6d3":"markdown","068236a9":"markdown","d4a3a691":"markdown","e94cfdbf":"markdown","dc96aaa9":"markdown","a4ce96fb":"markdown","49e93eee":"markdown","850a8ab3":"markdown","81f74d9b":"markdown","2bb355c4":"markdown","e712d9a5":"markdown","178dc718":"markdown","da0aba40":"markdown","e04cc748":"markdown","6efa9c85":"markdown","c432b42a":"markdown","dd8232a0":"markdown","acd47c6e":"markdown"},"source":{"0577bd5a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aedca2f1":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_PassengerId = test_df['PassengerId']\n","57e5545f":"train_df.columns","e9b617e0":"train_df.head()","d034da6e":"train_df.info()","1e837da5":"def bar_plot(variable):\n    \"\"\"\n    input: variable ex: \"Sex\"\n    output: bar plot & value count\n    \"\"\"\n    #get feature\n    var = train_df[variable]\n    #count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    #visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index,varValue) #x = 0 or 1 y = varValue\n    plt.xticks(varValue.index,varValue.index.values)\n    plt.ylabel('Frequency')\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}:\".format(variable,varValue))","4ac8b24f":"category1 = ['Survived','Sex','Pclass','Embarked','SibSp','Parch']\nfor c in category1:\n    bar_plot(c)","391ce35d":"category2 = ['Cabin','Name','Ticket']\nfor c in category2:\n    print(\"{}: \\n\".format(train_df[c].value_counts()))","1128cba4":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable],bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel('Frequency')\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","150abe4b":"numericVar = [\"Fare\",\"Age\",\"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","5b7635aa":"# Pclass vs Survived\ntrain_df[['Pclass','Survived']].groupby(['Pclass'],as_index = False).mean().sort_values(by = 'Survived', ascending = False)\n","c96f77a5":"# Sex vs Survived\ntrain_df[['Sex','Survived']].groupby(['Sex'],as_index = False).mean()","28444651":"#SibSp vs Survived\ntrain_df[['SibSp','Survived']].groupby(['SibSp']).mean()","9b9f0f6c":"#Parch vs Survived\ntrain_df[['Parch','Survived']].groupby(['Parch']).mean()","80fbc1b4":"def detect_outlier(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # First Quartile\n        \n        Q1 = np.percentile(df[c],25)\n        \n        \n        # Third Quartile\n        Q3 = np.percentile(df[c],75)\n        \n        \n        # IQR\n        IQR = Q3 - Q1\n        \n        # Outlier Step\n        outlier_step = IQR * 1.5\n        \n        # Detect outlier and their indeces\n        \n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        \n        # St indexes\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers\n    \n    ","3cbeb51d":"train_df.loc[detect_outlier(train_df,['Age','SibSp','Parch','Fare'])]","64d4aeb9":"#\u00a0Drop Outliers\ntrain_df = train_df.drop(detect_outlier(train_df,['Age','SibSp','Parch','Fare']),axis = 0).reset_index(drop = True)","ca3726fa":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis = 0 ).reset_index(drop = True)","8d6fefa6":"train_df.head()","a958d4c9":"train_df.columns[train_df.isnull().any()]","dd41a181":"train_df.isnull().sum()","12f024a6":"train_df[train_df['Embarked'].isnull()]","8ffcf944":"train_df.boxplot(column = 'Fare',by = 'Embarked')\nplt.show()","b68a7a84":"train_df['Embarked'] = train_df['Embarked'].fillna('C')","d57f033f":"train_df[train_df['Embarked'].isnull()]","472aac70":"train_df[train_df['Fare'].isnull()]","e87f0542":"train_df['Fare'] = train_df['Fare'].fillna(np.mean(train_df[train_df['Pclass'] == 3]['Fare']))","8fbeb3ae":"train_df[train_df['Fare'].isnull()]","fe43047c":"train_df[train_df['Age'].isnull()]","a2e8bac3":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","0cdf49b1":"#index_nan_age","bd7bffe4":"train_df[train_df['Age'].isnull()]","324b4c90":"name  = train_df['Name']\ntrain_df['Title'] = [i.split('.')[0].split(',')[-1].strip() for i in name]","8957a2fc":"#name","f92c62b4":"train_df.Title.value_counts()","fc64b38f":"# to categorical\ntrain_df['Title'] =train_df['Title'].replace(['Lady','the Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'Other')\ntrain_df['Title'] = [0 if i == 'Master' else 1 if i == 'Miss' or i == 'Ms' or i == 'Mlle' or i == 'Mrs' else 2 if i == 'Mr' else 3 for i in train_df['Title']]","b049ded1":"train_df.Title.value_counts()","59016a4e":"import seaborn as sns\ng = sns.factorplot(x = 'Title', y = 'Survived',data = train_df,kind = 'bar')\ng.set_xticklabels(['Master','Mrs','Mr','Other'])\ng.set_ylabels('Survival Probability')\nplt.show()\n\n","e142051a":"train_df.drop(labels = ['Name'],axis = 1,inplace = True)","a83ee6b2":"train_df.head()","947d5700":"train_df = pd.get_dummies(train_df,columns = ['Title'])\ntrain_df.head()","f4387a5c":"#train_df.head()","f3ec9fb7":"train_df['Fsize'] = train_df['SibSp'] + train_df['Parch'] + 1","29136406":"train_df.head()","dc7bafc9":"g = sns.factorplot(x = 'Fsize',y = 'Survived',kind = 'bar',data = train_df)\ng.set_ylabels('Survival ')\ng.set_xlabels('Family Size')\nplt.show()","bb5dfbcd":"train_df['family_size'] = [1 if i <5 else 0 for i in train_df['Fsize']]","cce07e9d":"sns.countplot(x = 'family_size', data = train_df)\nplt.show()","f9ede9e4":"g = sns.factorplot(x = 'family_size',y = 'Survived',kind = 'bar',data = train_df)\ng.set_ylabels('Survived ')\n\nplt.show()","cc205bbc":"train_df = pd.get_dummies(train_df,columns = ['family_size'])\ntrain_df.head()","c5f1cebb":"train_df = pd.get_dummies(train_df,columns = ['Embarked'])\ntrain_df.head()","df335c24":"train_df['Ticket'].head(20)","abf03580":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace('.','').replace('\/','').strip().split(' ')[0])\n    else:\n        tickets.append('x')\n        \ntrain_df['Ticket'] = tickets","ac17618a":"#train_df.Ticket","fd579483":"train_df = pd.get_dummies(train_df, columns = ['Ticket'],prefix = 'T')\n#train_df.head(2)","93df5abb":"train_df.head(3)","c10dbea3":"sns.countplot(x = 'Pclass',data = train_df)\nplt.show()","53716d2a":"train_df['Pclass'] = train_df['Pclass'].astype('category')\ntrain_df = pd.get_dummies(train_df, columns = ['Pclass'])\ntrain_df.head()","3774f779":"train_df['Sex'] = train_df['Sex'].astype('category')\ntrain_df = pd.get_dummies(train_df,columns = ['Sex'])\ntrain_df.head()","6fae933c":"train_df.drop(labels = ['PassengerId','Cabin'],axis = 1 , inplace = True)","874d83c8":"train_df.head()","92c1cae7":"from sklearn.model_selection import train_test_split, StratifiedKFold,GridSearchCV\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score , f1_score\nfrom catboost import CatBoostClassifier","d3012c37":"print(train_df_len)","9b9efa23":"test = train_df[train_df_len:]\ntest.drop(labels = ['Survived'],axis = 1, inplace = True)","b9d3b7a3":"test.head()","513af29e":"train = train_df[:train_df_len]\nX_train = train.drop(labels = 'Survived',axis = 1)\ny_train = train['Survived']\nX_train , x_test , y_train , y_test = train_test_split(X_train,y_train,test_size = 0.33,random_state = 42)\nprint('X_train',len(X_train))\nprint('x_test',len(x_test))\nprint('y_train',len(y_train))\nprint('y_test',len(y_test))","9143be0b":"#?CatBoostClassifier","7f299805":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n              GaussianNB(),\n              KNeighborsClassifier(),\n              LGBMClassifier(),\n              #CatBoostClassifier()\n                ]\n\ndt_param_grid = {'min_samples_split': range(10,500,20),\n                'max_depth': range(1,20,2)}\n\n\n\ngaussian_param_grid = {}\n\n\nknn_param_grid = {'n_neighbors': np.linspace(1,19,10, dtype = int).tolist(),\n                 'weights': ['uniform','distance'],\n                 'metric': ['euclidean','manhattan']}\n\nlgbm_param_grid = {'n_estimators': range(100,200,10),\n                  'max_depth': range(1,20,2),\n                  'learning_rate': [0.01,0.05,0.1]\n                  }\n#\nclassifier_param = [dt_param_grid ,gaussian_param_grid,knn_param_grid ,lgbm_param_grid]","02490cc2":"cv_results = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i],param_grid= classifier_param[i],cv = StratifiedKFold(n_splits = 10),scoring = 'f1',n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_results.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_results[i])","d6001547":"cv_result = pd.DataFrame({'Cross Validation Means': cv_results, 'ML Models': ['DecisionTreeClassifier',\n              'NaiveBayes',\n              'KNeighborsClassifier',\n              'LGBMClassifier'\n              \n                ] })\n\ng = sns.barplot('Cross Validation Means','ML Models',data = cv_result)\ng.set_xlabel('Mean Score')\ng.set_title('Cross Validation Scores')\nplt.show()","4b00d85f":"cv_result","32a5260f":"best_estimators","c8d1f9d3":"<a id = '9'> <\/a>\n## Find Missing Value","67c5136e":"<a id = '7' > <\/a>\n\n# Outlier Detection","761c208a":" * float64(2): Fare and Age\n * int64(5): Pclass, SibSp, Parch, Survived and PassengerId\n * object(5): Name, Sex, Ticket, Cabin, Embarked","51d9b136":"<a id = '11'><\/a>\n## Fill Missing: Age Feature","82aeed6a":"<a id = '16'><\/a>\n## Pclass","154cf6d3":"<a id = '15'><\/a>\n## Ticket","068236a9":"<a id = '3' > <\/a><br>\n# Univariate Variable Analysis\n\n   * Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp and Parch\n   * Numerical Variable: Age, PassengerId and Fare","d4a3a691":"<a id = '19'><\/a>\n# MODEL","e94cfdbf":"<a id = '14'><\/a>\n## Embarked","dc96aaa9":"<a id = '10'> <\/a>\n## Fill Missing Value\n* Embarked has 2 missing value\n* Fare has only 1","a4ce96fb":"<a id = '5' > <\/a><br>\n## Numerical Variable","49e93eee":"<a id = '20'><\/a>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\n* Naive Bayes Classifier\n* Decision Tree Classifier\n* K-Nearest Neighbor Classifier\n* LightGBM Classifier\n","850a8ab3":"* People who take in class one are much more likely to survive","81f74d9b":"<a id = '21'><\/a>\n## Conclusion","2bb355c4":"<a id = '8' > <\/a>\n# Missing Value\n  * Find Missing Value\n  * Fill Missing Value","e712d9a5":"<a id = '17'><\/a>\n## Sex","178dc718":" ## Introduction \n- The sinking of Titanic is one of the most notorious shipwrecks in the history. During her voyage, the Titanic sank after colliding with an iceberg. killing 1502 out of 2224 passengers and crew.\n\n<font color = \"blue\">\nContent:\n\n1. [Load and check Data](#1)\n2. [Variable Description](#2)\n * [Univariate Variable Analysis](#3)\n   * [Categorical Variable Analysis](#4)\n   * [Numerical Variable Analysis](#5)\n1. [Basic Data Analysis](#6)\n1. [Outlier Detection](#7)\n1. [Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n    * [Fill Missing: Age Feature](#11)\n1. [Feature Engineering](#12)\n    * [Family Size](#13)\n    * [Embarked](#14)\n    * [Ticket](#15)\n    * [Pclass](#16)\n    * [Sex](#17)\n    * [Drop PassengerId and Cabin](#18)\n1. [MODELING](#19)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#20)\n    * [Conclusion](#21)\n","da0aba40":"<a id = \"2\" ><\/a><br>\n# Variable Description\n1. PassengerId: unique id number to each passenger\n2. Survived: passenger survive(1) or died(0)\n3. Pclass: passenger class\n4. Name: name\n5. Sex: gender of passenger\n6. Age: age of passenger\n7. SibSp: number of siblings\/spouses\n8. Parch: number of parents\/children\n9. Ticket: number of ticket\n10. Fare: amount of money spent on ticket\n11. Cabin: cabin category\n12. Embarked: port where passenger embarked(C = Cherbourg, Q = Queenstown, S = Southampton)\n\n","e04cc748":"<a id = '6'><\/a>\n# Basic Data Analysis\n\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived\n<br> ","6efa9c85":"<a id = '12' ><\/a>\n# Feature Engineering","c432b42a":"<a id = '18'><\/a>\n## Drop PassengerId and Cabin","dd8232a0":"<a id = \"1\"><\/a>\n# Load and Check Data","acd47c6e":"<a id = '13'> <\/a>\n## Family Size"}}