{"cell_type":{"ca6ead6a":"code","734338cd":"code","c9aece90":"code","16bbf1a3":"code","8fc68c40":"code","4f7e5400":"code","7050eddd":"code","31ce8d5a":"code","586f5c6d":"code","acf2b2cf":"code","6dadb070":"code","45f94e90":"code","5aa0f22f":"code","199d7f99":"code","7536c6e6":"code","d12283d6":"code","83a37d61":"markdown","e3a4d7a6":"markdown","19cebf70":"markdown","e1d826f1":"markdown","2a304226":"markdown","428bcd65":"markdown","cb279b7d":"markdown","0e0657bb":"markdown","2c5bee00":"markdown","e0aa9932":"markdown","00d71613":"markdown","79accc23":"markdown","724388fc":"markdown","a7c1f975":"markdown","10631d30":"markdown","2ad1f2ce":"markdown","19fec041":"markdown","f9bfa222":"markdown","5e9484c1":"markdown"},"source":{"ca6ead6a":"import os\nimport torch\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport random\nimport time\n\nfrom torch.utils.data import Dataset, random_split, DataLoader\nfrom PIL import Image\nimport torchvision.models as models\nfrom tqdm.notebook import tqdm\nimport torchvision.transforms as T\n\nfrom sklearn.metrics import f1_score\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\n","734338cd":"# Load the paths to the images in a directory\n\ndef load_images_from_folder(folder,only_path = False, label = \"\"):\n    if only_path == False:\n        images = []\n        file_name=[]\n        for filename in os.listdir(folder):\n            img = plt.imread(os.path.join(folder,filename))\n            \n            if img is not None:\n                end=filename.find(\".\")\n                file_name.append(file[0:end])\n                images.append(img)\n                \n        return images, file_name\n    else:\n        path = []\n        for filename in os.listdir(folder):\n            img_path = os.path.join(folder,filename)\n            if img_path is not None:\n                path.append([label,img_path])\n        return path","c9aece90":"# Load the paths on the images\nimages = []\npath = \"..\/input\/insect-identification-from-habitus-images\/database\/\"\nfor f in os.listdir(path):\n    if \"jpg\" in os.listdir(path+f)[0]:\n        images += load_images_from_folder(path+f,True,label = f)\n      \n    else: \n        for d in os.listdir(path+f):\n            images += load_images_from_folder(path+f+\"\/\"+d,True,label = f)\n            \n                        \n# Create a dataframe with the paths and the label for each insect\ndf1 = pd.DataFrame(images, columns = [\"insect_gbif\", \"path_img\"])\n\nfile_name=[]\nfor i in range(len(df1[\"path_img\"])):\n    temp=df1.path_img[i].split('\/')[-1].split('.')[0]\n    file_name.append(temp)\nfile_name\n\ndf1['file_name'] = file_name\ndisplay(df1.describe())\n\ndisplay(df1)\n","16bbf1a3":"labels = df1[\"insect_gbif\"].unique()\n\nlabels_dict = dict(zip(range(len(labels)),labels))\nlabels_dict ","8fc68c40":"num_images = len(df1[\"insect_gbif\"])\nprint('Number of images are:', num_images)\nno_labels=len(labels)\nprint('Number of insect species are:', no_labels)","4f7e5400":"bar = df1[\"insect_gbif\"].value_counts(ascending=True).plot.barh(figsize = (30,120))\nplt.title(\"Distribution of the insect species\", fontsize = 20)\nbar.tick_params(labelsize=16)\nplt.show()","7050eddd":"df1[\"insect_gbif\"].value_counts()","31ce8d5a":"train, validate, test = np.split(df1.sample(frac=1), [int(.6*len(df1)), int(.8*len(df1))])\n\ndisplay(train.describe())\ndisplay(validate.describe())\ndisplay(test.describe())","586f5c6d":"df=train.append(test, ignore_index=True)\ndf.describe()","acf2b2cf":"# Shuffle the dataset\nfrom sklearn.utils import shuffle\ndf = shuffle(df, random_state = 0)\ndf = df.reset_index(drop=True)\n\n# Display 20 picture of the dataset with their labels\nfig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df.path_img[i]))\n    ax.set_title(df.insect_gbif[i])\nplt.tight_layout()\nplt.show()","6dadb070":"imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\ntrain_tfms = T.Compose([\n#this will resize the image \n    T.Resize((256,256)),   \n   \n#Randomly change the brightness, contrast and saturation of an image\n#    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),    \n\n#this will remove parts (crop) the Image at a random location.   \n#    T.RandomCrop(32, padding=4, padding_mode='reflect'),   \n\n#Horizontally flip (rotate by 180 degree) the given image randomly; default is 50% of images\n    T.RandomHorizontalFlip(), \n    \n#Rotate the image by angle -here by 10%\n    T.RandomRotation(10),\n    \n#convert it to a tensor   \n    T.ToTensor(),\n\n#Normalize a tensor image with mean and standard deviation - here with the Imagenet stats\n    T.Normalize(*imagenet_stats,inplace=True)\n    \n#Randomly selects a rectangle region in an image and erases its pixels.    \n#    T.RandomErasing(inplace=True)\n])\n\nval_tfms = T.Compose([\n#this will resize the image \n    T.Resize((256,256)),   \n     \n#convert it to a tensor   \n    T.ToTensor(),\n\n#Normalize a tensor image with mean and standard deviation - here with the Imagenet stats\n    T.Normalize(*imagenet_stats,inplace=True)\n    \n])","45f94e90":"class InsectDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n        \n        \n    def __len__(self):\n        return len(self.df)    \n    \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_id, img_label = row['path_img'], row['insect_gbif']\n        img = Image.open(img_id)\n        if self.transform:\n            img = self.transform(img)\n        return img, img_label","5aa0f22f":"train_ds = InsectDataset(train,transform=train_tfms)\nval_ds = InsectDataset(validate, transform=val_tfms)","199d7f99":"def show_sample(img, target, invert=True):\n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    print('Labels:', target)","7536c6e6":"show_sample(*train_ds[241])","d12283d6":"show_sample(*train_ds[1149], invert= False)","83a37d61":"lets also make a table.. may be better as there are 200+ species","e3a4d7a6":"Some may prefer only test abd validation\n\nyou may combine two data sets- this will result in only train and validation set\n\ncomment or delete the below code if you want three sets of data","19cebf70":"# Insect Identification & Classification Project","e1d826f1":"# Lets GO!!","2a304226":"# Image Analysis","428bcd65":"It is a very unbalanced data. Some insect species have only 50 images, while others have 888!","cb279b7d":"# Image transforms using PyTorch","0e0657bb":"Let us look at the data and make some initial conclusions","2c5bee00":"# Exlporatory Data Analysis (EDA)","e0aa9932":"This is an image classification problem of 291 species of Insects using  63,364 images from the Natural History Museum London\n\nSource: https:\/\/zenodo.org\/record\/3549369#.XvI_jMfVLIU","00d71613":"# View Sample Images after Transform","79accc23":"# Split data into test, train and validation","724388fc":"# Set up the data and a label dictionary","a7c1f975":"Are images equally distributed between different insect species?\n\nLet's plot a graph and see!","10631d30":"#  Import Libraries","2ad1f2ce":"# Read the data","19fec041":"Let us display 20 picture of the dataset with their labels","f9bfa222":"What do you observe?\n\nAll images are of differnt sizes\n\nThe backgrounsd vary a bit and as these are from a museum, there are the nals and other marks","5e9484c1":"Lets make an image classification model! Hope this is a good starter for you!\n\nThanks and all the best!"}}