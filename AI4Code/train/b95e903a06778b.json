{"cell_type":{"82435ca0":"code","d4e427d6":"code","6e1f515f":"code","3bba7561":"code","2b9d10b0":"code","3cf7d592":"code","606e8d46":"code","e5032c46":"code","6c54d6c4":"code","1f9eec41":"code","460827a1":"code","c114abe1":"code","bbb646f9":"code","2c47b36a":"code","aa325276":"code","d69e66f8":"code","b0cd5390":"code","97186432":"code","a46d79f4":"code","f301bb93":"code","3c54d951":"code","01b4c1b5":"code","b120c76f":"code","590570ae":"code","b4011bdb":"code","d5dff585":"code","071dbb70":"code","74a653fc":"code","144cab69":"code","e9990752":"code","d55891e8":"code","406afec0":"markdown","2e165a0d":"markdown","1de24a7d":"markdown","824bfe8e":"markdown","d79e5ca6":"markdown","e61ae0a1":"markdown","996f3c82":"markdown","9f184e06":"markdown","010222da":"markdown","cab0e4b5":"markdown","a5ec2b27":"markdown","1c6e1ffd":"markdown","91517790":"markdown","a6b77457":"markdown","a88c3160":"markdown","7f6ffffd":"markdown","06fc3c6d":"markdown","7ba4322d":"markdown","b370e070":"markdown","6fb7ba96":"markdown","05dff257":"markdown","cb1b7d60":"markdown","ff1e445f":"markdown","451f89af":"markdown","35df75ab":"markdown","4f9df462":"markdown"},"source":{"82435ca0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4e427d6":"%pip install fastai2","6e1f515f":"%pip install fastcore==0.1.35 ##Currently supported with fastai2","3bba7561":"import fastcore\nfastcore.__version__","2b9d10b0":"import fastai2\nfastai2.__version__","3cf7d592":"from fastai2.tabular.all import *","606e8d46":"df_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_train.head()","e5032c46":"df_train.describe()","6c54d6c4":"df_train.isnull().sum().sort_index()\/len(df_train)","1f9eec41":"g_train = df_train.columns.to_series().groupby(df_train.dtypes).groups; g_train","460827a1":"cat_names= [\n        'Name', 'Sex', 'Ticket', 'Cabin', \n        'Embarked'\n]\n\ncont_names = [ \n    'PassengerId', 'Pclass', 'SibSp', 'Parch', \n    'Age', 'Fare'\n ]\n\n","c114abe1":"splits = RandomSplitter(valid_pct=0.2)(range_of(df_train))\n\nto = TabularPandas(df_train, procs=[Categorify, FillMissing,Normalize],\n                   cat_names = cat_names,\n                   cont_names = cont_names,\n                   y_names='Survived',\n                   splits=splits)","bbb646f9":"to.train.xs.columns.to_series().groupby(to.train.xs.dtypes).groups","2c47b36a":"to.train.xs.Age_na.sample(10)","aa325276":"to.train","d69e66f8":"to.train.xs","b0cd5390":"to.train.ys","97186432":"### RANDOM FOREST\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_train, y_train = to.train.xs, to.train.ys.values.ravel()\nX_valid, y_valid = to.valid.xs, to.valid.ys.values.ravel()","a46d79f4":"X_train.sample(10)","f301bb93":"rnf_classifier = RandomForestClassifier(n_estimators=100, n_jobs=-1)\nrnf_classifier.fit(X_train,y_train)","3c54d951":"from sklearn.metrics import accuracy_score\n\n\ny_pred = rnf_classifier.predict(X_valid)\naccuracy_score(y_pred, y_valid)","01b4c1b5":"accuracy_score(\n    np.array(X_valid.Sex.values == 1, dtype=int).reshape((len(X_valid), 1)),\n    y_valid)","b120c76f":"df_test.sample(10)","590570ae":"test = TabularPandas(df_test, \n                     procs=[Categorify, FillMissing,Normalize],\n                     cat_names = cat_names,\n                     cont_names = cont_names,\n                    )","b4011bdb":"X_test = test.train.xs","d5dff585":"X_test.sample(10)","071dbb70":"X_test.columns.to_series().groupby(X_test.dtypes).groups","74a653fc":"X_test = X_test.drop('Fare_na', axis=1)","144cab69":"y_pred = rnf_classifier.predict(X_test)\n","e9990752":"y_pred = y_pred.astype(int)","d55891e8":"output= pd.DataFrame({'PassengerId':df_test.PassengerId, 'Survived': y_pred})\noutput.to_csv('my_submission_titanic.csv', index=False)\noutput.head()","406afec0":"~~WOW, we get the accuracy of 0.98 on validation dataset this means on leader board getting rank of 200 something our of 19,000. ~~  \nWe got _only_ 76.4%","2e165a0d":"Now you would be thinking why we are dropping the 'Fare_na' column. The reason is, originally we trained model on 24 features. But as you know that tabularpandas function creates a new column if there is any missing value spotted in any particular feature.\n\nHere, our test data had some Fare values missing so the function created the boolean column this lead to 25 features. If you try to pass without dropping Fare_na column, it will give you the error that model was trained on 24 features and we are passing 25. That's why dropping Fare_na feature. And dont worry it doesnt have any effect on the output.\n","1de24a7d":"Using RandomForestClassifier for solving this problem\n\nand taking out X_train and y_train values like we showed before\n","824bfe8e":"# FastAI2\n\nnow we are diving into fastai2. looking down at code. Might be new and intimidating. But no worries,\nfollowing the documentation helped me. https:\/\/docs.fast.ai\/tutorial.tabular\n\nHere we are using fastai TabularPandas library. Which will do all the preprocessing for us.\nbefore that splitting our data into validation set to have a fair amount of idea that we are not overfitting the data. valid_pct= 0.2 means (as you may have guessed by now) it means 20% validation data.\n\ny_names, using column we are targetting to be predicted.\nprocs are [Categorify, FillMissing,Normalize], Convering objects into category, filling the missing value and normalizing the content for quick processing.\n\n\nNOTE:\nTabularpandas function creates a new column if there is any missing value spotted in any particular feature(only float or int column). for example: lets say Fare has a missing value somewhere. It will create a new column named 'Fare_na' where it will have integer values (1 or 2). ","d79e5ca6":"Generally what happens is, we cannot use the output of tabularpandas straightaway. So we need to access it as follows.. just taking peek at train data(for validation data replace train with valid)","e61ae0a1":"avoiding, y_name and split for obvious reasons","996f3c82":"For comparison, if we simply predict the survival based on `Sex` alone we get 72.5%.","9f184e06":"Here you can see `Age_na` as a binary feature where the original `Age` feature had missing values.","010222da":"Installing fastai2, yes its not preinstalled. We would need to install on our own.\n\nWarning: If you get some sort of error in importing fastai modules. I would recommend changing notebook environment to\n\n    Always use latest environment Always get the latest package versions, but you may have to modify your code.\n\n","cab0e4b5":"Now this might be a bit puzzling if you are new to fastai. And its completely alright.\n\ncat_names refers to the features which are categorical.\n\ncont_names refers to the features which are continuous. For example : int and float\n\nfastai needs them in order to do preprocessing for you properly\n","a5ec2b27":"# TEST dataset","1c6e1ffd":"#  Importing and Loading files","91517790":"Calculating the average null values we have in our data. It is important to know. Just to get intuition about data ","a6b77457":"using the same for target value","a88c3160":"We have table without any hardcore preprocessing all we did was just to use fastai tabular function to get this","7f6ffffd":"![](https:\/\/www.startpage.com\/av\/proxy-image?piurl=https%3A%2F%2Fmiro.medium.com%2Fmax%2F3220%2F1%2AEoktyGnUpOv9Zq-85AIDZw.png&sp=1604574674Ta7af17791962192680c603c3207c07371e29404b8ca44eabde41a70ce72f86a2)","06fc3c6d":"Getting names of columns according to its datatype.\n\nThis will allow us to understand which feature is int, float, and object(categorical)\n","7ba4322d":"doing the same preprocessing we did for training set","b370e070":"getting the table value for test dataset. we used train.xs becoz it lets us extact the data we had given the tabularpandas function\n","6fb7ba96":"We just Trained randomforest classifier and predicting accuracy on validation set","05dff257":"here is our output","cb1b7d60":"# Conclusion\n\nSo what is our main take away?\nFastAI makes it really simple to do pre-processing and prediction.  \nBut without the extended data set, i.e. good feature engineering, this won't help alone.","ff1e445f":"Just taking abit statistical look into data.","451f89af":"using 'xs' to get the table in the manner we are used to see it. Notice that it is without 'Survived' column","35df75ab":"> This is my first notebook submission. Please let me know if i can improve incase i have left some things unexplained.\n> We are not USING EDA here. Only automatic preprocessing data in fastai and training model and getting score of top1%.\n> \n> \n> ~~Here, we are using dataset which is a bit extension of classic titanic dataset. you can check out this: https:\/\/www.kaggle.com\/pavlofesenko\/titanic-extended~~ \n> ~~And It is fair to use this, i reckon. We are not altering test data at all. Only using new features(Like how we generate new features). Number of rows remains same in both test and training data.~~\n> Is it fair? Let's test it.\n> \n> \n> We will be using newly released fastai2.0 library and standard sklearn. fastai2.0 is worth checking out https:\/\/docs.fast.ai\/ It is more fast and efficient. With this, we can minimize our effort for preprocessing and gain better results.\n> \n\nThis notebook is based on [this one](https:\/\/www.kaggle.com\/hitesh1724\/titanic-1-fastai-beginner-tutorial), where the author achieved astonishing 98% on the test set without any feature engineering, EDA, etc.\nIn this notebook I explore and demonstrate that it is only because of the extended data set.\nThe main take away is that Fast.ai makes machine\/deep learning more accessable but you still need to check the data and do feature engineering (resulting in an extended data set).","4f9df462":"# ~~Top1%:~~ FastAI Beginner Tutorial Revisited\n"}}