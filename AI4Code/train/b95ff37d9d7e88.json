{"cell_type":{"a8e16b74":"code","a9105f5d":"code","45125b80":"code","9acc3bd7":"code","ddd0aa38":"code","b91c7fa0":"code","55740852":"code","a2871de7":"code","2fbfd226":"code","3626ad30":"code","0b709ac2":"code","3a0b9e4c":"code","cec04aef":"code","e3668dd2":"code","a80947a2":"code","0464326f":"code","8cd277b0":"code","7f834874":"code","8fae56c1":"code","5d2a7d52":"code","914e100c":"code","29d448b5":"code","75168219":"code","2ccdee6b":"code","49d950b2":"code","868553a9":"markdown","bfaa7d0a":"markdown","d3c2e944":"markdown","34228dd9":"markdown","00918df4":"markdown","cd96b217":"markdown","943f98a0":"markdown","c1590080":"markdown","90f65636":"markdown","c9cd9cd9":"markdown","a2aa8d08":"markdown","33277be4":"markdown"},"source":{"a8e16b74":"import pandas as pd\nimport tensorflow as tf\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport IPython.display as ipd  \nimport glob \nimport os\nimport sys\nimport numpy as np\n\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense,Input, Flatten, Dropout, Activation, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.utils import np_utils\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder \nimport seaborn as sns\nfrom tqdm import tqdm\nimport keras_tuner as kt\nfrom keras_tuner import HyperModel\nfrom keras_tuner.tuners import Hyperband","a9105f5d":"def speedNpitch(data):\n    length_change = np.random.uniform(low=0.8, high = 1)\n    speed_fac = 1.2  \/ length_change\n    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n    minlen = min(data.shape[0], tmp.shape[0])\n    data *= 0\n    data[0:minlen] = tmp[0:minlen]\n    return data\n\ndef plot_history(history):\n    fig, axs = plt.subplots(2)\n    # create accuracy sublpot\n    axs[0].plot(history.history['acc'], label='train accuracy')\n    axs[0].plot(history.history['val_acc'], label='test accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].legend(loc='lower right')\n    axs[0].set_title('Accuracy eval')\n    # create error sublpot\n    axs[1].plot(history.history['loss'], label='train error')\n    axs[1].plot(history.history['val_loss'], label='test error')\n    axs[1].set_ylabel('Error')\n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(loc='upper right')\n    axs[1].set_title('Error eval')\n    plt.show()\n    \ndef print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n\n    df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names, )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n        \n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","45125b80":"ref = pd.read_csv(\"\/kaggle\/input\/data-pathcsv\/Data_path.csv\")  \nprint(ref.shape)\ndf=np.empty(shape=(ref.shape[0], 30, 216))","9acc3bd7":"j = 0\ninput_length = 44100 * 2.5\nfor i in tqdm(ref.path):\n    path = i\n    wav, sr = librosa.core.load(path, sr=44100, offset=0.5, duration=2.5, res_type='kaiser_fast')\n    \n    # Random offset \/ Padding\n    if len(wav) > input_length:\n        max_offset = len(wav) - input_length\n        offset = np.random.randint(max_offset)\n        wav = wav[offset:(input_length+offset)]\n    else:\n        if input_length > len(wav):\n            max_offset = input_length - len(wav)\n            offset = np.random.randint(max_offset)\n        else:\n            offset = 0\n        wav = np.pad(wav, (offset, int(input_length) - len(wav) - offset), \"constant\")\n        \n    wav = speedNpitch(wav)\n    MFCC = librosa.feature.mfcc(y=wav, sr=sr, n_mfcc=30)\n    df[j,0:30,0:MFCC.shape[1]] = MFCC\n    j = j+1   ","ddd0aa38":"print(MFCC.shape)","b91c7fa0":"print(df.shape)","55740852":"X_train, X_test, y_train, y_test = train_test_split(df, ref.labels, test_size = 0.25, random_state = 42)\n#X_train = np.array(X_train)\n#y_train = np.array(y_train)\n#X_test = np.array(X_test)\n#y_test = np.array(y_test)\nX_shape = X_train\nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\nprint(X_train.shape)\nprint(lb.classes_)\nprint(y_train[0:10])\nprint(y_test[0:200])","a2871de7":"X_train = np.expand_dims(X_train, axis=3)\nX_test = np.expand_dims(X_test, axis=3)\nX_train.shape[1]","2fbfd226":"X_train.shape","3626ad30":"#Hyper Tuning\nclass CNNHyperModel(HyperModel):\n    def __init__(self, input_shape, num_classes):\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n\n    def build(self, hp):\n        model = tf.keras.Sequential()\n        #input layer\n        model.add(Conv2D(filters=hp.Choice('num_filters_1',values=[16, 256],default=16,), kernel_size=(4,10),activation=hp.Choice('Conv2D_activation_1',values=['relu','tanh','sigmoid'],default='relu'), padding='same', input_shape = (30, 216, 1)))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D())\n        model.add(Dropout(rate=hp.Float('dropout_1',min_value=0.0,max_value=0.5,default=0.25,step=0.05,)))\n        # 2nd Conv2d layer          \n        model.add(Conv2D(filters=hp.Choice('num_filters_2',values=[16, 256],default=16,),activation=hp.Choice('Conv2D_activation_2',values=['relu','tanh','sigmoid'],default='relu'),kernel_size=(4,10),padding='same'))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D())\n        model.add(Dropout(rate=hp.Float('dropout_2',min_value=0.0,max_value=0.5,default=0.25,step=0.05,)))\n        # 3rd Conv2d layer          \n        model.add(Conv2D(filters=hp.Choice('num_filters_3',values=[16, 256],default=16,), activation=hp.Choice('Conv2D_activation_3',values=['relu','tanh','sigmoid'],default='relu'),kernel_size=(4,10),padding='same'))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D())\n        model.add(Dropout(rate=hp.Float('dropout_3',min_value=0.0,max_value=0.5,default=0.25,step=0.05,)))\n        # 4th Conv2d layer          \n        model.add(Conv2D(filters=hp.Choice('num_filters_4',values=[16, 256],default=16,),activation=hp.Choice('Conv2D_activation_4',values=['relu','tanh','sigmoid'],default='relu'),kernel_size=(4,10),padding='same'))\n        model.add(BatchNormalization())\n        model.add(MaxPool2D())\n        model.add(Dropout(rate=hp.Float('dropout_4',min_value=0.0,max_value=0.5,default=0.25,step=0.05,)))\n        # 1st Dense layer\n        model.add(Flatten())\n        model.add(Dense(units=hp.Int('units',min_value=32, max_value=512,step=32,default=64),activation=hp.Choice('dense_activation',values=['relu','tanh','sigmoid'],default='relu')))\n        model.add(Dropout(rate=hp.Float('dropout_5', min_value=0.0,max_value=0.5,default=0.25,step=0.05)))\n        # Output layer \n        model.add(Dense(14))         \n        model.add(Activation('softmax'))\n        #opt = tf.keras.optimizers.Adam(hp.Float('learning_rate',min_value=1e-4,max_value=1e-2,sampling='LOG',default=1e-3))\n        model.compile(optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate',min_value=1e-4, max_value=1e-2,sampling='LOG',default=1e-3)),loss=tf.keras.losses.categorical_crossentropy,metrics=['accuracy'])\n        #model.summary()\n        return model","0b709ac2":"NUM_CLASSES=14\nhypermodel = CNNHyperModel(input_shape=(30, 216, 1), num_classes=NUM_CLASSES)","3a0b9e4c":"HYPERBAND_MAX_EPOCHS = 30\nMAX_TRIALS = 60\nEXECUTION_PER_TRIAL = 3\nSEED = 1\nN_EPOCH_SEARCH = 40\ntuner = Hyperband(hypermodel,max_epochs=HYPERBAND_MAX_EPOCHS,objective='val_accuracy',seed=SEED,executions_per_trial=EXECUTION_PER_TRIAL,directory='hyperband',project_name='TPU1_aug')","cec04aef":"tuner.search_space_summary()","e3668dd2":"# train model normally\ntuner.search(X_train, y_train, epochs=N_EPOCH_SEARCH, validation_split=0.1)","a80947a2":"# Show a summary of the search\ntuner.results_summary()\n\n# Retrieve the best model.\nbest_model = tuner.get_best_models(num_models=1)[0]\n\n# Evaluate the best model.\nloss, accuracy = best_model.evaluate(X_test, y_test)\n\nmodel_name = 'best_model_aug.h5'\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\n\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nbest_model.save(model_path)\nprint('Save model and weights at %s ' % model_path)\n\nmodel_json = best_model.to_json()\nwith open(\"model_json_aug.json\", \"w\") as json_file:\n    json_file.write(model_json)","0464326f":"best_model.compile(optimizer = tf.keras.optimizers.Adam(0.00034981818142934215), loss = tf.keras.losses.categorical_crossentropy, metrics = ['acc'])#tf.keras.losses.categorical_crossentropy.,loss='sparse_categorical_crossentropy'\nhistory = best_model.fit(X_train, y_train, batch_size = 32, epochs = 30, validation_data = (X_test, y_test))","8cd277b0":"plot_history(history)","7f834874":"model_name = 'EM_2D_aug.h5'\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\n\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint('Save model and weights at %s ' % model_path)\n\nmodel_json = model.to_json()\nwith open(\"model_json_aug.json\", \"w\") as json_file:\n    json_file.write(model_json)","8fae56c1":"preds = best_model.predict(X_test, batch_size=16, verbose=1)\n\npreds=preds.argmax(axis=1)\npreds = preds.astype(int).flatten()\npreds = (lb.inverse_transform((preds)))\npreds = pd.DataFrame({'predictedvalues': preds})\n\nactual = y_test.argmax(axis=1)\nactual = actual.astype(int).flatten()\nactual = (lb.inverse_transform((actual)))\nactual = pd.DataFrame({'actualvalues': actual})\n\nfinaldf = actual.join(preds)\nfinaldf1 = actual.join(preds)\n\nfinaldf[170:180]","5d2a7d52":"classes = finaldf.actualvalues.unique()\nclasses.sort()    \n\nc = confusion_matrix(finaldf.actualvalues, finaldf.predictedvalues)\nprint(accuracy_score(finaldf.actualvalues, finaldf.predictedvalues))\nprint_confusion_matrix(c, class_names = classes)","914e100c":"# Classification report \nclasses = finaldf.actualvalues.unique()\nclasses.sort()    \nprint(classification_report(finaldf.actualvalues, finaldf.predictedvalues, target_names=classes))","29d448b5":"modidf1 = finaldf1\nmodidf1['actualvalues'] = modidf1.actualvalues.replace({'female_angry':'angry' , 'female_disgust':'disgust', 'female_fear':'fear', 'female_happy':'happy', 'female_sad':'sad'\n                                       , 'female_surprise':'surprise', 'female_neutral':'neutral', 'male_angry':'angry', 'male_fear':'fear', 'male_happy':'happy', 'male_sad':'sad'\n                                       , 'male_surprise':'surprise' , 'male_neutral':'neutral' , 'male_disgust':'disgust'})\n\nmodidf1['predictedvalues'] = modidf1.predictedvalues.replace({'female_angry':'angry', 'female_disgust':'disgust', 'female_fear':'fear', 'female_happy':'happy', 'female_sad':'sad'\n                                       , 'female_surprise':'surprise', 'female_neutral':'neutral', 'male_angry':'angry', 'male_fear':'fear', 'male_happy':'happy', 'male_sad':'sad'\n                                       , 'male_surprise':'surprise', 'male_neutral':'neutral', 'male_disgust':'disgust'})\n\nclasses = modidf1.actualvalues.unique() \nclasses.sort() \n\nd = confusion_matrix(modidf1.actualvalues, modidf1.predictedvalues)\nprint(accuracy_score(modidf1.actualvalues, modidf1.predictedvalues))\nprint_confusion_matrix(d, class_names = classes)","75168219":"modidf = finaldf\nmodidf['actualvalues'] = finaldf.actualvalues.replace({'female_angry':'female', 'female_disgust':'female', 'female_fear':'female', 'female_happy':'female'\n                                       , 'female_sad':'female', 'female_surprise':'female', 'female_neutral':'female', 'male_angry':'male', 'male_fear':'male', 'male_happy':'male'\n                                       , 'male_sad':'male', 'male_surprise':'male' , 'male_neutral':'male', 'male_disgust':'male'})\n\nmodidf['predictedvalues'] = finaldf.predictedvalues.replace({'female_angry':'female', 'female_disgust':'female', 'female_fear':'female', 'female_happy':'female'\n                                       , 'female_sad':'female', 'female_surprise':'female', 'female_neutral':'female', 'male_angry':'male', 'male_fear':'male', 'male_happy':'male'\n                                       , 'male_sad':'male', 'male_surprise':'male', 'male_neutral':'male', 'male_disgust':'male'})\n\nclasses = modidf.actualvalues.unique()  \nclasses.sort() \n\nc = confusion_matrix(modidf.actualvalues, modidf.predictedvalues)\nprint(accuracy_score(modidf.actualvalues, modidf.predictedvalues))\nprint_confusion_matrix(c, class_names = classes)","2ccdee6b":"# Classification report \nclasses = modidf.actualvalues.unique()\nclasses.sort()    \nprint(classification_report(modidf.actualvalues, modidf.predictedvalues, target_names=classes))","49d950b2":"# Classification report \nclasses = modidf.actualvalues.unique()\nclasses.sort()    \nprint(classification_report(modidf.actualvalues, modidf.predictedvalues, target_names=classes))","868553a9":"## Introduction \nThis model is our 2D CNN model for Speech Emotion Recognition. It follows this steps\n1. Data prepration and processing\n2. Build a model\n3. Compile model\n4. Serialize model\n5. Validate model\n\n\n","bfaa7d0a":"**Emotion accuracy**","d3c2e944":"**Emotion by gender accuracy**","34228dd9":"<a id=\"data\"><\/a>\n## 1. Getting Data\nRead in the data csv-file with all labels and paths of the four datasets.","00918df4":"<a id=\"processing\"><\/a>\n### Data processing\n\nNow the data is being put into a practical format for Keras and the CNN.\n","cd96b217":"Here we are reading the audio file in and try to extract the mfcc features. There we take the mean to save space and to accelerate it.","943f98a0":"<a id=\"compile\"><\/a>\n## 3. Compile Model \n","c1590080":"**Gender accuracy result**","90f65636":"## 5. Validate model","c9cd9cd9":"<a id=\"build\"><\/a>\n## 2. Build a model\nWe are using a 2D CNN. ","a2aa8d08":"# <center>Speech emotion recognition - UHH ML Project 2D-CNN\n<\/center> ","33277be4":"## 4. Serialize model"}}