{"cell_type":{"d88b19ac":"code","e6a3c53a":"code","aeb415b5":"code","e3197133":"code","6799533a":"code","4d304e74":"code","112cb987":"code","905eb7c6":"code","34f5a4e2":"code","be15d4da":"code","6bea95c4":"code","2e921de5":"code","403f40c0":"code","05c16552":"code","fe9f7ace":"code","4b55927a":"code","708c3e09":"code","c11f195d":"code","20d348dd":"markdown","8a3548f7":"markdown","82efcd10":"markdown","321c8379":"markdown","f8d58fe1":"markdown"},"source":{"d88b19ac":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, load_model, Model\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications.xception import Xception\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport PIL.Image\n\ndaisy_path = \"..\/input\/flower\/flower_classification\/train\/daisy\/\"\ndandelion_path = \"..\/input\/flower\/flower_classification\/train\/dandelion\/\"\nrose_path = \"..\/input\/flower\/flower_classification\/train\/rose\/\"\nsunflower_path = \"..\/input\/flower\/flower_classification\/train\/sunflower\/\"\ntulip_path = \"..\/input\/flower\/flower_classification\/train\/tulip\/\"\ntest_path=\"..\/input\/flower\/flower_classification\/test\/\"\nsubmission = pd.read_csv('..\/input\/submission.csv')","e6a3c53a":"from os import listdir\nimport cv2\n\n\n\nimg_data = []\nlabels = []\n\nsize = 224,224\ndef iter_images(images,directory,size,label):\n    try:\n        for i in range(len(images)):\n            img = cv2.imread(directory + images[i])\n            img = cv2.resize(img,size,PIL.Image.ANTIALIAS)\n            img_data.append(img)\n            labels.append(label)\n    except:\n        pass\n\niter_images(listdir(daisy_path),daisy_path,size,0)\niter_images(listdir(dandelion_path),dandelion_path,size,1)\niter_images(listdir(rose_path),rose_path,size,2)\niter_images(listdir(sunflower_path),sunflower_path,size,3)\niter_images(listdir(tulip_path),tulip_path,size,4)","aeb415b5":"len(img_data),len(labels)","e3197133":"test_data = []\n\nsize = 224,224\ndef test_images(images,directory,size):\n    try:\n        for i in range(len(images)):\n            img = cv2.imread(directory + submission['id'][i]+\".jpg\")\n            img = cv2.resize(img,size,PIL.Image.ANTIALIAS)\n            test_data.append(img)\n    except:\n        pass\n\n\ntest_images(listdir(test_path),test_path,size)","6799533a":"len(test_data)","4d304e74":"train_X = np.asarray(img_data)\ntrain_Y = np.asarray(labels)\n\nidx = np.arange(train_X.shape[0])\nnp.random.shuffle(idx)\n\ntrain_X = train_X[idx]\ntrain_Y = train_Y[idx]\n\ntestData=np.asarray(test_data)\n\nprint(train_X.shape)\nprint(train_Y.shape)","112cb987":"import numpy as np\ndata = np.asarray(img_data)\ntestData=np.asarray(test_data)\n\n#div by 255\n# data = data \/ 255.0\n# testData=testData\/255.0\n\nlabels = np.asarray(labels)","905eb7c6":"dict = {0:'daisy', 1:'dandelion', 2:'rose', 3:'sunflower', 4:'tulip'}\ndef plot_image(number):\n    fig = plt.figure(figsize = (15,8))\n    plt.imshow(testData[number])\n    plt.title(dict[labels[number]])\nplot_image(0)\nlabels[0]","34f5a4e2":"from sklearn.model_selection import train_test_split\n\n# Split the data\nX_train, X_validation, Y_train, Y_validation = train_test_split(data, labels, test_size=0.10, shuffle= True)","be15d4da":"print(\"Length of X_train:\", len(X_train), \"Length of Y_train:\", len(Y_train))\nprint(\"Length of X_validation:\",len(X_validation), \"Length of Y_validation:\", len(Y_validation))","6bea95c4":"from tensorflow.python.keras.models import Model\nfrom tensorflow.python.keras.models import load_model\nfrom tensorflow.python.keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.python.keras.applications.resnet50 import ResNet50\nfrom tensorflow.python.keras.optimizers import Adam\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   channel_shift_range=10,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')","2e921de5":"net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n               input_shape=(224,224, 3))\nx = net.output\nx = Flatten()(x)\n\nx = Dropout(0.5)(x)\nx = Dense(200, activation='relu', name='dense1')(x)\nx = BatchNormalization()(x)\nx = Dense(200, activation='relu', name='dense2')(x)\nx = BatchNormalization()(x)\noutput_layer = Dense(5, activation='softmax', name='softmax')(x)\n\nnet_final = Model(inputs=net.input, outputs=output_layer)","403f40c0":"for layer in net_final.layers[:2]:\n    layer.trainable = False\nfor layer in net_final.layers[2:]:\n    layer.trainable = True\n\nnet_final.compile(optimizer=Adam(lr=5e-5, decay=0.005),\n                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nprint(net_final.summary())","05c16552":"History=net_final.fit_generator(train_datagen.flow(train_X, train_Y, batch_size=64), \n                        steps_per_epoch=len(train_X) \/ 64,\n                        epochs=15)","fe9f7ace":"plt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","4b55927a":"plt.plot(History.history['acc'])\nplt.plot(History.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","708c3e09":"pred =  np.argmax(net_final.predict(testData), axis=1)\nnewsSbmission=submission\nnewsSbmission[\"class\"]=pred\nnewsSbmission.to_csv(\"submission.csv\", index=False)","c11f195d":"pred","20d348dd":"## 6 ) Output Testing Data","8a3548f7":"## 3 ) Modelling\nData augmentation","82efcd10":"## 4 ) Evaluating the Model Performance","321c8379":"## 2 ) Data preprocessing","f8d58fe1":"## 1 ) Load data\n### 1.1) Making the functions to get the training and testing set"}}