{"cell_type":{"55b77814":"code","7830d2db":"code","96e75987":"code","b2376441":"code","519b70ca":"code","60837694":"code","56fbef51":"code","9800d9ce":"code","9012f825":"code","d90237dc":"code","3a94e370":"code","bc8a25e4":"code","7d216a22":"code","41b0f3f4":"code","20572d50":"markdown","f1756f30":"markdown","03d80923":"markdown","88d6e6eb":"markdown","8f50c2d8":"markdown","2ce71fc6":"markdown","fad497cc":"markdown","23979750":"markdown"},"source":{"55b77814":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","7830d2db":"import tensorflow as tf\nconfig  = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsess = tf.Session(config=config)","96e75987":"# Get file path\nvideo_record = \"..\/input\/video-sample\/video\/train00.tfrecord\"\nframe_record = \"..\/input\/frame-sample\/frame\/train00.tfrecord\"","b2376441":"# read file and get record_iterator\nrecord_iterator = tf.python_io.tf_record_iterator(video_record)\n# Maybe many records in oen TFRecord file, we just need one record to analyze structur\nrecord_0 = [record for record in record_iterator][0]\n# parse record string as tf.train.Example\nexample = tf.train.Example.FromString(record_0)","519b70ca":"# analyze structur\n# pleas pay atention to 'key' and 'value' of feature ,especialy the data_type of the value'\nprint(example)","60837694":"# Ther are two ways to get the value of record.\n# First\nexample.features.feature['id'].bytes_list.value[0].decode(encoding='UTF-8')\nexample.features.feature['labels'].int64_list.value\nexample.features.feature['mean_rgb'].float_list.value\nexample.features.feature['mean_audio'].float_list.value\nexample.features.feature['id'].bytes_list.value","56fbef51":"# Second \n# encourge to use this way\nfeature_keys  = {'id': tf.FixedLenFeature([],tf.string),\n                 'labels': tf.VarLenFeature(tf.int64),\n                 'mean_rgb': tf.FixedLenFeature([1024],tf.float32),\n                 'mean_audio': tf.FixedLenFeature([128],tf.float32)}\n\nparsed = tf.parse_single_example(record_0,feature_keys)\n# NOTE:: tf.VarLenFeature(tf.int64) will parse and return a sparse tensor, should cover it to dense tensor\n# 3862:: according to YouTube-8M Tensorflow Starter Code, dataset have 3862 labels\nparsed[\"labels\"] = tf.sparse_to_dense(parsed[\"labels\"].values, [3862], 1) \nsess.run(parsed)","9800d9ce":"# The function to parse record\ndef parser(record):\n    feature_keys  = {'id': tf.FixedLenFeature([],tf.string),\n                     'labels': tf.VarLenFeature(tf.int64),\n                     'mean_rgb': tf.FixedLenFeature([1024],tf.float32),\n                     'mean_audio': tf.FixedLenFeature([128],tf.float32)}                                                    \n    parsed= tf.parse_single_example(record,feature_keys)\n    parsed[\"labels\"] = tf.sparse_to_dense(parsed[\"labels\"].values, [3862], 1) \n    return parsed\n# The tool\ndef input_video_data(video_path,batch_size=1,num_epoch=1):\n    # Get all TFRecord files in this path\n    # The first item of os.listdir(video_path) is current path\n    filenames = [os.path.join(video_path,file) for file in os.listdir(video_path)][1:]\n    # creat dataset\n    dataset  = tf.data.TFRecordDataset(filenames)\n    # parse every record string \n    dataset = dataset.map(parser)\n    # Random shuffle\n    dataset = dataset.shuffle(buffer_size=1000)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.repeat(num_epoch)\n    iterator = dataset.make_one_shot_iterator()\n    try:\n        next_element = iterator.get_next()\n    except tf.errors.OutOfRangeError:\n        print(\"Iterations exhausted\")\n    return next_element","9012f825":"# Use this tool to get data\nvideo_path = \"..\/input\/video-sample\/video\"\nbatch_example = input_video_data(video_path)\n# every training time, sess.run will get a batch of data.\nsess.run(batch_example)","d90237dc":"record_iterator = tf.python_io.tf_record_iterator(frame_record)\nrecord_0 = [record for record in record_iterator][100]\n# NOTE\uff1aframe-level TFRecord files contain SequenceExamples\nexample = tf.train.SequenceExample.FromString(record_0)\n\n# print(example)\n\n# keys to parse context_features\nfeature_keys  = {'id': tf.FixedLenFeature([],tf.string),\n                 'labels':tf.VarLenFeature(tf.int64)}\n# keys to parse features_lists\nsequence_features_keys = {'audio': tf.FixedLenSequenceFeature([],tf.string,allow_missing=True),\n                          'rgb': tf.FixedLenSequenceFeature([],tf.string,allow_missing=True)}\n# Use tf.parse_single_sequence_example to parse sequenceExample \nparsed = tf.parse_single_sequence_example(record_0,feature_keys,sequence_features_keys)\nparsed[0][\"labels\"] = tf.sparse_to_dense(parsed[0][\"labels\"].values, [3862], 1) \n# return tuple:\uff08features_dict\uff0csequence_features_dict\uff09\nresult = sess.run(parsed)","3a94e370":"num_classes = 3862\ndef parser(record):\n    feature_keys  = {'id': tf.FixedLenFeature([],tf.string),\n                     'labels': tf.VarLenFeature(tf.int64)}\n    sequence_features_keys = {'audio': tf.FixedLenSequenceFeature([],tf.string),\n                              'rgb': tf.FixedLenSequenceFeature([],tf.string)}\n    context_parsed, sequence_parsed = tf.parse_single_sequence_example(record,feature_keys,sequence_features_keys)\n    context_parsed[\"labels\"] = tf.sparse_to_dense(context_parsed[\"labels\"].values, [num_classes], 1,validate_indices=False)\n    return context_parsed, sequence_parsed\n\ndef input_frame_data(frame_path,batch_size=1,num_epoch=1):\n    filenames = [os.path.join(frame_path,file) for file in os.listdir(frame_path)][1:]\n    dataset  = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(parser)\n    dataset = dataset.shuffle(buffer_size=1000)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.repeat(num_epoch)\n    iterator = dataset.make_one_shot_iterator()\n    next_element = iterator.get_next()\n    return next_element","bc8a25e4":"frame_path = \"..\/input\/frame-sample\/frame\"\nbatch_example = input_frame_data(frame_path)\nresult = sess.run(batch_example)","7d216a22":"# 1024 bit features\nlen(result[1]['rgb'][0][0])","41b0f3f4":"# 300 up frames\nlen(result[1]['rgb'][0])","20572d50":"# Frame-level","f1756f30":"# overview\nResently, I'm working to learn tensorflow.data API (tf.data) to figure out data importing problem on tensorflow task, especially importing TFRecord file data. And, I find **tf.data** and **TFRecord** are very powerful. Then I will use tf.data API to import data, e.g.train00.tfrecord.  Although [YouTube-8M Tensorflow Starter Code](https:\/\/github.com\/google\/youtube-8m#overview-of-files) has readers.py to import data, it's really confusing. Note that; some API maybe throw-out errors, you should update your tensorflow. The  **tf.parse_single_sequence_example** will get error under tensorflow-1.4, so I update to tensorflow-1.9, everything is OK. ","03d80923":"##  Automatically read, parse and get training data","88d6e6eb":"##  Analyze TFRecord file \nYou can do these with new TFRecord files, find structur and parse record string.","8f50c2d8":"##  Automatically read, parse and get training data","2ce71fc6":"I know, it's late to finish this competition. (\u256f\u2035\u25a1\u2032)\u256f\ufe35\u253b\u2501\u253b\n","fad497cc":"# Video-level","23979750":"##  Analyze TFRecord file "}}