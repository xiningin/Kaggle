{"cell_type":{"8cae72c6":"code","d5b364db":"code","9a0fc4af":"code","ba738de0":"code","d825867f":"code","d1995acd":"code","eb874077":"code","d1d40404":"code","ab321e82":"code","1b82d640":"code","5f24aa3e":"code","69028ed0":"code","35597596":"code","9a76cf20":"code","7731669e":"code","79278db5":"code","b75ff6a4":"code","c4e9c4a1":"code","762355c5":"code","98f7c92d":"code","94be5b56":"code","8a19c471":"code","8371c1fc":"code","f2824fcc":"code","938dfcda":"code","0634b545":"code","bf1a47b2":"code","83281932":"code","9ef361cd":"code","2ba2064a":"code","8a3d6444":"code","b59f68d7":"code","a996a5c0":"code","fdad0ca2":"markdown","23922c78":"markdown","c8a927b1":"markdown","fa7967dc":"markdown","eb2701e5":"markdown"},"source":{"8cae72c6":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom collections import Counter\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport re\nimport string\n\npd.options.display.max_columns = None\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d5b364db":"path = \"\/kaggle\/input\/tweet-sentiment-extraction\"\n\ntrain = pd.read_csv(os.path.join(path, \"train.csv\"))\ntest = pd.read_csv(os.path.join(path, \"test.csv\"))\nsample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))","9a0fc4af":"train.head()","ba738de0":"test.head()","d825867f":"sample_submission.head()","d1995acd":"train.info()","eb874077":"train.describe()","d1d40404":"test.info()","ab321e82":"test.describe()","1b82d640":"sns.set(style='darkgrid')\n\nsns.countplot(data=train, x='sentiment', color=\"b\")\nplt.show()","5f24aa3e":"sns.set(style='darkgrid')\n\nsns.countplot(data=test, x='sentiment', color=\"b\")\nplt.show()","69028ed0":"train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","35597596":"f, ax = plt.subplots(figsize=(6, 15))\n\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"count\", y=\"Common_words\", data=temp,\n            label=\"Count\", color=\"b\")\n\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(xlim=(0, temp[\"count\"].max()), ylabel=\"\")\nsns.despine(left=True, bottom=True)","9a76cf20":"def remove_stopword(text):\n    return [w for w in text if not w in stop]\n\ndef clean_text(text):\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","7731669e":"train['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))\ntrain.drop(columns=\"temp_list\", inplace=True)","79278db5":"train","b75ff6a4":"train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))","c4e9c4a1":"train","762355c5":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","98f7c92d":"f, ax = plt.subplots(figsize=(6, 15))\n\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"count\", y=\"Common_words\", data=temp,\n            label=\"Count\", color=\"b\")\n\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(xlim=(0, temp[\"count\"].max()), ylabel=\"\")\nsns.despine(left=True, bottom=True)","94be5b56":"positive_train = train[train[\"sentiment\"]==\"positive\"]\nnegative_train = train[train[\"sentiment\"]==\"negative\"]\nneutral_train = train[train[\"sentiment\"]==\"neutral\"]","8a19c471":"def tokenizeandstopwords(text):\n    tokens = nltk.word_tokenize(text)\n    token_words = [w for w in tokens if w.isalpha()]\n    meaningful_words = [w for w in token_words if not w in stop]\n    joined_words = ( \" \".join(meaningful_words))\n    return joined_words","8371c1fc":"positive_train[\"selected_text\"] = positive_train[\"selected_text\"].apply(clean_text)\nnegative_train[\"selected_text\"] = negative_train[\"selected_text\"].apply(clean_text)\nneutral_train[\"selected_text\"] = neutral_train[\"selected_text\"].apply(clean_text)","f2824fcc":"positive_train[\"selected_text\"] = positive_train[\"selected_text\"].apply(tokenizeandstopwords)\nnegative_train[\"selected_text\"] = negative_train[\"selected_text\"].apply(tokenizeandstopwords)\nneutral_train[\"selected_text\"] = neutral_train[\"selected_text\"].apply(tokenizeandstopwords)","938dfcda":"positive_train['temp_list'] = positive_train['selected_text'].apply(lambda x:str(x).split())\npositive_train['temp_list'] = positive_train['temp_list'].apply(lambda x:remove_stopword(x))\npositive_top = Counter([item for sublist in positive_train['temp_list'] for item in sublist])\npositive_temp = pd.DataFrame(positive_top.most_common(20))\npositive_temp.columns = ['Common_words','count']\npositive_temp.style.background_gradient(cmap='Blues')","0634b545":"negative_train['temp_list'] = negative_train['selected_text'].apply(lambda x:str(x).split())\nnegative_train['temp_list'] = negative_train['temp_list'].apply(lambda x:remove_stopword(x))\nnegative_top = Counter([item for sublist in negative_train['temp_list'] for item in sublist])\nnegative_temp = pd.DataFrame(negative_top.most_common(20))\nnegative_temp.columns = ['Common_words','count']\nnegative_temp.style.background_gradient(cmap='Blues')","bf1a47b2":"neutral_train['temp_list'] = neutral_train['selected_text'].apply(lambda x:str(x).split())\nneutral_train['temp_list'] = neutral_train['temp_list'].apply(lambda x:remove_stopword(x))\nneutral_top = Counter([item for sublist in neutral_train['temp_list'] for item in sublist])\nneutral_temp = pd.DataFrame(neutral_top.most_common(20))\nneutral_temp.columns = ['Common_words','count']\nneutral_temp.style.background_gradient(cmap='Blues')","83281932":"positive_train['number of words'] = positive_train['text'].apply(lambda x : len(str(x).split()))\nnegative_train['number of words'] = negative_train['text'].apply(lambda x : len(str(x).split()))\nneutral_train['number of words'] = neutral_train['text'].apply(lambda x : len(str(x).split()))\n\nplt.figure(figsize=(15,8))\np1=sns.kdeplot(negative_train['number of words'], shade=True, color=\"r\")\np1=sns.kdeplot(positive_train['number of words'], shade=True, color=\"b\")\np1=sns.kdeplot(neutral_train['number of words'], shade=True, color=\"g\")\np1.set_title('Distribution of Number Of words',fontsize=20)\nplt.show()","9ef361cd":"from sklearn.feature_extraction.text import CountVectorizer\n\n\ndef WordRanking(corpus,n_gram,n=None):\n   \n    vec = CountVectorizer(ngram_range=n_gram,stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    \n    return words_freq[:n]","2ba2064a":"positive_selected_text = train[train['sentiment']=='positive']['selected_text']\nnegative_selected_text = train[train['sentiment']=='negative']['selected_text']\nneutral_selected_text = train[train['sentiment']=='neutral']['selected_text']\n\npositive_bigrams = WordRanking(positive_selected_text,(2,2),20)\nnegative_bigrams = WordRanking(negative_selected_text,(2,2),20)\nneutral_bigrams = WordRanking(neutral_selected_text,(2,2),20)\n\npositive_bigrams = pd.DataFrame(positive_bigrams,columns=['word','counting'])\nnegative_bigrams = pd.DataFrame(negative_bigrams,columns=['word','counting'])\nneutral_bigrams = pd.DataFrame(neutral_bigrams,columns=['word','counting'])","8a3d6444":"plt.figure(figsize=(19,10))\nax= sns.barplot(data=positive_bigrams,y='word',x='counting', color=\"b\")\nax.set_title('Top 20 positive bigram words from selected text'.title(),fontsize=20)\n\nax.set_ylabel('Word counting',fontsize=15)\nplt.show()","b59f68d7":"plt.figure(figsize=(19,10))\nax= sns.barplot(data=negative_bigrams,y='word',x='counting', color=\"b\")\nax.set_title('Top 20 negative bigram words from selected text'.title(),fontsize=20)\n\nax.set_ylabel('Word counting',fontsize=15)\nplt.show()","a996a5c0":"plt.figure(figsize=(19,10))\nax= sns.barplot(data=neutral_bigrams,y='word',x='counting', color=\"b\")\nax.set_title('Top 20 neutral bigram words from selected text'.title(),fontsize=20)\n\nax.set_ylabel('Word counting',fontsize=15)\nplt.show()","fdad0ca2":"## Cleaning data\n\n","23922c78":"## Check data","c8a927b1":"## Load data","fa7967dc":"## Separate dataframe by sentiment","eb2701e5":"## EDA"}}