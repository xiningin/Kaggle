{"cell_type":{"886dfd17":"code","9857293a":"code","1c970a71":"code","ef7f6502":"code","e34ef9fc":"code","e9dbbb88":"code","b66d6488":"code","e13c5036":"code","d569613c":"code","2de3eb28":"code","b5403658":"code","e0406c0e":"code","7b739396":"code","0337d2db":"code","236c60e1":"code","4e721ba4":"code","c96905db":"code","bf4b28ae":"code","159e4bfb":"code","49be76da":"code","835903fc":"code","406a6769":"code","2f6b8e3b":"code","8155671b":"code","7e355f07":"code","227fcc62":"code","305ae40a":"code","2d5f0d48":"code","2450729f":"code","d86cd61a":"code","1766392e":"code","2dde14e0":"code","8ec60352":"code","f98b0855":"code","1373e173":"code","72b48ba8":"code","07d804a9":"code","a3065eac":"code","3e779899":"code","a4de9964":"code","53abd9a6":"code","a349e5b9":"code","deb1ddcf":"code","74044485":"code","8151c95c":"code","9a4fa0cb":"code","9e6044cb":"code","5053ce81":"code","1771c690":"code","7b5ad0f6":"code","81873d9a":"code","36cc67f8":"code","384bcd9f":"code","7a9aa5be":"code","1de830c6":"code","8854c835":"markdown","1b65e0cc":"markdown","f725998f":"markdown","c92dfb4d":"markdown","ab1f7b4c":"markdown","6fbc1a7d":"markdown","d283f7b2":"markdown","9d40ee55":"markdown","5efd2aa5":"markdown","73db62ca":"markdown","d4d53d95":"markdown","350b1342":"markdown","a12ff434":"markdown","5d773dee":"markdown","05ef9f6f":"markdown","55b5b1ce":"markdown","a276610c":"markdown","eea1ae76":"markdown","8fe160a9":"markdown","fcccd0af":"markdown","32fdea41":"markdown","122ef200":"markdown","8361ddfb":"markdown","494a85c2":"markdown","e92334e8":"markdown","fec51d65":"markdown","a2ff91ed":"markdown","5b84692c":"markdown","08084916":"markdown","eec85ab2":"markdown","ea16d6f7":"markdown","acdea2a4":"markdown","04ed9413":"markdown","823ce69e":"markdown","693293f8":"markdown","6d934448":"markdown","730d84d0":"markdown","de5b5756":"markdown","fb7f0f15":"markdown","acc63c31":"markdown","408a8bfe":"markdown","f3aeeabc":"markdown","fdb3d4c8":"markdown","89b17e3c":"markdown","cf746e11":"markdown","ade4be02":"markdown","a992796e":"markdown","5dce0acc":"markdown","508a2042":"markdown","c40e498a":"markdown","38a87b0b":"markdown","345f5fce":"markdown","67fc8fd7":"markdown","3e1e8b02":"markdown","1ddc40b9":"markdown","9b18484c":"markdown","877c4943":"markdown","0b48209f":"markdown","de50ea2a":"markdown","08999794":"markdown","18a38c4f":"markdown","42ddc66a":"markdown","cef02e30":"markdown","3fd2ddad":"markdown","239ef3df":"markdown","0ce1ef18":"markdown","ab1b082d":"markdown","a5d6b126":"markdown","2885cc7c":"markdown","a3d3d270":"markdown","12d43645":"markdown","8e7fd042":"markdown","9a5d76f5":"markdown","37b32ece":"markdown","c164e34c":"markdown","09db7d20":"markdown","3e87e2cd":"markdown","079aabb4":"markdown","33e94c32":"markdown","64696bd6":"markdown","8ea4be9b":"markdown"},"source":{"886dfd17":"# for data manipulation\nimport numpy as np \nimport pandas as pd \nimport pandas_profiling as pp\npd.set_option('display.max_columns', 50)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\n\n# for date manipulation\nfrom datetime import datetime\n\n# for visualization: matplotlib\nfrom matplotlib import pyplot as plt\nfrom IPython.core.pylabtools import figsize\n%matplotlib inline\n# to display visuals in the notebook\n\n# for visualization: seaborn\nimport seaborn as sns\nsns.set_context(font_scale=2)\n\n# for visualization: plotly\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\n\n# to cleanup memory usage\nimport gc\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9857293a":"# path\npath = \"\/kaggle\/input\/ashrae-energy-prediction\"\n\n# train  data\nbuilding = pd.read_csv(path + \"\/building_metadata.csv\")\nweather_train = pd.read_csv(path + \"\/weather_train.csv\", \n                            index_col=1, parse_dates = True)\ntrain = pd.read_csv( path + \"\/train.csv\", \n                    index_col=2, parse_dates = True)","1c970a71":"# look at the number of rows and columns\nprint('Size of the building dataset is', building.shape)\nprint('Size of the weather_train dataset is', weather_train.shape)\nprint('Size of the train dataset is', train.shape)","ef7f6502":"# test data\nweather_test = pd.read_csv(path + \"\/weather_test.csv\", \n                           index_col=1, parse_dates = True)\ntest = pd.read_csv(path + \"\/test.csv\", \n                   index_col=3, parse_dates = True)\n# submission data\nsample_submission = pd.read_csv( path + \"\/sample_submission.csv\")","e34ef9fc":"# look at the number of rows and columns\nprint('Size of the weather_test dataset is', weather_test.shape)\nprint('Size of the test dataset is', test.shape)\nprint('Size of the sample_submission is', sample_submission.shape)","e9dbbb88":"del sample_submission\ngc.collect()","b66d6488":"## Function to reduce the DF size\ndef reduce_memory_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","e13c5036":"reduce_memory_usage(building)\nreduce_memory_usage(weather_train)\nreduce_memory_usage(train)\n\nreduce_memory_usage(weather_test)\nreduce_memory_usage(test)","d569613c":"pp.ProfileReport(building)","2de3eb28":"building.sort_values(by=\"square_feet\", ascending=True).tail()","b5403658":"pp.ProfileReport(weather_train)","e0406c0e":"train.info()","7b739396":"print(\"Percentage of missing values in the train dataset\")\ntrain.isna().sum()","0337d2db":"train.describe(include=\"all\")","236c60e1":"train.head()","4e721ba4":"test.describe(include=\"all\")","c96905db":"pp.ProfileReport(weather_test)","bf4b28ae":"del weather_test, test\ngc.collect()","159e4bfb":"# set the plot size\nfigsize(12,10)\n\n# set the histogram, mean and median\nsns.distplot(train['meter_reading'],\n             kde=True)\nplt.axvline(x=train.meter_reading.mean(), \n            linewidth=3, color='g', label=\"mean\", alpha=0.5)\nplt.axvline(x=train.meter_reading.median(), \n            linewidth=3, color='y', label=\"median\", alpha=0.5)\n\n# set title, legends and labels\nplt.title(\"Distribution of Meter Reading\", size=14)\nplt.legend([\"mean\", \"median\"])","49be76da":"# set the plot size\nfigsize(12,10)\n\n# set the histogram, mean and median\nsns.distplot(np.log1p(train['meter_reading']),\n             kde=True)\nplt.axvline(x=np.log1p(train.meter_reading.mean()), \n            linewidth=3, color='g', label=\"mean\", alpha=0.5)\nplt.axvline(x=np.log1p(train.meter_reading.median()), \n            linewidth=3, color='y', label=\"median\", alpha=0.5)\n\n# set title, legends and labels\nplt.title(\"Distribution of Logarithm(Meter Reading + 1) \", size=14)\nplt.legend([\"mean\", \"median\"])","835903fc":"# create dataframe excluding 0 measurements of meter_reading and take the natural logarithm\n# np.log is used this time because we don't have 0 values in the meter_reading\npositive_train = train[train['meter_reading'] != 0]\npositive_train['log_meter_reading'] = np.log(positive_train['meter_reading'])","406a6769":"# set the plot size\nfigsize(12,10)\n\n# set the histogram, mean and median\nsns.distplot(positive_train['log_meter_reading'], \n             kde=True)\nplt.axvline(x=positive_train['log_meter_reading'].mean(),\n            linewidth=3, color='g', label=\"mean\", alpha=0.5)\nplt.axvline(x=positive_train['log_meter_reading'].median(),\n            linewidth=3, color='y', label=\"median\", alpha=0.5)\n\n# set title, legends and labels\nplt.title(\"Distribution of Logarithm(Meter Reading) w\/o 0 Measurements\", size=14)\nplt.legend([\"mean\", \"median\"])","2f6b8e3b":"def outlier_function(df, col_name):\n    ''' this function detects first and third quartile and interquartile range for a given column of a dataframe\n    then calculates upper and lower limits to determine outliers conservatively\n    returns the number of lower and uper limit and number of outliers respectively\n    '''\n    first_quartile = np.percentile(\n        np.array(df[col_name].tolist()), 25)\n    third_quartile = np.percentile(\n        np.array(df[col_name].tolist()), 75)\n    IQR = third_quartile - first_quartile\n                      \n    upper_limit = third_quartile+(3*IQR)\n    lower_limit = first_quartile-(3*IQR)\n    outlier_count = 0\n                      \n    for value in df[col_name].tolist():\n        if (value < lower_limit) | (value > upper_limit):\n            outlier_count +=1\n    return lower_limit, upper_limit, outlier_count","8155671b":"# percentage of outliers in the meter_reading\nprint(\"{} percent of {} are outliers.\"\n      .format((\n              (100 * outlier_function(train, 'meter_reading')[2])\n               \/ len(train['meter_reading'])),\n              'meter_reading'))","7e355f07":"train['meter_reading'].sort_values().tail()","227fcc62":"positive_train['meter_reading'].sort_values().head()","305ae40a":"# distribution of the meter reading in meters without zeros\nfigsize(12,10)\n\n#list of different meters\nmeters = sorted(train['meter'].unique().tolist())\n\n# plot meter_reading distribution for each meter\nfor meter_type in meters:\n    subset = train[train['meter'] == meter_type]\n    sns.kdeplot(np.log1p(subset[\"meter_reading\"]), \n                label=meter_type, linewidth=2)\n\n# set title, legends and labels\nplt.ylabel(\"Density\")\nplt.xlabel(\"Meter_reading\")\nplt.legend(['electricity', 'chilled water', 'steam', 'hot water'])\nplt.title(\"Density of Logartihm(Meter Reading + 1) Among Different Meters\", size=14)","2d5f0d48":"# distribution of the meter reading in meters without zeros\nfigsize(12,10)\n\n# plot meter_reading distribution for each meter\nfor meter_type in meters:\n    subset = positive_train[positive_train['meter'] == meter_type]\n    sns.kdeplot(subset[\"log_meter_reading\"], \n                label=meter_type, linewidth=2)\n\n# set title, legends and labels\nplt.ylabel(\"Density\")\nplt.xlabel(\"Log_meter_reading\")\nplt.legend(['electricity', 'chilled water', 'steam', 'hot water'])\nplt.title(\"Density of Positive Logarithm(Meter Reading) Among Different Meters\", size=14)","2450729f":"# upsample hourly observations to daily and aggregate by meter category\ntrain_daily_avg_by_meter = (train.\n                            groupby('meter').\n                            meter_reading.\n                            resample('d').mean().\n                            reset_index())","d86cd61a":"# assign meter values as column headers to create tidy-form dataframe\ntidy_train_daily_avg = (train_daily_avg_by_meter.\n                        pivot(index='timestamp', \n                              columns='meter', \n                              values='meter_reading').\n                        reset_index())","1766392e":"# rename column header back to meter categories\ntidy_train_daily_avg.rename(columns = {0: \"electricity\",\n                                       1: \"chilled_water\",\n                                       2: \"steam\",\n                                       3: \"hot_water\"},\n                           inplace=True)","2dde14e0":"# create meter and color dictionary\nmeter_dict = {'electricity': 'darkblue',\n              'chilled_water':'orange',\n              'steam': 'green',\n              'hot_water': 'red'\n             }\n\n# create figure object and plot each meter category\nfig = go.Figure()\n\nfor key in meter_dict:\n    fig.add_trace(go.Line(\n        x=tidy_train_daily_avg.timestamp, \n        y=tidy_train_daily_avg[key], \n        mode='lines',\n        name=key,\n        line_color=meter_dict[key]))\n\n# add title and show figure\nfig.update_layout(\n    title_text='Average Daily Energy Consumption in kWh',\n    xaxis_rangeslider_visible=True)\nfig.show()","8ec60352":"# upsample weather_train dataframe to get daily means\nweather_train_daily_avg = (weather_train.\n                           resample('d').\n                           mean())","f98b0855":"# align weather train dataframe with the train_daily_avg dataframe\nweather_train_daily_avg.reset_index(inplace=True)","1373e173":"weather_vs_meter_reading = (train_daily_avg_by_meter.\n                            merge(weather_train_daily_avg, \n                                  on='timestamp', \n                                  how='left'))","72b48ba8":"# rename meter column\nweather_vs_meter_reading['meter'] = (weather_vs_meter_reading['meter'].\n                                     map({0: 'electricity',\n                                          1: 'chilled_water',\n                                          2: 'steam',\n                                          3: 'hot_water'}))","07d804a9":"# create weather variables and color dictionary\nweather_dict = {\"air_temperature\": \"red\",\n                \"cloud_coverage\": \"orange\",\n                \"dew_temperature\": \"coral\",\n                \"precip_depth_1_hr\": \"olive\",\n                \"sea_level_pressure\": \"teal\",\n                \"wind_direction\": \"purple\",\n                \"wind_speed\": \"navy\" \n               }","a3065eac":"# create plotly object and plot weather variables against dates\nfig = go.Figure()\n    \nfor key in weather_dict:\n    fig.add_trace(go\n                  .Line(x=weather_vs_meter_reading['timestamp'],\n                        y=weather_vs_meter_reading[key], \n                        name=key,\n                        line_color=weather_dict[key]))\n    \nfig.update_layout(title_text='Time Series of Weather Variables')\nfig.show()      ","3e779899":"# fig = ff.create_scatterplotmatrix(\n#    weather_vs_meter_reading[[\"meter_reading\",\n#                              \"air_temperature\",\n#                              \"cloud_coverage\",\n#                              \"dew_temperature\",\n#                              \"precip_depth_1_hr\",\n#                              \"sea_level_pressure\",\n#                              \"wind_direction\",\n#                              \"wind_speed\",\n#                              \"meter\"]], diag='histogram', index='meter',\n#                                  height=1400, width=1400)\n# fig.update_layout(\n#    title='Weather Varaibles and Meter Reading',\n#    dragmode='select'\n#)\n\n# fig.show()","a4de9964":"fig = px.scatter_matrix(weather_vs_meter_reading,\n                        dimensions=[\"meter_reading\",\n                                    \"air_temperature\",\n                                    \"cloud_coverage\",\n                                    \"dew_temperature\",\n                                    \"precip_depth_1_hr\",\n                                    \"sea_level_pressure\",\n                                    \"wind_direction\",\n                                    \"wind_speed\"],\n                        color=\"meter\")\n\nfig.update_layout(\n    title='Weather Varaibles and Meter Reading',\n    dragmode='select',\n    width=1400,\n    height=1400,\n    hovermode='closest')\n\nfig.update_traces(diagonal_visible=True)\nfig.show()","53abd9a6":"# group train dataset per building and meter category\ntrain_by_building = (train.\n                     groupby([\"building_id\", \"meter\"]).\n                     meter_reading.mean().\n                     reset_index())","a349e5b9":"# merge grouped train dataframe with building dataset\nbuilding_w_meter_reading = (train_by_building.\n                            merge(building, \n                                  on='building_id', \n                                  how='left'))","deb1ddcf":"# add log_meter_reading to visualize meter_reading distribution\nbuilding_w_meter_reading['log_meter_reading'] = np.log1p(building_w_meter_reading['meter_reading'])","74044485":"# map primary use column \nbuilding_w_meter_reading['primary_use_mapped'] = (building_w_meter_reading['primary_use'].\n                                                  map({'Office': 'Office',\n                                                        'Education': 'Education',\n                                                        'Entertainment\/public assembly':'Entertainment\/public',\n                                                        'Lodging\/residential': 'Residential',\n                                                        'Public services': 'Public services'\n                                                       }))","8151c95c":"# replace the rest with Other\nbuilding_w_meter_reading['primary_use_mapped'].replace(np.nan, \n                                                       'Other', \n                                                       regex=True, \n                                                       inplace=True)","9a4fa0cb":"building_w_meter_reading['meter'] = (building_w_meter_reading['meter'].\n                                     map({0: 'electricity',\n                                          1: 'chilled_water',\n                                          2: 'steam',\n                                          3: 'hot_water'\n                                         }))","9e6044cb":"# split b\u0131ilding_w_meter_reading dataset per primary use category\neducation = (building_w_meter_reading[building_w_meter_reading[\n    'primary_use_mapped'] == 'Education'])\n\noffice = (building_w_meter_reading[building_w_meter_reading[\n    'primary_use_mapped'] == 'Office'])\n\nentertainment_public = (building_w_meter_reading[building_w_meter_reading[\n    'primary_use_mapped'] == 'Entertainment\/public'])\n\nresidential = (building_w_meter_reading[building_w_meter_reading[\n    'primary_use_mapped'] == 'Residential'])\n\npublic_services = (building_w_meter_reading[building_w_meter_reading[\n    'primary_use_mapped'] == 'Public services'])\n\nother = (building_w_meter_reading[building_w_meter_reading[\n    'primary_use_mapped'] == 'Other'])","5053ce81":"# create distplot parameters as lists\nhist_data = [education['log_meter_reading'], \n             office['log_meter_reading'],\n             entertainment_public['log_meter_reading'],\n             residential['log_meter_reading'],\n             public_services['log_meter_reading'],\n             other['log_meter_reading']]\n\ngroup_labels = ['education', 'office', 'entertainment_public',\n               'residential', 'public_services', 'other' ]\n\ncolors = ['#333F44', '#37AA9C', '#94F3E4', '#66CCFF', '#2C89AB', '#0324A9']","1771c690":"# create KDE plot of log_meter_reading \nfig = ff.create_distplot(hist_data, group_labels, \n                         show_hist=False, colors=colors, show_rug=True)\nfig.update_layout(title_text='Distribution of Logarithm Meter Reading among Primary Use')\nfig.show()","7b5ad0f6":"# histogram of site_ids\nfig = px.histogram(building, x=\"site_id\")\nfig.update_layout(title_text='Distribution Site IDs')\nfig.show()","81873d9a":"# create site id list\nsite_ids = building_w_meter_reading.site_id.unique().tolist()\n\n# create plotly object and visualize the distribution\nfig = go.Figure()\n\n# add a violin plot for each site_id\nfor site_id in site_ids:\n    fig.add_trace(go.Violin(y=building_w_meter_reading\n                            [building_w_meter_reading['site_id'] == site_id]\n                            ['log_meter_reading'],\n                            name=site_id,\n                            box_visible=True))\n\n# set title and show the object\nfig.update_layout(title_text='Distribution of Logarithm Meter Reading among Site ID')\nfig.show()","36cc67f8":"fig = px.scatter(building_w_meter_reading, x=\"square_feet\", y=\"log_meter_reading\", \n                 color=\"meter\", hover_data=['meter_reading'])\n\nfig.update_layout(title_text='Meter Reading VS Square Feet Among Different Meters')\nfig.show()","384bcd9f":"currentYear = datetime.now().year\nbuilding_w_meter_reading['age'] = currentYear - building_w_meter_reading['year_built']","7a9aa5be":"fig = px.scatter(building_w_meter_reading, x=\"age\", y=\"log_meter_reading\",\n                 color=\"meter\", hover_data=['meter_reading'])\n\nfig.update_layout(title_text='Meter Reading VS Age of the Building Among Different Meters')\nfig.show()","1de830c6":"fig = px.scatter(building_w_meter_reading, x=\"floor_count\", y=\"log_meter_reading\", \n                 color=\"meter\", hover_data=['meter_reading'])\n\nfig.update_layout(title_text='Meter Reading VS Floor Count Among Different Meters')\nfig.show()","8854c835":"### <a id='1-4'> 1.4. Information about the test datasets <\/a>\n<a href='#top'>Back to top <\/a>","1b65e0cc":"## <a id='2-5'> 2.5. Findings from exploratory data analysis <\/a> \n<a href='#top'> Back to top <\/a>     ","f725998f":"### <a id='2-1-3'> 2.1.3. Distribution of meter reading among different meter categories <\/a>\n<a href='#top'> Back to top <\/a>","c92dfb4d":"**Merge weather and train_daily_avg datasets**","ab1f7b4c":"* `meter_reading` is the target that we are trying to predict.\n* `meter` is the meter category, representing:\n  * 0: electricity\n  * 1: chilled water\n  * 2: steam\n  * 3: hot water\n* `meter_reading` values ranges between 0 and 22 million. We are going to take a closer look at the max value and investigate the reasons behind.\n* We don't have any missing values in the train dataset.","6fbc1a7d":"Very first observation is training and test data spans in 5 different csv files. If you look at the [data tab of the competition](https:\/\/www.kaggle.com\/c\/ashrae-energy-prediction\/data) you will see that:\n- `train.csv`, `test.csv`, `weather_train.csv` and `weather_test.csv` are time-series data, with hourly measurements.\n- `building_metadata.csv` contains the characteristics of a building such as:\n  - site id of the building\n  - primary use\n  - square feet\n  - year built\n- In the weather datasets, there are features related to wind, clouds, temperature and pressure.\n- Weather_train dataset measured from 1 Jan, 2016 to 1 Jan, 2017.\n- Weather_test dataset spans from 1 Jan, 2017 to 1, Jan 2019. \n\nSo using 1 year data we are going to predict following 2 years energy consumption of a building.\n\n\nLooking at the `test_csv`and `samplele_submissions.csv`, predictions will be based on:\n- building_id\n- meter (energy consumption category)\n- timestamp","d283f7b2":"Distribution of logarithm(meter reading + 1) values, regardless of the category, shows a right-skewed distribution. Median value is smaller than the mean value proving this skewness. This skewness is caused by the significanlty high number of 0 and 1 measurements in the `meter_reading`. Let's look at the definition if we can get some logical explanation to 0 measurements:\n\n> They are the Energy consumption in kWh (or equivalent). This is the real data with measurement error, which we expect will impose a baseline level of modeling error. \n\nExplanation implies this is a real data with some errors, due this error, there may be some missed observations in the `meter_reading`. Thus high number of 0 meter reading values shows not only zero consumption but may indicate some missing data in the `meter_reading`. Moving on with this suspicion, let's see how the distribution will look like if we exclude 0 measurements from the dataset. \n\nI think it is impossible for a building to consume 0 kWh energy at a given time. Every office, home at least having some fridges and other home appliances running all the time. \n\nThus, I I will visualize meter reading excluding 0 measurements.","9d40ee55":"### <a id='2-2-3'> 2.2.3. Pairplot of meter reading vs weather data <\/a>\n<a href='#top'> Back to top <\/a>","5efd2aa5":"This function converts data types in such a way that, they allocate less space in the memory. Then, reports the size of the reduction.","73db62ca":"Most of the training set examples are coming from site id 0, 2, 3, 4, 5, 9, 13, 14 and 15.","d4d53d95":"Meter reading values will be visualized without any categories, among meter categories and as a time-series data.","350b1342":"Our very first plot already conveyed some information: Meter reading values are highly skewed.\n\nRecall that, meter-reding values range between 0 and 22 million, this picture shows that high percentage of them are gathered around zero. And unfortunately due this high skewness it is impossible to visualize raw meter reading values and draw a histogram. \n\nDue to this wide range and highly skewed data the natural log(1 + meter_reading) will be visualized using [np.log1p](https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.log1p.html). Since the natural logarithm of zero is minus infinity (a real number to the power of some real number is never 0), np.log1p enables to transform 0 measurements to 1, including those in the visualization.","a12ff434":"### <a id='2-3-2'> 2.3.2. Meter reading distribution among primary uses <\/a> \n<a href='#top'> Back to top <\/a>  ","5d773dee":"This is the biggest dataset in amongst the training datasets. Thus, pandas_profiling crunches data in higher run-times. I will use handy pandas exploration functions to explore that dataset.","05ef9f6f":"## <a id='1-1'> 1.1. Load data into dataframes <\/a>\n<a href='#top'>Back to top <\/a>","55b5b1ce":"Time series data will be loaded by parsing `timestamp`column to enabling timestamp column to be formatted as datetime data type and as index.","a276610c":"Although I excluded 0s, there are still plenty of data points which are very close to 0.\n\nOut of 20 million observations 8% are detected with the logic of determining [extreme outliers](https:\/\/people.richland.edu\/james\/lecture\/m170\/ch03-pos.html). We are going to decide what to do with the outliers in the target data at the end of the notebook.","eea1ae76":"Recall Dec 19, 2016 where there is a peak int the hot_water consumption. On that date, 4th lowest air_temperature is recorded 1 degrees celcius, this might explain the spike in the hot_water consumption. Obviously, air temperature trend shows that this measurements recorded somewhere in Northern hemisphere.\n\nRecall from the definition dew temperature it is usually lower than air_temperature. If you look at air_temperature and dew_temperatur together, it proves this statement. Especially, dew_temperature is 5 degrees lower than the air_temperature and shares the same trend as air_temperature.\n\nAverage daily cloud coverage values are between 1 and 5. Higher cloud coverage indicates cloudy days, thus in winter there are more cloudy days.\n\nIf we look at the precipt_depth_1_hr half of the year is rainy, and half of the year seems to be dry. There are some days where average daily precip_depth_1_hr goes beyond 5. \n\nSea level pressure is not changing much over the year. Wind_direction will make more sense if we look at it as directions (north, south and so on). Thus I will convert them to directions. Average wind speed is around 3.5 and varies values throughout the year.","8fe160a9":"### <a id='2-4-3'> 2.4.3. Scatter plot of meter reading VS floor count <\/a> \n<a href='#top'> Back to top <\/a>  ","fcccd0af":"### <a id='2-4-1'> 2.4.1. Scatter plot of meter reading VS square feet <\/a> \n<a href='#top'> Back to top <\/a>     ","32fdea41":"### <a id='1-3-2'> 1.3.2. Weather_train dataset <a\/>\n<a href='#top'>Back to top<\/a>","122ef200":"![image](https:\/\/pixy.org\/src\/128\/1285841.jpg)\nImage source: [pixy](https:\/\/pixy.org\/1285841\/)","8361ddfb":"I am going to visualize weather data available and meter_reading values per meter category to see how each observation of cloud, temperature, pressure, precipitation and wind affects meter reading. Moreover, I am going to look for reasonable explanations of extremes in the chilled water, steam and hot water consumption in the weather data.\n\nTo aggreagte hourly observations, weather train data will be upsampled to daily averages. After that, two datasets will be merged on timestamp column since this is the shared column between two.","494a85c2":"**Imports**:\n<br> I will use numpy and pandas for data munging and manipulation. For the visualizations I will discover some [plotly](https:\/\/plot.ly\/python\/) in this project and create interactive visuals where possible. <br\/>","e92334e8":"## <a id='1-5'> 1.5. Findings from Understand, Clean, Format Data <a\/>\n<a href='#top'>Back to top<\/a>","fec51d65":"### <a id='2-3-3'> 2.3.3. Meter reading distribution among site id as violinplot <\/a> \n<a href='#top'> Back to top <\/a>   ","a2ff91ed":"Again for the visualization purposes, we are looking at the distribution of the np.log1p(meter_reading) values. \n\nOne thing that is obvious is; significant number of observations 0 are coming from hot water, chilled water and steam consumption,meaning we have less missing values and 0 observations in the electricity usage.\n\nThis picture shows that meter reading values shows different distribution in each meter category, especially electricity consumption is different than others. Thus, meter is a signifcant variable to determine the meter_reading values. It is already included in the train and test dataset as a determinant factor.\n\nLet's visualize the meter reading values excluding 0 measurements for different meter categories using the dataset created earlier.","5b84692c":"To understand how meter reading values distributed in each site_id lets first understand the distribution of site_ids in the building dataset.","08084916":"All primary_use categories shows uni-modal distirbution. We have fewer data points where log_meter_reading values are greater than 10 in all primary use categories.\n\nMedian values log_meter_reading in Education, residential and office are between 4.5 and 4.9, whereas median values of entertainment, publice services and other are between 3.9 and 4.3.\n\n**Education:**\n- This primary use category has the most datapoints (38%) in the primary_use column.\n- Meter reading values are normally distributed between 0 and 10.\n- There is one outlier in this category whose log_meter_reading value is greater than 15.\n\n**Residential:**\n- Residential category is the 10% of all primary_use values.\n- Meter reading values are spread between 1.5 and 8.\n- This primary use category has the narrowest data range.\n\n**Office**:\n- Office category has the second most datapoints (20%).\n- Log meter reading values spread between 0.7 and 8.5.\n- There are several outliers greater than 10.\n\n**Entertainment\/public:**\n- Entertainment\/public category is the 13% of all primary_use values.\n- Meter reading value spread between 0.1 and 9.6.\n- Entertainment\/public category has one outlier point greater than 10.\n\n**Public services:**\n- This category distributed between 0.7 and 7.5 having 3 outlier points.\n\n**Other:**\n- Log meter reading values are spread between 0.2 and 8.2.\n- It has one outlier greater than 10.\n\nAlthough some of primary_use meter reading distirbution resembles, it has importance in determining a meter_reading values, by each primary_use category having different ranges of log_meter_reading_values.","eec85ab2":"## <a id='2-1'> 2.1. Distribution of meter reading <\/a>","ea16d6f7":"Now, I have more concrete evidence that 0 observations represents missing values.\n\nMoreover, this is the picture I expected to see in the first place. However, after dropping the zero values and taking the logarithm of the meter reading values, distribution shows a perfect normal distribution. Data is centered around the mean. Mean and median values are equal to each other. Taking the logarithm helped to lower the variance.\n\nMoreover, some immediately observed outliers for log_meter_reading are around -7 and -5 and greater than 10. Let's have a closer look at the outliers:","acdea2a4":"We are dealing with some big datasets here (20 and 40 million rows). We have 41 million rows to predict with the built model. \n\nTo save some space from the memory, I am going to delete unused dataframes and use a function built as part of this [popular notebook](https:\/\/www.kaggle.com\/caesarlupum\/ashrae-start-here-a-gentle-introduction#2.-Imports-) to reduce the memory size use of the datasets.","04ed9413":"# <a id='1'> 1. Understand, Clean and Format Data <\/a>\n<a href='#top'>Back to top <\/a>","823ce69e":"### <a id='2-1-5'> 2.1.5. Average daily meter reading values over 2016 <\/a>\n<a href='#top'>Back to top <\/a>","693293f8":"### <a id='1-3-1'> 1.3.1. Building dataset <a\/>\n<a href='#top'>Back to top<\/a>","6d934448":"**By clicking on the legend in the right hand side, you can observe meter categories individually.**","730d84d0":"**Weather Dataframe**","de5b5756":"After dropping the zero values and taking the logarithm of the meter reading values: Electricity shows a slightly different distribution than other categories. Chilled water and steam meter_reading shows similar distributions with close mean values. Hot water has the least number of datapoints and has more spikes than the other categories.","fb7f0f15":"## <a id='1-2'> 1.2. Reduce the memory size <\/a>\n<a href='#top'>Back to top <\/a>","acc63c31":"I will run a detailed exploratory data analysis by visualizing trends, correlations and distributions between target and feature variables. Thanks to the pandas profiling I have already observed the single variable distributions of building and weather_train columns. So, I will start by looking at the high-level distribution of meter reading values.","408a8bfe":"Spikes and anomalies detected in the section *2.1.3.Average daily meter reading values over 2016* will be investigated while plotting average daily values of weather variables.","f3aeeabc":"## <a id='2-2'> 2.2. Meter reading VS weather_train data <\/a>\n<a href='#top'> Back to top <\/a>","fdb3d4c8":"**By clicking on the legend in each category, you can observe meter categories individually.**","89b17e3c":"**After a long and very detailed exploratory data analysis, here are the most important findings:**\n\nMeter reading values are higly and positively skewed. When we apply log1p function (calculates log(x+1)) to meter reading values we are able to obtain meaningful visualizations and conclusions.\n\nThere are significant number of 0 observations in the meter reading, which is due to erroneous or missing measurements. For generating the predictions on meter reading this is a valuable information.\n\nEven with the extreme outlier detection 7% of the meter reading observations are detected as outliers. I will keep all of the rows of the train data and build machine learning model with them, even 800.000 square feet buildings.\n\nEnergy consumption has different data ranges among meter categories and shows different distributions. Chilled water and hot_water time-series consumption shows seasonality: Hot water consumption increases in winter and chilled water consumption increases in summer. Electricty consumption has an increasing trend towards the end of 2016. There are no obvious patterns or seasonality effect in the steam consumption.\n\nPrimary use, site id, year built (or age), square feet has a significant effect in determining meter reading values which also intuitively makes sense. Floor_count has high missing values, so it will manipulate the training data into a different direction if we impute it. So, I am going to exclude that one from the training set in the second notebook.\n\nSome weather variables (air_temperature, dew_temperature, cloud_coverage) have high impact on meter reading values, some of them have slight (wind_direction, wind_speed) effect. For that reason, I am going to convert wind_direction to categorical data in the feature engineering part. Air and dew temperature are highly collinear. All of the weather variables might be useful for feaure engineering and addition, so I will keep all of them.","cf746e11":"# <a id='2'> 2. Exploratory Data Analysis <\/a>","ade4be02":"### <a id='2-1-2'> 2.1.2. Consolidated distribution of positive meter reading values <\/a>\n<a href='#top'> Back to top <\/a>","a992796e":"* Site ids 0, 1, 2, 3, 4, 5, 8, 9, 14 and 15 have similar meter reading distributions.\n* Site ids 6 and 10 meter_reading values shares almost the same distribution and summary statistics.\n* Site id 13 has the widest meter reading value range that goes beyond log_meter_reading_value 10.\n* Site id 11 has the narrowest meter reading values range, centered around 5.\n* Site id 13 shows the widest meter_reading distributions.\n\nAs site_id's are highly correlated with building id's, I might one to keep only one of them which I will decide at the end of this notebook.","5dce0acc":"### <a id='2-1-4'> 2.1.4. Distribution of positive meter reading values among different meter categories <\/a>\n<a href='#top'> Back to top <\/a>","508a2042":"### <a id='1-4-1'> 1.4.1. Test dataset <\/a>","c40e498a":"### <a id='1-3-3'> 1.3.3. Train dataset <\/a>\n<a href='#top'>Back to top <\/a>","38a87b0b":"### <a id='2-2-2'> 2.2.2. Average daily weather variable values over 2016 <\/a>\n<a href='#top'> Back to top <\/a>","345f5fce":"## <a id='1-3'> 1.3. Information about the training datasets <\/a>\n<a href='#top'>Back to top <\/a>","67fc8fd7":"Since there are 3 csv files, I will use pandas_profiling to get the quick glance of the data for the datasets with less than 1 million rows. \n\nPandas_profiling is a great library to display information about \n* Essentials\n* Quantile statistics\n* Descriptive statistics\n* Most frequent values\n* Histogram\n* Correlations (even rejects a column if a collinear correlation is found) \n<br> and provides a Sample consisting of first and last rows. <\/br> \n\nThe further details about the dataset can be observed by clicking on each tab and Toggle Details buttons per column.\n\nThe best part of the pandas profiling: It delivers whole bunch of information with just one line of code! If you want to dive deeper into pandas_profiling, you can check their [GitHub page](https:\/\/pandas-profiling.github.io\/pandas-profiling\/docs\/).","3e1e8b02":"**Summary from the report:**\n* Since this is a time-series data, we have much more observations (139.772) than the building dataset.\n* Except timestamp, all of the features are numeric and in following units and ranges:\n\n|   | Feature           | Range                              | Description\n|---|-------------------|------------------------------------|-------------------------------\n| 1 | air_temperature   | -28 to 47 Degrees Celsius          | \n| 2 | cloud_coverage    | 0 to 9 oktas                       | Portion of the sky covered in clouds\n| 3 | dew_temperature   | -35 to 26 Degrees Celsius          | The temperature at which the air can no longer \"hold\"                                                                  all of the water vapor. The dew temperature is aways                                                                    lower than (or equal to) the air temperature.\n| 4 | precip_depth_1_hr | -1 to 343 Millimeters              | The amount of rain, snow, hail, etc., that has fallen at                                                                a given place within a given period.\n| 5 | sea_level_pressure| 968 to 1046 Millibar\/hectopascals  | The average atmospheric pressure at mean sea level\n| 6 | wind_direction    | 0 to 360 degrees                   | Direction that the wind comes\n| 7 | wind_speed        | 0 to 19 Meters per second          |\n\n<br>\n* We have equal number of samples coming from 16 different sites.\n* It seems there are some extreme observations in this dataset, which can be observed by clicking toggle details and extreme values tab\n* `cloud_coverage`, `precip_depth_1_hr`, `sea_level_pressure` and `wind_direction` have significantly high missing values.","1ddc40b9":"Due to the less data points we have in the floor_count, it is hard to extract some meaningful conclusions from the graph, although it gives pretends to give for electricity, chilled water and hot water.","9b18484c":"I will add one more column as `age` using `year_built` column and use that one.","877c4943":"### <a id='2-2-1'> 2.2.1. Prepare & merge dataframes <\/a>\n<a href='#top'> Back to top <\/a>","0b48209f":"Pairplots are very useful to look at several continuous variables relationships in one chart. Ploly version of pairplots are scatterplots or scatter matrix.\n\nTo understand the relationship between meter_reading and weather related variables, scatter matrix of energy consumption data and weather data will be visualized and relationships & correlations will be searched.","de50ea2a":"### <a id='2-4-2'> 2.4.2. Scatter plot of meter reading VS age of the building <\/a> \n<a href='#top'> Back to top <\/a>    ","08999794":"## <a id='2-3'> 2.3. Meter reading VS building data categorical features <\/a>","18a38c4f":"Recall from the profiling report 80% of the `primary_use` values consists of the top 5 values:\n![image.png](attachment:image.png)\n\n\nI am going to decode top 5 primary_use values as a new column first, then look for the distribution of meter reading among different primary use.","42ddc66a":"Those extremely large buildings that lack year_built or floor_count values and can be named as outliers. I am going to determine how to handle outliers at the end of this notebook.","cef02e30":"Logarithm of the meter reading values in each meter category will be visualized against the continuous variables (square_feet, year and floor_count) of the building dataset.","3fd2ddad":"#### Relationships between tables:\n- building_id is the primary key of the building dataset.\n- building_id is the foreign key for the train dataset.\n- site_id is the foreign key for weather_train dataset.\n\n---------------------------------------------------------\nIn total, there are 15 unique columns in all training datasets excluding target column. Those columns are self-explanatory and clear. Excluding timestamp, rest are potential candidates for feature set.\n\n`meter_reading` is the target we are trying to predict. `meter_reading` represents energy consumption of a building for a 1-hour period in different meter reading categories.\n\n`timestamp` columns are converted to date-time format and seems like measurements are recorded in hourly periods.\n\nAlthough we have missing values and outliers in the training datasets, I will keep them all for now, and decide how to handled them at the end of the notebook.\n\nThere are nearly 20 million `meter_reading` values in the train dataset which are observed among 1448 buildings between 1 Jan, 2016 and 1 Jan, 2017; most of them being electricity meter observations.\n\nThere are 40 million `meter_reading`values in the test dataset observed among the same buildings betweeen 1 Jan 2017 and 1 Jan 2019.","239ef3df":"![image](https:\/\/www.technotification.com\/wp-content\/uploads\/2018\/09\/Renewable-Energy-Ideas.jpg)\n\nImage source: [technotification](https:\/\/www.technotification.com\/2018\/09\/amazing-renewable-energy-ideas.html)\n\nThis notebook aims to predict a building's energy consumption over 2017 and 2018 using the data from 2016 in 4 different consumpiton categories (electricity, chilled water, steam, hot water) using ASHRAE data, which is our problem statement as well.\n\nThis is a *supervised machine learning model*, meaning based on the columns available in the datasets and data from 2016, we are going to train the model to predict an energy consumption of a building in each category. Since, consumption values are labeled as `meter_reading` and they are continuous, we are going to apply *regression techniques* to generate predictions on meter_reading. \n\nIt is a highly debated and popular competition in Kaggle currently, however my main motivation is to contribute to make energy-efficient buildings by estimating its energy consumption. It seemed like a good start to save our energy for future!\n\nThere will be 3 notebooks covering the complete machine learning building pipeline. \n\nThis notebook will focus on parts 1 and 2 and provide information about the datasets with a detailed EDA.\n\n**1) Understand, Cleand and Format Data**\n\n**2) Exploratory Data Analysis**\n\n3) Feature Engineering & Selection\n\n4) Compare Several Machine Learning Models\n\n5) Perform Hyperparameter Tuning and Cross Validation\n\n6) Evaluate Model with Test Data\n\n7) Interpret Model Results\n\n8) Submissions & Summary & Conclusions\n\n* [Notebook 2](https:\/\/www.kaggle.com\/cereniyim\/save-the-energy-for-the-future-2-fe-lightgbm) will cover 3, 4 and 5 be focusing on building the optimal machine learning model.\n* [Notebook 3](https:\/\/www.kaggle.com\/cereniyim\/save-the-energy-for-the-future-3-predictions) will cover 6, 7 and 8 be focusing on generating the predictions with the best model and summary for the whole project.\n\nMachine Learning application and building is not a linear and one time process. Steps above enable me to follow a structured way for an end-to-end machine project flow and preparation for the each step ahead. All in all, steps might be modified or revisited according to findings. You can use the table of contents to navigate to each section and visual \ud83d\udc47\n\nEnjoy reading !","0ce1ef18":"### <a id='2-3-1'> 2.3.1. Prepare & merge dataframes <\/a> \n<a href='#top'> Back to top <\/a> ","ab1b082d":"### <a id='1-4-2'> 1.4.2 Weather_test <\/a>\n<a href='#top'>Back to top <\/a>","a5d6b126":"Meter reading values will be visualized against the categorical variables (primary_use and site_id) of building data. To do that, first train data will be grouped by building id and meter category and data will be aggreagted by mean.","2885cc7c":"Weather_test's column values and ranges are consistent with the weather_train's column values and ranges.","a3d3d270":"**By clicking on the legend in each category, you can observe meter categories individually.**","12d43645":"### <a id='2-1-1'> 2.1.1. Consolidated distribution of meter reading <\/a>\n<a href='#top'> Back to top <\/a>","8e7fd042":"This is the end of the first notebok, thank you for reading until the end!\n\nIn this notebook we covered:\n1. Understand, Clean and Format Data\n2. Exploratory Data Analysis\n\nThe most important findings in each section is summarized under <a href='#1-5'> 1.5. Findings from Understand, Clean, Format Data <\/a> and <a href='#2-5'> 2.5. Findings from exploratory data analysis <\/a>.\n\nAs a result of the first two sections, now an idea of how to approach feature engineering started to form. Second notebook will continue with *3. Feature Engineering & Selection* using findings of this notebook.\n\nAnd our problem statement still remains challenging \u26a1\ufe0f. Based on the 15 features and available, 1 year time-series data (nearly 20 million rows) we are going to predict the next 2 years electricity, chilled water, hot water and steam consumption of each building (nearly 40 million rows). \n\nSee you in the [second notebook](https:\/\/www.kaggle.com\/cereniyim\/save-the-energy-for-the-future-2-fe-lightgbm) \ud83d\udc4b where I start to dig into ML models following the steps described at the beginning.","9a5d76f5":"Violinplots are one [my favorite](https:\/\/towardsdatascience.com\/recipes-for-the-visualizations-of-data-distributions-a1527a0faf77) data exploratation tools, conveying the summary statistics and distribution at the same time. They are robust visualization when it comes to looking at a distribuiton among categories.","37b32ece":"**Summary from the Report:**\n* `Building_id` is the primary key for this dataset.\n* Observations coming from 1448 buildings.\n* `building_id` and `site_id`are collinear features.\n* More than 50% of the values are missing at columns`floor_count`and `year_built` which easily captured in the first raws of the data.\n* Except `primary_use`all of the columns are numeric.\n* `primary_use` column is categorical, most of the values being Education, Office and Public Assembly.\n* Looking at the `floor_count` histogram, data is gathered mostly from 1 to 5 floor buildings. Whether to keep or drop this column will be decided after looking at how this feature contributes to determining meter_reading.\n* Looking at the `square_feet` histogram most of the buildings are smaller than 200.000 square feet. There are few extremely large buildings: square feet is more than 800.000 square feet.\n* We have buildings from every age: 2 year-old buildings to 100-year-old buildings.","c164e34c":"**Electricity:**\n- As the air and dew temperature goes up, electricity consumption increases.\n- Cloud coverage, sea level pressure, precip depth 1 hour shows positive trend with the electricity consumption. Although their correlations are not as strong as temperature variables.\n- Wind direction and wind speed has almost no effect in electricity consumption.\n\n**Chilled water:**\n- As the air and dew temperature rises, chilled water consumption increases.\n- Other weather variables shows a slightly weaker positive trend with chilled water consumption, compared to temperature variables.\n\n**Steam:**\n- Although the data range is wider and higher than the weather variables, air temperature, dew temperature and cloud coverage shows positive trend with the steam consumption.\n- Precip depth 1 hour have a small effect (with a positive trend) in determining the steam consumption.\n- Rest of the weather variables does not significantly impacting steam consumption.\n\n**Hot water:**\n- Other weather variables shows positive trend with the hot water consumption.\n- Air and dew temprature shows negative trend with the hot water consumption.\n\nOne other important observation is air and dew temperature are highly collinear. All of the weather variables whether it is slight or strong have an affect on energy consumption.","09db7d20":"## <a id='2-4'> 2.4. Meter reading VS building data continuous features as scatterplots <\/a> \n<a href='#top'> Back to top <\/a>    ","3e87e2cd":"There is a clear connectcion between square feet and meter_reading values in all categories, whcih can be captured by intuition also: As the size of the building increases, it consumes more in each category.","079aabb4":"# <a id='top'> Table of Contents <\/a>\n- <a href='#1'> 1. Undserstand, Clean and Format Data <\/a>\n  - <a href='#1-1'> 1.1. Load data into dataframes <\/a>\n  - <a href='#1-2'> 1.2. Reduce the memory size <\/a>\n  - <a href='#1-3'> 1.3. Information about the training datasets <\/a>\n    - <a href='#1-3-1'> 1.3.1. Building dataset <\/a>\n    - <a href='#1-3-2'> 1.3.2. Weather_train dataset <\/a>\n    - <a href='#1-3-3'> 1.3.3. Train dataset <\/a>\n  - <a href='#1-4'> 1.4. Information about the test datasets <\/a>\n    - <a href='#1-4-1'> 1.4.1 Test dataset <\/a>\n    - <a href='#1-4-2'> 1.4.2 Weather_test <\/a>\n  - <a href='#1-5'> 1.5. Findings from Understand, Clean, Format Data <\/a>\n\n\n- <a href='#2'> 2. Exploratory Data Analysis <\/a>\n  - <a href='#2-1'> 2.1. Distribution of meter reading <\/a>\n    - <a href='#2-1-1'> 2.1.1. Consolidated distribution of meter reading <\/a>\n    - <a href='#2-1-2'> 2.1.2. Consolidated distribution of positive meter reading values <\/a>\n    - <a href='#2-1-3'> 2.1.3. Distribution of meter reading among different meter categories <\/a>\n    - <a href='#2-1-4'> 2.1.4. Distribution of positive meter reading values among different meter categories <\/a>\n    - <a href='#2-1-5'> 2.1.5. Average daily meter reading values over 2016 <\/a>\n  - <a href='#2-2'> 2.2. Meter reading VS weather_train data <\/a>\n    - <a href='#2-2-1'> 2.2.1. Prepare & merge dataframes <\/a>\n    - <a href='#2-2-2'> 2.2.2. Average daily weather variable values over 2016 <\/a>\n    - <a href='#2-2-3'> 2.2.3. Pairplot of meter reading vs weather data <\/a>\n  - <a href='#2-3'> 2.3. Meter reading VS building data categorical features <\/a>\n    - <a href='#2-3-1'> 2.3.1. Prepare & merge dataframes <\/a>\n    - <a href='#2-3-2'> 2.3.2. Meter reading distribution among primary uses <\/a>\n    - <a href='#2-3-3'> 2.3.3. Meter reading distribution among site id as violinplot <\/a>\n  - <a href='#2-4'> 2.4. Meter reading VS building data continuous features as scatterplots <\/a>\n    - <a href='#2-4-1'> 2.4.1. Scatter plot of meter reading VS square feet <\/a>\n    - <a href='#2-4-2'> 2.4.2. Scatter plot of meter reading VS age of the building <\/a>\n    - <a href='#2-4-3'> 2.4.3. Scatter plot of meter reading VS floor count <\/a> \n  - <a href='#2-5'> 2.5. Findings from exploratory data analysis <\/a>\n\n\n- <a href='#3'> Conclusions <\/a>","33e94c32":"Electricity observations spread between 0 and 220 kWh. For the first half of the year consumption does not exceed 160 kWh, for the second half consumption increases and ranges between 160 and 220 kWh. In general electricity consumption shows an increasing trend in 2016.\n\nChilled water consumption ranges between 130 - 2500 kWh. It shows a steady increase up to 1000 kWh until September 2016. Between September and October, there are spikes in the consumption causing the range going up to 2500 kWh. Starting from November it shows downward trend.\n\nSteam consuption has the highest and most volatile range: 0 - 80.000 kWh. There is no obvious trend in the steam consumption and steam is utilized only in the first half of the year. For the rest of the year, consumption decreases drastically which may indicate either steam is not used for the rest of the year or the errors (0 measurements) are coming from the steam category in the second half of 2016. There is an interesting spike in the Nov 9, 2016.\n\nHot water also is variable, however data is consistent in itself. Hot water consumtion is higher in the winter season and shows the lowest results between May and July. The data range is 0-1200 kWh having only one data point as 1200 on Dec 19, 2016. Excluding this, data is spread between 0-1000 kWh. The lesser consumption in summer season is a useful trend for our ML model to catch.","64696bd6":"There is no obivous relationship between the age and log_meter_reading values of electricity and steam.\n\nThere is obvious relationship in the hot_water category as the age of the building increases hot water consumption increases.\n\nOther obvious relationship is as the building age increases chilled water consumption decrease. Maybe old buildings don't have chilled water supply structures.","8ea4be9b":"# <a id='3'>  Conclusions <\/a>\n<a href='#top'> Back to top <\/a> "}}