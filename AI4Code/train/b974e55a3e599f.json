{"cell_type":{"96b558e0":"code","4530f93f":"code","c7e7c0a8":"code","a9265402":"code","2e0577af":"code","02482e61":"code","e6608ae2":"code","68be2af5":"code","2455e4de":"code","ce5a0470":"code","fa4c0bd7":"code","2bc335ff":"code","35cb76bf":"code","ec43a42f":"code","5d51f7a5":"code","1214afad":"code","5f5a1dcf":"code","73d878b1":"code","62724ade":"code","88108841":"markdown","911dd897":"markdown","78e1739a":"markdown","7f9aa9ce":"markdown","757337c8":"markdown","6638d44a":"markdown","5e922735":"markdown","041e93c5":"markdown","185963c1":"markdown","21308d22":"markdown","fbb1a3ee":"markdown","e2286ea6":"markdown","967878cb":"markdown","9b5a41f6":"markdown","f5f09613":"markdown","8a1e9517":"markdown","e34c8a28":"markdown","5db98ea1":"markdown","9620ed23":"markdown"},"source":{"96b558e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4530f93f":"from builtins import range, input\n\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom glob import glob","c7e7c0a8":"# training and testing path\ntrain_path = \"..\/input\/fruits\/fruits-360\/Training\"\nvalid_path = \"..\/input\/fruits\/fruits-360\/Test\"\n\n# useful for getting number of files\nimage_files = glob(train_path + '\/*\/*.jp*g')\nvalid_image_files = glob(valid_path + '\/*\/*.jp*g')\n\n# useful for getting number of classes\nfolders = glob(train_path + '\/*')","a9265402":"plt.imshow(image.load_img(np.random.choice(image_files)))\nplt.show()","2e0577af":"# re-size all images to this size\nIMAGE_SIZE = [100,100]\n\n# training config\nepochs = 5\nbatch_size = 32","02482e61":"vgg = VGG16(input_shape=IMAGE_SIZE + [3] , weights='imagenet', include_top=False)","e6608ae2":"for layer in vgg.layers:\n    layer.trainable = False","68be2af5":"x = Flatten()(vgg.output)\nprediction = Dense(len(folders), activation=\"softmax\")(x)","2455e4de":"model = Model(inputs=vgg.input, outputs=prediction)","ce5a0470":"model.summary()","fa4c0bd7":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer='rmsprop',\n    metrics=['accuracy']\n)","2bc335ff":"gen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True\n)","35cb76bf":"test_gen = gen.flow_from_directory(valid_path, target_size=IMAGE_SIZE)\nprint(test_gen.class_indices)\nlabels = [None] * len(test_gen.class_indices)\nfor k, v in test_gen.class_indices.items():\n    labels[v] = k","ec43a42f":"for x, y in test_gen:\n    print(\"min:\", x[0].min(),\"max:\",x[0].max())\n    plt.title(labels[np.argmax(y[0])])\n    plt.imshow(x[0])\n    plt.show()\n    break","5d51f7a5":"train_generator = gen.flow_from_directory(\n    train_path,\n    target_size=IMAGE_SIZE,\n    shuffle=True,\n    batch_size=batch_size,\n)\n\nvalid_generator = gen.flow_from_directory(\n    valid_path,\n    target_size=IMAGE_SIZE,\n    shuffle=True,\n    batch_size=batch_size,\n)","1214afad":"r = model.fit_generator(\n    train_generator,\n    validation_data=valid_generator,\n    epochs=epochs,\n    steps_per_epoch=len(image_files) \/\/ batch_size,\n    validation_steps = len(valid_image_files) \/\/ batch_size,\n)","5f5a1dcf":"def get_confusion_matrix(data_path, N):\n    print(\"Generating Confusion Matrix\", N)\n    predictions = []\n    targets = []\n    i = 0\n    for x, y in gen.flow_from_directory(data_path, target_size=IMAGE_SIZE, shuffle=False, batch_size=batch_size * 2):\n        i += 1\n        if i % 50 == 0:\n            print(i)\n        p = model.predict(x)\n        p = np.argmax(p, axis=1)\n        y = np.argmax(y, axis=1)\n        predictions = np.concatenate((predictions, p))\n        targets = np.concatenate((targets, y))\n        if len(targets) >= N:\n            break\n        \n        cm = confusion_matrix(targets, predictions)\n        return cm","73d878b1":"cm = get_confusion_matrix(train_path, len(image_files))\nprint(cm)\nvalid_cm = get_confusion_matrix(valid_path, len(valid_image_files))\nprint(valid_cm)","62724ade":"# loss\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label = 'val loss')\nplt.legend()\nplt.show()\n\n# accuracies\nplt.plot(r.history['accuracy'], label=\"train acc\")\nplt.plot(r.history['val_accuracy'], label=\"val acc\")\nplt.legend()\nplt.show()\n\nfrom utils import plot_confusion_matrix\nplot_confusion_matrix(r, cm, labels)\nplot_confusion_matrix(valid_cm, labels, title=\"Validation Confusion Matrix\")","88108841":"**Create an instance of ImageDataGenerator for data augmentation**","911dd897":"**Reading the Dataset**","78e1739a":"**Train the model**","7f9aa9ce":"**Import Libraries**","757337c8":"**Create generators**","6638d44a":"**Let's look at an image to get an idea**","5e922735":"**Calling Confusion Matrix**","041e93c5":"**Complining the model with *categorical_crossentropy* loss fucntion and *rmsprop* as optimizer method**","185963c1":"**Create a model object**","21308d22":"**I am using Transfer Learning that's why here there is no need to re-train train existing weights**","fbb1a3ee":"**Making a function for confusion matrix**","e2286ea6":"**Get label mapping for confusion matrix plot which will be used later in this notebook**","967878cb":"**Adding Preprocessing Layer in front of VGG**","9b5a41f6":"*Here I am adding Dense Layer with *softmax* actiation function\n\n# YOU CAN ADD MORE LAYERS IF YOU WANT","f5f09613":"**Sould be a strangely colored image (due to VGG weights being RGB)**","8a1e9517":"**View the structure of the model**","e34c8a28":"# Fruits classification with VGG16 and Trasnfer Learning","5db98ea1":"**Plot some data for further analysis**","9620ed23":"**Some Preprocessing and training Options**"}}