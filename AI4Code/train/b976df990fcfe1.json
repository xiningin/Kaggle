{"cell_type":{"7ff0b946":"code","03abe040":"code","0c5e4ed3":"code","af239bc8":"code","3e6e549c":"code","db7e9913":"code","655a08dc":"code","42c8113e":"code","baf827fe":"code","2e4a2865":"code","157c3f3f":"code","69ce7c42":"code","3b5d98d1":"code","ef9fec05":"code","67f636e9":"code","7f887969":"code","d7f15fcc":"code","5be7ed28":"code","7837d254":"code","cc5bc9f4":"markdown","6cf70cbe":"markdown","62217661":"markdown","2cc0bb8e":"markdown","7610542c":"markdown","42de1114":"markdown","6120a027":"markdown","eb09b789":"markdown","0b19c4c0":"markdown","a5ba96e9":"markdown","eb970036":"markdown","554c99ba":"markdown","c9b63507":"markdown","2e4d6d4c":"markdown"},"source":{"7ff0b946":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","03abe040":"data = pd.read_csv(\"\/kaggle\/input\/heart-failure-prediction\/heart.csv\")\ndata","0c5e4ed3":"data.describe()","af239bc8":"data.dtypes","3e6e549c":"target = pd.DataFrame()\ntarget = data.HeartDisease\ndata = data.drop(\"HeartDisease\",axis=1)","db7e9913":"data.ChestPainType.unique()","655a08dc":"data.RestingECG.unique()","42c8113e":"data.ExerciseAngina.unique()","baf827fe":"data.ST_Slope.unique()","2e4a2865":"X_0 = pd.get_dummies(data.Sex,prefix=\"Sex\")\nX_1 = pd.get_dummies(data.ChestPainType,prefix=\"CPT\")\nX_2 = pd.get_dummies(data.RestingECG,prefix=\"RECG\")\nX_3 = pd.get_dummies(data.ExerciseAngina,prefix=\"EA\")\nX_4 = pd.get_dummies(data.ST_Slope,prefix=\"ST_S\")\n\ndata = data.join([X_0,X_1,X_2,X_3,X_4])","157c3f3f":"data = data.drop([\"Sex\",\"ChestPainType\",\"RestingECG\",\"ExerciseAngina\",\"ST_Slope\"],axis=1)","69ce7c42":"data[\"normal_chol\"] = 0\ndata[\"border_chol\"] = 0\ndata[\"dangerous_chol\"] = 0\n\nfor i in range(len(data.index)):\n    if (data.Cholesterol.iloc[i] <= 239) and (data.Cholesterol.iloc[i] >=200):\n        data[\"border_chol\"].iloc[i] = 1\n    elif (data.Cholesterol.iloc[i] < 200):\n        data[\"normal_chol\"].iloc[i] =1\n    else:\n        data[\"dangerous_chol\"].iloc[i] = 1        ","3b5d98d1":"data","ef9fec05":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(data,target,random_state=42,test_size=0.3)","67f636e9":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom lightgbm import LGBMClassifier\n\nrnd_clf = RandomForestClassifier(n_estimators=200,random_state=42)\nsvm_clf = SVC(max_iter=100,tol=20,random_state=42)\nmlp_clf = MLPClassifier(random_state=42)\nlgbm_clf = LGBMClassifier(n_estimators=200)","7f887969":"estimators = [rnd_clf,svm_clf,mlp_clf,lgbm_clf]\n\nfor estimator in estimators:\n    print(\"Training the\", estimator)\n    estimator.fit(X_train,y_train)","d7f15fcc":"from sklearn.ensemble import VotingClassifier\n\nnamed_estimators = [\n    (\"random_forest_clf\",rnd_clf),\n    (\"SVM\",svm_clf),\n    (\"MLP\",mlp_clf),\n    (\"LGBM\",lgbm_clf)\n]\n\nvoting_clf = VotingClassifier(named_estimators)","5be7ed28":"voting_clf.fit(X_train,y_train)","7837d254":"score = voting_clf.score(X_test,y_test)\nprint(f\"score: {score*100:.1f}%\")","cc5bc9f4":"Delete any unnecessary category data that has already been converted.","6cf70cbe":"*OK,it looks like we need to convert the category data into dummy variables; using \"get_dummies\" is suitable.","62217661":"Prediction using Random Forest seems to be the best. On the other hand, SVM looks pretty poor.\n\nLet's take a look at the results of letting them vote.","2cc0bb8e":"# Data importing\nLet's see what kind of data we are going to analyze","7610542c":"# Sumarry\nWe checked basic data preprocessing methods, the implementation of well-known techniques, and the improvement of prediction accuracy through voting. Thank you.","42de1114":"# Preprocessing ","6120a027":"# Method and Score\n|Version|Voting Method|Accuracy|Comment|\n|:--:|:--|:--:|:--:|\n|1|RandomForest  + MLP + SVM + ExtraTrees| 89.5%|\n|2|RandomForest  + MLP + SVM + LGBMClassifier | 90.2%|**Best**|","eb09b789":"Ok, let's look at the data at this point.","0b19c4c0":"In this time, I would like to use \"Voting Clasifier\" by using \"Random Forest Regression\",\"Extra Trees Regression\" ,\"Liner SVC\" and \"Neural Network\" to try to predict heart failure.I hope it works :D\n\nFirst of all, we will split the data into training and test data.","a5ba96e9":"# Training and Predicting","eb970036":"Let's import the libraries we need.","554c99ba":"# Voting method","c9b63507":"It is well known that cholesterol levels can be divided into \"dangerous\", \"border\" and \"normal\" ranges. Therefore, we will create a new column for categorical data according to the numerical value.","2e4d6d4c":"estimator_results = [estimator.score(X_test,y_test) for estimator in estimators]\nprint(estimator_results)"}}