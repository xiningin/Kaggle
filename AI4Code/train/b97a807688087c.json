{"cell_type":{"f9a85186":"code","3182c673":"code","9ae45484":"code","27a42fd3":"code","816a42fa":"code","c2845a82":"code","2961607c":"code","15420ad2":"code","83170c7c":"code","a355ac84":"code","6eede0f5":"code","f88120e4":"code","f7050fd3":"code","1d3800a0":"code","5295f723":"code","eb7c8825":"code","e615b59c":"code","59b18d21":"code","21567f2e":"code","6541acd8":"code","8ed1f375":"code","ab6332b1":"code","d7350aa2":"code","c79778cc":"code","6c68cf09":"code","907c70d2":"code","a182e49d":"code","7177046b":"code","71412640":"code","67212e40":"code","271f253a":"code","44ae74ce":"code","ea80805f":"code","97066ebb":"code","34cde678":"code","f10eab97":"code","cb795267":"code","ecd19ce0":"code","b65ea4d5":"code","c7116b57":"code","3f11ccb7":"code","82ef58cb":"code","3187cf8b":"code","8369e2a9":"code","1e88dad3":"code","6acca05b":"markdown","ebec86dc":"markdown","5a24b7e6":"markdown","ecdf02e1":"markdown","7b54e517":"markdown","33e02adc":"markdown","8976148f":"markdown","4d2d515d":"markdown","a048f99b":"markdown","86f46a8d":"markdown","288949d9":"markdown","69b3d13f":"markdown","1abbd934":"markdown","edb6a9f5":"markdown","c95b3199":"markdown","adbdcf06":"markdown","7be0e242":"markdown"},"source":{"f9a85186":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go  \nfrom plotly.subplots import make_subplots\npd.set_option('precision',0)\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv1D, Dense, Flatten, Dropout, BatchNormalization,LSTM,SeparableConv1D\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\nimport warnings\nwarnings.filterwarnings('ignore')\n\n","3182c673":"url = \"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_confirmed_global.csv\"\ndf_confirmed = pd.read_csv(url)\nurl = \"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_deaths_global.csv\"\ndf_deaths = pd.read_csv(url)\nurl = \"https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/time_series_covid19_recovered_global.csv\"\ndf_recovered = pd.read_csv(url)\n","9ae45484":"df_confirmed.head(5)","27a42fd3":"df_deaths.head(5)","816a42fa":"df_recovered.head(5)","c2845a82":"df_list = [df_confirmed,df_deaths,df_recovered]\ncases = ['Confirmed', 'Deaths', 'Recovered', 'Active']\ncase_color = ['orange','red','green','blue']\ncase_dict = {cases[i]:case_color[i] for i in range(len(cases))}","2961607c":"## creating time series data\n\ntime_series_data = pd.DataFrame()\nfor i in range(len(cases)-1):\n    df =  pd.DataFrame(df_list[i][df_list[i].columns[4:]].sum(),columns=[cases[i]])\n    time_series_data = pd.concat([time_series_data,df],axis = 1)\ntime_series_data.index = pd.to_datetime(time_series_data.index,format='%m\/%d\/%y')\ntime_series_data['Active'] = time_series_data['Confirmed'] - time_series_data['Deaths'] - time_series_data['Recovered']\ntime_series_data= time_series_data.rename_axis('ObservationDate').reset_index()","15420ad2":"time_series_data.head(10).style.background_gradient(cmap='PuBu')","83170c7c":"time_series_data.info()","a355ac84":"country_wise_data = pd.DataFrame()\nfor i in range(len(cases)-1):\n    series =  df_list[i][df_list[i].columns[4:]].sum(axis = 1)\n    df = pd.concat([df_list[i]['Country\/Region'] ,series],axis = 1)\n    df = df.groupby('Country\/Region').sum().rename(columns = {0:cases[i]})\n    country_wise_data = pd.concat([country_wise_data,df],axis = 1)\ncountry_wise_data['Active'] = country_wise_data['Confirmed'] - country_wise_data['Deaths'] - country_wise_data['Recovered']\ncountry_wise_data = country_wise_data.reset_index()","6eede0f5":"country_wise_data.head(10).style.background_gradient(cmap='PuBu')","f88120e4":"country_wise_data.info()","f7050fd3":"country_wise_data = country_wise_data.sort_values(by='Confirmed',ascending=False).reset_index(drop = True)\ncountry_wise_data.head(10).style.background_gradient(cmap='Oranges',subset=[\"Confirmed\"])\\\n.background_gradient(cmap='Reds',subset=['Deaths'])\\\n.background_gradient(cmap='Greens',subset=[\"Recovered\"])\\\n.background_gradient(cmap='Blues',subset=[\"Active\"])","1d3800a0":"#Displaying dates where confirmed case counts were highest\ntime_series_data = time_series_data.sort_values('ObservationDate', ascending=False).reset_index(drop = True)\ntime_series_data.head(10).style.background_gradient(cmap='Oranges',subset=[\"Confirmed\"])\\\n.background_gradient(cmap='Reds',subset=['Deaths'])\\\n.background_gradient(cmap='Greens',subset=[\"Recovered\"])\\\n.background_gradient(cmap='Blues',subset=[\"Active\"])","5295f723":"time_series_data['Recovered'] = time_series_data['Recovered'].replace(to_replace=0, method='bfill')\ntime_series_data.head(10).style.background_gradient(cmap='Oranges',subset=[\"Confirmed\"])\\\n.background_gradient(cmap='Reds',subset=['Deaths'])\\\n.background_gradient(cmap='Greens',subset=[\"Recovered\"])\\\n.background_gradient(cmap='Blues',subset=[\"Active\"])","eb7c8825":"count_df = time_series_data.iloc[1,1:]\ncount_df = pd.DataFrame(count_df).reset_index(level = 0).rename(columns = {'index':'category',1:'count'})\nfig = px.bar(count_df, x='count', y='category',\n             hover_data=['count'], color='count',\n             labels={}, orientation='h',height=400, width = 650)\nfig.update_layout(title_text='<b>Confirmed vs Recovered vs Deaths vs Active<\/b>',title_x=0.5,showlegend = False) \nfig.show()","e615b59c":"df_confirmed = country_wise_data.loc[:,['Country\/Region','Confirmed']].sort_values(by = 'Confirmed',ascending = False).reset_index(drop = True).head(10)\ndf_deaths =    country_wise_data.loc[:,['Country\/Region','Deaths']].sort_values(by = 'Deaths',ascending = False).reset_index(drop = True).head(10)\ndf_active =    country_wise_data.loc[:,['Country\/Region','Active']].sort_values(by = 'Active',ascending = False).reset_index(drop = True).head(10)\ndf_recovered =    country_wise_data.loc[:,['Country\/Region','Recovered']].sort_values(by = 'Recovered',ascending = False).reset_index(drop = True).head(10)","59b18d21":"fig = px.bar(df_confirmed, x='Confirmed', y='Country\/Region',\n             hover_data=['Confirmed'], color='Confirmed',\n             labels={},orientation='h', height=800, width=650)\nfig.update_layout(title_text='<b>Total number of Confirmed cases<\/b>',title_x=0.5)\nfig.show()","21567f2e":"fig = px.bar(df_deaths, x='Deaths', y='Country\/Region',\n             hover_data=['Deaths'], color='Deaths',\n             labels={},orientation='h', height=800, width=650)\nfig.update_layout(title_text='<b>Total number of Death cases<\/b>',title_x=0.5)\nfig.show()","6541acd8":"fig = px.bar(df_active, x='Active', y='Country\/Region',\n             hover_data=['Active'], color='Active',\n             labels={},orientation='h', height=800, width=650)\nfig.update_layout(title_text='<b>Total number of Active cases<\/b>',title_x=0.5)\nfig.show()","8ed1f375":"fig = px.bar(df_recovered, x='Recovered', y='Country\/Region',\n             hover_data=['Recovered'], color='Recovered',\n             labels={},orientation='h', height=800, width=650)\nfig.update_layout(title_text='<b>Total number of Recovered cases<\/b>',title_x=0.5)\nfig.show()","ab6332b1":"# Cases over time\ntime_series_data = time_series_data.sort_values('ObservationDate').reset_index(drop = True)\ntime_series_data.iloc[:,1:] = time_series_data.iloc[:,1:].astype('int64')\ntime_series_data.head(10)","d7350aa2":"#cases_over_time moving average\ntime_series_data_avg = time_series_data.copy()\ntime_series_data_avg.iloc[:,1:] = time_series_data_avg.iloc[:,1:].rolling(window = 7, min_periods = 1).mean()\ntime_series_data_avg.head(20)","c79778cc":"tplot = go.Figure()\nfor case in cases:\n    tplot.add_trace(\n        go.Scatter(\n            x = time_series_data['ObservationDate'],\n            y = time_series_data[case],\n            name = case,\n            line = dict(color=case_dict[case]),\n            hovertemplate ='<br><b>Date<\/b>: %{x}'+'<br><b>Count<\/b>: %{y}',\n        )\n    )\nfor case in cases:\n    tplot.add_trace(\n        go.Scatter(\n            x = time_series_data_avg['ObservationDate'],\n            y = time_series_data_avg[case],\n            name = case + \" 7-day moving average\",\n            line = dict(dash = 'dash',color=case_dict[case]),\n            hovertemplate ='<br><b>Date<\/b>: %{x}'+'<br><b>Moving Average Count<\/b>: %{y}',\n            showlegend = False\n        )\n    )\n\ntplot.update_layout(\n    updatemenus=[\n        dict(\n        buttons=list(\n            [dict(label = 'All Cases',\n                  method = 'update',\n                  args = [{'visible': [True, True, True, True, True, True, True, True]},\n                          {'title': 'All Cases',\n                           'showlegend':True}]),\n             dict(label = 'Confirmed',\n                  method = 'update',\n                  args = [{'visible': [True, False, False, False, True, False, False, False]},\n                          {'title': 'Confirmed',\n                           'showlegend':True}]),\n             dict(label = 'Active',\n                  method = 'update',\n                  args = [{'visible': [False, False, False, True, False, False, False, True]},\n                          {'title': 'Active',\n                           'showlegend':True}]),\n             dict(label = 'Recovered',\n                  method = 'update',\n                  args = [{'visible': [False, False, True, False, False, False, True, False]},\n                          {'title': 'Recovered',\n                           'showlegend':True}]),\n             dict(label = 'Deaths',\n                  method = 'update',\n                  args = [{'visible': [False, True, False, False, False, True, False, False]},\n                          {'title': 'Deaths',\n                           'showlegend':True}]),\n            ]),type = 'buttons',\n             direction=\"right\",\n             showactive = True,\n             x=-0.25,\n             xanchor=\"left\",\n             y=1.25,\n             yanchor=\"top\"\n        ),\n        dict(\n        buttons=list(\n            [dict(label = 'Linear Scale',\n                  method = 'relayout',\n                  args = [{'yaxis': {'type': 'linear'}},\n                          {'title': 'All Cases',\n                           'showlegend':True}]),\n             dict(label = 'Log Scale',\n                  method = 'relayout',\n                  args = [{'yaxis': {'type': 'log'}},\n                          {'title': 'All Cases',\n                           'showlegend':True}]),\n            ]),\n             direction=\"right\",\n             x=-0.25,\n             xanchor=\"left\",\n             y=1.39,\n             yanchor=\"top\"\n        )\n    ])\n\ntplot.update_layout(\n    height=600, width=1100, \n    title_text=\"<b>Global cases over time<\/b>\", title_x=0.5, title_font_size=20,\n                            legend=dict(orientation='h',yanchor='top',y=1.15,xanchor='right',x=1), paper_bgcolor=\"snow\",\n                            xaxis_title=\"Observation Date\", yaxis_title=\"Number of Cases\")\ntplot.show()\n","6c68cf09":"# Cases over time\ntime_series_data_increase = time_series_data.copy()\ntime_series_data_increase.iloc[:,1:] = time_series_data_increase.iloc[:,1:].diff(1)\ntime_series_data_increase_avg  = time_series_data_increase.copy()\ntime_series_data_increase_avg.iloc[:,1:] = time_series_data_increase_avg.iloc[:,1:].rolling(window = 7, min_periods = 1).mean()","907c70d2":"fig = make_subplots(rows=len(cases), cols=1, vertical_spacing=0.2, horizontal_spacing=0.04, # shared_yaxes=True,\n                           subplot_titles=('<b>Confirmed<\/b>','<b>Active<\/b>','<b>Recovered<\/b>','<b>Deaths<\/b>'),\n                            x_title=\"Observation Date\", y_title=\"Number of Cases\")\n\n\nfor i in range(len(cases)):\n\n    fig.add_trace( go.Bar(\n                x = time_series_data_increase['ObservationDate'],\n                y = time_series_data_increase[cases[i]],\n                name = cases[i],\n                hovertemplate ='<br><b>Date<\/b>: %{x}'+'<br><b>Count<\/b>: %{y}',\n                marker = dict(color = case_dict[cases[i]])\n            ),row = i+1, col = 1)\n\n    fig.add_trace( go.Scatter(\n                x = time_series_data_increase_avg['ObservationDate'],\n                y = time_series_data_increase_avg[cases[i]],\n                name = cases[i],\n                hovertemplate ='<br><b>Date<\/b>: %{x}'+'<br><b>7-day average<\/b>: %{y}',\n                showlegend=False,\n                line=dict(dash=\"dash\", color=case_color[i])\n            ),row = 1+i, col = 1)\nfig.update_layout(\n    height=800, width=1100, \n    title_text=\"<b>Daily increase in global cases over time<\/b>\", title_x=0.5, title_font_size=20,\n                            legend=dict(orientation='h',yanchor='top',y=1.15,xanchor='right',x=1), paper_bgcolor=\"snow\")\nfig.show()\n\n","a182e49d":"fig,ax = plt.subplots(1,4,figsize = (20,5))\nfor i in range(len(cases)):\n    sns.set_style('whitegrid')\n    sns.distplot(time_series_data[cases[i]], kde = True, rug = True, bins = 25,ax =ax[i],color = case_color[i])\n    ax[i].set_xlabel( cases[i]+ ' cases')\n    ax[i].set_ylabel('Density')\n    ax[i].set_title('Distribution plot for ' + cases[i]+ ' cases')\nfig.tight_layout()\nplt.suptitle('Distribution of Cases',fontsize = 15,y = 1.1)\nplt.show()\n","7177046b":"dataset = time_series_data.iloc[:,1].values #using only confirmed cases\ndataset.shape","71412640":"#Feature scaling\nsplit = round(0.8*len(dataset))\ndataset = dataset.reshape(-1,1)\nscaler = MinMaxScaler(feature_range=(0,1))\nscaler.fit(dataset[:split]) #fit only on the training data which is the first 80%\ndataset_n = scaler.transform(dataset).flatten()\ndataset_n.shape\n","67212e40":"def create_dataset(df,previous,split_ratio):\n    X, Y = [], []\n    for i in range(len(df)-previous):\n        a = df[i:(i+previous)]\n        X.append(a)\n        y = df[i+previous]\n        Y.append(y)\n    X = np.array(X).reshape(-1,T,1)\n    Y = np.array(Y)\n    N = len(X)\n    split = round(split_ratio*len(df)) \n    X_train = X[:split]\n    X_test = X[split:]\n    Y_train = Y[:split]\n    Y_test = Y[split:]\n    print(\"X.shape\", X.shape, \"Y.shape\", Y.shape)\n    print(\"X_train.shape\", X_train.shape, \"Y_train.shape\", Y_train.shape)\n    print(\"X_test.shape\", X_test.shape, \"Y_test.shape\", Y_test.shape)\n    return X,X_train,X_test,Y,Y_train,Y_test","271f253a":"T = 5  #number of past days used to predict the value for the current day\nX,X_train,X_test,Y,Y_train,Y_test = create_dataset(dataset_n,T,0.8) #80% of data for training and 20% for testing","44ae74ce":"def plotLearningCurve(history,epochnum,batchnum):\n  epochRange = range(1,epochnum+1)\n  plt.figure(figsize = (5,5))\n  plt.plot(epochRange,history.history['loss'],'b',label = 'Training Loss')\n  plt.plot(epochRange,history.history['val_loss'],'r',label = 'Validation Loss')\n  plt.xlabel('Epoch', fontsize = 15)\n  plt.ylabel('Loss', fontsize = 15)\n  plt.grid(color='gray', linestyle='--')\n  plt.legend()\n  plt.title('LOSS, Epochs={}, Batch={}'.format(epochnum, batchnum))\n  plt.show()","ea80805f":"def lstm_model(previous):\n    i = Input(shape=(previous,1)) #input shape is n-timesteps x n-features\n    x = Conv1D(filters=64, kernel_size= 5, strides=3, padding=\"causal\", activation=\"relu\")(i)\n    x = LSTM(64, return_sequences=True)(x)\n    x = Dropout(0.4)(x)\n    x = LSTM(64,return_sequences=True)(x)\n    x = Dropout(0.4)(x)\n    x = LSTM(64)(x)\n    x = Dropout(0.2)(x)\n    x = Dense(1)(x)\n    model = Model(i, x)\n    model.summary()\n    return model","97066ebb":"model = lstm_model(T)","34cde678":" model.compile(loss = 'mse',\n              optimizer = 'adam')","f10eab97":"batchnum = 64\nepochnum = 100\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.8, \n                                            min_lr=1e-10)\nearly_stop = EarlyStopping(monitor='val_loss',patience=50,restore_best_weights=True)\nr = model.fit(X_train,\n                    Y_train,\n                    batch_size=batchnum,\n                    epochs=epochnum,\n                    validation_split=0.2,\n                    shuffle=False, #time_series\n                    callbacks=[learning_rate_reduction])","cb795267":"n_epochs = len(r.history['loss'])","ecd19ce0":"print(\"Train score:\", model.evaluate(X_train,Y_train))\nprint(\"Test score:\", model.evaluate(X_test,Y_test))\n","b65ea4d5":"plotLearningCurve(r,epochnum,batchnum)","c7116b57":"Y_pred = model.predict(X_test)\nY_pred = scaler.inverse_transform(Y_pred)\nY_test = scaler.inverse_transform(Y_test.reshape(-1,1))\nY_train = scaler.inverse_transform(Y_train.reshape(-1,1))\nplt.plot(Y_pred, color='red')\nplt.plot(Y_test, color='blue')\nplt.title('Actual vs. Predicted Covid Cases (Test Data)')\nplt.ylabel('Number of Cases')\nplt.xlabel('Day')\nplt.legend(['predicted', 'actual'])","3f11ccb7":"Y_train = Y_train.reshape(-1)\nY_test = Y_test.reshape(-1)\nY_pred = Y_pred.reshape(-1)","82ef58cb":"date_array = np.array(time_series_data['ObservationDate'].values)\ndate_train = date_array[:split]\ndate_test = date_array[split:]","3187cf8b":"\ntrace1 = go.Scatter(\n    x = date_train,\n    y = Y_train,\n    mode = 'lines',\n    name = 'Data'\n)\ntrace2 = go.Scatter(\n    x = date_test,\n    y = Y_pred,\n    mode = 'lines',\n    name = 'Prediction'\n)\ntrace3 = go.Scatter(\n    x = date_test,\n    y = Y_test,\n    mode='lines',\n    name = 'Ground Truth'\n)\nlayout = go.Layout(\n    title = \"<b>Confirmed Cases<\/b>\",\n    xaxis = {'title' : \"Date\"},\n    yaxis = {'title' : \"Cases\"}\n)\nfig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\nfig.show()","8369e2a9":"T = 5\nprediction_list = dataset_n[-T:]  #take last 100 values from the dataset\nnum_prediction = 30 #predicting cases for next 1 month\nfor _ in range(num_prediction):\n    x = prediction_list[-T:]\n    x = x.reshape((1,T, 1))\n    out = model.predict(x)[0][0]\n    prediction_list = np.append(prediction_list, out) #appending the prediction\nprediction_list = prediction_list[T-1:] \nprediction_list = scaler.inverse_transform(np.array(prediction_list).reshape(-1,1)).reshape(-1)\n\n\nlast_date = time_series_data['ObservationDate'].values[-1]\nprediction_dates = np.array(pd.date_range(last_date, periods=num_prediction+1))\n\n","1e88dad3":"trace1 = go.Scatter(\n    x = date_array,\n    y = dataset.reshape(-1),\n    mode = 'lines',\n    name = 'Data'\n)\ntrace2 = go.Scatter(\n    x = prediction_dates,\n    y = prediction_list,\n    mode = 'lines',\n    name = 'Forecast'\n)\n\nlayout = go.Layout(\n    title = \"<b>Confirmed Cases<\/b>\",\n    xaxis = {'title' : \"Date\"},\n    yaxis = {'title' : \"Cases\"}\n)\nfig = go.Figure(data=[trace1, trace2], layout=layout)\nfig.show()","6acca05b":"# **3. Exploratory Data Analysis**","ebec86dc":"### Forecasting future values","5a24b7e6":"### Creating country wise data from the extracted data","ecdf02e1":"**Comment:** <br>\nThe numbers of deaths are pretty low and the recovery numbers are lesser than the confirmed numbers.","7b54e517":"### Extracting data from the JHU Github repository","33e02adc":"### Predicting test data","8976148f":"# **1. Importing Libraries**","4d2d515d":"**Comment:** <br>\nSome recovery cases are zero so we will fill with previous non-zero values","a048f99b":"### Creating time series data from the extracted data","86f46a8d":"## Motivation\n\nPredicting the dynamics of SARS-Cov-2 infections is essential for quick and effective diagnosis of Covid19,public health planning and mitigating burden on healthcare systems. \n \n## Dataset Description\nThe John Hopkins University has a dedicated Github repository for Covid19 where it has been publishing time series data for confirmed, recovered and death cases every day for each country.\n\n## Project Overview\nTwo specific datasets - i.e. time based and country based are created from the JHU data. Exploratory data analysis is performed on this data followed by modeling using convolutional LSTM for prediction and forecasting.\n","288949d9":"### Building the model architecture","69b3d13f":"# **4.Predictive modelling using CNN + Bi-Directional LSTM**\n","1abbd934":"# **2. Creating dataset and preprocessing the dataset**\n\nWe will create a time series data and country data of Covid19 cases with the data exracted from the JHU repository","edb6a9f5":"**Comment**:<br>\nThe distribution plots are skewed. So appropriate normalization techniques need to be applied before modelling.","c95b3199":"### Forecasting","adbdcf06":"**Comment**: Based on the above table it can be said that US is the most affected country with respect to number of confirmed cases and fatalities.","7be0e242":"### Creating dataset for predictive modelling"}}