{"cell_type":{"9eedf8ed":"code","82a7f334":"code","7ff21f85":"code","819e4154":"code","80b97664":"code","9f1773f5":"code","07ccbfe8":"code","a4a2ccbd":"code","fcb190f4":"code","ed9e444a":"code","5d708c8d":"code","7c8c4ec1":"code","c405192c":"code","076a1667":"code","a5998581":"code","06e18fb2":"code","b31be91a":"code","c426de02":"code","66f5ccf9":"code","c47d6146":"code","d011a4f6":"code","2ce2d50f":"code","5023c040":"code","7432337c":"code","767ba145":"code","a7a3ff4f":"code","4d4cdb2a":"code","f6e1f7eb":"code","e5f8531b":"code","9f97b86e":"code","66894beb":"code","00484996":"code","c2ac9b73":"code","891a64eb":"code","dbef2391":"code","d96a4d09":"code","3ee781ef":"code","f3b351b8":"code","6884fde1":"code","aa15fdc2":"markdown","a2c9da53":"markdown","842a3c57":"markdown","5e693d11":"markdown","58abe3e6":"markdown","57c3b1e4":"markdown","2fc34509":"markdown","b22e06dc":"markdown","5173838b":"markdown","ac79842e":"markdown","b6fdb8f7":"markdown","a6cec7a2":"markdown","848a43eb":"markdown","1c2e010f":"markdown","f7fc62e1":"markdown","5f5bd019":"markdown","6fbd3cb4":"markdown","446fd0cb":"markdown","bf94d618":"markdown","e9f542bb":"markdown","8bc27517":"markdown","1093c837":"markdown","6d3a9431":"markdown"},"source":{"9eedf8ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","82a7f334":"#Importing libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score","7ff21f85":"# loading the dataset to a pandas DataFrame\n# Read .csv file into dataframe\ndata = pd.read_csv('\/kaggle\/input\/loan-status\/Loan_status.csv')\ndata.head()","819e4154":"#Shape of data \nprint(\"The shape of data is \",data.shape)\n#dtypes of data \nprint(data.dtypes)","80b97664":"# Info of data\ndata.info()","9f1773f5":"# Checking for null values\ndata.isnull().sum()","07ccbfe8":"# Dropping null values\nfinal_data = data.dropna()\nfinal_data.isnull().sum()","a4a2ccbd":"# label encoding\nfinal_data.replace({\"Loan_Status\":{'N':0,'Y':1}},inplace=True)\n# printing the first 5 rows of the dataframe\nfinal_data.head(5)","fcb190f4":"# Value_counts of loan_status\nfinal_data['Loan_Status'].value_counts()","ed9e444a":"# Value_counts of Dependents\nfinal_data['Dependents'].value_counts()","5d708c8d":"# convert 3+ to 4\nfinal_data = final_data.replace(to_replace='3+',value=4)\n# Checking for value again\nfinal_data['Dependents'].value_counts()","7c8c4ec1":"# education & Loan Status\nsns.countplot(x='Education',hue='Loan_Status',data=final_data)","c405192c":"# marital status & Loan Status\nsns.countplot(x='Married',hue='Loan_Status',data=final_data)","076a1667":"# marital status & Loan Status\nsns.countplot(x='LoanAmount',hue='Loan_Status',data=final_data)","a5998581":"# marital status & Loan Status\nsns.countplot(x='Property_Area',hue='Loan_Status',data=final_data)    ","06e18fb2":"# convert categorical columns to numerical values\nfinal_data.replace({'Married':{'No':0,'Yes':1},'Gender':{'Male':1,'Female':0},'Self_Employed':{'No':0,'Yes':1},\n                      'Property_Area':{'Rural':0,'Semiurban':1,'Urban':2},'Education':{'Graduate':1,'Not Graduate':0}},inplace=True)","b31be91a":"final_data.head()","c426de02":"# separating the data and label\nX = final_data.drop(columns=['Loan_ID','Loan_Status'],axis=1)\ny = final_data['Loan_Status']","66f5ccf9":"print(\"Shape of X is \" ,X.shape)\nprint(\"Shape of Y is \" ,y.shape)","c47d6146":"# separating into train and testing\nX_train, X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=42)\nprint(\"Shape of X_train is \" ,X_train.shape)\nprint(\"Shape of X_test  is \" ,X_test.shape)\nprint(\"Shape of Y_train is \" ,Y_train.shape)\nprint(\"Shape of Y_test  is \" ,Y_test.shape)","d011a4f6":"# After statify Y train & test values\nprint(Y_train.value_counts())\nprint(Y_test.value_counts())","2ce2d50f":"classifier_model = svm.SVC(kernel='linear')\nclassifier_model.fit(X_train,Y_train)","5023c040":"from sklearn.linear_model import LogisticRegression\nlogistic_model = LogisticRegression(max_iter=200)\nlogistic_model.fit(X_train,Y_train)","7432337c":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nsc_X_train = sc_X.fit_transform(X_train)\nsc_X_test = sc_X.transform(X_test)","767ba145":"from sklearn.tree import DecisionTreeClassifier\ndecision_tree_model = DecisionTreeClassifier(random_state = 0)\ndecision_tree_model.fit(sc_X_train,Y_train)","a7a3ff4f":"# hyper parameter tuning\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_params = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : [3, 5, 7, 10],\n    'min_samples_split' : range(2, 10, 1),\n    'min_samples_leaf' : range(2, 10, 1)\n}\n\ngrid_search = GridSearchCV(decision_tree_model, grid_params, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search.fit(sc_X_train, Y_train)","4d4cdb2a":"# best parameters and best score\n\nprint(grid_search.best_params_)\nprint(grid_search.best_score_)","f6e1f7eb":"from sklearn.neighbors import KNeighborsClassifier\nk_model = KNeighborsClassifier(n_neighbors=16)\nkfitModel = k_model.fit(sc_X_train, Y_train)\nprint(kfitModel)\n#predictions = fitModel.predict(X_test)","e5f8531b":"# finding optimal values for k\nfrom sklearn.model_selection import cross_val_score\ncross_valid_scores = []\nfor k in range(1, 100):\n  knn = KNeighborsClassifier(n_neighbors = k)\n  scores = cross_val_score(knn,X, y, cv = 10, scoring = 'accuracy')\n  cross_valid_scores.append(scores.mean())    \n\nprint(\"Optimal k with cross-validation: \\t\",np.argmax(cross_valid_scores))","9f97b86e":"# Random Forest model\nfrom sklearn.ensemble import RandomForestRegressor\nmodelRF = RandomForestRegressor(random_state = 0)\nmodelRF.fit(sc_X_train,Y_train)","66894beb":"# accuracy score on training data\n\nX_train_prediction = classifier_model.predict(X_train)\ntraining_data_accuray = accuracy_score(X_train_prediction,Y_train)\nprint('Accuracy on training data : ', training_data_accuray)\n\n# accuracy score on testing data\n\nX_test_prediction = classifier_model.predict(X_test)\nsvm_test_data_accuray = accuracy_score(X_test_prediction,Y_test)\nprint('Accuracy on test data    : ', svm_test_data_accuray)","00484996":"# accuracy score on training data\n\nX_train_prediction = logistic_model.predict(sc_X_train)\ntraining_data_accuray = accuracy_score(X_train_prediction,Y_train)\nprint('Accuracy on training data  : ', training_data_accuray)\n\n# accuracy score on testing data\nX_test_prediction = logistic_model.predict(sc_X_test)\nlgr_test_data_accuray = accuracy_score(X_test_prediction,Y_test)\nprint('Accuracy on test data      : ', lgr_test_data_accuray)","c2ac9b73":"dtc = grid_search.best_estimator_\ny_pred = dtc.predict(sc_X_test)\ndtc_train_acc = accuracy_score(Y_train, dtc.predict(sc_X_train))\ndtc_test_acc = accuracy_score(Y_test, y_pred)\n\nprint(f\"Training Accuracy of Decesion Tree Model is {dtc_train_acc}\")\nprint(f\"Test Accuracy of Decesion Tree Model is {dtc_test_acc}\")","891a64eb":"import matplotlib.pyplot as plt\nfrom sklearn import tree\nplt.figure(figsize=(15,10))\ntree.plot_tree(dtc,filled=True)","dbef2391":"# accuracy score on testing data\nX_test_prediction = logistic_model.predict(sc_X_test)\nkr_test_data_accuray = accuracy_score(X_test_prediction,Y_test)\nprint('Accuracy on test data      : ', kr_test_data_accuray)\n","d96a4d09":"for i in range(0,10):\n  plt.figure(figsize=(15,10))\n  tree.plot_tree(modelRF.estimators_[i],filled=True)","3ee781ef":"# accuracy score on training data\n\nkX_train_prediction = kfitModel.predict(sc_X_train)\ntraining_data_accuray = accuracy_score(kX_train_prediction,Y_train)\nprint('Accuracy on training data  : ', training_data_accuray)\n\n# accuracy score on testing data\nkX_test_prediction = kfitModel.predict(sc_X_test)\nkx_lgr_test_data_accuray = accuracy_score(kX_test_prediction,Y_test)\nprint('Accuracy on test data      : ', kx_lgr_test_data_accuray)","f3b351b8":"models = ['Logistic Regression','KNN','SVC', 'Decision Tree', 'Random Forest']\nscores = [lgr_test_data_accuray,kx_lgr_test_data_accuray, svm_test_data_accuray, dtc_test_acc, kr_test_data_accuray]\nmodels = pd.DataFrame({'Model' : models, 'Score' : scores})\nmodels.head()","6884fde1":"import matplotlib.pyplot as plt\n\nplt.figure(figsize = (18, 8))\n\nsns.barplot(x = 'Model', y = 'Score', data = models)\nplt.show()","aa15fdc2":"## **Random Forest model**","a2c9da53":"## **Model Evaluation Of SVM**","842a3c57":"## **SVM model**","5e693d11":"# **Exploratory data analysis**","58abe3e6":"## **Model Evaluation of Random Forest**","57c3b1e4":"# **Getting Started**\n\n**Title : Loan Status Prediction**\n\nLoan Status :\n\n0 -- > No loan pending\n\n1 -- > loan pending","2fc34509":"# **Model Preparation**","b22e06dc":"# **Model Evaluation**","5173838b":"**LR, KNN, Random forest score is mostly same.**","ac79842e":"## **Logistic Regression Model**","b6fdb8f7":"## **Descision Tree**","a6cec7a2":"## **Visualization for Random Forest trees**","848a43eb":"## **Feature Scaling for Decision tree & Random Forest**","1c2e010f":"### **Visualization for DTR trees**","f7fc62e1":"## **Models Best Scores : -**","5f5bd019":"# **Model Preparation**\n\nWe will train different model after the evaluation of model we will select out best model for production.\n\n1.   SVM Model\n2.   Logistic Regression\n3.   Random Forest Regressor\n4.   Decision Tree \n5.   KNN","6fbd3cb4":"### **Model Evaluation of DTR after hypertuning**","446fd0cb":"# **Transformation**","bf94d618":"# **Data Visualization**","e9f542bb":"## **Model Evaluation Of LGR**\n\n","8bc27517":"## **KNeighborsClassifier**","1093c837":"\n### **SVC gives us the best result so we will save this model for production.**","6d3a9431":"## **Model Evaluation of KNN**"}}