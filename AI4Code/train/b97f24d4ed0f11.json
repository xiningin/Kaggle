{"cell_type":{"3fdef23b":"code","b39a13c9":"code","d332f286":"code","28ba9f93":"code","4ceefade":"code","eb985470":"code","3c1c3b06":"code","fb0d18c5":"code","ea09970c":"code","b4f90770":"code","cbcaa004":"code","bf90177b":"code","26751c52":"code","c955c764":"code","542d7add":"code","f4b7ef28":"code","0a024e5c":"code","ff72ee45":"code","3961b9c0":"code","7ff3b616":"code","cbd49b30":"code","5b1ced5d":"code","a9012e41":"code","09301966":"code","503cd2e2":"code","5758c922":"code","8f49260b":"code","434b37d6":"code","77ef0d93":"code","f57a7065":"code","a185f97a":"code","4d4df0d0":"code","ecd3b77e":"code","2a1ebeb2":"markdown","00ae274c":"markdown","ad078796":"markdown","643eeb37":"markdown","b4c9a477":"markdown","eff332f0":"markdown","b636f117":"markdown","df5ccc44":"markdown"},"source":{"3fdef23b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b39a13c9":"import matplotlib\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set(color_codes = True)\n%matplotlib inline\npd.pandas.set_option('display.max_columns', None)\n\n\nfrom sklearn.linear_model import LinearRegression,SGDClassifier, RidgeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler , StandardScaler","d332f286":"df_train = pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/health-insurance-cross-sell-prediction\/test.csv\")\n\ndf_train.head()","28ba9f93":"## check Nan value\nfor i in df_train.columns:\n    print (i+\": \"+str(df_train[i].isna().sum()))","4ceefade":"# remove cloumns that wont help to build the model.\ndf = df_train.drop(['id','Region_Code','Policy_Sales_Channel'],axis = 1)","eb985470":"#convert Categorical feature in nominal encoding\ndf[\"Gender\"] = pd.get_dummies(df['Gender'],drop_first = True)\ndf['Vehicle_Damage'] = pd.get_dummies(df[\"Vehicle_Damage\"],drop_first = True)","3c1c3b06":"# perform ordinal encoding on vehicle age\nlabel = LabelEncoder()\n\ndf['Vehicle_Age'] = label.fit_transform(df['Vehicle_Age'])\n\ndf.head()","fb0d18c5":"# From the bar chart we can say men are caught in more vehicle damage as compared to female.\nplt.figure(figsize = (15,8))\nax = sns.barplot(x=\"Gender\", y=\"Vehicle_Damage\", data=df,palette = 'icefire_r')","ea09970c":"# it is clearly showing person who dont have Insurance that having more damage as compared to person who got an insurance.\nplt.figure(figsize = (15,8))\nax = sns.barplot(x=\"Previously_Insured\", y=\"Vehicle_Damage\", data=df,palette = 'RdPu_r')","b4f90770":"# From below graph we can predict vehicle age matters when it comes to an accident or damage.\nplt.figure(figsize = (15,8))\nax = sns.barplot(x=\"Vehicle_Age\", y=\"Vehicle_Damage\", data=df)","cbcaa004":"# Most of the people who caught in damage they took an insurance. \nplt.figure(figsize = (15,8))\nax = sns.barplot(x=\"Response\", y=\"Vehicle_Damage\", data=df)","bf90177b":"#Below graph shows it never affect parameter vintage(person associate with company in days), graph is just evenly splitted.\n\nax = sns.violinplot(x=\"Response\", y=\"Vintage\", data=df,\n                    inner=None, color=\".8\")\nax = sns.stripplot(x=\"Response\", y=\"Vintage\", data=df)","26751c52":"# From below Scatter plot, we can not classify weather person who will pay more or less premium will buy an insurance, so will go for more visualization.\n\n\nplt.figure(figsize=(16,8)) # Adding size to the graph- width by height\n# Use `+` as marker; color set as `g` (green); size proportion to Y values\nplt.scatter(x = df['Response'], y = df.Annual_Premium, c='r',alpha = 0.2) \n# set x\/y labels\nplt.xlabel('Response')\nplt.ylabel('Annual_Premium')\n# set title\nplt.title('Response vs Annual_Premium')","c955c764":"# Scatter plot shows us all people who have age range between 20-80, fill annual premium nearly 100000-150000 range.\n\nplt.figure(figsize=(16,8)) # Adding size to the graph- width by height\n# Use `+` as marker; color set as `g` (green); size proportion to Y values\nplt.scatter(x = df['Vintage'], y = df.Annual_Premium, c='r') \n# set x\/y labels\nplt.xlabel('Vintage')\nplt.ylabel('Annual_Premium')\n# set title\nplt.title('Vintage vs Annual_Premium')","542d7add":"plt.figure(figsize=(16,8)) # Adding size to the graph- width by height\n# Use `+` as marker; color set as `g` (green); size proportion to Y values\nplt.scatter(x = df['Age'], y = df.Annual_Premium, c='r') \n# set x\/y labels\nplt.xlabel('Age')\nplt.ylabel('Annual_Premium')\n# set title\nplt.title('Age vs Annual_Premium')","f4b7ef28":"# Check outliers using boxpot method.\nax = sns.boxplot(x=\"Annual_Premium\",data = df)","0a024e5c":"Q1 = df['Annual_Premium'].quantile(0.25)\nQ3 = df['Annual_Premium'].quantile(0.75)\nIQR = Q3 - Q1\n\nfilter = (df['Annual_Premium'] >= Q1 - 1.5 * IQR) & (df['Annual_Premium']<= Q3 + 1.5 *IQR)\ntrain2 = df.loc[filter]  \nprint(\"data loss percentage {}%\".format(((len(df) - len(train2))\/len(df))*100))","ff72ee45":"train2.head()","3961b9c0":"# Using correlation check how other parameter will affect on dependent feature, If it is affecting negatively then you can remove variable as it is impacting negatively. However I am not removing variable.\ncorrelation = train2.corr()\n\nplt.figure(figsize = (20,8))\nsns.heatmap(correlation,annot = True,cmap = 'gist_heat')","7ff3b616":"# Separate Dependent variable and Independent variable.\nx = train2.iloc[:,:-1]\ny = train2.iloc[:,-1]","cbd49b30":"# Standard scaler helps us to make all variable in same unit.\nstandard = StandardScaler()\n\nstd_x = standard.fit_transform(x)","5b1ced5d":"x_final = np.array(std_x)\ny_final = np.array(y)\n\nx_final.shape","a9012e41":"y_final.shape","09301966":"from sklearn.model_selection import train_test_split\n\n\n#Split data into Train and test format\nx_train,x_test,y_train,y_test = train_test_split(x_final,y_final,test_size = 0.20,random_state =35)\n\nprint('Shape of Training Xs:{}'.format(x_train.shape))\nprint('shape of Test:{}'.format(x_test.shape))","503cd2e2":"clf = LogisticRegression()\n\nclf.fit(x_train,y_train)\ny_predicted = clf.predict(x_test)\nscore = clf.score(x_test,y_test)\n\n\nprint(score)\n#results.append(score)","5758c922":"cnf_matrix = confusion_matrix(y_test, y_predicted)\nnp.set_printoptions(precision=2)\ncnf_matrix","8f49260b":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","434b37d6":"classes = df['Response'].value_counts()","77ef0d93":"plt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes.index,\n                      title='Confusion matrix, without normalization')\n# With normalization\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes= classes.index, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","f57a7065":"from sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier()\n\nclf.fit(x_train,y_train)\nscore = clf.score(x_test,y_test)\ny_predicted = clf.predict(x_test)\n\nprint(score)","a185f97a":"cnf_matrix = confusion_matrix(y_test, y_predicted)\nnp.set_printoptions(precision=2)\ncnf_matrix","4d4df0d0":"from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\nclf.fit(x_train,y_train)\n\nscore = clf.score(x_test,y_test)\ny_predicted = clf.predict(x_test)\n\nprint(score)","ecd3b77e":"cnf_matrix = confusion_matrix(y_test, y_predicted)\nnp.set_printoptions(precision=2)\ncnf_matrix","2a1ebeb2":"<a id=\"1\"><\/a>\n<h1 style='background:#a9a799; border:0; color:black'><center>LIBRARIES<\/center><\/h1>","00ae274c":"- It seems like customer who are interested these are predicting wrong in logistic algorithm let dig more and try to predict with another method.","ad078796":"<a id='top'><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 style='background:#a9a799; border:0; color:black'><center>INDEX<\/center><\/h1>","643eeb37":"<a id=\"2\"><\/a>\n<h1 style='background:#a9a799; border:0; color:black'><center>IMPORT_DATA<\/center><\/h1>","b4c9a477":"- 1.Import Libraries\n- 2.Import Data\n- 3.Data Visualization\n- 4.Data Preprocessing\n- 5.Validation Technique\n- 6.Model Building\n- 7.Confusion Matrix","eff332f0":"<a id=\"5\"><\/a>\n<h1 style='background:#a9a799; border:0; color:black'><center>CONFUSION_MATRIX<\/center><\/h1>","b636f117":"<a id=\"4\"><\/a>\n<h1 style='background:#a9a799; border:0; color:black'><center>BUILD_MODEL<\/center><\/h1>","df5ccc44":"<a id=\"3\"><\/a>\n<h1 style='background:#a9a799; border:0; color:black'><center>DATA_PREPROCESSING& DATA_VISUALIZATION<\/center><\/h1>"}}