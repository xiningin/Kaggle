{"cell_type":{"ca5b41f1":"code","0595c846":"code","214258df":"code","b314c8af":"code","bdc910fc":"code","41408bc5":"code","8ee92bb6":"code","ea187217":"code","ac66ea66":"code","9bbc5436":"code","d175d90f":"code","7b53c788":"code","932b0f6d":"code","f75c8508":"code","da4dc0bd":"code","1085a00f":"code","1db498b0":"code","0f7b9391":"code","c82f7694":"code","583d333c":"code","fcc4ec13":"code","a425256c":"code","0941cfbb":"code","094eab7f":"code","28373e9a":"code","09a98e92":"code","0ff84bda":"code","298e29c4":"code","9d98d188":"code","818c6524":"code","db11a986":"code","03242b86":"code","cc57960c":"code","dac211b7":"code","6c08a663":"code","c8fb5001":"code","7eac45d2":"code","a2e454a5":"code","285d0bb8":"code","c4aae0fa":"code","169bcc77":"code","7719eed5":"code","40e2d610":"code","d260b01f":"code","3bee8662":"code","947203a9":"code","536f0b73":"code","908c6ea7":"code","58a1d13b":"code","fc1755db":"code","963a263e":"code","3eb9a987":"code","209d04e5":"code","9c9a63c0":"markdown","3bb9a181":"markdown","923c07b3":"markdown","948dc443":"markdown","c8b9bc33":"markdown","d431134b":"markdown","36fb818e":"markdown","f595a6af":"markdown","496d0dd0":"markdown","33aab1a0":"markdown","6e2580be":"markdown","56820274":"markdown","b4122f6e":"markdown","0e5f4689":"markdown","c0982286":"markdown","5f7dd3fa":"markdown","aec942d2":"markdown","7824b4a4":"markdown","7f187261":"markdown","eb17c2d6":"markdown","c34af1bf":"markdown","bb6214c7":"markdown","d09e0287":"markdown","5805126d":"markdown","3c35b92e":"markdown","e787b0eb":"markdown","22d15833":"markdown","491b2f70":"markdown","c0710e5a":"markdown","50b88252":"markdown","01413189":"markdown","a8adf1e0":"markdown"},"source":{"ca5b41f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0595c846":"df=pd.read_csv('\/kaggle\/input\/online-retail-data-set-from-ml-repository\/retail_dataset.csv')","214258df":"df.head()","b314c8af":"df.fillna('<nothing>',inplace=True)","bdc910fc":"labels=df.values.reshape(-1)\nlabels=set(labels)","41408bc5":"labels        ","8ee92bb6":"from sklearn.preprocessing import OneHotEncoder","ea187217":"ohe=OneHotEncoder()","ac66ea66":"ohe.fit(np.asarray(list(labels)).reshape(-1,1))","9bbc5436":"ohe.categories_","d175d90f":"ohe.transform([[df['0'][4]]]).toarray()","7b53c788":"import torch as T\nimport torch.nn as nn","932b0f6d":"class Network(nn.Module):\n    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n        super(Network,self).__init__()\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True) \n        self.fc = nn.Sequential(nn.Linear(hidden_dim, hidden_dim),\n                    nn.ReLU())\n        self.out=nn.Sequential(\n                    nn.Linear(hidden_dim,output_size),\n                    nn.LogSoftmax()\n        \n        )\n    def forward(self, x):\n        \n        batch_size = x.size(0)\n\n        hidden = self.init_hidden(batch_size)\n\n        out, hidden = self.rnn(x, hidden)\n        \n        \n        out = out.contiguous().view(-1, self.hidden_dim)\n        out = self.fc(out)\n        out=self.out(out)\n        return out, hidden\n    \n    def init_hidden(self, batch_size):\n        hidden = T.zeros(self.n_layers, batch_size, self.hidden_dim)\n    \n        return hidden ","f75c8508":"model=Network(input_size=len(labels),output_size=len(labels),hidden_dim=8,n_layers=1)","da4dc0bd":"model","1085a00f":"model.forward(T.from_numpy(ohe.transform([[df['0'][0]]]).toarray()).unsqueeze(0).float())","1db498b0":"X=np.zeros((1,7,10))\n\nfor x in range(len(df)):\n    X=np.concatenate((X,ohe.transform(df.values[x].reshape(-1, 1)).toarray().reshape(1,7,10)),axis=0)","0f7b9391":"X.shape","c82f7694":"model.forward(T.from_numpy(X[1]).float().unsqueeze(0))","583d333c":"X=T.from_numpy(X[1:]).float()","fcc4ec13":"X","a425256c":"optimizer=T.optim.Adam(model.parameters())","0941cfbb":"creterion = nn.CrossEntropyLoss()","094eab7f":"out=model.forward(X[0].unsqueeze(0))","28373e9a":"out","09a98e92":"Y=X[:,1:,:].max(axis=2)[1]","0ff84bda":"X=X[:,0:-1,:]","298e29c4":"out=model.forward(X[0].unsqueeze(0))","9d98d188":"X[:,0:,:].shape","818c6524":"creterion(out[0],Y[0])","db11a986":"X.shape\n","03242b86":"out=model.forward(X)","cc57960c":"creterion(out[0],Y.view(-1,1).squeeze(1))","dac211b7":"#normalizing\ns=df['0'].value_counts()+df['1'].value_counts()+df['3'].value_counts()+df['2'].value_counts()+df['4'].value_counts()+df['5'].value_counts()+df['6'].value_counts()","6c08a663":"s=2*s","c8fb5001":"s[0]=50","7eac45d2":"s","a2e454a5":"s=6*s\/sum(s)","285d0bb8":"s","c4aae0fa":"mask=T.from_numpy(s.to_numpy())","169bcc77":"mask","7719eed5":"X=X*mask","40e2d610":"losses=[]\nfor i in range(6500):\n        \n   optimizer.zero_grad()\n   out=model.forward(X.float())\n   loss=creterion(out[0],Y.view(-1,1).squeeze(1))\n        \n   losses.append(loss.item())\n   loss.backward()\n   if(i%500==0):\n        print('loss is {}'.format(loss.item()))\n   optimizer.step()","d260b01f":"from matplotlib import pyplot as plt\nplt.plot(losses)","3bee8662":"def predict(model,item):\n#     item=ohe.transform(item)\n    out, hidden = model(item)\n    prob = nn.functional.softmax(out[-1], dim=0).data\n    # Taking the class with the highest probability score from the output\n    idx = T.topk(prob,k=4, dim=0)\n    return idx, hidden","947203a9":"p=predict(model,X[2,0].reshape([1,1,-1]).float())","536f0b73":"p[0][1]","908c6ea7":"def conv_from_idx(idx):\n    return ohe.categories_[0][idx]","58a1d13b":"conv_from_idx(p[0][1][0])","fc1755db":"from random import randint","963a263e":"def sample(model,inital_data):\n    l=[]\n    for i in inital_data:\n\n        p=predict(model,i.float())\n        print(conv_from_idx(p[0][1][0]))\n        l.append(p[0])\n    return l","3eb9a987":"X.shape","209d04e5":"for i in range(100):\n    l = []\n    for j in range(3):\n        l.append(conv_from_idx(X[i][j].max(axis=0)[1]))\n        print('for {} consumer can buy '.format(l),end=' ')\n        sample(model,[X[i][0:j+1].unsqueeze(0).float()])","9c9a63c0":"This is our function to convert back ohe to class ame","3bb9a181":"SO Y is actually next input or X, so we shift X one unit and get max to get idx of class to which it belong","923c07b3":"So we have following classes or labels","948dc443":"Lets try our model","c8b9bc33":"Lets Create Our Model. It is a simple model with a Gated RNN and then 1 connected layers and 1 output layer","d431134b":"so result is fine for one output, lets check for whole dataset","36fb818e":"So we are actually getting top 4 classes with highest probilities of comming next.","f595a6af":"Lets check our loss and optimizer for one step","496d0dd0":"So we need a diaper after buying bread and wine :D","33aab1a0":"okay so first input is actually all zeros we will not convert them to tensors","6e2580be":"Lets One Hot Code them, Later we will also normalize the input so we dont get same result continuously due to screwed data","56820274":"lets check our fucntion","b4122f6e":"here first tensor is our output or we can use these to extract prob for each classes later in our function predict()","0e5f4689":"So we have reduced our loss and curve seems to flat out","c0982286":"So lets predict the muliple results","5f7dd3fa":"Lets check our model and solve errors if any","aec942d2":"lets do some predictions","7824b4a4":"So we whave loaded basics modules pd and np. Lets load our data into a dataframe","7f187261":"lets try X[0] our model","eb17c2d6":"Lets us create X(input) for our model,first we take one hot encodings of columns of df and then concatenate it to previously calculated ohe of previous columns ","c34af1bf":"so our one hot encoder is ready","bb6214c7":"seems fine,we will implement a function later to convert it back to class.","d09e0287":"lets try it out","5805126d":"Meat is having highest probability to be a good suggestion depepnding upon first thing consumer buy","3c35b92e":"lets change nan to <<nothing>>.its not a compulsory but when testing model it seems better to seem \"nothing\"(ie customer will not take anything else) rather than nan ","e787b0eb":"similarly there is no use of last value in x as a input","22d15833":"Hey, This Notebook is an attempt to use rnn network to try to predict frequently bought object together. I am not sure rnn are supposed to be used this way or not but it helped me to learn bout rnn module and also nlp without preprocessing the sentences before being fed to network.","491b2f70":"Our Data Looks Like...","c0710e5a":"We are using Adams optimizer and cross entropy as our loss function","50b88252":"Choosing Y. we our using crossentropy which requires [0 to num_classes] as target and probs as y_hat","01413189":"so model  is ready,\n\nA final step:\nsee we dont wnat our model predicting too much <nothing> class. We we count all occurences of a word and then assign a low value to <nothing> class.","a8adf1e0":"so we need to create a one hot code for our input.\n\nfirst we should know all labels.\n\nwe use set to remove all repeated elements"}}