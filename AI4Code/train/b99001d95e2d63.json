{"cell_type":{"955b40af":"code","9a8a3363":"code","2ea6a523":"code","5977516a":"code","c9426daa":"code","f362b3a3":"code","24c211ef":"code","27556dc0":"code","82b33cef":"code","2ba3cedb":"markdown","1c3450e0":"markdown","64c55547":"markdown","401c4bcf":"markdown","4b029011":"markdown"},"source":{"955b40af":"import tensorflow as tf\nimport numpy as np","9a8a3363":"model = tf.saved_model.load('..\/input\/baseline-landmark-retrieval-model\/baseline_landmark_retrieval_model')","2ea6a523":"len(model.variables)","5977516a":"model.graph.get_collection('variables')[:10]","c9426daa":"var_names = [var.name for var in model.graph.get_collection('variables')]","f362b3a3":"test_in = tf.constant(np.uint8(np.random.randn(300, 300, 3)))","24c211ef":"var_names_to_fetch = [\n    var_name[:-2] + '\/read' + var_name[-2:] for var_name in var_names]\n\nweight_fetcher = model.prune(\n    feeds=[\"input_image:0\"],\n    fetches=var_names_to_fetch\n)\n\nweights = weight_fetcher(test_in)","27556dc0":"len(weights) == len(model.graph.get_collection('variables'))","82b33cef":"weights[0].numpy().shape, weights[0].numpy()","2ba3cedb":"Now, all numpy arrays with model parameters are saved into eager Tensors in the `weights` list.","1c3450e0":"Firstly, this magic one-liner shows us list of variables that are hidden in model's graph.","64c55547":"The baseline model provided by organizers was really tricky to work with. In particular, it was hard even to re-save the model, since the variables were not recorded.","401c4bcf":"It turned out that getting to model's variables (which then can be used, for example, for loading them into Keras reimplementation, using Keras `set_weights()` function from `Model` API) is tricky. Below I present the way to load the weights into numpy arrays, in order to be able to use them later (for example in Keras).","4b029011":"Now that we have variable names, we can use the following trick, which I discovered by reading TF source code and examining model in Tensorboard, to load the weights into numpy arrays."}}