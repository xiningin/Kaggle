{"cell_type":{"f9dd8f8a":"code","e46d7cf7":"code","b5ebd17d":"code","a5b96fc0":"code","d01e9870":"code","7e9cab7c":"code","cda804d6":"code","5774718a":"code","0bcba44a":"code","804a5662":"code","c3ea9921":"code","9c14d7d2":"code","cfc835ed":"code","d65d9659":"code","4316dac1":"code","723a4b77":"code","aaef75f4":"code","dd9f27ae":"code","db16e6fc":"code","d8e02454":"markdown","3bc40d56":"markdown"},"source":{"f9dd8f8a":"import os\nimport cv2\nimport numpy as np\nfrom collections import defaultdict\n\nimport scikitplot\nimport seaborn as sns\nfrom matplotlib import pyplot\n\nimport tensorflow as tf\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling3D, GlobalMaxPool3D\nfrom tensorflow.keras.layers import TimeDistributed, LSTM, Bidirectional, ConvLSTM2D\nfrom tensorflow.keras.layers import Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","e46d7cf7":"INPUT_PATH = \"..\/input\/ck48-5-emotions\/CK+48\/\"\n\nfor dir_ in os.listdir(INPUT_PATH):\n    count = 0\n    for f in os.listdir(INPUT_PATH + dir_ + \"\/\"):\n        count += 1\n    print(f\"{dir_} has {count} number of images\")","b5ebd17d":"TOP_EMOTIONS = [\"happy\", \"surprise\", \"anger\", \"sadness\", \"fear\"]","a5b96fc0":"INPUT_PATH = \"..\/input\/ck48-5-emotions\/CK+48\/\"\n\ndata = defaultdict(str)\nfor dir_ in os.listdir(INPUT_PATH):\n    if dir_ in TOP_EMOTIONS:\n        data[dir_] = defaultdict(list)\n        for f in os.listdir(INPUT_PATH + dir_ + \"\/\"):\n            sub = f.split(\"_\")[0]\n            data[dir_][sub].append(f)\n\n# data","d01e9870":"def preprocess_list(x):\n    return int((x.split(\"_\")[2]).split(\".\")[0])\n\ndef preprocess_dict(x):\n    res = list(np.argsort(list(map(preprocess_list, x))))\n    return [x[i] for i in res]\n\ndef img2array(x,path):\n    arr = np.empty(shape=(3,48,48))\n    for i,f in enumerate(x):\n        img = cv2.imread(path+f, 0)\n        arr[i] = img\n    return arr","7e9cab7c":"for emotion in data:\n    data[emotion] = dict((k, preprocess_dict(v)) for k, v in data[emotion].items())\n    data[emotion] = dict((k, img2array(v, path=INPUT_PATH + emotion + \"\/\")) for k, v in data[emotion].items())\n\n# data","cda804d6":"for k,v in data.items():\n    print(f\"{k} has {len(v)} samples\")","5774718a":"surprise = np.stack(data[\"surprise\"].values(), axis=0)\nsurprise = surprise.reshape(*surprise.shape,1)\n\nhappy = np.stack(data[\"happy\"].values(), axis=0)\nhappy = happy.reshape(*happy.shape,1)\n\nanger = np.stack(data[\"anger\"].values(), axis=0)\nanger = anger.reshape(*anger.shape,1)\n\nsadness = np.stack(data[\"sadness\"].values(), axis=0)\nsadness = sadness.reshape(*sadness.shape,1)\n\nfear = np.stack(data[\"fear\"].values(), axis=0)\nfear = fear.reshape(*fear.shape,1)\n\nX = np.concatenate((surprise, happy, anger, sadness, fear))\ny = np.concatenate((np.array([0]*83), np.array([1]*69), np.array([2]*45), np.array([3]*28), np.array([4]*25)))\n\n# X = np.concatenate((surprise, happy, anger, sadness, fear, surprise, happy, anger, sadness, fear))\n# y = np.concatenate((np.array([0]*83), np.array([1]*69), np.array([2]*45), np.array([3]*28), np.array([4]*25), np.array([0]*83), np.array([1]*69), np.array([2]*45), np.array([3]*28), np.array([4]*25)))\n\ny = np_utils.to_categorical(y)\n\nX.shape, y.shape","0bcba44a":"label_emotion_mapper = {0:\"surprise\", 1:\"happy\", 2:\"anger\", 3:\"sadness\", 4:\"fear\"}","804a5662":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, shuffle=True, random_state=42)\nX_train.shape, X_test.shape","c3ea9921":"np.random.seed(42)\nsurprise_idx = np.random.choice(np.where(y_train[:, 0]==1)[0], size=1)\nhappy_idx = np.random.choice(np.where(y_train[:, 1]==1)[0], size=1)\nanger_idx = np.random.choice(np.where(y_train[:, 2]==1)[0], size=1)\nsad_idx = np.random.choice(np.where(y_train[:, 3]==1)[0], size=1)\nfear_idx = np.random.choice(np.where(y_train[:, 4]==1)[0], size=1)\n\nfig = pyplot.figure(1, (6,13))\n\ni = 0\nfor name, idx in zip(label_emotion_mapper.values(), [surprise_idx, happy_idx, anger_idx, sad_idx, fear_idx]):\n    for j in range(3):\n        i += 1\n        ax = pyplot.subplot(5,3,i)\n        sample_img = X_train[idx][0,j,:,:,0]\n        ax.imshow(sample_img, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(name)","9c14d7d2":"# data normalization\nX_train = X_train \/ 255.\nX_test = X_test \/ 255.","cfc835ed":"def build_convlstm(input_shape, num_class, show_summary=True):\n    net = Sequential(name='ConvLSTM2D')\n\n    net.add(\n        ConvLSTM2D(\n            filters=64,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_1'))\n    net.add(\n        ConvLSTM2D(\n            filters=64,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_2'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_2'))\n\n    net.add(\n        MaxPooling3D(\n            pool_size=(1, 2, 2),\n            padding='same',\n            name='maxpool3d_1'\n        )\n    )\n    net.add(Dropout(0.3, name='dropout_1'))\n\n    net.add(\n        ConvLSTM2D(\n            filters=128,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_3'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_3'))\n    net.add(\n        ConvLSTM2D(\n            filters=128,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_4'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_4'))\n\n    net.add(\n        MaxPooling3D(\n            pool_size=(1, 2, 2),\n            padding='same',\n            name='maxpool3d_2'\n        )\n    )\n    net.add(Dropout(0.3, name='dropout_2'))\n\n    net.add(\n        ConvLSTM2D(\n            filters=256,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_5'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_5'))\n    net.add(\n        ConvLSTM2D(\n            filters=256,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_6'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_6'))\n\n    net.add(\n        MaxPooling3D(\n            pool_size=(1, 2, 2),\n            padding='same',\n            name='maxpool3d_3'\n        )\n    )\n    net.add(Dropout(0.3, name='dropout_3'))\n    \n    net.add(TimeDistributed(Flatten(name=\"flatten\")))\n    \n    net.add(\n        TimeDistributed(\n            Dense(\n                64,\n                activation='elu',\n                kernel_initializer='he_normal',\n                name='dense_1'\n            )\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_7'))\n    net.add(Dropout(.6, name=\"dropout_4\"))\n\n    net.add(\n        TimeDistributed(\n            Dense(\n                num_class,\n                activation='softmax',\n                name='out_layer'\n            )\n        )\n    )\n\n    if show_summary:\n        net.summary()\n\n    return net","d65d9659":"y_train_ = np.empty((y_train.shape[0], 3, 5))\nfor i in range(y_train.shape[0]):\n    y_train_[i] = np.tile(y_train[i], (3,1))\n    \ny_test_ = np.empty((y_test.shape[0], 3, 5))\nfor i in range(y_test.shape[0]):\n    y_test_[i] = np.tile(y_test[i], (3,1))","4316dac1":"y_train_.shape, y_test_.shape","723a4b77":"early_stopping = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.00005,\n    patience=12,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n#     early_stopping,\n    lr_scheduler,\n]\n\nbatch_size = 8\nepochs = 60","aaef75f4":"INPUT_SHAPE = (3, 48, 48, 1)\noptim = optimizers.Adam(0.001)\n\nmodel = build_convlstm(INPUT_SHAPE, num_class=5, show_summary=False)\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optim,\n        metrics=['accuracy']\n)","dd9f27ae":"history = model.fit(\n    x=X_train,\n    y=y_train_,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=callbacks,\n    use_multiprocessing=True\n)","db16e6fc":"sns.set()\nfig = pyplot.figure(0, (12, 4))\n\nax = pyplot.subplot(1, 2, 1)\nsns.lineplot(history.epoch, history.history['accuracy'], label='train')\nsns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\npyplot.title('Accuracy')\npyplot.tight_layout()\n\nax = pyplot.subplot(1, 2, 2)\nsns.lineplot(history.epoch, history.history['loss'], label='train')\nsns.lineplot(history.epoch, history.history['val_loss'], label='valid')\npyplot.title('Loss')\npyplot.tight_layout()\n\npyplot.savefig('epoch_history.png')\npyplot.show()","d8e02454":"`sadness` and `fear` has very low number of images as compared to other classes","3bc40d56":"### Data Preprocessing\n\nI first make the data compatible for the model."}}