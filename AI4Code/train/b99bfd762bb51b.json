{"cell_type":{"02d5eb73":"code","750dc41e":"code","baf47e11":"code","0729220f":"code","07671511":"code","e161a417":"code","0b71d863":"code","d20c69cb":"code","69b8dde8":"code","7ff8bec5":"code","29bb2ed8":"code","ee648a6e":"code","7bf751c7":"code","92b43cf0":"code","658743eb":"code","18f77c85":"code","8ec84dfc":"code","c203757e":"code","57c03d0b":"code","bb46592b":"code","c3d39598":"code","681bcbf4":"code","ef6cbe46":"code","ba0569ca":"code","ef05b900":"code","a397b7b6":"code","b9efed59":"code","f6d7ef88":"code","64a84e07":"markdown","b47e7c69":"markdown","0a7f5dcc":"markdown","c0495b14":"markdown","e26a2890":"markdown","1f1aea49":"markdown","e0e0f601":"markdown","a3cb97af":"markdown","41c098fa":"markdown","73120b4d":"markdown","647e73a5":"markdown","f8749b17":"markdown","a480e3ef":"markdown","90ff4d27":"markdown","c0c77964":"markdown","5d4f17b1":"markdown","ba87c988":"markdown","9aeb8c85":"markdown","d15cfc91":"markdown","e50ce7c1":"markdown","9f7c6912":"markdown","15e05797":"markdown","17d2f5c5":"markdown","c9a00f45":"markdown","c63cb712":"markdown","9a93242d":"markdown","d6474dbe":"markdown","5b10cc8c":"markdown","a1f06e70":"markdown","0b7e061d":"markdown","8ed08c66":"markdown","55256d72":"markdown","c26b00b2":"markdown","aad9c5e3":"markdown","01abeb70":"markdown","f6468186":"markdown","a2c2d12c":"markdown","91138367":"markdown","44eb445b":"markdown","8851e680":"markdown","adc266b2":"markdown","96cac46e":"markdown","8c6141fb":"markdown","73b9920d":"markdown","c17513de":"markdown","81912222":"markdown","1b5ce062":"markdown","9cf9c62f":"markdown","21240220":"markdown","c3092798":"markdown","be87a5aa":"markdown","f7a46e80":"markdown","f19327e4":"markdown","73642531":"markdown","e8d0382d":"markdown","7c532dd0":"markdown","3d01d1fa":"markdown","83d86298":"markdown","95a8e298":"markdown"},"source":{"02d5eb73":"# @title Tutorial slides\n\n# @markdown These are the slides for the videos in this tutorial\nfrom IPython.display import IFrame\nIFrame(src=f\"https:\/\/mfr.ca-1.osf.io\/render?url=https:\/\/osf.io\/3qevp\/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)","750dc41e":"# @title Install dependencies\n!pip install git+https:\/\/github.com\/NeuromatchAcademy\/evaltools --quiet\n\nfrom evaltools.airtable import AirtableForm\n# init airtable form\natform = AirtableForm('appn7VdPRseSoMXEG','W1D2_T1','https:\/\/portal.neuromatchacademy.org\/api\/redirect\/to\/9c55f6cb-cdf9-4429-ac1c-ec44fe64c303')","baf47e11":"# Imports\nimport torch\nimport numpy as np\nfrom torch import nn\nfrom math import pi\nimport matplotlib.pyplot as plt","0729220f":"# @title Figure settings\nimport ipywidgets as widgets       # interactive display\n%config InlineBackend.figure_format = 'retina'\nplt.style.use(\"https:\/\/raw.githubusercontent.com\/NeuromatchAcademy\/content-creation\/main\/nma.mplstyle\")","07671511":"# @title Plotting functions\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\ndef ex3_plot(model, x, y, ep, lss):\n  f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n  ax1.set_title(\"Regression\")\n  ax1.plot(x, model(x).detach().numpy(), color='r', label='prediction')\n  ax1.scatter(x, y, c='c', label='targets')\n  ax1.set_xlabel('x')\n  ax1.set_ylabel('y')\n  ax1.legend()\n\n  ax2.set_title(\"Training loss\")\n  ax2.plot(np.linspace(1, epochs, epochs), losses, color='y')\n  ax2.set_xlabel(\"Epoch\")\n  ax2.set_ylabel(\"MSE\")\n\n  plt.show()\n\n\ndef ex1_plot(fun_z, fun_dz):\n  \"\"\"Plots the function and gradient vectors\n\n  \"\"\"\n  x, y = np.arange(-3, 3.01, 0.02), np.arange(-3, 3.01, 0.02)\n  xx, yy = np.meshgrid(x, y, sparse=True)\n  zz = fun_z(xx, yy)\n  xg, yg = np.arange(-2.5, 2.6, 0.5), np.arange(-2.5, 2.6, 0.5)\n  xxg, yyg = np.meshgrid(xg, yg, sparse=True)\n  zxg, zyg = fun_dz(xxg, yyg)\n\n  plt.figure(figsize=(8, 7))\n  plt.title(\"Gradient vectors point towards steepest ascent\")\n  contplt = plt.contourf(x, y, zz, levels=20)\n  plt.quiver(xxg, yyg, zxg, zyg, scale=50, color='r', )\n  plt.xlabel('$x$')\n  plt.ylabel('$y$')\n  ax = plt.gca()\n  divider = make_axes_locatable(ax)\n  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n  cbar = plt.colorbar(contplt, cax=cax)\n  cbar.set_label('$z = h(x, y)$')\n  plt.show()","e161a417":"# @title Set random seed\n\n# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n\n# for DL its critical to set the random seed so that students can have a\n# baseline to compare their results to expected results.\n# Read more here: https:\/\/pytorch.org\/docs\/stable\/notes\/randomness.html\n\n# Call `set_seed` function in the exercises to ensure reproducibility.\nimport random\nimport torch\n\ndef set_seed(seed=None, seed_torch=True):\n  if seed is None:\n    seed = np.random.choice(2 ** 32)\n  random.seed(seed)\n  np.random.seed(seed)\n  if seed_torch:\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n  print(f'Random seed {seed} has been set.')\n\n\n# In case that `DataLoader` is used\ndef seed_worker(worker_id):\n  worker_seed = torch.initial_seed() % 2**32\n  np.random.seed(worker_seed)\n  random.seed(worker_seed)","0b71d863":"# @title Set device (GPU or CPU). Execute `set_device()`\n# especially if torch modules used.\n\n# inform the user if the notebook uses GPU or CPU.\n\ndef set_device():\n  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n  if device != \"cuda\":\n    print(\"GPU is not enabled in this notebook. \\n\"\n          \"If you want to enable it, in the menu under `Runtime` -> \\n\"\n          \"`Hardware accelerator.` and select `GPU` from the dropdown menu\")\n  else:\n    print(\"GPU is enabled in this notebook. \\n\"\n          \"If you want to disable it, in the menu under `Runtime` -> \\n\"\n          \"`Hardware accelerator.` and select `None` from the dropdown menu\")\n\n  return device","d20c69cb":"SEED = 2021\nset_seed(seed=SEED)\nDEVICE = set_device()","69b8dde8":"# @title Video 0: Introduction\nfrom ipywidgets import widgets\n\nout2 = widgets.Output()\nwith out2:\n  from IPython.display import IFrame\n  class BiliVideo(IFrame):\n    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n      self.id=id\n      src = \"https:\/\/player.bilibili.com\/player.html?bvid={0}&page={1}\".format(id, page)\n      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n\n  video = BiliVideo(id=f\"BV1Qf4y1578t\", width=730, height=410, fs=1)\n  print(\"Video available at https:\/\/www.bilibili.com\/video\/{0}\".format(video.id))\n  display(video)\n\nout1 = widgets.Output()\nwith out1:\n  from IPython.display import YouTubeVideo\n  video = YouTubeVideo(id=f\"i7djAv2jnzY\", width=730, height=410, fs=1, rel=0)\n  print(\"Video available at https:\/\/youtube.com\/watch?v=\" + video.id)\n  display(video)\n\nout = widgets.Tab([out1, out2])\nout.set_title(0, 'Youtube')\nout.set_title(1, 'Bilibili')\n\n#add event to airtable\natform.add_event('Video 0:Introduction')\n\ndisplay(out)","7ff8bec5":"# @title Video 1: Gradient Descent\nfrom ipywidgets import widgets\n\nout2 = widgets.Output()\nwith out2:\n  from IPython.display import IFrame\n  class BiliVideo(IFrame):\n    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n      self.id=id\n      src = \"https:\/\/player.bilibili.com\/player.html?bvid={0}&page={1}\".format(id, page)\n      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n\n  video = BiliVideo(id=f\"BV1Pq4y1p7em\", width=730, height=410, fs=1)\n  print(\"Video available at https:\/\/www.bilibili.com\/video\/{0}\".format(video.id))\n  display(video)\n\nout1 = widgets.Output()\nwith out1:\n  from IPython.display import YouTubeVideo\n  video = YouTubeVideo(id=f\"UwgA_SgG0TM\", width=730, height=410, fs=1, rel=0)\n  print(\"Video available at https:\/\/youtube.com\/watch?v=\" + video.id)\n  display(video)\n\nout = widgets.Tab([out1, out2])\nout.set_title(0, 'Youtube')\nout.set_title(1, 'Bilibili')\n\n#add event to airtable\natform.add_event('Video 1: Gradient Descent')\n\ndisplay(out)","29bb2ed8":"def fun_z(x, y):\n  \"\"\"Function sin(x^2 + y^2)\n\n  Args:\n    x (float, np.ndarray): variable x\n    y (float, np.ndarray): variable y\n\n  Return:\n    z (float, np.ndarray): sin(x^2 + y^2)\n  \"\"\"\n  z = np.sin(x**2 + y**2)\n  return z\n\n\ndef fun_dz(x, y):\n  \"\"\"Function sin(x^2 + y^2)\n\n  Args:\n    x (float, np.ndarray): variable x\n    y (float, np.ndarray): variable y\n\n  Return:\n    (tuple): gradient vector for sin(x^2 + y^2)\n  \"\"\"\n  #################################################\n  ## Implement the function which returns gradient vector\n  ## Complete the partial derivatives dz_dx and dz_dy\n  # Complete the function and remove or comment the line below\n  ## raise NotImplementedError(\"Gradient function `fun_dz`\")\n  #################################################\n  dz_dx = np.cos(x**2+y**2)*2*x\n  dz_dy = np.cos(x**2+y**2)*2*y\n  return (dz_dx, dz_dy)\n\n#add event to airtable\natform.add_event('Coding Exercise 1.1: Gradient Vector')\n\n## Uncomment to run\nex1_plot(fun_z, fun_dz)","ee648a6e":"# @title Video 2: Gradient Descent - Discussion\nfrom ipywidgets import widgets\n\nout2 = widgets.Output()\nwith out2:\n  from IPython.display import IFrame\n  class BiliVideo(IFrame):\n    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n      self.id=id\n      src = \"https:\/\/player.bilibili.com\/player.html?bvid={0}&page={1}\".format(id, page)\n      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n\n  video = BiliVideo(id=f\"BV1Rf4y157bw\", width=730, height=410, fs=1)\n  print(\"Video available at https:\/\/www.bilibili.com\/video\/{0}\".format(video.id))\n  display(video)\n\nout1 = widgets.Output()\nwith out1:\n  from IPython.display import YouTubeVideo\n  video = YouTubeVideo(id=f\"8s22ffAfGwI\", width=730, height=410, fs=1, rel=0)\n  print(\"Video available at https:\/\/youtube.com\/watch?v=\" + video.id)\n  display(video)\n\nout = widgets.Tab([out1, out2])\nout.set_title(0, 'Youtube')\nout.set_title(1, 'Bilibili')\n\n#add event to airtable\natform.add_event('Video 2: Gradient Descent ')\n\ndisplay(out)","7bf751c7":"# @title Video 3: Computational Graph\nfrom ipywidgets import widgets\n\nout2 = widgets.Output()\nwith out2:\n  from IPython.display import IFrame\n  class BiliVideo(IFrame):\n    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n      self.id=id\n      src = \"https:\/\/player.bilibili.com\/player.html?bvid={0}&page={1}\".format(id, page)\n      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n\n  video = BiliVideo(id=f\"BV1c64y1B7ZG\", width=730, height=410, fs=1)\n  print(\"Video available at https:\/\/www.bilibili.com\/video\/{0}\".format(video.id))\n  display(video)\n\nout1 = widgets.Output()\nwith out1:\n  from IPython.display import YouTubeVideo\n  video = YouTubeVideo(id=f\"2z1YX5PonV4\", width=730, height=410, fs=1, rel=0)\n  print(\"Video available at https:\/\/youtube.com\/watch?v=\" + video.id)\n  display(video)\n\nout = widgets.Tab([out1, out2])\nout.set_title(0, 'Youtube')\nout.set_title(1, 'Bilibili')\n\n#add event to airtable\natform.add_event('Video 3: Computational Graph ')\n\ndisplay(out)","92b43cf0":"# @title Video 4: Auto-Differentiation\nfrom ipywidgets import widgets\n\nout2 = widgets.Output()\nwith out2:\n  from IPython.display import IFrame\n  class BiliVideo(IFrame):\n    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n      self.id=id\n      src = \"https:\/\/player.bilibili.com\/player.html?bvid={0}&page={1}\".format(id, page)\n      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n\n  video = BiliVideo(id=f\"BV1UP4y1s7gv\", width=730, height=410, fs=1)\n  print(\"Video available at https:\/\/www.bilibili.com\/video\/{0}\".format(video.id))\n  display(video)\n\nout1 = widgets.Output()\nwith out1:\n  from IPython.display import YouTubeVideo\n  video = YouTubeVideo(id=f\"IBYFCNyBcF8\", width=730, height=410, fs=1, rel=0)\n  print(\"Video available at https:\/\/youtube.com\/watch?v=\" + video.id)\n  display(video)\n\nout = widgets.Tab([out1, out2])\nout.set_title(0, 'Youtube')\nout.set_title(1, 'Bilibili')\n\n#add event to airtable\natform.add_event('Video 4: Auto-Differentiation ')\n\ndisplay(out)","658743eb":"#add event to airtable\natform.add_event('Coding Exercise 2.1: Computational Graph ')\n\n\nclass SimpleGraph:\n  def __init__(self, w, b):\n    \"\"\"Initializing the SimpleGraph\n\n    Args:\n      w (float): initial value for weight\n      b (float): initial value for bias\n    \"\"\"\n    assert isinstance(w, float)\n    assert isinstance(b, float)\n    self.w = torch.tensor([w], requires_grad=True)\n    self.b = torch.tensor([b], requires_grad=True)\n\n  def forward(self, x):\n    \"\"\"Forward pass\n\n    Args:\n      x (torch.Tensor): 1D tensor of features\n\n    Returns:\n      torch.Tensor: model predictions\n    \"\"\"\n    assert isinstance(x, torch.Tensor)\n    #################################################\n    ## Implement the the forward pass to calculate prediction\n    ## Note that prediction is not the loss, but the value after `tanh`\n    # Complete the function and remove or comment the line below\n    ## raise NotImplementedError(\"Forward Pass `forward`\")\n    #################################################\n    prediction = torch.tanh(x*self.w + self.b)\n    return prediction\n\n\ndef sq_loss(y_true, y_prediction):\n  \"\"\"L2 loss function\n\n  Args:\n    y_true (torch.Tensor): 1D tensor of target labels\n    y_prediction (torch.Tensor): 1D tensor of predictions\n\n  Returns:\n    torch.Tensor: L2-loss (squared error)\n  \"\"\"\n  assert isinstance(y_true, torch.Tensor)\n  assert isinstance(y_prediction, torch.Tensor)\n  #################################################\n  ## Implement the L2-loss (squred error) given true label and prediction\n  # Complete the function and remove or comment the line below\n  ## raise NotImplementedError(\"Loss function `sq_loss`\")\n  #################################################\n  loss = (y_true - y_prediction)**2\n  return loss\n\n\nfeature = torch.tensor([1])  # input tensor\ntarget = torch.tensor([7])  # target tensor\n## Uncomment to run\nsimple_graph = SimpleGraph(-0.5, 0.5)\nprint(f\"initial weight = {simple_graph.w.item()}, \"\n      f\"\\ninitial bias = {simple_graph.b.item()}\")\nprediction = simple_graph.forward(feature)\nsquare_loss = sq_loss(target, prediction)\nprint(f\"for x={feature.item()} and y={target.item()}, \"\n      f\"prediction={prediction.item()}, and L2 Loss = {square_loss.item()}\")","18f77c85":"a = torch.tensor([1.0], requires_grad=True)\nb = torch.tensor([-1.0], requires_grad=True)\nc = a + b\nprint(f'Gradient function = {c.grad_fn}')","8ec84dfc":"print(f'Gradient function for prediction = {prediction.grad_fn}')\nprint(f'Gradient function for loss = {square_loss.grad_fn}')","c203757e":"# analytical gradients (remember detaching)\nana_dloss_dw = - 2 * feature * (target - prediction.detach())*(1 - prediction.detach()**2)\nana_dloss_db = - 2 * (target - prediction.detach())*(1 - prediction.detach()**2)\n\nsquare_loss.backward()  # first we should call the backward to build the graph\nautograd_dloss_dw = simple_graph.w.grad  # we calculate the derivative w.r.t weights\nautograd_dloss_db = simple_graph.b.grad  # we calculate the derivative w.r.t bias\n\nprint(ana_dloss_dw == autograd_dloss_dw)\nprint(ana_dloss_db == autograd_dloss_db)","57c03d0b":"# @title Video 5: PyTorch `nn` module\nfrom ipywidgets import widgets\n\nout2 = widgets.Output()\nwith out2:\n  from IPython.display import IFrame\n  class BiliVideo(IFrame):\n    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n      self.id=id\n      src = \"https:\/\/player.bilibili.com\/player.html?bvid={0}&page={1}\".format(id, page)\n      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n\n  video = BiliVideo(id=f\"BV1MU4y1H7WH\", width=730, height=410, fs=1)\n  print(\"Video available at https:\/\/www.bilibili.com\/video\/{0}\".format(video.id))\n  display(video)\n\nout1 = widgets.Output()\nwith out1:\n  from IPython.display import YouTubeVideo\n  video = YouTubeVideo(id=f\"jzTbQACq7KE\", width=730, height=410, fs=1, rel=0)\n  print(\"Video available at https:\/\/youtube.com\/watch?v=\" + video.id)\n  display(video)\n\nout = widgets.Tab([out1, out2])\nout.set_title(0, 'Youtube')\nout.set_title(1, 'Bilibili')\n\n#add event to airtable\natform.add_event('Video 5: PyTorch `nn` module')\n\ndisplay(out)","bb46592b":"# @markdown #### Generate the sample dataset\nset_seed(seed=SEED)\nn_samples = 32\ninputs = torch.linspace(-1.0, 1.0, n_samples).reshape(n_samples, 1)\nnoise = torch.randn(n_samples, 1) \/ 4\ntargets = torch.sin(pi * inputs) + noise\nplt.figure(figsize=(8, 5))\nplt.scatter(inputs, targets, c='c')\nplt.xlabel('x (inputs)')\nplt.ylabel('y (targets)')\nplt.show()","c3d39598":"inputs","681bcbf4":"## A Wide neural network with a single hidden layer\nclass WideNet(nn.Module):\n\n  def __init__(self):\n    \"\"\"Initializing the WideNet\n    \"\"\"\n    n_cells = 512\n    super().__init__()\n    self.layers = nn.Sequential(\n        nn.Linear(1, n_cells),\n        nn.Tanh(),\n        nn.Linear(n_cells, 1),\n    )\n\n  def forward(self, x):\n    \"\"\"Forward pass\n\n    Args:\n      x (torch.Tensor): 2D tensor of features\n\n    Returns:\n      torch.Tensor: model predictions\n    \"\"\"\n    return self.layers(x)","ef6cbe46":"# creating an instance\nset_seed(seed=SEED)\nwide_net = WideNet()\nprint(wide_net)","ba0569ca":"# Create a mse loss function\nloss_function = nn.MSELoss()\n\n# Stochstic Gradient Descent optimizer (you will learn about momentum soon)\nlr = 0.003  # learning rate\nsgd_optimizer = torch.optim.SGD(wide_net.parameters(), lr=lr, momentum=0.9)","ef05b900":"# Reset all gradients to zero\nsgd_optimizer.zero_grad()\n\n# Forward pass (Compute the output of the model on the features (inputs))\nprediction = wide_net(inputs) # like wide_net.forward(inputs)\n\n# Compute the loss\nloss = loss_function(prediction, targets)\nprint(f'Loss: {loss.item()}')\n\n# Perform backpropagation to build the graph and compute the gradients\nloss.backward()\n\n# Optimizer takes a tiny step in the steepest direction (negative of gradient)\n# and \"updates\" the weights and biases of the network\nsgd_optimizer.step()","a397b7b6":"def train(features, labels, model, loss_fun, optimizer, n_epochs):\n\n  \"\"\"Training function\n\n  Args:\n    features (torch.Tensor): features (input) with shape torch.Size([n_samples, 1])\n    labels (torch.Tensor): labels (targets) with shape torch.Size([n_samples, 1])\n    model (torch nn.Module): the neural network\n    loss_fun (function): loss function\n    optimizer(function): optimizer\n    n_epochs (int): number of training iterations\n\n  Returns:\n    list: record (evolution) of training losses\n  \"\"\"\n  loss_record = []  # keeping recods of loss\n\n  for i in range(n_epochs):\n    #################################################\n    ## Implement the missing parts of the training loop\n    # Complete the function and remove or comment the line below\n    ## raise NotImplementedError(\"Training loop `train`\")\n    #################################################\n    optimizer.zero_grad()  # set gradients to 0\n    predictions = model(features)  # Compute model prediction (output)\n    loss = loss_fun( predictions,labels )  # Compute the loss\n    loss.backward()  # Compute gradients (backward pass)\n    optimizer.step()  # update parameters (optimizer takes a step)\n\n    loss_record.append(loss.item())\n  return loss_record\n\n#add event to airtable\natform.add_event('Coding Exercise 3.1: Training Loop')\n\n\nset_seed(seed=2021)\nepochs = 1847 # Cauchy, Exercices d'analyse et de physique mathematique (1847)\n## Uncomment to run\nlosses = train(inputs, targets, wide_net, loss_function, sgd_optimizer, epochs)\nex3_plot(wide_net, inputs, targets, epochs, losses)","b9efed59":"# @title Video 6: Tutorial 1 Wrap-up\nfrom ipywidgets import widgets\n\nout2 = widgets.Output()\nwith out2:\n  from IPython.display import IFrame\n  class BiliVideo(IFrame):\n    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n      self.id=id\n      src = \"https:\/\/player.bilibili.com\/player.html?bvid={0}&page={1}\".format(id, page)\n      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n\n  video = BiliVideo(id=f\"BV1Pg41177VU\", width=730, height=410, fs=1)\n  print(\"Video available at https:\/\/www.bilibili.com\/video\/{0}\".format(video.id))\n  display(video)\n\nout1 = widgets.Output()\nwith out1:\n  from IPython.display import YouTubeVideo\n  video = YouTubeVideo(id=f\"TvZURbcnXc4\", width=730, height=410, fs=1, rel=0)\n  print(\"Video available at https:\/\/youtube.com\/watch?v=\" + video.id)\n  display(video)\n\nout = widgets.Tab([out1, out2])\nout.set_title(0, 'Youtube')\nout.set_title(1, 'Bilibili')\n\n#add event to airtable\natform.add_event('Video 6: Tutorial 1 Wrap-up')\n\ndisplay(out)","f6d7ef88":"# @title Airtable Submission Link\nfrom IPython import display as IPyDisplay\nIPyDisplay.HTML(\n    f\"\"\"\n  <div>\n    <a href= \"{atform.url()}\" target=\"_blank\">\n    <img src=\"https:\/\/github.com\/NeuromatchAcademy\/course-content-dl\/blob\/main\/tutorials\/static\/AirtableSubmissionButton.png?raw=1\"\n  alt=\"button link to Airtable\" style=\"width:410px\"><\/a>\n    <\/div>\"\"\" )","64a84e07":"Before introducing the gradient descent algorithm, let's review a very important property of gradients. The gradient of a function always points in the direction of the steepest ascent. The following exercise will help clarify this.","b47e7c69":"### Coding Exercise 1.1: Gradient Vector\n\nImplement (complete) the function which returns the gradient vector for $z=\\sin(x^2 + y^2)$.","0a7f5dcc":"## Section 1.3: Computational Graphs and Backprop\n","c0495b14":"##  Plotting functions\n","e26a2890":"##  Install dependencies\n","1f1aea49":"Deep learning frameworks such as PyTorch, JAX, and TensorFlow come with a very efficient and sophisticated set of algorithms, commonly known as Automatic Differentiation. AutoGrad is PyTorch's automatic differentiation engine. Here we start by covering the essentials of AutoGrad, and you will learn more in the coming days.\n\n","e0e0f601":"## Section 1.2: Gradient Descent Algorithm","a3cb97af":" Executing `set_seed(seed=seed)` you are setting the seed\n","41c098fa":"### Coding Exercise 2.1: Buiding a Computational Graph\n\nIn PyTorch, to indicate that a certain tensor contains learnable parameters, we can set the optional argument `requires_grad` to `True`. PyTorch will then track every operation using this tensor while configuring the computational graph. For this exercise, use the provided tensors to build the following graph, which implements a single neuron with scalar input and output.\n\n<br\/>\n\n<center><img src=\"https:\/\/raw.githubusercontent.com\/NeuromatchAcademy\/course-content-dl\/main\/tutorials\/W1D2_LinearDeepLearning\/static\/simple_graph.png\" alt=\"Simple nn graph\" width=\"600\"\/><\/center>","73120b4d":"##  Video 4: Auto-Differentiation\n","647e73a5":"References and more:\n* [A GENTLE INTRODUCTION TO TORCH.AUTOGRAD](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/autograd_tutorial.html)\n\n* [AUTOMATIC DIFFERENTIATION PACKAGE - TORCH.AUTOGRAD](https:\/\/pytorch.org\/docs\/stable\/autograd.html)\n\n* [AUTOGRAD MECHANICS](https:\/\/pytorch.org\/docs\/stable\/notes\/autograd.html)\n\n* [AUTOMATIC DIFFERENTIATION WITH TORCH.AUTOGRAD](https:\/\/pytorch.org\/tutorials\/beginner\/basics\/autogradqs_tutorial.html)","f8749b17":"We can now create an instance of our neural net and print its parameters.","a480e3ef":"For more complex functions, printing the `grad_fn` would only show the last operation, even though the object tracks all the operations up to that point:","90ff4d27":"##  Tutorial slides\n","c0c77964":"### Analytical Exercise 1.3: Chain Rule (Optional)\nFor the function above, calculate the $\\dfrac{\\partial f}{\\partial y}$ using the computational graph and chain rule.\n\n---\n#### Solution:\n\\begin{equation}\n\\dfrac{\\partial f}{\\partial y} = \\dfrac{\\partial f}{\\partial e}~\\dfrac{\\partial e}{\\partial d}~\\dfrac{\\partial d}{\\partial c}~\\dfrac{\\partial c}{\\partial b}~\\dfrac{\\partial b}{\\partial y} = \\left( 1-\\tanh^2(e) \\right) \\cdot \\frac{1}{d+1}\\cdot z \\cdot \\frac{-a}{b^2} \\cdot \\cos(y)\n\\end{equation}","5d4f17b1":"---\n# Section 2: PyTorch AutoGrad\n\n*Time estimate: ~30-45 mins*","ba87c988":"---\n# Section 0: Introduction","9aeb8c85":"---\n# Setup\n\nThis a GPU-Free tutorial!\n","d15cfc91":"## Section 3.1: Training loop in PyTorch\n\nWe use a regression problem to study the training loop in PyTorch.\n\nThe task is to train a wide nonlinear (using $\\tanh$ activation function) neural net for a simple $\\sin$ regression task. Wide neural networks are thought to be really good at generalization.","e50ce7c1":"## Section 2.1: Forward Propagation\n\nEverything starts with the forward propagation (pass). PyTorch tracks all the instructions, as we declare the variables and operations, and it builds the graph when we call the `.backward()` pass. PyTorch rebuilds the graph every time we iterate or change it (or simply put, PyTorch uses a dynamic graph).\n\nFor gradient descent, it is only required to have the gradients of cost function with respect to the variables we wish to learn. These variables are often called \"learnable \/ trainable parameters\" or simply \"parameters\" in PyTorch. In neural nets, weights and biases are often the learnable parameters. ","9f7c6912":"[*Click for solution*](https:\/\/github.com\/NeuromatchAcademy\/course-content-dl\/tree\/main\/\/tutorials\/W1D2_LinearDeepLearning\/solutions\/W1D2_Tutorial1_Solution_6668feea.py)\n\n","15e05797":"##  Video 0: Introduction\n","17d2f5c5":"---\n#Tutorial Objectives\n\nDay 2 Tutorial 1 will continue on buiding PyTorch skillset and motivate its core functionality, Autograd. In this notebook, we will cover the key concepts and ideas of:\n\n* Gradient descent\n* PyTorch Autograd\n* PyTorch nn module\n\n\n","c9a00f45":"##  Video 6: Tutorial 1 Wrap-up\n","c63cb712":" *Exercise 1.2* is an example of how overwhelming the derivation of gradients can get, as the number of variables and nested functions increases. This function is still extraordinarily simple compared to the loss functions of modern neural networks. So how can we (as well as PyTorch and similar frameworks) approach such beasts?\n\nLet\u2019s look at the function again:\n\n\\begin{equation}\nf(x, y, z) = \\tanh \\left(\\ln \\left[1 + z \\frac{2x}{sin(y)} \\right] \\right)\n\\end{equation}\n\nWe can build a so-called computational graph (shown below) to break the original function into smaller and more approachable expressions.\n\n<center><img src=\"https:\/\/raw.githubusercontent.com\/NeuromatchAcademy\/course-content-dl\/main\/tutorials\/W1D2_LinearDeepLearning\/static\/comput_graph.png\" alt=\"Computation Graph\" width=\"700\"\/><\/center>\n\nStarting from $x$, $y$, and $z$ and following the arrows and expressions, you would see that our graph returns the same function as $f$. It does so by calculating intermediate variables $a,b,c,d,$ and $e$. This is called the **forward pass**.\n\nNow, let\u2019s start from $f$, and work our way against the arrows while calculating the gradient of each expression as we go. This is called the **backward pass**, from which the **backpropagation of errors** algorithm gets its name.\n\n<center><img src=\"https:\/\/raw.githubusercontent.com\/NeuromatchAcademy\/course-content-dl\/main\/tutorials\/W1D2_LinearDeepLearning\/static\/comput_graph_full.png\" alt=\"Computation Graph full\" width=\"1200\"\/><\/center>\n\nBy breaking the computation into simple operations on intermediate variables, we can use the chain rule to calculate any gradient:\n\n\\begin{equation}\n\\dfrac{\\partial f}{\\partial x} = \\dfrac{\\partial f}{\\partial e}~\\dfrac{\\partial e}{\\partial d}~\\dfrac{\\partial d}{\\partial c}~\\dfrac{\\partial c}{\\partial a}~\\dfrac{\\partial a}{\\partial x} = \\left( 1-\\tanh^2(e) \\right) \\cdot \\frac{1}{d+1}\\cdot z \\cdot \\frac{1}{b} \\cdot 2\n\\end{equation}\n\nConveniently, the values for $e$, $b$, and $d$ are available to us from when we did the forward pass through the graph. That is, the partial derivatives have simple expressions in terms of the intermediate variables $a,b,c,d,e$ that we calculated and stored during the forward pass.\n","9a93242d":"Since the goal of most learning algorithms is **minimizing the risk (also known as the cost or loss) function**, optimization is often the core of most machine learning techniques! The gradient descent algorithm, along with its variations such as stochastic gradient descent, is one of the most powerful and popular optimization methods used for deep learning. Today we will introduce the basics, but you will learn much more about Optimization in the coming days (Week 1 Day 4).\n\n\n\n","d6474dbe":"##  Set random seed\n","5b10cc8c":"For more: [Calculus on Computational Graphs: Backpropagation](https:\/\/colah.github.io\/posts\/2015-08-Backprop\/)","a1f06e70":"##  Set device (GPU or CPU). Execute `set_device()`\n","0b7e061d":"Let's define a very wide (512 neurons) neural net with one hidden layer and `Tanh` activation function.","8ed08c66":"PyTorch provides us with ready-to-use neural network building blocks, such as layers (e.g. linear, recurrent, ...), different activation and loss functions, and much more, packed in the [`torch.nn`](https:\/\/pytorch.org\/docs\/stable\/nn.html) module. If we build a neural network using `torch.nn` layers, the weights and biases are already in `requires_grad` mode and will be registered as model parameters. \n\nFor training, we need three things:\n\n*   **Model parameters** - Model parameters refer to all the learnable parameters of the model, which are accessible by calling `.parameters()` on the model. Please note that NOT all the `requires_grad` tensors are seen as model parameters. To create a custom model parameter, we can use [`nn.Parameter`](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.parameter.Parameter.html) (*A kind of Tensor that is to be considered a module parameter*).\n\n*   **Loss function** - The loss that we are going to be optimizing, which is often combined with regularization terms (conming up in few days).\n\n*   **Optimizer** - PyTorch provides us with many optimization methods (different versions of gradient descent). Optimizer holds the current state of the model and by calling the `step()` method, will update the parameters based on the computed gradients.\n\nYou will learn more details about choosing the right model architecture, loss function, and optimizer later in the course.","55256d72":"## Section 2.2: Backward Propagation\n\nHere is where all the magic lies. In PyTorch, `Tensor` and `Function` are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each variable has a `grad_fn` attribute that references a function that has created the Tensor (except for Tensors created by the user - these have `None` as `grad_fn`).  The example below shows that the tensor `c = a + b` is created by the `Add` operation and the gradient function is the object `<AddBackward...>`. Replace `+` with other single operations (e.g., `c = a * b` or `c = torch.sin(a)`) and examine the results.","c26b00b2":"**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n\n<p align='center'><img src='https:\/\/github.com\/NeuromatchAcademy\/widgets\/blob\/master\/sponsors.png?raw=True'\/><\/p>","aad9c5e3":"In this tutorial we covered one of the most basic concepts of deep learning; the computational graph and how a network learns via gradient descent and the backpropagation algorithm. We have seen all of these using PyTorch modules and we compared the analytical solutions with the ones provided directly by the PyTorch module.","01abeb70":"Today, we will go through 3 tutorials. Starting with Gradient Descent, the workhorse of deep learning algorithms, in this tutorial. The second tutorial will help us build a better intuition about neural networks and basic hyper-parameters. Finally, in tutorial 3, we learn about the learning dynamics, what the (a good) deep network is learning, and why sometimes they may perform poorly.","f6468186":"It is important to appreciate the fact that PyTorch can follow our operations as we arbitrarily go through classes and functions.","a2c2d12c":"##  Video 5: PyTorch `nn` module\n","91138367":"## Section 1.1: Gradients & Steepest Ascent","44eb445b":"##  Figure settings\n","8851e680":"---\n# Section 3: PyTorch's Neural Net module (`nn.Module`)\n\n*Time estimate: ~30 mins*","adc266b2":"####  Video 2: Gradient Descent - Discussion\n","96cac46e":"###  Video 1: Gradient Descent\n","8c6141fb":"The training process in PyTorch is interactive - you can perform training iterations as you wish and inspect the results after each iteration. \n\nLet's perform one training iteration. You can run the cell multiple times and see how the parameters are being updated and the loss is reducing. This code block is the core of everything to come: please make sure you go line-by-line through all the commands and discuss their purpose with the pod.","73b9920d":"---\n# Summary","c17513de":"We can see from the plot that for any given $x_0$ and $y_0$, the gradient vector $\\left[ \\dfrac{\\partial z}{\\partial x}, \\dfrac{\\partial z}{\\partial y}\\right]^{\\top}_{(x_0, y_0)}$ points in the direction of $x$ and $y$ for which $z$ increases the most. It is important to note that gradient vectors only see their local values, not the whole landscape! Also, length (size) of each vector, which indicates the steepness of the function, can be very small near local plateaus (i.e. minima or maxima).\n\nThus, we can simply use the aforementioned formula to find the local minima. \n\nIn 1847, Augustin-Louis Cauchy used **negative of gradients**  to develop the Gradient Descent algorithm as an **iterative** method to **minimize** a **continuous** and (ideally) **differentiable function** of **many variables**.","81912222":"### Analytical Exercise 1.1: Gradient vector (Optional)\n\nGiven the following function:\n\n\\begin{equation}\nz = h(x, y) = \\sin(x^2 + y^2)\n\\end{equation}\n\nfind the gradient vector:\n\n\\begin{equation}\n  \\begin{bmatrix}\n  \\dfrac{\\partial z}{\\partial x} \\\\ \\\\ \\dfrac{\\partial z}{\\partial y}\n  \\end{bmatrix}\n\\end{equation}\n\n\n*hint: use the chain rule!*\n\n**Chain rule**: For a composite function $F(x) = g(h(x)) \\equiv (g \\circ h)(x)$:\n\n\\begin{equation}\nF'(x) = g'(h(x)) \\cdot h'(x)\n\\end{equation}\n\nor differently denoted:\n\n\\begin{equation}\n\\frac{dF}{dx} = \\frac{dg}{dh} ~ \\frac{dh}{dx}\n\\end{equation}\n\n---\n#### Solution:\nWe can rewrite the function as a composite function:\n\n\\begin{equation}\nz = f\\left( g(x,y) \\right), ~~ f(u) = \\sin(u), ~~ g(x, y) = x^2 + y^2\n\\end{equation}\n\nUsing chain rule:\n\n\\begin{align}\n\\dfrac{\\partial z}{\\partial x} &= \\dfrac{\\partial f}{\\partial g} \\dfrac{\\partial g}{\\partial x} = \\cos(g(x,y)) ~ (2x) = \\cos(x^2 + y^2) \\cdot 2x \\\\ \\\\\n\\dfrac{\\partial z}{\\partial y} &= \\dfrac{\\partial f}{\\partial g} \\dfrac{\\partial g}{\\partial y} = \\cos(g(x,y)) ~ (2y) = \\cos(x^2 + y^2) \\cdot 2y\n\\end{align}\n","1b5ce062":"### Analytical Exercise 1.2: Gradients\n\nGiven $f(x, y, z) = \\tanh \\left( \\ln \\left[1 + z \\frac{2x}{sin(y)} \\right] \\right)$, how easy is it to derive $\\dfrac{\\partial f}{\\partial x}$, $\\dfrac{\\partial f}{\\partial y}$ and $\\dfrac{\\partial f}{\\partial z}$? (*hint: you don't have to actually calculate them!*)","9cf9c62f":"Let $f(\\mathbf{w}): \\mathbb{R}^d \\rightarrow \\mathbb{R}$ be a differentiable function. Gradient Descent is an iterative algorithm for minimizing the function $f$, starting with an initial value for variables $\\mathbf{w}$, taking steps of size $\\eta$ (learning rate) in the direction of the negative gradient at the current point to update the variables $\\mathbf{w}$.\n\n\\begin{equation}\n\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} - \\eta \\nabla f (\\mathbf{w}^{(t)})\n\\end{equation}\n\nwhere $\\eta > 0$ and $\\nabla f (\\mathbf{w})= \\left( \\frac{\\partial f(\\mathbf{w})}{\\partial w_1}, ..., \\frac{\\partial f(\\mathbf{w})}{\\partial w_d} \\right)$. Since negative gradients always point locally in the direction of steepest descent, the algorithm makes small steps at each point **towards** the minimum.\n  \n<br\/>\n\n**Vanilla Algorithm**\n\n---\n> **inputs**: initial guess $\\mathbf{w}^{(0)}$, step size $\\eta > 0$, number of steps $T$\n\n> *For* $t = 0, 2, \\dots , T-1$ *do* \\\n$\\qquad$ $\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} - \\eta \\nabla f (\\mathbf{w}^{(t)})$\\\n*end*\n\n> *return*: $\\mathbf{w}^{(t+1)}$\n\n---\n\n<br\/>\n\nHence, all we need is to calculate the gradient of the loss function with respect to the learnable parameters (i.e. weights):\n\n\\begin{equation}\n\\dfrac{\\partial Loss}{\\partial \\mathbf{w}} = \\left[ \\dfrac{\\partial Loss}{\\partial w_1}, \\dfrac{\\partial Loss}{\\partial w_2} , ..., \\dfrac{\\partial Loss}{\\partial w_d} \\right]^{\\top}\n\\end{equation}\n\n","21240220":" #### Generate the sample dataset\n","c3092798":"### Coding Exercise 3.1: Training Loop\nUsing everything we've learned so far, we ask you to complete the `train` function below.","be87a5aa":"[*Click for solution*](https:\/\/github.com\/NeuromatchAcademy\/course-content-dl\/tree\/main\/\/tutorials\/W1D2_LinearDeepLearning\/solutions\/W1D2_Tutorial1_Solution_0c8e3872.py)\n\n*Example output:*\n\n<img alt='Solution hint' align='left' width=1120.0 height=976.0 src=https:\/\/raw.githubusercontent.com\/NeuromatchAcademy\/course-content-dl\/main\/tutorials\/W1D2_LinearDeepLearning\/static\/W1D2_Tutorial1_Solution_0c8e3872_0.png>\n\n","f7a46e80":"<a href=\"https:\/\/colab.research.google.com\/github\/NeuromatchAcademy\/course-content-dl\/blob\/main\/tutorials\/W1D2_LinearDeepLearning\/student\/W1D2_Tutorial1.ipynb\" target=\"_blank\"><img alt=\"Open In Colab\" src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\"\/><\/a>","f19327e4":"Now let's kick off the backward pass to calculate the gradients by calling `.backward()` on the tensor we wish to initiate the backpropagation from. Often, `.backward()` is called on the loss, which is the last node on the graph. Before doing that, let's calculate the loss gradients by hand:\n\n$$\\frac{\\partial{loss}}{\\partial{w}} = - 2 x (y_t - y_p)(1 - y_p^2)$$\n\n$$\\frac{\\partial{loss}}{\\partial{b}} = - 2 (y_t - y_p)(1 - y_p^2)$$\n\nWhere $y_t$ is the target (true label), and $y_p$ is the prediction (model output). We can then compare it to PyTorch gradients, which can be obtained by calling `.grad` on the relevant tensors.\n\n**Important Notes**\n* Learnable parameters (i.e. `reguires_grad` tensors) are \"contagious\". Let's look at a simple example: `Y = W @ X`, where `X` is the feature tensors and `W` is the weight tensor (learnable parameters, `reguires_grad`), the newly generated output tensor `Y` will be also `reguires_grad`. So any operation that is applied to `Y` will be part of the computational graph. Therefore, if we need to plot or store a tensor that is `reguires_grad`, we must first `.detach()` it from the graph by calling the `.detach()` method on that tensor.\n\n\n* `.backward()` accumulates gradients in the leaf nodes (i.e., the input nodes to the node of interest). We can call `.zero_grad()` on the loss or optimizer to zero out all `.grad` attributes (see [autograd.backward](https:\/\/pytorch.org\/docs\/stable\/autograd.html#torch.autograd.backward) for more).\n\n* Recall that in python we can access variables and associated methods with `.method_name`. You can use the command `dir(my_object)` to observe all variables and associated methods to your object, e.g., `dir(simple_graph.w)`.","73642531":"##  Airtable Submission Link\n","e8d0382d":"# Tutorial 1: Gradient Descent and AutoGrad\n**Week 1, Day 2: Linear Deep Learning**\n\n**By Neuromatch Academy**\n\n__Content creators:__ Saeed Salehi, Vladimir Haltakov, Andrew Saxe\n\n__Content reviewers:__ Polina Turishcheva, Antoine De Comite, Kelson Shilling-Scrivo\n\n__Content editors:__ Anoop Kulkarni, Spiros Chavlis\n\n__Production editors:__ Khalid Almubarak, Spiros Chavlis\n","7c532dd0":" These are the slides for the videos in this tutorial\n","3d01d1fa":"---\n# Section 1: Gradient Descent Algorithm\n\n*Time estimate: ~30-45 mins*","83d86298":"###  Video 3: Computational Graph\n","95a8e298":"[*Click for solution*](https:\/\/github.com\/NeuromatchAcademy\/course-content-dl\/tree\/main\/\/tutorials\/W1D2_LinearDeepLearning\/solutions\/W1D2_Tutorial1_Solution_5204c053.py)\n\n*Example output:*\n\n<img alt='Solution hint' align='left' width=1696.0 height=544.0 src=https:\/\/raw.githubusercontent.com\/NeuromatchAcademy\/course-content-dl\/main\/tutorials\/W1D2_LinearDeepLearning\/static\/W1D2_Tutorial1_Solution_5204c053_1.png>\n\n"}}