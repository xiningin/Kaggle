{"cell_type":{"93893a40":"code","921c0a21":"code","39b9643d":"code","d8003cd2":"code","9f19051f":"code","4f544038":"code","049d9201":"code","0393c8a9":"code","58d202ac":"code","1fc8d96c":"code","b8f32505":"code","49edddbc":"code","572bc54e":"code","3dbce38a":"code","7e539a6a":"code","e120d70f":"code","55a7a9bc":"code","4407b044":"code","f079498e":"code","56ab57f7":"code","0d46b0ba":"code","3ea23817":"code","afdac1cf":"code","ada74b47":"code","ba6358ce":"code","68bebaee":"code","ad4b1abc":"code","ab1f06a7":"code","d829cfa1":"code","7d6c80f2":"code","8bf09626":"code","c309fd9b":"code","c6074424":"code","19632e45":"code","dd723058":"code","3253504e":"code","e21d5c70":"code","870a9af0":"code","96a0d2d5":"code","e46db366":"code","cbcaf923":"code","6f8d80a4":"code","9205fa4a":"code","7c5282ee":"code","0599114f":"code","d1184c15":"code","aba7ac68":"markdown","0597a9ad":"markdown","2f878404":"markdown","66d92c27":"markdown","ef31a262":"markdown"},"source":{"93893a40":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","921c0a21":"df=pd.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndf.head()","39b9643d":"df.corr()","d8003cd2":"df.isnull().sum()","9f19051f":"df['Pregnancies'].value_counts()","4f544038":"df['Outcome'].value_counts()","049d9201":"plt.figure(figsize=(10,6))\nsns.countplot(df[\"Age\"],palette=\"muted\")","0393c8a9":"df.nunique()","58d202ac":"X=df.iloc[:,:-1].values\nX","1fc8d96c":"Y=df.iloc[:,-1].values","b8f32505":"from sklearn.preprocessing import StandardScaler\none=StandardScaler()\nX=one.fit_transform(X)","49edddbc":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=42)","572bc54e":"from sklearn.svm import SVC\nsvc = SVC(kernel='rbf')\nsvc.fit(x_train,y_train)\npred_svc =svc.predict(x_test)","3dbce38a":"from sklearn import metrics\n\n# Model Accuracy: how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, pred_svc))","7e539a6a":"from sklearn.metrics import classification_report,accuracy_score\nprint(classification_report(y_test,pred_svc))","e120d70f":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=21)\nknn.fit(x_train,y_train)\npred_knn=knn.predict(x_test)","55a7a9bc":"from sklearn import metrics\n\n# Model Accuracy: how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, pred_knn))","4407b044":"from sklearn.metrics import classification_report,accuracy_score\nprint(classification_report(y_test,pred_knn))","f079498e":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, pred_knn)","56ab57f7":"print(\"Precision:\",metrics.precision_score(y_test, pred_knn))\n# Model Recall: what percentage of positive tuples are labelled as such?\nprint(\"Recall:\",metrics.recall_score(y_test, pred_knn))","0d46b0ba":"from sklearn import naive_bayes\nNB = naive_bayes.GaussianNB()\nNB.fit(x_train,y_train)\npred_nb=NB.predict(x_test)","3ea23817":"from sklearn import metrics\n\n# Model Accuracy: how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, pred_nb))","afdac1cf":"from sklearn.metrics import classification_report,accuracy_score\nprint(classification_report(y_test,pred_nb))","ada74b47":"print(\"Precision:\",metrics.precision_score(y_test, pred_nb))\n# Model Recall: what percentage of positive tuples are labelled as such?\nprint(\"Recall:\",metrics.recall_score(y_test, pred_nb))","ba6358ce":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)\npred_dt=dt.predict(x_test)","68bebaee":"from sklearn import metrics\n\n# Model Accuracy: how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, pred_dt))","ad4b1abc":"from sklearn.metrics import classification_report,accuracy_score\nprint(classification_report(y_test,pred_dt))","ab1f06a7":"print(\"Precision:\",metrics.precision_score(y_test, pred_dt))\n# Model Recall: what percentage of positive tuples are labelled as such?\nprint(\"Recall:\",metrics.recall_score(y_test, pred_dt))","d829cfa1":"clf_entropy = DecisionTreeClassifier(criterion=\"entropy\", random_state = 42)\nclf_gini = DecisionTreeClassifier(criterion=\"gini\", random_state = 42)","7d6c80f2":"clf_entropy.fit(x_train,y_train)\npred_clf_entropy=clf_entropy.predict(x_test)","8bf09626":"from sklearn import metrics\n\n# Model Accuracy: how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, pred_clf_entropy))","c309fd9b":"clf_gini.fit(x_train,y_train)\npred_clf_gini=clf_gini.predict(x_test)","c6074424":"from sklearn import metrics\n\n# Model Accuracy: how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, pred_clf_gini))","19632e45":"X1=df.iloc[:,:-1].values","dd723058":"Y1=df.iloc[:,-1].values","3253504e":"from sklearn.preprocessing import StandardScaler\nsk=StandardScaler()\nX1=sk.fit_transform(X1)","e21d5c70":"Y1=Y1.reshape(-1,1)","870a9af0":"Y1","96a0d2d5":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X1, Y1, test_size = 0.1,random_state=42)","e46db366":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size = 0.1,random_state=42)","cbcaf923":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.activations import relu,softmax\nfrom keras.regularizers import l2","6f8d80a4":"model = Sequential()\nmodel.add(Dense(16, input_dim=8,kernel_regularizer=l2(0.01), activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(48, kernel_regularizer=l2(0.01),activation='relu'))\nmodel.add(Dense(64, kernel_regularizer=l2(0.01),activation='relu',))\nmodel.add(Dense(1, activation='sigmoid'))","9205fa4a":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","7c5282ee":"from keras.callbacks import ModelCheckpoint\ncheckpointer=ModelCheckpoint(filepath='Convolutional.hdf5',verbose=1,save_best_only=True)\nhistory = model.fit(x_train, y_train, epochs=100, batch_size=16,validation_data=(x_val,y_val))","0599114f":"score=model.evaluate(x_test,y_test,verbose=1)               #evaluates the model\naccuracy=100*score[1]                                       \nprint('Test accuracy is %.4f%%' % accuracy)","d1184c15":"score=model.evaluate(x_train,y_train,verbose=1)               #evaluates the model\naccuracy=100*score[1]                                       \nprint('Test accuracy is %.4f%%' % accuracy)","aba7ac68":"# K NEAREST NEIGHBOURS","0597a9ad":"# NEURAL NETWORKS ","2f878404":"# NAIVE BAYES","66d92c27":"# SUPPORT VECTOR MACHINES","ef31a262":"# DECISION TREE CLASSIFIER "}}