{"cell_type":{"f6803e89":"code","0e1050f1":"code","08c23348":"code","f7d93c80":"code","e2b2d745":"code","6c1f534e":"code","6f688f0e":"code","1c729468":"code","bd2b54f2":"code","dd2e31ce":"code","1ec4cfe3":"code","aa8b712d":"code","ec49bcd0":"code","1893ccbd":"code","5d6ee3d4":"code","cd37c56d":"code","66dfc22a":"code","d6755fc1":"code","b3af3446":"code","847f2f14":"code","8745a393":"markdown","98a5237e":"markdown","92988548":"markdown"},"source":{"f6803e89":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e1050f1":"from sklearn.metrics import confusion_matrix\n\nimport keras\nfrom keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport seaborn as sns\nfrom PIL import Image\n\nnp.random.seed(42)","08c23348":"data= pd.read_csv('..\/input\/skin-cancer-mnist-ham10000\/hmnist_28_28_RGB.csv')","f7d93c80":"data.head(5)","e2b2d745":"data.columns","6c1f534e":"Label = data[\"label\"]\ndata.drop('label', axis=1 , inplace= True)","6f688f0e":"data","1c729468":"Label.unique()","bd2b54f2":"Label.value_counts()","dd2e31ce":"# check the class balance\nplt.figure(figsize = (8,10))\nplt.bar(Label.unique(), Label.value_counts())","1ec4cfe3":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data, Label, test_size=0.2, random_state=42)","aa8b712d":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=42)\nX_smote, y_smote = sm.fit_resample(X_train, y_train)","ec49bcd0":"y_smote.value_counts()","1893ccbd":"# pick a random sample \n\nplt.figure(figsize=(22, 32))\nfor i in range(15):\n    plt.subplot(7, 5, i + 1)\n    k= np.random.randint(0,len(data)-1, 15)\n    plt.imshow(np.array(data.iloc[k[i]]).reshape(28, 28, 3))\n    img_label = Label.iloc[k[i]]\n    plt.title(img_label)\n    plt.axis(\"off\")\nplt.show()","5d6ee3d4":"%%html \n<h3> Modeling<\/h3> ","cd37c56d":"X_tr= np.array(X_smote).reshape(len(X_smote),28, 28, 3)","66dfc22a":"model= Sequential()\nmodel.add(Conv2D(256, 3, input_shape = (28, 28, 3), activation = 'relu'))\n# model.add(Conv2D(256, 3, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(BatchNormalization())\n# model.add(Dropout(0.5))\nmodel.add(Conv2D(128, 3, activation= 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.2))\n\n# model.add(BatchNormalization())\nmodel.add(Conv2D(64, 3, activation= 'relu'))\n# model.add(BatchNormalization())\nmodel.add(Conv2D(32, 3, activation= 'relu'))\n# model.add(BatchNormalization())\n\nmodel.add(Flatten())\n# model.add(Dense(128, activation= 'relu'))\n# model.add(Dropout(0.3))\nmodel.add(Dense(24, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(12, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(len(Label), activation='softmax'))\n\nmodel.summary()\nmodel.compile(optimizer= 'adam', loss= keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n\nhistory= model.fit(X_tr, y_smote, epochs=50, batch_size= 32, validation_split=0.2,shuffle= True)\n\n","d6755fc1":"X_test= np.array(X_test).reshape(len(X_test),28, 28, 3)","b3af3446":"history_test= model.evaluate(X_test, y_test)","847f2f14":"# plt.figure(figsize= (5, 5))\nplt.subplot(211)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n\nplt.subplot(212)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","8745a393":"**Plotting a rondom sample of the data**","98a5237e":"**The bar diagram showed that we are facing an imbalanced situation. To deal with it, I will be using SMOTE algorithm. To do that, first we need to split the data into test and train sets, then apply SMOTE algorithm on the train data. **","92988548":"**Checking for number of instances in each class after running SMOTE algorithm.  **"}}