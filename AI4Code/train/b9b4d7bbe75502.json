{"cell_type":{"73d8ad1f":"code","998ee721":"code","a1cb71d1":"code","2af316fb":"code","b1511dc9":"code","e33b037f":"code","90ca9d84":"code","fb20dddd":"code","038be1ab":"code","2ce2ae90":"code","f68ba763":"code","8f1306b1":"code","e2ef5a04":"code","18862b5b":"code","696aa493":"code","c106fcc5":"code","104ab118":"code","cbe0eca7":"code","bc0f43ae":"code","d6bd7b7c":"code","ef98e832":"code","a8cf9914":"code","0eec8701":"code","fb048271":"markdown","9cc51356":"markdown","66305cf0":"markdown","fb3430ad":"markdown","622e7dae":"markdown","e50ec69d":"markdown","0d0fb997":"markdown","9b7eb813":"markdown","ad8f124a":"markdown"},"source":{"73d8ad1f":"!pip install natsort","998ee721":"#import necessary libraries\n\nimport os\nimport cv2\nimport random\nimport itertools\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom natsort import natsorted\nfrom os import makedirs, listdir\nfrom os.path import join, exists, isdir\nfrom PIL import Image, ImageChops, ImageEnhance\n\nimport sklearn\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import Sequential,Model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\nfrom tensorflow.keras.applications import (MobileNetV2, Xception, InceptionV3, EfficientNetB7, ResNet101, NASNetLarge, \n                                           VGG19, VGG16, DenseNet201)\nfrom tensorflow.keras.applications import (mobilenet_v2, xception, inception_v3, efficientnet, resnet, nasnet, vgg19, \n                                           vgg16, densenet)\n\nnp.random.seed(2)\nplt.rcParams['figure.dpi'] = 100\nmpl.rcParams['figure.figsize'] = (8, 6)\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']","a1cb71d1":"class Config:\n    CASIA1 = \"..\/input\/casia-dataset\/CASIA1\"\n    CASIA2 = \"..\/input\/casia-dataset\/CASIA2\"\n    autotune = tf.data.experimental.AUTOTUNE\n    epochs = 30\n    batch_size = 32\n    lr = 1e-3\n    name = 'xception'\n    n_labels = 2\n    image_size = (224, 224)\n    decay = 1e-6\n    momentum = 0.95\n    nesterov = False","2af316fb":"models = {\n    'densenet': DenseNet201,\n    'xception': Xception,\n    'inceptionv3': InceptionV3,\n    'effecientnetb7': EfficientNetB7,\n    'vgg19': VGG19,\n    'vgg16': VGG16,\n    'nasnetlarge': NASNetLarge,\n    'mobilenetv2': MobileNetV2,\n    'resnet': ResNet101\n}\n# To use => myNet = models['densenet']() \n\npreprocess = {\n    'densenet': densenet.preprocess_input,\n    'xception': xception.preprocess_input,\n    'inceptionv3': inception_v3.preprocess_input,\n    'effecientnetb7': efficientnet.preprocess_input,\n    'vgg19': vgg19.preprocess_input,\n    'vgg16': vgg16.preprocess_input,\n    'nasnetlarge': nasnet.preprocess_input,\n    'mobilenetv2': mobilenet_v2.preprocess_input,\n    'resnet': resnet.preprocess_input\n}","b1511dc9":"# source = https:\/\/stackoverflow.com\/a\/62010096\/6118987\ndef compute_ela_cv(path, quality):\n    temp_filename = 'temp_file_name.jpg'\n    SCALE = 15\n    orig_img = cv2.imread(path)\n    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n    \n    cv2.imwrite(temp_filename, orig_img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n\n    # read compressed image\n    compressed_img = cv2.imread(temp_filename)\n\n    # get absolute difference between img1 and img2 and multiply by scale\n    diff = SCALE * cv2.absdiff(orig_img, compressed_img)\n    return diff\n\n\ndef convert_to_ela_image(path, quality):\n    temp_filename = 'temp_file_name.jpg'\n    ela_filename = 'temp_ela.png'\n    image = Image.open(path).convert('RGB')\n    image.save(temp_filename, 'JPEG', quality = quality)\n    temp_image = Image.open(temp_filename)\n\n    ela_image = ImageChops.difference(image, temp_image)\n\n    extrema = ela_image.getextrema()\n    max_diff = max([ex[1] for ex in extrema])\n    if max_diff == 0:\n        max_diff = 1\n\n    scale = 255.0 \/ max_diff\n    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n    \n    return ela_image\n\n\ndef random_sample(path, extension=None):\n    if extension:\n        items = Path(path).glob(f'*.{extension}')\n    else:\n        items = Path(path).glob(f'*')\n        \n    items = list(items)\n        \n    p = random.choice(items)\n    return p.as_posix()","e33b037f":"\"\"\"Tensorflow format image encoding\"\"\"\n\n# p = join(Config.CASIA2, 'Tp\/')\n# p = random_sample(p)\n\n# img = tf.io.read_file(p)\n# # img = tf.keras.preprocessing.image.load_img(p, target_size=(224, 224))\n# # img = tf.keras.preprocessing.image.img_to_array(img)\n\n# img = tf.image.decode_jpeg(img, channels=3)\n# img = tf.image.resize(img, (224, 224))\n# img = tf.cast(img, \"uint8\")\n\n# compressed_img = tf.io.encode_jpeg(img, quality=95)\n# compressed_img = tf.image.decode_jpeg(compressed_img, channels=3)\n\n# diff = np.absolute(img.numpy() - compressed_img.numpy())\n# # diff = tf.cast(diff, \"float32\")\n# # absdiff = tf.math.abs(diff)\n# plt.imshow(diff\/255)","90ca9d84":"p = join(Config.CASIA2, 'Au\/')\np = random_sample(p)\norig = cv2.imread(p)\norig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) \/ 255.0\ninit_val = 100\ncolumns = 3\nrows = 3\n\nfig=plt.figure(figsize=(15, 10))\nfor i in range(1, columns*rows +1):\n    quality=init_val - (i-1) * 3\n    img = compute_ela_cv(path=p, quality=quality)\n    if i == 1:\n        img = orig.copy()\n    ax = fig.add_subplot(rows, columns, i) \n    ax.title.set_text(f'q: {quality}')\n    plt.imshow(img)\nplt.show()","fb20dddd":"p = join(Config.CASIA2, 'Tp\/')\np = random_sample(p)\norig = cv2.imread(p)\norig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB) \/ 255.0\ninit_val = 100\ncolumns = 3\nrows = 3\n\nfig=plt.figure(figsize=(15, 10))\nfor i in range(1, columns*rows +1):\n    quality=init_val - (i-1) * 3\n    img = compute_ela_cv(path=p, quality=quality)\n    if i == 1:\n        img = orig.copy()\n    ax = fig.add_subplot(rows, columns, i) \n    ax.title.set_text(f'q: {quality}')\n    plt.imshow(img)\nplt.show()## Test on a spliced fake image","038be1ab":"# !ls ..\/input\/casia-dataset\/CASIA1\/Sp | wc -l\n# !ls ..\/input\/casia-dataset\/CASIA1\/Au | wc -l","2ce2ae90":"import albumentations as A\nfrom albumentations import OneOf, Compose\n\n@tf.function\ndef tensor_aug(img):\n    img = tf.image.random_flip_left_right(img, 5)\n    img = tf.image.random_flip_up_down(img, 5)\n    return img\n\n@tf.function\ndef batch_aug(images, labels):\n    images = tf.map_fn(lambda img: tensor_aug(img), images)\n    return images, labels\n\n# def aug_flip(p=0.5):\n#     return OneOf([\n#         A.Flip(),\n#         A.Transpose(),\n#         A.RandomRotate90()\n#     ],\n#         p=p)\n\n# def albumentation_aug(image, p=0.5):\n#     augmented = Compose([aug_flip(p=1.0)],p=p)\n#     result = augmented(image=image)\n#     return result['image']\n\ndef ela_process(file_path):\n    # https:\/\/www.tensorflow.org\/guide\/data\n    QUALITY = 95\n    SCALE = 15\n    LABELS = np.array(['Au', 'Tp'])\n    \n    parts = tf.strings.split(file_path, os.path.sep)\n    one_hot = parts[-2] == LABELS\n    # Integer encode the label\n    label = tf.argmax(one_hot)\n    label = tf.cast(label, tf.float32)\n    \n    # Generate the image\n    orig = cv2.imread(file_path.numpy().decode('utf-8'))\n    orig = cv2.resize(orig, (224, 224), interpolation = cv2.INTER_AREA)\n    orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n    # Augmentation\n#     orig = albumentation_aug(orig)\n    # Save it in buffer\n    _, buffer = cv2.imencode(\".jpg\", orig, [cv2.IMWRITE_JPEG_QUALITY, QUALITY])\n    # get it from buffer and decode it to numpy array\n    compressed_img = cv2.imdecode(np.frombuffer(buffer, np.uint8), cv2.IMREAD_COLOR)\n\n    # Compute the absolute difference\n    diff = SCALE * (cv2.absdiff(orig, compressed_img))\n    img = preprocess[Config.name](diff)\n    \n    return img, label\n","f68ba763":"jpg_pattern = '..\/input\/casia-dataset\/CASIA2\/*\/*jp*g'\ntif_pattern = '..\/input\/casia-dataset\/CASIA2\/*\/*tif'\n\njpg_files = tf.data.Dataset.list_files(tif_pattern)\ntif_files = tf.data.Dataset.list_files(jpg_pattern)\n\ndata_ds = jpg_files.concatenate(tif_files)\n\ntensor_preprocess = lambda x: tf.py_function(ela_process, [x], [tf.float32, tf.float32])\n\nn_data = data_ds.cardinality().numpy()\nn_val = int(.2 * n_data)\ndata_ds = data_ds.shuffle(n_data)\n\ntrain_ds = data_ds.skip(n_val).map(\n    tensor_preprocess, num_parallel_calls=Config.autotune).batch(Config.batch_size).map(\n    batch_aug, num_parallel_calls=Config.autotune)\n\nval_ds = data_ds.take(n_val).map(\n    tensor_preprocess, num_parallel_calls=Config.autotune).batch(Config.batch_size)\n\nfor img, label in train_ds:\n    print(label)\n    break","8f1306b1":"METRICS = [\n    tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n    tf.keras.metrics.Precision(name='precision'),\n    tf.keras.metrics.Recall(name='recall'),\n    tf.keras.metrics.AUC(name='auc'),\n    tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]\n\ndef create_model(optimizer, name='mobilenet', loss='categorical_crossentropy'):\n    \"\"\"\n    Creates model based on the input name and freezes `blocks_to_train` blocks.\n    Args: \n        optimizer(tf.keras.optimizers): initialized tensorflow optimizers.\n        name(str): one of the keys in the `models` list.\n        blocks_to_train: name of the blocks to freeze, if not given all the \n        layers will be trainable.\n        loss: sets loss\n        \n    \"\"\"\n    \n    base_model = models[name](include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n    # model = Model(base_model.inputs, base_model.layers[-1].output)\n\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(1024, activation='relu')(x)\n    output = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(base_model.inputs, output)\n    \n    model.compile(loss=loss,\n                  optimizer=optimizer,\n                  metrics=METRICS)\n    return model\n\ndef scheduler(epoch):\n    if epoch % 25 == 0 and epoch != 0:\n        lr = K.get_value(model.optimizer.lr)\n        K.set_value(model.optimizer.lr, lr * 0.9)\n        \n    return K.get_value(model.optimizer.lr)\n\ndef generate_path(path_to_output, last_run=False):\n    \"\"\"\n    Creates new path and returns the address.\n    Notes:\n        Sometimes accidently it happens that you overwrite your previous models. so\n        this function is designed to create a new path for each run.\n    \"\"\"\n    if not isdir(path_to_output):\n        makedirs(path_to_output)\n    \n    runs = natsorted([path for path in listdir(path_to_output) if path.startswith(\"run_tf_data\")])\n    if last_run:\n        if not bool(runs):\n            path = join(path_to_output, \"run_tf_data_1\")\n        else:\n            path = join(path_to_output, runs[-1])\n\n        return path\n    if not bool(runs):\n        path = join(path_to_output, 'run_tf_data_1')\n    else:\n        f = runs[-1].rsplit(\"data_\")[1]\n        path = join(path_to_output, 'run_tf_data_' + str(int(f) + 1))\n    \n    return path","e2ef5a04":"METRICS = [\n    tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n    tf.keras.metrics.Precision(name='precision'),\n    tf.keras.metrics.Recall(name='recall'),\n    tf.keras.metrics.AUC(name='auc'),\n    tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]\n\ndef create_model(optimizer, name='mobilenet', loss='categorical_crossentropy'):\n    \"\"\"\n    Creates model based on the input name and freezes `blocks_to_train` blocks.\n    Args: \n        optimizer(tf.keras.optimizers): initialized tensorflow optimizers.\n        name(str): one of the keys in the `models` list.\n        blocks_to_train: name of the blocks to freeze, if not given all the \n        layers will be trainable.\n        loss: sets loss\n        \n    \"\"\"\n    \n    base_model = models[name](include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n    # model = Model(base_model.inputs, base_model.layers[-1].output)\n\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dense(1024, activation='relu')(x)\n    output = Dense(1, activation='sigmoid')(x)\n    \n    model = Model(base_model.inputs, output)\n    \n    model.compile(loss=loss,\n                  optimizer=optimizer,\n                  metrics=METRICS)\n    return model\n\ndef scheduler(epoch):\n    if epoch % 25 == 0 and epoch != 0:\n        lr = K.get_value(model.optimizer.lr)\n        K.set_value(model.optimizer.lr, lr * 0.9)\n        \n    return K.get_value(model.optimizer.lr)\n\ndef generate_path(path_to_output, last_run=False):\n    \"\"\"\n    Creates new path and returns the address.\n    Notes:\n        Sometimes accidently it happens that you overwrite your previous models. so\n        this function is designed to create a new path for each run.\n    \"\"\"\n    if not isdir(path_to_output):\n        makedirs(path_to_output)\n    \n    runs = natsorted([path for path in listdir(path_to_output) if path.startswith(\"run_tf_data\")])\n    if last_run:\n        if not bool(runs):\n            path = join(path_to_output, \"run_tf_data_1\")\n        else:\n            path = join(path_to_output, runs[-1])\n\n        return path\n    if not bool(runs):\n        path = join(path_to_output, 'run_tf_data_1')\n    else:\n        f = runs[-1].rsplit(\"data_\")[1]\n        path = join(path_to_output, 'run_tf_data_' + str(int(f) + 1))\n    \n    return path\n","18862b5b":"loss=tf.keras.losses.BinaryCrossentropy()\noptimizer = SGD(lr=Config.lr, \n#                 decay=Config.decay, \n                momentum=Config.momentum, \n                nesterov=Config.nesterov)\n\"\"\"\nModel             Params\nmobilenet           3M \neffecientnetb7      66M \nnasnetlarge         89M\ninceptionv3         23M\nxception            22M\nresnet              44M\ndensenet            20M\n\n\"\"\"\n\n\nmodel = create_model(optimizer, name=Config.name, loss=loss)\n\n# model.summary()","696aa493":"path = generate_path('checkpoints')\nweight_path = join(path, 'weights')\ntensorboard_path = join(path, 'logs')\n\nmakedirs(weight_path)\nmakedirs(tensorboard_path)\n\nckpt = ModelCheckpoint(\n    filepath=weight_path, \n    monitor='val_loss', \n    save_best_only=True,\n    save_weights_only=True\n)\n\ntensorboard = TensorBoard(\n    log_dir=tensorboard_path, \n    write_graph=True\n)\n\nreduce_lr = LearningRateScheduler(scheduler)\n\n\ncallbacks = [ckpt, \n#              reduce_lr, \n             tensorboard]","c106fcc5":"path = generate_path('checkpoints')\nweight_path = join(path, 'weights')\ntensorboard_path = join(path, 'logs')\n\nmakedirs(weight_path)\nmakedirs(tensorboard_path)\n\nckpt = ModelCheckpoint(\n    filepath=weight_path, \n    monitor='val_loss', \n    save_best_only=True,\n    save_weights_only=True\n)\n\ntensorboard = TensorBoard(\n    log_dir=tensorboard_path, \n    write_graph=True\n)\n\nreduce_lr = LearningRateScheduler(scheduler)\n\n\ncallbacks = [ckpt, \n#              reduce_lr, \n             tensorboard]","104ab118":"history = model.fit(\n    train_ds,\n    epochs=6,\n    batch_size=Config.batch_size,\n    callbacks=callbacks,\n    validation_data=val_ds\n)","cbe0eca7":"# https:\/\/www.tensorflow.org\/tutorials\/structured_data\/imbalanced_data#evaluate_metrics\n# Plot loss\n\ndef plot_loss(history, label, n):\n    # Use a log scale on y-axis to show the wide range of values.\n    plt.semilogy(history.epoch, history.history['loss'],\n               color=colors[n], label='Train ' + label)\n    plt.semilogy(history.epoch, history.history['val_loss'],\n               color=colors[n], label='Val ' + label,\n               linestyle=\"--\")\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\nplot_loss(history, Config.name, 0)","bc0f43ae":"def plot_metrics(history):\n    metrics = ['loss', 'prc', 'precision', 'recall']\n    for n, metric in enumerate(metrics):\n        name = metric.replace(\"_\",\" \").capitalize()\n        plt.subplot(2,2,n+1)\n        plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n        plt.plot(history.epoch, history.history['val_'+metric],color=colors[0], \n                 linestyle=\"--\", label='Val')\n        plt.xlabel('Epoch')\n        plt.ylabel(name)\n        if metric == 'loss':\n            plt.ylim([0, plt.ylim()[1]])\n        elif metric == 'auc':\n            plt.ylim([0.8,1])\n        else:\n            plt.ylim([0,1])\n\n        plt.legend()\n\nplot_metrics(history)","d6bd7b7c":"val_ds_x = []\nval_ds_y = []\n\nfor _, (val_x_batch, val_y_batch) in enumerate(val_ds):\n    for val_x, val_y in zip(val_x_batch, val_y_batch):\n        val_ds_x.append(val_x)\n        val_ds_y.append(val_y)\n\nval_data = (tf.convert_to_tensor(val_ds_x, dtype=tf.float32), \n            tf.convert_to_tensor(val_ds_y, dtype=tf.float32))","ef98e832":"val_data[0].numpy().shape","a8cf9914":"# https:\/\/www.tensorflow.org\/tutorials\/structured_data\/imbalanced_data#evaluate_metrics\n# sns.color_palette(\"mako\", as_cmap=True)\nclass_names = ['fake', 'authentic'] # make sure its correct\n\ntest_predictions_baseline = model.predict(val_data[0].numpy(), batch_size=Config.batch_size)\n\n## CHECK\ndef plot_cm(label_matrix, predictions):\n    \n    preds = np.around(np.squeeze(predictions))\n    gt = np.around(np.squeeze(predictions))\n    \n    cm = confusion_matrix(gt, \n                          preds,\n                          labels=np.array([0, 1]))\n    plt.figure(figsize=(8,8))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"icefire_r\")\n    indices = np.arange(len(class_names))\n    plt.xticks(indices, class_names, rotation=45)\n    plt.yticks(indices, class_names)\n    plt.title('Confusion matrix')\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n\nbaseline_results = model.evaluate(val_data[0].numpy(), \n                                  val_data[1].numpy(),\n                                  batch_size=Config.batch_size, \n                                  verbose=0)\n\nfor name, value in zip(model.metrics_names, baseline_results):\n    print(name, ': ', value)\nprint()\n\nplot_cm(val_data[1].numpy(), np.squeeze(test_predictions_baseline))","0eec8701":"model.save_weights(\"weights.h5\")","fb048271":"# Callbacks","9cc51356":"## Utility functions for Training and Evaluations","66305cf0":"# Test on a Authentic image","fb3430ad":"# Computing error rate analysis","622e7dae":"## Test on a spliced fake image","e50ec69d":"# Evaluation","0d0fb997":"## Initializing the model","9b7eb813":"## Check the generated images","ad8f124a":"## Test on a tampered fake image"}}