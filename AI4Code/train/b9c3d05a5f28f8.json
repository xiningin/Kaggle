{"cell_type":{"d8c5b998":"code","ff6b15b1":"code","0a2499d5":"code","30a7e2d9":"code","25e320fa":"code","08025d4e":"code","3596dbf7":"code","59a9198e":"code","aaa5cc44":"code","2d9552cf":"code","81db01c1":"markdown","5cfda2fe":"markdown","eae16fd6":"markdown","af64ad82":"markdown","41788af7":"markdown","4f87e985":"markdown","eb3e48a7":"markdown","d6a656a3":"markdown"},"source":{"d8c5b998":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ff6b15b1":"# save filepath to variable for easier access\nmelbourne_file_path = '..\/input\/melbourne-housing-snapshot\/melb_data.csv'\n# read the data and store data in DataFrame titled melbourne_data\nmelbourne_data = pd.read_csv(melbourne_file_path) \n# print a summary of the data in Melbourne data\nmelbourne_data.describe()","0a2499d5":"melbourne_data.columns","30a7e2d9":"# The Melbourne data has some missing values (some houses for which some variables weren't recorded.)\n# We'll learn to handle missing values in a later tutorial.  \n# So we will take the simplest option for now, and drop houses from our data.\n# dropna drops missing values (think of na as \"not available\")\nmelbourne_data = melbourne_data.dropna(axis=0)","25e320fa":"y=melbourne_data.Price","08025d4e":"melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']\n#print(melbourne_features)","3596dbf7":"X = melbourne_data[melbourne_features]\n#print(X)\n\nX.describe()\n","59a9198e":"X.head()","aaa5cc44":"#import the DecisionTreeregressor from the package sklearn.tree\nfrom sklearn.tree import DecisionTreeRegressor\n\n#specify the model\n#For model reproducibility, set a numeric value for random_state when specifying the model\nmelbourne_model = DecisionTreeRegressor(random_state=1)\n\n#Fit the model\nmelbourne_model.fit(X,y)\n","2d9552cf":"predictions = melbourne_model.predict(X)\n\n#checking the predictions with the Price that I stored in a variable y\nprint(predictions)\nprint(y)\n\n","81db01c1":"# Choosing Features\nThe columns that are inputted into our model (and later used to make predictions) are called \"features.\" In our case, those would be the columns used to determine the home price. Sometimes, you will use all columns except the target as features. Other times you'll be better off with fewer features.\n\nFor now, we'll build a model with only a few features. Later on you'll see how to iterate and compare models built with different features.\n\nWe select multiple features by providing a list of column names inside brackets. Each item in that list should be a string (with quotes).","5cfda2fe":"# Make Predictions\nMake predictions with the model's predict command using X as the data. Save the results to a variable called predictions.","eae16fd6":"Decision Tree: \nWe'll start with a model called the Decision Tree. There are fancier models that give more accurate predictions. But decision trees are easy to understand, and they are the basic building block for some of the best models in data science.\n\nAs an example, we'll look at data about home prices in Melbourne, Australia. In the hands-on exercises, you will apply the same processes to a new dataset, which has home prices in Iowa.\n\nThe example (Melbourne) data is at the file path ..\/input\/melbourne-housing-snapshot\/melb_data.csv.\n\nWe load and explore the data with the following commands:","af64ad82":"# Building the Model\nI am going to use the scikit-learn library to create your models. When coding, this library is written as sklearn, as you will see in the sample code. Scikit-learn is easily the most popular library for modeling the types of data typically stored in DataFrames.\n\nThe steps to building and using a model are:\n\n1. **Define**: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n2. **Fit**: Capture patterns from provided data. This is the heart of modeling.\n3. **Predict**: Just what it sounds like\n4. **Evaluate**: Determine how accurate the model's predictions are.","41788af7":"**Examine the Columns**","4f87e985":"# Selecting The Prediction Target","eb3e48a7":"# **Load the Data**","d6a656a3":"By convention, this data is called X."}}