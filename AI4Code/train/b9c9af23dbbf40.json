{"cell_type":{"2d35b85e":"code","ce6bb09a":"code","35ae8aa9":"code","20403c6a":"code","91c96d37":"code","ff3e5714":"code","1de60e32":"code","81b6bffe":"code","3826b15d":"code","af86faab":"code","3ceb3da3":"code","69df1674":"code","e328eebc":"code","ed112559":"code","6c9e5f19":"code","6e8bd4c5":"code","63f5826b":"code","acd98a82":"code","cb055d73":"code","8a0b856d":"code","972fa3a5":"code","feb60573":"code","3477b1a3":"code","d9aac9fc":"code","7ec6b574":"code","36e56a50":"code","e8d94d59":"code","71527dec":"code","e8d6a83a":"code","e5a70c72":"code","2efbe8ea":"code","722dd9d6":"code","1d15df41":"code","d531d58f":"code","57eacc9b":"code","4759082f":"code","2ef8dd55":"code","eca24f22":"code","8a06e294":"code","a826c62c":"code","310a1b77":"code","c8ece5ac":"code","57f07705":"code","80e4b785":"code","5cb98a99":"code","d3d1aba4":"code","b244049c":"code","8e831eba":"code","266d2c7f":"code","6a653ebc":"code","666a0a19":"code","477cf890":"code","75fe6182":"code","fe728746":"code","83a259a1":"code","c4194986":"code","f3ff8f25":"code","efae796e":"code","6cec0708":"code","c2199cbf":"code","1581266f":"code","1913aa77":"code","d766e7e4":"code","d6fa93a4":"code","0665b4c9":"code","bb7d0905":"code","3f8e2c69":"code","f6c64ba6":"code","56746511":"code","dc4a9420":"code","42d83e58":"code","5d9c7aae":"code","bcf48731":"code","5cc52394":"code","5f9539e2":"code","2f84444f":"code","0963e9d9":"code","e965b85b":"code","73ef5773":"code","011c7b69":"code","469b93ad":"code","f8212e46":"code","40659b98":"code","ea779a8f":"code","4a27a3d9":"code","72541d22":"code","607ee330":"code","f04590f2":"code","32bc82ec":"code","29b7788d":"code","3a58fa26":"code","601a69a3":"markdown","3e108c34":"markdown","6a760cc3":"markdown","e49a4833":"markdown","7c1143f4":"markdown","776b6142":"markdown","d437dd06":"markdown","a7554ba2":"markdown","13ecae4e":"markdown","55257501":"markdown","2d6510a4":"markdown","ba74e452":"markdown","e5b50b09":"markdown","c16e7e78":"markdown","e4f8261e":"markdown","da6e953f":"markdown","63a6a919":"markdown","e6c55588":"markdown","e17e44ab":"markdown","c6adfdee":"markdown","f27ca9ca":"markdown","2de91376":"markdown","3f142422":"markdown","5712cc5f":"markdown","f6757fbd":"markdown","53be38f6":"markdown","e9e99106":"markdown","97cb5971":"markdown","73da3cde":"markdown","69e58592":"markdown","82fcac39":"markdown"},"source":{"2d35b85e":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport scipy\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\n%matplotlib inline","ce6bb09a":"# Hide unnecessary warnings when loading audio files\nimport warnings\nwarnings.filterwarnings(\"ignore\")","35ae8aa9":"audio_path = '..\/input\/birdsong-recognition\/train_audio\/'\ntest_audio_path = '..\/input\/birdsong-recognition\/example_test_audio\/'","20403c6a":"subFolderList = []\nfor x in os.listdir(audio_path):\n    if os.path.isdir(audio_path + '\/' + x):\n        subFolderList.append(x)\n\nsample_audio = []\ntotal = 0\nfor x in subFolderList:\n    \n    # get all the wave files\n    all_files = [y for y in os.listdir(audio_path+x) if '.mp3' in y]\n    total += len(all_files)\n    \n    # collect the first file from each dir\n    sample_audio.append(audio_path + x + '\/'+ all_files[0])\n    \n    # show file counts\n    print(x, len(all_files), end=' | ')","91c96d37":"print('Number of classes:', len(subFolderList))\nprint('  Number of files:', total)\n\nprint('\\nAverage number of files per class:', round(total\/len(subFolderList)))","ff3e5714":"# demo_audio = '..\/input\/birdsong-recognition\/train_audio\/aldfly\/XC142068.mp3'\ndemo_audio = '..\/input\/birdsong-recognition\/train_audio\/bewwre\/XC122453.mp3' #shorter clip\ndemo_clip, demo_sample_rate = librosa.load(demo_audio, sr=None)\nprint(\"Class:\", demo_audio.split('\/')[-2])\nprint(\" File:\", demo_audio)\nAudio(demo_audio)","1de60e32":"trace = [go.Scatter(\n    x=np.linspace(0, demo_sample_rate\/len(demo_clip), len(demo_clip)), \n    y=demo_clip\n)]\nlayout = go.Layout(\n    title = 'Waveform <br><sup>Interactive<\/sup>',\n    yaxis = dict(title='Amplitude'),\n    xaxis = dict(title='Time'),\n    )\nfig = go.Figure(data=trace, layout=layout)\nfig.show()","81b6bffe":"# fig = plt.figure(figsize=(25,15))\nfig = plt.figure(figsize=(25,12))\nfor i, filepath in enumerate(sample_audio[:20]):\n    # plt.subplot(5,1,i+1)\n    plt.subplot(5,4,i+1)\n    clip, sample_rate = librosa.load(filepath, sr=None)\n    plt.title(filepath.split('\/')[-2])\n    plt.axis('off')\n    plt.plot(clip, c='black', lw=0.5)","3826b15d":"def plot_raw_waves(label, color=None):\n    same_samples = [audio_path + f'{label}\/' + y for y in os.listdir(audio_path + f'{label}\/')[:20]]\n\n    fig = plt.figure(figsize=(25,12))\n    fig.suptitle(label, fontsize=30, c=color)\n    for i, filepath in enumerate(same_samples):\n        plt.subplot(5,4,i+1)\n        clip, sample_rate = librosa.load(filepath, sr=None)\n        plt.axis('off')\n        plt.plot(clip, c=color, lw=0.5)","af86faab":"plot_raw_waves('ribgul', '#FBC02D')","3ceb3da3":"plot_raw_waves('casfin', '#D81B60')","69df1674":"plot_raw_waves('snobun', '#F4511E')","e328eebc":"plot_raw_waves('lazbun', '#039BE5')","ed112559":"def log_specgram(audio, sample_rate, window_size=20,\n                 step_size=10, eps=1e-10):\n    nperseg = int(round(window_size * sample_rate \/ 1e3))\n    noverlap = int(round(step_size * sample_rate \/ 1e3))\n    freqs, times, spec = scipy.signal.spectrogram(audio,\n                                    fs=sample_rate,\n                                    window='hann',\n                                    nperseg=nperseg,\n                                    noverlap=noverlap,\n                                    detrend=False)\n    return freqs, times, np.log(spec.T.astype(np.float32) + eps)","6c9e5f19":"demo_freqs, demo_times, demo_spec = log_specgram(demo_clip, sample_rate)","6e8bd4c5":"trace = [go.Heatmap(\n    x= demo_times,\n    y= demo_freqs,\n    z= demo_spec.T,\n    colorscale='viridis',\n    )]\nlayout = go.Layout(\n    title = 'Spectrogram <br><sup>Interactive<\/sup>',\n    yaxis = dict(title='Frequency'),\n    xaxis = dict(title='Time'),\n    )\nfig = go.Figure(data=trace, layout=layout)\nfig.show()","63f5826b":"fig = plt.figure(figsize=(25,12))\nfor i, filepath in enumerate(sample_audio[:20]):\n    plt.subplot(5,4,i+1)\n    label = filepath.split('\/')[-2]\n    plt.title(label)\n    clip, sample_rate = librosa.load(filepath, sr=None)\n    _, _, spectrogram = log_specgram(clip, sample_rate)\n    plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n    plt.axis('off');","acd98a82":"def plot_spectrograms(label):\n    same_samples = [audio_path + f'{label}\/' + y for y in os.listdir(audio_path + f'{label}\/')[:20]]\n\n    fig = plt.figure(figsize=(25,12))\n    fig.suptitle(label, fontsize=30)\n    for i, filepath in enumerate(same_samples):\n        plt.subplot(5,4,i+1)\n        clip, sample_rate = librosa.load(filepath, sr=None)\n        _, _, spectrogram = log_specgram(clip, sample_rate)\n        plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n        plt.axis('off')","cb055d73":"plot_spectrograms('ribgul')","8a0b856d":"plot_spectrograms('casfin')","972fa3a5":"plot_spectrograms('snobun')","feb60573":"plot_spectrograms('lazbun')","3477b1a3":"trace = [go.Surface(\n    x= demo_times,\n    y= demo_freqs,\n    z= demo_spec.T,\n    colorscale='viridis',\n)]\nlayout = go.Layout(\ntitle='3D Specgtrogram <br><sup>Interactive<\/sup>',\nscene = dict(\n    yaxis = dict(title='Frequency', range=[demo_freqs.min(),demo_freqs .max()]),\n    xaxis = dict(title='Time', range=[demo_times.min(),demo_times.max()],),\n    zaxis = dict(title='Log amplitude'),\n    ),\n)\nfig = go.Figure(data=trace, layout=layout)\nfig.show()","d9aac9fc":"from scipy.fftpack import fft\ndef custom_fft(y, fs):\n    T = 1.0 \/ fs\n    N = y.shape[0]\n    yf = fft(y)\n    xf = np.linspace(0.0, 1.0\/(2.0*T), N\/\/2)\n    vals = 2.0\/N * np.abs(yf[0:N\/\/2])  \n    return xf, vals","7ec6b574":"demo_xf, demo_vals = custom_fft(demo_clip, demo_sample_rate)","36e56a50":"trace = [go.Scatter(\n    x=demo_xf, \n    y=demo_vals,\n    line_color='deeppink'\n)]\nlayout = go.Layout(\n    title = 'Fast Fourier Transform (FFT) <br><sup>Interactive<\/sup>',\n    yaxis = dict(title='Magnitude'),\n    xaxis = dict(title='Frequency'),\n    )\nfig = go.Figure(data=trace, layout=layout)\nfig.show()","e8d94d59":"fig = plt.figure(figsize=(25,12))\nfor i, filepath in enumerate(sample_audio[:20]):\n    plt.subplot(5,4,i+1)\n    label = filepath.split('\/')[-2]\n    plt.title(label)\n    clip, sample_rate = librosa.load(filepath, sr=None)\n    xf, vals = custom_fft(clip, sample_rate)\n    plt.plot(xf, vals, c='black')\n    plt.axis('off');","71527dec":"def plot_ffts(label, color=None):\n    same_samples = [audio_path + f'{label}\/' + y for y in os.listdir(audio_path + f'{label}\/')[:20]]\n\n    fig = plt.figure(figsize=(25,12))\n    fig.suptitle(label, fontsize=30, c=color)\n    for i, filepath in enumerate(same_samples):\n        plt.subplot(5,4,i+1)\n        clip, sample_rate = librosa.load(filepath, sr=None)\n        xf, vals = custom_fft(clip, sample_rate)\n        plt.plot(xf, vals, c=color)\n        plt.axis('off')","e8d6a83a":"plot_ffts('ribgul', '#FBC02D')","e5a70c72":"plot_ffts('casfin', '#D81B60')","2efbe8ea":"plot_ffts('snobun', '#F4511E')","722dd9d6":"plot_ffts('lazbun', '#039BE5')","1d15df41":"demo_S = librosa.feature.melspectrogram(demo_clip, sr=demo_sample_rate, n_mels=128)    \ndemo_log_S = librosa.power_to_db(demo_S, ref=np.max)","d531d58f":"trace = [go.Heatmap(\n    x= demo_times,\n    y= demo_freqs,\n    z= demo_log_S,\n    colorscale='magma',\n    )]\nlayout = go.Layout(\n    title = 'Mel Power Spectrogram <br><sup>Interactive<\/sup>',\n    yaxis = dict(title='Mel'),\n    xaxis = dict(title='Time'),\n    )\nfig = go.Figure(data=trace, layout=layout)\nfig.show()","57eacc9b":"fig = plt.figure(figsize=(25,12))\nfor i, filepath in enumerate(sample_audio[:20]):\n    plt.subplot(5,4,i+1)\n    label = filepath.split('\/')[-2]\n    plt.title(label)\n    clip, sample_rate = librosa.load(filepath, sr=None)\n    S = librosa.feature.melspectrogram(clip, sr=sample_rate, n_mels=128)    \n    log_S = librosa.power_to_db(S, ref=np.max)    \n    librosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel')\n    plt.axis('off');","4759082f":"def plot_mel_spectrograms(label):\n    same_samples = [audio_path + f'{label}\/' + y for y in os.listdir(audio_path + f'{label}\/')[:20]]\n\n    fig = plt.figure(figsize=(25,12))\n    fig.suptitle(label, fontsize=30)\n    for i, filepath in enumerate(same_samples):\n        plt.subplot(5,4,i+1)\n        clip, sample_rate = librosa.load(filepath, sr=None)\n        S = librosa.feature.melspectrogram(clip, sr=sample_rate, n_mels=128)    \n        log_S = librosa.power_to_db(S, ref=np.max)    \n        librosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel')\n        plt.axis('off');","2ef8dd55":"plot_mel_spectrograms('ribgul')","eca24f22":"plot_mel_spectrograms('casfin')","8a06e294":"plot_mel_spectrograms('snobun')","a826c62c":"plot_mel_spectrograms('lazbun')","310a1b77":"demo_mfcc = librosa.feature.mfcc(S=demo_log_S, n_mfcc=13)\ndemo_delta2_mfcc = librosa.feature.delta(demo_mfcc, order=2)","c8ece5ac":"trace = [go.Heatmap(\n    x= demo_times,\n    y= demo_freqs,\n    z= demo_delta2_mfcc,\n    colorscale='RdBu_r',\n    )]\nlayout = go.Layout(\n    title = 'MFCC  <br><sup>Interactive<\/sup>',\n    yaxis = dict(title='MFCC coeffs'),\n    xaxis = dict(title='Time'),\n    )\nfig = go.Figure(data=trace, layout=layout)\nfig.show()","57f07705":"fig = plt.figure(figsize=(25,12))\nfor i, filepath in enumerate(sample_audio[:20]):\n    plt.subplot(5,4,i+1)\n    label = filepath.split('\/')[-2]\n    plt.title(label)\n    clip, sample_rate = librosa.load(filepath, sr=None)\n    S = librosa.feature.melspectrogram(clip, sr=sample_rate, n_mels=128)    \n    log_S = librosa.power_to_db(S, ref=np.max)    \n    mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n    librosa.display.specshow(delta2_mfcc, cmap='bwr')\n    plt.axis('off');","80e4b785":"def plot_mmfcs(label):\n    same_samples = [audio_path + f'{label}\/' + y for y in os.listdir(audio_path + f'{label}\/')[:20]]\n\n    fig = plt.figure(figsize=(25,12))\n    fig.suptitle(label, fontsize=30)\n    for i, filepath in enumerate(same_samples):\n        plt.subplot(5,4,i+1)\n        clip, sample_rate = librosa.load(filepath, sr=None)\n        S = librosa.feature.melspectrogram(clip, sr=sample_rate, n_mels=128)    \n        log_S = librosa.power_to_db(S, ref=np.max)    \n        mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n        delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n        librosa.display.specshow(delta2_mfcc, cmap='bwr')\n        plt.axis('off');","5cb98a99":"plot_mmfcs('ribgul')","d3d1aba4":"plot_mmfcs('casfin')","b244049c":"plot_mmfcs('snobun')","8e831eba":"plot_mmfcs('lazbun')","266d2c7f":"def audio_plots(filename):\n    clip, sample_rate = librosa.load(filename, sr=None)\n    freqs, times, spectrogram = log_specgram(clip, sample_rate)\n    label = filename.split('\/')[-2]\n    \n    # # Normalize (if needed)\n    # mean = np.mean(spectrogram, axis=0)\n    # std = np.std(spectrogram, axis=0)\n    # spectrogram = (spectrogram - mean) \/ std\n\n    fig = plt.figure(figsize=(20,15), dpi=200)\n      \n    # Raw wave\n    ax1 = fig.add_subplot(511)\n    ax1.set_title('Raw wave of ' + label)\n    ax1.set_ylabel('Amplitude')\n    librosa.display.waveplot(clip.astype('float'), sr=sample_rate)\n\n    # FFT    \n    ax2 = fig.add_subplot(512)\n    xf, vals = custom_fft(clip, sample_rate)\n    ax2.set_title('FFT of ' + label + ' with ' + str(sample_rate) + ' Hz')\n    ax2.plot(xf, vals, 'm')\n    ax2.set_xlabel('Frequency')\n    ax2.set_ylabel('Magnitude')\n    ax2.grid()\n    \n    # Spectrogram    \n    ax3 = fig.add_subplot(513)\n    ax3.set_title('Spectrogram of ' + label)\n    ax3.set_ylabel('Freqs in Hz')\n    ax3.set_xlabel('Seconds')\n    ax3.imshow(spectrogram.T, aspect='auto', origin='lower', \n               extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n    \n    # Mel power spectrogram\n    ax4 = fig.add_subplot(514)    \n    S = librosa.feature.melspectrogram(clip, sr=sample_rate, n_mels=128)    \n    log_S = librosa.power_to_db(S, ref=np.max) \n    librosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel')\n    ax4.set_title('Mel power spectrogram of ' + label)   \n    \n    # MFCC\n    ax5 = fig.add_subplot(515)\n    mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n    delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n    librosa.display.specshow(delta2_mfcc, cmap='bwr')\n    ax5.set_title('MFCC of ' + label)\n    ax5.set_ylabel('MFCC coeffs')\n    ax5.set_xlabel('Time')\n\n    plt.tight_layout()\n    print(f\"Class: {label}\\n File: {filename}, \")\n    return Audio(filename)","6a653ebc":"audio_plots(demo_audio)","666a0a19":"audio_plots(sample_audio[1])","477cf890":"audio_plots(sample_audio[50])","75fe6182":"audio_plots(sample_audio[100])","fe728746":"audio_plots(sample_audio[150])","83a259a1":"audio_plots(sample_audio[200])","c4194986":"audio_plots(sample_audio[250])","f3ff8f25":"def load_audio_file(filename):\n    data, sr = librosa.load(filename, sr=None)\n    return data, sr\n\nsns.set(style='darkgrid')\ndef plot_time_series(data, sr, alpha=0.5, color=None, label=None):\n#     plt.figure(figsize=(20,5))\n    plt.title('Raw wave')\n    plt.ylabel('Amplitude')\n    plt.plot(np.linspace(0, sr\/len(data), len(data)), data, alpha=alpha, c=color, label=label)\n    plt.legend(loc='lower left', ncol=2, frameon=False)\n    return Audio(data, rate=sr)\n\ndef plot_spectrogram(data, sr, label=None):\n    S = librosa.feature.melspectrogram(data, sr, n_mels=128)    \n    log_S = librosa.power_to_db(S, ref=np.max)\n    plt.figure(figsize=(20,3), dpi=200)\n    plt.title('Mel power spectrogram')\n    plt.text(0.05, 200, label, fontsize=12, c='w')\n    librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')    \n#     plt.axis('off')","efae796e":"org_data, sr = load_audio_file(demo_audio)\nprint(\"Class:\", demo_audio.split('\/')[-2])\nprint(\" File:\", demo_audio)\n\nplt.figure(figsize=(20,5))\nplot_time_series(org_data, sr, 0.67, 'blue', 'Actual')","6cec0708":"plot_spectrogram(org_data, sr, 'Actual')","c2199cbf":"# Use mean & std of individual data or of all data as custom params\ndef normalize(X, mean=None, std=None):\n    mean = mean or X.mean()\n    std = std or (X-X.mean()).std()\n    return ((X - mean)\/std).astype(np.float64)","1581266f":"data = normalize(org_data)","1913aa77":"plt.figure(figsize=(20,5))\nplot_time_series(org_data, sr, 0.7, 'blue', 'Actual')\nplot_time_series(data, sr, 0.6, 'red', 'Normalized')","d766e7e4":"plot_spectrogram(org_data, sr, 'Actual')\nplot_spectrogram(data, sr, 'Normalized')","d6fa93a4":"wn = np.random.randn(len(data))\ndata_wn = data + 0.1 * wn","0665b4c9":"plt.figure(figsize=(20,5))\nplot_time_series(data, sr, 0.7, 'blue', 'Actual')\nplot_time_series(data_wn, sr, 0.6, 'red', 'White Noise')","bb7d0905":"plot_spectrogram(data, sr, 'Actual')\nplot_spectrogram(data_wn, sr, 'White Noise')","3f8e2c69":"data_roll = np.roll(data, 5000)","f6c64ba6":"plt.figure(figsize=(20,5))\nplot_time_series(data, sr, 0.5, 'blue', 'Actual')\nplot_time_series(data_roll, sr, 0.7, 'red', 'Shifted')","56746511":"plot_spectrogram(data, sr, 'Actual')\nplot_spectrogram(data_roll, sr, 'Shifted')","dc4a9420":"# larger value\ndata_stretch = librosa.effects.time_stretch(data, 1.2)","42d83e58":"plt.figure(figsize=(20,5))\nplot_time_series(data, sr, 0.3, 'blue', 'Actual')\nplot_time_series(data_stretch, sr, 0.8, 'red', 'Stretched')","5d9c7aae":"plot_spectrogram(data, sr, 'Actual')\nplot_spectrogram(data_stretch, sr, 'Stretched')","bcf48731":"# smaller value\ndata_stretch = librosa.effects.time_stretch(data, 0.8)","5cc52394":"plt.figure(figsize=(20,5))\nplot_time_series(data, sr, 0.3, 'blue', 'Actual')\nplot_time_series(data_stretch, sr, 0.8, 'red', 'Stretched')","5f9539e2":"plot_spectrogram(data, sr, 'Actual')\nplot_spectrogram(data_stretch, sr, 'Stretched')","2f84444f":"data_pitch = librosa.effects.pitch_shift(data, sr, n_steps=-10)","0963e9d9":"plt.figure(figsize=(20,5))\nplot_time_series(data, sr, 0.5, 'blue', 'Actual')\nplot_time_series(data_pitch, sr, 0.8, 'red', 'Pitch changed')","e965b85b":"plot_spectrogram(data, sr, 'Actual')\nplot_spectrogram(data_pitch, sr, 'Pitch changed')","73ef5773":"data_invert = -data","011c7b69":"plt.figure(figsize=(20,5))\nplot_time_series(data, sr, 1, 'blue', 'Actual')\nplot_time_series(data_invert, sr, 0.7, 'red', 'Inverted')","469b93ad":"plot_spectrogram(data, sr, 'Actual')\nplot_spectrogram(data_invert, sr, 'Inverted')","f8212e46":"x = np.linspace(0, sr\/len(data), len(data))\ntrace = [\n    go.Scatter(x=x, y=org_data, name='Actual', opacity=0.5),\n    go.Scatter(x=x, y=data, name='Normalized', opacity=0.5),\n    go.Scatter(x=x, y=data_wn, name='Noise', opacity=0.5),\n    go.Scatter(x=x, y=data_roll, name='Shift', opacity=0.5),\n    go.Scatter(x=x, y=data_stretch, name='Stretch', opacity=0.5),\n    go.Scatter(x=x, y=data_pitch, name='Pitch', opacity=0.5),\n    go.Scatter(x=x, y=data_invert, name='Invert', opacity=0.5),\n]\n\nlayout = go.Layout(\n    title = 'Augmentations <br><sup>Interactive<\/sup>',\n    yaxis = dict(title='Amplitude'),\n    xaxis = dict(title='Time'),\n    legend_title_text='Augmentations <br><sup>Toggle augmentations on\/off<\/sup>'\n    )\n\nfig = go.Figure(data=trace, layout=layout)\nfig.show()","40659b98":"print(\"ACTUAL:\")\norg_data, sr = load_audio_file(demo_audio)\nAudio(org_data, rate=sr)","ea779a8f":"data = normalize(org_data)\ndata_wn = data + 0.1 * wn\ndata_roll = np.roll(data_wn, 5000)\ndata_stretch = librosa.effects.time_stretch(data_roll, 1)\ndata_pitch = librosa.effects.pitch_shift(data_stretch, sr, n_steps=-10)\ndata_invert = -data_pitch\ndata_aug = data_invert\n\nplt.figure(figsize=(20,5))\nplot_time_series(data, sr, 0.3, 'blue', 'Actual')\nprint(\"AUGMENTED:\")\nplot_time_series(data_aug, sr, 0.7, 'red', 'Augmented')","4a27a3d9":"plot_spectrogram(data, sr, 'Actual')\nplot_spectrogram(data_aug, sr, 'Augmented')","72541d22":"clip, sample_rate = librosa.load(demo_audio, sr=None)\nprint(\"Class:\", demo_audio.split('\/')[-2])\nprint(\" File:\", demo_audio)\nAudio(demo_audio)","607ee330":"S = librosa.feature.melspectrogram(clip, sr=sample_rate, n_mels=256)    \nlog_S = librosa.power_to_db(S, ref=np.max)\n\nplt.figure(figsize=(20,4))\nplt.title('Mel power spectrogram')\nplt.text(0.05, 200, 'original audio', fontsize=12, c='w')\nlibrosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel');","f04590f2":"def spec_augment(spec: np.ndarray, num_mask=2, freq_masking_max_percentage=0.15, time_masking_max_percentage=0.3):\n    spec = spec.copy()\n    for i in range(num_mask):\n        num_freqs, num_frames = spec.shape\n        freq_percentage = random.uniform(0.0, freq_masking_max_percentage)\n        time_percentage = random.uniform(0.0, time_masking_max_percentage)\n        \n        num_freqs_to_mask = int(freq_percentage * num_freqs)\n        num_frames_to_mask = int(time_percentage * num_frames)\n        \n        t0 = int(np.random.uniform(low=0.0, high=num_frames - num_frames_to_mask))\n        f0 = int(np.random.uniform(low=0.0, high=num_freqs - num_freqs_to_mask))\n        \n        spec[:, t0:t0 + num_frames_to_mask] = 0     \n        spec[f0:f0 + num_freqs_to_mask, :] = 0 \n        \n    return spec","32bc82ec":"for i in range(4):\n    plt.figure(figsize=(20,3))\n    librosa.display.specshow(spec_augment(log_S), sr=sample_rate, x_axis='time', y_axis='mel');\n#     plt.axis('off')","29b7788d":"def pad_to_size(signal, size, mode):\n    if signal.shape[1] < size:\n        padding = size - signal.shape[1]\n        offset = padding \/\/ 2\n        pad_width = ((0, 0), (offset, padding - offset))\n        if mode == 'constant':\n            signal = np.pad(signal, pad_width, 'constant', constant_values=signal.min())\n        elif mode == 'wrap':\n            signal = np.pad(signal, pad_width, 'wrap')\n    return signal    ","3a58fa26":"img_size = 400\n\nplt.figure(figsize=(20,4))\nplt.title('Mel power spectrogram')\nplt.text(0.05, 200, 'constant', fontsize=12, c='w')\nlibrosa.display.specshow(pad_to_size(log_S, img_size, 'constant'), sr=sample_rate, x_axis='time', y_axis='mel');\n\nplt.figure(figsize=(20,4))\nplt.title('Mel power spectrogram')\nplt.text(0.05, 200, 'wrap', fontsize=12, c='w')\nlibrosa.display.specshow(pad_to_size(log_S, img_size, 'wrap'), sr=sample_rate, x_axis='time', y_axis='mel');","601a69a3":"### Adding white noise ","3e108c34":"## Mel Spec Augmentations\n\nAs mentioned earlier, we can convert this time-series problem into a computer vision problem by converting the audio data into mel spectrograms *(or MFCC)*.\n\nThis is similar to any other image classification problem, where all the common augmentations can be done. Here are a few most common augmentation methods for mel spectrograms.\n\nLet us consider this *(same)* audio as an example to demonstrate.","6a760cc3":"## In-depth per sample analysis\n\nLet's analyse individual audio files with all the above visualizations to get a better understanding.","e49a4833":"### Normalize\n\nLet's first normalize the audio clip before applying augmentations.","7c1143f4":"### Shifting the sound","776b6142":"> In classical, but still state-of-the-art systems, MFCC or similar features are taken as the input to the system instead of spectrograms. However, in end-to-end (often neural-network based) systems, the most common input features are probably raw spectrograms, or mel power spectrograms. For example MFCC decorrelates features, but NNs deal with correlated features well.","d437dd06":"## Acknowledgements and References:\n\n- https:\/\/www.kaggle.com\/davids1992\/speech-representation-and-data-exploration\n- https:\/\/www.kaggle.com\/timolee\/audio-data-conversion-to-images-eda\n- https:\/\/www.kaggle.com\/CVxTz\/audio-data-augmentation\n\n---","a7554ba2":"## Mel Spectrogram\n\nThe Mel Scale, mathematically speaking, is the result of some **non-linear transformation of the frequency scale**. This Mel Scale is constructed such that sounds of equal distance from each other on the Mel Scale, also _\u201csound\u201d_ to humans as they are equal in distance from one another.\nIn contrast to Hz scale, where the difference between 500 and 1000 Hz is obvious, whereas the difference between 7500 and 8000 Hz is barely noticeable.\nMel Spectrogram, is, rather surprisingly, a Spectrogram with the Mel Scale as its y axis.\nMore [here](https:\/\/towardsdatascience.com\/getting-to-know-the-mel-spectrogram-31bca3e2d9d0).\n","13ecae4e":"### Stretching the sound","55257501":"#### Combining all in one","2d6510a4":"Function that calculates spectrogram.\n\nNote, that we are taking logarithm of spectrogram values. It will make our plot much more clear, moreover, it is strictly connected to the way people hear. We need to assure that there are no 0 values as input to logarithm.","ba74e452":"This visualization is called the **time-domain** representation of a given signal. This shows us the loudness (amplitude) of sound wave changing with time. Here amplitude = 0 represents silence. These amplitudes are not very informative, as they only talk about the loudness of audio recording. ","e5b50b09":"### Raw waves of a few samples\n\nWaveform is merely a graph that displays amplitude or level changes over time. Amplitude is measured in a bipolar manner, with positive and negative values.\n\nAmazing interactive site to learn more: https:\/\/pudding.cool\/2018\/02\/waveforms","c16e7e78":"### Changing the Pitch","e4f8261e":"### Inverting the Polarity","da6e953f":"### All Augmentations","63a6a919":"### 3D Spectrogram","e6c55588":"### Example Audio \n\nLet us consider this audio as an example to demonstrate.","e17e44ab":"### Spectrograms of a few samples\n\nA spectrogram is a visual way of representing the signal strength, or \u201cloudness\u201d, of a signal over time at various frequencies present in a particular waveform.  Not only can one see whether there is more or less energy at, for example, 2 Hz vs 10 Hz, but one can also see how energy levels vary over time.\n\nSpectrograms can be two-dimensional graphs with a third variable represented by color. One axis represents time, and the other axis represents frequency; a third dimension indicating the amplitude of a particular frequency at a particular time is represented by the intensity or color of each point in the image.\n\nAmazing spectrogram visualization for ***bird*** here: https:\/\/musiclab.chromeexperiments.com\/Spectrogram\/","c6adfdee":"## Audio Analysis and Augmentation Demo <br><sup>with Interactive Plots<\/sup>\n\n**Dataset:** [Cornell Birdcall Identification](https:\/\/www.kaggle.com\/c\/birdsong-recognition\/data)\n\n\n<details>\n  <summary><em>Version History<\/em><\/summary>\n  <br \/>\n  <ul>\n    <li>V1: <em>Initial Commit<\/em><\/li>\n    <li>V2: <em>More Examples and Interactive plots<\/em><\/li>\n    <li>V3: <em>Better Augmentations Demo and Comparisons<\/em><\/li>\n    <li>V4: <em>Normalization and Fixes<\/em><\/li>\n    <li>V5: <em>Melspec Augmentations<\/em><\/li>\n  <\/ul>\n<\/details>\n\n---","f27ca9ca":"<span style=\"color: blue;\"><strong>BLUE<\/strong><\/span> is the actual audio clip and <span style=\"color: red;\"><strong>RED<\/strong><\/span> is for the augmented audio clip.","2de91376":"## Mel Frequency Cepstral Coefficient (MFCC)\n\nMFCC features represent phonemes (distinct units of sound) as the shape of the vocal tract (which is responsible for sound generation) is manifest in them. The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10-20) which concisely **describe the overall shape of a spectral envelope**.\nMore [here](https:\/\/medium.com\/prathena\/the-dummys-guide-to-mfcc-aceab2450fd) & [here](http:\/\/practicalcryptography.com\/miscellaneous\/machine-learning\/guide-mel-frequency-cepstral-coefficients-mfccs\/).","3f142422":"## Audio Augmentations\n\nLet us consider this *(same)* audio as an example to demonstrate.\n\n> ***NOTE:*** Augmentation values are boosted to showcase their effect","5712cc5f":"### Spec Dropout\n\nWe augment spectrograms by hiding random time & frequency intervals.","f6757fbd":"### Pad to size\n\nIf the spectrogram is shorter than the required image size, it can be padded.","53be38f6":"Analyse the data and the number of audio files per class","e9e99106":"Function that calculates FFT.\n\nNote, FFT is simmetrical, so we take just the first half and FFT is also complex, so we consider the real part (abs).","97cb5971":"# Data","73da3cde":"## Audio Visualizations","69e58592":"Load the data","82fcac39":"## Fast Fourier Transform (FFT)\n\nAn audio signal is a complex signal composed of multiple \u2018single-frequency sound waves\u2019 which travel together as a disturbance(pressure-change) in the medium. When sound is recorded we only capture the resultant amplitudes of those multiple waves. Fourier Transform is a mathematical concept that can **decompose a signal into its constituent frequencies**. Fourier transform does not just give the frequencies present in the signal, It also gives the magnitude of each frequency present in the signal. The only difference between FT(Fourier Transform) and FFT is that FT considers a continuous signal while FFT takes a discrete signal as input."}}