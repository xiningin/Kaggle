{"cell_type":{"2a64cd6e":"code","86df616f":"code","4f758b01":"code","1d3730f7":"code","28accba4":"code","0e06770f":"code","0510d33f":"code","7e941768":"code","3c53448d":"code","f5a7b0ad":"code","30304356":"code","82ee18de":"code","abd00d38":"code","aac07c61":"code","380e3ec3":"code","3e22845d":"code","0ac8f94e":"code","72a2bf9e":"code","7c283a60":"code","03459d7a":"code","88250e58":"code","271bccce":"code","7e6c6cea":"code","89770967":"code","6825918f":"code","53ac525c":"code","5a41f4b1":"code","487b8236":"code","a1fc77dd":"code","448f4d88":"code","3a8d310e":"code","051626d4":"code","240f3d31":"code","92af1a06":"code","273de6d2":"code","8a63026f":"markdown","41abebbc":"markdown","41ff7807":"markdown","ff778a5d":"markdown","69665500":"markdown","a1187c02":"markdown","3b403ff2":"markdown","2f6a7f62":"markdown","c6c90334":"markdown"},"source":{"2a64cd6e":"import numpy as np\nimport pandas as pd\nimport missingno as msno\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.express as px \nimport plotly.tools as tls \nimport plotly.figure_factory as ff \n\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames[0:1]:\n#        print(os.path.join(dirname, filename))","86df616f":"district_df = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\nproducts_df = pd.read_csv('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')","4f758b01":"district_df.head(3)","1d3730f7":"products_df.head(3)","28accba4":"# Check missing value on both dataset\ndisplay(district_df.info(),district_df.isna().sum()\/len(district_df)*100)","0e06770f":"# Visuaize occurence of missing value in dataset\nmsno.matrix(district_df.sort_values(by = 'state', ascending = True))","0510d33f":"# Drop rows where '''state''' column is null\ndistrict_df.dropna(subset = ['state'], how = 'any', inplace = True)","7e941768":"'''\nReformat on 4 columns by following steps\n- Remove the bracket\n- Split number by comma\n- Get max and min number by position after split\n- Get average from max and min value\n'''\n\nreformat_colname = ['pct_black\/hispanic', 'pct_free\/reduced', 'county_connections_ratio', 'pp_total_raw']\n\nfor colname in reformat_colname:\n    district_df[colname] = district_df[colname].str.replace('[', '', regex = False)\n    district_df[colname + '_min'] = district_df[colname].str.split(',', expand = True)[0].astype('float')\n    district_df[colname + '_max'] = district_df[colname].str.split(',', expand = True)[1].astype('float')\n    district_df[colname + '_avg'] = (district_df[colname + '_min']  + district_df[colname + '_max'])\/2\n    district_df.drop(columns = colname, inplace = True)\n    \ndistrict_df['state_local'] = district_df['state'] + ':' + district_df['locale']\ndistrict_df['district_id'] = district_df['district_id'].astype('string')","3c53448d":"district_df.head(5)","f5a7b0ad":"# Check missing value on dataset\ndisplay(products_df.info(),products_df.isna().sum()\/len(products_df)*100)","30304356":"msno.matrix(products_df.sort_values(by = 'Sector(s)', ascending = False))","82ee18de":"# Create product count by provider\/company name for fill the missing value\nproduct_count = products_df.groupby(['Provider\/Company Name']).agg({'Product Name' : 'nunique',\n                                                                    'Sector(s)' : lambda x : x.isnull().sum()}).reset_index()\n\npotential_product_dup = product_count[(product_count['Product Name']  > product_count['Sector(s)']) &\n                                      (product_count['Sector(s)'] > 0)].rename(columns = {\"Product Name\":\"Unique_Product Name\",\n                                                                                          \"Sectors(s)\" : \"Missing_Sector(s)\"})\n\npotential_product_dup","abd00d38":"# Example of missing Sectors by CompanyName\nproducts_df[products_df['Provider\/Company Name'] == 'Adobe Inc.']","aac07c61":"#Adobe Inc.\t\nproducts_df.at[305, 'Sector(s)'] = products_df.iloc[213]['Sector(s)']\nproducts_df.at[305, 'Primary Essential Function'] = products_df.iloc[213]['Primary Essential Function']\n\n#ClassDojo, Inc.\t\nproducts_df.at[237, 'Sector(s)'] = products_df.iloc[19]['Sector(s)']\nproducts_df.at[237, 'Primary Essential Function'] = products_df.iloc[19]['Primary Essential Function']\n\n#Code.org\nproducts_df.at[356, 'Sector(s)'] = products_df.iloc[22]['Sector(s)']\nproducts_df.at[356, 'Primary Essential Function'] = products_df.iloc[22]['Primary Essential Function']\n\n#EDpuzzle Inc.\nproducts_df.at[370, 'Sector(s)'] = products_df.iloc[31]['Sector(s)']\nproducts_df.at[370, 'Primary Essential Function'] = products_df.iloc[31]['Primary Essential Function']\n\n#Grammarly\nproducts_df.at[314, 'Sector(s)'] = products_df.iloc[57]['Sector(s)']\nproducts_df.at[314, 'Primary Essential Function'] = products_df.iloc[57]['Primary Essential Function']\n\n#IXL Learning\nproducts_df.at[61, 'Sector(s)'] = products_df.iloc[60]['Sector(s)']\nproducts_df.at[61, 'Primary Essential Function'] = products_df.iloc[60]['Primary Essential Function']\n\n#Microsoft\nproducts_df.at[183, 'Sector(s)'] = products_df.iloc[216]['Sector(s)']\nproducts_df.at[183, 'Primary Essential Function'] = products_df.iloc[216]['Primary Essential Function']\n\n#Technological Solutions, Inc. (TSI)\nproducts_df.at[352, 'Sector(s)'] = products_df.iloc[301]['Sector(s)']\nproducts_df.at[352, 'Primary Essential Function'] = products_df.iloc[301]['Primary Essential Function']","380e3ec3":"# Helper Functions for cleaning sub-strip in list\ndef clean_sectors_list(sector_list: list) -> list:\n    try:\n        sub_sector = [sector.strip() for sector in sector_list]\n        return sub_sector\n    except:\n        return ['Unknow']\n        \n        \ndef clean_sub_cat(item_list: list) -> list:\n    try:\n        sub_cat = item_list[1:]\n        sub_cat = [item.strip() for item in sub_cat]\n        return sub_cat\n    except:\n        return ['Unknow']","3e22845d":"# Sectors Column\nproducts_df['Sector(s)_list'] = products_df['Sector(s)'].str.split(';')\nproducts_df['Sector(s)_list'] = products_df['Sector(s)_list'].apply(lambda x : clean_sectors_list(x))\n\nsector = products_df['Sector(s)_list'].explode()\nproducts_df= products_df.join(pd.crosstab(sector.index, sector))\nproducts_df.rename(columns = {'Corporate' : 'Sector_Corporate',\n                             'Higher Ed' : 'Sector_Higher Ed',\n                             'PreK-12' : 'Sector_PreK-12',\n                             'Unknow' : 'Sector_Unknow'}, inplace = True)","0ac8f94e":"# Category Column\nproducts_df['Product Category'] = products_df['Primary Essential Function'].str.split('-', expand = True)[0]\nproducts_df['Primary Essential Function_list'] = products_df['Primary Essential Function'].str.split('-')\nproducts_df['Product Sub-Cat_list'] = products_df['Primary Essential Function_list'].apply(lambda x: clean_sub_cat(x))\n\nsubcat = products_df['Product Sub-Cat_list'].explode()\nproducts_df = products_df.join(pd.crosstab(subcat.index, subcat))\n\nproducts_df.head(5)","72a2bf9e":"engauge_path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'\nengauge_data_list = os.listdir(engauge_path)\n\ntotal_engauge_df = pd.DataFrame()\nfor file in engauge_data_list:\n    single_city_data = pd.read_csv(engauge_path + '\/' +file)\n    single_city_data['district_id'] = str(file.replace('.csv', ''))\n    total_engauge_df = total_engauge_df.append(single_city_data)","7c283a60":"total_engauge_df.head(5)","03459d7a":"# Check mising value on all columns\n''' Consider to drop all missing lp_id and pct_access due to low percentage of missing'''\ntotal_engauge_df.isna().sum()\/len(total_engauge_df)*100","88250e58":"'''\nClean Up #1\n- Drop missing value on columns lp_id, pct_access\n- Correct format of 'lp_id'\n- Correct datatyppe of 'lp_id', '\n- Conver 'time' to date_time data type\n'''\ntotal_engauge_df = total_engauge_df.dropna(subset = ['lp_id', 'pct_access'])\ntotal_engauge_df['lp_id'] = total_engauge_df['lp_id'].astype('str').str.replace('.0', '', regex = False)\ntotal_engauge_df['time'] = pd.to_datetime(total_engauge_df['time'], format = '%Y-%m-%d')","271bccce":"total_engauge_df['month'] = total_engauge_df['time'].dt.month\ntotal_engauge_df['year'] = total_engauge_df['time'].dt.year\ntotal_engauge_df['year'] = total_engauge_df['time'].dt.quarter\ntotal_engauge_df['dateofweek_quarter'] = total_engauge_df['time'].dt.dayofweek # Monday = 0, Sunday = 6\ntotal_engauge_df['dateofweek_name'] = total_engauge_df['time'].dt.day_name()","7e6c6cea":"# Extract datetime features\ntotal_engauge_df['month'] = total_engauge_df['time'].dt.month\ntotal_engauge_df['year'] = total_engauge_df['time'].dt.year\ntotal_engauge_df['quarter'] = total_engauge_df['time'].dt.quarter\ntotal_engauge_df['dateofweek_quarter'] = total_engauge_df['time'].dt.dayofweek # Monday = 0, Sunday = 6\ntotal_engauge_df['dateofweek_name'] = total_engauge_df['time'].dt.day_name()\ntotal_engauge_df['year_month'] = total_engauge_df['time'].dt.to_period('M')\n\ntotal_engauge_df['district_product'] = total_engauge_df['district_id'] + '_' + total_engauge_df['lp_id']","89770967":"overall_engage = total_engauge_df.groupby(['month']).agg({'engagement_index' : 'mean'}).reset_index()\noverall_access = total_engauge_df.groupby(['month']).agg({'pct_access' : 'mean'}).reset_index()","6825918f":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Create figure with secondary y-axis\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=overall_engage['month'], y=overall_engage['engagement_index'], name=\"Engaugement data\"),\n    secondary_y=False,\n)\n\nfig.add_trace(\n    go.Scatter(x=overall_access['month'], y=overall_access['pct_access'], name=\"Access Pct data\"),\n    secondary_y=True,\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Overall of engaugement index and access percentage over 2020\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Month\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"Enagement Index\", secondary_y=False)\nfig.update_yaxes(title_text=\"Access Percentage\", secondary_y=True)\n\nfig.show()","53ac525c":"covid_data = pd.read_csv('..\/input\/covid-case-from-ourworldindata\/owid-covid-data.csv')\nus_data = covid_data[covid_data['location'] == 'United States'][['date','new_cases', 'new_vaccinations']]\n\nus_data['date'] = pd.to_datetime(us_data['date'])\n\nus_data['month'] = us_data['date'].dt.month\nus_data['year'] = us_data['date'].dt.year\nus_data['quarter'] = us_data['date'].dt.quarter\n\nus_data_2020 = us_data[us_data['year'] == 2020]\n\nus_data_2020monthly = us_data_2020.groupby(['month']).agg({'new_cases':'sum'}).reset_index()","5a41f4b1":"fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\nfig.add_trace(\n    go.Scatter(x=overall_engage['month'], y=overall_engage['engagement_index'], name=\"Engaugement data\"),\n    secondary_y=False,\n)\n\nfig.add_trace(\n    go.Bar(x = us_data_2020monthly['month'], y = us_data_2020monthly['new_cases'], name = \"COVID19 Case in USA\"), secondary_y = True\n)\n\n# Add figure title\nfig.update_layout(\n    title_text=\"Overall of engaugement index and monthly COVID case over 2020\"\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Month\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"Enagement Index\", secondary_y=False)\nfig.update_yaxes(title_text=\"Monthly COVID case\", secondary_y=True)\n\nfig.show()","487b8236":"# Helper functions to reduce memory usage\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","a1fc77dd":"total_engauge_df = reduce_mem_usage(total_engauge_df)\ndistrict_df = reduce_mem_usage(district_df)","448f4d88":"total_engauge_df = total_engauge_df.merge(district_df, on= 'district_id', how = 'left')","3a8d310e":"total_engauge_df.dropna(subset = ['state_local'], inplace = True)","051626d4":"px.line(total_engauge_df.groupby(['locale', 'month']).agg({'engagement_index' : 'mean','pct_access' : 'mean'}).reset_index(), \n                                    x = 'month', y = 'engagement_index', color = 'locale', title = 'Monthly Average Engaugement Index by Locale')","240f3d31":"px.line(total_engauge_df.groupby(['locale', 'month']).agg({'engagement_index' : 'mean','pct_access' : 'mean'}).reset_index(), \n                                    x = 'month', y = 'pct_access', color = 'locale', title = 'Monthly Average Access Pct by Locale')","92af1a06":"px.line(total_engauge_df.groupby(['state', 'month']).agg({'engagement_index' : 'mean','pct_access' : 'mean'}).reset_index(), \n                                    x = 'month', y = 'engagement_index', color = 'state', title = 'Monthly Average Engaugement Index by District')","273de6d2":"px.line(total_engauge_df.groupby(['state', 'month']).agg({'engagement_index' : 'mean','pct_access' : 'mean'}).reset_index(), \n                                    x = 'month', y = 'engagement_index', color = 'state', title = 'Monthly Average Engaugement Index by District')","8a63026f":"# Exploratory Data Analysis","41abebbc":"## Overall Trend by District and Locale","41ff7807":"# Data Cleaning on All Dataset","ff778a5d":"### Product Data\n#### Finding\n- Missing value on ```Sector(s)``` and ```Primary Essential Function``` are due to duplicateion in ```Product Name``` and ```URL```\n- Both ```Sector(s)``` and ```Primary Essential Function```  will be missed together\n\n#### Cleaning Requirement\n- Manual fill up ```Sector(s)``` and ```Primary Essential Function``` from other ```Product Name```  in within group of ```Provider\/Company Name``` \n- Replace '-' in ```Primary Essential Function``` for spliting\n- Split ```Primary Essential Function``` to get product labels and sub-cateogires\n- Split ```Sector(s)``` to be columns-wise and turn it to boolean","69665500":"### District Data\n#### Finding\n- All missing data in state will have ```state```, ```locale```, ```pct_black\/hispanic```, ```pct_free\/reduced```, ```country_connections_ratio``` and ```pp_total_raw```\n<br\/>\n<br\/>\n\n#### Cleaning Requirement\n- Consider to drop out all ```district_id``` in the row that contain missing value in ```state```\n- Correct format of columns ```pct_black\/hispanic```, ```pct_free\/reduced``` , ```county_connections_ratio```, ```pp_total_raw``` by spliting to min, max and mean","a1187c02":"### Engagement Data","3b403ff2":"### Data Types Checking","2f6a7f62":"## Product and District Data","c6c90334":"## Overall Trend Over 2020"}}