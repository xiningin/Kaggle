{"cell_type":{"5cfe7e4e":"code","44fb925e":"code","eb7a532a":"code","aca0ce0e":"code","a028abda":"code","16ea0d8c":"code","8148dbef":"code","53538a3b":"code","2bf7c9a5":"code","718299ca":"code","b547b94e":"code","6a0672be":"code","2790da11":"code","a5c117b5":"code","de41f96a":"code","49f020a5":"code","b0142074":"code","bd83dd96":"code","e1165a74":"code","9588927d":"code","0c12375f":"code","eae81e8c":"code","37045ddd":"code","b84b3268":"code","66caaa63":"code","b9a46965":"code","e81d651e":"code","cec90d83":"code","84a9e0a4":"code","f5e1fa75":"code","0305b769":"code","37a3da4e":"code","f91209fe":"code","eceef0c4":"code","6d686349":"code","62f7f61e":"code","133c1f8e":"code","80a19a7b":"code","a3207aae":"code","c4a71e70":"code","33c79f23":"code","d12c4bb3":"code","f7da7e07":"code","bf659b90":"code","29e7f637":"code","790ad80a":"code","542ad424":"code","72bdf0fd":"code","9b53d2d6":"code","644a5be8":"code","1b20f3f3":"code","a0e96544":"code","5da55e6d":"code","962d5fb8":"code","7603082d":"code","fd226d76":"code","4dd76c2e":"code","09bb595f":"code","26395cd0":"code","54c8e4a4":"code","0ee61baa":"code","f0f9e600":"code","f9c1fbf3":"code","b6131e35":"code","ff817fb7":"markdown","82a8e076":"markdown","4e9f1451":"markdown","f21f7e5a":"markdown","89a8411b":"markdown","19b7e22f":"markdown","f1c26d3e":"markdown","3098878b":"markdown","d818f251":"markdown","2fc9be2a":"markdown","948d5b6f":"markdown","75d0a8dc":"markdown","5703cfe0":"markdown","5cf6180b":"markdown","82778df4":"markdown","01a6386f":"markdown","ac7de4b2":"markdown","cff48436":"markdown","c1f5eb8b":"markdown","bf06315f":"markdown","4c3318c1":"markdown","62767741":"markdown","f5e3de41":"markdown","dce3e8da":"markdown","d9e6ede6":"markdown","9c7b18a5":"markdown","22796316":"markdown","07c64512":"markdown","73864390":"markdown","ba45b247":"markdown","3334c4ec":"markdown","6da7a816":"markdown","ec6325a2":"markdown","36502b63":"markdown","776a4f03":"markdown","60047807":"markdown","34ba9429":"markdown","216b659a":"markdown","27c4ba35":"markdown","112865d4":"markdown","4c05f2f2":"markdown","8fa3ba49":"markdown","50ac235a":"markdown","98605ec4":"markdown","75f8fea4":"markdown","f5bf1fe1":"markdown","9e488dac":"markdown","935153ac":"markdown","8f880c4c":"markdown","8dc52103":"markdown","d9ac34be":"markdown","1f13f72c":"markdown","2068a857":"markdown","bdd22204":"markdown","93d8061a":"markdown","4ed245f2":"markdown","5e9e8473":"markdown","b01bf63a":"markdown","b4911098":"markdown","0d6721f9":"markdown","3e285592":"markdown","22190fc3":"markdown","9e86b8fe":"markdown","ecb5e37d":"markdown"},"source":{"5cfe7e4e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","44fb925e":"house_price_train_dataset = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","eb7a532a":"house_price_test_dataset = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","aca0ce0e":"pd.pandas.set_option('display.max_columns', None)\nhouse_price_train_dataset.head()","a028abda":"pd.pandas.set_option('display.max_columns', None)\nhouse_price_test_dataset.head()","16ea0d8c":"house_price_train_dataset.shape","8148dbef":"house_price_test_dataset.shape","53538a3b":"house_price_train_dataset.info()","2bf7c9a5":"house_price_test_dataset.info()","718299ca":"train_features_with_nan = [feature for feature in house_price_train_dataset.columns if (house_price_train_dataset[feature].isnull().sum() > 0)]\nplt.figure(figsize=(20,5))\nhouse_price_train_dataset[train_features_with_nan].isnull().sum().plot(kind='bar')","b547b94e":"test_features_with_nan = [feature for feature in house_price_test_dataset.columns if (house_price_test_dataset[feature].isnull().sum() > 0)]\nplt.figure(figsize=(20,5))\nhouse_price_test_dataset[test_features_with_nan].isnull().sum().plot(kind='bar')","6a0672be":"plt.figure(figsize=(20,5))\nhouse_price_train_dataset[train_features_with_nan].isnull().mean().plot(kind='bar')","2790da11":"plt.figure(figsize=(20,5))\nhouse_price_test_dataset[test_features_with_nan].isnull().mean().plot(kind='bar')","a5c117b5":"plt.figure(figsize=(30,10))\nsns.heatmap(house_price_train_dataset.isnull(), cbar=False)\nplt.show()","de41f96a":"plt.figure(figsize=(30,10))\nsns.heatmap(house_price_test_dataset.isnull(), cbar=False)\nplt.show()","49f020a5":"msno.heatmap(house_price_train_dataset)","b0142074":"msno.heatmap(house_price_test_dataset)","bd83dd96":"Id = house_price_test_dataset['Id']","e1165a74":"drop_columns = ['Id', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\nhouse_price_train_dataset.drop(house_price_train_dataset[drop_columns], inplace=True, axis=1)\nhouse_price_test_dataset.drop(house_price_test_dataset[drop_columns], inplace=True, axis=1)\nhouse_price_train_dataset.shape,house_price_test_dataset.shape","9588927d":"train_cat_features_with_nan = [feature for feature in house_price_train_dataset if (house_price_train_dataset[feature].isnull().sum() > 0 and\n                                                                                house_price_train_dataset[feature].dtypes == 'O')]\nplt.figure(figsize=(20,5))\nhouse_price_train_dataset[train_cat_features_with_nan].isnull().sum().plot(kind='bar')\nplt.show()","0c12375f":"test_cat_features_with_nan = [feature for feature in house_price_test_dataset if (house_price_test_dataset[feature].isnull().sum() > 0 and\n                                                                                house_price_test_dataset[feature].dtypes == 'O')]\nplt.figure(figsize=(20,5))\nhouse_price_test_dataset[test_cat_features_with_nan].isnull().sum().plot(kind='bar')\nplt.show()","eae81e8c":"train_num_features_with_nan = [feature for feature in house_price_train_dataset.columns if (house_price_train_dataset[feature].isnull().sum() > 0 and\n                                                                                house_price_train_dataset[feature].dtypes != 'O')]\nhouse_price_train_dataset[train_num_features_with_nan].isnull().sum().plot(kind='bar')","37045ddd":"test_num_features_with_nan = [feature for feature in house_price_test_dataset.columns if (house_price_test_dataset[feature].isnull().sum() > 0 and\n                                                                                house_price_test_dataset[feature].dtypes != 'O')]\nhouse_price_test_dataset[test_num_features_with_nan].isnull().sum().plot(kind='bar')","b84b3268":"train_num_features_with_outliers = [feature for feature in house_price_train_dataset.columns if (house_price_train_dataset[feature].dtypes != 'O')]\nhouse_price_train_dataset[train_num_features_with_outliers].describe()","66caaa63":"test_num_features_with_outliers = [feature for feature in house_price_test_dataset.columns if (house_price_test_dataset[feature].dtypes != 'O')]\nhouse_price_test_dataset[test_num_features_with_outliers].describe()","b9a46965":"house_price_train_dataset.boxplot(column='MSSubClass')","e81d651e":"house_price_train_dataset.boxplot(column='LotFrontage')","cec90d83":"house_price_train_dataset.boxplot(column='LotArea')","84a9e0a4":"house_price_train_dataset.boxplot(column='MasVnrArea')","f5e1fa75":"house_price_train_dataset.boxplot(column='BsmtFinSF1')","0305b769":"outliers_features = ['MSSubClass', 'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch']\noutliers_features","37a3da4e":"plt.figure(figsize=(60,20))\nplt.plot(house_price_train_dataset.skew())","f91209fe":"plt.figure(figsize=(60,20))\nplt.plot(house_price_test_dataset.skew())","eceef0c4":"house_price_train_dataset.duplicated().sum()","6d686349":"house_price_test_dataset.duplicated().sum()","62f7f61e":"def replace_cat_missing_values_in_train_dataset(house_price_train_dataset, train_cat_features_with_nan):\n    house_price_train_dataset_new = house_price_train_dataset.copy()\n    for feature in train_cat_features_with_nan:\n        house_price_train_dataset_new[feature] = house_price_train_dataset_new[feature].fillna(house_price_train_dataset_new[feature].mode()[0])\n    return house_price_train_dataset_new\n\nhouse_price_train_dataset = replace_cat_missing_values_in_train_dataset(house_price_train_dataset, train_cat_features_with_nan)\n\ndef replace_cat_missing_values_in_test_dataset(house_price_test_dataset, test_cat_features_with_nan):\n    house_price_test_dataset_new = house_price_test_dataset.copy()\n    for feature in test_cat_features_with_nan:\n        house_price_test_dataset_new[feature] = house_price_test_dataset_new[feature].fillna(house_price_test_dataset_new[feature].mode()[0])\n    return house_price_test_dataset_new\n\nhouse_price_test_dataset = replace_cat_missing_values_in_test_dataset(house_price_test_dataset, test_cat_features_with_nan)","133c1f8e":"for feature in train_num_features_with_nan:\n    median_of_feature = house_price_train_dataset[feature].median()\n    house_price_train_dataset[feature].fillna(median_of_feature, inplace=True)\n    \nfor feature in test_num_features_with_nan:\n    median_of_feature = house_price_test_dataset[feature].median()\n    house_price_test_dataset[feature].fillna(median_of_feature, inplace=True)","80a19a7b":"plt.figure(figsize=(30,5))\nplt.plot(house_price_train_dataset.isnull().sum())\n\nplt.figure(figsize=(30,5))\nplt.plot(house_price_test_dataset.isnull().sum())","a3207aae":"for feature in outliers_features:\n    IQR = house_price_train_dataset[feature].quantile(0.75) - house_price_train_dataset[feature].quantile(0.25)\n    lower_boundary = house_price_train_dataset[feature].quantile(0.25) - (IQR*3)\n    upper_boundary = house_price_train_dataset[feature].quantile(0.75) + (IQR*3)\n    print(feature, lower_boundary, upper_boundary)","c4a71e70":"for feature in outliers_features:\n    IQR = house_price_train_dataset[feature].quantile(0.75) - house_price_train_dataset[feature].quantile(0.25)\n    lower_boundary = house_price_train_dataset[feature].quantile(0.25) - (IQR*3)\n    upper_boundary = house_price_train_dataset[feature].quantile(0.75) + (IQR*3)\n    house_price_train_dataset.loc[house_price_train_dataset[feature]<=lower_boundary, feature] = lower_boundary\n    house_price_train_dataset.loc[house_price_train_dataset[feature]>=upper_boundary, feature] = upper_boundary\n    \nhouse_price_train_dataset[outliers_features].describe()","33c79f23":"for feature in outliers_features:\n    IQR = house_price_test_dataset[feature].quantile(0.75) - house_price_test_dataset[feature].quantile(0.25)\n    lower_boundary = house_price_test_dataset[feature].quantile(0.25) - (IQR*3)\n    upper_boundary = house_price_test_dataset[feature].quantile(0.75) + (IQR*3)\n    print(feature, lower_boundary, upper_boundary)","d12c4bb3":"for feature in outliers_features:\n    IQR = house_price_test_dataset[feature].quantile(0.75) - house_price_test_dataset[feature].quantile(0.25)\n    lower_boundary = house_price_test_dataset[feature].quantile(0.25) - (IQR*3)\n    upper_boundary = house_price_test_dataset[feature].quantile(0.75) + (IQR*3)\n    house_price_test_dataset.loc[house_price_test_dataset[feature]<=lower_boundary, feature] = lower_boundary\n    house_price_test_dataset.loc[house_price_test_dataset[feature]>=upper_boundary, feature] = upper_boundary\n    \nhouse_price_test_dataset[outliers_features].describe()","f7da7e07":"plt.figure(figsize=(30,20))\ncorr = house_price_train_dataset.corr()\nsns.heatmap(corr, annot=True, cmap='RdYlGn')\nplt.show()","bf659b90":"corr_features = corr.index[abs(corr['SalePrice']) < 0.3]\ncorr_features","29e7f637":"house_price_train_dataset.drop(['BsmtFinSF2', 'LowQualFinSF', 'BsmtHalfBath', 'HalfBath', 'KitchenAbvGr', 'KitchenAbvGr', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold'], axis=1, inplace=True)\nhouse_price_test_dataset.drop(['BsmtFinSF2', 'LowQualFinSF', 'BsmtHalfBath', 'HalfBath', 'KitchenAbvGr', 'KitchenAbvGr', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold'], axis=1, inplace=True)\nhouse_price_train_dataset.shape, house_price_test_dataset.shape","790ad80a":"house_price_train_dataset['train'] = 1\nhouse_price_test_dataset['train'] = 0","542ad424":"house_price_dataset = pd.concat([house_price_train_dataset, house_price_test_dataset], axis=0)\nhouse_price_dataset.shape","72bdf0fd":"house_price_dataset = pd.get_dummies(house_price_dataset, drop_first=True)\nhouse_price_dataset.shape","9b53d2d6":"train_dataset = house_price_dataset[house_price_dataset['train'] == 1]\ntest_dataset = house_price_dataset[house_price_dataset['train'] == 0]\ntrain_dataset.shape, test_dataset.shape","644a5be8":"train_dataset.drop(['train'], axis=1, inplace=True)\ntest_dataset.drop(['train'], axis=1, inplace=True)\ntrain_dataset.shape, test_dataset.shape","1b20f3f3":"test_dataset.drop(['SalePrice'], axis=1, inplace=True)","a0e96544":"train_features = train_dataset.drop(['SalePrice'], axis=1)\ntrain_label = train_dataset['SalePrice']\ntrain_features.shape","5da55e6d":"plt.figure(figsize=(12,10))\nfrom sklearn.ensemble import ExtraTreesRegressor\netr = ExtraTreesRegressor()\netr.fit(train_features, train_label)\nfeat_importances = pd.Series(etr.feature_importances_, index=train_features.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show","962d5fb8":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=20, random_state=None, shuffle=False)\nskf.get_n_splits(train_features, train_label)\nfor train_index, test_index in skf.split(train_features, train_label):\n    features_train, features_test = train_features.iloc[train_index], train_features.iloc[test_index]\n    label_train, label_test = train_label.iloc[train_index], train_label.iloc[test_index]","7603082d":"#Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start=100, stop=1200, num=12)]\n\n#Number of features to consider in every split\nmax_features = ['auto', 'sqrt']\n\n#Maximum number of levels in a tree\nmax_depth = [int(x) for x in np.linspace(start=5, stop=30, num=6)]\n\n#Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n\n#Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","fd226d76":"#Random Grid\nrandom_grid = {'n_estimators' : n_estimators,\n              'max_features' : max_features,\n              'max_depth' : max_depth,\n              'min_samples_split' : min_samples_split,\n              'min_samples_leaf' : min_samples_leaf}","4dd76c2e":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nrandom_forest = RandomForestRegressor()\nrandam_forest_model = RandomizedSearchCV(estimator=random_forest, param_distributions=random_grid,\n                                         scoring='neg_mean_squared_error', n_iter=10, cv=5, verbose=2,\n                                        random_state=42, n_jobs=1)\nrandam_forest_model.fit(train_features, train_label)","09bb595f":"randam_forest_model.best_params_","26395cd0":"from sklearn.metrics import r2_score\nr2_score(label_train, randam_forest_model.predict(features_train))","54c8e4a4":"from sklearn.metrics import r2_score\nr2_score(label_test, randam_forest_model.predict(features_test))","0ee61baa":"plt.figure(figsize=(12,5))\nsns.distplot(label_train-randam_forest_model.predict(features_train))","f0f9e600":"plt.figure(figsize=(12,5))\nsns.distplot(label_test-randam_forest_model.predict(features_test))","f9c1fbf3":"test_label = randam_forest_model.predict(test_dataset)\ntest_label","b6131e35":"house_price_predictions = pd.DataFrame(test_label)\nhouse_price_prediction_submission = pd.concat([Id, house_price_predictions], axis=1)\nhouse_price_prediction_submission.columns = ['Id', 'SalePrice']\nhouse_price_prediction_submission.to_csv('house_price_prediction_submission.csv', index=False)","ff817fb7":"# In this notebook I have built a model using ensemble model technique to predict the price of house.\n# Train and Test dataset should always be kept separate and operations such as Data Cleaning, Feature Engineering should be performed on both train and test dataset separately in order to avoid the data leakage. \n# This dataset has huge number of missing values for numerical and categorical features. Thus this notebook contains the techniques to handle the missing values for both numeric and categorical features.\n# This dataset also has very high outliers. Thus I have used the Interquantile range to handle the outliers.\n\n# Below is a quick view of all the steps performed to buid the model.\n# 1) Importing the dataset\n# 2) Analysing the dataset by viewing the top rows of dataset\n# 3) Exploratory Data Analysis\n     - Identifying and Visualizing the percentage of missing values, location of missing values in the dataset, and correlation            between the missing values in the dataset.\n     - Cheking for duplicate rows.\n# 4) Feature Engineering\n     - Handling the missing values of numerical and categorical features using median and mode and applying one hot encoding.\n     - Handling outliers in the train and test dataset.\n     * Feature Selection to select the important features to build the model\n     - Correlation Matrix\n     - Feature Importance\n# 5) Splitting data into train and test\n# 6) Using Randomized Search CV for automated hyperparameter tuning\n# 6) Applying ML algorithm to build the model\n# 7) Using Metrics to check model performance\n# 8) Using the model to predict the price of test data","82a8e076":"* Displaying the best parameters","4e9f1451":"* Above bar and plot graph shows that Alley, PoolQc, Fence and MiscFeature are the features which have most number of missing valus.","f21f7e5a":"# Applying ML Algorithm","89a8411b":"# Identifying all the features which contains missing values in the train dataset","19b7e22f":"# Importing the train dataset","f1c26d3e":"* The train dataset contains 1460 rows and 81 columns","3098878b":"* Value near -1 : means if one variable appears then the other variable is very likely to be missing.\n* Value near 0 : means there is no dependence between the occurrence of missing values of two variables.\n* Value near 1 : means if one variable appears then the other variable is very likely to be present.","d818f251":"# Separating the features and label in the train dataset","2fc9be2a":"# Identifying the outliers in the test dataset","948d5b6f":"* As some features do not have good correlation with the other features, there is not good volume of linearity present in the dataset. So its better to use non linear algorithms to buils the model.","75d0a8dc":"# Displaying top 5 rows for all the coulmns in the train dataset","5703cfe0":"* There is no duplicate row in the test dataset.","5cf6180b":"# Splitting the dataset into train and test","82778df4":"# Metrics to check the model performance","01a6386f":"# Identifying the numeric features in train dataset which contains the missing values","ac7de4b2":"* There is no duplicate row in the train dataset.","cff48436":"# Displaying the percentage of missing values for each feature in train dataset","c1f5eb8b":"# Handling Outliers in the train and test dataset","bf06315f":"# Feature Engineering","4c3318c1":"# Dropping SalePrice Column from the test dataset","62767741":"# Checking duplicated rows in train dataset","f5e3de41":"# Dropping features from train and test dataset having missing values more than 50 percent","dce3e8da":"# Identifying the outliers in the train dataset","d9e6ede6":"# Importing the test dataset","9c7b18a5":"# Visualizing the outliers for few features in the train dataset","22796316":"# Exploratory Data Analysis","07c64512":"# Predicting the SalePrice for the test data","73864390":"# Feature Importance","ba45b247":"# Applying one hot encoding on the dataset","3334c4ec":"* The columns MsSubClass, LotFrontage, LotArea, MasVnrArea, BsmtFinSF1, BsmtUnfSF, TotalBsmtSF, 1stFlrSF, 2ndFlrSF, GrLivArea, GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch have heavy outliers.","6da7a816":"# Create a csv to sumbit the predictions to kaggle","ec6325a2":"* Above bar and plot graph shows that Alley, PoolQc, Fence and MiscFeature are the features which have most number of missing valus.","36502b63":"# Visualize the location of missing values in train dataset.","776a4f03":"* All the missing values in the train and test dataset has been handled.","60047807":"# Visualizing the skewness of the train dataset","34ba9429":"# Separating the train and test dataset","216b659a":"# RandomSearchCV - Automated hyper parameters tuning","27c4ba35":"# Visualizing train and test dataset after handling all the missing values","112865d4":"# Identifying the numeric features in test dataset which contains the missing values","4c05f2f2":"* The dataset has skewness, so replace the missing values for the numerical features with the median.","8fa3ba49":"# Displaying top 5 rows for all the coulmns in the test dataset","50ac235a":"# Displaying the percentage of missing values for each feature in test dataset","98605ec4":"* The train dataset contains 1460 rows and 81 columns","75f8fea4":"Observations:\n* Foundation, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinSF1, BsmtFinType2, BsmtFinSf2, GarageType, GarageYrBuilt, GarageFinsish, GarageQual and GarageCond columns have missing values with variation in occurrence,\n* FireplaceQu, PoolQc, Fence, MiscFeature columns are almost filled with missing values with variation in occurrence and\n* Electrical column has missing value at the end","f5bf1fe1":"Handling missing values of the categorical faetures in train and test dataset\n* Replacing the missing value of the categorical features with the mode of the feature.","9e488dac":"Handling missing values of the numerical features in the train and test dataset.\n* As the dataset is skewed, replacing the missing value of the numerical feature with median.","935153ac":"# Identifying the categorical features in test dataset which contains the missing values","8f880c4c":"* There are total 3 numeric columns which contains the missing values.","8dc52103":"* There are total 11 categorical columns which contains the missing values.","d9ac34be":"# Visualize the location of missing values in test dataset.","1f13f72c":"# Visualizing the skewness of the test dataset","2068a857":"# Visualizing the correlation between the number of missing values in different columns in test dataset as a heatmap ","bdd22204":"# Identifying all the features which contains missing values in the test dataset","93d8061a":"# Feature Selection\n* Correlation Matrix\n* Feature Importance","4ed245f2":"# Dropping the columns which do not have very good correlation with label and other features","5e9e8473":"# Concatinating train and test dataset","b01bf63a":"* As the test dataset contains 1460 rows but for few of the columns rows are < 1460. It means there are missing values in some of the columns in the test dataset.","b4911098":"# Identifying the categorical features in train dataset which contains the missing values","0d6721f9":"# Visualizing the correlation between the number of missing values in different columns in train dataset as a heatmap ","3e285592":"# Checking duplicated rows in test dataset","22190fc3":"Observations :\n* 'MSSubClass', 'LotArea', 'OverallCond', 'BsmtFinSF2', 'BsmtUnfSF', 'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', 'HalfBath',   'BedroomAbvGr', 'KitchenAbvGr', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold' features do not have very good correlation with the label SalePrice\n* 'BsmtFinSF2, 'LowQualFinSF', 'BsmtHalfBath', 'HalfBath', 'KitchenAbvGr', 'KitchenAbvGr', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold' features do not have good correlation with other features.\n* Dropping 'BsmtFinSF2, 'LowQualFinSF', 'BsmtHalfBath', 'HalfBath', 'KitchenAbvGr', 'KitchenAbvGr', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold' features as they do not have good correaltion with the label as well as other features.","9e86b8fe":"* As the train dataset contains 1460 rows but for few of the columns rows are < 1460. It means there are missing values in some of the columns in the train dataset.","ecb5e37d":"# Correlation Matrix"}}