{"cell_type":{"1ca1c9a8":"code","d7bbd797":"code","729fdfe5":"code","e28df0bc":"code","7ba64369":"code","c807040f":"code","af425649":"code","db9a36be":"code","ef4c98dd":"code","71cbb607":"code","90567088":"code","42a9193a":"code","248bb476":"code","1ebc92a5":"code","113dfc81":"code","7cd22b58":"code","7b5b5097":"code","5840a713":"code","f4df64dc":"code","bf73360d":"markdown","58b3f146":"markdown","e15d1d94":"markdown","c1202e9d":"markdown"},"source":{"1ca1c9a8":"ver = 'nn_bl_14'\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nplt.style.use(['seaborn-darkgrid'])\nplt.rcParams['font.family'] = 'DejaVu Sans'\nimport time\nfrom datetime import datetime\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\n\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))\n% matplotlib inline","d7bbd797":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntarget = pd.read_csv('..\/input\/sample_submission.csv')\n","729fdfe5":"train.head()","e28df0bc":"train.describe()","7ba64369":"train.info()","c807040f":"train['target'].value_counts().sort_index(ascending=False).plot(kind='barh', \n                                                                          figsize=(15,6))\nplt.title('Target', fontsize=18);","af425649":"X = train.iloc[:,2:].values\ny = train.iloc[:,1].values\ntest = test.iloc[:,1:].values","db9a36be":"sc0 = StandardScaler()\nsc1 = RobustScaler()\n","ef4c98dd":"X_train0 = sc0.fit_transform(X)\nX_test0 = sc0.transform(test)\nX_train1 = sc1.fit_transform(X)\nX_test1 = sc1.transform(test)\n","71cbb607":"from sklearn.decomposition import PCA","90567088":"fig, ax = plt.subplots(1, 2, figsize = (24, 12))\npca = PCA()\nX_reduced0 = pca.fit_transform(X_train0)\nX_reduced1 = pca.fit_transform(X_train1)\n\n\nax[0].scatter(X_reduced0[:, 0], X_reduced0[:, 1], c=y,\n            edgecolor='none', alpha=0.7, s=40,\n            cmap=plt.cm.get_cmap('bwr', 2))\nax[0].set_title('PCA projection StdScalar')\n\nax[1].scatter(X_reduced1[:, 0], X_reduced1[:, 1], c=y,\n            edgecolor='none', alpha=0.7, s=40,\n            cmap=plt.cm.get_cmap('bwr', 2))\nax[1].set_title('PCA projection Robust')\n\nprint(pca.n_components_)","42a9193a":"def modelir():\n    model = Sequential()\n\n    #input \n    model.add(Dense(200, input_dim=200, kernel_initializer = 'uniform'))\n    model.add(Activation(\"relu\"))\n    #model.add(Dropout(0.8))\n\n    #2 \n    model.add(Dense(1024, kernel_initializer = 'uniform'))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization())\n    for _ in range(5):\n        model.add(Dense(10, kernel_initializer = 'uniform'))\n        model.add(Activation('relu'))\n    \n    model.add(Dense(10, kernel_initializer = 'uniform'))\n    model.add(Activation('relu'))\n    \n    \n\n    #output\n    model.add(Dense(1, activation = 'sigmoid'))\n\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    return model\n#print(model.summary())","248bb476":"def simple_blend1(X, y, test):\n    model = modelir()\n    pred = pd.DataFrame()\n    for i in range(1, 3):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = i)\n        earlystopper = EarlyStopping(patience=5, verbose=1)\n        history = model.fit(X_train, y_train, batch_size=512, epochs=500, validation_split=0.2, verbose=2, callbacks=[earlystopper], shuffle=True)\n        scores = model.evaluate(X_test, y_test, verbose=0)\n        print(\"accuracy for test data: %.2f%%\" % (scores[1]*100))\n        plt.plot(history.history['acc'], label='accuracy for train data')\n        plt.plot(history.history['val_acc'], label='validation data accuracy')\n        plt.xlabel('epochs')\n        plt.ylabel('accuracy')\n        plt.legend()\n        plt.show()\n        y_pred = model.predict(X_test)\n        y_pred = (y_pred > 0.7)\n        cm = confusion_matrix(y_test, y_pred)\n        print(cm)\n        y_pred_t = model.predict(test)\n        print(y_pred_t.T[0])\n        pred[i] = y_pred_t.T[0]\n    return pred","1ebc92a5":"pr1 = simple_blend1(X, y, test)","113dfc81":"pr1['mean'] = pr1.mean(axis=1)\npr1.head()","7cd22b58":"def simple_blend2(X, y, test):\n    pred = pd.DataFrame()\n    for i in range(1, 3):\n        model = modelir()\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = i)\n        earlystopper = EarlyStopping(patience=5, verbose=1)\n        history = model.fit(X_train, y_train, batch_size=512, epochs=500, validation_split=0.2, verbose=2, callbacks=[earlystopper], shuffle=True)\n        scores = model.evaluate(X_test, y_test, verbose=0)\n        print(\"accuracy for test data: %.2f%%\" % (scores[1]*100))\n        plt.plot(history.history['acc'], label='accuracy for train data')\n        plt.plot(history.history['val_acc'], label='validation data accuracy')\n        plt.xlabel('epochs')\n        plt.ylabel('accuracy')\n        plt.legend()\n        plt.show()\n        y_pred = model.predict(X_test)\n        y_pred = (y_pred > 0.7)\n        cm = confusion_matrix(y_test, y_pred)\n        print(cm)\n        y_pred_t = model.predict(test)\n        print(y_pred_t.T[0])\n        pred[i] = y_pred_t.T[0]\n    return pred","7b5b5097":"pr2 = simple_blend2(X, y, test)","5840a713":"pr2['mean'] = pr2.mean(axis=1)\npr2.head()","f4df64dc":"filename = 'subm_{}_{}_'.format(ver, datetime.now().strftime('%Y-%m-%d'))\ntarget['target'] = pr1['mean']\ntarget.to_csv(filename+'1'+'.csv', index=False)\ntarget['target'] = pr2['mean']\ntarget.to_csv(filename+'2'+'.csv', index=False)","bf73360d":"**Model**","58b3f146":"**Load datasets**","e15d1d94":"**Data preparation**","c1202e9d":"**Submission**"}}