{"cell_type":{"b4457ca6":"code","6e3d62c4":"code","75956e57":"code","b2ccbdb6":"code","99d4f9c4":"code","ff463e60":"code","20dc3ed2":"code","2ed32ac6":"code","e571ad5d":"code","60409f77":"code","16672b38":"code","2f41ae6f":"code","34b815b6":"code","5678ee7f":"code","19c4abf7":"code","1a2db503":"code","2a8c58cc":"code","28a56cb9":"code","d59f6fd5":"code","5fb85ba6":"code","774616f9":"code","949b553b":"code","05acefc4":"code","ecc7f746":"code","6837cf3b":"code","da3996c3":"code","62348349":"code","7df74118":"code","e959ab16":"code","886d874d":"code","4a35f7df":"code","e99b452d":"code","8b201d0e":"code","954d2340":"code","a4a178dd":"code","1bcbc132":"code","38adf22e":"code","98a71ef5":"code","1a67eb7b":"code","69347711":"code","daa73b51":"code","a4321058":"code","02099e1d":"code","ae6be713":"code","45f13f81":"markdown","bfaa9c0c":"markdown","3ac2c6d7":"markdown","4014d243":"markdown","061e5dcb":"markdown","47bbf5cb":"markdown","296e7ceb":"markdown","3696d816":"markdown","e0efb196":"markdown","215c1a71":"markdown","5e7940b0":"markdown","01b0d79c":"markdown","4c6dc2c4":"markdown","26e415aa":"markdown","e5f1561e":"markdown","7f8e5dc0":"markdown","517b1f6d":"markdown","2b40a300":"markdown","52660a02":"markdown","384ded36":"markdown"},"source":{"b4457ca6":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix","6e3d62c4":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nsub = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nmix = [train, test] #(1)","75956e57":"train.columns.values","b2ccbdb6":"train.head()","99d4f9c4":"train.tail()","ff463e60":"train.info()\nprint(\"-\"*40)\nprint(\"\/\"*40)\nprint(\"-\"*40)\ntest.info()","20dc3ed2":"train.describe()","2ed32ac6":"train.describe(include=['O'])","e571ad5d":"train.isnull().sum()","60409f77":"train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","16672b38":"train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","2f41ae6f":"train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","34b815b6":"g = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","5678ee7f":"grid = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","19c4abf7":"grid = sns.FacetGrid(train, col='Embarked')\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","1a2db503":"train = train.drop(['Ticket', 'Cabin'],  axis=1)\ntest = test.drop(['Ticket', 'Cabin'], axis=1)\nmix = [train, test]","2a8c58cc":"print(train.info())\nprint('-'*40)\nprint(test.info())","28a56cb9":"for dataset in mix:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train['Title'], train['Sex'])","d59f6fd5":"for dataset in mix:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","5fb85ba6":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in mix:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain.head()","774616f9":"train = train.drop(['PassengerId', 'Name'], axis=1)\ntest = test.drop(['Name'], axis = 1)\nmix = [train, test]","949b553b":"print(test.shape, test.shape)\nprint('-'*40)\nprint(train.head())\nprint('-'*40)\nprint(test.head())","05acefc4":"for dataset in mix:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain.head()","ecc7f746":"for dataset in mix:\n  dataset['IsAlone'] = 0\n  dataset.loc[dataset['SibSp'] >= 1, 'IsAlone'] = 1\n  dataset.loc[dataset['Parch'] >= 1, 'IsAlone'] = 1\ntrain[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()","6837cf3b":"train = train.drop(['SibSp', 'Parch'], axis = 1)\ntest = test.drop(['SibSp', 'Parch'], axis = 1)\nmix = [train, test]","da3996c3":"print(train.head())\nprint('-'*80)\nprint(test.head())","62348349":"guess_ages = np.zeros((2,3))\nfor dataset in mix:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)","7df74118":"train['AgeBand'] = pd.cut(train['Age'], 5)\ntrain[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","e959ab16":"for dataset in mix:    \n    dataset.loc[ dataset['Age'] <= 16.0, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16.0) & (dataset['Age'] <= 32.0), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32.0) & (dataset['Age'] <= 48.0), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48.0) & (dataset['Age'] <= 64.0), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64.0, 'Age']\ntrain.head()","886d874d":"train = train.drop(['AgeBand'], axis = 1)\nmix = [train, test]\ntrain.head()","4a35f7df":"for dataset in mix:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n    \ntrain[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\nfor dataset in mix:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","e99b452d":"test.isnull().sum()","8b201d0e":"#we replace by the mean\ntest['Fare'].fillna(test['Fare'].dropna().median(), inplace=True)","954d2340":"train['FareBand'] = pd.qcut(train['Fare'], 4)\ntrain[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","a4a178dd":"for dataset in mix:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain = train.drop(['FareBand'], axis=1)\nmix = [train, test]","1bcbc132":"print(train.head())\nprint('-'*80)\nprint(test.head())\nprint(\"Data Ready\")","38adf22e":"X_train = train.iloc[:,1:8].values\ny_train = train.iloc[:,0].values\nX_test  = test.iloc[:, 1:8]\nX_train.shape, y_train.shape, X_test.shape","98a71ef5":"classifier = RandomForestClassifier(n_estimators = 100, max_depth=3, random_state = 2)\nclassifier.fit(X_train, y_train)","1a67eb7b":"y_pred  = classifier.predict(X_test)","69347711":"classifier.score(X_train, y_train)\nscore = round(classifier.score(X_train, y_train) * 100, 2)\nscore","daa73b51":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": y_pred\n    })","a4321058":"submission.head()","02099e1d":"cm = confusion_matrix(sub['Survived'], y_pred)\ncm","ae6be713":"submission.to_csv(r'.\/submission.csv', index=False) ","45f13f81":"this code snippet is not mine, I took it as it gave me error when replacing the NaN of age by the mean of all other ages :(\n\n---\nsince we have the ratios of the ages we can replace them in the intervals that show us","bfaa9c0c":"we fill the NaNs from Embarked and convert them to better operate with them","3ac2c6d7":"## ***Missing data***","4014d243":"Separating the terms from the names we realize that some had a better survival rate than others, so we add it to the model and eliminate the name and id variables since we do not need them","061e5dcb":"*  we must treat the blank fields and the NaN so that they do not affect our model, but first we need to know that they are also related to our variable: Survived, so as not to do too much work.","47bbf5cb":"(1)we combine the two datasets to do operations in conjunction with them.\n\n\n---\nwe analyze the variables that our data set has.\nwe separate the variables that are categorical into numerical, ordinary and discrete.","296e7ceb":"The survival rate of this dataset is 38%, the name is unique as far as we can see, most were traveling with siblings or spouses\n\n\n*   ticket we can eliminate it since it does not contribute to our model and also there are many repetitions.\n*   cabin can be eliminated this very incomplete and repeated, it gives us to understand that the majority went together either with brothers, children or spouses.\n*   it will be better to analyze the variable Name to see if it is related to the survival of people.\n\n\n\n---\nWe will analyze how significant the variables are with respect to survival","3696d816":"*28 November 2020*\n\n\n1.   **Intro.**\n      *   *Importing the data set.* \n2.   **Analysis.**\n      *   *Info dataset* \n      *   *Categorical Data.*\n      *   *dataset treatment* \n      *   *Missing Data.*\n      *   *Dataset Ready*\n3.    **Modeling**","e0efb196":"Survival is also defined by the class they were in, with class = 1 having a better rate than those of more classes","215c1a71":"# Modeling","5e7940b0":"From what has been seen previously, we know that those of ***Sex = (female)*** had a better survival rate than men, those of ***class = (1)*** also had a better index than the others; ***SibSp*** and ***Parch*** have ***0%*** probability for some cases but in other significant values, it would be better to derive them to propose it in the model.","01b0d79c":"We will take the variable \"Embarked\" since we can see a relationship with the survivors, although they are more diverse, for example, in Embarked = C more men of class 1 and 2 survived, otherwise in Embarked = Q.\n\n---\n\nKnowing the above, we will eliminate Ticket and Cabin since they do not help our model, we will also complete the age NAN since it is a fundamental variable for our model.","4c6dc2c4":"# 1. Intro.\n\n\n> This is my first at a kaggle script.After looking at several scripts for     inspiration I decided to star developing this script, I will use graphics      to explain things a little better and I will use Random Forest to create a model predicting survival on the Titanic. I am new to machine learning and hoping to learn a lot, so feedback is very welcome!","26e415aa":"let's change the sex to female = 1, male = 0","e5f1561e":"##  ***dataset treatment***","7f8e5dc0":"# Analysis\nAnalyze and understand the data","517b1f6d":"the probability that a person survived being accompanied (either by siblings, children or spouses)> that they were alone, therefore we classify in a variable those who were alone = \"0\" and the others in \"1\", I will not classify with how many women or lovers they went, I will take as family those who are >= 1","2b40a300":"As can be seen, children had a better survival rate than those between 20 and 30 years old.","52660a02":"*  Categorical:\n\n    > Survived, Sex, Embarked.\n\n*  Ordinal:\n\n    > Pclass\n\n*  Numeric:\n\n    > Age, Fare.\n\n*  Discrete:\n\n    > SibSp, Parch.","384ded36":"*   *Import libraries and Data Set*"}}