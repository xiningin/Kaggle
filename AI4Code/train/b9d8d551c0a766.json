{"cell_type":{"458260b2":"code","81597e13":"code","9de031aa":"code","0add929d":"code","e2f13495":"code","0daf7ea2":"code","f4115297":"code","c9e6cf08":"markdown"},"source":{"458260b2":"import os\nos.makedirs(\"images\", exist_ok=True)\nos.makedirs(\"saved_model\", exist_ok=True)","81597e13":"from __future__ import print_function, division\nfrom keras.datasets import fashion_mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\nfrom keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nclass ACGAN():\n    def __init__(self):\n        # Input shape\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        self.num_classes = 10\n        self.latent_dim = 100\n\n        optimizer = Adam(0.0002, 0.5)\n        losses = ['binary_crossentropy', 'sparse_categorical_crossentropy']\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss=losses,\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build the generator\n        self.generator = self.build_generator()\n\n        # The generator takes noise and the target label as input\n        # and generates the corresponding digit of that label\n        noise = Input(shape=(self.latent_dim,))\n        label = Input(shape=(1,))\n        img = self.generator([noise, label])\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The discriminator takes generated image as input and determines validity\n        # and the label of that image\n        valid, target_label = self.discriminator(img)\n\n        # The combined model  (stacked generator and discriminator)\n        # Trains the generator to fool the discriminator\n        self.combined = Model([noise, label], [valid, target_label])\n        self.combined.compile(loss=losses,\n            optimizer=optimizer)\n\n    def build_generator(self):\n\n        model = Sequential()\n\n        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n        model.add(Reshape((7, 7, 128)))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(UpSampling2D())\n        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(UpSampling2D())\n        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n        model.add(Activation(\"relu\"))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Conv2D(self.channels, kernel_size=3, padding='same'))\n        model.add(Activation(\"tanh\"))\n\n        model.summary()\n\n        noise = Input(shape=(self.latent_dim,))\n        label = Input(shape=(1,), dtype='int32')\n        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n\n        model_input = multiply([noise, label_embedding])\n        img = model(model_input)\n\n        return Model([noise, label], img)\n\n    def build_discriminator(self):\n\n        model = Sequential()\n\n        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.25))\n\n        model.add(Flatten())\n        model.summary()\n\n        img = Input(shape=self.img_shape)\n\n        # Extract feature representation\n        features = model(img)\n\n        # Determine validity and label of the image\n        validity = Dense(1, activation=\"sigmoid\")(features)\n        label = Dense(self.num_classes, activation=\"softmax\")(features)\n\n        return Model(img, [validity, label])\n\n    def train(self, epochs, batch_size=128, sample_interval=50):\n\n        # Load the dataset\n        (X_train, y_train), (_, _) = fashion_mnist.load_data()\n\n        # Configure inputs\n        X_train = (X_train.astype(np.float32) - 127.5) \/ 127.5\n        X_train = np.expand_dims(X_train, axis=3)\n        y_train = y_train.reshape(-1, 1)\n\n        # Adversarial ground truths\n        valid = np.ones((batch_size, 1))\n        fake = np.zeros((batch_size, 1))\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random batch of images\n            idx = np.random.randint(0, X_train.shape[0], batch_size)\n            imgs = X_train[idx]\n\n            # Sample noise as generator input\n            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n\n            # The labels of the digits that the generator tries to create an\n            # image representation of\n            sampled_labels = np.random.randint(0, 10, (batch_size, 1))\n\n            # Generate a half batch of new images\n            gen_imgs = self.generator.predict([noise, sampled_labels])\n\n            # Image labels. 0-9 \n            img_labels = y_train[idx]\n\n            # Train the discriminator\n            d_loss_real = self.discriminator.train_on_batch(imgs, [valid, img_labels])\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, [fake, sampled_labels])\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            # Train the generator\n            g_loss = self.combined.train_on_batch([noise, sampled_labels], [valid, sampled_labels])\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0]))\n\n            # If at save interval => save generated image samples\n            if epoch % sample_interval == 0:\n                self.save_model()\n                self.sample_images(epoch)\n\n    def sample_images(self, epoch):\n        r, c = 10, 10\n        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n        sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n        gen_imgs = self.generator.predict([noise, sampled_labels])\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n                axs[i,j].axis('off')\n                cnt += 1\n        fig.savefig(\"images\/%d.png\" % epoch)\n        plt.close()\n\n    def save_model(self):\n\n        def save(model, model_name):\n            model_path = \"saved_model\/%s.json\" % model_name\n            weights_path = \"saved_model\/%s_weights.hdf5\" % model_name\n            options = {\"file_arch\": model_path,\n                        \"file_weight\": weights_path}\n            json_string = model.to_json()\n            open(options['file_arch'], 'w').write(json_string)\n            model.save_weights(options['file_weight'])\n\n        save(self.generator, \"generator\")\n        save(self.discriminator, \"discriminator\")\n\n\nif __name__ == '__main__':\n    acgan = ACGAN()\n    acgan.train(epochs=10000, batch_size=32, sample_interval=100)","9de031aa":"from matplotlib import animation, rc\nrc('animation', html='jshtml')\nfrom tqdm import tqdm\nimport glob\nimport os\nimport cv2","0add929d":"data_dir='\/kaggle\/working\/images'","e2f13495":"def load_png_line(path):\n    t_paths = sorted(\n        glob.glob(os.path.join(path,\"*\")), \n        key=lambda x: x,\n    )\n    images = []\n    for filename in tqdm(np.array(t_paths)):\n        data = cv2.imread(filename)\n        if data.max() == 0:\n            continue\n        images.append(data)\n        \n    return images\n\n\ndef load_png_line(path):\n    t_paths = sorted(\n        glob.glob(os.path.join(path,\"*\")), \n        key=lambda x: x,\n    )\n    images = []\n    for filename in tqdm(np.array(t_paths)):\n        data = cv2.imread(filename)\n        if data.max() == 0:\n            continue\n        images.append(data)\n        \n    return images\n\n\ndef create_animation(ims):\n    fig=plt.figure(figsize=(12,12))\n    plt.axis('off')\n    im=plt.imshow(cv2.cvtColor(ims[0],cv2.COLOR_BGR2RGB))\n    \n    def animate_func(i):\n        im.set_array(cv2.cvtColor(ims[i],cv2.COLOR_BGR2RGB))\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames=len(ims), interval=1000\/\/2)","0daf7ea2":"images = load_png_line(data_dir)","f4115297":"create_animation(images)","c9e6cf08":"# Fashion MNIST Keras Auxiliary Classifier GAN Sample\nThis notebook referred to the following scripts.<\/br>\nhttps:\/\/github.com\/eriklindernoren\/Keras-GAN\/blob\/master\/acgan\/acgan.py"}}