{"cell_type":{"791fb5fc":"code","defb1d54":"code","b2525371":"code","3b3942e9":"code","71f7532b":"code","4de618c9":"code","e3dca5b5":"code","d044bd4c":"code","c0cb39d9":"code","dca42b8b":"code","d52c905a":"code","0d43bb3c":"code","87e953f1":"code","050cc266":"markdown","c57767ab":"markdown","c248a2f5":"markdown","4fca3d33":"markdown","a9299f67":"markdown"},"source":{"791fb5fc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","defb1d54":"data = pd.read_csv('..\/input\/ebay-reviews\/ebay_reviews.csv')","b2525371":"import warnings\nwarnings.simplefilter(action='ignore', category=UserWarning)","3b3942e9":"class DuplicatesRemover(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to remove duplicated rows.\n    \"\"\"\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X2 = X.copy()\n        #indexes of duplicated reviews\n        duplicated_idx = X2.duplicated()\n        X2 = X2[~duplicated_idx].dropna()\n        return X2.set_index(np.arange(X2.shape[0]))","71f7532b":"class ForeignReviewsRemover(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to remove non-english reviews.\n    If no word from the common-english-wordslist is found in a review\/title the row is treated as nonenglish\n    \n    see_dismissed - if True non-english rows are displayed\n    \"\"\"\n  \n    def __init__(self, see_dismissed=False):\n        #built-in stopwords\n        words = stopwords.words('english')\n        #these words are kept because they can be useful in sentiment analysis\n        additional_words = ['good','beautiful', 'great','best','well','work','working','excellent','price','nice','handy','bad','terrible','worse','worst','broken','no','useless', 'ok','yes','fine','ok','awesome','awful', 'low', 'high', 'cool']\n        #additional words that are not defined in built-in stopwords\n        words_to_remove={'i','me','a','d','o','y','s','t','don','ma'}\n        words.extend(additional_words)\n        self.words = list(set(words).difference(words_to_remove))\n        self.see_dismissed = see_dismissed\n\n    def fit(self, X, y=None, user_words=[]):\n        self.words.extend(user_words)\n        #pattern for removing stop words\n        self.pattern = \" | \".join(self.words) + \"| \".join(self.words) + \" |\".join(self.words)\n        return self\n\n    def transform(self, X):\n        X2 = X.copy()\n        \n        X_temp = pd.DataFrame()\n        cols_to_join = []\n\n        for col in X2.columns:\n            if not X2.loc[:, col].dtypes == int:\n                cols_to_join.append(col)\n                \n        X_temp['connected'] = X2[cols_to_join].astype(str).agg(' '.join, axis=1)\n        #using the defined pattern in fit function\n        idx = np.where(X_temp['connected'].str.contains(self.pattern, case=False, regex=True).values == True, True, False)\n        \n        if self.see_dismissed == True:\n            for row in X2['connected'][~idx]:\n                print(row)\n        return X2[idx]","4de618c9":"class TextCleaning(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to remove punctation and multiple spaces from text and change uppercase letters to lowercase.\n    \"\"\"\n    def __init__(self, pattern=\"[!\\\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_`{|}~]\"):\n        self.pattern = pattern\n    \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X2 = X.copy()\n        X2.replace({\"\\s\\s+\":\" \"}, regex=False, inplace=True)\n        \n        for col in X2.columns:\n            if X2.loc[:, col].dtypes == int: continue\n            X2.loc[:, col] = X2.loc[:, col].str.replace(self.pattern, \"\", regex=True).str.lower()\n        return X2","e3dca5b5":"class StopWordsRemover(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to remove popular english words with some default exceptions. User can add his own words to keep.\n    \"\"\"\n    \n    def __init__(self, words_to_keep=['few','not', 'off','all','any','not','no','very']):\n        stop_words = set(stopwords.words('english'))    \n        self.eng_words = stop_words.difference(set(words_to_keep))\n         \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X2 = X.copy()\n        \n        for col in X2.columns:\n            if X2.loc[:, col].dtypes == int: continue\n            for en, review in enumerate(X2.loc[:, col].astype(str)):\n                new = (\" \").join(j for j in review.split(\" \") if j.lower() not in self.eng_words)\n                try:\n                    X2.loc[:, col].iloc[en] = new\n                except:\n                    continue\n        return X2","d044bd4c":"class Stemmer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to stemm words.\n    stem - if False the words are not stemmed (for experimental reasons)\n    \"\"\"\n    \n    def __init__(self, stem=True):\n        self.stemmer = nltk.PorterStemmer()\n        self.stem = stem\n    \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        if self.stem == False:\n            return X\n        else:\n            X2 = X.copy()  \n            for col in X2.columns:\n                if X2.loc[:, col].dtypes == int: continue\n                for en, review in enumerate(X2.loc[:, col].astype(str)):\n                    new = (\" \").join(self.stemmer.stem(j) for j in review.split(\" \"))\n                    try:\n                        X2[:, col].iloc[en] = new\n                    except:\n                        continue\n            return X2","c0cb39d9":"class Rating(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to change reviews ratings numbers\n    labels_to_del - a list of reviews rating to remove (the assumption is that only ratings with 3 starts will be removed)\n    \"\"\"\n    def __init__(self, scale={1:1, 2:1, 3:0, 4:0, 5:0}, labels_to_del=[]):\n        self.scale = scale\n        self.labels_to_del = labels_to_del\n    \n    def fit(self, X, y=None):\n        if self.labels_to_del != []:\n            self.idx_to_del = X['rating'] == self.labels_to_del[0]\n        return self\n\n    def transform(self, X):    \n        X2 = X.copy()\n        if self.labels_to_del:\n            X2 = X2[~self.idx_to_del]\n        X2.replace(self.scale, inplace=True)\n        return X2","dca42b8b":"class Connector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to connect columns in one column.\n    \"\"\"\n        \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X2 = X.copy()\n        X3 = pd.DataFrame()\n        cols_to_join = []\n        for col in X2.columns:\n            if X2.loc[:, col].dtypes == int:\n                X3['rating'] = X2.loc[:, col]     \n            else:\n                cols_to_join.append(col)\n                \n        X3['review'] = X2[cols_to_join].astype(str).agg(' '.join, axis=1)\n        return X3","d52c905a":"#transformers for classic machine learning approach\n\n#columns that are going to be transformed\ncols = ['review title', 'review content', 'rating']\n\n#pipeline\npreprocessor = Pipeline([\n    #at first duplicated reviews will be removed\n    ('DuplicateRemover', DuplicatesRemover()),\n    #next nonenglish reviews will be removed\n    ('ForeignReviewsRemover',ForeignReviewsRemover()),\n    #symbols that will be removed are defined in the transformer but a user can define his own\/some additional symbols\n    ('TextCleaning',TextCleaning()),\n    #removing popular english words\n    ('StopWordsRemover',StopWordsRemover()),\n    #if stem is False the words will not be stemmed\n    ('Stemmer', Stemmer(stem=False)),\n    #connecting text columns to one column (this is only for machine learning process, it is not necessary for data analysis)\n    #('Connector', Connector()),\n    #rating changer, in this example negative(1, 2) ratings are equal to -1, neutral (3) 0 and positive(4,5) 1\n    ('Rating', Rating(scale={1:-1, 2:-1, 3:0, 4:1, 5:1})),\n    #the autor noticed that after cleaning the reviews some duplicated reviews are left, one more time duplicateremover is used (we could use it only one time, but it would make the process of data cleaning longer)\n    ('DuplicateRemover2', DuplicatesRemover())\n])","0d43bb3c":"#cleaned reviews are available after running this cell (note: it may take a while)\npreprocessor.fit(data[cols])\ndata_preprocessed = preprocessor.transform(data[cols])","87e953f1":"data_preprocessed.head(20)","050cc266":"# This notebook contains user-defined transformers for adjusting the reviews for nlp modelling. The following classes for data transformation are defined:\n - class for removing duplicated reviews\n - class for removing nonenglish reviews\n - class for text cleaning (user defined symbols like commas, points, colons etc. are removed)\n - class for removing stop words (common english words which do not contribute to review sentiment, e.g. the, a, I, we, them etc.)\n - class for stemming (process of reducing inflected (or sometimes derived) words to their word stem, e.g. words like big, bigger, biggest are represented by word 'big')\n - class for changing ratings (the reviews can have five ratings in total whereas sentiments can be of three kind)","c57767ab":"### Transformers","c248a2f5":"### All comments and questions are welcome","4fca3d33":"### Loading the dataset","a9299f67":"### How to make use of user-defined transformers? We will use a pipeline\n### Note: the pipeline in the following cell is defined for classic machine learning approach (support vector machine, logistic regression etc.). Please keep in mind that for neural networks commas, dots and other symbols may have some influence on model accuracy "}}