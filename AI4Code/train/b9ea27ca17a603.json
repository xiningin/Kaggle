{"cell_type":{"7cb687bf":"code","4a853814":"code","53b297c1":"code","1ea4f459":"code","95f8ef20":"code","0344f721":"code","d934d4d9":"code","f9d11921":"code","8f9f18bb":"code","d0aeb4c8":"code","d2e24de6":"code","09f77452":"code","4e27adc2":"code","81d2c65d":"code","95384ba0":"code","1bdec86a":"code","79692e12":"code","ee9bb0ac":"code","6f6ba1dc":"code","da0636c7":"code","4159cf8f":"code","cd7b801a":"code","32b7059a":"code","5cf4dd93":"code","69740f91":"code","3332350d":"markdown","3789c05b":"markdown","e53db56b":"markdown"},"source":{"7cb687bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4a853814":"import tensorflow as tf\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport sklearn.metrics as metric\nimport warnings\nfrom sklearn.utils import shuffle\nwarnings.filterwarnings(\"ignore\")\nplt.style.use('ggplot')\n%matplotlib inline ","53b297c1":"#Checking for gpu device\ntf.config.experimental.list_physical_devices()","1ea4f459":"parent_dir = '\/kaggle\/input\/vegetable-image-dataset\/Vegetable Images'\ntrain_dir = os.path.join(parent_dir, 'train')\ntest_dir = os.path.join(parent_dir, 'test')\nvalid_dir = os.path.join(parent_dir, 'validation')","95f8ef20":"#Directories of images\ntrain_dirs = os.listdir(train_dir)\nprint(f'Folder count in train_dirs - {len(train_dirs)}')\ntest_dirs = os.listdir(test_dir)\nprint(f'Folder count in test_dirs - {len(test_dirs)}')\nvalid_dirs = os.listdir(valid_dir)\nprint(f'Folder count in valid_dirs - {len(valid_dirs)}')","0344f721":"#15 different types of vegetables\nos.listdir(train_dir)","d934d4d9":"def imagesLabels(dirs,dir_):\n    image_path = []\n    label = []\n    for di in dirs:\n        for path in os.listdir(dir_+'\/'+di):\n            image_path.append(dir_+'\/'+di+'\/'+path)\n            label.append(di)\n    return image_path, label","f9d11921":"train_Im, train_Lb = imagesLabels(train_dirs,train_dir)\ntest_Im, test_Lb = imagesLabels(test_dirs,test_dir)\nval_Im, val_Lb = imagesLabels(valid_dirs,valid_dir)","8f9f18bb":"train_df = pd.DataFrame(list(zip(train_Im, train_Lb)),columns = ['Filepath', 'Labels'])\ntrain_df.head()","d0aeb4c8":"val_df = pd.DataFrame(list(zip(val_Im, val_Lb)),columns = ['Filepath', 'Labels'])\ntest_df = pd.DataFrame(list(zip(test_Im, test_Lb)),columns = ['Filepath', 'Labels'])","d2e24de6":"veg_list = list(train_df['Labels'].unique())\nveg_dict = dict(zip(veg_list,range(len(veg_list))))","09f77452":"def shuffle_label(df):\n    \"\"\"\n    Function to shuffle and replace categories with numbers\n    \"\"\"\n    #df['Labels'] = df['Labels'].replace(veg_dict)\n    df = shuffle(df)\n    df.reset_index(inplace=True)\n    df.drop('index',axis=1,inplace=True)\n    return df","4e27adc2":"train_df = shuffle_label(train_df)\nval_df = shuffle_label(val_df)\ntest_df = shuffle_label(test_df)","81d2c65d":"f,a = plt.subplots(nrows=3, ncols=3,subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(a.flat):\n    ax.imshow(plt.imread(train_df.Filepath[i]))\n    ax.set_title(train_df.Labels[i])\n    #ax.set_title(list(veg_dict.keys())[list(veg_dict.values()).index(train_df.Labels[i])])\n    \nplt.tight_layout()\nplt.show()","95384ba0":"train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255, \n                                   rotation_range=30, \n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2, \n                                   horizontal_flip = 'true')\nval_test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)","1bdec86a":"x_train =  train_gen.flow_from_dataframe(dataframe = train_df,  x_col='Filepath', y_col='Labels',target_size=(224, 224))\nx_val =  val_test_gen.flow_from_dataframe(dataframe = val_df,  x_col='Filepath', y_col='Labels',target_size=(224, 224))\nx_test =  val_test_gen.flow_from_dataframe(dataframe = test_df,  x_col='Filepath', y_col='Labels',target_size=(224, 224))","79692e12":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(224, 224, 3)))\nmodel.add(tf.keras.layers.MaxPooling2D((2,2)))\nmodel.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(tf.keras.layers.MaxPooling2D((2,2)))\nmodel.add(tf.keras.layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dense(15,activation='softmax'))\n    \nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","ee9bb0ac":"# Defining and early stopping criteria to avoid overfitting. If for 2 epochs the val loss increases then model stops training.\nearly_stopping = tf.keras.callbacks.EarlyStopping(patience = 2)","6f6ba1dc":"model.summary()","da0636c7":"network = model.fit(x_train,\n                    epochs=10,\n                    steps_per_epoch = 200,\n                    validation_data=x_val,\n                    callbacks = [early_stopping])","4159cf8f":"test_loss,test_acc = model.evaluate(x_test)","cd7b801a":"print(f\"The accuracy for testing is {round(test_acc,2) * 100} % \")","32b7059a":"plt.figure(figsize=(12,6))\nplt.plot(network.history['loss'],label = 'Training')\nplt.plot(network.history['val_loss'],label = 'Validation')\nplt.legend(loc='best',fontsize=12)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\");","5cf4dd93":"plt.figure(figsize=(12,6))\nplt.plot(network.history['accuracy'],label = 'Training')\nplt.plot(network.history['val_accuracy'],label = 'Validation')\nplt.legend(loc='best',fontsize=12)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\");","69740f91":"# Saving our model\nmodel.save(\"veg_classifier_model.h5\")","3332350d":"## This model is giving us 84.0 % test accuracy. It is performing quite good. \n## As there is no class imbalance so high accuracy can be a good metric.","3789c05b":"### Image generator to augment training images and just rescale test and validation images","e53db56b":"### Plotting the first 9 vegetable images"}}