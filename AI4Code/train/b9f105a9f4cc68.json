{"cell_type":{"27893b71":"code","899d918d":"code","156e1d2c":"code","1df05cc0":"code","65b923cd":"code","07162841":"code","18195849":"code","508a7fec":"code","0c8a02a2":"code","1bccd731":"code","f3b7325b":"code","435b685e":"code","b7ddda51":"code","77962bfc":"code","26fa2c2d":"code","df753fa0":"code","c43ca722":"code","e059c7b8":"code","993b3653":"code","02e692e8":"code","ea1ad43f":"code","c5297e46":"code","10b8eb1b":"code","aed2f799":"code","2ffabdb8":"code","83e7a572":"code","a237959f":"code","3a194412":"markdown","132806fe":"markdown","b1f93312":"markdown","bec5012f":"markdown","60745585":"markdown","ecedb475":"markdown","ed877303":"markdown","15116100":"markdown","8892b8f0":"markdown","55fe15bf":"markdown","2694b5f7":"markdown","035a0d87":"markdown","342cc629":"markdown","784baae9":"markdown","08239fb9":"markdown","49832d56":"markdown","346c70b4":"markdown","ba5910f1":"markdown","17458dfc":"markdown","b682da45":"markdown","1e9b598c":"markdown","5534f804":"markdown","33742d94":"markdown","1c989b33":"markdown","0fc2db88":"markdown","a0d3bfe0":"markdown","2b366ea9":"markdown","2022bdb8":"markdown","5d3f2ae7":"markdown","dbeb6249":"markdown","794a3260":"markdown","eea4cc63":"markdown","f9296528":"markdown","5edf957a":"markdown","898cf358":"markdown","4c114062":"markdown","5a6d6538":"markdown","2e70760e":"markdown","b00f8623":"markdown","5a041a09":"markdown"},"source":{"27893b71":"# importanto as bibliotecas b\u00e1scias\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mtick\nimport seaborn as sns\n\n# obtendo cores do padr\u00e3o Tableau\nimport matplotlib.colors as mcolors\n\n# imoportando as bibliotecas de ML\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\n\n# importanto os modelos de ML\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom xgboost import XGBClassifier","899d918d":"# importando os dados\ntreino = pd.read_csv('..\/input\/titanic\/train.csv')\nteste = pd.read_csv('..\/input\/titanic\/test.csv')\n\n# definindo seed para reprodu\u00e7\u00e3o dos mesmos resultados\nseed = 10\n\n# definindo os temas dos gr\u00e1ficos\ncustom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\nsns.set_theme(style=\"ticks\", rc=custom_params)","156e1d2c":"# avaliando os dados de treino\ntreino.head()","1df05cc0":"# avaliando os dados de teste\nteste.head()","65b923cd":"# verificando os tipos de dados armazenados\ntreino.info()\nprint('\\n','-'*50,'\\n')\nteste.info()","07162841":"# verificando valores nulos\nprint('Dados de treino:\\n')\nprint(treino.isnull().sum().sort_values(ascending = False))\nprint('\\n','-'*30,'\\n')\nprint('Dados de teste:\\n')\nprint(teste.isnull().sum().sort_values(ascending = False))","18195849":"# verificando a propor\u00e7\u00e3o entre classes\ntreino.groupby('Survived').size()","508a7fec":"# verificando as vari\u00e1veis num\u00e9ricas\ntreino.describe()","0c8a02a2":"# verificando as vari\u00e1veis categ\u00f3ricas\ntreino.describe(include =['O'])","1bccd731":"# verificando a correla\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas\nfig, ax = plt.subplots(figsize = (7,7))\nax = sns.heatmap(treino.corr(), annot=True, linewidths=0.5, vmax = 1, vmin = -1, center = 0)","f3b7325b":"# quantidade de sobreviventes por classe de cabine:\nfig2, ax2 = plt.subplots(constrained_layout=True)\ntreino2 = treino[['Pclass', 'Survived']].groupby('Pclass', as_index=False).sum()\ntreino2['Quantidade'] = treino[['Pclass', 'Survived']].groupby('Pclass').count().values\ntreino2['%Survived'] = treino2['Survived']\/treino2['Quantidade']*100\nprint(treino2)\nsns.barplot(data=treino2, x='Pclass', y='%Survived', alpha=0.8, ax=ax2)\nax2.yaxis.set_major_formatter(mtick.PercentFormatter())\nax2.bar_label(ax2.containers[0], fmt='%d%%')\nax2.set_title(\"Propor\u00e7\u00e3o de sobreviventes por Classe\\n\", size=15)","435b685e":"# quantidade de sobreviventes por sexo:\nfig3, ax3 = plt.subplots(constrained_layout=True)\ntreino3 = treino[['Sex', 'Survived']].groupby('Sex', as_index=False).sum()\ntreino3['Quantidade'] = treino[['Sex', 'Survived']].groupby('Sex').count().values\ntreino3['%Survived'] = treino3['Survived']\/treino3['Quantidade']*100\nprint(treino3)\nsns.barplot(data=treino3, x='Sex', y='%Survived', alpha=0.8, ax=ax3)\nax3.yaxis.set_major_formatter(mtick.PercentFormatter())\nax3.bar_label(ax3.containers[0], fmt='%d%%')\nax3.set_title(\"Propor\u00e7\u00e3o de sobreviventes por Sexo\\n\", size=15)","b7ddda51":"# quantidade de sobreviventes por idade:\nfig5, ax5 = plt.subplots(figsize=(17,5), constrained_layout=True)\ntreino4 = treino.copy()\ntreino4['AgeBand'] = pd.cut(treino['Age'],10)\ntreino5 = treino4[['AgeBand', 'Survived']].groupby('AgeBand', as_index=False).sum()\ntreino5['Quantidade'] = treino4[['AgeBand', 'Survived']].groupby('AgeBand').count().values\ntreino5['%Survived'] = treino5['Survived']\/treino5['Quantidade']*100\nprint(treino5)\nsns.barplot(data=treino5, x='AgeBand', y='%Survived', alpha=0.8, ax=ax5)\nax5.yaxis.set_major_formatter(mtick.PercentFormatter())\nax5.bar_label(ax5.containers[0], fmt='%d%%')\nax5.set_title(\"Propor\u00e7\u00e3o de sobreviventes por faixa de Idade\\n\", size=20)","77962bfc":"# quantidade de sobreviventes por SibSp:\nfig6, ax6 = plt.subplots(constrained_layout=True)\ntreino6 = treino[['SibSp', 'Survived']].groupby('SibSp', as_index=False).sum()\ntreino6['Quantidade'] = treino[['SibSp', 'Survived']].groupby('SibSp').count().values\ntreino6['%Survived'] = treino6['Survived']\/treino6['Quantidade']*100\nprint(treino6)\nsns.barplot(data=treino6, x='SibSp', y='%Survived', alpha=0.8, ax=ax6)\nax6.yaxis.set_major_formatter(mtick.PercentFormatter())\nax6.bar_label(ax6.containers[0], fmt='%d%%')\nax6.set_title(\"Propor\u00e7\u00e3o de sobreviventes por SibSp\\n\", size=15)","26fa2c2d":"# quantidade de sobreviventes por Parch:\nfig7, ax7 = plt.subplots(constrained_layout=True)\ntreino7 = treino[['Parch', 'Survived']].groupby('Parch', as_index=False).sum()\ntreino7['Quantidade'] = treino[['Parch', 'Survived']].groupby('Parch').count().values\ntreino7['%Survived'] = treino7['Survived']\/treino7['Quantidade']*100\nprint(treino7)\nsns.barplot(data=treino7, x='Parch', y='%Survived', alpha=0.8, ax=ax7)\nax7.yaxis.set_major_formatter(mtick.PercentFormatter())\nax7.bar_label(ax7.containers[0], fmt='%d%%')\nax7.set_title(\"Propor\u00e7\u00e3o de sobreviventes por Parch\\n\", size=15)","df753fa0":"# quantidade de sobreviventes por embarque:\nfig8, ax8 = plt.subplots(constrained_layout=True)\ntreino8 = treino[['Embarked', 'Survived']].groupby('Embarked', as_index=False).sum()\ntreino8['Quantidade'] = treino[['Embarked', 'Survived']].groupby('Embarked').count().values\ntreino8['%Survived'] = treino8['Survived']\/treino8['Quantidade']*100\nprint(treino8)\nsns.barplot(data=treino8, x='Embarked', y='%Survived', alpha=0.8, ax=ax8)\nax8.yaxis.set_major_formatter(mtick.PercentFormatter())\nax8.bar_label(ax8.containers[0], fmt='%d%%')\nax8.set_title(\"Propor\u00e7\u00e3o de sobreviventes por Embarque\\n\", size=15)","c43ca722":"# avaliando a distribui\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas de forma geral\nvariaveis_num = ['Age', 'SibSp', 'Parch', 'Fare']\nfig9, ax9 = plt.subplots(nrows = 2, ncols = 2, figsize = (10,7), constrained_layout=True)\nfor variavel,axes, color in zip(variaveis_num, ax9.flat, mcolors.TABLEAU_COLORS.keys()):\n    sns.kdeplot(x=treino[variavel], ax=axes, fill=True, color=color)","e059c7b8":"# elimando as colunas que n\u00e3o ajudar\u00e3o na predi\u00e7\u00e3o\ntreino.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], inplace = True, axis = 1)\n#salvando um backup de teste antes\nteste_inicial = teste.copy()\nteste.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], inplace = True, axis = 1)\ntreino.head()","993b3653":"# passando a vari\u00e1vel target para a \u00faltima coluna (melhorando a visualiza\u00e7\u00e3o)\ntreino = treino[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n       'Fare', 'Embarked', 'Survived']]\nteste = teste[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n       'Fare', 'Embarked']]\ntreino.head()","02e692e8":"# separa\u00e7\u00e3o das vari\u00e1veis independentes e vari\u00e1vel target\nX = treino.iloc[:,:-1]\ny = treino.iloc[:,-1]\nprint(X.head(),'\\n\\n')\nprint(y.head())","ea1ad43f":"# cria\u00e7\u00e3o dos pipelines\nnum_transform = make_pipeline(SimpleImputer(strategy = 'median'), MinMaxScaler(), StandardScaler())\ncat_transform = make_pipeline(SimpleImputer(strategy = 'most_frequent'), OneHotEncoder())\n\n# cria\u00e7\u00e3o do processador unificado para as diferentes colunas\nct = ColumnTransformer(transformers = [('num_transform', num_transform, ['Age', 'SibSp', 'Parch', 'Fare']),\n                                      ('cat_transform', cat_transform, ['Pclass', 'Sex', 'Embarked'])])","c5297e46":"# cria\u00e7\u00e3o do pipeline unificado e final\n#modelo_base = make_pipeline(ct, XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n\n# cria\u00e7\u00e3o de kfolds (usando o shuffle para alterar a ordem dos dados)\nkfold = KFold(n_splits=10, random_state=seed, shuffle=True)\n\n# defini\u00e7\u00e3o dos modelos que ser\u00e3o iterados para escolha\nmodelos = {'LRE': LogisticRegression(),\n           'LDA': LinearDiscriminantAnalysis(),\n           'GNB': GaussianNB(),\n           'KNN': KNeighborsClassifier(),\n           'SVC': SVC(),\n           'DTC': DecisionTreeClassifier(),\n           'RFC': RandomForestClassifier(),\n           'ADB': AdaBoostClassifier(),\n           'XGB': XGBClassifier(use_label_encoder=False, eval_metric='logloss')}\n\n# cria\u00e7\u00e3o do loop de verifica\u00e7\u00e3o\nscores = []\nfor nome, modelo in modelos.items(): \n    modelo_teste = make_pipeline(ct,modelo)\n    score = cross_val_score(modelo_teste, X, y, cv=kfold)\n    scores.append(score)\n    print('Modelo: %s | M\u00e9dia: %.3f | Desvio Padr\u00e3o: %.2f | Mediana: %.3f' %(nome, score.mean(), score.std(), np.median(score)))","10b8eb1b":"# cria\u00e7\u00e3o do daframe e gr\u00e1fico boxplot\ndf = pd.DataFrame(dict(zip(modelos.keys(), scores)))\nfig10, ax10 = plt.subplots(figsize=(10,5),constrained_layout=True )\nsns.boxplot(data=df, ax=ax10)\nsns.swarmplot(data=df, color=\".25\", ax=ax10)","aed2f799":"# cria\u00e7\u00e3o do teste de vari\u00e1veis para o RandomForest (usando o GridSearchCV de forma simples)\nmodelo_escolhido = make_pipeline(ct, RandomForestClassifier(random_state=seed))\n\nparametros = {'randomforestclassifier__criterion': ['gini', 'entropy'],\n              'randomforestclassifier__max_depth': range(1,11)}\n\nmodelo = GridSearchCV(estimator = modelo_escolhido, param_grid = parametros, cv = kfold)\n\n# ajustando o modelo aos dados de treino\nmodelo.fit(X,y)\nmodelo.best_estimator_","2ffabdb8":"# verificando a acur\u00e1cia do modelo em rela\u00e7\u00e3o aos dados de treino\nprint('A acur\u00e1cia do modelo \u00e9: %.2f%%' % (modelo.score(X,y) *100))","83e7a572":"# colando os dados de teste em uma vari\u00e1vel para melhorar a compreens\u00e3o\nX_teste = teste.copy()\n\nX_teste.head()\n\n# prevendo os resultados\ny_teste = modelo.predict(X_teste)","a237959f":"## Colocando no formato final de envio e salvando em um arquivo\n\ndf_final = pd.DataFrame({'PassengerId': teste_inicial['PassengerId'], 'Survived': y_teste})\nprint(df_final.head()) #confer\u00eancia no formato final\ndf_final.to_csv('\/kaggle\/working\/submission.csv', index = False)","3a194412":"## An\u00e1lises Gr\u00e1ficas","132806fe":"### Sobreviventes por Classe de Cabine","b1f93312":"Por meio desse trecho de c\u00f3digo podemos percerber que os **dados de treino** possuem **891 indiv\u00edduos** enquanto os **dados de teste** possuem **418 indiv\u00edduos**.\n\nAl\u00e9m disso, \u00e9 poss\u00edvel perceber que existem **dados faltantes** tanto em **vari\u00e1veis categ\u00f3ricas** como nas **vari\u00e1veis num\u00e9ricas** (vai requerer que apliquemos t\u00e9cnicas diferentes para preenchimento desses valores). **A vari\u00e1vel target n\u00e3o possui valores faltantes**.","bec5012f":"## Cria\u00e7\u00e3o das Pipelines\n\nPara as vari\u00e1veis num\u00e9ricas ser\u00e3o utilizados m\u00e9todos de transforma\u00e7\u00e3o para preencher os valores faltantes e ao mesmo tempo normaliz\u00e1-los e padroniz\u00e1-los.\n\nJ\u00e1 para as vari\u00e1veis categ\u00f3ricas ser\u00e3o criadas transforma\u00e7\u00e3o para preencher valores faltantes e coloc\u00e1-las em formato num\u00e9rico codificado para melhorar o aprendizado dos algoritmos.","60745585":"Percebe-se que proporcionalmente os passageiros **com poucos parentes\/filhos** s\u00e3o os com **maior chance de sobreviv\u00eancia.** Um pouco diferente da vari\u00e1vel SibSp, possilvemente os pais foram salvos com os filhos e os filhos com os pais (no caso de poucos filhos).","ecedb475":"# Melhorias para revis\u00f5es futuras\n\n1. Criar uma fun\u00e7\u00e3o para cria\u00e7\u00e3o dos gr\u00e1ficas e evitar a repeti\u00e7\u00e3o do c\u00f3digo (melhorar legibilidade do c\u00f3digo);\n2. Criar uma vari\u00e1vel relacionada aos nomes que possa ajudar na avalia\u00e7\u00e3o;\n3. Parch e SibSp s\u00e3o vari\u00e1veis de correla\u00e7\u00e3o baixa, talvez seja melhor junt\u00e1-las e criar uma nova vari\u00e1vel mais interessante;\n4. Explorar mais o modelo de RandomForest (hyperparameters tuning) e entender mais sobre a \u00e1rvore gerada.","ed877303":"# Refer\u00eancias\n\n1. Um c\u00f3digo bem explicado e com v\u00e1rias t\u00e9cnicas aplicadas: https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n2. Um guia bem bacana sobre pipelines: https:\/\/medium.com\/data-hackers\/como-usar-pipelines-no-scikit-learn-1398a4cc6ae9\n3. Um Cheat Sheet iterativo do Scikit Learning muito bom: https:\/\/scikit-learn.org\/stable\/tutorial\/machine_learning_map\/index.html\n4. Muitas das t\u00e9cnicas aprendi no curso da DSA: https:\/\/www.datascienceacademy.com.br\/course\/analise-de-dados-com-python","15116100":"# 5) Previs\u00e3o dos resultados","8892b8f0":"### Sobreviventes por Idade","55fe15bf":"Por meio dessa descri\u00e7\u00e3o podemos avaliar que:\n\n* **Name**: todas as pessoas tem seus nomes preenchidos;\n* **Sex**: a maioria dos passageiros era do sexo masculino;\n* **Ticket** e **Cabin**: possuem uma quantidade alta de valores faltantes e\/ou repetidos;\n* **Embarked**: a maioria das pessoas embarcou no porto \"S\" (Southampton).","2694b5f7":"Os dados possuem distribui\u00e7\u00e3o exponencial em sua maioria e portanto devem ser normalizados e padronizados para se adequarem melhor ao modelo de Machine Learning.\n\n***\u00c9 poss\u00edvel ainda fazer muito mais an\u00e1lises correlacionais entre as vari\u00e1veis. Elas poder\u00e3o surgir de acordo com a necessidade da modelagem e acur\u00e1cia necess\u00e1ria.***","035a0d87":"### Sobreviventes por quantidade de irm\u00e3os e marido\/esposa","342cc629":"As informa\u00e7\u00f5es coletadas e o boxplot evidenciam que os **modelos mais acertivos e est\u00e1veis** entre os testados s\u00e3o o **RandomForestClassifier** e o **XGBClassifier** (o queredinho do Kaggle). **O RFC \u00e9 mais est\u00e1vel** que o XGB j\u00e1 que possui **menor desvio padr\u00e3o e range**. Portanto, **o modelo escolhido \u00e9 o RandomForestClassifier**.","784baae9":"## Defini\u00e7\u00e3o dos par\u00e2metros do modelo final (usando crossvalidation)","08239fb9":"\u00c9 interessante saber a propor\u00e7\u00e3o entre as classes, j\u00e1 que classes muito desbalanceadas podem levar a aprendizados tamb\u00e9m desbalanceados. Ou seja, o algoritmo vai aprender mais sobre uma classe do que da outra, prejudicando a acur\u00e1cia do modelo.\n\nNesse caso, temos um balan\u00e7o razo\u00e1vel (geralmente at\u00e9 a propor\u00e7\u00e3o de 1 para 5) entre as classes e n\u00e3o ser\u00e1 necess\u00e1rio aplicar oversampling ou undersampling.","49832d56":"Percebe-se que proporcionalmente os passageiros da **primeira classe** s\u00e3o os com maior chance de sobreviv\u00eancia.","346c70b4":"### Sobreviventes por Sexo:","ba5910f1":"Percebe-se que proporcionalmente os passageiros **mais jovens** e **mais velhos** s\u00e3o os com **maior chance de sobreviv\u00eancia.**","17458dfc":"De acordo com as an\u00e1lises efetuadas as seguintes vari\u00e1veis ser\u00e3o inicialmente eliminadas:\n\n* **Name**: trata-se do nome dos passageiros e inicialmente n\u00e3o traz nenhum informa\u00e7\u00e3o pertinente para a cria\u00e7\u00e3o do modelo. *Talvez em futuras otimiza\u00e7\u00e3o possa ser utilizada para criar classes de passageiros de acordo com sua classifica\u00e7\u00e3o (Mr. Sr. etc.)*;\n* **Ticket**: valor alfanum\u00e9rico que indica o n\u00famero da passagem. N\u00e3o traz informa\u00e7\u00f5es relevantes em rela\u00e7\u00e3o \u00e0 sobreviv\u00eancia dos passageiros;\n* **Cabin**: valor alfanum\u00e9rico que indica a cabine do passageiro. \u00c9 uma vari\u00e1vel com muitos valores nulos (687 de 891 nos dados de treino) e valores duplicados. N\u00e3o traz informa\u00e7\u00e3o relevante para o modelo.\n* **PassengerId**: identifica\u00e7\u00e3o num\u00e9rica do passageiro. N\u00e3o traz informa\u00e7\u00f5es \u00fateis ao modelo.","b682da45":"## Elimina\u00e7\u00e3o de vari\u00e1veis","1e9b598c":"Percebemos atrav\u00e9s da descri\u00e7\u00e3o dos dados que:\n\n* **Survived:** cerca de 38% da amostra sobreviveu ao naufr\u00e1gio (valor pr\u00f3ximo ao que realmente ocorreu de 32%);\n* **Pclass**: mais de 50% das pessoas viajaram de terceira classe;\n* **Age**: a amostra mostra que a maioria dos passageiros eram jovens (por volta dos 30 anos de idade);\n* **Sibsp**: mais de 50% dos passageiros viajaram sem os irm\u00e3os ou maridos\/esposas;\n* **Parch**: mais de 75% das pessoas viajaram sem parentes (pais e m\u00e3e) e filhos;\n* **Fare**: o valor das passagens possui um range alto, indicando desigualdade nos pre\u00e7os entre as classes de cabine. Sendo que 50% das passagens tinham pre\u00e7os por volta ou menores que 15 d\u00f3lares.","5534f804":"## Importando os dados e defini\u00e7\u00f5es b\u00e1sicas","33742d94":"### Sobreviventes por quantidade de parentes ou filhos","1c989b33":"# 3) Pr\u00e9-processamento\n\nNessa etapa ser\u00e3o executadas as atividades de elimina\u00e7\u00e3o e escolha de vari\u00e1veis, transforma\u00e7\u00e3o de vari\u00e1veis e cria\u00e7\u00e3o das pipelines para tornar o c\u00f3digo mais pythonico, manuten\u00edvel e tamb\u00e9m evitar que dados de teste vazem para os dados de treino.","0fc2db88":"Por meio da an\u00e1lise de correla\u00e7\u00e3o \u00e9 poss\u00edvel perceber que:\n\n1. A vari\u00e1vel **Pclass** tem uma **correla\u00e7\u00e3o negativa** com a vari\u00e1vel target **survived**, indicando que quanto menor o n\u00famero da classe, ou seja, quanto mais luxuosa a classe, maior s\u00e3o as chances de sobreviv\u00eancia.\n2. A vari\u00e1vel **Fare** tem uma correla\u00e7\u00e3o positiva com a vari\u00e1vel target **survived**, indicando que quanto maior foi o valor da passagem, maiores foram as chances de sobreviv\u00eancia. Muito correlacionado com o item superior (a matriz de correla\u00e7\u00e3o tamb\u00e9m mostra essa avalia\u00e7\u00e3o).\n\nAmbas as avalia\u00e7\u00f5es fazem sentido no contexto dessa trag\u00e9dia, j\u00e1 que \u00e9 esperado que as pessoas mais ricas (mais privilegiadas) tenham sobrevivido \u00e0 custo das mais pobres.\n\nSeguem abaixo comparativos relacionados a cada vari\u00e1vel independente em rela\u00e7\u00e3o a vari\u00e1vel target:","a0d3bfe0":"## Salvando arquivo para submiss\u00e3o","2b366ea9":"## Avaliando a distribui\u00e7\u00e3o dos dados","2022bdb8":"# 1) Introdu\u00e7\u00e3o\n\nEsse c\u00f3digo foi feito com o intuito de demonstrar algumas t\u00e9cnicas de ci\u00eancia de dados em um dos datasets mais famosos da comunidade.\n\nO trabalho foi dividido da seguinte forma:\n\n1. Introdu\u00e7\u00e3o;\n2. An\u00e1lise explorat\u00f3ria;\n3. Pr\u00e9-processamento;\n4. Cria\u00e7\u00e3o do modelo;\n5. Previs\u00e3o dos resultados.\n","5d3f2ae7":"Percebe-se que proporcionalmente os passageiros que **embarcaram em Cherbourg** s\u00e3o os com **maior chance de sobreviv\u00eancia.**","dbeb6249":"## Transforma\u00e7\u00e3o do Data Frame\n\nPara melhorar a visualiza\u00e7\u00e3o, irei mover a vari\u00e1vel target para a \u00faltima coluna. Al\u00e9m disso separar a matriz de vari\u00e1veis indepentes em **X** e o vetor target para **y**.","794a3260":"## Importando as bibliotecas necess\u00e1rias","eea4cc63":"### Sobreviventes por local de embarque","f9296528":"## An\u00e1lises Num\u00e9ricas","5edf957a":"## Objetivo:\n\nPredizer quais pessoas v\u00e3o sobreviver ao naufr\u00e1gio do Titanic.","898cf358":"# 2) An\u00e1lise Explorat\u00f3ria\n\nNessa etapa irei explorar os dados e obter mais informa\u00e7\u00f5es sobre o naufr\u00e1gio, tentando identificar padr\u00f5es estat\u00edsticos\/visuais nas vari\u00e1veis, al\u00e9m de determinar quais features s\u00e3o importantes para a modelagem subsequente.","4c114062":"# 4) Cria\u00e7\u00e3o do Modelo","5a6d6538":"Percebe-se que proporcionalmente os passageiros **sem nenhum ou com poucos irm\u00e3os ou maridos\/esposas** s\u00e3o os com **maior chance de sobreviv\u00eancia.**","2e70760e":"## Teste de Modelos para Classifica\u00e7\u00e3o (usando crossvalidation)\n\nO teste dos modelos \u00e9 essencial para definir qual algoritmo ir\u00e1 possuir a maior acur\u00e1cia (m\u00e9todo de avalia\u00e7\u00e3o desse desafio). O uso do CrossValidation agrega mais confian\u00e7a na decis\u00e3o, j\u00e1 que com essa metodologia reduzimos a possibilidade de overfitting do modelo para os dados apresentados no treinamento.\n\nVamos utilizar os seguinte modelos:\n\n* Logistic Regression\n* Linear Discrimination Analysis\n* Naive Bayes\n* K-Nearest Neighbours\n* Suppor Vector Machine - Classifier\n* Decision Tree Classifier\n* Random Forest\n* AdaBoost\n* XGBoost Classifier","b00f8623":"## Dados fornecidos:\n\nForam fornecidos dados de treino e teste. Os dados de treino s\u00e3o uma **amostra da popula\u00e7\u00e3o do Titanic** e possuem uma coluna indicando se os indiv\u00edduos sobreviveram ou n\u00e3o e esta deve ser tomada como verdade para predizer o futuro dos outros passageiros n\u00e3o inclu\u00eddos na amostra.\n\nOs dados fornecidos possuem 9 vari\u00e1veis independentes e 1 vari\u00e1vel target:\n\n* **survival**: vari\u00e1vel target indicando quem sobreviveu ou n\u00e3o ao naufr\u00e1gio;\n* **pclass**: indica a qual classe o passageiro pertencia (primeira, segunda ou terceira classes);\n* **Sex**: indica o sexo do passageiro;\n* **Age**: indica a idade do passageiro;\n* **SibSp**: indica a quantidade de irm\u00e3o ou esposa\/marido abordo;\n* **Parch**: indica a quantitdade de pais e filhos abordo;\n* **ticket**: n\u00famero do ticket (passagem) para o navio;\n* **cabin**: n\u00famero da cabine na qual o passageiro foi alocado para a viagem;\n* **Embarked**: local de embarque do passageiro.","5a041a09":"Percebe-se que proporcionalmente os passageiros do **sexo feminino** s\u00e3o os com **maior chance de sobreviv\u00eancia.**"}}