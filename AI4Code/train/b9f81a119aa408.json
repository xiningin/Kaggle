{"cell_type":{"248fe593":"code","eb205c0f":"code","41f84e0c":"code","59eebb48":"code","0c080bb0":"code","226b637f":"code","24fcbb78":"code","27d9d806":"code","da52521c":"code","3d0a26eb":"code","cfe9adbe":"code","42c6d27d":"code","c06bb49e":"code","c1bd8121":"code","c802ee41":"code","e1ca51a3":"code","b9cb1d62":"code","5df1ac24":"code","09d2674f":"code","6ed79882":"code","1fbe95ac":"code","576e370b":"code","8c76fd6b":"code","9a1470ee":"code","b6864681":"markdown","63edbd0e":"markdown","bd34c634":"markdown","0f74f21e":"markdown"},"source":{"248fe593":"import pandas as pd\nimport os\nimport torch\nimport time\nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as tt\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import *\n\n%matplotlib inline","eb205c0f":"batch_size = 400\nepochs = 120\nmax_lr = 0.001\ngrad_clip = 0.01\nweight_decay =0.001\nopt_func = torch.optim.Adam","41f84e0c":"train_data = torchvision.datasets.CIFAR100('.\/', train=True, download=True)\n\n# Stick all the images together to form a 1600000 X 32 X 3 array\nx = np.concatenate([np.asarray(train_data[i][0]) for i in range(len(train_data))])\n\n# calculate the mean and std along the (0, 1) axes\nmean = np.mean(x, axis=(0, 1))\/255\nstd = np.std(x, axis=(0, 1))\/255\n# the the mean and std\nmean=mean.tolist()\nstd=std.tolist()\n","59eebb48":"transform_train = tt.Compose([tt.RandomCrop(32, padding=4,padding_mode='reflect'), \n                         tt.RandomHorizontalFlip(), \n                         tt.ToTensor(), \n                         tt.Normalize(mean,std,inplace=True)])\ntransform_test = tt.Compose([tt.ToTensor(), tt.Normalize(mean,std)])","0c080bb0":"trainset = torchvision.datasets.CIFAR100(\".\/\",\n                                         train=True,\n                                         download=True,\n                                         transform=transform_train)\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size, shuffle=True, num_workers=2,pin_memory=True)\n\ntestset = torchvision.datasets.CIFAR100(\".\/\",\n                                        train=False,\n                                        download=True,\n                                        transform=transform_test)\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size*2,pin_memory=True, num_workers=2)","226b637f":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","24fcbb78":"device = get_default_device()\ndevice","27d9d806":"trainloader = DeviceDataLoader(trainloader, device)\ntestloader = DeviceDataLoader(testloader, device)","da52521c":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n        \ndef conv_block(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n              nn.BatchNorm2d(out_channels), \n              nn.ReLU(inplace=True)]\n    if pool: layers.append(nn.MaxPool2d(2))\n    return nn.Sequential(*layers)\n\nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_classes):\n        super().__init__()\n        \n        self.conv1 = conv_block(in_channels, 64)\n        self.conv2 = conv_block(64, 128, pool=True) \n        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128)) \n        \n        self.conv3 = conv_block(128, 256, pool=True)\n        self.conv4 = conv_block(256, 512, pool=True) \n        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) \n        self.conv5 = conv_block(512, 1028, pool=True) \n        self.res3 = nn.Sequential(conv_block(1028, 1028), conv_block(1028, 1028))  \n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(2), # 1028 x 1 x 1\n                                        nn.Flatten(), # 1028 \n                                        nn.Linear(1028, num_classes)) # 1028 -> 100\n        \n    def forward(self, xb):\n        out = self.conv1(xb)\n        out = self.conv2(out)\n        out = self.res1(out) + out\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.res2(out) + out\n        out = self.conv5(out)\n        out = self.res3(out) + out\n        out = self.classifier(out)\n        return out\n\nmodel = to_device(ResNet9(3, 100), device)\nmodel","3d0a26eb":"@torch.no_grad()\ndef evaluate(model, test_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in test_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, test_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, test_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","cfe9adbe":"# Initial evaluation\nhistory = [evaluate(model, testloader)]\nhistory","42c6d27d":"# Fitting the first 1\/4 epochs\ncurrent_time=time.time()\nhistory += fit_one_cycle(int(epochs\/4), max_lr, model, trainloader, testloader, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","c06bb49e":"# Fitting the second 1\/4 epochs\nhistory += fit_one_cycle(int(epochs\/4), max_lr\/10, model, trainloader, testloader, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","c1bd8121":"\nhistory += fit_one_cycle(int(epochs\/8), max_lr\/100, model, trainloader, testloader, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","c802ee41":"\nhistory += fit_one_cycle(int(epochs\/8), max_lr\/1000, model, trainloader, testloader, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","e1ca51a3":"\nhistory += fit_one_cycle(int(epochs\/4), max_lr\/100, model, trainloader, testloader, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)\n# Print training time\nprint('Training time: {:.2f} s'.format(time.time() - current_time))","b9cb1d62":"# Collect training time and result\ncurrent_time = time.time()\nresult = evaluate(model, testloader)\nresult\nprint('Training time: {:.2f} s'.format(time.time() - current_time))","5df1ac24":"# Saving the model to h5 file\ntorch.save(model.state_dict(), 'group22_pretrained_model.h5')","09d2674f":"# Generate testing accuracy, predicted label, confusion matrix, and table for classification report\ndef test_label_predictions(model, device, test_loader):\n    model.eval()\n    actuals = []\n    predictions = []\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            prediction = output.argmax(dim=1, keepdim=True)\n            actuals.extend(target.view_as(prediction))\n            predictions.extend(prediction)\n    return [i.item() for i in actuals], [i.item() for i in predictions]\n\ny_test, y_pred = test_label_predictions(model, device, testloader)\ncm=confusion_matrix(y_test, y_pred)\ncr=classification_report(y_test, y_pred)\nfs=f1_score(y_test,y_pred,average='weighted')\nrs=recall_score(y_test, y_pred,average='weighted')\naccuracy=accuracy_score(y_test, y_pred)\nprint('Confusion matrix:')\nprint(cm)\nprint(cr)\nprint('F1 score: %f' % fs)\nprint('Recall score: %f' % rs)\nprint('Accuracy score: %f' % accuracy)","6ed79882":"# Save classificationreport into csv\nreport = classification_report(y_test, y_pred, output_dict = True)\ndf=pd.DataFrame(report).transpose()\ndf.to_csv('classificationreport.csv',index=False)","1fbe95ac":"# Plot classification report and save to pdf function\ndef plot_classification(precision, recall, f1_score):\n    plt.rcParams['font.size'] = 12\n    plt.rc('axes', linewidth=1.75)\n    marker_size = 8\n    figsize = 6\n    plt.figure(figsize=(1.4 * figsize, figsize))\n    plt.subplot(3, 1, 1)\n    plt.plot(precision, 'o', markersize=marker_size)\n    # plt.legend(loc=0)\n    # plt.yticks(np.arange(0.5, 1.01, 0.1))\n    plt.ylabel('Precision', fontsize=14)\n    plt.xticks([])\n    plt.subplot(3, 1, 2)\n    plt.plot(recall, 'o', markersize=marker_size)\n    # plt.yticks(np.arange(0.5, 1.01, 0.1))\n    plt.ylabel('Recall', fontsize=14)\n    plt.xticks([])\n    plt.subplot(3, 1, 3)\n    plt.plot(f1_score, 'o', markersize=marker_size)\n    # plt.yticks(np.arange(0.5, 1.01, 0.1))\n    plt.ylabel('F1-score', fontsize=14)\n    plt.xlabel('Class', fontsize=14)\n    plt.subplots_adjust(hspace=0.001)\n    plt.tight_layout()\n    plt.savefig(\"classification.pdf\")\n","576e370b":"# Plot classification report and save to pdf\ndef plot_confusion_matrix(cm):\n    plt.figure()\n    plt.imshow(cm, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n    plt.colorbar()\n    plt.ylabel('True label', fontsize=14)\n    plt.xlabel('Predicted label', fontsize=14)\n    plt.tight_layout()\n    plt.savefig(\"confusion_matrix.pdf\")\n    plt.show()","8c76fd6b":"# Obtain training accuracy\ny_train, y_pred2 = test_label_predictions(model, device, trainloader)\ntrain_accuracy=accuracy_score(y_train, y_pred2)\nprint('Train accuracy: %f' % train_accuracy)","9a1470ee":"# Plot and save confusion matrix\nprecision, recall, f1,_= precision_recall_fscore_support(y_test, y_pred)\nprint(recall)\nplot_classification(precision, recall, f1)\n\n# Plot confusion matrix\nplot_confusion_matrix(cm)","b6864681":"# Device check and load model into device","63edbd0e":"# Layer Setup","bd34c634":"# Training Setup","0f74f21e":"# Prediction"}}