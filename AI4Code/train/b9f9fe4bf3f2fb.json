{"cell_type":{"04566e77":"code","ede9f54d":"code","a59de435":"code","58a34e15":"code","2987b369":"code","7219ef2d":"code","2e150e8c":"code","3da3225e":"code","0a755712":"code","8b37d0d7":"code","6abe6229":"code","fb7a1ed8":"code","3458208f":"markdown","9ce69fc8":"markdown","1b3af783":"markdown"},"source":{"04566e77":"!pip install watermark --quiet\n%load_ext watermark\n%watermark -a 'Adwitiya Trivedi' -v -p torch","ede9f54d":"#import libraries\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport seaborn as sns\nimport numpy as np\nfrom torch.utils.data import random_split\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","a59de435":"\nBATCH_SIZE=64\nnum_epochs=5\nlr=1e-4\nclass_size=10","58a34e15":"\ntranform_train = transforms.Compose([transforms.Resize((224,224)), transforms.RandomHorizontalFlip(p=0.7), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\ntranform_test = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n#prep the train, validation and test dataset\ntorch.manual_seed(2021)\ntrain = torchvision.datasets.CIFAR10(\"data\/\", train=True, download=True, transform=tranform_train) \nval_size = 10000 \ntrain_size = len(train) - val_size\ntrain, val = random_split(train, [train_size, val_size]) \ntest = torchvision.datasets.CIFAR10(\"data\/\", train=False, download=True, transform=tranform_test) \n\n#  train, val and test datasets to the dataloader\ntrain_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)","2987b369":"import matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid\nfor images, _ in train_loader:\n    print('images.shape:', images.shape)\n    plt.figure(figsize=(16,8))\n    plt.axis('off')\n    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n    break","7219ef2d":"sample_image=iter(train_loader)\nsamples,labels=sample_image.next()\nprint(samples.shape) #64 batch size, 1 channel, width 224 , height 224\nprint(labels)","2e150e8c":"#how the maxpool works while we are preserving the shape in blocks by padding (1,1)\n'''\n    x = (width- kernel_size +2P) \/S +1\n    where P= padding\n    S= strides\n'''\nimport math\nblock1 =224\npool1 =math.ceil((block1-3)\/2 +1)\nprint(pool1)\n\n\nblock2=pool1\n\npool2 =math.ceil((block2-3)\/2 +1)\nprint(pool2)\n\n\n\nblock3=pool2\npool3 =math.ceil((block3-3)\/2 +1)\nprint(pool3)\n\n\nblock4=pool3\npool4 =math.ceil((block4-3)\/2 +1)\nprint(pool4)\n\n\nblock5=pool4\npool5 =math.ceil((block5-3)\/2 +1)\nprint(pool5)\n\n\n#After flatten \nflatten= pool5 * pool5 * 512\nprint(f'After flatten:: {flatten}')","3da3225e":"class VGG16_NET(nn.Module):\n    def __init__(self):\n        super(VGG16_NET, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n\n        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n\n        self.conv8 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n        self.conv9 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n        self.conv10 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n\n        self.conv11 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n        self.conv12 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n        self.conv13 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.fc14 = nn.Linear(25088, 4096)\n        self.fc15 = nn.Linear(4096, 4096)\n        self.fc16 = nn.Linear(4096, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv5(x))\n        x = F.relu(self.conv6(x))\n        x = F.relu(self.conv7(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv8(x))\n        x = F.relu(self.conv9(x))\n        x = F.relu(self.conv10(x))\n        x = self.maxpool(x)\n        x = F.relu(self.conv11(x))\n        x = F.relu(self.conv12(x))\n        x = F.relu(self.conv13(x))\n        x = self.maxpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = F.relu(self.fc14(x))\n        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n        x = F.relu(self.fc15(x))\n        x = F.dropout(x, 0.5)\n        x = self.fc16(x)\n        return x","0a755712":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \nmodel = VGG16_NET() \nmodel = model.to(device=device) \nload_model = True\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr= lr) ","8b37d0d7":"for epoch in range(num_epochs): #I decided to train the model for 50 epochs\n    loss_var = 0\n    \n    for idx, (images, labels) in enumerate(train_loader):\n        images = images.to(device=device)\n        labels = labels.to(device=device)\n        ## Forward Pass\n        optimizer.zero_grad()\n        scores = model(images)\n        loss = criterion(scores,labels)\n        loss.backward()\n        optimizer.step()\n        loss_var += loss.item()\n        if idx%64==0:\n            print(f'Epoch [{epoch+1}\/{num_epochs}] || Step [{idx+1}\/{len(train_loader)}] || Loss:{loss_var\/len(train_loader)}')\n    print(f\"Loss at epoch {epoch+1} || {loss_var\/len(train_loader)}\")\n\n    with torch.no_grad():\n        correct = 0\n        samples = 0\n        for idx, (images, labels) in enumerate(val_loader):\n            images = images.to(device=device)\n            labels = labels.to(device=device)\n            outputs = model(images)\n            _, preds = outputs.max(1)\n            correct += (preds == labels).sum()\n            samples += preds.size(0)\n        print(f\"accuracy {float(correct) \/ float(samples) * 100:.2f} percentage || Correct {correct} out of {samples} samples\")","6abe6229":"#SAVE & LOAD\ntorch.save(model.state_dict(), \"cifar10_vgg16_model.pt\") #SAVES THE TRAINED MODEL\nmodel = VGG16_NET()\nmodel.load_state_dict(torch.load(\"cifar10_vgg16_model.pt\")) #loads the trained model\nmodel.eval()","fb7a1ed8":"#TESTING LOOP SIMILAR TO VALIDATION(EVAL)\n'''\ntest_loader = DataLoader(test, batch_size=8, shuffle=False)\ncorrect = 0\nsamples = 0\nfor idx, (images, labels) in enumerate(test_dl):\n    images = images.to(device='cpu')\n    labels = labels.to(device='cpu')\n    outputs = model(images)\n    _, preds = outputs.max(1)\n    correct += (preds == labels).sum()\n    samples += preds.size(0)\nprint(f\"accuracy {float(correct) \/ float(samples) * 100:.2f} percentage || Correct {correct} out of {samples} samples\")\n'''","3458208f":"**MODEL CAN BE FURTHER TRAINED FOR BETTER ACCURACY ALSO Accuracy on each class can checked too**\n## For more info check https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html","9ce69fc8":"![68747470733a2f2f7777772e63732e746f726f6e746f2e6564752f7e66726f73736172642f706f73742f76676731362f76676731362e706e67.png](attachment:a8afc2c8-98ce-4a45-a518-5253f9b27e89.png)","1b3af783":"#### Unseen layers VGG employs ReLU in all of its secret layers (AlexNet came up with a big idea that sliced training time in half.). Local Response Normalization (LRN) is not used by VGG because It improves memory retention and training time while providing little improvement inaccuracy."}}