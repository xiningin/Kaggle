{"cell_type":{"52f4743a":"code","2639287e":"code","81b88f2f":"code","fba3d804":"code","3923e337":"code","bc810f25":"code","caed7441":"code","0b08bbb0":"code","cb98eca7":"code","477b874b":"code","4950c2a3":"code","42b6d9e8":"code","9309ac99":"code","cb28721f":"code","2f8a5d5d":"code","bf4ad1da":"code","3c466f56":"code","cb90d626":"code","24d3616b":"code","ed3587e1":"code","9728dcd2":"code","e869ae1b":"code","a723a5d7":"code","d695c9cb":"code","30da9b0f":"code","cce710d0":"code","a7908c54":"markdown","4a328cb1":"markdown","726fb2e2":"markdown","8c59383d":"markdown","d3e58375":"markdown","6715dcda":"markdown","810e8dc0":"markdown","486f5492":"markdown","c5919356":"markdown","9b9e0df0":"markdown","6296a66f":"markdown","6282904a":"markdown","5fd04bfd":"markdown","317f3524":"markdown","bccc9162":"markdown","12b9207e":"markdown"},"source":{"52f4743a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2639287e":"import matplotlib.pyplot as plt\nimport seaborn as sns","81b88f2f":"df = pd.read_csv('\/kaggle\/input\/60k-stack-overflow-questions-with-quality-rate\/data.csv')","fba3d804":"df.head()","3923e337":"df.shape","bc810f25":"df.columns","caed7441":"df = df.drop(['Id','Tags','CreationDate'],axis=1)\ndf.head()","0b08bbb0":"df['Num_words_body'] = df['Body'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ndf['Num_words_title'] = df['Title'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ndf['Total_words'] = abs(df['Num_words_body'] + df['Num_words_title']) #Total  Number of words text and Selected Text\n","cb98eca7":"plt.figure(figsize=(12,6))\np = sns.kdeplot(df['Num_words_body'],shade=True).set_title('Distribution of Body text')\np = sns.kdeplot(df['Num_words_title'],shade=True).set_title('Distribution of Body text')\nplt.xlim(0,300)","477b874b":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(df[df['Y']=='HQ']['Total_words'], shade=True,).set_title('Distribution of Total No.Of words Per Category')\np2=sns.kdeplot(df[df['Y']=='LQ_CLOSE']['Total_words'], shade=True)\np2=sns.kdeplot(df[df['Y']=='LQ_EDIT']['Total_words'], shade=True)\nplt.legend(labels=['HQ','LQ_CLOSE','LQ_EDIT'])\nplt.xlim(-20,500)","4950c2a3":"df['Y'] = df['Y'].map({'LQ_CLOSE':0,'LQ_EDIT':1,'HQ':2})\ndf.head()","42b6d9e8":"df.isnull().sum()","9309ac99":"values = [len(df[df['Y']==0]),len(df[df['Y']==1]),len(df[df['Y']==2])]\nplt.bar(['LQ_CLOSE','LQ_EDIT','HQ'],values)\nplt.show()","cb28721f":"df['All_text'] = df['Title']+' '+df['Body']\nnew_df = df.copy()\nnew_df = new_df.drop(['Title','Body'],axis=1)\nnew_df.head()","2f8a5d5d":"from nltk.corpus import stopwords\nimport re","bf4ad1da":"stop_words = stopwords.words('english')","3c466f56":"def data_cleaning(data):\n    data = data.lower()\n    data = re.sub(r'[^(a-zA-Z)\\s]','',data)\n    data = data.split()\n    temp = []\n    for i in data:\n        if i not in stop_words:\n            temp.append(i)\n    data = ' '.join(temp)\n    return data","cb90d626":"new_df['All_text'] = new_df['All_text'].apply(data_cleaning)","24d3616b":"new_df['All_text']","ed3587e1":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(new_df['All_text'],new_df['Y'],test_size=0.20)","9728dcd2":"print(x_train.size,x_test.size,y_train.size,y_test.size)","e869ae1b":"from sklearn.feature_extraction.text import TfidfVectorizer\nvec = TfidfVectorizer()\nx_train = vec.fit_transform(x_train)\nx_test = vec.transform(x_test)","a723a5d7":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(x_train,y_train)","d695c9cb":"from sklearn.metrics import accuracy_score,plot_confusion_matrix\npredictions = xgb.predict(x_test)\nacc = accuracy_score(predictions,y_test)","30da9b0f":"acc","cce710d0":"plot_confusion_matrix(xgb,x_test,y_test)","a7908c54":"Define some additional coulmns to explore the data","4a328cb1":"## Cleaning the data","726fb2e2":"It shows that length of Body is greater than title, OFFCourse it is!!!","8c59383d":"## Check for null values","d3e58375":"I will try to use Advanced Models like BERT in future.\nTHANKS FOR YOUR TIME.\n> Please Upvote if this notebook help you anyhow.","6715dcda":"Perfect no missing value and all categories have same number of rows","810e8dc0":"![](https:\/\/s3.amazonaws.com\/media.eremedia.com\/uploads\/2012\/08\/24111405\/stackoverflow-logo-700x467.png)","486f5492":"Since our dataset was balanced, accuracy or score metrix can be used","c5919356":"There is no much of a difference here!!","9b9e0df0":"**Distribution of text**","6296a66f":"# LETS AUTOMATICALLY DEFINE QUALITY OF QUESTIONS \ud83d\ude0a \ud83e\udd18 !!!!","6282904a":"Lets drop the columns that will be not used.","5fd04bfd":"## Encoding Y label","317f3524":"# Vectorizing Data\nConvert data into numerical form because its all numbers game","bccc9162":"We have achieved the accuracy of around 87 % in first try!!","12b9207e":"# Splitting for Training and Testing"}}