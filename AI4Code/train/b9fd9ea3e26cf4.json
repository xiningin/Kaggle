{"cell_type":{"6bd12c39":"code","6a0d17a4":"code","c39225e9":"code","d850b54b":"code","4e3958e2":"code","976315b4":"code","bc0ddee3":"code","c34e14f7":"code","50f6f933":"code","4668b26c":"markdown","c4477ef3":"markdown","c5e8d6c3":"markdown","e75e01bf":"markdown","d84702dd":"markdown","367fd121":"markdown"},"source":{"6bd12c39":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os  # to call the image files for training and validation\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","6a0d17a4":"from keras.preprocessing.image import load_img, img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# importing important layers which are required for making the cnn model\nfrom keras.layers import Dense, Input, Dropout\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import Flatten, Conv2D, BatchNormalization\nfrom keras.layers import Activation, MaxPooling2D\n\n# importing important keras optimizers and models\n#importing models\nfrom keras.models import Model, Sequential\n# importing optimizers to to reduce the losses and get results faster\nfrom keras.optimizers import Adam, SGD, RMSprop","c39225e9":"# standardizing the size of each and every picture because its not necessary that each picture is of one standard size\n# standardizing the picture to be of size 48 * 48\npicture_size = 48\n# defining the folder path\nfolder_path = \"..\/input\/face-expression-recognition-dataset\/images\/\"","d850b54b":"# plotting some of the images from \"disgust\" folder\nexpression = 'disgust'\n# defining figure size of the matplotlib graph by 12 * 12\nplt.figure(figsize= (12,12))\nfor i in range(1, 10, 1):\n    plt.subplot(3,3,i)\n    # os.listdir() is used to get the list of all files and directories in the specified directory\n    img = load_img(folder_path+\"train\/\"+expression+\"\/\"+\n                   os.listdir(folder_path + \"train\/\" + expression)[i], target_size = (picture_size, picture_size))\n    # displaying data as an image\n    plt.imshow(img)\nplt.show()","4e3958e2":"# batch_size defines how many training example the model should take in one iteration.\nbatch_size = 128\n\n# defining two variables as ImageDatagenerator\ndatagen_train = ImageDataGenerator()\ndatagen_eval = ImageDataGenerator()\n\n# defining two variaables that are train_set and test_set\n# these variables are going to contain data which is comming from the directory\n\"\"\"\nthe data which is present in train folder is given to datagen_train(which is the ImageDataGerator) and is stored in vatiable train_set \nusing flow_from_directory function\n\"\"\"\ntrain_set = datagen_train.flow_from_directory(folder_path+\"train\",\n                                              target_size = (picture_size, picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size = batch_size,\n                                              # defining class mode as categorical because there are 7 different categories of output\n                                              class_mode = 'categorical',\n                                              shuffle = True)\n\"\"\"\nthe data which is present in test folder is given to datagen_eval(which is the ImageDataGerator) and is stored in vatiable test_set \nusing flow_from_directory function\n\"\"\"\ntest_set = datagen_train.flow_from_directory(folder_path+\"validation\",\n                                              target_size = (picture_size, picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size = batch_size,\n                                              # defining class mode as categorical because there are 7 different categories of output\n                                              class_mode = 'categorical',\n                                              shuffle = False)\n","976315b4":"# number of classes is 7 because there is 7 different possible outcomes\nno_of_classes = 7\n\n# model is defined as sequential because i'm going to use the sequential model\nmodel = Sequential()\n\n# Defining the neural network layers\n\n# cnn layer 1\n# defining 64 filters and 3 * 3 kernel size\nmodel.add(Conv2D(64,(3,3), padding = 'same', input_shape = (48, 48, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2))) # extracts important feature from @ * 2 area of the image\nmodel.add(Dropout(0.25)) # adding dropout to prevent our model from getting overfitted\n\n# cnn layer 2\nmodel.add(Conv2D(512,(3,3), padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n# cnn layer 3\nmodel.add(Conv2D(512, (3,3), padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n# cnn layer 4\nmodel.add(Conv2D(512, (3,3), padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n# flattening layer collapses input to one dimensional array which could be fed into the model\nmodel.add(Flatten())\n\n# connecting all layers using dense\n\n# fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# fully connected 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\nopt = Adam(lr = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","bc0ddee3":"# fitting the Model with Training and Validation Data\ncheckpoint = ModelCheckpoint(\".\/model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n\nepochs = 48\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])","c34e14f7":"history = model.fit_generator(generator=train_set,\n                                steps_per_epoch=train_set.n\/\/train_set.batch_size,\n                                epochs=epochs,\n                                validation_data = test_set,\n                                validation_steps = test_set.n\/\/test_set.batch_size,\n                                callbacks=callbacks_list\n                                )","50f6f933":"# Plotting Accuracy & Loss\nplt.style.use('dark_background')\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","4668b26c":"Importing Deep Learning Libraries ","c4477ef3":"Importing the important dependencies","c5e8d6c3":"Make the Training and validation it's like Train, Test, Split","e75e01bf":"Importing important dependencies for data analysis and visualization","d84702dd":"Defining the Model \n(Here i'm going to build the artificial neural network that is going to detect different different emotions)","367fd121":"Displaying some of the images to get the idea of what are the images that are going to use to train the model"}}