{"cell_type":{"59504373":"code","365fcc93":"code","d4fecb33":"code","b34c5870":"code","bfc93ac9":"code","bba89d5d":"code","888c42b5":"code","85c2d9d0":"code","60567b97":"code","19a0d88e":"code","b596316f":"code","a0eb1214":"code","b26a1042":"code","fc5a6285":"code","b73f063a":"code","816d6d42":"code","5014101a":"code","efb0ccac":"code","3500b906":"code","6d3e4991":"code","5b792b56":"code","3a4c42b3":"code","74ef0011":"code","5d9c6ee2":"code","a429b06a":"code","c33374b2":"code","50320e3b":"code","f7a8a4ad":"code","d88ab8de":"code","d395d92b":"code","a3d1c768":"code","988f2d78":"code","14de5d5a":"code","053e42ce":"code","90c94908":"code","d0b9b78c":"code","cd048baa":"code","f1efd93a":"code","05352d19":"code","c0b831cd":"code","e3d2cbde":"code","c67662cb":"code","dda8c35d":"code","391eff79":"code","745fab61":"code","e6546560":"code","c6b90bee":"code","debe1ded":"code","a2af8d7b":"code","40765680":"code","2dbd5f71":"code","3addf3dd":"code","5c04b520":"code","6d32d39a":"code","ab000086":"code","4c0a44eb":"code","76008781":"code","0c7306dc":"code","a10c6aca":"code","02862e39":"code","fef55523":"code","359a1f38":"code","21ef8036":"code","9a60c48a":"code","fd0ec6df":"code","722e1906":"code","8c209bbf":"code","e2dffde5":"markdown","41fdfed2":"markdown","fe446d2b":"markdown","8029be9e":"markdown","ed04a7e4":"markdown","119d9102":"markdown","20fdbc58":"markdown","bfa57259":"markdown","62f2f1e9":"markdown","abc7c750":"markdown","69e11033":"markdown","be87ac15":"markdown","caa0732f":"markdown","3f120773":"markdown","d1716b7b":"markdown","de036ea0":"markdown","326c1e51":"markdown","d459096c":"markdown","04ce6324":"markdown","b741a5d4":"markdown","d80f4526":"markdown","82d84de2":"markdown","16b51d4f":"markdown","c6d47d32":"markdown","5e10f13b":"markdown","58ba5557":"markdown","2932a805":"markdown","935cd737":"markdown","e9cc6936":"markdown","7aa76efb":"markdown","f2589300":"markdown","e93bb96a":"markdown","809f4c7f":"markdown","9426690c":"markdown","83905b25":"markdown","06d4711d":"markdown","f1acccf7":"markdown","2b514907":"markdown","51232ccd":"markdown","22a1d8b4":"markdown","d19ee80b":"markdown","8ad506ae":"markdown","a4b06f58":"markdown","5e142943":"markdown","7c5b4648":"markdown","e19b48a5":"markdown","8eedf78e":"markdown","951536a0":"markdown","3e9bb701":"markdown","6167daa8":"markdown","c22b1e30":"markdown","c82d5931":"markdown","31c23402":"markdown","05fdf927":"markdown","feb73d61":"markdown","57298f93":"markdown","f0ef4310":"markdown","ef243c6f":"markdown","54d10305":"markdown"},"source":{"59504373":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom datetime import datetime\nimport calendar\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","365fcc93":"pd.set_option('display.max_columns', None) #This helps in viewing all columns of dataset","d4fecb33":"df=pd.read_csv('..\/input\/nifty50-stocks-dataset20102021\/Final-50-stocks.csv')\ndf.sample(5)","b34c5870":"df.isna().sum()  #Nan values are present","bfc93ac9":"idx=np.where(df.isna().sum()>0)[0]     #finding index of columns where nan-values are more than 0 \ncols=df.iloc[:,idx].columns\ncols","bba89d5d":"from sklearn.impute import KNNImputer\nimputer=KNNImputer(n_neighbors=2)\ndf[cols]=imputer.fit_transform(df[cols])         #fitting knn imputer to impute nan values with two neighbouring values \ndf[cols]=np.round(df[cols],2)","888c42b5":"df.DATE=df.DATE.apply(pd.to_datetime)","85c2d9d0":"df['year']=df.DATE.apply(lambda x:datetime.date(x).year)\ndf['month']=df.DATE.apply(lambda x:datetime.date(x).month)\ndf['day']=df.DATE.apply(lambda x:datetime.date(x).day)\ndf['day_num']=df.DATE.apply(lambda x:datetime.date(x).weekday())\ndf['week_num']=df.DATE.apply(lambda x:datetime.date(x).isocalendar()[1])","60567b97":"df.year.value_counts().sort_index(ascending=True).plot(kind='bar')\n# Year 2010 has the least number of listed stocks on NIFTY-50","19a0d88e":"df['month_name']=df.month.apply(lambda x: calendar.month_name[x])\nsns.barplot(df.month.value_counts().index,df.month.value_counts().values)\nplt.xticks(rotation=45)","b596316f":"df.groupby('week_num')['week_num'].count().plot()\n# week 51,52,53 occurs quite rarely in stock market","a0eb1214":"df.day_num=df.day_num.apply(lambda x: calendar.day_name[x])\nsns.barplot(df.groupby('day_num')['day_num'].count().index,df.groupby('day_num')['day_num'].count().values)\n#Sat & Sun have least number of stock market entries","b26a1042":"df2=df.copy()\ndf2.drop([\"month_name\",\"day_num\"],axis=1,inplace=True)","fc5a6285":"for i in df2.columns[1:8]:             #first 5 stocks in the dataset\n    sns.displot(df2[i],kde=True)\n    plt.title(i)\n    plt.xlabel('stock price')\n    plt.show()","b73f063a":"plt.figure(figsize=(12,6))\ndef area_plot():\n    for stock_name in df.columns[1:8]:                           #plotting first 8 stocks\n        df.plot.area(x='DATE',y=stock_name)\n        plt.xlabel('year',fontsize=14)\n        plt.ylabel('price',fontsize=14)\narea_plot()","816d6d42":"for name in df2.columns[1:8]:  # Taking first 8 columns for line-plot\n    plt.figure(figsize=(10,5))\n    sns.lineplot(x=\"year\",y=name,data=df2)\n    plt.title(name)\n    plt.ylabel('close price')\n    plt.show()","5014101a":"for name in df2.columns[1:8]:                   #Taking first 8 columns only for scatter-plot\n    plt.figure(figsize=(10,5))\n    for i in df2.year.unique():\n        d=df2.loc[df2.year==i,[name,'DATE']]\n        plt.scatter(d[\"DATE\"],d[name])    \n\n    plt.xlabel('years',fontsize=14)\n    plt.ylabel(f'{name} close price',fontsize=14)\n    \n    plt.legend(['2010',\"2011\",'2012',\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\", \"2020\",\"2021\"])\n    plt.show()","efb0ccac":"df3_above_mean=pd.DataFrame()\n\nfor i in df2.columns:\n    df3_above_mean[f\"{i}_Above\"]=df2.loc[df2[i]>df2[i].mean(),i].reset_index(drop=True)\n","3500b906":"df3_below_mean=pd.DataFrame()\n\nfor i in df2.columns:\n    df3_below_mean[f\"{i}_Below\"]=df2.loc[df2[i]<df2[i].mean(),i].reset_index(drop=True)","6d3e4991":"df3_below_mean.year_Below.value_counts() #2015 is cutoff -date for stock prices below mean","5b792b56":"df3_above_mean.year_Above.value_counts() #from 2016 stock prices started to go par thier mean","3a4c42b3":"def hide_axis():\n    fig = plt.figure(figsize=(12,6))\n    ax = fig.add_subplot()\n    ax.axes.get_xaxis().set_visible(False)","74ef0011":"df3_below_mean.columns","5d9c6ee2":"def line_plot_below_mean(cols):\n    hide_axis()\n    for i in df3_below_mean['year_Below'].unique():\n        plt.plot(df3_below_mean.loc[df3_below_mean['year_Below']==i,cols])\n        plt.xlabel(\"Across the years\",fontsize=18)\n        plt.ylabel(\"price(below-mean)\",fontsize=18)\n        plt.legend([\"2010\",\"2011\",\"2012\",\"2013\",\"2014\", \"2015\"])\nline_plot_below_mean(\"RELIANCE_Below\")           #enter stock name here","a429b06a":"def line_plot_above_mean(cols):\n    hide_axis()\n    for i in df3_above_mean['year_Above'].unique():\n        plt.plot(df3_above_mean.loc[df3_above_mean['year_Above']==i,cols])\n        plt.xlabel(\"Across the years\",fontsize=18)\n        plt.ylabel(\"price(above-mean)\",fontsize=18)\n        plt.legend([\"2016\",\"2017\",\"2018\",\"2019\",\"2020\", \"2021\"])\nline_plot_above_mean(\"RELIANCE_Above\")           #enter stock name here","c33374b2":"def hist_below_mean(cols):\n    for i in df3_below_mean['year_Below'].unique():\n        d=df3_below_mean.loc[df3_below_mean['year_Below']==i,cols]\n        print(cols,i)\n        d.hist()\n        plt.xlabel('price',fontsize=18)\n        plt.ylabel('count',fontsize=18)\n        plt.show()\nhist_below_mean(\"RELIANCE_Below\")       #enter stock name here","50320e3b":"plt.figure(figsize=(6,3))\ndef hist_above_mean(cols):\n    for i in df3_above_mean['year_Above'].unique():\n        d=df3_above_mean.loc[df3_above_mean['year_Above']==i,cols]\n        print(cols,i)\n        d.hist()\n        plt.xlabel('price',fontsize=18)\n        plt.ylabel('count',fontsize=18)\n        plt.show()\n        \nhist_above_mean(\"RELIANCE_Above\")   #enter stock name here","f7a8a4ad":"mean_vals=[]\nyr=[]\nmon=[]\n\ndef plot_monthly_prices(stock_name):\n    for year in df3_above_mean['year_Above'].unique():\n        for month in df3_above_mean['month_Above'].unique():\n            mean_vals.append(df3_above_mean.loc[(df3_above_mean['month_Above']==month) & (df3_above_mean['year_Above']==year),f'{stock_name}_Above'].mean())\n            yr.append(year)\n            mon.append(month)\n \n    new_df=pd.DataFrame()\n    days=[19, 20, 21, 22, 25, 26, 27, 28, 29, 16, 18, 23, 24, 29, 30, 17,19, 20, 21, 22, 25, 26, 27, 28, 29, 16, 18, 23, 24, 28, 30, 17,19,20,21,22]\n    new_df['day']=days\n    new_df['mean']=mean_vals\n    new_df['month']=mon\n    new_df['year']=yr\n    \n    new_df['date']=pd.to_datetime(new_df[[\"year\", \"month\", \"day\"]])\n    sns.lineplot(x='date',y='mean',data=new_df)\n    plt.xticks(rotation=45)\n\nplot_monthly_prices('TATAMOTORS')","d88ab8de":"mean_vals=[]\nyr=[]\nmon=[]\n\ndef plot_monthly_prices(stock_name):\n    for year in df3_below_mean['year_Below'].unique():\n        for month in df3_below_mean['month_Below'].unique():\n            mean_vals.append(df3_below_mean.loc[(df3_below_mean['month_Below']==month) & (df3_below_mean['year_Below']==year),f'{stock_name}_Below'].mean())\n            yr.append(year)\n            mon.append(month)\n \n    new_df=pd.DataFrame()\n    days=[11., 12., 15., 13., 14.,  2.,  3.,  4.,  6.,  7.,  8.,  5.,  9.,1., 10.,11., 12., 15., 13., 14.,  2.,  3.,  4.,  6.,  7.,  8.,  5.,  9.,\n          1., 10.,11., 12., 15., 13., 14.,  2.,  3.,  4.,  6.,  7.,  8.,  5.,  9., 1., 10.,11.,12.,15.,13.]\n    new_df['day']=days\n    new_df['mean']=mean_vals\n    new_df['month']=mon\n    new_df['year']=yr\n     \n    new_df['date']=pd.to_datetime(new_df[[\"year\", \"month\", \"day\"]])\n    sns.lineplot(x='date',y='mean',data=new_df)\n    plt.xticks(rotation=45)\n\nplot_monthly_prices('RELIANCE')","d395d92b":"df=df.iloc[:,1:48]","a3d1c768":"# making list of first occurance-last occurance stock price and appending as a row\nd=(df.iloc[1,:].values-df.iloc[-1,:].values).tolist()\ndf.iloc[-1,:]=d","988f2d78":"# preparing a losers list by filtering values more than 0(positive values =losers)\nidx=np.where(df.iloc[-1,:]>0)[0]\nnames_=df.iloc[2710,idx].sort_values(ascending=False)\nlosers_list=names_.index.tolist()","14de5d5a":"#15 nifty losers stocks\nlen(losers_list)","053e42ce":"round(np.abs(df.loc[2710,losers_list])).sort_values(ascending=False)[:5]","90c94908":"round(np.abs(df.loc[2710,losers_list]\/df.loc[2709,losers_list]),2).sort_values(ascending=False)[:5]","d0b9b78c":"# taking everything except common elements in list a and list b to form gainers list\na=df.iloc[-1,:].index.tolist()\nb=losers_list\n\ngainers_list = list(set(a)^set(b))","cd048baa":"# 32 nifty stocks are gainers\nlen(gainers_list)","f1efd93a":"round(np.abs(df.loc[2710,gainers_list])).sort_values(ascending=False)[:6]","05352d19":"round(np.abs(df.loc[2710,gainers_list]\/df.loc[2709,gainers_list]),2).sort_values(ascending=False)[:6]","c0b831cd":"df3_above_mean=df3_above_mean.iloc[:,1:48]","e3d2cbde":"d=(df3_above_mean.iloc[1,:].values-df3_above_mean.iloc[-1,:].values).tolist()\ndf3_above_mean.iloc[-1,:]=d","c67662cb":"idx=np.where(df3_above_mean.iloc[-1,:]>0)[0]\nnames_=df3_above_mean.iloc[1027,idx].sort_values(ascending=False)\nlosers_list=names_.index.tolist()\n\n# ['TITAN_Above','SUNPHARMA_Above', 'TATAMOTORS_Above','ONGC_Above', ULTRACEMO_Above] are the top losers in 5 years\n# Titan prices have gone down the most in last 5 years","dda8c35d":"losers_list","391eff79":"round(np.abs(df3_above_mean.loc[1027,losers_list])).sort_values(ascending=False)[:5]","745fab61":"round(np.abs(df3_above_mean.loc[1027,losers_list]\/df3_above_mean.loc[1026,losers_list]),2).sort_values(ascending=False)[:5]\n\n#age change in thier prices","e6546560":"a=df3_above_mean.iloc[-1,:].index.tolist()\nb=losers_list\n\ngainers_list = list(set(a)^set(b))\ngainers_list","c6b90bee":"round(np.abs(df3_above_mean.loc[1027,gainers_list])).sort_values(ascending=False)[:5]\n#top gainers in last 5 years are ['BAJAJFINSERV_Above', 'BAJAJFINANCE_Above', 'SHREECEM_Above','EICHERMOTOR_Above', 'DRREDDYS_Above']","debe1ded":"round(np.abs(df3_above_mean.loc[1027,gainers_list]\/df3_above_mean.loc[1026,gainers_list]),2).sort_values(ascending=False)[:5]\n\n# %age change in prices","a2af8d7b":"df3_below_mean=df3_below_mean.iloc[:,1:48]","40765680":"d=(df3_below_mean.iloc[1,:].values-df3_below_mean.iloc[-1,:].values).tolist()\ndf3_below_mean.iloc[-1,:]=d","2dbd5f71":"idx=np.where(df3_below_mean.iloc[-1,:]>0)[0]\nnames_=df3_below_mean.iloc[1027,idx].sort_values(ascending=False)\nlosers_list=names_.index.tolist()","3addf3dd":"round(np.abs(df3_below_mean.loc[1027,losers_list])).sort_values(ascending=False)[:5]","5c04b520":"round(np.abs(df3_below_mean.loc[1027,losers_list]\/df3_below_mean.loc[1026,losers_list]),2).sort_values(ascending=False)[:5]","6d32d39a":"a=df3_below_mean.iloc[-1,:].index.tolist()\nb=losers_list\n\ngainers_list = list(set(a)^set(b))","ab000086":"round(np.abs(df3_below_mean.loc[1027,gainers_list])).sort_values(ascending=False)[:5]","4c0a44eb":"round(np.abs(df3_below_mean.loc[1027,gainers_list]\/df3_below_mean.loc[1026,gainers_list]),2).sort_values(ascending=False)[:5]","76008781":"d=pd.DataFrame(df2.columns[1:47])\nd.columns=['stock_names']","0c7306dc":"dicts={\"NIFTY-METAL\":[\"TATASTEEL\",\"HINDALCO\",\"JSWSTEEL\",],\"NIFTY-IT\":['TECHM',\"TCS\",\"WIPRO\",\"INFY\",\"HCLTECH\"],\"NIFTY-AUTO\":['TATAMOTORS',\"M&M\",\"HEROMOTOCO\",\"BAJAJ-AUTO\",\"EICHERMOTOR\",\"MARUTI\"],\"NIFTY-BANK\":['SBIN',\"HDFCBANK\",\"KOTAKBANK\",\"ICICIBANK\",\"INDUSBANK\",\"BAJAJFINANCE\",\"AXISBANK\",\"HDFC\"],\n       \"NIFTY-INFRA\":[\"ULTRACEMO\",\"ASIANPAINT\",\"ADANIPORTS\",\"SHREECEM\",\"LT\"],\"NIFTY-FMCG\":[\"TITAN\",\"NESTLEIND\",\"BRITANNIA\",\"HINDUNILVR\",\"ITC\"],\"NIFTY-PHARMA\":['DRREDDYS',\"CIPLA\",\"DRREDDYS\",\"SUNPHARMA\"],\"NIFTY-FINSERV\":['BAJAJFINSERV']\n       ,\"NIFTY-ENERGY\":['ONGC',\"NTPC\",\"POWERGRID\",\"COALINDIA\",\"BPCL\",\"IOC\",\"RELIANCE\"],\"NIFTY-Comm.\":[\"BHARTIARTL\"],\"NIFTY-AGRO\":['UPL'],\"NIFTY-Textiles\":['GRASIM']}","a10c6aca":"d['sectors']=''\nfor name in range(len(d.index)):\n    for i,j in dicts.items():\n        if d.stock_names[name] in j:\n            d['sectors'][name]=i\n\nd","02862e39":"d.sectors.value_counts()","fef55523":"frame=pd.DataFrame({\"stocks\":df2.columns[1:48]})","359a1f38":"all_lows_list=[]\nall_highs_list=[]\nfor name in frame.stocks:\n    all_lows_list.append(df2[name].min())\n    all_highs_list.append(df2[name].max())","21ef8036":"frame[\"ATH\"]=all_highs_list\nframe['ATL']=all_lows_list\nframe","9a60c48a":"#getting the latest prices of stocks in our dataset(oct-14 2021)\nframe['current_price']=df2.iloc[-1,1:48].values","fd0ec6df":"idx_all_high=np.where(np.abs(frame['current_price'].values- frame['ATL'].values) > np.abs(frame['current_price'].values- frame['ATH'].values))[0]\n\nnear_all_time_high=np.where(frame.iloc[idx_all_high,-1].values> frame.iloc[idx_all_high,1].values-frame.iloc[idx_all_high,1].values*(10\/100))\nframe.iloc[near_all_time_high]","722e1906":"idx_all_lows=np.where(np.abs(frame['current_price'].values- frame['ATL'].values) < np.abs(frame['current_price'].values- frame['ATH'].values))[0]\n\nframe.iloc[idx_all_lows]","8c209bbf":"idx_on_the_highs=np.where(frame['current_price']==frame['ATH'])\nframe.iloc[idx_on_the_highs]","e2dffde5":"Absolute price change wise **Losers** (2016-2020)","41fdfed2":"Percentage change wise **Losers** (2010-2015)","fe446d2b":"#### Top Losers in first 5 years","8029be9e":"<a id='subsection-six'><\/a>\n## Area-plot showing growth of a stock's price over time","ed04a7e4":"<a id='subsection-sixteen'><\/a>\n## Scatter-Plot for distribution of stock price (2010-2021)","119d9102":"##### Here is the distribution of reliance stock prices from 2010-2015. for example in 2015 its price range was (rs.800-1050) and mean was around 900","20fdbc58":"Absolute change wise **Losers** (2010-2020)","bfa57259":"<a id=\"section-two\"><\/a>\n# Feature Engineering","62f2f1e9":"<a id=\"subsection-two\"><\/a>\n\n## Extracting year and month ","abc7c750":"<a id='section-four'><\/a>\n# Exploratory Data Analysis","69e11033":"#### The thing is that few columns have a good proportion of nan values. Either we can drop nan values which will lead to reduce in size of dataset or we can impute missing values using knn imputer as it takes neighboring values to fill up the spot.\n\n#### It usually happens in stock when current day's stock price is quite near to previous day's stock price.","be87ac15":"Absolute price change wise **Losers** (2010-2015)","caa0732f":"<a id='subsection-eleven'><\/a>\n## Mapping Nifty sectors to each stock","3f120773":"#### Here we take stock prices every six months by taking the mean value of each month's price...","d1716b7b":"#### Top Losers throughout the past decade","de036ea0":"#### Top Gainers in last 5 years","326c1e51":"#### Now we are going to divide our stocks dataset into two datasets:\n####    `df3_below_mean` If a stock's prices appears more in this dataset than `df3_above_mean` it means that the stock was on its peak in initial years but is struggling to go par its mean in recent years(example- Titan was on peak in 2010-2015 but is struggling recently)\n\n####    `df3_above_mean` If a stock's prices appears more in this dataset than `df3_below_mean` it means that the stock is on its peak right now but was underperforming in its initial years. (example- TCS had a slow start in recent years but is now picking its pace up)","d459096c":"<a id='subsection-seventeen'><\/a>\n## Displot for data distribution","04ce6324":"#### Stocks that are closer to their all-time-lows","b741a5d4":"Percentage change wise **Losers** (2016-2020)","d80f4526":"<a id='subsection-ten'><\/a>\n## Histplot of a particular stock for multiple years(from 2016 to 2020)","82d84de2":"<a id='subsection-twenty' ><\/a>\n## Half yearly stock prices for the decade (above-mean prices)","16b51d4f":"#### Here is the hist distribution of reliance stock prices from 2016-2020. for example in 2018 stock prices went beyond rs.2000 for the first time. Possibly 80 days it have stayed around 2000","c6d47d32":"<a id=\"section-three\"><\/a>\n\n# Conclusion","5e10f13b":"##### Here in the graph we can see that from 2018 reliance prices crossed (rs.2000) far above its mean price (Rs.1100)","58ba5557":"\n#### Top Gainers throughout the Decade","2932a805":"Here the graph is not going above the mean price (Rs.1100)","935cd737":"Absolute price change wise **Gainers** (2010-2020)","e9cc6936":"![](http:\/\/scontent.fhyd2-2.fna.fbcdn.net\/v\/t1.18169-9\/12143280_1639222123017328_2734027745677467051_n.png?_nc_cat=111&ccb=1-5&_nc_sid=9267fe&_nc_ohc=9it_o-1iFOUAX8F9sm8&_nc_ht=scontent.fhyd2-2.fna&oh=4fa711f399eccd4987f30bddee018163&oe=6195BAAB)","7aa76efb":"<a id='subsection-tweleve'><\/a>\n## All Time Lows and All Time Highs of each stock","f2589300":"Percentage change wise **Gainers** (2016-2020)","e93bb96a":"<a id='subsection-fifteen'><\/a>\n## Line-PLot to plot stock prices from (2010-2021)","809f4c7f":"#### *This dataset consists of 47 columns where each column represents a nifty-50 stock. The idea for making the [dataset](https:\/\/www.kaggle.com\/setseries\/nifty50-stocks-dataset20102021) this way was to be able to compare changes in stocks's close prices each day (from Jan-2010 to Oct-2021) and compare it with its peer stock. Although each stock tells a different story and should not be compared. Every stock follows a similar cycle\/pattern to its fellow stock.*\n\n#### *The motive behind this notebook is explore as many features of a stock as possible, followed by relating it back to the stock market metrics (like:top gainers,all-time highs etc)*","9426690c":"#### A stock being at its lifetime high or lifetime low can be crucial for making investment decisions.  Lets see if any stock is at such a point...","83905b25":"* ### That's it from my side! We reached the end of this kernel.\n \n* ### Throughout this kernel we have tried to extract features with FEATURE-ENGINEERING , understand data with DATA-VISUALIZATION and finally relate market metrics using EDA.\n \n* ### Hopefully you have got to know a little more about this dataset.\n\n* ### And you can maybe start implementing a MACHINE-LEARNING\/DEEP-LEARNING model as per your will.\n \n* ### Please upvote this kernel if you liked it. Bye!!","06d4711d":"#### So we see that majority of nifty stocks belong to banking sector.Followed by,IT and energy. This means these three sectors should carry a major portion of nifty stocks. Lets see if that is the case..","f1acccf7":"Absolute price change wise **Gainers** (2010-2015)","2b514907":"Absolute price change wise **Gainers** (2016-2020)","51232ccd":"<a id='subsection-three'><\/a>\n## Top Gainers\/losers for 2010-2020\n","22a1d8b4":"##### Here we are going to see increase\/decrease in stock prices of a stock over a decade\n\n##### Areaplot shows the exponential change in stock prices overtime","d19ee80b":"Percentage change wise **Gainers** (2010-2015)","8ad506ae":"#### Here, first we are going to subract first record from the last record and then append it as row to dataset. Then we are going to make the losers list, by taking elements only positive values from the last row. If value is negative it means its a gain and positive means a loss. \n\n#### Example Reliance's price on 1st jan 2010= 200, Reliance's price on 31st dec 2020= 2000 .So (200-2000=-1800 gained). \n\n#### Lastly we are going to exclude losers list from the dataset and remaining columns make up for gainers list.","a4b06f58":"<a id='section-three'><\/a>\n# Data Visualization","5e142943":"<a id='subsection-nine'><\/a>\n## Histplot of a particular stock for multiple years(from 2010 to 2015)","7c5b4648":"<a id='subsection-twentyone' ><\/a>\n## Half yearly stock prices for the decade (below-mean prices)","e19b48a5":"<a id='subsection-four'> <\/a>\n## Top Gainers\/losers for 2010-2015\n","8eedf78e":"<a id='subsection-five'><\/a>\n## Top Gainers\/losers for 2016-2020\n","951536a0":"<a id=\"subsection-one\"><\/a>\n\n## Imputing missing values with KNNImputer","3e9bb701":"Percentage change wise **Gainers** (2010-2020)","6167daa8":"Percentage change wise **Losers** (2010-2020)","c22b1e30":"#### Top Gainers in first 5 years","c82d5931":"#### Top Losers in last 5 years","31c23402":"#### The displot displays the variation in distibution of prices. Example in case `Wipro` of the range is even which means that prices are not diversified but centered around the mean.\n#### Whereas incase of `Titan` the prices are right skewed and lot of variation can be seen.","05fdf927":"#### TABLE OF CONTENTS:\n\n* [Introduction](#section-one)\n* [Feature Engineering](#section-two)\n    - [Imputing Nans](#subsection-one)\n    - [Extracting year,month and more](#subsection-two)\n\n* [Data-Visualization](#section-three)\n    - [Displot for data distribution](#subsection-seventeen)\n    - [Area-Plot](#subsection-six)\n    - [lineplot for entire decade(2010-2021)](#subsection-fifteen)\n    - [Scatter-Plot represent stock price over the decade](#subsection-sixteen)\n    - [lineplot for 2010-2015](#subsection-seven)\n    - [lineplot for 2016-2020](#subsection-eight)\n    - [Histogram for 2010-2015](#subsection-nine)\n    - [Histogram for 2016-2020](#subsection-ten)\n    - [Half-yearly prices from year 2010-2015](#subsection-twentyone)\n    - [Half-yearly prices from year 2016-2020](#subsection-twenty)\n    \n* [EDA](#section-four)\n    - [Top Gainers\/Losers for 2010-2020](#subsection-three)\n    - [Top Gainers\/Losers for 2010-2015](#subsection-four)\n    - [Top Gainers\/Losers for 2016-2020](#subsection-five)\n    - [Mapping Nifty sectors to each stock](#subsection-eleven)\n    - [All Time Low and All Time High of a stock](#subsection-tweleve)\n\n* [Conclusion](#section-three)","feb73d61":"#### Stocks that are closer to their all-time-highs","57298f93":"<a id='subsection-seven'><\/a>\n## Lineplot of a stock's price over multiple years(from 2010 to 2015)","f0ef4310":"#### Stocks that are currently to their all-time-High\n","ef243c6f":"<a id=\"section-one\"><\/a>\n\n# INTRODUCTION","54d10305":"<a id='subsection-eight'><\/a>\n## Lineplot of a stock's price over multiple years(from 2016 to 2020)"}}