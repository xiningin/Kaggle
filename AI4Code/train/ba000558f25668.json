{"cell_type":{"fd62d5a7":"code","b22c392e":"code","339020fa":"code","f4cef55b":"code","b9a4416e":"code","1263180f":"code","0feca47b":"code","0387841d":"code","bbe4ca66":"code","9a1c5738":"code","c0d182c1":"code","e25cae02":"code","3b442506":"code","20a7d51b":"code","65797670":"markdown","589c89ff":"markdown","4901a62d":"markdown","032fdf92":"markdown","5793927d":"markdown","507c15d7":"markdown"},"source":{"fd62d5a7":"!pip install --no-deps '..\/input\/timm-package\/timm-0.1.26-py3-none-any.whl' > \/dev\/null\n!pip install --no-deps '..\/input\/pycocotools\/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > \/dev\/null","b22c392e":"import sys\nsys.path.insert(0, \"..\/input\/timm-efficientdet-pytorch\")\nsys.path.insert(0, \"..\/input\/omegaconf\")\nsys.path.insert(0, \"..\/input\/weightedboxesfusion\")\n\nfrom ensemble_boxes import *\nimport torch\nimport random\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom torch.utils.data import Dataset,DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport cv2\nimport gc\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom effdet import get_efficientdet_config, EfficientDet, DetBenchEval\nfrom effdet.efficientdet import HeadNet\nfrom sklearn.model_selection import StratifiedKFold","339020fa":"marking = pd.read_csv('..\/input\/global-wheat-detection\/train.csv')\n\nbboxs = np.stack(marking['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\nfor i, column in enumerate(['x', 'y', 'w', 'h']):\n    marking[column] = bboxs[:,i]\nmarking.drop(columns=['bbox'], inplace=True)","f4cef55b":"marking.tail()","b9a4416e":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ndf_folds = marking[['image_id']].copy()\ndf_folds.loc[:, 'bbox_count'] = 1\ndf_folds = df_folds.groupby('image_id').count()\ndf_folds.loc[:, 'source'] = marking[['image_id', 'source']].groupby('image_id').min()['source']\ndf_folds.loc[:, 'stratify_group'] = np.char.add(\n    df_folds['source'].values.astype(str),\n    df_folds['bbox_count'].apply(lambda x: f'_{x \/\/ 15}').values.astype(str)\n)\ndf_folds.loc[:, 'fold'] = 0\n\nfor fold_number, (train_index, val_index) in enumerate(skf.split(X=df_folds.index, y=df_folds['stratify_group'])):\n    df_folds.loc[df_folds.iloc[val_index].index, 'fold'] = fold_number","1263180f":"def get_valid_transforms():\n    return A.Compose(\n        [\n            A.Resize(height=512, width=512, p=1.0),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n        bbox_params=A.BboxParams(\n            format='pascal_voc',\n            min_area=0, \n            min_visibility=0,\n            label_fields=['labels']\n        )\n    )","0feca47b":"x = torch.ones((3,), dtype=torch.int64)","0387841d":"x","bbe4ca66":"TRAIN_ROOT_PATH = '..\/input\/global-wheat-detection\/train'\n\ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, marking, image_ids, transforms=None, test=False):\n        super().__init__()\n\n        self.image_ids = image_ids\n        self.marking = marking\n        self.transforms = transforms\n        self.test = test\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n\n        image, boxes = self.load_image_and_boxes(index)\n\n        # there is only one class\n        labels = torch.ones((boxes.shape[0],), dtype=torch.int64)\n        \n        target = {}\n        target['boxes'] = boxes\n        target['labels'] = labels\n        target['image_id'] = torch.tensor([index])\n\n        if self.transforms:\n            for i in range(10):\n                sample = self.transforms(**{\n                    'image': image,\n                    'bboxes': target['boxes'],\n                    'labels': labels\n                })\n                if len(sample['bboxes']) > 0:\n                    image = sample['image']\n                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n#                     target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n                    break\n\n        return image, target, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]\n\n    def load_image_and_boxes(self, index):\n        image_id = self.image_ids[index]\n        image = cv2.imread(f'{TRAIN_ROOT_PATH}\/{image_id}.jpg', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image \/= 255.0\n        records = self.marking[self.marking['image_id'] == image_id]\n        boxes = records[['x', 'y', 'w', 'h']].values\n        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n        return image, boxes","9a1c5738":"def draw_image_and_boxes(list_images, list_boxes):\n    fig, ax = plt.subplots(4, 2, figsize=(16, 32))\n    for i, (image, boxes) in enumerate(zip(list_images, list_boxes)):\n        for box in boxes:\n            cv2.rectangle(image,(box[0], box[1]),(box[2],  box[3]),(0, 1, 0), 2)\n        ax.set_axis_off()\n        ax.imshow(image);","c0d182c1":"dataset = DatasetRetriever(\n    image_ids=df_folds[df_folds['fold'] == 0].index.values,\n    marking=marking,\n    transforms=get_valid_transforms(),\n    test=True,\n)","e25cae02":"count = 4\n\nfig, ax = plt.subplots(count, 3, figsize=(16, 6*count))\n\nfor i in range(count):\n    image, boxes = dataset.load_image_and_boxes(random.randint(0, dataset.image_ids.shape[0] - 1))\n    r_image, r_boxes = dataset.load_image_and_boxes(random.randint(0, dataset.image_ids.shape[0] - 1))\n    mixup_image = (image+r_image)\/2\n\n    for box in boxes.astype(int):\n        cv2.rectangle(image,(box[0], box[1]),(box[2],  box[3]),(0, 0, 1), 3)\n        cv2.rectangle(mixup_image,(box[0], box[1]),(box[2],  box[3]),(0, 0, 1), 3)\n        \n    for box in r_boxes.astype(int):\n        cv2.rectangle(r_image,(box[0], box[1]),(box[2],  box[3]),(1, 0, 0), 3)\n        cv2.rectangle(mixup_image,(box[0], box[1]),(box[2],  box[3]),(1, 0, 0), 3)\n        \n    ax[i][0].imshow(image)\n    ax[i][1].imshow(r_image)\n    ax[i][2].imshow(mixup_image)","3b442506":"count = 4\n\nfig, ax = plt.subplots(count, 3, figsize=(16, 6*count))\n\nfor i in range(count):\n    image, boxes = dataset.load_image_and_boxes(random.randint(0, dataset.image_ids.shape[0] - 1))\n    r_image, r_boxes = dataset.load_image_and_boxes(random.randint(0, dataset.image_ids.shape[0] - 1))\n    \n    for box in r_boxes.astype(int):\n        cv2.rectangle(r_image,(box[0], box[1]),(box[2],  box[3]),(1, 0, 0), 3)\n    \n    mixup_image = image.copy()\n\n    imsize = image.shape[0]\n    x1, y1 = [int(random.uniform(imsize * 0.0, imsize * 0.45)) for _ in range(2)]\n    x2, y2 = [int(random.uniform(imsize * 0.55, imsize * 1.0)) for _ in range(2)]\n    \n    mixup_boxes = r_boxes.copy()\n    mixup_boxes[:, [0, 2]] = mixup_boxes[:, [0, 2]].clip(min=x1, max=x2)\n    mixup_boxes[:, [1, 3]] = mixup_boxes[:, [1, 3]].clip(min=y1, max=y2)\n    \n    mixup_boxes = mixup_boxes.astype(np.int32)\n    mixup_boxes = mixup_boxes[np.where((mixup_boxes[:,2]-mixup_boxes[:,0])*(mixup_boxes[:,3]-mixup_boxes[:,1]) > 0)]\n    \n    cv2.rectangle(r_image,(x1, y1),(x2,  y2),(0, 1, 1), 5)\n    \n    mixup_image[y1:y2, x1:x2] = (mixup_image[y1:y2, x1:x2] + r_image[y1:y2, x1:x2])\/2\n    \n    cv2.rectangle(mixup_image,(x1, y1),(x2,  y2),(0, 1, 1), 5)\n    \n    for box in boxes.astype(int):\n        cv2.rectangle(image,(box[0], box[1]),(box[2],  box[3]),(0, 0, 1), 3)\n        cv2.rectangle(mixup_image,(box[0], box[1]),(box[2],  box[3]),(0, 0, 1), 3)\n        \n    for box in mixup_boxes.astype(int):\n        cv2.rectangle(mixup_image,(box[0], box[1]),(box[2],  box[3]),(1, 0, 0), 3)\n        \n    ax[i][0].imshow(image)\n    ax[i][1].imshow(r_image)\n    ax[i][2].imshow(mixup_image)","20a7d51b":"count = 4\n\nfig, ax = plt.subplots(count, 3, figsize=(16, 6*count))\n\nfor i in range(count):\n    image, boxes = dataset.load_image_and_boxes(random.randint(0, dataset.image_ids.shape[0] - 1))\n    r_image, r_boxes = dataset.load_image_and_boxes(random.randint(0, dataset.image_ids.shape[0] - 1))\n    \n    for box in r_boxes.astype(int):\n        cv2.rectangle(r_image,(box[0], box[1]),(box[2],  box[3]),(1, 0, 0), 3)\n\n    imsize = image.shape[0]\n    w,h = imsize, imsize\n    s = imsize \/\/ 2\n\n    xc, yc = [int(random.uniform(imsize * 0.4, imsize * 0.6)) for _ in range(2)]\n    direct = random.randint(0, 3)\n\n    result_image = image.copy()\n    result_boxes = []\n\n    if direct == 0:\n        x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\n        x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\n    elif direct == 1:  # top right\n        x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n        x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n    elif direct == 2:  # bottom left\n        x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n        x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\n    elif direct == 3:  # bottom right\n        x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n        x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n\n    padw = x1a - x1b\n    padh = y1a - y1b\n\n    r_boxes[:, 0] += padw\n    r_boxes[:, 1] += padh\n    r_boxes[:, 2] += padw\n    r_boxes[:, 3] += padh\n\n    result_boxes.append(r_boxes)\n\n    result_image[y1a:y2a, x1a:x2a] = (result_image[y1a:y2a, x1a:x2a] + r_image[y1b:y2b, x1b:x2b]) \/ 2 \n    \n    cv2.rectangle(image,(x1a, y1a),(x2a,  y2a),(0, 1, 1), 5)\n    cv2.rectangle(r_image,(x1b, y1b),(x2b,  y2b),(0, 1, 1), 5)\n    cv2.rectangle(result_image,(x1a, y1a),(x2a,  y2a),(0, 1, 1), 5)\n    \n    result_boxes = np.concatenate(result_boxes, 0)\n    np.clip(result_boxes[:, 0:], 0, 2 * s, out=result_boxes[:, 0:])\n    result_boxes = result_boxes.astype(np.int32)\n    result_boxes = result_boxes[np.where((result_boxes[:,2]-result_boxes[:,0])*(result_boxes[:,3]-result_boxes[:,1]) > 0)]\n    \n    for box in boxes.astype(int):\n        cv2.rectangle(image,(box[0], box[1]),(box[2],  box[3]),(0, 0, 1), 3)\n        cv2.rectangle(result_image,(box[0], box[1]),(box[2],  box[3]),(0, 0, 1), 3)\n        \n    for box in result_boxes.astype(int):\n        cv2.rectangle(result_image,(box[0], box[1]),(box[2],  box[3]),(1, 0, 0), 3)\n        \n    ax[i][0].imshow(image)\n    ax[i][1].imshow(r_image)\n    ax[i][2].imshow(result_image)","65797670":"# Mixup #3\n\nusing only for one part of [mosaic](https:\/\/www.kaggle.com\/nvnnghia\/awesome-augmentation), getting fix size 2 random boxes from image1 and image2, then mixing","589c89ff":"# Mixup #2\n\nrandom selection","4901a62d":"**References**\n\n* gc : https:\/\/medium.com\/dmsfordsm\/garbage-collection-in-python-777916fd3189","032fdf92":"# Prepare folds","5793927d":"# Mixup #1\n\nfull images 1:1","507c15d7":"# References\n\n* OFF : https:\/\/daewonyoon.tistory.com\/287"}}