{"cell_type":{"67b9673e":"code","b4777c84":"code","f37366dc":"code","3e10b00f":"code","e84caf3b":"code","0ac66f44":"code","ae0ebabe":"code","6e87ec75":"code","6883c722":"code","27794ab3":"code","fcff7cd8":"code","6e70a792":"code","5ceb91fd":"code","f23cca24":"code","3693e6d6":"code","f8ab6a2e":"code","c4db9432":"code","ce3504b7":"code","40d2920c":"code","60f33fbf":"code","c7d4746e":"code","4a57d897":"code","21496371":"code","f753fcfe":"code","a1bf21dc":"code","6e137bc3":"code","9f83e131":"code","5cd949b6":"code","dcd76713":"code","bc062b32":"code","5297e8fc":"code","48af7873":"code","1ab40724":"code","6dba8c8b":"code","837be235":"code","e1150f04":"code","cd95312a":"code","1286d419":"code","bf268034":"code","7be6ee36":"code","f85ed70d":"code","f01f4931":"code","45616b01":"code","01f6cb5f":"code","15aae738":"code","64ae056a":"code","920cf68f":"code","8a358a37":"code","f0b5702a":"code","e19c329b":"code","7d8267de":"code","4c17950d":"code","fe4d4ed0":"code","d6e452e6":"code","b84d747a":"code","7acf9be0":"code","b666e910":"code","bd4a7c60":"code","2810061c":"code","64f0424d":"code","7435a68c":"code","33c295db":"code","6afc4ddf":"code","48969ed1":"code","c26d5d92":"code","e2e969d7":"code","26655c5e":"code","25d95d82":"code","91ec3e67":"code","630ed31b":"code","5818a774":"code","d3dd17eb":"code","c519e124":"code","d6fd0c0a":"code","dfc938c8":"code","ccadc784":"code","20ca009e":"code","02e3116a":"code","f25a591a":"code","f93ee93a":"code","188d138d":"code","41950057":"code","4b8432e4":"code","92d325e6":"code","cfd77378":"code","84a169a0":"code","556a611a":"code","d8c5e593":"code","67a5206e":"code","6d253ed3":"code","4b32808a":"code","76537059":"code","2ecff09b":"code","2864b979":"code","20dff527":"code","69c19f95":"code","599da014":"code","a83be391":"code","8c88d8f1":"code","1acdc9ca":"code","15811cc0":"code","00dfc979":"code","de3b24ee":"code","fde55fd7":"code","9032be18":"code","a0d9bbb4":"code","66f8e66d":"code","297f12fc":"code","b49ba559":"code","61343ecf":"code","b5edaf07":"code","ca330c11":"code","ed92846e":"code","7708db07":"code","c7bfb3f8":"code","d55b57b8":"code","c2335d29":"code","1c9f433c":"code","215a5cc7":"code","4ecfb9c9":"code","3df4d28c":"code","d06bd6b0":"code","38f8776e":"code","31ebe1e9":"code","d65a628a":"code","74cb9cb9":"code","e661d802":"code","b9c71b93":"code","4e18651a":"code","293097b5":"code","93eee7f3":"code","e534780a":"code","2e72a0c5":"code","648b4494":"code","a53a848f":"code","17fce95b":"code","138ddeb7":"code","bb80b421":"code","62dfe691":"code","0d0698ae":"code","6488755c":"code","ee47a06d":"code","94efa0a3":"code","5e36b0a1":"code","6fb8b18c":"code","82617208":"code","4a912475":"code","598e6159":"code","a5493f7f":"code","1b41d587":"code","299531fe":"code","17667133":"code","3b556e48":"code","1edfd74e":"code","a42db719":"code","f816bbc9":"code","2342be58":"code","b4fadcd8":"code","5149d16f":"code","7b7f94d9":"code","d2eebfa6":"code","dd7e3162":"code","0d11d4f3":"code","0c9fcb1c":"code","da6019ea":"code","4ef66394":"code","e8c718aa":"code","54f99296":"code","6f513090":"code","1cbfad94":"code","61e37295":"code","f6787c43":"code","0e04afb4":"markdown","12045fa3":"markdown","ae7cae2b":"markdown","11c41e03":"markdown","e25f50fa":"markdown","07cb9e98":"markdown","80d5b482":"markdown","a68821d2":"markdown","4b96a75e":"markdown","ab67ef49":"markdown","ed5146e3":"markdown","efca0a7e":"markdown","52c35f5a":"markdown","b9f960e0":"markdown","28216113":"markdown","fa7f1cf8":"markdown","78eb8a67":"markdown","4bbed53d":"markdown","2f502a32":"markdown","134daea2":"markdown","5fd304ec":"markdown","5136ab0c":"markdown","d8195cfa":"markdown","4da7cdef":"markdown","c4f665c3":"markdown","06e8ada9":"markdown"},"source":{"67b9673e":"!git clone https:\/\/github.com\/MIC-DKFZ\/nnUNet.git\n!git clone https:\/\/github.com\/NVIDIA\/apex\n!pip install -e .\/nnUNet\n!pip install --upgrade git+https:\/\/github.com\/nanohanno\/hiddenlayer.git@bugfix\/get_trace_graph#egg=hiddenlayer","b4777c84":"!pip install git+https:\/\/github.com\/shijianjian\/EfficientNet-PyTorch-3D\n!pip install efficientnet_pytorch","f37366dc":"import sys\nsys.path.append('..\/input\/efficientnetpyttorch3d\/EfficientNet-PyTorch-3D')\nfrom efficientnet_pytorch_3d import EfficientNet3D\npackage_path = \"..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch\/EfficientNet-PyTorch-master\/\"\nsys.path.append(package_path)","3e10b00f":"import os\nimport glob\nimport json\nimport glob\nimport random\nimport collections\nimport re\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport time\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport efficientnet_pytorch\nfrom sklearn.model_selection import StratifiedKFold\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom matplotlib import pyplot\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\nfrom sklearn import metrics\nimport optuna\n# from boostaroota import BoostARoota\nfrom sklearn.metrics import log_loss\nfrom optuna.samplers import TPESampler\nimport functools\nfrom functools import partial\nimport xgboost as xgb\nfrom sklearn.metrics import confusion_matrix, average_precision_score, recall_score, accuracy_score, f1_score\nimport pylab as pl\nfrom tensorflow import keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nimport torch.nn as nn\nimport tensorflow\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import Sequence\nfrom random import shuffle\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.metrics import AUC\nimport math\nimport joblib\nDEVICE = \"GPU\"","e84caf3b":"# Download pretrained Task001_BrainTumour, and setting up the nnUnet environment.\nos.mkdir('.\/nnUNet_raw_data_base')\nos.mkdir('.\/nnUNet_raw_data_base\/nnUNet_raw_data')\nos.mkdir('.\/RESULTS_FOLDER')\nos.environ['nnUNet_raw_data_base'] = '.\/nnUNet_raw_data_base\/nnUNet_raw_data'\nos.environ['RESULTS_FOLDER'] = '.\/RESULTS_FOLDER'\nos.environ['nnUNet_preprocessed'] = '.\/nnUNet_preprocessed'\n!nnUNet_download_pretrained_model Task001_BrainTumour","0ac66f44":"if os.path.exists(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n    data_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"..\/input\/efficientnetpyttorch3d\/EfficientNet-PyTorch-3D\"\nelse:\n    data_directory = '\/media\/roland\/data\/kaggle\/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"EfficientNet-PyTorch-3D\"","ae0ebabe":"train_df = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv\")\ntrain_df","6e87ec75":"plt.figure(figsize=(5, 5))\nsns.countplot(data=train_df, x=\"MGMT_value\");","6883c722":"def crop_image_pixel_array(arr, margin = 5, crop = True):\n\n    arr_formatted = arr.copy()\n    arr_formatted = arr_formatted - np.min(arr_formatted)\n    if np.max(arr_formatted) != 0:\n        arr_formatted = arr_formatted \/ np.max(arr_formatted)\n\n    percent_pixels = ((arr_formatted>0).sum()\/(arr_formatted.shape[0]*arr_formatted.shape[1])) * 100\n    \n    if (crop) & (percent_pixels>5):\n        # Get rows containing brain portion\n        first_row_index = list([arr_formatted.sum(axis = 1)>0][0])\n        first_row_index = first_row_index.index(True) - margin\n        if first_row_index<0:\n            first_row_index = 0\n\n        last_row_index = list([arr_formatted.sum(axis = 1)>0][0])\n        last_row_index.reverse()\n        last_row_index = (len(last_row_index) - last_row_index.index(True)) + margin\n        if last_row_index>arr_formatted.shape[0]:\n            last_row_index = arr_formatted.shape[0]\n\n        # Get columns containing brain portion\n        first_column_index = list([arr_formatted.sum(axis = 0)>0][0])\n        first_column_index = first_column_index.index(True) - margin\n        if first_column_index<0:\n            first_column_index = 0\n\n        last_column_index = list([arr_formatted.sum(axis = 0)>0][0])\n        last_column_index.reverse()\n        last_column_index = (len(last_column_index) - last_column_index.index(True)) + margin\n        if last_column_index>arr_formatted.shape[1]:\n            last_column_index = arr_formatted.shape[1]\n\n        num_rows = last_row_index - first_row_index\n        num_columns = last_column_index - first_column_index\n        \n        if ((num_rows<arr_formatted.shape[0]) & (num_rows<arr_formatted.shape[1])) & ((num_columns<arr_formatted.shape[0]) & (num_columns<arr_formatted.shape[1])):\n            if (num_columns > num_rows):\n                if arr_formatted.shape[0] < (last_row_index+(num_columns-num_rows)):\n                    last_row_index = arr_formatted.shape[0]\n                    first_row_index = (last_row_index - num_columns)\n                else:\n                    last_row_index = last_row_index+(num_columns-num_rows)\n            elif (num_columns < num_rows):\n                if arr_formatted.shape[1] < (last_column_index+(num_rows-num_columns)):\n                    last_column_index = arr_formatted.shape[1]\n                    first_column_index = (last_column_index - num_rows)\n                else:\n                    last_column_index = last_column_index+(num_rows-num_columns)\n\n            arr_crop = arr[first_row_index:last_row_index,:]\n            arr_crop = arr_crop[:,first_column_index:last_column_index]   \n        else:\n            first_row_index = np.NaN\n            last_row_index = np.NaN\n            first_column_index = np.NaN\n            last_column_index = np.NaN\n            arr_crop = arr.copy()\n    \n    else:\n        first_row_index = np.NaN\n        last_row_index = np.NaN\n        first_column_index = np.NaN\n        last_column_index = np.NaN\n        arr_crop = arr.copy()\n    return arr_crop, [first_row_index,last_row_index,first_column_index,last_column_index]","27794ab3":"def get_image_plane(data):\n    x1, y1, _, x2, y2, _ = [round(j) for j in data.ImageOrientationPatient]\n    cords = [x1, y1, x2, y2]\n\n    if cords == [1, 0, 0, 0]:\n        return 'Coronal'\n    elif cords == [1, 0, 0, 1]:\n        return 'Axial'\n    elif cords == [0, 1, 0, 0]:\n        return 'Sagittal'\n    else:\n        return 'Unknown'","fcff7cd8":"def get_voxel(dcm_path):\n    imgs = []\n    positions = []\n    \n    img = pydicom.dcmread(str(dcm_path))\n    imgs.append(img.pixel_array)\n    positions.append(img.ImagePositionPatient)\n\n    plane = get_image_plane(img)\n    voxel = np.stack(imgs)\n    \n    # reorder planes if needed and rotate voxel\n    if plane == \"Coronal\":\n        if positions[0][1] < positions[-1][1]:\n            voxel = voxel[::-1]\n        voxel = voxel.transpose((1, 0, 2))\n    elif plane == \"Sagittal\":\n        if positions[0][0] < positions[-1][0]:\n            voxel = voxel[::-1]\n        voxel = voxel.transpose((1, 2, 0))\n        voxel = np.rot90(voxel, 2, axes=(1, 2))\n    elif plane == \"Axial\":\n        if positions[0][2] > positions[-1][2]:\n            voxel = voxel[::-1]\n        voxel = np.rot90(voxel, 2)\n        \n    min_index = np.argmin(voxel.shape)\n    \n    if min_index == 0:\n        voxel = voxel[0,:,:]\n    elif min_index == 1:\n        voxel = voxel[:,0,:]\n    elif min_index == 2:\n        voxel = voxel[:,:,0]\n    \n    return voxel, plane","6e70a792":"def load_dicom_for_saving_into_png(path, voi_lut = False, fix_monochrome = True, rotate = 0):\n    dicom = pydicom.read_file(path)\n    data, plane = get_voxel(path)\n    \n    if voi_lut:\n        data = apply_voi_lut(data, dicom)\n    \n    if rotate > 0:\n        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        data = cv2.rotate(data, rot_choices[rotate])\n    \n    # MONOCHROME1 indicates that the greyscale ranges from bright to dark with ascending pixel values, whereas MONOCHROME2 ranges from dark to bright with ascending pixel values\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n        \n    data = (data * 255).astype(np.uint8)\n    return data","5ceb91fd":"from matplotlib import animation, rc\nrc('animation', html='jshtml')\n\ndef create_animation(ims):\n    fig = plt.figure()\n    plt.axis('off')\n    im = plt.imshow(ims[0], cmap=\"gray\")\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000\/\/24)\n\ndef get_gray(org_img):\n    gray_img=cv2.cvtColor(org_img.copy(),cv2.COLOR_RGB2GRAY)\n    return gray_img\n\ndef get_RGB(gray_img):\n    rgb_img=cv2.cvtColor(gray_img.copy(),cv2.COLOR_GRAY2RGB)\n    return rgb_img\n\ndef get_threshold(org_img,blur=False,erode=False,dilate=False):\n    gray_img=get_gray(org_img.copy())\n    if blur:\n        img=cv2.GaussianBlur(gray_img.copy(), (5, 5), 0)\n    img=cv2.threshold(img,5,255,cv2.THRESH_BINARY)[1]\n    if erode:\n        img=cv2.erode(img, None, iterations=2)\n    if dilate:\n        img=cv2.dilate(img, None, iterations=2)\n    return img\n\ndef get_contours(th_img):\n    cnts,_ = cv2.findContours(th_img.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n    return cnts\n   \ndef edge_smoothing(org_img,cnts):\n    gray_img=get_gray(org_img.copy())\n    if len(cnts)==0:  \n        return gray_img\n    c = max(cnts, key=cv2.contourArea)\n    black_img=np.zeros_like(gray_img)\n    black_cnt=cv2.drawContours(black_img.copy(),c,-1, (255, 255, 255), 2)\n    black_cnt=cv2.dilate(black_cnt.copy(), None, iterations=10)\n    white_cnt=cv2.bitwise_not(black_cnt.copy())\n    white_cnt=get_RGB(white_cnt)\n    smooth_img=cv2.bitwise_and(white_cnt.copy(),org_img.copy())\n    return smooth_img\n\ndef get_iou(bb1, bb2):\n    assert bb1[0] < bb1[2]\n    assert bb1[1] < bb1[3]\n    assert bb2[0] < bb2[2]\n    assert bb2[1] < bb2[3]\n    x_left = max(bb1[0], bb2[0])\n    y_top = max(bb1[1], bb2[1])\n    x_right = min(bb1[2], bb2[2])\n    y_bottom = min(bb1[3], bb2[3])\n    if x_right < x_left or y_bottom < y_top:\n        return 0.0\n\n    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n    iou = intersection_area \/ float(bb1_area + bb2_area - intersection_area)\n    assert iou >= 0.0\n    assert iou <= 1.0\n    return iou\n\ndef check_overlapping(prev_cnt,curr_cnt):\n    x,y,w,h=cv2.boundingRect(prev_cnt)\n    bb1=[x,y,x+w,y+h]\n    x,y,w,h=cv2.boundingRect(curr_cnt)\n    bb2=[x,y,x+w,y+h]\n    iou=get_iou(bb1,bb2)\n    return iou\n    \n\ndef load_patient_images(path,threshold=False,roi_threshold=False,matchpattern=False,template_path=None):\n    t_paths = sorted(\n        glob.glob(os.path.join(path, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    templates=[]\n    if not template_path is None:\n        for t_path in template_path:\n            templates.append(cv2.imread(t_path))\n    \n    images = []\n    for filename in t_paths:\n        imageio.imsave('temp_png.png',load_dicom_for_saving_into_png(filename))\n        data = cv2.imread('temp_png.png')\n        if data.max() == 0:\n            continue\n        images.append(data)\n    \n    mid_idx=len(images)\/\/2\n    th_middle_image=get_threshold(images[mid_idx].copy(),blur=True,erode=True,dilate=True)\n    x1,y1,w1,h1=cv2.boundingRect(th_middle_image)\n    print('-->',x1,y1,w1,h1)\n    max_area=w1*h1\n    \n    images=np.array(images)\n    new_images=[]\n    if images[0].shape[0]<=256 or images[1].shape[0]<=256:\n        t_size=1\n    elif images[0].shape[0]>=500 or images[1].shape[0]>=500:\n        t_size=3\n    else:\n        t_size=2\n    print('text size: ',t_size)\n     \n    prev_cnt=0\n    initialize_prev_cnt=False\n    for i,data in enumerate(images):\n        th_data=get_threshold(data.copy(),blur=True,erode=True,dilate=True)\n        x,y,w,h=cv2.boundingRect(th_data)\n        area=w*h\n        ratio=area\/max_area\n        if ratio<0.4:\n            continue\n            \n        org_cnts=get_contours(th_data.copy())\n        if org_cnts:\n            org_max = max(org_cnts, key=cv2.contourArea)\n            org_cnts_area=cv2.contourArea(org_max)\n        \n        if matchpattern:\n            image=data.copy()\n            comm_image=image.copy()\n            result=cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n            (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(result)\n            (startX, startY) = maxLoc\n            endX = startX + template.shape[1]\n            endY = startY + template.shape[0]\n        \n        if roi_threshold:\n            image=data.copy()\n            g_image=cv2.cvtColor(image.copy(),cv2.COLOR_BGR2GRAY)\n            thresh=g_image.mean()+((g_image.max()-g_image.mean())\/\/3)\n            th_data=cv2.threshold(g_image,thresh,g_image.max(),cv2.THRESH_BINARY)[1]\n            g_image=cv2.putText(g_image,f\"{i}\",(20,25),3,1,(255,255,0),2) \n            data=np.hstack([g_image,th_data])   \n        \n        if threshold:\n            image=data.copy()  \n            \n            g_image=cv2.cvtColor(image.copy(),cv2.COLOR_BGR2GRAY)\n            mean_values=g_image[np.nonzero(g_image)]\n            thresh=mean_values.mean()+((mean_values.max()-mean_values.mean())\/\/2)\n            smooth_image=edge_smoothing(image,org_cnts)\n            smooth_image=cv2.putText(smooth_image,f\"{i}\",(20,25),t_size,1,(thresh+1,thresh+1,thresh+1),2)\n            gray_smooth_image=get_gray(smooth_image)\n            \n            th_image=cv2.threshold(gray_smooth_image.copy(),thresh,g_image.max(),cv2.THRESH_BINARY)[1]\n            cnts,_ = cv2.findContours(th_image.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n            c = max(cnts, key=cv2.contourArea)\n            data=cv2.drawContours(image.copy(),c,-1, (0, 255, 255), 2)\n\n        new_images.append(data)        \n               \n    return new_images\n\ndef get_images(i,mri_type,threshold=False,roi_threshold=False,matchpattern=False,template_path=None):\n    patient_id=str(train_df['BraTS21ID'][i]).zfill(5)\n    mgmt=train_df['MGMT_value'][i]\n    path=f'{data_directory}\/train\/{patient_id}\/{mri_type}'\n    print('Path: ',path)\n    print('# Images: ',len(os.listdir(path)))\n    print('MGMT: ',mgmt)\n    images=load_patient_images(path,threshold,roi_threshold,matchpattern,template_path)\n    print(np.array(images).shape)\n    return images","f23cca24":"import imageio \ni=80\nmri_type='FLAIR'\nimages=get_images(i,mri_type,threshold=True)\ncreate_animation(images)","3693e6d6":"def load_dicom(path, voi_lut = False, fix_monochrome = True, rotate = 0):\n    dicom = pydicom.read_file(path)\n#     data, plane = get_voxel(path)\n    data = dicom.pixel_array\n    \n    if voi_lut:\n        data = apply_voi_lut(data, dicom)\n    \n    if rotate > 0:\n        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        data = cv2.rotate(data, rot_choices[rotate])\n    \n    # MONOCHROME1 indicates that the greyscale ranges from bright to dark with ascending pixel values, whereas MONOCHROME2 ranges from dark to bright with ascending pixel values\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n#     data = data - np.min(data)\n#     if np.max(data) != 0:\n#         data = data \/ np.max(data)\n        \n#     data = (data * 255).astype(np.uint8)\n    return data","f8ab6a2e":"def visualize_sample(\n    brats21id, \n    slice_i,\n    mgmt_value,\n    types=(\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"), \n    rotate = 0\n):\n    plt.figure(figsize=(16, 5))\n    patient_path = os.path.join(\n        \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/\", \n        str(brats21id).zfill(5),\n    )\n    for i, t in enumerate(types, 1):\n        t_paths = sorted(\n            glob.glob(os.path.join(patient_path, t, \"*\")), \n            key=lambda x: int(x[:-4].split(\"-\")[-1]),\n        )\n        data = load_dicom(t_paths[int(len(t_paths) * slice_i)], rotate = rotate)\n#         if data.sum()!=0:\n#             data = crop_image_pixel_array(data, crop = False)\n        data = cv2.resize(data, (256, 256)) \/ 255\n        plt.subplot(1, 4, i)\n        plt.imshow(data, cmap=\"gray\")\n        plt.title(f\"{t}\", fontsize=16)\n        plt.axis(\"off\")\n\n    plt.suptitle(f\"MGMT_value: {mgmt_value}\", fontsize=16)\n    plt.show()","c4db9432":"print('Before cropping')\ndata = load_dicom('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/FLAIR\/Image-101.dcm', rotate = 0)\nprint(data.shape)\nplt.imshow(data, cmap=\"gray\")","ce3504b7":"print('After cropping')\ndata = load_dicom('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/FLAIR\/Image-101.dcm', rotate = 0)\ndata,_ = crop_image_pixel_array(data, crop = True)\nprint(data.shape)\nplt.imshow(data, cmap=\"gray\")","40d2920c":"NUM_IMAGES = 64\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=256, mri_type=\"FLAIR\", split=\"train\", rotate=0):\n\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    sum_pixels_across_files = [load_dicom(x).sum() for x in files]\n    files_with_pixels = [files[x] for x in range(0, len(sum_pixels_across_files)) if sum_pixels_across_files[x]>0]\n    middle = len(files_with_pixels)\/\/2\n    num_imgs2 = num_imgs\/\/2\n\n    if len(files_with_pixels)>=num_imgs:\n#         best_interval = int(len(files_with_pixels)\/num_imgs)\n        best_interval = 1\n        p1 = max(0, middle - best_interval*num_imgs2)\n        p2 = min(len(files), middle + best_interval*num_imgs2)    \n        selected_files = files_with_pixels[p1:p2:best_interval]\n    else:\n        p1 = max(0, middle - num_imgs2)\n        p2 = min(len(files), middle + num_imgs2)  \n        selected_files = files_with_pixels[p1:p2]\n    \n    images_list_array = [load_dicom(f, rotate=rotate) for f in selected_files]\n    \n    #Cropping\n    mean_image_for_cropping = np.array(images_list_array).mean(axis = 0)\n    img_cropped,dim_for_cropping = crop_image_pixel_array(mean_image_for_cropping)\n    first_row_index = dim_for_cropping[0]\n    last_row_index = dim_for_cropping[1]\n    first_column_index = dim_for_cropping[2]\n    last_column_index = dim_for_cropping[3]\n    if ((not pd.isnull(first_row_index)) & (not pd.isnull(last_row_index)) & (not pd.isnull(first_column_index)) & (not pd.isnull(last_column_index))):\n        images_list_array = [f[first_row_index:last_row_index,first_column_index:last_column_index] for f in images_list_array]\n\n    images_list_array = [cv2.resize(f, (img_size, img_size)) for f in images_list_array]\n    img3d = np.stack(images_list_array).T\n\n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d \/ np.max(img3d)\n\n    return np.expand_dims(img3d,0)\n\na = load_dicom_images_3d(\"00012\",mri_type = 'FLAIR')\nprint(a.shape)\nprint(np.min(a), np.max(a), np.mean(a), np.median(a))\nprint(a.shape)\nplt.imshow(a[0,:,:,10], cmap=\"gray\")","60f33fbf":"for i in random.sample(range(train_df.shape[0]), 10):\n    _brats21id = train_df.iloc[i][\"BraTS21ID\"]\n    _mgmt_value = train_df.iloc[i][\"MGMT_value\"]\n    visualize_sample(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.5)","c7d4746e":"from matplotlib import animation, rc\nrc('animation', html='jshtml')\n\ndef create_animation(ims):\n    fig = plt.figure(figsize=(6, 6))\n    plt.axis('off')\n    im = plt.imshow(ims[0], cmap=\"gray\")\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000\/\/24)","4a57d897":"def load_dicom_line(path, crop = False):\n    t_paths = sorted(\n        glob.glob(os.path.join(path, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    images = []\n    for filename in t_paths:\n        data = load_dicom(filename)\n        \n        data = data - np.min(data)\n        if np.max(data) != 0:\n            data = data \/ np.max(data)\n        \n        if crop:\n            if data.sum()!=0:\n                data = crop_image_pixel_array(data, crop = False)\n        \n        data = cv2.resize(data, (256, 256))\n        if data.max() == 0:\n            continue\n        images.append(data)\n        \n    return images","21496371":"images = load_dicom_line(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/FLAIR\")\ncreate_animation(images)","f753fcfe":"images = load_dicom_line(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/T1w\")\ncreate_animation(images)","a1bf21dc":"images = load_dicom_line(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/T1wCE\")\ncreate_animation(images)","6e137bc3":"images = load_dicom_line(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/T2w\")\ncreate_animation(images)","9f83e131":"from sklearn.metrics import roc_auc_score, roc_curve, auc\n\nlist_y_true = [\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n]\nlist_y_pred = [\n    [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n    [0.9, 0.9, 0.9, 0.9, 0.1, 0.9, 0.9, 0.1, 0.9, 0.1, 0.1, 0.5],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], #  IMBALANCE\n]\n\nfor y_true, y_pred in zip(list_y_true, list_y_pred):\n    fpr, tpr, _ = roc_curve(y_true, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(5, 5))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([-0.01, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()","5cd949b6":"submission = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv\")\nsubmission","dcd76713":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\n# set_seed(42)\nset_seed(3407)","bc062b32":"df = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv\")\ndf = df[~(df['BraTS21ID'].isin([109, 123, 709]))].reset_index(drop = True)\ndf_train, df_valid = sk_model_selection.train_test_split(\n    df, \n    test_size=0.2, \n    random_state=42, \n    stratify=df[\"MGMT_value\"])","5297e8fc":"df_train.head()","48af7873":"!mkdir -p .\/RESULTS_FOLDER\/nnUNet\/2d\/image_raw\n!cp ..\/input\/brats2021dataset\/nnUNet_raw_data_base\/nnUNet_raw_data\/Task101_BrainTumour\/imagesTs\/BRATS_188_0000.nii .\/RESULTS_FOLDER\/nnUNet\/2d\/image_raw\/BRATS_188_0000.nii.gz\n!cp ..\/input\/brats2021dataset\/nnUNet_raw_data_base\/nnUNet_raw_data\/Task101_BrainTumour\/imagesTs\/BRATS_188_0001.nii .\/RESULTS_FOLDER\/nnUNet\/2d\/image_raw\/BRATS_188_0001.nii.gz\n!cp ..\/input\/brats2021dataset\/nnUNet_raw_data_base\/nnUNet_raw_data\/Task101_BrainTumour\/imagesTs\/BRATS_188_0002.nii .\/RESULTS_FOLDER\/nnUNet\/2d\/image_raw\/BRATS_188_0002.nii.gz\n!cp ..\/input\/brats2021dataset\/nnUNet_raw_data_base\/nnUNet_raw_data\/Task101_BrainTumour\/imagesTs\/BRATS_188_0003.nii .\/RESULTS_FOLDER\/nnUNet\/2d\/image_raw\/BRATS_188_0003.nii.gz\n!nnUNet_predict -i .\/RESULTS_FOLDER\/nnUNet\/2d\/image_raw -o .\/RESULTS_FOLDER\/nnUNet\/2d\/ -t \"001\" -tr nnUNetTrainerV2 -m 2d","1ab40724":"!ls .\/RESULTS_FOLDER\/nnUNet\/2d\/image_raw\/","6dba8c8b":"path_raw=\"..\/input\/brats2021dataset\/nnUNet_raw_data_base\/nnUNet_raw_data\/Task101_BrainTumour\/imagesTs\/BRATS_188_0000.nii\"\npath=\".\/RESULTS_FOLDER\/nnUNet\/2d\/\"\n\nimport nibabel as nib\nplt.figure(figsize=(12,6))\nplt.subplot(121)\nflair_nib = nib.load(path_raw)\nflair_nib_array = flair_nib.get_fdata()\nplt.imshow(flair_nib_array[:,:,flair_nib_array.shape[2]\/\/2], cmap = 'gray')\nplt.subplot(122)\nflair_nib = nib.load(path+\"BRATS_188.nii.gz\")\nflair_nib_array = flair_nib.get_fdata()\nplt.imshow(flair_nib_array[:,:,flair_nib_array.shape[2]\/\/2], cmap = 'gray')","837be235":"import SimpleITK as sitk\nfrom skimage.transform import resize\nfrom tqdm import tqdm\nfrom os.path import join\nfrom fastai.vision.all import *","e1150f04":"!mkdir -p .\/test\/post\/\nreader = sitk.ImageSeriesReader()\nreader.LoadPrivateTagsOn()\ntrain_path=\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/\"\n# studi_id=[\"00000\",\"00002\",\"00003\"]\nstudi_id = [str(x).zfill(5) for x in df[df['BraTS21ID'].isin([840])]['BraTS21ID'].unique().tolist()]\nmri_types = [\"FLAIR\",\"T1w\",\"T1wCE\",\"T2w\"]\npixel_size_h=240\npixel_size_w=240\ninner_count=0\n\ndef dicom2nifti(image_dir, out_dir, save=True):\n    \"given a dicom directory, loads them into single file and can save it as .nii file\"\n    reader = sitk.ImageSeriesReader()\n    reader.LoadPrivateTagsOn()\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(str(image_dir))\n    reader.SetFileNames(filenamesDICOM)\n    img = reader.Execute()\n    img = sitk.Cast(img, sitk.sitkFloat32)\n    \n    if save:\n        sitk.WriteImage(img, f'{out_dir}\/{image_dir.parent.name}.nii')\n    else:\n        return img\n\ndef resample_nifti(image_dir, ref_image, fn, save=True):\n    \"resample using a reference image\"\n\n    image = sitk.ReadImage(str(image_dir), sitk.sitkFloat32)\n    \n    initial_transform = sitk.CenteredTransformInitializer(ref_image, \n                                                          image, \n                                                          sitk.Euler3DTransform(), \n                                                          sitk.CenteredTransformInitializerFilter.GEOMETRY)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetReferenceImage(ref_image)\n    resampler.SetInterpolator(sitk.sitkLinear)\n    resampler.SetTransform(initial_transform)\n    resampler.SetOutputSpacing(ref_image.GetSpacing())\n    resampler.SetSize((ref_image.GetSize()))\n    resampler.SetOutputDirection(ref_image.GetDirection())\n    resampler.SetOutputOrigin(ref_image.GetOrigin())\n    resampler.SetDefaultPixelValue(image.GetPixelIDValue())\n    resamped_image = resampler.Execute(image)\n    \n    if save:\n        sitk.WriteImage(resamped_image, fn)\n\n    return resamped_image\n\nref_image = sitk.ReadImage('..\/input\/sri24-dataset\/sri24\/spgr.nii', sitk.sitkFloat32)\n!mkdir -p .\/tmp\/T1w\n!mkdir -p .\/tmp\/T1wCE\n!mkdir -p .\/tmp\/T2w\n!mkdir -p .\/tmp\/FLAIR\n\nfor c in tqdm(studi_id):\n    path=join(train_path,c)\n    samples = [Path(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/\"+c)]\n    path_train_t2w, path_train_t1wce,path_train_t1w,path_train_flair = [],[],[],[]\n    for each in samples:\n        path_train_t2w.append(each.ls()[0])\n        path_train_t1wce.append(each.ls()[1])\n        path_train_t1w.append(each.ls()[2])\n        path_train_flair.append(each.ls()[3])\n    for fn in path_train_t1w: dicom2nifti(fn, \".\/tmp\/T1w\/\")\n    for fn in path_train_t1wce: dicom2nifti(fn, \".\/tmp\/T1wCE\/\")\n    for fn in path_train_t1w: dicom2nifti(fn, \".\/tmp\/T2w\/\")\n    for fn in path_train_flair: dicom2nifti(fn, \".\/tmp\/FLAIR\/\")      \n    for b in tqdm(mri_types):\n        path=join(train_path,c)\n        file=[]\n        for each in  [Path(join('.\/tmp\/',b))]:\n            file.append(each.ls()[0])        \n        for fn2 in file:\n            pat_id = str(fn2).split('\/')[-1].split('.')[0]\n            if b==\"FLAIR\":\n                final_fn = f\".\/test\/post\/\"+pat_id+\"_0000.nii.gz\"\n            if b==\"T1w\":\n                final_fn = f\".\/test\/post\/\"+pat_id+\"_0001.nii.gz\"\n            if b==\"T1wCE\":\n                final_fn = f\".\/test\/post\/\"+pat_id+\"_0002.nii.gz\"    \n            if b==\"T2w\":\n                final_fn = f\".\/test\/post\/\"+pat_id+\"_0003.nii.gz\"\n            resample_nifti(fn2, ref_image, final_fn, True)\n            os.remove(str(fn2))","cd95312a":"# import shutil\n# shutil.rmtree(\".\/RESULTS_FOLDER\")\n# shutil.rmtree(\".\/tmp\")\n# shutil.rmtree(\".\/apex\")\n# shutil.rmtree(\".\/nnUNet\")\n# shutil.rmtree(\".\/nnUNet_preprocessed\")","1286d419":"!nnUNet_predict -i .\/test\/post\/ -o .\/RESULTS_FOLDER\/nnUNet\/2d\/ -t 001 -tr nnUNetTrainerV2 -m 3d_fullres --disable_tta","bf268034":"# !ls .\/RESULTS_FOLDER\/nnUNet\/2d\/","7be6ee36":"# !ls .\/test\/post\/","f85ed70d":"def get_array(fn):\n    \"opens .nii file and return the array\"\n    img = sitk.ReadImage(str(fn))\n    imgd = sitk.GetArrayFromImage(img)\n    return imgd\n\ndef plot_slice(imgd, sli):\n    \"given an image of shape slices x height x width, plots a slice\"\n    plt.imshow(imgd[sli], cmap='gray')\n    plt.axis('off')\n    \ndef get_array_plot(fn, sli):\n    imgd = get_array(fn)\n    plot_slice(imgd, sli)","f01f4931":"get_array_plot(f'.\/RESULTS_FOLDER\/nnUNet\/2d\/00003.nii.gz', 125)","45616b01":"get_array_plot(f'.\/test\/post\/00003_0000.nii.gz', 125)","01f6cb5f":"get_array_plot(f'.\/test\/post\/00003_0001.nii.gz', 125)","15aae738":"get_array_plot(f'.\/test\/post\/00003_0002.nii.gz', 125)","64ae056a":"get_array_plot(f'.\/test\/post\/00003_0003.nii.gz', 125)","920cf68f":"x = 0\nslice_num = 70\ndisplay(df[df['BraTS21ID']==x])\nplt.figure(figsize=(30, 5))\nplt.subplot(1, 5,1)\nget_array_plot(f'.\/RESULTS_FOLDER\/nnUNet\/2d\/{str(x).zfill(5)}.nii.gz', slice_num)\nplt.subplot(1, 5,2)\nget_array_plot(f'.\/test\/post\/{str(x).zfill(5)}_0000.nii.gz', slice_num) \nplt.subplot(1, 5,3)\nget_array_plot(f'.\/test\/post\/{str(x).zfill(5)}_0001.nii.gz', slice_num)\nplt.subplot(1, 5,4)\nget_array_plot(f'.\/test\/post\/{str(x).zfill(5)}_0002.nii.gz', slice_num)\nplt.subplot(1, 5,5)\nget_array_plot(f'.\/test\/post\/{str(x).zfill(5)}_0003.nii.gz', slice_num)","8a358a37":"imgd = get_array(f'.\/RESULTS_FOLDER\/nnUNet\/2d\/{str(x).zfill(5)}.nii.gz')\nplt.figure(figsize=(30, 5))\nimg_slice = imgd[slice_num]\nimg_slice = imgd[slice_num]\nimg_slice[img_slice > 0] = 1\n\nplt.figure(figsize=(30, 5))\n\nplt.subplot(1, 4,1)\ntemp = get_array(f'.\/test\/post\/{str(x).zfill(5)}_0000.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,2)\ntemp = get_array(f'.\/test\/post\/{str(x).zfill(5)}_0001.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,3)\ntemp = get_array(f'.\/test\/post\/{str(x).zfill(5)}_0002.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,4)\ntemp = get_array(f'.\/test\/post\/{str(x).zfill(5)}_0003.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\nplt.show()","f0b5702a":"imgd = get_array(f'.\/RESULTS_FOLDER\/nnUNet\/2d\/{str(x).zfill(5)}.nii.gz')\nplt.figure(figsize=(30, 5))\nimg_slice = imgd[slice_num]\nimg_slice = imgd[slice_num]\n# img_slice[img_slice > 0] = 1\n\nplt.figure(figsize=(30, 5))\n\nplt.subplot(1, 4,1)\ntemp = get_array(f'.\/test\/post\/{str(x).zfill(5)}_0000.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,2)\ntemp = get_array(f'.\/test\/post\/{str(x).zfill(5)}_0001.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,3)\ntemp = get_array(f'.\/test\/post\/{str(x).zfill(5)}_0002.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\n\nplt.subplot(1, 4,4)\ntemp = get_array(f'.\/test\/post\/{str(x).zfill(5)}_0003.nii.gz')\nplt.imshow(img_slice*temp[slice_num], cmap = 'gray')\nplt.show()","e19c329b":"image_data = cv2.imread('..\/input\/ct-head-scans\/Necrosis\/Necrosis14.jpg')\nprint(image_data.shape)\nplt.imshow(image_data)","7d8267de":"plt.imshow(cv2.resize(image_data,(256,256)))","4c17950d":"image_data.shape, image_data.mean(), image_data.min(), image_data.max()","fe4d4ed0":"image_data[:,:,0].sum(), image_data[:,:,1].sum(), image_data[:,:,2].sum()","d6e452e6":"data_tumor_identification = pd.DataFrame(data=None, columns = ['ID','Tumor flag'])\ndata_tumor_identification['ID'] = ['Tumor\/' + x for x in os.listdir('..\/input\/ct-head-scans\/Tumor')]\ndata_tumor_identification['Tumor flag'] = 1\ndata = pd.DataFrame(data=None, columns = ['ID','Tumor flag'])\ndata['ID'] = ['Control\/' + x for x in os.listdir('..\/input\/ct-head-scans\/Control')]\ndata['Tumor flag'] = 0\ndata_tumor_identification = pd.concat([data_tumor_identification, data], axis = 0).reset_index(drop = True)\ndata = pd.DataFrame(data=None, columns = ['ID','Tumor flag'])\ndata['ID'] = ['Necrosis\/' + x for x in os.listdir('..\/input\/ct-head-scans\/Necrosis')]\ndata['Tumor flag'] = 0\ndata_tumor_identification = pd.concat([data_tumor_identification, data], axis = 0).reset_index(drop = True)","b84d747a":"print(data_tumor_identification.shape)\ndata_tumor_identification.head()","7acf9be0":"data_tumor_identification = data_tumor_identification.sample(frac=1).reset_index(drop=True)\ndata_tumor_identification.head()","b666e910":"plt.figure(figsize=(5, 5))\nsns.countplot(data=data_tumor_identification, x=\"Tumor flag\");","bd4a7c60":"train_data_tumor_identification, valid_data_tumor_identification = sk_model_selection.train_test_split(\n    data_tumor_identification, \n    test_size=0.2, \n    random_state=42, \n    stratify=data_tumor_identification[\"Tumor flag\"])","2810061c":"print('Training data')\nplt.figure(figsize=(5, 5))\nsns.countplot(data=train_data_tumor_identification, x=\"Tumor flag\");","64f0424d":"print('Validation data')\nplt.figure(figsize=(5, 5))\nsns.countplot(data=valid_data_tumor_identification, x=\"Tumor flag\");","7435a68c":"def load_data_brain_tumor_identification(data):\n    paths = ['..\/input\/ct-head-scans\/'+x for x in data['ID']]\n    image_data_list = []\n    for path in paths:\n        image_data = cv2.imread(path)[:,:,0].astype('float32')\n        image_data = cv2.resize(image_data,(256,256))\/255\n        image_data_list.append(image_data.reshape((256,256,1)))\n    return image_data_list, data['Tumor flag']\n\ntrain_batches_tumor_identification = load_data_brain_tumor_identification(train_data_tumor_identification)\nvalid_batches_tumor_identification = load_data_brain_tumor_identification(valid_data_tumor_identification)","33c295db":"print(len(train_batches_tumor_identification[0]))\ntrain_batches_tumor_identification[0][0].shape, train_batches_tumor_identification[1].shape","6afc4ddf":"np.array(train_batches_tumor_identification[0]).shape, np.array(train_batches_tumor_identification[1]).shape","48969ed1":"# ##model building\n# model = Sequential()\n# #convolutional layer with rectified linear unit activation\n# model.add(layers.Conv2D(32, kernel_size=(3, 3),\n#                  activation='relu',\n#                  input_shape=(256,256,1)))\n# #32 convolution filters used each of size 3x3\n# #choose the best features via pooling\n# model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n# #randomly turn neurons on and off to improve convergence\n# model.add(layers.Dropout(0.25))\n# #flatten since too many dimensions, we only want a classification output\n# model.add(layers.Flatten())\n# #fully connected to get all relevant data\n# model.add(layers.Dense(128, activation='relu'))\n# #one more dropout for convergence' sake :) \n# model.add(layers.Dropout(0.5))\n# #output a softmax to squash the matrix into output probabilities\n# model.add(layers.Dense(1, activation='sigmoid'))\n# model.summary()","c26d5d92":"len(train_batches_tumor_identification[0]), len(train_batches_tumor_identification[1]), train_batches_tumor_identification[1].min(), train_batches_tumor_identification[1].max()","e2e969d7":"# Train the model, doing validation at the end of each epoch\nepochs = 500\n\ninitial_learning_rate = 0.001\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n)\n\n# model.compile(\n#     loss=\"binary_crossentropy\",\n#     optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n#     metrics=[AUC(name='auc'),\"acc\"])\n    \n# model_save = ModelCheckpoint(f'brain_tumor_identification_model.h5', \n#                              save_best_only = True, \n#                              monitor = 'val_auc', \n#                              mode = 'max', verbose = 1)\n# early_stop = EarlyStopping(monitor = 'val_auc', \n#                            patience = 50, mode = 'max', verbose = 1,\n#                            restore_best_weights = True)\n# model.fit(\n#     np.array(train_batches_tumor_identification[0]),np.array(train_batches_tumor_identification[1]),\n#     validation_data=(np.array(valid_batches_tumor_identification[0]),np.array(valid_batches_tumor_identification[1])),\n#     batch_size=10,\n#     epochs=epochs,\n#     shuffle=True,\n#     verbose=1,\n#     callbacks = [model_save, early_stop])","26655c5e":"class Model_2D_CNN_brain_tumor_identification(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b0\")\n#         checkpoint = torch.load('..\/input\/efficientnet-pytorch\/efficientnet-b7-dcc49843.pth')\n#         self.net.load_state_dict(checkpoint)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n\n    def forward(self, x):\n        out = self.net(x)\n        return out","25d95d82":"class DataRetriever_2D_CNN_brain_tumor_identification(torch_data.Dataset):\n    def __init__(self, paths, targets, label_smoothing=0.01, rotate= 0):\n        self.paths = paths\n        self.targets = targets\n        self.target_flag = True\n        self.train_flag = 'train'\n        self.label_smoothing = label_smoothing\n        self.rotate = rotate\n        if len(targets)==0:\n            self.target_flag = False\n            self.train_flag = 'test'\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = '..\/input\/ct-head-scans\/' + _id\n        channels = []\n        \n        image_data = cv2.imread(patient_path).astype('float32')\n        image_data = cv2.resize(image_data,(256,256))\/255\n\n        image_data = image_data - np.min(image_data)\n        if np.max(image_data) != 0:\n            image_data = image_data \/ np.max(image_data)\n\n        channels.append(image_data[:,:,0])\n        channels.append(image_data[:,:,0])\n        channels.append(image_data[:,:,0])\n                    \n        if (self.target_flag):\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(channels).float(), \"y\": y}\n        else:\n            return {\"X\": torch.tensor(channels).float(), \"id\": _id}","91ec3e67":"# train_data_retriever = DataRetriever_2D_CNN_brain_tumor_identification(\n#     data_tumor_identification[\"ID\"].values, \n#     data_tumor_identification[\"Tumor flag\"].values, rotate = 0)","630ed31b":"# train_data_retriever[0]['X'].shape, train_data_retriever[0]['y']","5818a774":"# class Trainer_brain_tumor_identification:\n#     def __init__(\n#         self, \n#         model, \n#         device, \n#         optimizer, \n#         criterion,\n#         best_valid_score\n#     ):\n#         self.model = model\n#         self.device = device\n#         self.optimizer = optimizer\n#         self.criterion = criterion\n        \n#         self.best_valid_score = best_valid_score\n#         self.n_patience = 0\n        \n#         self.messages = {\n#             \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n#             \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n#             \"patience\": \"\\nValid loss didn't improve last {} epochs.\"\n#         }\n    \n#     def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n#         for n_epoch in range(1, epochs + 1):\n#             self.info_message(\"EPOCH: {}\", n_epoch)\n            \n#             train_loss, train_score, train_time = self.train_epoch(train_loader)\n#             valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n#             self.info_message(\n#                 self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n#             )\n            \n#             self.info_message(\n#                 self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n#             )\n\n#             if (self.best_valid_score < valid_score):\n#                 self.info_message(\n#                     self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n#                 )\n#                 self.best_valid_score = valid_score\n#                 self.save_model(n_epoch, save_path)\n#                 self.n_patience = 0\n#             else:\n#                 self.n_patience += 1\n            \n#             if self.n_patience >= patience:\n#                 self.info_message(self.messages[\"patience\"], patience)\n#                 break\n            \n#     def train_epoch(self, train_loader):\n#         self.model.train()\n#         t = time.time()\n#         sum_loss = 0\n#         y_all =[]\n#         outputs_all = []\n        \n#         for step, batch in enumerate(train_loader, 1):\n#             X = batch[\"X\"].to(self.device)\n#             targets = batch[\"y\"].to(self.device)\n#             self.optimizer.zero_grad()\n#             outputs = self.model(X).squeeze(1)\n            \n#             loss = self.criterion(outputs, targets)\n#             loss.backward()\n\n#             sum_loss += loss.detach().item()\n#             y_all.extend(batch[\"y\"].tolist())\n#             outputs_all.extend(torch.sigmoid(outputs).tolist())\n\n#         y_all = [1 if x > 0.5 else 0 for x in y_all]\n#         auc = roc_auc_score(y_all, outputs_all)\n\n#         _loss, _score = sum_loss\/step, auc\n#         message = 'Train Step {}\/{}, train_loss: {:.5f}, train_roc_auc: {:.5f}'\n#         self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n        \n#         return _loss, _score, int(time.time() - t)\n    \n#     def valid_epoch(self, valid_loader):\n#         self.model.eval()\n#         t = time.time()\n#         sum_loss = 0\n#         y_all =[]\n#         outputs_all = []\n\n#         for step, batch in enumerate(valid_loader, 1):\n#             with torch.no_grad():\n#                 X = batch[\"X\"].to(self.device)\n#                 targets = batch[\"y\"].to(self.device)\n\n#                 outputs = self.model(X).squeeze(1)\n#                 loss = self.criterion(outputs, targets)\n\n#                 sum_loss += loss.detach().item()\n#                 y_all.extend(batch[\"y\"].tolist())\n#                 outputs_all.extend(torch.sigmoid(outputs).tolist())\n            \n#         y_all = [1 if x > 0.5 else 0 for x in y_all]\n#         auc = roc_auc_score(y_all, outputs_all)\n\n#         _loss, _score = sum_loss\/step, auc\n#         message = 'Valid Step {}\/{}, valid_loss: {:.5f}, valid_roc_auc: {:.5f}'\n#         self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n\n#         return _loss, _score, int(time.time() - t)\n    \n#     def save_model(self, n_epoch, save_path):\n#         torch.save(\n#             {\n#                 \"model_state_dict\": self.model.state_dict(),\n#                 \"optimizer_state_dict\": self.optimizer.state_dict(),\n#                 \"best_valid_score\": self.best_valid_score,\n#                 \"n_epoch\": n_epoch,\n#             },\n#             save_path,\n#         )\n    \n#     @staticmethod\n#     def info_message(message, *args, end=\"\\n\"):\n#         print(message.format(*args), end=end)","d3dd17eb":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# gc.collect()\n# torch.cuda.empty_cache()\n# model = Model_2D_CNN_brain_tumor_identification()\n# model.to(device)\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# criterion = torch_functional.binary_cross_entropy_with_logits\n\n# best_valid_score = -np.inf\n\n# trainer = Trainer_brain_tumor_identification(\n#     model, \n#     device, \n#     optimizer, \n#     criterion,\n#     best_valid_score\n# )\n\n# train_data_retriever = DataRetriever_2D_CNN_brain_tumor_identification(\n#     train_data_tumor_identification[\"ID\"].values, \n#     train_data_tumor_identification[\"Tumor flag\"].values, rotate = 0)\n\n# valid_data_retriever = DataRetriever_2D_CNN_brain_tumor_identification(\n#     valid_data_tumor_identification[\"ID\"].values, \n#     valid_data_tumor_identification[\"Tumor flag\"].values, rotate = 0)\n\n# train_loader = torch_data.DataLoader(\n#     train_data_retriever,\n#     batch_size=2,\n#     shuffle=True,\n#     num_workers=8,\n# )\n\n# valid_loader = torch_data.DataLoader(\n#     valid_data_retriever, \n#     batch_size=2,\n#     shuffle=False,\n#     num_workers=8,\n# )\n\n# history = trainer.fit(\n#     30, \n#     train_loader,\n#     valid_loader, \n#     f\"effnet-best-model-brain-tumor-identification.pth\",\n#     10,\n# )","c519e124":"del train_data_tumor_identification, valid_data_tumor_identification, data_tumor_identification","d6fd0c0a":"##brain_tumor_identification_model building\nbrain_tumor_identification_model = Sequential()\n#convolutional layer with rectified linear unit activation\nbrain_tumor_identification_model.add(layers.Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(256,256,1)))\n#32 convolution filters used each of size 3x3\n#choose the best features via pooling\nbrain_tumor_identification_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n#randomly turn neurons on and off to improve convergence\nbrain_tumor_identification_model.add(layers.Dropout(0.25))\n#flatten since too many dimensions, we only want a classification output\nbrain_tumor_identification_model.add(layers.Flatten())\n#fully connected to get all relevant data\nbrain_tumor_identification_model.add(layers.Dense(128, activation='relu'))\n#one more dropout for convergence' sake :) \nbrain_tumor_identification_model.add(layers.Dropout(0.5))\n#output a softmax to squash the matrix into output probabilities\nbrain_tumor_identification_model.add(layers.Dense(1, activation='sigmoid'))\nbrain_tumor_identification_model.summary()","dfc938c8":"brain_tumor_identification_model.load_weights('..\/input\/brain-tumor-identification-model\/brain_tumor_identification_model.h5')","ccadc784":"img_num = 63\na = load_dicom_images_3d(\"00012\")\nprint('MGMT_value:',train_df[train_df['BraTS21ID']==12]['MGMT_value'].iloc[0])\nplt.imshow(a[0,:,:,img_num], cmap=\"gray\")\nprint('Model result on brain tumor identification',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","20ca009e":"img_num = 10\na = load_dicom_images_3d(\"00012\")\nprint('MGMT_value:',train_df[train_df['BraTS21ID']==12]['MGMT_value'].iloc[0])\nplt.imshow(a[0,:,:,img_num], cmap=\"gray\")\nprint('Model result on brain tumor identification',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","02e3116a":"img_num = 0\na = load_dicom_images_3d(\"00002\")\nprint('MGMT_value:',train_df[train_df['BraTS21ID']==2]['MGMT_value'].iloc[0])\nplt.imshow(a[0,:,:,img_num], cmap=\"gray\")\nprint('Model result on brain tumor identification',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","f25a591a":"img_num = 56\na = load_dicom_images_3d(\"00002\")\nprint('MGMT_value:',train_df[train_df['BraTS21ID']==2]['MGMT_value'].iloc[0])\nplt.imshow(a[0,:,:,img_num], cmap=\"gray\")\nprint('Model result on brain tumor identification',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","f93ee93a":"# from tqdm import tqdm\n\n# all_files_list = []\n# for i in tqdm(os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train')):\n#     for j in os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/'+i):\n#         for f in os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/'+i+'\/'+j):\n#             all_files_list.append('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/' + i + '\/' + j + '\/' + f)\n            \n# for i in tqdm(os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test')):\n#     for j in os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/'+i):\n#         for f in os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/'+i+'\/'+j):\n#             all_files_list.append('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/' + i + '\/' + j + '\/' + f)\n            \n# print(len(all_files_list))","188d138d":"def get_img_data(f):\n    image_data = load_dicom(f, rotate=0)\n    image_data = cv2.resize(image_data, (256, 256))\n    image_data = image_data - np.min(image_data)\n    if np.max(image_data) != 0:\n        image_data = image_data \/ np.max(image_data)\n    return image_data","41950057":"# brain_tumor_identification_model_pred_df = pd.DataFrame(data = None, columns = ['Filename','Brain tumor pred'])\n# tqdm.pandas()\n# brain_tumor_identification_model_pred_df['Filename'] = all_files_list\n# brain_tumor_identification_model_pred_df['Brain tumor pred'] = brain_tumor_identification_model_pred_df['Filename'].progress_apply(lambda x: brain_tumor_identification_model.predict(get_img_data(x).reshape((1,256,256,1)))[0][0])\n# joblib.dump(brain_tumor_identification_model_pred_df,'brain_tumor_identification_model_pred_df.pkl')","4b8432e4":"from tqdm import tqdm\nall_files_list = []\nfor i in tqdm(os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test')):\n    for j in os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/'+i):\n        for f in os.listdir('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/'+i+'\/'+j):\n            all_files_list.append('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/' + i + '\/' + j + '\/' + f)\n            \nprint(len(all_files_list))","92d325e6":"brain_tumor_identification_model_pred_df = joblib.load('..\/input\/brain-tumor-predictions\/brain_tumor_identification_model_pred_df.pkl')\nprint(brain_tumor_identification_model_pred_df.shape)\nbrain_tumor_identification_model_pred_df.tail()","cfd77378":"intersection_files = set.intersection(set(all_files_list), set(brain_tumor_identification_model_pred_df['Filename'].tolist()))\nall_files_list = list(set(all_files_list) - intersection_files)","84a169a0":"len(all_files_list)","556a611a":"print(brain_tumor_identification_model_pred_df.shape)\nfor i in range(0, len(all_files_list)):\n    brain_tumor_identification_model_pred_df.loc[brain_tumor_identification_model_pred_df.shape[0]] = all_files_list[i], brain_tumor_identification_model.predict(get_img_data(all_files_list[i]).reshape((1,256,256,1)))[0][0]\nprint(brain_tumor_identification_model_pred_df.shape)","d8c5e593":"del brain_tumor_identification_model, get_img_data","67a5206e":"# def select_best_images(files,img_size,num_imgs):\n#     model_pred_df = pd.DataFrame(data = None, columns = ['Order','Filename','Brain tumor pred'])\n#     count = 0\n\n#     for f in files:\n#         image_data = load_dicom(f, rotate=0)\n#         image_data = cv2.resize(image_data, (img_size, img_size))\n#         image_data = image_data - np.min(image_data)\n#         if np.max(image_data) != 0:\n#             image_data = image_data \/ np.max(image_data)\n#         model_pred_df.loc[count] = (count+1), f, brain_tumor_identification_model.predict(image_data.reshape((1,256,256,1)))[0][0]\n#         count += 1\n    \n#     selected_image_paths = model_pred_df.sort_values(by = ['Brain tumor pred'], ascending = False).head(num_imgs)\n#     selected_image_paths = selected_image_paths.sort_values(by = 'Order', ascending = True).reset_index(drop = True)\n    \n#     return selected_image_paths['Filename'].tolist()","6d253ed3":"# img_num = 20\n# a = load_dicom_images_3d(\"00002\")\n# print('MGMT_value:',train_df[train_df['BraTS21ID']==2]['MGMT_value'].iloc[0])\n# plt.imshow(a[0,:,:,img_num], cmap=\"gray\")\n# print('Model result on brain tumor identification:',brain_tumor_identification_model.predict(a[0,:,:,img_num].reshape((1,256,256,1)))[0][0]*100,'%')","4b32808a":"# Update function to include top images containing tumor\n\nNUM_IMAGES = 64\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=256, mri_type=\"FLAIR\", split=\"train\", rotate=0):\n\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    files = [x for x in files if load_dicom(x).sum()!=0]\n    \n    #----Selecting best images START----    \n\n#     selected_files = select_best_images(files,img_size,num_imgs)\n\n    files_df = pd.DataFrame(files)\n    files_df.columns = ['Filename']\n    files_df['Order'] = files_df.index + 1\n    \n    selected_image_paths = brain_tumor_identification_model_pred_df[brain_tumor_identification_model_pred_df['Filename'].isin(files)].sort_values(by = ['Brain tumor pred'], ascending = False).head(num_imgs)\n    selected_image_paths = selected_image_paths.merge(files_df, on = 'Filename', how = 'left')\n    selected_image_paths = selected_image_paths.sort_values(by = 'Order', ascending = True).reset_index(drop = True)\n    selected_files = selected_image_paths['Filename'].tolist()\n    \n    #----Selecting best images END----    \n\n    # crop_image_pixel_array()\n    images_list_array = [load_dicom(f, rotate=rotate) for f in selected_files]\n    \n    #Cropping\n    mean_image_for_cropping = np.array(images_list_array).mean(axis = 0)\n    img_cropped,dim_for_cropping = crop_image_pixel_array(mean_image_for_cropping)\n    first_row_index = dim_for_cropping[0]\n    last_row_index = dim_for_cropping[1]\n    first_column_index = dim_for_cropping[2]\n    last_column_index = dim_for_cropping[3]\n    if ((not pd.isnull(first_row_index)) & (not pd.isnull(last_row_index)) & (not pd.isnull(first_column_index)) & (not pd.isnull(last_column_index))):\n        images_list_array = [f[first_row_index:last_row_index,first_column_index:last_column_index] for f in images_list_array]\n\n    images_list_array = [cv2.resize(f, (img_size, img_size)) for f in images_list_array]\n    img3d = np.stack(images_list_array).T\n\n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d \/ np.max(img3d)\n\n    return np.expand_dims(img3d,0)","76537059":"valid_combinations = [['T2w', 'T1wCE', 'T1w'], ['FLAIR', 'T2w', 'T1w'], ['FLAIR', 'T2w', 'T1wCE'], ['FLAIR', 'T1wCE', 'T1w']]","2ecff09b":"class DataRetriever_2D_CNN(torch_data.Dataset):\n    def __init__(self, paths, targets, list_combinations, label_smoothing=0.001, rotate= 0):\n        self.paths = paths\n        self.targets = targets\n        self.target_flag = True\n        self.train_flag = 'train'\n        self.label_smoothing = label_smoothing\n        self.list_combinations = list_combinations\n        self.rotate = rotate\n        if len(targets)==0:\n            self.target_flag = False\n            self.train_flag = 'test'\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        patient_path = f\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/{self.train_flag}\/{str(_id).zfill(5)}\/\"\n        channels = []\n        for t in list(self.list_combinations):\n            t_paths = sorted(\n                glob.glob(os.path.join(patient_path, t, \"*\")), \n                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n            )\n\n            x = len(t_paths)\n            num_images = 5\n                \n            if x < num_images:\n                r = range(x)\n            else:\n                d = x \/\/ num_images\n                r = range(d, x - d, d)\n\n            channel = []\n\n            for i in r:\n                pixel_array_processed = load_dicom(t_paths[i], rotate = self.rotate)\n                pixel_array_processed = pixel_array_processed - np.min(pixel_array_processed)\n                if np.max(pixel_array_processed) != 0:\n                    pixel_array_processed = pixel_array_processed \/ np.max(pixel_array_processed)\n                #Crop image\n                if pixel_array_processed.sum() != 0:\n                    pixel_array_processed,_ = crop_image_pixel_array(pixel_array_processed)\n                pixel_array_processed = (pixel_array_processed * 255).astype(np.uint8)\n                pixel_array_processed = cv2.resize(pixel_array_processed, (256, 256)) \/ 255\n                channel.append(pixel_array_processed)\n            channel = np.mean(channel, axis=0)\n            channels.append(channel)\n                    \n        if (self.target_flag):\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(channels).float(), \"y\": y}\n        else:\n            return {\"X\": torch.tensor(channels).float(), \"id\": _id}","2864b979":"train_data_retriever_comb_1 = DataRetriever_2D_CNN(\n    df_train[\"BraTS21ID\"].values,\n    df_train[\"MGMT_value\"].values, \n    list(valid_combinations[0]), rotate = 0)\n\nvalid_data_retriever_comb_1 = DataRetriever_2D_CNN(\n    df_valid[\"BraTS21ID\"].values, \n    df_valid[\"MGMT_value\"].values,\n    list(valid_combinations[0]), rotate = 0)","20dff527":"img = train_data_retriever_comb_1[0]['X']\nprint(img.shape)\nplt.imshow(img[1], cmap=\"gray\")","69c19f95":"num = 230\nplt.figure(figsize=(16, 6))\nif (df_train.iloc[num]['MGMT_value'])==0:\n    print('Patient without tumor')\nelse:\n    print('Patient with tumor')\nfor i in range(3):\n    plt.subplot(1, 3, i + 1)\n    plt.imshow(train_data_retriever_comb_1[num][\"X\"].numpy()[i], cmap=\"gray\")","599da014":"plt.figure(figsize=(16, 6))\nif (df_train.iloc[101]['MGMT_value'])==0:\n    print('Patient without tumor')\nelse:\n    print('Patient with tumor')\nfor i in range(3):\n    plt.subplot(1, 3, i + 1)\n    plt.imshow(train_data_retriever_comb_1[101][\"X\"].numpy()[i], cmap=\"gray\")","a83be391":"del train_data_retriever_comb_1, valid_data_retriever_comb_1","8c88d8f1":"class Model_2D_CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b7\")\n#         checkpoint = torch.load('..\/input\/efficientnet-pytorch\/efficientnet-b7-dcc49843.pth')\n#         self.net.load_state_dict(checkpoint)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n\n    def forward(self, x):\n        out = self.net(x)\n        return out","1acdc9ca":"# class LossMeter:\n#     def __init__(self):\n#         self.avg = 0\n#         self.n = 0\n\n#     def update(self, val):\n#         self.n += 1\n#         # incremental update\n#         self.avg = val \/ self.n + (self.n - 1) \/ self.n * self.avg\n\n        \n# class AccMeter:\n#     def __init__(self):\n#         self.true_count = 0\n#         self.n = 0\n#         self.avg = 0\n        \n#     def update(self, y_true, y_pred):\n#         y_true = y_true.cpu().numpy() >= 0.5\n#         y_pred = y_pred.cpu().numpy() >= 0\n#         self.n += len(y_true)\n#         self.true_count += np.sum(y_true == y_pred)\n#         # incremental update\n#         if self.n != 0:\n#             self.avg = self.true_count \/ self.n\n#         else:\n#             self.avg = 0","15811cc0":"# class Trainer:\n#     def __init__(\n#         self, \n#         model, \n#         device, \n#         optimizer, \n#         criterion,\n#         best_valid_score\n#     ):\n#         self.model = model\n#         self.device = device\n#         self.optimizer = optimizer\n#         self.criterion = criterion\n        \n#         self.best_valid_score = best_valid_score\n#         self.n_patience = 0\n        \n#         self.messages = {\n#             \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n#             \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n#             \"patience\": \"\\nValid loss didn't improve last {} epochs.\"\n#         }\n    \n#     def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n#         for n_epoch in range(1, epochs + 1):\n#             self.info_message(\"EPOCH: {}\", n_epoch)\n            \n#             train_loss, train_score, train_time = self.train_epoch(train_loader)\n#             valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n#             self.info_message(\n#                 self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n#             )\n            \n#             self.info_message(\n#                 self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n#             )\n\n#             if (self.best_valid_score < valid_score):\n#                 self.info_message(\n#                     self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n#                 )\n#                 self.best_valid_score = valid_score\n#                 self.save_model(n_epoch, save_path)\n#                 self.n_patience = 0\n#             else:\n#                 self.n_patience += 1\n            \n#             if self.n_patience >= patience:\n#                 self.info_message(self.messages[\"patience\"], patience)\n#                 break\n            \n#     def train_epoch(self, train_loader):\n#         self.model.train()\n#         t = time.time()\n#         sum_loss = 0\n#         y_all =[]\n#         outputs_all = []\n        \n#         for step, batch in enumerate(train_loader, 1):\n#             X = batch[\"X\"].to(self.device)\n#             targets = batch[\"y\"].to(self.device)\n#             self.optimizer.zero_grad()\n#             outputs = self.model(X).squeeze(1)\n            \n#             loss = self.criterion(outputs, targets)\n#             loss.backward()\n\n#             sum_loss += loss.detach().item()\n#             y_all.extend(batch[\"y\"].tolist())\n#             outputs_all.extend(torch.sigmoid(outputs).tolist())\n\n#         y_all = [1 if x > 0.5 else 0 for x in y_all]\n#         auc = roc_auc_score(y_all, outputs_all)\n\n#         _loss, _score = sum_loss\/step, auc\n#         message = 'Train Step {}\/{}, train_loss: {:.5f}, train_roc_auc: {:.5f}'\n#         self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n        \n#         return _loss, _score, int(time.time() - t)\n    \n#     def valid_epoch(self, valid_loader):\n#         self.model.eval()\n#         t = time.time()\n#         sum_loss = 0\n#         y_all =[]\n#         outputs_all = []\n\n#         for step, batch in enumerate(valid_loader, 1):\n#             with torch.no_grad():\n#                 X = batch[\"X\"].to(self.device)\n#                 targets = batch[\"y\"].to(self.device)\n\n#                 outputs = self.model(X).squeeze(1)\n#                 loss = self.criterion(outputs, targets)\n\n#                 sum_loss += loss.detach().item()\n#                 y_all.extend(batch[\"y\"].tolist())\n#                 outputs_all.extend(torch.sigmoid(outputs).tolist())\n            \n#         y_all = [1 if x > 0.5 else 0 for x in y_all]\n#         auc = roc_auc_score(y_all, outputs_all)\n\n#         _loss, _score = sum_loss\/step, auc\n#         message = 'Valid Step {}\/{}, valid_loss: {:.5f}, valid_roc_auc: {:.5f}'\n#         self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n\n#         return _loss, _score, int(time.time() - t)\n    \n#     def save_model(self, n_epoch, save_path):\n#         torch.save(\n#             {\n#                 \"model_state_dict\": self.model.state_dict(),\n#                 \"optimizer_state_dict\": self.optimizer.state_dict(),\n#                 \"best_valid_score\": self.best_valid_score,\n#                 \"n_epoch\": n_epoch,\n#             },\n#             save_path,\n#         )\n    \n#     @staticmethod\n#     def info_message(message, *args, end=\"\\n\"):\n#         print(message.format(*args), end=end)","00dfc979":"valid_combinations","de3b24ee":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# for i in range(0,len(valid_combinations)):\n#     print('Combination :', list(valid_combinations[i]))\n    \n#     gc.collect()\n#     torch.cuda.empty_cache()\n#     model = Model_2D_CNN()\n#     model.to(device)\n\n#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n#     criterion = torch_functional.binary_cross_entropy_with_logits\n\n#     best_valid_score = -np.inf\n\n#     trainer = Trainer(\n#         model, \n#         device, \n#         optimizer, \n#         criterion,\n#         best_valid_score\n#     )\n    \n#     for rotate_dir in [0,2]:\n#         train_data_retriever = DataRetriever_2D_CNN(\n#             df_train[\"BraTS21ID\"].values, \n#             df_train[\"MGMT_value\"].values, \n#             list(valid_combinations[i]), rotate = rotate_dir)\n\n#         valid_data_retriever = DataRetriever_2D_CNN(\n#             df_valid[\"BraTS21ID\"].values, \n#             df_valid[\"MGMT_value\"].values,\n#             list(valid_combinations[i]), rotate = rotate_dir)\n\n#         train_loader = torch_data.DataLoader(\n#             train_data_retriever,\n#             batch_size=4,\n#             shuffle=True,\n#             num_workers=8,\n#         )\n\n#         valid_loader = torch_data.DataLoader(\n#             valid_data_retriever, \n#             batch_size=4,\n#             shuffle=False,\n#             num_workers=8,\n#         )\n\n#         history = trainer.fit(\n#             30, \n#             train_loader,\n#             valid_loader, \n#             f\"best-model-{i}.pth\",\n#             10,\n#         )","fde55fd7":"# from __future__ import print_function  # for Python2\n\n# local_vars = list(locals().items())\n# for var, obj in local_vars:\n#     print(var, sys.getsizeof(obj))","9032be18":"# del image_data, intersection_files, brain_tumor_identification_model","a0d9bbb4":"def get_model(width=128, height=128, depth=64):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = tensorflow.keras.Input((width, height, depth, 1))\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n\n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Dense(units=512, activation=\"relu\")(x)\n    x = layers.Dropout(0.3)(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    # Define the model.\n    model = tensorflow.keras.Model(inputs, outputs, name=\"3dcnn\")\n    return model","66f8e66d":"df_train['BraTS21ID5'] = df_train['BraTS21ID'].apply(lambda x: format(x, '05d'))\ndf_valid['BraTS21ID5'] = df_valid['BraTS21ID'].apply(lambda x: format(x, '05d'))","297f12fc":"class Dataset(Sequence):\n    def __init__(self,df,mri_type,is_train=True,batch_size=4,shuffle=True):\n        self.idx = df[\"BraTS21ID\"].values\n        self.paths = df[\"BraTS21ID5\"].values\n        self.y =  df[\"MGMT_value\"].values\n        self.is_train = is_train\n        self.batch_size = batch_size\n        self.mri_type = mri_type\n        self.shuffle = shuffle\n    def __len__(self):\n        return math.ceil(len(self.idx)\/self.batch_size)\n   \n    def __getitem__(self,ids):\n        id_path= self.paths[ids]\n        batch_paths = self.paths[ids * self.batch_size:(ids + 1) * self.batch_size]\n        \n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n        \n        if self.is_train:\n            list_x =  [load_dicom_images_3d(x,split=\"train\") for x in batch_paths]\n            batch_X = np.stack(list_x, axis=4)\n            return batch_X,batch_y\n        else:\n            list_x =  load_dicom_images_3d(id_path,split=\"test\", mri_type = self.mri_type)#str(scan_id).zfill(5)\n            batch_X = np.stack(list_x)\n            return batch_X\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","b49ba559":"mri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']","61343ecf":"initial_learning_rate = 0.0001\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n)\n\n# for i in range(0, len(mri_types)):\n#     train_dataset = Dataset(df_train,mri_type = mri_types[i], batch_size=4)\n#     valid_dataset = Dataset(df_valid,mri_type = mri_types[i], batch_size=4)\n\n#     # Define callbacks\n#     model_save = ModelCheckpoint(f'{mri_types[i]}.h5', \n#                                  save_best_only = True, \n#                                  monitor = 'val_auc', \n#                                  mode = 'max', verbose = 1)\n#     early_stop = EarlyStopping(monitor = 'val_auc', \n#                                patience = 10, mode = 'max', verbose = 1,\n#                                restore_best_weights = True)\n\n#     # Train the model, doing validation at the end of each epoch\n#     epochs = 1\n\n#     # Build model.\n#     model = get_model(width=256, height=256, depth=64)\n#     model.summary()\n\n#     model.compile(\n#         loss=\"binary_crossentropy\",\n#         optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n#         metrics=[AUC(name='auc'),\"acc\"],\n#     )\n\n#     model.fit(\n#         train_dataset,\n#         validation_data=valid_dataset,\n#         epochs=epochs,\n#         shuffle=True,\n#         verbose=1,\n#         callbacks = [model_save, early_stop],\n#     )","b5edaf07":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, paths, targets, mri_type, label_smoothing=0.01, augment = True):\n        self.paths = paths\n        self.targets = targets\n        self.target_flag = True\n        self.train_flag = 'train'\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.augment = augment\n        if len(targets)==0:\n            self.target_flag = False\n            self.train_flag = 'test'\n\n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        if self.augment:\n            rotation = np.random.randint(0,4)\n        else:\n            rotation = 0\n        data = load_dicom_images_3d(str(_id).zfill(5), mri_type=self.mri_type, split=self.train_flag, rotate=rotation)        \n        if (self.target_flag):\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}\n        else:\n            return {\"X\": torch.tensor(data).float(), \"id\": _id}","ca330c11":"class Model_3D_effnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","ed92846e":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n\n        self.best_valid_score = np.inf\n        self.n_patience = 0\n        self.lastmodel = None\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s            \",\n                n_epoch, train_loss, train_time\n            )\n            \n            self.info_message(\n                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n                n_epoch, valid_loss, valid_auc, valid_time\n            )\n\n            # if True:\n            #if self.best_valid_score < valid_auc: \n            if self.best_valid_score > valid_loss: \n                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n                self.info_message(\n                     \"Valid loss improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n                    self.best_valid_score, valid_loss, self.lastmodel\n                )\n                self.best_valid_score = valid_loss\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        sum_loss = 0\n\n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            sum_loss += loss.detach().item()\n\n            self.optimizer.step()\n            \n            message = 'Train Step {}\/{}, train_loss: {:.4f}'\n            self.info_message(message, step, len(train_loader), sum_loss\/step, end=\"\\r\")\n        \n        return sum_loss\/len(train_loader), int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        sum_loss = 0\n        y_all = []\n        outputs_all = []\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                sum_loss += loss.detach().item()\n                y_all.extend(batch[\"y\"].tolist())\n                outputs_all.extend(torch.sigmoid(outputs).tolist())\n\n            message = 'Valid Step {}\/{}, valid_loss: {:.4f}'\n            self.info_message(message, step, len(valid_loader), sum_loss\/step, end=\"\\r\")\n            \n        y_all = [1 if x > 0.5 else 0 for x in y_all]\n        auc = roc_auc_score(y_all, outputs_all)\n        \n        return sum_loss\/len(valid_loader), auc, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, loss, auc):\n        self.lastmodel = f\"{save_path}\"\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            self.lastmodel,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","7708db07":"from tqdm import tqdm\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n\nfor i in tqdm(range(0,len(mri_types))):\n    print('MRI type :', mri_types[i])\n    \n    gc.collect()\n    torch.cuda.empty_cache()\n    model = Model_3D_effnet()\n    model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = torch_functional.binary_cross_entropy_with_logits\n    \n    trainer = Trainer(\n        model, \n        device, \n        optimizer, \n        criterion\n    )\n    \n    train_data_retriever = DataRetriever(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values, \n        mri_types[i], \n        augment = True)\n\n\n    valid_data_retriever = DataRetriever(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        mri_types[i], \n        augment = False)\n\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=4,\n        shuffle=True,\n        num_workers=8, pin_memory = True\n    )\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever, \n        batch_size=4,\n        shuffle=False,\n        num_workers=8, pin_memory = True\n    )\n\n    history = trainer.fit(\n        30, \n        train_loader,\n        valid_loader, \n        f\"best-model-{mri_types[i]}.pth\",\n        10,\n    )","c7bfb3f8":"class DataRetriever_unet(torch_data.Dataset):\n    def __init__(self, paths, targets, label_smoothing=0.01, augment = True, num_imgs = 64, mri_type = 'FLAIR'):\n        self.paths = paths\n        self.targets = targets\n        self.target_flag = True\n        self.train_flag = 'train'\n        self.label_smoothing = label_smoothing\n        self.augment = augment\n        self.num_imgs = num_imgs\n        self.mri_type = mri_type\n        if len(targets)==0:\n            self.target_flag = False\n            self.train_flag = 'test'\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        _id = self.paths[index]\n        if self.augment:\n            rotation = np.random.randint(0,4)\n        else:\n            rotation = 0\n            \n        unet_mask = get_array(f'..\/input\/nnunet-masks\/{str(_id).zfill(5)}.nii.gz')\n            \n        if self.mri_type == 'FLAIR':\n            temp = get_array(f'..\/input\/preprocessed-train-images\/{str(_id).zfill(5)}_0000.nii.gz')\n        elif self.mri_type == 'T1w':\n            temp = get_array(f'..\/input\/preprocessed-train-images\/{str(_id).zfill(5)}_0001.nii.gz')\n        elif self.mri_type == 'T1wCE':\n            temp = get_array(f'..\/input\/preprocessed-train-images\/{str(_id).zfill(5)}_0002.nii.gz')\n        elif self.mri_type == 'T2w':\n            temp = get_array(f'..\/input\/preprocessed-train-images\/{str(_id).zfill(5)}_0003.nii.gz')\n        \n        data = []\n        for slice_num in range(0, unet_mask.shape[0]):\n            img_slice = unet_mask[slice_num,:,:]\n            img_data = img_slice * temp[slice_num,:,:]\n            if (img_data.sum() != 0):\n                data.append(img_data)\n\n        data = np.stack(data, axis = 2)\n        data = data[:,:,:64]\n        \n        if data.shape[-1] < self.num_imgs:\n            n_zero = np.zeros((240, 240, self.num_imgs - data.shape[-1]))\n            data = np.concatenate((data,  n_zero), axis = -1)\n\n        data = np.expand_dims(data,0)\n        \n        if (self.target_flag):\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}\n        else:\n            return {\"X\": torch.tensor(data).float(), \"id\": _id}","d55b57b8":"class Model_3D_effnet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","c2335d29":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n\n        self.best_valid_score = np.inf\n        self.n_patience = 0\n        self.lastmodel = None\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_auc, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                \"[Epoch Train: {}] loss: {:.4f}, time: {:.2f} s            \",\n                n_epoch, train_loss, train_time\n            )\n            \n            self.info_message(\n                \"[Epoch Valid: {}] loss: {:.4f}, auc: {:.4f}, time: {:.2f} s\",\n                n_epoch, valid_loss, valid_auc, valid_time\n            )\n\n            # if True:\n            #if self.best_valid_score < valid_auc: \n            if self.best_valid_score > valid_loss: \n                self.save_model(n_epoch, save_path, valid_loss, valid_auc)\n                self.info_message(\n                     \"Train loss improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n                    self.best_valid_score, valid_loss, self.lastmodel\n                )\n                self.best_valid_score = valid_loss\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        sum_loss = 0\n\n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            sum_loss += loss.detach().item()\n\n            self.optimizer.step()\n            \n            message = 'Train Step {}\/{}, train_loss: {:.4f}'\n            self.info_message(message, step, len(train_loader), sum_loss\/step, end=\"\\r\")\n        \n        return sum_loss\/len(train_loader), int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        sum_loss = 0\n        y_all = []\n        outputs_all = []\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                sum_loss += loss.detach().item()\n                y_all.extend(batch[\"y\"].tolist())\n                outputs_all.extend(torch.sigmoid(outputs).tolist())\n\n            message = 'Valid Step {}\/{}, valid_loss: {:.4f}'\n            self.info_message(message, step, len(valid_loader), sum_loss\/step, end=\"\\r\")\n            \n        y_all = [1 if x > 0.5 else 0 for x in y_all]\n        auc = roc_auc_score(y_all, outputs_all)\n        \n        return sum_loss\/len(valid_loader), auc, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, loss, auc):\n        self.lastmodel = f\"{save_path}\"\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            self.lastmodel,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","1c9f433c":"from tqdm import tqdm\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\n\nfor i in tqdm(range(0,len(mri_types))):\n    print('MRI type :', mri_types[i])\n    gc.collect()\n    torch.cuda.empty_cache()\n    model = Model_3D_effnet()\n    model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = torch_functional.binary_cross_entropy_with_logits\n\n    trainer = Trainer(\n        model, \n        device, \n        optimizer, \n        criterion\n    )\n\n    train_data_retriever = DataRetriever_unet(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values, \n        augment = True,\n        mri_type = mri_types[i],\n        num_imgs = 64)\n\n\n    valid_data_retriever = DataRetriever_unet(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        augment = False,\n        mri_type = mri_types[i],\n        num_imgs = 64)\n\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=4,\n        shuffle=True,\n        num_workers=8, pin_memory = True\n    )\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever, \n        batch_size=4,\n        shuffle=False,\n        num_workers=8, pin_memory = True\n    )\n\n    history = trainer.fit(\n        50, \n        train_loader,\n        valid_loader, \n        f\"unet_images_3d_cnn_best-model_{mri_types[i]}.pth\",\n        15,\n    )","215a5cc7":"# Train Model Class\nclass nn_model():\n    def __init__(self, loader,criterion,num_epochs=25,embed_size=4096, num_classes=2,device='cpu',debug=False):\n        \n        torch.cuda.empty_cache()\n        \n        self.embed_size = embed_size\n        self.device = device\n        self.debug = debug\n        \n        vgg = torchvision.models.vgg19(pretrained = True)\n        \n        self.vgg_feat  = nn.Sequential(vgg.features)\n        self.vgg_pool = nn.Sequential(vgg.avgpool)\n        self.vgg_class = nn.Sequential(vgg.classifier[0])  \n        \n        self.criterion = criterion\n        self.num_epochs = num_epochs\n        del vgg\n        \n    def encoder(self,imgs):\n        features = np.zeros((imgs.shape[0],imgs.shape[1],4096))\n        for i in range(0,imgs.shape[0]):\n            for j in range(0,imgs.shape[1]):\n                A = imgs[i,j:j+1,:,:]\n                B = A.repeat(3,1,1).type(torch.FloatTensor).unsqueeze(0)\n\n                emb_ = self.vgg_class.forward(\n                                               self.vgg_pool.forward(\n                                                                       self.vgg_feat.forward(B)\n                                                                      ).view(-1)\n                                             )\n                \n                features[i,j,:] = emb_.detach().numpy()\n        \n        self.embed = torch.from_numpy(features)\n#         pdb.set_trace()\n#         self.embed = self.embed.permute(1,0,2).flatten(start_dim=1,end_dim=2)\n#         print(\"Check:\", self.embed.shape)\n        return self.embed\n    \n    def model_arch(self):\n        self.model = LSTM_RSNA()\n        \n    def train_model(self):\n        since = time.time()\n        self.optimizer = optim.SGD(self.model.parameters(), lr=0.005, momentum=0.9)\n        # Decay LR by a factor of 0.1 every 7 epochs\n        self.scheduler = lr_scheduler.StepLR(self.optimizer, step_size=3, gamma=0.1)\n        \n        best_model_wts = copy.deepcopy(self.model.state_dict())\n        best_acc = 0.0\n        self.model.to(self.device)\n        self.track = []\n        for epoch in tqdm(range(self.num_epochs)):\n            print('Epoch {}\/{}'.format(epoch, self.num_epochs - 1))\n            print('-' * 10)\n\n            # Each epoch has a training and validation phase\n            for phase in ['train', 'val']:\n                if phase == 'train':\n                    self.model.train()  # Set model to training mode\n                else:\n                    self.model.eval()   # Set model to evaluate mode\n\n                running_loss = 0.0\n                running_corrects = 0\n\n                # Iterate over data.\n                i=0                    \n                for inputs, labels in dataloaders[phase]:\n                    if self.debug and i>3:\n                        break\n                    else:\n                        inputs = inputs.to(self.device)\n                        labels = labels.to(self.device)[:,0,:]\n                        \n\n                        # zero the parameter gradients\n                        self.optimizer.zero_grad()\n\n                        # forward\n                        # track history if only in train\n                        with torch.set_grad_enabled(phase == 'train'):\n                            outputs,states = self.model(self.encoder(inputs).float())\n                            _, preds = torch.max(outputs, 1)                            \n                            loss = self.criterion(outputs, labels)\n\n                            # backward + optimize only if in training phase\n                            if phase == 'train':\n                                loss.backward()\n                                self.optimizer.step()\n\n                        # statistics\n                        running_loss += loss.item() * inputs.size(0)\n                        running_corrects += torch.sum(preds == labels.data[:,1])\n                        i+=1\n                    \n                if phase == 'train':\n                    self.scheduler.step()\n#                 pdb.set_trace()\n                epoch_loss = running_loss \/ len(dataloaders[phase])\n                epoch_acc = running_corrects.double() \/ len(dataloaders[phase])\n                \n                \n                if self.device=='cuda':\n                    labels = labels.to('cpu')\n                    preds = preds.to('cpu')\n                \n                epoch_metrics = np.asarray(precision_recall_fscore_support(labels.data[:,1],preds))\n#                 pdb.set_trace()\n                epoch_roc = roc_auc_score(labels.data[:,1],preds)\n                self.track.append([phase, epoch_loss, epoch_acc, \n                                   epoch_metrics[0,1],epoch_metrics[1,1], epoch_metrics[2,1],\n                                   epoch_roc])\n                \n                print('{} Loss: {:.4f} Acc: {:.4f} Precision: {:.4f} Recall: {:.4f} F1 Score: {:.4f} F1 AUC: {:.4f}'.format(\n                    phase, epoch_loss, epoch_acc, epoch_metrics[0,1],\n                    epoch_metrics[1,1], epoch_metrics[2,1],epoch_roc))\n\n                # deep copy the model\n                if phase == 'val' and epoch_roc > best_acc:\n                    best_acc = epoch_roc\n                    print('Current Best Model Epoch: ', epoch,'\\n')\n                    best_model_wts = copy.deepcopy(self.model.state_dict())\n                    torch.save({'lstm': self.model.state_dict(),'optimizer': self.optimizer.state_dict()}, 'model1.path')\n\n            print()\n\n        time_elapsed = time.time() - since\n        print('Training complete in {:.0f}m {:.0f}s'.format(\n            time_elapsed \/\/ 60, time_elapsed % 60))\n        \n        print('Best val Acc: {:4f}'.format(best_acc))\n        \n        # load best model weights\n        self.model.load_state_dict(best_model_wts)\n","4ecfb9c9":"!pip install pyradiomics","3df4d28c":"import radiomics","d06bd6b0":"# models_2D_CNN = []\n# for i in range(4):\n#     gc.collect()\n#     torch.cuda.empty_cache()\n#     model = Model_2D_CNN()\n#     model.to(device)\n    \n#     checkpoint = torch.load(f\"..\/input\/brain-tumor-classification-model\/best-model-{i}.pth\")\n# #     checkpoint = torch.load(f\"best-model-{i}.pth\")\n#     print(checkpoint['best_valid_score'])\n#     model.load_state_dict(checkpoint[\"model_state_dict\"])\n#     model.eval()\n    \n#     models_2D_CNN.append(model)","38f8776e":"# models_3D_user_defined_CNN = []\n# for i in range(4):\n#     model = get_model(width=256, height=256, depth=64)\n\n#     model.load_weights(f'..\/input\/brain-tumor-classification-model-3d-simple-cnn\/{mri_types[i]}.h5')\n    \n#     models_3D_user_defined_CNN.append(model)","31ebe1e9":"gc.collect()\ntorch.cuda.empty_cache()","d65a628a":"models_3D_CNN_effnet = []\nfor i in range(4):\n    model = Model_3D_effnet()\n    model.to(device)\n    \n    checkpoint = torch.load(f\"..\/input\/brain-tumor-classification-model-efficientnet-v1\/best-model-{mri_types[i]} v1.pth\")\n#     checkpoint = torch.load(f\"best-model-{mri_types[i]}.pth\")\n    \n    print(checkpoint['best_valid_score'])\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models_3D_CNN_effnet.append(model)","74cb9cb9":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(valid_combinations)):\n    print('Combination :', list(valid_combinations[i]))\n\n    train_data_retriever = DataRetriever_2D_CNN(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values,\n        list(valid_combinations[i]), rotate = 0)\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(train_loader):\n        print(f\"{e}\/{len(train_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_2D_CNN[i]\n            tmp_res =torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n            y_true.extend(batch[\"y\"].numpy().tolist())\n    \n    master_y_pred.append(y_pred)\n    master_y_true.append(y_true)","e661d802":"train_pred_df = pd.concat([pd.DataFrame(df_train[\"BraTS21ID\"].values).reset_index(drop = True), pd.DataFrame(df_train[\"MGMT_value\"].values).reset_index(drop = True), pd.DataFrame(master_y_pred[0]).reset_index(drop = True), pd.DataFrame(master_y_pred[1]).reset_index(drop = True), pd.DataFrame(master_y_pred[2]), pd.DataFrame(master_y_pred[3]).reset_index(drop = True)], axis = 1).reset_index(drop = True)\ntrain_pred_df.columns = ['BraTS21ID', 'MGMT_value', 'T2w + T1wCE + T1w pred', 'FLAIR + T2w + T1w pred', 'FLAIR + T2w + T1wCE pred', 'FLAIR + T1wCE + T1w pred']\ntrain_pred_df.head()","b9c71b93":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(valid_combinations)):\n    print('Combination :', list(valid_combinations[i]))\n\n    valid_data_retriever = DataRetriever_2D_CNN(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        list(valid_combinations[i]), rotate = 0)\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(valid_loader):\n        print(f\"{e}\/{len(valid_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_2D_CNN[i]\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n            y_true.extend(batch[\"y\"].numpy().tolist())\n    \n    master_y_pred.append(y_pred)\n    master_y_true.append(y_true)","4e18651a":"valid_pred_df = pd.concat([pd.DataFrame(df_valid[\"BraTS21ID\"].values).reset_index(drop = True), pd.DataFrame(df_valid[\"MGMT_value\"].values).reset_index(drop = True), pd.DataFrame(master_y_pred[0]).reset_index(drop = True), pd.DataFrame(master_y_pred[1]).reset_index(drop = True), pd.DataFrame(master_y_pred[2]), pd.DataFrame(master_y_pred[3]).reset_index(drop = True)], axis = 1).reset_index(drop = True)\nvalid_pred_df.columns = ['BraTS21ID', 'MGMT_value', 'T2w + T1wCE + T1w pred', 'FLAIR + T2w + T1w pred', 'FLAIR + T2w + T1wCE pred', 'FLAIR + T1wCE + T1w pred']\nvalid_pred_df.head()","293097b5":"for i in range(0, len(mri_types)):\n    data = Dataset(df_train,mri_type = mri_types[i], batch_size=1)\n    model = models_3D_user_defined_CNN[i]\n    y_pred = model.predict(data)\n    y_pred = y_pred.reshape(-1)\n    train_pred_df[f'{mri_types[i]}_3D_user_defined_CNN_pred'] = y_pred","93eee7f3":"for i in range(0, len(mri_types)):\n    data = Dataset(df_valid,mri_type = mri_types[i], batch_size=1)\n    model = models_3D_user_defined_CNN[i]\n    y_pred = model.predict(data)\n    y_pred = y_pred.reshape(-1)\n    valid_pred_df[f'{mri_types[i]}_3D_user_defined_CNN_pred'] = y_pred","e534780a":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(mri_types)):\n    print('MRI type :', mri_types[i])\n\n    gc.collect()\n    torch.cuda.empty_cache()\n    train_data_retriever = DataRetriever(\n        df_train[\"BraTS21ID\"].values, \n        df_train[\"MGMT_value\"].values,\n        mri_types[i],\n        augment = False)\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=2,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(train_loader):\n        print(f\"{e}\/{len(train_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_3D_CNN_effnet[i]\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n            y_true.extend(batch[\"y\"].numpy().tolist())\n    \n    master_y_pred.append(y_pred)\n    master_y_true.append(y_true)","2e72a0c5":"# train_pred_df = pd.DataFrame(data = None)\n# train_pred_df[\"BraTS21ID\"] = df_train[\"BraTS21ID\"]\ntrain_pred_df['FLAIR pred - 3D effnet'] = master_y_pred[0]\ntrain_pred_df['T1w pred - 3D effnet'] = master_y_pred[1]\ntrain_pred_df['T1wCE pred - 3D effnet'] = master_y_pred[2]\ntrain_pred_df['T2w pred - 3D effnet'] = master_y_pred[3]\ntrain_pred_df.head()","648b4494":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(mri_types)):\n    print('MRI type :', mri_types[i])\n\n    gc.collect()\n    torch.cuda.empty_cache()\n    valid_data_retriever = DataRetriever(\n        df_valid[\"BraTS21ID\"].values, \n        df_valid[\"MGMT_value\"].values,\n        mri_types[i],\n        augment = False)\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever,\n        batch_size=2,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(valid_loader):\n        print(f\"{e}\/{len(valid_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_3D_CNN_effnet[i]\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n            y_true.extend(batch[\"y\"].numpy().tolist())\n    \n    master_y_pred.append(y_pred)\n    master_y_true.append(y_true)","a53a848f":"valid_pred_df = pd.DataFrame(data = None)\nvalid_pred_df[\"BraTS21ID\"] = df_valid[\"BraTS21ID\"]\nvalid_pred_df['FLAIR pred - 3D effnet'] = master_y_pred[0]\nvalid_pred_df['T1w pred - 3D effnet'] = master_y_pred[1]\nvalid_pred_df['T1wCE pred - 3D effnet'] = master_y_pred[2]\nvalid_pred_df['T2w pred - 3D effnet'] = master_y_pred[3]\nvalid_pred_df.head()","17fce95b":"flair_pred = train_pred_df['FLAIR pred - 3D effnet']\nt1w_pred = train_pred_df['T1w pred - 3D effnet']\nt1wce_pred = train_pred_df['T1wCE pred - 3D effnet']\nt2w_pred = train_pred_df['T2w pred - 3D effnet']","138ddeb7":"# Combinations\ny_pred = train_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\ny_true = df_train['MGMT_value']\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - mean')\n\ny_pred = train_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].median(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - median')\n\ny_pred = train_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].max(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - max')\n\ny_pred = flair_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - flair')\n\ny_pred = t1w_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t1w')\n\ny_pred = t1wce_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t1wce')\n\ny_pred = t2w_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t2w')","bb80b421":"flair_pred = valid_pred_df['FLAIR pred - 3D effnet']\nt1w_pred = valid_pred_df['T1w pred - 3D effnet']\nt1wce_pred = valid_pred_df['T1wCE pred - 3D effnet']\nt2w_pred = valid_pred_df['T2w pred - 3D effnet']","62dfe691":"# Combinations\ny_pred = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\ny_true = df_valid['MGMT_value']\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - mean')\n\ny_pred = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].median(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - median')\n\ny_pred = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].max(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - max')\n\ny_pred = flair_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - flair')\n\ny_pred = t1w_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t1w')\n\ny_pred = t1wce_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t1wce')\n\ny_pred = t2w_pred\n\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc, ' - t2w')","0d0698ae":"def classification_metrics(y_true, y_prob):\n    '''\n     Calculates classification metrics\n    :param y_true: true label\n    :param y_prob: probabilitites of true label\n    :param thrshold: threshold\n    :return: metrics\n    '''\n    \n    # calculating auroc values\n    fpr_rf, tpr_rf,thresholds = roc_curve(y_true, y_prob)\n    roc_auc_rf = auc(fpr_rf, tpr_rf)\n    optimal_idx = np.argmax(tpr_rf - fpr_rf)\n    optimal_threshold = thresholds[optimal_idx]\n        \n#         print(optimal_threshold)\n#         print(\"=====\"*20) \n#     if optimal_cal==False:\n#         optimal_threshold = thrshold   \n     \n    # generating prediction on the basis of certain threshold\n    y_pred = np.where(y_prob >= optimal_threshold, 1, 0)\n\n    # calculating tp,tn,fp,fn from confusion metrics\n    tn, fp, fn, tp = (confusion_matrix(y_true, y_pred)).ravel()\n\n    # calculating auprc\n    average_precision = average_precision_score(y_true, y_prob)\n\n    # calculating precision,recall and f1 sscore and accuracy\n    precision = (precision_score(y_true, y_pred))\n    recall = (recall_score(y_true, y_pred))\n    accuracy = (accuracy_score(y_true, y_pred))\n    f1_accuracy = (f1_score(y_true, y_pred))\n    from sklearn.metrics import cohen_kappa_score\n    kappa_score = cohen_kappa_score(y_true, y_pred, labels=None, weights=None)\n    binary_cross_entropy=log_loss(y_true, y_prob)\n    # creating dictionary of classification metric\n    target_mean=np.mean(y_true)\n    classification_metric_dict = {\"True_negatives\": tn,\n                                  \"False_positives\": fp,\n                                  \"False_negatives\": fn,\n                                  \"True_positives\": tp,\n                                  \"Accuracy\": accuracy,\n                                  \"Recall\": recall,\n                                  \"Precision\": precision,\n                                  \"f1_score\": f1_accuracy,\n                                  \"PR_AUC\": average_precision,\n                                  \"ROC_AUC\": roc_auc_rf,\n                                  \"Kappa Score\": kappa_score,\n                                  \"binary_cross_etropy\":binary_cross_entropy,\n                                  \"target_imbalance\":target_mean,\n                                  \"target_size\":len(y_true)\n                                  }\n\n    return classification_metric_dict, optimal_threshold\n\ndef classification_metrics_train(y_true, y_prob,threshold):\n    '''\n     Calculates classification metrics\n    :param y_true: true label\n    :param y_prob: probabilitites of true label\n    :param thrshold: threshold\n    :return: metrics\n    '''\n    \n    # calculating auroc values\n    fpr_rf, tpr_rf,thresholds = roc_curve(y_true, y_prob)\n    roc_auc_rf = auc(fpr_rf, tpr_rf)\n#     optimal_idx = np.argmax(tpr_rf - fpr_rf)\n    optimal_threshold = threshold\n        \n#         print(optimal_threshold)\n#         print(\"=====\"*20) \n#     if optimal_cal==False:\n#         optimal_threshold = thrshold   \n     \n    # generating prediction on the basis of certain threshold\n    y_pred = np.where(y_prob >= optimal_threshold, 1, 0)\n\n    # calculating tp,tn,fp,fn from confusion metrics\n    tn, fp, fn, tp = (confusion_matrix(y_true, y_pred)).ravel()\n\n    # calculating auprc\n    average_precision = average_precision_score(y_true, y_prob)\n\n    # calculating precision,recall and f1 sscore and accuracy\n    precision = (precision_score(y_true, y_pred))\n    recall = (recall_score(y_true, y_pred))\n    accuracy = (accuracy_score(y_true, y_pred))\n    f1_accuracy = (f1_score(y_true, y_pred))\n    from sklearn.metrics import cohen_kappa_score\n    kappa_score = cohen_kappa_score(y_true, y_pred, labels=None, weights=None)\n    binary_cross_entropy=log_loss(y_true, y_prob)\n    # creating dictionary of classification metric\n    target_mean=np.mean(y_true)\n    classification_metric_dict = {\"True_negatives\": tn,\n                                  \"False_positives\": fp,\n                                  \"False_negatives\": fn,\n                                  \"True_positives\": tp,\n                                  \"Accuracy\": accuracy,\n                                  \"Recall\": recall,\n                                  \"Precision\": precision,\n                                  \"f1_score\": f1_accuracy,\n                                  \"PR_AUC\": average_precision,\n                                  \"ROC_AUC\": roc_auc_rf,\n                                  \"Kappa Score\": kappa_score,\n                                  \"binary_cross_etropy\":binary_cross_entropy,\n                                  \"target_imbalance\":target_mean,\n                                  \"target_size\":len(y_true)\n                                  }\n\n    return classification_metric_dict, optimal_threshold","6488755c":"def objective_classification(X_train, y_train, X_val, y_val, target_value, trial):\n    \"\"\"It tries to find the best hyper-parameters for XGBOOST model for given task\n\n        Details:\n            It uses OPTUNA library which is based on Baseian-optimization to tune the hyper-params.\n\n        Args:\n            X_train: training data\n            X_test: testing data\n            y_tain: training label\n            y_val: validation label\n            trail: object of optuna for optimizing the task in hand\n\n        Returns:\n            best score till now\n\n    \"\"\"\n    if ((target_value)):\n        tree_methods = ['approx', 'hist', 'exact']\n        boosting_lists = ['gbtree', 'gblinear']\n        objective_list_reg = ['binary:logistic']  # 'reg:gamma', 'reg:tweedie'\n        boosting = trial.suggest_categorical('boosting', boosting_lists),\n        tree_method = trial.suggest_categorical('tree_method', tree_methods),\n        n_estimator = trial.suggest_int('n_estimators',20, 120, 10),\n        max_depth = trial.suggest_int('max_depth', 1, 10),\n        reg_alpha = trial.suggest_int('reg_alpha', 2,7),\n        reg_lambda = trial.suggest_int('reg_lambda', 2,7),\n        min_child_weight = trial.suggest_int('min_child_weight', 0,5),\n        gamma = trial.suggest_int('gamma', 0, 5),\n        learning_rate = trial.suggest_loguniform('learning_rate', 0.01, 0.1),\n        objective = trial.suggest_categorical('objective', objective_list_reg),\n        colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.8, 1, 0.05),\n        colsample_bynode = trial.suggest_discrete_uniform('colsample_bynode', 0.8, 1, 0.05),\n        colsample_bylevel = trial.suggest_discrete_uniform('colsample_bylevel', 0.8, 1, 0.05),\n        subsample = trial.suggest_discrete_uniform('subsample', 0.8, 1, 0.05),\n#         scale_pos_weight = trial.suggest_discrete_uniform('scale_pos_weight', 0, 3, 0.1)\n        nthread = -1\n        \n        \n    xgboost_tune = xgb.XGBClassifier(\n        tree_method=tree_method[0],\n#         boosting=boosting[0],\n        reg_alpha=reg_alpha[0],\n        reg_lambda=reg_lambda[0],\n        gamma=gamma[0],\n        objective=objective[0],\n        colsample_bynode=colsample_bynode[0],\n        colsample_bylevel=colsample_bylevel[0],\n        n_estimators=n_estimator[0],\n        max_depth=max_depth[0],\n        min_child_weight=min_child_weight[0],\n        learning_rate=learning_rate[0],\n        subsample=subsample[0],\n        colsample_bytree=colsample_bytree[0],\n#         scale_pos_weight=scale_pos_weight,\n        eval_metric='logloss',\n        num_class=1,\n        n_jobs=nthread,\n        random_state=SEED)\n    xgboost_tune.fit(X_train, y_train)\n    pred_val = xgboost_tune.predict(X_val)\n    \n    return roc_auc_score(y_val,pred_val)","ee47a06d":"cols = [x for x in train_pred_df.columns.tolist() if 'pred' in x.lower()]\n# get a list of models to evaluate\ndef get_models():\n\tmodels = dict()\n\tmodels['lr'] = LogisticRegression()\n\tmodels['knn'] = KNeighborsClassifier()\n\tmodels['cart'] = DecisionTreeClassifier()\n\tmodels['svm'] = SVC()\n\tmodels['bayes'] = GaussianNB()\n\treturn models\n \n# evaluate a given model using cross-validation\ndef evaluate_model(model, X, y):\n\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n\treturn scores\n \n# define dataset\nX = pd.concat([train_pred_df[cols],valid_pred_df[cols]], axis = 0).reset_index(drop = True)\ny = pd.concat([train_pred_df[['MGMT_value']],valid_pred_df[['MGMT_value']]], axis = 0).reset_index(drop = True)\ny = y['MGMT_value']\n# get the models to evaluate\nclassifier_models = get_models()\n# evaluate the models and store results\nresults, names = list(), list()\nfor name, model in classifier_models.items():\n\tscores = evaluate_model(model, X, y)\n\tresults.append(scores)\n\tnames.append(name)\n\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n# plot model performance for comparison\npyplot.boxplot(results, labels=names, showmeans=True)\npyplot.show()","94efa0a3":"model = LogisticRegression()\nmodel.fit(train_pred_df[cols], train_pred_df['MGMT_value'])\ntrain_pred = model.predict_proba(train_pred_df[cols])\ntrain_pred = [x[1] for x in train_pred]\nvalid_pred = model.predict_proba(valid_pred_df[cols])\nvalid_pred = [x[1] for x in valid_pred]\nmodel_performance_results = classification_metrics(train_pred_df['MGMT_value'], train_pred)\nprint('\\nTrain data performance:')\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\nprint('\\nValidation data performance:')\nmodel_performance_results = classification_metrics(valid_pred_df['MGMT_value'], valid_pred)\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\njoblib.dump(model, 'lr_model.pkl')","5e36b0a1":"train_pred = train_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\nvalid_pred = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\nmodel_performance_results = classification_metrics(train_pred_df['MGMT_value'], train_pred)\nprint('\\nTrain data performance:')\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\nprint('\\nValidation data performance:')\nmodel_performance_results = classification_metrics(valid_pred_df['MGMT_value'], valid_pred)\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)","6fb8b18c":"SEED = 42\nX_train = train_pred_df[cols]\ny_train = train_pred_df[['MGMT_value']]\nX_valid = valid_pred_df[cols]\ny_valid = valid_pred_df[['MGMT_value']]\n\n# # br = BoostARoota(metric='logloss')\n# # br.fit(X_train,y_train)\n# # X_train=X_train[br.keep_vars_.tolist()]\n# # X_valid=X_valid[br.keep_vars_.tolist()]\n\nstudy = optuna.create_study(direction='maximize', sampler=TPESampler(seed=SEED))\nstudy.optimize(\n    functools.partial(objective_classification, X_train, y_train, X_valid, y_valid,'trial'),\n            timeout=20)\n\nmodel_xgb = xgb.XGBClassifier(**study.best_params, random_state=SEED)\nmodel_xgb.fit(X_train,y_train)\n\ntrain_pred = model_xgb.predict_proba(train_pred_df[cols])\ntrain_pred = [x[1] for x in train_pred]\nvalid_pred = model_xgb.predict_proba(valid_pred_df[cols])\nvalid_pred = [x[1] for x in valid_pred]\n\nmodel_performance_results = classification_metrics(train_pred_df['MGMT_value'], train_pred)\nprint('\\nTrain data performance:')\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\nprint('\\nValidation data performance:')\nmodel_performance_results = classification_metrics(valid_pred_df['MGMT_value'], valid_pred)\ndisplay(pd.DataFrame(model_performance_results[0].items(), columns = ['Metric', 'Value']).T)\n\nimport joblib\nprint(\"Saving model .. \",end=\" \")\njoblib.dump(model,r\"XGBoost_model.pkl\")","82617208":"valid_pred_df.head()","4a912475":"valid_pred_df.columns","598e6159":"y_pred = list(valid_pred_df[['T2w + T1wCE + T1w pred',\n       'FLAIR + T2w + T1w pred', 'FLAIR + T2w + T1wCE pred',\n       'FLAIR + T1wCE + T1w pred']].mean(axis = 1))\ny_true = list(valid_pred_df['MGMT_value'])\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc)","a5493f7f":"y_pred = list(valid_pred_df[['FLAIR_3D_user_defined_CNN_pred',\n       'T1w_3D_user_defined_CNN_pred', 'T1wCE_3D_user_defined_CNN_pred',\n       'T2w_3D_user_defined_CNN_pred']].mean(axis = 1))\ny_true = list(valid_pred_df['MGMT_value'])\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc)","1b41d587":"y_pred = list(valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1))\ny_true = list(valid_pred_df['MGMT_value'])\nfpr, tpr, thresholds =roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"Area under the ROC curve : %f\" % roc_auc)\n\n####################################\n# The optimal cut off would be where tpr is high and fpr is low\n# tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n####################################\ni = np.arange(len(tpr)) # index for df\nroc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\nroc.iloc[(roc.tf-0).abs().argsort()[:1]]\n\n# Plot tpr vs 1-fpr\nfig, ax = pl.subplots()\npl.plot(roc['tpr'])\npl.plot(roc['1-fpr'], color = 'red')\npl.xlabel('Index')\npl.ylabel('TPR\/(1-FPR)')\npl.title('Receiver operating characteristic')\noptimal_threshold = roc.iloc[(roc.tf-0).abs().argsort()[:1]]['thresholds'].iloc[0]\nprint('Optimal threshold:', optimal_threshold*100,'%')","299531fe":"# ROC curve\nfpr, tpr, _ = roc_curve(y_true, y_pred)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(5, 5))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.plot([roc.iloc[(roc.tf-0).abs().argsort()[:1]]['fpr'].iloc[0], roc.iloc[(roc.tf-0).abs().argsort()[:1]]['fpr'].iloc[0]], [0, 1], color='green', lw=2, linestyle='--') # Performance metrics at optimal threshold\nplt.xlim([-0.01, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","17667133":"valid_pred_df['Final pred'] = valid_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\n\nfpr, tpr, thresholds =roc_curve(valid_pred_df['MGMT_value'], valid_pred_df['Final pred'])\nroc_auc = auc(fpr, tpr)\nprint(\"\\nArea under the ROC curve : %f\" % roc_auc)\n\nprint('\\n','# False positives:',valid_pred_df[(valid_pred_df['Final pred']>0.5) & (valid_pred_df['MGMT_value']==0)].shape[0],'\\n')\nvalid_pred_df[(valid_pred_df['Final pred']>0.5) & (valid_pred_df['MGMT_value']==0)]","3b556e48":"print('\\n','# False negatives:',valid_pred_df[(valid_pred_df['Final pred']<0.5) & (valid_pred_df['MGMT_value']==1)].shape[0],'\\n')\nvalid_pred_df[(valid_pred_df['Final pred']<0.5) & (valid_pred_df['MGMT_value']==1)]","1edfd74e":"# a = load_dicom_images_3d(scan_id = '00819')\n# plt.imshow(a[0,:,:,49], cmap = 'gray')","a42db719":"# master_y_pred = []\n# for i in range(0,len(mri_types)):\n#     print('MRI type :', mri_types[i])\n\n#     train_data_retriever = DataRetriever(\n#         df_train[\"BraTS21ID\"].values, \n#         df_train[\"MGMT_value\"].values,\n#         mri_types[i],\n#         augment = False)\n\n#     train_loader = torch_data.DataLoader(\n#         train_data_retriever,\n#         batch_size=4,\n#         shuffle=False,\n#         num_workers=8,\n#     )\n\n#     y_pred = []\n    \n#     for e, batch in enumerate(train_loader):\n#         print(f\"{e}\/{len(train_loader)}\", end=\"\\r\")\n#         with torch.no_grad():\n#             tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n#             model = models[i]\n#             embeddings_df = model.base_model(batch[\"X\"].to(device))\n#             y_pred.extend(embeddings_df)\n            \n#     master_y_pred.append(y_pred)","f816bbc9":"# neurons_num = 1000\n\n# for i in tqdm(range(0, len(mri_types))):\n#     for j in range(0, neurons_num):\n#         train_pred_df[mri_types[i]+'_'+str(j+1)] = [master_y_pred[i][m][0].cpu().numpy().tolist() for m in range(0, len(train_pred_df))]","2342be58":"# master_y_pred = []\n# for i in range(0,len(mri_types)):\n#     print('MRI type :', mri_types[i])\n\n#     valid_data_retriever = DataRetriever(\n#         df_valid[\"BraTS21ID\"].values, \n#         df_valid[\"MGMT_value\"].values,\n#         mri_types[i],\n#         augment = False)\n\n#     valid_loader = torch_data.DataLoader(\n#         valid_data_retriever,\n#         batch_size=4,\n#         shuffle=False,\n#         num_workers=8,\n#     )\n\n#     y_pred = []\n    \n#     for e, batch in enumerate(valid_loader):\n#         print(f\"{e}\/{len(valid_loader)}\", end=\"\\r\")\n#         with torch.no_grad():\n#             tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n#             model = models[i]\n#             embeddings_df = model.base_model(batch[\"X\"].to(device))\n#             y_pred.extend(embeddings_df)\n            \n#     master_y_pred.append(y_pred)","b4fadcd8":"# for i in tqdm(range(0, len(mri_types))):\n#     for j in range(0, neurons_num):\n#         valid_pred_df[mri_types[i]+'_'+str(j+1)] = [master_y_pred[i][m][0].cpu().numpy().tolist() for m in range(0, len(valid_pred_df))]","5149d16f":"# Neural network\n\nX_train = train_pred_df[cols]\ny_train = train_pred_df['MGMT_value']\n\nsimple_nn_model = Sequential()\nsimple_nn_model.add(Dense(100, input_dim=12, activation='relu'))\nsimple_nn_model.add(Dense(50, activation='relu'))\nsimple_nn_model.add(Dense(10, activation='relu'))\nsimple_nn_model.add(Dense(1, activation='sigmoid'))\nsimple_nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[AUC(name = 'auc'),'accuracy'])\n\n# Define callbacks\nmodel_save = ModelCheckpoint('simple_nn_model.h5', \n                             save_best_only = True, \n                             monitor = 'val_auc', \n                             mode = 'max', verbose = 1)\nearly_stop = EarlyStopping(monitor = 'val_auc', \n                           patience = 40, mode = 'max', verbose = 1,\n                           restore_best_weights = True)\n\nsimple_nn_model.fit(X_train, y_train, validation_data=(valid_pred_df[cols], valid_pred_df['MGMT_value']), epochs=500, batch_size=10,\n        shuffle=True,\n        verbose=1,\n        callbacks = [model_save, early_stop],\n    )","7b7f94d9":"y_pred = [x[0] for x in simple_nn_model.predict(train_pred_df[cols]).tolist()]\nfpr, tpr, thresholds =roc_curve(train_pred_df['MGMT_value'], y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"\\n Training data: Area under the ROC curve - %f\" % roc_auc)\n\ny_pred = [x[0] for x in simple_nn_model.predict(valid_pred_df[cols])]\nfpr, tpr, thresholds =roc_curve(valid_pred_df['MGMT_value'], y_pred)\nroc_auc = auc(fpr, tpr)\nprint(\"\\n Validation data: Area under the ROC curve - %f\" % roc_auc)","d2eebfa6":"submission = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv\")\nsubmission['BraTS21ID5'] = submission['BraTS21ID'].apply(lambda x: format(x, '05d'))","dd7e3162":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(valid_combinations)):\n    print('Combination :', list(valid_combinations[i]))\n\n    test_data_retriever = DataRetriever_2D_CNN(\n        submission[\"BraTS21ID\"].values, \n        np.array([]),\n        list(valid_combinations[i]), rotate = 0)\n\n    test_loader = torch_data.DataLoader(\n        test_data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(test_loader):\n        print(f\"{e}\/{len(test_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_2D_CNN[i]\n            tmp_res =torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n    \n    master_y_pred.append(y_pred)","0d11d4f3":"test_pred_df = pd.concat([pd.DataFrame(submission[\"BraTS21ID\"].values).reset_index(drop = True), pd.DataFrame(master_y_pred[0]).reset_index(drop = True), pd.DataFrame(master_y_pred[1]).reset_index(drop = True), pd.DataFrame(master_y_pred[2]), pd.DataFrame(master_y_pred[3]).reset_index(drop = True)], axis = 1).reset_index(drop = True)\ntest_pred_df.columns = ['BraTS21ID', 'T2w + T1wCE + T1w pred', 'FLAIR + T2w + T1w pred', 'FLAIR + T2w + T1wCE pred', 'FLAIR + T1wCE + T1w pred']\ntest_pred_df.head()","0c9fcb1c":"for i in range(0, len(mri_types)):\n    data = Dataset(submission,mri_type = mri_types[i], batch_size=1, is_train = False)\n    model = models_3D_user_defined_CNN[i]\n    y_pred = model.predict(data)\n    y_pred = y_pred.reshape(-1)\n    test_pred_df[f'{mri_types[i]}_3D_user_defined_CNN_pred'] = y_pred","da6019ea":"master_y_pred = []\nmaster_y_true = []\nfor i in range(0,len(mri_types)):\n    print('MRI type :', mri_types[i])\n\n    gc.collect()\n    torch.cuda.empty_cache()\n    test_data_retriever = DataRetriever(\n        submission[\"BraTS21ID\"].values, \n        np.array([]),\n        mri_types[i],\n        augment = False)\n\n    test_loader = torch_data.DataLoader(\n        test_data_retriever,\n        batch_size=2,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    y_pred = []\n    y_true = []\n\n    for e, batch in enumerate(test_loader):\n        print(f\"{e}\/{len(test_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n            model = models_3D_CNN_effnet[i]\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n            y_pred.extend(tmp_pred)\n    \n    master_y_pred.append(y_pred)","4ef66394":"test_pred_df['FLAIR pred - 3D effnet'] = master_y_pred[0]\ntest_pred_df['T1w pred - 3D effnet'] = master_y_pred[1]\ntest_pred_df['T1wCE pred - 3D effnet'] = master_y_pred[2]\ntest_pred_df['T2w pred - 3D effnet'] = master_y_pred[3]\ntest_pred_df.head()","e8c718aa":"model_xgb = joblib.load(r\".\/XGBoost_model.pkl\")\ntest_pred_df['XGBoost pred'] = model_xgb.predict_proba(test_pred_df[cols])[:,1]\nsimple_nn_model = Sequential()\nsimple_nn_model.add(Dense(100, input_dim=12, activation='relu'))\nsimple_nn_model.add(Dense(50, activation='relu'))\nsimple_nn_model.add(Dense(10, activation='relu'))\nsimple_nn_model.add(Dense(1, activation='sigmoid'))\n\ntest_pred_df['Simple NN pred'] = simple_nn_model.predict(test_pred_df[cols])\nmodel = joblib.load('.\/lr_model.pkl')\ntest_pred_df['lr pred'] = model.predict_proba(test_pred_df[cols])[:,1]","54f99296":"test_pred_df.head()","6f513090":"y_pred = test_pred_df[['FLAIR pred - 3D effnet','T1w pred - 3D effnet','T1wCE pred - 3D effnet','T2w pred - 3D effnet']].mean(axis = 1)\nids = test_pred_df['BraTS21ID']","1cbfad94":"submission = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred})\nsubmission.to_csv(\"submission.csv\", index=False)","61e37295":"print(submission.shape)\nsubmission.head()","f6787c43":"plt.figure(figsize=(5, 5))\nplt.hist(submission[\"MGMT_value\"]);","0e04afb4":"<a id=\"100\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Stacking models<center><h2>","12045fa3":"### Transfer learning - 3D CNN","ae7cae2b":"The work uses some ideas from next great works:\n- https:\/\/www.kaggle.com\/avloss\/eda-with-animation - animation technique\n- https:\/\/www.kaggle.com\/victorfernandezalbor\/brats-20-win-nnunet-segment-with-brats-21-rsna - nnUnet","11c41e03":"# Predictions on test data","e25f50fa":"# LSTM","07cb9e98":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:darkviolet; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation<\/center><\/h3>\n\n* [Overview](#1)\n* [Data Visualization](#2)\n    \n\n* [Competition Metric](#10)\n* [Sample Submission](#20)\n    \n\n* [Modeling](#100)","80d5b482":"### Identify images with tumor","a68821d2":"# nnUnet","4b96a75e":"### User defined 3D CNN","ab67ef49":"# RSNA-MICCAI Brain Tumor Radiogenomic Classification - Exploratory Data Analysis and Modeling\n\n\n### Predict the status of a genetic biomarker important for brain cancer treatment\n\nQuick Exploratory Data Analysis for [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification) challenge    \n\n\n","ed5146e3":"Research papers to try out: \n<https:\/\/link.springer.com\/article\/10.1007\/s40998-021-00426-9>","efca0a7e":"### Brain tumor identification model","52c35f5a":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/29653\/logos\/header.png)","b9f960e0":"<a id=\"10\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Competition Metric<center><h2>","28216113":"# Error analysis","fa7f1cf8":"# Transfer learning - nnUnet + CNN","78eb8a67":"<a id=\"100\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Modeling<center><h2>","4bbed53d":"# Pyradiomics","2f502a32":"<a id=\"20\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Sample Submission<center><h2>","134daea2":"Submissions are evaluated on [area under the ROC curve](https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic) between the predicted probability and the observed target.","5fd304ec":"<a id=\"1\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Overview<center><h2>","5136ab0c":"Ratio 'T1w\/T2w' : <https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC6465519\/>","d8195cfa":"## 2D CNN","4da7cdef":"# Selecting best model","c4f665c3":"<a id=\"2\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>Data Visualization<center><h2>","06e8ada9":"**train\/** - folder containing the training files, with each top-level folder representing a subject  \n**train_labels.csv** - file containing the target MGMT_value for each subject in the training data (e.g. the presence of MGMT promoter methylation)   \n**test\/** - the test files, which use the same structure as train\/; your task is to predict the MGMT_value for each subject in the test data. NOTE: the total size of the rerun test set (Public and Private) is ~5x the size of the Public test set   \n**sample_submission.csv** - a sample submission file in the correct format"}}