{"cell_type":{"4e56bf68":"code","4526398c":"code","2e1ffddc":"code","53d7a8a1":"markdown","f92de56b":"markdown"},"source":{"4e56bf68":"pip install transformers","4526398c":"%%time\nimport os\nimport tqdm\nimport textwrap\nimport json\nimport prettytable\nimport logging\nimport pickle\nimport warnings\nwarnings.simplefilter('ignore')\n\nfrom  transformers import *\nimport pandas as pd\nimport scipy\nfrom sentence_transformers import SentenceTransformer\n\nCOVID_BROWSER_ASCII = \"\"\"\n================================================================================\n  _____           _     _      __  ___    ____                                  \n \/ ____|         (_)   | |    \/_ |\/ _ \\  |  _ \\                                 \n| |     _____   ___  __| | ___ | | (_) | | |_) |_ __ _____      _____  ___ _ __ \n| |    \/ _ \\ \\ \/ \/ |\/ _` ||___|| |\\__, | |  _ <| '__\/ _ \\ \\ \/\\ \/ \/ __|\/ _ \\ '__|\n| |___| (_) \\ V \/| | (_| |     | |  \/ \/  | |_) | | | (_) \\ V  V \/\\__ \\  __\/ |   \n \\_____\\___\/ \\_\/ |_|\\__,_|     |_| \/_\/   |____\/|_|  \\___\/ \\_\/\\_\/ |___\/\\___|_|   \n=================================================================================\n\"\"\"\n\nCOVID_BROWSER_INTRO = \"\"\"\nThis demo uses a state-of-the-art language model trained on scientific papers to\nsearch passages matching user-defined queries inside the COVID-19 Open Research\nDataset. Ask something like 'Is smoking a risk factor for Covid-19?' to retrieve\nrelevant abstracts.\\n\n\"\"\"\n\nBIORXIV_PATH = '\/kaggle\/input\/all-cleaned\/biroxiv_clean'#because i pre-processed them using the  cleaner for a former notebook\n#the two followings elements are not used so i comment them: \n\n#COMM_USE_PATH = '\/kaggle\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/'\n#NONCOMM_USE_PATH = '\/kaggle\/input\/CORD-19-research-challenge\/noncomm_use_subset\/noncomm_use_subset\/'\n\nMETADATA_PATH = '\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv'\n\nDATA_PATH = '\/kaggle\/input\/CORD-19-research-challenge'\nMODELS_PATH = 'models'\nMODEL_NAME = 'scibert-nli'\nCORPUS_PATH = os.path.join(DATA_PATH, 'corpus.pkl')\nMODEL_PATH = os.path.join(MODELS_PATH, MODEL_NAME)\nEMBEDDINGS_PATH = os.path.join(DATA_PATH, f'{MODEL_NAME}-embeddings.pkl')\n\n\ndef load_json_files(dirname):\n    filenames = [file for file in os.listdir(dirname) if file.endswith('.json')]\n    raw_files = []\n\n    for filename in tqdm(filenames):\n        filename = dirname + filename\n        file = json.load(open(filename, 'rb'))\n        raw_files.append(file)\n    print('Loaded', len(raw_files), 'files from', dirname)\n    return raw_files\n\n\ndef create_corpus_from_json(files):\n    corpus = []\n    for file in tqdm(files):\n         for item in file['abstract']:\n            corpus.append(item['text'])\n        for item in file['body_text']:\n            corpus.append(item['text'])\n    print('Corpus size', len(corpus))\n    return corpus\n\n\ndef cache_corpus(mode='CSV'):\n    corpus = []\n    if mode == 'CSV':\n        df = pd.read_csv(METADATA_PATH)\n        corpus = [a for a in df['abstract'] if type(a) == str and a != \"Unknown\"]\n        print('Corpus size', len(corpus))\n    elif mode == 'JSON':\n        biorxiv_files = load_json_files(BIORXIV_PATH)\n        #comm_use_files = load_json_files(COMM_USE_PATH)\n        #noncomm_use_files = load_json_files(NONCOMM_USE_PATH)\n        corpus = create_corpus_from_json(biorxiv_files) #+ comm_use_files + noncomm_use_files\n    else:\n        raise AttributeError('Mode should be either CSV or JSON')\n    '''with open(CORPUS_PATH, 'wb') as file:\n        pickle.dump(corpus, file)'''\n    return corpus\n\n\ndef ask_question(query, model, corpus, corpus_embed, top_k=5):\n    \"\"\"\n    Adapted from https:\/\/www.kaggle.com\/dattaraj\/risks-of-covid-19-ai-driven-q-a\n    \"\"\"\n    queries = [query]\n    query_embeds = model.encode(queries, show_progress_bar=False)\n    for query, query_embed in zip(queries, query_embeds):\n        distances = scipy.spatial.distance.cdist([query_embed], corpus_embed, \"cosine\")[0]\n        else:\n        print(\"Loading the corpus from\", CORPUS_PATH, '...')\n        with open(CORPUS_PATH, 'rb') as corpus_pt:\n            corpus = pickle.load(corpus_pt)\n\n    model =  SentenceTransformer('bert-base-nli-stsb-mean-tokens')\n\n    if not os.path.exists(EMBEDDINGS_PATH):\n        print(\"Computing and caching model embeddings for future use...\")\n        embeddings = model.encode(corpus, show_progress_bar=True)\n        '''with open(EMBEDDINGS_PATH, 'wb') as file:\n            pickle.dump(embeddings, file)'''\n    else:\n        print(\"Loading model embeddings from\", EMBEDDINGS_PATH, '...')\n        with open(EMBEDDINGS_PATH, 'rb') as file:\n            embeddings = pickle.load(file)\n\n    ","2e1ffddc":"questions = ['Real-time tracking of whole genomes', ' Access to geographic and temporal diverse sample sets to understand geographic distribution and genomic differences', 'Evidence of whether farmers are infected', 'Surveillance of mixed wildlife- livestock farms for SARS-CoV-2', 'Experimental infections to test host range for this pathogen', 'Animal host(s) and any evidence of continued spill-over to humans', 'Experimental infections to test host range for this pathogen', 'Socioeconomic and behavioral risk factors for this spill-over', 'Sustainable risk reduction strategies']\nfor i in range(len(questions)):\n        query = questions[i]\n        print(f'Query {i+1} : {query}\\n\\n')\n        results = ask_question(query, model, corpus, embeddings)\n        show_answers(results)\n","53d7a8a1":"****DISCLAIMER: This model is not mine.\n\nIt has been found on the following notebooks\nhttps:\/\/www.kaggle.com\/mobassir\/mining-covid-19-scientific-papers\nhttps:\/\/www.kaggle.com\/theamrzaki\/covid-19-bert-researchpapers-semantic-search\n\nand it has been modified according to what we want it in our particular case to do. It here only put as a module from a more general project that i will publish soon. If you want to know more about it, I highly recommend you to check those notebooks as well as this https:\/\/towardsdatascience.com\/covid-19-bert-literature-search-engine-4d06cdac08bd website where the model is explained. ","f92de56b":"Here I adapt the queries to the taks of interest to me, which are, the taks around the genetic question. The tasks are: \n1. Real-time tracking of whole genomes\n2. Access to geographic and temporal diverse sample sets to understand geographic distribution and genomic differences\n3. Evidence of whether farmers are infected\n4. Surveillance of mixed wildlife- livestock farms for SARS-CoV-2\n5. Experimental infections to test host range for this pathogen\n6. Animal host(s) and any evidence of continued spill-over to humans\n7. Experimental infections to test host range for this pathogen\n8. Socioeconomic and behavioral risk factors for this spill-over\n9. Sustainable risk reduction strategies\n"}}