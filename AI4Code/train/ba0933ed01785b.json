{"cell_type":{"3751ffed":"code","9a200483":"code","97fba68c":"code","7dd1d38a":"code","7ec72f49":"code","8c96927e":"code","84ff57e5":"code","815a1633":"code","d72c34f0":"code","0d1dc5fd":"code","d672bbbb":"code","1c9609ad":"code","6387eb08":"code","359ffd2f":"code","b6119168":"code","2215d493":"code","3b05688b":"code","bf4f0608":"code","4c65d353":"code","f6b10dec":"code","c52429fc":"code","f985e3f7":"markdown","2ecb0b6a":"markdown","fd0ad2ab":"markdown","1a544f3d":"markdown","b9fa1c9c":"markdown","e83ef809":"markdown","2f8451e2":"markdown","7ee44992":"markdown","a59556a3":"markdown","8c682a92":"markdown","17c5557c":"markdown"},"source":{"3751ffed":"import numpy as np\nimport pandas as pd\nfrom keras import Model\nfrom keras.applications.mobilenet import MobileNet, preprocess_input\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\nfrom keras.layers import Conv2D, Reshape\nfrom keras.utils import Sequence\nfrom keras.backend import epsilon\nimport tensorflow as tf\n\nfrom PIL import Image\n\nimport os\nimport random\n\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\nimport numpy as np\nimport cv2\n\nnp.random.seed(1)","9a200483":"train = pd.read_csv(\"..\/input\/racoon-detection\/train_labels_.csv\")","97fba68c":"train.head()","7dd1d38a":"train.shape","7ec72f49":"IMAGE_SIZE = 128","8c96927e":"coords=train[[\"width\",\"height\",\"xmin\",\"ymin\",\"xmax\",\"ymax\"]]\n\ncoords[\"xmin\"] = coords[\"xmin\"] *IMAGE_SIZE\/coords[\"width\"]\ncoords[\"xmax\"] = coords[\"xmax\"]*IMAGE_SIZE \/coords[\"width\"]\ncoords[\"ymin\"] = coords[\"ymin\"] *IMAGE_SIZE\/coords[\"height\"]\ncoords[\"ymax\"] = coords[\"ymax\"] *IMAGE_SIZE\/coords[\"height\"]\n\ncoords.drop([\"width\",\"height\"],axis =1,inplace=True)\ncoords.head()","84ff57e5":"paths = train[\"filename\"]\nlen(paths)","815a1633":"images = \"..\/input\/racoon-detection\/Racoon Images\/images\/\"\n\nbatch_images = np.zeros((len(paths), IMAGE_SIZE, IMAGE_SIZE,3), dtype=np.float32)\n\nfor i, f in enumerate(paths):\n  #print(f)\n  img = Image.open(images+f)\n  img = img.resize((IMAGE_SIZE, IMAGE_SIZE))\n  img = img.convert('RGB')\n  batch_images[i] = preprocess_input(np.array(img, dtype=np.float32))","d72c34f0":"ALPHA = 1.0\n\nmodel = MobileNet(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3), include_top=False, alpha=ALPHA)","0d1dc5fd":"for layers in model.layers:\n  layers.trainable = False\n\nx = model.layers[-1].output\nx = Conv2D(4, kernel_size = 4, name=\"coords\")(x)\nx = Reshape((4,))(x)\n\nmodel = Model(inputs = model.inputs, outputs = x)\n","d672bbbb":"model.summary()","1c9609ad":"def loss(gt,pred):\n    intersections = 0\n    unions = 0\n    diff_width = np.minimum(gt[:,0] + gt[:,2], pred[:,0] + pred[:,2]) - np.maximum(gt[:,0], pred[:,0])\n    diff_height = np.minimum(gt[:,1] + gt[:,3], pred[:,1] + pred[:,3]) - np.maximum(gt[:,1], pred[:,1])\n    intersection = diff_width * diff_height\n    \n    # Compute union\n    area_gt = gt[:,2] * gt[:,3]\n    area_pred = pred[:,2] * pred[:,3]\n    union = area_gt + area_pred - intersection\n\n#     Compute intersection and union over multiple boxes\n    for j, _ in enumerate(union):\n        if union[j] > 0 and intersection[j] > 0 and union[j] >= intersection[j]:\n            intersections += intersection[j]\n            unions += union[j]\n\n    # Compute IOU. Use epsilon to prevent division by zero\n    iou = np.round(intersections \/ (unions + epsilon()), 4)\n    iou = iou.astype(np.float32)\n    return iou\n\ndef IoU(y_true, y_pred):\n    iou = tf.py_function(loss, [y_true, y_pred], tf.float32)\n    return iou","6387eb08":"gt = coords\n\nPATIENCE=10\n\nmodel.compile(optimizer = \"Adam\", loss = \"mse\", metrics = [IoU])\n\nstop = EarlyStopping(monitor='val_iou', patience=PATIENCE, mode=\"max\" )\n\nreduce_lr = ReduceLROnPlateau(monitor='val_iou',factor=0.2,patience=PATIENCE, min_lr=1e-7, verbose=1, mode=\"max\" )\n\nmodel.fit(batch_images, gt, epochs=100,callbacks=[stop,reduce_lr], verbose = 2)","359ffd2f":"print(paths)\nprint(random.choice(paths))","b6119168":"test_img = random.choice(paths)","2215d493":"filename = images+ test_img\nprint(filename)\nunscaled = cv2.imread(filename)\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Create figure and axes\nfig,ax = plt.subplots(1)\n#ax.show(unscaled)\n#plt.show()","3b05688b":"image_height, image_width, _ = unscaled.shape\nimage = cv2.resize(unscaled,(IMAGE_SIZE,IMAGE_SIZE))\nfeat_scaled = preprocess_input(np.array(image, dtype=np.float32))","bf4f0608":"region = model.predict(x = np.array([feat_scaled]))[0]","4c65d353":"from keras.models import model_from_json\nimport numpy\nmodel_json=model.to_json();\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save_weights(\"model.h5\")    ","f6b10dec":"x0 = int(region[0] * image_width \/ IMAGE_SIZE) \ny0 = int(region[1] * image_height \/ IMAGE_SIZE)\n\nx1 = int((region[2]) * image_width \/ IMAGE_SIZE)\ny1 = int((region[3]) * image_height \/ IMAGE_SIZE)","c52429fc":"# Create figure and axes\nfig,ax = plt.subplots(1)\n\n# Display the image\nax.imshow(unscaled)\n\n# Create a Rectangle patch\nrect = patches.Rectangle((x0, y0), (x1 - x0) , (y1 - y0) , linewidth=2, edgecolor='r', facecolor='none')\n\n# Add the patch to the Axes\nax.add_patch(rect)\n\nplt.show()","f985e3f7":"## Importing the necessary libraries","2ecb0b6a":"## Compiling the model","fd0ad2ab":"## Pick a test image from the given data","1a544f3d":"* Create a list variable known as 'path' which has all the path for all the training images\n* Create an array 'coords' which has the resized coordinates of the bounding box for the training images","b9fa1c9c":"## Define a custom loss function IoU which calculates Intersection Over Union","e83ef809":"## Reading the training data from train.csv file","2f8451e2":"## Plotting the predicted bounding box","7ee44992":"* Predict the coordinates of the bounding box for the given test image","a59556a3":"* Scaling the BBox","8c682a92":"## Preprocessing of Test Image\nResizing the image to 128 * 128 and preprocess the image for the MobileNet model","17c5557c":"## Model Building\n* Building the model using transfer learning"}}