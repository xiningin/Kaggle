{"cell_type":{"e3382a50":"code","5f2a7534":"code","36245337":"code","9343ae5d":"code","8413bea1":"code","4d5e0803":"code","dc31c7b5":"code","1a2bd7b7":"code","adb72cdc":"code","524d9922":"code","f7ec0dfb":"code","e200a339":"code","34eb97c6":"markdown","c0807556":"markdown","58da6f00":"markdown","5c07f4cc":"markdown","1ec4f6c5":"markdown","de059a18":"markdown","c35127fc":"markdown","f9df7650":"markdown","b598da6f":"markdown"},"source":{"e3382a50":"# basic lib\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# LIME lib\nimport lime\nfrom lime import lime_image\nfrom skimage.segmentation import mark_boundaries\n\n# CNN lib\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop\nfrom keras import preprocessing\n\n# warnings\nimport warnings\nwarnings.filterwarnings('ignore') ","5f2a7534":"# import data\n\npath_cats = []\ntrain_path_cats = '..\/input\/training_set\/training_set\/cats'\nfor path in os.listdir(train_path_cats):\n    if '.jpg' in path:\n        path_cats.append(os.path.join(train_path_cats, path))\npath_dogs = []\ntrain_path_dogs = '..\/input\/training_set\/training_set\/dogs'\nfor path in os.listdir(train_path_dogs):\n    if '.jpg' in path:\n        path_dogs.append(os.path.join(train_path_dogs, path))\nlen(path_dogs), len(path_cats)\n\n\n# load training set\ntraining_set = np.zeros((6000, 150, 150, 3), dtype='float32')\nfor i in range(6000):\n    if i < 3000:\n        path = path_dogs[i]\n        img = preprocessing.image.load_img(path, target_size=(150, 150))\n        training_set[i] = preprocessing.image.img_to_array(img)\n    else:\n        path = path_cats[i - 3000]\n        img = preprocessing.image.load_img(path, target_size=(150, 150))\n        training_set[i] = preprocessing.image.img_to_array(img)\n        \n# load validation set\nvalidation_set = np.zeros((2000, 150, 150, 3), dtype='float32')\nfor i in range(2000):\n    if i < 1000:\n        path = path_dogs[i + 3000]\n        img = preprocessing.image.load_img(path, target_size=(150, 150))\n        validation_set[i] = preprocessing.image.img_to_array(img)\n    else:\n        path = path_cats[i + 2000]\n        img = preprocessing.image.load_img(path, target_size=(150, 150))\n        validation_set[i] = preprocessing.image.img_to_array(img)","36245337":"# plot show data\n\nplt.figure(figsize = (12,10))\nrow, colums = 4, 4\nfor i in range(16):  \n    plt.subplot(colums, row, i+1)\n    image = training_set[i].astype(np.uint8)\n    plt.imshow(image)\nplt.show()","9343ae5d":"# build CNN\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (5, 5), activation='relu',\n                       input_shape=(150, 150, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation='relu',\n                       input_shape=(150, 150, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',\n             optimizer=RMSprop(lr=1e-4),\n             metrics=['acc'])\n\nmodel.summary()","8413bea1":"# make target tensor\ntrain_labels = np.zeros((3000,))\ntrain_labels = np.concatenate((train_labels, np.ones((3000,))))\nvalidation_labels = np.zeros((1000,))\nvalidation_labels = np.concatenate((validation_labels, np.ones((1000,))))\n\ntrain_datagen = preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow(\n    training_set,\n    train_labels,\n    batch_size=32)\n\nvalidation_generator = train_datagen.flow(\n    validation_set,\n    validation_labels,\n    batch_size=32)","4d5e0803":"# fit the model\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs= 8,\n    validation_steps=50,\n    validation_data=validation_generator,\n)","dc31c7b5":"# create lime ImageExplainer\nexplainer = lime_image.LimeImageExplainer()","1a2bd7b7":"image_number = 2\n\n\nimage = training_set[image_number].astype(np.uint8)\nimage * 1\/255\nexplanation = explainer.explain_instance(image, model.predict, top_labels=5, hide_color=0, num_samples=1000)\ntemp, mask = explanation.get_image_and_mask(0, positive_only=False, num_features=5, hide_rest=False)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask).astype(np.uint8))","adb72cdc":"# Check number of images \n\nplt.figure(figsize = (12,10))\nrow, colums = 3, 3\nfor i in range(9):  \n    plt.subplot(colums, row, i+1)\n    image = training_set[i].astype(np.uint8)\n    image * 1\/255\n    explanation = explainer.explain_instance(image, model.predict, top_labels=5, hide_color=0, num_samples=1000)\n    temp, mask = explanation.get_image_and_mask(0, positive_only=False, num_features=5, hide_rest=False)\n    plt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask).astype(np.uint8))\nplt.show()","524d9922":"image_number = 20\n\n\nimage = training_set[image_number].astype(np.uint8)\nimage * 1\/255\nexplanation = explainer.explain_instance(image, model.predict, top_labels=5, hide_color=0, num_samples=1000)\ntemp, mask = explanation.get_image_and_mask(0, positive_only=False, num_features=5, hide_rest=True)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask).astype(np.uint8))","f7ec0dfb":"image_number = 34\n\nimage = training_set[image_number].astype(np.uint8)\nimage * 1\/255\nexplanation = explainer.explain_instance(image, model.predict, top_labels=5, hide_color=0, num_samples=1000)\ntemp, mask = explanation.get_image_and_mask(0, positive_only=True, num_features=5, hide_rest=False)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask).astype(np.uint8))","e200a339":"image_number = 62\n\nimage = training_set[image_number].astype(np.uint8)\nimage * 1\/255\nexplanation = explainer.explain_instance(image, model.predict, top_labels=5, hide_color=0, num_samples=1000)\ntemp, mask = explanation.get_image_and_mask(0, positive_only=False, num_features=20, hide_rest=False)\nplt.imshow(mark_boundaries(temp \/ 2 + 0.5, mask).astype(np.uint8))","34eb97c6":"# 1. Create CNN model ","c0807556":"Now we have model. (Not the best model but enough for this tutorial)\n\n## Lest check the model with *Lime* ","58da6f00":"num_features = 20","5c07f4cc":"This kernel is assume that you know about LIME, \n\nIf you don't please take a look at [LIME](https:\/\/www.youtube.com\/watch?v=CY3t11vuuOM&t=1343s)\n\nAlso check the libery [Here](https:\/\/github.com\/marcotcr\/lime)","1ec4f6c5":"You can show the explanation in diffrent ways:\n\npositive_only - Show only the positive or also the nagtive (green for positive and red for nagtive) \n\nnum_features - Number of features to show (by priority) \n\nhide_rest - Show only the features the explan and hide the rest ","de059a18":"positive_only = True","c35127fc":"Let show the first 9 images","f9df7650":"Lime is checking only 1 image at a time\n\nUse the explain_instance func to create an explanation,\nand use the get_image_and_mask for see the result \n\nexplain_instance:\n\nimage - image to explain\n\npredict - the predict func (you can pass any model prdict func) \n\ntop_labels - number of label to show in the explain (top 5 or any number you want) \n\nnum_samples - number of samples to create for the explain\n\n\n\n\n\nchange the image_number to check other images.","b598da6f":"Hide rest = True"}}