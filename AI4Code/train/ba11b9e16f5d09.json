{"cell_type":{"f0434fd1":"code","07ed94ad":"code","18ad992f":"code","d2fb0bce":"code","10a7eb15":"code","727834d2":"code","c9bd96c0":"code","66a5b2ce":"code","1b214283":"code","ad713965":"code","dc8d1421":"code","eecab3b8":"code","91bd3a6c":"code","522ddff3":"code","fd698531":"code","655d88af":"code","716c5a5c":"code","58657bf8":"code","3d86de0b":"code","9b7c2908":"code","27cd94d8":"code","d33350f0":"code","fed00cc7":"code","10701a27":"code","bf179310":"code","aa21a841":"code","b0656e48":"code","47fec027":"code","90a2a9db":"code","cf0c3ec0":"code","5a1a1a57":"code","bc184ef9":"code","d7daf580":"code","e2523f45":"code","ad726b5c":"code","c853fb08":"code","18fa5437":"code","cce32c82":"code","349c315f":"code","6fbbdbf5":"markdown","1e191251":"markdown","dd4d4fae":"markdown","c6ee5734":"markdown","ea7c2bbf":"markdown","c8cd7f3e":"markdown","c52fe69e":"markdown","8591f94e":"markdown","8fb5c71b":"markdown","fda012ab":"markdown","e40a709b":"markdown","ac11b995":"markdown","85dcfe24":"markdown","a48402f1":"markdown","83803667":"markdown","9f932af6":"markdown","eb440110":"markdown","265a58a6":"markdown","458de1fa":"markdown","7137220f":"markdown","7054941a":"markdown","aa2546c5":"markdown","77c4b194":"markdown","ec95237d":"markdown","d3b7b1a8":"markdown","6d34c1b9":"markdown","601088bf":"markdown","1fc9c2b2":"markdown","234aff82":"markdown"},"source":{"f0434fd1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","07ed94ad":"df = pd.read_csv('..\/input\/capstone-car-accident-serveity\/Data_Collisions.csv')\ndf.head()","18ad992f":"df.shape","d2fb0bce":"col_data = df[['SEVERITYCODE', 'X', 'Y', 'ADDRTYPE', 'COLLISIONTYPE',\n               'PERSONCOUNT', 'VEHCOUNT', 'JUNCTIONTYPE',  'WEATHER', 'ROADCOND', 'LIGHTCOND', \n               'SPEEDING', 'UNDERINFL', 'INATTENTIONIND']]\ncol_data.head()","10a7eb15":"for col in col_data.columns:\n    if ((col_data[col].value_counts()\/len(col_data[col])) > 0.8).any() == True:\n        print(col)","727834d2":"def list_count(columns, df):\n    for col in columns:\n        print(col)\n        print(df[col].value_counts())\n        print()\n\ndata_columns = ['SEVERITYCODE','ADDRTYPE', 'COLLISIONTYPE', 'JUNCTIONTYPE', 'WEATHER', \n 'ROADCOND','LIGHTCOND', 'SPEEDING', 'UNDERINFL', 'INATTENTIONIND']\n\n#Use value_counts() method in each column\nlist_count(data_columns, col_data)","c9bd96c0":"filterCond = (col_data.LIGHTCOND == 'Other') | (col_data.LIGHTCOND == 'Unknown') | \\\n                      (col_data.LIGHTCOND == 'Dark - Unknown Lighting') |\\\n                      (col_data.ROADCOND == 'Other') | (col_data.ROADCOND == 'Unknown') | \\\n                      (col_data.WEATHER == 'Other') | (col_data.WEATHER == 'Unknown') | \\\n                      (col_data.JUNCTIONTYPE == 'Other') | (col_data.JUNCTIONTYPE == 'Unknown') | \\\n                      (col_data.COLLISIONTYPE == 'Other')\ncol_data = col_data.drop(col_data[filterCond].index)","66a5b2ce":"col_data[\"LIGHTCOND\"] = col_data[\"LIGHTCOND\"].replace(\"Dark - Street Lights Off\", \"Dark - No Street Lights\")\ncol_data[\"UNDERINFL\"] = col_data[\"UNDERINFL\"].replace(\"N\", 0)\ncol_data[\"UNDERINFL\"] = col_data[\"UNDERINFL\"].replace(\"0\", 0)\ncol_data[\"UNDERINFL\"] = col_data[\"UNDERINFL\"].replace(\"1\", 1)\ncol_data[\"UNDERINFL\"] = col_data[\"UNDERINFL\"].replace(\"Y\", 1)\ncol_data[\"INATTENTIONIND\"] = col_data[\"INATTENTIONIND\"].replace(\"Y\", 1)\ncol_data[\"SPEEDING\"] = col_data[\"SPEEDING\"].replace(\"Y\", 1)","1b214283":"# Check the columns which has NaN values\ncol_data.isna().sum()","ad713965":"col_data['UNDERINFL'] = col_data['UNDERINFL'].fillna(0)\ncol_data['INATTENTIONIND'] = col_data['INATTENTIONIND'].fillna(0)\ncol_data['SPEEDING'] = col_data['SPEEDING'].fillna(0)","dc8d1421":"col_data.dropna(inplace=True)","eecab3b8":"col_data.info()","91bd3a6c":"col_data['SEVERITYCODE'].unique()","522ddff3":"# Rename severitycode to 0,1\ncol_data[\"SEVERITYCODE\"] = col_data[\"SEVERITYCODE\"].replace(1, 0)\ncol_data[\"SEVERITYCODE\"] = col_data[\"SEVERITYCODE\"].replace(2, 1)","fd698531":"# One hot encoding for the relevant dataset\nfeature = pd.concat([pd.get_dummies(col_data['WEATHER']), \n                     pd.get_dummies(col_data['ROADCOND']),\n                     pd.get_dummies(col_data['LIGHTCOND'])], axis=1)\nfeature.head()","655d88af":"col_data.columns","716c5a5c":"import seaborn as sns\nsns.countplot(x=\"ADDRTYPE\", hue=\"SEVERITYCODE\", data=col_data)","58657bf8":"plt.figure(figsize=(10,5))\nax= sns.countplot(x=\"COLLISIONTYPE\", hue=\"SEVERITYCODE\", data=col_data)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)","3d86de0b":"plt.figure(figsize=(8,5))\nsns.countplot(y=\"JUNCTIONTYPE\", hue=\"SEVERITYCODE\", data=col_data)","9b7c2908":"plt.figure(figsize=(10,5))\nax= sns.countplot(x=\"WEATHER\", hue=\"SEVERITYCODE\", data=col_data)\nax.set_xticklabels(ax.get_xticklabels(), rotation=45)","27cd94d8":"plt.figure(figsize=(8,5))\nsns.countplot(y=\"ROADCOND\", hue=\"SEVERITYCODE\", data=col_data)","d33350f0":"plt.figure(figsize=(8,5))\nsns.countplot(y=\"LIGHTCOND\", hue=\"SEVERITYCODE\", data=col_data)","fed00cc7":"fig, axes = plt.subplots(1, 3, figsize=(12, 4))\nsns.countplot(x=\"SPEEDING\", hue=\"SEVERITYCODE\", data=col_data, ax=axes[0])\nsns.countplot(x=\"UNDERINFL\", hue=\"SEVERITYCODE\", data=col_data, ax=axes[1])\nsns.countplot(x=\"INATTENTIONIND\", hue=\"SEVERITYCODE\", data=col_data, ax=axes[2])","10701a27":"# !conda install -c conda-forge folium=0.5.0 --yes\nimport folium\n\nprint('Folium installed and imported!')","bf179310":"from folium import plugins\nseattle_long= -122.335167\nseattle_lat= 47.608013\nseattle_map = folium.Map(location=[seattle_lat, seattle_long], zoom_start=4)\n# let's start again with a clean copy of the map of Seattle\n\n# instantiate a mark cluster object for the incidents in the dataframe\nincidents = plugins.MarkerCluster().add_to(seattle_map)\n\n# loop through the dataframe and add each data point to the mark cluster\nfor lat, lng, in zip(col_data.Y, col_data.X):\n    folium.Marker(\n        location=[lat, lng],\n        icon=None,\n        #popup=label,\n    ).add_to(incidents)\n\n# display map\nseattle_map","aa21a841":"# Defining X matrix and y vector\nX = feature\ny = col_data['SEVERITYCODE'].values","b0656e48":"# Normalizing and splitting data\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nX = preprocessing.StandardScaler().fit(X).transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)","47fec027":"from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss","90a2a9db":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics","cf0c3ec0":"Ks = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n    std_acc[n-1]=np.std(yhat==y_test)\/np.sqrt(yhat.shape[0])","5a1a1a57":"import matplotlib.pyplot as plt\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+\/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()","bc184ef9":"print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) ","d7daf580":"k = 4\nneigh6 = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nyhat6 = neigh6.predict(X_test)\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh6.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat6))","e2523f45":"# predicted y\nyhat_knn = neigh.predict(X_test)\n\n# jaccard\njaccard_knn = jaccard_similarity_score(y_test, yhat_knn)\nprint(\"KNN Jaccard index: \", jaccard_knn)\n\n# f1_score\nf1_score_knn = f1_score(y_test, yhat_knn, average='weighted')\nprint(\"KNN F1-score: \", f1_score_knn)","ad726b5c":"from sklearn.tree import DecisionTreeClassifier\nseverityTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nseverityTree.fit(X_train, y_train)\n# predicted y\nyhat_dt = severityTree.predict(X_test)\n\n# jaccard\njaccard_dt = jaccard_similarity_score(y_test, yhat_dt)\nprint(\"DT Jaccard index: \", jaccard_dt)\n\n# f1_score\nf1_score_dt = f1_score(y_test, yhat_dt, average='weighted')\nprint(\"DT F1-score: \", f1_score_dt)","c853fb08":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLR = LogisticRegression(C=0.01).fit(X_train,y_train)\nLR","18fa5437":"yhat_lg = LR.predict(X_test)\nyhat_lg_prob = LR.predict_proba(X_test)\n\n# jaccard\njaccard_lg = jaccard_similarity_score(y_test, yhat_lg)\nprint(\"LR Jaccard index: \", jaccard_lg)\n\n# f1_score\nf1_score_lg = f1_score(y_test, yhat_lg, average='weighted')\nprint(\"LR F1-score: \", f1_score_lg)\n\n# logloss\nlogloss_lg = log_loss(y_test, yhat_lg_prob)\nprint(\"LR log loss: \", logloss_lg)","cce32c82":"from sklearn import svm\n# training\nclf = svm.SVC()\nclf.fit(X_train, y_train)","349c315f":"# predicted y\nyhat_svm = clf.predict(X_test)\n\n# jaccard\njaccard_svm = jaccard_similarity_score(y_test, yhat_svm)\nprint(\"SVM Jaccard index: \", jaccard_svm)\n\n# f1_score\nf1_score_svm = f1_score(y_test, yhat_svm, average='weighted')\nprint(\"SVM F1-score: \", f1_score_svm)","6fbbdbf5":"In daylight condition has more accidents than other light conditions.","1e191251":"# Conclusion","dd4d4fae":"The society as a whole \u2014 the accident victims and their families, their employers, insurance firms, emergency and health care personal and many others \u2014 is affected by motor vehicle crashes in many ways. It would be great if real-time conditions can be provided to estimate the trip safeness. In this way, it can be decided beforehand if the driver will take the risk, based on reliable information.","c6ee5734":"## Logistic Regression","ea7c2bbf":"# Capstone Project - Car Severity Accident","c8cd7f3e":"## Introduction\/Business Problem","c52fe69e":"## Support Vector Machine (SVM)","8591f94e":"## Decision Tree","8fb5c71b":"## Choosing relevant variables\n\nFrom the complete dataset, we will choose only the relevant variables which might have an impact in the model training.","fda012ab":"Now our data is cleaned. We have 143.741 observations.","e40a709b":"There are many missing values, especially in 'Speeding' and 'Inattentionid' column. We will fill them as 0. (Boolean columns with 0)","ac11b995":"The most accidents happened in parked cars with property damage.","85dcfe24":"## KNN ","a48402f1":"| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                | 0.6215  | 0.5654   | NA      |\n| Decision Tree      | 0.6638  | 0.5297   | NA      |\n| SVM                | 0.6635  | 0.5296   | NA      |\n| LogisticRegression | 0.6638  | 0.5297   | 0.6377  |","83803667":"# TRAIN\/TEST SPLIT","9f932af6":"This project aims to predict the accident \u201cseverity\u201d. Which factors have more impact on the accidents such as weather, road condition, light condition, speding or any other type of accidents. ","eb440110":"The above plot represents that 'block' areas have more property damage than intersection areas.","265a58a6":"In this project we will explore which areas and conditions in Seattle that cause accidents.\n\nIn first step we have analyzed the data using charts and tables.\n\nSecond step in our analysis will be exploration of 'severity density' across different type of conditions in Seattle - we will use countplot to identify which factors have more impact on the property damage.\n\nIn third and final step we will focus on most property damage conditions and within those create clusters of those conditions and find most accurate model to predict it.","458de1fa":"# Results and Discussion","7137220f":"# Methodology","7054941a":"### Background Discussion","aa2546c5":"## Data\n\nThe data was collected by Seattle SPOT Traffic Management Division and provided by Coursera via a link. This dataset is updated weekly and is from 2004 to present. It contains information such as severity code, address type, location, collision type, weather, road condition, speeding, among others.\n\nThere are 194,673 observations and 38 variables in this data set. Since we would like to identify the factors that cause the accident and the level of severity, we will use SEVERITYCODE as our dependent variable Y, and try different combinations of independent variables X to get the result. Since the observations are quite large, we may need to filter out the missing value and delete the unrelated columns first. Then we can select the factor which may have more impact on the accidents, such as address type, weather, road condition, and light condition.\n","77c4b194":"## Data Cleaning\n\nSome of the categories include 'Other' and 'Unknown' which does not provide enough information. Threfore, we should drop this entries from our dataset.","ec95237d":"### Report","d3b7b1a8":"Purpose of this project was to predict the accident severity in Seattle which conditions have higher impact of those accidents in order to aid stakeholders or government in narrowing down the search for optimal solution for reduce collisions. We used 4 different algorithms to predict severity. We found out that Decision Tree and Logistic Regression have more accuracy score than others.\n\nFinal decision on optimal solution will be made by stakeholders based on specific characteristics of conditions and locations.","6d34c1b9":"## Table of contents\n* [Introduction: Business Problem](#introduction)\n* [Data](#data)\n* [Data Cleaning](#datacleaning)\n* [Methodology](#methodology)\n* [Results and Discussion](#results)\n* [Conclusion](#conclusion)","601088bf":"Suprisingly, the most property damage happened in clear weather. Snowing, rainy and other weather conditions have very low. Moreover, dry road condition has more property damage than other road conditions.","1fc9c2b2":"This project and analysis are quite helpful for the Seattle transportation department. Before I did the analysis, I thought that maybe weather, road, and light condition may cause more accidents, the results showed that it was not correct. However, we do figure out that the accidents are highly related to some specific locations. Thus, the traffic management division could try to improve the safety instructions or some other factors that could reduce the accidents.\n\nFurthermore, there are some places which has more accidents during the dark time. For those places, adding lights might be a good solution to reduce the collisions. ","234aff82":"Now let's explore the data and get the frequency of each category for a given feature."}}