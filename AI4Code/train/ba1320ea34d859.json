{"cell_type":{"b998ff81":"code","b4b4a911":"code","3a1f7352":"code","f7971b55":"code","b602be1e":"code","28e776b3":"markdown"},"source":{"b998ff81":"import numpy as np # linear algebra\nimport os\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","b4b4a911":"def doi_url(d):\n    if '\"' in d:\n        d = str.split(d,'\"')[1]\n    if d.startswith('http:\/\/'):\n        return d\n    if d.startswith('https:\/\/'):\n        return d\n    elif d.startswith('doi.org'):\n        return f'http:\/\/{d}'\n    else:\n        return f'http:\/\/doi.org\/{d}'","3a1f7352":"# read CORD-19 metadata, set up subset dfs for matching \nmetadata_df = pd.read_csv(\"\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv\")\n# clean url - should be a doi\nmetadata_df.url = metadata_df.url.fillna('').apply(doi_url)\n\nmetadata_doi_df = metadata_df[metadata_df.columns.intersection(['cord_uid', 'doi'])]\nmetadata_doi_df = metadata_doi_df.rename(columns = {'cord_uid':'doi_cord_uid', 'doi':'doi_metadata'})\nmetadata_doi_df['doi_metadata'] = \"https:\/\/doi.org\/\" + str(metadata_doi_df['doi_metadata'])\n# print(metadata_doi_df)\nmetadata_title_df = metadata_df[metadata_df.columns.intersection(['cord_uid', 'title'])]\nmetadata_title_df = metadata_title_df.rename(columns = {'cord_uid':'title_cord_uid', 'title':'title_metadata'})\nmetadata_url_df = metadata_df[metadata_df.columns.intersection(['cord_uid', 'url'])]\n# explode delimited url values onto separate rows\nmetadata_url_df.assign(url=metadata_url_df['url'].astype(str).str.split(';')).explode('url')\nmetadata_url_df = metadata_url_df.rename(columns = {'cord_uid':'url_cord_uid', 'url':'url_metadata'})\n\nmetadata_df = None","f7971b55":"# Loop over input data files, deriving metadata\n\nall_papers_df = None\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        if (( \"\/target_tables\/\" in dirname or \"\/cord-19-task-csv-exports\/\" in dirname \n            or \"\/coronawhy-task-ties-patient-descriptions\" in dirname\n            or \"\/covid-19-temperature-and-humidity-summary-tables\" in dirname)\n            and filename.endswith(\".csv\")):\n            this_file_df = pd.read_csv(os.path.join(dirname, filename))\n            \n            # conform filename\n            if filename == \"temperature_or_humidity.csv\":\n                filename = \"How does temperature and humidity affect the transmission of 2019-nCoV_.csv\"\n\n        # add metadata columns\n            ML_Notebook = str(str.split(dirname,\"\/input\/\")[1])\n            ML_Notebook = str(str.split(ML_Notebook,\"\/\")[0])\n            this_file_df[\"ML Notebook\"] = ML_Notebook\n\n            if \"CORD-19-research-challenge\" in ML_Notebook:\n                ML_Author = \"Kaggle Community\"\n                ML_Notebook_URL = \"https:\/\/kaggle.com\/allen-institute-for-ai\/\" + ML_Notebook\n                if \"\/0_\" in dirname or \"\/unsorted\" in dirname:\n                    break\n                else:\n                    None\n            elif \"cord-19-task-csv-exports\" in ML_Notebook:\n                ML_Author = \"David Mezzetti\"\n                ML_Notebook_URL = \"https:\/\/kaggle.com\/davidmezzetti\/\" + ML_Notebook\n            elif \"coronawhy-task-ties-patient-descriptions\" in ML_Notebook: \n                ML_Author = \"CoronaWhy Team Task-TIES\"\n                ML_Notebook_URL = \"https:\/\/kaggle.com\/crispyc\/\" + ML_Notebook\n            elif \"covid-19-temperature-and-humidity-summary-tables\" in ML_Notebook: \n                ML_Author = \"Javier Sastre et.al\"\n                ML_Notebook_URL = \"https:\/\/kaggle.com\/javiersastre\/\" + ML_Notebook\n            else:\n                ML_Author = ML_Notebook\n                ML_Notebook_URL = \"\"\n\n            this_file_df[\"ML Author\"] = ML_Author\n            this_file_df[\"ML Notebook URL\"] = ML_Notebook_URL\n                \n            this_file_df[\"File Name\"] = filename\n            print(ML_Author + \" - \" + filename)\n\n    # conform column types and names\n            this_file_df.rename(columns={'Study Type ': 'Study Type'}, inplace=True)\n            this_file_df.rename(columns={'Study type': 'Study Type'}, inplace=True)\n            this_file_df.rename(columns={'Study':'Title'}, inplace=True)\n            this_file_df.rename(columns={'Link':'URL'}, inplace=True)\n            this_file_df.rename(columns={'Study Link':'URL'}, inplace=True)\n            this_file_df.rename(columns={'Study link':'URL'}, inplace=True)\n\n            # clean url - should be a doi\n            this_file_df.URL = this_file_df.URL.fillna('').apply(doi_url)\n\n            this_file_df.rename(columns={'Discharge vs. death?': 'Discharged vs. death?'}, inplace=True)\n            allcolumns = list(this_file_df)\n            this_file_df[allcolumns] = this_file_df[allcolumns].fillna('')\n            this_file_df[allcolumns] = this_file_df[allcolumns].astype(str)\n\n            # engineer new attributes\n            this_file_df_copy = this_file_df.copy()\n            for idx in this_file_df_copy.index:\n                \n                # clean URL\n                try:\n                    if not \"http\" in this_file_df_copy.at[idx,'URL']:\n                        this_file_df.at[idx,'URL'] = \"https:\/\/\" + this_file_df_copy.at[idx,'URL']\n                except:\n                    None\n                \n                # append Journal to Title\n                Title = \"\"\n                try:\n                    Title = this_file_df_copy.at[idx,'Title']\n                    Title = Title + \" (\" + this_file_df_copy.at[idx,'Journal'] + \")\"\n                except:\n                    None\n                this_file_df.at[idx,'Title'] = Title\n                \n                # clean Sample Size\n                Sample_Size = \"\"\n                try:\n                    Sample_Size = str.replace(str(this_file_df_copy.at[idx,'Sample Size']), \"n=\", \"\")\n                    this_file_df.at[idx,'Sample Size'] = Sample_Size\n                except:\n                    this_file_df.at[idx,'Sample Size'] = Sample_Size\n\n                # engineer Sample - patients\n                Sample_subjects = \"\"\n                try:\n                    Sample_subjects = str.strip(str(this_file_df_copy.at[idx,'Sample Size']))\n    #                 print(\"in: \" + Sample_subjects)\n                    Sample_subjects = str.replace(Sample_subjects, \" subjects\", \" patients\")\n                    Sample_subjects = str.split(Sample_subjects, \" subjects\")[0]\n                    Sample_subjects = str(str.split(Sample_subjects,\" \")[-2])\n    #                 print(\"out: \" + Sample_subjects)\n                    this_file_df.at[idx,'Sample Subjects'] = Sample_subjects\n                except:\n    #                 print(\"except: \" + Sample_subjects)\n                    this_file_df.at[idx,'Sample Subjects'] = Sample_subjects\n\n                Severe_Raw =\"\"\n                try:\n                    Severe_Raw = str(this_file_df_copy.at[idx,'Severe'])\n                    Severe_Raw = str.replace(Severe_Raw, '\\s+', ' ',regex=True )\n                except:\n                    None\n\n                # engineer Severe Metric, e.g. OR, RR\n                Severe_Metric = \"\"\n                try:\n                    Severe_Metric = str.strip(Severe_Raw)\n                    Severe_Metric = str.strip(str.replace(str.split(Severe_Metric,\" \")[0],\":\",\"\"))\n                    Severe_Metric = str.strip(str.split(Severe_Metric,\"=\")[0])\n                    this_file_df.at[idx,'Severe Metric'] = Severe_Metric\n                except:\n                    None\n\n                # engineer Severe Value, e.g. 1.07 or whatever the ratio is.\n                Severe_Value = \"\"\n                try:\n                    Severe_Value = str.strip(str.replace(str.replace(str.replace(Severe_Raw, \":\", \" \"), \"=\", \" \"),\"  \", \" \"))\n                    Severe_Value = str.split(Severe_Value,\" \")[1]\n                    this_file_df.at[idx,'Severe Value'] = Severe_Value\n                except:\n                    None\n\n                # engineer Severe Method\n                Severe_Method = \"\"\n                try:\n                    Severe_Method = str.strip(Severe_Raw)\n                    Severe_Method = str.strip(str.replace(str.replace(Severe_Method, Severe_Value ,\"\"), \":\", \"\"))\n                    Severe_Method = str.split(Severe_Method, \" \")[0]           \n                    this_file_df.at[idx,'Severe Method'] = Severe_Method\n                except:\n                    None\n\n                # engineer Severe Label\n                Critical_Only_Footnote = \"\"\n                try:\n                    Critical_Only = str.lower(this_file_df_copy.at[idx,'Critical only'])\n                    if Critical_Only == \"y\":\n                        Critical_Only_Footnote = \"\u2021 \"\n                except:\n                    None\n                    \n                Discharged_vs_Death = \"\"\n                Discharged_vs_Death_Footnote = \"\"\n                try:\n                    Discharged_vs_Death = str.lower(this_file_df_copy.at[idx,'Discharged vs. death?'])\n                except:\n                    None\n                if Discharged_vs_Death == \"y\":\n                    Discharged_vs_Death_Footnote = \"\u2e38 \"\n                \n                Severe_Label = \"\"\n                this_file_df.at[idx,'Severe Label'] = Severe_Label\n                \n                try:\n                    if Severe_Raw != \"\":\n                        Severe_Label = Severe_Raw\n                        Severe_Label = Critical_Only_Footnote + Discharged_vs_Death_Footnote + Severe_Label\n                        if \"not adjusted\" in str.lower(this_file_df_copy.at[idx,'Severe Adjusted']):\n                            Severe_Label = \"\u00a7 \" + Severe_Label\n                        if \"calculated\" in str.lower(this_file_df_copy.at[idx,'Severe Calculated']):\n                            Severe_Label = \"\u2020 \" + Severe_Label\n                        if this_file_df_copy.at[idx,'Severe lower bound'] != None:\n                            Severe_Label = Severe_Label + \" (95% CI: \" + str(this_file_df_copy.at[idx,'Severe lower bound'])\n#                         print(\"debug 1: \" + Severe_Label) if this_file_df_copy.at[idx,'URL'] == \"https:\/\/doi.org\/10.1101\/2020.04.24.20078006\" else None\n                        if this_file_df_copy.at[idx,'Severe upper bound'] != None:\n                            Severe_Label = Severe_Label + \"-\" + str(this_file_df_copy.at[idx,'Severe upper bound']) + \")\"\n                        if str(this_file_df_copy.at[idx,'Severe p-value']) > \"\":\n                            if str.isdigit(str(this_file_df_copy.at[idx,'Severe p-value'])[:1]):\n                                Severe_Label = Severe_Label + \" p=\" + str(this_file_df_copy.at[idx,'Severe p-value'])\n                            else:\n                                Severe_Label = Severe_Label + \" p\" + this_file_df_copy.at[idx,'Severe p-value']\n                            Severe_Label = Severe_Label + \")\" \n\n                        Severe_Label = ( Severe_Label + \", \" + this_file_df_copy.at[idx,'Severe Significant'] + \", \" + \n                            this_file_df_copy.at[idx,'Severe Adjusted'] + \", \" + \n                            this_file_df_copy.at[idx,'Severe Calculated'] )\n#                         print(\"debug 2: \" + Severe_Label) if this_file_df_copy.at[idx,'URL'] == \"https:\/\/doi.org\/10.1101\/2020.04.24.20078006\" else None\n                        this_file_df.at[idx,'Severe Label'] = Severe_Label\n        #                 print (Severe_Label)\n                    else:\n                        None\n                except:\n                    this_file_df.at[idx,'Severe Label'] = Severe_Label\n                \n                Severe_Label_Background_Color = \"\"\n                try:\n                    if this_file_df_copy.at[idx,'Severe Significant'] == \"\":\n                        Severe_Label_Background_Color = \"\"\n                    elif \"not significant\" in str.lower(this_file_df_copy.at[idx,'Severe Significant']):\n                        Severe_Label_Background_Color = \"#F4C7C3\"\n                    else:\n                        Severe_Label_Background_Color = \"#B7E1CD\"\n                except:\n                    None\n                this_file_df.at[idx,'Severe Label Background Color'] = Severe_Label_Background_Color\n#                 print(\"debug 1: \" + Severe_Label_Background_Color) if this_file_df_copy.at[idx,'URL'] == \"https:\/\/doi.org\/10.1101\/2020.04.24.20078006\" else None\n                \n                Fatality_Raw =\"\"\n                try:\n                    Fatality_Raw = str(this_file_df_copy.at[idx,'Fatality'])\n                    Fatality_Raw = str.replace(Fatality_Raw, '\\s+', ' ',regex=True )\n                except:\n                    None\n\n                # engineer Fatality Metric\n                Fatality_Metric = \"\"\n                try:\n                    Fatality_Metric = str.strip(Fatality_Raw)\n                    Fatality_Metric = str.strip(str.replace(str.split(Fatality_Metric,\" \")[0],\":\",\"\"))\n                    Fatality_Metric = str.strip(str.split(Fatality_Metric, \"=\")[0])\n                    this_file_df.at[idx,'Fatality Metric'] = Fatality_Metric\n                except:\n                    None\n\n                # engineer Fatality Value\n                Fatality_Value = Fatality_Raw\n                try:\n                    Fatality_Value = str.strip(str.replace(str.replace(str.replace(Fatality_Value, \":\", \" \"), \"=\", \" \"),\"  \", \" \"))\n                    Fatality_Value = str.split(str.strip(Fatality_Value),\" \")[1]\n                    this_file_df.at[idx,'Fatality Value'] = Fatality_Value\n                except:\n                    None\n\n                # engineer Fatality Method\n                Fatality_Method = \"\"\n                try:\n                    Fatality_Method = str.strip(Fatality_Raw)\n                    Fatality_Method = str.strip(str.replace(str.replace(Fatality_Method, Fatality_Value ,\"\"), \":\", \"\"))\n                    Fatality_Method = str.split(Fatality_Method, \" \")[0]           \n                    this_file_df.at[idx,'Fatality Method'] = Fatality_Method\n                except:\n                    this_file_df.at[idx,'Fatality Method'] = Fatality_Method\n\n                # engineer Fatality Label\n                Fatality_Label = \"\"\n                this_file_df.at[idx,'Fatality Label'] = Fatality_Label\n                try:\n                    if Fatality_Raw != \"\":\n                        Fatality_Label = Fatality_Raw \n                        Fatality_Label = Critical_Only_Footnote + Discharged_vs_Death_Footnote + Fatality_Label\n                        if \"not adjusted\" in str.lower(this_file_df_copy.at[idx,'Fatality Adjusted']):\n                            Fatality_Label = \"\u00a7 \" + Fatality_Label\n                        if \"calculated\" in str.lower(this_file_df_copy.at[idx,'Fatality Calculated']):\n                            Fatality_Label = \"\u2020 \" + Fatality_Label\n                        if this_file_df_copy.at[idx,'Fatality lower bound'] != None:\n                            Fatality_Label = Fatality_Label + \" (95% CI: \" + str(this_file_df_copy.at[idx,'Fatality lower bound'])\n                        if this_file_df_copy.at[idx,'Fatality upper bound'] != None:\n                            Fatality_Label = Fatality_Label + \"-\" + str(this_file_df_copy.at[idx,'Fatality upper bound']) + \")\"\n                        if str(this_file_df_copy.at[idx,'Fatality p-value']) > \"\":\n                            if str.isdigit(str(this_file_df_copy.at[idx,'Fatality p-value'])[:1]):\n                                Fatality_Label = Fatality_Label + \" p=\" + str(this_file_df_copy.at[idx,'Fatality p-value'])\n                            else:\n                                Fatality_Label = Fatality_Label + \" p\" + this_file_df_copy.at[idx,'Fatality p-value']\n                            Fatality_Label = Fatality_Label + \")\" \n\n                        if str(this_file_df_copy.at[idx,'Fatality Significant']) > \"\":\n                            Fatality_Label = Fatality_Label + \", \" + this_file_df_copy.at[idx,'Fatality Significant']  \n                        if str(this_file_df_copy.at[idx,'Fatality Adjusted']) > \"\":\n                            Fatality_Label = Fatality_Label + \", \" + this_file_df_copy.at[idx,'Fatality Adjusted']  \n                        if str(this_file_df_copy.at[idx,'Fatality Calculated']) > \"\":\n                            Fatality_Label = Fatality_Label + \", \" + this_file_df_copy.at[idx,'Fatality Calculated']  \n\n        #                 print (Fatality_Label)\n                        this_file_df.at[idx,'Fatality Label'] = Fatality_Label\n                    else:\n                        None\n                except:\n                    this_file_df.at[idx,'Fatality Label'] = Fatality_Label\n\n                Fatality_Label_Background_Color = \"\"\n                try:\n                    if this_file_df_copy.at[idx,'Fatality Significant'] == \"\":\n                        Fatality_Label_Background_Color = \"\"\n                    elif \"not significant\" in str.lower(this_file_df_copy.at[idx,'Fatality Significant']):\n                        Fatality_Label_Background_Color = \"#F4C7C3\"\n                    else:\n                        Fatality_Label_Background_Color = \"#B7E1CD\"\n                except:\n                    None\n                this_file_df.at[idx,'Fatality Label Background Color'] = Fatality_Label_Background_Color\n\n\n    #       append this file to the collection df\n            all_papers_df = pd.concat([this_file_df, all_papers_df], ignore_index=True, sort=False)\n","b602be1e":"\nall_papers_merge_df = all_papers_df[all_papers_df.columns.intersection(['Title','URL'])]\n\n# doi Merge - Cartesian product by introducing key(self join)\ncombined_df = all_papers_merge_df.merge(metadata_doi_df, how=\"left\", left_on=['URL'], right_on=['doi_metadata'])\ncombined_df = combined_df.merge(metadata_url_df, how=\"left\", left_on=['URL'], right_on=['url_metadata'])\ncombined_df = combined_df.merge(metadata_title_df, how=\"left\", left_on=['Title'], right_on=['title_metadata'])\ncombined_df = combined_df[combined_df.columns.intersection(['doi_cord_uid', 'doi_metadata', 'url_cord_uid', 'url_metadata', 'title_cord_uid', 'title_metadata'])]\n# print(combined_df)\n\nall_papers_df = all_papers_df.merge(combined_df, left_index=True, right_index=True)\n# print(all_papers_df)\n\n# write out the all_papers df\nall_papers_df['all papers index'] = all_papers_df.index\nall_papers_df.to_csv('all_papers.csv', index = False)\nprint(\"Wrote the all_papers.csv file with: \" + str(len(all_papers_df.index)) + \" rows of table data.\")            \n\n# create value-pair version of file. Preserve common columns and pivot every other column into Attribute and Value\nall_papers_df['Study Type - Copy'] = all_papers_df['Study Type']\nall_papers_value_pairs_df = (all_papers_df.set_index(['all papers index', \"ML Author\", \"ML Notebook\", \"ML Notebook URL\", \"File Name\", \"Date\", \"Title\", \"URL\", \"Journal\", \"Study Type - Copy\"])\n                             .stack().reset_index())\nall_papers_value_pairs_df.rename(columns={'level_10': 'Attribute'}, inplace=True)\nall_papers_value_pairs_df = all_papers_value_pairs_df.query('Attribute != \"Unnamed: 0\"')\nall_papers_value_pairs_df.rename(columns={'Study Type - Copy':'Study Type'}, inplace=True)\n# print(all_papers_value_pairs_df)\nall_papers_value_pairs_df.to_csv('all_papers_value_pairs.csv', index = False)\n\nprint(\"Wrote the all_papers_value_pairs.csv file with: \" + str(len(all_papers_value_pairs_df.index)) + \" rows of value-pair data.\")            \nprint(\"Finished!\")\n","28e776b3":"# AI-Powered Literature Review - with submissions\nWhat's new:\n* 2020-12-03 - this notebook is now being refreshed automatically, using [David Mezzetti's](https:\/\/www.kaggle.com\/davidmezzetti) [Kernelpipes project](https:\/\/github.com\/neuml\/kernelpipes).\n* Added output from [COVID-19 Temperature and Humidity Summary Tables](https:\/\/www.kaggle.com\/javiersastre\/covid-19-temperature-and-humidity-summary-tables\/) notebook\n* Added [CoronaWhy-Task-TIES Patient Descriptions notebook submissions](https:\/\/www.kaggle.com\/crispyc\/coronawhy-task-ties-patient-descriptions). Removed column Literature Category - now relies on connection to CORD-19 list_of_tables_and_table_formats.csv using File Name.\n* This notebook is now being re-run automatically (using [David Mezzetti's kernelpipes project](https:\/\/github.com\/neuml\/kernelpipes)).\n* Re-added [David Mezzetti's notebook submissions](https:\/\/www.kaggle.com\/davidmezzetti\/cord-19-task-csv-exports).\n\nThis notebook is an effort to collate the data from Kaggle's AI-Powered Literature Review dataset in consolidated, conformed files.  The relevant Kaggle files are in the Kaggle folder of the [CORD-19 Open Research Challenge](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge). The primary purpose is to feed data visualisation efforts e.g. [Hyperion](https:\/\/www.kaggle.com\/mikehoney\/hyperion\/notebook), but other uses are welcomed and encouraged.\n\nI have started integrating the submissions to that review by other Kaggle authors. IMO aggregation of the reviewed and approved data from Kaggle's dataset together with the fresh submissions can be a useful tool for analysis of progress in this effort. "}}