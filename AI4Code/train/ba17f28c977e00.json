{"cell_type":{"e6ebb2e6":"code","be4abfa4":"code","63b62c73":"code","c3a88a82":"code","8373d5c3":"code","cabc0a6d":"code","c1d0e72c":"code","7de18d2e":"code","78912f0b":"code","a2d766f5":"code","8b3e839e":"code","f27e062d":"code","99403980":"code","442c3848":"code","15e42378":"code","87b0a1e5":"code","cfc37491":"code","0671f742":"code","3fca669a":"code","13576a52":"code","5ab74041":"code","c88ba0f3":"code","f831274d":"code","83f42ba0":"code","03a73b3d":"code","b2aae2cf":"code","4593efd2":"code","ffbeefe6":"code","693a62be":"code","ffe1d8cc":"code","c82804c9":"code","4114bfdc":"code","4c8429e2":"code","cd28bb93":"code","b44cdd01":"code","18730770":"code","70c90b0a":"code","2a1f2125":"code","a1610ecc":"code","2640a364":"code","d801d9d4":"code","0d85ea19":"code","906ad189":"code","ba46dc96":"code","6ff964bd":"code","fb7c0d5c":"markdown","485852ad":"markdown","19ae9f1d":"markdown","f1a3e93d":"markdown","185dfb20":"markdown"},"source":{"e6ebb2e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be4abfa4":"!pip install talib-binary","63b62c73":"import talib","c3a88a82":"from datetime import datetime\nimport time\ntotimestamp = lambda s: np.int32(time.mktime(datetime.strptime(s, \"%d\/%m\/%Y\").timetuple()))","8373d5c3":"data_folder = \"..\/input\/g-research-crypto-forecasting\/\"\ncrypto_df = pd.read_csv(data_folder + 'train.csv')\nasset_details_df = pd.read_csv(data_folder + 'asset_details.csv')\nsupp_train_df = pd.read_csv(data_folder + 'supplemental_train.csv')\nexpl_test = pd.read_csv(data_folder + 'example_test.csv')","cabc0a6d":"asset_details_df[\"Asset_Name\"] = asset_details_df[\"Asset_Name\"].str.replace(' ','_')\nasset_details_df[\"Asset_Name\"] = asset_details_df[\"Asset_Name\"].str.replace('.','_')","c1d0e72c":"asset_details = asset_details_df.copy()\nasset_details_df = asset_details_df.set_index(\"Asset_ID\")","7de18d2e":"crypto_df","78912f0b":"#Create a dictionary of data frames assigned to each coin \ndataframes = {}\nfor asset_id, asset_name in zip(asset_details.Asset_ID, asset_details.Asset_Name):    \n    vars()[asset_name] = crypto_df[crypto_df[\"Asset_ID\"]==asset_id].set_index(\"timestamp\")#.merge(asset_details, how='left', on='Asset_ID')\n    dataframes[asset_id] = vars()[asset_name]\n\n\ncleaned_dataframes = {}\nfor i in list(dataframes):\n    #cols = ['Asset_ID','Asset_Name','Count','Volume','Open','High','Low', 'Close','VWAP','Target']\n    cleaned_dataframes[i] = dataframes[i].reindex(range(dataframes[i].index[0],dataframes[i].index[-1]+60,60),method='pad')\n    #cleaned_dataframes[i] = cleaned_dataframes[i][cols]\n    ","a2d766f5":"#Reduce the datastes to ease the correlation calculation\nreduced_dataframes = {}\nfor i in list(dataframes):\n    #reduced_dataframes[i] = cleaned_dataframes[i].loc[totimestamp('01\/01\/2021'):totimestamp('01\/05\/2021')]\n    reduced_dataframes[i] = cleaned_dataframes[i].iloc[-10000:]","8b3e839e":"reduced_dataframes_base = reduced_dataframes\nreduced_dataframes_base[1]","f27e062d":"original_columns = cleaned_dataframes[2].columns.tolist()","99403980":"momentum_indicators_columns = ['adx_mm','adxr_mm','aroondown_mm','aroonup_mm','bop_mm','mfi_mm','cci_mm','cmo_mm','rsi_mm','mdi_mm','pdi_mm','mdm_mm','pdm_mm','dx_mm','roc_mm','rocp_mm','will_mm']\ndef get_momentum_indicators(df) :\n    \n    df[\"adx_mm\"] = talib.ADX(df['High'], df['Low'], df['Close'], timeperiod=14) #Average Directional Movement Index\n    df[\"adxr_mm\"] = talib.ADXR(df['High'], df['Low'], df['Close'], timeperiod=14) #Average Directional Movement Index Rating\n    df[\"aroondown_mm\"], df[\"aroonup_mm\"] = talib.AROON(df['High'], df['Low'],timeperiod=14) \n    df[\"bop_mm\"] = talib.BOP(df['Open'], df['High'], df['Low'], df['Close']) #Balance Of Power\n    df[\"mfi_mm\"] = talib.MFI(df['High'], df['Low'], df['Close'], df['Volume'], timeperiod=14) #Money Flow Index\n    df[\"cci_mm\"] = talib.CCI(df['High'], df['Low'], df['Close'], timeperiod=14) #Commodity Channel Index\n    df[\"cmo_mm\"] = talib.CMO(df['Close'], timeperiod=14) #Chande Momentum Oscillator\n    df[\"rsi_mm\"] = talib.RSI(df['Close'], timeperiod=14) #Relative Strenght Index\n    df[\"mdi_mm\"] = talib.MINUS_DI(df['High'], df['Low'], df['Close'], timeperiod=14) #Minus Directional Indicator\n    df[\"pdi_mm\"] = talib.PLUS_DI(df['High'], df['Low'], df['Close'], timeperiod=14)  #Plus Directional Indicator\n    df[\"mdm_mm\"] = talib.MINUS_DM(df['High'], df['Low'],timeperiod=14)  #Minus Directional Movement\n    df[\"pdm_mm\"] = talib.PLUS_DM(df['High'], df['Low'],timeperiod=14)  #Plus Directional Movement\n    df[\"dx_mm\"] = talib.DX(df['High'], df['Low'], df['Close'], timeperiod=14) #Directional Movement Index\n    df[\"roc_mm\"] = talib.ROC(df['Close'], timeperiod=10) #Rate of change\n    df[\"rocp_mm\"] = talib.ROCP(df['Close'], timeperiod=10) #Rate of change Percentage\n    df[\"will_mm\"] = talib.WILLR(df['High'], df['Low'], df['Close'], timeperiod=14)  #Williams' %R\n    ","442c3848":"volatility_indicators_columns = ['atr_vlt','natr_vlt','trange_vlt']\ndef get_volatility_indicators(df) :\n    \n    df['atr_vlt'] = talib.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n    df['natr_vlt'] = talib.NATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n    df['trange_vlt'] = talib.TRANGE(df['High'], df['Low'], df['Close'])","15e42378":"volume_indicators_columns = ['ad_vol','adosc_vol','obv_vol']\ndef get_volume_indicators(df) :\n    \n    df['ad_vol'] = talib.AD(df['High'], df['Low'], df['Close'], df['Volume'])\n    df['adosc_vol'] = talib.ADOSC(df['High'], df['Low'], df['Close'], df['Volume'], fastperiod=5, slowperiod=20)\n    df['obv_vol'] = talib.OBV(df['Close'], df['Volume'])","87b0a1e5":"cycle_indicators_columns = ['htdcpe_cyc','htdcpa_cyc','htsn_cyc','htinph_cyc','httrnd_cyc']\ndef get_cycle_indicators(df) :\n    \n    df['htdcpe_cyc'] = talib.HT_DCPERIOD(df['Close'])\n    df['htdcpa_cyc'] = talib.HT_DCPHASE(df['Close'])\n    df['htsn_cyc'], df['htldsn_cyc'] = talib.HT_SINE(df['Close'])\n    df['htinph_cyc'], df['htquad_cyc'] = talib.HT_PHASOR(df['Close'])\n    df['httrnd_cyc'] = talib.HT_TRENDLINE(df['Close'])","cfc37491":"statitics_functions_columns = ['beta_stat','correl_stat','stddev_stat','tsf_stat','var_stat']\ndef get_statitics_functions(df) :\n    \n    df['beta_stat'] = talib.BETA(df['High'], df['Low'], timeperiod=5)\n    df['correl_stat'] = talib.CORREL(df['High'], df['Low'], timeperiod=30)\n    df['stddev_stat'] = talib.STDDEV(df['Close'], timeperiod=5, nbdev=1)\n    df['tsf_stat'] = talib.TSF(df['Close'], timeperiod=14)\n    df['var_stat'] = talib.VAR(df['Close'], timeperiod=5, nbdev=1)","0671f742":"overlap_functions_columns = ['bbup_ovlp','kama_ovlp','sar_ovlp']\ndef get_overlap_functions(df) :\n    \n    df['bbup_ovlp'], df['bbmidl_ovlp'], df['bblow_ovlp'] = talib.BBANDS(df['Close'], timeperiod=10, nbdevup=2, nbdevdn=2, matype=0)\n    df['kama_ovlp']= talib.KAMA(df['Close'], timeperiod=30)\n    #df['mama_ovlp'], df['fama'] = talib.MAMA(df['Close'], fastlimit=0, slowlimit=0)\n    df['sar_ovlp']= talib.SAR(df['High'], df['Low'], acceleration=0, maximum=0)\n    ","3fca669a":"price_transformations = ['avg_price','med_price','typ_price','weight_price']\ndef get_price_transformations(df) :\n    \n    df['avg_price'] = talib.AVGPRICE(df['Open'], df['High'], df['Low'], df['Close'])\n    df['med_price'] = talib.MEDPRICE(df['High'], df['Low'])\n    df['typ_price'] = talib.TYPPRICE(df['High'], df['Low'], df['Close'])\n    df['weight_price'] = talib.WCLPRICE(df['High'], df['Low'], df['Close'])","13576a52":"pattern_recognition_columns = ['cdl2crows',\n       'cdl3blackcrows', 'cdl3inside', 'cdl3linestrike', 'cdl3outside',\n       'cdl3starsinsouth', 'cdl3whitesoldiers', 'cdlabandonedbaby',\n       'cdladvanceblock', 'cdlbelthold', 'cdlbreakaway', 'cdlclosingmarubozu',\n       'cdlconcealbabyswall', 'cdlcounterattack', 'cdldarkcloudcover',\n       'cdldoji', 'cdldojistar', 'cdldragonflydoji', 'cdlengulfing',\n       'cdleveningdojistar', 'cdleveningstar', 'cdlgapsidesidewhite',\n       'cdlgravestonedoji', 'cdlhammer', 'cdlhangingman', 'cdlharami',\n       'cdlharamicross', 'cdlhighwave', 'cdlhikkake', 'cdlhikkakemod',\n       'cdlhomingpigeon', 'cdlidentical3crows', 'cdlinneck',\n       'cdlinvertedhammer', 'cdlkicking', 'cdlkickingbylength',\n       'cdlladderbottom', 'cdllongleggeddoji', 'cdllongline', 'cdlmarubozu',\n       'cdlmatchinglow', 'cdlmathold', 'cdlmorningdojistar', 'cdlmorningstar',\n       'cdlonneck', 'cdlpiercing', 'cdlrickshawman', 'cdlrisefall3methods',\n       'cdlseparatinglines', 'cdlshootingstar', 'cdlshortline',\n       'cdlspinningtop', 'cdlstalledpattern', 'cdlsticksandwich', 'cdltakuri',\n       'cdltasukigap', 'cdlthrusting', 'cdltristar', 'cdlunique3river',\n       'cdlupsidegap2crows', 'cdlxsidegap3methods']\n\ndef get_pattern_recognition(df) :\n    \n    df['cdl2crows'] = talib.CDL2CROWS(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdl3blackcrows'] = talib.CDL3BLACKCROWS(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdl3blackcrows'] = talib.CDL3BLACKCROWS(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdl3inside'] = talib.CDL3INSIDE(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdl3linestrike'] = talib.CDL3LINESTRIKE(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdl3outside'] = talib.CDL3OUTSIDE(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdl3starsinsouth'] = talib.CDL3STARSINSOUTH(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdl3whitesoldiers'] = talib.CDL3WHITESOLDIERS(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlabandonedbaby'] = talib.CDLABANDONEDBABY(df['Open'], df['High'], df['Low'], df['Close'], penetration=0)\n    df['cdladvanceblock'] = talib.CDLADVANCEBLOCK(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlbelthold'] = talib.CDLBELTHOLD(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlbreakaway'] = talib.CDLBREAKAWAY(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlclosingmarubozu'] = talib.CDLCLOSINGMARUBOZU(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlconcealbabyswall'] = talib.CDLCONCEALBABYSWALL(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlcounterattack'] = talib.CDLCOUNTERATTACK(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdldarkcloudcover'] = talib.CDLDARKCLOUDCOVER(df['Open'], df['High'], df['Low'], df['Close'], penetration=0)\n    df['cdldoji'] = talib.CDLDOJI(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdldojistar'] = talib.CDLDOJISTAR(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdldragonflydoji'] = talib.CDLDRAGONFLYDOJI(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlengulfing'] = talib.CDLENGULFING(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdleveningdojistar'] = talib.CDLEVENINGDOJISTAR(df['Open'], df['High'], df['Low'], df['Close'], penetration=0)\n    df['cdleveningstar'] = talib.CDLEVENINGSTAR(df['Open'], df['High'], df['Low'], df['Close'], penetration=0)\n    df['cdlgapsidesidewhite'] = talib.CDLGAPSIDESIDEWHITE(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlgravestonedoji'] = talib.CDLGRAVESTONEDOJI(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlhammer'] = talib.CDLHAMMER(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlhangingman'] = talib.CDLHANGINGMAN(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlharami'] = talib.CDLHARAMI(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlharamicross'] = talib.CDLHARAMICROSS(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlhighwave'] = talib.CDLHIGHWAVE(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlhikkake'] = talib.CDLHIKKAKE(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlhikkakemod'] = talib.CDLHIKKAKEMOD(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlhomingpigeon'] = talib.CDLHOMINGPIGEON(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlidentical3crows'] = talib.CDLIDENTICAL3CROWS(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlinneck'] = talib.CDLINNECK(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlinvertedhammer'] = talib.CDLINVERTEDHAMMER(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlkicking'] = talib.CDLKICKING(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlkickingbylength'] = talib.CDLKICKINGBYLENGTH(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlladderbottom'] = talib.CDLLADDERBOTTOM(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdllongleggeddoji'] = talib.CDLLONGLEGGEDDOJI(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdllongline'] = talib.CDLLONGLINE(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlmarubozu'] = talib.CDLMARUBOZU(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlmatchinglow'] = talib.CDLMATCHINGLOW(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlmathold'] = talib.CDLMATHOLD(df['Open'], df['High'], df['Low'], df['Close'], penetration=0)\n    df['cdlmorningdojistar'] = talib.CDLMORNINGDOJISTAR(df['Open'], df['High'], df['Low'], df['Close'], penetration=0)\n    df['cdlmorningstar'] = talib.CDLMORNINGSTAR(df['Open'], df['High'], df['Low'], df['Close'], penetration=0)\n    df['cdlonneck'] = talib.CDLONNECK(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlpiercing'] = talib.CDLPIERCING(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlrickshawman'] = talib.CDLRICKSHAWMAN(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlrisefall3methods'] = talib.CDLRISEFALL3METHODS(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlseparatinglines'] = talib.CDLSEPARATINGLINES(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlshootingstar'] = talib.CDLSHOOTINGSTAR(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlshortline'] = talib.CDLSHORTLINE(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlspinningtop'] = talib.CDLSPINNINGTOP(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlstalledpattern'] = talib.CDLSTALLEDPATTERN(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlsticksandwich'] = talib.CDLSTICKSANDWICH(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdltakuri'] = talib.CDLTAKURI(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdltasukigap'] = talib.CDLTASUKIGAP(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlthrusting'] = talib.CDLTHRUSTING(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdltristar'] = talib.CDLTRISTAR(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlunique3river'] = talib.CDLUNIQUE3RIVER(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlupsidegap2crows'] = talib.CDLUPSIDEGAP2CROWS(df['Open'], df['High'], df['Low'], df['Close'])\n    df['cdlxsidegap3methods'] = talib.CDLXSIDEGAP3METHODS(df['Open'], df['High'], df['Low'], df['Close'])","5ab74041":"for i in list(reduced_dataframes) :\n    get_momentum_indicators(reduced_dataframes[i])\n    get_volatility_indicators(reduced_dataframes[i])\n    get_volume_indicators(reduced_dataframes[i])\n    get_cycle_indicators(reduced_dataframes[i])\n    get_statitics_functions(reduced_dataframes[i])\n    get_overlap_functions(reduced_dataframes[i])\n    get_price_transformations(reduced_dataframes[i])\n    get_pattern_recognition(reduced_dataframes[i])","c88ba0f3":"reduced_dataframes_full = reduced_dataframes\nreduced_dataframes_full[1].info()","f831274d":"# Here we will remove the irrelevant features that does not have any predicting power\n# if a features is non-variant we will remove it\n# then we will use only pttrn_cols_keep\n\npttrn_cols_remove = {}\npttrn_cols_keep = {}\nfor i in list(reduced_dataframes) :\n    inter = []\n    inter = reduced_dataframes[i].loc[:,pattern_recognition_columns].fillna(0).astype(bool).sum().astype(bool)\n    pttrn_cols_remove[i] = inter.loc[inter.values == False ].index.tolist()\n    pttrn_cols_keep[i] = inter.loc[inter.values == True ].index.tolist()\n    reduced_dataframes[i].drop(columns=pttrn_cols_remove[i], inplace = True)","83f42ba0":"reduced_dataframes_full[1]","03a73b3d":"# Drop the rows with null target and start the EDA\nfor i in list(reduced_dataframes) :\n    reduced_dataframes[i].drop(reduced_dataframes[i][original_columns].loc[pd.isnull(reduced_dataframes[i][original_columns]).Target == True ].index, inplace=True)\n    reduced_dataframes[i].drop(reduced_dataframes[i][cycle_indicators_columns].loc[pd.isnull(reduced_dataframes[i][cycle_indicators_columns]).htsn_cyc == True ].index, inplace=True)","b2aae2cf":"#check that we don't have nulls\n\nsum_nulls = []\nfor i in list(reduced_dataframes) :\n    sum_nulls.append(reduced_dataframes[i].isnull().sum().sum())\nsum_nulls","4593efd2":"studied_columns = ['Target'] + momentum_indicators_columns + statitics_functions_columns + volatility_indicators_columns + price_transformations","ffbeefe6":"reduced_dataframes[1].loc[:,studied_columns].describe()","693a62be":"import matplotlib.pyplot as plt\nimport seaborn as sns","ffe1d8cc":"import plotly.graph_objects as go\n\nfig = go.Figure(data=[go.Candlestick(x=reduced_dataframes[1].index, open=reduced_dataframes[1]['Open'], high=reduced_dataframes[1]['High'], low=reduced_dataframes[1]['Low'], close=reduced_dataframes[1]['Close'])])\nfig.show()","c82804c9":"sns.kdeplot( data=reduced_dataframes[1], x=\"Target\", cumulative=False, common_norm=False, common_grid=True, )","4114bfdc":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n#print(scaler.fit(studied_columns))\n\nX = reduced_dataframes[1][studied_columns].copy()\ny = X.pop('Target')\nX_scaled = scaler.fit_transform(X)","4c8429e2":"X","cd28bb93":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=30, n_init=10, random_state=0, verbose=1, )\nX[\"Cluster\"] = kmeans.fit_predict(X_scaled)","b44cdd01":"Xy = X.copy()\nXy[\"Cluster\"] = Xy.Cluster.astype(\"category\")\nXy[\"Target\"] = y\n#sns.relplot(\n#    x=\"value\", y=\"Target\", hue=\"Cluster\", col=\"variable\",\n#    height=4, aspect=1, facet_kws={'sharex': False}, col_wrap=3,\n#    data=Xy.melt(\n#        value_vars=studied_columns, id_vars=[\"Target\", \"Cluster\"],\n#    ),\n#);","18730770":"good_clusters = []\nfor i in Xy.Cluster.value_counts().index :\n    lup = len(Xy.loc[(Xy.Cluster == i) & (Xy.Target > 0)]['Target'])\n    ldown = len(Xy.loc[(Xy.Cluster == i) & (Xy.Target <= 0)]['Target'])\n    m = (lup - ldown) \/ (lup + ldown)\n    good_clusters.append(m)","70c90b0a":"X['Cluster'].value_counts()","2a1f2125":"[good_clusters,Xy.Cluster.value_counts().index.tolist()]","a1610ecc":"Xy = X.copy()\nXy[\"Cluster\"] = Xy.Cluster.astype(\"category\")\nXy[\"Target\"] = y\nsns.relplot(\n    x=\"value\", y=\"Target\", hue=\"Cluster\", col=\"variable\",\n    height=4, aspect=1, facet_kws={'sharex': False}, col_wrap=3,\n    data=Xy.loc[Xy.Cluster == 14].melt(\n        value_vars=studied_columns, id_vars=[\"Target\", \"Cluster\"],\n    ),\n);","2640a364":"Xy.loc[(Xy.Cluster == 2) & (Xy.Target >= 0)].","d801d9d4":"sns.kdeplot( data=Xy.loc[(Xy.Cluster == 2) & (Xy.Target >= 0)], x=\"Target\", cumulative=False, common_norm=False, common_grid=True, )","0d85ea19":"sns.kdeplot( data=Xy.loc[(Xy.Cluster == 3)], x=\"Target\", cumulative=False, common_norm=False, common_grid=True, )","906ad189":"good_clusters = []\nfor i in Xy.Cluster.value_counts().index :\n    lup = len(Xy.loc[(Xy.Cluster == i) & (Xy.Target > 0)]['Target'])\n    ldown = len(Xy.loc[(Xy.Cluster == i) & (Xy.Target <= 0)]['Target'])\n    m = (lup - ldown) \/ (lup + ldown)\n    good_clusters.append(m)\n    ","ba46dc96":"Xy.Cluster.value_counts().index.tolist()","6ff964bd":"[good_clusters,Xy.Cluster.value_counts().index.tolist()]","fb7c0d5c":"sns.pairplot(reduced_dataframes[1][studied_columns],   \n    x_vars= studied_columns,\n    y_vars=['Target'], size = 10)\n\nplt.savefig('output.png')","485852ad":"Here let's generate each Technical indicators grouped by the type of the indicator","19ae9f1d":"\nsns.relplot(\n    data=reduced_dataframes[1], x=\"obv_vol\", y=\"Target\"\n    ,palette=[\"b\", \"r\"], sizes=(10, 100)\n)","f1a3e93d":"Instead of using all the KPIs let's use only what is useful,below we will stard by deleting the indecators that are either zeros or null across all the dataset","185dfb20":"sns.kdeplot(\n    data=reduced_dataframes[1], x=\"ad_vol\",\n    cumulative=False, common_norm=False, common_grid=True,\n)"}}