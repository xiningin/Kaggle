{"cell_type":{"a0e2c73b":"code","2a823e09":"code","19bfb42a":"code","82eb7c29":"code","b5596d63":"code","bf6b77a2":"code","7a80e332":"code","b114d3a8":"code","9634612b":"code","827ee755":"code","6c4230df":"code","0ba9da08":"code","abf77b60":"code","6f8805ab":"code","07d698e0":"code","0fd58050":"code","62a74ca4":"code","5b9075c2":"code","ca2de478":"code","0a7fa598":"code","e79f2032":"code","26270363":"code","f7e4d2b5":"code","df7d1f08":"code","c143314c":"code","cc3e7166":"code","636e413d":"code","327f1f8f":"code","cb9a5470":"code","8a9d26f5":"code","3da25e7a":"code","2f2a46a6":"code","aedeac49":"code","be08a733":"code","805bfdc8":"code","5d7cc6d2":"code","3f08cfa2":"code","66c2fe80":"code","55a56468":"markdown","c6fdb9ef":"markdown","0801bc7b":"markdown","e971bb00":"markdown","499bcf9d":"markdown","c39da207":"markdown","e9f4fb03":"markdown","e43b5d47":"markdown","26d9b2e4":"markdown","fde8e52b":"markdown","53a7686f":"markdown","431701a2":"markdown","6b051171":"markdown"},"source":{"a0e2c73b":"#It is a good practice to import all the modules that may be needed for the project.\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","2a823e09":"DATASET_URL = \"https:\/\/hub.jovian.ml\/wp-content\/uploads\/2020\/05\/insurance.csv\"\nDATA_FILENAME = \"insurance.csv\"\ndownload_url(DATASET_URL, '.')","19bfb42a":"dataframe_raw= pd.read_csv(DATA_FILENAME) #To read csv from a csv file using pandas dataframe where dataframe is like rows by columns.\ndataframe_raw.head(5) #used to see first 5 data in the dataframe","82eb7c29":"your_name = \"karthikayan\" # at least 5 characters","b5596d63":"def customize_dataset(dataframe_raw, rand_str):\n    dataframe = dataframe_raw.copy(deep=True)\n    # drop some rows\n    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n    # scale input\n    dataframe.bmi = dataframe.bmi * ord(rand_str[1])\/100.\n    # scale target\n    dataframe.charges = dataframe.charges * ord(rand_str[2])\/100.\n    # drop column\n    if ord(rand_str[3]) % 2 == 1:\n        dataframe = dataframe.drop(['region'], axis=1)\n    return dataframe","bf6b77a2":"dataframe = customize_dataset(dataframe_raw, your_name)\ndataframe.head()","7a80e332":"num_rows = len(dataframe)\nprint(num_rows)","b114d3a8":"num_cols = sum(1 for i in dataframe.columns)\nprint(num_cols)","9634612b":"input_cols = [i for i in dataframe.columns if(i!='charges')] #to get the input column titles\nprint(input_cols)","827ee755":"#to get the columns that contain string values instead of float values(will explain why we are doing this later)\ncategorical_cols = [i for i in input_cols if(type(dataframe[i][0]) is str)] \nprint(categorical_cols)","6c4230df":"output_cols = ['charges'] #the output column titles are obtained here.","0ba9da08":"mini=min(dataframe['charges'])\nmaxi=max(dataframe['charges'])\nmean=sum(dataframe['charges'])\/(len(dataframe['charges']))\nprint(mini,maxi,mean)\nplt.plot([i for i in range(num_rows)],dataframe['charges'],'x-r')\nplt.title(\"Output Distribution\")\nplt.xlabel('people')\nplt.ylabel('charges')\nplt.show()","abf77b60":"import numpy as np\ndef dataframe_to_arrays(dataframe):\n    # Make a copy of the original dataframe in order to make changes to the dataframe according to our needs\n    dataframe1 = dataframe.copy(deep=True) \n    # Convert non-numeric categorical columns to numbers (i.e, string variables to numbers as we can communicate with the machine only with numbers)\n    for col in categorical_cols:\n        dataframe1[col] = dataframe1[col].astype('category').cat.codes \n        #used to convert string to numbers(i.e if a column contains 'yes' or 'no' predominantly,it will assign 1-'yes' and 0-'no' likewise)\n        #print(dataframe1[col][:10],dataframe[col][:10])\n    # Extract input & outupts as numpy arrays in datatype float32 as the tensor expects the data to be of float type.\n    inputs_array = dataframe1[input_cols].to_numpy().astype(np.float32)\n    targets_array = dataframe1[output_cols].to_numpy().astype(np.float32)\n    return inputs_array, targets_array","6f8805ab":"inputs_array, targets_array = dataframe_to_arrays(dataframe)#you can understand better on looking into the outputs\ninputs_array, targets_array ","07d698e0":"#now the numpy arrays are converted to tensors\ninputs = torch.from_numpy(inputs_array)\ntargets = torch.from_numpy(targets_array)","0fd58050":"inputs.dtype, targets.dtype","62a74ca4":"dataset = TensorDataset(inputs, targets) #now the input and outputs are combined\ndataset[0] #you can see that the first part contains input feature values and the second part contains output values","5b9075c2":"#let's now split the train data into train and validation so that we can see the performance on the untouched data parallely\nval_percent = 0.1 # may be between 0.1 and 0.2\nval_size = int(num_rows * val_percent)\ntrain_size = num_rows - val_size\n\n\ntrain_ds, val_ds = random_split(dataset,[train_size,val_size]) # Use the random_split function to split dataset into 2 parts of the desired length","ca2de478":"batch_size = 128 # it is used to speed up the learning process","0a7fa598":"#we are shuffling the data in order to avoid overfitting as the input data is contiguous in aspect of categories(i.e, initial half of data represents a category and as it goes on other categories)\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True) \nval_loader = DataLoader(val_ds, batch_size)","e79f2032":"#let's have a look at the 1st batch \nfor xb, yb in train_loader:\n    print(\"inputs:\", xb)\n    print(\"targets:\", yb)\n    break","26270363":"input_size = len(input_cols)\noutput_size = len(output_cols)\nprint(input_size,output_size)","f7e4d2b5":"class InsuranceModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size,output_size)                  # fill this (hint: use input_size & output_size defined above)\n        \n    def forward(self, xb):\n        out = self.linear(xb)                         # fill this\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        # Generate predictions\n        out = self(inputs)          \n        # Calcuate loss\n        loss = F.l1_loss(out,targets)                          # fill this\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch\n        # Generate predictions\n        out = self(inputs)\n        # Calculate loss\n        loss = F.l1_loss(out,targets)                           # fill this    \n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result, num_epochs):\n        # Print result every 20th epoch\n        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))","df7d1f08":"model = InsuranceModel()","c143314c":"list(model.parameters())","cc3e7166":"jovian.commit(project=project_name, environment=None)","636e413d":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result, epochs)\n        history.append(result)\n    return history","327f1f8f":"result = evaluate(model,val_loader) # Use the the evaluate function\nprint(result)","cb9a5470":"epochs = 100\nlr = 1e-4\nhistory1 = fit(epochs, lr, model, train_loader, val_loader)","8a9d26f5":"epochs = 100\nlr = 1e-5\nmodel = InsuranceModel()\nhistory2 = fit(epochs, lr, model, train_loader, val_loader)","3da25e7a":"epochs = 100\nlr = 1e-6\nmodel = InsuranceModel()\nhistory3 = fit(epochs, lr, model, train_loader, val_loader)","2f2a46a6":"epochs = 100\nlr = 1e-7\nmodel = InsuranceModel()\nhistory4 = fit(epochs, lr, model, train_loader, val_loader)","aedeac49":"epochs = 40000\nlr = 1e-4\nmodel = InsuranceModel()\nhistory5 = fit(epochs, lr, model, train_loader, val_loader)","be08a733":"val_loss = history5[-1]['val_loss']\nprint(val_loss)","805bfdc8":"def predict_single(input, target, model):\n    inputs = input.unsqueeze(0)\n    predictions = model(inputs)     \n    prediction = predictions[0].detach()\n    print(\"Input:\", input)\n    print(\"Target:\", target)\n    print(\"Prediction:\", prediction)","5d7cc6d2":"input, target = val_ds[0]\npredict_single(input, target, model)","3f08cfa2":"input, target = val_ds[10]\npredict_single(input, target, model)","66c2fe80":"input, target = val_ds[20]\npredict_single(input, target, model)","55a56468":"## Step 5: Make predictions using the trained model\n","c6fdb9ef":"\nWe are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible.","0801bc7b":"## Step 3: Create a Linear Regression Model\n\nOur model itself is a fairly straightforward linear regression . \n","e971bb00":"Let's check out the weights and biases of the model using `model.parameters`.","499bcf9d":"## Step 1: Download and explore the data\n\nLet us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. ","c39da207":"## Step 4: Train the model to fit the data\n\nTo train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem.","e9f4fb03":"Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`.","e43b5d47":"## Step 2: Prepare the dataset for training\n\nWe need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays.","26d9b2e4":"To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https:\/\/data36.com\/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection\/","fde8e52b":"One final commit before we train the model.","53a7686f":"Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`.","431701a2":"Let's look at a batch of data to verify everything is working fine so far.","6b051171":"**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"}}