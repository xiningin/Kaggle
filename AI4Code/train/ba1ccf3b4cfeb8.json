{"cell_type":{"8c108a29":"code","f760020a":"code","e85eedb8":"code","92a66ca4":"code","13bddd21":"code","19ecc807":"code","84abc583":"code","bdec8eba":"code","b7a6a1be":"code","9453ecb4":"code","260ab6c3":"code","4c29a0bd":"code","8f059cc3":"code","2f7f6ac8":"code","3103ab77":"code","3b1e1fe8":"code","c86c993b":"code","61e58923":"markdown","72ae699f":"markdown","3765278a":"markdown","2fecd8b8":"markdown"},"source":{"8c108a29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Dl framwork - tensorflow, keras a backend \nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization \nfrom tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nfrom os import listdir\nfrom os.path import isfile, join\nfrom PIL import Image\nimport glob\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ndir_name = '\/kaggle\/input\/'\n# for dirname, _, filenames in os.walk(dir_name):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n    \n# Any results you write to the current directory are saved as output.","f760020a":"config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56}, log_device_placement=True ) \nsess = tf.compat.v1.Session(config=config) ","e85eedb8":"# Input data file\ntrain_path = os.path.join(dir_name, 'chest-xray-pneumonia\/chest_xray\/train')\ntrain_normal_path = os.path.join(train_path, 'NORMAL')\ntrain_pneumonia_path = os.path.join(train_path, 'PNEUMONIA')\n\nval_path = os.path.join(dir_name, 'chest-xray-pneumonia\/chest_xray\/test')\nval_normal_path = os.path.join(val_path, 'NORMAL')\nval_pneumonia_path = os.path.join(val_path, 'PNEUMONIA')\n\ntest_path = os.path.join(dir_name, 'chest-xray-pneumonia\/chest_xray\/test')\ntest_normal_path = os.path.join(test_path, 'NORMAL')\ntest_pneumonia_path = os.path.join(test_path, 'PNEUMONIA')","92a66ca4":"# # Plot the Images:\ndef plot_images(item_dir, n=6):\n    all_item_dir = os.listdir(item_dir)\n    item_files = [os.path.join(item_dir, file) for file in all_item_dir][:n]\n    \n    plt.figure(figsize=(35, 10))\n    for idx, img_path in enumerate(item_files):\n        plt.subplot(2, n, idx+1)\n        img = plt.imread(img_path)\n        plt.imshow(img, cmap='gray')\n        plt.axis('off')\n    \n    plt.tight_layout()","13bddd21":"plot_images(train_normal_path, 5)\nplot_images(train_pneumonia_path, 5)","19ecc807":"def Images_details_Print_data(data, path):\n    print(\" ====== Images in: \", path)    \n    for k, v in data.items():\n        print(\"%s:\\t%s\" % (k, v))\n\ndef Images_details(path):\n    files = [f for f in glob.glob(path + \"**\/*.*\", recursive=True)]\n    data = {}\n    data['images_count'] = len(files)\n    data['min_width'] = 10**100  # No image will be bigger than that\n    data['max_width'] = 0\n    data['min_height'] = 10**100  # No image will be bigger than that\n    data['max_height'] = 0\n\n\n    for f in files:\n        im = Image.open(f)\n        width, height = im.size\n        data['min_width'] = min(width, data['min_width'])\n        data['max_width'] = max(width, data['max_height'])\n        data['min_height'] = min(height, data['min_height'])\n        data['max_height'] = max(height, data['max_height'])\n\n    Images_details_Print_data(data, path)","84abc583":"Images_details(train_normal_path)\nImages_details(train_pneumonia_path)","bdec8eba":"input_path = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/\"\n    \nfor _set in ['train', 'test', 'val']:\n    nrml = len(os.listdir(input_path + _set + '\/NORMAL'))\n    pnm = len(os.listdir(input_path + _set + '\/PNEUMONIA'))\n    print('{}, Normal images: {}, Pneumonia images: {}'.format(_set, nrml, pnm))","b7a6a1be":"\ndef process_data(img_dims, batch_size):\n    # Data generation objects - thorugh rescalling, veticle flip, zoom range\n    train_datagen = ImageDataGenerator(\n                        rescale = 1.\/255,\n                      # featurewise_center=True,\n                      # featurewise_std_normalization=True,\n                        zoom_range = 0.3,\n                        vertical_flip = True)\n    \n    test_datagen = ImageDataGenerator(\n                      #  featurewise_center=True,\n                      #  featurewise_std_normalization=True,\n                        rescale=1.\/255)\n    \n    # This is fed to the network in the specified batch sizes and image dimensions\n    train_gen = train_datagen.flow_from_directory(\n                                directory = train_path, \n                                target_size = (img_dims, img_dims), \n                                batch_size = batch_size, \n                                class_mode = 'binary', \n                                shuffle=True)\n\n    test_gen = test_datagen.flow_from_directory(\n                                directory=test_path, \n                                target_size=(img_dims, img_dims), \n                                batch_size=batch_size, \n                                class_mode='binary', \n                                shuffle=True)\n    \n    # Making predictions off of the test set in one batch size\n    # This is useful to be able to get the confusion matrix\n    test_data = []\n    test_labels = []\n\n    for cond in ['\/NORMAL\/', '\/PNEUMONIA\/']:\n        for img in (os.listdir(test_path + cond)):\n            img = plt.imread(test_path + cond + img)\n            img = cv2.resize(img, (img_dims, img_dims))\n            img = np.dstack([img, img, img])\n            img = img.astype('float32') \/ 255\n            if cond=='\/NORMAL\/':\n                label = 0\n            elif cond=='\/PNEUMONIA\/':\n                label = 1\n            test_data.append(img)\n            test_labels.append(label)\n        \n    test_data = np.array(test_data)\n    test_labels = np.array(test_labels)\n    \n    return train_gen, test_gen, test_data, test_labels","9453ecb4":"# Hyperparameters\nimg_dims = 150\nepochs = 20\nbatch_size = 32\n\n# Getting the data\ntrain_gen, test_gen, test_data, test_labels = process_data(img_dims, batch_size)","260ab6c3":"inputs = Input(shape=(img_dims, img_dims, 3))\n\n# First conv block\nx = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\nx = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Second conv block\nx = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Third conv block\nx = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Fourth conv block\nx = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = Dropout(rate=0.2)(x)\n\n# Fifth conv block\nx = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = Dropout(rate=0.2)(x)\n\n# FC layer\nx = Flatten()(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(rate=0.7)(x)\nx = Dense(units=128, activation='relu')(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(units=64, activation='relu')(x)\nx = Dropout(rate=0.3)(x)\n\n# Output layer\noutput = Dense(units=1, activation='sigmoid')(x)\n\n# Creating model and compiling\nmodel = Model(inputs=inputs, outputs=output)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Callbacks\ncheckpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)\nlr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')","4c29a0bd":"model.summary()","8f059cc3":"#### Fitting the model\nhistory = model.fit_generator(\n           train_gen, steps_per_epoch=train_gen.samples \/\/ batch_size, \n           epochs=epochs, \n           validation_data=test_gen, \n           validation_steps=test_gen.samples \/\/ batch_size,\n           callbacks=[checkpoint, lr_reduce])","2f7f6ac8":"# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","3103ab77":"# confution matrix\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\npreds = model.predict(test_data)\n\naccuracy = accuracy_score(test_labels, np.round(preds))*100\nconf_mat = confusion_matrix(test_labels, np.round(preds))\ntrue_negative, false_postive, false_negative, true_posiitve = conf_mat.ravel()\n\nplt.title(\"CONFUSION MATRIX\")\nplot_confusion_matrix(conf_mat,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.show()","3b1e1fe8":"print('\\n','-'*20,' TEST METRICS', '-'*20)\nprecision = true_posiitve \/ (true_posiitve + false_postive) * 100\nrecall = true_posiitve \/ (true_posiitve + false_negative) * 100\nprint('\\tAccuracy: {}%'.format(accuracy))\nprint('\\tPrecision: {}%'.format(precision))\nprint('\\tRecall: {}%'.format(recall))\nprint('\\tF1-score: {}'.format(2*precision*recall\/(precision+recall)))","c86c993b":"# Save the model\nmodel.save('xray-pneumona-depthwise-convolution.h5')","61e58923":"### Data Augmentation\nThe practice of data augmentation is an effective way to increase the size of the training set.\n\nAugmenting the training examples allow the network to \u201csee\u201d more diversified, but still representative, data points during training.\n\nThere's two data generators: one for training data, and the other for validation data. A data generator is capable of loading the required amount of data (a mini batch of images) directly from the source folder, convert them into training data (fed to the model) and training targets (a vector of attributes \u2014 the supervision signal).","72ae699f":"The dataset respective to already classified category is divided into three sets: \n1. train set ,\n1. validation set and \n1. test set. ","3765278a":"## Model\u00b6\n\nIn this approach, I tried to trained the modal from scratch. The process I followed is - \n\n1. Selected a simple architecture.\n1. Initialized the layers from given training data with dims 150. \n1. Choose layers that introduce a lesser number of parameters. For example, [Depthwise SeparableConv](https:\/\/towardsdatascience.com\/a-basic-introduction-to-separable-convolutions-b99ec3102728) is a good replacement for `Conv layer`. It introduces lesser number of parameters as compared to normal convolution and as different filters are applied to each channel, so it captures more information. \n1. Used batch norm with convolutions. As the network becomes deeper, batch norm start to play an important role.\n1. Added dense layers with reasonable amount of neurons. Trained with a higher learning rate and experiment with the number of neurons in the dense layers. Did it for the depth of your network too.\n1. Once a good depth, started training the network with a lower learning rate.\n\nRef: https:\/\/towardsdatascience.com\/a-basic-introduction-to-separable-convolutions-b99ec3102728","2fecd8b8":"The model is converging which can be observed from the decrease in loss and validation loss with epochs. Also it is able to reach over 90% validation accuracy in just 20 epochs, which is good.\n\nThe classes are imbalanced therefore validation accuracy won't be a good metric to analyze the model performance. The other metric, recall, precison and confusion matrix is good alternative to see the performance of the model. In this model, we got almost 98% recall value and 90% precison which is pretty good.\n\nAlso, here recall is most significant quantity even more than accuracy and precision because in this dataset we have to minimize the false negative as low as possible\n\nFalse negative has to be intuitively minimized because falsely diagnosing a patient of pneumonia as not having a pneumonia is a much larger deal than falsely diagnosing a healthy person as a pneumonia patient which is our major concern . That is why we are making this model. To reduce the mistakes done by doctors accidentally. "}}