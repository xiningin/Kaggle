{"cell_type":{"ed323982":"code","b3a240de":"code","b114b550":"code","a98e3cf5":"code","2cc5dd88":"code","1b399c80":"code","cd732d8d":"code","3653fbfc":"code","a790edef":"code","a4d48d03":"code","59fd0857":"code","e6ef4c18":"code","0eef885e":"code","18a9e3d3":"code","a03c4596":"code","06602319":"code","e42856aa":"code","a90b8828":"code","98d0c190":"code","690e13ae":"code","d1f31d2c":"code","757d0f52":"code","9b010ca3":"code","8951ebf0":"code","3cc70efc":"code","1fa9977e":"code","57ec5ee3":"code","a9de1011":"code","77d680c0":"code","dc447abd":"code","39a90da1":"code","a699849d":"code","571dac6c":"code","081cf2c0":"code","3f5b80ca":"code","ccabfc93":"code","90656242":"code","14c2d6f1":"code","f70dc0a4":"code","8c37ab94":"code","71e6f534":"code","a45cbeb7":"code","7949c099":"code","4f831c6f":"code","4e54ddfb":"code","0fc25b5b":"code","2c7d3821":"code","aaab8846":"code","303f7019":"code","5a86ed49":"code","8f246aba":"code","c13dd58b":"code","3ca707f9":"code","fc16d487":"code","5aef59b7":"code","8e11cb07":"code","f7098753":"code","83250b07":"code","1478b33b":"code","cc9a72f2":"code","9a157c5a":"code","01809f1e":"code","0406b666":"code","bc0e34e1":"code","4d0d7696":"code","91529d61":"code","e7f3b063":"code","6bf666d3":"code","60bf8ed4":"code","ada9ea11":"code","11182edb":"code","7f3ab531":"code","b003136f":"code","237af86c":"code","7b8d45cc":"code","737f7c12":"code","08b59090":"markdown","026fd4d6":"markdown","3548e6d7":"markdown","dec3721e":"markdown","0ad02e7a":"markdown","5fff1d5e":"markdown","c7fe8398":"markdown","1f0d6494":"markdown","49b5a8d1":"markdown","6292b951":"markdown","6414325b":"markdown","cb691687":"markdown","e2332baa":"markdown","6dd2425e":"markdown","578fbfb4":"markdown","cce1febd":"markdown","61bd671b":"markdown","c5f4b285":"markdown","2ba5b553":"markdown","d6213439":"markdown","2fefff69":"markdown","11511a8e":"markdown","0586b205":"markdown","4bb3b2f6":"markdown","43205b83":"markdown","3d0b0a06":"markdown","1cc5bb47":"markdown","8cd344fd":"markdown","e28b5935":"markdown","ba8e0e4b":"markdown","989d8357":"markdown","2c7d3b11":"markdown","b680bf62":"markdown","99fbf80c":"markdown","ac825c29":"markdown","4a16df4c":"markdown","3d026ef4":"markdown","b9f1a0b4":"markdown","4b0fd971":"markdown","250d797e":"markdown","2fe72f96":"markdown","64262d83":"markdown","fa9427f0":"markdown","653eb31a":"markdown","f22d1af4":"markdown","3877f888":"markdown","505c3bf0":"markdown","0f60f8e0":"markdown","c628ac09":"markdown","23808960":"markdown","b2126bd3":"markdown","18c94bee":"markdown","dea16f77":"markdown","3358c9b9":"markdown","f8c75a85":"markdown","d1251b88":"markdown","2801023f":"markdown","a8f89c77":"markdown","accd96aa":"markdown"},"source":{"ed323982":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b3a240de":"# Importing all required packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport datetime\n\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","b114b550":"#Import data into python\nboombikes = pd.read_csv('..\/input\/bike-sharing-assignment\/day.csv')","a98e3cf5":"# Check head of the Data\nboombikes.head()","2cc5dd88":"#Check info \nboombikes.info()","1b399c80":"# Check shape\nboombikes.shape","cd732d8d":"# Check describe\nboombikes.describe()","3653fbfc":"#Check columnwise null values\nboombikes.isnull().mean()","a790edef":"# check row-wise null values\nboombikes.isnull().mean(axis=1)","a4d48d03":"boombikes.isnull().values.any()","59fd0857":"# Create a dummy dataframefor duplicate check\nbb_duplicates = boombikes\n\n# Checking for duplicates and dropping the entire duplicate row if any\nbb_duplicates.drop_duplicates(subset=None, inplace=True)\nprint(bb_duplicates.shape)\nprint(boombikes.shape)","e6ef4c18":"boombikes.drop(['instant','dteday', 'casual','registered'], axis=1, inplace=True)","0eef885e":"boombikes.head()","18a9e3d3":"# Check the correlation between the variables in Dataframe\nplt.figure(figsize = (16, 10))\nsns.heatmap(boombikes.corr(),annot = True, cmap=\"YlGnBu\")\nplt.show()","a03c4596":"#Drop atemp variable as we are using temp variable in analysis\nboombikes.drop(['atemp'], axis = 1, inplace = True)\nboombikes.head()","06602319":"plt.figure(figsize = (16, 10))\nsns.heatmap(boombikes.corr(),annot = True, cmap=\"YlGnBu\")\nplt.show()","e42856aa":"#Check data types of the variable\nboombikes.dtypes","a90b8828":"# Convert categoric variables to 'category' data type\n\nboombikes['season']=boombikes['season'].astype('category')\nboombikes['weathersit']=boombikes['weathersit'].astype('category')\nboombikes['mnth']=boombikes['mnth'].astype('category')\nboombikes['weekday']=boombikes['weekday'].astype('category')\nboombikes.info()","98d0c190":"#adding categorical values into categorical variables\nboombikes['season'] = boombikes['season'].map({1:'spring', 2:'summer',3:'fall',4:'winter'})\nboombikes['mnth'] = boombikes['mnth'].map({1:'JAN', 2:'FEB',3:'MAR',4:'APR',5:'MAY',6:'JUN',7:'JUL',8:'AUG',9:'SEP',10:'OCT',11:'NOV',12:'DEC'})\nboombikes['weekday'] = boombikes['weekday'].map({0:'SUN',1:'MON', 2:'TUE',3:'WED',4:'THU',5:'FRI',6:'SAT'})\nboombikes['weathersit'] = boombikes['weathersit'].map({1:'Clear', 2:'Mist & Cloudy',3:'Light snow & Rain',4:'Heavy snow & rain'})","690e13ae":"boombikes.head()","d1f31d2c":"##### 5.1 Numeric Variables:\nsns.boxplot('temp', data = boombikes)\nplt.show()","757d0f52":"sns.boxplot('hum', data = boombikes)\nplt.show()","9b010ca3":"sns.boxplot('windspeed', data = boombikes)\nplt.show()","8951ebf0":"sns.barplot(x ='yr', y = 'cnt' ,data = boombikes )","3cc70efc":"sns.barplot(x ='holiday', y = 'cnt' ,data = boombikes )","1fa9977e":"sns.barplot(x ='workingday', y = 'cnt' ,data = boombikes )","57ec5ee3":"sns.barplot(x ='season', y = 'cnt' ,data = boombikes )","a9de1011":"sns.barplot(x ='mnth', y = 'cnt' ,data = boombikes )","77d680c0":"sns.barplot(x ='weekday', y = 'cnt' ,data = boombikes )","dc447abd":"sns.barplot(x ='weathersit', y = 'cnt' ,data = boombikes )","39a90da1":"#Get Dummy variables for 'season'\nseason = pd.get_dummies(boombikes['season'], drop_first = True)\nboombikes = pd.concat([boombikes, season], axis = 1)\n#Get Dummy variables for 'mnth'\nmnth = pd.get_dummies(boombikes['mnth'], drop_first = True)\nboombikes = pd.concat([boombikes, mnth], axis = 1)\n#Get Dummy variables for 'weekday'\nweekday = pd.get_dummies(boombikes['weekday'], drop_first = True)\nboombikes = pd.concat([boombikes, weekday], axis = 1)\n#Get Dummy variables for 'weathersit'\nweathersit = pd.get_dummies(boombikes['weathersit'], drop_first = True)\nboombikes = pd.concat([boombikes, weathersit], axis = 1)\nboombikes.head()\n","a699849d":"#Drop the variables for which dummies are created.\nboombikes.drop(['season','mnth','weekday','weathersit'], axis=1, inplace = True)\nboombikes.head()","571dac6c":"boombikes.shape","081cf2c0":"boombikes.dtypes","3f5b80ca":"#Import train_test_split from sklearn model_selection\nfrom sklearn.model_selection import train_test_split","ccabfc93":"train, test = train_test_split(boombikes, train_size = 0.7, random_state = 100)","90656242":"print(train.shape)\nprint(test.shape)\nprint(boombikes.shape)","14c2d6f1":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","f70dc0a4":"num_vars = ['temp', 'hum', 'windspeed','cnt']\n\ntrain[num_vars] = scaler.fit_transform(train[num_vars])","8c37ab94":"sns.heatmap(train[num_vars].corr(),annot = True, cmap=\"YlGnBu\")\nplt.show()","71e6f534":"train.head()","a45cbeb7":"train.describe()","7949c099":"y_train = train.pop('cnt')\nX_train = train","4f831c6f":"X_train.head()","4e54ddfb":"y_train.head()","0fc25b5b":"#Importing the statsmodels api \nimport statsmodels.api as sm\n# Importing RFE and LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","2c7d3821":"#Running RFE\nlm = LinearRegression()\nlm.fit(X_train, y_train)\n\nrfe = RFE(lm, 15)\nrfe = rfe.fit(X_train, y_train)\n\nlist(zip(X_train.columns,rfe.support_,rfe.ranking_))\n","aaab8846":"#Featured columns after rfe\ncol = X_train.columns[rfe.support_]\n\nprint(col)\nprint(X_train.columns[~rfe.support_])","303f7019":"##lm_1\n# Creating X_test dataframe with RFE selected variables\nX_train_rfe = X_train[col]\nX_train_rfe = sm.add_constant(X_train_rfe)\nlm_1 = sm.OLS(y_train,X_train_rfe).fit()\nprint(lm_1.summary())","5a86ed49":"#Import variance_inflation_factor from statsmodels\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nX_train_new = X_train_rfe.drop(['const'], axis=1)\n# Calculate the VIFs \nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","8f246aba":"##Lm_2\n#New model without \"fall\"\n\nX_train_new = X_train_new.drop([\"fall\"], axis = 1)\nX_train_lm = sm.add_constant(X_train_new)\nlm_2 = sm.OLS(y_train,X_train_lm).fit()\nprint(lm_2.summary())","c13dd58b":"# VIFs without \"fall\"\n# X_train_new = X_train_new.drop(['const'], axis =1)\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","3ca707f9":"#New model without \"fall\"& \"hum\"\nX_train_new = X_train_new.drop([\"hum\"], axis = 1)\nX_train_lm = sm.add_constant(X_train_new)\nlm_3 = sm.OLS(y_train,X_train_lm).fit()\nprint(lm_3.summary())","fc16d487":"# VIFs without \"fall\"& \"hum\"\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","5aef59b7":"#New model without \"fall\"& \"hum\" & \"OCT\"\nX_train_new = X_train_new.drop([\"OCT\"], axis = 1)\nX_train_lm = sm.add_constant(X_train_new)\nlm_4 = sm.OLS(y_train,X_train_lm).fit()\nprint(lm_4.summary())","8e11cb07":"# VIFs without \"fall\"& \"hum\" & \"OCT\"\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","f7098753":"#New model without  \"fall\"& \"hum\" & \"OCT\" & \"holiday\"\nX_train_new = X_train_new.drop([\"holiday\"], axis = 1)\nX_train_lm = sm.add_constant(X_train_new)\nlm_5 = sm.OLS(y_train,X_train_lm).fit()\nprint(lm_5.summary())","83250b07":"# VIFs without \"fall\"& \"holiday\" & \"OCT\" & \"workingday\"\n\nvif = pd.DataFrame()\nX = X_train_new\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","1478b33b":"#New model without \"fall\",\"hum\",\"OCT\",\"holiday\",\"AUG\"\nX_train_new6 = X_train_rfe.drop([\"fall\",\"hum\",\"OCT\",\"holiday\",\"AUG\"], axis = 1)\nX_train_lm6 = sm.add_constant(X_train_new6)\nlm_6 = sm.OLS(y_train,X_train_lm6).fit()\nprint(lm_6.summary())\n","cc9a72f2":"print(lm_6.params)","9a157c5a":"# VIFs without \nX_train_new6  = X_train_new6.drop([\"const\"], axis =1)\nvif = pd.DataFrame()\nX = X_train_new6\nvif['Features'] = X.columns\nvif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","01809f1e":"y_train_pred = lm_6.predict(X_train_lm6)","0406b666":"res = y_train-y_train_pred\n\n# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((res), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18) ","bc0e34e1":"# Perform scaling on test data for numeric variables\nnum_vars = ['temp', 'hum', 'windspeed','cnt']\ntest[num_vars] = scaler.fit_transform(test[num_vars])","4d0d7696":"test.describe()","91529d61":"test.head()","e7f3b063":"#Dividing into X_test and y_test\ny_test = test.pop('cnt')\nX_test = test","6bf666d3":"X_test.head()","60bf8ed4":"X_test.info()","ada9ea11":"#Selecting the variables that were part of final model.\nfinal_columns = X_train_new6.columns\n\nX_test=X_test[final_columns]\n\n# Adding constant variable to test dataframe\nX_test_lm6 = sm.add_constant(X_test)\n\nX_test_lm6.info()","11182edb":"X_test_lm6.head()","7f3ab531":"# Making predictions using the final model (lm_7)\n\ny_pred = lm_6.predict(X_test_lm6)","b003136f":"# Plotting y_test and y_pred to understand the spread.\nfig = plt.figure()\nplt.scatter(y_test, y_pred, alpha=.5)\nfig.suptitle('y_test vs y_pred', fontsize = 20)             \nplt.xlabel('y_test', fontsize = 18)                         \nplt.ylabel('y_pred', fontsize = 16) ","237af86c":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","7b8d45cc":"X_test.shape","737f7c12":"# n is number of rows in X\nr2= r2_score(y_test, y_pred)\nn = X_test.shape[0]\n\n\n# Number of features (predictors, p) is the shape along axis 1\np = X_test.shape[1]\n\n# We find the Adjusted R-squared using the formula\n\nadjusted_r2 = 1-(1-r2)*(n-1)\/(n-p-1)\nadjusted_r2","08b59090":"## Problem Statement","026fd4d6":"### Visualization of Numeric, Binary and Categoric Variables","3548e6d7":" - We could see temp is having no outliers values range between 2.5 to 35","dec3721e":" - We could see cnt is high for fall followed by summer and winter","0ad02e7a":"### Final Report","5fff1d5e":"  - season         : -  season (1:spring, 2:summer, 3:fall, 4:winter)\n  - yr             : - year (0: 2018, 1:2019)\n  - mnth           : - month ( 1 to 12) (JAN to DEC)\n  - holiday        : -  weather day is a holiday or not (extracted from http:\/\/dchr.dc.gov\/page\/holiday-schedule)\n  - weekday        : -  day of the week (MON to SUN)\n  - workingday     : -  if day is neither weekend nor holiday is 1, otherwise is 0.\n  - weathersit     : \n - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog","c7fe8398":"### Check Null counts in Dataframe","1f0d6494":"As per our final Model, the top 3 predictor variables that influences the bike booking are: \n\n - temp  :a unit increase in temp variable increases the bike hiring members by 0.549892\n - yr    : a unit increase in yr variable increases the bike hiring members by 0.233139\n - winter: a unit increase in winter variable increases the bike hiring members by 0.130655\n\n& most effecting factor for bike booking are :\n - Light snow & Rain: a unit increase in Light snow & Rain variable decreases the bike hiring members by 0.287090\n - windspeed :a unit increase in windspeed variable decreases the bike hiring members by 0.155203\n - Mist & Cloudy : a unit increase in Mist & Cloudy variable decreases the bike hiring members by 0.080022\n   \n   \n& other variables to get maximum bookings are :\nconst  : the constant is 0.075009, in absence of all predictor variables hiring members will be increasing by 0.075009\nworkingday : a unit increase in working variable increases the bike hiring members by 0.056117\nsummer : a unit increase in summer variable increases the bike hiring members by 0.088621\nSEP : a unit increase in SEP variable increases the bike hiring members by 0.097365\nSAT : a unit increase in SAT variable increases the bike hiring members by0.067500\n\n\n","49b5a8d1":"### Importing all required packages","6292b951":" - Both boombikes and bike_dup shape is same, so we conclude that there is no duplicates in the dataframe","6414325b":"##### 5.1 Numeric Variables:\n        - temp\n        - hum\n        - windspeed\n        - cnt        \n##### 5.2 Binary Variables:\n        - yr\n        - Holiday\n        - Workingday\n##### 5.3 Categoric Variables:\n        - season\n         - mnth\n        - weekday\n        - weathersit","cb691687":" # BikeSharing Assignment","e2332baa":"### Dummy Variables","6dd2425e":"### Linear_model_1","578fbfb4":" -  Lets drop OCT as it is 5% p-value","cce1febd":"### Building a linear model","61bd671b":"#### 5.2 Binary Variables:\n        - yr\n        - Holiday\n        - Workingday","c5f4b285":" - We could see start of the year count is low and it increases gradually and reduces at the end of the year","2ba5b553":"### Linear_model_5","d6213439":"### Linear_model_6","2fefff69":" -  Drop holiday as it is having 4% p-value","11511a8e":" - temp most correlated variables with target variable cnt\n - As both conveyed same info we dropped atemp","0586b205":" - From above, we can say that there is no null data present in dataframe.","4bb3b2f6":"### Data Preparation, visualization and Creating Dummy Variables","43205b83":"### Linear_model_2","3d0b0a06":" - From the above, we could see P-Value for fall is >5%\n - Calculate the VIF to work further on the model","1cc5bb47":" - hum is having outliers below 25 value.\n - hum is in range between 25 to 100\n - if the value is required to be imputed it can be mean value.","8cd344fd":"- We could see temp and atemp are highly correlated, one of the variable can be dropped as both contains same information.","e28b5935":" - 2019 is having higher count","ba8e0e4b":"### Linear_model_3","989d8357":"A bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state. \n\n\nIn such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\nWhich variables are significant in predicting the demand for shared bikes.\nHow well those variables describe the bike demands\nBased on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors. ","2c7d3b11":"### Linear_model_4","b680bf62":"FINAL RESULT COMPARISON: \n - Train R^2 :0.835 \n - Train Adjusted R^2 :0.832 \n - Test R^2 :0.787 \n - Test Adjusted R^2 :0.777 \n\nThe difference in test and train R score is 5%, this seems to be a  good model that can very well 'Generalize' various datasets","99fbf80c":"### Splitting the data into Test and train","ac825c29":"### R^2 Value for TEST","4a16df4c":" - We could see residuals distribution is Normal\n - Mean value is 0\n - Hence our assumption for Linear Regression is valid","3d026ef4":"#### 5.2 Categoric Variables:\u00b6\n    - season\n    - mnth\n    - weekday\n    - weathersit","b9f1a0b4":"## Business Goal","4b0fd971":"### Making Predictions with test datam","250d797e":"### Adjusted R^2 Value for TEST\nFormula for Adjusted R^2\n\nR2adj.=1\u2212(1\u2212R2)\u2217n\u22121n\u2212p\u22121","2fe72f96":" - As Temp is highly correlated variable with target variable, we have to look at other variables. from p-value we could see fall is having more than 5%, lets drop \"fall\"","64262d83":"### Residual Analysis of the train data","fa9427f0":" - windspeed is having outliers above 25\n - windspeed value ranges between 1 to 25\n - if the value required to be imputed it can be mean","653eb31a":"You are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market. ","f22d1af4":" - cnt and temp are +ve correlated(0.63)\n - cnt and season are +ve correlated(0.4)\n - cnt and yr are +ve correlated(0.57)\n - weathersit and hum are +ve correlated(0.59)\n","3877f888":"### Comments :\n - Lets take above model lm_6 as best fit model\n - All Variables P-Value is 0, means that all the variables are significant\n - VIF values of variables in less than 5\n - According to VIF we can say that there is less multicolinearity between the variables\n \n ### Coefficients of the variables are :\n -  const                0.075009\n -  yr                   0.233139\n -  workingday           0.056117\n -  temp                 0.549892\n -  windspeed           -0.155203\n -  summer               0.088621\n -  winter               0.130655\n -  SEP                  0.097365\n -  SAT                  0.067500\n -  Mist & Cloudy       -0.080022\n -  Light snow & Rain   -0.287090\n \n \n### Final Model Interpretation\n - Hypothesis Testing:\n           H0:B1=B2=...=Bn=0 \n           H1:Bi!=0\n - From the lm_7 model summary, it is evident that all our coefficients are not equal to zero. which means We REJECT the NULL      HYPOTHESIS\n\n### F-Statistics \n - F-statistic:                     253.0\n - Prob (F-statistic):          3.13e-188\n - The F-Statistics value of 253 (which is greater than 1) and the p-value of '~0.0000' states that the overall model is significant\n \n### Equation of the best fit model is \n\n - cnt =  0.075009+(0.233139*yr)+(0.056117*workingday)+(0.549892*temp)-(0.155203*windspeed)+(summer*0.088621)+(winter*0.130655)+(0.097365*SEP)+(SAT*0.067500)-(0.080022* Mist & Cloudy)-(0.287090*Light snow & Rain)\n \n \n### Coefficients Interpretation :\n\n -  #### const  : the constant is 0.075009, in absence of all predictor variables hiring members will be increasing by 0.075009\n -  #### yr     : a unit increase in yr variable increases the bike hiring members by 0.233139\n -  #### workingday : a unit increase in working variable increases the bike hiring members by 0.056117\n -  #### temp  :a unit increase in temp variable increases the bike hiring members by 0.549892\n -  #### windspeed :a unit increase in windspeed variable decreases the bike hiring members by 0.155203\n -  #### summer : a unit increase in summer variable increases the bike hiring members by 0.088621\n -  #### winter: a unit increase in winter variable increases the bike hiring members by 0.130655\n -  #### SEP : a unit increase in SEP variable increases the bike hiring members by 0.097365\n -  #### SAT : a unit increase in SAT variable increases the bike hiring members by0.067500\n -  #### Mist & Cloudy : a unit increase in Mist & Cloudy variable decreases the bike hiring members by 0.080022\n -  #### Light snow & Rain: a unit increase in Light snow & Rain variable decreases the bike hiring members by 0.287090","505c3bf0":" - Cnt is high on working day","0f60f8e0":"### Model Evaluation","c628ac09":" - Cnt is high on Clear days","23808960":"### Check the correlation between the variables","b2126bd3":"### Inspect the data","18c94bee":"### Rescaling the Features","dea16f77":" - hum is having high VIF and p-value is less than 5% for all variables","3358c9b9":"### Dividing into X and Y sets for the model building","f8c75a85":" - Cnt is more on working days","d1251b88":"### Drop unwanted columns\/variables\n\n#### Dropping the below columns as these are not required to perform linear regression.\n - instant - just instant not required\n - dteday - dteday is a date column, as we have day, month and year already in the dataframe we can drop this column\n - casual & registered - cnt is target variable, these two columns become duplicate as casual + registered considered as cnt, hence deling the columns\n","2801023f":"### Final Result Comparison","a8f89c77":" - cnt is less on Sundays and it gradually increasing","accd96aa":"### RFE"}}