{"cell_type":{"0a67a42d":"code","42086b4f":"code","c5145e95":"code","eb3e557e":"code","57e44075":"code","c72aebe0":"code","bf3a7241":"code","a6555abf":"code","89a4e1da":"code","a82b6739":"code","3fd50814":"code","557e733b":"code","78e9a393":"code","f4f876a4":"code","7422ba5c":"markdown","dec59d25":"markdown"},"source":{"0a67a42d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42086b4f":"ad_df = pd.read_csv('..\/input\/internet-advertisements-data-set\/add.csv', index_col=0,low_memory=False)\nad_df.head(5)","c5145e95":"# Drop invalid\nad_df2 = ad_df.applymap(lambda val: np.nan if str(val).strip() == '?' else val)\nad_df2 = ad_df2.dropna()\n\nad_df2.head(5)","eb3e557e":"from sklearn.preprocessing import LabelEncoder\nlb = LabelEncoder()\ny = lb.fit_transform(ad_df2.iloc[:, -1])","57e44075":"y[0:5]","c72aebe0":"X = ad_df2.iloc[:,:-1]\n","bf3a7241":"X.head(5)","a6555abf":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","89a4e1da":"X[0:5,:]","a82b6739":"from sklearn import model_selection \nfrom sklearn.ensemble import BaggingClassifier \nfrom sklearn.tree import DecisionTreeClassifier \n\n\ndef get_accuracy_with_bagging(base_cls = DecisionTreeClassifier(), bag_percent_size=10, splits=10, seed=1887, num_trees=50):\n    kfold = model_selection.KFold(n_splits = splits)     \n\n    # bagging classifier \n    model = BaggingClassifier(base_estimator = base_cls, \n                              n_estimators = num_trees, \n                              random_state = seed,\n                              max_samples=(bag_percent_size\/100.0)\n                             ) \n\n    results = model_selection.cross_val_score(model, X, y, cv = kfold) \n    return results.mean() ","3fd50814":"result = []\n\nfor bag_percent_size in range(10, 101, 10):\n    accuracy = get_accuracy_with_bagging(bag_percent_size=bag_percent_size, splits=10)\n    print (\"Accuracy: \", accuracy, \" Bag Percent Size: \", bag_percent_size)\n    result.append([bag_percent_size, accuracy])","557e733b":"result","78e9a393":"result_pd = pd.DataFrame(result)\nresult_pd.columns = ['BagPercentSize', 'Accuracy']\nresult_pd","f4f876a4":"result_pd.plot(x='BagPercentSize', y='Accuracy')","7422ba5c":"## Analysis\nWe can observe from graph that max accuracy is at bag percent size of 50. Secondly accuracy above 95 are in range of 50-80 bag percent size. \n","dec59d25":"[[](http:\/\/)](http:\/\/)"}}