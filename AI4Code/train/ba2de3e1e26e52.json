{"cell_type":{"a15a5a89":"code","481dfa94":"code","3ea865ba":"code","727ab8e1":"code","aad575e7":"code","26ec676b":"code","dbaca641":"code","9a333527":"code","28aaa50b":"code","99557062":"code","d3996b67":"code","d91a4265":"code","77f281bd":"code","78379487":"code","f24be5ef":"code","2e1c8dd1":"code","92e901c3":"code","b031cdfd":"code","77b88c4e":"code","6007ca88":"code","ffe35b27":"code","2ea11420":"code","67e2335c":"markdown","a759b924":"markdown","d21182c9":"markdown","86c6a95c":"markdown","a0f61ca4":"markdown","d960fdbf":"markdown","b604ef9e":"markdown","c2c7e21d":"markdown","9880b6af":"markdown","1d5a3263":"markdown","0d995284":"markdown","b6f3bf04":"markdown","1d58e4b2":"markdown","9d4815d7":"markdown","5256f834":"markdown","1d5115cb":"markdown","85677dfa":"markdown","6d50795c":"markdown","5ec1204e":"markdown","26e629b3":"markdown","9893d065":"markdown","270b7e7c":"markdown","c310834b":"markdown"},"source":{"a15a5a89":"import random, os, warnings, math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import optimizers, losses, metrics, Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom transformers import TFAutoModelForSequenceClassification, TFAutoModel, AutoTokenizer\n\n\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 0\nseed_everything(seed)\nsns.set(style='whitegrid')\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_colwidth', 150)","481dfa94":"# TPU or GPU detection\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f'Running on TPU {tpu.master()}')\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","3ea865ba":"train_filepath = '\/kaggle\/input\/commonlitreadabilityprize\/train.csv'\ntest_filepath = '\/kaggle\/input\/commonlitreadabilityprize\/test.csv'\n\ntrain = pd.read_csv(train_filepath)\ntest = pd.read_csv(test_filepath)\n\nprint(f'Train samples: {len(train)}')\ndisplay(train.head())\n\nprint(f'Test samples: {len(test)}')\ndisplay(test.head())\n\n# removing unused columns\ntrain.drop(['url_legal', 'license'], axis=1, inplace=True)\ntest.drop(['url_legal', 'license'], axis=1, inplace=True)","727ab8e1":"BATCH_SIZE = 8 * REPLICAS\nLEARNING_RATE = 1e-5 * REPLICAS\nEPOCHS = 35\nES_PATIENCE = 7\nPATIENCE = 2\nN_FOLDS = 5\nSEQ_LEN = 256 #300\nBASE_MODEL = '\/kaggle\/input\/huggingface-roberta\/roberta-base\/'","aad575e7":"# Datasets utility functions\ndef custom_standardization(text):\n    text = text.lower() # if encoder is uncased\n    text = text.strip()\n    return text\n\n\ndef sample_target(features, target):\n    mean, stddev = target\n    sampled_target = tf.random.normal([], mean=tf.cast(mean, dtype=tf.float32), \n                                      stddev=tf.cast(stddev, dtype=tf.float32), dtype=tf.float32)\n    \n    return (features, sampled_target)\n    \n\ndef get_dataset(pandas_df, tokenizer, labeled=True, ordered=False, repeated=False, \n                is_sampled=False, batch_size=32, seq_len=128):\n    \"\"\"\n        Return a Tensorflow dataset ready for training or inference.\n    \"\"\"\n    text = [custom_standardization(text) for text in pandas_df['excerpt']]\n    \n    # Tokenize inputs\n    tokenized_inputs = tokenizer(text, max_length=seq_len, truncation=True, \n                                 padding='max_length', return_tensors='tf')\n    \n    if labeled:\n        dataset = tf.data.Dataset.from_tensor_slices(({'input_ids': tokenized_inputs['input_ids'], \n                                                      'attention_mask': tokenized_inputs['attention_mask']}, \n                                                      (pandas_df['target'], pandas_df['standard_error'])))\n        if is_sampled:\n            dataset = dataset.map(sample_target, num_parallel_calls=tf.data.AUTOTUNE)\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices({'input_ids': tokenized_inputs['input_ids'], \n                                                      'attention_mask': tokenized_inputs['attention_mask']})\n        \n    if repeated:\n        dataset = dataset.repeat()\n    if not ordered:\n        dataset = dataset.shuffle(1024)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset\n\n\ndef plot_metrics(history):\n    metric_list = list(history.keys())\n    size = len(metric_list)\/\/2\n    fig, axes = plt.subplots(size, 1, sharex='col', figsize=(20, size * 5))\n    axes = axes.flatten()\n    \n    for index in range(len(metric_list)\/\/2):\n        metric_name = metric_list[index]\n        val_metric_name = metric_list[index+size]\n        axes[index].plot(history[metric_name], label='Train %s' % metric_name)\n        axes[index].plot(history[val_metric_name], label='Validation %s' % metric_name)\n        axes[index].legend(loc='best', fontsize=16)\n        axes[index].set_title(metric_name)\n\n    plt.xlabel('Epochs', fontsize=16)\n    sns.despine()\n    plt.show()","26ec676b":"display(train.head())","dbaca641":"display(train.sort_values(by=['target']).head())","9a333527":"display(train.sort_values(by=['target'], ascending=False).head())","28aaa50b":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.distplot(train['target'], ax=ax)\nplt.show()","99557062":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.distplot(train['standard_error'], ax=ax)\nplt.show()","d3996b67":"print(f\"standard_error values >= than 0.4: {len(train[train['standard_error'] >= 0.4])}\")\nprint(f\"standard_error values < than 0.4: {len(train[train['standard_error'] < 0.4])}\")","d91a4265":"fig, ax = plt.subplots(1, 1, figsize=(10, 10))\nsns.scatterplot(x=train['target'], y=train['standard_error'], s=10, color=\".15\")\nsns.kdeplot(x=train['target'], y=train['standard_error'], levels=5, color=\"r\", linewidths=1)\nplt.ylim([0.4, None])\nplt.show()","77f281bd":"tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\ntrain['excerpt_len'] = train['excerpt'].apply(lambda x : len(x))\ntrain['excerpt_wordCnt'] = train['excerpt'].apply(lambda x : len(x.split(' ')))\ntrain['excerpt_tokenCnt'] = train['excerpt'].apply(lambda x : len(tokenizer.encode(x, add_special_tokens=False)))\n\nfig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.distplot(train['excerpt_len'], ax=ax).set_title('Excerpt length')\nplt.show()","78379487":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.distplot(train['excerpt_wordCnt'], ax=ax).set_title('Excerpt word count')\nplt.show()","f24be5ef":"fig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.distplot(train['excerpt_tokenCnt'], ax=ax).set_title('Excerpt token count')\nplt.show()","2e1c8dd1":"def model_fn(encoder, seq_len=256):\n    input_ids = L.Input(shape=(seq_len,), dtype=tf.int32, name='input_ids')\n    input_attention_mask = L.Input(shape=(seq_len,), dtype=tf.int32, name='attention_mask')\n    \n    outputs = encoder({'input_ids': input_ids, \n                       'attention_mask': input_attention_mask})\n    \n    model = Model(inputs=[input_ids, input_attention_mask], outputs=outputs)\n\n    optimizer = optimizers.Adam(lr=LEARNING_RATE)\n    model.compile(optimizer=optimizer, \n                  loss=losses.MeanSquaredError(), \n                  metrics=[metrics.RootMeanSquaredError()])\n    \n    return model\n\n\nwith strategy.scope():\n    encoder = TFAutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)\n    model = model_fn(encoder, SEQ_LEN)\n    \nmodel.summary()","92e901c3":"tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\nskf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\noof_pred = []; oof_labels = []; history_list = []; test_pred = []\n\nfor fold,(idxT, idxV) in enumerate(skf.split(train)):\n    if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    print(f'\\nFOLD: {fold+1}')\n    print(f'TRAIN: {len(idxT)} VALID: {len(idxV)}')\n\n    # Model\n    K.clear_session()\n    with strategy.scope():\n        encoder = TFAutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)\n        model = model_fn(encoder, SEQ_LEN)\n        \n    model_path = f'model_{fold}.h5'\n    es = EarlyStopping(monitor='val_root_mean_squared_error', mode='min', \n                       patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n    checkpoint = ModelCheckpoint(model_path, monitor='val_root_mean_squared_error', mode='min', \n                                 save_best_only=True, save_weights_only=True)\n\n    # Train\n    history = model.fit(x=get_dataset(train.loc[idxT], tokenizer, repeated=True, is_sampled=True, \n                                      batch_size=BATCH_SIZE, seq_len=SEQ_LEN), \n                        validation_data=get_dataset(train.loc[idxV], tokenizer, ordered=True, \n                                                    batch_size=BATCH_SIZE, seq_len=SEQ_LEN), \n                        steps_per_epoch=50, \n                        callbacks=[es, checkpoint], \n                        epochs=EPOCHS,  \n                        verbose=2).history\n      \n    history_list.append(history)\n    # Save last model weights\n    model.load_weights(model_path)\n    \n    # Results\n    print(f\"#### FOLD {fold+1} OOF RMSE = {np.min(history['val_root_mean_squared_error']):.4f}\")\n\n    # OOF predictions\n    valid_ds = get_dataset(train.loc[idxV], tokenizer, ordered=True, batch_size=BATCH_SIZE, seq_len=SEQ_LEN)\n    oof_labels.append([target[0].numpy() for sample, target in iter(valid_ds.unbatch())])\n    x_oof = valid_ds.map(lambda sample, target: sample)\n    oof_pred.append(model.predict(x_oof)['logits'])\n\n    # Test predictions\n    test_ds = get_dataset(test, tokenizer, labeled=False, ordered=True, batch_size=BATCH_SIZE, seq_len=SEQ_LEN)\n    x_test = test_ds.map(lambda sample: sample)\n    test_pred.append(model.predict(x_test)['logits'])","b031cdfd":"for fold, history in enumerate(history_list):\n    print(f'\\nFOLD: {fold+1}')\n    plot_metrics(history)","77b88c4e":"y_true = np.concatenate(oof_labels)\ny_preds = np.concatenate(oof_pred)\n\n\nfor fold, history in enumerate(history_list):\n    print(f\"FOLD {fold+1} RMSE: {np.min(history['val_root_mean_squared_error']):.4f}\")\n    \nprint(f'OOF RMSE: {mean_squared_error(y_true, y_preds, squared=False):.4f}')","6007ca88":"preds_df = pd.DataFrame({'Label': y_true, 'Prediction': y_preds[:,0]})\n\nfig, ax = plt.subplots(1, 1, figsize=(20, 6))\nsns.distplot(preds_df['Label'], ax=ax, label='Label')\nsns.distplot(preds_df['Prediction'], ax=ax, label='Prediction')\nax.legend()\nplt.show()","ffe35b27":"sns.jointplot(data=preds_df, x='Label', y='Prediction', kind='reg', height=10)\nplt.show()","2ea11420":"submission = test[['id']]\nsubmission['target'] = np.mean(test_pred, axis=0)\nsubmission.to_csv('submission.csv', index=False)\ndisplay(submission.head(10))","67e2335c":"## Model loss and metrics graph","a759b924":"<center><img src=\"https:\/\/github.com\/dimitreOliveira\/MachineLearning\/blob\/master\/Kaggle\/CommonLit%20Readability%20Prize\/banner.png?raw=true\" width=\"1000\"><\/center>\n<br>\n<center><h1>CommonLit Readability - EDA & RoBERTa TF baseline<\/h1><\/center>\n<br>","d21182c9":"### Now the examples with the 5 lowest `target` values","86c6a95c":"# Load data","a0f61ca4":"## `excerpt` text distribution\n\n### `excerpt` length","d960fdbf":"I would say that just by simply looking at those samples may be a little hard to decide the `target` score for them, but the samples with the lowest `target` score seems to have a mixture of grammatical, semantics, and punctuation error, that indeed would make them less easy to reading and understanding.","b604ef9e":"# Model","c2c7e21d":"# Test set predictions","9880b6af":"## Dependencies","1d5a3263":"## Auxiliary functions","0d995284":"# Model evaluation\n\nWe are evaluating the model on the `OOF` predictions, it stands for `Out Of Fold`, since we are training using `K-Fold` our model will see all the data, and the correct way to evaluate each fold is by looking at the predictions that are not from that fold.\n\n## OOF metrics","b6f3bf04":"The `standard_error` column seems to have some outliers with values lower than `0.4`.","1d58e4b2":"## Label distribution","9d4815d7":"The `target` column follows a distribution close to normal, but we can see that we have much more samples with the negative score than positive, also the negative values get close to `-4` while positive only go as high as `2`.","5256f834":"### Hardware configuration","1d5115cb":"# Training","85677dfa":"We can see that samples with extreme `target` values (closer to `-4` and `2`) usually have higher `standard_error`.","6d50795c":"# Model parameters","5ec1204e":"### **Error analysis**, label x prediction distribution\n\nHere we can compare the distribution from the labels and the predicted values, in a perfect scenario they should align.","26e629b3":"### `excerpt` token count (after using the tokenizer)","9893d065":"### `excerpt` word count","270b7e7c":"# EDA\n\n### Looking at a few examples","c310834b":"### Now the examples with the 5 highest `target` values"}}