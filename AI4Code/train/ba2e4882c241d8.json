{"cell_type":{"2a7114ea":"code","816aaab4":"code","9ad14dec":"code","b3541128":"code","f486bacc":"code","00f5c15c":"code","9504b4d0":"code","4246a2f6":"code","c0dca1cd":"code","12f507ef":"code","0b585811":"code","806df422":"code","56ef237c":"code","28157fe0":"code","c3d8355a":"code","bf5eb03a":"code","24ec2944":"code","a3cadad3":"code","3f567ab0":"code","7808d065":"code","bea19214":"code","d6eb3350":"code","a3635135":"code","fc8deeb7":"code","0253f9a4":"code","82c935a8":"code","066e1ce3":"code","15aa5dbf":"code","ec2a4f9f":"code","4980ea28":"code","1a4bbf85":"code","5cd7a987":"code","abfd82b9":"markdown","7d41512d":"markdown","d22c5bc4":"markdown","1845b529":"markdown","36bf64eb":"markdown","7fc6baaf":"markdown","07b52896":"markdown","9fd9b5ba":"markdown","6f8aade6":"markdown","b761920e":"markdown","70299c20":"markdown","2fa29bc3":"markdown","72d9ec11":"markdown","7d844f0d":"markdown","c11b36f2":"markdown","ad30fd46":"markdown","1f930959":"markdown","85fb3dc5":"markdown","bfec5745":"markdown","eea89cfe":"markdown","640f00e6":"markdown"},"source":{"2a7114ea":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTpnmOck-xZlKTvUcwp4rywVsgr34amgR_3AVCyLU3w7wRT7I-A',width=400,height=400)","816aaab4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\nimport cv2\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9ad14dec":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/www.mobihealthnews.com\/sites\/default\/files\/SPHCC%20and%20Yitu%20Healthcare%20AI%20software_Mobi.jpg',width=400,height=400)","b3541128":"with open('\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/biorxiv_medrxiv\/biorxiv_medrxiv\/07e833d0917cace550853f72923856d0fe1a7120.json', 'r') as f:\n    test = json.load(f)\ntest.keys()","f486bacc":"def affiliation_parsing(x: dict) -> str:\n    \"\"\"Parse affiliation into string.\"\"\"\n    current = []\n    for key in ['laboratory', 'institution']:\n        if x['affiliation'].get(key):  # could also use try, except\n            current.append(x['affiliation'][key])\n        else:\n            current.append('')\n    for key in ['addrLine', 'settlement', 'region', 'country', 'postCode']:\n        if x['affiliation'].get('location'):\n            if x['affiliation']['location'].get(key):\n                current.append(x['affiliation']['location'][key])\n        else:\n            current.append('')\n    return ', '.join(current)\n\nextract_key = lambda x, key: [[i[key] for i in x]]\nextract_func = lambda x, func: [[func(i) for i in x]]\nformat_authors = lambda x: f\"{x['first']} {x['last']}\"\nformat_full_authors = lambda x: f\"{x['first']} {''.join(x['middle'])} {x['last']} {x['suffix']}\"\nformat_abstract = lambda x: \"{}\\n{}\".format(x['section'], x['text'])\nall_keys = lambda x, key: [[i[key] for i in x.values()]]","00f5c15c":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/pbs.twimg.com\/media\/ESnTl26XkAY_RCj?format=jpg&name=small',width=400,height=400)","9504b4d0":"for path in ['biorxiv_medrxiv', 'comm_use_subset', 'noncomm_use_subset', 'pmc_custom_license']:\n    json_files = [file for file in os.listdir(f'\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/{path}\/{path}') if file.endswith('.json')]\n    df_list = []\n\n    for js in json_files:\n        with open(os.path.join(f'\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/{path}\/{path}', js)) as json_file:\n            paper = json.load(json_file)\n        paper_df = pd.DataFrame({\n            'paper_id': paper['paper_id'],\n            'title': paper['metadata']['title'],\n            'authors': extract_func(paper['metadata']['authors'], format_authors),\n            'full_authors': extract_func(paper['metadata']['authors'], format_full_authors),\n            'affiliations': extract_func(paper['metadata']['authors'], affiliation_parsing),\n            'emails': extract_key(paper['metadata']['authors'], 'email'),\n            'raw_authors': [paper['metadata']['authors']],\n            'abstract': extract_func(paper['abstract'], format_abstract),\n            'abstract_cite_spans': extract_key(paper['abstract'], 'cite_spans'),\n            'abstract_ref_spans': extract_key(paper['abstract'], 'ref_spans'),\n            'body': extract_func(paper['body_text'], format_abstract),\n            'body_cite_spans': extract_key(paper['body_text'], 'cite_spans'),\n            'body_ref_spans': extract_key(paper['body_text'], 'ref_spans'),\n            'bib_titles': all_keys(paper['bib_entries'], 'title'),\n            'raw_bib_entries': [paper['bib_entries']],\n            'ref_captions': all_keys(paper['ref_entries'], 'text'),\n            'raw_ref_entries': [paper['ref_entries']],\n            'back_matter': [paper['back_matter']]\n        })\n        df_list.append(paper_df)\n    temp_df = pd.concat(df_list)\n    temp_df.to_csv(f'\/kaggle\/working\/{path}.csv', index=False)","4246a2f6":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/healthmanagement.org\/uploads\/from_cloud\/cw\/00116374_cw_image_wi_4b727520e6ffc2fb5088f4be9576f7b9.jpg.pagespeed.ce.oZjkUhglUi.jpg',width=400,height=400)","c0dca1cd":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcS6kGQzHbJKLbb5ZLG1ezKfpmUlcfUFAlp0O-ARn9cYcyxAiN3F',width=400,height=400)","12f507ef":"df_list = []\nfor path in ['biorxiv_medrxiv', 'comm_use_subset', 'noncomm_use_subset', 'pmc_custom_license']:\n    temp_df = pd.read_csv(f'\/kaggle\/working\/{path}.csv')\n    temp_df['dataset'] = path\n    df_list.append(temp_df)\n    \naggregate_df = pd.concat(df_list)\naggregate_df.to_csv(f'\/kaggle\/working\/all_df.csv', index=False)","0b585811":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRGKG7NakimAmL2UNPbjwMiR6c0xBzMkgg4jnrG1WmCrBt4YdhZ',width=400,height=400)","806df422":"aggregate_df  # view the aggregated data","56ef237c":"aggregate_df.dtypes","28157fe0":"# Necessary Functions: \ndef pie_plot(labels, values, colors, title):\n    fig = {\n      \"data\": [\n        {\n          \"values\": values,\n          \"labels\": labels,\n          \"domain\": {\"x\": [0, .48]},\n          \"name\": \"Job Type\",\n          \"sort\": False,\n          \"marker\": {'colors': colors},\n          \"textinfo\":\"percent+label+value\",\n          \"textfont\": {'color': '#FFFFFF', 'size': 10},\n          \"hole\": .6,\n          \"type\": \"pie\"\n        } ],\n        \"layout\": {\n            \"title\":title,\n            \"annotations\": [\n                {\n                    \"font\": {\n                        \"size\": 25,\n\n                    },\n                    \"showarrow\": False,\n                    \"text\": \"\"\n\n                }\n            ]\n        }\n    }\n    return fig","c3d8355a":"from collections import Counter\nimport json\nfrom IPython.display import HTML\nimport altair as alt\nfrom  altair.vega import v5","bf5eb03a":"##-----------------------------------------------------------\n# This whole section \nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v5.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\n#------------------------------------------------ Defs for future rendering\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n\n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\n\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\")))","24ec2944":"def word_cloud(df, pixwidth=6000, pixheight=350, column=\"index\", counts=\"count\"):\n    data= [dict(name=\"dataset\", values=df.to_dict(orient=\"records\"))]\n    wordcloud = {\n        \"$schema\": \"https:\/\/vega.github.io\/schema\/vega\/v5.json\",\n        \"width\": pixwidth,\n        \"height\": pixheight,\n        \"padding\": 0,\n        \"title\": \"Hover to see number of occureances from all the sequences\",\n        \"data\": data\n    }\n    scale = dict(\n        name=\"color\",\n        type=\"ordinal\",\n        range=[\"cadetblue\", \"royalblue\", \"steelblue\", \"navy\", \"teal\"]\n    )\n    mark = {\n        \"type\":\"text\",\n        \"from\":dict(data=\"dataset\"),\n        \"encode\":dict(\n            enter=dict(\n                text=dict(field=column),\n                align=dict(value=\"center\"),\n                baseline=dict(value=\"alphabetic\"),\n                fill=dict(scale=\"color\", field=column),\n                tooltip=dict(signal=\"datum.count + ' occurrances'\")\n            )\n        ),\n            \"transform\": [{\n            \"type\": \"wordcloud\",\n            \"text\": dict(field=column),\n            \"size\": [pixwidth, pixheight],\n            \"font\": \"Helvetica Neue, Arial\",\n            \"fontSize\": dict(field=\"datum.{}\".format(counts)),\n            \"fontSizeRange\": [10, 60],\n            \"padding\": 2\n        }]\n    }\n    wordcloud[\"scales\"] = [scale]\n    wordcloud[\"marks\"] = [mark]\n    \n    return wordcloud\n\nfrom collections import defaultdict\n\ndef wordcloud_create(df):\n    ult = {}\n    corpus = aggregate_df.affiliations.values.tolist()\n    final = defaultdict(int) #Declaring an empty dictionary for count (Saves ram usage)\n    for words in corpus:\n        for word in words.split():\n             final[word]+=1\n    temp = Counter(final)\n    for k, v in  temp.most_common(200):\n        ult[k] = v\n    corpus = pd.Series(ult) #Creating a dataframe from the final default dict\n    return render(word_cloud(corpus.to_frame(name=\"count\").reset_index(), pixheight=600, pixwidth=900))","a3cadad3":"wordcloud_create(aggregate_df)","3f567ab0":"image = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/000_1ov3n5_0.jpeg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Create our shapening kernel, we don't normalize since the \n# the values in the matrix sum to 1\nkernel_sharpening = np.array([[-1,-1,-1], \n                              [-1,9,-1], \n                              [-1,-1,-1]])\n\n# applying different kernels to the input image\nsharpened = cv2.filter2D(image, -1, kernel_sharpening)\n\n\nplt.subplot(1, 2, 2)\nplt.title(\"Image Sharpening\")\nplt.imshow(sharpened)\n\nplt.show()","7808d065":"# Load our new image\nimage = cv2.imread('\/kaggle\/input\/\/medical-masks-dataset\/images\/003_1024.jpeg', 0)\n\nplt.figure(figsize=(30, 30))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Values below 127 goes to 0 (black, everything above goes to 255 (white)\nret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Threshold Binary\")\nplt.imshow(thresh1)\n\n# It's good practice to blur images as it removes noise\nimage = cv2.GaussianBlur(image, (3, 3), 0)\n\n# Using adaptiveThreshold\nthresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5) \n\nplt.subplot(3, 2, 3)\nplt.title(\"Adaptive Mean Thresholding\")\nplt.imshow(thresh)\n\n\n_, th2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\nplt.subplot(3, 2, 4)\nplt.title(\"Otsu's Thresholding\")\nplt.imshow(th2)\n\n\nplt.subplot(3, 2, 5)\n# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(image, (5,5), 0)\n_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.title(\"Guassian Otsu's Thresholding\")\nplt.imshow(th3)\nplt.show()","bea19214":"image = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/002_1024.jpeg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Let's define our kernel size\nkernel = np.ones((5,5), np.uint8)\n\n# Now we erode\nerosion = cv2.erode(image, kernel, iterations = 1)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Erosion\")\nplt.imshow(erosion)\n\n# \ndilation = cv2.dilate(image, kernel, iterations = 1)\nplt.subplot(3, 2, 3)\nplt.title(\"Dilation\")\nplt.imshow(dilation)\n\n\n# Opening - Good for removing noise\nopening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\nplt.subplot(3, 2, 4)\nplt.title(\"Opening\")\nplt.imshow(opening)\n\n# Closing - Good for removing noise\nclosing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\nplt.subplot(3, 2, 5)\nplt.title(\"Closing\")\nplt.imshow(closing)","d6eb3350":"# Let's load a simple image with 3 black squares\nimage = cv2.imread('\/kaggle\/input\/medical-masks-dataset\/images\/so(19).jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(2, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n\n# Grayscale\ngray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n\n# Find Canny edges\nedged = cv2.Canny(gray, 30, 200)\n\nplt.subplot(2, 2, 2)\nplt.title(\"Canny Edges\")\nplt.imshow(edged)\n\n# Finding Contours\n# Use a copy of your image e.g. edged.copy(), since findContours alters the image\ncontours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n\nplt.subplot(2, 2, 3)\nplt.title(\"Canny Edges After Contouring\")\nplt.imshow(edged)\n\nprint(\"Number of Contours found = \" + str(len(contours)))\n\n# Draw all contours\n# Use '-1' as the 3rd parameter to draw all\ncv2.drawContours(image, contours, -1, (0,255,0), 3)\n\nplt.subplot(2, 2, 4)\nplt.title(\"Contours\")\nplt.imshow(image)","a3635135":"import numpy as np\nimport pandas as pd \nimport cv2\nfrom fastai.vision import *\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport shutil\nfrom glob import glob\n%matplotlib inline\n!pip freeze > '..\/working\/dockerimage_snapshot.txt'","fc8deeb7":"def makeWordCloud(df,column,numWords):\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=numWords,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n\ndef plotImages(artist,directory):\n    print(artist)\n    multipleImages = glob(directory)\n    plt.rcParams['figure.figsize'] = (15, 15)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        im = cv2.resize(im, (128, 128)) \n        plt.subplot(5, 5, i_+1) #.set_title(l)\n        plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        i_ += 1\n\nnp.random.seed(7)","0253f9a4":"print(os.listdir(\"..\/input\/medical-masks-dataset\/images\/\"))","82c935a8":"img_dir='..\/input\/medical-masks-dataset\/images'\npath=Path(img_dir)\ndata = ImageDataBunch.from_folder(path, train=\".\", \n                                  valid_pct=0.2,\n                                  ds_tfms=get_transforms(do_flip=False,flip_vert=False, max_rotate=0,max_lighting=0.3),\n                                  size=299,bs=64, \n                                  num_workers=0).normalize(imagenet_stats)\nprint(f'Classes: \\n {data.classes}')\ndata.show_batch(rows=8, figsize=(40,40))","066e1ce3":"cnt_srs = aggregate_df['dataset'].value_counts().head()\ntrace = go.Bar(\n    y=cnt_srs.index[::-1],\n    x=cnt_srs.values[::-1],\n    orientation = 'h',\n    marker=dict(\n        color=cnt_srs.values[::-1],\n        colorscale = 'Blues',\n        reversescale = True\n    ),\n)\n\nlayout = dict(\n    title='Dataset distribution',\n    )\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"dataset\")","15aa5dbf":"cnt_srs = aggregate_df['abstract'].value_counts().head()\ntrace = go.Bar(\n    y=cnt_srs.index[::-1],\n    x=cnt_srs.values[::-1],\n    orientation = 'h',\n    marker=dict(\n        color=cnt_srs.values[::-1],\n        colorscale = 'Reds',\n        reversescale = True\n    ),\n)\n\nlayout = dict(\n    title='Abstracts distribution',\n    )\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"abstract\")","ec2a4f9f":"fig = px.pie( values=aggregate_df.groupby(['dataset']).size().values,names=aggregate_df.groupby(['dataset']).size().index)\nfig.update_layout(\n    title = \"dataset\",\n    font=dict(\n        family=\"Arial, monospace\",\n        size=15,\n        color=\"#7f7f7f\"\n    )\n    )   \n    \npy.iplot(fig)","4980ea28":"fig = px.histogram(aggregate_df[aggregate_df.dataset.notna()],x=\"dataset\",marginal=\"box\",nbins=10)\nfig.update_layout(\n    title = \"dataset\",\n    xaxis_title=\"dataset\",\n    yaxis_title=\"Number of datasets\",\n    barmode=\"group\",\n    bargap=0.1,\n    xaxis = dict(\n        tickmode = 'linear',\n        tick0 = 0,\n        dtick = 10),\n    font=dict(\n        family=\"Arial, monospace\",\n        size=15,\n        color=\"#7f7f7f\"\n    )\n    )\npy.iplot(fig)","1a4bbf85":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQ2WW7WwEFT0lnnLSu9j4XAGpgW7N-gYJODifJ02D0j6Q3z2MrK',width=400,height=400)","5cd7a987":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcT72jGRpDdXhCyNI7k28qbxadRkMeKMMC0-5wZjblpDj35loLuX',width=400,height=400)","abfd82b9":"#Codes from Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/collections-of-paintings-from-50-artists\/data","7d41512d":"Chest CT plays an important role in the diagnosis of patients with suspected coronavirus disease-19 (COVID-19) infection. In a new study, researchers from Icahn School of Medicine at Mount Sinai, New York, and their counterparts in China, reviewed chest CTs of 121 COVID-19 patients for common CT findings in relationship to the time between symptom onset and the initial CT scan.\n\nTheir findings show that a pattern of ground-glass and consolidative pulmonary opacities, often with a bilateral and peripheral lung distribution, is emerging as the chest CT hallmark of COVID-19 infection. Below the Axial CT Scan of the Lung\n\nhttps:\/\/healthmanagement.org\/c\/imaging\/news\/chest-ct-scans-probe-covid-19-symptoms","d22c5bc4":"#SPHCC and Yitu develop `AI-powered Intelligent Evaluation System` of Chest CT for COVID-19\n\nSince the outbreak of COVID-19 virus in China, Shanghai Public Health Clinical Center (SPHCC) has been actively mobilizing other parties to use the latest tech in the fight against the virus. Through the joint effort of SPHCC and Yitu Healthcare, a Shanghai-based AI startup, the Intelligent Evaluation System of Chest CT for COVID-19 was officially launched on 28 January. \n\nThe system utilizes intelligent diagnosis and quantitative evaluation of CT images of COVID-19 through industry-leading image algorithms, and grades the severity of various pneumonia diseases of local lesions, diffuse lesions, and whole lung involvement. \n\nIn addition, it accurately quantifies the cumulative pneumonia load of the disease through quantitative and omics analysis of key image features such as the morphology, range, and density of the lesion. The system can also render a dynamic 4D contrast of the whole lung lesions on CT, helping in clinical judgment of the condition, evaluation of the efficacy, and prediction of the prognosis. The system can complete a quantitative analysis of lung lesions in 2-3 seconds.\n\nAbove photo: A doctor in SPHCC using the Intelligent Evaluation System of Chest CT for COVID-19 for accurate diagnosis. Credit: Business Wire\n\nhttps:\/\/www.mobihealthnews.com\/news\/asia-pacific\/sphcc-and-yitu-develop-ai-powered-intelligent-evaluation-system-chest-ct-covid-19","1845b529":"#Codes from Anthony https:\/\/www.kaggle.com\/anthony358\/cord-19-simple-parsing-to-dataframes\/comments","36bf64eb":"linkresearcher.com - Coronavirus: definition of cure challenges doctors who discharge patients\n\nInfected persons discharged from hospitals are instructed to prolong isolation, and there have been cases where symptoms have reappeared.\nAmid announcements of \" cure \", \"discharge\" and \"recovery\", however, doctors warn that these words leave room for doubt .- The science of the new coronavirus is only ten weeks old, and a range of knowledge has not yet been built to assert assertively what healing means.\n\nAs a rule, doctors have dismissed patients when they stop showing a series of symptoms, but continue to follow them from a distance. The \"discharge\", technically, occurs after an extra period of observation for another 14 days, in addition to the two weeks of quarantine .\n\nThe most important criterion for dismissal is generic: it is the conviction by the clinical evaluation that the disease has stopped progressing, mainly in the respiratory part - explains Luis Fernando Aranha Camargo, doctor who treats patients with Covid-19 at Hospital Israelita Albert Einstein , an institution that received 98 patients with a confirmed diagnosis of virus infection.\n When the patient stops having a fever and has no evidence of progression in the respiratory condition, it is time to go home and follow up there - he says.\n \n The criterion for considering patients able to return to normal life is purely clinical, since laboratory tests (the PCR, which detects genetic material from the virus) are still expensive and in limited stock.\n \n  Only patients recruited for scientific studies are being submitted to PCR again - says Naime. - Especially because we still don't know if the negative result for PCR means the cure of the disease, effectively.\n  One of the concerns expressed by doctors is that there are already informal reports of patients who are discharged without symptoms and then present them again.\n  Few specialists hope, however, that previous coronavirus infection will generate lasting immunity, which will protect the person from reinfection indefinitely.https:\/\/oglobo.globo.com\/sociedade\/coronavirus-servico\/coronavirus-definicao-de-cura-desafia-medicos-que-concedem-alta-pacientes-24304792","7fc6baaf":"Define utilities for parsing the data","07b52896":"#Seven measures that made Singapore an example in the fight against the disease:\n\nONE OF THE BEST HEALTH SYSTEMS IN THE WORLD \n\nSingapore was named by the Bloomberg Health-Efficiency Index as the 2nd most efficient healthcare system in the world. In 2000, WHO listed the city-state as the 6th best health in the world.\n\nTHERMOMETERS, MANY THERMOMETERS \n\nAirports and tourist attractions have cameras sensitive to body heat. Schools, restaurants and residential buildings measure the temperature of all entrants.\n\nBORDER CONTROL \n\nTravelers who have been in China, South Korea, Iran and, most recently, Italy, France, Germany and Spain for the past 14 days are prohibited from entering the country.\n\nSMALL DIMENSIONS \n\nA city-state of only 5.6 million: the government has a very small area of \u200b\u200bactivity.\n\nNO CROWDS \n\nThe government discourages crowds, especially religious agglomerations, one of the major sources of recent contagion in Asia. Mosques are closed after a post-cult outbreak in Malaysia, and Catholic churches follow the guidance to avoid crowds.\nhttps:\/\/oglobo.globo.com\/sociedade\/coronavirus-sete-medidas-que-tornaram-cingapura-exemplo-na-luta-contra-doenca-1-24314038","9fd9b5ba":"#Codes from Anthony https:\/\/www.kaggle.com\/anthony358\/cord-19-simple-parsing-to-dataframes\/comments\n#codes from Shivam Ralli @hoshi7\n#codes from Paul Mooney @paultimothymooney \n#codes from Helder Peixoto","6f8aade6":"#Artificial Intelligence Identifies High-Risk COVID-19 Patients\n\nMarch 16, 2020 - Medical Home Network, an organization serving patients in the Chicago area, is using artificial intelligence to identify individuals who have a heightened vulnerability to severe complications from COVID-19.\n\nFor Medicaid beneficiaries who face challenges such as homelessness or lack of transportation access, it can be difficult to take measures to protect against or receive treatment for COVID-19. Medical Home Network is leveraging an AI-based predictive analytics model to prioritize care management outreach to patients most at risk from the virus.https:\/\/healthitanalytics.com\/news\/artificial-intelligence-identifies-high-risk-covid-19-patients\n\n\nCOVID-19 and the Risk to Health Care Workers: A Case Report https:\/\/annals.org\/aim\/fullarticle\/2763329\/covid-19-risk-health-care-workers-case-report\n\nNew analysis breaks down age-group risk for coronavirus \u2014 and shows millennials are not invincible https:\/\/www.statnews.com\/2020\/03\/18\/coronavirus-new-age-analysis-of-risk-confirms-young-adults-not-invincible\/\nThat approach is interesting since data shows that seniors are the most vulnerable. The CDC (Centers for Disease Control and Prevention) data highlights that the young are not immune to getting seriously ill, with 38 percent of hospitalized patients between the ages of 20 and 54.\n\nRisk Factors for Death From COVID-19 Identified in Wuhan Patients\nPatients who did not survive hospitalization for COVID-19 in Wuhan were more likely to be older, have comorbidities, and elevated D-dimer, according to the first study to examine risk factors associated with death among adults hospitalized with COVID-19. https:\/\/www.medscape.com\/viewarticle\/926504\n\nOlder age, high Sequential Organ Failure Assessment (SOFA) score, and blood d-dimer levels >1 \u03bcg\/mL on admission are significant early stage risk factors for poor prognosis and in-hospital mortality in patients with COVID-19, according to study findings published in The Lancet.\nApproximately 48% (n=91) patients in the overall cohort had a comorbidity. The most common comorbidities in this patient population were hypertension (30%), diabetes (19%), and coronary heart disease (8%).https:\/\/www.pulmonologyadvisor.com\/home\/topics\/lung-infection\/covid-19-risk-factors-identified-for-poor-prognosis-in-hospital-mortality\/\n\nZhou F, Yu T, Du R, et al. Clinical course and risk factors for mortality of adult inpatients with COVID-19 in Wuhan, China: a retrospective cohort study [published online March 11, 2020]. Lancet. doi:10.1016\/S0140-6736(20)30566-3\n","b761920e":"Chest CT scan - apkpure.com","70299c20":"#codes from Shivam Ralli @hoshi7","2fa29bc3":"#Correlation of Chest CT and RT-PCR Testing in Coronavirus Disease 2019 (COVID-19) in China: A Report of 1014 Cases\n\n#Tao Ai*, Zhenlu Yang*, Hongyan Hou, Chenao Zhan, Chong Chen, Wenzhi Lv, Qian Tao, Ziyong Sun, Liming Xia, \nTao Ai and Zhenlu Yang contributed equally to this work.\n\nPublished Online:Feb 26 2020https:\/\/doi.org\/10.1148\/radiol.2020200642\n\nSince December 2019, a number of cases of \u201cunknown viral pneumonia\u201d related to a local Seafood Wholesale Market were reported in Wuhan City, Hubei Province, China (1). A novel coronavirus (SARS-CoV-2) was suspected to be the etiology with Phinolophus bat as the alleged origin.\n\nIn absence of specific therapeutic drugs or vaccines for 2019 novel coronavirus disease (COVID-19), it is essential to detect the diseases at an early stage, and immediately isolate the infected person from the healthy population. According to the latest `guideline of Diagnosis and Treatment of Pneumonitis Caused by 2019-nCoV` (trial sixth version) published by the China government, the diagnosis of COVID-19 must be confirmed by the reverse transcription polymerase chain reaction (RT-PCR) or gene sequencing for respiratory or blood specimens, as the key indicator for hospitalization. However, with limitations of sample collection and transportation, and kit performance, the total positive rate of RT-PCR for throat swab samples was reported to be about 30% to 60% at initial presentation . In the current emergency, the low sensitivity of RT-PCR implies that many COVID-19 `patients may not be identified` and may not receive appropriate treatment in time; such patients constitute a risk for infecting a larger population given the highly contagious nature of the virus. `Chest CT, as a routine imaging tool for pneumonia diagnosis`, is relatively easy to perform and can produce fast diagnosis. In this context, chest CT may provide benefit for diagnosis of COVID-19. As recently reported, chest CT demonstrates typical radiographic features in almost all COVID-19 patients, including ground-glass 4 opacities, multifocal patchy consolidation, and\/or interstitial changes with a peripheral distribution. Those typical features were also observed in patients with negative RT-PCR results but clinical symptoms. It has been noted in small-scale studies that the current RT-PCR testing has limited sensitivity, while chest CT may reveal pulmonary abnormalities consistent with COVID-19 in patients with initial negative RT-PCR results.\nTo better understand the diagnostic value of chest CT compared with RT-PCR testing, they report the results of chest CT in comparison to the initial and serial RT-PCR results in 1014 patients with suspected COVID-19.\n\nIn conclusion, chest CT imaging has high sensitivity for diagnosis of COVID-19. Our data and analysis suggest that chest CT should be considered for the COVID-19 screening, comprehensive evaluation, and following-up, especially in epidemic areas with high pre-test probability for disease.\nhttps:\/\/pubs.rsna.org\/doi\/10.1148\/radiol.2020200642","72d9ec11":"youtube.com","7d844f0d":"#Health Promotion\n\nNow that COVID-19 has been declared a global pandemic the All of Government (AoG) response has kicked in to centralise the public information work. This means the focus is not just on health, but on all areas eg, border, economics and gatherings, etc. \n\nLooking after your mental health during the COVID-19 pandemic\n\nFor children and young people:\nHave open and honest conversations\nRelay the facts, in a way that is appropriate for their age and temperament. \nListen to their questions.\nLet them know that they are okay and it\u2019s normal to feel concerned.\n\nFor older parents, grandparents or friends:\nCheck in on them and stay in touch.\nHelp them with their physical and medical needs, if they need it, (with consideration to the latest advice from Health authorities)\n\nPlanning for self-isolation:\nMake sure your wider health needs are being looked after such as having enough prescription medicines available to you.\n\nIf you are in self-isolation:\nDevelop a routine that suits you. Think about your needs such as meals, exercise, sleep, medication and how you will organise your day and home to create your new routine. Writing it out can help.\nIf you are well enough, find activities to keep your mind and body stimulated, including getting creative, exercising in your home, or self-care.\nConnect with your friends and family via phone, email or social media\nStay informed with good quality factual information from credible sources (see above) but also switch off and watch favourite TV\/films\/reading books.\nDon\u2019t be afraid to rely on others to deliver medication, food or essential supplies to you to comply with your self-isolation requirements. Remember that you are helping others and potentially saving lives.\n\nA huge thanks who have shared the initial messaging that got people washing their hands with soap and water often and using cough and sneeze etiquette. Messaging has expanded to include self-isolation, staying home if you\u2019re sick, and being kind to others through this. Together we can slow the spread.\n\nhttps:\/\/www.mhc.wa.gov.au\/about-us\/news-and-media\/news-updates\/looking-after-your-mental-health-during-the-covid-19-pandemic\/\n","c11b36f2":"OTHER DEVELOPMENTS IN CHINA TO COMBAT THE SPREAD OF COVID-19\n\nSPHCC also worked with VivaLNK, a Santa Clara, California-based connected health startup, to use the latter\u2019s continuous temperature sensor to combat the spread of coronavirus in China, MobiHealthNews reported.\n\nIn mid-February, the Chinese government released a public app to gauge potential coronavirus exposures \u2013 the tool acts as a way to collect data as well as to educate citizens on what to do if they have been in close contact with the virus \u2014 which is to stay at home and get advice from health authorities.\n\nBaidu, a Chinese multinational tech company, made its online doctor consultation platform publicly free for users that want to consult with a doctor about COVID-19. According to the company, the platform has so far handled (as of 11 Feb) over 4.2 million inquiries from users about COVID-19 with over 300,000 inquires per day. \nhttps:\/\/www.mobihealthnews.com\/news\/asia-pacific\/sphcc-and-yitu-develop-ai-powered-intelligent-evaluation-system-chest-ct-covid-19","ad30fd46":"#Codes from Bulent Siyah https:\/\/www.kaggle.com\/bulentsiyah\/learn-opencv-by-examples-with-python","1f930959":"rebelem.com - Emergency Medicine blog. \n\nNone of our current dx tools are great\nRT-PCR assay has long turnaround time (currently 1 \u2013 7d)\nAvailability (we simply don\u2019t have enough tests to test everyone)\nThis (figure above)seems to be what makes the most sense","85fb3dc5":"Create stacked dataframe","bfec5745":"Parse all jsons into dataframes","eea89cfe":"#Health for all and all for health","640f00e6":"Kaggle Notebook Runner: Mar\u00edlia Prata @mpwolke"}}