{"cell_type":{"85d9175f":"code","fdc4d833":"code","970d082c":"code","2de0ae46":"code","31be2230":"code","1d177043":"code","7a953a77":"code","7b138f4c":"code","c37db28e":"code","77636711":"code","c46b992c":"code","01d04079":"code","725996c8":"code","ef3cf586":"code","6700f75a":"code","080fa689":"code","17cde1e4":"code","13efe5c1":"code","ba8ff49e":"code","e5c8df9a":"code","cdb2a598":"code","04795559":"code","04c8577c":"code","544d00cc":"code","dddb47f7":"code","71d49f5e":"code","631a527d":"code","94ee3b7c":"code","0184c647":"code","11128c71":"code","2e0cc9cb":"code","695deab7":"code","9df2a547":"code","2de9ab36":"code","ce5b56fb":"code","d719aa64":"code","2f6eb918":"code","b9860d3e":"code","4c52d73b":"code","6c3dc38d":"code","b44f16ed":"code","acf54385":"code","5c919a3a":"code","482c7d5d":"code","af62cc0c":"code","edf8b725":"code","cc8e2c39":"code","cd4e1b65":"code","cb6d5655":"code","c6105466":"code","35b9960d":"code","9fd8f0e9":"code","616d11b1":"code","610a251e":"code","73fa7331":"code","e136158f":"code","a8c8c93f":"code","535bdef0":"code","f85f147d":"code","8d1f7555":"code","cb66115a":"code","f41f477e":"code","26c5a487":"code","eea53960":"code","b634603e":"code","1553eb94":"code","ed3ff9dd":"code","302e7430":"code","086e1a38":"code","eb45bc0e":"code","b5e9a432":"code","13e067ad":"markdown"},"source":{"85d9175f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","fdc4d833":"train_data = pd.read_csv(\"..\/input\/learn-together\/train.csv\", index_col='Id')\ntrain_data.sample(5)","970d082c":"test_data = pd.read_csv(\"..\/input\/learn-together\/test.csv\", index_col='Id')\ntest_data.shape","2de0ae46":"soils = [\n    [7, 15, 8, 14, 16, 17,\n     19, 20, 21, 23], \n    [3, 4, 5, 10, 11, 13],   \n    [6, 12],   \n    [2, 9, 18, 26],      \n    [1, 24, 25, 27, 28, 29, 30,\n     31, 32, 33, 34, 36, 37, 38, \n     39, 40, 22, 35], ]","31be2230":"soil_dict = dict()\nfor index, values in enumerate(soils):\n    for v in values:\n        soil_dict[v] = index","1d177043":"family= [[1], [2,6,7, 8, 9, 15, 26], [3, 4, 5], [10, 11, 13], [12],[14], \n         [16, 17, 19], [18], [20, 21, 23], [22, 24, 25, 27, 28, 31, 38], \n         [29, 30], [32, 33], [34, 39, 40], [35, 36, 37]]","7a953a77":"family_dict = dict()\nfor index, values in enumerate(family):\n    for v in values:\n        family_dict[v] = index","7b138f4c":"def family(df, family_dict=family_dict):\n    df['family'] =  sum(i * df['Soil_Type'+ str(i)] for i in range(1, 41))\n    df['family'] = df['family'].map(family_dict) \n    df['Rocky'] =  sum(i * df['Soil_Type'+ str(i)] for i in range(1, 41))\n    df['Rocky'] = df['Rocky'].map(soil_dict) \n    return df\n","c37db28e":"train = family(train_data)","77636711":"test= family(test_data)","c46b992c":"test.shape","01d04079":"train.shape","725996c8":"train.columns","ef3cf586":"def interaction(series1, series2):\n    interactions = (series1).astype(str) + \"_\" + series2.astype(str)\n    labels, uniques = pd.factorize(interactions)\n    return labels\n    ","6700f75a":"\ny= train['Cover_Type']\ntrain= train.drop(['Cover_Type'], axis= 1)","080fa689":"total= pd.concat([train, test], keys= ['train', 'test'])","17cde1e4":"total['aspect_slope']= interaction(total.Aspect, total.Slope)","13efe5c1":"total['horizontal_vertical']= interaction(total['Horizontal_Distance_To_Hydrology'], total['Vertical_Distance_To_Hydrology'])","ba8ff49e":"total['hydrology_fire']= interaction(total['Horizontal_Distance_To_Hydrology'], total['Horizontal_Distance_To_Fire_Points'])","e5c8df9a":"total['9am_Noon']= interaction(total['Hillshade_9am'], total['Hillshade_Noon'])","cdb2a598":"total['3pm_Noon']= interaction(total['Hillshade_3pm'], total['Hillshade_Noon'])","04795559":"total['9am_3pm']= interaction(total['Hillshade_9am'], total['Hillshade_3pm'])","04c8577c":"listk= ['Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n       'Horizontal_Distance_To_Fire_Points']","544d00cc":"from sklearn.preprocessing import LabelEncoder","dddb47f7":"for col in listk:\n    label_enc = LabelEncoder()\n    total[col+'new'] = label_enc.fit_transform(total[col].astype(str))","71d49f5e":"#total['elevationbin']= pd.cut(total['Elevation'], 8)","631a527d":"train= total.loc['train']","94ee3b7c":"test= total.loc['test']","0184c647":"test.shape","11128c71":"train.shape","2e0cc9cb":"#def number(df):\n    #for col in listk:\n        #label_enc = LabelEncoder()\n        #df[col+'new'] = label_enc.fit_transform(df[col].astype(str))\n        \n        #return df\n    \n    ","695deab7":"#train= number(train)","9df2a547":"#test= number(test)","2de9ab36":"#test","ce5b56fb":"train.columns","d719aa64":"from sklearn.model_selection import train_test_split\n#from sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score","2f6eb918":"#train= train.fillna(method= 'ffill')","b9860d3e":"train.isnull().sum()[train.isnull().sum() > 0]","4c52d73b":"import matplotlib.pyplot as plt","6c3dc38d":"\nplt.hist('Horizontal_Distance_To_Roadways', data= train)\nplt.show()\n","b44f16ed":"plt.hist('Horizontal_Distance_To_Roadways', data= test)\nplt.show()","acf54385":"X_train, X_test, y_train, y_test = train_test_split(train, y, test_size = 0.2, random_state = 21)","5c919a3a":"classifier = RandomForestClassifier(max_depth=3, n_estimators=650)\nclassifier.fit(X_train, y_train)","482c7d5d":"import eli5\nfrom eli5.sklearn import PermutationImportance\n","af62cc0c":"perm = PermutationImportance(classifier, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","edf8b725":"from sklearn.metrics import f1_score\ny_pred = classifier.predict(X_test)\nf1_score(y_test, y_pred, average='macro')  \n\nf1_score(y_test, y_pred, average='micro')  \n\nf1_score(y_test, y_pred, average='weighted')  \n\nf1_score(y_test, y_pred, average=None)\n","cc8e2c39":"plt.hist('Elevation', data= train)\nplt.show()","cd4e1b65":"plt.hist('Elevation', data= test)\nplt.show()","cb6d5655":"total['elevationbin']= pd.cut(total['Elevation'], 8, labels= ['best', 'very good', 'good', 'not good', 'medium', 'bad', 'very bad', 'worst'])\n\n","c6105466":"label_enc = LabelEncoder()\ntotal['elevationnumber'] = label_enc.fit_transform(total['elevationbin'])","35b9960d":"pd.get_dummies(train, prefix_sep='_', drop_first=True)","9fd8f0e9":"train= total.loc['train']\ntest= total.loc['test']","616d11b1":"train= pd.get_dummies(train, prefix_sep='_', drop_first=True)","610a251e":"test= pd.get_dummies(test, prefix_sep='_', drop_first=True)","73fa7331":"train.head()","e136158f":"X_train, X_test, y_train, y_test = train_test_split(train, y, test_size = 0.2, random_state = 21)","a8c8c93f":"classifier = RandomForestClassifier(max_depth=None, n_estimators=1000, min_samples_split=2, max_features=\"sqrt\", n_jobs=-1)\nclassifier.fit(X_train, y_train)","535bdef0":"perm = PermutationImportance(classifier, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","f85f147d":"from sklearn.metrics import f1_score\ny_pred = classifier.predict(X_test)\nf1_score(y_test, y_pred, average='macro')  \n\nf1_score(y_test, y_pred, average='micro')  \n\nf1_score(y_test, y_pred, average='weighted')  \n\nf1_score(y_test, y_pred, average=None)\n","8d1f7555":"from sklearn import model_selection \nfrom sklearn.ensemble import BaggingClassifier \nfrom sklearn.tree import DecisionTreeClassifier ","cb66115a":"kfold = model_selection.KFold(n_splits = 3, \n                       random_state = 10) \n  \n# initialize the base classifier \nbase_cls = DecisionTreeClassifier() \n  \n# no. of base classifier \nnum_trees = 500\n  \n# bagging classifier \nmodel = BaggingClassifier(base_estimator = base_cls, n_estimators = num_trees, \n                                      random_state = 10) \n  \nresults = model_selection.cross_val_score(model, X_train, y_train, cv = kfold) \nprint(\"accuracy :\") \nprint(results.mean()) ","f41f477e":"from sklearn.metrics import f1_score\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nf1_score(y_test, y_pred, average='macro')  \n\nf1_score(y_test, y_pred, average='micro')  \n\nf1_score(y_test, y_pred, average='weighted')  \n\nf1_score(y_test, y_pred, average=None)","26c5a487":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier","eea53960":"from sklearn.model_selection import cross_val_score","b634603e":"from sklearn.neighbors import KNeighborsClassifier","1553eb94":"clf1 = DecisionTreeClassifier()\nclf2 = RandomForestClassifier(max_depth=None, n_estimators=1000, min_samples_split=2, max_features=\"sqrt\", n_jobs=-1)\n\n\neclf = VotingClassifier(estimators=[('dt', clf1), ('rf', clf2)], voting='soft', weights=[1, 2])\n\nfor clf, label in zip([clf1, clf2, eclf], ['decision tree', 'Random Forest', 'Ensemble']):\n    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+\/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n","ed3ff9dd":"eclf.fit(X_train, y_train)\ny_pred = eclf.predict(X_test)\nf1_score(y_test, y_pred, average='macro')  \n\nf1_score(y_test, y_pred, average='micro')  \n\nf1_score(y_test, y_pred, average='weighted')  \n\nf1_score(y_test, y_pred, average=None)","302e7430":"classifier = RandomForestClassifier(max_depth=None, n_estimators=1000, min_samples_split=2, max_features=\"sqrt\", n_jobs=-1)\nclassifier.fit(train, y)","086e1a38":"rfc_predict = classifier.predict(test)","eb45bc0e":"submission= pd.read_csv('..\/input\/learn-together\/sample_submission.csv', index_col= 'Id')\nsubmission['Cover_Type']= list(rfc_predict)\nsubmission['Cover_Type'].value_counts()","b5e9a432":"submission.to_csv('submission.csv')","13e067ad":"Finding important variables using permutation method."}}