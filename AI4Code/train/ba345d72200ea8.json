{"cell_type":{"7cdf31c2":"code","08a8e15b":"code","cb726b5d":"code","cd9d7bc8":"code","c164c525":"code","9fc253b6":"code","27a90125":"code","b31d69c9":"code","20afe617":"code","2406d1a4":"code","ac8c7eaa":"code","bae56fe6":"code","10546a36":"code","9da58a50":"code","43a35167":"code","2e441821":"code","751296c0":"code","63bac7c2":"code","99903e55":"code","31136d05":"code","aac13567":"code","774a14ee":"code","4fbac750":"code","09a1cdea":"code","c12a7b52":"code","46e1b1ea":"code","47f8c32c":"code","33b78c9c":"code","cd47ddfe":"code","aa6535ff":"code","0eaa1437":"code","bd2d013f":"code","02fc2910":"code","5278d8ea":"code","94cab071":"code","ad238e60":"code","f78f9ec9":"code","54e3667d":"code","eda15a5f":"code","ee06166d":"code","5662c146":"code","97c2a66f":"code","08d21ada":"code","43dded5f":"code","a2c746a8":"code","139708db":"code","2f6fb048":"code","9bdc2b33":"code","f336ede5":"code","5b6cf9b7":"code","63b0dfa2":"code","09eb0177":"code","17bd3443":"code","7cbfdc53":"code","0f90d125":"code","ecde932d":"code","f1fddbda":"code","f1d1c3c5":"code","c2879e5f":"code","5b0cbe24":"code","1636a863":"markdown","60cf1086":"markdown","f0d39085":"markdown","cb47b01c":"markdown","7c332311":"markdown","7bb41dee":"markdown","42784c37":"markdown","bba0c48b":"markdown","3d2e942e":"markdown","e532262f":"markdown","6bd4f8f6":"markdown","0d101a1b":"markdown","454b6a89":"markdown","fa7ddd72":"markdown","8ed4051b":"markdown","70f2209e":"markdown","2f832499":"markdown"},"source":{"7cdf31c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","08a8e15b":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport PIL\nimport pathlib\nimport cv2\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob\nimport csv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","cb726b5d":"print(tf.__version__)","cd9d7bc8":"#path_data = '..\/input\/brain-mri-images-for-brain-tumor-detection\/brain_tumor_dataset'\npath_test = '..\/input\/brain-tumor-classification-mri\/Testing'\npath_data = '..\/input\/brain-tumor-classification-mri\/Training'\n\n\npath_test = pathlib.Path(path_test)\npath_data = pathlib.Path(path_data)\nprint(path_data)\n\nimage_count = len(list(path_data.glob('*\/*.jpg')))\nprint(image_count)\ntest_image_count = len(list(path_test.glob('*\/*.jpg')))\nprint(test_image_count)","c164c525":"tumors = list(path_data.glob('glioma_tumor\/*'))\nprint(tumors[1])\nimg1 = PIL.Image.open(str(tumors[0]))\nimg1","9fc253b6":"not_tumors = list(path_data.glob('no_tumor\/*'))\nimg2 = PIL.Image.open(str(not_tumors[0]))\nimg2","27a90125":"img_opencv = cv2.imread(str(not_tumors[0]))\nprint(img_opencv.shape)\nimg_opencv1 = cv2.imread(str(tumors[0]))\nprint(img_opencv1.shape)","b31d69c9":"batch = 12\nimg_height = 250\nimg_width = 250","20afe617":"train = tf.keras.preprocessing.image_dataset_from_directory(\npath_data,\nvalidation_split = 0.2,\nsubset = 'training',\nseed = 42,\nimage_size  =(img_height,img_width),\nbatch_size = batch)","2406d1a4":"val = tf.keras.preprocessing.image_dataset_from_directory(\npath_data,\nvalidation_split = 0.2,\nsubset = 'validation',\nseed = 42,\nimage_size = (img_height,img_width),\nbatch_size = batch)","ac8c7eaa":"test = tf.keras.preprocessing.image_dataset_from_directory(\npath_test,\nseed = 42,\nimage_size = (img_height,img_width),\nbatch_size = batch)","bae56fe6":"print(train.class_names)\nprint(val.class_names)\nprint(test.class_names)","10546a36":"classes = train.class_names\nplt.figure(figsize = (10,10))\nfor img,label in train.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(img[i].numpy().astype(\"uint8\"))\n        plt.title(classes[label[i]],\n                  fontdict = {'fontsize': '19',\n                              'color': 'white'}\n                 )\n        ","9da58a50":"for image_batch, labels_batch in train:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","43a35167":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain = train.prefetch(buffer_size=AUTOTUNE)\nval = val.prefetch(buffer_size=AUTOTUNE)\ntest = test.prefetch(buffer_size=AUTOTUNE)","2e441821":"help(test.as_numpy_iterator())","751296c0":"def prediction_label_comparison(model,test):\n    #Retrieve a batch of images from the test set\n    image_batch, label_batch = test.as_numpy_iterator().next()\n    prediction = model.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        predict.append(pred)\n    predict = np.array(predict)\n\n    #print('Predictions:\\n',predictions)#.numpy())\n    print('Labels:\\n', label_batch)\n    print('Predictions:\\n',predict)\n    '''\n    print(predictions.shape)\n    print(label_batch.shape)\n    print(predict.shape)\n    '''\n\n    plt.figure(figsize=(10, 10))\n    for i in range(9):\n      ax = plt.subplot(3, 3, i + 1)\n      plt.imshow(image_batch[i].astype(\"uint8\"))\n      plt.title(classes[predict[i]],fontdict = {'fontsize': '14',\n                                  'color': 'white'})\n      plt.axis(\"off\")\n    return label_batch , predict","63bac7c2":"def test_tumor(list_test_path,model):\n    # sunflower_url = 'https:\/\/'\n    # sunflower_path = tf.keras.utils.get_file('name of file', origin=sunflower_url)\n    for path_name in list_test_path:\n        test_img_path = path_name\n\n\n        test_image = tf.keras.preprocessing.image.load_img(\n            test_img_path, target_size=(img_height, img_width)\n        )\n        test_array = tf.keras.preprocessing.image.img_to_array(test_image)\n        test_array = tf.expand_dims(test_array, 0) # Create a batch\n\n        predictions = model.predict(test_array)\n        score = tf.nn.softmax(predictions[0])\n\n        print(\n            \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n            .format(classes[np.argmax(score)], 100 * np.max(score))\n        )","99903e55":"def csv_builder(path_data,label_names):\n    df = pd.DataFrame(columns = ['images','labels'])\n    for name in label_names:\n        BASE_DIR = str(path_data)+'\/'\n        #train_folder_glioma = BASE_DIR+'glioma_tumor\/'\n        train_folder_name = BASE_DIR+name+'\/'\n\n        #train_annotation = BASE_DIR+'annotated_train_data\/'\n\n        files_in_train = sorted(os.listdir(train_folder_name))\n        #files_in_annotated = sorted(os.listdir(train_annotation))\n\n        image_names =[i for i in files_in_train]\n\n        \n        for x in image_names:\n            df = df.append({'images':train_folder_name+str(x),'labels':name},ignore_index=True)\n            #df = df.append({'images':str(x),'labels':name},ignore_index=True)\n\n        #df['images']=[train_folder_glioma+str(x) for x in image_names]\n        #df['labels']=[train_annotation+str(x) for x in images]\n        #pd.to_csv('files_path.csv', header=None)\n    return df","31136d05":"def model_inputs(model2,train,val,test):\n    num_classes = 4\n    epochs = 50\n    model2.fit(\n        train,\n        validation_data=val,\n        epochs=epochs,\n        #callbacks = callback,\n        shuffle=False,\n        verbose = 0\n    )\n    results = model2.evaluate(test)\n    return results[0],results[1] , model","aac13567":"def cross_validation(n_splits,final_csv,test_csv,img_width,img_height,model):\n    final_loss = 0\n    final_acc = 0\n\n    '''\n    Seperating a dataframe for testing data\n    '''\n    ##\n    final_csv = final_csv.sample(frac=1)\n    ##\n    Y = final_csv[['labels']]\n    n = len(Y)\n    kf = KFold(n_splits = 5)\n    #skf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True) \n    idg = ImageDataGenerator(#width_shift_range=0.1,\n#                          height_shift_range=0.1,\n#                          zoom_range=0.3,\n#                          fill_mode='nearest',\n#                          horizontal_flip = True,\n                         rescale=1.\/255)\n    \n    \n    \n    \n    print('Performing cross validation...')\n    test = idg.flow_from_dataframe(test_csv,\n                                       x_col = \"images\",\n                                       y_col = \"labels\",\n                                       class_mode = \"sparse\",\n                                       shuffle = True,\n                                      target_size = (img_width,img_height),\n                                      verbose = 0)#,subset='validation')\n#     test = tf.keras.preprocessing.image_dataset_from_directory(path_test,\n#                                                                    seed = 42,\n#                                                                    image_size = (img_height,img_width),\n#                                                                    batch_size = 32)\n\n    for train_index, val_index in kf.split(np.zeros(n),Y):\n        training_data = final_csv.iloc[train_index]\n        validation_data = final_csv.iloc[val_index]\n        train = idg.flow_from_dataframe(training_data,\n                                        x_col = \"images\",\n                                        y_col = \"labels\",\n                                        class_mode = \"sparse\",\n                                        shuffle = True,\n                                        subset='training',\n                                       target_size = (img_width,img_height),\n                                       verbose = 0)\n        val = idg.flow_from_dataframe(validation_data,\n                                      x_col = \"images\",\n                                      y_col = \"labels\",\n                                      class_mode = \"sparse\",\n                                      shuffle = True,\n                                     target_size = (img_width,img_height),\n                                     verbose = 0)\t\n        \n#         if pretrained == 1:\n#             # Create the base model from the pre-trained model MobileNet V2\n#             image_size = (img_width,img_height)\n#             IMG_SHAPE = image_size + (3,)\n#             base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n#                                                            include_top=False,\n#                                                            weights='imagenet')\n\n#             base_model.trainable = False\n#             ##\n#             image_batch, label_batch = next(iter(train))\n#             feature_batch = base_model(image_batch)\n#             print(feature_batch.shape)\n#             ##\n#             global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n#             feature_batch_average = global_average_layer(feature_batch)\n#             ##\n#             prediction_layer = tf.keras.layers.Dense(4)\n#             prediction_batch = prediction_layer(feature_batch_average)\n#             ##\n#             preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n#             ##\n#             inputs = tf.keras.Input(shape=(250, 250, 3))\n#             #x = data_augmentation(inputs)\n#             x = preprocess_input(inputs)\n#             x = base_model(x, training=False)\n#             x = global_average_layer(x)\n#             x = tf.keras.layers.Dropout(0.2)(x)\n#             x = tf.keras.layers.Flatten()(x)\n#             x = tf.keras.layers.Dense(1280,activation='relu')(x)\n#             outputs = prediction_layer(x)\n#             model = tf.keras.Model(inputs, outputs)\n#             ##\n#             base_learning_rate = 0.0001\n#             model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n#                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n#                           metrics=['accuracy'])\n#             ##\n            \n        \n        '''\n        Passing the preprocessed data for model training\n        '''\n        loss,acc,returned_model = model_inputs(model,train,val,test)\n        final_loss += loss\n        final_acc += acc\n    return final_loss\/n_splits , final_acc\/n_splits , returned_model\n   ","774a14ee":"normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)\nconv_layer_32 = tf.keras.layers.Conv2D(32,(3,3),activation='relu')\nconv_layer_64 = tf.keras.layers.Conv2D(64,3,activation='relu')\nconv_layer_16 = tf.keras.layers.Conv2D(16,3,activation='relu')\nmax_pool = tf.keras.layers.MaxPooling2D()\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)","4fbac750":"data_augmentation = tf.keras.Sequential(\n  [\n    normalization_layer,\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    #tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n    #tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),\n    #tf.keras.layers.experimental.preprocessing.RandomCrop(170,170)  \n  ]\n)","09a1cdea":"# IMG_SIZE = 180\n\n# resize_and_rescale = tf.keras.Sequential([\n#   tf.keras.layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n#   tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)\n# ])\n# result = resize_and_rescale(img_opencv)\n# _ = plt.imshow(result)","c12a7b52":"plt.figure(figsize=(10, 10))\nimg_array = tf.keras.preprocessing.image.img_to_array(img_opencv)\nimg_array = tf.expand_dims(img_array,0)\nfor i in range(9):\n  augmented_image = data_augmentation(img_array)\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(augmented_image[0])\n  plt.axis(\"off\")","46e1b1ea":"num_classes = 4\n\nmodel = tf.keras.Sequential([\n  normalization_layer,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","47f8c32c":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","33b78c9c":"history = model.fit(\n    train,\n    validation_data=val,\n    epochs= 50,\n    callbacks = callback,\n    shuffle=False\n)\neff_epochs = len(history.history['loss'])","cd47ddfe":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs = 50\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(eff_epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy',fontdict = {'fontsize': '14',\n                              'color': 'white'})\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss',fontdict = {'fontsize': '14',\n                              'color': 'white'})\nplt.show()","aa6535ff":"model.summary()","0eaa1437":"results = model.evaluate(test)\nprint(\"test loss, test acc:\", results)","bd2d013f":"list_of_paths = ['..\/input\/brain-tumor-classification-mri\/Testing\/pituitary_tumor\/image(20).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/no_tumor\/image(11).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/meningioma_tumor\/image(120).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/glioma_tumor\/image(16).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/glioma_tumor\/image(100).jpg']\ntest_tumor(list_of_paths,model)","02fc2910":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","5278d8ea":"print(classification_report(labels_entire, pred_entire, target_names=classes))","94cab071":"num_classes = 4\n\nmodel2 = tf.keras.Sequential([\n  #data_augmentation,\n  normalization_layer,\n  #tf.keras.layers.Conv2D(32,3,activation='relu'),\n  conv_layer_32,\n  layers.MaxPooling2D(pool_size=(2,2)),\n  conv_layer_32,\n  layers.MaxPooling2D(pool_size=(2,2)),\n  layers.Flatten(),\n  layers.Dense(32, activation='relu'),\n  layers.Dropout(0.25),\n  layers.Dense(num_classes,activation='softmax')\n])","ad238e60":"model2.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","f78f9ec9":"epochs = 50\nhistory = model2.fit(\n  train,\n  validation_data=val,\n  epochs=epochs,\n  callbacks = callback,\n  shuffle=False\n)","54e3667d":"model2.summary()","eda15a5f":"eff_epochs = len(history.history['loss'])\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs = 50\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(eff_epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy',fontdict = {'fontsize': '14',\n                              'color': 'white'})\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss',fontdict = {'fontsize': '14',\n                              'color': 'white'})\nplt.show()","ee06166d":"results = model2.evaluate(test)\nprint(\"test loss, test acc:\", results)","5662c146":"list_of_paths = ['..\/input\/brain-tumor-classification-mri\/Testing\/pituitary_tumor\/image(20).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/no_tumor\/image(11).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/meningioma_tumor\/image(120).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/glioma_tumor\/image(16).jpg']\ntest_tumor(list_of_paths,model2)","97c2a66f":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model2.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","08d21ada":"print(classification_report(labels_entire, pred_entire, target_names=classes))","43dded5f":"path_data","a2c746a8":"label_names = os.listdir(path_data)\nlabel_names","139708db":"final_csv = csv_builder(path_data,label_names)\nfinal_csv","2f6fb048":"final_csv.to_csv('files_path.csv', header=None)","9bdc2b33":"path_of_csv = '.\/files_path.csv'","f336ede5":"test_csv = csv_builder(path_test,label_names)\ntest_csv","5b6cf9b7":"test_csv = test_csv.sample(frac=1)\ntest_csv","63b0dfa2":"k = 5","09eb0177":"num_classes = 4\n\nmodel = tf.keras.Sequential([\n  normalization_layer,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes,activation='softmax')\n])\nmodel.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","17bd3443":"loss,acc,model = cross_validation(k,final_csv,test_csv,img_width,img_height,model = model)","7cbfdc53":"print(loss,acc)","0f90d125":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","ecde932d":"print(classification_report(labels_entire, pred_entire, target_names=classes))","f1fddbda":"num_classes = 4\n\nmodel2 = tf.keras.Sequential([\n  #data_augmentation,\n  normalization_layer,\n  #tf.keras.layers.Conv2D(32,3,activation='relu'),\n  layers.Conv2D(32,(3,3),activation='relu'),\n  layers.MaxPooling2D(),#pool_size=(2,2)),\n  layers.Conv2D(32,(3,3),activation='relu'),\n  layers.MaxPooling2D(),#pool_size=(2,2)),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dropout(0.25),\n  layers.Dense(num_classes,activation='softmax')\n])\nmodel2.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","f1d1c3c5":"loss,acc,model2 = cross_validation(k,final_csv,test_csv,img_width,img_height,model = model2)\nprint(loss,acc)","c2879e5f":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model2.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","5b0cbe24":"print(classification_report(labels_entire, pred_entire, target_names=classes))","1636a863":"# **Checking effects of the data augmentation**","60cf1086":"# **Cross Validation on Second Model**","f0d39085":"# **Importing Libraries**","cb47b01c":"# **Second Model**","7c332311":"# **Model Building**","7bb41dee":"**Image of a brain with no tumor**","42784c37":"# Using k-fold cross validation","bba0c48b":"**References for model:\nModel 2: Obtained from a Kaggle notebook by chityeaung\nModel 1 and 3 taken from Tensorflow tutorials:\nImage Classification Tutorial\nTransfer Learning Tutorial**","3d2e942e":"# **Preparing dataset**","e532262f":"**Defining number of folds**","6bd4f8f6":"# Cross validation on the first model","0d101a1b":"**Image of a brain with tumor**","454b6a89":"# Helper Functions","fa7ddd72":"# Functions csv_builder() and cross_validation() have been defined in the helper functions","8ed4051b":"**Creating Testing Validation and Testing Sets**","70f2209e":"Adding a data augmentation layer to add more images to the training data by simply modifying the existing images in ways such as flipping them or making similar random transformations to the training data.","2f832499":"# **First Model**"}}