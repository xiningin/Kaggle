{"cell_type":{"3f12f148":"code","636f25b0":"code","d19bfa52":"code","2364f4ae":"code","56a877b6":"code","92d1424b":"code","8ce2544f":"code","5cccf17b":"code","01e263f7":"code","1a12b6be":"code","943834e3":"code","87ef6b6b":"code","469ce9f2":"code","2471f24f":"code","914765d8":"code","12cd5484":"code","210c0bf0":"code","9b04d4cb":"code","3e94e4bd":"code","f0a158ca":"code","4f737e49":"code","d8cf767a":"code","b3baf24d":"code","8b0b66eb":"code","4c963d79":"code","d3a00e92":"code","ae767484":"code","f180e1b0":"code","eda3f933":"code","5b2abe0d":"code","d9f855a5":"code","8ee25410":"code","5d5b79f4":"code","b856d0d8":"code","20192e8e":"code","8757f981":"markdown","d9a9e2b5":"markdown","5b97d7be":"markdown","ab3ce17d":"markdown","898890ee":"markdown"},"source":{"3f12f148":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","636f25b0":"# scintific computing libraries\nimport pandas as pd                                      \nimport numpy as np                    \nfrom scipy import optimize, stats        \n\n# visualisation libraries\nimport matplotlib.pyplot as plt                      \nimport seaborn as sns                \n\n# algorithmic library\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn import svm                 \nfrom sklearn.linear_model import LogisticRegression                              \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.utils import resample\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, RandomizedSearchCV, GridSearchCV  \nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, log_loss, mean_squared_error\n\n%matplotlib inline","d19bfa52":"df_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_test =  pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ndf_submission = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","2364f4ae":"print(df_train.shape)\ndf_train.head()","56a877b6":"print(df_test.shape)\ndf_test.head()","92d1424b":"print(df_submission.shape)\ndf_submission.head()","8ce2544f":"df_train.describe()","5cccf17b":"def data_analysis(df1,  df2):\n    print(df1.shape, df2.shape)\n    train_dtype = []\n    train_isnull = []\n    train_unique = []\n    test_dtype = []\n    test_isnull = []\n    test_unique = []\n    for col in df2.columns:\n        train_dtype.append(df1[col].dtypes)\n        train_isnull.append(df1[col].isnull().sum())\n        train_unique.append(df1[col].unique().shape[0])\n        test_dtype.append(df2[col].dtypes)\n        test_isnull.append(df2[col].isnull().sum())\n        test_unique.append(df2[col].unique().shape[0])\n\n    df = pd.DataFrame({'train_dtype':train_dtype,'test_dtype':test_dtype,'train_isnull':train_isnull,'test_isnull':test_isnull,\n                       'train_unique':train_unique,'test_unique':test_unique}, index=df2.columns)\n    df.sort_values(['train_isnull'], axis=0, ascending=False, inplace=True)\n    return df","01e263f7":"data_analysis(df_train, df_test).head(50)","1a12b6be":"col_drop = []\nfor col in df_test.columns:\n    if (df_train[col].isnull().sum() > 45) or (df_test[col].isnull().sum() > 45):\n        col_drop.append(col)\ndf_train.drop(col_drop, axis=1, inplace=True)\ndf_test.drop(col_drop, axis=1, inplace=True)","943834e3":"for col in df_test.columns:\n    if df_train[col].unique().shape[0] <= 30:\n        df_train[col].fillna(df_train[col].mode()[0], inplace=True)\n        df_test[col].fillna(df_test[col].mode()[0], inplace=True)\n        \n        df_train[col]= LabelEncoder().fit_transform(df_train[col]) \n        df_test[col]= LabelEncoder().fit_transform(df_test[col]) \n        #print(col, df_train[col].unique().shape[0])","87ef6b6b":"for col in df_test.columns:\n    if (df_train[col].isnull().sum() > 0) or (df_test[col].isnull().sum() > 0):\n        df_train[col].fillna(df_train[col].median(), inplace=True)\n        df_test[col].fillna(df_test[col].median(), inplace=True)","469ce9f2":"df_train.head()","2471f24f":"df_test.head()","914765d8":"df_train.corr()","12cd5484":"for col in df_train.columns:\n    pearson_coef, p_value = stats.pearsonr(df_train[col], df_train['SalePrice'])\n    print(col, pearson_coef, p_value)","210c0bf0":"col_continues = []\nfor col in df_test.columns:\n    if df_train[col].unique().shape[0] >= (df_train.shape[0])\/\/10:\n        col_continues.append(col)\nprint(col_continues)","9b04d4cb":"col_skew = df_train[col_continues].apply(lambda x: stats.skew(x)).sort_values(ascending=False)\nhigh_skew = col_skew[abs(col_skew) > 0.5]\nhigh_skew","3e94e4bd":"'''for col in high_skew.index:\n    df_train[col] = np.log1p(df_train[col])\n    df_test[col] = np.log1p(df_test[col])'''","f0a158ca":"sns.distplot(df_train['LotArea'])","4f737e49":"q = df_train['LotArea'].quantile(0.99)\ndf_train = df_train[df_train['LotArea'] < q]\ndf_train.reset_index(drop=True, inplace=True)","d8cf767a":"sns.distplot(df_train['BsmtFinSF1'])","b3baf24d":"sns.distplot(df_train['BsmtUnfSF'])","8b0b66eb":"sns.distplot(df_train['TotalBsmtSF'])","4c963d79":"sns.distplot(df_train['1stFlrSF'])","d3a00e92":"sns.distplot(df_train['GrLivArea'])","ae767484":"Y_train = df_train['SalePrice'].values\nX_train = df_train.drop(['Id','SalePrice'], axis = 1)\nX_test = df_test.drop(['Id'], axis = 1)\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape)","f180e1b0":"'''X_train = StandardScaler().fit(X_train).transform(X_train)\nX_test = StandardScaler().fit(X_test).transform(X_test)'''","eda3f933":"x_train, x_test, y_train, y_test = train_test_split( X_train, Y_train, test_size=0.2, random_state=4)\nprint ('Train set:', x_train.shape,  y_train.shape)\nprint ('Test set:', x_test.shape,  y_test.shape)","5b2abe0d":"LR = LinearRegression()\nLR.fit(x_train,y_train)\n\nprint('Train set mse:', mean_squared_error(y_train, LR.predict(x_train)))\nprint('Test set mse:', mean_squared_error(y_test, LR.predict(x_test)))\nprint('Test set score:', LR.score(x_test,y_test))","d9f855a5":"RFR = RandomForestRegressor(n_estimators = 1000)\nRFR.fit(x_train,y_train)\n\nprint('Train set mse:', mean_squared_error(y_train, RFR.predict(x_train)))\nprint('Test set mse:', mean_squared_error(y_test, RFR.predict(x_test)))\nprint('Test set score:', RFR.score(x_test,y_test))","8ee25410":"GBR = GradientBoostingRegressor(learning_rate=0.05, max_depth=4, n_estimators=1000)\nGBR.fit(x_train,y_train)\n\nprint('Train set mse:', mean_squared_error(y_train, GBR.predict(x_train)))\nprint('Test set mse:', mean_squared_error(y_test, GBR.predict(x_test)))\nprint('Test set score:', GBR.score(x_test,y_test))","5d5b79f4":"'''model = GradientBoostingRegressor()\nparams={ 'learning_rate'    : [0.05, 0.10, 0.15],\n         'max_depth'        : [3, 4, 5, 6, 8, 10, 12, 15],\n         'n_estimators'     : [100, 500, 1000]}\n\nrandom_search = RandomizedSearchCV(model, params, cv=5)\nrandom_search.fit(x_train, y_train)\nprint(random_search.best_estimator_)\nprint(random_search.best_params_)\nprint(random_search.best_score_)'''","b856d0d8":"prediction = GBR.predict(X_test)","20192e8e":"df_submission['SalePrice'] = prediction\ndf_submission.to_csv('prediction.csv', index=False)\ndf_submission.head()","8757f981":"## Data Acquisition","d9a9e2b5":"## Submission","5b97d7be":"## Model Development","ab3ce17d":"## Data Exploration","898890ee":"## Data Wrangling"}}