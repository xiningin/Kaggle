{"cell_type":{"3c69e9a5":"code","3f91d49b":"code","80885884":"code","d72d878c":"code","8e04884d":"code","f5934cbb":"code","d2e78a12":"code","3ad298df":"code","14a91b17":"code","b00fe92c":"code","13adba65":"code","aabb83b5":"code","22fa01ed":"code","32fd0dd7":"code","7145cb84":"code","e4928c82":"code","16ebbb20":"markdown","6b51c22d":"markdown","0ca0611c":"markdown","b909c198":"markdown","e9968341":"markdown","d8a02892":"markdown","81d94306":"markdown","b17d4877":"markdown"},"source":{"3c69e9a5":"import numpy as np\nimport pandas as pd\nimport random\nimport os\nimport time\nimport pickle\nfrom pathlib import Path\nimport gc\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport lightgbm as lgb\n#import xgboost as xgb\n#import catboost as ctb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","3f91d49b":"target = 'target'\n\nDEBUG = False\n\nif DEBUG:\n    N_ESTIMATORS = 1\n    N_SPLITS = 2\n    SEED = 2017\n    CVSEED = 2017\n    EARLY_STOPPING_ROUNDS = 1\n    VERBOSE = 100\n    #N_ITERS = 2\nelse:\n    N_SPLITS = 5\n    N_ESTIMATORS = 20000\n    EARLY_STOPPING_ROUNDS = 300\n    VERBOSE = 1000\n    SEED = 2017\n    CVSEED = 2017\n    #N_ITERS = 10","80885884":"def set_seed(seed=2017):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nset_seed(SEED)","d72d878c":"INPUT = Path(\"..\/input\/tabular-playground-series-oct-2021\")\n\ntrain = pd.read_csv(INPUT \/ \"train.csv\")\ntest = pd.read_csv(INPUT \/ \"test.csv\")\nsubmission = pd.read_csv(INPUT \/ \"sample_submission.csv\")","8e04884d":"train = train[train.columns[1:]]\ntest = test[test.columns[1:]]","f5934cbb":"features = [col for col in train.columns if 'f' in col]","d2e78a12":"cont_features =[]\ndisc_features =[]\n\nfor col in features:\n    if train[col].dtype=='float64':\n        cont_features.append(col)\n    else:\n        disc_features.append(col)\n        \nfeatures = disc_features + cont_features","3ad298df":"train[cont_features] = train[cont_features].astype('float32')\ntrain[disc_features] = train[disc_features].astype('uint8')\ntrain[target] = train[target].astype('uint8')\n\ntest[cont_features] = test[cont_features].astype('float32')\ntest[disc_features] = test[disc_features].astype('uint8')","14a91b17":"test[features]","b00fe92c":"train[target]","13adba65":"lgb_params = {\n     'objective': 'binary',\n     'n_estimators':N_ESTIMATORS,\n     'importance_type': 'gain',\n     'metric':'auc',\n     'boosting_type': 'gbdt',\n     'n_jobs' : -1,\n        \n    'learning_rate': 0.0038511441056118664, \n    'subsample': 0.5827550088149794, \n    'subsample_freq': 1, \n    'colsample_bytree': 0.19599597755538956, \n    'reg_lambda': 0.011685550612519125, \n    'reg_alpha': 0.04502045156737212, \n    'min_child_weight': 16.843316711276092, \n    'min_child_samples': 412, \n    'num_leaves': 546, \n    'max_depth': 5, \n    'cat_smooth': 36.40200359200525, \n    'cat_l2': 12.979520035205597\n    }","aabb83b5":"lgb_oof = np.zeros(train.shape[0])\nlgb_pred = np.zeros(test.shape[0])\nlgb_importances = pd.DataFrame()\n\nX_test = test[features]\ndel test\ngc.collect()\n\n\nkf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=CVSEED)\nseed_list=[SEED+1]\n\nfor fold, (trn_idx, val_idx) in enumerate(kf.split(X=train[features], y=train[target])):\n    print(f\"===== fold {fold} =====\")\n    if fold == 4:\n        \n        X_train = train[features].iloc[trn_idx]\n        y_train = train[target].iloc[trn_idx]\n        X_valid = train[features].iloc[val_idx]\n        y_valid = train[target].iloc[val_idx]\n        \n\n\n        start = time.time()\n        for inseed in seed_list:\n            lgb_params['random_state'] = inseed\n\n            pre_model = lgb.LGBMClassifier(**lgb_params)\n            pre_model.fit(\n                X_train, \n                y_train,\n                eval_set=[(X_valid, y_valid)],\n                eval_metric='auc',\n                categorical_feature = disc_features,\n                early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n                verbose=VERBOSE,\n            )\n\n            lgb_params2 = lgb_params.copy()\n            lgb_params2['reg_lambda'] *= 0.9\n            lgb_params2['reg_alpha'] *= 0.9\n            lgb_params2['learning_rate'] *= 0.1\n            model = lgb.LGBMClassifier(**lgb_params2)\n            model.fit(\n                    X_train, y_train,\n                    eval_set=[(X_valid, y_valid)],\n                    eval_metric='auc',\n                    categorical_feature = disc_features,\n                    early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n                    verbose=VERBOSE,\n                    init_model=pre_model\n            )    \n\n            with open(f\"lgb_model{fold}_seed{inseed}.pkl\", 'wb') as f:\n                pickle.dump(model, f)\n\n            fi_tmp = pd.DataFrame()\n            fi_tmp['feature'] = X_train.columns\n            fi_tmp['importance'] = model.feature_importances_\n            fi_tmp['fold'] = fold\n            fi_tmp['seed'] = inseed\n            lgb_importances = lgb_importances.append(fi_tmp)\n\n            lgb_oof[val_idx] += model.predict_proba(X_valid)[:,-1] \/ len(seed_list)\n            lgb_pred += model.predict_proba(X_test)[:,-1] \/ len(seed_list)\n            \n            del pre_model\n            del model\n            gc.collect()\n\n\n        elapsed = time.time() - start\n        auc = roc_auc_score(y_valid, lgb_oof[val_idx])\n        print(f\"fold {fold} - lgb auc: {auc:.6f}, elapsed time: {elapsed:.2f}sec\\n\")\n        \n        del X_train\n        del y_train\n        del X_valid\n        del y_valid\n        gc.collect()\n\n\ndel X_test\ngc.collect()\n\nlgb_pred \/= N_SPLITS\nprint(f\"oof lgb_auc = {roc_auc_score(train[target], lgb_oof)}\")\n\nnp.save(\"lgb_oof.npy\", lgb_oof)\nnp.save(\"lgb_pred.npy\", lgb_pred)","22fa01ed":"plt.plot(train[target], train[target])\nplt.scatter(train[target], lgb_oof)","32fd0dd7":"del train\ndel lgb_oof\ngc.collect()","7145cb84":"order = list(lgb_importances.groupby('feature').mean().sort_values('importance', ascending=False).index)\n\nfig = plt.figure(figsize=(16, 16), tight_layout=True)\nsns.barplot(x=\"importance\", y=\"feature\", data=lgb_importances.groupby('feature').mean().reset_index(), order=order)\nplt.title(\"LGB feature importances\")","e4928c82":"submission[target] = lgb_pred\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission","16ebbb20":"# OOF predictions","6b51c22d":"# Log\n\nseeds\n\n2017 ver1\n2018 ver6 fold 0-3 ver7 fold 4 \n2019 ver3\n2020 ver4\n2021 ver5","0ca0611c":"# Submission","b909c198":"# Parameters","e9968341":"# LGB","d8a02892":"# Features importances","81d94306":"# Preprocessing","b17d4877":"# Datasets"}}