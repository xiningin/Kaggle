{"cell_type":{"90c8121f":"code","1a2c9326":"code","dd441fcf":"code","fa3d9902":"code","e9fc3c8d":"code","5ed82337":"code","e0cb7420":"code","9cdaae1a":"code","c5370be8":"code","f38c61dc":"code","54953422":"code","ef25cdc2":"code","5dc88c1e":"code","a34a6332":"code","ec934763":"code","268152d3":"code","3855aff7":"code","6e19bd31":"code","8aa69b08":"code","5d155972":"code","6f3bc9e7":"code","7a6c9e45":"code","2e4e2a0e":"code","0d784772":"code","f3d05043":"code","77a9576a":"code","7747069e":"code","26fe3741":"code","29f84860":"code","238bff0e":"code","62df47fd":"code","a3c876ba":"code","1166b29c":"code","9f55b60f":"code","389ce573":"code","2b1384ee":"code","c0d7cfea":"code","0344b32c":"code","a251c2ce":"code","6da8edaa":"code","ab831f9e":"code","41bec27b":"code","1ad93804":"code","6841d5f0":"code","279d0ef9":"code","1a4fced5":"code","95502b51":"code","5d772936":"code","e2836020":"code","b79a568a":"code","7dcaadea":"code","f8728428":"code","1701e74e":"code","022909c5":"code","d748e75a":"code","8dd7ce8a":"code","22b92f6f":"code","08a5a873":"code","4278efa9":"code","b1ce88e3":"code","7a5bc716":"code","1fa5a980":"code","1a97bbc1":"code","48986136":"code","8f0055c5":"code","e003828f":"code","5cca7515":"code","c4a7b4dd":"code","94cc8960":"code","29105ab6":"code","5ca00285":"code","6110283b":"code","2d37d209":"code","abd7c3f4":"code","4ded55bc":"markdown","37fa2cc9":"markdown","a9a17b8f":"markdown","74874d86":"markdown","fe400ac9":"markdown","57c9a2c6":"markdown","be912dd8":"markdown","3283f193":"markdown","ce08e454":"markdown","8dba5294":"markdown","c3c03b18":"markdown","42d71b41":"markdown","6b3837ee":"markdown","e1f20714":"markdown"},"source":{"90c8121f":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt  \nimport seaborn as seabornInstance \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor\nimport xgboost as xgb\nfrom sklearn.metrics import make_scorer, r2_score","1a2c9326":"%matplotlib inline","dd441fcf":"weather_actuals=pd.read_csv(\"\/kaggle\/input\/climateconnect\/weather_actuals.csv\")\nwf=pd.read_csv(\"\/kaggle\/input\/climateconnect\/weather_forecast.csv\")\nweather_actuals=weather_actuals.iloc[:,3:32]\nweather_actuals.head()\nweather_actuals.rename(columns={'datetime_local':'datetime'},inplace=True)\nweather_actuals.precip_type.unique()","fa3d9902":"weather_actuals[\"precip_type\"].fillna(\"no rain\",inplace=True)\nweather_actuals.precip_type.unique()","e9fc3c8d":"power_actuals=pd.read_csv(\"\/kaggle\/input\/climateconnect\/power_actual.csv\")\npower_actuals","5ed82337":"import seaborn as sns\nsns.scatterplot(x=power_actuals.index[4],y='power',data=power_actuals);","e0cb7420":"weather_actuals","9cdaae1a":"merged = pd.merge(weather_actuals,power_actuals,on='datetime',how='right',sort=True) #merge target(power_actuals) and features(weather_actuals) dataset\nmerged","c5370be8":"merged.fillna(method=\"ffill\",inplace=True)","f38c61dc":"merged=merged.replace([-9999,-9999.0,-9999.00,'-9999'],np.nan) #Removing all the negative values with null values","54953422":"merged.shape","ef25cdc2":"merged.dropna(how='all',axis=1,inplace=True)\nmerged.shape","5dc88c1e":"merged.dropna(inplace=True)\nmerged.shape","a34a6332":"merged.columns","ec934763":"numericalFeatures = merged.select_dtypes(include = [np.number])\nprint(\"The number of numerical features is: {}\".format(numericalFeatures.shape[1]))","268152d3":"numericalFeatures.columns","3855aff7":"categoricalFeatures = merged.select_dtypes(exclude = [np.number])\nprint(\"The number of categorical features is: {}\".format(categoricalFeatures.shape[1]))","6e19bd31":"categoricalFeatures.columns","8aa69b08":"merged['precip_type_en'] = LabelEncoder().fit_transform(merged['precip_type'])\nmerged[['precip_type', 'precip_type_en']]","5d155972":"merged['icon_encoded'] = LabelEncoder().fit_transform(merged['icon'])\nmerged[['icon', 'icon_encoded']] # special syntax to get just these two columns","6f3bc9e7":"merged['summary_encoded'] = LabelEncoder().fit_transform(merged['summary'])\nmerged[['summary', 'summary_encoded']]","7a6c9e45":"merged['sunset']=pd.to_datetime(merged['sunset'])\nmerged['sunrise']=pd.to_datetime(merged['sunrise'])\nmerged['datetime']=pd.to_datetime(merged['datetime'])\nmerged[\"daylight\"]=(merged[\"sunset\"]-merged['sunrise']).dt.total_seconds() #to get the daylight time in seconds","2e4e2a0e":"merged","0d784772":"merged.drop(['precip_type','icon', 'summary','updated_at','sunrise','sunset','Unnamed: 0'],axis=1,inplace=True)","f3d05043":"print(merged.isnull().sum())","77a9576a":"from sklearn.neighbors import LocalOutlierFactor","7747069e":"clf = LocalOutlierFactor(n_neighbors=50, contamination='auto')","26fe3741":"merged.describe()","29f84860":"merged.drop(merged[merged['power']>40].index,inplace=True)","238bff0e":"merged.info()","62df47fd":"merged.describe()","a3c876ba":"merged.shape","1166b29c":"merged.drop(['dew_point','wind_bearing','apparent_temperature','wind_gust','precip_probability','ghi','gti','pressure','uv_index'],axis=1,inplace=True)","9f55b60f":"merged.plot(subplots=True,figsize = (10,15) )","389ce573":"merged.columns","2b1384ee":"corrmat = merged.corr(method='spearman')\nf, ax = plt.subplots(figsize=(12, 10))\nsns.heatmap(corrmat, ax=ax, cmap=\"YlGnBu\", linewidths=0.1)","c0d7cfea":"merged.info()","0344b32c":"data=merged[['datetime','cloud_cover', 'temperature', 'humidity',\n       'wind_speed', 'ozone',\n       'precip_intensity', 'visibility', 'power',\n       'precip_type_en', 'icon_encoded', 'summary_encoded', 'daylight']]","a251c2ce":"X=data.drop(['datetime','power'],axis=1)","6da8edaa":"y=data['power']","ab831f9e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) ","41bec27b":"sc = StandardScaler() # standardizing a feature by subtracting the mean and then scaling to unit variance.\nX_train = sc.fit_transform(X_train)\nX_test  = sc.transform(X_test)","1ad93804":"def test_model(model, x_train, y_train):\n    cv = KFold(n_splits = 3, shuffle=True, random_state = 45)\n    r2 = make_scorer(r2_score)\n    r2_val_score = cross_val_score(model, x_train, y_train, cv=cv, scoring = r2)\n    score = [r2_val_score.mean()]\n    return score","6841d5f0":"def rsme(model, x, y):\n    cv_scores = -cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=10)\n    return np.sqrt(cv_scores)","279d0ef9":"LR = LinearRegression()\nacc_LR = test_model(LR, X_train, y_train)\n\nLR_rsme = rsme(LR, X_train, y_train)\n\n\nprint('Score: {:.5f}'.format((acc_LR[0])))\nprint('RSME: {:.5f}'.format(LR_rsme.mean()))","1a4fced5":"LR.fit(X_train,y_train)\ny_pred1=LR.predict(X_test)\nfor i in range(len(y_pred1)):\n    if y_pred1[i]<1:\n        y_pred1[i]=0","95502b51":"df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred1})\ndf.head()","5d772936":"svr_reg = SVR(kernel='rbf')\nacc_SVR = test_model(svr_reg, X_train, y_train)\n\nsvr_rsme = rsme(svr_reg, X_train, y_train)\nprint('Score: {:.5f}'.format((acc_SVR[0])))\nprint('RSME: {:.5f}'.format(svr_rsme.mean()))","e2836020":"svr_reg.fit(X_train,y_train)\ny_pred2=svr_reg.predict(X_test)\nfor i in range(len(y_pred2)):\n    if y_pred2[i]<1:\n        y_pred2[i]=0","b79a568a":"df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred2})\ndf.head()","7dcaadea":"dt_reg = DecisionTreeRegressor(random_state=21)\nacc_tree = test_model(dt_reg, X_train, y_train)\n\ndt_rsme = rsme(dt_reg, X_train, y_train)\nprint('Score: {:.5f}'.format((acc_tree[0])))\nprint('RSME: {:.5f}'.format(dt_rsme.mean()))","f8728428":"dt_reg.fit(X_train,y_train)\ny_pred3=dt_reg.predict(X_test)\nfor i in range(len(y_pred3)):\n    if y_pred3[i]<1:\n        y_pred3[i]=0","1701e74e":"df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred3})\ndf.tail(20)","022909c5":"from matplotlib.ticker import FuncFormatter,MaxNLocator\nfig,ax=plt.subplots()\nax=fig.add_axes([0,0,1,1])\nax.grid(True)\nax.xaxis.set_major_locator(plt.MaxNLocator(30))\nax.set_xlabel('Date_Time')\nax.set_ylabel('Power_Predicted')\nax.plot(merged.index[0:45],y_pred3[0:45])\nplt.xticks(rotation='vertical')","d748e75a":"rf_reg = RandomForestRegressor(n_estimators =10, random_state=51)\nacc_rf = test_model(rf_reg, X_train, y_train)\n\nrf_rsme = rsme(rf_reg, X_train, y_train)\nprint('Score: {:.5f}'.format((acc_rf[0])))\nprint('RSME: {:.5f}'.format(rf_rsme.mean()))","8dd7ce8a":"rf_reg.fit(X_train,y_train)\ny_pred4=rf_reg.predict(X_test)\nfor i in range(len(y_pred4)):\n    if y_pred4[i]<1:\n        y_pred4[i]=0","22b92f6f":"df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred4})\ndf.head()","08a5a873":"from matplotlib.ticker import FuncFormatter,MaxNLocator\nfig,ax=plt.subplots()\nax=fig.add_axes([0,0,1,1])\nax.grid(True)\nax.xaxis.set_major_locator(plt.MaxNLocator(30))\nax.set_xlabel('Date_Time')\nax.set_ylabel('Power_Predicted')\nax.plot(merged.index[0:45],y_pred4[0:45])\nplt.xticks(rotation='vertical')","4278efa9":"results = pd.DataFrame({\n    'Model': ['Linear Regression', 'Support Vector Regressor', \n              'Decision Tree', 'Random Forest'],\n    'Score': [acc_LR[0], acc_SVR[0], acc_tree[0], acc_rf[0]],\n    'RSME': [LR_rsme[0], svr_rsme[0], dt_rsme[0], rf_rsme[0]]\n             })\n\nresult = results.sort_values(by='RSME', ascending=True)\nresult = result.set_index('Model')\ndisplay(result.head(8))","b1ce88e3":"wf=pd.read_csv(\"\/kaggle\/input\/climateconnect\/weather_forecast.csv\")\nwf=wf.iloc[:,3:]\nwf.shape\nwf.info()","7a5bc716":"wf.describe()","1fa5a980":"wf.precip_type.unique()","1a97bbc1":"wf[\"precip_type\"].fillna(\"no rain\",inplace=True)\nwf.precip_type.unique()","48986136":"wf['icon_encoded'] = LabelEncoder().fit_transform(wf['icon'])\nwf[['icon', 'icon_encoded']] # special syntax to get just these two columns\nwf['summary_encoded'] = LabelEncoder().fit_transform(wf['summary'])\nwf[['summary', 'summary_encoded']] # special syntax to get just these two columns","8f0055c5":"wf['precip_type_en'] = LabelEncoder().fit_transform(wf['precip_type'])\nwf[['precip_type', 'precip_type_en']]","e003828f":"wf['sunset']=pd.to_datetime(wf['sunset'])\nwf['sunrise']=pd.to_datetime(wf['sunrise'])\n\nwf[\"daylight\"]=(wf[\"sunset\"]-wf['sunrise']).dt.total_seconds()","5cca7515":"wf.columns","c4a7b4dd":"wf.rename(columns={'datetime_local':'datetime'},inplace=True)\n#wf.set_index('datetime', inplace=True) ","94cc8960":"wf.drop(['dew_point','wind_chill','heat_index','pressure','uv_index','wind_bearing','qpf','snow','pop','fctcode','precip_accumulation','precip_type','sunrise','sunset','icon','summary','updated_at'],axis=1,inplace=True)\nwf.head()","29105ab6":"wf.drop(['apparent_temperature','wind_gust','precip_probability'],axis=1,inplace=True)\nprint(wf.isnull().sum())","5ca00285":"wf=wf.dropna()\nwf.set_index('datetime', inplace=True)\nwf['output']=dt_reg.predict(wf)\npred=wf['output']\nfor i in range(len(pred)):\n    if pred[i]<1:\n        pred[i]=0\nprediction=wf[[\"output\" ]]\nprediction.rename(columns={'output':'power_predicted'},inplace=True)","6110283b":"prediction","2d37d209":"submission = pd.DataFrame(prediction)","abd7c3f4":"submission.to_csv(\"submission.csv\", header=True)\nsubmission","4ded55bc":"# **Linear Regression Model**","37fa2cc9":"# **Predicting generated Power on Weather_forecast file**","a9a17b8f":"# **Support Vector Regressor**","74874d86":"# **Random Forest Regressor**","fe400ac9":"# **Reading CSV dataset**","57c9a2c6":"# **Data PreProcessing**","be912dd8":"# **Visualizing the datasets**","3283f193":"# **Merging features and the corresponding Target files**","ce08e454":"# **Converting Categorical Values into Numerical values using Label Encoder**","8dba5294":"# **Saving all the predicted powers in a csv file**","c3c03b18":"# **Decision Tree Regressor**","42d71b41":"# **Comparing all the models**","6b3837ee":"# **Importing all the libraries required**","e1f20714":"# **Splitting Datasets into training and testing set using train_test_split function**"}}