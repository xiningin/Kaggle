{"cell_type":{"ef085e51":"code","a8de551f":"code","3b6710c3":"code","c2f60967":"code","cbe8c36e":"code","336a4d6a":"code","44185d0a":"code","346d59c7":"code","7598b369":"code","dded5a4f":"code","33570656":"code","aee56184":"code","554bd576":"code","e430d8f7":"code","2815a9bb":"code","99183950":"code","94e94006":"code","c26ecba6":"code","c3c7f11b":"code","45909e02":"code","24767eab":"code","0b0e4b5b":"code","9b3dcd32":"code","7762f566":"markdown","82fab283":"markdown"},"source":{"ef085e51":"# Importing required libraries\n\nimport numpy as np\nimport pandas as pd\nnp.random.seed(1)\n\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\nimport plotly.express as px\npyo.init_notebook_mode(connected = True)\nfrom plotly.subplots import make_subplots\n\nimport cv2\n\nimport keras\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\ntf.random.set_seed(1)\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\nfrom keras.models import Sequential\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom keras.applications import VGG16\nfrom keras.models import load_model\n","a8de551f":"os.getcwd()","3b6710c3":"os.listdir('\/kaggle\/input\/intel-image-classification')","c2f60967":"os.listdir('\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train')","cbe8c36e":"train = '\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train'\nval = '\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test'\ntest = '\/kaggle\/input\/intel-image-classification\/seg_pred'","336a4d6a":"train_datgen = ImageDataGenerator(rescale=1.\/255,\n                                     rotation_range=30,\n                                     width_shift_range=0.2,\n                                     height_shift_range=0.2,\n                                     shear_range=0.2,\n                                     zoom_range=0.2,\n                                     horizontal_flip=True,\n                                     fill_mode='nearest')\n\ntrain_generator = train_datgen.flow_from_directory(train,target_size=(150, 150),batch_size=50,\n                                                                         classes=['sea', 'forest', 'mountain', 'glacier', 'buildings', 'street'],\n                                                                        class_mode='categorical')\n\n\nval_generator = ImageDataGenerator(rescale=1.\/255).flow_from_directory(val,target_size=(150, 150),batch_size=30,\n                                                                         classes=['sea', 'forest', 'mountain', 'glacier', 'buildings', 'street'],\n                                                                        class_mode='categorical')\n","44185d0a":"n=1\n\nfig,ax = plt.subplots(6,6,figsize=(15,15))\ni = 0\nfor path in os.listdir(train):\n    img_path = os.path.join(train,path,os.listdir(os.path.join(train,path))[n])\n    img = image.load_img(img_path,target_size=(150,150))\n    img = image.img_to_array(img)\n    #flow requires (batch,width,height,channel), our current image shape is (width,height,channel) so we need to add batch\n    img = img.reshape((1,)+img.shape)\n    # alternatively this can be done with np.expand_dims()\n    j=0\n    for batch in train_datgen.flow(img,batch_size=1):\n        sub = ax[i,j]\n        sub.imshow(image.array_to_img(batch[0]))\n        sub.axis('off')\n        j+=1\n        if j%6 == 0:\n            break\n    i+=1","346d59c7":"data = {'Train':dict([(path,len(os.listdir(os.path.join(train,path)))) for path in os.listdir(train)]),\n       'Validation':dict([(path,len(os.listdir(os.path.join(val,path)))) for path in os.listdir(val)])}\ndata = pd.DataFrame(data)\ndata","7598b369":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(20,6))\nsns.barplot(x = 'Train', y = 'index', data = data.reset_index(),ax=ax1)\nsns.barplot(x = 'Validation', y = 'index', data = data.reset_index(),ax=ax2)","dded5a4f":"data = data.reset_index()\ndata.columns = ['Category','Train_value','Validation_Value']\nlabels = data['Category']\ntrain = data['Train_value']\nval = data['Validation_Value']\n\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]],subplot_titles=['Train Ratio', 'Validation Ratio'])\nfig.add_trace(go.Pie(labels=labels, values=train, name=\"Train\"),\n              1, 1)\nfig.add_trace(go.Pie(labels=labels, values=val, name=\"Validation\"),\n              1, 2)\nfig.update_traces(textposition='inside', textinfo='percent+label',hole=.4, hoverinfo=\"label+percent+name\")\nfig.show()","33570656":"model = Sequential()\nmodel.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3),padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),strides=2))\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),strides=2))\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),strides=2))\nmodel.add(Conv2D(256,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2),strides=2))\nmodel.add(Flatten())\nmodel.add(Dense(768,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(6,activation='softmax'))\n\nmodel.summary()","aee56184":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='auto')\noptimizer = RMSprop(learning_rate=0.0001)\n\nmodel.compile(optimizer,loss='categorical_crossentropy',metrics=['acc'])","554bd576":"history = model.fit_generator(train_generator,steps_per_epoch=560,epochs=100,callbacks=[early_stopping],\n                              validation_data=val_generator,validation_steps=100)","e430d8f7":"def loss_accuracy_plot(history):\n    accuracy = history.history['acc']\n    loss = history.history['loss']\n    val_accuracy = history.history['val_acc']\n    val_loss = history.history['val_loss']\n    epochs = history.epoch\n    \n    fig = make_subplots(rows=2, cols=1)\n    \n    fig.add_trace(go.Scatter(x=epochs, y=loss, name='Train Loss',\n                             line=dict(color='royalblue', width=4)),row=1,col=1)\n    fig.add_trace(go.Scatter(x=epochs, y=val_loss, name = 'Validation Loss',\n                             line=dict(color='firebrick', width=4, dash='dot')),row=1,col=1)\n    \n        \n    fig.add_trace(go.Scatter(x=epochs, y=accuracy, name='Train Accuracy',\n                             line=dict(color='royalblue', width=4)),row=2,col=1)\n    fig.add_trace(go.Scatter(x=epochs, y=val_accuracy, name = 'Validation Accuracy',\n                             line=dict(color='firebrick', width=4, dash='dot')),row=2,col=1)\n    \n    fig.update_layout(height=800, width=800, title_text=\"Loss and Accuracy\")\n    fig.show()","2815a9bb":"loss_accuracy_plot(history)","99183950":"conv_base = VGG16(weights='imagenet',\n                 include_top=False,\n                 input_shape=(150,150,3))","94e94006":"model2 = Sequential()\nmodel2.add(conv_base)\nmodel2.add(Flatten())\nmodel2.add(Dense(256,activation='relu'))\nmodel2.add(Dropout(0.2))\nmodel2.add(Dense(6,activation='softmax'))\n\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='auto',verbose=1)\ncheckpoint1 = ModelCheckpoint('check_1.h5',monitor='val_acc',verbose=1,save_best_only=True,mode='auto')\ncheckpoint2 = ModelCheckpoint('check_2.h5',monitor='val_loss',verbose=1,save_best_only=True,mode='auto')\n\noptimizer = RMSprop(learning_rate=0.0001)\n\nmodel2.compile(optimizer,loss='categorical_crossentropy',metrics=['acc'])","c26ecba6":"history2 = model2.fit_generator(train_generator,steps_per_epoch=560,epochs=100,callbacks=[early_stopping,checkpoint1,checkpoint2],\n                              validation_data=val_generator,validation_steps=100)","c3c7f11b":"loss_accuracy_plot(history2)","45909e02":"saved_model = load_model('check_2.h5')","24767eab":"pred_class = dict([(v,k) for (k,v) in train_generator.class_indices.items()])\npred_class","0b0e4b5b":"def result_plotter(rows=3,cols=3):\n    \n    fig, ax = plt.subplots(rows,cols,figsize=((cols*2)+1,(rows*2)+1))\n\n    for i in range(rows):\n        for j in range(cols):\n            img_path = os.path.join(test,'seg_pred',os.listdir(test+'\/seg_pred')[(i*cols)+j])\n            img = image.load_img(img_path,target_size=(150,150))\n            img = image.img_to_array(img)\n            img = img.reshape((1,)+img.shape)\n            pred = saved_model.predict(img)\n            pred = np.argmax(pred)\n\n\n            sub = ax[i,j]\n            img = plt.imread(img_path)\n            cv2.rectangle(img,(0,150),(150,130),thickness=-1, color=(255, 255, 255))\n            sub.text(75,140,pred_class[pred],ha='center',va='center',size=12)\n            sub.imshow(img)\n            sub.axis('off')\n#             sub.set_title(pred_class[pred],fontdict={'fontsize':'x-large'})","9b3dcd32":"result_plotter(rows=10,cols=10)","7762f566":"### Keras CNN","82fab283":"### Using Pretrained model VGG16"}}