{"cell_type":{"2b8b2beb":"code","c3a0d9ef":"code","0cd5c7e6":"code","f1c19f38":"code","334080d8":"code","36e84493":"code","1378c379":"code","f293a99b":"code","cb071d09":"code","61cffe1e":"code","483f1dfd":"code","cdc7a432":"code","e2662bea":"code","4865a9bf":"code","01affc42":"code","13a084fe":"markdown","bd5ad4bc":"markdown","1be9a09d":"markdown","ca55194c":"markdown","16f4b2bf":"markdown","62a568ce":"markdown","989f2585":"markdown","c27bdea2":"markdown","b6f252bb":"markdown"},"source":{"2b8b2beb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom jcopml.plot import plot_missing_value\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\nfrom jcopml.pipeline import num_pipe, cat_pipe\nfrom jcopml.utils import save_model, load_model\nfrom jcopml.plot import plot_missing_value\nfrom jcopml.feature_importance import mean_score_decrease, mean_loss_decrease\nfrom jcopml.tuning import grid_search_params as gsp\nfrom jcopml.tuning import random_search_params as rsp\nfrom jcopml.plot import plot_actual_vs_prediction, plot_residual\n\nfrom xgboost import XGBRegressor\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c3a0d9ef":"df = pd.read_csv(\"\/kaggle\/input\/used-cars-price-prediction\/train-data.csv\")","0cd5c7e6":"df.drop(columns=[\"Unnamed: 0\", \"New_Price\"], inplace=True)\ndf[\"Brand\"] = df[\"Name\"].str.split(\" \").str[0]\ndf[\"Mileage\"] = df[\"Mileage\"].str.split(\" \").str[0]\ndf[\"Engine\"] = df[\"Engine\"].str.split(\" \").str[0]\ndf[\"Power\"] = df[\"Power\"].str.split(\" \").str[0]\ndf.drop(columns=\"Name\", inplace=True)\ndf = df.loc[df[\"Seats\"]>0]\ndf = df[df['Mileage'].notna()]\ndf = df[df['Engine'].notna()]\ndf = df[df['Power'].notna()]\ndf = df[df['Seats'].notna()]\ndf = df.loc[df[\"Power\"]!= 'null']\ndf[\"Mileage\"] = pd.to_numeric(df[\"Mileage\"])\ndf[\"Engine\"] = pd.to_numeric(df[\"Engine\"])\ndf[\"Power\"] = pd.to_numeric(df[\"Power\"])\n\ndf.head(4)","f1c19f38":"df.shape","334080d8":"plot_missing_value(df, return_df=True)","36e84493":"print(df[\"Price\"].agg([\"min\", \"max\", \"mean\"]))\nplt.figure(figsize=(12, 6))\nax = sns.distplot(df[\"Price\"], bins=1000, color=\"red\")","1378c379":"df.describe()","f293a99b":"f, axes = plt.subplots(4, 2, figsize=(19, 15), sharex=False)\nax = sns.scatterplot(x=\"Year\", y=\"Price\", data=df, hue=\"Fuel_Type\", size=\"Transmission\", ax = axes[0, 0])\nax = sns.distplot(df[\"Year\"], bins=19, ax = axes[0, 1], color='g')\nax = sns.scatterplot(x=\"Kilometers_Driven\", y=\"Price\", data=df, hue=\"Fuel_Type\", size=\"Transmission\", ax = axes[1, 0])\nax = sns.distplot(df[\"Kilometers_Driven\"], bins=100, ax = axes[1, 1], color='r')\nax = sns.boxplot(x=\"Seats\", y=\"Price\", data=df, ax = axes[2, 0])\nax = sns.distplot(df[\"Seats\"], bins=8, ax = axes[2, 1], color='r', kde_kws = {'bw' : 1.0})\nax = sns.scatterplot(x=\"Engine\", y=\"Price\", data=df, ax = axes[3, 0])\nax = sns.scatterplot(x=\"Power\", y=\"Price\", data=df, ax = axes[3, 1])","cb071d09":"f, axes = plt.subplots(3, 2, figsize=(19, 15), sharex=False)\nax = sns.stripplot(x=\"Transmission\", y=\"Price\", data=df, ax=axes[0, 0])\nax = sns.stripplot(x=\"Location\", y=\"Price\", data=df, ax=axes[0, 1])\nax = sns.stripplot(x=\"Fuel_Type\", y=\"Price\", data=df, ax=axes[1, 0])\nax = sns.stripplot(x=\"Owner_Type\", y=\"Price\", data=df, ax=axes[1, 1])\nax = sns.stripplot(x=\"Brand\", y=\"Price\", data=df, ax=axes[2, 0])","61cffe1e":"correlation = df.corr()\nn = 9\ncols = correlation.nlargest(n, 'Price')['Price'].index\ndf_cor = np.corrcoef(df[cols].values.T)\n\nplt.figure(figsize=(8, 5))\nax = sns.heatmap(df_cor, cbar=True, annot=True, fmt='.1f', yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","483f1dfd":"# Separate the features and target columns\nX = df.drop(columns=[\"Price\"])\ny = df[\"Price\"]\n\n# Create data train and data test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","cdc7a432":"preprocessor = ColumnTransformer([\n    ('numeric', num_pipe(poly=2, scaling='robust', transform='yeo-johnson'), [\"Year\", \"Kilometers_Driven\", \"Mileage\",\n                                                                             \"Engine\", \"Power\", \"Seats\"]),\n    ('categoric', cat_pipe(encoder='onehot'), [\"Location\", \"Fuel_Type\", \"Transmission\", \"Owner_Type\", \"Brand\"])\n])\n\npipeline = Pipeline([\n    ('prep', preprocessor),\n    ('algo', XGBRegressor(n_jobs=-1, random_state=42))\n])\n\nparameter_tune = {\n    'algo__colsample_bytree': [0.9657264649759805], \n    'algo__gamma': [10], \n    'algo__learning_rate': [0.1], \n    'algo__max_depth': [10], \n    'algo__n_estimators': [200], \n    'algo__reg_alpha': [0.004359456845930351], \n    'algo__reg_lambda': [0.142428167785941], \n    'algo__subsample': [0.6], \n    'prep__numeric__poly__degree': [3], \n    'prep__numeric__poly__interaction_only': [True]\n}\n\nmodel_xgb = GridSearchCV(pipeline, parameter_tune, cv=3, n_jobs=-1, verbose=1)\nmodel_xgb.fit(X_train, y_train)\n\nprint(model_xgb.best_params_)\nprint(model_xgb.score(X_train, y_train), model_xgb.best_score_, model_xgb.score(X_test, y_test))\nprint(\" \")\nprint(\"Accuracy on train:\", model_xgb.score(X_train, y_train))\nprint(\"Accuracy on test:\", model_xgb.score(X_test, y_test))","e2662bea":"mean_score_decrease(X_train, y_train, model_xgb, plot=True, topk=10)","4865a9bf":"plot_actual_vs_prediction(X_train, y_train, X_test, y_test, model_xgb)","01affc42":"plot_residual(X_train, y_train, X_test, y_test, model_xgb)","13a084fe":"# Modelling XgBoost","bd5ad4bc":"### Correlation Matrix","1be9a09d":"### Categoric Data","ca55194c":"# Datasets Splitting","16f4b2bf":"# Evaluation","62a568ce":"# Simple EDA\n### Check Missing Value","989f2585":"### Price (Target Variable)","c27bdea2":"## Import Datasets","b6f252bb":"### Numeric Data"}}