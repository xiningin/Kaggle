{"cell_type":{"daefdfe6":"code","5a416703":"code","57f1b030":"code","0268628f":"code","53cb646c":"code","f4bada75":"code","ad71634d":"code","22ff318f":"code","e2d6d984":"code","82d0909f":"markdown","d4e5e816":"markdown","5a7c75fe":"markdown","a398b1c3":"markdown","51776f19":"markdown","d39ffe61":"markdown","d1c683aa":"markdown","26bae3a6":"markdown","4ac903be":"markdown"},"source":{"daefdfe6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import plot_model\n\nfrom tqdm import tqdm\nfrom numpy import asarray\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array","5a416703":"class Sampling(layers.Layer):\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon","57f1b030":"latent_dim = 2\ntotal_epoch = 100\nbatch_size = 64\nimg_dim = (256, 256)\n\nencoder_inputs = keras.Input(shape=(*img_dim, 3))\n\nx = layers.Conv2D(16, kernel_size=(5,5), strides=(2,2), padding='SAME')(encoder_inputs)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(32, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(64, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2D(128, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(256, activation=\"relu\")(x)\n\nz_mean    = layers.Dense(latent_dim, name=\"z_mean\")(x)\nz_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\nz         = Sampling()([z_mean, z_log_var])\n\nencoder = keras.Model(encoder_inputs, \n                      [z_mean, z_log_var, z], name=\"encoder\")\n\nencoder.summary()","0268628f":"plot_model(encoder, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","53cb646c":"latent_inputs = keras.Input(shape=(latent_dim,))\nx = layers.Dense(16 * 16 * 128, activation=\"relu\")(latent_inputs)\nx = layers.Reshape((16, 16, 128))(x)\n\nx = layers.Conv2DTranspose(128, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2DTranspose(64, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2DTranspose(32, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\nx = layers.Conv2DTranspose(16, kernel_size=(5,5), strides=(2,2), padding='SAME')(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(0.2)(x)\n\ndecoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()","f4bada75":"plot_model(decoder, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","ad71634d":"class VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def train_step(self, data):\n        if isinstance(data, tuple):\n            data = data[0]\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z = encoder(data)\n            reconstruction = decoder(z)\n            reconstruction_loss = tf.reduce_mean(\n                keras.losses.binary_crossentropy(data, reconstruction)\n            )\n            reconstruction_loss *= 28 * 28\n            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n            kl_loss = tf.reduce_mean(kl_loss)\n            kl_loss *= -0.5\n            total_loss = reconstruction_loss + kl_loss\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        return {\n            \"loss\": total_loss,\n            \"reconstruction_loss\": reconstruction_loss,\n            \"kl_loss\": kl_loss,\n        }","22ff318f":"trn_images = os.listdir('..\/input\/gan-getting-started\/monet_jpg')\ntrn_sizes = []\n\nfor i, img_path in enumerate(tqdm(trn_images)):\n    img = load_img(os.path.join('..\/input\/gan-getting-started\/monet_jpg',\n                                f'{img_path}'), target_size=(256, 256))\n    img_ary = img_to_array(img)\n    trn_sizes.append(img_ary.astype(\"float32\")\/255.0)\n    \ntrn_sizes = asarray(trn_sizes)","e2d6d984":"vae = VAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\nvae.fit(trn_sizes, \n        epochs=100, \n        batch_size=batch_size)","82d0909f":"# Encoder","d4e5e816":"## Encoder Plot","5a7c75fe":"# Decoder","a398b1c3":"# Modeling","51776f19":"## Decoder Plots","d39ffe61":"# Training","d1c683aa":"## Work In Progress","26bae3a6":"# Create Sampling Layer","4ac903be":"## Training Data"}}