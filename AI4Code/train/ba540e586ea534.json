{"cell_type":{"3b6e4fe4":"code","06625096":"code","5d6ad2d5":"code","54b13dc3":"code","3f15a547":"code","0c86abff":"code","4cf853bb":"code","62e32660":"code","d5fd321a":"code","ba179a5d":"code","55e3a722":"code","c1479846":"code","ee11d84d":"code","d40cca11":"code","70d63e25":"code","c207b1d7":"code","6fbbd632":"code","0d213a85":"code","59a4c70e":"code","69d697ac":"code","bba462ba":"code","58c331ac":"code","861ba310":"code","5f0fb3b6":"code","3053e70b":"code","dae1b21b":"code","10829471":"code","97fb491a":"code","1ade8f6b":"code","60e6a422":"code","bee32e7f":"code","68c454d5":"code","dd4b5a8a":"code","0ddeb5eb":"code","a6889db3":"code","dd315001":"code","f4b6a1d6":"code","eea55a4c":"code","a9ce9aa0":"code","71068a74":"code","482b88f8":"code","3e0985f9":"code","1f6be5ae":"code","53fcbf7a":"code","bced3ab8":"code","47da6e0f":"code","32a577f0":"code","fab9e5ac":"code","8ab7d4f6":"code","9bccc018":"code","82c3753e":"code","a3ace874":"code","d1416c85":"code","71054402":"code","de4b6c9e":"code","f6925f46":"code","cbe2c720":"code","e77bf758":"code","517106d4":"code","c4d8257f":"code","de505c7e":"code","ca7a4688":"code","ff398f23":"code","7c91dfa1":"code","0fabd578":"code","3dce35c1":"code","273bce77":"code","197a8f36":"code","575c88f2":"code","fd2d9036":"code","bee40dd3":"code","6f37ee24":"code","9a1c41d1":"code","6c7b2032":"code","6ec36a3b":"code","1e970cf6":"code","5dc8f89b":"code","10da2aa9":"code","d8809ffc":"code","495b8acc":"code","52d5caa6":"code","db18ee23":"code","281bb311":"code","5106163e":"code","dc6018a8":"code","b8eceb66":"code","8979f322":"code","10064da4":"code","84ea2903":"code","6075acd2":"code","ebf4d09d":"code","f76b3975":"code","9b5ed205":"code","1e745c58":"code","41bde590":"code","7e11bd43":"code","0276f243":"code","65d93ef3":"code","e195e287":"code","34ff5e73":"code","9480ce8e":"code","2c29f75e":"code","4fa9433d":"code","f248dc81":"code","7e343b0e":"code","30e9c4fb":"code","a91aebfa":"code","f2b3ae1e":"code","bb675e19":"code","46a9d1b6":"code","bfb832a8":"markdown","84121dd4":"markdown","e5c4fb69":"markdown","d6a84639":"markdown","f6bbc67c":"markdown","39da8ce6":"markdown","a73cc954":"markdown","eebd7297":"markdown","232dc691":"markdown","5d9010ea":"markdown","18a423e6":"markdown","0eef45fb":"markdown","5f21add2":"markdown","5f99c0fd":"markdown","ebeaa313":"markdown","f8f1227d":"markdown","9e5c2a26":"markdown","b6529501":"markdown","30e01c30":"markdown","353abb16":"markdown","7f403e40":"markdown","8614613a":"markdown","2eb23330":"markdown","d2fca06b":"markdown","1fa14ddc":"markdown","d2852f8b":"markdown","ce0780ba":"markdown","a1b3a32d":"markdown","398bab8e":"markdown","b3962e17":"markdown","0b3dcbc4":"markdown","8c6c144d":"markdown","8fe2ac02":"markdown","5fdc9519":"markdown","b2de54f5":"markdown","0dd3f831":"markdown","57d6b6a2":"markdown","6aecaa13":"markdown","ea391bc5":"markdown","673dda2f":"markdown","155ad098":"markdown","3fa6113d":"markdown","1228a5de":"markdown","3dee0d8a":"markdown","18bf9ed3":"markdown","d8feb746":"markdown","8688d6b7":"markdown","88702117":"markdown","12aa5321":"markdown","8275a91d":"markdown","6d3cb6b9":"markdown","f36abc0d":"markdown","1a6846d8":"markdown","832f0dba":"markdown","d10c98a9":"markdown","8a01f888":"markdown","50287cc1":"markdown","24b08d75":"markdown","00a9d713":"markdown","4f0101e3":"markdown","5f7c3d0f":"markdown","cd981693":"markdown","a8cf634a":"markdown","3ad605ad":"markdown","e72cb128":"markdown","10326ebf":"markdown","4d2417d4":"markdown","9e916992":"markdown","066ee641":"markdown","18a5c89e":"markdown","5466b760":"markdown","ef9d3105":"markdown","b8ef899b":"markdown","08ecce52":"markdown","b894ba1f":"markdown","eb3efe7e":"markdown","a5fd6dcd":"markdown","553fc01b":"markdown","22357f23":"markdown","b81a1933":"markdown","c74d2a76":"markdown","642f956a":"markdown","fa5e4f0c":"markdown","c787026a":"markdown"},"source":{"3b6e4fe4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom sklearn import preprocessing","06625096":"train_data = pd.read_csv('..\/input\/train.csv') #train_data\ntest_data = pd.read_csv('..\/input\/test.csv')  #test_data","5d6ad2d5":"train_data.head(5)","54b13dc3":"test_data.head(5)","3f15a547":"#Numerical features NaN value filling\n#train_data\nnum_feat_index = train_data.dtypes[train_data.dtypes != \"object\"].index\nprint('Train Data Numerical features are:' )\nprint(num_feat_index)\ntrain_num_na = train_data[num_feat_index].isnull().sum()\/len(train_data)\ntrain_num_na=train_num_na.drop(train_num_na[train_num_na == 0].index).sort_values(ascending = False)\ntrain_num_na = pd.DataFrame({'Train Data Missing Ratio': train_num_na})\ntrain_num_na","0c86abff":"plt.xticks(rotation = '0')\nsns.barplot(x=train_num_na.index, y=train_num_na.iloc[:,0])","4cf853bb":"#for column in ['LotFrontage','GarageYrBlt']:\n #   train_data[column]=train_data[column].fillna(train_data[column].mode()[0])\ntrain_data['LotFrontage']=train_data['LotFrontage'].fillna(train_data['LotFrontage'].mode()[0])","62e32660":"#Text type features NaN value filling\n#train_data\ntext_feat_index = train_data.dtypes[train_data.dtypes == \"object\"].index\nprint('Train Data Text Type features are:' )\nprint(text_feat_index)\ntrain_text_na = train_data[text_feat_index].isnull().sum()\/len(train_data)\ntrain_text_na=train_text_na.drop(train_text_na[train_text_na == 0].index).sort_values(ascending = False)\ntrain_text_na = pd.DataFrame({'Train Data Missing Ratio': train_text_na})\nplt.xticks(rotation = '90')\nsns.barplot(x = train_text_na.index, y = train_text_na.iloc[:,0])","d5fd321a":"train_text_na","ba179a5d":"train_data.loc[train_data['PoolArea']>0, ['PoolQC','PoolArea']]","55e3a722":"train_data['PoolQC']=train_data['PoolQC'].fillna('None')","c1479846":"columns = ['MiscFeature','Alley','Fence','FireplaceQu','Electrical']\nfor column in columns:\n    train_data[column] = train_data[column].fillna('None')","ee11d84d":"train_data.loc[train_data['GarageCars']==0, ['GarageArea','GarageCond','GarageQual','GarageFinish','GarageType','GarageCars','GarageYrBlt']].head(10)","d40cca11":"train_data.loc[train_data['GarageCars']==0, ['GarageYrBlt']] = train_data.loc[train_data['GarageCars']==0, ['GarageYrBlt']].fillna(0)\ntrain_data.loc[train_data['GarageCars']==0, ['GarageCond','GarageQual','GarageFinish','GarageType']]=train_data.loc[train_data['GarageCars']==0, ['GarageCond','GarageQual','GarageFinish','GarageType']].fillna('None')","70d63e25":"inx = (train_data['GarageCars']>0)&((train_data['GarageCond'].isnull())|(train_data['GarageQual'].isnull())|(train_data['GarageFinish'].isnull())|(train_data['GarageType'].isnull())|(train_data['GarageArea'].isnull())|(train_data['GarageYrBlt'].isnull()))\ntrain_data.loc[inx, ['GarageArea','GarageCars','GarageYrBlt','GarageCond','GarageQual','GarageFinish','GarageType']]","c207b1d7":"train_data[['GarageArea','GarageCars','GarageYrBlt','GarageCond','GarageQual','GarageFinish','GarageType']].isnull().sum()","6fbbd632":"train_data.loc[train_data['TotalBsmtSF']==0,['TotalBsmtSF','BsmtFinType1','BsmtFinType2','BsmtExposure','BsmtCond','BsmtQual']]","0d213a85":"for column in ['BsmtFinType1','BsmtFinType2','BsmtExposure','BsmtCond','BsmtQual']:\n    train_data[column]=train_data[column].fillna('None')","59a4c70e":"inx = train_data['MasVnrArea'].isnull() | train_data['MasVnrType'].isnull()\ntrain_data.loc[inx,['MasVnrArea','MasVnrType']]","69d697ac":"train_data['MasVnrType']=train_data['MasVnrType'].fillna('None')\ntrain_data['MasVnrArea'] = train_data['MasVnrArea'].fillna(0)","bba462ba":"print(len(text_feat_index[train_data[text_feat_index].isnull().sum()\/len(train_data)==0])\/len(text_feat_index)*100,'%')","58c331ac":"print(len(train_data.columns[train_data.isnull().sum()==0])\/len(train_data.columns)*100,'%')","861ba310":"# Function collecting dummies variables\ndef dummies(data, columns):\n    dummiesgroup = {}\n    for column in columns:\n        dummies = {}\n        variables = train_data[column].unique()\n        num = 1\n        for variable in variables:\n            if variable == 'None':\n                dummies[variable] = 0\n            else:\n                dummies[variable] = num\n            num += 1\n        dummiesgroup[column] = dummies\n    return(dummiesgroup)   ","5f0fb3b6":"dummiesgroup = dummies(train_data, text_feat_index)\ndummiesgroup","3053e70b":"new_train_data = train_data.copy()\nfor column in text_feat_index:\n    new_train_data[column] = train_data[column].map(dummiesgroup[column])","dae1b21b":"test_data.head(10)","10829471":"#test_data\nnum_feat_index = test_data.dtypes[test_data.dtypes != \"object\"].index\nprint('Test Data Numerical features are:' )\nprint(num_feat_index)\ntest_num_na = test_data[num_feat_index].isnull().sum()\/len(test_data)\ntest_num_na=test_num_na.drop(test_num_na[test_num_na == 0].index).sort_values(ascending = False)\ntest_num_na = pd.DataFrame({'Test Data Missing Ratio': test_num_na})\ntest_num_na","97fb491a":"#for column in ['LotFrontage','GarageYrBlt']:\n #   test_data[column]=test_data[column].fillna(train_data[column].mode()[0])\ntest_data['LotFrontage']=test_data['LotFrontage'].fillna(train_data['LotFrontage'].mode()[0])   ","1ade8f6b":"txt_feat_index = test_data.dtypes[test_data.dtypes == \"object\"].index\nprint('Test Data text type features are:' )\nprint(txt_feat_index)\ntest_txt_na = test_data[txt_feat_index].isnull().sum()\/len(test_data)\ntest_txt_na=test_txt_na.drop(test_txt_na[test_txt_na == 0].index).sort_values(ascending = False)\ntest_txt_na = pd.DataFrame({'Test Data Missing Ratio': test_txt_na})\ntest_txt_na","60e6a422":"test_data.loc[test_data['PoolArea']>0, ['PoolQC','PoolArea']]","bee32e7f":"test_data.loc[test_data['PoolArea']>0,'PoolQC'] = test_data.loc[test_data['PoolArea']>0,'PoolQC'].fillna(train_data.loc[train_data['PoolArea']>0,'PoolQC'].mode()[0])","68c454d5":"test_data.loc[test_data['PoolArea']==0,'PoolQC'] = test_data.loc[test_data['PoolArea']==0,'PoolQC'].fillna('None')","dd4b5a8a":"columns = ['MiscFeature','Alley','Fence','FireplaceQu']\nfor column in columns:\n    test_data[column] = test_data[column].fillna('None')","0ddeb5eb":"test_data.loc[test_data['GarageArea']==0, ['GarageArea','GarageCars','GarageYrBlt','GarageCond','GarageQual','GarageFinish','GarageType']].head(5)","a6889db3":"test_data.loc[test_data['GarageArea']==0, ['GarageArea','GarageCond','GarageQual','GarageFinish','GarageType']] = test_data.loc[test_data['GarageArea']==0, ['GarageArea','GarageCond','GarageQual','GarageFinish','GarageType']].fillna('None')\ntest_data.loc[test_data['GarageArea']==0,'GarageYrBlt'] = test_data.loc[test_data['GarageArea']==0,'GarageYrBlt'].fillna(0)","dd315001":"inx = (test_data['GarageArea'] > 0) & (test_data['GarageCond'].isnull() | test_data['GarageQual'].isnull() | test_data['GarageFinish'].isnull() | test_data['GarageType'].isnull() | (test_data['GarageYrBlt'].isnull()) | (test_data['GarageCars'].isnull()))\ntest_data.loc[inx, ['GarageArea','GarageCond','GarageQual','GarageFinish','GarageType','GarageCars','GarageYrBlt']]","f4b6a1d6":"test_data.loc[inx,'GarageCond'] = test_data.loc[inx,'GarageCond'].fillna(train_data.loc[train_data['GarageArea']>0,'GarageCond'].mode()[0])\ntest_data.loc[inx, 'GarageQual'] = test_data.loc[inx,'GarageQual'].fillna(train_data.loc[train_data['GarageArea']>0,'GarageQual'].mode()[0])\ntest_data.loc[inx,'GarageFinish'] = test_data.loc[inx,'GarageFinish'].fillna(train_data.loc[train_data['GarageType'] == 'Detchd','GarageFinish'].mode()[0])\ntest_data.loc[inx,'GarageYrBlt'] = test_data.loc[inx, 'GarageYrBlt'].fillna(train_data.loc[train_data['GarageArea'] > 0,'GarageYrBlt'].mode()[0])","eea55a4c":"test_data[['GarageArea','GarageCond','GarageQual','GarageFinish','GarageType']].isnull().sum()","a9ce9aa0":"inx = (test_data['GarageCond'].isnull() | test_data['GarageQual'].isnull() | test_data['GarageFinish'].isnull() | test_data['GarageType'].isnull())\ntest_data.loc[inx, ['GarageArea','GarageCond','GarageQual','GarageFinish','GarageType','GarageCars','GarageYrBlt']]","71068a74":"test_data.loc[inx,'GarageArea'] = test_data.loc[inx,'GarageArea'].fillna(train_data.loc[train_data['GarageType'] == 'Detchd','GarageArea'].mode()[0])\ntest_data.loc[inx,'GarageCars'] = test_data.loc[inx,'GarageCars'].fillna(train_data.loc[train_data['GarageType'] == 'Detchd','GarageCars'].mode()[0])\ntest_data.loc[inx,'GarageCond'] = test_data.loc[inx, 'GarageCond'].fillna(train_data.loc[train_data['GarageArea'] > 0,'GarageCond'].mode()[0])\ntest_data.loc[inx,'GarageQual'] = test_data.loc[inx, 'GarageQual'].fillna(train_data.loc[train_data['GarageArea'] > 0,'GarageQual'].mode()[0])\ntest_data.loc[inx,'GarageFinish'] = test_data.loc[inx, 'GarageFinish'].fillna(train_data.loc[train_data['GarageArea'] > 0,'GarageFinish'].mode()[0])\ntest_data.loc[inx,'GarageYrBlt'] = test_data.loc[inx, 'GarageYrBlt'].fillna(train_data.loc[train_data['GarageArea'] > 0,'GarageYrBlt'].mode()[0])","482b88f8":"test_data[['GarageArea','GarageCars','GarageYrBlt','GarageCond','GarageQual','GarageFinish','GarageType']].isnull().sum()","3e0985f9":"inx = test_data['MasVnrType'].isnull() | test_data['MasVnrArea'].isnull()\ntest_data.loc[inx, ['MasVnrType','MasVnrArea']]","1f6be5ae":"test_data.loc[(test_data['MasVnrType'].isnull()) & (test_data['MasVnrArea']>0),'MasVnrType'] = test_data.loc[(test_data['MasVnrType'].isnull()) & (test_data['MasVnrArea']>0),'MasVnrType'].fillna(train_data.loc[train_data['MasVnrArea']>0,'MasVnrType'].mode()[0])","53fcbf7a":"test_data.loc[inx,'MasVnrType'] = test_data.loc[inx,'MasVnrType'].fillna('None')\ntest_data.loc[inx,'MasVnrArea'] = test_data.loc[inx,'MasVnrArea'].fillna(0)","bced3ab8":"test_data[['MasVnrType','MasVnrArea']].isnull().sum()","47da6e0f":"inx = test_data['BsmtQual'].isnull()|test_data['BsmtCond'].isnull()|test_data['BsmtExposure'].isnull()|test_data['BsmtFinType1'].isnull()\\\n|test_data['BsmtFinType2'].isnull()|test_data['BsmtFinSF1'].isnull()|test_data['BsmtFinSF2'].isnull()|test_data['TotalBsmtSF'].isnull()\\\n|test_data['BsmtUnfSF'].isnull()|test_data['BsmtFullBath'].isnull()|test_data['BsmtHalfBath'].isnull()\ntest_data.loc[inx,['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF','BsmtFullBath','BsmtHalfBath']]","32a577f0":"inx1 = (test_data['BsmtQual'].isnull()|test_data['BsmtCond'].isnull()|test_data['BsmtExposure'].isnull()|test_data['BsmtFinType1'].isnull()\\\n|test_data['BsmtFinType2'].isnull())&((test_data['BsmtFinSF1'] == 0)&(test_data['BsmtFinSF2']==0)&(test_data['TotalBsmtSF']==0)\\\n&(test_data['BsmtUnfSF']==0)&(test_data['BsmtFullBath']==0)&(test_data['BsmtHalfBath']==0))\ntest_data.loc[inx1, ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF','BsmtFullBath','BsmtHalfBath']]","fab9e5ac":"test_data.loc[inx1, ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']]=test_data.loc[inx1, ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']].fillna('None')","8ab7d4f6":"inx = test_data['BsmtQual'].isnull()|test_data['BsmtCond'].isnull()|test_data['BsmtExposure'].isnull()|test_data['BsmtFinType1'].isnull()\\\n|test_data['BsmtFinType2'].isnull()|test_data['BsmtFinSF1'].isnull()|test_data['BsmtFinSF2'].isnull()|test_data['TotalBsmtSF'].isnull()\\\n|test_data['BsmtUnfSF'].isnull()|test_data['BsmtFullBath'].isnull()|test_data['BsmtHalfBath'].isnull()\ntest_data.loc[inx,['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF','BsmtFullBath','BsmtHalfBath']]","9bccc018":"test_data.loc[inx,['BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF','BsmtFullBath','BsmtHalfBath']] = test_data.loc[inx,['BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF','BsmtFullBath','BsmtHalfBath']].fillna(0)","82c3753e":"test_data.loc[inx,['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF','BsmtFullBath','BsmtHalfBath']]","a3ace874":"test_data.loc[test_data['TotalBsmtSF']==0,['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']] = test_data.loc[test_data['TotalBsmtSF']==0,['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']].fillna('None')\ntest_data.loc[inx,'BsmtExposure'] = test_data.loc[inx,'BsmtExposure'].fillna('No')\ntest_data.loc[inx, 'BsmtCond'] = test_data.loc[inx, 'BsmtCond'].fillna(train_data.loc[train_data['TotalBsmtSF']>0, 'BsmtCond'].mode()[0])\ntest_data.loc[inx, 'BsmtQual'] = test_data.loc[inx, 'BsmtQual'].fillna(train_data.loc[train_data['TotalBsmtSF']>0, 'BsmtQual'].mode()[0])","d1416c85":"inx1 = (test_data['BsmtQual'].isnull()|test_data['BsmtCond'].isnull()|test_data['BsmtExposure'].isnull()|test_data['BsmtFinType1'].isnull()\\\n|test_data['BsmtFinType2'].isnull())&((test_data['BsmtFinSF1'] == 0)&(test_data['BsmtFinSF2']==0)&(test_data['TotalBsmtSF']==0)\\\n&(test_data['BsmtUnfSF']==0)&(test_data['BsmtFullBath']==0)&(test_data['BsmtHalfBath']==0))\ntest_data.loc[inx1, ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2','TotalBsmtSF','BsmtUnfSF','BsmtFullBath','BsmtHalfBath']]","71054402":"inx = test_data['MSZoning'].isnull() | test_data['Utilities'].isnull() | test_data['Functional'].isnull()\ntest_data.loc[inx,['MSZoning', 'Utilities', 'Functional']]","de4b6c9e":"for column in ['MSZoning', 'Utilities', 'Functional']:\n    test_data.loc[inx,column] = test_data.loc[inx,column].fillna(train_data[column].mode()[0])","f6925f46":"inx = test_data['KitchenQual'].isnull()\ntest_data.loc[inx,'KitchenQual']","cbe2c720":"test_data.loc[inx,'KitchenQual'] = test_data.loc[inx,'KitchenQual'].fillna(train_data['KitchenQual'].mode()[0])","e77bf758":"inx = test_data['SaleType'].isnull()\ntest_data.loc[inx,'SaleType']","517106d4":"test_data.loc[inx, 'SaleType'] = test_data.loc[inx, 'SaleType'].fillna(train_data['SaleType'].mode()[0])","c4d8257f":"inx = test_data['Exterior1st'].isnull() | test_data['Exterior2nd'].isnull()\ntest_data.loc[inx,['Exterior1st','Exterior2nd']]","de505c7e":"test_data.loc[inx,['Exterior1st']] = test_data.loc[inx,['Exterior1st']].fillna(train_data['Exterior1st'].mode()[0])\ntest_data.loc[inx,['Exterior2nd']] = test_data.loc[inx, ['Exterior2nd']].fillna(train_data['Exterior2nd'].mode()[0])","ca7a4688":"print(len(test_data.columns[test_data.isnull().sum()==0])\/len(test_data.columns)*100,'%')","ff398f23":"new_test_data = test_data.copy()\nfor column in text_feat_index:\n    new_test_data[column] = test_data[column].map(dummiesgroup[column])","7c91dfa1":"new_test_data.head(5)","0fabd578":"train_x = new_train_data[['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\\\n       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\\\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\\\n       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\\\n       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\\\n       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\\\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\\\n       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\\\n       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\\\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\\\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\\\n       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\\\n       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\\\n       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\\\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\\\n       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\\\n       'SaleCondition']]","3dce35c1":"test_x = new_test_data[['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\\\n       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\\\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\\\n       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\\\n       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\\\n       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\\\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\\\n       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\\\n       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\\\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\\\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\\\n       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\\\n       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\\\n       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\\\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\\\n       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\\\n       'SaleCondition']]","273bce77":"scaler = preprocessing.MinMaxScaler()\ntrain_x = scaler.fit_transform(train_x)\ntest_x = scaler.transform(test_x)","197a8f36":"test_x","575c88f2":"train_x = pd.DataFrame(train_x, columns = ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\\\n       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\\\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\\\n       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\\\n       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\\\n       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\\\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\\\n       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\\\n       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\\\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\\\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\\\n       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\\\n       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\\\n       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\\\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\\\n       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\\\n       'SaleCondition'])\ntest_x = pd.DataFrame(test_x, columns = ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\\\n       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\\\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\\\n       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\\\n       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\\\n       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\\\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\\\n       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\\\n       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\\\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\\\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\\\n       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\\\n       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\\\n       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\\\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\\\n       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\\\n       'SaleCondition'])","fd2d9036":"train_x.head(5)","bee40dd3":"train_x.shape","6f37ee24":"test_x.head(5)","9a1c41d1":"sns.distplot(train_data['SalePrice'],fit=norm)\nmu, sigma = norm.fit(train_data['SalePrice'])\nplt.legend(['Normal dist.\\n($\\mu=$ {:.2f} and $\\sigma=$ {:.2f})'.format(mu,sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice Distribution')\nplt.figure()\nstats.probplot(train_data['SalePrice'],plot=plt)","6c7b2032":"train_y = np.log1p(train_data['SalePrice'])","6ec36a3b":"sns.distplot(train_y,fit=norm)\nmu,sigma = norm.fit(train_y)\nplt.legend(['Normal dist.\\n($\\mu=$ {:.2f} and $\\sigma=$ {:.2f})'.format(mu, sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('SalePrice Distribution')\nplt.figure()\nstats.probplot(train_data['SalePrice'],plot=plt)","1e970cf6":"corr = new_train_data.iloc[:,1::].corr()","5dc8f89b":"plt.subplots(figsize=(12,9))\nsns.heatmap(corr, vmax = 0.9, square=True)","10da2aa9":"#rank features according to the correlation coefficient with SalePrice \ncolumns = np.abs(corr['SalePrice']).sort_values(ascending = False).index[1::].tolist()\nprint(columns)","d8809ffc":"#Looking for high correlated variables\nn=0\ncolumnsA=[]\ncolumnsB=[]\nwhile n < len(columns):\n    if columns[n] not in columnsB:\n        cols = corr.columns[corr[columns[n]]>=0.8].tolist() #Assume corr coefficient 0.8 as valve value.\n        cols.remove(columns[n])\n        if len(cols)>0:\n            for col in cols:\n                if col!='SalePrice':\n                    columnsB.append(col)\n            print(n, columns[n], cols)\n        columnsA.append(columns[n])\n    n+=1","495b8acc":"print(columnsA)","52d5caa6":"print(columnsB)","db18ee23":"from sklearn.model_selection import KFold, cross_val_score, train_test_split\nn_folds = 5\ndef rmse_kfold(model):\n    kf = KFold(n_folds, shuffle = True, random_state = 42).get_n_splits(train_x[columnsA].values)\n    rmse = np.sqrt(-cross_val_score(model, train_x[columnsA].values, train_y, scoring = \"neg_mean_squared_error\", cv = kf ))\n    return(rmse)","281bb311":"from sklearn import linear_model\nlr = linear_model.LinearRegression()\nlr_loss = rmse_kfold(lr)","5106163e":"from sklearn.svm import SVR\n#linear kernel\nlinear_svr_loss = []\nfor i in [1,10,1e2]:\n#for i in [1,10,1e2,1e3,1e4]:\n    linear_svr = SVR(kernel = 'linear', C=i)\n    linear_svr_loss.append(rmse_kfold(linear_svr).mean())\nplt.plot([1,10,1e2],linear_svr_loss)\nplt.xlabel('C')\nplt.ylabel('mean-loss')","dc6018a8":"linear_svr = SVR(kernel = 'linear', C=1)\nlinear_svr_loss = rmse_kfold(linear_svr)","b8eceb66":"#poly kernel\nfor i in [1,10,1e2,1e3,1e4]:\n    poly_svr_loss=[]\n    for j in np.linspace(2,9,10):\n        poly_svr = SVR(kernel = 'poly',C=i, degree=j)\n        poly_svr_loss.append(rmse_kfold(poly_svr).mean())\n    plt.plot(np.linspace(2,9,10), poly_svr_loss, label='C='+str(i))\n    plt.legend()\nplt.xlabel('degree')\nplt.ylabel('mean-loss')","8979f322":"poly_svr = SVR(kernel = 'poly',C=100, degree=2)\npoly_svr_loss=rmse_kfold(poly_svr)","10064da4":"#rbf kernel\nfor i in [1,10,1e2,1e3,1e4]:\n    rbf_svr_loss = []\n    for j in np.linspace(0.1,1,10):\n        rbf_svr = SVR(kernel = 'rbf', C=i, gamma=j)\n        rbf_svr_loss.append(rmse_kfold(rbf_svr).mean())\n    plt.plot(np.linspace(0.1,1,10), rbf_svr_loss, label='C='+str(i))\n    plt.legend()\nplt.xlabel('gamma')\nplt.ylabel('mean-loss')","84ea2903":"rbf_svr = SVR(kernel = 'rbf',C=1,gamma=0.1)\nrbf_svr_loss = rmse_kfold(rbf_svr)","6075acd2":"from sklearn.neighbors import KNeighborsRegressor\nknn_loss = []\nfor n_neighbors in range(1,21):\n    knn = KNeighborsRegressor(n_neighbors, weights = 'uniform' )\n    knn_loss.append(rmse_kfold(knn).mean())\nplt.plot(np.linspace(1,20,20), knn_loss)\nplt.xlabel('n-neighbors')\nplt.ylabel('mean-loss')","ebf4d09d":"knn = KNeighborsRegressor(6, weights = 'uniform' )\nknn_loss = rmse_kfold(knn)","f76b3975":"from sklearn.tree import DecisionTreeRegressor\ndtr_loss=[]\nfor n in range(1,11):\n    dtr = DecisionTreeRegressor(max_depth = n)\n    dtr_loss.append(rmse_kfold(dtr).mean())\nplt.plot(np.linspace(1,10,10), dtr_loss)\nplt.xlabel('max_depth')\nplt.ylabel('mean-loss')","9b5ed205":"dtr = DecisionTreeRegressor(max_depth = 7)\ndtr_loss=rmse_kfold(dtr)","1e745c58":"from sklearn.kernel_ridge import KernelRidge    \n#linear kernel\nkr_linear_loss = []\nfor i in np.linspace(0.1,2.0,8):\n    kr = KernelRidge(alpha = i,kernel = 'linear')\n    kr_linear_loss.append(rmse_kfold(kr).mean())\nplt.plot(np.linspace(0.1,2.0,8), kr_linear_loss)\nplt.xlabel('alpha')\nplt.ylabel('mean-loss')","41bde590":"kr_linear = KernelRidge(alpha = 1.3,kernel = 'linear')\nkr_linear_loss = rmse_kfold(kr_linear)","7e11bd43":"#poly kernel\nfor j in np.linspace(0.1,2.0,8):\n    kr_poly_loss = []\n    for i in np.linspace(0.01,0.1,10):\n        kr = KernelRidge(alpha = j,kernel = 'poly', gamma = i)\n        kr_poly_loss.append(rmse_kfold(kr).mean())\n    plt.plot(np.linspace(0.01,0.1,10), kr_poly_loss,label='alpha:{:.2f}'.format(j))\n    plt.legend(loc='upper right')\nplt.xlabel('gamma')\nplt.ylabel('mean-loss')","0276f243":"kr_poly = KernelRidge(alpha = 0.1,kernel = 'poly',gamma = 0.05)\nkr_poly_loss = rmse_kfold(kr_poly)","65d93ef3":"#rbf kernel\nfor j in np.linspace(0.00001,0.0001,10):\n    kr_rbf_loss = []\n    for i in np.linspace(0.0005,0.02,10):\n        kr = KernelRidge(alpha = j,kernel = 'rbf', gamma = i)\n        kr_rbf_loss.append(rmse_kfold(kr).mean())\n    plt.plot(np.linspace(0.0005,0.02,10), kr_rbf_loss,label='alpha:{:.5f}'.format(j))\n    plt.legend(loc='upper right')\nplt.xlabel('gamma')\nplt.ylabel('mean-loss')","e195e287":"kr_rbf = KernelRidge(alpha = 0.0001,kernel = 'rbf', gamma = 0.0025)\nkr_rbf_loss=rmse_kfold(kr_rbf)","34ff5e73":"evaluating = {\n    'lr': lr_loss,\n    'linear_svr':linear_svr_loss,\n    'polyl_svr':poly_svr_loss,\n    'rbf_svr':rbf_svr_loss,\n    'knn':knn_loss,\n    'drt':dtr_loss,\n    'kr_linear':kr_linear_loss,\n    'kr_poly':kr_poly_loss,\n    'kr_rbf':kr_rbf_loss\n}\nevaluating = pd.DataFrame(evaluating)\nprint(evaluating)","9480ce8e":"evaluating.plot.hist()","2c29f75e":"evaluating.hist(color='k',alpha=0.6,figsize=(8,7))","4fa9433d":"evaluating.describe()","f248dc81":"n_folds = 5\ndef rmse_kfold1(model,corr_valve):\n    corr1 = pd.DataFrame(corr.loc[columnsA,'SalePrice'])\n    columns_split = corr1.loc[list(abs(corr1.loc[columnsA,'SalePrice'])>=corr_valve),'SalePrice'].index.tolist()\n    kf = KFold(n_folds, shuffle = True, random_state = 42).get_n_splits(train_x[columns_split].values)\n    rmse = np.sqrt(-cross_val_score(model, train_x[columns_split].values, train_y, scoring = \"neg_mean_squared_error\", cv = kf ))\n    return(rmse)","7e343b0e":"loss={}\nloss_mean={}\nfor valve in [0.5, 0.3, 0]:\n    model_loss=[]\n    model_mean_loss=[]\n    for model in [lr,linear_svr,poly_svr,rbf_svr,knn,dtr,kr_poly,kr_rbf]:\n        model_loss.append(rmse_kfold1(model,valve))\n        model_mean_loss.append(rmse_kfold1(model,valve).mean())\n    loss[str(valve)]=model_loss\n    loss_mean[str(valve)]=model_mean_loss","30e9c4fb":"sns.violinplot(data = pd.DataFrame(loss_mean))\nplt.xlabel('valve value')\nplt.ylabel('mean-loss')","a91aebfa":"loss_mean = pd.DataFrame(loss_mean,index = ['lr','linear_svr','poly_svr','rbf_svr','knn','dtr','kr_poly','kr_rbf'])","f2b3ae1e":"test_y_predict = np.expm1(rbf_svr.fit(train_x[columnsA].values,train_y).predict(test_x[columnsA].values))","bb675e19":"submission = pd.DataFrame()\nsubmission['Id'] = test_data['Id']\nsubmission['SalePrice'] = test_y_predict","46a9d1b6":"submission.to_csv('submission.csv',index = False)","bfb832a8":"When gamma is 0.1 and C is 1, the loss is minimum.","84121dd4":"In decision tree model, the tree depth need to be confirmed. The above figure shows that 7 could be best value.","e5c4fb69":"Check if all text type features filling work done.","d6a84639":"**KitchenQual**","f6bbc67c":"**Exterior**","39da8ce6":"The tendency of rmse value with gamma increased. Fix gamma equals 0.0025 and alpha equals 0.0001.","a73cc954":"Here, the 'SalePrice' looks like right skewed distribution. In order to boost our model predicting performance, I use log transform for target variable. As result, the distributon will be normal distribution. ","eebd7297":"When C is 1, the model loss value is minimum.","232dc691":"Following the way of thinking in train data, analyzing test data and handle it.","5d9010ea":"The result shows that the Masonry veneer related data match each other. No masonry veneer, no mas type, no mas area.  \nSo, easily, just fill 0 and None.","18a423e6":"## About Train Set","0eef45fb":"### Numerical Features","5f21add2":"Above output shows the strong correlated variables which corr efficient is over 0.7. The columnsA means relatively independent features and columnsB means the rest features after selection as shown as below.","5f99c0fd":"When alpha is set between 1.25 and 1.5 in linear kernel of KernelRidge, the rmse values reach minimum. Here, fix alpha equals 1.3.","ebeaa313":"These three class all have other related text type data, so we will analyzing them holding all data together later. ","f8f1227d":"**Linear regression**","9e5c2a26":"About pool, just two relevant information we have, PoolArea, PoolQC. Now, we just know there is pool by PoolArea, but we can't know the quality of it. ","b6529501":"Here, the result shows just one rowd data means missing type, others is one type, none masonry veneer.","30e01c30":"**Features about Basement**  \nThe same way as Garage feature, here is 5 basement features with Na.","353abb16":"**Features about Garage**  \nThe features about Garage covers t numerical type, like GarageArea and text type, like GarageType. The GarageArea is without Na, so, we could take it as a reference to judge other text type na value is 'None' or missing.","7f403e40":"Next, I will use columnsA as features to make model selection, and in final, I will try combining columnsB to see the effect on model performance.","8614613a":"# **4. Model Selection & Model Evaluation**","2eb23330":"Four models will be used:  \n- Linear regression  \n- Support vector machine regression  \n    1. Kernel 'linear'  \n    1. Kernel  'poly'\n    1. Kernel 'rbf'\n- Nearest neighbors regression  \n- Decision tree regression  \n- KernelRidge","d2fca06b":"**SaleType**","1fa14ddc":"Check if all features filling work done.","d2852f8b":"Till now, finally, this work has been done. Not perfect, in this project, I realise about model I truly need to learn much deeper. And also I need to be fast to make myself drop new project environment. Anyway, I will keep going and see next project.","ce0780ba":"**First of all**, before we start, we need to deeply understand what the problem is and what the variables means. ","a1b3a32d":"- ## Text Type Feature Transforming to Dummies Variable  ","398bab8e":"Check again, see any data is filling for garage.","b3962e17":"### **Model Selection**","0b3dcbc4":"**Masonry veneer Class**","8c6c144d":"**MSZoning & Utilities & Functional**","8fe2ac02":"Here, the information is missing, We don't know quality, interior finish and condition. ","5fdc9519":"### Text Type Features","b2de54f5":"**PoolQC**","0dd3f831":"**Features about Garage**  ","57d6b6a2":"**MasVnrType**","6aecaa13":"The above shows, all missing data about garage have been filled. ","ea391bc5":"Check each above feature's meaning based on data_description.txt file. If the data is surely missing, drop or filling.  \n**LotFrontage**:  linear feet of street connected to property.    \nReplace NaN with Mode.  \n**GarageYrBlt**: year garage was built.  \nConsidering the Garage has seven related variables which covered three numerical type and four text type, filling any data needed to refer to all attributes. I'll do this later.  \n**MasVnrArea**: masonry veneer area in square feet.\nThe NaN may have two meaning, none veneer or missing. Like Garage, do this later.","673dda2f":"Correlation map","155ad098":"Looks like it nees many steps to finish filling.","3fa6113d":"**SVR**","1228a5de":"### Numerical features","3dee0d8a":"- ## Text Type Feature Transforming to Dummies Variable  ","18bf9ed3":"Now, check if exists another situation that there is garage but missing garage type.","d8feb746":"**Masonry veneer Class & Garage Class & Basement Class**","8688d6b7":"## About Test Set","88702117":"- Locate no basement row","12aa5321":"In this step, just one thing I think needed to say, that I want to set 'None' as 0, Others variables will be set a number as sequence.","8275a91d":"The rmse is increased with degree increasing and the tendency of different C is almost same. At last, C set 100, degree set 2.","6d3cb6b9":"In the end of feature selection part, I ranked all features by the correlated efficient with SalePrice. At the same time, I seperate all features into two parts according to corr efficient between each features just for taking out some repetition content.","f36abc0d":"# **2. Feature Engineering**  \n- ## Missing data filling  \n    1. Numerical features NaN value filling  \n    1. Text type features NaN value filling ","1a6846d8":"**Nearest Neighbors Regression**","832f0dba":"Feature Analysis","d10c98a9":"From above result, we could know when Pool exists in house the evaluation value isn't missing. So, that also means the NaN in PoolQC just have one possible that there is no Pool. Here, the NaN of PoolQC will be filled as 0.","8a01f888":"**LotFrontage**","50287cc1":">****Absolutely, this is the first kaggle project for my data science career. I need to be familiar with the working way of all friends in data science and kaggle world. Hope this will be a piece of unforgetable experience and a good start for my kaggle career.  \nBenJ - September 2018****","24b08d75":"- ## 0-1 Standardization","00a9d713":"In KNN model, the number of neighbors need to be confirmed. The above figure shows that 6 could be best value. ","4f0101e3":"GarageArea and GarageCars both equal to 0 means no Garage, so other revelant garage features' value should 'None' or 0.","5f7c3d0f":"The No. 660 row, in which all features about basement are missing, just think as none basement","cd981693":"Untill now, the feature engineering work for train data and test data have been finished. A little tedious, sometimes boring. However, it's necessary. In this process, not only data transforming, nan data filling, but, more important, understanding what the data means.","a8cf634a":"# **3. Data Analysis & Feature Selection**","3ad605ad":"**Decision Tree Regression**","e72cb128":"The rmse value drop with alpha decreased and gamma has less effect on model than alpha. Here, fix alpha equals 0.1 and gamma equals 0.05. ","10326ebf":"Target data analysis","4d2417d4":"- Locate unsure row","9e916992":"Here, I select the 'rbf' SVR model as final model.","066ee641":"Like numerical features, checking each feature's meaning, then decide to drop or fill.   \n  \n**PoolQC**: Pool quality. We find 'PoolArea' is only feature relevant to PoolQC. Back to PoolArea, numerical feature without NaN value. So, we need to make sure NaN in PoolQC means No Pool or missing evaluation value.  \n**MiscFeature**: Miscellaneous feature not covered in other categories. NaN means no other misc features.  \n**Alley**: Na means no alley access.  \n**Fence**: Na means no fence.  \n**FireplaceQu**: Na means no fireplace.    \n**GarageCond**: Na means no garage.  \n**GarageQual**: Na means no garage.  \n**GarageFinish**: Na means no garage.  \n**GarageType**: Na means no garage.  \n**BsmtFinType1**: Na means no basement.  \n**BsmtFinType2**: Na means no basement.  \n**BsmtExposure**: Na means no basement.  \n**BsmtCond**: Na means no basement.  \n**BsmtQual**: Na means no basement.  \n**MasVnrType**: Na means no masonry veneer.  \n**Electrical**: Na means missing.  \n  \n  Note: I just fill na with 'None' as dummies variable.\n\n\n\n","18a5c89e":"- From above the first figure, clearly, KernelRidge's linear kernel is the worst and KernelRidges's rbf kernel seems well. \n- In the second figure, the loss of dtr and knnl are more closed and around 0.2. The others model's loss distribution are wide. Here, through range of x axis, 'linear' kernel, 'rbf' kernel and linear model seems better.","5466b760":"# **1. Data import and overview**","ef9d3105":"Through the above mean loss distribution, we can see that average level of model validation loss is lower with data dimention increased. On the other hand, with data dimention expanding, the performance of different models distributes much wider.","b8ef899b":"### Text Type Features","08ecce52":"**Basement**","b894ba1f":"**MiscFeature, Alley, Fence, FireplaceQu, Elecrical**  \nThese features we just think the na value means no this feature item. After all we have no way to judge if it has other possibility.","eb3efe7e":"**PoolQC**","a5fd6dcd":"Still information was missing, garage type is detached, so garage area could not be 0.  ","553fc01b":"**MiscFeature, Alley, Fence, FireplaceQu**  \nThese features we just think the na value means no this feature item. After all we have no way to judge if it has other possibility.","22357f23":"Through overview train_data and test_data, there are several more important things to do.\n1. Some text type variables need transforming to dummies variable. Test data should keep same rules with train data.\n2. Some features covered the NaN value need be filling or dropping.\n3. In feature engineering, numerical variables need to tranform as normal distribution.","b81a1933":"### **Model Evaluation**","c74d2a76":"**Kernel Ridge**","642f956a":"Here, normally, I just need to select top 10 features in rank of correlation coefficient. However, in practical case, this way should be carefully used. Actually, we should make sure the selected features are independent for each other high rank features. Of course, you could give this step up if you ignore the dimention disaster. Otherwise, when the model confirmed, this part could optimize our model.","fa5e4f0c":"If GarageArea is equal to 0, that make sense other Garage relevant column is null. So, just filling 'None'.","c787026a":"### **The effect of Data Import Dimension on Model Performance**"}}