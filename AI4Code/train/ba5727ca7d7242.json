{"cell_type":{"b590e29f":"code","9f80930f":"code","b549f38f":"code","d22188f2":"code","42dd3592":"code","098e5ca8":"code","f5a0099c":"code","fb26eb4e":"code","b2592163":"code","06a040a6":"code","95305592":"code","f228c23a":"code","2506a7cc":"code","9e9cd875":"code","b790eea1":"code","09830fd0":"code","d9ff6229":"code","4e8c275b":"code","0044262a":"code","640cb139":"code","7e19e249":"code","2902fcaf":"markdown","8ec7161a":"markdown","5e4b060c":"markdown","ab9b4a7a":"markdown","2f604286":"markdown"},"source":{"b590e29f":"import warnings\nwarnings.filterwarnings(\"ignore\")","9f80930f":"# General Libs\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,Dense, BatchNormalization, Dropout, Flatten, Conv2D, MaxPooling2D,Activation\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\n\nimport tensorflow as tf\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline","b549f38f":"# Alguns par\u00e2metros para leitura do dataset\nim_shape = (200,200)\n\nTRAINING_DIR = '..\/input\/chest-xray-pneumoniacovid19tuberculosis\/train'\nTEST_DIR = '..\/input\/chest-xray-pneumoniacovid19tuberculosis\/test'\nVAL_DIR = '..\/input\/chest-xray-pneumoniacovid19tuberculosis\/val'\n\nseed = 10\nBATCH_SIZE = 16","d22188f2":"#Using keras ImageGenerator and flow_from_directoty\n\n# Image dataset \n# With augmentation\n\n# data_generator = ImageDataGenerator(\n#        validation_split=0.2, rotation_range=5, width_shift_range=0.05,\n#        height_shift_range=0.05, preprocessing_function=preprocess_input,\n#        zoom_range=0.05, horizontal_flip=True, fill_mode='nearest')\n\n# Image dataset \n# Without augmentation\ndata_generator = ImageDataGenerator(validation_split=0.2,preprocessing_function=preprocess_input)\n\nval_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.2)","42dd3592":"\n# Generator para parte train\ntrain_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=True, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n# Generator para parte valida\u00e7\u00e3o\nvalidation_generator = val_data_generator.flow_from_directory(VAL_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n\n# Generator para dataset de teste\ntest_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\ntest_generator = test_generator.flow_from_directory(TEST_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n\nnb_train_samples = train_generator.samples\nnb_validation_samples = validation_generator.samples\nnb_test_samples = test_generator.samples\nclasses = list(train_generator.class_indices.keys())\nprint('Classes: '+str(classes))\nnum_classes  = len(classes)","098e5ca8":"# Visualizando alguns exemplos do dataset por meio do Generator criado\nplt.figure(figsize=(15,15))\nfor i in range(9):\n    #gera subfigures\n    plt.subplot(330 + 1 + i)\n    batch = train_generator.next()[0]*255\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","f5a0099c":"modelcnn = Sequential()\nmodelcnn.add(Conv2D(16, kernel_size=(3, 3),activation='relu',input_shape=(im_shape[0],im_shape[1],3)))\nmodelcnn.add(MaxPooling2D(pool_size=(2, 2)))\nmodelcnn.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodelcnn.add(MaxPooling2D(pool_size=(2, 2)))\nmodelcnn.add(Dropout(0.2))\nmodelcnn.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodelcnn.add(MaxPooling2D(pool_size=(2, 2)))\nmodelcnn.add(Flatten())\nmodelcnn.add(Dense(100, activation='relu'))\nmodelcnn.add(Dropout(0.2))\nmodelcnn.add(Dense(num_classes, activation='softmax'))\nmodelcnn.summary()\n\nmodelcnn.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","fb26eb4e":"epochs = 10\n\n#Callback to save the best model\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='modelcnn.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,verbose=1)\n]\n\n#Training\nhistory = modelcnn.fit(\n        train_generator,\n        steps_per_epoch=nb_train_samples \/\/ BATCH_SIZE,\n        epochs=epochs,\n        callbacks = callbacks_list,\n        validation_data=validation_generator,\n        verbose = 1,\n        validation_steps=nb_validation_samples \/\/ BATCH_SIZE)","b2592163":"val_loss = list()\nval_accuracy = list()\ntest_loss= list()\ntest_accuracy = list()","06a040a6":"# Load the best saved model\nfrom tensorflow.keras.models import load_model\n\n#model = load_model('..\/input\/classify-food-datas-models\/model.h5')\n#modelcnn = load_model('modelcnn.h5')\nscore = modelcnn.evaluate_generator(validation_generator)\nval_loss.append(score[0])\nval_accuracy.append(score[1])\nprint('\\n\\nVal loss:', score[0])\nprint('Val accuracy:', score[1])\n\nscore = modelcnn.evaluate_generator(test_generator)\nprint('\\nTest loss:', score[0])\nprint('Test accuracy:', score[1])\n\ntest_loss.append(score[0])\ntest_accuracy.append(score[1])","95305592":"import itertools\n#Gera matriz de confus\u00e3o\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","f228c23a":"from sklearn.metrics import classification_report, confusion_matrix\n\n#Confution Matrix and Classification Report\nY_pred = modelcnn.predict_generator(test_generator)#, nb_test_samples \/\/ BATCH_SIZE, workers=1)\ny_pred = np.argmax(Y_pred, axis=1)\ntarget_names = classes\n\n#Confution Matrix\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","2506a7cc":"#Using keras ImageGenerator and flow_from_directoty\n\n# Image dataset \n# With augmentation\n\n# Image dataset \n# With augmentation\n\n# data_generator = ImageDataGenerator(\n#        validation_split=0.2, rotation_range=5, width_shift_range=0.05,\n#        height_shift_range=0.05, preprocessing_function=preprocess_input,\n#        shear_range=0.05,\n#        zoom_range=0.05, horizontal_flip=True, fill_mode='nearest')\n\n# Image dataset \n# Without augmentation\ndata_generator = ImageDataGenerator(validation_split=0.2,preprocessing_function=preprocess_input)\n\nval_data_generator = ImageDataGenerator( preprocessing_function=preprocess_input,validation_split=0.2)","9e9cd875":"\n# Generator para parte train\ntrain_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=True, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n# Generator para parte valida\u00e7\u00e3o\nvalidation_generator = val_data_generator.flow_from_directory(VAL_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n\n# Generator para dataset de teste\ntest_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\ntest_generator = test_generator.flow_from_directory(TEST_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n\nnb_train_samples = train_generator.samples\nnb_validation_samples = validation_generator.samples\nnb_test_samples = test_generator.samples\nclasses = list(train_generator.class_indices.keys())\nprint('Classes: '+str(classes))\nnum_classes  = len(classes)","b790eea1":"# Visualizando alguns exemplos do dataset por meio do Generator criado\nplt.figure(figsize=(15,15))\nfor i in range(9):\n    #gera subfigures\n    plt.subplot(330 + 1 + i)\n    batch = train_generator.next()[0]*255\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","09830fd0":"base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(im_shape[0], im_shape[1], 3))\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(120, activation='relu')(x)\npredictions = Dense(num_classes, activation='softmax', kernel_initializer='random_uniform')(x)\n\nmodeltrf = Model(inputs=base_model.input, outputs=predictions)\n\n# Freezing pretrained layers\nfor layer in base_model.layers:\n    layer.trainable=False\n    \noptimizer = Adam()\nmodeltrf.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])","d9ff6229":"epochs = 10\n\n# Saving the best model\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='modeltrf.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n]\n\nhistory = modeltrf.fit(\n        train_generator,\n        steps_per_epoch=nb_train_samples \/\/ BATCH_SIZE,\n        epochs=epochs,\n        callbacks = callbacks_list,\n        validation_data=validation_generator,\n        verbose = 1,\n        validation_steps=nb_validation_samples \/\/ BATCH_SIZE)","4e8c275b":"# from tensorflow.keras.models import load_model\n# Load the best saved model\n# model = load_model('modeltrf.h5')","0044262a":"# Using the validation dataset\nscore = modeltrf.evaluate_generator(validation_generator)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","640cb139":"# Using the test dataset\nscore = modeltrf.evaluate_generator(test_generator)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","7e19e249":"# Some reports\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\n#Confution Matrix and Classification Report\nY_pred = modeltrf.predict_generator(test_generator)#, nb_test_samples \/\/ BATCH_SIZE, workers=1)\ny_pred = np.argmax(Y_pred, axis=1)\ntarget_names = classes\n\n#Confution Matrix\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","2902fcaf":"# Transfer Learning from a Deep Model","8ec7161a":"# Uso de CNN com Augmentation","5e4b060c":"# Lendo o dataset","ab9b4a7a":"# Inicializa\u00e7\u00e3o","2f604286":"**Aluno:** Lelson Lopes Nascimento\n\n**Discipina:** Deep Learning \n\n**Curso:** Especializa\u00e7\u00e3o em Ci\u00eancia de Dados\n\n**Professor:** Carlos Maur\u00edcio Serodio Figueiredo\n\n\n**Resumo:**\n\nEsta atividade visa comparar uma implementa\u00e7\u00e3o com CNN e uma usando transfer learning para aprendizado sobre avalia\u00e7\u00e3o de imagens de Raio-x de pulm\u00e3o. \n\n\n**Data set:** https:\/\/www.kaggle.com\/jtiptj\/chest-xray-pneumoniacovid19tuberculosis\n\n"}}