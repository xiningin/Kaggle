{"cell_type":{"28a207b6":"code","b3139ec0":"code","30a1b038":"code","61d30ad4":"code","991fed4a":"code","b1b702e3":"code","be511af4":"code","dee6573e":"code","edd095c5":"code","6367207d":"code","da6fe56b":"code","1c60c8cc":"code","7de2019d":"code","7aa44d68":"code","4d29f503":"code","34bab0fa":"code","868b9f01":"code","c198fb5f":"code","848b5045":"code","4c979e85":"code","0cf42dc9":"code","13e7d473":"code","c961e988":"code","32ed4e41":"markdown","ff1a5f11":"markdown"},"source":{"28a207b6":"# import libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # plot\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b3139ec0":"# load data\ndf = pd.read_csv(\"..\/input\/cardio_train.csv\",sep=';')\ndf.head()","30a1b038":"# drop 'id' column \ndf.drop('id',axis=1,inplace=True)","61d30ad4":"df.info()","991fed4a":"df.describe()","b1b702e3":"# visualize cardio with gender\nsns.countplot(x='cardio',data=df,hue='gender',palette='rainbow')","be511af4":"# distribution wrt age\nsns.boxplot(x='cardio',y='age',data=df)","dee6573e":"plt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nsns.boxplot(x='cardio',y='height',data=df,palette='winter')\nplt.subplot(1,2,2)\nsns.boxplot(x='cardio',y='weight',data=df,palette='summer')","edd095c5":"# correlations with target class\ncorrelations = df.corr()['cardio'].drop('cardio')\nprint(correlations)","6367207d":"def feat_select(threshold):\n    abs_cor = correlations.abs()\n    features = abs_cor[abs_cor > threshold].index.tolist()\n    return features","da6fe56b":"def model(mod,X_tr,X_te):\n    mod.fit(X_tr,y_train)\n    pred = mod.predict(X_te)\n    print('Model score = ',mod.score(X_te,y_test)*100,'%')","1c60c8cc":"# split data\nmsk = np.random.rand(len(df))<0.85\ndf_train_test = df[msk]\ndf_val = df[~msk]\n\nX = df_train_test.drop('cardio',axis=1)\ny = df_train_test['cardio']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=70)","7de2019d":"# for logistic regression\nlr = LogisticRegression()","7aa44d68":"threshold = [0.001,0.002,0.005,0.01,0.05,0.1]\nfor i in threshold:\n    print('\\n',i)\n    feature_i = feat_select(i)\n    X_train_i = X_train[feature_i]\n    X_test_i = X_test[feature_i]\n    model(lr,X_train_i,X_test_i)","4d29f503":"scale = StandardScaler()\nscale.fit(X_train)\nX_train_scaled = scale.transform(X_train)\nX_train_ = pd.DataFrame(X_train_scaled,columns=df.columns[:-1])","34bab0fa":"scale.fit(X_test)\nX_test_scaled = scale.transform(X_test)\nX_test_ = pd.DataFrame(X_test_scaled,columns=df.columns[:-1])","868b9f01":"# optimum k with optimum threshold\nfor i in threshold:\n    feature = feat_select(i)\n    X_train_k = X_train_[feature]\n    X_test_k = X_test_[feature]\n    err = []\n    for j in range(1,30):\n        knn = KNeighborsClassifier(n_neighbors=j)\n        knn.fit(X_train_k,y_train)\n        pred_j = knn.predict(X_test_k)\n        err.append(np.mean(y_test != pred_j))\n\n    plt.figure(figsize=(10,6))\n    plt.plot(range(1,30),err)\n    plt.xlabel('K value')\n    plt.ylabel('Error')","c198fb5f":"# final feature selection with threshold 0.05\nfeat_final = feat_select(0.05)\nprint(feat_final)","848b5045":"# scaling the val data as well\nX_train = X_train_[feat_final]\nX_val = np.asanyarray(df_val[feat_final])\ny_val = np.asanyarray(df_val['cardio'])\n\nscale.fit(X_val)\nX_val_scaled = scale.transform(X_val)\nX_val_ = pd.DataFrame(X_val_scaled,columns=df_val[feat_final].columns)","4c979e85":"# knn with k=15\nknn = KNeighborsClassifier(n_neighbors=15)\nknn.fit(X_train,y_train)\npred = knn.predict(X_val_)","0cf42dc9":"# reports\nprint('Confusion Matrix =\\n',confusion_matrix(y_val,pred))\nprint('\\n',classification_report(y_val,pred))","13e7d473":"# Logistic regression\nlr.fit(X_train,y_train)\npred = lr.predict(X_val_)","c961e988":"# reports\nprint('Confusion Matrix =\\n',confusion_matrix(y_val,pred))\nprint('\\n',classification_report(y_val,pred))","32ed4e41":"Both give more or less the similar results. I am planning to work on this project to improve performance.","ff1a5f11":"# Cardiovascular disease prediction\n\nThis code uses 2 algorithms to serve the purpose.\nFurther imporovement is to made."}}