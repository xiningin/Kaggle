{"cell_type":{"88c97177":"code","aa2c77ef":"code","d63dfac1":"code","5cda0178":"code","52b5aa7b":"code","d9037577":"code","2be6b308":"code","a11a5108":"code","34c89cd3":"code","6823c66a":"code","62c3bbac":"code","1d04d96e":"code","20dbc721":"code","6da1eb31":"code","2ff4983a":"markdown","ecef53ab":"markdown","72382fb7":"markdown","b802cc22":"markdown","e6f53905":"markdown","fd333a38":"markdown","f9c21eab":"markdown","4e584e08":"markdown","bb570507":"markdown","062eb084":"markdown","2b99eab7":"markdown"},"source":{"88c97177":"!pip install -q --upgrade wandb\nimport wandb\nprint(wandb.__version__)\nfrom wandb.keras import WandbCallback\n\nwandb.login()","aa2c77ef":"import tensorflow as tf\nprint(tf.__version__)\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import mixed_precision\n\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\n\nimport os\nimport gc\nimport json\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom functools import partial\n\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import train_test_split","d63dfac1":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)","5cda0178":"TRAIN_PATH = '..\/input\/seti-breakthrough-listen\/train\/'\nAUTOTUNE = tf.data.AUTOTUNE\n\nCONFIG = dict (\n    img_width = 224,\n    img_height = 224,\n    batch_size = 32,\n    epochs = 100,\n    learning_rate = 1e-3,\n    competition = 'seti',\n    _wandb_kernel = 'ayut',\n    architecture = \"CNN\",\n    infra = \"Kaggle\",\n)","52b5aa7b":"# Note: Please run this cell once and run all your experiments using the train_df and valid_df.\ndf = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ndf = df.sample(5000).reset_index(drop=True)\nprint(f'Number of train images: {len(df)}')\ndf['img_path'] = df['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')\n\ntrain_df, valid_df = train_test_split(df, test_size=0.2, stratify=df['target'].values)\nprint(len(train_df), len(valid_df))\ndf.head()","d9037577":"class_weights = compute_class_weight('balanced', \n                                    classes=np.unique(train_df['target'].values),\n                                    y=train_df['target'].values)\n\nclass_weights_dict = {key: val for key, val in zip(np.unique(train_df['target'].values), class_weights)}\nclass_weights_dict                                                         ","2be6b308":"def load_npy(path, mode):\n    # load npy data\n    data = np.load(path.numpy()).astype(np.float32)\n    \n    if mode==0:\n        # channel wise full stack\n        data = np.dstack((data[0], data[1], data[2], data[3], data[4], data[5])) \n        return data # (273, 256, 6)\n    \n    elif mode==1:\n        # channel wise target stack\n        data = np.dstack((data[0], data[2], data[4]))\n        return data # (273, 256, 3)\n    \n    elif mode==2:\n        # Spatially stack spectrograms\n        data = np.vstack(data).transpose((1, 0))\n        data = tf.expand_dims(data, -1)\n        return data # (256, 1638, 1)\n    \n    elif mode==3:\n        # Spatially stack target spectrograms\n        data = np.vstack((data[0], data[2], data[4])).transpose((1, 0))\n        data = tf.expand_dims(data, -1)\n        return data # (256, 819, 1)\n    \n    elif mode==4:\n        # Spatially stack target and normalize\n        data = np.vstack((data[0], data[2], data[4])).transpose((1, 0))\n        data = ((data - np.mean(data, axis=0)) \/ np.std(data, axis=0))\n        data = tf.expand_dims(data, -1)\n        return data # (256, 819, 1)\n    \n    elif mode==5:\n        # Spatially stack target spectrograms, clip and then normalize\n        data = np.vstack((data[0], data[2], data[4])).transpose((1, 0))\n        data = ((np.clip(data, -1, 3) + 1) \/ 4 * 255).astype(np.uint8)\n        data = tf.image.convert_image_dtype(data, tf.float32)\n        data = tf.expand_dims(data, -1)\n        return data # (256, 819, 1)\n    \n@tf.function\ndef load_resize_spec(df_dict, mode):\n    # Load image\n    [image,] = tf.py_function(load_npy, [df_dict['img_path'], mode], [tf.float32])\n    \n    if mode==0:\n        image.set_shape((273, 256, 6))\n    elif mode==1:\n        image.set_shape((273, 256, 3))\n    elif mode==2:\n        image.set_shape((256, 1638, 1))\n    elif mode==3 or mode==4 or mode==5:\n        image.set_shape((256, 819, 1))\n    \n    # Resize image\n    image = tf.image.resize(image, (CONFIG['img_height'], CONFIG['img_width'])) # (224, 224, channel)\n    # Simple augmentations\n    image = tf.image.random_flip_left_right(image)\n    \n    # Parse label\n    label = df_dict['target']\n    label = tf.one_hot(label, depth=2)\n    \n    return image, label\n\n# Mixup\n@tf.function\ndef mixup(a, b, alpha=1.0):\n    # unpack (image, label) pairs\n    (image1, label1), (image2, label2) = a, b\n\n    # define beta distribution\n    dist = tfd.Beta([alpha], [alpha])\n    # sample from this distribution\n    l = dist.sample(1)[0][0]\n\n    # mixup augmentation\n    img = l*image1+(1-l)*image2\n    lab = l*label1+(1-l)*label2\n\n    return img, lab","a11a5108":"AUTOTUNE = tf.data.AUTOTUNE\n\ndef get_dataloaders(train_df, valid_df, mode):\n    # Train Loader\n    trainloader = tf.data.Dataset.from_tensor_slices(dict(train_df))\n    # Valid Loader\n    validloader = tf.data.Dataset.from_tensor_slices(dict(valid_df))\n\n    trainloader = (\n        trainloader\n        .shuffle(1024)\n        .map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n\n    validloader = (\n        validloader\n        .map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n    \n    return trainloader, validloader\n\n\ndef get_mixup_dataloaders(train_df, valid_df, mode, alpha=1.0):\n    # Train Loader\n    trainloader1 = tf.data.Dataset.from_tensor_slices(dict(train_df)).shuffle(1024).map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n    trainloader2 = tf.data.Dataset.from_tensor_slices(dict(train_df)).shuffle(1024).map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n\n    trainloader = tf.data.Dataset.zip((trainloader1, trainloader2))\n\n    # Valid Loader\n    validloader = tf.data.Dataset.from_tensor_slices(dict(valid_df))\n\n    trainloader = (\n        trainloader\n        .shuffle(1024)\n        .map(partial(mixup, alpha=alpha), num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n\n    validloader = (\n        validloader\n        .map(partial(load_resize_spec, mode=mode), num_parallel_calls=AUTOTUNE)\n        .batch(CONFIG['batch_size'])\n        .prefetch(AUTOTUNE)\n    )\n    \n    return trainloader, validloader","34c89cd3":"#sanity check\n# Prepare dataloaders\ntrainloader, validloader = get_mixup_dataloaders(train_df, valid_df, 5)\nimgs, labels = next(iter(trainloader))","6823c66a":"def get_model(mode):\n    base_model = tf.keras.applications.EfficientNetB0(input_shape=(CONFIG['img_height'], CONFIG['img_width'], 3), include_top=False, weights='imagenet')\n    base_model.trainabe = True\n\n    if mode==0:\n        inputs = layers.Input((CONFIG['img_height'], CONFIG['img_width'], 6))\n        x = layers.Conv2D(3, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(inputs)\n    elif mode==1:\n        inputs = layers.Input((CONFIG['img_height'], CONFIG['img_width'], 3))\n        x = inputs\n    else:\n        inputs = layers.Input((CONFIG['img_height'], CONFIG['img_width'], 1))\n        x = layers.Conv2D(3, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(inputs)\n        \n    x = base_model(x, training=True)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.5)(x)\n    \n    outputs = layers.Dense(2)(x)\n    outputs = layers.Activation('sigmoid', dtype='float32', name='predictions')(outputs)\n    \n    return models.Model(inputs, outputs)\n\ntf.keras.backend.clear_session() \nmodel = get_model(mode=1)\nmodel.summary()","62c3bbac":"# Callbacks\nearlystopper = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=5, verbose=0, mode='min',\n    restore_best_weights=True\n)","1d04d96e":"MODES = {\n    'channel-wise-full': 0,\n    'channel-wise-target': 1, \n    'spatial-full': 2,\n    'spatial-target': 3, \n    'spatial-target-normalize': 4,\n    'spatial-target-clip': 5\n}\nMODES_ID_TO_EXP = {val: key for key, val in MODES.items()}\n\nUSE_MIXUP = True\nmode = MODES['spatial-target-clip'] # Please change the key here\nexp_name = MODES_ID_TO_EXP[mode]\n\nprint(f'Running the experiment : {exp_name} and with\/without mixup: {USE_MIXUP}')","20dbc721":"# Prepare dataloaders\nif USE_MIXUP:\n    trainloader, validloader = get_dataloaders(train_df, valid_df, mode=mode)\nelse:\n    trainloader, validloader = get_mixup_dataloaders(train_df, valid_df, mode=mode)\n\nSEEDS = [42, 64, 524]\n\nfor i in range(3):\n    # Initialize model\n    tf.keras.backend.clear_session()\n    tf.random.set_seed(SEEDS[i])\n    model = get_model(mode=mode)\n\n    # Compile model\n    optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG['learning_rate'])\n    model.compile(optimizer, \n                  loss='binary_crossentropy',\n                  metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\n\n    # Update CONFIG dict with the name of the model.\n    CONFIG['seed'] = SEEDS[i]\n    CONFIG['model_name'] = 'EfficientNetB0'\n    CONFIG['group'] = exp_name\n    print('Training configuration: ', CONFIG)\n\n    # Initialize W&B run\n    run = wandb.init(project='kaggle-seti-exp', \n                     config=CONFIG,\n                     group=CONFIG['group'], \n                     job_type='train')\n\n    # Train\n    _ = model.fit(trainloader, \n                  epochs=CONFIG['epochs'],\n                  validation_data=validloader,\n                  class_weight=class_weights_dict,\n                  callbacks=[WandbCallback(),\n                             earlystopper])\n\n    # Evaluate\n    loss, auc = model.evaluate(validloader)\n    wandb.log({'Val AUC-ROC': auc})\n\n    # Close W&B run\n    run.finish()\n\n    del model\n    _ = gc.collect()","6da1eb31":"ALPHAS = [0.2, 0.4, 0.6, 0.8, 1.0]\nVAL_AUC_ROC = []\nSEEDS = [42, 64, 524]\n\nfor alpha in ALPHAS:\n    # Prepare dataloaders\n    trainloader, validloader = get_mixup_dataloaders(train_df, valid_df, mode=mode, alpha=alpha)\n    # Run the experiment 3 times.\n    for i in range(3):\n        # Initialize model\n        tf.keras.backend.clear_session()\n        tf.random.set_seed(SEEDS[i])\n        model = get_model(mode=mode)\n\n        # Compile model\n        optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG['learning_rate'])\n        model.compile(optimizer, \n                      loss='binary_crossentropy',\n                      metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\n\n        # Update CONFIG dict with the name of the model.\n        CONFIG['seed'] = SEEDS[i]\n        CONFIG['model_name'] = 'EfficientNetB0'\n        CONFIG['group'] = f'Mixup-Alpha-{alpha}'\n        print('Training configuration: ', CONFIG)\n\n        # Initialize W&B run\n        run = wandb.init(project='kaggle-seti-exp2', \n                         config=CONFIG,\n                         group=CONFIG['group'], \n                         job_type='train')\n\n        # Train\n        _ = model.fit(trainloader, \n                      epochs=CONFIG['epochs'],\n                      validation_data=validloader,\n                      class_weight=class_weights_dict,\n                      callbacks=[WandbCallback(),\n                                 earlystopper])\n\n        # Evaluate\n        loss, auc = model.evaluate(validloader)\n        VAL_AUC_ROC.append(auc)\n        wandb.log({'Val AUC-ROC': auc})\n\n        # Close W&B run\n        run.finish()\n\n        del model\n        _ = gc.collect()","2ff4983a":"## [Check out the dasbhboard here $\\rightarrow$](https:\/\/wandb.ai\/ayush-thakur\/kaggle-seti-exp?workspace=user-ayush-thakur) \n\n## [Experiment summary report here $\\rightarrow$](http:\/\/wandb.me\/seti-img-mixup-exp)\n\n![img](https:\/\/i.imgur.com\/InH4hEi.gif)","ecef53ab":"## [Check out the W&B Dashboard here $\\rightarrow$](http:\/\/wandb.me\/kaggle-seti-alpha-mixup)\n\n![img](https:\/\/i.imgur.com\/Ca02x9U.gif)","72382fb7":"# Experiments to Run: Select the experiment mode","b802cc22":"# Callbacks","e6f53905":"# \ud83d\ude84 Train to find best image arrangement\n\nYou can find the detailed summary in this discussion post [here](https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/245152). For an interactive summary check out this [W&B report](http:\/\/wandb.me\/seti-img-mixup-exp). ","fd333a38":"# Find the best alpha value for Mixup\n\nThe mixup augmentation mixes two images pixel-wise and mixes their labels as well. This is done by weighted element-wise sum where the weight is sampled from the [Beta Distribution](https:\/\/en.wikipedia.org\/wiki\/Beta_distribution). \n\nThe Beta distribution depends on two parameters - `alpha` and `beta`. In the context of Mixup, the `alpha` and `beta` takes the same value and the value is less or equal to 1.0. You can play with this interactive chart [here](https:\/\/keisan.casio.com\/exec\/system\/1180573226).\n\nIn this experiment we will use different values of alpha (beta) and find out:\n* if there is any effect of alpha on this dataset, <br>\n* if yes, what's the optimal value to use. ","f9c21eab":"# \ud83e\uddf0 Imports and Setups","4e584e08":"This kernel is created to run few experiments of my own to answer two very important questions:\n\n* **What's the best way to use the cadence snippet?** Should we use it **channel-wise or spatially?** **Should we use all 6 spectrograms or just the ones with aliens' signal?**\n\n* **Mixup** is giving a significant performance boost. But what's the **gain in percentage**? How much are the models trained with Mixup dependent on random initialization?\n\nYou can find the detailed summary in this discussion post [here](https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/245152). For an interactive summary check out this [W&B report](http:\/\/wandb.me\/seti-img-mixup-exp). ","bb570507":"# \ud83d\udd28 Build Input Pipeline","062eb084":"# \ud83d\udc24 Model","2b99eab7":"# \ud83d\udcc0 Hyperparameters"}}