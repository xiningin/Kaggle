{"cell_type":{"f56be990":"code","278dd44f":"code","fdaf10b4":"code","0f6902a4":"code","6d3b2bf3":"code","82b03181":"code","6a7c9c57":"code","fcdb165b":"code","781668d9":"code","a20bca76":"code","21501bfa":"code","71575cda":"code","9eb0d976":"code","a32d862e":"code","569f4b62":"code","bc9cc9a9":"code","19f3f8fd":"code","6647fc57":"code","806707c6":"markdown","9fa24a11":"markdown","4e7ce014":"markdown","bec65eec":"markdown","96a5e421":"markdown","3aca4dfd":"markdown","0b607d9d":"markdown"},"source":{"f56be990":"#importing data to be used\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","278dd44f":"from textblob import TextBlob\nimport nltk","fdaf10b4":"# we read the required csv file as GBcomments\nGBcomments=pd.read_csv('..\/input\/youtube\/GBcomments.csv',error_bad_lines=False)","0f6902a4":"GBcomments.head()","6d3b2bf3":"import string","82b03181":"def punc_remover(t):\n    no_punc=[char for char in t if char not in string.punctuation]\n    return ''.join(no_punc)","6a7c9c57":"GBcomments['comment_text']=GBcomments['comment_text'].astype(str)\n","fcdb165b":"GBcomments['comment_text']=GBcomments['comment_text'].apply(punc_remover)","781668d9":"GBcomments.head()","a20bca76":"from nltk.corpus import stopwords","21501bfa":"sr= stopwords.words('english')\ndef remstop(t):\n    return [word for word in t.split() if word not in sr]\n","71575cda":"GBcomments['comment_text']=GBcomments['comment_text'].apply(remstop)","9eb0d976":"GBcomments.head()","a32d862e":"def pol(text):\n    a=str(text)\n    b=TextBlob(a)\n    return b.sentiment.polarity","569f4b62":"GBcomments['polarity']=GBcomments.comment_text.apply(pol)","bc9cc9a9":"def checker(text):\n    if text>0:\n        return 1\n    elif text<0:\n        return -1\n    else:\n        return 0\nGBcomments['polarity']=GBcomments['polarity'].apply(checker)","19f3f8fd":"GBcomments.head()","6647fc57":"sns.set_style('whitegrid')\nsns.countplot(x='polarity',data=GBcomments)\n","806707c6":"#### We will now remove all the punctuations and stopwords from the comment_text column so that our analysis becomes easier. First removing all the punctuations.\n","9fa24a11":"#### We will now assign positive comments as 1, negative comments as -1, and neutral comments as 0","4e7ce014":" #### Now removing all the stopwords from the comment_text column.","bec65eec":"\n#### For sentiment analyis, we will first convert the data into textblobs, and then find out its sentiment polarity.\n","96a5e421":"#### From our above analyis, we can conclude that there were around 300k positive comments, around 100k negative comments, and a little less than 300k neutral comments. ","3aca4dfd":"#### Now, we will read the GBcomments csv file. Since, there is some problem in its formatting, we will have to add error_bad_lines=False as an argument. File was not opening without adding this argument.\n","0b607d9d":" ### **For this project, our goal is to do sentiment analysis of the available comments of some youtube videos.**"}}