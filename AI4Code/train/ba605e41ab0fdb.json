{"cell_type":{"0674f042":"code","17f03ecf":"code","f14cbff7":"code","cb021bd6":"code","aa9c37be":"code","1560d535":"code","63ab977a":"code","11e2e0a1":"code","5e437c5d":"code","e14d4569":"code","4865bf7d":"code","a066ce24":"code","a75784f7":"code","c09be9cd":"code","8834d712":"code","d5bdc0c8":"code","033a3366":"code","6bc86808":"code","41283f40":"code","808fd05b":"code","2c106b8a":"markdown","b561b45b":"markdown","3ff43220":"markdown","93cebb3f":"markdown","a3231ba3":"markdown","b47543a3":"markdown","da8073ef":"markdown","5936a02a":"markdown","a2863ada":"markdown","43f2aeac":"markdown","566f1be2":"markdown","9efd8116":"markdown","ea054a31":"markdown","6da3e0e9":"markdown","6d54f031":"markdown","d7d6af94":"markdown","cd60ff38":"markdown","f75b9db2":"markdown","01f99646":"markdown","250ce7e8":"markdown","7fbd6eda":"markdown","1f1d9812":"markdown","02105488":"markdown","c9fd95cf":"markdown","13598670":"markdown","f115348b":"markdown","04dff9db":"markdown","a366458a":"markdown","3f679fc0":"markdown","ee983cb7":"markdown","6c236d1c":"markdown","fc7a2941":"markdown","f74d85f9":"markdown","426b478d":"markdown","e3711cd9":"markdown","efb7008e":"markdown","f267d4a5":"markdown","5ae0d901":"markdown","1b6448d3":"markdown","b82ca45f":"markdown"},"source":{"0674f042":"from warnings import filterwarnings\nfilterwarnings(\"ignore\")","17f03ecf":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict,ShuffleSplit,GridSearchCV\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,roc_curve, classification_report,mean_squared_error,f1_score,recall_score,precision_score\nfrom sklearn.naive_bayes import GaussianNB\nimport time","f14cbff7":"pd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)\npd.set_option('display.width', 1000)","cb021bd6":"df = pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndf.head()","aa9c37be":"df.shape","1560d535":"df.describe()","63ab977a":"X = df.drop(\"Outcome\",axis=1)\ny= df[\"Outcome\"] #We will predict Outcome(diabetes) ","11e2e0a1":"X_train = X.iloc[:600]\nX_test = X.iloc[600:]\ny_train = y[:600]\ny_test = y[600:]\n\nprint(\"X_train Shape: \",X_train.shape)\nprint(\"X_test Shape: \",X_test.shape)\nprint(\"y_train Shape: \",y_train.shape)\nprint(\"y_test Shape: \",y_test.shape)","5e437c5d":"nb = GaussianNB().fit(X_train,y_train)","e14d4569":"nb","4865bf7d":"nb.predict(X_test)[:10]","a066ce24":"y_pred = nb.predict(X_test)","a75784f7":"cm = confusion_matrix(y_test,y_pred)","c09be9cd":"cm","8834d712":"print(\"Our Accuracy is: \", (cm[0][0]+cm[1][1])\/(cm[0][0]+cm[1][1]+cm[0][1]+cm[1][0]))","d5bdc0c8":"accuracy_score(y_test,y_pred)","033a3366":"recall_score(y_test,y_pred)","6bc86808":"precision_score(y_test,y_pred)","41283f40":"f1_score(y_test,y_pred)","808fd05b":"print(classification_report(y_test,y_pred))","2c106b8a":"In order to see all rows and columns, we will increase max display numbers of dataframe.","b561b45b":"The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of the ROC curve. The higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes.\n\nThis is an example of AUC:\n\n![image.png](attachment:image.png)","3ff43220":"#### Precision","93cebb3f":"Accuracy is one metric for evaluating classification models. Informally, accuracy is **the fraction of predictions our model got right**.\n\nFormally, accuracy has the following definition: All correct predictions \/ all predictions\n\nFor binary classification, accuracy can also be calculated in terms of positives and negatives as follow: (TP+TN) \/ (TP+FP+FN+TN)","a3231ba3":"**Notation**: TP = True Positives, TN = True Negatives, FP = False Positives, and FN = False Negatives.","b47543a3":"Recall gives us the answer of this question :\n\n**What proportion of actual positives was identified correctly?**\n\nIt is defined as follows: TP \/ (TP+FN)","da8073ef":"- **true positive**: These are cases in which we predicted positive, and they are actually positive.\n- **false positive (Type 1 Error)**: We predicted postive, but they are actually negative. (Also known as a \"Type 1 error.\")\n- **true negative**: We predicted negative, and they are actually negative.\n- **false negative (Type 2 Error)**: We predicted negative, but they are actually postive. (Also known as a \"Type 2 error.\")","5936a02a":"**Created by Berkay Alan**\n\n**Classification | Naive Bayes**\n\n**17 January 2022**\n\n**For more Tutorial:** https:\/\/github.com\/berkayalan","a2863ada":"#### Confusion Matrix","43f2aeac":"### Classification","566f1be2":"***\n\n Naive Bayes is a classification algorithm for binary (two-class) and multi-class classification problems. The technique is easiest to understand when described using binary or categorical input values.\n\nIt is called *naive Bayes or idiot Bayes* because the calculation of the probabilities for each hypothesis are simplified to make their calculation tractable. Rather than attempting to calculate the values of each attribute value P(d1, d2, d3|h), they are assumed to be conditionally independent given the target value and calculated as P(d1|h) * P(d2|H) and so on.\n\n A list of probabilities are stored to file for a learned naive Bayes model. This includes:\n\n- **Class Probabilities**: The class probabilities are simply the frequency of instances that belong to each class divided by the total number of instances.\n\n- **Conditional Probabilities**: The conditional probabilities are the frequency of each attribute value for a given class value divided by the frequency of instances with that class value.\n\nThere are different types of Naive Bayes Classifier:\n\n- Multinomial Naive Bayes:\n\nThis is mostly used for document classification problem, i.e whether a document belongs to the category of sports, politics, technology etc. The features\/predictors used by the classifier are the frequency of the words present in the document.\n\n- Bernoulli Naive Bayes:\n\nThis is similar to the multinomial naive bayes but the predictors are boolean variables. The parameters that we use to predict the class variable take up only values yes or no, for example if a word occurs in the text or not.\n\n- Gaussian Naive Bayes:\n\nWhen the predictors take up a continuous value and are not discrete, we assume that these values are sampled from a gaussian distribution.","9efd8116":"#### ROC Curve (Receiver Operating Characteristic Curve)","ea054a31":"Before we dive into to the Naive Bayes algorithm, we need to understand basis of it: **Bayes Therom**.\n\nIn machine learning we are often interested in selecting the best hypothesis (h) given data (d).\n\nIn a classification problem, our hypothesis (h) may be the class to assign for a new data instance (d).\n\nOne of the easiest ways of selecting the most probable hypothesis given the data that we have that we can use as our prior knowledge about the problem. Bayes Theorem provides a way that we can calculate the probability of a hypothesis given our prior knowledge.\n\nBayes\u2019 Theorem is stated as:\n\n                                P(h|d) = (P(d|h) * P(h)) \/ P(d)\n\nWhere\n\n- P(h|d) is the probability of hypothesis h given the data d. This is called the **posterior probability**.\n\n- P(d|h) is the probability of data d given that the hypothesis h was true.\n\n- P(h) is the probability of hypothesis h being true (regardless of the data). This is called the **prior probability of h**.\n\n- P(d) is the probability of the data (regardless of the hypothesis).\n\n\n - Note: **P** is considered as probability.\n\n We can see that we are interested in calculating the posterior probability of P(h|d) from the prior probability p(h) with P(d) and P(d|h).","6da3e0e9":"To compute the points in an ROC curve, we could evaluate a classification model many times with different classification thresholds, but this would be inefficient. Fortunately, there's an efficient, sorting-based algorithm that can provide this information for us, called AUC.","6d54f031":"If you want to see other algorithms such as:\n\n- Logistic Regression (Theory - Model- Tuning)\n\n- Decision Tree Classification (Theory - Model- Tuning)\n\n- Support Vector Machines(SVC) - Linear Kernel (Theory - Model- Tuning)\n\n- Support Vector Machines(SVC) - Radial Basis Kernel (Theory - Model- Tuning)\n\n- Ensemble Learning - Random Forests Classification (Theory - Model- Tuning)\n\n- K - Nearest Neighbors(KNN) (Theory - Model- Tuning)\n\n- XGBoost(Extreme Gradient Boosting) Classification (Theory - Model- Tuning)\n\nPlease visit my [Classification tutorial](https:\/\/github.com\/berkayalan\/Data-Science-Tutorials\/blob\/master\/Classification\/Classification.ipynb)","d7d6af94":"#### F1 - Score","cd60ff38":"Because we are doing a classification case, we will create a **confusion matrix** in order to evaluate our model.  Confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.","f75b9db2":"### Model","01f99646":"Classification is the process of finding or discovering a model or function which helps in separating the data into multiple categorical classes i.e. discrete values. In classification, data is categorized under different labels according to some parameters given in input and then the labels are predicted for the data. \nThe derived mapping function could be demonstrated in the form of \u201cIF-THEN\u201d rules. The classification process deal with the problems where the data can be divided into binary or multiple discrete labels. ","250ce7e8":"#### AUC (Area under Curve)","7fbd6eda":"Some use-cases:\n\n- Mail classification (spam or not)\n\n- Diagnosis of the sicknesses\n\n- Customer buying prediction (if customer will buy or not)","1f1d9812":"Now we're going to split our dataset to train and test set. We will choose almost 20% of dataset as test size.","02105488":"### Prediction","c9fd95cf":"Precision gives us the answer of this question : \n\n**What proportion of positive identifications was actually correct?**\n\nIt is defined as follows: TP \/ (TP+FP)","13598670":"## Classification and Evaluation Metrics","f115348b":"## Naive Bayes Classification","04dff9db":"The F1 score can be interpreted as a harmonic mean of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. \n\nThe formula for the F1 score is: 2 * (precision * recall) \/ (precision + recall)","a366458a":"#### Accuracy","3f679fc0":"An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. \n\nAn ROC curve plots TP rates vs. FP rares at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. The following figure shows a typical ROC curve.\n\n![image.png](attachment:image.png)","ee983cb7":"For a real world example, we will work with **Pima Indians Diabetes** dataset by UCI Machine Learning as before.\n\nIt can be downloaded [here](https:\/\/www.kaggle.com\/uciml\/pima-indians-diabetes-database).\n\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\nWe will try to predict whether the patient has diabetes or not.","6c236d1c":"Because we are doing a classification case, we will create a **confusion matrix** in order to evaluate out model.","fc7a2941":"### Evaluation Metrics","f74d85f9":"- **The Elements of  Statistical Learning** - Trevor Hastie,  Robert Tibshirani, Jerome Friedman -  Data Mining, Inference, and Prediction (Springer Series in Statistics) \n\n- [**What is a Confusion Matrix in Machine Learning?**](https:\/\/machinelearningmastery.com\/confusion-matrix-machine-learning\/)\n\n- [**Naive Bayes for Machine Learning**](https:\/\/machinelearningmastery.com\/naive-bayes-for-machine-learning\/)\n\n- [**Gaussian Naive Bayes by Statquest**](https:\/\/www.youtube.com\/watch?v=H3EjCKtlVog&ab_channel=StatQuestwithJoshStarmer)\n\n- [**Introduction To Naive Bayes Algorithm**](https:\/\/www.analyticsvidhya.com\/blog\/2021\/03\/introduction-to-naive-bayes-algorithm\/)\n\n- [**Naive Bayes Classifier**](https:\/\/towardsdatascience.com\/naive-bayes-classifier-81d512f50a7c)\n\n- [**Classification: Precision and Recall**](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/precision-and-recall)\n\n- [**Classification: ROC Curve and AUC**](https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/roc-and-auc)\n\n- [**AUC-ROC Curve in Machine Learning Clearly Explained**](https:\/\/www.analyticsvidhya.com\/blog\/2020\/06\/auc-roc-curve-machine-learning\/)","426b478d":"## Resources","e3711cd9":"Naive Bayes has no hyperparameter, so that's why we won't do model tuning here.","efb7008e":"## Importing Libraries","f267d4a5":"### Theory","5ae0d901":"![image.png](attachment:image.png)\n\nPhoto is cited by [here](https:\/\/www.google.com\/url?sa=i&url=https%3A%2F%2Ftowardsdatascience.com%2Fconfusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826&psig=AOvVaw29atdmY9s4wmI-rc0qQZZb&ust=1628435461495000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCKj1g_2Yn_ICFQAAAAAdAAAAABAD).","1b6448d3":"#### Recall","b82ca45f":"After calculating the posterior probability for a number of different hypotheses, we can select the hypothesis with the highest probability. This is the maximum probable hypothesis and may formally be called the *maximum a posteriori (MAP)* hypothesis.\n\nLet's do an example.\n\nImagine that we have 2 machine M1 and M2. Machine 1 produces 30 wrenches in an hour while machine 2 produces 20 wrenches. Out of all produced parts, the probability of being defective is 1%. But out of all defective parts, 50% comes from M1 and othen 50% comes from M2. So the question is: **What is the probability that a part produced by M2 is defective?**\n\nFirst, let's convert all details to mathematical terms.\n\n- P(M1) : 30 \/ 50 = 0.6\n\n- P(M2) : 20 \/ 50 = 0.4\n\n- P(defective) : 1 %\n\n- P(M1 | defective) : 50 %\n\n- P(M2 | defective) : 50 %\n\nWhat we want is : **P(defective | M2)**\n\nSo the formula of bayes therom is :\n\n                        P(defective | M2) = (P(M2 | defective) * P(defective)) \/ P(M2) \n                        \nWhen we calculate it:\n\n(0.5 * 0.01) \/ 0.1 = 0.0125 = 12.5 % "}}