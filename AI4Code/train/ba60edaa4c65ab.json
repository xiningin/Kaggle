{"cell_type":{"99499872":"code","2ada9d93":"code","2c96d729":"code","d3eb3616":"code","44ece7e5":"code","c593a6b2":"code","62a20386":"code","a15a6236":"code","f23c25b5":"code","86d46c7e":"code","48fe7b06":"code","7f5feb8f":"code","5272451a":"code","51bc5206":"code","1992bf3c":"code","dbf57490":"code","b820eb50":"code","1d512fdf":"code","cf032275":"code","46ae8950":"code","3c589d52":"code","ffc9e578":"code","4100b95a":"code","92af140f":"code","1b88416e":"code","8d0c0f0a":"code","fbaae80d":"code","9c497219":"code","f3fb22a1":"code","1fa3609b":"code","12bf399e":"code","f0e98f7d":"code","12e3edb9":"code","83065fe9":"code","637719ba":"code","aa78beb4":"code","bc05e6ba":"code","95b38f73":"code","1a0f56d2":"code","016794b5":"code","dcf358cc":"code","083036fb":"code","b4d54fda":"code","5a372fb4":"code","9dfedfdb":"code","5faff63e":"code","399d7554":"code","0670a9d8":"code","17f30709":"markdown","b5e127aa":"markdown","0f940751":"markdown","d2c75f14":"markdown","2a281a54":"markdown","27b28ad0":"markdown","c80bb5a1":"markdown","4a108a32":"markdown","0335f3b5":"markdown","e2466b25":"markdown","72c3f170":"markdown","c5e7a2c7":"markdown","8cbb2d8c":"markdown","94de0590":"markdown","1199844c":"markdown","e2afd3c6":"markdown","6f297e0f":"markdown","0bad4128":"markdown","009b27a8":"markdown","ad315538":"markdown","c41f6a69":"markdown","9b263a3a":"markdown","c763020b":"markdown"},"source":{"99499872":"!python -m pip install seaborn==0.11.1","2ada9d93":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.pipeline import Pipeline,FeatureUnion,make_pipeline\nfrom sklearn.preprocessing import StandardScaler,RobustScaler\nfrom sklearn.ensemble import RandomForestClassifier, IsolationForest\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split,cross_val_score,KFold,GridSearchCV,\\\nRepeatedKFold,RandomizedSearchCV,StratifiedKFold,RepeatedStratifiedKFold\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score,\\\naverage_precision_score,roc_auc_score,recall_score,f1_score,jaccard_score,cohen_kappa_score,auc,precision_recall_curve,plot_precision_recall_curve,plot_roc_curve\nfrom imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline as imb_pipe\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.decomposition import PCA\n\n\nimport warnings\nwarnings.simplefilter('ignore',DeprecationWarning)\nwarnings.simplefilter('ignore',FutureWarning)\npd.set_option(\"precision\", 6)\nsns.set_style('darkgrid')\n%matplotlib inline","2c96d729":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.rename(columns={'Class':'Fraud'},inplace=True) # the change of name\ndf.head()","d3eb3616":"# some info about our columns\n# all floats except for Fraud\ndf.info()","44ece7e5":"# no missing values\ndf.isnull().any().sum()","c593a6b2":"# Percentage of fraudulent transactions\nprint(f'Percentage of fraudulent transactions: {100*df.Fraud.mean():.6f}%')","62a20386":"# The number of fraudulent transactions is very small\n# The data is not balanced\n\ndf['Fraud'].value_counts().plot(kind='bar',color='purple')\nplt.title('Non Fraud                                 Fraud')\nplt.yscale('log') # for better visualization\nplt.xlabel('Fraud')\nplt.show()","a15a6236":"f,(ax1,ax2)  = plt.subplots(2,1,figsize=(10,6),sharex=True)\n\nsns.histplot(df.loc[(df.Fraud==1),'Time'],kde=True,stat='density',ax=ax1,bins='sqrt') # sqrt of number of fraud operat\nax1.set_title('Fraud')\nax2.set_xlabel('Time (in seconds) after the first observation')\nsns.histplot(df.loc[(df.Fraud==0),'Time'],kde=True,stat='density',ax=ax2)\nax2.set_title('Non-Fraud')\nplt.show()","f23c25b5":"amount_fraud = df.loc[(df.Fraud==1),'Amount']\namount_n_fraud = df.loc[(df.Fraud==0),'Amount']\nf,(ax1,ax2)  = plt.subplots(1,2,figsize=(8,4),sharey=True)\nf.suptitle('Amount of the transaction',fontdict={'weight':'bold'},fontsize=14)\nsns.boxenplot(y=amount_fraud,ax=ax1,orient='v')\nax1.set_xlabel('Fraud')\nsns.boxenplot(y=amount_n_fraud,ax=ax2,orient='v')\nax2.set_xlabel('Non-Fraud')\nplt.show()","86d46c7e":"# Fraud transactions analysis\nIQR =np.percentile(amount_fraud,75)- np.percentile(amount_fraud,25) \nprint(f'The IQR of Fraud transactions is {IQR:.6f}')\namount_fraud.describe()","48fe7b06":"# Non-Fraud transactions analysis\nIQR_nf =np.percentile(amount_n_fraud,75)- np.percentile(amount_n_fraud,25) \nprint(f'The IQR of Non-Fraud transactions is {IQR_nf:.6f}')\namount_n_fraud.describe()","7f5feb8f":"# The mean absolute deviation is more robust to outliers\n\nprint('  Fraud MAD',' '*10,'Non-Fraud MAD')\namount_fraud.mad(),amount_n_fraud.mad()","5272451a":"# We split our data set, keeping the original distribution of Fruad by using stratify=y\n\nX = df.loc[:,df.columns.difference(['Fraud'])]\ny = df.Fraud\nX_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size=0.25)","51bc5206":"# The same distribution\ny_train.mean()","1992bf3c":"### We use smote to balance our training observations\n# We combine undersampling(majority class) and oversampling(minority class)\n# returns new X_train and y_train\n\ndef resampler(over, under, X_train, y_train):\n    over = SMOTE(sampling_strategy = over, random_state = 0)\n    under = RandomUnderSampler(sampling_strategy = under, random_state = 0)\n    samp_pipe = imb_pipe([('over', over), ('under', under)])\n    return samp_pipe.fit_resample(X_train, y_train)","dbf57490":"# new training sets\n# We want the minority class to be 0.2 of the data\n# If we undersample too much we will lose too many information\n# If we oversample too much we will be creating unrealistic samples\n\nnew_X_train, new_y_train = resampler(y_train.mean()*1.2, 1\/4, X_train, y_train)","b820eb50":"print('Fraud Distribution:',new_y_train.mean())\nprint('Number of Fraud and Non-Fraud:')\nprint(new_y_train.value_counts())","1d512fdf":"# Principal components are always centered (mean=0), but in this case, \n# they don't have unit variance \ndf.describe()","cf032275":"## PCA pipeline. \npre_pca = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=2))])","46ae8950":"## umap\nimport umap\n# We apply UMAP to scaled data\npre = Pipeline([('scaler',StandardScaler()),('umap',umap.UMAP())])","3c589d52":"%%time \n#  Embedding of the resampled data\nembedding = pre.fit_transform(new_X_train, new_y_train)","ffc9e578":"## We use PCA to see if our classes are separable\npca_plot = pre_pca.fit_transform(new_X_train).T  # data for the PCA plot\n\n# We do the same with umap\nemb_plot = embedding.T ## data for the UMAP plot\n\n# We plot them\nf = plt.figure(figsize=(12,5))\nf.add_subplot(1,2,1)\nfor i in [0,1]:\n    ix = np.where(new_y_train==i)\n    plt.scatter(*pca_plot[:,ix],label=i,cmap='Dark2',alpha = 0.2)\n    plt.title('2 First Principal Components',fontsize=14)\n    plt.ylabel('1st Principal Component')\n    plt.xlabel('2nd Principal Component')\n    plt.legend()\n    \nf.add_subplot(1,2,2)\nfor i in [0,1]:\n    ix = np.where(new_y_train==i)\n    plt.scatter(*emb_plot[:,ix],label=i,cmap='Dark2',alpha=0.6)\n    plt.title('Data Embedded via UMAP',fontsize=14)\n    plt.legend()","4100b95a":"f = plt.figure(figsize=(15,8))\nplt.title('Correlation Matrix: Among Predictors',fontsize=15,fontdict={'weight':'bold'})\nsns.heatmap(new_X_train.corr(),linewidths=0.1,annot=True,cmap='Spectral')\nplt.show()","92af140f":"# Let's see how the predictors correlate with the response\n\nf = plt.figure(figsize=(12,6))\nplt.title('Correlation: Fraud vs predictors',fontsize=14,fontdict={'weight':'bold'})\nnew_X_train.corrwith(new_y_train,method='kendall').sort_values(ascending=True).plot(kind='barh')\nplt.show()","1b88416e":"# the \"hihgly\" correlated variables with the response\n# abs(0.35) was chosen arbitrarily\nhighly_corr = new_X_train.corrwith(new_y_train,method='kendall')[abs(new_X_train.corrwith(new_y_train))>0.35].index\nhighly_corr","8d0c0f0a":"# Confusition matrix plot function\ndef conf_matrix_plot(y_test,y_pred):\n    sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,linewidths=0.7,fmt=\"d\",cbar=False)\n    plt.ylabel('True')\n    plt.xlabel('Predicted')\n    plt.title('Confusion Matrix',fontdict={'weight':'bold'},fontsize=14)\n    plt.show()","fbaae80d":"# Complete classification report \ndef complete_class_report(y_test, y_pred, y_score=None):\n    print('---  Complete Classification Report  ---')\n    print(classification_report(y_test,y_pred))\n    # Other useful metrics\n    print(f'Jaccard: {jaccard_score(y_test,y_pred)}')\n    print(f\"Cohen's kappa: {cohen_kappa_score(y_test,y_pred)}\")\n    # info of Precision-Recall and ROC curves\n    if list(y_score)!=None:\n        print(f'ROC_AUC: {roc_auc_score(y_test,y_score)}')\n        print(f'Average Precision: {average_precision_score(y_test,y_score)}')\n        precision, recall, _ = precision_recall_curve(y_test, y_score)\n        print(f'Area under Recall-Precision Curve: {auc(recall, precision)}')","9c497219":"# precision-recall and ROC curve plots\n\ndef curves(clf,X_test,y_test,name=None):\n    f,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n    ax1.set_title(f'Precision-Recall Curve')\n    ax2.set_title(f'ROC Curve')\n    plot_precision_recall_curve(clf,X_test,y_test,ax=ax1,c='goldenrod',name=name)\n    plot_roc_curve(clf,X_test,y_test,ax=ax2,c='green',name=name)\n    plt.show()","f3fb22a1":"### Random Forest fitted on original data\n## I am not going to tune the hyperparameters because it takes too much time and the idea is to fit a model on the resampled data\nclf = RandomForestClassifier(n_estimators=200)\nclf.fit(X_train,y_train)","1fa3609b":"# Best model from gridsearch\nproba_pred = clf.predict_proba(X_test)[:,1] # probabilities","12bf399e":"# We try different probability thresholds to visualize the effect in recall and precision\n\nfor th in [0.1,0.2,0.3,0.4,0.5]:\n    y_pred = (proba_pred>th).astype(int)\n    print('-'*40)\n    print(''*40)\n    print('Threshold:',th)\n    conf_matrix_plot(y_test,y_pred)\n    complete_class_report(y_test,y_pred,proba_pred) # the last 3 metrics are already taking into consideration all thresholds","f0e98f7d":"# We plot the roc curve and the precision-recall curve\ncurves(clf,X_test,y_test,name='Random Forest (all data)')","12e3edb9":"# models and scores for plotting later\nmodels = []\nclassifiers = []","83065fe9":"rf_params = {'n_estimators':[100,160,200,300,350],'max_depth':[None,5,10,20,50,60,80,100],'min_samples_split': [2, 5, 10]}\nfold = RepeatedStratifiedKFold(n_splits=5,n_repeats=3,random_state=0) # 5 folds and 3 repetitions\nprueba = RandomizedSearchCV(RandomForestClassifier(),rf_params,cv=fold,scoring='jaccard',n_iter = 15).fit(new_X_train,new_y_train)","637719ba":"prueba_proba = prueba.predict_proba(X_test)[:,1]\nmodels.append('Random Forest')\nclassifiers.append(prueba)\nprueba.best_params_","aa78beb4":"# We try different thresholds\nfor th in [0.1,0.2,0.3,0.4,0.5]:\n    y_pred = (prueba_proba>th).astype(int)\n    print('-'*40)\n    print(''*40)\n    print('Threshold:',th)\n    conf_matrix_plot(y_test,y_pred),complete_class_report(y_test,y_pred,prueba_proba)","bc05e6ba":"model = LogisticRegressionCV(max_iter=10000,scoring='jaccard',cv = fold)\npipe = Pipeline([('scaler',StandardScaler()),('model',model)])","95b38f73":"%%time\n# fitted on resampled data\npipe.fit(new_X_train,new_y_train)","1a0f56d2":"# we estimate the probability of fraud\nprob_lr =pipe.predict_proba(X_test)[:,1]\nmodels.append('Logistic Regression')\nclassifiers.append(pipe)","016794b5":"# We try different thresholds\nfor th in [0.1,0.2,0.3,0.4,0.5]:\n    y_pred = (prob_lr>th).astype(int)\n    print('-'*40)\n    print(''*40)\n    print('Threshold:',th)\n    conf_matrix_plot(y_test,y_pred),complete_class_report(y_test,y_pred,prob_lr)","dcf358cc":"# We plot the ROC curve and the P-R curve\nfor mod,cl in zip(models,classifiers):\n    curves(cl,X_test,y_test,name=mod)","083036fb":"# Logistic Regression\nmodel = LogisticRegressionCV(max_iter=10000,scoring='jaccard',cv = fold)\npipe_hc = Pipeline([('scaler',StandardScaler()),('model',model)])\npipe_hc.fit(new_X_train[highly_corr],new_y_train)","b4d54fda":"h_c_prob = pipe_hc.predict_proba(X_test[highly_corr])[:,1]","5a372fb4":"# We try different thresholds\nfor th in [0.1,0.2,0.3,0.4,0.5]:\n    y_pred = (h_c_prob>th).astype(int)\n    print('-'*40)\n    print(''*40)\n    print('Threshold:',th)\n    conf_matrix_plot(y_test,y_pred),complete_class_report(y_test,y_pred,h_c_prob)","9dfedfdb":"### With Random Forest\nprueba2 = RandomizedSearchCV(RandomForestClassifier(),rf_params,\n                       cv=fold,scoring='jaccard',n_iter=15).fit(new_X_train[highly_corr],new_y_train)","5faff63e":"prueba2_proba = prueba2.predict_proba(X_test[highly_corr])[:,1]\nprueba2.best_params_","399d7554":"# We try different thresholds\nfor th in [0.1,0.2,0.3,0.4,0.5]:\n    y_pred = (prueba2_proba>th).astype(int)\n    print('-'*40)\n    print(''*40)\n    print('Threshold:',th)\n    conf_matrix_plot(y_test,y_pred),complete_class_report(y_test,y_pred,prueba2_proba)","0670a9d8":"# Plot the ROC curve and P-R curve of the models that only used highly correlated features\nmodels_hc = ['Random Forest HC','Logistic Regression HC']\nclassi_hc = [prueba2,pipe_hc]\nfor mod,clas in zip(models_hc,classi_hc):\n    curves(clas,X_test[highly_corr],y_test,name=mod)","17f30709":"* Random Forest is outperforming Logistic Regression  Average Precison. ","b5e127aa":"****\n**Some comments**\n* Like before, the ROC AUC is too optimistic.\n* The recall improves using the resampled data, but the precision is very bad. The same happens by lowering the threshold.\n* Jaccard and Cohen's Kappa coefficients are low because of the bad precision\n","0f940751":"### Correlation analysis\n","d2c75f14":"### Resampling \n","2a281a54":"#### Time\n","27b28ad0":"***\n#### **Models with resampled data**\n We are going to use RandomForest model fitted on the resampled data","c80bb5a1":"***\n***\n# **Conclusions**","4a108a32":"Fraud transactions seems to occur almost at every time of the day in the same way, while Non-Fraud transactions have some off-peak times","0335f3b5":"## **EDA**\nColumns:\n* Time: Number of seconds elapsed between this transaction and the first transaction in the dataset\n* Class: 0 if normal transaction, 1 if fraud. I will change \"Class\" for \"Fraud\"\n* V1 to V28: The 28 Principal Components obtained using PCA. This is done to protect sensitive information. \n* Amount: Transacion amount","e2466b25":"* The Jaccard coefficient is a good metric if the data is imbalanced and we are more interested in the positive class. [Info](https:\/\/en.wikipedia.org\/wiki\/Jaccard_index)\n* Cohen's kappa coefficient is a robust measure because takes into account the possibility of the agreement occurring by chance. [Info](https:\/\/en.wikipedia.org\/wiki\/Cohen%27s_kappa)\n","72c3f170":"#### Amount","c5e7a2c7":"#### Random Forest fitted on original data\nRandom Forest is robust to outliers and features don't need to be scaled","8cbb2d8c":"# **Credit Card Fraud Detection**\nThis Notebook aims to:\n* Show how to deal with imbalanced data and which metrics could be useful\n* Present the precision\/recall trade-off \n* Predict whether a transaction is fraudulent or not <br>\n\nThe personal data of the clients has been transformed using PCA in order to protect sensitive information. <br>\n\n**Plenty of things can still be done, including trying other models. If you have any suggestions or positive comments, please let me know.**","94de0590":"***\n***\n## **Modelling**","1199844c":"* The area under the ROC curve is not a good metric if the data is imbalanced\n* The precision-recall curve is a better option\n* The area under the Precision-Recall curve is slightly more optimistic than the Average Precision. The latter is better because takes into consideration the increase in recall from the previous threshold used as the weight. [Example](https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py) \n* Training a model using imbalanced data results in high precision, but low recall\n* Resampling increases the recall considerably, but the precision cost is very high\n* By lowering the probability threshold the recall increases, but the precision decreases\n\n**What should the credit card companies do?**\n* The companies should prevent fraudulent transactions. Given that there is a trade-off between recall and precision, companies should calculate the economic, moral and reputational costs of:\n    - Not being able to recognize fraudulent transactions.\n    - Falsely accusing a transaction of being fraudulent and blocking the client's credit card.\n* After knowing the impact of their decisions, companies will **set minimum values of both recall and precision.** ","e2afd3c6":"***\n***\n**Using Logistic Regression**","6f297e0f":"* Non-fraud transactions are less variable, but have some important outliers","0bad4128":"**Some comments**\n* The area under the ROC curve give us an extremely optimistic score. \n* The recall is not good, but the precision is high","009b27a8":"Let's make a better analysis","ad315538":"### Some exploration","c41f6a69":"Classes are separable <br>\nUMAP did a better job separating the classes <br>","9b263a3a":"***\n##### **Only using highly correlated variables** \n(Arbitraty)","c763020b":"### PCA and UMAP"}}