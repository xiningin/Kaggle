{"cell_type":{"4705377d":"code","a6c41aa1":"code","294cba08":"code","bfafda77":"code","df1e784b":"code","25606022":"code","bdf128fe":"code","c99fc16f":"code","6d848da2":"code","e37b32b7":"code","2955ad69":"code","7609824f":"code","a0a29499":"code","72f2d255":"code","99af6a9c":"code","f310a82b":"code","a52c18a1":"code","0656cdcf":"code","f81b0101":"code","086959bc":"code","1092de91":"code","a3bcd3f8":"code","0a7ee92c":"code","169877c8":"code","c172c07b":"code","b35fb023":"code","1c9a9e33":"markdown","de61eb13":"markdown","9dae3fbd":"markdown","0284e367":"markdown"},"source":{"4705377d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a6c41aa1":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels","294cba08":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing.image import ImageDataGenerator","bfafda77":"df = pd.read_csv('..\/input\/train.csv')\n","df1e784b":"test_df = pd.read_csv('..\/input\/test.csv')","25606022":"df.head()","bdf128fe":"Y = df['label']\nX = df.drop(['label'], axis = 1)","c99fc16f":"X = X \/ 255.0\nX = X.values.reshape(-1,28,28,1)\nY = np.array(Y)\nY = to_categorical(Y, num_classes = 10)","6d848da2":"print(X.shape)\nprint(Y.shape)","e37b32b7":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y, random_state = 31, test_size = 0.2)","2955ad69":"print(type(X_train), type(X_test) , type(Y_train),type( Y_test))","7609824f":"g = plt.imshow(X_train[0][:,:,0])","a0a29499":"model = Sequential()","72f2d255":"model.add(Conv2D(32,(5,5),padding = 'Same',activation ='relu', input_shape = (28,28,1)))\n\nmodel.add(Conv2D(64,(3,3), padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128,(3,3), padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64,(3,3), padding = 'same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation = 'softmax'))\n\n","99af6a9c":"# Maybe we can try augementing the data to improve the accuracy\ndatagen = ImageDataGenerator(featurewise_center=False, \n                             samplewise_center=False, \n                             featurewise_std_normalization=False, \n                             samplewise_std_normalization=False, \n                             zca_whitening=False, \n                             zca_epsilon=1e-06, \n                             rotation_range=10, \n                             width_shift_range=0.1, \n                             height_shift_range=0.1, \n                             brightness_range=None, \n                             shear_range=0.1, \n                             zoom_range=0.15, \n                             channel_shift_range=0.0, \n                             fill_mode='nearest', \n                             cval=0.0, \n                             horizontal_flip=False, \n                             vertical_flip=False, \n                             rescale=None, \n                             preprocessing_function=None, \n                             data_format=None, validation_split=0.0, dtype=None)","f310a82b":"datagen.fit(X_train)","a52c18a1":"model.compile(optimizer = \"Nadam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","0656cdcf":"max_epochs = 30\nbatch_size = 256","f81b0101":"history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size = batch_size) ,\n                              epochs = max_epochs, verbose = 1, validation_data = (X_test, Y_test),\n                              steps_per_epoch=X_train.shape[0] \/\/ batch_size)","086959bc":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'g', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'g', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","1092de91":"test_df.head()","a3bcd3f8":"test_df = test_df \/ 255.0\ntest_arr = test_df.values.reshape(-1,28,28,1)","0a7ee92c":"Y_pred_arr = model.predict(test_arr)","169877c8":"Y_pred_arr.shape","c172c07b":"Y_pred_arr = np.argmax(Y_pred_arr, axis = 1)","b35fb023":"results = pd.Series(Y_pred_arr,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","1c9a9e33":"* Note that optimizer is NOT the normal Adam.\n* We are using Nestrov accelerated Adam\n* You can find more details here https:\/\/keras.io\/optimizers\/\n* Also in tf https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/optimizers\/Nadam\n* It already has learning_rate decay and it is recommended not to tune its hyperparamters.\n* Simple so we are ready to use it directly.","de61eb13":"* We are trying to augumgent the data.\n* Try zooming in and zooming out.\n* We are also shifting the numbers a bit left and right by width_shift and height_shift\n* Also we cannot do horizontal and vertical flip as it will convert 6 to 9 and make 4 look very odd.\n","9dae3fbd":"* Our X will be all the featurs, in this case they are the pixels\n* Our Y are the labels for each number\n* We need to normalize X by dividing it by 255.\n* Then we need to convert Y to one-hot encoded vector.\n* We will cut the data into two parts, train and test\n","0284e367":"* Please try adjusting epochs for further improvement.\n* Also adding regularization may help."}}