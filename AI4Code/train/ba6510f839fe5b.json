{"cell_type":{"a1905d67":"code","ad3f9e88":"code","c2a1dcb8":"code","07b7b401":"code","5ec8c130":"code","280d6ce7":"code","e28fdaa0":"code","c240d6c6":"code","a8b70a42":"code","0622f7b4":"code","8ca69716":"code","f53f2d2f":"code","f2b9e1cc":"code","8ef84a99":"code","414c0301":"code","f494c611":"code","8d542f12":"code","bbe7afa9":"code","49130b7b":"code","77d74809":"code","d85ca472":"code","cd8cb501":"code","2b52eb13":"code","76151a31":"code","7b091761":"code","b8aa3352":"code","e05530e7":"code","7bc4377b":"code","2cbdc2bf":"code","e0edfd80":"code","c299085d":"code","f48e6a4e":"code","4a4836ff":"code","04511c39":"code","9e245a46":"code","7cf36a5c":"code","e35a23d6":"code","dbdf69c0":"code","7fecb12b":"code","b82c1a90":"markdown","f6611ce6":"markdown","2e13be89":"markdown","456d8216":"markdown","1a0a8d89":"markdown","0e62657b":"markdown","3b7757dc":"markdown"},"source":{"a1905d67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad3f9e88":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n# import libraries for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import rcParams\n%matplotlib inline\nplt.style.use('dark_background')\n\n# ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# algorithms\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB","c2a1dcb8":"# loading the data set\ndf = pd.read_csv(\"\/kaggle\/input\/adult-census-income\/adult.csv\", encoding='latin-1')","07b7b401":"df.shape","5ec8c130":"df.head(5)","280d6ce7":"df.isnull().sum()","e28fdaa0":"df[df == '?'].count()","c240d6c6":"df[df == '?'] = np.nan","a8b70a42":"df.head(5)","0622f7b4":"#check the missing value \ndf.isna().sum()   #df.isnull.sum()","8ca69716":"df.info()","f53f2d2f":"#check with \"workclass\" column , unique value\nprint(df.workclass.value_counts())\ncolors = [\"white\",\"red\", \"green\", \"blue\", \"orange\", \"yellow\", \"purple\"] \ndf.workclass.value_counts().plot.bar(color=colors,legend=True)\n","f2b9e1cc":"print((df.workclass.value_counts()*100)\/df.workclass.value_counts().sum())","8ef84a99":"#check with \"Occupation\" column , unique value\nprint(df.occupation.value_counts())\ncolors = [\"white\",\"red\", \"green\", \"blue\", \"orange\", \"yellow\", \"purple\"] \ndf.occupation.value_counts().plot.bar(color=colors,legend=True)\n","414c0301":"#As we see the value counts - the Count the number of times a value occurs and \n#Private having almost covered 74 % Let see in % percentage\n\nprint((df.occupation.value_counts()*100)\/df.occupation.value_counts().sum())","f494c611":"#check with \"native.country\" column , unique value\nprint(df[\"native.country\"].value_counts())\ncolors = [\"white\",\"red\", \"green\", \"blue\", \"orange\", \"yellow\", \"purple\"] \ndf[\"native.country\"].value_counts().plot.bar(color=colors,legend=True)","8d542f12":"print((df[\"native.country\"].value_counts()*100)\/df[\"native.country\"].value_counts().sum())","bbe7afa9":"# imputing the missing values with mode\nfor col in ['workclass', 'occupation', 'native.country']:\n    df[col].fillna(df[col].mode()[0], inplace=True)","49130b7b":"df.isna().sum()","77d74809":"df.info()","d85ca472":"df.columns = [\"age\", \"workclass\", \"final_weight\", \"education\", \"education_num\", \"martial_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"]","cd8cb501":"# As we observe education and education_num both are same , so we can drop one of the column\ndf.drop(['education'], axis = 1, inplace = True)","2b52eb13":"#catogrical column\ncatogrical_column = [column for column in df.columns if df[column].dtypes=='object']\nprint(catogrical_column)","76151a31":"#numerical_column\nnumerical_column = [column for column in df.columns if df[column].dtypes !='object']\nprint(numerical_column)","7b091761":"df.head()","b8aa3352":"print(\"Sex : \\n\",df[\"sex\"].value_counts())\nprint(\"Income: \\n\",df[\"income\"].value_counts())\nprint(\"Race: \\n\",df[\"race\"].value_counts())","e05530e7":"# As we observe sex having the label\nencode ={\"sex\":{\"Male\": 0, \"Female\": 1},\n        \"income\":{\"<=50K\": 0, \">50K\": 1}}\ndf = df.replace(encode)\ndf.head()","7bc4377b":"# encoding categorical variables\nfrom sklearn import preprocessing\n\nfor feature in catogrical_column:\n        le = preprocessing.LabelEncoder()\n        df[feature] = le.fit_transform(df[feature])\n        ","2cbdc2bf":"df.describe()","e0edfd80":"# ploting the correlation between the output(income) and individual features\nrcParams['figure.figsize'] = 12, 12\nplt.matshow(df.corr())\nplt.colorbar()\nplt.xticks(np.arange(len(df.corr().columns)), df.corr().columns.values, rotation = 45) \nplt.yticks(np.arange(len(df.corr().columns)), df.corr().columns.values) \nfor (i, j), corr in np.ndenumerate(df.corr()):\n    plt.text(j, i, '{:0.1f}'.format(corr), ha='center', va='center', color='white', fontsize=14)","c299085d":"# As we observe the correlation between Income and native_country ,occupation ,workclass,final_weight is zero.\n# dropping ative_country ,occupation ,workclass,final_weight since it has 0 correlation\ndf.drop([\"native_country\" ,\"occupation\" ,\"workclass\",\"final_weight\"], axis = 1, inplace = True)","f48e6a4e":"df.dtypes","4a4836ff":"# setting x as input features and y as target feature\nX = df.drop(['income'], axis=1)\ny = df['income']","04511c39":"# splitting the data into training and test set\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","9e245a46":"# Feature scaling\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n\nX_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)","7cf36a5c":"#Applying the GaussianNB algorithm\ngaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\ny_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred)*100)\ndf_pred = pd.DataFrame(y_pred, columns=['Income Predicted - GaussianNB'])\ndf_out = pd.concat([y_test.reset_index(drop='Tru\u200c\u200be'), df_pred.reset_index(drop='Tru\u200c\u200be')],axis=1)","e35a23d6":"#Applying the BernoulliNB algorithm\nbernouli = BernoulliNB()\nbernouli.fit(X_train, y_train)\ny_pred = bernouli.predict(X_test)\nacc_bernouli = round(bernouli.score(X_train, y_train) * 100, 2)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred)*100)\ndf_pred = pd.DataFrame(y_pred, columns=['Income Predicted - BernouliNB'])\ndf_out = pd.concat([df_out.reset_index(drop='Tru\u200c\u200be'), df_pred.reset_index(drop='Tru\u200c\u200be')],axis=1)","dbdf69c0":"#Applying the MultinomialNB algorithm\nmultinomial = MultinomialNB()\nmultinomial.fit(X_train, y_train)\ny_pred = multinomial.predict(X_test)\nacc_multinomial = round(multinomial.score(X_train, y_train) * 100, 2)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint(accuracy_score(y_test, y_pred)*100)\ndf_pred = pd.DataFrame(y_pred, columns=['Income Predicted - MultinomialNB'])\ndf_out = pd.concat([df_out.reset_index(drop='Tru\u200c\u200be'), df_pred.reset_index(drop='Tru\u200c\u200be')],axis=1)","7fecb12b":"#Plotting the accuracy of the used algorithms to find the best fit\n\nresults = pd.DataFrame({\n    'Model': ['BernouliNB', 'GaussianNB', 'MultinomialNB'],\n    'Score': [acc_gaussian, acc_bernouli, acc_multinomial]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df.head(3)","b82c1a90":"As we observe above most of the native.country is United-states\nLet see in % percenatge , United satates having covered  91% ","f6611ce6":"As we above data set having some missing value i.e \"?\" , so need to check in how many columns having this missing value and according to that handle the missing value futher.","2e13be89":"In Given dataset having to 15 Columns (feature) and 32561 Rows(index)","456d8216":"As we see above in only three columns \"workclass\",\"occupation\" and \"native.country\" having special character \"?\"\nso we can replace with \"nan\" and then futher we will fill in \"nan\" value with meaningful value","1a0a8d89":"Filling the missing value with most common value in dataset i.e mode.","0e62657b":"As we see the value counts - the Count the number of times a value occurs \nand Private having almost covered 74 % \nLet see in % ge .","3b7757dc":"1st need to check the null value is present or not , as we see below there is no null value present in the data set but having special character as missing value i.e \"?\""}}