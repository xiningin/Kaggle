{"cell_type":{"5380e550":"code","c830831a":"code","61b65dab":"code","14f4ff94":"code","3f979127":"code","3fe06e06":"code","da1f9b74":"code","db22e216":"code","55ad147a":"code","ac8d3b26":"code","5210f6b2":"code","27574843":"code","5c9165a4":"code","22436b6c":"code","6a0f3844":"code","276c5e40":"code","ed386b3f":"code","88bf9c01":"code","3a7392ae":"code","b3e9bca1":"code","6058f2ff":"code","d11d5614":"code","ea1f162d":"code","766a63d4":"code","bc8822b2":"code","f8723b69":"code","725f89e9":"code","79139a30":"code","b034a61a":"code","c7784c08":"code","55d22caf":"code","c35ad735":"code","e28f227c":"code","a46ac12d":"code","f1d5f987":"code","153e9e48":"code","0855fa4c":"code","53fc410f":"code","8fc2965b":"code","32a30745":"code","f3ce5926":"code","ed6e5c05":"code","71ebbaf3":"code","bb250c8f":"code","a9c47373":"code","82cfc5bc":"code","6fc9c131":"code","31c6dfd3":"code","3241b578":"code","5a8b1465":"code","b14ff652":"code","e1fe876d":"code","c1caeb8a":"code","40f3482a":"code","fbae9c24":"code","4c636b30":"code","08bda209":"code","a9d7fc61":"markdown","710043ee":"markdown","45f32a92":"markdown","234f1b71":"markdown","021a391f":"markdown","9d11d77e":"markdown","3ed67db1":"markdown","0bc645b6":"markdown","a830e615":"markdown","46c7b91f":"markdown","fbdd10d0":"markdown","1b9998b8":"markdown","d9a9ee0d":"markdown","a2cf61cd":"markdown","abab3741":"markdown","c4e21bcc":"markdown"},"source":{"5380e550":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c830831a":"import pandas as pd    \nimport numpy as np\nimport seaborn as sns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nimport matplotlib.pyplot as plt","61b65dab":"pd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);\npd.set_option('display.float_format', lambda x: '%.0f' % x)\n\ndata = pd.read_excel(\"..\/input\/online-retail\/Online Retail.xlsx\")\ndf = data.copy()","14f4ff94":"   class color:\n       BOLD = '\\033[1m'\n       UNDERLINE = '\\033[4m'\n       END = '\\033[0m'","3f979127":"def data_info(df):\n    \"\"\"Parametre olarak verilen dizindeki dosyadan Dataframe olu\u015fturur ve bu Dataframe yap\u0131s\u0131 hakk\u0131nda genel bir rapor sunar.\n    Okunan Dataframe'i geri d\u00f6nd\u00fcr\u00fcr.\"\"\"\n    print(\"*******************************O*******************************\")\n    print(color.BOLD+color.UNDERLINE+\"\u0130LK 5 G\u00d6ZLEM\"+color.END)\n    print(df.head())\n    print(\"*******************************O*******************************\")\n    print(color.BOLD+color.UNDERLINE+\"SON 5 G\u00d6ZLEM\"+color.END)\n    print(df.tail())\n    print(\"*******************************O*******************************\")\n    print(color.BOLD+color.UNDERLINE+\"DATAFRAME GENEL YAPISI\"+color.END)\n    print(df.info())\n    print(\"*******************************O*******************************\")\n    print(color.BOLD+color.UNDERLINE+\"G\u00f6zlem Say\u0131s\u0131:\"+color.END+\" \"+str(df.shape[0]))\n    print(color.BOLD+color.UNDERLINE+\"De\u011fi\u015fken Say\u0131s\u0131:\"+color.END+\" \"+str(df.shape[1]))\n    print(\"*******************************O*******************************\")\n    print(color.BOLD+color.UNDERLINE+\"Numerik De\u011fi\u015fkenler:\"+color.END+\" \")\n    if df.select_dtypes([\"int64\",\"float64\"]).empty:\n        print(\"Numerik de\u011fi\u015fken yoktur.\")\n    else:\n        print(df.select_dtypes([\"int64\",\"float64\"]).columns) \n    print(color.BOLD+color.UNDERLINE+\"Kategorik De\u011fi\u015fkenler:\"+color.END+\" \")\n    if df.select_dtypes(\"object\").empty:\n        print(\"Kategorik de\u011fi\u015fken yoktur\")\n    else:\n        print(df.select_dtypes(\"object\").columns)\n    print(\"*******************************O*******************************\")\n    print(color.BOLD+color.UNDERLINE+\"Eksik G\u00f6zlemler:\"+color.END+\" \")\n    print(df.isnull().sum())    \n    print(\"*******************************O*******************************\")\n    print(color.BOLD+color.UNDERLINE+\"BET\u0130MSEL \u0130STAT\u0130ST\u0130KLER\"+color.END)\n    print(df.describe().T)\n    return df","3fe06e06":"data_info(df)","da1f9b74":"df.isnull().sum()","db22e216":"#visualizing missing data\nimport missingno as msno\nmsno.bar(df);","55ad147a":"df.head()","ac8d3b26":"# We don't need \"lower\" feature\ndf.drop(\"lower\",axis=1,inplace=True)\ndf.head()","5210f6b2":"df.isnull().sum()","27574843":"#visualizing missing data\nimport missingno as msno\nmsno.bar(df);","5c9165a4":"## We have enough data, so I prefer to drop the missing data.\ndf.dropna(inplace=True)","22436b6c":"df.isnull().sum()","6a0f3844":"# Unique values in Description Column (Number of product type)\ndf[\"Description\"].nunique()","276c5e40":"# top 5 ordered products\npd.DataFrame.sort_values(df.groupby(\"Description\").agg({\"Quantity\":\"sum\"}),by=\"Quantity\",ascending=False).head()\n","ed386b3f":"pd.DataFrame.sort_values(df.groupby(\"Description\").agg({\"Quantity\":\"sum\"}),by=\"Quantity\").head()","88bf9c01":"# Finding Negative Quantity Values\ndf[df[\"Quantity\"].astype(str).str.startswith(\"-\",na=False)].head()","3a7392ae":"# Invoice numbers of returns start with c\ndf.drop(df[df[\"Quantity\"].astype(str).str.startswith(\"-\",na=False)].index, inplace=True)","b3e9bca1":"df[df[\"Quantity\"].astype(str).str.startswith(\"-\",na=False)].count()","6058f2ff":"df.shape","d11d5614":"# Checking out returned products\ndf[df[\"Quantity\"].astype(str).str.startswith(\"-\",na=False)].head()","ea1f162d":"df.head()","766a63d4":"#We are creating a new feature showing the amount of the invoice. (Monetary)\ndf[\"Total_Price\"]=df.Quantity*df.UnitPrice\ndf.head()","bc8822b2":"#Total Price per bill\ndf.groupby(\"InvoiceNo\").agg({\"Total_Price\":\"sum\"}).head()","f8723b69":"# 5 most expensive product\ndf.sort_values(\"UnitPrice\",ascending=False).head()","725f89e9":"# number of orders by country \ndf[\"Country\"].value_counts().head()","79139a30":"#how much money was made from which country?\npd.set_option('display.float_format', lambda x: '%.2f' % x)\ndf.groupby(\"Country\").agg({\"Total_Price\":\"sum\"}).sort_values(by=\"Total_Price\",ascending=False).head()","b034a61a":"def manage_outliers(df,q1=0.05,q3=0.95,method=\"quantiles\",\n                    inplace=False):\n    if method==\"quantiles\":\n        for feature in df:\n            Q1 = df[feature].quantile(q1)\n            Q3 = df[feature].quantile(q3)\n            IQR = Q3-Q1\n            lower = Q1- 1.5*IQR\n            upper = Q3 + 1.5*IQR\n            if df[(df[feature] > upper)].any(axis=None):\n                print(color.BOLD+color.UNDERLINE+feature+\":\"+color.END,\"OUTLIERS\"+\" \",sep=\"\\n\")\n                print(df[(df[feature] > upper)])\n                if inplace==True:\n                    df.loc[df[feature] > upper,feature] = upper\n                    return df\n                print(\"*******************************O*******************************\")\n            else:\n                print(color.BOLD+color.UNDERLINE+feature+color.END+\": There aren't outliers in this feature\"+color.END+\" \")\n                print(\"*******************************O*******************************\")\n    elif method==\"LOF\":\n        from sklearn.neighbors import LocalOutlierFactor\n        n_neighbors=int(input(\"n_neighbors(default=20): \"))\n        clf = LocalOutlierFactor(n_neighbors=n_neighbors)\n        clf.fit_predict(df)\n        df_scores = clf.negative_outlier_factor_\n        print(np.sort(df_scores)[0:30])\n        threshold=int(input(\"threshold: \"))\n        threshold=np.sort(df_scores)[threshold-1]\n        print(threshold)\n        print(df[df_scores< threshold])\n        if inplace==True:\n            print(df[df_scores< threshold])\n            df.drop(index=df[df_scores< threshold].index,inplace=True)\n            return df","c7784c08":"num_columns=df[[\"UnitPrice\",\"Quantity\"]]","55d22caf":"num_columns.head()","c35ad735":"manage_outliers(num_columns,inplace=True) \n\"\"\"Outlier Analysis to the quantiles 0,05 and 0,95,\nwe suppress the outliers to the the upper part\"\"\"","e28f227c":"df[[\"UnitPrice\",\"Quantity\"]]=num_columns","a46ac12d":"df.head()","f1d5f987":"# Checking out\nmanage_outliers(df[[\"UnitPrice\",\"Quantity\"]],inplace=False) \n# we only suppressed the outliers left at the top, the ones at the bottom stand.","153e9e48":"# the date of the last purchase\ndf[\"InvoiceDate\"].max()","0855fa4c":"#we consider the date of the last purchase as today's date.\nimport datetime as dt\ntoday_date=dt.datetime(2011,12,9)\ntoday_date","53fc410f":"df.groupby(\"CustomerID\").agg({\"InvoiceDate\":\"max\"}).sort_values(by=\"InvoiceDate\",ascending=False).head()","8fc2965b":"df[\"CustomerID\"].dtype","32a30745":"df[\"CustomerID\"]=df[\"CustomerID\"].astype(int)","f3ce5926":"# Finding Recency Metric\nrecency_df=df.groupby(\"CustomerID\").agg({\"InvoiceDate\": lambda x: (today_date - x.max()).days})\nrecency_df.rename(columns={\"InvoiceDate\":\"Recency\"},inplace=True)\nrecency_df.head()","ed6e5c05":"temp_df=df.groupby([\"CustomerID\",\"InvoiceNo\"]).agg({\"InvoiceNo\":\"count\"})\ntemp_df.head()","71ebbaf3":"# Frequency Per Customer\ntemp_df.groupby(\"CustomerID\").agg({\"InvoiceNo\":\"count\"}).head()","bb250c8f":"freq_df=temp_df.groupby(\"CustomerID\").agg({\"InvoiceNo\":\"count\"})\nfreq_df.rename(columns={\"InvoiceNo\":\"Frequency\"},inplace=True)\nfreq_df.head()","a9c47373":"monetary_df=df.groupby(\"CustomerID\").agg({\"Total_Price\":\"sum\"})\nmonetary_df.rename(columns={\"Total_Price\":\"Monetary\"},inplace=True)\nmonetary_df.head()","82cfc5bc":"#we create rfm table by combining these 3 tables\nrfm_df=pd.concat([recency_df,freq_df,monetary_df],axis=1)\nrfm_df.head()","6fc9c131":"from sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler((0,1))\ndf = sc.fit_transform(rfm_df)\ndf[0:5]","31c6dfd3":"rfm_df_m=rfm_df.copy()","3241b578":"# we label customers by segment\nrfm_df_m[\"RecencyScore\"] = pd.qcut(rfm_df['Recency'], 5, labels = [5, 4, 3, 2, 1])\nrfm_df_m[\"FrequencyScore\"] = pd.qcut(rfm_df['Frequency'].rank(method=\"first\"), 5, labels = [1, 2, 3, 4,5])\nrfm_df_m[\"MonetaryScore\"]=pd.qcut(rfm_df[\"Monetary\"],5,labels=[1,2,3,4,5])\nrfm_df_m.head()","5a8b1465":"# rfm score\nrfm_df_m[\"RFM_Score\"]=rfm_df_m.FrequencyScore.astype(str)+rfm_df_m.MonetaryScore.astype(str)+rfm_df_m.RecencyScore.astype(str)\nrfm_df_m.head()","b14ff652":"# Hibernating Customers\nrfm_df_m[rfm_df_m[\"RFM_Score\"]==\"111\"].head(3)","e1fe876d":"# segmentation with the help of regex\nseg_map = {\n    r'[1-2][1-2]': 'Hibernating',\n    r'[1-2][3-4]': 'At Risk',\n    r'[1-2]5': 'Can\\'t Loose',\n    r'3[1-2]': 'About to Sleep',\n    r'33': 'Need Attention',\n    r'[3-4][4-5]': 'Loyal Customers',\n    r'41': 'Promising',\n    r'51': 'New Customers',\n    r'[4-5][2-3]': 'Potential Loyalists',\n    r'5[4-5]': 'Champions'\n}\nrfm_df_m['Segment'] = rfm_df_m['RecencyScore'].astype(str) + rfm_df_m['MonetaryScore'].astype(str)\nrfm_df_m['Segment'] = rfm_df_m['Segment'].replace(seg_map, regex=True)\nrfm_df_m.head()","c1caeb8a":"kmeans = KMeans(n_clusters = 5)\nk_fit = kmeans.fit(df)\nk_fit.labels_","40f3482a":"clusters = k_fit.labels_\nkmeans_clusters = pd.DataFrame({\"Customer ID\": rfm_df.index, \"Cluster\": clusters})\nkmeans_clusters.head()","fbae9c24":"rfm_df[\"cluster_no\"] = clusters\nrfm_df[\"cluster_no\"] = rfm_df[\"cluster_no\"] + 1\nrfm_df.head()","4c636b30":"# In order to accurately represent how many classes customers should be divided into\nfrom yellowbrick.cluster import KElbowVisualizer\nkmeans = KMeans()\nvisu = KElbowVisualizer(kmeans, k = (2,20))\nvisu.fit(df)\nvisu.poof();","08bda209":"rfm_df.head()","a9d7fc61":"By looking at the intersection, we can say that 5 and 6 clusters are optimal. We have already choose 5 clusters.\n.","710043ee":"### Outlier Analysis","45f32a92":"### Scaling","234f1b71":"### Recency","021a391f":"### Recency","9d11d77e":"Negative values probably refer to returned products.Let's find all the negative values and drop.Because at this point, we will focus the sales for RFM analysis.","3ed67db1":"### Modelling","0bc645b6":"### Frequency","a830e615":"### Customer Segmentation with K-means","46c7b91f":"### Importing Libraries","fbdd10d0":"### Reading Data","1b9998b8":"### Monetary","d9a9ee0d":"### Manual Customer Segmentation ","a2cf61cd":"### Hyperparameter optimization","abab3741":"### Data Preprocessing","c4e21bcc":"### Data Understanding and Analysis"}}