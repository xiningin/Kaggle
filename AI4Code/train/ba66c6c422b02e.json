{"cell_type":{"11d5dd6e":"code","ffe6357e":"code","b0d86de9":"code","da2f9409":"code","5e2db7ac":"code","de819333":"code","6c024ba6":"code","f1901253":"code","2e67764c":"code","7aaf7f33":"code","390c7642":"code","de050b67":"code","b3a86e52":"code","363ed539":"code","5809cb4a":"markdown","fe8a1aeb":"markdown","8e0bc01c":"markdown","4a7f6fa5":"markdown","1a6cdf72":"markdown","5489f4ef":"markdown","cc2e0f1b":"markdown","7a1d1879":"markdown","5a9c01c9":"markdown","d0b0d493":"markdown"},"source":{"11d5dd6e":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ffe6357e":"data = pd.read_csv(\"\/kaggle\/input\/biomechanical-features-of-orthopedic-patients\/column_3C_weka.csv\")\ndata.info()","b0d86de9":"data.head()","da2f9409":"data['class'].value_counts()\n# Class label1 = Spondylolisthesis (Ortopedi bir hastal\u0131k t\u00fcr\u00fc)\n# Class label2 = Normal\n# Class label3 = Hernia (F\u0131t\u0131k hastal\u0131\u011f\u0131)","5e2db7ac":"spl = data[data['class'] == 'Spondylolisthesis']\nnormal = data[data['class'] == 'Normal']\nhernia = data[data['class'] == 'Hernia']","de819333":"# Scatter plot\nplt.scatter(spl.lumbar_lordosis_angle, spl.sacral_slope, label=\"Spondylolisthesis\",color=\"red\",alpha=0.5)\nplt.scatter(normal.lumbar_lordosis_angle, normal.sacral_slope, label=\"Normal\",color=\"Green\",alpha=0.5)\nplt.scatter(hernia.lumbar_lordosis_angle, hernia.sacral_slope, label=\"Hernia\",color=\"Blue\",alpha=0.2)\nplt.xlabel(\"lumbar_lordosis_angle\")\nplt.ylabel(\"sacral_slope\")\nplt.legend()\nplt.show()","6c024ba6":"# Normal = 0   , Spondylolisthesis = 1, Hernia=2\ndata['class'] = [0 if each == \"Normal\" else 1 if each == \"Spondylolisthesis\" else 2 for each in data['class']]\n\ny = data['class'].values\nx_data = data.drop(['class'],axis=1)\nx_data.head()","f1901253":"x = (x_data - np.min(x_data)) \/ (np.max(x_data) - np.min(x_data))\nx.head()","2e67764c":"# train test split\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.4,random_state=1)","7aaf7f33":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 3) # n_neighbors = k\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)","390c7642":"prediction","de050b67":"print(\"{} nn score: {} \".format(3,knn.score(x_test,y_test))) #k = hyper parameter","b3a86e52":"score_list = []\nfor each in range(1,50):\n    knn2 = KNeighborsClassifier(n_neighbors = each) # n_neighbors = k\n    knn2.fit(x_train,y_train)\n    knn2.score(x_test,y_test)\n    score_list.append(knn2.score(x_test,y_test))\nplt.plot(range(1,50),score_list)\nplt.xlabel(\"K Values\")\nplt.ylabel(\"Accuracy( K Values)\")\nplt.show()","363ed539":"max_accuracy_value= max(score_list) # what is max score value ?\nmax_accuracy_k = score_list.index(max_accuracy_value)+1   # what is hyper parameter(k) value for max score ?\nprint(\"for max score ==> k={},score={}\".format(max_accuracy_k,max_accuracy_value))","5809cb4a":"    Yap\u0131lacak s\u0131n\u0131fland\u0131rma i\u015fleminde\n    test veri setinde yer alan g\u00f6zlem noktalar\u0131n\u0131n a\u015fa\u011f\u0131da yer alan hastal\u0131k t\u00fcrlerinden\n    hangisine sahip oldu\u011fu tahmin edilecektir.\n    Normalde test veri seti dataset'in kendisinden t\u00fcredi\u011fi i\u00e7in:\n    Class labellar\u0131da bellidir fakat biz tahminlerimiz ile ger\u00e7ekte olan sonu\u00e7lar\u0131 k\u0131yaslayarak\n    kurdu\u011fumuz modelin do\u011frulu\u011funu ve hata pay\u0131n\u0131 ortaya \u00e7\u0131karaca\u011f\u0131z.\n    \n    -------------------------------------------------------------------------------------\n       \n    In the classification process to be made\n    One of the disease types listed below is the observation points in the test dataset.\n    which one will be guessed.\n    Normally, since the test dataset is derived from dataset itself:\n    Class labels are also obvious, but by comparing our estimates with the actual results\n    We will reveal the accuracy and margin of error of the model we have installed.","fe8a1aeb":"<a id=\"7\" ><\/a>\n# Accuracy Visualize\n    \n    Modelimizin Do\u011fruluk de\u011ferlerinin g\u00f6rselle\u015ftirmesi i\u00e7in izledi\u011fimiz yol:\n    k parametresi i\u00e7in 1 ile 50 aras\u0131nda de\u011ferler vererek toplam'da 50 kez e\u011fiterek\n    50 \u00e7al\u0131\u015fma sonucu olu\u015fan score de\u011ferlerini score_list dizesine aktard\u0131k.\n    Daha sonra bu de\u011ferleri plot ettik.\n    ----------------------------------------------------------------------\n    \n    The way we follow to visualize the accuracy values \u200b\u200bof our model:\n    By giving values \u200b\u200bbetween 1 and 50 for the k parameter, by training 50 times in total\n    We transferred the score values \u200b\u200bof 50 studies to score_list string.\n    Then we plotted these values.","8e0bc01c":"<a id=\"8\"><\/a>\n# Conclusion","4a7f6fa5":"<a id=\"4\" > <\/a>\n# Data Normalization\n\n\n![a](https:\/\/i.hizliresim.com\/m3ppNz.png)\n","1a6cdf72":"<a id =\"5\" ><\/a>\n# Train Test Split\n\n    Train test split sklearn k\u00fct\u00fcphanesinin bir mod\u00fcl\u00fcd\u00fcr.\n    Bu mod\u00fcl ile veri seti \u00f6\u011frenme veri seti, \u00f6\u011frenme veri seti etiketi, test veri seti ve test veri seti etiketleri olmak \u00fczere 4 de\u011fi\u015fkene b\u00f6l\u00fcmlenebiliyor.\n    B\u00f6l\u00fcmleme i\u015fleminde parametreleri incelersek, x \u00f6\u011frenme veri setini (train_dataset), \n    y test veri setini (test_dataset), test_size ise data setinin ka\u00e7ta ka\u00e7\u0131n\u0131 test i\u00e7in kullan\u0131laca\u011f\u0131n\u0131 belirleyen parametrelerdir.\n    random_state parametresine verdi\u011fimiz rastgele bir de\u011ferle de her split etme i\u015fleminde birinci seferde olu\u015fan random grubunun birdahaki seferlerde de ayn\u0131 \u015fekilde olmas\u0131n\u0131 istedi\u011fimizi belirtiyoruz.\n    Yani random_state'e verilen de\u011feri index olarak d\u00fc\u015f\u00fcn\u00fcrsek bu mod\u00fcl 2. kez kullan\u0131l\u0131rsa index'imizi bakarak yine ayn\u0131 x_\u00f6\u011frenme, x_test, y_\u00f6\u011frenme, y_test d\u00f6rtlemesini kar\u015f\u0131m\u0131za \u00e7\u0131karacakt\u0131r. De\u011ferler de\u011fi\u015ftirilmeden bu sayede alaca\u011f\u0131m\u0131z MSE ve ba\u015far\u0131 skorlar\u0131 de\u011fi\u015fmeyecektir.\n    \n    dataset'de yer alan verilerin %40'\u0131 test i\u00e7in, %60'\u0131 ise \u00f6\u011frenim i\u00e7in kullan\u0131lacak.\n    \n ----------------------------------------------------------------------------------------------------------------\n \n     The train test is a module of the split sklearn library.\n    With this module, the data set can be divided into 4 variables: learning data set, learning data set label, test data set and test data set options.\n    If we examine the evaluation in the segmentation process, x learning data set (train_dataset),\n    y is the test dataset (test_dataset), and test_size are parameters that determine how many of the dataset will be used for testing.\n    It is done in the same way the next time of the random group formed in the first time in its split operation with a random value we give to the random_state parameter.\n    In other words, if we consider this value as the value index given to random_state, you can see the same x_ learning, x_test, y_ learning, y_test quadrances by using our index. MSE and success scores will not change.\n\n    40% of dataset is required for testing and 60% for learning.","5489f4ef":"# INTRODUCTION\n-  (Our aim in this kernel is to classify the orthopedic patients using the K Nearest Neighborhood algorithm (KNN) using their biomedical features.)\n- Bu kernelde amac\u0131m\u0131z: biomedikal featurelerini kullanarak ortopedik hastalar i\u00e7in K Nearest Neighborhood (KNN) algoritmas\u0131 ile s\u0131n\u0131fland\u0131rma yapmakt\u0131r.\n- KNN algoritmas\u0131ndan bahsedecek olursak:\n\n        KNN algoritmas\u0131 bir s\u0131n\u0131fland\u0131rma algoritmas\u0131d\u0131r. Yapaca\u011f\u0131 i\u015flem temel olarak verilen g\u00f6zlem noktalar\u0131n\u0131n\n        hangi s\u0131n\u0131fa ait oldu\u011funu belirlemektir.\n        Hangi s\u0131n\u0131fa ait oldu\u011funu belirlemek i\u00e7in train(\u00f6\u011frenme) veri setinde yer alan noktalar\u0131n uzakl\u0131klar\u0131n\u0131 (distances)referans alarak s\u0131n\u0131fland\u0131rma i\u015flemi yapar. Test veri setinde yer alan noktalar ile \u00f6\u011frenme veri setinde yer alan noktalar\u0131n birbirlerine olan uzakl\u0131klar\u0131 hesaplan\u0131r. En yak\u0131n K adet uzakl\u0131k belirlenir. Belirlenen K adet uzakl\u0131klara ait g\u00f6zlem noktalar\u0131n\u0131n s\u0131n\u0131f etiketleri (class label) k\u0131yaslan\u0131r. \n        \u00d6rnek verecek olursa 3 adet g\u00f6zlem noktas\u0131n\u0131n s\u0131n\u0131f etiketlerinin \"abnormal\", \"normal\", \"abnormal\" oldu\u011funu varsayal\u0131m. Hangi s\u0131n\u0131fa ait oldu\u011funu belirlemek i\u00e7in unique s\u0131n\u0131f de\u011ferlerinin count de\u011ferine bak\u0131l\u0131r, yani 2 adet \"abnormal\", 1 adet \"normal\" etiket bulundu\u011funa g\u00f6re test veri setinde yer alan ilgili g\u00f6zlemin yeni s\u0131n\u0131f de\u011feri \"abnormal\" olarak belirlenir.\n        Bu i\u015flem t\u00fcm test veri setindeki her g\u00f6zlem noktas\u0131na uygulanarak her bir g\u00f6zlemin s\u0131n\u0131f de\u011feri tahmin edilir.\n        Yap\u0131lan tahmin i\u015fleminin do\u011frulu\u011funu s\u0131namak i\u00e7in Mean Square Error (MSE) tekni\u011fi kullan\u0131l\u0131r. MSE de\u011ferini en az indirgemek hedeftir.\n  **Hangi K parametresinin en iyi sonucu verece\u011fi bilinmemektedir. K parametresi bir hyper parameter'dir. Yani model kurulduktan sonra hangi k de\u011feri en iyi sonucu verecek denenerek bulunabilir.**\n\n1.) [Data Info](#1)<br>\n2.) [Data Visualization](#2)<br>\n3.) [Determination and Seperation of Data](#3)<br>\n4.) [Data Normalization](#4)<br>\n5.) [Train Test Split](#5)<br>\n6.) [create model KNN](#6)<br>\n7.) [Accuracy Visualize](#7)<br>\n8.) [Conclusion](#8)<br>\n\n\n","cc2e0f1b":"<a id=\"1\"> <\/a>\n# Data Info","7a1d1879":"<a id=\"2\"> <\/a>\n# Data Visualization","5a9c01c9":"<a id = \"3\"> <\/a>\n# Determination and Seperation of Data","d0b0d493":"<a id=\"6\" > <\/a>\n# Create Model KNN\n    Sklearn k\u00fct\u00fcphanesinin neighbours mod\u00fcl\u00fcn\u00fc importla ba\u015flad\u0131k\n    n_neighbors yani K parametremizi belirledik.\n    modelimize x_train ve y_train yani \u00f6\u011frenme veri seti ve etiketlerini vererek e\u011fittik,\u00f6\u011frettik.\n    test veri setinde yer alan g\u00f6zlemleri modelimizi kullanarak tahmin ettik.\n    ----------------------------------------------------------------------------   \n    We started importing the neighbors module of the Sklearn library\n    We have determined our n_neighbors, K parameter.\n    We trained and taught x_train and y_train, that is, learning data set and tags.\n    using the ground observations model in the test data set."}}