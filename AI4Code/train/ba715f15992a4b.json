{"cell_type":{"e16f84b8":"code","7e6158c4":"code","cd3d997d":"code","33bc95d2":"code","30a29a0a":"code","549240c0":"code","7954f00b":"markdown","7e2dfae3":"markdown","974dfc84":"markdown","67795ae7":"markdown"},"source":{"e16f84b8":"# install magic module\n! pip install python-magic","7e6158c4":"# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"..\/input\/sheep-data-validation-script\/virginia-lamb-data-validation-script.py\", dst = \"..\/working\/script.py\")\n\n# import all our functions\nfrom script import *","cd3d997d":"# use the script we imported for data validation \n# you can see a copy of the script here\ncheck_lamb_data(\"..\/input\/lamb-auction-data\/\")","33bc95d2":"import pandas as pd\n\n# create an empty dataframe for our clean data\ncleaned_data = pd.DataFrame()\n\n# we'll use these labels in each loop, so it's more efficient\n# to declare them out of the loop\ncolumn_labels = [\"category\",\"head_sold\"]\n\n# loop through every .txt file in our target directory\nfor file in glob.glob(\"..\/input\/lamb-auction-data\/*.txt\"):\n   \n    # read in all the data for a specific file (they're small\n    # so this shouldn't be a big problem)\n    data = open(file).read()\n   \n    # find # of head sold\n    sales = re.findall('(lamb|ram|ewe|wether|sheep).* (.*) head', data.lower())\n    \n    # name of market (always on fourth line)\n    market = data.split(sep=\"\\n\")[3]\n\n    # date reported\n    reported = re.findall(\"Richmond, VA(.*)\", data)\n    date = dparser.parse(reported[0],fuzzy=True).date()\n\n    # only proceed from here if there was one or more sales\n    if len(sales) > 0:\n        \n        df_temp = pd.DataFrame.from_records(sales, columns=column_labels)\n        df_temp[\"market\"] = market\n        df_temp[\"date_reported\"] = date\n\n    # add data about markets with no sheep sales\n    else:\n        df_temp = pd.DataFrame(data={\"category\": [\"none\"], \"head_sold\": [0]})\n        df_temp[\"market\"] = market\n        df_temp[\"date_reported\"] = date\n    \n    # append data to our cleaned data\n    cleaned_data = cleaned_data.append(df_temp, ignore_index=True)","30a29a0a":"# now let's take a peek at the cleaned data and make sure it looks good\ncleaned_data","549240c0":"# save our data as a .csv file\ncleaned_data.to_csv(\"\/kaggle\/working\/cleaned_lamb_data.csv\", index=False)","7954f00b":"# Data validation\n\nThis step (which we talked about yesterday) lets you check to make sure your data meets your expectations. \n\nHere, I've written a little Python script for data validation ([you can see a copy here](https:\/\/www.kaggle.com\/rtatman\/virginia-lamb-data-validation-script?scriptVersionId=10091127)), imported it in the code cell above and am using it to quickly validate my data. ","7e2dfae3":"# Boilerplate code \n\nFirst, we need to get our environment set up and read in every thing we'll need. ","974dfc84":"# Save out our data\n\nNow that our data is all cleaned and good to go, we can save it out as its own file.\n\n> **Note**: You should save your data to the directory \"\/kaggle\/working\/\". This ensures that when you commit your kernel, your data will be saved as output. \n\nWith our file saved, we can commit our kernel using the \"Commit\" button. This will run our code top to bottom, save the current version of our kernel, and create an output file we can use to create a new dataset from.","67795ae7":"# Data cleaning\n\nNow that I've validated my data and see that everything looks ok, I can do my data cleaning! These files have a lot of information on Cattle in them, but I'm only interested in the number of sheep sold. I can get that information from these flat text files with a little bit of general data munging, like so:"}}