{"cell_type":{"ec64a0c9":"code","bb14acbe":"code","3bbe7756":"code","28ee506d":"code","6ba6b70d":"code","0eaeaf9a":"code","61ea7401":"code","c998f785":"code","b103f329":"code","e9b51cd2":"code","7b6d33c4":"code","ddb06faa":"code","38f42192":"code","52922269":"code","8d7cdddf":"code","22f50075":"code","28492e8e":"code","9f1eb25f":"code","d82e2354":"code","aa3e2dbc":"code","494e2b41":"code","a842669a":"code","25b4271d":"code","3b0293b6":"code","3c01b8bc":"code","44000303":"code","7dbd50c3":"code","d715155f":"code","e99c5169":"code","29a99299":"code","bab01d6f":"code","6e658914":"code","ddeb7187":"code","1b9ad4af":"code","4cd53018":"code","172b60c9":"code","313648e6":"code","04862226":"code","84fbea91":"code","7d5717f4":"code","9a7f15e2":"code","0c41e0ec":"code","ef17ade8":"code","f57fc814":"code","f1172bb3":"code","aa1f00f2":"code","b4f23a68":"code","e60961e0":"code","d94e981d":"code","1703d9fc":"code","8928038c":"code","e6836341":"code","31945497":"code","f10e2d4e":"code","3ae68097":"code","9d7c586d":"code","85c55957":"markdown","635b9dd7":"markdown","4baa5ce8":"markdown","22c88712":"markdown","54c817ee":"markdown","a38255b5":"markdown","35efa0a0":"markdown","a3c84d91":"markdown","49d13759":"markdown","b5739dc2":"markdown","200cad46":"markdown","7781e3f2":"markdown","02b04577":"markdown","5ee55aab":"markdown","4fedb8fd":"markdown"},"source":{"ec64a0c9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nsns.set_theme(style='white')\nsns.set(rc = {'figure.figsize':(20,6)}, font=\"Arial\", font_scale=1.3)","bb14acbe":"df_1718 = pd.read_csv('..\/input\/soccer-players-values-and-their-statistics\/transfermarkt_fbref_201718.csv', delimiter=';', index_col=0)\ndf_1819 = pd.read_csv('..\/input\/soccer-players-values-and-their-statistics\/transfermarkt_fbref_201819.csv', delimiter=';', index_col=0)\ndf_1920 = pd.read_csv('..\/input\/soccer-players-values-and-their-statistics\/transfermarkt_fbref_201920.csv', delimiter=';', index_col=0)","3bbe7756":"df_1718.head()","28ee506d":"df_1718['year'] = 2017\ndf_1819['year'] = 2018\ndf_1920['year'] = 2019","6ba6b70d":"df = pd.concat([df_1718, df_1819, df_1920])\ndf.shape","0eaeaf9a":"df.head()","61ea7401":"df.info()","c998f785":"df.index = range(len(df))","b103f329":"df = df.dropna(subset=['value'])\ndf.index = range(len(df))","e9b51cd2":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in split.split(df, df['year']):\n    train_set = df.loc[train_index]\n    test_set = df.loc[test_index]","7b6d33c4":"df_train = train_set.copy()","ddb06faa":"df_cat = train_set.select_dtypes(include=['object'])\ndf_cat.drop(columns=['Attendance','Season'], axis=1, inplace=True)","38f42192":"df_num = train_set.select_dtypes(exclude=['object'])","52922269":"train_set.describe()","8d7cdddf":"from matplotlib.ticker import FuncFormatter\n\ndef millions(x, pos):\n    'The two args are the value and tick position'\n    return '%1.1fM' % (x * 1e-6)\n\n\nformatter = FuncFormatter(millions)","22f50075":"fig, ax = plt.subplots(2, 3, figsize=(15,8))\n\nfor i, yr in enumerate([2017, 2018, 2019]):\n    df_yr = train_set[train_set['year'] == yr].dropna()\n    \n\n    ax[0,i].hist(df_yr.value)\n    ax[0,i].set_title('Value ($) Distribution in %i-%i' % (yr, yr+1))\n    ax[0,i].set_xticks(np.arange(df.value.min(), df.value.max()+50000000, 50_000_000))\n    ax[0,i].set_ylabel('Frequency')\n    ax[0,i].set_yticks(np.arange(0, 2250, 250))\n    ax[0,i].xaxis.set_major_formatter(formatter)\n    \n    ax[1,i].boxplot(df_yr.value)\n    ax[1,i].yaxis.set_major_formatter(formatter)\n    ax[1,i].set_yticks(np.arange(df.value.min(), df.value.max()+50000000, 50_000_000))\n        \n    \nplt.tight_layout()\n\n","28492e8e":"def format_nationality(x):\n    return str(x)[-3:]\n\ntrain_set['nationality'] = train_set[\"nationality\"].map(format_nationality)","9f1eb25f":"nation_count = pd.DataFrame(train_set.nationality.value_counts())","d82e2354":"nation_count[\"hue\"] = np.array([10]*10 + [0]*(len(nation_count)-10))\nnation_count[\"country\"] = nation_count.index\nnation_count.index = range(len(nation_count))","aa3e2dbc":"import matplotlib.patches as patches\n\ng = sns.barplot(x=\"country\", y=\"nationality\", hue=\"hue\", dodge=False,\n                hue_order=[10,0],\n                data=nation_count[:50],\n                palette=\"Blues_r\",\n                )\n\ng.set_title(\"N\u00ba of Athletes per Nation\")\ng.set_ylabel('')\ng.set_xlabel('')\n\nplt.xticks(rotation=90)\n\nplt.text(5, 600, 'Top 10 Nations represent %.1f%% of the total' % (nation_count.nationality[:10].sum()\/nation_count.nationality.sum()*100),\n         color='#264d73', fontsize=16)\nplt.text(30, -80, \"Others\")\n\nfor ind, label in enumerate(g.get_xticklabels()):\n    if ind < 10:  # every 10th label is kept\n        label.set_visible(True)\n    else:\n        label.set_visible(False)\n\ng.legend_.remove()\nplt.show()","494e2b41":"important_nations = nation_count.country[:10].tolist()\n\ntrain_set[\"nationality\"] = train_set.nationality.map(lambda x: x if x in important_nations else \"Other\")","a842669a":"train_set.position.unique()","25b4271d":"train_set.position.replace('0', None, inplace=True)\ntrain_set = train_set.dropna(axis=0, subset=['position'])","3b0293b6":"def format_position_1(x):\n    if len(x) > 2:\n        return x[:2]\n    else:\n        return x\n    \ndef format_position_2(y):\n    if len(y) > 2:\n        return y[3:]\n    else:\n        return 'None'\n    \ntrain_set['position_1'] = train_set.position.map(format_position_1)\ntrain_set['position_2'] = train_set.position.map(format_position_2)\ntrain_set = train_set.drop(columns=['position'], axis=1)","3c01b8bc":"def show_values_on_bars(axs, h_v=\"v\", space=0.4): # function by https:\/\/stackoverflow.com\/users\/7898385\/secant-zhang\n    def _show_on_single_plot(ax):\n        if h_v == \"v\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() \/ 2\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_height())\n                ax.text(_x, _y, value, ha=\"center\") \n        elif h_v == \"h\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_width())\n                ax.text(_x, _y, value, ha=\"left\")\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)\n        \ndef show_values_on_bars_formatted(axs, h_v=\"v\", space=0.4): \n    def _show_on_single_plot(ax):\n        if h_v == \"v\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() \/ 2\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_height())\n                ax.text(_x, _y, formatter(value), ha=\"center\") \n        elif h_v == \"h\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_width())\n                ax.text(_x, _y, formatter(value), ha=\"left\")\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)","44000303":"fig, axs = plt.subplots(1,2)\n\nfor idx, pos in enumerate([\"position_1\", \"position_2\"]):\n    by_position = train_set[[\"value\", pos]].groupby(pos).mean().sort_values(by='value', ascending=False)\n    \n    g = sns.barplot(x=by_position.index, y=by_position.value,\n                palette=\"Greens_r\", ax=axs[idx])\n\n    g.set_title(\"Average Value by Position #\" + str(idx+1))\n    g.set_ylabel('Average Value ($)')\n    g.set_xlabel('Position')\n\n    g.set(yticks=[]) \n\n    show_values_on_bars_formatted(g, h_v=\"v\")\n\nplt.show()","7dbd50c3":"fig, ax = plt.subplots(2,1, sharex=True)\n\ng = sns.stripplot(x=\"league\", y=\"value\", data=train_set, palette=\"CMRmap\",\n                ax=ax[0], alpha=0.5, jitter=True,)\n\nax[0].yaxis.set_major_formatter(formatter)\n\ng.set_title(\"Value ($) by League\")\ng.set_ylabel('Value ($)')\ng.set_xlabel('')\n\ng = sns.boxplot(x=\"league\", y=\"value\", data=train_set, palette=\"CMRmap\",\n                ax=ax[1])\n\nax[1].yaxis.set_major_formatter(formatter)\n\ng.set_xlabel('League')\ng.set_ylabel('')\n\n\nplt.show()","d715155f":"train_set = train_set.dropna(axis=0, subset=['foot'])","e99c5169":"g = sns.countplot(x=\"foot\", data=train_set, palette=\"BuPu\", order=[\"left\", \"both\", \"right\"])\n\ng.set_title(\"N\u00ba of Players by Foot\")\ng.set_ylabel('N\u00ba of Players')\ng.set_xlabel('Foot')\ng.set(yticks=[])\nshow_values_on_bars(g, h_v=\"v\")","29a99299":"by_foot = train_set[[\"value\", \"foot\"]].groupby(\"foot\").mean()\n\nfig, ax = plt.subplots(1,1)\n\ng = sns.violinplot(x=train_set.foot, y=train_set.value, palette=\"BuPu\", order=[\"left\", \"both\", \"right\"],\n                   ax=ax)\n\ng.set_title(\"Value ($) Distribution by Foot\")\ng.set_ylabel('Value ($)')\ng.set_xlabel('Foot')\n\nax.yaxis.set_major_formatter(formatter)\n\nplt.show()","bab01d6f":"def format_Attendance(x):\n    x = str(x)\n    if ',' in x:\n        return round(float(x.replace(',', '')))\n    else:\n        return round(float(x))","6e658914":"train_set[\"Attendance\"] = train_set.Attendance.map(format_Attendance)","ddeb7187":"fig, ax = plt.subplots(1,1)\n\ng = sns.scatterplot(x=\"Attendance\", y=\"value\", data=train_set, palette=\"BuPu\", alpha=0.3,\n                    x_jitter=True, y_jitter=True, edgecolor=\"black\", ax=ax)\n\ng.set_title(\"Value ($) by Attendance\")\ng.set_ylabel('Value ($)')\ng.set_xlabel('Attendance')\n\nax.yaxis.set_major_formatter(formatter)\n\nplt.show()\n","1b9ad4af":"cat_cols = [\"nationality\", \"position\", \"foot\"]","4cd53018":"drop = [\"aerials_lost\", \"aerials_won\", 'crosses_into_penalty_area', 'crosses_stopped_gk',\n        \"pressure_regains\", \"pressures\", \"saves\", ]\n\ntrain_set = train_set.drop(drop, axis=1)","172b60c9":"def correlated(df, threshold, target):\n    '''returns the columns of a dataframe whose correlation with the target is above the threshold'''\n    corr = pd.Series(abs(df.corr()[target]) > threshold)\n    corr_cols = corr.index[corr].tolist()\n    corr_cols.remove(target)\n    return corr_cols\n\nnum_cols_corr = correlated(train_set, 0.3, 'value')","313648e6":"train_set[num_cols_corr].describe()","04862226":"train_set[num_cols_corr].isnull().sum().sum()","84fbea91":"len(num_cols_corr)","7d5717f4":"from pandas.plotting import scatter_matrix\n\nscatter_matrix(train_set[num_cols_corr[:10]], figsize=(20,10))\nplt.tight_layout()\nplt.show()","9a7f15e2":"num_cols = train_set.select_dtypes(exclude=[\"object\"]).columns\nnum_non_corr = list(set(num_cols) - set(num_cols_corr))\ntrain_set[num_non_corr].describe()","0c41e0ec":"fig, ax = plt.subplots(8,8, figsize=(20,20))\n\nfor idx, col in enumerate(num_non_corr[:64]):\n    sns.scatterplot(x=train_set[col], y=train_set.value, ax=ax[idx\/\/8, idx%8])\n    \nplt.tight_layout()\nplt.show()","ef17ade8":"cat_cols","f57fc814":"num_cols = train_set.select_dtypes(exclude=\"object\").columns.tolist()\nnum_cols.remove(\"value\")\nnum_cols.remove(\"Attendance\")","f1172bb3":"df_train = df_train.drop(drop, axis=1)\nX = df_train[num_cols + cat_cols]\ny = df_train.value","aa1f00f2":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass Prepare_Categorical_Data(BaseEstimator, TransformerMixin):\n    def __init__(self, cat_cols):\n        self.cat_cols = cat_cols\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X['nationality'] = X[\"nationality\"].map(format_nationality)\n        X[\"nationality\"] = X.nationality.map(lambda x: x if x in important_nations else \"Other\")\n        X.position.replace('0', None, inplace=True)\n        X['position_1'] = X.position.map(format_position_1)\n        return X[cat_cols]","b4f23a68":"from sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\n\ncat_pipe = Pipeline([\n    ('prepare_cat', Prepare_Categorical_Data(cat_cols)),\n    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n    ('onehot', OneHotEncoder(handle_unknown=\"ignore\"))\n])","e60961e0":"num_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"mean\")),\n    ('scaler', StandardScaler())\n])","d94e981d":"from sklearn.compose import ColumnTransformer\n\ndata_prep_pipe = ColumnTransformer([\n    (\"num\", num_pipe, num_cols),\n    (\"cat\", cat_pipe, cat_cols)\n])","1703d9fc":"X_prep = data_prep_pipe.fit_transform(X)","8928038c":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.svm import SVR\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom scipy.stats import reciprocal, expon\nimport joblib","e6836341":"def get_model(model_name, params):\n    if model_name == \"xgb\":\n        model = xgb.XGBRegressor(**params)\n    elif model_name == \"lgb\":\n        model = lgb.LGBMRegressor(**params)\n    elif model_name == \"svr\":\n        model = SVR(**params)\n    else:\n        model = RandomForestRegressor(**params)\n    return model\n\ndef get_params(model_name):\n    if model_name == \"xgb\":\n        params = {\n            \"n_estimators\": [100, 200, 300, 400, 500],\n            \"max_depth\": [3, 5, 7],\n            \"learning_rate\": [1e-3, 1e-2, 1e-1, 0.5, 1.0],\n        }\n    elif model_name == \"lgb\":\n        params = {\n            \"n_estimators\": [100, 200, 300, 400, 500],\n            \"max_depth\": [3, 5, 7],\n            \"learning_rate\": [1e-3, 1e-2, 1e-1, 0.5, 1.0],\n        }\n    elif model_name == \"svr\":\n        params = {\n            'kernel': ['linear', 'rbf'],\n            'C': reciprocal(20, 200000),\n            'gamma': expon(scale=1.0),\n        }\n    else:\n        params = {\n            \"n_estimators\": [100, 200, 300, 400, 500],\n            \"max_depth\": [3, 5, 7],\n        }   \n    return params\n        ","31945497":"for model_name in [\"xgb\", \"lgb\", \"svr\", \"rf\"]:\n    params = get_params(model_name)\n    model = get_model(model_name, params)\n    search = RandomizedSearchCV(model, params, cv=5, n_iter=10, \n                                scoring=\"neg_mean_squared_error\",\n                                random_state=42)\n    search.fit(X_prep, y)\n    best_score = np.sqrt(-search.best_score_)\n    print(\"Best parameters for {}: {} with the score {:.2f}\".format(model_name, search.best_params_, best_score))","f10e2d4e":"model_name = \"xgb\"\n\nparams = {\n            \"n_estimators\": [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n            \"max_depth\": [3, 5, 7, 9],\n            \"learning_rate\": [1e-3, 1e-2, 1e-1, 0.5, 1.0],\n            \"subsample\": [0.5, 0.7, 0.9, 1.0],\n            \"colsample_bytree\": [0.5, 0.7, 0.9, 1.0],\n            \"gamma\": [0.1, 0.5, 0.7, 1.0],\n        }\nmodel = get_model(model_name, params)\nsearch = RandomizedSearchCV(model, params, cv=5, n_iter=50, \n                            scoring=\"neg_mean_squared_error\",\n                            random_state=42)\nsearch.fit(X_prep, y)\nbest_score = np.sqrt(-search.best_score_)\nprint(\"Best parameters for {}: {} with the score {:.2f}\".format(model_name, search.best_params_, best_score))","3ae68097":"pred_and_prep_pipe = Pipeline([\n    (\"data_prep\", data_prep_pipe),\n    (\"best_model\", search)\n])","9d7c586d":"from sklearn.metrics import mean_squared_error\n\ny_test = test_set.value\nX_test = test_set[num_cols + cat_cols]\n\ntest_preds = pred_and_prep_pipe.predict(X_test)\n\nrmse = np.sqrt(mean_squared_error(y_test, test_preds))\nprint(\"RMSE for test evaluation: {:.2f}\".format(rmse))","85c55957":"# Data Visualization","635b9dd7":"# Evaluating Test Data","4baa5ce8":"The values by Leagues is pretty similar (given that our dataset has only the 5 biggest european leagues).","22c88712":"### Numerical Data","54c817ee":"### Creating Test Set","a38255b5":"# Modeling","35efa0a0":"We can see that is a strong relationship between the 1st position and value, but not so much with the second position.","a3c84d91":"# Introduction\n\nHello there! There is no question that Soccer is the most popular sport in the world, and also one of the most lucrative. Their transfer market moves the media and the investors globally, and estimating correctly the value of each player before their transfer is a valuable asset from fans to professionals. This is the **goal** of this Jupyter Notebook: given the data from the transfer markets from 2017 to 2020 (available\nin https:\/\/www.kaggle.com\/kriegsmaschine\/soccer-players-values-and-their-statistics), I will try to predict using Machine Learning models the value of the soccer athletes. Let's start! ","49d13759":"# Data Preparation","b5739dc2":"### Categorical Data","200cad46":"Given that new data will always be the upcoming year, I used StratifiedShuffleSplit to have a well distributed train and test set by year.","7781e3f2":"### Categorical Attributes","02b04577":"### Numerical Attributes","5ee55aab":"As the top 10 nations represent 69.4% of the training data, I will label the other nationalities as `Others`.","4fedb8fd":"# Reading Data"}}