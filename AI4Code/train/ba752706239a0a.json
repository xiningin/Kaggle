{"cell_type":{"be9e5b5c":"code","c78885ce":"code","7fed912b":"code","b3c267cb":"code","a5ef902b":"code","c7d25e75":"code","8f6d42fd":"code","cb63c52d":"code","6b1dd913":"code","4ea87642":"code","76a7b572":"code","082994e9":"code","abaee1b5":"code","d334ae4f":"code","b3d47034":"code","b31201bc":"code","3c4366ca":"code","656c84eb":"code","a8deede4":"code","b29c94ce":"code","053f7101":"code","4dae3f8d":"code","a726995f":"code","1bb76a58":"code","48bebd8a":"code","04a153d0":"code","ca23a104":"code","898f412b":"code","41f622f1":"code","0c89ed80":"code","f8a2a6b0":"code","aa79ceb9":"code","1ddb9908":"code","bb290e8b":"code","a58f5658":"code","cf168b20":"code","6b83b971":"code","0b481299":"code","10dee393":"markdown","10cc5da4":"markdown","ab3ae579":"markdown","76ab1508":"markdown","cdd87d3d":"markdown","6a77c152":"markdown","f2df4cbe":"markdown","1d57bd86":"markdown","68de5c69":"markdown"},"source":{"be9e5b5c":"#importing the library\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#for LSTM layers of neurons\nimport tensorflow as tf","c78885ce":"st_df = pd.read_csv('\/kaggle\/input\/pakistan-stock-exchange-kse-100\/Stock Exchange KSE 100(Pakistan).csv')","7fed912b":"st_df.shape","b3c267cb":"st_df.info()","a5ef902b":"#resetting the index\nst_df['Date'] = pd.to_datetime(st_df['Date'])\nst_df.set_index('Date',inplace=True)","c7d25e75":"#remove the comma in prices\nst_df = st_df.replace(regex=[','], value='')","8f6d42fd":"#change the datatype of columns\nst_df['Open'] = pd.to_numeric(st_df['Open'], errors='coerce')\nst_df['Close'] = pd.to_numeric(st_df['Close'], errors='coerce')\nst_df['High'] = pd.to_numeric(st_df['High'], errors='coerce')\nst_df['Low'] = pd.to_numeric(st_df['Low'], errors='coerce')\nst_df['Change'] = pd.to_numeric(st_df['Change'], errors='coerce')\nst_df['Volume'] = pd.to_numeric(st_df['Volume'], errors='coerce')","cb63c52d":"st_df.info()","6b1dd913":"st_df.head()","4ea87642":"st_df.describe()","76a7b572":"#checking null values\nst_df.isnull().sum()","082994e9":"#checking not a number nan value\nst_df.isna().sum()","abaee1b5":"#dropping the duplicates\nst_df.drop_duplicates(keep=False, inplace=True)","d334ae4f":"st_df.shape","b3d47034":"#correlation b\/w columns\/ variables\ncorrelation = st_df.corr()","b31201bc":"#finding the correlation b\/w variables\nsns.heatmap(correlation, xticklabels=correlation.columns, \n            yticklabels=correlation.columns, \n            annot=True)","3c4366ca":"#finding the outliers in dataset\nst_df.boxplot()","656c84eb":"#taking the Quantile (q1) and q3 and then subtract it for to find inter quantile range\nQ1 = st_df.quantile(0.25)\nQ3 = st_df.quantile(0.75)\n\nIQR = Q3-Q1\nprint(IQR)","a8deede4":"st_df = st_df[~((st_df < (Q1 -1.5 * IQR)) | (st_df > (Q3 + 1.5 *IQR))).any(axis=1)]","b29c94ce":"st_df.boxplot()","053f7101":"#viualize the variables\nsns.pairplot(st_df)","4dae3f8d":"#visualize the volume of stock price\nst_df['Volume'].plot(figsize=(15,5))","a726995f":"np.log(st_df['Volume']).plot(figsize=(15,5))","1bb76a58":"#visualize the volume quarterly\nst_df['Volume'].resample('Q').mean().plot(figsize=(20,10), kind='line')","48bebd8a":"#visualize change in stocks\nst_df['Change'].resample('Q').mean().plot(figsize=(20,10), kind='line')","04a153d0":"closing = st_df[['Close']]\nst_df.rolling(12).mean().plot(figsize=(20,10), color=['yellow','red', 'green', 'blue','brown','orange'],linewidth=5, fontsize=20)","ca23a104":"#visualize open and close of market by taking mean\nOpen_close = pd.concat([st_df[['Open']].rolling(12).mean(), st_df[['Close']].rolling(12).mean()], axis=1)\nOpen_close .plot(figsize=(20,10), linewidth=5, fontsize=20)\nplt.xlabel('Year', fontsize=20)","898f412b":"# #searching for the market crash in 2008\n# from googlesearch import search\n# query = 'Pakistan stock market crash 2008'\n  \n# print('Links for market crash:')\n# for j in search(query, num=5, stop=5):\n#     print(j)","41f622f1":"#visualize the high and low price\nhigh_close = pd.concat([st_df[['High']].rolling(12).mean(), st_df[['Low']].rolling(12).mean()], axis=1)\nhigh_close.plot(figsize=(20,10), linewidth=5, fontsize=15)\nplt.xlabel('Year', fontsize=15)","0c89ed80":"#importing the libraries for LSTM\nimport math\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import LSTM\nfrom keras.layers import *\n\n#scaling the input and output\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\n","f8a2a6b0":"#splitting the dataset in train and test\ntrain_set = st_df.iloc[:800, 1:2].values\ntest_set = st_df.iloc[800:,1:2].values\n\nprint(train_set.shape)\nprint(test_set.shape)","aa79ceb9":"# train_set,test_set","1ddb9908":"#scaling the train and test data\n# st_df = st_df.reset_index()\nscale = MinMaxScaler(feature_range = (0,1))\ntrain_set_scaling = scale.fit_transform(train_set)\n\ntrain_X = []\ntrain_y = []\n\nfor i in range(60, len(train_set_scaling)):\n    train_X.append(train_set_scaling[i-60:i, 0])\n    train_y.append(train_set_scaling[i, 0])\n    \ntrain_X, train_y = np.array(train_X), np.array(train_y)\n\ntrain_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1],1))\n","bb290e8b":"model = Sequential()\n\n#adding the input layer\nmodel.add(LSTM(30, return_sequences=True, input_shape=(train_X.shape[1],1)))\nmodel.add(Dropout(0.3))\n\n#Dense layers\nmodel.add(LSTM(50, return_sequences=True))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(100, return_sequences=True))\nmodel.add(Dropout(0.3))\n\nmodel.add(LSTM(50))\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(30,activation='relu'))\n\n#ouput layer\nmodel.add(Dense(1, activation='softmax'))\n\n#calculating loss\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n# fit network\nmodel.fit(train_X, train_y, epochs=100, batch_size=25)\n\n","a58f5658":"#setting the test data\ntrain_data = st_df.iloc[:800 ,1:2]\ntest_data = st_df.iloc[800: ,1:2]\n\ndf = pd.concat((train_data, test_data), axis=0)\n\ninputs = df[len(df)-len(test_data)-60:].values\n\ninputs = inputs.reshape(-1, 1)\ninputs = scale.transform(inputs)\ntest_X = []\n\nfor i in range(60, 519):\n    test_X.append(inputs[i-50:i, 0])\n    \ntest_X = np.array(test_X)\ntest_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))\nprint(test_X.shape)\n                                          ","cf168b20":"train_X.shape","6b83b971":"#preding the closing price of stock\npred_stk_price = model.predict(test_X)\npred_stk_price = scale.inverse_transform(pred_stk_price)\n","0b481299":"plt.figure(figsize=(20,10))\nplt.plot(test_data,'red',label='Closing Prices')\nplt.plot(pred_stk_price,'blue',label='Predicted closing Prices')\nplt.xlabel('Date',size=20)\nplt.xticks(size=20)\nplt.ylabel('Prices',size=20)\nplt.yticks(size=20)\nplt.title('Real vs Predicted closing Prices')\nplt.legend(loc='best', fontsize=20)","10dee393":"1. Exploratory Data Analysis\n    * Correlation\n    * Removing outliers from dataset\n    * Visualization of Data\n        * Why Stock market crash in 2009\n        \n   \n    \n2. Long-Short Term Model LSTM for prediction\n    * Spliting the Dataset\n    * Using Min Max Scaler for scaling data\n    * LSTM\n    * Prediction","10cc5da4":"### Handling outliers","ab3ae579":"### Stock Market Crashing","76ab1508":"The difference b\/w 75% percentile and max value is not high its mean there is less number of outliers in our dataset","cdd87d3d":"\n* In the start of 2008 Pakistan stock market is going to crash","6a77c152":"## Exploraotry Data Analysis - EDA","f2df4cbe":"# Stock Market Prediction ","1d57bd86":"## Long Short Term Model - LSTM","68de5c69":"# Roll NO  : Name\n# CS-172061 : Moiz Ullah Khan\n# CS172029 : Muhammad Qasim\n# CS172041 : Haider Naseer"}}