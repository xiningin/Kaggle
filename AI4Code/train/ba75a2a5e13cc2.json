{"cell_type":{"0d518183":"code","06bc3f03":"code","f8e7c9c0":"code","4097d2e4":"code","184cf894":"code","16fe7fba":"code","c8dfae60":"code","ca773152":"markdown","1e5c482d":"markdown","36c09d1f":"markdown","67f9430f":"markdown","0a4b310e":"markdown","8253b70f":"markdown"},"source":{"0d518183":"\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nimport matplotlib.pyplot as plt\nimport tempfile\nfrom six.moves.urllib.request import urlopen\nfrom six import BytesIO\n\nimport numpy as np\nfrom PIL import Image\nfrom PIL import ImageColor\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageOps\n","06bc3f03":"# in this notebook we will use ssd MobileNetV2\n# if you want too see other pre-trained models you can check tensorflow hub official website at\n# the following url : https:\/\/tfhub.dev\/\n\n# select the model \nmodule_name = 'https:\/\/tfhub.dev\/google\/openimages_v4\/ssd\/mobilenet_v2\/1'\n\n# load the model \nmodel  = hub.load(module_name)\n\n","f8e7c9c0":"# let's see the different signitures of this model \nprint(model.signatures.keys())\n# it turns out that this model has only one signuture and it's the default one \n\n# so we will use the deafult one \n\ndetector  = model.signatures['default']\n","4097d2e4":"# for downloading , resizing and display images , we will use the following functions : \ndef display_image(image):\n    \"\"\"\n    Displays an image inside the notebook.\n    This is used by download_and_resize_image()\n    \"\"\"\n    fig = plt.figure(figsize=(20, 15))\n    plt.grid(False)\n    plt.imshow(image)\n\n\ndef download_and_resize_image(url, new_width=256, new_height=256, display=False):\n    '''\n    Fetches an image online, resizes it and saves it locally.\n    \n    Args:\n        url (string) -- link to the image\n        new_width (int) -- size in pixels used for resizing the width of the image\n        new_height (int) -- size in pixels used for resizing the length of the image\n        \n    Returns:\n        (string) -- path to the saved image\n    '''\n    \n    \n    # create a temporary file ending with \".jpg\"\n    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n    \n    # opens the given URL\n    response = urlopen(url)\n    \n    # reads the image fetched from the URL\n    image_data = response.read()\n    \n    # puts the image data in memory buffer\n    image_data = BytesIO(image_data)\n    \n    # opens the image\n    pil_image = Image.open(image_data)\n    \n    # resizes the image. will crop if aspect ratio is different.\n    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n    \n    # converts to the RGB colorspace\n    pil_image_rgb = pil_image.convert(\"RGB\")\n    \n    # saves the image to the temporary file created earlier\n    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n    \n    print(\"Image downloaded to %s.\" % filename)\n    \n    if display:\n        display_image(pil_image)\n\n    \n    return filename","184cf894":"image_url  = 'https:\/\/bevasarloutca.hu\/uploads\/shops\/small-img-15632723829756.jpg'\ndownloaded_resized_image = download_and_resize_image(image_url, new_width=256, new_height=256, display=True) ","16fe7fba":"# we will use the following functions to draw bounding boxes \ndef draw_bounding_box_on_image(image,\n                               ymin,\n                               xmin,\n                               ymax,\n                               xmax,\n                               color,\n                               font,\n                               thickness=4,\n                               display_str_list=()):\n\n    \"\"\"\n    Adds a bounding box to an image.\n    \n    Args:\n        image -- the image object\n        ymin -- bounding box coordinate\n        xmin -- bounding box coordinate\n        ymax -- bounding box coordinate\n        xmax -- bounding box coordinate\n        color -- color for the bounding box edges\n        font -- font for class label\n        thickness -- edge thickness of the bounding box\n        display_str_list -- class labels for each object detected\n    \n    \n    Returns:\n        No return.  The function modifies the `image` argument \n                    that gets passed into this function\n    \n    \"\"\"\n    draw = ImageDraw.Draw(image)\n    im_width, im_height = image.size\n    \n    # scale the bounding box coordinates to the height and width of the image\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                ymin * im_height, ymax * im_height)\n    \n    # define the four edges of the detection box\n    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n             (left, top)],\n            width=thickness,\n            fill=color)\n\n    # If the total height of the display strings added to the top of the bounding\n    # box exceeds the top of the image, stack the strings below the bounding box\n    # instead of above.\n    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n    # Each display_str has a top and bottom margin of 0.05x.\n    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n\n    if top > total_display_str_height:\n        text_bottom = top\n    else:\n        text_bottom = top + total_display_str_height\n        \n    # Reverse list and print from bottom to top.\n    for display_str in display_str_list[::-1]:\n        text_width, text_height = font.getsize(display_str)\n        margin = np.ceil(0.05 * text_height)\n        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n                        (left + text_width, text_bottom)],\n                       fill=color)\n        draw.text((left + margin, text_bottom - text_height - margin),\n                  display_str,\n                  fill=\"black\",\n                  font=font)\n        text_bottom -= text_height - 2 * margin\n\n\ndef draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n    \"\"\"\n    Overlay labeled boxes on an image with formatted scores and label names.\n    \n    Args:\n        image -- the image as a numpy array\n        boxes -- list of detection boxes\n        class_names -- list of classes for each detected object\n        scores -- numbers showing the model's confidence in detecting that object\n        max_boxes -- maximum detection boxes to overlay on the image (default is 10)\n        min_score -- minimum score required to display a bounding box\n    \n    Returns:\n        image -- the image after detection boxes and classes are overlaid on the original image.\n    \"\"\"\n    colors = list(ImageColor.colormap.values())\n\n    try:\n        font = ImageFont.truetype(\"\/usr\/share\/fonts\/truetype\/liberation\/LiberationSansNarrow-Regular.ttf\",\n                              25)\n    except IOError:\n        print(\"Font not found, using default font.\")\n        font = ImageFont.load_default()\n\n    for i in range(min(boxes.shape[0], max_boxes)):\n        \n        # only display detection boxes that have the minimum score or higher\n        if scores[i] >= min_score:\n            ymin, xmin, ymax, xmax = tuple(boxes[i])\n            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n                                         int(100 * scores[i]))\n            color = colors[hash(class_names[i]) % len(colors)]\n            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n\n            # draw one bounding box and overlay the class labels onto the image\n            draw_bounding_box_on_image(image_pil,\n                                       ymin,\n                                       xmin,\n                                       ymax,\n                                       xmax,\n                                       color,\n                                       font,\n                                       display_str_list=[display_str])\n            np.copyto(image, np.array(image_pil))\n        \n    return image","c8dfae60":"# 1 read the image \nimg = tf.io.read_file(downloaded_resized_image)\n    \n# 2 convert it to a tensor\nimg = tf.image.decode_jpeg(img, channels=3)\n\n# 3 add a batch dimension because the model expect a list of images \nconverted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n    \n# 4 run the detector :) \n\nresult = detector(converted_img)\n\n  \n# 5 save the results in a dictionary\nresult = {key:value.numpy() for key,value in result.items()}\n\n#  6 print results\nprint(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n\n# 7 draw predicted boxes over the image\nimage_with_boxes = draw_boxes(\n      img.numpy(), result[\"detection_boxes\"],\n      result[\"detection_class_entities\"],\n      result[\"detection_scores\"])\n\n# 8 display the image\ndisplay_image(image_with_boxes)","ca773152":"# 1. import the necessry libraries ","1e5c482d":"# 5. draw bounding boxes  ","36c09d1f":"# 6. run detector ","67f9430f":"# 2. Select and load the model ","0a4b310e":"# 4. select and download image  ","8253b70f":"# 3. download and resize images  "}}