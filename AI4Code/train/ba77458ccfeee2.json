{"cell_type":{"b53fab8f":"code","f2485104":"code","b542ed2f":"code","35ce067a":"code","7719d748":"code","f29678b2":"code","dc01697a":"code","3693171e":"code","aaf1f6fd":"code","e9617793":"code","718b013d":"code","aa48f591":"code","dad3214e":"code","2ed82330":"code","8ab296ed":"code","d9cc5b6d":"code","dd5f8ff8":"code","3e160b42":"code","f9acbf44":"code","1c4211ea":"code","11c43ebe":"code","277d7ea3":"code","1e4b2d29":"code","39f1a802":"code","d6fff31b":"code","ccd2b2b1":"code","9cee82d2":"code","2e41b7cf":"code","116016af":"code","8152c2dc":"code","56bb12b4":"code","7b21c69f":"code","e4beb72a":"code","13390fca":"code","df7fe207":"code","be441d04":"code","03755075":"code","7d362026":"code","44082a19":"code","32bcfaa9":"code","1a7bdc4a":"code","8a4a4087":"code","2a2681d6":"code","236e5fb1":"code","76c266fe":"code","9c8b3025":"code","e340d00f":"code","f4a18a8b":"code","856db578":"code","fa1d2f62":"code","40bebdb5":"code","d66aa43e":"code","58c35b7a":"code","5bde11d0":"code","3fa3bdc8":"code","9def3cad":"code","9336887c":"code","b2e795b3":"code","63a4a20b":"code","35232a76":"code","1cffc1ac":"code","8ed3568e":"code","96ad2fd9":"code","62f1bde8":"code","9dad0d96":"code","47e1631a":"code","2e9e65a1":"code","dcf4c605":"code","61a7abe6":"code","ad5e4889":"code","039ace00":"code","be555018":"code","cb4e1a5d":"code","42b5bcb2":"code","c0d14633":"markdown","b8e04bd6":"markdown","2059753c":"markdown","44889acb":"markdown","099a24cd":"markdown","4c0c7c0c":"markdown","42846a83":"markdown","bc2a8d6c":"markdown","ec9d1c1b":"markdown","a2217c3a":"markdown","cbbed8be":"markdown","12855eac":"markdown","85286b98":"markdown","71e766aa":"markdown","3d307c1e":"markdown","e0389823":"markdown","d7e815cc":"markdown","d7e0fadd":"markdown","772e94d1":"markdown","2df878e9":"markdown","2128380d":"markdown","6fa078c6":"markdown"},"source":{"b53fab8f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfrom mpl_toolkits.mplot3d import Axes3D\nimport statsmodels.api as sm\nimport missingno as msno\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom scipy.stats import levene\nfrom scipy.stats import shapiro\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.preprocessing import scale\nfrom sklearn.model_selection import ShuffleSplit, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import tree\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve","f2485104":"filterwarnings(\"ignore\", category=DeprecationWarning) \nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","b542ed2f":"DigitsTrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\") # train main","35ce067a":"DigitsTest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\") # test main","7719d748":"data = DigitsTrain.copy() # to protect train main data","f29678b2":"dataTest = DigitsTest.copy() # to protect test main data","dc01697a":"print(data.head())","3693171e":"print(data.shape)","aaf1f6fd":"print(data.columns)","e9617793":"print(data.columns.value_counts().sum())","718b013d":"print(data.info())","aa48f591":"print(data.describe().T)","dad3214e":"print(data.index)","2ed82330":"print(type(data)) # checking type","8ab296ed":"print(data.corr()) # checking correlation\n# it is not suitable for this data, but you should use and try for others","d9cc5b6d":"print(data.cov()) # checking covariance\n# it is not suitable for this data, but you should use and try for others","dd5f8ff8":"print(data.groupby([\"label\"])[\"pixel0\"].mean()) # example for groupby\n# it is not suitable for this data, but you should use and try for others","3e160b42":"print(data.groupby([\"label\"])[\"pixel783\"].mean()) # example for groupby\n# it is not suitable for this data, but you should use and try for others","f9acbf44":"maxPixel783 = data[data[\"pixel783\"] == data[\"pixel783\"].max()] # example for checking max\n# it is not suitable for this data, but you should use and try for others\nprint(maxPixel783.index.value_counts())","1c4211ea":"print(data.isnull().all().sum()) # checking all missing values for rows and columns","11c43ebe":"print(data.isnull().any().sum()) # checking any missing values for rows and columns","277d7ea3":"print(data.duplicated().sum()) # checking duplicated","1e4b2d29":"print(dataTest.head())","39f1a802":"print(dataTest.shape)","d6fff31b":"print(dataTest.columns)","ccd2b2b1":"print(dataTest.info())","9cee82d2":"print(dataTest.describe().T)","2e41b7cf":"print(dataTest.corr())","116016af":"print(dataTest.cov())","8152c2dc":"print(dataTest.columns.value_counts().sum())","56bb12b4":"print(dataTest.isnull().all().sum())","7b21c69f":"print(dataTest.isnull().any().sum())","e4beb72a":"print(dataTest.duplicated().sum())","13390fca":"x = data.drop(\"label\",axis=1) # features\ny = data[\"label\"] # prediction target","df7fe207":"xTrain,xTest,yTrain,yTest = train_test_split(x,y,test_size=0.2,random_state=42) # for testing our models","be441d04":"scaler = MinMaxScaler()","03755075":"xTrain = scaler.fit_transform(xTrain)\nxTest = scaler.fit_transform(xTest)\n# for faster process\n# you can also use StandartScaler","7d362026":"print(xTrain.shape)","44082a19":"print(xTest.shape)","32bcfaa9":"figure = plt.figure(figsize=(15,8))\nsns.countplot(data[\"label\"],color=\"black\")\n# we see how many numbers are in the data\nplt.show()","1a7bdc4a":"for i in range(0,5):\n    image = x.iloc[i]\n    image = np.array(image,dtype='uint8')\n    # we need to transform it to numpy array for visualizing\n    image = image.reshape((28,28))\n    # we need to reshape for visualizing because of pixels\n    plt.imshow(image,cmap=\"gray\")\n    plt.axis(\"off\")\n    plt.show()\n# visualizing numbers in data by using pixel values","8a4a4087":"# models training\nlj = LogisticRegression(solver=\"liblinear\").fit(xTrain,yTrain)\ngnb = GaussianNB().fit(xTrain,yTrain)\nknnc = KNeighborsClassifier().fit(xTrain,yTrain)\ncartc = DecisionTreeClassifier(random_state=42).fit(xTrain,yTrain)\nrfc = RandomForestClassifier(random_state=42,verbose=False).fit(xTrain,yTrain)","2a2681d6":"modelsc = [lj,gnb,knnc,cartc,rfc]\n# we will try 5 models for example\n# if you want you can try all of them","236e5fb1":"# models' accuracy scores\nfor model in modelsc:\n    name = model.__class__.__name__\n    predict = model.predict(xTest)\n    R2CV = cross_val_score(model,xTest,yTest,cv=10,verbose=False).mean()\n    error = -cross_val_score(model,xTest,yTest,cv=10,scoring=\"neg_mean_squared_error\",verbose=False).mean()\n    print(name + \": \")\n    print(\"-\" * 10)\n    print(\"ACC-->\",accuracy_score(yTest,predict))\n    print(\"R2CV-->\",R2CV)\n    print(\"MEAN SQUARED ERROR-->\",np.sqrt(error))\n    print(\"-\" * 30)","76c266fe":"testlabel = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","9c8b3025":"predictC = rfc.predict(testlabel)","e340d00f":"print(predictC[0])","f4a18a8b":"# checking same value\nimageT = testlabel.iloc[0]\nimageT = np.array(imageT,dtype='uint8')\n# we need to transform it to numpy array for visualizing\nimageT = imageT.reshape((28,28))\n# we need to reshape for visualizing because of pixels\nplt.imshow(imageT,cmap=\"gray\")\nplt.axis(\"off\")\nplt.show()","856db578":"print(predictC.shape)","fa1d2f62":"imageIDC = [h+1 for h in range(len(predictClass))]","40bebdb5":"print(imageIDC)","d66aa43e":"submissionClass = pd.DataFrame()\nsubmissionClass[\"ImageId\"] = imageIDC\nsubmissionClass[\"Label\"] = predictC","58c35b7a":"submissionC.to_csv('submissionClass.csv', index=False)","5bde11d0":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nimport tensorflow as tf","3fa3bdc8":"xN = data.drop(\"label\",axis=1)\nyN = data[\"label\"]","9def3cad":"xN = np.array(xN)\nxN = xN.reshape(42000, 28, 28)","9336887c":"print(xN.shape)","b2e795b3":"ANNmodel = tf.keras.models.Sequential([\n  # inputs\n  tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255),\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  # hiddens\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  # output\n  tf.keras.layers.Dense(10)\n])\n\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nANNmodel.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])","63a4a20b":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n\nMainModel = ANNmodel.fit(xN, yN, validation_split=0.2, epochs=30, callbacks=[callback])","35232a76":"print(ANNmodel.summary())","1cffc1ac":"loss = pd.DataFrame(ANNmodel.history.history)","8ed3568e":"print(loss.head())","96ad2fd9":"loss.plot()","62f1bde8":"plt.plot(MainModel.history[\"accuracy\"])\nplt.plot(MainModel.history[\"val_accuracy\"])\nplt.xlabel(\"EPOCH\")\nplt.ylabel(\"ACC\")\nplt.legend()\nplt.show()","9dad0d96":"dataTest = np.array(dataTest)","47e1631a":"print(dataTest.shape)","2e9e65a1":"dataTest = dataTest.reshape(28000,28,28)","dcf4c605":"predictANN = ANNmodel.predict(dataTest)","61a7abe6":"plt.imshow(dataTest[0])\nplt.show()","ad5e4889":"p = [np.argmax(i) for i in predictANN]","039ace00":"# checking same value\nprint(p[0])","be555018":"imageID = [x+1 for x in range(len(p))]","cb4e1a5d":"submission = pd.DataFrame()\nsubmission[\"ImageId\"] = imageID\nsubmission[\"Label\"] = p","42b5bcb2":"submission.to_csv('submissionANN.csv', index=False)","c0d14633":"#### SUBMISSION","b8e04bd6":"# VISUALIZATION","2059753c":"IT'S TRUE","44889acb":"#### TRAIN","099a24cd":"#### WARNINGS ","4c0c7c0c":"# MODELS","42846a83":"# EXPLORATORY DATA ANALYSIS","bc2a8d6c":"# DATA","ec9d1c1b":"# SPLITTING TRAIN AND TEST FOR TRAINING","a2217c3a":"# ANN MODEL","cbbed8be":"#### SUBMISSION","12855eac":"# PACKAGES AND LIBRARIES","85286b98":"#### LIBRARY ","71e766aa":"as we see, the best is Random Forest for each of 5 models","3d307c1e":"IT'S TRUE","e0389823":"#### TEST DATA","d7e815cc":"#### CREATING","d7e0fadd":"#### CLASSIFIER","772e94d1":" we use \"dataTest\" for ANN, that is why we need to define again","2df878e9":"#### PREDICTION","2128380d":"#### TRAIN DATA","6fa078c6":"#### PREDICTION"}}