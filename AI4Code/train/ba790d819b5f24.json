{"cell_type":{"6c951332":"code","3a2b3b4f":"code","c8534c8d":"code","44829eff":"code","73519603":"code","0b0dc599":"code","dd169b08":"code","4652d2e2":"code","9088b78b":"code","3661cb6d":"code","2985b838":"code","9ac4a8c6":"code","bf790481":"code","8bb5495e":"code","a74b3a9e":"code","e3d07532":"code","ea48de85":"code","398d1122":"code","b0e084b3":"code","1b529e7b":"code","65bc252b":"code","d573e025":"code","544a9372":"code","045c804e":"code","85d34b93":"code","9f1652e4":"code","187422c9":"code","e5761e85":"code","9af78fbf":"code","e9be4272":"code","5c90ef70":"code","1514f383":"code","88883f0d":"code","ac832bdc":"code","aff970ee":"code","4f7c4ee2":"code","d5ff267f":"code","d5c50085":"code","18792f39":"code","00147e63":"code","e978e682":"code","585a4968":"code","80d6a82c":"code","dd967ef8":"code","bc90ffc5":"code","428298ba":"code","9440ff86":"code","37d17d16":"code","059d0b94":"code","2ae5fe30":"code","d19697cc":"code","b785a1e7":"code","4061d317":"code","80ffc7e5":"code","2db7d617":"code","6d08677e":"code","46184920":"code","bb2e15a4":"code","b0c06443":"code","79dc1ecd":"markdown","c5cab473":"markdown","e32af858":"markdown","333b4f41":"markdown","815af424":"markdown","5b3465df":"markdown","95ba4c9b":"markdown","ad7ab83a":"markdown","5ed2da54":"markdown","f873dfd4":"markdown","4b5f577e":"markdown","c7268e99":"markdown","7cd6aa00":"markdown","69c239f5":"markdown","0efffcc6":"markdown","a43f0063":"markdown","f9774d91":"markdown","276328d4":"markdown","f8add2f5":"markdown","8dfd84e2":"markdown","a9717246":"markdown","d10d27bc":"markdown"},"source":{"6c951332":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3a2b3b4f":"! pip install dexplot","c8534c8d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px \nimport plotly.graph_objs as go\nfrom plotly.offline import iplot","44829eff":"df = pd.read_csv('\/kaggle\/input\/lung-cancer-dataset\/lung_cancer_examples.csv')\ndf.head()","73519603":"# Trying to get the info from the dataset\ndf.info()","0b0dc599":"# # Trying to see whether there is any null value or bot in the dataset\ndf.isnull().sum()","dd169b08":"# Lets describe the dataset\n\ndf.describe()","4652d2e2":"# the number of unique values in Smokes columns \nprint(df['Smokes'].nunique())\ndf['Smokes'].unique()","9088b78b":"# the number of unique values in AreaQ columns\nprint(df['AreaQ'].nunique())\ndf['AreaQ'].unique()","3661cb6d":"# the number of unique values in Alkhol columns\nprint(df['Alkhol'].nunique())\ndf['Alkhol'].unique()","2985b838":"# the number of unique values in Age columns\nprint(df['Age'].nunique())\ndf['Age'].unique()","9ac4a8c6":"# Since Name and Surname are in no way impacting the accuracy of the model so Dropping them\n\ndf.drop(['Name', 'Surname'], inplace = True, axis = 'columns')\ndf.head()","bf790481":"# Lets see the distribution of Data about the persons who are suffering from \n# Lung Cancer or Not\n\nlabels = df['Result'].value_counts()[:].index\nvalues = df['Result'].value_counts()[:].values\n\ncolors=['#2678bf', '#98adbf']\n\nfig = go.Figure(data=[go.Pie(labels = labels, values=values, textinfo=\"label+percent\",\n                            insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()\n","8bb5495e":"# Lets visualize the distribution of the person who are smokes in \n# terms of the number cigrates smokes\n\n# I will plot here the bar graph for the top 10 smokers\n\nlabels = df['Smokes'].value_counts()[:10].index\nvalues = df['Smokes'].value_counts()[:10].values\n\ncolors=df['Smokes']\n\nfig = go.Figure(data=[go.Pie(labels = labels, values=values, textinfo=\"label+percent\",\n                            insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","a74b3a9e":"# Lets visualize the AreaQ \nlabels = df['AreaQ'].value_counts().index\nvalues = df['AreaQ'].value_counts().values\n\ncolors=df['AreaQ']\n\nfig = go.Figure(data=[go.Pie(labels = labels, values=values, textinfo=\"label+percent\",\n                            insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","e3d07532":"# Lets visualize the Alkhol\n\nlabels = df['Alkhol'].value_counts().index\nvalues = df['Alkhol'].value_counts().values\n\ncolors=df['Alkhol']\n\nfig = go.Figure(data=[go.Pie(labels = labels, values=values, textinfo=\"label+percent\",\n                            insidetextorientation=\"radial\", marker=dict(colors=colors))])\n\nfig.show()","ea48de85":"# Lets visualize the number of cigarattes one Smoke and whether he suffers from \n# Lung Cancer or not\n\nimport dexplot as dxp\n\ndxp.count(val='Smokes', data=df, figsize=(4,3), split = 'Result', normalize=True)","398d1122":"# Splitting the data\n\nfrom sklearn.model_selection import train_test_split\n\nX = df.drop(['Result'], axis = 'columns')\ny = df['Result']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)","b0e084b3":"# Printing the shape of the splitted data\n\nprint('The shape of X_train is {}'.format(X_train.shape))\nprint('The shape of X_test is {}'.format(X_test.shape))\nprint('The shape of y_train is {}'.format(y_train.shape))\nprint('The shape of y_test is {}'.format(y_test.shape))","1b529e7b":"def true_positive(y_true, y_pred):\n    \"\"\"\n    Function to calculate the True Positive\n    : param y_true: list of true values\n    : param y_pred: list of predicted values\n    : return: number of true positives\n    \"\"\"\n    \n    # initialize\n    tp = 0\n    for yt, yp in zip(y_true, y_pred):\n        if yt == 1 and yp == 1:\n            tp += 1\n    return tp\n\ndef true_negative(y_true, y_pred):\n    \"\"\"\n    Function to calculate the True Positive\n    : param y_true: list of true values\n    : param y_pred: list of predicted values\n    : return: number of true negatives\n    \"\"\"\n    \n    # initialize\n    tn = 0\n    for yt, yp in zip(y_true, y_pred):\n        if yt == 0 and yp == 0:\n            tn += 1\n    return tn\n\ndef false_positive(y_true, y_pred):\n    \"\"\"\n    Function to calculate the True Positive\n    : param y_true: list of true values\n    : param y_pred: list of predicted values\n    : return: number of false positives\n    \"\"\"\n    \n    # initialize\n    fp = 0\n    for yt, yp in zip(y_true, y_pred):\n        if yt == 0 and yp == 1:\n            fp += 1\n    return fp\n\ndef false_negative(y_true, y_pred):\n    \"\"\"\n    Function to calculate the True Positive\n    : param y_true: list of true values\n    : param y_pred: list of predicted values\n    : return: number of true positives\n    \"\"\"\n    \n    # initialize\n    fn = 0\n    for yt, yp in zip(y_true, y_pred):\n        if yt == 1 and yp == 0:\n            fn += 1\n    return fn","65bc252b":"from sklearn.linear_model import LogisticRegression\nmodel_log = LogisticRegression()\nmodel_log.fit(X_train, y_train)\npredict1 = model_log.predict(X_test)","d573e025":"# Defining the model\n\ndef accuracy_score(y_true, y_pred):\n    \"\"\"\n    Function to calculate the True Positive\n    : param y_true: list of true values\n    : param y_pred: list of predicted values\n    : return: accuracy score\n    \"\"\"\n    \n    tp = true_positive(y_true, y_pred)\n    fp = false_positive(y_true, y_pred)\n    fn = false_negative(y_true, y_pred)\n    tn = true_negative(y_true, y_pred)\n    \n    accuracy_score = (tp+tn)\/(tp+tn+fp+fn)\n    return accuracy_score","544a9372":"# Calculating the accuracy score of the above model\n\naccuracy_score(y_test, predict1)","045c804e":"# Definig the model\n\ndef precision(y_true, y_pred):\n    \"\"\"\n    Function to calculate the True Positive\n    : param y_true: list of true values\n    : param y_pred: list of predicted values\n    : return: precision score\n    \"\"\"\n    \n    tp = true_positive(y_true, y_pred)\n    fp = false_positive(y_true, y_pred)\n    precision = tp\/(tp+fp)\n    return precision","85d34b93":"# Calculating the precision score of the above model\n\n\nprecision(y_test, predict1)","9f1652e4":"# Defining the model\n\ndef recall(y_true, y_pred):\n    \"\"\"\n    Function to calculate the True Positive\n    : param y_true: list of true values\n    : param y_pred: list of predicted values\n    : return: recall score\n    \"\"\"\n    \n    tp = true_positive(y_true, y_pred)\n    fn = false_negative(y_true, y_pred)\n    recall = tp\/(tp+fn)\n    return recall","187422c9":"# Calculating the recall score of the above model\n\n\nrecall(y_test, predict1)","e5761e85":"# Defining the model\n\ndef f1(y_true, y_pred):\n    \"\"\"\n    Function to calculate the True Positive\n    : param y_true: list of true values\n    : param y_pred: list of predicted values\n    : return: f1 score\n    \"\"\"\n    \n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    \n    score = 2*p*r\/(p+r)\n    \n    return score","9af78fbf":"# Calculating the f1 score \n\nf1(y_test, predict1)","e9be4272":"# Calculating the roc_auc_score\n\nfrom sklearn import metrics\nmetrics.roc_auc_score(y_test, predict1)","5c90ef70":"# Plotting the Confusion Matrix\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, predict1)\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cm, annot = True, ax = ax)\nplt.title('Confusion Matrix for the Logistic Regression')\nplt.ylabel('True Value')\nplt.xlabel('Predicted Value')\nplt.show()","1514f383":"from sklearn.tree import DecisionTreeClassifier\n\nmodel_dtc = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, \n                                   min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n                                   max_features=None, random_state=None, max_leaf_nodes=None, \n                                   min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, \n                                   presort='deprecated', ccp_alpha=0.0)\nmodel_dtc.fit(X_train, y_train)\npredict2 = model_dtc.predict(X_test)","88883f0d":"# Calculating the accuracy score of the above model\n\naccuracy_score(y_test, predict2)","ac832bdc":"# Calculating the precision score of the above model\n\n\nprecision(y_test, predict2)","aff970ee":"# Calculating the2recall score of the above model\n\n\nrecall(y_test, predict2)","4f7c4ee2":"# Calculating the f1 score \n\nf1(y_test, predict2)","d5ff267f":"# Calculating the roc_auc_score\n\nfrom sklearn import metrics\nmetrics.roc_auc_score(y_test, predict2)","d5c50085":"# Plotting the Confusion Matrix\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, predict2)\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cm, annot = True, ax = ax)\nplt.title('Confusion Matrix for the Decision Tree Classification')\nplt.ylabel('True Value')\nplt.xlabel('Predicted Value')\nplt.show()","18792f39":"from sklearn.ensemble import RandomForestClassifier\n\n# Create a Gaussian Classifier\nmodel_rfc = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, \n                                   min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n                                   max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n                                   bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n                                   verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\nmodel_rfc.fit(X_train, y_train)\npredict3 = model_rfc.predict(X_test)","00147e63":"# Calculating the accuracy score of the above model\n\naccuracy_score(y_test, predict3)","e978e682":"# Calculating the precision score of the above model\n\n\nprecision(y_test, predict3)","585a4968":"# Calculating the recall score of the above model\n\n\nrecall(y_test, predict3)","80d6a82c":"# Calculating the f1 score \n\nf1(y_test, predict3)","dd967ef8":"# Calculating the roc_auc_score\n\nfrom sklearn import metrics\nmetrics.roc_auc_score(y_test, predict3)","bc90ffc5":"# Plotting the Confusion Matrix\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, predict3)\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cm, annot = True, ax = ax)\nplt.title('Confusion Matrix for the Decision Tree Classification')\nplt.ylabel('True Value')\nplt.xlabel('Predicted Value')\nplt.show()","428298ba":"#Import svm model\nfrom sklearn import svm\n\n#Create a svm Classifier\nmodel_svm = svm.SVC(kernel='linear') # Linear Kernel\n\nmodel_svm.fit(X_train, y_train)\npredict4 = model_svm.predict(X_test)","9440ff86":"# Calculating the accuracy score of the above model\n\naccuracy_score(y_test, predict4)","37d17d16":"# Calculating the precision score of the above model\n\n\nprecision(y_test, predict4)","059d0b94":"# Calculating the recall score of the above model\n\n\nrecall(y_test, predict4)","2ae5fe30":"# Calculating the f1 score \n\nf1(y_test, predict4)","d19697cc":"# Calculating the roc_auc_score\n\nfrom sklearn import metrics\nmetrics.roc_auc_score(y_test, predict4)","b785a1e7":"# Plotting the Confusion Matrix\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, predict4)\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cm, annot = True, ax = ax)\nplt.title('Confusion Matrix for the Decision Tree Classification')\nplt.ylabel('True Value')\nplt.xlabel('Predicted Value')\nplt.show()","4061d317":"#Import Gaussian Naive Bayes model\nfrom sklearn.naive_bayes import GaussianNB\n\n#Create a Gaussian Classifier\nmodel_NB = GaussianNB()\n\n# Train the model using the training sets\nmodel_NB.fit(X_train, y_train)\npredict5 = model_NB.predict(X_test)","80ffc7e5":"# Calculating the accuracy score of the above model\n\naccuracy_score(y_test, predict5)","2db7d617":"# Calculating the prec5sion score of the above model\n\n\nprecision(y_test, predict5)","6d08677e":"# Calcul5ting the recall score of the above model\n\n\nrecall(y_test, predict5)","46184920":"# Calculating the f1 score \n\nf1(y_test, predict5)","bb2e15a4":"# Calculating the roc_auc_score\n\nfrom sklearn import metrics\nmetrics.roc_auc_score(y_test, predict5)","b0c06443":"# Plotting the Confusion Matrix\n\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, predict5)\nf, ax = plt.subplots(figsize=(10,10))\nsns.heatmap(cm, annot = True, ax = ax)\nplt.title('Confusion Matrix for the Decision Tree Classification')\nplt.ylabel('True Value')\nplt.xlabel('Predicted Value')\nplt.show()","79dc1ecd":"### F1 Score","c5cab473":"### Lets see the number of unique values in each of the relevant columns","e32af858":"### Model 5. Naive Bayes","333b4f41":"### Precision","815af424":"# Building and Trainig the Model","5b3465df":"### Recall","95ba4c9b":"Its Cool that there is no null value in the dataset ","ad7ab83a":"### Model 3. Random Forest Classification\n","5ed2da54":"### Model 1. Logistic Regression\n","f873dfd4":"Precision = tp\/(tp+fp)","4b5f577e":"### Model 4. SVM","c7268e99":"## Let's Visualize the  Data","7cd6aa00":"### Definig the model to calculate the True  Positive, True Negative, False Positive and False Negative","69c239f5":"Recall = tp\/(tp+fn)","0efffcc6":"### Model 2. Decision Tree Classification","a43f0063":"### If you found this notebook please upvote it\n\n### Feel free to comment for any suggestions and queries","f9774d91":"Both precision and recall range from 0 to 1 and a value closer to 1 is better\n\nF1 = 2PR\/(P+R)","276328d4":"Since we know the accuracy score of the model is given by using the formula\n\nAccuracy Score = (TP+TN)\/(TP+TN+FP+FN)\n","f8add2f5":"From the above model we can see that the model seems to be 100% accurate since the data is small we can cross-check even but for the larger dataset 100% accuracy is clear indication of model being biased","8dfd84e2":"### Accuracy Score","a9717246":"The above model has 100% precision score, since the data is small we can cross-check even but for the larger dataset 100% accuracy is clear indication of model being biased","d10d27bc":"From the above output we can see that there are some serious smoker who can smokes upto 34 cigarettes in a day and some don't even smoke"}}