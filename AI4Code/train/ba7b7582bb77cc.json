{"cell_type":{"650842b8":"code","335b3291":"code","0daae65c":"code","54cc1a67":"code","f8bb1b82":"code","7c8afc0c":"code","bc46b55f":"code","83037ef1":"code","65275b47":"code","bc821f3d":"code","fbd0795c":"code","8ba5dd9a":"code","c07a0b50":"code","984e1895":"code","e8c64132":"code","dcfd3c27":"code","d64a43db":"code","61047ba8":"code","8b3d8515":"code","3ae9dbdb":"code","0b3db444":"code","aeac94a4":"code","021acf4e":"code","7abc1e17":"code","09862a9e":"code","c96420b9":"code","dea79734":"code","f43e94ba":"code","fd0ecd82":"code","d5c9464f":"code","0d0b1fb5":"code","166e13b6":"code","1f9d72a8":"code","ddb364fa":"code","efd703ec":"code","4351550d":"code","cfa2006c":"code","c04a9bcb":"code","4c0edbdf":"code","5124fe89":"code","01f55647":"code","01af1e37":"code","aa1e5b5f":"code","1194121b":"code","ddd10a8b":"code","e949535e":"code","16841867":"code","a5f4cd93":"code","f96bad5e":"code","fed10ad4":"code","e721639f":"code","e5d228ea":"code","96684534":"code","6c82ac73":"code","1bb81f16":"code","7f537ede":"code","c0d91405":"markdown","b7197e47":"markdown","70da9f6a":"markdown","bd1c9b2e":"markdown","4d0dac54":"markdown","798a41d8":"markdown","63a29ef4":"markdown","cc117b34":"markdown","c0cc3391":"markdown","bac3ae0a":"markdown","3ca32509":"markdown","8c968e09":"markdown","1882d43c":"markdown","b0f6d565":"markdown","27c6f50c":"markdown","edb22b4d":"markdown","5bbc48d4":"markdown","78b86231":"markdown","73d63354":"markdown","0d861e4e":"markdown","f85b406c":"markdown","c30067cd":"markdown","b51f02b9":"markdown","ffdc5f7f":"markdown","38594807":"markdown","0725eea4":"markdown","3ece18ad":"markdown","151f38ab":"markdown","bdbc534b":"markdown","24e1a0c7":"markdown","090d4bd3":"markdown","df026c55":"markdown","d35b3ced":"markdown","827c04c6":"markdown","64dbb190":"markdown"},"source":{"650842b8":"import pandas as pd\nimport json\nfrom pandas import DataFrame\n!pip install pyvi\nfrom pyvi import ViTokenizer, ViPosTagger\nfrom pyvi import ViUtils\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport pandas as pd \nimport io \nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import f1_score, log_loss\nfrom tabulate import tabulate\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cluster import KMeans\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom nltk.corpus import stopwords\n\nimport os\nimport csv\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","335b3291":"!apt-get install p7zip\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/train.tsv.7z\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/test.tsv.7z\n!p7zip -d -f -k \/kaggle\/input\/mercari-price-suggestion-challenge\/sample_submission.csv.7z","0daae65c":"!unzip \/kaggle\/input\/mercari-price-suggestion-challenge\/sample_submission_stg2.csv.zip\n!unzip \/kaggle\/input\/mercari-price-suggestion-challenge\/test_stg2.tsv.zip","54cc1a67":"train_data = pd.read_csv('train.tsv', sep='\\t')\ntest_data = pd.read_csv('test_stg2.tsv', sep='\\t')\nprint(train_data.shape)\nprint(test_data.shape)\nprint(train_data.columns)\nprint(test_data.columns)","f8bb1b82":"train_data.head()","7c8afc0c":"test_data.head()","bc46b55f":"print('Number of duplicates in train: {}'.format(sum(train_data.duplicated())))\nprint('Number of duplicates in test : {}'.format(sum(test_data.duplicated())))","83037ef1":"train_data.isnull().any()","65275b47":"print('{} NaN\/Null values in train'.format(train_data.isnull().values.sum()))\nprint('{} NaN\/Null values in test'.format(test_data.isnull().values.sum()))","bc821f3d":"# train_data[\"category_name\"] = train_data[\"category_name\"].fillna(\"Other\").astype(\"category\")\ntrain_data[\"brand_name\"] = train_data[\"brand_name\"].fillna(\"unknown\")\ntrain_data[\"item_description\"] = train_data[\"item_description\"].fillna(\"None\")\ntrain_data[\"brand_name\"] = train_data[\"brand_name\"].astype(\"category\")\n\n# test_data[\"category_name\"] = test_data[\"category_name\"].fillna(\"Other\").astype(\"category\")\ntest_data[\"brand_name\"] = test_data[\"brand_name\"].fillna(\"unknown\")\ntest_data[\"item_description\"] = test_data[\"item_description\"].fillna(\"None\")\ntest_data[\"brand_name\"] = test_data[\"brand_name\"].astype(\"category\")","fbd0795c":"train_copy = train_data.copy()\ntest_copy = test_data.copy()","8ba5dd9a":"def split_cat(text):\n    try: return text.split(\"\/\")\n    except: return (\"No Label\", \"No Label\", \"No Label\")\n    \ndef create_split_categories(data):\n    data['main_category'],data['subcat_1'],data['subcat_2']=zip(*data['category_name'].apply(lambda x: split_cat(x)))\n\ndef toNumeric(frame, data,to):\n    le = preprocessing.LabelEncoder()\n    frame[to] = le.fit_transform(frame[data].astype(str))\n    \ndef split_cat_encoder(frame):\n    toNumeric(frame, 'main_category', 'main_category' )\n    toNumeric(frame, 'subcat_1', 'subcat_1' )\n    toNumeric(frame, 'subcat_2', 'subcat_2' )\n    \ndef data_frame_encoder(frame):\n    toNumeric(frame, 'category_name', 'category_name' )\n    toNumeric(frame, 'item_description', 'item_description' )\n    toNumeric(frame, 'name', 'name' )\n    toNumeric(frame, 'brand_name', 'brand_name' )\n    \ndef divide_cats(data):\n    if(0<= data <=1):\n        return \"CAT1\"\n    if(1 < data <= 2):\n        return \"CAT2\"\n    if(2 < data <= 3):\n        return \"CAT3\"\n    if(3 < data <= 4):\n        return \"CAT4\"\n    if(4 < data <= 5):\n        return \"CAT5\"\n    if(5< data <=6):\n        return \"CAT6\"\n    if(6 < data <= 7):\n        return \"CAT7\"\n    return \"CATOTHER\"\n\ndef remove_stop_words(x):\n    x = ' '.join([i for i in x.lower().split(' ') if i not in stopwords.words('english')])\n    return x","c07a0b50":"create_split_categories(train_copy)\ntrain_copy['log_price'] = train_copy['price'].map(lambda x: np.log(x) if x>0 else x)\ntrain_copy['price_cats'] = train_copy['log_price'].map(lambda x : divide_cats(x))\n\n\ntest_copy = test_data.copy()\ncreate_split_categories(test_copy)","984e1895":"train_copy.head(10)","e8c64132":"split_cat_encoder(train_copy)\ndata_frame_encoder(train_copy)\n\nsplit_cat_encoder(test_copy)\ndata_frame_encoder(test_copy)","dcfd3c27":"train_copy.head(5)","d64a43db":"test_copy.head(5)","61047ba8":"train_copy.price.describe() # std do lech chuan","8b3d8515":"print(\" Range of price : \",'$',train_copy[\"price\"].min(), ' - ','$',train_copy[\"price\"].max())\nfig, ax = plt.subplots(2, 1, figsize = (15, 10))\nax[0].hist(train_copy.price, bins = 200, range = [min(train_copy.price), max(train_copy.price)], label = \"price\",color = \"skyblue\")\nax[0].set_title(\"\\n \\n  Histogram \", fontsize = 15)\nax[0].set_xlabel(\"Sale Price\", fontsize = 10)\nax[0].set_ylabel(\" Frequency \", fontsize = 10)\nsns.boxplot(train_copy.price, showfliers = False, ax = ax[1],color = \"skyblue\")\nax[1].set_title(\"Box Plot\", fontsize = 15)\nplt.show()","3ae9dbdb":"print(\" Range of price : \",'$',train_copy[\"log_price\"].min(), ' - ','$',train_copy[\"log_price\"].max())\nfig, ax = plt.subplots(2, 1, figsize = (15, 10))\nax[0].hist(train_copy.log_price, bins = 200, range = [min(train_copy.log_price), max(train_copy.log_price)], label = \"log_price\",color = \"skyblue\")\nax[0].set_title(\"\\n \\n  Histogram \", fontsize = 15)\nax[0].set_xlabel(\"Log Price\", fontsize = 10)\nax[0].set_ylabel(\" Frequency \", fontsize = 10)\nsns.boxplot(train_copy.log_price, showfliers = False, ax = ax[1],color = \"skyblue\")\nax[1].set_title(\"Box Plot\", fontsize = 15)\nplt.show()","0b3db444":"# barplot bi\u1ec3u di\u1ec5n m\u1eadt \u0111\u1ed9 xu\u1ea5t hi\u1ec7n c\u1ee7a c\u00e1c brand name\n# scarterplot bi\u1ec3u d\u1ec5n gi\u00e1 c\u1ee7a t\u1eebng t\u1eebng s\u1ea3n ph\u1ea3m thu\u1ed9c t\u1eebng brand name d\u01b0\u1edbi d\u1ea1ng numberic (index)\nbrands = train_data[\"brand_name\"].value_counts()\nprint(\"Unique Brand Names :\", brands.size)\nbrands_key = []\nfor i in range(0,5):\n    brands_key.append(brands[1:6].keys()[i])\nfig, ax = plt.subplots(2, 1, figsize = (15, 10))\nsns.barplot(brands[1:6].values, brands_key , ax = ax[0]) #brand[0] c\u00f3 nh\u00e3n \"-1\"\nf1 = train_copy['log_price'].values\nf2 = train_copy['brand_name'].values\n\nf3 = train_copy['price'].values\nf4 = train_copy['brand_name'].values\n\nax[1].set_title(\"\\n \\n  Scatter Plot \", fontsize = 15)\nax[1].scatter(f1, f2, c='black', s = 7)# s l\u00e0 size c\u1ee7a scatter\nax[0].set_xlabel(\" Appear Times\", fontsize = 10)\nax[0].set_ylabel(\" Brand Name\", fontsize = 10)\nax[1].set_xlabel(\" Log Price\", fontsize = 10)\nax[1].set_ylabel(\" Brand Name\", fontsize = 10)\n\nplt.show()","aeac94a4":"fig, ax = plt.subplots(3, 1, figsize = (15,10))\nsns.countplot(train_copy.item_condition_id, ax = ax[0])\nrectangles = ax[0].patches\nax[0].set_title(\"Count Plot \", fontsize = 15)\nlabels = train_copy.item_condition_id.value_counts().values\nfor rect, label in zip(rectangles, labels):#\u0111\u01b0a s\u1ed1 l\u1ea7n xu\u1ea5t hi\u1ec7n l\u00ean \u0111\u1ea7u c\u00e1c c\u1ed9t\n    height = rect.get_height()\n    ax[0].text(rect.get_x() + rect.get_width()\/2, height + 5, label, ha = \"center\", va = \"bottom\")\n    \nsns.boxplot(x = train_copy.item_condition_id, y = train_copy.price,showfliers = False, orient = \"v\", ax = ax[1])\nax[2].scatter(x = train_copy.item_condition_id, y = train_copy.price,alpha=0.9)\nax[2].set_xlabel(\" Item Condition id\", fontsize = 10)\nax[2].set_ylabel(\" Sale Price\", fontsize = 10)\nplt.show()","021acf4e":"fig, ax = plt.subplots(3, 1, figsize = (15,10))\nsns.countplot(train_copy.shipping, ax = ax[0])\nrectangles = ax[0].patches\nlabels = train_copy.shipping.value_counts().values\nfor rect, label in zip(rectangles, labels):\n    height = rect.get_height()\n    ax[0].text(rect.get_x() + rect.get_width()\/2, height + 5, label, ha = \"center\", va = \"bottom\")\nsns.boxplot(x = train_copy.shipping, y = train_copy.price,showfliers = False, orient = \"v\", ax = ax[1])\nax[2].scatter(x = train_copy.price, y = train_copy.shipping,alpha=0.9)\nax[2].set_xlabel(\" Shipping \", fontsize = 10)\nax[2].set_ylabel(\" Sale Price\", fontsize = 10)\nplt.show()","7abc1e17":"corltn=train_copy.corr() #t\u00ednh \u0111\u1ed9 t\u01b0\u01a1ng quan gi\u1eefa c\u00e1c c\u1ed9t, b\u1ecf qua gi\u00e1 tr\u1ecb null\ncorltn=corltn.fillna(0)\nplt.figure(figsize=(12, 10))\nplt.imshow(corltn, cmap='YlGnBu', interpolation='none', aspect='auto')\nplt.colorbar()\nplt.xticks(range(len(corltn)), corltn.columns, rotation='vertical')\nplt.yticks(range(len(corltn)), corltn.columns);\nplt.suptitle(' Correlations Heat Map for attributes', fontsize=16, fontweight='bold')","09862a9e":"X_train, x_test, Y_train, y_test = train_test_split(\ntrain_copy['main_category'], train_copy['log_price'], test_size=0.2, random_state=42) #t\u00e1ch th\u00e0nh 2 t\u1eadp test v\u00e0 train \nregr_0 = linear_model.LinearRegression()\nX_train = X_train[:, np.newaxis] # reshape 2D array into 1D array\nY_train = Y_train[:, np.newaxis]  # reshape 2D array into 1D array\nx_test = x_test[:, np.newaxis]  # reshape 2D array into 1D array\ny_test = y_test[:, np.newaxis]  # reshape 2D array into 1D array\nregr_0.fit(X_train, Y_train)\n\ny_train_predict = regr_0.predict(X_train)\ny_val_predict = regr_0.predict(x_test)\n\ntable = [['Score', 'Training', 'Valdation'], \n         ['MSE', '{} '.format(round((mean_squared_error(Y_train, y_train_predict)), 5)), '{} '.format(round((mean_squared_error(y_test, y_val_predict)), 5))], \n         ['RMSE', '{} '.format(round((np.sqrt(mean_squared_error(Y_train, y_train_predict))), 2)), '{} '.format(np.sqrt(round((mean_squared_error(y_test, y_val_predict)), 5)))], \n         ['R2_Score', '{} '.format(round((r2_score(Y_train, y_train_predict)), 5)), '{} '.format(round((r2_score(y_test, y_val_predict)), 5))]]\n\nprint(tabulate(table, headers='firstrow', tablefmt='grid'))","c96420b9":"train_split_data = train_copy[['main_category', 'subcat_1', 'subcat_2', 'item_condition_id']]\nX_train, x_test, Y_train, y_test = train_test_split(\ntrain_split_data, train_copy['log_price'], test_size=0.2, random_state=42) #t\u00e1ch th\u00e0nh 2 t\u1eadp test v\u00e0 train \nregr_1 = linear_model.LinearRegression()\nY_train = Y_train[:, np.newaxis]  # reshape 2D array into 1D array\ny_test = y_test[:, np.newaxis]  # reshape 2D array into 1D array\nregr_1.fit(X_train, Y_train)\ny_predict = regr_1.predict(x_test)\n\ny_train_predict = regr_1.predict(X_train)\ny_val_predict = regr_1.predict(x_test)\n\ntable = [['Score', 'Training', 'Valdation'], \n         ['MSE', '{} '.format(round((mean_squared_error(Y_train, y_train_predict)), 5)), '{} '.format(round((mean_squared_error(y_test, y_val_predict)), 5))], \n         ['RMSE', '{} '.format(round((np.sqrt(mean_squared_error(Y_train, y_train_predict))), 2)), '{} '.format(np.sqrt(round((mean_squared_error(y_test, y_val_predict)), 5)))], \n         ['R2_Score', '{} '.format(round((r2_score(Y_train, y_train_predict)), 5)), '{} '.format(round((r2_score(y_test, y_val_predict)), 5))]]\n\nprint(tabulate(table, headers='firstrow', tablefmt='grid'))","dea79734":"train_split_data = train_copy[['name','main_category', 'subcat_1', 'subcat_2', 'item_condition_id', 'brand_name', 'shipping']]\nX_train, x_test, Y_train, y_test = train_test_split(\ntrain_split_data, train_copy['log_price'], test_size=0.2, random_state=42) #t\u00e1ch th\u00e0nh 2 t\u1eadp test v\u00e0 train \nregr_2 = linear_model.LinearRegression()\nY_train = Y_train[:, np.newaxis]  # reshape 2D array into 1D array\ny_test = y_test[:, np.newaxis]  # reshape 2D array into 1D array\nregr_2.fit(X_train, Y_train)\n\ny_train_predict = regr_2.predict(X_train)\ny_val_predict = regr_2.predict(x_test)\n\ntable = [['Score', 'Training', 'Valdation'], \n         ['MSE', '{} '.format(round((mean_squared_error(Y_train, y_train_predict)), 5)), '{} '.format(round((mean_squared_error(y_test, y_val_predict)), 5))], \n         ['RMSE', '{} '.format(round((np.sqrt(mean_squared_error(Y_train, y_train_predict))), 2)), '{} '.format(np.sqrt(round((mean_squared_error(y_test, y_val_predict)), 5)))], \n         ['R2_Score', '{} '.format(round((r2_score(Y_train, y_train_predict)), 5)), '{} '.format(round((r2_score(y_test, y_val_predict)), 5))]]\n\nprint(tabulate(table, headers='firstrow', tablefmt='grid'))","f43e94ba":"train_split_data = train_copy.drop(['price', 'log_price', 'price_cats'], axis = 1)\nX_train, x_test, Y_train, y_test = train_test_split(\ntrain_split_data, train_copy['log_price'], test_size=0.2, random_state=42) #t\u00e1ch th\u00e0nh 2 t\u1eadp test v\u00e0 train \nregr_3 = linear_model.LinearRegression()\nY_train = Y_train[:, np.newaxis]  # reshape 2D array into 1D array\ny_test = y_test[:, np.newaxis]  # reshape 2D array into 1D array\nregr_3.fit(X_train, Y_train)\n\ny_train_predict = regr_3.predict(X_train)\ny_val_predict = regr_3.predict(x_test)\n\ntable = [['Score', 'Training', 'Valdation'], \n         ['MSE', '{} '.format(round((mean_squared_error(Y_train, y_train_predict)), 5)), '{} '.format(round((mean_squared_error(y_test, y_val_predict)), 5))], \n         ['RMSE', '{} '.format(round((np.sqrt(mean_squared_error(Y_train, y_train_predict))), 2)), '{} '.format(np.sqrt(round((mean_squared_error(y_test, y_val_predict)), 5)))], \n         ['R2_Score', '{} '.format(round((r2_score(Y_train, y_train_predict)), 5)), '{} '.format(round((r2_score(y_test, y_val_predict)), 5))]]\n\nprint(tabulate(table, headers='firstrow', tablefmt='grid'))","fd0ecd82":"train_csr_matrix = train_data.copy()\ncreate_split_categories(train_csr_matrix)\n\ntest_csr_matrix = test_data.copy()\ncreate_split_categories(test_csr_matrix)","d5c9464f":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom scipy.sparse import csr_matrix\n\nvectorizer = CountVectorizer()\ntrain_name = vectorizer.fit_transform(train_csr_matrix['name'])\ntest_name = vectorizer.transform(test_csr_matrix['name'])\n\nlb_condition = LabelBinarizer(sparse_output=True)\ntrain_condition = lb_condition.fit_transform(train_csr_matrix['item_condition_id'])\ntest_condition = lb_condition.transform(test_csr_matrix['item_condition_id'])\n\nvectorizer_brand = CountVectorizer()\ntrain_brand = vectorizer_brand.fit_transform(train_csr_matrix['brand_name'])\ntest_brand = vectorizer_brand.transform(test_csr_matrix['brand_name'])\n\nlb_shipping = LabelBinarizer(sparse_output=True)\ntrain_shipping = lb_condition.fit_transform(train_csr_matrix['shipping'])\ntest_shipping = lb_condition.transform(test_csr_matrix['shipping'])\n\nvectorizer_main_category = CountVectorizer()\ntrain_main_category = vectorizer_main_category.fit_transform(train_csr_matrix['main_category'])\ntest_main_category = vectorizer_main_category.transform(test_csr_matrix['main_category'])\n\nvectorizer_subcat_1 = CountVectorizer()\ntrain_subcat_1 = vectorizer_subcat_1.fit_transform(train_csr_matrix['subcat_1'])\ntest_subcat_1 = vectorizer_subcat_1.transform(test_csr_matrix['subcat_1'])\n\nvectorizer_subcat_2 = CountVectorizer()\ntrain_subcat_2 = vectorizer_subcat_2.fit_transform(train_csr_matrix['subcat_2'])\ntest_subcat_2 = vectorizer_subcat_2.transform(test_csr_matrix['subcat_2'])\n","0d0b1fb5":"# train_csr_matrix['item_description'] = train_csr_matrix['item_description'].apply(remove_stop_words)\n# test_csr_matrix['item_description'] = test_csr_matrix['item_description'].apply(remove_stop_words)","166e13b6":"# tfidf_descp = TfidfVectorizer(ngram_range=(1,2),min_df=10,max_features=5000)\n# train_descp = tfidf_descp.fit_transform(train_csr_matrix['item_description'])\n# test_descp = tfidf_descp.transform(test_csr_matrix['item_description'])","1f9d72a8":"train_csr_matrix['log_price'] = train_csr_matrix['price'].map(lambda x: np.log(x) if x>0 else x)","ddb364fa":"train_matrix_list = (train_name, train_brand, train_condition,\n                      train_shipping, train_main_category, \n                      train_subcat_1, train_subcat_2)\n\ntest_matrix_list = (test_name, test_brand, test_condition,\n                      test_shipping, test_main_category, \n                      test_subcat_1, test_subcat_2)","efd703ec":"from scipy.sparse import hstack\ndata_train_matrix = hstack(train_matrix_list).tocsr()","4351550d":"#Training model\nX_train, x_test, Y_train, y_test = train_test_split(\ndata_train_matrix, train_csr_matrix['log_price'], test_size=0.2, random_state=42) #t\u00e1ch th\u00e0nh 2 t\u1eadp test v\u00e0 train \nregr_csr_matrix = linear_model.LinearRegression(normalize=True)\n\nregr_csr_matrix.fit(X_train, Y_train)\n\ny_train_predict = regr_csr_matrix.predict(X_train)\ny_val_predict = regr_csr_matrix.predict(x_test)","cfa2006c":"table = [['Score', 'Training', 'Valdation'], \n         ['MSE', '{} '.format(round((mean_squared_error(Y_train, y_train_predict)), 5)), '{} '.format(round((mean_squared_error(y_test, y_val_predict)), 5))], \n         ['RMSE', '{} '.format(round((np.sqrt(mean_squared_error(Y_train, y_train_predict))), 2)), '{} '.format(np.sqrt(round((mean_squared_error(y_test, y_val_predict)), 5)))], \n         ['R2_Score', '{} '.format(round((r2_score(Y_train, y_train_predict)), 5)), '{} '.format(round((r2_score(y_test, y_val_predict)), 5))]]\n\nprint(tabulate(table, headers='firstrow', tablefmt='grid'))","c04a9bcb":"X_train_rfr = train_copy.drop(['price', 'log_price' , 'price_cats'], axis = 1)\nY_train_rfr = train_copy['log_price']","4c0edbdf":"# #Train model\nX_train, x_test, Y_train, y_test = train_test_split(\nX_train_rfr, Y_train_rfr, test_size=0.2, random_state=42) #t\u00e1ch th\u00e0nh 2 t\u1eadp test v\u00e0 train \n\nrfr = RandomForestRegressor(n_jobs = -1, min_samples_leaf = 5, n_estimators = 200)\nrfr.fit(X_train, Y_train)","5124fe89":"y_train_predict = rfr.predict(X_train)\ny_val_predict = rfr.predict(x_test)\n\ntable = [['Score', 'Training', 'Valdation'], \n         ['MSE', '{} '.format(round((mean_squared_error(Y_train, y_train_predict)), 5)), '{} '.format(round((mean_squared_error(y_test, y_val_predict)), 5))], \n         ['RMSE', '{} '.format(round((np.sqrt(mean_squared_error(Y_train, y_train_predict))), 2)), '{} '.format(np.sqrt(round((mean_squared_error(y_test, y_val_predict)), 5)))], \n         ['R2_Score', '{} '.format(round((r2_score(Y_train, y_train_predict)), 5)), '{} '.format(round((r2_score(y_test, y_val_predict)), 5))]]\n\nprint(tabulate(table, headers='firstrow', tablefmt='grid'))","01f55647":"price_cats = train_copy.price_cats\ndef Kmeansmethod(frame1,frame1_name):\n    np.random.seed(5)\n    X = frame1\n    y = price_cats\n    estimators = [('k_means_iris_11', KMeans(n_clusters=11)),\n              ('k_means_iris_8', KMeans(n_clusters=8)),\n              ('k_means_iris_3', KMeans(n_clusters=3)),\n              ('k_means_iris_bad_init', KMeans(n_clusters=3, n_init=1,\n                                               init='random'))]\n    X  = X.values\n    y = y.values\n    colors = {'CAT1':'#1f77b4', 'CAT2':'#ff7f0e', 'CAT3':'#2ca02c', 'CAT4':'#d62728', 'CAT5':'#9467bd', 'CAT6' : '#8c564b', 'CAT7':'#e377c2', 'CATOTHER' : \"#1e12c4\", 'CAT50':'#17becf'}\n    cat_color = price_cats.apply(lambda x : colors[x])\n    cat_color = cat_color.to_list()\n    fignum = 1\n    titles = ['11 clusters' , '8 clusters', '3 clusters', '3 clusters, bad initialization']\n    for name, est in estimators:\n        fig = plt.figure(fignum, figsize=(4, 3))\n        ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n        est.fit(X)\n        labels = est.labels_\n\n        ax.scatter(X[:, 3], X[:, 0], X[:, 2],\n                   c=labels.astype(np.float), edgecolor='k')\n\n        ax.w_xaxis.set_ticklabels([])\n        ax.w_yaxis.set_ticklabels([])\n        ax.w_zaxis.set_ticklabels([])\n        ax.set_xlabel(frame1_name[3])\n        ax.set_ylabel(frame1_name[0])\n        ax.set_zlabel(frame1_name[2])\n        ax.set_title(titles[fignum - 1])\n        ax.dist = 12\n        fignum = fignum + 1\n\n\n    fig = plt.figure(fignum, figsize=(4, 3))\n    ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n\n    # Labels reorder\n\n    ax.scatter(X[:, 3], X[:, 0], X[:, 2], c=cat_color, edgecolor='k')\n\n    ax.w_xaxis.set_ticklabels([])\n    ax.w_yaxis.set_ticklabels([])\n    ax.w_zaxis.set_ticklabels([])\n    ax.set_xlabel(frame1_name[3])\n    ax.set_ylabel(frame1_name[0])\n    ax.set_zlabel(frame1_name[2])\n    ax.set_title('Sale Price Category')\n    ax.dist = 12\n\n    fig.show()","01af1e37":"frame1=train_copy[['main_category','subcat_1','subcat_2','brand_name']]\nframe1_name = ['main_category','subcat_1','subcat_2','brand_name']\nKmeansmethod(frame1,frame1_name)","aa1e5b5f":"train_encoder_price_category = train_copy.copy()\ntoNumeric(train_encoder_price_category, 'price_cats', 'price_cats')\ntrain_encoder_price_category.head(5)","1194121b":"price_cats = np.array(train_encoder_price_category.pop('price_cats'))#t\u00e1ch c\u1ed9t price_cats t\u1eeb frametrain\ntrain_encoder_price_category = train_encoder_price_category.drop(['train_id', 'price', 'category_name'] , axis=1)\ntrain_encoder_price_category.head(5)","ddd10a8b":"def Knnmethod(frametrain1,price_cats):\n    frametraink1 = frametrain1.to_numpy()\n    X_train, X_test, y_train, y_test = train_test_split(frametraink1, price_cats, test_size=0.20, random_state=42)\n    accuracy_array = []\n    k_array = []\n    for k in range(1,100,3):\n        knn = KNeighborsClassifier(n_neighbors=k, p = 2)\n        accuracy = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')#cv = 10 fold, m\u1eb7c \u0111\u1ecbnh l\u00e0 5\n        accuracy_array.append(accuracy.mean())#do chia l\u00e0m nhi\u1ec1u fold n\u00ean accurracy l\u00e0 m\u1ed9t arr c\u1ea7n ph\u1ea3i l\u1ea5y mean\n        k_array.append(k)\n        \n    class_error = 1.0 - np.array(accuracy_array)\n    plt.plot(k_array, class_error)\n    plt.xlabel('K')\n    plt.ylabel('Classification Error')\n    plt.show()\n    min_ind = np.argmin(class_error)\n    OptK = k_array[min_ind]\n\n    accuracy_array = []\n    k_array = []\n    for k in range(OptK-2, OptK+2,1):\n        knn = KNeighborsClassifier(n_neighbors=k)\n        accuracy = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')#cv = 10 fold, m\u1eb7c \u0111\u1ecbnh l\u00e0 5\n        accuracy_array.append(accuracy.mean())#do chia l\u00e0m nhi\u1ec1u fold n\u00ean accurracy l\u00e0 m\u1ed9t arr c\u1ea7n ph\u1ea3i l\u1ea5y mean\n        k_array.append(k)\n    class_error = 1.0 - np.array(accuracy_array)\n    plt.plot(k_array, class_error)\n    plt.xlabel('K')\n    plt.ylabel('Classification Error')\n    plt.show()\n    min_ind = np.argmin(class_error)\n    OptK = k_array[min_ind]\n\n    print (\"Optimal value of K is %d \" %  OptK)\n    knn = KNeighborsClassifier(n_neighbors=OptK)\n\n    # fitting the model\n    knn.fit(X_train, y_train)\n\n    # predict\n    pred = knn.predict(X_test)\n\n    # evaluate accuracy\n    print(\"accuracy_score\",accuracy_score(y_test, pred))","e949535e":"Knnmethod(train_encoder_price_category[0:5000],price_cats[0:5000])","16841867":"frametrain=train_encoder_price_category[['brand_name','main_category']]\nKnnmethod(frametrain[0:5000],price_cats[0:5000])","a5f4cd93":"frametrain=train_encoder_price_category[['main_category','subcat_1','brand_name']]\nKnnmethod(frametrain[0:5000],price_cats[0:5000])","f96bad5e":"frametrain=train_encoder_price_category[['main_category','subcat_1','subcat_2', 'item_condition_id']]\nKnnmethod(frametrain[0:5000],price_cats[0:5000])","fed10ad4":"frametrain=train_encoder_price_category[['main_category','subcat_1','subcat_2', 'item_condition_id', 'brand_name']]\nKnnmethod(frametrain[0:5000],price_cats[0:5000])","e721639f":"frametrain=train_encoder_price_category[['main_category','subcat_1','subcat_2', 'item_condition_id', 'brand_name','shipping']]\nKnnmethod(frametrain[0:5000],price_cats[0:5000])","e5d228ea":"train_encoder_price_category.head(5)","96684534":"X_train_logr = train_encoder_price_category.drop(['log_price'], axis = 1)\nY_train_logr = price_cats","6c82ac73":"#Training\nX_train, x_test, Y_train, y_test = train_test_split(\nX_train_logr, Y_train_logr, test_size=0.2, random_state=42) #t\u00e1ch th\u00e0nh 2 t\u1eadp test v\u00e0 train \n\nY_train = Y_train[:, np.newaxis]  # reshape 2D array into 1D array\ny_test = y_test[:, np.newaxis]  # reshape 2D array into 1D array\n\nlr = LogisticRegression(random_state=0).fit(X_train, Y_train)\n","1bb81f16":"y_train_predict = lr.predict(X_train)\ny_val_predict = lr.predict(x_test)\n\ntable = [['Score', 'Training', 'Valdation'], ['Accuracy', '{} %'.format(round((accuracy_score(Y_train, y_train_predict)*100), 2)), '{} %'.format(round((accuracy_score(y_test, y_val_predict)*100), 2))], ['F1_Score', '{} %'.format(round((f1_score(Y_train, y_train_predict, average='macro')*100))), '{} %'.format(round((f1_score(y_test, y_val_predict, average='macro')*100)))]]\nprint(tabulate(table, headers='firstrow', tablefmt='grid'))","7f537ede":"data_test_matrix = hstack(test_matrix_list).tocsr()\npreds = regr_csr_matrix.predict(data_test_matrix)\nnp.exp(preds)\nsubmission_data = pd.read_csv('sample_submission_stg2.csv')\nsubmission_data.loc[:, 'price'] = np.expm1(preds)\nsubmission_data.to_csv('submission.csv', index=False)","c0d91405":"# **Step 1: Load Data and Import Library**","b7197e47":"**Using main category, subcat_1, subcat_2, item_condition_id, brand_name , shipping, name**","70da9f6a":"**Log Price**","bd1c9b2e":"# **Model 4: K-NN**","4d0dac54":"# **Model 1. Linear Regreession**","798a41d8":"**Item Condition ID**","63a29ef4":"Hai model tr\u00ean \u0111\u00e3 cho ra \u0111\u01b0\u1ee3c k\u1ebft qu\u1ea3 MSE (RMSE) kh\u00e1 t\u1ed1t (\u0111\u1eb7c bi\u1ec7t l\u00e0 s\u1eed d\u1ee5ng vi\u1ec7c CountVectorizer, LabelBinarizer, TfidfVectorizer)chia log_price ra th\u00e0nh 8 kho\u1ea3ng gi\u00e1 ti\u1ec1n.","cc117b34":"**C\u00f3 th\u1ec3 th\u1ea5y Accuracy Score v\u00e0 F1_Score khi s\u1eed d\u1ee5ng model LogisticRegression v\u1edbi c\u00e1c class \u0111\u01b0\u1ee3c chia theo t\u1eebng kho\u1ea3ng gi\u00e1 ti\u1ec1n l\u00e0 r\u1ea5t th\u1ea5p => Vi\u1ec7c s\u1eed d\u1ee5ng model LogisticRegression theo class t\u1eebng kho\u1ea3ng gi\u00e1 ti\u1ec1n l\u00e0 kh\u00f4ng hi\u1ec7u qu\u1ea3.**","c0cc3391":"Gi\u00e1 c\u00e1c s\u1ea3n ph\u1ea9m r\u01a1i nhi\u1ec1u v\u00e0o kho\u1ea3ng 2 \u0111\u1ebfn 4.","bac3ae0a":"**CountVectorizer and LabelBinarizer**","3ca32509":"Gi\u00e1 c\u00e1c s\u1ea3n ph\u1ea9m r\u01a1i nhi\u1ec1u v\u00e0o kho\u1ea3ng 10 \u0111\u1ebfn 30, trong \u0111\u00f3 l\u1ec7ch v\u1ec1 10 nhi\u1ec1u h\u01a1n, c\u00f3 s\u1ef1 xu\u1ea5t hi\u1ec7n c\u1ee7a c\u00e1c s\u1ea3n ph\u1ea9m c\u00f3 gi\u00e1 0 (do ng\u01b0\u1eddi b\u00e1n mu\u1ed1n t\u1eb7ng ho\u1eb7c b\u00e1n mi\u1ec5n ph\u00ed).","8c968e09":"Kh\u00f4ng c\u00f3 s\u1ef1 t\u01b0\u01a1ng quan r\u00f5 r\u00e0ng gi\u1eefa c\u1ed9t gi\u00e1 v\u00e0 c\u00e1c c\u1ed9t kh\u00e1c \u0111\u1ec3 s\u1eed d\u1ee5ng \u0111\u1ec3 d\u1ef1 \nb\u00e1o.","1882d43c":"# **Step 5: Test & Output**","b0f6d565":"MSE, RMSE \u0111\u00e3 gi\u1ea3m nhi\u1ec1u; R2_Score c\u0169ng t\u0103ng so v\u1edbi vi\u1ec7c s\u1eed d\u1ee5ng LabelEncoder. Tuy v\u1eady, vi\u1ec7c s\u1eed d\u1ee5ng Compressed Sparse Row khi\u1ebfn cho model ch\u1ea1y l\u00e2u h\u01a1n.","27c6f50c":"Mean squared error regression loss l\u00e0 r\u1ea5t l\u1edbn do \u0111\u00f3 s\u1eed d\u1ee5ng main category, subcat_1, subcat_2, item_condition_id kh\u00f4ng hi\u1ec7u qu\u1ea3","edb22b4d":"**Shipping**","5bbc48d4":"**Brand Name**","78b86231":"M\u1eb7c d\u00f9 cho ra k\u1ebft qu\u1ea3 MSE kh\u00e1 l\u00e0 th\u1ea5p nh\u01b0ng t\u00f4i v\u1eabn mu\u1ed1n gi\u1ea3m MSE (RMSE) \u0111i n\u1eefa. Do \u0111\u00f3, t\u00f4i thay v\u00ec s\u1eed d\u1ee5ng LabelEncoder \u0111\u1ec3 Label Encoder cho t\u1eadp d\u1eef li\u1ec7u th\u00ec t\u00f4i s\u1eed d\u1ee5ng CountVectorizer cho d\u1eef li\u1ec7u ch\u1eef, LabelBinarizer cho d\u1eef li\u1ec7u s\u1ed1, TfidfVectorizer cho ri\u00eang c\u1ed9t item_description, sau \u0111\u00f3 s\u1eed d\u1ee5ng hstack \u0111\u1ec3 g\u1ed9p l\u1ea1i d\u1eef li\u1ec7u sau khi convert \u1edf tr\u00ean sang d\u1ea1ng d\u1eef li\u1ec7u Compressed Sparse Row matrix \u0111\u1ec3 t\u1ea1o ra t\u1eadp d\u1eef li\u1ec7u training.","73d63354":"# **Model 5: LogisticRegression**","0d861e4e":"**2.3. Encoder**","f85b406c":"# **Step 2: Data Preprocessing**","c30067cd":"# **Model 3: K-MEANS**","b51f02b9":"# **Model 2: Random Forest Regression**","ffdc5f7f":"Vi\u1ec7c l\u1ea5y log cho price gi\u00fap price s\u1ebd \u0111\u01b0\u1ee3c ph\u00e2n b\u1ed1 \u0111\u1ed3ng \u0111\u1ec1u h\u01a1n so v\u1edbi vi\u1ec7c \u0111\u1ec3 nguy\u00ean price. C\u00f3 th\u1ec3 th\u1ea5y r\u00f5 qua Range of price, trong khi Range of price c\u1ee7a price l\u00e0 t\u1eeb $ 0.0  -  $ 2009.0 th\u00ec Range of price c\u1ee7a log_price ch\u1ec9 l\u00e0 t\u1eeb $ 0.0  -  $ 7.60. Vi\u1ec7c ch\u00eanh l\u1ec7ch qu\u00e1 l\u1edbn c\u1ee7a price (n\u1ebfu kh\u00f4ng l\u1ea5y log) s\u1ebd khi\u1ebfn cho model g\u1eb7p kh\u00f3 kh\u0103n trong vi\u1ec7c training, khi\u1ebfn cho model kh\u00f4ng c\u00f2n ch\u00ednh x\u00e1c n\u1eefa. Do \u0111\u00f3, ch\u00fang t\u00f4i s\u1ebd ch\u1ecdn log_price thay th\u1ebf cho price trong qu\u00e1 tr\u00ecnh training c\u00e1c model.","38594807":"**2.2. Checking for NaN\/null values**","0725eea4":"**2.1. Check for Duplicates**","3ece18ad":"# **Step 4 : Data Modeling**","151f38ab":"Nh\u1eadn x\u00e9t: Ba h\u00ecnh (H\u00ecnh 1, 2, 3) s\u1eed d\u1ee5ng model k-mean ( cluster l\u1ea7n l\u01b0\u1ee3t b\u1eb1ng 11, 8, 3). Ta th\u1ea5y, d\u1eef li\u1ec7u \u0111\u01b0\u1ee3c chia th\u00e0nh c\u00e1c c\u1ee5m t\u01b0\u01a1ng \u1ee9ng v\u1edbi s\u1ed1 cluster. Trong khi \u0111\u00f3 d\u1eef li\u1ec7u th\u1ef1c t\u1ebf (H\u00ecnh 4), c\u00e1c \u0111i\u1ec3m d\u1eef li\u1ec7u c\u00f3 m\u00e0u s\u1eafc t\u01b0\u01a1ng \u1ee9ng v\u1edbi label l\u00e0 kho\u1ea3ng gi\u00e1 ti\u1ec1n n\u1eb1m ng\u1eabu nhi\u00ean kh\u00f4ng theo m\u1ed9t quy lu\u1eadt hay m\u1ed9t c\u1ee5m n\u00e0o c\u1ea3. Do \u0111\u00f3, kh\u00f4ng th\u1ec3 l\u1ea5y t\u00ednh t\u01b0\u01a1ng \u0111\u1ed3ng c\u1ee7a c\u00e1c \u0111i\u1ec3m d\u1eef li\u1ec7u \u1edf trong c\u00f9ng m\u1ed9t c\u1ee5m \u0111\u1ec3 g\u00e1n nh\u00e3n c\u1ee5m theo nh\u00e3n (label) l\u00e0 kho\u1ea3ng gi\u00e1 ti\u1ec1n.","bdbc534b":"# **Step 3 : Exploratory Data Analysis**","24e1a0c7":"**Sale Price**","090d4bd3":"Nh\u1eadn x\u00e9t: Khi d\u00f9ng K-NN model cho t\u1eadp d\u1eef li\u1ec7u, ch\u00fang t\u00f4i lo\u1ea1i b\u1ecf c\u1ed9t 'Price' v\u00e0 s\u1eed d\u1ee5ng c\u1ed9t 'price_cats' l\u00e0m labels k\u1ebft qu\u1ea3 cho m\u00f4 h\u00ecnh, do 2 c\u1ed9t n\u00e0y th\u1ec3 hi\u1ec7n \u0111\u1ed9 t\u01b0\u01a1ng quan cao. Sau khi \u00e1p d\u1ee5ng K-NN model cho t\u1eadp d\u1eef li\u1ec7u, ch\u00fang t\u00f4i nh\u1eadn \u0111\u01b0\u1ee3c \u0111\u1ed9 ch\u00ednh x\u00e1c th\u1ea5p, trong kho\u1ea3ng 0.18-0.225, gi\u00e1 tr\u1ecb ch\u00ednh x\u00e1c cao nh\u1ea5t sau khi s\u1eed d\u1ee5ng c\u00e1c c\u1ed9t 'main_category', 'subcat_1', 'brand_name'.","df026c55":"**Using main category, subcat_1, subcat_2, item_condition_id**","d35b3ced":"Vi\u1ec7c s\u1eed d\u1ee5ng t\u1ea5t c\u1ea3 c\u00e1c class (tr\u1eeb m\u1ea5y class v\u1ec1 price) \u0111\u00e3 gi\u1ea3m \u0111\u01b0\u1ee3c MSE, RMSE \u0111i so v\u1edbi vi\u1ec7c s\u1eed d\u1ee5ng m\u1ed9t v\u00e0i class.","827c04c6":"**Using Category_name**","64dbb190":"**Using most classes except price, price_cats, log_price**"}}