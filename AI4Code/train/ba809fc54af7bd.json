{"cell_type":{"a63a0bb8":"code","37777354":"code","ca4f1c75":"code","d14f6220":"code","c4d58c46":"code","f6269a6f":"code","c38b806d":"code","4da39159":"code","7c81f671":"code","b7757825":"code","e3394725":"code","8c39bbde":"code","89f62393":"code","b7995e89":"markdown","f6e02243":"markdown","02c95fa7":"markdown","fd9eb620":"markdown","f41e6844":"markdown","fcef3391":"markdown","292c438a":"markdown","31f853b1":"markdown","50754328":"markdown","e7ac4682":"markdown","0fcec9ff":"markdown","42d73a69":"markdown","de4c1560":"markdown","f56459a9":"markdown","1b3d7190":"markdown","f81b46ef":"markdown"},"source":{"a63a0bb8":"from torch import nn\nfrom torchvision.models import alexnet","37777354":"model = alexnet()\nmodel","ca4f1c75":"model.features","d14f6220":"model.features[1]","c4d58c46":"model.classifier = nn.Linear(9216, 1000)\nmodel","f6269a6f":"model.features[1] = nn.ReLU6()\nmodel","c38b806d":"def replace_layers(model, old, new):\n    for n, module in model.named_children():\n        if len(list(module.children())) > 0:\n            ## compound module, go inside it\n            replace_layers(module, old, new)\n            \n        if isinstance(module, old):\n            ## simple module\n            n = int(n)\n            model[n] = new","4da39159":"replace_layers(model.features, nn.ReLU, nn.ReLU6())\nmodel","7c81f671":"replace_layers(model, nn.AdaptiveAvgPool2d, nn.AdaptiveMaxPool2d((6,6)))\nmodel","b7757825":"def replace_layers(model, old, new):\n    for n, module in model.named_children():\n        if len(list(module.children())) > 0:\n            ## compound module, go inside it\n            replace_layers(module, old, new)\n            \n        if isinstance(module, old):\n            ## simple module\n            try:\n                n = int(n)\n                model[n] = new\n            except:\n                setattr(model, n, new)","e3394725":"replace_layers(model, nn.AdaptiveAvgPool2d, nn.AdaptiveMaxPool2d((6, 6)))\nmodel","8c39bbde":"replace_layers(model, nn.ReLU6, nn.ReLU())\nmodel","89f62393":"def replace_layers(model, old, new):\n    for n, module in model.named_children():\n        if len(list(module.children())) > 0:\n            ## compound module, go inside it\n            replace_layers(module, old, new)\n            \n        if isinstance(module, old):\n            ## simple module\n            setattr(model, n, new)","b7995e89":"I just created a `try . . except` block. So, if `[ ]` notation fails because we cannot convert string to integer, then we will switch to `.` notation.\n\nLets test our new function . . . ","f6e02243":"time to test the function . . .","02c95fa7":"### Replacing modules\/layers\n\nOnce you have access to the module, you can easily replace it. You ask how, just assign a new module.","fd9eb620":"And this is the function (or some version of it) that everyone was using. Now does it make sense why everyone is using `setattr` to replace layers?\n\nThank you somuch for reading the notebook. I really hope you learned something new, Cheers!","f41e6844":"# Why is everyone using `setattr` to replace pytorch layers?\n\nI was looking for ways to replace layers in pytorch. I found many solutions. Some made sense, others didn't. Some where naive & straight forward, others where mysterious. But one thing was common among all the working solutions : they all used `setattr`. Here are all the solutions I found, go have a look:\n- https:\/\/stackoverflow.com\/a\/58297341\n- https:\/\/discuss.pytorch.org\/t\/how-to-modify-a-pretrained-model\/60509\/10\n- https:\/\/www.kaggle.com\/parthdhameliya77\/pytorch-eca-nfnet-l0-image-tfidf-inference?scriptVersionId=60130957&cellId=12 - look at `replace_activations` function\n\nWhy is everyone using `setattr` ? Why can't we directly update layers by simple assignment ? These questions bothered me for a couple of days and I finally decided to go down the rabbit hole. \n\nIn this notebook, I will discuss the things that I learned in this brief adventure.","fcef3391":"We will use **alexnet** as our sample model. But the techniques discussed here applyies to all pytorch models.\n\n**Note:** In pytorch, every layer is a module. So, I will be using modules & layers interchangeably or I will metion both. Don't get confused, its standard pytorch stuff.\n","292c438a":"its working for, hurry! Just for sanity check lets try to convert all `nn.ReLU6` back to `nn.ReLU` ","31f853b1":"Great, all the `nn.ReLU` are now replaced by `nn.ReLU6`. But will this function work when we try to replace a layer with name associated with it. Lets see . . . ","50754328":"We just updated the `classifier` module. Now, lets try to replace the 1st Relu activation with Relu6 activation.","e7ac4682":"Perfect, it worked as expected. Lets try to a function to replace layers.","0fcec9ff":"Now, how can one access the 2nd layer (i.e. `ReLU` layer)? Since its a `Sequential` module, we can index into it. Let me show you . . .","42d73a69":"OOPS, error! It cannot convert `avgpool` to `int`. But we will need interger to access the layer \ud83e\udd14\n\nif you remember, we used the `.` (dot) notation to access the modules with names. But how do one access an attribute when you have attribute name as string. You guessed it, `setattr`. Lets update the function to accomodate this new change.","de4c1560":"### Accessing modules\/layers","f56459a9":"Easy, right? Let me summarize what discussed so far. \n\nA pytorch model consists of multiple modules. \n- If a module has name associated with it, then you can access it using the `.` (dot) notation. \n- To access the modules\/layers present inside `nn.Sequential` module, we will have to use `[ ]` (index) notation. Just like python lists.\n\n**Tip:** Just print the model and see if the layer has a name (i.e. `str`) or number (i.e. `int`) associated with it. If its a name, then use `.` (dot) notation, else use `[ ]` (index) notation.\n\nThis is important because this subtle difference will play a huge role in understanding the further content.","1b3d7190":"as you can see, our model is made up of 3 parts : `features`, `avgpool` & `classifier`. You can access them using `.` (dot) notation","f81b46ef":"### Why `setattr`?\n\nFinally, we have our function ready. It can replace both : layer with or without names. \n\nBut still the question remains, why is everyone using `setattr` ? So, I did some digging & realized why.\n\n> Only the modules\/layers inside `nn.Sequential` have number associated to them. All other modules will have names. So, whenever we are using `[ ]` index notation to replace the layer, we are actually calling `__setitem__` method inside `nn.Sequential` class.\n\nthis is how its defined:\n\nSource : [pytorch source code](https:\/\/github.com\/pytorch\/pytorch\/blob\/74089a0d34ec9fd2dda8860ac2638e68271955dd\/torch\/nn\/modules\/container.py#L107)\n\n```python\n    def __setitem__(self, idx: int, module: Module) -> None:\n        key: str = self._get_item_by_idx(self._modules.keys(), idx)\n        return setattr(self, key, module)\n```\n\nUnder the hood, its calling `setattr` method. That means, we can remove the `try . . . except` block. This is how it will look\n"}}