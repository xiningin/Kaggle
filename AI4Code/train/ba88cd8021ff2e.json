{"cell_type":{"f04cde2c":"code","f1da3bd2":"code","8953b5c5":"code","8bddc622":"code","1d1f920d":"code","498f423d":"code","885cf109":"code","a723aead":"code","4d5c5893":"code","595e05cc":"code","ab4a3c4d":"code","707b6b53":"code","33b8c5db":"code","23c367ef":"code","9c7be246":"code","ddc038fa":"code","7fcf1e4a":"code","5b7cc668":"code","d87066e0":"code","96292de7":"code","7064d4d9":"code","51faddd8":"code","81b7d797":"markdown","aecddb26":"markdown","d4c83368":"markdown","3adb079f":"markdown","4a35440c":"markdown","3a130da1":"markdown","63715dce":"markdown","45d7e289":"markdown","b2f0e1da":"markdown","82afdafa":"markdown","7deb374f":"markdown","8079452d":"markdown","e474c958":"markdown","6f87f006":"markdown","6276153e":"markdown","a62689ee":"markdown","6d13d264":"markdown","4bf57d8c":"markdown","54987505":"markdown","874b094d":"markdown","7fa9cad1":"markdown","d4c155d9":"markdown","d92552c3":"markdown","dee03051":"markdown","54ebfa30":"markdown","4fc82cdb":"markdown","1804e238":"markdown"},"source":{"f04cde2c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport json, codecs\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1da3bd2":"train = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv\")","8953b5c5":"train.head()","8bddc622":"print(\"train Shape --> \",train.shape)","1d1f920d":"print(\"Train Info\")\ntrain.info()","498f423d":"Number = train.label.value_counts().values\nLabel = train.label.value_counts().index\ncircle = plt.Circle((0,0),0.3,color = \"black\")\nexplodeTuple = (0.275, 0.25, 0.225, 0.2, 0.175, 0.15, 0.125, 0.1, 0.075, 0.05)\n\nplt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nsns.countplot(train[\"label\"])\nplt.subplot(1,2,2)\nplt.pie(Number, labels = Label,autopct='%1.2f%%', explode=explodeTuple,startangle=90, wedgeprops = { 'linewidth' : 2 , 'edgecolor' : 'black'})\np = plt.gcf()\np.gca().add_artist(circle) \nplt.legend()\nplt.show()","885cf109":"X_train = train.drop([\"label\"], axis=1).values\nY_train = train.label.values\nX_test = test.drop([\"label\"], axis=1).values\nY_test = test.label.values","a723aead":"print(\"X_train shape --> \",X_train.shape)\nprint(\"Y_train shape --> \",Y_train.shape)\nprint(\"X_test shape --> \",X_test.shape)\nprint(\"Y_test shape --> \",Y_test.shape)","4d5c5893":"X_train = X_train.astype(\"float32\") \/ 255.0\nX_test = X_test.astype(\"float32\") \/ 255.0","595e05cc":"plt.figure(figsize=(30,20))\n\nfor i in range(20):\n    plt.subplot(4,5,i+1)\n    plt.imshow(X_train[i].reshape(28,28), cmap=\"gist_yarg\")\n    plt.title(\"T-shirt\/top\" if Y_train[i] == 0 \n              else \"Trouser\" if Y_train[i] == 1\n              else \"Pullover\" if Y_train[i] == 2\n              else \"Dress\" if Y_train[i] == 3\n              else \"Coat\" if Y_train[i] == 4\n              else \"Sandal\" if Y_train[i] == 5\n              else \"Shirt\" if Y_train[i] == 6\n              else \"Sneaker\" if Y_train[i] == 7\n              else \"Bag\" if Y_train[i] == 8\n              else \"Ankle boot\", size = 20, color = \"brown\", fontweight = \"bold\")\n    plt.axis(\"off\")\n    \nplt.show()\n","ab4a3c4d":"from keras.models import Model\nfrom keras.layers import Input, Dense","707b6b53":"input_img = Input(shape = (784,))","33b8c5db":"encoded = Dense(32, activation=\"relu\")(input_img)\nencoded = Dense(16, activation=\"relu\")(encoded)\ndecoded = Dense(32, activation=\"relu\")(encoded)\ndecoded = Dense(784, activation=\"sigmoid\")(decoded)","23c367ef":"autoencoder = Model(input_img, decoded)","9c7be246":"autoencoder.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")","ddc038fa":"hist = autoencoder.fit(X_train, \n                       X_train,\n                       epochs=250, \n                       batch_size=256, \n                       shuffle=True,\n                       validation_data=(X_train, X_train))","7fcf1e4a":"encoder = Model(input_img, encoded)\nencoded_img = encoder.predict(X_test)","5b7cc668":"plt.figure(figsize=(10, 8))\nplt.subplot(2, 2, 1)\nplt.imshow(X_test[25].reshape(28,28), cmap=\"gist_yarg\")\nplt.title(\"Original Image\", color = \"green\")\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 2)\nplt.imshow(encoded_img[25].reshape(4,4), cmap=\"gist_yarg\")\nplt.title(\"Image Resulting from Encoder\", color = \"Darkred\")\nplt.axis(\"off\")\nplt.show()","d87066e0":"decoded_imgs = autoencoder.predict(X_test) ","96292de7":"plt.figure(figsize=(20, 5))\nfor i in range(10):\n    \n    plt.subplot(2, 10, i + 1)\n    plt.imshow(X_test[i].reshape(28, 28), cmap=\"gist_yarg\")\n    plt.title(\"(Original)\\nT-shirt\/top\" if Y_test[i] == 0 \n              else \"(Original)\\nTrouser\" if Y_test[i] == 1\n              else \"(Original)\\nPullover\" if Y_test[i] == 2\n              else \"(Original)\\nDress\" if Y_test[i] == 3\n              else \"(Original)\\nCoat\" if Y_test[i] == 4\n              else \"(Original)\\nSandal\" if Y_test[i] == 5\n              else \"(Original)\\nShirt\" if Y_test[i] == 6\n              else \"(Original)\\nSneaker\" if Y_test[i] == 7\n              else \"(Original)\\nBag\" if Y_test[i] == 8\n              else \"(Original)\\nAnkle boot\", size = 13, color = \"darkred\")\n    plt.axis(\"off\")\n\n    plt.subplot(2, 10, i + 1 + 10)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    plt.title(\"(Reconstructed)\\nT-shirt\/top\" if Y_test[i] == 0 \n              else \"(Reconstructed)\\nTrouser\" if Y_test[i] == 1\n              else \"(Reconstructed)\\nPullover\" if Y_test[i] == 2\n              else \"(Reconstructed)\\nDress\" if Y_test[i] == 3\n              else \"(Reconstructed)\\nCoat\" if Y_test[i] == 4\n              else \"(Reconstructed)\\nSandal\" if Y_test[i] == 5\n              else \"(Reconstructed)\\nShirt\" if Y_test[i] == 6\n              else \"(Reconstructed)\\nSneaker\" if Y_test[i] == 7\n              else \"(Reconstructed)\\nBag\" if Y_test[i] == 8\n              else \"(Reconstructed)\\nAnkle boot\", size = 13, color = \"green\")\n    plt.axis(\"off\")\n\nplt.show()","7064d4d9":"print(\"History Keys -->\", hist.history.keys())","51faddd8":"plt.plot(hist.history[\"loss\"], label = \"Train Loss\", color = \"black\", alpha=0.7, linewidth=5)\nplt.plot(hist.history[\"val_loss\"], label = \"Val Loss\", color = \"darkred\", linewidth=2, linestyle='dashed')\n\nplt.legend()\nplt.show()","81b7d797":"<a id ='3' ><\/a>\n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nLoad and Check Data \ud83d\uddf8 <\/h2>","aecddb26":"<a id ='2' ><\/a>\n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nUsage areas of Autoencoder \u2753 <\/h2>\n\n<div style = \"background:#F5DEB3;box-shadow: 5px 8px 18px black;border-style: outset;\">\n<ul>\n    <li style = \"color:black;font-family:Segoe Print;font-weight:bold\" >Feature Extraction<\/li>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" >Dimension Reduction<\/li>\n    <li style = \"color:black;font-family:Segoe Print;font-weight:bold\" >Denoising<\/li>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" >Image coloring\/completion<\/li>\n    <li style = \"color:black;font-family:Segoe Print;font-weight:bold\" >Generating new data<\/li>\n<\/ul>\n    <\/div>","d4c83368":"![Ads\u0131z.png](attachment:ecd7efd4-b453-4aa8-98c2-985dd4f0e3a1.png)\n\n<center><h1 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\">Introduction \ud83d\udcd6 <\/h1><\/center>\n<p style = \"color:black;font-family:Segoe Print;font-weight:bold\">Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.<\/p>\n\n<p style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > What are we going to do in this notebook? <\/p>\n\n<p style = \"color:black;font-family:Segoe Print;font-weight:bold\">Yes, in this notebook, I will briefly talk about what autoencoder is and where it is used and I will finish by coding the steps we see below. While doing these, I will use visuals to be more permanent.<\/p>\n\n<p style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > So, let's get started. <\/p>\n    \n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\">Content :<\/h2>\n\n<div style = \"background:#F5DEB3;border: 4px dotted black\">\n<ul>\n    <li style = \"color:gray;font-size:16px\"> <a href = \"#1\" style = \"color:black;font-family:Segoe Print;font-weight:bold\"> What is Autoencoder \ud83d\udcda \u2753 <\/a> <\/li> \n        <li style = \"color:gray;font-size:16px\"> <a href = \"#2\" style = \"color:black;font-family:Segoe Print;font-weight:bold\"> Usage areas of Autoencoder \u2753 <\/a>\n    <ul>\n        <li style = \"color:darkblue;font-size:16px\"> <a href = \"#2\" style = \"color:darkblue;font-family:Segoe Print;font-weight:bold\"> Feature Extraction<\/a> <\/li>\n         <li style = \"color:darkblue;font-size:16px\"> <a href = \"#2\" style = \"color:darkblue;font-family:Segoe Print;font-weight:bold\"> Dimension Reduction <\/a> <\/li>\n         <li style = \"color:darkblue;font-size:16px\"> <a href = \"#2\" style = \"color:darkblue;font-family:Segoe Print;font-weight:bold\"> Denoising <\/a> <\/li>\n         <li style = \"color:darkblue;font-size:16px\"> <a href = \"#2\" style = \"color:darkblue;font-family:Segoe Print;font-weight:bold\"> Image coloring\/completion <\/a> <\/li>\n         <li style = \"color:darkblue;font-size:16px\"> <a href = \"#2\" style = \"color:darkblue;font-family:Segoe Print;font-weight:bold\"> Generating new data <\/a> <\/li>\n    <\/ul>\n        <li style = \"color:gray;font-size:16px\"> <a href = \"#3\" style = \"color:black;font-family:Segoe Print;font-weight:bold\"> Load and Check Data \ud83d\uddf8 <\/a> <\/li> \n    <li  style = \"color:gray;font-size:16px\" > <a href = \"#4\" style = \"color:black;font-family:Segoe Print;font-weight:bold\" > Train - Test Split <\/a>  <\/li>\n            <li style = \"color:gray;font-size:16px\" ><a href = \"#5\" style = \"color:black;font-family:Segoe Print;font-weight:bold\" >  Normalization \u2049\ufe0f  <\/a> \n                <ul>\n                    <li style = \"color:gray;font-size:16px\" ><a href = \"#6\" style = \"color:darkblue;font-family:Segoe Print;font-weight:bold\" >   Why do we want to normalize the pictures? <\/a><\/li>\n                <\/ul>\n            <\/li>\n      <li style = \"color:gray;font-size:16px\" ><a href = \"#7\" style = \"color:black;font-family:Segoe Print;font-weight:bold\"> Implementing with Keras \u2754<\/a> <\/li>         \n<li style = \"color:gray;font-size:16px\"> <a href = \"#8\" style = \"color:black;font-family:Segoe Print;font-weight:bold\"> What happens after the encoder?  <\/a> <\/li>\n    <li style = \"color:gray;font-size:16px\"> <a href = \"#9\" style = \"color:black;font-family:Segoe Print;font-weight:bold\"> What happens after the Autoencoder? <\/a> <\/li>\n        <li style = \"color:gray;font-size:16px\"> <a href = \"#10\" style = \"color:black;font-family:Segoe Print;font-weight:bold\"> Model Evaluation  <\/a> <\/li>\n<\/ul>\n<\/div>","3adb079f":"<ul>\n    <li style = \"color:blue;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" > We took a look at the clothes\/shoes in our data.<\/p> <\/li>\n<\/ul>","4a35440c":"<a id ='8' ><\/a>\n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nWhat happens after the encoder? <\/h2>\n\n<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >What does the part up to the encoder we created does? We'll take a look at it.<\/p> <\/li>\n<\/ul>","3a130da1":"<ul>\n    <li style = \"color:blue;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" > Since the shape of the data we have is already as we want, there is no need to reshape it.<\/p> <\/li>\n<\/ul>","63715dce":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" > We separate the data into train and test. <\/p> <\/li>\n<\/ul>","45d7e289":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >We create the autoencoder using the layers we created above.<\/p> <\/li>\n<\/ul>","b2f0e1da":"<ul>\n    <li style = \"color:blue;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" > We see that our data has a uniform distribution. There is an equal amount of each part<\/p> <\/li>\n<\/ul>","82afdafa":"<a id ='9' ><\/a>\n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nWhat happens after the Autoencoder? <\/h2>\n\n<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >We will examine the images produced as a result of the automatic encoder by comparing them with the real ones.<\/p> <\/li>\n<\/ul>","7deb374f":"<h4 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nWhat's in our data? <\/h4>","8079452d":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >Now that our model is ready, we can compile it.<\/p> <\/li>\n<\/ul>","e474c958":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >train and validation loss gradually decreased. We got what we wanted now. But of course we can improve this further by changing the parameters.<\/p> <\/li>\n<\/ul>","6f87f006":"<a id ='10' ><\/a>\n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nModel Evaluation <\/h2>\n\n<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >We will finish our notebook by evaluating our model.<\/p> <\/li>\n<\/ul>","6276153e":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >We see how the bot looks after exiting the encoder. This model can get better as it is trained. Now let's decode this compressed picture and look at our pictures that are formed as a result of autoencoder.<\/p> <\/li>\n<\/ul>","a62689ee":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" > We normalize our images.<\/p> <\/li>\n<\/ul>","6d13d264":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >We took a look at the keywords that we can visualize.<\/p> <\/li>\n<\/ul>","4bf57d8c":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >I am creating the encoder and decoder layers as I have shown in the picture above.<\/p> <\/li>\n        <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >Here we connect the layers by typing the name of the previous layer in parentheses at the end of the line.<\/p> <\/li>\n<\/ul>","54987505":"<p style = \"text-shadow: 12px 12px 2px #333;color:brown;font-family:Segoe Print;font-weight:bold\" > I YES, WE HAVE COME TO AN END. THANK YOU<\/p>","874b094d":"<ul>\n    <li style = \"color:blue;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >For a better understanding of the model that we will create above, I wanted to show it by drawing.<\/p> <\/li>\n<\/ul>","7fa9cad1":"<a id ='4' ><\/a>\n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nTrain -Test Split <\/h2>","d4c155d9":"<a id ='5' ><\/a>\n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nNormalization \u2049\ufe0f <\/h2>\n\n<div style = \"background:#FFE4E1;box-shadow: 5px 8px 18px black;border-style: outset;\">\n<a id ='6' ><\/a>\n<p style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > Why do we want to normalize the pictures? <\/p>\n\n<p style = \"color:black;font-family:Segoe Print;font-weight:bold\" >If we do not normalize, there may be errors due to certain colors. So, we first need to normalize. <\/p>\n\n<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print;font-weight:bold\"> Images are represented by values \u200b\u200bbetween 0 and 255. Therefore, we have to normalize the images before the model.<\/p> <\/li>\n <\/ul>\n    <\/div>","d92552c3":"<a id ='1' ><\/a>\n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nWhat is Autoencoder \ud83d\udcda \u2753 <\/h2>\n\n![Ads\u0131z.png](attachment:67b6b4d9-14d8-4942-aede-a66039c05c48.png)\n\n<div style = \"background:#E0E0E0;border: 4px dotted black\">\n<p style = \"color:black;font-family:Segoe Print;font-weight:bold\" > An autoencoder is a neural network that copies values \u200b\u200bfrom the input layer to the output layer.That is, we reconstruct the data we give as input to the neural network in the output layer. Autoencoder is an unsupervised learning model in which labels are not explicitly specified when training the dataset. <\/p>\n\n<p style = \"color:black;font-family:Segoe Print;font-weight:bold\" > This neural network consists of two separate phases as seen in the picture above; encoder and decoder. The encoder generates the h code from the x input with the f function h=f(x), the decoder converts this h code to the r output with the g function r=g(h), since the input (x) and the output (r) will be equal to each other, this process called reconstruction. <\/p>\n    <\/div>","dee03051":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >After importing our libraries, we create our input layer.<\/p> <\/li>\n        <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >Since the size of our image is 784, we adjust our input size accordingly.<\/p> <\/li>\n<\/ul>","54ebfa30":"<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nImport Libraries \ud83d\udd16 <\/h2>","4fc82cdb":"<ul>\n    <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >We train our model. Let's pay attention to the same input and output values \u200b\u200bhere.<\/p> <\/li>\n        <li style = \"color:darkred;font-family:Segoe Print;font-weight:bold\" > <p style = \"color:black;font-family:Segoe Print\" >We shuffle data using shuffle.<\/p> <\/li>\n<\/ul>","1804e238":"<a id ='7' ><\/a>\n<h2 style = \"background:#0C0C0C ;color:white;border:0;font-family:Segoe Print;font-weight:bold\"> \nImplementing with Keras \u2754 <\/h2>\n\n![Ads\u0131z.png](attachment:b6fb5682-3cac-4a7e-a7c8-bd8efeb85698.png)"}}