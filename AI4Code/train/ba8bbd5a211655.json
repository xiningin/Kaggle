{"cell_type":{"2a8dcacb":"code","e23bf865":"code","4bcbbf05":"code","72784c4a":"code","e8a8f75a":"code","825c9132":"code","77bd7ee5":"code","eac1d55d":"code","a4e10289":"code","36005c14":"code","a240ff51":"code","98145319":"code","c77b8665":"code","9d6105b4":"code","4d8a72c9":"code","19ee83f0":"code","42680f1c":"code","d7ff4b5b":"code","2a0a1bef":"code","cc06771e":"code","9fb0123f":"code","d9f438f0":"code","60016ebb":"code","4151edb9":"code","2c59f5de":"code","ce470b6b":"code","f5bce1cf":"code","62c53464":"code","929c90f0":"code","1bc5a6eb":"code","b962ce86":"code","28b06a55":"code","93b84ddf":"code","c990fd10":"code","c94b5e52":"code","9949f9ce":"code","8f1ca485":"code","ba83299a":"code","bad0e45e":"code","080ec34d":"code","58a97894":"code","7f786958":"code","38f3f84b":"code","b416e6ac":"code","608a4d0c":"code","209af631":"code","c2156f3f":"code","4865a44e":"code","9e66c38e":"code","dd343bac":"code","be5741ae":"code","5c14024b":"code","46201332":"code","578e8f98":"code","b69be067":"code","6fff057b":"code","b2ca1842":"code","349824ca":"code","ecf0061f":"code","7613c002":"code","d44b9c16":"code","a163ac49":"code","739c832d":"code","b99430bd":"code","a38acbd9":"code","df91fa57":"code","b0562795":"code","bc9c12a1":"code","b4ddeac8":"code","94755fd9":"code","e1c087e6":"code","986d71f5":"markdown","5fad7ea3":"markdown","ac2edf63":"markdown","f03fe0ff":"markdown","dcea6b9e":"markdown","4c1ddc9d":"markdown","bcddabf8":"markdown","f7c3c4b1":"markdown","e0b485ac":"markdown","dc2a240d":"markdown","f844a3a1":"markdown","5916eaa0":"markdown","a38eca60":"markdown","422b9ce5":"markdown","afe80df9":"markdown","5377fb6f":"markdown"},"source":{"2a8dcacb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e23bf865":"#Importiamo le librerie per la visualizzazione dati\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#Questo \u00e8 il dataset di training\ndata = pd.read_csv(\"\/kaggle\/input\/soai21-fish-regression\/dati.csv\")","4bcbbf05":"#Diamo uno sguardo alle prime 5 righe che compongono il nostro dataset\ndata.head()\n","72784c4a":"#Non sembrano esserci valori mancanti ma potrebbero esserci degli outliers\ndata.isna().sum()","e8a8f75a":"#Notiamo che alcuni pesci hanno un valori pari a 0 relativamente al peso ed \u00e8 molto improbabile quindi li elimineremo\ndata.describe().transpose()","825c9132":"#Creiamo una copia del dataset. Ora il nostro valore minimo \u00e8 per Weight \u00e8 4.079 che sembr pi\u00f9 verosimile\ndata=data.loc[data.Weight!= 0,:].copy()","77bd7ee5":"#Vediamo le dimensioni del dataset\ndata.shape","eac1d55d":"#E le caratteristiche  quindi valori non nulli e tipo di variabile\ndata.info()","a4e10289":"\n\n\n#A quanto pare le differenze nella media dei pesi sono abbastanza nette\ndata.groupby(\"Species\")[\"Weight\"].mean().sort_values(ascending=False)","36005c14":"#Le varie specie sono distribuite in modo abbbastanza omogeneo nel training. Quindi \u00e8 molto bilanciato da questo punto di vista\ndata.groupby(\"Species\")[\"Weight\"].count().sort_values(ascending=False)","a240ff51":"#Alcune variabili sono un po asimmetriche\ndata.skew()","98145319":"data.corr()","c77b8665":"# Vediamo anche con il grafico heatmap. \nsns.heatmap(data.corr())","9d6105b4":"#Vediamo le distribuzioni incrociate  e singole delle variabili tenendo conto delle specie\n\nsns.pairplot(data,hue=\"Species\")\nplt.tight_layout()\n","4d8a72c9":"#Elimino le due colonne di troppo\ndata=data.drop([\"Length1\",\"Length3\"],axis =1)\ndata","19ee83f0":"#Un modo per creare variabili dummies per specie \u00e8 questo lo tengo da parte\ndummy=pd.get_dummies(data[\"Species\"])\ndummy.head()","42680f1c":"#Questa \u00e8 una strad percorribile per creare il nuovo dataset con le variabili dummy\n#pesci=pd.concat([data,dummy],axis=1)\n#pesci.head()","d7ff4b5b":"#Separo la matrice dei predittori dalla colonna target\nX = data.drop([\"Weight\"], axis=1).copy()\ny= data[\"Weight\"]","2a0a1bef":"from sklearn.model_selection import train_test_split","cc06771e":"#Eseguo lo split del dataset cosi ho un training ad un validation set \nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)","9fb0123f":"#decido di importare queste librerie per eseguire trasformazioni sulle variabili. Robust scaler per lo scaling one hot encoder per la variabile qualitativa\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import OneHotEncoder","d9f438f0":"scaler = RobustScaler()\nnumeric_df = scaler.fit_transform(X_train.iloc[:,:3])#Tenendo conto delle diverse unit\u00e0 di misura eseguo lo scaling\nnumeric_val = scaler.transform(X_val.iloc[:,:3])","60016ebb":"encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\ncat_df = encoder.fit_transform(X_train[[\"Species\"]])\ncat_val = encoder.transform(X_val[[\"Species\"]])","4151edb9":"#Partiamo dal modello di Regressione classico e scegliamo la metrica dell'mse per valutare le perormances\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error","2c59f5de":"#Ricongiungo la parte numerica e quella .Il nuovo dataset ha 10 colonne\nX_train_adj=np.hstack((numeric_df,cat_df))\nX_val_adj = np.hstack((numeric_val, cat_val))\nX_train_adj.shape","ce470b6b":"regression_model = LinearRegression()#instanzio il modello\nregression_model.fit(X_train_adj, y_train)#lo adatto ai dati di training","f5bce1cf":"#... e lo valutiamo \nprint(\"R2 on train: \", regression_model.score(X_train_adj, y_train))\nprint(\"R2 on validation: \", regression_model.score(X_val_adj, y_val))","62c53464":"y_pred=regression_model.predict(X_val_adj)\ny_pred# i valori predetti sul validation set","929c90f0":"y_val","1bc5a6eb":"regression_model.coef_","b962ce86":"#Eseguiamo la prima predizione con il modello lineare classico\ntest = pd.read_csv(\"\/kaggle\/input\/soai21-fish-regression\/test.csv\")\ntest = test.drop(columns=['Id'])\n","28b06a55":"test.describe().T","93b84ddf":"test=test.drop([\"Length1\", \"Length3\"], axis=1)\ntest","c990fd10":"# They are not distributed in the same way\ntest.Species.value_counts()","c94b5e52":"#Eseguiamo le stesse trasformazioni sul dataset di test\nnumeric_test = scaler.transform(test.iloc[:,:3])\ncat_test = encoder.transform(test[[\"Species\"]])\n\nX_test_new = np.hstack((numeric_test, cat_test))","9949f9ce":"output=pd.DataFrame()","8f1ca485":"output['Weight']=regression_model.predict(X_test_new)","ba83299a":"#Diamo la predizione\noutput['Id'] = np.arange(len(test))\noutput.to_csv(\"regressione_pesci.csv\",index=False)","bad0e45e":"output#questa \u00e8 la prima predizione finale","080ec34d":"#Importiamo la libreria per la regressione Ridge\nfrom sklearn.linear_model import Ridge","58a97894":"#Regressione Ridge\nregr_r = Ridge(alpha= 0.7)\nregr_r.fit(X_train_adj, y_train)\n\nprint(\"R2 on train: \", regr_r.score(X_train_adj, y_train))\nprint(\"R2 on validation: \", regr_r.score(X_val_adj, y_val))","7f786958":"output=pd.DataFrame()\noutput['Weight']=regr_r.predict(X_test_new)\noutput['Id'] = np.arange(len(test))\noutput.to_csv(\"regressione_pesci.csv\",index=False)\noutput #predizione finale Ridge","38f3f84b":"#Libreria per la Regressione polinomiale\nfrom sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(2) #ho scelto il grado due per non appesantire troppo e perch\u00e8 dal grafico sembra che la relazione sia quadrativa","b416e6ac":"# eseguiamo la trasformazione polinomiale sul dataset con le nuove variabili\npoly_train=poly.fit_transform(numeric_df)\npoly_val = poly.fit_transform(numeric_val)\n","608a4d0c":"X_train_poly = np.hstack((poly_train, cat_df))\nX_val_poly = np.hstack((poly_val, cat_val))\nX_train_poly.shape ","209af631":"from sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nPoly_reg=Lasso()\nPoly_reg.fit(X_train_poly, y_train)\nprint(\"R2 on train: \", Poly_reg.score(X_train_poly, y_train))\nprint(\"R2 on validation: \", Poly_reg.score(X_val_poly, y_val))","c2156f3f":"poly_test = poly.fit_transform(numeric_test)\nX_test_poly=np.hstack((poly_test,cat_test))","4865a44e":"output=pd.DataFrame()\noutput['Weight']=Poly_reg.predict(X_test_poly)\noutput['Id'] = np.arange(len(test))\noutput.to_csv(\"regressione_pesci.csv\",index=False)\noutput","9e66c38e":"poly_test.shape","dd343bac":"from sklearn.model_selection import KFold,cross_val_score \nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n\nn_folds=5\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train)\n    rmse= np.sqrt(-cross_val_score(model, train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","be5741ae":"\nmodel=BayesianRidge()\ntrain= X_train_poly\nscore = rmsle_cv(model)\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","5c14024b":"def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n          # Train cloned base models\n        \n        for model in self.models_:\n            model.fit(X, y)\n\n        return self\n    \n#Now we do the predictions for cloned models and average them\ndef predict(self, X):\n        predictions = np.column_stack([\n            model.predict(X) for model in self.models_\n        ])\n        return np.mean(predictions, axis=1)  ","46201332":"from sklearn.pipeline import make_pipeline\n#Regressione elasticnet\nregressione_ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n\nscore = rmsle_cv(regressione_ENet)\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","578e8f98":"#regressione_lasso\nregressione_lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nscore = rmsle_cv(regressione_lasso)\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","b69be067":"from sklearn.kernel_ridge import KernelRidge\n#Kernel rigdge regression\nKRR = KernelRidge(alpha=0.6 ,kernel='polynomial', degree=2, coef0=2.5)\nscore = rmsle_cv(KRR)\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","6fff057b":"KRR.fit(X_train_poly, y_train)\noutput=pd.DataFrame()\noutput['Weight']=KRR.predict(X_test_poly)\noutput['Id'] = np.arange(len(test))\noutput.to_csv(\"regressione_pesci.csv\",index=False)\noutput #predizione finale Ridge","b2ca1842":"from sklearn.model_selection import GridSearchCV\n\nkr = GridSearchCV(KernelRidge(kernel='polynomial', degree=2),\n                  param_grid={\"alpha\": [0.1,0.3,0.5,0.6, 1e-2, 1e-3],\n                              \"coef0\": [1.0 ,1.5 ,2.0 ,2.5, 3]})                              ","349824ca":"score = rmsle_cv(kr)\nprint(score)\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n","ecf0061f":"kr.fit(X_train_poly, y_train)\noutput=pd.DataFrame()\noutput['Weight']=kr.predict(X_test_poly)\noutput['Id'] = np.arange(len(test))\noutput.to_csv(\"regressione_pesci.csv\",index=False)\noutput #predizione finale Ridge","7613c002":"print(kr.best_score_)\nprint(kr.best_estimator_)\nprint(kr.best_params_)\n","d44b9c16":"KRR = KernelRidge(alpha=0.01 ,kernel='polynomial', degree=2, coef0=2.0)\nscore = rmsle_cv(KRR)\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","a163ac49":"KRR.fit(X_train_poly, y_train)\noutput=pd.DataFrame()\noutput['Weight']=kr.predict(X_test_poly)\noutput['Id'] = np.arange(len(test))\noutput.to_csv(\"regressione_pesci.csv\",index=False)\noutput #predizione finale Ridge","739c832d":"from sklearn.model_selection import GridSearchCV\nkr1 = GridSearchCV(KernelRidge(kernel= \"polynomial\", degree=2),\n                  param_grid={\"alpha\": [0.05, 0.1,0.3,0.5,0.6, 1e-2, 1e-3],\n                              \"coef0\": [1.0 ,1.5 ,1.8,2.0 ,2.5, 3]})\n                             \nscore = rmsle_cv(kr1)\nprint(score)\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","b99430bd":"kr1.fit(X_train_poly,y_train)\nprint(kr1.best_score_)\nprint(kr1.best_estimator_)\nprint(kr1.best_params_)\n","a38acbd9":"from sklearn.svm import SVR","df91fa57":"from sklearn.model_selection import GridSearchCV\nsvr = GridSearchCV(SVR(kernel='poly',degree=2),\n                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3,1250,1500],\n                            \"coef0\": [0.0,1.0 ,1.5 ,1.8,2.0 ,2.5, 3]\n                               })","b0562795":"#svr_poly = SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,coef0=1)\nscore = rmsle_cv(svr)\nprint(score)\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","bc9c12a1":"svr.fit(X_train_poly,y_train)\nprint(svr.best_estimator_)\nsvr.best_score_","b4ddeac8":"model=SVR(kernel=\"poly\",degree=2,C=1250)\nmodel.fit(X_train_poly,y_train)\nscore=rmsle_cv(model)\nscore\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","94755fd9":"svr.fit(X_train_poly, y_train)\noutput=pd.DataFrame()\noutput['Weight']=svr.predict(X_test_poly)\noutput['Id'] = np.arange(len(test))\noutput.to_csv(\"regressione_pesci.csv\",index=False)\noutput #predizione finale Ridge","e1c087e6":"model.fit(X_train_poly, y_train)\noutput=pd.DataFrame()\noutput['Weight']=model.predict(X_test_poly)\noutput['Id'] = np.arange(len(test))\noutput.to_csv(\"regressione_pesci.csv\",index=False)\noutput #predizione finale Ridge","986d71f5":"Ho scelto il valore di alfa che mi dava un risultato pi\u00f9 stabile tra training e validation set. Abbiamo ottenuto un leggero miglioremento con la regolarizzazione","5fad7ea3":"LA maggior parte delle variabili sono molto correlate e possiamo notare una forma quadratica dal pairplot. L'inclinazione della parabola \u00e8 pi\u00f9 o meno accentuata a seconda del tipo di specie. Possiamo considerare una regressone polinomiale per stimare i valori del target","ac2edf63":"Sembra che ci sia un miglioramento abbastanza evidente","f03fe0ff":"Regressione polinomiale\n-----","dcea6b9e":"Tuttavia forse sono un po' poche per poter fare delle analisi separate per specie in modo robusto","4c1ddc9d":"\nRegressione sui pesci\n----\nIn questa competizione l'obiettivo \u00e8 trovare il giusto peso ad un gruppo di pesci di ben 7 tipologie diverse in base ad alcune variabili descrittive delle loro caratteristiche.\nPer farlo utilizzeremo alcuni modelli di machine learning applicati ad un dataset contenente variabili sia qualitative che quantitative. La variabile target Weight rappresenta il peso ed \u00e8 una variabile continua perci\u00f2 siamo di fronte ad un modello di classificazione supervisionata in quanto abbiamo un dataset di train con i valori relativi ai pesi dei pesci e dovremo stimare una variabile quantitativa.\nAbbiamo anche un dataset di test al quale mancano i pesi ( li dobbiamo stimare noi) e quello della submission.\nAddestreremo i nostri modelli sul dataset di train e poi successivamente proveremo a predirre i nuovi valori nel test set con gli algoritmi visti finora nel corso.\nLa mia idea \u00e8 di partire da un modello ancora pi\u00f9 semplice di quello di baseline ossia la regressione lineare classica per poi andare ad aumentare la complessit\u00e0 con ridge lasso elasticnet... e perch\u00e8 no regressione polinomiale se le relazioni tra variabile target e predittori saranno non lineari.\nInfatti dalla letteratura dell'argomento sembra che ci sia una relazione quadratica tra peso ed altre features che abbiamo nel dataset.. Successivamente poi proveremo altri modelli pi\u00f9 complessi\n","bcddabf8":"Analizziamo le correlazioni:\nPossiamo vedere come tutte le variabili sono molto correlate con la variabile target ma sono anche correlate tra di loro quindi potremmo andare incontro a problemi di multicollinearit\u00e0. Sicuramente le prime 3 sono molto correlate e tenerle tutte e tre potrebbe causarci un po di overfitting. Scegliamo di tenerne una","f7c3c4b1":"Abbiamo ora 17 variabili ","e0b485ac":"In questo modo ho creato convertito la variabile qualitativa in una matrice di 0 e 1","dc2a240d":"Mi sembra che il RobustScaler sia adatto a questa situazione perch\u00e8 resistente agli outlier ma potrei anche usare lo StandardScaler. ","f844a3a1":"Lavoriamo sul test\n---","5916eaa0":"  0.956725765683848\nR2 on validation:  0.9427389215192064","a38eca60":"kr1 = GridSearchCV(KernelRidge(kernel= \"polynomial\", degree=2),\n                  param_grid={\"alpha\": [0.1,0.3,0.5,0.6, 1e-2, 1e-3],\n                              \"coef0\": [1.0 ,1.5 ,1.8,2.0 ,2.5, 3]})\n                             \nscore = rmsle_cv(kr1)\nprint(score)\nprint(\"\\nmodel score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","422b9ce5":"Il coefficiente di determinazione \u00e8 0.95 sul training e 0.94 circa sul test.. non c'\u00e8 molto overfitting vediamo se riusciamo a migliorarlo aggiungendo qualcosa.","afe80df9":"Risultato:\n\n0.9928252007671329\n\nKernelRidge(alpha=0.01, coef0=2.0, degree=2, kernel='polynomial')\n\n{'alpha': 0.01, 'coef0': 2.0}","5377fb6f":"#Reressione Ridge\n---"}}