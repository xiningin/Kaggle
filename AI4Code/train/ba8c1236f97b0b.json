{"cell_type":{"4f5f3c5a":"code","bc96748d":"code","15f37750":"code","2f8c9d83":"code","b6e76e51":"code","a1848b54":"code","3b24de5e":"code","326c70b6":"code","103d90f9":"code","826377c2":"code","803f555e":"code","12b78e75":"code","7fe5a4e0":"code","3e1be27e":"code","5d779ce6":"code","b71e52e6":"code","1d8dddd1":"code","0ef73d4b":"code","2e13965e":"code","67398cd9":"code","59dfa226":"code","6b33e3ae":"code","2b0df3c5":"code","d13a2b98":"code","1ac4aac4":"code","543adb43":"code","43808a23":"code","117bdc83":"code","ac418ee7":"code","2d7ecc28":"code","cb0bac37":"code","3f3db027":"code","626f6f83":"code","75a98021":"code","e9b00f59":"code","abc5d2e4":"code","7496c2db":"code","1f2e9ea3":"code","063d34a7":"code","59f3ef50":"code","4bb87b3f":"code","902860e0":"code","faffd39b":"code","fb4f1764":"code","c88677e3":"code","02583856":"code","856c9665":"code","0ad16cfe":"code","799ee66b":"code","0f16fc4a":"code","8006ba59":"code","9449a368":"code","75185d7c":"code","a08e454b":"code","780ddb95":"code","b718eff0":"code","4b513471":"code","ab439439":"code","3b3ab4f5":"code","f82660bf":"code","9c1e22cf":"code","f8bb19fb":"code","4abaceba":"code","5efbd89e":"code","f3742e52":"code","60678138":"code","82f839ef":"code","3ab63f02":"code","a7cf9a0d":"code","bf1cb174":"code","235bf7dc":"code","19da760c":"code","c196e331":"code","5c1c5621":"code","49cab74b":"code","58aea0dd":"code","a86a6289":"code","0909abab":"code","5486d635":"markdown","8ec38cb5":"markdown","fcebf69f":"markdown","e0c540d5":"markdown","bea67302":"markdown","0100863b":"markdown","6c3e20b2":"markdown","df2cffc0":"markdown","4dd193ce":"markdown","b55a39cd":"markdown","7c1cc510":"markdown","033385aa":"markdown"},"source":{"4f5f3c5a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom seaborn import heatmap\nimport matplotlib.pyplot as plt\nfrom datetime import time, datetime\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc96748d":"dataset_path = '\/kaggle\/input\/car-crashes-severity-prediction\/'\n\ndf = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n\nprint(\"The shape of the dataset is {}.\\n\\n\".format(df.shape))\n\ndf.head()","15f37750":"df['Dates'] = pd.to_datetime(df['timestamp']).dt.date\ndf['Time'] = pd.to_datetime(df['timestamp']).dt.time\n","2f8c9d83":"_df= df.drop(columns=['ID', 'Bump', 'Roundabout', 'timestamp'])\n_df","b6e76e51":"_df['Crossing'] = _df['Crossing'].astype('int')\n_df['Give_Way'] = _df['Give_Way'].astype('int')\n_df['Junction'] = _df['Junction'].astype('int')\n_df['No_Exit'] = _df['No_Exit'].astype('int')\n_df['Railway'] = _df['Railway'].astype('int')\n_df['Stop'] = _df['Stop'].astype('int')\n_df['Amenity'] = _df['Amenity'].astype('int')\nenc = LabelEncoder()\nenc.fit(_df['Side'])\n_df['Side'] = enc.transform(_df['Side'])\n_df","a1848b54":"df_corr = _df.corr()\ndf_corr","3b24de5e":"fig, ax = plt.subplots(figsize=(11, 9))\nheatmap(df_corr, cmap=\"gray\")\nplt.show()","326c70b6":"_df","103d90f9":"a= time(hour = 7, minute = 0, second = 0)\nb= time(hour = 14, minute = 0, second = 0)\nc= time(hour = 0, minute = 0, second = 0)\n\n_df['Time_Interval'] = _df['Time'].apply(lambda x: 'Dawn' if (x <= a and x > c) else ('Day' if (x <= b and x > a) else 'Night'))","826377c2":"_df.groupby(['Time_Interval']).count()","803f555e":"_df['Time']","12b78e75":"df2 = pd.read_csv(os.path.join(dataset_path, 'weather-sfcsv.csv'))","7fe5a4e0":"df2","3e1be27e":"df2['newDate'] = df2.apply(lambda row: datetime.strptime(f\"{int(row.Year)}-{int(row.Month)}-{int(row.Day)}\", '%Y-%m-%d'), axis=1)","5d779ce6":"_df2= df2.drop(columns=['Year', 'Day', 'Selected'])\n_df2","b71e52e6":"_df2['newHour'] = _df2.apply(lambda row: datetime.strptime(f\"{int(row.Hour)}:{'00'}:{'00'}\", '%H:%M:%S'), axis=1)\n_df2","1d8dddd1":"_df2['Time'] = pd.to_datetime(_df2['newHour']).dt.time\n_df2['Time']","0ef73d4b":"_df2= _df2.drop(columns=['Hour', 'newHour'])\n","2e13965e":"_df2","67398cd9":"a= time(hour = 7, minute = 0, second = 0)\nb= time(hour = 14, minute = 0, second = 0)\nc= time(hour = 0, minute = 0, second = 0)\n\n_df2['Time_Interval'] = _df2['Time'].apply(lambda x: 'Dawn' if (x <= a and x > c) else ('Day' if (x <= b and x > a) else 'Night'))","59dfa226":"_df2['Temperature(F)'].isnull().sum(axis = 0)  #Drop 1775, 6539","6b33e3ae":"_df2['Humidity(%)'].isnull().sum(axis = 0)   #Drop 1775, 6539","2b0df3c5":"_df2['Precipitation(in)'].isnull().sum(axis = 0)","d13a2b98":"_df2['Weather_Condition'].isnull().sum(axis = 0)   #Drop 1775","1ac4aac4":"_df2['Wind_Chill(F)'].isnull().sum(axis = 0)","543adb43":"_df2['Wind_Speed(mph)'].isnull().sum(axis = 0)","43808a23":"_df2['Visibility(mi)'].isnull().sum(axis = 0)   #Drop 1775","117bdc83":"df2_corr = _df2.corr()\ndf2_corr","ac418ee7":"fig, ax = plt.subplots(figsize=(11, 9))\nheatmap(df2_corr, cmap=\"gray\")\nplt.show()","2d7ecc28":"def imputation_Vals(X, imputed_Col_name):\n    \"\"\"This function returns the Mean, Median, and Mode\"\"\"\n    X_sort= X.sort_values('Month')\n    _X_sort= X_sort[X_sort[f\"{imputed_Col_name}\"].notna()]\n    mean_arr= []\n    median_arr= []\n    mode_arr= []\n    for i in range(12):\n        temp= _X_sort.loc[_X_sort['Month'] == (i+1)]\n        mean_ele= temp[f\"{imputed_Col_name}\"].mean()\n        mean_arr.append(mean_ele)\n        median_ele= temp[f\"{imputed_Col_name}\"].median()\n        median_arr.append(median_ele)\n        mode_ele= temp[f\"{imputed_Col_name}\"].mode()\n        mode_arr.append(mode_ele)\n    \n    return mean_arr, median_arr, mode_arr\n        ","cb0bac37":"def imputation_Imp(A, DF, imputed_Col_name):\n    \"\"\"This function applies Mean or Median or Mode to NaN values\"\"\"\n    X_sort= DF.sort_values('Month')\n    _X_sort= X_sort[X_sort[f\"{imputed_Col_name}\"].isnull()]\n    index= [1,2,3,4,5,6,7,8,9,10,11,12]\n    dict_of_arr= dict(zip(index, A))\n    _X_sort_NEW= _X_sort['Month'].map(dict_of_arr)\n    \n    return _X_sort_NEW\n","3f3db027":"_df2_Precipitation= _df2[['Month', 'Precipitation(in)']]","626f6f83":"_df2_Wind_Speed= _df2[['Month', 'Wind_Speed(mph)']]\n_df2_Wind_Speed\n","75a98021":"_df2_Chill= _df2[['Month', 'Wind_Chill(F)']]\n_df2_Chill","e9b00f59":"MEAN_pre, MEDIAN_pre, MODE_pre= imputation_Vals(_df2_Precipitation, 'Precipitation(in)')","abc5d2e4":"NEW_VALUE_pre= imputation_Imp(MEAN_pre, _df2_Precipitation, 'Precipitation(in)')","7496c2db":"_df2['Temp_col']= NEW_VALUE_pre","1f2e9ea3":"_df2[\"new_Precipitation\"] = _df2[[\"Precipitation(in)\", \"Temp_col\"]].sum(axis=1)","063d34a7":"_df2.set_index('newDate')['Precipitation(in)'].plot(figsize = (16,6))","59f3ef50":"_df2.set_index('newDate')['new_Precipitation'].plot(figsize = (16,6))","4bb87b3f":"MEAN_WS, MEDIAN_WS, MODE_WS= imputation_Vals(_df2_Wind_Speed, 'Wind_Speed(mph)')","902860e0":"NEW_VALUE_WS= imputation_Imp(MEDIAN_WS, _df2_Wind_Speed, 'Wind_Speed(mph)')","faffd39b":"_df2['Temp_col']= NEW_VALUE_WS","fb4f1764":"_df2[\"new_Wind_Speed\"] = _df2[[\"Wind_Speed(mph)\", \"Temp_col\"]].sum(axis=1)","c88677e3":"_df2.set_index('newDate')['Wind_Speed(mph)'].plot(figsize = (16,6))","02583856":"_df2.set_index('newDate')['new_Wind_Speed'].plot(figsize = (16,6))","856c9665":"MEAN_WC, MEDIAN_WC, MODE_WC= imputation_Vals(_df2_Chill, 'Wind_Chill(F)')","0ad16cfe":"NEW_VALUE_WC= imputation_Imp(MEDIAN_WC, _df2_Chill, 'Wind_Chill(F)')","799ee66b":"_df2['Temp_col']= NEW_VALUE_WC","0f16fc4a":"_df2[\"new_Wind_Chill\"] = _df2[[\"Wind_Chill(F)\", \"Temp_col\"]].sum(axis=1)","8006ba59":"_df2.set_index('newDate')['Wind_Chill(F)'].plot(figsize = (16,6))\n#Odd distribution","9449a368":"_df2.set_index('newDate')['new_Wind_Chill'].plot(figsize = (16,6))","75185d7c":"_df2= _df2.drop(columns=['Temp_col'])","a08e454b":"_df2","780ddb95":"_df['Dates']= pd.to_datetime(_df['Dates'])","b718eff0":"_df.dtypes","4b513471":"_df2.dtypes","ab439439":"_DF= _df.merge(_df2, left_on= ['Dates', 'Time_Interval'], right_on= ['newDate', 'Time_Interval'], how= 'left')","3b3ab4f5":"_DF","f82660bf":"Holiday = pd.read_csv(os.path.join('\/kaggle\/input\/dataccc\/holidays.csv'))","9c1e22cf":"df_Holiday= pd.DataFrame(Holiday)\ndf_Holiday","f8bb19fb":"df_Holiday['date']=pd.to_datetime(df_Holiday['date']).dt.date","4abaceba":"df_Holiday['date']= pd.to_datetime(df_Holiday['date'])\ndf_Holiday.dtypes","5efbd89e":"Final_DF= _DF.merge(df_Holiday, left_on= ['Dates'], right_on= ['date'], how= 'left')","f3742e52":"Final_DF","60678138":"train_df, val_df = train_test_split(Final_DF, test_size=0.2, random_state=42)","82f839ef":"X_train = train_df.drop(columns=['Severity'])","3ab63f02":"y_train = train_df['Severity']","a7cf9a0d":"X_val = val_df.drop(columns=['Severity'])","bf1cb174":"y_val = val_df['Severity']","235bf7dc":"X_train = X_train[['Lat', 'Lng', 'Distance(mi)']]\nX_val = X_val[['Lat', 'Lng', 'Distance(mi)']]","19da760c":"classifier = RandomForestClassifier(max_depth=2, random_state=0)","c196e331":"classifier = classifier.fit(X_train, y_train)","5c1c5621":"classifier.score(X_val, y_val)","49cab74b":"test_df = pd.read_csv(os.path.join(dataset_path, 'test.csv'))","58aea0dd":"X_test = test_df.drop(columns=['ID'])\n\n# You should update\/remove the next line once you change the features used for training\nX_test = X_test[['Lat', 'Lng', 'Distance(mi)']]\n\ny_test_predicted = classifier.predict(X_test)\n\ntest_df['Severity'] = y_test_predicted","a86a6289":"test_df[['ID', 'Severity']].to_csv('\/kaggle\/working\/submission.csv', index=False)","0909abab":"Final_DF","5486d635":"The remaining steps is to submit the generated file and are as follows. \n\n1. Press `Save Version` on the upper right corner of this notebook.\n2. Write a `Version Name` of your choice and choose `Save & Run All (Commit)` then click `Save`.\n3. Wait for the saved notebook to finish running the go to the saved notebook.\n4. Scroll down until you see the output files then select the `submission.csv` file and click `Submit`.\n\nNow your submission will be evaluated and your score will be updated on the leaderboard! CONGRATULATIONS!!","8ec38cb5":"Now we're ready to generate the submission file. The submission file needs the columns `ID` and `Severity` only.","fcebf69f":"Now let's test our classifier on the validation dataset and see the accuracy.","e0c540d5":"## Data Splitting\n\nNow it's time to split the dataset for the training step. Typically the dataset is split into 3 subsets, namely, the training, validation and test sets. In our case, the test set is already predefined. So we'll split the \"training\" set into training and validation sets with 0.8:0.2 ratio. \n\n*Note: a good way to generate reproducible results is to set the seed to the algorithms that depends on randomization. This is done with the argument `random_state` in the following command* ","bea67302":"## You're here! \nWelcome to your first competition in the [ITI's AI Pro training program](https:\/\/ai.iti.gov.eg\/epita\/ai-engineer\/)! We hope you enjoy and learn as much as we did prepairing this competition.\n\n\n## Introduction\n\nIn the competition, it's required to predict the `Severity` of a car crash given info about the crash, e.g., location.\n\nThis is the getting started notebook. Things are kept simple so that it's easier to understand the steps and modify it.\n\nFeel free to `Fork` this notebook and share it with your modifications **OR** use it to create your submissions.\n\n### Prerequisites\nYou should know how to use python and a little bit of Machine Learning. You can apply the techniques you learned in the training program and submit the new solutions! \n\n### Checklist\nYou can participate in this competition the way you perefer. However, I recommend following these steps if this is your first time joining a competition on Kaggle.\n\n* Fork this notebook and run the cells in order.\n* Submit this solution.\n* Make changes to the data processing step as you see fit.\n* Submit the new solutions.\n\n*You can submit up to 5 submissions per day. You can select only one of the submission you make to be considered in the final ranking.*\n\n\nDon't hesitate to leave a comment or contact me if you have any question!","0100863b":"## Conclusion\n\nIn this notebook, we have demonstrated the essential steps that one should do in order to get \"slightly\" familiar with the data and the submission process. We chose not to go into details in each step to keep the welcoming notebook simple and make a room for improvement.\n\nYou're encourged to `Fork` the notebook, edit it, add your insights and use it to create your submission.","6c3e20b2":"As pointed out eariler, I'll use the numerical features to train the classifier. **However, you shouldn't use the numerical features only to make the final submission if you want to make it to the top of the leaderboard.** ","df2cffc0":"## Import the libraries\n\nWe'll use `pandas` to load and manipulate the data. Other libraries will be imported in the relevant sections.","4dd193ce":"## Exploratory Data Analysis\nIn this step, one should load the data and analyze it. However, I'll load the data and do minimal analysis. You are encouraged to do thorough analysis!\n\nLet's load the data using `pandas` and have a look at the generated `DataFrame`.","b55a39cd":"We've got 6407 examples in the dataset with 14 featues, 1 ID, and the `Severity` of the crash.\n\nBy looking at the features and a sample from the data, the features look of numerical and catogerical types. What about some descriptive statistics?","7c1cc510":"## Model Training\n\nLet's train a model with the data! We'll train a Random Forest Classifier to demonstrate the process of making submissions. ","033385aa":"## Submission File Generation\n\nWe have built a model and we'd like to submit our predictions on the test set! In order to do that, we'll load the test set, predict the class and save the submission file. \n\nFirst, we'll load the data."}}