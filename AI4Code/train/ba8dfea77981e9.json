{"cell_type":{"d71f1943":"code","f51a3681":"code","8fb84140":"code","31dc36c8":"code","8dbb528f":"code","f9ce054a":"code","bb29ff28":"code","614e0667":"code","1fa0d48b":"code","422a18f7":"code","e01a9c96":"code","eeec4bbd":"code","dca0d0cb":"code","1d857588":"code","e17f42ab":"code","8efb6353":"code","22b3b1dc":"code","ff9bf611":"code","dbb5c289":"code","4049d631":"code","dbf21348":"code","3df10464":"code","db72f2db":"code","6d476f51":"code","b92333c4":"code","1d352c42":"code","10403949":"code","303e8642":"code","8ba9680a":"code","156e7a28":"code","5504edec":"code","1ec9358f":"code","0a693bf1":"code","597b74a3":"code","c6a2c3f4":"code","63e180ff":"code","9776369d":"code","fc63ed37":"code","7808fec6":"code","c9566a3f":"code","fa889a6a":"code","f1df6461":"code","9b71bc95":"code","d94d1dad":"code","35ca36c6":"code","3125840e":"code","87cb863b":"code","1c306223":"code","9971d28c":"code","3d552896":"code","28817b04":"code","cd845cf1":"code","f0230c41":"code","48382ed0":"code","9ad15810":"code","62e08a4d":"code","70b9c6a4":"code","ecd3b111":"code","47abcaf2":"code","e389a07a":"code","d6312faa":"code","8e0c23c7":"code","3f53b13d":"code","cff25675":"code","4e0cb21d":"code","3e2f3cd0":"code","b4eccfe8":"code","3a3ccc12":"code","312e120c":"code","47dd091c":"markdown","623d53e6":"markdown","98e0c1b2":"markdown","ec5cca4c":"markdown","9c1a3b78":"markdown","2521769e":"markdown","2e555685":"markdown","d0d19ee6":"markdown","6fe7e201":"markdown","0e51224e":"markdown","9a7e29b0":"markdown"},"source":{"d71f1943":"# notebook settings\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n%config InlineBackend.figure_format = 'retina'","f51a3681":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n","8fb84140":"meta = pd.read_csv('\/kaggle\/input\/data\/metatable_with_viral_status.csv', delimiter=',', index_col=0)\nexpr = pd.read_csv('\/kaggle\/input\/data\/swab_gene_counts.csv', delimiter=',', index_col=0)\nexpr_name = pd.read_csv('\/kaggle\/input\/annotation\/gene2name.txt', \n                        delimiter='\\t', \n                        index_col=0, \n                        names=['gene_id', 'gene_name', 'val'])","31dc36c8":"# rename\nnames = dict(zip(expr_name.index, expr_name['gene_name']))\n# transpose, reorder, and rename\nexprT = expr.T.loc[meta.index,:].rename(columns=names)\nexprT.dataframeName = 'swab_gene_counts.csv'\nexprT.head()","8dbb528f":"!head \/kaggle\/input\/results\/deconvolution\/CIBERSORTx_Results_Krasnow_facs_droplet.csv","f9ce054a":"# theres more data!\n# differntial expression analysis results\ndea = pd.read_csv(\"\/kaggle\/input\/results\/DE\/3way_diff_expr_and_regression.csv\", delimiter=\",\", index_col=0)\ndea.head()","bb29ff28":"# get viral calls data\nviral = pd.read_csv(\"\/kaggle\/input\/results\/viral_calls\/viruses_with_pval.csv\", delimiter=\",\", index_col=0)\nviral.head(100)","614e0667":"# but what is \"sample_name\"?\nviral.shape\n# there are many more than number of patients, so probably > 1 sample per patient\nviral.index.nunique()\n# still more than per patient, but I think that some of the samples are controls\n# where do we get the mapping of sample_name -> patient Id?\nmeta_viral = pd.read_csv(\"\/kaggle\/input\/data\/viral_calls\/sample_overviews.csv\", index_col=0)\nmeta_viral.head()","1fa0d48b":"meta_viral.columns\n# i'm seeing a pattern with the sample_name column, I think we care more about the viral calls dataset because the meta_viral is\n# actually the raw data metadata","422a18f7":"# lets parse the sample_name column of `viral`\n# what do you think each of these fields represents\nsample_names = viral.reset_index()['sample_name'].str.split(\"_\", expand=True)\nsample_names.head()\nsample_names[0].unique()","e01a9c96":"# what do the patient IDs look like again?\npatient_ids = meta.reset_index()['CZB_ID'].str.split(\"_\", expand=True)\npatient_ids.head()\npatient_ids[0].unique()","eeec4bbd":"# it looks like 'RR' is probably a control for the assay instead of a patient\n# lets check some of the sample_name rows not starting with 'RR'\nsample_names[sample_names[0] != 'RR']","dca0d0cb":"# wow! I just went back to look at the data and I missed a very important file!\nsample_map = pd.read_csv(\"\/kaggle\/input\/data\/viral_calls\/ngs_samples.csv\", index_col=0)\nsample_map.head()\nsample_map.nunique()\n# lets check if all patient IDs are in this mapping file\n# What does this code do?\nset(meta.index).issubset(set(sample_map['CZB_ID']))","1d857588":"# lets get all of the samples we care by joining tables\n# join is very power operation and used all of the time\n# read the documentation to become familiar with the different join \"types\"\nviral_patients = viral.join(sample_map, how='inner')\nviral_patients.head()\nviral_patients['CZB_ID'].nunique()","e17f42ab":"# check meta samples\nmeta.index.nunique()\n# hmm it looks like there are 2 fewer samples after the merge than in the metadata\n# lets check which ids in our viral_partiens ID list are NOT in the meta ID list\nmeta[~meta.index.isin(viral_patients['CZB_ID'])].index\n# interesting there is actually a discrepancy of 5 samples\n# I believe there are 241 unique patients, but only 236 had viral samples\n# this is a discrepancy we should investigate further, but we can come back to\n# it since we can continue on the analysis with the majority of patients","8efb6353":"# same thing for the expression dataset\nexprT[~exprT.index.isin(viral_patients['CZB_ID'])].index","22b3b1dc":"# lets create a table that is patients X virus, p-value in cells\n# What is nt_ and nr_?\nwith pd.option_context('display.max_rows', 10, 'display.max_columns', None): \n    viral_patients.head(10)","ff9bf611":"# first how many unique viruses are actually present?\nviral_patients['name'].value_counts()\nviral_patients['category'].value_counts()","dbb5c289":"# now lets create that dataframe\nvp_pivot = viral_patients.pivot_table(values='nt_rpm', index='CZB_ID', columns='name', fill_value=0.)\nvp_pivot.head(20)","4049d631":"vp_pivot.shape","dbf21348":"#simplify meta and viral_patients tables\nviral_patients_d=viral_patients.loc[:, ['name','CZB_ID', 'p_val', 'nt_rpm']].dropna()\nviral_patients_d\nmeta_d=meta.loc[:,['SC2_rpm','viral_status']]\nmeta_d","3df10464":"#combine meta_d and viral_patients_d\nmeta_virus=viral_patients_d.copy()\nrpms=[]\nstatuses=[]\ncount=0\nfor i in meta_virus.index:\n    id=meta_virus.loc[i, \"CZB_ID\"]\n    if type(id) == pd.Series:\n        id=id[0]\n    if id not in meta_d.index:\n        rpms.append('none')\n        statuses.append('none')\n    else:\n        rpms.append(meta_d.loc[id, 'SC2_rpm'])\n        statuses.append(meta_d.loc[id, 'viral_status'])\nmeta_virus['SC2_rpm']=rpms\nmeta_virus['viral_status']=statuses\nmeta_virus=meta_virus[meta_virus['viral_status']=='SC2']\nmeta_virus=meta_virus[meta_virus['p_val']<0.05]\nmeta_virus=meta_virus.drop(columns=['viral_status'])\nmeta_virus = meta_virus[['name', 'CZB_ID', 'SC2_rpm', 'nt_rpm', 'p_val']]\nmeta_virus = meta_virus.drop(index=[\"RR057e_00154_G18_S279\",\"RR057e_00723_D06_S84\"]) #2 samples with one coinfection but low sc2 pval\nmeta_virus","db72f2db":"#mark coinfection status of each sample\ncounts=meta_virus.index.value_counts()\ncoinfection_ids=[]\nno_coinfection_ids=[]\nfor c in counts.index:\n    if counts[c] == 1:\n        no_coinfection_ids.append(c)\n    else:\n        coinfection_ids.append(c)\n        \nmeta_virus['coinfection']=[False]*len(meta_virus.index)\nfor i in meta_virus.index:\n    if i in coinfection_ids:\n        meta_virus.loc[i, 'coinfection']=True\nmeta_virus\nmeta_virus['coinfection'].value_counts()\n","6d476f51":"#separate coinfection and no_coinfection samples\ncoinfection=meta_virus[meta_virus.index.isin(coinfection_ids)]\nno_coinfection=meta_virus[meta_virus.index.isin(no_coinfection_ids)]\n\ncoinfection\nno_coinfection","b92333c4":"#coinfection count bar plot\nnames = ['coinfected','non coinfected']\nvalues = [337, 113]\nplt.figure(figsize=(6, 5))\nplt.bar(range(len(names)),values,tick_label=names)\nplt.ylabel(\"count\")\nplt.show()","1d352c42":"#gets only unique samples in the data\ndef drop_duplicates(data):\n    indexes_nums=[]\n    indexes=[]\n    for i in range(len(data.index)):\n        if data.index[i] not in indexes_nums:\n            indexes.append(i)\n            indexes_nums.append(data.index[i])\n    return data.iloc[indexes,:]","10403949":"#drop duplicates off coinfection samples\n#disregarding each virus's p_val and nt_rpm, only sc2_rpm matters here\ncoinf_unique_samples=drop_duplicates(coinfection)\ncoinf_unique_samples","303e8642":"#sc2 rpm in sc2+ coinfected patients\nplt.figure(figsize=(8, 3))\na=sns.stripplot(x=coinf_unique_samples['SC2_rpm'], color='black', size=4)\n# sns.boxplot(x=coinf_unique_samples['SC2_rpm'], color='skyblue')\nplt.xlabel(\"sc2_rpm\")\nplt.title(\"sc2 rpm values in coinfected sc2+ patients\")\nplt.show()","8ba9680a":"#all unique sc2+ patients, sc2_rpm log reduced\nsc2_rpm_log=np.log1p(meta_virus['SC2_rpm'].tolist())\nmeta_virus_log=meta_virus.copy()\nmeta_virus_log['SC2_rpm']=sc2_rpm_log\nmeta_virus_log=drop_duplicates(meta_virus_log)\nmeta_virus_log","156e7a28":"#box plots of sc2 rpm values in sc2+ patients, separated by coinfection\nsns.set(style=\"whitegrid\")\nax=sns.boxplot(x='coinfection', y='SC2_rpm', data=meta_virus_log, palette=sns.color_palette([\"paleturquoise\", \"sandybrown\"]))\nsns.stripplot(x='coinfection', y='SC2_rpm', data=meta_virus_log, color='black', size=4)\nax.set_title(\"SC2 rpm values in SC2+ patients (log reduction)\")\nax.set(yticklabels=['a','10\u2070','10\u00b2','10\u2074','10\u2076','10\u2078','10\u00b9\u2070','10\u00b9\u00b2','10\u00b9\u2074'])","5504edec":"#table comparing mean and median sc2_rpm in coinfected and noncoinfected\nmean_med=pd.DataFrame(index=['coinfected patients', 'noncoinfected patients'])\nmean_med['mean sc2 rpm']=[coinfection['SC2_rpm'].mean(),no_coinfection['SC2_rpm'].mean()]\nmean_med['median sc2 rpm']=[coinfection['SC2_rpm'].median(), no_coinfection['SC2_rpm'].median()]\nmean_med","1ec9358f":"#list of top coinfection viruses\ncoinfection_viruses=coinfection['name'].value_counts()\nfor i in coinfection_viruses.iteritems():\n    if i[1] <3:\n        coinfection_viruses=coinfection_viruses.drop([i[0]]) #only keeping frequency > 2 bc too much data\n# coinfection_viruses=coinfection_viruses.drop(['Wuhan seafood market pneumonia virus'])\nlen(coinfection_viruses)\ncoinfection_viruses","0a693bf1":"#bar plot of top coinfection viruses\ncoinfection_viruses_r = coinfection_viruses.sort_values()\nnames = list(coinfection_viruses_r.index)\nvalues = list(coinfection_viruses_r.values)\nplt.figure(figsize=(6, 5))\nplt.barh(range(len(coinfection_viruses_r)),values,tick_label=names)\nplt.xlabel(\"frequency\")\nplt.title(\"top viruses in coinfected sc2+ patients\")\nplt.show()","597b74a3":"def get_avg(data, name_col, count_col, value_counts):\n    sums=dict()\n    for i in data.index.unique():\n        names=data.loc[i, name_col]\n        counts=data.loc[i, count_col]\n        for j in range(len(counts)):\n            name=names[j]\n            count=counts[j]\n            if name in value_counts:\n                if name in sums:\n                    sums[name]+=count\n                else:\n                    sums[name]=count\n    data_avg=pd.DataFrame(index=value_counts.keys(), columns=['count','{f}_total'.format(f=count_col)])\n    data_avg['count']=value_counts.values()\n    data_avg['{f}_total'.format(f=count_col)]=sums.values()\n    data_avg['avg_{f}'.format(f=count_col)]=data_avg['{f}_total'.format(f=count_col)]\/data_avg['count']\n    return data_avg","c6a2c3f4":"#sc2_rpm average for each coinfection virus\ncoinfection_sc2_avg=get_avg(coinfection, 'name', 'SC2_rpm', coinfection_viruses.to_dict())\ncoinfection_sc2_avg","63e180ff":"#above graphed\nnames = list(coinfection_sc2_avg.index)\nvalues = list(coinfection_sc2_avg['avg_SC2_rpm'])\nplt.figure(figsize=(6, 5))\nplt.barh(range(len(coinfection_sc2_avg)),values,tick_label=names)\nplt.xlabel(\"sc2_rpm avg\")\nplt.title(\"sc2_rpm average for each coinfection virus\")\nplt.show()","9776369d":"#log reduction\nnames = list(coinfection_sc2_avg.index)\nvalues = list(coinfection_sc2_avg['avg_SC2_rpm'])\nvalues=np.log1p(values)\nplt.figure(figsize=(6, 5))\nplt.barh(range(len(coinfection_sc2_avg)),values,tick_label=names)\nplt.xlabel(\"avg_SC2_rpm\")\nplt.title(\"sc2_rpm average for each coinfection virus (after log reduction)\")\nplt.show()","fc63ed37":"#table of above, but only samples with sc2_rpm greater than 300000\ngreater_rpms=coinfection[coinfection['SC2_rpm']>300000]\ngreater_rpms","7808fec6":"#above graphed\ngreater_rpms_counts=greater_rpms['name'].value_counts().to_dict()\ngreater_rpms_sc2_avg = get_avg(greater_rpms, 'name', 'SC2_rpm', greater_rpms_counts)\ngreater_rpms_sc2_avg.head()\n#graphing\nnames = list(greater_rpms_sc2_avg.index)\nvalues = list(greater_rpms_sc2_avg['avg_SC2_rpm'])\nvalues=np.log1p(values)\nplt.figure(figsize=(6, 5))\nplt.barh(range(len(greater_rpms_sc2_avg)),values,tick_label=names)\nplt.xlabel(\"avg_SC2_rpm\")\nplt.title(\"sc2_rpm average for coinfection viruses (after log reduction)\")\nplt.show()","c9566a3f":"## PCA CODE\nfrom sklearn.decomposition import PCA","fa889a6a":"# subset to SC2+\nsc2_meta = meta[meta['viral_status']=='SC2']\nsc2_exprT = exprT[exprT.index.isin(sc2_meta.index)]\nsc2_exprT.head()\nsc2_exprT.shape","f1df6461":"# see\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html\npca = PCA(n_components=50)\nexprT_pca = pca.fit_transform(sc2_exprT)\nprint(\"Explained variance ratio: {}\".format(np.sum(pca.explained_variance_ratio_)))\nexprT_pca = pd.DataFrame(np.hstack((sc2_meta, exprT_pca)),\n                       index=sc2_meta.index,\n                       columns=np.concatenate((sc2_meta.columns, [\"PCA_{}\".format(i) for i in range(50)])))","9b71bc95":"plt.plot(np.arange(50), pca.explained_variance_ratio_)","d94d1dad":"sns.scatterplot(x=\"PCA_0\", y=\"PCA_1\", hue='SC2_rpm', style='gender', data=exprT_pca)","35ca36c6":"# lets do pca on virus data\n# see\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html\npca_virus = PCA(n_components=50)\nvp_pca = pca_virus.fit_transform(vp_pivot)\nprint(\"Explained variance ratio: {}\".format(np.sum(pca_virus.explained_variance_ratio_)))\nvp_pca = pd.DataFrame((vp_pca),\n                       index=vp_pivot.index,\n                       columns=[\"PCA_{}\".format(i) for i in range(50)])\nvp_pca = meta.join(vp_pca, how='inner')\nvp_pca.head()","3125840e":"sns.scatterplot(x='PCA_0', y='PCA_1', hue='viral_status', data=vp_pca)","87cb863b":"# That's quite intersting! Looks like 3 major clusters not perfectly separated by virus status!\n# lets separate out just the SC2+ patients and redo PCA","1c306223":"# subset\nsc2_vp = vp_pivot[vp_pivot.index.isin(sc2_meta.index)]\nsc2_vp.shape\nsc2_vp","9971d28c":"from sklearn.preprocessing import minmax_scale","3d552896":"sc2_vp_scale = pd.DataFrame(minmax_scale(sc2_vp),\n                            index=sc2_vp.index,\n                            columns=sc2_vp.columns)","28817b04":"sc2_vp_scale","cd845cf1":"pca_sc2_virus = PCA(n_components=50)","f0230c41":"sc2_vp_pca = pca_sc2_virus.fit_transform(sc2_vp_scale)\nprint(\"Explained variance ratio: {}\".format(np.sum(pca_sc2_virus.explained_variance_ratio_)))","48382ed0":"sc2_vp_pca = pd.DataFrame((sc2_vp_pca),\n                       index=sc2_vp.index,\n                       columns=[\"PCA_{}\".format(i) for i in range(50)])\nsc2_vp_pca = sc2_meta.join(sc2_vp_pca, how='inner')\nsc2_vp_pca.head()","9ad15810":"plt.plot(np.arange(50), pca_sc2_virus.explained_variance_ratio_)","62e08a4d":"sns.scatterplot(x='PCA_0', y='PCA_1', hue='SC2_rpm', data=sc2_vp_pca)\n# very cool, so what is driving this separation of groups? how do we discover that?\n# visually it looks like one cluster has higher viral load","70b9c6a4":"vp_pivot.columns","ecd3b111":"# lets try combining the viral data with the expression data and redo the PCA analysis\nsc2_all = sc2_exprT.join(sc2_vp, how='inner')\nsc2_all.shape\nsc2_all.head()","47abcaf2":"# at this point we have redone the same pca pipeline several times - we should make a function to do this for us\ndef run_pca(data, meta, n_components=50):\n    pca = PCA(n_components=n_components)\n    data_pca = pca.fit_transform(data)\n    print(\"Explained variance ratio: {}\".format(np.sum(pca.explained_variance_ratio_)))\n    # create dataframe\n    data_pca = pd.DataFrame((data_pca),\n                             index=data.index,\n                             columns=[\"PCA_{}\".format(i) for i in range(n_components)])\n    # join with metadata\n    joined = meta.join(data_pca, how='inner')\n    return joined, joined.drop(columns=meta.columns)","e389a07a":"sc2_all_meta_pca, sc2_all_pca = run_pca(sc2_all, sc2_meta)","d6312faa":"sc2_all_pca","8e0c23c7":"sns.scatterplot(x='PCA_0', y='PCA_1', hue='SC2_rpm', data=sc2_all_meta_pca)\n# not clear with 2 dimensions, maybe transcriptomic data adds too much noise","3f53b13d":"sns.scatterplot(x='PCA_0', y='PCA_1', hue='sequencing_batch', data=sc2_all_meta_pca)","cff25675":"from sklearn.cluster import KMeans","4e0cb21d":"sc2_vp_meta_pca, sc2_vp_pca_ = run_pca(sc2_vp, sc2_meta, n_components=50)","3e2f3cd0":"sc2_vp_meta_pca","b4eccfe8":"sc2_vp_pca","3a3ccc12":"kmeans = KMeans(n_clusters=2, random_state=0).fit_predict(sc2_vp_pca)","312e120c":"sc2_vp_meta_pca['cluster'] = kmeans\nsns.scatterplot(x='PCA_0', y='PCA_1', hue='cluster', data=sc2_vp_meta_pca)","47dd091c":"### Imports","623d53e6":"### Read data","98e0c1b2":"### Analyzed data","ec5cca4c":"## top coinfection viruses","9c1a3b78":"### Clustering\nWe could use several different algorithms here -","2521769e":"### sc2_rpm average for each coinfection virus","2e555685":"## coinfection","d0d19ee6":"\n## sc2 rpm","6fe7e201":"## Dim Reduction","0e51224e":"Which column from the virus names represents SC2?","9a7e29b0":"What are the viral_call statistics for patients labeled as \"no_virus\"?"}}