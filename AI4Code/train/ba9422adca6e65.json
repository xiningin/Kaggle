{"cell_type":{"042ed592":"code","19b29af2":"code","57be4d30":"code","2652107b":"code","54162e66":"code","0ef3e083":"code","4f44ad50":"code","2346eb90":"code","12ac7279":"code","1e6967f5":"code","9e645753":"code","c4fae11b":"code","562cfbfe":"markdown","03619ac5":"markdown","832e5489":"markdown","53417ff9":"markdown","c18b9a84":"markdown","246614cb":"markdown","fe9a7a61":"markdown","6f5b48de":"markdown","7eec2347":"markdown","412a36f3":"markdown","b7583b8b":"markdown","352ba286":"markdown","b2c128bb":"markdown","4cd4cb2b":"markdown","e79c91e6":"markdown","45d0ab77":"markdown"},"source":{"042ed592":"from tensorflow import keras\nfrom tensorflow import keras\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom matplotlib import pyplot\nfrom keras import datasets\n\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nimport numpy as np\nfrom keras.utils.np_utils import to_categorical\nimport matplotlib.pyplot as plt","19b29af2":"#import data\n(train_images,train_labels),(test_images,test_labels) = keras.datasets.cifar10.load_data()","57be4d30":"print(\"Training Images Shape (x train shape) :\", train_images.shape)\nprint(\"Label of training images (y train shape) :\",train_labels.shape)\nprint(\"Test Images Shape (x test shape) :\",test_images.shape)\nprint(\"Label of test images (y test shape) :\",test_labels.shape)","2652107b":"# plot first few images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# plot raw pixel data\n\tpyplot.imshow(train_images[i])\n# show the figure\npyplot.show()","54162e66":"train_images, test_images = train_images \/ 255, test_images \/ 255","0ef3e083":"from keras.applications.mobilenet_v2 import MobileNetV2\nIMG_SHAPE = (32, 32, 3)\n# Pre-trained model with MobileNetV2\nbase_model = MobileNetV2(\n    input_shape=IMG_SHAPE,\n    include_top=False,\n    weights='imagenet'\n)\n# Freeze the pre-trained model weights\nbase_model.trainable = True\n\nfor layer in base_model.layers[:100]:\n  layer.trainable =  False\n  \n  \n\n# Trainable classification head\nmaxpool_layer = GlobalMaxPooling2D()\nprediction_layer = Dense(units=10, activation='softmax')\n# Layer classification head with feature detector\nmodel = Sequential([\n    base_model,\n    maxpool_layer,\n    prediction_layer\n])\nnum_epochs = 10\nfine_tune_epochs = 30\ntotal_epochs =  num_epochs + fine_tune_epochs\n\n","4f44ad50":"model.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=\"Adam\", metrics=[\"sparse_categorical_accuracy\"])","2346eb90":"#Fit the model\nhist= model.fit(train_images, train_labels, epochs=20)\n","12ac7279":"prediction = model.predict(test_images)\nprediction","1e6967f5":"prediction.shape","9e645753":"\nhistory_dict = hist.history\nprint(history_dict.keys())","c4fae11b":"plt.figure(figsize=(6,6))\nplt.plot(hist.history['loss'], color='b', label=\"Training loss\")\nplt.legend()\nplt.show()\n\nplt.figure()\n\nplt.figure(figsize=(6,6))\nplt.plot(hist.history['sparse_categorical_accuracy'], color='b', label=\"Training accuracy\")\nplt.legend(loc = \"lower right\")\nplt.show()","562cfbfe":"<a id='8'><\/a><br>\n# 8. Evaluation of the Model","03619ac5":"\nThe dataset consists of images of the following types of objects. Each class in the dataset contains an equal number of 6000 images.\n\n- airplane\n- automobile\n- bird\n- cat\n- deer\n- dog\n- frog\n- horse\n- ship\n- truck","832e5489":"<a id='3'><\/a><br>\n# 3. Data Visualization","53417ff9":"<a id='2'><\/a><br>\n# 2. Variable Description","c18b9a84":"The CIFAR-10 dataset contains 60,000 color images of 10 classes and 32 x 32 pixels in 3 channels. The training set contains 50,000 images while the test sets contain 10,000 images","246614cb":"<a id='7'><\/a><br>\n# 7. Train the Data","fe9a7a61":"<a id='6'><\/a><br>\n# 6. Defining Optimizer and Loss Function\n","6f5b48de":"<a id='1'><\/a><br>\n# 1. Load and Check Data","7eec2347":"**Thanks for the reading this document. Feel free to ask questions or give comments. Don't forget to give a star if you found it useful. See you :)**","412a36f3":"<a id='4'><\/a><br>\n# 4. Data Normalization","b7583b8b":"# CIFAR-10 Object Classification with MobileNetV2\n","352ba286":"If the class variable was one hot encoded, categorical cross entropy could be used. But we use sparse categorical cross entropy because the y's, that is, the labels of the picture, consist of integer numbers.","b2c128bb":"Grayscale and color image pixel data are both stored as unsigned integer values with values ranging from 0 to 255. The image data must be rescaled before modelling, for example, by normalization to the range 0-1.","4cd4cb2b":"MobileNet is a small but efficient deep learning architecture with fewer training parameters. **MobileNet uses Depthwise Separable Convolutions**, which we encounter in the XCeption architecture, instead of the standard convolutional operation during feature extraction with convolutional filters. Thanks to this technique, feature extraction can be done with much less parameters than the standard convolution process.\n\nAt the same time, it provides faster calculation capability thanks to the skip connection feature in ResNet architectures.","e79c91e6":"# Introduction\nThe CIFAR-10 dataset consists of 10 different types of images. The goal is to recognize previously unseen images and assign them to one of 10 classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. \n\n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n3. [Data Visualization](#3)\n4. [Data Normalization](#4)\n5. [CNN Model Generation](#5)\n6. [Defining Optimizer and Loss Function](#6)\n7. [Train the Data](#7)\n8. [Evaluation of the Model](#8)\n","45d0ab77":"<a id='5'><\/a><br>\n# 5. CNN Model Generation"}}