{"cell_type":{"e75eed34":"code","05b63cc3":"code","428ddce1":"code","f6364446":"code","c76af403":"code","4c693cc9":"code","30fefa0a":"code","ce97fd23":"code","a3396028":"code","2891676f":"code","8d77e629":"code","7fbc68bb":"code","c19e6a63":"code","e6b6423b":"code","13f5bb93":"code","98a6dee0":"code","e3924c40":"code","9b7b2b89":"code","dcb77026":"code","5f6c31e1":"code","c38d29ae":"code","db476856":"code","1682dc62":"markdown","c0691e91":"markdown","805fcac3":"markdown","4246cbf9":"markdown","7398a41a":"markdown","defab168":"markdown","a6c3e022":"markdown","b257c8a6":"markdown","200c3a0f":"markdown","9fce856d":"markdown","c5790a66":"markdown","ef0ca3ed":"markdown","074876a2":"markdown","dca840e2":"markdown"},"source":{"e75eed34":"!pip install git+https:\/\/github.com\/AutoViML\/Auto_TS.git","05b63cc3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","428ddce1":"# import related libraries\n\n# dates\nfrom pandas import datetime\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns # advanced vizs\n%matplotlib inline\n\n# statistics\nfrom statsmodels.distributions.empirical_distribution import ECDF\n\n# time series analysis\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\npd.set_option(\"display.max_rows\", 20)\n\n# prophet by Facebook\nfrom fbprophet import Prophet","f6364446":"# Import data\ntrain_data_csv = \"..\/input\/train.csv\"\ntest_data_csv = \"..\/input\/test.csv\"\nsample_submission_csv = \"..\/input\/sample_submission.csv\"\n\ntrain = pd.read_csv(train_data_csv, parse_dates = True,\n                    low_memory = False, index_col = 'date')\ntest = pd.read_csv(test_data_csv, parse_dates = True,\n                   low_memory = False, index_col = 'date')\nsubmission = pd.read_csv(sample_submission_csv)\nprint(\"Check imported data\")\nprint()\nprint(\"In total:\")\nprint(\"train.shape {} \".format(train.shape))\nprint(\"test.shape {} \".format(test.shape))\nprint(\"submission.shape {} \".format(submission.shape))\nprint()\nprint(\"train.columns {} \".format(train.columns))\nprint(\"test.colmuns {} \".format(test.columns))\nprint(\"submission.colmuns {} \".format(submission.columns))\nprint()\nprint(\"train.index {} \".format(train.index))\nprint(\"test.index {} \".format(test.index))\nprint(\"submission.index {} \".format(submission.index))","c76af403":"train.head()","4c693cc9":"# rows which contains NA column\nprint(train[train.isna().any(axis=1)].shape)\n# rows which contains NA column\nprint(test[test.isna().any(axis=1)].shape)","30fefa0a":"sns.set(style = \"ticks\")# to format into seaborn \nc = '#386B7F' # basic color for plots\nplt.figure(figsize = (12, 13))\n\nplt.subplot(311)\ncdf = ECDF(train['store'])\nplt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\nplt.xlabel('store'); plt.ylabel('ECDF');\n\nplt.subplot(312)\ncdf = ECDF(train['item'])\nplt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\nplt.xlabel('item'); plt.ylabel('ECDF');\n\nplt.subplot(313)\ncdf = ECDF(train['sales'])\nplt.plot(cdf.x, cdf.y, label = \"statmodels\", color = c);\nplt.xlabel('sales'); plt.ylabel('ECDF');\n\n","ce97fd23":"#!pip install auto-ts","a3396028":"train_X = train.copy(deep=True)\ndel train_X['sales']\ntrain_y = train['sales']","2891676f":"trainx = train.reset_index()\ntrainx.head()","8d77e629":"test_X = test.copy(deep=True)\ndel test_X['id']\ntest_X.columns","7fbc68bb":"testx = test.drop('id',axis=1)\ntestx = testx.reset_index()\ntestx.head()","c19e6a63":"from sklearn.ensemble import GradientBoostingRegressor\n\nclf = GradientBoostingRegressor(n_estimators=100, learning_rate=0.25,\n        max_depth=1)\nclf.fit(train_X, train_y)","e6b6423b":"pred_y = clf.predict(test_X)\nprint (\"Predict \",pred_y)","13f5bb93":"from auto_ts import auto_timeseries","98a6dee0":"model = auto_timeseries(score_type='rmse',forecast_period=100,\n                time_interval='D',\n                non_seasonal_pdq=None, seasonality=False, seasonal_period=1,\n                model_type=['ML'],\n                verbose=2)","e3924c40":"ts_column = 'date'\ntarget = 'sales'","9b7b2b89":"model.fit(train, ts_column,target)","dcb77026":"predictions = model.predict(\n            testdata=testx,\n            model='ML',\n        )","5f6c31e1":"pred_x = predictions['yhat'].values\npred_x","c38d29ae":"out_df = pd.DataFrame({'id': test['id'].astype(np.int32), 'sales': pred_x})\nout_df.to_csv('submission.csv', index=False)","db476856":"# Write submission file\nout_df = pd.DataFrame({'id': test['id'].astype(np.int32), 'sales': pred_y})\nout_df.to_csv('submissiony.csv', index=False)","1682dc62":"## First impression of result of EDA\n- There are 10 different stores and 50 different items. Thus we have to predict 500 different value for same day. There is two approaches. One way is generate 500 different model to predict 500 different sales values. Another way is generate only one model to predict 500 different sales values.\n\n## Gradient Boosting Decision Tree(GBDT)\n- This is good baseline model in competition.\n- Fortunately Desision-Tree type model can  handle such kind of data.\n- However decision tree does not compute any regression coefficients like linear regression, so trend modeling is not possible. Thus it is necessary to detrend time series. (Below, detrending is not yet applied)\n","c0691e91":"# Exploratory Data Analysis (Data understanding)\n\n- Quick viewing of given raw data before importing\n- First glance at given data set\n - Check shape of data, columns, index\n - Viewing raw data\n - Check NaN\n - Check describe\n- Pivotal analysis\n- Check ECDF: empirical cumulative distribution function\n- Check Histgram\n- Check trend\n- Check timeseries plot\n- Conclusion of EDA","805fcac3":"# Demand prediction for multi-store and multi-item\n\nThis kernel is for Kaggle's Store Item Demand Forecasting Challenge\n\n## Data Description\nThe objective of this competition is to predict 3 months of item-level sales data at different store locations.\n\nFile descriptions\n\n* train.csv - Training data\n* test.csv - Test data (Note: the Public\/Private split is time based)\n* sample_submission.csv - a sample submission file in the correct format\n\nData fields\n\n* date - Date of the sale data. There are no holiday effects or store closures.\n* store - Store ID\n* item - Item ID\n* sales - Number of items sold at a particular store on a particular date.","4246cbf9":"# This notebook is derived from this notebook\nhttps:\/\/www.kaggle.com\/istnnrhk\/demand-prediction-for-multi-store-and-multi-item\n\nMany thanks to istnnrhk! Please upvote that notebook if you liked this notebook!","7398a41a":"### result of quick viewing\n- Data have header\n- train.csv has three columns\n- test.csv data has three columns, but has ID column instead of sales\n- sample_submission.csv has two columns. it's id and sales.\n- Number of rows of test.csv and number of rows of sample_submission.csv are same. \n- Maybe, test.csv is test_X, and sample_submission.sales is test_y.\n- training period : 2013-01-01 to 2017-12-31 (5 years)\n- test period : 2018-01-01 to 2018-03-31 (3 month)","defab168":"### Let's compare Auto_TS to a simple GBT Model","a6c3e022":"### Check NaN","b257c8a6":"# Modeling approach (comparing GBT vs Auto_TS)","200c3a0f":"References:\n- https:\/\/www.kaggle.com\/elenapetrova\/time-series-analysis-and-forecasts-with-prophet\n- https:\/\/petolau.github.io\/Regression-trees-for-forecasting-time-series-in-R\/\n","9fce856d":"# First glance at given data set\nIn this section we go through given data, handle missing values","c5790a66":"## ECDF: empirical cumulative distribution function","ef0ca3ed":"### Viewing raw data\nIt is important.","074876a2":"## Quick viewing of given raw data before importing","dca840e2":"## Conclusion of EDA\n\n- 10 different stores and 50 different items\n- Training period : 2013-01-01 to 2017-12-31\n- Test period: 2018-01-01 to 2018-03-31\n- No missing data\n- Given data (stores sales data and items sales data) are stacked into one column\n- sales data is increasing year by year\n- Monday is lowest sales day. Sunday is highest sales day.\n- Most store's sales is increasing\n- Most item's sales is increasing\n- Sales of month end is larger than other days\n- Sales in summer is larger than other seasons"}}