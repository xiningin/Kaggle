{"cell_type":{"b5bfa9d1":"code","d4f52214":"code","ca328fb2":"code","f0e4147c":"code","fef72e51":"code","2352b149":"code","1aa80f42":"code","4ca0870b":"code","11c654d6":"code","5aaa5bce":"code","e38955fe":"code","570a07b5":"code","2b20194c":"code","a8c55862":"code","3de351db":"code","baa66dae":"code","f3d9b771":"code","70656543":"code","9ded2be2":"code","85b0f285":"code","4c47bcfd":"code","d4b20c2b":"code","b0a6cedc":"code","e1434047":"code","d564eff0":"code","7ff18eea":"code","6c379b19":"code","19472065":"code","ad6cd1fa":"code","a86f01af":"code","37f426f5":"code","f2874ebf":"code","c90348ee":"code","c396df84":"markdown","b17808d4":"markdown","bf7be655":"markdown","31a72a18":"markdown"},"source":{"b5bfa9d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4f52214":"data= pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndata.head(5)","ca328fb2":"data.info()","f0e4147c":"data.describe","fef72e51":"data.shape","2352b149":"data.corr()","1aa80f42":"# Import label encoder\nfrom sklearn import preprocessing\n  \n# label_encoder object knows how to understand word labels.\nlabel_encoder = preprocessing.LabelEncoder()\n  \n# Encode labels in column 'species'.\ndata['Sex']= label_encoder.fit_transform(data['Sex'])\n  \n","4ca0870b":"data.head()","11c654d6":"data=data.drop(['Name'],axis=1)","5aaa5bce":"data=data.drop(['Ticket'],axis=1)","e38955fe":"data.info()","570a07b5":"y_train=(data['Survived'])\nX_train=(data[['PassengerId','Pclass','Sex','Age','SibSp','Parch','Fare']])\n","2b20194c":"\nX_train['Age'] = X_train['Age'].fillna(0)","a8c55862":"X_train.isnull().sum()","3de351db":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score","baa66dae":"rf=RandomForestClassifier(n_estimators=100)\nrf.fit(X_train, y_train)","f3d9b771":"col_sorted_by_importance=rf.feature_importances_.argsort()\nfeat_imp=pd.DataFrame({\n    'cols':X_train.columns[col_sorted_by_importance],\n    'imps':rf.feature_importances_[col_sorted_by_importance]\n})\n\nimport plotly_express as px\npx.bar(feat_imp, x='cols', y='imps')","70656543":"y_train=(data['Survived'])\nX_train=(data[['PassengerId','Pclass','Sex','Age','Fare']])","9ded2be2":"data1= pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndata1.head(5)","85b0f285":"data1['Sex']= label_encoder.fit_transform(data1['Sex'])","4c47bcfd":"data1.isnull().sum()\n","d4b20c2b":"mean_value=data1['Fare'].mean()","b0a6cedc":"data1['Age'] = data1['Age'].fillna(0)\ndata1['Fare'] = data1['Fare'].fillna(mean_value)","e1434047":"X_test=(data1[['PassengerId','Pclass','Sex','Age','Fare']])\n","d564eff0":"\n# First XGBoost model for Pima Indians dataset\nfrom numpy import loadtxt\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nseed = 7\ntest_size = 0.33\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=test_size, random_state=seed)\n# fit model no training data\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\n# make predictions for test data\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","7ff18eea":"\nfrom sklearn.metrics import make_scorer\nboth_scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Loss':'neg_log_loss'}\nparams = {\n        'n_estimators': [100, 200, 500, 1000, 1500],\n        'learning_rate': [0.05, 0.1, 0.2]\n        #'max_depth':[3, 4, 5]\n        }","6c379b19":"clf = GridSearchCV(model, params, cv=5, scoring=both_scoring, refit='AUC', return_train_score=True)\nclf.fit(X_train, y_train)","19472065":"print((clf.best_score_, clf.best_params_))\nprint(\"=\"*30)\n\nprint(\"Grid scores on training data:\")\nmeans = clf.cv_results_['mean_test_AUC']\nstds = clf.cv_results_['std_test_AUC']\nlog_losses = clf.cv_results_['std_test_Loss']\n\nfor mean, std, log_loss, params in zip(means, stds, log_losses, clf.cv_results_['params']):\n    print(\"AUC Score: %0.3f (+\/-%0.03f); Log Loss: %0.3f for %r\" % (mean, std * 2, log_loss, params))","ad6cd1fa":"\nresults = clf.cv_results_\n\nplt.figure(figsize=(13, 13))\nplt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\", fontsize=16)\n\nplt.xlabel(\"n_estimators: no of boosted trees\")\nplt.ylabel(\"AUC Score\")\n\nax = plt.gca()\nax.set_xlim(80, 1020)\nax.set_ylim(0.7, 1)\n\nX_axis = np.array(results['param_n_estimators'].data, dtype=float)\n\nfor scorer, color in zip(sorted(both_scoring), ['g', 'k']):\n    for sample, style in (('train', '--'), ('test', '-')):\n        sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n                        sample_score_mean + sample_score_std,\n                        alpha=0.1 if sample == 'test' else 0, color=color)\n        ax.plot(X_axis, sample_score_mean, style, color=color,\n                alpha=1 if sample == 'test' else 0.7,\n                label=\"%s (%s)\" % (scorer, sample))\n\n    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n    best_score = results['mean_test_%s' % scorer][best_index]\n\n    # Plot a dotted vertical line at the best score for that scorer marked by x\n    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n\n    # Annotate the best score for that scorer\n    ax.annotate(\"%0.2f\" % best_score,\n                (X_axis[best_index], best_score + 0.005))\n    ","a86f01af":"predictions = clf.predict(X_train).astype(int)\n\nsubmission = pd.DataFrame({'PassengerId':X_train['PassengerId'], 'Survived':predictions})","37f426f5":"# Fill submission csv file\nfilename = 'submit.csv'\nsubmission.to_csv(filename,index=False)","f2874ebf":"df= pd.read_csv('.\/submit.csv')\ndf.head(5)","c90348ee":"df1= pd.read_csv('..\/input\/titanic\/gender_submission.csv')\ndf.head(5)","c396df84":"FEATURE IMPORTANCE BASED ON RANDOM FOREST CLASSIFIER","b17808d4":"DATA PREPROCESSING","bf7be655":"Selecting the features above importance score of 0.05","31a72a18":"MODEL BUILDING "}}