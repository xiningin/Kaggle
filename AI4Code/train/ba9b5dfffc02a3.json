{"cell_type":{"05f93f32":"code","01a06c39":"code","6a55e349":"code","4612a0b1":"code","46670c58":"code","82aad95e":"code","4429eace":"code","c28f5954":"code","570058ca":"code","8d3c0492":"code","1fd9e584":"code","5a859d5f":"code","07ee0a58":"code","52873e3c":"code","82270ba0":"code","ea3d4712":"code","a4fc71b9":"code","546ccace":"code","d83eb9b8":"code","4f8a53d1":"code","71c7bd73":"code","8a66a0fc":"code","68e1a7c8":"code","a700ff2d":"code","bf43f681":"code","54b7d729":"code","11e743b8":"code","a0148e97":"code","9d9fa691":"code","af47c71a":"code","912d549d":"code","ca708d46":"code","488202ca":"code","3624d6e0":"code","07409110":"code","851d5236":"code","25abba87":"code","6b5fd67b":"code","59da245f":"code","c99cb90b":"code","943d5de7":"code","05576c5f":"code","c5523469":"code","9b14bcc1":"code","67f6c531":"code","0a689355":"code","6cd1ae7c":"code","e61edd52":"code","ee424c2a":"code","4167b305":"code","f0548b7e":"code","f9301272":"code","e22b8219":"code","f3eac993":"code","447f3670":"code","1f3c2bea":"code","84791aaa":"code","ed2c3551":"code","692899a3":"code","b3cadd01":"markdown","a75ef30c":"markdown","56cf2e68":"markdown","65ad9c62":"markdown","ce925868":"markdown","86fef661":"markdown","5d3127ea":"markdown","3aa57ff3":"markdown","fdbcfed5":"markdown","807007ee":"markdown","c4e2e95f":"markdown","99e52975":"markdown","6ac08ee9":"markdown","68c12f53":"markdown","140bc397":"markdown","5ffff61f":"markdown","435471ad":"markdown","1fae6e4d":"markdown","76c42f67":"markdown","0bd67373":"markdown","4cfcb011":"markdown","21575afe":"markdown","82b337c6":"markdown","101be343":"markdown","eb9b49db":"markdown","d5271bcd":"markdown","e5bab43e":"markdown","8763987f":"markdown","4d32aa85":"markdown","c1d2d808":"markdown","01071504":"markdown","5f49fc50":"markdown","fc4088fe":"markdown","90437f60":"markdown","78aedb3c":"markdown","8a198e27":"markdown","66c57ee7":"markdown"},"source":{"05f93f32":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","01a06c39":"#loading need libraries\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n%matplotlib inline","6a55e349":"## Display all the columns of the dataframe\n\npd.pandas.set_option('display.max_columns',None)","4612a0b1":"train = pd.read_csv('..\/input\/my-data\/trainhouse.csv')","46670c58":"train.shape","82aad95e":"train.head()","4429eace":"plt.figure(figsize = (12,8))\nsns.distplot(train['SalePrice'])\nmu, sigma = stats.norm.fit(train['SalePrice'])\nplt.legend([\"Normal Distribution Mean{:.2f} and Std Deviation{:.2f}\".format(mu, sigma)], loc = 'best')\nplt.show()","c28f5954":"stats.probplot(train['SalePrice'], plot = plt)","570058ca":"train['SalePrice'] = np.log1p(train['SalePrice'])","8d3c0492":"plt.figure(figsize = (12,8))\nsns.distplot(train['SalePrice'])\nmu, sigma = stats.norm.fit(train['SalePrice'])\nplt.legend([\"Normal Distribution Mean{:.2f} and Std Deviation{:.2f}\".format(mu, sigma)], loc = 'best')\nplt.show()","1fd9e584":"stats.probplot(train['SalePrice'], plot = plt)","5a859d5f":"nul = train.isnull().sum() \/ len(train)\nnul = nul[nul>0]\nnul = nul.sort_values(ascending = False)\nnul","07ee0a58":"isnull = pd.DataFrame(nul)\nisnull.rename(columns = {0 : 'Count'}, inplace = True)\ncol = isnull.index.values\ncol","52873e3c":"plt.figure(figsize = (10,6))\nsns.barplot(x = isnull.index.values, y = isnull['Count'], data = isnull)\nplt.xticks(rotation = 90)\nplt.show()","82270ba0":"train.drop('Id', axis = 1, inplace = True)","ea3d4712":"numeric = [f for f in train.columns if train[f].dtype != \"O\"]\ncategory = [f for f in train.columns if train[f].dtype == \"O\"]\nlen(numeric), len(category)","a4fc71b9":"train_num = train[numeric]","546ccace":"corr = train_num.corr()\nplt.figure(figsize = (20,10))\nsns.heatmap(corr, annot = True)","d83eb9b8":"top = corr.index[abs(corr['SalePrice'] > 0.5)]\ntop_corr = train_num[top].corr()\nplt.figure(figsize = (12,6))\nsns.heatmap(top_corr, annot = True)","4f8a53d1":"train['OverallQual'].unique()","71c7bd73":"sns.barplot(train['OverallQual'], np.log1p(train['SalePrice']))","8a66a0fc":"corr.sort_values(['SalePrice'], ascending = False, inplace = True)","68e1a7c8":"val = abs(corr.SalePrice).tail(10).index\ntrain.drop(val, axis = 1, inplace = True)\ntrain.shape","a700ff2d":"nullval = isnull.head(5).index.values\nnullval","bf43f681":"train.drop(nullval, axis = 1, inplace = True)","54b7d729":"nul = train.isnull().sum() \/ len(train)\nnul = nul[nul>0]\nnul = nul.sort_values(ascending = False)\nnul","11e743b8":"isnull = pd.DataFrame(nul)","a0148e97":"colnul = isnull.index.values\ncolnul\ncolnul1 = [f for f in colnul if train[f].dtype == 'O']\ncolnul1","9d9fa691":"for value in colnul:\n    train[value] = train[value].fillna('None')","af47c71a":"nul = train.isnull().sum() \/ len(train)\nnul = nul[nul>0]\nnul = nul.sort_values(ascending = False)\nnul","912d549d":"col = [f for f in train.columns if train[f].nunique() < 40]\ncol","ca708d46":"len(col)","488202ca":"from sklearn.preprocessing import LabelEncoder\nfor value in col:\n    lbl = LabelEncoder()\n    train[value] = lbl.fit_transform(train[value])","3624d6e0":"train.head()","07409110":"train['YearBuilt'] =  train['YearBuilt'] - train['YearBuilt'].min()\ntrain['YearRemodAdd'] =  train['YearRemodAdd'] - train['YearRemodAdd'].min()","851d5236":"train['GarageYrBlt'] = pd.to_numeric(train['GarageYrBlt'], errors = 'coerce')","25abba87":"train[train['GarageYrBlt'].isnull() == True]","6b5fd67b":"train['GarageYrBlt'] = train['GarageYrBlt'].fillna(train['GarageYrBlt'].mean())","59da245f":"train['GarageYrBlt'] =  train['GarageYrBlt'] - train['GarageYrBlt'].min()","c99cb90b":"train.head()","943d5de7":"col = [f for f in train.columns if train[f].dtype == 'O']\ncol","05576c5f":"train['LotFrontage'] = pd.to_numeric(train['LotFrontage'], errors = 'coerce')\ntrain['MasVnrArea'] = pd.to_numeric(train['MasVnrArea'], errors = 'coerce')","c5523469":"train['LotFrontage'] = train['LotFrontage'].fillna(train['LotFrontage'].mean())\ntrain['MasVnrArea'] = train['MasVnrArea'].fillna(train['MasVnrArea'].mean())","9b14bcc1":"col = [f for f in train.columns if train[f].dtype == 'O']\ncol","67f6c531":"x = train.drop('SalePrice', axis = 1)\ny = train[['SalePrice']]\n\nx.shape, y.shape","0a689355":"# Feature Scaling\n\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nx_new = scaler.fit_transform(x)\nx_new = pd.DataFrame(x_new, columns = x.columns)","6cd1ae7c":"from sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel","e61edd52":"feature = SelectFromModel(Lasso(alpha = 0.001, random_state = 0))\nfeature.fit(x_new, y)","ee424c2a":"feature.get_support()","4167b305":"selected_feat = x.columns[(feature.get_support())]\nlen(selected_feat)","f0548b7e":"x = x[selected_feat]\nx.shape, y.shape","f9301272":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","e22b8219":"class Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        \n        self.linear1 = nn.Linear(in_features = x_new.shape[1], out_features = 512)\n        self.linear2 = nn.Linear(in_features = 512, out_features = 1024)\n        self.linear3 = nn.Linear(in_features = 1024, out_features = 256)\n        self.outlayer = nn.Linear(in_features = 256, out_features = y.shape[1])\n        \n    def forward(self, x):\n        x = x\n        x = self.linear1(x)\n        x = self.linear2(x)\n        x = self.linear3(x)\n        x = self.outlayer(x)\n        \n        return x","f3eac993":"network = Network()","447f3670":"list(network.parameters())","1f3c2bea":"xtorch = torch.tensor(x_new.values, dtype = torch.float)\nytorch = torch.tensor(y.values, dtype = torch.float)\nxtorch.dtype, ytorch.dtype","84791aaa":"loss = nn.MSELoss(reduction='mean')","ed2c3551":"import torch.optim as optim\noptimizer = optim.Adam(network.parameters(), lr = 1e-3)","692899a3":"for epoch in range(1000):\n    total_error = 0\n    pred = network(xtorch)\n    criteria = loss(pred.squeeze(), ytorch.squeeze())\n    total_error = total_error + criteria\n    print(epoch, criteria.item())\n    \n    if torch.isnan(criteria):\n        break\n        \n    optimizer.zero_grad()\n    criteria.backward()\n    optimizer.step()","b3cadd01":"Lets Impute them","a75ef30c":"# Feature Selection","56cf2e68":"Separate Dependent and Independent variables","65ad9c62":"Get the instance of Above Network Class","ce925868":"# Feature Selection","86fef661":"# Important Libraries & Read data","5d3127ea":"Lets have a look at initial bias and weights value, which are assumed values by Torch Library","3aa57ff3":"Now Its Normally distributed!!","fdbcfed5":"Label Encoding, to convert Values into Numeric","807007ee":"Exploring OverallQual more, as it has 82% correlation with SalePrice","c4e2e95f":"Hurray, model is trainined and Mean Square Error is 0.019, it seems model got converge, to achieve higher accuracy we need to Tune hyperparameters","99e52975":"Impprtant Features will be marked as True","6ac08ee9":"Get back to Null Values","68c12f53":"Converting Year Columns into more meaningful numbers","140bc397":"Get Numeric and Categorical variable in Data","5ffff61f":"Lets select best 59 columns only from 64 columns\n","435471ad":"No More Null values present in data now  :)","1fae6e4d":"# Working on Dependent Variable","76c42f67":"Let's Train Model","0bd67373":"# Model Building","4cfcb011":"This is too Messy, lets explore more","21575afe":"As SalePrice (D.V.) is highly skewed, lets apply Log Transformation to get Normal Distribution","82b337c6":"Q-Q Plot","101be343":"Checking Null value","eb9b49db":"* We can do Train Test Split and Even Import test data, to submit and get rank,\n* Aim of this Notebook was to understand how Pytorch can achieve unbelievably high accuracy (Less Error)\n* That is power of Pytorch, with some hyperparameter Tuning and dataLoader we might get low loss\n* Thanks, If you find this interesing, kindly consider upvoting this notebook, Keep learning and keep growing","d5271bcd":"Lets convert into torch.tensor datatype","e5bab43e":"Droping top 5 COlumn as having Null rate more than 50%","8763987f":"Converted all columns into Numeric :)","4d32aa85":"Define Loss Function","c1d2d808":"Running for 1000 Epochs as data is too small to train Neural network","01071504":"Feature Scaling","5f49fc50":"Study distribution of dependent variable via Histogram and Q-Q Plot","fc4088fe":"Dropping loosely correlated columns","90437f60":"# Missing Values Imputation","78aedb3c":"Select Optimizer and Respective parameters","8a198e27":"Sort with Descending Values of Correlation","66c57ee7":"\n* Aim of this Notebook was to understand how Pytorch can achieve unbelievably high accuracy (Less Error)\n* That is power of Pytorch, with some hyperparameter Tuning and DataLoader we might get low loss\n* Thanks, If you find this interesing, kindly consider upvoting this notebook, Keep learning and keep growing"}}