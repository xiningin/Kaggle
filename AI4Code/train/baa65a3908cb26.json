{"cell_type":{"a1d249fb":"code","0324ced7":"code","17321516":"code","b25429d9":"code","b3b4c4cb":"code","013753e5":"code","a95868a1":"code","fcfd40da":"code","5c7c9b26":"code","5baccf1a":"code","55cb2e9c":"code","7d686b84":"code","713b30d3":"code","f695379f":"code","d3118ae6":"code","596fe396":"code","26ba7b40":"code","ba804cff":"code","f4f01db4":"code","f58671aa":"code","7ac2928e":"code","661ed7cd":"code","0b418cf1":"code","5e900777":"code","cdddad2d":"code","bc7be311":"code","4d5a6a99":"markdown","3f1afab5":"markdown","caf8dbb8":"markdown","489a952a":"markdown","aa13e97c":"markdown","357e617c":"markdown","02b67d8d":"markdown","6fbd569c":"markdown","5785d2bf":"markdown","919f4db3":"markdown","e9e4ca76":"markdown"},"source":{"a1d249fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0324ced7":"import os, glob, string\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision import transforms\n\nfrom tqdm.notebook import tqdm\nimport multiprocessing as mp\n\nimport cv2\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","17321516":"BATCH_SIZE = 16\nNUM_EPOCHS = 50\nLEARNING_RATE = 0.001\nWEIGHT_DECAY = 1e-3\nCLIP_NORM = 5\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncpu_count = mp.cpu_count()\n\nprint(f'Device: {DEVICE}')\nprint(f'cpu_count: {cpu_count}')","b25429d9":"data_path = '\/kaggle\/input\/captcha-version-2-images\/samples\/'\ncapcha_images = os.listdir(data_path)\n\nprint(f'There are total {len(capcha_images)} files in the data path')\nprint(f'Example of a capcha image filename: {capcha_images[:5]}')\n\nunique_len, _ = np.unique([len(capcha_image.split(\".\")[0]) for capcha_image in capcha_images])\nprint(f'Unique length of capcha: {unique_len}')","b3b4c4cb":"# Check for non-capcha files and remove them from the list of filenames\nfor idx, filename in enumerate(capcha_images):\n    if len(filename.split(\".\")[0]) != 5:\n        print(f'Found file \"{filename}\" at index {idx} that does not look like a valid capcha image')\n        capcha_images.remove(filename)\nprint(f'After cleaning, there are total {len(capcha_images)} files in the data path')","013753e5":"train_images, test_images = train_test_split(capcha_images, random_state=0)\nprint(f'{len(train_images)} train images, {len(test_images)} test images.')","a95868a1":"def remove_file_extension(filename):\n    return filename.split('.')[0]\n\nimages = [remove_file_extension(image) for image in capcha_images]\nimages = \"\".join(images)\nletters = sorted(list(set(list(images))))\n\nprint(f'There are {len(letters)} unique letters in the dataset: {letters}')","fcfd40da":"vocabulary = [\"-\"] + letters\nidx2char = {k:v for k,v in enumerate(vocabulary, start=0)}\nchar2idx = {v:k for k,v in idx2char.items()}\n\nprint(len(vocabulary))\nprint(idx2char)\nprint(char2idx)","5c7c9b26":"class CapchaDataset(Dataset):\n    def __init__(self, base_dir, image_filenames):\n        self.base_dir = base_dir\n        self.image_filenames = image_filenames\n        \n    def __len__(self):\n        return len(self.image_filenames)\n    \n    def __getitem__(self, index):\n        image_filename = self.image_filenames[index]\n        image_filepath = os.path.join(self.base_dir, image_filename)\n        image = Image.open(image_filepath).convert('RGB')\n        image = self.transform(image)\n        label = remove_file_extension(image_filename)\n        return (image, label)\n    \n    def transform(self, image):\n        transform_ops = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(\n                mean=(0.485, 0.456, 0.406),\n                std=(0.229, 0.224, 0.225)\n            )\n        ])\n        return transform_ops(image)","5baccf1a":"train_dataset = CapchaDataset(data_path, train_images)\ntest_dataset = CapchaDataset(data_path, test_images)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=cpu_count, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=cpu_count, shuffle=False)\n\nprint(f'{len(train_loader)} batches in the train_loader')\nprint(f'{len(test_loader)} batches in the test_loader')","55cb2e9c":"batch_images, batch_labels = iter(train_loader).next()\n\nprint(batch_images.shape)\nprint(batch_labels)","7d686b84":"resnet = resnet18(pretrained=True)","713b30d3":"class CRNN(nn.Module):\n    def __init__(self, num_chars, rnn_hidden_size=256, dropout=0.1):\n        super(CRNN, self).__init__()\n        self.num_chars = num_chars\n        self.rnn_hidden_size = rnn_hidden_size\n        self.dropout = dropout\n        \n        # Get resnet18 without the last 3 layers\n        resnet_modules = list(resnet.children())[:-3]\n        self.cnn_p1 = nn.Sequential(*resnet_modules)\n        \n        # Add custom layers\n        self.cnn_p2 = nn.Sequential(\n            nn.Conv2d(\n                in_channels=256,\n                out_channels=256,\n                kernel_size=(3,6),\n                stride=1,\n                padding=1),\n            nn.BatchNorm2d(num_features=256),\n            nn.ReLU(inplace=True)\n        )\n        self.linear1 = nn.Linear(1024, 256)\n        \n        # RNN\n        self.rnn1 = nn.GRU(\n            input_size=rnn_hidden_size,\n            hidden_size=rnn_hidden_size,\n            bidirectional=True,\n            batch_first=True\n        )\n        self.rnn2 = nn.GRU(\n            input_size=rnn_hidden_size,\n            hidden_size=rnn_hidden_size,\n            bidirectional=True,\n            batch_first=True\n        )\n        self.linear2 = nn.Linear(self.rnn_hidden_size*2, num_chars)\n        \n    def forward(self, x):\n        x = self.cnn_p1(x)\n        x = self.cnn_p2(x)\n        x = x.permute(0,3,1,2)\n\n        batch_size = x.size(0)\n        T = x.size(1)\n        x = x.view(batch_size, T, -1)\n        x = self.linear1(x)\n\n        x, hidden = self.rnn1(x)\n        feature_size = x.size(2)\n        x = x[:, :, :feature_size\/\/2] + x[:, :, feature_size\/\/2:]\n\n        x, hidden = self.rnn2(x)\n        x = self.linear2(x)\n        x = x.permute(1,0,2)\n\n        return x","f695379f":"def initialize_weights(m):\n    class_name = m.__class__.__name__\n    if type(m) in [nn.Linear, nn.Conv2d, nn.Conv1d]:\n        torch.nn.init.xavier_uniform_(m.weight)\n        if m.bias is not None:\n            m.bias.data.fill_(0.01)\n    elif class_name.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","d3118ae6":"num_chars = len(vocabulary)\nrnn_hidden_size = 256\n\ncrnn = CRNN(num_chars=num_chars, rnn_hidden_size=rnn_hidden_size)\ncrnn.apply(initialize_weights)\ncrnn = crnn.to(DEVICE)","596fe396":"predicted_labels = crnn(batch_images.to(DEVICE))\nprint(batch_labels)\nprint(predicted_labels.shape)","26ba7b40":"criterion = nn.CTCLoss(blank=0)","ba804cff":"def encode(labels):\n    lens = [len(label) for label in labels]\n    lens = torch.IntTensor(lens)\n    \n    labels_string = ''.join(labels)\n    targets = [char2idx[char] for char in labels_string]\n    targets = torch.IntTensor(targets)\n    \n    return (targets, lens)\n\ndef compute_loss(gtruth, pred):\n    \"\"\"\n    text_batch: list of strings of length equal to batch size\n    text_batch_logits: Tensor of size([T, batch_size, num_classes])\n    \"\"\"\n    predicted_capchas = F.log_softmax(pred, 2)\n    predicted_capchas_lens = torch.full(size=(predicted_capchas.size(1),), \n                                       fill_value=predicted_capchas.size(0), \n                                       dtype=torch.int32).to(DEVICE)\n\n    gtruth_capchas, gtruth_capchas_lens = encode(gtruth)\n    loss = criterion(predicted_capchas, gtruth_capchas, predicted_capchas_lens, gtruth_capchas_lens)\n\n    return loss\n\ncompute_loss(batch_labels, predicted_labels)","f4f01db4":"optimizer = optim.Adam(crnn.parameters(), lr=LEARNING_RATE, weight_decay= WEIGHT_DECAY)\nlr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=5)","f58671aa":"epoch_losses = []\niteration_losses = []\nnum_updates_epochs = []\n\nfor epoch in tqdm(range(1, NUM_EPOCHS +1)):\n    epoch_loss_list = []\n    num_updates_epoch = 0\n    \n    for x, y in tqdm(train_loader, leave=False):\n        optimizer.zero_grad()\n        pred = crnn(x.to(DEVICE))\n        loss = compute_loss(y, pred)\n        iteration_loss = loss.item()\n        \n        if np.isnan(iteration_loss) or np.isinf(iteration_loss):\n            continue\n        \n        num_updates_epoch += 1\n        iteration_losses.append(iteration_loss)\n        epoch_loss_list.append(iteration_loss)\n        loss.backward()\n        nn.utils.clip_grad_norm_(crnn.parameters(), CLIP_NORM)\n        optimizer.step()\n        \n    epoch_loss = np.mean(epoch_loss_list)\n    print(f'Epoch {epoch}:    Loss {loss}     Num_updates {num_updates_epoch}')\n    \n    epoch_losses.append(epoch_loss)\n    num_updates_epochs.append(num_updates_epoch)\n    lr_scheduler.step(epoch_loss)","7ac2928e":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n\nax1.plot(epoch_losses)\nax1.set_xlabel(\"Epochs\")\nax1.set_ylabel(\"Loss\")\n\nax2.plot(iteration_losses)\nax2.set_xlabel(\"Iterations\")\nax2.set_ylabel(\"Loss\")\n\nplt.show()","661ed7cd":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n\nax1.plot(epoch_losses[-50:])\nax1.set_xlabel(\"Epochs\")\nax1.set_ylabel(\"Loss\")\n\nax2.plot(iteration_losses[-2000:])\nax2.set_xlabel(\"Iterations\")\nax2.set_ylabel(\"Loss\")\n\nplt.show()","0b418cf1":"def decode(labels):\n    tokens = F.softmax(labels, 2).argmax(2)\n    tokens = tokens.numpy().T\n    capchas = []\n    \n    for token in tokens:\n        chars = [idx2char[idx] for idx in token]\n        capcha = ''.join(chars)\n        capchas.append(capcha)\n    return capchas\n\ndef remove_duplicates(text):\n    if len(text) > 1:\n        letters = [text[0]] + [letter for idx, letter in enumerate(text[1:], start=1) if text[idx] != text[idx-1]]\n    elif len(text) == 1:\n        letters = [text[0]]\n    else:\n        return \"\"\n    return \"\".join(letters)\n\ndef correct_prediction(word):\n    parts = word.split(\"-\")\n    parts = [remove_duplicates(part) for part in parts]\n    corrected_word = \"\".join(parts)\n    return corrected_word","5e900777":"results_test = pd.DataFrame(columns=['Actual', 'Prediction'])\nwith torch.no_grad():\n    \n    for x, y in tqdm(test_loader, leave=True):\n        pred = crnn(x.to(DEVICE))\n        pred = decode(pred.cpu())\n        df = pd.DataFrame(columns=['Actual', 'Prediction'])\n        df['Actual'] = y\n        df['Prediction'] = [correct_prediction(p) for p in pred]\n        results_test = pd.concat([results_test, df])\n        results_test = pd.concat([results_test, df])\n        \nresults_test = results_test.reset_index(drop=True)\nresults_test = results_test.reset_index(drop=True)","cdddad2d":"results_test","bc7be311":"accuracy_score(results_test['Actual'], results_test['Prediction'])","4d5a6a99":"# Define loss function","3f1afab5":"# Prepare datasets","caf8dbb8":"# Define character maps","489a952a":"# Define variables","aa13e97c":"# Make predictions","357e617c":"# Plot loss","02b67d8d":"# Define model","6fbd569c":"# Source\nhttps:\/\/www.kaggle.com\/gokulkarthik\/captcha-text-recognition-using-crnn-in-pytorch","5785d2bf":"# Train model","919f4db3":"# Import libraries","e9e4ca76":"# Define Data Loader"}}