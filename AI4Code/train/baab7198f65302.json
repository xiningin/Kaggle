{"cell_type":{"790cbef2":"code","db9f6c7a":"code","d99aa6a1":"code","802ecc38":"code","9e370cf4":"code","3d499900":"code","b74beb14":"code","17472f67":"code","81e27401":"code","f8102142":"code","a28845a7":"code","3d5388c7":"code","e2965e25":"code","8517fb1d":"code","bbe922c5":"code","bbc0b4ca":"markdown","275f41f8":"markdown","efb8a1d4":"markdown","7b0035df":"markdown","09e28c30":"markdown","4f7085b0":"markdown","dfded98c":"markdown"},"source":{"790cbef2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nfrom sklearn import datasets\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","db9f6c7a":"\niris = datasets.load_iris()\niris_data = iris.data\niris_labels = iris.target\n#load datasets and create dataframes\nX = pd.DataFrame(data=iris.data, columns=iris.feature_names)\ny = pd.DataFrame(data=iris['target'])\ny.columns = [\"labels\"]","d99aa6a1":"def minkowski_distance(point1,point2,p):\n    distance = 0\n    for i in range(len(point1)):\n        distance = distance+(abs(point1[i]-point2[i])**(1\/p))\n        \n    distance = distance**p\n    \n    return distance","802ecc38":"#try minkowski_distance function\n\np1=X.iloc[0]\np2=X.iloc[3]\nminkowski_distance(p1, p2, 2)","9e370cf4":"test_point = [6.3,2.5,4.2,1.8]\n\ndistance_to_each_point_euclid = []\ndistance_to_each_point_manhattan = []\npoints_labels = []\ne=2\nm=1\n\nfor i in range(len(X)):\n    distance_to_each_point_euclid.append(minkowski_distance(test_point,X.iloc[i],e))\n    distance_to_each_point_manhattan.append(minkowski_distance(test_point,X.iloc[i],m))\n    points_labels.append(y[\"labels\"][i])\n    \ndistance_for_test_point_e = pd.DataFrame()\ndistance_for_test_point_m = pd.DataFrame()\ndistance_for_test_point_e[\"euclid_distance\"] = distance_to_each_point_euclid\ndistance_for_test_point_m[\"manhattan_distance\"] = distance_to_each_point_manhattan\ndistance_for_test_point_e[\"labels_of_compared_labels\"] = points_labels\ndistance_for_test_point_m[\"labels_of_compared_labels\"] = points_labels","3d499900":"distance_for_test_point_e","b74beb14":"distance_for_test_point_m","17472f67":"distance_for_test_point_m.sort_values(by=['manhattan_distance'], inplace=True)\ndistance_for_test_point_e.sort_values(by=['euclid_distance'],inplace=True)","81e27401":"distance_for_test_point_m.head(10)","f8102142":"distance_for_test_point_e.head(10)","a28845a7":"from collections import Counter\n\nk = 25\nc = Counter(distance_for_test_point_e[\"labels_of_compared_labels\"][:k])\n\nc.most_common()[0][0]","3d5388c7":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)","e2965e25":"def calculate_distance_return_labels(X_train,X_test,y_train,k,p):\n    \n    test_values_predictions = []\n    \n    for i in range(len(X_test)):\n        points_labels_calculate = []\n        dist=[]\n        \n        for j in range(len(X_train)):\n            dist.append(minkowski_distance(X_test.iloc[i],X_train.iloc[j],p))\n            points_labels_calculate.append(y_train.iloc[j,0])\n\n        distance_for_X_test_point = pd.DataFrame()\n        distance_for_X_test_point[\"distance\"] = dist\n        distance_for_X_test_point[\"y_train_labels\"] = points_labels_calculate\n        distance_for_X_test_point.sort_values(by=['distance'],inplace=True)\n        #[0:k,1]:k means number of neighbors 1 means columns number of \"y_train_labels\" \n        c = Counter(distance_for_X_test_point.iloc[0:k,1])\n        predict_value = c.most_common(1)[0][0]\n        \n        test_values_predictions.append(predict_value)\n        \n    return test_values_predictions","8517fb1d":"predicted_value = calculate_distance_return_labels(X_train,X_test,y_train,3,2)\n","bbe922c5":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test,predicted_value))","bbc0b4ca":"**You can also try again and again by changing the p and k values.**","275f41f8":"**Let's compare the variable \"[6.3,2.5,4.2,1.8]\" with each row in the data set and see how the results come out with manhattan and Euclidean distance measurement.**","efb8a1d4":"**When we sort the data frames according to the columns where the distances are located, the main differences will begin to emerge.**","7b0035df":"![](https:\/\/miro.medium.com\/max\/325\/1*wWdhIZJd6y_v4C3Ze2tqFQ.png)**Knn's default distance metric in the sklearn library is minkowski, so use the distance function based on the mathematical expression of minkowski. Minkowski needs a p value, p = 2 is defined for euclid, p = 1 manhattan.**","09e28c30":"**Split the data with the train_test_split function in order to calculate on the test data set.**","4f7085b0":"**I gathered what I wrote in the previous lines in a function.**","dfded98c":"**We can select the nearest k neighbors of test_point, create Counter and find the most_common function to find out which class the majority belongs to. You can also try by changing the K values.**"}}