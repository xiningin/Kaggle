{"cell_type":{"9dbe7417":"code","b4b1442e":"code","a6af73cb":"code","37e989cc":"code","9aa8610c":"code","1839e695":"code","f29f417c":"code","f7c4cee2":"code","0b564af5":"code","458829e3":"code","bdb23ee0":"code","af989b58":"code","d725bcd3":"code","58b9a7a9":"code","846645b7":"code","feb41d45":"code","0a96ccf2":"code","5b9d57b3":"code","51cd10cb":"code","a9f1e11b":"code","14d8fcdf":"code","f31fd212":"code","7f517d0f":"code","33fbf7f0":"code","6b385a1d":"code","a58bff36":"code","e762a560":"code","6db7f6e3":"code","02e7bb4f":"code","4edf7c4d":"code","6013d17a":"code","005ad55c":"code","c2417e74":"code","d9ccf65d":"code","af715077":"code","728506b9":"code","b61ff5e7":"code","c701af5d":"code","739605ce":"code","e5cfc7bc":"code","609f701c":"code","a03b42a2":"code","7bdccb83":"code","0927b552":"code","7bdccbfc":"code","e924f0b6":"code","c4582fc5":"code","fbf6ed16":"code","0b869920":"markdown","d9fbaa83":"markdown","24d2b1b0":"markdown","8c93cd84":"markdown","dfb4e5af":"markdown","afbfd3e4":"markdown","27775429":"markdown","d2240ebb":"markdown","917d8af8":"markdown","5758702a":"markdown","b7100555":"markdown","cf114ab0":"markdown","f52b2abb":"markdown","d479d3bc":"markdown","4ede30dc":"markdown","b31f858f":"markdown","eacaf12d":"markdown","6df95117":"markdown","4f5a0e38":"markdown","0a0e021d":"markdown","829cd8c7":"markdown","0e36d226":"markdown","615c37bd":"markdown","abddead8":"markdown","d3b21629":"markdown","e2e97a14":"markdown","6a42b884":"markdown","d9cead98":"markdown","2b9e34bf":"markdown","c817e398":"markdown","e8bb6987":"markdown","a1a70f95":"markdown","65f57aed":"markdown","367ac192":"markdown","d3d40ef0":"markdown","048383f7":"markdown","f2230034":"markdown","956a0f8f":"markdown","64f8c15b":"markdown"},"source":{"9dbe7417":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b4b1442e":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import recall_score, confusion_matrix, precision_score, f1_score, accuracy_score, classification_report","a6af73cb":"df = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","37e989cc":"df.head()","9aa8610c":"print('Rows: {}, Columns: {}'.format(df.shape[0], df.shape[1]))\nfeatures = df.columns.to_list()\nfeatures.remove('Churn')\nprint('Features:\\n', features, sep='')","1839e695":"df.drop([\"customerID\"], axis = 1,inplace = True)","f29f417c":"df.isnull().sum()","f7c4cee2":"def check_values():\n    for i in range(df.columns.size):\n        print(df.columns[i] + ':')\n        for j in range(df[df.columns[i]].size):\n            if df[df.columns[i]][j] == ' ' :\n                print('Found space')\n            elif df[df.columns[i]][j] == '-' :\n                print('Found hyphen')\n            elif df[df.columns[i]][j] == 'NA' :\n                print('Found NA')\n        print('Done!')","0b564af5":"check_values()","458829e3":"# replacing spaces with null values\ndf['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)","bdb23ee0":"check_values()","af989b58":"df.isnull().sum()","d725bcd3":"df = df[df[\"TotalCharges\"].notnull()]","58b9a7a9":"df.isnull().sum()","846645b7":"df.reset_index(drop = True, inplace = True)","feb41d45":"df.dtypes","0a96ccf2":"df.TotalCharges = df.TotalCharges.astype(float)","5b9d57b3":"df.dtypes","51cd10cb":"df.nunique()","a9f1e11b":"for i in range(df.columns.size) :\n    if df[df.columns[i]].nunique() <= 4:\n        print(df[df.columns[i]].unique())","14d8fcdf":"col_map = ['Partner', \n          'Dependents', \n          'PhoneService', \n          'MultipleLines',\n          'OnlineSecurity',\n          'OnlineBackup',\n          'DeviceProtection',\n          'TechSupport',\n          'StreamingTV',\n          'StreamingMovies',\n          'PaperlessBilling', \n          'Churn']\nfor col in col_map:\n    df[col] = [1 if val == \"Yes\" else 0 if val == \"No\" else -1 for val in df[col]]","f31fd212":"for i in range(df.columns.size) :\n    if df[df.columns[i]].nunique() <= 4:\n        print(df[df.columns[i]].unique())","7f517d0f":"df['gender'] = [1 if gen == 'Male' else 0 for gen in df['gender']]","33fbf7f0":"df.head()","6b385a1d":"plt.figure(figsize = [15, 6])\nplt.pie(df['Churn'].value_counts(), \n        labels = ['No', 'Yes'], \n        startangle = 90, \n        autopct='%1.1f%%', \n        wedgeprops = {'width' : 0.2},\n        counterclock = True);\nplt.title('Customer churn')\nplt.legend()\nplt.axis('equal');","a58bff36":"plt.figure(figsize = [15, 6])\nplt.suptitle('Gender distribution')\n\nplt.subplot(1, 2, 1)\nplt.pie(df[df['Churn'] == 1]['gender'].value_counts(), \n        labels = ['Female', 'Male'], \n        startangle = 90, \n        autopct='%1.1f%%', \n        wedgeprops = {'width' : 0.2},\n        counterclock = True);\nplt.legend()\nplt.text(-0.13,-0.03, 'Churn',fontsize = 14)\nplt.axis('equal')\n\nplt.subplot(1, 2, 2)\nplt.pie(df[df['Churn'] == 0]['gender'].value_counts(), \n        labels = ['Male', 'Female'], \n        startangle = 90, \n        autopct='%1.1f%%', \n        wedgeprops = {'width' : 0.2},\n        counterclock = True);\nplt.legend()\nplt.text(-0.22,-0.03, 'Not Churn',fontsize = 14)\nplt.axis('equal');","e762a560":"bluish = sns.color_palette()[0]\norangish = sns.color_palette()[1]","6db7f6e3":"plt.figure(figsize = [15, 8])\nten_dist = sns.kdeplot(df['tenure'][df[\"Churn\"] == 0], color = bluish, shade = True)\nten_dist = sns.kdeplot(df['tenure'][df[\"Churn\"] == 1], color = orangish, shade= True)\nten_dist.legend(['Not Churn', 'Churn'])\nten_dist.set_xlabel('Tenure')\nten_dist.set_ylabel('Frequency')\nplt.xticks(np.arange(0, 80, 5))\nplt.title('Distribution of tenure for churn and not churn customers');","02e7bb4f":"plt.figure(figsize = [15, 8])\nten_dist = sns.kdeplot(df['MonthlyCharges'][df[\"Churn\"] == 0], color = bluish, shade = True)\nten_dist = sns.kdeplot(df['MonthlyCharges'][df[\"Churn\"] == 1], color = orangish, shade= True)\nten_dist.legend(['Not Churn', 'Churn'])\nten_dist.set_xlabel('Monthly charges')\nten_dist.set_ylabel('Frequency')\nplt.title('Distribution of monthly charges for churn and not churn customers');","4edf7c4d":"plt.figure(figsize = [15, 8])\nten_dist = sns.kdeplot(df['TotalCharges'][df[\"Churn\"] == 0], color = bluish, shade = True)\nten_dist = sns.kdeplot(df['TotalCharges'][df[\"Churn\"] == 1], color = orangish, shade= True)\nten_dist.legend(['Not Churn', 'Churn'])\nten_dist.set_xlabel('Total charges')\nten_dist.set_ylabel('Frequency')\nplt.title('Distribution of total charges for churn and not churn customers');","6013d17a":"plt.figure(figsize = [10,6])\nsns.countplot(data = df, x = 'Contract', hue = 'Churn')\nplt.legend(['Not Churn', 'Churn'])\nplt.title('Contracts against churn and not churn customers', fontsize = 14);","005ad55c":"plt.figure(figsize = [10,6])\nsns.countplot(data = df, x = 'InternetService', hue = 'Churn')\nplt.legend(['Not Churn', 'Churn'])\nplt.title('Internet service against churn and not churn customers', fontsize = 14);","c2417e74":"df = pd.get_dummies(data = df)\ndf.head()","d9ccf65d":"corr = df.corr()\nfig = plt.figure(figsize = (8, 8))\nax = fig.add_subplot(111)\np = ax.matshow(corr, vmin = -1, vmax = 1)\nfig.colorbar(p)\nticks = np.arange(0, 27, 1) \nax.set_xticks(ticks)\nax.set_yticks(ticks)\nax.set_xticklabels(df.columns.to_list(), rotation = 90)\nax.set_yticklabels(df.columns.to_list());","af715077":"df.corr()['Churn'].sort_values()","728506b9":"df.describe()","b61ff5e7":"X = df.drop([\"Churn\"], axis = 1)\nX = (X - np.mean(X, axis = 0)) \/ np.std(X, axis = 0)\nX.describe()","c701af5d":"y = df['Churn'].values","739605ce":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","e5cfc7bc":"print('Test: ', X_train.shape[0], ', ', y_train.shape[0], sep = '')\nprint('Train: ', X_test.shape[0],',', y_test.shape[0], sep = '')","609f701c":"lr_model = LogisticRegression()\nlr_model.fit(X_train,y_train)\nlr_train_acc = lr_model.score(X_train, y_train)\nlr_test_acc = lr_model.score(X_test, y_test)\nprint('Logistic Regression')\nprint('Training accuracy:', lr_train_acc)\nprint('Testing accuracy:', lr_test_acc) ","a03b42a2":"svc_model = SVC(random_state = 1)\nsvc_model.fit(X_train, y_train)\nsvm_train_acc = svc_model.score(X_train,y_train)\nsvm_test_acc = svc_model.score(X_test,y_test)\nprint('SVM')\nprint('Training accuracy:', svm_train_acc)\nprint('Testing accuracy:', svm_test_acc)","7bdccb83":"plt.figure(figsize = (15, 6))\nacc = []\nacc_k = []\nfor k in range(1, 25):\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(X_train, y_train)\n    acc.append(knn.score(X_test,y_test))\n    acc_k.append([knn.score(X_test,y_test), k])\n    \nplt.plot(range(1, 25), acc)\nplt.xticks(np.arange(1, 26, 1))\nplt.xlabel(\"Range\")\nplt.ylabel(\"Score\")\nplt.title('Finding k for KNN');","0927b552":"max(acc_ind)","7bdccbfc":"knn_model = KNeighborsClassifier(n_neighbors = 9)\nknn_model.fit(X_train, y_train)\nknn_train_acc = knn_model.score(X_train, y_train)\nknn_test_acc = knn_model.score(X_test, y_test)\nprint('KNN for k = 15')\nprint('Training accuracy:', knn_train_acc)\nprint('Testing accuracy:', knn_test_acc)","e924f0b6":"def scores(name, y, y_hat):\n    acc = accuracy_score(y, y_hat)\n    precision = precision_score(y, y_hat)\n    recall = recall_score(y, y_hat)    \n    f1 = f1_score(y, y_hat, average='weighted')\n    \n    print(name)    \n    print('Accuracy:', acc)\n    print('Precision: ', precision)                   \n    print('Recall:', recall)\n    print('F1_score:', f1)\n    print()","c4582fc5":"scores(\"Logistic Regression\",y_test, lr_model.predict(X_test))\nscores(\"Support Vector Machine\", y_test, svc_model.predict(X_test))\nscores(\"K-Nearest Neighbors\", y_test, knn_model.predict(X_test))","fbf6ed16":"lr_matrix = confusion_matrix(y_test, lr_model.predict(X_test))\nf, ax = plt.subplots(figsize = (8, 8))\nsns.heatmap(lr_matrix, annot = True, color = \"red\", fmt = \".0f\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\");","0b869920":"Converting categorical variables to indicator variables.","d9fbaa83":"We observe that probability of churning out is maximum for customers who have a **short tenure** (between 0 to approx. 15).","24d2b1b0":"Let's build the correlation matrix to analyse the relation.","8c93cd84":"We observe that Contract_Month-to-month, InternetService_Fiber optic, PaymentMethod_Electronic check are highly positively correlated and Tenure, Contract_Two year are negatively highly correlated with Churn.","dfb4e5af":"We observe that our feautres are on different scales and this can slow the process of convergence of our learning algorithm. \n\nTo fix this let's normalize our dataset.","afbfd3e4":"### Model Selection","27775429":"#### Logistic Regression","d2240ebb":"### Overview","917d8af8":"Since the data is imbalanced we can't just rely upon training and test accuracy.\n\nWe'll build a confusion matrix and use f1 score to select our model.","5758702a":"### Data Pre-processing","b7100555":"Let's check if the data types are defined properly.","cf114ab0":"- 26.6% of the total customers have churned out.\n- There isn't any drastic difference between churn and not churn customers based on their gender.\n- The probability of churning out is maximum for customers who have a short tenure (between 0 to approx. 15).\n- Most of the customers who have churned out have high monthly charges when compared to the ones who have not churned out.\n- Most of the customers who have churned out were part of the month-to-month contract.\n- The participation in one and two year contract is very less for the customers who have churned out whereas the participation is significant for those who have not\n- The customers who opted for Fiber optic were likely to churn out.\n- The customers who opted for DSL were less likely to churn out.\n- Features like Contract_Month-to-month, InternetService_Fiber optic, PaymentMethod_Electronic check are highly positively correlated and Tenure, Contract_Two year are negatively highly correlated with Churn.\n- We used F1 score to choose our model as the data was imbalanced.\n- Logistic Regression gave the best results in terms of accuracy and F1 score thus it is the best model.","f52b2abb":"### Modelling","d479d3bc":"Mapping yes to 1, no to 0 and no internet service to -1.","4ede30dc":"Analysizing the probability distributions of churn and not churn customers against various features using Kernel Density Estimate(KDE) plot.","b31f858f":"\nWe learn that most of the customers who have churned out were part of the month-to-month contract.\n\nWe also observe that the participation in one and two year contract is very less for the customers who have churned out whereas the participation is significant for those who have not.","eacaf12d":"We observe that the customers who opted for Fiber optic were likely to churn out.\n\nWe also see that the customers who opted for DSL were less likely to churn out.","6df95117":"We observe that Logistic Regression is the one with highest accuracy and F1 score thus we select it as our model.\n\nLet's now visualize the confusion matrix for our model.","4f5a0e38":"#### K-Nearest Neighbours","0a0e021d":"Fixing the index.","829cd8c7":"We find that k = 9 is the one that we should use for maximum accuracy.","0e36d226":"TotalCharges is of object data type, we need to convert it into float.","615c37bd":"Mapping male to 1 and female to 0 in Gender column.","abddead8":"Let's explore the dataset.","d3b21629":"Let's drop the customer ids as they do not have anything to do with churning.","e2e97a14":"We observe that distribution of the customers who have churned out is high between 0 to approx. 1000.","6a42b884":"Let's find out the optimal value for k.","d9cead98":"Checking if there are any null values.","2b9e34bf":"Seems like there are no NaNs.\n\nBut to be 100% sure, let's see if there is something else in place of a value.","c817e398":"We do not observe any drastic difference between churn and not churn customers based on their _gender_.","e8bb6987":"We have found 'Spaces' in TotalCharges column which can't be used for training.\n\nLet's fix this.","a1a70f95":"Let's see the number of unique values in our data.","65f57aed":"#### Support Vector Machine","367ac192":"### Conclusion","d3d40ef0":"We observe that **26.6%** of the total customers have churned out.","048383f7":"#### Splitting the dataset into train and test set","f2230034":"We observe that most of the customers who have churned out have **high monthly charages** when compared to the ones who have not churned out.","956a0f8f":"#### Mean normalization","64f8c15b":"### Exploratory Data Analysis and Visualization"}}