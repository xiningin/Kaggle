{"cell_type":{"ab3c52d3":"code","76875a31":"code","ff86d82d":"code","9b1f21ad":"code","a77c6436":"code","e37b93de":"code","0c50543a":"code","f77422c2":"code","108d1d3f":"code","4b06875c":"code","5361ebdc":"code","9d2861bd":"code","c9049f23":"code","0370186a":"code","63dce83d":"code","72b81a61":"code","ea368cf3":"code","929cfc50":"code","ee8117a8":"code","7a06d313":"code","15d0ef73":"code","f867d563":"code","25eaa1ec":"markdown"},"source":{"ab3c52d3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport warnings\nimport seaborn as sns\nimport matplotlib.pylab as plt\nimport PIL\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import f1_score\nfrom keras import backend as K\nfrom keras import layers, models, optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import *\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nwarnings.filterwarnings('ignore')\nK.image_data_format()","76875a31":"BATCH_SIZE = 32\nEPOCHS = 50\nk_folds = 2\nTTA_STEPS = 5\nPATIENCE = 6\nSEED = 2019\nBASE_MODEL = Xception\nIMAGE_SIZE = 299","ff86d82d":"DATA_PATH = '..\/input'\n\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\nTEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))\n\nmodel_path = '.\/'\nif not os.path.exists(model_path):\n    os.mkdir(model_path)","9b1f21ad":"def crop_boxing_img(img_name, margin=0, size=(IMAGE_SIZE,IMAGE_SIZE)):\n    if img_name.split('_')[0] == 'train':\n        PATH = TRAIN_IMG_PATH\n        data = df_train\n    else:\n        PATH = TEST_IMG_PATH\n        data = df_test\n\n    img = PIL.Image.open(os.path.join(PATH, img_name))\n    pos = data.loc[data[\"img_file\"] == img_name, ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n\n    width, height = img.size\n    x1 = max(0, pos[0] - margin)\n    y1 = max(0, pos[1] - margin)\n    x2 = min(pos[2] + margin, width)\n    y2 = min(pos[3] + margin, height)\n\n    return img.crop((x1, y1, x2, y2)).resize(size)","a77c6436":"%%time\nTRAIN_CROPPED_PATH = '..\/cropped_train'\nTEST_CROPPED_PATH = '..\/cropped_test'\n\nif (os.path.isdir(TRAIN_CROPPED_PATH) == False):\n    os.mkdir(TRAIN_CROPPED_PATH)\n\nif (os.path.isdir(TEST_CROPPED_PATH) == False):\n    os.mkdir(TEST_CROPPED_PATH)\n\nfor i, row in df_train.iterrows():\n    cropped = crop_boxing_img(row['img_file'])\n    cropped.save(os.path.join(TRAIN_CROPPED_PATH, row['img_file']))\n\nfor i, row in df_test.iterrows():\n    cropped = crop_boxing_img(row['img_file'])\n    cropped.save(os.path.join(TEST_CROPPED_PATH, row['img_file']))","e37b93de":"df_train['class'] = df_train['class'].astype('str')\ndf_train = df_train[['img_file', 'class']]\ndf_test = df_test[['img_file']]","0c50543a":"def recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","f77422c2":"def get_callback(model_name, patient):\n    ES = EarlyStopping(\n        monitor='val_f1_m', \n        patience=patient, \n        mode='max', \n        verbose=1)\n    RR = ReduceLROnPlateau(\n        monitor = 'val_f1_m', \n        factor = 0.5, \n        patience = patient \/ 2, \n        min_lr=0.000001, \n        verbose=1, \n        mode='max')\n    MC = ModelCheckpoint(\n        filepath=model_name, \n        monitor='val_f1_m', \n        verbose=1, \n        save_best_only=True, \n        mode='max')\n\n    return [ES, RR, MC]","108d1d3f":"def get_model(model_name, iamge_size):\n    base_model = model_name(weights='imagenet', input_shape=(iamge_size,iamge_size,3), include_top=False)\n    #base_model.trainable = False\n    model = models.Sequential()\n    model.add(base_model)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(2048, activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(0.15))\n \n    model.add(layers.Dense(196, activation='softmax', kernel_initializer='lecun_normal'))\n    #model.summary()\n\n    optimizer = optimizers.Nadam(lr=0.0003)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc', f1_m, precision_m, recall_m])\n\n    return model","4b06875c":"#ref: https:\/\/github.com\/yu4u\/cutout-random-erasing\/blob\/master\/cifar10_resnet.py\ndef get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1\/0.3, v_l=0, v_h=255, pixel_level=False):\n    def eraser(input_img):\n        img_h, img_w, img_c = input_img.shape\n        p_1 = np.random.rand()\n\n        if p_1 > p:\n            return input_img\n\n        while True:\n            s = np.random.uniform(s_l, s_h) * img_h * img_w\n            r = np.random.uniform(r_1, r_2)\n            w = int(np.sqrt(s \/ r))\n            h = int(np.sqrt(s * r))\n            left = np.random.randint(0, img_w)\n            top = np.random.randint(0, img_h)\n\n            if left + w <= img_w and top + h <= img_h:\n                break\n\n        if pixel_level:\n            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n        else:\n            c = np.random.uniform(v_l, v_h)\n\n        input_img[top:top + h, left:left + w, :] = c\n\n        return input_img\n\n    return eraser","5361ebdc":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    #featurewise_center= True,  # set input mean to 0 over the dataset\n    #samplewise_center=True,  # set each sample mean to 0\n    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    #samplewise_std_normalization=True,  # divide each input by its std\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=False,\n    zoom_range=0.3,\n    shear_range=0.5,\n    brightness_range=[0.5, 1.5],\n    fill_mode='nearest',\n    preprocessing_function = get_random_eraser(v_l=0, v_h=255),\n    )\n\nvalid_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    #featurewise_center= True,  # set input mean to 0 over the dataset\n    #samplewise_center=True,  # set each sample mean to 0\n    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    #samplewise_std_normalization=True  # divide each input by its std\n    )\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    #featurewise_center= True,  # set input mean to 0 over the dataset\n    #samplewise_center=True,  # set each sample mean to 0\n    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    #samplewise_std_normalization=True,  # divide each input by its std\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=False,\n    zoom_range=0.3,\n    shear_range=0.5,\n    brightness_range=[0.5, 1.5],\n    fill_mode='nearest',\n    preprocessing_function = get_random_eraser(v_l=0, v_h=255),\n    )","9d2861bd":"skf = StratifiedKFold(n_splits=k_folds, random_state=SEED)\n#skf = KFold(n_splits=k_folds, random_state=SEED)","c9049f23":"%%time\nj = 1\nmodel_names = []\nfor (train_index, valid_index) in skf.split(\n    df_train['img_file'], \n    df_train['class']):\n\n    traindf = df_train\n    validdf = df_train.iloc[valid_index, :].reset_index()\n\n    print(\"=========================================\")\n    print(\"====== K Fold Validation step => %d\/%d =======\" % (j,k_folds))\n    print(\"=========================================\")\n    \n    train_generator = train_datagen.flow_from_dataframe(\n        dataframe=traindf,\n        directory=TRAIN_CROPPED_PATH,\n        x_col='img_file',\n        y_col='class',\n        target_size= (IMAGE_SIZE, IMAGE_SIZE),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=BATCH_SIZE,\n        seed=SEED,\n        shuffle=True\n        )\n    \n    valid_generator = valid_datagen.flow_from_dataframe(\n        dataframe=validdf,\n        directory=TRAIN_CROPPED_PATH,\n        x_col='img_file',\n        y_col='class',\n        target_size= (IMAGE_SIZE, IMAGE_SIZE),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=BATCH_SIZE,\n        seed=SEED,\n        shuffle=True\n        )\n    \n    model_name = model_path + str(j) + '_' + 'Xception' + '.hdf5'\n    model_names.append(model_name)\n    \n    model = get_model(BASE_MODEL, IMAGE_SIZE)\n    \n    try:\n        model.load_weights(model_name)\n    except:\n        pass\n        \n    history = model.fit_generator(\n        train_generator,\n        steps_per_epoch=len(traindf.index) \/ BATCH_SIZE,\n        epochs=EPOCHS,\n        validation_data=valid_generator,\n        validation_steps=len(validdf.index) \/ BATCH_SIZE,\n        verbose=1,\n        shuffle=False,\n        callbacks = get_callback(model_name, PATIENCE)\n        )\n        \n    j+=1","0370186a":" print(history.history.keys())  ","63dce83d":"plt.figure(figsize=(7, 7), dpi= 80, facecolor='w', edgecolor='k')\nplt.plot(history.history['acc']) \nplt.plot(history.history['val_acc'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.show()","72b81a61":"plt.figure(figsize=(7, 7), dpi= 80, facecolor='w', edgecolor='k')\nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.show()","ea368cf3":"plt.figure(figsize=(7, 7), dpi= 80, facecolor='w', edgecolor='k')\nplt.plot(history.history['f1_m'])  \nplt.plot(history.history['val_f1_m'])  \nplt.title('model f1_score')  \nplt.ylabel('f1_score')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.show()","929cfc50":"test_generator = test_datagen.flow_from_dataframe(\n    dataframe=df_test,\n    directory=TEST_CROPPED_PATH,\n    x_col='img_file',\n    y_col=None,\n    target_size= (IMAGE_SIZE, IMAGE_SIZE),\n    color_mode='rgb',\n    class_mode=None,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","ee8117a8":"prediction = []\nfor i, name in enumerate(model_names):\n    model = get_model(BASE_MODEL, IMAGE_SIZE)\n    model.load_weights(name)\n    \n    preds = []\n    for j in range(TTA_STEPS):\n        test_generator.reset()\n        pred = model.predict_generator(\n            generator=test_generator,\n            steps = len(df_test)\/BATCH_SIZE,\n            verbose=1\n        )\n        preds.append(pred)\n    pred_tta = np.mean(preds, axis=0)\n    prediction.append(pred_tta)\n\ny_pred = np.mean(prediction, axis=0)","7a06d313":"preds_class_indices=np.argmax(y_pred, axis=1)","15d0ef73":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nfinal_pred = [labels[k] for k in preds_class_indices]","f867d563":"submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\nsubmission[\"class\"] = final_pred\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","25eaa1ec":"based on [General base model stratifiedkfold ensemble w\/test](https:\/\/www.kaggle.com\/meditech101\/general-base-model-stratifiedkfold-ensemble-w-test) kernel <br\/>\nis originated from [bronze medal[3rd ML Month] Xception, StratifiedKFold, Ensemble](https:\/\/www.kaggle.com\/janged\/3rd-ml-month-xception-stratifiedkfold-ensemble)\n\nF1 score, Cutout Augmentation, and Test Time Augmentation are applied."}}