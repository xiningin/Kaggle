{"cell_type":{"a0afb8cc":"code","17e522ba":"code","910d06a7":"code","4c1577af":"code","49c96e40":"code","17644ef8":"code","3197f901":"code","c7a8ceea":"code","33d4b2ab":"code","c3f08f13":"code","00dc796c":"code","0122c6e4":"code","1ad85be4":"code","a26e5cc4":"code","1edc5e50":"code","076c37ba":"code","ee04d6ed":"code","c367b87d":"code","a9436e82":"code","4ebb2dce":"code","4f19c7cb":"code","6363eb73":"code","4bc58793":"code","a4f6d366":"markdown","6bdacc9a":"markdown","a7f93660":"markdown","46257fb1":"markdown","16c0d203":"markdown"},"source":{"a0afb8cc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","17e522ba":"amazon_df = pd.read_csv(\"..\/input\/sentiment labelled sentences\/sentiment labelled sentences\/amazon_cells_labelled.txt\", \n                        delimiter='\\t', \n                        header=None, \n                        names=['review', 'sentiment'])\n\nimdb_df = pd.read_csv(\"..\/input\/sentiment labelled sentences\/sentiment labelled sentences\/imdb_labelled.txt\", \n                        delimiter='\\t', \n                        header=None, \n                        names=['review', 'sentiment'])\n\nyelp_df = pd.read_csv(\"..\/input\/sentiment labelled sentences\/sentiment labelled sentences\/yelp_labelled.txt\", \n                        delimiter='\\t', \n                        header=None, \n                        names=['review', 'sentiment'])","910d06a7":"amazon_df.head()","4c1577af":"imdb_df.head()","49c96e40":"yelp_df.head()","17644ef8":"all_df = pd.concat([amazon_df, imdb_df, yelp_df])\nall_df.reset_index(drop=True, inplace=True)\n\nreviews = all_df['review'].get_values()\nsentiment = all_df['sentiment'].get_values()","3197f901":"import  re\nfrom nltk.corpus import stopwords\nimport unidecode","c7a8ceea":"print(reviews[1])\na = unidecode.unidecode(reviews[1])\na = re.sub('[^a-zA-Z ]', '', reviews[1])\nprint(a)\nprint(a.lower())\n","33d4b2ab":"clean_reviews = []\n\nfor review in reviews:\n    # removendo acentos\n    a = unidecode.unidecode(review)\n    # removendo nao letras\n    a = re.sub('[^a-zA-Z ]', '', a)\n    # lowercase\n    a = a.lower()\n    \n    # faz o split pelo espaco\n    a = a.split()\n\n    # removendo stop words\n    novo_a = []\n    for word in a:\n        if not word in stopwords.words('english'):\n            novo_a.append(word)\n    \n    clean_reviews.append(novo_a)\n","c3f08f13":"reviews[0]","00dc796c":"len(clean_reviews)","0122c6e4":"from collections import Counter","1ad85be4":"word_freq = Counter()\nfor review in clean_reviews:\n    for word in review:\n        word_freq[word] += 1","a26e5cc4":"top3000_words = word_freq.most_common(3000)","1edc5e50":"word_to_id = {}\n# palavras vao receber o valor do seu rank\nidx = 3000\nfor t in top3000_words:\n    word_to_id[t[0]] = idx\n    idx -= 1\n\n# palavras que nao foram rankeadas vao receber valor 1\nfor word in word_freq.keys():\n    if not word in word_to_id:\n        word_to_id[word] = 1","076c37ba":"data = []\nfor review in clean_reviews:\n    aux = []\n    for word in review:\n        aux.append(word_to_id[word])\n    \n    data.append(aux)","ee04d6ed":"from keras.preprocessing.sequence import pad_sequences","c367b87d":"data = pad_sequences(data, maxlen=100, padding='post')","a9436e82":"from keras.layers import *\nfrom keras.models import Model","4ebb2dce":"input_node = Input(shape=(None, 100))\nembedding_layer = Embedding(input_dim=3001, output_dim=32)(input_node)\nreshape = Reshape((100, 32))(embedding_layer)\nlstm = LSTM(100)(reshape)\ndrop = Dropout(0.2)(lstm)\noutput_node = Dense(1, activation='sigmoid')(drop)\n\nmodel = Model(input_node, output_node)","4f19c7cb":"model.compile('Adam', loss='binary_crossentropy', metrics=['accuracy'])","6363eb73":"data = data.reshape(len(data), 1, 100)","4bc58793":"model.fit(data, sentiment, epochs=1)","a4f6d366":"<h2>Criando o modelo<\/h2>","6bdacc9a":"<h2>Substindo palavras por ID<\/h2>","a7f93660":"<h2>Ranqueamento de palavras<\/h2>","46257fb1":"<h2>Padronizar as entradas<\/h2>","16c0d203":"<h2>Processamento das frases<\/h2>"}}