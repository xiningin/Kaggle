{"cell_type":{"1917cb93":"code","2063b2c3":"code","6fd3f0ae":"code","e2027789":"code","8cff62c5":"code","c2e52767":"code","2baacd64":"code","46060dee":"code","bec9c2df":"code","85bdfe0c":"code","16f0269e":"code","dad935a8":"code","cb076e00":"code","bb210b7d":"code","12677557":"code","2b041f71":"code","4ab82001":"code","57c8e88a":"code","32b228b6":"code","bfcd04dd":"code","95c5264d":"code","009d33be":"code","b09d36d7":"code","a0b0cbc8":"code","b1f5e4dd":"code","8b3b90a1":"code","5107af3a":"code","53df2536":"code","fd8e627f":"code","ffb3916e":"code","3f59cbfa":"code","83b97ac3":"code","25607f7d":"code","6611b28c":"code","abc0afbb":"code","9e635b6f":"code","058f413e":"code","fa1e9ba2":"code","33b91529":"code","ffafe995":"code","6fbf1946":"code","10eeb61e":"code","dffa57d4":"code","f822db27":"code","60fb8bb0":"code","593bbba1":"code","efc2770a":"markdown","a834845e":"markdown","12ea10e8":"markdown","d0b02c22":"markdown","d1229690":"markdown","a277219c":"markdown","bbbd7b1b":"markdown","774469d4":"markdown","5ed2d7ff":"markdown","a29fbb1c":"markdown","6c89ee8c":"markdown","4187732f":"markdown","71b34168":"markdown","f5e924f6":"markdown","008d8e44":"markdown","1f463543":"markdown","b98f58b8":"markdown","d8c0d0eb":"markdown","93a2dd33":"markdown","ad3c1171":"markdown","283fb114":"markdown","c136d34b":"markdown","63748c21":"markdown","267fe8c0":"markdown","2a0fbb34":"markdown","26dc6a1c":"markdown","271f2f34":"markdown","de5b37df":"markdown","1b9d2797":"markdown","f5a31e64":"markdown"},"source":{"1917cb93":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom matplotlib_venn import venn2, venn3\nimport squarify\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2063b2c3":"pd.read_excel(\"..\/input\/Data_Dictionary.xlsx\", sheet = 0, header = 2)","6fd3f0ae":"train  = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)\n\ntrain.head()","e2027789":"sns.distplot(train.target)","8cff62c5":"test = pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)\ntest.head()","c2e52767":"venn2([set(train.card_id), set(test.card_id)])","2baacd64":"sns.jointplot(train.index.values, train.target)","46060dee":"from sklearn.preprocessing import LabelEncoder","bec9c2df":"sns.jointplot(LabelEncoder().fit_transform(train.card_id), train.target)","85bdfe0c":"train[\"is_test\"] = np.int8(0)\ntest[\"is_test\"] = np.int8(1)\ntest[\"target\"] = np.NaN\ntrain_test = pd.concat([train,test], ignore_index=True, sort=True, axis = 0)\ntrain_test[\"first_active_month\"] = pd.to_datetime(train_test.first_active_month)\ntrain_test[\"mon\"] = train_test.first_active_month.dt.month\ntrain_test[\"year\"] = train_test.first_active_month.dt.year\n\nprint(train_test.shape)\ntrain_test.head()\n","16f0269e":"del train\ndel test","dad935a8":" pd.merge(train_test.groupby([\"is_test\", \"feature_1\"])[\"card_id\"].count().reset_index(),\n                      train_test.groupby([\"is_test\"]).count().reset_index(), on = \"is_test\" )","cb076e00":"def compare_cat_pct_counts(df, col_name, compare_col_name = \"is_test\", ind_col =\"card_id\"):\n    cnt_df = pd.merge(df.groupby([compare_col_name, col_name])[ind_col].count().reset_index(),\n                      df.groupby([compare_col_name])[ind_col].count().reset_index(), on = \"is_test\" )\n    cnt_df[\"cnt\"] = cnt_df[ind_col + \"_x\"] \/ cnt_df[ind_col + \"_y\"] \n    sns.barplot(col_name, \"cnt\", hue = compare_col_name, data = cnt_df)\n     ","bb210b7d":"compare_cat_pct_counts(train_test, \"feature_1\")","12677557":"compare_cat_pct_counts(train_test, \"feature_2\")","2b041f71":"compare_cat_pct_counts(train_test, \"feature_3\")","4ab82001":"plt.subplots(figsize=(15,6))\nplt.subplot(131)\nsns.boxplot(train_test[\"feature_1\"], train_test.target)\nplt.subplot(132)\nsns.boxplot(train_test[\"feature_2\"], train_test.target)\nplt.subplot(133)\nsns.boxplot(train_test[\"feature_3\"], train_test.target)","57c8e88a":"compare_cat_pct_counts(train_test, \"mon\")","32b228b6":"compare_cat_pct_counts(train_test, \"year\")","bfcd04dd":"plt.subplots(figsize=(15,6))\nplt.subplot(121)\nsns.boxplot(train_test.mon, train_test.target)\nplt.subplot(122)\nsns.boxplot(train_test.year, train_test.target)","95c5264d":"pd.read_excel(\"..\/input\/Data_Dictionary.xlsx\", 1)","009d33be":"hist_trans = pd.read_csv(\"..\/input\/historical_transactions.csv\")\nprint(hist_trans.shape)\nhist_trans.head()","b09d36d7":"plt.figure(figsize=(20,10))\nprint(hist_trans.card_id.nunique())\nvenn3([set(hist_trans.card_id.unique()), set(train_test.query(\"is_test == 0\").card_id), \n                                             set(train_test.query(\"is_test == 1\").card_id)])","a0b0cbc8":"hist_trans.card_id.value_counts().head(10)","b1f5e4dd":"tmp_df = pd.merge(hist_trans.card_id.value_counts().reset_index(), train_test, left_on=\"index\", right_on = \"card_id\")\nplt.subplots(figsize = (14, 6))\nplt.subplot(131)\nsns.boxplot(\"is_test\", \"card_id_x\", data=tmp_df )\nplt.subplot(132)\nsns.distplot(tmp_df.query(\"is_test == 0\")[\"card_id_x\"],  color = \"blue\" )\nsns.distplot(tmp_df.query(\"is_test == 1\")[\"card_id_x\"],  color = \"green\")\nplt.subplot(133)\nsns.distplot(np.log(tmp_df.query(\"is_test == 0\")[\"card_id_x\"]),  color = \"blue\" )\nsns.distplot(np.log(tmp_df.query(\"is_test == 1\")[\"card_id_x\"]),  color = \"green\")\ndel tmp_df","8b3b90a1":"# a helper function\ndef plot_cat_treemap(df, col_name, title = None):\n    cnts = df[col_name].value_counts()\n    cmap = matplotlib.cm.Spectral\n    mini=min(cnts)\n    maxi=max(cnts)\n    norm = matplotlib.colors.Normalize(vmin=mini, vmax=maxi)\n    colors = [cmap(norm(value)) for value in cnts]\n\n    \n    squarify.plot(sizes = cnts, label = cnts.index.values, value = cnts, color = colors)\n    plt.axis(\"off\")\n    plt.title(title)","5107af3a":"card_auth_agg = pd.merge(train_test, \n                         hist_trans.groupby([\"card_id\", \"authorized_flag\"])[\"city_id\"].count().unstack(level=-1),\n                         on = \"card_id\").rename(columns = {\"N\":\"cnt_unauthorized\", \"Y\":\"cnt_authorized\"}).fillna(0)\n\ncard_auth_agg[\"cnt_trans\"] = card_auth_agg[\"cnt_unauthorized\"] + card_auth_agg[\"cnt_authorized\"] \n#plt.subplot(311)\nsns.jointplot(card_auth_agg.target, card_auth_agg.cnt_trans)","53df2536":"sns.jointplot(card_auth_agg.target, card_auth_agg.cnt_unauthorized)","fd8e627f":"sns.jointplot(card_auth_agg.target, card_auth_agg.cnt_authorized)","ffb3916e":"del card_auth_agg","3f59cbfa":"plt.figure(figsize=(20,14))\nplot_cat_treemap(hist_trans, \"city_id\", \"City ID\")","83b97ac3":"city_agg = hist_trans.groupby(\"city_id\")[\"purchase_amount\"].agg([\"mean\", \"min\", \"max\", \"median\"])","25607f7d":"city_agg.sort_values(\"mean\", ascending=False).head()","6611b28c":"city_agg.sort_values(\"max\", ascending=False).head()","abc0afbb":"del city_agg","9e635b6f":"city_card_agg  = pd.merge(hist_trans.groupby(\"card_id\")[\"city_id\"].agg([\"nunique\"]).reset_index(), train_test, on=\"card_id\").rename(columns={\"nunique\":\"city_count\"})","058f413e":"plt.subplot(111)\nsns.distplot(city_card_agg.loc[~city_card_agg.target.isnull(), \"city_count\"], color = \"blue\")\nsns.distplot(city_card_agg.loc[city_card_agg.target.isnull(), \"city_count\"], color = \"green\")","fa1e9ba2":"del city_card_agg","33b91529":"gc.collect()","ffafe995":"plt.figure(figsize=(20,14))\nplot_cat_treemap(hist_trans, \"state_id\", \"State ID\")","6fbf1946":"stat_city_df = hist_trans.groupby([\"state_id\", \"city_id\"])[\"card_id\"].count().reset_index().sort_values(\"card_id\", ascending=False)","10eeb61e":"stat_city_df.query(\"state_id == -1\")","dffa57d4":"stat_city_df.query(\"city_id == -1\")","f822db27":"stat_city_df.query(\"city_id == 179\")","60fb8bb0":"stat_city_df.query(\"city_id == 75\")","593bbba1":"del stat_city_df","efc2770a":"conclusion: seems like for a very high number of transactions (independent on whether they were unathorized or not, the loyalty score is 0). For lower number of transactions, the loyalty score is all over","a834845e":"## peek at train and train shape","12ea10e8":"### number of authorized \/ non authorized and target","d0b02c22":"## Let's look at the first_active_month","d1229690":"## Let's check if any card_ids overlap between train and test","a277219c":"### Number of citites per persona","bbbd7b1b":"## state_id","774469d4":"Conclusion: most of the cards conduct transactions from a few cities. there are some, that have 70-100 different cities in their transaction history.","5ed2d7ff":"Some purchase amounts are huge, especially knowing they are already scaled","a29fbb1c":"## Comparing target stats for different categories","6c89ee8c":"## Just in case, let's check for any dependency of the target on data order or card_id","4187732f":"conclusion: they don't","71b34168":"Target distribution","f5e924f6":"conclusion: same proportion of categories for train and test","008d8e44":"Looks like some cards have a lot of transactions","1f463543":"conclusion: these features look useless. What do they mean?","b98f58b8":"### Target by the most frequent city","d8c0d0eb":"So, all card_ids present in transaction history, are either from train or from test","93a2dd33":"## Train fields description","ad3c1171":"Count of transactions has lognormal distribution, with some cards have an extreme number of transactions. However test set happens to have some cards that have even bigger number of transactions (5k vs 3k highest in train)\n\nBy now, I am convinced that train and test split is absolutely random and are selected from the same population and there is no need to compare the two sets further.","283fb114":"## Number of transactions per card","c136d34b":"peek at test","63748c21":"## city_id","267fe8c0":"# ELO data exploration\n\n[TOC]\n\nthis is my late EDA for this competition. I made it for myself, but perhaps other people will find it useful. I am still playing with it so please refresh from time to time","2a0fbb34":"### imports and listing files","26dc6a1c":"conclusion: no dependency","271f2f34":"### Purchase amt by city","de5b37df":"## Let's have a look at the \"feature_N\" categoricals. Is the proportion of different categories different for train and test?","1b9d2797":"### number of historical transactions per city","f5a31e64":"## authorized_flag"}}