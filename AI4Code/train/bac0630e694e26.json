{"cell_type":{"515ddf41":"code","c81e6384":"code","820ccb86":"code","bfe7f4d7":"code","6bc4c4c1":"code","b1c076b4":"code","22126ddc":"code","c14ddbbc":"code","1ef34321":"code","d04736af":"code","b6519ecd":"code","a8ba1897":"code","23858043":"code","08c7f045":"code","5c1c88bf":"markdown","bc83803a":"markdown","0f46184c":"markdown"},"source":{"515ddf41":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c81e6384":"# Use relevant imports as needed for running the functions\n\n#Data Library Imports\nimport pandas as pd\nimport numpy as np\n\nfrom collections import Counter\n\n","820ccb86":"# Data Visualization imports\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style='white', context='notebook', palette='deep')","bfe7f4d7":"#Model Cross Validation Imports\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve","6bc4c4c1":"#Model Algo Imports\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC","b1c076b4":"# Multiple Outlier detection in a given dataset\nfrom collections import Counter\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey (Tukey JW., 1977) method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n\"\"\"\nReference : https:\/\/www.kaggle.com\/yassineghouzam\/titanic-top-4-with-ensemble-modeling\nSample Usage -  \n\nOutliers_to_drop = detect_outliers(train_dataset,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]) # Call the multiple outlier detection function\ntrain_dataset.loc[Outliers_to_drop] # Show the outliers rows\ntrain_dataset = train_dataset.drop(Outliers_to_drop, axis = 0).reset_index(drop=True) # Drop outliers\n\nNotes from author of the original function in Kaggle Kernel -\nSince outliers can have a dramatic effect on the prediction (espacially for regression problems), i choosed to manage them.\nI used the Tukey method (Tukey JW., 1977) to detect ouliers which defines an interquartile range comprised between the 1st and 3rd quartile of the distribution values (IQR). \nAn outlier is a row that have a feature value outside the (IQR +- an outlier step).I decided to detect outliers from the numerical values features (Age, SibSp, Sarch and Fare). \nThen, i considered outliers as rows that have at least two (n) outlier numerical values.\n\n\"\"\"","22126ddc":"# Joining two dataframes with same number and type of columns and returning the combined dataframe with combined rows (axis=0)\ndef join_two_dataframes_having_same_features(df1,df2):\n    joined_dataframe =  pd.concat(objs=[df1, df2], axis=0).reset_index(drop=True)\n    return joined_dataframe\n\"\"\"\nUsage - \nJoin train and test dataframe for feature engineering\ncombined_dataframe = join_two_dataframes_having_same_features(train_dataframe,test_dataframe)\n\"\"\"","c14ddbbc":"# High Level Review and Analysis of a given dataset\n# Provides  decribe, info , data types , null summary, head, tail of the given dataframe.\n# Usually used in the inital stage before visual and detailed exploration of dataset\n\n\ndef inital_review_of_dataframe(df):\n    # Fill empty and NaNs values with NaN\n    df = df.fillna(np.nan)\n    print(\"Info of DataFrame : \", df.info())\n    print(\"Is Null Summary : \", df.isnull().sum())\n    print(\"Data Types : \", df.dtypes)\n    print(\"Summary and Stats of Numerical Variables: \", df.describe(percentiles=[0.01,0.1,0.25,0.5,0.75,0.9,0.99]))\n    print(\"Summary and Stats of Object type or Categorical Variables: \", df.describe(include=['O']))\n    print(\"First few records : \", df.head())\n    print(\"Last few records : \", df.tail())\n\n\"\"\"\nUsage - \ninital_review_of_dataframe(train_dataframe)\n\"\"\"","1ef34321":"# Visual Plot Analysis of correlations between 3 features and 1 target variable y in a dataframe df \n\n#import library if not done previously\nimport seaborn as sns\nimport warnings\n\n\ndef correl_plt_of_3features_with_1target(y,df,feature1, feature2, feature3):\n    warnings.filterwarnings(\"ignore\")\n    sns.set(style='white', context='notebook', palette='deep')\n    g = sns.heatmap(df[[feature1,feature2,feature3,y]].corr(), vmin = -1, annot=True, fmt = \".2f\", cmap = \"coolwarm\")\n\n\"\"\"\nUsage - \ncorrel_plt_of_3features_with_1target(target_var_name, train_dataframe, feature1_name, feature2_name, feature3_name)\n\"\"\"","d04736af":"# Visual Data Exploration Function for 3 category type variables and 1 numerical variable in a DataFrame using catplot of Seaborn\n\ndef catplots_with_3cat1num_vars(df,numvar,catvar1,catvar2,catvar3):\n    \n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    sns.set(style='ticks', context='notebook', palette='deep')\n    \n    fig, ax = plt.subplots(1,3,sharex = True,figsize=(25,5))\n    sns.catplot(x=catvar1,data=df, kind = \"count\",ax=ax[0]) \n    plt.close()\n    sns.catplot(x=catvar2,data=df, kind = \"count\",ax=ax[1])\n    plt.close()\n    sns.catplot(x=catvar3,data=df, kind = \"count\",ax=ax[2])\n    plt.close()\n    \n    fig, ax = plt.subplots(1,2,sharex = True,figsize=(25,10))\n    g1 = sns.catplot(x=catvar1, y=numvar, hue=catvar2, data=df, ax=ax[0])\n    plt.close()\n    g2 = sns.catplot(x=catvar1, y=numvar, hue=catvar2, data=df, kind = \"swarm\", ax=ax[1])\n    plt.close()    \n    \n    fig, ax = plt.subplots(1,2,sharex = True,figsize=(25,10))\n    g3 = sns.catplot(x=catvar1, y=numvar, hue=catvar2, data=df, kind = \"bar\", ax=ax[0])\n    plt.close()    \n    g4 = sns.catplot(x=catvar1, y=numvar, hue=catvar2, data=df, kind = \"violin\", ax=ax[1])\n    plt.close()\n\n    fig, ax = plt.subplots(1,2,sharex = True,figsize=(25,10))\n    g5 = sns.catplot(x=catvar1, y=numvar, hue=catvar2, data=df, kind = \"box\", ax=ax[0])\n    plt.close()\n    g6 = sns.catplot(x=catvar1, y=numvar, hue=catvar2, data=df, kind = \"boxen\", ax=ax[1])\n    plt.close()\n    \n    g7 = sns.catplot(x=catvar1, y=numvar, hue=catvar2, data=df, kind = \"point\")\n    g8 = sns.catplot(x=catvar1, y=numvar, hue=catvar2, col=catvar3, col_wrap=4, data=df, height=5, aspect=.8)\n    \n    \n\"\"\"\nUsage - \ncatplots_with_3cat1num_vars(train_dataframe,numerical_var_name,categorical_var_name1,categorical_var_name2,categorical_var_name3)\n\"\"\"","b6519ecd":"# Visual Data Exploration Function for 2 variables in a DataFrame using regplot of Seaborn\n\nimport seaborn as sns\nimport warnings\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\ndef regplot_with_2vars(df,xvar,yvar,color_choice ='r', jitter = 0):\n    sns.set(color_codes=True)\n    ax = sns.regplot(x=xvar, y=yvar, data=df,color = color_choice, x_jitter = jitter, y_jitter = jitter)\n    \n\"\"\"\nUsage - \nregplot_with_2vars(train_dataframe,xaxis_varname,yaxis_varname,'g',0.1)\n\"\"\"","a8ba1897":"# Visual Data Exploration Function for a variable in a DataFrame to plot distribution using distplot of Seaborn\ndef plot_distribution_1var(df,varname,xsize = 25, ysize = 12, color_choice = 'r' ):\n    \n    df[varname] = df[varname].fillna(df[varname].median())\n    x = df[varname]\n   \n    ax = sns.distplot(df[varname], rug=True, rug_kws={\"color\": color_choice},\n                   kde_kws={\"color\": \"k\", \"lw\": 3, \"label\": \"KDE-Kernel Density Estimate\"},\n                   label=\"Skewness : %.2f\"%(x.skew()),\n                   hist_kws={\"histtype\": \"step\", \"linewidth\": 3,\n                             \"alpha\": 1, \"color\": color_choice})\n    ax.figure.set_size_inches(xsize, ysize)\n    ax = ax.legend(loc=\"best\")\n    \n    \n\"\"\"\nUsage - \nplot_distribution_1var(train_datafeame,Varname,xaxis_size_opt,yaxis_size_opt,'g')\n\"\"\"","23858043":"#Log Transform the values of  a specific column in a dataframe and return the transformed set\ndef log_transform_dataframe_col(df,col_name):\n    x = df[col_name].map(lambda i: np.log(i) if i > 0 else 0)\n    return x\n\n\"\"\"\nUsage - \ntransformed = log_transform_dataframe_col(train_dataframe,column_name)\n\"\"\"","08c7f045":"#Create a panda series with subset of a panda dataframe string column based on pattern match\ndef create_series_from_pattern_in_anothercol(df,col_name,start_pattern,end_pattern):\n    patterns = [i.split(start_pattern)[1].split(end_pattern)[0].strip() for i in df[col_name]]\n    return pd.Series(patterns)\n\n\"\"\"\nUsage - \ntitles = []\ncolumn_name = \"Name\"\ntitles = create_newcol_from_pattern_in_anothercol(input_dataframe,column_name,',','.')\n\"\"\"","5c1c88bf":" **Python Custom Built Functions for fast tracking Predictions **","bc83803a":"**I have create a few common functions related to Data visualization and exploration that can help fast track our ML projects . Suggestions to add to this list is welcome.***","0f46184c":"****Libraries to Import****"}}