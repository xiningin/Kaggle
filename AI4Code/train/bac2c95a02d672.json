{"cell_type":{"4115acf2":"code","65d9cd7e":"code","a3fa3783":"code","22fa4410":"code","b6e3beff":"code","ed96db27":"code","e0540e75":"code","4408b7ea":"code","1b3da8a3":"code","d0076bd1":"code","63648c4e":"code","d4fae102":"code","90d5bd85":"code","1015890c":"code","9accf421":"code","00f50234":"code","2ff28ca4":"code","6e5477fb":"code","d80b20c2":"code","02010122":"code","646c1c89":"code","d6d6759a":"code","517aeb40":"markdown","47eb269e":"markdown","f2879feb":"markdown","c0c499db":"markdown","c113706a":"markdown","e1ebd61e":"markdown","2a7ea0ab":"markdown","1483ef5a":"markdown","3d755121":"markdown","646d1b6d":"markdown","9747a24e":"markdown","6fd118f0":"markdown","768e6dbb":"markdown","6138e7ea":"markdown","04bc85d9":"markdown","8eb6b839":"markdown","abd87a14":"markdown","515c98d8":"markdown"},"source":{"4115acf2":"# import basic library\nfrom sklearn.impute import SimpleImputer\nfrom IPython.display import display\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMRegressor\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostRegressor\nfrom catboost import CatBoostClassifier","65d9cd7e":"# import data\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a3fa3783":"# import train & test data\ntrain = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\")\nsample = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")","22fa4410":"# information about test and train data\ndisplay(train.info())\ndisplay(test.info())","b6e3beff":"# basic structure of train data\ntrain.head()","ed96db27":"# basic structure of train data 2\ntrain.describe().T","e0540e75":"print(\" train data\")\nprint(f' Number of rows: {train.shape[0]}\\n Number of columns: {train.shape[1]}\\n No. of missing values: {sum(train.isna().sum())}')","4408b7ea":"print(\" test data\")\nprint(f' Number of rows: {test.shape[0]}\\n Number of columns: {test.shape[1]}\\n No. of missing values: {sum(test.isna().sum())}')","1b3da8a3":"# number of misssing values by feature\nprint(\"number of misssing values by feature\")\ntrain.isnull().sum().sort_values(ascending = False)","d0076bd1":"# train_data missing values\nnull_values_train = []\nfor col in train.columns:\n    c = train[col].isna().sum()\n    pc = np.round((100 * (c)\/len(train)), 2)            \n    dict1 ={\n        'Features' : col,\n        'null_train (count)': c,\n        'null_trian (%)': '{}%'.format(pc)\n    }\n    null_values_train.append(dict1)\nDF1 = pd.DataFrame(null_values_train, index=None).sort_values(by='null_train (count)',ascending=False)\n\n\n# test_data missing values\nnull_values_test = []\nfor col in test.columns:\n    c = test[col].isna().sum()\n    pc = np.round((100 * (c)\/len(test)), 2)            \n    dict2 ={\n        'Features' : col,\n        'null_test (count)': c,\n        'null_test (%)': '{}%'.format(pc)\n    }\n    null_values_test.append(dict2)\nDF2 = pd.DataFrame(null_values_test, index=None).sort_values(by='null_test (count)',ascending=False)\n\n\ndf = pd.concat([DF1, DF2], axis=1)\ndf","63648c4e":"df = pd.DataFrame()\ndf[\"n_missing\"] = train.drop([\"id\", \"claim\"], axis=1).isna().sum(axis=1)\ndf[\"claim\"] = train[\"claim\"].copy()\n\nfig, ax = plt.subplots(figsize=(12,5))\nax.hist(df[df[\"claim\"]==0][\"n_missing\"],\n        bins=10, edgecolor=\"black\",\n        color=\"darkseagreen\", alpha=0.7, label=\"claim is 0\")\nax.hist(df[df[\"claim\"]==1][\"n_missing\"],\n        bins=10, edgecolor=\"black\",\n        color=\"darkorange\", alpha=0.7, label=\"claim is 1\")\nax.set_title(\"Missing Values Distributionin in Each Target Class\", fontsize=20, pad=15)\nax.set_xlabel(\"Missing Values Per Row\", fontsize=14, labelpad=10)\nax.set_ylabel(\"Number of Rows\", fontsize=14, labelpad=10)\nax.legend(fontsize=14)\nplt.show();","d4fae102":"# looking at Claim column\nfig, ax = plt.subplots(figsize=(6, 6))\n\nbars = ax.bar(train[\"claim\"].value_counts().index,\n              train[\"claim\"].value_counts().values,              \n              edgecolor=\"black\",\n              width=0.4)\nax.set_title(\"Claim (target) values distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Amount of values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Claim (target) value\", fontsize=14, labelpad=10)\nax.set_xticks(train[\"claim\"].value_counts().index)\nax.tick_params(axis=\"both\", labelsize=14)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in train[\"claim\"].value_counts().values\/(len(train)\/100)],\n                 padding=5, fontsize=15)\nax.bar_label(bars, [f\"{x:2d}\" for x in train[\"claim\"].value_counts().values],\n                 padding=-30, fontsize=15)\nax.margins(0.2, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","90d5bd85":"# proportion of no null in each row\ntrain1 = train[train.isna().sum(axis=1)==0]\nprint(\"proportion of no null data : %.2f\" %(len(train1)\/len(train)*100))\nprint(\"number of claim 1 in no null data : %d\" %(len(train1[train1['claim']==0])))\nprint(\"number of claim 0 in no null data : %d\" %(len(train1[train1['claim']==1])))","1015890c":"fig, ax = plt.subplots(figsize=(6, 6))\n\nbars = ax.bar(train1[\"claim\"].value_counts().index,\n              train1[\"claim\"].value_counts().values,              \n              edgecolor=\"black\",\n              width=0.4)\nax.set_title(\"Claim (target) values distribution\", fontsize=20, pad=15)\nax.set_ylabel(\"Amount of values\", fontsize=14, labelpad=15)\nax.set_xlabel(\"Claim (target) value\", fontsize=14, labelpad=10)\nax.set_xticks(train1[\"claim\"].value_counts().index)\nax.tick_params(axis=\"both\", labelsize=14)\nax.bar_label(bars, [f\"{x:2.2f}%\" for x in train1[\"claim\"].value_counts().values\/(len(train1)\/100)],\n                 padding=5, fontsize=15)\nax.bar_label(bars, [f\"{x:2d}\" for x in train1[\"claim\"].value_counts().values],\n                 padding=-30, fontsize=15)\nax.margins(0.2, 0.12)\nax.grid(axis=\"y\")\n\nplt.show();","9accf421":"target = train.pop('claim')","00f50234":"train_ = train[0:9579]\ntest_ = test[0:4934]","2ff28ca4":"# distribution of Features f1 to f60\nL = len(train.columns[0:60])\nnrow= int(np.ceil(L\/6))\nncol= 6\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\n#ax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\ni = 1\nfor feature in train.columns[0:60]:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.kdeplot(train_[feature], shade=True, color='cyan',  alpha=0.5, label='train')\n    ax = sns.kdeplot(test_[feature], shade=True, color='darkblue',  alpha=0.5, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    i += 1\nplt.suptitle('DistPlot: train & test data', fontsize=20)\nplt.show()","6e5477fb":"# distribution of Features f61 to f118\nL = len(train.columns[60:])\nnrow= int(np.ceil(L\/6))\nncol= 6\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(24, 30))\n#ax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\ni = 1\nfor feature in train.columns[60:]:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.kdeplot(train_[feature], shade=True, color='cyan',  alpha=0.5, label='train')\n    ax = sns.kdeplot(test_[feature], shade=True, color='darkblue',  alpha=0.5, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    i += 1\nplt.suptitle('DistPlot: train & test data', fontsize=20)\nplt.show()","d80b20c2":"# outlier of train data\ndf_plot = ((train - train.min())\/(train.max() - train.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\nsns.boxplot(data = df_plot.iloc[:, 1:30], ax = ax[0])\nsns.boxplot(data = df_plot.iloc[:, 30:60], ax = ax[1])\nsns.boxplot(data = df_plot.iloc[:, 60:90], ax = ax[2])\nsns.boxplot(data = df_plot.iloc[:, 90:120], ax = ax[3])","02010122":"# outlier of test data\ndf_plot = ((test - test.min())\/(test.max() - test.min()))\nfig, ax = plt.subplots(4, 1, figsize = (25,25))\nsns.boxplot(data = df_plot.iloc[:, 1:30], ax = ax[0])\nsns.boxplot(data = df_plot.iloc[:, 30:60], ax = ax[1])\nsns.boxplot(data = df_plot.iloc[:, 60:90], ax = ax[2])\nsns.boxplot(data = df_plot.iloc[:, 90:119], ax = ax[3])","646c1c89":"# correlation of train\ncorr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nplt.figure(figsize = (15, 15))\nplt.title('Corelation matrix')\nsns.heatmap(corr, mask = mask, cmap = 'Spectral_r', linewidths = .5)\n\nplt.show()","d6d6759a":"# correlation of train\ncorr = test.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nplt.figure(figsize = (15, 15))\nplt.title('Corelation matrix')\nsns.heatmap(corr, mask = mask, cmap = 'Spectral_r', linewidths = .5)\n\nplt.show()","517aeb40":"- It is vague to understand what features are through the describe.","47eb269e":"## 1.3 Cheacking the Distribution of Features.","f2879feb":"- The correlation between the two data are also similar.\n- Overall, every feature in both training and testing sets are vary similar.","c0c499db":"# 0. Setting","c113706a":"## 0.1 Calling Basic Libraries","e1ebd61e":"- Boxplots show that both training and testing sets are similarly distributed.","2a7ea0ab":"## 1.4 Cheacking the Box-plots","1483ef5a":"- 120 columns in train data\n\n > The dataset includes 118 features and one target variable, 'claim'.","3d755121":"## 1.1 Skimming the Data sets","646d1b6d":"# 1. EDA","9747a24e":"- Before the Nan-values are dropped, 'claim' = 0 and 1 have approximately have same number of rows.","6fd118f0":"- The plot shows that the rows have missing values and claim = 0 is skewed to the first few rows.\n- The rows have missing values and claim = 1 are more likely distributed then claim = 0.","768e6dbb":"## 0.2 Data Setting","6138e7ea":"- However, if Nan-values are dropped, then proportion of 'claim' = 0 and 1 are vary different.\n- The plot tells most of missing values are located in rows where 'claim' = 1.\n- Thus, it will be inbalanced if the Nan-values are simply dropped.\n","04bc85d9":"- The training set has 1,820,782 missing values.\n- The testing set has 936,218 missing values.","8eb6b839":"- It seems like every feature has approximatley same number of missing values.","abd87a14":"- Features in both traing and testing sets have similar distribution.\n- Thus, it is expected that the same imputation is going to be worked for both training snd testing sets.","515c98d8":"## 1.2 Cheacking the Missing Values"}}