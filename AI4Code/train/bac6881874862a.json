{"cell_type":{"1702e233":"code","f21fd8a0":"code","201a79a5":"code","0728c0a8":"code","17253157":"code","d8c5946f":"code","3cdd42e2":"code","4adeb0d1":"code","cf4a23b5":"code","a8506ff6":"code","d247fd60":"code","b79cc223":"code","53b61c28":"code","2ab151ca":"code","20b839ac":"code","561ca3d8":"code","94955fa0":"code","77c3cf01":"code","22c5abe0":"code","f98811ca":"code","ede807fe":"code","129ff4c5":"code","4be264eb":"code","ad1e9fd6":"code","de3d5741":"code","ef12c9a6":"code","8331a72a":"code","b0202ef0":"code","92518cdf":"code","d49542a2":"code","8c2e7d64":"markdown"},"source":{"1702e233":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f21fd8a0":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations import Normalize, Compose\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nimport os\nimport glob\nfrom matplotlib import pyplot as plt","201a79a5":"import cv2\nimport random","0728c0a8":" os.listdir('\/kaggle\/input\/cat-dataset\/')","17253157":"#Removes the .cat names in the end of some of the file names since it cannot be loaded with it.\n\ndef remove_dot_cat():\n    Folders =['CAT_03', 'CAT_01', 'CAT_04', 'CAT_00', 'CAT_06', 'CAT_02', 'CAT_05']\n    new_data = []\n    cate_data = []\n\n    for c in Folders:\n        for i in range(len(Folders)):\n            path1 = '\/kaggle\/input\/cat-dataset\/' + Folders[i] + '\/'\n            data = os.listdir(path1)\n            for img_name in data:\n                if 'cat' not in img_name:\n                    img_name = '\/kaggle\/input\/cat-dataset\/'+ c + '\/' + img_name\n                    new_data.append(img_name)\n                else:\n                    img_name = '\/kaggle\/input\/cat-dataset\/'+ c + '\/' + img_name\n                    img_name = img_name.replace('.cat', '')\n                    new_data.append(img_name)\n    return new_data\nnew_data = remove_dot_cat()","d8c5946f":"print('Before ->')\nprint(len(new_data))\nnew_data = new_data[:9000]\nprint('After ->')\nprint(len(new_data))","3cdd42e2":"dogs = os.listdir('..\/input\/cat-and-dog\/training_set\/training_set\/dogs')\ncat = os.listdir('..\/input\/cat-and-dog\/training_set\/training_set\/cats')","4adeb0d1":"print(len(cat))\nprint(len(dogs))","cf4a23b5":"type(cat)","a8506ff6":"#cat-and-dog   dataset\nIMG_SIZE = 100\ndef create_training_data():\n    PATHDIR = \"..\/input\/cat-and-dog\/\"\n    categories = [\"cats\",\"dogs\"]\n\n    \n    training_data2 = []\n    \n    for c in categories:\n        for img_name in os.listdir(os.path.join(PATHDIR,\"training_set\/training_set\",c)):\n            img_path = os.path.join(PATHDIR,\"training_set\/training_set\",c,img_name)\n            img_arr = cv2.imread(img_path,0)\n            try:\n                resized = cv2.resize(img_arr, (IMG_SIZE,IMG_SIZE))\n                norm_arr = resized\/255\n                training_data2.append([norm_arr, categories.index(c)])\n            except Exception as e:\n                pass\n    random.shuffle(training_data2)\n    return training_data2\n\ntraining_data2 = create_training_data()","d247fd60":"len(training_data2)","b79cc223":"#cat-dataet\ndef create_training_data2():\n    training_data = []\n    categories = [\"cats\"]\n    IMG_SIZE = 100\n    labels = []\n    for i in categories:\n        for c in new_data:\n            img_arr = cv2.imread(i,0) # cv2.imread loads an image from the specified file, note that the flag is set to 0 \n            #which means that we load an image in grayscale mode. note also that everytime we use imread the flag has to be the same \n            try:\n                resized = cv2.resize(img_arr, (IMG_SIZE,IMG_SIZE))\n                norm_arr = resized\/255\n                training_data.append([img_arr, categories.index(i)]) #categories.index(i) puts the cats images in index 0 the same\n                #as for the other dataset in create_training_data above if we have more categories it will be added in categories\n                labels.append()\n            except Exception as e:\n                pass\n#     random.shuffle(training_data)\n    return training_data\n\ntraining_data = create_training_data2()","53b61c28":"len(training_data)","2ab151ca":"len(training_data2 + training_data)","20b839ac":"train_images = training_data2 + training_data ","561ca3d8":"# print(50*50)\n# print(2500*3)","94955fa0":"# train_images = train_images[:7500]","77c3cf01":"len(train_images)","22c5abe0":"X = []\ny = []\n\nfor images,columns in train_images:  #for each image there are a name which is in column\n    X.append(images)\n    y.append(columns)\n\n\nX = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE,1)\ny = np.array(y)","f98811ca":"len(X)","ede807fe":"len(y)","129ff4c5":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout","4be264eb":"model = Sequential()\n\n#First Layer\nmodel.add(Conv2D(64, (3,3), input_shape = (IMG_SIZE,IMG_SIZE,1)))\nmodel.add(MaxPooling2D(pool_size= (2,2)))\nmodel.add(Flatten())\n\n#Second Layer\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.2))\n\n#Output Layer\nmodel.add(Dense(10, activation = \"softmax\"))\n\nmodel.summary()","ad1e9fd6":"model.compile(optimizer = \"adam\",\n             loss =\"sparse_categorical_crossentropy\",\n             metrics = [\"accuracy\"])\n\nmodel.fit(X,y, epochs = 20)","de3d5741":"def create_testing_data():\n    testing_data = []\n    PATHDIR = \"..\/input\/cat-and-dog\/\"\n    categories = [\"cats\",\"dogs\"]\n    for c in categories:\n        for img_name in os.listdir(os.path.join(PATHDIR,\"training_set\/training_set\",c)):\n            img_path = os.path.join(PATHDIR,\"training_set\/training_set\",c,img_name)\n            img_arr = cv2.imread(img_path,0)\n            try:\n                resized = cv2.resize(img_arr, (IMG_SIZE,IMG_SIZE))\n                norm_arr = resized\/255\n                testing_data.append([norm_arr, categories.index(c)])\n            except Exception as e:\n                pass\n    random.shuffle(testing_data)\n    return testing_data\n\ntest_data = create_testing_data()","ef12c9a6":"X_test = []\ny_test = []\n\nfor features,labels in test_data:\n    X_test.append(features)\n    y_test.append(labels)\n    \nX_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE,1)\ny_test = np.array(y_test)","8331a72a":"model.evaluate(X_test, y_test)","b0202ef0":"import matplotlib.pyplot as plt","92518cdf":"img_path = \"\/kaggle\/input\/cat-dataset\/CAT_03\/00000831_005.jpg\"\nimg_arr = cv2.imread(img_path,0)\nimg_arr = cv2.resize(img_arr, (IMG_SIZE,IMG_SIZE))\nnorm_arr = img_arr\/255\npred_img = (norm_arr)\n    \n    \npred_img = pred_img.reshape(100,100,1)","d49542a2":"test_img = pred_img\ntest_img = test_img.reshape(1,IMG_SIZE,IMG_SIZE,1)\npredict_ = model.predict(test_img)[0]\n\nfor i in range(len(predict_)):\n    if(predict_[i] == max(predict_)):\n        if(i == 0):\n            print(\"This is a CAT!\")\n        else:\n            print(\"This is a DOG!\")\n        \nplt.imshow(test_img.reshape(IMG_SIZE,IMG_SIZE))","8c2e7d64":"# Cats vs Dogs\n\n## Note all .cat images are broken and a can only be used if you fix them or put them in a numpy array or someting else"}}