{"cell_type":{"c60497ee":"code","b56998d8":"code","c35ac3c5":"code","3bb4046c":"code","34ebb860":"code","9e26c5a7":"code","cc6abd8c":"code","070b1afa":"code","5ee43693":"code","7cd1c9c9":"code","24e9a2a8":"code","aa31dec2":"code","ae14c54d":"code","08068821":"code","65e58dee":"code","40a9a4ff":"code","a6853895":"code","0fe5495c":"code","76775cf0":"code","d8f801a6":"code","36e8be75":"code","98b758e9":"code","9cc1f9e3":"code","ce0661a5":"code","64d85e16":"code","59445e70":"code","a2d57d74":"code","028c3c9c":"code","a1994bcf":"code","894a86d7":"markdown","4dfbc0c2":"markdown","61288215":"markdown","57ab1305":"markdown","85c7107a":"markdown","951125eb":"markdown","9a69b29b":"markdown","765ce75a":"markdown","11b9bd47":"markdown","7cc8871f":"markdown","3fa84de1":"markdown","26a37359":"markdown","da75403a":"markdown","533df743":"markdown"},"source":{"c60497ee":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport itertools\nimport re\nimport nltk\n\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier","b56998d8":"train_data = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip')\ntest_data = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv.zip')","c35ac3c5":"train_data.head()","3bb4046c":"train_data.tail()","34ebb860":"data = train_data.copy()","9e26c5a7":"comments = data['comment_text'].to_numpy()\nlabels = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].to_numpy()","cc6abd8c":"dataframe = []\nfor index in range(len(labels)):\n    num = np.count_nonzero(labels[index])\n    if(num == 0):\n        dataframe.append([comments[index], 0])\n    else:\n        dataframe.append([comments[index], 1])","070b1afa":"df = pd.DataFrame(dataframe, columns = ['comment', 'label'])","5ee43693":"df.head()","7cd1c9c9":"df.tail()","24e9a2a8":"ax = plt.subplot()\n\ng = sns.countplot(df.label)\ng.set_xticklabels(['Toxic', 'Not Toxic'])\ng.set_yticklabels(['Count'])\n\n# function to show values on bars\ndef show_values_on_bars(axs):\n    def _show_on_single_plot(ax):        \n        for p in ax.patches:\n            _x = p.get_x() + p.get_width() \/ 2\n            _y = p.get_y() + p.get_height()\n            value = '{:.0f}'.format(p.get_height())\n            ax.text(_x, _y, value, ha=\"center\") \n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)\nshow_values_on_bars(ax)\n\nsns.despine(left=True, bottom=True)\nplt.xlabel('')\nplt.ylabel('')\nplt.title('Distribution of Classes', fontsize=30)\nplt.tick_params(axis = 'x', which='major', labelsize=15)\nplt.show()","aa31dec2":"df['label'].value_counts()","ae14c54d":"count_class_toxic, count_class_non_toxic = df.label.value_counts()\n\nclass_toxic = df[df['label'] == 0]\nclass_not_toxic = df[df['label'] == 1]","08068821":"class_not_toxic_over = class_not_toxic.sample(count_class_toxic, replace = True)\ntest_over = pd.concat([class_toxic, class_not_toxic_over], axis = 0)\nprint(test_over.label.value_counts())","65e58dee":"test_over.head()","40a9a4ff":"test_over.tail()","a6853895":"new_filter = test_over[\"comment\"] != \"\"\ntest_over = test_over[new_filter]\ntest_over = test_over.dropna()","0fe5495c":"def preprocessing_text(sen):\n    # Remove punctuations and numbers\n    sent = re.sub('[^a-zA-Z]', ' ', sen)\n\n    # Single character removal\n    sent = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sent)\n\n    # Removing multiple spaces\n    sent = re.sub(r'\\s+', ' ', sent)\n\n    return sent","76775cf0":"X_new = []\nnew_sentences = list(test_over[\"comment\"])\nfor sents in new_sentences:\n    X_new.append(preprocessing_text(sents))","d8f801a6":"new_stopwords = stopwords.words('english')","36e8be75":"vectorizer_new = TfidfVectorizer(stop_words = new_stopwords, use_idf = True)\nbag_of_words_new = vectorizer_new.fit_transform(X_new)","98b758e9":"x = bag_of_words_new\ny = test_over['label']\nX_train_old, X_test_old, Y_train_old, Y_test_old = train_test_split(x, y, test_size = 0.25, random_state = 27)","9cc1f9e3":"rf_clf_resampled = RandomForestClassifier(25)\nrf_clf_resampled.fit(X_train_old, Y_train_old)","ce0661a5":"rf_predict_resampled = rf_clf_resampled.predict(X_test_old)","64d85e16":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","59445e70":"rf_cm_resampled = confusion_matrix(Y_test_old, rf_predict_resampled)\nplot_confusion_matrix(rf_cm_resampled, [0, 1])\nplt.show()","a2d57d74":"print('Accuracy Score:', accuracy_score(Y_test_old, rf_predict_resampled))\nprint('Precision:', precision_score(Y_test_old, rf_predict_resampled))\nprint('Recall:',recall_score(Y_test_old, rf_predict_resampled))\nprint('F1 Score:', f1_score(Y_test_old, rf_predict_resampled))","028c3c9c":"print(\"Area under curve for Random Forest:\", roc_auc_score(Y_test_old, rf_predict_resampled))","a1994bcf":"score_rf = cross_val_score(rf_clf_resampled, x, y, cv = 5)\nprint(\"CV score {}\".format(np.mean(score_rf)))","894a86d7":"# Creating the dataframe","4dfbc0c2":"# ROC curve evaluation","61288215":"Now performing the following operations on resampled data:\n1. Data Cleaning\n2. Vectorization\n3. Train Test split\n\n# Data Cleaning","57ab1305":"# Comments and labels as numpy","85c7107a":"# Vectorization","951125eb":"Resampled data equally","9a69b29b":"### Confusion Matrix","765ce75a":"# Resampling Data\n\n## Oversampling minority class","11b9bd47":"For an ideal classifier the area under curve is 1.0 so Random Forest is close enough to being called an ideal classifier","7cc8871f":"Considerable imbalance {0 : 143346, 1 : 16225}\n\nNow lets check the performance of provided data without training the model","3fa84de1":"## Random Forest","26a37359":"# Train Test split","da75403a":"# Checking imbalancing","533df743":"### Performance Measure"}}