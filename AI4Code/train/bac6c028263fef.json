{"cell_type":{"8a3caab2":"code","c0bbecef":"code","da486bdd":"code","68f6c1e8":"code","2d809d1c":"code","e5277162":"code","2192e5fb":"code","acee5240":"code","9dbbac85":"code","c8614e91":"code","ebe14f0e":"code","f6fbd6ba":"code","3ef87791":"code","8fab4ab6":"code","9e3d00bd":"code","597457d0":"code","84a20f7d":"code","38f4cd8f":"code","3b736030":"code","98e4cc55":"code","6f9a55d5":"code","b48a2181":"code","1716003b":"code","43713a20":"code","83bc8ee9":"code","d7ccd0ca":"code","307972c5":"code","aa035381":"code","c19bf236":"code","60da10b7":"code","fac26ed4":"code","11eefe9f":"code","bb77ac78":"code","8834f8e6":"code","f3613c33":"code","7e638036":"code","a9d08ceb":"code","ddde9e9e":"code","cdc132dd":"code","9981c004":"code","5d90c86f":"code","5dd12786":"code","ae405fa8":"markdown","6f6c5686":"markdown","3e3e4323":"markdown","88bada68":"markdown","e94344a8":"markdown","6679344e":"markdown","e3cfb6bc":"markdown","30036635":"markdown","477ea05c":"markdown","25556c4b":"markdown"},"source":{"8a3caab2":"import numpy as np # linear algebra\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline","c0bbecef":"test = [1,2,3,4,15]\nnp.zeros((3,3))\nnp.pi\nnp.clip(test,2,4)\nnp.median(test)\nnp.mean(test)\nnp.diag((5,5,5))\nnp.sum(test)\nnp.max(test)\nnp.min(test)\nnp.exp(1)","da486bdd":"n = 4\nres = []\nfor i in range(1, n):\n    res.append((1+ 1\/i)**i)\nplt.plot(res)","68f6c1e8":"img = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg')\nimg = img[50:274,100:324]\nplt.figure()\nplt.imshow(img)\nplt.axis('off')\nplt.show();","2d809d1c":"def gaussian_filter(img, K_size=3, sigma=1.3):\n    if len(img.shape) == 3:\n        H, W, C = img.shape\n    else:\n        img = np.expand_dims(img, axis=-1)\n        H, W, C = img.shape\n\n    ## Zero padding\n    pad = K_size \/\/ 2\n    out = np.zeros((H + pad * 2, W + pad * 2, C), dtype=np.float)\n    out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n\n    ## prepare Kernel\n    K = np.zeros((K_size, K_size), dtype=np.float)\n    for x in range(-pad, -pad + K_size):\n        for y in range(-pad, -pad + K_size):\n            K[y + pad, x + pad] = np.exp( -(x ** 2 + y ** 2) \/ (2 * (sigma ** 2)))\n    K \/= (2 * np.pi * sigma * sigma)\n    K \/= K.sum()\n\n    tmp = out.copy()\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            for c in range(C):\n                out[pad + y, pad + x, c] = np.sum(K * tmp[y: y + K_size, x: x + K_size, c])\n\n    out = np.clip(out, 0, 255)\n    out = out[pad: pad + H, pad: pad + W].astype(np.uint8)\n\n    return out","e5277162":"img = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg')\nimg = img[50:274,100:324]\nout = gaussian_filter(img, K_size=11)\nplt.figure()\nplt.imshow(out)\nplt.axis('off')\nplt.show();","2192e5fb":"def median_filter(img, K_size=3):\n    H, W, C = img.shape\n\n    ## Zero padding\n    pad = K_size \/\/ 2\n    out = np.zeros((H + pad*2, W + pad*2, C), dtype=np.float)\n    out[pad:pad+H, pad:pad+W] = img.copy().astype(np.float)\n\n    tmp = out.copy()\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            for c in range(C):\n                out[pad+y, pad+x, c] = np.median(tmp[y:y+K_size, x:x+K_size, c])\n\n    out = out[pad:pad+H, pad:pad+W].astype(np.uint8)\n\n    return out","acee5240":"img = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg')\nimg = img[50:274,100:324]\nplt.figure()\nplt.imshow(img)\nplt.axis('off')\nplt.show();","9dbbac85":"img = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg')\nimg = img[50:274,100:324]\nout = median_filter(img, K_size=11)\nplt.figure()\nplt.imshow(out)\nplt.axis('off')\nplt.show();","c8614e91":"def motion_filter(img, K_size=3):\n    H, W, C = img.shape\n\n    # Kernel\n    K = np.diag( [1] * K_size ).astype(np.float)\n    K \/= K_size\n\n    # zero padding\n    pad = K_size \/\/ 2\n    out = np.zeros((H + pad * 2, W + pad * 2, C), dtype=np.float)\n    out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n    tmp = out.copy()\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            for c in range(C):\n                out[pad + y, pad + x, c] = np.sum(K * tmp[y: y + K_size, x: x + K_size, c])\n\n    out = out[pad: pad + H, pad: pad + W].astype(np.uint8)\n\n    return out","ebe14f0e":"img = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg')\nimg = img[50:274,100:324]\nout = motion_filter(img, K_size=11)\nplt.figure()\nplt.imshow(out)\nplt.axis('off')\nplt.show();","f6fbd6ba":"def max_min_filter_3(img, K_size=3):\n    H, W, C = img.shape\n\n    # Zero padding\n    pad = K_size \/\/ 2\n    out = np.zeros((H + pad * 2, W + pad * 2, C), dtype=np.float)\n    out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n    tmp = out.copy()\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            for c in range(C):\n                out[pad + y, pad + x,c] = np.max(tmp[y: y + K_size, x: x + K_size, c]) - \\\n                    np.min(tmp[y: y + K_size, x: x + K_size, c])\n\n    out = out[pad: pad + H, pad: pad + W].astype(np.uint8)\n\n    return out","3ef87791":"img = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg')\nimg = img[50:274,100:324]\nout = max_min_filter_3(img, K_size=3)\nplt.figure()\nplt.imshow(out)\nplt.axis('off')\nplt.show();","8fab4ab6":"def BGR2GRAY(img):\n    b = img[:, :, 0].copy()\n    g = img[:, :, 1].copy()\n    r = img[:, :, 2].copy()\n\n    # Gray scale\n    out = 0.2126 * r + 0.7152 * g + 0.0722 * b\n    out = out.astype(np.uint8)\n\n    return out\n\n# max-min filter\n\n\ndef max_min_filter_1(img, K_size=3):\n    H, W = img.shape\n\n    # Zero padding\n    pad = K_size \/\/ 2\n    out = np.zeros((H + pad * 2, W + pad * 2), dtype=np.float)\n    out[pad: pad + H, pad: pad + W] = gray.copy().astype(np.float)\n    tmp = out.copy()\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            out[pad + y, pad + x] = np.max(tmp[y: y + K_size, x: x + K_size]) - \\\n                np.min(tmp[y: y + K_size, x: x + K_size])\n\n    out = out[pad: pad + H, pad: pad + W].astype(np.uint8)\n\n    return out\nimg = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg').astype(np.float)\nimg = img[50:274,100:324]\ngray = BGR2GRAY(img)\nout = max_min_filter_1(gray, K_size=3)\nplt.figure()\nplt.imshow(out)\nplt.axis('off')\nplt.show();","9e3d00bd":"def BGR2GRAY(img):\n    b = img[:, :, 0].copy()\n    g = img[:, :, 1].copy()\n    r = img[:, :, 2].copy()\n\n    # Gray scale\n    out = 0.2126 * r + 0.7152 * g + 0.0722 * b\n    out = out.astype(np.uint8)\n\n    return out\n\n\n# sobel filter\ndef sobel_filter(img, K_size=3):\n    if len(img.shape) == 3:\n        H, W, C = img.shape\n    else:\n        img = np.expand_dims(img, axis=-1)\n        H, W, C = img.shape\n\n    # Zero padding\n    pad = K_size \/\/ 2\n    out = np.zeros((H + pad * 2, W + pad * 2), dtype=np.float)\n    out[pad: pad + H, pad: pad + W] = gray.copy().astype(np.float)\n    tmp = out.copy()\n\n    out_v = out.copy()\n    out_h = out.copy()\n\n    ## Sobel vertical\n    Kv = [[1., 2., 1.],[0., 0., 0.], [-1., -2., -1.]]\n    ## Sobel horizontal\n    Kh = [[1., 0., -1.],[2., 0., -2.],[1., 0., -1.]]\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            out_v[pad + y, pad + x] = np.sum(Kv * (tmp[y: y + K_size, x: x + K_size]))\n            out_h[pad + y, pad + x] = np.sum(Kh * (tmp[y: y + K_size, x: x + K_size]))\n\n    out_v = np.clip(out_v, 0, 255)\n    out_h = np.clip(out_h, 0, 255)\n\n    out_v = out_v[pad: pad + H, pad: pad + W].astype(np.uint8)\n    out_h = out_h[pad: pad + H, pad: pad + W].astype(np.uint8)\n\n    return out_v, out_h","597457d0":"img = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg').astype(np.float)\nimg = img[50:274,100:324]\ngray = BGR2GRAY(img)\nout_v, out_h = sobel_filter(gray, K_size=3)\nplt.figure()\nplt.imshow(out_v)\nplt.axis('off')\nplt.show();","84a20f7d":"plt.figure()\nplt.imshow(out_h)\nplt.axis('off')\nplt.show();","38f4cd8f":"def laplacian_filter(img, K_size=3):\n    H, W = img.shape\n\n    # zero padding\n    pad = K_size \/\/ 2\n    out = np.zeros((H + pad * 2, W + pad * 2), dtype=np.float)\n    out[pad: pad + H, pad: pad + W] = gray.copy().astype(np.float)\n    tmp = out.copy()\n\n    # laplacian kernle\n    K = [[0., 1., 0.],[1., -4., 1.], [0., 1., 0.]]\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            out[pad + y, pad + x] = np.sum(K * (tmp[y: y + K_size, x: x + K_size]))\n\n    out = np.clip(out, 0, 255)\n    out = out[pad: pad + H, pad: pad + W].astype(np.uint8)\n\n    return out","3b736030":"img = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg').astype(np.float)\nimg = img[50:274,100:324]\ngray = BGR2GRAY(img)\nout = laplacian_filter(gray, K_size=3)\nplt.figure()\nplt.imshow(out)\nplt.axis('off')\nplt.show();","98e4cc55":"def emboss_filter(img, K_size=3):\n    H, W = img.shape\n\n    # zero padding\n    pad = K_size \/\/ 2\n    out = np.zeros((H + pad * 2, W + pad * 2), dtype=np.float)\n    out[pad: pad + H, pad: pad + W] = gray.copy().astype(np.float)\n    tmp = out.copy()\n\n    # emboss kernel\n    K = [[-2., -1., 0.],[-1., 1., 1.], [0., 1., 2.]]\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            out[pad + y, pad + x] = np.sum(K * (tmp[y: y + K_size, x: x + K_size]))\n\n    out = np.clip(out, 0, 255)\n    out = out[pad: pad + H, pad: pad + W].astype(np.uint8)\n\n    return out\nimg = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg').astype(np.float)\nimg = img[50:274,100:324]\ngray = BGR2GRAY(img)\nout = emboss_filter(gray, K_size=3)\nplt.figure()\nplt.imshow(out)\nplt.axis('off')\nplt.show();","6f9a55d5":"class Conv2d(num_filters = 64, kernel_size = 3):\n  # A Convolution layer using 3x3 filters.\n    def __init__(self, num_filters):\n        self.num_filters = num_filters\n        self.kernel_size = kernel_size\n\n    # filters is a 3d array with dimensions (num_filters, 3, 3)\n    # We divide by 9 to reduce the variance of our initial values\n        self.filters = np.random.randn(num_filters, 3, 3) \/ 9\n  \n    def iterate_regions(self, image):\n        '''\n        Generates all possible 3x3 image regions using valid padding.\n        - image is a 2d numpy array.\n        '''\n        h, w = image.shape\n\n        for i in range(h - 2):\n            for j in range(w - 2):\n                im_region = image[i:(i + 3), j:(j + 3)]\n                yield im_region, i, j\n                \n    def forward(self, input):\n        '''\n        Performs a forward pass of the conv layer using the given input.\n        Returns a 3d numpy array with dimensions (h, w, num_filters).\n        - input is a 2d numpy array\n        '''\n        self.last_input = input\n\n        h, w = input.shape\n        output = np.zeros((h - 2, w - 2, self.num_filters))\n\n        for im_region, i, j in self.iterate_regions(input):\n            output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n\n        return output\n\n    def backprop(self, d_L_d_out, learn_rate):\n        '''\n        Performs a backward pass of the conv layer.\n        - d_L_d_out is the loss gradient for this layer's outputs.\n        - learn_rate is a float.\n        '''\n        d_L_d_filters = np.zeros(self.filters.shape)\n\n        for im_region, i, j in self.iterate_regions(self.last_input):\n            for f in range(self.num_filters):\n                d_L_d_filters[f] += d_L_d_out[i, j, f] * im_region\n\n    # Update filters\n        self.filters -= learn_rate * d_L_d_filters\n        return None","b48a2181":"import torch\nimport torch.nn as nn\nimport torchvision.transforms.functional as F\nconv2d = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 3, stride = 1, padding = 1)\nimg = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg')\nimg = img[50:274,100:324]\nimg_tensor = torch.from_numpy(img)\nimg_tensor = img_tensor.permute(2, 0, 1)\nimg_tensor = img_tensor.unsqueeze(dim=0)\nout = conv2d(img_tensor.float())\nout.size()","1716003b":"def average_pooling(img, G=8): # \u5e73\u5747\u6c60\u5316\n    H, W, C = img.shape\n    Nh = int(H \/ G)\n    Nw = int(W \/ G)\n    out = img[:Nh,:Nw].copy()\n\n    for y in range(Nh):\n        for x in range(Nw):\n            for c in range(C):\n                out[y:y+1, x:x+1, c] = np.mean(img[G*y:G*(y+1), G*x:G*(x+1), c]).astype(np.int)\n    \n    return out\n\ndef max_pooling(img, G=8): # \u5e73\u5747\u6c60\u5316\n    H, W, C = img.shape\n    Nh = int(H \/ G)\n    Nw = int(W \/ G)\n    out = img[:Nh,:Nw].copy()\n\n    for y in range(Nh):\n        for x in range(Nw):\n            for c in range(C):\n                out[y:y+1, x:x+1, c] = np.max(img[G*y:G*(y+1), G*x:G*(x+1), c]).astype(np.int)\n    \n    return out","43713a20":"img = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg')\nplt.figure()\nplt.imshow(img)\nplt.axis('off')\nplt.show();\nprint(img.shape)","83bc8ee9":"out_mean = average_pooling(img, G=25)\nplt.figure()\nplt.imshow(out_mean)\nplt.axis('off')\nplt.show();\nprint(out.shape)","d7ccd0ca":"out_max = max_pooling(img, G=25)\nplt.figure()\nplt.imshow(out_mean)\nplt.axis('off')\nplt.show();\nprint(out.shape)","307972c5":"import torch\nimport torch.nn as nn\nimport torchvision.transforms.functional as F\nmaxp = nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1)\nimg = cv2.imread('..\/input\/cat-dataset\/CAT_00\/00000001_000.jpg')\nimg = img[50:274,100:324]\nimg_tensor = torch.from_numpy(img)\nimg_tensor = img_tensor.permute(2, 0, 1)\n#img_tensor = img_tensor.unsqueeze(dim=0)\nout = maxp(img_tensor.float())\nF.to_pil_image(out)","aa035381":"class Sigmoid():\n    def fn(self, x):\n        return 1 \/ (1 + np.exp(-x))\n    def grad(self, x):\n        return self.fn(x) * (1 - self.fn(x))\n    def grad2(self, x):\n        return self.grad(x) * (1 - 2 * self.fn(x))","c19bf236":"class ReLU():\n    def fn(self, x):\n        return np.clip(x, 0, np.inf)\n    def grad(self, x):\n        return (x > 0).astype(int)\n    def grad2(self, x):\n        return np.zeros_like(x)","60da10b7":"class LeakyReLU():\n    def __init__(self, alpha=0.3):\n        self.alpha = alpha\n    def fn(self, x):\n        _x = x.copy()\n        _x[x < 0] = _x[x < 0] * self.alpha\n        return _x\n    def grad(self, x):\n        out = np.ones_like(x)\n        out[x < 0] *= self.alpha\n        return out\n    def grad2(self, x):\n        return np.zeros_like(x)","fac26ed4":"class Tanh():\n    def fn(self, x):\n        return np.tanh(x)\n    def grad(self, x):\n        return 1 - np.tanh(x) ** 2\n    def grad2(self, x):\n        return -2 * np.tanh(x) * self.grad(x)","11eefe9f":"import torch.nn as nn\nact = nn.ReLU()\ntest = torch.randn((3,3,3))\ntest -= 0.3\ntest","bb77ac78":"output = act(test)\noutput","8834f8e6":"class SGD:\n    para = parameters\n    setting = hyperparameters\n    lr = learning rate\n    def update:\n        v = setting.momentum * v - lr * para_grad\n        return params + v\n\n    \nclass AdaGrad:\n    para = parameters\n    setting = hyperparameters\n    lr = learning rate\n    def update:\n        cache += para_grad ** 2\n        x += - lr * para_grad \/ (np.sqrt(cache) + eps)\n        return x\n    \nclass RMSProp:\n    para = parameters\n    setting = hyperparameters\n    lr = learning rate\n    decay_rate = decay rate\n    def update:\n        cache = decay_rate * cache + (1 - decay_rate) * para_grad ** 2\n        x += - lr * para_grad \/ (np.sqrt(cache) + eps)\n        return x\n    \nclass Adam:\n    para = parameters\n    setting = hyperparameters\n    lr = learning rate\n    beta1 = beta one\n    beta2 = beta two\n    def update:\n        m = beta1*m + (1\u2010beta1)*para_grad\n        v = beta2*v + (1\u2010beta2)*(para_grad**2)\n        x += \u2010 lr * m \/ (np.sqrt(v) + eps)\n        return x","f3613c33":"torch.optim.SGD(params, lr=0.1, momentum=0, weight_decay=0)\ntorch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0)\ntorch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0)\ntorch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)","7e638036":"class ConstantScheduler:\n    def __init__(self, lr=0.1):\n        self.lr = lr\n\n    def __call__(self, num_update):\n        return self.lr\nscheduler = ConstantScheduler(lr=0.2)\nn = 100\nres = []\nfor i in range(1, n):\n    res.append(scheduler(i))\nplt.plot(res)","a9d08ceb":"class StepScheduler:\n    def __init__(self, lr=0.1,mile_stones=[30,60],gamma=0.1):\n        self.lr = lr\n        self.gamma = gamma\n        self.mile_stones = mile_stones\n\n    def __call__(self, num_update):\n        if num_update in self.mile_stones:\n            self.lr *= self.gamma\n        return self.lr\nscheduler = StepScheduler(lr=0.1)\nn = 100\nres = []\nfor i in range(1, n):\n    res.append(scheduler(i))\nplt.plot(res)","ddde9e9e":"class SquareRootScheduler:\n    def __init__(self, lr=0.1):\n        self.lr = lr\n\n    def __call__(self, num_update):\n        return self.lr * pow(num_update + 1.0, -0.5)\nscheduler = SquareRootScheduler(lr=0.1)\nn = 100\nres = []\nfor i in range(1, n):\n    res.append(scheduler(i))\nplt.plot(res)","cdc132dd":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nmodel = [nn.Parameter(torch.randn(2, 2, requires_grad=True))]\noptimizer = optim.SGD(model,lr=0.0001)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\nscheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)","9981c004":"import numpy as np\nclass SquaredLoss:\n    def loss(y, y_pred):\n        return np.linalg.norm(y_pred-y) ** 2\n\nclass CrossEntropy:\n    def loss(y, y_pred):\n        eps = np.finfo(float).eps\n        return -np.sum(y * np.log(y_pred + eps))\neps = np.finfo(float).eps\neps","5d90c86f":"loss_L1 = nn.L1Loss()\nloss_MSE = nn.MSELoss()\nloss_CE = nn.CrossEntropyLoss()\ninput = torch.randn(3, 5, requires_grad=True)\ntarget = torch.randn(3, 5)\ntarget_CE = torch.empty(3, dtype=torch.long).random_(5)\noutput = loss_MSE(input, target)\noutput.backward()\noutput","5dd12786":"import numpy as np\n\nnp.random.seed(0)\n\nclass NN:\n    def __init__(self, ind=2, w=64, outd=1, lr=0.1):\n        self.w1 = np.random.normal(0, 1, [ind, w])\n        self.b1 = np.random.normal(0, 1, [w])\n        self.wout = np.random.normal(0, 1, [w, outd])\n        self.bout = np.random.normal(0, 1, [outd])\n        self.lr = lr\n\n    def forward(self, x):\n        self.z1 = x\n        self.z2 = sigmoid(np.dot(self.z1, self.w1) + self.b1)\n        self.out = sigmoid(np.dot(self.z2, self.wout) + self.bout)\n        return self.out\n\n    def train(self, x, t):\n        # backpropagation output layer\n        #En = t * np.log(self.out) + (1-t) * np.log(1-self.out)\n        En = (self.out - t) * self.out * (1 - self.out)\n        grad_En = En #np.array([En for _ in range(t.shape[0])])\n        grad_wout = np.dot(self.z2.T, En)\n        grad_bout = np.dot(np.ones([En.shape[0]]), En)\n        self.wout -= self.lr * grad_wout#np.expand_dims(grad_wout, axis=-1)\n        self.bout -= self.lr * grad_bout\n\n        # backpropagation inter layer\n        grad_u1 = np.dot(En, self.wout.T) * self.z2 * (1 - self.z2)\n        grad_w1 = np.dot(self.z1.T, grad_u1)\n        grad_b1 = np.dot(np.ones([grad_u1.shape[0]]), grad_u1)\n        self.w1 -= self.lr * grad_w1\n        self.b1 -= self.lr * grad_b1\n\ndef sigmoid(x):\n    return 1. \/ (1. + np.exp(-x))\n\ntrain_x = np.array([[0,0], [0,1], [1,0], [1,1]], dtype=np.float32)\ntrain_t = np.array([[0], [1], [1], [0]], dtype=np.float32)\n\nnn = NN(ind=train_x.shape[1])\n\n# train\nfor i in range(10000):\n    nn.forward(train_x)\n    nn.train(train_x, train_t)\n\n# test\nfor j in range(4):\n    x = train_x[j]\n    t = train_t[j]\n    print(\"in:\", x, \"pred:\", nn.forward(x))","ae405fa8":"# Activations\n![](https:\/\/github.com\/zlannnn\/numpy-ml\/blob\/master\/neural_nets\/activations\/img\/plot.png?raw=true)!","6f6c5686":"# **Convolution**","3e3e4323":"# A simple NN","88bada68":"# Numpy\nNumPy\u662fPython\u8bed\u8a00\u7684\u4e00\u4e2a\u6269\u5c55\u7a0b\u5e8f\u5e93\u3002\u652f\u6301\u9ad8\u9636\u5927\u91cf\u7684\u7ef4\u5ea6\u6570\u7ec4\u4e0e\u77e9\u9635\u8fd0\u7b97\uff0c\u6b64\u5916\u4e5f\u9488\u5bf9\u6570\u7ec4\u8fd0\u7b97\u63d0\u4f9b\u5927\u91cf\u7684\u6570\u5b66\u51fd\u6570\u5e93\u3002","e94344a8":"# \u81ea\u7136\u5e38\u6570e","6679344e":"# Filters","e3cfb6bc":"# Optimzers","30036635":"# Loss func","477ea05c":"# LR schedulers","25556c4b":"# **Pooling**"}}