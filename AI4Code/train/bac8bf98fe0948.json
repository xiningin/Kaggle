{"cell_type":{"4612d2f5":"code","4c2fe880":"code","6a54b3eb":"code","e8c3daa6":"code","918f9870":"code","00f69c7b":"code","7c2e29de":"markdown"},"source":{"4612d2f5":"import os\nimport gc\nimport time\nimport random\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nimport lightgbm as lgb\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nSEED = 2021\nseed_everything(SEED)","4c2fe880":"class config:\n    paths = {\n        # train path\n        \"train_csv\"  : \"..\/input\/tabular-playground-series-oct-2021\/train.csv\",\n        \"test_csv\" : \"..\/input\/tabular-playground-series-oct-2021\/test.csv\",\n        \"ss\": \"..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv\",\n        \n        'lgb_paths': \".\/lgb_models\/\"\n    }\n\n    random_state = SEED\n\n    model_params = {\n        \"lgb\": {\n            'learning_rate': 0.02,\n            'subsample': 0.6,\n            'colsample_bytree': 0.4,\n            'reg_alpha': 10.0,\n            'reg_lambda': 2,\n            'min_child_weight': 256,\n            'min_child_samples': 32,\n            'objective': 'binary',\n            'metric': 'auc',\n            'n_jobs': -1,\n            'verbose': -1,\n            \"seed\": SEED,\n            \"feature_fraction_seed\": SEED,\n            \"bagging_seed\": SEED,\n            \"drop_seed\": SEED,\n            \"data_random_seed\": SEED,\n        }\n    }","6a54b3eb":"def get_cols(df):\n    binary_features = []\n    for idx, dt in enumerate(df.dtypes):\n        if dt==\"int64\":\n            col = df.columns[idx]\n            if col=='id' or col=='target':\n                continue\n\n            binary_features.append(col)\n\n    cont_features = []\n    for col in tqdm(df.columns):\n        if col not in binary_features and col!='id' and col!=\"target\":\n            cont_features.append(col)\n            \n    print(f\"No of binary features: {len(binary_features)} \\t No of continuous features: {len(cont_features)}\")\n    return binary_features, cont_features","e8c3daa6":"class TrainFer:\n    def __init__(self, params_dict, n_splits, model_path, random_state):\n        self.params = params_dict\n        self.n_splits = n_splits\n        self.random_state = random_state\n        self.model_path = model_path\n        if not os.path.isdir(model_path):\n            os.makedirs(model_path)\n            \n    \n    def train(self, X, y):\n        oof_predictions = np.zeros(X.shape[0])\n        kfold = KFold(n_splits=self.n_splits, random_state=0, shuffle=True)\n        oof_scores = []\n\n        for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n            print(f\"\\nFold - {fold}\\n\")\n\n            x_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n            x_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n            \n            dtrain = lgb.Dataset(x_train, y_train)\n            dval = lgb.Dataset(x_val, y_val)\n\n            model = lgb.train(params=self.params,\n                              num_boost_round=5000,\n                              train_set=dtrain,\n                              valid_sets=[dtrain, dval],\n                              verbose_eval=100,\n                              early_stopping_rounds=100)\n            \n            fold_preds = model.predict(x_val, num_iteration=model.best_iteration)\n            oof_score = roc_auc_score(y_val, fold_preds)\n            print(f\"\\nAUC_ROC of fold {fold}: {oof_score}\")\n            pickle.dump(model, open(os.path.join(self.model_path, f\"lgb_bl_{fold}_{oof_score}.pkl\"), \"wb\"))\n            \n            oof_scores.append(oof_score)\n            oof_predictions[val_idx] = fold_preds\n            \n            del x_train, x_val, y_train, y_val, model, fold_preds, dtrain, dval\n            _ = gc.collect()\n            \n            time.sleep(10)\n        \n        print(f\"\\nOOF Scores: {oof_scores}\\n\")\n        auc_roc_score = roc_auc_score(y, oof_predictions)\n        print(f\"OOF AUC_ROC: {auc_roc_score}\")\n        \n        return auc_roc_score","918f9870":"def infer_lgb(test_data, model_dir):\n    print(\"\\n[INFO] LGB Inference...\")\n    test_predictions = np.zeros(test_data.shape[0])\n    \n    for mpth in tqdm(os.listdir(model_dir)):\n        model = pickle.load(open(os.path.join(model_dir, mpth), \"rb\"))\n        test_predictions += model.predict(test_data)\/len(os.listdir(model_dir))\n    \n    return test_predictions\n    pass","00f69c7b":"if __name__ == \"__main__\":\n    _ = gc.collect()\n    train_df = pd.read_csv(config.paths[\"train_csv\"])\n    \n    cat_feats, cont_feats = get_cols(train_df)\n    clf = TrainFer(config.model_params[\"lgb\"], n_splits=5, model_path=config.paths[\"lgb_paths\"], random_state=config.random_state) \n\n    score = clf.train(train_df[cat_feats+cont_feats], train_df[\"target\"])\n    \n    test_df = pd.read_csv(config.paths[\"test_csv\"])\n    test_predictions = infer_lgb(test_df[cat_feats+cont_feats], config.paths[\"lgb_paths\"])\n    test_df[\"target\"] = test_predictions\n    test_df[[\"id\", \"target\"]].to_csv(f\"submission_{score}.csv\", index=False)\n    pass","7c2e29de":"EOF!"}}