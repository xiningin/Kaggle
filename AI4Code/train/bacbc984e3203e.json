{"cell_type":{"a1658fa3":"code","d679a7e5":"code","22428350":"code","daee61e4":"code","cde87ee5":"code","f15bd56c":"code","45847047":"code","b24025bf":"code","97f80df6":"code","993fbb24":"code","f67e71e7":"code","452beceb":"code","67bf95d2":"code","1151de73":"code","e644cb6b":"code","593c5569":"code","02212246":"code","259e75e0":"code","556520c3":"code","8bbcdf13":"code","34eeb15c":"markdown","3bfcb235":"markdown","ae6e19d0":"markdown","f1d88962":"markdown","ac6f83e0":"markdown","5c3bb235":"markdown","0acf7e8d":"markdown","e613cd74":"markdown","05f0711e":"markdown","86e6bb1b":"markdown","9c44462d":"markdown"},"source":{"a1658fa3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n#model selection\nfrom sklearn.model_selection import train_test_split , GridSearchCV, cross_val_score, cross_val_predict\n\n#models.\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\n#validation \nfrom sklearn.metrics import classification_report , precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, roc_curve","d679a7e5":"# reading CSV file from kaggle\ndata = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\n# reading CSV file from my PC\n# data = pd.read_csv('diabetes.csv')\n","22428350":"data.head()   ","daee61e4":"data.info()","cde87ee5":"data.describe()","f15bd56c":"data.hist(figsize=(20,10));","45847047":"fig=plt.figure(figsize=(20,12))\ngs=fig.add_gridspec(2,4)\nax0=fig.add_subplot(gs[0,0])\nax1=fig.add_subplot(gs[0,1])\nax2=fig.add_subplot(gs[0,2])\nax3=fig.add_subplot(gs[0,3])\nax4=fig.add_subplot(gs[1,0])\nax5=fig.add_subplot(gs[1,1])\nax6=fig.add_subplot(gs[1,2])\nax7=fig.add_subplot(gs[1,3])\n\nsns.boxplot(data['Pregnancies'],data=data,ax=ax0)\nsns.boxplot(data['Glucose'],data=data,ax=ax1)\nsns.boxplot(data['BloodPressure'],data=data,ax=ax2)\nsns.boxplot(data['SkinThickness'],data=data,ax=ax3)\nsns.boxplot(data['Insulin'],data=data,ax=ax4)\nsns.boxplot(data['BMI'],data=data,ax=ax5)\nsns.boxplot(data['DiabetesPedigreeFunction'],data=data,ax=ax6)\nsns.boxplot(data['Age'],data=data,ax=ax7)","b24025bf":"plt.subplots(figsize=(20,15))\nax = sns.heatmap(\ndata.corr() ,\ncmap=sns.diverging_palette(20,220, n=200),\nannot=True)","97f80df6":"corr_matrix = data.corr()\ncorr_matrix[\"Outcome\"].sort_values(ascending = False)\n# ('Glucose', 'BMI', 'Age', 'Pregnancies', 'DiabetesPedigreeFunction', 'Insulin', 'SkinThickness', 'BloodPressure')","993fbb24":"y = data.Outcome\nX = data.drop(['Outcome'],axis=1)\nX.head()","f67e71e7":"from sklearn.model_selection import train_test_split\n\n# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)","452beceb":"from sklearn.neighbors import KNeighborsClassifier as knn\n\nknn_model = knn(n_neighbors=110)\nknn_model.fit(X_train, y_train)\ny_preds = knn_model.predict(X_test)","67bf95d2":"from sklearn.metrics import mean_squared_error\nfrom math import sqrt\nmse = mean_squared_error(y_test, y_preds)\nrmse = sqrt(mse)\nprint(\"RMSE = \",rmse)","1151de73":"print('My accuracy: ', knn_model.score(X_test, y_test)*100, '%')\n# My accuracy:  78.57142857142857 %\nprint(\"Classification Report is:\\n\",classification_report(y_test, y_preds))","e644cb6b":"from sklearn.linear_model import LogisticRegression\n\nlg_model = LogisticRegression(solver='liblinear')\nlg_model.fit(X_train, y_train)\ny_pred = lg_model.predict(X_test)","593c5569":"mse = mean_squared_error(y_test, y_pred)\nrmse = sqrt(mse)\nprint(\"RMSE = \",rmse)","02212246":"print('My accuracy: ', lg_model.score(X_test, y_test)*100, '%')\n# My accuracy:  81.81818181818183 %\nprint(\"Classification Report is:\\n\",classification_report(y_test, y_pred))","259e75e0":"from sklearn.svm import SVC\n\nsvc_model = SVC()\nsvc_model.fit(X_train, y_train)\ny_preds = svc_model.predict(X_test)","556520c3":"mse = mean_squared_error(y_test, y_preds)\nrmse = sqrt(mse)\nprint(\"RMSE = \",rmse)","8bbcdf13":"print('My accuracy = ', svc_model.score(X_test, y_test)*100, '%')\n# My accuracy:  79.22077922077922 %\nprint(\"Classification Report is:\\n\",classification_report(y_test, y_preds))","34eeb15c":"#### correlation","3bfcb235":"# CONTENT <a id='content'><\/a>\n##   1.[Intro and imports](#intro)\n\n##   2.[Reading CSV and EDA](#csv)\n\n##   3.[Data Preprocessing](#preprocess) <br>\n\n## 4.[Model selection](#mod)\n#### [KNN](#KNN)\n#### [Logistic Regression](#lr)\n#### [SVM](#svm)<br>\n---","ae6e19d0":"## SVM <a id='svm'><\/a>\n\n##### [Back to CONTENT](#content)","f1d88962":"## Logistic Regression <a id='lr'><\/a>\n##### [Back to CONTENT](#content)","ac6f83e0":"# Reading CSV and EDA <a id='csv'><\/a>\n\n##### [Back to CONTENT](#content)","5c3bb235":"# Data preprocessing <a id='preprocess'><\/a>\n\n##### [Back to CONTENT](#content)","0acf7e8d":"#### histogram","e613cd74":"# Model selection <a id='mod'><\/a>\n##### [Back to CONTENT](#content)","05f0711e":"## KNN <a id='KNN'><\/a>\n##### [Back to CONTENT](#content)","86e6bb1b":"# Intro and imports <a id='intro'><\/a>\n##### [Back to CONTENT](#content)\n#### Data\nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n\nPregnancies: Number of times pregnant\n\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n\nBloodPressure: Diastolic blood pressure (mm Hg)\n\nSkinThickness: Triceps skin fold thickness (mm)\n\nInsulin: 2-Hour serum insulin (mu U\/ml)\n\nBMI: Body mass index (weight in kg\/(height in m)^2)\n\nDiabetesPedigreeFunction: Diabetes pedigree function\n\nAge: Age (years)\n\nOutcome: Class variable (0 or 1)\n#### Objective\nWe will try to build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?","9c44462d":"## The best one is Logistic Regression"}}