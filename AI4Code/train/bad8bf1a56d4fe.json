{"cell_type":{"16c00553":"code","15be087b":"code","18a6f832":"code","df8c4c77":"code","2028a44d":"code","a5817524":"code","a4d34ec3":"code","e17cd628":"code","f97d0f82":"code","4b91d88f":"code","a413c0c5":"code","98db5169":"code","b54bc254":"code","546afce7":"code","58a4428d":"code","e7275ed0":"code","6434093f":"markdown"},"source":{"16c00553":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nimport lightgbm as lgb\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot, plot\ninit_notebook_mode(connected=True)","15be087b":"path_train = '..\/input\/health-insurance-cross-sell-prediction\/train.csv'\n\ndf = pd.read_csv(path_train, sep=',', index_col=['id'])\n\ntrain = pd.read_csv(path_train, sep=',', index_col=['id'])\n\n#encoding categorical features\nva = {'> 2 Years': 2, '1-2 Year': 1, '< 1 Year': 0}\ngen = {'Male' : 0, 'Female' : 1}\nvg = {'Yes' : 1, 'No' : 0}\ntrain['Vehicle_Age'] = train['Vehicle_Age'].map(va)\ntrain['Gender'] = train['Gender'].map(gen)\ntrain['Vehicle_Damage'] = train['Vehicle_Damage'].map(vg)\n\ntrain.tail()","18a6f832":"fig = go.Figure()\nfig.add_trace(go.Histogram(\n    x = train['Age'],\n    marker_color='#ab1a5d',\n    opacity=1\n))\n\nfig.update_layout(\n    title_text='age distribution',\n    xaxis_title_text='AGE',\n    yaxis_title_text='COUNT', \n    bargap=0.05,\n    xaxis =  {'showgrid': False },\n    yaxis = {'showgrid': False },\n    template = 'plotly_dark'\n)\n\niplot(fig)","df8c4c77":"grouped = round(train.groupby(['Vehicle_Age'], as_index=False)\n                .agg({'Vehicle_Damage':'mean', 'Previously_Insured':'mean', 'Age':'mean'}) , 2)\ngrouped.head()","2028a44d":"hist_of_1 = train.query('Vehicle_Age == 1')\nhist_of_0 = train.query('Vehicle_Age == 0')\nhist_of_2 = train.query('Vehicle_Age == 2')","a5817524":"fig = go.Figure(data = [\n    go.Histogram(x = hist_of_0['Age'],\n    marker_color='#ab1a5d', opacity=1),\n    go.Histogram(x=hist_of_1['Age']),\n    go.Histogram(x=hist_of_2['Age'])]\n)\n\nfig.update_layout(\n    title_text=\"Distribution of a person's age in relation to the age of a car\",\n    xaxis_title_text='AGE',\n    yaxis_title_text='COUNT', \n    bargap=0.05,\n    xaxis =  {'showgrid': False },\n    yaxis = {'showgrid': False },\n    template = 'plotly_dark'\n)\n\niplot(fig)","a4d34ec3":"fig = go.Figure()\n\nfig = go.Figure(data=[\n    go.Bar(name = \"> 2 Years = 2, 1-2 Year = 1, < 1 Year = 0\", x = grouped['Vehicle_Age'], \n        y = grouped['Vehicle_Damage'], marker_color='#394d99'),\n    go.Bar(name = \"1 is already has vehicle insured, 0 is not\", x = grouped['Vehicle_Age'],\n        y = grouped['Previously_Insured'])\n]\n)\n\n#394d99, ab1a5d\nfig.update_layout(\n    title_text='mean distribution',\n    xaxis_title_text='mean of three scores',\n    yaxis_title_text='COUNT', \n    bargap=0.18,\n    xaxis =  {'showgrid': False },\n    yaxis = {'showgrid': False },\n    template = 'plotly_dark',\n    legend=dict(\n    yanchor=\"top\",\n    y=0.99,\n    xanchor=\"left\",\n    x=0.01),\n    showlegend=True\n)\nfig.show()","e17cd628":"#Removing outliers\ntrain = train.query('Annual_Premium <= 100000')\ntrain.shape","f97d0f82":"num_feat = ['Age', 'Vintage', 'Annual_Premium']\n\ncat_feat = [\n    'Gender', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage',\n    'Driving_License', 'Policy_Sales_Channel', 'Region_Code'\n]","4b91d88f":"#Just scaling num_cols\nscl = StandardScaler()\n\nnum_scl = pd.DataFrame(scl.fit_transform(train[num_feat]))\nnum_scl.index = train[num_feat].index\nnum_scl.columns = train[num_feat].columns\nX_ = pd.concat([num_scl, train[cat_feat]], axis=1)\nX_.head()","a413c0c5":"y = train.Response\nX_.shape, y.shape","98db5169":"grid_param = {\n    'num_leaves': [60, 70, 80],\n    'min_child_weight': [0.1, 0.5, 1, 1.5, 2],\n    'feature_fraction': [0.1, 0.5, 1, 1.5, 2],\n    'bagging_fraction': [0.1, 0.5, 1, 1.5, 2],\n    'max_depth': [6, 7, 8],\n    'learning_rate': [0.9, 0.1, 0.12, 0.15],\n    'reg_alpha': [0.5, 0.9, 1.2, 1.8],\n    'reg_lambda': [0.5, 0.9, 1.2, 1.8,],\n    'num_iterations': [90, 100, 110]\n}\n\nmodel = lgb.LGBMClassifier(random_state=22)\n\ngrid_fold = KFold(n_splits=5, shuffle=True, random_state=12)\n\ngrid_search = RandomizedSearchCV(model,\n                                 param_distributions=grid_param,\n                                 scoring='roc_auc',\n                                 cv=grid_fold,\n                                 n_jobs=-1,\n                                 verbose=1,\n                                 random_state=112)\n\ngrid_result = grid_search.fit(X_, y)\nprint(grid_result.best_score_, grid_result.best_params_)","b54bc254":"params = {\n    'reg_lambda': 1.8,\n    'reg_alpha': 0.9,\n    'num_leaves': 80,\n    'min_child_weight': 1,\n    'max_depth': 6,\n    'learning_rate': 0.12,\n    'feature_fraction': 0.5,\n    'bagging_fraction': 0.5,\n    'objective': 'binary',\n    \"boosting_type\": \"gbdt\",\n    \"bagging_seed\": 23,\n    \"metric\": 'auc',\n    \"verbosity\": -1\n}","546afce7":"#split to folds and training lightgbm\n\nn_folds = 5\nfold = KFold()\nsplits = fold.split(X_, y)\ncolumns = X_.columns\noof = np.zeros(X_.shape[0])\nscore = 0\ny_oof = np.zeros(X_.shape[0])\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = columns","58a4428d":"for fold_n, (train_index, valid_index) in enumerate(splits):\n    X_train, X_valid = X_[columns].iloc[train_index], X_[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    dtrain = lgb.Dataset(X_train, label = y_train)\n    dvalid = lgb.Dataset(X_valid, label = y_valid)\n    \n    clf = lgb.train(params, dtrain, valid_sets=[dtrain, dvalid], \n                    verbose_eval=100)\n    \n    \n    feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n    \n    y_pred_valid = clf.predict(X_valid)\n    y_oof[valid_index] = y_pred_valid\n    print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")\n    score += roc_auc_score(y_valid, y_pred_valid) \/ n_folds\n    \nprint(f\"\\nMean AUC = {score}\")\nprint(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")","e7275ed0":"feature_importances['average'] = feature_importances[[\n    f'fold_{fold_n + 1}' for fold_n in range(fold.n_splits)\n]].mean(axis=1)\n\nplt.figure(figsize=(14, 7))\nsns.barplot(data=feature_importances.sort_values(by='average', ascending=False).head(10), x='average', y='feature');\nplt.title('TOP feature importance over {} folds average'.format(fold.n_splits))","6434093f":"# TRAINING"}}