{"cell_type":{"86445c05":"code","eb806a6d":"code","f152d634":"code","07780361":"code","afa590bb":"code","d0dfe574":"code","1e97df3c":"code","ff8798fd":"code","8954affd":"code","d7104592":"code","54f3df06":"code","5de01943":"code","7c0ba3fc":"code","e55e424f":"code","7a962e28":"code","7ec3a442":"code","105259ef":"code","bc649a2a":"code","553c2add":"code","b0f9c6ca":"code","6cb0a2c4":"markdown","e3449e2e":"markdown","47c318a4":"markdown"},"source":{"86445c05":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport os","eb806a6d":"train_data = pd.read_csv('..\/input\/train.csv')\n","f152d634":"train_X = train_data.drop(['id', 'target'], axis = 1)\ntrain_Y = train_data['target']","07780361":"test_data = pd.read_csv('..\/input\/test.csv')","afa590bb":"test_data_X = test_data.drop(['id'], axis = 1)","d0dfe574":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ntrain_X = sc.fit_transform(train_X)\ntest_data_X = sc.fit_transform(test_data_X)","1e97df3c":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(train_X, train_Y, test_size=0.20, random_state=111)","ff8798fd":"# import the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout , BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.utils import np_utils\nfrom keras.optimizers import SGD\nfrom keras import regularizers\nfrom keras.constraints import max_norm\n","8954affd":"import tensorflow as tf\nfrom keras import backend as K\n\ndef auc(y_true, y_pred):\n    auc = tf.metrics.auc(y_true, y_pred)[1]\n    K.get_session().run(tf.local_variables_initializer())\n    return auc\n\n\n","d7104592":"# Initialize the NN \nmodel = Sequential()\nmodel.add(Dense(256, input_dim=X_train.shape[1] , activation='tanh', \n                kernel_initializer = \"normal\", kernel_regularizer=regularizers.l2(0.005), \n                kernel_constraint = max_norm(5.)))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128, activation='tanh', kernel_regularizer=regularizers.l2(0.005)\n                , kernel_constraint=max_norm(5)))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='tanh', kernel_regularizer=regularizers.l2(0.005)\n                , kernel_constraint=max_norm(5)))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(0.005)\n                , kernel_constraint=max_norm(5)))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1, activation='sigmoid'))","54f3df06":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])","5de01943":"model.summary()","7c0ba3fc":"checkpoint = ModelCheckpoint('rc_model', monitor='val_auc', verbose=1, \n                             save_best_only=True, mode='max', save_weights_only = True)\n\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=5, \n                                   verbose=1, mode='max', min_delta=0.001)\n# early stopping\nearlyStoping = EarlyStopping(monitor='val_auc', \n                                  patience=9, mode='max', verbose=1)\n\ncallbacks_list = [checkpoint, reduceLROnPlat, earlyStoping]","e55e424f":"# fit model\nhistory = model.fit(X_train, Y_train, batch_size = 256, epochs=50, validation_split=0.20,\n                    validation_data=(X_test, Y_test), callbacks=callbacks_list)","7a962e28":"_, train_auc = model.evaluate(X_train, Y_train, verbose=0)\nprint(train_auc)","7ec3a442":"_, test_auc = model.evaluate(X_test, Y_test, verbose=0)\nprint(test_auc)","105259ef":"# plot accuracy learning curves\nplt.subplot(212)\nplt.title('Accuracy', pad=-40)\nplt.plot(history.history['auc'], label='train')\nplt.plot(history.history['val_auc'], label='test')\nplt.legend()\nplt.show()","bc649a2a":"# plot loss learning curves\nplt.subplot(211)\nplt.title('Cross-Entropy Loss', pad=-40)\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show()","553c2add":"preds = model.predict(test_data_X)","b0f9c6ca":"# make submission\nsubmission = pd.DataFrame({\"id\" : test_data['id'].values,\n                           \"target\" : preds[:,0]})\nsubmission.to_csv('submission.csv', index = False, header = True)\ndisplay(submission.head(15))\ndisplay(submission.tail(15))","6cb0a2c4":"**Preprocess the Data**","e3449e2e":"**Load Data**","47c318a4":"Machine Learning"}}