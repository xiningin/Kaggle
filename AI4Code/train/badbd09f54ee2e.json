{"cell_type":{"5b89dfaf":"code","27c0a95c":"code","e84e7dc4":"code","b21b2f70":"code","f0fd6810":"code","3238a682":"code","1fe87e17":"code","71bb051a":"code","d9efd9b8":"code","b9f816b7":"code","0c38d9b7":"code","dfabe4ad":"code","751e4ff9":"code","d539b376":"code","68bb3d74":"code","93cb6892":"code","0afda4e7":"code","9aeecb9c":"code","2ca44137":"code","2e02779a":"code","f65466b9":"code","4db37221":"code","c2f7c89d":"code","a1de5b9f":"code","2d321604":"code","7f73814c":"code","62df3e83":"code","845a261f":"code","a04ba98a":"code","5627537b":"code","2ece7e5d":"code","b132eecf":"code","da37af4b":"code","dfbfe042":"code","bc961e74":"code","47876c0a":"code","ac929479":"code","81b5aca3":"code","9eb1dcb0":"code","ef61bfe2":"code","2c21ddea":"code","876c0b62":"code","d9acd30a":"code","fb94fd17":"code","2ba4c48c":"code","d1fc3444":"code","ccfa34ad":"code","f347c7d3":"code","815a9cd5":"code","0ed4c744":"code","e85c3fff":"code","3a4026ea":"markdown","85961e14":"markdown","89cb6a88":"markdown","15c7cb4d":"markdown","48e4a49b":"markdown","57ce48c4":"markdown","3d0bba66":"markdown","7ed4bd90":"markdown","f6ba6b05":"markdown","ca93809e":"markdown","6cfa7988":"markdown","ae9742d3":"markdown","43c2f9ab":"markdown","76f0ffd8":"markdown"},"source":{"5b89dfaf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27c0a95c":"import pandas as pd\nimport numpy as np\ndf_train = pd.read_csv('\/kaggle\/input\/shopee-workshop-building-ann\/HR-Employee-Attrition_train.csv')\ndf_train","e84e7dc4":"#check if there is any missing value\ndf_train.info()","b21b2f70":"#Check numerical data columns\nprint('There are %s numerical columns.'%(str(len(df_train.select_dtypes(include=['int64']).columns))))\ndf_train.select_dtypes(include=['int64']).columns","f0fd6810":"#check categorical data columns \nprint('There are %s numerical columns.'%(str(len(df_train.select_dtypes(include=['object']).columns))))\ndf_train.select_dtypes(include=['object']).columns","3238a682":"id_col = 'EmployeeNumber'\n\ntarget_col = 'Attrition'\n\n#25 numerical columns\nnumerical_cols = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EmployeeCount', 'EnvironmentSatisfaction', \n                'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', \n                'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', \n                'StandardHours', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', \n                'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']\n\n#8 categorical columns\ncategorical_cols = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', \n                 'Over18', 'OverTime']","1fe87e17":"#check 8 categorical columns\nnunique_values = []\nna_values = []\nfor col in categorical_cols:\n    nunique_values.append(df_train[col].nunique())\n    na_values.append(len(df_train.loc[df_train[col].isna()]))\ndf_train_stats_categorical = pd.DataFrame(list(zip(categorical_cols,nunique_values,na_values)),columns=['Column_Name','#Unique_Values','#Null_Value'])\ndf_train_stats_categorical","71bb051a":"#check Null columns\ndf_train_stats_categorical[df_train_stats_categorical['#Null_Value']>0]","d9efd9b8":"#check columns with only 1 value\ndf_train_stats_categorical[df_train_stats_categorical['#Unique_Values'] == 1]","b9f816b7":"#check 25 numerical columns\nna_values = []\nfor col in numerical_cols:\n    na_values.append(len(df_train.loc[df_train[col].isna()]))\ndf_train_stats_numerical = pd.DataFrame(list(zip(numerical_cols,na_values)),columns=['Column_Name','#Null_Value'])\ndf_train_stats_numerical","0c38d9b7":"#check Null columns\ndf_train_stats_numerical[df_train_stats_numerical['#Null_Value']>0]","dfabe4ad":"df_train_stats_numerical = df_train[numerical_cols].describe().T\ndf_train_stats_numerical","751e4ff9":"#check columns with only 1 value\ndf_train_stats_numerical[df_train_stats_numerical['std']==0]","d539b376":"#check categorical columns\ndef explore_categorical_columns(df,categorical_cols):\n    nunique_values = []\n    na_values = []\n    for col in categorical_cols:\n        nunique_values.append(df[col].nunique())\n        na_values.append(len(df.loc[df[col].isna()]))\n    df_stats_categorical = pd.DataFrame(list(zip(categorical_cols,nunique_values,na_values)),columns=['Column_Name','#Unique_Values','#Null_Value'])\n    df_null = df_stats_categorical[df_stats_categorical['#Null_Value']>0]\n    df_unique_value = df_stats_categorical[df_stats_categorical['#Unique_Values'] == 1]\n    if len(df_null) > 0:\n        print('Columns with Null value: %s'%(str(df_null['Column_Name'])))\n    else:\n        print('There is no Null values in the categorical columns')\n    if len(df_unique_value) > 0:\n        print('Columns with only 1 unique value: %s'%(str(list(df_unique_value['Column_Name']))))\n    else:\n        print('All categorical columns have more than 1 value.')\n        \n#check numerical columns\ndef explore_numerical_columns(df,numerical_cols):\n    na_values = []\n    for col in numerical_cols:\n        na_values.append(len(df.loc[df[col].isna()]))\n    df_stats_numerical = pd.DataFrame(list(zip(numerical_cols,na_values)),columns=['Column_Name','#Null_Value'])\n    df_null = df_stats_numerical[df_stats_numerical['#Null_Value']>0]\n    df_stats = df[numerical_cols].describe().T\n    df_unique_value = df_stats[df_stats['std']==0]\n    \n    if len(df_null) > 0:\n        print('Columns with Null value: %s'%(str(df_null['Column_Name'])))\n    else:\n        print('There is no Null values in the numerical columns')\n    \n    if len(df_unique_value) > 0:\n        print('Columns with only 1 unique value: %s'%(str(list(df_unique_value.index))))\n    else:\n        print('All numerical columns have more than 1 value. \\n')\n\n#check categorical columns\nprint('Categorical_Columns'.center(50,\"*\"))\nexplore_categorical_columns(df_train,categorical_cols)\nprint('Numerical_Columns'.center(50,\"*\"))\n#check numerical columns\nexplore_numerical_columns(df_train,numerical_cols)","68bb3d74":"# Check target variable\ndf_train[target_col].unique()","93cb6892":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\ndef process_numerical_data(df,numerical_cols,drop_numerical_columns):\n    sacalar = MinMaxScaler()\n    # sacalar = StandardScaler() if using StandardScaler\n    scale_numerical_cols = list(set(numerical_cols)-set(drop_numerical_columns))\n    df_numerical = sacalar.fit_transform(df[scale_numerical_cols])\n    df_numerical = pd.DataFrame(df_numerical,columns=scale_numerical_cols)\n    return df_numerical\n\ndrop_numerical_columns = ['EmployeeCount', 'StandardHours']\ndf_train_numerical = process_numerical_data(df_train,numerical_cols,drop_numerical_columns)\ndf_train_numerical","0afda4e7":"df_train[categorical_cols]","9aeecb9c":"?pd.get_dummies","2ca44137":"def process_categorical_data(df,categorical_cols,drop_categorical_columns):\n    df_categorical = pd.get_dummies(df[[var for var in categorical_cols if var not in drop_categorical_columns]])\n    return df_categorical","2e02779a":"drop_categorical_columns = ['Over18']\ndf_train_categorical = process_categorical_data(df_train, categorical_cols, drop_categorical_columns)\ndf_train_categorical","f65466b9":"df_train_numerical.shape, df_train_categorical.shape","4db37221":"df_train_features = pd.concat([df_train_numerical, df_train_categorical],axis=1)\ndf_train_features.shape","c2f7c89d":"df_train_features","a1de5b9f":"def process_label(df):\n    target_col_dict = {'Yes': 1, 'No': 0}\n    df_labels = df[target_col].map(target_col_dict).values\n    return df_labels\ndf_train_labels = process_label(df_train)\ndf_train_labels.shape","2d321604":"df_train_labels","7f73814c":"# split the data into train and test\nfrom sklearn.model_selection import train_test_split\ntrain_x, test_x, train_y, test_y = train_test_split(df_train_features,df_train_labels,test_size=0.3,random_state=23)","62df3e83":"from sklearn.neural_network import MLPClassifier\nNN = MLPClassifier()\nNN.fit(train_x,train_y)","845a261f":"NN_predicted_y = NN.predict(test_x)","a04ba98a":"from sklearn.metrics import accuracy_score\naccuracy_score(test_y,NN_predicted_y)","5627537b":"df_test = pd.read_csv('\/kaggle\/input\/shopee-workshop-building-ann\/HR-Employee-Attrition_test.csv')\ndf_test","2ece7e5d":"df_test.info()","b132eecf":"print('Missing columns in test dataset(campared with train dataset): %s'%(str(set(df_train.columns)-set(df_test.columns))))","da37af4b":"id_col = 'EmployeeNumber'\n\nnumerical_cols = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EmployeeCount', 'EnvironmentSatisfaction', 'HourlyRate', \n                  'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', \n                  'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel', \n                  'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', \n                  'YearsSinceLastPromotion', 'YearsWithCurrManager']\n\ncategorical_cols = ['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']","dfbfe042":"#check 8 categorical columns\nprint('Categorical_Columns'.center(50,\"*\"))\nexplore_categorical_columns(df_test,categorical_cols)\nprint('Numerical_Columns'.center(50,\"*\"))\nexplore_numerical_columns(df_test,numerical_cols)","bc961e74":"drop_numerical_columns = ['EmployeeCount', 'StandardHours']\ndf_test_numerical = process_numerical_data(df_test,numerical_cols,drop_numerical_columns)\ndf_test_numerical","47876c0a":"# to check if there's any missing numerical columns in test dataset\nset(df_train_numerical.columns)-set(df_test_numerical.columns)","ac929479":"drop_categorical_columns = ['Over18']\ndf_test_categorical = process_categorical_data(df_test,categorical_cols,drop_categorical_columns)\ndf_test_categorical","81b5aca3":"# to check if there's any missing categorical columns in test dataset\nset(df_train_categorical.columns)-set(df_test_categorical.columns)","9eb1dcb0":"df_test_features = pd.concat([df_test_numerical, df_test_categorical],axis=1)\ndf_test_features","ef61bfe2":"predicted_test = NN.predict(df_test_features)\npredicted_test","2c21ddea":"answer = df_test[['EmployeeNumber']]\nanswer['Attrition'] = ['Yes' if i == 1 else 'No' for i in predicted_test]\nanswer","876c0b62":"answer.to_csv('submission.csv',index=False)","d9acd30a":"#You can use below code to download the answer:\n\nfrom IPython.display import FileLink\nFileLink(r'submission.csv')","fb94fd17":"%%time\nimport time\nstart_time = time.time()\nNN_new = MLPClassifier(max_iter=1000)\nparameter_space = {\n    'hidden_layer_sizes': [(50,50,50), (50,100,50), (50,100,50,25)],\n    'activation': ['tanh', 'relu','logistic'],\n    'solver': ['adam', 'lbfgs'],\n    'alpha': [0.001, 0.01],\n    'learning_rate': ['constant','adaptive'],\n}\nfrom sklearn.model_selection import GridSearchCV\n\nclf = GridSearchCV(NN_new, parameter_space, n_jobs=-1, cv=10)\nclf.fit(train_x, train_y)\nprint('Time taken for training the model: '+ str(time.time() - start_time))","2ba4c48c":"# Best paramete set\nprint('Best parameters found:\\n', clf.best_params_)","d1fc3444":"# All results\nmeans = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, clf.cv_results_['params']):\n    print(\"%0.3f (+\/-%0.03f) for %r\" % (mean, std * 2, params))","ccfa34ad":"y_true, y_pred = test_y , clf.predict(test_x)\nfrom sklearn.metrics import classification_report\nprint('Results on the test set:')\nprint(classification_report(y_true, y_pred))","f347c7d3":"accuracy_score(y_true, y_pred)","815a9cd5":"test_y_pred = clf.predict(df_test_features)","0ed4c744":"df_result = pd.DataFrame.from_dict(dict({'EmployeeNumber':list(df_test['EmployeeNumber']),\n                                         'Attrition':['Yes' if i == 1 else 'No' for i in test_y_pred]}))\ndf_result","e85c3fff":"temp = pd.merge(df_result,answer,on='EmployeeNumber',how='inner')\ntemp.loc[~(temp['Attrition_x']==temp['Attrition_y'])]","3a4026ea":"<img src= 'https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F4342316%2F9c2161bc579fae87686285d953bdf56d%2Fdata%20description.png?generation=1591008771269892&alt=media'>","85961e14":"The column 'Over18' only contains 1 unique value, therefore we could drop it.","89cb6a88":"# Loading the test dataset and do the EDA","15c7cb4d":"# GridSearch to find the optimal parameter setting\nMost used parameter\n\n1\uff09The ith element represents the number of neurons in the ith hidden layer.\n    example: ``hidden_layer_sizes``=(10)\n    \n2\uff09activation function\n    example: ``activation``=\"relu\"\n\n3\uff09The solver for weight optimization. {'lbfgs', 'sgd', 'adam'}\n    example: ``solver``='adam'\n\n4\uff09L2 penalty (regularization term) parameter\n    example: ``alpha``=0.0001\n\n5\uff09Size of minibatches for stochastic optimizers.\n    If the solver is 'lbfgs', the classifier will not use minibatch.\n    When set to 'auto', 'batch_size=min(200, n_samples)'\n    example: ``batch_size``='auto'\n\n6\uff09Learning rate schedule for weight updates.\n    example: ``learning_rate``=\"constant\"\n\n7\uff09The initial learning rate used. It controls the step-size in updating the weights. Only used when solver='sgd' or 'adam'.\n    example: ``learning_rate_init``=0.001\n\n8\uff09Maximum number of iterations. The solver iterates until convergence\n    example: ``max_iter``=200\n\n9\uff09Tolerance for the optimization. When the loss or score is not improving\n    by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n    unless ``learning_rate`` is set to 'adaptive', convergence is\n    considered to be reached and training stops.\n    example: ``tol``=1e-4","48e4a49b":"we can continue using the same 4 group column types:","57ce48c4":"# Make prediction on test dataset","3d0bba66":"# Set up and train the model","7ed4bd90":"    # Scaling Numerical Data\n<img src=\"https:\/\/miro.medium.com\/max\/1276\/0*_apuT0HdrVYMUCh7\">","f6ba6b05":"- The column 'Over18' only contains 1 unique value, therefore we could drop it.\n- Columns like 'EmployeeCount' and 'StandardHours' have 0 std, meaning all the values are the same, therefore we can drop them.","ca93809e":"# Loading data and do EDA(Exploratory Data Analysis)","6cfa7988":"Columns like 'EmployeeCount' and 'StandardHours' have 0 std, meaning all the values are the same, therefore we can drop them.","ae9742d3":"    # Convert categorical columns into numerical columns\n<img src=\"https:\/\/i.imgur.com\/mtimFxh.png\">\n    ","43c2f9ab":"# Data Process","76f0ffd8":"# Now we can divide all these 35 columns into 4 parts:\n1. id column\n2. target column\n3. numerical columns\n4. categorical columns"}}