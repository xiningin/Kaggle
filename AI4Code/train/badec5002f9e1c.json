{"cell_type":{"f97bb65d":"code","d43f0264":"code","6ff8330d":"code","cd7067a8":"code","a5e2e6cb":"code","eb1b9bc2":"code","91fd87aa":"code","5b0bfedf":"code","68b331a6":"code","c0c396ad":"code","fbc7ca9a":"code","39be72b4":"code","c0a937e2":"code","4e0dcbd4":"code","41ab3df9":"code","9a4b42fc":"markdown","7b03b701":"markdown","e9160e7a":"markdown","43fb26e8":"markdown","952c9211":"markdown","67e34134":"markdown","170a200f":"markdown"},"source":{"f97bb65d":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom IPython.core.interactiveshell import InteractiveShell\nimport warnings\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nimport gc\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold","d43f0264":"pd.options.display.max_columns = None\nwarnings.filterwarnings('ignore')","6ff8330d":"traindf = pd.read_csv('..\/input\/santander-customer-transaction-prediction\/train.csv')\ntestdf = pd.read_csv('..\/input\/santander-customer-transaction-prediction\/test.csv')","cd7067a8":"traindf['target'].value_counts().plot(kind='bar', title='Unbalance target variable')","a5e2e6cb":"fig = plt.figure(figsize=(20,10))\n\nfor i in range(0,50):\n    fig.add_subplot(5,10,i+1)\n    plt.title('Distribution on var_'+str(50+i))\n    sns.distplot(traindf['var_'+str(50+i)], color=\"m\")\n\nfig.tight_layout(pad=0.1)","eb1b9bc2":"cols=[c for c in traindf.columns if c not in ['ID_code', 'target']]\ny = traindf[\"target\"]\nx = traindf[cols]\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","91fd87aa":"rb = RobustScaler(with_centering=True,copy=False)\nx_train = rb.fit_transform(x_train)\nx_test = rb.fit_transform(x_test)\ntransform_2 = rb.fit_transform(testdf[cols])\ntestdf[cols] = transform_2","5b0bfedf":"params = {\n    'subsample': 0.95,\n    'subsample_freq': 100,\n    'num_iterations': 25000,\n    'learning_rate': 0.01,\n    'early_stopping_rounds':2500,\n    'max_bin':20,\n    'min_data_in_leaf':80,\n    'objective': 'binary',\n    'metric': 'auc',\n    'boosting' : 'gbdt',\n    'is_unbalance': True,\n    'num_threads': 8,\n    'verbosity': 1,\n    'num_leaves': 16,\n    'min_hessian': 80,\n    'tree_learner': 'serial',\n    'max_depth': 4,\n    'feature_fraction': 0.95,\n}","68b331a6":"train_data = lgb.Dataset(x_train, label=y_train)\nvalid_data = lgb.Dataset(x_test, label=y_test, reference=train_data)\n\nlgbmodel = lgb.train(params, train_data,                     \n                 valid_sets=[valid_data],\n                 valid_names=['valid'],\n                 verbose_eval=1000)\nscore = lgbmodel.best_score['valid']['auc']\ny_pred = lgbmodel.predict(x_test)\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test, y_pred.round(0).astype(int)))\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred.round(0).astype(int))*100))\nprint('Best AUC score {}'.format(score*100))","c0c396ad":"model = Sequential()\nmodel.add(Dense(36, input_dim=200,activation='relu',kernel_initializer='glorot_normal',bias_initializer='random_normal'))\nmodel.add(Dense(20, activation='relu',kernel_initializer='glorot_uniform',bias_initializer='random_normal'))\nmodel.add(Dense(16, activation='relu',kernel_initializer='glorot_uniform',bias_initializer='random_normal'))\nmodel.add(Dense(8, activation='relu',kernel_initializer='glorot_uniform',bias_initializer='random_normal'))\nmodel.add(Dense(1, activation='sigmoid',kernel_initializer='glorot_uniform',bias_initializer='random_normal'))","fbc7ca9a":"model.compile(loss = 'binary_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])","39be72b4":"model.fit(x_train, y_train, epochs=20, batch_size=1000)\n_, accuracy = model.evaluate(x_test, y_test)\nprint('Accuracy: %.2f' % (accuracy*100))","c0a937e2":"y_pred = model.predict_classes(x_test)\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred)))","4e0dcbd4":"logreg = LogisticRegression(max_iter=10000, C=50)\nlogreg.fit(x_train, y_train.ravel())\n\ny_pred = logreg.predict(x_test)\nprint(\"Accuracy on test data:\",metrics.accuracy_score(y_test.ravel(), y_pred))\nprint(\"Model ROC_AUC on test data: {:.2f}%\".format(roc_auc_score(y_test, y_pred)))","41ab3df9":"y_pred_1 = logreg.predict(testdf[cols].to_numpy())\ny_pred_2 = model.predict_classes(testdf[cols].to_numpy())\ny_pred_3 = lgbmodel.predict(testdf[cols].to_numpy()).round(0).astype(int)\n\ntestdf['target'] = y_pred_1\ntestdf[['ID_code','target']].to_csv('SantanderSubmission1.csv', index=False)\n\ntestdf['target'] = y_pred_2\ntestdf[['ID_code','target']].to_csv('SantanderSubmission2.csv', index=False)\n\ntestdf['target'] = y_pred_3\ntestdf[['ID_code','target']].to_csv('SantanderSubmission3.csv', index=False)","9a4b42fc":"## Light Gredient Boost Decision Tree","7b03b701":"# Learning Data Science Part 2.0\n\nThis kernel I create to train my data science skills. I want to train my step course to apply them on this data set. I never mind about the accuracy of my model, but, as long as my progress on this kernel, I try to improve that. So, task for this competition is to predict probability customer of santander who will conducted transaction on future and their nominal.","e9160e7a":"Based on graph above, I think variable have normal distribution. But, they have different range. So, in the next step, i will apply standard scaler to those variable.","43fb26e8":"## Neural Network","952c9211":"## Logistic Regression","67e34134":"## For Submission","170a200f":"## Build Model"}}