{"cell_type":{"b89319c1":"code","0fa4a625":"code","a71a8c76":"code","524e47a5":"code","c2864fd2":"code","5ac3ed8a":"code","953eabb8":"code","435bb4df":"code","b3830a85":"code","d806acaa":"code","684a6d65":"code","863db471":"code","146980db":"code","22db0131":"code","8050aa73":"code","f34d66d2":"code","0c27751e":"code","da23f7b4":"code","b63b9c3f":"code","66801e84":"code","77ad961d":"code","be240470":"code","4a25a86d":"code","c8a86800":"markdown","951a4ede":"markdown","a388c905":"markdown","d1261c92":"markdown","617add28":"markdown","7f23cfe1":"markdown","7cbce21f":"markdown","f518a7e4":"markdown","1d84fe4c":"markdown","9d1784d7":"markdown","e39a323f":"markdown","b2fa0051":"markdown"},"source":{"b89319c1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom collections import Counter\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split, KFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nsns.set(style='white', context='notebook', palette='deep')","0fa4a625":"dataset = pd.read_csv(\"..\/input\/adult.csv\")\n\n# Check for Null Data\ndataset.isnull().sum()","a71a8c76":"# Replace All Null Data in NaN\ndataset = dataset.fillna(np.nan)","524e47a5":"# Get data types\ndataset.dtypes","c2864fd2":"# Peek at data\ndataset.head(4)","5ac3ed8a":"\n# Reformat Column We Are Predicting\ndataset['income']=dataset['income'].map({'<=50K': 0, '>50K': 1, '<=50K.': 0, '>50K.': 1})\ndataset.head(4)","953eabb8":"# Identify Numeric features\nnumeric_features = ['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week','income']\n\n# Identify Categorical features\ncat_features = ['workclass','education','marital.status', 'occupation', 'relationship', 'race', 'sex', 'native']","435bb4df":"# Count of >50K & <=50K\nsns.countplot(dataset['income'],label=\"Count\")\nsns.plt.show()","b3830a85":"# Correlation matrix between numerical values\ng = sns.heatmap(dataset[numeric_features].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")\nsns.plt.show()","d806acaa":"# Explore Education Num vs Income\ng = sns.factorplot(x=\"education.num\",y=\"income\",data=dataset,kind=\"bar\",size = 6,palette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\">50K probability\")","684a6d65":"# Explore Hours Per Week vs Income\ng  = sns.factorplot(x=\"hours.per.week\",y=\"income\",data=dataset,kind=\"bar\",size = 6,palette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\">50K probability\")","863db471":"# Explore Age vs Income\ng = sns.FacetGrid(dataset, col='income')\ng = g.map(sns.distplot, \"age\")\nsns.plt.show()","146980db":"# Fill Missing Category Entries\ndataset[\"workclass\"] = dataset[\"workclass\"].fillna(\"X\")\ndataset[\"occupation\"] = dataset[\"occupation\"].fillna(\"X\")\ndataset[\"native.country\"] = dataset[\"native.country\"].fillna(\"United-States\")\n\n# Confirm All Missing Data is Handled\ndataset.isnull().sum()","22db0131":"# Explore Native Nation vs Income\ng = sns.barplot(x=\"native.country\",y=\"income\",data=dataset)\ng = g.set_ylabel(\"Income >50K Probability\")\nsns.plt.show()","8050aa73":"# Explore Sex vs Income\ng = sns.barplot(x=\"sex\",y=\"income\",data=dataset)\ng = g.set_ylabel(\"Income >50K Probability\")\nsns.plt.show()","f34d66d2":"# Explore Relationship vs Income\ng = sns.factorplot(x=\"relationship\",y=\"income\",data=dataset,kind=\"bar\", size = 6 ,\npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"Income >50K Probability\")\nsns.plt.show()","0c27751e":"# Explore Marital Status vs Income\ng = sns.factorplot(x=\"marital.status\",y=\"income\",data=dataset,kind=\"bar\", size = 6 ,\npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"Income >50K Probability\")\nsns.plt.show()","da23f7b4":"# Explore Workclass vs Income\ng = sns.factorplot(x=\"workclass\",y=\"income\",data=dataset,kind=\"bar\", size = 6 ,\npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"Income >50K Probability\")\nsns.plt.show()","b63b9c3f":"####################################################\n############### FEATURE ENGINEERING ################\n####################################################\n# Convert Sex value to 0 and 1\ndataset[\"sex\"] = dataset[\"sex\"].map({\"Male\": 0, \"Female\":1})\n\n# Create Married Column - Binary Yes(1) or No(0)\ndataset[\"marital.status\"] = dataset[\"marital.status\"].replace(['Never-married','Divorced','Separated','Widowed'], 'Single')\ndataset[\"marital.status\"] = dataset[\"marital.status\"].replace(['Married-civ-spouse','Married-spouse-absent','Married-AF-spouse'], 'Married')\ndataset[\"marital.status\"] = dataset[\"marital.status\"].map({\"Married\":1, \"Single\":0})\ndataset[\"marital.status\"] = dataset[\"marital.status\"].astype(int)\n\n# Drop the data you don't want to use\ndataset.drop(labels=[\"workclass\",\"education\",\"occupation\",\"relationship\",\"race\",\"native.country\"], axis = 1, inplace = True)\nprint('Dataset with Dropped Labels')\nprint(dataset.head())","66801e84":"###################################################\n##################### MODELING #####################\n####################################################\n# Split-out Validation Dataset and Create Test Variables\narray = dataset.values\nX = array[:,0:8]\nY = array[:,8]\nprint('Split Data: X')\nprint(X)\nprint('Split Data: Y')\nprint(Y)\nvalidation_size = 0.20\nseed = 7\nnum_folds = 10\nscoring = 'accuracy'\nX_train, X_validation, Y_train, Y_validation = train_test_split(X,Y,\n    test_size=validation_size,random_state=seed)\n\n# Params for Random Forest\nnum_trees = 100\nmax_features = 3\n\n#Spot Check 5 Algorithms (LR, LDA, KNN, CART, GNB, SVM)\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))\n#models.append(('SVM', SVC()))\n# evalutate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","77ad961d":"fig = plt.figure()\nfig.suptitle('Algorith Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","be240470":"####################################################\n################ ALGORITHM TUNING ##################\n####################################################\n'''\nCommented Out to Reduce Script Time - Took 20 Minutes to run.\nbest n_estimator = 250\nbest max_feature = 5\n# Tune Random Forest\nn_estimators = np.array([50,100,150,200,250])\nmax_features = np.array([1,2,3,4,5])\nparam_grid = dict(n_estimators=n_estimators,max_features=max_features)\nmodel = RandomForestClassifier()\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(X_train, Y_train)\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n'''","4a25a86d":"####################################################\n################# FINALIZE MODEL ###################\n####################################################\n# 5. Finalize Model\n# a) Predictions on validation dataset - KNN\nrandom_forest = RandomForestClassifier(n_estimators=250,max_features=5)\nrandom_forest.fit(X_train, Y_train)\npredictions = random_forest.predict(X_validation)\nprint(\"Accuracy: %s%%\" % (100*accuracy_score(Y_validation, predictions)))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))","c8a86800":"##5. Modeling","951a4ede":"##7. Finalize Model","a388c905":"##6. Algorithm Tuning","d1261c92":"##4. Feature Engineering","617add28":"#Income Prediction Problem\nIn this Notebook, I am working through the Income Prediction problem associated with the Adult Income Census dataset. The goal is to accurately predict whether or not someone is making more or less than $50,000 a year. While working through this problem, I am following a framework I use to attack all my machine learning problems. It includes the following steps:\n\n1. Load Libraries\n2. Load Data\n3. Analyze Data\n4. Feature Engineering\n5. Modeling\n6. Algorithm Tuning\n7. Finalizing the Model\n\nI hope you enjoy this notebook and find it useful. Please keep in mind this is my first Notebook on here so don't judge it too harshly!","7f23cfe1":"##2. Load Data","7cbce21f":"##3. Analyze Data","f518a7e4":"First, we need to load all of our libraries we will use for this project.","1d84fe4c":"##1. Load Libaraies","9d1784d7":"###3.2. Categorical Data Analysis","e39a323f":"###3.1. Numeric Data Analysis","b2fa0051":"Next, we load our data."}}