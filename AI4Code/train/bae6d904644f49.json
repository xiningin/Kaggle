{"cell_type":{"81218e9e":"code","3e9719b8":"code","b0d5fdc1":"code","50ce1449":"code","0fef49bc":"code","af2be1ef":"code","0d469a81":"code","fb472c71":"code","932bfbbd":"code","034d3e5c":"code","ea577f38":"code","7f6d7b05":"code","d3e6fc3d":"code","55fa15ec":"code","25cfee6a":"markdown","396ececb":"markdown","abcfe8ca":"markdown","d549a07d":"markdown"},"source":{"81218e9e":"# linear algebra\nimport numpy as np \n# data processing\nimport pandas as pd \n\ndepth_df=pd.read_csv(\"..\/input\/depths.csv\")\ndepth_df.info()","3e9719b8":"depth_df.head()","b0d5fdc1":"depth_df.hist()","50ce1449":"depth_df[depth_df['z'].isnull()]['z'].count()","0fef49bc":"import os\nfrom tqdm import tqdm\nimport hashlib\n\nTRAIN_IMAGE_DIR = '..\/input\/train\/images\/'\nTRAIN_MASK_DIR = '..\/input\/train\/masks\/'\n\ntrain_file_lst = os.listdir(TRAIN_IMAGE_DIR)\ntrain_mask_lst = os.listdir(TRAIN_MASK_DIR)\n\nmd5sum=[]\nfor file_name in tqdm(train_file_lst):\n    filePath=TRAIN_IMAGE_DIR + file_name\n    image_file = open(filePath, 'rb').read()\n    md5sum.append(hashlib.md5(image_file).hexdigest())","af2be1ef":"train_md5sum_df = pd.DataFrame(np.column_stack([train_file_lst, md5sum]), \n                               columns=['file', 'md5sum'])\ntrain_md5sum_df.info()","0d469a81":"train_md5sum_df.head()","fb472c71":"train_md5sum_df[train_md5sum_df['md5sum'].duplicated()]","932bfbbd":"from PIL import Image\nimg = Image.open(TRAIN_IMAGE_DIR+\"b552fb0d9d.png\")\nimg","034d3e5c":"#Mask for image \"b552fb0d9d.png\"\n\nmask = Image.open(TRAIN_MASK_DIR+\"b552fb0d9d.png\")\nmask","ea577f38":"def read_image(file_name):    \n    path = TRAIN_IMAGE_DIR+file_name\n    img = Image.open(path)\n    img = img.convert('RGB')\n    return img\n    \ndef read_mask(file_name):\n    path = TRAIN_MASK_DIR+file_name   \n    img = Image.open(path)\n    #8-bit pixels, black and white\n    bk = Image.new('L', size=img.size)\n    g = Image.merge('RGB', (bk, img.convert('L'), bk))\n    return g\n\nfrom image_dataset_viz import DatasetExporter\n\n\nde = DatasetExporter(read_image, read_mask, blend_alpha=0.2, n_cols=20, max_output_img_size=(100, 100))\nde.export(train_file_lst, train_mask_lst, \"train_dataset_viz\")","7f6d7b05":"!ls train_dataset_viz","d3e6fc3d":"ds_viz_image = Image.open(\"train_dataset_viz\/dataset_part_0.png\")","55fa15ec":"ds_viz_image","25cfee6a":"Histogram check and null value check in the depth data","396ececb":"Lets have a quick look into depth data","abcfe8ca":"So 79 duplicate images in train data.\nLets display one duplicate image and corresponding mask ","d549a07d":"So there is no null values for depth  data.\n\n**Exploring image data**\n\nCalculate MD5sum of each image and check for duplicate"}}