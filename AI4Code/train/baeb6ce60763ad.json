{"cell_type":{"c5e05910":"code","496e92b4":"code","1c9ddb01":"code","67efd01f":"code","c7891381":"code","ad6ea6c5":"code","d5f8951b":"code","395fb40c":"code","1258a0ab":"code","b791d106":"code","159b9d49":"code","46817c53":"code","9381b259":"code","1da28676":"markdown","a1bcb6f0":"markdown"},"source":{"c5e05910":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","496e92b4":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n\ntrain.head()","1c9ddb01":"train.describe().loc['max',].max()","67efd01f":"train.shape, test.shape","c7891381":"Y_train = train['label'].values\nX_train = (train.loc[:, 'pixel0':] \/ 255).values\n\nX_train.shape, Y_train.shape","ad6ea6c5":"X_test = (test \/ 255).values","d5f8951b":"from keras import models, optimizers\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import Dense, Dropout\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nmodel = models.Sequential()\nmodel.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer=optimizers.Adam(lr=1e-3), \n              loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n\ndef lr_scheduler(epoch, lr):\n    return lr * 0.9\n\ncheckpoint_path = 'bestmodel2.hdf5'\ncheckpoint = ModelCheckpoint(checkpoint_path, monitor='val_sparse_categorical_accuracy', \n                             verbose=0, save_best_only=True, mode='max')\n\nscheduler = LearningRateScheduler(lr_scheduler, verbose=0)\n\nearly_stop = EarlyStopping(monitor='var_loss', min_delta=0, patience=5, mode='min', verbose=0)\n\ntqdm_callback = tfa.callbacks.TQDMProgressBar(leave_epoch_progress=False, \n                                              leave_overall_progress=True, \n                                              show_epoch_progress=False,\n                                              show_overall_progress=True)\n\ncallbacks_list = [checkpoint, scheduler, tqdm_callback, early_stop]\n\n\nhistory = model.fit(X_train, Y_train, batch_size=200, epochs=100, \n                    callbacks=callbacks_list, verbose=0, validation_split=0.2)","395fb40c":"def graph_plot(history):\n    \n    for i in history.history.keys():\n        print(f'{i}\\nmin = {min(history.history[i])}, max = {max(history.history[i])}\\n')\n    \n    epoch = len(history.history['loss'])\n    for k in list(history.history.keys()):\n        if 'val' not in k:\n            plt.figure(figsize=(10, 7))\n            plt.plot(history.history[k])\n            if k != 'lr':\n                plt.plot(history.history['val_' + k])\n            plt.title(k, fontsize=10)\n\n            plt.ylabel(k)\n            plt.xlabel('epoch')\n            plt.grid()\n\n            plt.yticks(fontsize=10, rotation=30)\n            plt.xticks(fontsize=10, rotation=30)\n            plt.legend(['train', 'test'], loc='upper left', fontsize=10, title_fontsize=15)\n            plt.show()\n            \ngraph_plot(history)","1258a0ab":"from keras.layers import Conv2D, MaxPooling2D, Flatten\n\nX_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n\nmodel2 = models.Sequential()\nmodel2.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n\nmodel2.add(MaxPooling2D((2, 2)))\nmodel2.add(Conv2D(128, (3, 3), activation='relu'))\n\nmodel2.add(MaxPooling2D((2, 2)))\nmodel2.add(Conv2D(96, (3, 3), activation='relu'))\n\nmodel2.add(Flatten())\nmodel2.add(Dense(128, activation='relu'))\nmodel2.add(Dropout(0.6))\nmodel2.add(Dense(64, activation='relu'))\nmodel2.add(Dropout(0.6))\nmodel2.add(Dense(10, activation='softmax'))\n\nmodel2.compile(optimizer=optimizers.Adam(lr=1e-3), \n              loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n\ncheckpoint_path2 = 'bestmodel2.hdf5'\ncheckpoint2 = ModelCheckpoint(checkpoint_path2, monitor='val_sparse_categorical_accuracy', \n                             verbose=0, save_best_only=True, mode='max')\n\nscheduler2 = LearningRateScheduler(lr_scheduler, verbose=0)\n\nearly_stop2 = EarlyStopping(monitor='var_loss', min_delta=0, patience=5, mode='min', verbose=0)\n\ntqdm_callback2 = tfa.callbacks.TQDMProgressBar(leave_epoch_progress=False, \n                                              leave_overall_progress=True, \n                                              show_epoch_progress=False,\n                                              show_overall_progress=True)\n\ncallbacks_list2 = [checkpoint2, scheduler2, tqdm_callback2, early_stop2]\n\n\nhistory2 = model2.fit(X_train, Y_train, batch_size=390, epochs=30, \n                    callbacks=callbacks_list2, verbose=0, validation_split=0.2)","b791d106":"graph_plot(history2)","159b9d49":"model2.load_weights(checkpoint_path2)\nX_test = X_test.reshape((X_test.shape[0], 28, 28, 1))","46817c53":"submit = pd.DataFrame(np.argmax(model2.predict(X_test), axis=1), columns=['Label'], \n                      index=pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')['ImageId'])\n\nsubmit.index.name = 'ImageId'\nsubmit.to_csv('submittion.csv')","9381b259":"submit","1da28676":"Normalize","a1bcb6f0":"Not bit\n\nRGB format"}}