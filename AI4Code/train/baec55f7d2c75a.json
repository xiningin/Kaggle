{"cell_type":{"21e0056c":"code","4b9d31c9":"code","1dd660d7":"code","31427125":"code","9433eb75":"code","8a4786aa":"code","bcadb1bf":"code","b6c663fe":"code","e5f24599":"code","7556e377":"code","4eb7323e":"code","54fb3632":"code","4b17fc50":"code","a332fb32":"code","e5ccbc5c":"code","8f7119da":"code","d97b0524":"code","a9c888d8":"code","f61ee339":"code","766a5094":"code","b4ad430b":"code","c241354a":"code","9b2e34aa":"code","36181b30":"code","dca751da":"code","5a6ccbd5":"code","afd9af20":"code","9c63e865":"code","745a5d5a":"code","c2360a7b":"code","64820cbc":"code","9a154325":"code","345cfbd0":"code","4bff0fd9":"code","ee298e6d":"code","63a28d65":"code","e21d49d4":"code","d484f6e2":"code","7192618d":"code","770baaf6":"code","e8dfcd4f":"markdown","06bbc185":"markdown","20d36ebe":"markdown","7f82a75b":"markdown","4b499217":"markdown","5d52f63d":"markdown","771ab6b0":"markdown","a56fcce0":"markdown"},"source":{"21e0056c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b9d31c9":"import warnings\nwarnings.filterwarnings('ignore')","1dd660d7":"## importing the dataset \ntitanic = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')","31427125":"## let's check the head\ntitanic.head()","9433eb75":"## let's check the shape\ntitanic.shape","8a4786aa":"# let's check info of dataset\ntitanic.info()","bcadb1bf":"## converted pclass into object type \ntitanic['Pclass']=titanic['Pclass'].astype('str')","b6c663fe":"## check for null values\nround(100*(titanic.isnull().sum()\/titanic.shape[0]),2)","e5f24599":"## cabin has 77% null values hence removing it \ntitanic.drop('Cabin',axis=1,inplace=True)","7556e377":"## remove rows don't have Embarked \ntitanic = titanic[~titanic['Embarked'].isnull()]","4eb7323e":"## impute the missing values with mean of the Age \nage_mean = titanic['Age'].mean()\ntitanic['Age'].fillna(age_mean,inplace=True)","54fb3632":"## computing the mean fare \nfare_mean = titanic['Fare'].mean()\n","4b17fc50":"## checking after removing null values\nround(100*(titanic.isnull().sum()\/titanic.shape[0]),2)","a332fb32":"## let's impute null values of age using mode\/median\n## hence check for outliers first\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncap_cols = ['Age','SibSp','Parch','Fare']\nplt.figure(figsize=(15,5))\nfor i in enumerate(cap_cols):\n    plt.subplot(2,2,i[0]+1)\n    sns.boxplot(titanic[i[1]])\nplt.tight_layout()\nplt.show()\n","e5ccbc5c":"## replacing outliers by some upper range and lower range values\nfor i in cap_cols:\n    q1 = titanic[i].quantile(0.05)\n    q3 = titanic[i].quantile(0.95)\n    titanic[i][titanic[i]<=q1]=q1\n    titanic[i][titanic[i]>=q3]=q3","8f7119da":"plt.figure(figsize=(15,5))\nfor i in enumerate(cap_cols):\n    plt.subplot(2,2,i[0]+1)\n    sns.boxplot(titanic[i[1]])\nplt.tight_layout()\nplt.show()","d97b0524":"## create dummy variables\ndummy = pd.get_dummies(titanic[['Sex','Embarked','Pclass']],drop_first=True)\ndummy.head()","a9c888d8":"titanic = pd.concat([titanic,dummy],axis=1)\n## concatinate our dummy sets with main dataframe","f61ee339":"titanic.drop(['Sex','Embarked','Ticket','Name','PassengerId','Pclass'],axis=1,inplace=True)","766a5094":"import sklearn\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ntitanic[cap_cols] = sc.fit_transform(titanic[cap_cols])","b4ad430b":"## check head after scaling\ntitanic.head()","c241354a":"y_train = titanic.pop('Survived')\nX_train = titanic","9b2e34aa":"from sklearn.svm import SVC\nsvc = SVC(C = 1).fit(X_train,y_train)","36181b30":"titanic['Survived_pred'] = svc.predict(X_train)","dca751da":"## check head once \ntitanic.head()","5a6ccbd5":"# Evaluate the model using confusion matrix \nfrom sklearn import metrics\nmetrics.confusion_matrix(y_true=y_train, y_pred=titanic.Survived_pred)","afd9af20":"# print other metrics\n\n# accuracy\nprint(\"accuracy\", metrics.accuracy_score(y_train, titanic.Survived_pred))\n\n# precision\nprint(\"precision\", metrics.precision_score(y_train, titanic.Survived_pred))\n\n# recall\/sensitivity\nprint(\"recall\", metrics.recall_score(y_train, titanic.Survived_pred))","9c63e865":"## let's prepare the test data \ntitanic_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","745a5d5a":"titanic_test[cap_cols] = sc.transform(titanic_test[cap_cols])","c2360a7b":"## converted pclass into object type \ntitanic_test['Pclass']=titanic_test['Pclass'].astype('str')","64820cbc":"## create dummy variables\ndummy_test = pd.get_dummies(titanic_test[['Sex','Embarked','Pclass']],drop_first=True)\ndummy_test.head()","9a154325":"titanic_test = pd.concat([titanic_test,dummy_test],axis=1)\n## concatenate our dummy sets","345cfbd0":"titanic_test.head()","4bff0fd9":"## impute the missing values with mean of the Age \ntitanic_test['Age'].fillna(age_mean,inplace=True)","ee298e6d":"titanic_test['Fare'].fillna(fare_mean,inplace=True) ## impute missing fare values ","63a28d65":"cols_pred = ['Age', 'SibSp', 'Parch', 'Fare', 'Sex_male', 'Embarked_Q', 'Embarked_S',\n       'Pclass_2', 'Pclass_3']\ntitanic_test['Survived'] = svc.predict(titanic_test[cols_pred])","e21d49d4":"titanic_test.head()","d484f6e2":"titanic_test_final = titanic_test[['PassengerId','Survived']]","7192618d":"titanic_test_final.head()","770baaf6":"titanic_test_final.to_csv(\"prediction_titanic_svm.csv\",index=False)\n","e8dfcd4f":"Divided our scaled data in X_train and y_train","06bbc185":"**SVM**\n* What is Support Vector Machine?\nThe objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N \u2014 the number of features) that distinctly classifies the data points.\nTo separate the two classes of data points, there are many possible hyperplanes that could be chosen. Our objective is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes. Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence.\nHyperplanes are decision boundaries that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes. Also, the dimension of the hyperplane depends upon the number of features. If the number of input features is 2, then the hyperplane is just a line. If the number of input features is 3, then the hyperplane becomes a two-dimensional plane. It becomes difficult to imagine when the number of features exceeds 3.\nSupport vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM.\n\ncheck out the link for more clarification on svm : [https:\/\/towardsdatascience.com\/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47](http:\/\/)","20d36ebe":"Finally created our dataframe on test data with our model's prediction","7f82a75b":"Fit SVC model and also added the prediction in our dataframe","4b499217":"# Titanic survival prediction using SVM","5d52f63d":"Drop some of the variables like sex,embarked,ticket,name,passengerid and pclass as they are not going to be very useful in building our model.\n* Embarked's dummy variable created hence remove this variable\n* Sex's dummy variable created hence remove this variable\n* Pclass's dummy variable created hence remove this variable\n* Ticket,Name,PassengerId not important for predicting survival","771ab6b0":"checking variables after done capping.","a56fcce0":"Check the head and uploaded my prediction"}}