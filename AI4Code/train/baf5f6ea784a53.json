{"cell_type":{"7a9b9941":"code","f7532bad":"code","409f20b4":"code","c1b34d78":"code","9f067000":"code","6d633547":"code","15a91951":"code","f7494c13":"code","fd6087d3":"code","182999d0":"code","3e3d473e":"code","c5a79f78":"code","5fe56f14":"code","6570c84f":"code","e419ad59":"code","ac18c05c":"code","9c763cd8":"code","3d0ef9af":"code","db016643":"markdown","7c6864c9":"markdown","7b607911":"markdown","658ceb7e":"markdown","10ba8942":"markdown","f41289b3":"markdown","904b7818":"markdown","3930ce8f":"markdown","3d79b125":"markdown","adb0b000":"markdown"},"source":{"7a9b9941":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport torch\nimport glob\nimport os\nimport pathlib\nimport matplotlib.pyplot as plt\nfrom fastai.imports import *\nfrom fastai.transforms import *\nfrom fastai.conv_learner import *\nfrom fastai.model import *\nfrom fastai.dataset import *\nfrom fastai.sgdr import *\nfrom fastai.plots import *","f7532bad":"PATH = \"..\/input\/10-monkey-species\/\"\nsz=224","409f20b4":"labels = np.array(pd.read_csv(\"..\/input\/10-monkey-species\/monkey_labels.txt\", header=None, skiprows=1).iloc[:,2])\nlabels = [labels[i].strip() for i in range(len(labels))]\nlabels_name = ['Class: %d, %s'%(i,labels[i]) for i in range(10)]","c1b34d78":"def plots(ims, figsize=(12,6), rows=3, titles=None):\n    f = plt.figure(figsize=figsize)\n    for i in range(len(ims)):\n        sp = f.add_subplot(rows, len(ims)\/\/rows+1, i+1)\n        sp.axis('Off')\n        if titles is not None: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i])","9f067000":"imgs = []\nfor i in range(10):\n    file = os.listdir(f'{PATH}training\/training\/n%d'%i)\n    img = plt.imread(f'{PATH}training\/training\/n%d\/{file[0]}'%i)\n    imgs.append(img)\n\nplots(imgs, titles=labels_name, rows=4, figsize=(16,15))","6d633547":"cache_dir = os.path.expanduser(os.path.join('~', '.torch'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)","15a91951":"!cp ..\/input\/resnet34\/resnet34.pth \/tmp\/.torch\/models\/resnet34-333f7ec4.pth","f7494c13":"arch = resnet34\ndata = ImageClassifierData.from_paths(PATH, tfms=tfms_from_model(arch, sz), trn_name='training\/training', val_name='validation\/validation')\ndata.path = pathlib.Path('.') \nlearn = ConvLearner.pretrained(arch, data, precompute=False)\nlearn.fit(0.01, 2)","fd6087d3":"log_preds = predict(learn.model,learn.data.val_dl)\npreds = np.argmax(log_preds, axis=1)","182999d0":"def correct(is_correct): return np.where((preds == data.val_y)==is_correct)[0]\n\ndef load_img_id(ds, idx): return np.array(PIL.Image.open(PATH+ds.fnames[idx]))\n\ndef plot_val_with_title(idxs, title):\n    imgs = [load_img_id(data.val_ds,x) for x in idxs]\n    title_probs = ['Prediction: %d, Truth: %d'%(preds[x],data.val_y[x]) for x in idxs]\n    print(title)\n    return plots(imgs, rows=1, titles=title_probs, figsize=(16,8))","3e3d473e":"plot_val_with_title(np.random.choice(correct(True),3,replace=False), \"Correctly classified\")","c5a79f78":"plot_val_with_title(correct(False), \"All Incorrectly classified\")","5fe56f14":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(data.val_y, preds)","6570c84f":"plot_confusion_matrix(cm, data.classes)","e419ad59":"pltimgs = [plt.imread('..\/input\/monkeys\/'+name) for name in os.listdir('..\/input\/monkeys\/')]","ac18c05c":"plots(pltimgs, titles=os.listdir('..\/input\/monkeys\/'), rows=2, figsize=(16,15))","9c763cd8":"trn_tfms, val_tfms = tfms_from_model(arch,sz)\ntest_imgs = [val_tfms(open_image('..\/input\/monkeys\/'+name)) for name in os.listdir('..\/input\/monkeys\/')]\nlearn.precompute=False\ntest_pred = learn.predict_array(test_imgs)\ntest_pred = np.argmax(test_pred, axis=1)\ntest_pred","3d0ef9af":"plots(pltimgs, titles=['Predict: '+labels[i] for i in test_pred], rows=2, figsize=(16,15))","db016643":"## Confusion Matrix\nWe can also observe the confusion matrix to see the correct\/incorrectly classified instances of all classes.","7c6864c9":"## Predictions for Validation Set\nModel is allowed to run on validation set and predictions for their classes are made.","7b607911":"## All Instances of Incorrectly Classified Monkeys\nWe can view all the instances in which a monkey was wrongly classified. ","658ceb7e":"## Random Examples of Correctly Classified Monkeys","10ba8942":"## Train Model\nResNet weights are already powerful enough to achieve high classification accuracy without needing a large number of epochs (we use only 2 in this case), and is able to arrive at 99% accuracy of classifying the 10 monkey species within a couple of GPU-minutes.","f41289b3":"## Testing on a Random Pictures\nHere, a few pictures of monkeys are obtained from the internet. We check if the network is able to correctly identify their species. For fun, we include also a picture of a monkey not from any of the 10 above species.","904b7818":"# Training Monkey Recognition with Fast.ai and ResNet34\nMonkey classification performed using a pre-trained model with ImageNet (1.2 million images and 1000 classes). The pre-trained ResNet34 is a CNN model, a varied version of the model that won the 2015 ImageNet competition.\n\n[ResNet-34](https:\/\/www.kaggle.com\/pytorch\/resnet34\/home): Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n[https:\/\/arxiv.org\/abs\/1512.03385](https:\/\/arxiv.org\/abs\/1512.03385)\n\nThis method achieved a **high accuracy of 98%-100% on validation** (depending on seed), wrongly classifying only 1~3 monkeys out of the 272 validation examples, proving ResNet34 to also be well-adapted to a general purpose as detecting feature differences in monkey species.","3930ce8f":"## Load ResNet34\nIf working without internet connection, the following steps are necessary to import the resnet34 weights. Otherwise, these are not necessary.","3d79b125":"## Viewing some monkeys\nLet's first view the different species names along with an image from that class.","adb0b000":"Except for the gorilla which was identified, the other monkeys are all correctly classified."}}