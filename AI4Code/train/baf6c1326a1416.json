{"cell_type":{"b9d7deaa":"code","e4c258cc":"code","ac2c059b":"code","cfb96b68":"code","bf3f78af":"code","91dca253":"code","034cba24":"code","2278b9fb":"code","38ddaf82":"code","be5c4ec0":"code","9aa4c031":"code","ae78b806":"code","9791d008":"code","3f8af4e6":"code","907e50a5":"code","a142e74e":"code","febd4c62":"code","de8b54ee":"code","950e7f2d":"code","747e10f5":"code","46aa143b":"code","e652498f":"code","a77a4827":"code","96423dd8":"code","2711068c":"markdown","7d9dc0b0":"markdown","cfc154fc":"markdown","3e4ff614":"markdown","5e9a7584":"markdown","6e162f82":"markdown","0917a8cd":"markdown","b0f15b23":"markdown","548bc7cc":"markdown","8f11f304":"markdown","2e11197f":"markdown","134481dd":"markdown","39ae4510":"markdown"},"source":{"b9d7deaa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e4c258cc":"# for visualizations\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.rcParams['figure.figsize'] = (18, 8)\n\n# for interactive visualizations\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected = True)\nimport plotly.figure_factory as ff\n\n# for Model Building\nfrom sklearn.cluster import KMeans\n\nimport warnings \nwarnings.filterwarnings('ignore')","ac2c059b":"df= pd.read_csv('\/kaggle\/input\/mall-customers\/Mall_Customers.csv')\ndata = ff.create_table(df.head())\npy.iplot(data)","cfb96b68":"df.rename(columns={'Genre':'Gender'},inplace= True)","bf3f78af":"# Checking the shape of dataframe\ndf.shape","91dca253":"# summary statistics\ndf.describe()","034cba24":"# checking if there is any missing value present in dataset\ndf.isnull().sum()","2278b9fb":"sns.heatmap(df.corr(), cmap = 'plasma', annot = True)\nplt.show()","38ddaf82":"sns.kdeplot(df['Age'], palette = 'OrRd')\nplt.title('Distribution of Age', fontsize = 20)\nplt.show()","be5c4ec0":"plt.figure(figsize=(10,6))\nsns.countplot(df['Gender'])\nplt.title('Count Plot For Gender')\nplt.show()","9aa4c031":"plt.figure(figsize=(24,8))\nsns.countplot(df['Spending Score (1-100)'], palette = 'tab10')\nplt.title('count plot of Spending Score', fontsize = 15)\nplt.show()","ae78b806":"plt.figure(figsize=(10,6))\nsns.histplot(df['Annual Income (k$)'], palette = 'tab10')\nplt.title('Distribution of Annual Income', fontsize = 20)\nplt.show()","9791d008":"# Encoding Gender column\ndf['Gender'] = df['Gender'].map({'Female':0,'Male':1})","3f8af4e6":"df.head()","907e50a5":"# creating independent variables matrix\nX = df.loc[:, ['Annual Income (k$)', 'Spending Score (1-100)']].values","a142e74e":"# Inertia: It is the sum of squared distances of samples to their closest cluster center.\ninertia = []\nfor i in range(1, 15):\n    ''' We iterate the values of k from 1 to 15 and \n    calculate the inertia for each value of k in the given range.'''\n    ## Building and fitting the model\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10)\n    kmeans.fit(X)\n    inertia.append(kmeans.inertia_)","febd4c62":"# The Elbow Method\n# Plotting Number of Clusters Vs Inertia\nplt.plot(range(1, 15), inertia,'bx-')\nplt.title('The Elbow Method using Inertia')\nplt.xlabel('Number of clusters')\nplt.ylabel('inertia')\nplt.show()","de8b54ee":"#Taking number of clusters = 5\nkmeans = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, n_init = 10)\ny_kmeans = kmeans.fit_predict(X)","950e7f2d":"# PLotting the clusters\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'yellow', label = 'Cluster-A')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'red', label = 'Cluster-B')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster-C')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'blue', label = 'Cluster-D')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'pink', label = 'Cluster-E')\nplt.title('Clusters of Customers')\nplt.xlabel('Annual income(k$)')\nplt.ylabel('spending score')\nplt.legend()\nplt.show()","747e10f5":"y = df.iloc[:, [2, 4]].values","46aa143b":"wss = []\nfor i in range(1, 15):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 50)\n    kmeans.fit(y)\n    wss.append(kmeans.inertia_)\n\nplt.rcParams['figure.figsize'] = (13, 5)\nplt.plot(range(1, 15), wss)\nplt.title('K-Means Clustering(The Elbow Method)', fontsize = 20)\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.grid()\nplt.show()","e652498f":"kmeans = KMeans(n_clusters = 4, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 50)\nymeans = kmeans.fit_predict(y)\n\nplt.rcParams['figure.figsize'] = (30, 10)\nplt.title('Cluster of Ages', fontsize = 30)\n\nplt.scatter(y[ymeans == 0, 0], y[ymeans == 0, 1], s = 100, c = 'pink', label = 'Usual Customers' )\nplt.scatter(y[ymeans == 1, 0], y[ymeans == 1, 1], s = 100, c = 'orange', label = 'Priority Customers')\nplt.scatter(y[ymeans == 2, 0], y[ymeans == 2, 1], s = 100, c = 'lightgreen', label = 'Target Customers(Young)')\nplt.scatter(y[ymeans == 3, 0], y[ymeans == 3, 1], s = 100, c = 'red', label = 'Target Customers(Old)')\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 50, c = 'black')\n\nplt.style.use('dark_background')\nplt.xlabel('Age')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.grid()\nplt.show()\n","a77a4827":"x = df[['Age', 'Spending Score (1-100)', 'Annual Income (k$)']].values\nkm = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 50)\nkm.fit(x)\nlabels = km.labels_\ncentroids = km.cluster_centers_","96423dd8":"df['labels'] =  labels\ntrace1 = go.Scatter3d(\n    x= df['Age'],\n    y= df['Spending Score (1-100)'],\n    z= df['Annual Income (k$)'],\n    mode='markers',\n     marker=dict(\n        color = df['labels'], \n        size= 10,\n        line=dict(\n            color= df['labels'],\n            width= 12\n        ),\n        opacity=0.8\n     )\n)\ndf = [trace1]\n\nlayout = go.Layout(\n    title = 'Character vs Gender vs Alive or not',\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0  \n    ),\n    scene = dict(\n            xaxis = dict(title  = 'Age'),\n            yaxis = dict(title  = 'Spending Score'),\n            zaxis = dict(title  = 'Annual Income')\n        \n        )\n)\n\nfig = go.Figure(data = df, layout = layout)\npy.iplot(fig)","2711068c":"### Clustering ","7d9dc0b0":"### Exploratory Data Analysis(EDA)","cfc154fc":"**To determine the optimal number of clusters, we have to select the value of k at the \u201celbow\u201d ie the point after which the inertia start decreasing in a linear fashion. Thus for the given data, we conclude that the optimal number of clusters for the data is 5.**","3e4ff614":"**Building the clustering model and calculating the values of Inertia:**","5e9a7584":"**As we can see there are 200 observations and 5 features.**","6e162f82":"**Visualizing the result**","0917a8cd":"### Importing Libraries","b0f15b23":"#### Taking only Age and Spending score as a feature","548bc7cc":"### Load the Data","8f11f304":"#### Correlation Plot","2e11197f":"#### Taking Age,spending score and Annual Income","134481dd":"**Optimal Number of cluster is 4.**","39ae4510":"### Data PreProcesssing"}}