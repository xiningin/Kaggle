{"cell_type":{"9fcebe2f":"code","3ad54adb":"code","fb5701b8":"code","cd9ce2cd":"code","5026142c":"code","0b04784c":"code","626e9dab":"code","0c7b9753":"code","acdd8571":"code","6edaf1ab":"code","ae06331f":"code","22b6098a":"code","7828963b":"code","8c8c1260":"code","a79bca02":"code","18731ce6":"code","8e40a982":"code","99e5d57b":"code","b3ffe465":"code","25c7ca20":"code","727fc0d7":"code","5382ab9e":"code","16b74573":"code","04b8ff30":"markdown","f2ad93db":"markdown","94822c31":"markdown","c9e1f472":"markdown","471ee3d0":"markdown","f8614fc2":"markdown"},"source":{"9fcebe2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ad54adb":"#import module\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nimport warnings\n","fb5701b8":"data = pd.read_csv(\"\/kaggle\/input\/students-performance-in-exams\/StudentsPerformance.csv\")\ndata.head()","cd9ce2cd":"data[\"mean_scores\"] = (data[\"math score\"] + data[\"reading score\"] + data[\"writing score\"]) \/ 3","5026142c":"# There is no missing value so I want to look statistical information with describe()\ndata.info()","0b04784c":"data.describe().T\n# data is distributed as normally but,\n# math score has 0 point cause math is harder than other all the time.\n# when I look the data, I can see min exam_score is 27.\n# Values of mean and 50% is so close.","626e9dab":"data.corr()\n# I want to look before I do get_dummies","0c7b9753":"import matplotlib.pyplot as plt\n# I did that to see histogram plot and distribution of exam_scores\n\ndef histogramPlot(variable):\n    variable.plot(kind = \"hist\", density = True, bins = 15)\n    variable.plot(kind = \"kde\");\n\nif __name__=='__main__':\n    histogramPlot(data)","acdd8571":"data.head()","6edaf1ab":"data.columns","ae06331f":"def groupbyFunc(data, feature):\n    # The function that you can use to analyze the mean of the features you have given and their situation in the data.\n    values = data[feature].value_counts()\n    feature_analysis = data.groupby(feature).mean()\n    return values,feature_analysis    \n    \n    \n# Firstly\ngroupbyFunc(data, \"parental level of education\")","22b6098a":"# Secondly\ngroupbyFunc(data, \"race\/ethnicity\")","7828963b":"# Lastly\ngroupbyFunc(data, \"gender\")","8c8c1260":"# I have to drop values of outlier scores to take a better rmse value.\nsns.boxplot( y = data[\"math score\"])\nplt.show()\n\nsns.boxplot(y = data[\"reading score\"] )\nplt.show()\n\n\nsns.boxplot(y = data[\"writing score\"])\nplt.show()\n\nsns.boxplot(y = data[\"mean_scores\"])\nplt.show()","a79bca02":"def drop_outliers(df,column_name,lower,upper):\n    drop_outliers = df[column_name].between(df[column_name].quantile(lower), df[column_name].quantile(upper))\n    \n    print(str(df[column_name][drop_outliers].size) + \"\/\" + str(df[column_name].size) + \" data points remain.\") \n\n    index_names = df[~drop_outliers].index\n    return df.drop(index_names)\n\n\nnew_data = drop_outliers(data,\"mean_scores\",0.05,0.95) ","18731ce6":"print(\"data:\",data.shape)\nprint(\"new_data:\", new_data.shape)","8e40a982":"math_score = new_data[\"math score\"]\nreading_score = new_data[\"reading score\"]\nwriting_score = new_data[\"writing score\"]\nmean_score = new_data[\"mean_scores\"]\nX_features = new_data.drop([\"math score\",\"reading score\",\"writing score\",\"mean_scores\"],axis = 'columns')","99e5d57b":"X_features.head()","b3ffe465":"X_features_encoded = X_features.apply(lambda x: x.astype('category')) \n\nX_features_encoded = pd.get_dummies(X_features_encoded,drop_first= True)\nX_features_encoded.head()\n","25c7ca20":"mean_score","727fc0d7":"target = mean_score\nX_train, X_val, y_train, y_val = train_test_split(X_features_encoded, \n                                                      target, \n                                                      test_size=0.4, \n                                                      shuffle = True, \n                                                      random_state=1)","5382ab9e":"# true ---> real     predicted---> predict\ndef calculateModel(real, predict):\n    rmse = np.sqrt(mean_squared_error(real, predict))\n    r2 = r2_score(real, predict)\n    print(\"rmse:\",rmse)\n    print(\"r2 score:\",r2)","16b74573":"## Random Forest and Linear Model that I tried to calculate model\nprint(\"Random Forest Regressor\")\nprint(\"------------\")\nrf = RandomForestRegressor(random_state=0).fit(X_train, y_train)\nrf_pred = rf.predict(X_train)\nprint(\"Train set of RF\")\ncalculateModel(y_train,rf_pred)\n\nprint(\"------------\")\nprint(\"Test set of RF\")\nrf_pred_val= rf.predict(X_val)\ncalculateModel(y_val,rf_pred_val)\n\nprint(\"------------\")\n\n\nprint(\"Linear Regression\")\nprint(\"------------\")\nlr = LinearRegression(normalize=True).fit(X_train, y_train)\nlr_pred = lr.predict(X_train)\nprint(\"Train set of LR\")\ncalculateModel(y_train,lr_pred)\n\nprint(\"------------\")\nprint(\"Test set of LR\")\nlr_pred_val= lr.predict(X_val)\ncalculateModel(y_val,lr_pred_val)\n","04b8ff30":"## RMSE","f2ad93db":"#### I can say: when parents of the student were graduated the master degree and bachelor degree, students are better at lessons","94822c31":"## Get Dummy Function\n","c9e1f472":"## Modeling","471ee3d0":"## Train Test","f8614fc2":"### Libraries "}}