{"cell_type":{"1b646259":"code","1ec2211a":"code","fc733857":"code","cf8f02e7":"code","2afc0b82":"code","dd5b19b2":"code","2657c16e":"code","e0e16343":"code","3d6a6e38":"code","0c7bdaeb":"code","229d8663":"code","4bf1a263":"code","8484f957":"code","e163c378":"code","0e19ae8a":"code","9541e05c":"code","7f1a0a05":"code","21fa3814":"code","112a8ddb":"code","bd5c1413":"code","79f67cf5":"code","c5b2a5aa":"code","a7d81e74":"code","ae98c8ce":"code","3a5b571e":"code","8c71e628":"code","cf76088b":"code","96fcfc0a":"code","84f5a106":"markdown","182893a3":"markdown","b9d54d60":"markdown","5940db2a":"markdown","bd9ac5e2":"markdown","8fa4043b":"markdown","6cb2edde":"markdown","7d636abe":"markdown"},"source":{"1b646259":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ec2211a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n!pip install tensorflow==1.14\nimport random\nfrom collections import Counter\nfrom sklearn.metrics import roc_curve, auc, average_precision_score","fc733857":"import tensorflow as tf\ntf.__version__","cf8f02e7":"path = '..\/input\/steam-games-2017-cleaned\/steam-200k-cleaned.csv'\n#path = 'steam-200k.csv'\ndf = pd.read_csv(path, header = None,\n                 names = ['UserID', 'Game', 'Action', 'Hours', 'Other'])\ndf.head()\n\ndf['Hours_Played'] = df['Hours'].astype('float32')\n\ndf.loc[(df['Action'] == 'purchase') & (df['Hours'] == 1.0), 'Hours_Played'] = 0","2afc0b82":"df.UserID = df.UserID.astype('int')\ndf = df.sort_values(['UserID', 'Game', 'Hours_Played'])\n\nclean_df = df.drop_duplicates(['UserID', 'Game'], keep = 'last').drop(['Action', 'Hours', 'Other'], axis = 1)\n\n# every transaction is represented by only one record now\nclean_df.head()","dd5b19b2":"n_users = len(clean_df.UserID.unique())\nn_games = len(clean_df.Game.unique())\n\nprint('There are {0} users and {1} games in the data'.format(n_users, n_games))","2657c16e":"sparsity = clean_df.shape[0] \/ float(n_users * n_games)\nprint('{:.2%} of the user-item matrix is filled'.format(sparsity))","e0e16343":"user_counter = Counter()\nfor user in clean_df.UserID.tolist():\n    user_counter[user] +=1\n\ngame_counter = Counter()\nfor game in clean_df.Game.tolist():\n    game_counter[game] += 1\n\nuser2idx = {user: i for i, user in enumerate(clean_df.UserID.unique())}\nidx2user = {i: user for user, i in user2idx.items()}\n\ngame2idx = {game: i for i, game in enumerate(clean_df.Game.unique())}\nidx2game = {i: game for game, i in game2idx.items()}","3d6a6e38":"user_idx = clean_df['UserID'].apply(lambda x: user2idx[x]).values\ngame_idx = clean_df['gameIdx'] = clean_df['Game'].apply(lambda x: game2idx[x]).values\nhours = clean_df['Hours_Played'].values","0c7bdaeb":"zero_matrix = np.zeros(shape = (n_users, n_games)) # Create a zero matrix\nuser_game_pref = zero_matrix.copy()\nuser_game_pref[user_idx, game_idx] = 1 # Fill preference matrix\n\nuser_game_interactions = zero_matrix.copy()\n# Confidence matrix\nuser_game_interactions[user_idx, game_idx] = hours + 1 ","229d8663":"#\uac80\uc99d\n\nk = 5\n\n# Count the number of purchases for each user\npurchase_counts = np.apply_along_axis(np.bincount, 1, user_game_pref.astype(int))\nbuyers_idx = np.where(purchase_counts[:, 1] >= 2 * k)[0] #find the users who purchase 2 * k games\nprint('{0} users bought {1} or more games'.format(len(buyers_idx), 2 * k))","4bf1a263":"test_frac = 0.2 # Let's save 10% of the data for validation and 10% for testing.\ntest_users_idx = np.random.choice(buyers_idx,\n                                  size = int(np.ceil(len(buyers_idx) * test_frac)),\n                                  replace = False)","8484f957":"val_users_idx = test_users_idx[:int(len(test_users_idx) \/ 2)]\ntest_users_idx = test_users_idx[int(len(test_users_idx) \/ 2):]","e163c378":"def data_process(dat, train, test, user_idx, k):\n    for user in user_idx:\n        purchases = np.where(dat[user, :] == 1)[0]\n        mask = np.random.choice(purchases, size = k, replace = False)\n        \n        train[user, mask] = 0\n        test[user, mask] = dat[user, mask]\n    return train, test","0e19ae8a":"train_matrix = user_game_pref.copy()\ntest_matrix = zero_matrix.copy()\nval_matrix = zero_matrix.copy()\n\n# Mask the train matrix and create the validation and test matrices\ntrain_matrix, val_matrix = data_process(user_game_pref, train_matrix, val_matrix, val_users_idx, k)\ntrain_matrix, test_matrix = data_process(user_game_pref, train_matrix, test_matrix, test_users_idx, k)","9541e05c":"test_matrix[test_users_idx[0], test_matrix[test_users_idx[0], :].nonzero()[0]]","7f1a0a05":"train_matrix[test_users_idx[0], test_matrix[test_users_idx[0], :].nonzero()[0]]","21fa3814":"tf.reset_default_graph() # Create a new graphs\n\npref = tf.placeholder(tf.float32, (n_users, n_games))  # Here's the preference matrix\ninteractions = tf.placeholder(tf.float32, (n_users, n_games)) # Here's the hours played matrix\nusers_idx = tf.placeholder(tf.int32, (None))","112a8ddb":"n_features = 30 # \ucd94\ucd9c\ub418\ub294 \ud53c\uccd0 \uc218\n\n# The X matrix represents the user latent preferences with a shape of user x latent features\nX = tf.Variable(tf.truncated_normal([n_users, n_features], mean = 0, stddev = 0.05))\n\n# The Y matrix represents the game latent features with a shape of game x latent features\nY = tf.Variable(tf.truncated_normal([n_games, n_features], mean = 0, stddev = 0.05))\n\n# Here's the initilization of the confidence parameter\nconf_alpha = tf.Variable(tf.random_uniform([1], 0, 1))","bd5c1413":"#user bias\nuser_bias = tf.Variable(tf.truncated_normal([n_users, 1], stddev = 0.2))\n\n# Concatenate the vector to the user matrix\nX_plus_bias = tf.concat([X, \n                         #tf.convert_to_tensor(user_bias, dtype = tf.float32),\n                         user_bias,\n                         tf.ones((n_users, 1), dtype = tf.float32)], axis = 1)","79f67cf5":"# game bias\nitem_bias = tf.Variable(tf.truncated_normal([n_games, 1], stddev = 0.2))\n\n# Cocatenate the vector to the game matrix\nY_plus_bias = tf.concat([Y, \n                         tf.ones((n_games, 1), dtype = tf.float32),\n                         item_bias],\n                         axis = 1)","c5b2a5aa":"pred_pref = tf.matmul(X_plus_bias, Y_plus_bias, transpose_b=True)\n\n# Construct the confidence matrix with the hours played and alpha paramter\nconf = 1 + conf_alpha * interactions","a7d81e74":"cost = tf.reduce_sum(tf.multiply(conf, tf.square(tf.subtract(pref, pred_pref))))\nl2_sqr = tf.nn.l2_loss(X) + tf.nn.l2_loss(Y) + tf.nn.l2_loss(user_bias) + tf.nn.l2_loss(item_bias)\nlambda_c = 0.01\nloss = cost + lambda_c * l2_sqr","ae98c8ce":"lr = 0.05\noptimize = tf.train.AdagradOptimizer(learning_rate = lr).minimize(loss)","3a5b571e":"# This is a function that helps to calculate the top k precision \ndef top_k_precision(pred, mat, k, user_idx):\n    precisions = []\n    \n    for user in user_idx:\n        rec = np.argsort(-pred[user, :]) # Found the top recommendation from the predictions\n        \n        top_k = rec[:k]\n        labels = mat[user, :].nonzero()[0]\n        \n        precision = len(set(top_k) & set(labels)) \/ float(k) # Calculate the precisions from actual labels\n        precisions.append(precision)\n    return np.mean(precisions) ","8c71e628":"iterations = 100\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    \n    for i in range(iterations):\n        sess.run(optimize, feed_dict = {pref: train_matrix,\n                                        interactions: user_game_interactions})\n        \n        if i % 10 == 0:\n            mod_loss = sess.run(loss, feed_dict = {pref: train_matrix,\n                                                   interactions: user_game_interactions})            \n            mod_pred = pred_pref.eval()\n            train_precision = top_k_precision(mod_pred, train_matrix, k, val_users_idx)\n            val_precision = top_k_precision(mod_pred, val_matrix, k, val_users_idx)\n            print('Iterations {0}...'.format(i),\n                  'Training Loss {:.2f}...'.format(mod_loss),\n                  'Train Precision {:.3f}...'.format(train_precision),\n                  'Val Precision {:.3f}'.format(val_precision)\n                )\n\n    rec = pred_pref.eval()\n    test_precision = top_k_precision(rec, test_matrix, k, test_users_idx)\n    print('\\n')\n    print('Test Precision{:.3f}'.format(test_precision))","cf76088b":"n_examples = 10\nusers = np.random.choice(test_users_idx, size = n_examples, replace = False)\nrec_games = np.argsort(-rec)","96fcfc0a":"for user in users:\n    print('User #{0} recommendations ...'.format(idx2user[user]))\n    purchase_history = np.where(train_matrix[user, :] != 0)[0]\n    recommendations = rec_games[user, :]\n\n    \n    new_recommendations = recommendations[~np.in1d(recommendations, purchase_history)][:k]\n    \n    print('Recommendations')\n    print(', '.join([idx2game[game] for game in new_recommendations]))\n    print('\\n')\n    print('Actual purchases')\n    print(', '.join([idx2game[game] for game in np.where(test_matrix[user, :] != 0)[0]]))\n    print('\\n')\n    print('Precision of {0}'.format(len(set(new_recommendations) & set(np.where(test_matrix[user, :] != 0)[0])) \/ float(k)))\n    print('--------------------------------------')\n    print('\\n')","84f5a106":"# Making a Steam game recommender with Collaborative filtering\n\n\ud55c\uae00\ubc88\uc5ed\uc740 [\uc5ec\uae30\ub85c](https:\/\/dnagooner.tistory.com\/51) \uac00\uc8fc\uc138\uc694\n\nBefore we begin, this project was inspired by [Wik Hung Pun's work](https:\/\/www.kaggle.com\/wikhung\/implicit-cf-tensorflow-implementation)\n\nCollaborative Filtering is a technique used for recommender systems. Collaborative filtering infers the preferences for new items given the known preferences from users.\n\nOne of the ways to implement collaborative filtering is  **Matrix Factorization**\n\nTo explain it simple, think of it as a matrix multiplication problem\n\n![image.png](attachment:image.png)\nHere is a depiction from Stienweg-Woods's image.\n\nTo explain it further, we consider the matrix R as a product of user preferences U and Item Features V. \n\nFor example, if I am a die-hard fan of Total War series, which is historical strategy game, then I will have high values in RTS \/ History \/ Grand Strategy \/ Turn based columns. Then, when recommending, it would find me a similar game, like Crusader Kings, which is also a historical strategy game.","182893a3":"# Adding biases\n\nThere could be differences with users and games. Some games like DOTA 2 just don't have an end. While on the other side, there could be users that tend to speedrun through games thanks to their experience.\n\nWe want to implement a statistical model to take care of such biases.","b9d54d60":"# Result evaluation\n\nSome users were very genre-based and predictable. User #22689481 got the following results :\n\n\nRecommendations\nCounter-Strike Condition Zero Deleted Scenes, Counter-Strike Condition Zero, Deathmatch Classic, Ricochet, Left 4 Dead 2\n\nActual purchases\nDeathmatch Classic, Half-Life 2 Lost Coast, Ricochet, Counter-Strike Condition Zero, Counter-Strike Condition Zero Deleted Scenes\n\n...which meant he is a very hardcore FPS gamer.\n\nHowever, some users such as User #129391396 got some strange-looking results such as :\n\nRecommendations\nCounter-Strike Global Offensive, Dota 2, Team Fortress 2, The Elder Scrolls V Skyrim, Portal\n\nActual purchases\nTeam Fortress 2, Call of Duty Modern Warfare 3, Call of Duty Modern Warfare 3 - Multiplayer, Rust, Stranded Deep\n\nMaybe he was affiliated with games that were popular (Team Fortress 2, Call of Duty, Rust), so he got recommended other commercially popular games recommended to him such as CS:GO(understandable as it is an FPS), Dota 2 and Skyrim.\n","5940db2a":"Here's the actual training session.","bd9ac5e2":"# User X game matrix formation\n\nWe use two matrices here\n\n1. Preference matrix : shows whether the user has actually purchased the game (1) or not (0)\n\n2. Confidence matrix : The matrix that shows the confidence measure, or how long the user played \/ enjoyed the specific game.","8fa4043b":"# Data cleaning\n\nThe original poster did a good job with cleaning the play and buy columns, and deleting all the buy columns.\n\nThe data was corrupted with DLCs and expansion packs. \n\nSince I am a huge gamer, I used whatever domain knowledge I have to cleanse the data.\n\nFor example, some games such as Skyrim and Dawn of War series which just act like expansions count as one.\n\nOther DLC \/ contents such as Total War : Shogun 2 - Fall of the Samurai which were independent enough counted as a separate entity from the original\n\nAlso, there were non-video game contents such as the Source Film Maker, which had to be filtered out.\n\nHowever, I counted some 'series' games such as Counter-Strike and Football Manager to be separate as the users play the older editions due to system changes\n","6cb2edde":"The overall cost of the model would become the square sum of predicted prefs and actual pref. Then, this cost is modified by conference matrix. To sum things up, I added I2-regularization like the original poster did... (and due to my lack of statistical skills)","7d636abe":"# Test\n\nThe overall precision score comes out really low. However, I think there should be a separate way to tell whether this precision is correct or not. (more domain-knowledge based like genre savvy-ness or the relations of the games etc)\n\nAfter all, the recommender is not doing its job if it recommends the games the user already bought."}}