{"cell_type":{"9fd45903":"code","28a10486":"code","89ba8163":"code","5d383f91":"code","bc008358":"code","d2898e2c":"code","7c9d48d4":"code","6fa819a5":"code","884cd004":"code","b1de43fb":"code","e2ed311d":"markdown","67770521":"markdown","6ef27b89":"markdown"},"source":{"9fd45903":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))","28a10486":"df = pd.read_json(\"..\/input\/recipes.json\")","89ba8163":"df.head()","5d383f91":"print(\"We have {} recipes\".format(df.shape[0]))","bc008358":"!python -m spacy download de_core_news_sm","d2898e2c":"import spacy\nnlp = spacy.load('de_core_news_sm', disable=['parser', 'tagger', 'ner'])","7c9d48d4":"tokenized = [nlp(t) for t in df['Instructions'].values]","6fa819a5":"for t in tokenized[0]:\n    print(t)","884cd004":"vocab = {}\nfor txt in tokenized:\n    for token in txt:\n        if token.text not in vocab.keys():\n            vocab[token.text] = len(vocab)","b1de43fb":"print(\"Number of unique tokens: {}\".format(len(vocab)))","e2ed311d":"We use spacy to tokenize the Instructions and investigate the vocabulary.","67770521":"# Load the recipe data","6ef27b89":"# Basic dataset statisitcs"}}