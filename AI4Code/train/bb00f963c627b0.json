{"cell_type":{"14ad974d":"code","1960caae":"code","b5416f53":"code","2ee95c9c":"code","2f13b89a":"code","136b8bef":"code","4df1c3c9":"code","3214805d":"code","57d17bbc":"code","f5f4d5fc":"code","323b934f":"code","b34be44d":"code","bfa5baf1":"code","0ba982b5":"markdown","5eca6171":"markdown","5ec1fb86":"markdown","f2ff0109":"markdown"},"source":{"14ad974d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nimport statistics\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1960caae":"df=pd.read_csv(\"\/kaggle\/input\/iris\/Iris.csv\")\ndf=df.iloc[:,1:]\ny=df['Species']\nx=df.iloc[:,:4]\n#Pr\u00e9-processamento\nencoder = LabelEncoder()\nencoder.fit(y)\nencoded_x = encoder.transform(y)\ny= np_utils.to_categorical(encoded_x)","b5416f53":"x['x0']=-1","2ee95c9c":"#Separar treino e teste\nframe=[x['x0'],x['SepalLengthCm'],x['SepalWidthCm'],x['PetalLengthCm'],x['PetalWidthCm']]\nx=pd.DataFrame(frame).T\ny=pd.DataFrame(y)\nX_train=pd.concat([x.iloc[:25,:],x.iloc[50:75,:],x.iloc[100:125,:]])\nx_test=pd.concat([x.iloc[25:50,:],x.iloc[75:100,:],x.iloc[125:,:]])\ny_train=pd.concat([y.iloc[:25,:],y.iloc[50:75,:],y.iloc[100:125,:]])\ny_test=pd.concat([y.iloc[25:50,:],y.iloc[75:100,:],y.iloc[125:,:]])","2f13b89a":"def saida_neuronio(vetor_peso, vetor_exemplo):\n    v=0\n    \n    for i in range(len(vetor_exemplo)):\n        v=v+vetor_peso[i]*vetor_exemplo[i]\n        \n    if(v>0):\n        return 1\n    else:\n        return 0","136b8bef":"def treinamento(erro_max,x,y,eta,w):\n    erro_total=erro_max\n    epoca=0\n    atualizacao=0\n    w=[0,0,0,0,0]\n    lista_erro=[]\n    while(erro_total>=erro_max):\n        epoca+=1\n        #print('#EPOCA:'+str(epoca))\n        \n        for i in range(len(x)):\n\n                f=saida_neuronio(w,x[i])\n                delta=(y[i][0]-f)\n                erro=delta*delta\n                erro_total=erro_total+erro\n                #print(\"y[\"+str(i)+\"]=\" + str(y[i][0])+ \",f=\"+str(f))\n                \n                if(erro>0):\n                    atualizacao=atualizacao+1\n                    for j in range(len(w)):\n                        w[j]=w[j] + eta * x[i][j] * delta\n                        \n                        #print(\", w[\"+str(j)+\"]=\" + str(w[j]))\n                    #print('Atualiza\u00e7\u00e3o='+ str(atualizacao) + '\\n')\n       \n        erro_total=0\n        #print()\n        for i in range(len(x)):\n\n                f=saida_neuronio(w,x[i])\n                delta=(y[i][0]-f)\n                erro=delta*delta\n                erro_total=erro_total+erro\n        #print(\"erro_total=\"+str(erro_total)+ '\\n')\n        lista_erro.append(erro_total)  \n                \n    return w,lista_erro\n       \nw=[0,0,0,0,0]                    \nvetor_w,lista_erro=treinamento(0.001,X_train.iloc[:,:].values,y_train.iloc[:,:].values,1,w)\nprint(\"Vetor de peso: \"+ str(vetor_w))","4df1c3c9":"def avaliar_setosa(x,y,w):\n    erro_total=0\n    for i in range(len(x)):\n\n        f=saida_neuronio(w,x[i])\n        delta=(y[i][0]-f)\n        erro=delta*delta\n        erro_total=erro_total+erro\n    return erro_total","3214805d":"#Calcular o erro no conjunto de teste\navaliar_setosa(x_test.iloc[:,:].values,y_test.iloc[:,:].values,vetor_w)\n","57d17bbc":"def treinamento_virginica(erro_max,x,y,eta,num_epoca,w):\n    erro_total=erro_max\n    epoca=0\n    atualizacao=0\n    lista_erro=[]\n    while(num_epoca>0):\n        epoca+=1\n        #print('#EPOCA:'+str(epoca))\n        \n        for i in range(len(x)):\n\n                f=saida_neuronio(w,x[i])\n                delta=(y[i][2]-f)\n                erro=delta*delta\n                erro_total=erro_total+erro\n                #print(\"y[\"+str(i)+\"]=\" + str(y[i][2])+ \",f=\"+str(f))\n                \n                if(erro>0):\n                    atualizacao=atualizacao+1\n                    for j in range(len(w)):\n                        w[j]=w[j] + eta * x[i][j] * delta\n                        \n                        #print(\", w[\"+str(j)+\"]=\" + str(w[j]))\n                    #print('Atualiza\u00e7\u00e3o='+ str(atualizacao) + '\\n')\n                \n        erro_total=0\n        num_epoca=num_epoca-1\n        #print()\n        for i in range(len(x)):\n\n                f=saida_neuronio(w,x[i])\n                delta=(y[i][2]-f)\n                erro=delta*delta\n                erro_total=erro_total+erro\n        #print(\"erro_total=\"+str(erro_total)+ '\\n')\n        lista_erro.append(erro_total)\n                \n    return w,lista_erro\n       \nw=[0,0,0,0,0]                 \nvetor_w,lista_erro=treinamento_virginica(0.001,X_train.iloc[:,:].values,y_train.iloc[:,:].values,1,100,w)\nprint(\"Vetor de peso: \"+ str(vetor_w))","f5f4d5fc":"def avaliar_virginica(x,y,w):\n    erro_total=0\n    for i in range(len(x)):\n\n        f=saida_neuronio(w,x[i])\n        delta=(y[i][2]-f)\n        erro=delta*delta\n        erro_total=erro_total+erro\n    return erro_total","323b934f":"#Calcular o erro no conjunto de teste\navaliar_virginica(x_test.iloc[:,:].values,y_test.iloc[:,:].values,vetor_w)","b34be44d":"def repetir_treinamento():\n    \n    data=pd.DataFrame(index=range(1))\n    data['mediaA_taxa0.1']=0\n    data['mediaB_taxa0.1']=0\n    data['desvioA_taxa0.1']=0\n    data['desvioB_taxa0.1']=0\n        \n    data['mediaA_taxa1']=0\n    data['mediaB_taxa1']=0\n    data['desvioA_taxa1']=0\n    data['desvioB_taxa1']=0\n    \n    data['mediaA_taxa10']=0\n    data['mediaB_taxa10']=0\n    data['desvioA_taxa10']=0\n    data['desvioB_taxa10']=0 \n    \n    L1_1=[]\n    L1_2=[]\n    \n    \n    L2_1=[]\n    L2_2=[]\n   \n    \n    L3_1=[]\n    L3_2=[]\n   \n    \n    for i in range(30):\n        w=np.random.rand(5)\n        #aprendizagem 0.1\n        t2_1,lista_errot2_1=treinamento_virginica(0.001,X_train.iloc[:,:].values,y_train.iloc[:,:].values,0.1,100,w)\n        t1_1,lista_errot1_1=treinamento(0.001,X_train.iloc[:,:].values,y_train.iloc[:,:].values,0.1,w)\n        V2=avaliar_virginica(x_test.iloc[:,:].values,y_test.iloc[:,:].values,t2_1)\n        V1=avaliar_setosa(x_test.iloc[:,:].values,y_test.iloc[:,:].values,t1_1)\n        L1_1.append(V1)\n        L1_2.append(V2)\n        \n        #aprendizagem 1\n        t2_2,lista_errot2_2=treinamento_virginica(0.001,X_train.iloc[:,:].values,y_train.iloc[:,:].values,1,100,w)\n        t1_2,lista_errot1_2=treinamento(0.001,X_train.iloc[:,:].values,y_train.iloc[:,:].values,1,w)\n        V2=avaliar_virginica(x_test.iloc[:,:].values,y_test.iloc[:,:].values,t2_2)\n        V1=avaliar_setosa(x_test.iloc[:,:].values,y_test.iloc[:,:].values,t1_2)\n        L2_1.append(V1)\n        L2_2.append(V2)\n        \n        \n        #aprendizagem 10\n        t2_3,lista_errot2_3=treinamento_virginica(0.001,X_train.iloc[:,:].values,y_train.iloc[:,:].values,10,100,w)\n        t1_3,lista_errot1_3=treinamento(0.001,X_train.iloc[:,:].values,y_train.iloc[:,:].values,10,w)\n        V2=avaliar_virginica(x_test.iloc[:,:].values,y_test.iloc[:,:].values,t2_3)\n        V1=avaliar_setosa(x_test.iloc[:,:].values,y_test.iloc[:,:].values,t1_3)\n        L3_1.append(V1)\n        L3_2.append(V2)\n        \n        \n    data['mediaA_taxa0.1']=statistics.mean(L1_1)\n    data['desvioA_taxa0.1']=statistics.stdev(L1_1)\n    data['mediaB_taxa0.1']=statistics.mean(L1_2)\n    data['desvioB_taxa0.1']=statistics.stdev(L1_2)\n    \n    data['mediaA_taxa1']=statistics.mean(L2_1)\n    data['desvioA_taxa1']=statistics.stdev(L2_1)\n    data['mediaB_taxa1']=statistics.mean(L2_2)\n    data['desvioB_taxa1']=statistics.stdev(L2_2)\n    \n    data['mediaA_taxa10']=statistics.mean(L3_1)\n    data['desvioA_taxa10']=statistics.stdev(L3_1)\n    data['mediaB_taxa10']=statistics.mean(L3_2)\n    data['desvioB_taxa10']=statistics.stdev(L3_2)\n    \n    return data\n        \ndata=repetir_treinamento()    ","bfa5baf1":"data","0ba982b5":"(a) Treine um neur\u00f4nio para classificar a classe Iris-setosa como 1 e as demais como zero.\nPare o algor\u00edtimo de treinamento com erro zero no conjunto de treino. Calcule o erro no\nconjunto de teste.","5eca6171":"(c) Inicie os pesos aleatoriamente, cada peso tem um valor rand\u00f4mico uniformemente distri-\nbu\u00eddo entre 0 e 1; utilize os mesmos pesos iniciais todos os casos. Repita o processo das\n\nletras (a) e (b) 30 vezes para os valores de taxa de aprendizagem 0,1; 1,0 e 10,0. Calcule\na m\u00e9dia e o desvio padr\u00e3o das taxas de erro.","5ec1fb86":"(b) Treine um neur\u00f4nio para classificar a classe Iris-virg\u00ednica como 1 e as demais como zero.\nPare o algor\u00edtimo de treinamento ap\u00f3s 100 \u00e9pocas. Calcule o erro no conjunto de teste.","f2ff0109":"1. (30 pontos) Utilizado a base \u201cIris\u201d, https:\/\/archive.ics.uci.edu\/ml\/datasets\/Iris. Os\n25 primeiros exemplos de cada classe ser\u00e3o o conjunto de treino, os outros exemplos s\u00e3o o\nconjunto de teste. Fa\u00e7a sua pr\u00f3pria implementa\u00e7\u00e3o de Neur\u00f4nio Artificial."}}