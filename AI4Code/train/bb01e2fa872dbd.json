{"cell_type":{"20591b3f":"code","b25d27cd":"code","aa77e508":"code","0bc36d14":"code","0d32e6ca":"code","afe942cf":"code","f2b8a1fd":"code","220f3e84":"code","68689d09":"code","b42ca589":"code","d51162a9":"code","0635813f":"code","58a7a5a2":"code","f242edb5":"code","bd906b90":"code","79be91dd":"code","f51dd6ec":"code","1a77ae1f":"code","e1018927":"code","b100ec63":"code","05360a2e":"code","6bbfaa52":"code","113a439f":"code","e5ad103e":"code","f201f05a":"code","3a79cfcb":"code","ba71db9b":"code","7f1e8c48":"markdown","2aa6a6f4":"markdown","13b80e65":"markdown","bffe7a95":"markdown"},"source":{"20591b3f":"import os\nimport gc\nimport random\nimport json\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom pathlib import Path\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\nfrom sklearn.model_selection import train_test_split,KFold\n\nfrom keras.layers import Input, Dense, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, UpSampling1D, UpSampling2D, Lambda, Embedding, Flatten, Add,Concatenate, Dropout, LSTM\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Nadam\nimport keras.backend as K\n\nfrom keras.applications.vgg16 import VGG16","b25d27cd":"data_path = Path('\/kaggle\/input\/abstraction-and-reasoning-challenge\/')\ntraining_path = data_path \/ 'training'\nevaluation_path = data_path \/ 'evaluation'\ntest_path = data_path \/ 'test'\n\ntraining_tasks = sorted(os.listdir(training_path))\nevaluation_tasks = sorted(os.listdir(evaluation_path))\ntest_tasks = sorted(os.listdir(test_path))\nprint(len(training_tasks), len(evaluation_tasks), len(test_tasks))","aa77e508":"def get_data(task_filename):\n    with open(task_filename, 'r') as f:\n        task = json.load(f)\n    return task\n\nnum2color = [\"black\", \"blue\", \"red\", \"green\", \"yellow\", \"gray\", \"magenta\", \"orange\", \"sky\", \"brown\"]\ncolor2num = {c: n for n, c in enumerate(num2color)}","0bc36d14":"for i in range(400):\n    print(get_data(str(test_path \/ test_tasks[i])))\n    break","0d32e6ca":"for i in range(400):\n    print(get_data(str(training_path \/ training_tasks[i]))['test'])\n    break","afe942cf":"x_train = []\ny_train = []\nx_test = []\ny_test = []\n\nox_train = []\noy_train = []\nox_test = []\n\nfor i in range(400):\n    for train_data in get_data(str(training_path \/ training_tasks[i]))['train']:\n        x_train.append(cv2.resize(np.asarray(train_data['input']), dsize=(32, 32), interpolation=cv2.INTER_NEAREST))\n        y_train.append(cv2.resize(np.asarray(train_data['output']), dsize=(32, 32), interpolation=cv2.INTER_NEAREST))\n        ox_train.append(np.asarray(train_data['input']))\n        oy_train.append(np.asarray(train_data['output']))\n        \nfor i in range(100):\n    for test_data in get_data(str(test_path \/ test_tasks[i]))['test']:\n        x_test.append(cv2.resize(np.asarray(test_data['input']), dsize=(32, 32), interpolation=cv2.INTER_NEAREST))\n        ox_test.append(np.asarray(test_data['input']))\n    for train_data in get_data(str(test_path \/ test_tasks[i]))['train']:\n        x_train.append(cv2.resize(np.asarray(train_data['input']), dsize=(32, 32), interpolation=cv2.INTER_NEAREST))\n        y_train.append(cv2.resize(np.asarray(train_data['output']), dsize=(32, 32), interpolation=cv2.INTER_NEAREST))\n        ox_train.append(np.asarray(train_data['input']))\n        oy_train.append(np.asarray(train_data['output']))\n        \nx_train = np.asarray(x_train) \/ 10. \ny_train = np.asarray(y_train) \/ 10.\nx_test = np.asarray(x_test) \/ 10.\n\nprint('length of x_train:', len(x_train))\nprint('length of x_test:', len(x_test))","f2b8a1fd":"#ref: https:\/\/github.com\/yu4u\/cutout-random-erasing\/blob\/master\/cifar10_resnet.py\ndef get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1\/0.3, v_l=0, v_h=255, pixel_level=False):\n    def eraser(input_img):\n        img_h, img_w, img_c = input_img.shape\n        p_1 = np.random.rand()\n\n        if p_1 > p:\n            return input_img\n\n        while True:\n            s = np.random.uniform(s_l, s_h) * img_h * img_w\n            r = np.random.uniform(r_1, r_2)\n            w = int(np.sqrt(s \/ r))\n            h = int(np.sqrt(s * r))\n            left = np.random.randint(0, img_w)\n            top = np.random.randint(0, img_h)\n\n            if left + w <= img_w and top + h <= img_h:\n                break\n\n        if pixel_level:\n            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n        else:\n            c = np.random.uniform(v_l, v_h)\n\n        input_img[top:top + h, left:left + w, :] = c\n\n        return input_img\n\n    return eraser","220f3e84":"datagen = ImageDataGenerator(\n    width_shift_range=0.5,\n    height_shift_range=0.5,\n    #horizontal_flip=True,\n    #vertical_flip=True\n    dtype=float,\n    fill_mode='nearest',\n    preprocessing_function = get_random_eraser(p=0.8, s_l=0.0009765625, s_h=0.0009765625, r_1=0.03124, r_2=0.03124, v_l=0, v_h=9, pixel_level=True),\n)\n\nx_train = x_train.reshape(x_train.shape + (1,) )\ndatagen.fit(x_train)\n\ny_train = y_train.reshape(y_train.shape + (1,))\n\nx_test = x_test.reshape(x_test.shape + (1,))\ndatagen.fit(x_test)","68689d09":"def sampling(args):\n    z_mean, z_log_var = args\n    batch = K.shape(z_mean)[0]\n    dim = K.int_shape(z_mean)[1]\n    # by default, random_normal has mean = 0 and std = 1.0\n    epsilon = K.random_normal(shape=(batch, dim))\n    return z_mean + K.exp(0.5 * z_log_var) * epsilon","b42ca589":"original_dim = 32 * 32\ninput_shape_vae = (original_dim, )","d51162a9":"x_vae_train = np.reshape(x_train, [-1, original_dim])\nx_vae_test = np.reshape(x_test, [-1, original_dim])","0635813f":"x_vae_train.shape","58a7a5a2":"intermediate_dim = 512\nbatch_size = 32\nlatent_dim = 256\nepochs = 100","f242edb5":"#def create_vae_model(batch_size, input_shape):\n\ninputs = Input(shape=input_shape_vae)\nx = Dense(intermediate_dim, activation='relu')(inputs)\nx = Dropout(0.5)(x)\nx = Dense(intermediate_dim, activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(intermediate_dim, activation='relu')(x)\n\n#x = LSTM(512)(x)\n\nz_mean = Dense(latent_dim)(x)\nz_log_var = Dense(latent_dim)(x)\n\nz = Lambda(sampling, output_shape=(latent_dim, ))([z_mean, z_log_var])\n\n# instantiate encoder model\nencoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\nencoder.summary()\n\n# build decoder model\nlatent_inputs = Input(shape=(latent_dim, ), name='z_sampling')\nx = Dense(intermediate_dim, activation='relu')(latent_inputs)\n#x = LSTM(512, return_sequences=True)(x)\nx = Dropout(0.3)(x)\nx = Dense(intermediate_dim, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(intermediate_dim, activation='relu')(x)\noutputs = Dense(original_dim, activation='sigmoid')(x)\n\n# instantiate decoder model\ndecoder = Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()\n\n# instantiate VAE model\noutputs = decoder(encoder(inputs)[2])\nvae = Model(inputs, outputs, name='vae_mlp')","bd906b90":"from keras.losses import mse, binary_crossentropy\n\n#reconstruction_loss = mse(inputs, outputs)\nreconstruction_loss = binary_crossentropy(inputs, outputs)\n\nreconstruction_loss *= original_dim\nkl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\nkl_loss = K.sum(kl_loss, axis=-1)\nkl_loss *= -0.3\nvae_loss = K.mean(reconstruction_loss + kl_loss)\nvae.add_loss(vae_loss)\n\nnadam = Nadam(learning_rate=0.003, beta_1=0.999, beta_2=0.999999)\nvae.compile(optimizer=nadam)\n\nvae.fit(x_vae_train,\n        epochs=epochs,\n        batch_size=batch_size,\n        shuffle=True)","79be91dd":"decoded_train = vae.predict(x_vae_train)\n\ndecoded_train = np.reshape(decoded_train, [-1, 32, 32, 1])","f51dd6ec":"_max = np.amax(decoded_train)\n_min = np.amin(decoded_train)\n\n_range = _max - _min\n_step = _range \/ 10\n\n#decoded_train = (decoded_train - _min) \/ _range\n\ndecoded_train = (decoded_train * 18)\ndecoded_train = decoded_train.astype(int)","1a77ae1f":"rd_train = []\nfor i in range(len(decoded_train)):\n    w = ox_train[i].shape[0]\n    h = ox_train[i].shape[1]\n    if (decoded_train[i].shape[0] != h) | (decoded_train[i].shape[1] != w) :\n        rd_train.append( cv2.resize(decoded_train[i], dsize=(h, w), interpolation=cv2.INTER_NEAREST) )","e1018927":"n = 10\nplt.figure(figsize=(20, 4))\nfor i in range(1,n+1):\n    # \uc785\ub825 \ucd9c\ub825\n    ax = plt.subplot(3, n, i)\n    plt.imshow(ox_train[i])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    # \uc815\ub2f5 \ucd9c\ub825\n    ax = plt.subplot(3, n, i + n)\n    plt.imshow(oy_train[i])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # \uc0dd\uc131 \ucd9c\ub825\n    ax = plt.subplot(3, n, i + 2 * n)\n    plt.imshow(rd_train[i])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","b100ec63":"decoded_test = vae.predict(x_vae_test)\n\ndecoded_test = np.reshape(decoded_test, [-1, 32, 32, 1])\n\n_max = np.amax(decoded_test)\n_min = np.amin(decoded_test)\n\n_range = _max - _min\n_step = _range \/ 10\n\n#decoded_test = (decoded_test - _min) \/ _range\n\ndecoded_test = (decoded_test * 19)\ndecoded_test = decoded_test.astype(int)\n\nprint( np.amax(decoded_test) )\nprint( np.amin(decoded_test) )\n\nrd_test = []\nfor i in range(len(decoded_test)):\n    w = ox_test[i].shape[0]\n    h = ox_test[i].shape[1]\n    if (decoded_test[i].shape[0] != h) | (decoded_test[i].shape[1] != w) :\n        rd_test.append( cv2.resize(decoded_test[i], dsize=(h, w), interpolation=cv2.INTER_NEAREST) )","05360a2e":"n = 10\nplt.figure(figsize=(20, 4))\nfor i in range(1,n+1):\n    # \uc785\ub825 \ucd9c\ub825\n    ax = plt.subplot(2, n, i)\n    plt.imshow(ox_test[i])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    # \uc0dd\uc131 \ucd9c\ub825\n    ax = plt.subplot(2, n, i + n)\n    plt.imshow(rd_test[i])\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","6bbfaa52":"df_submission = pd.read_csv(\"..\/input\/abstraction-and-reasoning-challenge\/sample_submission.csv\")\ndf_submission.head()","113a439f":"df_submission['output'][1]","e5ad103e":"'|' + str(rd_test[0]).replace('[','').replace(']','').replace('\\n','|').replace(' ','') + '|'","f201f05a":"for i, row in df_submission.iterrows():\n    cand_0 = ''\n    cand_1 = ''\n    cand_2 = '|' + str(rd_test[i]).replace('[','').replace(']','').replace('\\n','|').replace(' ','') + '|'\n    answer = ''\n    for j, cand in enumerate(row[1].split(' ')):\n        #print(j)\n        #print('-', cand)\n        #print('=', cand_2)\n        if j == 0: #cand_0\n            cand_0 = cand\n            answer += cand_0\n            #print(answer)\n        elif j == 1: #cand_1\n            nums = []\n            for c in cand_0.replace('|', ''):\n                nums.append(int(c))\n            for k, c in enumerate(cand_0):\n                #print(k, c, cand_0)\n                if c == '|':\n                    cand_1 += '|'\n                elif int(c) == np.amax(nums):\n                    if np.amax(rd_test[i]) == cand_2[k]:\n                        cand_1 += c\n                    else:\n                        cand_1 += cand_2[k]\n                else:\n                    cand_1 += c\n            answer += ' ' + cand_1\n            #print('+2', answer)\n        elif j == 2: #cand_2\n            answer += ' ' + cand_2\n            #print(answer)\n    #print(answer)\n    #print()\n    df_submission.at[i,'output'] = answer","3a79cfcb":"df_submission.head()","ba71db9b":"df_submission.to_csv(\"submission.csv\", index=False)","7f1e8c48":"# Submission","2aa6a6f4":"# To Do\n\n1. fine-tune?\n    - Test file has also train part. I think we should use it with just one epoch or more.\n\n2. Data Augmentation\n    - shift\n\n2. post-process\n    - quantization way\n        - resize first or rescale first\n        - following exist value\n    - how to have the answer for top-3?","13b80e65":"# Prediction","bffe7a95":"# AutoEncoder for Abstraction and Reasoning (Keras)\n\n![](https:\/\/github.com\/seriousran\/img_link\/blob\/master\/kg\/anr\/img_1.PNG?raw=true)\n\nI have tried to solve it with autoencoder with Keras.\nBut it is not that looks useful yet.\n\nPlease give me some advice and vote.\n\n### updates\n- v3?\n    - add cutout augmentation\n- v4\n    - CAE to VAE (and no data augmentation)\n- v5~6\n    - submission error correction\n- v7\n    - Dropout\n- v8\n    - knn"}}