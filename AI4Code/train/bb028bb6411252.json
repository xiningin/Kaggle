{"cell_type":{"5da593d4":"code","16d399a4":"code","09be7b67":"code","759a16ff":"code","e43e0591":"code","7f179562":"code","bc98e615":"code","c86d705a":"code","729d3693":"code","ae9e66d5":"code","75268349":"code","8df95e6c":"code","ee21b7d1":"code","d80cc5f8":"code","9f6d91e0":"code","d951da2a":"code","317f93e8":"code","64d12253":"code","56d18435":"code","6eca5fa5":"code","68cbb35d":"code","0a4b8a15":"code","17986231":"code","4f88af43":"code","0d669987":"code","6aa81620":"code","688ba68f":"code","1d0e001c":"code","f811526c":"code","f113ebea":"code","7c27e9fb":"code","fa2ac85f":"code","69183c25":"code","02f11be4":"code","a4686495":"code","dfcc3373":"code","56f5b5ca":"code","fc4f0b9f":"code","203b9d02":"code","9e46014a":"code","c5495556":"code","10543cc8":"code","67cdc71b":"code","45cdb0f3":"code","fcd96936":"code","3e8c2a1d":"code","8b4d00f7":"code","438cf2f4":"code","b656ec5e":"code","10b2bc99":"markdown","ae0d3e00":"markdown","9dda7e5c":"markdown","fdcf30ca":"markdown","f76191b0":"markdown","84d65000":"markdown","8a1b70df":"markdown","cfab535f":"markdown","a037d7cc":"markdown","7bd7930c":"markdown","6b023598":"markdown","eb1553d2":"markdown"},"source":{"5da593d4":"from fastai import *\nfrom fastai.vision import *","16d399a4":"import numpy as np \nimport pandas as pd \n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom glob import glob\nimport random\nimport cv2\nimport matplotlib.pylab as plt\nimport random as rand\nimport keras\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization, Input\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom keras.optimizers import Adam,RMSprop,SGD","09be7b67":"df = pd.read_csv(\"..\/input\/10-monkey-species\/monkey_labels.txt\")\ndf.head()","759a16ff":"path = Path('..\/input\/10-monkey-species')","e43e0591":"(path\/'').ls()","7f179562":"np.random.seed(42)\ndata = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n        ds_tfms=get_transforms(), size=64, num_workers=0).normalize(imagenet_stats)","bc98e615":"data.classes","c86d705a":"data.show_batch(rows=3, figsize=(10,10))","729d3693":"learn = create_cnn(data, models.resnet34, metrics= accuracy, model_dir=\"\/tmp\/model\/\")   #metrics= error_rate","ae9e66d5":"learn.fit_one_cycle(4) ","75268349":"learn.save('stage-1') #save the model","8df95e6c":"learn.unfreeze()","ee21b7d1":"learn.lr_find() #finding best learning rate","d80cc5f8":"learn.recorder.plot()","9f6d91e0":"lr = 0.01","d951da2a":"learn.fit_one_cycle(5, slice(lr))","317f93e8":"learn.save('stage-2')","64d12253":"learn.unfreeze()","56d18435":"learn.lr_find()\nlearn.recorder.plot()","6eca5fa5":"learn.fit_one_cycle(5, slice(1e-5, lr\/5))","68cbb35d":"learn.fit_one_cycle(5, max_lr=slice(1e-5,1e-4))","0a4b8a15":"learn.save('stage-3')","17986231":"#np.random.seed(42)\n#src = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n#        ds_tfms=get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.), size=64, num_workers=0.1).normalize(imagenet_stats)","4f88af43":"np.random.seed(42)\ndata = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n        ds_tfms=get_transforms(), size=256, num_workers=0).normalize(imagenet_stats)\n\nlearn.data = data\ndata.train_ds[0][0].shape","0d669987":"learn.freeze()","6aa81620":"learn.lr_find()\nlearn.recorder.plot()","688ba68f":"lr=1e-2\/2","1d0e001c":"learn.fit_one_cycle(5, slice(lr))","f811526c":"learn.save('stage-4')","f113ebea":"learn.unfreeze()","7c27e9fb":"learn.fit_one_cycle(5, slice(1e-5, lr\/5))","fa2ac85f":"learn.recorder.plot_losses()","69183c25":"learn.save('stage-5')","02f11be4":"learn.load('stage-3');  #load the model","a4686495":"interp = ClassificationInterpretation.from_learner(learn)","dfcc3373":"interp.plot_confusion_matrix()","56f5b5ca":"#from fastai.widgets import *","fc4f0b9f":"#ds, idxs = DatasetFormatter().from_toplosses(learn, n_imgs=100)","203b9d02":"#ImageCleaner(ds, idxs, path)","9e46014a":"#ds, idxs = DatasetFormatter().from_similars(learn)","c5495556":"#get the image .jpg nummer \nimage_path = \"..\/input\/10-monkey-species\/training\/training\/\"\nimages_dict = {}\n\n\nfor image in os.listdir(image_path):\n    folder_path = os.path.join(image_path, image)\n    images = os.listdir(folder_path)\n    \n    images_dict[image] = [folder_path, image]\n    img_idx = rand.randint(0,len(image)-1)\n    image_img_path = os.path.join(image_path, image, images[img_idx])\n    #printing image\n    img = cv2.imread(image_img_path)\n    print(image_img_path) # to get the path of one image with the .jpg number; uncommen this line\n    #plt.imshow(img);","10543cc8":"import fastai\n#fastai.defaults.device = torch.device('cpu')","67cdc71b":"img = open_image('..\/input\/10-monkey-species\/training\/training\/n4\/n4146.jpg')\nimg","45cdb0f3":"classes = ['n0', 'n1', 'n2', 'n3', 'n4','n5','n6','n7', 'n8','n9']","fcd96936":"data2 = ImageDataBunch.single_from_classes(path, classes, tfms=get_transforms(), size=224).normalize(imagenet_stats)","3e8c2a1d":"learn = create_cnn(data2, models.resnet34, model_dir=\"\/tmp\/model\/\").load('stage-3')","8b4d00f7":"pred_class,pred_idx,outputs = learn.predict(img)\npred_class","438cf2f4":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","b656ec5e":"interp.plot_top_losses(9, figsize=(15,11))","10b2bc99":"# Prediction\n","ae0d3e00":"# Creating your own dataset from 10 monkeys\n\n*by: Francisco Ingham and Jeremy Howard. Inspired by [Adrian Rosebrock](https:\/\/www.pyimagesearch.com\/2017\/12\/04\/how-to-create-a-deep-learning-dataset-using-google-images\/)*","9dda7e5c":"First we need to get the file paths from our top_losses. We can do this with `.from_toplosses`. We then feed the top losses indexes and corresponding dataset to `ImageCleaner`.\n\nNotice that the widget will not delete images directly from disk but it will create a new csv file `cleaned.csv` from where you can create a new ImageDataBunch with the corrected labels to continue training your model.","fdcf30ca":"Flag photos for deletion by clicking 'Delete'. Then click 'Next Batch' to delete flagged photos and keep the rest in that row. ImageCleaner will show you a new row of images until there are no more to show. In this case, the widget will show you images until there are none left from top_losses.ImageCleaner(ds, idxs)\n\nYou can also find duplicates in your dataset and delete them! To do this, you need to run .from_similars to get the potential duplicates' ids and then run ImageCleaner with duplicates=True. The API works in a similar way as with misclassified images: just choose the ones you want to delete and click 'Next Batch' until there are no more images left.","f76191b0":"Remember to recreate your ImageDataBunch from your cleaned.csv to include the changes you made in your data!","84d65000":"Note: Please Set the Number of images to a number that you'd like to view:\nex: ```n_imgs=100```","8a1b70df":"...And fine-tune the whole model:","cfab535f":"## View data","a037d7cc":"# This code is from fastai and are used on the dataset 10 monkeys.","7bd7930c":"Note: A few lines have been commented out since it causes \"Commit Errors\" in kaggle (The steps require manual correction of data which causes the kernel to stop running automatically). \nPlease uncomment the lines as you spot them","6b023598":"## Cleaning Up\n\nSome of our top losses aren't due to bad performance by our model. There are images in our data set that shouldn't be.\n\nUsing the `ImageCleaner` widget from `fastai.widgets` we can prune our top losses, removing photos that don't belong.","eb1553d2":"## Interpretation"}}