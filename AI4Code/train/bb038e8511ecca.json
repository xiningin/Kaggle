{"cell_type":{"a613da70":"code","13c5787e":"code","91de8673":"code","f6d9d683":"code","1c215696":"code","c3eb807a":"code","7ada004c":"code","7d5183fa":"code","a9be952d":"code","879cb166":"code","b0951c89":"code","27cbc330":"code","16155ccd":"code","87d048bd":"code","ef6bff0c":"code","3f7af3a4":"code","ee58939c":"code","47e26732":"markdown","da25004c":"markdown","8fd67711":"markdown","d3e39ce7":"markdown","c0fe663b":"markdown","eb85d4e1":"markdown","b3f6c170":"markdown","747903bd":"markdown","e6a2e816":"markdown","39e84d4e":"markdown","ba08cb40":"markdown","a1f2cbf8":"markdown","13f7e3ae":"markdown","633790bf":"markdown","d5bfe7d9":"markdown","d9860f48":"markdown","35b649ab":"markdown","d321effc":"markdown","73611333":"markdown","aecfbda8":"markdown","7a5a9a59":"markdown"},"source":{"a613da70":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport seaborn as sns\nfrom sklearn.utils import shuffle\n%matplotlib inline","13c5787e":"df = pd.read_csv('..\/input\/league-of-legend-high-elo-ranked-team-comp-s11\/s11.csv')\ndf = shuffle(df)\ndf.head()","91de8673":"# Convert game_length(str) to float(seconds)\nimport re\ndate_str = df.game_length\n\nfor i in range(len(date_str)):\n    if type(date_str[i]) == str:\n        p = re.compile('\\d*')\n        min = float(p.findall(date_str[i][:2])[0])\n        temp = p.findall(date_str[i][-3:])\n        for j in temp:\n            if j != '':\n                sec = float(j)\n                break\n        date_str[i] = (60*min+sec)\n    else: \n        date_str[i] = date_str[i]\n#     print(date_str[i])\n# print(len(date_str))\n\n# remove timestamp since it does not affect the game\ndf = df.drop(['timestamp'], axis=1)","f6d9d683":"df.describe()","1c215696":"# see if there are any null values\nno_nulls = set(df.columns[df.isnull().sum()==0])\nprint(no_nulls)","c3eb807a":"# Categorical Columns\ncat_cols = ['result', 'server', 'team_1__004', 'team_2__003', 'team_1__001', 'team_2__005', 'team_1__003', 'team_2__001','team_1__002', 'team_1__005', 'team_2__004', 'team_2__002']\n\ndef create_dummy_df(df, cat_cols):\n    '''\n    INPUT:\n    df - pandas dataframe with categorical variables you want to dummy\n    cat_cols - list of strings that are associated with names of the categorical columns\n    \n    OUTPUT:\n    df - new dataframe with following characteristics:\n        1. contains all columns that were not specified as categorical\n        2. removes all the original columns in cat_cols\n        3. dummy columns for each of the categorical columns in cat_cols\n        4. Use a prefix of the column name with an underscore (_) for separating\n    '''\n    for col in cat_cols:\n        try:\n            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True)], axis=1)\n        except:\n            continue\n    return df","7ada004c":"df = create_dummy_df(df, cat_cols)","7d5183fa":"# Might as well normalize game_length as well since Linear Regression is sensitive to it\nmax_time = max(df['game_length'])\ndf=pd.concat([df.drop('game_length', axis=1), (df['game_length']\/max_time)], axis=1)","a9be952d":"df.head(10)","879cb166":"# Train test\ny = df['result_Victory']\nX = df.drop(['result_Victory'], axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n\nlm_model = LinearRegression(normalize=True)","b0951c89":"lm_model.fit(X_train, y_train)","27cbc330":"test_pred = lm_model.predict(X_test)\ntrain_pred = lm_model.predict(X_train)\nr2_test = r2_score(y_test, test_pred)\nr2_train = r2_score(y_train, train_pred)\nprint(\"test r2: \"+str(r2_test))\nprint(\"train r2: \"+str(r2_train))","16155ccd":"def coef_weights(coefficients, X_train):\n    '''\n    INPUT:\n    coefficients - the coefficients of the linear model \n    X_train - the training data, so the column names can be used\n    OUTPUT:\n    coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate)\n    \n    Provides a dataframe that can be used to understand the most influential coefficients\n    in a linear model by providing the coefficient estimates along with the name of the \n    variable attached to the coefficient.\n    '''\n    coefs_df = pd.DataFrame()\n    coefs_df['est_int'] = X_train.columns\n    coefs_df['coefs'] = lm_model.coef_\n    coefs_df['abs_coefs'] = np.abs(lm_model.coef_)\n    coefs_df = coefs_df.sort_values('abs_coefs', ascending=False)\n    return coefs_df","87d048bd":"coef_df = coef_weights(lm_model.coef_, X_train)\ncoef_df.head(20)","ef6bff0c":"from sklearn.ensemble import RandomForestClassifier\n\nrnd_clf = RandomForestClassifier(n_estimators=2000, max_leaf_nodes=32, n_jobs=-1)\nrnd_clf.fit(X_train, y_train)","3f7af3a4":"y_test_pred = rnd_clf.predict(X_test)\ntest_acc = np.sum(y_test_pred == y_test)\/len(y_test)\nprint(\"test accuracy: \"+str(test_acc))","ee58939c":"import shap\n\nexplainer = shap.TreeExplainer(rnd_clf)\nshap_values = explainer.shap_values(X_test)\nshap.summary_plot(shap_values[1], X_test)","47e26732":"### Data Cleaning\n1. Change game_length to continuous variable\n2. Clean null values and uninformative columns\n3. Change categorical variables to dummy variables\n","da25004c":"The data is ready for modelling.","8fd67711":"Comparisons\n   - The new update caused each roles to impact more evenly to the game's result\n   - Bottom lane has generally good picks with no worst picks in season 11.\n   - The new update caused more 'high risk high reward' champions to win more and 'generally good' champions to fall\n    ","d3e39ce7":"Recall that 1 = Blue win and 0 = Red win. So positive coefs. here means helpful for the Blue team and negative coefs. means helpful for the Red team. Most of the fields in the top 20 table above, are not something we see often. For example 435-aphelios(top), 689-sion(adc), 248-sona(top) are considered troll. Here are some other findings.\n- Looks like every lane is somewhat equally important as their appearance in the table above are similiar\n- Most of these are troll picks negatively affecting its own team's winrate\n- Picks that are actually helping team's winrate: Sion(ADC), Pantheon(ADC), Yasuo(Sup)??, Ekko(Sup)??\n- This table raises more questions than answers!","c0fe663b":"Interestingly, West Europe tend to win more as Blue team as games are longer. In contrast, Korea tend to win more as Red Team as games gets longer. So there seem to be a trend difference between regions. Furthermore, in general, the shorter the game, blue team wins more for some reason I cannot figure out. ","eb85d4e1":"### Introduction\nRiot Games brings massive changes to their game 'League of Legend' every year. This year, they changed their item system, drastically changing their game ecosystem. It has been few months since the big update and now players have fully adapted to the changes. Let's take a look at what happened to the ecosystem and what is the best team composition now.","b3f6c170":"### Linear Regression","747903bd":"<center> Worst team composition<\/center>","e6a2e816":"# LoL Prediction S11\n> League of Legends s11 Ranked Prediction\n[blog post](https:\/\/jaekangai.medium.com\/season-11-will-make-you-want-to-play-more-aggressively-1bd421220b4d)","39e84d4e":"### Best\/Worst Composition\nBest\n- (Top)Camille,Yone (Jg)Hecarim,Olaf,Twitch (Mid)Akali (Adc)Miss Fortune,Jhin (Sup)Alistar,Janna,Leona <br>\n\nWorst\n- (Top)Pantheon,Irelia (Jg)Wukong (Mid)Sylas,Yone \n\nIf we compare this with the official na.op.gg champion rankings, all the best champions listed here are also listed on their website as either tier one or two as well. (Except Twitch and Pantheon).\n![image.png](attachment:image.png)\nNote that this is just for comparison. Op.gg has million times more data with more regions. Also how they rank these champions are not revealed.","ba08cb40":"- Find out what are the most popular champions now.\n- Find out which team composition is the best.\n- Compare Season 10 and pre-Season 11. How did the item changes impact the game?","a1f2cbf8":"<center> Best team composition<\/center>","13f7e3ae":"Wow we went from 0% to 80% accuracy with random forest!","633790bf":"So there are no null values which is good!","d5bfe7d9":"![image.png](attachment:image.png)","d9860f48":"Clearly, linear regression is a poor model for this problem haha. Makes sense since we only have discrete fields except game_length.","35b649ab":"### The dataset\nThe data we are going to use is a csv file obtained from scraping op.gg which is a website with League of Legend statistics. If you are interested you can visit [here](https:\/\/github.com\/leejaeka\/MyDatas\/tree\/main\/lolgames). The dataset consists of 2901 ranked matches from Korea(WWW), North America(NA), Eastern Europe(EUNE), and Western Europe(EUW) servers. It has which team won the match, the total time of the match, blue team composition and red team composition. Note that only the high elo games were added this includes Challenger, Grand Master, Master and sometimes even High Diamonds. Note that there are 153 total unique champions with 'Rell' as the latest addition. Duplicate games have been removed.","d321effc":"### Random Forests","73611333":"### Most popular champions \n- Camille(Top): 19.68% pick rate\n- Graves(Jg): 37.4% pick rate\n- Akali\/Yone(Mid): 15.89% pick rate combined\n- Jhin\/Kai'sa(Adc): 39.92% pick rate combined\n- Leona(Supp): 25.37% pick rate <br>\n\nNotes:\n- The result is very skewed because there are 2271 Red Team win compared to only 630 Blue Team wins\n- There are in total 2901 games and more than half of it is from Korean server","aecfbda8":"### Comparing with S10","7a5a9a59":"![image.png](attachment:image.png)"}}