{"cell_type":{"5fa5ee73":"code","fc5e8218":"code","1c700efa":"code","8957b913":"code","7b6604ca":"code","577b878a":"code","1690854c":"code","0da07138":"code","bd7708b9":"code","4b327e0f":"code","81df3e9b":"code","bb1671ea":"code","fd1d592c":"code","2f4a025d":"code","220fd0f2":"code","7fda361b":"code","7bb35a24":"markdown","196cac4e":"markdown","a65ced3d":"markdown","a002beba":"markdown","9ed4948a":"markdown","1a143381":"markdown","4eb3cbe6":"markdown"},"source":{"5fa5ee73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc5e8218":"# plotting lib\nimport matplotlib.pyplot as plt\nimport seaborn as sns","1c700efa":"df = pd.read_csv(\"..\/input\/bank-note-authentication-uci-data\/BankNote_Authentication.csv\")","8957b913":"df.head()","7b6604ca":"df.info()","577b878a":"sns.countplot(x=df[\"class\"])","1690854c":"sns.pairplot(df, hue=\"class\")","0da07138":"sns.heatmap(df.corr(), annot=True)","bd7708b9":"columns = list(df.columns)\ncolumns.remove('class')","4b327e0f":"fig, ax = plt.subplots(ncols = 4, figsize=(16, 4))\nfig.suptitle(\"Distribution Plot\")\n\nfor index, column in enumerate(columns):\n    sns.distplot(df[column], ax=ax[index])","81df3e9b":"fig, ax = plt.subplots(ncols=4, figsize=(20, 5))\nfig.suptitle(\"All Features vs Class\")\n\nfor index, column in enumerate(columns):\n    sns.boxplot(x=\"class\", y=column, data=df, ax=ax[index])","bb1671ea":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split","fd1d592c":"X = df.loc[: ,df.columns != \"class\"]\ny = df[\"class\"]","2f4a025d":"rfc = RandomForestClassifier()\nxgbc = XGBClassifier()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=142)","220fd0f2":"rfc.fit(X_train, y_train)\nxgbc.fit(X_train, y_train)","7fda361b":"print(\"RandomTreeClassifier Train Score: \", rfc.score(X_train, y_train))\nprint(\"RandomTreeClassifier Test Score: \", rfc.score(X_test, y_test))\n\nprint(\"==============================================================\")\n\nprint(\"XGBClassifier Train Score: \", xgbc.score(X_train, y_train))\nprint(\"XGBClassifier Test Score: \", xgbc.score(X_test, y_test))","7bb35a24":"## \u2714 As we can see we dont have any **Missing Values** \ud83d\udc4d","196cac4e":"## \u2b55 From Above Diagram we can see their is a **multicolliniraty** between **curtosis** and **skewness** but can be ignored","a65ced3d":"# \ud83e\uddd0 Exploratory Data Analysis","a002beba":"# If you find this \ud83d\udcd5Notebook \ud83e\udde9interesting consider **\u26a1 \u2b06Up Voteing this NoteBook** ","9ed4948a":"# \u2699 Data PreProcessing","1a143381":"# Conclution From Above Diagram\n1. Their may be outliers in **entropy** and **curtosis** column\n2. Data is not normalized\n\nsince we gonna use trees in our model above things dont effect model much","4eb3cbe6":"# \ud83d\udd25 Model Creation"}}