{"cell_type":{"5fed7943":"code","1fbdc2fc":"code","e2c94845":"code","7ab58032":"code","2facd17e":"code","ed3ffdc4":"code","7e2d561e":"code","f2056c5b":"code","37a067fc":"code","6fa436b4":"code","743f08fa":"code","53a83fd6":"code","2ca0f7fb":"code","e37c2cc9":"code","898a9677":"code","1e3eead1":"code","e9ebab30":"code","2d018866":"code","fa13f32d":"markdown","83d6a94b":"markdown","2542686d":"markdown","81c39052":"markdown","c7935e8c":"markdown","f0a8be13":"markdown","af456012":"markdown","c18826f6":"markdown","45f92abe":"markdown","567b98fa":"markdown","86cf233d":"markdown","c9b7705b":"markdown","0d9339de":"markdown","b3523970":"markdown","2951e167":"markdown","4e18b2c3":"markdown","b38696ac":"markdown","5088fd48":"markdown","a81a14b3":"markdown","1b33de8c":"markdown","46ac57ca":"markdown","0e5c036e":"markdown","a49957b4":"markdown","5326cb3f":"markdown","61950b34":"markdown","43a1ff82":"markdown"},"source":{"5fed7943":"%matplotlib inline\n\nimport os, shutil # directory operations\nimport numpy as np # linear algebra \nimport pandas as pd # I\/O of data\nfrom zipfile import ZipFile # woking with zip archives\n\n# packages for visualization\nimport ipywidgets as iw\nfrom IPython.display import display, clear_output\nimport matplotlib.pyplot as plt\nfrom skimage.transform import resize as imresize","1fbdc2fc":"zp_filenames = ['Testing.zip','Training.zip','Validation.zip']","e2c94845":"# using list comprehension to build a list for zipped file with their path names.\nzp_filenamesWithpath = [os.path.join('..\/input\/kaggle-for-deep-learning-p-1-getting-data-ready',k) for k in zp_filenames] ","7ab58032":"for k in zp_filenamesWithpath: # looping over the files that need to be unzipped\n    \n    # extracting the zipfiles to the current directory\n    with ZipFile(k,'r') as zp: \n        zp.extractall()","2facd17e":"f_names = [k for k in os.listdir('working\/Training')] # list of fruit names\n\ndp = iw.Dropdown(options = f_names, \n                 description = 'Select fruit') # creating a dropdown widgets for fruit names\n\npath4 = '..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Training' # path to training images\n\n# displaying the dropdown widget\ndisplay(dp)\nout = iw.Output()\ndisplay(out)\n\n# defining a function which is activated when the drop down value is changed\ndef on_index_change(change):\n    \n    out.clear_output() # first let's clear the output if there is any\n    \n    f_dir = f_names[change.new] # assigning the new fruit name to f_dir\n    \n    num_imgs = len(os.listdir(os.path.join(path4, f_dir))) - 1 # calculating the number of images in the new fruit directory \n    path2image = os.path.join(path4, f_dir) # getting the path to the new fruit directory\n    \n    # defining a function which will be used for the slider widget. This function shows an image based on scroll value.\n    def showfruit(vchange):\n        \n        fig = plt.figure(figsize = (5, 5)) # initializing the figure\n        \n        im2show = os.listdir(path2image)[vchange] # storing the name of image to be shown\n        path5 = os.path.join(path2image,im2show) # storing the complete path to the image to be shown\n        \n        img = plt.imread(path5) # reading the image to be shown\n        \n        plt.imshow(img) # displaying the image\n        plt.axis('off') # turning the axis off\n    \n    # making a slider widget which uses the function showfruit to plot fruit images\n    with out:\n        k = iw.interactive(showfruit, vchange =  iw.IntSlider(description = 'Scroll images',\n                                                              min = 0,\n                                                              max = num_imgs,\n                                                              readout = False))\n        \n        # displaying the slider widget\n        display(k)\n\n# observing if there is a change to the dropdown widget index\ndp.observe(on_index_change, names='index')","ed3ffdc4":"# initializing an array to store resized images\nimgs = np.empty([75,32,32,3])\n\n# looping over folders in the training directory\nfor i, folder in enumerate(os.listdir(path4)):\n    \n    # selecting first image in the folder\n    first_image = (os.listdir(os.path.join(path4,folder)))[0]\n    \n    # reading the image\n    img = plt.imread(os.path.join(path4,folder + '\/' + first_image))\n    \n    # resizing the image\n    imgs[i,:,:,:] = imresize(img, (32, 32, 3), mode = 'constant')\n\n# creating 75 subplots with 13 rows and 5 columns\nfigure, ax = plt.subplots(13,5,figsize = (20, 20))\n\n# initializing count variable i\n\ni = 0\n\n# looping over subplot rows\nfor k in range(13):\n    \n    # looping over subplot columns\n    for j in range(5):\n        # plotting image\n        ax[k,j].imshow(imgs[i])\n        \n        #turning axis off\n        ax[k,j].axis('off')\n        \n        # updating count variable\n        i += 1","7e2d561e":"path1 = 'working\/Training' # path to the training folder where folders with fruit names are stored\npath2 = 'working\/Validation' # path to the validation folder where folders with fruit names are stored\npath3 = 'working\/Test' # path to the test folder where folders with fruit names are stored\nf_names = [k for k in os.listdir(path1)] # list of fruit names","f2056c5b":"# initializing empty dictionaries to contain number of fruits\ncount_train = {}\ncount_test = {}\ncount_validation = {}\ncount_total = {}\n\n# looping over the list of fruit names\nfor k in f_names:\n    \n    # storing the number of images in each class to different folders\n    count_train[k] = len(os.listdir(os.path.join(path1,k)))\n    count_test[k] = len(os.listdir(os.path.join('working\/Test',k)))\n    count_validation[k] = len(os.listdir(os.path.join('working\/Validation',k)))\n\n# Assigning the number of fruits in different sets to one dictionary\ncount_total['Test'] = count_test\ncount_total['Training'] = count_train\ncount_total['Validation'] = count_validation\n\n# Storing the dictionary to a data frame, df\ndf = pd.DataFrame.from_dict(count_total)","37a067fc":"df.head()","6fa436b4":"# Calculating the number of images in each set and the number of classes. Storing these values in a dictionary\ncnn_params = {}\ncnn_params['No training images'] = np.sum(df.Training)\ncnn_params['No validation images'] = np.sum(df.Validation)\ncnn_params['No test images'] = np.sum(df.Test)\ncnn_params['No classes'] = len(df.Test)\n\n# Printing the number of images in each set and the number of classes.\nprint('Number of training images = {} \\n'.format(cnn_params['No training images']))\nprint('Number of validation images = {} \\n'.format(cnn_params['No validation images']))\nprint('Number of test images = {} \\n'.format(cnn_params['No test images']))\nprint('Number of classes = {} \\n'.format(cnn_params['No classes']))","743f08fa":"# batch sizes to search from\npotential_batch_sizes = [k for k in range(8,129)]\n\n# dividing the total number of images by potential_batch_sizes are calculating the remainder\nremaining_images_training = list(zip(potential_batch_sizes, cnn_params['No training images']%potential_batch_sizes))\nremaining_images_validation = list(zip(potential_batch_sizes, cnn_params['No validation images']%potential_batch_sizes))\n\n# printing the potential_batch_sizes with their respective remainders\nprint('Batch size and corresponding remaining training images :\\n {}'.\n      format(remaining_images_training)) \nprint('Batch size and corresponding remaining validation images :\\n {}'.\n      format(remaining_images_validation)) ","53a83fd6":"cnn_params['Training batch size'] = 18\ncnn_params['Validation batch size'] = 17","2ca0f7fb":"cnn_params['Training steps\/epoch'] = int(cnn_params['No training images'] \/ cnn_params['Training batch size'])\ncnn_params['Validation steps\/epoch'] = int(cnn_params['No validation images'] \/ cnn_params['Validation batch size'])","e37c2cc9":"# Storing the dictionary to a data frame, cnn_params\ndf_cnn_params = pd.DataFrame.from_dict(cnn_params, orient='index')\ndf_cnn_params.to_csv('CNNParameters.csv')","898a9677":"# making the bar plot\ndf['Training'].plot(kind='bar', figsize=(20, 10), legend=False)\n\n# labeling the axis and setting a title\nplt.ylabel('Number of images')\nplt.title('Training set')\nplt.tight_layout()","1e3eead1":"# making the bar plot\ndf['Validation'].plot(kind='bar', figsize=(20, 10), legend=False)\n\n# labeling the axis and setting a title\nplt.ylabel('Number of images')\nplt.title('Validation set')\nplt.tight_layout()","e9ebab30":"# making the bar plot\ndf['Test'].plot(kind='bar', figsize=(20, 10), legend=False)\n\n# labeling the axis and setting a title\nplt.ylabel('Number of images')\nplt.title('Test set')\nplt.tight_layout()","2d018866":"# Removing extracted images folders\nshutil.rmtree('working')","fa13f32d":"Next, we plot the number of fruits in each class for the test set.","83d6a94b":"Finally,  we remove the extracted images from the working directory.","2542686d":"First, we plot the number of fruits in each class for the training set.","81c39052":"The figure shows that in the training set there are approximately 40 images for each class. Similar to the training and validation set there are a few exceptions.","c7935e8c":"Steps per epoch should be equal to 'total number of images in a set \/ batch size for that set'. Lets calculate steps per epoch and store them to cnn_params.","f0a8be13":"Before moving on, let's explore the head of the dataframe first. ","af456012":"Based on the results printed above, we can use the number of batches for training and validation sets = 18 and 17 respectively. Let's store the batch number to the dictionary cnn_params.","c18826f6":"# Using convolution neural network to classify fruits\nThis is **Part 2** of the fruit classification project. In [**Part 1**](https:\/\/www.kaggle.com\/rehanali88\/kaggle-for-deep-learning-p-1-getting-data-ready) we split the data into training, validation and test sets. We saved these folders in zip format. In this part we will use the split data to calculate certain parameters that will be used in building the convolution neural network. We will also visually analyze the number of images in different classes and build an interactive plot to explore fruit images in the test data. ","45f92abe":"The dataframe shows that if we sum columns we will get the total number of images in each set. Also, if we calculate the number of rows of the data frame, it should be equal to the number of classes. Let's calculate the total number of images in each set and number of classes, and store the values in a dictionary.","567b98fa":"## Summary\nIn this part of the project we completed a few important steps:\n* We have calculated the parameters values that will be used in the next part, where we will build the convolution neural network.\n* We have performed some informative visualizations:\n    \n * We plotted the number of images in each class for each set.\n * We also created an interactive visual that let's us explore fruit images in each class. \n      \nIn the next part we will use the split sets (from part 1)and parameters values that we calculated and stored in this part to build the convolution neural network. Also, we will use the same code to extract zipped files that we used in this part.","86cf233d":"Now, we will use the list of fruit names as keys for a dictionary in which we will store the number of images in each class for each set.","c9b7705b":"As shown in the above interactive widget, we can explore any image in any class. This helps us to get a sense of the input data.\n\n**THE WIDGET USES DATASET FROM KAGGLE, THEREFORE ONLY WORKS IN A KAGGLE KERNEL. **Because of this the code below shows one image of each fruit.","0d9339de":"## Extracting zipped files\nWe need to extract the images from test, training and validation sets.","b3523970":"The figure shows that in the training set there are approximately 500 images for each class with a few exceptions. ","2951e167":"We make a list with names of zip folders.","4e18b2c3":" Now we will divide the images in training and validation set to a certain number of batches. The number of batches we will search for are values between 8 and 64. For every set we need to find the batch size such that images can be evenly divided into different batches.","b38696ac":"Now, we extract the files in zipped folders to this directory.","5088fd48":"## Visualizing fruits\nWe will use matplotlib.pyplot along with ipywidgets and display packages to make an interactive plot to visualize different fruits in the test set. ","a81a14b3":"## Importing required packages\nFirstly, lets import the packages that we will be using. The particular use of every package is shown in the comments.","1b33de8c":"Using this list, we make a list of zip folders names including their path.","46ac57ca":"Next, we plot the number of fruits in each class for the validation set.","0e5c036e":"## Exploratory analysis of the data\nIn the last step of this part of the project, we will perform some visual exploratory analysis. We will make bar plots of the number of fruits in each class for each set. ","a49957b4":"## Calculating parameters to use in building the convolution neural network\nWhen we build the convolution neural network and fit it, batches of images will go as input to the network. We need to calculate the number of images in a batch for different sets. Along with the number of images in a batch, we also need to calculate 'steps per epoch'. This number should be 'total number of images in a set \/ number of images in a batch'. Lastly, the output of the last layer needs to be calculated. This should equal the number of classes. In summary, we need to calculate the following:\n* Number of images in a batch for training and validation set,\n* Numer of steps per epoch for training and validation set,\n* Number of classes to be used as the output of the last layer.","5326cb3f":"The figure shows that in the validation set there are approximately 125 images for each class. Similar to the training set there are a few exceptions.","61950b34":"To calculate the different parameters, lets first find the names of different fruits.","43a1ff82":"Finaly, we will convert the dictionary cnn_params to a dataframe and save it as '.csv' file. We will use this data in the next part of this project when we build the convolution neural network."}}