{"cell_type":{"bf87ae8d":"code","f51705e7":"code","87b2af41":"code","8b347280":"code","062eedb0":"code","edaee695":"code","9b663a8a":"code","bbbee646":"code","761107ba":"code","84d7fa38":"code","4195ec3c":"code","e844fd35":"code","04f05f5c":"code","d42ffab1":"code","8a8427e1":"code","08f30782":"code","802c7731":"code","17479fb1":"code","b8e765f0":"markdown"},"source":{"bf87ae8d":"import os\nimport warnings\nimport pathlib\nimport gc\nfrom pprint import pprint\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold, GroupKFold\nfrom sklearn.metrics import roc_auc_score, mean_squared_error, mean_absolute_error\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nimport lightgbm as lgb\n\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 500)\nsns.set(font=\"IPAexGothic\", style=\"darkgrid\")\nwarnings.simplefilter('ignore')","f51705e7":"def split(data:pd.DataFrame, method:str=\"random\", **params):\n    \"\"\"\n    Wrapper of train_test_split\n    \n    Parameters\n    -----\n    data : pd.DataFrame\n        input data\n    method : str (default random)\n        splitting method\n    params : \n        parameters of train_test_split function\n        \n    Returns\n    -----\n    train_set, test_set:pd.DataFrame\n        split_data\n        \n    Note\n    -----\n    * Abount method\n        * random : random split\n        * breath : split by breath_id\n    \"\"\"\n    def random_split(data, **params):\n        return train_test_split(data, **params)\n    \n    def breath_split(data, **params):\n        train_id, test_id = train_test_split(data[\"breath_id\"].unique(), **params)\n        return data[data[\"breath_id\"].isin(train_id)], data[data[\"breath_id\"].isin(test_id)]\n    \n    if method == \"random\":\n        return random_split(data, **params)\n    elif method == \"breath\":\n        return breath_split(data, **params)\n    else:\n        raise ValueError(f\"Invalid value {method}. method must be random or breath.\")\n        \ndef get_feats(data:pd.DataFrame):\n    print(\"target : \", target)\n    print(\"Excluded features : \", excluded_feats)\n    return [col for col in data.columns if col not in [target] + excluded_feats]","87b2af41":"def gKFold(df, **params):\n    df = df.copy().reset_index(drop=True)\n    g_kfold = GroupKFold(**params)\n    \n    df[\"folds\"] = -1\n    for fold, (train_idx, test_idx) in enumerate(g_kfold.split(df, groups=df[\"breath_id\"])):\n        df[\"folds\"][test_idx] = fold\n    \n    return df\n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose:\n        print(\"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n","8b347280":"SEED = 43\n\n#If true, We use 10% data of train set.\nDEBUG = False\n","062eedb0":"date=20211022\ntrain_iter = pd.read_csv(f\"..\/input\/google-brain-create-features\/train_with_feats_{date}.csv\", chunksize=1000000)\ntrain = pd.concat([reduce_mem_usage(tr) for tr in tqdm(train_iter)], axis=0)\n\nsubmission_iter = pd.read_csv(f\"..\/input\/google-brain-create-features\/test_with_feats_{date}.csv\", chunksize=1000000)\nsubmission = pd.concat([reduce_mem_usage(sub) for sub in tqdm(submission_iter)], axis=0)\n\nprint(train.shape)\nprint(submission.shape)","edaee695":"train[\"pressure_ratio\"] = (train[\"pressure\"] \/ train.groupby(\"breath_id\")[\"pressure\"].shift(1)).fillna(1)","9b663a8a":"display(train.head())\n#display(train.describe())\n\n#If DEBUG is True, 10% train_valid is used.\nif DEBUG:\n    breath_id_list = np.unique(train[\"breath_id\"])\n    breath_id_list = np.random.choice(breath_id_list, int(len(breath_id_list)*0.1), replace=False)\n    train = train[train[\"breath_id\"].isin(breath_id_list)]\nelse:\n    pass\n\n#20 % breath_ids are used for test.\ntrain_valid, test = split(train, method=\"breath\", test_size=0.20, random_state=SEED)\n\ndel train\ngc.collect()\n\nprint(train_valid.shape)\nprint(test.shape)","bbbee646":"n_splits = 3\ntrain_valid = gKFold(train_valid, n_splits=n_splits)\n\ntarget = \"pressure_ratio\"\nexcluded_feats = [\n    \"id\"\n    , \"breath_id\"\n    , \"folds\"\n    , \"predicts\"\n    , \"pressure\"\n    , \"pressure_ratio\"\n    , \"time_step\"\n    , \"time_step_lag1\"\n    , \"time_step_lag2\"\n] + [col for col in train_valid.columns if \"all\" in col]\n\nfeats = [col for col in train_valid.columns if col not in excluded_feats]\npprint(feats)","761107ba":"def train_fn(train_valid, test, submission, n_folds, num_boost_round, learning_rate):\n\n    model_list = []\n    \n    train_valid_preds = np.zeros([len(train_valid)])\n\n    for fold in range(n_folds):\n        tr = train_valid.query(f\"folds != {fold}\")\n        va = train_valid.query(f\"folds == {fold}\")\n\n        lgb_tr = lgb.Dataset(tr.query(\"u_out == 0\")[feats], label=tr.query(\"u_out == 0\")[target])\n        #lgb_va = lgb.Dataset(va[feats], label=va[target])\n        lgb_va = lgb.Dataset(va.query(\"u_out == 0\")[feats], label=va.query(\"u_out == 0\")[target])\n\n        LGB_PARAMS = {\n            \"boosting_type\":\"gbdt\"\n            , \"objective\":\"huber\"\n            , \"metric\":\"mae\"\n            , \"max_depth\":12\n            , \"colsample_bytree\":0.8\n            , \"min_data_in_leaf\":4000\n            , \"lambda_l1\":0 #reg_alpha(L1)\n            , \"lambda_l2\":10 #reg_lambda(L2)\n            , \"learning_rate\":learning_rate\n            , \"verbosity\":-1\n        }\n\n        metrics = {}\n\n        lgb_reg = lgb.train(\n            LGB_PARAMS\n            , lgb_tr\n            , num_boost_round=num_boost_round\n            , valid_sets=(lgb_tr, lgb_va)\n            , valid_names=(\"train\", \"valid\")\n            , early_stopping_rounds=int(50)\n            , verbose_eval=100\n            , evals_result=metrics\n        )\n\n        #lgb.plot_metric(metrics)\n\n        #fig, ax = plt.subplots(figsize=(12, 8))\n        #lgb.plot_importance(lgb_reg, ax=ax)\n        #fig.tight_layout()\n        #plt.show()\n        #plt.close()\n\n        #\u4e88\u6e2c\n        print(f\"Training of Fold {fold} is finished.\")\n        print(\"Predict Valid data\")\n        pred_va = lgb_reg.predict(va[feats])\n        train_valid_preds[train_valid[\"folds\"] == fold] = pred_va\n\n        print(\"Predict test data\")\n        pred_test = lgb_reg.predict(test[feats])\n        test[\"predicts\"] += pred_test \/ n_folds\n        \n        #\u63d0\u51fa\u7528\n        print(\"Predict submission data\")\n        pred_sub = lgb_reg.predict(submission[feats])\n        submission[\"predicts\"] += pred_sub \/ n_folds\n\n        model_list.append(lgb_reg)\n    \n    train_valid[\"predicts\"] = train_valid_preds\n    return model_list, train_valid, test, submission","84d7fa38":"def eval_mae(df):\n    mask = df[\"u_out\"] == 0\n    eval_df = df[mask][[\"pressure\", \"predicts\"]]\n    return mean_absolute_error(eval_df[\"pressure\"], eval_df[\"predicts\"])","4195ec3c":"\nresults = {\"train_valid\":[], \"test\":[]}\n#parameters\nlearning_rate = 0.5\nnum_boost_round = 5000\n\n\n\n#=====\u5b66\u7fd2\ntrain_valid[\"predicts\"] = 0 \ntest[\"predicts\"] = 0 \nsubmission[\"predicts\"] = 0\n\nmodel_list, train_valid, test, submission = train_fn(train_valid, test, submission, n_splits, num_boost_round, learning_rate)\n\n#results[\"train_valid\"].append(eval_mae(train_valid))\n#results[\"test\"].append(eval_mae(test))\n#print(\"train_valid\", results[\"train_valid\"][-1])\n#print(\"test\", results[\"test\"][-1])\n\n","e844fd35":"for lgb_reg in model_list:\n    fig, ax = plt.subplots(figsize=(12, 16))\n    lgb.plot_importance(lgb_reg, ax=ax)\n    fig.tight_layout()\n    plt.show()\n    plt.close()\n","04f05f5c":"train_valid = train_valid.rename({\"predicts\":\"predicts_ratio\"}, axis=1)\ntest = test.rename({\"predicts\":\"predicts_ratio\"}, axis=1)\nsubmission = submission.rename({\"predicts\":\"predicts_ratio\"}, axis=1)","d42ffab1":"n_splits = 3\ntrain_valid = gKFold(train_valid, n_splits=n_splits)\n\ntarget = \"pressure\"\nexcluded_feats = [\n    \"id\"\n    , \"breath_id\"\n    , \"folds\"\n    , \"predicts\"\n    , \"pressure\"\n    , \"pressure_ratio\"\n    , \"time_step\"\n    , \"time_step_lag1\"\n    , \"time_step_lag2\"\n] + [col for col in train_valid.columns if \"all\" in col]\n\nfeats = [col for col in train_valid.columns if col not in excluded_feats]\npprint(feats)","8a8427e1":"results = {\"train_valid\":[], \"test\":[]}\n#parameters\nlearning_rate = 0.1\nnum_boost_round = 5000\n\n\n#=====\u5b66\u7fd2\ntrain_valid[\"predicts\"] = 0 \ntest[\"predicts\"] = 0 \nsubmission[\"predicts\"] = 0\n\nmodel_list, train_valid, test, submission = train_fn(train_valid, test, submission, n_splits, num_boost_round, learning_rate)\n\nresults[\"train_valid\"].append(eval_mae(train_valid))\nresults[\"test\"].append(eval_mae(test))\nprint(\"train_valid\", results[\"train_valid\"][-1])\nprint(\"test\", results[\"test\"][-1])\n\n","08f30782":"pd.concat([\n    train_valid[[\"id\", \"breath_id\", \"predicts_ratio\", \"predicts\"]]\n    , test[[\"id\", \"breath_id\", \"predicts_ratio\", \"predicts\"]]\n]).to_csv(\".\/lgbm_predicts_train.csv\", index=False)\n\nsubmission.to_csv(\".\/lgbm_predicts_test.csv\", index=False)","802c7731":"del train_valid, test\ngc.collect()","17479fb1":"sample_submission = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/sample_submission.csv\").drop(\"pressure\", axis=1)\n\nsample_submission = sample_submission.merge(submission[[\"id\", \"predicts\"]], on=\"id\")\n\nsample_submission.columns = [\"id\", \"pressure\"]\n\nsample_submission.to_csv(\"submission.csv\", index=False)","b8e765f0":"### \u5b66\u7fd2"}}