{"cell_type":{"3f5db059":"code","01c1336d":"code","01a6c6cd":"code","941d4c10":"code","43624ac9":"code","d4abcff9":"code","00935015":"code","2b862e5f":"code","baba443f":"code","a0a58d5a":"code","496d63e0":"code","58e5a7a5":"code","29c0964f":"code","f4c6cc19":"code","4628ac25":"code","08517756":"code","b3194582":"code","88cb41c4":"code","c0dfb89f":"code","51c1b43a":"code","615ff03b":"code","ad827682":"code","70640322":"code","9a2b9872":"code","65b27257":"code","ffa45e2d":"code","52b7958c":"markdown","01d8e12d":"markdown","4691d294":"markdown","07f3d4c1":"markdown","7928c629":"markdown","ad05e632":"markdown","7e4ac098":"markdown","358793fb":"markdown","60f3deb6":"markdown","93c25087":"markdown","0cfe6cd9":"markdown","cbf4495b":"markdown","390459ef":"markdown","c6b05350":"markdown","65e268f5":"markdown","139ab64a":"markdown","e64b3361":"markdown","bbef5e96":"markdown","343b5a7f":"markdown","d84858ff":"markdown","6bd224d6":"markdown","69848e38":"markdown"},"source":{"3f5db059":"!wget -O train.parquet https:\/\/www.dropbox.com\/s\/j3jupvnmi4xelwz\/train.parquet?dl=1","01c1336d":"!wget -O test.parquet https:\/\/www.dropbox.com\/s\/95jwpl5bs7o8i7g\/test.parquet?dl=1","01a6c6cd":"!ls \/content","941d4c10":"import pandas as pd\nimport seaborn as sns\n\nwork_dir = \"\/content\"\n\n#leitura dos dados de entrada\ndf_train_bruto = pd.read_parquet(work_dir +\"\/train.parquet\", engine=\"pyarrow\")\ndf_test_bruto = pd.read_parquet(work_dir +\"\/test.parquet\", engine=\"pyarrow\")\n\nprint(df_train_bruto.shape)\nprint(df_test_bruto.shape)","43624ac9":"df_train_bruto.info()","d4abcff9":"df_test_bruto.info()","00935015":"df_train_bruto.head(1).T","2b862e5f":"# iremos remover as features NR_IDADE_DATA_POSSE e TOTAL_BENS, \n# mas fica como exerc\u00edcio voc\u00ea aproveit\u00e1-las no conjunto de features\ndf_train_preparado = df_train_bruto.drop(['ID_CANDIDATO', 'NR_IDADE_DATA_POSSE', 'TOTAL_BENS'], axis=1)\ndf_test_preparado = df_test_bruto.drop(['ID_CANDIDATO', 'NR_IDADE_DATA_POSSE', 'TOTAL_BENS'], axis=1)","baba443f":"# Substitui valores nulos por 0 nas colunas num\u00e9ricas\ncolunas_numericas = ['ANO_ELEICAO','CD_TIPO_ELEICAO','NR_TURNO','CD_ELEICAO','CD_CARGO','CD_SITUACAO_CANDIDATURA','CD_DETALHE_SITUACAO_CAND','NR_PARTIDO','CD_NACIONALIDADE','CD_GENERO','CD_GRAU_INSTRUCAO','CD_ESTADO_CIVIL','CD_COR_RACA','CD_OCUPACAO']\n\ndf_train_preparado[colunas_numericas] = df_train_preparado[colunas_numericas].fillna(value=0)\ndf_test_preparado[colunas_numericas] = df_test_preparado[colunas_numericas].fillna(value=0)","a0a58d5a":"# remo\u00e7\u00e3o das \ndf_train_preparado = df_train_preparado.drop(['DS_COMPOSICAO_COLIGACAO', 'NM_MUNICIPIO_NASCIMENTO'], axis=1)\ndf_test_preparado = df_test_preparado.drop(['DS_COMPOSICAO_COLIGACAO', 'NM_MUNICIPIO_NASCIMENTO'], axis=1)","496d63e0":"# transformar colunas categ\u00f3ricas em num\u00e9ricas\ncolunas_categoricas = ['SG_UF','TP_AGREMIACAO','SG_UF_NASCIMENTO','ST_REELEICAO','ST_DECLARAR_BENS']\ndf_train_preparado = pd.get_dummies(df_train_preparado, columns=colunas_categoricas)\ndf_test_preparado = pd.get_dummies(df_test_preparado, columns=colunas_categoricas)\ndf_train_preparado.head()","58e5a7a5":"print(df_test_preparado.shape)\nprint(df_train_preparado.shape)","29c0964f":"df_train_preparado['ELEITO'] = df_train_preparado['ELEITO'].astype(bool)","f4c6cc19":"!pip install h2o","4628ac25":"import h2o\nfrom h2o.automl import H2OAutoML\n\nh2o.init(max_mem_size=8)","08517756":"train_df = h2o.H2OFrame(df_train_preparado)\n\ntrain, valid = train_df.split_frame(ratios = [.8], seed = 1234)\n\nx = train.columns\ny = \"ELEITO\"\nx.remove(y)","b3194582":"#aml = H2OAutoML(max_models=2, seed=10, include_algos = [\"XGBoost\"], nfolds=0, sort_metric=\"AUC\")\n#aml.train(x=x, y=y, training_frame=train, validation_frame=valid)\n\n#aml = H2OAutoML(max_models=5, seed=1, include_algos = [\"XGBoost\"])\n#aml.train(x=x, y=y, training_frame=train_df)\n\naml = H2OAutoML(max_models=5, seed=1)\naml.train(x=x, y=y, training_frame=train_df)","88cb41c4":"lb = aml.leaderboard\nlb.head(rows=lb.nrows)","c0dfb89f":"model = aml.leader\nmodel","51c1b43a":"model.varimp(use_pandas=True)","615ff03b":"#model.varimp_plot()","ad827682":"test = h2o.H2OFrame(df_test_preparado)\npreds = aml.predict(test)\n\n#predict\n#y_test =  preds.as_data_frame()['predict'].astype(int)\n\n#predict_proba\ny_test =  preds.as_data_frame()['True']","70640322":"preds","9a2b9872":"output = df_test_bruto.assign(ELEITO=y_test)\noutput = output.loc[:, ['ID_CANDIDATO','ELEITO']]\noutput.head()","65b27257":"output.to_csv(work_dir +\"\/ouput_h2o.csv\", index=False)","ffa45e2d":"from google.colab import files\nfiles.download('ouput_h2o.csv') ","52b7958c":"## Predi\u00e7\u00e3o sobre os dados de testes\n\nNesta \u00faltima etapa, o modelo busca predizer se o candidato foi eleito ou n\u00e3o sobre os dados de teste. Os dados de teste est\u00e3o armazenados no DataFrame *df_test_preparado*. O modelo faz a predi\u00e7\u00e3o e tem como sa\u00edda os valores da predi\u00e7\u00e3o em *y_test*.","01d8e12d":"## Considera\u00e7\u00f5es Finais\n\nAgora \u00e9 com **voc\u00ea**! Ainda existe muito espa\u00e7o para melhoria na acur\u00e1cia do modelo que desenvolvemos at\u00e9 agora. Utilize o material complementar abaixo para modificar este notebook e construir um algoritmo melhor.\n\n- [Documenta\u00e7\u00e3o do H2O](http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/automl.html)\n- [Curso de Aprendizado de M\u00e1quina de Stanford com Andrew Ng](https:\/\/www.coursera.org\/learn\/machine-learning)\n- [M\u00e3os \u00e0 Obra: Aprendizado de M\u00e1quina com Scikit-Learn & TensorFlow](https:\/\/www.amazon.com.br\/M%C3%A3os-Obra-Aprendizado-Scikit-Learn-TensorFlow\/dp\/8550803812)\n- [Introduction to Machine Learning with Python](https:\/\/www.amazon.com.br\/Introduction-Machine-Learning-Andreas-Mueller\/dp\/1449369413)\n- [Data Science do Zero](https:\/\/www.amazon.com.br\/Data-Science-zero-Joel-Grus\/dp\/857608998X)\n- [Customer Churn Classification Using Predictive Machine Learning Models](https:\/\/towardsdatascience.com\/customer-churn-classification-using-predictive-machine-learning-models-ab7ba165bf56)","4691d294":"## Engenharia de Features\n\nEngenharia de Features \u00e9 o processo de usar o conhecimento de dom\u00ednio sobre os dados para criar *features* que fazem os algoritmos de aprendizado de m\u00e1quina funcionar da forma que esperamos. Iremos aplicar [Engenharia de Features](https:\/\/www.kaggle.com\/sudalairajkumar\/feature-engineering-validation-strategy) nos Dataframes de treinamento e teste. ","07f3d4c1":"As vari\u00e1veis *NR_IDADE_DATA_POSSE* e *TOTAL_BENS* foram removidas. Ir\u00e1 ficar como **exerc\u00edcio** para voc\u00ea inclu\u00ed-las no conjunto de features. O artigo neste [link](https:\/\/towardsdatascience.com\/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b) apresenta algumas estrat\u00e9gias para lidar com vari\u00e1veis num\u00e9ricas. Veja que essas duas vari\u00e1veis podem ser discretizadas e transformadas em v\u00e1rias categorias. Por exemplo, para a feature *NR_IDADE_DATA_POSSE* voc\u00ea pode criar faixas et\u00e1rias.\n\nA vari\u00e1vel 'ID_CANDIDATO' tamb\u00e9m ser\u00e1 removida para n\u00e3o dar overfiting no modelo. Ou seja, ele vai ter uma acur\u00e1cia \u00f3tima nos dados de treinamento que n\u00e3o se reflete nos dados de teste.","7928c629":"O esquema \u00e9 apresentado na linha abaixo, para que possamos visualizar o modelo de dados que iremos trabalhar.","ad05e632":"Para **avaliar** o melhor modelo no automl:","7e4ac098":"## Treinamento e Avalia\u00e7\u00e3o do modelo\n\nNesta etapa iremos treinar o nosso classificador, neste caso usando o [AutoML](https:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/automl.html) da biblioteca H2O. Os dados de treinamento est\u00e3o armazenados em *train*, com a predi\u00e7\u00e3o sendo realizada nos dados de valida\u00e7\u00e3o *valid*.","358793fb":"## Preparando o ambiente\n\nO c\u00f3digo abaixo adiciona a **raiz** do projeto, que cont\u00e9m c\u00f3digos e dados necess\u00e1rios para o \"Hands on\".","60f3deb6":"Iremos iniciar o framework do H2O com ``h2o.init`` e separar as colunas de treinamento na vari\u00e1vel *x* e o r\u00f3tulo a ser predito na vari\u00e1vel *y*. O H2O vai iniciar com 8GB de mem\u00f3ria alocada para n\u00e3o quebrar o m\u00e1ximo de recurso dispon\u00edvel no Google.","93c25087":"Primeiro vamos transformar a coluna ELEITO de num\u00e9rica para booleana para for\u00e7ar o automl a entender o problema como classifica\u00e7\u00e3o.","0cfe6cd9":"Os valores nulos das colunas num\u00e9ricas s\u00e3o substitu\u00eddos por zero para n\u00e3o gerar exce\u00e7\u00f5es no treinamento do modelo de aprendizado de m\u00e1quina.","cbf4495b":"Melhor modelo:","390459ef":"*Import\u00e2ncia* das vari\u00e1veis:","c6b05350":"Para **avaliar** a acur\u00e1cia do modelo, o resultado da predi\u00e7\u00e3o *y_pred* \u00e9 comparado com o resultado esperado *y_valid* para gerar as m\u00e9tricas ROC, Acur\u00e1cia e F1.","65e268f5":"Iremos remover tamb\u00e9m as colunas discretas \"DS_COMPOSICAO_COLIGACAO\" e \"NM_MUNICIPIO_NASCIMENTO\". Voc\u00ea acha que vale a pena adicion\u00e1-las? No artigo [Categorical Data](https:\/\/towardsdatascience.com\/understanding-feature-engineering-part-2-categorical-data-f54324193e63), o autor discorre sobre v\u00e1rias estrat\u00e9gias para trabalhar com dados categ\u00f3ricos.","139ab64a":"## Classifica\u00e7\u00e3o utilizando Pandas e H2O\n\nNeste notebook iremos fazer a predizer os candidatos eleitos utilizando o framework [H2O](https:\/\/docs.h2o.ai\/) e o Pandas. Iremos desenvolver, neste notebook, um modelo capaz de predizer se o candidato foi eleito ou n\u00e3o, ou seja, uma tarefa de classifica\u00e7\u00e3o bin\u00e1ria.","e64b3361":"## Leitura dos dados\n\nO trecho de c\u00f3digo abaixo cria uma vari\u00e1vel *work_dir*, que ir\u00e1 apontar para o caminho no sistema de arquivos onde est\u00e3o os dados de entrada e onde a sa\u00edda ser\u00e1 escrita. Como os dados de entrada est\u00e3o no formato Parquet, o Pandas ir\u00e1 utilizar o motor de leitura Pyarrow para conseguir ler este formato de dados e aumentar a performance de leitura e transforma\u00e7\u00f5es no DataFrame.","bbef5e96":"A sa\u00edda do modelo \u00e9 salvo em um arquivo csv, contendo as colunas \"ID_CANDIDATO\" e \"ELEITO\". Estas colunas ser\u00e3o utilizadas para avaliar a acur\u00e1cia do modelo. Por isso, o resultado da predi\u00e7\u00e3o em *y_test* \u00e9 adicionada em uma nova coluna (ELEITO) do DataFrame *df_test_bruto*.","343b5a7f":"As colunas \"SG_UF\", \"TP_AGREMIACAO\", \"DS_COMPOSICAO_COLIGACAO\", \"SG_UF_NASCIMENTO\", \"NM_MUNICIPIO_NASCIMENTO\", \"ST_REELEICAO\" e \"ST_DECLARAR_BENS\" s\u00e3o transformadas para valores num\u00e9ricos utilizando a fun\u00e7\u00e3o [get_dummies](https:\/\/pandas.pydata.org\/pandas-docs\/version\/0.23.4\/generated\/pandas.get_dummies.html) do Pandas. Essa Engenharia de Features \u00e9 importante para que o classificador funcione corretamente. Desenvolvi um [notebook](https:\/\/colab.research.google.com\/drive\/1SzJ_GpFjRq6UmH1d5H1cfMAGXb4YxX7K) que mostra atrav\u00e9s de exemplos o que esta fun\u00e7\u00e3o *get_dummies* faz.","d84858ff":"## Preparando os dados de treinamento","6bd224d6":"Dentro dos dados de treinamento (*df_train_preparado*) vamos dividir nosso *dataset* entre dados de treinamento do modelo e dados de valida\u00e7\u00e3o, sendo 80% para o primeiro conjunto e 20% para o segundo. Esta divis\u00e3o serve para treinar e validar a acur\u00e1cia do nosso modelo. Existem outras formas de valida\u00e7\u00e3o, como pode ser visto no artigo [Cross-Validation in Machine Learning](https:\/\/towardsdatascience.com\/cross-validation-in-machine-learning-72924a69872f).","69848e38":"O Dataframe *output* \u00e9 escrito no formato CSV para gerar a sa\u00edda do algoritmo de aprendizado de m\u00e1quina constru\u00eddo neste notebook."}}