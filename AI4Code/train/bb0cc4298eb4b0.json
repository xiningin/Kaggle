{"cell_type":{"9459df5d":"code","18d0bc4b":"code","f95c9d55":"code","db925403":"code","b1c7c64d":"code","740a789c":"code","376f6988":"code","fccdd919":"code","047579a9":"code","ccb3b7f8":"code","2c915102":"code","481220d3":"code","18e2a052":"code","e89eca8f":"code","5f6d92ff":"code","a8709405":"code","c44531dd":"code","9d7b6d78":"code","b0ee2004":"code","261e68c6":"code","6eefe92b":"code","13e7e913":"code","7bb0530a":"code","2c5eb74c":"code","c7543aee":"code","24535b8c":"code","19cf8974":"code","49667b60":"code","2b91d3be":"code","e29539c5":"code","2e972023":"markdown","c49c759e":"markdown","e0299b03":"markdown","a5153907":"markdown","de81d426":"markdown","625c41c0":"markdown","a45bb5fe":"markdown","026f0cf8":"markdown","293365d5":"markdown"},"source":{"9459df5d":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport matplotlib.pyplot as plt # visuals \n\nfrom sklearn.preprocessing import MinMaxScaler # scale the data\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator # time series Generator\nfrom tensorflow.keras.models import Sequential # Sequential model\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout # LSTM\nfrom tensorflow.keras.callbacks import EarlyStopping # Early Stopping","18d0bc4b":"# load the data \ndf = pd.read_csv('..\/input\/retail-sales-clothing-clothing-accessory-stores\/RSCCASN.csv', parse_dates = True, index_col='DATE')","f95c9d55":"# main info\ndf.info()","db925403":"# shape of the data \ndf.shape","b1c7c64d":"# Top 5 rows\ndf.head()","740a789c":"# rename the column\ndf.columns = ['Sales']","376f6988":"# plot the data \ndf.plot(figsize = (15,6));","fccdd919":"# train test split \ntest_size = 18\ntest_index = len(df) - test_size \n\ntrain = df.iloc[:test_index]\ntest = df.iloc[test_index:]","047579a9":"train.tail()","ccb3b7f8":"test.head()","2c915102":"# scaler \nscaler = MinMaxScaler()\n\n# fit the scaler on the training data \nscaler.fit(train)\n\n# use the scaler to transform training and test data \nscaled_train = scaler.transform(train)\nscaled_test = scaler.transform(test)","481220d3":"# Timeseries Generator\nlength = 12 # a whole year \ntrain_generator = TimeseriesGenerator(scaled_train, scaled_train, length = length, batch_size = 1)\nvalidation_generator = TimeseriesGenerator(scaled_test, scaled_test, length = length, batch_size = 1)","18e2a052":"X, y = generator[0]","e89eca8f":"X","5f6d92ff":"y","a8709405":"# number of features in our dataset\nn_features = 1 \n\n# build the model\nmodel = Sequential()\nmodel.add(LSTM(64, activation = 'relu', input_shape = (length, n_features)))\nmodel.add(Dense(1))\n\n# compile the model\nmodel.compile(optimizer='adam', loss = 'mse')\n\n# Early Stopping\nearly_stop = EarlyStopping(monitor='val_loss', patience=2)\n\n# fir the model\nmodel.fit(train_generator, epochs = 20, validation_data= validation_generator, callbacks = [early_stop]);","c44531dd":"# plot losses \nlosses = pd.DataFrame(model.history.history)\nlosses.plot(figsize = (12,6))","9d7b6d78":"test_predictions = []\n\nfirst_eval_batch = scaled_train[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(len(test)):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    test_predictions.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","b0ee2004":"true_predictions = scaler.inverse_transform(test_predictions)\ntest['Predictions'] = true_predictions","261e68c6":"test","6eefe92b":"test.plot(figsize = (12, 6));","13e7e913":"# scale the full data \nfull_scaler = MinMaxScaler()\nscaled_full_data = full_scaler.fit_transform(df)","7bb0530a":"# generator for the full data \nlength = 12\ngenerator = TimeseriesGenerator(scaled_full_data, scaled_full_data, length = length, batch_size = 1)","2c5eb74c":"# number of features in our dataset\nn_features = 1 \n\n# build the model\nmodel = Sequential()\nmodel.add(LSTM(64, activation = 'relu', input_shape = (length, n_features)))\nmodel.add(Dense(1))\n\n# compile the model\nmodel.compile(optimizer='adam', loss = 'mse')\n\n# fir the model\nmodel.fit(generator, epochs = 10);","c7543aee":"forecast = []\n# Replace periods with whatever forecast length you want\nperiods = 12\n\nfirst_eval_batch = scaled_full_data[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(periods):\n    \n    # get prediction 1 time stamp ahead ([0] is for grabbing just the number instead of [array])\n    current_pred = model.predict(current_batch)[0]\n    \n    # store prediction\n    forecast.append(current_pred) \n    \n    # update batch to now include prediction and drop first value\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)","24535b8c":"# true values of the forcast  \nforecast = scaler.inverse_transform(forecast)","19cf8974":"# create a date index \nforecast_index = pd.date_range(start='2019-11-01',periods=periods,freq='MS')","49667b60":"# concatinate index with forcasts  \nforecast_df = pd.DataFrame(data=forecast,index=forecast_index,\n                           columns=['Forecast'])\nforecast_df","2b91d3be":"ax = df.plot(figsize = (12,6))\nforecast_df.plot(ax=ax)","e29539c5":"# zoom in\nax = df.plot(figsize = (12,6))\nforecast_df.plot(ax=ax)\nplt.xlim('2018-01-01','2020-12-01')","2e972023":"# Train Test Split ","c49c759e":"# Retrain and Forecast","e0299b03":"# Build and Train the model","a5153907":"# Load and Check the Data ","de81d426":"# Imports ","625c41c0":"# Data Pre-Processing","a45bb5fe":"# Evaluate the Model","026f0cf8":"> Very Godd Forcast !","293365d5":"> It is monthly data, so 12 rows is one year. We will set our test data to be 2 years (24 months)"}}