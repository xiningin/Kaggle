{"cell_type":{"d9901503":"code","f9a88b11":"code","84e2b225":"code","b80e8a3b":"code","f7b4b5ea":"code","5a111ebc":"code","15a7dc00":"code","2ace3f2c":"code","202a1376":"code","ab769fe3":"code","438790e3":"code","5f05b93e":"code","02e5b3eb":"code","a89a10cc":"code","9b825d44":"code","2e4e34ec":"code","adf59641":"code","f38f9562":"code","0396cfa6":"code","239bea6e":"code","4bd39a3f":"code","9137b212":"code","e2fa760d":"code","05a1e9e8":"code","2e617084":"code","5686bc3a":"code","b24aadd4":"code","19dea9fb":"code","293ff629":"code","56e8b25f":"code","9e131fae":"code","7d4ca360":"markdown","6090c41a":"markdown","7a69dc01":"markdown","d981b6a8":"markdown","861a67e7":"markdown","625fd16f":"markdown","a990c5bc":"markdown","df720656":"markdown","a61c8d27":"markdown","3839eadd":"markdown","d0556aab":"markdown","b8bdadc5":"markdown","2bdca14e":"markdown","9486987e":"markdown","d7183d9b":"markdown","9bac30cb":"markdown","a2827be2":"markdown","6d4e3153":"markdown","22e62bc0":"markdown","eb8e076c":"markdown","1ead0e66":"markdown","f0b7293f":"markdown","3a2a9ad1":"markdown","ba982754":"markdown"},"source":{"d9901503":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy as SCC\n\nimport tensorflow as tf\nimport math\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f9a88b11":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest= pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\ntrain.head()","84e2b225":"# Separating labels from pixels\nX_train = train.iloc[:,1:]\nY_train = train.iloc[:,0]\n\nX_train.shape","b80e8a3b":"# normalizing\nX_train = X_train \/ 255\ntest = test \/ 255","f7b4b5ea":"# initial shapes\nX_train.shape, test.shape","5a111ebc":"# Reshaping pixels to (28, 28, 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n\nX_train.shape, test.shape","15a7dc00":"# train-test split for model evaluation\nX_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.2)","2ace3f2c":"# An example image for each number\nfig, ax = plt.subplots(3,3,figsize=(10,10))\n\nnums, x = range(10), 0\nfor i in range(3):\n    for j in range(3):\n        label = nums[x]\n        numbers_pixels = train[train['label']==label]\n        img = numbers_pixels.iloc[0,1:].values\n        img = img.reshape((28,28))\n        ax[i][j].imshow(img, cmap=plt.cm.binary)\n        ax[i][j].set_title(\"Number: \" + str(label))\n        x += 1","202a1376":"# initial model\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(units=10, activation='softmax')) # 10 labels","ab769fe3":"# compilation\nmodel.compile(optimizer='adam', loss=SCC(), metrics=['accuracy'])","438790e3":"# fitting the model\nmodel.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_test, Y_test))","5f05b93e":"initial_submission = model.predict(test)\ninitial_submission_labels = np.argmax(initial_submission, axis=1)\nsubmission1 = pd.DataFrame({'ImageId': np.arange(1, 28001), 'Label': initial_submission_labels})\n# submission1.to_csv(\"submission_1.csv\", index=False)","02e5b3eb":"# Getting the labels\nY_test_pred = model.predict(X_test)\nY_pred_labels = np.argmax(Y_test_pred, axis=1)\nY_pred_labels","a89a10cc":"# Preview of shape before reshaping\nX_test.shape, Y_pred_labels.shape","9b825d44":"# Reshaping X_test to its original form to attach their corresponding labels and analyze\nX_test_copy = X_test.copy()\nX_test_copy = X_test_copy.reshape(-1, len(X_test_copy),784)\nX_test_copy.shape","2e4e34ec":"# Attaching predicted labels to pixels\nX_test_df = pd.DataFrame(X_test_copy[0])\nX_test_df['pred_label'] = Y_pred_labels\nX_test_df.head()","adf59641":"# Incorrect predictions for each label\nfig, ax = plt.subplots(3,3,figsize=(10,10))\n\nX_test_df['true_label'] = Y_test.reset_index()['label']\nincorrect = X_test_df[X_test_df['pred_label'] != X_test_df['true_label']]\n\nnums, x = range(10), 0\nfor i in range(3):\n    for j in range(3):\n        label = nums[x]\n        numbers_pixels = incorrect[incorrect['pred_label']==label]\n        img = numbers_pixels.iloc[0,:784].values\n        img = img.reshape((28,28))\n        ax[i][j].imshow(img, cmap=plt.cm.binary)\n        ax[i][j].set_title(\"Incorrect Label: \" + str(label))\n        x += 1","f38f9562":"# Confusion matrix\nY_pred = model.predict(X_test)\nY_pred_classes = np.argmax(Y_pred, axis = 1) \nY_true = Y_test.values\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nplt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Reds\", fmt= '.1f')\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","0396cfa6":"# load the data\ntrain = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest= pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\n# separate\nX_train = train.iloc[:,1:]\nY_train = train.iloc[:,0]\n\n# normalize\nX_train = X_train \/ 255\ntest = test \/ 255\n\nX_train.shape, test.shape","239bea6e":"# Reshape images to (28, 28, 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n\nX_train.shape, test.shape","4bd39a3f":"# train-test split\nX_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.2)","9137b212":"# model - adding pooling\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D((2, 2)))  # new\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(units=10, activation='softmax'))","e2fa760d":"# compilation\nmodel.compile(optimizer='adam', loss=SCC(), metrics=['accuracy'])","05a1e9e8":"# fitting the model\nmodel.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_test, Y_test))","2e617084":"# model - adding more depth\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))  # new\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))  # new\nmodel.add(MaxPooling2D((2, 2)))  # new\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(units=10, activation='softmax'))","5686bc3a":"# compilation\nmodel.compile(optimizer='adam', loss=SCC(), metrics=['accuracy'])","b24aadd4":"# fitting the model\nmodel.fit(X_train, Y_train, batch_size=32, epochs=10, validation_data=(X_test, Y_test))","19dea9fb":"# model - changing hyperparameters\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))  # changed hyperparam\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))  # changed hyperparam\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(units=10, activation='softmax'))","293ff629":"# compilation\nmodel.compile(optimizer='adam', loss=SCC(), metrics=['accuracy'])","56e8b25f":"# fitting the model - also increased epochs\nmodel.fit(X_train, Y_train, batch_size=32, epochs=25, validation_data=(X_test, Y_test))","9e131fae":"improved_submission = model.predict(test)\nimproved_submission_labels = np.argmax(improved_submission, axis=1)\nsubmission2 = pd.DataFrame({'ImageId': np.arange(1, 28001), 'Label': improved_submission_labels})\n\n# final submission\nsubmission2.to_csv(\"submission_2.csv\", index=False)","7d4ca360":"# Improved Model\n* Note: repeating the initial model's preprocessing (instead of re-using) to remain coherent in this latter half of the notebook","6090c41a":"Here, we see that adding a pooling layer already decreases validation loss compared to the initial model. To try to reduce validation loss even more, more depth will be added.","7a69dc01":"## Improved Submission","d981b6a8":"# Simple Initial Model\n- very minimal layers","861a67e7":"### Part 3: Experimenting with Hyperparameters\n* Also increased epochs as this is the final edit for the improved model.","625fd16f":"Initial submission - very minimal layers\n\n### **This model received a score of 0.98207.**","a990c5bc":"Initially, I checked 50 epochs to see the improvement trends. The model generally did not increase after epoch=25. Epoch=15 may even be optimal, but I will stick with epoch=25.","df720656":"Added a pooling layer, added depth, tweaked hyperparameteres, and increased epochs\n\n**Score: 0.99096**","a61c8d27":"### Part 1: Adding a pooling layer","3839eadd":"Pixels range from [0, 255]. Each element needs to be normalized to a range of [0, 1].","d0556aab":"Now I will be adding to the initial model within 3 different parts to observe the difference each change makes.","b8bdadc5":"____","2bdca14e":"A model contains two main parts: It begins with feature extraction (convolution\/pooling layers) and ends with the classifier that will make the predictions.\n\n**Here, a convolutional layer was added. In between the two parts comes a Flatten layer. Afterwards, two Dense layers were added to make the predictions.**","9486987e":"### Preprocessing","d7183d9b":"### Part 2: Adding more depth","9bac30cb":"## Initial Submission","a2827be2":"# MNIST Digit Recognizer\n\n# Very Simple Initial Model Followed by an Improved Model\n- Simple initial model received ***Score: 0.98207***\n- Improved model received ***Score: 0.99096***","6d4e3153":"___","22e62bc0":"## Optional: Exploring the Predictions","eb8e076c":"The 784 pixels of each entry need to be reshaped into (28, 28, 1) to be processed.","1ead0e66":"Validation loss decreased even more from adding more layers. Next, the hyperparameters of these new layers will be tweaked.","f0b7293f":"Validation loss decreased as I changed the Conv2D filter sizes from 32 to 64 for the middle layers. This is the final model used for the improved submission.","3a2a9ad1":"## What do these images look like?","ba982754":"Let's see example images for **incorrect labels.**"}}