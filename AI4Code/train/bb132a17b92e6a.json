{"cell_type":{"18f14a2e":"code","43fec8cb":"code","4e105953":"code","53ccfe11":"code","05a3233c":"code","142bfc9b":"code","0c55bb23":"code","b069541b":"code","a40d77d6":"code","77cf520f":"code","29556b57":"code","3ee892a5":"code","871e789b":"markdown","50f97204":"markdown"},"source":{"18f14a2e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nimport torch.utils.data as data_utils\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","43fec8cb":"data_sets = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\n\nY = data_sets[\"Class\"]\nX = data_sets.drop(columns=[\"Class\"])","4e105953":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=1)","53ccfe11":"data_sets.head(5)","05a3233c":"class classifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Conv1d(in_channels=1, out_channels=10,kernel_size=3,stride=3)\n        self.layer2 = nn.Conv1d(in_channels=10, out_channels=5,kernel_size=2,stride=2)\n        self.max_pool = nn.MaxPool1d(kernel_size=2, stride=1)\n        self.fc1 = nn.Linear(20,10)\n        self.fc2 = nn.Linear(10,2)\n        self.drop_out = nn.Dropout(0.2)\n        \n    def forward(self, x):\n        x = x.view(-1,1,30)\n        x = F.relu(self.layer1(x))\n        x = self.max_pool(x)\n        x = F.relu(self.layer2(x))        \n        # reshape the tensor\n        x = x.view(-1, 5*4)\n        x = F.relu(self.fc1(x))\n        x = self.drop_out(x)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n        ","142bfc9b":"train_target = torch.tensor(Y_train.values.astype(np.float32))\ntrain_data = torch.tensor(X_train.values.astype(np.float32))\ntrain_tensor = data_utils.TensorDataset(train_data, train_target)\ntrainloader = data_utils.DataLoader(dataset=train_tensor, batch_size=32,shuffle=True)","0c55bb23":"test_target = torch.tensor(Y_test.values.astype(np.float32))\ntest_data = torch.tensor(X_test.values.astype(np.float32))\ntest_tensor = data_utils.TensorDataset(test_data, test_target)\ntestloader = data_utils.DataLoader(dataset=test_tensor, batch_size=32)","b069541b":"device = torch.device(\"cuda:0\")\n","a40d77d6":"model = classifier().cuda()\ncriterion = nn.NLLLoss()\noptimizer =  torch.optim.Adam(model.parameters(), lr=0.001)\nprint_every_n = 10\nepochs= 10\nmodel.to(device)\ntrain_losses, test_losses = [], []\nfor epoch in range(epochs):\n    running_loss = 0.0\n    model.train()\n    for step, (data, label) in enumerate(trainloader):\n        data , label = data.to(device), label.to(device)\n        optimizer.zero_grad()\n        train_logps = model.forward(data)\n        loss = criterion(train_logps, label.long())\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    else:\n        with torch.no_grad():\n            model.eval()\n            running_test_loss = 0.0\n            accuracy = 0.0\n            for test_data, test_label in testloader:\n                test_data, test_label = test_data.to(device), test_label.to(device)\n                test_logps = model.forward(test_data)\n                test_loss = criterion(test_logps, test_label.long())\n                running_test_loss += test_loss.item()\n                test_prob = torch.exp(test_logps)\n                prob, predic_class = test_prob.topk(1, dim=1)\n                equal = predic_class == test_label.long().view(*predic_class.shape)\n                accuracy += torch.mean(equal.type(torch.FloatTensor)).item()\n        train_losses.append(running_loss \/ len(trainloader))    \n        test_losses.append(running_test_loss \/ len(testloader))                          \n                \n        print(f\"Epoch= {epoch+1},Training loss = {running_loss\/len(trainloader)},Test loss = {running_test_loss\/len(testloader)}, Accuracy >> {accuracy\/len(testloader)}\")\n                \n    \n    ","77cf520f":"with torch.no_grad():\n    x_test = torch.tensor(X_test.values).to(device)\n    predicted_value = model.forward(x_test.float()).cpu().data.numpy().argmax(axis=1)","29556b57":"print(f\"accuracy >> {accuracy_score(predicted_value, Y_test.values)} \")\nprint(f\"Area Under the Curve >> {roc_auc_score(predicted_value, Y_test.values)} \")","3ee892a5":"plt.plot(train_losses,color=\"blue\",label=\"training error\")\nplt.plot(test_losses, color=\"red\", label=\"test error\")\nplt.ylabel(\"Negative Log likelihood loss\")\nplt.xlabel(\"Epoch\")","871e789b":"Prepare the test datseets","50f97204":"Prepare the training data setst"}}