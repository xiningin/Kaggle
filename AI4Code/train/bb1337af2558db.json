{"cell_type":{"bd7a9cc5":"code","6939a965":"code","739e8bb5":"code","65f6b695":"code","9f0ae1c1":"code","dcc3b8cb":"code","d6d27789":"code","5a1b7b42":"code","63b96943":"code","e694894a":"code","938c8e59":"code","e7430006":"code","5f240a35":"code","a36be661":"code","2f41942d":"code","7079eef7":"markdown"},"source":{"bd7a9cc5":"import numpy as np\nimport pandas as pd \nimport os\nimport keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(keras.__version__)\n\nprint(\"{} paintings\".format(len(os.listdir(\"..\/input\/resized\/resized\"))))","6939a965":"df = pd.read_csv('..\/input\/artists.csv')\ndf.head()","739e8bb5":"from skimage.transform import resize\nfrom keras.preprocessing import image\n\nimg_dir = '..\/input\/images\/images\/'\nfiles = os.listdir(img_dir)\nimg_size = (300,300)\ninput_shape = [*img_size, 3]\n\ndef load_img(path):\n    img = image.load_img(path=path, target_size=img_size)\n    return np.asarray(img, dtype=\"int32\" )\/255","65f6b695":"datagen = keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rescale=1.0\/255,\n    rotation_range=0,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    validation_split=0.1)\n\ntrain_generator = datagen.flow_from_directory(\n        img_dir,\n        target_size=img_size,\n        batch_size=12,\n        class_mode='categorical',\n        subset=\"training\")\nvalidation_generator = datagen.flow_from_directory(\n        img_dir,\n        target_size=img_size,\n        batch_size=12,\n        class_mode='categorical',\n        subset=\"validation\")\n\nnum_classes = len(train_generator.class_indices)","9f0ae1c1":"plt.hist(train_generator.classes)\nplt.hist(validation_generator.classes)","dcc3b8cb":"from keras.applications.xception import Xception\nfrom keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Dense\n\nbase_model = Xception(include_top=False, weights='imagenet')\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu', name=\"dense_1024\")(x)\npredictions = Dense(num_classes, activation='softmax', name=\"predictions\")(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)","d6d27789":"for i, layer in enumerate(base_model.layers):\n    print(i, layer.name)","5a1b7b42":"# freeze some layers, only train the last blocks\nfor layer in base_model.layers[:31]:\n    layer.trainable = True\nfor layer in base_model.layers[86:]:\n    layer.trainable = True","63b96943":"%%time\nfrom keras.callbacks import *\nfrom keras.optimizers import *\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=6),\n    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.2, min_lr=0.001)\n]\n\nmodel.compile(optimizer=SGD(lr=0.01),\n              loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit_generator(\n    train_generator, \n    callbacks=callbacks, \n    validation_data=validation_generator, \n    epochs=16,\n    steps_per_epoch=500,\n    validation_steps=80,\n    workers=2)","e694894a":"model.load_weights('best_model.h5')\n\nmodel.evaluate_generator(datagen.flow_from_directory(\n        img_dir,\n        target_size=img_size,\n        batch_size=16,\n        class_mode='categorical'), steps=100)","938c8e59":"from keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.models import Model\n\nclass ImgVectorizer:\n\n    def __init__(self, model, dense_layer_name):\n        self.intermediate_layer_model = Model(\n            inputs=model.input, \n            outputs=model.get_layer(dense_layer_name).output\n        )\n\n    def to_vector(self, imgs):\n        \"\"\" Gets a vector embedding from an image\n        :param image_path: path to image on filesystem\n        :returns: numpy ndarray\n        \"\"\"\n        batch = np.array(imgs)\n        intermediate_output = self.intermediate_layer_model.predict(batch)\n        return intermediate_output\n    \nvectorizer = ImgVectorizer(model=model, dense_layer_name=\"dense_1024\")","e7430006":"def batched(batch_size, iterable):\n    batch = []\n    for item in iterable:\n        batch.append(item)\n        if len(batch) == batch_size:\n            yield batch\n            batch = []\n    if len(batch) > 0:\n        yield batch","5f240a35":"import glob\nimport re\n\np = re.compile(\".*\/images\/(?P<name>.*)\/(?P<img>.*)\\.jpg\")\n\ndef img_dict_generator():\n    for file in glob.glob(img_dir + '*\/*'):\n        match = p.match(file)\n        if match:\n            artist = p.match(file).group(\"name\")\n            yield {'artist': artist, 'file': file, 'vector': []}\n        \ndf = pd.DataFrame(img_dict_generator())","a36be661":"%%time\n\ndef add_vector_field(dataframe):\n    dataframe['file'].values\n\nfor indexes in batched(16, df.index):\n    df_batch = df.loc[indexes]\n    imgs = [load_img(file) for file in df_batch['file'].values]\n    vectors = vectorizer.to_vector(imgs)\n    df_batch['vector'] = [tuple(list) for list in vectors]\n    df.update(df_batch)","2f41942d":"df.to_hdf('df_with_vectors.h5', key=\"vectors\")\ndf.to_csv('df_with_vectors.csv')","7079eef7":"# Building an artist classifier for vector encoding\nWe use the [Xception](https:\/\/arxiv.org\/abs\/1610.02357v2) model with the imagenet weights as a base model without the top layers.\nWe add a dense vector layer with 1024 dimensions and a classification layer with 50 dimensions for the 50 classes\/artists that are given in the dataset.\n\nThis model can than be used to extract vector representations for images.\nWe want to use these vector representations to build a simple similarity search for images.\nSee https:\/\/www.kaggle.com\/roccoli\/painting-similarity\/"}}