{"cell_type":{"bf260f9f":"code","37c2a923":"code","bc9841d4":"code","4bbfec64":"code","582c24d7":"code","0456d0c4":"code","46c9154a":"code","fe873782":"code","c8bd6bd9":"code","a8c00556":"code","2734fa77":"code","9cc4e00d":"code","33c15f05":"code","03c60560":"code","1c11e26c":"code","0f6b8ba7":"code","f7036c6a":"code","f077bd54":"code","1b94dc02":"code","945ebb10":"code","41f099ba":"code","91d89a12":"code","53c9faf4":"code","7b7f9da2":"code","4b005c64":"code","f75c437b":"code","2963cbf7":"code","8a4d6b7e":"code","7904882d":"code","e89fdae6":"code","80e29e80":"code","88c7ea08":"code","f7334947":"code","570c21cd":"code","923adec6":"code","785f595b":"code","328a6b86":"code","a3162d5e":"code","2274794a":"code","8ae5f072":"code","62216749":"code","040c4600":"code","ce9d5f9c":"code","feeac159":"code","3901d31a":"code","0deda4bf":"code","c7a2f986":"code","305ca4b4":"code","cb2b5758":"code","0ce59596":"code","507dcb37":"markdown","94387703":"markdown","99a51f4a":"markdown","53d10a3c":"markdown","d5954b78":"markdown","b4305f41":"markdown","9c575e80":"markdown","323a5617":"markdown","c4018b1a":"markdown","bcaa5743":"markdown","0fcd4458":"markdown","e5f81724":"markdown","6a785d1e":"markdown","19ccf5ec":"markdown"},"source":{"bf260f9f":"!pip show  -q\n!pip install -q efficientnet\n# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043e\u0431\u0432\u044f\u0437\u043a\u0443 \u043f\u043e\u0434 keras \u0434\u043b\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u044f \u043f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0445 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, albuminations\n!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor -q","37c2a923":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pickle\nimport csv\nimport os\nimport random\nfrom kaggle_datasets import KaggleDatasets\nimport zipfile\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom keras.callbacks import Callback\nfrom keras.regularizers import l2\nfrom keras import optimizers\nfrom keras.models import Model\nfrom keras.utils import np_utils\nfrom keras.applications.xception import Xception\nfrom keras.layers import *\nimport efficientnet.tfkeras as efn\n\nimport tensorflow.keras as keras\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.callbacks as C\nfrom tensorflow.keras.preprocessing import image\nfrom keras.callbacks import LearningRateScheduler,EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n\n\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nimport csv\nimport sys\nimport os\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","bc9841d4":"print()","4bbfec64":"# Checking the GPU.\n!nvidia-smi","582c24d7":"# \u0412 \u0441\u0435\u0442\u0430\u043f \u0432\u044b\u043d\u043e\u0448\u0443 \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438, \u0442\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0439 \u0438\u0445 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c\nEPOCHS               = 11  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 64 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.2 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 20%\n\nCLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\nIMG_SIZE             = 224 # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\nIMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\n\n\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/sf-dl-car-classification\/'\nOUT_PATH = '.\/car'\nPATH = \"\/kaggle\/working\/car\"\nMODEL = \"Xception\"\nMODEL_PATH = '\/kaggle\/working'","0456d0c4":"os.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)\n\nimport tensorflow\ntensorflow.random.set_seed(RANDOM_SEED)\n","46c9154a":"print('\u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\n\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    print(data_zip)\n    with zipfile.ZipFile(f\"{DATA_PATH}{data_zip}\",\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","fe873782":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","c8bd6bd9":"train_df.info()","a8c00556":"train_df.Category.value_counts()","2734fa77":"print('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(f'{OUT_PATH}\/train\/{random_image_cat[index]}\/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","9cc4e00d":"image = PIL.Image.open(OUT_PATH+'\/train\/0\/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","33c15f05":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations","03c60560":"# \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0447\u0435\u043d\u044c \u0432\u0430\u0436\u043d\u0430 \u043a\u043e\u0433\u0434\u0430 \u0443 \u043d\u0430\u0441 \u043d\u0435 \u0431\u043e\u043b\u044c\u0448\u043e\u0439 \u0434\u0430\u0442\u0430\u0441\u0435\u0442 (\u043a\u0430\u043a \u0432 \u043d\u0430\u0448\u0435\u043c \u0441\u043b\u0443\u0447\u0430\u0435)\n# \u041f\u043e\u0438\u0433\u0440\u0430\u0439\u0441\u044f \u0442\u0443\u0442 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438 \u0447\u0442\u043e\u0431 \u043f\u043e\u043d\u044f\u0442\u044c \u0447\u0442\u043e \u043a \u0447\u0435\u043c\u0443. \n# \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0434\u043e\u043a\u0430 https:\/\/keras.io\/preprocessing\/image\/\nAUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1.\/255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)","1c11e26c":"# \"\u0417\u0430\u0432\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u0435\u043c\" \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 generator\n\ntrain_generator = train_datagen.flow_from_directory(\n    OUT_PATH+'\/train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    OUT_PATH+'\/train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe(\n    dataframe=sample_submission,\n    directory=OUT_PATH+'\/test_upload',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n\n# \u043a\u0441\u0442\u0430\u0442\u0438, \u0442\u044b \u0437\u0430\u043c\u0435\u0442\u0438\u043b, \u0447\u0442\u043e \u0434\u043b\u044f \u0441\u0430\u0431\u043c\u0438\u0448\u0435\u043d\u0430 \u043c\u044b \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0434\u0440\u0443\u0433\u043e\u0439 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 flow_from_dataframe? \n# \u041a\u0430\u043a \u0442\u044b \u0434\u0443\u043c\u0430\u0435\u0448\u044c, \u043f\u043e\u0447\u0435\u043c\u0443?","0f6b8ba7":"def make_callbacks():\n    \n    callback_early_stopping = EarlyStopping(monitor='accuracy',patience=2, verbose=1)\n    callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.5,min_lr=1e-10,patience=0,verbose=1)\n    callback_learing_rate = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x),\n    path_checkpoint = 'checkpoint.keras'\n    callback_checkpoint = ModelCheckpoint(f'{MODEL}_best.hdf5' , monitor = ['val_acc'] , verbose = 1  , mode = 'max') #ModelCheckpoint(filepath=path_checkpoint,monitor='val_loss',verbose=1,save_weights_only=True, save_best_only=True)\n\n    return [callback_checkpoint,\n            callback_learing_rate,\n                 callback_reduce_lr]\n\ncallbacks = make_callbacks()","f7036c6a":"# \u041a\u0441\u0442\u0430\u0442\u0438 \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u0435\u0449\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0441\u0435\u0442\u0435\u0439...\nbase_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)","f077bd54":"base_model.summary()","1b94dc02":"# \u0414\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u0437\u0430\u043c\u043e\u0440\u043e\u0437\u0438\u043c \u0432\u0435\u0441\u0430 Xception \u0438 \u043e\u0431\u0443\u0447\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e \"\u0433\u043e\u043b\u043e\u0432\u0443\". \n# \u0414\u0435\u043b\u0430\u0435\u043c \u044d\u0442\u043e \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u0445\u043e\u0440\u043e\u0448\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043d\u0430 Imagenet \u043d\u0435 \u0437\u0430\u0442\u0438\u0440\u0430\u043b\u0438\u0441\u044c \u0432 \u0441\u0430\u043c\u043e\u043c \u043d\u0430\u0447\u0430\u043b\u0435 \u043d\u0430\u0448\u0435\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\nbase_model.trainable = False","945ebb10":"# \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043d\u043e\u0432\u0443\u044e \"\u0433\u043e\u043b\u043e\u0432\u0443\" (head)\n\nmodel=M.Sequential()\nmodel.add(base_model)\nmodel.add(L.GlobalAveragePooling2D(),) # \u043e\u0431\u044a\u0435\u0434\u0438\u043d\u044f\u0435\u043c \u0432\u0441\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u0432 \u0435\u0434\u0438\u043d\u044b\u0439 \u0432\u0435\u043a\u0442\u043e\u0440 \n\n\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","41f099ba":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","91d89a12":"# \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0441\u043b\u043e\u0435\u0432\nprint(len(model.layers))\nlen(model.trainable_variables)\n# Check the trainable status of the individual layers\nfor layer in model.layers:\n    print(layer, layer.trainable)","53c9faf4":"model.summary()","7b7f9da2":"callbacks = make_callbacks()","4b005c64":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\n\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks\n)","f75c437b":"model.save(f'{MODEL}_last.hdf5')\nmodel.load_weights(f'{MODEL}_best.hdf5')","2963cbf7":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","8a4d6b7e":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","7904882d":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission_base_Xception.csv', index=False)\nprint('Save submit')","e89fdae6":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))","80e29e80":"base_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = len(base_model.layers)\/\/2\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","88c7ea08":"len(base_model.trainable_variables)","f7334947":"# Check the trainable status of the individual layers\nfor layer in model.layers:\n    print(layer, layer.trainable)","570c21cd":"EPOCHS               = 14  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 16 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU","923adec6":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","785f595b":"callbacks = make_callbacks()","328a6b86":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks\n)","a3162d5e":"model.save(f'{MODEL}_last_finetuning.hdf5')\nmodel.load_weights(f'{MODEL}_best.hdf5')","2274794a":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","8ae5f072":"test_sub_generator.samples","62216749":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","040c4600":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","ce9d5f9c":"submission.head()","feeac159":"model.load_weights(f'{MODEL}_best.hdf5')","3901d31a":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=220, width=200),\n        albumentations.CenterCrop(height=200, width=220),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n      \ntest_datagen = ImageDataAugmentor( \n    rescale=1.\/255,\n    augment = AUGMENTATIONS,\n    validation_split=VAL_SPLIT,\n)","0deda4bf":"test_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=OUT_PATH+'\/test_upload',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","c7a2f986":"tta_steps = 10 # \u0431\u0435\u0440\u0435\u043c \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0438\u0437 10 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","305ca4b4":"predictions = np.argmax(pred, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","cb2b5758":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission_TTA.csv', index=False)\nprint('Save submit')","0ce59596":"# Clean OUT_PATH\nimport shutil\nshutil.rmtree(OUT_PATH)","507dcb37":"# Submission","94387703":"## Fit\n* \u0414\u043b\u044f \u043f\u0440\u043e - \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439 \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c \u0440\u0430\u0437\u043d\u044b\u0435 \u0442\u0435\u0445\u043d\u0438\u043a\u0438 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f Learning Rate\n#### \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440:\n* https:\/\/towardsdatascience.com\/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6\n* http:\/\/teleported.in\/posts\/cyclic-learning-rate\/","99a51f4a":"# Callbackss","53d10a3c":"# EDA \/ \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445","d5954b78":"# Test Time Augmentation\n\nhttps:\/\/towardsdatascience.com\/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d\n\n\u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u0435\u043c \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0438 \u0441\u0434\u0435\u043b\u0430\u0435\u043c \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u043e\u0434\u043d\u043e\u0439 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0432 \u0440\u0430\u0437\u043d\u043e\u043c \u0432\u0438\u0434\u0435. \u0412\u0437\u044f\u0432 \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0438\u0437 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439 \u043f\u043e\u043b\u0443\u0447\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u0435 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435.","b4305f41":"# \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u044b \u0432\u0435\u0441\u043e\u0432 FineTuning","9c575e80":"# \u0412\u044b\u0432\u043e\u0434\n* Debug \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u044f\n* transfer learning \u0438 fine-tuning\n* \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 LR, optimizer\n* \u043f\u043e\u0434\u043e\u0431\u0440\u0430\u043d\u044b \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 (\u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438, \u0431\u0430\u0442\u0447 \u0438 \u0442.\u0434.)\n* SOTA \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 \u0441\u0435\u0442\u0435\u0439 - Xception\n* \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0430 Batch Normalization \u0438 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0430 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0430 \u201c\u0433\u043e\u043b\u043e\u0432\u044b\u201d\n* \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u044b \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 callback Keras https:\/\/keras.io\/callbacks\/\n* TTA (Test Time Augmentation)","323a5617":"# Data","c4018b1a":"# Setup","bcaa5743":"### \u043f\u043e\u0434\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0443\u044e \u0441\u0435\u0442\u044c Xception","0fcd4458":"# Model","e5f81724":"### datagen","6a785d1e":"### Data augmentation","19ccf5ec":"# Car classification\n![](http:\/\/img1.joyreactor.cc\/pics\/post\/\u0430\u0432\u0442\u043e\u043f\u0440\u043e\u043c-\u0432\u0430\u0437-\u043b\u0438\u043c\u0443\u0437\u0438\u043d-\u0432\u0430\u0442\u0435\u0440\u043c\u0430\u0440\u043a-351083.jpeg)\n\n### \u041e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0438\u0434\u0435\u044f - \u0431\u0435\u0440\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0443\u044e \u043d\u0430 imagenet \u0441\u0435\u0442\u044c Xception \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043f\u043e\u0434 \u043d\u0430\u0448\u0443 \u0437\u0430\u0434\u0430\u0447\u0443.\n\u041f\u043e \u0445\u043e\u0434\u0443 \u043a\u0435\u0440\u043d\u0435\u043b\u0430 \u044f \u0431\u0443\u0434\u0443 \u0434\u0430\u0432\u0430\u0442\u044c \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438 \u0438 \u043f\u043e\u0434\u0441\u043a\u0430\u0437\u043a\u0438 (\u0433\u0434\u0435 \u0447\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u0434\u043a\u0440\u0443\u0442\u0438\u0442\u044c \u0438 \u0447\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u0435\u0449\u0435 \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c, \u0447\u0442\u043e\u0431 \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u0441\u043a\u043e\u0440).  \n\u041c\u043d\u043e\u0433\u0438\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u043e \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043b\u0435\u043d\u044b \u043d\u0435 \u043e\u043f\u0442\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c ;)\n\n\u0423\u0434\u0430\u0447\u0438 \u0438 \u041f\u043e\u0435\u0445\u0430\u043b\u0438!"}}