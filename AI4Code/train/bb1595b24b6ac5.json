{"cell_type":{"d1731ef6":"code","3f0ddb9d":"code","4f8f5ffd":"code","102eac96":"code","b8f92ffa":"code","b4120528":"code","6a00c610":"code","6d0de2da":"code","30459b81":"code","b93a7c9a":"code","5287942c":"code","059fbf3c":"code","bba59f5c":"code","56451b95":"code","2964ab4e":"code","42e33da0":"code","d70c710d":"code","254b7147":"code","7c1495ef":"code","1a6ae0c0":"code","c9af8936":"code","6eed52b9":"code","e587bbff":"code","a9951cb7":"code","be4ef1b9":"code","26426691":"code","190a86cf":"code","69591139":"code","dd73c653":"code","89342312":"code","8196a522":"code","250530ed":"code","1dd13b10":"code","f102779e":"code","c04476d7":"code","19a35464":"code","bc0a7e8c":"code","b3d5f385":"code","b6f33490":"code","b3b265b5":"code","0a45377e":"code","16de88cc":"code","6f425376":"markdown","90d3f0b4":"markdown","29076a19":"markdown","ef7413a2":"markdown","6d472c1a":"markdown","18116866":"markdown","a75aa7ad":"markdown","0bde2da7":"markdown","59f596a5":"markdown","03044028":"markdown","b07d683d":"markdown","b3998654":"markdown","bf4dc347":"markdown","07604973":"markdown","924651b8":"markdown","396775c5":"markdown","a22ddf4c":"markdown","977e3487":"markdown","ae6dcb7f":"markdown","7a77b183":"markdown","4a62361c":"markdown","5af0da2a":"markdown","e9359101":"markdown","dcea0109":"markdown","35e540e5":"markdown","b749c355":"markdown","29c74eea":"markdown","a6b5617e":"markdown","bc17105e":"markdown","3116fb61":"markdown","303e0c46":"markdown","a75fd4ce":"markdown","fef05b87":"markdown","4952afe5":"markdown","42810826":"markdown","6933a9b2":"markdown","1ff81fb1":"markdown","ba2de4b2":"markdown","9aa85cca":"markdown","05e925a5":"markdown","5b44fb99":"markdown","c8d402d4":"markdown","d24be3b3":"markdown","cc3ded00":"markdown","bdafc4f7":"markdown","e1f9bcb2":"markdown"},"source":{"d1731ef6":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nfrom sklearn.metrics import mean_squared_error","3f0ddb9d":"df = pd.read_csv('..\/input\/amazon-product-reviews\/ratings_Electronics (1).csv', header=None) #There are no headers in the data file\n\ndf.columns = ['user_id', 'prod_id', 'rating', 'timestamp'] #Adding column names\n\ndf = df.drop('timestamp', axis=1) #Dropping timestamp\n\ndf_copy = df.copy(deep=True) #Copying the data to another dataframe","4f8f5ffd":"# see few rows of the imported dataset\ndf.head()","102eac96":"# Check the number of rows and columns\nrows, columns = df.shape[0], df.shape[1]\nprint(\"No of rows: \", rows) \nprint(\"No of columns: \", columns) ","b8f92ffa":"#Check Data types\ndf.dtypes","b4120528":"# Find number of missing values in each column\ndf.isna().sum()","6a00c610":"# Summary statistics of 'rating' variable\ndf.describe()","6d0de2da":"#Create the plot and provide observations\n\nplt.figure(figsize = (12,6))\ndf['rating'].value_counts(1).plot(kind='bar')\nplt.show()","30459b81":"# Number of unique user id and product id in the data\nprint('Number of unique USERS in Raw data = ', df['user_id'].nunique())\nprint('Number of unique ITEMS in Raw data = ', df['prod_id'].nunique())","b93a7c9a":"# Top 10 users based on rating\nmost_rated = df.groupby('user_id').size().sort_values(ascending=False)[:10]\nmost_rated","5287942c":"counts = df['user_id'].value_counts()\ndf_final = df[df['user_id'].isin(counts[counts >= 50].index)]","059fbf3c":"print('The number of observations in the final data =', len(df_final))\nprint('Number of unique USERS in the final data = ', df_final['user_id'].nunique())\nprint('Number of unique PRODUCTS in the final data = ', df_final['prod_id'].nunique())","bba59f5c":"#Creating the interaction matrix of products and users based on ratings and replacing NaN value with 0\nfinal_ratings_matrix = df_final.pivot(index = 'user_id', columns ='prod_id', values = 'rating').fillna(0)\nprint('Shape of final_ratings_matrix: ', final_ratings_matrix.shape)\n\n#Finding the number of non-zero entries in the interaction matrix \ngiven_num_of_ratings = np.count_nonzero(final_ratings_matrix)\nprint('given_num_of_ratings = ', given_num_of_ratings)\n\n#Finding the possible number of ratings as per the number of users and products\npossible_num_of_ratings = final_ratings_matrix.shape[0] * final_ratings_matrix.shape[1]\nprint('possible_num_of_ratings = ', possible_num_of_ratings)\n\n#Density of ratings\ndensity = (given_num_of_ratings\/possible_num_of_ratings)\ndensity *= 100\nprint ('density: {:4.2f}%'.format(density))\n\nfinal_ratings_matrix.head()","56451b95":"#Calculate the average rating for each product \naverage_rating = df_final.groupby(['prod_id']).mean().rating\nprint(average_rating.head())\n#Calculate the count of ratings for each product\ncount_rating = df_final.groupby(['prod_id']).count().rating\n\n#Create a dataframe with calculated average and count of ratings\nfinal_rating = pd.DataFrame(pd.concat([average_rating,count_rating], axis = 1))\nfinal_rating.columns=[\"Average Rating\", \"Ratings Count\"]\n\n#Sort the dataframe by average of ratings\nfinal_rating = final_rating.sort_values(by='Average Rating', ascending=False)\n\nfinal_rating.head()","2964ab4e":"#defining a function to get the top n products based on highest average rating and minimum interactions\ndef top_n_products(final_rating, n, min_interaction):\n    \n    #Finding movies with minimum number of interactions\n    recommendations = final_rating[final_rating['Ratings Count'] >= min_interaction]\n    \n    #Sorting values w.r.t average rating \n    recommendations = recommendations.sort_values(by='Average Rating', ascending=False)\n    \n    return recommendations.index[:n]","42e33da0":"list(top_n_products(final_rating, 5, 50))","d70c710d":"list(top_n_products(final_rating, 5, 100))","254b7147":"final_ratings_matrix.head()","7c1495ef":"final_ratings_matrix['user_index'] = np.arange(0, final_ratings_matrix.shape[0])\nfinal_ratings_matrix.set_index(['user_index'], inplace=True)\n\n# Actual ratings given by users\nfinal_ratings_matrix.head()","1a6ae0c0":"# defining a function to get similar users\ndef similar_users(user_index, interactions_matrix):\n    similarity = []\n    for user in range(0, interactions_matrix.shape[0]):\n        \n        #finding cosine similarity between the user_id and each user\n        sim = cosine_similarity([interactions_matrix.loc[user_index]], [interactions_matrix.loc[user]])\n        \n        #Appending the user and the corresponding similarity score with user_id as a tuple\n        similarity.append((user, sim))\n        \n    similarity.sort(key=lambda x: x[1], reverse=True)\n    most_similar_users = [Tuple[0] for Tuple in similarity] #Extract the user from each tuple in the sorted list\n    similarity_score = [Tuple[1] for Tuple in similarity]   ##Extracting the similarity score from each tuple in the sorted list\n   \n    #Remove the original user and its similarity score and keep only other similar users \n    most_similar_users.remove(user_index)\n    similarity_score.remove(similarity_score[0])\n       \n    return most_similar_users, similarity_score","c9af8936":"similar = similar_users(3, final_ratings_matrix)[0][0:10]\nsimilar","6eed52b9":"#Print the similarity score\nsimilar_users(3,final_ratings_matrix)[1][0:10]","e587bbff":"similar = similar_users(1521, final_ratings_matrix)[0][0:10]\nsimilar","a9951cb7":"#Print the similarity score\nsimilar_users(1521, final_ratings_matrix)[1][0:10]","be4ef1b9":"# defining the recommendations function to get recommendations by using the similar users' preferences\ndef recommendations(user_index, num_of_products, interactions_matrix):\n    \n    #Saving similar users using the function similar_users defined above\n    most_similar_users = similar_users(user_index, interactions_matrix)[0]\n    \n    #Finding product IDs with which the user_id has interacted\n    prod_ids = set(list(interactions_matrix.columns[np.where(interactions_matrix.loc[user_index] > 0)]))\n    recommendations = []\n    \n    observed_interactions = prod_ids.copy()\n    for similar_user in most_similar_users:\n        if len(recommendations) < num_of_products:\n            \n            #Finding 'n' products which have been rated by similar users but not by the user_id\n            similar_user_prod_ids = set(list(interactions_matrix.columns[np.where(interactions_matrix.loc[similar_user] > 0)]))\n            recommendations.extend(list(similar_user_prod_ids.difference(observed_interactions)))\n            observed_interactions = observed_interactions.union(similar_user_prod_ids)\n        else:\n            break\n    \n    return recommendations[:num_of_products]","26426691":"recommendations(3, 5, final_ratings_matrix)","190a86cf":"recommendations(1521, 5, final_ratings_matrix)","69591139":"from scipy.sparse.linalg import svds # for sparse matrices\n\n# Singular Value Decomposition\nU, s, Vt = svds(final_ratings_matrix, k = 50) # here k is the number of latent features\n\n# Construct diagonal array in SVD\nsigma = np.diag(s)","dd73c653":"U.shape #checking the shape of the U matrix","89342312":"sigma.shape #checking the shape of the sigma matrix","8196a522":"Vt.shape #checking the shape of the Vt matrix","250530ed":"all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n\n# Predicted ratings\npreds_df = pd.DataFrame(abs(all_user_predicted_ratings), columns = final_ratings_matrix.columns)\npreds_df.head()","1dd13b10":"# Recommend the items with the highest predicted ratings\n\ndef recommend_items(user_index, interactions_matrix, preds_df, num_recommendations):\n    \n    # Get and sort the user's ratings from the actual and predicted interaction matrix\n    sorted_user_ratings = interactions_matrix.loc[user_index].sort_values(ascending=False)\n    sorted_user_predictions = preds_df.loc[user_index].sort_values(ascending=False)\n\n    #Creating a dataframe with actual and predicted ratings columns\n    temp = pd.concat([sorted_user_ratings, sorted_user_predictions], axis=1)\n    temp.index.name = 'Recommended Products'\n    temp.columns = ['user_ratings', 'user_predictions']\n    \n    #Filtering the dataframe where actual ratings are 0 which implies that the user has not interacted with that product\n    temp = temp.loc[temp['user_ratings'] == 0]   \n    \n    #Recommending products with top predicted ratings\n    temp = temp.sort_values(by='user_predictions', ascending=False) #Sort the dataframe by user_predictions in descending order\n    print('\\nBelow are the recommended products for user(user_id = {}):\\n'.format(user_index))\n    print(temp['user_predictions'].head(num_recommendations))","f102779e":"#Enter 'user index' and 'num_recommendations' for the user\nrecommend_items(121, final_ratings_matrix, preds_df, 5)","c04476d7":"#Enter 'user_index' and 'num_recommendations' for the user #\nrecommend_items(465, final_ratings_matrix, preds_df, 5)","19a35464":"# Actual ratings given by the users\nfinal_ratings_matrix.head()","bc0a7e8c":"# Find average actual rating for each item\nfinal_ratings_matrix.mean()","b3d5f385":"# Predicted ratings \npreds_df.head()","b6f33490":"# Find average predicted rating for each item\npreds_df.mean()","b3b265b5":"#create a dataframe containing average actual ratings and avearge predicted ratings for each product\nrmse_df = pd.concat([final_ratings_matrix.mean(), preds_df.mean()], axis=1)\n\nrmse_df.columns = ['Avg_actual_ratings', 'Avg_predicted_ratings']\n\nrmse_df.head()","0a45377e":"#Calculate and print RMSE using the mean_square_error function\nRMSE = mean_squared_error(rmse_df['Avg_actual_ratings'], rmse_df['Avg_predicted_ratings'], squared=False)\nprint('\\nRMSE SVD Model = {} \\n'.format(RMSE))","16de88cc":"# Enter 'user_index' and 'num_recommendations' for the user #\nrecommend_items(100, final_ratings_matrix, preds_df, 10)","6f425376":"#### Recommending top 5 products with 100 minimum interactions based on popularity","90d3f0b4":"#### Data types","29076a19":"We have recommended the top 5 products by using popularity recommendation system. Now, let's build a recommendation system using collaborative filtering","ef7413a2":"## Observations\n\n- Around 75% of the ratings are positive (~55% is 5.0, and ~19% is 4.0). This shows that most users were happy with the products they rated.\n- ~12% of the ratings is 1.0 and only ~5% is 2.0. It also gives positive idea about the products. \n\n","6d472c1a":"### Recommendation","18116866":"We have applied two technique to recommend products to users. Now, let's build one more recommendation system using matrix factorization (SVD).","a75aa7ad":"#### Checking the number of unique users and items in the dataset","0bde2da7":"### Importing Libraries","59f596a5":"#### Recommend 5 products to user index 1521 based on similarity based collaborative filtering","03044028":"#### Finding out top 10 similar users to the user index 1521 and their similarity score","b07d683d":"**Here, user_id (index) is of the object data type. We will replace the user_id by numbers starting from 0 to 1539 (for all user ids) so that the index is of integer type and represents a user id in the same format**","b3998654":"#### Finding out top 10 similar users to the user index 3 and their similarity score","bf4dc347":"### Evaluate the model","07604973":"### Collaborative Filtering based Recommendation System (15 marks)","924651b8":"### Conclusion","396775c5":"#### Checking for missing values","a22ddf4c":"**We have seen above that the interaction matrix is highly sparse. SVD is best to apply on a large sparse matrix. Note that for sparse matrices, we can use the sparse.linalg.svds() function to perform the decomposition**\n\nAlso, we will use **k=50 latent features** to predict rating of products","977e3487":"#### Checking the rating distribution\n\nCheck the distribution of ratings and **provide observations** from the plot ","ae6dcb7f":"#### Recommend 5 products to user index 3 based on similarity based collaborative filtering","7a77b183":"#### Summary Statistics","4a62361c":"Now that we have explored and preprocessed the data, let's build the first recommendation system","5af0da2a":"- Even with the subset of users and products, the current number of ratings is just **0.17%** of the possible number of ratings. This implies that the data is **highly sparse**.\n- We will build recommendation systems to recommend products to users with which they have not interacted.","e9359101":"### Data preparation","dcea0109":"#### Checking the density of the rating matrix","35e540e5":"### Model based Collaborative Filtering: Singular Value Decomposition","b749c355":"Now, let's define a **function to get similar users** for a particular user","29c74eea":"- There are **42,01,696 users and 4,76,002 products** in the dataset","a6b5617e":"#### Recommending top 5 products with 50 minimum interactions based on popularity","bc17105e":"#### Users with most number of ratings","3116fb61":"**Recommending the 5 products to user index 465**","303e0c46":"### Exploratory Data Analysis","a75fd4ce":"**DISCLAIMER:** I have done this project as part of my enrollment in MIT's Applied Data Science Program. The notebook is templated and some credit goes to the program's faculty\/mentors.","fef05b87":"### Loading data","4952afe5":"We have the prediction of ratings but we need to create a **function to recommend products** to the users on the basis of predicted ratings for each product","42810826":"#### Evaluation of the Model based Collaborative Filtering (SVD)","6933a9b2":"**Conclusion: _______________**\n- Explored the data (sparse) and prepared it for recommendation system prediction task.\n- Implemented ranking recommendation system and build recommender for user who has given more that 50 rankings.\n- Build Collaborative Filtering based Recommendation System by finding similarities and utilizing it.\n- Improved the collaborative filtering based system by using Singular Value Decomposition, evaluated cost function and drew recommendations.","1ff81fb1":"#### Recommend top 10 products to the user id 100","ba2de4b2":"#### Shape of the data","9aa85cca":"Now, let's regenerate the original matrix using U, Sigma, and Vt matrices. The resulting matrix would be the predicted ratings for all users and products","05e925a5":"**Let's take a subset of the dataset (by only keeping the users who have given 50 or more ratings) to make the dataset less sparse and easy to work with.**","5b44fb99":"# Recommendation Systems: Amazon product reviews\n\nWe will work with the Amazon product reviews dataset for this project. The dataset contains ratings of different electronic products. It does not include information about the products or reviews to avoid bias while building the model. \n\n--------------\n### Context: \n--------------\n\nOnline E-commerce websites like Amazon, Flipkart uses different recommendation models to provide personalized suggestions to different users. Amazon currently uses item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n\n----------------\n### Objective:\n----------------\n\nBuild a recommendation system to recommend products to customers based on their previous ratings for other products.\n\n--------------\n### Dataset:\n--------------\n\nThe Amazon dataset contains the following attributes:\n\n- **userId:** Every user identified with a unique id\n- **productId:** Every product identified with a unique id\n- **Rating:** Rating of the corresponding product by the corresponding user\n- **timestamp:** Time of the rating (ignore this column for this exercise)","c8d402d4":"- The dataframe **df_final has users who have rated 50 or more items**\n- **We will use df_final to build recommendation systems**","d24be3b3":"**Recommending top 5 products to user id 121**","cc3ded00":"We have found similar users for a given user. Now, let's create **a function to recommend products** to the user using the ratings given by similar users.","bdafc4f7":"- The highest number of ratings by a user is 520 which is far from the actual number of products present in the data. We can build a recommendation system to recommend products to users which they have not interacted with.","e1f9bcb2":"### Rank Based Recommendation System"}}