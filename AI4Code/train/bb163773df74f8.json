{"cell_type":{"3dab20fc":"code","1f24a52e":"code","f082982b":"code","613f1eb3":"code","f97bcb81":"code","ef445ff6":"code","e44aa267":"code","f0772ffe":"code","736a7484":"code","dff29f19":"code","6e3ed1f6":"code","ecbc7395":"code","ec0da4b9":"code","6289b96f":"code","5fda09cd":"code","0017c35e":"code","29408755":"code","b837ae09":"code","dc6ecfb0":"code","741b5c24":"code","ee46b20d":"code","00e779a5":"code","dfb33533":"code","90a0798e":"code","da7cca75":"code","17e1c55c":"markdown","c5caf621":"markdown","295cec44":"markdown","1c1956fd":"markdown","3628de20":"markdown","ee629431":"markdown"},"source":{"3dab20fc":"import pandas as pd\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n","1f24a52e":"df = pd.read_csv('..\/input\/fake-news\/train.csv')","f082982b":"df.head()","613f1eb3":"df = df.dropna()","f97bcb81":"X = df.drop('label', axis = 1)\ny = df['label']","ef445ff6":"y.value_counts()","e44aa267":"X.shape","f0772ffe":"y.shape","736a7484":"#vocabulary size\nvoc_size = 5000","dff29f19":"messages = X.copy()\nmessages['title'][0]","6e3ed1f6":"messages.reset_index(inplace = True)","ecbc7395":"import nltk\nimport re\nfrom nltk.corpus import stopwords","ec0da4b9":"nltk.download('stopwords')","6289b96f":"from nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    #print(i)\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","5fda09cd":"corpus[0:5] #stemming and removed stopwords","0017c35e":"onehot_repr = [one_hot(words, voc_size) for words in corpus]\nonehot_repr","29408755":"#we are assigning input length to be 30\nsent_length = 30\nembedded_docs = pad_sequences(onehot_repr, padding = 'pre', maxlen = sent_length)\nprint(embedded_docs)","b837ae09":"#for first news text\nembedded_docs[0]","dc6ecfb0":"#giving vector features\n\nembedding_vector_features = 40\nmodel = Sequential()\nmodel.add(Embedding(voc_size, embedding_vector_features, input_length = sent_length))\nmodel.add(Dropout(0.4))\nmodel.add(Bidirectional(LSTM(100)))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nmodel.summary()","741b5c24":"import numpy as np\nX_final = np.array(embedded_docs)\ny_final = np.array(y)\nX_final.shape, y_final.shape","ee46b20d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.2, random_state = 42)","00e779a5":"model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs = 25, batch_size = 64)","dfb33533":"y_pred = model.predict_classes(X_test)","90a0798e":"y_pred","da7cca75":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","17e1c55c":"# The End","c5caf621":"# Performance Metrics Check","295cec44":"# Embedding Representation","1c1956fd":"Dataset Preprocessing","3628de20":"# Model Creation","ee629431":"# One Hot Represenation"}}