{"cell_type":{"3acca8f7":"code","561b031e":"code","3543a98c":"code","745a6358":"code","7d10682f":"code","ff2ec487":"code","4af2ffff":"code","a2a13a4b":"code","2151b2a1":"code","a5f41d88":"code","72690f3b":"code","39b98c73":"code","faeba7a5":"code","79fee2de":"code","d9f75bc9":"code","61eca934":"code","e4b0843c":"code","8640ba81":"code","8e5d2fae":"code","a4eb66bb":"code","3c63210d":"code","89e34a37":"code","ee581ee4":"code","46f8aae2":"code","87fdc8dd":"code","ffd92afa":"code","4bfb7259":"code","b239b662":"code","4dee95a7":"code","00c3b94f":"code","8a030053":"code","421a2cc2":"code","ac26da1c":"code","dcbfa880":"code","9cbd1e97":"code","16489a52":"code","bbb171d2":"code","1195e1cb":"markdown","0825f4aa":"markdown","e027031a":"markdown","e040b653":"markdown","33d15318":"markdown"},"source":{"3acca8f7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","561b031e":"dframe = pd.read_csv(\"..\/input\/ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)","3543a98c":"dframe","745a6358":"dframe.columns","7d10682f":"dataset=dframe.drop(['Unnamed: 0', 'lemma', 'next-lemma', 'next-next-lemma', 'next-next-pos',\n       'next-next-shape', 'next-next-word', 'next-pos', 'next-shape',\n       'next-word', 'prev-iob', 'prev-lemma', 'prev-pos',\n       'prev-prev-iob', 'prev-prev-lemma', 'prev-prev-pos', 'prev-prev-shape',\n       'prev-prev-word', 'prev-shape', 'prev-word',\"pos\"],axis=1)","ff2ec487":"dataset.info()","4af2ffff":"dataset.head()","a2a13a4b":"dataset=dataset.drop(['shape'],axis=1)","2151b2a1":"dataset.head()","a5f41d88":"class SentenceGetter(object):\n    \n    def __init__(self, dataset):\n        self.n_sent = 1\n        self.dataset = dataset\n        self.empty = False\n        agg_func = lambda s: [(w, t) for w,t in zip(s[\"word\"].values.tolist(),\n                                                        s[\"tag\"].values.tolist())]\n        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n        self.sentences = [s for s in self.grouped]\n    \n    def get_next(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None","72690f3b":"getter = SentenceGetter(dataset)","39b98c73":"sentences = getter.sentences","faeba7a5":"print(sentences[5])","79fee2de":"maxlen = max([len(s) for s in sentences])\nprint ('Maximum sequence length:', maxlen)","d9f75bc9":"# Check how long sentences are so that we can pad them\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use(\"ggplot\")","61eca934":"plt.hist([len(s) for s in sentences], bins=50)\nplt.show()","e4b0843c":"words = list(set(dataset[\"word\"].values))\nwords.append(\"ENDPAD\")","8640ba81":"n_words = len(words); n_words","8e5d2fae":"tags = list(set(dataset[\"tag\"].values))","a4eb66bb":"n_tags = len(tags); n_tags","3c63210d":"word2idx = {w: i for i, w in enumerate(words)}\ntag2idx = {t: i for i, t in enumerate(tags)}","89e34a37":"word2idx['Obama']","ee581ee4":"tag2idx[\"O\"]","46f8aae2":"from keras.preprocessing.sequence import pad_sequences\nX = [[word2idx[w[0]] for w in s] for s in sentences]","87fdc8dd":"X = pad_sequences(maxlen=140, sequences=X, padding=\"post\",value=n_words - 1)","ffd92afa":"y = [[tag2idx[w[1]] for w in s] for s in sentences]","4bfb7259":"y = pad_sequences(maxlen=140, sequences=y, padding=\"post\", value=tag2idx[\"O\"])","b239b662":"from keras.utils import to_categorical\ny = [to_categorical(i, num_classes=n_tags) for i in y]","4dee95a7":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","00c3b94f":"from keras.models import Model, Input\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional","8a030053":"input = Input(shape=(140,))\nmodel = Embedding(input_dim=n_words, output_dim=140, input_length=140)(input)\nmodel = Dropout(0.1)(model)\nmodel = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\nout = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  # softmax output layer","421a2cc2":"model = Model(input, out)","ac26da1c":"model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","dcbfa880":"history = model.fit(X_train, np.array(y_train), batch_size=32, epochs=1, validation_split=0.2, verbose=1)","9cbd1e97":"i = 0\np = model.predict(np.array([X_test[i]]))\np = np.argmax(p, axis=-1)\nprint(\"{:14} ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\nfor w,pred in zip(X_test[i],p[0]):\n    print(\"{:14}: {}\".format(words[w],tags[pred]))","16489a52":"p[0]","bbb171d2":"model.summary()","1195e1cb":"**Converting words to numbers and numbers to words**","0825f4aa":"**Data preprocessing**","e027031a":"\n**Importing the dataset for named entity recognition model**","e040b653":"* We want word, pos, sentence_idx and tag as an input ","33d15318":"> **Create list of list of tuples to differentiate each sentence from each other**"}}