{"cell_type":{"dcd0d382":"code","242c06d2":"code","79bdf187":"code","dba125f7":"code","0be99d73":"code","7639f1eb":"code","c8a341e2":"code","54e0728b":"code","1f12980d":"code","d008f474":"code","059b9943":"code","f2f37831":"code","cecf9847":"code","e439cec9":"code","c60ea4b0":"code","9ca49c03":"code","09858b10":"code","47cd0294":"code","23c2ccc5":"code","8c070ed4":"code","ce0b4afc":"markdown","ea8b47c0":"markdown","c2253f94":"markdown","4e2ce4af":"markdown","36358b1f":"markdown","1f29936a":"markdown","f4d60d9a":"markdown","d6d20fc8":"markdown","857f2cc6":"markdown","cd4c3119":"markdown","e522f66f":"markdown","2be70d85":"markdown"},"source":{"dcd0d382":"import os\nimport gc\nimport cv2\nimport math\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Concatenate, Dense, Conv2D, BatchNormalization, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom sklearn.model_selection import train_test_split, GroupShuffleSplit, GroupKFold\nfrom sklearn.metrics import make_scorer, accuracy_score, roc_auc_score, roc_curve\n\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE","242c06d2":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","79bdf187":"MIXED_PRECISION = False\nXLA_ACCELERATE = False\n\nif MIXED_PRECISION:\n    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n    mixed_precision.set_policy(policy)\n    print('Mixed precision enabled')\n\nif XLA_ACCELERATE:\n    tf.config.optimizer.set_jit(True)\n    print('Accelerated Linear Algebra enabled')","dba125f7":"def read_image(filepath):\n    return cv2.imread(os.path.join(data_dir, filepath)) \n\ndef resize_image(image, image_size):\n    return cv2.resize(image.copy(), image_size, interpolation = cv2.INTER_AREA)\n\ndef get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation \/ 180.\n    shear = math.pi * shear \/ 180.\n    \n    # ROTATION MATRIX\n    c1 = tf.math.cos(rotation)\n    s1 = tf.math.sin(rotation)\n    one = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    rotation_matrix = tf.reshape( tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3] )\n        \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)\n    shear_matrix = tf.reshape( tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3] )    \n    \n    # ZOOM MATRIX\n    zoom_matrix = tf.reshape( tf.concat([one\/height_zoom,zero,zero, zero,one\/width_zoom,zero, zero,zero,one],axis=0),[3,3] )\n    \n    # SHIFT MATRIX\n    shift_matrix = tf.reshape( tf.concat([one,zero,height_shift, zero,one,width_shift, zero,zero,one],axis=0),[3,3] )\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), K.dot(zoom_matrix, shift_matrix))\n\ndef transform(image,label):\n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    DIM = IMAGE_SIZE\n    XDIM = DIM%2 #fix for size 331\n    \n    rot = 15. * tf.random.normal([1],dtype='float32')\n    shr = 5. * tf.random.normal([1],dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1],dtype='float32')\/10.\n    w_zoom = 1.0 + tf.random.normal([1],dtype='float32')\/10.\n    h_shift = 16. * tf.random.normal([1],dtype='float32') \n    w_shift = 16. * tf.random.normal([1],dtype='float32') \n  \n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x = tf.repeat( tf.range(DIM\/\/2,-DIM\/\/2,-1), DIM )\n    y = tf.tile( tf.range(-DIM\/\/2,DIM\/\/2),[DIM] )\n    z = tf.ones([DIM*DIM],dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m,tf.cast(idx,dtype='float32'))\n    idx2 = K.cast(idx2,dtype='int32')\n    idx2 = K.clip(idx2,-DIM\/\/2+XDIM+1,DIM\/\/2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack( [DIM\/\/2-idx2[0,], DIM\/\/2-1+idx2[1,]] )\n    d = tf.gather_nd(image,tf.transpose(idx3))\n        \n    return tf.reshape(d,[DIM,DIM,3]),label\n\ndef get_training_dataset(dataset, do_aug = True):\n    if do_aug: \n        dataset = dataset.map(transform, num_parallel_calls = AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(dataset):\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset","0be99d73":"disease_types=['COVID', 'non-COVID']\ndata_dir = '..\/input\/sarscov2-ctscan-dataset\/'\ntrain_dir = os.path.join(data_dir)","7639f1eb":"train_data = []\nfor defects_id, sp in enumerate(disease_types):\n    for file in os.listdir(os.path.join(train_dir, sp)):\n        train_data.append(['{}\/{}'.format(sp, file), defects_id, sp])      \ntrain = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])","c8a341e2":"IMAGE_SIZE = 64\nX = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\nfor i, file in tqdm(enumerate(train['File'].values), total = len(train)):\n    image = read_image(file)\n    if image is not None:\n        X[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\nX \/= 255.\ny = train['DiseaseID'].values\nprint(X.shape)\nprint(y.shape)","54e0728b":"from sklearn.cluster import KMeans\n\nX0 = X[y == 0].reshape(len(X[y == 0]), -1)\nX1 = X[y == 1].reshape(len(X[y == 1]), -1)\n\nk = 50\nkmeans = KMeans(k)\ncluster0 = kmeans.fit_predict(X0)\ncluster1 = kmeans.fit_predict(X1)\ncluster1 += k\ncluster = np.concatenate([cluster0, cluster1])","1f12980d":"np.random.seed(42)\n\nrows = 5 \ncols = 5\n\nfig, ax = plt.subplots(rows, cols, figsize=(12, 12))\nfor i in range(rows):\n    clt = np.random.randint(0, 2 * k)\n    clt_idx = np.random.choice(np.where(cluster == clt)[0], cols, replace = True)\n    X_clt = X[clt_idx]\n    for j in range(cols):\n        ax[i, j].set_xticks([])\n        ax[i, j].set_yticks([])\n        ax[i, j].set_title([f'Cluster {clt}'])\n        ax[i, j].imshow(X_clt[j])","d008f474":"train_idx, val_idx = next(GroupShuffleSplit(test_size = 0.2, \n                                            n_splits = 2, \n                                            random_state = 42).split(X, groups = cluster))\n\nX_train, X_val, Y_train, Y_val = X[train_idx], X[val_idx], y[train_idx], y[val_idx]","059b9943":"BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n\ntrain_dataset = get_training_dataset(tf.data.Dataset.from_tensor_slices((X_train, Y_train)))\nval_dataset = get_validation_dataset(tf.data.Dataset.from_tensor_slices((X_val, Y_val)))","f2f37831":"# EfficientNet models are not applicable on Tensorflow 2.2.0 for TPU\nwith strategy.scope():\n\n    if not tpu:\n        net = tf.keras.applications.EfficientNetB0(include_top = False,\n                                                   weights = 'imagenet',\n                                                   pooling = None)\n    else:\n        net = tf.keras.applications.DenseNet121(include_top = False,\n                                                weights = 'imagenet',\n                                                pooling = None)\n\n    inp = Input(shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n    x = Conv2D(3, (3, 3), padding = 'same')(inp)\n    x = net(x)\n    x1 = GlobalAveragePooling2D()(x)\n    x2 = GlobalMaxPooling2D()(x)\n    x = Concatenate()([x1, x2])\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    out = Dense(1, activation = 'sigmoid')(x)\n\n    model = Model(inputs = inp, outputs = out)\n\n    metric = tf.keras.metrics.AUC(name = 'auc')\n    \n    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = [metric])\n\nmodel.summary()","cecf9847":"plot_model(model, \n           show_shapes = True, \n           show_layer_names = True, \n           rankdir = 'TB', \n           expand_nested = False, \n           dpi = 60)","e439cec9":"# Cosine Annealing Learning Rate from 'https:\/\/github.com\/4uiiurz1\/keras-cosine-annealing'\nclass CosineAnnealingScheduler(Callback):\n    \"\"\"Cosine annealing scheduler.\n    \"\"\"\n\n    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n        super(CosineAnnealingScheduler, self).__init__()\n        self.T_max = T_max\n        self.eta_max = eta_max\n        self.eta_min = eta_min\n        self.verbose = verbose\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, 'lr'):\n            raise ValueError('Optimizer must have a \"lr\" attribute.')\n        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch \/ self.T_max)) \/ 2\n        K.set_value(self.model.optimizer.lr, lr)\n        if self.verbose > 0:\n            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n                  'rate to %s.' % (epoch + 1, lr))\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)","c60ea4b0":"EPOCHS = 100\n\n# earlystopping = EarlyStopping(monitor = 'val_auc', min_delta = 0.001, patience = 10, verbose = 1, mode = 'max', restore_best_weights = True)\n# annealer = ReduceLROnPlateau(monitor = 'val_auc', factor = 0.2, patience = 5, verbose = 1, min_lr = 1e-4, mode = 'max')\n# checkpoint = ModelCheckpoint('model.h5', monitor = 'val_auc', verbose = 0, mode = 'max', save_best_only = True)\nannealer = CosineAnnealingScheduler(EPOCHS, 1e-3, 1e-5)\n\nhist = model.fit(train_dataset,\n                 steps_per_epoch = X_train.shape[0] \/\/ BATCH_SIZE,\n                 epochs = EPOCHS,\n                 verbose = 1,\n                 callbacks = [annealer],\n                 validation_data = val_dataset)","9ca49c03":"# AUC score is better than accuracy if the classes are imbalanced\nprint('Best Validation AUC:\\t', round(max(hist.history['val_auc']), 2))\n\nauc = hist.history['auc']\nval_auc = hist.history['val_auc']\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\n\nepochs = range(len(auc))\n\nplt.figure(figsize = (7, 5))\nplt.title('Training and Validation AUC')\nplt.plot(epochs, auc, 'r', label = 'Train')\nplt.plot(epochs, val_auc, 'b', label = 'Val')\nplt.xlabel('Epochs')\nplt.ylabel('AUC')\nplt.legend(loc = 0)\nplt.show()","09858b10":"pred_proba = model.predict(X_val)\nauc_score = roc_auc_score(Y_val, pred_proba)\nfpr, tpr, th = roc_curve(Y_val, pred_proba)\nprint('AUC Score:\\t', round(auc_score, 2))","47cd0294":"plt.figure(figsize = (7, 5))\nplt.title('ROC Curve')\nplt.plot(fpr, tpr, 'r')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive')\nplt.ylabel('True Positive')\nplt.legend(loc = 4)\nplt.show()","23c2ccc5":"def threshold_optimisation(y_true, y_pred, thresholds):\n    best_th = thresholds[0]\n    best_acc = accuracy_score(y_true, np.where(y_pred > thresholds[0], 1, 0))\n    for th in thresholds[1:]:\n        acc = accuracy_score(y_true, np.where(y_pred > th, 1, 0))\n        if acc > best_acc:\n            best_th = th\n            best_acc = acc\n    return best_acc, best_th","8c070ed4":"best_acc, best_th = threshold_optimisation(Y_val, pred_proba, th)\nprint('Best Accuracy:\\t', round(best_acc, 2))\nprint('Best Threshold:\\t', best_th)","ce0b4afc":"# Train Model","ea8b47c0":"# KMeans Clustering for patients\n\nThe raw data does not contain patient ID for each image though there are multiple images come from the same pateints. Before split the train and validation sets, we need to make sure that images from the same patients do not appear in both sets to prevent data leakage. Here I use KMeans to cluster the images have close patterns for Covid and non-Covid separately. It is worth noting that we do not need to know the exact number of patients since we only need to roughly cluster those images that have close patterns. That is, one cluster can contain multiple patients.","c2253f94":"# Create Training and Validation Sets","4e2ce4af":"# Plot AUC Score","36358b1f":"# Threshold Optimisation","1f29936a":"# Mixed Precision and\/or XLA","f4d60d9a":"# Plot Images from The Same Cluster\nIt can be seen that the images from the same cluster are generally very similar to each other. They are more likely to be from the same patient. \n\nSome clusters contain multiple types of images. This means they contain images from multiple patients. Since we only want the images from the same patient to be in the same cluster, one cluster containing multiple patients does not matter.","d6d20fc8":"# Read Dataset","857f2cc6":"# Covid-19 Diagnosis on TPU with Patients Clustering using KMeans \nThis notebook shows how to use TPU to train model on this Covid-19 dataset. The KMeans algorithm is used to cluster images that may come from the same patients in order to prevent data leakage during splitting training and validation sets. \n\nThe data augmentation methods are proposed by Chris in [Rotation Augmentation GPU\/TPU - [0.96+]][1].\n\n[1]: https:\/\/www.kaggle.com\/cdeotte\/rotation-augmentation-gpu-tpu-0-96","cd4c3119":"# Add Data Augmentation","e522f66f":"# Create Model","2be70d85":"# Configurations"}}