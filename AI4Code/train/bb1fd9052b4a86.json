{"cell_type":{"5679b24b":"code","28d4cd28":"code","33a9249a":"code","577fae9c":"code","acb49ccd":"code","efc4dbe3":"code","a8f426ee":"code","564299b7":"code","af30e533":"code","49a8351d":"code","6e518a4f":"code","5cd55141":"code","b3b114b5":"code","fa9e12ae":"code","e40c5041":"code","1d93535d":"code","05b063ba":"code","30940bb5":"markdown","c3daefd1":"markdown","86ea07f0":"markdown","95391dbb":"markdown","7c99d46b":"markdown","c2e0806f":"markdown"},"source":{"5679b24b":"import re\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image\nimport xml.etree.ElementTree as ET\nfrom tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Input, Flatten\nfrom tensorflow.keras import Model\nfrom sklearn.model_selection import train_test_split\nimport cv2","28d4cd28":"breed_list=os.listdir('..\/input\/stanford-dogs-dataset\/images\/Images\/')\nbreeds=[re.sub('n\\d+-','',breed) for breed in os.listdir('..\/input\/stanford-dogs-dataset\/images\/Images\/')]\nnbreed=len(breeds)","33a9249a":"pix=224\ntotal_training_image=2000\nimg_arr=np.empty((total_training_image,224,224,3),dtype=np.uint8)\nbbox=np.empty((total_training_image,4),dtype=np.uint8)\ncount=0\nfor breed in breed_list:\n    for file in os.listdir('..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/{}'.format(breed)):\n        img=Image.open('..\/input\/stanford-dogs-dataset\/images\/Images\/{}\/{}.jpg'.format(breed,file))\n        tree=ET.parse('..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/{}\/{}'.format(breed,file))\n        xmin=int(tree.getroot().findall('object')[0].find('bndbox').find('xmin').text)\n        xmax=int(tree.getroot().findall('object')[0].find('bndbox').find('xmax').text)\n        ymin=int(tree.getroot().findall('object')[0].find('bndbox').find('ymin').text)\n        ymax=int(tree.getroot().findall('object')[0].find('bndbox').find('ymax').text)\n        xppix, yppix=img.size\n        img.thumbnail((pix,pix))\n        xcpix, ycpix=img.size\n        new_img=Image.new(\"RGB\",size=(pix,pix))\n        x,y=(pix-xcpix)\/\/2,(pix-ycpix)\/\/2\n        new_img.paste(img,((x,y)))\n        x_nmin = int(x + (xmin*(xcpix\/xppix)))\n        x_nmax = int(x + (xmax*(xcpix\/xppix)))\n        y_nmin = int(y + (ymin*(ycpix\/yppix)))\n        y_nmax = int(y + (ymax*(ycpix\/yppix)))\n        bbox[count]=([x_nmin,x_nmax,y_nmin,y_nmax])\n        img_ar=np.array(new_img)\n        img_arr[count]=img_ar\n        count+=1\n        if count==total_training_image:\n            break\n    if count==total_training_image:\n        break","577fae9c":"# Lets check how it is\nnum=99\nimg1=np.copy(img_arr[num])\ncv2.rectangle(img1,(bbox[num][0],bbox[num][3]),(bbox[num][1],bbox[num][2]),(255,0,0),3)\nplt.imshow(img1)","acb49ccd":"# Divide in train and test - two parts\nx_train,x_test,y_train,y_test=train_test_split(img_arr,bbox,test_size=0.1)\nprint(x_train.shape,x_test.shape,y_train.shape,y_test.shape)","efc4dbe3":"num=8\nimg1=np.copy(x_train[num])\ncv2.rectangle(img1,(y_train[num][0],y_train[num][3]),(y_train[num][1],y_train[num][2]),(255,0,0),3)\nplt.imshow(img1)","a8f426ee":"inp=Input((224,224,3))\nmodel_vgg16=tf.keras.applications.vgg16.VGG16(include_top=False,input_tensor=inp)","564299b7":"output=model_vgg16.output\nx=Flatten()(output)\nx=Dense(4096,activation='relu')(x)\nx=Dropout(0.2)(x)\nx=Dense(1024,activation='relu')(x)\nx=Dropout(0.1)(x)\nout=Dense(4)(x)\nmodel16=Model(inp,out)\nmodel16.summary()","af30e533":"# Only train last four layers\nfor layer in model16.layers[:-4]:\n    layer.trainable=False","49a8351d":"model16.compile(optimizer='adam',loss='mean_absolute_error',metrics=['accuracy'])","6e518a4f":"model16.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=64,epochs=15)","5cd55141":"pred=model16.predict(np.reshape(x_test[0],(1,224,224,3)))\npred.astype('int')","b3b114b5":"y_pred=model16.predict(x_test[:10])\ny_pred=y_pred.astype('int')\nplt.figure(figsize=(20,20))\nfor num in range(1,10):\n    img1=np.copy(x_test[num])\n    #Original boundary boxes\n    cv2.rectangle(img1,(y_test[num][0],y_test[num][3]),(y_test[num][1],y_test[num][2]),(255,0,0),3)\n    #Predicted boundary boxes\n    cv2.rectangle(img1,(y_pred[num][0],y_pred[num][3]),(y_pred[num][1],y_pred[num][2]),(0,255,0),3)\n    ax=plt.subplot(3,5,num)\n    ax.imshow(img1)","fa9e12ae":"def download_predict(url,filename):\n    plt.figure(figsize=(30,20))\n    pix=224\n    os.system(\"curl -s {} -o {}\".format(url, filename))\n    img = Image.open(filename)\n    #xppix, yppix=img.size\n    img.thumbnail((pix,pix))\n    xcpix, ycpix=img.size\n    new_img=Image.new(\"RGB\",size=(pix,pix))\n    x,y=(pix-xcpix)\/\/2,(pix-ycpix)\/\/2\n    new_img.paste(img,((x,y)))\n    y_pred=model16.predict(np.reshape(np.array(new_img),(1,224,224,3)))\n    y_pred=y_pred.astype('int')\n    img1=np.copy(np.array(new_img))\n    cv2.rectangle(img1,(y_pred[0][0],y_pred[0][3]),(y_pred[0][1],y_pred[0][2]),(0,255,0),3)\n    ax=plt.subplot(3,5,num)\n    ax.imshow(img1)","e40c5041":"download_predict('https:\/\/cdn.pixabay.com\/photo\/2016\/07\/25\/00\/06\/corgi-1539598_1280.jpg','test1.jpg')","1d93535d":"download_predict(\"https:\/\/cdn.pixabay.com\/photo\/2016\/02\/19\/15\/46\/dog-1210559_1280.jpg\",\n                     \"test_4.jpg\")","05b063ba":"download_predict(\"https:\/\/cdn.pixabay.com\/photo\/2018\/08\/12\/02\/52\/belgian-mallinois-3599991_1280.jpg\",\n                     \"test_1.jpg\")","30940bb5":"## Download some images from Internet and test the model.","c3daefd1":"## Modify VGG16 model as per our requirement","86ea07f0":"## List out the dog breeds.","95391dbb":"## Check model performance on test data set.","7c99d46b":"## Download VGG16 Model","c2e0806f":"## Preprocess data to create image array as X and correspoding bounding boxes as Y"}}