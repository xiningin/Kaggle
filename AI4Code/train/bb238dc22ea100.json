{"cell_type":{"dc7105b4":"code","a08536a0":"code","c5a7ff54":"code","a40cc74d":"code","107f5e16":"code","5a49a3e0":"code","123f2ef4":"code","4d1c9feb":"code","da0043a1":"code","b7873ff9":"code","506f9437":"code","561dd800":"code","62719546":"code","77b1d5ee":"code","20b8b7e9":"code","5c1ca99a":"code","31960462":"code","0485ab8c":"code","13f01b52":"code","f72b406c":"code","ce6ff6f8":"code","cb8f2f0b":"code","727a223e":"code","d37c1eba":"code","2a1c4726":"code","a11ba783":"code","1d34ccb0":"code","485974f2":"code","ea291ec8":"code","7feda152":"code","38b216a4":"code","c0a65b6f":"code","5dbfa3b3":"code","dcf2f15c":"code","2a8bf07f":"code","9b962ce4":"code","0062738b":"code","77661609":"code","1ebefdc9":"code","0d767ea4":"markdown","d7688a89":"markdown","7689287c":"markdown","a391b7fb":"markdown","3c055e7c":"markdown","59477d98":"markdown","04a4e95f":"markdown","3fae9bc5":"markdown","76016ea1":"markdown","cb2049d1":"markdown","32d210e3":"markdown","cdadd275":"markdown"},"source":{"dc7105b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a08536a0":"import pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\nimport glob, os, time, random, re, collections\n\n%matplotlib inline\n\nfrom math import ceil, floor\n\nimport plotly.express as px\n\n'''  IGNORING WARNINGS  '''\nimport warnings\nwarnings.filterwarnings('ignore')\n\n'''  NOTEBOOK DISPLAY SETTINGS  '''\npd.options.display.max_rows = 1000    # None\npd.options.display.max_columns = None\n\npd.set_option('display.max_colwidth', -1)\npd.set_option('display.expand_frame_repr', False)\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:95% !important; }<\/style>\"))\n","c5a7ff54":"df = pd.read_csv(\"..\/input\/combined.csv\")\ndf.head()","a40cc74d":"df.shape","107f5e16":"df.info()","5a49a3e0":"pd.options.display.float_format = '{:.2f}'.format\ndf.describe()","123f2ef4":"l = []\nd = pd.DataFrame(columns = df.columns[:-1])\n\ndf2 = df[df['annotation'].isin([1, 2])]\n\n# Do it for only annotations labels - 1 and 2.\nfor  x,df_  in df2.groupby(['filename']):\n    print('Filename:', x)\n    display(df_.describe().loc['mean'])\n    l.append(df_.describe())\n    d.loc[x] = df_.describe().loc['mean'].to_list()\n    ","4d1c9feb":"import plotly.figure_factory as ff\nif 'time' in d.columns:    del d['time']\nfig = ff.create_annotated_heatmap(d.round(3).values.tolist(), x=d.columns.tolist(), y=d.index.tolist())\nfig.show()\n","da0043a1":"print(df[(df['filename']=='S03R03') & (df['annotation'].isin([1, 2]))]['acc_thigh_hor'].unique(),\n      df[(df['filename']=='S03R03') & (df['annotation'].isin([1, 2]))]['acc_thigh_ver'].unique(),\n      df[(df['filename']=='S03R03') & (df['annotation'].isin([1, 2]))]['acc_thigh_hl'].unique())\n","b7873ff9":"for  col  in df:\n    print(col, df[col].isna().sum())","506f9437":"for  col  in df:\n    print(col, df[col].nunique())","561dd800":"files  =  df['filename'].unique().tolist()[:8]    # Can diaplay only 8 plots at a time (TODO: fix it.)\n\nfor  file  in files:\n        data = df[df['filename']==file]\n\n        print('Filename:', file)\n        \n        fig = px.line(data, x='time', y='acc_ankel_hor')\n        fig.add_scatter(x=data['time'], y=data['annotation']*2000, mode='lines')\n\n        fig.show()","62719546":"files  =  df['filename'].unique().tolist()\ndf_ = df[df['filename'] == files[0]]\n\n\n# Adding 'i' column.\ndel df_['filename']\n\nl = df_['annotation'].tolist()\nl2 = [i  for i in range(1,len(l))  if l[i-1]!=l[i]] + [len(l)]\nl3 = [l2[0]] + [l2[i]-l2[i-1]  for i in range(1,len(l2))]\n\ndf_['i'] = sum([[i+1]*j  for i,j in enumerate(l3)], [])\n","77b1d5ee":"for  _,df__  in df_.groupby(['i']):\n    df__ = df__.reset_index(drop=True)\n    display(df__.index, df__.shape)","20b8b7e9":"ws = 64\nfor i in range(0, df__.shape[0]-ws, int(ws*0.75)):    display(df__.iloc[i:i+64])","5c1ca99a":"x = df__.iloc[i:i+64]\nx","31960462":"# Min, Max\nx['acc_ankel_hor'].min(), x['acc_ankel_hor'].max()","0485ab8c":"# Median\nx['acc_ankel_hor'].median()","13f01b52":"# Mean, ArmMean\nfrom scipy import stats\n\nx['acc_ankel_hor'].mean(), stats.hmean(x['acc_ankel_hor'])","f72b406c":"# Root Mean Square (RMS)\n(x['acc_ankel_hor']**2).mean()**0.5","ce6ff6f8":"# GeoMean\nfrom scipy.stats.mstats import gmean\ngmean(x['acc_ankel_hor'])\n","cb8f2f0b":"# Variance\nx['acc_ankel_hor'].var()","727a223e":"# Standard Deviation (STD)\nx['acc_ankel_hor'].std()","d37c1eba":"# Kurtosis\nx['acc_ankel_hor'].kurtosis()","2a1c4726":"# Skewness\nx['acc_ankel_hor'].skew()","a11ba783":"# Mode\nx['acc_ankel_hor'].mode()","1d34ccb0":"# TrimMean - Trimmed mean of the signal in the window\nfrom scipy import stats\nstats.tmean(x['acc_ankel_hor'])\n\n# It's the same as mean.","485974f2":"# Entropy - Measure of the distribution of frequency components\n# Source: https:\/\/stackoverflow.com\/a\/57400809\/8321339\n\nfrom scipy.stats import entropy\nfrom math import log, e\n\ndef pandas_entropy(column, base=None):\n    vc = pd.Series(column).value_counts(normalize=True, sort=False)\n    base = e if base is None else base\n    return -(vc * np.log(vc)\/np.log(base)).sum()\n\n\npandas_entropy(x['acc_ankel_hor'])","ea291ec8":"# Asymmetry coefficient - The first moment of the data in the window divided by STD over the window\nx['acc_ankel_hor'].iloc[0] \/ x['acc_ankel_hor'].std()","7feda152":"# Range - The difference between the largest and smallest values of the signal\nx['acc_ankel_hor'].max() - x['acc_ankel_hor'].min()","38b216a4":"# Zero Crossing Rate (ZCR) - Total number of times the signal changes from positive to negative or back, normalized by the window length\na = x['acc_ankel_hor'].values.tolist()\na = [i  for i in a  if i]    # removing 0s.\nnp.where(np.diff(np.sign( a )))[0].shape[0]  \/  ws\n","c0a65b6f":"# Mean Crossing Rate (MCR) - Total number of times the signal changes from below average to above average, normalized by the window length\na = (x['acc_ankel_hor'] - x['acc_ankel_hor'].mean()).values.tolist()\na = [i  for i in a  if i]    # removing 0s.\nnp.where(np.diff(np.sign( a )))[0].shape[0]  \/  ws","5dbfa3b3":"# Signal Magnitude Vector (SMV) - Sum of the euclidean norm over the three axis over the entire window normalized by the window length\n((x['acc_ankel_hor']**2).sum()**0.5 + (x['acc_ankel_ver']**2).sum()**0.5 + (x['acc_ankel_hl']**2).sum()**0.5) \/ ws","dcf2f15c":"# Normalized Signal Magnitude Area (SMA) - Acceleration magnitude summed over three axes normalized by the window length\n(x['acc_ankel_hor'].abs().sum() + x['acc_ankel_ver'].abs().sum() + x['acc_ankel_hl'].abs().sum()) \/ ws","2a8bf07f":"# Eigenvalues of Dominant Directions (EVA) - Eigenvalues of the covariance matrix of the acceleration data along x, y, and z axis\n","9b962ce4":"# Averaged Acceleration Energy (AAE) - Mean value of the energy over three acceleration axes\n(x['acc_ankel_hor'].mean() + x['acc_ankel_ver'].mean() + x['acc_ankel_hl'].mean()) \/ 3","0062738b":"df[]","77661609":"s1 = pd.Series([0.90010907, 0.13484424, 0.62036035])\ns2 = pd.Series([0.12528585, 0.26962463, 0.51111198])\ns1.cov()","1ebefdc9":"x.columns","0d767ea4":"Feature Functions","d7688a89":"### Imports","7689287c":"# 'acc_ankel_hor' for different 'annotation' values.","a391b7fb":"Sensor Features","3c055e7c":"### Unique Values","59477d98":"### Missing Values","04a4e95f":"### Looking at the distribution of Numerical columns.","3fae9bc5":"# Replicating the paper.","76016ea1":"No Missing Value","cb2049d1":"Each file comprises the data in a matrix format, with one line per sample, and one column per channel. The channels are as follows:  <br>\nTime of sample in millisecond  <br>\nAnkle (shank) acceleration - horizontal forward acceleration [mg]  <br>\nAnkle (shank) acceleration - vertical [mg]  <br>\nAnkle (shank) acceleration - horizontal lateral [mg]  <br>\nUpper leg (thigh) acceleration - horizontal forward acceleration [mg]  <br>\nUpper leg (thigh) acceleration - vertical [mg]  <br>\nUpper leg (thigh) acceleration - horizontal lateral [mg]  <br>\nTrunk acceleration - horizontal forward acceleration [mg]  <br>\nTrunk acceleration - vertical [mg]  <br>\nTrunk acceleration - horizontal lateral [mg]<br>\nAnnotation [0, 1, or 2]\n\n\nhor: front-back  <br>\nver: up-down  <br>\nhl:  left-right  <br>","32d210e3":"# Looking at how mean of different columns varies across different files.","cdadd275":"In File 'S03R03', when annotations are labeled 1 or 2, thigh reading are always 0 (maybe the accelerometer is not working).  <br>\nAlso, some files have no value annotated 2, i.e. are w\/o a FoG event - as written in the paper."}}