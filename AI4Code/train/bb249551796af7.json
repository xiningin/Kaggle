{"cell_type":{"0d0d307d":"code","09ba1f31":"code","d8e4ab44":"code","9eb2c2ad":"code","5ead890f":"code","4a3d9ae9":"code","fc87642f":"code","3c4b4a5d":"code","415afe88":"code","3adfe441":"code","560a4ade":"code","8e9f8b27":"code","f4f7387b":"code","c67fdbf8":"code","50aab8bd":"code","688cb63a":"code","cd1e0435":"code","8f9159b5":"code","6616ce6d":"code","127c58eb":"code","74e89ad0":"code","434f42b1":"code","6246fa13":"code","84e23014":"code","4a8a9ea2":"code","6ed9f708":"code","7d5cf410":"code","ff5dac47":"code","ecbd41ed":"code","5f0ff181":"code","e973c2bd":"code","e01eb4e0":"code","93a2a01d":"code","402a12f1":"markdown","cdf854eb":"markdown","57588cd5":"markdown","95bdca27":"markdown"},"source":{"0d0d307d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nINPUTDIR = \"\/kaggle\/input\/telecom-case-study\/\"","09ba1f31":"data = pd.read_csv(INPUTDIR + \"RawdatafileV0.0.csv\")\ndata.head()","d8e4ab44":"data.isnull().sum()","9eb2c2ad":"data.fillna('UNK', inplace = True) # Replace nulls with a placeholder","5ead890f":"## There are 90 rows which are duplicates, dropping them \nselCols = data.columns\n\ndata.drop_duplicates(subset = selCols[2:], inplace= True)\nprint(data.shape)","4a3d9ae9":"data.describe().T","fc87642f":"# Copying out the index variable & the target variable\ncustID = data['Cust_id']\ntarget = data['Plan_Chg_Flag']\n\n# Drop Var10 since it has the same value (POSTPAID)\n# Removing the target variable & index variable (cust_id)\n\ndata.drop(labels=['Cust_id', 'Plan_Chg_Flag', 'Var10'], inplace = True, axis =1) # Var10 is a constant (POSTPAID)\n","3c4b4a5d":"# Check the memory usage\ndata.info(memory_usage='deep')","415afe88":"# Copying all column names \n# Converting all columns to categories \n\nselCols = data.columns # Read the column names\n\ndata = data.apply(lambda x: x.astype('category')) # Convert all columns to category \n\n# Check the memory usage \ndata.info(memory_usage='deep')","3adfe441":"# Convert to one-hot-encoding \ndf_with_dummies = pd.get_dummies( data, columns = selCols)\ndf_with_dummies['Cust_id'] = custID\n\nprint(df_with_dummies.shape)\ndf_with_dummies.head()","560a4ade":"# just checking the size of the DF after converting to dummy values \ndf_with_dummies.info()","8e9f8b27":"# Importing the sklearn libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nfrom sklearn.metrics import classification_report\n\n# Converting the target variable via LabelEncoding\nlabel_encoder = LabelEncoder().fit(target)\ntargetLE = label_encoder.transform(target)","f4f7387b":"#Create train and validation set\ntrain_x, valid_x, train_y, valid_y = train_test_split(df_with_dummies, targetLE, test_size=0.3, shuffle=True, stratify=target, random_state= 93456)","c67fdbf8":"# Removing the cust_id before creating the model\ncustID_train = train_x['Cust_id']\ncustID_valid = valid_x['Cust_id']\n\ntrain_x.drop(labels= ['Cust_id'], axis= 1, inplace= True)\nvalid_x.drop(labels= ['Cust_id'], axis= 1, inplace= True)","50aab8bd":"#------------------------Build LightGBM Model-----------------------\nimport lightgbm as lgb\n\ntrain_data=lgb.Dataset(train_x,label=train_y)\nvalid_data=lgb.Dataset(valid_x,label=valid_y)\n\n#Select Hyper-Parameters\nparams = {'metric' : 'auc',\n          'boosting_type' : 'gbdt',\n          'colsample_bytree' : 0.9234,\n          'num_leaves' : 13,\n          'max_depth' : -1,\n          'n_estimators' : 200,\n          'min_child_samples': 399, \n          'min_child_weight': 0.1,\n          'reg_alpha': 2,\n          'reg_lambda': 5,\n          'subsample': 0.855,\n          'verbose' : -1,\n          'num_threads' : 4\n}","688cb63a":"#Train model on selected parameters and number of iterations\nlgbm = lgb.train(params,\n                 train_data,\n                 2500,\n                 valid_sets=valid_data,\n                 early_stopping_rounds= 30,\n                 verbose_eval= 10\n                 )","cd1e0435":"lgbm.params","8f9159b5":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Feature importance \nfeature_imp = pd.DataFrame(sorted(zip(lgbm.feature_importance(),train_x.columns), reverse=True), columns= ['Value', 'Feature'])\n\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances-01.png')","6616ce6d":"# If you are running it on your local systems then you will have to install the package using the following\n# pip install shap\nimport shap\n\n# Explain model predictions using shap library:\nlgbm.params['objective'] = 'binary'\nexplainer = shap.TreeExplainer(lgbm)\nshap_values = explainer.shap_values(valid_x)","127c58eb":"?shap.summary_plot","74e89ad0":"# Plot summary_plot\nshap.summary_plot(shap_values, valid_x)","434f42b1":"# Low values of Var27 has a high impact on the prediction values. When Var27_UNK =0, it is either a GOOD ore POOR value.   \n# For Plan_chg_flag = 1 customers have either a Var27 (Good\/Poor) value \n\nvalid_x.Var27_UNK.value_counts() ","6246fa13":"# load JS visualization code to notebook\nshap.initjs()","84e23014":"# When customer is employed in a Private organization, lower values of Var26_20 have a larger impact on the prediction \n# Var3_Private = 1\n# Var26_20 = 0\n\nshap.dependence_plot(\"Var3_Private\", shap_values[0], valid_x)","4a8a9ea2":"shap.dependence_plot(\"Var3_Private\", shap_values[1], valid_x)","6ed9f708":"# Var27_UNK = 0\n\nshap.dependence_plot(\"Var27_UNK\", shap_values[0], valid_x)","7d5cf410":"# Have a large impact onthe prediction (Plan_Chg_Flag = 1)\n# Var27_Good = 1 \n# Var3_Private = 1\n\nshap.dependence_plot(\"Var27_Good\", shap_values[1], valid_x)","ff5dac47":"# calculating the interaction values \n\nshap_interaction_values = shap.TreeExplainer(lgbm).shap_interaction_values(valid_x)\nshap.summary_plot(shap_interaction_values, valid_x)","ecbd41ed":"# Interaction between Var7_1200 and Var3_Private is not conclusive\n# When VAr7_1200 =0 , and Var3_Private = 1 , has a higher impact on the shap values & vice versa\n# When Var7_1200 =1, Var3_Private = 1 has a negative impact & vice versa\n\nshap.dependence_plot((\"Var7_1200\", \"Var3_Private\"), shap_interaction_values, valid_x)","5f0ff181":"# Var26_20 =1 & Var3_Private =1 has a positive impact\n\nshap.dependence_plot((\"Var26_20\", \"Var3_Private\"), shap_interaction_values, valid_x)","e973c2bd":"shap.dependence_plot((\"Var4_30\", \"Var3_Private\"), shap_interaction_values, valid_x)","e01eb4e0":"import numpy as np \n\nshap_sum = np.abs(shap_values[1]).mean(axis=0)\nimportance_df = pd.DataFrame([valid_x.columns.tolist(), shap_sum.tolist()]).T\nimportance_df.columns = ['column_name', 'shap_importance']\nimportance_df = importance_df.sort_values('shap_importance', ascending=False)\nimportance_df","93a2a01d":"import shap \nshap.__version__","402a12f1":"Impact of converting to categorical variables. Size of the dataframe:\n\nBefore: **2.5 MB**\n\nAfter converting: **166.6 Kb**","cdf854eb":"We will be creating a base model & then use SHAP to understand the interaction between variables","57588cd5":"Light GBM has a method which prints out the feature importance of each variable from the training dataset. We will first plot these values as a bar chart","95bdca27":"Only Var1 & Var2 has null values. Filling with a placeholder symbol 'UNK' "}}