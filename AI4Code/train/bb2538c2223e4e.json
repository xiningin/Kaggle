{"cell_type":{"1b9edc79":"code","ccf83849":"code","48d60026":"code","4d6515fc":"code","d606cd98":"code","0151b530":"code","eb0d1312":"code","f45a25ba":"code","0a57d55c":"code","3e1bdb42":"code","1acc4c98":"code","66295daa":"code","131a0554":"code","70d090b5":"code","e2de2432":"code","88cdae7f":"code","e9a8df2d":"code","dd73c60f":"code","da95e781":"code","bfb51320":"code","8989a4b9":"code","c2427154":"code","1ed5011c":"code","12950736":"code","4b4e20ac":"code","34ec91e3":"code","cdff5535":"code","e191f49f":"code","57820a41":"code","3bba9433":"code","110f5851":"code","1143adb8":"code","463e697f":"code","e01fc6bf":"code","83697136":"code","63008da8":"code","67b52009":"code","2a0172da":"code","3c486036":"code","f320a5f9":"code","ee0c6100":"code","74d42411":"code","d6e23e9b":"code","323bd021":"markdown","e622cdbf":"markdown","49e2b850":"markdown","090b3f85":"markdown"},"source":{"1b9edc79":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ccf83849":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt","48d60026":"plt.style.use('seaborn-darkgrid')\nsns.set_style(\"darkgrid\") ","4d6515fc":"df = pd.read_csv(\"\/kaggle\/input\/iris\/Iris.csv\")\ndf.head()","d606cd98":"df.shape","0151b530":"df.info()","eb0d1312":"df.describe()","f45a25ba":"corr = df.corr()\ncorr","0a57d55c":"plt.figure(figsize=(10, 8))\n\nsns.heatmap(corr,  cmap = 'plasma', annot= True);","3e1bdb42":"sns.countplot(df[\"Species\"])","1acc4c98":"plt.figure(figsize=(10, 10))\n\nsns.distplot(df[\"SepalLengthCm\"]);","66295daa":"plt.figure(figsize=(10, 10))\n\nsns.distplot(df[\"SepalWidthCm\"]);","131a0554":"plt.figure(figsize=(10, 10))\n\nsns.boxplot(data=df, x = 'Species', y = 'PetalWidthCm');","70d090b5":"plt.figure(figsize=(20, 10))\nsns.boxplot(x = \"PetalWidthCm\", y = \"SepalWidthCm\", data = df, hue = \"Species\")","e2de2432":"fig, axs = plt.subplots(nrows=3)\nfig = plt.gcf()\nfig.set_size_inches(13,9)\nplt.subplots_adjust(hspace=0.8)\n\nsns.boxplot(df['SepalLengthCm'], ax=axs[0]).set_title('Iris');\nsns.boxplot(df['PetalLengthCm'], ax=axs[1]).set_title('Iris');\nsns.boxplot(df['PetalWidthCm'],  ax=axs[2]).set_title('Iris');\nplt.show()","88cdae7f":"plt.figure(figsize=(10, 10))\nsns.scatterplot(x = \"SepalLengthCm\", y = \"PetalLengthCm\", data = df, hue = \"Species\")","e9a8df2d":"plt.figure(figsize=(10, 10))\nsns.scatterplot(x = \"PetalWidthCm\", y = \"SepalWidthCm\", data = df, hue = \"Species\")","dd73c60f":"sns.pairplot(df)","da95e781":"x = df[['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\ny = df[['Species']]","bfb51320":"x.shape","8989a4b9":"y.shape","c2427154":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler_train = scaler.fit_transform(x)\nscaler_test = scaler.fit_transform(x)","1ed5011c":"scaler_train.shape","12950736":"scaler_test.shape","4b4e20ac":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.7)","34ec91e3":"x_train.shape","cdff5535":"y_train.shape","e191f49f":"x_test.shape","57820a41":"y_test.shape","3bba9433":"from sklearn.naive_bayes import GaussianNB\n\nnaive = GaussianNB()\nnaive.fit(x_train, y_train)\nnaive_pred = naive.predict(x_test)\nnaive_scor = naive.score(x_train, y_train)\nnaive_pred","110f5851":"naive_scor","1143adb8":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p = 2)\nknn_fit= knn.fit(x_train, y_train)\nknn_pred = knn.predict(x_test)\nknn_scor = knn.score(x_train, y_train)\nknn_scor","463e697f":"knn_pred","e01fc6bf":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n\nde_tree = DecisionTreeClassifier()\nde_tree = de_tree.fit(x_train, y_train)\nde_score = de_tree.score(x_train, y_train)\nde_pred = de_tree.predict(x_test)\nde_pred","83697136":"de_score","63008da8":"plt.figure(figsize=(15, 13))\n\nclf = tree.plot_tree(de_tree)\nplt.title(\"Decision Tree\")\nplt.show();\nplt.savefig(\"Decision_Tree_1\")","67b52009":"from sklearn.metrics import accuracy_score\n\nacuracia_naive_bayes = accuracy_score(y_test, naive_pred)\nacuracia_KNN = accuracy_score(y_test, knn_pred)\nacuracia_tree = accuracy_score(y_test, de_pred)\n\nprint(\"Acuracia model 1 - Naive bayes: %.3f\" % (acuracia_naive_bayes * 100))\nprint(\"Acuracia model 2 - K-NN: %.3f\" % (acuracia_KNN * 100))\nprint(\"Acuracia model 3 - Decision tree: %.3f\" % (acuracia_tree * 100))","2a0172da":"from sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\n\nprint(\"Precision - Naive bayes = {}\".format(precision_score(y_test, naive_pred, average='macro')))\nprint(\"Recall - Naive bayes = {}\".format(recall_score(y_test, naive_pred, average='macro')))\nprint(\"Accuracy - Naive bayes = {}\".format(accuracy_score(y_test, naive_pred)))\nprint(\"F1 Score - Naive bayes = {}\".format(f1_score(y_test, naive_pred, average='macro')))\nprint(\"\\n\")\n\nprint(\"Precision - K-NN = {}\".format(precision_score(y_test, knn_pred, average='macro')))\nprint(\"Recall - K-NN = {}\".format(recall_score(y_test, knn_pred, average='macro')))\nprint(\"Accuracy - K-NN = {}\".format(accuracy_score(y_test, knn_pred)))\nprint(\"F1 Score - K-NN = {}\".format(f1_score(y_test, knn_pred, average='macro')))\nprint(\"\\n\")\n\nprint(\"Precision - Decision tree = {}\".format(precision_score(y_test, de_pred, average='macro')))\nprint(\"Recall - Decision tree = {}\".format(recall_score(y_test, de_pred, average='macro')))\nprint(\"Accuracy - Decision tree = {}\".format(accuracy_score(y_test, de_pred)))\nprint(\"F1 Score - Decision tree = {}\".format(f1_score(y_test, de_pred, average='macro')))\nprint(\"\\n\")","3c486036":"from sklearn.metrics import classification_report\n\nprint(\"Naive bayes\", classification_report(y_test, naive_pred))\nprint(\"\\n\")\nprint(\"K-NN\", classification_report(y_test, knn_pred))\nprint(\"\\n\")\nprint(\"Decision tree\", classification_report(y_test, de_pred))","f320a5f9":"from sklearn.metrics import confusion_matrix\n\nmatrix_confusion_1 =  confusion_matrix(y_test, naive_pred)\nmatrix_confusion_2 =  confusion_matrix(y_test, knn_pred)\nmatrix_confusion_3 =  confusion_matrix(y_test, de_pred)\n\ny_true  = ['Iris-setosa', 'Iris-virginica', \"Iris-versicolor\"]\n\nmatrix_confusion =  confusion_matrix(y_test, naive_pred)\n\ndf_cm = pd.DataFrame(matrix_confusion_1, columns=np.unique(y_true), index = np.unique(y_true))\n\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)\n\nplt.title(\"Model 1 - Matrix confusion - Naive bayes\")\nax = sns.heatmap(df_cm, cmap = 'plasma', annot=True,annot_kws={\"size\": 16}, fmt = \"\")","ee0c6100":"y_true  = ['Iris-setosa', 'Iris-virginica', \"Iris-versicolor\"]\n\nmatrix_confusion =  confusion_matrix(y_test, knn_pred)\n\ndf_cm = pd.DataFrame(matrix_confusion_2, columns=np.unique(y_true), index = np.unique(y_true))\n\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)\n\nplt.title(\"Model 2 - Matrix confusion - KNN\")\nsns.heatmap(df_cm, cmap = 'plasma', annot=True,annot_kws={\"size\": 16}, fmt = \"\")","74d42411":"y_true  = ['Iris-setosa', 'Iris-virginica', \"Iris-versicolor\"]\n\nmatrix_confusion =  confusion_matrix(y_test, de_pred)\n\ndf_cm = pd.DataFrame(matrix_confusion_3, columns=np.unique(y_true), index = np.unique(y_true))\n\ndf_cm.index.name = 'Actual'\ndf_cm.columns.name = 'Predicted'\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)\n\nplt.title(\"Model 3 - Matrix confusion - Tree\")\nsns.heatmap(df_cm, cmap = 'plasma', annot=True,annot_kws={\"size\": 16}, fmt = \"\")","d6e23e9b":"import pickle\n \nwith open('naive_pred.pkl', 'wb') as file:\n    pickle.dump(naive_pred, file)\n    \nwith open('knn_pred.pkl', 'wb') as file:\n    pickle.dump(knn_pred, file)\n    \nwith open('de_pred.pkl', 'wb') as file:\n    pickle.dump(de_pred, file)","323bd021":"#  Decision Tree","e622cdbf":"# K-NN","49e2b850":"# Exploratory analysis","090b3f85":"# Naive bayes"}}