{"cell_type":{"fd920027":"code","6df83d90":"code","c6116104":"code","d4b9abc9":"code","90ccb557":"code","19ea2ee4":"code","1e3c730f":"code","8d8dd4b5":"code","8e0399da":"markdown","409fb32f":"markdown","d6f699bf":"markdown","4cebeee3":"markdown","bfc52551":"markdown"},"source":{"fd920027":"import pandas as pd\nimport numpy as np\nimport pickle\nimport itertools\nimport gc\nimport math\nimport matplotlib.pyplot as plt\nimport dateutil.easter as easter\nfrom matplotlib.ticker import MaxNLocator, FormatStrFormatter, PercentFormatter\nfrom datetime import datetime, date, timedelta\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nimport scipy.stats","6df83d90":"NO_STORE = True\n\noriginal_train_df = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\noriginal_test_df = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\n\ngdp_df = pd.read_csv('..\/input\/gdp-20152019-finland-norway-and-sweden\/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')\ngdp_df.set_index('year', inplace=True)\n\ncci_df = pd.read_csv('..\/input\/oecd-consumer-confidence-index\/DP_LIVE_21012022073653464.csv')\ncci_df.set_index(['LOCATION', 'TIME'], inplace=True)\n\n# The dates are read as strings and must be converted\nfor df in [original_train_df, original_test_df]:\n    df['date'] = pd.to_datetime(df.date)\noriginal_train_df.head(6)","c6116104":"kaggle_rama_log_diff = \\\n    np.log(original_train_df[original_train_df.store == \"KaggleRama\"].num_sold.values).mean() - \\\n    np.log(original_train_df[original_train_df.store == \"KaggleMart\"].num_sold.values).mean()\nprint(f\"KaggleRama always sells {np.exp(kaggle_rama_log_diff):.5f} more than KaggleMart.\")","d4b9abc9":"def smape_loss(y_true, y_pred):\n    \"\"\"SMAPE Loss\"\"\"\n    return np.abs(y_true - y_pred) \/ (y_true + np.abs(y_pred)) * 200\n","90ccb557":"# Feature engineering\ndef engineer(df):\n    \"\"\"Return a new dataframe with the engineered features\"\"\"\n    \n    def get_gdp(row):\n        country = 'GDP_' + row.country\n        return gdp_df.loc[row.date.year, country]\n        \n    def get_cci(row):\n        country = row.country\n        time = f\"{row.date.year}-{row.date.month:02d}\"\n        # There is no monthly CCI data for Norway.\n        # We use the Finland data instead.\n        if country == 'Norway': country = 'Finland'\n        return cci_df.loc[country[:3].upper(), time].Value\n        \n    new_df = pd.DataFrame({'gdp': np.log(df.apply(get_gdp, axis=1)),\n                           'cci': df.apply(get_cci, axis=1),\n                           'wd4': df.date.dt.weekday == 4, # Friday\n                           'wd56': df.date.dt.weekday >= 5, # Saturday and Sunday\n                          })\n\n    # One-hot encoding (no need to encode the last categories)\n    for country in ['Finland', 'Norway']:\n        new_df[country] = df.country == country\n    new_df['KaggleRama'] = df.store == 'KaggleRama'\n    for product in ['Kaggle Mug', 'Kaggle Hat']:\n        new_df[product] = df['product'] == product\n        \n    # Seasonal variations (Fourier series)\n    # The three products have different seasonal patterns\n    dayofyear = df.date.dt.dayofyear\n    for k in range(1, 3):\n        sink = np.sin(dayofyear \/ 365 * 2 * math.pi * k)\n        cosk = np.cos(dayofyear \/ 365 * 2 * math.pi * k)\n        new_df[f'mug_sin{k}'] = sink * new_df['Kaggle Mug']\n        new_df[f'mug_cos{k}'] = cosk * new_df['Kaggle Mug']\n        new_df[f'hat_sin{k}'] = sink * new_df['Kaggle Hat']\n        new_df[f'hat_cos{k}'] = cosk * new_df['Kaggle Hat']\n\n    new_df.drop(columns=['mug_sin1'], inplace=True)\n    new_df.drop(columns=['mug_sin2'], inplace=True)\n\n    # Special days\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d)\n                                      for d in range(24, 32)}),\n                        pd.DataFrame({f\"n-dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(25, 32)}),\n                        pd.DataFrame({f\"f-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in range(1, 15)}),\n                        pd.DataFrame({f\"n-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                      for d in range(1, 10)}),\n                        pd.DataFrame({f\"s-jan{d}\":\n                                      (df.date.dt.month == 1) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in range(1, 15)})\n                       ],\n                       axis=1)\n    \n    # May and June\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) \n                                      for d in list(range(1, 10))}),\n#                         pd.DataFrame({f\"f-may{d}\":\n#                                       (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Finland') # end of the war\n#                                       for d in [9]}),\n                        pd.DataFrame({f\"may{d}\":\n                                      (df.date.dt.month == 5) & (df.date.dt.day == d) & (df.country == 'Norway')\n                                     for d in list(range(18, 26)) + [27]}),\n                        pd.DataFrame({f\"june{d}\":\n                                      (df.date.dt.month == 6) & (df.date.dt.day == d) & (df.country == 'Sweden')\n                                      for d in list(range(8, 15))}),\n                       ],\n                       axis=1)\n    \n    # Last Wednesday of June\n    wed_june_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-06-24')),\n                                         2016: pd.Timestamp(('2016-06-29')),\n                                         2017: pd.Timestamp(('2017-06-28')),\n                                         2018: pd.Timestamp(('2018-06-27')),\n                                         2019: pd.Timestamp(('2019-06-26'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"wed_june{d}\": \n                                      (df.date - wed_june_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(-4, 5))})],\n                       axis=1)\n    \n    # First Sunday of November\n    sun_nov_date = df.date.dt.year.map({2015: pd.Timestamp(('2015-11-1')),\n                                         2016: pd.Timestamp(('2016-11-6')),\n                                         2017: pd.Timestamp(('2017-11-5')),\n                                         2018: pd.Timestamp(('2018-11-4')),\n                                         2019: pd.Timestamp(('2019-11-3'))})\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"sun_nov{d}\": \n                                      (df.date - sun_nov_date == np.timedelta64(d, \"D\")) & (df.country != 'Norway')\n                                      for d in list(range(0, 9))})],\n                       axis=1)\n    \n    # First half of December (Independence Day of Finland, 6th of December)\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"dec{d}\":\n                                      (df.date.dt.month == 12) & (df.date.dt.day == d) & (df.country == 'Finland')\n                                      for d in list(range(6, 15))})],\n                       axis=1)\n\n    # Easter\n    easter_date = df.date.apply(lambda date: pd.Timestamp(easter.easter(date.year)))\n    new_df = pd.concat([new_df,\n                        pd.DataFrame({f\"easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\"))\n                                      for d in list(range(-2, 11)) + list(range(40, 48)) + list(range(51, 58))}),\n                        pd.DataFrame({f\"n_easter{d}\": \n                                      (df.date - easter_date == np.timedelta64(d, \"D\")) & (df.country == 'Norway')\n                                      for d in list(range(-3, 8)) + list(range(50, 61))})],\n                       axis=1)\n    \n    return new_df.astype(np.float32)\n\ntrain_df = engineer(original_train_df)\ntrain_df['date'] = original_train_df.date\ntrain_df['num_sold'] = original_train_df.num_sold.astype(np.float32)\ntest_df = engineer(original_test_df)\n\nfeatures = list(test_df.columns)\nif NO_STORE: features.remove('KaggleRama')\nprint(list(features))\n","19ea2ee4":"def predict(features, preproc, model, X):\n    y = (np.exp(model.predict(preproc.transform(X[features])))).reshape(-1, 1)\n    if NO_STORE: y[X.KaggleRama.values > 0] = y[X.KaggleRama.values > 0] * np.exp(kaggle_rama_log_diff)\n    return y\n\n\ndef fit_model(X_tr, X_va=None, score_list=[], mse_list=[], run=0, fold=0, oof=None, outliers=False, correction=1.0):\n    \"\"\"Scale the data, fit a model, plot the training history and validate the model\"\"\"\n    start_time = datetime.now()\n\n    # Preprocess the data\n    X_tr_f = X_tr[features]\n    preproc = make_pipeline(ColumnTransformer([('general', MinMaxScaler(), ['gdp', 'wd4', 'wd56', 'Finland', 'Norway',\n                                                                            'Kaggle Mug', 'Kaggle Hat',\n                                                                            'mug_cos1', 'hat_sin1', 'hat_cos1', 'mug_cos2',\n                                                                            'hat_sin2', 'hat_cos2']),\n                                               ('cci', MinMaxScaler((0, 0.06)), ['cci']),\n                                              ],\n                                              remainder=MinMaxScaler((0, 2.8))),\n                            StandardScaler(with_std=False))\n    #preproc = make_pipeline(MinMaxScaler(), StandardScaler(with_std=False))\n    #preproc = StandardScaler()\n    X_tr_f = preproc.fit_transform(X_tr_f)\n    y_tr = X_tr.num_sold.values.reshape(-1, 1).copy()\n    if NO_STORE: y_tr[X_tr.KaggleRama != 0] = y_tr[X_tr.KaggleRama != 0] \/ np.exp(kaggle_rama_log_diff)\n\n    # Train the model\n    model = Ridge(alpha=0.2, tol=0.00001, max_iter=10000)\n    model.fit(X_tr_f, np.log(y_tr).ravel())\n\n    if X_va is not None:\n        # Preprocess the validation data\n        y_va = X_va.num_sold.values.reshape(-1, 1)\n\n        # Inference for validation\n        y_va_pred = predict(features, preproc, model, X_va)\n        oof.update(pd.Series(y_va_pred.ravel(), index=X_va.index))\n        \n        # Evaluation: Execution time and SMAPE\n        smape_before_correction = np.mean(smape_loss(y_va, y_va_pred))\n        y_va_pred *= correction\n        smape = np.mean(smape_loss(y_va, y_va_pred))\n        mse = mean_squared_error(np.log(y_va), np.log(y_va_pred))\n        print(f\"Fold {run}.{fold} | {str(datetime.now() - start_time)[-12:-7]}\"\n              f\" | SMAPE: {smape:.5f}   (before correction: {smape_before_correction:.5f})\"\n              f\" | MSE: {mse:.5f}\")\n        score_list.append(smape)\n        mse_list.append(mse)\n        \n    return preproc, model\n","1e3c730f":"RUNS = 1 # should be 1\n\ndef validate(train_df, correction_factor=1.0):\n    # Make the results reproducible\n    np.random.seed(202100)\n\n    total_start_time = datetime.now()\n    oof = pd.Series(0.0, index=train_df.index)\n    score_list, mse_list = [], []\n    for run in range(RUNS):\n        kf = GroupKFold(n_splits=4)\n        for fold, (train_idx, val_idx) in enumerate(kf.split(train_df, groups=train_df.date.dt.year)):\n            X_tr = train_df.iloc[train_idx]\n            X_va = train_df.iloc[val_idx]\n            print(f\"Fold {run}.{fold} validating on {train_df.iloc[val_idx].iloc[0].date.year}\")\n            preproc, model = fit_model(X_tr, X_va, score_list, mse_list, run=run, fold=fold, oof=oof, correction=correction_factor)\n\n    print(f\"Average SMAPE: {sum(score_list) \/ len(score_list):.5f} | MSE: {sum(mse_list) \/ len(mse_list):.7f}   \"\n          f\"| Y: {smape_loss(train_df.num_sold, oof).mean():.5f}   \"\n          f\"| Q1: {smape_loss(train_df.num_sold, oof)[train_df.date.dt.month <= 3].mean():.5f}   \"\n          f\"| Q234: {smape_loss(train_df.num_sold, oof)[train_df.date.dt.month > 3].mean():.5f}\")\n    with open('oof.pickle', 'wb') as handle: pickle.dump(oof, handle)\n        \nvalidate(train_df)\n","8d8dd4b5":"# Fit the model on the complete training data\npreproc, model = fit_model(train_df, None)\n\n# Inference for test\ntest_pred_list = []\ntest_pred_list.append(predict(features, preproc, model, test_df) * 1.003) # magic scaling factor\n\n# Prepare the submission file\nsub = original_test_df[['row_id']].copy()\nsub['num_sold'] = sum(test_pred_list) \/ len(test_pred_list)\n\n# Plot the distribution of the test predictions\nplt.figure(figsize=(16,3))\nplt.hist(train_df['num_sold'], bins=np.linspace(0, 3000, 201),\n         density=True, label='Training')\nplt.hist(sub['num_sold'], bins=np.linspace(0, 3000, 201),\n         density=True, rwidth=0.5, label='Test predictions')\nplt.xlabel('num_sold')\nplt.ylabel('Frequency')\nplt.legend()\nplt.show()\n\n# Create a rounded submission file\nsub_rounded = sub.copy()\nsub_rounded['num_sold'] = sub_rounded['num_sold'].round()\nsub_rounded.to_csv('submission_linear_model_rounded.csv', index=False)\nsub_rounded","8e0399da":"# Advanced linear model for the January TPS with customer confidence index\n\nThis notebook contains some major changes compared to my earlier [linear model](https:\/\/www.kaggle.com\/ambrosm\/tpsjan22-03-linear-model):\n- Feature engineering\n  - more external data: monthly consumer confidence index\n  - different selection of Fourier series; no Fourier series for stickers\n  - Small changes in length of holidays\n  - Different Easter effect for Norway than for other countries\n- Cross-validation shows results for Q1 and the other three quarters separately.\n- Regularization has been tuned with three MinMaxScalers\n- KaggleRama factor has been taken out of the regression (direct computation is more accurate)\n","409fb32f":"# Inference and submission\n","d6f699bf":"# Feature engineering\n","4cebeee3":"Before starting, we calculate the ratio between KaggleRama and KaggleMart sales. This ratio is always the same and does not depend on any other features. A direct calculation is more accurate than linear regression:","bfc52551":"# Validation\n\nWe train on a GroupKFold with the years as groups. For the validation, we separate the SMAPE for the first quarter from the rest of the year. As the private leaderboard is computed on the predictions for April through December, SMAPE for these nine months is more important than SMAPE for the first quarter.\n\nThe data is scaled using three separate MinMaxScalers. Ridge regression will penalize high weights on the customer confidence index more than on other features."}}