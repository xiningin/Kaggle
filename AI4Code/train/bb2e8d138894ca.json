{"cell_type":{"b35e2c76":"code","63034451":"code","06383d8b":"code","63688bb2":"code","ef1f8cc0":"code","0167b041":"code","65619406":"code","310f1582":"code","3e034e7b":"code","a74c3937":"code","58cc7e0f":"code","949fc0aa":"code","c3a82865":"code","bf7ddf52":"markdown","85b12f55":"markdown","4ea5e5fe":"markdown","5df25fc0":"markdown","c3e3210a":"markdown","5acbd9ee":"markdown","17c135a0":"markdown","3af54fdb":"markdown","87fe46cd":"markdown","d74eb623":"markdown","278b69db":"markdown","4d58f0b1":"markdown","9ca92735":"markdown"},"source":{"b35e2c76":"import numpy as np\nimport tensorflow.keras.optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport cv2\nimport random\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.layers import Dense,Dropout,Flatten\nfrom tensorflow.keras.models import Model,load_model\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\nimport keras\nfrom tqdm import tqdm\nimport glob \n","63034451":"file_path = '..\/input\/sports-image-dataset\/data'\n\ndef data_pre_processing(file_path,valid_split = 0.25,input_size = (224, 224),image_color = 'rgb',batch_size = 32,\n                        shuffle=True ):\n\n    train_gen=ImageDataGenerator(rescale=1.\/255,validation_split=valid_split,zoom_range=0.5,horizontal_flip=True,rotation_range=40,vertical_flip=0.5,width_shift_range=0.3,height_shift_range=0.2,brightness_range=[0.2,1.0],fill_mode='nearest')\n\n    validation_gen=ImageDataGenerator(rescale=1.\/255,validation_split=valid_split)\n\n    train_data=train_gen.flow_from_directory(directory=file_path,target_size=input_size,color_mode=image_color,\n                                             batch_size=batch_size,shuffle=shuffle,subset='training')\n    test_data=validation_gen.flow_from_directory(directory=file_path,target_size=input_size,color_mode=image_color,\n                                             batch_size=batch_size,shuffle=shuffle,subset='validation')\n\n    return train_data,test_data\n\ntrain,validation=data_pre_processing(file_path)","06383d8b":"def observing_the_data(train,validation):\n    labels=dict()\n    for label_name,label_num in validation.class_indices.items():\n        labels[label_num]=label_name\n    plt.figure(figsize=(10,10))\n    for i in tqdm(range(9)):\n        plt.subplot(3,3,i+1)\n        for x_batch,y_batch in validation:\n            image=x_batch[0]\n            argmax=np.argmax(y_batch)\n            plt.tight_layout(h_pad=5)\n            plt.title(labels[argmax])\n            plt.xticks(())\n            plt.yticks(())\n            plt.imshow(image)\n            break\n    return plt.show()\n\ndef labels_distribution_bar(train):\n    values_counter=Counter(train.classes)\n    sorted(values_counter.items())\n    plt.bar(train.class_indices.keys(), values_counter.values(), color=(1, 0.1, 0.1, 0.6))\n    plt.xticks(rotation=90)\n    return plt.show()\n\n\nobserving_the_data(train,validation)\nlabels_distribution_bar(train)","63688bb2":"def model(new_model=VGG16(),layers_num=11,trainable=False):\n    for layer in new_model.layers[:layers_num]:\n        layer.trainable=trainable\n    for i, layer in enumerate(new_model.layers):\n      print(i, layer.name, layer.trainable)\n    return new_model\n\n","ef1f8cc0":"def configure_model(model_name):\n  flatten=model_name.layers[-4]\n  predictions = model_name.layers[-1]\n  dropout1 = Dropout(0.3,name='Dropout1')\n  dropout2 = Dropout(0.5,name='Dropout2')\n  x=Dense(units=4096,activation='relu',name='FC1',kernel_regularizer='l2')(flatten.output)\n  x = dropout1(x)\n  x=Dense(units=4096,activation='relu',name='FC2',kernel_regularizer='l2')(x)\n  x = dropout2(x)\n  predictors = Dense(22,activation='softmax',name='Predictions')(x)\n  final_model = Model(inputs=model_name.input, outputs=predictors)\n  print(final_model.summary())\n  return final_model\n\nvgg_model=model()\nvgg_model=configure_model(vgg_model)","0167b041":"#************Hyper-Parameters*************\n\nbatch_size=32\nepochs=100\nopt=tensorflow.keras.optimizers.Adam(learning_rate=0.00003)\nloss=tensorflow.keras.losses.categorical_crossentropy\nvalidation_steps=validation.samples\/batch_size\ntrain_steps=train.samples\/batch_size","65619406":"def callbacks():\n    modelcheck=ModelCheckpoint('vgg16.h5',monitor='val_accuracy',save_best_only=True,period=1)\n    earlystop=EarlyStopping(monitor='val_loss',patience=10)\n    return modelcheck,earlystop","310f1582":"counter = Counter(train.classes)                          \nmax_val = float(max(counter.values()))       \nclass_weights1 = {class_id : max_val\/num_images for class_id, num_images in counter.items()}   ","3e034e7b":"vgg_model.compile(optimizer=opt,loss=tensorflow.keras.losses.categorical_crossentropy,\n                  metrics=['accuracy'])\nhistory=vgg_model.fit_generator(generator=train,steps_per_epoch=train_steps,epochs=epochs,verbose=1,callbacks=callbacks(),validation_data=validation,validation_steps=validation_steps,validation_freq=1,class_weight=class_weights1)\n\n","a74c3937":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title(\"model loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend([\"loss\",\"Validation Loss\"])\nplt.show()","58cc7e0f":"plt.plot(history.history[\"accuracy\"])\nplt.plot(history.history['val_accuracy'])\nplt.title(\"model accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend([\"Accuracy\",\"Validation Accuracy\"])\nplt.show()","949fc0aa":"vgg_model.save('vgg16.h5')","c3a82865":"path='..\/input\/d\/omreekapon\/dataset'\n\nlabels=dict()\nfor label_name,label_num in validation.class_indices.items():\n      labels[label_num]=label_name\npredictions=[]\n\ndata_path = os.path.join(path,'*g') \nfiles = glob.glob(data_path) \ndata = [] \nfor f1 in files: \n    img = cv2.imread(f1) \n    data.append(img)\nresized_images=[]\n   \nfor image in data:\n     image=cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n     image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n     resized_images.append(image)\n     yhat = vgg_model.predict(image)\n     predictions.append(labels[np.argmax(yhat)])\nresized_images=np.array(resized_images)\n\nplt.figure(figsize=(10,10))\nfor i in tqdm(range(12)):\n    plt.subplot(4,3,i+1)\n    plt.tight_layout(h_pad=5)\n    img=resized_images[i]\n    img = np.squeeze(img)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.title(predictions[i])\n    plt.xticks(())\n    plt.yticks(())\n    plt.imshow(img)\nplt.show()\n\n\n\n\n\n\n","bf7ddf52":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Exploring the data<\/b>\n\n<p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">Here I'm going to display images from random categories with their labels. Additionally, the distribution of the labels will be shown to examine if the data is balanced or not.<\/p>","85b12f55":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:350%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Conclusions<\/b><dic>\n    \n<p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">The model succeeded in predicting most of the images with high accuracy. The main challenge is that many sports categories look pretty the same: tennis, table tennis, and badminton have very similar features. The same with hockey and ice hockey, MotoGP and formula which share common features, and also WWE and wrestling. Yet the model did a pretty good job on a new dataset but failed in predicting WWE for example. The confusion may occur since WWE involves also boxing. Additionally, the fact that the model should distinguish between 22 categories makes it a challenging task. To conclude, to get even higher performance more data needs to be added to each category, or trying even more augmentations. \n<\/p>","4ea5e5fe":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Predictions<\/b>\n <p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">Now let's test the model with new data.","5df25fc0":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Setting the Callbacks<\/b>\n\n<p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">Modelcheck point was used to save the best parameters while the Earlystopping callback was used to prevent from the model to be trained if there is no additional change.<\/p>","c3e3210a":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b> Introduction<\/b><\/div>\n\n<p style=\"padding: 10px;color:black;font-size:130%;font-family: Times New Roman, Times, serif;\"> Since 2014 <b>VGG16<\/b> has been widely used for image classification. In this project i used VGG as the basic model with <b>transfer learning<\/b>. Transfer learning  is a process where a model was already trained on a specific problem and can be used for solving other problems as well. The reason is that different tasks can be solved with similar features. This can be done by two approaches: The first approach is to freeze the pre-trained layers and train just the fully-connected layers, while the second approach is called <b>fine-tuning<\/b> when you can unfreeze some of the pre-trained layers and train them very gently with a very low learning rate. This is the approach I used in my project. I'll be happy for any feedback or comment and feel free to send me any questions about the model! thanks in advance&#128512;<\/p>\n","5acbd9ee":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Fine-Tuning<\/b> \n\n<p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">In order to improve the model performance and prevent overfitting, I'm going to unfreeze the last two blocks and train them on my dataset.<\/p>","17c135a0":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Training The Data<\/b>","3af54fdb":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Loading Data & Data Preprocessing<\/b>\n\n<p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">In this section, I'll upload different sports images from 22 categories. This part will also include splitting the data to train and validation 75% and 25% respectively.\nOther than rescaling the images, data augmentation was done as well to prevent overfitting and improve the model performance.\nI trained the model using RGB as the color format since it may be crucial when working with sports image classification(e.g., basketball has orange color while a tennis ball is green).<\/p>","87fe46cd":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Data Insights<\/b>\n\n<p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">It can be shown that there is imbalanced data since different categories have a different number of images(e.g., badminton has ~700 while basketball has ~350, 50% less).\nWhen dealing with sports images it may effect on the predictions since few categories are very similar. For example, tennis, table tennis, and badminton have very similar features as well for WWE and wrestling. I will need to address for it later.<\/p>","d74eb623":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Accuracy\/Loss Plot<\/b>\n<p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">It's time to examine the model performance, hence I'll plot the loss and accuracy of both train and validation data. I expect to see similar drop in both train and validation data, as well for high accuracy.<\/p>","278b69db":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Balance The Data<\/b>\n\n<p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">Since different categories have a different amount of images, here I weighted their amount, hence the model should have better performances.<\/p>","4d58f0b1":" <div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           font-size:300%;\n           font-family: Times New Roman, Times, serif;\n    letter-spacing:0.5px\"><b>Configuring The Model<\/b>\n\n\n<p style=\"padding: 10px;color:black;font-size:40%;font-family: Times New Roman, Times, serif;\">I added two dropout layers to the last block to keep the model from overfitting. Regularization was used for the same reason. While the original VGG Model was used for classifying 1000 categories, in this project only 22 should be classified, therefor I changed the last layers unit from 1000 to 22.<\/p>","9ca92735":"<span style=\"font-family: Times New Roman, Times, serif;;\"> <span style=\"color:black;\"><span style=\"font-size:42px;\">  **Import Libraries**"}}