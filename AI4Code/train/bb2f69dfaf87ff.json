{"cell_type":{"58691f04":"code","aee47b91":"code","f24e96fe":"code","60f65834":"code","98b728f3":"code","2419aef4":"code","634beb83":"code","0fca5209":"code","7727ee71":"code","251d6f77":"code","f76b50f2":"code","349f2d4e":"code","104d29ea":"code","809a5951":"code","bc0b354d":"code","7ae45d3b":"code","f3ef2c1b":"code","face50a8":"code","5e5b9468":"code","86b0582c":"code","57ae9100":"code","9c19a794":"code","14be7853":"code","e3c1c3ea":"code","591d2e31":"code","de058a17":"code","25cf43e1":"code","70fceb92":"code","165215f4":"code","952e40c6":"code","5a57e308":"code","ff15cec8":"code","638fc359":"code","b7742b01":"code","0b5daac5":"code","3560bed2":"code","edd42267":"code","b580b362":"code","d7dd7583":"code","997a2e5f":"markdown","6a118b02":"markdown","19874b50":"markdown","1070f393":"markdown","81c221fa":"markdown","8567f461":"markdown","2c2dfa4f":"markdown","58beb41b":"markdown","fd281e74":"markdown","7e289fc2":"markdown","d44e4565":"markdown","3019e3a9":"markdown","bb0e9dbd":"markdown","a4db4e01":"markdown","f845d4b7":"markdown","ec9dc1d6":"markdown","19a0013b":"markdown","708248b6":"markdown","803cf6a0":"markdown","f1da446f":"markdown","0f7f73c9":"markdown","1fab4a4b":"markdown","a9e3ebbf":"markdown","4c5ef0ee":"markdown","1d8b0d80":"markdown"},"source":{"58691f04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aee47b91":"!pip install chart_studio","f24e96fe":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport chart_studio.plotly as py\nimport cufflinks as cf\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, plot, init_notebook_mode, iplot\ninit_notebook_mode(connected=True)# initiate notebook for offline plot\ncf.go_offline()\n\nfrom sklearn import preprocessing\nfrom sklearn import pipeline\nfrom sklearn import model_selection","60f65834":"fruits_df = pd.read_table(\"\/kaggle\/input\/fruits-with-colors-dataset\/fruit_data_with_colors.txt\")\nfruits_df.head()","98b728f3":"fruits_df.shape","2419aef4":"fruits_df.isna().sum()","634beb83":"trace = go.Scatter(x=fruits_df[\"mass\"], y=fruits_df[\"height\"]\/fruits_df[\"width\"],\n                   mode=\"markers\",\n                   hovertext=fruits_df[\"fruit_name\"],\n                   marker=dict(\n                       size=12,\n                        color=fruits_df[\"fruit_label\"],\n              ))\nfig = go.Figure(data=[trace])\n\nfig.update_layout(title=\"Fruits Classification based on Dimensions\")\nfig.update_xaxes(title=\"Mass\")\nfig.update_yaxes(title=\"Height\/Width\")\n\niplot(fig)","0fca5209":"#lets try to visualize the distribution or outlier if any for all features\nfrom matplotlib import style\nstyle.use(\"fivethirtyeight\")\nfruits_df.drop([\"fruit_label\"], axis=1).plot(kind=\"box\", layout=(2,2), figsize=(8,10),\n                                             subplots=True, sharey=False)\nplt.show()","7727ee71":"fruits_df[\"fruit_name\"].value_counts()","251d6f77":"from pandas.plotting import scatter_matrix\natts = [\"mass\", \"width\", \"height\", \"color_score\"]\nscatter_matrix(fruits_df[atts], figsize=(12,12))","f76b50f2":"fruits_corr = fruits_df.corr()\nfruits_corr[\"mass\"]","349f2d4e":"fruits_corr = fruits_df.corr()\nfruits_corr[\"fruit_label\"]","104d29ea":"fruits_df.describe()","809a5951":"minmax_scaler = preprocessing.MinMaxScaler()","bc0b354d":"fruits_minmax_scaled = minmax_scaler.fit_transform(\n    fruits_df.drop([\"fruit_label\",\"fruit_name\",\"fruit_subtype\"], axis=1)\n)","7ae45d3b":"fruits_df_scaled = pd.DataFrame(fruits_minmax_scaled, columns=fruits_df.columns[3:])\nfruits_df_scaled.head()","f3ef2c1b":"fruits_df_scaled.describe()","face50a8":"X_train, X_test, y_train, y_test = model_selection.train_test_split(fruits_df_scaled,\n                                                                   fruits_df[\"fruit_label\"],\n                                                                   test_size=0.2)","5e5b9468":"print(X_train.shape)\nprint(X_test.shape)","86b0582c":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression","57ae9100":"logis_reg = LogisticRegression()\nlogis_reg.fit(X_train, y_train)\naccuracy = logis_reg.score(X_test, y_test)\nprint(accuracy)","9c19a794":"clf = KNeighborsClassifier()\nclf.fit(X_train, y_train)\naccuracy = clf.score(X_test, y_test)\nprint(accuracy)","14be7853":"#testing accuracy of model with n_neighbor values from 1 to 20\nerror_rate = []\nfor i in range(1,20):\n clf = KNeighborsClassifier(n_neighbors=i)\n clf.fit(X_train,y_train)\n pred_i = clf.predict(X_test)\n error_rate.append(np.mean(pred_i != y_test))","e3c1c3ea":"print(error_rate)","591d2e31":"plt.plot(range(1,20),error_rate)\nplt.title(\"Error Rate vs. K Value\")\nplt.xlabel(\"K\")\nplt.ylabel(\"Error Rate\")\nplt.show()","de058a17":"from sklearn.linear_model import SGDClassifier","25cf43e1":"sgd_clf = SGDClassifier(random_state=42)","70fceb92":"sgd_clf.fit(X_train, y_train)","165215f4":"sgd_accuracy = sgd_clf.score(X_test, y_test)\nprint(sgd_accuracy)","952e40c6":"from sklearn.ensemble import RandomForestClassifier","5a57e308":"rfc = RandomForestClassifier(random_state=42)","ff15cec8":"rfc.fit(X_train, y_train)","638fc359":"rfc_accuracy = rfc.score(X_test, y_test)\nprint(rfc_accuracy)","b7742b01":"y_test.value_counts()","0b5daac5":"y_test_prediction = rfc.predict(X_test)\nprint(y_test_prediction)","3560bed2":"from sklearn.metrics import confusion_matrix\nconf_mat_rfc = confusion_matrix(y_test, y_test_prediction)\nprint(conf_mat_rfc)","edd42267":"plt.matshow(conf_mat_rfc, cmap=plt.cm.gray)\nplt.show()","b580b362":"from sklearn import metrics\nprint(metrics.precision_score(y_test, y_test_prediction, average=\"weighted\"))","d7dd7583":"print(metrics.recall_score(y_test, y_test_prediction, average=\"weighted\"))","997a2e5f":"<img src=\"https:\/\/images.unsplash.com\/photo-1568391047493-d859d5ddb509?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=700&q=80\" width=\"400px\">","6a118b02":"**We can see that error rate is at its lowest at K=6 after 4(as total classes of fruits are 4 so we need to take k > 4)**","19874b50":"# Feature Scaling using MinMax Scaler","1070f393":"We have a non-linear scattering and based on their fruit labels classes can be formed ","81c221fa":"**Kindly Upvote if you like the notebook and share possible improvements in the comments.**","8567f461":"# Plotting of Error Rates vs K values","2c2dfa4f":"We dont have any null or missing values in the data","58beb41b":"# Confusion Matrix - to describe the performance of our Classification Model","fd281e74":"# Fitting and Training Logistic Regression and K-Nearest Neighbour models","7e289fc2":"# Fruits Classification using Logistic Regression & K-Nearest Neighbour","d44e4565":"# Necessary libraries and Importing the Dataset","3019e3a9":"# Checking Missing Values","bb0e9dbd":"**KNeighborsClassifier performed better than Logistic Regression. Lets try to optimize n_neighbors value as default is 5**","a4db4e01":"# Splitting of Data into Training And Testing Sets","f845d4b7":"From value counts we can see that label 2 ie. Mandarin and label 4 ie. Lemon have lesser data in test set","ec9dc1d6":"We can see darker regions when predicted and true test classes are different and grey regions when they are same.","19a0013b":"**We can clearly observe from the Pearson Correlation Coefficient(PCC) that Mass is highly correlated with Height and Width**","708248b6":"**We can calculate precision(ability not to label -ves as +ves) and recall score(ability to correctly identify the +ves) which identifies false positives and negatives**","803cf6a0":"**we can see that we have 4 classes with the fruits\napple, orange, lemon, mandarin**","f1da446f":"As we know we have multiple classes so lets try to plot the confusion matrix for a better visualization","0f7f73c9":"Range of all feature values are widely spread as seen from min, max and 25-75 percentile values","1fab4a4b":"Mass, Height, Width have a few outliers. Whereas color_score seems to represent approx. a Normal Distribution","a9e3ebbf":"# Visualizing Pairwise correlation among features","4c5ef0ee":"**It Shows that our model has high accuracy but it gives no information about the distribution and errors it is making**","1d8b0d80":"# Visualization of all the available fruits based on their mass and dimensions"}}