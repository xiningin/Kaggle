{"cell_type":{"32e6205a":"code","53d0975e":"code","f7028e30":"code","81970442":"code","1e04fdf6":"code","741376ea":"code","517e7d54":"code","385b957e":"code","7cc95d64":"code","fcfe1c79":"code","7324fafd":"code","f3453730":"code","b41e32c8":"code","39998794":"code","5d50b990":"code","c11ba5c5":"code","9e929553":"code","cb626d4d":"code","fdca2750":"code","3db7e1a7":"code","af80d21a":"code","fa717c89":"code","6ba5f2bf":"code","cf5c4235":"code","c0832e69":"code","dade228d":"code","ed26ad9d":"code","2e74d6a4":"code","9d3582ed":"code","5c4ea76a":"code","678a2af3":"code","9d6c75ba":"code","1f3755fb":"code","f1cb39e3":"code","1c6480bb":"code","22b2ebe7":"code","1c219d79":"code","76707efc":"code","cdb9602f":"code","a7752b09":"code","52ae39df":"code","b73aa3ec":"code","a0f9d678":"code","12607ba1":"code","fb49ae22":"code","2c74bec0":"code","be2f4ae8":"code","0135519b":"code","26c595d8":"code","9ade3d98":"code","201bce04":"code","ae8de467":"code","e4eb0241":"code","baa4b711":"code","b9c544b9":"code","8d49c2b8":"code","b9dbf93c":"code","4ac6ca84":"code","d670375c":"code","9a5e23f1":"code","51764fb0":"code","d687b00a":"code","efca660d":"code","4eb839b8":"code","f3bfc265":"code","7043d618":"code","19c146ba":"markdown","d13af1c9":"markdown","b15554cd":"markdown","6edafd5c":"markdown","a5079a21":"markdown","dd581f3a":"markdown","9d285444":"markdown","f6318652":"markdown","db35f656":"markdown","06de2b59":"markdown","21d22976":"markdown","23a87ca2":"markdown","b452f28d":"markdown","b2f513c2":"markdown","9db47e8b":"markdown","230715dd":"markdown","74c8565a":"markdown","51ef116c":"markdown","eff2d7a5":"markdown","c8bef250":"markdown","9bbe2d09":"markdown","4c1a23df":"markdown","064524fe":"markdown","f61754d1":"markdown","ec2382f7":"markdown","7eb17886":"markdown","243b20a8":"markdown","90b27888":"markdown","62eee49e":"markdown","3af0ae67":"markdown"},"source":{"32e6205a":"\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns \nplt.rcParams[\"figure.figsize\"] = (11,3)\nsns.set_style(\"whitegrid\")\nimport math\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout, SimpleRNN\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.float_format', lambda x: '%.1f' % x)\n\nimport itertools\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.optimizers import RMSprop, Adam, SGD\n\n","53d0975e":"# CODE SECTION\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\ndef eval_metrics(actual, pred):\n    mae = mean_absolute_error(actual, pred)\n    mse = mean_squared_error(actual, pred)\n    rmse = np.sqrt(mean_squared_error(actual, pred))\n    R2_score = r2_score(actual, pred)\n    print(\"------------------------------------\")\n    print(f\"R2_score \\t: {R2_score}\")\n    print(f\"MAE \\t\\t: {mae}\")\n    print(f\"MSE \\t\\t: {mse}\")\n    print(f\"RMSE \\t\\t: {rmse}\")\ndef evals_():\n    print(\"y_train \/ y_train_pred \")\n    eval_metrics(y_train, y_train_pred)\n    print(\"y_test \/ y_test_pred \")\n    eval_metrics(y_test, y_test_pred)\n\n# Visualising the results\ndef ploty(real,predicted)  :\n    plt.plot(real,      color = 'red' , label = '  Real Price'     )   # Real Stock price\n    plt.plot(predicted, color = 'blue', label = '  Predicted Price')\n    plt.xlabel('Day') ; plt.ylabel(' Price') ; plt.legend()\n    plt.show()\ndef plot_():\n    ploty(y_train,y_train_pred)    # TRAIN\n    ploty(y_test,y_test_pred)       # TEST","f7028e30":"data = pd.read_csv(\"..\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv\")","81970442":"data.head()","1e04fdf6":"data.tail()","741376ea":"data.info()","517e7d54":"# Converting Timestamp value to Date-Time (yy\/mm\/dd hh:mm:ss)\n\ndata['Timestamp'] = pd.to_datetime(data['Timestamp'], unit='s')\ndata.head(4)","385b957e":"data.shape","7cc95d64":"# Make a new column which has only Date value of timestamp\ndata['Date'] = data['Timestamp'].dt.date\ndata.head(2)","fcfe1c79":"data_day=data.groupby(\"Date\").mean()    # it takes the mean of the dataset \ndata_day.head(2)                      # now the columns are   in daily","7324fafd":"data_day.tail(2)","f3453730":"len(data_day)","b41e32c8":"data.corr()*100","39998794":"data_day.corr()*100","5d50b990":"# Rename the column names to getrid off () paranthesis\n\ndata_day.rename(columns={'Volume_(BTC)': 'Volume_BTC', 'Volume_(Currency)': 'Volume_Currency'}, inplace=True)","c11ba5c5":"fn=list(data_day.columns)\nfn","9e929553":"f,ax = plt.subplots(figsize=(9, 4))\nsns.heatmap(data_day.corr(), annot=True, linewidths=5, fmt= '.1f',ax=ax)\nplt.xticks(rotation= 45) \nplt.show()","cb626d4d":"data_weighted=data_day.Weighted_Price\ndata_weighted.head(4)","fdca2750":"# Line Plot\n#plt.figure(figsize=(8, 5))\ndata_weighted.plot( grid=True) # color = \"b\",kind = \"line\",  linewidth=1,  alpha=1,linestyle=\":\"\nplt.xlabel(\"Time (Year)\")            # label = name of the x axis\nplt.ylabel(\"Weighted BTC Price\")            # label = name of the y axis\nplt.title(\"Line Plot for Weighted_Price\")          # title = Title of the Plot\nplt.tight_layout()\nplt.show()","3db7e1a7":"# Scatter Plot\ndata_day.plot(kind=\"scatter\", x=\"Weighted_Price\", y=\"Volume_Currency\", alpha=0.5 )\nplt.xlabel(\"Weighted_Price\")\nplt.ylabel(\"Volume_Currency\")\nplt.title(\"Weighted_Price vs Volume_Currency Scatter Plot\")\n#plt.show()","af80d21a":"#sns.pairplot(data_day)","fa717c89":"# Scatter Plot\ndata_day.plot(kind=\"scatter\", x=\"Weighted_Price\", y=\"Volume_BTC\", alpha=0.5 )\nplt.xlabel(\"Weighted_Price\")\nplt.ylabel(\"Volume_BTC\")\nplt.title(\"Weighted_Price vs Volume_Currency Scatter Plot\")\n#plt.show()","6ba5f2bf":"for h in fn: # fn: feautere names\n    plt.figure(figsize=(11,2))\n    plt.hist( data_day[h],bins = 50) ; plt.ylabel(\"Frequency\") \n    plt.title(\"{} _hist distribution\".format(h))\n    plt.show()","cf5c4235":"data_day.describe().T","c0832e69":"data_day.isnull().sum()  # Get the number of missing data in each feauture","dade228d":"data_day.isnull().sum().sum()  # Get the number of missing data in each feauture","ed26ad9d":"data_last=data_day[int(len(data_day)*0.66):]  # The last 1\/3 part of the dataset\nlen(data_last)","2e74d6a4":"for h in fn: # fn: feautere names\n    plt.hist( data_last[h],bins = 50) ; plt.ylabel(\"Frequency\") \n    plt.title(\"{} _hist distribution\".format(h))\n    plt.show()","9d3582ed":"df=pd.DataFrame(data_weighted).values","5c4ea76a":"# Defining the  TRAIN and TEST part of the dataset\n\ntest_days=30   \ntrain=df[:-test_days]               # the days before the last 30 days\ntest=df[len(df)-test_days:]         # the last 30 days","678a2af3":"print(\"Train length:\",len(train), \"\\nTest length:\",len(test))","9d6c75ba":"plt.plot(train)\nplt.show()","1f3755fb":"plt.plot(test)\nplt.show()","f1cb39e3":"df=pd.DataFrame(data_day.Weighted_Price)\ndf.shape","1c6480bb":"#df=np.array(data_day.Weighted_Price).reshape(-1,1)\n#df.shape","22b2ebe7":"# Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf_s = scaler.fit_transform(df)     # df_s : df_scaled\ndf_s \n","1c219d79":"print(\"Max:\",df_s.max(),\"\\tMin:\",df_s.min())","76707efc":"# Creating a data structure with 90 timesteps and 1 output\n\ndf_X, df_y = [],[]\n\nfirst=90           #  first array=  time steps\nlast =len(df_s)   # last array\n\nfor i in range(first,last):\n    df_X.append(df_s[i-first:i])\n    df_y.append(df_s[i])","cdb9602f":"df_X, df_y = np.array(df_X), np.array(df_y) ","a7752b09":"# Defining the  TRAIN and TEST part of the dataset\n\ntest_days=30   \n\nX_train=df_X[:-test_days]               # the days before the last 30 days\ny_train=df_y[:-test_days]\n\nX_test=df_X[len(df_X)-test_days:]         # the last 30 days\ny_test=df_y[len(df_X)-test_days:] ","52ae39df":"def shape_():\n    print(\"X_train shape:\",X_train.shape, \"\\nX_test shape:\",X_test.shape)\n    print(\"y_train shape:\",y_train.shape, \"\\ny_test shape:\",y_test.shape)","b73aa3ec":"shape_()","a0f9d678":"# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 90, activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))    # units: 75\nregressor.add(Dropout(0.2))\n\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 30,activation='relu', return_sequences = True))\n#regressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 10,activation='tanh', return_sequences = True))\n#regressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 100))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n\n","12607ba1":"regressor.summary()\n","fb49ae22":"plot_model(regressor, show_shapes=True, show_layer_names=True)","2c74bec0":" epochs= 30\n batch_size=15","be2f4ae8":"# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)\n","0135519b":"y_train_pred = regressor.predict(X_train)\ny_train_pred = scaler.inverse_transform(y_train_pred)\n\n\ny_test_pred= regressor.predict(X_test)        #  predicted_stock_price\ny_test_pred =scaler.inverse_transform(y_test_pred)\n\n\ny_train= scaler.inverse_transform(y_train)\ny_test= scaler.inverse_transform(y_test)","26c595d8":"plot_()","9ade3d98":"evals_()","201bce04":"# Creating a data structure with 75 timesteps and 1 output\n\ndf_X, df_y = [],[]\nfirst=75           #  first array=  time steps\nlast =len(df_s)   # last array\nfor i in range(first,last):\n    df_X.append(df_s[i-first:i])\n    df_y.append(df_s[i])\n    \ndf_X, df_y = np.array(df_X), np.array(df_y) \n\n# Defining the  TRAIN and TEST part of the dataset\ntest_days=30   \nX_train=df_X[:-test_days]               # the days before the last 30 days\ny_train=df_y[:-test_days]\nX_test=df_X[len(df_X)-test_days:]         # the last 30 days\ny_test=df_y[len(df_X)-test_days:] \n\nshape_()","ae8de467":"# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 75, activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))    # units: 75\nregressor.add(Dropout(0.2))\n\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 30,activation='relu', return_sequences = True))\n#regressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 10,activation='tanh', return_sequences = True))\n#regressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 100))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))","e4eb0241":"\nepochs, batch_size = 30,15\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)\n\n## Prediction wih RNN Model\ny_train_pred = regressor.predict(X_train)\ny_train_pred = scaler.inverse_transform(y_train_pred)\ny_test_pred= regressor.predict(X_test)        #  predicted_stock_price\ny_test_pred =scaler.inverse_transform(y_test_pred)\n\ny_train= scaler.inverse_transform(y_train)\ny_test= scaler.inverse_transform(y_test)\nplot_()","baa4b711":"evals_()","b9c544b9":"# Creating a data structure with 50 timesteps and 1 output\n\ndf_X, df_y = [],[]\nfirst=50           #  first array=  time steps\nlast =len(df_s)   # last array\nfor i in range(first,last):\n    df_X.append(df_s[i-first:i])\n    df_y.append(df_s[i])\n    \ndf_X, df_y = np.array(df_X), np.array(df_y) \n\n# Defining the  TRAIN and TEST part of the dataset\ntest_days=30   \nX_train=df_X[:-test_days]               # the days before the last 30 days\ny_train=df_y[:-test_days]\nX_test=df_X[len(df_X)-test_days:]         # the last 30 days\ny_test=df_y[len(df_X)-test_days:] \n\nshape_()","8d49c2b8":"### Create RNN Model\n\n# Initialising the RNN\nregressor = Sequential()\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))    # units: 50\nregressor.add(Dropout(0.2))\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='relu', return_sequences = True))\n#regressor.add(Dropout(0.2))\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n# Adding the output layer\nregressor.add(Dense(units = 1))\nregressor.summary()\n","b9dbf93c":"\nepochs, batch_size = 30,15\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)\n\n## Prediction wih RNN Model\ny_train_pred = regressor.predict(X_train)\ny_train_pred = scaler.inverse_transform(y_train_pred)\ny_test_pred= regressor.predict(X_test)        #  predicted_stock_price\ny_test_pred =scaler.inverse_transform(y_test_pred)\n\ny_train= scaler.inverse_transform(y_train)\ny_test= scaler.inverse_transform(y_test)\nplot_()","4ac6ca84":"evals_()","d670375c":"# Creating a data structure with 50 timesteps and 1 output\n\ndf_X, df_y = [],[]\nfirst=30           #  first array=  time steps\nlast =len(df_s)   # last array\nfor i in range(first,last):\n    df_X.append(df_s[i-first:i])\n    df_y.append(df_s[i])\n    \ndf_X, df_y = np.array(df_X), np.array(df_y) \n\n# Defining the  TRAIN and TEST part of the dataset\ntest_days=30   \nX_train=df_X[:-test_days]               # the days before the last 30 days\ny_train=df_y[:-test_days]\nX_test=df_X[len(df_X)-test_days:]         # the last 30 days\ny_test=df_y[len(df_X)-test_days:] \n\nshape_()","9a5e23f1":"### Create RNN Model\n\n# Initialising the RNN\nregressor = Sequential()\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 30,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))    # units: 30\nregressor.add(Dropout(0.2))\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 10,activation='relu', return_sequences = True))\n#regressor.add(Dropout(0.2))\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 2,activation='tanh', return_sequences = True))\n#regressor.add(Dropout(0.2))\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n# Adding the output layer\nregressor.add(Dense(units = 1))\nregressor.summary()\n","51764fb0":"\nepochs, batch_size = 30,15\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)\n\n## Prediction wih RNN Model\ny_train_pred = regressor.predict(X_train)\ny_train_pred = scaler.inverse_transform(y_train_pred)\ny_test_pred= regressor.predict(X_test)        #  predicted_stock_price\ny_test_pred =scaler.inverse_transform(y_test_pred)\n\ny_train= scaler.inverse_transform(y_train)\ny_test= scaler.inverse_transform(y_test)\nplot_()","d687b00a":"evals_()","efca660d":"# Creating a data structure with 50 timesteps and 1 output\n\ndf_X, df_y = [],[]\nfirst=30           #  first array=  time steps\nlast =len(df_s)   # last array\nfor i in range(first,last):\n    df_X.append(df_s[i-first:i])\n    df_y.append(df_s[i])\n    \ndf_X, df_y = np.array(df_X), np.array(df_y) \n\n# Defining the  TRAIN and TEST part of the dataset\ntest_days=30   \nX_train=df_X[:-test_days]               # the days before the last 30 days\ny_train=df_y[:-test_days]\nX_test=df_X[len(df_X)-test_days:]         # the last 30 days\ny_test=df_y[len(df_X)-test_days:] \n\nshape_()","4eb839b8":"### Create RNN Model\n\n# Initialising the RNN\nregressor = Sequential()\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 10,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))    # units: 30\nregressor.add(Dropout(0.2))\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 10,activation='relu', return_sequences = True))\n#regressor.add(Dropout(0.2))\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 2,activation='tanh', return_sequences = True))\n#regressor.add(Dropout(0.2))\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 20))\nregressor.add(Dropout(0.2))\n# Adding the output layer\nregressor.add(Dense(units = 1))\nregressor.summary()\n\n","f3bfc265":"\nepochs, batch_size = 30,15\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)\n\n## Prediction wih RNN Model\ny_train_pred = regressor.predict(X_train)\ny_train_pred = scaler.inverse_transform(y_train_pred)\ny_test_pred= regressor.predict(X_test)        #  predicted_stock_price\ny_test_pred =scaler.inverse_transform(y_test_pred)\n\ny_train= scaler.inverse_transform(y_train)\ny_test= scaler.inverse_transform(y_test)\nplot_()","7043d618":"evals_()","19c146ba":"#### There are many NaN values","d13af1c9":"The number of records now more practical","b15554cd":"### 50 squential days","6edafd5c":"### 30 squential days","a5079a21":"# RNN:Recurrent Neural Network","dd581f3a":"#### Weighted_Price has a full relation with Open, High and Low","9d285444":"## Prepare Data for RNN","f6318652":"## Explanation of the features","db35f656":"There is no NaN values ( all disappered when merging minutes into day )\n#### It means that all these are \" nearest to the Zero\" values are because of they are very small values.\n(for a long time from BTC's early days it has been very low priced)\n\n","06de2b59":"#  RNN ","21d22976":"### 10 squential days","23a87ca2":"### Create RNN Model","b452f28d":"<div>\n\n<p>   Timestamp - This is the unix timestamp   Day and Time recorded together in a series\n<p>   Open - This is the opening price of the time period\n<p>   High - This is the highest price of the time period\n<p>   Low - This is the lowest price of the time period\n<p>   Close - This is the closing price of the time period\n<p>   Volume (BTC) - This is the volume in BTC\n<p>   Volume (Curency) - This is the volume in USDT amount\n<p>   Weighted_Price - This is the weighted price of BTC in USDT\n\n<\/div>\n","b2f513c2":"There are many ZERO or near ZERO records even in Weighted_Price ","9db47e8b":"##  using only 30 sequential days","230715dd":"#### It is seen that records are in minutes","74c8565a":"#### inverse proportion between VolumeBTC and Price.  When price increase, volume decrease.","51ef116c":"## Using only 50 sequential","eff2d7a5":"## Using only 75 sequential","c8bef250":"#### There are No ZERO values in Weihted_Price feuture as it is seen above.\nThen it can show that there maybe  NaN values Let's check.","9bbe2d09":"##  using only 10 sequential days","4c1a23df":"## EDA","064524fe":"#### We only will use Weighted_Price column  \n(any of the high correlation feautures as Open, High, Low, Close can be used)","f61754d1":"data_day correlation increased !","ec2382f7":"## Visulazations\n","7eb17886":"### 90 squential days","243b20a8":"##  90 squential days","90b27888":"### Prediction and Visualising RNN Model","62eee49e":"### 75 squential days","3af0ae67":"#### There are 4.8 million records. They are too much to evaluate, it can take days\n####  So lets decrease it by summing the minutes into day"}}