{"cell_type":{"443efc77":"code","c570f8af":"code","aa37d2ba":"code","cdda82de":"code","50a07aa7":"code","7f6dcdff":"code","5c5bfa29":"code","b7341fe2":"code","5de634a7":"code","7beaf735":"code","592add2d":"code","79e2c211":"code","409ca131":"code","31fbad27":"code","3b9c196f":"code","b6b71fe3":"code","97b944d0":"code","fe5a6753":"code","06820973":"code","a50e75b3":"code","6f7c8cd3":"code","22592848":"code","e48fdb4b":"code","0e32f1e1":"code","8c414009":"code","4a807be2":"code","33638472":"code","04b20710":"code","166f30cd":"code","93dc4a19":"code","537fb080":"code","6437bee5":"code","64d07208":"code","58ccd2d7":"code","60073d05":"code","011e3276":"code","f88148f3":"code","f1805303":"code","924afc13":"code","27274df1":"code","6e2a6757":"code","1c379331":"markdown","14d691ba":"markdown","1e301c8d":"markdown","0c329587":"markdown","702f9c99":"markdown","48d2601e":"markdown","dc43320a":"markdown","33543c5c":"markdown","e8e1e7dd":"markdown","d869fda6":"markdown","e048b81c":"markdown","515cfab8":"markdown","2780ea00":"markdown","3e70447d":"markdown"},"source":{"443efc77":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","c570f8af":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport lightgbm as lgb\n\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom colorama import Fore, Back, Style \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier","aa37d2ba":"heart_data = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\nheart_data.head()","cdda82de":"heart_data.describe()","50a07aa7":"#Features = ['age','anaemia','diabetes','time','ejection_fraction','serum_creatinine']\nz = heart_data[\"DEATH_EVENT\"]\nx = heart_data.drop([\"DEATH_EVENT\",\"creatinine_phosphokinase\",\"diabetes\"],axis=1)\ny = z.copy()\nx_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2, random_state=2)","7f6dcdff":"accuracy_list = []","5c5bfa29":"# logistic regression\n\nlog_reg = LogisticRegression()\nlog_reg.fit(x_train, y_train)\nlog_reg_pred = log_reg.predict(x_test)\nlog_reg_acc = accuracy_score(y_test, log_reg_pred)\naccuracy_list.append(100*log_reg_acc)","b7341fe2":"print(\"Accuracy of Logistic Regression model is : \", 100*log_reg_acc)","5de634a7":"cm = confusion_matrix(y_test, log_reg_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap = plt.cm.Blues)\nplt.title(\"Logistic Regression Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\", \"Heart Fail\"], fontsize = 16)\nplt.yticks(range(2), [\"Heart Not Failed\", \"Heart Fail\"], fontsize = 16)\nplt.show()\n","7beaf735":"# svc \n\nsv_clf = SVC()\nsv_clf.fit(x_train, y_train)\nsv_clf_pred = sv_clf.predict(x_test)\nsv_clf_acc = accuracy_score(y_test, sv_clf_pred)\naccuracy_list.append(100*sv_clf_acc)","592add2d":"print(\"Accuracy of SVC is : \", 100*sv_clf_acc)","79e2c211":"cm = confusion_matrix(y_test, sv_clf_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap = plt.cm.Blues)\nplt.title(\"SVC Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\", \"Heart Fail\"], fontsize = 16)\nplt.yticks(range(2), [\"Heart Not Failed\", \"Heart Fail\"], fontsize = 16)\nplt.show()\n","409ca131":"# K Neighbors Classifier\n\nkn_clf = KNeighborsClassifier(n_neighbors=6)\nkn_clf.fit(x_train, y_train)\nkn_pred = kn_clf.predict(x_test)\nkn_acc  = accuracy_score(y_test, kn_pred)\naccuracy_list.append(100*kn_acc)","31fbad27":"print(\"Accuracy of K Neighbors Classifier is : \", 100*kn_acc)","3b9c196f":"cm = confusion_matrix(y_test, kn_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize = (12,8), hide_ticks=True, cmap = plt.cm.Blues)\nplt.title(\"K Neighbors Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\", \"Heart Fail\"], fontsize = 16)\nplt.yticks(range(2), [\"Heart Not Failed\", \"Heart Fail\"], fontsize = 16)\nplt.show()\n","b6b71fe3":"# Decision Tree Classifier\n\ndt_clf = DecisionTreeClassifier(max_leaf_nodes=3, random_state=0, criterion='entropy')\ndt_clf.fit(x_train, y_train)\ndt_pred = dt_clf.predict(x_test)\ndt_acc = accuracy_score(y_test, dt_pred)\naccuracy_list.append(100*dt_acc)","97b944d0":"print(\"Accuracy of Decision Tree Classifier is : \", 100* dt_acc)","fe5a6753":"cm = confusion_matrix(y_test, dt_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Decision Tree Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","06820973":"\n\nr_clf = RandomForestClassifier(max_features=0.5, max_depth=15, random_state=1)\nr_clf.fit(x_train, y_train)\nr_pred = r_clf.predict(x_test)\nr_acc = accuracy_score(y_test, r_pred)\naccuracy_list.append(100*r_acc)","a50e75b3":"print(\"Accuracy of RandomForestClassifier is : \", 100*r_acc)","6f7c8cd3":"cm = confusion_matrix(y_test, r_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Random Forest Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","22592848":"# GradientBoostingClassifier\n\ngradientboost_clf = GradientBoostingClassifier(max_depth=2, random_state=1)\ngradientboost_clf.fit(x_train,y_train)\ngradientboost_pred = gradientboost_clf.predict(x_test)\ngradientboost_acc = accuracy_score(y_test, gradientboost_pred)\naccuracy_list.append(100*gradientboost_acc)","e48fdb4b":"print(\"Accuracy of GradientBoostingClassifier is : \", 100*gradientboost_acc)","0e32f1e1":"cm = confusion_matrix(y_test, gradientboost_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Gredient Boosting Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()\n","8c414009":"# CatBoostClassifier\n\ncat_clf = CatBoostClassifier()\ncat_clf.fit(x_train,y_train)\ncat_pred = cat_clf.predict(x_test)\ncat_acc = accuracy_score(y_test, cat_pred)\naccuracy_list.append(100*cat_acc)","4a807be2":"print (\"Accuracy of CatBoostClassifier is :\", 100*cat_acc)","33638472":"xgb_clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators=10)\nxgb_clf.fit(x_train, y_train)\nxgb_pred = xgb_clf.predict(x_test)\nxgb_acc = accuracy_score(y_test, xgb_pred)\naccuracy_list.append(100*xgb_acc)","04b20710":"print (\"Accuracy of XGBoostClassifier is :\", 100*xgb_acc)","166f30cd":"cm = confusion_matrix(y_test, xgb_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"XGB Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","93dc4a19":"from xgboost import XGBClassifier, plot_importance,to_graphviz\n\nplt.figure()\nplot_importance(xgb_clf,title=\"Feature importance from XGBoost model\")\nplt.show()","537fb080":"lgb_clf = lgb.LGBMClassifier()\nlgb_clf.fit(x_train, y_train)\nlgb_pred = lgb_clf.predict(x_test)\nlgb_acc = accuracy_score(y_test, lgb_pred)\naccuracy_list.append(100*lgb_acc)","6437bee5":"print (\"Accuracy of XGBoostClassifier is :\", 100*xgb_acc)","64d07208":"cm = confusion_matrix(y_test, lgb_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"LGBM Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","58ccd2d7":"from sklearn.naive_bayes import GaussianNB\n\nnb_clf = GaussianNB()\nnb_clf.fit(x_train, y_train)\nnb_pred = nb_clf.predict(x_test)\nnb_acc = accuracy_score(y_test, nb_pred)\naccuracy_list.append(100*nb_acc)","60073d05":"print (\"Accuracy of XGBoostClassifier is :\", 100*nb_acc)","011e3276":"cm = confusion_matrix(y_test, nb_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Gaussian Naive Bayes Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","f88148f3":"from sklearn.ensemble import VotingClassifier\n\nLR_clf2 = LogisticRegression().fit(x_train, y_train)\nDT_clf = DecisionTreeClassifier().fit(x_train, y_train)\nknn_clf = KNeighborsClassifier().fit(x_train, y_train)\nRF_clf = RandomForestClassifier(random_state=0).fit(x_train, y_train)\nsvc_clf = SVC().fit(x_train, y_train)\n\nvc_clf = VotingClassifier(estimators=[('lr', LR_clf2), \n            ('dt', DT_clf), ('knn', knn_clf),\n            ('rf', RF_clf), ('svc', svc_clf), ('r-clf', r_clf)], \n            voting='hard')\nvc_clf.fit(x_train, y_train)\nvc_pred = vc_clf.predict(x_test)\nvc_acc = accuracy_score(y_test, vc_pred)\naccuracy_list.append(100*vc_acc)","f1805303":"print (\"Accuracy of VotingClassifier is :\", 100*vc_acc)","924afc13":"cm = confusion_matrix(y_test, vc_pred)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Voting Classifier Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.yticks(range(2), [\"Heart Not Failed\",\"Heart Fail\"], fontsize=16)\nplt.show()","27274df1":"model_list = ['Logistic Regression', 'SVC','KNearestNeighbours', 'DecisionTree', 'RandomForest',\n              'GradientBooster','CatBoostClassifier', 'XGB', 'LGBM', 'Naive Bayes', 'Voting Classifier']","6e2a6757":"import seaborn as sns\n\nplt.rcParams['figure.figsize']=20,8\nsns.set_style('darkgrid')\n\n\nax = sns.barplot(x=model_list, y=accuracy_list, palette = \"husl\", saturation =2.0)\nplt.xlabel('Classifier Models', fontsize = 20 )\nplt.ylabel('% of Accuracy', fontsize = 20)\nplt.title('Accuracy of different Classifier Models', fontsize = 20)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 12)\nfor i in ax.patches:\n    width, height = i.get_width(), i.get_height()\n    x, y = i.get_xy() \n    ax.annotate(f'{round(height,2)}%', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\n\n\n    \nplt.show()","1c379331":"# GradientBoostingClassifier","14d691ba":"# RandomForestClassifier","1e301c8d":"# Decision Tree Classifier\n\n","0c329587":"# Logistic Regression","702f9c99":"# Support Vector","48d2601e":"# Naive Bayes","dc43320a":"# CatBoostClassifier","33543c5c":"# Voting Classifier","e8e1e7dd":"#  Data Modeling","d869fda6":"# XGB","e048b81c":"# K Neighbors Classifier","515cfab8":"**Import Libraries**","2780ea00":"# Accuracy for all models","3e70447d":"# LGBM"}}