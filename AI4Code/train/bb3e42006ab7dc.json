{"cell_type":{"261cb4e7":"code","2f858d74":"code","5107c25c":"code","fc3b8106":"code","54fe68a0":"code","bd40b6bb":"code","15f32531":"code","b5f7efc2":"code","734a5d7f":"code","fbcdeb44":"code","f48fc5db":"code","da1d9f7b":"code","267fb44b":"code","89a2b878":"code","0bcb1330":"code","8d150ff3":"code","a0d0daee":"code","fe78003b":"code","3eae16c4":"code","3a5c86d7":"code","1f4dc105":"code","04b78c02":"code","66f0796a":"code","059d5182":"code","632ace4b":"code","9f10e395":"code","c9c3b697":"code","b57a070d":"code","c9929400":"code","5c212cee":"code","ad8642f6":"code","3013c6fb":"code","e7f326ea":"code","7a4dd65f":"code","56af0c5f":"code","1a63896d":"code","5089feb1":"code","e03aeaf7":"code","92c676e9":"code","5a24c98c":"markdown","e93e921f":"markdown","5eac6b0d":"markdown","ffd9e2be":"markdown","22903eb1":"markdown","ea4a65e6":"markdown","d958fc82":"markdown","96e36690":"markdown","c1f9c4e4":"markdown","57bbcba7":"markdown"},"source":{"261cb4e7":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import load_boston\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nsns.set_style('whitegrid')\n%matplotlib inline","2f858d74":"#datasets = pd.read_csv('..\/input\/boston-housing\/housing.data', delim_whitespace=True, header= None)","5107c25c":"boston_data = load_boston()\ndatasets = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)","fc3b8106":"#columns_datasets =  ['CRIM', 'ZN' , 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']","54fe68a0":"#datasets.columns = columns_datasets","bd40b6bb":"datasets.head()","15f32531":"from sklearn.tree import DecisionTreeRegressor","b5f7efc2":"X = datasets[['LSTAT']].values\ny = boston_data.target","734a5d7f":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","fbcdeb44":"tree_model = DecisionTreeRegressor(max_depth=5)","f48fc5db":"tree_model.fit(X, y)","da1d9f7b":"y_test_Predict = tree_model.predict(x_test)\ny_train_Predict = tree_model.predict(x_train)","267fb44b":"print('Mean Squared Error\\t Train : {0:0.4f}, Test: {1:.4f}'.format(mean_squared_error(y_train, y_train_Predict), mean_squared_error(y_test, y_test_Predict)))","89a2b878":"print('R Score\\t Train : {0:0.4f}, Test: {1:.4f}'.format(r2_score(y_train, y_train_Predict), r2_score(y_test, y_test_Predict)))","0bcb1330":"idx = X.flatten().argsort()","8d150ff3":"plt.figure(figsize = (10, 8))\nplt.scatter(X[idx], y[idx])\nplt.plot(X[idx], tree_model.predict(X[idx]), color = 'k')\nplt.xlabel(\"% lower status of the population\")\nplt.ylabel(\"Median value of owner-occupied homes in $1000's\")\nplt.tight_layout()\nplt.show()","a0d0daee":"tree_model = DecisionTreeRegressor(max_depth=2)\ntree_model.fit(X, y)\nplt.figure(figsize = (10, 8))\nplt.scatter(X[idx], y[idx])\nplt.plot(X[idx], tree_model.predict(X[idx]), color = 'k')\nplt.xlabel(\"% lower status of the population\")\nplt.ylabel(\"Median value of owner-occupied homes in $1000's\")\nplt.tight_layout()\nplt.show()","fe78003b":"X = datasets.values","3eae16c4":"forest_model = RandomForestRegressor(n_estimators=500,\n                                    criterion='mse',\n                                    random_state = 42,\n                                    n_jobs= -1)","3a5c86d7":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","1f4dc105":"forest_model.fit(X, y)","04b78c02":"y_train_Predict = forest_model.predict(x_train)","66f0796a":"y_test_Predict = forest_model.predict(x_test)","059d5182":"print('Mean Squared Error\\t Train : {0:0.4f}, Test: {1:.4f}'.format(mean_squared_error(y_train, y_train_Predict), mean_squared_error(y_test, y_test_Predict)))","632ace4b":"print('R Score\\t Train : {0:0.4f}, Test: {1:.4f}'.format(r2_score(y_train, y_train_Predict), r2_score(y_test, y_test_Predict)))","9f10e395":"from sklearn.ensemble import AdaBoostRegressor","c9c3b697":"adaBoost_model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), \n                        n_estimators=500, random_state=42)","b57a070d":"adaBoost_model.fit(x_train, y_train)","c9929400":"y_train_Predict = adaBoost_model.predict(x_train)\ny_test_Predict = adaBoost_model.predict(x_test)","5c212cee":"print('Mean Squared Error\\t Train : {0:0.4f}, Test: {1:.4f}'.format(mean_squared_error(y_train, y_train_Predict), mean_squared_error(y_test, y_test_Predict)))","ad8642f6":"print('R Score\\t Train : {0:0.4f}, Test: {1:.4f}'.format(r2_score(y_train, y_train_Predict), r2_score(y_test, y_test_Predict)))","3013c6fb":"adaBoost_model.feature_importances_","e7f326ea":"result = pd.DataFrame(adaBoost_model.feature_importances_, datasets.columns)\nresult.columns = ['feature']","7a4dd65f":"result.sort_values(by = 'feature', ascending=False)","56af0c5f":"result.sort_values(by = 'feature', ascending=False).plot(kind = 'bar')","1a63896d":"forest_model.feature_importances_","5089feb1":"result = pd.DataFrame(forest_model.feature_importances_, datasets.columns)\nresult.columns = ['feature']\nresult.sort_values(by='feature', ascending=False).plot(kind='bar');","e03aeaf7":"tree = DecisionTreeRegressor(max_depth=3)\ntree.fit(x_train, y_train)\n\ny_train_pred = tree.predict(x_train)\ny_test_pred = tree.predict(x_test)","92c676e9":"result = pd.DataFrame(tree.feature_importances_, datasets.columns)\nresult.columns = ['feature']\nresult.sort_values(by='feature', ascending=False).plot(kind='bar');","5a24c98c":"# Load Dataset","e93e921f":"# AdaBoost","5eac6b0d":"# Import Libraries","ffd9e2be":"Using Max Depth = 5 is lead to overfitting,\nNow, Let's try max depth = 2","22903eb1":"# Random Forest","ea4a65e6":"# Decision Tree","d958fc82":"# According to Decision Tree","96e36690":"# According to AdaBoost","c1f9c4e4":"# Feature Importance\n In this dataset there are 13 features.\n\nAre they all equally important?\n\nWhich features are more important?\n\nCan scikit-learn help us with this?","57bbcba7":"# According to Random Forest"}}