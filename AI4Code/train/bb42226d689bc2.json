{"cell_type":{"f745660e":"code","ea162c01":"code","8c40bb4e":"code","4a790b09":"code","d35c873f":"code","00ab483d":"code","895d03be":"code","6eae42f9":"code","083a9962":"code","7e0447fd":"code","702de03b":"code","0f747a07":"code","cd72e732":"code","ae05f867":"code","362a09ba":"code","5aa9cf53":"code","531712d0":"code","90961f0e":"markdown","4fcbf37f":"markdown","b44197f8":"markdown","532531bf":"markdown","f749c47b":"markdown","4b172660":"markdown"},"source":{"f745660e":"import numpy as np\nimport pandas as pd\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport glob\nimport os.path as osp\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","ea162c01":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils import data as D","8c40bb4e":"# Tutorail for torch version:\ntorch.__version__","4a790b09":"path = '..\/input\/train\/'","d35c873f":"class AirbusDS(D.Dataset):\n    \"\"\"\n    A customized data loader.\n    \"\"\"\n    def __init__(self, root):\n        \"\"\" Intialize the dataset\n        \"\"\"\n        self.filenames = []\n        self.root = root\n        self.transform = transforms.ToTensor()\n        filenames = glob.glob(osp.join(path, '*.jpg'))\n        for fn in filenames:\n            self.filenames.append(fn)\n        self.len = len(self.filenames)\n        \n    # You must override __getitem__ and __len__\n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        image = Image.open(self.filenames[index])\n        return self.transform(image)\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","00ab483d":"# Simple dataset. Only save path to image and load it and transform to tensor when call __getitem__.\nairimg = AirbusDS(path)\n# total images in set\nprint(airimg.len)","895d03be":"# Use the torch dataloader to iterate through the dataset\nloader = D.DataLoader(airimg, batch_size=24, shuffle=False, num_workers=0)\n\n# functions to show an image\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n# get some images\ndataiter = iter(loader)\nimages = dataiter.next()\n\n# show images\nplt.figure(figsize=(16,8))\nimshow(torchvision.utils.make_grid(images))","6eae42f9":"train_len = int(0.7*airimg.len)\nvalid_len = airimg.len - train_len\ntrain, valid = D.random_split(airimg, lengths=[train_len, valid_len])","083a9962":"# check lens of subset\nlen(train), len(valid)","7e0447fd":"# https:\/\/github.com\/albu\/albumentations\nfrom albumentations import (ToFloat, \n    CLAHE, RandomRotate90, Transpose, ShiftScaleRotate, Blur, OpticalDistortion, \n    GridDistortion, HueSaturationValue, IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, \n    MedianBlur, IAAPiecewiseAffine, IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, \n    Flip, OneOf, Compose\n)","702de03b":"class AirbusDS(D.Dataset):\n    \"\"\"\n    A customized data loader.\n    \"\"\"\n    def __init__(self, root, aug = False):\n        \"\"\" Intialize the dataset\n        \"\"\"\n        self.filenames = []\n        self.root = root\n        self.aug = aug\n        if self.aug:\n            self.transform = OneOf([\n                                CLAHE(clip_limit=2),\n                                IAASharpen(),\n                                RandomRotate90(),\n                                IAAEmboss(),\n                                Transpose(),\n                                RandomContrast(),\n                                RandomBrightness(),\n                            ], p=0.3)\n        else:\n            self.transform = transforms.ToTensor()\n        filenames = glob.glob(osp.join(path, '*.jpg'))\n        for fn in filenames:\n            self.filenames.append(fn)\n        self.len = len(self.filenames)\n        \n    # You must override __getitem__ and __len__\n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        image = Image.open(self.filenames[index])\n        if self.aug:\n            data = {\"image\": np.array(image)}\n            image = self.transform(**data)['image']\n            images = np.transpose(image, (2, 0, 1))\n            return images\n        else:\n            return self.transform(image)\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","0f747a07":"airimg = AirbusDS(path, aug=True)","cd72e732":"# Use the torch dataloader to iterate through the dataset\nloader = D.DataLoader(airimg, batch_size=24, shuffle=False, num_workers=0)\n\n# get some images\ndataiter = iter(loader)\nimages = dataiter.next()\n\n# show images\nplt.figure(figsize=(16,8))\nimshow(torchvision.utils.make_grid(images))","ae05f867":"# based on https:\/\/www.kaggle.com\/inversion\/run-length-decoding-quick-start\nmasks = pd.read_csv('..\/input\/train_ship_segmentations.csv')\nmasks.head()","362a09ba":"# ref: https:\/\/www.kaggle.com\/paulorzp\/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction","5aa9cf53":"class AirbusDS(D.Dataset):\n    \"\"\"\n    A customized data loader.\n    \"\"\"\n    def __init__(self, root, aug = False, mode='train'):\n        \"\"\" Intialize the dataset\n        \"\"\"\n        self.filenames = []\n        self.root = root\n        self.aug = aug\n        self.mode = 'test'\n        if mode == 'train':\n            self.mode = 'train'\n            self.masks = pd.read_csv('..\/input\/train_ship_segmentations.csv').fillna(-1)\n        if self.aug:\n            self.transform = OneOf([\n                                RandomRotate90(),\n                                Transpose(),\n                                Flip(),\n                            ], p=0.3)\n        else:\n            self.transform = transforms.ToTensor()\n        filenames = glob.glob(osp.join(path, '*.jpg'))\n        for fn in filenames:\n            self.filenames.append(fn)\n        self.len = len(self.filenames)\n        \n    # You must override __getitem__ and __len__\n    def get_mask(self, ImageId):\n        img_masks = self.masks.loc[self.masks['ImageId'] == ImageId, 'EncodedPixels'].tolist()\n\n        # Take the individual ship masks and create a single mask array for all ships\n        all_masks = np.zeros((768, 768))\n        if img_masks == [-1]:\n            return all_masks\n        for mask in img_masks:\n            all_masks += rle_decode(mask)\n        return all_masks\n    \n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        image = Image.open(self.filenames[index])\n        ImageId = self.filenames[index].split('\/')[-1]\n        if self.mode == 'train':\n            mask = self.get_mask(ImageId)\n        if self.aug:\n            if self.mode == 'train':\n                data = {\"image\": np.array(image), \"mask\": mask}\n            else:\n                data = {\"image\": np.array(image)}\n            transformed = self.transform(**data)\n            image = transformed['image']\/255\n            image = np.transpose(image, (2, 0, 1))\n            if self.mode == 'train':\n                return image, transformed['mask'][np.newaxis,:,:] \n            else:\n                return image\n        else:\n            if self.mode == 'train':\n                return self.transform(image), mask[np.newaxis,:,:] \n            return self.transform(image)\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","531712d0":"airimg = AirbusDS(path, aug=True, mode='train')\n# Use the torch dataloader to iterate through the dataset\nloader = D.DataLoader(airimg, batch_size=24, shuffle=False, num_workers=0)\n\n# get some images\ndataiter = iter(loader)\nimages, masks = dataiter.next()\n\n# show images\nplt.figure(figsize=(16,16))\nplt.subplot(211)\nimshow(torchvision.utils.make_grid(images))\nplt.subplot(212)\nimshow(torchvision.utils.make_grid(masks))","90961f0e":"# Data preparetion. Spet by step\n-   Simple Dataset\n-  Splitting data into train and validation part\n- Using augmentation for images\n- Adding mask\n","4fcbf37f":"### 2. Splitting data into train and validation part\nUse random split as example. For this aim create 2 Subset","b44197f8":"### 4. Adding masks","532531bf":"### 3. Using augmentation for images","f749c47b":"## Dataset: basic structure\nSo go to official [web documantation](https:\/\/pytorch.org\/docs\/stable\/data.html). And see 3 main class: Dataset,  Sampler and DataLoader.\n- Dataset:\n    - An abstract class representing a Dataset.\n    - All other datasets should subclass it. All subclasses should override __len__, that provides the size of the dataset, and __getitem__, supporting integer indexing in range from 0 to len(self) exclusive.\n- Sampler:\n    - Base class for all Samplers.\n    - Every Sampler subclass has to provide an __iter__ method, providing a way to iterate over indices of dataset elements, and a __len__ method that returns the length of the returned iterators.\n- DataLoader:\n    - Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset.","4b172660":"### 1.  Simple Dataset:"}}