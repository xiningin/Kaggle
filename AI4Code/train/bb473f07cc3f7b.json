{"cell_type":{"647a5ce5":"code","e1247c84":"code","5d213c91":"code","826a4afa":"code","61bd88e0":"code","a123b841":"code","c44bcd9e":"code","bc100169":"code","e9d64052":"code","c3e2627f":"code","d2eec6a5":"code","08769bb5":"code","d80756fb":"code","2151d83a":"code","2b3206d1":"code","732e1d74":"code","9e7d30eb":"code","985571b2":"code","d877c47c":"code","4c6776a7":"code","d17d8591":"code","a739b865":"markdown","c8d4724a":"markdown","72a50c10":"markdown","fc0d209b":"markdown","cef96e3f":"markdown","6550c0a0":"markdown","c2a02ca5":"markdown","a76d8b40":"markdown","abec1176":"markdown","31da599c":"markdown","ca49d139":"markdown"},"source":{"647a5ce5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e1247c84":"train_dataset = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_dataset = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","5d213c91":"train_dataset.head()","826a4afa":"train_dataset.shape","61bd88e0":"from keras.utils import to_categorical\n\ntrain_labels = np.asarray(train_dataset['label'])\ntrain_labels = to_categorical(train_labels)\n\ntrain_data = train_dataset.drop('label', axis=1)\ntrain_data = np.asarray(train_data).reshape(train_data.shape[0], 28, 28, 1)","a123b841":"from sklearn.model_selection import train_test_split\n\ntrain_images, validation_images, train_labels, validation_labels = train_test_split(train_data, train_labels, test_size=0.3, random_state=40)","c44bcd9e":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255, \n    rotation_range=30, \n    width_shift_range=0.2, \n    height_shift_range=0.2, \n    shear_range=0.2, \n    zoom_range=0.2, \n    horizontal_flip=False, \n    fill_mode='constant')\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)","bc100169":"train_generator = train_datagen.flow(train_images, train_labels, batch_size=294)\nvalidation_generator = validation_datagen.flow(validation_images, validation_labels, batch_size=126)","e9d64052":"for data_batch, labels_batch in train_generator:\n    print('data batch shape:', data_batch.shape)\n    print('labels batch shape:', labels_batch.shape)\n    break","c3e2627f":"from keras.preprocessing import image\nimport matplotlib.pyplot as plt\n\ntest_img = train_images[4].reshape(1, 28, 28, 1)\ni = 0\n\nfor batch in train_datagen.flow(test_img, batch_size=1):\n    plt.figure(i, figsize=(1, 1))\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\n\nplt.show()","d2eec6a5":"from keras import models\nfrom keras import layers\nfrom keras import regularizers\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(128, (3, 3), \n                        activation='relu', \n                        input_shape=(28, 28, 1), \n                        kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), \n                        activation='relu', \n                        kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), \n                        activation='relu', \n                        kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dense(10, activation='softmax'))","08769bb5":"from keras import optimizers\n\n# lr_schedule = optimizers.schedules.ExponentialDecay(\n#     initial_learning_rate=1e-3,\n#     decay_steps=10000,\n#     decay_rate=0.9)\n\nmodel.compile(\n    optimizer = optimizers.RMSprop(lr=1e-4), \n    loss='categorical_crossentropy', \n    metrics=['acc'])","d80756fb":"history = model.fit(\n    train_generator, \n    steps_per_epoch=100, \n    epochs=100, \n    validation_data=validation_generator, \n    validation_steps=50, \n    verbose=1)","2151d83a":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","2b3206d1":"# model = models.Sequential()\n# model.add(layers.Conv2D(128, (3, 3), \n#                         activation='relu', \n#                         input_shape=(28, 28, 1), \n#                         kernel_regularizer=regularizers.l2(0.001)))\n# model.add(layers.MaxPooling2D((2, 2)))\n# model.add(layers.Conv2D(64, (3, 3), \n#                         activation='relu', \n#                         kernel_regularizer=regularizers.l2(0.001)))\n# model.add(layers.MaxPooling2D((2, 2)))\n# model.add(layers.Conv2D(64, (3, 3), \n#                         activation='relu', \n#                         kernel_regularizer=regularizers.l2(0.001)))\n# model.add(layers.Flatten())\n# model.add(layers.Dropout(0.5))\n# model.add(layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n# model.add(layers.Dense(10, activation='softmax'))\n\n# model.compile(\n#     optimizer = optimizers.RMSprop(lr=1e-4), \n#     loss='categorical_crossentropy', \n#     metrics=['acc'])\n\n# model.fit(\n#     train_generator, \n#     steps_per_epoch=100, \n#     epochs=50, \n#     validation_data=validation_generator, \n#     validation_steps=50, \n#     verbose=1)","732e1d74":"test_dataset.shape","9e7d30eb":"test_images = np.asarray(test_dataset)\ntest_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\ntest_images = test_images.astype('float32')\/255","985571b2":"predictions = model.predict(test_images, batch_size=128)\nimage_id = range(1, predictions.shape[0] + 1)","d877c47c":"pred = [np.argmax(i) for i in predictions]","4c6776a7":"sample = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsample.head()","d17d8591":"submission = pd.DataFrame({'ImageId': image_id, 'Label': pred})\nsubmission.to_csv('digit_recognizer_submission', index=False)\nprint('file saved!')","a739b865":"### Compile model","c8d4724a":"### Check the output of the generator","72a50c10":"### Train model","fc0d209b":"### Train a new model with proper epoch","cef96e3f":"### Define model","6550c0a0":"### Make prediction","c2a02ca5":"## Data augmentation with ImageDataGenerator","a76d8b40":"## Keras model","abec1176":"## Split training and validation dataset","31da599c":"## Submission","ca49d139":"### Check if the ImageDataGenerator transforms well"}}