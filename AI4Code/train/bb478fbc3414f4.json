{"cell_type":{"48af0de8":"code","20dd1e7c":"code","da40f021":"code","8962c2df":"code","303803ac":"code","25d58cf7":"code","c90cb79e":"code","6b4dbd1a":"code","89485e02":"code","946cb9ec":"code","7896e89e":"code","3271dafe":"code","9ca1a3da":"code","9b3aac2b":"code","fa20abb7":"code","8d2b89f7":"code","e84a376f":"code","4d4d96d6":"code","1576aab2":"code","b3043da7":"code","b6a459e4":"code","8416e24f":"code","24bc74c5":"markdown","26af2380":"markdown","a78867d3":"markdown","3f16deb9":"markdown","b1b6620c":"markdown","413a8f11":"markdown","afe8f1fc":"markdown","864d8f43":"markdown","f02583ef":"markdown","99d0bd7b":"markdown"},"source":{"48af0de8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport cv2\nimport PIL\nimport glob\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport albumentations as alb\nfrom pydicom import dcmread","20dd1e7c":"def plot(img):\n    plt.figure(figsize=(10, 10))\n    plt.title(\"Raw visualization\")\n    plt.imshow(img, 'gray')\n\n\ndef get_labels(df):\n    for i, row in df.iterrows():\n        if(row[labels[0]] == 1):\n            df.loc[i, 'label']=labels[0]\n        elif(row[labels[1]] == 1):\n            df.loc[i, 'label']=labels[1]\n        elif(row[labels[2]] == 1):\n            df.loc[i, 'label']=labels[2]\n        elif(row[labels[3]] == 1):\n            df.loc[i, 'label']=labels[3]","da40f021":"def get_paths(df):\n    list_, labels=[], []\n\n    for i, path_ in tqdm(enumerate(df.path), total=len(df)):\n        for folder in glob.glob(path_+'*'):\n            list_.extend(glob.glob(folder+'\/*.dcm'))\n            labels.extend([df.iloc[i, 6] for _ in glob.glob(folder+'\/*.dcm')])\n            if(len(list_)!=len(labels)):\n                print(len(list_),len(labels))\n    return list_, labels\n\n\ndef convert_dicom(path):\n    dicom = dcmread(path)\n    return dicom.pixel_array\n\ndef augmentations(path):\n    img = convert_dicom(path)\n    \n    aug = alb.Compose([\n#         alb.RandomBrightnessContrast(p=1),\n        alb.Emboss(p=1),\n#         alb.Downscale(scale_min=0.1, scale_max=0.5,p=1),\n#         alb.Equalize(p=1),\n        alb.RandomGamma(p=1),\n    ])\n    \n    return aug(image=img)['image']","8962c2df":"study_level = pd.read_csv('..\/input\/siim-covid19-detection\/train_study_level.csv')\nstudy_level.head()","303803ac":"study_level['id'] = study_level.apply(lambda row: row.id.split('_')[0], axis=1)\nstudy_level['path'] = study_level.apply(lambda row: \"..\/input\/siim-covid19-detection\/train\/\"+row.id+'\/', axis=1)\n\nstudy_level.head(5)","25d58cf7":"labels = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\nstudy_level['label']=''\n\nget_labels(study_level)","c90cb79e":"study_level","6b4dbd1a":"train_images_path, train_images_labels = get_paths(study_level)\nlen(train_images_path), len(train_images_labels)","89485e02":"sns.countplot(study_level['Negative for Pneumonia'].value_counts())","946cb9ec":"sns.countplot(study_level['Typical Appearance'].value_counts())","7896e89e":"sns.countplot(study_level['Indeterminate Appearance'].value_counts())","3271dafe":"sns.countplot(study_level['Atypical Appearance'].value_counts())","9ca1a3da":"sns.countplot(study_level.label)","9b3aac2b":"dicom = dcmread(train_images_path[10])\nimg = dicom.pixel_array\nplot(img)\n\nprint(train_images_labels[10])","fa20abb7":"img = augmentations(train_images_path[10])\nplot(np.array(img))","8d2b89f7":"img = convert_dicom(train_images_path[5])\nretval, threshold = cv2.threshold(img, 2500, 255, cv2.THRESH_TOZERO_INV)\nplt.imshow(threshold)","e84a376f":"img = convert_dicom(train_images_path[5])\nretval, threshold = cv2.threshold(img, 2500, 255, cv2.THRESH_TOZERO)\nplt.imshow(threshold)","4d4d96d6":"img = convert_dicom(train_images_path[5])\nretval, threshold = cv2.threshold(img, 2500, 255, cv2.THRESH_TRUNC)\nplt.imshow(threshold)","1576aab2":"img = convert_dicom(train_images_path[5])\nretval, threshold = cv2.threshold(img, 2500, 255, cv2.THRESH_BINARY_INV)\nplt.imshow(threshold)","b3043da7":"img = convert_dicom(train_images_path[5])\nretval, threshold = cv2.threshold(img, 2500, 255, cv2.THRESH_BINARY)\nplt.imshow(threshold)","b6a459e4":"class FeatureExtractor(nn.Module):\n    def __init__(self, fil1, fil2, fil3):\n        super(FeatureExtractor, self).__init__()\n        self.conv1 = nn.Conv2d(1, 1, fil1)\n        self.conv2 = nn.Conv2d(1, 1, fil2)\n        self.conv3 = nn.Conv2d(1, 1, fil3)\n        \n    def forward(self, img):\n        img = self.conv1(img)\n        img = self.conv2(img)\n        img = self.conv3(img)\n        return img\n    \nmodel = FeatureExtractor(32, 32, 64)","8416e24f":"img = convert_dicom(train_images_path[10])\nimg = torch.Tensor(img.astype('float32')).unsqueeze(0).unsqueeze(0)\nplt.imshow(model(img).squeeze(0).squeeze(0).squeeze(0).detach().numpy())","24bc74c5":"## Albumentations","26af2380":"# Helper","a78867d3":"## Normal Deep 2D Convolution","3f16deb9":"# Class Distribution","b1b6620c":"# Image Visualization","413a8f11":"# Imports","afe8f1fc":"# Image and label segregation","864d8f43":"# Feature Extraction","f02583ef":"# Data processing","99d0bd7b":"## OpenCV Image Threshold"}}