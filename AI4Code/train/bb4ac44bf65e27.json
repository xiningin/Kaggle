{"cell_type":{"da8c72c0":"code","2d6bb1e1":"code","e1c21029":"code","fd04ac1d":"code","86a5a5fa":"code","a2c3eeaa":"code","52a58121":"code","22bd88a9":"code","199d3b2f":"code","fe06955d":"code","4223d42b":"code","b4445e74":"code","e730ffa5":"code","cba6bdec":"code","1deddd32":"code","548e537f":"code","a9fa640b":"code","fd335055":"code","b0cad4d6":"markdown","23ae851e":"markdown","133fd2ae":"markdown","8b39565b":"markdown","b08efeb0":"markdown"},"source":{"da8c72c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2d6bb1e1":"data = pd.read_csv('..\/input\/housedata\/data.csv')\ndata.columns","e1c21029":"#Eliminating the columnns which are not useful for prediction as of now\ndata = data.drop(columns=['country','statezip','city','street','date'])\ndata.columns","fd04ac1d":"data.tail(7)","86a5a5fa":"# Some operations on data so that gradient descent will converge faster\ndata = data-data.mean()\ndata","a2c3eeaa":"data=data\/data.std()\ndata","52a58121":"X=data[data.columns[2:]].to_numpy()\ntype(X)","22bd88a9":"a=np.ones((4600,1) )\ntype(a)\nX=np.append(a,X,axis=1)\nX","199d3b2f":"y=data['price'].to_numpy()\ny= np.reshape(y,(len(y),1))\ny","fe06955d":"X.shape","4223d42b":"# returns the value of cost function corresponding to parameters theta at given point\ndef cost(th,m):\n    h = np.matmul(X,th)\n    h = h - y\n    h= np.sum(np.square(h))\/2*m\n    return h\n    ","b4445e74":"cost(theta,4600)","e730ffa5":"def gradient_descent(alpha):\n    theta=np.zeros((12,1))\n    theta.shape\n    J=[]\n    it=[]\n    m=4600\n    #print(theta.shape)\n    for i in range(1,100001):\n        h = np.matmul(X,theta)\n        #print(h.shape)\n        h = h - y\n        #print(h.shape)\n        #print(X.shape)\n        h = np.sum(np.multiply(h,X),axis=0)*(alpha\/m)\n        theta = theta - h\n        J.append(cost(theta,m))\n        it.append(i)\n    print('complete')\n    return(J,it,theta)","cba6bdec":"# Plotting the cost function vs no. of iterations for different values of alpha\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n(J,it,theta)=gradient_descent(0.0001)\nplt.plot(it,J)\nplt.xlabel('Iterations ->')\nplt.ylabel('Cost function ->')\n","1deddd32":"(J,it,theta)=gradient_descent(0.0003)\nplt.plot(it,J)\nplt.xlabel('Iterations ->')\nplt.ylabel('Cost function ->')","548e537f":"(J,it,theta)=gradient_descent(0.00001)\nplt.plot(it,J)\nplt.xlabel('Iterations ->')\nplt.ylabel('Cost function ->')","a9fa640b":"(J,it,theta)=gradient_descent(0.00003)\nplt.plot(it,J)\nplt.xlabel('Iterations ->')\nplt.ylabel('Cost function ->')","fd335055":"(J,it,theta)=gradient_descent(0.0001)\nplt.plot(it,J)\nplt.xlabel('Iterations ->')\nplt.ylabel('Cost function ->')","b0cad4d6":"In the above examples value of alpha as 0.0001 seems the most suitable let us increase iterations to confirm cost function doesnot increase","23ae851e":"The value of cost function starts increasing which suggests our learning rate alpha is a higher value","133fd2ae":"Here gradient descent is converging very slowly and will need more iterations or a higher value of alpha","8b39565b":"The following is a take at solving multivariate linear regression through gradient descent to predict the cost of a house and checking its correctness by plotting the cost function vs number of Iterations","b08efeb0":"Therefore the correct form of hypothesis is given for learning rate at 0.0001, and the hypothesis formed by the given values of theta is a correct one."}}