{"cell_type":{"8481b1fb":"code","561315c8":"code","81e948fa":"code","5de46aa5":"code","35827dbe":"code","3c9dd1a8":"code","5d09a105":"code","9132f182":"code","523704d7":"code","35098c7d":"code","972a584e":"code","0361fecc":"code","759824b6":"code","ae85c152":"code","d93c51b6":"code","9fc4f174":"code","2a4b4984":"code","1ed27c88":"code","df7aec1c":"code","7dd11a98":"code","a63445bf":"code","9ede190e":"code","71d6f669":"code","abd09fc5":"code","6093fcc3":"code","89d0cd79":"code","e4cf5be2":"code","e200fd93":"code","813933b4":"code","7e132678":"code","1ae00a4c":"code","14f4aa6e":"code","c22d3d59":"code","628f60ee":"code","2687e2d8":"code","5844ebe8":"code","0f930335":"code","6929c9bf":"code","9c6ff5ea":"code","fe37a500":"code","abafb7db":"code","dfcef5d7":"code","1b378ed6":"code","d4756f56":"code","f73c6edb":"code","68b51123":"code","9429684e":"code","050f482a":"code","e904c0c1":"code","9975d05e":"code","4d61ea2a":"code","ae2d0d56":"code","4580e422":"code","6aa30df7":"code","76c345c5":"code","851c19a4":"code","96fdf2cf":"code","d401c2ed":"code","cbb77f1d":"code","0b708f78":"code","9f1d8cbc":"code","33c95df7":"code","c7c6ce6d":"code","b29c442c":"code","2c9c6909":"code","e834422e":"code","2c9f2cea":"code","9a349ec6":"code","52d1131d":"code","bf2cc3ff":"code","cede5c91":"code","2a447108":"markdown","425df1f2":"markdown","626857bd":"markdown","9828ab6a":"markdown","d6d9b2ac":"markdown","19e3fba8":"markdown","95c0969f":"markdown","24bb15dc":"markdown","32fb15eb":"markdown","0ed316b0":"markdown","2ed05412":"markdown","36c08c34":"markdown","7f45040a":"markdown","bf73f07d":"markdown","a02960f7":"markdown","ecec90ad":"markdown","d601f362":"markdown","77152636":"markdown","6ce0f03d":"markdown","6be823ed":"markdown","70a69288":"markdown","2b299f23":"markdown","55f799a4":"markdown","b00908e6":"markdown","96db81ca":"markdown","02da89da":"markdown","b3b12ec6":"markdown","2f5d6ffd":"markdown","1972faae":"markdown","031fc2e5":"markdown","0d7197c4":"markdown","7bec8df1":"markdown","f1dd6cba":"markdown","22692977":"markdown","34a062c0":"markdown","adfe3ecd":"markdown","f5a3d3d3":"markdown","c3065431":"markdown","a6125ea6":"markdown","e5e38957":"markdown","c600c96d":"markdown","fc2fea86":"markdown","ae5aedaa":"markdown","3c071389":"markdown","4c979100":"markdown","e41d5846":"markdown","3c6b7cc9":"markdown","813d815e":"markdown","f68bb9b5":"markdown","df7261a1":"markdown","ba090699":"markdown","dc6d3732":"markdown","e1c2fb5b":"markdown","2d3b3368":"markdown","4b7d6c19":"markdown","c5df13b2":"markdown","b16c7d4a":"markdown","037f3c9d":"markdown","3e224aae":"markdown","8085274f":"markdown","987f4ec4":"markdown","0ce03359":"markdown","1e8719b5":"markdown","baffed2a":"markdown","aea11f2b":"markdown","934ad542":"markdown","d3274775":"markdown","f2938e6e":"markdown","40be0ffa":"markdown","77ae90a2":"markdown","1af748bd":"markdown","0beaee0b":"markdown","71be906c":"markdown","9edc165e":"markdown","fc958a53":"markdown","200a8aea":"markdown","a0d8a58b":"markdown","8e99f95e":"markdown","ad969d7c":"markdown","aaf8f5a9":"markdown","c75747b4":"markdown","e8998ac8":"markdown","1f51bc26":"markdown","17b24861":"markdown","579871f2":"markdown","30846f4e":"markdown"},"source":{"8481b1fb":"from sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\nfrom pandas.api.types import is_string_dtype, is_numeric_dtype\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz\n\ndef get_sample(df,n):\n    \"\"\" Gets a random sample of n rows from df, without replacement.\n    Parameters:\n    -----------\n    df: A pandas data frame, that you wish to sample from.\n    n: The number of rows you wish to sample.\n    Returns:\n    --------\n    return value: A random sample of n rows of df.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    >>> get_sample(df, 2)\n       col1 col2\n    2     3    a\n    1     2    b\n    \"\"\"\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()\n\ndef proc_df(df, y_fld, skip_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n\n    \"\"\" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n    y_fld: The name of the response variable\n    skip_flds: A list of fields that dropped from df.\n    do_scale: Standardizes each column in df,Takes Boolean Values(True,False)\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n    preproc_fn: A function that gets applied to df.\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n    subset: Takes a random subset of size subset from df.\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time(mean and standard deviation).\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n        y: y is the response variable\n        nas: returns a dictionary of which nas it created, and the associated median.\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continous\n        variables which is then used for scaling of during test-time.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    note the type of col2 is string\n    >>> train_cats(df)\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    now the type of col2 is category { a : 1, b : 2}\n    >>> x, y, nas = proc_df(df, 'col1')\n    >>> x\n       col2\n    0     1\n    1     2\n    2     1\n    >>> data = DataFrame(pet=[\"cat\", \"dog\", \"dog\", \"fish\", \"cat\", \"dog\", \"cat\", \"fish\"],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    \"\"\"\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    df = df.copy()\n    if preproc_fn: preproc_fn(df)\n    y = df[y_fld].values\n    df.drop(skip_flds+[y_fld], axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    res = [pd.get_dummies(df, dummy_na=True), y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res\n\ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\ndef set_rf_samples(n):\n    \"\"\" Changes Scikit learn's random forests to give each tree a random sample of\n    n random rows.\n    \"\"\"\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n))\n\ndef reset_rf_samples():\n    \"\"\" Undoes the changes produced by set_rf_samples.\n    \"\"\"\n    forest._generate_sample_indices = (lambda rs, n_samples:\n        forest.check_random_state(rs).randint(0, n_samples, n_samples))","561315c8":"# For autoreloading modules\n%load_ext autoreload\n%autoreload 2\n# For notebook plotting\n%matplotlib inline\n\n# Standard libraries\nimport os\nimport numpy as np\nimport pandas as pd\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pdpbox import pdp\nfrom plotnine import *\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor\nfrom IPython.display import display\n\n# Machine Learning\nimport sklearn\nfrom sklearn import metrics\nfrom scipy.cluster import hierarchy as hc\nfrom fastai.imports import *\n\n# Directories\nKAGGLE_DIR = '..\/input\/'\n\n# Info about dataset\nprint('Files and directories: \\n{}\\n'.format(os.listdir(\"..\/input\")))\n\nprint('\\n# File sizes')\nfor file in os.listdir(KAGGLE_DIR):\n    print('{}| {} MB'.format(file.ljust(30), \n                             str(round(os.path.getsize(KAGGLE_DIR + file) \/ 1000000, 2))))","81e948fa":"# Import dataset\ntrain = pd.read_csv(KAGGLE_DIR + 'train_V2.csv')\ntest = pd.read_csv(KAGGLE_DIR + 'test_V2.csv')","5de46aa5":"# First five rows (From Head)\nprint('First 5 rows: ')\ndisplay(train.head())\n\n# Last five rows (To Tail)\nprint('Last 5 rows: ')\ndisplay(train.tail())","35827dbe":"# Stats\ntrain.describe()","3c9dd1a8":"# Types, Data points, memory usage, etc.\ntrain.info()\n\n# Check dataframe's shape\nprint('Shape of training set: ', train.shape)","5d09a105":"# Use this code if you want to store and read DataFrames in a feather format\n# os.makedirs('tmp', exist_ok=True)\n# train.to_feather('tmp\/PUBG')\n# df_raw = pd.read_feather('tmp\/PUBG')","9132f182":"# Check row with NaN value\ntrain[train['winPlacePerc'].isnull()]","523704d7":"# Drop row with NaN 'winPlacePerc' value\ntrain.drop(2744604, inplace=True)","35098c7d":"# The row at index 2744604 will be gone\ntrain[train['winPlacePerc'].isnull()]","972a584e":"# playersJoined\ntrain['playersJoined'] = train.groupby('matchId')['matchId'].transform('count')\nplt.figure(figsize=(15,10))\nsns.countplot(train[train['playersJoined']>=75]['playersJoined'])\nplt.title('playersJoined')\nplt.show()","0361fecc":"# Create normalized features\ntrain['killsNorm'] = train['kills']*((100-train['playersJoined'])\/100 + 1)\ntrain['damageDealtNorm'] = train['damageDealt']*((100-train['playersJoined'])\/100 + 1)\ntrain['maxPlaceNorm'] = train['maxPlace']*((100-train['playersJoined'])\/100 + 1)\ntrain['matchDurationNorm'] = train['matchDuration']*((100-train['playersJoined'])\/100 + 1)\n# Compare standard features and normalized features\nto_show = ['Id', 'kills','killsNorm','damageDealt', 'damageDealtNorm', 'maxPlace', 'maxPlaceNorm', 'matchDuration', 'matchDurationNorm']\ntrain[to_show][0:11]","759824b6":"# Create new feature healsandboosts\ntrain['healsandboosts'] = train['heals'] + train['boosts']\ntrain[['heals', 'boosts', 'healsandboosts']].tail()","ae85c152":"# Create feature totalDistance\ntrain['totalDistance'] = train['rideDistance'] + train['walkDistance'] + train['swimDistance']\n# Create feature killsWithoutMoving\ntrain['killsWithoutMoving'] = ((train['kills'] > 0) & (train['totalDistance'] == 0))","d93c51b6":"# Create headshot_rate feature\ntrain['headshot_rate'] = train['headshotKills'] \/ train['kills']\ntrain['headshot_rate'] = train['headshot_rate'].fillna(0)","9fc4f174":"# Check players who kills without moving\ndisplay(train[train['killsWithoutMoving'] == True].shape)\ntrain[train['killsWithoutMoving'] == True].head(10)","2a4b4984":"# Remove outliers\ntrain.drop(train[train['killsWithoutMoving'] == True].index, inplace=True)","1ed27c88":"# Players who got more than 10 roadKills\ntrain[train['roadKills'] > 10]","df7aec1c":"# Drop roadKill 'cheaters'\ntrain.drop(train[train['roadKills'] > 10].index, inplace=True)","7dd11a98":"# Plot the distribution of kills\nplt.figure(figsize=(12,4))\nsns.countplot(data=train, x=train['kills']).set_title('Kills')\nplt.show()","a63445bf":"# Players who got more than 30 kills\ndisplay(train[train['kills'] > 30].shape)\ntrain[train['kills'] > 30].head(10)","9ede190e":"# Remove outliers\ntrain.drop(train[train['kills'] > 30].index, inplace=True)","71d6f669":"# Plot the distribution of headshot_rate\nplt.figure(figsize=(12,4))\nsns.distplot(train['headshot_rate'], bins=10)\nplt.show()","abd09fc5":"# Players who made a minimum of 10 kills and have a headshot_rate of 100%\ndisplay(train[(train['headshot_rate'] == 1) & (train['kills'] > 9)].shape)\ntrain[(train['headshot_rate'] == 1) & (train['kills'] > 9)].head(10)","6093fcc3":"# Plot the distribution of longestKill\nplt.figure(figsize=(12,4))\nsns.distplot(train['longestKill'], bins=10)\nplt.show()","89d0cd79":"# Check out players who made kills with a distance of more than 1 km\ndisplay(train[train['longestKill'] >= 1000].shape)\ntrain[train['longestKill'] >= 1000].head(10)","e4cf5be2":"# Remove outliers\ntrain.drop(train[train['longestKill'] >= 1000].index, inplace=True)","e200fd93":"# Summary statistics for the Distance features\ntrain[['walkDistance', 'rideDistance', 'swimDistance', 'totalDistance']].describe()","813933b4":"# Plot the distribution of walkDistance\nplt.figure(figsize=(12,4))\nsns.distplot(train['walkDistance'], bins=10)\nplt.show()","7e132678":"# walkDistance anomalies\ndisplay(train[train['walkDistance'] >= 10000].shape)\ntrain[train['walkDistance'] >= 10000].head(10)","1ae00a4c":"# Remove outliers\ntrain.drop(train[train['walkDistance'] >= 10000].index, inplace=True)","14f4aa6e":"# Plot the distribution of rideDistance\nplt.figure(figsize=(12,4))\nsns.distplot(train['rideDistance'], bins=10)\nplt.show()","c22d3d59":"# rideDistance anomalies\ndisplay(train[train['rideDistance'] >= 20000].shape)\ntrain[train['rideDistance'] >= 20000].head(10)","628f60ee":"# Remove outliers\ntrain.drop(train[train['rideDistance'] >= 20000].index, inplace=True)","2687e2d8":"# Plot the distribution of swimDistance\nplt.figure(figsize=(12,4))\nsns.distplot(train['swimDistance'], bins=10)\nplt.show()","5844ebe8":"# Players who swam more than 2 km\ntrain[train['swimDistance'] >= 2000]","0f930335":"# Remove outliers\ntrain.drop(train[train['swimDistance'] >= 2000].index, inplace=True)","6929c9bf":"# Plot the distribution of weaponsAcquired\nplt.figure(figsize=(12,4))\nsns.distplot(train['weaponsAcquired'], bins=100)\nplt.show()","9c6ff5ea":"# Players who acquired more than 80 weapons\ndisplay(train[train['weaponsAcquired'] >= 80].shape)\ntrain[train['weaponsAcquired'] >= 80].head()","fe37a500":"# Remove outliers\ntrain.drop(train[train['weaponsAcquired'] >= 80].index, inplace=True)","abafb7db":"# Distribution of heals\nplt.figure(figsize=(12,4))\nsns.distplot(train['heals'], bins=10)\nplt.show()","dfcef5d7":"# 40 or more healing items used\ndisplay(train[train['heals'] >= 40].shape)\ntrain[train['heals'] >= 40].head(10)","1b378ed6":"# Remove outliers\ntrain.drop(train[train['heals'] >= 40].index, inplace=True)","d4756f56":"# Remaining players in the training set\ntrain.shape","f73c6edb":"print('There are {} different Match types in the dataset.'.format(train['matchType'].nunique()))","68b51123":"# One hot encode matchType\ntrain = pd.get_dummies(train, columns=['matchType'])\n\n# Take a look at the encoding\nmatchType_encoding = train.filter(regex='matchType')\nmatchType_encoding.head()","9429684e":"# Turn groupId and match Id into categorical types\ntrain['groupId'] = train['groupId'].astype('category')\ntrain['matchId'] = train['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\ntrain['groupId_cat'] = train['groupId'].cat.codes\ntrain['matchId_cat'] = train['matchId'].cat.codes\n\n# Get rid of old columns\ntrain.drop(columns=['groupId', 'matchId'], inplace=True)\n\n# Lets take a look at our newly created features\ntrain[['groupId_cat', 'matchId_cat']].head()","050f482a":"# Drop Id column, because it probably won't be useful for our Machine Learning algorithm,\n# because the test set contains different Id's\ntrain.drop(columns = ['Id'], inplace=True)","e904c0c1":"# Take sample for debugging and exploration\nsample = 500000\ndf_sample = train.sample(sample)","9975d05e":"# Split sample into training data and target variable\ndf = df_sample.drop(columns = ['winPlacePerc']) #all columns except target\ny = df_sample['winPlacePerc'] # Only target variable","4d61ea2a":"# Function for splitting training and validation data\ndef split_vals(a, n : int): \n    return a[:n].copy(), a[n:].copy()\nval_perc = 0.12 # % to use for validation set\nn_valid = int(val_perc * sample) \nn_trn = len(df)-n_valid\n# Split data\nraw_train, raw_valid = split_vals(df_sample, n_trn)\nX_train, X_valid = split_vals(df, n_trn)\ny_train, y_valid = split_vals(y, n_trn)\n\n# Check dimensions of samples\nprint('Sample train shape: ', X_train.shape, \n      'Sample target shape: ', y_train.shape, \n      'Sample validation shape: ', X_valid.shape)","ae2d0d56":"# Metric used for the PUBG competition (Mean Absolute Error (MAE))\nfrom sklearn.metrics import mean_absolute_error\n\n# Function to print the MAE (Mean Absolute Error) score\n# This is the metric used by Kaggle in this competition\ndef print_score(m : RandomForestRegressor):\n    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train), \n           'mae val: ', mean_absolute_error(m.predict(X_valid), y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","4580e422":"# Train basic model\nm1 = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features='sqrt',\n                          n_jobs=-1)\nm1.fit(X_train, y_train)\nprint_score(m1)","6aa30df7":"# What are the most predictive features according to our basic random forest model\nfi = rf_feat_importance(m1, df); fi[:10]","76c345c5":"# Plot a feature importance graph for the 20 most important features\nplot1 = fi[:20].plot('cols', 'imp', figsize=(14,6), legend=False, kind = 'barh')\nplot1","851c19a4":"# Use this code if you want to save the figure\n#fig = plot1.get_figure()\n#fig.savefig(\"Feature_importances(AllFeatures).png\")","96fdf2cf":"# Keep only significant features\nto_keep = fi[fi.imp>0.005].cols\nprint('Significant features: ', len(to_keep))\nto_keep","d401c2ed":"# Make a DataFrame with only significant features\ndf_keep = df[to_keep].copy()\nX_train, X_valid = split_vals(df_keep, n_trn)","cbb77f1d":"# Train model on top features\nm2 = RandomForestRegressor(n_estimators=80, min_samples_leaf=3, max_features='sqrt',\n                          n_jobs=-1)\nm2.fit(X_train, y_train)\nprint_score(m2)","0b708f78":"# Get feature importances of our top features\nfi_to_keep = rf_feat_importance(m2, df_keep)\nplot2 = fi_to_keep.plot('cols', 'imp', figsize=(14,6), legend=False, kind = 'barh')\nplot2\n\n# Use this code if you want to save the figure\n#fig = plot2.get_figure()\n#fig.savefig(\"Feature_importances(TopFeatures).png\")","9f1d8cbc":"# Create a Dendrogram to view highly correlated features\ncorr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(14,10))\ndendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)\nplt.plot()","33c95df7":"# Use this code if you want to save the figure\n#plt.savefig('Dendrogram.png')","c7c6ce6d":"# Correlation heatmap\ncorr = df_keep.corr()\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Create heatmap\nheatmap = sns.heatmap(corr)","b29c442c":"# Use this code if you want to save the figure\n#fig = heatmap.get_figure()\n#fig.savefig(\"Heatmap(TopFeatures).png\")","2c9c6909":"# Plot the predictive quality of kills \nx_all = get_sample(train, 100000)\nggplot(x_all, aes('kills','winPlacePerc'))+stat_smooth(se=True, colour='red', method='mavg')","e834422e":"# Plot the predictive quality of walkDistance\nx_all = get_sample(train, 100000)\nggplot(x_all, aes('walkDistance','winPlacePerc'))+stat_smooth(se=True, colour='red', method='mavg')","2c9f2cea":"# Prepare data\nval_perc_full = 0.12 # % to use for validation set\nn_valid_full = int(val_perc_full * len(train)) \nn_trn_full = len(train)-n_valid_full\ndf_full = train.drop(columns = ['winPlacePerc']) # all columns except target\ny = train['winPlacePerc'] # target variable\ndf_full = df_full[to_keep] # Keep only relevant features\nX_train, X_valid = split_vals(df_full, n_trn_full)\ny_train, y_valid = split_vals(y, n_trn_full)\n\n# Check dimensions of data\nprint('Sample train shape: ', X_train.shape, \n      'Sample target shape: ', y_train.shape, \n      'Sample validation shape: ', X_valid.shape)","9a349ec6":"# Train final model\n# You should get better results by increasing n_estimators\n# and by playing around with the parameters\nm3 = RandomForestRegressor(n_estimators=70, min_samples_leaf=3, max_features=0.5,\n                          n_jobs=-1)\nm3.fit(X_train, y_train)\nprint_score(m3)","52d1131d":"# Add engineered features to the test set\ntest['headshot_rate'] = test['headshotKills'] \/ test['kills']\ntest['headshot_rate'] = test['headshot_rate'].fillna(0)\ntest['totalDistance'] = test['rideDistance'] + test['walkDistance'] + test['swimDistance']\ntest['playersJoined'] = test.groupby('matchId')['matchId'].transform('count')\ntest['killsNorm'] = test['kills']*((100-test['playersJoined'])\/100 + 1)\ntest['damageDealtNorm'] = test['damageDealt']*((100-test['playersJoined'])\/100 + 1)\ntest['maxPlaceNorm'] = test['maxPlace']*((100-train['playersJoined'])\/100 + 1)\ntest['matchDurationNorm'] = test['matchDuration']*((100-test['playersJoined'])\/100 + 1)\ntest['healsandboosts'] = test['heals'] + test['boosts']\ntest['killsWithoutMoving'] = ((test['kills'] > 0) & (test['totalDistance'] == 0))\n\n# Turn groupId and match Id into categorical types\ntest['groupId'] = test['groupId'].astype('category')\ntest['matchId'] = test['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\ntest['groupId_cat'] = test['groupId'].cat.codes\ntest['matchId_cat'] = test['matchId'].cat.codes\n\n# Remove irrelevant features from the test set\ntest_pred = test[to_keep].copy()\n\n# Fill NaN with 0 (temporary)\ntest_pred.fillna(0, inplace=True)\ntest_pred.head()","bf2cc3ff":"# Make submission ready for Kaggle\n# We use our final Random Forest model (m3) to get the predictions\npredictions = np.clip(a = m3.predict(test_pred), a_min = 0.0, a_max = 1.0)\npred_df = pd.DataFrame({'Id' : test['Id'], 'winPlacePerc' : predictions})\n\n# Create submission file\npred_df.to_csv(\"submission.csv\", index=False)","cede5c91":"# Last check of submission\nprint('Head of submission: ')\ndisplay(pred_df.head())\nprint('Tail of submission: ')\ndisplay(pred_df.tail())","2a447108":"**Dendrogram (to view correlation of features)**","425df1f2":"**Feature importance for top features**","626857bd":"Some rows in our dataset have weird characteristics. The players could be cheaters, maniacs or just anomalies. Removing these outliers will likely improve results.\n\nInspiration for this section comes from [this amazing Kaggle Kernel.](https:\/\/www.kaggle.com\/rejasupotaro\/cheaters-and-zombies)","9828ab6a":"Let's plot the total kills for every player first. It doesn't look like there are too many outliers.","d6d9b2ac":"It is unclear if these players are cheating so we are probably not deleting these players from the dataset.\nIf they are legitimate players, they are probably really crushing the game!\n\n![Alt Text](https:\/\/media.giphy.com\/media\/l3mZrOajz5VCZf7Hy\/giphy.gif)\n","19e3fba8":"# Categorical Variables <a id=\"7\"><\/a>","95c0969f":"# Initial Exploration <a id=\"3\"><\/a>","24bb15dc":"Let's look at the DataFrame from head to tail.","32fb15eb":"Let's take a look at the players who make these shots.","0ed316b0":"**Correlation Heatmap**","2ed05412":"* [Preparation](#1)\n* [Extra Data (Coming Soon)](#2)\n* [Initial Exploration](#3)\n* [Illegal Match](#4)\n* [Feature Engineering](#5)\n* [Outlier Detection](#6)\n* [Categorical Variables](#7)\n* [Preparation for Machine Learning](#8)\n* [Feature Importance](#9)\n* [Final Random Forest Model](#10)\n* [Kaggle Submission](#11)\n","36c08c34":"The [fastai](https:\/\/www.fast.ai\/) library gives us an easy way to analyze feature importances from a random forest algorithm with just one line of code!","7f45040a":"This is likely a very valuable feature for our model. If we know how many people are in a match we can normalize other features and get stronger predictions on individual players.","bf73f07d":"# Final Random Forest Model <a id=\"10\"><\/a>","a02960f7":"Summary Statistics of the training data.","ecec90ad":"Do you think these guys are legit?\n\n![Alt Text](https:\/\/thumbs.gfycat.com\/EvenSpiffyFerret-size_restricted.gif)","d601f362":"# Table of Contents","77152636":"We will take a sample of 500000 rows from our training set for easy debugging and exploration.","6ce0f03d":"![Alt Text](https:\/\/media.giphy.com\/media\/OPRbXcsGctvZC\/giphy.gif)","6be823ed":"# Feature Importance <a id=\"9\"><\/a>","70a69288":"## Split target variable, validation data, etc.","2b299f23":"Let's take a closer look.","55f799a4":"## Sampling","b00908e6":"**Kills without movement**","96db81ca":"We try to identify cheaters by checking if people are getting kills without moving. We first identify the totalDistance travelled by a player and then set a boolean value to True if someone got kills without moving a single inch. We will remove cheaters in our outlier detection section.","02da89da":"Earlier in this kernel we created the new features ''totalDistance'' and  ''headshot_rate\". In this section we add more interesting features to improve the predictive quality of our machine learning models.\n\nInitial ideas for this section come from [this amazing kernel](https:\/\/www.kaggle.com\/deffro\/eda-is-fun).\n\nNote: It is important with feature engineering that you also add the engineered features to your test set!","b3b12ec6":"## Second Random Forest Model","2f5d6ffd":"### Players Joined","1972faae":"# Feature Engineering <a id=\"5\"><\/a>","031fc2e5":"**swimDistance**","0d7197c4":"There is something fishy going on with these players. We are probably better off removing them from our dataset.\n\n![Alt Text](https:\/\/media.giphy.com\/media\/RHJkLqcdvMQF4GI3P7\/giphy.gif)","7bec8df1":"What do you think? Should we remove all these outliers from our dataset?","f1dd6cba":"# Preparation <a id=\"1\"><\/a>","22692977":"## Set metrics (MAE)","34a062c0":"First we import the dependencies needed for handling data, visualization and training our model. \n\nImportant dependencies are:\n* [Pandas](https:\/\/pandas.pydata.org) for their dataframe structures and easy visualization.\n* [Matplotlib](https:\/\/matplotlib.org) for visualization.\n* [Scikit-learn](https:\/\/scikit-learn.org\/stable) for machine learning.\n* [fastai](https:\/\/www.fast.ai) for machine learning and feature importance.","adfe3ecd":"We should probably remove these outliers from our model. Do you agree?\n\nNote that player 3f2bcf53b108c4 acquired 236 weapons in one game!\n\n![Alt Text](https:\/\/media.giphy.com\/media\/69lWR6c8Afx9qeg2Tu\/giphy.gif)","f5a3d3d3":"## Correlations","c3065431":"# Preparation for Machine Learning <a id=\"8\"><\/a>","a6125ea6":"# Kaggle Submission <a id=\"11\"><\/a>","e5e38957":"# Let's Go!","c600c96d":"**Check of submission file**","fc2fea86":"**Predictive quality of kills**","ae5aedaa":"The feature headshot_rate will also help us to catch cheaters.","3c071389":"**Anomalies in supplies (weaponsAcquired)**\n\nMost people acquire between 0 and 10 weapons in a game, but you also see some people acquire more than 80 weapons! Let's check these guys out.","4c979100":"Let's delete this entry:","e41d5846":"Again, we first take a look at the whole dataset and create a new feature 'headshot_rate'.\nWe see that the most players score in the 0 to 10% region. However, there are a few anomalies that have a headshot_rate of 100% percent with more than 9 kills!","3c6b7cc9":"Fellow Kaggler '[averagemn](https:\/\/www.kaggle.com\/donkeys)' brought to our attention that there is one particular player with a 'winPlacePerc' of NaN. The case was that this match had only one player. We will delete this row from our dataset.","813d815e":"**rideDistance**","f68bb9b5":"### Heals and Boosts","df7261a1":"It is always nice to take a look at few of your predictions to make sure that the structure is right for a Kaggle submission.","ba090699":"**Normalize features**","dc6d3732":"# Outlier Detection <a id=\"6\"><\/a>","e1c2fb5b":"**Predictive quality of walkDistance**","2d3b3368":"Note that player c3e444f7d1289d drove 5 meters but killed 14 people with it. Sounds insane doesn't it?\n\n![Alt Text](https:\/\/media.giphy.com\/media\/3o7aD85usFbbbrCR3i\/giphy.gif)","4b7d6c19":"**Anomalies in roadKills**","c5df13b2":"**Anomalies in travelling (rideDistance, walkDistance and swimDistance)**\n\nLet's check out anomalies in Distance travelled.","b16c7d4a":"### Killing without moving","037f3c9d":"There are a few matches with fewer than 75 players that are not displayed here. As you can see most of the matches are nearly packed a have nearly 100 players. It is nevertheless interesting to take these features into our analysis.","3e224aae":"### Feature descriptions (From Kaggle)\n\n* DBNOs - Number of enemy players knocked.\n* assists - Number of enemy players this player damaged that were killed by teammates.\n* boosts - Number of boost items used.\n* damageDealt - Total damage dealt. Note: Self inflicted damage is subtracted.\n* headshotKills - Number of enemy players killed with headshots.\n* heals - Number of healing items used.\n* Id - Player\u2019s Id\n* killPlace - Ranking in match of number of enemy players killed.\n* killPoints - Kills-based external ranking of player. (Think of this as an Elo ranking where only kills matter.) If there is a value other than -1 in rankPoints, then any 0 in killPoints should be treated as a \u201cNone\u201d.\n* killStreaks - Max number of enemy players killed in a short amount of time.\n* kills - Number of enemy players killed.\n* longestKill - Longest distance between player and player killed at time of death. This may be misleading, as downing a player and driving away may lead to a large longestKill stat.\n* matchDuration - Duration of match in seconds.\n* matchId - ID to identify match. There are no matches that are in both the training and testing set.\n* matchType - String identifying the game mode that the data comes from. The standard modes are \u201csolo\u201d, \u201cduo\u201d, \u201csquad\u201d, \u201csolo-fpp\u201d, \u201cduo-fpp\u201d, and \u201csquad-fpp\u201d; other modes are from events or custom matches.\n* rankPoints - Elo-like ranking of player. This ranking is inconsistent and is being deprecated in the API\u2019s next version, so use with caution. Value of -1 takes place of \u201cNone\u201d.\n* revives - Number of times this player revived teammates.\n* rideDistance - Total distance traveled in vehicles measured in meters.\n* roadKills - Number of kills while in a vehicle.\n* swimDistance - Total distance traveled by swimming measured in meters.\n* teamKills - Number of times this player killed a teammate.\n* vehicleDestroys - Number of vehicles destroyed.\n* walkDistance - Total distance traveled on foot measured in meters.\n* weaponsAcquired - Number of weapons picked up.\n* winPoints - Win-based external ranking of player. (Think of this as an Elo ranking where only winning matters.) If there is a value other than -1 in rankPoints, then any 0 in winPoints should be treated as a \u201cNone\u201d.\n* groupId - ID to identify a group within a match. If the same group of players plays in different matches, they will have a different groupId each time.\n* numGroups - Number of groups we have data for in the match.\n* maxPlace - Worst placement we have data for in the match. This may not match with numGroups, as sometimes the data skips over placements.\n* winPlacePerc - The target of prediction. This is a percentile winning placement, where 1 corresponds to 1st place, and 0 corresponds to last place in the match. It is calculated off of maxPlace, not numGroups, so it is possible to have missing chunks in a match.\n\n[Source](https:\/\/www.kaggle.com\/c\/pubg-finish-placement-prediction\/data)","8085274f":"This is perhaps the most obvious sign of cheating in the game. It is already fishy if a player hasn't moved during the whole game, but the player could be AFK and got killed. However, if the player managed to get kills without moving it is most likely a cheater.","987f4ec4":"Got the suckers! ","0ce03359":"**Anomalies in supplies part 2 (heals)**\n\nMost players us 5 healing items or less. We can again recognize some weird anomalies","1e8719b5":"[Mean Absolute Error (MAE)](https:\/\/en.wikipedia.org\/wiki\/Mean_absolute_error) is the metric that is used for this competition. The scikit-learn library already programmed this metric for us so we don't have to implement it from scratch.","baffed2a":"![API Img](http:\/\/media.comicbook.com\/2018\/03\/pubg-api-1093349.jpeg)\n","aea11f2b":"### Normalized features","934ad542":"We create a feature called 'healsandboosts' by adding heals and boosts. (duh!) We are not sure if this has additional predictive value, but we can always delete it later if the feature importance according to our random forest model is too low.","d3274775":"Most kills are made from a distance of 100 meters or closer. There are however some outliers who make a kill from more than 1km away. This is probably done by cheaters.","f2938e6e":"**voil\u00e0!**","40be0ffa":"This time we use only the top features to train a random forest model. This often improves results a little bit.","77ae90a2":"**Anomalies in aim part 2 (100% headshot rate)**","1af748bd":"![Alt Text](https:\/\/media.giphy.com\/media\/xT9IgnOQS8e8uKkflK\/giphy.gif)","0beaee0b":"**Anomalies in aim part 3 (Longest kill)**","71be906c":"Cheaters or do they just like to ride like these guys?\n\n![Alt Text](https:\/\/media.giphy.com\/media\/qlCFjkSruesco\/giphy.gif)","9edc165e":"## First basic Random Forest Model","fc958a53":"There are a lot of groupId's and matchId's so one-hot encoding them is computational suicide.\nWe will turn them into category codes. That way we can still benefit from correlations between groups and matches in our Random Forest algorithm.","200a8aea":"Now that we have a feature 'playersJoined' we can normalize other features based on the amount of players. Features that can be valuable to normalize are:\n1. kills\n2. damageDealt\n3. maxPlace\n4. matchDuration\n\nLet's try out some things!","a0d8a58b":"**walkDistance**","8e99f95e":"**Outlier conclusions**","ad969d7c":"And he's gone!","aaf8f5a9":"# Illegal Match <a id=\"4\"><\/a>","c75747b4":"We removed about 2000 players from our dataset. Do you think this is too much? Please let us know in the comments.","e8998ac8":"And of course, we import our data from the Kaggle kernel directory and load it into two different DataFrames. one for the training data and one for the test data.","1f51bc26":"Data types, memory usage, shape, etc.","17b24861":"**Anomalies in aim (More than 45 kills)**","579871f2":"# PUBG Data Exploration + Random Forest (+ Funny GIFs)","30846f4e":"We will one hot encode the 'matchType' feature to use it in our Random Forest model."}}