{"cell_type":{"80513cba":"code","74889f33":"code","56e95708":"code","63be6c9b":"code","955147ed":"code","5080eb1a":"code","a25919c2":"code","0d712aac":"code","051b84ca":"code","1bef0810":"code","8c98fe6d":"code","fc0a825b":"code","55421ad4":"code","21315fd5":"code","c9ab4fea":"code","824da548":"code","58b8a285":"code","64c71874":"code","33fc399b":"code","9e5994ee":"code","4cbc7e10":"code","3f9b9aab":"code","775858e6":"code","b7a81d43":"code","328324ab":"code","529b2f7e":"code","1effee75":"code","c1ab0a6c":"code","5569932f":"code","e482f072":"markdown","218569bf":"markdown","cf1cf199":"markdown","c1e4a704":"markdown","d45f471e":"markdown","23d302e0":"markdown","346c36eb":"markdown","b0aeb885":"markdown","4dfed8cd":"markdown","302f5814":"markdown","6f45d3e0":"markdown","3da0613f":"markdown","13f1a303":"markdown","99983431":"markdown","570894aa":"markdown","0beea923":"markdown","c6dad964":"markdown","3de15cf5":"markdown","8a30d099":"markdown","167bc5d3":"markdown","b79ba3e4":"markdown","00375cd2":"markdown","ed5e0c79":"markdown","ee151dc4":"markdown","5d5852c2":"markdown","12cba4aa":"markdown","acc1cabf":"markdown"},"source":{"80513cba":"import numpy as np \nimport pandas as pd \n\n# graphics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# modeling\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","74889f33":"credit_card = pd.read_csv('..\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv')\n\ncredit_card.drop(columns='ID', inplace=True) # drop ID, as this is irrelevant\n\ncredit_card.rename(columns={'default.payment.next.month':'default'}, inplace=True)","56e95708":"credit_card.head()","63be6c9b":"credit_card.info()","955147ed":"credit_card.describe()","5080eb1a":"credit_card.isnull().sum()","a25919c2":"# count \n\nplt.figure(figsize=(6,6))\nsns.countplot(data=credit_card, x='default')\nplt.title('default', size=19)\nplt.show()","0d712aac":"print('non-default:', len(credit_card.default) - sum(credit_card.default))\nprint('default:', sum(credit_card.default))","051b84ca":"plt.figure(figsize=(6,6))\nsns.countplot(data=credit_card, x='default', hue='SEX')\nplt.title('default', size=19)\nplt.show()","1bef0810":"plt.figure(figsize=(6,6))\nsns.countplot(data=credit_card, x='default', hue='EDUCATION')\nplt.title('default', size=19)\nplt.show()","8c98fe6d":"plt.figure(figsize=(6,6))\nsns.countplot(data=credit_card, x='default', hue='MARRIAGE')\nplt.title('default', size=19)\nplt.show()","fc0a825b":"plt.figure(figsize=(6,6))\nsns.distplot(credit_card.AGE)\nplt.title('Age', size=19)\nplt.show()","55421ad4":"non_default = credit_card.loc[credit_card.default == 0]\ndefault = credit_card.loc[credit_card.default == 1]\n\nplt.figure(figsize=(6,6))\nsns.distplot(non_default.AGE)\nplt.title('non-default', size=19)\nplt.show()\n\nplt.figure(figsize=(6,6))\nsns.distplot(non_default.AGE)\nplt.title('default', size=19)\nplt.show()","21315fd5":"cc = credit_card.copy()\n\n# base X and y\ny = cc.iloc[:,-1]\nX = cc.iloc[:,0:-1]\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=10)\n\nprint('x_train:', x_train.shape)\nprint('x_test:', x_test.shape)\nprint('y_train:', y_train.shape)\nprint('y_test:', y_test.shape)","c9ab4fea":"# proportion of 0 and 1 in train\/test, just to make sure train and test had same distribution\n\nprint(y_train.value_counts()\/len(y_train))\nprint('\\n')\nprint(y_test.value_counts()\/len(y_test))","824da548":"model = XGBClassifier(scale_pos_weight=3.52, eval_metric='auc')\nmodel.fit(x_train, y_train)","58b8a285":"pred = model.predict_proba(x_test)\nroc_auc_score(y_test, pred[:,1])","64c71874":"# tune scale_pos_weight\n\nmodel = XGBClassifier()\n\nscale_pos_weight = [3.45, 3.5, 3.55, 3.6, 3.65]\nparam = dict(scale_pos_weight = scale_pos_weight)\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\ngrid_search = GridSearchCV(model, param, scoring='roc_auc', n_jobs = -1, cv=kfold)\ngrid_result = grid_search.fit(X, y)\n\nprint('best cv score:', grid_result.best_score_, grid_result.best_params_)\n\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\n\nfor mean, std, param in zip(means, stds, params):\n    print('%f, (%f),%r' % (mean, std, param))\n\nplt.errorbar(scale_pos_weight, means, yerr=stds)\nplt.title('CV error vs n_estimators')\nplt.show()","33fc399b":"# # tune n_estimator\n\n# model = XGBClassifier(scale_pos_weight=3.65, eval_metric='auc')\n\n# # n_estimators : 50 ~ 400\n# n_estimators = range(50, 400, 50)\n# param = dict(n_estimators = n_estimators)\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n# grid_search = GridSearchCV(model, param, scoring='roc_auc', n_jobs = -1, cv=kfold)\n# grid_result = grid_search.fit(X, y)\n\n# print('best cv score:', grid_result.best_score_, grid_result.best_params_)\n\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n\n# for mean, std, param in zip(means, stds, params):\n#     print('%f, (%f),%r' % (mean, std, param))\n\n# plt.errorbar(n_estimators, means, yerr=stds)\n# plt.title('CV error vs n_estimators')\n# plt.show()","9e5994ee":"# # tune tree size\n\n# model = XGBClassifier(scale_pos_weight=3.65, eval_metric='auc')\n\n# # tree depth = 1,3,5,7,9\n# max_depth = [1,3,5,7,9]\n# param = dict(max_depth = max_depth)\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n# grid_search = GridSearchCV(model, param, scoring='roc_auc', n_jobs = -1, cv=kfold)\n# grid_result = grid_search.fit(X, y)\n\n# print('best cv score:', grid_result.best_score_, grid_result.best_params_)\n\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n\n# for mean, std, param in zip(means, stds, params):\n#     print('%f, (%f),%r' % (mean, std, param))\n\n# plt.errorbar(max_depth, means, yerr=stds)\n# plt.title('CV error vs max_depth')\n# plt.show()","4cbc7e10":"# # tune learning rate\n\n# model = XGBClassifier(scale_pos_weight=3.65, eval_metric='auc')\n\n# # learning rate\n# learning_rate = [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3]\n# param = dict(learning_rate = learning_rate)\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n# grid_search = GridSearchCV(model, param, scoring='roc_auc', n_jobs = -1, cv=kfold)\n# grid_result = grid_search.fit(X, y)\n\n# print('best cv score:', grid_result.best_score_, grid_result.best_params_)\n\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n\n# for mean, std, param in zip(means, stds, params):\n#     print('%f, (%f),%r' % (mean, std, param))\n\n# plt.errorbar(learning_rate, means, yerr=stds)\n# plt.title('CV error vs learning rate')\n# plt.show()","3f9b9aab":"# # tune learning rate and n_estimator\n\n# model = XGBClassifier(scale_pos_weight=3.65, eval_metric='auc')\n\n# # learning rate and n_estimator\n# learning_rate = [0.005, 0.01, 0.05, 0.1, 0.2]\n# n_estimators = [50, 100, 200, 300, 400]\n# param = dict(learning_rate = learning_rate, n_estimators=n_estimators)\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n# grid_search = GridSearchCV(model, param, scoring='roc_auc', n_jobs = -1, cv=kfold)\n# grid_result = grid_search.fit(X, y)\n\n# print('best cv score:', grid_result.best_score_, grid_result.best_params_)\n\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n\n# for mean, std, param in zip(means, stds, params):\n#     print('%f, (%f),%r' % (mean, std, param))\n\n","775858e6":"# # row sampling\n\n# model = XGBClassifier(scale_pos_weight=3.65, eval_metric='auc')\n\n# # learning rate and n_estimator\n# subsample = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n# param = dict(subsample = subsample)\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n# grid_search = GridSearchCV(model, param, scoring='roc_auc', n_jobs = -1, cv=kfold)\n# grid_result = grid_search.fit(X, y)\n\n# print('best cv score:', grid_result.best_score_, grid_result.best_params_)\n\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n\n# for mean, std, param in zip(means, stds, params):\n#     print('%f, (%f),%r' % (mean, std, param))\n\n# plt.errorbar(subsample, means, yerr=stds)\n# plt.title('CV error vs max_depth')\n# plt.show()","b7a81d43":"# # tune column sampling\n\n# model = XGBClassifier(scale_pos_weight=3.65, eval_metric='auc')\n\n# colsample_bytree = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n# param = dict(colsample_bytree = colsample_bytree)\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n# grid_search = GridSearchCV(model, param, scoring='roc_auc', n_jobs = -1, cv=kfold)\n# grid_result = grid_search.fit(X, y)\n\n# print('best cv score:', grid_result.best_score_, grid_result.best_params_)\n\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n\n# for mean, std, param in zip(means, stds, params):\n#     print('%f, (%f),%r' % (mean, std, param))\n\n# plt.errorbar(colsample_bytree, means, yerr=stds)\n# plt.title('CV error vs max_depth')\n# plt.show()","328324ab":"# # tune column sub sampling\n\n# model = XGBClassifier(scale_pos_weight=3.65, eval_metric='auc')\n\n# colsample_bylevel = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n# param = dict(colsample_bylevel = colsample_bylevel)\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n# grid_search = GridSearchCV(model, param, scoring='roc_auc', n_jobs = -1, cv=kfold)\n# grid_result = grid_search.fit(X, y)\n\n# print('best cv score:', grid_result.best_score_, grid_result.best_params_)\n\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n\n# for mean, std, param in zip(means, stds, params):\n#     print('%f, (%f),%r' % (mean, std, param))\n\n# plt.errorbar(colsample_bylevel, means, yerr=stds)\n# plt.title('CV error vs max_depth')\n# plt.show()","529b2f7e":"# # tuning all parameters togather\n\n# model = XGBClassifier(n_estimators=100, scale_pos_weight=3.65, eval_metric='auc')\n\n# learning_rate = [0.04, 0.045, 0.05, 0.055, 0.06]\n# max_depth = [2, 3]\n# colsample_bytree = [0.2, 0.3, 0.4, 0.5]\n# min_child_weight = [1, 1.8, 2.0, 2.2]\n# param = dict(learning_rate=learning_rate, max_depth = max_depth, colsample_bytree=colsample_bytree, min_child_weight=min_child_weight)\n# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n# grid_search = GridSearchCV(model, param, scoring='roc_auc', n_jobs = -1, cv=kfold)\n# grid_result = grid_search.fit(X, y)\n\n# print('best cv score:', grid_result.best_score_, grid_result.best_params_)\n\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n\n# for mean, std, param in zip(means, stds, params):\n#     print('%f, (%f),%r' % (mean, std, param))","1effee75":"# final model\nmodel = XGBClassifier(n_estimators=100, learning_rate=0.06, colsample_bytree=0.4, max_depth=3, min_child_weight=1.8,scale_pos_weight=3.65 )\nmodel.fit(x_train, y_train)\n\npred = model.predict_proba(x_test)\nprint('auc:', roc_auc_score(y_test, pred[:,1]))\n","c1ab0a6c":"pred = model.predict(x_test)\nconf_mx = pd.crosstab(pred, y_test, rownames=['Prediction'], colnames=['True Value'])\n\nplt.figure(figsize=(6,6))\nsns.heatmap(conf_mx, annot=True, fmt='g', square=True,\n            xticklabels=['non-default', 'default'],\n           yticklabels=['non-default', 'default'],\n           cmap=\"Greens\")\nplt.title('Confusion Matrix', fontsize=18)\nplt.show()","5569932f":"fig, ax = plt.subplots(figsize=(9,7))\nxgb.plot_importance(model, height=0.6, ax=ax, color='red')\nplt.show()","e482f072":"SEX: Gender (1=male, 2=female)\n\nFor `non-default`, there are more female than male\n\nFor `default`, there are slightly more female than male","218569bf":"## There are 25 variables:\n\nID: ID of each client\n\nLIMIT_BAL: Amount of given credit in NT dollars (includes individual and family\/supplementary credit\n\nSEX: Gender (1=male, 2=female)\n\nEDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n\nMARRIAGE: Marital status (1=married, 2=single, 3=others)\n\nAGE: Age in years\n\nPAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, \u2026 8=payment delay for eight months, 9=payment delay for nine months and above)\n\nPAY_2: Repayment status in August, 2005 (scale same as above)\n\nPAY_3: Repayment status in July, 2005 (scale same as above)\n\nPAY_4: Repayment status in June, 2005 (scale same as above)\n\nPAY_5: Repayment status in May, 2005 (scale same as above)\n\nPAY_6: Repayment status in April, 2005 (scale same as above)\n\nBILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n\nBILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\nBILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n\nBILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n\nBILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n\nBILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n\nPAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n\nPAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n\nPAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n\nPAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n\nPAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n\nPAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n\ndefault.payment.next.month: Default payment (1=yes, 0=no)","cf1cf199":"## Tune `max_depth`\n\nbest cv score: 0.7791281026402791 {'max_depth': 3}","c1e4a704":"# EDA","d45f471e":"## Tune `n_estimator`\n\nbest cv score: 0.7711229012960673 {'n_estimators': 50}","23d302e0":"MARRIAGE: Marital status (1=married, 2=single, 3=others)","346c36eb":"Data is not very balanced, there are way more `non-default` than `default`","b0aeb885":"## Tune `learning_rate`\n\nbest cv score: 0.7814509434904099 {'learning_rate': 0.05}","4dfed8cd":"## Please upvote if you found this notebook useful, THANK YOU","302f5814":"## Confusion Matrix","6f45d3e0":"## column subsampling before creating a tree\n\nbest cv score: 0.7664118466032764 {'colsample_bytree': 0.2}","3da0613f":"## Tune `scale_pos_weight`\n\nbest cv score: 0.7641200092121778 {'scale_pos_weight': 3.65}","13f1a303":"## set `scale_pos_weight`\n\nThe data is imbalanced, so we need to set `scale_pos_weight`, from EDA:\n\n* non-default: 23364\n* default: 6636\n\nso preliminary `scale_pos_weight` = 23364\/6636 = 3.52","99983431":"## column subsampling for each split in a tree\n\nbest cv score: 0.7689689215616526 {'colsample_bylevel': 0.1}","570894aa":"## Hyperparameter Tuning, Part 2\n\ncombining all the results from above\n\nbest cv score: 0.7815174509656737 {'colsample_bytree': 0.4, 'learning_rate': 0.06, 'max_depth': 3, 'min_child_weight': 1.8}","0beea923":"# Final Model\n\nUsing the results from all the hyperparameter tuning from above, the final auc is 0.793","c6dad964":"## There are no missing values","3de15cf5":"# Hyperparameter Tuning","8a30d099":"## Feature Importance\n\nThe most important features are:\n\n* BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n* PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, \u2026 8=payment delay for eight months, 9=payment delay for nine months and above)\n* PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n* LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family\/supplementary credit\n\nThis makes sense, since September is the most recent Month in the data, the ability to repay the bill in the previous month would be a good indicator of repayment in next month.","167bc5d3":"Age","b79ba3e4":"## Tuning Stochastic Gradient Boosting\n\n## row subsampling\n\nest cv score: 0.7641200092121778 {'subsample': 1.0}\n\nusing all the rows","00375cd2":"## Dataset Information\n\nThis dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005.\n\n* A XGBoost model is built to predict if a client will default on next payment, **final auc: 0.793**","ed5e0c79":"![image.png](attachment:image.png)","ee151dc4":"## searching for best combination of `n_estimators` and `learning_rate`\n\nbest cv score: 0.7816162765619434 {'learning_rate': 0.01, 'n_estimators': 400}\n\n0.781182, (0.009172),{'learning_rate': 0.01, 'n_estimators': 300}\n\n0.781451, (0.008836),{'learning_rate': 0.05, 'n_estimators': 100}","5d5852c2":"default vs age\n\ndistrbution of age between the two classes showed not much of difference","12cba4aa":"# XGBoost","acc1cabf":"EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)"}}