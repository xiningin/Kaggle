{"cell_type":{"3fa95318":"code","cc72d3c5":"code","03589944":"code","2b530ac1":"code","fc530d93":"code","a8c918f5":"code","7cdcf4b7":"code","6ef6afbf":"code","450561e5":"code","fa92fd51":"code","40257e36":"code","763e4ed9":"code","655a7b3c":"code","dab4088f":"code","3895be07":"code","042d5520":"code","b869d55c":"code","848c9270":"code","150ae643":"code","90c28889":"code","b5f84249":"code","e2d63ee1":"code","462b6d0c":"code","5061b51f":"code","acd2283a":"code","bd73e52b":"code","2b34975d":"code","06306c02":"code","519b2394":"code","6a4d91c2":"code","3668902c":"code","a2c6220f":"code","03543c5b":"code","51d559a3":"code","8654e39c":"code","16075552":"code","fc8d9dce":"code","82a6625a":"code","b3946586":"code","61acd645":"code","dfb9a397":"code","ed1e8074":"code","2aa39260":"code","c0619140":"code","85ff8b22":"code","70f54c1e":"code","d4a1c580":"code","e2f11d18":"code","bdbedba8":"code","b3ef193b":"markdown","4ab21798":"markdown","2ff2f08a":"markdown","6d4bf04c":"markdown","b83e0a92":"markdown","4743de17":"markdown","5be030f0":"markdown","479d0c63":"markdown","41d95a3f":"markdown","5689bb55":"markdown"},"source":{"3fa95318":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cc72d3c5":"\nimport warnings\nwarnings.filterwarnings('ignore')","03589944":"train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\n#train.head()\ntrain_Id = train['Id']\ntest_Id = test['Id']\ntrain.drop(['Id'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)\n\n\npd.set_option('display.max_columns', None)\ntrain.head()\ntest.head()","2b530ac1":"train.info()\n#test.info()","fc530d93":"#train.isna().sum().sort_values(ascending=False)[1:20]\ntest.isna().sum().sort_values(ascending=False)[1:35]    #.plot.bar()\n","a8c918f5":"train.columns","7cdcf4b7":"test.columns","6ef6afbf":"cat_train=[cat for cat in train.columns if train[cat].dtype=='object']\nnum_train=[cat for cat in train.columns if train[cat].dtype=='int64' or train[cat].dtype=='float64']\n\n\ncat_test=[cat for cat in test.columns if test[cat].dtype=='object']\nnum_test=[cat for cat in test.columns if test[cat].dtype=='int64' or test[cat].dtype=='float64']\n\ncat_train\n#cat_test","450561e5":"train[cat_train].isna().sum().sort_values(ascending=False)[1:20]\n#test[cat_train].isna().sum().sort_values(ascending=False)[1:25]","fa92fd51":"train.MasVnrType.value_counts()","40257e36":"train.MiscFeature.value_counts()","763e4ed9":"train.MiscFeature.fillna('NA', inplace=True) \ntrain.Alley.fillna('NA', inplace=True)          \ntrain.Fence.fillna('NA', inplace=True)         \ntrain.FireplaceQu.fillna('NA', inplace=True)    \ntrain.GarageCond.fillna('NA', inplace=True)    \ntrain.GarageQual.fillna('NA', inplace=True)     \ntrain.GarageFinish.fillna('NA', inplace=True)   \ntrain.GarageType.fillna('NA', inplace=True) \ntrain.BsmtFinType2.fillna('NA', inplace=True)     \ntrain.BsmtExposure.fillna('NA', inplace=True)\ntrain.BsmtFinType1.fillna('NA', inplace=True)   \ntrain.BsmtQual.fillna('NA', inplace=True)  \ntrain.BsmtCond.fillna('NA', inplace=True)  \ntrain.MasVnrType.fillna('None', inplace=True) \ntrain.Exterior2nd.fillna('None', inplace=True)\ntrain.PoolQC.fillna('NA', inplace=True)  \n\n\ntest.MiscFeature.fillna('NA', inplace=True) \ntest.Alley.fillna('NA', inplace=True)          \ntest.Fence.fillna('NA', inplace=True)         \ntest.FireplaceQu.fillna('NA', inplace=True)    \ntest.GarageCond.fillna('NA', inplace=True)    \ntest.GarageQual.fillna('NA', inplace=True)     \ntest.GarageFinish.fillna('NA', inplace=True)   \ntest.GarageType.fillna('NA', inplace=True)     \ntest.BsmtExposure.fillna('NA', inplace=True)     \ntest.BsmtCond.fillna('NA', inplace=True)        \ntest.BsmtQual.fillna('NA', inplace=True)        \ntest.BsmtFinType2.fillna('NA', inplace=True)     \ntest.BsmtFinType1.fillna('NA', inplace=True)     \ntest.MasVnrType.fillna('None', inplace=True) \ntest.Exterior2nd.fillna('None', inplace=True)  \ntest.PoolQC.fillna('NA', inplace=True)  ","655a7b3c":"print(train.select_dtypes(include='object').isnull().sum().sort_values(ascending=False).head(2))\nprint(test.select_dtypes(include='object').isnull().sum().sort_values(ascending=False).head(7))","dab4088f":"#\u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0447\u0430\u0441\u0442\u044b\u043c\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\u043c\u0438\ntrain.Electrical.fillna(train.Electrical.mode()[0], inplace=True)\ntest.Functional.fillna(train.Functional.mode()[0], inplace=True)       \ntest.Utilities.fillna(train.Utilities.mode()[0], inplace=True)          \ntest.Exterior1st.fillna(train.Exterior1st.mode()[0], inplace=True)        \ntest.SaleType.fillna(train.SaleType.mode()[0], inplace=True)                \ntest.KitchenQual.fillna(train.KitchenQual.mode()[0], inplace=True) \ntest.MSZoning.fillna(train.MSZoning.mode()[0], inplace=True)","3895be07":"test.Exterior2nd=test.Exterior2nd.replace('None',train.Exterior2nd.mode()[0] )","042d5520":"#\u0417\u0430\u043a\u043e\u0434\u0438\u0440\u0443\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0432 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u0446\u0438\u0444\u0440\u0430\u043c\u0438. \n\nfrom sklearn.preprocessing import LabelEncoder\n\n\nfor c in cat_train:\n    #print(c)\n    lbl = LabelEncoder() \n    lbl.fit(list(train[c].values)) \n    train[c] = lbl.transform(list(train[c].values))\n    test[c] = lbl.transform(list(test[c].values))\n\nprint('Shape train: {}'.format(train.shape))\nprint('Shape test: {}'.format(test.shape))","b869d55c":"train","848c9270":"print(train[num_train].isnull().sum()[train[num_train].isnull().sum()>0].sort_values(ascending=False))\nprint(test[num_test].isnull().sum()[test[num_test].isnull().sum()>0].sort_values(ascending=False))","150ae643":"test.GarageYrBlt.value_counts()","90c28889":"train.MasVnrArea.fillna(0, inplace=True)    \n\ntest.MasVnrArea.fillna(0, inplace=True)    \ntest.BsmtHalfBath.fillna(0, inplace=True)\ntest.BsmtFullBath.fillna(0, inplace=True)\ntest.GarageArea.fillna(0, inplace=True)\ntest.GarageCars.fillna(0, inplace=True)    \ntest.TotalBsmtSF.fillna(0, inplace=True)   \ntest.BsmtUnfSF.fillna(0, inplace=True)     \ntest.BsmtFinSF1.fillna(0, inplace=True) \ntest.BsmtFinSF2.fillna(0, inplace=True) \n\ntrain.GarageYrBlt.fillna(train.GarageYrBlt.median(), inplace=True)\ntest.GarageYrBlt.fillna(train.GarageYrBlt.median(), inplace=True)\ntrain.LotFrontage.fillna(train.LotFrontage.median(), inplace=True)\ntest.LotFrontage.fillna(train.LotFrontage.median(), inplace=True)","b5f84249":"test.isnull().sum().sort_values(ascending=False)","e2d63ee1":"train","462b6d0c":"#\u041a\u0430\u043a \u043c\u044b \u0432\u0438\u0434\u0438\u043c, \u0435\u0441\u0442\u044c \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435, \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0449\u0438\u0435 \u0437\u0430 \u0433\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u0438 \u043f\u0440\u043e\u0434\u0430\u0436\u0438. \n#\u0420\u0430\u0437\u0443\u043c\u043d\u043e \u0431\u044b\u043b\u043e \u0431\u044b \u0441\u043e\u0437\u0434\u0430\u0442\u044c \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435, \u043e\u0442\u0440\u0430\u0436\u0430\u044e\u0449\u0438\u0435 \u0432\u043e\u0437\u0440\u0430\u0441\u0442 \u0434\u043e\u043c\u0430, \u0447\u0442\u043e \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0442\u0438\u0432\u043d\u0435\u0435 \u043a\u0430\u043b\u0435\u043d\u0434\u0430\u0440\u043d\u044b\u0445 \u0433\u043e\u0434\u043e\u0432\ntrain['HouseAge']=train.YrSold - train.YearBuilt\ntrain['RemodAge'] = train.YrSold - train.YearRemodAdd\ntrain['GarageAge']= train.YrSold - train.GarageYrBlt\n\n\ntest['HouseAge']=test.YrSold - test.YearBuilt\ntest['RemodAge']= test.YrSold - test.YearRemodAdd\ntest['GarageAge']= test.YrSold - test.GarageYrBlt\n\n\ntrain.HouseAge = train.HouseAge.map(lambda x: 0 if x < 0 else x)\ntrain.RemodAge= train.RemodAge.map(lambda x: 0 if x < 0 else x)\ntrain.GarageAge = train.GarageAge.map(lambda x: 0 if x < 0 else x)\n\ntest.HouseAge = train.HouseAge.map(lambda x: 0 if x < 0 else x)\ntest.RemodAge= train.RemodAge.map(lambda x: 0 if x < 0 else x)\ntest.GarageAge = train.GarageAge.map(lambda x: 0 if x < 0 else x)\n\ntrain=train.drop(['YrSold','YearBuilt','YearRemodAdd','GarageYrBlt'],axis=1)\ntest=test.drop(['YrSold','YearBuilt','YearRemodAdd','GarageYrBlt'],axis=1)","5061b51f":"y=train['SalePrice']\ntrain=train.drop(['SalePrice'],axis=1)","acd2283a":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom scipy import stats\n\nplt.figure(1); plt.title('Normal')\nsns.distplot(y, fit=norm, color=\"g\")\nplt.figure(2); plt.title('Log Normal')\nsns.distplot(y, fit=stats.lognorm,  color=\"g\")\n","bd73e52b":"y = np.log(y)","2b34975d":"print(train.shape)\nprint(y.shape)\nprint(test.shape)","06306c02":"df=train.append(test , ignore_index = True)","519b2394":"df = pd.get_dummies(df,columns=cat_train).reset_index(drop=True)","6a4d91c2":"df","3668902c":"trainf = df.iloc[:len(y), :]\ntestf = df.iloc[len(y):, :]\ntrainf.shape, y.shape, testf.shape","a2c6220f":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train, y, test_size= 0.3)","03543c5b":"from sklearn.metrics import mean_squared_error\n\n\ndef rmse(model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    return mean_squared_error(y_test, y_pred, squared= False)                ","51d559a3":"import sklearn\nfrom sklearn.ensemble import RandomForestRegressor","8654e39c":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\n\nalg_model = RandomForestRegressor(random_state=1)\nalg_params = [{\n    'bootstrap': [True],\n    'max_depth': [80, 90, 100, 110],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300, 1000]\n}]\nalg_grid = GridSearchCV(alg_model, alg_params, cv=3, refit=True, verbose=2, n_jobs=-1)\n\n\nalg_grid.fit(X_train, y_train)\nalg_best = alg_grid.best_params_\nalg_best\n","16075552":"alg_grid.best_params_","fc8d9dce":"# [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.","82a6625a":"clf_tree = RandomForestRegressor(bootstrap =  True, max_depth = 80, max_features = 'sqrt', min_samples_leaf = 3,\n                               min_samples_split = 8, n_estimators = 1000, n_jobs=-1, random_state=12)\n\n# \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nclf_tree.fit(X_train, y_train)\n\n# \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \ny_pred_rf = clf_tree.predict(X_test)\nprint(\"RandomForestRegressor RMSE:\",np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n\n\ny_pred_rf = np.exp(clf_tree.predict(test))\nsubmission = pd.DataFrame({'Id': test_Id, 'SalePrice': y_pred_rf})\nsubmission.to_csv(\"randomforest_submission.csv\", index=False)","b3946586":"from sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression, Lasso, ElasticNet, ElasticNetCV\nfrom sklearn.preprocessing import RobustScaler #\u043f\u043e\u0432\u044b\u0441\u0438\u0442\u044c \u0443\u0441\u0442\u043e\u0439\u0447\u0438\u0432\u043e\u0441\u0442\u044c \u043a \u0432\u044b\u0431\u0440\u043e\u0441\u0430\u043c\n\nlasso=make_pipeline(RobustScaler(),Lasso(max_iter=1e7, alpha=0.01))\nscore = rmse(lasso)\n\nprint(f'Lasso Score= {score}')","61acd645":"lasso.fit(X_train, y_train)\n\ny_pred_lasso = np.exp(lasso.predict(test))\nsubmission = pd.DataFrame({'Id': test_Id, 'SalePrice': y_pred_lasso})\nsubmission.to_csv(\"lasso_submission.csv\", index=False)\n","dfb9a397":"from sklearn.model_selection import KFold, cross_val_score\nkfolds = KFold(n_splits=10, shuffle=True, random_state=10)\n","ed1e8074":"elasticnetcv = make_pipeline(RobustScaler(),\n                             ElasticNetCV(max_iter=100000, \n                                          l1_ratio=[0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99],\n                                          alphas=np.logspace(-4, -2, 9),\n                                          cv=kfolds,\n                                          n_jobs=-1,\n                                          verbose=1,\n                                         ))\nelasticnetcv.fit(X_train, y_train)\nl1_ratio = elasticnetcv._final_estimator.l1_ratio_\nalpha = elasticnetcv._final_estimator.alpha_\nprint('l1_ratio', l1_ratio)\nprint('alpha', alpha)\n\n","2aa39260":"elasticnet = ElasticNet(alpha=alpha,\n                        l1_ratio=l1_ratio,\n                        max_iter=10000)\n\nscores = -cross_val_score(elasticnet, X_train, y_train,\n                          scoring=\"neg_root_mean_squared_error\",\n                          cv=kfolds,\n                          n_jobs=-1)\n\nprint()\nprint(\"CV RMSE %.04f (STD %.04f)\" % (np.mean(scores), np.std(scores)))\n","c0619140":"elasticnet.fit(X_train, y_train)\n\ny_pred_elasticnet = np.exp(elasticnet.predict(test))\nsubmission = pd.DataFrame({'Id': test_Id, 'SalePrice': y_pred_elasticnet})\nsubmission.to_csv(\"elasticnet_submission.csv\", index=False)","85ff8b22":"from xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV","70f54c1e":"alg_model = XGBRegressor(random_state=1)\nalg_params = [{'max_depth':[3,4],\n          'learning_rate':[0.01,0.03],\n          'min_child_weight':[1,3],\n          'reg_lambda':[0.1,0.5],\n          'reg_alpha':[1,1.5],      \n          'gamma':[0.1,0.5],\n          'subsample':[0.4,0.5],\n         'colsample_bytree':[0.4,0.5],\n}]\nalg_grid = GridSearchCV(alg_model, alg_params, cv=4, refit=True, verbose=2, n_jobs=-1)\n\n\nalg_grid.fit(X_train, y_train)\nalg_best = alg_grid.best_params_\nalg_best","d4a1c580":"xgbr_model = XGBRegressor(learning_rate=0.03,n_estimators=3460,\n                                     max_depth=4,min_child_weight=3, \n                                     gamma=0.1, subsample=0.5,\n                                     colsample_bytree=0.5,\n                                     objective='reg:squarederror', \nnthread=-1, scale_pos_weight=1, seed=27,reg_alpha=1, reg_lambda=0.1)\n\n# \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nxgbr_model.fit(X_train, y_train)\n\n# \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \ny_pred_xgbr = xgbr_model.predict(X_test)\nprint(\"XGBR RMSE:\",np.sqrt(mean_squared_error(y_test, y_pred_xgbr)))\n      \ny_xgbr = np.exp(xgbr_model.predict(test))\nsubmission = pd.DataFrame({'Id': test_Id, 'SalePrice': y_xgbr})\nsubmission.to_csv(\"xgbr_submission.csv\", index=False)","e2f11d18":"def blending(X):\n    return ((0.2 * clf_tree.predict(X)) + \\\n            (0.5 * elasticnet.predict(X) + \\\n            (0.3 * xgbr_model.predict(X)) \n            ))\n            \n    \n\nprint(np.sqrt(mean_squared_error(y_train, blending(X_train))))","bdbedba8":"y_predicted = np.exp(blending(test))\nsubmission = pd.DataFrame({'Id': test_Id, 'SalePrice': y_predicted})\nsubmission.to_csv(\"blend_submission.csv\", index=False)\n","b3ef193b":"# **\u041f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445**","4ab21798":"Lasso","2ff2f08a":"Random Forest","6d4bf04c":"xgboost","b83e0a92":"# ***\u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0435\u0439***","4743de17":"\u041f\u0435\u0440\u0435\u0439\u0434\u0451\u043c \u043a \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u043c \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u043c","5be030f0":"\u0412\u044b\u0434\u0435\u043b\u0438\u043c \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u0438 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435. \u0417\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438","479d0c63":"ElasticNet","41d95a3f":"\u0417\u0430\u0433\u0440\u0443\u0437\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435","5689bb55":"\u0426\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f"}}