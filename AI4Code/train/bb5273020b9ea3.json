{"cell_type":{"af668542":"code","ade6f992":"code","214c2c27":"code","f2e3138c":"code","2f9540e0":"code","749da857":"code","ef79f858":"code","94603bfa":"code","6575ea9f":"code","99d52cb7":"code","2344795a":"code","eb9a348d":"code","6e0fdea8":"code","e58f37f0":"code","38953e12":"code","5837ff91":"code","d5400f35":"code","8e91ca27":"code","f84dcebf":"code","f897cfe1":"code","42f630c2":"code","40ea3ab2":"code","f107f1e1":"code","bf3117f7":"code","09b34d01":"code","3d901641":"code","546a5ebe":"code","ec21b4e9":"code","0a317585":"code","03d423d4":"code","715ca62b":"code","ea4e01bc":"code","2476613a":"code","8ce8b2c5":"code","f08a41e5":"code","fec2d6d5":"code","16ae797d":"code","d9b92a44":"code","90334336":"markdown","2384715b":"markdown","78c4c51c":"markdown","a77acd3a":"markdown","4141df47":"markdown","8a6dea24":"markdown","54752c85":"markdown","224f1224":"markdown","fe553341":"markdown"},"source":{"af668542":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ade6f992":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","214c2c27":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')","f2e3138c":"print(train.shape)\ntrain.head()","2f9540e0":"print(test.shape)\ntest.head()","749da857":"train.describe()","ef79f858":"test.describe()","94603bfa":"train.isnull().sum()","6575ea9f":"test.isnull().sum()","99d52cb7":"plt.style.use(\"fivethirtyeight\")\nsns.set_style('darkgrid')","2344795a":"fig, ax = plt.subplots(figsize=(10, 6))\nsns.countplot(x='target', data=train)\nax.set_title('Target Distribution')","eb9a348d":"corr_matrix = train.corr()\nmask = np.triu(np.ones_like(corr_matrix, dtype=np.bool))\n\nfig, ax = plt.subplots(figsize=(20, 15))\nax = sns.heatmap(corr_matrix,\n                 annot=False,\n                 linewidth=0.1,\n                 cmap=\"inferno\",\n                 mask=mask, ax=ax); #bone cmap type\nplt.title('Heatmap for the Dataset', fontsize = 10)\nbottom, top = ax.get_ylim()","6e0fdea8":"le = LabelEncoder()\ntrain['target'] = le.fit_transform(train['target'])\ntrain.columns\n\ncols = list(train.columns)\ncols.remove(\"id\")\ncols.remove(\"target\")","e58f37f0":"train.columns","38953e12":"scaler = StandardScaler()\ntrain[cols] = scaler.fit_transform(train[cols])\ntest[cols] = scaler.transform(test[cols])","5837ff91":"X=train.drop(['id','target'],axis=1)\nY=train['target']","d5400f35":"from catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import model_selection\nimport optuna","8e91ca27":"def objective(trial,data=X,target=Y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25,random_state=50)\n    params = {'iterations':trial.suggest_int(\"iterations\", 4000, 16000),\n              'od_wait':trial.suggest_int('od_wait', 500, 3200),\n             'loss_function':'MultiClass',\n              'task_type':\"GPU\",\n              'eval_metric':'MultiClass',\n              'leaf_estimation_method':'Newton',\n              'bootstrap_type': 'Bernoulli',\n              'learning_rate' : trial.suggest_uniform('learning_rate',0.01,0.5),\n              'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n              'subsample': trial.suggest_uniform('subsample',0,1),\n              'random_strength': trial.suggest_uniform('random_strength',10,30),\n              'depth': trial.suggest_int('depth',1,6),\n              'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n              'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,8),\n               }\n    model = CatBoostClassifier(**params)  \n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=100,verbose=False)\n        \n    y_preds = model.predict_proba(X_test)\n\n\n    log_loss_multi = log_loss(y_test, y_preds)\n    \n    return log_loss_multi","f84dcebf":"OPTUNA_OPTIMIZATION = True\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=25)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))","f897cfe1":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))","42f630c2":"cat_params = study.best_trial.params\ncat_params['loss_function'] = 'MultiClass'\ncat_params['eval_metric'] = 'MultiClass'\ncat_params['bootstrap_type']= 'Bernoulli'\ncat_params['leaf_estimation_method'] = 'Newton'\ncat_params['random_state'] = 42\ncat_params['task_type']='GPU'\ntest_preds=None\n\nkf = StratifiedKFold(n_splits = 10 , shuffle = True , random_state = 50)\nfor fold, (tr_index , val_index) in enumerate(kf.split(X.values , Y.values)):\n    \n    print(\"-\" * 50)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = X.values[tr_index] , X.values[val_index]\n    y_train,y_val = Y.values[tr_index] , Y.values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model =CatBoostClassifier(**cat_params)\n    model.fit(x_train, y_train, eval_set = eval_set, verbose = False)\n    \n    train_preds = model.predict(x_train)    \n    val_preds = model.predict_proba(x_val)\n    \n    print(log_loss(y_val, val_preds))\n    \n    if test_preds is None:\n        test_preds = model.predict_proba(test[cols].values)\n    else:\n        test_preds += model.predict_proba(test[cols].values)\n\nprint(\"-\" * 50)\ntest_preds \/= 10","40ea3ab2":"submission1 = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\nsubmission1['Class_1']=test_preds[:,0]\nsubmission1['Class_2']=test_preds[:,1]\nsubmission1['Class_3']=test_preds[:,2]\nsubmission1['Class_4']=test_preds[:,3]\nsubmission1['Class_5']=test_preds[:,4]\nsubmission1['Class_6']=test_preds[:,5]\nsubmission1['Class_7']=test_preds[:,6]\nsubmission1['Class_8']=test_preds[:,7]\nsubmission1['Class_9']=test_preds[:,8]\nsubmission1.head()","f107f1e1":"submission1.to_csv(\"submission1.csv\",index=False)","bf3117f7":"from IPython.display import FileLink\nFileLink('submission1.csv')","09b34d01":"from xgboost import XGBClassifier\nimport xgboost\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score, make_scorer","3d901641":"X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25,random_state=50)\n\nxgb_clf = XGBClassifier(learning_rate = 0.1, n_estimators = 200,use_label_encoder = False, verbose= None, objective = 'multi:softmax', eval_metric = 'mlogloss',eval_set = [X_test, y_test])\n\nxgb_clf.fit(X_train, y_train)","546a5ebe":"y_pred_xgb_pr = xgb_clf.predict_proba(X_test)\n\ny_pred_xgb = xgb_clf.predict(X_test)","ec21b4e9":"acc_scr_xgb = accuracy_score(y_test, y_pred_xgb)\nacc_scr_xgb","0a317585":"auc_score_xgb = roc_auc_score(y_test, y_pred_xgb_pr, multi_class = 'ovr')\nauc_score_xgb","03d423d4":"clf_xgb = classification_report(y_test, y_pred_xgb)\nprint(clf_xgb)","715ca62b":"cfm_xgb = confusion_matrix(y_test, y_pred_xgb)","ea4e01bc":" test_preds2 = xgb_clf.predict_proba(test[cols].values)","2476613a":"plt.figure(figsize = (8, 6))\nsns.heatmap(cfm_xgb, annot = True)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")","8ce8b2c5":"import shap\n\nexplainer = shap.TreeExplainer(xgb_clf)\nshap_values = explainer.shap_values(X_test)","f08a41e5":"shap.summary_plot(shap_values, X_test)","fec2d6d5":"submission2 = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\nsubmission2['Class_1']=test_preds2[:,0]\nsubmission2['Class_2']=test_preds2[:,1]\nsubmission2['Class_3']=test_preds2[:,2]\nsubmission2['Class_4']=test_preds2[:,3]\nsubmission2['Class_5']=test_preds2[:,4]\nsubmission2['Class_6']=test_preds2[:,5]\nsubmission2['Class_7']=test_preds2[:,6]\nsubmission2['Class_8']=test_preds2[:,7]\nsubmission2['Class_9']=test_preds2[:,8]\nsubmission2.head()","16ae797d":"submission2.to_csv(\"submission2.csv\",index=False)","d9b92a44":"from IPython.display import FileLink\nFileLink('submission2.csv')","90334336":"Generating the submission file:","2384715b":"# XGB Classifier","78c4c51c":"# **Import Libraries**","a77acd3a":"#  Please Upvote if it helps you","4141df47":"# **Feature Transformation**","8a6dea24":"# **Correlation**","54752c85":"Most features are too less correlated - 0.14 or less.\n","224f1224":"# CatBoostClassifier","fe553341":"Model Explainability with SHAP library:"}}