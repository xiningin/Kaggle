{"cell_type":{"7ca9602b":"code","1e6285d2":"code","a5a4e9cf":"code","c3658ef9":"code","21b024f1":"code","723dcdf6":"code","3a564235":"code","676df665":"code","7fec0f37":"code","15338959":"code","7528c4a7":"markdown"},"source":{"7ca9602b":"pip install contractions","1e6285d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport contractions\nimport re\nimport string\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport matplotlib.pyplot as plt\nimport nltk\nnltk.download(\"all\")\nfrom nltk.corpus import stopwords as sw\nfrom wordcloud import WordCloud, STOPWORDS\n","a5a4e9cf":"blog_details = pd.read_csv('..\/input\/ctdsmedium-blogs\/sb_blog.csv', encoding='ISO-8859-1', parse_dates=['release_date'])\nblog_details","c3658ef9":"print(\"Category vs Claps: \", blog_details.groupby('category')['claps'].sum())\nprint(\"\\nRatio of Women-to-Men heroes is \",blog_details.groupby('heroes_gender')['heroes'].count()[0]\/(blog_details.groupby('heroes_gender')['heroes'].count()[0] + blog_details.groupby('heroes_gender')['heroes'].count()[1]))","21b024f1":"# Sorted by claps in descending order \nsorted_blog_details = blog_details.sort_values('claps', ascending=False)\nplt.bar(sorted_blog_details['heroes'], sorted_blog_details['claps'])\nplt.xlabel('Heroes', fontsize=15)\nplt.ylabel('Claps', fontsize=15)\nplt.xticks(sorted_blog_details['heroes'], fontsize=9, rotation=90)\nplt.title('Heroes Vs Claps')\nplt.figure(figsize=(20,15))\nplt.show()","723dcdf6":"#pre processing methods\ndef clean_the_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    # Expanding Contractions eg. i've to I have\n    text = contractions.fix(text)\n    text = re.sub(r\".*native.*\\n?\",\"\",text)    \n    text = re.sub('Hey.+science.', '', text)\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n          \n    text = re.sub(r\".*Audio.*\\n?\",\"\",text)    \n    text = re.sub(r\".*sanyambhutani.com.*\\n?\",\"\",text)\n    text = re.sub(r\".*Newsletter.*\\n?\",\"\",text)\n    text = re.sub(r\".*so much.*\\n?\",\"\",text)\n    text = re.sub(r\".*Sanyam Bhutani:.*\\n?\",\"\",text)\n    text = re.sub(r\".*Subscribe.*\\n?\",\"\",text)\n    text = re.sub(r\".*twitter.*\\n?\",\"\",text)\n    text = re.sub(r\".*Flow.*\\n?\",\"\",text)\n    text = re.sub(r\".*Follow.*\\n?\",\"\",text)\n    text = re.sub(r\".*Playlist.*\\n?\",\"\",text)\n    text = re.sub(r\".*support.*\\n?\",\"\",text)\n    text = re.sub(r\".*Linkedin.*\\n?\",\"\",text)\n    text = re.sub(r\".*Kaggle:.*\\n?\",\"\",text)\n    text = re.sub(r\".*hosted.*\\n?\",\"\",text)\n    text = re.sub(r\"interview[s|ed|ing]\",\"\",text,re.IGNORECASE)\n    text = re.sub(r\".*track.*\\n?\",\"\",text)\n    text = re.sub(r\".*available.*\\n?\",\"\",text)\n    text = re.sub(r\".*Blog.*\\n?\",\"\",text)\n    text = re.sub(r\".*Correction.*\\n?\",\"\",text)\n    text = re.sub(r\".*Note.*\\n?\",\"\",text)\n    text = re.sub(r\".*About.*\\n?\",\"\",text)\n    #text = re.sub(r\".*YouTube.*.?\",\"\",text)\n    text = re.sub(r\".*lazy.*\\n?\",\"\",text)\n   \n    #text = re.sub(r\".*find.*.?\",\"\",text)\n    text = re.sub(r\".*Link[s].*\\n?\",\"\",text)\n    text = re.sub(r\".*KaggleDaysMeetup.*\\n?\",\"\",text)\n    \n    text = re.sub('\\n', ' ', text)\n    text = text.lower()\n    text = re.sub(r\"enjoy\",\"\",text)\n    text = re.sub(r\"show\",\"\",text)\n    text = re.sub(r\"even\",\"\",text)\n    text = re.sub(r\"another\",\"\",text)\n    text = re.sub(r\"time\",\"\",text)\n    text = re.sub(r\"part\",\"\",text)\n    text = re.sub(r\"sanyam\",\"\",text)\n    text = re.sub(r\"episode\",\"\",text)\n    text = re.sub(r\"interview\",\"\",text)\n    text = re.sub(r\"bhutani\",\"\",text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n\ndef text_preprocessing(text):\n    \"\"\"\n    Cleaning and parsing the text.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    \n    nopunc = clean_the_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    common_words = set(['sure','everyone','chai','us','also','hello','find','check','currently','two','description','welcome','podcast','many','like','get','lot','please','hi','heres','really','one'])\n    stop_wds = common_words.union(sw.words('english'))\n    remove_stopwords = [w for w in tokenized_text if w not in stop_wds]\n    combined_text = ' '.join(remove_stopwords)\n    return combined_text","3a564235":"#preprocessing and counting word length of script and introduction\nblog_details['script'] = blog_details['transcript'].apply(str).apply(lambda x: text_preprocessing(x))\nblog_details['intro'] = blog_details['introduction'].apply(str).apply(lambda x: text_preprocessing(x))\nblog_details['script_len'] = blog_details['script'].apply(str).apply(lambda x: len(x.split()))\nblog_details['intro_len'] = blog_details['intro'].apply(str).apply(lambda x: len(x.split()))\nblog_details","676df665":"#calculating the average word length of blog interviews and the range that they usually are in.\nprint(\"Average Word Length of blog interviews is {} words.\".format(int(round(np.percentile(blog_details['script_len'],50)))))\nlower_range = int(round(np.percentile(blog_details['script_len'],.1)))\nupper_range = int(round(np.percentile(blog_details['script_len'],95)))\nprint(\"Word Length of blog interviews are between {} and {} words.\".format(lower_range, upper_range))\nprint(\"Dr.Vladimir's interview is a long one (2564 words), which is standing below as an outlier.\")\nsns.set(style=\"whitegrid\")\nax = sns.boxplot(x=blog_details[\"script_len\"], linewidth=2.5)","7fec0f37":"sorted_blog_details[['heroes','claps','script_len','intro_len']]","15338959":"from nltk.tokenize import sent_tokenize\nfrom nltk.probability import FreqDist\n\n# We will look at Frequency Distribution of words used in introduction\nblog_guest_intro = []\nfor s in blog_details['intro']:\n    blog_guest_intro.append(sent_tokenize(s))   \n\ngi_string = ''.join(str(gi) for gi in blog_guest_intro)\ngi_string = re.sub('[^a-zA-Z]', ' ', gi_string )\ngi_tokenized_word = nltk.word_tokenize(gi_string)\ngi_fdist = FreqDist(gi_tokenized_word)\nprint(gi_fdist.most_common(80))\n\n%matplotlib inline\ngi_fdist.plot(30, cumulative=False,title = \"Common words used in Guest Introduction\")\nplt.show()\n\nprint(\"Bigrams :\")\nbigrams = nltk.bigrams(gi_tokenized_word)\nprint(list(bigrams)[:35])","7528c4a7":"# Please carry on your investigation"}}