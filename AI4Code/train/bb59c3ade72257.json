{"cell_type":{"85dfa9f0":"code","2ca08abe":"code","edc1662a":"code","77f7cccd":"code","3b632789":"code","d8fc282f":"code","375f76df":"code","504779fe":"code","af66d9e1":"code","8e79ac2e":"code","3f5b6444":"code","f3358f97":"code","dcf1f3b6":"code","f144da58":"code","f5a342fd":"code","5a542f42":"code","5141993f":"code","81911e3c":"code","36b93a8a":"code","8bb06a82":"code","578625f4":"code","3f30a4f0":"markdown","f54f4e51":"markdown","4072d827":"markdown","61ffe607":"markdown","c57ef113":"markdown","9cdea9e8":"markdown","86f9aeef":"markdown","5c131c23":"markdown","f48880d2":"markdown","473bb1df":"markdown","54276949":"markdown","7f41619f":"markdown","3a9d0e6d":"markdown","dca0a4f5":"markdown","5aed20bc":"markdown","9162473f":"markdown","9f7bdc21":"markdown","36eeae2b":"markdown","1b47e2c3":"markdown","2b362b30":"markdown"},"source":{"85dfa9f0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2 #cv2 for image processing\nimport random\nimport os\nimport numpy as np #NumPy for array manipulation\nimport matplotlib.pyplot as plt #Matplotlib for visualizing the performance of the models\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport keras #Keras is a library for building neural networks on top of TensorFlow\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.applications import InceptionResNetV2\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras import layers, models, optimizers\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2ca08abe":"mask_dir = '..\/input\/face-mask-detection-data\/with_mask'\nno_mask_dir = '..\/input\/face-mask-detection-data\/without_mask'\nmask_img = [f'{mask_dir}\/{i}' for i in os.listdir(mask_dir)]\nno_mask_img = [f'{no_mask_dir}\/{i}' for i in os.listdir(no_mask_dir)]","edc1662a":"#Identify how many images we have in each group and total images\nprint(\"Total number of images with mask: \" + str(len(mask_img)))\nprint(\"Total number of images without mask: \" + str(len(no_mask_img)))\nprint(\"Total images: \" + str(len(mask_img) + len(no_mask_img)))","77f7cccd":"#Split the mask and no mask into training and testing sets\ntr_mask = mask_img[0:1499]\ntr_no_mask = no_mask_img[0:1499]\ntest_mask = mask_img[1500:]\ntest_no_mask = no_mask_img[1500:]\n\n#Combine the training and testing sets\ntrain_img = tr_mask + tr_no_mask\ntest_img = test_mask + test_no_mask","3b632789":"#Define a function to resive and convert the images to the 3 channel BGR color image\n#Also creates labels for with mask = 0 and without mask = 1 for classification use in neural network\ndef process_imgs(imgs, width=150, height=150):\n    x = []\n    y = []\n    for i in imgs:\n        x.append(cv2.resize(cv2.imread(i, cv2.IMREAD_COLOR), (width, height), interpolation=cv2.INTER_CUBIC))\n        label = 1 if 'without' in i else 0\n        y.append(label)\n    return np.array(x), np.array(y)\n\ntr_x, tr_y = process_imgs(train_img)\ntest_x, test_y = process_imgs(test_img)\n\n# plot 5 images just to see the results of processing the images\nplt.figure(figsize=(20, 10))\ncols = 5\nfor i in range(cols):\n    plt.subplot(5 \/ cols+1, cols, i+1) #keras\n    plt.imshow(tr_x[i])","d8fc282f":"#Image data augmentation for use in TensorFlow with test and training sets\ntr_data = ImageDataGenerator(rescale=1\/255,\n                            rotation_range=40,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.2,\n                            zoom_range=0.2,\n                            horizontal_flip=True)\n\ntr_gen = tr_data.flow(tr_x, tr_y, batch_size=32)\ntest_gen = tr_data.flow(test_x, test_y, batch_size = 32)","375f76df":"#Designing our first CNN for training\nmodel = models.Sequential()\nmodel.add(Conv2D(64, (1, 1), input_shape = (150,150,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(128, (1, 1), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(2, activation='softmax'))","504779fe":"print(model.summary())","af66d9e1":"#Compiling and training our first CNN using RMSprop as an optimizer\nbatch_size = 32\nepochs = 20\nmodel.compile(loss='sparse_categorical_crossentropy',\n             optimizer=optimizers.RMSprop(lr=2e-5),\n             metrics=['acc'])\nhist = model.fit(tr_gen, steps_per_epoch=tr_x.shape[0] \/\/ batch_size, epochs=epochs)","8e79ac2e":"#Comparing the accuracy and loss of our first CNN on the test data\nresults = model.evaluate(test_gen, batch_size = 32)\nprint(\"Test loss and test accuracy: \", results)","3f5b6444":"#Graphing the loss and accuracy for our first CNN\nepochs = list(range(1, len(hist.history['acc'])+1))\naccuracy = hist.history['acc']\nloss = hist.history['loss']\n\n\nplt.subplot(2,1,1)\nplt.plot(epochs, accuracy)\nplt.title(\"CNN for Accuracy and Loss (Mask vs No Mask)\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.subplot(2,1,2)\nplt.plot(epochs, loss)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","f3358f97":"#Rebuilding the same model to compile using a different optimizer\nmodel2 = models.Sequential()\nmodel2.add(Conv2D(64, (1, 1), input_shape = (150,150,3), activation='relu'))\nmodel2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel2.add(Conv2D(128, (1, 1), activation='relu'))\nmodel2.add(layers.Flatten())\nmodel2.add(layers.Dense(256, activation='relu'))\nmodel2.add(layers.Dense(2, activation='softmax'))","dcf1f3b6":"#Compiling and training our first CNN using ADAM as an optimizer\nbatch_size = 32\nepochs = 20\nmodel2.compile(loss='sparse_categorical_crossentropy',\n             optimizer='adam',\n             metrics=['acc'])\nhist2 = model2.fit(tr_gen, steps_per_epoch=tr_x.shape[0] \/\/ batch_size, epochs=epochs)","f144da58":"results2 = model2.evaluate(test_gen, batch_size = 32)\nprint(\"Test loss and test accuracy: \", results2)","f5a342fd":"epochs2 = list(range(1, len(hist2.history['acc'])+1))\naccuracy2 = hist2.history['acc']\nloss2 = hist2.history['loss']\n\nplt.subplot(2,1,1)\nplt.plot(epochs2, accuracy2)\nplt.title(\"CNN for Accuracy and Loss (Mask vs No Mask)\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.subplot(2,1,2)\nplt.plot(epochs2, loss2)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","5a542f42":"#Loading pre-trained weights from ImageNet to save training time, thank you Transfer Learning\nbase=InceptionResNetV2(weights='imagenet',\n                             include_top=False,\n                             input_shape=(150, 150, 3))","5141993f":"model3 = models.Sequential()\nmodel3.add(base)\nmodel3.add(layers.Flatten())\nmodel3.add(layers.Dense(256, activation='relu'))\nmodel3.add(layers.Dense(2, activation='softmax'))\nbase.trainable = False","81911e3c":"print(model3.summary())","36b93a8a":"batch_size = 32\nepochs = 20\nmodel3.compile(loss='sparse_categorical_crossentropy',\n             optimizer='adam',\n             metrics=['acc'])\nhist3 = model3.fit(tr_gen, steps_per_epoch=tr_x.shape[0] \/\/ batch_size, epochs=epochs)","8bb06a82":"#Comparing the accuracy and loss of our model relying on ImageNet model as the first layer\nresults3 = model3.evaluate(test_gen, batch_size = 32)\nprint(\"Test loss and test accuracy: \", results3)","578625f4":"#Graphing the loss and accuracy for our model using ImageNet model as the first layer\nepochs3 = list(range(1, len(hist3.history['acc'])+1))\naccuracy3 = hist3.history['acc']\nloss3 = hist3.history['loss']\n\n\nplt.subplot(2,1,1)\nplt.plot(epochs3, accuracy3)\nplt.title(\"ImageNet and our NN for Accuracy and Loss (Mask vs No Mask)\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.subplot(2,1,2)\nplt.plot(epochs3, loss3)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","3f30a4f0":"**Capture all the image file paths**\n\nNow that all the various libraries have been imported, we want to capture all the image data in this dataset. We will use the directory path to capture the images of people wearing masks and the images of those not wearing masks. Once we have the file path we use iteration to create a list of all the images in each file path.","f54f4e51":"Notice I don't use a convoluational layer for this model. The idea is to rely heavily upon the ImageNet's pretrained model, and add only a few basic layers on top for specialization with our dataset. We build a model with our first layer consisting of the ImageNet's model.","4072d827":"Lets look at the total number of each images in each list, and the total of all images. This is used so we can identify how we will split the dataset into training and testing sets.","61ffe607":"**Graphing the epochs of the model we created**\n\nWe can use matplotlib to view the training progression of our model. This is why I stored the model to hist, so we can access the loss and accuracy over each epoch.","c57ef113":"## The power of Transfer Learning\n\nNow let's use transfer learning to help improve our performance. What we are doing is using ImageNet's pre-trained weights for images to help improve our performance. What I mean by this, is instead of training our network from scratch, let's use some already trained model, throw a few layers on top for specialization with our dataset, and see if we can get increased performance.","9cdea9e8":"**Building the same neural network to use the ADAM optimizer**\n\nNow we will simply rebuild the same neural network (same number and type of layers and nodes):","86f9aeef":"Same process as above but this time we will utilize the string 'adam' for our optimizer argument and train the model this way.","5c131c23":"Lets see how this model performs on the test set:","f48880d2":"That's all folks! I hope this was clear and easy to follow, and hopefully demostrated the power of transfer learning.\n\nIf you enjoyed this notebook please throw me an upvote!\nThanks for reading!","473bb1df":"### **Building our first CNN**\n\nNow that we have done all the image processing, we can build our first neural network. I will use an input convolutional 2D layer. There are numerous resources online describing what exactly a convolutional layer is and why it should be used, I highly suggest doing some personal research on this topic.\n\nNotice the input_shape = (150,150,3), this is because when we processed the images our new width and height are 150 and the 3 is for the BGR channel.\n\nOur output layer contains only 2 neurons (nodes) because this is a simple binary classification problem (with mask or without mask).\n\nWhen designing a neural network it's important to play with the number of nodes in each layer, along with how many layers you want in your network. Just be aware that the more layers and nodes you add, the higher your compuational cost will be (how long it'll take for your model to be trained). Also we always run the risk of overfitting if our model becomes too complex. For this tutorial I tried to keep it simple.","54276949":"Let's check out if anything changes when utilizing the ADAM optimizer.","7f41619f":"**Training our first model**\n\nTime to train our model! We will compile using a RMSprop optimizer with a specified learning rate. I will repeat this exact process with this exact model using a different optimizer just for comparison later on.","3a9d0e6d":"And as a comparison let's check out that matplotlib graph of loss and accuracy for each epoch:","dca0a4f5":"# Implementing CNN for a basic image classification\n\nThe main goal of this notebook is to give an introduction to utilizing Keras library for building a basic Convolutional Neural Network. As a secondary goal I wished to highlight transfer learning using ImageNet as an example for improving a neural networks performance. Image processing, splitting testing\/training data, and basic plotting of model performance will also be highlighted here.\n\n**First we will import at the necessary libararies:**","5aed20bc":"**Image processing**\n\nNow that we have captured all the images and split into training and testing sets, we will do some image processing and classification labeling. This utilizes the CV2 library for resizing the images, converting the images to 3 channel BGR colors, and pulling out a NumPy array version of the images to be used in TensorFlow. We wish to resize the images so they are all same size when inputting them into the neural networks. Converting the images to 3 channel BGR colors is so they aren't as complex (as a full colored image contains quite a lot more information, oftentimes unncessary and increasing our computational complexity). Converting the information into a NumPy array is necessary as an input for TensorFlow which Keras uses.\n\nAt the end we will print 5 images just to see what our data processing has accomplished.","9162473f":"Lets train the model and see if anything improves!","9f7bdc21":"Usually we want to split the data in either a 70%\/30% or a 80%\/20% training\/testing sets. For convenience I split just below a 80%\/20% split, capturing the first 1500 images in each set for training. The remaining images will make up our testing set. After we have split for training and testing, we combine the training sets with and without masks, and do the same for the testing sets.","36eeae2b":"**How well does our model perform on the test set?**\n\nNow that we have trained our model, lets see how it perfoms on the testing data. This is easily done using the method .evaluate()","1b47e2c3":"**We can look at our model we created using a simple method summary():**","2b362b30":"Now that we have processed the images, we will use ImageDataGenerator for data augmentation. This will help the model generalize better. I suggest reading the relevant information available for ImageDataGenerator to learn more. We will run the training and the testing data through this."}}