{"cell_type":{"6b4ac870":"code","16878de4":"code","c530bcb6":"code","224b3231":"code","5fb2e41f":"code","ecf7fcdd":"code","1e687004":"code","fb7d3713":"code","9a83b972":"code","c6468044":"code","8392f7a3":"code","eb811357":"code","63362f51":"code","9cc0f177":"code","12710efa":"code","17158247":"code","550d2006":"code","e3fc0629":"code","afda1ef5":"code","b5e3bace":"code","18728ef3":"code","26f2e47a":"code","fcf772d7":"code","804291dd":"code","a6eb9eaa":"code","e10d9b17":"code","ae11e489":"code","47493655":"code","42fb714e":"code","e80a68e4":"code","4f7410fb":"code","0e4f9b01":"code","4695351b":"code","b432d59b":"code","2d4f4742":"code","2a3ceb77":"code","c179cb2f":"code","4e3cd17c":"code","79f64daa":"code","9177d509":"code","d0add3c3":"code","9d74f647":"code","adfdb5c8":"code","1ae1667f":"code","6a49f067":"code","47ad265c":"code","9c509379":"code","c8970d75":"code","08f882e7":"code","9d814d1e":"code","d746b3ae":"code","915d2584":"code","1f870009":"code","41f3105d":"code","c78aeb4a":"code","8fe26cda":"code","81074331":"code","09a36062":"markdown","79836cd3":"markdown","2634069c":"markdown","e7013cb9":"markdown","12dc228b":"markdown","7122c316":"markdown","4cca095f":"markdown","d8106bcd":"markdown","002d2ea1":"markdown","2c3268a9":"markdown","7746702e":"markdown","93774ec9":"markdown","79c02e9b":"markdown","b3112107":"markdown"},"source":{"6b4ac870":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nmatplotlib.style.use('fivethirtyeight')","16878de4":"df=pd.read_csv(\"..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","c530bcb6":"#checking the dataframe head\ndf.head()","224b3231":"df.info()","5fb2e41f":"#Here we don't have any null values. Lets check the outlier values if any","ecf7fcdd":"sns.pairplot(df)","1e687004":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True)","fb7d3713":"df.corr()","9a83b972":"plt.figure(figsize=(10,10))\nfor feature in (df.columns):\n        plt.hist(df[feature])\n        plt.title(feature)\n        plt.show()","c6468044":"bins=(2,6.5,8)\ngroup_names = ['bad', 'good']\ndf['quality'] = pd.cut(df['quality'], bins = bins, labels = group_names)","8392f7a3":"from sklearn.preprocessing import  LabelEncoder\n#for changing into \nlabel_quality = LabelEncoder()\ndf['quality'] = label_quality.fit_transform(df['quality'])","eb811357":"df.head()","63362f51":"plt.figure(figsize=(10,10))\nfor feature in (df.columns):\n        sns.barplot(y=df[feature],x=df['quality'])\n        plt.title(feature)\n        plt.show()","9cc0f177":"from sklearn.preprocessing import StandardScaler\n","12710efa":"from sklearn.model_selection import train_test_split","17158247":"X=df.drop(['quality'],axis=1)\ny=df['quality']","550d2006":"ms=StandardScaler()\nX= ms.fit_transform(X)","e3fc0629":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=101)","afda1ef5":"from sklearn.ensemble import RandomForestClassifier","b5e3bace":"rf=RandomForestClassifier()","18728ef3":"rf.fit(X_train,y_train)","26f2e47a":"prediction=rf.predict(X_test)","fcf772d7":"print(\"Score on Train Set\",rf.score(X_train,y_train))","804291dd":"print(\"Score on Test Set\",rf.score(X_test,y_test))","a6eb9eaa":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","e10d9b17":"print(\"Classification Report on Random Forest\\n\",classification_report(y_test,prediction))","ae11e489":"print(\"Classification Report on Random Forest\\n\",confusion_matrix(y_test,prediction))","47493655":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Criterian to select\ncriterion=['gini','entropy']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# max_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]\n\n","42fb714e":"# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'criterion':criterion,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}\n\nprint(random_grid)","e80a68e4":"randomforest=RandomForestClassifier()","4f7410fb":"from sklearn.model_selection import RandomizedSearchCV","0e4f9b01":"rf_random = RandomizedSearchCV(estimator = randomforest, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=101, n_jobs = 1)","4695351b":"rf_random.fit(X_train,y_train)","b432d59b":"rf_random.best_params_","2d4f4742":"prediction=rf_random.predict(X_test)","2a3ceb77":"print(\"Classification Report on Random Forest\\n\",confusion_matrix(y_test,prediction))","c179cb2f":"print(\"Classification Report on Random Forest\\n\",classification_report(y_test,prediction))","4e3cd17c":"from xgboost import XGBClassifier","79f64daa":"xg=XGBClassifier()","9177d509":"xg.fit(X_train,y_train)","d0add3c3":"prediction=xg.predict(X_test)","9d74f647":"print(\"Classification Report on XGBoost\\n\",confusion_matrix(y_test,prediction))","adfdb5c8":"print(\"Classification Report on XGBoost\\n\",classification_report(y_test,prediction))","1ae1667f":"from sklearn.svm import SVC","6a49f067":"svc=SVC()","47ad265c":"svc.fit(X_train,y_train)","9c509379":"prediction=svc.predict(X_test)","c8970d75":"print(\"Classification Report on SVC\\n\",confusion_matrix(y_test,prediction))","08f882e7":"print(\"Classification Report on SVC\\n\",classification_report(y_test,prediction))","9d814d1e":"param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n              'kernel': ['linear','rbf','sigmoid']}  ","d746b3ae":"sv=SVC()","915d2584":"rf_random = RandomizedSearchCV(estimator = sv, param_distributions = param_grid, n_iter = 100, cv = 5, verbose=2, random_state=101, n_jobs = 1)","1f870009":"rf_random.fit(X_train,y_train)","41f3105d":"rf_random.best_params_","c78aeb4a":"prediction=rf_random.predict(X_test)","8fe26cda":"print(\"Classification Report on SVC\\n\",confusion_matrix(y_test,prediction))","81074331":"print(\"Classification Report on SVC\\n\",classification_report(y_test,prediction))","09a36062":"### Binning the Quality into Good and Bad ","79836cd3":"#### Scaling the data for getting better results","2634069c":"## Random Forest Classifier","e7013cb9":"### Random Forest with HyperParameter Tuning using RandomSearch CV","12dc228b":"### Splitting the data into train and test","7122c316":"### Check for the basic data ","4cca095f":"#### There is not much difference between HyperParameter Tuning and normal Random Forest","d8106bcd":"#### We can see little positive correlation between density and fixed acidity and negative correlation between ph and fixed acidity","002d2ea1":"## Creating model for the Prediction of Red Wine Quality taking it as Classifier Problem","2c3268a9":"### Support Vector Machine","7746702e":"### XGBoost Model","93774ec9":"### Exploratory Data Analysis","79c02e9b":"### Hyperparameter tuning with SVC","b3112107":"### Checking the correlation"}}