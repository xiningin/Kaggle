{"cell_type":{"99ae6a82":"code","7eaec39c":"code","e8c24583":"code","f4f623e1":"code","148182cb":"code","b2d4b0a2":"code","60e580f6":"code","f194720b":"code","82fe7824":"code","c98acf99":"code","859f4361":"code","9b2d35f2":"code","96fdea76":"markdown","5ab97716":"markdown","b9ae02ac":"markdown","ad52081a":"markdown","0fe45dc4":"markdown","b161e4af":"markdown","fbf2893e":"markdown","3f96033b":"markdown","cf9e5427":"markdown","0f65f611":"markdown","b3ef4b7a":"markdown","10ba88af":"markdown","f2c63b73":"markdown","5f4808c2":"markdown","671b9339":"markdown","152e8fdb":"markdown"},"source":{"99ae6a82":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","7eaec39c":"from google.colab import files\nuploaded = files.upload()\n\nimport io\nveri = pd.read_csv(io.BytesIO(uploaded['veri.csv'])) #we must change name of veri.csv\n#now our data imported as pandas dataframe","e8c24583":"print(veri.head())","f4f623e1":"url = 'https:\/\/raw.githubusercontent.com\/RegaipKURT\/R-Project-Giri-\/master\/cancer.csv' #Copied GitHub Link\n#When you load the URL, enter \"RAW\" and copy the link.\n\n#NOT ONLY APPLY TO GITHUB, WE CAN TRANSFER DATA FROM OTHER PLACES.\n\nveri_cancer = pd.read_csv(url)\n# Dataset is now stored in a Pandas Dataframe\n\nprint(veri_cancer.head())","148182cb":"from google.colab import drive\ndrive.mount('\/content\/gdrive')","b2d4b0a2":"veri = pd.read_csv(\"\/content\/gdrive\/My Drive\/Colab Notebooks\/datasets\/timesData.csv\")\nprint(veri.head())","60e580f6":"from google.colab import files\n\nuploaded = files.upload()\n\nfor fn in uploaded.keys():\n  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n      name=fn, length=len(uploaded[fn])))\n  \n# Then move kaggle.json into the folder where the API expects to find it.\n!mkdir -p ~\/.kaggle\/ && mv kaggle.json ~\/.kaggle\/ && chmod 600 ~\/.kaggle\/kaggle.json\n\n# WE NEED TO IMPORT KAGGLE MODULE\n!pip install kaggle\nimport kaggle\n!kaggle datasets download \"center-for-policing-equity\/data-science-for-good\"","f194720b":"pd.read_csv(\"veri.csv\") ","82fe7824":"from google.colab import drive\ndrive.mount('\/content\/gdrive')","c98acf99":"!mv \/content\/data-science-for-good.zip \/content\/gdrive\/My\\ Drive\/Colab\\ Notebooks\/datasets","859f4361":"#DOWNLOADING DATA\n!wget http:\/\/openpsychometrics.org\/_rawdata\/16PF.zip #link address","9b2d35f2":"#exrating data from zip\nimport zipfile\nwith zipfile.ZipFile(\"16PF.zip\", 'r') as zip_ref:\n    zip_ref.extractall(\"ornek_zip_klas\u00f6r\u00fc\") #\u00e7\u0131karaca\u011f\u0131m\u0131z klas\u00f6r ve yeri","96fdea76":"# 3 - RECEIVING THE FILE FROM DRIVE WITH PATH\nIn this way, after uploading our file to google drive, we import the drive and read the data via drive.\n\nWe need to press enter by entering the link that will be released and pasting the code in the field below.","5ab97716":"With this process, we can directly upload the file on our local drive and work on it. But the file will be deleted after logout. To prevent this, we can upload and read the file to drive, or copy it into drive after uploading it. Either way, the following sections show how to do it.\n\nThe important thing here is that \"data.csv\" should be the same as the name of the uploaded file. Otherwise, the file cannot be read.","b9ae02ac":"Let's copy the file we downloaded above into google drive.","ad52081a":"Yukar\u0131da belirtti\u011fim dosya ismi sorununa burada rastl\u0131yaca\u011f\u0131z. \u00c7\u00fcnk\u00fc bir linux komutuyla dosya ta\u015f\u0131ma i\u015flemi ger\u00e7ekle\u015ftirece\u011fiz ve dosya ismimiz t\u0131rnak i\u015faretleri ( \" \" ) aras\u0131nda olmayacak.\n\nE\u011fer dosya isimleri aras\u0131nda bo\u015fluk varsa bo\u015fluk olan yere yukar\u0131daki gibi ters slash koyarak belirtmemiz gerekiyor. ( \\ \u015fu i\u015faret yani)","0fe45dc4":"# 2 - LOADING FILES THROUGH GITHUB etc. PLACES AND READING TO PANDAS","b161e4af":"# 4.KAGGLE DATA DOWNLOAD AND WORK\n\nTo do this, you need to download the file * json * from kaggle account and click on the new api import section.\n\nThen, after doing this process, enter the page where the data kaggle.com\/ section and then copy the link section below * kaggle dataset download * after the text \"\" in the place we need to paste.\n\nThe link to our example is: https:\/\/www.kaggle.com\/center-for-policing-equity\/data-science-for-good\n\n","fbf2893e":"We can extract the data from the zip with the zipfile module.","3f96033b":"When implementing this path, the data must be accessible directly through its url. We can better understand how it looks from the link below:\n\nhttps:\/\/raw.githubusercontent.com\/regaipkurt\/r-project-giri-\/master\/cancer.csv\n\nIn this way, we can access the data directly to the pandas can be read through the url.","cf9e5427":"By importing the drive, we can also import the data into the drive. Just type the file path we want to extract in the extractall section","0f65f611":"After downloading and installing the file, it will appear in the files section. We can read the file directly.","b3ef4b7a":"# WORK WITH ZIP FILES\nIf we want to download a zip file or if the file we will use is a zip file, we can work as follows.\n\nWe can download any file with the wget command. (Not necessarily a zip file.)","10ba88af":"# Storing Data\nThe data we download will be lost after the session closes. If we want to keep this data, we can copy it into drive.\n\nTo do this, you need to import the drive first. Then we can move our file to drive with file move commands in linux operating system.\n\nImport Drive:","f2c63b73":"# Why do we use google colab?\n\nColab gives us high processing power, GPU, TPU usage and efficiency. Especially with the automatic code completion feature, it is very close to becoming an integrated development environment.\n\nGoogle Colab gives us 12 GB of RAM and approximately 360 GB of disk space for our data. Of course when we don't copy the data to drive. In addition, if we download and read data via google colab, we are able to download data much faster than our own internet speed. Because Google is downloading data to its own drive and using its own internet speed. As a result, we do not have a process related to our computer google own infrastructure and very quickly completes the work.\n\nIn addition, colab is a good option for our computers where there is insufficient processing power or time-consuming work.\n\nWe will explain the various ways of reading data below.","5f4808c2":"I named the file path gdrive you can write another name.\n\nIn Colab, you can go to the files section from the left-hand tab, find our file, then right-click and copy the path.\n\nIncidentally, if the path to the reverse slash file contains spaces, it is important. If the file path is given in \"\" double hacks, spaces may not be a problem. However, operations not specified in \"\" will result in a file not found error. In this case, do not forget to put a reverse slash (\\) in the spaces, or we may get a file not found error.\n\nKeep in mind that if you get the file not found error just in case you reverse slash.\n\nWhile we are reading data to pandas, we will not have any problem because we have read the data in double quotes like \"bus\".","671b9339":"# 1 - LOADING A FILE FROM THE LOCAL DRIVE AND TRANSFERING TO PANDAS","152e8fdb":"# **WAYS TO WORK WITH SPECIAL DATA ON COLAB**"}}