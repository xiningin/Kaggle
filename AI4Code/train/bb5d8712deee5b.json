{"cell_type":{"c411d725":"code","3d41276b":"code","e8782cce":"code","57d966f6":"code","14b137fd":"code","e4e9d70f":"code","ff50dca8":"code","8fce3101":"code","79072040":"code","475a9a95":"code","ba7d5447":"code","04016a57":"code","e90eaa98":"markdown","d58e4e01":"markdown","f898201f":"markdown","93c5aa1f":"markdown","f27323ff":"markdown","c8f7b8ce":"markdown","859d329e":"markdown","60b790a7":"markdown","04a38750":"markdown","3bb7fbc1":"markdown","a136c186":"markdown","0e573a8f":"markdown"},"source":{"c411d725":"!pip install google-play-scraper","3d41276b":"import json\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom pygments import highlight\nfrom pygments.lexers import JsonLexer\nfrom pygments.formatters import TerminalFormatter\n\nfrom google_play_scraper import Sort, reviews, app\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)","e8782cce":"app_packages = [\n  'com.anydo',\n  'com.todoist',\n  'com.ticktick.task',\n  'com.habitrpg.android.habitica',\n  'cc.forestapp',\n  'com.oristats.habitbull',\n  'com.levor.liferpgtasks',\n  'com.habitnow',\n  'com.microsoft.todos',\n  'prox.lab.calclock',\n  'com.gmail.jmartindev.timetune',\n  'com.artfulagenda.app',\n  'com.tasks.android',\n  'com.appgenix.bizcal',\n  'com.appxy.planner'\n]\n\nlen(app_packages)","57d966f6":"app_infos = []\n\nfor ap in tqdm(app_packages):\n  info = app(ap, lang='en', country='us')\n  del info['comments']\n  app_infos.append(info)","14b137fd":"def print_json(json_object):\n  json_str = json.dumps(\n    json_object,\n    indent=2,\n    sort_keys=True,\n    default=str\n  )\n  print(highlight(json_str, JsonLexer(), TerminalFormatter()))","e4e9d70f":"print_json(app_infos[0])","ff50dca8":"def format_title(title):\n  sep_index = title.find(':') if title.find(':') != -1 else title.find('-')\n  if sep_index != -1:\n    title = title[:sep_index]\n  return title[:10]\n\nfig, axs = plt.subplots(2, len(app_infos) \/\/ 2, figsize=(14, 5))\n\nfor i, ax in enumerate(axs.flat):\n  ai = app_infos[i]\n  img = plt.imread(ai['icon'])\n  ax.imshow(img)\n  ax.set_title(format_title(ai['title']))\n  ax.axis('off')","8fce3101":"app_infos_df = pd.DataFrame(app_infos)\napp_infos_df.to_csv('apps.csv', index=None, header=True)","79072040":"app_reviews = []\n\nfor ap in tqdm(app_packages):\n  for score in list(range(1, 6)):\n    for sort_order in [Sort.MOST_RELEVANT, Sort.NEWEST]:\n      rvs, _ = reviews(\n        ap,\n        lang='en',\n        country='us',\n        sort=sort_order,\n        count= 200 if score == 3 else 100,\n        filter_score_with=score\n      )\n      for r in rvs:\n        r['sortOrder'] = 'most_relevant' if sort_order == Sort.MOST_RELEVANT else 'newest'\n        r['appId'] = ap\n      app_reviews.extend(rvs)","475a9a95":"print_json(app_reviews[0])","ba7d5447":"len(app_reviews)","04016a57":"app_reviews_df = pd.DataFrame(app_reviews)\napp_reviews_df.to_csv('reviews.csv', index=None, header=True)","e90eaa98":"### Here is a sample app information from the list:","d58e4e01":"### We will store the app information for later by converting the JSON objects into a Pandas dataframe and saving the result into a CSV file:","f898201f":"### This contains lots of information including the number of ratings, number of reviews and number of ratings for each score (1 to 5). Let's ignore all of that and have a look at their beautiful icons:","93c5aa1f":"### We got the info for all 15 apps. Let's write a helper function that prints JSON objects a bit better:","f27323ff":"### Let's save the reviews to a CSV file:","c8f7b8ce":"### Lets see how to create a dataset for Sentiment Analysis by scraping user reviews for Android apps. We will convert the app and review information into Data Frames and save that to CSV files.\n\n### We will learn how to:\n#### * Set a goal and inclusion criteria for your dataset\n#### * Get real-world user reviews by scraping Google Play\n#### * Use Pandas to convert and save the dataset into CSV files","859d329e":"#### Let's install the required packages and setup the imports:","60b790a7":"## Scraping App Information\n### Lets scrape information for each app","04a38750":"### Number of reviews ","3bb7fbc1":"#### We want to get the necessary feedback for different applications, both negative and positive reviews would be good but the negative one can reveal critical features that are missing in an application's service. Lucky for us, Google Play as plenty of applications, reviews and scores. We will be scraping application info and reviews using the google-play-scraper package. \n\n#### There are a lot of applications which we can choose to analyze, but the different application categories contain different audiences and domain specific knowledge. We will start simple. We want apps that have been around some time, so opinion is collected organically. We want to mitigate advertising strategies as much as possible. Apps are constantly being updated, so the time of the review is an important factor. Ideally, you would want to collect every possible review and work with that. However, in the real world, data is often limited. So, we'll do the best we can.\n\n#### Let's choose some apps that fit the criteria from the Productivity category. We'll use AppAnnie to select some of the top US apps:","a136c186":"### Note that we're adding the app id and sort order to each review. Here's an example for one:","0e573a8f":"## Scraping App Reviews\n### In an ideal world, we would get all the reviews. But there are lots of them and we're scraping the data. That wouldn't be very polite. What should we do?\n\n### We want:\n\n#### * Balanced dataset - roughly the same number of reviews for each score (1-5)\n#### * A representative sample of the reviews for each app\n\n### We can satisfy the first requirement by using the scraping package option to filter the review score. For the second, we'll sort the reviews by their helpfulness, which are the reviews that Google Play thinks are most important. Just in case, we'll get a subset from the newest, too:"}}