{"cell_type":{"66e831fe":"code","7d3a887e":"code","06fe26f3":"code","792ac092":"code","30fa42d7":"code","c2a4fed7":"code","5e5d383e":"code","10e4afd1":"code","f437fe00":"code","a6c11bd6":"code","6582fcb1":"code","7d1bec6b":"markdown","6e4643c9":"markdown","2d915849":"markdown"},"source":{"66e831fe":"# install dependencies: (use cu101 because colab has CUDA 10.1)\n!pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n\n# install mmcv-full thus we could use CUDA operators\n!pip install mmcv-full\n\n# Install mmdetection\n!rm -rf mmdetection\n!git clone https:\/\/github.com\/open-mmlab\/mmdetection.git\n%cd mmdetection\n\n!pip install -e .\n\n# install Pillow 7.0.0 back in order to avoid bug in colab\n!pip install Pillow==7.0.0","7d3a887e":"# Check Pytorch installation\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n\n# Check MMDetection installation\nimport mmdet\nprint(mmdet.__version__)\n\n# Check mmcv installation\nfrom mmcv.ops import get_compiling_cuda_version, get_compiler_version\nprint(get_compiling_cuda_version())\nprint(get_compiler_version())","06fe26f3":"!mkdir checkpoints\n#download pretrained detector\n!wget -c https:\/\/download.openmmlab.com\/mmdetection\/v2.0\/mask_rcnn\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n      -O checkpoints\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth","792ac092":"from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\nfrom IPython.core.display import Video, display\nimport os\nimport subprocess\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport gc\nimport cv2\nimport shutil\n\n# Choose to use a config and initialize the detector\nconfig = 'configs\/mask_rcnn\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco.py'\n# Setup a checkpoint file to load\ncheckpoint = 'checkpoints\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n# initialize the detector\nmodel = init_detector(config, checkpoint, device='cuda:0')","30fa42d7":"data_dir = '\/kaggle\/input\/nfl-health-and-safety-helmet-assignment\/'\nexample_video = f'{data_dir}\/train\/57913_000218_Sideline.mp4'\n\nfrac = 0.65\n\ndisplay(Video(example_video, embed=True, height=int(720*frac), width=int(1280*frac)))","c2a4fed7":"\n# create frames \nimg_ext = 'png'\nimage_name = '57913_000218_Sideline'\nframe_dir = '\/kaggle\/tmp\/mp4_img\/'\nos.makedirs(frame_dir, exist_ok=True)\n\ncmd = 'ffmpeg -i \\\"{}\\\" -qscale:v 2 \\\"{}\/{}_%d.{}\\\"'.format(example_video, frame_dir, image_name, img_ext)\nprint(cmd)\nsubprocess.call(cmd, shell=True)","5e5d383e":"model = init_detector(config, checkpoint, device='cuda:0')\nprint('Number of classes: {}'.format(len(model.CLASSES)))\nprint(model.CLASSES)","10e4afd1":"def filter_results(result):\n    \"\"\"\n    Filter only person class from results (first class)\n    \"\"\"\n    bbox = [result[0][0]]\n    for i in range(79):\n        x = np.array([], dtype=np.float32)\n        x.shape = (0, 5)\n        bbox.append(x)\n\n    objects = [result[1][0]]\n    for i in range(79):\n        objects.append([])\n\n    return (bbox, objects)\n\nframe_bbox_dir = '\/kaggle\/tmp\/mp4_img_bbox\/'\nos.makedirs(frame_bbox_dir, exist_ok=True)\n\nfor f in tqdm(os.listdir(frame_dir)):\n    \n    img = f'{frame_dir}\/{f}'\n    # the model is initialized and deleted each time because of RAM usage\n    model = init_detector(config, checkpoint, device='cuda:0')\n    # get results\n    result = inference_detector(model, img)\n    # filter only person class\n    result_filtered = filter_results(result)\n    # save image with bboxes into out_file\n    model.show_result(img, result_filtered, out_file=os.path.join(frame_bbox_dir,f))\n    del result, result_filtered, model\n    gc.collect()","f437fe00":"# make video from frames\nvideo_name = '57913_000218_Sideline_players_fps60.mp4'\ntmp_video_path = os.path.join('\/kaggle\/working\/', f'tmp_{video_name}')\nvideo_path = os.path.join('\/kaggle\/working\/', video_name)\n\nframe_rate = 60\n\nimages = [img for img in os.listdir(frame_bbox_dir)]\nimages.sort(key = lambda x: int(x.split('_')[-1][:-4]))\n\nframe = cv2.imread(os.path.join(frame_bbox_dir, images[0]))\nheight, width, layers = frame.shape\n\nvideo = cv2.VideoWriter(tmp_video_path, cv2.VideoWriter_fourcc(*'MP4V'),\n                        frame_rate, (width,height))\n\nfor f in images:\n    img = cv2.imread(os.path.join(frame_bbox_dir, f))\n    video.write(img)\n\nvideo.release()\n\n# Not all browsers support the codec, we will re-load the file at tmp_video_path\n# and convert to a codec that is more broadly readable using ffmpeg\n\nif os.path.exists(video_path):\n    os.remove(video_path)\n    \nsubprocess.run([\"ffmpeg\", \"-i\", tmp_video_path, \"-crf\", \"18\", \"-preset\", \"veryfast\",\n                \"-vcodec\",\"libx264\", video_path,])\n\nos.remove(tmp_video_path)","a6c11bd6":"frac = 0.65\ndisplay(Video(video_path, embed=True, height=int(720*frac), width=int(1280*frac)))","6582fcb1":"# remove directories with frames (optional)\n\nfor path in [frame_dir, frame_bbox_dir]:\n    try:\n        shutil.rmtree(path)\n    except OSError as e:\n        print (\"Error: %s - %s.\" % (e.filename, e.strerror))","7d1bec6b":"The model loaded above is trained to detect multiple kind of objects. Below we can see what it is capable to detect. Because of that we will filter only results for first class (person).","6e4643c9":"### References:\n\n* MMDetection tutorial https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/demo\/MMDet_Tutorial.ipynb\n* NFL Helmet Assignment - Getting Started Guide https:\/\/www.kaggle.com\/robikscube\/nfl-helmet-assignment-getting-started-guide\n* Convert MP4 to PNG\/JPG and back https:\/\/www.kaggle.com\/denispotapov\/convert-mp4-to-png-jpg-and-back?scriptVersionId=72389425","2d915849":"# Goal\n\n**The goal of this notebook is to explore method for object detection, concretely person detection, using MMDetection high level API.** \n\n## MMDdetection\n\nMMDetection is an open source object detection toolbox based on PyTorch.\n\n### Major features\n\n* **Modular Design**\n\nThe detection framework consist of different components and one can easily construct a customized object detection framework by combining different modules.\n\n* **Support of multiple frameworks out of box**\n\nThe toolbox directly supports popular and contemporary detection frameworks, e.g. Faster RCNN, Mask RCNN, RetinaNet, etc.\n\n* **High efficiency**\n\nAll basic bbox and mask operations run on GPUs. The training speed is faster than or comparable to other codebases, including Detectron2, maskrcnn-benchmark and SimpleDet.\n\n* **State of the art**\n\nThe toolbox stems from the codebase developed by the MMDet team, who won COCO Detection Challenge in 2018, and we keep pushing it forward.\n"}}