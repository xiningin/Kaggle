{"cell_type":{"42bd8915":"code","305608a6":"code","c0ed66c4":"code","a22a82ca":"code","ae7d2b22":"code","832dd19e":"code","bd564ab0":"code","3cfa1350":"code","f3357cc9":"code","b66d2f46":"code","ff158876":"code","5484af0b":"code","76bb574b":"code","aaf96122":"code","73422977":"code","e5c22222":"code","3dfe2914":"code","383d21ea":"code","bca2cede":"code","58637793":"code","80307341":"markdown","ee89bbb7":"markdown","deb6c3db":"markdown","36673342":"markdown","7799bbe6":"markdown"},"source":{"42bd8915":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","305608a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","c0ed66c4":"# # Initial Python environment setup...\n# import numpy as np # linear algebra\n# import pandas as pd # CSV file I\/O (e.g. pd.read_csv)\n# import os # reading the input files we have access to\n\n# print(os.listdir('..\/input'))","a22a82ca":"# Read train data\ntaxi_train = pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/train.csv', nrows = 10_000_000)","ae7d2b22":"taxi_train.columns.to_list()","832dd19e":"taxi_train.dtypes","bd564ab0":"# Read sample submission\ntaxi_sample_sub = pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/sample_submission.csv')\ntaxi_sample_sub.head()","3cfa1350":"import matplotlib.pyplot as plt\n# Plot a histogram\ntaxi_train.fare_amount.hist(bins=30, alpha=0.5)\nplt.show() ","f3357cc9":"# Given a dataframe, add two new features 'abs_diff_longitude' and\n# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n# the pickup location to the dropoff location.\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n\nadd_travel_vector_features(taxi_train)","b66d2f46":"print(taxi_train.isnull().sum())","ff158876":"print('Old size: %d' % len(taxi_train))\ntaxi_train = taxi_train.dropna(how = 'any', axis = 'rows')\nprint('New size: %d' % len(taxi_train))","5484af0b":"plot = taxi_train.iloc[:2000].plot.scatter('abs_diff_longitude', 'abs_diff_latitude')","76bb574b":"print('Old size: %d' % len(taxi_train))\ntaxi_train = taxi_train[(taxi_train.abs_diff_longitude < 5.0) & (taxi_train.abs_diff_latitude < 5.0)]\nprint('New size: %d' % len(taxi_train))","aaf96122":"# Construct and return an Nx3 input matrix for our linear model\n# using the travel vector, plus a 1.0 for a constant bias term.\ndef get_input_matrix(df):\n    return np.column_stack((df.abs_diff_longitude, df.abs_diff_latitude, np.ones(len(df))))\n\ntaxi_train_X = get_input_matrix(taxi_train)\ntaxi_train_y = np.array(taxi_train['fare_amount'])\n\nprint(taxi_train_X.shape)\nprint(taxi_train_y.shape)","73422977":"# The lstsq function returns several things, and we only care about the actual weight vector w.\n(w, _, _, _) = np.linalg.lstsq(taxi_train_X, taxi_train_y, rcond = None)\nprint(w)","e5c22222":"w_OLS = np.matmul(np.matmul(np.linalg.inv(np.matmul(taxi_train_X.T, taxi_train_X)), taxi_train_X.T), taxi_train_y)\nprint(w_OLS)","3dfe2914":"# Read test data\ntaxi_test = pd.read_csv('..\/input\/new-york-city-taxi-fare-prediction\/test.csv')\ntaxi_test.columns.to_list()","383d21ea":"# Reuse the above helper functions to add our features and generate the input matrix.\nadd_travel_vector_features(taxi_test)\ntaxi_test_X = get_input_matrix(taxi_test)\n# Predict fare_amount on the test set using our model (w) trained on the training set.\ntaxi_test_y_predictions = np.matmul(taxi_test_X, w).round(decimals = 2)\n\n# Write the predictions to a CSV file which we can submit to the competition.\nsubmission = pd.DataFrame(\n    {'key': taxi_test.key, 'fare_amount': taxi_test_y_predictions},\n    columns = ['key', 'fare_amount'])\nsubmission.to_csv('submission.csv', index = False)\n\nprint(os.listdir('.'))","bca2cede":"# from sklearn.linear_model import LinearRegression\n# # Create a LinearRegression object\n# lr = LinearRegression()","58637793":"# # Fit the model on the train data\n# lr.fit(X=taxi_train[['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count']],\n# y=taxi_train['fare_amount']) ","80307341":"### Make predictions on the test set\nNow let's load up our test inputs and predict the fare_amounts for them using our learned weights!","ee89bbb7":"### Ideas for Improvement\nThe output here will score an RMSE of $5.74, but you can do better than that! Here are some suggestions:\n\n* Use more columns from the input data. Here we're only using the start\/end GPS points from columns [pickup|dropoff]_[latitude|longitude]. Try to see if the other columns -- pickup_datetime and passenger_count -- can help improve your results.\n* Use absolute location data rather than relative. Here we're only looking at the difference between the start and end points, but maybe the actual values -- indicating where in NYC the taxi is traveling -- would be useful.\n* Use a non-linear model to capture more intricacies within the data.\n* Try to find more outliers to prune, or construct useful feature crosses.\n* Use the entire dataset -- here we're only using about 20% of the training data!\n\nSpecial thanks to Dan Becker, Will Cukierski, and Julia Elliot for reviewing this Kernel and providing suggestions!","deb6c3db":"These weights pass a quick sanity check, since we'd expect the first two values -- the weights for the absolute longitude and latitude differences -- to be positive, as more distance should imply a higher fare, and we'd expect the bias term to loosely represent the cost of a very short ride.\n\nSidenote: we can actually calculate the weight column  w  directly using the Ordinary Least Squares method:  w=(XT\u22c5X)\u22121\u22c5XT\u22c5y","36673342":"### Train our model\nOur model will take the form  X\u22c5w=y  where  X  is a matrix of input features, and  y  is a column of the target variable, fare_amount, for each row. The weight column  w  is what we will \"learn\".\n\nFirst let's setup our input matrix  X  and target column  y  from our training set. The matrix  X  should consist of the two GPS coordinate differences, plus a third term of 1 to allow the model to learn a constant bias term. The column  y  should consist of the target fare_amount values.","7799bbe6":"Now let's use numpy's lstsq library function to find the optimal weight column  w ."}}