{"cell_type":{"75cb6634":"code","f6540c66":"code","101dfdb7":"code","e45c32c3":"code","2c11d4a7":"code","176471d9":"code","4652f674":"code","06615316":"code","e2e686e3":"code","93a77b35":"code","d6b45ec5":"code","667b5215":"code","e50797f6":"code","1a13bf28":"code","32d30acf":"code","4d62929b":"code","61289d93":"code","71d4fc7e":"markdown","16a5ead0":"markdown","39866733":"markdown","97f4ab11":"markdown","66590d06":"markdown","7aa71686":"markdown"},"source":{"75cb6634":"##\u51fa\u529b\nprint(\"Hello!!\")","f6540c66":"a = 192\nprint(a)","101dfdb7":"print(3+4)\nprint(3-4)\nprint(3*4)\nprint(3**4)\nprint(13\/4)\nprint(13\/\/4)\nprint(13%4)\nprint(\"aaa\"+\"bbb\")","e45c32c3":"print(8-3+4+2*0.6)\nprint(3-3**3+49\/\/7)","2c11d4a7":"import sys\nimport gc\nimport os\nimport random\nimport time\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\n\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nimport pydicom\nimport sklearn.metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom functools import partial\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score,recall_score,f1_score,log_loss\nfrom  sklearn.metrics import accuracy_score as acc\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.models as models\nfrom sklearn.model_selection import train_test_split\n#from aug import RandomAugMix\nfrom albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip,RandomGamma, RandomRotate90,GaussNoise,Cutout\nfrom albumentations.pytorch import ToTensorV2\n!pip install geffnet\nimport geffnet\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=42)\nSIZE = 512","176471d9":"import glob\nj = glob.glob(\"..\/input\/agriculture-crop-images\/crop_images\/jute\/*\")\nr = glob.glob(\"..\/input\/agriculture-crop-images\/crop_images\/rice\/*\")\ndf_j = pd.DataFrame()\ndf_j[\"path\"] = j\ndf_j[\"label\"] = 0\ndf_r = pd.DataFrame()\ndf_r[\"path\"] = r\ndf_r[\"label\"] = 1\ndf = pd.concat([df_r,df_j],axis =0)\ndf.head()","4652f674":"def func0(x):\n    return os.path.isfile(x)\ndf[\"exist\"] = df[\"path\"].map(func0)","06615316":"##train,test\u306b\u5206\u5272,train\u3092train,valid\u306b\u307e\u305f\u5206\u5272\ntrain,test = train_test_split(df)\ntrain = train.reset_index(drop=True)\nfolds = train.copy()\nkf = StratifiedKFold(n_splits=4, shuffle=True, random_state=2020)\nfor fold, (train_index, val_index) in enumerate(kf.split(folds.values, folds[\"label\"])):\n    print(\"num_train,val\",len(train_index),len(val_index),len(val_index)+len(train_index))\n    folds.loc[val_index, 'fold'] = int(fold)","e2e686e3":"# Utils\n# ====================================================\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n    \ndef init_logger(log_file='train.log'):\n    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n    \n    log_format = '%(asctime)s %(levelname)s %(message)s'\n    \n    stream_handler = StreamHandler()\n    stream_handler.setLevel(DEBUG)\n    stream_handler.setFormatter(Formatter(log_format))\n    \n    file_handler = FileHandler(log_file)\n    file_handler.setFormatter(Formatter(log_format))\n    \n    logger = getLogger('RSNA2020')\n    logger.setLevel(DEBUG)\n    logger.addHandler(stream_handler)\n    logger.addHandler(file_handler)\n    \n    return logger\nimport datetime\ndt_now = datetime.datetime.now()\nprint(\"\u5b9f\u9a13\u958b\u59cb\",dt_now)\nLOG_FILE = 'train{}.log'.format(dt_now)\nLOGGER = init_logger(LOG_FILE)","93a77b35":"class TrainDataset(Dataset):\n    def __init__(self, df,transform1=None, transform2=None):\n        self.df = df\n        self.transform = transform1\n        self.transform_ = transform2\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.df['path'].values[idx]\n        image = cv2.imread(file_path)\n        try:\n            image = cv2.resize(image,(SIZE,SIZE))\n        except Exception as e:\n            print(file_path)\n        label_ = self.df[\"label\"].values[idx]\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.transform_:\n            image = self.transform_(image=image)['image']\n        #label = torch.eye(5)[torch.tensor(label_)]\n        label = torch.tensor(label_)\n        \n        return image, label","d6b45ec5":"class efenet_Model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.model = geffnet.efficientnet_b0(pretrained=True, drop_rate=0.25)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 1)\n    def forward(self, x):\n        x = self.model(x)\n        return x\nclass inf_efnet_model(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.model = geffnet.efficientnet_b0(pretrained=False, drop_rate=0.25)\n        self.model.classifier = nn.Linear(self.model.classifier.in_features, 1)  \n    def forward(self, x):\n        x = self.model(x)\n        return x","667b5215":"def get_transforms1(*, data):\n\n    #train,valid\u4ee5\u5916\u3060\u3063\u305f\u3089\u6012\u308b\n    \n    if data == 'train':\n        return Compose([\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            #GaussNoise(p=0.5),\n            #RandomRotate90(p=0.5),\n            #RandomGamma(p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n    \n    elif data == 'valid':\n        return Compose([\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            )\n        ])\n\ndef to_tensor(*args):\n\n        return Compose([\n            ToTensorV2()\n        ])","e50797f6":"class CFG:\n    debug=False\n    lr=1e-4\n    batch_size=16\n    epochs=10# you can train more epochs\n    seed=777\n    target_size=1\n    n_fold=4\n    warmup=-1\n    device=1\n    under_sample=True","1a13bf28":"from  sklearn.metrics import roc_auc_score \ndef AUC(y_true,y_pred):\n    return roc_auc_score(y_true,y_pred)","32d30acf":"def train_fn(fold):\n    print(f\"### fold: {fold} ###\")\n\n        \n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n    train_dataset = TrainDataset(folds.loc[trn_idx].reset_index(drop=True), \n                                 transform1=get_transforms1(data='train'),transform2=to_tensor())#\n    valid_dataset = TrainDataset(folds.loc[val_idx].reset_index(drop=True), \n                                 transform1=get_transforms1(data='valid'),transform2=to_tensor())#\n\n    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=4)\n    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4)\n    model = efenet_Model()\n    \n    \n    model.to(device)\n    \n    optimizer = Adam(model.parameters(), lr=CFG.lr, amsgrad=False)\n    \n    criterion = nn.BCELoss()\n    best_score = -100\n    best_loss = np.inf\n    best_preds = None\n    \n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n\n        model.train()\n\n        if CFG.warmup>epoch:\n            print(\"freeze\")\n            for param in model.model.parameters():\n                param.requires_grad = False\n            for param in model.model.classifier.parameters():\n                param.requires_grad = True\n        \n        if CFG.warmup<=epoch:\n            print(\"unfreeze\")\n            for param in model.parameters():\n                param.requires_grad = True\n        avg_loss = 0.\n\n        optimizer.zero_grad()\n        tk0 = tqdm(enumerate(train_loader), total=len(train_loader))\n\n        for i, (images, labels) in tk0:\n\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            y_preds = model(images.float())\n            y_preds = torch.sigmoid(y_preds.view(-1))\n            \"\"\"\n            if i ==0:\n                print(y_preds.dtype,labels.dtype)\n                print(y_preds.shape,labels.shape)\"\"\"\n            loss = criterion(y_preds, labels.float())\n            \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            avg_loss += loss.item() \/ len(train_loader)\n        model.eval()\n        avg_val_loss = 0.\n        preds = []\n        valid_labels = []\n        tk1 = tqdm(enumerate(valid_loader), total=len(valid_loader))\n\n        for i, (images, labels) in tk1:\n            \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            with torch.no_grad():\n                y_preds = model(images.float())\n                \n                y_preds = torch.sigmoid(y_preds.view(-1))\n            preds.append(y_preds.to('cpu').numpy())\n            valid_labels.append(labels.to('cpu').numpy())\n\n            loss = criterion(y_preds,labels.float())\n            avg_val_loss += loss.item() \/ len(valid_loader)\n            \n        preds = np.concatenate(preds)\n        valid_labels = np.concatenate(valid_labels)\n\n        print(preds.shape,valid_labels.shape)\n\n        score = AUC(valid_labels,preds)\n\n        elapsed = time.time() - start_time\n        LOGGER.debug(f'  Epoch {epoch+1} - avg_train_loss: {avg_loss:.6f}  avg_val_loss: {avg_val_loss:.6f}  time: {elapsed:.0f}s')\n        \n        if score>best_score:#logloss\u306e\u30b9\u30b3\u30a2\u304c\u826f\u304b\u3063\u305f\u3089\u4e88\u6e2c\u5024\u3092\u66f4\u65b0...best_epoch\u3092\u304d\u3081\u308b\u305f\u3081\n            best_score = score\n            best_preds = preds\n            LOGGER.debug(f'  Epoch {epoch+1} - Save Best Score: {best_score:.4f}')\n            torch.save(model.state_dict(), f'fold{fold}_baseline.pth')#\u5404epoch\u306e\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3002\u3002\u3002best_epoch\u7d42\u4e86\u6642\u306e\u30e2\u30c7\u30eb\u3092\u63a8\u8ad6\u306b\u4f7f\u7528\u3059\u308b\uff1f\n    \n\n    return best_preds, valid_labels","4d62929b":"\"\"\"\npreds = []\nvalid_labels = []\nfor fold in range(CFG.n_fold):\n    _preds, _valid_labels = train_fn(fold)\n    preds.append(_preds)\n    valid_labels.append(_valid_labels)\npreds = np.concatenate(preds)\nvalid_labels = np.concatenate(valid_labels)\"\"\"","61289d93":"\"\"\"\n\nscore = AUC(valid_labels,preds)\nimport datetime\nfrom sklearn import metrics\ndt_now = datetime.datetime.now()\nprint(\"\u73fe\u5728\u6642\u523b\",dt_now)\nprint(\"=====AUC(CV)======\",score)\n\nacc = metrics.accuracy_score(valid_labels,preds>0.5)\nprint('  =====acc(CV)====== {}'.format(acc))\"\"\"","71d4fc7e":"#### Python\u3068\u306f\n* \u30b7\u30f3\u30d7\u30eb\u3067\u899a\u3048\u308b\u3053\u3068\u304c\u5c11\u306a\u3044\u69cb\u6587\n* 1\u884c\u3067\u591a\u304f\u306e\u51e6\u7406\u3092\u8a18\u8ff0\u53ef\u80fd\n* \u6a19\u6e96\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u3057\u3066\u3001\u8a00\u8a9e\u306b\u591a\u304f\u306e\u6a5f\u80fd\u304c\u3042\u3089\u304b\u3058\u3081\u7528\u610f\u3055\u308c\u3066\u3044\u308b\n* \u3055\u3089\u306b\u5e45\u5e83\u3044\u7528\u9014\u306b\u4f7f\u3048\u308bPython\u5411\u3051\u5916\u90e8\u30e9\u30a4\u30d6\u30e9\u30ea\u304c\u8c4a\u5bcc\u306b\u5b58\u5728\u3057\u3066\u3044\u308b\n\n\u3068\u3044\u3046\u7279\u5fb4\u304c\u3042\u308a\u3001\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u3092\u59cb\u3081\u308b\u306b\u6301\u3063\u3066\u3053\u3044\u306e\u8a00\u8a9e\u3002\n","16a5ead0":"###### \u51fa\u529b\n\u51fa\u529b\u306b\u306fprint(\u51fa\u529b\u3057\u305f\u3044\u3082\u306e\uff09\u3092\u7528\u3044\u308b","39866733":"###### \u56db\u5247\u6f14\u7b97\n\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u56db\u5247\u6f14\u7b97\u304c\u53ef\u80fd","97f4ab11":"###### \u5909\u6570\na = [\u30c7\u30fc\u30bf]\u3000\u3068\u3059\u308b\u3068\u3001a\u3068\u3044\u3046\u7bb1\u306b\u30c7\u30fc\u30bf\u3092\u683c\u7d0d\u3057\u305f\u3000\u3068\u3044\u3046\u30a4\u30e1\u30fc\u30b8\u3068\u306a\u308b\u3002\u3053\u308c\u3092\u201d\u5909\u6570\u306b\u5024\u3092\u4ee3\u5165\u3059\u308b\"\u3068\u3044\u3046\u3002","66590d06":"\u6f14\u7fd2\n\u9069\u5b9c\u3001**\u8abf\u3079\u308b**\u3000\u304c\u5927\u4e8b\u3067\u3059\u3002","7aa71686":"###### \u8a08\u7b97\u898f\u5247\n()\u306e\u4e2d\u304b\u3089\u8a08\u7b97\u3001\u4ed6\u306f\u5de6\u304b\u3089\u9806\u306b\u8a08\u7b97"}}