{"cell_type":{"a85752f1":"code","78db9082":"code","fc093c8e":"code","2f2e201c":"code","addc2d00":"code","bd1722ac":"code","bf1da3ac":"code","ad6aa7eb":"code","76af0709":"code","9fedf992":"code","cb34a624":"code","9f58ca55":"code","dc2ab4e5":"code","30bafdf2":"code","58d6134e":"code","63947a1f":"code","ed2c1f8d":"code","e3e4bc6d":"code","ad46f1de":"code","75513448":"code","876839e1":"code","c7bb82e0":"code","ff38cc63":"code","4e196d5a":"code","7fce0458":"code","14a4d656":"code","8027f9f4":"code","cb02aef8":"code","a6e4c4a0":"code","3aa38f19":"code","c2c54ac3":"code","077a8874":"code","32f21555":"code","ede0c3ba":"code","3e65571d":"code","0e2dac87":"code","58f79fd6":"code","773a4c32":"code","bbfbc29d":"code","11fbcf82":"code","a4d5fcf3":"code","4ab06779":"code","ca64c90b":"code","abd47d26":"code","1326276a":"code","2f2972c5":"code","15d1dc1a":"code","827a1f32":"code","51f53961":"code","d972878f":"code","64fe5065":"code","4cdb42ae":"code","423707d7":"code","e13ca829":"code","61623f7f":"code","ff906f9b":"code","695393ef":"code","d7d2c8b3":"code","a329b88a":"code","2a9d4b87":"code","7b8861ba":"code","fd687170":"code","a972651b":"code","949cacb0":"code","5a6fc8d3":"code","d34962e8":"code","e4ce607a":"code","5889a531":"code","bcc54301":"code","f041c279":"code","a37c217a":"code","ef131cb4":"code","fda49516":"code","4b41efab":"code","0c7cd3d8":"code","4bf5f6e3":"code","72c286bc":"code","0b7986b5":"code","d8e7122e":"code","b895a215":"code","8c139585":"code","871afe15":"code","534a2665":"code","ce3d7119":"code","c5178cb7":"code","2719d671":"code","74976389":"code","d29910ca":"code","c820371b":"code","1c05e3c4":"code","6988a937":"code","5cfbe932":"code","ad6b072f":"code","7a39db11":"code","1cc6ab67":"markdown","95cc5bc9":"markdown","ca2fb3dd":"markdown","5ab42019":"markdown","c28daad6":"markdown","2c31eaa7":"markdown","ee1d1b91":"markdown","7732614b":"markdown","49eea25e":"markdown","7f2fc8e0":"markdown","014662a1":"markdown","fe668e21":"markdown","4a3618b7":"markdown","7c9dc339":"markdown","936db731":"markdown","4d1746d3":"markdown","d58b93b5":"markdown","d61b69d9":"markdown","4ebb777b":"markdown","6105192a":"markdown","64af2e33":"markdown","af964bac":"markdown","57c00f2e":"markdown","9a5c89ab":"markdown","4f731e60":"markdown","c15e182e":"markdown","82aa4cb4":"markdown","7895655e":"markdown","19c489d5":"markdown","6b4fd295":"markdown","f7b0b222":"markdown","0820875a":"markdown","a8b9faed":"markdown","cdd8d7e4":"markdown","7524ae30":"markdown","b4e0910e":"markdown","03956282":"markdown","c826158f":"markdown","323d0ae6":"markdown","355a4af8":"markdown","06ec3156":"markdown","1f043a80":"markdown","61fe3605":"markdown","ae80608d":"markdown","e2f82222":"markdown","58e35e01":"markdown","68fe21bb":"markdown","f30e57a9":"markdown","552a58c4":"markdown","e13afe7e":"markdown","7ed7afa9":"markdown","a7c74841":"markdown","4460313d":"markdown","2c552a05":"markdown","4f98fe0b":"markdown","8519f39a":"markdown","040e80b6":"markdown","583772dd":"markdown","82ebced7":"markdown","81702029":"markdown","47f53cc6":"markdown","6a8cd5ea":"markdown","b53349b6":"markdown","e32eeff4":"markdown","3b14dc1c":"markdown","74744a1c":"markdown","55995f81":"markdown","ee459d9a":"markdown","b9a9c51e":"markdown","a0686646":"markdown","22cff063":"markdown","c9c2f1b8":"markdown","6883a3b3":"markdown","b6926347":"markdown","8658bc33":"markdown","d80d8b41":"markdown","a36d2dbb":"markdown","1484922c":"markdown","c6690eb5":"markdown"},"source":{"a85752f1":"# Python libraries\n# Classic,data manipulation and linear algebra\nimport pandas as pd\nimport numpy as np\n\n# Plots\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\nimport squarify\n\n# Data processing, metrics and modeling\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix,  roc_curve, precision_recall_curve, accuracy_score, roc_auc_score\nimport lightgbm as lgbm\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_predict\nfrom yellowbrick.classifier import DiscriminationThreshold\n\n# Stats\nimport scipy.stats as ss\nfrom scipy import interp\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\n\n# Time\nfrom contextlib import contextmanager\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') ","78db9082":"data = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","fc093c8e":"display(data.info(),data.head())","2f2e201c":"# 2 datasets\nD = data[(data['Outcome'] != 0)]\nH = data[(data['Outcome'] == 0)]\n\n#------------COUNT-----------------------\ndef target_count():\n    trace = go.Bar( x = data['Outcome'].value_counts().values.tolist(), \n                    y = ['healthy','diabetic' ], \n                    orientation = 'h', \n                    text=data['Outcome'].value_counts().values.tolist(), \n                    textfont=dict(size=15),\n                    textposition = 'auto',\n                    opacity = 0.8,marker=dict(\n                    color=['lightskyblue', 'gold'],\n                    line=dict(color='#000000',width=1.5)))\n\n    layout = dict(title =  'Count of Outcome variable')\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)\n\n#------------PERCENTAGE-------------------\ndef target_percent():\n    trace = go.Pie(labels = ['healthy','diabetic'], values = data['Outcome'].value_counts(), \n                   textfont=dict(size=15), opacity = 0.8,\n                   marker=dict(colors=['lightskyblue', 'gold'], \n                               line=dict(color='#000000', width=1.5)))\n\n\n    layout = dict(title =  'Distribution of Outcome variable')\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)","addc2d00":"target_count()\ntarget_percent()","bd1722ac":"data[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = data[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)","bf1da3ac":"# Define missing plot to detect all missing values in dataset\ndef missing_plot(dataset, key) :\n    null_feat = pd.DataFrame(len(dataset[key]) - dataset.isnull().sum(), columns = ['Count'])\n    percentage_null = pd.DataFrame((len(dataset[key]) - (len(dataset[key]) - dataset.isnull().sum()))\/len(dataset[key])*100, columns = ['Count'])\n    percentage_null = percentage_null.round(2)\n\n    trace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, text = percentage_null['Count'],  textposition = 'auto',marker=dict(color = '#7EC0EE',\n            line=dict(color='#000000',width=1.5)))\n\n    layout = dict(title =  \"Missing Values (count & %)\")\n\n    fig = dict(data = [trace], layout=layout)\n    py.iplot(fig)\n    ","ad6aa7eb":"# Plotting \nmissing_plot(data, 'Outcome')","76af0709":"plt.style.use('ggplot') # Using ggplot2 style visuals \n\nf, ax = plt.subplots(figsize=(11, 15))\n\nax.set_facecolor('#fafafa')\nax.set(xlim=(-.05, 200))\nplt.ylabel('Variables')\nplt.title(\"Overview Data Set\")\nax = sns.boxplot(data = data, \n  orient = 'h', \n  palette = 'Set2')","9fedf992":"def correlation_plot():\n    #correlation\n    correlation = data.corr()\n    #tick labels\n    matrix_cols = correlation.columns.tolist()\n    #convert to array\n    corr_array  = np.array(correlation)\n    trace = go.Heatmap(z = corr_array,\n                       x = matrix_cols,\n                       y = matrix_cols,\n                       colorscale='Viridis',\n                       colorbar   = dict() ,\n                      )\n    layout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                            #autosize = False,\n                            #height  = 1400,\n                            #width   = 1600,\n                            margin  = dict(r = 0 ,l = 100,\n                                           t = 0,b = 100,\n                                         ),\n                            yaxis   = dict(tickfont = dict(size = 9)),\n                            xaxis   = dict(tickfont = dict(size = 9)),\n                           )\n                      )\n    fig = go.Figure(data = [trace],layout = layout)\n    py.iplot(fig)","cb34a624":"correlation_plot()","9f58ca55":"def median_target(var):   \n    temp = data[data[var].notnull()]\n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    return temp","dc2ab4e5":"def plot_distribution(data_select, size_bin) :  \n    # 2 datasets\n    tmp1 = D[data_select]\n    tmp2 = H[data_select]\n    hist_data = [tmp1, tmp2]\n    \n    group_labels = ['diabetic', 'healthy']\n    colors = ['#FFD700', '#7EC0EE']\n\n    fig = ff.create_distplot(hist_data, group_labels, colors = colors, show_hist = True, bin_size = size_bin, curve_type='kde')\n    \n    fig['layout'].update(title = data_select)\n\n    py.iplot(fig, filename = 'Density plot')","30bafdf2":"plot_distribution('Insulin', 0)","58d6134e":"median_target('Insulin')","63947a1f":"data.loc[(data['Outcome'] == 0 ) & (data['Insulin'].isnull()), 'Insulin'] = 102.5\ndata.loc[(data['Outcome'] == 1 ) & (data['Insulin'].isnull()), 'Insulin'] = 169.5","ed2c1f8d":"plot_distribution('Glucose', 0)","e3e4bc6d":"median_target('Glucose')","ad46f1de":"data.loc[(data['Outcome'] == 0 ) & (data['Glucose'].isnull()), 'Glucose'] = 107\ndata.loc[(data['Outcome'] == 1 ) & (data['Glucose'].isnull()), 'Glucose'] = 140","75513448":"plot_distribution('SkinThickness', 10)","876839e1":"median_target('SkinThickness')","c7bb82e0":"data.loc[(data['Outcome'] == 0 ) & (data['SkinThickness'].isnull()), 'SkinThickness'] = 27\ndata.loc[(data['Outcome'] == 1 ) & (data['SkinThickness'].isnull()), 'SkinThickness'] = 32","ff38cc63":"plot_distribution('BloodPressure', 5)","4e196d5a":"median_target('BloodPressure')","7fce0458":"data.loc[(data['Outcome'] == 0 ) & (data['BloodPressure'].isnull()), 'BloodPressure'] = 70\ndata.loc[(data['Outcome'] == 1 ) & (data['BloodPressure'].isnull()), 'BloodPressure'] = 74.5","14a4d656":"plot_distribution('BMI', 0)","8027f9f4":"median_target('BMI')","cb02aef8":"data.loc[(data['Outcome'] == 0 ) & (data['BMI'].isnull()), 'BMI'] = 30.1\ndata.loc[(data['Outcome'] == 1 ) & (data['BMI'].isnull()), 'BMI'] = 34.3","a6e4c4a0":"#plot distribution \nplot_distribution('Age', 0)\nplot_distribution('Pregnancies', 0)\nplot_distribution('DiabetesPedigreeFunction', 0)","3aa38f19":"missing_plot(data, 'Outcome')","c2c54ac3":"def plot_feat1_feat2(feat1, feat2) :  \n    D = data[(data['Outcome'] != 0)]\n    H = data[(data['Outcome'] == 0)]\n    trace0 = go.Scatter(\n        x = D[feat1],\n        y = D[feat2],\n        name = 'diabetic',\n        mode = 'markers', \n        marker = dict(color = '#FFD700',\n            line = dict(\n                width = 1)))\n\n    trace1 = go.Scatter(\n        x = H[feat1],\n        y = H[feat2],\n        name = 'healthy',\n        mode = 'markers',\n        marker = dict(color = '#7EC0EE',\n            line = dict(\n                width = 1)))\n\n    layout = dict(title = feat1 +\" \"+\"vs\"+\" \"+ feat2,\n                  yaxis = dict(title = feat2,zeroline = False),\n                  xaxis = dict(title = feat1, zeroline = False)\n                 )\n\n    plots = [trace0, trace1]\n\n    fig = dict(data = plots, layout=layout)\n    py.iplot(fig)","077a8874":"def barplot(var_select, sub) :\n    tmp1 = data[(data['Outcome'] != 0)]\n    tmp2 = data[(data['Outcome'] == 0)]\n    tmp3 = pd.DataFrame(pd.crosstab(data[var_select],data['Outcome']), )\n    tmp3['% diabetic'] = tmp3[1] \/ (tmp3[1] + tmp3[0]) * 100\n\n    color=['lightskyblue','gold' ]\n    trace1 = go.Bar(\n        x=tmp1[var_select].value_counts().keys().tolist(),\n        y=tmp1[var_select].value_counts().values.tolist(),\n        text=tmp1[var_select].value_counts().values.tolist(),\n        textposition = 'auto',\n        name='diabetic',opacity = 0.8, marker=dict(\n        color='gold',\n        line=dict(color='#000000',width=1)))\n\n    \n    trace2 = go.Bar(\n        x=tmp2[var_select].value_counts().keys().tolist(),\n        y=tmp2[var_select].value_counts().values.tolist(),\n        text=tmp2[var_select].value_counts().values.tolist(),\n        textposition = 'auto',\n        name='healthy', opacity = 0.8, marker=dict(\n        color='lightskyblue',\n        line=dict(color='#000000',width=1)))\n    \n    trace3 =  go.Scatter(   \n        x=tmp3.index,\n        y=tmp3['% diabetic'],\n        yaxis = 'y2',\n        name='% diabetic', opacity = 0.6, marker=dict(\n        color='black',\n        line=dict(color='#000000',width=0.5\n        )))\n\n    layout = dict(title =  str(var_select)+' '+(sub),\n              xaxis=dict(), \n              yaxis=dict(title= 'Count'), \n              yaxis2=dict(range= [-0, 75], \n                          overlaying= 'y', \n                          anchor= 'x', \n                          side= 'right',\n                          zeroline=False,\n                          showgrid= False, \n                          title= '% diabetic'\n                         ))\n\n    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n    py.iplot(fig)","32f21555":"# Define pie plot to visualize each variable repartition vs target modalities : Survived or Died (train)\ndef plot_pie(var_select, sub) :\n    D = data[(data['Outcome'] != 0)]\n    H = data[(data['Outcome'] == 0)]\n    \n    col =['Silver', 'mediumturquoise','#CF5C36','lightblue','magenta', '#FF5D73','#F2D7EE','mediumturquoise']\n    \n    trace1 = go.Pie(values  = D[var_select].value_counts().values.tolist(),\n                    labels  = D[var_select].value_counts().keys().tolist(),\n                    textfont=dict(size=15), opacity = 0.8,\n                    hole = 0.5, \n                    hoverinfo = \"label+percent+name\",\n                    domain  = dict(x = [.0,.48]),\n                    name    = \"Diabetic\",\n                    marker  = dict(colors = col, line = dict(width = 1.5)))\n    trace2 = go.Pie(values  = H[var_select].value_counts().values.tolist(),\n                    labels  = H[var_select].value_counts().keys().tolist(),\n                    textfont=dict(size=15), opacity = 0.8,\n                    hole = 0.5,\n                    hoverinfo = \"label+percent+name\",\n                    marker  = dict(line = dict(width = 1.5)),\n                    domain  = dict(x = [.52,1]),\n                    name    = \"Healthy\" )\n\n    layout = go.Layout(dict(title = var_select + \" distribution by target <br>\"+(sub),\n                            annotations = [ dict(text = \"Diabetic\"+\" : \"+\"268\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .22, y = -0.1),\n                                            dict(text = \"Healthy\"+\" : \"+\"500\",\n                                                font = dict(size = 13),\n                                                showarrow = False,\n                                                x = .8,y = -.1)]))\n                                          \n\n    fig  = go.Figure(data = [trace1,trace2],layout = layout)\n    py.iplot(fig)","ede0c3ba":"plot_feat1_feat2('Glucose','Age')","3e65571d":"palette ={0 : 'lightblue', 1 : 'gold'}\nedgecolor = 'black'\n\nfig = plt.figure(figsize=(12,8))\n\nax1 = sns.scatterplot(x = data['Glucose'], y = data['Age'], hue = \"Outcome\",\n                    data = data, palette = palette, edgecolor=edgecolor)\n\nplt.annotate('N1', size=25, color='black', xy=(80, 30), xytext=(60, 35),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.plot([50, 120], [30, 30], linewidth=2, color = 'red')\nplt.plot([120, 120], [20, 30], linewidth=2, color = 'red')\nplt.plot([50, 120], [20, 20], linewidth=2, color = 'red')\nplt.plot([50, 50], [20, 30], linewidth=2, color = 'red')\nplt.title('Glucose vs Age')\nplt.show()","0e2dac87":"data.loc[:,'N1']=0\ndata.loc[(data['Age']<=30) & (data['Glucose']<=120),'N1']=1","58f79fd6":"barplot('N1', ':Glucose <= 120 and Age <= 30')","773a4c32":"plot_pie('N1', '(Glucose <= 120 and Age <= 30)')","bbfbc29d":"data.loc[:,'N2']=0\ndata.loc[(data['BMI']<=30),'N2']=1","11fbcf82":"barplot('N2', ': BMI <= 30')","a4d5fcf3":"plot_pie('N2', 'BMI <= 30')","4ab06779":"plot_feat1_feat2('Pregnancies','Age')","ca64c90b":"palette ={0 : 'lightblue', 1 : 'gold'}\nedgecolor = 'black'\n\nfig = plt.figure(figsize=(12,8))\n\nax1 = sns.scatterplot(x = data['Pregnancies'], y = data['Age'], hue = \"Outcome\",\n                    data = data, palette = palette, edgecolor=edgecolor)\n\nplt.annotate('N3', size=25, color='black', xy=(6, 25), xytext=(10, 25),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.plot([0, 6], [30, 30], linewidth=2, color = 'red')\nplt.plot([6, 6], [20, 30], linewidth=2, color = 'red')\nplt.plot([0, 6], [20, 20], linewidth=2, color = 'red')\nplt.plot([0, 0], [20, 30], linewidth=2, color = 'red')\nplt.title('Pregnancies vs Age')\nplt.show()","abd47d26":"data.loc[:,'N3']=0\ndata.loc[(data['Age']<=30) & (data['Pregnancies']<=6),'N3']=1","1326276a":"barplot('N3', ': Age <= 30 and Pregnancies <= 6')","2f2972c5":"plot_pie('N3', 'Age <= 30 and Pregnancies <= 6')","15d1dc1a":"plot_feat1_feat2('Glucose','BloodPressure')","827a1f32":"palette ={0 : 'lightblue', 1 : 'gold'}\nedgecolor = 'black'\n\nfig = plt.figure(figsize=(12,8))\n\nax1 = sns.scatterplot(x = data['Glucose'], y = data['BloodPressure'], hue = \"Outcome\",\n                    data = data, palette = palette, edgecolor=edgecolor)\n\nplt.annotate('N4', size=25, color='black', xy=(70, 80), xytext=(50, 110),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.plot([40, 105], [80, 80], linewidth=2, color = 'red')\nplt.plot([40, 40], [20, 80], linewidth=2, color = 'red')\nplt.plot([40, 105], [20, 20], linewidth=2, color = 'red')\nplt.plot([105, 105], [20, 80], linewidth=2, color = 'red')\nplt.title('Glucose vs BloodPressure')\nplt.show()","51f53961":"data.loc[:,'N4']=0\ndata.loc[(data['Glucose']<=105) & (data['BloodPressure']<=80),'N4']=1","d972878f":"barplot('N4', ': Glucose <= 105 and BloodPressure <= 80')","64fe5065":"plot_pie('N4', 'Glucose <= 105 and BloodPressure <= 80')","4cdb42ae":"data.loc[:,'N5']=0\ndata.loc[(data['SkinThickness']<=20) ,'N5']=1","423707d7":"barplot('N5', ':SkinThickness <= 20')","e13ca829":"plot_pie('N5', 'SkinThickness <= 20')","61623f7f":"plot_feat1_feat2('SkinThickness','BMI')","ff906f9b":"data.loc[:,'N6']=0\ndata.loc[(data['BMI']<30) & (data['SkinThickness']<=20),'N6']=1","695393ef":"palette ={0 : 'lightblue', 1 : 'gold'}\nedgecolor = 'black'\n\nfig = plt.figure(figsize=(12,8))\n\nax1 = sns.scatterplot(x = data['SkinThickness'], y = data['BMI'], hue = \"Outcome\",\n                    data = data, palette = palette, edgecolor=edgecolor)\n\nplt.annotate('N6', size=25, color='black', xy=(20, 20), xytext=(50, 25),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.plot([0, 20], [30, 30], linewidth=2, color = 'red')\nplt.plot([0, 0], [16, 30], linewidth=2, color = 'red')\nplt.plot([0, 20], [16, 16], linewidth=2, color = 'red')\nplt.plot([20, 20], [16, 30], linewidth=2, color = 'red')\nplt.title('SkinThickness vs BMI')\nplt.show()","d7d2c8b3":"barplot('N6', ': BMI < 30 and SkinThickness <= 20')","a329b88a":"plot_pie('N6', 'BMI < 30 and SkinThickness <= 20')","2a9d4b87":"plot_feat1_feat2('Glucose','BMI')","7b8861ba":"palette ={0 : 'lightblue', 1 : 'gold'}\nedgecolor = 'black'\n\nfig = plt.figure(figsize=(12,8))\n\nax1 = sns.scatterplot(x = data['Glucose'], y = data['BMI'], hue = \"Outcome\",\n                    data = data, palette = palette, edgecolor=edgecolor)\n\nplt.annotate('N7', size=25, color='black', xy=(70, 35), xytext=(40, 60),\n            arrowprops=dict(facecolor='black', shrink=0.05),\n            )\nplt.plot([105, 105], [16, 30], linewidth=2, color = 'red')\nplt.plot([40, 40], [16, 30], linewidth=2, color = 'red')\nplt.plot([40, 105], [16, 16], linewidth=2, color = 'red')\nplt.plot([40, 105], [30, 30], linewidth=2, color = 'red')\nplt.title('Glucose vs BMI')\nplt.show()","fd687170":"data.loc[:,'N7']=0\ndata.loc[(data['Glucose']<=105) & (data['BMI']<=30),'N7']=1","a972651b":"barplot('N7', ': Glucose <= 105 and BMI <= 30')","949cacb0":"plot_pie('N7', 'Glucose <= 105 and BMI <= 30')","5a6fc8d3":"plot_distribution('Insulin', 0)","d34962e8":"data.loc[:,'N9']=0\ndata.loc[(data['Insulin']<200),'N9']=1","e4ce607a":"barplot('N9', ': Insulin < 200')","5889a531":"plot_pie('N9', 'Insulin < 200')","bcc54301":"data.loc[:,'N10']=0\ndata.loc[(data['BloodPressure']<80),'N10']=1","f041c279":"barplot('N10', ': BloodPressure < 80')","a37c217a":"plot_pie('N10', 'BloodPressure < 80')","ef131cb4":"plot_distribution('Pregnancies', 0)","fda49516":"data.loc[:,'N11']=0\ndata.loc[(data['Pregnancies']<4) & (data['Pregnancies']!=0) ,'N11']=1","4b41efab":"barplot('N11', ': Pregnancies > 0 and < 4')","0c7cd3d8":"plot_pie('N11', 'Pregnancies > 0 and < 4')","4bf5f6e3":"data['N0'] = data['BMI'] * data['SkinThickness']\n\ndata['N8'] =  data['Pregnancies'] \/ data['Age']\n\ndata['N13'] = data['Glucose'] \/ data['DiabetesPedigreeFunction']\n\ndata['N12'] = data['Age'] * data['DiabetesPedigreeFunction']\n\ndata['N14'] = data['Age'] \/ data['Insulin']\n","72c286bc":"D = data[(data['Outcome'] != 0)]\nH = data[(data['Outcome'] == 0)]","0b7986b5":"plot_distribution('N0', 0)","d8e7122e":"data.loc[:,'N15']=0\ndata.loc[(data['N0']<1034) ,'N15']=1","b895a215":"barplot('N15', ': N0 < 1034')","8c139585":"plot_pie('N15', 'N0 < 1034')","871afe15":"target_col = [\"Outcome\"]\ncat_cols   = data.nunique()[data.nunique() < 12].keys().tolist()\ncat_cols   = [x for x in cat_cols ]\n#numerical columns\nnum_cols   = [x for x in data.columns if x not in cat_cols + target_col]\n#Binary columns with 2 values\nbin_cols   = data.nunique()[data.nunique() == 2].keys().tolist()\n#Columns more than 2 values\nmulti_cols = [i for i in cat_cols if i not in bin_cols]\n\n#Label encoding Binary columns\nle = LabelEncoder()\nfor i in bin_cols :\n    data[i] = le.fit_transform(data[i])\n    \n#Duplicating columns for multi value columns\ndata = pd.get_dummies(data = data,columns = multi_cols )\n\n#Scaling Numerical columns\nstd = StandardScaler()\nscaled = std.fit_transform(data[num_cols])\nscaled = pd.DataFrame(scaled,columns=num_cols)\n\n#dropping original values merging scaled values for numerical columns\ndf_data_og = data.copy()\ndata = data.drop(columns = num_cols,axis = 1)\ndata = data.merge(scaled,left_index=True,right_index=True,how = \"left\")","534a2665":"def correlation_plot():\n    #correlation\n    correlation = data.corr()\n    #tick labels\n    matrix_cols = correlation.columns.tolist()\n    #convert to array\n    corr_array  = np.array(correlation)\n    trace = go.Heatmap(z = corr_array,\n                       x = matrix_cols,\n                       y = matrix_cols,\n                       colorscale='Viridis',\n                       colorbar   = dict() ,\n                      )\n    layout = go.Layout(dict(title = 'Correlation Matrix for variables',\n                            #autosize = False,\n                            #height  = 1400,\n                            #width   = 1600,\n                            margin  = dict(r = 0 ,l = 100,\n                                           t = 0,b = 100,\n                                         ),\n                            yaxis   = dict(tickfont = dict(size = 9)),\n                            xaxis   = dict(tickfont = dict(size = 9)),\n                           )\n                      )\n    fig = go.Figure(data = [trace],layout = layout)\n    py.iplot(fig)\n","ce3d7119":"correlation_plot()","c5178cb7":"# Def X and Y\nX = data.drop('Outcome', 1)\ny = data['Outcome']","2719d671":"def model_performance(model, subtitle) :   \n    #Kfold\n    cv = KFold(n_splits=5,shuffle=False, random_state = 42)\n    y_real = []\n    y_proba = []\n    tprs = []\n    aucs = []\n    mean_fpr = np.linspace(0,1,100)\n    i = 1\n    \n    for train,test in cv.split(X,y):\n        model.fit(X.iloc[train], y.iloc[train])\n        pred_proba = model.predict_proba(X.iloc[test])\n        precision, recall, _ = precision_recall_curve(y.iloc[test], pred_proba[:,1])\n        y_real.append(y.iloc[test])\n        y_proba.append(pred_proba[:,1])\n        fpr, tpr, t = roc_curve(y[test], pred_proba[:, 1])\n        tprs.append(interp(mean_fpr, fpr, tpr))\n        roc_auc = auc(fpr, tpr)\n        aucs.append(roc_auc) \n    \n    # Confusion matrix\n    y_pred = cross_val_predict(model, X, y, cv=5)\n    conf_matrix = confusion_matrix(y, y_pred)\n    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                        colorscale = 'Viridis', showscale  = False)\n    \n    #Show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)\/(tp+tn+fp+fn))\n    Precision =  (tp\/(tp+fp))\n    Recall    =  (tp\/(tp+fn))\n    F1_score  =  (2*(((tp\/(tp+fp))*(tp\/(tp+fn)))\/((tp\/(tp+fp))+(tp\/(tp+fn)))))\n\n    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n    show_metrics = show_metrics.T\n\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n    trace2 = go.Bar(x = (show_metrics[0].values), \n                    y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto', textfont=dict(color='black'),\n                    orientation = 'h', opacity = 1, marker=dict(\n            color=colors,\n            line=dict(color='#000000',width=1.5)))\n\n    #Roc curve\n    mean_tpr = np.mean(tprs, axis=0)\n    mean_auc = auc(mean_fpr, mean_tpr)\n\n    trace3 = go.Scatter(x=mean_fpr, y=mean_tpr,\n                        name = \"Roc : \" ,\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n    trace4 = go.Scatter(x = [0,1],y = [0,1],\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n    \n    #Precision - recall curve\n    y_real = y\n    y_proba = np.concatenate(y_proba)\n    precision, recall, _ = precision_recall_curve(y_real, y_proba)\n\n    trace5 = go.Scatter(x = recall, y = precision,\n                        name = \"Precision\" + str(precision),\n                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n    \n    mean_auc=round(mean_auc,3)\n    #Subplots\n    fig = tls.make_subplots(rows=2, cols=2, print_grid=False,\n                          specs=[[{}, {}], \n                                 [{}, {}]],\n                          subplot_titles=('Confusion Matrix',\n                                          'Metrics',\n                                          'ROC curve'+\" \"+ '('+ str(mean_auc)+')',\n                                          'Precision - Recall curve',\n                                          ))\n    #Trace and layout\n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,2,1)\n    fig.append_trace(trace4,2,1)\n    fig.append_trace(trace5,2,2)\n    \n    fig['layout'].update(showlegend = False, title = '<b>Model performance report (5 folds)<\/b><br>'+subtitle,\n                        autosize = False, height = 830, width = 830,\n                        plot_bgcolor = 'black',\n                        paper_bgcolor = 'black',\n                        margin = dict(b = 195), font=dict(color='white'))\n    fig[\"layout\"][\"xaxis1\"].update(color = 'white')\n    fig[\"layout\"][\"yaxis1\"].update(color = 'white')\n    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1], color = 'white')))\n    fig[\"layout\"][\"yaxis2\"].update(color = 'white')\n    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"), color = 'white')\n    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"),color = 'white')\n    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05],color = 'white')\n    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05],color = 'white')\n    for i in fig['layout']['annotations']:\n        i['font'] = titlefont=dict(color='white', size = 14)\n    py.iplot(fig)","74976389":"def scores_table(model, subtitle):\n    scores = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n    res = []\n    for sc in scores:\n        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n        res.append(scores)\n    df = pd.DataFrame(res).T\n    df.loc['mean'] = df.mean()\n    df.loc['std'] = df.std()\n    df= df.rename(columns={0: 'accuracy', 1:'precision', 2:'recall',3:'f1',4:'roc_auc'})\n\n    trace = go.Table(\n        header=dict(values=['<b>Fold', '<b>Accuracy', '<b>Precision', '<b>Recall', '<b>F1 score', '<b>Roc auc'],\n                    line = dict(color='#7D7F80'),\n                    fill = dict(color='#a1c3d1'),\n                    align = ['center'],\n                    font = dict(size = 15)),\n        cells=dict(values=[('1','2','3','4','5','mean', 'std'),\n                           np.round(df['accuracy'],3),\n                           np.round(df['precision'],3),\n                           np.round(df['recall'],3),\n                           np.round(df['f1'],3),\n                           np.round(df['roc_auc'],3)],\n                   line = dict(color='#7D7F80'),\n                   fill = dict(color='#EDFAFF'),\n                   align = ['center'], font = dict(size = 15)))\n\n    layout = dict(width=800, height=400, title = '<b>Cross Validation - 5 folds<\/b><br>'+subtitle, font = dict(size = 15))\n    fig = dict(data=[trace], layout=layout)\n\n    py.iplot(fig, filename = 'styled_table')","d29910ca":"random_state=42\n\nfit_params = {\"early_stopping_rounds\" : 100, \n             \"eval_metric\" : 'auc', \n             \"eval_set\" : [(X,y)],\n             'eval_names': ['valid'],\n             'verbose': 0,\n             'categorical_feature': 'auto'}\n\nparam_test = {'learning_rate' : [0.01, 0.02, 0.03, 0.04, 0.05, 0.08, 0.1, 0.2, 0.3, 0.4],\n              'n_estimators' : [100, 200, 300, 400, 500, 600, 800, 1000, 1500, 2000],\n              'num_leaves': sp_randint(6, 50), \n              'min_child_samples': sp_randint(100, 500), \n              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n              'subsample': sp_uniform(loc=0.2, scale=0.8), \n              'max_depth': [-1, 1, 2, 3, 4, 5, 6, 7],\n              'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n              'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n              'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n\n#number of combinations\nn_iter = 300\n\n#intialize lgbm and lunch the search\nlgbm_clf = lgbm.LGBMClassifier(random_state=random_state, silent=True, metric='None', n_jobs=4)\ngrid_search = RandomizedSearchCV(\n    estimator=lgbm_clf, param_distributions=param_test, \n    n_iter=n_iter,\n    scoring='accuracy',\n    cv=5,\n    refit=True,\n    random_state=random_state,\n    verbose=True)\n\ngrid_search.fit(X, y, **fit_params)\nopt_parameters =  grid_search.best_params_\nlgbm_clf = lgbm.LGBMClassifier(**opt_parameters)","c820371b":"model_performance(lgbm_clf, 'LightGBM')\nscores_table(lgbm_clf, 'LightGBM')","1c05e3c4":"visualizer = DiscriminationThreshold(lgbm_clf)\n\nvisualizer.fit(X, y)  \nvisualizer.poof() ","6988a937":"knn_clf = KNeighborsClassifier()\n\nvoting_clf = VotingClassifier(estimators=[ \n    ('lgbm_clf', lgbm_clf),\n    ('knn', KNeighborsClassifier())], voting='soft', weights = [1,1])\n\nparams = {\n      'knn__n_neighbors': np.arange(1,30)\n      }\n      \ngrid = GridSearchCV(estimator=voting_clf, param_grid=params, cv=5)\n\ngrid.fit(X,y)\n\nprint(\"Best Score:\" + str(grid.best_score_))\nprint(\"Best Parameters: \" + str(grid.best_params_))","5cfbe932":"knn_clf = KNeighborsClassifier(n_neighbors = 25)\n\nvoting_clf = VotingClassifier (\n        estimators = [('knn', knn_clf), ('lgbm', lgbm_clf)],\n                     voting='soft', weights = [1,1])","ad6b072f":"model_performance(voting_clf, 'LightGBM & KNN')\nscores_table(voting_clf, 'LightGBM & KNN')","7a39db11":"visualizer = DiscriminationThreshold(voting_clf)\n\nvisualizer.fit(X, y)  \nvisualizer.poof()  ","1cc6ab67":"**LightGBM** is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n\n* Faster training speed and higher efficiency.\n* Lower memory usage.\n* Better accuracy.\n* Support of parallel and GPU learning.\n* Capable of handling large-scale data.","95cc5bc9":"- <a href='#1'>1. Load libraries and read the data<\/a>  \n\n    - <a href='#1.1'>1.1. Load libraries<\/a> \n    - <a href='#1.2'>1.2. Read the data<\/a> \n    \n- <a href='#2'>2. Overview<\/a> \n\n    - <a href='#2.1'>2.1. Head<\/a> \n    - <a href='#2.2'>2.2. Target<\/a> \n    - <a href='#2.3'>2.3. Missing values<\/a> \n    \n- <a href='#3'>3. Replace missing values and EDA<\/a>\n\n    - <a href='#3.1'>3.1. Insulin<\/a> \n    - <a href='#3.2'>3.2. Glucose<\/a> \n    - <a href='#3.3'>3.3. SkinThickness<\/a>\n    - <a href='#3.4'>3.4. BloodPressure<\/a>\n    - <a href='#3.5'>3.5. BMI<\/a>\n    \n- <a href='#4'>4. New features (16) and EDA<\/a>\n\n- <a href='#5'>5. Prepare dataset<\/a> \n    - <a href='#5.1'>5.1. StandardScaler and LabelEncoder<\/a> \n    - <a href='#5.2'>5.2. Correlation Matrix<\/a>\n    - <a href='#5.3'>5.3. X and y<\/a>\n    - <a href='#5.4'>5.4. Model Performance<\/a>\n\t- <a href='#5.4'>5.5. Scores Table<\/a>\n    \n- <a href='#6'>6.Machine Learning<\/a> \n\n    - <a href='#6.1'>6.1. RandomSearch + LightGBM - Accuracy = 89.8%<\/a> \n    - <a href='#6.2'>6.2. LightGBM - Discrimination Threshold<\/a>\n    - <a href='#6.3'>6.3. GridSearch + LightGBM & KNN- Accuracy = 90.6%<\/a>\n    - <a href='#6.4'>6.4. LightGBM & KNN - Discrimination Threshold<\/a>","ca2fb3dd":"To find the best hyperparameters, we'll use Random Search CV.\n\nRandom search is a technique where random combinations of the hyperparameters are used to find the best solution for the built model. \nGenerally RS is more faster and accurate than GridSearchCV who calculate all possible combinations. With Random Grid we specify the number of combinations that we want","5ab42019":"* **Glucose** : Plasma glucose concentration a 2 hours in an oral glucose tolerance test","c28daad6":"Now, we can look at where are missing values :","2c31eaa7":"**To fill these Nan values the data distribution needs to be understood against the target**. ","ee1d1b91":"We define X and y :","7732614b":"## <a id='3.1'>3.1. Insulin<\/a> ","49eea25e":"With GridSearch CV we search the best \"n_neighbors\" to optimize accuracy of Voting Classifier","7f2fc8e0":"We can complete model performance report with a table contain all results by fold","014662a1":"107 for a healthy person and 140 for a diabetic person","fe668e21":"# <a id='3'>3. Replace missing values and EDA<\/a> ","4a3618b7":"# <a id='1'>1. Load libraries and read the data<\/a> ","7c9dc339":"## <a id='1.1'>1.1. Load libraries<\/a> ","936db731":"# <a id='5'>5. Prepare dataset<\/a> ","4d1746d3":"## <a id='3.4'>3.4. BloodPressure<\/a> ","d58b93b5":"# <a id='2'>2. Overview<\/a> ","d61b69d9":"According to wikipedia \"The body mass index (BMI) or Quetelet index is a value derived from the mass (weight) and height of an individual. The BMI is defined as the body mass divided by the square of the body height, and is universally expressed in units of kg\/m2, resulting from mass in kilograms and height in metres.\"\n\n30 kg\/m\u00b2 is the limit to obesity","4ebb777b":"Insulin's medians by the target are really different ! 102.5 for a healthy person and 169.5 for a diabetic person","6105192a":"## <a id='5.4'>5.4. Model Performance<\/a> ","64af2e33":"* **BMI** : Body mass index (weight in kg\/(height in m)^2)","af964bac":"* **Glucose and BloodPressure**","57c00f2e":"All features are complete ! \n\nNow, we can create new features","9a5c89ab":"## <a id='6.2'>6.2. LightGBM - Discrimination Threshold<\/a> ","4f731e60":"Healthy persons are concentrate with a BMI < 30 and skin thickness <= 20**","c15e182e":"## <a id='6.4'>6.4. LightGBM & KNN  - Discrimination Threshold<\/a> ","82aa4cb4":"# <a id='6'>6. Machine Learning<\/a> ","7895655e":"* **Insulin**","19c489d5":"* **Discrimination Threshold** :\nA visualization of precision, recall, f1 score, and queue rate with respect to the discrimination threshold of a binary classifier. The discrimination threshold is the probability or score at which the positive class is chosen over the negative class","6b4fd295":"OK, all missing values are encoded with NaN value","f7b0b222":"* **SkinThickness and BMI**","0820875a":"* **BloodPressure**","a8b9faed":"Checking data head and info","cdd8d7e4":"## <a id='3.3'>3.3. SkinThickness<\/a> ","7524ae30":"A **correlation matrix** is a table showing correlation coefficients between sets of variables. Each random variable (Xi) in the table is correlated with each of the other values in the table (Xj). This allows you to see which pairs have the highest correlation.","b4e0910e":"* **SkinThickness**","03956282":"Loading dataset with pandas (pd)","c826158f":"Now, we can compute correlation matrix ","323d0ae6":"## <a id='6.1'>6.1. RandomSearch + LightGBM - Accuracy = 89.8%<\/a> ","355a4af8":"27 for a healthy person and 32 for a diabetic person","06ec3156":"## <a id='3.5'>3.5. BMI<\/a> ","1f043a80":"We saw on data.head() that some features contain 0, it doesn't make sense here and this indicates missing value\nBelow we replace 0 value by NaN :","61fe3605":"## <a id='2.1'>2.1. Head<\/a> ","ae80608d":"To replace missing values, we'll use median by target (Outcome)","e2f82222":"* **Glucose and Age**","58e35e01":"With n_neighbors = 25, the accuracy increase to 90.625 ! Bellow the model performance report ","68fe21bb":"Healthy persons are concentrate with an age <= 30 and glucose <= 120","f30e57a9":"# Thank you","552a58c4":"Healthy persons are concentrate with an blood pressure <= 80 and glucose <= 105","e13afe7e":"# What is diabetes ? \nAcccording to NIH, \"**Diabetes** is a disease that occurs when your blood glucose, also called blood sugar, is too high. Blood glucose is your main source of energy and comes from the food you eat. Insulin, a hormone made by the pancreas, helps glucose from food get into your cells to be used for energy. Sometimes your body doesn\u2019t make enough\u2014or any\u2014insulin or doesn\u2019t use insulin well. Glucose then stays in your blood and doesn\u2019t reach your cells.\n\nOver time, having too much glucose in your blood can cause health problems. Although diabetes has no cure, you can take steps to manage your diabetes and stay healthy.\n\nSometimes people call diabetes \u201ca touch of sugar\u201d or \u201cborderline diabetes.\u201d These terms suggest that someone doesn\u2019t really have diabetes or has a less serious case, but every case of diabetes is serious.\n\n**What are the different types of diabetes?**\nThe most common types of diabetes are type 1, type 2, and gestational diabetes.\n\n**Type 1 diabetes**\nIf you have type 1 diabetes, your body does not make insulin. Your immune system attacks and destroys the cells in your pancreas that make insulin. Type 1 diabetes is usually diagnosed in children and young adults, although it can appear at any age. People with type 1 diabetes need to take insulin every day to stay alive.\n\n**Type 2 diabetes**\nIf you have type 2 diabetes, your body does not make or use insulin well. You can develop type 2 diabetes at any age, even during childhood. However, this type of diabetes occurs most often in middle-aged and older people. Type 2 is the most common type of diabetes.\n\n**Gestational diabetes**\nGestational diabetes develops in some women when they are pregnant. Most of the time, this type of diabetes goes away after the baby is born. However, if you\u2019ve had gestational diabetes, you have a greater chance of developing type 2 diabetes later in life. Sometimes diabetes diagnosed during pregnancy is actually type 2 diabetes.\n\n**Other types of diabetes**\nLess common types include monogenic diabetes, which is an inherited form of diabetes, and cystic fibrosis-related diabetes .\"","7ed7afa9":"* **Others**","a7c74841":"* **Did you watch Inception ?** Here is the same! It's not a dream in a dream but a new feature extract from a new feature","4460313d":"## <a id='5.1'>5.1. StandardScaler and LabelEncoder<\/a> ","2c552a05":"## <a id='5.5'>5.5. Scores Tables<\/a> ","4f98fe0b":"What's target's distribution ? ","8519f39a":"The datasets consist of several medical predictor (independent) variables and one target (dependent) variable, Outcome. Independent variables include the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.","040e80b6":"The above graph shows that the data is unbalanced. The number of non-diabetic is 268 the number of diabetic patients is 500","583772dd":"**BloodPressure** : Diastolic blood pressure (mm Hg)","82ebced7":"* **BMI**","81702029":"Here, we define 3 plots functions","47f53cc6":"Missing values : \n* Insulin = 48.7% - 374\n* SkinThickness = 29.56% - 227\n* BloodPressure = 4.56% - 35\n* BMI = 1.43% - 11\n* Glucose = 0.65% - 5","6a8cd5ea":"* **Insulin** : 2-Hour serum insulin (mu U\/ml)","b53349b6":"# <a id='4'>4. New features (16) and EDA<\/a> ","e32eeff4":"A **correlation matrix** is a table showing correlation coefficients between sets of variables. Each random variable (Xi) in the table is correlated with each of the other values in the table (Xj). This allows you to see which pairs have the highest correlation.","3b14dc1c":"* ** SkinThickness** : Triceps skin fold thickness (mm)","74744a1c":"## <a id='6.3'>6.3. GridSearch + LightGBM & KNN- Accuracy = 90.6%<\/a> ","55995f81":"## <a id='1.2'>1.2. Read data<\/a> ","ee459d9a":"* **Pregnancies**","b9a9c51e":"## <a id='5.2'>5.2. Correlation Matrix<\/a> ","a0686646":"We obtain a really good result but we can beat 90% with adding a KNeighborsClassifier to LightGBM (Voting Classifier)\n\n* **KNeighborsClassifier** : KNeighborsClassifier implements learning based on the k nearest neighbors of each query point, where  k is an integer value specified by the user.\n\n* **VotingClassifier** : VotingClassifier is a meta-classifier for combining similar or conceptually different machine learning classifiers for classification via majority or plurality voting","22cff063":"## <a id='2.3'>2.3. Missing values<\/a> ","c9c2f1b8":"Loading the libraries","6883a3b3":"## <a id='5.3'>5.3. X and y<\/a> ","b6926347":"* **Glucose and BMI**","8658bc33":"## <a id='2.2'>2.2 Target<\/a> ","d80d8b41":"* **Pregnancies and Age**","a36d2dbb":"## <a id='3.2'>3.2. Glucose<\/a> ","1484922c":"* **LightGBM : Hyperparameters ** :\n\n    * learning_rate : This determines the impact of each tree on the final outcome. GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates\n    * n_estimators : number of trees (or rounds)\n    * num_leaves : number of leaves in full tree, default: 31\n    * min_child_samples : minimal number of data in one leaf. Can be used to deal with over-fitting\n    * min_child_weight : minimal sum hessian in one leaf.\n    * subsample : randomly select part of data without resampling\n    * max_depth : It describes the maximum depth of tree. This parameter is used to handle model overfitting.\n    * colsample_bytree : LightGBM will randomly select part of features on each iteration if colsample_bytree smaller than 1.0. For example, if you set it to 0.8, LightGBM will select 80% of features before training each tree\n    * reg_alpha : regularization\n    * reg_lambda : regularization\n    \n    * early_stopping_rounds : This parameter can help you speed up your analysis. Model will stop training if one metric of one validation data doesn\u2019t improve in last early_stopping_round rounds. This will reduce excessive iterations","c6690eb5":"* **Age** : Age (years)\n* **DiabetesPedigreeFunction** : Diabetes pedigree function\n* **Pregnancies** : Number of times pregnant"}}