{"cell_type":{"e7debd85":"code","88023316":"code","ef35eaa0":"code","999b0a53":"code","2f0b8ad1":"code","cc7b93f4":"code","023c2e88":"code","af6bb267":"code","3fe18dba":"code","7dbabdfa":"code","b5165363":"code","ba1282bc":"code","8ac0c5ed":"code","9d84b93b":"code","59387068":"code","0df2305d":"code","2d459192":"code","7a65801c":"code","3dc51983":"code","1af15666":"markdown","4e0d4a41":"markdown","d0081d9c":"markdown","8dbed5bd":"markdown","e9cbb1a4":"markdown","94c441a7":"markdown","d48e8e27":"markdown","ba84b7e8":"markdown","ca3a583a":"markdown","4d9033c0":"markdown","94094046":"markdown","f176287d":"markdown","73da163d":"markdown","62fbe820":"markdown","f54b8a59":"markdown","2b71a754":"markdown","bf660ea8":"markdown","65e9d538":"markdown","e516d08d":"markdown","f4537ebf":"markdown"},"source":{"e7debd85":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport cv2\nfrom glob import glob\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.optimizers import RMSprop,Adam\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","88023316":"train_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nval_folder = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'","ef35eaa0":"print('Number of images in training set = ',str(len(glob(train_folder+'\/*\/*'))))\nprint('Number of images in validation set = ',str(len(glob(val_folder+'\/*\/*'))))\nprint('Number of images in testing set = ',str(len(glob(test_folder+'\/*\/*'))))","999b0a53":"train_f = tf.io.gfile.glob(train_folder+'\/*\/*')\nvalidation_f = tf.io.gfile.glob(val_folder+'\/*\/*')\n\ntotal_files = train_f \ntotal_files.extend(validation_f)\n\nprint(\"Total no. of images we have [train_f + validation_f] = {}\".format(len(total_files)))","2f0b8ad1":"## So now spliting this data into 80:20 \n\ntrain_images,val_images = train_test_split(total_files,test_size =0.2)\nprint(\"Train_images = {}\".format(len(train_images)))\nprint(\"Validation_images = {}\".format(len(val_images)))","cc7b93f4":"tf.io.gfile.makedirs('\/kaggle\/working\/val_dataset\/NORMAL\/')\ntf.io.gfile.makedirs('\/kaggle\/working\/val_dataset\/PNEUMONIA\/')\ntf.io.gfile.makedirs('\/kaggle\/working\/train_dataset\/NORMAL\/')\ntf.io.gfile.makedirs('\/kaggle\/working\/train_dataset\/PNEUMONIA\/')","023c2e88":"for element in train_images:\n    parts_of_path = element.split('\/')\n\n    if 'PNEUMONIA' == parts_of_path[-2]:\n        tf.io.gfile.copy(src = element, dst = '\/kaggle\/working\/train_dataset\/PNEUMONIA\/' +  parts_of_path[-1])\n    else:\n        tf.io.gfile.copy(src = element, dst = '\/kaggle\/working\/train_dataset\/NORMAL\/' +  parts_of_path[-1])","af6bb267":"for element in val_images:\n    parts_of_path = element.split('\/')\n\n    if 'PNEUMONIA' == parts_of_path[-2]:\n        tf.io.gfile.copy(src = element, dst = '\/kaggle\/working\/val_dataset\/PNEUMONIA\/' +  parts_of_path[-1])\n    else:\n        tf.io.gfile.copy(src = element, dst = '\/kaggle\/working\/val_dataset\/NORMAL\/' +  parts_of_path[-1])","3fe18dba":"print('Pneumonia x-ray images in training set after split = ',len(os.listdir('\/kaggle\/working\/train_dataset\/PNEUMONIA\/')))\nprint('Normal x-ray images in training set after split = ',len(os.listdir('\/kaggle\/working\/train_dataset\/NORMAL\/')))\nprint('Pneumonia x-ray images in validation set after split = ',len(os.listdir('\/kaggle\/working\/val_dataset\/PNEUMONIA\/')))\nprint('Normal x-ray images in validation set after split = ',len(os.listdir('\/kaggle\/working\/val_dataset\/NORMAL\/')))\nprint('Pneumonia x-ray images in test set = ',len(os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/')))\nprint('Normal x-ray images in test set = ',len(os.listdir('..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL')))","7dbabdfa":"dataset_info = {'Dataset': ['train_dataset','val_dataset','test_dataset'],\n        'Pneumonia': [3107,776,390],\n        'Normal' : [1078,271,234]\n        }\n\ndf = pd.DataFrame(dataset_info, columns = ['Dataset', 'Pneumonia','Normal'])\n\nprint (df)","b5165363":"train_dir='\/kaggle\/working\/train_dataset\/'\nval_dir='\/kaggle\/working\/val_dataset\/'\ntest_dir='..\/input\/chest-xray-pneumonia\/chest_xray\/test\/'\n\n\n\ntrain_normal_dir='\/kaggle\/working\/train_dataset\/NORMAL\/'\ntrain_pneumonia_dir='\/kaggle\/working\/train_dataset\/PNEUMONIA\/'\nval_normal_dir='\/kaggle\/working\/val_dataset\/NORMAL'\nval_pneumonia_dir='\/kaggle\/working\/val_dataset\/PNEUMONIA'\n\n\ntrain_normal_fnames=os.listdir(train_normal_dir)\ntrain_pneumonia_fnames=os.listdir(train_pneumonia_dir)","ba1282bc":"%matplotlib inline \n\nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\n\nncols = 4\nnrows = 2\n\npic_index = 0","8ac0c5ed":"fig = plt.gcf()\nfig.set_size_inches(4*ncols,4*nrows)\n\npic_index+=4\n\nnormal = [os.path.join(train_normal_dir,fname) for fname in train_normal_fnames[pic_index-4:pic_index]]\npneumonia = [os.path.join(train_pneumonia_dir,fname) for fname in train_pneumonia_fnames[pic_index-4:pic_index]]\n\nfor i,img in enumerate(pneumonia+normal):\n    ax = plt.subplot(nrows,ncols,i+1)\n    ax.axis()\n    \n    imgs = mpimg.imread(img)\n    plt.imshow(imgs,cmap='gray')\n    if(i<4):\n        plt.title('Pneumonia')\n    else:\n        plt.title('Normal')\nplt.show()","9d84b93b":"train_datagen2=ImageDataGenerator(rescale=1.0\/255,\n                                 rotation_range=30,\n                                 width_shift_range=0.2,\n                                 height_shift_range=0.2,\n                                 zoom_range=0.2,\n                                 )\n\nval_datagen2=ImageDataGenerator(rescale=1.0\/255)\n\ntest_datagen2=ImageDataGenerator(rescale=1.0\/255)\n\ntrain_generator2=train_datagen2.flow_from_directory(train_dir,target_size=(180,180),batch_size=128,class_mode='binary')\n\nval_generator2=val_datagen2.flow_from_directory(val_dir,target_size=(180,180),batch_size=128,class_mode='binary')\n\ntest_generator2=test_datagen2.flow_from_directory(test_dir,target_size=(180,180),batch_size=128,class_mode='binary')","59387068":"#load pre trained Xception model\n\nmodel = Xception(weights= None, include_top=False, input_shape= (180,180,3))\n\n#freazing the trained layers\nfor layers in model.layers:\n    layers.trainable = False\n\nmodel.summary()","0df2305d":"last_layer=model.get_layer('block14_sepconv2_act')\nlast_output = last_layer.output\n\nx=tf.keras.layers.Flatten()(last_output)\nx=tf.keras.layers.Dense(1024,activation='relu')(x)\nx=tf.keras.layers.Dropout(0.2)(x)\nx=tf.keras.layers.Dense(256,activation='relu')(x)\nx=tf.keras.layers.Dropout(0.2)(x)\nx=tf.keras.layers.Dense(1,activation='sigmoid')(x)\n\nmodel=tf.keras.Model(model.input,x)\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss='binary_crossentropy',\n               metrics=['accuracy','Precision','Recall'])\n\nmodel.summary()","2d459192":"history = model.fit(train_generator2,validation_data=val_generator2,epochs=10,steps_per_epoch=5,verbose=2)","7a65801c":"acc2 = history.history['accuracy']\nval_acc2 = history.history['val_accuracy']\n\n\nloss2 = history.history['loss']\nval_loss2 = history.history['val_loss']\nepochs = range(len(acc2))\n\nplt.plot(epochs, acc2, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc2, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\n\n\n\nplt.plot(epochs, loss2, 'r', label='Training Loss')\nplt.plot(epochs, val_loss2, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","3dc51983":"eval_result3 = model.evaluate_generator(test_generator2, 624)\nprint('loss  :', eval_result3[0])\nprint('accuracy  :', eval_result3[1])\nprint('Precision :', eval_result3[2])\nprint('Recall :', eval_result3[3])","1af15666":"### Again we have to make new directories for training and validation folders.","4e0d4a41":"### Previewing the images of both the classes","d0081d9c":"## So in this notebook we are going try identifing who may be suffering from Pneumonia on the bases of images of lung.","8dbed5bd":"### We will use glob it finds all the pathnames matching a specified pattern according to the rules used by the Unix shell. \n\n### find more on  -- https:\/\/docs.python.org\/3\/library\/glob.html","e9cbb1a4":"## Hope this notebook helped you in anyway. \n## Do share your valuable comments and please UpVote the notebook Thank You.. \ud83d\ude4f","94c441a7":"#### Let's start by going through the training dataset. We will do some analysis on that, look at some of the samples, check the number of samples for each class, etc. Lets' do it.\n\n#### There are sub-categories  -- <br>\nNORMAL: These are the samples that describe the normal (no pneumonia) case.<br>\nPNEUMONIA: This directory contains those samples that are the pneumonia cases.","d48e8e27":"### Copying the images in new directories","ba84b7e8":"## Model Creation","ca3a583a":"### Here we can see there is a very poor distribution of data. And the some ratio should be followed and a proper distribution of data should be there. \n### It can be either 80:20 or 70:30 any standered train_test_split as compared to the above one. ","4d9033c0":"## New Dataset distribution ","94094046":"## What is Phenumonia ??\n\n### Infection that inflames air sacs in one or both lungs, which may fill with fluid.\n### With pneumonia, the air sacs may fill with fluid or pus. The infection can be life-threatening to anyone, but particularly to infants, children and people over 65.\n### Symptoms include a cough with phlegm or pus, fever, chills and difficulty breathing.\n### Antibiotics can treat many forms of pneumonia. Some forms of pneumonia can be prevented by vaccines.","f176287d":"## Re-assembling dataset ","73da163d":"## Do comment and upvote if you like my efforts. Thank you!!\ud83d\ude4f","62fbe820":"## Loss . Accuracy . Precision . Recall ","f54b8a59":"![depth%20wise%20seperations.png](attachment:depth%20wise%20seperations.png)","2b71a754":"![alveoli_normal_v_pneumonia.png](attachment:alveoli_normal_v_pneumonia.png)","bf660ea8":"## Loading the Data","65e9d538":"## We will be using Xception Model implemented using Transfer learning \n### Reason: Though we want to classify those images into different classification, However we also want to learn elements which make them different and evaluate them depth-wise.","e516d08d":"## Conclusion\n\n## 1. Primary Evaluation shows average accuracy and recall rate as well as the graphs suggests that we are not overfitting the model . However we maybe using a very complex model and there is a need to drop few layers or use different model for the classification purpose. \n## 2. In coming versions of the notebook I will be using other models as well with the hope of getting better results. ","f4537ebf":"## Quite frankly if I have to say it I can't make much difference in both the pictures which is quite normal. However our model may find some interesting ways to differentitate and bifurcate them so lets start with the model creation."}}