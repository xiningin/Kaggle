{"cell_type":{"0a32f1ce":"code","0b27fd10":"code","997f794c":"code","3d3e1ae2":"code","5458aeba":"code","702922d2":"code","1ad5a654":"code","d0286f90":"code","b533f295":"code","e1f120f2":"code","c48983e9":"code","0e30ba0b":"code","360eabd8":"code","69c66290":"code","df8b6ade":"code","4c24ed25":"code","c3cec112":"code","a5e64165":"code","a6d11d6e":"code","82ce9c72":"code","2eb5e9c8":"markdown"},"source":{"0a32f1ce":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0b27fd10":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","997f794c":"train_fp = '..\/input\/tabular-playground-series-aug-2021\/train.csv'\ntrain = pd.read_csv(train_fp)\n\ntest_fp = '..\/input\/tabular-playground-series-aug-2021\/test.csv'\ntest = pd.read_csv(test_fp)","3d3e1ae2":"train","5458aeba":"#plt.figure(figsize=(10, 6))\nsns.displot(train['loss'], kde=True, height=6, aspect=2)","702922d2":"train_corr = train.corr()\nmask = np.triu(np.ones_like(train_corr, dtype=np.bool))\n\nfig = plt.figure(figsize=(16,13))\nsns.heatmap(train_corr, mask=mask)\nplt.title('Correlation between features')","1ad5a654":"X = train.drop(['loss'], axis=1)\ny = train.loss","d0286f90":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0, test_size=0.3)","b533f295":"'''\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nxgbr = XGBRegressor(seed=20)\n\nparams = { \"max_depth\": [2, 3, 4],\n           \"learning_rate\": [0.03, 0.04, 0.05],\n           \"n_estimators\": np.arange(100, 1000, 100),\n           \"colsample_bytree\": np.arange(0.2, 0.7, 0.1),\n            \"colsample_bylevel\": np.arange(0.2, 0.7, 0.1),\n            \"colsample_bynode\": np.arange(0.2, 0.7, 0.1)\n            }\n\nreg = RandomizedSearchCV(estimator=xgbr,\n                  param_distributions=params,\n                  scoring='neg_root_mean_squared_error',\n                    n_iter=100,\n                  verbose=1)\n'''","e1f120f2":"'''\nreg.fit(X_train, y_train)\n\nprint(\"Best parameters:\", reg.best_params_)\n'''","c48983e9":"\nfrom xgboost import XGBRegressor\n\nparams = {'n_estimators': 900,\n         'learning_rate': 0.05,\n         'max_depth': 4,\n         'colsample_bytree': 0.5000000000000001,\n         'colsample_bynode': 0.2,\n         'colsample_bylevel': 0.4000000000000001}\n\nmodel = XGBRegressor(**params)\n\nmodel.fit(X_train, y_train,\n         early_stopping_rounds=5,\n         eval_set=[(X_val, y_val)],\n         verbose=False)\n\npreds = model.predict(X_val)","0e30ba0b":"\nfrom sklearn.metrics import accuracy_score, mean_absolute_error, r2_score\nfrom sklearn.model_selection import cross_val_score \n\nmae = \"Mean absolute error: {}\".format(mean_absolute_error(y_val, preds))\nprint(mae)\n\nr2 = \"r2 score: {}\".format(r2_score(y_val, preds))\nprint(r2)\n","360eabd8":"test","69c66290":"test_trimmed = test[:150000]","df8b6ade":"final_output = model.predict(test_trimmed)","4c24ed25":"final_output","c3cec112":"'''\nfinal_mae = \"Mean absolute error: {}\".format(mean_absolute_error(y_val, final_output))\nprint(mae)\n\nfinal_r2 = \"r2 score: {}\".format(r2_score(y_val, final_output))\nprint(r2)\n'''","a5e64165":"sample_fp = \"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\"\nsample = pd.read_csv(sample_fp)","a6d11d6e":"sample_trimmed = sample.copy()\nsample_trimmed = sample_trimmed[:150000]\nsample_trimmed['loss'] = final_output\n\nsample_trimmed.to_csv('submission.csv', index=False)","82ce9c72":"sample_trimmed","2eb5e9c8":"# EDA"}}