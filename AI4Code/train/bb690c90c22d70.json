{"cell_type":{"5a87417d":"code","a288a0aa":"code","48b5e57e":"code","5761fe6b":"code","f1aee2e3":"code","b9909849":"code","9eacaa77":"code","ad352087":"code","f006747b":"code","b8c7fb50":"code","e3c604db":"code","9d0cf386":"code","03130ce7":"code","66d829d8":"code","347e672c":"code","518be9d6":"code","fcef3949":"code","8c09f027":"code","fbaaa458":"code","05666e89":"code","f0db5b2f":"code","ab3180fc":"code","8b70a6dd":"code","8c8a5694":"code","7ef9cfb0":"code","2a262243":"code","372e8b1e":"code","142abf5c":"code","cb7678da":"code","0b0302a3":"code","54df0265":"code","0f13095d":"code","7b249277":"code","f24f09f0":"code","1f3f081e":"code","2fa19e37":"code","75aace3a":"code","c8148a85":"code","0314e760":"code","e12d88c8":"code","1cb1513f":"code","21da1aef":"code","295aa5c8":"code","9b7c6446":"code","2d822e88":"code","f2842c57":"code","98750256":"code","41fe0240":"code","59a5a9df":"code","208103c8":"code","6c298615":"code","d3a7b889":"code","08730f2c":"code","e089e9d0":"code","513553e0":"code","2bd29240":"code","1db56d41":"code","a435db3b":"code","3f38cace":"code","e189a41f":"code","d2ca4a5f":"code","a1d7998b":"code","264a24f4":"code","7fdafcb2":"code","e439af75":"code","cef6984d":"code","6e5603ea":"code","e4f7dd23":"code","24a3b067":"code","80c63e44":"code","85f1b741":"code","a69ff87b":"code","da1ab2e1":"code","e6575e2e":"code","c66f4bb9":"code","946e8bfc":"code","3f2dc4bd":"markdown","fb457313":"markdown","1b532ada":"markdown","fe4daaab":"markdown","42e99e82":"markdown","08eb86e4":"markdown","7967a6a0":"markdown","e0f1fdb0":"markdown","4762351b":"markdown","40f584e0":"markdown","d3cdbd60":"markdown","795db222":"markdown","a33b1a3a":"markdown","a4249c47":"markdown","eec6da0b":"markdown","bb503278":"markdown","769dc720":"markdown","603b3219":"markdown","19f1e0ac":"markdown","78ab6f33":"markdown","2a038aca":"markdown","c9aa5379":"markdown","e0c557af":"markdown","ea09713d":"markdown","8d5742ad":"markdown","3793891a":"markdown","f7c5e566":"markdown","0a5586d8":"markdown","b9fbe8c2":"markdown","0331adb2":"markdown","cb0448d2":"markdown","af8496f4":"markdown","13a80301":"markdown","03935274":"markdown"},"source":{"5a87417d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a288a0aa":"# Load the dataframe\ndataframe = pd.read_csv(\"..\/input\/santander-customer-satisfaction\/train.csv\")\n\n# Print the first 20 rows\ndataframe.head(20)","48b5e57e":"# We print the sum of NaNs in each coloumn\nnp.isnan(dataframe).sum()","5761fe6b":"# Assigning data to the train dataframe\ntrain_data = dataframe","f1aee2e3":"# Dropping Target as we are supposed to predict that\n# Dropping ID as it is unique to all rows\ntrain_data = train_data.drop(['TARGET'], axis = 1)\ntrain_data = train_data.drop(['ID'], axis = 1)","b9909849":"# We append the coloumn names that have 0 standard deviation as we can't gather much info from these due to low variance\nremove_col_std = []\nfor i in train_data.columns:\n    if(train_data[i].std() == 0):\n        remove_col_std.append(i)","9eacaa77":"# Redefining train dataframe by removing the 0 standard deviation coloumns\ntrain_data = train_data.drop(remove_col_std, axis = 1)","ad352087":"# Removing columns that are identical to one another\nremove_col_redund = []\ncount = 0\nfor i in range(len(train_data.columns)):\n    i_values = train_data[train_data.columns[i]].values\n    for j in range(i+1, len(train_data.columns)):\n        if(np.array_equal(i_values, train_data[train_data.columns[j]].values)):\n            remove_col_redund.append(train_data.columns[j])","f006747b":"# Redefining the train dataframe once more by dropping redundant coloumns\ntrain_data = train_data.drop(remove_col_redund, axis = 1)","b8c7fb50":"# We select the first 20 features and the target coloumn\nfirst_df = pd.concat([train_data.iloc[:, :20], train_data.iloc[:, 305]], axis = 1)","e3c604db":"# We print the correlation heatmap for these 20 features with the target variable\nplt.figure(figsize = (20 ,20))\ncorrmat = first_df.corr()\ntop_corr_features = corrmat.index\nsns.heatmap(first_df[top_corr_features].corr(), annot = True, cmap = 'RdYlGn')","9d0cf386":"first_df = pd.concat([train_data.iloc[:, 296:306], train_data.iloc[:, 305]], axis = 1)","03130ce7":"plt.figure(figsize = (20 ,20))\ncorrmat = first_df.corr()\ntop_corr_features = corrmat.index\nsns.heatmap(first_df[top_corr_features].corr(), annot = True, cmap = 'RdYlGn')","66d829d8":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif","347e672c":"X = train_data.iloc[:, :306]\ny = dataframe.iloc[:, 370]","518be9d6":"bestfeatures = SelectKBest(score_func = f_classif, k = 40)\nfit = bestfeatures.fit(X, y)","fcef3949":"dfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)","8c09f027":"featureScores = pd.concat([dfcolumns, dfscores], axis = 1)\nfeatureScores.columns = ['Features', 'Score']","fbaaa458":"featureScores","05666e89":"print(featureScores.nlargest(40, 'Score'))","f0db5b2f":"plt.figure(figsize = (25, 6))\nsns.barplot(x = featureScores.nlargest(30, 'Score')['Features'], y = featureScores.nlargest(30, 'Score')['Score'])\nplt.xticks(rotation = 45)\nax = plt.gca()\nplt.show()","ab3180fc":"from sklearn.ensemble import ExtraTreesClassifier","8b70a6dd":"model = ExtraTreesClassifier()\nselector = model.fit(X, y)","8c8a5694":"plt.figure(figsize = (60, 40))\nfeat_importances = pd.Series(model.feature_importances_, index = X.columns)\nfeat_importances.nlargest(40).plot(kind = 'barh')\nplt.show()","7ef9cfb0":"plt.figure(figsize = (10, 6))\nsns.countplot(dataframe['TARGET'].values)","2a262243":"dataframe[dataframe['TARGET'] == 0].shape[0]","372e8b1e":"dataframe[dataframe['TARGET'] == 1].shape[0]","142abf5c":"# List of the top 40 features selected by the ExtraTreesClassifier\nlist(feat_importances.nlargest(40).index)","cb7678da":"X_feat_1 = X[list(feat_importances.nlargest(40).index)]","0b0302a3":"print(\"X shape: \" +  str(X_feat_1.shape) + \" || y shape: \" + str(y.shape))","54df0265":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_feat_1, y, test_size = 0.25, random_state = 4)","0f13095d":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","7b249277":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV","f24f09f0":"params={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]   \n}","1f3f081e":"# Instantiating the XGBClassfier\nclassifier_etc = XGBClassifier()","2fa19e37":"random_search = RandomizedSearchCV(classifier_etc, param_distributions = params, n_iter = 5, scoring = 'roc_auc', n_jobs = -1, cv = 5, verbose = 3)","75aace3a":"random_search.fit(X_train,y_train)","c8148a85":"random_search.best_estimator_","0314e760":"random_search.best_params_","e12d88c8":"classifier_etc = random_search.best_estimator_","1cb1513f":"from sklearn.model_selection import cross_val_score\nscore=cross_val_score(classifier_etc,X,y,cv=10)","21da1aef":"score","295aa5c8":"score.mean()","9b7c6446":"classifier_etc.fit(X_train, y_train)","2d822e88":"y_pred = classifier_etc.predict(X_test)","f2842c57":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","98750256":"cm","41fe0240":"from sklearn.metrics import roc_auc_score\nprint(\"Roc AUC: \", roc_auc_score(y_test, classifier_etc.predict_proba(X_test)[:,1], average='macro'))","59a5a9df":"list(featureScores.nlargest(40, 'Score')['Features'])","208103c8":"X_feat_2 = X[list(featureScores.nlargest(40, 'Score')['Features'])]","6c298615":"print(\"X shape: \" +  str(X_feat_2.shape) + \" || y shape: \" + str(y.shape))","d3a7b889":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_feat_2, y, test_size = 0.20, random_state = 4)","08730f2c":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","e089e9d0":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV","513553e0":"params={\n \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n \"min_child_weight\" : [ 1, 3, 5, 7 ],\n \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]   \n}","2bd29240":"classifier_k_best = XGBClassifier()","1db56d41":"random_search = RandomizedSearchCV(classifier_k_best, param_distributions = params, n_iter = 5, scoring = 'roc_auc', n_jobs = -1, cv = 5, verbose = 3)","a435db3b":"random_search.fit(X_train,y_train)","3f38cace":"random_search.best_estimator_","e189a41f":"random_search.best_params_","d2ca4a5f":"classifier_k_best = random_search.best_estimator_","a1d7998b":"from sklearn.model_selection import cross_val_score\nscore=cross_val_score(classifier_k_best,X,y,cv=10)","264a24f4":"score","7fdafcb2":"score.mean()","e439af75":"classifier_k_best.fit(X_train, y_train)","cef6984d":"y_pred = classifier_k_best.predict(X_test)","6e5603ea":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","e4f7dd23":"cm","24a3b067":"from sklearn.metrics import roc_auc_score\nprint(\"Roc AUC: \", roc_auc_score(y_test, classifier_k_best.predict_proba(X_test)[:,1], average='macro'))","80c63e44":"# Creating the test dataframe\ntest_df = pd.read_csv(\"..\/input\/santander-customer-satisfaction\/test.csv\")","85f1b741":"test_df_X = test_df[list(feat_importances.nlargest(40).index)]","a69ff87b":"test_df_X.shape","da1ab2e1":"test_df_X = sc.fit_transform(test_df_X)","e6575e2e":"test_ID = test_df.ID","c66f4bb9":"probs = classifier_etc.predict_proba(test_df_X)","946e8bfc":"submission = pd.DataFrame({\"ID\":test_ID, \"TARGET\": probs[:,1]})\nsubmission.to_csv(\"submission.csv\", index=False)","3f2dc4bd":"Intresting features:\n<ol>\n    <li>var15<\/li>\n<\/ol>","fb457313":"We implement random search CV technique as this will search the search space randomly and will attempt to find the best set of hyperparameters","1b532ada":"Once we have fit the data, we can directly get the best model parameters through the 'best_estimator_' method","fe4daaab":"Correlation of first 10 features with TARGET","42e99e82":"Plotting the top 30 features","08eb86e4":"## Class distribution","7967a6a0":"Performing the final steps for result submission","e0f1fdb0":"We use the ANOVA test to determine the feature importance. This is done through the 'f_classif' method.\n\n'k' determines how many features are we going to select","4762351b":"Clearly there's a lot of class imbalance","40f584e0":"We create two dataframes. One containing the scores for each feature and the second dataframe, the feature itself","d3cdbd60":"We repeat the same process as before","795db222":"## Finalizing","a33b1a3a":"And our ROC curve score is...","a4249c47":"Unsatisfied customers:-","eec6da0b":"Printing the confusion matrix for the same","bb503278":"This means we may have to use algorithms such as XGBoost or AdaBoost as they are known to be resilient to such class imbalance problem.","769dc720":"## Removing redundant and low variance features","603b3219":"## Feature Selection using Feature Importance","19f1e0ac":"We may have to implement the same process for all the features to check how each feature correlates with the target variable which can be quite tedious given the number of features.","78ab6f33":"Attempting to get the cross validation score","2a038aca":"## Selecting a feature set based on ExtraTreesClassifier","c9aa5379":"We determine the shape of the matrix and confirm if the shape of rows for the input matrix 'X' is same as that of 'y' ","e0c557af":"The optimal parameters can be extracted through the model","ea09713d":"Seems that ind_var2_0, ind_var2, ind_var27_0, ind_var28_0, ind_var28, ind_var27 don't have any correlation with any feature.\n\nIntresting features:\n<ol>\n    <li>var15 = 0.1<\/li>\n    <li>ind_var8_0 = 0.047<\/li>\n    <li>ind_var8 = 0.028<\/li>\n    <li>ind_var26_cte = 0.024<\/li>\n    <li>ind_var25_cte = 0.023<\/li>\n    <li>num_var8_0 = 0.047<\/li>\n    <li>num_var8 = 0.028<\/li>\n    <li>var36 = 0.1<\/li>\n    <li>num_var22_ult1 = 0.025<\/li>\n    <li>num_meses_var8_ult3 = 0.026<\/li>\n    <li>num_op_var41_efect_ult1 = 0.021<\/li>\n    <li>num_op_var41_efect_ult3 = 0.02<\/li>\n    <li>num_op_var39_efect_ult1 = 0.022<\/li>\n    <li>num_op_var39_efect_ult3 = 0.02<\/li>\n<\/ol>","8d5742ad":"We sort the top 40 features","3793891a":"Ideally, try to take features which are having either a correlation score closer to 1 or -1","f7c5e566":"## Feature Selection using K-Best","0a5586d8":"Satisfied customers:-","b9fbe8c2":"Using the 'roc_auc' scoring parameter as that is the metrics to be evaluated in the problem statement","0331adb2":"## Feature Selection using Correlation-Heatmap","cb0448d2":"Implementing the above strategy for the rest of the features. <br>We take the correlation boundary as 0.020. This means all features above or equal to this correlation value will be considered as an intresting feature.\n\nNOTE: Since the scale for correlation changes, evaluate by the value in each box rather than the colour.","af8496f4":"## Selecting a feature set based on K-Best","13a80301":"Next we need to implement  train_test_split and feature scaling","03935274":"We segregate the data features into 'X' dataframe and the target variable in the 'y' dataframe"}}