{"cell_type":{"1ce7d5bd":"code","a49a7a66":"code","8176fe47":"code","e6fa64e8":"code","5aed2cf6":"code","aaf8dc75":"code","ae29e767":"code","18961b77":"code","32d63d0a":"code","785bab8e":"code","bfa38abd":"code","acb17eed":"code","df5766af":"code","a237a05b":"code","5d2f7951":"code","012d8264":"code","1f9a53fd":"code","85b7b8a1":"code","fc29fb45":"code","92fafa90":"code","236d3ad5":"code","4ecf6bd6":"code","93f075d4":"code","d13a69df":"code","400dfd88":"code","65b01ac0":"code","ba9c76ad":"code","2b19d958":"code","4b7e5457":"code","993126db":"code","ca0b7599":"code","b356678b":"code","c6adadb1":"code","c9f45e67":"code","82941e3b":"code","b77ad0b5":"code","4447880b":"code","4711acb8":"code","c2d9158a":"code","c9e81b97":"code","92fef275":"code","decffa2a":"code","c44d1af7":"code","8e17ccd3":"code","082f9967":"code","dfa0237d":"code","e27e71a2":"code","7e6cc640":"code","2b224a24":"code","52959c71":"code","b1ea707f":"code","e0d01cce":"code","415e3240":"code","acb9d2e5":"code","c134f5c3":"code","ba681398":"code","ec6d32cd":"code","49295f9d":"code","d640e155":"code","94fd8187":"code","1e55dfe7":"code","d1691151":"code","9373d19e":"code","006d4832":"code","5b9db7f5":"code","095e018d":"code","5f2f6524":"code","f26f17f5":"code","8667add7":"code","7b220f11":"code","deadceb7":"code","223c18ca":"code","229fd8df":"markdown","3c038f4a":"markdown","7e0c9824":"markdown","e64cd6dd":"markdown","90e3e5f6":"markdown","8004744e":"markdown"},"source":{"1ce7d5bd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time \n%matplotlib inline","a49a7a66":"data = pd.read_csv(\"..\/input\/Skyserver_SQL2_27_2018 6_51_39 PM.csv\")\ndata = pd.DataFrame(data)\ndatanew = data","8176fe47":"from sklearn.preprocessing import LabelEncoder\nlab = LabelEncoder()\ndatanew['class'] = lab.fit_transform(datanew['class'])\n ","e6fa64e8":"datanew.head()","5aed2cf6":"for col in datanew.columns:\n    print(\"    {} \\n ---------- \\n\".format(col),np.unique(np.asarray(datanew[col])),\"\\n\")","aaf8dc75":"from collections import Counter\n\ncount = Counter(datanew['class'])\ncount","ae29e767":"Y = datanew['class']\nY = pd.DataFrame(Y)\nY.head()","18961b77":"X=datanew\nX = X.drop(columns=['class','objid','rerun'])\nX.head()","32d63d0a":"from sklearn import preprocessing\n\nX_scaled = preprocessing.scale(X)\n\nX_scaled = pd.DataFrame(data=X_scaled,columns=X.columns)\ndatanew_scaled = X_scaled.copy()\ndatanew_scaled['class']=Y\nfinaldata = datanew_scaled.copy()\ndatanew_scaled.head()","785bab8e":"X_scaled.shape","bfa38abd":"import seaborn as sns\nsns.pairplot(datanew_scaled,kind='scatter',hue='class',palette=\"Set2\")","acb17eed":"import scipy as sp\ndef corrfunc(x, y, **kws):\n    r, _ = sp.stats.pearsonr(x, y)\n    ax = plt.gca()\n    ax.annotate(\"{:.2f}\".format(r), xy=(.1, .5), xycoords=ax.transAxes, size=50)","df5766af":"g = sns.PairGrid(datanew_scaled)\ng = g.map_lower(plt.scatter)\ng = g.map_diag(plt.hist, edgecolor=\"w\")\ng = g.map_upper(corrfunc)","a237a05b":"datanew_scaled.corr()","5d2f7951":"plt.figure(figsize=(15,30), dpi=100)\nplt.subplot(7,2,1)\nplt.scatter('g','u', data=datanew_scaled)\nplt.xlabel('g')\nplt.ylabel('u')\nplt.subplot(7,2,2)\nplt.scatter('g','r',data=datanew_scaled)\nplt.xlabel('g')\nplt.ylabel('r')\nplt.subplot(7,2,3)\nplt.scatter('i','r',data=datanew_scaled)\nplt.xlabel('i')\nplt.ylabel('r')\nplt.subplot(7,2,4)\nplt.scatter('z','i',data=datanew_scaled)\nplt.xlabel('z')\nplt.ylabel('i')\nplt.subplot(7,2,5)\nplt.scatter('mjd','plate',data=datanew_scaled)\nplt.xlabel('mjd')\nplt.ylabel('plate')\nplt.subplot(7,2,6)\nplt.scatter('specobjid','plate',data=datanew_scaled)\nplt.xlabel('specobjid')\nplt.ylabel('plate')\nplt.subplot(7,2,7)\nplt.scatter('specobjid','mjd',data=datanew_scaled)\nplt.xlabel('specobjid')\nplt.ylabel('mjd')\nplt.ylabel('plate')\nplt.subplot(7,2,8)\nplt.scatter('g','i',data=datanew_scaled)\nplt.xlabel('g')\nplt.ylabel('i')\n\nplt.show()","012d8264":"fig,ax = plt.subplots()\nfig.set_size_inches(15,8)\nsns.boxplot(data=X_scaled)","1f9a53fd":"datanew_scaled.describe()","85b7b8a1":"Q1 = X_scaled.quantile(0.25)\nQ3 = X_scaled.quantile(0.75)\nIQR = Q3 - Q1","fc29fb45":"((X_scaled < (Q1 - 1.5 * IQR)) | (X_scaled > (Q3 + 1.5 * IQR))).sum()","92fafa90":"mask = (X_scaled < (Q1 - 1.5 * IQR)) | (X_scaled > (Q3 + 1.5 * IQR))\ndatanew_scaled[mask] = np.nan","236d3ad5":"datanew_scaled = datanew_scaled.dropna()","4ecf6bd6":"datanew_scaled.shape","93f075d4":"datanew_scaled = datanew_scaled.reset_index(drop=True)","d13a69df":"from collections import Counter\n\ncount = Counter(datanew_scaled['class'])\ncount","400dfd88":"fig,ax = plt.subplots()\nfig.set_size_inches(15,8)\nsns.boxplot(data=datanew_scaled)","65b01ac0":"finaldata.shape","ba9c76ad":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nX = finaldata.iloc[:,0:14]\nY = finaldata.iloc[:,15]\n\nY = np.asarray(Y)\nY = Y.astype('int')\n\nX_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.33,random_state=66)\nkf = KFold(n_splits=5)\n\nfor train, valid in kf.split(X_train):\n\tprint('train: %s, valid: %s' % (train, valid))","2b19d958":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n\nfor k in range(1,21,2):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn,X_train,y_train,cv=5,scoring=\"accuracy\")\n    print(scores.mean())   ","4b7e5457":"knn=KNeighborsClassifier(n_neighbors=5)\n\ntraining_start = time.perf_counter()\nknnfit = knn.fit(X_train,y_train)\ntraining_end = time.perf_counter()\ntotal_time = training_end-training_start\nprint(\"Training Accuracy:       \",knnfit.score(X_train,y_train))\nscores = cross_val_score(knn,X_train,y_train,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy \", scores.mean())\nprint(\"\\nTime consumed for training %5.4f\" % (total_time))\na=[None]*6\na[0]=scores.mean()","993126db":"from sklearn.tree import DecisionTreeClassifier\nt = DecisionTreeClassifier(max_depth=5)\n\ntraining_start = time.perf_counter()\ntfit = t.fit(X_train,y_train)\ntraining_end = time.perf_counter()\n\ntotal_time = training_end-training_start\nprint(\"Training Accuracy:        \",tfit.score(X_train,y_train))\nscores = cross_val_score(t,X_train,y_train,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy:\", scores.mean())   \nprint(\"\\nTime consumed for training %5.4f\" % (total_time))\na[1]=scores.mean()","ca0b7599":"from sklearn.naive_bayes import GaussianNB\nGnb = GaussianNB(priors=None)\n\n\ntraining_start = time.perf_counter()\nGnbfit = Gnb.fit(X_train,y_train)\ntraining_end = time.perf_counter()\n\ntotal_time = training_end-training_start\n\nprint(\"Training Accuracy:        \",Gnbfit.score(X_train,y_train))\nscores = cross_val_score(Gnb,X_train,y_train,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy:\", scores.mean()) \nprint(\"\\nTime consumed for training %5.4f\" % (total_time))\na[2]=scores.mean()","b356678b":"from sklearn.neural_network import MLPClassifier\nMLP = MLPClassifier(hidden_layer_sizes = (1000,1000),max_iter = 1000)\ntraining_start = time.perf_counter()\nMLPfit = MLP.fit(X_train,y_train)\ntraining_end = time.perf_counter()\n\ntotal_time = training_end-training_start\nprint(\"Training Accuracy:        \",MLPfit.score(X_train,y_train))\nscores = cross_val_score(MLP,X_train,y_train,cv=5,scoring=\"accuracy\")\n\nprint(\"Cross Validation Accuracy:\", scores.mean())\nprint(\"\\nTime consumed for training %5.4f\" % (total_time))\na[3]=scores.mean()","c6adadb1":"from sklearn.svm import LinearSVC\nSVC = LinearSVC(penalty='l2',C=10.0,max_iter = 100000)\ntraining_start = time.perf_counter()\nSVCfit = SVC.fit(X_train,y_train)\ntraining_end = time.perf_counter()\n\n\ntotal_time = training_end-training_start\n\nprint(\"Training Accuracy:        \",SVCfit.score(X_train,y_train))\nscores = cross_val_score(SVC,X_train,y_train,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy:\", scores.mean()) \nprint(\"\\nTime consumed for training %5.4f\" % (total_time))\na[4]=scores.mean()","c9f45e67":"from sklearn.ensemble import RandomForestClassifier\nRFC = RandomForestClassifier(n_estimators=10,max_depth=10)\n\ntraining_start = time.perf_counter()\nRFCfit = RFC.fit(X_train,y_train)\ntraining_end = time.perf_counter()\n\ntotal_time = training_end-training_start\nprint(\"Training Accuracy:        \",RFCfit.score(X_train,y_train))\nscores = cross_val_score(RFC,X_train,y_train,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy:\", scores.mean()) \nprint(\"\\nTime consumed for training %5.4f\" % (total_time))\na[5]=scores.mean()","82941e3b":"d1 = pd.DataFrame(a)\nx=['KNN','Decision Tree','Naive Bayes','Neural Network','SVM','Random Forest']\n\nfig,ax = plt.subplots()\nfig.set_size_inches(15,8)\nbottom, top = ax.set_ylim(0.85, 1)\nplt.bar(x,a)\n","b77ad0b5":"prediction_start = time.perf_counter()\nknnpred = knnfit.predict(X_test)\nprediction_end = time.perf_counter()\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",knnfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime ))\nb = [None]*6\nb[0]=knnfit.score(X_test,y_test)\nknnpred","4447880b":"\nprediction_start = time.perf_counter()\ntpred = tfit.predict(X_test)\nprediction_end = time.perf_counter()\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",tfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\nb[1]=tfit.score(X_test,y_test)\ntpred","4711acb8":"prediction_start = time.perf_counter()\nGnbpred = Gnbfit.predict(X_test)\nprediction_end = time.perf_counter()\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",Gnbfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\nb[2]=Gnbfit.score(X_test,y_test)\nGnbpred","c2d9158a":"prediction_start = time.perf_counter()\nMLPpred = MLPfit.predict(X_test)\nprediction_end = time.perf_counter()\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",MLPfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\n\nb[3]=MLPfit.score(X_test,y_test)\nMLPpred","c9e81b97":"prediction_start = time.perf_counter()\nSVCpred = SVCfit.predict(X_test)\nprediction_end = time.perf_counter()\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",SVCfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\n\nb[4]=SVCfit.score(X_test,y_test)\nSVCpred","92fef275":"prediction_start = time.perf_counter()\nRFCpred = RFCfit.predict(X_test)\nprediction_end = time.perf_counter()\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",RFCfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\n\nb[5]=RFCfit.score(X_test,y_test)\nRFCpred","decffa2a":"\nx=['KNN','Decision Tree','Naive Bayes','Neural Network','SVM','Random Forest']\n\nfig,ax = plt.subplots()\nfig.set_size_inches(15,8)\nbottom, top = ax.set_ylim(0.85, 1)\nplt.bar(x,b)\n","c44d1af7":"fig,ax = plt.subplots()\nfig.set_size_inches(20,8)\nplt.subplot(1,2,1)\nbottom, top = ax.set_ylim(0.8, 1)\nplt.bar(x,a)\nplt.title(\"Training set\")\nplt.ylabel(\"Accuracy\")\n\nplt.subplot(1,2,2)\nbottom, top = ax.set_ylim(0.8, 1)\nplt.bar(x,b)\nplt.title(\"Test set\")\nplt.ylabel(\"Accuracy\")\n\n","8e17ccd3":"import itertools\nfrom sklearn.metrics import confusion_matrix\n\nclass_names =['GALAXY','QUASAR','STAR']\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Reds):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n\n\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, RFCpred)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix, without normalization')\n\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\n\nplt.show()","082f9967":"from sklearn.model_selection import GridSearchCV\n\ngrid_param = {\n    'n_estimators' : [50,100,300,500,800,1000],\n    'criterion' : ['gini','entropy'],\n    'bootstrap' : [True, False],\n    'max_depth' : [10,20,50,100]\n}","dfa0237d":"RFCbest = GridSearchCV(RFC,param_grid=grid_param,scoring = \"accuracy\",cv=5,n_jobs=-1)","e27e71a2":"RFCbest.fit(X_train,y_train)","7e6cc640":"print(RFCbest.best_estimator_)","2b224a24":"best_params = RFCbest.best_params_\nprint(best_params)","52959c71":"from sklearn.ensemble import RandomForestClassifier\nRFCa = RandomForestClassifier(bootstrap=False,criterion='gini',max_depth=50,n_estimators=1000)\n\ntraining_start = time.perf_counter()\nRFCbestfit = RFCa.fit(X_train,y_train)\ntraining_end = time.perf_counter()\n\ntotal_time = training_end-training_start\n\nprint(\"Training Accuracy:        \",RFCbestfit.score(X_train,y_train))\nscores = cross_val_score(RFCa,X_train,y_train,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy:\", scores.mean()) \nprint(\"\\nTime consumed for training %6.5f\" % (total_time))\n\na[5]=scores.mean()","b1ea707f":"prediction_start = time.perf_counter()\nRFCpred = RFCbestfit.predict(X_test)\nprediction_end = time.perf_counter()\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",RFCbestfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\nb[5]=RFCbestfit.score(X_test,y_test)\nRFCpred","e0d01cce":"un = np.unique(np.asarray(finaldata['class']).astype('int'))","415e3240":"from collections import Counter\nfrom imblearn.over_sampling import SMOTE\n\nfor i,k in enumerate(un):\n    print(\"Before Oversampling\", k,\"  \",list(Counter(y_train).values())[i]) # counts the elements' frequency\n\nsm = SMOTE(random_state=2)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '2': {}\".format(sum(y_train_res==2)))\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))","acb9d2e5":"from sklearn.ensemble import RandomForestClassifier\nRFC = RandomForestClassifier(bootstrap=False,criterion='gini',max_depth=50,n_estimators=1000)\n\ntraining_start = time.perf_counter()\nRFCfit = RFC.fit(X_train_res,y_train_res)\ntraining_end = time.perf_counter()\n\ntotal_time = training_end-training_start\n\nprint(\"Training Accuracy:        \",RFCfit.score(X_train_res,y_train_res))\nscores = cross_val_score(RFC,X_train_res,y_train_res,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy:\", scores.mean()) \na[5]=scores.mean()","c134f5c3":"\nprediction_start = time.perf_counter()\nRFCpred = RFCfit.predict(X_test)\nprediction_end = time.perf_counter()\n\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",RFCfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\n\nb[5]=RFCfit.score(X_test,y_test)\nRFCpred","ba681398":"from sklearn.decomposition import PCA","ec6d32cd":"pca_d = PCA()\npca_d.fit(X)\ncumsum = np.cumsum(pca_d.explained_variance_ratio_)\nd = np.argmax(cumsum >= 0.95) + 1\nd","49295f9d":"fig,ax = plt.subplots()\nplt.plot(cumsum)\nplt.grid()\nplt.axvline(d,c='r',linestyle='--')","d640e155":"pca = PCA(n_components = 7)\nd_reduced = pca.fit_transform(X)\nd_reducedt = pca.inverse_transform(d_reduced)\n\nprint(d_reduced.shape,d_reducedt.shape)","94fd8187":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nX_train,X_test,y_train,y_test = train_test_split(d_reduced,Y,test_size=0.33,random_state=66)\nkf = KFold(n_splits=5)\n\nfor train, valid in kf.split(X_train):\n\tprint('train: %s, valid: %s' % (train, valid))","1e55dfe7":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nRFCa = RandomForestClassifier(bootstrap=False,criterion='gini',max_depth=50,n_estimators=1000)\n\ntraining_start = time.perf_counter()\nRFCbestfit = RFCa.fit(X_train,y_train)\ntraining_end = time.perf_counter()\n\ntotal_time = training_end-training_start\n\nprint(\"Training Accuracy:        \",RFCbestfit.score(X_train,y_train))\nscores = cross_val_score(RFCa,X_train,y_train,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy:\", scores.mean()) \nprint(\"\\nTime consumed for training %6.5f\" % (total_time))","d1691151":"\nprediction_start = time.perf_counter()\nRFCpred = RFCbestfit.predict(X_test)\nprediction_end = time.perf_counter()\n\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",RFCbestfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\n","9373d19e":"from collections import Counter\nfrom imblearn.over_sampling import SMOTE\nfor i,k in enumerate(un):\n    print(\"Before Oversampling\", k,\"  \",list(Counter(y_train).values())[i]) # counts the elements' frequency\n\nsm = SMOTE(random_state=2)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '2': {}\".format(sum(y_train_res==2)))\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))","006d4832":"from sklearn.ensemble import RandomForestClassifier\nRFC = RandomForestClassifier(bootstrap=False,criterion='gini',max_depth=50,n_estimators=1000)\n\ntraining_start = time.perf_counter()\nRFCfit = RFC.fit(X_train_res,y_train_res)\ntraining_end = time.perf_counter()\n\ntotal_time = training_end-training_start\n\nprint(\"Training Accuracy:        \",RFCfit.score(X_train_res,y_train_res))\nscores = cross_val_score(RFC,X_train_res,y_train_res,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy:\", scores.mean()) \nprint(\"\\nTime consumed for training %6.5f\" % (total_time))","5b9db7f5":"prediction_start = time.perf_counter()\nRFCpred = RFCfit.predict(X_test)\nprediction_end = time.perf_counter()\n\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",RFCfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\n","095e018d":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nX_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.33,random_state=66)\nkf = KFold(n_splits=5)\n\nfor train, valid in kf.split(X_train):\n\tprint('train: %s, valid: %s' % (train, valid))","5f2f6524":"# Fitting the model to get feature importances after training\nmodel = RandomForestClassifier()\nmodel.fit(X_train , y_train)\n\n# Draw feature importances\nimp = model.feature_importances_\nf = X.columns\n# Sort by importance descending\nf_sorted = f[np.argsort(imp)[::-1]]\nfig,ax = plt.subplots(figsize=(15,8))\nsns.barplot(x=f,y = imp, order = f_sorted)\n\n\nplt.title(\"Features importances\")\nplt.ylabel(\"Importance\")\nplt.show()","f26f17f5":"finaldatanew = finaldata[['redshift','specobjid','mjd','z','plate','i','r','g','u']]","8667add7":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nX = finaldatanew\nY = finaldata.iloc[:,15]\n\nY = np.asarray(Y)\nY = Y.astype('int')\n\nX_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.33,random_state=66)\nkf = KFold(n_splits=5)\n\nfor train, valid in kf.split(X_train):\n\tprint('train: %s, valid: %s' % (train, valid))","7b220f11":"from collections import Counter\nfrom imblearn.over_sampling import SMOTE\nfor i,k in enumerate(un):\n    print(\"Before Oversampling\", k,\"  \",list(Counter(y_train).values())[i]) # counts the elements' frequency\n\nsm = SMOTE(random_state=2)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '2': {}\".format(sum(y_train_res==2)))\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))","deadceb7":"from sklearn.ensemble import RandomForestClassifier\nRFC = RandomForestClassifier(bootstrap=False,criterion='gini',max_depth=50,n_estimators=1000)\n\ntraining_start = time.perf_counter()\nRFCfit = RFC.fit(X_train_res,y_train_res)\ntraining_end = time.perf_counter()\n\ntotal_time = training_end-training_start\n\nprint(\"Training Accuracy:        \",RFCfit.score(X_train_res,y_train_res))\nscores = cross_val_score(RFC,X_train_res,y_train_res,cv=5,scoring=\"accuracy\")\nprint(\"Cross Validation Accuracy:\", scores.mean()) \nprint(\"\\nTime consumed for training %6.5f\" % (total_time))","223c18ca":"prediction_start = time.perf_counter()\nRFCpred = RFCfit.predict(X_test)\nprediction_end = time.perf_counter()\n\n\ntotal_testtime = prediction_end-prediction_start\nprint(\"Testing accuracy        \",RFCfit.score(X_test,y_test))\nprint(\"\\nTime consumed for testing %6.5f\" % (total_testtime))\n","229fd8df":"# PCA","3c038f4a":"# Feature subset selection","7e0c9824":"## Since most of the datapoints deleted are w.r.t. quasars we need not delete them since they might be useful for classification of quasars","e64cd6dd":"### SMOTE with the best parameters (Random forest)","90e3e5f6":"# Preliminary Data Analysis","8004744e":"# Karthik Narayanan \n# Vishakaraj Shanmugavel"}}