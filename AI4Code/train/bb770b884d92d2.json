{"cell_type":{"831d97ce":"code","e8aaf20b":"code","fd1b2a26":"code","52927f18":"code","34d599d1":"code","839f2b36":"code","27043aa1":"code","4351d86b":"code","5ff90a2d":"code","a33e20ba":"code","9e13a453":"code","2f3ab151":"code","4e151bfe":"code","748b533f":"code","959d3139":"code","610d2bc2":"code","5a6a1c36":"code","ae1c7d47":"code","b2c099a3":"code","f03fc53d":"code","78453dd0":"code","edd9c79a":"code","105587cb":"code","c56297a3":"code","8db76bf4":"code","d8f45388":"code","03747321":"code","3dd8c56f":"code","e22af71b":"code","db1eebea":"code","6a19dd08":"code","1b9657c1":"code","5ea55cd0":"code","68fa1615":"code","6e181758":"code","87857d76":"code","7ed510b7":"code","327f818c":"code","e3edf56e":"code","d3c7c31a":"code","4e7b80fa":"code","2efd4676":"code","d2dede76":"code","1dc2375b":"code","5d297309":"code","8e7f6905":"code","5a1b84b8":"code","f792a40a":"code","19747f3b":"code","2c24a540":"code","67c96930":"code","fa92fa23":"code","44ac4f31":"code","53291258":"code","f62b9a4c":"code","1a317cce":"code","175ef93e":"code","225c8224":"code","c56d98a0":"code","5e619c36":"code","fb44cbe0":"code","33d30e40":"code","4bfe41b8":"code","6835e328":"code","977cd179":"markdown","eaca3251":"markdown","ceba5713":"markdown","32da00d2":"markdown","8d7e70ec":"markdown","f215dd05":"markdown","45ba0fe6":"markdown","ac3ee934":"markdown","e856bd7c":"markdown","b6068564":"markdown","c77c4ae0":"markdown","391dd656":"markdown","ee968594":"markdown","7e280164":"markdown","07f66a4b":"markdown","abff5464":"markdown","eec6553b":"markdown","5457cda4":"markdown","19a55f57":"markdown","77c7dc5b":"markdown","f95ac440":"markdown","da315e8a":"markdown","339843ca":"markdown","4d21384d":"markdown","0b849059":"markdown","77ba479b":"markdown","f708ca35":"markdown","3485cbdc":"markdown","0993d9d9":"markdown","6fb5093a":"markdown","29b8f761":"markdown","a6d39fd9":"markdown","0c4a1cb4":"markdown","1ffcf5de":"markdown","92bda10d":"markdown","79ab7968":"markdown","868a39fe":"markdown","240c55ba":"markdown","2cbccbed":"markdown","22d40b3f":"markdown","b69d58a6":"markdown","80279a98":"markdown","01b14219":"markdown","f9c66045":"markdown","510716ec":"markdown","62e4133f":"markdown"},"source":{"831d97ce":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport os\nimport missingno as msno\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n","e8aaf20b":"data_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndata = data_test.copy()","fd1b2a26":"data_train.head()","52927f18":"data_test.head()","34d599d1":"print(\"No of passengers:\", str(len(data_train.index)))","839f2b36":"print(\"No of passengers:\", str(len(data_test.index)))","27043aa1":"msno.bar(data_train,figsize=(20, 5),fontsize=12)\nplt.grid()","4351d86b":"msno.bar(data_test,figsize=(20, 5),fontsize=12)\nplt.grid()","5ff90a2d":"dups_train=data_train.duplicated().sum()\ndups_test=data_test.duplicated().sum()\nprint(\"Total no of duplicate values in train dataset:\",dups_train)\nprint(\"Total no of duplicate values in test dataset:\",dups_test)","a33e20ba":"plt.figure(figsize = (20,8))\nplt.subplot(1,2,1)\nsns.heatmap(data_train.corr(), annot = True,annot_kws={\"size\": 12}, fmt = '.2f', linewidths=.5, cmap=\"Set1\")\nplt.title('Correlation plot of train data', fontsize = 15)\n\nplt.subplot(1,2,2)\nsns.heatmap(data_test.corr(), annot = True,annot_kws={\"size\": 12}, fmt = '.2f', linewidths=.5, cmap=\"Set1\")\nplt.title('Correlation plot of test data', fontsize = 15)\n\nplt.tight_layout()\nplt.show()","9e13a453":"plt.figure(figsize = (10,5))\nsns.countplot(x = 'Survived', data = data_train)\nplt.xticks(np.arange(2), ['No', 'Yes'], fontsize = 12)\nplt.xlabel('Survived', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Count', fontsize = 15)\nplt.show()\nprint(data_train.Survived.value_counts())","2f3ab151":"plt.figure(figsize = (10,5))\nsns.countplot(x = 'Survived', hue = 'Sex', data = data_train)\nplt.xticks(np.arange(2), ['No', 'Yes'], fontsize = 12)\nplt.xlabel('Survived', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Sex', fontsize = 15)\nplt.show()\nprint(pd.crosstab(data_train['Survived'],data_train['Sex']))","4e151bfe":"plt.figure(figsize = (20,5))\nsns.swarmplot(x= 'Survived', y = 'Pclass', data = data_train, hue = 'Sex', size=10,linewidth=2,palette=\"Set2\")\nplt.xticks(np.arange(2), ['No', 'Yes'], fontsize = 12)\nplt.xlabel('Survived', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Pclass', fontsize = 15)\nplt.show()\nprint(pd.crosstab(data_train['Survived'],data_train['Pclass']))","748b533f":"plt.figure(figsize = (20,10))\nsns.swarmplot(x= 'Survived', y = 'Age', data = data_train, hue = 'Sex', size=10,linewidth=2,palette=\"Set2\")\nplt.xticks(np.arange(2), ['No', 'Yes'], fontsize = 12)\nplt.xlabel('Survived', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Age', fontsize = 15)\n\nplt.grid()\nplt.show()","959d3139":"plt.figure(figsize = (20,10))\nsns.swarmplot(x= 'Survived', y = 'Fare', data = data_train, hue = 'Sex', size=10,linewidth=2,palette=\"Set2\")\nplt.xticks(np.arange(2), ['No', 'Yes'], fontsize = 12)\nplt.xlabel('Survived', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Fare', fontsize = 15)\n\nplt.grid()\nplt.show()","610d2bc2":"plt.figure(figsize = (20,10))\nsns.swarmplot(x= 'Survived', y = 'SibSp', data = data_train, hue = 'Sex', size=10,linewidth=2,palette=\"Set2\")\nplt.xticks(np.arange(2), ['No', 'Yes'], fontsize = 12)\nplt.xlabel('Survived', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('SibSp', fontsize = 15)\n\nplt.grid()\nplt.show()","5a6a1c36":"plt.figure(figsize = (20,10))\nsns.swarmplot(x= 'Survived', y = 'Parch', data = data_train, hue = 'Sex', size=10,linewidth=2,palette=\"Set2\")\nplt.xticks(np.arange(2), ['No', 'Yes'], fontsize = 12)\nplt.xlabel('Survived', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Parch', fontsize = 15)\n\nplt.grid()\nplt.show()","ae1c7d47":"plt.figure(figsize = (20,5))\nplt.subplot(1,2,1)\ndata_train['Age'].plot.hist(bins = 20, cmap=\"Set2\")\nplt.xticks(fontsize = 12)\nplt.xlabel('Age', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Frequency', fontsize = 15)\nplt.title('Distribution of the age in train data', fontsize = 15)\n\nplt.subplot(1,2,2)\ndata_test['Age'].plot.hist(bins = 20, cmap=\"Set2\")\nplt.xticks(fontsize = 12)\nplt.xlabel('Age', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Frequency', fontsize = 15)\nplt.title('Distribution of the age in test data', fontsize = 15)\n\nplt.tight_layout()\nplt.show()","b2c099a3":"plt.figure(figsize = (20,5))\nplt.subplot(1,2,1)\nsns.boxplot(x= 'Sex', y = 'Age', data = data_train,notch = True,linewidth=2,palette=\"Set2\")\nplt.xticks(np.arange(2), ['Male', 'Female'], fontsize = 12)\nplt.xlabel('Sex', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Age', fontsize = 15)\nplt.title('Age of Passengers in train data')\n\nplt.subplot(1,2,2)\nsns.boxplot(x= 'Sex', y = 'Age', data = data_test,notch = True,linewidth=2,palette=\"Set2\")\nplt.xticks(np.arange(2), ['Male', 'Female'], fontsize = 12)\nplt.xlabel('Sex', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Age', fontsize = 15)\nplt.title('Age of Passengers in test data')\n\nplt.tight_layout()\nplt.show()","f03fc53d":"plt.figure(figsize = (20,5))\nplt.subplot(1,2,1)\nsns.boxplot(x= 'Pclass', y = 'Age', data = data_train,notch = True, linewidth=2,palette=\"Set2\")\nplt.xticks(np.arange(3), ['First', 'Second', 'Third'], fontsize = 12)\nplt.xlabel('Passenger Class', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Age', fontsize = 15)\nplt.title('Age of Passengers in different Class in train data')\n\nplt.subplot(1,2,2)\nsns.boxplot(x= 'Pclass', y = 'Age', data = data_test,notch = True, linewidth=2,palette=\"Set2\")\nplt.xticks(np.arange(3), ['First', 'Second', 'Third'], fontsize = 12)\nplt.xlabel('Passenger Class', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Age', fontsize = 15)\nplt.title('Age of Passengers in different Class in test data')\n\nplt.tight_layout()\nplt.show()","78453dd0":"plt.figure(figsize = (20,5))\nplt.subplot(1,2,1)\ndata_train['Fare'].plot.hist(bins = 20, cmap=\"Set2\")\nplt.xticks(fontsize = 12)\nplt.xlabel('Fare', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Frequency', fontsize = 15)\nplt.title('Distribution of the fare in train data', fontsize = 15)\n\nplt.subplot(1,2,2)\ndata_test['Fare'].plot.hist(bins = 20, cmap=\"Set2\")\nplt.xticks(fontsize = 12)\nplt.xlabel('Fare', fontsize = 15)\nplt.yticks(fontsize = 12)\nplt.ylabel('Frequency', fontsize = 15)\nplt.title('Distribution of the fare in test data', fontsize = 15)\n\nplt.tight_layout()\nplt.show()","edd9c79a":"data_train.drop(['PassengerId','Name','Ticket', 'Cabin'], axis = 1, inplace = True)\ndata_test.drop(['PassengerId','Name','Ticket', 'Cabin'], axis = 1, inplace = True)","105587cb":"data_train.dropna(inplace = True)\ndata_test['Age'] = data_test['Age'].fillna(0)\ndata_test['Fare'] = data_test['Fare'].fillna(0)","c56297a3":"msno.bar(data_train,figsize=(20, 5),fontsize=12)\nplt.grid()","8db76bf4":"msno.bar(data_test,figsize=(20, 5),fontsize=12)\nplt.grid()","d8f45388":"sex = pd.get_dummies(data_train['Sex'], drop_first=True)\nembark = pd.get_dummies(data_train['Embarked'], drop_first=True)\npcl = pd.get_dummies(data_train['Pclass'], drop_first=True)","03747321":"S = pd.get_dummies(data_test['Sex'], drop_first=True)\nE = pd.get_dummies(data_test['Embarked'], drop_first=True)\nP = pd.get_dummies(data_test['Pclass'], drop_first=True)","3dd8c56f":"data_train = pd.concat([data_train, sex, embark, pcl], axis = 1)","e22af71b":"data_test = pd.concat([data_test, S, E, P], axis = 1)","db1eebea":"data_train.drop(['Sex','Pclass','Embarked'], axis = 1, inplace = True)\ndata_train.head()","6a19dd08":"data_test.drop(['Sex','Pclass','Embarked'], axis = 1, inplace = True)\ndata_test.head()","1b9657c1":"from sklearn.model_selection import train_test_split","5ea55cd0":"X = data_train.drop('Survived', axis = 1)\ny = data_train['Survived']","68fa1615":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)","6e181758":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\nfrom sklearn.metrics import confusion_matrix","87857d76":"LR_model = LogisticRegression(solver='liblinear')\nLR_model.fit(X_train,y_train)","7ed510b7":"LR_test_predict = LR_model.predict(X_test)","327f818c":"print('Accuracy Score : ' + str(accuracy_score(y_test,LR_test_predict)))\nprint('Precision Score : ' + str(precision_score(y_test,LR_test_predict)))\nprint('Recall Score : ' + str(recall_score(y_test,LR_test_predict)))\nprint('F1 Score : ' + str(f1_score(y_test,LR_test_predict)))","e3edf56e":"#print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,LR_test_predict)))","d3c7c31a":"from sklearn.ensemble import RandomForestClassifier","4e7b80fa":"RF_model=RandomForestClassifier(n_estimators=100,random_state=1)\nRF_model.fit(X_train, y_train)","2efd4676":"RF_test_predict = RF_model.predict(X_test)","d2dede76":"print('Accuracy Score : ' + str(accuracy_score(y_test,RF_test_predict)))\nprint('Precision Score : ' + str(precision_score(y_test,RF_test_predict)))\nprint('Recall Score : ' + str(recall_score(y_test,RF_test_predict)))\nprint('F1 Score : ' + str(f1_score(y_test,RF_test_predict)))","1dc2375b":"print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,RF_test_predict)))","5d297309":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier","8e7f6905":"RF1_model=RandomForestClassifier(n_estimators=100,random_state=1)\n\nBagging_model=BaggingClassifier(base_estimator=RF1_model,n_estimators=100,random_state=1)\nBagging_model.fit(X_train, y_train)","5a1b84b8":"Bagging_test_predict = Bagging_model.predict(X_test)","f792a40a":"print('Accuracy Score : ' + str(accuracy_score(y_test,Bagging_test_predict)))\nprint('Precision Score : ' + str(precision_score(y_test,Bagging_test_predict)))\nprint('Recall Score : ' + str(recall_score(y_test,Bagging_test_predict)))\nprint('F1 Score : ' + str(f1_score(y_test,Bagging_test_predict)))","19747f3b":"print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,Bagging_test_predict)))","2c24a540":"from sklearn.ensemble import AdaBoostClassifier\nADB_model = AdaBoostClassifier(n_estimators=100,random_state=1)","67c96930":"ADB_model.fit(X_train,y_train)","fa92fa23":"ADB_test_predict = ADB_model.predict(X_test)","44ac4f31":"print('Accuracy Score : ' + str(accuracy_score(y_test,ADB_test_predict)))\nprint('Precision Score : ' + str(precision_score(y_test,ADB_test_predict)))\nprint('Recall Score : ' + str(recall_score(y_test,ADB_test_predict)))\nprint('F1 Score : ' + str(f1_score(y_test,ADB_test_predict)))","53291258":"print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,ADB_test_predict)))","f62b9a4c":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nLDA_model= LinearDiscriminantAnalysis()","1a317cce":"LDA_model.fit(X_train, y_train)","175ef93e":"LDA_test_predict = LDA_model.predict(X_test)","225c8224":"print('Accuracy Score : ' + str(accuracy_score(y_test,LDA_test_predict)))\nprint('Precision Score : ' + str(precision_score(y_test,LDA_test_predict)))\nprint('Recall Score : ' + str(recall_score(y_test,LDA_test_predict)))\nprint('F1 Score : ' + str(f1_score(y_test,LDA_test_predict)))","c56d98a0":"print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,LDA_test_predict)))","5e619c36":"LDA_test_data_predict = LDA_model.predict(data_test)","fb44cbe0":"temp = data['PassengerId']","33d30e40":"df = pd.DataFrame(temp)","4bfe41b8":"df['Survived'] = LDA_test_data_predict","6835e328":"df.to_csv('submission.csv',index=False)","977cd179":"The outliers present in age is relavant so we keep them.","eaca3251":"**4.1 Train and test data split**","ceba5713":"**2.3 Feature Engineering & Hypothesis Building**","32da00d2":"# 4.0 Building Model","8d7e70ec":"In the dataset, PassengerId, Name, Ticket, and Cabin are the features with no correlation to survival rate. Therefore, we can discard them.","f215dd05":"Looks everything is in order except for the Age, Cabin and Embarked variable. Before imputing the missing data, EDA is necessary.","45ba0fe6":"**3.4.1 MIssing Value Treatment**","ac3ee934":" According to the Pclass, age differs significantly, while for the sexes, the average age is approximately the same.","e856bd7c":"**4.4.1 Model Evaluation metrics**","b6068564":"# 5.0 Result","c77c4ae0":"**4.2.1 Model Evaluation metrics**","391dd656":"**4.3.1 Model Evaluation metrics**","ee968594":"The variables used in the dataset both for train and test, are as follows.\n\n* PassengerId - This is a unique passenger id which should be independent to the survival rate.\n* Survived - This is the target variable which we will use to train model. The 0 means passenger did not               survive and 1 means passenger abled to survive. This is Categorical type as the data are in discreate form. \n* Pclass - The ticket class reflects the socio-economic status of the passenger, it may be possible for a               higher proportion of rich people to survive than poor people. \n* Name - Name of the passengers, which is irrevalent to the survival rate.\n* Sex - Male and Female. This is also an important feature for determining the survival rate.\n* Age - There is a possibility that the younger people were given priority since they have their future and              the older people maybe were given priority because of their dependents.\n* SibSp - Number of siblings or spouses who boarded. It is a important variable to ppredict the Survival rate.\n* Parch - Parents or children who boarded, also have corelation to the survival rate.\n* Ticket - The ticket number. It is not giving any important information to predict the survival rate.\n* Cabin - This is also not an relevant feature to determine the survival rate.\n* Embarked - The embarking port is unlikely to have any correlation on the survival rate.\n\nThus, for determining the survival rate, features with no correlation will be removed.","7e280164":"**3.4.2. Outlier Treatment**","07f66a4b":"**3.4.3 One hot Encoding**","abff5464":"**4.3 Random Forest Model**","eec6553b":"# 3.0 Exploratory Data Analysis:","5457cda4":"**4.2 Logistic Regression Model**","19a55f57":"The number of survivors was almost half that of the dead. Overall, more female passengers survived than male passengers, even though there were more male dead passengers than total survivors. \nFemale passengers were secured first, followed by male co-passengers. The most deaths occurred among men in the 19-30 age group. Top-fare passengers were protected. \n","77c7dc5b":"The selection of the best model depends upon the four performance metrics:\n\n* Accuracy: AdaBoost and Linear Discriminant Analysis produced the best test accuracy with approximately close scores at 78.5. \n\n* Precision: Linear Discriminant Analysis is a clear winner followed by Bagging-Random Forest and Logistic Regression both in second place, respectively.\n\n* Recall: AdaBoost is the strongest by far with a score of 78.4.  Linear Discriminant Analysis is second. \n\n* F1 Score: AdaBoost is best, followed by Linear Discriminant Analysis, respectively. \n\n","f95ac440":"**3.1 Overview**","da315e8a":"# 1.0 Objective:","339843ca":"**3.2.1 Survived**","4d21384d":"**2.5 Duplicate Data**","0b849059":"# 2.0 Data Processing:","77ba479b":"**3.4 Data Wrangling**","f708ca35":"* Predicting Survival on test data set using LDA","3485cbdc":"**4.6 Linear Discriminant Analysis**","0993d9d9":"# 6.0 Verdict","6fb5093a":"Every features are in order except for the Age, Fare and Cabin. EDA is necessary before imputing the missing data.","29b8f761":"The objective of the work is to build a model which can predict survival rate.","a6d39fd9":"An accurate and precise model is the most important metric to determine survival rates. In this study, Linear Discriminant Analysis is preferred.","0c4a1cb4":"**2.1 Importing the basic libraries needed**","1ffcf5de":"**3.4.4. Ready dataset after EDA**","92bda10d":"**3.2.3 Fare**","79ab7968":"For a better understanding of the relationship between all variables, we should first plot the correlation, and then examine the different variables, seeing if we can spot anything unusual or significant.","868a39fe":"**4.5 AdaBoost Model**","240c55ba":"More younger and middle age paggesgers were travelling.","2cbccbed":"**4.6.1 Model Evaluation metrics**","22d40b3f":"No such strong correlations have been observed in both train and test data. Let define and summarize the variables, and analyze the pattern present.","b69d58a6":"**2.2 Importing the data set**","80279a98":"**4.4 Bagging -Random forest Model**","01b14219":"**2.4 Missing Data**","f9c66045":"**3.2 Univariate & Bivariate Analysis**","510716ec":"**3.2.2 Age**","62e4133f":"**4.5.1 Model Evaluation metrics**"}}