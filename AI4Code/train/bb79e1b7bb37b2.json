{"cell_type":{"7f3b22a7":"code","1fddd95b":"code","730631d6":"code","ba98383b":"code","b283520d":"code","f221e9a5":"code","3c8a90c6":"code","934cdf8d":"code","2bbfabe5":"code","bf3ee2ca":"code","edd1d956":"code","a3bc01a8":"code","3ffeff55":"code","d3bafb9a":"code","9f05a651":"code","fa64d388":"code","decee60d":"code","731e299a":"code","6b881507":"code","f20d93be":"code","3e5ea9f5":"code","da72b535":"code","ca421b67":"code","4cf3ad92":"code","bcac7a7b":"code","21debb99":"code","4e5beaa3":"code","8bcb793b":"code","4673845a":"code","8f3d400f":"code","b5cf951c":"code","50ec6c37":"code","fcbd85a1":"code","62a78ab0":"code","10999a09":"code","da0605d4":"code","0cbac1f9":"code","bc6ac2bf":"code","10736cdd":"code","ec6a836e":"code","ce050bbd":"code","c138e82c":"code","e43642a8":"code","00b4bac6":"code","54f94aa5":"code","d62c6439":"code","ad3505a7":"code","a75f2744":"markdown","bf17b8cb":"markdown","86962180":"markdown","5c456bbb":"markdown","d9139441":"markdown","1612497e":"markdown","cf1961c4":"markdown","98acbdcb":"markdown","88025e6e":"markdown","1da97ca6":"markdown","453ab671":"markdown"},"source":{"7f3b22a7":"# Octopus ML pakage - github.com\/gershonc\/octopus-ml\n!pip install octopus-ml --upgrade","1fddd95b":"import warnings\nwarnings.simplefilter(\"ignore\")\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport time\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport tracemalloc\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.metrics import classification_report\n%matplotlib inline\nsns.set_style(\"whitegrid\")\n\npd.set_option('display.max_columns', None)  # or 1000\npd.set_option('display.max_rows', None)  # or 1000\npd.set_option('display.max_colwidth', -1)  # or 199\n\n#check out https:\/\/github.com\/gershonc\/octopus-ml\nimport octopus_ml as oc\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","730631d6":"train_df = pd.read_csv ( \"..\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")","ba98383b":"# Data shape \nprint (\"Train set: \",train_df.shape)\nprint (\"Test set: \",test_df.shape)","b283520d":"# DataFrane Summary by pandas summary package (extension of pandas.describe method) \ndfs = DataFrameSummary(train_df)\ndfs.summary()","f221e9a5":"import missingno as msno\nmsno.matrix(train_df)\n# The dataset is quite full, there are sparse areas which are mainly the lab results (low frequency data)","3c8a90c6":"# Top 5 sparse features, mainly labs results \npd.Series(1 - train_df.count() \/ len(train_df)).sort_values(ascending=False).head(5)","934cdf8d":"# Target distribution analysis\nfig, ax =plt.subplots(1,2)\n\n\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(3,4))\nsns.set_context(\"paper\", font_scale=1.2)                                                  \nsns.countplot('Survived',data=train_df, ax=ax[0])\ntrain_df['Survived'].value_counts().plot.pie(explode=[0,0.2],autopct='%1.2f%%',ax=ax[1])\nfig.show()\n\n# it's a slightly imbalanced datast  ","2bbfabe5":"sns.displot(data = train_df, kind = 'hist', x = 'Age', hue = 'Survived', multiple = 'stack',bins=25,height = 4, aspect = 1.7)\n# The lower the age the survival rate is higher","bf3ee2ca":"sns.displot(data = train_df, kind = 'hist', x = 'Sex', hue = 'Survived', multiple = 'stack',bins=25,height = 4, aspect = 1.7)\n# Female survived in much higher rate than males","edd1d956":"sns.displot(data = train_df, kind = 'hist', x = 'Fare', hue = 'Survived', multiple = 'stack',bins=25,height = 4, aspect = 1.7)\n# the higher the fare the survival rate is high as well","a3bc01a8":"sns.displot(data = train_df, kind = 'hist', x = 'Pclass', hue = 'Survived', multiple = 'stack',bins=3,height = 4, aspect = 1.7)\n\n# Pclass 3 has the lowest survival rate  ","3ffeff55":"plt.style.use('fivethirtyeight')\nplt.figure(figsize=(3,4))\nsns.set_context(\"paper\", font_scale=1.2)   \nsns.factorplot(x=\"Sex\", y=\"Age\", hue=\"Survived\", data=train_df, kind=\"bar\",height = 4, aspect = 2.3)\n\n# the survival rate is higher in older females and younger males","d3bafb9a":"train_df['Embarked'].fillna('S',inplace = True)\ntest_df['Embarked'].fillna('S',inplace = True)","9f05a651":"#remove null value from Age\n\nprint('Median Age of the train passengers: ',train_df['Age'].median())\nprint(train_df['Age'].isnull().sum(),test_df['Age'].isnull().sum(),\"null values present in train, test\")\ntrain_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n\nprint('Median Age of the test passengers: ',test_df['Age'].median())\ntest_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n","fa64d388":"combined_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in train_df[\"Name\"]]\ntrain_df[\"Title\"] = pd.Series(combined_title)\ntrain_df[\"Title\"] = train_df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntrain_df[\"Title\"] = train_df[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ntrain_df[\"Title\"] = train_df[\"Title\"].astype('category')\n\ncombined_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in test_df[\"Name\"]]\ntest_df[\"Title\"] = pd.Series(combined_title)\ntest_df[\"Title\"] = test_df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntest_df[\"Title\"] = test_df[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ntest_df[\"Title\"] = test_df[\"Title\"].astype('category')\n","decee60d":"Ticket = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ntrain_df[\"Ticket\"] = Ticket\ntrain_df[\"Ticket\"].head()\n\nTicket2 = []\nfor i in list(test_df.Ticket):\n    if not i.isdigit() :\n        Ticket2.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket2.append(\"X\")\n        \ntest_df[\"Ticket\"] = Ticket2\ntest_df[\"Ticket\"].head()\n","731e299a":"train_df['Ticket_Frequency'] = train_df.groupby('Ticket')['Ticket'].transform('count')\ntest_df['Ticket_Frequency'] = test_df.groupby('Ticket')['Ticket'].transform('count')","6b881507":"import re\n\ndeck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\ndata = [train_df, test_df]\n\nfor dataset in data:\n    # Modification of cabin column to keep only the letter contained corresponding to the deck of the boat\n\n    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n    dataset['Deck'] = dataset['Deck'].map(deck)\n    dataset['Deck'] = dataset['Deck'].fillna(0)\n    dataset['Deck'] = dataset['Deck'].astype('category')\n    \n    #calculate feature that shows number of relatives on the ship \n\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n    dataset['not_alone'] = dataset['not_alone'].astype(int)\n\n    # Create a Title column from name column\n    # dataset['Title'] = pd.Series((name.split('.')[0].split(',')[1].strip() for name in dataset['Name']), index=dataset.index)\n    # dataset['Title'] = dataset['Title'].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    # dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')\n    # dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    # dataset['Title'] = dataset['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5})","f20d93be":"def encodeAgeFare(train):\n    train.loc[train['Age'] <= 16, 'Age_fare'] = 0\n    train.loc[(train['Age'] > 16) & (train['Age'] <= 32), 'Age_fare'] = 1\n    train.loc[(train['Age'] > 32) & (train['Age'] <= 48), 'Age_fare'] = 2\n    train.loc[(train['Age'] > 48) & (train['Age'] <= 64), 'Age_fare'] = 3\n    train.loc[ (train['Age'] > 48) & (train['Age'] <= 80), 'Age_fare'] = 4\n    \n    train.loc[train['Fare'] <= 7.91, 'Fare'] = 0\n    train.loc[(train['Fare'] > 7.91) & (train['Fare'] <= 14.454), 'Fare_adj'] = 1\n    train.loc[(train['Fare'] > 14.454) & (train['Fare'] <= 31.0), 'Fare_adj'] = 2\n    train.loc[(train['Fare'] > 31.0) & (train['Fare'] <= 512.329), 'Fare_adj'] = 3\n\nencodeAgeFare(train_df)\nencodeAgeFare(test_df)","3e5ea9f5":"train_df.head(3)","da72b535":"features=train_df.columns.to_list()\nprint ('Number of features ', len(features)-1)\nfeatures_remove=['Survived']\nfor f in features_remove:\n    features.remove(f)","ca421b67":"# Categorical features\n\ncategorical_features=[]\nfor c in train_df.columns:\n    col_type = train_df[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        train_df[c] = train_df[c].astype('category')\n        categorical_features.append(c)\nprint (categorical_features)","4cf3ad92":"X=train_df[features]\ny=train_df['Survived']","bcac7a7b":"params = {\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': 'auc',\n        'learning_rate': 0.05,\n        'n_estimators': 100,\n        'verbose': -1,\n        'max_depth': -1,\n        'seed':100,      \n        'min_split_gain': 0.01, \n        'num_leaves': 18, \n        'reg_alpha': 0.071, \n        'reg_lambda': 1.50,\n        'feature_fraction':0.2,\n        'bagging_fraction':0.84,\n        'lambda_l2':2.4777,\n        'min_child_weight':20.70, \n        'min_split_gain':0.01363\n}\n\nmetrics = oc.cv_adv(X,y,0.5,100,shuffle=True,params=params)","21debb99":"oc.cv_plot(metrics['f1_weighted'],metrics['f1_macro'],metrics['f1_positive'],'Titanic Kaggle competition')","4e5beaa3":"print(classification_report(metrics['y'], metrics['predictions_folds']))","8bcb793b":"oc.roc_curve_plot(metrics['y'], metrics['predictions_proba'])","4673845a":"oc.confusion_matrix_plot(metrics['y'], metrics['predictions_folds'])","8f3d400f":"feature_imp_list=oc.plot_imp(metrics['final_clf'],X,'LightGBM Mortality Kaggle',num=15)","b5cf951c":"top_features=feature_imp_list.sort_values(by='Value', ascending=False).head(20)\ntop_features\n","50ec6c37":"list_for_correlations=top_features['Feature'].to_list()\nlist_for_correlations.append('Survived')\noc.correlations(train_df,list_for_correlations)\n\n# following the EDA above, we can see the same correlations, SibSp shows opposite correlation (families were less fortunate to survive)","fcbd85a1":"oc.target_corr(X,y,top_features['Feature'].to_list())","62a78ab0":"oc.data_leakage(X,top_features['Feature'].to_list())","10999a09":"oc.preds_distribution(metrics['y'], metrics['predictions_proba'], bins=40)","da0605d4":"fps=oc.recieve_fps(X, metrics['index'] ,metrics['y'], metrics['predictions_proba'],top=10)\nfns=oc.recieve_fns(X, metrics['index'] ,metrics['y'], metrics['predictions_proba'],top=10)","0cbac1f9":"fps","bc6ac2bf":"fns","10736cdd":"def Kaggle_submission(file_name,model,test_data,ids_list):\n    if TARGET in test_data.columns:\n        test_data.drop([TARGET],axis=1,inplace=True)\n    #test_pred=model.predict(test_data[features])[:,1]\n    test_pred=model.predict(test_data[features])\n    predictions = []\n    predictions = oc.adjusted_classes(test_pred, 0.5)\n\n    submit=pd.DataFrame()\n    submit['PassengerId'] = ids_list\n    submit['Survived'] = predictions\n    submit.to_csv(file_name,index=False)\n    return submit","ec6a836e":"# Categorical features on testset\n\ncategorical_features=[]\nfor c in test_df.columns:\n    col_type = train_df[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        test_df[c] = test_df[c].astype('category')\n        categorical_features.append(c)\nprint (categorical_features)\n\nTARGET=\"Survived\"\nsubmit=Kaggle_submission(\"LGBM_baseline_final_clf.csv\",metrics['final_clf'],test_df,test_df['PassengerId'].tolist())","ce050bbd":"test_pred=metrics['final_clf'].predict(test_df[features])\npredictions = []\npredictions = oc.adjusted_classes(test_pred, 0.5)","c138e82c":"test_pred[1:20]","e43642a8":"predictions[0:10]","00b4bac6":"submit.head(10)","54f94aa5":"results=submit.copy()\nfor i, s_clf in enumerate(metrics['stacked_models']):\n    test_pre = (s_clf.predict(test_df))\n    results['clf_'+str(i)]=test_pre\n\ncol = results.loc[: , \"clf_0\":\"clf_4\"]\nresults['final_proba'] = col.mean(axis=1)\nresults.head(2)\n","d62c6439":"submit['Survived']= oc.adjusted_classes(results['final_proba'], 0.5)\nsubmit.to_csv('stacked_submission.csv',index = False)\nsubmit.head(4)","ad3505a7":"test_pred=metrics['final_clf'].predict(X[features])\npredictions = []\npredictions = oc.adjusted_classes(test_pred, 0.5)\nprint(classification_report(y, predictions))","a75f2744":"## Load the datasets  ","bf17b8cb":"### Mimissing data analysis ","86962180":"## Sanity test","5c456bbb":"## Introduction\n\nThis notebook is a very basic   example of LightGBM model and a showcase of a package octopus-ml:\n[https:\/\/github.com\/gershonc\/octopus-ml](https:\/\/github.com\/gershonc\/octopus-ml)\n","d9139441":"## Stacked CV 5-folds models ","1612497e":"## OCTOPUS-ML functions\n[https:\/\/github.com\/gershonc\/octopus-ml](https:\/\/github.com\/gershonc\/octopus-ml)","cf1961c4":"## Model Training (LightGBM)","98acbdcb":"## EDA","88025e6e":"## Model evaluation\n","1da97ca6":"## Test Submission ","453ab671":"## Data pre-processing "}}