{"cell_type":{"79606f07":"code","bc28cfbc":"code","de143acf":"code","b6e35f24":"code","84248fe4":"code","aaf272d2":"code","861a22b6":"code","d30da340":"code","369e585a":"code","b6e76ce3":"code","620edca7":"code","73c6627b":"code","da83ce94":"code","a123c966":"code","f44e365c":"code","699a4c4d":"code","bc652d18":"code","661ddb0c":"code","a4dbd549":"code","d1da582f":"code","adcbbc76":"code","0c88201d":"code","2d8bccb5":"code","1d2ad38c":"code","d99e8268":"code","0e25037f":"code","5bf0629e":"code","7c663806":"code","a09dd21e":"code","22e4b978":"code","3ecabdb9":"code","7d49c3cc":"code","1af2c6e4":"code","f224f472":"code","afa687e6":"code","36a37ee5":"code","ea2cb455":"code","e4c6ec49":"code","dca4e389":"code","7da7fcf2":"code","45ae034f":"code","2d031f1b":"code","58928d9f":"code","13e573e4":"markdown","5791a86d":"markdown","b1e6bec1":"markdown","2679206f":"markdown","810604d5":"markdown","1bfd11b0":"markdown","a7afa517":"markdown","f3dce8b6":"markdown","92fd81f9":"markdown","ebd8ed2b":"markdown","ac022698":"markdown","e7f5b58e":"markdown","d90db3b6":"markdown","20c4b9cb":"markdown","565618eb":"markdown","a92f6e07":"markdown","bb77ffbb":"markdown","e22d8334":"markdown","47f61721":"markdown","f6b82377":"markdown","9209c8a6":"markdown","fe37919c":"markdown","a73f7a14":"markdown","194ace8f":"markdown","d0cccdc3":"markdown","6241f9d5":"markdown","be6aa89a":"markdown","28156160":"markdown","2acc3c9e":"markdown"},"source":{"79606f07":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns\nimport datetime as dt\nfrom scipy import stats\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.decomposition import PCA","bc28cfbc":"current_date = dt.datetime.strptime('2019-12-10', \"%Y-%m-%d\")","de143acf":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b6e35f24":"df_ecom = pd.read_csv('\/kaggle\/input\/ecom-dataset\/df_ecom.csv').drop('Unnamed: 0', axis=1)","84248fe4":"df_ecom.head()","aaf272d2":"print('Number of rows: ', df_ecom.shape[0])\nprint('Number of columns: ', df_ecom.shape[1])","861a22b6":"df_ecom.info()","d30da340":"df_ecom['reqDate'] = pd.to_datetime(df_ecom['InvoiceDate'], format='%Y-%m-%d %H:%M:%S').dt.strftime('%Y-%m-%d')\ndf_ecom['r'] = df_ecom['reqDate'].apply(lambda x: dt.datetime.strptime(x, \"%Y-%m-%d\"))","369e585a":"df_ecom[(df_ecom['Quantity']<0)|(df_ecom['UnitPrice']<0)][['Quantity', 'UnitPrice']].count()","b6e76ce3":"df_ecom.isnull().sum()","620edca7":"df_ecom.duplicated().sum()","73c6627b":"df_ecom.agg({'reqDate':['min', 'max']})","da83ce94":"df_ecom_cleaned = (df_ecom[(df_ecom['Quantity']>0)\n                       &(df_ecom['UnitPrice']>=0)\n                       &~(df_ecom['CustomerID'].isnull())\n                      ]\n                   .drop_duplicates()\n                  )","a123c966":"print(f'Removed {df_ecom.shape[0] - df_ecom_cleaned.shape[0]} rows')","f44e365c":"df_ecom_cleaned.shape","699a4c4d":"df_ecom_cleaned['amount'] = df_ecom_cleaned['UnitPrice'] * df_ecom_cleaned['Quantity']","bc652d18":"pie_country = (df_ecom_cleaned.groupby('Country').agg({'InvoiceNo': pd.Series.nunique}).reset_index()\n               .sort_values(by='InvoiceNo', ascending=False)\n              )\n\npie = plt.pie(pie_country['InvoiceNo'], startangle=90)\nplt.axis('equal')\n\nlabels = pie_country['Country'][:5]\nplt.legend(pie[0],labels, bbox_to_anchor=(1.05,0.5), loc=\"center right\", fontsize=10, \n           bbox_transform=plt.gcf().transFigure)\n\nplt.show()","661ddb0c":"df_rfm_uk = (df_ecom_cleaned[df_ecom_cleaned['Country']=='United Kingdom']\n              .groupby('CustomerID')\n              .agg({'InvoiceNo':pd.Series.nunique, 'Quantity':'sum'\n                    , 'amount':'sum', 'r':['min','max']\n                   })\n              .reset_index()\n             )\ndf_rfm_uk.columns = ['CustomerID', 'Frequency', 'Quantity', 'Monetary', 'minDate', 'maxDate']\ndf_rfm_uk['currentDate'] = current_date\ndf_rfm_uk['Recency'] = (df_rfm_uk['currentDate'] - df_rfm_uk['maxDate']).dt.days\ndf_rfm_uk = df_rfm_uk.drop(['minDate', 'maxDate', 'currentDate'], axis=1)","a4dbd549":"fig, ax = plt.subplots(figsize=(12, 4))\n\nplt.subplot(1,3,1)\nplt.boxplot(df_rfm_uk['Frequency'], labels=['Frequency'])\nplt.subplot(1,3,2)\nplt.boxplot(df_rfm_uk['Recency'], labels=['Recency'])\nplt.subplot(1,3,3)\nplt.boxplot(df_rfm_uk['Monetary'], labels=['Monetary'])\nplt.show()","d1da582f":"zscores = stats.zscore(df_rfm_uk)","adcbbc76":"df_new_rfm_uk = df_rfm_uk[(zscores < 3).all(axis=1)][['CustomerID','Frequency','Monetary','Recency']]","0c88201d":"print(f'Removed {df_rfm_uk.shape[0]-df_new_rfm_uk.shape[0]} rows containing abnormal values')","2d8bccb5":"df_new_rfm_uk.head(5)","1d2ad38c":"df_new_rfm_uk.shape","d99e8268":"# calculate correlation matrix\ncorr = df_new_rfm_uk.iloc[:,1:4].corr()# plot the heatmap\nsns.heatmap(corr, xticklabels=corr.columns\\\n            , yticklabels=corr.columns, annot=True\\\n            , cmap=sns.diverging_palette(220, 20, as_cmap=True))\nplt.show()","0e25037f":"r_labels=range(4,0,-1)\nf_labels=range(1,5)\nm_labels=range(1,5)\n\nr_quartiles = pd.cut(df_new_rfm_uk['Recency'], bins=4, labels = r_labels)\nf_quartiles = pd.cut(df_new_rfm_uk['Frequency'],bins=4, labels = f_labels)\nm_quartiles = pd.cut(df_new_rfm_uk['Monetary'],bins=4,labels = m_labels)\ndf_new_rfm_uk = df_new_rfm_uk.assign(R=r_quartiles,F=f_quartiles,M=m_quartiles)\n\ndf_new_rfm_uk['RFM_concat'] = df_new_rfm_uk['R'].astype('str')+\\\n                            df_new_rfm_uk['F'].astype('str')+\\\n                            df_new_rfm_uk['M'].astype('str')\n\ndf_new_rfm_uk['RFM_sum'] = df_new_rfm_uk['R'].astype('int')+\\\n                            df_new_rfm_uk['F'].astype('int')+\\\n                            df_new_rfm_uk['M'].astype('int')","5bf0629e":"df_new_rfm_uk.head()","7c663806":"df_rfm = df_new_rfm_uk[['Frequency','Monetary','Recency']]","a09dd21e":"f, ax = plt.subplots(figsize=(15,5))\n\nplt.subplot(1, 3, 1)\nsns.distplot(df_rfm['Frequency'])\n\nplt.subplot(1, 3, 2)\nsns.distplot(df_rfm['Recency'])\n\nplt.subplot(1, 3, 3)\nsns.distplot(df_rfm['Monetary'])\n\nplt.show()","22e4b978":"df_rfm.describe()","3ecabdb9":"df_rfm_log = np.log(df_rfm)","7d49c3cc":"print('After using log transformation')\nf, ax = plt.subplots(figsize=(15,5))\n\nplt.subplot(1, 3, 1)\nsns.distplot(df_rfm_log['Frequency'])\n\nplt.subplot(1, 3, 2)\nsns.distplot(df_rfm_log['Recency'])\n\nplt.subplot(1, 3, 3)\nsns.distplot(df_rfm_log['Monetary'])\n\nplt.show()","1af2c6e4":"scaler = StandardScaler()\nscaler.fit(df_rfm_log)\ndf_normalized = pd.DataFrame(scaler.transform(df_rfm_log))\ndf_normalized.columns = df_rfm_log.columns","f224f472":"df_normalized.describe().round(2)","afa687e6":"# Run the Kmeans algorithm and get the index of data points clusters\n\n#sum of squared distances\nsse = [] # for Elbow method\nsse_ = [] # for Silhouette analysis\n\nlist_k = list(range(2, 15))\n\nfor k in list_k:\n    km = KMeans(n_clusters=k)\n    km.fit(df_normalized)\n    sse.append(km.inertia_)\n    sse_.append([k, silhouette_score(df_normalized, km.labels_)])","36a37ee5":"# Plot sse against k\nplt.plot(list_k, sse, '-o')\nplt.xlabel(r'Number of clusters *k*')\nplt.ylabel('Sum of squared distance')\nplt.grid()\nplt.title('Elbow method')\nplt.show()","ea2cb455":"plt.plot(pd.DataFrame(sse_)[0], pd.DataFrame(sse_)[1])\nplt.xticks(list(range(2, 15)))\nplt.grid()\nplt.title('Silhouette analysis')\nplt.show()","e4c6ec49":"n = 4\n\nkm = KMeans(n_clusters= n)\nkm.fit(df_normalized)\ncentroids = km.cluster_centers_","dca4e389":"df_normalized['label'] = km.labels_","7da7fcf2":"df_normalized.head()","45ae034f":"fig = plt.figure(figsize=(10, 9))\nax = Axes3D(fig)\n\ncolors = ['#2E86C1', '#76D7C4', '#AF601A', '#CB4335', '#F9E79F', '#76448A', '#0E6655', '#99A3A4', 'red', 'black', 'orange']\nfor i in range(0, n):\n    ax.scatter(df_normalized[df_normalized['label']==i]['Monetary']\n                , df_normalized[df_normalized['label']==i]['Frequency']\n                , df_normalized[df_normalized['label']==i]['Recency']\n                , c=f'{colors[i]}', label=f'cluster {i}'\n                , alpha = 0.4\n              )\n    ax.scatter(centroids[i][1], centroids[i][0], centroids[i][2]\n                , marker='*', s=200,\n                c='black')\nplt.legend()\nplt.show()","2d031f1b":"df_rfm['label'] = km.labels_","58928d9f":"fig, ax = plt.subplots(figsize=(5, 10))\n\nplt.subplot(3,1,1)\nsns.boxplot(df_rfm['label'], df_rfm['Frequency'])\n\nplt.subplot(3,1,2)\nsns.boxplot(df_rfm['label'], df_rfm['Monetary'])\n\nplt.subplot(3,1,3)\nsns.boxplot(df_rfm['label'], df_rfm['Recency'])\n\nplt.show()","13e573e4":"As shown above:\n\n* Lable 1: Best customers - bought most recently, most often, and are heavy spenders. <br>\n* Lable 0: Potential loyalist - purchased often with average frequency and spent a good amount, and active recently. <br>\n* Label 3: Promising - recently purchased and had a relatively high frequency.<br>\n* Label 2: Can't lose them - used to visit and purchase, but haven\u2019t been visiting recently<br>\n\nNow we can use these user segments for business purposes such as engagement campaigns, loyalty program, etc.","5791a86d":"## Kmeans clustering","b1e6bec1":"# Background and purposes <br>\nOne of the things to make marketing campaigns successful is to understand your customers based on common characteristics (e.g., region, age, device, or behavior). So that user segmentation is all we need for, we can identify subgroups of users who have similar needs to one another, then make the right actions on each group.\n\nThere are a lot of methods to segment user, for my way, I find the combination of RFM analysis and Kmeans is a simple and elegant approach. Let see how it works.","2679206f":"# RFM analysis","810604d5":"I converted the data type of col \"InvoiceDate\" just in case ","1bfd11b0":"As per this method, k = 2 was a local optimum. But for my purposes in this analysis, I want to segment users in detail, so k = 4 probably works for me.","a7afa517":"+ **Check if data is skewed**","f3dce8b6":"United Kingdom had highest orders. <br>\nSo I try myself first with data of them to make sure customers have a similar in demography or taste of shopping","92fd81f9":"# Data load","ebd8ed2b":"# Package load","ac022698":"## Removing outliers","e7f5b58e":"It's not obviously clear to see where the elbow is, probably from 3 to 5.","d90db3b6":"Suppose that the current date is 2019-12-10","20c4b9cb":"Duplicated rows?","565618eb":"We can see that there is a postive correlation between Monetary and Frequency, and negative correlation between Recency and other variables.","a92f6e07":"Now I can use the RFM score to segment users, however, in this analysis I want to try applying Kmean to see how it works","bb77ffbb":"All variables have the right-skewed distribution, this makes sense as the popular shape of RFM data in retail industry. <br>\n=> Unskew data by Logarithmic transformation (positive values only)","e22d8334":"Using z-score to remove outliers","47f61721":"### Normalizing data (if needed)","f6b82377":"## Data cleaning","9209c8a6":"# Time bound","fe37919c":"It's important to remove noises, we can dive deeper into these customers separately, if they are outliers or genuine bulk buyers.","a73f7a14":"### Selecting optimal number of clusters","194ace8f":"Noted that min of Quantity and UnitPrice is negative, probably these orders are cancelled. Let check how many rows contain minus numbers","d0cccdc3":"# Data exploration","6241f9d5":"+ **K-means works well on variables with the same mean**\n+ **K-means works better on variables with the same variance\/std**","be6aa89a":"Check the time range that I'm working on","28156160":"## Data understanding","2acc3c9e":"Any null cells"}}