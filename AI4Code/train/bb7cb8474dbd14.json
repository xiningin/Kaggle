{"cell_type":{"90f21997":"code","e8310564":"code","d13b1dbd":"code","66330ff7":"code","794e3aab":"code","dc62d584":"code","f05e53d9":"code","00bde32c":"code","0c76369c":"code","5968659d":"code","5bfabb89":"code","4d9699ba":"code","cdd4accd":"markdown","2fe7cc62":"markdown","b2a45792":"markdown","08f13ce1":"markdown","aa342a03":"markdown","8b729716":"markdown","a7380132":"markdown","30a1d0f3":"markdown","2010b264":"markdown","62f4c331":"markdown","049de298":"markdown","a9280002":"markdown"},"source":{"90f21997":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0' # specify GPUs locally\n\nOUTPUT_DIR = '.\/'\nMODEL_DIR = '..\/input\/seti-resnext50-32x4d-weights\/sample7\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","e8310564":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    num_workers=8\n    encoder='tf_efficientnet_b0' #[resnext50_32x4d, tf_efficientnet_b0 ]\n    size=256\n    batch_size=128\n    seed=2020\n    target_size=1\n    target_col='target'\n    n_fold=4\n    trn_fold=[0,1,2,3]\n    inference=True\n    mode='spatial_6ch' #['spatial_6ch', 'spatial_3ch', '6_channel', '3_channel']","d13b1dbd":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport timm\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","66330ff7":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\ndef init_logger(log_file=OUTPUT_DIR+'inference.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n#LOGGER = init_logger()\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","794e3aab":"test = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\ntest['file_path'] = test['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/test\/{x[0]}\/{x}.npy')\ndisplay(test.head())","dc62d584":"# ====================================================\n# Dataset\n# ====================================================\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = np.load(self.file_names[idx])\n        if CFG.mode == 'spatial_6ch':\n            image = image.astype(np.float32)\n            image = np.vstack(image).transpose((1, 0))\n        elif CFG.mode == 'spatial_3ch':\n            image = image[::2].astype(np.float32)\n            image = np.vstack(image).transpose((1, 0))\n        elif CFG.mode == '6_channel':\n            image = image.astype(np.float32)\n            image = np.transpose(image, (1,2,0))\n        elif CFG.mode == '3_channel':\n            image = image[::2].astype(np.float32)\n            image = np.transpose(image, (1,2,0))\n        \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        else:\n            image = image[np.newaxis,:,:]\n            image = torch.from_numpy(image).float()\n\n        return image","f05e53d9":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    if data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size*3),\n            ToTensorV2(),\n        ])","00bde32c":"# ====================================================\n# MODEL\n# ====================================================\nclass SETImodel(nn.Module):\n    def __init__(self, model_name=CFG.encoder, pretrained=False):\n        super().__init__()\n        if CFG.mode == 'spatial_6ch' or CFG.mode == 'spatial_3ch':\n            self.encoder = timm.create_model(model_name, pretrained=pretrained, in_chans=1)\n        else:\n            self.encoder = timm.create_model(model_name, pretrained=pretrained, in_chans=6)\n\n        if hasattr(self.encoder, \"fc\"):\n            nb_ft = self.encoder.fc.in_features\n            self.encoder.fc = nn.Linear(nb_ft, CFG.target_size)\n        elif hasattr(self.encoder, \"_fc\"):\n            nb_ft = self.encoder._fc.in_features\n            self.encoder._fc = nn.Linear(nb_ft, CFG.target_size)\n        elif hasattr(self.encoder, \"classifier\"):\n            nb_ft = self.encoder.classifier.in_features\n            self.encoder.classifier = nn.Linear(nb_ft, CFG.target_size)\n        elif hasattr(self.encoder, \"last_linear\"):\n            nb_ft = self.encoder.last_linear.in_features\n            self.encoder.last_linear = nn.Linear(nb_ft, CFG.target_size)\n\n    def forward(self, x):\n        x = self.encoder(x)\n        return x","0c76369c":"# ====================================================\n# Helper functions\n# ====================================================\ndef inference(model, states, test_loader, device):\n    model.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state)\n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images)\n            y_preds = y_preds.sigmoid().to('cpu').numpy()\n            avg_preds.append(y_preds)\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","5968659d":"# ====================================================\n# inference\n# ====================================================\nmodel = SETImodel(model_name=CFG.encoder, pretrained=False)\nstates = [torch.load(MODEL_DIR+f'{CFG.encoder}_fold{fold}_best_score.pth')['state_dict'] for fold in CFG.trn_fold]\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\npredictions = inference(model, states, test_loader, device)","5bfabb89":"# submission\ntest['target'] = predictions\ntest[['id', 'target']].to_csv(OUTPUT_DIR+'submission.csv', index=False)\ntest.head()","4d9699ba":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,6))\nplt.hist(test.target,bins=100);","cdd4accd":"# Library","2fe7cc62":"`V3` - Initial version\n\n`V4` - Use 3 folds for inference\n\n`V5` - Add `CFG.mode` for `channel` and `spatial`. Use effb0 and 4 folds for inference\n> you can get lb 0.96+.\n\n`V7` - `Train notebook` was updated, so change some parts for `4` mode types.\n> `spatial_6ch`, `spatial_3ch`, `6_channel`, `3_channel`\n\n`V9` - Fix some bugs","b2a45792":"# Dataset","08f13ce1":"# Directory settings","aa342a03":"# Helper functions","8b729716":"# CFG","a7380132":"# Data Loading","30a1d0f3":"# Utils","2010b264":"# Transforms","62f4c331":"# About this notebook  \n- PyTorch resnext50_32x4d -> tf_efficientnet_b0\n- No TTA\n- baseline notebook is [here](https:\/\/www.kaggle.com\/yasufuminakama\/cassava-resnext50-32x4d-starter-inference)\n\n\n## Train Info.\n- 256 Image Size\n- 3 folds -> 4 folds\n- Train notebook : [[Train] SETI-BL: Pytorch Starter\ud83d\udd25](https:\/\/www.kaggle.com\/piantic\/train-seti-bl-pytorch-starter)\n\n\n## Try more\n- Use different image size\n- Ensemble other difference models\n- TTA\n- etc.\n\n\nIf this notebook is helpful, feel free to upvote :)\n\nAnd please upvote the original notebook as well.","049de298":"# inference","a9280002":"# MODEL"}}