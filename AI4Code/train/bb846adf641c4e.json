{"cell_type":{"31daec92":"code","f95890f3":"code","400c08e4":"code","adafb82f":"code","34650639":"code","6ceb925e":"code","6a487663":"code","1abadcbf":"code","b160d313":"code","a88240fb":"code","596b7c92":"code","388e5250":"code","4f70d986":"code","28f33779":"markdown","0fbebf49":"markdown","d18b34db":"markdown","f83a4cc0":"markdown","5c73dd02":"markdown"},"source":{"31daec92":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt","f95890f3":"train_csv = \"..\/input\/traindata\/traindata.csv\"\ntest_csv = \"..\/input\/ucu-machine-learning-inclass\/testdata.csv\"","400c08e4":"X_Train = pd.read_csv(train_csv, usecols = range(1, 17))\ny_Train = pd.read_csv(train_csv, usecols = [17])\nX_Submit = pd.read_csv(test_csv, usecols = range(1, 17))\nprint('X_Train: ', X_Train.shape)\nprint('y_Train: ',y_Train.shape)\nprint(y_Train['y'].value_counts())\nprint('\\nX_Submit: ', X_Submit.shape)","adafb82f":"X_Train.head()","34650639":"frames = [X_Train, X_Submit]\nX_join = pd.concat(frames, keys=['train', 'test'])\n\n# !pip install pandas-profiling\n# import pandas_profiling\n# pandas_profiling.ProfileReport(X_join)","6ceb925e":"# Remove 'previous' because of the correlation\nX_Train_cleaned = X_Train.loc[:, X_Train.columns != 'previous']\nX_Submit_cleaned = X_Submit.loc[:, X_Submit.columns != 'previous']\n\n# One-hot encoding\nframes = [X_Train_cleaned, X_Submit_cleaned]\nX_join = pd.concat(frames, keys=['train', 'test'])\nX_join_dummies = pd.get_dummies(X_join)\n\n# pandas_profiling.ProfileReport(X_join_dummies)","6a487663":"X_Train = X_join_dummies.loc['train']\nX_Submit = X_join_dummies.loc['test']","1abadcbf":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_Train, y_Train, test_size=0.1, random_state=42, stratify=y_Train)\ny_train = np.ravel(y_train)\ny_test = np.ravel(y_test)\ny_test_transformed = np.hstack((1 - y_test.reshape(y_test.size,1),\n                                y_test.reshape(y_test.size,1)))\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","b160d313":"from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nimport xgboost\n\nXGB_Classifier = xgboost.XGBClassifier()\n\nCV_SSS = StratifiedShuffleSplit(n_splits=5, test_size=0.33, random_state=None)\n\nxgb_param_grid = {\n                  'max_depth': np.arange(2, 40, 2),\n                  'learning_rate': np.arange(0.2, 2, 0.2),\n                  'n_estimators': np.arange(20, 400, 20),\n                  'reg_alpha': np.arange(0, 2, 0.2),\n                  'reg_lambda': np.arange(0, 2, 0.2)\n                 }\n\nrandom_grid_XGB_CV = RandomizedSearchCV(XGB_Classifier,\n                                        xgb_param_grid,\n                                        scoring = 'roc_auc',\n                                        cv = CV_SSS,\n                                        n_iter = 1) # change it to 10 or more\nrandom_grid_XGB_CV.fit(X_train, y_train)\nprint(random_grid_XGB_CV.best_score_)\nprint(random_grid_XGB_CV.best_params_)","a88240fb":"# XGB_Classifier = random_grid_XGB_CV.best_estimator_\nXGB_Classifier = xgboost.XGBClassifier(params={'reg_lambda': 1.2, 'reg_alpha': 1.6, 'n_estimators': 60, 'max_depth': 30, 'learning_rate': 0.4})\nXGB_Classifier.fit(X_train, np.ravel(y_train))\nprint(XGB_Classifier.feature_importances_)\n\ny_score = XGB_Classifier.predict_proba(X_test)\nauc_score = roc_auc_score(y_test_transformed, y_score, average='weighted')\nprint('roc-auc = {}'.format(round(auc_score, 4)))","596b7c92":"fpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(2):\n    fpr[i], tpr[i], _ = roc_curve(y_test_transformed[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure()\nlw = 2\n\nplt.plot(fpr[1], tpr[1], color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","388e5250":"submission_prediction = XGB_Classifier.predict_proba(X_Submit)[:,1]\nprint(submission_prediction)","4f70d986":"import csv\nfrom datetime import datetime as dt\nimport pytz\n\ntime_now = dt.now(pytz.timezone('Etc\/GMT-3')).strftime(\"%Y%m%dT%H%M\")\nsubmission_file = 'submission_{}_auc_{}.csv'.format(time_now, round(auc_score, 3))\nwith open(submission_file, 'w') as csvfile:\n    fieldnames = ['id', 'y']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n    for i in range(X_Submit.shape[0]):\n            writer.writerow({'id': i+1, 'y': np.round(submission_prediction, 3)[i]})\nprint(submission_file)","28f33779":"## It was a baseline, but it gave the best score","0fbebf49":"### Train-test split","d18b34db":"### Preprocessing","f83a4cc0":"### ROC curve on test data","5c73dd02":"# XGBoost (:\n### Random grid search for parameters tuning"}}