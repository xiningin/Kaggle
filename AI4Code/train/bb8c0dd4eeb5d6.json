{"cell_type":{"0a38b0b8":"code","5a9057a4":"code","bfccee8f":"code","b9d111b4":"code","b910f096":"code","db3ba75f":"code","e631eb7c":"code","1c246b0b":"code","8e3941ef":"code","526dd243":"code","d9924f7c":"code","08cb2d24":"code","3b4b1aa0":"code","ef8bf821":"code","d14db84d":"markdown","bddb8347":"markdown","594ee6e9":"markdown","53c54207":"markdown"},"source":{"0a38b0b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5a9057a4":"df = pd.read_csv('..\/input\/student-alcohol-consumption\/student-por.csv')\ndf.info()","bfccee8f":"df.head(3)","b9d111b4":"df.isnull().sum()\n","b910f096":"df.info()","db3ba75f":"object_type_features = df.select_dtypes(\"object\").columns\nobject_type_features","e631eb7c":"df.G3.value_counts()","1c246b0b":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nfor feat_name in object_type_features: \n    df[feat_name] = le.fit_transform(df[feat_name])\ndf.head()","8e3941ef":"df.info(2)\n","526dd243":"X = df.drop(['G3'], axis = 1)\ny = df.G3","d9924f7c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)","08cb2d24":"from sklearn.metrics import recall_score, precision_score, confusion_matrix","3b4b1aa0":"from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression()\n\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\nprint(\"Train Score LR-\", clf.score(X_train, y_train)*100 , \"%\")\nprint(\"Test Score LR-\", clf.score(X_test, y_test)*100, \"%\")\nprint(\"Recall score\", recall_score(y_test, y_pred, average='macro'))\nprint(\"Precision score\", precision_score(y_test, y_pred, average='macro'))\nprint (\"CONFUSION MATRIX\", confusion_matrix(y_test, y_pred))","ef8bf821":"from sklearn.tree import DecisionTreeClassifier\nclf_dt = DecisionTreeClassifier()\n\nclf_dt.fit(X_train, y_train)\ny_pred = clf_dt.predict(X_test)\nprint(\"Train Score LR-\", clf_dt.score(X_train, y_train)*100 , \"%\")\nprint(\"Test Score LR-\", clf_dt.score(X_test, y_test)*100, \"%\")\nprint(\"Recall score\", recall_score(y_test, y_pred, average='macro'))\nprint(\"Precision score\", precision_score(y_test, y_pred, average='macro')) \nprint (\"CONFUSION MATRIX\", confusion_matrix(y_test, y_pred))","d14db84d":"Clearly **Decision Tree** gives me a better result in all format scores.\nThe scores can be further improved by doing **hyperparameter tuning**.","bddb8347":"**2)Decision Tree**","594ee6e9":"**1) Logistic Regression**","53c54207":"Now I will use Logistic Regression and Decision Tree.\nLet's check which one is better here "}}