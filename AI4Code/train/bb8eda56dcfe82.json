{"cell_type":{"6d4862b0":"code","beb03ec5":"code","12b07add":"code","db90dd78":"code","9f461330":"code","66d856a9":"code","8b227e99":"code","864629c9":"code","95dcf788":"code","ff2c6273":"code","d6584846":"code","7ac0bbc9":"code","4f06bef8":"markdown","9f7ccd25":"markdown","f06fcaee":"markdown","cfb03e51":"markdown","0b421aad":"markdown","1f92cf56":"markdown","fecb60e9":"markdown","22a42dd1":"markdown"},"source":{"6d4862b0":"%%capture\n!pip install pycocotools\n!pip install mxnet-cu110 autogluon.vision\n!pip install -U gluoncv==0.10.3.post0","beb03ec5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport logging\nimport sys\nimport os\nimport json  # for dumping json serialized results\nimport zipfile  # for creating submission zip file\nfrom pycocotools.coco import COCO\nroot = '..\/input\/cowboyoutfits'\nlogger = logging.getLogger()\nlogger.addHandler(logging.StreamHandler(sys.stderr))","12b07add":"coco = COCO(os.path.join(root, 'train.json'))","db90dd78":"print('Data info:', coco.info())\ncategories = {cat_info['name']:cat_info['id'] for cat_info in coco.loadCats(coco.getCatIds())}\nprint('Categories:', categories)","9f461330":"from autogluon.vision import ObjectDetector","66d856a9":"train = ObjectDetector.Dataset.from_coco(os.path.join(root, 'train.json'), root=os.path.join(root, 'images'))\ntrain","8b227e99":"train.show_images()","864629c9":"# randomly select 10 images for each category as valid_data\nsample_n_per_cat = 10\nvalid_ids = pd.Int64Index([])\nfor cat_name in categories.keys():\n    df = train[train.apply(lambda x: True if any([y['class'] == cat_name for y in x['rois']]) else False, axis=1)]\n    df = df.sample(sample_n_per_cat)\n    valid_ids = valid_ids.append(df.index)\ntrain_ids = train.index\ntrain_ids = train_ids.drop(valid_ids)\ntrain_data = train.loc[train_ids]\nvalid_data = train.loc[valid_ids]\nprint('train split:', len(train_data), 'valid split', len(valid_data))","95dcf788":"detector = ObjectDetector(verbosity=2).fit(train_data, valid_data, hyperparameters={'batch_size': 8, 'epochs': 3, 'transfer': 'ssd_512_resnet50_v1_coco'})","ff2c6273":"from PIL import Image\ndef create_submission(df, detector, score_thresh=0.1):\n    results = []\n    for index, row in df.iterrows():\n        img_id = row['id']\n        file_name = row['file_name']\n        img = Image.open(file_name)\n        width, height = img.size\n        output = detector.predict(file_name)\n        for _, p in output.iterrows():\n            if p['predict_score'] > score_thresh:\n                roi = p['predict_rois']\n                pred = {'image_id': img_id,\n                        'category_id': categories[p['predict_class']],\n                        'bbox': [roi['xmin'] * width, roi['ymin'] * height, roi['xmax'] * width, roi['ymax'] * height],\n                        'score': p['predict_score']}\n                results.append(pred)\n    return results","d6584846":"submission_df = pd.read_csv(os.path.join(root, 'valid.csv'))  # replace with test.csv on the last day\nsubmission_df['file_name'] = submission_df.apply(lambda x: os.path.join(root, 'images', x['file_name']), axis=1)\nsubmission = create_submission(submission_df, detector)","7ac0bbc9":"# create json and zip\nsubmission_name = '\/kaggle\/working\/answer.json'\nwith open(submission_name, 'w') as f:\n    json.dump(submission, f)\nzf = zipfile.ZipFile('\/kaggle\/working\/sample_answer.zip', 'w')\nzf.write(submission_name, 'answer.json')\nzf.close()","4f06bef8":"# Stater kit\n\nThis notebook provides the basics of 1) how to handle the data, 2) good practices and pitfalls to avoid, 3) how to generate the submission file for codalab","9f7ccd25":"## Example training module using AutoGluon","f06fcaee":"## Submit to codalab competition to get the evaluation score\n\nhttps:\/\/competitions.codalab.org\/competitions\/33573#participate-submit_results\n\nYou have to submit the your solution file together with the file submission to win the awards!","cfb03e51":"## Load the training data","0b421aad":"## Generate submission\n\nYou will use `valid.csv` for public phase submission, and `test.csv` for the final phase submission. Note that you only have 3 chance to submit for the final phase so be careful not to submit wrong results on the last day","1f92cf56":"Dataset info and categories","fecb60e9":"## Training stater code\n\nWe provide  a fundamental training example using autogluon.vision package with default settings. In order to achieve higher scores, there are multiple details you need to take care:\n\n- Imbalanced training sample: consider that the training samples for e.g. belt is very rare, you can try methods like class aware sampling to inflate the rare classes\n- The training data might contain noises in anotations, there are many custom losses to handle this issue\n- others?","22a42dd1":"### Split train\/valid data with cautious\n\nSince the distribution of categories is very imbalanced, we should carefully split the data by category, to make sure we have enough sample for evaluation. "}}