{"cell_type":{"26eb86d9":"code","cb49de1d":"code","3483baad":"code","15f2dc9b":"code","5ab4ea2d":"code","575a5202":"code","0f25ca01":"code","91d848cc":"code","c64e23be":"code","3850e5fc":"code","5968efb7":"code","b01c7c33":"code","43ebd708":"code","403f7dcf":"markdown","1722eda6":"markdown","7738519e":"markdown","3670f6e9":"markdown","c0a68f34":"markdown"},"source":{"26eb86d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cb49de1d":"social_network_data=pd.read_csv('..\/input\/social-network-ads\/Social_Network_Ads.csv')\n","3483baad":"social_network_data.head()","15f2dc9b":"social_network_data.describe()","5ab4ea2d":"social_network_data.isna().sum()\n#our data is clean","575a5202":"sns.pairplot(social_network_data)\n","0f25ca01":"corr=social_network_data.corr()\nprint(corr)","91d848cc":"sns.heatmap(corr)","c64e23be":"#Features and Labes\nX=social_network_data.iloc[:,[2,3]]#Matrix, our features\ny=social_network_data.iloc[:,4]#Vector, our target","3850e5fc":"#Scaling Our Features\n#First let's split our data into test and train set\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)","5968efb7":"#Now Let's Turn Features_Scaling\nfrom sklearn.preprocessing import StandardScaler\n#Instanciate our scaler\nscaler=StandardScaler()\n#Let's fit and transform our data on training set\nX_train_std=scaler.fit_transform(X_train)\n#Let's transsform our data on test set \nX_test_std=scaler.transform(X_test)","b01c7c33":"#We are going to use support vector machine:SVM\n#We have classification situation so we are going tu use Support Vector Classifier:SVC\nfrom sklearn.svm import SVC\n#Instanciate Our Model\nsvc=SVC(random_state=0)#Here we are going to use linear svc but for non linear we specifiy the parameter kernel='rbf'\n#Let's fit our model \nsvc.fit(X_train_std,y_train)\n#Let's Predict Now\ny_pred=svc.predict(X_test_std)\n","43ebd708":"#Evaluate our model by using confusion matrix\nfrom sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_test,y_pred)\nprint(cm)","403f7dcf":"# Evaluate Our Model","1722eda6":"# Let's Model","7738519e":"# Import The Data ","3670f6e9":"# Data Exploring    ","c0a68f34":"# Data Preprocessing "}}