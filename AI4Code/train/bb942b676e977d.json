{"cell_type":{"1ed5e420":"code","2c34266a":"code","8f33be24":"code","e18ace75":"code","43672e9a":"code","d536d2c9":"code","9ad1d02e":"code","bbb4a86f":"code","6b84a7b4":"code","0750ec2b":"code","8fa3405c":"code","99ad3b6b":"code","3e583cc5":"code","a6de581e":"code","9901c6db":"code","f0bfe5d7":"code","24169ff5":"code","3090ae25":"code","8a70580e":"code","f22d82bf":"code","6e1bc091":"code","cf190975":"code","791743e6":"code","43d8343b":"code","c0349a6e":"code","86037241":"code","0d106769":"code","f7c618ea":"code","0e943aa9":"markdown"},"source":{"1ed5e420":"## DONE: Installed featuretools library in the environment\n# !python -m pip install featuretools","2c34266a":"## DONE: Key imports for any data science project\nimport numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","8f33be24":"## DONE: Create files dictionary for any file in the input directory\nfiles = {}\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        files[filename] = os.path.join(dirname, filename)\n        print(os.path.join(dirname, filename))","e18ace75":"## DONE: Subsidiary import libraries for this project\nimport featuretools as ft","43672e9a":"##DONE: Read in files from input directory\ntrain = pd.read_csv(files['Train.csv'])\ntest = pd.read_csv(files['Test.csv'])\nsubmission = pd.read_csv(files['Submission.csv'])","d536d2c9":"## DONE: Data preparation\n\n# saving identifiers\ntest_Item_Identifier = test['Item_Identifier']\ntest_Outlet_Identifier = test['Outlet_Identifier']\nsales = train['Item_Outlet_Sales']\ntrain.drop(['Item_Outlet_Sales'], axis=1, inplace=True)\n","9ad1d02e":"combi = train.append(test, ignore_index=True)","bbb4a86f":"## DONE: Check the sum of the missing values in the dataframe\ncombi.isnull().sum()","6b84a7b4":"# imputing missing data\ncombi['Item_Weight'].fillna(combi['Item_Weight'].mean(), inplace = True)\ncombi['Outlet_Size'].fillna(\"missing\", inplace = True)","0750ec2b":"## DONE: Data preprocessing\ncombi['Item_Fat_Content'].value_counts()","8fa3405c":"## DONE: Dealing with categorical values i.e here we are doing label encoding\n# dictionary to replace the categories\nfat_content_dict = {'Low Fat':0, 'Regular':1, 'LF':0, 'reg':1, 'low fat':0}\n\ncombi['Item_Fat_Content'] = combi['Item_Fat_Content'].replace(fat_content_dict, regex=True)","99ad3b6b":"# Created unique identifier\ncombi['id'] = combi['Item_Identifier'] + combi['Outlet_Identifier']\ncombi.drop(['Item_Identifier'], axis=1, inplace=True)","3e583cc5":"# creating and entity set 'es'\nes = ft.EntitySet(id = 'sales')\n\n# adding a dataframe \nes.entity_from_dataframe(entity_id = 'bigmart', dataframe = combi, index = 'id')","a6de581e":"es.normalize_entity(base_entity_id='bigmart', new_entity_id='outlet', index = 'Outlet_Identifier', \nadditional_variables = ['Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'])","9901c6db":"feature_matrix, feature_names = ft.dfs(entityset=es, \ntarget_entity = 'bigmart', \nmax_depth = 2, \nverbose = 1, \nn_jobs = 3)","f0bfe5d7":"feature_matrix.columns","24169ff5":"feature_matrix.head()","3090ae25":"feature_matrix = feature_matrix.reindex(index=combi['id'])\nfeature_matrix = feature_matrix.reset_index()","8a70580e":"from catboost import CatBoostRegressor","f22d82bf":"categorical_features = np.where(feature_matrix.dtypes == 'object')[0]\n\nfor i in categorical_features:\n    feature_matrix.iloc[:,i] = feature_matrix.iloc[:,i].astype('str')","6e1bc091":"feature_matrix.drop(['id'], axis=1, inplace=True)\ntrain = feature_matrix[:8523]\ntest = feature_matrix[8523:]","cf190975":"# removing uneccesary variables\ntrain.drop(['Outlet_Identifier'], axis=1, inplace=True)\ntest.drop(['Outlet_Identifier'], axis=1, inplace=True)","791743e6":"# identifying categorical features\ncategorical_features = np.where(train.dtypes == 'object')[0]","43d8343b":"from sklearn.model_selection import train_test_split","c0349a6e":"# splitting train data into training and validation set\nxtrain, xvalid, ytrain, yvalid = train_test_split(train, sales, test_size=0.25, random_state=11)","86037241":"model_cat = CatBoostRegressor(iterations=100, learning_rate=0.3, depth=6, eval_metric='RMSE', random_seed=7)","0d106769":"model_cat.fit(xtrain, ytrain, cat_features=categorical_features, use_best_model=True)","f7c618ea":"model_cat.score(xvalid, yvalid)","0e943aa9":"# **A Hands-On Guide to Automated Feature Engineering using Featuretools in Python**"}}