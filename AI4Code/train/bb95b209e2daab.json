{"cell_type":{"719ba9d8":"code","77ac068d":"code","af998047":"code","2a325a7c":"code","322e52fe":"code","2bb65fb2":"code","456bdfe9":"code","ea62b059":"code","e2f50c09":"code","c9cecd4a":"code","fc4cbc81":"code","188e7c6a":"code","f09bd0d2":"code","b2945833":"code","cc4d7f18":"code","cb83036b":"code","98549930":"code","d17430e6":"code","26071177":"code","490cb828":"code","2f8746bd":"code","2a43ba7f":"code","0fcce4f7":"code","768762fc":"code","f387bb46":"code","6c664fba":"code","dac9df89":"code","dd4cfde5":"code","cf9de851":"code","31c2b6d3":"code","710d25c1":"code","1e8f4ef2":"code","61ff186b":"code","6c205a0a":"code","df599999":"code","9b057a7b":"code","cb535f7d":"code","b84b81b0":"code","635cf085":"code","37e93510":"code","dbb1cbc8":"code","a2217504":"code","05b42f61":"code","f5fbfcfd":"code","f88346a5":"code","66d0144f":"code","173d4250":"code","120cc39b":"code","fa271efa":"code","b2d5d2c7":"code","857275db":"code","f70fbfd6":"code","e41e3480":"code","6251c560":"code","a2f06b1a":"code","9db65222":"code","33d71344":"code","f37b577c":"code","652ac5ed":"code","190a35c2":"code","59e9fa20":"code","d869630d":"code","b0c9b2b3":"code","0efbcf69":"code","e582d8c7":"code","4233e583":"code","63fa6986":"code","031d4513":"code","3cdef80a":"code","dac093d1":"code","f34e57f2":"code","e0dffb43":"code","e12f5924":"code","00662efa":"code","82768457":"code","14b9a0a6":"code","07703f0e":"code","24985227":"code","72b6585e":"code","9fdb12f8":"code","dbb46a52":"code","febbc752":"code","264efc8d":"code","ccc22841":"code","0f607a7f":"code","96d98bd6":"code","dd54760c":"code","46867456":"code","1de857e3":"code","4a66ebd8":"code","bc3dc25e":"code","4ae61bb1":"code","d6eb48d8":"markdown","42ab5a56":"markdown","bd4a9354":"markdown","60aea1fd":"markdown"},"source":{"719ba9d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\n\n\n%matplotlib inline\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","77ac068d":"survived = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsurvived","af998047":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain","2a325a7c":"test = pd.read_csv('..\/input\/titanic\/test.csv')\ntest","322e52fe":"np.sum(pd.isnull(test))","2bb65fb2":"np.sum(pd.isnull(train))","456bdfe9":"def bar_chart(feature):\n    survived = train[train['Survived'] == 1][feature].value_counts()\n    dead = train[train['Survived'] == 0][feature].value_counts()\n    df = pd.DataFrame([survived, dead])\n    df.index = ['Survived', 'Dead']\n    df.plot(kind='bar',stacked=True, figsize =(10,5))","ea62b059":"bar_chart('Sex')","e2f50c09":"#\ud0c0\uc774\ud0c0\ub2c9\uc740 \uac00\ub77c\uc549\uc744\ub54c \ubc43\uba38\ub9ac\ubd80\ud130 \uac00\ub77c\uc549\uc558\uc73c\ubbc0\ub85c \uc704\ucabd\ubd80\ubd84\uc778 1st \ud074\ub798\uc2a4 \uce78\uc774 \uc0dd\uc874\ub960\uc774 \ub192\uc558\ub2e4\uace0 \uac00\uc815\ud560\uc218\uc788\ub2e4\nbar_chart('Pclass')","c9cecd4a":"bar_chart('SibSp')","fc4cbc81":"bar_chart('Parch')","188e7c6a":"bar_chart('Embarked')","f09bd0d2":"train_test_data = [train,test]\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\\.',expand=False)","b2945833":"train['Title'].value_counts()","cc4d7f18":"test","cb83036b":"train","98549930":"pd.set_option('display.max_rows',None)","d17430e6":"#Pclass = 1 : A ~ E,T   Pclass = 2 : D ~ F   Pclass = 3 : E ~ G\ntrain_test_data[0].groupby(['Pclass'])['Cabin'].value_counts()","26071177":"#Pclass = 1 : A ~ E,T   Pclass = 2 : D ~ F   Pclass = 3 : E ~ G\ntrain_test_data[1].groupby(['Pclass'])['Cabin'].value_counts()","490cb828":"#Pclass = 1 : A ~ E,T   Pclass = 2 : D ~ F   Pclass = 3 : E ~ G\n\ntrain_test_data[0].groupby(['Pclass','Cabin','Sex','Age','Title'])['Survived'].value_counts()","2f8746bd":"pd.reset_option('display.max_rows')","2a43ba7f":"train[train['Cabin'] == 'T']['Survived'].value_counts()","0fcce4f7":"train[(train['Survived'] == 1)&(train['Sex'] == 'female')&train['Pclass'] == 1]['Cabin'].value_counts()","768762fc":"train[(train['Sex'] == 'female') & (train['Title'] == 'Countess')]['Survived'].value_counts()","f387bb46":"title_mapping = {'Mr' : 0, 'Miss' : 1, 'Mrs' : 2, 'Master':1, 'Dr':3, 'Rev':3, 'Major':3, 'Col':3, 'Mlle':2, 'Mme':2, 'Ms':2, 'Sir':3, 'Countess':2, 'Jonkheer':3, 'Lady':2, 'Dona':2, 'Capt':3,'Don':3 }\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","6c664fba":"test['Title']","dac9df89":"bar_chart('Title')","dd4cfde5":"train['Fare'].fillna(train.groupby('Pclass')['Fare'].transform('median'), inplace=True)\ntest['Fare'].fillna(test.groupby('Pclass')['Fare'].transform('median'), inplace=True)","cf9de851":"train.groupby('Pclass')['Fare'].transform('median')","31c2b6d3":"facet = sns.FacetGrid(train, hue='Survived',aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade=True)\nfacet.set(xlim=(0,train['Fare'].max()))\nfacet.add_legend()\n\nplt.show()","710d25c1":"test['Family'] = (test.SibSp + test.Parch + 1)\ntrain['Family'] = (train.SibSp + train.Parch + 1)","1e8f4ef2":"test.drop('SibSp', axis=1,inplace=True)\ntest.drop('Parch', axis=1,inplace=True)\ntrain.drop('SibSp', axis=1,inplace=True)\ntrain.drop('Parch', axis=1,inplace=True)","61ff186b":"facet = sns.FacetGrid(train, hue='Survived',aspect=4)\nfacet.map(sns.kdeplot,'Family',shade=True)\nfacet.set(xlim=(0,train['Family'].max()))\nfacet.add_legend()\n\nplt.show()","6c205a0a":"facet = sns.FacetGrid(train, hue='Survived',aspect=4)\nfacet.map(sns.kdeplot,'Family',shade=True)\nfacet.set(xlim=(0,train['Family'].max()))\nfacet.add_legend()\n\nplt.xlim(0,1.73)","df599999":"facet = sns.FacetGrid(train, hue='Survived',aspect=4)\nfacet.map(sns.kdeplot,'Family',shade=True)\nfacet.set(xlim=(0,train['Family'].max()))\nfacet.add_legend()\n\nplt.xlim(1.73,4.6)","9b057a7b":"facet = sns.FacetGrid(train, hue='Survived',aspect=4)\nfacet.map(sns.kdeplot,'Family',shade=True)\nfacet.set(xlim=(0,train['Family'].max()))\nfacet.add_legend()\n\nplt.xlim(4.6,)","cb535f7d":"for data in train_test_data:\n    data.loc[data['Family'] <= 1.73, 'Family'] = 0\n    data.loc[(data['Family'] > 1.73) & (data['Family'] <= 4.6), 'Family'] = 1\n    data.loc[data['Family'] > 4.6, 'Family'] = 2","b84b81b0":"test['Family'].describe()","635cf085":"train['Family'].describe()","37e93510":"test['Age'].fillna(test.groupby('Title')['Age'].transform('median'),inplace=True)\ntrain['Age'].fillna(train.groupby('Title')['Age'].transform('median'),inplace=True)","dbb1cbc8":"facet = sns.FacetGrid(train, hue='Survived', aspect = 4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0,train['Age'].max()))\nfacet.add_legend()\n\nplt.show()","a2217504":"facet = sns.FacetGrid(train, hue='Survived', aspect = 4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0,train['Age'].max()))\nfacet.add_legend()\n\nplt.xlim(0,18)","05b42f61":"facet = sns.FacetGrid(train, hue='Survived', aspect = 4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0,train['Age'].max()))\nfacet.add_legend()\n\nplt.xlim(18,35)","f5fbfcfd":"facet = sns.FacetGrid(train, hue='Survived', aspect = 4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0,train['Age'].max()))\nfacet.add_legend()\n\nplt.xlim(35,60)","f88346a5":"facet = sns.FacetGrid(train, hue='Survived', aspect = 4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0,train['Age'].max()))\nfacet.add_legend()\n\nplt.xlim(60,)","66d0144f":"for data in train_test_data:\n    data.loc[data['Age'] < 18,'Age'] = 0\n    data.loc[(data['Age'] >= 18) & (data['Age'] < 35), 'Age'] = 1\n    data.loc[(data['Age'] >= 35) & (data['Age'] < 60), 'Age'] = 2\n    data.loc[(data['Age'] >= 60),'Age'] = 3","173d4250":"np.sum(pd.isnull(test))","120cc39b":"test.iloc[88]","fa271efa":"np.sum(pd.isnull(train))","b2d5d2c7":"test.groupby('Pclass')['Cabin'].describe()","857275db":"facet = sns.FacetGrid(train, hue='Survived', aspect = 4)\nfacet.map(sns.kdeplot, 'Fare', shade=True)\nfacet.set(xlim=(0,train['Fare'].max()))\nfacet.add_legend()\n\nplt.show()","f70fbfd6":"facet = sns.FacetGrid(train, hue='Survived', aspect = 4)\nfacet.map(sns.kdeplot, 'Fare', shade=True)\nfacet.set(xlim=(0,train['Fare'].max()))\nfacet.add_legend()\n\n\nplt.xlim(0,29)","e41e3480":"facet = sns.FacetGrid(train, hue='Survived', aspect = 4)\nfacet.map(sns.kdeplot, 'Fare', shade=True)\nfacet.set(xlim=(0,train['Fare'].max()))\nfacet.add_legend()\n\nplt.xlim(29,150)","6251c560":"facet = sns.FacetGrid(train, hue='Survived', aspect = 4)\nfacet.map(sns.kdeplot, 'Fare', shade=True)\nfacet.set(xlim=(0,train['Fare'].max()))\nfacet.add_legend()\n\nplt.xlim(150,)","a2f06b1a":"for data in train_test_data:\n    data.loc[data['Fare'] <= 29, 'Fare'] = 0\n    data.loc[(data['Fare'] <= 150) & (data['Fare'] > 29), 'Fare'] = 1\n    data.loc[data['Fare'] > 150 , 'Fare'] = 2","9db65222":"train_test_data[1]['Sex']","33d71344":"for data in train_test_data:\n    data.loc[data['Sex'] == 'female','Sex'] = 0\n    data.loc[data['Sex'] == 'male','Sex'] = 1","f37b577c":"train_test_data","652ac5ed":"np.sum(pd.isnull(train))","190a35c2":"test['Embarked'].fillna('S',inplace=True)\ntrain['Embarked'].fillna('S',inplace=True)","59e9fa20":"np.sum(pd.isna(train))","d869630d":"test.info()","b0c9b2b3":"train.info()","0efbcf69":"test.info()","e582d8c7":"Embarked_mapping = {'S':0,'C':1,'Q':2}\nfor data in train_test_data:\n    data['Embarked'] = data['Embarked'].map(Embarked_mapping)","4233e583":"for data in train_test_data:\n    data['Cabin'] = data['Cabin'].str[:1]","63fa6986":"Pclass1 = train[train['Pclass'] == 1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass'] == 2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass'] == 3]['Cabin'].value_counts()\n\ndf = pd.DataFrame([Pclass1,Pclass2,Pclass3])\ndf.index = ['1','2','3']\ndf.plot(kind='bar', stacked=True, figsize=(10,5))","031d4513":"cabin_mapping = {'T':1.2,'A':0.2,'B':0.4,'C':0.6,'D':0.8,'E':1.0,'F':1.0,'G':1.2}\n\nfor data in train_test_data:\n    data['Cabin'] = data['Cabin'].map(cabin_mapping)","3cdef80a":"test['Cabin'].fillna(test.groupby('Pclass')['Cabin'].transform('median'),inplace=True)\ntrain['Cabin'].fillna(train.groupby('Pclass')['Cabin'].transform('median'),inplace=True)","dac093d1":"train_data = train.drop('Survived',axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","f34e57f2":"train_data.drop('Name',axis=1,inplace=True)\ntrain_data.drop('Ticket',axis=1,inplace=True)\ntrain_data.drop('PassengerId',axis=1,inplace=True)\ntest.drop('Name',axis=1,inplace=True)\ntest.drop('Ticket',axis=1,inplace=True)","e0dffb43":"train_data","e12f5924":"test","00662efa":"np.sum(pd.isnull(test))","82768457":"np.sum(pd.isnull(train))","14b9a0a6":"target","07703f0e":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split","24985227":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle = True, random_state=0)","72b6585e":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1,scoring= scoring)\nprint(score)","9fdb12f8":"round(np.mean(score)*100,2)","dbb46a52":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1,scoring= scoring)\nprint(score)","febbc752":"round(np.mean(score)*100,2)","264efc8d":"clf = RandomForestClassifier(n_estimators = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1,scoring= scoring)\nprint(score)","ccc22841":"round(np.mean(score)*100,2)","0f607a7f":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1,scoring= scoring)\nprint(score)","96d98bd6":"round(np.mean(score)*100,2)","dd54760c":"test","46867456":"clf = SVC()\nclf.fit(train_data, target)\n\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1,scoring= scoring)\nprint(score)","1de857e3":"round(np.mean(score)*100,2)","4a66ebd8":"clf = SVC()\nclf.fit(train_data, target)\n\ntest_data = test.drop('PassengerId',axis=1).copy()\nprediction = clf.predict(test_data)","bc3dc25e":"submission = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived':prediction\n})\n\nsubmission.to_csv('submission.csv',index=False)","4ae61bb1":"submission = pd.read_csv('submission.csv')\nsubmission.head()","d6eb48d8":"# 3. Data Engineering & Fill Na","42ab5a56":"# 2.EDA","bd4a9354":"# 4. Modeling","60aea1fd":"# 1. Import"}}