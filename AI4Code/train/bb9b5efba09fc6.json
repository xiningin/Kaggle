{"cell_type":{"cc94bb41":"code","94ba369d":"code","59580eb1":"code","3c82f141":"code","8a5a1964":"code","c7a83819":"code","f434ebe1":"code","f9781153":"code","32d536ea":"code","d6ee923b":"code","10aa2666":"code","f386f6f7":"code","861647fa":"markdown","1a160ca2":"markdown","0210f6a4":"markdown","83e01aa1":"markdown","bf2369e5":"markdown"},"source":{"cc94bb41":"import numpy as np\nimport pandas as pd\n\nimport re\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor","94ba369d":"data = pd.read_csv('..\/input\/autompg-dataset\/auto-mpg.csv')","59580eb1":"data","3c82f141":"data.info()","8a5a1964":"data","c7a83819":"def onehot_encode(df, column_dict):\n    df = df.copy()\n    for column, prefix in column_dict.items():\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","f434ebe1":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Fill in missing horsepower values with the column mean\n    df['horsepower'] = df['horsepower'].replace('?', np.NaN).astype(np.float)\n    df['horsepower'] = df['horsepower'].fillna(df['horsepower'].mean())\n    \n    # Create make feature\n    df['make'] = df['car name'].apply(lambda x: re.search(r'^\\w+', x).group(0))\n    df = df.drop('car name', axis=1)\n    \n    # Fix typos in make names\n    make_typo_correction = {\n        'vw': 'volkswagen',\n        'chevy': 'chevrolet',\n        'maxda': 'mazda',\n        'vokswagen': 'volkswagen',\n        'toyouta': 'toyota',\n        'chevroelt': 'chevrolet'\n    }\n    df['make'] = df['make'].replace(make_typo_correction)\n    \n    # One-hot encode nominal features\n    nominal_feature_dict = {\n        'origin': 'orig',\n        'make': 'mk'\n    }\n    df = onehot_encode(df, nominal_feature_dict)\n    \n    # Split df into X and y\n    y = df['mpg'].copy()\n    X = df.drop('mpg', axis=1).copy()\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n    \n    # Scale X_train and X_test with a standard scaler fit only on X_train\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","f9781153":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","32d536ea":"X_train","d6ee923b":"# Using a simple linear model\nlinear_model = LinearRegression()\nlinear_model.fit(X_train, y_train)\n\nlinear_r2 = linear_model.score(X_test, y_test)\nprint(\"Linear Regression R^2: {:.1f}\".format(linear_r2))","10aa2666":"# Using a decision tree model\ntree_model = DecisionTreeRegressor()\ntree_model.fit(X_train, y_train)\n\ntree_r2 = tree_model.score(X_test, y_test)\nprint(\"Decision Tree R^2: {:.5f}\".format(tree_r2))","f386f6f7":"# Using random forest regression model\nrf_model = RandomForestRegressor()\nrf_model.fit(X_train, y_train)\n\nrf_r2 = rf_model.score(X_test, y_test)\nprint(\"Random Forest R^2: {:.5f}\".format(rf_r2))","861647fa":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/Q-mEPW2Zf4Q","1a160ca2":"# Getting Started","0210f6a4":"# Training","83e01aa1":"# Task for Today  \n\n***\n\n## Automobile MPG Prediction  \n\nGiven *data about various cars*, let's try to predict the **miles per gallon** of a given vehicle.  \n  \nWe will use linear regression, decision tree, and random forest models to make our predictions.","bf2369e5":"# Preprocessing"}}