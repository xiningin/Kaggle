{"cell_type":{"63f68473":"code","67f9af7c":"code","9fbe3127":"code","43c4cae7":"code","614c22e1":"code","454ceee4":"code","2542a226":"code","ea2b5ae1":"code","6f7026ac":"code","82abe910":"code","2f01d9e9":"markdown","4b5b3182":"markdown","91c43cfb":"markdown","13e429c6":"markdown","5affadbd":"markdown","d270e930":"markdown","2548de66":"markdown","f8db09dd":"markdown","35bd4e1e":"markdown","24b5efcd":"markdown","a3dfcf19":"markdown"},"source":{"63f68473":"import sys, csv\nimport numpy as np\nimport keras\nimport matplotlib.pyplot as plt\nfrom keras import models\nfrom keras import layers\nfrom keras.utils.np_utils import to_categorical","67f9af7c":"def smooth_curve(points, factor=0.9):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n    return smoothed_points","9fbe3127":"Train_Data_List = []\nTrain_Target_List = []","43c4cae7":"with\topen('..\/input\/crime_by_state_rt.csv',\t'r')\tas\tf:\n    reader\t=\tcsv.DictReader(f,\tdelimiter=',')\n    for\trow\tin\treader:\n        Murder\t=\tfloat(row[\"Murder\"])\n        Assault_on_women    =   float(row[\"Assault on women\"])\n        Kidnapping_and_Abduction  =\tfloat(row[\"Kidnapping and Abduction\"])\n        Dacoity\t=\tfloat(row[\"Dacoity\"])\n        Robbery\t=\tfloat(row[\"Robbery\"])\n        Arson\t=\tfloat(row[\"Arson\"])\n        Hurt\t=\tfloat(row[\"Hurt\"])\n        POA\t    =\tfloat(row[\"Prevention of atrocities (POA) Act\"])\n        PCR\t    =\tfloat(row[\"Protection of Civil Rights (PCR) Act\"])\n        Other\t=\tfloat(row[\"Other Crimes Against SCs\"])\n        \n        Train_Data_List.append([Murder, Assault_on_women, Dacoity, Robbery, Arson, Hurt, POA, PCR, Other])\n        Train_Target_List.append(Kidnapping_and_Abduction)\n\nprint(\"=======================Training data=======================\")\nprint(Train_Data_List)\nprint(\"=======================Training Targets====================\")\nprint(Train_Target_List)","614c22e1":"train_data =  np.array(Train_Data_List)\ntrain_targets = np.array(Train_Target_List)\nprint(\"=======================Training data=======================\")\nprint(train_data)\nprint(train_data.shape)\nprint(\"=========================Test data=========================\")\nprint(train_targets)\nprint(train_targets.shape)","454ceee4":"mean = train_data.mean(axis=0)\ntrain_data -= mean\nstd = train_data.std(axis=0)\ntrain_data \/= std","2542a226":"def build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1))\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n    return model","ea2b5ae1":"k = 4\nnum_val_samples = len(train_data) \/\/ k\nnum_epochs = 200\nall_mae_histories = []\nfor i in range(k):\n    print('processing fold #', i)\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n    \n    partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n    \n    model = build_model()\n    history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=100, verbose=0)\n    \n    mae_history = history.history['val_mean_absolute_error']\n    all_mae_histories.append(mae_history)","6f7026ac":"average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]","82abe910":"smooth_mae_history = smooth_curve(average_mae_history[10:])\n    \nplt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()","2f01d9e9":"Take data from ***crimes_by_state_rt.csv*** and append the required data to the above two lists.\nIn this case the target column is chosen to be \"Kidnapping_and_Abduction\".Print the training data and training targets","4b5b3182":"# Regression Model for crimes by state\nThis regression model trains itself with crime data in the ***crimes_by_state_rt.csv*** data set\n","91c43cfb":"A function that's used to smooth the resultant visualiztions","13e429c6":"Using Keras with tensorflow backend, and other imports","5affadbd":"Create two lists to store the training data and the training targets.","d270e930":"Calucate and store the mean MAE for each fold","2548de66":"Convert the Training data and targets into 2D Tensors and print the tensors and there shapes.","f8db09dd":"Train the model, validate the model using k-fold validation and save the validation logs at each fold","35bd4e1e":"Plot the validation scores using matplotlib","24b5efcd":"Normalize the training and test data","a3dfcf19":"Deep learning regression model architecture as a function"}}