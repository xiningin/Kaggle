{"cell_type":{"a0b31c94":"code","da7e591e":"code","03949572":"code","ce93d3a9":"code","3c7b8b0e":"code","7cad9dea":"code","d0572fa1":"code","b7869445":"code","1322f8a6":"code","6c101749":"code","01c1d8cd":"code","374cc845":"code","bb4feaf3":"code","f820b357":"code","eb0b8aad":"code","a31ec323":"code","00338aaa":"code","9b5e6d48":"code","4d2b8468":"code","8c865b47":"code","5391c8a9":"code","02012312":"code","d5e2c65e":"code","5e7ab3c0":"code","4e834eb6":"code","2346f944":"code","a1b16c77":"code","5b197a52":"code","3ceea968":"code","508de302":"code","cfb32906":"code","9bcf2593":"code","dbe7a355":"code","e288654b":"code","73c0920d":"code","4527d632":"code","78086376":"code","9a0a32e2":"code","f997b6f3":"code","d32b62d0":"code","db133470":"code","73c9d971":"code","37abe297":"code","92d6d1f2":"code","d44fcaf7":"code","0017732b":"code","382de8e5":"code","0a6754a4":"code","8e67c0bc":"code","86d65402":"code","f7673969":"code","bcab064d":"code","cf5ce187":"code","f645ecf8":"code","c0429532":"code","4c2cbd52":"code","f664b378":"code","59eecae1":"code","f9b09d71":"code","18de9318":"code","1d146445":"code","b551260b":"markdown","77252e9c":"markdown","30606502":"markdown"},"source":{"a0b31c94":"import numpy as np\nimport pandas as  pd\nimport matplotlib.pyplot as plt\nfrom warnings import filterwarnings\nfrom mpl_toolkits.mplot3d import Axes3D\nimport statsmodels.api as sm\nimport missingno as msno\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom scipy.stats import levene\nfrom scipy.stats import shapiro\nfrom scipy.stats.stats import pearsonr\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, ShuffleSplit, GridSearchCV \nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nimport xgboost as xgb\nfrom xgboost import XGBRegressor, XGBClassifier\nfrom lightgbm import LGBMRegressor, LGBMClassifier\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn import tree\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nimport seaborn as sns ","da7e591e":"train_data = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/train.csv')\ntrain_data","03949572":"train_data.info()","ce93d3a9":"train_data.drop(['id'], 1, inplace=True)","3c7b8b0e":"def change_object_to_int(self):\n    data = self.copy()\n    o_columns = data.select_dtypes(include=object).columns\n    for column in o_columns:\n        le = LabelEncoder()\n        le.fit(data[column])\n        data[column] = le.transform(data[column])\n        print(le.classes_)\n    return data","7cad9dea":"change_object_to_int(train_data)","d0572fa1":"tr_data = change_object_to_int(train_data)","b7869445":"mapping={0:1,1:0, 2:2}\ntr_data['Vehicle_Age'] = tr_data['Vehicle_Age'].map(mapping)  # \u9806\u5e8f\u3092\u305f\u3060\u3059","1322f8a6":"tr_data","6c101749":"def visualize_test_of_no_correlation(self):\n    corrPearson = self.corr(method='pearson')\n    corrSpearman = self.corr(method='spearman')\n    corr_list = [corrPearson, corrSpearman]\n    names = ['Pearson', 'Spearman']\n    for i, corr in enumerate(corr_list):\n        plt.figure(figsize=(10,8))\n        sns.heatmap(corr,annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\n        plt.title('{}'.format(names[i]), fontsize=18, color='blue')\n        plt.xlabel('columns', fontsize=18)\n        plt.ylabel('columns', fontsize=18)\n        plt.show()","01c1d8cd":"visualize_test_of_no_correlation(tr_data)","374cc845":"tr_data.corr(method='spearman') > 0.8","bb4feaf3":"y = tr_data['Response']\nx = tr_data.drop(['Response'], 1)","f820b357":"ols = sm.OLS(y, x).fit()\nols.summary()","eb0b8aad":"x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=4)","a31ec323":"x_train","00338aaa":"y_train.sum() \/ y_train.count(), y_test.sum() \/ y_test.count(), y.sum() \/ y.count()\n# \u3088\u3063\u3066\u3001\u5e73\u7b49\u306b\u5272\u308a\u632f\u3089\u308c\u3066\u3044\u308b\u304c\u3053\u308c\u3067\u306f\u3061\u3083\u3093\u3068\u3057\u305f\u30e2\u30c7\u30eb\u304c\u3067\u304d\u306a\u3044\u306e\u3067\u30010.5\u306b\u306a\u308b\u3088\u3046\u306b\u5272\u308a\u632f\u308b","9b5e6d48":"def create_appropriate_data(self, t_column):\n    df = pd.DataFrame()\n    true = self[self[t_column] == 1]\n    true_num = len(true)\n    false = self[self[t_column] == 0].sample(frac=1) #.reset_index(drop=True)\n    fal = false.iloc[:true_num]\n    df = df.append(true)\n    df = df.append(fal)\n    df = df.sample(frac=1)\n    return df","4d2b8468":"new_train = create_appropriate_data(tr_data, 'Response')","8c865b47":"new_train","5391c8a9":"n_train = new_train.reset_index(drop=True)","02012312":"n_train","d5e2c65e":"n_train['Response'].sum() \/ n_train['Response'].count()\n# \u3053\u308c\u3067\u6b63\u78ba\u306a\u30e2\u30c7\u30eb\u3092\u4f5c\u308b\u3053\u3068\u304c\u3067\u304d\u308b","5e7ab3c0":"n_train.info()","4e834eb6":"n_trainV = n_train.copy()","2346f944":"category_lists = ['Gender', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Response']","a1b16c77":"def change_to_category(self, lists):\n    for column in lists:\n        self[column] = pd.Categorical(self[column])\n    return self","5b197a52":"change_to_category(n_trainV, category_lists)","3ceea968":"n_trainV.info()","508de302":"#sns.catplot(x='Response', y='Age', data=n_trainV, kind='swarm')   # https:\/\/qiita.com\/g-k\/items\/2c5891a27d399645b9aa","cfb32906":"def visualize_bar(self, lists):\n    columns = lists[:-1]\n    t_column = lists[-1]\n    for column in columns:\n        try:\n            plt.figure(figsize=(15,8))\n            #x = self[column]\n            #y = self[t_column].sum()\n            plt.subplot(1,2,1)\n            sns.boxplot(x=column, y=t_column, data=self)\n            plt.subplot(1,2,2)\n            sns.violinplot(x=column, y=t_column, data=self)\n            plt.show()\n        except:\n            fig = plt.figure(figsize=(15,8))\n            ax1 = fig.add_subplot(1,2,1)\n            sns.countplot(x=self[self[t_column] == 1][column])\n            ax1.set_title('subscribe vehicle insurance', fontsize=14)\n            ax2 = fig.add_subplot(1,2,2)\n            sns.countplot(x=self[self[t_column] == 0][column])\n            ax2.set_title('not subscribe vehicle insurance', fontsize=14)\n            fig.show()","9bcf2593":"visualize_bar(n_trainV, n_trainV.columns)\n# \u3069\u3046\u3057\u3066\u304b\u3089\u306e\u56f3\u304c\u3067\u304d\u308b\u304b\u306f\u308f\u304b\u3089\u306a\u3044","dbe7a355":"n_trainV.columns[-1]","e288654b":"fig=plt.figure(figsize=(15,8))\nax1 = fig.add_subplot(1,2,1)\nsns.boxplot(x='Age',y='Response',data=n_trainV)\nax2 = fig.add_subplot(1,2,2)\nsns.violinplot(x='Age',y='Response',data=n_trainV)\nfig.show()","73c0920d":"plt.figure(figsize=(15,8))\nplt.subplot(1,2,1)\nsns.boxplot(x='Age',y='Response', data=n_trainV)\nplt.subplot(1,2,2)\nsns.violinplot(x='Age',y='Response', data=n_trainV)\nplt.show()","4527d632":"x2 = n_train.drop(['Response'],1)\ny2 = n_train['Response']","78086376":"x_tr, x_te, y_tr, y_te = train_test_split(x2, y2, test_size=0.2, random_state=5)","9a0a32e2":"y_tr.sum() \/ y_tr.count(), y_te.sum() \/ y_te.count()","f997b6f3":"lj = LogisticRegression(solver='liblinear').fit(x_tr, y_tr)\ngnb = GaussianNB().fit(x_tr,y_tr)\nknnc = KNeighborsClassifier().fit(x_tr, y_tr)\ncartc = DecisionTreeClassifier(random_state=32).fit(x_tr, y_tr)\nrfc = RandomForestClassifier(random_state=32, verbose=False).fit(x_tr, y_tr)\ngbmc = GradientBoostingClassifier(verbose=False).fit(x_tr, y_tr)\nxgbc = XGBClassifier().fit(x_tr, y_tr)\nlgbmc = LGBMClassifier().fit(x_tr, y_tr)\ncatbc = CatBoostClassifier(verbose=False).fit(x_tr, y_tr)","d32b62d0":"modelsc = [lj, gnb, knnc, cartc, gbmc, xgbc, lgbmc, catbc]","db133470":"def evaluation_models(lists):\n    for model in lists:\n        name = model.__class__.__name__\n        prediction = model.predict(x_te)\n        R2CV = cross_val_score(model, x_te, y_te, cv=10, verbose=False).mean()\n        error = -cross_val_score(model, x_te, y_te, cv=10, scoring='neg_mean_squared_error', verbose=False).mean()\n        print(name+':')\n        print('-'*10)\n        print(accuracy_score(y_te, prediction))\n        print(R2CV)\n        print(np.sqrt(error))\n        print('-'*30)","73c9d971":"evaluation_models(modelsc)","37abe297":"def visualize_R2CV(lists):\n    df = pd.DataFrame(columns=['MODELS', 'R2CV'])\n    for model in lists:\n        name = model.__class__.__name__\n        R2CV = cross_val_score(model, x_te, y_te, cv=10, verbose=False).mean()\n        result = pd.DataFrame([[name,R2CV*100]], columns=['MODELS', 'R2CV'])\n        df = df.append(result)\n    \n    plt.figure(figsize=(10,8))\n    sns.barplot(x='R2CV', y='MODELS', data=df, color='blue')\n    plt.xlabel('R2CV', fontsize=18)\n    plt.ylabel('MODELS', fontsize=18)\n    plt.xlim(0,100)\n    plt.title('MODEL ACCURACY COMPARISON', fontsize=18)\n    plt.show()","92d6d1f2":"visualize_R2CV(modelsc)","d44fcaf7":"test_data = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/test.csv') \ntest_data = change_object_to_int(test_data)\ntest_data['Vehicle_Age'] = test_data['Vehicle_Age'].map(mapping)","0017732b":"test_data","382de8e5":"x3 = test_data.drop(['id'],1)\npredict = gbmc.predict(x3)\nsubmission = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/sample_submission.csv')\nsubmission['Response'] = predict\nsubmission.to_csv('sample_submission.csv', index=False)","0a6754a4":"submission","8e67c0bc":"def visualize_R2CV_2(lists):\n    df = pd.DataFrame(columns=['MODELS', 'R2CV'])\n    for model in lists:\n        name = model.__class__.__name__\n        R2CV = cross_val_score(model, x, y, cv=10, verbose=False).mean()\n        result = pd.DataFrame([[name,R2CV*100]], columns=['MODELS', 'R2CV'])\n        df = df.append(result)\n    \n    plt.figure(figsize=(10,8))\n    sns.barplot(x='R2CV', y='MODELS', data=df, color='blue')\n    plt.xlabel('R2CV', fontsize=18)\n    plt.ylabel('MODELS', fontsize=18)\n    plt.xlim(0,100)\n    plt.title('MODEL ACCURACY COMPARISON', fontsize=18)\n    plt.show()","86d65402":"visualize_R2CV_2(modelsc)","f7673969":"tr_data2 = tr_data.copy()","bcab064d":"tr_data2","cf5ce187":"from imblearn.over_sampling import SMOTE","f645ecf8":"X = tr_data2.drop(['Response'],1)\nY = tr_data2['Response']","c0429532":"xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.2, random_state=37)","4c2cbd52":"#\u4e00\u56de\u76ee\u306f\u30c7\u30fc\u30bf\u3092\u30a2\u30f3\u30c0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3057\u305f\u306e\u3067\u3001\u4eca\u56de\u306f\u30aa\u30fc\u30d0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3092\u8a66\u307f\u308b","f664b378":"oversample = SMOTE()\nxrTrain, yrTrain = oversample.fit_resample(xTrain, yTrain)","59eecae1":"yrTrain.sum(), yTrain.sum() #\u30aa\u30fc\u30d0\u30fc\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3055\u308c\u3066\u3044\u308b\u306e\u304c\u5206\u304b\u308b","f9b09d71":"lj = LogisticRegression(solver='liblinear').fit(xrTrain, yrTrain)\ngnb = GaussianNB().fit(xrTrain,yrTrain)\nknnc = KNeighborsClassifier().fit(xrTrain, yrTrain)\ncartc = DecisionTreeClassifier(random_state=32).fit(xrTrain, yrTrain)\nrfc = RandomForestClassifier(random_state=32, verbose=False).fit(xrTrain, yrTrain)\ngbmc = GradientBoostingClassifier(verbose=False).fit(xrTrain, yrTrain)\nxgbc = XGBClassifier().fit(xrTrain, yrTrain)\nlgbmc = LGBMClassifier().fit(xrTrain, yrTrain)\ncatbc = CatBoostClassifier(verbose=False).fit(xrTrain, yrTrain)","18de9318":"def visualize_R2CV_3(lists):\n    df = pd.DataFrame(columns=['MODELS', 'R2CV'])\n    for model in lists:\n        name = model.__class__.__name__\n        R2CV = cross_val_score(model, xTest, yTest, cv=10, verbose=False).mean()\n        result = pd.DataFrame([[name,R2CV*100]], columns=['MODELS', 'R2CV'])\n        df = df.append(result)\n    \n    plt.figure(figsize=(10,8))\n    sns.barplot(x='R2CV', y='MODELS', data=df, color='blue')\n    plt.xlabel('R2CV', fontsize=18)\n    plt.ylabel('MODELS', fontsize=18)\n    plt.xlim(0,100)\n    plt.title('MODEL ACCURACY COMPARISON', fontsize=18)\n    plt.show()","1d146445":"visualize_R2CV_3(modelsc)","b551260b":"from above graphs, men tends to be interested in vehicle insurance than women.\nAnd people are getting more interested in as getting older.\nand, between vehicle_age from 1 to 2 is a feature which people who is interested in have.\nEspecially, vehice damage and previously_insured are so important to predict. people have vehicle_damage or previously_insured are subject to be interested in the insurance.","77252e9c":"Let's create prediction!","30606502":"SMOTE \u3067\u30c7\u30fc\u30bf\u306e\u4e0d\u5747\u8861\u3084\u4e0d\u8db3\u3092\u88dc\u3046\u6c34\u5897\u3057\u3092\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\nhttps:\/\/qiita.com\/ps010\/items\/38880fad0b8e71464a54"}}