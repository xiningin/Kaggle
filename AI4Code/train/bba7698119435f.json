{"cell_type":{"e95bd2da":"code","284fb6aa":"code","467cbcb3":"code","5c9e4335":"code","b166bbf5":"code","0d3d8d72":"code","d95972a6":"code","f5d813d0":"code","9cb81c13":"code","4c496394":"code","a0e7a32d":"code","e92bdedb":"code","f2ebce37":"code","6807348d":"code","fe3701cd":"code","31f4a512":"code","8a1907e3":"code","e111ca2d":"code","6a24834b":"code","3ecae7d5":"code","10c69137":"code","df910844":"code","ba8fa287":"code","cc543a28":"code","ec86cb18":"code","d61807e2":"code","ef381ffd":"code","29a193a0":"code","5224d338":"code","7113e0c8":"code","521c8eea":"code","76170ddf":"code","87d895a4":"code","239dc25f":"code","d4658dcf":"code","132aa68f":"code","7d029d47":"code","9d9d0e7d":"code","280aaf03":"code","4b53476b":"code","32238686":"code","65ebde72":"code","ec4b6e81":"code","5c27690f":"code","76d00f64":"code","eed5a357":"code","a25c0f6a":"markdown","18ef2f61":"markdown","7cd7a654":"markdown","6b2040b6":"markdown","702dfb91":"markdown"},"source":{"e95bd2da":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nimport os\nfrom distutils.dir_util import copy_tree, remove_tree\n\nfrom PIL import Image\nfrom random import randint\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow_addons as tfa\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPool2D\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","284fb6aa":"base_dir = \"\/kaggle\/input\/alzheimers-dataset-4-class-of-images\/Alzheimer_s Dataset\/\"\nroot_dir = \".\/\"\ntest_dir = base_dir + \"test\/\"\ntrain_dir = base_dir + \"train\/\"\nwork_dir = root_dir + \"dataset\/\"\n\nif os.path.exists(work_dir):\n    remove_tree(work_dir)\n    \n\nos.mkdir(work_dir)\ncopy_tree(train_dir, work_dir)\ncopy_tree(test_dir, work_dir)\nprint(\"Working Directory Contents:\", os.listdir(work_dir))","467cbcb3":"WORK_DIR = '.\/dataset\/'\n\nCLASSES = [ 'NonDemented',\n            'VeryMildDemented',\n            'MildDemented',\n            'ModerateDemented']\n\nIMG_SIZE = 100\nIMAGE_SIZE = [IMG_SIZE, IMG_SIZE]\nDIM = (IMG_SIZE, IMG_SIZE)","5c9e4335":"#Performing Image Augmentation to have more data samples\n\nZOOM = [.99, 1.01]\nBRIGHT_RANGE = [0.8, 1.2]\nHORZ_FLIP = True\nFILL_MODE = \"constant\"\nDATA_FORMAT = \"channels_last\"\n\nwork_dr = IDG(rescale = 1.\/255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n\ntrain_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6500, shuffle=True)","b166bbf5":"def show_images(generator,y_pred=None, nn=6400):\n    \"\"\"\n    Input: An image generator,predicted labels (optional)\n    Output: Displays a grid of 9 images with lables\n    \"\"\"\n    \n    # get image lables\n    labels =dict(zip([0,1,2,3], CLASSES))\n    \n    # get a batch of images\n    x,y = generator.next()\n    \n    # display a grid of 9 images\n    plt.figure(figsize=(10, 10))\n    if y_pred is None:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            idx = randint(0, nn)\n            plt.imshow(x[idx])\n            plt.axis(\"off\")\n            plt.title(\"Class:{}\".format(labels[np.argmax(y[idx])]))\n                                                     \n    else:\n        for i in range(9):\n            ax = plt.subplot(3, 3, i + 1)\n            plt.imshow(x[i])\n            plt.axis(\"off\")\n            plt.title(\"Actual:{} \\nPredicted:{}\".format(labels[np.argmax(y[i])],labels[y_pred[i]]))\n    \n# Display Train Images\nshow_images(train_data_gen,nn=6400)","0d3d8d72":"#Retrieving the data from the ImageDataGenerator iterator\n\ntrain_data, train_labels = train_data_gen.next()","d95972a6":"#Getting to know the dimensions of our dataset\n\nprint(train_data.shape, train_labels.shape)","f5d813d0":"#Splitting the data into train, test, and validation sets\n\ntrain_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)","9cb81c13":"# OVER SAMPLING\n# - train data\nsm = SMOTE(random_state=42)\n\ntrain_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n\ntrain_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(train_data.shape, train_labels.shape)\n\n","4c496394":"# OVER SAMPLING\n# - validation data\nval_data, val_labels = sm.fit_resample(val_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), val_labels)\n\nval_data = val_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(val_data.shape, val_labels.shape)","a0e7a32d":"# OVER SAMPLING\n# - test data\ntest_data, test_labels = sm.fit_resample(test_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), test_labels)\n\ntest_data = test_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nprint(test_data.shape, test_labels.shape)","e92bdedb":"def conv_block(filters, act='relu'):\n    \"\"\"Defining a Convolutional NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(BatchNormalization())\n    block.add(MaxPool2D())\n    \n    return block","f2ebce37":"def dense_block(units, dropout_rate, act='relu'):\n    \"\"\"Defining a Dense NN block for a Sequential CNN model. \"\"\"\n    \n    block = Sequential()\n    block.add(Dense(units, activation=act))\n    block.add(BatchNormalization())\n    block.add(Dropout(dropout_rate))\n    \n    return block","6807348d":"def construct_model(act='relu'):\n    \"\"\"Constructing a Sequential CNN architecture for performing the classification task. \"\"\"\n    \n    model = Sequential([\n        Input(shape=(*IMAGE_SIZE, 3)),\n        Conv2D(16, 3, activation=act, padding='same'),\n        Conv2D(16, 3, activation=act, padding='same'),\n        MaxPool2D(),\n        conv_block(32),\n        conv_block(64),\n        conv_block(128),\n        Dropout(0.2),\n        conv_block(256),\n        Dropout(0.2),\n        Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        Dense(4, activation='softmax')        \n    ], name = \"cnn_model\")\n\n    return model","fe3701cd":"#Defining a custom callback function to stop training our model when accuracy goes above 99%\n\nclass MyCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('val_acc') > 0.99:\n            print(\"\\nReached accuracy threshold! Terminating training.\")\n            self.model.stop_training = True\n            \nmy_callback = MyCallback()\n\n#EarlyStopping callback to make sure model is always learning\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2)","31f4a512":"#Defining other parameters for our CNN model\n\nmodel = construct_model()\n\nMETRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc'), \n           tfa.metrics.F1Score(num_classes=4)]\n\nCALLBACKS = [my_callback]\n\n\nmodel.compile(optimizer='adam',\n              loss=tf.losses.CategoricalCrossentropy(),\n              metrics=METRICS)\n\nmodel.summary()","8a1907e3":"#Fit the training data to the model and validate it using the validation data\nEPOCHS = 150\n\nhistory = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, epochs=EPOCHS)","e111ca2d":"#Plotting the trend of the metrics during training\n\nfig, ax = plt.subplots(1, 3, figsize = (30, 5))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"acc\", \"auc\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","6a24834b":"#Evaluating the model on the data\n\n#train_scores = model.evaluate(train_data, train_labels)\n#val_scores = model.evaluate(val_data, val_labels)\ntest_scores = model.evaluate(test_data, test_labels)\n\n#print(\"Training Accuracy: %.2f%%\"%(train_scores[1] * 100))\n#print(\"Validation Accuracy: %.2f%%\"%(val_scores[1] * 100))\nprint(\"Testing Accuracy: %.2f%%\"%(test_scores[1] * 100))","3ecae7d5":"#Predicting the test data\n\npred_labels = model.predict(test_data)","10c69137":"#Print the classification report of the tested data\n\n#Since the labels are softmax arrays, we need to roundoff to have it in the form of 0s and 1s,\n#similar to the test_labels\ndef roundoff(arr):\n    \"\"\"To round off according to the argmax of each predicted label array. \"\"\"\n    arr[np.argwhere(arr != arr.max())] = 0\n    arr[np.argwhere(arr == arr.max())] = 1\n    return arr\n\nfor labels in pred_labels:\n    labels = roundoff(labels)\n\nprint(classification_report(test_labels, pred_labels, target_names=CLASSES))","df910844":"#Plot the confusion matrix to understand the classification in detail\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_labels, axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Alzheimer\\'s Disease Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","ba8fa287":"#Printing some other classification metrics\n\nprint(\"Balanced Accuracy Score: {} %\".format(round(BAS(test_ls, pred_ls) * 100, 2)))\nprint(\"Matthew's Correlation Coefficient: {} %\".format(round(MCC(test_ls, pred_ls) * 100, 2)))","cc543a28":"#Saving the model for future use\n\nmodel_dir = work_dir + \"alzheimer_cnn_model\"\nmodel.save(model_dir, save_format='h5')\nos.listdir(work_dir)","ec86cb18":"pretrained_model = tf.keras.models.load_model(model_dir)\n\n#Check its architecture\nplot_model(pretrained_model, to_file=work_dir + \"model_plot.png\", show_shapes=True, show_layer_names=True)","d61807e2":"model.summary()","ef381ffd":"from keras.models import Model\n# layer = model.layers[-2]                                                                \n#                                                                    \n# model2 = tf.keras.Model(model.input, layer.output)\n# model2= Model(inputs=model.input, outputs=model.get_layer(\"sequential_13\").output)\nmodel2=Sequential(model.layers[:-1])\n\n# model2 = Model(model.input, model.layers[-1].output)\nmodel2.add(Dense(3, activation='softmax'))\nmodel2.build(input_shape=(None,100,100,3))\nmodel2.summary()","29a193a0":"METRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),\n           tf.keras.metrics.AUC(name='auc'), \n           tfa.metrics.F1Score(num_classes=3)]","5224d338":"model2.compile(optimizer='adam',\n              loss=tf.losses.CategoricalCrossentropy(),\n            metrics=METRICS\n              )","7113e0c8":"# model2.get_weights()","521c8eea":"base_dr = \"\/kaggle\/input\/alzheimers-brain-mri\/MRI\/Training\/\"\nroot_dir = \".\/\"\n\nif os.path.exists(work_dir):\n    remove_tree(work_dir)\n    \n\nos.mkdir(work_dir)\n# copy_tree(base_dr, work_dir)\n\nprint(\"Working Directory Contents:\", os.listdir(base_dr))","76170ddf":"WORK_DIR = base_dr\n\nCLASSES = [ 'CN',\n            'MCI',\n            'AD' ]\n\nIMG_SIZE = 100\nIMAGE_SIZE = [IMG_SIZE, IMG_SIZE]\nDIM = (IMG_SIZE, IMG_SIZE)","87d895a4":"train_data_gen2 = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=600, shuffle=True, )","239dc25f":"train_data2, train_labels2 = train_data_gen2.next()","d4658dcf":"train_data2, test_data2, train_labels2, test_labels2 = train_test_split(train_data2, train_labels2, test_size = 0.2, random_state=42)\ntrain_data2, val_data2, train_labels2, val_labels2 = train_test_split(train_data2, train_labels2, test_size = 0.2, random_state=42)","132aa68f":"print(train_data2.shape, train_labels2.shape)\nprint(val_data2.shape, val_labels2.shape)\nprint(test_data2.shape, test_labels2.shape)","7d029d47":"aug = ImageDataGenerator(\n# \t\trotation_range=20,\n\t\tzoom_range=0.3,\n# \t\twidth_shift_range=0.2,\n# \t\theight_shift_range=0.2,\n# \t\tshear_range=0.15,\n\t\thorizontal_flip=True,\n\t\tfill_mode=\"nearest\")\n\n\n\ntrain_data_gen2=aug.flow(train_data2, train_labels2, batch_size=8)\nval_data_gen2=aug.flow(val_data2, val_labels2, batch_size=8)\ntest_data_gen2=aug.flow(test_data2, test_labels2, batch_size=120)\n","9d9d0e7d":"history2 = model2.fit(train_data_gen2,validation_data= val_data_gen2,callbacks=CALLBACKS, epochs=100)","280aaf03":"len(train_data_gen2[1][0])","4b53476b":"show_images(test_data_gen2, nn=100)","32238686":"test_scores = model2.evaluate(test_data2, test_labels2)","65ebde72":"pred_labels = model2.predict(test_data_gen2[0][0])","ec4b6e81":"print(test_data2.shape, test_labels2.shape)\nprint(len(test_data_gen2[0][0]))","5c27690f":"# print(classification_report(test_labels2, pred_labels, target_names=CLASSES))","76d00f64":"#Plot the confusion matrix to understand the classification in detail\n\n\n\npred_ls = np.argmax(pred_labels, axis=1)\ntest_ls = np.argmax(test_data_gen2[0][1], axis=1)\n\nconf_arr = confusion_matrix(test_ls, pred_ls)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n\nax = sns.heatmap(conf_arr, cmap='Greens', annot=True, fmt='d', xticklabels=CLASSES, yticklabels=CLASSES)\n\nplt.title('Alzheimer\\'s Disease Diagnosis')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","eed5a357":"\nmodel_dir = \".\/\" + \"alzheimer_cnn_model2\"\nmodel.save(model_dir, save_format='h5')\nos.listdir(\".\/\")","a25c0f6a":"# finetune in another dataset  (it isnt complete yet!)\ncontinue training on another dataset of 3 classes:\nAD (200),\nCN (200),\nMCI (200)\n","18ef2f61":"Constructing a Convolutional Neural Network Architecture","7cd7a654":"Training & Testing the Model","6b2040b6":"# Data Preprocessing","702dfb91":"# over sampling"}}