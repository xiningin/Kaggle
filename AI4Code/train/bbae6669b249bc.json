{"cell_type":{"1883b1b4":"code","e89bc871":"code","74f9297e":"code","7f692e72":"code","9292c762":"code","9d41c2cd":"code","5bb82e22":"code","f10f2cd8":"code","f6274d40":"code","35f3912b":"code","da735c07":"code","baa05503":"code","1d753870":"code","77917183":"code","85650d1c":"code","a6b6ec4b":"code","5e70ed84":"code","b63c32e1":"code","ba0ddf76":"code","b2aadcc7":"markdown","e2b842dc":"markdown","ced5c924":"markdown","ca90fba7":"markdown","d35fee4c":"markdown"},"source":{"1883b1b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e89bc871":"from requests import get\n\n\ndef get_data(url):\n    response = get(endpoint, timeout=10)\n    \n    if response.status_code >= 400:\n        raise RuntimeError(f'Request failed: { response.text }')\n        \n    return response.json()\n    \n\nif __name__ == '__main__':\n    endpoint = (\n        'https:\/\/api.coronavirus.data.gov.uk\/v1\/data?'\n        'filters=areaType=nation;areaName=england&'\n        'structure={\"date\":\"date\",\"newCases\":\"newCasesByPublishDate\"}'\n    )\n    \n    data = get_data(endpoint)\n    print(data)","74f9297e":"print(type(data))    #print the type of the data. It is a dictionary","7f692e72":"data_list = data[\"data\"]            #Get the data from the dictionary \nprint(type(data_list))              #print the type of the data_list\ndata_df = pd.DataFrame(data_list )  #convert the list of the updated data into data frame\nprint(data_df.head())               #print the first 5 rows","9292c762":"import matplotlib.pyplot as plt                                                   #matplotlib for graphs\nplt.figure(figsize = (18,10))                                                     #set the figure size \nplt.xticks(range(0,data_df.shape[0],30),data_df['date'].loc[::30],rotation=90)    #Get the xticks from the date (every 30th date) and totate the text to 90 deg\nplt.plot(data_df['date'], data_df['newCases'])                                    #plot the newcases","9d41c2cd":"data_df_rev = data_df.iloc[::-1]                                                            #Reverse the data frame and plot the same graph\nplt.figure(figsize = (18,10))\nplt.plot(range(data_df_rev.shape[0]),(data_df_rev['newCases']))\nplt.xticks(range(0,data_df_rev.shape[0],30),data_df_rev['date'].loc[::30],rotation=90)\nplt.xlabel('Date',fontsize=12)\nplt.ylabel('New Cases',fontsize=12)\nplt.show()\n","5bb82e22":"data_df_rev['SMA_30'] = data_df_rev.newCases.rolling(30, min_periods=14).mean()  #simple moving average of window of 30 days\ndata_df_rev['SMA_14'] = data_df_rev.newCases.rolling(14, min_periods=7).mean() #SMA of window of 14 days","f10f2cd8":"data_df_rev['CMA'] = data_df_rev.newCases.expanding().mean() #cumulative moving average ... it does not perform well for this data as no historical data","f6274d40":"data_df_rev['EMA_0.3'] = data_df_rev.newCases.ewm(alpha=0.3, adjust=False).mean() #exponetial moving average might do well we may have to find right alpha","35f3912b":"print(data_df_rev.head(20))","da735c07":"plt.figure(figsize = (18,10))                                                                      #plot each of these columns \nplt.plot(range(data_df_rev.shape[0]),(data_df_rev['newCases']), color='r', label='New cases')\nplt.plot(range(data_df_rev.shape[0]),(data_df_rev['SMA_30']), color = 'g', label='SMA 30')\nplt.plot(range(data_df_rev.shape[0]),(data_df_rev['SMA_14']), color = 'b', label ='SMA 14')\nplt.plot(range(data_df_rev.shape[0]),(data_df_rev['CMA']), color = 'y', label='CMA')\nplt.plot(range(data_df_rev.shape[0]),(data_df_rev['EMA_0.3']), color = 'k', label = 'EMA 0.3')\nplt.xticks(range(0,data_df_rev.shape[0],14),data_df_rev['date'].loc[::14],rotation=90)\nplt.xlabel('Date',fontsize=18)\nplt.ylabel('New Cases',fontsize=18)\nplt.legend(loc='upper left')\nplt.show()\n","baa05503":"newCases = np.array(data_df_rev.loc[:,'newCases'])          #Get the newcases into an array\nprint(type(newCases))\nprint(newCases.ndim)","1d753870":"train_data = newCases[30:300].reshape(-1,1)         #split and reshape the array into 2 dim. Ignore first 30 data as it is 0 \ntest_data = newCases[300:].reshape(-1,1)            #This is for test","77917183":"print(train_data.shape)     #check the shapes of the test and train data\nprint(test_data.shape)","85650d1c":"from sklearn.gaussian_process import GaussianProcessRegressor                             #import gaussian process regressor which is one of the best model for the timeseries\nfrom sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel, RBF     #some standard kernel functions for the gaussian process    \nkernel = ConstantKernel() + Matern(length_scale=3, nu=3\/2) + WhiteKernel(noise_level=1)   #create a kernel by combining different standard functions\ngp1 = GaussianProcessRegressor(\n    kernel=kernel, \n    n_restarts_optimizer=20, \n    normalize_y=True,\n    alpha=0.1\n)                                                                                      #Create a gaussian process regressor using the kernel functions and setting other parameters","a6b6ec4b":"X = np.array(range(0,len(train_data))).reshape(-1,1)  #create an array of size train_data using the range\nprint(X.shape)","5e70ed84":"gp1.fit(X, train_data)          #fit the train_data ","b63c32e1":"x = np.array(range((len(train_data)-1),len(test_data)+len(train_data)-1)).reshape(-1,1)  #create another array of the size of test_data\ny_pred, sigma = gp1.predict(x, return_std=True)                                          #predict the next few new cases and sigma of the prediction\nprint(y_pred)                                                                            #print the prediction","ba0ddf76":"#plot the results \nplt.figure(figsize = (18,10))\nplt.plot(x, test_data, color='y', label='Test Data')\nplt.plot(X, train_data, color='g', label='Train Data')\nplt.plot(x, y_pred, color='r', label='Prediction')\nplt.fill(np.concatenate([x, x[::-1]]), np.concatenate([y_pred - 2 * sigma, (y_pred + 2 * sigma)[::-1]]), alpha=.01, fc='b', ec='None')\nplt.xlabel('Days from the start of the pandemic')\nplt.ylabel('New Caes')\nplt.legend(loc='upper left')","b2aadcc7":"You can use these code to develop a gaussian process regressor which use all the avaliable data as train data and estimate next few new cases. Check the new cases next day and varify your prediction. Think how can you imporve the prediction of new cases. ","e2b842dc":"If you want to know more about the kernal functions you can check this [The Kernel Cookbook](https:\/\/www.cs.toronto.edu\/~duvenaud\/cookbook\/). Check the [sklearn api](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.gaussian_process.GaussianProcessRegressor.html) documents for more details about the GaussianProcessRegressor and how to use it. ","ced5c924":"We will try to estimate few traditional timeseries model parameters such as simple moving averages for different windows, cumulative moving average, exponetial moving average, etc.","ca90fba7":"Following code is from [UK Coronavirus Data - Developers Guide](https:\/\/coronavirus.data.gov.uk\/details\/developers-guide). We can use this code to get daily updated data into our program. ","d35fee4c":"Becuase the data is in the form of stack (First In Last Out), we get the latest data first and you can see from the graph that latest data is shown at the start of the graph. We need to reverse the data frame if we want to keep as a normal form where latest data will be at the end of the data frame."}}