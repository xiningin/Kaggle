{"cell_type":{"5cb26188":"code","47d33e02":"code","798e4752":"code","82a304ad":"code","5acfbbaa":"code","399062e0":"code","10207c70":"code","aefbde72":"code","bb720899":"code","58ab29f7":"code","ad85d9c6":"code","b8a21e74":"code","4e73267c":"code","52c926e3":"code","bf6d6d9c":"code","00d1170f":"code","b6d6f7b6":"code","c5999915":"code","9f765bed":"code","c9b53e42":"code","f83c58f5":"markdown","5ce55394":"markdown","27f237b9":"markdown","9ad786b9":"markdown"},"source":{"5cb26188":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","47d33e02":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\n","798e4752":"df=pd.read_csv(\"..\/input\/heart-failure-prediction\/heart.csv\")\ndf.head()","82a304ad":"df.shape","5acfbbaa":"df.isnull().sum()","399062e0":"print(\"Sex:\",df['Sex'].unique())\nprint(\"RestingECG:\",df['RestingECG'].unique())\nprint(\"ChestPainType:\",df['ChestPainType'].unique())\nprint(\"ExerciseAngina:\",df['ExerciseAngina'].unique())\nprint(\"ST_Slope:\",df['ST_Slope'].unique())","10207c70":"f, axes = plt.subplots(2, 3, figsize=(15, 10))\n\nsns.countplot(x = df['HeartDisease'], data = df, palette='rocket', ax=axes[0,0])\nsns.countplot(x = df['RestingECG'], data = df, palette='rocket', ax=axes[0,1])\nsns.countplot(x = df['ChestPainType'], data = df, palette='rocket', ax=axes[0,2])\n\nsns.countplot(x = df['ExerciseAngina'], data = df, palette='rocket', ax=axes[1,0])\nsns.countplot(x = df['RestingECG'], data = df, palette='rocket', ax=axes[1,1])\nsns.countplot(x = df['Sex'], data = df, palette='rocket', ax=axes[1,2])\nplt.show()","aefbde72":"plt.figure(figsize = (15, 10))\nsns.displot(df['RestingBP'], color = 'y', kind='kde')\n\nplt.show()","bb720899":"plt.figure(figsize = (20, 10))\nsns.displot(df['Cholesterol'])\n\nplt.show()","58ab29f7":"le=LabelEncoder()\n\ndf['Sex']=le.fit_transform(df['Sex'])\ndf['RestingECG']=le.fit_transform(df['RestingECG'])\ndf['ChestPainType']=le.fit_transform(df['ChestPainType'])\ndf['ExerciseAngina']=le.fit_transform(df['ExerciseAngina'])\ndf['ST_Slope']=le.fit_transform(df['ST_Slope'])\n\ndf.head()","ad85d9c6":"plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(), annot=True, cmap='RdYlBu')","b8a21e74":"X = df.drop('HeartDisease', axis=1)\ny = df['HeartDisease']","4e73267c":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n\nprint(\"X_train: \", X_train.shape)\nprint(\"X_test: \", X_test.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"y_test: \", y_test.shape)","52c926e3":"from sklearn.ensemble import AdaBoostClassifier\n\nabc = AdaBoostClassifier(n_estimators=500, learning_rate=0.01, random_state=0)\nmodel = abc.fit(X_train, y_train)","bf6d6d9c":"y_pred_adaboost = model.predict(X_test)\nprint(y_pred_adaboost)","00d1170f":"from sklearn.metrics import accuracy_score\n\nprint(\"AdaBoost Classifier Model Accuracy:\", accuracy_score(y_test, y_pred_adaboost))","b6d6f7b6":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier(n_estimators=500, learning_rate=0.01, random_state=0)\nmodel = gbc.fit(X_train, y_train)\n","c5999915":"y_pred_xgboost = model.predict(X_test)\nprint(y_pred_xgboost)","9f765bed":"from sklearn.metrics import accuracy_score\n\nprint(\"XGBoost Classifier Model Accuracy:\", accuracy_score(y_test, y_pred_xgboost))","c9b53e42":"acc = pd.DataFrame({\n    \"algorithms\": ['Adaboost', 'Xgboost'],\n    \"accuracy\": [accuracy_score(y_test, y_pred_adaboost),accuracy_score(y_test, y_pred_xgboost)]\n})\nsns.barplot(x='accuracy', y='algorithms', data=acc, palette='rocket')","f83c58f5":"## If YOU lIKE  PLEASE UPVOTE :)","5ce55394":"## XGBoost Classifier","27f237b9":"## AdaBoost Classifier","9ad786b9":"## Comparision between Adaboost and XGboost"}}