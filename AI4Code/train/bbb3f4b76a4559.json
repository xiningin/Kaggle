{"cell_type":{"0b35f4c5":"code","b4b40018":"code","1a99ca29":"code","cb85efe2":"code","c236ff0c":"code","7b60cda5":"code","13838c22":"code","06a49285":"code","7bb861cb":"code","9d767709":"code","bb37b28f":"code","2244a87a":"code","be5f3768":"code","2464c704":"code","55b33f8c":"code","67f81f69":"code","d9441e28":"code","302c68a1":"code","676d91b7":"code","5521c6a7":"code","85f52bb1":"code","540aebeb":"code","881c2261":"code","730dd2f6":"code","95516e86":"code","2fedf5d7":"code","bcefaef7":"markdown","16b6cfb9":"markdown","36d2f23f":"markdown","24f532a6":"markdown","46e1e83b":"markdown","981e463c":"markdown","6be62f9d":"markdown","9573ec59":"markdown","130a63b5":"markdown","f27d6197":"markdown","78bcb96d":"markdown"},"source":{"0b35f4c5":"from logging import getLogger, StreamHandler, DEBUG, INFO\nlogger = getLogger(__name__)\nhandler = StreamHandler()\nhandler.setLevel(INFO)\nlogger.setLevel(INFO)\nlogger.addHandler(handler)\nlogger.propagate = False","b4b40018":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport pandas_profiling as pdp\n\nimport lightgbm as lgb\nimport optuna, os, uuid, pickle\n\nfrom sklearn import datasets\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport scipy.stats\n\nfrom imblearn.over_sampling import SMOTE\n\nimport matplotlib\nimport matplotlib.pyplot as plt #Visulization\nimport seaborn as sns\n% matplotlib inline\nplt.style.use('ggplot') ","1a99ca29":"pdp.ProfileReport(pd.read_csv('..\/input\/train.csv'))","cb85efe2":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\ntest_df['Fare'] = test_df['Fare'].fillna(0)\n\ngenders = {'male': 0, 'female': 1} \ntrain_df['Sex'] = train_df['Sex'].map(genders) \ntest_df['Sex'] = test_df['Sex'].map(genders)\n# to dummy\ntrain_df = pd.get_dummies(train_df, columns=['Pclass', 'Embarked']) \ntest_df = pd.get_dummies(test_df, columns = ['Pclass', 'Embarked'])\n# remove unuse cols\ntrain_df.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1, inplace=True) \ntest_df.drop(['PassengerId', 'Name', 'Cabin', 'Ticket'], axis=1, inplace=True)\n\ntrain_df['Age'] = train_df['Age'].fillna(200)\ntest_df['Age'] = test_df['Age'].fillna(200)\n\ntrain_df.sample(5)","c236ff0c":"train_df.shape[1]","7b60cda5":"pca_n_components = train_df.shape[1] - 1\npca_all = PCA(n_components=pca_n_components)\nX_train_pca_all = pca_all.fit_transform(train_df.drop('Survived', axis=1))","13838c22":"plt.bar(range(1, pca_n_components+1), pca_all.explained_variance_ratio_, alpha=0.5, align='center')\nplt.step(range(1, pca_n_components+1), np.cumsum(pca_all.explained_variance_ratio_), where='mid')\nplt.ylabel('Explained variance ratio')\nplt.xlabel('Principal components')\n\nplt.show()","06a49285":"pca_n_components = 2\npca = PCA(n_components=pca_n_components)\n\nX_train = pca.fit_transform(train_df.drop('Survived', axis=1))\nX_test = pca.fit_transform(test_df)\n\ny_train = np.array(train_df['Survived'])","7bb861cb":"# you can see result of pca like this way\n# PCA_cols = ['PCA_' + str(i) for i in range(pca_n_components)]\n# train_df_pca = pd.DataFrame(X_train, columns=PCA_cols)\n# test_df_pca = pd.DataFrame(X_test, columns=PCA_cols)\n\n# train_df_pca['Survived'] = train_df['Survived']\n# train_df_pca.sample(5)","9d767709":"sm = SMOTE(random_state=84, k_neighbors=20)\nX_res, y_res = sm.fit_sample(X_train, y_train)\n\nprint(X_res.shape)\nprint(y_res.shape)","bb37b28f":"def shuffle_samples(X, y):\n    zipped = list(zip(X, y))\n    np.random.shuffle(zipped)\n    X_result, y_result = zip(*zipped)\n    return np.asarray(X_result), np.asarray(y_result)\n\nX_res, y_res = shuffle_samples(X_res, y_res)","2244a87a":"import sys\n\nprint(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\nprint(\" ------------------------------------ \")\nfor var_name in dir():\n    if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000:\n        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))","be5f3768":"TRIAL_TIMES = 1000\nNUM_BOOST_ROUND = 1000\nEARLY_STOP_COUNTS = 10\n\ndef train_optuna(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=84)\n    \n    def objectives(trial):\n        # set UUID\n        trial_uuid = str(uuid.uuid4())\n        trial.set_user_attr(\"uuid\", trial_uuid)\n\n        # if you want to tune multi-class learning, you have to \n        # change objective to \"multiclass\", metric to {'multi_logloss', 'multi_error'} and \n        # add 'num_class': \"your_class_count\"\n        params = {\n            'boosting_type': trial.suggest_categorical('boosting', ['gbdt', 'goss']),#, 'dart']),\n            'objective': 'binary',\n            'metric': {'binary', 'binary_error', 'auc'},\n            'num_leaves': trial.suggest_int(\"num_leaves\", 10, 1000),\n            'learning_rate': trial.suggest_loguniform(\"learning_rate\", 1e-4, 1),\n            'feature_fraction': trial.suggest_uniform(\"feature_fraction\", 0.0, 1.0),\n#             'device' : 'gpu',\n            'verbose' : 0\n        }\n        if params['boosting_type'] == 'dart':\n            params['drop_rate'] = trial.suggest_loguniform('drop_rate', 1e-8, 1.0)\n            params['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n        if params['boosting_type'] == 'goss':\n            params['top_rate'] = trial.suggest_uniform('top_rate', 0.0, 1.0)\n            params['other_rate'] = trial.suggest_uniform('other_rate', 0.0, 1.0 - params['top_rate'])\n\n        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"binary_logloss\")\n        gbm = lgb.train(params, lgb.Dataset(X_train, y_train), num_boost_round=NUM_BOOST_ROUND,\n                        valid_sets=lgb.Dataset(X_test, y_test), callbacks=[pruning_callback],\n                        early_stopping_rounds=EARLY_STOP_COUNTS\n                       )\n\n        # check train\/eval error\n        y_pred_train = np.rint(gbm.predict(X_train))\n        y_pred_test = np.rint(gbm.predict(X_test))\n        error_train = 1.0 - accuracy_score(y_train, y_pred_train)\n        error_test = 1.0 - accuracy_score(y_test, y_pred_test)\n\n        # set error rate\n        trial.set_user_attr(\"train_error\", error_train)\n        trial.set_user_attr(\"test_error\", error_test)\n\n        # save model\n        if not os.path.exists(\"lgb_output\"):\n            os.mkdir(\"lgb_output\")\n        with open(\"lgb_output\/\"+f\"{trial_uuid}.pkl\", \"wb\") as fp:\n            pickle.dump(gbm, fp)\n\n        return error_test\n\n    study = optuna.create_study()\n    study.optimize(objectives, n_trials=TRIAL_TIMES)\n\n    print(study.best_params)\n    print(study.best_value)\n\n    print(study.best_trial.user_attrs)\n\n    df = study.trials_dataframe()\n    df.to_csv(\"optuna_lgb.csv\")\n    \n    return study.best_trial.user_attrs\n\noptuna.logging.disable_default_handler()\nresult_dict = train_optuna(X_res, y_res)","2464c704":"best_uuid = result_dict['uuid']\nprint(best_uuid)\n\ndef load_model(X, y):\n    with open('lgb_output\/' + str(best_uuid) + '.pkl', 'rb') as fp:\n        gbm = pickle.load(fp)\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=84)\n    y_pred = np.rint(gbm.predict(X_test))\n    print(\"Test Accuracy\")\n    print(accuracy_score(y_test, y_pred))\n    return gbm\n    \ngbm = load_model(X_train, y_train)\ny_pred = np.rint(gbm.predict(X_test))\noutput_df = pd.DataFrame(y_pred, columns=['Survived']).astype('int')\noutput_df['PassengerId'] = pd.read_csv('..\/input\/test.csv')['PassengerId']\noutput_df = output_df.loc[:,['PassengerId', 'Survived']]\noutput_df.to_csv('submit.csv', header=True, index=False)","55b33f8c":"plt.scatter(X_train[:,0], X_train[:,1])\nplt.show()","67f81f69":"plt.scatter(X_test[:,0], X_test[:,1])\nplt.show()","d9441e28":"X_train_resize = X_train\nX_train_resize[:,0] = X_train_resize[:,0] \/ max(abs(X_train_resize[:,0]))\nX_train_resize[:,1] = X_train_resize[:,1] \/ max(abs(X_train_resize[:,1]))\n\nX_test_resize = X_test\nX_test_resize[:,0] = X_test_resize[:,0] \/ max(abs(X_test_resize[:,0]))\nX_test_resize[:,1] = X_test_resize[:,1] \/ max(abs(X_test_resize[:,1]))","302c68a1":"from sklearn.cluster import KMeans\nn_clusters = 6\ncmap = plt.get_cmap(\"tab10\")\nkmeans_model_train = KMeans(n_clusters=n_clusters, random_state=84).fit(X_train_resize)\nkmeans_model_test = KMeans(n_clusters=n_clusters, random_state=84).fit(X_test_resize)\n\nshape_dict = {0:'x', 1:'+'}\n# plt.figure()\nplt.subplot(1, 2, 1)\nfor (i, label) in enumerate(tqdm(kmeans_model_train.labels_)):\n    plt.scatter(X_train_resize[i, 0], X_train_resize[i, 1], c=cmap(label), marker=shape_dict[y_train[i]])\n\nplt.subplot(1, 2, 2)\nfor (i, label) in enumerate(tqdm(kmeans_model_test.labels_)):\n    plt.scatter(X_test_resize[i, 0], X_test_resize[i, 1], c=cmap(label))\n    \nplt.show()","676d91b7":"cols = ['PCA_' + str(i) for i in range(pca_n_components)]\ntrain_resize_df = pd.DataFrame(X_train_resize, columns=cols)\ntrain_resize_df['KMEANS_ID'] = kmeans_model_train.labels_\ntrain_resize_df.sample(5)","5521c6a7":"id_df_train = pd.DataFrame(train_resize_df['KMEANS_ID'].value_counts())\nid_df_train = id_df_train.reset_index()\nid_df_train.columns = ['KMEANS_ID', 'count']\nid_df_train","85f52bb1":"from imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import roc_auc_score\n\ndef imbalanced_data_split(X, y, test_size=0.1):\n    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=0)\n    for train_index, test_index in sss.split(X, y.tolist()):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        return X_train, X_test, y_train, y_test\n\ndef gbm_train(X_train, X_eval, y_train, y_eval, gbm_params):\n    lgb_train = lgb.Dataset(X_train, y_train)\n    lgb_eval = lgb.Dataset(X_eval, y_eval, reference=lgb_train)\n    model = lgb.train(gbm_params, lgb_train, num_boost_round=NUM_BOOST_ROUND,\n                      valid_sets=lgb_eval, early_stopping_rounds=20\n                     )\n    return model\n    \ndef bagging(seed, X_df, y, gbm_params):\n    sampler = RandomUnderSampler(random_state=seed, replacement=True)\n    X_resampled, y_resampled = sampler.fit_resample(X_df, y)\n    X_train, X_eval, y_train, y_eval = imbalanced_data_split(X_resampled, y_resampled, test_size=0.1)\n    logger.debug('X_train.shape:' + str(X_train.shape))\n    logger.debug('X_train:' + str(X_train))\n    logger.debug('y_train.shape:' + str(y_train.shape))\n    logger.debug('y_train:' + str(y_train))\n    logger.debug('X_eval.shape:' + str(X_eval.shape))\n    logger.debug('X_eval:' + str(X_eval))\n    logger.debug('y_eval.shape:' + str(y_eval.shape))\n    logger.debug('y_eval:' + str(y_eval))\n    \n    model_bagging = gbm_train(X_train, X_eval, y_train, y_eval, gbm_params)\n    return model_bagging","540aebeb":"gbm_params = gbm.params\nmodels = []\nfor i in tqdm(range(10)):\n    models.append(bagging(i, train_resize_df, y_train, gbm_params))","881c2261":"y_preds = []\n\nfor model in models:\n    y_preds.append(model.predict(X_test, num_iteration=model.best_iteration))\n\ny_preds_bagging = sum(y_preds)\/len(y_preds)\n\nmy_answer = np.rint(y_preds_bagging)\nmy_answer_df = pd.DataFrame(my_answer, columns=['Survived']).astype('int')\nmy_answer_df['PassengerId'] = pd.read_csv('..\/input\/test.csv')['PassengerId']\nmy_answer_df = output_df.loc[:,['PassengerId', 'Survived']]\nmy_answer_df.to_csv('submit_bagging.csv', header=True, index=False)","730dd2f6":"my_answer_df.sample(15)","95516e86":"# doubt PCA\nmodels = []\nfor i in tqdm(range(10)):\n    models.append(bagging(i, train_df, y_train, gbm_params))\n\ny_preds = []\n\nfor model in models:\n    y_preds.append(model.predict(test_df, num_iteration=model.best_iteration))\n\ny_preds_bagging = sum(y_preds)\/len(y_preds)\n\nmy_answer = np.rint(y_preds_bagging)\nmy_answer_df = pd.DataFrame(my_answer, columns=['Survived']).astype('int')\nmy_answer_df['PassengerId'] = pd.read_csv('..\/input\/test.csv')['PassengerId']\nmy_answer_df = output_df.loc[:,['PassengerId', 'Survived']]\nmy_answer_df.to_csv('submit_bagging_noPCA.csv', header=True, index=False)","2fedf5d7":"logger.debug(y_preds)\nlogger.debug(y_preds_bagging)","bcefaef7":"### SMOTE\nSMOTE give us easily over\/down sampling imblance dataset. In this kernel, I chose oversampling smaller label. If your target is not binaly_classification, you can use this cell without changes.  \nBut you have to change k_neighbors to fit your data. This sets how many neighbors data SMOTE chose.  \ndetails : https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/generated\/imblearn.over_sampling.SMOTE.html\n\nAnd unfotunately, downsampling and bagging may be better approach...  \nhttps:\/\/www.semanticscholar.org\/paper\/Class-Imbalance%2C-Redux-Wallace-Small\/a8ef5a810099178b70d1490a4e6fc4426b642cde","16b6cfb9":"### Downsampling and Bagging","36d2f23f":"### PCA to drop dims\nAs you can see, This dataset(droped some cols) has just 10 dims. But usually ML problem has a lot of features and this make ML difficult. So I some times use PCA to get features has more info less cols.  \nAt first, PCA with all cols (of course without \"Answer col\"), then check explained variance ratio like this.","24f532a6":"Oh... In this case, we need only 2 features to explane 9 original cols. So let's take 2 cols like bellow.   \n(Usually only few cols can't explane all of origins. We shoud consider balance of Explained variance ratio and feature dims. For example, \"take 32 cols to explane 80% of origins\".)","46e1e83b":"### KMEANS\nAs you can see, train\/test dataset distribution is not so far and distributed not evenly. So let's try clustering methods to split train\/eval data keep distribution.  \nThe bellow cell show k_means clustering. You can modify \"n_clusters\" to decide cluster counts.","981e463c":"### Preprocess : use only int or float\nPCA can't handle non numeric value and NaN. This is simple way to preprocess. If you want to get high score, you have to this process seriously.","6be62f9d":"This is not so bad... But not good.  \nLet's see data.","9573ec59":"### Optuna : tuning hyperparameters\nThe next cell, recode uuid of every trial of optuna. You can change range of hyperparameters to improve output. This is not suit this dataset.  \nAnd at first, you should set small number at NUM_BOOST_ROUND. Titanic is small dataset (and also we have only 2 dims) so it doesn't take long time. But in other dataset, I recommend to run small NUM_BOOST_ROUND and narrowing the parameter width sometimes. And then set NUM_BOOST_ROUND what you want.\n\nAnd this cell print a lot of things...","130a63b5":"By the way, fearture engineering needs a lot of variables (and RAMs). The next cell show variables with memory usage. If you find needless huge variable(s), you can drop it to exec  \ndel var","f27d6197":"### Very simple EDA\nTitanic dataset is quite famous and there are a lot of great EDA. So I don't spend time to EDA. Just use pandas-profiling.","78bcb96d":"# LightGBM_with_Optuna\nThis notebook show you how to use lightGBM and how to tuning with optuna.  \nThis is my first public kernel and I'm a beginner of ML (and also English...). So if you feel \"I don't understand what this note say\" please don't hesitate to comments and questions. \n  \n  \nThe highlight of this kernel is :  \nUsing optuna to tuning hyperparameter : Hyperparameter tuning is always bother but optuna automatically find them.  \nUsing PCA to drop feature dim : The titanic dataset is not learge and doesn't have too many cols to learn but in ML this is a rare case. This kernel introduce how to drop dims with PCA.  \nUsing SMOTE to oversampling : Survived label is imblance and sometimes imbalance dataset makes difficult to predict. So I show the way to use SMOTE the library to preprocess imblanced data. (Maybe this not suit titanic dataset...)"}}