{"cell_type":{"82988174":"code","2af1886d":"code","86cc37ee":"code","dc70a23c":"code","7c5e4e78":"code","a62ec9af":"code","809a288e":"code","a589e925":"code","1e74e1a2":"code","092b422f":"code","ce8eaf88":"code","76052a3f":"code","098b2310":"code","2199ec3c":"code","83d11bb8":"code","b6054b47":"code","d7683e97":"code","63a4e6c5":"code","de5a3baf":"code","c7110aec":"code","e0130290":"code","6caf72da":"code","532e099e":"code","cd966f08":"code","6ec81d7b":"code","8bce0d01":"code","c0f0899f":"code","d049e924":"code","d1a0ccf7":"code","64d4da88":"code","39b93db8":"code","01e5017c":"code","c6d739b5":"code","f6f2ae51":"code","8a76b18e":"code","615521ff":"code","e9fd68ce":"code","2fff3efa":"code","19516daa":"code","a83485bc":"code","a4e089df":"code","2db48ed4":"code","9a9098d1":"markdown","c7a97d36":"markdown","fe2e73db":"markdown","765bfbe2":"markdown","a2fb1e04":"markdown","b5a0221c":"markdown","4c082b7b":"markdown","074b7d02":"markdown","fedcc739":"markdown","a6a82117":"markdown","51767835":"markdown","9f03dc71":"markdown","4823621e":"markdown","dc357bd4":"markdown","fc16b60e":"markdown","e137d19b":"markdown","2e77f0d6":"markdown","1ece00ff":"markdown","82e654c1":"markdown","828ee714":"markdown","c9d24f52":"markdown","12044ffa":"markdown","65b0432d":"markdown"},"source":{"82988174":"#Importing required libraries\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost as xgb\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\n","2af1886d":"df = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndf.head()","86cc37ee":"df.shape","dc70a23c":"df.info()","7c5e4e78":"(df.isnull().sum()\/len(df))*100","a62ec9af":"#Function to impute missing values in bmi column based on the age\n\nbmi_less_than_age_15 = np.mean(df[df['age']<=15]['bmi'])\nbmi_age_15_to_50 = np.mean(df[(df['age']>15) & (df['age']<=50)]['bmi'])\nbmi_age_greater_50 = np.mean(df[df['age']>50]['bmi'])\n\ndef bmi_imputation(data):\n    for index,row in data.iterrows():\n        if math.isnan(row['bmi']):\n            if row['age'] <=15:\n                data.loc[index,'bmi'] = bmi_less_than_age_15\n            elif (row['age'] >15) & (row['age']<=50):\n                data.loc[index,'bmi'] = bmi_age_15_to_50\n            elif row['age'] >50:\n                data.loc[index,'bmi'] = bmi_age_greater_50\n    return data","809a288e":"df1 = bmi_imputation(df)\ndf1.isnull().sum()","a589e925":"df1.describe()","1e74e1a2":"sns.countplot(x=\"stroke\",data=df1,hue='gender')","092b422f":"ax=sns.countplot(x='smoking_status',data=df1[df1['stroke']==1])\nplt.title(\"Smoking status of persons affected by Stroke\")\ntotal_1 =float(len(df1[df1['stroke']==1]))\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total_1)\n    x = p.get_x() + p.get_width()\n    y = p.get_height()\n    ax.annotate(percentage, (x, y), ha='right')\nplt.show()","ce8eaf88":"# sns.displot(data=df1, x=\"age\", col=\"stroke\", kind=\"kde\")\nsns.distplot(df1[df1['stroke']==1]['age'],color='red')\nplt.title(\"Distribution of age of people affected by stroke\")","76052a3f":"work_type = df1[df1['stroke'] == 1]['work_type']\nvalues = work_type.value_counts()\nlabels = values.keys()\nbar,ax = plt.subplots(figsize=(7,7))\nplt.pie(x = values, labels = labels , autopct=\"%.2f%%\",pctdistance=0.8)\nplt.title('Work type of people affected by Stroke', fontsize=20)","098b2310":"sns.distplot(df1[df1['stroke']==1]['bmi'],color='purple')\nplt.title(\"Distribution of bmi of people affected by stroke\")","2199ec3c":"sns.boxplot(x=\"stroke\",y=\"avg_glucose_level\",data=df1)\nplt.title(\"Average glucose level\")","83d11bb8":"ax=sns.countplot(x='heart_disease',data=df1[df1['stroke']==1])\nplt.title(\"Heart disease of persons affected by Stroke\")\ntotal_1 =float(len(df1[df1['stroke']==1]))\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total_1)\n    x = p.get_x() + p.get_width()\n    y = p.get_height()\n    ax.annotate(percentage, (x, y), ha='right')\nplt.show()","b6054b47":"ax=sns.countplot(x='hypertension',data=df1[df1['stroke']==1])\nplt.title(\"Hyper tension of persons affected by Stroke\")\ntotal_1 =float(len(df1[df1['stroke']==1]))\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total_1)\n    x = p.get_x() + p.get_width()\n    y = p.get_height()\n    ax.annotate(percentage, (x, y), ha='right')\nplt.show()\n# df1.head()","d7683e97":"ax=sns.countplot(x='Residence_type',data=df1[df1['stroke']==1])\nplt.title(\"Hyper tension of persons affected by Stroke\")\ntotal_1 =float(len(df1[df1['stroke']==1]))\nfor p in ax.patches:\n    percentage = '{:.1f}%'.format(100 * p.get_height()\/total_1)\n    x = p.get_x() + p.get_width()\n    y = p.get_height()\n    ax.annotate(percentage, (x, y), ha='right')\nplt.show()","63a4e6c5":"corr = df1.corr()\ncorr.style.background_gradient(cmap='coolwarm')","de5a3baf":"#Dropping id column because of high cardinality\ndf1.drop(['id'],inplace=True,axis=1)","c7110aec":"df2=pd.get_dummies(df1,columns=['gender','ever_married','work_type','Residence_type','smoking_status'],drop_first=True)\ndf2.head()","e0130290":"#Standardization of variables\nscaled_data = df2.copy()\ncol_names=['age','avg_glucose_level','bmi']\nfeatures = scaled_data[col_names]\nscaler = StandardScaler().fit(features)\nfeatures = scaler.transform(features)\nscaled_data[col_names] = features\nscaled_data.head()","6caf72da":"#Data is imbalanced\nscaled_data['stroke'].value_counts()","532e099e":"X = scaled_data.drop(['stroke'],axis=1)\ny = scaled_data['stroke']","cd966f08":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=42)","6ec81d7b":"\nsm = SMOTE(random_state=42)\nX_train_smote,y_train_smote = sm.fit_resample(X_train,y_train)","8bce0d01":"y_train_smote.value_counts()","c0f0899f":"models = {\n    'SVM':{'model':SVC(gamma='auto',C=5,kernel='rbf'),'params': {'C': [1,5,10]}},\n    'xgboost':{'model':xgb.XGBClassifier(),'params': {'max_depth':[4,6,8],'gamma': [0.5, 1, 2, 5]}},\n     'Logistic regression':{'model':LogisticRegression(),'params':{}},\n     'DecisionTree':{'model':DecisionTreeClassifier(),'params':{'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8]}}\n              }\n","d049e924":"scores = []\n\nfor model_name, mp in models.items():\n    clf =  GridSearchCV(mp['model'],mp['params'] ,cv= 2, return_train_score=False)\n    clf.fit(X_train_smote, y_train_smote)\n    scores.append({\n        'model': model_name,\n        'best_score': clf.best_score_,\n        'best_params': clf.best_params_\n    })\n    \ndf_model = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf_model","d1a0ccf7":"model=xgb.XGBClassifier(gamma= 0.5,max_depth=8)\nxgb_model = model.fit(X_train_smote, y_train_smote)\npred = xgb_model.predict(X_test)","64d4da88":"print(classification_report(pred,y_test))","39b93db8":"model=SVC(gamma='auto',C=10,kernel='rbf')\nsvc_model = model.fit(X_train_smote, y_train_smote)\npred_svc = svc_model.predict(X_test)","01e5017c":"print(classification_report(pred_svc,y_test))","c6d739b5":"model=DecisionTreeClassifier(criterion= 'entropy', max_depth= 8)\ndt_model = model.fit(X_train_smote, y_train_smote)\npred_dt = dt_model.predict(X_test)","f6f2ae51":"print(classification_report(pred_dt,y_test))","8a76b18e":"model=LogisticRegression()\nlog_model = model.fit(X_train_smote, y_train_smote)\npred_log = log_model.predict(X_test)\n","615521ff":"print(classification_report(pred_log,y_test))","e9fd68ce":"X_train_smote.shape","2fff3efa":"ann_model = Sequential()\nann_model.add(Dense(14,input_dim=16,activation='relu'))\nann_model.add(Dense(8,activation='relu'))\nann_model.add(Dense(1,activation='sigmoid'))","19516daa":"ann_model.compile(loss=\"binary_crossentropy\", optimizer='SGD',metrics=['accuracy'])","a83485bc":"ann_model.fit(X_train_smote, y_train_smote, epochs=100, batch_size=10)","a4e089df":"ann_predictions = ann_model.predict_classes(X_test)","2db48ed4":"print(classification_report(ann_predictions,y_test))","9a9098d1":"**Observation**\n* 73% of the people who are affected by Stroke are not suffering from Hypertension. So, Even Hypertension might not be a significant reason for stroke","c7a97d36":"# Data Profiling","fe2e73db":"**Observation:**\n* Around 54% of the people affected by Stroke are from Urban area. A possible reason could be people in urban areas might experience health issues due to pollution and other factors such as eating habits, etc","765bfbe2":"**Observation**\n* 59.84% of the people who are affected by stroke belongs to private work type. Very less percent of around 13% of the people belongs to Govt Job. So, Based on the analysis we could say that the candiates working in private jobs might experience high stress or pressure.","a2fb1e04":"Obervation:\n* ","b5a0221c":"# Stroke Prediction and analysis","4c082b7b":"**Observation:**\n* 81 percent of the people are who are affected by stroke dont have a heart disease. Heart disease might not be a significant reason for stroke","074b7d02":"# Model Building and GridSearchCV","fedcc739":"# **Feature Engineering**","a6a82117":"#  **Exploratory Data Analysis**","51767835":"**Observation:**\n* 3.9% of values are missing in bmi column. Since it is less than 5%. We can impute those values based on the age factor","9f03dc71":"Observation:\n* Around 45% of the people who are affected by strokes, they have either formaly smoked or smokes. So, Smoking might also be a factor which could cause strokes","4823621e":"**Observation:**\n* Most of them who got stroke are older people aged above 60. Age factor could be a potential threat for stroke. Older people should monitor their condition with atmost care to prevent stroke.\n* Younger generation might be less susceptible to stroke\n","dc357bd4":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRXPPX4JDPfzzwDVuommp6FqgA1WgZjtTuh_gKxG6YBt7j68kOXsgcZGBgXlzLG9dvIimg&usqp=CAU)","fc16b60e":"# Deep learning - ANN Model","e137d19b":"**Observation:**\n* The accuracy of ANN model model is 83%. However, it has reasonably good score for class 1 labels when compared to xgboost","2e77f0d6":"**Observation**\n* Age is almost slightly positive correlated with other features such as hyper tension, heart disease, glucose level, bmi and even stroke. So, As the age increases, the health related issues also increases in general. Here, Age could be a good indicator for predicting whether a person will be affected by Stroke or not","1ece00ff":"**Observation**\n* We could notice that the dataset is imbalanced\n* Among those who have experienced stroke, females are higher","82e654c1":"**Observation**\n* Xgboost has a higher accuracy of 93%. But precision and recall value for class 1 is very less. In this usecase predicting correctly the positive class (1) is important\n* SVM, Decicion Tree, Logistic regression has better precision and recall values for class 1 labels","828ee714":"# SMOTE - Handling imbalances in data","c9d24f52":"Let's focus on the people who are affected by Stroke !","12044ffa":"**Observation**\n* Average BMI value of people affected by stroke is 30. BMI value of greater than 25 is considered to be obese. On a average we could say that people who are affected by stroke are obese. From the graph we could notice that few have bmi of greater than 45, they are considered to be morbidly obese","65b0432d":"**Observation**\n* People who are affected by Stroke have higher glucose level of above 100 on average. A fasting blood sugar level of 100-125 is considered to be prediabetic."}}