{"cell_type":{"97dcb0cd":"code","5c85f6f0":"code","1fe3a6ff":"code","2198fa06":"code","18ec0a8d":"code","3304d941":"code","eb155dd7":"code","e4a5bd4d":"code","8cda98df":"code","89f41872":"code","1bd841d7":"code","2028a821":"code","b468350c":"code","9c1874d4":"code","1d0f576b":"code","7bb44a3d":"code","77228784":"code","3aefe67c":"code","44d4a744":"code","3a0b1cab":"code","0b2007bc":"code","3b073c4e":"code","69e45f8e":"code","ce7d0b64":"code","d5cc0e82":"code","af0e3a9d":"code","dd324593":"code","c5ed5a75":"code","9acd5f01":"code","230565b7":"code","364e3ca8":"code","5a5a2804":"code","3a7836f2":"code","75d58ebe":"code","248a65e1":"code","36730599":"code","98e99d1c":"code","6e6bc4e8":"code","5d5089b0":"code","4e46f7c8":"code","03e1c7a8":"markdown","a362fdac":"markdown","d03c81e4":"markdown"},"source":{"97dcb0cd":"import numpy as np \nimport pandas as pd \nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","5c85f6f0":"train = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\ntest = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","1fe3a6ff":"train.head()","2198fa06":"train.shape","18ec0a8d":"print((train.target == 1).sum()) # Disaster\nprint((train.target == 0).sum()) # No Disaster","3304d941":"string.punctuation","eb155dd7":"def remove_URL(text):\n    url = re.compile(r\"https?:\/\/\\S+|www\\.\\S+\")\n    return url.sub(r\"\", text)\n\ndef remove_punct(text):\n    translator = str.maketrans(\"\", \"\", string.punctuation)\n    return text.translate(translator)","e4a5bd4d":"#regex pattern to remove links\npattern = re.compile(r\"https?:\/\/(\\S+|www)\\.\\S+\")\n#for train\nfor t in train.text:\n    matches = pattern.findall(t)\n    for match in matches:\n        print(t)\n        print('After Transformation:')\n        print(pattern.sub(r\"\", t))\n    if len(matches) > 0:\n        break","8cda98df":"#for test:\nfor t in test.text:\n    matches = pattern.findall(t)\n    for match in matches:\n        print(t)\n        print('After Transformation:')\n        print(pattern.sub(r\"\", t))\n    if len(matches) > 0:\n        break","89f41872":"#preprocess data frames:\n#train\ntrain[\"text\"] = train.text.map(remove_URL) \ntrain[\"text\"] = train.text.map(remove_punct)\n#test\ntest[\"text\"] = test.text.map(remove_URL) \ntest[\"text\"] = test.text.map(remove_punct)","1bd841d7":"# remove stopwords\nnltk.download('stopwords')\n\nstop = set(stopwords.words(\"english\"))\n\ndef remove_stopwords(text):\n    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n    return \" \".join(filtered_words)","2028a821":"stop","b468350c":"#train\ntrain[\"text\"] = train.text.map(remove_stopwords)\n#test\ntest[\"text\"] = test.text.map(remove_stopwords)","9c1874d4":"#Check\ntrain.text","1d0f576b":"# Count unique words\ndef counter_word(text_col):\n    count = Counter()\n    for text in text_col.values:\n        for word in text.split():\n            count[word] += 1\n    return count\n\n\ncounter = counter_word(train.text)","7bb44a3d":"len(counter)","77228784":"# counter","3aefe67c":"counter.most_common(5)","44d4a744":"num_unique_words = len(counter)\nnum_unique_words","3a0b1cab":"# Split dataset into training and validation set\nX = train.text\ny = train.target\ntrain_sentences, val_sentences , train_labels, val_labels = train_test_split(X, y, test_size=0.2)","0b2007bc":"#train\/val\ntrain_sentences = train_sentences.to_numpy()\ntrain_labels = train_labels.to_numpy()\nval_sentences = val_sentences.to_numpy()\nval_labels = val_labels.to_numpy()","3b073c4e":"#test\ntest_sentences = test.text.to_numpy()","69e45f8e":"train_sentences.shape, val_sentences.shape","ce7d0b64":"# Tokenize\n# vectorize a text corpus by turning each text into a sequence of integers\n\ntokenizer = Tokenizer(num_words=num_unique_words)\ntokenizer.fit_on_texts(train_sentences) # fit only to training","d5cc0e82":"# Now each word has unique index\nword_index = tokenizer.word_index\nword_index","af0e3a9d":"#apply on train, validation, and test sentences\n\ntrain_sequences = tokenizer.texts_to_sequences(train_sentences)\nval_sequences = tokenizer.texts_to_sequences(val_sentences)\ntest_sequences = tokenizer.texts_to_sequences(test_sentences)","dd324593":"#Check\nprint(train_sentences[10:15])\nprint(train_sequences[10:15])","c5ed5a75":"# Pad the sequences to have the same length\nmax_length = 15 #arbitrary number\n\ntrain_padded = pad_sequences(train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\") #post-> 0\nval_padded = pad_sequences(val_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\ntest_padded = pad_sequences(test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")","9acd5f01":"#Check\ntrain_padded.shape, val_padded.shape","230565b7":"#Check\ntrain_padded[10]","364e3ca8":"#Check\nprint(train_sentences[10])\nprint(train_sequences[10])\nprint(train_padded[10])","5a5a2804":"# flip (key, value)\nreverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])","3a7836f2":"#Check\nreverse_word_index","75d58ebe":"#decoding\ndef decode(sequence):\n    return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])","248a65e1":"decoded_text = decode(train_sequences[10])\n#Check\nprint(train_sequences[10])\nprint(decoded_text)","36730599":"# Create LSTM model\n\n# Embedding: Turns positive integers (indexes) into dense vectors of fixed size.\n\nmodel = keras.models.Sequential()\nmodel.add(layers.Embedding(num_unique_words, 100, input_length=max_length))\n\nmodel.add(layers.LSTM(32, dropout=0.25))\nmodel.add(layers.Dense(1, activation=\"sigmoid\"))\n\nmodel.summary()","98e99d1c":"loss = keras.losses.BinaryCrossentropy(from_logits=False)\noptim = keras.optimizers.Adam(learning_rate=0.001)\nmetrics = [\"accuracy\"]\n\nmodel.compile(loss=loss, optimizer=optim, metrics=metrics)","6e6bc4e8":"model.fit(train_padded, train_labels, epochs=25, validation_data=(val_padded, val_labels), verbose=2)","5d5089b0":"predictions = model.predict(test_padded)\npredictions = [1 if p > 0.5 else 0 for p in predictions]","4e46f7c8":"submission = pd.DataFrame({'id':test['id'].values.tolist(),'target':predictions})\nsubmission.to_csv('submission.csv',index=False)","03e1c7a8":"# 1- Imports","a362fdac":"# 2- Preprocessing","d03c81e4":"# 3- Modeling"}}