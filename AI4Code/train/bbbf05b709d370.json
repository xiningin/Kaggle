{"cell_type":{"726b376b":"code","fc616d74":"code","4020a3f8":"code","af25703e":"code","2a85b035":"code","dd3b1a4f":"code","2e74375b":"code","06f40c7a":"code","f7c98102":"code","9d91dd1a":"code","53043510":"code","edb2e6cb":"code","d08d6f9b":"code","d72562f6":"code","aa31cf05":"code","57d89ade":"code","e553287d":"code","22b1ff67":"code","483bea9d":"code","47bba2ed":"code","ea2530e8":"code","509dc700":"code","2ae9c1c0":"code","a27986aa":"code","6aeb4702":"code","82fa3e90":"code","584dcba4":"code","f0e5c2e0":"code","28fbcfe6":"code","4a9249ff":"code","168eaee9":"code","d7a0b656":"code","c1943e7b":"code","1a228fb8":"code","e026a1a4":"code","944a29da":"code","e808b8b8":"code","03b3bc35":"markdown","a73cff71":"markdown","af61131c":"markdown","6354a25f":"markdown","691fef75":"markdown","b6fd8045":"markdown","ac2059ad":"markdown","6d9c28e8":"markdown","bfc25b67":"markdown","53ed10aa":"markdown","d0bb4577":"markdown","cf0128e2":"markdown","481c006d":"markdown","7dec60f8":"markdown","b40639d8":"markdown","684fd3f9":"markdown","4163e6d0":"markdown","50bd8c4f":"markdown","072c5608":"markdown","5c6d798b":"markdown","f0758765":"markdown","12b1cd1a":"markdown","160e7be4":"markdown","1c00ea05":"markdown","18d09345":"markdown","ae2d5ae9":"markdown","2d4a303e":"markdown","c4c2177b":"markdown"},"source":{"726b376b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport cv2","fc616d74":"labels = os.listdir(\"..\/input\/drowsiness-dataset\/train\")","4020a3f8":"labels","af25703e":"import matplotlib.pyplot as plt\nplt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/Closed\/_0.jpg\"))","2a85b035":"a = plt.imread(\"..\/input\/drowsiness-dataset\/train\/yawn\/10.jpg\")","dd3b1a4f":"a.shape","2e74375b":"plt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/yawn\/10.jpg\"))","06f40c7a":"def face_for_yawn(direc=\"..\/input\/drowsiness-dataset\/train\", face_cas_path=\"..\/input\/prediction-images\/haarcascade_frontalface_default.xml\"):\n    yaw_no = []\n    IMG_SIZE = 145\n    categories = [\"yawn\", \"no_yawn\"]\n    for category in categories:\n        path_link = os.path.join(direc, category)\n        class_num1 = categories.index(category)\n        print(class_num1)\n        for image in os.listdir(path_link):\n            image_array = cv2.imread(os.path.join(path_link, image), cv2.IMREAD_COLOR)\n            face_cascade = cv2.CascadeClassifier(face_cas_path)\n            faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n            for (x, y, w, h) in faces:\n                img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n                roi_color = img[y:y+h, x:x+w]\n                resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n                yaw_no.append([resized_array, class_num1])\n    return yaw_no\n\n\nyawn_no_yawn = face_for_yawn()","f7c98102":"def get_data(dir_path=\"..\/input\/drowsiness-dataset\/train\/\", face_cas=\"..\/input\/prediction-images\/haarcascade_frontalface_default.xml\", eye_cas=\"..\/input\/prediction-images\/haarcascade.xml\"):\n    labels = ['Closed', 'Open']\n    IMG_SIZE = 145\n    data = []\n    for label in labels:\n        path = os.path.join(dir_path, label)\n        class_num = labels.index(label)\n        class_num +=2\n        print(class_num)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n                resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                data.append([resized_array, class_num])\n            except Exception as e:\n                print(e)\n    return data","9d91dd1a":"data_train = get_data()","53043510":"def append_data():\n#     total_data = []\n    yaw_no = face_for_yawn()\n    data = get_data()\n    yaw_no.extend(data)\n    return np.array(yaw_no)","edb2e6cb":"new_data = append_data()","d08d6f9b":"X = []\ny = []\nfor feature, label in new_data:\n    X.append(feature)\n    y.append(label)","d72562f6":"X = np.array(X)\nX = X.reshape(-1, 145, 145, 3)","aa31cf05":"from sklearn.preprocessing import LabelBinarizer\nlabel_bin = LabelBinarizer()\ny = label_bin.fit_transform(y)","57d89ade":"y = np.array(y)","e553287d":"from sklearn.model_selection import train_test_split\nseed = 42\ntest_size = 0.30\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=test_size)","22b1ff67":"len(X_test)","483bea9d":"# !pip install tensorflow==2.3.1\n# !pip install keras==2.4.3","47bba2ed":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","ea2530e8":"tf.__version__","509dc700":"import keras\nkeras.__version__","2ae9c1c0":"train_generator = ImageDataGenerator(rescale=1\/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)\ntest_generator = ImageDataGenerator(rescale=1\/255)\n\ntrain_generator = train_generator.flow(np.array(X_train), y_train, shuffle=False)\ntest_generator = test_generator.flow(np.array(X_test), y_test, shuffle=False)","a27986aa":"model = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=X_train.shape[1:]))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(128, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(64, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(2, 2))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation=\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n\nmodel.summary()","6aeb4702":"history = model.fit(train_generator, epochs=50, validation_data=test_generator, shuffle=True, validation_steps=len(test_generator))","82fa3e90":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, \"b\", label=\"trainning accuracy\")\nplt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, \"b\", label=\"trainning loss\")\nplt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\nplt.legend()\nplt.show()","584dcba4":"model.save(\"drowiness_new6.h5\")","f0e5c2e0":"model.save(\"drowiness_new6.model\")","28fbcfe6":"prediction = model.predict_classes(X_test)","4a9249ff":"prediction","168eaee9":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]","d7a0b656":"from sklearn.metrics import classification_report\nprint(classification_report(np.argmax(y_test, axis=1), prediction, target_names=labels_new))","c1943e7b":"labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]\nIMG_SIZE = 145\ndef prepare(filepath, face_cas=\"..\/input\/prediction-images\/haarcascade_frontalface_default.xml\"):\n    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n    img_array = img_array \/ 255\n    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n\nmodel = tf.keras.models.load_model(\".\/drowiness_new6.h5\")","1a228fb8":"# prepare(\"..\/input\/drowsiness-dataset\/train\/no_yawn\/1068.jpg\")\nplt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/no_yawn\/1067.jpg\"))\nprediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/no_yawn\/1067.jpg\")])\nnp.argmax(prediction)","e026a1a4":"plt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/Closed\/_101.jpg\"))\nprediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/Closed\/_101.jpg\")])\nnp.argmax(prediction)","944a29da":"plt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/Open\/_104.jpg\"))\nprediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/Open\/_104.jpg\")])\nnp.argmax(prediction)","e808b8b8":"plt.imshow(plt.imread(\"..\/input\/drowsiness-dataset\/train\/yawn\/113.jpg\"))\nprediction = model.predict([prepare(\"..\/input\/drowsiness-dataset\/train\/yawn\/113.jpg\")])\nnp.argmax(prediction)","03b3bc35":"# Not necessary, only use to matching with my pc version","a73cff71":"# new variable to store","af61131c":"# image shape","6354a25f":"# save model","691fef75":"# image array","b6fd8045":"# label array","ac2059ad":"# visualize random 1 image","6d9c28e8":"# Prediction","bfc25b67":"# Prediction \n## 0-yawn, 1-no_yawn, 2-Closed, 3-Open","53ed10aa":"# LabelBinarizer","d0bb4577":"# visualize yawn image. \n# Here background is unnecessary. we need only face image array","cf0128e2":"# labels","481c006d":"# reshape the array","7dec60f8":"# train test split","b40639d8":"# history","684fd3f9":"![fatigued-truck-driver-1.gif](attachment:fatigued-truck-driver-1.gif)\n\n## Driver drowsiness detection is a car safety technology which helps prevent accidents caused by the driver getting drowsy. Various studies have suggested that around 20% of all road accidents are fatigue-related, up to 50% on certain roads.","4163e6d0":"# tensorflow version","50bd8c4f":"# keras version","072c5608":"# for yawn and not_yawn. Take only face","5c6d798b":"# classification report","f0758765":"# predicting function","12b1cd1a":"# import some dependencies","160e7be4":"# length of X_test","1c00ea05":"# extend data and convert array","18d09345":"# Data Augmentation","ae2d5ae9":"# Model","2d4a303e":"# for closed and open eye","c4c2177b":"# separate label and features"}}