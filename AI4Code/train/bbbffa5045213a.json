{"cell_type":{"6a945669":"code","b0f1c819":"code","0a54ca83":"code","398f41cb":"code","8c989aba":"code","9f6b2d86":"code","54dc5bfc":"code","eed79419":"code","ceba2bfb":"markdown","2ea9f59e":"markdown","ff884dc3":"markdown","e5dd4758":"markdown","b38d061a":"markdown"},"source":{"6a945669":"import numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b0f1c819":"import time\nimport torch\nimport random\n\ns = time.time()\n\nseed = int(np.random.randint(0, 1e9))\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Random seed:\", seed)\nprint(\"Device:\", device)\nbasic_cols = ['row_id', 'time_id', 'investment_id', 'target']\nnum_feat = 300 #total of 300 feats from f_0 to f_299\nfeatures = [f'f_{i}' for i in range(num_feat)]\ncols = basic_cols + features","0a54ca83":"torch.__version__ ","398f41cb":"# import pytorch\nfrom IPython.display import clear_output\nimport torch.optim as optim\nimport torch\n\nfrom torch import nn\n\n# import activation functions\n#import Mish.Torch.functional as Func\n\n\n\n\n@torch.jit.script\ndef ALReLU(input):\n    \"\"\"\n    Applies the ALReLU function :\n    alrelu(x) = torch.maximum(torch.abs(alpha*input), input)\n    \"\"\"\n    alpha = 0.01\n    return torch.maximum(torch.abs(alpha*input), input)\n","8c989aba":"class RegressionModel(torch.nn.Module):\n    def __init__(self, in_shape, out_shape, hidden, device='cpu'):\n        super().__init__()\n        self.in_shape = in_shape\n        self.out_shape = out_shape\n        self.hidden = hidden\n        self.device = device\n        self.initialize_weights()\n        \n    def initialize_weights(self):\n        self.w1 = torch.nn.Parameter(torch.randn((self.hidden, self.in_shape), device=self.device, requires_grad=True))\n        self.w2 = torch.nn.Parameter(torch.randn((self.out_shape, self.hidden), device=self.device, requires_grad=True))\n        self.b1 = torch.nn.Parameter(torch.randn(1, device=self.device, requires_grad=True))\n        self.b2 = torch.nn.Parameter(torch.randn(1, device=self.device, requires_grad=True))\n    \n    def forward(self, x):\n        #basic linear computation\n        y_hat = torch.add(torch.mm(self.w1, x.t()), self.b1)\n        #Apply ALReLU\n        y_hat = ALReLU(y_hat)\n        #return regression out\n        return torch.add(torch.mm(self.w2, y_hat), self.b2)\n\nclass PredModel(torch.nn.Module):\n    def __init__(self, in_shape, out_shape, hidden, device='cpu'):\n        super().__init__()\n        self.in_shape = in_shape\n        self.out_shape = out_shape\n        self.hidden = hidden\n        self.device = device\n        # We will be considering a multi-tower construct with varying\n        # sized of hidden nodes\n        # Tower 1\n        self.t1 = RegressionModel(self.in_shape, self.hidden\/\/4, self.hidden, self.device)\n        self.t2 = RegressionModel(self.in_shape, self.hidden\/\/4, self.hidden\/\/2, self.device)\n        self.t3 = RegressionModel(self.in_shape, self.hidden\/\/4, self.hidden\/\/4, self.device)\n        self.out = RegressionModel(self.hidden\/\/4, self.out_shape, self.hidden\/\/4, self.device)\n    \n    def forward(self, x):\n        #get sum of each tower\n        y_hat = torch.add(self.t1(x), torch.add(self.t2(x), self.t3(x)))\n        #get average\n        y_hat = torch.mul(y_hat, 1\/3)\n        y_hat = self.out(y_hat.t())\n        return y_hat","9f6b2d86":"\n\ndef loss(y_predicted, y_target):\n    #RMSE Loss\n    return torch.sqrt(torch.mean((y_predicted - y_target)**2))\n\nmodel = PredModel(num_feat, 1, 64, device)\n\nverbose = 25\nepochs = 1000\nchunks = 900000\ntol = 500\n\nfor q, data in enumerate(pd.read_csv(\n    \"..\/input\/ubiquant-market-prediction\/train.csv\", usecols=cols, chunksize=chunks)):\n    #Initialize weights and biases\n    optimizer = optim.Adam(model.parameters(), lr=0.01\/(2**q))\n    \n    clear_output(wait=True)\n    print(f\"Currently training on {q*chunks} to {(q+1)*chunks}:\")\n    min_loss = np.inf\n    cnt = 0\n    \n    x_dataset = torch.tensor(data[features].values, dtype=torch.float).to(device)\n    y_dataset = torch.tensor(data['target'].values, dtype=torch.float).to(device)\n    \n    # Main optimization loop\n    for t in range(1, epochs+1):\n        # Set the gradients to 0.\n        optimizer.zero_grad()\n        # Compute the current predicted y's from x_dataset\n        y_predicted = model(x_dataset)\n        # See how far off the prediction is\n        current_loss = loss(y_predicted, y_dataset)\n        # Compute the gradient of the loss\n        current_loss.backward()\n        # Update model W and b accordingly.\n        optimizer.step()\n        \n        #Check for early stopping\n        if current_loss >= min_loss:\n            cnt += 1\n            if cnt >= tol:\n                print(\"Early stopping!\")\n                break\n        else:\n            min_loss = current_loss\n            cnt = 0\n\n        if t%verbose==0:\n            print(f\"epoch = {t:4}\/{epochs}, loss = {current_loss:.8f}, min_loss = {min_loss:.8f}, count = {cnt}\")\n    \n    print(f\"Total time spent: {time.time()-s:.4f} seconds\")","54dc5bfc":"import ubiquant\nenv = ubiquant.make_env()\niter_test = env.iter_test()","eed79419":"for (test_df, sample_prediction_df) in iter_test:\n    test_x = torch.tensor(test_df[features].values, dtype=torch.float).to(device)\n    pred = model(test_x)\n    sample_prediction_df['target'] = pred.detach().cpu().numpy().T\n    env.predict(sample_prediction_df) \n    display(sample_prediction_df)","ceba2bfb":"# Begin","2ea9f59e":"This notebook is just a fork of https:\/\/www.kaggle.com\/seraphwedd18\/pytorch-regression-model-train-by-chunks by using custom activation function ALReLU ( https:\/\/arxiv.org\/abs\/2012.07564 ) instead of ReLU","ff884dc3":"# Model creation and Training","e5dd4758":"# Prediction","b38d061a":"# Setting Environmental Variables"}}