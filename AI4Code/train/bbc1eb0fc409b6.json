{"cell_type":{"c6d2c788":"code","8b9f754c":"code","bea046f6":"code","0e22a8e4":"code","9d42f97d":"code","fce37c4b":"code","13a72828":"code","28d81d37":"code","22005cf5":"code","bbae42ac":"code","0999e7d4":"code","7cd6bcd5":"code","9aa03032":"code","1a7adf48":"code","556806f0":"code","9d9b6725":"code","1228de3a":"code","d446a25d":"code","79cb9415":"markdown","f6758085":"markdown","4455cbfd":"markdown","8296c588":"markdown","1bc580ed":"markdown","8df7e71a":"markdown","ff9aecf1":"markdown","def28b2f":"markdown","d6abc25c":"markdown"},"source":{"c6d2c788":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import  Input, Conv2D, MaxPooling2D,GlobalMaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Activation, MaxPool2D, AvgPool2D, Dropout\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.applications import DenseNet121, VGG19, ResNet50\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom IPython.display import display, Image\nimport matplotlib.pyplot as mpimg\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.utils import shuffle\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8b9f754c":"train_df = pd.read_csv('..\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_Metadata.csv')\nvalid_df = pd.read_csv('..\/input\/coronahack-chest-xraydataset\/Chest_xray_Corona_dataset_Summary.csv')\n\nprint('The training dataset has rows : ', format(train_df.shape[0]))\nprint('The training dataset has cols : ', format(train_df.shape[1]))","bea046f6":"missing_vals = train_df.isnull().sum()","0e22a8e4":"train_df.dropna(how = 'all')\ntrain_df.isnull().sum()","9d42f97d":"train_data = train_df[train_df['Dataset_type'] == 'TRAIN']\ntest_data = train_df[train_df['Dataset_type'] == 'TEST']\nassert train_data.shape[0] + test_data.shape[0] == train_df.shape[0]\nprint(f\"Shape of train data : {train_data.shape}\")\nprint(f\"Shape of test data : {test_data.shape}\")","fce37c4b":"train_fill = train_data.fillna('unknown')\ntest_fill = test_data.fillna('unknown')","13a72828":"test_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/test'\ntrain_img_dir = '\/kaggle\/input\/coronahack-chest-xraydataset\/Coronahack-Chest-XRay-Dataset\/Coronahack-Chest-XRay-Dataset\/train'","28d81d37":"final_train_data = train_data[(train_data['Label'] == 'Normal') | \n                              ((train_data['Label'] == 'Pnemonia') & (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n\n\n# Create a target attribute where value = positive if 'Pnemonia + COVID-19' or value = negative if 'Normal'\nfinal_train_data['target'] = ['negative' if holder == 'Normal' else 'positive' for holder in final_train_data['Label']]\n\nfinal_train_data = shuffle(final_train_data, random_state=1)\n\nfinal_validation_data = final_train_data.iloc[1000:, :]\nfinal_train_data = final_train_data.iloc[:1000, :]\n\nprint(f\"Final train data shape : {final_train_data.shape}\")\n","22005cf5":"def DistanceMatrix_cpu(boundary_x, boundary_y, internal_points_x, internal_points_y):\n    dist = []\n    dist_x = (boundary_x[:,npy.newaxis] - internal_points_x[npy.newaxis,:])**2\n\n    dist_y = (boundary_x[:,npy.newaxis] - internal_points_y[npy.newaxis,:])**2\n\n    return np.sqrt(dist_x+dist_y)\n\nfrom numpy import inf\nimport numpy as npy\nfrom timeit import default_timer as timer\nimport numpy as np\n\ndef gen_circle(img):\n\n        Boundary_Points = 1000\n        \n        y_in, x_in = npy.where(img != 0)\n        \n        if y_in.shape[0] == 0:\n          return None\n\n        Circ_Bound = np.linspace(0, 2*np.pi, Boundary_Points); \n        candidate_circle = 0\n        highest_size = 0\n \n        print('found candidate circle')\n\n        vv = npy.size(y_in);\n        ww = npy.size(x_in);\n        zz = npy.zeros(ww);\n        \n        #Create circle boundary\n        R = img.shape[0] \/\/ 2\n        x = int(img.shape[0] \/\/ 2)\n        y = int(img.shape[1] \/\/ 2)\n\n        #Find all points within circle by first getting indices of all points in the image\n        y_in_circle, x_in_circle = y_in, x_in\n\n        normalized = np.asarray(npy.column_stack([x_in_circle, y_in_circle]))\n    \n        Circ_Bound_x = R * np.cos(Circ_Bound) + x\n        Circ_Bound_y = R * np.sin(Circ_Bound) + y    \n\n        DM_data_Sample = DistanceMatrix_cpu((Circ_Bound_x), (Circ_Bound_y), normalized[:,0], normalized[:,1]);\n\n        IM = 1.\/DM_data_Sample; \n        Boundary_Values_Sample = np.sum(IM, axis=1);\n        Boundary_Values_Normalized = Boundary_Values_Sample\n\n        return Boundary_Values_Normalized","bbae42ac":"import cv2\nfrom skimage import io \nfrom skimage.transform import rotate, AffineTransform, warp\n\ndataset = {\n    'Normal' : [],\n    'Pnemonia' : []\n    \n}\n\ncovidCount = 0\nnormalCount = 0\n\nsubset = {\n    'Normal' : [],\n    'Pnemonia' : []\n    \n}\nfor index, row in final_train_data.iterrows():\n    fn = row['X_ray_image_name']\n    label = row['Label']\n    \n    path = train_img_dir + '\/' + fn\n    \n    #read image as grayscale\n    img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n\n    #resize images to 600x600 \n    #anything greater than it will cause our algorithm to run too slow and cause the notebook to crash due to memory bandwidtch\n    path = train_img_dir + '\/' + fn\n    width = 600 \n    height = 600\n    dim = (width, height)\n    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n    \n    if img is None:\n        continue\n    \n    subset[label].append(img)\n\n    if label == 'Pnemonia':\n        temp_data = [img]\n        covidCount += 1\n\n        temp_data = []\n        \n        r_image = rotate(img, angle=45) # angle value is positive for anticlockwise rotation \n        r_image1 = rotate(img, angle=-45) #angle value is negative for clockwise rotation\n\n        hflipped_image= np.fliplr(img) #fliplr reverse the order of columns of pixels in matrix\n        vflipped_image= np.flipud(img)\n\n        temp_data.append(r_image)\n        temp_data.append(r_image1)\n        temp_data.append(hflipped_image)\n        temp_data.append(vflipped_image)\n    else:\n        normalCount +=1\n        if normalCount >= 200:\n            continue\n            \n        temp_data = [img]\n        \n    for item in temp_data:\n        b = gen_circle(item)\n        dataset[label].append(b)\n\n    if covidCount >= 200 and normalCount >= 200:\n        break\nprint(c)","0999e7d4":"outfile = 'full_dataset.npz'\nnp.savez(outfile, **dataset)","7cd6bcd5":"try:\n    dataset\nexcept:\n    dataset = np.load('..\/input\/dataset-covid\/dataset_preprocessed.npz')","9aa03032":"import matplotlib.pyplot as plt\nimport scipy.stats as stats\n\nidx= 16\n\nfor obj in dataset:\n        item = dataset[obj][idx]\n        \n        plt.plot(item, label='Label: {}, raw signal'.format(obj))\n        plt.legend()\n\n        plt.show()\n        plt.plot(item[120:145], label='Label: {}, First peak'.format(obj))\n        plt.legend()\n        plt.show()\n        plt.plot(item[220:245], label='Label: {}, Second peak'.format(obj))\n        plt.legend()\n\n        plt.show()","1a7adf48":"data_modified = {\n    'Normal' : [],\n    'Pnemonia' : [],\n}\n\nfor shape in dataset:\n    \n    t = dataset[shape]\n    for item in t:\n        data_modified[shape].append(item[125:145])","556806f0":"train_x = []\ntest_x = []\ntrain_y=[]\ntest_y=[]\n\ni = 0\nfor shape in data_modified:\n    #select only the first 140 elements to make both labels have same number of objects\n    data = data_modified[shape][:140]\n\n    if len(data) == 0:\n        continue\n        \n    print('shape', shape, len(data))\n\n    data = np.asarray(data) \n    data \/= np.linalg.norm(data)\n    # data = data[:,0]\n    #data = np.abs(np.apply_along_axis(np.fft.fft, 1, data))\n    random_range = np.arange(data.shape[0])\n    np.random.shuffle(random_range)\n    train_range = int(random_range.shape[0] *.7)\n    \n    if i== 0:\n        train_y = [i] * data[random_range[:train_range]].shape[0]\n        test_y = [i] * data[random_range[train_range:]].shape[0]\n        train_x = data[random_range[:train_range]]\n        test_x = data[random_range[train_range:]]\n    else:\n        train_y = np.concatenate((train_y, [i] * data[random_range[:train_range]].shape[0]), axis=0)\n        test_y = np.concatenate((test_y, ([i] * data[random_range[train_range:]].shape[0])), axis=0)\n\n        train_x = np.concatenate((train_x, data[random_range[:train_range]]), axis=0)\n\n        test_x = np.concatenate((test_x, data[random_range[train_range:]]), axis=0)\n    i+=1","9d9b6725":"train_x.shape","1228de3a":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=2)\nneigh.fit(np.nan_to_num(train_x), train_y)\npred_i = neigh.predict(np.nan_to_num(test_x))\nneigh.score(np.nan_to_num(test_x), test_y)","d446a25d":"from sklearn.metrics import accuracy_score\nfrom sklearn import svm\n\nclf = svm.SVC(decision_function_shape='ovo', probability=True)\nclf.fit(np.nan_to_num(train_x), train_y)\n\npredicted = clf.predict(np.nan_to_num(test_x))\n\n# get the accuracy\naccuracy_score(test_y, predicted)","79cb9415":"**\nselect a subset of data and add into new object.**","f6758085":"Let's fill the missing values with 'unknown'","4455cbfd":"# Load the libraries","8296c588":"# **Visualize boundary conditions**","1bc580ed":"# 5. Classifiers","8df7e71a":"# 4. Process data for training","ff9aecf1":"# 1. Loading Datasets","def28b2f":"# 3. Save proccesed data or load already processed data","d6abc25c":"# 2. Calculate Boundary Conditions"}}