{"cell_type":{"b06c4a53":"code","bf3efe70":"code","488b3d04":"code","63acdec8":"code","f09c4f29":"code","35d8dc66":"code","63eb9c73":"code","3acf3b5a":"code","0b4239c5":"code","f68bf06e":"code","cb08564a":"code","ab9ab182":"code","3eb5f8b3":"code","5cfad058":"code","97aa57fb":"code","272bc140":"code","06aef849":"code","a9794712":"code","42b0a2c1":"code","e0dc4efd":"code","86d4ece7":"code","375265db":"code","888d5439":"code","207424fc":"code","34b1786f":"code","5fe19be2":"code","1dc4cacb":"code","2fa5de75":"code","0987a9bc":"code","9113be64":"code","4deca4e5":"code","585e90ad":"code","934ea437":"code","bfb2e895":"code","0b808e6b":"code","5ec378c0":"code","93bd5898":"code","5fcae9be":"code","696650c8":"code","02374632":"code","1bcff9ba":"code","f284fd90":"code","640577ee":"code","7f435d97":"code","752d9120":"code","df582df3":"code","6dddc33c":"code","09bf21a8":"code","95a12e96":"code","32c995b7":"code","e42607b6":"code","d578b86a":"code","7597018e":"code","6a3cf252":"code","b459ec23":"code","bc068bbb":"code","e2cda544":"code","be703c70":"code","ca9a8a7b":"code","d3c45ea1":"code","40769dfe":"code","f39f5707":"code","a6b50046":"code","c1e80b43":"code","8e5365a4":"code","124ccbd0":"code","3e7c7ea7":"code","f7a6ecc0":"code","bc89fae1":"code","0f5ba5b5":"code","0c08bfd7":"code","50bb5e74":"code","9e2aec96":"code","6c6b1f47":"code","565200a6":"code","9aa2f9ee":"code","8a5880ca":"code","3dd081db":"code","86e11111":"code","c9e9c3a2":"code","1edf29f9":"code","20794193":"code","baaa5d11":"code","18f25c6b":"code","0e815421":"code","bd0e18b2":"markdown","34fdea9e":"markdown","92800680":"markdown","3fc4f69d":"markdown","3f29c294":"markdown","0e72a788":"markdown","980ea2e8":"markdown","625e7771":"markdown","d8c9ab83":"markdown","8484ba45":"markdown","215f92bb":"markdown","7265fb68":"markdown","db6c4e5a":"markdown","b1d402a8":"markdown","d604d865":"markdown","a347af09":"markdown","e5364f6a":"markdown","d63df6e8":"markdown","c8f041b7":"markdown","6c23cf9d":"markdown","f09098c5":"markdown","281432e1":"markdown","d1350939":"markdown","8bfa0344":"markdown","7d7767b6":"markdown","ddad9b89":"markdown","f3cdc66a":"markdown","3bc90db6":"markdown","cf8b5a56":"markdown","cd3ecb7e":"markdown","5ac36c6a":"markdown","0d9a1b1a":"markdown"},"source":{"b06c4a53":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bf3efe70":"#-------Pandas Settings------------\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows',None)\n\n# Install some libraries\n!pip install researchpy # for some statistical operations\n!pip install dython # for categorical and numeric correlations\n\n# Import Libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport researchpy\nimport scipy # for statistics\nfrom scipy import stats\nimport yellowbrick #for some special visualizations\nfrom yellowbrick.target import class_balance\nfrom dython import nominal\nfrom yellowbrick.features import rank1d,rank2d #for shapiro wilks visualization\nfrom sklearn.metrics import pairwise_distances, matthews_corrcoef,f1_score,accuracy_score\nfrom sklearn.neighbors import LocalOutlierFactor # for outlier detection\nfrom sklearn.ensemble import RandomForestClassifier,VotingClassifier ,IsolationForest,BaggingClassifier,StackingClassifier \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier,plot_tree\nfrom xgboost import plot_tree\nfrom sklearn.linear_model import LogisticRegression,LogisticRegressionCV\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import MinMaxScaler,RobustScaler,StandardScaler\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\nfrom mlxtend.plotting import plot_learning_curves,plot_decision_regions\n\nfrom yellowbrick.classifier import ClassificationReport, confusion_matrix,precision_recall_curve,classification_report,roc_auc\nfrom yellowbrick.classifier import PrecisionRecallCurve,ConfusionMatrix,ROCAUC\nfrom yellowbrick.model_selection import FeatureImportances,feature_importances\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nfrom pdpbox import pdp, get_dataset, info_plots # for partial dependence plots\nimport shap #for shap values\nfrom mlxtend.evaluate import bias_variance_decomp\nfrom sklearn.model_selection import validation_curve","488b3d04":"data=pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")\ndf=data.copy() # I'm copying it just in case.\ndf.head()","63acdec8":"df.memory_usage(index=False)","f09c4f29":"df.info()","35d8dc66":"df[[\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]].describe().T","63eb9c73":"def show_statistics(df):\n    frame=pd.DataFrame(columns=scipy.stats.describe(df)._asdict().keys())\n    columns=df.select_dtypes(exclude=[\"object\"]).columns\n    for i in columns:\n        d=scipy.stats.describe(df[i])._asdict()\n        frame=frame.append(d,ignore_index=True)\n    frame.index=columns\n    return frame\n\nshow_statistics(df[[\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]])","3acf3b5a":"researchpy.summary_cat(df[[\"target\",\"sex\"]])","0b4239c5":"df.isnull().sum().to_frame(name=\"missing\")","f68bf06e":"df.head()","cb08564a":"columns_to_convert=[\"sex\",\"cp\",\"fbs\",\"restecg\",\"exang\",\"slope\",\"ca\",\"thal\"]\nfor i in columns_to_convert:\n    df[i]=df[i].astype(\"object\")","ab9ab182":"df.dtypes.to_frame(name=\"types\").T","3eb5f8b3":"sns.heatmap(df[[\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]].corr(),annot=True,cmap=\"coolwarm\");","5cfad058":"crosstab, res = researchpy.crosstab(df.sex, df.target, test= \"chi-square\")\ncrosstab","97aa57fb":"res ","272bc140":"plt.figure(figsize=(12,5));\nplt.subplot(121)\n#class_balance(df.target);\ndf.target.value_counts().plot.bar()\n\nplt.subplot(122)\nplt.pie(df.target.value_counts(),labels=[\"Patient\",\"Healthy\"],autopct='%1.1f%%',radius=1);\nplt.title(\"Target rates\", bbox={'facecolor':'0.9', 'pad':5},loc=\"center\");","06aef849":"plt.figure(figsize=(15,5))\nplt.subplot(131)\nsns.countplot(df.sex);\n\nplt.subplot(132)\nplt.pie(df[df.sex==1].groupby(\"target\")[\"sex\"].value_counts(),autopct='%1.1f%%',radius=1,labels=[\"Healthy Male\",\"Male Patient\"]);\n\nplt.subplot(133)\nplt.pie(df[df.sex==0].groupby(\"target\")[\"sex\"].value_counts(),autopct='%1.1f%%',radius=1,labels=[\"Healthy Female\",\"Female Patient\"]);\n\n# 1-male\n# 0-female","a9794712":"f, axs = plt.subplots(4,2,figsize=(15,10))\n\nf.tight_layout()\n\nsns.countplot(df.target,hue=\"sex\",data=df,ax=axs[0][0]);\n\nsns.countplot(df.target,hue=\"cp\",data=df,ax=axs[1][0]);\n\nsns.countplot(df.target,hue=\"fbs\",data=df,ax=axs[2][0]);\n\nsns.countplot(df.target,hue=\"restecg\",data=df,ax=axs[3][0]);\n\nsns.countplot(df.target,hue=\"exang\",data=df,ax=axs[0][1]);\n\nsns.countplot(df.target,hue=\"slope\",data=df,ax=axs[1][1]);\n\nsns.countplot(df.target,hue=\"ca\",data=df,ax=axs[2][1]);\n\nsns.countplot(df.target,hue=\"thal\",data=df,ax=axs[3][1]);","42b0a2c1":"plt.figure(figsize=(17,5));\nplt.subplot(131)\nsns.heatmap(pd.crosstab(df.sex,df.target),annot=True,fmt='g',cmap=\"coolwarm\"); \nplt.subplot(132)\nsns.heatmap(pd.crosstab(df.cp,df.target),annot=True,fmt='g',cmap=\"YlGnBu\"); \nplt.subplot(133)\nsns.heatmap(pd.crosstab(df.ca,df.target),annot=True,fmt='g',cmap=\"YlOrRd\"); \n# I'm adding fmt parameter, otherwise it would contain e number.","e0dc4efd":"pd.crosstab(df.age,df.target).plot.bar(figsize=(15,5));","86d4ece7":"for i in [\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]:\n    sns.catplot(x=\"sex\",y=i,hue=\"target\",data=df,kind=\"box\",aspect=2); #1 male 0 female","375265db":"sns.FacetGrid(df, col=\"target\",row=\"sex\",height=3, aspect=2).map(sns.distplot,\"age\",color=\"orange\");","888d5439":"sns.FacetGrid(df, col=\"target\",row=\"sex\",height=3, aspect=2).map(sns.distplot,\"chol\",color=\"orangered\");","207424fc":"sns.FacetGrid(df, col=\"target\",row=\"sex\",height=3, aspect=2).map(sns.distplot,\"oldpeak\",color=\"black\");","34b1786f":"sns.FacetGrid(df, col=\"target\",row=\"sex\",height=3, aspect=2).map(sns.distplot,\"thalach\",color=\"purple\");","5fe19be2":"sns.FacetGrid(df, col=\"target\",row=\"sex\",height=3, aspect=2).map(sns.regplot,\"oldpeak\",\"age\",color=\"b\");","1dc4cacb":"sns.FacetGrid(df, col=\"target\",row=\"sex\",height=3, aspect=2).map(sns.regplot,\"chol\",\"age\",color=\"purple\");","2fa5de75":"sns.FacetGrid(df, col=\"target\",row=\"sex\",height=3, aspect=2).map(sns.regplot,\"trestbps\",\"age\",color=\"green\");","0987a9bc":"sns.FacetGrid(df, col=\"target\",row=\"sex\",height=3, aspect=2).map(sns.regplot,\"thalach\",\"age\",color=\"r\");\n","9113be64":"g = sns.JointGrid(x=\"age\", y=\"chol\", data=df, space=0)\ng = g.plot_joint(sns.kdeplot, cmap=\"Purples_d\")\ng = g.plot_marginals(sns.kdeplot, shade=True,color=\"m\")","4deca4e5":"g = sns.JointGrid(x=\"age\", y=\"thalach\", data=df, space=0)\ng = g.plot_joint(sns.kdeplot)\ng = g.plot_marginals(sns.kdeplot, shade=True,color=\"green\")","585e90ad":"g = sns.JointGrid(x=\"oldpeak\", y=\"thalach\", data=df, space=0)\ng = g.plot_joint(sns.kdeplot)\ng = g.plot_marginals(sns.kdeplot, shade=True,color=\"b\")","934ea437":"sns.scatterplot(x=\"age\",y=\"thalach\",hue=\"target\",data=df,style=\"target\",palette=\"bright\");\nplt.title(\"Maximum Hearth rate vs. Age\");","bfb2e895":"sns.scatterplot(x=\"age\",y=\"thalach\",hue=\"sex\",data=df,style=\"target\",palette=\"bright\");","0b808e6b":"sns.lmplot(x=\"thalach\", y=\"age\", hue=\"target\", data=df,aspect=2);","5ec378c0":"df.hist(figsize=(12,10),color=\"r\");","93bd5898":"\n_, axes = plt.subplots(ncols=2, figsize=(12,5));\n\nrank1d(df[[\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]], ax=axes[0], show=False);\nrank2d(df[[\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]], ax=axes[1], show=False);\nplt.show()","5fcae9be":"X=df.drop(\"target\",axis=1)\ny=df[\"target\"]","696650c8":"\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=123)\nX_train.shape,y_train.shape,X_test.shape,y_test.shape","02374632":"plt.figure(figsize=(15,7));\nplt.subplot(151)\nsns.boxplot(X_train[\"age\"],orient=\"vertical\");\nplt.subplot(152)\nsns.boxplot(X_train[\"trestbps\"],orient=\"vertical\");\nplt.subplot(153)\nsns.boxplot(X_train[\"chol\"],orient=\"vertical\");\nplt.subplot(154)\nsns.boxplot(X_train[\"thalach\"],orient=\"vertical\");\nplt.subplot(155)\nsns.boxplot(X_train[\"oldpeak\"],orient=\"vertical\");","1bcff9ba":"def find_skewed_boundaries(df, variable, distance):\n\n    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n    #stats.iqr(df[variable])\n    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n\n    return upper_boundary, lower_boundary\n\nupper,lower=find_skewed_boundaries(X_train,\"age\",1.5)\nprint(\"Upper:\",upper,\"Lower:\",lower)\nX_train[(X_train[\"age\"]>upper) | (X_train[\"age\"]<lower)]\n  ","f284fd90":"upper,lower=find_skewed_boundaries(df,\"trestbps\",1.5)\nprint(\"Upper:\",upper,\"Lower:\",lower)\noutlier_indexes_iqr=[]\nfor index in X_train[(X_train[\"trestbps\"]>upper) | (X_train[\"trestbps\"]<lower)].index:\n    outlier_indexes_iqr.append(index)\nprint(\"Outlier indexes:\",outlier_indexes_iqr)\nX_train.loc[outlier_indexes_iqr]\n","640577ee":"upper,lower=find_skewed_boundaries(df,\"thalach\",1.5)\nprint(\"Upper:\",upper,\"Lower:\",lower)\nfor index in X_train[(X_train[\"thalach\"]>upper) | (X_train[\"thalach\"]<lower)].index:\n    outlier_indexes_iqr.append(index)\noutlier_indexes_iqr","7f435d97":"upper,lower=find_skewed_boundaries(df,\"oldpeak\",1.5)\nprint(\"Upper:\",upper,\"Lower:\",lower)\nfor index in X_train[(X_train[\"oldpeak\"]>upper) | (X_train[\"oldpeak\"]<lower)].index:\n    outlier_indexes_iqr.append(index)\noutlier_indexes_iqr","752d9120":"outlier_indexes_iqr=set(outlier_indexes_iqr)\nX_train.loc[outlier_indexes_iqr]","df582df3":"clf=LocalOutlierFactor(n_neighbors=7)\nclf","6dddc33c":"pred=clf.fit_predict(X_train)\npred[:40]","09bf21a8":"X_train[pred==-1]","95a12e96":"outlier_indexes_lof = X_train[pred==-1].index\nprint(outlier_indexes_lof)","32c995b7":"plt.figure(figsize=(20,5));\nplt.subplot(141)\nsns.scatterplot(X_train[\"age\"],X_train[\"chol\"]);\nplt.subplot(142)\nsns.scatterplot(X_train[\"age\"],X_train[\"thalach\"]);\nplt.subplot(143)\nsns.scatterplot(X_train[\"age\"],X_train[\"trestbps\"]);\nplt.subplot(144)\nsns.scatterplot(X_train[\"age\"],X_train[\"oldpeak\"]);","e42607b6":"clf_=IsolationForest(random_state=123,n_estimators=100,bootstrap=False,contamination=0.05).fit(X_train)\npred=clf_.predict(X_train)\noutlier_indexes_iso=X_train[pred==-1].index\noutlier_indexes_iso","d578b86a":"X_train=pd.get_dummies(X_train)\nX_test=pd.get_dummies(X_test)","7597018e":"X_train.drop(columns=[\"sex_1\",\"fbs_1\",\"exang_1\"],axis=1,inplace=True)\nX_test.drop(columns=[\"sex_1\",\"fbs_1\",\"exang_1\"],axis=1,inplace=True)","6a3cf252":"X_train=X_train.drop(outlier_indexes_iqr)\ny_train=y_train.drop(outlier_indexes_iqr)\n","b459ec23":"X_train.shape,y_train.shape","bc068bbb":"plt.figure(figsize=(15,7));\nplt.subplot(151)\nsns.boxplot(X_train[\"age\"],orient=\"vertical\");\nplt.subplot(152)\nsns.boxplot(X_train[\"trestbps\"],orient=\"vertical\");\nplt.subplot(153)\nsns.boxplot(X_train[\"chol\"],orient=\"vertical\");\nplt.subplot(154)\nsns.boxplot(X_train[\"thalach\"],orient=\"vertical\");\nplt.subplot(155)\nsns.boxplot(X_train[\"oldpeak\"],orient=\"vertical\");","e2cda544":"X_train[X_train.oldpeak>=4].index\n","be703c70":"X_train[X_train.chol>390].index","ca9a8a7b":"X_train=X_train.drop([220,295,28,85,246,96])\ny_train=y_train.drop([220,295,28,85,246,96])\n","d3c45ea1":"plt.figure(figsize=(15,7));\nplt.subplot(151)\nsns.boxplot(X_train[\"age\"],orient=\"vertical\");\nplt.subplot(152)\nsns.boxplot(X_train[\"trestbps\"],orient=\"vertical\");\nplt.subplot(153)\nsns.boxplot(X_train[\"chol\"],orient=\"vertical\");\nplt.subplot(154)\nsns.boxplot(X_train[\"thalach\"],orient=\"vertical\");\nplt.subplot(155)\nsns.boxplot(X_train[\"oldpeak\"],orient=\"vertical\");","40769dfe":"X_train.shape,y_train.shape","f39f5707":"scaler=MinMaxScaler()\nX_train_scaled=scaler.fit_transform(X_train)\nX_test_scaled=scaler.transform(X_test)","a6b50046":"clf=LogisticRegression(random_state=0,C=0.7,solver=\"liblinear\")\nclf_model=clf.fit(X_train_scaled,y_train)\npred=clf.predict(X_test_scaled)\naccuracy_score(y_test,pred)\n","c1e80b43":"clf.score(X_train_scaled,y_train)","8e5365a4":"clf.classes_","124ccbd0":"clf.predict_proba(X_test_scaled)[:3]","3e7c7ea7":"clf.get_params()","f7a6ecc0":"pred_cv=LogisticRegressionCV(cv=10,random_state=0).fit(X_train_scaled,y_train).predict(X_test_scaled)\naccuracy_score(y_test,pred_cv)","bc89fae1":"plot_learning_curves(X_train_scaled,y_train,X_test_scaled,y_test,clf);","0f5ba5b5":"avg_expected_loss, avg_bias, avg_var=bias_variance_decomp(clf,X_train_scaled,\n                                                          y_train.values,X_test_scaled,\n                                                          y_test.values,random_seed=0)\n\nprint('Average expected loss: %.3f' % avg_expected_loss)\nprint('Average bias: %.3f' % avg_bias)\nprint('Average variance: %.3f' % avg_var)","0c08bfd7":"\ndef visualize_result(model,X_train,X_test,y_train,y_test):\n    fig, axes = plt.subplots(2, 2,figsize=(15,12))\n    model = model\n    visualgrid = [\n        PrecisionRecallCurve(model,ax=axes[0][0]),\n        ConfusionMatrix(model, ax=axes[0][1]),\n        ClassificationReport(model, ax=axes[1][0]),\n        ROCAUC(model, ax=axes[1][1]),\n    ]\n\n    for viz in visualgrid:\n        viz.fit(X_train, y_train)\n        viz.score(X_test, y_test)\n        viz.finalize()\n\n    plt.show()\n","50bb5e74":"visualize_result(clf,X_train_scaled,X_test_scaled,y_train,y_test)","9e2aec96":"matthews_corrcoef(y_test,pred)","6c6b1f47":"perm = PermutationImportance(clf_model, random_state=1).fit(X_test_scaled, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","565200a6":"feature_importances(clf_model,pd.DataFrame(X_train_scaled,columns=X_train.columns),y_train);","9aa2f9ee":"clf.coef_","8a5880ca":"\nimportance = clf_model.coef_[0]\n\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\n\nplt.bar([x for x in range(len(importance))], importance);\nplt.show()","3dd081db":"x_test_frame=pd.DataFrame(X_test_scaled,columns=X_test.columns)\npdp_oldpeak = pdp.pdp_isolate(model=clf_model, dataset=x_test_frame,\n                            model_features=x_test_frame.columns, feature='oldpeak')\n\npdp.pdp_plot(pdp_oldpeak, 'oldpeak')\nplt.show()","86e11111":"pdp_oldpeak = pdp.pdp_isolate(model=clf_model, dataset=x_test_frame,\n                            model_features=x_test_frame.columns, feature='thalach')\n\npdp.pdp_plot(pdp_oldpeak, 'thalach')\nplt.show()","c9e9c3a2":"pdp_age = pdp.pdp_isolate(model=clf_model, dataset=x_test_frame,\n                            model_features=x_test_frame.columns, feature='age')\n\npdp.pdp_plot(pdp_age, 'age')\nplt.show()","1edf29f9":"pdp_ca0 = pdp.pdp_isolate(model=clf_model, dataset=x_test_frame,\n                            model_features=x_test_frame.columns, feature='ca_0')\n\npdp.pdp_plot(pdp_ca0, 'ca_0')\nplt.show()","20794193":"shap.initjs() # load JS visualization code to notebook","baaa5d11":"# summarize the effects of all the features\nexplainer=shap.LinearExplainer(clf_model,X_train_scaled)\nshap_values = explainer.shap_values(X_test_scaled)\nshap.summary_plot(shap_values, X_test_scaled, feature_names=X_test.columns)","18f25c6b":"shap.summary_plot(shap_values, pd.DataFrame(X_train_scaled,columns=X_train.columns), plot_type=\"bar\")","0e815421":"# visualize the training set predictions\nshap.force_plot(explainer.expected_value, shap_values, X_train_scaled)","bd0e18b2":"Apparently, there is no missing values.","34fdea9e":"Local outlier factor is one of the methods used to detect outlier observations.Outlier detection methods can be distribution-based,depth-based,clustering-based and density-based. LOF allows to define outliers by doing density-based scoring. It is similar to the KNN (nearest neighbor search) algorithm. The difference is that we\u2019re trying to find observations that are close together in KNN, but we\u2019re trying to find observations that are not alike in LOF.","92800680":"# Feature Information","3fc4f69d":"* age\n* sex\n* chest pain type (4 values)\n* resting blood pressure\n* serum cholestoral in mg\/dl\n* fasting blood sugar > 120 mg\/dl\n* resting electrocardiographic results (values 0,1,2)\n* maximum heart rate achieved\n* exercise induced angina\n* oldpeak = ST depression induced by exercise relative to rest\n* the slope of the peak exercise ST segment\n* number of major vessels (0-3) colored by flourosopy\n* thal: A blood disorder called thalassemia\n","3f29c294":"The partial dependence plot shows the marginal effect one or two features have on the predicted outcome of a machine learning model (J. H. Friedman 2001).A partial dependence plot can show whether the relationship between the target and a feature is linear, monotonic or more complex. For example, when applied to a linear regression model, partial dependence plots always show a linear relationship.\n\nFor more : https:\/\/christophm.github.io\/interpretable-ml-book\/pdp.html","0e72a788":"![image.png](attachment:image.png)","980ea2e8":"## Local Outlier Factor","625e7771":"# Import Libraries","d8c9ab83":"# Import Data","8484ba45":"According to the test, there is a meaningful difference between men and women in terms of being a patient or not.","215f92bb":"## IQR ","7265fb68":"The goal of SHAP is to explain the prediction of an instance x by computing the contribution of each feature to the prediction. The SHAP explanation method computes Shapley values from coalitional game theory. The feature values of a data instance act as players in a coalition.\n\nFor more : https:\/\/christophm.github.io\/interpretable-ml-book\/shap.html","db6c4e5a":"## Feature Importance","b1d402a8":"![image.png](attachment:image.png)","d604d865":"## Isolation Forests","a347af09":"![image.png](attachment:image.png)","e5364f6a":"### Feature Importance","d63df6e8":"![image.png](attachment:image.png)","c8f041b7":"### Permutation Importance","6c23cf9d":"I'm changing the types of some columns because I'll make visualizations and create some models based on tree so it's better to do this for now.","f09098c5":"If the bias is larger than zero, we also say that the estimator is positively biased, if the bias is smaller than zero, the estimator is negatively biased, and if the bias is exactly zero, the estimator is unbiased. ","281432e1":"**WORK IN PROGRESS...**","d1350939":"# Train Test Split","8bfa0344":"![image.png](attachment:image.png)","7d7767b6":"Isolation Forest, unlike other density-based or distance-based methods, tries to separate outliers from normal points by creating random trees. Selects a random feature on each node and sets a random treshold to split it in half.","ddad9b89":" ## Partial Dependence Plot","f3cdc66a":"## Shap Values","3bc90db6":"![image.png](attachment:image.png)","cf8b5a56":"# Exploratory Data Analysis","cd3ecb7e":"## Logistic Regression","5ac36c6a":"# Outlier Detection","0d9a1b1a":"You can read my article and check the numerical example to understand LOF. https:\/\/www.datasciencearth.com\/en\/local-outlier-factor-2\/"}}