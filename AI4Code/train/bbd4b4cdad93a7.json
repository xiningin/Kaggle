{"cell_type":{"961b09a9":"code","8bd37c3e":"code","cc2a1f53":"code","9265cc6a":"code","6cbdfb8d":"code","8cf27d20":"code","0e8eb06c":"code","a865c8fd":"code","17b298ad":"code","22975dfb":"code","a840a04f":"code","26e2c494":"code","1eae60b7":"code","31426158":"code","dce6b82b":"code","41ba7ff2":"code","36afe367":"code","0d1ee2d1":"code","54ba3a27":"code","30f40cd8":"code","e8445998":"code","962b8fb8":"code","d89fb789":"code","a3d059e0":"code","9eba2dae":"markdown","90290fca":"markdown","56fa1452":"markdown","8f6fb793":"markdown","6afb3af9":"markdown","34e8b9ae":"markdown","662a64dd":"markdown"},"source":{"961b09a9":"!pip install kaggle plot-keras-history -q","8bd37c3e":"import pandas as pd\nimport collections\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport numpy as np\nimport dill\nfrom tensorflow.keras import models, backend\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout, Dense, Flatten\nfrom sklearn.model_selection import train_test_split\nfrom plot_keras_history import plot_history\nplt.style.use('seaborn-ticks')","cc2a1f53":"# Read in the CSV files to a Pandas DataFrame\ntraindf = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntestdf = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nprint('Train data shape:',traindf.shape,'\\n','Test data shape:',testdf.shape,'\\n')","9265cc6a":"# Sanity check for any null values\nprint('Null values exist in training data?:',traindf.isnull().values.any())\nprint('Null values exist in test data?:',testdf.isnull().values.any())","6cbdfb8d":"# Extract the labels column from the train dataset, then drop it from the dataframe\nlabels = np.asarray(traindf['label'])\ntraindf.drop(columns=['label'], inplace=True)\n\nprint(labels[:20])\nprint(traindf.shape)","8cf27d20":"# View an example image and its associated label\nnum = 100\nplt.imshow(np.reshape(traindf.iloc[num,:].values,(28,28)))\nplt.title('The label of the image is:'+str(labels[num]))","0e8eb06c":"plt.figure(figsize=(16,8))\nplt.hist(labels, bins=(np.arange(11)-.5),ec='black',alpha=.8)\nplt.title('Histogram of Labels')\nplt.xlabel('Label')\nplt.ylabel('Count of Label')\nplt.xticks(range(max(labels)+1))\nplt.plot();","a865c8fd":"# Normalize the data by dividing each pixel value by 255\n# This reduces the variance from 0 - 255 to 0 - 1\ntrain_norm = traindf.iloc[:,:]\/255","17b298ad":"# Keeping the test.csv file as the test set, splitting a validation set off the training set\n# Stratifying to help with ensuring we have balanced data\nX_train, X_val, y_train, y_val = train_test_split(train_norm, labels, test_size=.10, stratify=labels)","22975dfb":"# Reviewing shapes of training and validation \nprint('X_Train shape:',X_train.shape,\n      '\\n','X_val shape:',X_val.shape,\n      '\\n','Y_train shape:',y_train.shape,\n      '\\n','y_val shape:',y_val.shape)","a840a04f":"# Defining a sequential model architecture using single hidden layer\n# Goal is to showcase performance from a simple model architecture\nmodel = Sequential()\nmodel.add(Dense(60, activation='relu', input_shape=(X_train.iloc[1].shape))) # Single hidden layer\nmodel.add(Dropout(.3)) # Good practice to help with reducing overfitting risk\nmodel.add(Dense(10, activation='softmax')) # Softmax with 10 nodes for the 10 possible labels\n\n# Generate review of the model architecture\nmodel.summary()","26e2c494":"# Compile the model \nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])","1eae60b7":"# Fit the model. Setting 60 epochs but using early stopping\noutput = model.fit(X_train,\n                   y_train,\n                   epochs = 60,\n                   validation_data=(X_val,y_val),\n                   callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)]\n                   )","31426158":"# Plot model performance using plot_history\nplot_history(output.history);","dce6b82b":"# Create predicted labels from the original test dataset\npred = np.argmax(model.predict(testdf),axis=1)","41ba7ff2":"# Show an example from the test dataset, including its predicted label\nnum = 900\nplt.imshow(np.reshape(testdf.iloc[num,:].values,(28,28)))\nplt.title('The PREDICTED label of the image is:'+str(pred[num]));","36afe367":"# Create subplots for first 15 numbers from the test dataset\nplt.figure(figsize=(12,6))\nfor im in range(15):\n  plt.subplot(3, 5, im + 1)\n  plt.imshow(np.reshape(testdf.iloc[im,:].values,(28,28)))\n  plt.xticks([])\n  plt.yticks([])\n  plt.xlabel(pred[im])\nplt.show();","0d1ee2d1":"# Extracts the outputs of the hidden layer:\nlayer_outputs = [layer.output for layer in model.layers]\n\n# Creates a model that will return these outputs, given the model input:\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n\nprint(f\"There are {len(layer_outputs)} layers\",'\\n')\nlayer_outputs","54ba3a27":"model.layers[0]","30f40cd8":"activations = activation_model.predict(X_train) # Predicting the training classes to generate activation values\nhidden_layer_activation = activations[0] # Hidden layer\noutput_layer_activations = activations[1] # Hidden layer's output\nhidden_layer_activation.shape   #  Each of the 60 hidden nodes has one activation value per training image\noutput_layer_activations.shape # Checking shape","e8445998":"print(f\"The maximum activation value of the hidden nodes in the hidden layer is: {hidden_layer_activation.max()}\")","962b8fb8":"activation_data = {'actual_class':y_train}\nfor k in range(0,model.layers[0].output_shape[1]):\n  activation_data[f\"activation_{k}\"] = hidden_layer_activation[:,k]\n\nactivation_df = pd.DataFrame(activation_data)\nactivation_df.T # Transpose the dataframe so rows become columns","d89fb789":"node = 10 # Random node from the hidden layer\n\n# Visualize the activation values from the selected node\nplt.figure(figsize=(16,8))\nsns.set(font_scale=1)\nsns.boxplot(y='activation_'+str(node), \n            x='actual_class', \n            data=activation_df, \n            width=0.5,\n            palette=\"colorblind\")\nplt.title('Activation Values Boxplots')\nplt.show();","a3d059e0":"submission =pd.DataFrame({\"ImageId\": list(range(1,len(pred)+1)),\n                         \"Label\": pred})\nsubmission.to_csv(\"mnistbp.csv\", index=False, header=True)\n","9eba2dae":"# Train\/Validation Split","90290fca":"# Data Analysis\/Review","56fa1452":"# MNIST Classification Challenge","8f6fb793":"# Model Training","6afb3af9":"# Review Model Performance","34e8b9ae":"# Reviewing Hidden Layer Activation Values","662a64dd":"**Introduction:** \n\nThere are many ways to slice this problem, as well as the argument between the trade-off of more complex networks with negligible increases in performance. Therefore, this notebook's goal is to showcase how to identify handwritten digits from the MNIST dataset using a simple single hidden layer fully connected network. While greater performance can be achieved with other network architectures or additional preprocessing measure, this notebook is meant to be kept more simplistic in nature and to explore more of the possibilities of simple networks.\n\n**Methods:** \n\nThe notebook starts out by importing the CSV files that consist of training data and respective class labels, and test data without labels. These were loaded into a Pandas DataFrame for quick review. A sanity check was done to ensure there are no null values in the image pixel values. The 'label' column from the train data was then pulled out of the DataFrame, converted to a NumPy matrix, and stored in a new variable. This same column was dropped from the DataFrame.\n\nTo visualize the data we're working with, a random number was plotted along with its respective label. We also visualize the count of labels within the dataset, which allows us to see the balance within the dataset and which values have the most and least occurrences. \n\nPrior to training we normalize the pixel values, converting each value by 255 (the maximum potential pixel value). This is a simple method to reduce the data variance, aiding in model performance. \n\nKeeping the provided test data as 'test' data, we then split the training data into a training and validation set, with 90% kept for training and 10% for validation. This results in 37,800 images for training and 4,200 for validation. These sets will be used during the network's training process, with the provided test set withheld to test the model's ability to generalize.\n\nTo keep with the purpose of this notebook, a simple architecture is defined using a single hidden layer consisting of 60 nodes. While the node count is more of a random choice, it also helps showcase performance with a lower node count than commonly seen in FC layers. Further, an early stopping callback is added to the training process, monitoring the validation accuracy and halting training if performance does not increase over two epochs. This allows us to choose an arbitrarily higher number of epochs and letting the callback stop when necessary, reducing the risk of overfitting. Model performance is then plotted using the plot_keras_history library, which is more of a convenience but not necessary. \n\nThe trained model is then used to predict the labels for the test dataset, and an example image and its predicted label shown visually. This is also done for the first 15 images from the test dataset, as a point of reference for visual review of images against predicted labels. \n\nOne additional step is taken to review the hidden layer's node's activation values. This is an attempt to include some model transparency to the process, showing us what input images causing each node to activate and with what activation values.\n\n**Results:**\n\nOverall, a single hidden layer with 60 nodes was able to obtain accuracy of about 96%, showing the potential of a simple network in this specific use case. Additional steps can be taken to further increase model performance such as tuning hyperparameters or working with input data, including techniques like image augmentation or simply shifting train\/test\/validation splits. "}}