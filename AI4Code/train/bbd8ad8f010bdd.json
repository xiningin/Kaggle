{"cell_type":{"8271719a":"code","e38ed13c":"code","f1fe57bb":"code","e23d701b":"code","678ae981":"code","9b30732d":"code","cd42661f":"code","747d057c":"code","21f1af9f":"code","d8348347":"code","db69f8c4":"code","1cdd1818":"code","dee34b98":"code","ac067d4a":"code","c1e01b1f":"code","29d0d051":"code","147326ac":"code","9df34538":"code","f5c75d6e":"markdown","b0993df8":"markdown","ff383d21":"markdown","d245b40a":"markdown","881539ef":"markdown","9f39c9ee":"markdown","9f1a73e6":"markdown","163db894":"markdown","a43b0ee3":"markdown","8e1c3cd9":"markdown"},"source":{"8271719a":"import pandas as pd\nimport sklearn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e38ed13c":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split","f1fe57bb":"X,y = load_iris(return_X_y=True)","e23d701b":"#For my Training what will the error graph?\n#Different accuracy scores for different K values\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\ndef plot_k_accuracy( train_X, train_y,  test_X, test_y):\n\n  accuracy = []\n  train_acc = []\n\n  # we check for k from 1 to 10 \n  for k in range(1,12):\n    model = KNeighborsClassifier(n_neighbors = k)\n    model.fit(train_X, train_y)\n    preds = model.predict(test_X)\n    train_pred = model.predict(train_X)\n    score = accuracy_score(test_y, preds)\n    accuracy.append(score)\n    train_acc.append(accuracy_score(train_y, train_pred))\n\n  fig, ax = plt.subplots(2,1)\n  sns.lineplot(x = np.arange(1,12), y = accuracy,ax=ax[0])\n  sns.lineplot(x = np.arange(1,12), y = train_acc,ax=ax[1])\n  \n  fig.show()\n","678ae981":"print(X.shape, y.shape)\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 24)\n\n\nplot_k_accuracy(train_X, train_y, test_X, test_y)","9b30732d":"import seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\ndef plot_k_accuracy( train_X, train_y,  test_X, test_y):\n\n  accuracy = []\n  train_acc = []\n\n  # we check for k from 1 to 10 \n  for k in range(1,12):\n    model = KNeighborsClassifier(n_neighbors = k)\n    model.fit(train_X, train_y)\n    preds = model.predict(test_X)\n    score = accuracy_score(test_y, preds)\n    accuracy.append(score)\n\n  ax = sns.relplot(x = np.arange(1,12), y = accuracy,ax=ax[0])\n  ax.set(xlabel = 'K', ylabel = 'Accuracy')\n  plt.show()\n","cd42661f":"from sklearn.model_selection import StratifiedKFold","747d057c":"skf = StratifiedKFold(n_splits=5)","21f1af9f":"k_dash_fold = 0\nresults = []\n\nfor train_index, test_index in skf.split(X,y):\n    \n    k_dash_fold +=1\n    \n    train_X = X[train_index, :]\n    train_y = y[train_index]\n    test_X = X[train_index, :]\n    test_y = y[train_index]\n\n    for k in range(1,12):\n        result_dict = {}\n        \n        model = KNeighborsClassifier(n_neighbors=k)\n        model.fit(train_X,train_y)\n        preds = model.predict(test_X)\n        score = accuracy_score(test_y,preds)\n        result_dict['k_dash'] = k_dash_fold\n        result_dict['k'] = k\n        result_dict['accuracy'] = score\n        results.append(result_dict)\n        \n    \nresult_df = pd.DataFrame(results)\nresult_df","d8348347":"result_df.groupby('k')['accuracy'].mean()","db69f8c4":"#1. get the data\n\nX,y = load_iris(return_X_y=True)\n\nprint(X.shape)\nprint(y.shape)","1cdd1818":"#split into train and test \ndTrain_x,test_X, dTrain_y,  test_y = train_test_split(X, y , test_size = 0.2, random_state = 24 )\n\n","dee34b98":"#split into train and validation\n\nk_dash_fold = 0\nresults = []\n\nfor train_index, test_index in skf.split(X,y):\n    \n    k_dash_fold +=1\n    \n    train_X = X[train_index, :]\n    train_y = y[train_index]\n    valid_X = X[train_index, :]\n    valid_y = y[train_index]\n\n    for k in range(1,12):\n        result_dict = {}\n        \n        model = KNeighborsClassifier(n_neighbors=k)\n        model.fit(train_X,train_y)\n        preds = model.predict(valid_X)\n        score = accuracy_score(valid_y,preds)\n        result_dict['k_dash'] = k_dash_fold\n        result_dict['k'] = k\n        result_dict['accuracy'] = score\n        results.append(result_dict)\n        \n    \nresult_df = pd.DataFrame(results)\n\nresult_df.groupby('k')['accuracy'].mean()","ac067d4a":"#Accuracy and K Graph\nsns.relplot(x='k',y='accuracy',data=result_df,kind=\"line\");","c1e01b1f":"#now to report accuracy we use k = 3\n\nfinal_model = KNeighborsClassifier(n_neighbors=3)\nfinal_model.fit(dTrain_x,dTrain_y)\npreds = final_model.predict(test_X)\n\nprint(\"The accuracy of the model is \", accuracy_score(test_y,preds))","29d0d051":"#Overfitting\n#Predicted same points on which training is done and takes the all the points as majority .\nfinal_model = KNeighborsClassifier(n_neighbors=1) \nfinal_model.fit(X,y)\npreds = final_model.predict(X)\naccuracy_score(y,preds)","147326ac":"#Model that learn well from seen data and perform better on unseen data and that's why we divide our dataset \n#into Training set and Testing set and hypertune on Validation set.\n","9df34538":"#So KNN is a Lazy Learner algorithm and is not used in production due to it's time complexity and it takes large space.\n#Note: This is a technique which is not used industry-wide to choose the correct value of n_neighbors.\n#Instead, we do hyperparameter tuning to choose the value that gives the best performance.","f5c75d6e":"# Which model is best?","b0993df8":"# Training and Testing Accuracy Graphs\n","ff383d21":"# How to choose value of K?","d245b40a":"# Training and Testing Accuracy\n","881539ef":"# Why 100% accuracy is wrong?\n","9f39c9ee":"## K Fold Cross Validation\n### and problem with choosing K from test dataset so we choose Cross Validation","9f1a73e6":"### Why Overfitting?","163db894":"# Hyperparameter tuning on Validation set\n### and we have to choose the value of K before fitting the model","a43b0ee3":"# Hyperparameter tuning on test set","8e1c3cd9":"## Final way to do the things"}}