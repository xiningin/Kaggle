{"cell_type":{"9c59112d":"code","414332dd":"code","5eda4cf8":"code","7c97df45":"code","f903c1fb":"code","2524c9f8":"code","b3136b52":"code","61c8b1bc":"code","275f0f86":"code","d08c3a66":"code","ebd39cf3":"code","7fc0ec82":"code","9361c8bb":"code","cf6d1da7":"code","30ae1fdc":"code","c1807b66":"code","a14abc38":"code","b7c18aed":"code","fa496d83":"code","d1ac00da":"code","b3e71216":"code","b39d3b02":"code","fd16d66d":"code","c732e19a":"code","15568b99":"code","ba09a7e4":"code","ec44d227":"code","1ab6a682":"code","6f2e5369":"code","ad61c135":"code","52dfa7cc":"code","bafcf549":"code","5a716e69":"code","5698e090":"code","2ae767fa":"markdown"},"source":{"9c59112d":"%matplotlib inline\n%reload_ext autoreload\n%autoreload 2\nfrom fastai.structured import *\nfrom fastai.column_data import *","414332dd":"path='..\/input\/'","5eda4cf8":"new_transactions = pd.read_csv(f'{path}new_merchant_transactions.csv')\nnew_transactions.head()","7c97df45":"new_transactions['authorized_flag'] = new_transactions['authorized_flag']=='Y'","f903c1fb":"def aggregate_new_transactions(new_trans):    \n    agg_func = {\n        'authorized_flag': ['sum', 'mean'],\n        'merchant_id': ['nunique'],\n        'city_id': ['nunique'],\n        'purchase_amount': ['sum', 'median', 'max', 'min', 'std'],\n        'installments': ['sum', 'median', 'max', 'min', 'std'],\n        'month_lag': ['min', 'max']\n        }\n    agg_new_trans = new_trans.groupby(['card_id']).agg(agg_func)\n    agg_new_trans.columns = ['new_' + '_'.join(col).strip() \n                           for col in agg_new_trans.columns.values]\n    agg_new_trans.reset_index(inplace=True)\n    \n    df = (new_trans.groupby('card_id')\n          .size()\n          .reset_index(name='new_transactions_count'))\n    \n    agg_new_trans = pd.merge(df, agg_new_trans, on='card_id', how='left')\n    \n    return agg_new_trans\n\nnew_trans = aggregate_new_transactions(new_transactions)\nnew_trans.head()","2524c9f8":"del new_transactions","b3136b52":"historical_transactions = pd.read_csv('..\/input\/historical_transactions.csv')\nhistorical_transactions.head()","61c8b1bc":"historical_transactions['authorized_flag'] = historical_transactions['authorized_flag']=='Y'","275f0f86":"def aggregate_historical_transactions(history):\n    \n    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).\\\n                                      astype(np.int64) * 1e-9\n    \n    agg_func = {\n        'authorized_flag': ['sum', 'mean'],\n        'merchant_id': ['nunique'],\n        'city_id': ['nunique'],\n        'purchase_amount': ['sum', 'median', 'max', 'min', 'std'],\n        'installments': ['sum', 'median', 'max', 'min', 'std'],\n        'purchase_date': [np.ptp],\n        'month_lag': ['min', 'max']\n        }\n    agg_history = history.groupby(['card_id']).agg(agg_func)\n    agg_history.columns = ['hist_' + '_'.join(col).strip() \n                           for col in agg_history.columns.values]\n    agg_history.reset_index(inplace=True)\n    \n    df = (history.groupby('card_id')\n          .size()\n          .reset_index(name='hist_transactions_count'))\n    \n    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n    \n    return agg_history\n\nhistory = aggregate_historical_transactions(historical_transactions)\nhistory.head()","d08c3a66":"del historical_transactions","ebd39cf3":"def read_data(input_file):\n    df = pd.read_csv(input_file)\n    add_datepart(df,'first_active_month')\n    return df\ntrain = read_data('..\/input\/train.csv')\ntest = read_data('..\/input\/test.csv')\n\ntarget='target'\n","7fc0ec82":"train = pd.merge(train, history, on='card_id', how='left')\ntest = pd.merge(test, history, on='card_id', how='left')\n\ntrain = pd.merge(train, new_trans, on='card_id', how='left')\ntest = pd.merge(test, new_trans, on='card_id', how='left')","9361c8bb":"train=train.set_index('card_id')\ntest=test.set_index('card_id')","cf6d1da7":"cat_vars = [col  for col in train.columns if('feature' in col or 'first_active_month' in col)]\ncontin_vars = [col  for col in train.columns if ('feature' not in col and 'first_active_month' not in col) and target not in col]","30ae1fdc":"train = train[cat_vars+contin_vars+[target]].copy()\nn = len(train); n","c1807b66":"test[target] = 0\ntest = test[cat_vars+contin_vars+[target]].copy()","a14abc38":"for v in cat_vars: train[v] = train[v].astype('category').cat.as_ordered()\napply_cats(test, train)","b7c18aed":"for v in contin_vars:\n    train[v] = train[v].fillna(0).astype('float32')\n    test[v] = test[v].fillna(0).astype('float32')","fa496d83":"df, y, nas, mapper = proc_df(train, target, do_scale=True)\nn=len(df);n","d1ac00da":"df_test, _, nas, mapper = proc_df(test, target, do_scale=True, \n                                  mapper=mapper, na_dict=nas)","b3e71216":"train_ratio = 0.75\n# train_ratio = 0.9\ntrain_size = int(n * train_ratio); train_size\nval_idx = list(range(train_size, len(df)))","b39d3b02":"model_data = ColumnarModelData.from_data_frame('.', val_idx, df, y.astype(np.float32), cat_flds=cat_vars, bs=64,\n                                       test_df=df_test)","fd16d66d":"cat_sz = [(c, len(train[c].cat.categories)+1) for c in cat_vars]\nemb_szs = [(c, min(50, (c+1)\/\/2)) for _,c in cat_sz]\ny_range=(np.min(y),np.max(y))","c732e19a":"def rmse(y_pred, targ):\n    var = np.square(targ - y_pred)\n    return math.sqrt(var.mean())","15568b99":"model_data.get_learner??","ba09a7e4":"learn = model_data.get_learner(emb_szs, len(df.columns)-len(cat_vars),\n                   0.20, 1, [1000,500], [0.2,0.2], y_range=y_range,metrics=[rmse])","ec44d227":"learn.lr_find()\nlearn.sched.plot()","1ab6a682":"learn.fit(1e-3, 1,cycle_len=5,use_clr_beta=(10,10,0.95,0.85))\nlearn.sched.plot_loss()","6f2e5369":"learn.sched.plot_lr()","ad61c135":"x,y=learn.predict_with_targs()\nrmse(x,y)","52dfa7cc":"preds=learn.predict(is_test=True)","bafcf549":"submission=pd.read_csv(f'{path}\/sample_submission.csv',index_col='card_id')\nsubmission.loc[df_test.index]=preds","5a716e69":"submission.to_csv('submission.csv')","5698e090":"!head submission.csv","2ae767fa":"# Fastai based Mixed Input Model\nMy Idea here was to use the approach that succeded in the Rossman Kaggle challenge [see the fastai notebook here](https:\/\/github.com\/fastai\/fastai\/blob\/master\/courses\/dl1\/lesson3-rossman.ipynb)\nThe data loading and initial feature engineering I borrowed heavily from [YouHan Lees Kernel](https:\/\/www.kaggle.com\/youhanlee\/hello-elo-ensemble-will-help-you) and [Hyun woo kim](https:\/\/www.kaggle.com\/chocozzz\/simple-data-exploration-with-python-lb-3-764\/notebook)\nI think in this challenge the key thing is the feature engineering.\nHere I start with the model and use the borrowed feature engineering as a starting point.\nI might use these embedding layers to do the feature engineering on the new and historic transactions but as of Yet I'm not sure how to do it.\nSuggestions are always welcome\n"}}