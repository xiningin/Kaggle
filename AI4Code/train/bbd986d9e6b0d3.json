{"cell_type":{"a5b26cb4":"code","2f69785d":"code","366b5eed":"code","420eadbd":"code","be7f38b2":"code","dea7a51f":"code","b5ca5fa0":"code","7783e16b":"code","9152aad5":"code","8c48fd8e":"code","57fea3c8":"code","713c848a":"code","dc10aee4":"code","f2ed9350":"code","f23a0d9f":"code","6878812d":"code","3061bb1e":"code","c014b6d6":"code","1b70f58c":"code","31f3b0d1":"code","f28f782a":"code","ba7ea47a":"code","422a0180":"code","140f2ef3":"code","55a963ee":"code","a222024b":"code","c68f8014":"code","b86b29b8":"code","a7dced25":"code","390d462d":"code","b2ec445b":"code","9951734b":"code","7c912df5":"code","0de2cee5":"markdown","dc972b6d":"markdown","a9465fe6":"markdown","dabc3158":"markdown","4ef39006":"markdown","3772b813":"markdown","768db576":"markdown","5700358f":"markdown","93436598":"markdown","3ee9d474":"markdown","8c6693fb":"markdown","bd450f83":"markdown","512b9e29":"markdown","d5fbf110":"markdown"},"source":{"a5b26cb4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2f69785d":"import pandas as pd # data manipulation and processing\nimport numpy as np # linear algebra\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n%matplotlib inline","366b5eed":"from keras.models import Sequential\nfrom keras.layers import Dense , Dropout , Lambda, Flatten\nfrom keras.optimizers import Adam ,RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom keras import  backend as K\nfrom keras.preprocessing.image import ImageDataGenerator","420eadbd":"from subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output.","be7f38b2":"# Load train.csv file using pandas\ntrain = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)","dea7a51f":"# Let's check top 5 records\ntrain.head()","b5ca5fa0":"# Load test.csv file using pandas\ntest= pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)","7783e16b":"# Let's check top 5 records\ntest.head()","9152aad5":"X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')","8c48fd8e":"X_train","57fea3c8":"y_train","713c848a":"import seaborn as sns\nplt.figure(figsize=(8,4))\nsns.countplot(x='label', data=train);","dc10aee4":"#Convert train datset to (num_images, img_rows, img_cols) format \nX_train = X_train.reshape(X_train.shape[0], 28, 28)\n\nfor i in range(3, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i]);","f2ed9350":"#expand 1 more dimention as 1 for colour channel gray\nX_train = X_train.reshape(X_train.shape[0], 28, 28,1)\nX_train.shape","f23a0d9f":"X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\nX_test.shape","6878812d":"mean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)\/std_px","3061bb1e":"from keras.utils.np_utils import to_categorical\ny_train= to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes","c014b6d6":"plt.title(y_train[9])\nplt.plot(y_train[9])\nplt.xticks(range(10));","1b70f58c":"# fix random seed for reproducibility\nseed = 10\nnp.random.seed(seed)","31f3b0d1":"from keras.models import  Sequential\nfrom keras.layers.core import  Lambda , Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import BatchNormalization, Convolution2D , MaxPooling2D","f28f782a":"model= Sequential()\nmodel.add(Lambda(standardize,input_shape=(28,28,1)))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\nprint(\"input shape \",model.input_shape)\nprint(\"output shape \",model.output_shape)","ba7ea47a":"from keras.optimizers import RMSprop\nmodel.compile(optimizer=RMSprop(lr=0.001),\n loss='categorical_crossentropy',\n metrics=['accuracy'])","422a0180":"from keras.preprocessing import image\ngen = image.ImageDataGenerator()","140f2ef3":"from sklearn.model_selection import train_test_split\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=10)\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches=gen.flow(X_val, y_val, batch_size=64)","55a963ee":"history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3, \n                    validation_data=val_batches, validation_steps=val_batches.n)","a222024b":"history_dict = history.history\nhistory_dict.keys()","c68f8014":"from keras.layers import Convolution2D, MaxPooling2D\n\ndef get_cnn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Convolution2D(64,(3,3), activation='relu'),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Flatten(),\n        Dense(512, activation='relu'),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(), loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","b86b29b8":"model= get_cnn_model()\nmodel.optimizer.lr=0.01","a7dced25":"history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","390d462d":"from keras.layers.normalization import BatchNormalization\n\ndef get_bn_model():\n    model = Sequential([\n        Lambda(standardize, input_shape=(28,28,1)),\n        Convolution2D(32,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(32,(3,3), activation='relu'),\n        MaxPooling2D(),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        BatchNormalization(axis=1),\n        Convolution2D(64,(3,3), activation='relu'),\n        MaxPooling2D(),\n        Flatten(),\n        BatchNormalization(),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dense(10, activation='softmax')\n        ])\n    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","b2ec445b":"model= get_bn_model()\nmodel.optimizer.lr=0.01\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n                    validation_data=val_batches, validation_steps=val_batches.n)","9951734b":"model.optimizer.lr=0.01\ngen = image.ImageDataGenerator()\nbatches = gen.flow(X, y, batch_size=64)\nhistory=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)","7c912df5":"predictions = model.predict_classes(X_test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"Digit_Recog.csv\", index=False, header=True)","0de2cee5":"## Convolutional Neural Network (CNN)","dc972b6d":"### Compile network\nBefore making network ready for training we have to make sure to add below things:\n\nA loss function: to measure how good the network is\n\nAn optimizer: to update network as it sees more data and reduce loss value\n\nMetrics: to monitor performance of network","a9465fe6":"## 1. Import necessary libraries","dabc3158":"#### Feature Standardization\nIt is important preprocessing step. It is used to centre the data around zero mean and unit variance.","4ef39006":"Let's plot 10th label.","3772b813":"## 3. Data Visualization\nLets look at 6 images from data set with their labels.","768db576":"### ***One Hot encoding of labels.***\nA one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n\nFor example, 3 would be [0,0,0,1,0,0,0,0,0,0].","5700358f":"## 5. Designing Neural Network Architecture","93436598":"#### The output variable is an integer from 0 to 9. This is a multiclass classification problem.","3ee9d474":"## Adding Batch Normalization","8c6693fb":"### Submitting Predictions to Kaggle.","bd450f83":"### Cross Validation","512b9e29":"## 4. Data Preprocessing","d5fbf110":"## 2. Load train and test dataset"}}