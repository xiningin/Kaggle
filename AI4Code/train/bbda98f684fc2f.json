{"cell_type":{"d9c61124":"code","ce16f47b":"code","f461a4b7":"code","b5ef8f07":"code","1dec94b8":"code","b0e99c0c":"code","147215dd":"code","894f11a3":"code","e67a2347":"code","81a0ddcf":"code","18853522":"code","55a61a62":"code","48ade979":"code","1ab14939":"code","46968fe7":"code","7c58bb9a":"code","4062d467":"code","cab8dc7f":"markdown","2b39e31f":"markdown","9be05043":"markdown"},"source":{"d9c61124":"# Importando as bibliotecas\nimport os\nimport time\n\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import random_split, DataLoader\nfrom torch import nn, optim","ce16f47b":"# Verificando o diret\u00f3rio com as imagens\nimg_dir = \"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\"\nprint(os.listdir(img_dir))","f461a4b7":"# Temos GPU?\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)","b5ef8f07":"# Transforma\u00e7\u00f5es que ser\u00e3o aplicadas \u00e0s imagens\ntrain_transform = transforms.Compose([transforms.Resize((32, 32)),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),\n                                      transforms.RandomRotation(35),\n                                      transforms.RandomGrayscale(p=0.02),                                      \n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.5, 0.5, 0.5], \n                                                           [0.5, 0.5, 0.5])])\n","1dec94b8":"# Criando nossos conjuntos de dados com base nas imagens\ntrain = datasets.ImageFolder(img_dir, transform=train_transform)","b0e99c0c":"# Dividindo os dados em treino e teste\ntrain_data, test_data = random_split(train, (20000, 7558))","147215dd":"# Definindo os loaders\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=64, shuffle=True)","894f11a3":"# Definir LeNet5\n\n# C\u00e1lculo do tamanho da sa\u00edda de cada convolu\u00e7\u00e3o\n# outputOfEachConvLayer = [(size + 2*padding - kernel_size) \/ stride] + 1\n\nmodel = nn.Sequential(\n    # Primeira convolu\u00e7\u00e3o\n    nn.Conv2d(in_channels=3, out_channels=18, kernel_size=5, padding=0, stride=1),\n    # Fun\u00e7\u00e3o de ativa\u00e7\u00e3o\n    nn.Tanh(),\n    # Average Pooling\n    nn.AvgPool2d(kernel_size=2, stride=2),\n    \n    # Segunda convolu\u00e7\u00e3o\n    nn.Conv2d(in_channels=18, out_channels=48, kernel_size=5, padding=0, stride=1),\n    # Fun\u00e7\u00e3o de ativa\u00e7\u00e3o\n    nn.Tanh(),\n    # Average Pooling\n    nn.AvgPool2d(kernel_size=2, stride=2),\n    \n    # Convertendo a imagem em estrutura plana\n    nn.Flatten(),\n    \n    # Iniciando a rede fully connected\n    # in_features = 1200\n    nn.Linear(in_features=48*5*5, out_features=120),\n    nn.Tanh(),\n    nn.Linear(in_features=120, out_features=84),\n    nn.Tanh(),\n    nn.Linear(in_features=84, out_features=2)\n)\n\nmodel.to(device)","e67a2347":"# Temos que definir a fun\u00e7\u00e3o de erro e o otimizador (que vai alterar os pesos dos perceptrons)\nerror_function = nn.CrossEntropyLoss() # criterion\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nerror_function.to(device)","81a0ddcf":"# Treinamento do modelo\n\n# Definindo o n\u00famero de \u00e9pocas\nepochs = 10\n\n# Colocando o modelo em modo de treinamento\nmodel.train()\n\n\n# For para rodar o n\u00famero de \u00e9pocas\nfor i in range(epochs):\n    # Treinamento\n    \n    # Monitorando o training loss\n    train_loss = 0.0\n    \n    # Obtendo dados e respostas\n    for data, target in train_loader:\n        \n        # Enviando os dados para GPU, se existir\n        data, target = data.to(device), target.to(device)\n    \n        # Foward Propagation (passando os dados de treino pela rede)\n        outputs = model(data)\n        # Calculando o erro\n        loss = error_function(outputs, target)\n       \n        # Back Propagation\n        # Limpar os parametros do otimizador (zerar o Gradiente Descendent)\n        optimizer.zero_grad()\n        # Calcular os novos pesos\n        loss.backward()\n        # Executar o optimizador (efetivamente fazer o back propagation mudando os pesos)\n        optimizer.step()\n        \n        # Atualizando o training loss\n        train_loss += loss.item() * data.size(0)\n        \n    # Calculando a m\u00e9dia de erro por epoch\n    train_loss = train_loss\/len(train_loader.dataset)\n\n    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(i+1, train_loss))","18853522":"# Variaveis para controlar os acertos das previs\u00f5es da rede\n# e  calcular a acur\u00e1cia\ncorrect = 0\ntotal = 0\n\n# Vamos colocar o modelo em modo de avalia\u00e7\u00e3o\/teste\nmodel.eval()\n\n# Obtendo dados e respostas\nfor data, target in test_loader:\n    \n    # Enviando os dados para GPU, se existir\n    data, target = data.to(device), target.to(device)    \n    \n    output = model(data)\n    \n    for index, i in enumerate(output):\n        if torch.argmax(i) == target[index]:\n            correct += 1\n        total += 1","55a61a62":"print('Accuracy: ', round(correct\/total, 3))","48ade979":"# Transforma\u00e7\u00f5es que ser\u00e3o aplicadas \u00e0s imagens\nnew_transform = transforms.Compose([transforms.Resize((120, 120)),\n                                    transforms.RandomHorizontalFlip(),\n                                    transforms.RandomVerticalFlip(),\n                                    transforms.RandomRotation(35),\n                                    transforms.RandomGrayscale(p=0.02),                                      \n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.5, 0.5, 0.5], \n                                                         [0.5, 0.5, 0.5])])\n\n# Criando nossos conjuntos de dados com base nas imagens\ntrain = datasets.ImageFolder(img_dir, transform=new_transform)\n\n# Dividindo os dados em treino e teste\ntrain_data, test_data = random_split(train, (20000, 7558))\n\n# Definindo os loaders\ntrain_loader = DataLoader(train_data, batch_size=128, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=128, shuffle=True)","1ab14939":"# Definir nova rede CNN\n\n# C\u00e1lculo do tamanho da sa\u00edda de cada convolu\u00e7\u00e3o\n# outputOfEachConvLayer = [(size + 2*padding - kernel_size) \/ stride] + 1\n\nmodel = nn.Sequential(\n    # 120 x 120, 3 canais\n    \n    # Primeira convolu\u00e7\u00e3o\n    nn.Conv2d(in_channels=3, out_channels=18, kernel_size=5, padding=2, stride=1),\n    # Fun\u00e7\u00e3o de ativa\u00e7\u00e3o\n    nn.ReLU(),\n    # Max Pooling\n    nn.MaxPool2d(kernel_size=2, stride=2),\n    \n    # 60 x 60, 18 canais\n    \n    # Segunda convolu\u00e7\u00e3o\n    nn.Conv2d(in_channels=18, out_channels=48, kernel_size=5, padding=2, stride=1),\n    # Fun\u00e7\u00e3o de ativa\u00e7\u00e3o\n    nn.ReLU(),\n    # Max Pooling\n    nn.MaxPool2d(kernel_size=2, stride=2),\n    \n    # 30 x 30, 48 canais\n    \n    # Terceira convolu\u00e7\u00e3o\n    nn.Conv2d(in_channels=48, out_channels=144, kernel_size=5, padding=2, stride=1),\n    # Fun\u00e7\u00e3o de ativa\u00e7\u00e3o\n    nn.ReLU(),\n    # Max Pooling\n    nn.MaxPool2d(kernel_size=2, stride=2),  \n    \n    # 15 x 15, 144 canais\n    \n    # Convertendo a imagem em estrutura plana\n    nn.Flatten(),\n    \n    # Iniciando a rede fully connected\n    # in_features = 32400\n    nn.Linear(in_features=144*15*15, out_features=5200),\n    nn.ReLU(),\n    nn.Linear(in_features=5200, out_features=256),\n    nn.ReLU(),\n    nn.Linear(in_features=256, out_features=64),\n    nn.ReLU(),\n    nn.Linear(in_features=64, out_features=2)\n)\n\nmodel.to(device)","46968fe7":"# Temos que definir a fun\u00e7\u00e3o de erro e o otimizador (que vai alterar os pesos dos perceptrons)\nerror_function = nn.CrossEntropyLoss() # criterion\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n\nerror_function.to(device)","7c58bb9a":"# Treinamento do modelo\n\n# Definindo o n\u00famero de \u00e9pocas\nepochs = 10\n\n# Colocando o modelo em modo de treinamento\nmodel.train()\n\n\n# For para rodar o n\u00famero de \u00e9pocas\nfor i in range(epochs):\n    # Treinamento\n    \n    # Monitorando o training loss\n    train_loss = 0.0\n    \n    # Obtendo dados e respostas\n    for data, target in train_loader:\n        \n        # Enviando os dados para GPU, se existir\n        data, target = data.to(device), target.to(device)\n    \n        # Foward Propagation (passando os dados de treino pela rede)\n        outputs = model(data)\n        # Calculando o erro\n        loss = error_function(outputs, target)\n       \n        # Back Propagation\n        # Limpar os parametros do otimizador (zerar o Gradiente Descendent)\n        optimizer.zero_grad()\n        # Calcular os novos pesos\n        loss.backward()\n        # Executar o optimizador (efetivamente fazer o back propagation mudando os pesos)\n        optimizer.step()\n        \n        # Atualizando o training loss\n        train_loss += loss.item() * data.size(0)\n        \n    # Calculando a m\u00e9dia de erro por epoch\n    train_loss = train_loss\/len(train_loader.dataset)\n\n    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(i+1, train_loss))","4062d467":"# Variaveis para controlar os acertos das previs\u00f5es da rede\n# e  calcular a acur\u00e1cia\ncorrect = 0\ntotal = 0\n\n# Vamos colocar o modelo em modo de avalia\u00e7\u00e3o\/teste\nmodel.eval()\n\n# Obtendo dados e respostas\nfor data, target in test_loader:\n    \n    # Enviando os dados para GPU, se existir\n    data, target = data.to(device), target.to(device)    \n    \n    output = model(data)\n    \n    for index, i in enumerate(output):\n        if torch.argmax(i) == target[index]:\n            correct += 1\n        total += 1\n        \nprint('Accuracy: ', round(correct\/total, 3))","cab8dc7f":"## Data Augumentation","2b39e31f":"## Tentando com uma nova rede CNN","9be05043":"# IESB - Graduacao - CIA035 - Malaria CNN\n## Vers\u00e3o 2"}}