{"cell_type":{"3cac51e8":"code","f0a9c39e":"code","5dd4fb3d":"code","c30c6d98":"code","70f476b1":"code","d742f72f":"code","b5fe729c":"code","3354bb39":"code","146cdff2":"code","77dd6c71":"code","2c3c5d85":"code","6d2f2c6b":"code","249cd84f":"code","ac25213b":"code","a260bc7b":"code","ec4c709b":"code","28ed4c42":"code","5148a4be":"code","06752b71":"code","b0b87e6c":"code","f56665a4":"code","21f26146":"code","062941f4":"code","abfcdbbc":"code","e3be3968":"code","e446095b":"code","6a5b7bb8":"code","07908efe":"code","1756a855":"code","28d24ada":"code","b58183a6":"code","e8f26eea":"markdown","82434dbc":"markdown","e4ad57ea":"markdown","96619af3":"markdown","a01c3200":"markdown","23de2fc6":"markdown","f56a3026":"markdown","ae9a2aff":"markdown","0cc3d4af":"markdown","908897b3":"markdown","5f0be5f1":"markdown","c4d8846d":"markdown","8a8d1d27":"markdown","3be6a28f":"markdown","28f0182d":"markdown","e192fb8d":"markdown","f49274a0":"markdown","44db9e4d":"markdown","6899083b":"markdown","4f91b8e7":"markdown","2b6bef44":"markdown","103b57cc":"markdown","83e8e823":"markdown","adb99285":"markdown","693d82cd":"markdown","818d29a9":"markdown"},"source":{"3cac51e8":"# Import main libraries necessary for this project\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\n# Import libraries needed for reading image and processing it\nimport csv\nfrom PIL import Image\nfrom scipy.ndimage import rotate\n\n# Pretty display for notebooks\n%matplotlib inline","f0a9c39e":"# Training letters images and labels files\nletters_training_images_file_path = \"..\/input\/ahcd1\/csvTrainImages 13440x1024.csv\"\nletters_training_labels_file_path = \"..\/input\/ahcd1\/csvTrainLabel 13440x1.csv\"\n# Testing letters images and labels files\nletters_testing_images_file_path = \"..\/input\/ahcd1\/csvTestImages 3360x1024.csv\"\nletters_testing_labels_file_path = \"..\/input\/ahcd1\/csvTestLabel 3360x1.csv\"\n\n# Loading dataset into dataframes\ntraining_letters_images = pd.read_csv(letters_training_images_file_path, header=None)\ntraining_letters_labels = pd.read_csv(letters_training_labels_file_path, header=None)\ntesting_letters_images = pd.read_csv(letters_testing_images_file_path, header=None)\ntesting_letters_labels = pd.read_csv(letters_testing_labels_file_path, header=None)\n\n# print statistics about the dataset\nprint(\"There are %d training arabic letter images of 32x32 pixels.\" %training_letters_images.shape[0])\nprint(\"There are %d testing arabic letter images of 32x32 pixels.\" %testing_letters_images.shape[0])\ntraining_letters_images.head()","5dd4fb3d":"def convert_values_to_image(image_values, display=False):\n    image_array = np.asarray(image_values)\n    image_array = image_array.reshape(32,32).astype('uint8')\n    # The original dataset is reflected so we will flip it then rotate for a better view only.\n    image_array = np.flip(image_array, 0)\n    image_array = rotate(image_array, -90)\n    new_image = Image.fromarray(image_array)\n    if display == True:\n        new_image.show()\n    return new_image","c30c6d98":"convert_values_to_image(training_letters_images.loc[0], True)","70f476b1":"training_letters_images_scaled = training_letters_images.values.astype('float32')\/255\ntraining_letters_labels = training_letters_labels.values.astype('int32')\ntesting_letters_images_scaled = testing_letters_images.values.astype('float32')\/255\ntesting_letters_labels = testing_letters_labels.values.astype('int32')","d742f72f":"print(\"Training images of letters after scaling\")\nprint(training_letters_images_scaled.shape)\ntraining_letters_images_scaled[0:5]","b5fe729c":"from keras.utils import to_categorical\n\n# one hot encoding\n# number of classes = 28 (arabic alphabet classes)\nnumber_of_classes = 28\n\ntraining_letters_labels_encoded = to_categorical(training_letters_labels-1, num_classes=number_of_classes)\ntesting_letters_labels_encoded = to_categorical(testing_letters_labels-1, num_classes=number_of_classes)","3354bb39":"print(training_letters_labels_encoded)","146cdff2":"# reshape input letter images to 32x32x1\ntraining_letters_images_scaled = training_letters_images_scaled.reshape([-1, 32, 32, 1])\ntesting_letters_images_scaled = testing_letters_images_scaled.reshape([-1, 32, 32, 1])\n\nprint(training_letters_images_scaled.shape, training_letters_labels_encoded.shape, testing_letters_images_scaled.shape, testing_letters_labels_encoded.shape)","77dd6c71":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense\n\ndef create_model(optimizer='adam', kernel_initializer='he_normal', activation='relu'):\n    # create model\n    model = Sequential()\n    model.add(Conv2D(filters=16, kernel_size=3, padding='same', input_shape=(32, 32, 1), kernel_initializer=kernel_initializer, activation=activation))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer=kernel_initializer, activation=activation))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer=kernel_initializer, activation=activation))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer=kernel_initializer, activation=activation))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=2))\n    model.add(Dropout(0.2))\n    model.add(GlobalAveragePooling2D())\n\n    #Fully connected final layer\n    model.add(Dense(28, activation='softmax'))\n\n    # Compile model\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n    return model","2c3c5d85":"model = create_model()\nmodel.summary()","6d2f2c6b":"import pydot\nfrom keras.utils import plot_model\n\nplot_model(model, to_file=\"model.png\", show_shapes=True)\nfrom IPython.display import Image as IPythonImage\ndisplay(IPythonImage('model.png'))","249cd84f":"# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)\n\n# define the grid search parameters\noptimizer = ['RMSprop', 'Adam', 'Adagrad', 'Nadam']\nkernel_initializer = ['normal', 'uniform']\nactivation = ['relu', 'linear', 'tanh']\n\nparam_grid = dict(optimizer=optimizer, kernel_initializer=kernel_initializer, activation=activation)\n\n# count number of different parameters values combinations\nparameters_number = 1\nfor x in param_grid:\n    parameters_number = parameters_number * len(param_grid[x]) \nprint(\"Number of different parameter combinations = {}\".format(parameters_number))","ac25213b":"epochs = 5\nbatch_size = 20 # 20 divides the training data samples\n\n#creating the models with different hyperparameters\nfor a,b,c in [(x,y,z) for x in optimizer for z in activation for y in kernel_initializer]:\n    params = {'optimizer' : a , 'kernel_initializer' : b , 'activation' : c}\n    print(params)\n    curr_model = create_model(a, b, c)\n    curr_model.fit(training_letters_images_scaled, training_letters_labels_encoded, \n                    validation_data=(testing_letters_images_scaled, testing_letters_labels_encoded),\n                    epochs=epochs, batch_size=batch_size, verbose=1)\n    print(\"=============================================================================\")","a260bc7b":"model = create_model(optimizer='Adam', kernel_initializer='uniform', activation='relu')\n","ec4c709b":"from keras.callbacks import ModelCheckpoint  \n\n# using checkpoints to save model weights to be used later instead of training again on the same epochs.\ncheckpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\nhistory = model.fit(training_letters_images_scaled, training_letters_labels_encoded, \n                    validation_data=(testing_letters_images_scaled, testing_letters_labels_encoded),\n                    epochs=15, batch_size=20, verbose=1, callbacks=[checkpointer])","28ed4c42":"import matplotlib.pyplot as plt\n\ndef plot_loss_accuracy(history):\n    # Loss Curves\n    plt.figure(figsize=[8,6])\n    plt.plot(history.history['loss'],'r',linewidth=3.0)\n    plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n    plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n    plt.xlabel('Epochs ',fontsize=16)\n    plt.ylabel('Loss',fontsize=16)\n    plt.title('Loss Curves',fontsize=16)\n\n    # Accuracy Curves\n    plt.figure(figsize=[8,6])\n    plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n    plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n    plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n    plt.xlabel('Epochs ',fontsize=16)\n    plt.ylabel('Accuracy',fontsize=16)\n    plt.title('Accuracy Curves',fontsize=16) ","5148a4be":"plot_loss_accuracy(history)","06752b71":"model.load_weights('weights.hdf5')","b0b87e6c":"# Final evaluation of the model\nmetrics = model.evaluate(testing_letters_images_scaled, testing_letters_labels_encoded, verbose=1)\nprint(\"Test Accuracy: {}\".format(metrics[1]))\nprint(\"Test Loss: {}\".format(metrics[0]))","f56665a4":"epochs = 30\nbatch_size = 20\n\ncheckpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\n\nhistory = model.fit(training_letters_images_scaled, training_letters_labels_encoded, \n                    validation_data=(testing_letters_images_scaled, testing_letters_labels_encoded),\n                    epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[checkpointer])\n          \nmodel.load_weights('weights.hdf5')\nplot_loss_accuracy(history)","21f26146":"plot_loss_accuracy(history)","062941f4":"# Final evaluation of the model\nmetrics = model.evaluate(testing_letters_images_scaled, testing_letters_labels_encoded, verbose=1)\nprint(\"Test Accuracy: {}\".format(metrics[1]))\nprint(\"Test Loss: {}\".format(metrics[0]))","abfcdbbc":"from keras.models import model_from_yaml\nmodel_yaml = model.to_yaml()\nwith open(\"model.yaml\", \"w\") as yaml_file:\n    yaml_file.write(model_yaml)","e3be3968":"# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","e446095b":"# load YAML and create model\nyaml_file = open('model.yaml', 'r')\nloaded_model_yaml = yaml_file.read()\nyaml_file.close()\nloaded_model = model_from_yaml(loaded_model_yaml)\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")\n \n# compile the loaded model\nloaded_model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])","6a5b7bb8":"def get_predicted_classes(model, data, labels=None):\n    image_predictions = model.predict(data)\n    predicted_classes = np.argmax(image_predictions, axis=1)\n    true_classes = np.argmax(labels, axis=1)\n    return predicted_classes, true_classes, image_predictions","07908efe":"from sklearn.metrics import classification_report\n\ndef get_classification_report(y_true, y_pred):\n    print(classification_report(y_true, y_pred))","1756a855":"y_pred, y_true, image_predictions = get_predicted_classes(model, testing_letters_images_scaled, testing_letters_labels_encoded)\nget_classification_report(y_true, y_pred)","28d24ada":"errors = (y_pred - y_true != 0)\n\n\nY_pred_classes_errors = y_pred[errors]\nY_pred_errors = image_predictions[errors]\nY_true_errors = y_true[errors]\nX_val_errors = testing_letters_images_scaled[errors]\n\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            \n            image_array = img_errors[error]\n            image_array = np.flip(image_array, 0)\n            image_array = rotate(image_array, -90)\n            \n            \n            ax[row,col].imshow((image_array).reshape((32,32)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted letters\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","b58183a6":"fig = plt.figure(0, figsize=(18,18))\nindices = np.random.randint(0, testing_letters_labels.shape[0], size=49)\ny_pred = np.argmax(model.predict(training_letters_images_scaled), axis=1)\n\nfor i, idx in enumerate(indices):\n    plt.subplot(7,7,i+1)\n        \n    image_array = training_letters_images_scaled[idx][:,:,0]\n    image_array = np.flip(image_array, 0)\n    image_array = rotate(image_array, -90)\n       \n    plt.imshow(image_array, cmap='gray')\n    plt.title(\"Pred: {} - Label: {}\".format(y_pred[idx], (training_letters_labels[idx] -1)))\n    plt.xticks([])\n    plt.yticks([])\nplt.show()","e8f26eea":"## Saving the Final Model\n#### Let's save the model on json format to be used later instead of creating the model again from scratch.","82434dbc":"### We get test accuracy of 95.14% after training on 10 epochs only\n\n#### What about increasing the epochs we train on ?","e4ad57ea":"****\n## Predict Image Classes\n<strong>Making a method which takes a model, data and its true labels (optional for using in testing). Then it gives the predicted classes of the given data using the given model.<\/strong>","96619af3":"# Arabic Handwritten Characters Recognition\n#### In this project we will employ deep learning model to classify the images to an arabic letter.\n\n## Dataset\n#### The dataset for this project originates from kaggle kernels which include [Arabic Letters](http:\/\/https:\/\/www.kaggle.com\/mloey1\/ahcd1).\n#### All the datasets are CSV files representing the image pixels values and their corresponding label.\n\n**Arabic Letters Dataset is composed of 16,800 characters written by 60 participants,** the age range is between 19 to 40 years, and 90% of participants are right-hand. Each participant wrote each character (from 'alef' to 'yeh') ten times. The images were scanned at the resolution of 300 dpi. Each block is segmented automatically using Matlab 2016a to determining the coordinates for each block. **The dataset is partitioned into two sets: a training set of 13,440 characters to 480 images per class and a test set of 3,360 characters to 120 images per class.** Writers of training set and test set are exclusive. Ordering of including writers to test set are randomized to make sure that writers of test set are not from a single institution to ensure variability of the test set.\n\n\n## Data Exploration\n#### Import libraries necessary for this project.\n","a01c3200":"#### if we want to load the model with the last obtained weights at anytime, we will run the following code cell.","23de2fc6":"<strong>From the above results we can see that best parameters are:\n* Optimizer: Adam\n* Kernel_initializer: uniform\n* Activation: relu\n<\/strong>\n<br\/>\nLet's create the model with the best parameters obtained.","f56a3026":"## Designing Model Architecture","ae9a2aff":"**We will try different models with different parameters to find the best parameter values.**","0cc3d4af":"#### Making a method which will print all metrics (precision, recall, f1-score and support) with each class in the dataset.","908897b3":"#### Save the model weights to file.","5f0be5f1":"### Load the Model with the Best Validation Loss","c4d8846d":"## Encoding Categorical Labels\n#### From the labels csv files we can see that labels are categorical values and it is a multi-class classification problem.\n**the outputs are in the form of:\nLetters from 'alef' to 'yeh' have categories numbers from 0 to 27**<br\/>\n### Here we will encode these categories values using One Hot Encoding with keras.\n\nOne-hot encoding transforms integer to a binary matrix where the array contains only one \u20181\u2019 and the rest elements are \u20180\u2019.","8a8d1d27":"## Data Preprocessing\n### Image Normalization <br\/>\n**We rescale the images by dividing every pixel in the image by 255 to make them into range [0, 1]","3be6a28f":"## Reshaping Input Images to 32x32x1\nWhen using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape (nb_samples,rows,columns,channels)\n\nwhere nb_samples corresponds to the total number of images (or samples), and rows, columns, and channels correspond to the number of rows, columns, and channels for each image, respectively.\n\nSo we will reshape the input images to a 4D tensor with shape (nb_samples, 32, 32 ,1) as we use grayscale images of 32x32 pixels.","28f0182d":"## Plotting Loss and Accuracy Curves with Epochs","e192fb8d":"**above code step by step.**\n\n* The first hidden layer is a convolutional layer. The layer has 16 feature maps, which with the size of 3\u00d73 and an activation function which is relu. This is the input layer, expecting images with the structure outlined above.\n* The second layer is Batch Normalization which solves having distributions of the features vary across the training and test data, which breaks the IID assumption. We use it to help in two ways faster learning and higher overall accuracy.\n* The third layer is the MaxPooling layer. MaxPooling layer is used to down-sample the input to enable the model to make assumptions about the features so as to reduce overfitting. It also reduces the number of parameters to learn, reducing the training time.\n* The next layer is a Regularization layer using dropout. It is configured to randomly exclude 20% of neurons in the layer in order to reduce overfitting.\n* Another hidden layer with 32 feature maps with the size of 3\u00d73 and a relu activation function to capture more features from the image.\n* Other hidden layers with 64 and 128 feature maps with the size of 3\u00d73 and a relu activation function to capture complex patterns from the image which will decribe the digits and letters later.\n* More MaxPooling, Batch Normalization, Regularization and GlobalAveragePooling2D layers.\n* The last layer is the output layer with (number of output classes) and it uses softmax activation function as we have multi-classes. Each neuron will give the probability of that class.\n* I used categorical_crossentropy as a loss function because its a multi-class classification problem. I used accuracy as metrics to improve the performance of our neural network.","f49274a0":"#### Load Arabic Letters dataset files into dataframes","44db9e4d":"Convert csv values to an image\nWritting a method to be used later if we want visualization of an image from its pixels values.","6899083b":"**Keras support plotting the model in keras.utils.vis_utils module which provides utility functions to plot a Keras model using graphviz.**","4f91b8e7":"## Test the Model","2b6bef44":"## Training the Model\n### Fitting the Model\n<strong>Train the model using batch_size=30 to reduce used memory and make the training more quick. We will train the model first on 15 epochs to see the accuracy that we will obtain<\/strong>","103b57cc":"## Model Summary And Visualization","83e8e823":"## Parameters Tuning","adb99285":"#from subprocess import check_output\n#print(check_output([\"ls\", \"..\/input\/0ae19-030\"]).decode(\"utf8\"))\n\nfrom PIL import Image\njpgfile1 = Image.open(\"..\/input\/0ae19-030\/char00.jpg\")\njpgfile2 = Image.open(\"..\/input\/0ae19-030\/char01.jpg\")\njpgfile3 = Image.open(\"..\/input\/0ae19-030\/char02.jpg\")\njpgfile4 = Image.open(\"..\/input\/0ae19-030\/char10.jpg\")\njpgfile5 = Image.open(\"..\/input\/0ae19-030\/char11.jpg\")\njpgfile6 = Image.open(\"..\/input\/0ae19-030\/char12.jpg\")\n\nlst_image = [jpgfile1,jpgfile2,jpgfile3,jpgfile4,jpgfile5,jpgfile6]\n\n#for i in lst_image:\n    ","693d82cd":"## Testing the Model again","818d29a9":"After training the model on more epochs we gained a better model which can classify complex patterns. So when we tested it on our test dataset we had better results than before.\n\n**Test accuracy is improved from 95.14% to 97.47% As we train the model on 20 more epochs.**"}}