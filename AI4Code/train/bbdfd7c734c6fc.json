{"cell_type":{"f10ca8c7":"code","88d7ce73":"code","210fe266":"code","e0523387":"code","2104615a":"code","686f7184":"code","248752e9":"code","9f4b18bc":"code","c120ac4e":"code","14d91b89":"code","654a543f":"code","bcef4ced":"code","af73e595":"code","33553217":"code","3289cb9f":"code","42d88c55":"code","8dea20b8":"code","86912c2c":"code","9ace93d8":"code","c57da398":"code","f9698a14":"code","7d41a8e5":"code","077190cf":"code","4e9185e8":"code","32bb2069":"code","e32b147f":"code","4378f505":"code","c0433107":"code","9e5c2429":"code","1920c57c":"code","fe8cbfc4":"code","95001366":"code","743ff90b":"code","2ef5e354":"code","57a33fd4":"code","e56102c7":"code","189da811":"code","2aca49d4":"code","a9045229":"code","18e32cb2":"code","0f25938b":"code","cfc5efe6":"code","745a1bb3":"code","92bb16a9":"code","14344dc6":"code","f3f04e27":"code","5216ee9c":"code","90127c2f":"code","a0d4e567":"code","6db71bfe":"code","3320f42a":"code","89496147":"code","cb512f7d":"code","f570173f":"markdown","b0c60088":"markdown","090cbeab":"markdown","32c7fce6":"markdown","d3fd1d7a":"markdown","8394b38f":"markdown","e231739d":"markdown","31a90ab9":"markdown","40aae554":"markdown","e2172ae3":"markdown","a5965244":"markdown","8ccca413":"markdown","9c59a443":"markdown","cb55fc0e":"markdown","b5971335":"markdown","324734f8":"markdown","0e0b5bb4":"markdown","ffa029fe":"markdown","5f602b11":"markdown","c464420c":"markdown","29f61092":"markdown","b94cfa52":"markdown","e4ee7abf":"markdown","a628574d":"markdown","c4673f00":"markdown","e8809a2c":"markdown","c192d38f":"markdown","35f337d4":"markdown","86cbf264":"markdown","787dcd77":"markdown","b3bdffe1":"markdown","2fa6c79f":"markdown","a25dc59c":"markdown","7e3bf7ba":"markdown"},"source":{"f10ca8c7":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,KFold,cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nimport plotly.express as px\nimport warnings\nwarnings.filterwarnings(\"ignore\")","88d7ce73":"df=pd.read_csv(r'..\/input\/credit-card-default-data\/Credit Card Default Data.csv')\ndf.head()","210fe266":"df.drop([\"Unnamed: 0\"],axis=1,inplace=True)","e0523387":"df.shape","2104615a":"df.info()","686f7184":"df.describe()","248752e9":"a=df.isna().sum()\/len(df)*100","9f4b18bc":"a.rename_axis('Columns').reset_index(name='Percentage of Null values')","c120ac4e":"sns.boxplot(data=df,x='balance')\nplt.show()","14d91b89":"sns.boxplot(data=df,x='income')\nplt.show()","654a543f":"px.scatter(data_frame=df,x='balance',y='income',color='default')","bcef4ced":"px.box(df,x='default',y='balance',color_discrete_sequence=[\"red\"])","af73e595":"px.box(df,x='default',y='balance',color_discrete_sequence=[\"navy\"])","33553217":"px.box(df,x='student',y='balance',color_discrete_sequence=[\"aqua\"])","3289cb9f":"num_col=df[df.dtypes[df.dtypes!='object'].index]\nfor i in num_col.columns:\n    sns.kdeplot(num_col[i],shade=True)\n    plt.show()","42d88c55":"df['default']=df['default'].replace('Yes',1).replace('No',0)","8dea20b8":"df.head()","86912c2c":"df=pd.get_dummies(df,columns=['student'],drop_first=True)","9ace93d8":"df.head()","c57da398":"heat=df.corr().loc['default'].sort_values(ascending=False)","f9698a14":"plt.figure(figsize=(8,8))\nsns.heatmap(heat.to_frame(),annot=True,cmap='gist_earth')\nplt.show()","7d41a8e5":"sns.pairplot(df,hue='default',diag_kind='kde',palette='husl')\nplt.show()","077190cf":"X=df.drop(['default'],axis=1)\ny=df['default']","4e9185e8":"sc=StandardScaler()\nnum_sc=sc.fit_transform(X)\nnum_sc=pd.DataFrame(num_sc,columns=X.columns)\nnum_sc.head()","32bb2069":"xtrain,xtest,ytrain,ytest=train_test_split(num_sc,y,test_size=0.3,random_state=48,stratify=y)","e32b147f":"log_reg=LogisticRegression()\nlog_reg.fit(xtrain,ytrain)","4378f505":"from sklearn.metrics import accuracy_score","c0433107":"ypred_test=log_reg.predict(xtest)\ntest_accuracy=accuracy_score(ytest,ypred_test)\ntest_accuracy","9e5c2429":"ypred_train=log_reg.predict(xtrain)\ntrain_accuracy=accuracy_score(ytrain,ypred_train)\ntrain_accuracy","1920c57c":"from sklearn import metrics","fe8cbfc4":"metrics.confusion_matrix(ytrain,ypred_train)","95001366":"metrics.confusion_matrix(ytest,ypred_test)","743ff90b":"report=metrics.classification_report(ytest,ypred_test,output_dict=True)","2ef5e354":"pd.DataFrame(report).transpose()","57a33fd4":"from sklearn.metrics import roc_curve,auc","e56102c7":"ypred_proba=log_reg.predict_proba(xtest)[:,1]","189da811":"fpr,tpr,threshold=roc_curve(ytest,ypred_proba)","2aca49d4":"plt.plot(fpr,tpr)\nplt.plot([0,1],[0,1])\nplt.xlabel('alpha\/false positive rate\/(1-specificty)')\nplt.ylabel('True Positive rate')\nplt.show()","a9045229":"lr=LogisticRegression()\nkf=KFold(n_splits=5,shuffle=True,random_state=0)\nauc=cross_val_score(lr,num_sc,y,cv=kf,scoring='roc_auc')\nlogreg_be=np.mean(1-auc)\nlogreg_ve=np.std(auc)\nprint('Bias error for logistic regression is',logreg_be)\nprint('Variance error for logistic regression is',logreg_ve)","18e32cb2":"from sklearn.model_selection import GridSearchCV","0f25938b":"knn=KNeighborsClassifier()\nparams={\"n_neighbors\":np.arange(1,100),\"weights\":['uniform','distance']}\nkf=KFold(n_splits=5,shuffle=True,random_state=0)\ngs=GridSearchCV(knn,param_grid=params,cv=kf,scoring='roc_auc')\ngs.fit(xtrain,ytrain)","cfc5efe6":"gs.best_params_","745a1bb3":"knn=KNeighborsClassifier(n_neighbors=92,weights='uniform')\nkf=KFold(n_splits=5,shuffle=True,random_state=0)\nauc=cross_val_score(knn,num_sc,y,cv=kf,scoring='roc_auc')\nknn_be=np.mean(1-auc)\nknn_ve=np.std(auc)\nprint('Bias error for kneighbors is',knn_be)\nprint('Varaince error for Kneighbors is',knn_ve)\nprint('KNN performed poorly because it paid a price in terms of variance that was not offset by a reduction in bias.')","92bb16a9":"from sklearn.ensemble import BaggingClassifier,RandomForestClassifier,GradientBoostingClassifier","14344dc6":"knn=KNeighborsClassifier(n_neighbors=92,weights='uniform')\nKNN_ve=[]                                                       #Customised grid search cv\nKNN_be=[]\nfor n in np.arange(1,100):\n    KNN_bag=BaggingClassifier(base_estimator=knn,n_estimators=n,random_state=0)\n    kf=KFold(shuffle=True,n_splits=5,random_state=0)\n    auc=cross_val_score(KNN_bag,num_sc,y,cv=kf,scoring='roc_auc')\n    KNN_be.append(np.mean(1-auc))\n    KNN_ve.append(np.std(auc))","f3f04e27":"np.min(KNN_ve),np.argmin(KNN_ve)","5216ee9c":"x_axis=np.arange(len(KNN_ve))\nplt.plot(x_axis,KNN_ve)\nplt.xlabel('length of variance error')\nplt.ylabel('Variance error')\nplt.show()","90127c2f":"rf=RandomForestClassifier(random_state=0)\nkf=KFold(n_splits=5,shuffle=True)\nauc=cross_val_score(rf,num_sc,y,cv=kf,scoring='roc_auc')\nrf_be=np.mean(1-auc)\nrf_ve=np.std(auc)\nrf_be,rf_ve","a0d4e567":"RF_ve=[]\nRF_be=[]\nfor i in np.arange(1,100):\n    rf=RandomForestClassifier(n_estimators=i,criterion='entropy',random_state=0)\n    kf=KFold(n_splits=5,shuffle=True,random_state=0)\n    auc=cross_val_score(rf,num_sc,y,cv=kf,scoring='roc_auc')\n    RF_be.append(np.mean(1-auc))\n    RF_ve.append(np.std(auc))","6db71bfe":"x_axis=np.arange(len(RF_be))\nplt.plot(x_axis,RF_ve,'b--')\nplt.xlabel('length of variance error')\nplt.ylabel('Variance error')\nplt.show()","3320f42a":"np.min(RF_ve),np.argmin(RF_ve)","89496147":"rf=RandomForestClassifier(n_estimators=24,criterion='entropy')\nkf=KFold(n_splits=5,shuffle=True)\nauc=cross_val_score(rf,num_sc,y,cv=kf,scoring='roc_auc')\nrf_be=np.mean(1-auc)\nrf_ve=np.std(auc)\nprint('Bias error for randomforest is',rf_be)\nprint('variance error for randomforest is',rf_ve)","cb512f7d":"lr=LogisticRegression()\nknn=KNeighborsClassifier(n_neighbors=92,weights='uniform')\nknn_bag=BaggingClassifier(knn,n_estimators=4,random_state=0)\nrf=RandomForestClassifier(n_estimators=24,criterion='entropy',random_state=0)\nmodels=[]\nmodels.append(('logistic_reg',lr))\nmodels.append(('k-neighbors classifier',knn))\nmodels.append(('Bagged K-neighbors classifier',knn_bag))\nmodels.append(('Randomforest classifier',rf))\nresults = []\nnames = []\nfor name, model in models:\n    kf=KFold(shuffle=True,n_splits=5,random_state=0)\n    cv_results=cross_val_score(model,num_sc,y,cv=kf,scoring='roc_auc')\n    results.append(cv_results)\n    names.append(name)\n    print(\"%s: %f (%f)\" % (name, np.mean(1-cv_results),np.std(cv_results,ddof=1)))\nfig = plt.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names,rotation=90)\nplt.show()","f570173f":"## Bagging for KNN","b0c60088":"## Income Vs Balance","090cbeab":"## Cross Validation for Logitic Regression","32c7fce6":"References-\n\n1.\"An Introduction to Statistical Learning, with applications in R\"  (Springer, 2013) with permission from the authors: G. James, D. Witten,  T. Hastie and R. Tibshirani \"","d3fd1d7a":"## Classification Report","8394b38f":"The annual incomes and monthly\ncredit card balances of a number of individuals. The individuals who defaulted on\ntheir credit card payments are shown in red, and those who did not are shown\nin blue.","e231739d":"Boxplots of balance as a function of default status.","31a90ab9":"# Univariate and Bivariate Anlaysis","40aae554":"## Boxplots","e2172ae3":"## Confusion Matrix","a5965244":"## Checking For Null Values","8ccca413":" we can use  linear regression model to represent\nthese probabilities:\np(X) = \u03b20 + \u03b21X. \nIf we use this approach to predict default=Yes using balance,then we see\nthe problem with this approach: for balances close to zero we predict a\nnegative probability of default; if we were to predict for very large balances,\nwe would get values bigger than 1. These predictions are not sensible, since\nof course the true probability of default, regardless of credit card balance,\nmust fall between 0 and 1. ","9c59a443":"## Categorical columns","cb55fc0e":"## RandomForest","b5971335":"We can see that for class 1 precision,recall and f1-score are not predicted as accurately as for class 0.\nUsing a threshold of 0.5,minimizes the overall error rate in logistic regression.\nHowever, How can we decide which threshold value is best? Such a decision must be based on domain knowledge, such as detailed\ninformation about the costs associated with default.","324734f8":"## Pairplot Analysis","0e0b5bb4":"In practice, a binary classifier such as this one can make two types of\nerrors: it can incorrectly assign an individual who defaults to the no default\ncategory, or it can incorrectly assign an individual who does not default to\nthe default category. It is often of interest to determine which of these two\ntypes of errors are being made. A confusion matrix, shown for the Default confusion\ndata is a convenient way to display this information.","ffa029fe":"## CUSTOMISED GRID SEARCH","5f602b11":"## Describing the data\/Checking the summary statistics","c464420c":"## Checking the Correlation","29f61092":"### Replacing the variables Yes and No in Target column with 1 and 0 for further analysis","b94cfa52":"The fact that students on the whole tend to have higher credit card\nbalances means that overall, students tend to default at a higher rate than\nnon-students. This is an important distinction for a credit card company\nthat is trying to determine to whom they should offer credit. ","e4ee7abf":"We can say that decision boundary is linear in nature thats why Logistic regression is a clear winner in terms of \nbias and variance error followed by bagged Kneighbors classifier and simple Kneigbors classifier.","a628574d":"## KNN Model","c4673f00":"## Splitting the data into train and test","e8809a2c":"## Scaling","c192d38f":"## Alogrithm Comparison","35f337d4":"Boxplots of income as a function of default status.","86cbf264":"## We are interested in predicting whether an individual will default on his or her credit card payment, on the basis of annual income and monthly credit card balance.","787dcd77":"**Since Accuracy score is not a good metric for classification we will be using confusion matrix to know our model.**","b3bdffe1":"## ROC Curve","2fa6c79f":"## Checking the shape","a25dc59c":"## Checking the Info","7e3bf7ba":"## Numerical Columns"}}