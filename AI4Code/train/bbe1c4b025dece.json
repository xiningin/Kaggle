{"cell_type":{"020abbd4":"code","2f8a29a3":"code","61b3a655":"code","6d5125a6":"code","cb958cd9":"code","711749a7":"code","cf9befd7":"code","1a77202f":"code","9db6672d":"code","ae06b598":"code","25c7943e":"code","ce28a5d0":"code","c5d12a54":"code","8403acdb":"code","0fe0f5d4":"code","4a83603c":"code","b5c6b158":"code","f0426fa2":"code","12f255bb":"code","7c394216":"code","c38f8691":"code","2e1d06e9":"code","3f405e78":"code","93c447a0":"code","aee13f68":"code","1e0833fa":"code","ace72d82":"code","14bd127d":"code","d93946e8":"markdown","03d15827":"markdown","14cbb8aa":"markdown","dd0f3de7":"markdown","85b6073d":"markdown","180dab75":"markdown","1077e03f":"markdown","d5ef7703":"markdown","e78004cc":"markdown","58de293d":"markdown","ecd22560":"markdown","d41f6e47":"markdown","2f208e76":"markdown","c38a3955":"markdown","8256dd62":"markdown"},"source":{"020abbd4":"# load packages\nfrom sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,HashingVectorizer\nfrom sklearn import decomposition, ensemble\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas, xgboost, numpy, textblob, string\nimport pandas as pd","2f8a29a3":"# load the dataset\ntrainDF = pd.read_csv('..\/input\/bbc-text.csv') # encoding = \"latin\"","61b3a655":"trainDF.head(10)","6d5125a6":"trainDF.shape","cb958cd9":"trainDF['category'].unique()","711749a7":"trainDF['category'].value_counts()","cf9befd7":"sns.set(rc={'figure.figsize':(10,10)})\nsns.countplot(trainDF['category'])","1a77202f":"# split the dataset into training and validation datasets \ntrain_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['category'])\n\ntrain_labels = train_y\nvalid_labels = valid_y\n# label encode the target variable \nencoder = preprocessing.LabelEncoder()\ntrain_y = encoder.fit_transform(train_y)\nvalid_y = encoder.fit_transform(valid_y)","9db6672d":"# Count Vectors as features\n# create a count vectorizer object \ncount_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\ncount_vect.fit(trainDF['text'])\n\n# transform the training and validation data using count vectorizer object\nxtrain_count =  count_vect.transform(train_x)\nxvalid_count =  count_vect.transform(valid_x)","ae06b598":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_count.toarray())\ndata2D = pca.transform(xtrain_count.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","25c7943e":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_count.toarray())\ndata2D = pca.transform(xvalid_count.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","ce28a5d0":"tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\ntfidf_vect.fit(trainDF['text'])\nxtrain_tfidf =  tfidf_vect.transform(train_x)\nxvalid_tfidf =  tfidf_vect.transform(valid_x)","c5d12a54":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_tfidf.toarray())\ndata2D = pca.transform(xtrain_tfidf.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","8403acdb":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_tfidf.toarray())\ndata2D = pca.transform(xvalid_tfidf.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","0fe0f5d4":"tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\ntfidf_vect_ngram.fit(trainDF['text'])\nxtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\nxvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)","4a83603c":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_tfidf_ngram.toarray())\ndata2D = pca.transform(xtrain_tfidf_ngram.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","b5c6b158":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_tfidf_ngram.toarray())\ndata2D = pca.transform(xvalid_tfidf_ngram.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","f0426fa2":"tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\ntfidf_vect_ngram_chars.fit(trainDF['text'])\nxtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \nxvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) ","12f255bb":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_tfidf_ngram_chars.toarray())\ndata2D = pca.transform(xtrain_tfidf_ngram_chars.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","7c394216":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_tfidf_ngram_chars.toarray())\ndata2D = pca.transform(xvalid_tfidf_ngram_chars.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","c38f8691":"# getting train features\nhash_vectorizer = HashingVectorizer(n_features=5000)\nhash_vectorizer.fit(trainDF['text'])\nxtrain_hash_vectorizer =  hash_vectorizer.transform(train_x) \nxvalid_hash_vectorizer =  hash_vectorizer.transform(valid_x)","2e1d06e9":"# plot the train features\npca = PCA(n_components=2).fit(xtrain_hash_vectorizer.toarray())\ndata2D = pca.transform(xtrain_hash_vectorizer.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=train_labels.tolist(),size=train_labels.tolist(),palette=\"husl\")","3f405e78":"# plot the validation features\npca = PCA(n_components=2).fit(xvalid_hash_vectorizer.toarray())\ndata2D = pca.transform(xvalid_hash_vectorizer.toarray())\ncmap = sns.cubehelix_palette(dark=.3, light=.8, as_cmap=True)\nax = sns.scatterplot(data2D[:,0], data2D[:,1],\nhue=valid_labels.tolist(),size=valid_labels.tolist(),palette=\"husl\")","93c447a0":"def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n    # fit the training dataset on the classifier\n    classifier.fit(feature_vector_train, label)\n    \n    # predict the labels on validation dataset\n    predictions = classifier.predict(feature_vector_valid)\n    \n    if is_neural_net:\n        predictions = predictions.argmax(axis=-1)\n    \n    return metrics.accuracy_score(predictions, valid_y)","aee13f68":"# Naive Bayes on Count Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\nprint(\"NB, Count Vectors: \", accuracy)\n\n# Naive Bayes on Word Level TF IDF Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\nprint(\"NB, WordLevel TF-IDF: \", accuracy)\n\n# Naive Bayes on Ngram Level TF IDF Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\nprint(\"NB, N-Gram Vectors: \", accuracy)\n\n# Naive Bayes on Character Level TF IDF Vectors\naccuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\nprint(\"NB, CharLevel Vectors: \", accuracy)","1e0833fa":"# Linear Classifier on Count Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_count, train_y, xvalid_count)\nprint(\"LR, Count Vectors: \", accuracy)\n\n# Linear Classifier on Word Level TF IDF Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_tfidf, train_y, xvalid_tfidf)\nprint(\"LR, WordLevel TF-IDF: \", accuracy)\n\n# Linear Classifier on Ngram Level TF IDF Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\nprint(\"LR, N-Gram Vectors: \", accuracy)\n\n# Linear Classifier on Character Level TF IDF Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\nprint(\"LR, CharLevel Vectors: \", accuracy)\n\n# Linear Classifier on Hash Vectors\naccuracy = train_model(linear_model.LogisticRegression(solver=\"lbfgs\",multi_class=\"auto\",max_iter=4000), xtrain_hash_vectorizer, train_y, xvalid_hash_vectorizer)\nprint(\"LR, Hash Vectors: \", accuracy)","ace72d82":"# RF on Count Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_count, train_y, xvalid_count)\nprint(\"RF, Count Vectors: \", accuracy)\n\n# RF on Word Level TF IDF Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_tfidf, train_y, xvalid_tfidf)\nprint(\"RF, WordLevel TF-IDF: \", accuracy)\n\n# RF on Ngram Level TF IDF Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\nprint(\"RF, N-Gram Vectors: \", accuracy)\n\n# RF on Character Level TF IDF Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\nprint(\"RF, CharLevel Vectors: \", accuracy)\n\n# RF on Hash Vectors\naccuracy = train_model(ensemble.RandomForestClassifier(n_estimators=10), xtrain_hash_vectorizer, train_y, xvalid_hash_vectorizer)\nprint(\"RF, Hash Vectors: \", accuracy)","14bd127d":"# Extreme Gradient Boosting on Count Vector\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\nprint(\"Xgb, Count Vectors: \", accuracy)\n\n# Extreme Gradient Boosting on Word Level TF IDF Vectors\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\nprint(\"Xgb, WordLevel TF-IDF: \", accuracy)\n\n# Extreme Gradient Boosting on Ngram Level TF IDF Vectors\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\nprint(\"Xgb, N-Gram Vectors: \", accuracy)\n\n# Extreme Gradient Boosting on Character Level TF IDF Vectors\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\nprint(\"Xgb, CharLevel Vectors: \", accuracy)\n\n# Extreme Gradient Boosting on Hash Vectors\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_hash_vectorizer, train_y, xvalid_hash_vectorizer)\nprint(\"Xgb, Hash Vectors: \", accuracy)","d93946e8":"### ngram level tf-idf ","03d15827":"### word level tf-idf","14cbb8aa":"### Linear Classifier","dd0f3de7":"### characters level tf-idf","85b6073d":" TF-IDF Vectors as features\n \n a. Word Level TF-IDF : Matrix representing tf-idf scores of every term in different documents\n \n b. N-gram Level TF-IDF : N-grams are the combination of N terms together. This Matrix representing tf-idf scores  of N-grams\n \n c. Character Level TF-IDF : Matrix representing tf-idf scores of character level n-grams in the corpus","180dab75":"### RandomForestClassifier","1077e03f":"### Count Vectors","d5ef7703":"## Model Building","e78004cc":"### HashingVectorizer","58de293d":"###  TF-IDF Vectors","ecd22560":"## Data preparation","d41f6e47":"## Feature Extraction","2f208e76":"### Naive Bayes","c38a3955":"### Extreme Gradient Boosting","8256dd62":"# BBC Text MultiClass Classification"}}