{"cell_type":{"33b5fe86":"code","01c72507":"code","6d786869":"code","431e16b5":"code","f59b0a98":"code","9db6e248":"code","03a587ec":"code","5c38cee9":"code","ffa32547":"code","0a849dfa":"code","8a4bbdf4":"code","25aadeee":"code","7121fbe8":"code","401d495a":"code","9c5470dc":"code","fc0f19ee":"code","4b6a9953":"code","0058536d":"code","956373ac":"code","00fa72ba":"code","1b92809a":"code","7247a38a":"code","8a9236a4":"code","6ae32d8f":"code","0d1280e7":"code","fc8fc7ef":"markdown","4386c670":"markdown","8b462784":"markdown","678b5b02":"markdown","031f07d5":"markdown","a2b6c261":"markdown","4b4cf013":"markdown","43a713e6":"markdown","c3ce3dcb":"markdown","e8526381":"markdown","a328b38f":"markdown","65b95d51":"markdown","992b442a":"markdown","982fc28e":"markdown","0dd6041e":"markdown"},"source":{"33b5fe86":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","01c72507":"df = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.head()","6d786869":"import matplotlib.pyplot as plt \nimport seaborn as sns \nsns.set(style='darkgrid')","431e16b5":"sns.heatmap(df.corr())","f59b0a98":"df.isnull().sum()","9db6e248":"df['Outcome'].value_counts()","03a587ec":"Glucose_mean = df.groupby('Outcome').Glucose.mean()\nGlucose_min = df.groupby('Outcome').Glucose.min()\nGlucose_max = df.groupby('Outcome').Glucose.max()\nprint('Mean value of glucose of people affected and not affected with diabetes', Glucose_mean)\nprint('Minimum value of glucose of people affected and not affected with diabetes', Glucose_min)\nprint('Maximum value of glucose of people affected and not affected with diabetes', Glucose_max)","5c38cee9":"sns.scatterplot(x = 'Glucose',y = 'Insulin', hue = 'Outcome', data=df)\nplt.title('Relation between Insulin and Glucose and how it affects diabetes')","ffa32547":"sns.distplot(df['Insulin'],bins = 8)\nplt.title('Distribution of Insulin column in the dataset')","0a849dfa":"sns.countplot(df['Pregnancies'],hue=df['Outcome'])","8a4bbdf4":"plt.figure(figsize=(10,6))\nplt.boxplot([df['Age'], df['BMI'], df['BloodPressure'], df['Glucose']], vert=False)\nplt.yticks([1, 2, 3, 4], ['Age', 'BMI', 'BloodPressure', 'Glucose'])\nplt.xlabel('Value')\nplt.title(\"Box Plot\")","25aadeee":"sns.scatterplot(x=df['Glucose'], y=df['BMI'], hue=df['Outcome'])\nplt.title('Relation between glucose level and BMI and how it affects diabetes')","7121fbe8":"# Taking all the dependent variables in x and all the independent variables in y \n\nX=df.drop('Outcome',axis=1).values\ny=df['Outcome'].values","401d495a":"# Making a 80:20 train test split\n\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n\nX_train.shape","9c5470dc":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","fc0f19ee":"##### Creating Tensors\nX_train=torch.FloatTensor(X_train)\nX_test=torch.FloatTensor(X_test)\ny_train=torch.LongTensor(y_train)\ny_test=torch.LongTensor(y_test)","4b6a9953":"class ANN_Model(nn.Module):\n    def __init__(self,input_features=8,hidden1=20,hidden2=10,hidden3= 5, out_features=2):\n        super().__init__()\n        self.f_connected1=nn.Linear(input_features,hidden1)\n        self.f_connected2=nn.Linear(hidden1,hidden2)\n        self.f_connected3=nn.Linear(hidden2,hidden3)\n        self.out=nn.Linear(hidden3,out_features)\n    def forward(self,x):\n        x=F.relu(self.f_connected1(x))\n        x=F.relu(self.f_connected2(x))\n        x=F.relu(self.f_connected3(x))\n        x=self.out(x)\n        return x","0058536d":"torch.manual_seed(20)\nmodel=ANN_Model()\n# torch.manual_seed() fixes the random value to a certain value and does not change the value everytime one reruns it","956373ac":"model.parameters","00fa72ba":"###Backward Propogation-- Define the loss_function,define the optimizer\nloss_function=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(),lr=0.01)","1b92809a":"epochs=500\nfinal_losses=[]\nfor i in range(epochs):\n    i=i+1\n    y_pred=model.forward(X_train)\n    loss=loss_function(y_pred,y_train)\n    final_losses.append(loss)\n    if i%10==1:\n        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","7247a38a":"### plot the loss function\nimport matplotlib.pyplot as plt\n%matplotlib inline","8a9236a4":"plt.plot(range(epochs),final_losses)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')","6ae32d8f":"predictions=[]\nwith torch.no_grad():\n    for i,data in enumerate(X_test):\n        y_pred=model(data)\n        predictions.append(y_pred.argmax().item())","0d1280e7":"from sklearn.metrics import accuracy_score\nscore=accuracy_score(y_test,predictions)\nscore","fc8fc7ef":"It is clear from the box plot that there are many outliers. We will see whether they affect the prediction or not","4386c670":"So there is no nan or missing values in the dataset.\n","8b462784":"- Pytorch is basically a library that uses tensors to build neural network. A tensor in pytorch is pretty similar to a numpy array but it can use the power of the GPU.\n","678b5b02":"## ANN with Pytorch ","031f07d5":"The neural network that I am going to create will have three layers \n- hidden layer 1 - 20 neurons \n- hidden layer 2 - 10 neurons\n- hidden layer 3 - 5 neurons ","a2b6c261":"![diabetes%20data.png](attachment:diabetes%20data.png)\n\nOne of the viusalization from the dataset. \n","4b4cf013":"So from the above data things that we can conclude are :-\n1. People with higher glucose level has more chances of diabetes as the mean value suggests\n2. However someone with zero glucose level can also be affected with diabetes. \n3. And someone with very high glucose level around 197 may not suffer from diabetes. ","43a713e6":"f_connected in this case means fully connected layer ","c3ce3dcb":"Importing and reading the requited files ","e8526381":"## First we need to do the feature engineering and data visualization \n\n","a328b38f":"# Context\n\n\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\n# Content \n\n\nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n\n# Goal \n\nCan you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?\n\n","65b95d51":"Conclusion from the correlation matrix:-\n    1. Glucose level plays the most important role in determining the whether the person is diabetic or not.\n    2. After that, BMI, pregnancy and Age plays the second most important role. \n    3. Third comes insulin and DiabetesPedigreeFunction. \n    4. And finally all other factors plays minor role as well. ","992b442a":"The first step towards creating the model is to create a tensor out of the pandas dataframe or numpy array.","982fc28e":"From the above observation we can say that the dataset is not imbalanced as one type of outcome does not dominate the dataset completely","0dd6041e":"Lets analyse the dataset a little more. You can skip the data visualization and exploratory data analysis after this and jump directly into the 'ANN with pytorch' section if you are not interested. "}}