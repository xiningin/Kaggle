{"cell_type":{"bcf0e789":"code","4f59703b":"code","c9365814":"code","f9ffe511":"code","35cc18e8":"code","26adfe11":"code","eb5acb86":"code","0b5d3977":"code","3d9f868d":"code","678ba0ce":"code","2cfa5d2f":"code","124b7637":"code","e60f9712":"code","57c1bf9e":"code","833a58e4":"code","a261d607":"markdown","4b3d2b3a":"markdown","a8a011fd":"markdown","00684145":"markdown","2a314eab":"markdown","d2f9f2ca":"markdown","2128006f":"markdown","9dec8711":"markdown","09c6eb1a":"markdown","483106ab":"markdown","0b3574b5":"markdown","3a009a56":"markdown","880cee07":"markdown"},"source":{"bcf0e789":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.datasets import load_boston\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f59703b":"%%html\n<style>\ntable {float:left}\n<\/style>","c9365814":"boston_housing = load_boston()\nboston_df = pd.DataFrame(boston_housing.data)\nboston_df.columns = boston_housing.feature_names\nboston_df['PRICE'] = boston_housing.target","f9ffe511":"boston_df.head()","35cc18e8":"print(f'Max house price is exactly: ${boston_df[\"PRICE\"].max()*1000}')\nsns.distplot(boston_df['PRICE'])","26adfe11":"sns.relplot(x=\"RM\", y=\"PRICE\", data=boston_df)\nplt.show()","eb5acb86":"boston_df = boston_df[\n    ~(boston_df['PRICE'] == 50)]","0b5d3977":"correlations = boston_df.corr()\nTHRESHOLD = .68\nfeatures = set()\nprint('The following features are highly correlated:')\n## Go through correlations and note ones that are significant (ignoring half the matrix along diagonal)\nfor i, (columnName, columnData) in enumerate(correlations.iteritems()):\n    for j,row in enumerate(columnData):\n        if j >= i:\n            # Exit, we've hit the diagonal after which consists of duplicates\n            break\n        if abs(row) >= THRESHOLD:\n            print(f'    {columnName} and {correlations.index[j]} with {row}')\n            features.add(columnName)\n            features.add(correlations.index[j])","3d9f868d":"corr_df = boston_df[list(features)].round(2)\nsns.heatmap(corr_df.corr(), annot=True)","678ba0ce":"f, ax = plt.subplots(figsize=(6, 6))\ncmap = sns.cubehelix_palette(as_cmap=True, dark=0, light=1, reverse=True)\nsns.kdeplot(boston_df.PRICE, boston_df.LSTAT, cmap=cmap, n_levels=60, shade=True);","2cfa5d2f":"sns.relplot(x='RM', y='PRICE', hue='PTRATIO', size='CRIM', sizes=(15, 200), data=boston_df);","124b7637":"g = sns.jointplot(x=\"RAD\", y=\"TAX\", data=boston_df, kind=\"kde\", color=\"m\")\ng.plot_joint(plt.scatter, c=\"w\", s=30, linewidth=1, marker=\"+\")\ng.ax_joint.collections[0].set_alpha(0)\ng.set_axis_labels(\"$Radial Highways Index$\", \"$Property Tax$\");","e60f9712":"def make_model_from_data(data, target, scaler=None, model=LinearRegression):\n    if scaler is not None:\n        data = scaler().fit_transform(data)\n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=.2, random_state=5)\n    assert X_train.shape[0] == y_train.shape[0]\n    assert X_test.shape[0] == y_test.shape[0]\n    assert X_train.shape[0] != y_test.shape[0]\n    assert X_test.shape[0] != y_train.shape[0]\n    model = model().fit(X_train, y_train)\n    y_test_pred = model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n    r2 = r2_score(y_test, y_test_pred)\n    return model, rmse, r2","57c1bf9e":"data = boston_df[['RM', 'LSTAT']]\ntarget = boston_df['PRICE']","833a58e4":"for scaler in (None, StandardScaler, MinMaxScaler):\n    _, rmse, r2 = make_model_from_data(data, target, scaler=scaler)\n    print(f'Normalization method: {scaler.__name__ if scaler else \"None\"}\\n'\n          f'RMSE: {rmse} R2: {r2}\\n{\"-\"*7}')","a261d607":"### A heatmap of features with strong relationships","4b3d2b3a":"# Predicting housing prices in Boston","a8a011fd":"### Column Descriptions\n\n| | | |\n|-|:-|-|\n|CRIM| per capita crime rate by town|\n|ZN|proportion of residential land zoned for lots over 25,000 sq.ft.|\n|INDUS|proportion of non-retail business acres per town.|\n|CHAS|Charles River dummy variable (1 if tract bounds river; 0 otherwise)|\n|NOX|nitric oxides concentration (parts per 10 million)|\n|RM|average number of rooms per dwelling|\n|AGE|proportion of owner-occupied units built prior to 1940|\n|DIS|weighted distances to five Boston employment centres|\n|RAD|index of accessibility to radial highways|\n|TAX|full-value property-tax rate per \\$10,000|\n|PTRATIO|pupil-teacher ratio by town|\n|B|1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town|\n|LSTAT|% lower status of the population|\n|PRICE|Median value of owner-occupied homes in $1000's|","00684145":"Reduce data to the features most correlated with price. That is, # rooms and economic status.","2a314eab":"### Relationship between Price, # Rooms, Crime, and Pupil-Teacher Ratio\nThere appears to be a relationship between number of rooms and price. It seems that expensive houses with a high number of rooms have a lower pupil-teacher ratio (lighter color). We also notice that cheaper houses are generally in neighborhoods with a higher crime rate (larger circle).","d2f9f2ca":"# Exploring Boston Housing Data","2128006f":"Homes farther away from employment centers have lower nitric oxide concentrations but also have less access to radial highways (and therefore urban centers). Conversely, homes with low nitric oxide levels have more residential land zoned for development.","9dec8711":"### Price Censoring\n[Housing prices appear to be censored](http:\/\/www.cs.toronto.edu\/~delve\/data\/boston\/bostonDetail.html) at exactly \\$50,000 given the fact that median house prices reach but do not exceed this number in 16 cases.","09c6eb1a":"### Relationship between distance from urban centers and property tax","483106ab":"### Relationship between economic status and price","0b3574b5":"### Comparison of linear regression performance for different methods of normalization","3a009a56":"Remove rows where price is exactly 50.","880cee07":"Price data is skewed by some prices being censored at 50."}}