{"cell_type":{"86bee61b":"code","68c3013b":"code","67e1a4c4":"code","1685b280":"code","c7d86e0b":"code","7dca8933":"code","f365868c":"code","e959afa6":"code","a3ce390f":"code","1498b955":"code","4c629819":"code","75317ea9":"code","df34c74f":"code","d871c16b":"markdown","dcddb362":"markdown","81293779":"markdown","72f6539e":"markdown","6abe2e63":"markdown","d95c88a0":"markdown"},"source":{"86bee61b":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import model_selection, metrics\nimport lightgbm as lgb\n\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path","68c3013b":"SEED = 1729\nINPUT_PATH = Path(\"..\/input\/lish-moa\/\")","67e1a4c4":"train_features = pd.read_csv(INPUT_PATH\/\"train_features.csv\"); print(f\"Train features shape: {train_features.shape}\")\ntest_features = pd.read_csv(INPUT_PATH\/\"test_features.csv\"); print(f\"Test features shape: {test_features.shape}\")\n\ntrain_targets = pd.read_csv(INPUT_PATH\/\"train_targets_scored.csv\"); print(f\"Train targets shape: {train_targets.shape}\")","1685b280":"train_features.head()","c7d86e0b":"test_features.head()","7dca8933":"# Build a model that can separate train and test based on the provided features.\ntrain_features[\"is_test\"] = 0\ntest_features[\"is_test\"] = 1\n\npanel = pd.concat([train_features, test_features], sort=False, ignore_index=True)","f365868c":"cp_type_dict = {\"trt_cp\": 0, \"ctl_vehicle\": 1}\ncp_dose_dict = {\"D1\": 0, \"D2\": 1}\n\npanel[\"cp_type\"] = panel[\"cp_type\"].map(cp_type_dict)\npanel[\"cp_dose\"] = panel[\"cp_dose\"].map(cp_dose_dict)","e959afa6":"columns_for_model = panel.columns[~np.in1d(panel.columns, [\"sig_id\", \"is_test\"])]\nprint(len(columns_for_model))","a3ce390f":"params = {\n    \"num_leaves\": 128,\n    \"min_data_in_leaf\": 64, \n    \"objective\": \"binary\",\n    \"max_depth\": 6,\n    \"learning_rate\": 0.001,\n    \"min_child_samples\": 64,\n    \"boosting\": \"gbdt\",\n    \"feature_fraction\": 0.9,\n    \"bagging_freq\": 5,\n    \"bagging_fraction\": 0.9 ,\n    \"bagging_seed\": SEED,\n    \"metric\": \"auc\",\n    \"lambda_l1\": 50.0,\n    \"lambda_l2\": 10.0,\n    \"verbosity\": -1\n}\nnum_rounds = 1000\nearly_stopping_rounds = 50\nverbose_eval = 50","1498b955":"kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=SEED)\ncv_scores = []\nmodels = []\nfor fold_idx, (dev_idx, val_idx) in enumerate(kf.split(panel)):\n    print(f\"Fold: {fold_idx+1}\")\n    X_dev, y_dev = panel.loc[dev_idx, columns_for_model], panel.loc[dev_idx, \"is_test\"].values\n    X_val, y_val = panel.loc[val_idx, columns_for_model], panel.loc[val_idx, \"is_test\"].values\n    \n    dev_dataset = lgb.Dataset(X_dev, y_dev)\n    val_dataset = lgb.Dataset(X_val, y_val)\n    \n    clf = lgb.train(\n        params,\n        dev_dataset,\n        num_rounds,\n        valid_sets=[dev_dataset, val_dataset],\n        early_stopping_rounds=early_stopping_rounds,\n        verbose_eval=verbose_eval\n    )\n    \n    cv_scores.append(clf.best_score[\"valid_1\"]['auc'])\n    models.append(clf)\n    print(\"\\n\")\n    \nadversarial_validation_auc = np.mean(cv_scores)\nprint(f\"Mean Adversarial AUC: {adversarial_validation_auc:.4f}\")","4c629819":"model = models[-1]\nfig, ax = plt.subplots(figsize=(15,15))\nlgb.plot_importance(model, max_num_features=50, importance_type=\"gain\", height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"LightGBM - Feature Importance by gain (Adversarial Validation)\", fontsize=15)\nplt.show()","75317ea9":"sample_submission = pd.read_csv(INPUT_PATH\/\"sample_submission.csv\")","df34c74f":"if adversarial_validation_auc < 0.55:\n    sample_submission.to_csv(\"submission.csv\", index=False)\nelse:\n    pass","d871c16b":"## Adversarial Validation on public test data","dcddb362":"## Adversarial Validation on private test data\n\nSince this is a code competition and the private dataset is available only when we submit the kernel to the competition.\nWe can make use of this fact to check a condition that can make a successful submission if the condition is true otherwise the submission would fail.\n\nBelow are the steps to check Adversarial Validation on private dataset:\n\n1. Run the Adversarial Validation just like how we would run on public test data in notebooks.\n2. Check the condition ```adversarial_validation_auc``` is less than 0.55 for private dataset.\n3. Make a submission if the condition satisfies.","81293779":"## Next steps:\n1. Build a baseline model\n2. Check CV-LB difference & correlation (Random KFold is a reasonable validation framework to start with here)\n3. Improve single model (This is important because, the competition is Code only)\n\nFinally a tabular competition to work on!\n\nHappy Kaggling!","72f6539e":"Train and Public test distributions are more or less similar!\nCV and LB should be in sync (Hopefully!)","6abe2e63":"Understanding the similarities between train and test distributions is a vital starting point for creating a local validation framework that generalises well on unseen data. In this kernel, let's look at Adversarial validation to compare the distributions of train and test.","d95c88a0":"Since the submission was successful, we can conclude that train and private test distributions are also similar."}}