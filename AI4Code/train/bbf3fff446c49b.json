{"cell_type":{"4480ac4f":"code","1dbb6e09":"code","ac7bc224":"code","3603c212":"code","184ee8d1":"code","5f1ebe89":"code","2bb5c96a":"code","1ae7e99a":"code","ef9573ec":"code","e2de8a1a":"code","d75e199a":"markdown","0ef0cb1c":"markdown","6ba1b7ca":"markdown","3dcb3271":"markdown","a5623457":"markdown","be6d7559":"markdown","9bc7cf77":"markdown","a8c5acd6":"markdown","c01140d4":"markdown","202ebaf4":"markdown","d8e2dbac":"markdown","5a9e10c6":"markdown"},"source":{"4480ac4f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1dbb6e09":"import requests\nfrom bs4 import BeautifulSoup\n\nURL = 'https:\/\/www.monster.com\/jobs\/search\/?q=Software-Developer&where=Australia'\npage = requests.get(URL)\n\nsoup = BeautifulSoup(page.content, 'html.parser')","ac7bc224":"results = soup.find(id='ResultsContainer')","3603c212":"print(results.prettify())","184ee8d1":"job_elems = results.find_all('section', class_='card-content')","5f1ebe89":"for job_elem in job_elems:\n    print(job_elem, end='\\n'*2)","2bb5c96a":"for job_elem in job_elems:\n    # Each job_elem is a new BeautifulSoup object.\n    # You can use the same methods on it as you did before.\n    title_elem = job_elem.find('h2', class_='title')\n    company_elem = job_elem.find('div', class_='company')\n    location_elem = job_elem.find('div', class_='location')\n    print(title_elem)\n    print(company_elem)\n    print(location_elem)\n    print()","1ae7e99a":"for job_elem in job_elems:\n    title_elem = job_elem.find('h2', class_='title')\n    company_elem = job_elem.find('div', class_='company')\n    location_elem = job_elem.find('div', class_='location')\n    if None in (title_elem, company_elem, location_elem):\n        continue\n    print(title_elem.text.strip())\n    print(company_elem.text.strip())\n    print(location_elem.text.strip())\n    print()","ef9573ec":"python_jobs = results.find_all('h2',\n                               string=lambda text: 'python' in text.lower())","e2de8a1a":"python_jobs = results.find_all('h2',\n                               string=lambda text: \"python\" in text.lower())\n\nfor p_job in python_jobs:\n    link = p_job.find('a')['href']\n    print(p_job.text.strip())\n    print(f\"Apply here: {link}\\n\")","d75e199a":"Extract Text From HTML Elements\nFor now, you only want to see the title, company, and location of each job posting. And behold! Beautiful Soup has got you covered. You can add .text to a Beautiful Soup object to return only the text content of the HTML elements that the object contains:","0ef0cb1c":"The filtered results will only show links to job opportunities that include python in their title. You can use the same square-bracket notation to extract other HTML attributes as well. A common use case is to fetch the URL of a link, as you did above.","6ba1b7ca":"Beautiful Soup is a Python library for parsing structured data. It allows you to interact with HTML in a similar way to how you would interact with a web page using developer tools. Beautiful Soup exposes a couple of intuitive functions you can use to explore the HTML you received","3dcb3271":"Still, there\u2019s a lot going on with all those HTML tags and attributes floating around:\n\n","a5623457":"Find Elements by HTML Class Name\nYou\u2019ve seen that every job posting is wrapped in a <section> element with the class card-content. Now you can work with your new Beautiful Soup object called results and select only the job postings. These are, after all, the parts of the HTML that you\u2019re interested in! You can do this in one line of code:","be6d7559":"Find Elements by Class Name and Text Content\nBy now, you\u2019ve cleaned up the list of jobs that you saw on the website. While that\u2019s pretty neat already, you can make your script more useful. However, not all of the job listings seem to be developer jobs that you\u2019d be interested in as a Python developer. So instead of printing out all of the jobs from the page, you\u2019ll first filter them for some keywords.\n","9bc7cf77":"That\u2019s already pretty neat, but there\u2019s still a lot of HTML! You\u2019ve seen earlier that your page has descriptive class names on some elements. Let\u2019s pick out only those:\n\n","a8c5acd6":"Here, you call .find_all() on a Beautiful Soup object, which returns an iterable containing all the HTML for all the job listings displayed on that page.\n\nTake a look at all of them:","c01140d4":"For easier viewing, you can .prettify() any Beautiful Soup object when you print it out. If you call this method on the results variable that you just assigned above, then you should see all the HTML contained within the <div>:","202ebaf4":"Building the Job Search Tool by using this program\n\n","d8e2dbac":"Find Elements by ID\nIn an HTML web page, every element can have an id attribute assigned. As the name already suggests, that id attribute makes the element uniquely identifiable on the page. You can begin to parse your page by selecting a specific element by its ID.\n\nSwitch back to developer tools and identify the HTML object that contains all of the job postings. Explore by hovering over parts of the page and using right-click to Inspect.\n\nNote: Keep in mind that it\u2019s helpful to periodically switch back to your browser and interactively explore the page using developer tools. This helps you learn how to find the exact elements you\u2019re looking for.\nAt the time of this writing, the element you\u2019re looking for is a <div> with an id attribute that has the value \"ResultsContainer\". It has a couple of other attributes as well, but below is the gist of what you\u2019re looking for:<div id=\"ResultsContainer\">\n    <!-- all the job listings -->\n<\/div>","5a9e10c6":"At this point, your Python script already scrapes the site and filters its HTML for relevant job postings. Well done! However, one thing that\u2019s still missing is the link to apply for a job.\n\nWhile you were inspecting the page, you found that the link is part of the element that has the title HTML class. The current code strips away the entire link when accessing the .text attribute of its parent element. As you\u2019ve seen before, .text only contains the visible text content of an HTML element. Tags and attributes are not part of that. To get the actual URL, you want to extract one of those attributes instead of discarding it.\n\nLook at the list of filtered results python_jobs that you created above. The URL is contained in the href attribute of the nested <a> tag. Start by fetching the <a> element. Then, extract the value of its href attribute using square-bracket notation:\n\n"}}