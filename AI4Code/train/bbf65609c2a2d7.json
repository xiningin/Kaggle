{"cell_type":{"0f788aff":"code","002cd772":"code","ba7dd500":"code","c2e8a66c":"code","f9e0d15e":"code","ff57e141":"code","c536668a":"code","10cb0890":"code","174051b4":"code","8a731edd":"code","8da594a3":"code","bfd8f280":"code","d3f259ea":"code","7878fc30":"code","486acf77":"code","fb195220":"code","b5f3d810":"code","c7a5bbbd":"code","fcd3d70b":"code","73f2eee1":"markdown","7d3b645c":"markdown","677d5895":"markdown","637b6db3":"markdown","8e994fed":"markdown","7004710a":"markdown","a786105d":"markdown","f6b9ffa9":"markdown","d3daa418":"markdown","ba386c2b":"markdown","f22c3f59":"markdown","3a825500":"markdown","fa1846bd":"markdown","2f7d8178":"markdown","6238b951":"markdown","4967399f":"markdown","3cd7979e":"markdown"},"source":{"0f788aff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport cv2\nimport glob\nimport torch\nimport shutil\nimport itertools\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom torch.nn import functional as F\nfrom torchvision import datasets, models, transforms","002cd772":"covid_path = '..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID-19'\nnormal_path = '..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL'\npneumonia_path = '..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia'","ba7dd500":"images = ['..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID-19\/COVID-19 (1).png',\n'..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL\/NORMAL (1).png',\n'..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia\/Viral Pneumonia (1).png',\n'..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID-19\/COVID-19 (10).png',\n'..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL\/NORMAL (10).png',\n'..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia\/Viral Pneumonia (10).png',\n'..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID-19\/COVID-19 (100).png',\n'..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL\/NORMAL (100).png',\n'..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia\/Viral Pneumonia (100).png']","c2e8a66c":"fig, axes = plt.subplots(3, 3, figsize=(7, 7))\nlabels = ['Covid', 'Normal', 'Pneumonia']\ni = 0\nj = 0\n\nfor row in axes:\n    for plot in row:\n        plot.imshow(cv2.imread(images[j], 0))\n        plot.axhline(y=0.5, color='r')\n        plot.set_title(labels[i], fontsize=15)\n        plot.axis('off')\n        i += 1\n        j += 1\n    i = 0\n    \nfig.tight_layout()\nplt.show()","f9e0d15e":"covid_path = '..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID-19'\nnormal_path = '..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL'\npneumonia_path = '..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia'","ff57e141":"os.mkdir('\/kaggle\/working\/train')\nos.mkdir('\/kaggle\/working\/test')\n\nos.mkdir('\/kaggle\/working\/train\/covid')\nos.mkdir('\/kaggle\/working\/test\/covid')\n\nos.mkdir('\/kaggle\/working\/train\/normal')\nos.mkdir('\/kaggle\/working\/test\/normal')\n\nos.mkdir('\/kaggle\/working\/train\/pneumonia')\nos.mkdir('\/kaggle\/working\/test\/pneumonia')","c536668a":"covid_train_len = int(np.floor(len(os.listdir(covid_path))*0.8))\ncovid_len = len(os.listdir(covid_path))\n\nnormal_train_len = int(np.floor(len(os.listdir(normal_path))*0.8))\nnormal_len = len(os.listdir(normal_path))\n\npneumonia_train_len = int(np.floor(len(os.listdir(pneumonia_path))*0.8))\npneumonia_len = len(os.listdir(pneumonia_path))","10cb0890":"for trainimg in itertools.islice(glob.iglob(os.path.join(covid_path, '*.png')), covid_train_len):\n    shutil.copy(trainimg, '\/kaggle\/working\/train\/covid')\n    \nfor trainimg in itertools.islice(glob.iglob(os.path.join(normal_path, '*.png')), normal_train_len):\n    shutil.copy(trainimg, '\/kaggle\/working\/train\/normal')\n    \nfor trainimg in itertools.islice(glob.iglob(os.path.join(pneumonia_path, '*.png')), pneumonia_train_len):\n    shutil.copy(trainimg, '\/kaggle\/working\/train\/pneumonia')\n\n\nfor testimg in itertools.islice(glob.iglob(os.path.join(covid_path, '*.png')), covid_train_len, covid_len):\n    shutil.copy(testimg, '\/kaggle\/working\/test\/covid')\n\nfor testimg in itertools.islice(glob.iglob(os.path.join(normal_path, '*.png')), normal_train_len, normal_len):\n    shutil.copy(testimg, '\/kaggle\/working\/test\/normal')\n\nfor testimg in itertools.islice(glob.iglob(os.path.join(pneumonia_path, '*.png')), pneumonia_train_len, pneumonia_len):\n    shutil.copy(testimg, '\/kaggle\/working\/test\/pneumonia')","174051b4":"normalizer = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25])\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((244, 244)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ColorJitter(),\n        transforms.ToTensor(),\n        normalizer\n    ]),\n    \n    'validation': transforms.Compose([\n        transforms.Resize((244, 244)),\n        transforms.ToTensor(),\n        normalizer\n    ])\n}","8a731edd":"data_images = {\n    'train': datasets.ImageFolder('\/kaggle\/working\/train', data_transforms['train']),\n    'validation': datasets.ImageFolder('\/kaggle\/working\/test', data_transforms['validation'])\n}","8da594a3":"dataloaders = {\n    'train': torch.utils.data.DataLoader(data_images['train'], batch_size=32, shuffle=True, num_workers=0),\n    'validation': torch.utils.data.DataLoader(data_images['validation'], batch_size=32,shuffle=True,num_workers=0)\n}","bfd8f280":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel = models.resnet50(pretrained=True)","d3f259ea":"for param in model.parameters():\n    param.requires_grad = False","7878fc30":"model.fc = nn.Sequential(\n    nn.Linear(2048, 64),\n    nn.ReLU(inplace=True),\n    nn.Linear(64, 3)\n).to(device)","486acf77":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters())","fb195220":"def trained_model(model, criterion, optimizer, epochs):\n    for epoch in range(epochs):\n        \n        print('Epoch:', str(epoch+1) + '\/' + str(epochs))\n        print('-'*10)\n        \n        for phase in ['train', 'validation']:\n            if phase == 'train':\n                model.train() #this trains the model\n            else:\n                model.eval() #this evaluates the model\n\n            running_loss, running_corrects = 0.0, 0 \n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device) #convert inputs to cpu or cuda\n                labels = labels.to(device) #convert labels to cpu or cuda\n\n                outputs = model(inputs) #outputs is inputs being fed to the model\n                loss = criterion(outputs, labels) #outputs are fed into the model\n\n                if phase == 'train':\n                    optimizer.zero_grad() #sets gradients to zero\n                    loss.backward() #computes sum of gradients\n                    optimizer.step() #preforms an optimization step\n\n                _, preds = torch.max(outputs, 1) #max elements of outputs with output dimension of one\n                running_loss += loss.item() * inputs.size(0) #loss multiplied by the first dimension of inputs\n                running_corrects += torch.sum(preds == labels.data) #sum of all the correct predictions\n\n            epoch_loss = running_loss \/ len(data_images[phase]) #this is the epoch loss\n            epoch_accuracy = running_corrects.double() \/ len(data_images[phase]) #this is the epoch accuracy\n\n            print(phase, ' loss:', epoch_loss, 'epoch_accuracy:', epoch_accuracy)\n\n    return model","b5f3d810":"model = trained_model(model, criterion, optimizer, 3)","c7a5bbbd":"os.mkdir('\/kaggle\/working\/models')","fcd3d70b":"torch.save(model.state_dict(), 'models\/weights.h5') #save the model's weights\nmodel.load_state_dict(torch.load('models\/weights.h5')) #load the model's weights","73f2eee1":"Then, we create a set of dataloaders which are used to split the data up into batches, which will be useful for our predictor.","7d3b645c":"## Transforming our data\nNow the transfer learning begins. We must firstly transform each dataset to have certain changes in it. For the train set, we resize the images, flip them horizontally and vertically and change their colours, while for the test set, we only resize the images.","677d5895":"## Thank you for reading my notebook.\n## If you enjoyed this notebook and found it helpful, please give it an upvote as it motivates me to make more of these.","637b6db3":"# Training our model","8e994fed":"# Creating a ResNet50 model","7004710a":"After the data has been transformed, we now create a device which makes the model be able to run on a cpu and cuda core, depending on which you use. \n\nFurthermore, we create a pretrained ResNet50 model.","a786105d":"Here we build the simple architecture of the model, being a linear input layer, a relu activation function and a linear output layer","f6b9ffa9":"## Sorting out the files\nIn order for our transfer learning model to work, we will first need to move the images into new folders. We will organise them split up into train and test sets, and then split it even further into the types of classes we have.\n\nThe structure of the files will be as follows:\n\n1.  train\n    * covid\n    * pneumonia\n    * normal\n2.  test \n    * covid\n    * pneumonia\n    * normal","d3daa418":"Also very importantly, we create the criterion of CrossEntropyLoss and an optimizer of Adam.","ba386c2b":"# Covid-19 Chest X-Ray Prediction\nWelcome to the Covid-19 classification dataset where we will be taking X-Ray images of chests that have either covid-19, pneumonia or neither. We will be using the ResNet50 classifier because the number of data samples that we are given is only a few hundred, which means that we need a transfer learning model. Predicting this dataset is important as it could help doctors in understanding whether or not someone has the coronavirus.","f22c3f59":"Finally, we train our model. As you can see below, the lines of code are of a great multitude and complexity. The result, however, is a trained model which produces a pleasing accuracy.","3a825500":"## Data Visualisation\nThe visualisations that we'll make are three sets of the covid, pneumonia and normal chest x-ray images.","fa1846bd":"Subsequently, we loop over all the parameters of the model and set an attribute of 'requires_grad' to False. This is important as it means that we don't update certain parts of our classifier, which can save a lot of unnecessary computation.","2f7d8178":"Then, we loop over each class and split them each up into train and test sets.","6238b951":"### If you enjoy this notebook and find it helpful, please give it an upvote as it will help me more of these.","4967399f":"Next, we use those transforms that we created and apply them to our data, storing it in a new file location.","3cd7979e":"In the following cell of code, we gather the length of how long each training set should be for each class."}}