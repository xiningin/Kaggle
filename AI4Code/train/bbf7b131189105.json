{"cell_type":{"d4b536f9":"code","ba0c2207":"code","67acd790":"code","65d3015b":"code","f5ae7d58":"code","6cd12e27":"code","032ae7c0":"code","1a558a43":"code","09fb02cc":"code","d610e256":"code","1f155194":"code","30956e64":"code","c06eae6c":"code","7e260e25":"code","887bd583":"code","d8e8daf6":"code","b0246f6e":"code","21ad1a34":"code","1fe45de4":"code","681b39c8":"code","1ef7fa72":"code","10f9fa35":"code","2c0416ec":"code","ff75b353":"code","8de42b12":"code","3ae3b7c0":"code","b3b5d1cf":"code","c4d4cd15":"code","ae5a4c91":"code","cc847097":"code","90a1e276":"code","42b0eae2":"code","a443b93c":"code","9c57de5f":"code","4b920eac":"code","f793696c":"code","dad2c093":"code","ea595893":"code","44e1f32a":"code","cbdea85c":"code","19d382b5":"code","384d6bea":"code","35abca53":"code","0d883e6f":"code","7b1c80be":"code","3bf2d83d":"code","5bc967d2":"code","f5bfc2c2":"code","e6b42c51":"code","51c568dd":"code","83a1ec04":"code","dcd0d051":"code","ad127ca9":"code","28d63ea4":"code","c5382b36":"code","2495d378":"code","0e0fe86f":"code","03778c02":"code","c4b42a3d":"code","04df351d":"markdown","fead218c":"markdown"},"source":{"d4b536f9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ba0c2207":"#importing the dataset\ndata =pd.read_csv(\"..\/input\/healthcare-project\/health care diabetes.csv\")","67acd790":"#Viewing first 5 rows of the dataset to have an idea about what exactly the data is about\ndata.head()","65d3015b":"#Checking for the missing values\ndata.isnull().sum()","f5ae7d58":"#Checking to the inforamtion about the dataset\ndata.info()","6cd12e27":"# From the above dataset we can able  to see that the target Outcome variable as \"Outcome\" which is \"1\" or \"0\" where 1 indicates the patient has diabetis (and we consider this as Positive) and 0 indicates that the patient doesnot have diabetis(and we consider this as Healthy)\nPositive = data[data[\"Outcome\"]==1]\nPositive.head()","032ae7c0":"Positive.shape","1a558a43":"Healthy =data[data[\"Outcome\"]!=1]\nHealthy.head()","09fb02cc":"Healthy.shape","d610e256":"data.shape\ndata.describe()","1f155194":"#From the above we can able to see that the min values as Zero's which means there are missing values as the Glusose,BP,Skinthickness,Insulin,BMI cannnot be Zero,Hence we repalce then with Mean values","30956e64":"data[\"Glucose\"]=data[\"Glucose\"].replace(0,data[\"Glucose\"].mean())","c06eae6c":"#Lets visualize the same\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nplt.figure(figsize=(12,10),dpi=100)\nplt.xlabel(\"Glucose\")\nplt.hist(data[\"Glucose\"])\nsns.set_style(style=\"darkgrid\")\nprint(\"Mean of Glucose level is :-\",data[\"Glucose\"].mean())\nprint(\"Datatype of Glucose Variable is :-\", data[\"Glucose\"].dtypes)","7e260e25":"data[\"BloodPressure\"]=data[\"BloodPressure\"].replace(0,data[\"BloodPressure\"].mean())","887bd583":"plt.figure(figsize=(12,10),dpi=100)\nplt.xlabel(\"BloodPressure\")\nplt.hist(data[\"BloodPressure\"])\nsns.set_style(style=\"darkgrid\")\nprint(\"Mean of the BloodPressure is :-\",data[\"BloodPressure\"].mean())\nprint(\"Datatype of the BloodPressure variable is :-\",data[\"BloodPressure\"].dtypes)","d8e8daf6":"data[\"SkinThickness\"]=data[\"SkinThickness\"].replace(0,data[\"SkinThickness\"].mean())\nplt.figure(figsize=(12,6),dpi=100)\nplt.xlabel(\"SkinThickness\")\nplt.hist(data[\"SkinThickness\"])\nsns.set_style(style=\"darkgrid\")\nprint(\"Mean of Skinthickness is:-\",data[\"SkinThickness\"].mean())\nprint(\"Datatype of Skinthickness is :-\",data[\"SkinThickness\"].dtypes)","b0246f6e":"data[\"BMI\"] =data[\"BMI\"].replace(0,data[\"BMI\"].mean())\nplt.figure(figsize=(12,6),dpi=100)\nplt.xlabel(\"BMI\")\nplt.hist(data[\"BMI\"])\nsns.set_style(style=\"darkgrid\")\nprint(\"Mean of BMI is :-\", data[\"BMI\"].mean())\nprint(\"Datatype of BMI :-\",data[\"BMI\"].dtypes)","21ad1a34":"data['Insulin']=data['Insulin'].replace(0,data['Insulin'].mean())\nplt.figure(figsize=(12,6),dpi=100)\nplt.xlabel(\"Insulin\")\nplt.hist(data['Insulin'])\nsns.set_style(style=\"darkgrid\")\nprint(\"Mean of Insulin is :-\" , data['Insulin'].mean())\nprint(\"Dataype off Insulin is :-\",data['Insulin'].dtypes)","1fe45de4":"data.describe()","681b39c8":"#From the above we can able to see that thereare no Zero values from Col 2 to 6 ","1ef7fa72":"data.describe().transpose()","10f9fa35":"#Checking the missing values with HEatmap\nplt.figure(figsize=(10,6),dpi=100)\nplt.title(\"Checking for the missing values\")\nsns.heatmap(data.isnull(),cmap=\"magma\",yticklabels=False)","2c0416ec":"#Now visualizing the Outcome count\nplt.figure(figsize=(10,6))\nsns.set_style(style=\"darkgrid\")\nsns.countplot(data[\"Outcome\"])\nplt.title(\"Count of Outcome\")\nplt.xlabel(\"Outcome\")\nplt.ylabel(\"Count\")\nprint(\"Count of Class :\\n\",data[\"Outcome\"].value_counts())","ff75b353":"#Now visualize all the variables using a Pairplot Function by this we able able to see any relation exists among the variables\nsns.pairplot(data)\nplt.title(\"Scatter plot b\/w the variables\")","8de42b12":"#From the above scatter plots we can clearly see that there is no strong multicollinarity between the variables but there is a small correlation between BMI and Skinthickness ,Pregnancy and age","3ae3b7c0":"# We can also find the relation among the variables using below data.corr() method\ndata.corr()","b3b5d1cf":"#From the above analysis we can see that there is a correction between BMI and Skinthickness \/ Age and Pregnencies","c4d4cd15":"# We can also visualize the corellation among the variables by using Heatmap\nplt.figure(figsize=(12,6),dpi=80)\nsns.heatmap(data.corr(),cmap='viridis')","ae5a4c91":"#Lets model the above dataset and start importing necessary libraries.\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\ndata.head()","cc847097":"x =data.drop(\"Outcome\",axis=1).values\ny=data[\"Outcome\"].values","90a1e276":"X_train,X_test,y_train,y_test =train_test_split(x,y,test_size=0.2,random_state=0)","42b0eae2":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","a443b93c":"#Scaling the data\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing","9c57de5f":"scale=StandardScaler()\nstand_x_train =scale.fit_transform(X_train)\nstand_x_test=scale.fit_transform(X_test)","4b920eac":"#Normalizing the data\ndata_norm =x\ndata_normalized=preprocessing.normalize(x)\nX_train_norm,X_test_norm,y_train_norm,y_test_norm =train_test_split(data_normalized,y,test_size=0.2,random_state=0)","f793696c":"print(X_train_norm.shape)\nprint(X_test_norm.shape)\nprint(y_train_norm.shape)\nprint(y_test_norm.shape)","dad2c093":"#This is a classification model with data in numerical hence Logistic regression can be used to model this data,\n#Along with these we can also use Randon Forest  ,Decision tree ,SVM(Support vector meachine) \n#to calucate the acuracy of the model and \n#we will find out which of these models provide better accuracy score.","ea595893":"# K-Nearest Neibours (KNN) Using Standard Scaling","44e1f32a":"from sklearn.neighbors import KNeighborsClassifier","cbdea85c":"knn_model =KNeighborsClassifier(n_neighbors=25)","19d382b5":"knn_model.fit(stand_x_train,y_train)\nknnn_predict =knn_model.predict(stand_x_test)","384d6bea":"print(\"model validation =======>\\n\")\nprint(\"Accuracy score of KNN Model : :\")\nprint(metrics.accuracy_score(knnn_predict,y_test))\nprint(\"\\n\",\"Classification Report : :\")\nprint(metrics.classification_report(knnn_predict,y_test))\nprint(\"\\n\",\"ROC Curve : :\")\nknn_prob =knn_model.predict_proba(stand_x_test)\nknn_prob1=knn_prob[:,1]\nfpr,tpr,thres =metrics.roc_curve(y_test,knn_prob1)\nroc_auc_knn =metrics.auc(fpr,tpr)\nplt.figure(figsize=(16,8),dpi=60)\nsns.set_style(style=\"darkgrid\")\nplt.title(\"ROC Curve\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.plot(fpr,tpr,'b',label=\"AUC Score =%0.2f\"%roc_auc_knn)\nplt.plot(fpr,fpr,\"r--\",color=\"red\")","35abca53":"# KNN with Normaliastion ","0d883e6f":"from sklearn.neighbors import KNeighborsClassifier\nKnnmodel=KNeighborsClassifier(n_neighbors=25)\nknn_model.fit(X_train_norm,y_train)\nknnn_predict_norm =knn_model.predict(X_test_norm)","7b1c80be":"print(\"model validation =======>\\n\")\nprint(\"Accuracy score of KNN Model : :\")\nprint(metrics.accuracy_score(knnn_predict_norm,y_test))\nprint(\"\\n\",\"Classification Report : :\")\nprint(metrics.classification_report(knnn_predict_norm,y_test))\nprint(\"\\n\",\"ROC Curve : :\")\nknn_prob =knn_model.predict_proba(X_test_norm)\nknn_prob1=knn_prob[:,1]\nfpr,tpr,thres =metrics.roc_curve(y_test,knn_prob1)\nroc_auc_knn =metrics.auc(fpr,tpr)\nplt.figure(figsize=(16,8),dpi=60)\nsns.set_style(style=\"darkgrid\")\nplt.title(\"ROC Curve\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.plot(fpr,tpr,'b',label=\"AUC Score =%0.2f\"%roc_auc_knn)\nplt.plot(fpr,fpr,\"r--\",color=\"red\")","3bf2d83d":"# From the above models -KNN Model with Standardasation is more accurate than Normalizaton ","5bc967d2":"# Support Vector Classifier","f5bfc2c2":"from sklearn.svm import SVC","e6b42c51":"SVC_model=SVC(kernel=\"linear\",random_state=0,probability=True,C=0.01)\nSVC_model.fit(stand_x_train,y_train)\nSVC_predict=SVC_model.predict(stand_x_test)","51c568dd":"print(\"Model Validation ==>:\\n\")\nprint(\"Accuracy Score : :\")\nprint(metrics.accuracy_score(SVC_predict,y_test))\nprint(\"\\n\", \"Classification Report : : \")\nprint(metrics.classification_report(SVC_predict,y_test))\nprint(\"\\n\", \"ROC Curve : :\")\nSVC_predict_prob=SVC_model.predict_proba(stand_x_test)\nSVC_predict_prob1=SVC_predict_prob[:,1]\nfpr,tpr,thres = metrics.roc_curve(y_test,SVC_predict_prob1)\nruc_auc_SVC=metrics.auc(fpr,tpr)\nplt.figure(figsize=(12,6),dpi=60)\nplt.title(\"ROC Curve\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.plot(fpr,tpr,'b',label=\"AUC Score =%0.2f\"%ruc_auc_SVC)\nplt.plot(fpr,fpr,'r--',color=\"red\")","83a1ec04":"SVC_model_rbf=SVC(kernel=\"rbf\",random_state=0,probability=True,C=1)\nSVC_model_rbf.fit(stand_x_train,y_train)\nSVC_predict=SVC_model_rbf.predict(stand_x_test)","dcd0d051":"print(\"Model Validation ==>:\\n\")\nprint(\"Accuracy Score : :\")\nprint(metrics.accuracy_score(SVC_predict,y_test))\nprint(\"\\n\", \"Classification Report : : \")\nprint(metrics.classification_report(SVC_predict,y_test))\nprint(\"\\n\", \"ROC Curve : :\")\nSVC_predict_prob=SVC_model.predict_proba(stand_x_test)\nSVC_predict_prob1=SVC_predict_prob[:,1]\nfpr,tpr,thres = metrics.roc_curve(y_test,SVC_predict_prob1)\nruc_auc_SVC=metrics.auc(fpr,tpr)\nplt.figure(figsize=(12,6),dpi=60)\nplt.title(\"ROC Curve\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.plot(fpr,tpr,'b',label=\"AUC Score =%0.2f\"%ruc_auc_SVC)\nplt.plot(fpr,fpr,'r--',color=\"red\")","ad127ca9":"#SVC Linear kernal is more accurate than RBF(Radial Basis Function) as the varibles are more linear with Outcome","28d63ea4":"# Logistic Regression ","c5382b36":"from sklearn.linear_model import LogisticRegression\nlr_model=LogisticRegression(C=0.01)\nlr_model.fit(stand_x_train,y_train)\nlr_predict=lr_model.predict(stand_x_test)","2495d378":"print(\"Model Validation ==>:\\n\")\nprint(\"Accuracy Score : :\")\nprint(metrics.accuracy_score(lr_predict,y_test))\nprint(\"\\n\", \"Classification Report : : \")\nprint(metrics.classification_report(lr_predict,y_test))\nprint(\"\\n\", \"ROC Curve : :\")\nlr_predict_prob=lr_model.predict_proba(stand_x_test)\nlr_predict_prob1=lr_predict_prob[:,1]\nfpr,tpr,thres = metrics.roc_curve(y_test,lr_predict_prob1)\nruc_auc_lr=metrics.auc(fpr,tpr)\nplt.figure(figsize=(12,6),dpi=60)\nplt.title(\"ROC Curve\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.plot(fpr,tpr,'b',label=\"AUC Score =%0.2f\"%ruc_auc_lr)\nplt.plot(fpr,fpr,'r--',color=\"red\")","0e0fe86f":"# Random Forest ","03778c02":"from sklearn.ensemble import RandomForestClassifier\nrf_model =RandomForestClassifier(n_estimators=1000,random_state=0)\nrf_model.fit(stand_x_train,y_train)\nrf_predict=rf_model.predict(stand_x_test)","c4b42a3d":"print(\"model Validation ==>\")\nprint(\"Accuracy Score of RF : : \\n\")\nprint(metrics.accuracy_score(rf_predict,y_test))\nprint(\"\\n\" , \"Classification Report : :\")\nprint(metrics.classification_report(rf_predict,y_test))\nprint(\"ROC Curve : :\")\nrf_predict_prob=rf_model.predict_proba(stand_x_test)\nrf_predict_prob1=rf_predict_prob[:,1]\nfpr,tpr,thres=metrics.roc_curve(y_test,rf_predict_prob1)\nroc_auc_RF=metrics.auc(fpr,tpr)\nplt.figure(figsize=(12,6),dpi=60)\nplt.title(\"ROC Curve\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.plot(fpr,tpr,'b',label=\"AUC Score =%0.2f\"%roc_auc_RF)\nplt.plot(fpr,fpr,'r--',color='red')","04df351d":"**So we have done with modeling all the different types of Classification Models and measured accuracy and based on this we can conclude that the\nAccuracy of Ensamble classfier (Random Forest) is more accurate than other models ,\nHence Random Forest classification is considered as the best model for evaluation for the above dataset and \nalso we can see that the model is so balanced \nbetween the classes of Precision and recall when compared with other models.**","fead218c":"**Context:**\n\nThis dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n\nProblem Statement:\n\nBuild a model to accurately predict whether the patients in the dataset have diabetes or not?\n\n**Dataset Description:**\n\nThe datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n\n\nPregnancies: Number of times pregnant\nGlucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\nBloodPressure: Diastolic blood pressure (mm Hg)\nSkinThickness: Triceps skin fold thickness (mm)\nInsulin: 2-Hour serum insulin (mu U\/ml)\nBMI: Body mass index (weight in kg\/(height in m)^2)\nDiabetesPedigreeFunction: Diabetes pedigree function\nAge: Age (years)\nOutcome: Class variable (0 or 1) 268 of 768 are 1, the others are 0\n\nApproach:\n\nFollowing pointers will be helpful to structure your findings.   \n\n1.\tPerform descriptive analysis. It is very important to understand the variables and corresponding values. We need to think through - Can minimum value of below listed columns be zero (0)? On these columns, a value of zero does not make sense and thus indicates missing value.\n\u2022\tGlucose\n\u2022\tBloodPressure\n\u2022\tSkinThickness\n\u2022\tInsulin\n\u2022\tBMI\n\n      How will you treat these values?\n\n2.\tVisually explore these variable, you may need to look for the distribution of these variables using histograms. Treat the missing values accordingly.\n\n3.\t We observe integer as well as float data-type of variables in this dataset. Create a count (frequency) plot describing the data types and the count of variables. \n\n\n4.\tCheck the balance of the data by plotting the count of outcomes by their value. Describe your findings and plan future course of actions.\n\n5.\tCreate scatter charts between the pair of variables to understand the relationships. Describe your findings.\n\n6.\tPerform correlation analysis. Visually explore it using a heat map.\n\n(Note: Do not focus on visualization aspects when working with SAS)\n\n7.\tDevise strategies for model building. It is important to decide the right validation framework. Express your thought process. Would Cross validation be useful in this scenario?\n\n(Note: if you are working with SAS, ignore this question and perform stratified sampling to partition the data. Create strata of age for this.)\n\n8.\tApply an appropriate classification algorithm to build a model. Compare various models with the results from KNN.\n\n(Note: if you are working with SAS, ignore this question. Apply logistic regression technique to build the model.)\n\n9.\tCreate a classification report by analysing sensitivity, specificity, AUC(ROC curve) etc. Please try to be as descriptive as possible to explain what values of these parameter you settled for? any why?\n\n10.\tCreate a dashboard in tableau by choosing appropriate chart types and metrics useful for the business. The dashboard must entail the following: \n\na)\tPie chart to describe the diabetic\/non-diabetic population\nb)\tScatter charts between relevant variables to analyse the relationships\nc)\tHistogram\/frequency charts to analyse the distribution of the data\nd)\tHeatmap of correlation analysis among the relevant variables\ne)\tCreate bins of Age values \u2013 20-25, 25-30, 30-35 etc. and analyse different variables for these age brackets using a bubble chart. \n\n\n\n\n\n\n\n\n\n\n"}}