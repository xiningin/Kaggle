{"cell_type":{"c1dc74b1":"code","96bd2424":"code","795e3320":"code","ff4490d6":"code","bac3693a":"code","7c7dd6c0":"code","0d18691c":"code","358964af":"markdown","d545ee99":"markdown","98739498":"markdown","8affd877":"markdown","6cc2bd6b":"markdown"},"source":{"c1dc74b1":"import os, glob\nimport random\nfrom PIL import Image \nimport numpy as np\nimport pandas as pd\nimport multiprocessing\nimport keras\nimport keras.backend as K\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback\nfrom keras.applications.densenet import DenseNet169\nfrom keras.layers import Dense, Flatten\nfrom keras.models import Model, load_model\nfrom keras.utils import Sequence\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import layers\nfrom keras.callbacks import LearningRateScheduler\nimport matplotlib.pyplot as plt, time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nfrom numpy.random import seed\nseed(1220)\nfrom tensorflow import set_random_seed\nset_random_seed(1220)\n%matplotlib inline\nprint(\"libraries imported!\")","96bd2424":"test_imgs_folder = '..\/input\/understanding_cloud_organization\/test_images\/'\ntrain_imgs_folder = '..\/input\/understanding_cloud_organization\/train_images\/'\nnum_cores = multiprocessing.cpu_count()","795e3320":"# based on https:\/\/www.kaggle.com\/cdeotte\/steel-adversarial-validation\/data\nTRAIN_IMG = os.listdir('..\/input\/understanding_cloud_organization\/train_images')\nTEST_IMG = os.listdir('..\/input\/understanding_cloud_organization\/test_images')\nprint('Original train count =',len(TRAIN_IMG),', Original test count =',len(TEST_IMG))\nos.mkdir('..\/tmp\/')\nos.mkdir('..\/tmp\/train_images\/')\nr = np.random.choice(TRAIN_IMG,len(TEST_IMG),replace=False)\nfor i,f in enumerate(r):\n    img = Image.open('..\/input\/understanding_cloud_organization\/train_images\/'+f)\n    img.save('..\/tmp\/train_images\/'+f)\nos.mkdir('..\/tmp\/test_images\/')\nfor i,f in enumerate(TEST_IMG):\n    img = Image.open('..\/input\/understanding_cloud_organization\/test_images\/'+f)\n    img.save('..\/tmp\/test_images\/'+f)","ff4490d6":"TRAIN_IMG_AV = os.listdir('..\/tmp\/train_images')\nTEST_IMG_AV = os.listdir('..\/tmp\/test_images')\nprint('New train count =',len(TRAIN_IMG_AV),', New test count =',len(TEST_IMG_AV))","bac3693a":"def get_model():\n    K.clear_session()\n    base_model = DenseNet169(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))\n    x = base_model.output\n    y_pred = Dense(1, activation='sigmoid')(x)\n    return Model(inputs=base_model.input, outputs=y_pred)\n\nmodel = get_model()\nmodel.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])","7c7dd6c0":"img_dir = '..\/tmp\/'\nimg_height = 224; img_width = 224\nbatch_size = 32; nb_epochs = 8\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.2) # set validation split\n\ntrain_generator = train_datagen.flow_from_directory(\n    img_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(\n    img_dir, # same directory as training data\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation') # set as validation data\n\nannealer = LearningRateScheduler(lambda x: 0.0001 * 0.95 ** x)\n\n# fit!\nh = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ batch_size,\n    epochs = nb_epochs,\n    callbacks = [annealer],\n    verbose=2)","0d18691c":"plt.figure(figsize=(15,5))\nplt.plot(h.history['acc'],label='Train ACC')\nplt.plot(h.history['val_acc'],label='Val ACC')\nplt.title('TRAIN COMPARED WITH TEST. Training History')\nplt.legend()\nplt.show()","358964af":"# Introduction\nFor this sort of a (image) classification task, it is worthwhile knowing whether the distribution of the train data is somewhat similar to that of the test data. If they are very different, a model fitted to the train data cannot do much job for classifying the test data. To see whether distributions of the train and test is similar, we can do so-called **adversarial validation**. \n\nThis kernel is largely based on this kernel (https:\/\/www.kaggle.com\/cdeotte\/steel-adversarial-validation) which did the adversarial classification for the steel competition.","d545ee99":"# train : test = 1: 1","98739498":"# Accuracy\nIf distributions of the train and test are similar to one another, the classification accuracy for validation should be around 0.5.","8affd877":"# Libraries","6cc2bd6b":"\n# Build an Adversarial Classifier\nI use a simple DenseNet169 as an adversarial classifier."}}