{"cell_type":{"6c3ea33e":"code","dbaf218d":"code","7460c157":"code","afeed22d":"code","20c138e4":"code","9d617d42":"code","ce03d9b6":"code","ceeb25f3":"code","532bb184":"code","27aca4bd":"code","9c48f1cc":"code","a8408c22":"code","8d57ed89":"code","e1b93809":"code","16a3f9d2":"code","144fb362":"code","d78ea854":"code","7cbc952d":"code","5d88a4ce":"code","9da849ec":"code","c41644d8":"code","66fcf3c7":"code","5485318f":"code","6e6bd7b6":"code","28d15fa4":"code","f2b4249e":"code","bb2be2d7":"code","9b2ac413":"code","c24594a8":"code","a734d698":"code","e83b99d1":"code","1325270b":"code","8fdbbcde":"code","d539e6bb":"code","dee44ef2":"code","2a30f6cf":"code","ea122a3b":"code","999df7bc":"code","728258b0":"code","82f1af57":"markdown"},"source":{"6c3ea33e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","dbaf218d":"### Libraries\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport shap\nfrom scipy.stats import probplot, kurtosis, skew, gmean\nfrom sklearn.mixture import GaussianMixture","7460c157":"### Config\ntrain_ = '..\/input\/tabular-playground-series-feb-2021\/train.csv'\ntest_ = '..\/input\/tabular-playground-series-feb-2021\/test.csv'\nsub_ = '..\/input\/tabular-playground-series-feb-2021\/sample_submission.csv'","afeed22d":"df_train= pd.read_csv(train_)\ndf_train.info()","20c138e4":"df_train.head(10)","9d617d42":"def plot_target(target):\n    \n    print(f'Target feature {target} Statistical Analysis\\n{\"-\" * 42}')\n        \n    print(f'Mean: {df_train[target].mean():.4}  -  Median: {df_train[target].median():.4}  -  Std: {df_train[target].std():.4}')\n    print(f'Min: {df_train[target].min():.4}  -  25%: {df_train[target].quantile(0.25):.4}  -  50%: {df_train[target].quantile(0.5):.4}  -  75%: {df_train[target].quantile(0.75):.4}  -  Max: {df_train[target].max():.4}')\n    print(f'Skew: {df_train[target].skew():.4}  -  Kurtosis: {df_train[target].kurtosis():.4}')\n    missing_values_count = df_train[df_train[target].isnull()].shape[0]\n    training_samples_count = df_train.shape[0]\n    print(f'Missing Values: {missing_values_count}\/{training_samples_count} ({missing_values_count * 100 \/ training_samples_count:.4}%)')\n\n    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(24, 12), dpi=100)\n\n    sns.distplot(df_train[target], label=target, ax=axes[0][0])\n    axes[0][0].axvline(df_train[target].mean(), label='Target Mean', color='r', linewidth=2, linestyle='--')\n    axes[0][0].axvline(df_train[target].median(), label='Target Median', color='b', linewidth=2, linestyle='--')\n    probplot(df_train[target], plot=axes[0][1])\n    \n    gmm = GaussianMixture(n_components=2, random_state=42)\n    gmm.fit(df_train[target].values.reshape(-1, 1))\n    df_train[f'{target}_class'] = gmm.predict(df_train[target].values.reshape(-1, 1))\n    \n    sns.distplot(df_train[target], label=target, ax=axes[1][0])\n    sns.distplot(df_train[df_train[f'{target}_class'] == 0][target], label='Component 1', ax=axes[1][1])\n    sns.distplot(df_train[df_train[f'{target}_class'] == 1][target], label='Component 2', ax=axes[1][1])\n    \n    axes[0][0].legend(prop={'size': 15})\n    axes[1][1].legend(prop={'size': 15})\n    \n    for i in range(2):\n        for j in range(2):\n            axes[i][j].tick_params(axis='x', labelsize=12)\n            axes[i][j].tick_params(axis='y', labelsize=12)\n            axes[i][j].set_xlabel('')\n            axes[i][j].set_ylabel('')\n    axes[0][0].set_title(f'{target} Distribution in Training Set', fontsize=15, pad=12)\n    axes[0][1].set_title(f'{target} Probability Plot', fontsize=15, pad=12)\n    axes[1][0].set_title(f'{target} Distribution Before GMM', fontsize=15, pad=12)\n    axes[1][1].set_title(f'{target} Distribution After GMM', fontsize=15, pad=12)\n    plt.show()\n    \n\nplot_target('target')","ce03d9b6":"test_df = pd.read_csv(test_)\ntest_df","ceeb25f3":"sns.set_style(\"whitegrid\")\nsns.set_palette('Purples')","532bb184":"fig , axes = plt.subplots(2,5,figsize = (18,12),constrained_layout = True)\nsns.countplot(ax=axes[0,0],x='cat0',data=df_train )\nsns.countplot(ax=axes[0,1],x='cat1',data=df_train)\nsns.countplot(ax=axes[0,2],x='cat2',data=df_train)\nsns.countplot(ax=axes[0,3],x='cat3',data=df_train)\nsns.countplot(ax=axes[0,4],x='cat4',data=df_train)\nsns.countplot(ax=axes[1,0],x='cat5',data=df_train)\nsns.countplot(ax=axes[1,1],x='cat6',data=df_train)\nsns.countplot(ax=axes[1,2],x='cat7',data=df_train)\nsns.countplot(ax=axes[1,3],x='cat8',data=df_train)\nsns.countplot(ax=axes[1,4],x='cat9',data=df_train)\nplt.suptitle('Count Plot for Each Columns')\nplt.show()","27aca4bd":"df_train['cat3'].value_counts()","9c48f1cc":"df_train['cat4'].value_counts()","a8408c22":"df_train['cat6'].value_counts()","8d57ed89":"df_train['cat7'].value_counts()","e1b93809":"df_train['cat8'].value_counts()","16a3f9d2":"df_train['cat9'].value_counts()","144fb362":"df_train['cat6'].replace('G','A',inplace = True)","d78ea854":"def preprocessing(column,target,result):\n    df_train[column].replace(target,result,inplace = True)\npreprocessing('cat6','H','A')\npreprocessing('cat6','E','A')\npreprocessing('cat6','I','A')\npreprocessing('cat6','D','A')\npreprocessing('cat3','B','C')\npreprocessing('cat7','I','E')\npreprocessing('cat7','C','E')\npreprocessing('cat7','A','E')\npreprocessing('cat7','F','E')\npreprocessing('cat8','B','C')\npreprocessing('cat9','C','F')\npreprocessing('cat9','D','F')\npreprocessing('cat9','E','F')","7cbc952d":"from sklearn.preprocessing import LabelEncoder,StandardScaler","5d88a4ce":"lb = LabelEncoder()\ndf_train['cat0'] = lb.fit_transform(df_train['cat0'])\ndf_train['cat1'] = lb.fit_transform(df_train['cat1'])\ndf_train['cat2'] = lb.fit_transform(df_train['cat2'])\ndf_train['cat3'] = lb.fit_transform(df_train['cat3'])\ndf_train['cat4'] = lb.fit_transform(df_train['cat4'])\ndf_train['cat5'] = lb.fit_transform(df_train['cat5'])\ndf_train['cat6'] = lb.fit_transform(df_train['cat6'])\ndf_train['cat7'] = lb.fit_transform(df_train['cat7'])\ndf_train['cat8'] = lb.fit_transform(df_train['cat8'])\ndf_train['cat9'] = lb.fit_transform(df_train['cat9'])","9da849ec":"print(df_train['cat0'].unique(),df_train['cat1'].unique(),df_train['cat2'].unique(),df_train['cat3'].unique(),df_train['cat4'].unique())","c41644d8":"df_train.columns","66fcf3c7":"data = df_train[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7',\n       'cat8', 'cat9', 'cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n       'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12',\n       'cont13']]","5485318f":"sb = StandardScaler()\ndata = sb.fit_transform(data)","6e6bd7b6":"from sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error","28d15fa4":"X_train,X_test,y_train,y_test = train_test_split(data,df_train['target'],test_size = 0.2 , random_state = 2021)","f2b4249e":"print(X_train.shape,y_train.shape)","bb2be2d7":"d_train = xgb.DMatrix(X_train, label=y_train)\nd_test = xgb.DMatrix(X_test, label=y_test)","9b2ac413":"model_parameters =  {\n            'learning_rate': 0.002,\n            'colsample_bytree': 0.6, \n            'colsample_bylevel': 0.6,\n            'colsample_bynode': 0.6,\n            'sumbsample': 0.8,\n            'max_depth': 14,\n            'gamma': 0,\n            'min_child_weight': 200,\n            'lambda': 0,\n            'alpha': 0,\n            'objective': 'reg:squarederror',\n            'seed': None,\n            'boosting_type': 'gbtree',\n            'tree_method': 'gpu_hist',\n            'silent': True,\n            'verbose': 1,\n            'n_jobs': -1,\n        }\nmodel = xgb.train(model_parameters, d_train, 25000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=200)","c24594a8":"lb = LabelEncoder()\ntest_df['cat0'] = lb.fit_transform(test_df['cat0'])\ntest_df['cat1'] = lb.fit_transform(test_df['cat1'])\ntest_df['cat2'] = lb.fit_transform(test_df['cat2'])\ntest_df['cat3'] = lb.fit_transform(test_df['cat3'])\ntest_df['cat4'] = lb.fit_transform(test_df['cat4'])\ntest_df['cat5'] = lb.fit_transform(test_df['cat5'])\ntest_df['cat6'] = lb.fit_transform(test_df['cat6'])\ntest_df['cat7'] = lb.fit_transform(test_df['cat7'])\ntest_df['cat8'] = lb.fit_transform(test_df['cat8'])\ntest_df['cat9'] = lb.fit_transform(test_df['cat9'])","a734d698":"x__test = test_df[['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7',\n       'cat8', 'cat9', 'cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n       'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12',\n       'cont13']]","e83b99d1":"x__test = sb.fit_transform(x__test)","1325270b":"x__test","8fdbbcde":"d__test = xgb.DMatrix(x__test)","d539e6bb":"target = model.predict(d__test)","dee44ef2":"type(target)","2a30f6cf":"submission = pd.DataFrame()\nsubmission['id'] = test_df['id']\nsubmission['target'] = target","ea122a3b":"submission.set_index('id',inplace = True)","999df7bc":"submission.shape","728258b0":"submission.to_csv('mygood.csv')","82f1af57":"Reference ---[https:\/\/xgboost.readthedocs.io\/en\/latest\/gpu\/index.html](http:\/\/xgboost.readthedocs.io\/en\/latest\/gpu\/index.html)"}}