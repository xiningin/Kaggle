{"cell_type":{"391b3055":"code","ac54598a":"code","bda12231":"code","7f9d7916":"code","398c8388":"code","d12865b9":"code","6e91cd50":"code","79d02e56":"code","a14f8210":"code","9dc231e4":"code","1994aecc":"code","bfb2c81d":"code","63521e95":"code","c1028389":"code","5732ff79":"code","9f639958":"code","2c37ad3b":"code","1ce505c0":"code","bd341006":"code","40b9d948":"code","3f76ae3b":"code","8397352e":"code","f3023dcf":"code","43266d5e":"markdown"},"source":{"391b3055":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ac54598a":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport os\nimport tempfile\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","bda12231":"file = tf.keras.utils\nraw_df = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\nraw_df.head()","7f9d7916":"raw_df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V26', 'V27', 'V28', 'Amount', 'Class']].describe()","398c8388":"neg, pos = np.bincount(raw_df['Class'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos \/ total))","d12865b9":"cleaned_df = raw_df.copy()\n\n# You don't want the `Time` column.\ncleaned_df.pop('Time')\n\n# The `Amount` column covers a huge range. Convert to log-space.\neps = 0.001 # 0 => 0.1\u00a2\ncleaned_df['Log Ammount'] = np.log(cleaned_df.pop('Amount')+eps)","6e91cd50":"X= cleaned_df.drop('Class', axis= 'columns')\ny= cleaned_df.Class\nX.shape, y.shape\n","79d02e56":"scaler = StandardScaler()\nX_scaled= scaler.fit_transform(X)\nX_scaled.shape","a14f8210":"X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, test_size= 0.2)","9dc231e4":"METRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]\n\ndef make_model(metrics=METRICS):\n    model = keras.Sequential([\n          keras.layers.Dense(32, activation='relu',input_shape=(X_train.shape)),\n          keras.layers.Dropout(0.5),\n          keras.layers.Dense(64, activation='relu',input_shape=(X_train.shape)),\n          keras.layers.Dropout(0.5),\n          keras.layers.Dense(1, activation='sigmoid'),\n      ])\n    model.compile(\n          optimizer=keras.optimizers.Adam(lr=1e-3),\n          loss=keras.losses.BinaryCrossentropy(),\n          metrics=metrics)\n    return model","1994aecc":"model = make_model()\nmodel.summary()","bfb2c81d":"model.predict(X_train[:10])","63521e95":"history= model.fit(X_train, y_train, epochs= 20,validation_split= 0.2,verbose= 2)","c1028389":"import matplotlib.pyplot as plt\nplt.plot(history.epoch ,history.history['loss'])\nplt.plot(history.epoch, history.history['val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')","5732ff79":"baseline_results = model.evaluate(X_test, y_test,\n                                  batch_size=2048, verbose= 0)\nfor name, value in zip(model.metrics_names, baseline_results):\n    print(name, ': ', value)\nprint()","9f639958":"test_predictions_baseline = model.predict(X_test, batch_size=2048)\n\ncm = confusion_matrix(y_test, test_predictions_baseline > 0.5 )\nplt.figure(figsize=(5,5))\nsns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title('Confusion matrix @{:.2f}'.format(0.5))\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","2c37ad3b":"from imblearn.over_sampling import SMOTE\n","1ce505c0":"oversample= SMOTE()\nX,y= oversample.fit_resample(X,y)\nX.shape, y.shape","bd341006":"X_train, X_test, y_train, y_test = train_test_split(X,y , test_size= 0.2)","40b9d948":"over_sampled = model.fit(X_train, y_train, epochs= 20, validation_split= 0.2, verbose= 2)","3f76ae3b":"plt.plot(over_sampled.epoch ,over_sampled.history['loss'])\nplt.plot(over_sampled.epoch, over_sampled.history['val_loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')","8397352e":"baseline_results = model.evaluate(X_test, y_test,\n                                  batch_size=2048, verbose= 0)\nfor name, value in zip(model.metrics_names, baseline_results):\n    print(name, ': ', value)\nprint()","f3023dcf":"test_predictions_baseline = model.predict(X_test, batch_size=2048)\n\ncm = confusion_matrix(y_test, test_predictions_baseline > 0.5 )\nplt.figure(figsize=(5,5))\nsns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title('Confusion matrix @{:.2f}'.format(0.5))\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","43266d5e":"# Applying SMOTE for oversampling"}}