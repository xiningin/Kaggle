{"cell_type":{"f29c5305":"code","a2928274":"code","59ec53e8":"code","41c2d039":"code","6e4f126b":"code","ce1c24d3":"code","01b9c7c5":"code","2f894fa4":"code","8afb57c1":"code","89573d4b":"code","bff6eaff":"code","d3c73ef7":"code","e8f4e2e7":"code","ff63f989":"code","1e310d87":"code","b0a045ef":"code","a845f535":"code","4b130f05":"code","01e3f463":"code","a9ec4126":"code","a59989f1":"code","0a724b0e":"code","5740107b":"code","db32e0b1":"code","809ea46a":"code","65b53629":"code","1361abdd":"code","17f785dd":"code","08c380ea":"code","58b827ba":"code","83d29390":"code","2331af18":"code","a6311e29":"code","2e570421":"code","abc358a7":"code","f08f4385":"markdown","88560835":"markdown","230fbd65":"markdown","6ac410e5":"markdown","1155c72f":"markdown","e3b93d14":"markdown","b417ac7f":"markdown","941225f7":"markdown","b8bef527":"markdown","4dc905ff":"markdown","c8efca86":"markdown","a9dd9c66":"markdown","40cf1bf5":"markdown","722da9db":"markdown"},"source":{"f29c5305":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.feature_selection import SelectFromModel\n\nimport lightgbm as lgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a2928274":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\npredicted_data = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","59ec53e8":"train_data.head()","41c2d039":"def data_merge(train, test):\n    train.drop(['Survived', 'PassengerId'], axis = 1, inplace = True)\n    test.drop('PassengerId', axis = 1, inplace = True)\n    frames = [train, test]\n    merged = pd.concat(frames)\n    return merged\n\nmerged_data = data_merge(train_data, test_data)\nmerged_data.reset_index(inplace = True)","6e4f126b":"merged_data.head()","ce1c24d3":"merged_data.shape","01b9c7c5":"merged_data.isnull().sum()","2f894fa4":"merged_data['FamilyNum'] = merged_data['SibSp'] + merged_data['Parch']\nmerged_data.drop(['SibSp', 'Parch'], axis = 1, inplace = True)","8afb57c1":"merged_data['Name'].isnull().sum()","89573d4b":"title = set()\nfor name in merged_data['Name']:\n    title.add(name.split(',')[1].split('.')[0].strip())\n\nprint(title)","bff6eaff":"Title_Dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Sir\" : \"Royalty\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Lady\" : \"Royalty\"\n}","d3c73ef7":"def name_process():\n    merged_data['Title'] = merged_data.Name.map(lambda a : a.split(',')[1].split('.')[0].strip())\n    \n    merged_data['Title'] = merged_data.Title.map(Title_Dictionary)\n    return merged_data\n\nmerged_data = name_process()\nmerged_data.drop(['Name', 'index'], axis = 1, inplace = True)","e8f4e2e7":"merged_data.Title.value_counts()","ff63f989":"merged_data['Title'].fillna('Mr', inplace = True)","1e310d87":"def OH_encode(data, col):\n    Medium_data = pd.get_dummies(data[col], prefix = col)\n    data = pd.concat([data, Medium_data], axis = 1)\n    data.drop(col, axis = 1, inplace = True)\n    return data","b0a045ef":"merged_data = OH_encode(merged_data, 'Title')","a845f535":"merged_data.replace(['male', 'female'], [1, 0], inplace = True)","4b130f05":"merged_data = OH_encode(merged_data, 'Pclass')","01e3f463":"merged_data = OH_encode(merged_data, 'Embarked')","a9ec4126":"merged_data['Fare'].fillna(method = 'ffill', axis = 0, inplace = True)","a59989f1":"merged_data['Age'].isnull().value_counts()","0a724b0e":"Age_fill_model = lgb.LGBMRegressor(random_state=1)\n\nAge_train_data = merged_data.loc[:891]\nAge_train_data = merged_data[merged_data['Age'].notnull()]\n\nAge_features = ['Sex'] + list(merged_data.columns[6:15])\n\nAge_fill_model.fit(Age_train_data.loc[:, Age_features], Age_train_data['Age'])","5740107b":"Age_predict_data = merged_data[merged_data.Age.isnull()].loc[:, Age_features]\nresult = Age_fill_model.predict(Age_predict_data)\nresult = result.astype(np.int32)\n\ni = 0\nfor num in merged_data[merged_data.Age.isnull()].index:\n    merged_data.loc[num, 'Age'] = result[i]\n    i+=1","db32e0b1":"def deal_with_ticket (data:pd.DataFrame) -> list:\n    result = []\n    length = len(data)\n    num = np.arange(length)\n    count = data['Ticket'].value_counts()\n    uni_value = count[count > 1].index.tolist()\n    for a in num:\n        if data['Ticket'][a] in uni_value:\n            result.append(a)\n    return result","809ea46a":"merged_same = deal_with_ticket(merged_data)","65b53629":"merged_data.loc[:, 'Ticket'] = 0\nmerged_data.loc[merged_same, 'Ticket'] = 1","1361abdd":"merged_data.drop(['Cabin'], axis = 1, inplace = True)","17f785dd":"merged_data.fillna(method = 'ffill', inplace = True)","08c380ea":"from sklearn.model_selection import cross_val_score\n\ndef compute_score(model, X, y, scoring='accuracy'):\n    xval = cross_val_score(model, X, y, cv = 5, scoring=scoring)\n    return np.mean(xval)\n","58b827ba":"tar = 'Survived'\n\ntrain_x = merged_data.iloc[:891]\ntrain_y = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')[tar]\n\nval_x = merged_data.iloc[891:]\nval_y = predicted_data[tar]\n\nSur_model = RandomForestClassifier(n_estimators=50, max_features='sqrt', random_state = 15)\nSur_model.fit(train_x, train_y)\n# result_a = Sur_model.predict(val_x)\n\n# print(mean_absolute_error(result_a, val_y))\n# print(compute_score(Sur_model, train_x, train_y, scoring='accuracy'))","83d29390":"features = pd.DataFrame()\nfeatures['feature'] = merged_data.columns\nfeatures['importance'] = Sur_model.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(25, 25))","2331af18":"model = SelectFromModel(Sur_model, prefit=True)\n\ntrain_x_reduced = model.transform(train_x)\nval_x_reduced = model.transform(val_x)\n\n# Sur_model = RandomForestClassifier(n_estimators=50, max_features='sqrt', random_state = 15)\n# Sur_model.fit(train_x_reduced, train_y)\n# result_b = Sur_model.predict(val_x_reduced)\n\n# print(mean_absolute_error(result_b, val_y))\n# print(compute_score(Sur_model, train_x_reduced, train_y, scoring='accuracy'))","a6311e29":"# Lgb_model = lgb.LGBMClassifier()\n# Lgb_model.fit(train_x, train_y)\n# result_c = Lgb_model.predict(val_x)\n\n# print(mean_absolute_error(result_c, val_y))\n# print(compute_score(Lgb_model, train_x, train_y, scoring='accuracy'))","2e570421":"Lgb_model = lgb.LGBMClassifier()\nLgb_model.fit(train_x, train_y)\nresult_d = Lgb_model.predict(val_x)\n\nprint(mean_absolute_error(result_d, val_y))\nprint(compute_score(Lgb_model, train_x, train_y, scoring='accuracy'))","abc358a7":"output = pd.DataFrame({'PassengerId': pd.read_csv('\/kaggle\/input\/titanic\/test.csv').PassengerId,\n                      'Survived': result_d})\noutput.to_csv('submission.csv', index=False)","f08f4385":"## \u5bb6\u5ead\u6210\u5458\u603b\u6570","88560835":"## Embarked\u5904\u7406","230fbd65":"## Fare\u5904\u7406","6ac410e5":"## \u5efa\u7acb\u6a21\u578b","1155c72f":"## \u8003\u8651\u56e2\u4f53\u7968\u7684\u60c5\u51b5","e3b93d14":"### \u5bf9Title\u8fdb\u884c\u7f16\u7801","b417ac7f":"## \u6570\u636e\u7684\u5408\u5e76","941225f7":"## \u5904\u7406\u59d3\u540d","b8bef527":"## \u6027\u522b\u5904\u7406","4dc905ff":"\u4f7f\u7528\u4f17\u6570\u586b\u5145Title","c8efca86":"## Pclass\u5904\u7406","a9dd9c66":"## \u5e74\u9f84\u7f3a\u635f\u586b\u5145\u5904\u7406","40cf1bf5":"### \u4f7f\u7528\u7ebf\u6027\u56de\u5f52\u586b\u5145\u7f3a\u5931\u7684\u5e74\u9f84\uff0c\u5728\u8fd9\u91cc\u6211\u4e3b\u8981\u9009\u4e86\u6027\u522b\uff0c\u8239\u8d39\uff0c\u540d\u79f0\u6765\u4f5c\u4e3a\u7279\u5f81","722da9db":"## \u6570\u636e\u6982\u89c8"}}