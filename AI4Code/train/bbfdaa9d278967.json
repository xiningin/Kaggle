{"cell_type":{"e968a032":"code","daba497a":"code","98789610":"code","59128101":"code","7096ac12":"code","225b86b6":"code","b29ee5a6":"code","a08de616":"code","0d262b0e":"code","9851c4d0":"code","c23da839":"code","c7029dd9":"code","f3573896":"code","6f360713":"markdown","5fc29a7c":"markdown"},"source":{"e968a032":"import copy\nimport gc\nimport glob\nimport os\nimport time\n\nimport cv2\nimport IPython\nimport IPython.display\nimport joblib\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport scipy\nfrom joblib import Parallel, delayed\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom tqdm import tqdm\n\n%matplotlib inline","daba497a":"pd.options.display.max_columns = 128\npd.options.display.max_rows = 128\nplt.rcParams['figure.figsize'] = (15, 8)","98789610":"class EasyDict(dict):\n    def __init__(self, d=None, **kwargs):\n        if d is None:\n            d = {}\n        if kwargs:\n            d.update(**kwargs)\n        for k, v in d.items():\n            setattr(self, k, v)\n        # Class attributes\n        for k in self.__class__.__dict__.keys():\n            if not (k.startswith('__') and k.endswith('__')) and not k in ('update', 'pop'):\n                setattr(self, k, getattr(self, k))\n\n    def __setattr__(self, name, value):\n        if isinstance(value, (list, tuple)):\n            value = [self.__class__(x)\n                     if isinstance(x, dict) else x for x in value]\n        elif isinstance(value, dict) and not isinstance(value, self.__class__):\n            value = self.__class__(value)\n        super(EasyDict, self).__setattr__(name, value)\n        super(EasyDict, self).__setitem__(name, value)\n\n    __setitem__ = __setattr__\n\n    def update(self, e=None, **f):\n        d = e or dict()\n        d.update(f)\n        for k in d:\n            setattr(self, k, d[k])\n\n    def pop(self, k, d=None):\n        delattr(self, k)\n        return super(EasyDict, self).pop(k, d)","59128101":"train_df = pd.read_csv('..\/input\/train_curated.csv')\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv')\nprint('train: {}'.format(train_df.shape))\nprint('test: {}'.format(sample_submission.shape))\n\nROOT = '..\/input\/'\ntest_root = os.path.join(ROOT, 'test\/')\ntrain_root = os.path.join(ROOT, 'train_curated\/')\n\n\nCONFIG = EasyDict()\nCONFIG.hop_length = 347 # to make time steps 128\nCONFIG.fmin = 20\nCONFIG.fmax = 44100 \/ 2\nCONFIG.n_fft = 480\n\nN_SAMPLES = 48\nSAMPLE_DIM = 256\n\nTRAINING_CONFIG = {\n    'sample_dim': (N_SAMPLES, SAMPLE_DIM),\n    'padding_mode': cv2.BORDER_REFLECT,\n}\n\nprint(CONFIG)\nprint(TRAINING_CONFIG)\n\ntrain_df.head()","7096ac12":"# Preprocessing functions inspired by:\n# https:\/\/github.com\/xiaozhouwang\/tensorflow_speech_recognition_solution\/blob\/master\/data.py\nclass DataProcessor(object):\n    \n    def __init__(self, debug=False):\n        self.debug = debug\n        \n        # Placeholders for global statistics\n        self.mel_mean = None\n        self.mel_std = None\n        self.mel_max = None\n        self.mfcc_max = None\n        \n    def createMel(self, filename, params, normalize=False):\n        \"\"\"\n        Create Mel Spectrogram sample out of raw wavfile\n        \"\"\"\n        y, sr = librosa.load(filename, sr=None)\n        mel = librosa.feature.melspectrogram(y, sr, n_mels=N_SAMPLES, **params)\n        mel = librosa.power_to_db(mel)\n        if normalize:\n            if self.mel_mean is not None and self.mel_std is not None:\n                mel = (mel - self.mel_mean) \/ self.mel_std\n            else:\n                sample_mean = np.mean(mel)\n                sample_std = np.std(mel)\n                mel = (mel - sample_mean) \/ sample_std\n            if self.mel_max is not None:\n                mel = mel \/ self.mel_max\n            else:\n                mel = mel \/ np.max(np.abs(mel))\n        return mel\n    \n    def createMfcc(self, filename, params, normalize=False):\n        \"\"\"\n        Create MFCC sample out of raw wavfile\n        \"\"\"\n        y, sr = librosa.load(filename, sr=None)\n        nonzero_idx = [y > 0]\n        y[nonzero_idx] = np.log(y[nonzero_idx])\n        mfcc = librosa.feature.mfcc(y, sr, n_mfcc=N_SAMPLES, **params)\n        if normalize:\n            if self.mfcc_max is not None:\n                mfcc = mfcc \/ self.mfcc_max\n            else:\n                mfcc = mfcc \/ np.max(np.abs(mfcc))\n        return mfcc\n    \n    def createLogspec(self, filename, params,\n                      normalize=False,\n                      window_size=20,\n                      step_size=10, eps=1e-10):\n        \"\"\"\n        Create log spectrogram,\n        based on \n        https:\/\/www.kaggle.com\/voglinio\/keras-2d-model-5-fold-log-specgram-curated-only\n        \"\"\"\n        \n        y, sr = librosa.load(filename, sr=None)\n        nperseg = int(round(window_size * sr \/ 1e3))\n        noverlap = int(round(step_size * sr \/ 1e3))\n        freqs, times, spec = scipy.signal.spectrogram(\n            y,\n            fs=sr,\n            window='hann',\n            nperseg=nperseg,\n            noverlap=noverlap,\n            detrend=False)\n        spec = np.log(spec.astype(np.float32) + eps)\n        return spec\n        \n    \n    def prepareSample(self, root, row, \n                      preprocFunc, \n                      preprocParams, trainingParams, \n                      test_mode=False, normalize=False, \n                      proc_mode='split'):\n        \"\"\"\n        Prepare sample for model training.\n        Function takes row of DataFrame, extracts filename and labels and processes them.\n        \n        If proc_mode is 'split':\n        Outputs sets of arrays of constant shape padded to TRAINING_CONFIG shape\n        with selected padding mode, also specified in TRAINING_CONFIG.\n        This approach prevents loss of information caused by trimming the audio sample,\n        instead it splits it into equally-sized parts and pads them.\n        To account for creation of multiple samples, number of labels are multiplied to a number\n        equal to number of created samples.\n        \n        If proc_mode is 'resize':\n        Resizes the original processed sample to (SAMPLE_DIM, N_SAMPLES) shape.\n        \"\"\"\n        \n        assert proc_mode in ['split', 'resize'], 'proc_must be one of split or resize'\n        \n        filename = os.path.join(root, row['fname'])\n        if not test_mode:\n            labels = row['labels']\n            \n        sample = preprocFunc(filename, preprocParams, normalize=normalize)\n        # print(sample.min(), sample.max())\n        \n        if proc_mode == 'split':\n            sample_split = np.array_split(\n                sample, np.ceil(sample.shape[1] \/ SAMPLE_DIM), axis=1)\n            samples_pad = []\n            for i in sample_split:\n                padding_dim = SAMPLE_DIM - i.shape[1]\n                sample_pad = cv2.copyMakeBorder(i, 0, 0, 0, padding_dim, trainingParams['padding_mode'])\n                samples_pad.append(sample_pad)\n            samples_pad = np.asarray(samples_pad)\n            if not test_mode:\n                labels = [labels] * len(samples_pad)\n                labels = np.asarray(labels)\n                return samples_pad, labels\n            return samples_pad\n        elif proc_mode == 'resize':\n            sample_pad = cv2.resize(sample, (SAMPLE_DIM, N_SAMPLES), interpolation=cv2.INTER_NEAREST)\n            sample_pad = np.expand_dims(sample_pad, axis=0)\n            if not test_mode:\n                labels = np.asarray(labels)\n                return sample_pad, labels\n            return sample_pad\n        elif proc_mode == 'raw':\n            if not test_model:\n                return sample, labels\n            return sample\n\n\nprocessor = DataProcessor()","225b86b6":"DATA_PREFIX = 'proc'\ntrain_filename = 'train_curated_{}.joblib'.format(DATA_PREFIX)\ntest_filename = 'test_{}.joblib'.format(DATA_PREFIX)\n\n\n# Train processing\/loading:\nif os.path.isfile(train_filename):\n    print('load processed train:')\n    train_dict = joblib.load(train_filename)\n    X_train = train_dict['X']\n    y_train = train_dict['y']\n    print(X_train.shape, y_train.shape)\nelse:\n    print('process train...')\n    output = Parallel(n_jobs=-3, verbose=1)(\n        delayed(processor.prepareSample)(\n            train_root, \n            train_df.iloc[f, :],\n            processor.createLogspec,\n            CONFIG,\n            TRAINING_CONFIG,\n            test_mode=False,\n            proc_mode='resize',\n        ) for f in range(train_df.shape[0]))  # change to number of sample in train data for full processing\n    X_train = np.array([x[0] for x in output])\n    y_train = np.array([x[1] for x in output])\n    y_train = pd.Series(y_train).str.get_dummies(sep=',')\n    print(X_train.shape, y_train.shape)\n    # Save output for quicker experiments\n    train_dict = {\n        'X': X_train,\n        'y': y_train,\n    }\n    joblib.dump(train_dict, train_filename)\n    \n\n# Test processing\/loading:\nif os.path.isfile(test_filename):\n    print('load processed test:')\n    test_dict = joblib.load(test_filename)\n    X_test = test_dict['X']\n    print(X_test.shape)\nelse:\n    print('process test...')\n    X_test = Parallel(n_jobs=-3, verbose=1)(\n        delayed(processor.prepareSample)(\n            test_root, \n            sample_submission.iloc[f, :],\n            processor.createLogspec,\n            CONFIG,\n            TRAINING_CONFIG,\n            test_mode=True,\n            proc_mode='resize',\n        ) for f in range(sample_submission.shape[0]))  # change to number of sample in test data for full processing\n    X_test = np.array(X_test)\n    print(X_test.shape)\n    test_dict = {\n        'X': X_test,\n    }\n    joblib.dump(test_dict, test_filename)\n    \n    \n# Switch channel axis from 2nd to last\nX_train = np.moveaxis(X_train, 1, -1)\nX_test = np.moveaxis(X_test, 1, -1)\nprint(X_train.shape, y_train.shape)","b29ee5a6":"# Distribution of multilabel labels\nprint('Multilabel class distribution:')\nprint(y_train.sum(axis=1).value_counts())\n\n# Most of the samples belong to only one class.\n# There are some (around 15%), which belong to two classes.\n# Occurrence of samples belonging to more than two classes at once\n# is quite rare, around 1.5%.","a08de616":"from collections import Counter\nfrom pprint import pprint\n\ndf_lab = (y_train.loc[y_train.sum(axis=1) > 1] > 0)\nmultilabel_combs = []\nfor i in range(df_lab.shape[0]):\n    row_label = df_lab.iloc[i, :][df_lab.iloc[i, :] > 0].index.tolist()\n    multilabel_combs.append(row_label)\n\nmultilabel_comb_counter = Counter(list(map(lambda x: ' + '.join(x), multilabel_combs)))\npprint(multilabel_comb_counter.most_common(20))\n# 20 most common combinations of labels","0d262b0e":"import numpy as np\nimport sklearn.metrics\n\n\n# Based on https:\/\/www.kaggle.com\/voglinio\/keras-2d-model-5-fold-log-specgram-curated-only\n# Core calculation of label precisions for one test sample.\ndef _one_sample_positive_class_precisions(scores, truth):\n    \"\"\"Calculate precisions for each true class for a single sample.\n\n    Args:\n      scores: np.array of (num_classes,) giving the individual classifier scores.\n      truth: np.array of (num_classes,) bools indicating which classes are true.\n\n    Returns:\n      pos_class_indices: np.array of indices of the true classes for this sample.\n      pos_class_precisions: np.array of precisions corresponding to each of those\n        classes.\n    \"\"\"\n    num_classes = scores.shape[0]\n    pos_class_indices = np.flatnonzero(truth > 0)\n    # Only calculate precisions if there are some true classes.\n    if not len(pos_class_indices):\n        return pos_class_indices, np.zeros(0)\n    # Retrieval list of classes for this sample.\n    retrieved_classes = np.argsort(scores)[::-1]\n    # class_rankings[top_scoring_class_index] == 0 etc.\n    class_rankings = np.zeros(num_classes, dtype=np.int)\n    class_rankings[retrieved_classes] = range(num_classes)\n    # Which of these is a true label?\n    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n    retrieved_class_true[class_rankings[pos_class_indices]] = True\n    # Num hits for every truncated retrieval list.\n    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n    precision_at_hits = (\n        retrieved_cumulative_hits[class_rankings[pos_class_indices]] \/\n        (1 + class_rankings[pos_class_indices].astype(np.float)))\n    return pos_class_indices, precision_at_hits\n\n# All-in-one calculation of per-class lwlrap.\n\n\ndef calculate_per_class_lwlrap(truth, scores):\n    \"\"\"Calculate label-weighted label-ranking average precision.\n\n    Arguments:\n      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n        of presence of that class in that sample.\n      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n        test's real-valued score for each class for each sample.\n\n    Returns:\n      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n        class.\n      weight_per_class: np.array of (num_classes,) giving the prior of each\n        class within the truth labels.  Then the overall unbalanced lwlrap is\n        simply np.sum(per_class_lwlrap * weight_per_class)\n    \"\"\"\n    assert truth.shape == scores.shape\n    num_samples, num_classes = scores.shape\n    # Space to store a distinct precision value for each class on each sample.\n    # Only the classes that are true for each sample will be filled in.\n    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n    for sample_num in range(num_samples):\n        pos_class_indices, precision_at_hits = (\n            _one_sample_positive_class_precisions(scores[sample_num, :],\n                                                  truth[sample_num, :]))\n        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n            precision_at_hits)\n    labels_per_class = np.sum(truth > 0, axis=0)\n    weight_per_class = labels_per_class \/ float(np.sum(labels_per_class))\n    # Form average of each column, i.e. all the precisions assigned to labels in\n    # a particular class.\n    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) \/\n                        np.maximum(1, labels_per_class))\n    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n    #                = np.sum(precisions_for_samples_by_classes) \/ np.sum(precisions_for_samples_by_classes > 0)\n    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n    #                = np.sum(per_class_lwlrap * weight_per_class)\n    return per_class_lwlrap, weight_per_class\n\n# Calculate the overall lwlrap using sklearn.metrics function.\n\n\ndef calculate_overall_lwlrap_sklearn(truth, scores):\n    \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n    # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n    sample_weight = np.sum(truth > 0, axis=1)\n    nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n    overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(\n        truth[nonzero_weight_sample_indices, :] > 0,\n        scores[nonzero_weight_sample_indices, :],\n        sample_weight=sample_weight[nonzero_weight_sample_indices])\n    return overall_lwlrap\n\n\n# Accumulator object version.\n\nclass lwlrap_accumulator(object):\n    \"\"\"Accumulate batches of test samples into per-class and overall lwlrap.\"\"\"\n\n    def __init__(self):\n        self.num_classes = 0\n        self.total_num_samples = 0\n\n    def accumulate_samples(self, batch_truth, batch_scores):\n        \"\"\"Cumulate a new batch of samples into the metric.\n\n        Args:\n          truth: np.array of (num_samples, num_classes) giving boolean\n            ground-truth of presence of that class in that sample for this batch.\n          scores: np.array of (num_samples, num_classes) giving the\n            classifier-under-test's real-valued score for each class for each\n            sample.\n        \"\"\"\n        assert batch_scores.shape == batch_truth.shape\n        num_samples, num_classes = batch_truth.shape\n        if not self.num_classes:\n            self.num_classes = num_classes\n            self._per_class_cumulative_precision = np.zeros(self.num_classes)\n            self._per_class_cumulative_count = np.zeros(self.num_classes,\n                                                        dtype=np.int)\n        assert num_classes == self.num_classes\n        for truth, scores in zip(batch_truth, batch_scores):\n            pos_class_indices, precision_at_hits = (\n                _one_sample_positive_class_precisions(scores, truth))\n            self._per_class_cumulative_precision[pos_class_indices] += (\n                precision_at_hits)\n            self._per_class_cumulative_count[pos_class_indices] += 1\n        self.total_num_samples += num_samples\n\n    def per_class_lwlrap(self):\n        \"\"\"Return a vector of the per-class lwlraps for the accumulated samples.\"\"\"\n        return (self._per_class_cumulative_precision \/\n                np.maximum(1, self._per_class_cumulative_count))\n\n    def per_class_weight(self):\n        \"\"\"Return a normalized weight vector for the contributions of each class.\"\"\"\n        return (self._per_class_cumulative_count \/\n                float(np.sum(self._per_class_cumulative_count)))\n\n    def overall_lwlrap(self):\n        \"\"\"Return the scalar overall lwlrap for cumulated samples.\"\"\"\n        return np.sum(self.per_class_lwlrap() * self.per_class_weight())","9851c4d0":"# import tensorflow.keras as keras\n# from tensorflow.keras import layers\n# from tensorflow.keras.callbacks import *\n# from tensorflow.keras.layers import *\n# from tensorflow.keras.optimizers import *\n# from tensorflow.keras.losses import *\n# from tensorflow.keras.models import Model\n\nfrom keras import layers\nfrom keras.callbacks import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.losses import *\nfrom keras.models import Model\n\n\n# Based on https:\/\/github.com\/keras-team\/keras-applications\/blob\/master\/keras_applications\/resnet_common.py\ndef block1(x, filters, kernel_size=3, stride=1,\n           conv_shortcut=True, name=None):\n    \"\"\"A residual block.\n    # Arguments\n        x: input tensor.\n        filters: integer, filters of the bottleneck layer.\n        kernel_size: default 3, kernel size of the bottleneck layer.\n        stride: default 1, stride of the first layer.\n        conv_shortcut: default True, use convolution shortcut if True,\n            otherwise identity shortcut.\n        name: string, block label.\n    # Returns\n        Output tensor for the residual block.\n    \"\"\"\n    bn_axis = 3\n\n    if conv_shortcut is True:\n        shortcut = layers.Conv2D(4 * filters, 1, strides=stride,\n                                 name=name + '_0_conv')(x)\n        shortcut = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                             name=name + '_0_bn')(shortcut)\n    else:\n        shortcut = x\n\n    x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\n    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                  name=name + '_1_bn')(x)\n    x = layers.PReLU(name=name + '_1_prelu')(x)\n\n    x = layers.Conv2D(filters, kernel_size, padding='SAME',\n                      name=name + '_2_conv')(x)\n    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                  name=name + '_2_bn')(x)\n    x = layers.PReLU(name=name + '_2_prelu')(x)\n\n    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                  name=name + '_3_bn')(x)\n\n    x = layers.Add(name=name + '_add')([shortcut, x])\n    x = layers.PReLU(name=name + '_out')(x)\n    \n    return x\n\n\ndef stack1(x, filters, blocks, stride1=2, name=None):\n    \"\"\"A set of stacked residual blocks.\n    # Arguments\n        x: input tensor.\n        filters: integer, filters of the bottleneck layer in a block.\n        blocks: integer, blocks in the stacked blocks.\n        stride1: default 2, stride of the first layer in the first block.\n        name: string, stack label.\n    # Returns\n        Output tensor for the stacked blocks.\n    \"\"\"\n    x = block1(x, filters, stride=stride1, name=name + '_block1')\n    for i in range(2, blocks + 1):\n        x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))\n    return x\n\n\ndef ResNetlike(input_shape, num_classes):\n    \n    use_bias = False\n    num_blocks = 1\n    strides = (2, 4)\n    \n    input_layer = layers.Input(input_shape)\n    # x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(input_layer)\n    x = layers.Conv2D(64, (3, 7), strides=2, use_bias=use_bias, name='conv1_conv')(input_layer)\n    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n                                      name='conv1_bn')(x)\n    x = layers.PReLU(name='conv1_prelu')(x)\n    \n    x = stack1(x, 64, num_blocks, stride1=1, name='conv2')\n    x = stack1(x, 64, num_blocks, stride1=strides, name='conv3')\n    x = stack1(x, 64, num_blocks, stride1=strides, name='conv4')\n    \n    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n    x = layers.Dense(num_classes, activation='softmax', name='probs')(x)\n    \n    model = Model(input_layer, x, name='resnetlike')\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","c23da839":"from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n\n\n# Inspired by https:\/\/www.kaggle.com\/yekenot\/pooled-gru-fasttext\nclass LwlRapEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = calculate_overall_lwlrap_sklearn(self.y_val, y_pred)\n            print(\"\\n LWLRAP - epoch: {} - score: {:.4f} \\n\".format(epoch +1, score))\n        return\n\n\n# Based on https:\/\/www.kaggle.com\/voglinio\/keras-2d-model-5-fold-log-specgram-curated-only\ndef create_unique_labels(all_labels):\n    label_dict = {}\n    all_labels_set = []\n    first_labels_set = []\n    for labs in all_labels:\n        lab = labs.split(',')\n        for l in lab:\n            if l in label_dict:\n                label_dict[l] = label_dict[l]  + 1\n            else:\n                label_dict[l]= 0\n\n        all_labels_set.append(set(lab))\n        first_labels_set.append(lab[0])\n    classes = list(label_dict.keys())\n    \n    return label_dict, classes, all_labels_set, first_labels_set\n\n\nlabel_dict, classes, all_labels_set, first_labels_set = create_unique_labels(train_df.labels)\nbinarize = MultiLabelBinarizer(classes=classes)\ny_cat = binarize.fit_transform(all_labels_set)","c7029dd9":"RUN_NAME = 'ResNetLike_mel'\nBATCH_SIZE = 32\nNUM_EPOCHS = 35\nNFOLDS = 5\nSEED = 1337\nLOAD_MODEL = False\nTRAIN_MODEL = True\nDEBUG = False\nSAVE_SUBMISSION = True\n\n\n# y_cat for categorical_crossentropy\n# y_train.values for binary_crossentropy\nlabels_set = y_cat   \nkfold = KFold(n_splits=NFOLDS, random_state=SEED)\nnum_classes = 80\nbn_axis = 3\n\noof_train = np.zeros((X_train.shape[0], num_classes))\noof_test = np.zeros((X_test.shape[0], num_classes, NFOLDS))\nvalid_scores = []\n\n\n# KFold training\nfor fold_idx, (train_idx, valid_idx) in enumerate(kfold.split(X_train)):\n    X_tr, y_tr = X_train[train_idx], labels_set[train_idx]\n    X_val, y_val = X_train[valid_idx], labels_set[valid_idx]\n    print(X_tr.shape, y_tr.shape)\n    print(X_val.shape, y_val.shape)\n    \n    checkpoint_name = '{}_{}.h5'.format(RUN_NAME, fold_idx)\n    lwl_callback = LwlRapEvaluation(validation_data=(X_val, y_val))\n    \n    callbacks_list = [\n        ModelCheckpoint(checkpoint_name, save_best_only=True, save_weights_only=True),\n        ReduceLROnPlateau(patience=5, factor=0.2),\n        EarlyStopping(patience=8, monitor='val_loss', restore_best_weights=True),\n        lwl_callback,\n    ]\n    \n    model = ResNetlike(X_train.shape[1:], y_train.shape[-1])\n    # model = BaselineModel(X_train.shape[1:])\n    # model.summary()\n    if LOAD_MODEL:\n        print('loading: {}'.format(checkpoint_name))\n        model.load_weights(checkpoint_name)\n    if TRAIN_MODEL:\n        print('training model...')\n        model.fit(\n            X_tr, y_tr, \n            validation_data=(X_val, y_val),\n            batch_size=BATCH_SIZE,\n            epochs=NUM_EPOCHS,\n            verbose=1,\n            callbacks=callbacks_list)\n    print('loading best weights from current fold')\n    model.load_weights(checkpoint_name)\n    \n    val_pred = model.predict(X_val, batch_size=BATCH_SIZE)\n    oof_train[valid_idx, :] = val_pred\n    oof_test[:, :, fold_idx] = model.predict(X_test, batch_size=BATCH_SIZE)\n    \n    val_lwlrap = calculate_overall_lwlrap_sklearn(y_val, val_pred)\n    valid_scores.append(val_lwlrap)\n    print(\"lwlrap fold: {:.4f}\".format(val_lwlrap))\n    # break\n    \n    \noof_lwl = calculate_overall_lwlrap_sklearn(labels_set, oof_train)\nprint('OOF LWLRAP: {:.4f}'.format(oof_lwl))","f3573896":"oof_test_mean = oof_test.mean(axis=-1)\nprint(oof_test_mean.shape)\n\nsort_idx = np.argsort(classes).astype(int)\noof_test_mean_sorted = oof_test_mean[:, sort_idx]\nsample_submission.iloc[:, 1:] =  oof_test_mean_sorted\nif SAVE_SUBMISSION:\n    # sample_submission.to_csv('{}_lwl_{:.4f}.csv'.format(RUN_NAME, oof_lwl, index=False))\n    sample_submission.to_csv('submission.csv', index=False)\n    print(sample_submission.shape)\n    \nsample_submission.head()","6f360713":"## Configuration and global parameters:","5fc29a7c":"## Data Processing class:"}}