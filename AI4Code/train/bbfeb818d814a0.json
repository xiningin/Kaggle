{"cell_type":{"70e208dd":"code","20feeb9f":"code","456a572b":"code","f95feda9":"code","e9a3c031":"code","fe681fa1":"code","b58563ea":"code","9ac1175d":"code","11a319bb":"code","87ec17e2":"code","025c1489":"code","11da2be9":"code","2c224f3c":"code","2eb3ca44":"code","b5a22b86":"code","d2d95074":"code","cb347c3b":"code","255e8d22":"code","7b0f7aa6":"code","78cf1e00":"code","94a59dcc":"code","fc7718a7":"code","529a682e":"code","25a09748":"code","d7a78d75":"code","ec25927d":"code","4ecac064":"code","f8ef892b":"code","234d6bef":"code","b7a9fc68":"code","db905d88":"code","0aaf5f53":"code","a88d60be":"code","841ead8f":"code","933325b8":"code","5dfe2b17":"code","8fce4d3f":"code","e61d1169":"code","15e63ffd":"code","4301cae3":"code","480fff9b":"code","8389023e":"code","7bb4a6b5":"code","b2c2c7a5":"code","f155efc8":"markdown","4fc34628":"markdown","5084663a":"markdown","61604478":"markdown","06253902":"markdown","1f6796a4":"markdown","fc0a0e9b":"markdown","c82b4e7c":"markdown"},"source":{"70e208dd":"import re\nimport string\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport collections \n\nimport nltk\nfrom nltk.corpus import stopwords\n\nimport nltk\nimport gensim\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n########VADER#####\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nvader = SentimentIntensityAnalyzer()\n        ","20feeb9f":"nltk.download('stopwords')","456a572b":"df = pd.read_csv(\"..\/input\/covid19-bharatbiotech-tweets\/BharatBioTech-Refined - Covaxin.csv\")","f95feda9":"df.head()","e9a3c031":"df.isnull().sum()","fe681fa1":"df.describe()","b58563ea":"df.info()","9ac1175d":"df = df.drop(['username','name','language'],axis = 1)","11a319bb":"df.head(10)","87ec17e2":"import string\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","025c1489":"df.tweet = df.tweet.apply(lambda x:clean_text(x))","11da2be9":"df.tweet.head(10)","2c224f3c":"# Now our tweets look cleaned a lot more","2eb3ca44":"sentiments = []\nfor count,tweet in enumerate(df.tweet):\n#     print(tweet)\n    sentiments.append(vader.polarity_scores(tweet))\n    print(count,vader.polarity_scores(tweet))","b5a22b86":"len(sentiments)","d2d95074":"target = []\nfor count,sentiment in enumerate(sentiments):\n    print(count)\n    if sentiment['compound'] >= 0.05: \n        print(\"Positive\")\n        target.append('POSITIVE')\n    elif sentiment['compound'] <= -0.05 : \n        print(\"Negative\")\n        target.append('NEGATIVE')\n    else: \n        print(\"Neutral\")\n        target.append('NEUTRAL')","cb347c3b":"print(target)","255e8d22":"target = pd.DataFrame(target, columns=['target'])\ntarget","7b0f7aa6":"type(target)","78cf1e00":"df = pd.concat([df, target], axis = 1)","94a59dcc":"df.head(10)","fc7718a7":"df.tweet[5]","529a682e":"temp = df.groupby('target').count()['tweet'].reset_index().sort_values(by='tweet',ascending=False)\ntemp.style.background_gradient(cmap='Purples')","25a09748":"plt.figure(figsize=(12,6))\nsns.countplot(x='target',data=df)","d7a78d75":"fig = go.Figure(go.Funnelarea(\n    text = temp.target,\n    values = temp.tweet,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","ec25927d":"stop_words = stopwords.words(\"english\")","4ecac064":"split_words = []\ntop = []\nfor tweet in df.tweet:\n    top.append(tweet)","f8ef892b":"top","234d6bef":"top = str(top)\ntweet = str(df.tweet)","b7a9fc68":"wordcount = {}\nfor word in tweet.lower().split():\n    word = word.replace(\".\",\"\")\n    word = word.replace(\",\",\"\")\n    word = word.replace(\":\",\"\")\n    word = word.replace(\"\\\"\",\"\")\n    word = word.replace(\"!\",\"\")\n    word = word.replace(\"\u00e2\u20ac\u0153\",\"\")\n    word = word.replace(\"\u00e2\u20ac\u02dc\",\"\")\n    word = word.replace(\"*\",\"\")\n    if word not in stop_words:\n        if word not in wordcount:\n            wordcount[word] = 1\n        else:\n            wordcount[word] += 1","db905d88":"word_counter = collections.Counter(wordcount)\nlst = word_counter.most_common(20)\ntemp = pd.DataFrame(lst, columns = ['Word', 'Count'])\ntemp.plot.bar(x='Word',y='Count')\ntemp.columns = ['Word','Count']\ntemp.style.background_gradient(cmap='Purples')","0aaf5f53":"my_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'a',' a ',' a','a ''below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]","a88d60be":"df['tweet_without_stopwords'] = df['tweet'].apply(lambda x:' '.join([word for word in x.split() if word not in  (my_stopwords)]))","841ead8f":"df.tweet.count()","933325b8":"df.tweet_without_stopwords.count()","5dfe2b17":"df","8fce4d3f":"fig = px.bar(temp, x=\"Word\", y=\"Count\", title='Commmon Words in Selected Text', orientation='v', \n             width=700, height=700,color='Count')\nfig.show()","e61d1169":"w2v_model = gensim.models.word2vec.Word2Vec(size=300, \n                                            window=7, \n                                            min_count=10, \n                                            workers=8)","15e63ffd":"%%time\ndocuments = [_text.split() for _text in df.tweet_without_stopwords] ","4301cae3":"w2v_model.build_vocab(documents)","480fff9b":"words = w2v_model.wv.vocab.keys()\nvocab_size = len(words)\nprint(\"Vocab size\", vocab_size)","8389023e":"w2v_model.train(documents, total_examples=len(documents), epochs=8)","7bb4a6b5":"w2v_model.most_similar(\"vaccine\")","b2c2c7a5":"w2v_model.most_similar(\"bharatbiotech\")","f155efc8":"# Bharat-Bio Tech Tweets Analysis using nltk and VADER\n###  This is a starter notebook to the dataset of twitter Bharat-Bio Tech Tweets.\n###  This is my first nltk notebook so please help me to learn and understand best practices.\n### Feel free to correct me and give suggestions by commenting below.\ud83d\ude04","4fc34628":"# Current knowings :\nData is very positive that means people's mood and actions are good towards the vaccination.\nBut some of them could be wrong too.","5084663a":"# Creating targets( POSITIVE, NEGATIVE, NEUTRAL) using VADER","61604478":"# Text cleaning","06253902":"# Notebook under devlopment!\n## Hope you like it and help me to learn more about nltk and Sentiment Analysis\ud83d\ude04\n### Please leave your valuable comment below.","1f6796a4":"# Data Vizualizations ","fc0a0e9b":"# Notebook under completion!","c82b4e7c":"# Imports"}}