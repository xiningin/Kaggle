{"cell_type":{"a4ba2c43":"code","d0c9525d":"code","2a220714":"code","b9037e0f":"code","7710843a":"code","9069cc15":"code","9a515ba0":"code","2ba3aa46":"code","0914cac0":"code","49e30b2b":"code","e2394691":"code","7b9c111f":"code","8833db96":"code","6b595292":"code","5c459c8b":"code","fe35ddae":"code","98d8ed9e":"code","aea107de":"code","6c705eb7":"code","21a54170":"code","4c1d3c38":"code","c875f05c":"code","39feca2b":"code","0147c5e1":"code","cbb042e3":"code","a9e6c9d9":"code","6f426802":"code","d4765577":"code","b2c33796":"code","1be60253":"code","74b6104a":"code","7495d3a3":"code","32b77e44":"code","0e1aa9fa":"code","27c9f898":"code","04310621":"code","2c679ae9":"code","88322fca":"code","b153af04":"markdown","e893e6ee":"markdown","a672ea57":"markdown","2002ba7f":"markdown","5e98f7e5":"markdown","2cdd948f":"markdown","39167055":"markdown","ed5fb901":"markdown","09649631":"markdown","98168420":"markdown","c80dedb0":"markdown"},"source":{"a4ba2c43":"!pip install --extra-index-url https:\/\/developer.download.nvidia.com\/compute\/redist\/cuda\/10.0 nvidia-dali\n","d0c9525d":"from fastai.vision import *\nimport cv2 as cv","2a220714":"train_sample_metadata = pd.read_json('..\/input\/deepfake-detection-challenge\/train_sample_videos\/metadata.json').T.reset_index()\ntrain_sample_metadata.columns = ['fname','label','split','original']\ntrain_sample_metadata.head()","b9037e0f":"fake_sample_df = train_sample_metadata[train_sample_metadata.label == 'FAKE']\nreal_sample_df = train_sample_metadata[train_sample_metadata.label == 'REAL']","7710843a":"train_dir = Path('\/kaggle\/input\/deepfake-detection-challenge\/train_sample_videos\/')\ntest_dir = Path('\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/')\ntrain_video_files = get_files(train_dir, extensions=['.mp4'])\ntest_video_files = get_files(test_dir, extensions=['.mp4'])","9069cc15":"len(train_video_files), len(test_video_files)","9a515ba0":"from nvidia.dali.pipeline import Pipeline\nfrom nvidia.dali import ops\n","2ba3aa46":"fname = train_video_files[0]","0914cac0":"batch_size=1\nsequence_length=30\ninitial_prefetch_size=16\n\nclass VideoPipe(Pipeline):\n    \"video pipeline for a single video with 30 frames\"\n    def __init__(self, batch_size, num_threads, device_id, data, shuffle):\n        super(VideoPipe, self).__init__(batch_size, num_threads, device_id, seed=16)\n        self.input = ops.VideoReader(device=\"gpu\", filenames=data, sequence_length=sequence_length,\n                                     shard_id=0, num_shards=1,\n                                     random_shuffle=shuffle, initial_fill=initial_prefetch_size)\n    def define_graph(self):\n        output = self.input(name=\"Reader\")\n        return output","49e30b2b":"def dali_batch(fname):\n    pipe = VideoPipe(batch_size=batch_size, num_threads=defaults.cpus, device_id=0, data=[fname], shuffle=False)\n    pipe.build()\n    pipe_out = pipe.run()\n    sequences_out = pipe_out[0].as_cpu().as_array()\n    data = torch.from_numpy(sequences_out[0])\n    data = data.permute(0,3,1,2).cuda()\n    return F.interpolate(data.to(torch.float32), (640,640))","e2394691":"%%time\ndata = dali_batch(train_video_files[0])","7b9c111f":"img0 = Image(data[0]\/255)\nimg0.show(figsize=(10,10))","8833db96":"def frame_img_generator(path, freq=None):\n    \"frame generator for a given video file\"\n    vidcap = cv.VideoCapture(str(path))\n    n_frames = 0\n    while True:\n        success = vidcap.grab()\n        if not success: \n            vidcap.release()\n            break   \n            \n        if (freq is None) or (n_frames % freq == 0):\n            _, frame = vidcap.retrieve()\n            frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n#             frame = cv.resize(frame, (640,640))\n            yield frame    \n        \n        n_frames += 1\n        \n    vidcap.release()","6b595292":"%%time\n# CPU warm up\nframes = list(frame_img_generator(train_video_files[0], 10)); len(frames)","5c459c8b":"%%timeit\nframes = list(frame_img_generator(train_video_files[0], freq=10)); len(frames)","fe35ddae":"%%time\nframes = frame_img_generator(train_video_files[0], 10)\ndata = torch.from_numpy(array(frames))\ndata = data.permute(0,3,1,2).cuda()\ndata = F.interpolate(data.to(torch.float32), (640,640))","98d8ed9e":"img1 = Image(data[0]\/255)\nimg1.show(figsize=(10,10))","aea107de":"del frames\ndel data; gc.collect()","6c705eb7":"!pip install -q \/kaggle\/input\/imutils\/imutils-0.5.3","21a54170":"from imutils.video import FileVideoStream","4c1d3c38":"def fvs_img_generator(path, freq=None):\n    \"frame generator for a given video file\"\n    fvs = FileVideoStream(str(path)).start()\n    n_frames = 0\n    while fvs.more():\n        frame = fvs.read()\n        if frame is None: break # https:\/\/github.com\/jrosebr1\/imutils\/pull\/119\n        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n        \n        if (freq is None) or (n_frames % freq == 0):\n            yield frame\n        \n        n_frames += 1\n    fvs.stop()","c875f05c":"%%timeit\nframes = list(fvs_img_generator(str(train_video_files[0]), 10))","39feca2b":"%%time\nframes = list(fvs_img_generator(str(train_video_files[0]), 10))\ndata = torch.from_numpy(array(frames))\ndata = data.permute(0,3,1,2).cuda()\ndata = F.interpolate(data.to(torch.float32), (640,640))","0147c5e1":"img2 = Image(data[0]\/255)\nimg2.show(figsize=(10,10))","cbb042e3":"del frames\ndel data; gc.collect()","a9e6c9d9":"assert torch.all(img1.data == img2.data)","6f426802":"!cp \/kaggle\/input\/decord\/install.sh . && chmod  +x install.sh && .\/install.sh ","d4765577":"sys.path.insert(0,'\/kaggle\/working\/reader\/python')\n\nfrom decord import VideoReader\nfrom decord import cpu, gpu\nfrom decord.bridge import set_bridge\nset_bridge('torch')","b2c33796":"# GPU warm up\nvideo = VideoReader(str(train_video_files[0]), ctx=gpu())\ndel video; gc.collect()","1be60253":"%%time\nvideo = VideoReader(str(train_video_files[0]), ctx=gpu())\ndata = video.get_batch(range(0, len(video), 10))\ndata = F.interpolate(data.to(torch.float32), (640,640))","74b6104a":"img3 = Image(data[0]\/255)\nimg3.show(figsize=(10,10))","7495d3a3":"del video\ndel data; gc.collect()","32b77e44":"torch.mean(torch.isclose(img1.data, img3.data, atol=0.01).float())","0e1aa9fa":"%%time\nvideo = VideoReader(str(train_video_files[0]), ctx=cpu())\ndata = video.get_batch(range(0, len(video), 10)).cuda()\ndata = F.interpolate(data.to(torch.float32), (640,640))","27c9f898":"img4 = Image(data[0]\/255)\nimg4.show(figsize=(10,10))","04310621":"del video\ndel data; gc.collect()","2c679ae9":"assert torch.all(img1.data == img4.data)","88322fca":"torch.mean(torch.isclose(img0.data, img1.data, atol=0.01).float())","b153af04":"### Intro","e893e6ee":"### Conclusion\n\n- Decoder GPU gives a really good boost with litle cost of ~%3 of deviated pixels within (-0.01, 0.01) range. That's a risk I am willing to take :)\n- FileVideoStream isn't much different than open-cv probably we do resizing on a GPU and don't have much CPU bound processing to get full power of threading\n- Let me know if there are anything I am mising\n- As discussed on https:\/\/www.kaggle.com\/leighplt\/decord-videoreader\/notebook memory leaks can occur, so garbage collection is important. I also recommend using https:\/\/github.com\/stas00\/ipyexperiments\/blob\/master\/docs\/ipyexperiments.md\n- Feedback are welcome!","a672ea57":"NVIDIA Dali seems to be more accurate","2002ba7f":"### Vanilla opencv","5e98f7e5":"### Decord Reader GPU\n\nThanks to: https:\/\/www.kaggle.com\/leighplt\/decord-videoreader\/data","2cdd948f":"One thing we can notice is that Decord GPU is not given exactly same results whereas previous 2 methods give exact same pixel level results. Let's check how close both results are.\n\n98% of the pixels are within -+0.01 difference.","39167055":"### imutils: FileVideoStream","ed5fb901":"### Nvidia DALI","09649631":"TODO: Add DALI as a dataset, or if it's available let me know :)","98168420":"In this kernel goal is to simply extract video batches to be fed to a model. For this we will compare vanilla open-cv. FileVideoStream from imutils and excellent latest contribution: Decord from https:\/\/www.kaggle.com\/leighplt\/decord-videoreader\/notebook.\n\n### Steps\n\n- Read frames with sample rate 10 (every 10th starting from 0th index) ~ batch of 30 frames per video\n- Resize frames\n- Convert to pytorch batch ","c80dedb0":"### Decord Reader CPU\n\nOn CPU we don't see any pixel level difference but it's slower."}}