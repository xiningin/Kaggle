{"cell_type":{"e39d9975":"code","74e064e6":"code","eaddd9e7":"code","db5d8348":"code","69fb58e1":"code","d3b4d21c":"code","ea6abc07":"code","428a1966":"code","91445032":"code","0ca8c1dc":"code","b4e3b83c":"code","59a06131":"code","e3878b2d":"code","b8eb5e56":"code","340408b7":"code","969f7176":"code","ebb57571":"code","35579d14":"code","eed5dd1c":"code","4e64fef7":"code","5c034683":"code","1093c595":"code","5779b885":"code","c9237565":"code","bddcef5e":"code","da6b319e":"code","55f46c68":"code","d8dacbc1":"code","1ba56fc4":"code","75039ba8":"code","49e8af54":"code","b385926f":"code","0748768e":"code","57510497":"code","ffb96091":"code","c2c54df6":"code","76c3258c":"code","cf156643":"code","ee8cb4c0":"code","fcccca5c":"code","f19c55c2":"code","b1fccd82":"code","b3ecdfb2":"code","440e8911":"code","e9af5f18":"code","bc6f5be7":"code","8fa5a731":"code","1255ddcd":"code","f46e8440":"code","f6fd04e0":"markdown","f09f48fb":"markdown","36e71373":"markdown","d653d7d3":"markdown","aa477d74":"markdown","ce6ac24d":"markdown","3a877ee3":"markdown","771dec0a":"markdown","1eda73a9":"markdown","78490da5":"markdown"},"source":{"e39d9975":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","74e064e6":"! pip install --upgrade pip\n! pip install scikit-learn==0.24","eaddd9e7":"import sklearn \nsklearn.__version__\nnp.random.seed(42)","db5d8348":"train_df = pd.read_csv(\"\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv\")","69fb58e1":"train_df.head()","d3b4d21c":"train_df.shape","ea6abc07":"# 80 % de treino e 20% de test\nsplit_size = 0.8\nmask = np.random.rand(len(train_df)) < split_size\ntest_df = train_df[~mask]\ntrain_df = train_df[mask]","428a1966":"train_df.shape","91445032":"test_df.shape","0ca8c1dc":"train_df.isna().sum()","b4e3b83c":"# drop na coluna Enrollee_Id\n\ntrain_df = train_df.drop(columns=[\"enrollee_id\"],axis=1)\ntest_df = test_df.drop(columns=[\"enrollee_id\"],axis=1)","59a06131":"## Criando fun\u00e7\u00e3o para retirar os nan, para trocar os valores e converter para inteiro:\n\ndef transform_nan(field):\n    train_df[field] = train_df[field].transform(lambda x: x.fillna(x.mode()[0]))\n    test_df[field] = test_df[field].transform(lambda x: x.fillna(x.mode()[0]))\n    \ndef update_data(field, values):\n    train_df[field].replace(values, inplace=True)\n    test_df[field].replace(values, inplace=True)\n    \ndef update_data_type(field):    \n    train_df[field] = train_df[field].astype(int)\n    test_df[field] = test_df[field].astype(int)\n    ","e3878b2d":"# Tratando o Campo \"Experience\"\n\ntrain_df['experience'].unique()","b8eb5e56":"# tirando o 'nan' da coluna experience do data set de train e test, aplicou o valor da condi\u00e7\u00e3o, passando para inteiro\n\ntransform_nan(\"experience\")\nupdate_data(\"experience\", {'<1': '0', '>20': '21'})\nupdate_data_type(\"experience\")","340408b7":"train_df['experience'].unique()","969f7176":"train_df['last_new_job'].unique()","ebb57571":"# tirando o 'nan' da coluna experience do data set de train e test, aplicou o valor da condi\u00e7\u00e3o, passando para inteiro\n\ntransform_nan(\"last_new_job\")\nupdate_data(\"last_new_job\", {'never': '0', '>4': '5'})\nupdate_data_type(\"last_new_job\")","35579d14":"train_df['last_new_job'].unique()","eed5dd1c":"# 3- Campo enrolled_university\n\ntrain_df['enrolled_university'].unique()","4e64fef7":"#retirando os nan do last_new_job\ntransform_nan(\"enrolled_university\")","5c034683":"train_df['enrolled_university'].unique()","1093c595":"train_df['education_level'].unique()","5779b885":"# retirando o nan da education_level\ntransform_nan(\"education_level\")","c9237565":"train_df['education_level'].unique()","bddcef5e":"train_df['gender'].unique()","da6b319e":"# criando a categoria Unknown do Gender, substiruindo nan = Unknown\n\ntrain_df['gender'] = train_df['gender'].fillna('Unknown')\ntest_df['gender'] = test_df['gender'].fillna('Unknown')","55f46c68":"train_df['gender'].unique()","d8dacbc1":"train_df['major_discipline'].unique()","1ba56fc4":"train_df['major_discipline'] = train_df['major_discipline'].fillna('Unknown')\ntest_df['major_discipline'] = test_df['major_discipline'].fillna('Unknown')","75039ba8":"train_df['major_discipline'].unique()","49e8af54":"train_df['company_size'].unique()","b385926f":"train_df['company_size']=train_df['company_size'].fillna('Unknown')\ntest_df['company_size'] = test_df['company_size'].fillna('Unknown')","0748768e":"train_df['company_size'].unique()","57510497":"train_df['company_type'].unique()","ffb96091":"#inserindo unknown no company_type\ntrain_df['company_type']=train_df['company_type'].fillna('Unknown')\ntest_df['company_type'] = test_df['company_type'].fillna('Unknown')","c2c54df6":"train_df['company_type'].unique()","76c3258c":"train_df.isna().sum()","cf156643":"train_df.head()","ee8cb4c0":"x_columns = [\"city\", \"city_development_index\", \"gender\", \"relevent_experience\", \"enrolled_university\", \"education_level\", \"major_discipline\", \"experience\",\"company_size\", \"company_type\", \"last_new_job\", \"training_hours\"]\ny_column = [\"target\"]\nX_train = train_df[x_columns]\ny_train = train_df[y_column]\nX_test = test_df[x_columns]\ny_test = test_df[y_column]","fcccca5c":"X_train.head()","f19c55c2":"y_train.head()","b1fccd82":"# transformar dataset para valores num\u00e9ricos\n\nfrom sklearn.preprocessing import OrdinalEncoder\n\ndata_encoder = OrdinalEncoder(handle_unknown = \"use_encoded_value\", unknown_value = -1)\nX_train = data_encoder.fit_transform(X_train)","b3ecdfb2":"X_train","440e8911":"# RANDOM FOREST\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# 100 arvores de decis\u00e3o ir\u00e3o ser geradas aleat\u00f3rias e  5 = profundidade das \u00e1rvores.\nclf = RandomForestClassifier(100, max_depth=5)\nclf.fit(X_train, y_train)","e9af5f18":"from sklearn.metrics import classification_report\n\nX_test = data_encoder.transform(X_test)\n\nreport = classification_report(clf.predict(X_test), y_test)\nprint(report)","bc6f5be7":"#encontrando os melhores valores de random forest com grid search\n\nfrom sklearn.metrics import accuracy_score\n\nbest_score = 0\nbest_n = 1\nresults_train, results_test = [], []\nfor n in range(1, 101):\n    clf = RandomForestClassifier(n, max_depth=3)\n    clf.fit(X_train, y_train)\n    score = accuracy_score(clf.predict(X_test), y_test)\n    results_train.append(score)\n    results_test.append( accuracy_score(clf.predict(X_train), y_train) )\n    if score > best_score:\n        best_score = score\n        best_n = n\nprint(\"Melhor score\", score)\nprint(\"Melhor n\u00famero de \u00e1rvores de decis\u00e3o: \", best_n)","8fa5a731":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(20,5))\n\nplt.plot(range(1, 101), results_train)\nplt.plot(range(1, 101), results_test)","1255ddcd":"clf.estimators_","f46e8440":"from sklearn import tree\nimport graphviz\n\n# DOT data\ndot_data = tree.export_graphviz(clf.estimators_[1], out_file=None, \n                                feature_names=x_columns,  \n                                class_names=[\"Sem vontade\", \"Com vontade\"],\n                                filled=True)\n\n# Draw graph\ngraph = graphviz.Source(dot_data, format=\"png\") \ngraph","f6fd04e0":"### 3- Campo enrolled_university","f09f48fb":"### Resultados: \n\n### O nosso melhor score foi de 0.7590897201150929 e o melhor n\u00famero de arvores de decis\u00e3o foi 2.\n","36e71373":"### 1 - Tratando o Campo \"last_new_job\"","d653d7d3":"### 4 - Campo education_level","aa477d74":"## 6 Campo - major_discipline","ce6ac24d":"### 5 - campo gender","3a877ee3":"### 8 - campo company_type","771dec0a":"### 0 - Tratando o Campo \"Experience\"","1eda73a9":"### 7 - campo company_size","78490da5":"##  Henrique Seschin Neto \n##  Robson Agapito Correa \n\n### Desafio Kaggle - Random Forest"}}