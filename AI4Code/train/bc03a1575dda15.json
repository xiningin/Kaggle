{"cell_type":{"e5f24f06":"code","2f07cad4":"code","7c584403":"code","f703e73f":"code","8550493c":"code","d257bf91":"code","c1171a71":"code","8794ef43":"code","5404c3b0":"code","52571459":"code","f9d80678":"code","0e9f1d7c":"code","9e4e1982":"code","7084e3f0":"code","9fc8d4d1":"code","f954e669":"code","00524d17":"code","c82d8a4c":"code","0b5563e3":"code","98309841":"code","59e90648":"code","a1191102":"code","d3d6c751":"code","cbd9cd2f":"code","eb97cb62":"code","61b1a433":"code","4e1150b1":"code","eb309277":"code","5fcb3167":"code","746bf830":"code","d3a24c11":"code","f169a231":"code","23b87a67":"code","1446ba89":"code","e13eed76":"code","648ae967":"code","067e7c1f":"code","c17fc2d4":"code","e51dc07a":"code","aef0b1b0":"code","99986918":"code","4d75eeee":"code","03f9193e":"code","0e231e13":"code","d3cc94a8":"code","b50b8e20":"code","8512b213":"code","f52917f4":"code","86307f90":"code","8ff400c3":"code","39dee9f5":"code","84b93d99":"code","5d40235b":"code","da07f58d":"code","6a5390a9":"code","c5f64d22":"code","a089e280":"code","42683ef8":"code","298a9dce":"code","974e6ee1":"code","8f7a8867":"code","5ccb9045":"code","9921d3c4":"code","f9bb489f":"code","972df2fb":"code","c47ba1c5":"code","5e501717":"code","0b66628b":"code","92d95c5c":"code","ee1c2d8f":"code","a0ef239e":"code","8f3cd87a":"code","c8c5c625":"code","b3928e37":"code","af2a5de9":"code","f3baba3c":"code","f8d0c4e7":"code","b0fc40c0":"code","f1563b93":"code","f1d5d919":"code","89b80a5b":"code","010c494c":"code","9373a7e2":"code","1b5e17cc":"code","6d0a86cc":"code","ffc629a7":"code","4e300d66":"code","3761288d":"code","b1cfe0a3":"code","9ebfb2f5":"code","280deeff":"code","15068a3a":"code","ba82f531":"code","b9bc67cb":"code","1d737036":"code","754b2517":"code","49beb987":"code","61837a6a":"code","b73cf705":"code","5afe7501":"code","255f9cb9":"code","a251b307":"code","8b6ad6ef":"code","a6e614f1":"code","b959f9c3":"code","3e389850":"code","9d5a69e3":"code","29a74c3b":"code","49cd33a6":"code","7db973c5":"code","0f76357c":"code","87fb31d0":"code","f818986f":"code","d416f8bc":"code","4b4d24eb":"code","26964127":"code","b79e2ff2":"code","7b47ede1":"code","7cf7e21e":"code","907f3896":"code","e106a91f":"code","1c7699b5":"code","c2ed30e0":"code","3341f0da":"code","89abddf7":"code","a3137c89":"code","42bcc456":"code","d717509d":"code","f673aa37":"code","5a4df64f":"code","97b78158":"code","a8a7d2ca":"code","5abf85d5":"code","d0ca5e1f":"code","48dff0b5":"code","5e7bceb4":"code","5dc921f1":"code","932eec63":"code","d66ef6d1":"code","e0055508":"code","e8562513":"code","16338967":"code","ab72c43a":"code","84f11bea":"code","cd484a5b":"code","6bfdd034":"code","bb099453":"code","7df9916e":"code","ef135709":"code","7f253796":"code","e5959dab":"code","089aa5eb":"code","985d743e":"code","0aadb673":"code","72afc2f0":"code","45b24313":"markdown","47ac5731":"markdown","4260d32e":"markdown","3aa42789":"markdown","6c12a30c":"markdown","3ec92ae7":"markdown","a24439fa":"markdown","0c3bc33e":"markdown","0e26d07e":"markdown","862873aa":"markdown","ceb4143b":"markdown","6c05d395":"markdown","20d9832e":"markdown","18674fea":"markdown","ef17e44c":"markdown","27a494b4":"markdown","8db3cecc":"markdown","65b386a2":"markdown","763e06a5":"markdown","336bb3b3":"markdown","f9bfe0f9":"markdown","9e7541d7":"markdown","7174a38b":"markdown","ca3c9c8d":"markdown","909c9fd6":"markdown","26ed359c":"markdown","b1bb9911":"markdown","48c85038":"markdown","cfd95206":"markdown","205e82e1":"markdown","403d112e":"markdown","b5c5809e":"markdown","f145da26":"markdown","7ec58589":"markdown","2c5c1561":"markdown","4437be14":"markdown","4f3e411f":"markdown","e9d34dc8":"markdown","6cfc3043":"markdown","dbec7856":"markdown","69d435aa":"markdown","2fd46277":"markdown","e6c7f64f":"markdown","cca838ff":"markdown","3a12f688":"markdown","4221939e":"markdown","f7375ced":"markdown","3e9cba1f":"markdown","c3961990":"markdown","9c61f4cc":"markdown","ccfe92b7":"markdown","8dd4f750":"markdown","fbcf3001":"markdown","d893cff0":"markdown","9bfb9499":"markdown","67ffd493":"markdown","da3ae4d3":"markdown","6694f559":"markdown","4d7551dc":"markdown","d74e91fa":"markdown","3d06703d":"markdown","490fe9e0":"markdown","586b2819":"markdown","f24f5683":"markdown","31957d40":"markdown","041fd893":"markdown","a96a5a73":"markdown"},"source":{"e5f24f06":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport sys\nimport os\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nimport eli5\n\nfrom scipy.stats import skew, norm\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\nfrom IPython.display import display\n\n\nPATH = '\/kaggle\/input\/house-prices-advanced-regression-techniques\/'","2f07cad4":"df_train = pd.read_csv(PATH + 'train.csv')\ndf_test = pd.read_csv(PATH + 'test.csv')","7c584403":"df_train.head()","f703e73f":"df_train.columns","8550493c":"df_train.info()","d257bf91":"df_train.shape, df_test.shape","c1171a71":"categorical_features = np.where(df_train.dtypes == object)\nnumerical_features = np.where(df_train.dtypes != object)\nlen(categorical_features[0]), len(numerical_features[0])","8794ef43":"df_train.describe().T","5404c3b0":"sns.distplot(df_train['SalePrice'])","52571459":"def fromNumtoName(data, num):\n    res = []\n    for i in data.columns:\n        if (data.columns.get_loc(i) in num):\n            res.append(i)\n    return res","f9d80678":"cat_features_text = fromNumtoName(df_train, categorical_features[0])\nnum_features_text = fromNumtoName(df_train, numerical_features[0])","0e9f1d7c":"sns.pairplot(df_train[num_features_text], x_vars=['SalePrice'],\n             y_vars = num_features_text[1:len(num_features_text)-1])","9e4e1982":"cor_marix = df_train[num_features_text].corr()\nsns.heatmap(cor_marix)","7084e3f0":"k = 14 #number of variables for heatmap\ncols = cor_marix.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = df_train[cols].corr()\n\nhm = sns.heatmap(cm, annot=True)","9fc8d4d1":"cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(df_train[cols])","f954e669":"# Remove the Ids from train and test, as they are unique for each row and hence not useful for the model\ntrain_ID = df_train['Id']\ntest_ID = df_test['Id']\ndf_train.drop(['Id'], axis=1, inplace=True)\ndf_test.drop(['Id'], axis=1, inplace=True)\ndf_train.shape, df_test.shape","00524d17":"df_train['SalePrice'] = np.log1p(df_train[\"SalePrice\"])","c82d8a4c":"sns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n#Check the new distribution \nsns.distplot(df_train['SalePrice'] , fit=norm, color=\"b\");\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(df_train['SalePrice'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice distribution\")\nsns.despine(trim=True, left=True)\n\nplt.show()","0b5563e3":"def checkMissingValues(data):\n    total = data.isnull().sum()\n    percent = (100*data.isnull().sum()\/data.isnull().count())\n    types = data.dtypes\n\n\n    missing_data = pd.DataFrame({'Total':total, 'Percent':percent, 'Type':types })\n    missing_data.sort_values(by='Percent', ascending =False, inplace = True)\n    \n    return missing_data","98309841":"missing_data_train = checkMissingValues(df_train)\nmissing_data_train.head(20)","59e90648":"df_train_filled = df_train.copy()","a1191102":"none_val_col = ['PoolQC','MiscFeature','Alley','Fence', 'FireplaceQu','GarageCond',\n               'GarageType', 'GarageFinish','GarageQual','BsmtFinType2','BsmtFinType1',\n               'BsmtExposure','BsmtQual','BsmtCond','MasVnrType']\nzero_num_col = ['GarageYrBlt','MasVnrArea']\ndrop_col = ['Electrical']\n\n\n#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\ndf_train_filled[\"LotFrontage\"] = df_train_filled.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n\ndf_train_filled[none_val_col] = df_train_filled[none_val_col].fillna('None')\ndf_train_filled[zero_num_col] = df_train_filled[zero_num_col].fillna(0)\ndf_train_filled = df_train_filled.drop(df_train_filled.loc[df_train['Electrical'].isnull()].index)","d3d6c751":"df_train_filled.isnull().sum().sum()","cbd9cd2f":"missing_data_test = checkMissingValues(df_test)\nmissing_data_test.head(34)","eb97cb62":"new_missing_cols=[]\nfor i in missing_data_test[missing_data_test['Total']>0].index:\n    if (i not in missing_data_train[missing_data_train['Total']>0].index):\n        new_missing_cols.append(i)\nnew_missing_cols","61b1a433":"sns.countplot(df_test['BsmtFinType1'])","4e1150b1":"df_test_filled = df_test.copy()\n\n\n#Utilities = AllPub\n#Functional = Typ\n\nmode_num_col_test = ['MSZoning','KitchenQual','Exterior1st','Exterior2nd','SaleType']\nzero_num_col_test = zero_num_col + ['BsmtHalfBath','BsmtFullBath','BsmtFinSF1','BsmtFinSF2','GarageArea','GarageCars',\n                                   'BsmtUnfSF','TotalBsmtSF']\nhigh_prob = {'Utilities':'AllPub', 'Functional':'Typ'}\n\n\n#Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\ndf_test_filled[\"LotFrontage\"] = df_test_filled.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n\nfor col in mode_num_col_test:\n    df_test_filled[col] = df_test_filled[col].fillna(df_test_filled[col].mode()[0])\n\ndf_test_filled[none_val_col] = df_test_filled[none_val_col].fillna('None')\ndf_test_filled[zero_num_col_test] = df_test_filled[zero_num_col_test].fillna(0)\n\nfor col in high_prob.keys():\n    df_test_filled[col] = df_test_filled[col].fillna(high_prob.get(col))","eb309277":"df_test_filled.isnull().sum().sum()","5fcb3167":"df_train_clean = df_train.copy()\ndf_test_clean = df_test_filled.copy()","746bf830":"df_train_clean = df_train_clean.drop((missing_data_train[missing_data_train['Total'] > 1]).index,axis = 1)\ndf_train_clean = df_train_clean.drop(df_train.loc[df_train['Electrical'].isnull()].index)\ndf_test_clean = df_test_filled.drop((missing_data_train[missing_data_train['Total'] > 1]).index,axis = 1)","d3a24c11":"cat_features_clean_text = fromNumtoName(df_train_clean, np.where(df_train_clean.dtypes == object)[0])\nnum_features_clean_text = fromNumtoName(df_train_clean, np.where(df_train_clean.dtypes != object)[0])","f169a231":"df_train_clean.isnull().sum().sum()","23b87a67":"df_test_filled.shape, df_test_clean.shape","1446ba89":"df_train_filled.shape,df_test_filled.shape","e13eed76":"df_train_clean.shape, df_test_clean.shape","648ae967":"#filled\ndf_filled = pd.concat([df_train_filled,df_test_filled])\ndf_filled = pd.get_dummies(data=df_filled, columns=cat_features_text,prefix=cat_features_text)\n\ndf_train_filled = df_filled.iloc[:df_train_filled.shape[0]]\ndf_test_filled = df_filled.iloc[df_train_filled.shape[0]:].drop('SalePrice', axis=1)\n\n\n\n#clean\ndf_clean = pd.concat([df_train_clean,df_test_clean])\ndf_clean = pd.get_dummies(data=df_clean, columns=cat_features_clean_text,prefix=cat_features_clean_text)\n\ndf_train_clean = df_clean[:df_train_clean.shape[0]]\ndf_test_clean = df_clean[df_train_clean.shape[0]:].drop('SalePrice', axis=1)","067e7c1f":"df_train_filled.shape, df_test_filled.shape,","c17fc2d4":"df_train_clean.shape, df_test_clean.shape,","e51dc07a":"def makeZommedHeatmap(data, k):\n    cor_matrix = data.corr()\n    cols = cor_matrix.nlargest(k, 'SalePrice')['SalePrice'].index\n    cor_matrix_zoomed = data[cols].corr()\n\n    sns.heatmap(cor_matrix_zoomed, annot=True)\n    return cor_matrix_zoomed","aef0b1b0":"makeZommedHeatmap(df_train_filled, 14);","99986918":"makeZommedHeatmap(df_train_clean, 14);","4d75eeee":"X_filled = df_train_filled.drop('SalePrice', axis=1)\nX_test_filled = df_test_filled\nX_clean = df_train_clean.drop(['SalePrice'], axis=1)\nX_test_clean = df_test_clean\n\ny = df_train_filled['SalePrice']","03f9193e":"X_train_filled, X_val_filled, y_train_filled, y_val_filled = train_test_split(X_filled, y,\n                                                                         test_size=0.3, random_state=17)\n\nX_train_clean, X_val_clean, y_train_clean, y_val_clean = train_test_split(X_clean, y,\n                                                                         test_size=0.3, random_state=17)","0e231e13":"#Validation function\nn_folds = 5\n\ndef cross_val(model, X,y, disp=True):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X)\n    rmse= np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv = kf))\n    model.fit(X,y)\n    if disp:\n        display(eli5.show_weights(estimator=model, feature_names=X.columns.values))\n    return(rmse)","d3cc94a8":"def makeSubm(estimator, X_train, y_train, X_test, nameFile):\n    estimator.fit(X_train, y_train);\n    test_pred = estimator.predict(X_test)\n    sample_sub = pd.read_csv(PATH +'sample_submission.csv', \n                             index_col='Id')\n    sample_sub['SalePrice'] = np.expm1(test_pred)\n    sample_sub.to_csv(nameFile)","b50b8e20":"forest = RandomForestRegressor(random_state=17, n_jobs=-1)\n\nforest.fit(X_train_filled,y_train_filled)","8512b213":"mean_squared_error(y_val_filled,forest.predict(X_val_filled), squared=False)","f52917f4":"cross_val(forest, X_filled, y).mean()","86307f90":"forest = RandomForestRegressor(random_state=17, n_jobs=-1)\n\nforest.fit(X_train_clean,y_train_clean)","8ff400c3":"mean_squared_error(y_val_clean,forest.predict(X_val_clean), squared=False)","39dee9f5":"eli5.show_weights(estimator=forest, feature_names=X_train_clean.columns.values)","84b93d99":"cross_val(forest,X_clean,y).mean()","5d40235b":"forest = RandomForestRegressor(random_state=17, n_jobs=-1)\nmakeSubm(forest, X_filled, y, X_test_filled, \"subm1.csv\")#0.14453","da07f58d":"X_all = pd.concat([X_filled,X_test_filled])","6a5390a9":"X_all['MSSubClass'] = X_all['MSSubClass'].astype(str)\nX_all['YrSold'] = X_all['YrSold'].astype(str)\nX_all['MoSold'] = X_all['MoSold'].astype(str)\n\n# Total sqfootage feature \nX_all['TotalSF'] = X_all['TotalBsmtSF'] + X_all['1stFlrSF'] + X_all['2ndFlrSF']\nX_all['Total_Home_Quality'] = X_all['OverallCond'] + X_all['OverallQual']","c5f64d22":"string_col = ['MSSubClass', 'YrSold', 'MoSold']\n\n\nX_all = pd.get_dummies(data=X_all, columns=string_col, prefix=string_col)\n\nX_filled = X_all.iloc[:X_filled.shape[0]]\nX_test_filled = X_all.iloc[X_filled.shape[0]:]","a089e280":"cross_val(RandomForestRegressor(random_state=17, n_jobs=-1), X_filled, y).mean()","42683ef8":"makeSubm(RandomForestRegressor(random_state=17, n_jobs=-1), X_filled, y, X_test_filled, \"subm2.csv\")#0.14236","298a9dce":"X_all = pd.concat([X_filled,X_test_filled])","974e6ee1":"X_all['YrBltAndRemod'] = X_all['YearBuilt'] + X_all['YearRemodAdd']\n\nX_all['has2ndfloor'] = (X_all['2ndFlrSF']> 0).astype('int')\nX_all['hasbsmt'] = (X_all['TotalBsmtSF']> 0).astype('int')\nX_all['hasgarage'] = (X_all['GarageArea']> 0).astype('int')\nX_all['HasWoodDeck'] = (X_all['WoodDeckSF'] == 0).astype('int')\nX_all['HasOpenPorch'] = (X_all['OpenPorchSF'] == 0).astype('int')\nX_all['HasEnclosedPorch'] = (X_all['EnclosedPorch'] == 0).astype('int')\nX_all['Has3SsnPorch'] = (X_all['3SsnPorch'] == 0).astype('int')\nX_all['HasScreenPorch'] = (X_all['ScreenPorch'] == 0).astype('int')","8f7a8867":"X_filled = X_all.iloc[:X_filled.shape[0]]\nX_test_filled = X_all.iloc[X_filled.shape[0]:]","5ccb9045":"cross_val(RandomForestRegressor(random_state=17, n_jobs=-1), X_filled, y).mean()","9921d3c4":"num_features_text_res =[]\nfor col in num_features_text:\n    if (col not in string_col+['Id', 'SalePrice']):\n        num_features_text_res.append(col)\nnum_features_text = num_features_text_res","f9bb489f":"X_all = pd.concat([X_filled,X_test_filled])","972df2fb":"# Create box plots for all numeric features\nsns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(8, 7))\nax.set_xscale(\"log\")\nax = sns.boxplot(data=X_all[num_features_text] , orient=\"h\", palette=\"Set1\")\nax.xaxis.grid(False)\nax.set(ylabel=\"Feature names\")\nax.set(xlabel=\"Numeric values\")\nax.set(title=\"Numeric Distribution of Features\")\nsns.despine(trim=True, left=True)","c47ba1c5":"# Find skewed numerical features\nskew_features = X_all[num_features_text].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nprint(f'There are {high_skew.shape[0]} numerical features with Skew > 0.5 :')\nskewness = pd.DataFrame({'Skew' :skew_features})\nskewness.head(25)","5e501717":"for col in skew_index:\n    X_all[col] = boxcox1p(X_all[col], boxcox_normmax(X_all[col] + 1))","0b66628b":"# Let's make sure we handled all the skewed values\nsns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(8, 7))\nax.set_xscale(\"log\")\nax = sns.boxplot(data=X_all[skew_index] , orient=\"h\", palette=\"Set1\")\nax.xaxis.grid(False)\nax.set(ylabel=\"Feature names\")\nax.set(xlabel=\"Numeric values\")\nax.set(title=\"Numeric Distribution of Features\")\nsns.despine(trim=True, left=True)","92d95c5c":"# Find skewed numerical features after box-cox\nskew_features_after = X_all[num_features_text].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew_after = skew_features_after[skew_features_after > 0.5]\n\nprint(f'There are {high_skew_after.shape[0]} numerical features with Skew > 0.5 :')\nskewness['Skew_after'] = skew_features_after\nskewness[skew_features_after > 0.5]","ee1c2d8f":"cols_for_box_cox = skewness[(skewness['Skew']>0.5) & (skewness['Skew']>skewness['Skew_after'])].index\nX_all = pd.concat([X_filled,X_test_filled])\n\nfor col in cols_for_box_cox:\n    X_all[col] = boxcox1p(X_all[col], boxcox_normmax(X_all[col] + 1))\n\nX_filled = X_all.iloc[:X_filled.shape[0]]\nX_test_filled = X_all.iloc[X_filled.shape[0]:]","a0ef239e":"cross_val(RandomForestRegressor(random_state=17, n_jobs=-1), X_filled, y).mean() ","8f3cd87a":"from sklearn.linear_model import ElasticNet,ElasticNetCV, Lasso, LassoCV, Ridge,RidgeCV\nfrom sklearn.ensemble import GradientBoostingRegressor, StackingRegressor\nfrom sklearn.pipeline import make_pipeline,Pipeline\nfrom sklearn.preprocessing import RobustScaler\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.svm import SVR","c8c5c625":"scores= pd.DataFrame()","b3928e37":"rf = RandomForestRegressor(random_state=17, n_jobs=-1)\nscore = cross_val(rf, X_filled, y)\nscores['rf'] = (score.mean(),score.std())","af2a5de9":"lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.001, random_state=17))\nscore = cross_val(lasso, X_filled,y)\nscores['lasso'] = (score.mean(),score.std())","f3baba3c":"ridge = make_pipeline(RobustScaler(), Ridge(alpha =50, random_state=17))\nscore = cross_val(ridge, X_filled,y)\nscores['ridge'] = (score.mean(),score.std())","f8d0c4e7":"ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.001, l1_ratio=1, random_state=17))\nscore = cross_val(ENet, X_filled,y)\nscores['ENet'] = (score.mean(),score.std())","b0fc40c0":"GBoost = GradientBoostingRegressor(random_state =17)\nscore = cross_val(GBoost, X_filled,y)\nscores['gboost'] = (score.mean(),score.std())","f1563b93":"gbr_pipe = make_pipeline(RobustScaler(), GBoost)\nscore = cross_val(gbr_pipe, X_filled,y)\nscores['gbr_pipe'] = (score.mean(),score.std())","f1d5d919":"model_xgb = xgb.XGBRegressor(random_state = 17)\nscore = cross_val(model_xgb, X_filled,y)\nscores['xgb'] = (score.mean(),score.std())","89b80a5b":"xgb_pipe = make_pipeline(RobustScaler(), model_xgb)\nscore = cross_val(xgb_pipe, X_filled,y)\nscores['xgb_pipe'] = (score.mean(),score.std())","010c494c":"model_lgb = lgb.LGBMRegressor(objective='regression', random_state=17)\nscore = cross_val(model_lgb, X_filled,y)\nscores['lgb'] = (score.mean(),score.std())","9373a7e2":"lgb_pipe = make_pipeline(RobustScaler(), model_lgb)\nscore = cross_val(lgb_pipe, X_filled,y)\nscores['lgb_pipe'] = (score.mean(),score.std())","1b5e17cc":"svr = make_pipeline(RobustScaler(), SVR(C=1))\nscore = cross_val(svr, X_filled,y)\nscores['svr'] = (score.mean(),score.std())","6d0a86cc":"scores['value'] = ('mean','std')\nscores.set_index('value',inplace = True)\nscores","ffc629a7":"makeSubm(lasso,X_filled,y,X_test_filled,'subm3.csv')#0.12484","4e300d66":"from sklearn.feature_selection import SelectPercentile, f_regression,mutual_info_regression\n\nX_filled_sp = SelectPercentile(mutual_info_regression, percentile=10).fit_transform(X_filled, y)\n\nres = pd.DataFrame()\nfor percent in range(10,100,10):\n    X_filled_sp = SelectPercentile(mutual_info_regression, percentile=percent).fit_transform(X_filled, y)\n    score = cross_val(GradientBoostingRegressor(random_state=17),X_filled_sp,y, disp=False)\n    res[f'{percent}'] = (score.mean(),score.std())\nres","3761288d":"for percent in range(52,60,2):\n    X_filled_sp = SelectPercentile(mutual_info_regression, percentile=percent).fit_transform(X_filled, y)\n    score = cross_val(GradientBoostingRegressor(random_state=17),X_filled_sp,y, disp=False)\n    res[f'{percent}'] = (score.mean(),score.std())\nres['values'] = ('mean','std')\nres.set_index('values', inplace=True)\nres","b1cfe0a3":"sp = SelectPercentile(mutual_info_regression, percentile=56)\nX_filled_perc = sp.fit_transform(X_filled, y)\nX_filled_perc.shape","9ebfb2f5":"X_test_perc = sp.transform(X_test_filled)\nX_test_perc.shape","280deeff":"from sklearn.model_selection import GridSearchCV","15068a3a":"n_folds=5\nkf = KFold(n_folds, shuffle=True, random_state=42)","ba82f531":"params_rf = {'n_estimators':[200,500,1000,1200, 1300,1400],#1300\n             'max_depth':[3,5,10,13, 15, 17], #15\n             'min_samples_split':[2,3,4,5,7], #2\n             'min_samples_leaf':[3,5,7]}\n\nrf = RandomForestRegressor(random_state=17,n_jobs=-1,max_depth=15, min_samples_split=2,\n                           n_estimators=1300, min_samples_leaf=3)\n\ngrid_rf = GridSearchCV(rf, {'min_samples_leaf':[3,5,7]}, cv=kf, n_jobs=-1,\n                       verbose=5,scoring=\"neg_mean_squared_error\")","b9bc67cb":"#grid_rf.fit(X_filled,y)\n#np.sqrt(-grid_rf.best_score_), grid_rf.best_params_","1d737036":"lasso_alphas = np.logspace(-10,2,50)\n                \nlassoCV = make_pipeline(RobustScaler(), LassoCV(alphas=lasso_alphas, cv=kf))","754b2517":"ridge_alphas = np.logspace(-5,5,50)\nridgeCV = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alphas, cv=kf))","49beb987":"ENet = make_pipeline(RobustScaler(), ElasticNetCV(alphas=ridge_alphas,\n                                                  l1_ratio=lasso_alphas, cv=kf))","61837a6a":"ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))","b73cf705":"params_svr = {'svr__C':[0.5,1,3,5,10,20,50],\n             'svr__epsilon':[1e-5,1e-4,5e-4,8e-3,1e-3,1e-2,0.1,1], \n             'svr__gamma':[1e-4,3e-4,1e-3,1e-2,0.1,1],\n             'svr__kernel':['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']}\n\nsvr = Pipeline(steps=[('scaler',RobustScaler()),('svr', SVR(C=20, epsilon=8e-3, gamma=3e-4))])\nsvr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n\ngrid_svr = GridSearchCV(svr, {'svr__kernel':['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']}, cv=kf, n_jobs=-1,\n                       verbose=5,scoring=\"neg_mean_squared_error\")","5afe7501":"#grid_svr.fit(X_filled,y)\n#grid_svr.best_params_","255f9cb9":"params_gbr = {'n_estimators':[200,1000,3000],\n             'learning_rate':[0.01,0.03,0.1,0.3], \n             'max_depth':[2,4,6,8],\n             'max_features':['auto', 'sqrt', 'log2'],\n             'min_samples_leaf':[5,10,15,20],\n             'min_samples_split':[5,10,15,20]}\n\ngbr = GradientBoostingRegressor(n_estimators=3000,\n                                learning_rate=0.01,\n                                max_depth=4,\n                                max_features='sqrt',\n                                min_samples_leaf=15,\n                                min_samples_split=10,\n                                loss='huber',\n                                random_state=42)\n\ngrid_gbr = GridSearchCV(gbr, {'min_samples_split':[5,10,15,20]}, cv=kf, n_jobs=-1,\n                       verbose=5,scoring=\"neg_mean_squared_error\")","a251b307":"#grid_gbr.fit(X_filled,y)\n#grid_gbr.best_params_","8b6ad6ef":"params_xgb = {'n_estimators':[200,1000,3000],\n             'learning_rate':[0.01,0.03,0.1,0.3], \n             'max_depth':[2,4,6,8],\n             'colsample_bytree':[0.1,0.5,1],\n             'gamma':[0.01,0.03,0.1,0.3,1],\n             'min_child_weight':[0,0.5,1,1.5,2],\n             'reg_alpha':[1e-6,1e-5,0.001,0.01,0.1,1],\n             'subsample':[0.01,0.1,0.5,1]}\n\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.5, gamma=0.03,\n                             learning_rate=0.03, max_depth=4, \n                              n_estimators=3000,min_child_weight=0,\n                              subsample=0.5,reg_alpha=1e-6,\n                             random_state =17, nthread = -1)\n\ngrid_xgb = GridSearchCV(model_xgb, {'reg_alpha':[1e-6,1e-5,0.001,0.01,0.1,1]}, cv=kf, n_jobs=-1,\n                       verbose=5,scoring=\"neg_mean_squared_error\")","a6e614f1":"#grid_xgb.fit(X_filled,y)\n#grid_xgb.best_params_","b959f9c3":"params_lgb = {'n_estimators':[200,1000,3000],\n             'num_leaves':[1,5,10],\n             'learning_rate':[0.01,0.03,0.1,0.3], \n             'max_bin':[25,50,100,200],\n             'bagging_fraction':[0.1,0.5,0.8,1],\n             'bagging_freq':[1,3,5,7],\n             'feature_fraction':[0.1,0.2,0.3,0.5,1],\n             'min_sum_hessian_in_leaf':[0.1,1,10,20]}\n\n\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.03, n_estimators=3000,\n                              bagging_fraction = 0.8,bagging_seed=9,\n                              bagging_freq = 5, feature_fraction = 0.2,\n                              feature_fraction_seed=9,max_bin = 50, \n                              min_sum_hessian_in_leaf = 10)\n\ngrid_lgb = GridSearchCV(model_lgb, {'max_bin':[25,50,100,200]}, cv=kf, n_jobs=-1,\n                       verbose=5,scoring=\"neg_mean_squared_error\")","3e389850":"#grid_lgb.fit(X_filled,y)\n#grid_lgb.best_params_","9d5a69e3":"gbr_pipe = make_pipeline(RobustScaler(), gbr)\nxgb_pipe = make_pipeline(RobustScaler(), model_xgb)\nlgb_pipe = make_pipeline(RobustScaler(), model_lgb)","29a74c3b":"scores_after = pd.DataFrame()\nscores_after_sel = pd.DataFrame()","49cd33a6":"score = cross_val(rf,X_filled,y)\nscores_after['rf']=(score.mean(),score.std())","7db973c5":"score = cross_val(rf,X_filled_perc,y,disp=False)\nscores_after_sel['rf']=(score.mean(),score.std())","0f76357c":"score = cross_val(lassoCV,X_filled,y)\nscores_after['lasso']=(score.mean(),score.std())","87fb31d0":"score = cross_val(lassoCV,X_filled_perc,y,disp=False)\nscores_after_sel['lasso_perc']=(score.mean(),score.std())","f818986f":"score = cross_val(ridgeCV,X_filled,y)\nscores_after['ridge']=(score.mean(),score.std())","d416f8bc":"score = cross_val(ridgeCV,X_filled_perc,y,disp=False)\nscores_after_sel['ridge']=(score.mean(),score.std())","4b4d24eb":"score = cross_val(ENet,X_filled,y)\nscores_after['ENet']=(score.mean(),score.std())","26964127":"score = cross_val(ENet,X_filled_perc,y,disp=False)\nscores_after_sel['ENet']=(score.mean(),score.std())","b79e2ff2":"score = cross_val(svr,X_filled,y)\nscores_after['svr']=(score.mean(),score.std())","7b47ede1":"score = cross_val(svr,X_filled_perc,y,disp=False)\nscores_after_sel['svr']=(score.mean(),score.std())","7cf7e21e":"score = cross_val(gbr,X_filled,y)\nscores_after['gbr']=(score.mean(),score.std())","907f3896":"score = cross_val(gbr_pipe,X_filled,y)\nscores_after['gbr_pipe']=(score.mean(),score.std())","e106a91f":"score = cross_val(gbr,X_filled_perc,y,disp=False)\nscores_after_sel['gbr']=(score.mean(),score.std())","1c7699b5":"score = cross_val(model_xgb,X_filled,y)\nscores_after['xgb']=(score.mean(),score.std())","c2ed30e0":"score = cross_val(xgb_pipe,X_filled,y)\nscores_after['xgb_pipe']=(score.mean(),score.std())","3341f0da":"score = cross_val(model_xgb,X_filled_perc,y,disp=False)\nscores_after_sel['xgb']=(score.mean(),score.std())","89abddf7":"score = cross_val(model_lgb,X_filled,y)\nscores_after['lgb']=(score.mean(),score.std())","a3137c89":"score = cross_val(lgb_pipe,X_filled,y)\nscores_after['lgb_pipe']=(score.mean(),score.std())","42bcc456":"score = cross_val(model_lgb,X_filled_perc,y,disp=False)\nscores_after_sel['lgb']=(score.mean(),score.std())","d717509d":"scores_after['value'] = ('mean','std')\nscores_after.set_index('value',inplace = True)\nscores_after","f673aa37":"scores_after_sel['value'] = ('mean','std')\nscores_after_sel.set_index('value',inplace = True)\nscores_after_sel","5a4df64f":"rf_pipe = make_pipeline(sp,RobustScaler(),rf)\nlasso_pipe = make_pipeline(sp, lassoCV)\nridge_pipe = make_pipeline(sp, ridgeCV)","97b78158":"makeSubm(model_lgb,X_filled,y,X_test_filled,'subm4.csv')#0.12406","a8a7d2ca":"makeSubm(model_xgb,X_filled,y,X_test_filled,'subm5.csv')#0.12495","5abf85d5":"makeSubm(gbr,X_filled,y,X_test_filled,'subm6.csv')#0.12365","d0ca5e1f":"makeSubm(lgb_pipe,X_filled,y,X_test_filled,'subm4(1).csv')#0.12338\nmakeSubm(xgb_pipe,X_filled,y,X_test_filled,'subm5(1).csv')#0.12495\nmakeSubm(gbr_pipe,X_filled,y,X_test_filled,'subm6(1).csv')#0.12365","48dff0b5":"from mlxtend.regressor import StackingCVRegressor\nstack_gen = StackingCVRegressor(regressors=(gbr,rf,ridgeCV,lassoCV,ENet,svr, model_xgb,model_lgb),\n                                meta_regressor=gbr,\n                                use_features_in_secondary=True)","5e7bceb4":"stack_gen_piped = StackingCVRegressor(regressors=(gbr_pipe,rf,ridgeCV,lassoCV,ENet,svr,\n                                                  xgb_pipe,lgb_pipe),\n                                meta_regressor=gbr_pipe,\n                                use_features_in_secondary=True)","5dc921f1":"stack_gen_piped_1 = StackingCVRegressor(regressors=(gbr_pipe,rf_pipe,ridge_pipe,lasso_pipe,ENet,svr,\n                                                  xgb_pipe,lgb_pipe),\n                                meta_regressor=gbr_pipe,\n                                use_features_in_secondary=True)","932eec63":"stack_gen_piped_lgb = StackingCVRegressor(regressors=(gbr_pipe,rf,ridgeCV,lassoCV,ENet,svr,\n                                                  xgb_pipe,lgb_pipe),\n                                meta_regressor=lgb_pipe,\n                                use_features_in_secondary=True)","d66ef6d1":"fitted_stack = stack_gen.fit(np.array(X_filled),np.array(y))\nfitted_stack_piped = stack_gen_piped.fit(np.array(X_filled),np.array(y))","e0055508":"fitted_stack_piped_lgb = stack_gen_piped_lgb.fit(np.array(X_filled),np.array(y))","e8562513":"fitted_stack_piped_1 = stack_gen_piped_1.fit(np.array(X_filled),np.array(y))","16338967":"mean_squared_error(y,fitted_stack.predict(np.array(X_filled)),squared=False)","ab72c43a":"mean_squared_error(y,fitted_stack_piped.predict(np.array(X_filled)),squared=False)","84f11bea":"mean_squared_error(y,fitted_stack_piped_lgb.predict(np.array(X_filled)),squared=False)","cd484a5b":"mean_squared_error(y,fitted_stack_piped_1.predict(np.array(X_filled)),squared=False)","6bfdd034":"test_pred = fitted_stack.predict(np.array(X_test_filled))\nsample_sub = pd.read_csv(PATH +'sample_submission.csv', \n                             index_col='Id')\nsample_sub['SalePrice'] = np.expm1(test_pred)\nsample_sub.to_csv(\"subm7.csv\")#0.11865","bb099453":"test_pred = fitted_stack_piped.predict(np.array(X_test_filled))\nsample_sub = pd.read_csv(PATH +'sample_submission.csv', \n                             index_col='Id')\nsample_sub['SalePrice'] = np.expm1(test_pred)\nsample_sub.to_csv(\"subm7(1).csv\")#0.11848","7df9916e":"test_pred = fitted_stack_piped_lgb.predict(np.array(X_test_filled))\nsample_sub = pd.read_csv(PATH +'sample_submission.csv', \n                             index_col='Id')\nsample_sub['SalePrice'] = np.expm1(test_pred)\nsample_sub.to_csv(\"subm7(2).csv\")#0.12488","ef135709":"test_pred = fitted_stack_piped_1.predict(np.array(X_test_filled))\nsample_sub = pd.read_csv(PATH +'sample_submission.csv', \n                             index_col='Id')\nsample_sub['SalePrice'] = np.expm1(test_pred)\nsample_sub.to_csv(\"subm7(3).csv\")#0.11836","7f253796":"fitted_rf = rf_pipe.fit(X_filled,y)\nfitted_ridge = ridge_pipe.fit(X_filled,y)\nfitted_lasso = lasso_pipe.fit(X_filled,y)\nfitted_ENet = ENet.fit(X_filled,y)\nfitted_svr = svr.fit(X_filled,y)\nfitted_xgb = xgb_pipe.fit(X_filled,y)\nfitted_lgb = lgb_pipe.fit(X_filled,y)\nfitted_gbr = gbr_pipe.fit(X_filled,y)","e5959dab":"def blended_predictions(X, params):\n    return ((params['rf'] * fitted_rf.predict(X)) + \\\n            (params['ridge'] * fitted_ridge.predict(X)) + \\\n            (params['lasso'] * fitted_lasso.predict(X)) + \\\n            (params['ENet'] * fitted_ENet.predict(X))+\\\n            (params['svr'] * fitted_svr.predict(X)) + \\\n            (params['xgb'] * fitted_xgb.predict(X)) + \\\n            (params['lgb'] * fitted_lgb.predict(X)) + \\\n            (params['gbr'] * fitted_gbr.predict(X)) + \\\n            (params['stack'] * fitted_stack_piped_1.predict(np.array(X))))","089aa5eb":"params = pd.DataFrame(columns=['rf','ridge','lasso','ENet','svr','xgb','lgb','gbr','stack'])\n\nparams =params.append({'rf':0.05,'ridge':0.1,'lasso':0.1,'ENet':0.1,\n                       'svr':0.05,'xgb':0.1,'lgb':0.1,'gbr':0.1,'stack':0.3},ignore_index=True)\nparams =params.append({'rf':0.05,'ridge':0.05,'lasso':0.1,'ENet':0.1,\n                       'svr':0.1,'xgb':0.1,'lgb':0.1,'gbr':0.1,'stack':0.3},ignore_index=True)\nparams =params.append({'rf':0,'ridge':0.1,'lasso':0.1,'ENet':0.1,\n                       'svr':0.1,'xgb':0.1,'lgb':0.1,'gbr':0.1,'stack':0.3},ignore_index=True)\nparams =params.append({'rf':0,'ridge':0.1,'lasso':0.1,'ENet':0.1,\n                       'svr':0,'xgb':0.1,'lgb':0.1,'gbr':0.1,'stack':0.4},ignore_index=True)\nparams =params.append({'rf':0,'ridge':0.05,'lasso':0.1,'ENet':0.1,\n                       'svr':0.05,'xgb':0.1,'lgb':0.15,'gbr':0.15,'stack':0.3},ignore_index=True)\nparams =params.append({'rf':0,'ridge':0,'lasso':0.05,'ENet':0.05,\n                       'svr':0,'xgb':0.15,'lgb':0.15,'gbr':0.15,'stack':0.45},ignore_index=True)\nparams =params.append({'rf':0,'ridge':0,'lasso':0,'ENet':0,\n                       'svr':0,'xgb':0.15,'lgb':0.2,'gbr':0.2,'stack':0.45},ignore_index=True)\nparams =params.append({'rf':0,'ridge':0,'lasso':0,'ENet':0,\n                       'svr':0,'xgb':0.1,'lgb':0.2,'gbr':0.2,'stack':0.5},ignore_index=True)\nparams =params.append({'rf':0,'ridge':0,'lasso':0,'ENet':0,\n                       'svr':0,'xgb':0.1,'lgb':0.1,'gbr':0.1,'stack':0.7},ignore_index=True)\nparams","985d743e":"params['rmse']=0\nfor i in range(0,params.shape[0]):\n    rmse = mean_squared_error(y,blended_predictions(X_filled, params.iloc[i]),squared=False)\n    params['rmse'].iloc[i]=rmse\nparams","0aadb673":"test_pred = blended_predictions(X_test_filled,params.iloc[5])\nsample_sub = pd.read_csv(PATH +'sample_submission.csv', \n                             index_col='Id')\nsample_sub['SalePrice'] = np.expm1(test_pred)\nsample_sub.to_csv(\"subm8.csv\")#0.11807","72afc2f0":"test_pred = blended_predictions(X_test_filled,params.iloc[5])\nsample_sub = pd.read_csv(PATH +'sample_submission.csv', \n                             index_col='Id')\nsample_sub['SalePrice'] = np.expm1(test_pred)\nq1 = sample_sub['SalePrice'].quantile(0.0045)\nq2 = sample_sub['SalePrice'].quantile(0.99)\nsample_sub['SalePrice'] = sample_sub['SalePrice'].apply(lambda x: x if x > q1 else x*0.95)\nsample_sub['SalePrice'] = sample_sub['SalePrice'].apply(lambda x: x if x < q2 else x*1.05)\nsample_sub.to_csv(\"subm9.csv\")#0.11788","45b24313":"Fix outleir predictions","47ac5731":"### We make another variant of dataset - clean dataset by dropping features","4260d32e":"# Feature Engineering","3aa42789":"### Split data","6c12a30c":"stack_gen_piped = tuned models + pipe RobustScaler with boosters","3ec92ae7":"stack_gen_piped_lgb = stack_gen_piped but with meta regressors LightGBM","a24439fa":"# Modelling","0c3bc33e":"View distribution of target feature (SalePrice)","0e26d07e":"Best blended is params with index 5. Other works worse because model overfit or underfit","862873aa":"Make params by hand","ceb4143b":"stack_gen = tuned models with meta regressor GradientBoost","6c05d395":"# Baseline","20d9832e":"##### We have slightly increased rmse. But for linear models this transformation is useful","18674fea":"##### We can see that rmse is the same for both datasets. We will use filled dataset","ef17e44c":"### Feature Selection","27a494b4":"# Make blended predictions","8db3cecc":"# Read the data","65b386a2":"stack_gen_piped_1 = tuned models + pipe SelectPercentile with RandomForest,Ridge, Lasso + pipe RobustScaler with boosters","763e06a5":"We make the same work as train set. But add two additional categories for missing values: mode and high prob. Missing values filled as mode in mode category and as values with high probability in high prob category","336bb3b3":"Fit best models in each algorithm","f9bfe0f9":"### Make submission","9e7541d7":"#### Execellent!!! We don`t have missing values<br>\nWe divided missing values to features with None values (none_val_col), with zero values (zero_num_col), and drop values(drop_col) after analyzing dataset. Also LotFrontage compute as median LotFrantages neighbors","7174a38b":"We find best estimator","ca3c9c8d":"##### We have slightly decreased rmse","909c9fd6":"We can se that SalePrice deviate from the normal distribution","26ed359c":"##### We have slightly decreased rmse","b1bb9911":"LightGBM","48c85038":"##### Ok. We have just dropped 'bad' features","cfd95206":"Show dependencies SalePrice","205e82e1":"### Let`s make correlation matrix for new datasets","403d112e":"We will use the best model in next steps (fitted_stack_piped_1)","b5c5809e":"#### 'SalePrice' correlation matrix (zoomed heatmap style)","f145da26":"### Missing data","7ec58589":"Use countplot to find the state with the highest probability","2c5c1561":"Support Vector","4437be14":"Make the function from index to name columns","4f3e411f":"##### We try to fill missing values","e9d34dc8":"### Let`s make correlation matrix","6cfc3043":"##### We compute the Box-Cox transformation. The goal is to find a simple transformation that lets us normalize data.","dbec7856":"XGBoost","69d435aa":"##### Filled dataset","2fd46277":"Gradient Boosting","e6c7f64f":"We use Robustscaler for reduce the influence of outliers","cca838ff":"We don't see dependencies on this heatmap. Let's make zoomed heatmap","3a12f688":"##### We can see that in filled dataset more features which influent on SalePrice","4221939e":"Ridge","f7375ced":"##### View info about columns","3e9cba1f":"# Try to add more useful features and convert some existing to categorical","c3961990":"##### Clean dataset","9c61f4cc":"# Check missing values in test set and analyze them","ccfe92b7":"# Check skewed features","8dd4f750":"##### Find categorical and numerical features","fbcf3001":"Make also pipeline for gbr, xgb and lgb","d893cff0":"##### Overview numerical features","9bfb9499":"# Tunning models","67ffd493":"### Convert categorical features with one-hot encoding ","da3ae4d3":"##### Apply Box-Cox for columns with decreasing skew","6694f559":"### Check scores after tunning","4d7551dc":"##### Scatter plots between 'SalePrice' and correlated variables (again)","d74e91fa":"We know that SalePrice is skewed to the right. This is a problem because most ML models don't do well with non-normally distributed data. We can apply a log(1+x) tranform to fix the skew.","3d06703d":"### Try to add more features","490fe9e0":"# View some features","586b2819":"RandomForest","f24f5683":"# Make stacked regressor","31957d40":"### OK","041fd893":"Elastic Net","a96a5a73":"Lasso"}}