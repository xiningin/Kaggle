{"cell_type":{"c73da941":"code","fc1f7ce9":"code","d7726b2c":"code","78b32d83":"code","0204a1fc":"code","3276f0ae":"code","368c6606":"code","bf891ba1":"code","95a4bd16":"code","267fd644":"code","0a069ba7":"markdown","2fc2da74":"markdown","d034d5c5":"markdown"},"source":{"c73da941":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","fc1f7ce9":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test_id.csv')\n\nprint(train.shape)\nprint(test.shape)","d7726b2c":"train['UPDATE_TIME'] = train['UPDATE_TIME'].astype('datetime64[ns]')\ntest['UPDATE_TIME'] = test['UPDATE_TIME'].astype('datetime64[ns]')\n\ntrain.drop(['ZONE_CODE'], axis=1, inplace=True)\ntest.drop(['ZONE_CODE'], axis=1, inplace=True)\n\ntrain.head()","78b32d83":"train_df= train.loc[train.UPDATE_TIME >= '2019-03-02']\n\ngroupby_min = train_df.groupby(['SERVER_NAME','HOUR_ID']).min().reset_index()\ngroupby_max = train_df.groupby(['SERVER_NAME','HOUR_ID']).max().reset_index()\ngroupby_mean = train_df.groupby(['SERVER_NAME','HOUR_ID']).mean().reset_index()\n\ngroupby_mean['mape_bandwidth'] = (groupby_max['BANDWIDTH_TOTAL'] - groupby_min['BANDWIDTH_TOTAL'])\/groupby_min['BANDWIDTH_TOTAL'] * 100\ngroupby_mean['mape_user'] = (groupby_max['MAX_USER'] - groupby_min['MAX_USER'])\/groupby_min['MAX_USER'] * 100\ngroupby_mean['min_of_BANDWIDTH'] = groupby_min['BANDWIDTH_TOTAL']\ngroupby_mean['min_of_MAXUSER'] = groupby_min['MAX_USER']\ngroupby_mean.head()","0204a1fc":"valid = train_df.drop(['BANDWIDTH_TOTAL', 'MAX_USER'], axis=1)\nvalid = valid.join(groupby_mean.set_index(['SERVER_NAME','HOUR_ID']),\n                     on=['SERVER_NAME','HOUR_ID'])\ntest_df = test.join(groupby_mean.set_index(['SERVER_NAME','HOUR_ID']),\n                     on=['SERVER_NAME','HOUR_ID'])\n\nvalid.head()","3276f0ae":"THRESHOLD = 100\n\nvalid.loc[(valid[\"mape_bandwidth\"] > THRESHOLD) & (valid[\"min_of_BANDWIDTH\"] < 200),\n          \"BANDWIDTH_TOTAL\"] = np.nan\ntest_df.loc[(test_df[\"mape_bandwidth\"] > THRESHOLD) & (test_df[\"min_of_BANDWIDTH\"] < 200),\n            \"BANDWIDTH_TOTAL\"] = np.nan\n\nprint(test_df['BANDWIDTH_TOTAL'].describe())\n","368c6606":"valid.loc[(valid[\"mape_user\"] > THRESHOLD) & (valid[\"min_of_MAXUSER\"] < 200),\n          \"MAX_USER\"] = np.nan\ntest_df.loc[(test_df[\"mape_user\"] > THRESHOLD) & (valid[\"min_of_MAXUSER\"] < 200),\n            \"MAX_USER\"] = np.nan\n\nprint(test_df['MAX_USER'].describe())","bf891ba1":"valid['MAX_USER'].fillna(0, inplace=True)\nvalid['BANDWIDTH_TOTAL'].fillna(0, inplace=True)\ntest_df['MAX_USER'].fillna(0, inplace=True)\ntest_df['BANDWIDTH_TOTAL'].fillna(0, inplace=True)\nprint(test_df.shape)","95a4bd16":"def MAPE(y_true, y_pred):\n    error = np.abs(y_true - y_pred)\/ y_true\n    error.replace([np.inf, -np.inf], np.nan, inplace=True)\n    error.dropna(inplace=True)\n    return np.mean(error)*100\n\nbandwidth_mape = MAPE(train_df['BANDWIDTH_TOTAL'], valid['BANDWIDTH_TOTAL'])\nuser_mape = MAPE(train_df['MAX_USER'], valid['MAX_USER'])\n\nprint('MAPE bandwidth : ', bandwidth_mape)\nprint('MAPE user : ', user_mape)\nprint('MAPE total: ', bandwidth_mape*0.8 + user_mape*0.2)","267fd644":"test_df['MAX_USER'] = test_df.MAX_USER.astype(int).astype(str)\ntest_df['BANDWIDTH_TOTAL'] = test_df.BANDWIDTH_TOTAL.round(2).astype(str)\ntest_df['label'] = test_df['BANDWIDTH_TOTAL'].str.cat(test_df['MAX_USER'],sep=\" \")\n\ntest_df[['id','label']].to_csv('sub_aivn.csv', index=False)\ntest_df.head()","0a069ba7":"**APPLY THE TRICK**","2fc2da74":"**LOAD DATA**","d034d5c5":"**PREPROCESS**"}}