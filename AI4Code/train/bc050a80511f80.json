{"cell_type":{"8baa87c1":"code","8fdeae6c":"code","a71223b8":"code","a920b498":"code","ff327580":"code","eefd8b12":"code","16d4ea8d":"code","6170492e":"code","432cc3be":"code","de66e4ec":"code","3444ff35":"code","98b5770a":"code","ea9aed44":"markdown","a4858f49":"markdown","72b46a4e":"markdown","980fd30c":"markdown","64507d19":"markdown"},"source":{"8baa87c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8fdeae6c":"dft = pd.read_csv('..\/input\/titanic-train\/train.csv')\ndft","a71223b8":"dftc = dft.copy()\ndftc.info()\n\n","a920b498":"index1 = [dftc.Sex.unique(), dftc.Embarked.unique()]\nindexes = pd.MultiIndex.from_product(index1, names=[\"Sex\", \"Embarked\"])\nindexes","ff327580":"column1 = [dftc.Pclass.unique(), dftc.Survived.unique()]\ncolumns = pd.MultiIndex.from_product(column1, names=[\"Pclass\", \"Survived\"])\ncolumns","eefd8b12":"dftc1 = pd.DataFrame(np.random.randint(9,size=(8,6)), index=indexes, columns=columns)\ndftc1","16d4ea8d":"dftc2 = dftc.iloc[:10].pivot(index='Name',columns='Ticket',values='Age')\ndftc2","6170492e":"dftc3 = dftc1.stack([0,1]).unstack([0,3])\ndftc3","432cc3be":"dftc4 = dftc.melt(id_vars=['Name','Embarked'], value_vars =['Sex', 'Age'], var_name='variable', value_name='value').iloc[:10]\ndftc4","de66e4ec":"#A#\npd.pivot_table(dftc, values=['Fare','Age'], index=\"Embarked\",aggfunc={'Fare':[np.mean,np.sum], 'Age' : [np.median,np.std]})","3444ff35":"#B#\n\npd.pivot_table(dftc, values=['Fare','Age'], \n               index=['Embarked', 'Sex', 'Pclass'],\n               aggfunc={'Fare':np.mean, 'Age' : np.median})","98b5770a":"#C#\n\npd.pivot_table(dftc, values=['Fare','Age'], \n               index=['Embarked', 'Sex', 'Pclass'],\n               aggfunc={'Fare':np.mean, 'Age' : np.median})","ea9aed44":"2. Pivot:\nData: https:\/\/www.kaggle.com\/c\/titanic\n\nTask: Create pivot table by using pivot\n\nIndex: Name\n\nColumn: Ticket\n\nValues: Age","a4858f49":"3. Stack & Unstack:\nData: Task 1\n\nTask: Manipulate the table you obtained in the 1st task with the stack and unstack methods","72b46a4e":"4. Melt:\nData: https:\/\/www.kaggle.com\/c\/titanic\n\nTask: Create the table below using melt method\n\nId_vars: 'Name' and 'Embarked'\n\nValue_vars: 'Sex' and 'Age'","980fd30c":"Task: Create a multi-indexed dataframe\n\nIndexes:\n\nlevel_0 = Sex\nlevel_1 = Embarked\nColumns:\n\nlevel_0 = Sex\nlevel_1 = Survived\nValues: Random\n\nResult:","64507d19":"5. Pivot Table:\nData: https:\/\/www.kaggle.com\/c\/titanic\n\nTask: Create the following pivot tables using the pivot_table method\n\nIndex:\n\nA) 'Embarked'\n\nB) 'Embarked', 'Sex', 'Pclass'\n\nC) 'Embarked', 'Sex', 'Pclass'\n\nValues: 'Fare' and 'Age'\n\naggfunc:\n\nA) 'Fare': mean, 'Age': median\n\nB) 'Fare': mean, 'Age': median\n\nC) 'Fare': mean and np.sum, 'Age': np.median and np.std"}}