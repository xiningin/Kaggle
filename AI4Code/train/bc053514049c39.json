{"cell_type":{"7371dd63":"code","e8d19ec4":"code","a54eadd0":"code","91482b64":"code","a0a18fda":"code","f93bdfea":"code","5d217719":"code","75110d06":"code","73eff8a4":"code","1ef1be10":"code","b32abaa0":"code","1710b81e":"code","38bd0fb4":"code","59b6dbfe":"code","b3c8f857":"code","f9b2a09d":"code","2f5303c6":"code","1c24baaf":"code","251a1bec":"markdown","fec13ab7":"markdown","db9d288c":"markdown","c6c3c648":"markdown","b242d6d2":"markdown","07c3d6bc":"markdown","31a35540":"markdown","e460a324":"markdown","e05e6391":"markdown","96cdc622":"markdown","d964693f":"markdown","cbfa7cab":"markdown","f416caa8":"markdown","52743c14":"markdown","9deccd8f":"markdown","c38d3b4f":"markdown","4ad5d2ae":"markdown","9557eea4":"markdown","3fa4d029":"markdown","b8963283":"markdown","84712bc2":"markdown","f5c187b5":"markdown","a759dc7b":"markdown","2bceeb95":"markdown","05025607":"markdown"},"source":{"7371dd63":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","e8d19ec4":"train_datagen = ImageDataGenerator(\n                      rescale=1.\/255,\n                      rotation_range=40,\n                      width_shift_range=0.2,\n                      height_shift_range=0.2,\n                      shear_range=0.2,\n                      zoom_range=0.2,\n                      horizontal_flip=True,\n                      fill_mode='nearest')","a54eadd0":"#Read the data from the dataset\ntrain_generator = train_datagen.flow_from_directory(\n    '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/train\/',\n    target_size= (300, 300),\n    batch_size=32,\n    class_mode='binary')","91482b64":"# Preprocessing the test set\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Reading the test set\nvalidation_generator = validation_datagen.flow_from_directory(\n    '\/kaggle\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/',\n    target_size= (300, 300),\n    batch_size=32,\n    class_mode='binary')","a0a18fda":"model = tf.keras.models.Sequential([\n      tf.keras.layers.Conv2D(16, (3,3), activation='relu',\n                             input_shape=(300, 300, 3)),\n      tf.keras.layers.MaxPooling2D(2, 2),\n      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n      tf.keras.layers.MaxPooling2D(2,2),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(512, activation='relu'),\n      tf.keras.layers.Dense(1, activation='sigmoid')\n])","f93bdfea":"model.summary()","5d217719":"model.compile(loss='binary_crossentropy',\n       optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n       metrics=['accuracy'])","75110d06":"history = model.fit(\n    train_generator,\n    epochs=15,\n    validation_data=validation_generator)","73eff8a4":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nplt.figure(figsize = (16, 10))\n\n# Plotting the Training and Validation Loss\nplt.plot(history.history['loss'],label='train loss')\nplt.plot(history.history['val_loss'],label='val loss')\nplt.legend()\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.show()\nplt.savefig('Loss_val loss')\n\n# Plotting the Training and Validation Accuracy\nplt.figure(figsize = (16, 10))\nplt.plot(history.history['accuracy'],label='train acc')\nplt.plot(history.history['val_accuracy'],label='val acc')\nplt.legend()\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.savefig('accVal_acc')","1ef1be10":"# Retraining with epochs = 8\nhistory = model.fit(\n    train_generator,\n    epochs=8,\n    validation_data=validation_generator)","b32abaa0":"model.save_weights('My_model.h5')\nmodel.load_weights('My_model.h5')","1710b81e":"# Creating path of test image:\npath = '..\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/humans\/valhuman01-01.png'","38bd0fb4":"from tensorflow.keras.preprocessing import image\nimport numpy as np\n\n# loads the image and resizes\nimg = image.load_img(path, target_size=(300, 300))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)","59b6dbfe":"img","b3c8f857":"classes = model.predict(x)\nif classes[0]>0.5:\n    print(\" Image is a human\")\nelse:\n    print(\" Image is a horse\")","f9b2a09d":"path = '..\/input\/horses-or-humans-dataset\/horse-or-human\/validation\/horses\/horse1-105.png'\n\nimg = image.load_img(path, target_size=(300, 300))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)","2f5303c6":"img","1c24baaf":"classes = model.predict(x)\nif classes[0]>0.5:\n    print(\" Image is a human\")\nelse:\n    print(\" Image is a horse\")","251a1bec":"### As you can see, our model correctly predicted both human and horse images. I hope you enjoy it. Please upvote \u2764\ufe0f","fec13ab7":"### We then specify that this will generate images for the training process by flowing them from a directory.","db9d288c":"# <span style = \"color: Orange\"> Plotting the Losses and Accuracies<\/span>","c6c3c648":"### In this example, I'll show you how to build a convolutional neural networks to try to classify the contents of images. \n\n# <span style = \"color: Orange\"> The Horses or Humans Dataset <\/span>\n\n### Horses or Humans is a dataset of 300\u00d7300 images approximately half each of horses and humans, rendered in different poses.\n\n# <span style = \"color: Orange\"> Importing Dataset<\/span>\n\n### To import dataset, I'll use TensorFlow.","b242d6d2":"# <span style = \"color: Orange\"> Saving the Model<\/span>","07c3d6bc":"### Let's take a look at the image.","31a35540":"### As you can see, the model begins to overfit after eight epochs. Let\u2019s train a new model from scratch for eight epochs.","e460a324":"# <span style = \"color: Orange\"> Retraining the Model<\/span>","e05e6391":"### Let's predict the image.","96cdc622":"# <span style = \"color: Orange\"> Training the Model<\/span>","d964693f":"# <span style = \"color: Orange\"> Compiling the Model<\/span>","cbfa7cab":"### Don\u2019t forget to follow us on [YouTube](https:\/\/youtube.com\/c\/tirendazakademi) \ud83c\udf9e, [GitHub](https:\/\/github.com\/tirendazacademy) \ud83c\udf31, [Twitter](https:\/\/twitter.com\/@tirendazacademy) \ud83d\ude0e, [LinkedIn](https:\/\/www.linkedin.com\/in\/tirendaz-academy) \ud83d\udc4d","f416caa8":"![](https:\/\/images.unsplash.com\/photo-1553284965-83fd3e82fa5a?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1171&q=80)","52743c14":"### Let's predict the image.","9deccd8f":"### Now, I am going to get horse image and predict the image. Let's load a horse image from validatio set.","c38d3b4f":"### Let's take a look at model architecture.","4ad5d2ae":"### Let's take a look at the image.","9557eea4":"# <span style = \"color: Orange\"> Predicting New Data<\/span>","3fa4d029":"# <span style = \"color:Orange\"> Resource<\/span>","b8963283":"# <span style = \"color: Orange\"> Importing the Test Set<\/span>","84712bc2":"# <span style = \"color: Orange\"> CNN Architecture for Horses or Humans<\/span>","f5c187b5":"### Let's load a human image from validation set.","a759dc7b":"# <span style = \"color: OrangeRed\"> Image Classification using CNN <\/span>","2bceeb95":"### Before importing dataset, I am going to create an instance of an ImageDataGenerator called train_datagen.","05025607":"### [Moroney L., 2021,  AI and Machine Learning for Coders.](https:\/\/www.oreilly.com\/library\/view\/ai-and-machine\/9781492078180\/)"}}