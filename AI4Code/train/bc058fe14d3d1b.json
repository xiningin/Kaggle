{"cell_type":{"576c7ec2":"code","1f563a64":"code","9a5a14f0":"code","34c8d582":"code","976e02d5":"code","89ff77b5":"code","453324e2":"code","67cd48e9":"code","00175eaf":"code","65997d0b":"code","d51b4d75":"code","4f67dec7":"code","c667b07f":"code","8716699d":"code","642c9c35":"code","10def3bf":"code","6f6b376d":"code","9ea14bbc":"code","72dfbcdc":"code","24087949":"code","07fd02a1":"code","ee67e288":"code","845fffe8":"code","9c3ea347":"code","a78cfa62":"code","2fc21c36":"code","d0712049":"code","32b74d25":"code","be61e608":"code","ac11e49c":"code","bca9316c":"code","d6c33631":"code","a5152196":"code","92ecfc03":"code","9d0c98a9":"code","67d0ea41":"code","8157b143":"code","115f7c05":"code","b70ad9f9":"code","23dcebc4":"code","7b1abdf4":"code","d2accc7f":"code","4385f6e8":"markdown","0669aafb":"markdown","73d088df":"markdown","25d6104c":"markdown","64d593f4":"markdown","654c0687":"markdown","c6da986e":"markdown","6d7f6046":"markdown","f460d733":"markdown","1a21a0f5":"markdown","bb83a6cb":"markdown","e386c7be":"markdown","c8dbc081":"markdown","e8ac60e8":"markdown","52b37882":"markdown","589e2123":"markdown","66349cb6":"markdown","3e0e1eb8":"markdown"},"source":{"576c7ec2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f563a64":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","9a5a14f0":"submission=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nshops=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\nitems=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cats=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ntrain=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ntest=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')","34c8d582":"test.head()","976e02d5":"items.head()","89ff77b5":"item_cats.head()","453324e2":"shops.head()","67cd48e9":"submission.head()","00175eaf":"train.head()","65997d0b":"print(\"shape of train:\",train.shape)\nprint(\"shape of test:\",test.shape)\nprint(\"shape of submission:\",submission.shape)\nprint(\"shape of items:\",items.shape)\nprint(\"shape of item_cats:\",item_cats.shape)\nprint(\"shape of shops:\",shops.shape)","d51b4d75":"# drop duplicates \nsubset = ['date','date_block_num','shop_id','item_id','item_cnt_day'] \nprint(train.duplicated(subset=subset).value_counts()) \ntrain.drop_duplicates(subset=subset, inplace=True)\nprint(\"shape of train:\",train.shape)","4f67dec7":"# drop shops&items not in test data \ntest_shops = test.shop_id.unique() \ntest_items = test.item_id.unique() \ntrain = train[train.shop_id.isin(test_shops)] \ntrain = train[train.item_id.isin(test_items)] \nprint(\"shape of train:\",train.shape)","c667b07f":"fig = plt.figure(figsize=(18,9))\nplt.subplots_adjust(hspace=.5)\n\nplt.subplot2grid((3,3), (0,0), colspan = 3)\ntrain['shop_id'].value_counts(normalize=True).plot(kind='bar', alpha=0.7)\nplt.title('Shop ID Values in the Training Set (Normalized)')\n\nplt.subplot2grid((3,3), (1,0))\ntrain['item_id'].plot(kind='hist', alpha=0.7)\nplt.title('Item ID Histogram')\n\nplt.subplot2grid((3,3), (1,1))\ntrain['item_price'].plot(kind='hist', alpha=0.7, color='orange')\nplt.title('Item Price Histogram')\n\nplt.subplot2grid((3,3), (1,2))\ntrain['item_cnt_day'].plot(kind='hist', alpha=0.7, color='green')\nplt.title('Item Count Day Histogram')\n\nplt.subplot2grid((3,3), (2,0), colspan = 3)\ntrain['date_block_num'].value_counts(normalize=True).plot(kind='bar', alpha=0.7)\nplt.title('Month (date_block_num) Values in the Training Set (Normalized)')\n\nplt.show()","8716699d":"fig = plt.figure(figsize=(10,5))\n\nplt.subplot2grid((1,2), (0,0))\ntrain['item_price'].plot(kind='box')\nplt.title('Item price')\n\nplt.subplot2grid((1,2), (0,1))\ntrain['item_cnt_day'].plot(kind='box')\nplt.title('item_cnt_day')\n\nplt.show()","642c9c35":"train['month']=train['date_block_num']","10def3bf":"train['month']+=1\ntrain['month']%=12\nprint('shape of train',train.shape)","6f6b376d":"train['month']","9ea14bbc":"#season\ntrain['season']=train['month']","72dfbcdc":"train['season']\/\/=3","24087949":"train['season']=train['season'].replace(0,4)","07fd02a1":"#area\ntrain=pd.merge(train,shops,how='left',on='shop_id')","ee67e288":"area = train['shop_name'].apply(lambda x: str.replace(x, '!', '')).apply(lambda x: x.split(' ')[0]) \ntrain['area'] = pd.Categorical(area).codes \ntrain.head()","845fffe8":"train.shape","9c3ea347":"from itertools import product\n\nblock_shop_combi = pd.DataFrame(list(product(np.arange(34), test_shops)), columns=['date_block_num','shop_id']) \nshop_item_combi = pd.DataFrame(list(product(test_shops, test_items)), columns=['shop_id','item_id']) \nall_combi = pd.merge(block_shop_combi, shop_item_combi, on=['shop_id'], how='inner')","a78cfa62":"train_base = pd.merge(all_combi, train, on=['date_block_num','shop_id','item_id'], how='left') \ntrain_base['item_cnt_day'].fillna(0, inplace=True) \ntrain_grp = train_base.groupby(['date_block_num','shop_id','item_id'])","2fc21c36":"train_month = pd.DataFrame(train_grp.agg({'item_cnt_day':['sum','count']})).reset_index() \ntrain_month.columns = ['date_block_num','shop_id','item_id','item_cnt','item_order']\ntrain_month.head()","d0712049":"grp = train_month.groupby(['shop_id', 'item_id']) \ntrain_shop = grp.agg({'item_cnt':['mean','median','std'],'item_order':'mean'}).reset_index() \ntrain_shop.columns = ['shop_id','item_id','cnt_mean_shop','cnt_med_shop','cnt_std_shop','order_mean_shop'] \nprint(train_shop[['cnt_mean_shop','cnt_med_shop','cnt_std_shop']].describe())\ntrain_shop.head()","32b74d25":"price_max = train.groupby(['item_id']).max()['item_price'].reset_index()\nprice_max.rename(columns={'item_price':'item_max_price'}, inplace=True)\nprice_max.head()","be61e608":"price = train.groupby(['item_id']).mean()['item_price'].reset_index()\nprice.rename(columns={'item_price':'item_mean_price'}, inplace=True)\nprice.head()","ac11e49c":"train_price_dc = pd.merge(price, price_max, on=['item_id'], how='left') \ntrain_price_dc['discount'] = 1 - (train_price_dc['item_mean_price'] \/ train_price_dc['item_max_price']) \ntrain_price_dc.drop('item_max_price', axis=1, inplace=True) \ntrain_price_dc.head()","bca9316c":"train=pd.merge(train,train_price_dc,how='left',on='item_id')\ntrain.head()","d6c33631":"train['shop_id']=train['shop_id'].astype(str)\ntrain['item_id']=train['item_id'].astype(str)\ntrain['shop_item']=train['shop_id']+\"-\"+train['item_id']\ntrain","a5152196":"train_month['shop_id']=train_month['shop_id'].astype(str)\ntrain_month['item_id']=train_month['item_id'].astype(str)\ntrain_month['shop_item']=train_month['shop_id']+\"-\"+train_month['item_id']","92ecfc03":"del train_month['date_block_num']\ndel train_month['shop_id']\ndel train_month['item_id']\ndel train_month['item_order']","9d0c98a9":"train=pd.merge(train,train_month,on='shop_item')","67d0ea41":"train","8157b143":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC","115f7c05":"X = train.iloc[:, 0:12]\nY = train.iloc[:, 12]\nx_train, x_test, y_train, y_test = train_test_split(X, Y, stratify = Y, random_state = 0)","b70ad9f9":"svc = SVC(C = 1000, gamma = 0.00001)\nsvc.fit(x_train, y_train)","23dcebc4":"print(\"prediction :\", svc.predict(x_test))\nprint(\"train accuracy :\", svc.score(x_train, y_train))\nprint(\"test accuracy :\", svc.score(x_test, y_test))","7b1abdf4":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators=10, random_state=0)\nforest.fit(X_train, y_train)\n\nprint(\"prediction :\", forest.predict(X_test))\nprint(\"train accuracy :\", forest.score(X_train, y_train))\nprint(\"test accuracy :\", forest.score(X_test, y_test))","d2accc7f":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbrt = GradientBoostingClassifier(random_state=0,max_depth=1)\n\ngbrt.fit(X_train,y_train)\n\n\nprint(\"train accuracy :\".format(gbrt.score(X_train,y_train)))\nprint(\"test accuracy :\".format(gbrt.score(X_test,y_test)))","4385f6e8":"### 2.1 SVM","0669aafb":"## 2. Modeling","73d088df":"month","25d6104c":"season","64d593f4":"ID-\ud14c\uc2a4\ud2b8 \uc138\ud2b8 \ub0b4\uc5d0\uc11c (Shop, Item) \ud29c\ud50c\uc744 \ub098\ud0c0\ub0b4\ub294 Id\\\nshop_id-\uc0c1\uc810\uc758 \uace0\uc720 \uc2dd\ubcc4\uc790\\\nitem_id-\uc0c1\ud488\uc758 \uace0\uc720 \uc2dd\ubcc4\uc790\\\nitem_category_id-\ud56d\ubaa9 \uce74\ud14c\uace0\ub9ac\uc758 \uace0\uc720 \uc2dd\ubcc4\uc790\\\nitem_cnt_day-\ud310\ub9e4 \ub41c \uc81c\ud488 \uc218\uc785\ub2c8\ub2e4. \uc774 \uce21\uc815 \uac12\uc758 \uc6d4\ubcc4 \uae08\uc561\uc744 \uc608\uce21\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.\\\nitem_price-\uc0c1\ud488\uc758 \ud604\uc7ac \uac00\uaca9\\\ndate-dd \/ mm \/ yyyy \ud615\uc2dd\uc758 \ub0a0\uc9dc\\\ndate_block_num-\ud3b8\uc758\ub97c \uc704\ud574 \uc0ac\uc6a9\ub418\ub294 \uc5f0\uc18d \uc6d4 \ubc88\ud638\uc785\ub2c8\ub2e4. 2013 \ub144 1 \uc6d4\uc740 0, 2013 \ub144 2 \uc6d4\uc740 1, ..., 2015 \ub144 10 \uc6d4\uc740 33\uc785\ub2c8\ub2e4.\\\nitem_name-\ud56d\ubaa9 \uc774\ub984\\\nshop_name-\uc0c1\uc810 \uc774\ub984\\\nitem_category_name-\ud56d\ubaa9 \uce74\ud14c\uace0\ub9ac \uc774\ub984","654c0687":"## 0.Before Start","c6da986e":"### 1.1 drop duplicates, remove train which is not in test","6d7f6046":"> ### 1.3 Feature Creation","f460d733":"area","1a21a0f5":"### 2.2 Random Forest","bb83a6cb":"discount rate","e386c7be":"### 0.1 Import Packages","c8dbc081":"### 2.3 Gradient Boosting Regression Tree","e8ac60e8":"### 1.2 Checking outlier","52b37882":"## 1. Features engineering","589e2123":"month","66349cb6":"shop_item_id","3e0e1eb8":"### 0.2 Loading Data"}}