{"cell_type":{"20d32063":"code","8ec4aa21":"code","ae97a6d9":"code","383c403e":"code","f9a064a9":"code","89d466b0":"code","ba6d0219":"code","493d15c5":"code","96f8f3ad":"code","1e51ef9f":"code","382dbcaf":"code","771d4786":"code","07cb33d1":"code","f0e455f0":"code","1482fcaf":"code","d9aca3f9":"code","934f9218":"code","b0e1b692":"code","0a5be6df":"code","2c78afd8":"code","7e1a25fe":"markdown","948b9512":"markdown","d3849792":"markdown","bc371b4a":"markdown","8f51314a":"markdown","89323770":"markdown","50f115fc":"markdown","efb3fc3f":"markdown","795b1b7d":"markdown"},"source":{"20d32063":"# Standard libraries\nimport datetime\nimport random\nimport json\nimport ast\nimport glob\n\n# Third-party libraries\nimport PIL.Image\nimport PIL.ImageDraw\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# Jupyter widgets\nfrom IPython.core.display import display, HTML\n\n# Configurations\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","8ec4aa21":"# Location of dataset\nDATASET_PATH = '..\/input\/airbus-oil-storage-detection-dataset'\n\n# List all images in the folder\nimage_list = [filename.split('\/')[-1].split('.')[0] for filename in glob.glob(DATASET_PATH + \"\/images\/*.jpg\")]\nimage_ids = pd.DataFrame(image_list).rename(columns={0:\"image_id\"})\nprint(\"Number of images in folder: {}\".format(len(image_ids)))\nimage_ids.head()","ae97a6d9":"# convert a string record into a valid python object\ndef f(x): \n    return ast.literal_eval(x.rstrip('\\r\\n'))\n\n# read the CSV with annotations\nlabels = pd.read_csv(DATASET_PATH + '\/annotations.csv',\n        converters={'bounds': f})\n\n# just in case, join annotations with image list\n#labels = image_ids.merge(right=labels, how='left')\n\n# print first lines\nlabels.head()","383c403e":"print(\"Total number of unique 'image_ids' in annotations: {}\".format(len(labels['image_id'].unique())))","f9a064a9":"print(\"Total number of annotations: {}\".format(len(labels)))","89d466b0":"print(\"Available classes: {}\".format(labels['class'].unique().tolist()))","ba6d0219":"histo = labels.image_id.value_counts()\nprint(\"Images with more than 400 oil storage tanks\")\nhisto[(histo > 400)]","493d15c5":"# Add number of storage tanks per tile in the dataframe and sort it\nlabels.at[:, 'records'] = labels.loc[:, 'image_id'].apply(lambda image_id: histo.loc[image_id])\nlabels = labels.sort_values(by=['records'], ascending=False)\nlabels.head(10)","96f8f3ad":"# Display the histogram of objects per image\nplt.figure(figsize=(25, 15))\nplt.title(\"Number of Oil Storage Tanks per image\")\nplt.grid(which='both')\ng = sns.countplot(x='image_id', data=labels)\nplt.xlabel(\"image_id\")\nplt.ylabel(\"n row per image_id\")\n\n# Rotate x labels\ng.set_xticklabels(labels=g.get_xticklabels(), rotation=90);\n# Or hide them\n# g.set_xticklabels(labels=[None]);\n\nplt.savefig(\"objects-per-image.png\")","1e51ef9f":"# Create polygon from bounds\ndef create_polygon_from_bounds(bbox):\n    (xmin, ymin, xmax, ymax) = bbox\n    coords = []\n    coords.append((xmin, ymin))\n    coords.append((xmin, ymax))\n    coords.append((xmax, ymax))\n    coords.append((xmax, ymin))\n    coords.append((xmin, ymin))\n    return coords\n\ndef overlay_image(image_id, bbox_df):\n    img = PIL.Image.open(DATASET_PATH + \"\/images\/\" + image_id + '.jpg')\n    draw = PIL.ImageDraw.Draw(img)\n\n    for k, row in bbox_df[bbox_df['image_id'] == image_id].iterrows():\n        geometry = create_polygon_from_bounds(row['bounds'])\n        draw.polygon(geometry, outline=(255,0,0))\n        #draw.text(geometry[0], row['class'], fill=(255,0,0))\n        \n    return img\n\n# select a random image or images with most annotations\n#pickone = random.choice(image_ids.to_numpy().tolist())[0]\npickone = \"1fcb9fee-da89-43f8-83d9-b5d17575f5e6\" # 893 annotations\n#pickone = \"9892f3a0-f541-43b8-bc62-d640701841f7\" # 540 annotations\n\nimg = overlay_image(pickone, labels)\nfilename = \"oil-storage-sample.jpg\"\nimg.save(filename)\ndisplay(img)","382dbcaf":"def getWidth(bounds):\n    try: \n        (xmin, ymin, xmax, ymax) = bounds\n        return np.abs(xmax - xmin)\n    except:\n        return np.nan\n\ndef getHeight(bounds):\n    try: \n        (xmin, ymin, xmax, ymax) = bounds\n        return np.abs(ymax - ymin)\n    except:\n        return np.nan\n# Create width and height\nlabels.loc[:,'width'] = labels.loc[:,'bounds'].apply(getWidth)\nlabels.loc[:,'height'] = labels.loc[:,'bounds'].apply(getHeight)\n\n# Display head\nlabels.head()","771d4786":"labels.describe()","07cb33d1":"plt.figure(figsize=(25, 15))\nsns.distplot(labels[labels['width'].notnull()]['width'])\nplt.xlim(0, 150)\nplt.show()","f0e455f0":"plt.figure(figsize=(25, 15))\nsns.distplot(labels[labels['width'].notnull()]['height'])\nplt.xlim(0, 150)\nplt.show()","1482fcaf":"labels.at[:,'aspect_ratio'] = labels[['height', 'width']].max(axis=1) \/ labels[['height', 'width']].min(axis=1)\nlabels['aspect_ratio'].describe()","d9aca3f9":"safe_labels = labels[(np.isfinite(labels['aspect_ratio'])) & labels['aspect_ratio'].notnull()]\nsafe_labels['aspect_ratio'].describe()","934f9218":"plt.figure(figsize=(25, 15))\nsns.distplot(safe_labels['aspect_ratio'], bins = 100)\nplt.show()","b0e1b692":"# Filter records with an aspect ratio > 2.5 and display them.\nstrange_labels = safe_labels.loc[safe_labels['aspect_ratio'] > 2.5]\nstrange_labels","0a5be6df":"pickone = strange_labels.sample()\nprint(pickone)\nimg = overlay_image(pickone['image_id'].tolist()[0], pickone)\ndisplay(img)","2c78afd8":"keep_tags_wt_width_over_px = 5\nkeep_tags_wt_height_over_px = 5\nbb_aspect_ratio_upper_limit =  2.5\n                                \nfilter_too_small = np.logical_or(safe_labels['width'] < keep_tags_wt_width_over_px, safe_labels['height'] < keep_tags_wt_width_over_px)\nprint(sum(filter_too_small), \"records too small\")\nfilter_ratio_too_high = safe_labels['aspect_ratio'] > bb_aspect_ratio_upper_limit\nprint(sum(filter_ratio_too_high), \"records with too high aspect ratio \")\n\ncleaned_labels = safe_labels[np.logical_not(np.logical_or(filter_too_small,filter_ratio_too_high))]","7e1a25fe":"### Cleaning by aspect ratio\nVery small objects (typically under 5 pixels) will not be correctly managed by YOLO and might not be oil storage tanks anyhow. Aspect ratios over 2.5 seems very weird as well. Remove them from the training dataset.","948b9512":"#### What conclusion can we draw from these statistics ?\nAre they any annotations that we can discard ?","d3849792":"#### Based on these informations, can we discard some annotations ?\nDisplay annotations with unusual aspect ratio bounding box.","bc371b4a":"## Part 1: Images\nCreate the dataframe with the JPEG images available on disk.","8f51314a":"### Compute the aspect ratio of each storage tanks\nClean the results in order to remove NaN elements.\nThen display some useful statistics and plot an histogram.","89323770":"## Part 4: Plot some images","50f115fc":"## Part 5: More Exploratory Data Analysis\n### Compute width and height of each storage tanks\nAdd the width and the height in pixels of each storage tanks to the dataframe.\nThen display some usefull statistics and plot an histogram.","efb3fc3f":"## Part 3: Compute some statistics\nCompute the number of objects in each image and store it in a dataframe named `histo`","795b1b7d":"## Part 2: Annotations\nNow, we want to add the bounding box informations to the dataframe. A bounding box is a rectangle around the object detected. We only need to know the coordinates of 2 points to describe a bounding box, for example top-left and bottom-right.\n![](assets\/bbox_image.jpg)"}}