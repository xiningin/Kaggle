{"cell_type":{"f8f6f021":"code","278f997e":"code","6bb723de":"code","ecb8c598":"code","783640a0":"code","71ae4653":"code","3d006962":"code","aff4226b":"code","ed221395":"code","6abfc855":"code","97429303":"code","0c9aa603":"code","498b40f0":"markdown","f1abaeaf":"markdown","a08f7ae9":"markdown","84a20d98":"markdown","5afaae1b":"markdown","807d1aeb":"markdown","8584edb4":"markdown","25017ae5":"markdown","fdd26542":"markdown","e5fc888d":"markdown","8348f96f":"markdown"},"source":{"f8f6f021":"import tensorflow as tf\n\nimport os\nimport tensorflow_datasets as tfds","278f997e":"resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc:\/\/' + os.environ['COLAB_TPU_ADDR'])\ntf.config.experimental_connect_to_cluster(resolver)\n# This is the TPU initialization code that has to be at the beginning.\ntf.tpu.experimental.initialize_tpu_system(resolver)\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))","6bb723de":"# Start the TPU you may also manually allocate TPU workspace --tf.distribute.TPUStrategy\nstrategy = tf.distribute.TPUStrategy(resolver)","ecb8c598":"from google.colab import drive\ndrive.mount('\/content\/gdrive')","783640a0":"import os\nos.environ['KAGGLE_CONFIG_DIR'] = \"\/content\/gdrive\/My Drive\/Kaggle\"","71ae4653":"Navigate to your folder with kaggle.json (Here Kaggle)\n%cd \/content\/gdrive\/My Drive\/Kaggle","3d006962":"# We need the latest version of KAGGLE API for this job to be done quick\n!pip install kaggle --upgrade","aff4226b":"!kaggle competitions download -c osic-pulmonary-fibrosis-progression","ed221395":"export KAGGLE_USERNAME=datadinosaur\nexport KAGGLE_KEY=xxxxxxxxxxxxxx","6abfc855":"# List of Commands Available\nkaggle competitions {list, files, download, submit, submissions, leaderboard}\nkaggle datasets {list, files, download, create, version, init}\nkaggle kernels {list, init, push, pull, output, status}\nkaggle config {view, set, unset}\n\n\n# A few Samples\nkaggle datasets list -s demographics\nkaggle datasets list --sort-by votes\nkaggle datasets files zillow\/zecon\nkaggle datasets download zillow\/zecon -f State_time_series.csv\nkaggle datasets init -p \/path\/to\/dataset # used to create a version log too..","97429303":"# You can choose to download even specific files\nkaggle competitions files favorita-grocery-sales-forecasting\nkaggle competitions download favorita-grocery-sales-forecasting -f test.csv.7z","0c9aa603":"# Last but not the least you can submit your results directly from colab without needing to run again\nkaggle competitions submit favorita-grocery-sales-forecasting -f sample_submission_favorita.csv.7z -m \"My submission message\"","498b40f0":"You can also choose to export your Kaggle username and token to the environment:","f1abaeaf":"Note: you will need to accept competition rules at\n[`https:\/\/www.kaggle.com\/c\/<competition-name>\/rules`](https:\/\/www.kaggle.com\/c\/<competition-name>\/rules)","a08f7ae9":"All Right! Before proceeding any further get yor Kaggle API token `kaggle.json` which can be found under `You Account` in Kaggle Dashboard.\n\nUp next create a folder in you drive and name it as you wish and place the `kaggle.json` under it.\n\n(i.e. Kaggle - Folder Name : Kaggle\/kaggle.json)\n\n Now you are almost set  ---> Head back to your colab env ","84a20d98":"## Setup","5afaae1b":"# Colab TPU for Training \n**Interface for using Kaggle Dataset and Competition Data in colab** (Free TPU seesion --`12 hrs` Timeout period --Not timebound as Kaggle)\nYou can always use model checkpoints.\nYou can Download this file as `.ipynb` and upload to your colab env.","807d1aeb":"## TPU Initialization\nTPUs are usually on Cloud TPU workers which are different from the local process running the user python program. Thus some initialization work needs to be done to connect to the remote cluster and initialize TPUs. Note that the `tpu` argument to `TPUClusterResolver` is a special address just for Colab. In the case that you are running on Google Compute Engine (GCE), you should instead pass in the name of your CloudTPU.","8584edb4":"Now you can download the dataset as well as the data required for competition \n(P.S. Don't worry(*Need not worry about the ISP data limit all you need is a stable network to run your model) the bridge for kaggle and colab will be set up and download speeds are pretty high ~120MB\/s ETA would be around 4-5 mins*)\nOr go the old school way and load you weights in the drive to get rocking","25017ae5":"Note: The TPU initialization code has to be at the beginning of your program.","fdd26542":"After running this right you will be invoked for an authorization code for allowing permission for accessing your gdrive\n\nThen change the directory to Kaggle and set it as working directory...","e5fc888d":"For more control over TPU check the [Colab_API](https:\/\/colab.research.google.com\/notebooks\/tpu.ipynb) ","8348f96f":"This is just quick guide on how to get started ASAP\nFor more details check the [Kaggle_API](https:\/\/github.com\/Kaggle\/kaggle-api) from Github"}}