{"cell_type":{"669ef87b":"code","0582ee06":"code","5f3c5baf":"code","d116b428":"code","c7ff0d74":"code","c110c2a1":"code","26d709ff":"code","4173e0aa":"code","da37ea99":"code","a7b80813":"code","3ce102a8":"code","85e552af":"code","d925f36a":"code","f08cf134":"markdown","493c4576":"markdown","f0fa784d":"markdown","b4397e41":"markdown","4c4fe8c2":"markdown","76e5b737":"markdown","d37413d5":"markdown"},"source":{"669ef87b":"import numpy as np\nimport pandas as pd\nimport unicodedata\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npd.set_option('display.max_colwidth', None)\n\ndf = pd.read_csv('..\/input\/medium-data-science-articles-dataset\/medium-data-science-articles-2020.csv')\n\n\nprint(df.shape)\ndf.head()","0582ee06":"print(f' We have {df.url.duplicated().sum()} duplicated values in url colum')\ndf.shape\n#df[df.url.duplicated(keep=False)]","5f3c5baf":"# I analysed the values and conclude that the correct duplicated values \n#is aways the first! So let's keep it.\n\ndf = df.drop_duplicates(subset=['url'], keep='first')\nprint(f' We have {df.url.duplicated().sum()} duplicated values in url colum')\ndf.shape","d116b428":"#df.title[:30]","c7ff0d74":"def normalize_title(title):\n    title = unicodedata.normalize(\"NFKD\", title) # normalize data\n    title = re.sub('<[^>]+>', '', title) # remove anything beteween <> (html noise)\n    title = re.sub(\" \\d+\", r\" X\", title) # replace numbers by X \n    return title \n    \ndf.title = df.title.apply(normalize_title)\ndf.title[:10]","c110c2a1":"words_count = {}\n\nfor title in df.title:\n    splited_title = title.split(' ')\n    if len(splited_title) > 2:\n        for i in range((len(splited_title) - 2)):\n            word_group = f'{splited_title[i]} {splited_title[i+1]} {splited_title[i+2]}'\n            if word_group in words_count.keys():\n                words_count[word_group] += 1 # apeear one more time\n            else:\n                words_count[word_group] = 1 # appear for the first time","26d709ff":"sorted_word_counts = pd.DataFrame(sorted(words_count.items(), key=lambda x: x[1], reverse=True), \n                                  columns=['word_set', 'apparitions'])\n\nplt.figure(figsize=(15, 10))\nplt.barh(sorted_word_counts.word_set[:20],sorted_word_counts.apparitions[:20])\nplt.title('Set of word popularity.')\nplt.xlabel('Apparitions')\nplt.ylabel('Set of words')\nplt.show()","4173e0aa":"claps_for_set_of_words = {}\n\nfor title, claps in zip(df.title, df.claps):\n    splited_title = title.split(' ')\n    if len(splited_title) > 2:\n        for i in range((len(splited_title) - 2)):\n            word_group = f'{splited_title[i]} {splited_title[i+1]} {splited_title[i+2]}'\n            if word_group in claps_for_set_of_words.keys():\n                claps_for_set_of_words[word_group]['count'] += 1\n                claps_for_set_of_words[word_group]['total_claps'] += claps\n            else:\n                claps_for_set_of_words[word_group] = {'count' : 1, \n                                                      'total_claps': claps}\n                \n\n#claps_for_set_of_words            ","da37ea99":"# Get only the popular set words, the one with more than X aparitions\nX = 50\nclaps_for_set_of_words = {key:val for key, val in claps_for_set_of_words.items() if val['count'] >= X}\n\n\nprint(f' There are {len(claps_for_set_of_words)} set of words that appear more than {X} times')","a7b80813":"# Extrac the mean value of the set of words.\nfor key in claps_for_set_of_words.keys():\n    claps_for_set_of_words[key]['claps_mean'] = claps_for_set_of_words[key]['total_claps'] \/ claps_for_set_of_words[key]['count']\n           \n#claps_for_set_of_words","3ce102a8":"transform_from_dict = [] # Auxiliar list to create a DataFrame\n\nfor x in claps_for_set_of_words:\n    claps_for_set_of_words[x]['word_set'] = x\n    transform_from_dict.append(claps_for_set_of_words[x])\n\ntransform_from_dict = sorted(transform_from_dict, key=lambda x: x['claps_mean'], reverse=True)\n\ndf_claps = pd.DataFrame.from_dict(\n                transform_from_dict,\n                orient='columns',\n                dtype=None\n)\n","85e552af":"plt.figure(figsize=(15, 10))\nplt.barh(df_claps.word_set[:20],df_claps.claps_mean[:20])\nplt.title('More atractives set of words')\nplt.xlabel('Claps Means')\nplt.ylabel('Set of words')\nplt.show()","d925f36a":"plt.figure(figsize=(15, 10))\nplt.barh(df_claps.word_set[-20:],df_claps.claps_mean[-20:])\nplt.title('Less atractives set of words')\nplt.xlabel('Claps Means')\nplt.ylabel('Set of words')\nplt.show()","f08cf134":"## Get data insights\n### What is the most popular set of words?","493c4576":"### Data understanding","f0fa784d":"# Analyzing data science articles\n\nThis notebook recreate the study present [here](https:\/\/medium.com\/the-mission\/this-new-data-will-make-you-rethink-how-you-write-headlines-751358f6639a) focusing in data science articles. \n\nThe data for this notebook can be found [here](https:\/\/www.kaggle.com\/viniciuslambert\/medium-data-science-articles-dataset).\n\n\n## Possible questions:\n\n- What is the influence of headlines in popularity?\n- Does reading time influence in popularity?\n- does the author matter?\n- there was a better day to post?\n\n\n## CRISP-DM\n\n- Business Undestanding\n- Data Undestanding\n- Prepare Data\n- Model Data\n- Result \n- Deploy","b4397e41":"### Cleaning the data\n\nAs you can see, it has some confusing character, so we need to normalize the data.","4c4fe8c2":"### What headline set of words atract mo claps?","76e5b737":"## Get most popular set of words in titles","d37413d5":"## Find url duplicateds values and drop it"}}