{"cell_type":{"6cd193d1":"code","d9b39c4f":"code","4b6479dd":"code","d98675c7":"code","f4a93448":"code","1a85dcb0":"code","1ff13a00":"code","649170cc":"code","c10e1aed":"code","d31b4db0":"code","39ba2065":"code","c86da07a":"code","51a41464":"code","b62d6491":"code","52e9cad2":"code","4a5fc300":"code","2828fd4a":"code","9b8f6e6e":"code","4533700a":"code","270aeb04":"code","a7bc941c":"code","a533b24c":"markdown","b004a042":"markdown","885b9981":"markdown","9a1dc335":"markdown","a989d619":"markdown","43c349c3":"markdown","cfaa4936":"markdown","0c69357b":"markdown"},"source":{"6cd193d1":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\nprint(\"Directory Path: \" + os.getcwd())","d9b39c4f":"data_dir = \"\"\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\"\"\"\n\nclasses = []\n\nfor directory in os.listdir(data_dir):\n    if \".\" not in directory:           # Removes .txt and segmentation script\n        classes.append(directory)\n        \nprint(classes)","4b6479dd":"image_paths = []\nimage_classes = np.array([[cls]*1000 for cls in classes]).reshape(-1) # create a classes array of shape (9000,)\n\nfor cls in classes:\n    # adds the path of the image to the first column\n    image_paths.extend(os.path.join(data_dir, cls, cls, i) for i in os.listdir(os.path.join(data_dir, cls, cls))) ","d98675c7":"data = pd.DataFrame({'path':image_paths, 'class':image_classes, })\n\nprint(data)","f4a93448":"import PIL\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms","1a85dcb0":"# Those are the transformations we will apply in our dataset\ntransform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))\n    ])","1ff13a00":"from PIL import Image\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader","649170cc":"str_to_int = {\n 'Hourse Mackerel': 0,\n 'Black Sea Sprat': 1,\n 'Sea Bass': 2,\n 'Red Mullet': 3,\n 'Trout': 4,\n 'Striped Red Mullet': 5,\n 'Shrimp': 6,\n 'Gilt-Head Bream': 7,\n 'Red Sea Bream': 8\n}","c10e1aed":"# Create the Torch Dataset object for our pandas dataframe \nclass MarketFishDataset(Dataset):\n    def __init__(self, data, root_dir, transform=transforms.ToTensor()):\n        self.data = data\n        self.root_dir = root_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        \n        img_name = self.data.iloc[idx, 0]\n        image = Image.open(img_name)\n        y_label = torch.tensor(str_to_int[self.data.iloc[idx, 1]])\n        \n        if self.transform:\n            image = self.transform(image)\n    \n        return (image, y_label)","d31b4db0":"dataset = MarketFishDataset(\n    data=data,\n    root_dir=data_dir,\n    transform=transform\n)","39ba2065":"from matplotlib import pyplot as plt","c86da07a":"img, lab = dataset[42]\nplt.imshow(img.numpy().transpose((1, 2, 0)))\nplt.title(classes[int(lab)])\nplt.axis('off')\nplt.show()","51a41464":"batch_size = 20\ntrain_set, test_set = torch.utils.data.random_split(dataset, [8000,1000])\ntrain_loader = DataLoader(dataset=train_set,batch_size=batch_size,shuffle=True)\ntest_loader = DataLoader(dataset=test_set,batch_size=batch_size,shuffle=True)","b62d6491":"a = next(iter(train_loader))\na[0].size()","52e9cad2":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN(nn.Module):\n    def __init__(self, in_dim, out_dim):\n        super(CNN, self).__init__()\n        self.out_dim = out_dim\n        \n        self.convs = nn.Sequential(\n            nn.Conv2d(in_dim, 8, 8, stride=4, padding=0),\n            nn.ReLU(),\n            nn.Conv2d(8, 16, 5, stride=2, padding=0),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, 5, stride=1, padding=0),\n            nn.ReLU()\n        )\n        \n        self.q1 = nn.Linear(22*22*32, 64) # The 22*22 are the final dimensions of the \"image\"\n        self.q2 = nn.Linear(64, out_dim)\n    \n    def forward(self, x):\n        conv = self.convs(x)\n        flat = conv.reshape(-1, 22*22*32)\n        q1 = F.relu(self.q1(flat))\n        q = self.q2(q1)\n        return q","4a5fc300":"input_dim = dataset[0][0].shape[0] # Number of channels in the image (3)\noutput_dim = len(classes) # Number of classes (9)\n\nloss_nn = nn.CrossEntropyLoss()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = CNN(input_dim, output_dim).to(device)\n\nlearning_rate = 3e-4\noptimizer_nn = torch.optim.Adam(model.parameters(), lr=learning_rate)","2828fd4a":"from torch.autograd import Variable","9b8f6e6e":"epochs = 10\niterations = 0\nloss_list = []\niteration_list = []\naccuracy_list = []\n\nfor epoch in range(epochs):\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        train = Variable(images.view(batch_size, 3, 224, 224))\n        labels = Variable(labels)\n        \n        outputs = model(train)\n        loss = loss_nn(outputs, labels)\n        \n        predictions = torch.max(outputs, 1)[1].to(device)\n    \n        optimizer_nn.zero_grad()\n        \n        loss.backward()\n        \n        optimizer_nn.step()\n        \n        iterations += 1\n        \n        if iterations % 50 == 0:\n            corrects = 0\n            total = 0\n            \n            for images, labels in test_loader:\n\n                images, labels = images.to(device), labels.to(device)\n\n                test = Variable(images.view(batch_size, 3, 224, 224))\n\n                outputs = model(test)\n\n                predict = torch.max(outputs.data, 1)[1].to(device)\n\n                total += len(labels)\n\n                corrects += (predict == labels).sum()\n        \n            acuracy = 100 * corrects \/ float(total)\n\n            loss_list.append(loss.data)\n            iteration_list.append(iterations)\n\n    print(f\"Epoch: {epoch+1} | Loss: {loss.data} | Acuracy: {acuracy}\")\n    ","4533700a":"plt.figure(figsize=(25,6))\nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of Iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"CNN: Loss vs Number of Iteration\")\nplt.show()","270aeb04":"def prediction(index, data):\n    img, _ = data[index]\n    img = img.to(device)\n    img = Variable(img.view([-1, 3, 224, 224]))\n    outputs = model(img)\n    predict = torch.max(outputs.data, 1)[1].to(device)\n    \n    return classes[int(predict)]","a7bc941c":"index = 2048\n\nfig = plt.figure(figsize=(10, 7))\n\nimg, label = dataset[index]\npredicted_label = prediction(index, dataset)\n\nfig.add_subplot(1, 2, 1)\nplt.imshow(img.numpy().transpose((1, 2, 0)))\nplt.axis('off')\nplt.title(\"Real Label: \" + classes[int(label)])\n\nfig.add_subplot(1,2,2)\nplt.imshow(img.numpy().transpose((1, 2, 0)))\nplt.axis('off')\nplt.title(\"Predicted Label: \" + predicted_label)\n\nplt.show()","a533b24c":"## Creating the dataset","b004a042":"# \ud83e\udde0 Creating the Neural Network ","885b9981":"# \ud83c\udfcb\ufe0f Training the Model","9a1dc335":"# \ud83d\udc3c Transforming into a pandas dataset\n\nSince this dataset doesn't follow the `torchvision.dataset.ImagesFolder` [structure](https:\/\/pytorch.org\/vision\/stable\/datasets.html?highlight=imagefolder#torchvision.datasets.ImageFolder****) we cannot use the abstraction for an easy data exportation. Instead I will use the same methods of [this notebook](https:\/\/www.kaggle.com\/tuqayabdullazade\/fish-species-classification-99-2-accuracy) by [Tugay Abdullazade](https:\/\/www.kaggle.com\/tuqayabdullazade\/fish-species-classification-99-2-accuracy) to first create a pandas dataframe and then create a PyTorch dataset.\n\n> As a post note I've discovered I could have used the `Chooser` class for a more customized `ImagesFolder` query.\n","a989d619":"# \ud83c\udfaf Objectives:\n\n - [x] Create a simple prediction model with a standard CNN\n - [x] Create a PyTorch Dataset class\n","43c349c3":"Let's see one of our images:","cfaa4936":"# \ud83d\udd00 Adapting for Torch","0c69357b":"# \ud83c\uddf0 Standard Kaggle imports:"}}