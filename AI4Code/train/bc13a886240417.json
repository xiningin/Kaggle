{"cell_type":{"f0e3e252":"code","a57dbffd":"code","be9e6cf6":"code","f7a146e5":"code","065309ad":"code","6f689734":"code","c2d6cbe2":"code","a640e9b1":"code","1321296b":"code","053b59a4":"code","842439ac":"code","a545d0ff":"code","f3f1b811":"code","b77cc79d":"code","dab0d731":"code","a9011e3b":"code","3711d8b2":"code","c7e30c94":"code","972fab30":"code","d03d7c49":"code","de87bf54":"code","290aca64":"code","c5a7e35b":"code","5978761f":"code","baa74b9e":"code","6d231aa9":"code","2f02df3c":"code","c030d238":"code","d102bd5a":"code","ab9f6895":"code","22fd3562":"code","3f00b4cf":"code","7a6219c0":"code","5b3ea510":"code","1a3fde3f":"code","50bc7335":"code","cc799c4b":"code","5b388b14":"markdown","34e16f26":"markdown","14883714":"markdown","c9bec393":"markdown","89681739":"markdown","c1554753":"markdown","75f1aa97":"markdown","239290b9":"markdown","2215a6cb":"markdown","bd224be7":"markdown"},"source":{"f0e3e252":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a57dbffd":"pip install timm","be9e6cf6":"#Importing Libraries\nimport sys\nsys.path.append('\/kaggle\/input\/pytorch-image-models\/pytorch-image-models-master')\n\nimport glob\nimport shutil\nimport json\nimport keras\nimport itertools\nimport math\nimport time\nimport random\nimport shutil\nimport albumentations\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport scipy as sp\nfrom scipy.special import softmax\nfrom scipy.signal import convolve2d\n%matplotlib inline\n\nimport imageio\nfrom collections import Counter\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport timm\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","f7a146e5":"#Defining working directories\n\nwork_dir = '..\/input\/cassava-leaf-disease-classification\/'\nos.listdir(work_dir) \ntrain_path = '\/kaggle\/input\/cassava-leaf-disease-classification\/train_images'","065309ad":"#Loading Data\ndf = pd.read_csv(work_dir + 'train.csv')\ndf.head()","6f689734":"disease_names = open('..\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json')\ndisease_names = json.load(disease_names)\ndf['disease_name'] = df['label'].apply(lambda x: disease_names[str(x)])\n#visualize top 20 rows from table\ndf.head(20)","c2d6cbe2":"#Calculating the number of label's per disease\n\ndf.disease_name.value_counts()","a640e9b1":"#Visualizing the Distribution of Class Labels\n\nfig = make_subplots(rows=1, cols=2,\n            specs=[[{\"type\": \"xy\"}, {\"type\": \"domain\"}]],)\n# value_counts: to count number of images in each class with respect to disease_name column\n# Bar plot \nt1 = go.Bar(x=df['disease_name'].value_counts().index, \n            y=df['disease_name'].value_counts().values,\n            text=df['disease_name'].value_counts().values,\n            textposition='auto',name='Count',\n           marker_color='indianred')\n#Pie chart with labels and counts\nt2 = go.Pie(labels=df['disease_name'].value_counts().index,\n           values=df['disease_name'].value_counts().values,\n           hole=0.3)\nfig.add_trace(t1,row=1, col=1)\nfig.add_trace(t2,row=1, col=2)\nfig.update_layout(title='Distribution of Class Labels')\nfig.show()","1321296b":"#Now let\u2019s load an image and observe its various properties in general\n\npic = imageio.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/1004105566.jpg')\nplt.figure(figsize = (5,5))\nplt.imshow(pic)","053b59a4":"#Observing the basic properties of the image\n\nprint('Type of the image : ' , type(pic))\n\nprint('Shape of the image : {}'.format(pic.shape))\nprint('Image Height : {}'.format(pic.shape[0]))\nprint('Image Width : {}'.format(pic.shape[1]))\nprint('Dimension of Image : {}'.format(pic.ndim))\n\nprint('Image size {}'.format(pic.size))\nprint('Maximum RGB value in this image {}'.format(pic.max()))\nprint('Minimum RGB value in this image {}'.format(pic.min()))","842439ac":"# A specific pixel located at Row : 100 ; Column : 50 \n# Each channel's value of it, gradually R , G , B\n\nprint('Image size {}'.format(pic.size))\nprint('Maximum RGB value in this image {}'.format(pic.max()))\nprint('Minimum RGB value in this image {}'.format(pic.min()))","a545d0ff":"#Now let\u2019s take a quick view of each channel in the whole image\n\nplt.title('R-CHANNEL')\nplt.ylabel('Height {}'.format(pic.shape[0]))\nplt.xlabel('Width {}'.format(pic.shape[1]))\nplt.imshow(pic[ : , : , 0])\nplt.show()\n\nplt.title('G-CHANNEL')\nplt.ylabel('Height {}'.format(pic.shape[0]))\nplt.xlabel('Width {}'.format(pic.shape[1]))\nplt.imshow(pic[ : , : , 1])\nplt.show()\n\nplt.title('B-CHANNEL')\nplt.ylabel('Height {}'.format(pic.shape[0]))\nplt.xlabel('Width {}'.format(pic.shape[1]))\nplt.imshow(pic[ : , : , 2])\nplt.show()","f3f1b811":"pic = imageio.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/1004105566.jpg')\nfig, ax = plt.subplots(nrows = 1, ncols=3, figsize=(15,5))\n\nfor c, ax in zip(range(3), ax):\n    # create zero matrix\n    split_img = np.zeros(pic.shape, dtype=\"uint8\") # 'dtype' by default: 'numpy.float64'\n    \n    # assing each channel \n    split_img[ :, :, c] = pic[ :, :, c]\n    \n    # display each channel\n    ax.imshow(split_img)","b77cc79d":"#Image Processing\n\n# Only Red Pixel value , higher than 180\npic = imageio.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/1004105566.jpg')\nred_mask = pic[:, :, 0] < 180\npic[red_mask] = 0\nplt.figure(figsize=(5,5))\nplt.imshow(pic)\n\n# Only Green Pixel value , higher than 180\npic = imageio.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/1004105566.jpg')\ngreen_mask = pic[:, :, 1] < 180\npic[green_mask] = 0\nplt.figure(figsize=(5,5))\nplt.imshow(pic)\n\n# Only Blue Pixel value , higher than 180\npic = imageio.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/1004105566.jpg')\nblue_mask = pic[:, :, 2] < 180\npic[blue_mask] = 0\nplt.figure(figsize=(5,5))\nplt.imshow(pic)\n\n# Composite mask using logical_and\npic = imageio.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/1004105566.jpg')\nfinal_mask = np.logical_and(red_mask, green_mask, blue_mask)\npic[final_mask] = 40\nplt.figure(figsize=(5,5))\nplt.imshow(pic)","dab0d731":"def visualize_batch(image_ids, labels):\n    plt.figure(figsize=(16, 12))\n    \n    for ind, (image_id, label) in enumerate(zip(image_ids, labels)):\n        plt.subplot(3, 3, ind + 1)\n        image = cv2.imread(os.path.join(work_dir, \"train_images\", image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(f\"Class: {label}\", fontsize=12)\n        plt.axis(\"off\")\n    \n    plt.show()","a9011e3b":"tmp_df = df.sample(9)\nimage_ids = tmp_df[\"image_id\"].values\nlabels = tmp_df[\"disease_name\"].values\n\nvisualize_batch(image_ids, labels)","3711d8b2":"tmp_df = df[df[\"label\"] == 0]\nprint(f\"Total train images for class 0: {tmp_df.shape[0]}\")\n\ntmp_df = tmp_df.sample(9)\nimage_ids = tmp_df[\"image_id\"].values\nlabels = tmp_df[\"label\"].values\n\nvisualize_batch(image_ids, labels)","c7e30c94":"tmp_df = df[df[\"label\"] == 1]\nprint(f\"Total train images for class 1: {tmp_df.shape[0]}\")\n\ntmp_df = tmp_df.sample(9)\nimage_ids = tmp_df[\"image_id\"].values\nlabels = tmp_df[\"label\"].values\n\nvisualize_batch(image_ids, labels)","972fab30":"tmp_df = df[df[\"label\"] == 2]\nprint(f\"Total train images for class 2: {tmp_df.shape[0]}\")\n\ntmp_df = tmp_df.sample(9)\nimage_ids = tmp_df[\"image_id\"].values\nlabels = tmp_df[\"label\"].values\n\nvisualize_batch(image_ids, labels)","d03d7c49":"tmp_df = df[df[\"label\"] == 3]\nprint(f\"Total train images for class 3: {tmp_df.shape[0]}\")\n\ntmp_df = tmp_df.sample(9)\nimage_ids = tmp_df[\"image_id\"].values\nlabels = tmp_df[\"label\"].values\n\nvisualize_batch(image_ids, labels)","de87bf54":"tmp_df = df[df[\"label\"] == 4]\nprint(f\"Total train images for class 4: {tmp_df.shape[0]}\")\n\ntmp_df = tmp_df.sample(9)\nimage_ids = tmp_df[\"image_id\"].values\nlabels = tmp_df[\"label\"].values\n\nvisualize_batch(image_ids, labels)","290aca64":"#for efficientnet\nBATCH_SIZE = 1\nimage_size = 512\nenet_type = ['tf_efficientnet_b4_ns'] * 5\nmodel_path = ['\/kaggle\/input\/efficientnet\/baseline_cld_fold0_epoch8_tf_efficientnet_b4_ns_512.pth', \n              '\/kaggle\/input\/efficientnet\/baseline_cld_fold1_epoch9_tf_efficientnet_b4_ns_512.pth', \n              '\/kaggle\/input\/efficientnet\/baseline_cld_fold2_epoch9_tf_efficientnet_b4_ns_512.pth',\n              '\/kaggle\/input\/efficientnet\/baseline_cld_fold3_epoch5_tf_efficientnet_b4_ns_512.pth',\n              '\/kaggle\/input\/efficientnet\/baseline_cld_fold4_epoch11_tf_efficientnet_b4_ns_512.pth']","c5a7e35b":"#Transform for efficientnet\ntransforms_valid = albumentations.Compose([\n    albumentations.CenterCrop(image_size, image_size, p=1),\n    albumentations.Resize(image_size, image_size),\n    albumentations.Normalize()\n])","5978761f":"#Working Dir for Model\nimport os\n\nMODEL_DIR = '\/kaggle\/input\/resnet50\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \nTRAIN_PATH = '\/kaggle\/input\/cassava-leaf-disease-classification\/train_images'\nTEST_PATH = '\/kaggle\/input\/cassava-leaf-disease-classification\/test_images'","baa74b9e":"# CFG for Resnext\nclass CFG:\n    debug=False\n    num_workers=8\n    model_name='resnext50_32x4d'\n    size=512\n    batch_size=32\n    seed=2020\n    target_size=5\n    target_col='label'\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]\n    inference=True","6d231aa9":"# Utils for Resnext\ndef get_score(y_true, y_pred):\n    return accuracy_score(y_true, y_pred)\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n    \ndef init_logger(log_file=OUTPUT_DIR+'inference.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n#LOGGER = init_logger()\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)    ","2f02df3c":"#Data Loading\ntest = pd.read_csv('\/kaggle\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\ntest['filepath'] = test.image_id.apply(lambda x: os.path.join('\/kaggle\/input\/cassava-leaf-disease-classification\/test_images', f'{x}'))","c030d238":"# Dataset for Resnext\nclass TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['image_id'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}\/{file_name}'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","d102bd5a":"# Dataset for efficientnet\nclass CLDDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        row = self.df.loc[index]\n        image = cv2.imread(row.filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            res = self.transform(image=image)\n            image = res['image']\n            \n        image = image.astype(np.float32)\n        image = image.transpose(2,0,1)\n        if self.mode == 'test':\n            return torch.tensor(image).float()\n        else:\n            return torch.tensor(image).float(), torch.tensor(row.label).float()    ","ab9f6895":"#for efficientnet\ntest_dataset_efficient = CLDDataset(test, 'test', transform=transforms_valid)\ntest_loader_efficient = torch.utils.data.DataLoader(test_dataset_efficient, batch_size=BATCH_SIZE, shuffle=False,  num_workers=4)","22fd3562":"# Transforms for Resnext\ndef get_transforms(*, data):\n    if data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])","3f00b4cf":"# ResNext Model\nclass CustomResNext(nn.Module):\n    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","7a6219c0":"# EfficientNet Model\nclass enet_v2(nn.Module):\n\n    def __init__(self, backbone, out_dim, pretrained=False):\n        super(enet_v2, self).__init__()\n        self.enet = timm.create_model(backbone, pretrained=pretrained)\n        in_ch = self.enet.classifier.in_features\n        self.myfc = nn.Linear(in_ch, out_dim)\n        self.enet.classifier = nn.Identity()\n\n    def forward(self, x):\n        x = self.enet(x)\n        x = self.myfc(x)\n        return x","5b3ea510":"# Helper functions for Resnext\ndef load_state(model_path):\n    model = CustomResNext(CFG.model_name, pretrained=False)\n    try:  # single GPU model_file\n        model.load_state_dict(torch.load(model_path)['model'], strict=True)\n        state_dict = torch.load(model_path)['model']\n    except:  # multi GPU model_file\n        state_dict = torch.load(model_path)['model']\n        state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n\n    return state_dict\n\ndef inference(model, states, test_loader, device):\n    model.to(device)\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for state in states:\n            model.load_state_dict(state)\n            model.eval()\n            with torch.no_grad():\n                y_preds = model(images)\n            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","1a3fde3f":"# Helper functions for efficientnet\ndef inference_func(test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n\n    LOGITS = []\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            logits = model(x)\n            LOGITS.append(logits.cpu())\n            PREDS += [torch.softmax(logits, 1).detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        LOGITS = torch.cat(LOGITS).cpu().numpy()\n    return PREDS\n\ndef tta_inference_func(test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n    PREDS = []\n    LOGITS = []\n\n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            x = torch.stack([x,x.flip(-1),x.flip(-2),x.flip(-1,-2),\n            x.transpose(-1,-2),x.transpose(-1,-2).flip(-1),\n            x.transpose(-1,-2).flip(-2),x.transpose(-1,-2).flip(-1,-2)],0)\n            x = x.view(-1, 3, image_size, image_size)\n            logits = model(x)\n            logits = logits.view(BATCH_SIZE, 8, -1).mean(1)\n            PREDS += [torch.softmax(logits, 1).detach().cpu()]\n            LOGITS.append(logits.cpu())\n\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        \n    return PREDS","50bc7335":"# inference\n\n#for Resnext\nmodel = CustomResNext(CFG.model_name, pretrained=False)\n#model = enet_v2(enet_type[i], out_dim=5)\nstates = [load_state(MODEL_DIR+f'{CFG.model_name}_fold{fold}.pth') for fold in CFG.trn_fold]\ntest_dataset = TestDataset(test, transform=get_transforms(data='valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, \n                         num_workers=CFG.num_workers, pin_memory=True)\npredictions = inference(model, states, test_loader, device)\n\n#for Efficientnet\ntest_preds = []\nfor i in range(len(enet_type)):\n    model = enet_v2(enet_type[i], out_dim=5)\n    model = model.to(device)\n    model.load_state_dict(torch.load(model_path[i]))\n    test_preds += [tta_inference_func(test_loader_efficient)]\n    ","cc799c4b":"# submission\n\npred = 0.5*predictions + 0.5*np.mean(test_preds, axis=0)\ntest['label'] = softmax(pred).argmax(1)\ntest[['image_id', 'label']].to_csv('submission.csv', index=False)\ntest.head()","5b388b14":"**4 - Healthy**","34e16f26":"**2 - CGM - Cassava Green Mottle**","14883714":"# **Modelling**","c9bec393":"**Splitting Layers**\n\nNow, we know that each pixel of the image is represented by three integers. Splitting the image into separate color components is just a matter of pulling out the correct slice of the image array.","89681739":"**0 - CBB - Cassava Bacterial Blight**","c1554753":"# > **If you are taking help,Please Upvote**","75f1aa97":"**Kindly upvote......If you find this notebook helpful!!**","239290b9":"**3 - CMD - Cassava Mosaic Disease**","2215a6cb":"**1 - CBSD - Cassava Brown Streak Disease**","bd224be7":"**General Visualization**"}}