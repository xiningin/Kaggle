{"cell_type":{"12dbc94e":"code","e25bd832":"code","0e2ab5be":"code","c12244d3":"code","f051e0b7":"code","c43720ea":"code","5d2d1131":"code","aef4b544":"code","30f220ab":"code","55481f87":"code","2442b950":"code","c130c6ab":"code","abc9ef3d":"code","18a14edf":"code","b1016e5e":"markdown","dd4c241d":"markdown","f5ff06c9":"markdown","e7df4927":"markdown","6010ef5d":"markdown","72e634b0":"markdown","a1a8f712":"markdown","99b73edd":"markdown","e88e5e00":"markdown","c35a2103":"markdown","f2bcd848":"markdown","716f6c8c":"markdown","ae56f417":"markdown","e7bde31a":"markdown","0b2c6ec8":"markdown"},"source":{"12dbc94e":"# importing libraries\nimport numpy as np \nimport pandas as pd \nimport os\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n%matplotlib inline\nfrom plotly import tools\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ninit_notebook_mode(connected=True)\nfrom ipywidgets import interact, interactive, interact_manual\nimport ipywidgets as widgets\nimport colorlover as cl","e25bd832":"# loading data from different years\nDIR = '\/kaggle\/input\/kaggle-survey-2018\/'\ndf_free_18 = pd.read_csv(DIR + 'freeFormResponses.csv', low_memory=False, header=[0,1])\ndf_choice_18 = pd.read_csv(DIR + 'multipleChoiceResponses.csv', low_memory=False, header=[0,1])\n# Format Dataframes\ndf_free_18.columns = ['_'.join(col) for col in df_free_18.columns]\ndf_choice_18.columns = ['_'.join(col) for col in df_choice_18.columns]\n\nDIR = '\/kaggle\/input\/kaggle-survey-2017\/'\ndf_free_17 = pd.read_csv(DIR + 'freeformResponses.csv', low_memory=False)\ndf_choice_17 = pd.read_csv(DIR + 'multipleChoiceResponses.csv', low_memory=False, encoding='latin-1')\n\nDIR = '\/kaggle\/input\/kaggle-survey-2019\/'\ndf_free_19 = pd.read_csv(DIR + 'other_text_responses.csv', low_memory=False)\ndf_choice_19 = pd.read_csv(DIR + 'multiple_choice_responses.csv', low_memory=False, encoding='latin-1', header=[0,1])\ndf_choice_19.columns = ['_'.join(col) for col in df_choice_19.columns]","0e2ab5be":"df_choice_19.columns.values.tolist()","c12244d3":"# processing data for visualizations\ntop_count = df_choice_19['Q3_In which country do you currently reside?'].value_counts().head(8).reset_index().rename(\n    columns={'Q3_In which country do you currently reside?': 'count', 'index': 'Country'})\n\n# taking only responders from your country of interest\ndef preprocess_by_country(df_choice_17, df_choice_18, df_choice_19, country=\"Japan\"):\n    df_choice_17 = df_choice_17.loc[df_choice_17['Country'] == country]\n    df_choice_18 = df_choice_18.loc[df_choice_18['Q3_In which country do you currently reside?'] == country]\n    df_choice_19 = df_choice_19.loc[df_choice_19['Q3_In which country do you currently reside?'] == country]\n\n    def get_age(x: int):\n        \"\"\"\n        Convert numerical age to categories.\n        \"\"\"\n        if 18 <= x <= 21:\n            return '18-21'\n        elif 22 <= x <= 24:\n            return '22-24'\n        elif 25 <= x <= 29:\n            return '25-29'\n        elif 30 <= x <= 34:\n            return '30-34'\n        elif 35 <= x <= 39:\n            return '35-39'\n        elif 40 <= x <= 44:\n            return '40-44'\n        elif 45 <= x <= 49:\n            return '45-49'\n        elif 50 <= x <= 54:\n            return '50-54'\n        elif 55 <= x <= 59:\n            return '55-59'\n        elif 60 <= x <= 69:\n            return '60-69'\n        elif x >= 70:\n            return '70+'\n\n    # create a new age column with the same name and unique values in all datasets\n    df_choice_17['Age_'] = df_choice_17['Age'].apply(lambda x: get_age(x))\n    df_choice_18['Age_'] = df_choice_18['Q2_What is your age (# years)?']\n    df_choice_18.loc[df_choice_18['Age_'].isin(['70-79', '80+']), 'Age_'] = '70+'\n    df_choice_19['Age_'] = df_choice_19['Q1_What is your age (# years)?']\n\n    # renaming columns so that it would be easier to work with them\n    df_choice_17 = df_choice_17.rename(columns={'GenderSelect': 'Gender', 'FormalEducation': 'Degree'})\n    df_choice_18 = df_choice_18.rename(columns={'Q1_What is your gender? - Selected Choice': 'Gender', 'Q9_What is your current yearly compensation (approximate $USD)?': 'Salary',\n                                                'Q4_What is the highest level of formal education that you have attained or plan to attain within the next 2 years?': 'Degree'})\n    df_choice_19 = df_choice_19.rename(columns={'Q2_What is your gender? - Selected Choice': 'Gender', 'Q10_What is your current yearly compensation (approximate $USD)?': 'Salary',\n                                                'Q4_What is the highest level of formal education that you have attained or plan to attain within the next 2 years?': 'Degree'})\n    df_choice_19['Degree'] = df_choice_19['Degree'].replace({'Master\u00e2\u0080\u0099s degree': 'Master\u2019s degree', 'Bachelor\u00e2\u0080\u0099s degree': 'Bachelor\u2019s degree',\n                                                             'Some college\/university study without earning a bachelor\u00e2\u0080\u0099s degree': 'Some college\/university study without earning a bachelor\u2019s degree'})\n    df_choice_17['Degree'] = df_choice_17['Degree'].replace({\"Master's degree\": 'Master\u2019s degree', \"Bachelor's degree\": 'Bachelor\u2019s degree',\n                                                             \"Some college\/university study without earning a bachelor's degree\": 'Some college\/university study without earning a bachelor\u2019s degree'})\n\n    # changing salary values to the same categories\n    df_choice_19.loc[df_choice_19['Salary'].isin(['$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999', '4,000-4,999', '5,000-7,499', '7,500-9,999']), 'Salary'] = '0-10,000'\n    df_choice_19.loc[df_choice_19['Salary'].isin(['10,000-14,999', '15,000-19,999']), 'Salary'] = '10-20,000'\n    df_choice_19.loc[df_choice_19['Salary'].isin(['20,000-24,999', '25,000-29,999']), 'Salary'] = '20-30,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '30,000-39,999', 'Salary'] = '30-40,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '40,000-49,999', 'Salary'] = '40-50,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '50,000-59,999', 'Salary'] = '50-60,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '60,000-69,999', 'Salary'] = '60-70,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '70,000-79,999', 'Salary'] = '70-80,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '80,000-89,999', 'Salary'] = '80-90,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '90,000-99,999', 'Salary'] = '90-100,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '100,000-124,999', 'Salary'] = '100-125,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '125,000-149,999', 'Salary'] = '125-150,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '150,000-199,999', 'Salary'] = '150-200,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '200,000-249,999', 'Salary'] = '200-250,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '250,000-299,999', 'Salary'] = '250-300,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '300,000-500,000', 'Salary'] = '300-500,000'\n    df_choice_19.loc[df_choice_19['Salary'] == '> $500,000', 'Salary'] = '500,000+'\n    df_choice_18.loc[df_choice_18['Salary'].isin(['400-500,000', '300-400,000']), 'Salary'] = '300-500,000'\n    \n    return df_choice_17, df_choice_18, df_choice_19","f051e0b7":"# Functions\n\n# some of the code is taken from my old kernel: https:\/\/www.kaggle.com\/artgor\/russia-usa-india-and-other-countries\n\ndef plot_gender_vars(df_choice_17, df_choice_18, df_choice_19, var1: str = '', title_name: str = '', nationality=\"Japanese\"):\n    \"\"\"\n    Make separate count plots for genders over years.\n    \"\"\"\n    colors = cl.scales['3']['qual']['Paired']\n    names = {0: '2017', 1: '2018', 2: '2019'}\n    fig = tools.make_subplots(rows=1, cols=2, subplot_titles=('Male', 'Female'), print_grid=False)\n    # there are too little responders, who don't identify as Male\/Female, I have decided that I can use the most common genders.\n    for j, c in enumerate(['Male', 'Female']):\n        data = []\n        for i, df in enumerate([df_choice_17, df_choice_18, df_choice_19]):\n            grouped = df.loc[(df['Gender'] == c), var1].value_counts().sort_index().reset_index()\n            grouped['Age_'] = grouped['Age_'] \/ np.sum(grouped['Age_'])\n            trace = go.Bar(\n                x=grouped['index'],\n                y=grouped.Age_,\n                name=names[i],\n                marker=dict(color=colors[i]),\n                showlegend=True if j == 0 else False,\n                legendgroup=i\n            )\n            fig.append_trace(trace, 1, j + 1)    \n\n    fig['layout'].update(height=400, width=1000, title=f'Rate of {nationality} kagglers by {title_name} and gender');\n    return fig\n\n\ndef plot_var(df_choice_17, df_choice_18, df_choice_19, var1: str = '', title_name: str = '', nationality=\"Japanese\"):\n    \"\"\"\n    Plot one variable over years.\n    \"\"\"\n    colors = cl.scales['3']['qual']['Paired']\n    names = {0: '2017', 1: '2018', 2: '2019'}\n    \n    data = []\n    for i, df in enumerate([df_choice_17, df_choice_18, df_choice_19]):\n        grouped = df[var1].value_counts().sort_index().reset_index()\n        grouped[var1] = grouped[var1] \/ np.sum(grouped[var1])\n        trace = go.Bar(\n            x=grouped['index'],\n            y=grouped[var1],\n            name=names[i],\n            marker=dict(color=colors[i]),\n            legendgroup=i\n        )\n        data.append(trace)\n    layout = dict(height=400, width=1000, title=f'{nationality} kagglers by {title_name}');  \n    fig = dict(data=data, layout=layout)\n    return fig\n    \ndef plot_var_salary(df_choice_18, df_choice_19, var1: str = '', title_name: str = '', normalize: bool = False, nationality=\"Japanese\"):\n    \"\"\"\n    Plot salary over years. This is a separate function, because\n    it is necessary to add code for sorting.\n    \"\"\"\n    colors = cl.scales['3']['qual']['Paired']\n    names = {0: '2018', 1: '2019'}\n    \n    data = []\n    for i, df in enumerate([df_choice_18, df_choice_19]):\n        grouped = df[var1].value_counts().sort_index().reset_index()\n        if normalize:\n            grouped[var1] = grouped[var1] \/ np.sum(grouped[var1])\n        map_dict = {'0-10,000': 0,\n                    '10-20,000': 1,\n                    '100-125,000': 10,\n                    '125-150,000' : 11,\n                    '150-200,000': 12,\n                    '20-30,000': 2,\n                    '200-250,000': 13,\n                    '250-300,000': 14,\n                    '30-40,000': 3,\n                    '300-500,000': 15,\n                    '40-50,000': 4,\n                    '50-60,000': 5,\n                    '60-70,000': 6,\n                    '70-80,000': 7,\n                    '80-90,000': 8,\n                    '90-100,000': 9,\n                    '500,000+': 16,\n                    'I do not wish to disclose my approximate yearly compensation': 17}\n        grouped['sorting'] = grouped['index'].apply(lambda x: map_dict[x])\n        grouped = grouped.loc[grouped['index'] != 'I do not wish to disclose my approximate yearly compensation']\n        grouped = grouped.sort_values('sorting', ascending=True)\n        trace = go.Bar(\n            x=grouped['index'],\n            y=grouped[var1],\n            name=names[i],\n            marker=dict(color=colors[i]),\n            legendgroup=i\n        )\n        data.append(trace)\n    layout = dict(height=500, width=1000, title=f'{nationality} kagglers by {title_name}');  \n    fig = dict(data=data, layout=layout)\n    return fig\n\n\ndef plot_choice_var(df_choice_19, var: str = '', title_name: str = ''):\n    \"\"\"\n    Plot a variable, in which responders could select several answers.\n    \"\"\"\n    col_names = [col for col in df_choice_19.columns if f'{var}_Part' in col]\n    data = []\n    small_df = df_choice_19[col_names]\n    text_values = [col.split('- ')[2] for col in col_names]\n    counts = []\n    for m, n in zip(col_names, text_values):\n        if small_df[m].nunique() == 0:\n            counts.append(0)\n        else:\n            counts.append(sum(small_df[m] == n))\n            \n    trace = go.Bar(\n        x=text_values,\n        y=counts,\n        name='c',\n        marker=dict(color='silver'),\n        showlegend=False\n    )\n    data.append(trace)    \n    fig = go.Figure(data=data)\n    fig['layout'].update(height=600, width=1000, title=f'Popular {title_name}');\n    return fig","c43720ea":"top_count = top_count.sort_values('count')\nfig = make_subplots(rows=1, cols=1)\nfig.add_trace(go.Bar(y=top_count['Country'], x=top_count['count'], orientation='h', \n                     name='Number of respondents by country in 2019'), row=1, col=1)\nfig['layout'].update(height=600, width=600, title=f'The number of respondants in 2019');\niplot(fig);","5d2d1131":"countries_to_analyze = (\"India\", \"United States of America\", \"Brazil\", \"Japan\", \"Russia\", \"China\")\nd2017 = {}\nd2018 = {}\nd2019 = {}\nfor c in countries_to_analyze:\n    df17, df18, df19 = preprocess_by_country(df_choice_17, df_choice_18, df_choice_19, country=c)\n    d2017[c] = df17\n    d2018[c] = df18\n    d2019[c] = df19","aef4b544":"fig = tools.make_subplots(rows=2, cols=3, subplot_titles=countries_to_analyze, print_grid=False)\nfor i, c in enumerate(countries_to_analyze):\n    df_count = pd.DataFrame({'Year': [2017, 2018, 2019], 'Count': [d2017[c].shape[0], d2018[c].shape[0], d2019[c].shape[0]]})\n    if i < 3:\n        row = 1\n        col = i + 1\n    else:        \n        row = 2\n        col = i - 2\n    fig.append_trace(go.Bar(x=df_count['Year'], y=df_count['Count'], name=c, showlegend=False), row=row, col=col)\n\nfig['layout'].update(height=800, width=1000);\niplot(fig);","30f220ab":"fig = plot_gender_vars(d2017[\"Japan\"], d2018[\"Japan\"], d2019[\"Japan\"], var1='Age_', title_name='age')\niplot(fig);","55481f87":"fig = plot_var(d2017[\"Japan\"], d2018[\"Japan\"], d2019[\"Japan\"], var1='Degree', title_name='degree')\niplot(fig);","2442b950":"fig = plot_var_salary(d2018[\"Japan\"], d2019[\"Japan\"], var1='Salary', title_name='salary')\niplot(fig);","c130c6ab":"d2019[\"Japan\"]['Q5_Select the title most similar to your current role (or most recent title if retired): - Selected Choice'].value_counts().plot.bar()","abc9ef3d":"fig = plot_choice_var(d2019[\"Japan\"], var='Q12', title_name='resources')\niplot(fig);","18a14edf":"fig = plot_choice_var(d2019[\"Japan\"], var='Q18', title_name='languages')\niplot(fig);","b1016e5e":"### Load data\nMany of the code are shamelessly taken from https:\/\/www.kaggle.com\/artgor\/a-look-at-russian-kagglers-over-time. Thanks a lot and pls upvote the kernel!","dd4c241d":"### The number of respondants as a function of year\nInterestingly, although the number itself is very different, Japan exhibits the same pattern as India: monotonic increase by year. This is exciting for Japan, having more and more kagglers.","f5ff06c9":"### Degree\nMostly master, as is the case with many other countries. Not many people dare to go to get PhD.","e7df4927":"# Conclusion\nThe future of kagglers in Japan seems bright.\n\n- More and more people joining Kaggle\n- Among them the top 3 occupations are software engineers, data scientists, and students\n- The yearly compensation for kagglers seems to get higher\n- They actively communicate mainly via blogs and twitters and learn and motivate one another","6010ef5d":"So...are you ready for Kaggle days in Tokyo?","72e634b0":"### Resources\nExcept for Kaggle, twitter and blogs are quite popular. Indeed, there are some influencers being Kaggle GM or master...so they may stimulate followers to keep up. ","a1a8f712":"# Results","99b73edd":"## How many respondants were there in Japan?\nHere is the ranking. You can see that the majority is Indian, yet Japan came into the 5th place (673 respondants). So seemingly there are relatively many kagglers in Japan.","e88e5e00":"### Salary\nWell there are more poor people (whose income is less than 10,000) in 2019 than 2018;( On the other hand, there are more people with > 100K...\nIt seems that except for the lowest bin, kagglers in Japan earn more than the previous year. Indeed, as I am living in Japan, I have encountered many job posts which favour kagglers.\n\n[This job post by a company called \"Rist\" located in Kyoto](https:\/\/recruit.jobcan.jp\/rist\/show\/b001\/115250) is for example an iconic one. This offer is limited to kaggle masters (!) and the yearly compensation is around 100k or more.\n\nAlso, [DeNA](https:\/\/dena.ai\/kaggle\/) is a quite famous domestic IT company which is well known to love kagglers and offer competitive compensations. \n\n![image.png](attachment:image.png)\n\nThere seems to be a trend that **more and more attractive offers are waiting for Kagglers in Japan**. This could explain the reason why the sharp increase in the lowest bin...more and more youngsters are seemingly joining Kaggle to get better an offer.  ","c35a2103":"# Introduction\n\n![image.png](attachment:image.png)\n\n## JAPAN\nHave you noticed that there are more and more names of kernels and teams with characters which do not look like English or Chinese?\nOr do you see more and more profile icons with a 2D girl? English discussions always missing \"the\" or \"a\"? \n\nThey may be ... Japanese.\n\nWhat is Japan famous for? \n\n- Sushi\n- Ramen\n- Anime\n- Manga\n\nSure, but how about data science?\n\nOn December 11-12, 2019 we will have the **kaggle days in Tokyo**, JAPAN. This is upcoming, so maybe it is worthwhile looking into what kagglers in Japan have to say. The result of this analysis might be useful to find something to chat with locals in the event!","f2bcd848":"### Age and gender\nThey are relatively young. It's kind of cool to see 70+ kagglers.  ","716f6c8c":"### Questions\nFYI, here is the list of questions.","ae56f417":"### Popular languages\nPython and that's it!","e7bde31a":"### Preprocess","0b2c6ec8":"### Job titles\nSoftware engineers and data scientists are 2 tops. Students follow, and they will be likely to be one or both of them in the near future."}}