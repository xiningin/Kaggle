{"cell_type":{"7a83aa74":"code","a2226058":"code","ced4089b":"code","5a4d59b5":"code","de2a3957":"code","1d9439df":"code","945c54cf":"code","8eb7d3ec":"code","3bd57a5e":"code","1ffacbf0":"code","f7650fff":"code","0e07d95b":"code","69bf1288":"code","fc798e72":"code","a909da86":"code","d4735398":"markdown","26bc17c8":"markdown","7b9747b2":"markdown","5f7e1969":"markdown","d7157a0c":"markdown","c128fb24":"markdown","53938191":"markdown","34abe7e8":"markdown","11a202a4":"markdown","a07f285e":"markdown","a9bb8bdc":"markdown","33a801ba":"markdown","7201d8ff":"markdown","0763ab52":"markdown"},"source":{"7a83aa74":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid","a2226058":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\n\nimport math\nimport random\n\nfrom PIL import Image, ImageOps, ImageEnhance\nimport numbers\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","ced4089b":"train, test = pd.read_csv('..\/input\/digit-recognizer\/train.csv'), \\\n              pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\ntrain.head()","5a4d59b5":"\ny_train = train['label']\nx_train, x_test = train.iloc[:,1:], test\nx_train, x_test = x_train \/ 255., x_test \/ 255. \n\nx_train, x_test = x_train.values.reshape(-1,28,28),\\\n                  x_test.values.reshape(-1,28,28)\n\nplt.imshow(x_train[3].reshape(28, 28), cmap='gray')","de2a3957":"ran=[0,1]\ngrid = make_grid(torch.Tensor((train.iloc[ran, 1:].to_numpy()\/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\nplt.rcParams['figure.figsize'] = (16, 2)\nplt.imshow(grid.numpy().transpose((1,2,0)))\nplt.axis('off')\nprint(*list(train.iloc[ran, 0].values), sep = ', ')","1d9439df":"n_train = len(train)\nn_pixels = len(train.columns) - 1","945c54cf":"class MNIST_data(Dataset):\n    \"\"\"MNIST dtaa set\"\"\"\n    \n    def __init__(self, file_path,l_data,transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n                     transforms.Normalize(mean=(0.5,), std=(0.5,))])):\n        \n        df = pd.read_csv(file_path)\n        \n        if len(df.columns) == n_pixels:\n            # test data\n            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = None\n        else:\n            # training data\n            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = torch.from_numpy(df.iloc[:,0].values)\n            \n        self.transform = transform\n        self.l_data=l_data\n    \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        meta=self.l_data.iloc[int(self.y[idx])].value\n        meta=torch.tensor(meta,dtype=torch.float32)\n        if self.y is not None:\n            return (self.transform(self.X[idx]),meta), self.y[idx]\n        else:\n            return (self.transform(self.X[idx]),meta)","8eb7d3ec":"l_data=pd.DataFrame(columns = [\"label\",\"value\"])\nfor i in range(10):\n    l_data.loc[i]=[(i)]+[(i*1.5)]\nl_data","3bd57a5e":"batch_size =16\n\ntrain_dataset = MNIST_data('..\/input\/digit-recognizer\/train.csv',l_data)\ntest_dataset = MNIST_data('..\/input\/digit-recognizer\/test.csv',l_data)\n\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                           batch_size=batch_size, shuffle=False)","1ffacbf0":"class Net(nn.Module):    \n    def __init__(self):\n        super(Net, self).__init__()\n          \n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n          \n        self.classifier = nn.Sequential(\n            nn.Dropout(p = 0.5),\n            nn.Linear(64 * 7 * 7, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            nn.Linear(512, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p = 0.5),\n            \n        )\n        # this is the structure i will be using for tabular data\n        self.meta = nn.Sequential(nn.Linear(16, 16),\n                                  \n                                  )\n        self.ouput = nn.Linear(513, 10)\n          \n        for m in self.features.children():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. \/ n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n        \n        for m in self.classifier.children():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform(m.weight)\n            elif isinstance(m, nn.BatchNorm1d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n                \n\n    def forward(self, inputs):\n        x,meta=inputs\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        meta_features=self.meta(meta)\n        #print(meta_features.shape,x.shape)\n        meta_features=torch.reshape(meta_features, (16, 1))\n        #this is the main step which will concat the data from image with the tabular data \n        #and this will be feeded to another model for final prediction,\n        feat = torch.cat((x, meta_features), dim=1)\n        x=self.ouput(feat)\n        \n        return x     ","f7650fff":"import math\nmodel = Net()\n\noptimizer = optim.Adam(model.parameters(), lr=0.003)\n\ncriterion = nn.CrossEntropyLoss()\n\n#exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nif torch.cuda.is_available():\n    print('yes')\n    model = model.cuda()\n    criterion = criterion.cuda()","0e07d95b":"def train(epoch):\n    model.train()\n    \n\n    for batch_idx,(data, target) in enumerate(train_loader):\n        #data, target = Variable(data), Variable(target)\n        \n        if torch.cuda.is_available():\n            data[0] = data[0].cuda()\n            data[1] = data[1].cuda() \n            target = target.cuda()\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        \n        loss.backward()\n        optimizer.step()\n      \n        if (batch_idx + 1)% 100 == 0:\n            print( epoch,loss.item())\n    #exp_lr_scheduler.step()","69bf1288":"model = Net()\n\noptimizer = optim.Adam(model.parameters(), lr=0.003)\n\ncriterion = nn.CrossEntropyLoss()\n\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()","fc798e72":"def evaluate(data_loader):\n    model.eval()\n    loss = 0\n    correct = 0\n    \n    for data, target in data_loader:\n        #data, target = Variable(data, volatile=True), Variable(target)\n        if torch.cuda.is_available():\n            data[0] = data[0].cuda()\n            data[1] = data[1].cuda()            \n            target = target.cuda()\n        \n        output = model(data)\n        \n        loss += F.cross_entropy(output, target, size_average=False).item()\n\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n        \n    loss \/= len(data_loader.dataset)\n        \n    print( 'loss',loss, correct, len(data_loader.dataset),100. * correct \/ len(data_loader.dataset))","a909da86":"n_epochs = 10\n\nfor epoch in range(n_epochs):\n    train(epoch)\n    evaluate(train_loader)","d4735398":"## You can see the output are almost close to 100% this is because of the tabular data which i have provided , they were a slight modification to the actual labels. If i have not provided the tabular data the accuracy was 95% ie training just the images.","26bc17c8":"## Defining the optimiser , lossfunction and loading the model to the cuda device.","7b9747b2":"## If you like the kernel please Upvote. It would help me keep motivated.","5f7e1969":"## Joining the two images and plotting","d7157a0c":"## Defining Train function ","c128fb24":"## Defining the optimiser , lossfunction and loading the model to the cuda device for evaluation.","53938191":"## This is the neural network structure I will be using Which I have got from another kernel with slight modifications.","34abe7e8":"# The main purpose of this is book is to combine tabular data with the images data for the prediction.\n## For example consider there is a situation where u are given with the ct scan of a patient(image data) and patient details(age,sex,...)(tabular data) and you are supposed to predict the status of the patient using the combined info. This notebook could be helpful in that scenario.","11a202a4":"## Finally training and evaluating the model.","a07f285e":"## This is the sample tabular data I will be using to combine with the image data just multiplied the labels with factor 1.5 by adding this value in training we can see that the accuracy of the model is almost close to 100%","a9bb8bdc":"## This is a function where we attach tabular data to the image data . i.e details of a patient to the patient ct scan. Here I am attaching the value for a label from the dataset I have created.","33a801ba":"## Reshaping the data which is in pixels is 784 pixels=28*28 .","7201d8ff":"## Procedure:\n1. Defining a Function to join tabular data with image data \n2. we get data from the above function ,this data is loaded into dataloader.\n3. This dataloader is given to the model to train\n4. once the model is trained evaluation is done.\n    ","0763ab52":"## After attaching the tabular data, provide this data as input to the dataloader which makes the data to load in batches avoiding the over usage of ram."}}