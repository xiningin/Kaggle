{"cell_type":{"fcde5faf":"code","1c25c22b":"code","386f10e5":"code","ca7e7f9b":"code","78654782":"code","7166f87b":"code","8aabd020":"code","ec6c1616":"code","35624966":"code","ca9c413d":"code","91903833":"code","2b7792ae":"code","36160cb2":"code","db402762":"code","cb007939":"code","673a9e25":"code","4d3a9aa4":"code","54f0d48c":"code","32854875":"code","7f01114d":"code","8a8872c2":"code","df413e06":"code","b27c5d01":"code","16d17952":"code","30b59180":"code","7847c58f":"code","13e3c44c":"code","94f2767c":"code","ff0abeaa":"code","ac32db7b":"code","55f8789e":"code","fce63011":"code","8f772efb":"code","c74dd784":"code","d0d411ac":"code","6c8ab89b":"code","70c84b07":"code","aa264911":"code","c62ffdd8":"code","2fdd4818":"code","4e5e2b5c":"code","cfe75949":"code","57721770":"code","c9082f22":"code","393c2512":"code","6b7fbecc":"code","e4507ec5":"code","921a6cd4":"code","e0e53e35":"code","28da5f19":"code","a8410c7b":"code","9416c0ab":"code","d51866cb":"code","e88c9e6a":"code","8d25d244":"code","29f8fd3d":"code","fbe07351":"code","e0b6216b":"code","4b520983":"code","0ed1ada9":"code","9a11fd38":"code","c35642ed":"code","4c976318":"code","567fb035":"code","e92d8c9a":"code","ded00a73":"code","a298fff5":"code","09120c6e":"code","d339174c":"code","1d409df8":"code","63969aa2":"code","8ceda4fd":"code","e7715c54":"code","157ec0bf":"code","2dc9ed8a":"code","32a66026":"code","7da3a382":"code","451c9c2a":"markdown","8eb86dc9":"markdown","0acf519e":"markdown","96ffaaac":"markdown","9f4d200c":"markdown","5a2a66db":"markdown","e443b8c5":"markdown","6af6cd0d":"markdown","4c7b2afa":"markdown","360870e3":"markdown","6544a679":"markdown","42052b3e":"markdown","26ea82e5":"markdown","20dc9ab1":"markdown","d7485f34":"markdown","fd0fc3dd":"markdown","08379ece":"markdown","0da15abe":"markdown","ebb35709":"markdown","9816c22e":"markdown","043318b0":"markdown","3640196e":"markdown","1cf8fbe7":"markdown","bb085ad9":"markdown","9023ca86":"markdown","003fd626":"markdown","0d67b1c2":"markdown","48816c44":"markdown","3878c2a1":"markdown","2063a67e":"markdown","c09d8106":"markdown","472729e7":"markdown","cbe8745f":"markdown","45945e07":"markdown","500e4bde":"markdown","ff88e6f5":"markdown","17b88aad":"markdown","df6317f9":"markdown","921e3514":"markdown","82bac4db":"markdown","42fbcda6":"markdown","9c19377c":"markdown","41dc098c":"markdown","e1e8350d":"markdown","49acbccf":"markdown","5ed71126":"markdown","b4ec365e":"markdown","19ae12c7":"markdown","a917c583":"markdown","27d8ea56":"markdown","4265f9e7":"markdown","83bf51e0":"markdown","00df26ab":"markdown","892454e3":"markdown","6339d225":"markdown","45c4388d":"markdown","c2d4b183":"markdown","b11ed13f":"markdown","aa76be4d":"markdown","7b8430dd":"markdown","61a48b66":"markdown","21e6e987":"markdown"},"source":{"fcde5faf":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Lasso, Ridge\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.gridspec as gridspec\nimport missingno as msno\nimport scipy.stats as stats \nfrom scipy.special import boxcox1p\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings(\"ignore\")","1c25c22b":"train_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","386f10e5":"train_data.head()","ca7e7f9b":"train_data.tail()","78654782":"train_data.columns","7166f87b":"print('lenght of data is', len(train_data))","8aabd020":"train_data.shape","ec6c1616":"train_data.info()","35624966":"train_data.dtypes","ca9c413d":"train_data[train_data.isnull().any(axis=1)].head()","91903833":"np.sum(train_data.isnull().any(axis=1))","2b7792ae":"train_data.isnull().values.any()","36160cb2":"train_data.isnull().sum()","db402762":"test_data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\nids_test_data = test_data['Id'].values","cb007939":"test_data.head()","673a9e25":"test_data.tail()","4d3a9aa4":"test_data.columns","54f0d48c":"print('lenght of data is', len(test_data))","32854875":"test_data.shape","7f01114d":"test_data.info()","8a8872c2":"test_data.dtypes","df413e06":"test_data[test_data.isnull().any(axis=1)].head()","b27c5d01":"np.sum(test_data.isnull().any(axis=1))","16d17952":"test_data.isnull().values.any()","30b59180":"test_data.isnull().sum()","7847c58f":"NANColumns=[]\ni=-1\nfor a in train_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(train_data.columns[i],a)\n        NANColumns.append(train_data.columns[i])","13e3c44c":"NANColumns=[]\ni=-1\nfor a in test_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(test_data.columns[i],a)\n        NANColumns.append(test_data.columns[i])","94f2767c":"train_data.hist(figsize=(50,50),bins = 20, color=\"#107009AA\")\nplt.title(\"Features\/Columns Distribution with values counts\")\nplt.show()","ff0abeaa":"temporal_features = [feat for feat in train_data if \"Year\" in feat or \"Yr\" in feat]\nprint(temporal_features)\nfor feature in temporal_features:\n    sns.scatterplot(x=feature,y=\"SalePrice\",data=train_data)\n    plt.title(feature)\n    plt.show()","ac32db7b":"#HERE condition less than 6 is the unique count of temporal features.  \"rain_data[feature].nunique() < 6\" return true\ndiscrete_features = [feature for feature in train_data if train_data[feature].nunique() < 6 and feature not in temporal_features]\ncontinuous_features = [feature for feature in train_data if feature not in discrete_features and feature not in temporal_features]\n\nprint(\"Discrete_Features:\\n\",discrete_features)\nprint(\"Continuous_Features:\\n\",continuous_features)","55f8789e":"def scatterplot(df,feature,target_feature):\n    plt.figure(constrained_layout=True)\n    sns.scatterplot(df[feature],df[target_feature])\n    plt.title(feature)\n    plt.show()\nfor feat in discrete_features:\n    scatterplot(train_data,feat,\"SalePrice\")\n","fce63011":"for feat in continuous_features:\n    scatterplot(train_data,feat,\"SalePrice\")","8f772efb":"corr_feat = train_data.corr().nlargest(10,\"SalePrice\")[\"SalePrice\"].index\ncmap = np.corrcoef(train_data[corr_feat].values.T)\nmask = np.zeros_like(cmap,dtype=bool)\nmask[np.triu_indices_from(mask)] = True\nplt.figure(figsize=(20,10))\nsns.heatmap(cmap,\n            annot=True,\n            fmt=\".3f\",\n            annot_kws = {\"size\":10},\n            cmap=sns.cubehelix_palette(),\n            xticklabels = corr_feat.values,\n            yticklabels = corr_feat.values,\n            mask=mask)","c74dd784":"y = train_data[\"SalePrice\"]","d0d411ac":"all_data = pd.concat([train_data,test_data],axis=0).reset_index(drop=True)","6c8ab89b":"all_data = all_data.drop([\"SalePrice\",\"Id\"],axis=1)","70c84b07":"def missing_value(df):\n    number = df.isnull().sum().sort_values(ascending=False)\n    number = number[number > 0]\n    percentage = df.isnull().sum() *100 \/ df.shape[0]\n    percentage = percentage[percentage > 0].sort_values(ascending=False)\n    return  pd.concat([number,percentage],keys=[\"Total\",\"Percentage\"],axis=1)\nmissing_value(all_data)","aa264911":"missing_col = [\"Alley\", \"PoolQC\", \"MiscFeature\",\"Fence\",\n               \"FireplaceQu\",\"GarageType\",\"GarageFinish\",\n               \"GarageQual\",\"GarageCond\",'BsmtQual','BsmtCond',\n               'BsmtExposure','BsmtFinType1','BsmtFinType2',\n               'MasVnrType']\n\nfor col in missing_col:\n    all_data[col] = all_data[col].fillna(\"None\") ","c62ffdd8":"#LotFrontage, Houses in the same neighborhood would have similar lotfrontage area. \n## filling the numerical features with median and mdeidan is the best suited method for numerical based features\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x:x.fillna(x.median()))","2fdd4818":"#MasVnrArea, Same apply to the MasVnrArea\n## filling the numerical features with median and mdeidan is the best suited method for numerical based features\nall_data[\"MasVnrArea\"] = all_data.groupby(\"Neighborhood\")[\"MasVnrArea\"].transform(lambda x:x.fillna(x.median()))","4e5e2b5c":"## MSSubClass\n## Imputing the missing values with the Mode because mode fill the values with the most accuring values and best for the categorical features\nall_data[\"MSZoning\"] = all_data.groupby(\"MSSubClass\")[\"MSZoning\"].transform(lambda x: x.fillna(x.mode()[0]))","cfe75949":"## GarageYrBlt\nall_data.loc[all_data[\"GarageFinish\"] == \"None\" , \"GarageYrBlt\"] = all_data[\"YearBuilt\"]","57721770":"## Check on the missing value\nmissing_value(all_data)","c9082f22":"### for the rest of the missing value\n## categorical feature are replaced with the mode value\n## numerical feature are replaced with the median value\nmissing_feat = missing_value(all_data).index","393c2512":"## getting categorical feature\nmissing_cat = [feat for feat in missing_feat if all_data[feat].dtype == np.object]","6b7fbecc":"## filling the categorical features with mode and mode is the best suited method for categorical based features\nfor feat in missing_cat:\n    all_data[feat] = all_data[feat].transform(lambda x: x.fillna(x.mode()[0]))\n\n## numerical feature\nmissing_num = [feat for feat in missing_feat if feat not in missing_cat]","e4507ec5":"## filling the numerical features with median and mdeidan is the best suited method for numerical based features\nfor feat in missing_num:\n    all_data[feat] = all_data[feat].transform(lambda x: x.fillna(x.median()))  \n### Check on the missing value\nmissing_value(all_data)","921a6cd4":"### Months ans years should be consider as categorical features\nall_data[\"MoSold\"] = all_data[\"MoSold\"].astype(str)\nall_data[\"YrSold\"] = all_data[\"YrSold\"].astype(str)\nall_data[\"YearBuilt\"] = all_data[\"YearBuilt\"].astype(str)","e0e53e35":"## Visualization\nfig = plt.figure(constrained_layout=True, figsize=(12,8))\ngrid = gridspec.GridSpec(ncols=3, nrows=4, figure=fig)\n # Histrogram\nax1 = fig.add_subplot(grid[0,:])\nsns.distplot(y,ax=ax1)\nax1.set_title(\"Histrogram of SalePrice\")\n# QQplot\nax2 = fig.add_subplot(grid[2:,:2])\nstats.probplot(y,plot=ax2)\nax2.set_title(\"QQplot of SalePrice\")\n # Boxplot\nax3 = fig.add_subplot(grid[2:,2])\nsns.boxplot(y,ax=ax3,orient=\"v\")\nax3.set_title(\"Boxplot of SalePrice\")\nplt.show()","28da5f19":"##Check on the kurtosis & the skewness of SalePrice\nprint(\"Kurtosis: {}\".format(y.kurt()))\nprint(\"Skewness: {}\".format(y.skew()))","a8410c7b":"## Normalize the Dependant Variable(SalePrice)\ny = np.log1p(y)\n\n## Visualize of SalePrice after the normalization\nfig,(ax1,ax2) = plt.subplots(2,1,constrained_layout=True,figsize=(12,9))\n\n # Histrogram\nsns.distplot(y,ax=ax1)\nax1.set_title(\"Histrogram of SalePrice\")\n # QQplot\nstats.probplot(y,plot=ax2)\nax2.set_title(\"QQplot of SalePrice\")\n\nplt.show()","9416c0ab":"## Kurtosis and skewness of SalePrice\nprint(\"Kurtosis: {}\".format(y.kurt()))\nprint(\"Skewness: {}\".format(y.skew()))","d51866cb":"## Check on the skewness and the kurtosis on continuos data only\nnumerical_feats = [feat for feat in all_data.columns if all_data[feat].dtype != np.object]\nskewness = all_data[numerical_feats].skew().sort_values(ascending=False)\nkurtosis = all_data[numerical_feats].kurt().sort_values(ascending=False)\n\ndf_norm = pd.concat([skewness,kurtosis],axis=1,keys=[\"Skewness\",\"Kurtosis\"])\n\ndf_norm","e88c9e6a":"### Feature with skewness greater than 0.5 or lower than -0.5 are considered highly skewed\nhigh_skew = skewness[abs(skewness) > 0.5].sort_values(ascending=False)\n\n## Visualization of TotalBsmtSF\nplt.figure(figsize=(8,6))\nsns.distplot(all_data[\"TotalBsmtSF\"])\nplt.show()","8d25d244":"## Look at its kurtosis and skewness value\nprint(\"Kurtosis: {}\".format(all_data[\"TotalBsmtSF\"].kurt()))\nprint(\"Skewness: {}\".format(all_data[\"TotalBsmtSF\"].skew()))","29f8fd3d":"## import packages\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n\n## Normalization of independant variables\nfor feat in high_skew.index:\n    all_data[feat] = boxcox1p(all_data[feat], boxcox_normmax(all_data[feat] + 1))\n## Visualization of TotalBsmtSF after normalization\nplt.figure(figsize=(8,6))\nsns.distplot(all_data[\"TotalBsmtSF\"])\nplt.show()\n","fbe07351":"## Look at its kurtosis and skewness value after the normalization\nprint(\"Kurtosis: {}\".format(all_data[\"TotalBsmtSF\"].kurt()))\nprint(\"Skewness: {}\".format(all_data[\"TotalBsmtSF\"].skew()))","e0b6216b":"## TotalHouseSF: The total Square Foot of the house\nall_data[\"TotalHouseSF\"] = all_data[\"TotalBsmtSF\"] + all_data[\"1stFlrSF\"] + all_data[\"2ndFlrSF\"]","4b520983":"## TotalBath: The total number of bathrooms in the house\nall_data[\"TotalBath\"] = all_data[\"BsmtFullBath\"] + all_data[\"BsmtFullBath\"]*0.5 + all_data[\"FullBath\"] + all_data[\"HalfBath\"]*0.5","0ed1ada9":"## TotalPorchSF: The total square foot of porch area of the house\nall_data[\"TotalPorchSF\"] = all_data[\"WoodDeckSF\"] + all_data[\"OpenPorchSF\"] + all_data[\"EnclosedPorch\"] + all_data[\"3SsnPorch\"] + all_data[\"ScreenPorch\"] ","9a11fd38":"## HouseRemodAge: Number of years the house being remodded to the time it was sold\nall_data[\"HouseRemodAge\"] = all_data[\"YrSold\"].astype(int) - all_data[\"YearRemodAdd\"]\nall_data.loc[all_data[\"HouseRemodAge\"] < 0, \"HouseRemodAge\"] = 0 ","c35642ed":"## function \npresence = lambda x: 1 if x > 0 else 0","4c976318":"## HasPool: Presence of pool\nall_data[\"HasPool\"] = all_data[\"PoolArea\"].transform(presence)","567fb035":"## Has2ndFlr: Presence of second floor\nall_data[\"Has2ndFlr\"] = all_data[\"2ndFlrSF\"].transform(presence)","e92d8c9a":"## HasGarage: Presence of garage\nall_data[\"HasGarage\"] = all_data[\"GarageArea\"].transform(presence)","ded00a73":"## HasBsmt: Presence of basement\nall_data[\"HasBsmt\"] = all_data[\"TotalBsmtSF\"].transform(presence)","a298fff5":"## HasFirePlace: Presence of fireplace\nall_data[\"HasFirePlace\"] = all_data[\"Fireplaces\"].transform(presence)","09120c6e":"## Bias feature reducer\nbias_feat = []\nfor feat in all_data.columns:\n    counts = all_data[feat].value_counts().iloc[0] ## mode value counts\n    if counts \/ len(all_data) * 100 > 99.94:\n        bias_feat.append(feat)\n\nbias_feat","d339174c":"## Remove the bias feature from the dataset\nall_data = all_data.drop(bias_feat,axis=1)","1d409df8":"all_data = pd.get_dummies(all_data).reset_index(drop=True)","63969aa2":"n = len(y)\ntrain_data = all_data[:n]\ntest_data = all_data[n:]","8ceda4fd":"X_train, X_test, y_train, y_test =  train_test_split(train_data,y,test_size=0.33,random_state=42)\nprint(\"Shapes of data: \", X_train.shape, X_test.shape, y_train.shape, y_test.shape)","e7715c54":"## Create an empty list\npipeline_models = []\n\n# Assign all models into the list\nseed = 42\nmodels = [Ridge(tol=10,random_state=seed),\n          Lasso(tol=1,random_state=seed),\n          RandomForestRegressor(random_state=seed),\n          ExtraTreesRegressor(random_state=seed),\n          GradientBoostingRegressor(),\n          DecisionTreeRegressor(),\n          KNeighborsRegressor()]\n\nmodel_names = [\"Ridge\",\"Lasso\",\"RFR\",\"ETR\",\"GBoost_Reg\",\"DT_Reg\",\"KNN_Reg\"]\n\n## Assign each model to a pipeline\nfor name, model in zip(model_names,models):\n    pipeline = (\"Scaled_\"+ name,\n                Pipeline([(\"Scaler\",StandardScaler()),\n                          (name,model)\n                         ]))\n    pipeline_models.append(pipeline)","157ec0bf":"## Create a dataframe to store all the models' cross validation score\nevaluate = pd.DataFrame(columns=[\"model\",\"cv\",\"std\"])\n\n\n## Encoded dataset\nfor name,model in pipeline_models:\n    kfold = KFold(n_splits=7,shuffle=True,random_state=42)\n    cv = cross_val_score(model, X_train, y_train, cv=kfold, n_jobs=-1, scoring=\"r2\")\n    \n    row = evaluate.shape[0]\n    evaluate.loc[row,\"model\"] = name\n    evaluate.loc[row,\"cv\"] = round(cv.mean(),3)\n    evaluate.loc[row,\"std\"] = \"+\/- {}\".format(round(cv.std(),4))\n    \n    evaluate = evaluate.sort_values(\"cv\",ascending=False)","2dc9ed8a":"## Visualization\nfig, ax = plt.subplots(1,1,sharey=False,figsize=(16,9))\n\n## Encoded dataset\nbar = sns.barplot(evaluate[\"model\"], evaluate[\"cv\"],ax=ax,palette = sns.cubehelix_palette(evaluate.shape[0]))\nfor rec in bar.patches:\n    height = rec.get_height()\n    ax.text(rec.get_x() + rec.get_width()\/2, height*1.02,height,ha=\"center\")\nax.set_title(\"Cross Validate Score\")\nax.set_xticklabels(evaluate[\"model\"].to_list(),rotation =50)","32a66026":"final_model = GradientBoostingRegressor()\nfinal_model = final_model.fit(X_train,y_train)","7da3a382":"submission_results = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nsubmission_results.iloc[:,1] = np.floor(np.expm1(final_model.predict(test_data)))\nsubmission_results.to_csv('submission_results', index=False)","451c9c2a":"# Exploratory data analysis of test data","8eb86dc9":"# Counts of missing values in each column","0acf519e":"# Looking at the train data missing values.","96ffaaac":"# Data information","9f4d200c":"<div class=\"alert alert-block alert-info\">  \n<h2><center><strong>Data Processing<\/strong><\/center><\/h2>\n        \n<\/div>","5a2a66db":"## Imputing the Missing Values of all data","e443b8c5":"## A function for checking the missing values","6af6cd0d":"# Counts of missing values in each column","4c7b2afa":"<div class=\"alert alert-block alert-danger\">  \n    <h1><strong>Loading training data<\/strong><\/h1>\n    <i><\/i>\n<\/div>","360870e3":"### Normalizing the of Dependant Variable SalePrice","6544a679":"## Coverting the categorical features into numeric form by applying the get_dummies function","42052b3e":"<div class=\"alert alert-block alert-success\">  \n<h2><center><strong> Adding the new features from the existing featrures because to make the model more distinguish for price predictions  !!<\/strong><\/center><\/h2>\n        \n<\/div>","26ea82e5":"<div class=\"alert alert-block alert-success\">  \n<h1><center><strong> Submitting the predicted prices of house on test data<\/strong><\/center><\/h1>\n        \n<\/div>","20dc9ab1":"# Checking missing Values","d7485f34":"# Length of data","fd0fc3dd":"# Is there any missing values?","08379ece":"# Shape of data","0da15abe":"# Shape of data","ebb35709":"# Is there any missing values?","9816c22e":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>As we can see from the graphs, TotalBsmtSF, 1stFlrSF, GrLivArea and GarageArea have stong correlation with SalePrice<\/strong><\/center><\/h2>\n        \n<\/div>","043318b0":"# Splitting the Train data into 70% for training and 30% for testing ","3640196e":"<div class=\"alert alert-block alert-info\">  \n<h2><center><strong> Training the models<\/strong><\/center><\/h2>\n        \n<\/div>","1cf8fbe7":"## Deleting the Biased Features\n","bb085ad9":"# Five last records of data","9023ca86":"# Looking at the Temporal data (temporal data is relating to time data, we are here looking at the past data) ","003fd626":"## Combining the train and test dataset","0d67b1c2":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>As we can see from the graphs, OverallQual, OverallCond, FullBath, TotRmsAbvGrd and GarageCars have stong correlation with SalePrice<\/strong><\/center><\/h2>\n        \n<\/div>","48816c44":"# Looking at the Discrete and Continuous features","3878c2a1":"# Hitogram of all columns where we are going to check that how the values of each column distributed with their counts","2063a67e":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>The above graphs show the following points<\/strong><\/center><\/h2>\n    <li>The SalePrice is drawn from a normal distribution<\/li>\n<li>The SalePrice is right skewed\/ postively skewed, which indicates that most people are able to afford lower priced house.<\/li>\n<li>Present some mutliple outliers in SalePrice<\/li>\n        \n<\/div>","c09d8106":"## Drop the SalePrice & Id columns","472729e7":"# Looking at the test data missing values.","cbe8745f":"# Five last records of data","45945e07":"# Scatter plot of each feature against Sale price on discrete features","500e4bde":"# Scatter plot of each feature against Sale price on continuous features","ff88e6f5":"# Now splitting the data for training and testing with same index ID's","17b88aad":"# Five top records of data","df6317f9":"# Data information","921e3514":"<div class=\"alert alert-block alert-danger\">  \n    <h1><strong>Loading testing data<\/strong><\/h1>\n    <i><\/i>\n<\/div>","82bac4db":"# <img src=\"https:\/\/www.mashvisor.com\/blog\/wp-content\/uploads\/2019\/01\/bigstock-Paper-House-Model-On-Coins-Sta-279182236-e1547969753106.jpg\">","42fbcda6":"# Exploratory data analysis of train data","9c19377c":"# Coloumns\/features in data","41dc098c":"## Extract the SalePrice out","e1e8350d":"# Data types of all coloumns","49acbccf":"# <img src=\"https:\/\/thumbs.dreamstime.com\/t\/bright-colorful-thank-you-banner-vector-overlapping-letters-118244535.jpg\">","5ed71126":"As we can see from the graphs, **TotalBsmtSF**, **1stFlrSF**, **GrLivArea** and **GarageArea** have stong correlation with **SalePrice**","b4ec365e":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>As indicated in the three charts above, SalePrice is postively-skewed. SalePrice is drawn from a Leptokurtic (distributions with wider tails, greater profusion of outliers) distributions.<\/strong><\/center><\/h2>\n    <li>Skewness: Defined as the degree of distortion from the symmetrical bell curve or the normal curve.<\/li>\n<li>Kurtosis: Defined as the measuer of the extreme values (also known as outliers) present in the distribution.<\/li>\n        \n<\/div>","19ae12c7":"## Normalizing the of Independant Variables","a917c583":"<div class=\"alert alert-block alert-info\">  \n<h2><center><strong> Building the models for training and testing<\/strong><\/center><\/h2>\n        \n<\/div>","27d8ea56":"# Five top records of data","4265f9e7":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong> Best Model is Gradient Boosting Regressor<\/strong><\/center><\/h2>\n        \n<\/div>","83bf51e0":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>Its better now !!<\/strong><\/center><\/h2>\n    <li>Now let's check on the kurtosis and skewness value of SalePrice<\/li>\n        \n<\/div>","00df26ab":"# Count of missing values","892454e3":"### Now the data is normalized well !!","6339d225":"# Length of data","45c4388d":"<div class=\"alert alert-block alert-info\">  \n    <h1><strong>\ud83d\udc68\u200d\ud83d\udcbb Getting Started with House Price Predictions<\/strong><\/h1>\n    <i><\/i>\n<\/div>","c2d4b183":"# Data types of all coloumns","b11ed13f":"# Importing Python Libraries \ud83d\udcd5 \ud83d\udcd7 \ud83d\udcd8 \ud83d\udcd9","aa76be4d":"# Count of missing values","7b8430dd":"# Coloumns\/features in data","61a48b66":"# Checking missing Values","21e6e987":"# Looking at the top 10 most correlated features with SalePrice "}}