{"cell_type":{"85202b6e":"code","eb4c6a33":"code","d463a180":"code","37297824":"code","d9d64a94":"code","4704a8c7":"code","ce6d1342":"code","ef47865a":"code","94c4a4b3":"code","8d76f3b6":"code","d51e682f":"code","43d4142c":"code","f11459ff":"code","151e858f":"code","b2cfae9f":"code","ee17dffa":"code","c7ce4467":"code","7ea4bb3f":"code","2db8ec17":"code","ea3803c1":"code","6f37a9a9":"code","52b3ecf7":"code","b10fc7f1":"code","1a06869f":"code","f618bac6":"code","2030e75a":"code","3e0fdd93":"code","27d35645":"code","5ea2c469":"code","5f2e65d3":"code","08d4acb5":"code","9190122b":"code","269778fd":"markdown","55aa2761":"markdown","6e0099fe":"markdown","dc36ffa1":"markdown","a3abefc9":"markdown","2240a6a3":"markdown","4115f930":"markdown","266224fc":"markdown","38004043":"markdown","41b98849":"markdown","73f05325":"markdown","ee40e24d":"markdown","8a1c6337":"markdown","ff54cece":"markdown","cf8b36ae":"markdown","6b095bbb":"markdown","42f46f5a":"markdown","e829f941":"markdown","776aad7e":"markdown","a50e8eb4":"markdown","f0d162f1":"markdown","080259d0":"markdown","52765c2b":"markdown","8060609f":"markdown","01ab51b3":"markdown"},"source":{"85202b6e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler, Normalizer, QuantileTransformer\nimport seaborn as sns\nfrom sklearn import decomposition\nimport plotly.express as px\n\ndata = pd.read_csv(\"\/kaggle\/input\/wholesale-customers-data-set\/Wholesale customers data.csv\")\ndata.head()","eb4c6a33":"regions = pd.DataFrame(data['Region'].value_counts().T)\nregions.rename(index={1:'Lisbon',2:'Oporto',3:'Other'},inplace=True)\nprint('Region Bar Plot')\nregions.T.plot.bar()","d463a180":"df=data.drop(['Region'],axis=1)","37297824":"plt.figure(figsize=(16, 6))\nsns.boxplot(data=df)","d9d64a94":"df.drop(df.index[(df['Fresh']==112151) | (df['Milk']==73498) | (df['Grocery']==92780) | (df['Frozen']==60869) | (df['Delicassen']==47943)],inplace=True)","4704a8c7":"dfSTD=pd.DataFrame(StandardScaler().fit_transform(df))\npca = decomposition.PCA(n_components=3)\n\n### Numpy 1.19.5 produces non-convergance random error on first pass, so retry if necessary ###\nwhile True: \n    try: \n        XSTD = pca.fit_transform(dfSTD) \n        break \n    except: \n        continue\nprint(\"Explained Variance ratio:\",pca.explained_variance_ratio_)\nXSTD.shape","ce6d1342":"fig = px.scatter_3d(x=XSTD[:, 0], y=XSTD[:, 1], z=XSTD[:, 2], width=1200, height=900)\nfig.show()","ef47865a":"channels = pd.DataFrame(data['Channel'].value_counts().T)\nchannels.rename(index={1:'HoReCa',2:'Retail'},inplace=True)\nprint('Channels Bar Plot')\nchannels.T.plot.bar()","94c4a4b3":"# Divide Retail from HoReCa and try to divide HoReCa in Hotel, Restaurant and Caf\u00e9\ndfHoReCa = df[df['Channel']==1].drop(['Channel'],axis=1)\ndfRetail = df[df['Channel']==2].drop(['Channel'],axis=1)\n\n# Plot both groups to visualize the difference\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(25, 10))\nax1.set_title('Hotels \/ Restaurants \/ Caf\u00e9s')\nax2.set_title('Retail')\nsns.boxplot(data=dfHoReCa, ax=ax1)\nsns.boxplot(data=dfRetail, ax=ax2)","8d76f3b6":"# dfcolumns = dfHoReCa.columns\n# ### Use QuantileTransformer if we want to force it to suggest a k=3 elbow ###\n# dfHoReCa=pd.DataFrame(QuantileTransformer().fit_transform(dfHoReCa))\n# dfHoReCa.columns = dfcolumns","d51e682f":"distortions = []\nK = range(1,10)\nfor k in K:\n    model = KMeans(n_clusters=k)\n    model.fit(dfHoReCa)\n    distortions.append(model.inertia_)\nprint(distortions)\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('Elbows')\nplt.show()","43d4142c":"kmeans = KMeans(n_clusters=3,max_iter=1000,random_state=42)\nkmeans.fit(dfHoReCa)\npredict = kmeans.predict(dfHoReCa)\ncentroids = kmeans.cluster_centers_\nprint(centroids)\n","f11459ff":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(25, 10))\nax1.set_title('Totals')\nax2.set_title('Percentages')\n\ngroups = pd.DataFrame({'Group 1: Restaurants?':centroids[0],'Group 2: Caf\u00e9s?':centroids[1],'Group 3: Hotels?':centroids[2]},index=dfHoReCa.columns).T\nstacked_data = groups\nstacked_data.plot.barh(stacked=False,ax=ax1)\ngroups = pd.DataFrame({'Group 1: Restaurants?':centroids[0],'Group 2: Caf\u00e9s?':centroids[1],'Group 3: Hotels?':centroids[2]},index=dfHoReCa.columns).T\nstacked_data2 = groups.apply(lambda x: x*100\/sum(x), axis=1)\nstacked_data2.plot.barh(stacked=True,ax=ax2)","151e858f":"fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(25, 10))\nax1.set_title('Group 1: Restaurants?')\nax2.set_title('Group 2: Caf\u00e9s?')\nax3.set_title('Group 3: Hotels?')\ndata = dfHoReCa.copy()\ndata['predict'] = predict\nsns.boxplot(data=data[data['predict']==0], ax=ax1)\nsns.boxplot(data=data[data['predict']==1], ax=ax2)\nsns.boxplot(data=data[data['predict']==2], ax=ax3)","b2cfae9f":"#dfHoReCa=pd.DataFrame(StandardScaler().fit_transform(dfHoReCa))\npca = decomposition.PCA(n_components=3)\n\n### Numpy 1.19.5 produces non-convergance random error on first pass, so retry if necessary ###\nwhile True: \n    try: \n        XHoReCa = pca.fit_transform(dfHoReCa) \n        break \n    except: \n        continue\nprint(\"Explained Variance ratio:\",pca.explained_variance_ratio_)\nXHoReCa.shape","ee17dffa":"fig = px.scatter_3d(x=XHoReCa[:, 0], y=XHoReCa[:, 1], z=XHoReCa[:, 2], color=predict,width=1200, height=900)\nfig.show()","c7ce4467":"dfcolumns = dfRetail.columns\ndfRetail=pd.DataFrame(PowerTransformer().fit_transform(dfRetail))\ndfRetail=pd.DataFrame(MinMaxScaler().fit_transform(dfRetail))\ndfRetail.columns = dfcolumns","7ea4bb3f":"distortions = []\nK = range(1,10)\nfor k in K:\n    model = KMeans(n_clusters=k)\n    model.fit(dfRetail)\n    distortions.append(model.inertia_)\nprint(distortions)\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('Elbows')\nplt.show()","2db8ec17":"kmeans = KMeans(n_clusters=2,max_iter=1000,random_state=42)\nkmeans.fit(dfRetail)\npredict = kmeans.predict(dfRetail)\ncentroids = kmeans.cluster_centers_\nprint(centroids)","ea3803c1":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(25, 10))\nax1.set_title('Totals')\nax2.set_title('Percentages')\n\ngroups = pd.DataFrame({'Group 1':centroids[0],'Group 2':centroids[1]},index=dfRetail.columns).T\nstacked_data = groups\nstacked_data.plot.barh(stacked=False,ax=ax1)\ngroups = pd.DataFrame({'Group 1':centroids[0],'Group 2':centroids[1]},index=dfRetail.columns).T\nstacked_data2 = groups.apply(lambda x: x*100\/sum(x), axis=1)\nstacked_data2.plot.barh(stacked=True,ax=ax2)","6f37a9a9":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(25, 10))\nax1.set_title('Group 1')\nax2.set_title('Group 2')\ndata = dfRetail.copy()\ndata['predict'] = predict\nsns.boxplot(data=data[data['predict']==0], ax=ax1)\nsns.boxplot(data=data[data['predict']==1], ax=ax2)","52b3ecf7":"#dfRetail=pd.DataFrame(StandardScaler().fit_transform(dfRetail))\npca = decomposition.PCA(n_components=3)\n\n### Numpy 1.19.5 produces non-convergance random error on first pass, so retry if necessary ###\nwhile True: \n    try: \n        XRetail = pca.fit_transform(dfRetail)\n        break \n    except: \n        continue\nprint(\"Explained Variance ratio:\",pca.explained_variance_ratio_)\nXRetail.shape","b10fc7f1":"fig = px.scatter_3d(x=XRetail[:, 0], y=XRetail[:, 1],z=XRetail[:, 2], color=predict,width=1200, height=900)\nfig.show()","1a06869f":"df.drop(['Channel'],axis=1, inplace=True)","f618bac6":"# dfcolumns = df.columns\n# # df=pd.DataFrame(StandardScaler().fit_transform(df))\n# df=pd.DataFrame(MinMaxScaler().fit_transform(df))\n# df.columns = dfcolumns","2030e75a":"distortions = []\nK = range(1,10)\nfor k in K:\n    model = KMeans(n_clusters=k)\n    model.fit(df)\n    distortions.append(model.inertia_)\nprint(distortions)\nplt.plot(K, distortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Distortion')\nplt.title('Elbows')\nplt.show()","3e0fdd93":"kmeans = KMeans(n_clusters=3,max_iter=1000,random_state=42)\nkmeans.fit(df)\npredict = kmeans.predict(df)\ncentroids = kmeans.cluster_centers_\nprint(centroids)","27d35645":"fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,figsize=(25, 10))\nax1.set_title('Totals')\nax2.set_title('Percentages')\n\ngroups = pd.DataFrame({'Group 1: Big Fresh':centroids[0],'Group 2: Small Balanced':centroids[1],'Group 3: Milk\/Groceries':centroids[2]},index=df.columns).T\nstacked_data = groups\nstacked_data.plot.barh(stacked=False,ax=ax1)\ngroups = pd.DataFrame({'Group 1: Big Fresh':centroids[0],'Group 2: Small Balanced':centroids[1],'Group 3: Milk\/Groceries':centroids[2]},index=df.columns).T\nstacked_data2 = groups.apply(lambda x: x*100\/sum(x), axis=1)\nstacked_data2.plot.barh(stacked=True,ax=ax2)","5ea2c469":"fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(25, 10))\nax1.set_title('Group 1: Big Fresh')\nax2.set_title('Group 2: Small Balanced')\nax3.set_title('Group 3: Milk\/Groceries')\ndata = df.copy()\ndata['predict'] = predict\nsns.boxplot(data=data[data['predict']==0], ax=ax1)\nsns.boxplot(data=data[data['predict']==1], ax=ax2)\nsns.boxplot(data=data[data['predict']==2], ax=ax3)","5f2e65d3":"#df=pd.DataFrame(StandardScaler().fit_transform(df))\npca = decomposition.PCA(n_components=3)\n\n### Numpy 1.19.5 produces non-convergance random error on first pass, so retry if necessary ###\nwhile True: \n    try: \n        XFull = pca.fit_transform(df)\n        break \n    except: \n        continue\nprint(\"Explained Variance ratio:\",pca.explained_variance_ratio_)\nXFull.shape","08d4acb5":"fig = px.scatter_3d(x=XFull[:, 0], y=XFull[:, 1],z=XFull[:, 2], color=predict,width=1200, height=900)\nfig.show()","9190122b":"# import sys\n# np.set_printoptions(threshold=sys.maxsize)\n# print(XFull)","269778fd":"## PCA (Full Dataset)","55aa2761":"## Visualize Retail Clusters","6e0099fe":"# \"Full Dataset\" Analysis and Clustering","dc36ffa1":"## Look for obvious outliers","a3abefc9":"## Disregard the clearly suggested k=3 Elbow, and use Elbow k=2 since this is a channels subset with very few samples","2240a6a3":"## Visualize HoReCa Clusters","4115f930":"# First divide by channel and visualize product mix differences","266224fc":"## Disregard the suggested k=2 Elbow, and use k=3 in order to *try* to classify into Hotels vs Restaurants vs Caf\u00e9s","38004043":"## Bar Chart with Totals and Percentages (Full Dataset)","41b98849":"## Alternative view with boxplots (Full Dataset)","73f05325":"## Visualize Full dataset clusters","ee40e24d":"## PCA (Retail)","8a1c6337":"## Simply drop region because it's very incomplete. It has a lot of \"others\"","ff54cece":"## Alternative view with boxplots (Retail Channel)","cf8b36ae":"## Look at \"Region\" categorical composition","6b095bbb":"# \"Retail Channel\" Analysis and Clustering","42f46f5a":"## PCA (HoReCa)","e829f941":"## Calculate a PCA on the full stardardized data, and look for obvious clusters","776aad7e":"## Look at \"Channel\" categorical composition","a50e8eb4":"## Bar Chart with Totals and Percentages (HoReCa Channel)","f0d162f1":"## Use the suggested k=3","080259d0":"## Bar Chart with Totals and Percentages (Retail Channel)","52765c2b":"## Alternative view with boxplots (HoReCa Channel)","8060609f":"# \"HoReCa Channel\" Analysis and Clustering","01ab51b3":"## Drop obvious outliers"}}