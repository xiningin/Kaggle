{"cell_type":{"7bd1c6be":"code","ae14f0de":"code","329ee462":"code","840c0851":"code","11171283":"code","8c460b0c":"code","9922c020":"code","39ef3dd4":"code","b5a90fba":"code","4e30b4bf":"code","ec91d9bd":"code","f34d31f4":"code","bef33bf6":"code","2189fbe2":"code","648a6ba6":"code","c9adf03c":"code","4e3ee32a":"code","51bef0d9":"code","08db1e3b":"code","33af8835":"code","4bc0ba12":"code","439d5f65":"code","43fbad65":"code","79862ac6":"code","778dda4f":"code","5b50db45":"code","f989a799":"code","a7cafde6":"code","ffd2df15":"code","e86172a8":"code","c0bb174e":"code","0e233d0b":"code","cbb84e70":"code","87d69386":"code","8e91c541":"code","ad91ed27":"code","e9ea6969":"code","6ca0f220":"code","c9f83fff":"code","a4f4917d":"code","781d7a5f":"code","fc89ba63":"code","0d8aba0c":"code","b7c6bc6d":"code","45bc931d":"code","d9f7055e":"code","7ed61aec":"code","ca4230c7":"code","a8db0668":"code","26c8f19b":"code","02facb79":"markdown","894dabc7":"markdown","cefd680e":"markdown"},"source":{"7bd1c6be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae14f0de":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","329ee462":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntest_data.head()","840c0851":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","11171283":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","8c460b0c":"train_data.isnull().mean()","9922c020":"test_data.isnull().mean()","39ef3dd4":"train_data.nunique()","b5a90fba":"\ntest_data.nunique()","4e30b4bf":"train_data.info()","ec91d9bd":"#The target variable is not too unbalanced\ntrain_data.Survived.value_counts()","f34d31f4":"train_data.describe()\n","bef33bf6":"#Let's have a comparisono with the training data\ntest_data.describe()","2189fbe2":"train_data.describe(include=\"all\").transpose()","648a6ba6":"train_data.corr()","c9adf03c":"train_data.groupby(\"Pclass\")[\"Survived\"].mean()","4e3ee32a":"print(train_data.SibSp.value_counts())\ntrain_data.groupby(\"SibSp\")[\"Survived\"].mean()","51bef0d9":"print(train_data.Parch.value_counts())\ntrain_data.groupby(\"Parch\")[\"Survived\"].mean()","08db1e3b":"print(train_data.groupby(\"Survived\")[\"Fare\"].mean())\nprint(train_data.groupby(\"Survived\")[\"Fare\"].std())","33af8835":"pd.crosstab(train_data[\"Embarked\"],train_data[\"Survived\"])","4bc0ba12":"print(train_data.groupby(\"Embarked\")[\"Survived\"].mean())\n","439d5f65":"numeric= [ 'Survived', 'Pclass', 'Age', 'SibSp',\n       'Parch', 'Fare']\n\nfor i in numeric:\n    plt.hist(train_data[i])\n    print(i)\n    plt.show()","43fbad65":"sns.pairplot(train_data)","79862ac6":"train_data.Cabin=train_data.Cabin.fillna(\"Missing\")\ntrain_data.Cabin","778dda4f":"test_data.Cabin=test_data.Cabin.fillna(\"Missing\")\ntest_data.Cabin","5b50db45":"def desk (string):\n    prima=string[0]\n    return prima\n","f989a799":"train_data[\"deck\"]=train_data[\"Cabin\"].apply(desk)\ntrain_data[\"deck\"]","a7cafde6":"test_data[\"deck\"]=test_data[\"Cabin\"].apply(desk)\ntest_data[\"deck\"]","ffd2df15":"pd.crosstab(train_data[\"deck\"],train_data[\"Survived\"])","e86172a8":"train_data.groupby(\"deck\")[\"Survived\"].mean()","c0bb174e":"def ponte (string):\n    if string==\"M\":\n        return 0\n    else:\n        return 1\n    \ntrain_data[\"Ponte\"]=train_data.deck.apply(ponte)\ntrain_data.Ponte","0e233d0b":"test_data[\"Ponte\"]=test_data.deck.apply(ponte)\ntest_data.Ponte","cbb84e70":"sub_train_data=train_data[[\"Pclass\",\"Sex\", \"SibSp\",\"Age\",\"Fare\", \"Survived\",\"Parch\",\"Embarked\",\"Cabin\",\"Ponte\"]]\nsub_train_data.head()","87d69386":"sub_train_data=sub_train_data.fillna(sub_train_data.Age.median())\nsub_train_data.isnull().mean()","8e91c541":"sub_test_data=test_data[[\"Pclass\",\"Sex\", \"SibSp\",\"Age\",\"Fare\",\"Parch\",\"Embarked\",\"Ponte\"]]\nsub_test_data.head()","ad91ed27":"sub_test_data.isnull().mean()","e9ea6969":"sub_test_data.Fare=sub_test_data.Fare.fillna(sub_test_data.Fare.median())\nsub_test_data.isnull().mean()","6ca0f220":"sub_test_data.Age=sub_test_data.Age.fillna(sub_test_data.Age.median())\nsub_test_data.isnull().mean()","c9f83fff":"#We substitute the 2 outliers with the mode of the distribution\nsub_train_data.loc[61,\"Embarked\"]=\"C\"\nsub_train_data.loc[829,\"Embarked\"]=\"C\"","a4f4917d":"sub_train_data.Embarked.value_counts()","781d7a5f":"train_b=sub_train_data.copy()\ntrain_b","fc89ba63":"train_b[\"log_Fare\"]=np.log1p(train_b[\"Fare\"])\ntrain_b.skew()","0d8aba0c":"test_b=sub_test_data.copy()\ntest_b","b7c6bc6d":"test_b[\"log_Fare\"]=np.log1p(test_b[\"Fare\"])\ntest_b.skew()","45bc931d":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_b[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\",\"log_Fare\", \"Age\",\"Parch\",\"Embarked\",\"Ponte\"]\nX = pd.get_dummies(train_b[features])\nX_test = pd.get_dummies(test_b[features])\n[]\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","d9f7055e":"X=pd.get_dummies(sub_test_data,columns=[\"Sex\"])\nX\n                            ","7ed61aec":"X_test=pd.get_dummies(sub_test_data,columns=[\"Sex\"])\nX_test","ca4230c7":"X_test","a8db0668":"model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","26c8f19b":"final_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors)","02facb79":"We have null values in particular for this variables;\nAge,Fare and Cabin\nWe should try to impute them","894dabc7":"#the most of the variable are very skewed.. but someone is not quantitave\ntrain_data.skew()","cefd680e":"i have some variable with too much levels:\nPassengerId is not fundamental as Name for the prediction. Ticket doesn't seems particularly meaningful\n\n"}}