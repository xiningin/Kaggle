{"cell_type":{"4b4ee71f":"code","d0d162c7":"code","4c96312e":"code","3a110e8a":"code","e5b634a2":"code","158e8768":"code","c361eb59":"code","66fa0dc2":"code","af7e84a4":"code","977b32ed":"code","f7687ed8":"code","6bb7fe55":"code","eecc0ea7":"code","e7b37d58":"code","67d403ca":"code","9b29c441":"code","e4dd86f5":"code","066eea4a":"code","980f70fd":"code","338621d2":"code","e7f58dc6":"code","e17bf77f":"code","a549c7ea":"code","e89dd36b":"code","a0dbf196":"code","aae10338":"code","e3434406":"code","8f8f3b2a":"code","23ca7158":"code","429bbc84":"code","0a8cb65b":"code","12cfe2e9":"code","40715399":"code","fe92afc3":"code","6ebb2241":"code","b3ac70f9":"code","b266d561":"code","e448397a":"code","51edb785":"code","98f91d0c":"code","7f3eeb8f":"code","8776f5a4":"code","f49c5824":"code","aff0fc79":"code","610f372b":"code","c68cf8e6":"code","53214c3a":"code","ee51badd":"code","abe30bba":"code","688d6337":"code","10a16f15":"code","a4ce3a1d":"code","d533a090":"code","9a79f84f":"code","87399ce0":"code","e2d749a7":"code","8f01157a":"code","69bb4978":"code","0fc9ad9b":"code","53cd2bdc":"code","ba40bc88":"code","096f4353":"code","6759b945":"markdown","b50711cb":"markdown","0233634d":"markdown","8a553391":"markdown","b1b060eb":"markdown"},"source":{"4b4ee71f":"# Import Libraries for Data Preparation and Exploration & Visualization\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","d0d162c7":"#Import Train and Test Data\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndatasets = [train, test]","4c96312e":"#Explore Raw Train Data 1\ntrain.info()","3a110e8a":"#Explore Raw Train Data 2\ntrain.describe()","e5b634a2":"#Explore Raw Train Data 3\ntrain.describe(exclude=[np.number])","158e8768":"#Explore Raw Train Data 4\ntrain.sample(5)","c361eb59":"#Explore Raw Test Data 1\ntest.info()","66fa0dc2":"#Explore Raw Test Data 2\ntest.describe()","af7e84a4":"#Explore Raw Test Data 3\ntest.describe(exclude=[np.number])","977b32ed":"#Explore Raw Test Data 4\ntest.sample(5)","f7687ed8":"#Save 'PassengerId' of Test for the Prediction Submission and Drop 'PassengerId' and 'Ticket'\ntest_id = test[\"PassengerId\"]\n\ntrain = train.drop([\"PassengerId\", \"Ticket\"], axis=1)\ntest = test.drop([\"PassengerId\", \"Ticket\"], axis=1)","6bb7fe55":"#Transform 'Sex' to Numeric Data\ntrain[\"Sex\"] = train[\"Sex\"].map({\"female\": 1, \"male\": 0}).astype(int)\ntest[\"Sex\"] = test[\"Sex\"].map({\"female\": 1, \"male\": 0}).astype(int)","eecc0ea7":"#Check Missing 'Embarked'\ntrain[train[\"Embarked\"].isna()]","e7b37d58":"#Fill 'Embarked' with the Mode\nembarked_mode = train[\"Embarked\"].mode()[0]\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(embarked_mode)","67d403ca":"#Check Missing 'Fare'\ntest[test[\"Fare\"].isna()]","9b29c441":"#Fill 'Fare' with the Mean of the Same 'Pclass'\nfare_class_mean = test[test[\"Pclass\"] == 3][\"Fare\"].mean()\ntest[\"Fare\"] = test[\"Fare\"].fillna(fare_class_mean)","e4dd86f5":"#Fill 'Cabin' with 'XXX'\ntrain[\"Cabin\"] = train[\"Cabin\"].fillna(\"XXX\")\ntest[\"Cabin\"] = test[\"Cabin\"].fillna(\"XXX\")","066eea4a":"#Check Correlated Features with Age in Train\ntrain.corr().abs()[\"Age\"].sort_values(ascending=False)","980f70fd":"#Check Correlated Features with Age in Test\ntest.corr().abs()[\"Age\"].sort_values(ascending=False)","338621d2":"#Find Number of Missing 'Age' Values in both Train and Test\nprint(\"# of Null 'Age' in train set: {}\".format(train[\"Age\"].isna().sum()))\nprint(\"# of Null 'Age' in test set: {}\".format(test[\"Age\"].isna().sum()))","e7f58dc6":"#Find the Mean 'Age' of the Same Train 'Pclass'\nage_class_mean_train = train.groupby(by=[\"Pclass\"]).mean()[\"Age\"].round(0).astype(int)\nage_class_mean_train","e17bf77f":"#Fill 'Age' with the Mean of the Same Train 'Pclass'\nfor i in range(3):\n    train.loc[(train[\"Age\"].isnull()) & (train[\"Pclass\"] == i+1), \"Age\"] = age_class_mean_train.loc[i+1]","a549c7ea":"#Find the Mean 'Age' of the Same Test 'Pclass'\nage_class_mean_test = test.groupby(by=[\"Pclass\"]).mean()[\"Age\"].round(0).astype(int)\nage_class_mean_test","e89dd36b":"#Fill 'Age' with the Mean of the Same Train 'Pclass'\nfor i in range(3):\n    test.loc[(test[\"Age\"].isnull()) & (test[\"Pclass\"] == i+1), \"Age\"] = age_class_mean_test.loc[i+1]","a0dbf196":"#Check Number of Missing 'Age' Values in both Train and Test\nprint(\"# of Null 'Age' in train set: {}\".format(train[\"Age\"].isna().sum()))\nprint(\"# of Null 'Age' in test set: {}\".format(test[\"Age\"].isna().sum()))","aae10338":"#Visualize 'Sex' Feature\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train, ci=None)","e3434406":"#Visualize 'Pclass' Feature\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train, ci=None)","8f8f3b2a":"#Create 5 'Age' Interval\nlist(pd.cut(train['Age'], 5).unique().sort_values())","23ca7158":"#Make 'Age' Categorical\ntrain.loc[train[\"Age\"] <= 16, \"Age\"] = 0\ntrain.loc[(train[\"Age\"] > 16) & (train[\"Age\"] <= 32), \"Age\"] = 1\ntrain.loc[(train[\"Age\"] > 32) & (train[\"Age\"] <= 48), \"Age\"] = 2\ntrain.loc[(train[\"Age\"] > 48) & (train[\"Age\"] <= 64), \"Age\"] = 3\ntrain.loc[train[\"Age\"] > 64, \"Age\"] = 4\n\ntest.loc[test[\"Age\"] <= 16, \"Age\"] = 0\ntest.loc[(test[\"Age\"] > 16) & (test[\"Age\"] <= 32), \"Age\"] = 1\ntest.loc[(test[\"Age\"] > 32) & (test[\"Age\"] <= 48), \"Age\"] = 2\ntest.loc[(test[\"Age\"] > 48) & (test[\"Age\"] <= 64), \"Age\"] = 3\ntest.loc[train[\"Age\"] > 64, \"Age\"] = 4","429bbc84":"#Visualize 'Age' Feature\nsns.barplot(x=\"Age\", y=\"Survived\", data=train, ci=None)","0a8cb65b":"#Create 5 'Fare' Interval\nlist(pd.qcut(train[\"Fare\"], 4).unique().sort_values())","12cfe2e9":"#Make 'Fare' Categorical\ntrain.loc[train[\"Fare\"] <= 7.91, \"Fare\"] = 0\ntrain.loc[(train[\"Fare\"] > 7.91) & (train[\"Fare\"] <= 14.454), \"Fare\"] = 1\ntrain.loc[(train[\"Fare\"] > 14.454) & (train[\"Fare\"] <= 31), \"Fare\"] = 2\ntrain.loc[train[\"Fare\"] > 31, \"Fare\"] = 3\ntrain[\"Fare\"] = train[\"Fare\"].astype(int)\n\ntest.loc[test[\"Fare\"] <= 7.91, \"Fare\"] = 0\ntest.loc[(test[\"Fare\"] > 7.91) & (test[\"Fare\"] <= 14.454), \"Fare\"] = 1\ntest.loc[(test[\"Fare\"] > 14.454) & (test[\"Fare\"] <= 31), \"Fare\"] = 2\ntest.loc[test[\"Fare\"] > 31, \"Fare\"] = 3\ntest[\"Fare\"] = test[\"Fare\"].astype(int)","40715399":"#Visualize 'Fare' Feature\nsns.barplot(x=\"Fare\", y=\"Survived\", data=train, ci=None)","fe92afc3":"#Get The First Char of 'Cabin'\ntrain[\"Cabin\"] = train[\"Cabin\"].apply(lambda x: x[0])\n\ntest[\"Cabin\"] = test[\"Cabin\"].apply(lambda x: x[0])","6ebb2241":"#Visualize 'Cabin' Feature\nsns.barplot(x=\"Cabin\", y=\"Survived\", data=train, ci=None)","b3ac70f9":"#Craete 'Family' Feature that Represent Family Size\ntrain[\"Family\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n\ntest[\"Family\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","b266d561":"#Visualize 'Family' Feature 1\nsns.barplot(x=\"Family\", y=\"Survived\", data=train, ci=None)","e448397a":"#Create 3 'Family' Category\ntrain.loc[(train[\"Family\"] > 1) & (train[\"Family\"] <= 4), \"Family\"] = 2 \ntrain.loc[(train[\"Family\"] > 4), \"Family\"] = 3 \n\ntest.loc[(test[\"Family\"] > 1) & (test[\"Family\"] <= 4), \"Family\"] = 2 \ntest.loc[(test[\"Family\"] > 4), \"Family\"] = 3 ","51edb785":"#Drop 'SibSp' and 'Parch'\ntrain = train.drop([\"SibSp\", \"Parch\"], axis=1)\ntest = test.drop([\"SibSp\", \"Parch\"], axis=1)","98f91d0c":"#Visualize 'Family' Feature 2\nsns.barplot(x=\"Family\", y=\"Survived\", data=train, ci=None)","7f3eeb8f":"#Find 'Title'\ntrain[\"Title\"] = train[\"Name\"].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n\ntest[\"Title\"] = test[\"Name\"].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]","8776f5a4":"#Find Unique 'Title' in Train\ntrain.groupby(\"Title\")[\"Title\"].count()","f49c5824":"#Find Unique 'Title' in Test\ntest.groupby(\"Title\")[\"Title\"].count()","aff0fc79":"#Collect Rare Titles\ntrain[\"Title\"] = train[\"Title\"].replace([\"Lady\", \"Countess\",\"Capt\", \"Col\",\"Don\", \"Dr\", \"Major\", \"Rev\", \"Sir\", \"Jonkheer\", \"the Countess\"], \"Rare\")\ntrain[\"Title\"] = train[\"Title\"].replace(\"Mlle\", \"Miss\")\ntrain[\"Title\"] = train[\"Title\"].replace(\"Ms\", \"Miss\")\ntrain[\"Title\"] = train[\"Title\"].replace(\"Mme\", \"Mrs\")\n\ntest[\"Title\"] = test[\"Title\"].replace([\"Col\",\"Dona\", \"Dr\", \"Rev\"], \"Rare\")\ntest[\"Title\"] = test[\"Title\"].replace(\"Ms\", \"Miss\")\ntest[\"Title\"] = test[\"Title\"].replace(\"Mme\", \"Mrs\")","610f372b":"#Visualize 'Title' Feature\nsns.barplot(x=\"Title\", y=\"Survived\", data=train, ci=None)","c68cf8e6":"#Drop 'Name'\ntrain = train.drop([\"Name\"], axis=1)\n\ntest = test.drop([\"Name\"], axis=1)","53214c3a":"#Get Number of Train Sample\ntrain_set_lenght = len(train)\ntrain_set_lenght","ee51badd":"#Concatenate Train and Test Data to Create Dummy Variables\nall_data = pd.concat([train, test])\n\nall_data = pd.get_dummies(all_data)","abe30bba":"#Split Train and Test Data\ntrain = all_data.iloc[:891]\n\ntest = all_data.iloc[891:].drop(\"Survived\", axis=1)","688d6337":"#Final Train Data\nprint(train.shape)\ntrain.head()","10a16f15":"#Final Test Data\nprint(test.shape)\ntest.head()","a4ce3a1d":"# Import Libraries for Expetimentation & Prediction\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix","d533a090":"#Create Target Feature\nX = train.drop(\"Survived\",axis=1)\ny = train[\"Survived\"]","9a79f84f":"#Separate Train and Test Set \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)","87399ce0":"#Train the Linear Regression Model\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)","e2d749a7":"#Make Predictions\npredictions = dtree.predict(X_test)","8f01157a":"#Test results 1\nprint(classification_report(y_test,predictions))","69bb4978":"#Test results 2\nprint(confusion_matrix(y_test,predictions))","0fc9ad9b":"dtree = DecisionTreeClassifier()\ndtree.fit(train.drop(\"Survived\",axis=1), train[\"Survived\"])","53cd2bdc":"predictions = dtree.predict(test)","ba40bc88":"submission = pd.DataFrame()\nsubmission[\"PassengerId\"] = test_id\nsubmission[\"Survived\"] = predictions.astype(int)\nsubmission","096f4353":"submission.to_csv('submission.csv',index=False)","6759b945":"# Data Preparation and Exploration & Visualization","b50711cb":"# Expetimentation & Prediction","0233634d":"# Titanic Prediction\nBertan Imre","8a553391":"Submission","b1b060eb":"Possible Progress: \n<br>Complex Machine Learning Algorithms\n<br>Novel Feature Engineering\n<br>Comprehensive EDA \n\n<br>Reference Code:\n<br>https:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\n<br>https:\/\/www.kaggle.com\/arthurtok\/introduction-to-ensembling-stacking-in-python"}}