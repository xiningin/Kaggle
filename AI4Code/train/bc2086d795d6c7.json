{"cell_type":{"bebc71fc":"code","827ae86d":"code","1ef6a7e2":"code","e4034bff":"code","eb84ae69":"code","9df7cfeb":"code","c16e43dd":"code","a337684e":"code","f72eaea2":"code","ff876948":"code","97738362":"code","c679b07b":"code","d67d1b8c":"code","4fd70982":"code","1d7183aa":"code","ccef0d4f":"code","e9ca155c":"code","02617835":"code","9eb90fc2":"code","2da27043":"code","913df60f":"code","2575e349":"code","7d258bb7":"code","fb01db7f":"code","7893b35c":"code","94b013c7":"code","8f0d3286":"markdown","6a4c4f39":"markdown","5c4f2e95":"markdown","6fa07e1b":"markdown","bf84c93a":"markdown","342dfd2c":"markdown"},"source":{"bebc71fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","827ae86d":"!pip install -q tf-nightly\n","1ef6a7e2":"import numpy as np\nimport os\nimport PIL\nimport PIL.Image\nimport tensorflow as tf\nprint(tf.__version__)","e4034bff":"! cp -R ..\/input\/recipes .\/myrecipes\n","eb84ae69":"import pathlib\ndata_dir = '.\/myrecipes'\ndata_dir = pathlib.Path(data_dir)\nimg_list = list(data_dir.glob('*\/*.*'))\nimage_count = len(img_list)\nprint(image_count)","9df7cfeb":"img_list[0]\n","c16e43dd":"import os.path\n\nimg_ext = dict()\nfor img in img_list:\n    extension = os.path.splitext(str(img))[1]\n    img_ext[extension] = img_ext.get(extension, 0) + 1\nimg_ext","a337684e":"import os\n\nnum_skipped = 0\n\nfor folder_name in ['briyani', 'burger', 'dosa', 'idly', 'pizza']:\n    folder_path = os.path.join(\".\/myrecipes\/\", folder_name)\n    for fname in os.listdir(folder_path):\n        fpath = os.path.join(folder_path, fname)\n        try:\n            fobj = open(fpath, \"rb\")\n            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n        finally:\n            fobj.close()\n\n        if not is_jfif:\n            num_skipped += 1\n            # Delete corrupted image\n            os.remove(fpath)\n\nprint(\"Deleted %d images\" % num_skipped)","f72eaea2":"import os.path\ndata_dir = '.\/myrecipes'\ndata_dir = pathlib.Path(data_dir)\nimg_list = list(data_dir.glob('*\/*.*'))\nimage_count = len(img_list)\nprint(image_count)\nimg_ext = dict()\nfor img in img_list:\n    extension = os.path.splitext(str(img))[1]\n    img_ext[extension] = img_ext.get(extension, 0) + 1\nprint(img_ext)","ff876948":"batch_size = 32\nimg_height = 250\nimg_width = 250\nimage_size = img_height, img_width","97738362":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    '.\/myrecipes\/',\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size=image_size,\n    batch_size=batch_size,\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    '.\/myrecipes\/',\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=image_size,\n    batch_size=batch_size,\n)","c679b07b":"class_names = train_ds.class_names\n","d67d1b8c":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(16, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[int(labels[i])])\n        plt.axis(\"off\")","4fd70982":"for image_batch, labels_batch in train_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","1d7183aa":"import numpy as np\n\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input, decode_predictions\n\nfrom tensorflow.python.keras.preprocessing import image","ccef0d4f":"from keras.preprocessing.image import ImageDataGenerator\n","e9ca155c":"\nbatch_size=163\n\n\n#Create training data generator\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        width_shift_range=0.1,\n        height_shift_range=0.1) ","02617835":"train_generator = train_datagen.flow_from_directory(\n        '.\/myrecipes\/', #directory that contains training data\n        target_size=(150, 150), #what size image we want\n        batch_size=batch_size, #how many files to read in at a time\n        class_mode=\"categorical\")","9eb90fc2":"from tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPool2D","2da27043":"model = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(250,250,3), activation='relu',padding = 'same'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(filters=64, kernel_size=(4,4), activation='relu',padding = 'same'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(4,4), activation='relu',padding = 'same'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(4,4), activation='relu',padding = 'same'))\nmodel.add(MaxPool2D(pool_size=(2, 2))) \n\nmodel.add(Conv2D(filters=128, kernel_size=(4,4), activation='relu',padding = 'same'))\nmodel.add(MaxPool2D(pool_size=(2, 2))) \n\ntf.keras.layers.Dropout(0.2),\n\nmodel.add(Flatten())\n\n\nmodel.add(Dense(256, activation='relu'))\n\nmodel.add(Dense(len(class_names), activation='softmax'))\n","913df60f":"model.summary()\n","2575e349":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","7d258bb7":"train_ds = train_ds.prefetch(buffer_size=32)\nval_ds = val_ds.prefetch(buffer_size=32)","fb01db7f":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","7893b35c":"from tensorflow.keras.callbacks import EarlyStopping ","94b013c7":"epochs = 100\n\nmodel_cp = keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\")\nearlystop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\n\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nhistory = model.fit(\n    train_ds, epochs=epochs, callbacks=[model_cp, earlystop], validation_data=val_ds\n)","8f0d3286":"# Image size","6a4c4f39":"# Pre-Trained Model","5c4f2e95":"# Explore images","6fa07e1b":"# Data Preparation","bf84c93a":"# Delete corrupted image","342dfd2c":"# Read Data"}}