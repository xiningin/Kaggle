{"cell_type":{"6910df8d":"code","d57c1db0":"code","0483b431":"code","3097f19e":"code","7baea663":"code","ba986640":"code","6204a060":"code","b1b8a7da":"code","72ce9255":"code","344c41bc":"code","d5b31962":"code","a99f2d94":"code","393190de":"code","dfd39480":"code","ac8892f3":"code","e12dccd5":"code","85800b91":"code","ef6ad091":"code","5ce393b3":"code","f8c42e4c":"code","1424390a":"code","973b5289":"markdown","d318fd9c":"markdown","471eaf43":"markdown","5af18464":"markdown","b0bd8048":"markdown","0871f13b":"markdown","8f1b4cdb":"markdown","ae4b2b0f":"markdown","f2815867":"markdown","9ae03b31":"markdown","e5bf45b9":"markdown","1751c840":"markdown","d244b579":"markdown","f8ecc894":"markdown","837f3faa":"markdown","541081a6":"markdown","beb04785":"markdown","b14a8fd1":"markdown"},"source":{"6910df8d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d57c1db0":"data = pd.read_csv(\"..\/input\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/test.csv\")\ndata.head()\n\n#Submission Data\ntest_data.head()","0483b431":"fig = plt.figure(figsize = (30,20))\nax = fig.gca()\nhist = data.hist(ax=ax)","3097f19e":"data.describe()","7baea663":"data['Cabin'].head() #Too much missing data to augment with the mean","ba986640":"#replace male female with 1 and 0\ndata['Sex'] = data['Sex'].map({'female': 1, 'male': 0}) \n#fill in missing data in age\ndata['Age'].fillna(data['Age'].mean(), inplace=True)\n#fill in missing data in embarked\ndata['Embarked'].fillna( method ='ffill', inplace = True) \n#one hot encode embarked\none_hot_columns = pd.get_dummies(data['Embarked'],prefix=None)\n# use pd.concat to join the new columns with your original dataframe\ndata = pd.concat([data,one_hot_columns],axis=1)\n# now drop the original 'country' column (you don't need it anymore)\ndata.drop(['Embarked'],axis=1, inplace=True)\n\n# Convert ticket to integer\nimport re\n\ndef ticket_to_float(ticket_str):\n    ticket_numbers_only = ''.join(i for i in ticket_str if i.isdigit())\n    if ticket_numbers_only is '':\n        return 0\n    return int(ticket_numbers_only)\n\ndata['Ticket'] = data['Ticket'].apply(ticket_to_float)\n\n#Submission Data\n\n#replace male female with 1 and 0\ntest_data['Sex'] = test_data['Sex'].map({'female': 1, 'male': 0}) \n#fill in missing data in age\ntest_data['Age'].fillna(test_data['Age'].mean(), inplace=True)\n#fill in missing data in fare\ntest_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)\n#fill in missing data in embarked\ntest_data['Embarked'].fillna( method ='ffill', inplace = True) \n#one hot encode embarked\none_hot_columns = pd.get_dummies(test_data['Embarked'],prefix=None)\n# use pd.concat to join the new columns with your original dataframe\ntest_data = pd.concat([test_data,one_hot_columns],axis=1)\n# now drop the original 'country' column (you don't need it anymore)\ntest_data.drop(['Embarked'],axis=1, inplace=True)\n# Convert ticket to integer\ntest_data['Ticket'] = test_data['Ticket'].apply(ticket_to_float)\n\ndata.head()","6204a060":"if data['Survived'].isnull().values.any():\n    print(\"Missing Values Survived\")\nif data['Pclass'].isnull().values.any():\n    print(\"Missing Values Pclass\")\nif data['Sex'].isnull().values.any():\n    print(\"Missing Values Sex\")\nif data['Age'].isnull().values.any():\n    print(\"Missing Values Age\")\nif data['SibSp'].isnull().values.any():\n    print(\"Missing Values SibSp\")\nif data['Parch'].isnull().values.any():\n    print(\"Missing Values Parch\")\nif data['Fare'].isnull().values.any():\n    print(\"Missing Values Fare\")\n    \n#Submission Data\nif test_data['Pclass'].isnull().values.any():\n    print(\"Missing Values Pclass\")\nif test_data['Sex'].isnull().values.any():\n    print(\"Missing Values Sex\")\nif test_data['Age'].isnull().values.any():\n    print(\"Missing Values Age\")\nif test_data['SibSp'].isnull().values.any():\n    print(\"Missing Values SibSp\")\nif test_data['Parch'].isnull().values.any():\n    print(\"Missing Values Parch\")\nif test_data['Fare'].isnull().values.any():\n    print(\"Missing Values Fare\")","b1b8a7da":"feature_columns = [\n    'Pclass',\n    'Sex',\n    'Age',\n    'SibSp',\n    'Parch',\n    'Fare',\n    'C',\n    'Q',\n    'S'\n]\n\ndata[feature_columns].head()","72ce9255":"from sklearn import preprocessing\n\n#Training Data\nx = data[feature_columns].values \nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndata[feature_columns] = pd.DataFrame(x_scaled)\n\n#Submission Data\nx_test_data = test_data[feature_columns].values \nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled_test_data = min_max_scaler.fit_transform(x_test_data)\ntest_data[feature_columns] = pd.DataFrame(x_scaled_test_data)\n\nfig = plt.figure(figsize = (30,20))\nax = fig.gca()\nhist = test_data[feature_columns].hist(ax=ax)","344c41bc":"f = plt.figure(figsize=(19, 15))\nplt.matshow(data[feature_columns].corr(), fignum=f.number)\nplt.xticks(range(data[feature_columns].shape[1]), data[feature_columns].columns, fontsize=14, rotation=45)\nplt.yticks(range(data[feature_columns].shape[1]), data[feature_columns].columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\nplt.title('Correlation Matrix', fontsize=16);","d5b31962":"from sklearn.model_selection import train_test_split\n\nX = data[feature_columns]\ny = data['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=0)\n\nX_train.shape\n","a99f2d94":"from sklearn.linear_model import LogisticRegression \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Logistic Regression\nlog_reg = LogisticRegression(solver='sag', random_state=0)\nlog_reg.fit(X_train, y_train)\n\n# Neural Net\nn_net = MLPClassifier(hidden_layer_sizes=(4,4,4),max_iter=500)\nn_net.fit(X_train, y_train)\n\n# Support Vector Machine\nsvmC = svm.SVC(kernel='linear')\nsvmC.fit(X_train, y_train)\n\n# kNN\nk_NN = KNeighborsClassifier(n_neighbors=3)\nk_NN.fit(X_train, y_train)\n\n# Random Forest\nrfc=RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train, y_train)","393190de":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\nif y_test is not None:\n\n    y_pred_log_reg = log_reg.predict(X_test)\n\n    confusion_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n\n    sn.heatmap(confusion_matrix_log_reg, annot=True, cmap='Blues', fmt='g')\n\n    target_names = ['Survived', 'Not Survived']\n\n    print(classification_report(y_test, y_pred_log_reg, target_names=target_names))\n","dfd39480":"\nif y_test is not None:\n    y_pred_n_net = n_net.predict(X_test)\n\n    confusion_matrix_n_net = confusion_matrix(y_test, y_pred_n_net)\n\n    sn.heatmap(confusion_matrix_n_net, annot=True, cmap='Blues', fmt='g')\n\n    target_names = ['Survived', 'Not Survived']\n\n    print(classification_report(y_test, y_pred_n_net, target_names=target_names))\n\n    print(\"Accuracy:\",accuracy_score(y_test, y_pred_log_reg))","ac8892f3":"if y_test is not None:\n    y_pred_svm = svmC.predict(X_test)\n\n    confusion_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n\n    sn.heatmap(confusion_matrix_svm, annot=True, cmap='Blues', fmt='g')\n\n    target_names = ['Survived', 'Not Survived']\n\n    print(classification_report(y_test, y_pred_svm, target_names=target_names))","e12dccd5":"if y_test is not None:\n    y_pred_k_NN = k_NN.predict(X_test)\n\n    confusion_matrix_k_NN = confusion_matrix(y_test, y_pred_k_NN)\n\n    sn.heatmap(confusion_matrix_k_NN, annot=True, cmap='Blues', fmt='g')\n\n    target_names = ['Survived', 'Not Survived']\n\n    print(classification_report(y_test, y_pred_k_NN, target_names=target_names))","85800b91":"if y_test is not None:\n    y_pred_rfc = rfc.predict(X_test)\n\n    confusion_matrix_rfc = confusion_matrix(y_test, y_pred_rfc)\n\n    sn.heatmap(confusion_matrix_rfc, annot=True, cmap='Blues', fmt='g')\n\n    target_names = ['Survived', 'Not Survived']\n\n    print(classification_report(y_test, y_pred_rfc, target_names=target_names))","ef6ad091":"if y_test is not None:\n    print(\"Accuracy Logistic Regression:\",accuracy_score(y_test, y_pred_log_reg))\n    print(\"Accuracy Neural Net:\",accuracy_score(y_test, y_pred_n_net))\n    print(\"Accuracy Support Vector Machine:\",accuracy_score(y_test, y_pred_svm))\n    print(\"Accuracy kNN:\",accuracy_score(y_test, y_pred_k_NN))\n    print(\"Accuracy Random Forest:\",accuracy_score(y_test, y_pred_rfc))","5ce393b3":"X_train=data[feature_columns + [\"PassengerId\"]]\nX_test=test_data[feature_columns  + [\"PassengerId\"]]\ny_train=data['Survived']\ny_test=None\n\nid_nr = X_test[\"PassengerId\"]\nX_train = X_train.drop(columns=[\"PassengerId\"])\nX_test = X_test.drop(columns=[\"PassengerId\"])","f8c42e4c":"import csv\n\n# Random Forest\nrfc=RandomForestClassifier(n_estimators=100)\nrfc.fit(X_train, y_train)\n\nsb = rfc.predict(X_test)\n\nsubmission = pd.DataFrame({\n    'PassengerId':id_nr,\n    'Survived':sb\n})\n\nsubmission.head()","1424390a":"submission.to_csv('csv_to_submit.csv', index = False)","973b5289":"Export CSV","d318fd9c":"**Check Accuracy**","471eaf43":"**Split the data**","5af18464":"Use test data and full training data","b0bd8048":"Random Forest","0871f13b":"**Clean up data**","8f1b4cdb":"**Visualise Correlation**","ae4b2b0f":"K Nearest Neighbours","f2815867":"**Summary**","9ae03b31":"Logistic Regression","e5bf45b9":"**Train the model**","1751c840":"**Look at the data**","d244b579":"Support Vector Machine","f8ecc894":"Neural Net","837f3faa":"**Normalise**","541081a6":"**Generate Competition Data**","beb04785":"**Select Features**","b14a8fd1":"Final Calculation for competition"}}