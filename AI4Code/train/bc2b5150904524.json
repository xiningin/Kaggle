{"cell_type":{"258d2b32":"code","5ce192a5":"code","33160ef4":"code","4bc8306a":"code","6ff3e0db":"code","93fa4993":"code","a845f52a":"code","f189fef3":"code","7d8b8917":"code","deaa54dc":"code","8c78049f":"code","87648953":"code","54155603":"code","a99e361e":"code","1fc459f9":"markdown","b8269886":"markdown","6d090f4e":"markdown","e4a92f59":"markdown","4eb8011e":"markdown","406cdd76":"markdown","ad9f1919":"markdown","e8f69abd":"markdown","ebc68ede":"markdown"},"source":{"258d2b32":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nimport numpy as np\nimport matplotlib.pyplot as plt\n","5ce192a5":"imagepath = '..\/input\/animal-image-datasetdog-cat-and-panda\/images\/dog.jpg'\nimage = load_img(imagepath)\nplt.imshow(image)\nplt.show()","33160ef4":"image1 = img_to_array(image)\nimage2 = np.expand_dims(image,axis=0)\n","4bc8306a":"aug = ImageDataGenerator(rotation_range=0.2,horizontal_flip=True,vertical_flip=True,width_shift_range=0.1\n                        ,height_shift_range=0.1,fill_mode='nearest',zoom_range=0.2)\n","6ff3e0db":"plt.figure(figsize=(10,10))\n# load the image\nimg = load_img(imagepath)\n# convert to numpy array\ndata = img_to_array(img)\n# expand dimension to one sample\nsamples = np.expand_dims(data, 0)\n# create image data augmentation generator\ndatagen = ImageDataGenerator(rotation_range=0.2,horizontal_flip=True,vertical_flip=True,width_shift_range=0.1\n                        ,height_shift_range=0.1,fill_mode='nearest',zoom_range=0.2)\n# prepare iterator\nit = datagen.flow(samples, batch_size=1)\n# generate samples and plot\nfor i in range(9):\n    # define subplot\n    plt.subplot(330 + 1 + i)\n    # generate batch of images\n    batch = it.next()\n    # convert to unsigned integers for viewing\n    image = batch[0].astype('uint8')\n    # plot raw pixel data\n    plt.imshow(image)\n# show the figure\nplt.show()","93fa4993":"! pip install imutils","a845f52a":"import cv2\nimport os\nfrom imutils import paths\n## Defining model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (Conv2D,Activation,BatchNormalization,MaxPooling2D,Flatten,Dense,Dropout)\nfrom tensorflow.keras.optimizers import SGD\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n","f189fef3":"def imagesloder(imagepaths,width,height):\n    data=[]\n    labels=[]\n    for (i,images) in enumerate(imagepaths):\n        image = cv2.imread(images)\n        image = cv2.resize(image,(height,width),interpolation=cv2.INTER_AREA)\n        image = img_to_array(image)\n        # image = np.expand_dims(image,axis=0)\n        label = int(images.split(os.path.sep)[-2])\n        data.append(image)\n        labels.append(label)\n    return np.array(data,dtype='float')\/255.0,np.array(labels)\n\n\ndef minivgg(width,height,depth,classes):\n    input_shape=(height,width,depth)\n    ch_dim = -1\n    model= Sequential()\n    model.add(Conv2D(32,(3,3),padding='same',input_shape=input_shape))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=ch_dim))\n\n    model.add(Conv2D(64,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=ch_dim))\n\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(32,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=ch_dim))\n\n    model.add(Conv2D(64,(3,3),padding='same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=ch_dim))\n\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Activation('relu'))\n    model.add(BatchNormalization(axis=ch_dim))\n\n    model.add(Flatten())\n    model.add(Dense(512))\n\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(classes))\n    model.add(Activation('softmax'))\n\n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    return model\n\n\n","7d8b8917":"# config file\nflower_dataset_path = '..\/input\/flowers17\/17flowers\/jpg'\nepochs = 100\nbatch_size = 32\n","deaa54dc":"\nflowerimagepaths = list(paths.list_images(flower_dataset_path))\n    \ndata,labels=imagesloder(flowerimagepaths,64,64)\n\ntrain_X,test_X,train_y,test_y = train_test_split(data,labels,test_size=0.2,random_state=41)\n\nmodel=minivgg(64,64,3,17)\n\nmodel.summary()","8c78049f":"H = model.fit(train_X,train_y,validation_data=(test_X,test_y),\n              batch_size=batch_size,epochs=epochs,steps_per_epoch=len(train_X) \/\/ 32)","87648953":"plt.figure(figsize=(10,8))\nplt.plot(np.arange(0,epochs),H.history['accuracy'],label='Training_accuracy')\nplt.plot(np.arange(0,epochs),H.history['loss'],label='Training_loss')\nplt.plot(np.arange(0,epochs),H.history['val_accuracy'],label='Validation_accuracy')\nplt.plot(np.arange(0,epochs),H.history['val_loss'],label='validation_loss')\nplt.xlabel('#Epochs')\nplt.ylabel('Percentage')\nplt.legend()\nplt.title('Training accuracy and Loss plot')\nplt.show()","54155603":"aug = ImageDataGenerator(rotation_range=0.2,horizontal_flip=True,vertical_flip=True,width_shift_range=0.1\n                        ,height_shift_range=0.1,fill_mode='nearest',zoom_range=0.2)\nH = model.fit_generator(aug.flow(train_X, train_y, batch_size=32),\n                        validation_data=(test_X, test_y), steps_per_epoch=len(train_X) \/\/ 32,epochs=100, verbose=1)","a99e361e":"plt.figure(figsize=(10,8))\nplt.plot(np.arange(0,epochs),H.history['accuracy'],label='Training_accuracy')\nplt.plot(np.arange(0,epochs),H.history['loss'],label='Training_loss')\nplt.plot(np.arange(0,epochs),H.history['val_accuracy'],label='Validation_accuracy')\nplt.plot(np.arange(0,epochs),H.history['val_loss'],label='validation_loss')\nplt.xlabel('#Epochs')\nplt.ylabel('Percentage')\nplt.legend()\nplt.title('Training accuracy and Loss plot')\nplt.show()","1fc459f9":"Our goal when applying data augmentation is to increase the generalizability of the\nmodel. Given that our network is constantly seeing new, slightly modified versions of the input data\npoints, it\u2019s able to learn more robust features\n\n**Left:**\nA sample of 250 data points that follow a normal distribution exactly. \n**Right:**\nAdding a small amount of random \u201cjitter\u201d to the distribution. This type of data augmentation can\nincrease the generalizability of our networks.\n![image.png](attachment:image.png)\n","b8269886":"## What is Data Augmentation ?\n\n\"Data Augmentation is another type of regularization (or technique) used to create the more data from the existing data\".\n\n**For example:**\n\n\nIn the above diagram we have a picture of the dog(left side) which is our training image(one image).\n\nAnd the right side images are the data augmented images by using the single image we have created many images by applying different image tranformation like Rotation,Width_shifting,Height_shifting,Shearing,Vertical_flip,Horzontal_flip so on.. \nby doing so now we have many training samples from which we can provide the generalized information to the model to avoid overfitting. \n\n**NOTE**\n\nAt testing we *don not apply* data augmentation ","6d090f4e":"## Comparing Training With and Without Data Augmentation","e4a92f59":"\n## Flowers Dataset Training a model without data augmentation and visualizing results","4eb8011e":"## Visualizing the data augmentation in Tensorflow Keras lib","406cdd76":"## Flowers Dataset Training a model with data augmentation and visualing results","ad9f1919":"## Data Augmentation:\n\nIn this Experiment we will find out the importance of data augmentation.\n\nFirst will discuss about the Data augmentation and then will start training process without data augmentation and anaylse the result and next with the same training data now will induce the data augmentation and will train and  analyse the results \n\nNext,compare the results with and without the data augmentation.\n\n<div>\n    <img src='https:\/\/miro.medium.com\/max\/665\/1*MUOrB2-H5qkJop3Kl2oYmQ.png'>\n<\/div>\n\n## Content\n\n* What Is Data Augmentation?\n\n* Visualizing Data Augmentation\n\n* Flowers Dataset Training a model without data augmentation and visualizing results\n\n* Flowers Dataset Training a model with data augmentation and visualing results\n\n* Comparing Training With and Without Data Augmentation","e8f69abd":"## Graph without data augmentation\nObservations\n1. Clearly in the first graph without data augmentation we can see our model is overfitting and got saturated in between epochs 10-15 which is not a good sign for model training(we can tackle this in data augmentation)\n\n2. And there is much gap between the validation accuracy and Training accuracy which means our provided data features are not learned correctly\n\n## Graph with data Augmentation.\n\n1. After applying the data augmentation we can see a clear nice graph with less gap between the training accuracy and validation accuracy.\n\n2. We can see our model still can learn features from training data but the issue is with optimizer \n\n\n\n## Conclusion:\n\nWe were able to increase our validation accuracy, thereby\nimproving the generalizability of our model, despite having lowering training accuracy.\n\nWith data augmentation our model learned the different possible features which eventually help to increase the validation accuracy and decrease the validation loss which is a good sign in model training.\n\nWhile there is still overfitting occurring, the effect is significantly dampened by using data\naugmentation.\n\n\n\nWill imporve the model performance by applying the Learning rate scheduler and fine tunning in furthur notebook \n\nStay tunned for updates....\n\nPlease upvote if you like my notebook.\n\n\n","ebc68ede":"In the context of computer vision, data augmentation lends itself naturally. For example, we\ncan obtain additional training data from the original images by apply simple geometric transforms\nsuch as random:\n1. Translations\n2. Rotations\n3. Changes in scale\n4. Shearing\n5. Horizontal (and in some cases, vertical) flips\n"}}