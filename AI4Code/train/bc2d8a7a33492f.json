{"cell_type":{"2bb8d4e1":"code","41f527a7":"code","803e8c6c":"code","31e3f337":"code","e35df29e":"code","896e5e46":"code","38ba3af2":"code","7fe96664":"code","d9b2bb95":"code","66eb5379":"code","cdd795b6":"code","ba7ba7d8":"code","dacddab6":"code","af13b091":"code","8c7cc96b":"code","dab2f42e":"code","d596eff3":"code","6d69f09e":"markdown","697fbde7":"markdown","874bc9a4":"markdown","8b4fba49":"markdown","ccd8d47c":"markdown","55f5c488":"markdown","f73d6c3c":"markdown"},"source":{"2bb8d4e1":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold","41f527a7":"%%time\nte = pd.read_csv('..\/input\/widsdatathon2022\/test.csv')\ntr = pd.read_csv('..\/input\/widsdatathon2022\/train.csv')","803e8c6c":"tr['energy_star_rating'] = tr['energy_star_rating'].fillna(-1)\nte['energy_star_rating'] = te['energy_star_rating'].fillna(-1)\n\nfor col in ['State_Factor', 'building_class', 'facility_type']:\n    _map = {mod : i for i, mod in enumerate(tr[col].unique())}\n    tr[col] = tr[col].map(_map)\n    te[col] = te[col].map(_map)","31e3f337":"n_state = tr['State_Factor'].max() + 1\nn_building = tr['building_class'].max() + 1\nn_facility = tr['facility_type'].max() + 1\nprint(n_state, n_building, n_facility)","e35df29e":"tr['cluster'] = (tr['State_Factor'].astype(str) + '_' + tr['building_class'].astype(str)+ \n                 '-' + tr['facility_type'].astype(str) )","896e5e46":"tr.head()","38ba3af2":"CATS = ['State_Factor', 'building_class', 'facility_type']\nNUM = ['Year_Factor', 'floor_area', 'year_built', 'ELEVATION','january_min_temp', 'energy_star_rating', \n       'january_avg_temp','january_max_temp', 'february_min_temp', 'february_avg_temp',\n       'february_max_temp', 'march_min_temp', 'march_avg_temp','march_max_temp', 'april_min_temp', \n       'april_avg_temp', 'april_max_temp','may_min_temp', 'may_avg_temp', 'may_max_temp', 'june_min_temp',\n       'june_avg_temp', 'june_max_temp', 'july_min_temp', 'july_avg_temp',\n       'july_max_temp', 'august_min_temp','august_avg_temp', 'august_max_temp', 'september_min_temp',\n       'september_avg_temp', 'september_max_temp', 'october_min_temp',\n       'october_avg_temp', 'october_max_temp', 'november_min_temp',\n       'november_avg_temp','november_max_temp', 'december_min_temp', 'december_avg_temp',\n       'december_max_temp', 'cooling_degree_days', 'heating_degree_days',\n       'precipitation_inches', 'snowfall_inches', 'snowdepth_inches',\n       'avg_temp', 'days_below_30F', 'days_below_20F', 'days_below_10F', 'days_below_0F',\n       'days_above_80F', 'days_above_90F', 'days_above_100F',\n       'days_above_110F', 'direction_max_wind_speed',\n       'direction_peak_wind_speed','max_wind_speed', 'days_with_fog']\nOTH = ['id']\nTGT = 'site_eui'\nlen(NUM)","7fe96664":"from sklearn.preprocessing import MinMaxScaler","d9b2bb95":"for col in NUM:\n    _val = tr[col].median()\n    tr[col] = tr[col].fillna(_val)\n    te[col] = te[col].fillna(_val)","66eb5379":"scaler = MinMaxScaler()\ntr[NUM] = scaler.fit_transform(tr[NUM])\nte[NUM] = scaler.transform(te[NUM])","cdd795b6":"import tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\n\ndef make_model(n_in):\n    ACT = 'swish' #\n    \n    cont = L.Input(name=\"cont\", shape=(n_in,))\n    state =  L.Input(name=\"state\", shape=(1,))\n    building =  L.Input(name=\"building\", shape=(1,))\n    facility =  L.Input(name=\"facility\", shape=(1,))\n    \n    x1 = L.Dense(100, name=\"d1\", activation=ACT)(cont)\n    x2a = L.Embedding(n_state, n_state)(state)\n    x2b = L.Embedding(n_building, n_building)(building)\n    x2c = L.Embedding(n_facility, n_facility)(facility)\n    \n    x2 = L.Concatenate(name=\"concatenate\")([x2a, x2b, x2c])\n    x2 = L.Flatten(name=\"flatten\")(x2)\n    x_all = L.Concatenate(name=\"x_all\")([x1, x2])\n    \n    x = L.Dense(100, name=\"d2\", activation=ACT)(x_all)\n    x = L.Dense(100, name=\"d3\", activation=ACT)(x)\n    \n    preds = L.Dense(1, name=\"preds\", activation=\"linear\")(x)\n    \n    model = M.Model([cont, state, building, facility], preds, name=\"ANN\")\n    model.compile(loss='mean_squared_error', optimizer=\"Adam\", \n                  metrics=tf.keras.metrics.RootMeanSquaredError('rmse'))\n    return model\n\nnet = make_model(len(NUM))\nprint(net.summary())","ba7ba7d8":"%%time\n\nN_FOLDS = 5\nEPOCHS = 500\nkf = StratifiedKFold(n_splits=N_FOLDS, random_state=19901028, shuffle=True)\n\noof = np.zeros(tr.shape[0],)\npreds = 0.\nXe = te[NUM]\nXe_s = te['State_Factor']\nXe_b = te['building_class']\nXe_f = te['facility_type']\n\nprint(\"=\"*100)\nidx = 0\n\nfor tr_idx, te_idx in kf.split(tr[NUM], tr[\"cluster\"]):\n    idx += 1\n    print(\"FOLD:\", idx)\n    Xt = tr.iloc[tr_idx][NUM].values \n    yt = tr.iloc[tr_idx][TGT].values\n    Xt_s = tr.iloc[tr_idx]['State_Factor'].values\n    Xt_b = tr.iloc[tr_idx]['building_class'].values\n    Xt_f = tr.iloc[tr_idx]['facility_type'].values\n    \n    Xv = tr.iloc[te_idx][NUM].values \n    yv = tr.iloc[te_idx][TGT].values\n    Xv_s = tr.iloc[te_idx]['State_Factor'].values\n    Xv_b = tr.iloc[te_idx]['building_class'].values\n    Xv_f = tr.iloc[te_idx]['facility_type'].values\n    \n    net = make_model(len(NUM))\n    \n    ckpt = ModelCheckpoint(f\"w{idx}.h5\", monitor='val_loss', verbose=1, save_best_only=True,mode='min')\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=3, min_lr=0.0005)\n    es = EarlyStopping(monitor='val_loss', patience=18)\n    \n    net.fit([Xt, Xt_s, Xt_b, Xt_f], yt, epochs=EPOCHS, \n            validation_data=([Xv, Xv_s, Xv_b, Xv_f], yv), batch_size=512, \n            callbacks=[ckpt, reduce_lr, es])\n    \n    oof[te_idx] = net.predict([Xv, Xv_s, Xv_b, Xv_f])[:, 0]\n    preds += net.predict([Xe, Xe_s, Xe_b, Xe_f])[:, 0]\/ N_FOLDS\n    print(\"=\"*100)\n#=====================","dacddab6":"y = tr[TGT].values\nscore = mean_squared_error(y, oof, squared=False)\nprint(\"RMSE:\", score)","af13b091":"plt.plot(y[:100])\nplt.plot(oof[:100])","8c7cc96b":"sub = te[['id']].copy()\nsub[TGT] = preds","dab2f42e":"sub.head()","d596eff3":"sub.to_csv('submission.csv', index=False)","6d69f09e":"## Training & Prediction","697fbde7":"## LABEL ENCODING","874bc9a4":"## Missing Value Imputation","8b4fba49":"## MinMax Scaling","ccd8d47c":"## TENSORFLOW STUFFS","55f5c488":"## OVERVIEW\n\nIn this simple notebook, we use a simple neural network with tensorflow. This notebook can be used as a guideline for beginner. It encompasses many ingredients like\n* Label Encoding\n* Missing Value Imputations\n* TF Callbacks","f73d6c3c":"We make a cluster variable to use for our stratified folds"}}