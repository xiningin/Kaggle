{"cell_type":{"c8c25a59":"code","bd12741f":"code","95a6d083":"code","4867f1d2":"code","bb59f666":"code","8e2902c4":"code","d0072302":"code","c8dd72fa":"code","bde35109":"code","0cc22de4":"code","00de7ea4":"code","902d6a0e":"code","e5f32174":"code","590ae9d7":"code","48766772":"code","055473c9":"code","5a261d17":"code","eb1339af":"code","850eae94":"code","c1d8187d":"code","76491e30":"code","5c6c82a6":"code","7df31626":"code","2f663c0d":"code","f597ade9":"code","2b34f333":"code","4a9a5472":"code","439bf4c8":"code","1c5cc556":"code","6d600732":"code","3f201506":"code","b5724955":"code","79dd5be1":"code","bfc015e4":"code","9f4f0831":"code","c00b600e":"code","b57ff3ed":"code","0ca400ec":"code","8f017bc4":"code","7891e184":"code","09ce52b6":"code","5970c211":"code","3b377592":"code","b29b751e":"code","709a07e5":"code","5ae89ad6":"code","ed1bad05":"code","fac2d983":"code","cb5555b1":"code","e3152e25":"code","4d05489f":"code","72ff8099":"code","c037baa7":"code","c3aef039":"code","50f32bea":"code","5bc6b69b":"code","2ca52902":"code","7346d19c":"code","ec19a465":"code","2a56d80d":"code","650bf5ef":"code","73f7ba31":"code","fa02f376":"code","9146a140":"markdown","2c6560f7":"markdown","e56e77ad":"markdown","ffa61179":"markdown","65e0cecb":"markdown","23d6a734":"markdown","9d489353":"markdown","affa45bc":"markdown","f9a7f8d9":"markdown","809cbeb4":"markdown","30e58863":"markdown","59b15745":"markdown","dbdc0471":"markdown","0858ac4a":"markdown","a16ca7f6":"markdown","b25e12a4":"markdown","0d935e74":"markdown","574d65b2":"markdown","ca451de5":"markdown","7771a65c":"markdown","77df1849":"markdown","ee333b76":"markdown","b650a598":"markdown"},"source":{"c8c25a59":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bd12741f":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import SGDClassifier,RidgeClassifier\nfrom sklearn.metrics import (precision_score, recall_score,f1_score)\nfrom sklearn.metrics import average_precision_score","95a6d083":"######## Base\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\npd.set_option('display.max_columns', None)\n\n######### Warning ##############\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\n########## Sklearn #############\n# Pre-processing\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n# Metrics\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve\n# Models\nfrom sklearn.linear_model import LogisticRegression     # Logistic Regression\nfrom sklearn.naive_bayes import GaussianNB              # Naive Bayes\nfrom sklearn.neighbors import KNeighborsClassifier      # KNN \nfrom sklearn.svm import SVC                             # SVC \nfrom sklearn import tree                                # CART - S\u0131n\u0131fland\u0131rma ve Regresyon A\u011fa\u00e7lar\u0131\nfrom sklearn.tree import DecisionTreeClassifier         # CART - S\u0131n\u0131fland\u0131rma ve Regresyon A\u011fa\u00e7lar\u0131\nfrom sklearn.ensemble import BaggingClassifier          # Bagging\nfrom sklearn.ensemble import VotingClassifier           # Voting \nfrom sklearn.ensemble import RandomForestClassifier     # Random Forest\nfrom sklearn.ensemble import AdaBoostClassifier         # Ada Boost\nfrom sklearn.ensemble import GradientBoostingClassifier # GBM - Gradient Boosting Machine\nfrom xgboost import XGBClassifier                       # XGBoost | !pip install xgboost\nfrom lightgbm import LGBMClassifier                     # LightGBM | !conda install -c conda-forge lightgbm\nfrom catboost import CatBoostClassifier                 # CatBoost | !pip install catboost\n!pip install --upgrade nboost                           # NGBoost\n!pip install --upgrade git+https:\/\/github.com\/stanfordmlgroup\/ngboost.git\nfrom ngboost import NGBClassifier\nfrom ngboost.distns import k_categorical, Bernoulli","4867f1d2":"train=pd.read_csv('\/kaggle\/input\/unsw-nb15\/UNSW_NB15_training-set.csv')\ntest=pd.read_csv('\/kaggle\/input\/unsw-nb15\/UNSW_NB15_testing-set.csv')\n","bb59f666":"# Print the number of train \/ test samples\nprint(f\"Train data length: {len(train)}\")\nprint(f\"Test data length: {len(test)}\")\n\n# Visualise the distribution of attacks and normal traffic\n\nf, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Create the plots\nsns.countplot(x=\"label\", data=train, ax=axes[0,0])\nsns.countplot(x=\"label\", data=test, ax=axes[0,1])\nsns.countplot(x=\"attack_cat\", data=train, ax=axes[1,0], order = train['attack_cat'].value_counts().index)\nsns.countplot(x=\"attack_cat\", data=test, ax=axes[1,1], order = test['attack_cat'].value_counts().index)\n\n# Set the plot titles\naxes[0,0].set_title(\"Training data distribution\")\naxes[1,0].set_title(\"Training data distribution\")\naxes[0,1].set_title(\"Testing data distribution\")\naxes[1,1].set_title(\"Testing data distribution\")\n\n# Rotate xticks for readability\naxes[1,0].tick_params('x', labelrotation=45)\naxes[1,1].tick_params('x', labelrotation=45)\n\n# Change the xtick labels for attack \/ normal\naxes[0,0].set_xticklabels([\"Normal\", \"Attack\"])\naxes[0,1].set_xticklabels([\"Normal\", \"Attack\"])\n\n# Remove xlabels\naxes[0,0].set_xlabel(\"\")\naxes[0,1].set_xlabel(\"\")\naxes[1,0].set_xlabel(\"\")\naxes[1,1].set_xlabel(\"\")\n\n# Add some space between the plots for y labels\nplt.subplots_adjust(wspace=0.25)","8e2902c4":"train.head()","d0072302":"train.shape,test.shape","c8dd72fa":"train.info()","bde35109":"train.isnull().sum()","0cc22de4":"mask = (train.dtypes == np.object)\nprint(train.loc[:,mask].head())\nlist_cat = train.loc[:,mask].columns.tolist()\nprint(list_cat)\nprint(train.loc[:,mask].values)","00de7ea4":"mask = (train.dtypes != np.object)\nprint(train.loc[:,mask].head())\nlist_cat = train.loc[:,mask].columns.tolist()\nprint(list_cat)\ntrain.loc[:,mask].describe()\n","902d6a0e":"#  Check whether the positive label (1) match attack categories, and whether attack categories match labelled data.\n\n# all(iterable) returns True if all elements of the iterable are considered as true values\nprint(all(((train.label == 1) & (train.attack_cat != 'Normal')) == (train.attack_cat != 'Normal')))\nprint(all(((train.attack_cat != 'Normal') & (train.label == 1)) == (train.label == 1)))","e5f32174":"train.attack_cat.value_counts()","590ae9d7":"mask = (train.label == 1)\nprint(train.loc[mask,:].service.value_counts())\nprint(train.loc[mask,:].proto.value_counts())","48766772":"mask = (train.label == 0)\nprint(train.loc[mask,:].service.value_counts())\nprint(train.loc[mask,:].proto.value_counts())","055473c9":"print(train.columns.values)\nprint(test.columns.values)","5a261d17":"df = pd.concat([train, test], ignore_index=True)\n\n# Remove unwanted columns\ndf.drop(['id', 'attack_cat'], inplace=True, axis=1)\n\n# Perform one-hot encoding on categorical columns and join back to main train_data\none_hot = pd.get_dummies(df[[\"proto\", \"state\", \"service\"]])\ndf = df.join(one_hot)\n\n# Remove the original categorical columns\ndf.drop([\"proto\", \"state\", \"service\"], inplace=True, axis=1)\n\n# Re split the data back into train \/ test\ntrain_data = df.iloc[0:175341, 0:]\ntest_data = df.iloc[175341:, 0:]\n\n# Create y_train and then drop the label from the training data\ny_train = np.array(train_data[\"label\"])\ntrain_data.drop(['label'], inplace=True, axis=1)\n\ny_test = np.array(test_data[\"label\"])\ntest_data.drop(['label'], inplace=True, axis=1)\n\n# Use min-max scaler to scale the features to 0-1 range\n# Only fit the scaler on the train data!!\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(train_data)\n\n# Scale the testing data\nX_test = scaler.transform(test_data)\n\n# Ensure our dataset splits are still correct\nprint(f\"Train data shape: {X_train.shape} Train label shape: {y_train.shape}\")\nprint(f\"Test data shape: {X_test.shape} Test label shape: {y_test.shape}\")","eb1339af":"# Logistic Regression\nlog = LogisticRegression(solver = \"liblinear\")\ny_pred_log_fit = log.fit(X_train, y_train)\ny_pred_log = y_pred_log_fit.predict(X_test)\nlog_accuracy = accuracy_score(y_test, y_pred_log)","850eae94":"log_accuracy","c1d8187d":"print (\"Accuracy: \" + str(accuracy_score(y_pred_log, y_test)))\nprint (\"Precision: \" + str(precision_score(y_pred_log, y_test)))\nprint (\"Recall: \" + str(recall_score(y_pred_log, y_test)))\nprint (\"F1: \" + str(f1_score(y_pred_log, y_test)))","76491e30":"confusion_matrix(y_test, y_pred_log)","5c6c82a6":"print(classification_report(y_test, y_pred_log))","7df31626":"log_roc_auc_score = roc_auc_score(y_test, y_pred_log)","2f663c0d":"log_roc_auc_score","f597ade9":"from sklearn import metrics\nfrom sklearn.metrics import (confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score, \n                             classification_report, f1_score, average_precision_score, precision_recall_fscore_support)","2b34f333":"fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred_log)\nroc_auc_lr = auc(fpr_lr, tpr_lr)\nprecision_lr, recall_lr, th_lr = precision_recall_curve(y_test, y_pred_log)","4a9a5472":"log_auprc_score=average_precision_score(y_test,y_pred_log)","439bf4c8":"log_auprc_score","1c5cc556":"# Ridge Classifier\nrc = RidgeClassifier()\nrc_fit = rc.fit(X_train, y_train)\ny_pred_rc = rc_fit.predict(X_test)\nrc_accuracy = accuracy_score(y_test, y_pred_rc)","6d600732":"rc_accuracy","3f201506":"print (\"Accuracy: \" + str(accuracy_score(y_pred_rc, y_test)))\nprint (\"Precision: \" + str(precision_score(y_pred_rc, y_test)))\nprint (\"Recall: \" + str(recall_score(y_pred_rc, y_test)))\nprint (\"F1: \" + str(f1_score(y_pred_rc, y_test)))","b5724955":"confusion_matrix(y_test, y_pred_rc)","79dd5be1":"print(classification_report(y_test, y_pred_rc))","bfc015e4":"rc_roc_auc_score = roc_auc_score(y_test, y_pred_rc)","9f4f0831":"rc_roc_auc_score","c00b600e":"fpr_rc, tpr_rc, thresholds_rc = roc_curve(y_test, y_pred_rc)\nroc_auc_rc = auc(fpr_rc, tpr_rc)\nprecision_rc, recall_rc, th_rc = precision_recall_curve(y_test, y_pred_rc)","b57ff3ed":"rc_auprc_score = average_precision_score(y_test,y_pred_rc)","0ca400ec":"rc_auprc_score","8f017bc4":"# SGD Classifier\nsgd = SGDClassifier()\nsgd_fit = sgd.fit(X_train, y_train)\ny_pred_sgd = sgd_fit.predict(X_test)\nsgd_accuracy = accuracy_score(y_test, y_pred_sgd)","7891e184":"sgd_accuracy","09ce52b6":"print (\"Accuracy: \" + str(accuracy_score(y_pred_sgd, y_test)))\nprint (\"Precision: \" + str(precision_score(y_pred_sgd, y_test)))\nprint (\"Recall: \" + str(recall_score(y_pred_sgd, y_test)))\nprint (\"F1: \" + str(f1_score(y_pred_sgd, y_test)))","5970c211":"confusion_matrix(y_test, y_pred_sgd)","3b377592":"print(classification_report(y_test, y_pred_sgd))","b29b751e":"sgd_roc_auc_score = roc_auc_score(y_test, y_pred_sgd)","709a07e5":"sgd_roc_auc_score","5ae89ad6":"fpr_sgd, tpr_sgd, thresholds_sgd = roc_curve(y_test, y_pred_sgd)\nroc_auc_sgd = auc(fpr_sgd, tpr_sgd)\nprecision_sgd, recall_sgd, th_sgd = precision_recall_curve(y_test, y_pred_sgd)","ed1bad05":"sgd_auprc_score = average_precision_score(y_test,y_pred_sgd)","fac2d983":"sgd_auprc_score","cb5555b1":"# Ensanmble Learning\nimport statistics\nfinal_pred = np.array([])\nfor i in range(0,len(X_test)):\n    final_pred = np.append(final_pred, statistics.mode( [y_pred_log[i],y_pred_rc[i], y_pred_sgd[i]]))","e3152e25":"import seaborn\nimport matplotlib.pyplot as plt\n \ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title,\n                          cmap=None,\n                          normalize=True):\n    \n    \n    data = cm\n    labels = target_names\n    \n    \"\"\"Plot confusion matrix using heatmap.\n \n    Args:\n        data (list of list): List of lists with confusion matrix data.\n        labels (list): Labels which will be plotted across x and y axis.\n        output_filename (str): Path to output file.\n \n    \"\"\"\n    seaborn.set(color_codes=True)\n    plt.figure(1, figsize=(9, 6))\n \n    plt.title(title)\n \n    seaborn.set(font_scale=1.4)\n    ax = seaborn.heatmap(data, annot=True, cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'}, fmt=\".5g\")\n    ax.set_xticklabels(labels)\n    ax.set_yticklabels(labels)\n \n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    ax.set(ylabel=\"True Label\", xlabel='Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n#     plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n    plt.show()\n    plt.close()","4d05489f":"ensamble_accuracy = accuracy_score(final_pred, y_test)","72ff8099":"ensamble_accuracy","c037baa7":"print (\"Accuracy: \" + str(accuracy_score(final_pred, y_test)))\nprint (\"Precision: \" + str(precision_score(final_pred, y_test)))\nprint (\"Recall: \" + str(recall_score(final_pred, y_test)))\nprint (\"F1: \" + str(f1_score(final_pred, y_test)))","c3aef039":"fpr_en, tpr_en, thresholds_en = roc_curve(y_test, final_pred)\nroc_auc_en = auc(fpr_en, tpr_en)\nprecision_en, recall_en, th_en = precision_recall_curve(y_test, final_pred)","50f32bea":"roc_auc_en","5bc6b69b":"plot_confusion_matrix(cm = confusion_matrix(y_test, final_pred, labels=[0,1]), \n                      normalize    = False,\n                      target_names = [0,1],\n                      title        = \"Binary Classification\")","2ca52902":"# Plot ROC curve\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_lr, tpr_lr, label='Log Reg (area = %0.3f)' % roc_auc_lr)\nplt.plot(fpr_rc, tpr_rc, label='Ridge Classifier (area = %0.3f)' % roc_auc_rc)\nplt.plot(fpr_sgd, tpr_sgd, label='SGD (area = %0.3f)' % roc_auc_sgd)\nplt.plot(fpr_en, tpr_en, label='Ensemble (area = %0.3f)' % roc_auc_en)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC curves from the investigated models')\nplt.legend(loc='best')\nplt.show()","7346d19c":"plt.plot([1, 0], [0, 1], 'k--')\nplt.plot(recall_lr, precision_lr, label='Log Reg')\nplt.plot(recall_rc, precision_rc, label='Ridge Classifier')\nplt.plot(recall_sgd, precision_sgd, label='SGD')\nplt.plot(recall_en, precision_en, label='Ensemble')\nplt.title('Precision vs. Recall')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend(loc='best')\nplt.show()","ec19a465":"import numpy as np\n\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, scoring=None, obj_line=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Generate a simple plot of the test and training learning curve.\n\n    Parameters\n    ----------\n    estimator : object type that implements the \"fit\" and \"predict\" methods\n        An object of that type which is cloned for each validation.\n\n    title : string\n        Title for the chart.\n\n    X : array-like, shape (n_samples, n_features)\n        Training vector, where n_samples is the number of samples and\n        n_features is the number of features.\n\n    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    ylim : tuple, shape (ymin, ymax), optional\n        Defines minimum and maximum yvalues plotted.\n\n    cv : int, cross-validation generator or an iterable, optional\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n          - None, to use the default 3-fold cross-validation,\n          - integer, to specify the number of folds.\n          - An object to be used as a cross-validation generator.\n          - An iterable yielding train\/test splits.\n\n        For integer\/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    scoring : string, callable or None, optional, default: None\n              A string (see model evaluation documentation)\n              or a scorer callable object \/ function with signature scorer(estimator, X, y)\n              For Python 3.5 the documentation is here:\n              http:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#scoring-parameter\n              For example, Log Loss is specified as 'neg_log_loss'\n\n    obj_line : numeric or None (default: None)\n               draw a horizontal line\n\n\n    n_jobs : integer, optional\n        Number of jobs to run in parallel (default 1).\n\n\n    Citation\n    --------\n        http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_learning_curve.html\n\n    Usage\n    -----\n        plot_learning_curve(estimator = best_estimator,\n                            title     = best_estimator_title,\n                            X         = X_train,\n                            y         = y_train,\n                            ylim      = (-1.1, 0.1), # neg_log_loss is negative\n                            cv        = StatifiedCV, # CV generator\n                            scoring   = scoring,     # eg., 'neg_log_loss'\n                            obj_line  = obj_line,    # horizontal line\n                            n_jobs    = n_jobs)      # how many CPUs\n\n         plt.show()\n    \"\"\"\n    from sklearn.model_selection import learning_curve\n    import numpy as np\n    from matplotlib import pyplot as plt\n\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, scoring=scoring, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    if obj_line:\n        plt.axhline(y=obj_line, color='blue')\n\n    plt.legend(loc=\"best\")\n    return plt","2a56d80d":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import StratifiedKFold","650bf5ef":"X, y = X_train, y_train\n\nestimator = LogisticRegression(solver = \"liblinear\")\nplot_learning_curve(estimator = estimator,\n                    title     = \"Learning Curves (Log Regression)\",\n                    X         = X,\n                    y         = y,\n                    ylim      = (0.5, 1.1),\n                    cv        = StratifiedKFold(),\n                    scoring   = 'accuracy',     \n                    obj_line  = 0.90,    \n                    n_jobs    = -1)  \nplt.show()\n","73f7ba31":"estimator = SGDClassifier()\nplot_learning_curve(estimator = estimator,\n                    title     = \"Learning Curves (SGD)\",\n                    X         = X,\n                    y         = y,\n                    ylim      = (0.5, 1.1),\n                    cv        = StratifiedKFold(),\n                    scoring   = 'accuracy',     \n                    obj_line  = 0.90,    \n                    n_jobs    = -1)  \nplt.show()\n","fa02f376":"estimator = RidgeClassifier()\nplot_learning_curve(estimator = estimator,\n                    title     = \"Learning Curves (Ridge classifier)\",\n                    X         = X,\n                    y         = y,\n                    ylim      = (0.5, 1.1),\n                    cv        = StratifiedKFold(),\n                    scoring   = 'accuracy',     \n                    obj_line  = 0.90,    \n                    n_jobs    = -1)  \nplt.show()","9146a140":"## AUROC Score","2c6560f7":"## AUPRC Score","e56e77ad":"## AUPRC Score","ffa61179":"# 3. Data Visualization","65e0cecb":"# 5. Machine Learning Analysis","23d6a734":"# Read Directories","9d489353":"# 4. Dataset Observation","affa45bc":"# Data cleaning","f9a7f8d9":"* Scaling the Data before doing anomoly detection\n* As anomoly detection methods works better with scaled data, but there is no compulsory need to do so.\n* Scale only continious data","809cbeb4":"## Categorical variables","30e58863":"## AUROC Score","59b15745":"## Evaluation of the training dataset","dbdc0471":"# 1. Import Liberaries","0858ac4a":"## Null Value check","a16ca7f6":"## AUROC Score","b25e12a4":"## In the negatively labelled ones?","0d935e74":" Ensanmble Learning","574d65b2":"## Numeric variables","ca451de5":"## number of occurrences for each attack category","7771a65c":"# 3. Data Preprocessing","77df1849":"## AUPRC Score","ee333b76":"# 2. Loading Data","b650a598":"## Which protocols and services appear in the positively labelled entries?"}}