{"cell_type":{"39378ae2":"code","828d248a":"code","fd362112":"code","df7213cb":"code","2ab50a3a":"code","09881476":"code","c41252eb":"code","cffb540f":"code","30598888":"code","02a92e51":"code","a605f69e":"code","80f480bb":"code","c5ed7d15":"code","66b2964b":"code","881ebd56":"code","0224e474":"code","49d9785e":"code","d9676cf2":"code","d76e8e95":"code","7c0f988e":"code","c024b0cb":"code","cc197d85":"code","88e82bb1":"code","872c090d":"code","b8f32197":"code","5dc0e806":"code","a2fe0a18":"code","a711d585":"code","cc86e6b0":"code","8962d0fe":"code","b4b7c122":"code","ef9bfb52":"code","a53e2338":"code","44386a52":"code","30b7199a":"code","86c8c8be":"code","28933a75":"code","36b32980":"code","f7adc0a6":"code","3ae1ff02":"code","bd3cb9b1":"code","ae6d1f16":"markdown","230d4c85":"markdown"},"source":{"39378ae2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import  auc, roc_curve, classification_report \n\nfrom lightgbm import LGBMClassifier, plot_importance","828d248a":"train = pd.read_csv('\/kaggle\/input\/janatahack-crosssell-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/janatahack-crosssell-prediction\/test.csv')\n","fd362112":"data = pd.concat([train,test], axis=0)\ndata.head()","df7213cb":"gender_bias= {\n'Male' : 0,\n'Female' : 1\n}\n\n\nvehicle = { '< 1 Year' :0,\n'1-2 Year' : 1,\n'> 2 Years' : 2}\n\n\nvehicle_damage = { 'No' : 0,\n'Yes' : 1}","2ab50a3a":"data['Gender'] = data['Gender'].map(gender_bias)\ndata['Vehicle_Age'] = data['Vehicle_Age'].map(vehicle)\ndata['Vehicle_Damage'] = data['Vehicle_Damage'].map(vehicle_damage)","09881476":"group_vars = ['Region_Code', 'Policy_Sales_Channel']\n\nagg_vars = ['Annual_Premium', 'Vintage', 'Age']\n\n\nfor g in group_vars:\n    for a in agg_vars:\n        data[f'{g}_{a}_count'] = data.groupby(data[g])[a].transform('count')\n        data[f'{g}_{a}_mean'] = data.groupby(data[g])[a].transform('mean')\n        data[f'{g}_{a}_std'] = data.groupby(data[g])[a].transform('std')\n        data[f'{g}_{a}_min'] = data.groupby(data[g])[a].transform('min')\n        data[f'{g}_{a}_max'] = data.groupby(data[g])[a].transform('max')","c41252eb":"! pip install pycaret","cffb540f":"import pycaret","30598888":"X = data.iloc[:len(train)]\nY = data.iloc[len(train):]\nX['Response'].tail()","02a92e51":"X.fillna(method='ffill', inplace=True)","a605f69e":"X.isnull().sum()","80f480bb":"from pycaret.classification import *","c5ed7d15":"X","66b2964b":"df = X.drop(columns='id')","881ebd56":"df.Response = df.Response.astype('int')","0224e474":"df.Response ","49d9785e":"session_1 = setup(data=df, target='Response', log_experiment=True)","d9676cf2":"best_model = compare_models()","d76e8e95":"models()","7c0f988e":"best_model = create_model('rf')","c024b0cb":"best_model","cc197d85":"tuned_gbc = tune_model(best_model)","88e82bb1":"tuned_gbc","872c090d":"plot_model(tuned_gbc)","b8f32197":"plot_model(tuned_gbc, plot= 'boundary')","5dc0e806":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(sampling_strategy='minority', random_state=55, k_neighbors=5)\n","a2fe0a18":"session_2 = setup(data=df, target='Response', log_experiment=False, normalize=True, normalize_method='zscore', transformation=True, transformation_method='quantile',\n                 fix_imbalance=True, fix_imbalance_method = sm)","a711d585":"best_model = create_model('catboost')","cc86e6b0":"tuned_Cat = tune_model(best_model)","8962d0fe":"lightgbm_model = create_model('lightgbm')","b4b7c122":"lightgbm_tuned = tune_model(lightgbm_model)","ef9bfb52":"blend = blend_models(estimator_list = [tuned_Cat, lightgbm_tuned], method='soft')","a53e2338":"plot_model(blend)","44386a52":"blend","30b7199a":"plot_model(blend, plot= 'confusion_matrix')","86c8c8be":"plot_model(blend, plot= 'error')","28933a75":"plot_model(blend, plot= 'boundary')","36b32980":"Final = Y.drop(columns=['id','Response'])","f7adc0a6":"# generate predictions on unseen data\npredictions = predict_model(blend, data = Final)","3ae1ff02":"predictions","bd3cb9b1":"result=pd.DataFrame(Y[\"id\"],columns=[\"id\",\"Response\"])\nresult[\"Response\"]=predictions['Score']\nresult.to_csv(\"LGBM_prediction.csv\",index=0)","ae6d1f16":"# AUC score we got on Unseen Data was 0.85","230d4c85":"# Lets combine both model"}}