{"cell_type":{"7a87435e":"code","914bdc0b":"code","ad0e7a4b":"code","27771886":"code","c60e34e1":"code","fe4b134a":"code","fcf7d5de":"code","964ec94f":"code","52ac7545":"code","6d7f01ff":"code","51582c50":"code","3988797e":"code","aa91de87":"code","83bac2cb":"code","52aa0732":"code","6bd0925c":"code","ee586bc1":"code","2bfacbf3":"code","7667c0ed":"code","d974f2f2":"code","0be977e2":"code","034be86a":"code","513e4450":"code","e11761af":"code","65a455ae":"code","a86528a5":"code","da79a756":"code","fe19536c":"code","f105bbac":"code","33c93b0e":"code","32a7fe11":"code","cc6aef6d":"code","24e4232c":"code","c7c6dc4e":"code","7dbeb199":"code","c403bb2e":"code","4e7e768e":"code","2e1c7084":"code","bba144b0":"code","111589e0":"code","6abac2cd":"code","31e137cd":"code","dfc8cbc6":"code","e0ea2f6d":"code","c484759b":"code","7565ea52":"code","2f1bff78":"code","8219b21d":"code","82b484ca":"code","febfcb2f":"markdown","46ab672c":"markdown","71a9794b":"markdown","9d29dc93":"markdown","bf0124d2":"markdown","2083c26c":"markdown","3ae00301":"markdown","0c999cc3":"markdown","d6143fec":"markdown","cccd00c0":"markdown","04619241":"markdown","c4a76cb5":"markdown","9d1baa8f":"markdown","5ce7622c":"markdown","4fbc4970":"markdown","e3c014ec":"markdown","bfec1c91":"markdown","0f3cf52e":"markdown","4c579d8f":"markdown","61f21564":"markdown","8c80ce7f":"markdown","6afdec1d":"markdown","d900d8ad":"markdown","cee026bf":"markdown","d00ffa7e":"markdown","65061ff0":"markdown","7ed47d16":"markdown","66ff7bfb":"markdown","2b410398":"markdown","e3fb8868":"markdown","8e29719a":"markdown"},"source":{"7a87435e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","914bdc0b":"# Importing the Required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","ad0e7a4b":"# Importing the csv file and checking the first five rows\ndf = pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\ndf.head()","27771886":"# Checking for the shape of the dataset\ndf.shape","c60e34e1":"# Checking the basic info of the dataset\ndf.info()","fe4b134a":"df['Date'] = pd.to_datetime(df['Date'])","fcf7d5de":"# Creating different columns based on the date feature, for further usage\ndf['Year'] = df['Date'].dt.year\ndf['Month'] = df['Date'].dt.month\ndf['Specific_Day']= df['Date'].dt.day","964ec94f":"# Checking for null values in the dataset\n(df.isnull().sum()\/len(df) *100).sort_values(ascending=False)","52ac7545":"# Let us first drop the null values from the columns which has less than 7% null values \ndf = df.dropna(subset=['MaxTemp','MinTemp','WindSpeed9am','Temp9am','Humidity9am','WindSpeed3pm','Rainfall','RainToday'\n                      ,'RainTomorrow','Temp3pm','WindDir3pm','Humidity3pm'])","6d7f01ff":"# Filling the null values of the categorical columns with the mode\ndf['WindDir9am'] = df['WindDir9am'].fillna(df['WindDir9am'].mode()[0])\ndf['WindGustDir'] = df['WindGustDir'].fillna(df['WindGustDir'].mode()[0])","51582c50":"# Filling the null values of the numerical columns with the median \n# Since we do not if the features are skewed or not, it is better to fill them with median\ndf['Sunshine'] = df['Sunshine'].fillna(df['Sunshine'].median())\ndf['Evaporation'] = df['Evaporation'].fillna(df['Evaporation'].median())\ndf['Cloud3pm'] = df['Cloud3pm'].fillna(df['Cloud3pm'].median())\ndf['Cloud9am'] = df['Cloud9am'].fillna(df['Cloud9am'].median())\ndf['Pressure9am'] = df['Pressure9am'].fillna(df['Pressure3pm'].median())\ndf['Pressure3pm'] = df['Pressure3pm'].fillna(df['Pressure3pm'].median())\ndf['WindGustSpeed'] = df['WindGustSpeed'].fillna(df['WindGustSpeed'].median())","3988797e":"# Let us check if the null values are all replaced\ndf.isnull().sum()","aa91de87":"# Checking if there are null values in the form of question mark symbol\ndf[df=='?'].count()","83bac2cb":"plt.rcParams['figure.figsize'] = 8,4\nfig,ax = plt.subplots(1,2)\ndf['RainTomorrow'].value_counts().plot(kind='bar',rot=0,ax=ax[0],cmap='Set2')\ndf['RainTomorrow'].value_counts().plot(kind='pie',autopct='%.1f%%',ax=ax[1],cmap='Set2',explode=[0,0.1])\nplt.show()","52aa0732":"# Creating new dataframe for numerical and categorical variables\ndf_num = df.select_dtypes(np.number)\ndf_cat = df.select_dtypes('object')","6bd0925c":"# Five point summary of the numeric variables\ndf.describe()","ee586bc1":"# For the numerical columns\nplt.rcParams['figure.figsize'] = 15,5\nfor col in df.select_dtypes(np.number):\n    fig,ax= plt.subplots(1,3)\n    print(col,':')\n    sns.distplot(df_num[col],ax=ax[0], color='Green')\n    sns.boxplot(df_num[col], ax=ax[1], palette='Greens')\n    sns.violinplot(df_num[col],ax=ax[2], palette='Greens')\n    plt.show()","2bfacbf3":"# For the categorical variable\nplt.rcParams['figure.figsize'] = 12,5\nfor col in df_cat:\n    fig ,ax = plt.subplots(1,2)\n    print(col,':')\n    df_cat[col].value_counts().plot(kind='bar',rot=0, ax=ax[0],cmap='summer')\n    df_cat[col].value_counts().plot(kind='pie',autopct='%.1f%%',ax=ax[1],cmap='Spectral')\n    plt.show()","7667c0ed":"plt.rcParams['figure.figsize']=10,4\nfor col in df_num:\n    fig,ax= plt.subplots(1,2)\n    print(col,'Vs RainTomorrow\\n')\n    sns.boxplot(df['RainTomorrow'],df_num[col],ax=ax[0],palette='summer')\n    sns.violinplot(df['RainTomorrow'],df_num[col],ax=ax[1],palette='summer')\n    plt.show()","d974f2f2":"plt.rcParams['figure.figsize'] = 8,6\nfor col in df_cat:\n    print(col,'Vs RainTomorrow\\n')\n    sns.countplot(df_cat[col],hue=df['RainTomorrow'],palette='rainbow')\n    plt.show()","0be977e2":"from scipy.stats import chi2_contingency\nfor col in df_cat:\n    print('\\n',col,'Vs RainTomorrow\\n')\n    print(chi2_contingency(pd.crosstab(df_cat[col],df['RainTomorrow'])))","034be86a":"from scipy.stats import shapiro\nfor i in df_num:\n    print(i,'Vs RainTomorrow')\n    st1= df[df['RainTomorrow']=='Yes'][i]\n    st2= df[df['RainTomorrow']=='No'][i]\n    print(shapiro(st1))\n    print(shapiro(st2))\n    print('\\n')","513e4450":"from scipy.stats import mannwhitneyu\nfor i in df_num:\n    z=df[df['RainTomorrow']=='Yes'][i]\n    w=df[df['RainTomorrow']=='No'][i]\n    print('%s with RainTomorrow, pvalue is:'%i,mannwhitneyu(z,w)[1])\n    print('\\n')","e11761af":"# Since the data is skewed, we transform them, so that it will be good for building the model\nfrom sklearn.preprocessing import PowerTransformer\npt = PowerTransformer()\nfor i in df.select_dtypes(np.number):\n    df[i] = pt.fit_transform(df[[i]])","65a455ae":"# Changing the values in the target variable\ndf['RainTomorrow'] = df['RainTomorrow'].map({'Yes':1,'No':0})\ndf['RainTomorrow'] = df['RainTomorrow'].astype('int')","a86528a5":"# Encoding the categorical features with label encoding technique\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor i in df.select_dtypes('object'):\n    df[i] = le.fit_transform(df[[i]])","da79a756":"# Dropping the date column before building the model as it is already split into 3 other features\ndf= df.drop('Date',axis=1)","fe19536c":"# Seperating the dependent variable and the independent variables\nX = df.drop('RainTomorrow',axis=1)\ny = df['RainTomorrow']","f105bbac":"# Seperating into train and test data\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(X,y,train_size=0.7,random_state=42)","33c93b0e":"# Scaling the train and test data seperately so as the model will not be biased towards values\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nfor i in xtrain.columns:\n    xtrain[i]= sc.fit_transform(xtrain[[i]])\nfor i in xtest.columns:\n    xtest[i]= sc.fit_transform(xtest[[i]])","32a7fe11":"# Importing the library for balancing the target variable\nimport imblearn\nfrom imblearn.over_sampling import SMOTE","cc6aef6d":"# Balancing the train set using SMOTE technique\nsm = SMOTE()\nx_sm, y_sm = sm.fit_resample(xtrain,ytrain)","24e4232c":"# Importing the metrices\nfrom sklearn.metrics import accuracy_score,classification_report, confusion_matrix","c7c6dc4e":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr = lr.fit(x_sm ,y_sm)\nypred_lr = lr.predict(xtest)\nprint('Training Score',lr.score(x_sm,y_sm))\nprint('Testing Score',lr.score(xtest,ytest))\nprint('\\n',classification_report(ytest,ypred_lr))\nprint(confusion_matrix(ytest,ypred_lr))","7dbeb199":"from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n\nVIF = pd.DataFrame([vif(X.values,i) for i in range(X.shape[1])],columns=['VIF'],index=X.columns)\nVIF","c403bb2e":"from mlxtend.feature_selection import SequentialFeatureSelector as sfs\nsfs2 = sfs(lr, forward=False, verbose=False, scoring='neg_mean_squared_error', k_features=20)\nsfs2 = sfs2.fit(x_sm,y_sm)\nfeat_names = list(sfs2.k_feature_names_)\nprint(feat_names)","4e7e768e":"x_sm = x_sm.drop(['MaxTemp','Temp3pm','Year','Specific_Day'],axis=1)\nxtest = xtest.drop(['MaxTemp','Temp3pm','Year','Specific_Day'],axis=1)","2e1c7084":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(max_depth=5,criterion='entropy',min_samples_split=7)\ndt = dt.fit(x_sm,y_sm)\nypred_dt = dt.predict(xtest)\nprint('Training Score', dt.score(x_sm,y_sm))\nprint('Testing Score', dt.score(xtest,ytest))\nprint('\\n',classification_report(ytest,ypred_dt))\nprint(confusion_matrix(ytest,ypred_dt))","bba144b0":"plt.rcParams['figure.figsize'] = 6,4\nfrom sklearn.metrics import roc_auc_score,roc_curve\ny_prob_dt = dt.predict_proba(xtest)[:,1]\nauc_dt = roc_auc_score(ytest,y_prob_dt)\nfpr_dt , tpr_dt, thr_dt = roc_curve(ytest,y_prob_dt)\nprint('AUC:',auc_dt)\nplt.plot([0,1],[0,1],linestyle='--')\nplt.plot(fpr_dt,tpr_dt)\nplt.show()","111589e0":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=200,max_depth=8,min_samples_split=7)\nrf = rf.fit(x_sm,y_sm)\nypred_rf = rf.predict(xtest)\nprint('Training Score',rf.score(x_sm,y_sm))\nprint('Testing Score', rf.score(xtest,ytest))\nprint('\\n',classification_report(ytest,ypred_rf))\nprint(confusion_matrix(ytest,ypred_rf))","6abac2cd":"y_prob_rf = rf.predict_proba(xtest)[:,1]\nauc_rf = roc_auc_score(ytest,y_prob_rf)\nfpr_rf , tpr_rf, thr_rf = roc_curve(ytest,y_prob_rf)\nprint('AUC:',auc_rf)\nplt.plot([0,1],[0,1],linestyle='--')\nplt.plot(fpr_rf,tpr_rf)\nplt.show()","31e137cd":"from sklearn.ensemble import AdaBoostClassifier\nadb = AdaBoostClassifier(n_estimators=50)\nadb = adb.fit(x_sm,y_sm)\nypred_abd = adb.predict(xtest)\nprint('Training Score',adb.score(x_sm,y_sm))\nprint('Testing Score', adb.score(xtest,ytest))\nprint('\\n',classification_report(ytest,ypred_abd))\nprint(confusion_matrix(ytest,ypred_abd))","dfc8cbc6":"y_prob_adb = adb.predict_proba(xtest)[:,1]\nauc_adb = roc_auc_score(ytest,y_prob_adb)\nfpr_adb , tpr_adb, thr_adb = roc_curve(ytest,y_prob_adb)\nprint('AUC:',auc_adb)\nplt.plot([0,1],[0,1],linestyle='--')\nplt.plot(fpr_adb,tpr_adb)\nplt.show()","e0ea2f6d":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators=50,max_depth=4)\ngb = gb.fit(x_sm,y_sm)\nypred_gb = gb.predict(xtest)\nprint('Training Score',gb.score(x_sm,y_sm))\nprint('Testing Score',gb.score(xtest,ytest))\nprint('\\n', classification_report(ytest,ypred_gb))\nprint(confusion_matrix(ytest,ypred_gb))","c484759b":"y_prob_gb = gb.predict_proba(xtest)[:,1]\nauc_gb = roc_auc_score(ytest,y_prob_gb)\nfpr_gb , tpr_gb, thr_gb = roc_curve(ytest,y_prob_gb)\nprint('AUC:',auc_gb)\nplt.plot([0,1],[0,1],linestyle='--')\nplt.plot(fpr_gb,tpr_gb)\nplt.show()","7565ea52":"cm = confusion_matrix(ytest,ypred_rf)\nsns.heatmap(cm,annot=True,fmt='g',cmap='coolwarm_r')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Random Forest Confusion Matrix')\nplt.yticks(rotation=0)\nplt.show()","2f1bff78":"from sklearn.metrics import precision_score,recall_score,f1_score\nprint('Precision Score:',precision_score(ytest,ypred_rf))\nprint('Recall Score   :', recall_score(ytest,ypred_rf))\nprint('F1 Score       :',f1_score(ytest,ypred_rf))\nprint('Accuracy score :',accuracy_score(ytest,ypred_rf))\nprint('ROC AUC Score  :',roc_auc_score(ytest,y_prob_rf))","8219b21d":"important_features = pd.DataFrame({'Features': x_sm.columns, \n                                   'Importance': rf.feature_importances_})\n\n# print the dataframe\nimportant_features.sort_values(by='Importance', ascending=False, inplace=True)\nimportant_features","82b484ca":"plt.rcParams['figure.figsize'] = 8,5\nsns.barplot(x = 'Importance', y = 'Features', data = important_features)\n\n# add plot and axes labels\n# set text size using 'fontsize'\nplt.title('Feature Importance', fontsize = 15)\nplt.xlabel('Importance', fontsize = 15)\nplt.ylabel('Features', fontsize = 15)\nplt.show()","febfcb2f":"#### Here too the pvalues are all less than alpha, so we can conclude that all the numerical columns has an effect on the target variable","46ab672c":"#### Ada Boost Classifier","71a9794b":"* Humidity3pm has the most influence on the RainTomorrow feature\n* So, this should be considered for predicting if it will rain tomorrow\n* Followed by the features, Cloud3pm, Rainfall , Sunshine and RainToday have more effect on the RainTomorrow feature.\n#### The model is 76% accurate and the false negative is also very less. So, this model has a good potential.","9d29dc93":"#### Everywhere, the pvalue is less than alpha, so the data is skewed. When data is skewed, we have to perform mannwhineyu test.","bf0124d2":"#### Inferences from the univariate analysis of the numerical columns:\n* The mintemp almost follows a normal distribution with outliers in both sides\n* Te maxtemp is left skewed more than right skewed\n* Rainfall is clearly right skewed and as we saw from describe, the days when rain was there it was high.\n* Similar to rainfall, evaporation is highly right skewed, whenever there is rain, it is having higher values\n* Sunshine has outliers on both sides, which means there were only less days when the sunshine was warm, many days it was cloudy and equally many days it was a sunshiny day.\n* Windgustspeed is right skewed,  as only on rainy days the windgustspeed was very high\n* Windspeed9am and Windspeed3pm are right skewed too\n* Humidity9am is left skewed and humidity3pm is normally distributed.\n* Pressure9am has outliers in both sides and same applies for pressure3pm, the pressure is either too less or too high on rainy days\n* Cloud9am and cloud3pm follows almost normal distribution\n* Temp9am and temp3pm follows similar distribution with outliers on both sides\n* Year, month and specific_day denote 3 columns of the date feature\n","2083c26c":"### Hypothesis Testing","3ae00301":"### Random Forest is the best model from the above models, checking the feature importance based on RF model","0c999cc3":"### Model building","d6143fec":"#### Inferences from the bivariate analysis of the categorical columns:\n* Location does not seem to have much effect on Raintomorrow as only very few regions have very less chances of getting rain, all other regions are having good chances for rain\n* Windgustdir seems to have a little effect on raintomorrow, when the value is very high then there is some chance for getting rain \n* Winddir9am is not having much effect on raintomorrow, in all directions the chance for rain is almost equal\n* Winddir3pm is similar to winddir9am , all directions seem to have equal chances for getting rain\n* It is a very informative variable as, if it rains today, then there is very much highchance that it will also rain tomorrow, if it does not rain today, then less chances for rain tomorrow","cccd00c0":"##### Based on VIF and Backward elimination we can eliminate few features","04619241":"#### Null hypothesis : The feature does not have an effect on Target variable\n#### Alternate hypothesis: The feature has an effect on Target variable","c4a76cb5":"Except the date column, all other features are identified with their right datatype\nLet's change the dtype of the date column.","9d1baa8f":"### Bivariate Analysis","5ce7622c":"#### Distribution of the Target Variable","4fbc4970":"#### We can see that, only 5 columns does not have null values. For the columns with null values accounting to less than 7%, these null values can be dropped and the null values in the rest of the columns should be replaced with median or mode depending on its datatype","e3c014ec":"##### For numerical features with the target column, we perform normality test to decide upon the test to be performed.\n#### Null hypothesis: Data is not skewed; skewness=0\n#### Alternate hypothesis: Data is skewed; skewness!=0","bfec1c91":"#### Inferences from the univariate analysis of the Categorical columns\n* From the location column we can observe that almost all the locations contribute to the dataset equally\n* The windgustdir is more from the West direction compared to all the other directions\n* The winddir9am is more from the North direction compared to all the other directions\n* The winddir3pm is more from the South-East direction followed almost equally by West and South directions\n* As we guessed from univariate of numerical features, most of the days there was no rain only 22% times of the days, rain occurred.","0f3cf52e":"#### So, the pvalue is less than alpha in all these columns so we can conclude that all the categorical features has an effect on RainTomorrow column","4c579d8f":"#### Backward Feature elimination","61f21564":"So, the null values are all replaced with appropriate values.","8c80ce7f":"#### So, there is clear imbalance in our dataset. ","6afdec1d":"### Univariate Analysis","d900d8ad":"### Transformation and Encoding","cee026bf":"So, there are 1 lakh 45k rows with 23 features","d00ffa7e":"#### Inferences from the describe function:\n* The mintemp varies between -8 and 33, and the mean and median are almost same, so the distribution is not skewed\n* The maxtemp varies between -4 and 48, here the mean is slightly higher than the median, so it is slightly skewed\n* The rainfall varies between 0 to 371, the mean is clearly higher than the median, so it skewed. So, there are many days with no rainfall. The mean is less but the max is very high, which means that, if it rains, it will be raining heavily, but many days rain was not observed.\n* The evaporation varies between 0 and 82, here the mean and median are slightly different, so the distribution is slightly skewed. It is same as observed from rainfall feature, from the mean and median, and also from 75% quantile it is very clear that, most of the days rainfall is not observed, but on days where it is observed, it is high.\n* The sunshine varies between 0 and 14, the mean and median are almost equal so it follows a normal distribution. The max is not very high, so there were many sun shiny days.\n* The windgustspeed is about a sudden burst of wind speed, it varies between 6 and 135, the mean and median are near so it is slightly skewed, and most of the days this value is less and only in rare cases it was very high.\n* The windspeed9am varies between 0 and 87, and the mean and median are slightly different so the distribution is skewed. Similarly, the normal value and the max is very much different, so we can guess that on rainy days the windspeed is high.\n* The windspeed3pm varies between 2 and 87, the mean and median are different, so it is skewed. The windspeed at 3pm is usually higher than that at 9am, we can observe that.\n* The humidity9am varies between 0 and 100, the mean and median are different, so it is skewed. It is clearly left skewed.\n* The humidity39m varies between 0 and 100, the mean and median are different, so it is skewed. It is clearly left and right skewed.\n* The Pressure9am varies between 980 and 1041, the mean and median are different, so it is skewed.\n* The pressure3pm varies between 977 and 1039, the mean and median are different, so it is skewed. The pressure9am and pressurep3pm are almost the same.\n* The colud9am and cloud3pm has almost identical values and both varies between 0 and 9 and the mean and median of them are not same, so it is skewed.\n* The temp9am is comparatively less than temp3pm, both are not much skewed.\n* The year, month, day are distributed as usual.","65061ff0":"##### Checking for multicollinearity ","7ed47d16":"#### Random Forest","66ff7bfb":"#### Inferences from bivariate analysis of numerical columns:\n* Whenever the mintemp is very less and very high, those time, Rain is not observed on the next day\n* Maxtemp doesn't seem to have much effect on the RainTomorrow, we can only tell that when the temperature is between 15-25, there are more chances of rain\n* As we guessed, most of the times when rainfall value is very high, rain is observed on the following day\n* Evaporation is lightly contradictory as, when evaporation value is at its maximum,  rain is not observed the next day, it does not have much effect on Rain tomorrow\n* Sunshine is having little effect on raintomorrow as, when sunshine is less,  chances of getting raintomorrow is more\n* Windgustspeed, if very high, then surely chances of raintomorrow\n* Windspeed9am doesn't seem to have much effect on Raintomorrow as even if it is high, there is almost equal chance for it to rain\n* Windspeed3pm if very high, then rain occurs\n* More chances of rain when humidity is very high\n* Pressure when very less, there are chances of getting rain\n* When cloud value is very high, less chances of getting rain tomorrow\n* Mostly rain occurs with normal temperature between 10-20 and equal chances of not getting rain\n* Year, month and day doesn't seem to have much effect on rain, as it is raining uniformly","2b410398":"#### Logistic Regression","e3fb8868":"##### For categorical Vs categorical, we perform chisquare test of independence\n#### Null hypothesis: The feature does not have an effect on RainTomorrow\n#### Alternate hypothesis: The feature has an effect on RainTomorrow","8e29719a":"#### Decision Tree"}}