{"cell_type":{"be0d6d40":"code","4e704dc9":"code","2b2c0689":"code","ed6cdc1b":"code","be97a69d":"code","a5110977":"code","ee09d70c":"code","c619b545":"code","ee041920":"code","98af1481":"code","267faf4b":"code","ce98b953":"code","e523dbda":"code","82368fe5":"code","cad18963":"code","7bb72123":"code","b191a371":"code","baad401e":"code","8c9600f0":"code","c8cd7043":"code","6647d204":"code","c8b9ab24":"code","afb692f4":"code","e2476cb7":"code","78e956fb":"code","ef128d45":"code","faa5f6c5":"code","f47b40f4":"markdown","e40d78b8":"markdown","1deaec58":"markdown","37d7e3a9":"markdown","5cc822bf":"markdown","c2321d55":"markdown","bf5400d9":"markdown"},"source":{"be0d6d40":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4e704dc9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")","2b2c0689":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/train.csv\")\ntrain.head()","ed6cdc1b":"train.shape","be97a69d":"import missingno as msno\nmsno.matrix(train)","a5110977":"train.columns","ee09d70c":"train.target.unique()","c619b545":"test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv\")\ntest.head()","ee041920":"test.drop(columns=\"id\", inplace=True)","98af1481":"test.head()","267faf4b":"y = train.target","ce98b953":"y.head()","e523dbda":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny  = le.fit_transform(y)","82368fe5":"train.drop(columns=[\"id\",\"target\"],inplace=True)\ny","cad18963":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ntrain = sc.fit_transform(train)\ntest = sc.transform(test)","7bb72123":"from sklearn.decomposition import PCA\npca = PCA()\npca.fit(train)\n\nxi = np.arange(1,76,1)\nyi = np.cumsum(pca.explained_variance_ratio_)\n\nplt.figure(figsize=(16,8))\nplt.plot(xi,yi, marker=\"p\", linestyle=\"--\", color=\"b\")\nplt.axhline(y=0.95, color='r',linestyle='-')\nplt.text(0.5, 0.85,\"95% cut-off Threshold\", color=\"red\")\nplt.xticks(np.arange(1,80,1))\nplt.ylabel(\"Cummulative Variance %\")\nplt.xlabel(\"Number of Components\")\nplt.grid(axis=\"x\")\nplt.show()","b191a371":"# Reducing components to 70 by observing the graph\npca_new = PCA(n_components=70)\ntrain = pca_new.fit_transform(train)\ntest = pca_new.transform(test)","baad401e":"y","8c9600f0":"from lightgbm import LGBMClassifier\nclassifier = LGBMClassifier(n_estimators=8000,max_depth=6)","c8cd7043":"%%time\nclassifier.fit(train, y)","6647d204":"y_pred_proba = classifier.predict_proba(test)\ny_pred_proba","c8b9ab24":"output = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\noutput.head()","afb692f4":"submission = pd.DataFrame(y_pred_proba,columns=['Class_1', 'Class_2', \n                                               'Class_3', 'Class_4','Class_5',\n                                               'Class_6','Class_7','Class_8','Class_9'])\n","e2476cb7":"test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jun-2021\/test.csv\")","78e956fb":"submission = pd.concat([test.id,output_df],axis = 1)","ef128d45":"submission.head()","faa5f6c5":"submission.to_csv('submission1.csv', index=False)","f47b40f4":"# Model Training..\ud83d\udeb4","e40d78b8":"# Submission...\ud83c\udfaf","1deaec58":"# Dimensionality Reduction..\n* Applying Principal Component Analysis : Principal Component Analysis, or PCA, is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.","37d7e3a9":"# Importing Libraries","5cc822bf":"-- Note: Checkout [this](https:\/\/builtin.com\/data-science\/step-step-explanation-principal-component-analysis) to get better understanding of PCA.\n","c2321d55":"* There are no missing values in the dataset.","bf5400d9":"# Scaling data using StandardScaler"}}