{"cell_type":{"393154ca":"code","46b444df":"code","1feedf5d":"code","5138a0de":"code","1a54f364":"code","0dba839e":"code","ab790b49":"code","3db87ea8":"code","5d83c428":"code","80234611":"code","39f08c17":"code","eb022460":"code","5584c3a7":"code","03c6cbca":"code","ee8c2186":"code","4e1e5260":"code","cee51277":"code","c3ec1051":"code","f2a0b440":"code","cf723852":"code","1cc96291":"code","24e438b7":"code","ddd42377":"code","d75f9b81":"code","6ab86915":"code","77cd23ad":"code","4d63d52a":"code","9e337e85":"code","baebaaf7":"code","b9380270":"code","1f9a63ae":"code","654776f5":"code","c7a2aa6a":"code","6d9b111d":"markdown","7a1e9bde":"markdown","1cf71e00":"markdown","b758221d":"markdown","a406d629":"markdown","58bf0897":"markdown","1479afb0":"markdown","f4b0980a":"markdown","b4352eea":"markdown","3e59cf36":"markdown","2d919511":"markdown","d932bce7":"markdown","8d8d4f51":"markdown","b9338c26":"markdown"},"source":{"393154ca":"import keras\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image as img","46b444df":"import glob\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","1feedf5d":"keras.backend.image_data_format()","5138a0de":"keras.backend.set_image_data_format(\"channels_first\")\nkeras.backend.image_data_format()","1a54f364":"img.open(\"..\/input\/train\/train\/dog.10001.jpg\").resize((64, 64)).convert(\"L\")","0dba839e":"img.open(\"..\/input\/train\/train\/cat.10001.jpg\").resize((64, 64)).convert(\"L\")","ab790b49":"dog_train_list = glob.glob(\"..\/input\/train\/train\/dog.*.jpg\")\ncat_train_list = glob.glob(\"..\/input\/train\/train\/cat.*.jpg\")","3db87ea8":"x_train = []\n\nfor i in tqdm(dog_train_list):\n    temp = img.open(i).resize((64, 64))\n    temp = temp.convert(\"L\")\n    \n    x_train.append((np.array(temp) - np.mean(temp)) \/ np.std(temp))\n    x_train.append((np.array(temp.rotate(90)) - np.mean(temp)) \/ np.std(temp))\n    x_train.append((np.array(temp.rotate(180)) - np.mean(temp)) \/ np.std(temp))\n    x_train.append((np.array(temp.rotate(270)) - np.mean(temp)) \/ np.std(temp))\n    \n#    if not idx % 200:\n#        print(idx)\n\ny_train = np.tile(1, len(dog_train_list)*4)\nprint(\"dog's images loading is done\")","5d83c428":"for i in tqdm(cat_train_list):\n    temp = img.open(i).resize((64, 64))\n    temp = temp.convert(\"L\")\n    \n    x_train.append((np.array(temp) - np.mean(temp)) \/ np.std(temp))\n    x_train.append((np.array(temp.rotate(90)) - np.mean(temp)) \/ np.std(temp))\n    x_train.append((np.array(temp.rotate(180)) - np.mean(temp)) \/ np.std(temp))\n    x_train.append((np.array(temp.rotate(270)) - np.mean(temp)) \/ np.std(temp))\n    \ny_train = np.concatenate((y_train, np.tile(0, len(cat_train_list)*4))).astype(\"uint8\")\nprint(\"cat's images loading is done\")","80234611":"a = np.asarray(x_train)\nx_train = a.reshape(a.shape[0], 1, a.shape[1], a.shape[2])","39f08c17":"del(a)","eb022460":"x_train.shape","5584c3a7":"LeakyReLU = keras.layers.LeakyReLU(alpha=0.01)","03c6cbca":"model = keras.models.Sequential()\n\nmodel.add(keras.layers.Conv2D(filters=32, kernel_size=(2, 2), input_shape=(1, 64, 64)))\nmodel.add(LeakyReLU)\nmodel.add(keras.layers.Dropout(rate=0.3))\n\nmodel.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3)))\nmodel.add(LeakyReLU)\nmodel.add(keras.layers.Dropout(rate=0.3))\n\nmodel.add(keras.layers.Conv2D(filters=64, activation=\"relu\", kernel_size=(3, 3)))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(3, 3)))\nmodel.add(keras.layers.Dropout(rate=0.3))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(units=12, activation=\"relu\"))\nmodel.add(keras.layers.Dense(units=1, activation=\"sigmoid\"))","ee8c2186":"model.compile(optimizer=keras.optimizers.SGD(), loss=keras.losses.binary_crossentropy, metrics=[\"binary_accuracy\"])","4e1e5260":"model.summary()","cee51277":"model.fit(x=x_train, y=y_train, epochs=10, validation_split=0.1, shuffle=True)","c3ec1051":"model.save(\"Dogs_Cats_model_01.h5\")","f2a0b440":"model = keras.models.load_model(\"Dogs_Cats_model_01.h5\")","cf723852":"model.fit(x=x_train, y=y_train, epochs=2, validation_split=0.1, shuffle=True)","1cc96291":"len(model.history.history[\"binary_accuracy\"])","24e438b7":"np.arange(1, len(model.history.history[\"binary_accuracy\"])+1, 1)","ddd42377":"plt.figure(figsize=(20, 7))\nplt.subplot(1, 2, 1)\nplt.plot(model.history.history[\"binary_accuracy\"])\nplt.plot(model.history.history[\"val_binary_accuracy\"])\nplt.title(\"Model Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train\", \"Val\"], loc=\"upper left\")\n#plt.xticks(np.arange(0, len(model.history.history[\"binary_accuracy\"]), 1))\n\nplt.xticks(np.arange(len(model.history.history[\"binary_accuracy\"])), np.arange(1, len(model.history.history[\"binary_accuracy\"])+1, 1))\n\nplt.subplot(1, 2, 2)\nplt.plot(model.history.history[\"loss\"])\nplt.plot(model.history.history[\"val_loss\"])\nplt.title(\"Model Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Train\", \"Val\"], loc=\"upper right\")\nplt.xticks(np.arange(len(model.history.history[\"loss\"])), np.arange(1, len(model.history.history[\"loss\"])+1, 1))\nplt.show()","d75f9b81":"test_list = glob.glob(\"..\/input\/test1\/test1\/*.jpg\")","6ab86915":"x_test = []\n\nfor i in tqdm(test_list):\n    temp = img.open(i).resize((64, 64))\n    temp = temp.convert(\"L\")\n    x_test.append((np.array(temp) - np.mean(temp)) \/ np.std(temp))\n\nprint(\"test images loading is done\")","77cd23ad":"a = np.asarray(x_test)\nx_test = a.reshape(a.shape[0], 1, a.shape[1], a.shape[2])","4d63d52a":"del(a)","9e337e85":"result = model.predict(x=x_test)","baebaaf7":"idx = []\nfor i in test_list:\n    idx.append(i[21:-4])","b9380270":"result = result.reshape(result.shape[0])\nresult[result>0.5] = 1\nresult[result<0.5] = 0","1f9a63ae":"submission = {\"id\": idx, \"label\": result}","654776f5":"pd.DataFrame(submission).to_csv(\"submission.csv\", index=False)","c7a2aa6a":"pd.DataFrame(submission)","6d9b111d":"#### Data Load(for Training)","7a1e9bde":"## Dogs vs. Cats\n-2018. 12. 25 <br>\n-Image Binary Classification","1cf71e00":"#### Change Image Data Format","b758221d":"#### Extra Model Training","a406d629":"#### Library Importing","58bf0897":"#### Predict","1479afb0":"#### Model Generate","f4b0980a":"---","b4352eea":"---","3e59cf36":"#### Model Training History","2d919511":"#### Data Load(for Test)","d932bce7":"#### Data Preview","8d8d4f51":"The end of this notebook","b9338c26":"#### Model Training"}}