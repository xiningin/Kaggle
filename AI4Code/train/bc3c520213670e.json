{"cell_type":{"19336628":"code","7c05120d":"code","66edd4f4":"code","7179bdcc":"code","fc0fad0c":"code","215573ab":"code","a45d7c74":"code","4c90cfc3":"code","19cce5bd":"code","7a2a55b3":"code","dcc777a7":"code","93bddd6a":"code","9a48bf16":"code","c2a9cd9e":"code","07ec97f3":"code","82bc16f8":"code","2b03c43e":"code","529dc83c":"code","e7926a26":"code","4b4d77b2":"code","bbc6151f":"code","f9108877":"code","02320a1f":"code","aad5c115":"code","b5c840b1":"code","a91e130a":"code","83851920":"code","fc7f0c91":"code","0eac1da4":"markdown","6c855d75":"markdown","20ee18de":"markdown","a085b2e9":"markdown","18ec0fcf":"markdown","f7c44936":"markdown","721473b7":"markdown","f6d49c24":"markdown","d36d280e":"markdown"},"source":{"19336628":"!mkdir -p Dataset\/Train Dataset\/Test","7c05120d":"import os \nTRAIN_ROOT = '..\/input\/sounddigittw\/SoundDigitTW\/Train\/'\nTEST_ROOT  = '..\/input\/sounddigittw\/SoundDigitTW\/Test\/'\nTRAIN_FILES = sorted(os.listdir(TRAIN_ROOT))\nTEST_FILES  = sorted(os.listdir(TEST_ROOT))","66edd4f4":"for FILE in TRAIN_FILES:\n    command = \"ffmpeg -i \"+TRAIN_ROOT+FILE+\" Dataset\/Train\/\"+FILE.replace('.3gp','.wav')\n    os.system(command)","7179bdcc":"for FILE in TEST_FILES:\n    command = \"ffmpeg -i \"+TEST_ROOT+FILE+\" Dataset\/Test\/\"+FILE.replace('.3gp','.wav')\n    os.system(command)","fc0fad0c":"import numpy as np\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display","215573ab":"# show Train data\nfor i in range(10):\n    y, sr = librosa.load('Dataset\/Train\/'+str(i)+'_000.wav')\n    plt.figure()\n    plt.subplot(3,1,1)\n    librosa.display.waveplot(y, sr=sr)\n    plt.title('Waveform')","a45d7c74":"# show Test data\nfor i in range(10):\n    y, sr = librosa.load('Dataset\/Test\/'+str(i)+'_000.wav')\n    plt.figure()\n    plt.subplot(3,1,1)\n    librosa.display.waveplot(y, sr=sr)\n    plt.title('Waveform')","4c90cfc3":"def extract_feature(file_name):\n    X, sample_rate = librosa.load(file_name)\n    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40)\n    return mfccs","19cce5bd":"def display_mfcc(S):\n    fig, ax = plt.subplots()\n    S_dB = librosa.power_to_db(S, ref=np.max)\n    img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, fmax=8000, ax=ax)\n    fig.colorbar(img, ax=ax, format='%+2.0f dB')\n    ax.set(title='Mel-frequency spectrogram')\n    plt.show()","7a2a55b3":"x_train = list()\ny_train = list()\n(row, col) = (40,62)\n\nfor FILE in TRAIN_FILES:\n    filename = FILE.replace('.3gp','.wav')\n    mfcc = extract_feature('Dataset\/Train\/'+filename)\n    # print(mfcc.shape)\n    if (mfcc.shape[1]!=col):\n        mfcc = np.resize(mfcc, (row,col))\n    x_train.append(mfcc)\n    y_train.append(FILE[0]) # first charactor of filename is the classname\n    if FILE[2:5]==\"000\":\n        print(mfcc.shape)\n        display_mfcc(mfcc)  ","dcc777a7":"x_test = list()\ny_test = list()\n(row, col) = (40,62)\n\nfor FILE in TEST_FILES:\n    filename = FILE.replace('.3gp','.wav')\n    mfcc = extract_feature('Dataset\/Test\/'+filename)\n    # print(mfcc.shape)\n    if (mfcc.shape[1]!=col):\n        mfcc = np.resize(mfcc, (row,col))\n    x_test.append(mfcc)\n    y_test.append(FILE[0]) # first charactor of filename is the classname\n    if FILE[2:5]==\"000\":\n        print(mfcc.shape)\n        display_mfcc(mfcc)  ","93bddd6a":"X_train = np.array(x_train)\nX_test  = np.array(x_test)\nX_train = X_train.reshape(-1,40,62,1)\nX_test  = X_test.reshape(-1,40,62,1)\nprint(X_train.shape)\nprint(X_test.shape)","9a48bf16":"print(y_train)","c2a9cd9e":"# shuffle train dataset\nfrom sklearn.utils import shuffle\nX_train, y_train = shuffle(X_train, y_train, random_state=41)\n\n# check shuffle result\nprint(y_train)","07ec97f3":"# Converts a class vector (integers) to binary class matrix\nfrom tensorflow.keras import utils\nY_train = utils.to_categorical(y_train)\nY_test  = utils.to_categorical(y_test) ","82bc16f8":"y_actual = y_test\nprint(y_actual)","2b03c43e":"import tensorflow as tf\nfrom tensorflow.keras import models, layers, losses","529dc83c":"input_shape = (40,62,1) \nnum_classes = 10 #10","e7926a26":"## Build Model\ninputs = layers.Input(shape=input_shape)\n# 1st Convolutional layer\nx = layers.Conv2D(32, 3, activation = 'relu', padding = 'same')(inputs)\nx = layers.MaxPooling2D(2, padding='same')(x)\n# 2nd Convolutional layer\nx = layers.Conv2D(32, 3, activation = 'relu', padding = 'same')(x)\nx = layers.MaxPooling2D(2, padding='same')(x)\n# 3rd Convolutional layer\nx = layers.Conv2D(64, 3, activation = 'relu', padding = 'same')(x)\nx = layers.MaxPooling2D(2, padding='same')(x)\n# 4th Convolutional layer\nx = layers.Conv2D(64, 3, activation = 'relu', padding = 'same')(x)\nx = layers.MaxPooling2D(2, padding='same')(x)\n# Fully Connected layer        \nx = layers.Flatten()(x)\nx = layers.Dense(64)(x)\noutputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n\nmodel = models.Model(inputs=inputs, outputs=outputs)\n\nmodel.summary()","4b4d77b2":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","bbc6151f":"# Train Model\nhistory = model.fit(X_train, Y_train, batch_size=10, epochs=30, validation_data=(X_test, Y_test))","f9108877":"models.save_model(model, 'sounddigitTW_cnn.h5')","02320a1f":"# Evaluate Model\nscore = model.evaluate(X_test, Y_test)\nprint('Test loss: ', score[0])\nprint('Test accuracy: ', score[1])","aad5c115":"y_pred = model.predict(X_test[0].reshape(-1,40,62,1)).argmax(axis=1)\nprint(y_pred[0])\nprint(y_actual[0])","b5c840b1":"from sklearn.metrics import classification_report, confusion_matrix\n\nlabels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']","a91e130a":"predY=model.predict(X_test)\n\ny_pred = []\n[y_pred.append(labels[int(np.argmax(y))]) for y in predY]\nprint(y_pred)","83851920":"cm = confusion_matrix(y_actual, y_pred)\nprint(cm)","fc7f0c91":"# report\nprint(classification_report(y_actual, y_pred, target_names=labels))","0eac1da4":"## Save Model","6c855d75":"# Sound Digit Recognizer","20ee18de":"## Prepare Dataset","a085b2e9":"## Build Model","18ec0fcf":"## Test Model","f7c44936":"## Confusion Matrix","721473b7":"## Show Data","f6d49c24":"## Evaluate Model","d36d280e":"## Dataset: [SoundDigitTW](https:\/\/www.kaggle.com\/rkuo2000\/sounddigittw) (Sound Digit in Taiwanese)\n### *recorded sound .3gp from smartphone*"}}