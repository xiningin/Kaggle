{"cell_type":{"6c84cb39":"code","ffa5a59a":"code","3893c25e":"code","2aa07226":"code","9a60636b":"code","90b6d09a":"code","b7c58111":"code","0429bd1f":"code","b57f4ac3":"code","bc2dcf5a":"code","4434584d":"code","24f8ffb4":"markdown"},"source":{"6c84cb39":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nfrom tensorflow.data import Dataset, AUTOTUNE\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Input, Conv2D, MaxPooling2D, SpatialDropout2D, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import InceptionV3, EfficientNetB3\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport os\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ffa5a59a":"NUM_TRAIN = 840\nIMAGE_SIZE = (229, 229)\nBATCH_SIZE = 64\nearly_stopping = EarlyStopping(monitor = 'val_accuracy', patience = 5, restore_best_weights = True)","3893c25e":"train_directory = '..\/input\/asian-vs-african-elephant-image-classification\/dataset\/train'\ntrain_files = []\nfor root, directories, files in os.walk(train_directory):\n    for file in files:\n        train_files.append(os.path.join(root, file))\nprint(len(train_files))","2aa07226":"test_directory = '..\/input\/asian-vs-african-elephant-image-classification\/dataset\/test'\ntest_files = []\nfor root, directories, files in os.walk(test_directory):\n    for file in files:\n        test_files.append(os.path.join(root, file))\nprint(len(test_files))","9a60636b":"train_ds = tf.keras.utils.image_dataset_from_directory(directory = train_directory,\n                                                     labels = 'inferred',\n                                                     label_mode = 'binary',\n                                                     image_size = IMAGE_SIZE,\n                                                     shuffle = True,\n                                                     batch_size = BATCH_SIZE)\nclasses = train_ds.class_names\ntrain_ds = train_ds.prefetch(1)\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(directory = test_directory,\n                                                    labels = 'inferred',\n                                                    label_mode = 'binary',\n                                                    image_size = IMAGE_SIZE,\n                                                    batch_size = BATCH_SIZE)\\\n                        .prefetch(1)","90b6d09a":"AUGMENT_LAYER = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip('horizontal'),\n    tf.keras.layers.RandomRotation(0.2),\n    tf.keras.layers.RandomZoom(0.2)\n])","b7c58111":"fig, axes = plt.subplots(5, 4, figsize = (15, 15))\naxes = axes.flatten()\nimages_to_show = next(iter(train_ds))\nfor i in range(10):\n    img = images_to_show[0]\n    img = img[i] \/ 255\n    lbl = images_to_show[1]\n    lbl = lbl.numpy().astype(int).reshape(-1)\n    lbl = lbl[i]\n    lbl = classes[lbl]\n    aug_img = AUGMENT_LAYER(img)\n    axes[2 * i].imshow(img)\n    axes[2 * i + 1].imshow(aug_img)\n    axes[2 * i].set_title(f'Example of {lbl}')\n    axes[2 * i + 1].set_title(f'Augmented Example of {lbl}')\n    plt.axis('off')\n    \nplt.tight_layout()","0429bd1f":"def build_model():\n    inp = Input(shape = (*IMAGE_SIZE, 3))\n    x = inp\n    x = AUGMENT_LAYER(x)\n    base_model = InceptionV3(weights = 'imagenet',\n                            include_top = False,\n                            input_tensor = x)\n    \n    head_model = base_model.output\n    head_model = Flatten()(head_model)\n    head_model = Dropout(rate = 0.50)(head_model)\n    head_model = Dense(units = 128, activation = 'relu')(head_model)\n    \n    head_model = Dense(units = 1, activation = 'sigmoid')(head_model)\n    \n    #inp = base_model.input\n    return Model(inputs = inp, outputs = head_model)","b57f4ac3":"model = build_model()\n\nmodel.compile(optimizer = Adam(learning_rate = 6*10**-5), loss = 'binary_crossentropy', metrics = ['accuracy'])\nhist = model.fit(train_ds, validation_data = test_ds, epochs = 50, callbacks = [early_stopping])","bc2dcf5a":"fig, axes = plt.subplots(1, 2, figsize = (15, 15))\naxes = axes.flatten()\nhist.history.keys()\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\nacc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nepochs = range(len(loss))\naxes[0].plot(epochs, loss, label = 'loss')\naxes[0].plot(epochs, val_loss, label = 'val_loss')\naxes[1].plot(epochs, acc, label = 'accuracy')\naxes[1].plot(epochs, val_acc, label = 'val_accuracy')\nplt.legend()","4434584d":"predictions = np.zeros(len(test_files))\ntrue = np.zeros(len(test_files))\nfor idx, batch in test_ds.enumerate():\n    images = batch[0]\n    labels = batch[1].numpy().reshape(-1)\n    preds = model.predict(images).reshape(-1)\n    \n    if len(preds) == BATCH_SIZE:\n        predictions[BATCH_SIZE * idx : BATCH_SIZE * (idx + 1)] = preds\n        true[BATCH_SIZE * idx : BATCH_SIZE * (idx + 1)] = labels\n    else:\n        predictions[BATCH_SIZE * idx:] = preds\n        true[BATCH_SIZE * idx:] = labels\n\npredictions[predictions < 0.5] = 0\npredictions[predictions >= 0.5] = 1\ncm = confusion_matrix(y_true = true, y_pred = predictions)\ncmd = ConfusionMatrixDisplay(confusion_matrix = cm)\ncmd.plot()","24f8ffb4":"I'm going to be using tensorflow datasets as opposed to the image generators, since \nthe datasets should be faster based on what I read, and a test on a different\ndataset (1.5 hours for epoch for image generator vs 25min\/epoch for dataset on CPU)\nAlthough this could use some testing"}}