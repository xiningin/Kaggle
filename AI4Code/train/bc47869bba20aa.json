{"cell_type":{"3346120e":"code","4141a25d":"code","77e2d2cd":"code","a80e1dfa":"code","7219703d":"code","c12460ae":"code","d83d54c7":"code","fecb4844":"code","90430156":"code","56376b75":"code","ba4a212e":"code","bc1275a8":"code","36d1ca48":"code","81925a73":"code","3d968244":"code","22802f32":"code","b6f4d0b4":"code","d833cc43":"code","26f3b59b":"code","2ec5122e":"code","638802a6":"code","8e9fe829":"code","fe955323":"code","da644984":"code","bd096f36":"code","dada46ae":"code","cbf7b40f":"code","09ea29ba":"code","4593c16f":"code","ee2ae21a":"code","5c30acad":"code","bdd09717":"code","aeb338fb":"code","56c40871":"code","b5f981d1":"code","a0a1f648":"code","427e1848":"code","e15ff3b7":"code","9df3c1f8":"code","cfb9528b":"code","91ffdf38":"code","aec8a19c":"code","4711c288":"code","33d90ce2":"code","c70bfb3f":"code","362cf698":"code","0739dfb3":"code","d559817a":"code","c064cc6e":"code","5ba7b489":"code","c6e5ca94":"code","c194c35b":"code","7328c046":"code","898a5205":"code","c3119c49":"code","dbba4d5d":"code","b50368e8":"code","53149535":"code","15acb2d8":"code","4a2e578f":"code","535ea5cb":"code","f0220d85":"code","cd82d419":"code","47bec9e3":"markdown","3c3e42c6":"markdown","39a84bfe":"markdown","d891ca18":"markdown","699e1d9b":"markdown","0ad00c73":"markdown","7279943a":"markdown","b8fd2307":"markdown","ca8b311c":"markdown","417a935a":"markdown","3ff78445":"markdown","e2ca4bb9":"markdown","9b4cf412":"markdown","b9928ffb":"markdown","d66fbf4f":"markdown","2cbdd83c":"markdown","47323165":"markdown","0a5c3db1":"markdown","9b2c840b":"markdown","d4268af7":"markdown"},"source":{"3346120e":"#Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","4141a25d":"df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')","77e2d2cd":"df.head()","a80e1dfa":"sns.countplot(data=df,x='sex',)","7219703d":"df.info()","c12460ae":"df.describe()","d83d54c7":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.distplot(df[(df['target']==1) & (df['sex']==1)]['age'],label='Male with heart disease',color='#3498DB',bins=20)\nplt.legend()\nplt.subplot(2,2,3)\nsns.distplot(df[(df['target']==0) & (df['sex']==1)]['age'],label='Male without heart disease',color='#3498DB',bins=20)\nplt.legend()\nplt.subplot(2,2,2)\nsns.distplot(df[(df['target']==1) & (df['sex']==0)]['age'],label='Female with heart disease',color='green',bins=20)\nplt.subplot(2,2,4)\nsns.distplot(df[(df['target']==0) & (df['sex']==0)]['age'],label='Female without heart disease',color='green',bins=20)\nplt.legend()","fecb4844":"sns.countplot(data=df, x='cp', hue = 'target', palette= 'Set2')\nplt.xlabel('Chest pain in people with and without heart disease')\nplt.legend( loc='upper right', labels=['Without heart disease', 'With heart disease'])","90430156":"sns.pairplot(df,hue='target',palette='Set1')","56376b75":"plt.figure(figsize=(12,10))\nsns.heatmap(df[df['target']==1].drop('target',axis=1).corr(),cmap='Blues',annot=True)\nplt.title('People with heart disease correlation heatmap')","ba4a212e":"plt.figure(figsize=(8, 6))\nsns.boxplot(data=df, x='target', y='thalach', hue=\"slope\")","bc1275a8":"from sklearn.model_selection import train_test_split","36d1ca48":"X = df.drop('target',axis=1)\ny = df['target']","81925a73":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)","3d968244":"from sklearn.tree import DecisionTreeClassifier","22802f32":"dtree = DecisionTreeClassifier()","b6f4d0b4":"dtree.fit(X_train,y_train)","d833cc43":"# Defining a function to store evaluation metrics\ndef evaluate(prediction,y_test): \n    result = classification_report(y_test,prediction,output_dict=True)\n    f1 = result['1']['f1-score']\n    accuracy = result['accuracy']\n    performance_data= {'f1-score':round(f1, 2),\n                      'accuracy':round(accuracy, 2)}\n    return performance_data","26f3b59b":"dt_prediction = dtree.predict(X_test)","2ec5122e":"from sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import precision_score","638802a6":"print(classification_report(y_test,dt_prediction))\n\ndtree_pr= evaluate(dt_prediction,y_test)\ndtree_pr\n","8e9fe829":"from IPython.display import Image  \nfrom sklearn.externals.six import StringIO  \nfrom sklearn.tree import export_graphviz\nimport pydot ","fe955323":"features = list(df.columns[:-1])\nfeatures","da644984":"dot_data = StringIO()  \nexport_graphviz(dtree, out_file=dot_data,feature_names=features,filled=True,rounded=True)\n\ngraph = pydot.graph_from_dot_data(dot_data.getvalue())  \nImage(graph[0].create_png())","bd096f36":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100)\nrf.fit(X_train, y_train)","dada46ae":"rf_prediction = rf.predict(X_test)","cbf7b40f":"print(classification_report(y_test,rf_prediction))\nrf_pr = evaluate(rf_prediction,y_test)\nrf_pr","09ea29ba":"from sklearn.model_selection import RandomizedSearchCV","4593c16f":"param_rand = {'n_estimators': np.arange(100,800,100),\n              'max_features' : ['auto', 'sqrt'],\n              'min_samples_leaf': [1,2,4],\n              'min_samples_split': [2, 5, 10],\n              'max_depth' : np.arange(10,100,10),\n              'max_leaf_nodes': np.arange(2,5,10),\n             }","ee2ae21a":"rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = param_rand, n_iter = 100,\n                               cv = 3, verbose=2, random_state=42, n_jobs = -1)","5c30acad":"# takes so much time, you can see the rsults for best parameters\n#rf_random.fit(X_train,y_train)","bdd09717":"rf_randomized = RandomForestClassifier(n_estimators= 600,min_samples_split= 5, min_samples_leaf = 1,\n                                       max_leaf_nodes= 2,max_features= 'auto',max_depth= 70)\nrf_randomized.fit(X_train,y_train)","aeb338fb":"rf_rand_prediction = rf_randomized.predict(X_test)","56c40871":"print(classification_report(y_test,rf_rand_prediction))\nrf_rand_pr = evaluate(rf_rand_prediction,y_test)\nrf_rand_pr","b5f981d1":"from sklearn.svm import SVC","a0a1f648":"model = SVC()","427e1848":"model.fit(X_train,y_train)","e15ff3b7":"svm_prediction = model.predict(X_test)","9df3c1f8":"from sklearn.metrics import classification_report,confusion_matrix","cfb9528b":"print(classification_report(y_test,svm_prediction))\nsvm_pr = evaluate(svm_prediction,y_test)\nsvm_pr","91ffdf38":"from sklearn.model_selection import GridSearchCV\nsvm_param_grid= {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001,0.00001],\n           'kernel': ['rbf','sigmoid']}","aec8a19c":"svm_grid = GridSearchCV(SVC(),svm_param_grid,refit=True,verbose=2)\nsvm_grid.fit(X_train,y_train)","4711c288":"svm_grid.best_params_","33d90ce2":"svm_grid_prediction = svm_grid.predict(X_test)","c70bfb3f":"print(classification_report(y_test,svm_grid_prediction))\nsvm_grid_pr = evaluate(svm_grid_prediction,y_test)\nsvm_grid_pr","362cf698":"## PCA (dimension reduction)\n\n# Scale Data\nfrom sklearn.preprocessing import StandardScaler\nscale= StandardScaler()\nscale.fit(df.drop('target',axis=1))\nscaled_data = scale.transform(df.drop('target',axis=1))","0739dfb3":"# 2 compoemts\nfrom sklearn.decomposition import PCA\npca2 = PCA(n_components=2)\n\npca2.fit(scaled_data)\n\ntransformed_pca2 = pca2.transform(scaled_data)\n\ntransformed_pca2.shape","d559817a":"transformed_df_2 = pd.DataFrame(transformed_pca2,columns=['component1', 'component2'])\ntransformed_df_2['target'] = df['target']","c064cc6e":"sns.scatterplot(x=transformed_df_2['component1'],y=transformed_df_2['component2'],hue=transformed_df_2['target'])","5ba7b489":"# 3 compoemts\npca3 = PCA(n_components=3)\n\npca3.fit(scaled_data)\n\ntransformed_pca = pca3.transform(scaled_data)\n\ntransformed_pca.shape","c6e5ca94":"import plotly.io as pio\nimport plotly.express as px\ntransformed_df = pd.DataFrame(transformed_pca,columns=['component1', 'component2','component3'])\ntransformed_df['target'] = df['target']\ntransformed_df.head()\n\nfig = px.scatter_3d(df, x=transformed_df['component1'], y=transformed_df['component2'], \n                    z=transformed_df['component3'],color='target')\nfig.show(renderer='kaggle')","c194c35b":"X2 = transformed_df.drop('target',axis=1)\ny2= transformed_df['target']\nX_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3,random_state=101)","7328c046":"from sklearn.svm import SVC\nmodel2 = SVC(C= 1000, gamma= 0.00001, kernel= 'rbf')\nmodel2.fit(X_train2,y_train2)","898a5205":"prediction2 = model2.predict(X_test2)","c3119c49":"print(classification_report(prediction2,y_test2))\nsvm_pca3_pr = evaluate(prediction2,y_test2)\nsvm_pca3_pr","dbba4d5d":"df_scaled = pd.DataFrame(scaled_data,columns=df.drop('target',axis=1).columns)\ndf_scaled.head()","b50368e8":"X_scaled_train, X_scaled_test, y_scaled_train, y_scaled_test = train_test_split(scaled_data,df['target'],\n                                                    test_size=0.30)","53149535":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=2)","15acb2d8":"knn.fit(X_scaled_train,y_scaled_train)","4a2e578f":"knn_prediction = knn.predict(X_scaled_test)","535ea5cb":"print(classification_report(knn_prediction,y_scaled_test))\nknn1_pr = evaluate(knn_prediction,y_scaled_test)\nknn1_pr","f0220d85":"prediction_data={'Model':['Decision Tree',\n                          'Random Forest',\n                          'Random Forest using Randomized Search',\n                          'SVM',\n                          'SVM using Grid Search',\n                          'SVM after PCA',\n                          'KNN'\n                         ],\n                   'F1-score':[dtree_pr['f1-score'],\n                              rf_pr['f1-score'],\n                              rf_rand_pr['f1-score'],\n                              svm_pr['f1-score'],\n                              svm_grid_pr['f1-score'],\n                              svm_pca3_pr['f1-score'],\n                              knn1_pr['f1-score']],\n                 \n                   'Accuracy':[dtree_pr['accuracy'],\n                              rf_pr['accuracy'],\n                              rf_rand_pr['accuracy'],\n                              svm_pr['accuracy'],\n                              svm_grid_pr['accuracy'],\n                              svm_pca3_pr['accuracy'],\n                              knn1_pr['accuracy']]\n                    }\n \n# Create DataFrame\nprediction_table = pd.DataFrame(prediction_data)\nprediction_table","cd82d419":"import plotly.express as px\nfig = px.bar(x=prediction_table['Model'], y=prediction_table['F1-score'])\nfig.update_layout( title={\n        'text': \"Comparison of defferent ML models\",\n        'y':0.95,'x':0.5,'xanchor': 'center','yanchor': 'top'},\n    xaxis_title=\" ML models\",\n    yaxis_title=\"F1-score\")\n\nfig.show(renderer='kaggle')","47bec9e3":"## Prediction and Evaluation ","3c3e42c6":"## Randomized Search\nInstead of using grid search which takes for ever to produce the best hyperparameters, we can use Random Search where uses random combinations of hyperparameters in order to find the best ones.","39a84bfe":"## 3D Visualization","d891ca18":"## Comparison","699e1d9b":"## PCA (dimension reduction)","0ad00c73":"## 2D Visualization","7279943a":"## EDA","b8fd2307":"## Support Vector Machine (SVM)","ca8b311c":"## Random Forest Classifier","417a935a":"## K Nearest Neighbors","3ff78445":"## Evaluate model","e2ca4bb9":"## Decision Tree","9b4cf412":"Random Forest performed better that desicion tree and 15 points mislabeled.\nBut what if we tuning the Random Forest parameters?  ","b9928ffb":"## Tree Visualization","d66fbf4f":"## Grid Search","2cbdd83c":"## Prediction and Evaluation","47323165":"## Prediction and Evaluation ","0a5c3db1":"## Train Test Split","9b2c840b":"## Sources:\nhttps:\/\/www.analyticsvidhya.com\/blog\/2015\/06\/tuning-random-forest-model\/\n\nhttps:\/\/towardsdatascience.com\/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n\nhttps:\/\/plot.ly\/python\/bar-charts\/","d4268af7":"Attribute Information: \n> 1. age \n> 2. sex \n> 3. chest pain type (4 values) \n> 4. resting blood pressure \n> 5. serum cholestoral in mg\/dl \n> 6. fasting blood sugar > 120 mg\/dl\n> 7. resting electrocardiographic results (values 0,1,2)\n> 8. maximum heart rate achieved \n> 9. exercise induced angina \n> 10. oldpeak = ST depression induced by exercise relative to rest \n> 11. the slope of the peak exercise ST segment \n> 12. number of major vessels (0-3) colored by flourosopy \n> 13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect"}}