{"cell_type":{"3b096f8f":"code","b2332d9e":"code","26983232":"code","df10fe38":"code","2e3c86e8":"code","342e47bd":"code","455e94df":"code","6a4ec928":"code","767a9058":"code","a1ff5980":"code","f825763d":"code","dd8368f9":"code","859fe81d":"code","b41c6a31":"code","076c651a":"code","16c5853c":"code","d836d6f7":"code","8860c1b7":"code","b9fa159e":"code","07f6d477":"code","9dff82fd":"code","6bc51b20":"code","52ffd614":"code","8408d766":"code","e95bd514":"code","ed0521bc":"code","4b70ab51":"code","eea01434":"code","7a70705c":"code","6012728b":"code","2ca73e3e":"code","f9c0982b":"code","724d2ba2":"code","1ba0a0df":"code","447cddee":"code","689ee347":"markdown","a59979fa":"markdown","14722ff3":"markdown","41826361":"markdown","3f52a8c1":"markdown","f2d03617":"markdown","904992b4":"markdown","2d8164e4":"markdown","380ab3ad":"markdown","a5f0ab95":"markdown","612fef8e":"markdown","a2fc1e11":"markdown","e9ccf1e0":"markdown","09c7fa3c":"markdown","6e57d94c":"markdown","de796e96":"markdown","f62bd06c":"markdown","c15a2edc":"markdown","0cbeb3a9":"markdown","72c7cbb0":"markdown","97e013dd":"markdown","0c73f8e6":"markdown","7578185e":"markdown","00933467":"markdown","c07ad131":"markdown","27dfc2e2":"markdown","1a4ba1c6":"markdown","2e04f310":"markdown","659e40a4":"markdown","15d97322":"markdown","66d67259":"markdown","9e6e9c66":"markdown","43de97d9":"markdown","e2d4e998":"markdown","656310c1":"markdown","172b3ec2":"markdown","9bfce5dd":"markdown","aac4160b":"markdown","7ccc6c80":"markdown","e63f446c":"markdown","8eea82d7":"markdown","ffea86e3":"markdown","4ca0b0f2":"markdown","e8674108":"markdown"},"source":{"3b096f8f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\n%matplotlib inline","b2332d9e":"data = pd.read_csv(\"..\/input\/train.csv\")","26983232":"data.head()","df10fe38":"print(\"# of passengers in dataset:\"+str(len(data)))","2e3c86e8":"sns.countplot(x = \"Survived\", data = data);","342e47bd":"sns.countplot(x = \"Survived\", hue = \"Sex\", data = data);","455e94df":"sns.countplot(x = \"Survived\", hue =\"Pclass\", data = data);","6a4ec928":"data[\"Age\"].plot.hist();","767a9058":"data[\"Fare\"].plot.hist(bins = 20, figsize=(10,5));","a1ff5980":"data.info()","f825763d":"sns.countplot(x=\"SibSp\", data = data);","dd8368f9":"data.isnull()","859fe81d":"data.isnull().sum()","b41c6a31":"sns.heatmap(data.isnull(), yticklabels = False, cmap=\"viridis\")","076c651a":"sns.boxplot(x = \"Pclass\", y = \"Age\", data = data);","16c5853c":"data.drop(\"Cabin\", axis = 1, inplace = True)","d836d6f7":"data.dropna(inplace = True)","8860c1b7":"sns.heatmap(data.isnull(), yticklabels = False, cbar = False);","b9fa159e":"data.isnull().sum()","07f6d477":"pd.get_dummies(data['Sex'])","9dff82fd":"sex = pd.get_dummies(data['Sex'], drop_first = True)","6bc51b20":"sex.head()","52ffd614":"embark = pd.get_dummies(data['Embarked'])\nembark.head()","8408d766":"embark = pd.get_dummies(data['Embarked'], drop_first=True)\nembark.head(5)","e95bd514":"pcl = pd.get_dummies(data['Pclass'])\npcl.head()","ed0521bc":"pcl = pd.get_dummies(data['Pclass'], drop_first = True)\npcl.head()","4b70ab51":"data = pd.concat([data, sex, embark, pcl], axis = 1)\ndata.head()","eea01434":"data.drop(['Sex', 'Embarked', 'Pclass', 'PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True)\ndata.head()","7a70705c":"X = data.drop(\"Survived\", axis = 1)","6012728b":"Y = data[\"Survived\"]  # this is our target variable","2ca73e3e":"from sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)","f9c0982b":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train, Y_train)\npredictions = logmodel.predict(X_test)","724d2ba2":"from sklearn.metrics import classification_report\nclassification_report(Y_test, predictions)","1ba0a0df":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(Y_test, predictions)","447cddee":"from sklearn.metrics import accuracy_score\naccuracy_score(Y_test, predictions)","689ee347":"We have 2 and 3, meaning if both these values are 0 then the passenger is travelling in the 1st class.\n\nSo the next step is we will concatenate all the above categorical values to the dataset","a59979fa":"Let us explore the age of the passengers","14722ff3":"Imputation : we can drop the missing values or fill in some other values","41826361":"# Titanic - How Rose survives and why Jack dies ?","3f52a8c1":"From the above we can notice that the passengers travelling in the first class and second class are older than the 3rd class","f2d03617":"Let us check table again","904992b4":"It's time to drop the Pclass, Sex, and Embarked categorical data columns","2d8164e4":"calculate accuracy","380ab3ad":"Data Cleaning \/ Data Wrangling ( we will remove  unnecessary columns wherever possible )","a5f0ab95":"We will train and predict by creating a model.","612fef8e":"We don't require both these columns. One column is enough to enough to tell whether it is male or female. So we will keep only one column, male column in this case. ","a2fc1e11":"From above data we can notice that there are missing values in Age, Cabin and Embarked","e9ccf1e0":"Applying dummy function on Pclass","09c7fa3c":"Let us check the fare details also","6e57d94c":"The cabin column has lot of null values, so we drop them","de796e96":"In the data set we have the column Survived which categorical.\nSo we apply Logistic regression on the columns ( i.e we need to predict the y value )","f62bd06c":"How many passengers are there ?","c15a2edc":"drop all NA values","0cbeb3a9":"In this Titanic dataset we will analyse the factors which have contributed to the person's survival.\nWe will use the Logistic Regression to predict if the person is survived or not.","72c7cbb0":"We see a lot of string values in our dataset, we need to convert it to categorical variables inorder to implement logistic regression. So the process is we will convert this to categorical variable into dummy variable as logistic regression takes only two values. So we will be creating dummy variables.","97e013dd":"It is time to evaluate how the model is performaing.\n\nWe can find the accuracy or classification report ","0c73f8e6":"Now let find the accuracy by creating a confusion matrix","7578185e":"So '0' basically tells its not afemale and 1 tells it's a female column. Similar is the case with male column.","00933467":"check the siblings status on the ship","c07ad131":"Let us analyse the columns","27dfc2e2":"we will build the model on the train data and predict output on test data","1a4ba1c6":"How many passengers survived ?","2e04f310":"Similarly we apply the dummy function on Embarked column also:","659e40a4":"So the female column is dropped and let us print few columns","15d97322":"We will split data in training and test data sets","66d67259":"So we got 78% accuracy","9e6e9c66":"Let us analyse the data by creating the different plots","43de97d9":"Let us import the necessary librariers","e2d4e998":"Let use the heatmap again to check null values removed or not","656310c1":"Let us analyse the age column","172b3ec2":"in the above, except Survived all other columns will become the independent variables ( i.e features )","9bfce5dd":"Let us see the null values using the heatmap","aac4160b":"Now our data set is clean","7ccc6c80":"Load the Titanic dataset","e63f446c":"Print top few rows to understand about the data","8eea82d7":"## Train and Test data","ffea86e3":"Passengers survived based on the passenger class","4ca0b0f2":"passengers survived based on the gender wise","e8674108":"we have C, Q and S columns. Here also we can drop the first column as the other two columns are enough where it tells if the passenger is travelling for Q(Queen's town), S(Southampton) or if the both these values are 0 then we can assume that he\/she is travelling for C(Cherbourg).\n\nSo let us drop the first value"}}