{"cell_type":{"d74eb31b":"code","0d363902":"code","53c4abc1":"code","e6297757":"code","b1ba40f2":"code","bc09035f":"code","fd6e9301":"code","4f762393":"code","17272b2a":"code","40840467":"code","a4521815":"code","e70ab463":"code","3254733f":"code","36185e61":"code","fc6ab362":"markdown","61afc25f":"markdown","41a85c96":"markdown","b7d8a3e9":"markdown","9ed4c22a":"markdown","b2572d3e":"markdown","a967fb86":"markdown","c90f2d9a":"markdown"},"source":{"d74eb31b":"%matplotlib inline\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport string\nfrom PIL import Image\nfrom PIL import ImageFont\nfrom PIL import ImageDraw\nfrom scipy.ndimage.filters import gaussian_filter\nfrom scipy import ndimage\n\nfrom keras import regularizers, optimizers\nfrom keras.utils.np_utils import to_categorical  # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import (\n    Dense,\n    Dropout,\n    Flatten,\n    ZeroPadding2D,\n    Conv2D,\n    AveragePooling1D,\n    MaxPool2D,\n    BatchNormalization,\n    Activation,\n)\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.preprocessing.image import (\n    random_rotation,\n    random_shift,\n    random_shear,\n    random_zoom,\n    random_channel_shift,\n    img_to_array,\n    ImageDataGenerator,\n)\nfrom keras import backend as K\nfrom keras.datasets import fashion_mnist\nfrom keras_tqdm import TQDMCallback, TQDMNotebookCallback\nimport itertools\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nfrom sklearn.utils import class_weight","0d363902":"# Set consistent random seed\nrandom_seed = 2018\nnp.random.seed(random_seed)  \ntf.set_random_seed(random_seed)","53c4abc1":"print(os.listdir(\"..\"))\nprint(os.listdir(\".\"))","e6297757":"print(os.listdir(\"..\/input\"))","b1ba40f2":"# flow_from_dataframe\ntraindf=pd.read_csv(\"..\/input\/train.csv\",dtype=str)\n# Remove new whales from input\ntraindf = traindf[traindf.Id != \"new_whale\"]\n# Remove single whales values\n# traindf = traindf.groupby('Id').filter(lambda x: len(x) > 1)\n# Plot Id frequencies\ntraindf['Id'].value_counts()[1:16].plot(kind='bar')\n\ntestdf=pd.read_csv(\"..\/input\/sample_submission.csv\",dtype=str)\n\ndatagen=ImageDataGenerator(rescale=1.\/255.,validation_split=0.25)\n\"\"\"\ndatagen = ImageDataGenerator(\n        rotation_range=20,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0.5,\n        zoom_range=(0.9, 1.1),\n        horizontal_flip=False,\n        vertical_flip=False,\n        fill_mode='constant',\n        cval=0,\n        rescale=1.\/255.,\n        validation_split=0.25    \n)\n\"\"\"","bc09035f":"traindf.shape\n# Calculate number of unique classes (whales)\nnumber_of_classes = traindf['Id'].nunique()","fd6e9301":"testdf.head(1)","4f762393":"# Pass the dataframes to 2 different flow_from_dataframe functions\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=traindf,\n    directory=\"..\/input\/train\/\",\n    x_col=\"Image\",\n    y_col=\"Id\",\n    subset=\"training\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(80, 80),\n)\n\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe=traindf,\n    directory=\"..\/input\/train\/\",\n    x_col=\"Image\",\n    y_col=\"Id\",\n    subset=\"validation\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(80, 80),\n)\n\ntest_datagen = ImageDataGenerator(rescale=1.0 \/ 255.0)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=testdf,\n    directory=\"..\/input\/test\/\",\n    x_col=\"Image\",\n    y_col=None,\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=None,\n    target_size=(80, 80),\n)","17272b2a":"# Model @frommedium\n# https:\/\/medium.com\/@vijayabhaskar96\/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\nmodel = Sequential()\nmodel.add(Flatten(input_shape=(80, 80, 3), name=\"Input_layer\"))\n\"\"\"\n# maybe good 0.030\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(1024, activation='relu'))\n\"\"\"\n\"\"\"\n# maybe good 0.031\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\n\"\"\"\n\"\"\"\n# maybe good 0.036 after 1st epoch\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\n\"\"\"\n# maybe good 0.039 after 1st epoch\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\n\"\"\"\n# maybe good 0.033 after 1st epoch\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(1024, activation='relu'))\n\"\"\"\n\"\"\"\n# maybe good 0.031 after 1st epoch\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(1024, activation='relu'))\n\"\"\"\nmodel.add(Dense(number_of_classes, activation=\"softmax\"))\nmodel.compile(\n    optimizers.rmsprop(lr=0.0001, decay=1e-6),\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\n\nprint(\"The model was compiled\")","40840467":"# Fit the model @frommedium\n# https:\/\/medium.com\/@vijayabhaskar96\/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\nSTEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size\n# Class weights balancing\nhistory = model.fit_generator(\n    generator=train_generator,\n    steps_per_epoch=STEP_SIZE_TRAIN,\n    validation_data=valid_generator,\n    validation_steps=STEP_SIZE_VALID,\n    class_weight=\"auto\",\n    epochs=37,\n)\n\n","a4521815":"# history plots\nplt.plot(history.history['acc'])\nplt.title('Model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('Epoch')\nplt.show()\n\n# Plot the loss curve for training\nplt.plot(history.history['loss'], color='r', label=\"Train Loss\")\nplt.title(\"Train Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","e70ab463":"# Evaluate model\nmodel.evaluate_generator(generator=valid_generator, steps=1)","3254733f":"# Predict the output\ntest_generator.reset()\npred = model.predict_generator(test_generator, steps=STEP_SIZE_TEST + 1, verbose=1)\n\npredicted_class_indices = np.argmax(pred, axis=1)\n\nlabels = train_generator.class_indices\nlabels = dict((v, k) for k, v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\n\nfilenames = test_generator.filenames\n\nprint(\"Filenames were prepared\")","36185e61":"# Multiple classes output\n# https:\/\/www.kaggle.com\/hexadd5\/simple-resnet50-with-keras\nkth = 5\nclasses = np.array([c for c, v in train_generator.class_indices.items()])\n\nif True:\n    classify_index = np.argpartition(-pred, kth)[:, :kth]\n    classify_value = pred[np.arange(pred.shape[0])[:, None], classify_index]\n    best_5_pred = np.zeros((len(classify_index), 5))\n    best_5_class = np.zeros((len(classify_index), 5), dtype=\"int32\")\n    for i, p in enumerate(classify_value):\n        sort_index = np.argsort(p)[::-1]\n        best_5_pred[i] = p[sort_index]\n        best_5_class[i] = classify_index[i][sort_index]\n\n    # create output\n    submit = pd.DataFrame(columns=[\"Image\", \"Id\"])\n    for i, p in enumerate(best_5_pred):\n        submit_classes = []\n        if p[0] < 0.55:\n            submit_classes.append(\"new_whale\")\n            submit_classes.extend(classes[best_5_class[i]][0:4])\n        elif p[1] < 0.4:\n            submit_classes.extend(classes[best_5_class[i]][0:1])\n            submit_classes.append(\"new_whale\")\n            submit_classes.extend(classes[best_5_class[i]][1:4])\n        elif p[2] < 0.1:\n            submit_classes.extend(classes[best_5_class[i]][0:2])\n            submit_classes.append(\"new_whale\")\n            submit_classes.extend(classes[best_5_class[i]][2:4])\n        elif p[3] < 0.05:\n            submit_classes.extend(classes[best_5_class[i]][0:3])\n            submit_classes.append(\"new_whale\")\n            submit_classes.extend(classes[best_5_class[i]][3:4])\n        else:\n            submit_classes.extend(classes[best_5_class[i]])\n        classes_text = \" \".join(submit_classes)\n        submit = submit.append(\n            pd.Series(\n                np.array([test_generator.filenames[i], classes_text]),\n                index=submit.columns,\n            ),\n            ignore_index=True,\n        )\n        # print(submit)\n    submit.to_csv(\"submit.csv\", index=False)\n    print(\"Submission results were written\")\n","fc6ab362":"![](http:\/\/)## Install dependencies","61afc25f":"## Dataset\nWhales dataset","41a85c96":"### Importing, normalizing, visualizing","b7d8a3e9":"### Show the content of the input folder","9ed4c22a":"### Show the content of the current and parent folder","b2572d3e":"Print obtained dataframes for checking","a967fb86":"Let's upload whales dataset.","c90f2d9a":"# Image classification with Keras with simple MLP model"}}