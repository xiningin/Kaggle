{"cell_type":{"d403d1a9":"code","e628ccfa":"code","0cea4b75":"code","3108ea94":"code","8786a309":"code","b54137ee":"code","48dfefb0":"code","2584b9fa":"code","4506b055":"code","607ce987":"code","7eb24dba":"code","573f43bd":"code","96554d00":"code","0a9aedf8":"code","d3d89ff4":"code","9169ae47":"code","08ab2c4e":"code","48c64253":"code","29be62b5":"code","49b640d3":"code","f49453b7":"code","278e5a8b":"code","b635949e":"code","64e41f1d":"code","785d0b9d":"code","f533b529":"code","a1089b45":"code","45634af3":"code","27ecb4ae":"code","64cc15e7":"code","dbe979b4":"code","fde1ec86":"code","1f61c056":"code","8e3fb315":"code","230393c9":"code","982b6327":"code","be006225":"code","6f8af9d5":"code","b3cc0864":"code","4502b0dc":"code","edd29b9a":"code","1ac01e30":"code","2047b1ff":"code","2a6e06ff":"code","7ec97e46":"code","5b009ef4":"code","e0832bef":"code","9bb7abac":"code","c1d16c52":"code","a6862dc3":"code","43b9ef0e":"code","6d139d39":"code","f1415b50":"code","73c865b9":"code","269e1638":"code","00142508":"code","7c269870":"code","74a58cf1":"code","1663da3a":"code","7cc04dcb":"code","8b4cba91":"code","03951ee8":"code","25c4117f":"code","713f0792":"code","17c567a9":"code","21a50749":"code","2bb06474":"code","7f511cb8":"code","81bd0814":"code","6ad0a1bd":"markdown","ffa9a2d4":"markdown","c99273de":"markdown","2f732303":"markdown","6355c816":"markdown","c593bb73":"markdown","4b36a1e8":"markdown","b553b9e2":"markdown","515a0bb1":"markdown","34cd1f94":"markdown","5cd9d2df":"markdown","42387818":"markdown","e07fce70":"markdown","5eed67d9":"markdown","d2055b76":"markdown","16eef965":"markdown","9579c224":"markdown","ccf49dd4":"markdown","ba6c237f":"markdown","a60f125b":"markdown","7a664c20":"markdown","84539ea0":"markdown","dd093e42":"markdown","69632246":"markdown","46821f53":"markdown","7ed0773c":"markdown","4b478ea7":"markdown","fa6805a8":"markdown","d054826e":"markdown","bc678d84":"markdown","e69ce913":"markdown","93ad019f":"markdown","fd993804":"markdown","03b5cd66":"markdown","4b86ddc2":"markdown","98487915":"markdown","feaa8587":"markdown","bbdf5de5":"markdown","ccfa80da":"markdown","e0794a7d":"markdown","f1f3198a":"markdown","f1822c66":"markdown"},"source":{"d403d1a9":"import numpy as np\nimport pandas as pd\n%matplotlib inline\n\ncars = pd.read_csv(\"craigslistVehiclesFull.csv\", header=0)\n\ncars.head()","e628ccfa":"cars.describe()","0cea4b75":"cars.shape","3108ea94":"def checkNullableCounts(data):\n    null_columns=data.columns[data.isnull().any()]\n    print(data[null_columns].isnull().sum())\n    \ncheckNullableCounts(cars)","8786a309":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef plot_carprice(cars):\n    plt.figure(figsize=(12,5))\n    plt.subplot(121)\n    sns.boxplot(y='price', data=cars)\n    plt.xlabel('Price Distribution boxplot')\n    plt.subplot(122)\n    sns.distplot(cars['price'], kde=False)\n    plt.xlabel('Price Distribution')\n\nplot_carprice(cars)","b54137ee":"cars_rawdata = cars.drop(cars[(cars['price'] > 100000) | (cars['price'] < 100)].index)\nplot_carprice(cars_rawdata)","48dfefb0":"plt.figure(figsize=(15,10))\nax = sns.countplot(x='manufacturer',data=cars_rawdata,order=cars_rawdata['manufacturer'].value_counts().index);\nax.set_xticklabels(ax.get_xticklabels(), fontsize=10, rotation= 90);","2584b9fa":"plt.figure(figsize=(20,10))\nax = sns.countplot(x='city',data=cars_rawdata,order=cars_rawdata['city'].value_counts().index);\nax.set_xticklabels(ax.get_xticklabels(), fontsize=10);","4506b055":"##Return dataframe with rank related dataframe that has unique values of category, rank based on mean price for category in\n##Ascending order i.e. lowest mean price category gets lowest rank (Little bias but based on real data)\ndef rankColumnInDataframe(cars, column):\n    retDF = cars.groupby(column)['price'].mean().sort_values().to_frame()\n    retDF[column]=retDF.index\n    retDF=retDF.reset_index(drop=True)\n    retDF['rank']=retDF.index+1\n    return retDF\n\ncities = rankColumnInDataframe(cars_rawdata, 'city')\ncities.head()","607ce987":"plt.figure(figsize=(10,6))\ng = sns.PairGrid(cities)\ng = g.map(plt.scatter)","7eb24dba":"def plotCountAndPriceForColumn(cars, column):\n    f=plt.figure(figsize=(25,15))\n    f.add_subplot(2,1,1)\n    plt.xticks(fontsize=10)\n    plt.title(column+' Histogram')\n    sns.countplot(cars[column],palette=(\"magma\"))\n    f.add_subplot(2,1,2)\n    plt.title(column +' vs Price')\n    sns.boxplot(x=cars[column], y=cars['price'], palette=(\"magma\"))","573f43bd":"plotCountAndPriceForColumn(cars_rawdata, 'weather')","96554d00":"cars_map = cars_rawdata.sample(n=10000, random_state=1)\nlatitude_list = cars_map['lat'].tolist()\nlongitude_list = cars_map['long'].tolist()\n\nimport gmplot\n  \ngmap3 = gmplot.GoogleMapPlotter(35, -100, 4, apikey=<your google maps key>) \n  \n# scatter method of map object  \n# scatter points on the google map \ngmap3.scatter( latitude_list, longitude_list, '#FF0000', size = 60, marker = False ) \n\ngmap3.draw(\"map.html\")\n\nfrom IPython.display import IFrame\n\ndisplay(IFrame(src='map.html', width=1000, height=600))","0a9aedf8":"cars_rawdata = cars_rawdata.drop(['image_url', 'county_fips', 'lat', 'long', 'county_name',\n                                  'state_name','state_fips', 'state_code', 'weather'],axis=1)","d3d89ff4":"print('Shape of cars raw dataset after dropping columns: {}'.format(cars_rawdata.shape))\nprint('Data types of columns in dataframe:')\ncars_rawdata.dtypes","9169ae47":"cars_rawdata['drive_na'] = cars_rawdata.drive.fillna('NA')\ncars_rawdata['paint_color_na'] = cars_rawdata.paint_color.fillna('NA')\ncars_rawdata['type_na']= cars_rawdata['type'].fillna('NA')\ncars_rawdata['size_na']= cars_rawdata['size'].fillna('NA')\ncars_rawdata['transmission_na'] = cars_rawdata.transmission.fillna('NA')\ncars_rawdata['title_status_na']=cars_rawdata.title_status.fillna('NA')\ncars_rawdata['cylinders_na']=cars_rawdata.cylinders.fillna('NA')\ncars_rawdata['fuel_na']=cars_rawdata.fuel.fillna('NA')\ncars_rawdata['condition_na']=cars_rawdata.condition.fillna('NA')","08ab2c4e":"plotCountAndPriceForColumn(cars_rawdata, 'drive_na')","48c64253":"plotCountAndPriceForColumn(cars_rawdata, 'paint_color_na')","29be62b5":"plotCountAndPriceForColumn(cars_rawdata, 'size_na')","49b640d3":"plotCountAndPriceForColumn(cars_rawdata, 'type_na')","f49453b7":"plotCountAndPriceForColumn(cars_rawdata, 'transmission_na')","278e5a8b":"plotCountAndPriceForColumn(cars_rawdata, 'title_status_na')","b635949e":"plotCountAndPriceForColumn(cars_rawdata, 'fuel_na')","64e41f1d":"plotCountAndPriceForColumn(cars_rawdata, 'condition_na')","785d0b9d":"plotCountAndPriceForColumn(cars_rawdata, 'cylinders_na')","f533b529":"# Assign previously created NA valued columns to categorical columns\ncars_rawdata['paint_color'] = cars_rawdata['paint_color_na']\ncars_rawdata['size'] = cars_rawdata['size_na']\ncars_rawdata['transmission'] = cars_rawdata['transmission_na']\ncars_rawdata['title_status']= cars_rawdata['title_status_na']\ncars_rawdata['cylinders']= cars_rawdata['cylinders_na']\ncars_rawdata['fuel']= cars_rawdata['fuel_na']\ncars_rawdata['condition']= cars_rawdata['condition_na']\n\n# drop *_na named columns\ncars_rawdata = cars_rawdata.drop(['paint_color_na', 'size_na', 'transmission_na', 'title_status_na', 'cylinders_na',\n                                 'fuel_na','condition_na' ],axis=1)\n\n#create dataframe to encode columns values for rank\npaint_colors = rankColumnInDataframe(cars_rawdata, 'paint_color')\nsizes = rankColumnInDataframe(cars_rawdata, 'size')\ntransmission_types = rankColumnInDataframe(cars_rawdata, 'transmission')\ntitle_statuses = rankColumnInDataframe(cars_rawdata, 'title_status')\ncylinders = rankColumnInDataframe(cars_rawdata, 'cylinders')\nfuel_types = rankColumnInDataframe(cars_rawdata, 'fuel')\nconditions = rankColumnInDataframe(cars_rawdata, 'condition')\n\n# check sample of ranked dataframe\ncylinders.head()","a1089b45":"def returnUniqueValues(cars, column):\n    return cars[column].unique()\n\ndrive_list = returnUniqueValues(cars_rawdata, 'drive_na').tolist()\ntype_list = returnUniqueValues(cars_rawdata, 'type_na').tolist()\n\ndrive_list.append('awd')\ndrive_list.append('4x4')\ndrive_list.remove('NA')\ntype_list.remove('NA')\n\nprint(\"Drive Values: \")\nprint(drive_list)\nprint(\"Type Values:\")\nprint(type_list)\ncars_rawdata = cars_rawdata.drop(['drive_na', 'type_na'],axis=1)","45634af3":"def odometerReading(year):\n    return 15000* (2018-year)","27ecb4ae":"listing_url = [x.split('\/')[-2].split('-') for x in cars_rawdata['url']]","64cc15e7":"listing_url[:10]","dbe979b4":"# Remove duplicates from list\ndef uniq(lst):\n    last = object()\n    for item in lst:\n        if item == last:\n            continue\n        yield item\n        last = item\n\ndef sort_and_deduplicate(l):\n    return list(uniq(sorted(l, reverse=False)))","fde1ec86":"import re\n\nmakelist = returnUniqueValues(cars_rawdata,'make')\nprint (\"Unique values in make column :\" + str(len(makelist)))\nprint(\"Sample of unique values for Make:\")\nmakeList = [re.sub('[^A-Za-z0-9]+', '-', str(x)) for x in makelist]\n##Clear '-' character if string starts with it\nmakeList = sorted([x[1:] if x.startswith('-') else x for x in makeList ])\n\n# Split string into array elements - separator : '-'\nmakeList = [x.split('-') for x in makeList]\n\nmakeList = sort_and_deduplicate(makeList)\nprint(makeList[:100])","1f61c056":"manufacturers_list = returnUniqueValues(cars_rawdata, 'manufacturer')\nmanufacturers_list = manufacturers_list[pd.notnull(np.array(manufacturers_list))]\nmanufacturers_list","8e3fb315":"def returnYear(x):\n    try:\n        if x.isdigit():\n            if len(x)==4 and bool(re.match(\"((19[0-9][0-9])|(200[0-9])|(201[0-5]))\",x)):\n                return x\n            if len(x)==2 and bool(re.match(\"([0-1][0-9])\",x)):\n                return x\n    except:\n        return None\n\ndef searchInColumns(column, columnValue):\n    year= None\n    manufacturer= None\n    make = None\n    drive = None\n    retType = None\n    returnValue = None\n    try:\n        if column=='url':\n            returnValue = columnValue.split('\/')[-2].split('-')\n        elif column =='make':\n            returnValue = re.sub('[^A-Za-z0-9]+', '-', str(columnValue))\n            returnValue = returnValue[1:] if returnValue.startswith('-') else returnValue\n            returnValue = returnValue.split('-')   \n        make = list(returnValue)\n        for x in returnValue:\n            if returnYear(x):\n                year = returnYear(x)\n                make.remove(x)\n            if x in manufacturers_list:\n                manufacturer = x\n                make.remove(x)\n            if x in drive_list:\n                drive = x\n                make.remove(x)\n            if x in type_list:\n                retType = x\n                make.remove(x) \n        make = ' '.join(make[:2])\n        return year, manufacturer, make, drive, retType\n    except Exception as e:\n        print(\"Exception occured: {}\".format(e))\n        return year, manufacturer, make, drive, retType","230393c9":"searchInColumns('url', 'https:\/\/marshall.craigslist.org\/cto\/d\/2010-dodge-challenger-se\/6717448841.html')","982b6327":"searchInColumns('make', 'patriot high altitude')","be006225":"from vininfo import Vin\n##Get manufacturer and year from VIN\ndef getManufacturerModelYearFromVIN(VIN):\n    try:\n        manufacturer = None\n        year = None\n        model = None\n        vin = Vin(VIN)\n        if vin.manufacturer and vin.manufacturer != 'UnsupportedBrand':\n            manufacturer = vin.manufacturer.lower()\n        if vin.years:\n            year= vin.years[0]\n        return manufacturer, year\n    except:\n        return None, None","6f8af9d5":"getManufacturerModelYearFromVIN('WDDNG79X97A124434')\n#getManufacturerModelYearFromVIN('1FAFP55UO4G113464')","b3cc0864":"import math\ndef refineDataset(cars):\n    returnDF = None\n    try:\n        returnDF = cars\n        for i, row in returnDF.iterrows():\n            year1, manufacturer1, make1, drive1, retType1 = searchInColumns('url', row['url'])\n            year2, manufacturer2, make2, drive2, retType2 = searchInColumns('make', row['make'])\n            ## if vin is avaible get this information\n            if row['vin']:\n                vin_manufacturer, vin_year = getManufacturerModelYearFromVIN(row['vin'])\n            if math.isnan(row['year']):\n                returnYear = None\n                if year1:\n                    returnYear = year1\n                elif year2:\n                    returnYear = year2\n                elif vin_year:\n                    returnYear = vin_year\n                returnDF.at[i, 'year'] = returnYear\n            if row['manufacturer'] is None:\n                returnManufacturer = None\n                if manufacturer1:\n                    returnManufacturer = manufacturer1\n                elif manufacturer2:\n                    returnManufacturer = manufacturer2\n                elif manufacturer_year:\n                    returnManufacturer = vin_manufacturer\n                returnDF.at[i, 'manufacturer'] = returnManufacturer\n            # Assign refined value of make if available instead of one from url\n            if row['make']:\n                returnDF.at[i, 'make'] = make2 if make2 else make1\n            if row['drive'] is None:\n                returnDF.at[i, 'drive'] = drive1 if drive1 else drive2\n            if row['type'] is None:\n                returnDF.at[i, 'type'] = retType1 if retType1 else retType2\n            if math.isnan(row['odometer']) or row['odometer'] <= float(100):\n                returnDF.at[i, 'odometer'] = odometerReading(row['year'])\n        return returnDF\n    except:\n        print(\"Exception occured: {}\".format(e))\n        return returnDF","4502b0dc":"cars_rawdata.head(10)","edd29b9a":"cars_refined = refineDataset(cars_rawdata)\ncars_refined.head(10)","1ac01e30":"cars_refined = cars_refined.drop(['vin','url' ],axis=1)","2047b1ff":"cars_refined.head()","2a6e06ff":"checkNullableCounts(cars_refined)","7ec97e46":"cars_refined['drive'] = cars_refined.drive.fillna('NA')\ncars_refined['manufacturer'] = cars_refined.manufacturer.fillna('NA')\ncars_refined['type'] = cars_refined.type .fillna('NA')","5b009ef4":"cars_refined= cars_refined.dropna(axis=0, subset=['year','odometer'])\ncheckNullableCounts(cars_refined)","e0832bef":"plt.figure(figsize=(15,10))\nax = sns.countplot(x='manufacturer',data=cars_refined,order=cars_refined['manufacturer'].value_counts().index);\nax.set_xticklabels(ax.get_xticklabels(), fontsize=10, rotation= 90);","9bb7abac":"def standardizeUsingDict(columnValue, allowedValues):\n    temp = columnValue\n    try:\n        if allowedValues[columnValue]:\n            temp=allowedValues[columnValue]\n        return temp\n    except:\n        return temp\n    \ndef standardizeManufacturer(manufacturer):\n    company={'aston':'aston-martin', 'chev':'chevrolet','harley':'harley-davidson', 'land rover' :'landrover', \n            'mercedes':'mercedes-benz', 'vw': 'volkswagen', 'alfa':'alfa-romeo', 'mercedesbenz':'mercedes-benz'}\n    return standardizeUsingDict(manufacturer, company)\n    \n\ndef standardizeDrive(drive):\n    company={'awd':'4wd', '4x4':'4wd'}\n    return standardizeUsingDict(drive, company)","c1d16c52":"cars_refined['manufacturer'] = cars_refined['manufacturer'].apply(standardizeManufacturer)","a6862dc3":"cars_refined['drive'] = cars_refined['drive'].apply(standardizeDrive)","43b9ef0e":"manufacturers = rankColumnInDataframe(cars_refined, 'manufacturer')\ndrive_ranks = rankColumnInDataframe(cars_refined, 'drive')\ntype_ranks = rankColumnInDataframe(cars_refined, 'type')\nmake = rankColumnInDataframe(cars_refined, 'make')","6d139d39":"def rankUsingDict(columnValue, allowedValues):\n    temp = columnValue\n    try:\n        if allowedValues[columnValue]:\n            temp=allowedValues[columnValue]\n        return temp\n    except:\n        return temp\n\ncities_dict = cities.set_index('city').T.to_dict('records')[1]\n\ndef rankCityFromDataframe(value):\n    return rankUsingDict(value, cities_dict)","f1415b50":"cars_refined['city'] = cars_refined['city'].apply(rankCityFromDataframe)","73c865b9":"### Converting all ranking dataframes to dicts for faster processing \n\nmanufacturers_dict = manufacturers.set_index('manufacturer').T.to_dict('records')[1]\nmake_dict = make.set_index('make').T.to_dict('records')[1]\ndrive_ranks_dict = drive_ranks.set_index('drive').T.to_dict('records')[1]\ntype_ranks_dict = type_ranks.set_index('type').T.to_dict('records')[1]\nconditions_dict = conditions.set_index('condition').T.to_dict('records')[1]\nfuel_types_dict = fuel_types.set_index('fuel').T.to_dict('records')[1]\ncylinders_dict = cylinders.set_index('cylinders').T.to_dict('records')[1]\ntitle_statuses_dict = title_statuses.set_index('title_status').T.to_dict('records')[1]\ntransmission_types_dict = transmission_types.set_index('transmission').T.to_dict('records')[1]\nsizes_dict = sizes.set_index('size').T.to_dict('records')[1]\npaint_colors_dict = paint_colors.set_index('paint_color').T.to_dict('records')[1]","269e1638":"def rankManufacturerFromDataframe(value):\n    return rankUsingDict(value, manufacturers_dict)\ndef rankMakeFromDataframe(value):\n    return rankUsingDict(value, make_dict)\ndef rankDriveFromDataframe(value):\n    return rankUsingDict(value, drive_ranks_dict)\ndef rankTypeFromDataframe(value):\n    return rankUsingDict(value, type_ranks_dict)\ndef rankConditionFromDataframe(value):\n    return rankUsingDict(value, conditions_dict)\ndef rankFuelTypeFromDataframe(value):\n    return rankUsingDict(value, fuel_types_dict)\ndef rankCylindersFromDataframe(value):\n    return rankUsingDict(value, cylinders_dict)\ndef rankTitleStatusFromDataframe(value):\n    return rankUsingDict(value, title_statuses_dict)\ndef rankTransmissionFromDataframe(value):\n    return rankUsingDict(value, transmission_types_dict)\ndef rankSizeFromDataframe(value):\n    return rankUsingDict(value, sizes_dict)\ndef rankPaintColorFromDataframe(value):\n    return rankUsingDict(value, paint_colors_dict)","00142508":"cars_refined['manufacturer'] = cars_refined['manufacturer'].apply(rankManufacturerFromDataframe)\ncars_refined['make'] = cars_refined['make'].apply(rankMakeFromDataframe)\ncars_refined['drive'] = cars_refined['drive'].apply(rankDriveFromDataframe)\ncars_refined['type'] = cars_refined['type'].apply(rankTypeFromDataframe)\ncars_refined['condition'] = cars_refined['condition'].apply(rankConditionFromDataframe)\ncars_refined['fuel'] = cars_refined['fuel'].apply(rankFuelTypeFromDataframe)\ncars_refined['cylinders'] = cars_refined['cylinders'].apply(rankCylindersFromDataframe)\ncars_refined['title_status'] = cars_refined['title_status'].apply(rankTitleStatusFromDataframe)\ncars_refined['transmission'] = cars_refined['transmission'].apply(rankTransmissionFromDataframe)\ncars_refined['size'] = cars_refined['size'].apply(rankSizeFromDataframe)\ncars_refined['paint_color'] = cars_refined['paint_color'].apply(rankPaintColorFromDataframe)\n","7c269870":"cars_prediction = cars_refined\ncars_prediction.head(10)","74a58cf1":"cars_final = cars_prediction[['price','year','manufacturer','make','cylinders','city','title_status','transmission','paint_color','drive','size','type','condition','fuel', 'odometer']]","1663da3a":"cars_final.to_csv('Cars_processed_dataset.csv')","7cc04dcb":"plt.figure(figsize = (30, 25))\nsns.heatmap(cars_final.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","8b4cba91":"price = cars_final['price']\nfeatures = cars_final.drop('price', axis=1)","03951ee8":"# Import train_test_split\nfrom sklearn.model_selection import train_test_split\n# Split the 'features' and 'income' data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, \n                                                    price, \n                                                    test_size = 0.2, \n                                                    random_state = 0)\n\n# Show the results of the split\nprint(\"Training set has {} samples.\".format(X_train.shape[0]))\nprint(\"Testing set has {} samples.\".format(X_test.shape[0]))\n","25c4117f":"# TODO: Import 'r2_score'\nfrom sklearn.metrics import r2_score\n\ndef performance_metric(y_true, y_predict):\n    \"\"\" Calculates and returns the performance score between \n        true and predicted values based on the metric chosen. \"\"\"\n    \n    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n    score = r2_score(y_true, y_predict)\n    \n    # Return the score\n    return score","713f0792":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\nfrom sklearn.tree import DecisionTreeRegressor\nimport xgboost as xgb\n\ndef fit_model(X, y):\n    \"\"\" Performs grid search over the 'max_depth' parameter for a \n        decision tree regressor trained on the input data [X, y]. \"\"\"\n    \n    # Create cross-validation sets from the training data\n    # sklearn version 0.18: ShuffleSplit(n_splits=10, test_size=0.1, train_size=None, random_state=None)\n    # sklearn versiin 0.17: ShuffleSplit(n, n_iter=10, test_size=0.1, train_size=None, random_state=None)\n    #cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n    cv_sets = ShuffleSplit(n_splits=10, test_size = 0.20, random_state = 0).split(X)\n\n    # TODO: Create a decision tree regressor object\n    #regressor = DecisionTreeRegressor()\n    regressor = xgb.XGBRegressor()\n\n    # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n    #params = {'max_depth':[10,50,100]}\n    params = {'max_depth':[10,25,50],\n              'objective':['reg:squarederror'],\n              'colsample_bytree' : [0.3], \n              'learning_rate': [0.1],\n              'alpha' : [10], \n              'n_estimators':[30, 50]}\n\n    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n    scoring_fnc = make_scorer(performance_metric)\n\n    # TODO: Create the grid search cv object --> GridSearchCV()\n    # Make sure to include the right parameters in the object:\n    # (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n    grid = GridSearchCV(estimator=regressor, param_grid=params, scoring=scoring_fnc, cv=cv_sets)\n\n    # Fit the grid search object to the data to compute the optimal model\n    grid = grid.fit(X, y)\n\n    # Return the optimal model after fitting the data\n    return grid","17c567a9":"reg = fit_model(X_train, y_train)\n\nbest_model = reg.best_estimator_\n\n# Produce the value for 'max_depth'\n#print(\"Parameter 'max_depth' is {} for the optimal model.\".format(best_model.get_params()['max_depth']))","21a50749":"print(\"Parameters for the optimal model : {}\".format(best_model.get_params()))","2bb06474":"import xgboost as xgb\nxg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 50, alpha = 10, n_estimators = 50)\nxg_reg.fit(X_train,y_train)\n\npreds = xg_reg.predict(X_test)","7f511cb8":"from sklearn.metrics import mean_squared_error\nrmse = np.sqrt(mean_squared_error(y_test, preds))\nprint(\"RMSE: %f\" % (rmse))","81bd0814":"print(\"R2 score for trained model based on results: \" + str(performance_metric(y_test, preds)))","6ad0a1bd":"From above location maps we can see that our dataset is distributed unevenly and area closer to east cost and west coast has more listings. This is done for only 10k customer and when plotted repeatedly it's noticed that some of the data points are over alask and in pacific ocean. Given these facts we can conclude that relying on latitude and longitude for accuracy of location is not advisable. Hence for location we will only use city location and drop other columns\n\n## Drop Insignifacant Columns\n\nFollowing columns will be dropped from dataset:\n- Image_url: \n    - Unique for each data point\n    - Unavailable for download\n    - Doesn't provide any significant information.\n- All location columns except City\n    - county_fips\n    - latitude\n    - longitude\n    - county_name \n    - state_fips \n    - state_code \n    - weather    \n\n","ffa9a2d4":"Based on drive related box and countplot it can be seen that if drive information is not available on large number of data points however when value is not provided mean price falls between front wheel drive and rear wheel drive. 4 wheel drive cars are expensive. We are going to assign 'NA' for data points where this information is not available and encode  category similar to city where mean price if high for category, it'll have higher rank. However before we do this, glance at URL and make column data (in other iterations) shows that sometimes drive information is hidden in them. We want to extract this information for data points where this information is missing so we can accurately predict price of car with appropriate information\n\nLets check price boxplot and countplots for following columns so that we can identify if same function similat to drive and cities can be applied to these categorical columns\n    - paint_color\n    - type\n    - size\n    - transmission\n    - title\n    - cylinders\n    - fuel\n    - condition","c99273de":"# Getting Started\n\nDataset contains following features which will be used for analysis and prediction.\n\n1.\tURL: Link to Listing\n2.\tCity: Craigslist Region\n3.\tPrice:  Price of the vehicle\n4.\tYear: Year of Manufacturing\n5.\tManufacturer: Manufacturer of Vehicle\n6.\tMake: Model of Vehicle\n7.\tCondition: Vehicle condition\n8.\tCylinder: Number of Cylinders\n9.\tFuel: Type of Fuel required\n10.\tOdometer: Miles traveled\n11.\tTitle_status: Title status (e.g. clean, missing, etc.)\n12.\ttransmission: Type of transmission\n13.\tvin: Vehicle Identification Number\n14.\tdrive: Drive of vehicle\n15.\tsize: Size of vehicle\n16.\ttype: Type of vehicle\n17.\tPaint_color: Color of vehicle\n18.\timage_url: Link to image\n19.\tlat: Latitude of listing\n20.\tLong: Longitude of listing\n21.\tcounty_fips : Federal Information Processing Standards code\n22.\tcounty_name: County of listing\n23.\tstate_fips: Federal Information Processing Standards code\n24.\tstate_code: 2 letter state code\n25.\tstate_name: State name\n26.\tWeather: Historical average temperature for location in October\/November\n\nAs mentioned before each listing can be identified by unique URL. We will go through following steps to get our regression model.\n\n__1. Data import and analysis (Visualizations)__\n\n__2. Data pre-processing and cleaning__\n\n__3. Data transformation (feature engineering)__\n\n__4. Modelling__\n\n__5. Evaluation using matrices__\n","2f732303":"We can definitely encode this column similar to drive and cost but would not find this in URL or make hence skipping refinement of this column\n\nLets move on to type categorical column","6355c816":"Based on above plots we can conclude that most of the vehicles have clean status however vehicles with lien status are expensive hence encoding them based on mean price should help model in predictive better prices\n\nLets check pattern for fuel column","c593bb73":"Visualize converted data to get better insights into what has been changed in dataset","4b36a1e8":"# Data Analysis and Exploratory Visualization\n\nWe will be using pandas and matplotlib functionality to describe data.","b553b9e2":"# Save processed dataset.\n\nWe could avoid loading raw dataset and refining it by saving it for future use","515a0bb1":"Since we are going to search for drive and type related values in URL and make we should lists with distinct values of them and append\/remove known values in list such as append awd for drive and remove 'NA' from both the lists","34cd1f94":"### VIN\n\n[VIN](https:\/\/driving-tests.org\/vin-decoder\/) (Vehicle identification number) is a unique code that is assigned to every motor vehicle when it's manufactured. The VIN is a 17-character string of letters and numbers without intrvening spaces or the letters Q, I and O which are avoided to avoid confusion with number 0 and 1. Each section of the VIN provides a specific piece of information about the vehicle including year, country, factory of manufacture; the make and model. VINs are usually printed in a single line and can be identified in several places on vehicle.\n\nAll the vehicle made after 1980 have 17 character long vin whereas the one manufactured before 1980 have 11 characters.\n\nWe will be extracting manufacturer and year information wherever vin is available to standardize information. After this activity since VIN is unique in each data point we will drop the information","5cd9d2df":"## Encoding Columns\n\nPreviously we created dataframe with ranks for different categorical columns. Now we will do the same exercise for mean price for following columns and apply ranks on each column so we can start predicting prices\n- Columns Targeted\n1. Manufacturer\n2. Drive\n3. Type\n4. Make","42387818":"## Drop Vin and URL\n\nThese columns would not be used anymore for refining data and also doesn't have significance given they only have unique values, we will drop these 2 columns","e07fce70":"We will use mean price based encoding given variance based on values and 'NA' as default value however we are not going to find this information in URL or make hence we will skip refinement of this column.\n\nLets check pattern for cylinder column","5eed67d9":"## Select Features and columns to be predicted","d2055b76":"Above plots conclude that most of the vehicles are automatic but surprisingly data points where this information is not provided have higher mean prices hence we cannot encode them to 'automatic'. Information would not be available in URL or make hence skipping on data refinement however it can be encoded based on mean price (Might result in some bias where values are not provided)\n\nLets check patterns for title","16eef965":"It could be concluded that vehicles with higher cylinder numbers would have higher price and hence the mean price for respective category. We will encode this category similar to drive and city i.e. based on mean price. Default for this category will be 'NA'.\n\nBased on all the above observations and discussions lets default following columns to NA and create dataframe to encode columns\n- paint_color\n- transmission\n- title_status\n- cylinder\n- size\n- fuel\n- condition","9579c224":"Based on pattern it's confirmed that we can apply similar encoding to paint_color as drive and city i.e. default will be 'NA' and ranking will be based on mean price for color. Colors would not be available in URL or make hence we don't need to refine this column more\n\nLets check count and price patterns for size","ccf49dd4":"# CraigsList Car and Truck Price Estimator\n\n","ba6c237f":"## City Statistics\n\nLets plot city counts distribution.","a60f125b":"This information can be encoded based on mean prices and information could be found in URL and make hence refinement will be required. Null values will be deafulted to 'NA' and encoding will be done based on mean price of the type\nChecking transmission columns patterns:","7a664c20":"### Filter data on Price\n\nIt appears that there are lot of values in data which are outside regular values. Lets assume that minimum price for any car or truck that is available for resale is 100 and maximum 100K. This means that we would not be targetting any high end cars and truck from manufacturers like Ferrari, porsche or Lamborghini\n\nFrom both the plots above we can confirm that there are some outliers in price column which should be removed.\nIt can be assumed that we are only looking at cars and trucks which are not luxirious and hence the price should not exceed 100k. Hence dropping data for cars which have price tags above 100K.","84539ea0":"# Data Features Cleanup\n\n## Manufacturer distribution\nLet's look at count of records for different manufacturers","dd093e42":"## Refine Dataset\n\nWe now have all the required functions to refine dataset. Lets apply following functions:\n- searchInColumns\n- odometerReading\n\nWhile applying function we are going to make sure that year information if unavailable then will be extracted form url first instead of make. \n\nThis will result in refinment of year, manufacturer, make, drive and type of vehicle","69632246":"### Price \n\nFrom the values obtained above for nullable column counts we can see that price is available on all columns and we are trying to predict price hence all the data points can be used for data analysis and refinement","46821f53":"## Encoding dataset by calculated ranks","7ed0773c":"# Categorical Columns\n\nFollowing columns have missing values which needs to be analyzed in order to decide what to do with unknowns\n- drive\n- paint_color\n- type\n- size\n- transmission\n- title_status\n- fuel\n- condition\n\nLets replace missing values with common value 'NA' to analyze trend in data","4b478ea7":"# Data load\n\nData is already made available through kaggle repository. This data is downloaded and used as it is directly.","fa6805a8":"# Conclusion\n\nBy using Xgboost we are able to reach benchmark i.e. \n- RMSE: 5007.23 \n- R2: 0.7866\n\nDecision trees provided:\n- RMSE : 9007\n- R2: 0.37\n\nWhich is very low compared to Xgboost","d054826e":"## Manufacturer Standardization\n\nNow as we have refined dataset, lets looks at Null count and effect of refinement on count of records for each manufacturer vs raw dataset.\nAfter looking at count plot we will standardize manufacturer as some of them are written in different way howeve mean the same for example: vw and volkswagen are same.\nWe will perform this standardization exercise for drive list as well","bc678d84":"Based on nullability count we are going to take following action on columns\n1. Year, odometer - Drop data points where information is missing\n2. manufacturer, drive, type - replace Nulls with NA","e69ce913":"## Location Information\n\nCity information is available on all the data points however we have more detailed feature on dataset which provides information about location from which listing was posted\ncolumns which provide this information are:\n- county_fips \n- county_name \n- state_fips  \n- state_code\n- latitude\n- longitude\n\nWeather is also a location dependent feature however following columns have missing values or nulls (As obtained before)\n\n|Column          | Null count |\n|----------------|------------|\n|county_fips     |  58833     |\n|county_name     |  58833     |\n|state_fips      |  58833     |\n|state_code      |  58833     |\n|weather         |  59428     |\n\nLets check weather information correlation with price using box and count plots\n","93ad019f":"# URL\n\n## Format\n\nURL of every datapoint contains description of the vehicle which is sometimes missing from make, year or model columns.\nFormat of url contains :\n1. City https:\/\/marshall.craigslist.org\/cto\/d\/\/\n2. Craigslist site and cto tag which stands for car and truck listing\n3. Description of the listing (2010-dodge-challenger-se)\n4. html page number (6717448841.html)\n\nWe are going to drop all other parts of url except description and split description using character '-'.","fd993804":"### Make\n\nWe can see from above makelist that manufacturer and year information could be available in make hence we will make sure to extract this information and refine make to use limited information. We might also find information about drive, type. Based on value lists created before we will try to extract as much information as possible\n\n### Manufacturer list\n\nWe have drive_list and type_list from previous functions, let's make manufacturer list using same function returnUniqueValues and remove null value","03b5cd66":"### Check Null counts in different columns\n\nWe have to determine action on various based on null values in columns. Since This check will be required periodically after formatting different columns lets create function and call it once","4b86ddc2":"Based on distribution plotted above we can notice that mean prices by cities are distributed evenly and hence to encode these cities we can use their rank.","98487915":"### Odometer\n\nOdometer reading provides us insights into condition of the engine. This will be one of the most important feature required on each data point to estimate price. From previous nullability check we have seen that many data points have nulls on odometer information but based on google search and information from insurance companies it appears that average number of kms covered by vehicle is around 15-20K. We will create a function that will return odometer reading if unavailable on data based on age of the car","feaa8587":"Based on graph represented above it looks like there is variable number of cars available in different cities and from nullability information it is confirmed that city information is available on all data points.\n\nSince we are trying to predict price of cars available in different cities we will plot distribution of mean values of cars for various cities and rank cities lowest when mean is lowest.","bbdf5de5":"There is definitely change in number of records in NA category and very little change in numbber of records at each category\n\n## Standardization function\n\nIt will be used against manufacturer and drive values to make sure only valida values are available in these columns","ccfa80da":"We can see that every other url description has a year information followed by manufacturer information in some cases. We also noticed during initial analysis that there are following number of records has that nullable values\n- year               6315\n- manufacturer     136414\n\nWe can extract this missing information from URL description and as discussed before make can also contain this information. Lets check data in make column","e0794a7d":"### Year\n\nYear is very important attribute on each data point to estimate price as it shows how old vehicle is. If year information is not available ater this cleanup if we are missing any values in this year column then we should drop data point.","f1f3198a":"Based on count and price graphs for weather pointers we can conclude that mean effect of weather on car prices is very negligible and in approximately 2k-3k range. This observation also holds true for distinct values of weather where count of records is high i.e mean price at 59 degrees and 45 degrees is very close where count of cars is high. Hence weather information can be ignored. This can be considered if data is available on all data points and for future studies.\n\nLets try and see distribution of data points based on latitude and longitude\n\n### Latitude and Longitude\n\nDistribution of Data over regions by sampling data for 10000 data points\nPlot using gmplot","f1822c66":"Most of the data points i.e. vehicles are gas based but it's interesting enough to see that mean price of diesel vehicles is higher than gas. We will use price based encoding and 'NA' as default value however we are not going to find this information in URL or make hence we will skip refinement of this column\n\nLets checke patterns for condition column"}}