{"cell_type":{"91057a15":"code","c3418cef":"code","c0147391":"code","032ea5b9":"code","83705e6b":"code","50eb4265":"code","9872c652":"code","f7e674f2":"code","05b59094":"code","e9c94569":"code","39eab898":"code","bad31ecc":"code","bcefc818":"code","eb071797":"code","715730c1":"code","2e17d0a4":"code","60503f4b":"code","4ee31957":"code","15fff22a":"code","ea400f37":"code","9a4dc4ea":"code","2ee52148":"code","f4db4309":"code","eb74a78d":"code","da470d32":"code","a89a5ef5":"code","8544d3dc":"code","71be6391":"code","60e2b67c":"code","8e999f48":"code","0d6eb79c":"code","becb682f":"code","d736fb21":"code","1faeb054":"code","9aac7112":"code","a490f36a":"code","8ccd313e":"code","3085b7a9":"code","740592d4":"code","32563bec":"markdown","a3ff67bb":"markdown","8274dc3a":"markdown","987179d5":"markdown","64f39267":"markdown","4add26e6":"markdown","5168d657":"markdown","f798e953":"markdown","3a8e9bfe":"markdown","0aba0a48":"markdown","7e4e3d6f":"markdown","f53ada0e":"markdown","4c8f6636":"markdown","6a305ce8":"markdown","109b0d74":"markdown","b8e20869":"markdown","3a167ee0":"markdown","e87bd559":"markdown","d2c3913c":"markdown","6e96bbdf":"markdown","6e17694b":"markdown","c09bdc3c":"markdown","165db944":"markdown"},"source":{"91057a15":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\nimport seaborn as sns\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization,MaxPool2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport random\nimport cv2\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nimport tensorflow as tf","c3418cef":"train_normal = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/'\ntrain_pneum = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/'\n\ntest_normal = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/'\ntest_pneum = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/'\n\nval_normal = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/NORMAL\/'\nval_pneum = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/val\/PNEUMONIA\/'","c0147391":"train_normal_images = glob.glob(train_normal + '*jpeg')\ntrain_pneum_images = glob.glob(train_pneum + '*jpeg')\n\ntest_normal_images = glob.glob(test_normal + '*jpeg')\ntest_pneum_images = glob.glob(test_pneum + '*jpeg')\n\nval_normal_images = glob.glob(val_normal + '*jpeg')\nval_pneum_images = glob.glob(val_pneum + '*jpeg')","032ea5b9":"train = []\ntest = []\nval = []\n\n# Appending Train Data\nfor x in train_normal_images:\n    train.append([x, 0])\n    \nfor x in train_pneum_images:\n    train.append([x,1])\n    \n# Appending test Data\n    \nfor x in test_normal_images:\n    test.append([x,0])\n    \nfor x in test_pneum_images:\n    test.append([x,1])\n    \n# Appending val Data    \n    \nfor x in val_normal_images:\n    val.append([x,0])\n    \nfor x in val_pneum_images:\n    val.append([x,1])\n    \n\n","83705e6b":"random.shuffle(train)\nrandom.shuffle(test)\nrandom.shuffle(val)","50eb4265":"train = pd.DataFrame(train, columns = ['Images', 'Labels'])\ntest = pd.DataFrame(test, columns = ['Images', 'Labels'])\nval = pd.DataFrame(val, columns = ['Images', 'Labels'])","9872c652":"train.head()","f7e674f2":"test.head()","05b59094":"val.head()","e9c94569":"train['Labels'].value_counts()","39eab898":"sns.countplot(train.Labels)","bad31ecc":"test['Labels'].value_counts()","bcefc818":"sns.countplot(test.Labels);","eb071797":"val['Labels'].value_counts()","715730c1":"sns.countplot(val.Labels);","2e17d0a4":"plt.figure(figsize=(20,12))\nfor i in range(15):\n    plt.subplot(3,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    img = plt.imread(train['Images'][i])\n    plt.imshow(img, cmap='gray')\n    plt.title('1 = Pneum,0 = Healthy')\n    plt.xlabel([train['Labels'][i]])\nplt.show()","60503f4b":"def process_data(img_path):\n    img = cv2.imread(img_path)\n    img = cv2.resize(img, (224, 224))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = img\/255.0\n    img = np.reshape(img, (224,224,1))\n    \n    return img\n\ndef compose_dataset(df):\n    data = []\n    labels = []\n\n    for img_path, label in df.values:\n        data.append(process_data(img_path))\n        labels.append(label)\n        \n    return np.array(data), np.array(labels)","4ee31957":"x_train, y_train = compose_dataset(train)\nx_test, y_test = compose_dataset(test)\nx_val, y_val = compose_dataset(val)","15fff22a":"print(x_train.shape,y_train.shape)\nprint(x_test.shape, y_test.shape)\nprint(x_val.shape, y_val.shape)","ea400f37":"datagen = ImageDataGenerator(\n    rotation_range=10,\n    zoom_range = 0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=False\n)\ndatagen.fit(x_train)","9a4dc4ea":"model = Sequential()\nmodel.add(Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu', input_shape=(224, 224, 1)))\nmodel.add(Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n\nmodel.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))","2ee52148":"model.summary()","f4db4309":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","eb74a78d":"history = model.fit(datagen.flow(x_train,y_train, batch_size=32),\n                    validation_data=(x_test, y_test),\n                    epochs = 25)","da470d32":"model.evaluate(x_test,y_test)","a89a5ef5":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Validation set'], loc='lower right')\nplt.show()","8544d3dc":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Validation set'], loc='upper left')\nplt.show()","71be6391":"preds = model.predict_classes(x_test)","60e2b67c":"preds = np.array(preds)\npreds[:10]","8e999f48":"print(classification_report(y_test,preds))","0d6eb79c":"conf = confusion_matrix(y_test,preds)\nconf","becb682f":"fig,ax = plt.subplots(figsize = (5,5))\nsns.heatmap(conf,\n            annot = True,\n            linewidths = 0.5,\n            linecolor = 'red',\n            fmt = '.0f',\n            ax = ax);","d736fb21":"correct = np.nonzero(preds == y_test)[0]\nincorrect = np.nonzero(preds != y_test)[0]","1faeb054":"i = 0\nplt.figure(figsize = (6,8))\nfor c in correct[:6]:\n    plt.subplot(3,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(x_test[c].reshape(224,224), cmap=\"gray\")\n    plt.title(\"Predicted Class {},Actual Class {}\".format(preds[c], y_test[c]))\n    plt.tight_layout()\n    i += 1","9aac7112":"i = 0\nplt.figure(figsize = (6,8))\nfor c in incorrect[:6]:\n    plt.subplot(3,2,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(x_test[c].reshape(224,224), cmap=\"gray\")\n    plt.title(\"Predicted Class {},Actual Class {}\".format(incorrect[c], y_test[c]))\n    plt.tight_layout()\n    i += 1","a490f36a":"# Training set\ntrain_data = ImageDataGenerator(rescale = 1.\/255,\n                                shear_range = 0.2,\n                                zoom_range = 0.2,\n                                horizontal_flip = True)\ntrain_df = train_data.flow_from_directory('..\/input\/chest-xray-pneumonia\/chest_xray\/train',\n                                          target_size = (150,150),\n                                          batch_size = 32,\n                                          class_mode = 'binary')\n# Validation set\nval_data = ImageDataGenerator(rescale = 1.\/255)\nval_df = val_data.flow_from_directory('..\/input\/chest-xray-pneumonia\/chest_xray\/val',\n                                      target_size = (150,150),\n                                      class_mode = 'binary')\n# test set\ntest_data = ImageDataGenerator(rescale = 1.\/255)\ntest_df = test_data.flow_from_directory('..\/input\/chest-xray-pneumonia\/chest_xray\/test',\n                                        target_size = (150,150),\n                                        batch_size = 32,\n                                        class_mode = 'binary')","8ccd313e":"cnn = tf.keras.models.Sequential()\n\ncnn.add(Conv2D(filters = 32,kernel_size = (3,3),activation = 'relu',input_shape = [150,150,3]))\ncnn.add(MaxPool2D((2,2), strides=(2,2)))\n\ncnn.add(Conv2D(filters = 64,kernel_size = (3,3),activation = 'relu'))\ncnn.add(MaxPool2D((2,2), strides=(2,2)))\n\ncnn.add(Conv2D(filters = 128,kernel_size = (3,3),activation = 'relu'))\ncnn.add(MaxPool2D((2,2), strides=(2,2)))\n\ncnn.add(Conv2D(filters = 256,kernel_size = (3,3),activation = 'relu'))\ncnn.add(MaxPool2D((2,2), strides=(2,2)))\n\ncnn.add(Flatten())\n\ncnn.add(Dense(512, activation='relu'))\ncnn.add(Dropout(0.4))\n\ncnn.add(Dense(512, activation='relu'))\ncnn.add(Dropout(0.4))\n\ncnn.add(Dense(1,activation = 'sigmoid'))\ncnn.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = 'accuracy')\ncnn.summary()","3085b7a9":"cnn.fit(x = train_df,epochs = 25,batch_size = 32,validation_data = test_df)","740592d4":"cnn.evaluate(test_df)","32563bec":"# Training","a3ff67bb":"* Plotting training accuracy vs validation accuracy","8274dc3a":"# Building Cnn Model","987179d5":"# Importing Libraries","64f39267":"* Compiling the model","4add26e6":"# Model Building","5168d657":"* Data Exploration","f798e953":"* Some Basic Stuff for building dataframes","3a8e9bfe":"# Visualizations\n* Plotting some healthy and non healtyh images","0aba0a48":"* Data preprocessing\n* Building a fuction to preprocess the images","7e4e3d6f":"# Another simpler way to build a Cnn Model","f53ada0e":"* Making Confusion Matrix & Plotting it","4c8f6636":"* Plotting Some Incorrect predictions","6a305ce8":"* Prediction on test set","109b0d74":"* File path","b8e20869":"* Plotting Some correct Predictions","3a167ee0":"* Predicting on x_test","e87bd559":"* Plotting training loss vs validation loss","d2c3913c":"* Classification report","6e96bbdf":"# Image Processing","6e17694b":"* Training the model On training set ","c09bdc3c":"# Visualizations","165db944":" # Plz Upvote!!! If You Liked This NoteBook."}}