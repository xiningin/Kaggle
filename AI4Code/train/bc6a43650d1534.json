{"cell_type":{"c425d9c9":"code","2331fe9c":"code","ba6d9c6c":"code","ec4a21a5":"code","8f86c84e":"code","c4045f32":"code","b720c554":"code","0fa85e46":"code","28b3a93b":"code","e582a584":"code","3ed7482b":"code","376ad283":"code","f4068994":"code","98bf1c32":"markdown","2b15aa62":"markdown","1d9d5b0d":"markdown","d38ba6a3":"markdown","185799a0":"markdown"},"source":{"c425d9c9":"import pandas as pd, numpy as np, os\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt","2331fe9c":"PATH = '..\/input\/melanoma-oof-and-sub\/'\nFILES = os.listdir(PATH)\n\nOOF = np.sort( [f for f in FILES if 'oof' in f] )\nOOF_CSV = [pd.read_csv(PATH+k) for k in OOF]\n\nprint('We have %i oof files...'%len(OOF))\nprint(); print(OOF)","ba6d9c6c":"x = np.zeros(( len(OOF_CSV[0]),len(OOF) ))\nfor k in range(len(OOF)):\n    x[:,k] = OOF_CSV[k].pred.values\n    \nTRUE = OOF_CSV[0].target.values","ec4a21a5":"all = []\nfor k in range(x.shape[1]):\n    auc = roc_auc_score(OOF_CSV[0].target,x[:,k])\n    all.append(auc)\n    print('Model %i has OOF AUC = %.4f'%(k,auc))\n    \nm = [np.argmax(all)]; w = []","8f86c84e":"old = np.max(all); \n\nRES = 200; \nPATIENCE = 10; \nTOL = 0.0003\nDUPLICATES = False\n\nprint('Ensemble AUC = %.4f by beginning with model %i'%(old,m[0]))\nprint()\n\nfor kk in range(len(OOF)):\n    \n    # BUILD CURRENT ENSEMBLE\n    md = x[:,m[0]]\n    for i,k in enumerate(m[1:]):\n        md = w[i]*x[:,k] + (1-w[i])*md\n        \n    # FIND MODEL TO ADD\n    mx = 0; mx_k = 0; mx_w = 0\n    print('Searching for best model to add... ')\n    \n    # TRY ADDING EACH MODEL\n    for k in range(x.shape[1]):\n        print(k,', ',end='')\n        if not DUPLICATES and (k in m): continue\n            \n        # EVALUATE ADDING MODEL K WITH WEIGHTS W\n        bst_j = 0; bst = 0; ct = 0\n        for j in range(RES):\n            tmp = j\/RES*x[:,k] + (1-j\/RES)*md\n            auc = roc_auc_score(TRUE,tmp)\n            if auc>bst:\n                bst = auc\n                bst_j = j\/RES\n            else: ct += 1\n            if ct>PATIENCE: break\n        if bst>mx:\n            mx = bst\n            mx_k = k\n            mx_w = bst_j\n            \n    # STOP IF INCREASE IS LESS THAN TOL\n    inc = mx-old\n    if inc<=TOL: \n        print(); print('No increase. Stopping.')\n        break\n        \n    # DISPLAY RESULTS\n    print(); #print(kk,mx,mx_k,mx_w,'%.5f'%inc)\n    print('Ensemble AUC = %.4f after adding model %i with weight %.3f. Increase of %.4f'%(mx,mx_k,mx_w,inc))\n    print()\n    \n    old = mx; m.append(mx_k); w.append(mx_w)","c4045f32":"print('We are using models',m)\nprint('with weights',w)\nprint('and achieve ensemble AUC = %.4f'%old)","b720c554":"md = x[:,m[0]]\nfor i,k in enumerate(m[1:]):\n    md = w[i]*x[:,k] + (1-w[i])*md\nplt.hist(md,bins=100)\nplt.title('Ensemble OOF predictions')\nplt.show()","0fa85e46":"df = OOF_CSV[0].copy()\ndf.pred = md\ndf.to_csv('ensemble_oof.csv',index=False)","28b3a93b":"SUB = np.sort( [f for f in FILES if 'sub' in f] )\nSUB_CSV = [pd.read_csv(PATH+k) for k in SUB]\n\nprint('We have %i submission files...'%len(SUB))\nprint(); print(SUB)","e582a584":"# VERFIY THAT SUBMISSION FILES MATCH OOF FILES\na = np.array( [ int( x.split('_')[1].split('.')[0]) for x in SUB ] )\nb = np.array( [ int( x.split('_')[1].split('.')[0]) for x in OOF ] )\nif len(a)!=len(b):\n    print('ERROR submission files dont match oof files')\nelse:\n    for k in range(len(a)):\n        if a[k]!=b[k]: print('ERROR submission files dont match oof files')","3ed7482b":"y = np.zeros(( len(SUB_CSV[0]),len(SUB) ))\nfor k in range(len(SUB)):\n    y[:,k] = SUB_CSV[k].target.values","376ad283":"md2 = y[:,m[0]]\nfor i,k in enumerate(m[1:]):\n    md2 = w[i]*y[:,k] + (1-w[i])*md2\nplt.hist(md2,bins=100)\nplt.show()","f4068994":"df = SUB_CSV[0].copy()\ndf.target = md2\ndf.to_csv('ensemble_sub.csv',index=False)","98bf1c32":"# Read OOF Files\nWhen i get more time, I will compete this table to describe all 39 models in this notebook. For now here are the ones that get selected:\n\n| k | CV | LB | read size | crop size | effNet | ext data | upsample | misc | name |\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n| 1 | 0.910 | 0.950 | 384 | 384 | B6 | 2018 | no |  | oof_100 |\n| 3 | 0.916 | 0.946 | 384 | 384 | B345 | no | no |  | oof_108 |\n| 8 | 0.935 | 0.949 | 768 | 512 | B7 | 2018 | 1,1,1,1 |  | oof_113 |\n| 10 | 0.920 | 0.941 | 512 | 384 | B5 | 2019 2018 | 10,0,0,0 |  | oof_117 |\n| 12 | 0.935 | 0.937 | 768 | 512 | B6 | 2019 2018 | 3,3,0,0 |  | oof_120 |\n| 21 | 0.933 | 0.950 | 1024 | 512 | B6 | 2018 | 2,2,2,2 |  | oof_30 |\n| 26 | 0.927 | 0.942 | 768 | 384 | B4 | 2018 | no |  | oof_385 |\n| 37 | 0.936 | 0.956 | 512 | 384 | B5 | 2018 | 1,1,1,1 |  | oof_67 |\n","2b15aa62":"# Build SUB Ensemble","1d9d5b0d":"# Load SUB Files","d38ba6a3":"# Build OOF Ensemble. Maximize CV Score","185799a0":"# How To Ensemble OOF\nIn this notebook, we learn how to use `forward selection` to ensemble OOF. First build lots of models using the same KFolds (i.e. use same `seed`). Next save all the oof files as `oof_XX.csv` and submission files as `sub_XX.csv` where the oof and submission share the same `XX` number. Then save them in a Kaggle dataset and run the code below.\n\nThe ensemble begins with the model of highest oof AUC. Next each other model is added one by one to see which additional model increases ensemble AUC the most. The best additional model is kept and the process is repeated until the ensemble AUC doesn't increase."}}