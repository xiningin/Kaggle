{"cell_type":{"8fd868fe":"code","05ded68c":"code","4587f5d9":"code","3e87754b":"code","6de3e9a5":"code","b7f7396b":"code","f5232852":"code","b1cf3612":"code","fc7de82e":"code","6ad76baa":"code","37957082":"code","bf338966":"code","c52f01a7":"code","ad9e1630":"code","174927d1":"code","01bc953e":"code","81cebb48":"code","83b5c495":"code","56352c2a":"code","b335c524":"code","63ad1420":"code","4c4132be":"code","df6eb32d":"code","15a59236":"code","370da5b1":"code","4cce85ff":"code","b9c16f5b":"code","33a01f96":"code","2f802f16":"code","8a09ba98":"code","94b6d720":"code","3b3f5d24":"code","9a4cb00e":"code","3b613f01":"code","a06f2883":"code","bca9d02b":"code","6332ea53":"code","c57bb73d":"code","c8d8f214":"code","c08d0d6c":"code","652481ff":"code","f892a2c5":"code","a087506a":"code","4406cffa":"code","d2ece98b":"code","5fcfba76":"code","c7b87fd0":"code","3c9f30e0":"code","33485596":"code","47a9dbda":"code","1bd5905f":"code","1d0bfb41":"code","a22668da":"code","51ca1054":"code","a32b5c2e":"code","6fa7c6f3":"code","b9136fb0":"code","541ada73":"code","ab952a21":"markdown","72e7fa66":"markdown","f8881abe":"markdown","70b38a00":"markdown","0ed3860d":"markdown","3013c553":"markdown","b2b5c86c":"markdown","cbd322ca":"markdown","eafcc4b3":"markdown","e9c07ec4":"markdown","340296b5":"markdown","1e7d5e11":"markdown","518b8a52":"markdown","607af04e":"markdown","71b15d8f":"markdown","cc3ebe22":"markdown","de43312b":"markdown","70efcd55":"markdown","9b57ccbb":"markdown","88cd59e7":"markdown","92d3312c":"markdown","6f493b35":"markdown","3d21f6c7":"markdown","1d2e4ea1":"markdown","985f5261":"markdown"},"source":{"8fd868fe":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport os.path\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, precision_recall_curve, classification_report, average_precision_score\n\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import precision_score,f1_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\n\nimport dask\nimport dask.dataframe as dd\n\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","05ded68c":"from dask.distributed import Client, LocalCluster # Look into parameters of LocalCluster for arguments used","4587f5d9":"client = Client(processes=False, threads_per_worker=4, n_workers=4, memory_limit='8GB')\nclient","3e87754b":"#input data\nroot_dir = '\/kaggle\/input\/widsdatathon2021\/'\n\nsample_submission = pd.read_csv(os.path.join(root_dir, \n                    'SampleSubmissionWiDS2021.csv'))\nsolution_template = pd.read_csv(os.path.join(root_dir, \n                    'SolutionTemplateWiDS2021.csv'))\nData_dictionary = pd.read_csv(os.path.join(root_dir,   \n                   'DataDictionaryWiDS2021.csv'))\nUnlabled_data = pd.read_csv(os.path.join(root_dir,     \n                'UnlabeledWiDS2021.csv'))\nTraining_data = pd.read_csv(os.path.join(root_dir,     \n                'TrainingWiDS2021.csv'))","6de3e9a5":"display(Data_dictionary.shape)\ndisplay(Unlabled_data.shape)\ndisplay(Training_data.shape)\ndisplay(solution_template.shape)","b7f7396b":"Training_data.isna().any().any()","f5232852":"Training_data.drop('Unnamed: 0', axis = 1, inplace = True)","b1cf3612":"display(Training_data.shape)","fc7de82e":"display(Unlabled_data.shape)\nUnlabled_data.head()","6ad76baa":"Unlabled_data.isna().any().any()","37957082":"Unlabled_data.drop('Unnamed: 0', axis = 1, inplace = True)","bf338966":"display(Unlabled_data.shape)\nUnlabled_data.head()","c52f01a7":"Training_data.info(verbose=True, null_counts=True)","ad9e1630":"Training_data.dtypes.value_counts()","174927d1":"Training_data.isnull().sum()","01bc953e":"def calc_missing_values(df_name):\n    \n    '''\n    Returns total number and percentage of missing value in each column of a\n    given dataframe.    \n    '''\n    # sum of missing values in each column\n    missing_values = df_name.isnull().sum() \n    \n    # percentage of missing values in each column\n    per_missing = df_name.isnull().sum() * 100 \/ len(df_name)\n    \n    # Table with sum and percentage of missing values\n    missing_table = pd.concat([missing_values, per_missing],axis = 1)\n        \n    # Assign column names\n    missing_table_rename = missing_table.rename(columns ={0: 'Missing Values', 1:'% of missing values'})\n    \n    # Sort it by percentage of missing values\n    \n    sorted_table = missing_table_rename[missing_table_rename.iloc[:,1] !=0].\\\n    sort_values('% of missing values', ascending = False).round(1)\n    \n    print('Out of ' + str(df_name.shape[1])+ ' columns in this dataframe '+ str(sorted_table.shape[0])+ \\\n                         ' columns have missing values')\n    \n    return sorted_table\n        ","81cebb48":"# Training data\nmissing_train = calc_missing_values(Training_data)\nmissing_train[:20].style.background_gradient(cmap='viridis')","83b5c495":"# Test data\nmissing_test = calc_missing_values(Unlabled_data)\nmissing_test[:20].style.background_gradient(cmap='cividis')","56352c2a":"#train_df = klib.data_cleaning(Training_data) # removes duplicate and empty row\/cols","b335c524":"#test_df = klib.data_cleaning(Unlabled_data) # removes duplicate and empty row\/cols#","63ad1420":"train_df = Training_data\ntest_df = Unlabled_data","4c4132be":"train_df['diabetes_mellitus'].value_counts(normalize = True)","df6eb32d":"train_df['diabetes_mellitus'].astype(int).plot.hist();","15a59236":"#klib.corr_plot(train_df, target='diabetes_mellitus') # correlation of target variable with other features#","370da5b1":" train_df.dtypes","4cce85ff":"cat_col_train = Training_data.select_dtypes('object').columns\ndisplay(len(cat_col_train))\ndisplay(cat_col_train)","b9c16f5b":"#visualization of the number and frequency of categorical features\n#klib.cat_plot(train_df)","33a01f96":"cat_col_test = Unlabled_data.select_dtypes('object').columns\ndisplay(len(cat_col_test))\ndisplay(cat_col_test)","2f802f16":"#klib.cat_plot(test_df)","8a09ba98":"cat_list = Training_data.select_dtypes('object').columns\ndisplay(cat_list)","94b6d720":"# Creating Label Encoder object\nle = LabelEncoder()\nfor ob in cat_list:\n    train_df[ob] = le.fit_transform(train_df[ob].astype(str))\n    test_df[ob] = le.fit_transform(test_df[ob].astype(str))\nprint(train_df.info())    \nprint(test_df.info()) ","3b3f5d24":"train_df.fillna(-9999,inplace = True)\ntrain_df.isnull().sum()","9a4cb00e":"test_df.fillna(-9999,inplace = True)\ntest_df.isnull().sum()","3b613f01":"Target = 'diabetes_mellitus'\ntrain_labels = train_df[Target]\ntrain_df_NT = train_df.drop(columns = [Target])\nfeatures = list(train_df_NT.columns)\nprint('Training data shape:', train_df_NT.shape)\nprint('Test data shape:', test_df.shape)","a06f2883":"X, y = train_df_NT, train_labels","bca9d02b":"#convert the dataset into an optimized data structure called Dmatrix that \n#XGBoost supports and gives it acclaimed performance and efficiency gains.\ndata_dmatrix = xgb.DMatrix(data=X,label=y)","6332ea53":"#create the train and validation set for cross-validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123)","c57bb73d":"scaler = StandardScaler()\n\n# Fit on training set only.\nscaler.fit(X_train)\n\n# Apply transform to both the training set and the test set.\nX_train = scaler.transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(test_df)","c8d8f214":"# Make an instance of the Model\npca = PCA(.90)","c08d0d6c":"pca.fit(X_train)","652481ff":"pca.n_components_","f892a2c5":"# Apply the mapping (transform) to both the training set and the test set.\nX_train = pca.transform(X_train)\nX_val = pca.transform(X_val)\nX_test = pca.transform(test_df)","a087506a":"#Instantiate an XGBoost classifier object by calling the XGBClassifier() class from the XGBoost \n#library with the hyper-parameters passed as arguments.\nxgb_cls = xgb.XGBClassifier(\n    max_depth = 6,\n    subsample = 1,\n    colsample_bytree = 0.7,\n    colsample_bylevel = 0.7,\n    scale_pos_weight = 1,\n    min_child_weight = 1,\n    reg_alpha = 4,\n    n_jobs = 4, \n    objective = 'binary:logistic',\n    nthread=4,\n    gamma = 0.05,\n    seed = 27,\n    #n_estimators=1000,\n)","4406cffa":"#Fit the classifier to the training set and make predictions on the \n#test set using the familiar .fit() and .predict() methods\n\n# ### Fit Model with Dask\nfrom joblib import Parallel, parallel_backend\nwith parallel_backend('dask'):\n  \n    xgb_cls.fit(X_train,y_train)\n\n    y_pred = xgb_cls.predict_proba(X_val)","d2ece98b":"y_scores = y_pred[:, 1]","5fcfba76":"fpr, tpr, _ = roc_curve(y_val, y_scores)\nroc_auc = auc(fpr, tpr)\naverage_precision = average_precision_score(y_val, y_scores)\nprecision, recall, _ = precision_recall_curve(y_val, y_scores)","c7b87fd0":"def roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='purple', label='ROC')\n    plt.plot([0, 1], [0, 1], color='yellow', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","3c9f30e0":"roc_curve(fpr, tpr)\nprint('AUC :',roc_auc_score(y_val,y_scores))","33485596":"xgb.plot_tree(xgb_cls,num_trees=0)\n#plt.rcParams['figure.figsize'] = [50, 20]\nplt.show()","47a9dbda":"print(xgb_cls.feature_importances_)","1bd5905f":"# a bar chart of the relative importances.\nplt.bar(range(len(xgb_cls.feature_importances_)), xgb_cls.feature_importances_)\nplt.show()","1d0bfb41":"xgb.plot_importance(xgb_cls)\nplt.rcParams['figure.figsize'] = [50, 15]\nplt.show()","a22668da":"print(roc_auc)","51ca1054":"#df_feature_importance = pd.DataFrame(xgb_cls.feature_importances_, index=features, columns=['feature importance']).sort_values('feature importance', ascending=False)\n#df_feature_importance","a32b5c2e":"#thresholds = df_feature_importance['feature importance'].to_list()\n#thresholds","6fa7c6f3":"\n# Make sure to select the second column only\nxgb_cls_pred = xgb_cls.predict_proba(X_test)[:,1]","b9136fb0":"xgb_cls_pred","541ada73":"# Submission dataframe\nsubmit = test_df[['encounter_id']]\nsubmit['diabetes_mellitus'] = xgb_cls_pred\nsubmit.to_csv('xgb_cls_pca.csv',index=False)\nsubmit.head()","ab952a21":"## Missing values","72e7fa66":"Training data has 130157 entries and 180 variables. ","f8881abe":"There are some missing data in training data.","70b38a00":"## Test data","0ed3860d":"## <span style='color:purple'>  Import libraries <\/span>","3013c553":"# <span style='color:purple'>  Women in Data Science Datathon 2021       <\/span>\n\n<div style=\"text-align: justify;\n             font-size:18px\">\nObjective of <span style='color:purple'> WiDS Datathon 2021  <\/span> is to develop models and make predictions to determine whether a patient admitted to ICU has been diagnosed with a particular type of diabetes, Diabetes Mellitus, using labeled training data from the first 24 hours of intensive care.\n    <\/div>","b2b5c86c":"# Feature Correlation","cbd322ca":"There are three unique datatypes.","eafcc4b3":"# References\n\nhttps:\/\/www.kaggle.com\/kabure\/eda-feat-engineering-with-xgboosting\/comments#320806\n\nhttps:\/\/www.kaggle.com\/parulpandey\/starter-code-with-baseline\n\nhttps:\/\/www.kaggle.com\/puneetgrover\/speed-up-your-algorithms-dask\nhttps:\/\/www.kaggle.com\/ryanholbrook\/mutual-information\n\n\n\n","e9c07ec4":"### Columns","340296b5":"Training data has 130157 entries and 181 variables. ","1e7d5e11":"Test data has 10234 entries and 179 variables which is 1 less than the training data due to the presence of TARGET column.","518b8a52":"# Missing  data handling","607af04e":"There is class imbalance in this dataset.","71b15d8f":"## Training data","cc3ebe22":"# Missing Values","de43312b":"# Categorical features","70efcd55":"## Target Column in Training data","9b57ccbb":"# Feature Selection","88cd59e7":"This column do not contain useful information so let's drop it.","92d3312c":"### Column types in training and test data","6f493b35":"## <span style='color:purple'> Input data <\/span>","3d21f6c7":"## <span style='color:purple'> Data Exploration <\/span>\n","1d2e4ea1":"# Feature importance","985f5261":"### Number of unique column datatypes "}}