{"cell_type":{"9b88ef1f":"code","2ef21586":"code","571b41b1":"code","df9f06ad":"code","dbe77965":"code","37049632":"code","da81facc":"code","75f95b2a":"code","6d8a088b":"code","a33e97f4":"code","3c456c7f":"code","5cbb5009":"code","22d58890":"code","9d4cea6b":"code","768b4ed2":"markdown","13f59730":"markdown"},"source":{"9b88ef1f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2ef21586":"data = pd.read_csv(os.path.join(dirname, filename))\n\n## Exploring major factors that are boosting to the Attrition %\n\ncol_val_nunique = [data[c].nunique() for c in data.columns]\nplt.figure(figsize=(10,10))\nplt.scatter(col_val_nunique,data.columns)\nplt.show()\n\n## Most of the columns are having distinct values < 20, can be explored using the groupby method to explore contrubuting factors of attrition","571b41b1":"# Function to get Columnname and Dataframe and hilight the groups that are exceeding the average attrition % and displaing the guided value\n\ndef Visualize_Group_By_Column(cname, data):\n    #Calculate % of attrition using overall data\n    gv = data.groupby(by=['Attrition']).get_group('Yes').Attrition.count() \/ data.index.size\n    \n    data_x = data.groupby(by=[cname,'Attrition']).Attrition.count()\n    data_y = data.groupby(by=[cname,'Attrition']).groups.keys()\n    data_x_lst = [x for x in data_x]\n    data_y_lst = [cname + ''.join(str(y)) for y in data_y]\n    data_z_lst = [data.groupby(by=[cname]).get_group(k).index.size for k in data.groupby(by=[cname]).groups.keys()]\n    \n    #Calculate count of expected attrition using gv\n    list2 = [nn for m in [h for h in zip(data_z_lst, list(map(lambda x:x*gv, data_z_lst)))] for nn in m]\n    plt.figure(figsize=(15,10))\n    bars = plt.bar(data_y_lst, data_x_lst, color='maroon', width=0.1)\n    plt.plot(list2,\"--\")\n    for b,j in zip(bars,list2):\n        vx = str(round(b.get_height(),0)) + \" > \" + str(round(j,2))\n    \n    #Identify attrition rate exceeding the guided count value\n        if (b.get_height() > j):\n            plt.text(b.get_x(), b.get_height() + 0.2, vx)\n            b.set_color('r')\n    plt.xticks(rotation=45, ha='right')\n    plt.title(\"Grouped by \" + cname)\n    plt.show()","df9f06ad":"## Choosing only columns having distinct values < 15 for exploratory analsysis\nfor c in data.columns:\n    if data[c].nunique() > 2 and data[c].nunique() < 15:\n        print(c)","dbe77965":"## Use defining function against column BussinessTravel\n\nx = Visualize_Group_By_Column('BusinessTravel',data)\n\n## Result -> Group \"Travel Frequently\" contribute for higher Attrition","37049632":"## Use defining function against column BussinessTravel\n\nx = Visualize_Group_By_Column('Department',data)\n\n## Result -> Departments \"HumanResources\" and \"Sales\" contribute to higher attrition","da81facc":"## Use defining function against column Education\n\nx = Visualize_Group_By_Column('Education',data)\n\n## Result -> Employees having education level 1 and 3 slightly exceeded the attrition value","75f95b2a":"## Use defining function against column EducationField\n\nx = Visualize_Group_By_Column('EducationField',data)\n\n## Result -> Employees beloning to \"HumarnResources\", \"Marketting\" and \"Technical Degress\" have more attrition","6d8a088b":"## Use defining function against column EnvironmentSatisfaction\n\nx = Visualize_Group_By_Column('EnvironmentSatisfaction',data)\n\n## Result -> Employees having lesser environment Satisfaction contribute more attrition","a33e97f4":"## Use defining function against column JobInvolvement\n\nx = Visualize_Group_By_Column('JobInvolvement',data)\n\n## Result -> Employees with lesser job involvement contribute more to Attrition","3c456c7f":"## Use defining function against column JobLevel\n\nx = Visualize_Group_By_Column('JobLevel',data)\n\n## Result -> Employees in Job Level 1 contribute more to Attrition","5cbb5009":"## Use defining function against column JobRole\n\nx = Visualize_Group_By_Column('JobRole',data)\n\n## Result -> Similar to Department, Jobroles in department 'HumanResources', 'Technical' and 'Sales' have more attrition rates","22d58890":"## Use defining function against column MaritalStatus\n\nx = Visualize_Group_By_Column('MaritalStatus',data)\n\n## Result -> Employees with Marital Status Single contribute more to Attrition","9d4cea6b":"## Use defining function against column WorkLifeBalance\n\nx = Visualize_Group_By_Column('WorkLifeBalance',data)\n\n## Result -> Worklife balance may not be a much contributor as Attrition is higher across all groups","768b4ed2":"though all types of business travel contribute to Attrition, Employees travelling frequently have higher attrition compared to expected level 45.","13f59730":"thanks for reading my analysis, Kindly share feed back!!."}}