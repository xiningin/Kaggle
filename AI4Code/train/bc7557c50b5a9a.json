{"cell_type":{"7bc03924":"code","ab876881":"code","9b2847cc":"code","b1c4f277":"code","5af17302":"code","9400ee6a":"code","055cb781":"code","14d832c1":"code","96250eac":"code","4a2cff50":"code","991bec8f":"code","280ff6cc":"code","0fe93694":"code","a8fd4716":"code","1bbb18d7":"code","3fcb4aac":"code","1f0c71bc":"code","dd2611fa":"code","e41a3340":"code","a5f5eea0":"code","f89f5067":"code","62497324":"code","a1b1adde":"code","30400e6a":"code","36dbabe4":"code","02923066":"code","8bd37552":"markdown","963ab688":"markdown","d8b4cc09":"markdown","9ccc712f":"markdown","57d6f34b":"markdown","4aff59a3":"markdown","fb122b67":"markdown","942a9bd3":"markdown","185f0d8f":"markdown","15cde9f6":"markdown"},"source":{"7bc03924":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ab876881":"import nltk","9b2847cc":"#Bigrams represent a set of two consecutive words appearing in a text.\n#bigrams function is called on tokenized words, as shown in the following example, to obtain bigrams.\ns = 'Python is an awesome language.'\ntokens = nltk.word_tokenize(s)","b1c4f277":"list(nltk.bigrams(tokens))","5af17302":"#Now let's find out three frequently occurring bigrams, present in english-kjv collection of genesis corpus.\n#Let's consider only those bigrams, whose words are having a length greater than 5\n#Working with Genesis Corpus\nfrom nltk.corpus import genesis\neng_tokens = genesis.words('english-kjv.txt')","9400ee6a":"eng_bigrams = nltk.bigrams(eng_tokens)\n#bigrams with length greater than or equal to 5\nfiltered_bigrams = [ (w1, w2) for w1, w2 in eng_bigrams if len(w1) >=5 and len(w2) >= 5 ]","055cb781":"#After computing bi-grams, the following code computes frequency distribution and displays three most frequent bigrams.\neng_bifreq = nltk.FreqDist(filtered_bigrams)\n#Most Common top 3\neng_bifreq.most_common(3)","14d832c1":"eng_tokens = genesis.words('english-kjv.txt')\neng_bigrams = nltk.bigrams(eng_tokens)\n#Now let's see an example which determines the two most frequent words occurring after 'living' are determined.\neng_cfd = nltk.ConditionalFreqDist(eng_bigrams)\neng_cfd['living'].most_common(2)","96250eac":"#Now let's define a function named generate, which returns words occurring frequently after a given word.\ndef generate(cfd, word, n=5):\n    n_words = []\n    for i in range(n):\n         n_words.append(word)\n         word = cfd[word].max()\n    return n_words    ","4a2cff50":"#Generating Most Frequent Next Word\ngenerate(eng_cfd, 'living')","991bec8f":"#Working with Brown Corpus","280ff6cc":"#Import text corpus brown\n#Extract the list of words associated with text collections belonging to news genre. Store the result in variable news_words.\n#Convert each word of list news_words into lower case and store the result in lc_news_words.\n#Compute length of each word present in list lc_news_words and store the result in list len_news_words\n#Compute bigrams of list len_news_words. Store the result in variable news_len_bigrams.\n#Compute the conditional frequency of news_len_bigrams, where condition and event refers to length of a words. Store the result in cfd_news\n#Determine the frequency of 6-letter words appearing next to a 4-letter word.","0fe93694":"from nltk.corpus import brown\nlist((genre, word) for genre in brown.categories() for word in brown.words(categories=genre))","a8fd4716":"from nltk.corpus import brown\nnews_words = brown.words(categories='news')\nlc_news_words = map(lambda x:x.lower(),news_words)\nlen_news_words = map(lambda x:len(x),news_words)\nnews_len_bigrams = list(nltk.bigrams(len_news_words))\ncfd_news = nltk.ConditionalFreqDist(news_len_bigrams)\nprint([(i,j) for i,j in cfd_news[4].most_common(25) if i == 6][0][1])","1bbb18d7":"cfd_news[4].most_common(25)","3fcb4aac":"#Compute bigrams of list lc_news_words and store in variable lc_news_bigrams.\n#From lc_news_bigrams filter those bigrams, whose both words contain only alphabet characters. Store the result in lc_news_alpha_bigrams.\n#Extract the list of words associated with corpus stopwords. Store the result in stop_words.\n#Convert each word of list stop_words into lower case and store the result in lc_stop_words.\n#Filter only those bigrams from lc_news_alpha_bigrams, whose words are not part of lc_stop_words. Store the result in lc_news_alpha_nonstop_bigrams.\n#Print the total number of filtered bigrams.","1f0c71bc":"#Promblem 1\nimport nltk\nfrom nltk.corpus import brown\nnews_words = brown.words(categories='news')\nlc_news_words = map(lambda x:x.lower(),news_words)\nlen_news_words = map(lambda x:len(x),news_words)\nnews_len_bigrams = list(nltk.bigrams(len_news_words))\ncfd_news = nltk.ConditionalFreqDist(news_len_bigrams)\nprint([(i,j) for i,j in cfd_news[4].most_common(25) if i == 6][0][1])\nlc_news_words = map(lambda x:x.lower(),news_words)\n#Problem 2\n#Bigrams of News Words\nlc_news_bigrams = list(nltk.bigrams(lc_news_words))\n#Filtered BiGrams\nlc_news_alpha_bigrams = [ (w1, w2) for w1, w2 in lc_news_bigrams if w1.isalpha()==True and w2.isalpha()==True]\nfrom nltk.corpus import stopwords\n#Stopwords\nstop_words = stopwords.words()\nlc_stop_words = [w.lower() for w in stop_words]\n#List of Bigrams not part of Stop Words\nlc_news_alpha_nonstop_bigrams = [(w1, w2) for w1, w2 in lc_news_alpha_bigrams if not w1 in lc_stop_words and not w2 in lc_stop_words]\n#Total Number of Bigrams\nprint(len(lc_news_alpha_bigrams) + len(lc_news_alpha_nonstop_bigrams))","dd2611fa":"s = 'Python is cool!!!'\ntokens = nltk.word_tokenize(s)\nlist(nltk.trigrams(tokens))","e41a3340":"#The following example displays a list of four consecutive words appearing in the text s.\ns = 'Python is an awesome language.'\ntokens = nltk.word_tokenize(s)\nlist(nltk.ngrams(tokens, 4))","a5f5eea0":"#A collocation is a pair of words that occur together, very often.\n#For example, red wine is a collocation.\n#One characteristic of a collocation is that the words in it cannot be substituted with words having similar senses.\n#For example, the combination maroon wine sounds odd.\n#Generating Collocations:\nfrom nltk.corpus import genesis\ntokens = genesis.words('english-kjv.txt')\ngen_text = nltk.Text(tokens)\ngen_text.collocations()","f89f5067":"from nltk.book import text6","62497324":"eng_bigrams = nltk.bigrams(text6.tokens)\neng_bifreq = nltk.FreqDist(eng_bigrams)","a1b1adde":"#Frequency of Bigram ('BLACK', 'KNIGHT')\neng_bifreq[('BLACK', 'KNIGHT')]","30400e6a":"#Frequency of Bigram ('HEAD', 'KNIGHT')\neng_bifreq[('HEAD', 'KNIGHT')]","36dbabe4":"#Frequency of Bigram ('clop', 'clop')\neng_bifreq[('clop', 'clop')]","02923066":"#most frequent words occurring after 'Holy'\neng_tokens = text6.tokens\neng_bigrams = nltk.bigrams(eng_tokens)\n#Now let's see an example which determines the two most frequent words occurring after 'living' are determined.\neng_cfd = nltk.ConditionalFreqDist(eng_bigrams)\neng_cfd['Holy'].most_common(2)","8bd37552":"### Generating Frequent Next Word:","963ab688":"### Collocations:","d8b4cc09":"### Trigrams","9ccc712f":"### Problem Statement 1","57d6f34b":"## BiGrams","4aff59a3":"### Determining Frequent After Words:","fb122b67":"### Computing Frequent Bigrams:","942a9bd3":"Problem Statement 2","185f0d8f":"### Additional Assignments","15cde9f6":"### Ngrams:\n#nltk also provides the function ngrams. It can be used to determine a set of all possible n consecutive words appearing in a text."}}