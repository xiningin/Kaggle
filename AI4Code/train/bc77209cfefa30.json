{"cell_type":{"303316d8":"code","7200ccf7":"code","2a8ba82f":"code","54ff6002":"code","28ba6508":"code","aca221a8":"code","5a357fd7":"code","db5c6774":"code","0291cadc":"code","db255348":"code","fd08b4b5":"markdown","d58bde4b":"markdown","f70809d1":"markdown","576e9a60":"markdown","d3f243c2":"markdown","211e1087":"markdown","60d07a20":"markdown","fbf7cd41":"markdown","b4e3ed3e":"markdown","22160028":"markdown"},"source":{"303316d8":"# importing libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Conv2D, Input, Conv2DTranspose, Activation, BatchNormalization, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras import regularizers\nimport tensorflow as tf","7200ccf7":"(train_data_clean, _), (test_data_clean, _) = cifar10.load_data()\n\n# scaling input data\ntrain_data_clean = train_data_clean.astype('float32') \/ 255.\ntest_data_clean = test_data_clean.astype('float32') \/ 255.\n\ndef add_noise_and_clip_data(data):\n    noise = np.random.normal(loc = 0.0, scale = 0.3, size = data.shape)\n    data = data + noise * 0.3\n    data = np.clip(data, 0., 1.)\n    return data\n\ntrain_data_noisy = add_noise_and_clip_data(train_data_clean)\ntest_data_noisy = add_noise_and_clip_data(test_data_clean)","2a8ba82f":"rows = 3 # defining no. of rows in figure\ncols = 5 # defining no. of colums in figure\n\nf = plt.figure(figsize = (2 * cols, 2 * rows * 2)) # defining a figure \n\nfor i in range(rows):\n    for j in range(cols): \n        f.add_subplot(rows * 2, cols, (2 * i * cols) + (j + 1)) # adding sub plot to figure on each iteration\n        plt.imshow(train_data_noisy[i * cols + j]) \n        plt.axis(\"off\")\n    \n    for j in range(cols): \n        f.add_subplot(rows * 2, cols, ((2 * i + 1) * cols) + (j + 1)) # adding sub plot to figure on each iteration\n        plt.imshow(train_data_clean[i * cols + j]) \n        plt.axis(\"off\")\n        \nf.suptitle(\"Sample Training Data\", fontsize = 18)\nplt.savefig(\"Cifar-trian.png\")\n\nplt.show()","54ff6002":"def conv_block(x, filters, kernel_size, strides = 2):\n    x = Conv2D(filters = filters,\n               kernel_size = kernel_size,\n               strides = strides,\n               padding = 'same',\n               activation = 'relu',\n               kernel_regularizer = regularizers.l2(0.001))(x)\n    x = BatchNormalization()(x)\n    return x\n\ndef deconv_block(x, filters, kernel_size):\n    x = Conv2DTranspose(filters = filters,\n                        kernel_size = kernel_size,\n                        strides = 2,\n                        padding = 'same',\n                        activation = 'relu',\n                        kernel_regularizer = regularizers.l2(0.001))(x)\n    x = BatchNormalization()(x)\n    return x","28ba6508":"def autoencoder():\n    inputs = Input(shape = (32, 32, 3), name = 'inputs')\n    conv_block1 = conv_block(inputs, 32, 3)\n    conv_block2 = conv_block(conv_block1, 64, 3)\n    conv_block3 = conv_block(conv_block2, 128, 3)\n    conv_block4 = conv_block(conv_block3, 256, 3)\n    conv_block5 = conv_block(conv_block4, 256, 3)\n    conv_block6 = conv_block(conv_block5, 512, 3, 1)\n    \n    deconv_block1 = deconv_block(conv_block6, 512, 3)\n    merge1 = Concatenate()([deconv_block1, conv_block4])\n    deconv_block2 = deconv_block(merge1, 256, 3)\n    merge2 = Concatenate()([deconv_block2, conv_block3])\n    deconv_block3 = deconv_block(merge2, 128, 3)\n    merge3 = Concatenate()([deconv_block3, conv_block2])\n    deconv_block4 = deconv_block(merge3, 64, 3)\n    merge4 = Concatenate()([deconv_block4, conv_block1])\n    deconv_block5 = deconv_block(merge4, 32, 3)\n    \n    final_deconv = Conv2DTranspose(filters = 3, kernel_size = 3, padding = 'same')(deconv_block5)\n    outputs = Activation('sigmoid', name = 'output')(final_deconv)\n    return Model(inputs, outputs, name = 'autoencoder')","aca221a8":"model = autoencoder()\n\ndef scheduler(epoch):\n    if epoch < 10:\n        return 0.0001\n    else:\n        return 0.0001 * tf.math.exp(0.1 * (10 - epoch))\n\nclass myCallback(Callback):\n    def on_epoch_end(self, epoch, logs = {}):\n        if(logs.get('accuracy') > 0.80):\n            print(\"\\nReached 80% accuracy so cancelling training!\")\n            self.model.stop_training = True\n\ncallbacks = myCallback()\n\nlr = LearningRateScheduler(scheduler)\ncheckpoint = ModelCheckpoint('best_model.h5', verbose = 1, save_best_only = True, save_weights_only = True)\n\nmodel.compile(optimizer = \"adam\", loss = 'mse', metrics=[\"accuracy\"])\nmodel.summary()","5a357fd7":"# Training\nhistory = model.fit(train_data_noisy,\n                    train_data_clean,\n                    validation_data = (test_data_noisy, test_data_clean),\n                    epochs = 25,\n                    batch_size = 128,\n                    shuffle = True,\n                    callbacks = [checkpoint, callbacks, lr])","db5c6774":" # Defining Figure\nf = plt.figure(figsize=(10,7))\nf.add_subplot()\n\n#Adding Subplot\nplt.plot(history.epoch, history.history['loss'], label = \"loss\") # Loss curve for training set\nplt.plot(history.epoch, history.history['val_loss'], label = \"val_loss\") # Loss curve for validation set\n\nplt.title(\"Loss Curve\",fontsize=18)\nplt.xlabel(\"Epochs\",fontsize=15)\nplt.ylabel(\"Loss\",fontsize=15)\nplt.grid(alpha=0.3)\nplt.legend()\nplt.savefig(\"Loss_curve_cifar10.png\")\nplt.show()","0291cadc":"# Select few random test images\nnum_imgs = 48\nrand = np.random.randint(1, test_data_noisy.shape[0]-48) \n\ncifar_test_images = test_data_noisy[rand:rand+num_imgs] # slicing\ncifar_test_predicted = model.predict(cifar_test_images) # predict","db255348":"rows = 4 # defining no. of rows in figure\ncols = 12 # defining no. of colums in figure\ncell_size = 1.5\nf = plt.figure(figsize=(cell_size*cols,cell_size*rows*2)) # defining a figure \nf.tight_layout()\nfor i in range(rows):\n    for j in range(cols): \n        f.add_subplot(rows * 2, cols, (2 * i * cols) + (j + 1)) # adding sub plot to figure on each iteration\n        plt.imshow(cifar_test_images[i * cols + j]) \n        plt.axis(\"off\")\n    \n    for j in range(cols): \n        f.add_subplot(rows * 2, cols, ((2 * i+ 1) * cols) + (j + 1)) # adding sub plot to figure on each iteration\n        plt.imshow(cifar_test_predicted[i * cols + j]) \n        plt.axis(\"off\")\n\nf.suptitle(\"Autoencoder Results - Cifar10\",fontsize=18)\nplt.savefig(\"test_results_cifar10.png\")\n\nplt.show()","fd08b4b5":"# Denoising using Autoencoder","d58bde4b":"Load the CIFAR10 dataset having shape of [32, 32, 3]. Rescale data to [0, 1] by dividing with 255.\n\n## Adding noice\n\nTo add noise we can generate array with same dimension of our images with random values between `[0,1]` using normal distribution with mean = 0 and standard deviation = 0.3.\n\nTo generate normal distribution, we can use `np.random.normal(loc,scale,size)`. Then scale the noise by some factor, here I am using `0.3`. After adding noise, pixel values can be out of range `[0,1]`, so we need to clip the values using `np.clip(arr, arr_min, arr_max )`.","f70809d1":"## Components\n1. Enoder: Reduce the data into low dimension\n2. Decoder: Takes an encoded version of input and regenerate the data in higher dimension\n3. Bottleneck: Compressed version of data","576e9a60":"# Step 4: Test the performance of Autoencoder","d3f243c2":"# steps \n1. Prepare input data by adding noise to CIFAR10 dataset\n2. Build a CNN Autoencoder Network\n3. Train the network\n4. Test the performance of Autoencoder","211e1087":"# Step 2: Build a CNN Autoencoder Network","60d07a20":"## Visualise Noisy Images","fbf7cd41":"# Step 1: Prepare input data by adding noise to CIFAR10 dataset","b4e3ed3e":"- 5 convolutional blocks with downsampling\n- 1 convolutional block without downsampling\n- 5 deconvolutional blocks with upsampling, interleaving concatenations\n- 1 final deconvolution that recreates image size (32, 32, 3)\n- 1 activation layer with sigmoid that scales values to 0-1.","22160028":"## Architecture\n\nConvolutional blocks consist of 3 operations: 2D convolution, batch normalization and ReLu activation. We use strides=2 to downsample data going through the network.\n\nDeconvolutional blocks also consist of 3 operations: 2D transposed convolution, batch normalization and also ReLu activation. Here strides=2 is used to upsample the data."}}