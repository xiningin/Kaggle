{"cell_type":{"02ca6c1b":"code","7cd5bd1a":"code","e8053117":"code","a6cb705c":"code","51bc7876":"code","6a9f9e82":"code","30761869":"code","dbe5c512":"code","cc2c3ce0":"code","9f1c82fe":"code","7e828519":"code","593bafa1":"code","3132aa10":"code","087e8327":"code","7fc69beb":"code","5e9c7796":"code","19b78642":"code","b287a2c4":"code","86666449":"code","061fa21a":"code","7da61ea1":"code","06856717":"code","24510803":"code","564f83be":"code","6a69e48e":"code","2516db23":"code","adcd5924":"code","0d096cbd":"code","bbb7f7ee":"code","fbe4c271":"code","b2a5eec5":"code","d87f89fb":"code","92ad0202":"code","5013fc89":"code","cf67ead1":"code","85eb6e15":"code","11377f09":"code","ec816301":"code","304dfbc6":"code","a907e23a":"code","a061e24e":"code","0f3ab30f":"code","6eb02fb5":"code","eec94cc1":"code","5e33722f":"code","d47e1f0f":"code","cb878b43":"code","12da5fe5":"code","b69fb6f4":"code","1fc34abc":"code","d336f94d":"code","19eaec53":"code","a36b6769":"code","ba330967":"code","7494918b":"code","09102129":"code","e68c5e46":"code","4918282b":"code","35b2d655":"code","f50a4b56":"code","3dd68075":"code","4ad318c3":"code","06385dfb":"code","4a6881fc":"code","5507241c":"code","c3f06c62":"code","06c76d79":"code","a3e71032":"code","1650db7d":"code","09a8675d":"code","ebf82f31":"code","1ec90871":"code","21835a7b":"code","f690e7a4":"markdown","27b92ee2":"markdown","3e0a3995":"markdown","68adede2":"markdown","32d8fa96":"markdown","198a1134":"markdown","fb91b77a":"markdown","6b6db62d":"markdown","bcb569fd":"markdown","bafdfe3b":"markdown"},"source":{"02ca6c1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7cd5bd1a":"import PIL\nimport PIL.Image\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom matplotlib import pyplot as plt\n\nprint(tf.__version__)","e8053117":"import pathlib\ndata_dir = pathlib.Path('\/kaggle\/input\/aerialimagedataset\/AID\/')\ndata_dir","a6cb705c":"image_count = len(list(data_dir.glob('*\/*.jpg')))\nprint(image_count)","51bc7876":"mountains = list(data_dir.glob('Mountain\/*'))\nPIL.Image.open(str(mountains[0]))","6a9f9e82":"from struct import unpack\nfrom tqdm import tqdm_notebook\n\nmarker_mapping = {\n    0xffd8: \"Start of Image\",\n    0xffe0: \"Application Default Header\",\n    0xffdb: \"Quantization Table\",\n    0xffc0: \"Start of Frame\",\n    0xffc4: \"Define Huffman Table\",\n    0xffda: \"Start of Scan\",\n    0xffd9: \"End of Image\"\n}\n\n\nclass JPEG:\n    def __init__(self, image_file):\n        with open(image_file, 'rb') as f:\n            self.img_data = f.read()\n    \n    def decode(self):\n        data = self.img_data\n        while(True):\n            marker, = unpack(\">H\", data[0:2])\n            # print(marker_mapping.get(marker))\n            if marker == 0xffd8:\n                data = data[2:]\n            elif marker == 0xffd9:\n                return\n            elif marker == 0xffda:\n                data = data[-2:]\n            else:\n                lenchunk, = unpack(\">H\", data[2:4])\n                data = data[2+lenchunk:]            \n            if len(data)==0:\n                raise TypeError(\"issue reading jpeg file\")       \n\n\nbads = []\n\nfor img in tqdm_notebook(list(data_dir.glob('*\/*.jpg'))):\n    image = str(img)\n    image = JPEG(image) \n    try:\n        image.decode()   \n    except:\n        bads.append(img)\n","30761869":"bads","dbe5c512":"batch_size = 32\nimg_height = 256\nimg_width = 256\nseed=42","cc2c3ce0":"train_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.1,\n  subset=\"training\",\n  shuffle=True,\n  seed=seed,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","9f1c82fe":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.1,\n  subset=\"validation\",\n  seed=seed,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","7e828519":"class_names = train_ds.class_names\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","593bafa1":"val_batches = tf.data.experimental.cardinality(val_ds)\nval_batches \/\/ 5","3132aa10":"test_ds = val_ds.take(val_batches \/\/ 5)\nval_ds = val_ds.skip(val_batches \/\/ 5)","087e8327":"print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\nprint('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))","7fc69beb":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\ntest_ds = test_ds.prefetch(buffer_size=AUTOTUNE)","5e9c7796":"data_augmentation = tf.keras.Sequential([\n  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n  tf.keras.layers.RandomRotation(0.2),\n])","19b78642":"num_classes = len(class_names)\nnum_classes","b287a2c4":"bs_model = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1.\/255),\n  data_augmentation,\n  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(num_classes)\n])\n\nbs_model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","86666449":"epochs=8\nhistory = bs_model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","061fa21a":"loss, acc = bs_model.evaluate(test_ds)\nprint(\"Accuracy\", acc)","7da61ea1":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","06856717":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","24510803":"# Create the base model from the pre-trained model MobileNet V2\nimg_size = (img_height, img_width) + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=img_size,\n                                               include_top=False,\n                                               weights='imagenet')","564f83be":"image_batch, label_batch = next(iter(train_ds))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","6a69e48e":"base_model.trainable = False","2516db23":"# Let's take a look at the base model architecture\nbase_model.summary()","adcd5924":"# To generate predictions from the block of features, average over the spatial 5x5 spatial locations,\n# using a tf.keras.layers.GlobalAveragePooling2D layer to convert the features to a single 1280-element vector per image.\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n# feature_batch_average = global_average_layer(feature_batch)","0d096cbd":"prediction_layer = tf.keras.layers.Dense(len(class_names), activation='softmax')","bbb7f7ee":"# Build a model by chaining together the data augmentation, rescaling, base_model and feature extractor layers using the Keras Functional API.\n# We use training=False as our model contains a BatchNormalization layer.\ninputs = tf.keras.Input(shape=img_size)\nx = data_augmentation(inputs)\nx = tf.keras.layers.Rescaling(1.\/255)(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","fbe4c271":"base_learning_rate = 0.001\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=base_learning_rate, momentum=0.9),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\nprint(model.summary())","b2a5eec5":"len(model.trainable_variables)","d87f89fb":"initial_epochs = 10\nloss0, accuracy0 = model.evaluate(val_ds)","92ad0202":"print(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))","5013fc89":"history = model.fit(train_ds,\n                    epochs=initial_epochs,\n                    validation_data=val_ds)","cf67ead1":"loss, acc = model.evaluate(test_ds)\nprint(\"Accuracy\", acc)","85eb6e15":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","11377f09":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","ec816301":"base_model.trainable = True","304dfbc6":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 100\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","a907e23a":"model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate\/100),\n              metrics=['accuracy'])","a061e24e":"model.summary()","0f3ab30f":"len(model.trainable_variables)","6eb02fb5":"fine_tune_epochs = 10\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model.fit(train_ds,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=val_ds)","eec94cc1":"acc = history.history['accuracy']+history_fine.history['accuracy']\nval_acc = history.history['val_accuracy']+history_fine.history['val_accuracy']\n\nloss = history.history['loss']+history_fine.history['loss']\nval_loss = history.history['val_loss']+history_fine.history['val_loss']","5e33722f":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","d47e1f0f":"loss, accuracy = model.evaluate(test_ds)\nprint('Test accuracy :', accuracy)","cb878b43":"model.save('\/kaggle\/working\/fine_tuned_mobilenet_v2.h5')","12da5fe5":"# Retrieve a batch of images from the test set\nimage_batch, label_batch = test_ds.as_numpy_iterator().next()\npredictions = model.predict_on_batch(image_batch).flatten()\n\nplt.figure(figsize=(10, 10))\nj = len(class_names)\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image_batch[i].astype(\"uint8\"))\n    preds = predictions[j-len(class_names):j]\n    pred = np.argmax(preds)\n    plt.title('pred: '+class_names[pred]+'\\ntrue: '+class_names[label_batch[i]])\n    plt.axis(\"off\")\n    j += len(class_names)","b69fb6f4":"def train_preset_weights(keras_app_model, base_learning_rate):\n    img_size = (img_height, img_width) + (3,)\n    base_model = keras_app_model(input_shape=img_size,\n                                 include_top=False,\n                                 weights='imagenet')\n    image_batch, label_batch = next(iter(train_ds))\n    feature_batch = base_model(image_batch)\n\n    base_model.trainable = False\n\n    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n    prediction_layer = tf.keras.layers.Dense(len(class_names), activation='softmax')\n\n    inputs = tf.keras.Input(shape=img_size)\n    x = data_augmentation(inputs)\n    x = tf.keras.layers.Rescaling(1.\/255)(x)\n    x = base_model(x, training=False)\n    x = global_average_layer(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    outputs = prediction_layer(x)\n    model = tf.keras.Model(inputs, outputs)\n\n    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=base_learning_rate, momentum=0.9),\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  metrics=['accuracy'])\n    print(model.summary())\n    print('trainable vars: ', len(model.trainable_variables))\n\n    loss0, accuracy0 = model.evaluate(val_ds)\n    print(\"initial loss: {:.2f}\".format(loss0))\n    print(\"initial accuracy: {:.2f}\".format(accuracy0))\n\n    history = model.fit(train_ds,\n                        epochs=initial_epochs,\n                        validation_data=val_ds)\n\n    loss, acc = model.evaluate(test_ds)\n    print(\"Accuracy with imagenet weights\", acc)\n    return base_model, model, history","1fc34abc":"def fine_tune_weights(base_model, model, learning_rate, fine_tune_at, fine_tune_epochs=10):\n    base_model.trainable = True\n\n    print(\"Number of layers in the base model: \", len(base_model.layers))\n    for layer in base_model.layers[:fine_tune_at]:\n        layer.trainable =  False\n    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                  optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n                  metrics=['accuracy'])\n    print(len(model.trainable_variables))\n\n    total_epochs =  initial_epochs + fine_tune_epochs\n\n    history_fine = model.fit(train_ds,\n                             epochs=total_epochs,\n                             initial_epoch=history.epoch[-1],\n                             validation_data=val_ds)\n    return base_model, model, history_fine","d336f94d":"def plot_history_single(history):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()\n\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()","19eaec53":"def plot_history_combined(history, history_fine):\n    acc = history.history['accuracy']+history_fine.history['accuracy']\n    val_acc = history.history['val_accuracy']+history_fine.history['val_accuracy']\n\n    loss = history.history['loss']+history_fine.history['loss']\n    val_loss = history.history['val_loss']+history_fine.history['val_loss']\n\n    plt.figure(figsize=(8, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, label='Validation Accuracy')\n    plt.ylim([0.4, 1])\n    plt.plot([initial_epochs-1,initial_epochs-1],\n              plt.ylim(), label='Start Fine Tuning')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(loss, label='Training Loss')\n    plt.plot(val_loss, label='Validation Loss')\n    plt.ylim([0, 1.0])\n    plt.plot([initial_epochs-1,initial_epochs-1],\n             plt.ylim(), label='Start Fine Tuning')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('epoch')\n    plt.show()","a36b6769":"def eval_on_test(model, test_ds):\n    loss, accuracy = model.evaluate(test_ds)\n    print('Test accuracy :', accuracy)","ba330967":"def save_results(model, name):\n    model.save(f'\/kaggle\/working\/{name}.h5')","7494918b":"def display_results(model, test_ds):\n    image_batch, label_batch = test_ds.as_numpy_iterator().next()\n    predictions = model.predict_on_batch(image_batch).flatten()\n\n    plt.figure(figsize=(10, 10))\n    j = len(class_names)\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(image_batch[i].astype(\"uint8\"))\n        preds = predictions[j-len(class_names):j]\n        pred = np.argmax(preds)\n        plt.title('pred: '+class_names[pred]+'\\ntrue: '+class_names[label_batch[i]])\n        plt.axis(\"off\")\n        j += len(class_names)","09102129":"base_model_xc, model_xc, history_xc = train_preset_weights(tf.keras.applications.Xception, 0.001)","e68c5e46":"plot_history_single(history_xc)","4918282b":"eval_on_test(model_xc, test_ds)","35b2d655":"_, model_xc, history_fine_xc = fine_tune_weights(base_model, model, base_learning_rate\/100, fine_tune_at=90)","f50a4b56":"plot_history_combined(history_xc, history_fine_xc)","3dd68075":"eval_on_test(model_xc, test_ds)","4ad318c3":"save_results(model_xc, 'fine_tuned_xception')","06385dfb":"display_results(model_xc, test_ds)","4a6881fc":"base_model_nas, model_nas, history_nas = train_preset_weights(tf.keras.applications.InceptionResNetV2, 0.001)","5507241c":"plot_history_single(history_nas)","c3f06c62":"eval_on_test(model_nas, test_ds)","06c76d79":"_, model_nas, history_fine_nas = fine_tune_weights(base_model_nas, model_nas, base_learning_rate\/100, fine_tune_at=700)","a3e71032":"plot_history_combined(history_nas, history_fine_nas)","1650db7d":"eval_on_test(model_nas, test_ds)","09a8675d":"save_results(model_nas, 'inception_resnet_v2')","ebf82f31":"display_results(model_nas, test_ds)","1ec90871":"kyiv_photos = tf.keras.utils.image_dataset_from_directory(\n  pathlib.Path('\/kaggle\/input\/kyiv-g-earth-cw\/'),\n  shuffle=True,\n  seed=seed,\n  image_size=(img_height, img_width),\n  batch_size=12)","21835a7b":"image_batch, _ = kyiv_photos.as_numpy_iterator().next()\npredictions = model.predict_on_batch(image_batch).flatten()\n\nplt.figure(figsize=(10, 10))\nj = len(class_names)\nfor i in range(12):\n    ax = plt.subplot(3, 4, i + 1)\n    plt.imshow(image_batch[i].astype(\"uint8\"))\n    preds = predictions[j-len(class_names):j]\n    pred = np.argmax(preds)\n    plt.title('pred: '+class_names[pred])\n    plt.axis(\"off\")\n    j += len(class_names)","f690e7a4":"### MobileNet V2\nhttps:\/\/www.tensorflow.org\/tutorials\/images\/transfer_learning","27b92ee2":"### Train a baseline model","3e0a3995":"### Import AID","68adede2":"### InceptionResNetV2","32d8fa96":"### Augmentation","198a1134":"### Xception","fb91b77a":"### Divide the data into Train, Validation and Test datasets","6b6db62d":"### Templates for different architectures","bcb569fd":"### Classify random land images","bafdfe3b":"### Check for corrupted images"}}