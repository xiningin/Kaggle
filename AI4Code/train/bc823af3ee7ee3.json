{"cell_type":{"41f80fbd":"code","b1a388b9":"code","3f761881":"code","4e5f6669":"code","53fd306d":"code","2402de46":"code","05be98a8":"code","998b1d05":"code","4a6dece7":"code","2c084594":"code","ea0ce4c0":"code","21789ca0":"code","e0dee2d7":"code","ab15ccb1":"code","8ce9272e":"code","4a0d9dc2":"code","6b87d61b":"code","57b75f50":"code","f682d690":"markdown","617372d4":"markdown","44783db0":"markdown"},"source":{"41f80fbd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom skimage import io, color, exposure, transform\nimport os\nimport glob\nimport h5py\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\n\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom keras import backend as K\nK.set_image_data_format('channels_first')\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\nNUM_CLASSES = 43\nIMG_SIZE = 48","b1a388b9":"def preprocess_img(img):\n    # Histogram normalization in y\n    hsv = color.rgb2hsv(img)\n    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n    img = color.hsv2rgb(hsv)\n\n    # central scrop\n    min_side = min(img.shape[:-1])\n    centre = img.shape[0]\/\/2, img.shape[1]\/\/2\n    img = img[centre[0]-min_side\/\/2:centre[0]+min_side\/\/2,\n              centre[1]-min_side\/\/2:centre[1]+min_side\/\/2,\n              :]\n\n    # rescale to standard size\n    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n\n    # roll color axis to axis 0\n    img = np.rollaxis(img,-1)\n\n    return img","3f761881":"import cv2\nDATA_DIR_TRAIN = \"..\/input\/gtsrb_challenge\/GTSRB_Challenge\/train\"\nx_train = []\ny_train = []\nfor i in range(43):\n    category = \"\"\n    if i<10:\n        category = \"0000\"+str(i)\n    else:\n        category = \"000\"+str(i)\n    path = os.path.join(DATA_DIR_TRAIN, category)   \n    \n    for p in os.listdir(path):\n        img_path = os.path.join(path, p)\n        img = cv2.imread(img_path)\n        new_img = preprocess_img(img)\n        x_train.append(new_img)\n        y_train.append(i)\n","4e5f6669":"x_train_np = np.array(x_train, dtype='float32')         \ny_train_np = np.eye(NUM_CLASSES, dtype='uint8')[y_train]\n\nprint(x_train_np.shape)\nprint(y_train_np.shape)","53fd306d":"random_array = np.random.randint(len(x_train),size=100)\nrandom_array","2402de46":"grids = (10,10)\ncounter = 0\n\nplt.figure(figsize=(20,20))\n\nfor i in range(0, 100):\n  ax = plt.subplot(10, 10, i+1)\n  img = np.rollaxis(x_train[random_array[i]], 0, 3)\n  ax = plt.imshow(img, cmap='gray')\n  plt.title(y_train[random_array[i]])\n  plt.xticks([])\n  plt.yticks([])","05be98a8":"random_array = np.random.randint(len(x_train),size=100)\nrandom_array","998b1d05":"grids = (10,10)\ncounter = 0\n\nplt.figure(figsize=(20,20))\n\nfor i in range(0, 100):\n  ax = plt.subplot(10, 10, i+1)\n  img = np.rollaxis(x_train[random_array[i]], 0, 3)\n  ax = plt.imshow(img, cmap='gray')\n  plt.title(y_train[random_array[i]])\n  plt.xticks([])\n  plt.yticks([])","4a6dece7":"def cnn_model():\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), padding='same',\n                     input_shape=(3, IMG_SIZE, IMG_SIZE),\n                     activation='relu'))\n    model.add(Conv2D(32, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(64, (3, 3), padding='same',\n                     activation='relu'))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, (3, 3), padding='same',\n                     activation='relu'))\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(NUM_CLASSES, activation='softmax'))\n    return model\n\ndef lr_schedule(epoch):\n    return lr*(0.1**int(epoch\/10))","2c084594":"from sklearn.model_selection import train_test_split","ea0ce4c0":"X_train, X_val, Y_train, Y_val = train_test_split(x_train_np, y_train_np, test_size=0.2, random_state=42)\n\ndatagen = ImageDataGenerator(featurewise_center=False, \n                            featurewise_std_normalization=False, \n                            width_shift_range=0.1,\n                            height_shift_range=0.1,\n                            zoom_range=0.2,\n                            shear_range=0.1,\n                            rotation_range=10.,)\n\ndatagen.fit(X_train)","21789ca0":"model = cnn_model()\nlr = 0.01\nsgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n          optimizer=sgd,\n          metrics=['accuracy'])\n\n\ndef lr_schedule(epoch):\n    return lr*(0.1**int(epoch\/10))","e0dee2d7":"batch_size = 32\nnb_epoch = 1\nmodel.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n                            steps_per_epoch=X_train.shape[0],\n                            epochs=nb_epoch,\n                            validation_data=(X_val, Y_val),\n                            callbacks=[LearningRateScheduler(lr_schedule),\n                                       ModelCheckpoint('model.h5',save_best_only=True)]\n                           )","ab15ccb1":"DATA_DIR_TEST = \"..\/input\/gtsrb_challenge\/GTSRB_Challenge\/test\"\nx_test = []\nfor p in os.listdir(DATA_DIR_TEST):\n    img_path = os.path.join(DATA_DIR_TEST, p)\n    img = cv2.imread(img_path)\n    new_img = preprocess_img(img)\n    x_test.append(new_img)","8ce9272e":"random_array = np.random.randint(len(x_test),size=100)\nrandom_array","4a0d9dc2":"grids = (10,10)\ncounter = 0\n\nplt.figure(figsize=(20,20))\n\nfor i in range(0, 100):\n    ax = plt.subplot(10, 10, i+1)\n    img = np.rollaxis(x_test[random_array[i]], 0, 3)\n    ax = plt.imshow(img, cmap='gray')\n    x = x_test[random_array[i]]\n    y_predict = np.argmax(model.predict(x.reshape(1,3,48,48)), axis=1)\n    plt.title(y_predict)\n    plt.xticks([])\n    plt.yticks([])","6b87d61b":"import csv\nwith open('dungdmse05228_submission.csv', mode='w') as csv_file:\n    fieldnames = ['Filename', 'ClassId']\n    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n\n    writer.writeheader()\n    DATA_DIR_TEST = \"..\/input\/gtsrb_challenge\/GTSRB_Challenge\/test\"\n    \n    for p in os.listdir(DATA_DIR_TEST):\n        img_path = os.path.join(DATA_DIR_TEST, p)\n        img = cv2.imread(img_path)\n        new_img = preprocess_img(img)\n        y_predict = np.argmax(model.predict(new_img.reshape(1,3,48,48)), axis=1)\n        \n        writer.writerow({'Filename': p, 'ClassId': int(y_predict)})","57b75f50":"img = cv2.imread(\"..\/input\/gtsrb_challenge\/GTSRB_Challenge\/train\/00009\/00000_00000.ppm\")\nimg = cv2.resize(img, (120, 120))\nplt.imshow(img)","f682d690":"# Training Model","617372d4":"# EDA","44783db0":"# Load Data"}}