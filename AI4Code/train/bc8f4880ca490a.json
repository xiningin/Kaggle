{"cell_type":{"a4547f42":"code","782aabe5":"code","a8e39133":"code","b71c26ca":"code","bec8d7d6":"code","e61f9b88":"code","e060ec37":"code","30b6cc6c":"code","04e5c51f":"code","4cbb0623":"markdown","9001504b":"markdown","f44aa4b0":"markdown"},"source":{"a4547f42":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy import linalg\nimport sys\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\nimport cv2","782aabe5":"def svd(A, tol=1e-5):\n    #singular values and right singular vectors coming from eigenvalues and eigenvectors of A' x A\n    eigs, V = linalg.eig(A.T.dot(A))\n\n    #singular values are the square root of the eigenvalues\n    sing_vals = np.sqrt(eigs)\n\n    #sort both sigular values and right singular vector\n    idx = np.argsort(sing_vals)\n\n    sing_vals = sing_vals[idx[::-1]]\n    V = V[:, idx[::-1]]\n\n    #remove zero singular values below tol\n    sing_vals_trunc = sing_vals[sing_vals>tol]\n    V = V[:, sing_vals>tol]\n\n    #is not necessary to store the entire sigma matrix, so only the diagonal is returned\n    sigma = sing_vals_trunc\n\n    #evaluate U matrix\n    U = A @ V \/sing_vals_trunc\n    \n    return U.real, sigma.real, V.T.real","a8e39133":"def truncate(U, S, V, k):\n    U_trunc = U[:, :k]\n    S_trunc = S[:k]\n    V_trunc = V[:k, :]\n    return U_trunc, S_trunc, V_trunc","b71c26ca":"from sklearn.datasets import load_iris\nimport seaborn as sns\nimport pandas as pd\n\niris = load_iris()\niris.keys()","bec8d7d6":"data = pd.DataFrame(iris.data)\nfeature_names = iris[\"feature_names\"]\ndata.columns = feature_names\ndata[\"labels\"] = iris.target","e61f9b88":"def custom_pairplot(data, feature_names, labels):\n    plt.figure(figsize=(10, 10))\n    plt.subplots_adjust(left = 0, right=1.5, bottom=0, top=1.5)\n    n_features = len(feature_names)\n    \n    for i in range(len(feature_names)):\n        for j in range(len(feature_names)):\n            plt.subplot(n_features, n_features, i*n_features+j+1)\n            if i==j:\n                sns.violinplot(data=data, x=labels, y=feature_names[i])\n            else:\n                plt.scatter(data[feature_names[i]], data[feature_names[j]], c=data[labels])\n                plt.xlabel(feature_names[i])\n                plt.ylabel(feature_names[j])","e060ec37":"custom_pairplot(data, feature_names=feature_names, labels=\"labels\")","30b6cc6c":"k = 2\n\nA = data[feature_names].values\n\nU, S, Vt = svd(A)\nU_trunc, S_trunc, Vt_trunc = truncate(U, S, Vt, k)\n\ntrunc_A = U_trunc @ np.diag(S_trunc)\nreduced_data = pd.DataFrame(trunc_A)\nplt.figure(figsize=(5, 5))\nplt.barh(feature_names[::-1], S[::-1])\nplt.title(f\"Singular values, (first {k} are kept)\")\nplt.gca().xaxis.grid(True)","04e5c51f":"plt.figure(figsize=(5, 5))\nplt.scatter(reduced_data[0], reduced_data[1], c = iris.target)\nplt.xlabel(\"First feature\")\nplt.ylabel(\"Second feature\");","4cbb0623":"# SVD for dimensionality reduction\nKita dapat melihat bagaimana dekomposisi svd berlaku untuk dimensionality reduction, dalam contoh ini, menggunakan **set data Iris** yang tersedia langsung dari library *sklearn* ","9001504b":"NAMA : Iwan Kusmiadi<br>\nNIM  : 20190040061\n<br><br>\n#TUGAS 2 MACHINE LEARNING \n\n\n\n","f44aa4b0":"# SVD decomposition and applications\n\nSVD adalah faktorisasi yang digunakan untuk menyelesaikan persamaan linear, pengurangan dimensi, kompresi data dan sebagainya.<br>\nIni didasarkan pada dekomposisi berikut:\n\n$$A = U\\Sigma V^*$$\n\nDiamana matriks A *(m x n)* dapat difaktorkan menjadi 3 matriks:<br>\n**U** *(m x m)* Matriks Kesatuan <br>\n**\u03a3** *(m x n)* Matriks Diagonal Persegi <br>\n**V** *(n x n)* Matriks Kesatuan <br>\n\nKolom **V** adalah vektor eigen dari **A\\*A** yang disebut vektor singular<br>\nKolom **U** adalah vektor eigen dari **AA*** yang disebut vektor singular<br>\nElemen pada diagonal **\u03a3** adalah nilai eigen tidak nol terurut dari **A*A** and **AA*** yang disebut *nilai singular*<br>"}}