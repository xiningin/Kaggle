{"cell_type":{"82b05702":"code","61a08332":"code","732de995":"code","4b90cc35":"code","eede2f4f":"code","1cd0aa6c":"code","3c2446ec":"code","a1f7225c":"code","73b0c47f":"code","789d2484":"code","33a4752d":"code","daf43809":"code","9d83d757":"code","0a5d6538":"code","fa8fa0ae":"code","37b625d0":"code","cc97e2a1":"code","e1001b3f":"code","55af9c3f":"code","bfaa5293":"code","e1b212e9":"code","b7d6f214":"code","d17c9963":"markdown","9852d781":"markdown","16e8ec56":"markdown","139cd66f":"markdown","c88b31c9":"markdown","b4213998":"markdown","826c6a36":"markdown","606f067b":"markdown","7bf2bdcc":"markdown","6ae880fa":"markdown","82c16826":"markdown","e26f2606":"markdown","81112a11":"markdown","5938dfac":"markdown"},"source":{"82b05702":"#Kutuphanelerin yuklenmesi\nimport pandas as pd\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom scipy.stats import shapiro\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nimport warnings","61a08332":"# Veri setinin y\u00fcklenmesi\n\ndf = pd.read_csv(\"..\/input\/churn-123\/churn kopyas.csv\")\n\n#ilk 2 sat\u0131r\u0131n gozlenmesi\n\ndf.head(2)\n\n#Churn s\u0131n\u0131f\u0131n\u0131n verideki bulunma y\u00fczdesi\n\n(2037) \/ (7963 + 2037) ","732de995":"#Her s\u0131n\u0131f\u0131n veride ka\u00e7 g\u00f6zlemde ge\u00e7ti\u011fini g\u00f6rmekteyiz.\ndf.Exited.value_counts()","4b90cc35":"#\u0130lgisiz degiskenlerin dusurulmesi\n\nneed_drops = [\"RowNumber\",  \"Surname\",\"CustomerId\"]\ndf.drop(need_drops, axis=1, inplace=True)","eede2f4f":"#Eksik deger var m\u0131 sorgulanmas\u0131. Herhangi eksik de\u011fere sahip de\u011fil.\ndf.isnull().sum()","1cd0aa6c":"#Normallik testi\n\nfor i in ['CreditScore' , 'Age', 'Balance', 'EstimatedSalary']:\n    print(i)\n    t_test , p_value = shapiro(df[i])\n    print('Test \u0130statisti\u011fi = %.4f, p-de\u011feri = %.4f' % (t_test, p_value))","3c2446ec":"def one_hot_encoder(dataframe, category_freq=10, nan_as_category=False):\n    categorical_cols = [col for col in dataframe.columns if len(dataframe[col].value_counts()) < category_freq\n                        and dataframe[col].dtypes == 'O']\n\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, dummy_na=nan_as_category, drop_first=True)\n\n    return dataframe\n\n#Enkod islemi\n\ndf = one_hot_encoder(df)\n\n#ilk iki gozlem\n\ndf.head(2)\n","a1f7225c":"#Histogram cizilmesi\n\ndef hist_for_nums(data, numeric_cols):\n    col_counter = 0\n    data = data.copy()\n    for col in numeric_cols:\n        data[col].hist(bins=20)\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()\n        col_counter += 1\n    print(col_counter, \"variables have been plotted\")\n\n\n\n#Say\u0131sal degiskenler icin histogram\u0131n cizdirilmesi.\n\na = ['CreditScore' , 'Age', 'Balance', 'EstimatedSalary']\n\nhist_for_nums(df, a)  ","73b0c47f":"for i in a:\n    sns.catplot(x =\"Exited\" , y= i ,data = df , kind=\"violin\")\n    plt.show()","789d2484":"#Korelasyonlar\u0131n hesaplanmas\u0131\n\ndf.corr().T","33a4752d":"#Modele haz\u0131lamak i\u00e7in hedef de\u011fi\u015fkenle ba\u011f\u0131ms\u0131z de\u011ferlerimizi birbirlerinden ay\u0131r\u0131yoruz.\nX = df.drop(['Exited'], axis=1)\ny = df[[\"Exited\"]]\n\n#Veri setinin egitim ve test seti olarak bolunmesi\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify = y , random_state=46)\n","daf43809":"# LightGBM\n\n#Model olusturma\nlgbm = LGBMClassifier(random_state=12345)\ncross_val_score(lgbm, X, y, cv=10).mean()\n\n# model tuning\nlgbm_params = {\"learning_rate\": [0.01, 0.1],\n               \"n_estimators\": [500, 1000],\n               \"max_depth\": [3, 5]}\n\n#GridSearchCV hesaplanmas\u0131\ngs_cv = GridSearchCV(lgbm,\n                     lgbm_params,\n                     cv=5,\n                     n_jobs=-1,\n                     verbose=2).fit(X, y)\n","9d83d757":"#En iyi parametrelerle model kurma\nlgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X_train, y_train)\ncross_val_score(lgbm_tuned, X_test, y_test, cv=10).mean()\n\n\nfeature_imp = pd.Series(lgbm_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\n#Degisken onem duzeylerinin grafiksel gosterimi\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('De\u011fi\u015fken \u00d6nem Skorlar\u0131')\nplt.ylabel('De\u011fi\u015fkenler')\nplt.title(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")\nplt.show()\n\n#cv islemleri(caprazlama)\nkfold = KFold(n_splits=10, random_state=123456)\ncv_results = cross_val_score(LGBMClassifier(), X_train, y_train, cv=kfold, scoring=\"accuracy\")\n","0a5d6538":"#\u00d6nem d\u00fczeyi y\u00fcksek olan de\u011fi\u015fkenlerin se\u00e7ilmesi\ndf = df[[\"Age\",\"Balance\",\"EstimatedSalary\",\"Exited\"]]\ndf.head()","fa8fa0ae":"#Age degiskenine gore esik deger bulma\ndf.groupby(\"Exited\").agg({\"Age\":\"median\"}).values.mean()\n","37b625d0":"#Balance degiskenine gore esik deger bulma\ndf.groupby(\"Exited\").agg({\"Balance\":\"median\"}).values.mean()","cc97e2a1":"#EstimatedSalary degiskenine gore esik deger bulma\ndf.groupby(\"Exited\").agg({\"EstimatedSalary\":\"median\"}).values.mean()","e1001b3f":"#Kartillerin e\u015fik de\u011fer olarak bulunmas\u0131.\ndf.loc[df.Age > 40.5 ,\"Age\"].quantile(0.90) \ndf.loc[df.Balance > 100710.98499999999 ,\"Balance\"].quantile(0.90) \ndf.loc[df.EstimatedSalary > 101052.94 ,\"EstimatedSalary\"].quantile(0.90)","55af9c3f":"#df 'in bir kopyas\u0131 alarak yeni bir degisken olusturduk.\nxx = df.copy()","bfaa5293":"#Bos bir sutun ac\u0131yoruz. Cunku esik degerlerini referans alarak s\u0131n\u0131fland\u0131rmak islemini gerceklestirecegiz.\nxx.Exited = np.NaN\n\nxx.loc[(xx.Age > 92) & (xx.Balance > 250898.09) & (xx.EstimatedSalary > 199992.48) , \"Exited\" ] = 1\nxx.loc[(xx.Age > 92.0) & (xx.Balance > 250898.09) , \"Exited\"] = 1\nxx.loc[(xx.Age > 92.0) & (xx.EstimatedSalary > 199992.48) , \"Exited\"] = 1\nxx.loc[(xx.Balance > 250898.09) & (xx.EstimatedSalary > 199992.48) , \"Exited\"] = 1\n\nxx.loc[(xx.Age <= 92.0) & (xx.Balance <= 250898.09) & (xx.EstimatedSalary <= 199992.48) , \"Exited\"] = 0\nxx.loc[(xx.Age <= 92.0) & (xx.Balance <= 250898.09) , \"Exited\"] = 0\nxx.loc[(xx.Age <= 92.0) & (xx.EstimatedSalary <= 199992.48) , \"Exited\"] = 0\nxx.loc[(xx.Balance <= 250898.09) & (xx.EstimatedSalary <= 199992.48) , \"Exited\"] = 0\n\n#Atanan s\u0131n\u0131f degerleri float seklinde gelmektedir. \n#Skor fonksiyonu icin bunu kategorik degiskene cevirmemiz gerekmektedir.\n\nxx.Exited =  xx.Exited.astype('category')\nxx.dtypes","e1b212e9":"#Eksik degerlerin sorgulanmas\u0131\nxx.isnull().sum()\n\n#Veri setindeki toplam g\u00f6zlem say\u0131s\u0131\nlen(xx)","b7d6f214":"#E\u015fik degerleri kullanarak olu\u015fturulan hedef de\u011fi\u015fkenle, gercek y_test hedef de\u011fi\u015fkeninin kar\u015f\u0131la\u015ft\u0131r\u0131lmas\u0131\nconfusion_matrix(xx.Exited, df.Exited)\naccuracy_score(xx.Exited, df.Exited)","d17c9963":"A\u015fa\u011f\u0131daki kod par\u00e7as\u0131yla baz\u0131 de\u011fi\u015fkenleri veri setimizden att\u0131k. Bunun nedeni ise ; id ve isim de\u011fi\u015fkenleri kuraca\u011f\u0131m\u0131z modelde herhangi olumlu bir etkiye sahip de\u011fil.","9852d781":"A\u015fa\u011f\u0131da bulunan one_hot_encoder fonksiyonuyla; veride bulunan say\u0131sal olmayan de\u011fi\u015fkenlerin , say\u0131sal de\u011ferlere (0 ve 1) \u00e7evrilmesidir. Bu ise makinan\u0131n anlayaca\u011f\u0131 dildir.","16e8ec56":"Violin grafikle de verideki de\u011fi\u015fkenlerin, hedef de\u011fi\u015fkenine g\u00f6re durumlar\u0131n\u0131 inceledik.","139cd66f":"Churn'da esik deger istenseydi bu deger seti ne olurdu ?","c88b31c9":"# MODELLEME","b4213998":"Demek ki elle de s\u0131n\u0131fland\u0131rma yap\u0131labiliyormu\u015f :)\n\nBir ba\u015fka yaz\u0131mda g\u00f6r\u00fc\u015fmek \u00fczere.\n\nlinkedin : https:\/\/www.linkedin.com\/in\/mehmet-kele%C5%9F-531032174\/","826c6a36":"Lightgbm algoritmas\u0131nda FeatureImportance se\u00e7ene\u011fiyle bize en \u00f6nemli olan de\u011fi\u015fkenleri se\u00e7iyoruz.Bu de\u011fi\u015fkenler Age,Balance ve EstimatedSalary'dir.","606f067b":"Yukar\u0131da kartil kullanarak elde edilen e\u015fik de\u011ferlerle s\u0131n\u0131flar\u0131n belirlenmesi. A\u015fa\u011f\u0131da \"&\" operat\u00f6r\u00fcn\u00fc kulland\u0131\u011f\u0131m\u0131z icin baz\u0131 degiskenlerin bos s\u0131n\u0131f gelmemesi icin \"&\" operat\u00f6r\u00fcn\u00fcn t\u00fcm olas\u0131l\u0131klar\u0131n\u0131 uygulayarak s\u0131n\u0131flar yaz\u0131ld\u0131.\n\n\n","7bf2bdcc":"A\u015fa\u011f\u0131da normallik testi yapt\u0131k. Bunun bizim i\u00e7in \u00e7ok \u00f6nemli. \u00c7\u00fcnk\u00fc modelin ba\u015far\u0131s\u0131n\u0131 etkileyecektir. Bu yapt\u0131\u011f\u0131m\u0131z test; degiskenlerin(s\u00fctunlar) normal dag\u0131l\u0131p dag\u0131lmad\u0131g\u0131n\u0131 gosterir. Yapt\u0131\u011f\u0131m\u0131z i\u015flemin sonu\u00e7lar\u0131n\u0131n yorumlanmas\u0131 ; yap\u0131lan normallik testlerinde t\u00fcm degiskenlerin pvalue degerleri 0.05'den kucuk oldu\u011fu icin H0 reddedilir. Yani tum degiskenler normal dag\u0131lmam\u0131st\u0131r.\n\n","6ae880fa":"A\u015fa\u011f\u0131da olu\u015fturulan grafik bizim i\u00e7in \u00e7ok \u00f6nemli. \u00c7\u00fcnk\u00fc de\u011fi\u015fkenlerin onem d\u00fczeylerini g\u00f6stermektedir. Biz ise buradan \u00f6nem d\u00fczeyi y\u00fcksek olan 3 de\u011fi\u015fkeni se\u00e7ip , tamamen manuel s\u0131n\u0131fland\u0131rma i\u015flemi yapaca\u011f\u0131z.","82c16826":"Herkese merhaba,\n\nBu hafta yapt\u0131\u011f\u0131m \u00e7al\u0131\u015fma ile hi\u00e7 model kurmadan bir s\u0131n\u0131fland\u0131rma projesi yapaca\u011f\u0131m. Peki nas\u0131l yapacaks\u0131n ? Biz \u00f6yle bir \u015fey duymad\u0131k ! Sadece ortalama , medyan ve kartilleri kullanarak yapaca\u011f\u0131z. Peki nas\u0131l ? Hadi gelin bakal\u0131m :)","e26f2606":"Histogram ile verideki \u00e7arp\u0131kl\u0131klar\u0131n g\u00f6zle incelenmesi sa\u011flanm\u0131\u015ft\u0131r.","81112a11":"Yukar\u0131daki 3 h\u00fccre ilk e\u015fik de\u011ferimizi olu\u015fturdu. Bu 3 e\u015fik de\u011fere g\u00f6re de doldurup d\u00fc\u015f\u00fck bir s\u0131n\u0131fland\u0131rma ba\u015far\u0131s\u0131 alabilirdik. Ama burada \u015funa dikkat etmeliyiz; verideki s\u0131n\u0131flar aras\u0131nda dengesizlik var. Bunun i\u00e7in kartilleri kullan\u0131p, \u00e7\u0131kan de\u011ferleri de e\u015fik de\u011fer olarak kullanaca\u011f\u0131z. Yani iki e\u015fik de\u011feri birlikte kullanarak s\u0131n\u0131fland\u0131rma i\u015flemi yapaca\u011f\u0131z. Verideki dengesizlikten dolay\u0131 1 s\u0131n\u0131f\u0131na do\u011fru ; yani yukar\u0131 do\u011fru kartillerden e\u015fik de\u011fer elde edece\u011fiz. Kartil y\u00fczdelerini artt\u0131r\u0131p azaltarak son\u0131fland\u0131rma sonu\u00e7lar\u0131n\u0131 inceleyebilirsiniz.\n\n\u00d6rnek :\n- \u0130lk e\u015fik deger =    df.loc[df.Age > 40.5 ,\"Age\"]\n- \u0130kinci e\u015fik de\u011fer = df.loc[df.Age > 40.5 ,\"Age\"].quantile(0.90)\n\n\u00c7e\u015fitli kartil degerlerine kar\u015f\u0131l\u0131k gelen s\u0131n\u0131fland\u0131rma ba\u015far\u0131lar\u0131:\n\n- 20 iken s\u0131n\u0131fland\u0131rma ba\u015far\u0131s\u0131 : 70.49\n- 25 iken s\u0131n\u0131fland\u0131rma ba\u015far\u0131s\u0131 : 71.54\n- 30 iken s\u0131n\u0131fland\u0131rma ba\u015far\u0131s\u0131 : 72.86\n- 50 iken s\u0131n\u0131fland\u0131rma ba\u015far\u0131s\u0131 : 76\n- 60 iken s\u0131n\u0131fland\u0131rma ba\u015far\u0131s\u0131 : 77\n- 80 iken s\u0131n\u0131fland\u0131rma ba\u015far\u0131s\u0131 : 78.83\n- 90 iken s\u0131n\u0131fland\u0131rma ba\u015far\u0131s\u0131 : 79.01","5938dfac":"**\u015eimdi akl\u0131m\u0131za \u015fu gelebilir biz neden e\u015fik de\u011fer olu\u015fturuyoruz ?**\n\n- Bunun nedeni; her de\u011fi\u015fkenin s\u0131n\u0131flar\u0131n\u0131 ay\u0131racak s\u0131n\u0131r\u0131n tespiti ve bu de\u011ferlere g\u00f6re elle s\u0131n\u0131fland\u0131rma i\u015flemidir. \u015eimdi akla \u015fu gelebilir; neden ortalama yerine medyan kulland\u0131n ? Bunun nedeni; ilk ba\u015fta normallik testi yapt\u0131k ve normal da\u011f\u0131lmad\u0131g\u0131n\u0131 g\u00f6rduk. Veri normal da\u011f\u0131lmad\u0131\u011f\u0131 zaman, araya giren bir tane b\u00fcy\u00fck de\u011fer ortalaman\u0131n sap\u0131tmas\u0131na neden olur. Bunun i\u00e7in de medyan de\u011ferini ald\u0131m. Fakat bunu klasik olarak bir de\u011fi\u015fkenin medyan\u0131n\u0131 alarak yapmad\u0131m. \u015e\u00f6yle yapt\u0131m ; 0 ve 1 s\u0131n\u0131f\u0131n\u0131n medyan de\u011ferlerini buldum ve bunlar\u0131n ortalamas\u0131n\u0131 alarak daha sa\u011fl\u0131kl\u0131 bir sonuca ula\u015ft\u0131m. Bu elde etti\u011fim ortalama ise ; benim ilk ba\u015fta verilerimin s\u0131n\u0131r\u0131n\u0131 \u00e7izen e\u015fik de\u011feri olu\u015fturdu. Yani 0 ve 1 s\u0131n\u0131flar\u0131n\u0131 birbirinden ay\u0131rd\u0131. Ama e\u015fik de\u011fer i\u015flemi daha burada bitmedi. Devam edelim :)"}}