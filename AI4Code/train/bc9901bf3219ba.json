{"cell_type":{"3b99da00":"code","e2c74271":"code","1cd1c107":"code","5f7b4607":"code","af648b6e":"code","c76ee757":"code","8f0918ac":"code","b7b06065":"code","4a21f0f3":"code","17688d5c":"code","fbd2f1da":"code","aa5d2084":"code","8b06f33a":"code","bca8a1ea":"code","4f7d8077":"code","ffd00113":"markdown","d5629540":"markdown","87ceeff8":"markdown","1c7c67a0":"markdown","cf6b0979":"markdown","c79b150f":"markdown","92714fe7":"markdown","75e35956":"markdown","a3c905f7":"markdown","be86e40e":"markdown","ae876b08":"markdown","a070f272":"markdown"},"source":{"3b99da00":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics","e2c74271":"df_train = pd.read_csv('\/kaggle\/input\/dda-p2\/train.csv', index_col=0)\ndf_train.head()","1cd1c107":"df_train.shape","5f7b4607":"df_train['Fehlerhaft'].value_counts()","af648b6e":"_ = df_train['Fehlerhaft'].plot.hist(bins=2, figsize=(12, 8), title='Verteilung fehlerfreie vs. fehlerhafte Produktionsst\u00fccke')","c76ee757":"df_train.isnull().sum()","8f0918ac":"# f\u00fcr schnellere Laufzeit und mehr \u00dcbersicht in den Plots: Stichprobe der Daten abbilden\ndata_sample = df_train.sample(2000, random_state=28)  # random_state sorgt f\u00fcr reproduzierbare Stichprobe, sodass die Stichprobe f\u00fcr uns alle identisch ist\n\n_ = pd.plotting.scatter_matrix(data_sample, c=data_sample['Fehlerhaft'], cmap='seismic', figsize=(16, 20))","b7b06065":"# Splitten von Features (X) und Zielgr\u00f6\u00dfe (y)\nX = df_train.drop('Fehlerhaft', axis=1)\ny = df_train['Fehlerhaft']","4a21f0f3":"X_train, X_validierung, y_train, y_validierung = train_test_split(X, y, test_size=0.2)  # nutze 20% der Trainingsdaten als Validierungsset","17688d5c":"prediction_pipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('clf', LogisticRegression(solver='lbfgs')),\n])","fbd2f1da":"_ = prediction_pipe.fit(X_train, y_train)\nprint('F1-Score auf den Trainingsdaten:', metrics.f1_score(y_train, prediction_pipe.predict(X_train)).round(2))\nprint('F1-Score auf den Validierungsdaten:', metrics.f1_score(y_validierung, prediction_pipe.predict(X_validierung)).round(2))","aa5d2084":"X_test = pd.read_csv('\/kaggle\/input\/dda-p2\/test.csv', index_col=0)\nX_test.head()","8b06f33a":"predicted_test = prediction_pipe.predict(X_test)","bca8a1ea":"submission = pd.read_csv('\/kaggle\/input\/dda-p2\/sample_submission.csv')\nsubmission['Fehlerhaft'] = predicted_test\nsubmission.head()","4f7d8077":"submission.to_csv('.\/predicted_values.csv', index=False)","ffd00113":"Darstellung als Histogramm:","d5629540":"Erstellen eines Validierungssets, um Hyperparameter zu optimieren und eventuelles Overfitting festzustellen","87ceeff8":"Eine einfache Pipeline erstellen, die die notwendigen Schritte f\u00fcr die Prognose enth\u00e4lt","1c7c67a0":"Wie liegen die Verteilungen zueinander?\n\n* Blaue Punkte = fehlerfreie Produktionsst\u00fccke\n* Rote Punkte = fehlerhafte Produktionsst\u00fccke","cf6b0979":"# Grundger\u00fcst zur Prognose\n\nDieses Notebook ist dazu gedacht, dass ihr eure Prognose darauf aufbauen k\u00f6nnt. Es enth\u00e4lt wesentliche Bausteine, die ihr in der ersten Gruppenarbeit kennengelernt habt.","c79b150f":"## Prognosemodell erstellen\n\nErstellen eines einfachen Baseline-Modells zur Prognose","92714fe7":"Existieren fehlerhafte  Werte?","75e35956":"Die Verteilung der Zielgr\u00f6\u00dfe ist stark unbalanciert: Die allermeisten produzierten St\u00fccke sind fehlerfrei. Einige wenige (284 \/ 20208) sind hingegen Fehlproduktionen.","a3c905f7":"## Erkunden der Daten\nEinlesen der Daten:","be86e40e":"Dimensionen des Datensatzes: 20492 Instanzen, 8 Features und die Zielgr\u00f6\u00dfe:","ae876b08":"Es scheint kein Overfitting vorzuliegen.\n\n## Prognose abgeben auf den Testdaten","a070f272":"Prognose:"}}