{"cell_type":{"c619b3db":"code","e41e4440":"code","22727561":"code","83c1f26f":"code","d4643ffa":"code","f05717e1":"code","2fae06be":"code","a3e7d9bd":"code","1fb63726":"code","659575cc":"code","d4ef49c2":"code","a4d4bbff":"code","01343324":"markdown","5083a320":"markdown","8f18db13":"markdown","8f9ef186":"markdown","12d7052a":"markdown","5af70759":"markdown","8ffa5ff0":"markdown","2b8fd6df":"markdown","cfa51f79":"markdown","7d9a5b6e":"markdown","c3e3f7b8":"markdown","e11c7488":"markdown","27c93531":"markdown","8f0ea1cf":"markdown"},"source":{"c619b3db":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\n\n","e41e4440":"# load user count timeseries\ndata = pd.read_csv('..\/input\/app.csv', sep=';')\nprint(data.head())\n# convert time column to datetime data type\ndata['time'] = pd.to_datetime(data['time'])\nprint(data.dtypes)\n# use time column as index within the dataset\ndata = data.set_index('time')\nprint(data.index)","22727561":"print(data.columns.tolist())\nplt.figure(figsize=(20, 3))\nplt.plot(data['users'], color='blue',label='User count')\nplt.legend(loc='best')","83c1f26f":"moving_mean = data['users'].rolling(5).mean()\nmoving_std = data['users'].rolling(5).std()\nplt.figure(figsize=(20, 3))\nplt.plot(data['users'], color='blue',label='User count')\nplt.plot(moving_mean, color='red', label='Moving mean')\nplt.plot(moving_std, color='black', label = 'Moving std')\nplt.legend(loc='best')","d4643ffa":"from statsmodels.tsa.stattools import adfuller\n\ndftest = adfuller(data['users'].values)\ndfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n\nfor key,value in dftest[4].items():\n    dfoutput['Critical Value (%s)'%key] = value\nprint(dfoutput)\n\n\n","f05717e1":"ts_diff = data['users'] - data['users'].shift()\nplt.figure(figsize=(20, 3))\nplt.plot(data['users'], color='blue',label='User count')\nplt.plot(ts_diff, color='red', label='Ts diff')\nplt.legend(loc='best')","2fae06be":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(data['users'])\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nplt.figure(figsize=(20, 3))\nplt.plot(data['users'], color='blue',label='User count')\nplt.plot(trend, color='red', label='Trend')\nplt.plot(seasonal, color='black', label='Seasonality')\nplt.plot(residual, color='green', label='Residuals')\nplt.legend(loc='best')","a3e7d9bd":"from statsmodels.tsa.ar_model import AR\n\n# fit model\nmodel = AR(data['users'])\nmodel_fit = model.fit()\n# make prediction\npred_users = model_fit.predict(100, 300)\n# plot\nplt.figure(figsize=(20, 3))\nplt.plot(data['users'], color='blue',label='User count')\nplt.plot(pred_users, color='red', label='Prediction')\nplt.legend(loc='best')\n","1fb63726":"from statsmodels.tsa.arima_model import ARMA\n# fit model\nmodel = ARMA(data['users'], order=(0, 1))\nmodel_fit = model.fit(disp=False)\n# make prediction\nma_pred_users = model_fit.predict(100, 300)\n\nplt.figure(figsize=(20, 3))\nplt.plot(data['users'], color='blue',label='User count')\nplt.plot(ma_pred_users, color='red',label='User count prediction')\nplt.legend(loc='best')","659575cc":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nmodel = SARIMAX(data['users'])\nmodel_fit = model.fit()\n# make prediction\nsarima_pred = model_fit.predict(100, 300)\nplt.figure(figsize=(20, 3))\nplt.plot(data['users'], color='blue',label='User count')\nplt.plot(sarima_pred, color='red',label='User count prediction')\nplt.legend(loc='best')","d4ef49c2":"from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n# fit model\nmodel = SimpleExpSmoothing(data['users'])\nmodel_fit = model.fit()\n# make prediction\npred_holtwint = model_fit.predict(100, 300)\nplt.figure(figsize=(20, 3))\nplt.plot(data['users'], color='blue',label='User count')\nplt.plot(pred_holtwint, color='red',label='User count prediction')\nplt.legend(loc='best')","a4d4bbff":"from statsmodels.tsa.holtwinters import ExponentialSmoothing\n# fit model\nmodel = ExponentialSmoothing(data['users'])\nmodel_fit = model.fit()\n# make prediction\nhwt_pred = model_fit.predict(100, 300)\nplt.figure(figsize=(20, 3))\nplt.plot(data['users'], color='blue',label='User count')\nplt.plot(hwt_pred, color='red',label='User count prediction')\nplt.legend(loc='best')","01343324":"### SARIMA\n","5083a320":"### Moving Average (MA)\n\nThis forcast method models the next steps within the predicted timeseries through a mean process of historic measurements.\n\n","8f18db13":"## References\nMany thanks to following important references, which are:\n\n1. https:\/\/www.analyticsvidhya.com\/blog\/2016\/02\/time-series-forecasting-codes-python\/\n2. https:\/\/machinelearningmastery.com\/time-series-forecasting-methods-in-python-cheat-sheet\/","8f9ef186":"## Forecasting a timeseries\nNow that we have extracted the essential residual timeseries by removing seasonality and trend aspects, we can start to predict the timeseries into the future.\n\nAs each timeseries contains multiple parts such as: \n- Trend \n- Seasonality \n- Residuals \n\n\n### Prediction with Autoregression (AR)\nThe autoregression (AR) method models the next step in the sequence as a linear function of the observations at prior time steps [2]. \n","12d7052a":"### Difference \nSubtract the original ts by its shifted value over time. ","5af70759":"### Lets check for stationary\nWithin timeseries analysis, stationary means that the properties of the timeseries such as **mean and variance remain constant over time**. In case mean and variance are increasing or decreasing over time we speak of a trend. \nLets do some test for checking a timeseries' stationarity characteristics. A simple but rather visual approach is to plot the moving average as well as the moving variance over time.\n","8ffa5ff0":"### Plot the user count timeseries\nSimply plot the original timeseries of user counts.","2b8fd6df":"## Timeseries analysis and forecast\n\nThis notebook represents my sandbox environment for playing around with timeseries analysis and forecast. The different sections will check for trend and seasonality and will give a quick forecast into the future.\nWe will start to use a real world statistics about the number of concurrent users of a mobile app in a hourly resolution over a period of one week. ","cfa51f79":"### Dickey-Fuller test for stationarity\n\nAnother test for stationarity is given by the Dickey-Fuller test. The Dickey-Fuller test defines a Null Hypothesis (H0) that the timeseries is time dependent and not stationary. If Null Hypothesis can be rejected this means that the timeseries is stationary. \nThe result of the test is interpreted through the tests p-value. A p-value below 5% or 1% means that we can reject the null hypothesis (stationary), otherwise a p-value above means we fail to reject the null hypothesis (non-stationary). \n* p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n* p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\n\nOur example timeseries has a p-value of 0.00027% that allows us to reject the Null Hypothesis, it is clearly stationary and shows no trend. \nThe probability of -3.47% at the significance level of 1% suggests that we can reject the Null Hypothesis with a significance level of less than 1%, meaning a very low probability that we wrongly rejected the hypothesis.","7d9a5b6e":"## Transform a timeseries from non-stationary to stationary [1]\n\nAs mentioned above, there are two aspects that renders a timeseries non-stationary, which are:\n1. Trend: Mean increases or decreases over time, e.g.: number of users slightly increases or decreases over time\n2. Seasonality: Mean changes with a specific frequency, e.g.: high mean top of the day, lower mean after business hours.\n\nThe idea is to detect trends and seasonality of a timeseries, use this information about trent and seasonality to transform the timeseries into a stationary timeseries. Then forcast the stationary timeseries and again apply the trend as well as seasonal changes for getting the final prediction.","c3e3f7b8":"### Holt Winters Simple Exponential Smoothing","e11c7488":"### Decomposing\nA decomposing step models the trend, seasonality as well as residuals individually. ","27c93531":"### Holt Winters Triple Exponential Smoothing\n","8f0ea1cf":"### Load the user count timeseries\nLoad the user count timeseries from the data set and convert the time column into datetime datatype."}}