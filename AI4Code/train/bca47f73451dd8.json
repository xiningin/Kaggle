{"cell_type":{"e35e8c53":"code","6097889f":"code","5607014b":"code","37cbe371":"code","8f334652":"code","a142dc1e":"code","f9d11849":"code","61972b82":"code","05e8848f":"code","3e5528b5":"code","6a6018d4":"code","f8ecf633":"code","39a43041":"code","efd1586c":"code","faf82801":"code","1ca5bfd3":"code","07e8317f":"code","7b66f5ea":"code","5dfa106c":"code","46788929":"code","8a36d027":"code","8ab230ea":"code","a36cda6d":"code","75e2e40d":"code","ee92e573":"code","b05457e6":"code","4d534086":"code","e164cf66":"code","464c4c25":"code","55f7c9fd":"code","477ffdb8":"code","ea245434":"code","ea464d3a":"code","36e3ad1b":"code","2d647307":"code","8272bde4":"code","b17b6c92":"code","4d87b13a":"code","4cea5147":"code","3d6dd823":"code","067cb728":"code","0630d684":"code","633ade04":"code","0a504dcc":"code","ee5ed451":"code","23aa7e93":"code","d3681b72":"markdown","7ffe1c9a":"markdown","96e45980":"markdown","8a684693":"markdown","d127e1c5":"markdown","ad831421":"markdown","49ec18b9":"markdown","d98a8973":"markdown","684af8da":"markdown","a809bb6b":"markdown","46abebb6":"markdown","d49fce7e":"markdown","7a0ef6a3":"markdown","3f1aa218":"markdown","4a796a15":"markdown","a575d37c":"markdown","1ad50c3e":"markdown","64963f7b":"markdown","af95167a":"markdown","2ecc690d":"markdown","c42e0eb5":"markdown","d8e810f4":"markdown","b43113ba":"markdown","e080faf2":"markdown","c614c15a":"markdown","3875be13":"markdown","6a0e229c":"markdown","a80ede94":"markdown","e948e251":"markdown","38c5cd5c":"markdown","681792d0":"markdown"},"source":{"e35e8c53":"from fastai import *\nfrom fastai.text import *\nfrom fastai.metrics import Precision, Recall, FBeta\nimport random\nimport re\nrandom.seed(42) # set the random seed","6097889f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","5607014b":"irony_data = pd.read_csv('\/kaggle\/input\/ironic-corpus\/irony-labeled.csv')\nirony_data.head()","37cbe371":"imdb_path = untar_data(URLs.IMDB_SAMPLE)\nimdb_path.ls()\nimdb = pd.read_csv(imdb_path\/'texts.csv')","8f334652":"imdb.head()","a142dc1e":"combined = imdb.append(irony_data.rename(columns={'comment_text':'text'}),sort=False)\ncombined.columns","f9d11849":"bs = 48\ndata_lm = (TextList.from_df(df=combined, cols='text')\n            .split_by_rand_pct(0.1)\n            .label_for_lm()           \n            .databunch(bs=bs))\ndata_lm.save('data_lm.pkl')","61972b82":"data_lm.show_batch()","05e8848f":"bs=48\npath = \".\"\ndata_lm = load_data(path, 'data_lm.pkl', bs=bs)","3e5528b5":"learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)","6a6018d4":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","f8ecf633":"learn.fit_one_cycle(4, 1e-2, moms=(0.8,0.7))","39a43041":"learn.save('fit_head')","efd1586c":"learn.load('fit_head');","faf82801":"learn.unfreeze()","1ca5bfd3":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","07e8317f":"learn.fit_one_cycle(2, slice(1e-2\/2,1e-3), moms=(0.8,0.7))","7b66f5ea":"learn.save('fine_tuned')","5dfa106c":"learn.load('fine_tuned');","46788929":"TEXT = \"I think that\"\nN_WORDS = 25\nN_SENTENCES = 2","8a36d027":"print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))","8ab230ea":"learn.save_encoder('fine_tuned_enc')","a36cda6d":"imdb = imdb[['text','label']]","75e2e40d":"imdb_clas = (TextList.from_df(df=imdb,cols='text',vocab=data_lm.vocab)\n             .split_by_rand_pct(.2)\n             #split by random 20% \n             .label_from_df(cols='label')\n             #label from the csv file\n             .databunch(bs=bs))\n\nimdb_clas.save('imdb_clas.pkl')","ee92e573":"imdb_clas = load_data(path, 'imdb_clas.pkl', bs=bs)","b05457e6":"imdb_clas.show_batch()","4d534086":"learn = text_classifier_learner(imdb_clas, AWD_LSTM, drop_mult=0.2)\nlearn.load_encoder('fine_tuned_enc');","e164cf66":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","464c4c25":"learn.fit_one_cycle(4, 1e-3, moms=(0.8,0.7))","55f7c9fd":"learn.save('froze_imdb')","477ffdb8":"learn.load('froze_imdb');","ea245434":"bs = 24 # was previously 48\nimdb_clas = load_data(path, 'imdb_clas.pkl', bs=bs)\nlearn = text_classifier_learner(imdb_clas, AWD_LSTM, drop_mult=0.5)\nlearn.load('froze_imdb');","ea464d3a":"learn.unfreeze()\nlearn.fit_one_cycle(1, slice(1e-3\/(2.6**4),1e-3), moms=(0.8,0.7))","36e3ad1b":"learn.save('unfroze_imdb')","2d647307":"from sklearn.model_selection import KFold # import KFold\n\nirony_data.head()\nX = irony_data['comment_text']\ny = irony_data['label']\nkf = KFold(n_splits=5)\nkf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator","8272bde4":"print(kf)","b17b6c92":"trains = list()\ntests = list()\nfor train_index, test_index in kf.split(X):\n    trains.append(train_index)\n    tests.append(test_index)","4d87b13a":"def create_validation(valnum):\n\n    train = {'comment_text': X[trains[valnum]], 'label': y[trains[valnum]]}\n    dftrain = pd.DataFrame(data=train)\n    \n    valid = {'comment_text': X[tests[valnum]], 'label': y[tests[valnum]]}\n    dfvalid = pd.DataFrame(data=valid)\n    \n    return dftrain, dfvalid","4cea5147":"fold1_train, fold1_valid = create_validation(0)\nfold2_train, fold2_valid = create_validation(1)\nfold3_train, fold3_valid = create_validation(2)\nfold4_train, fold4_valid = create_validation(3)\nfold5_train, fold5_valid = create_validation(4)","3d6dd823":"bs=48\npath = \".\"\ndata_lm = load_data(path, 'data_lm.pkl', bs=bs)\n\ntrains = [fold1_train, fold2_train, fold3_train, fold4_train, fold5_train]\nvalids = [fold1_valid, fold2_valid, fold3_valid, fold4_valid, fold5_valid]\nn_reps = 1\n# to hold precision, recall and f1 values across reps\nmetrics = np.zeros([len(trains),n_reps,3]) ","067cb728":"weights = [1., 3.]\nclass_weights=torch.FloatTensor(weights).cuda()","0630d684":"foldx = TextDataBunch.from_df(\".\",fold1_train,fold1_valid,text_cols=0,label_cols=1,vocab=data_lm.vocab,bs=bs)\nlearn = text_classifier_learner(foldx, AWD_LSTM, drop_mult=0.2,\n                                loss_func = nn.CrossEntropyLoss(weight=class_weights))\nlearn.load('unfroze_imdb');\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","633ade04":"for reps in range(n_reps):\n    for fold in range(0,len(trains)):\n        foldx = TextDataBunch.from_df(\".\",trains[fold],valids[fold],text_cols=0,label_cols=1,vocab=data_lm.vocab,bs=bs)\n        learn = text_classifier_learner(foldx, AWD_LSTM, drop_mult=0.2,metrics=[Precision(),Recall(),FBeta(beta=1)],\n                                       loss_func = nn.CrossEntropyLoss(weight=class_weights))\n        learn.load('unfroze_imdb');\n        learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))\n        metrics[fold,reps:] = learn.recorder.metrics\n    ","0a504dcc":"avg_per_fold = np.mean(metrics,axis=1);avg_per_fold","ee5ed451":"def format_scores(avg_metrics):\n    def print_line(name,arr):\n        print(name,':',format(np.mean(arr), '.3f'), '(range ', np.min(arr), ' - ',np.max(arr))\n    \n    print_line('F1 score',avg_metrics[:,2])\n    print_line('recall',avg_metrics[:,1])\n    print_line('precision',avg_metrics[:,0])\n    ","23aa7e93":"format_scores(avg_per_fold)","d3681b72":"Scores presented in the paper:\n- average [F1 score](https:\/\/en.wikipedia.org\/wiki\/F1_score): 0.383 (range 0.330 - 0.412)\n- average [recall](https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall): 0.496 (range 0.446 - 0.548)\n- average [precision](https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall): 0.315 (range 0.261 - 0.380)","7ffe1c9a":"When fine tuning the entire model, we need to have a smaller batch size. Here, we create another `DataBunch` with a smaller batch size, and then reload the model parameters. ","96e45980":"# Compare the results of the ULMFit and SVM classification","8a684693":"When we look at a batch of this data, we can see that the tokenizer has replaced some of the tokens. For example, xxmaj, xxunk.","d127e1c5":"Since this is a language model, we can use it to complete sentences. Since this is a combination of wikipedia, IMDB and Ironic, it might sound somewhat sensationalized.","ad831421":"Now that the language model is trained, we can create a classifier for the ironic sentences","49ec18b9":"## Creating Cross Validation Folds","d98a8973":"# 4. Retrain the classification model to detect irony class","684af8da":"## IMDB database","a809bb6b":"Here, we're using the sample size of the IMDB movie reviews found in the fastai datasets. If you haven't prevously downloaded this dataset, it is automatically downloaded from tha amazon server. The sample contains 1,000 movie reviews labeled as either _positive_ or _negative_. In addition, an IMDB validate set is already designated in the `is_valid` column. ","46abebb6":"Here, we create the data we will use to fine tune the langauge model. It is created as a `databunch`, and saved for later. Fastai does a lot of processing 'under the hood' to tokenize and numericalize the data. ","d49fce7e":"Breifly, this notebook uses data from  [_Ironic Corpus_](http:\/\/www.byronwallace.com\/static\/articles\/wallace-irony-acl-2014.pdf). To see a larger introduction and short exploratory data analysis, see [this notebook](https:\/\/www.kaggle.com\/melissarajaram\/ironic-corpus-understanding-the-data). The goal using this corpus is to classify internet comments as either \"ironic\" or \"unironic\".\n\nIn the original study, the authors used [Support Vector Machines](https:\/\/en.wikipedia.org\/wiki\/Support-vector_machine) (SVM) to classify the ironic and unironic comments. Their results are reported with respect to the F1 score, precision and recall using a five-fold cross-validation. When interpreting these outcome metrics, scores closer to 1 are best.\n- average [F1 score](https:\/\/en.wikipedia.org\/wiki\/F1_score): 0.383 (range 0.330 - 0.412)\n- average [recall](https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall): 0.496 (range 0.446 - 0.548)\n- average [precision](https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall): 0.315 (range 0.261 - 0.380)\n\nThe goal of this notebook is to try and duplicate or improve on the results using using more recent techniques that include transfer learning. The first **transfer learning** method applied to Natural Language Processing (NLP) was [Universal Language Model Fine-tuning for Text Classification](https:\/\/medium.com\/r\/?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1801.06146.pdf).(ULMFiT) method. This method involves starting with a pre-trained language model (LM), for example, trained on the Wikitext 103 dataset, and then fine tuning the language model on a new dataset. The fine tuned language model can then be used in a classification task with a different set of data. A video demonstration is in the [fast.ai course](https:\/\/course.fast.ai\/videos\/?lesson=4), incorporating other techniques like discriminate learning rates, gradual model unfreezing, and slanted triangular learning rates. A [text based example](https:\/\/docs.fast.ai\/text.html) can be found in the fastai docs. In this tutorial, I will use a language model that is pretrained on Wikitext 103, a subset of the IMDB movie reviews dataset, and the Ironic Corpus.\n\nThis notebook proceeds in the following sections:\n1. Data Loading\n1. Create a Language Model to predict IMDB and Ironic Corpus words\n1. Train a text classification model to predict the IMDB class\n1. Retrain the classification model to detect irony class\n1. Compare the results of the ULMFit and SVM classification\n","7a0ef6a3":"Find a good learning rate. with the suggestion=True, it gives a heuristic for choosing. ","3f1aa218":"## Looping through the cross validation folds","4a796a15":"## Combining the Ironic and IMDB sample datasets","a575d37c":"Since the goal is to first predict words by fine tuning the pretrained langauge model on IMDB and Ironic Corpus text, the two datasets are combined into one dataframe. From the resulting columns of the dataframe, we will only use the `text` column. ","1ad50c3e":"The csv file contains one column with the comment text, and one column with the label. A label value of _-1_ corresponds to \"not ironic\", and  label, and a label value of _1_ corresponds to \"ironic\".","64963f7b":"Now, train the model to predict words.","af95167a":"# 1. Data Loading","2ecc690d":"### Training a language model with combined data","c42e0eb5":"After importing all the python packages we'll need, the Ironic Corpus and IMDB Sample are loaded and combined.","d8e810f4":"# 2. Create a Language Model to predict IMDB and Ironic Corpus words","b43113ba":"Here, we're creating a language model learner. ","e080faf2":"# 3. Train a text classification model to predict the IMDB class","c614c15a":"## Interpretation:\n\nThe ULMFit technique is able to get close to the best scores from the paper. ","3875be13":"Remember that this has two parts, an encoder, and a decoder. We've just trained the model to predict words, and we want to now use that encoder with a different 'head' to make it into a text classifier.","6a0e229c":"To be able to compare these results with the previously published paper, we need to make a 5 fold cross validation before the training and testing cycles.","a80ede94":"This is important to account for the class imbalance in the ironic corpus.","e948e251":"## Ironic Corpus","38c5cd5c":"Now, instead of using `language_model_learner`, we use the `text_classifier_learner`. We pass the `DataBunch` with the IMDB data, and then load the previously fine tuned encoder.","681792d0":"# Ironic Corpus - ULMFIT technique"}}