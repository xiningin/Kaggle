{"cell_type":{"d9b7372c":"code","62384d22":"code","0f7a2cc1":"code","047bd81e":"code","31e46a38":"code","7bb6f978":"code","bb89fc1e":"code","747c4982":"code","96662e46":"code","7c635495":"code","522201a2":"code","52b0388f":"code","d1e2da26":"code","510edb23":"code","2d1bd92a":"code","9af02252":"code","9a3d7f6a":"code","e9bdc32f":"code","676e8437":"code","2f8b4139":"code","086e8a35":"code","78c5e939":"code","0b169afa":"code","2b71c065":"code","75905b5e":"code","f66b3456":"code","d3be2149":"code","3008c4c0":"code","003921f8":"code","56135f2a":"code","84922e05":"code","13a53359":"code","dafcee70":"code","c457fe4d":"code","5fc13bf7":"code","507f7aba":"code","036d167f":"code","d8bb38e0":"code","e04a4324":"code","65b0d10b":"code","9554f001":"code","52a55b3a":"code","8df159f3":"code","80da9a16":"code","c6abc591":"markdown","5c8f991a":"markdown","f55c52a6":"markdown","2fbce220":"markdown","7e0668b0":"markdown","8e73e6ae":"markdown","d1698bb2":"markdown","3beea74d":"markdown","6d484fe7":"markdown","6cec889d":"markdown","2130a8ed":"markdown","0009fa88":"markdown","e8d209da":"markdown","bd8d0963":"markdown","93cdad36":"markdown","2fdfe3b0":"markdown","ca178b22":"markdown","0c24de75":"markdown","018021c3":"markdown","caa682af":"markdown","f916a804":"markdown","a363a4fe":"markdown","066aa325":"markdown","67ee1d4b":"markdown","ba835084":"markdown","e507dcf9":"markdown","f3216826":"markdown","1ebde867":"markdown","d4daec92":"markdown","d8ef8d0b":"markdown","3b0ec27f":"markdown","10bef614":"markdown","fb82f720":"markdown","73b0865e":"markdown","e6864ea4":"markdown","0cc02e63":"markdown","0217f47b":"markdown","1f962086":"markdown","74e8edeb":"markdown","add4b278":"markdown"},"source":{"d9b7372c":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","62384d22":"df = pd.read_csv(\"..\/input\/credit-card-customers\/BankChurners.csv\")\ndf = df.iloc[:, 1:21]\ndf.head()","0f7a2cc1":"def export_png(xlabel, ylabel, image_name):\n    \"\"\"\n    Exports plots into png format\n\n    INPUTS:\n        xlabel \u2014 x axis name\n        ylabel \u2014 y axis name\n        image_name \u2014 File name for image with .png extension\n    \"\"\"\n    plt.xlabel(xlabel, fontsize=20)\n    plt.ylabel(ylabel, fontsize=20)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.savefig(image_name, dpi=600, transparent=False, bbox_inches=\"tight\")\n    \n    print(\"Export successful\")","047bd81e":"def categorical_probability(column):\n    \"\"\"\n    Calculates probability distribution of Existing Customer and Attrited Customer\n\n    INPUTS:\n        columns \u2014 DataFrame of a particular categorical variable\n    \n    OUTPUT:\n        DataFrame with p_existing, p_default for each sub-category, sorted in p_default descending order\n    \"\"\"\n    column_df = pd.crosstab(index=df[column], \n                               columns=df[\"attrition_flag\"],\n                                margins=True)\n\n\n    column_unique = df[column].unique()\n    all_cols = np.append(column_unique, \"col_total\")\n    column_df.index = all_cols\n    column_df.columns = [\"attrited\",\"existing\", \"row_total\"]\n    \n    column_df['p_existing'] = column_df['existing'] \/ column_df['row_total']\n\n    column_df['p_attrited'] = column_df['attrited'] \/ column_df['row_total']\n    column_df['p_attrited'] = column_df['p_attrited'].round(4)\n    column_df_probability = pd.DataFrame( [column_df['p_attrited'], column_df['p_existing']], columns=column_df.index ).T\n    column_df_probability.sort_values(by=['p_attrited'], ascending=False, inplace=True)\n    column_df_probability.drop(labels=['col_total'], inplace=True)\n#     column_df_probability.drop(labels=['p_existing'], axis=1, inplace=True)\n    return column_df_probability[:15]","31e46a38":"df.shape","7bb6f978":"df.info()","bb89fc1e":"# check if there's any null\/empty values in dataset\ndf.isna().sum()","747c4982":"df.columns = ['attrition_flag', 'customer_age', 'gender', 'dependent_count',\n       'education_level', 'marital_status', 'income_category', 'card_category',\n       'months_on_book', 'total_relationship_count', 'months_inactive_12_month',\n       'contacts_count_12_month', 'credit_limit', 'total_revolving_bal',\n       'avg_open_to_buy', 'total_amt_change_q4_q1', 'total_trans_amt',\n       'total_trans_count', 'total_count_change_q4_q1', 'avg_utilization_ratio']\n\nnumerical = ['customer_age', 'dependent_count', 'months_on_book', \n             'total_relationship_count', 'months_inactive_12_month',\n             'contacts_count_12_month', 'credit_limit', 'total_revolving_bal',\n             'avg_open_to_buy', 'total_amt_change_q4_q1', 'total_trans_amt',\n             'total_trans_count', 'total_count_change_q4_q1', 'avg_utilization_ratio']\n\ncategorical = ['attrition_flag', 'gender','education_level', \n                    'marital_status', 'income_category', 'card_category']","96662e46":"df[numerical].hist(bins=15, figsize=(15, 20), layout=(7,2))","7c635495":"# Retrieve name of skewed columns\nskewed = []\nfor skew_val in df.skew():\n    if skew_val > 1 or skew_val < -1:\n        skewed.append( df.skew()[ df.skew() == skew_val ].index[0] )\n        print( df.skew()[ df.skew() == skew_val ].index[0])\n        print(round(skew_val, 3) )","522201a2":"sns.set(rc={'figure.figsize': (30, 30)})\nfor i in range(len(numerical)):\n    plt.subplot(4, 4, i + 1)\n    sns.kdeplot(df[numerical[i]], shade=True)","52b0388f":"fig, ax = plt.subplots( figsize = (20,22) )\nres = sns.heatmap( df.corr(), cmap='coolwarm', annot=True, ax = ax, annot_kws={\"size\": 15.5}, cbar=False)\nres.set_xticklabels(res.get_xmajorticklabels(), fontsize = 18, rotation=90)\nres.set_yticklabels(res.get_ymajorticklabels(), fontsize = 18)\n\n# plt.savefig(\"correlation_matrix_heatmap.png\", transparent=False, dpi=500)\n# plt.show()","d1e2da26":"# Plot dataframe for collinear features\nresults = df.corr()[ (df.corr() > 0.2) & (df.corr() != 1) ]\n\nresults","510edb23":"# plt.figure(figsize=(20, 20))\n\n# test = sns.pairplot(df[numerical])\n# test.savefig('pairplots-dpi400.png', dpi=400, bbox_inches=\"tight\")\n# test.set_xticklabels(test.get_xmajorticklabels(), fontsize = 18, rotation=90)\n# test.set_yticklabels(test.get_ymajorticklabels(), fontsize = 18)\n\n# plt.show()","2d1bd92a":"fig, ax = plt.subplots( figsize = (8,6) )\nsns.scatterplot(x='credit_limit', y='avg_open_to_buy', data = df)\n\n# export_png('credit_limit','avg_open_to_buy', 'corr1.png')","9af02252":"fig, ax = plt.subplots( figsize = (8,6) )\nsns.scatterplot(x='total_trans_amt', y='total_trans_count', data = df)\n\n# export_png('total_trans_amt','total_trans_count', 'corr2.png')","9a3d7f6a":"fig, ax = plt.subplots( figsize = (8,6) )\nsns.scatterplot(x='customer_age', y='months_on_book', data = df)\n\n# export_png('customer_age','months_on_book', 'corr3.png')","e9bdc32f":"fig, ax = plt.subplots( figsize = (8,6) )\nsns.scatterplot(x='total_revolving_bal', y='avg_utilization_ratio', data = df)\n\n# export_png('total_revolving_bal','avg_utilization_ratio', 'corr4.png')","676e8437":"fig, ax = plt.subplots( figsize = (8,6) )\nsns.scatterplot(x='avg_open_to_buy', y='avg_utilization_ratio', data = df)\n\n# export_png('avg_open_to_buy','avg_utilization_ratio', 'corr5.png')","2f8b4139":"# Correlation: -0.48\nfig, ax = plt.subplots( figsize = (8,6) )\nsns.scatterplot(x='credit_limit', y='avg_utilization_ratio', data = df)\n\n# export_png('credit_limit','avg_utilization_ratio', 'corr6.png')","086e8a35":"# Correlation: 0.38\nfig, ax = plt.subplots( figsize = (8,6) )\nsns.scatterplot(x='total_amt_change_q4_q1', y='total_count_change_q4_q1', data = df)\n\n# export_png('total_amt_change_q4_q1','total_count_change_q4_q1', 'corr7.png')","78c5e939":"for cat in categorical:\n    print('Variable:', cat)\n    print('Unique values:', df[cat].nunique() )\n    print( df[cat].value_counts() )\n    print()","0b169afa":"# Plot histogram\nfig, ax = plt.subplots(2, 3, figsize=(20, 15))\nfor variable, subplot in zip(categorical, ax.flatten()):\n    sns.countplot(x=df[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)","2b71c065":"plt.figure(figsize=(28, 25))\nfor i in range(len(numerical) - 1):\n    plt.subplot(4, 4, i + 1)\n    sns.boxplot(x='attrition_flag', y=numerical[i], data=df)\n    plt.xlabel('attrition_flag', fontsize=18)\n    plt.ylabel(numerical[i], fontsize=18)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    \n\nplt.show()","75905b5e":"# Taking a closer look at the boxplots\nx = df['attrition_flag']\ny = df['months_inactive_12_month']\n\nfig, ax = plt.subplots( figsize = (6,4) )\nsns.boxplot(x=x, y=y)\n\n# export_png('attrition_flag', 'months_inactive_12_month', 'attrition_monthsinactive.png')","f66b3456":"# import dataframe_image as dfi\n# pd.options.display.precision = 4\n# pd.set_option('display.precision', 4)\n\nfor cat in categorical[1:]:\n    print(cat)\n    table = categorical_probability(cat)\n    cm = sns.color_palette(\"crest\", as_cmap=True)\n    styled_table = table.style.background_gradient(cmap=cm)\n    display(styled_table)\n    \n#    # Export DataFrame as image\n#     name = cat + '.png'\n#     dfi.export(styled_table, name)","d3be2149":"# Total revolving balance across card_categories\n\nfig, ax = plt.subplots( figsize = (10,8) )\nsns.boxplot(x = 'card_category', y='total_revolving_bal', hue='attrition_flag', data = df)\n\n# export_png('card_category', 'total_revolving_bal', 'card_v_revolvingbal.png')","3008c4c0":"# Those who called the bank more times have a higher chance of attrition\n\nfig, ax = plt.subplots( figsize = (10,8) )\nsns.boxplot(x = 'card_category', y='contacts_count_12_month', hue='attrition_flag', data = df)","003921f8":"# Those who spent less on their card has a lower chance of attrition\n\nfig, ax = plt.subplots( figsize = (10,8) )\nsns.boxplot(x = 'card_category', y='total_trans_count', hue='attrition_flag', data = df)\n\n# export_png('marital_status', 'total_trans_count', 'marital_v_transcount.png')","56135f2a":"fig, ax = plt.subplots( figsize = (10,8) )\nsns.boxplot(x = 'income_category', y='total_revolving_bal', hue='attrition_flag', data = df)\n\n# export_png('marital_status', 'total_trans_count', 'marital_v_transcount.png')\n","84922e05":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np","13a53359":"data = pd.read_csv(\"..\/input\/credit-card-customers\/BankChurners.csv\")\ndata.drop([\"CLIENTNUM\", \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1\", \"Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2\"], axis=1, inplace=True)\n\n# Standardise column naming\ndata.columns = ['attrition_flag', 'customer_age', 'gender', 'dependent_count',\n       'education_level', 'marital_status', 'income_category', 'card_category',\n       'months_on_book', 'total_relationship_count', 'months_inactive_12_month',\n       'contacts_count_12_month', 'credit_limit', 'total_revolving_bal',\n       'avg_open_to_buy', 'total_amt_change_q4_q1', 'total_trans_amt',\n       'total_trans_count', 'total_count_change_q4_q1', 'avg_utilization_ratio']\n\ndata.head(1)","dafcee70":"from sklearn.model_selection import train_test_split\n\ny = data['attrition_flag']\nX = data.iloc[:, 1:]\nX.head()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2021, stratify=y)\n","c457fe4d":"data_dropped = data.drop( columns=[\"avg_open_to_buy\", \"total_trans_count\", \"customer_age\", \"avg_utilization_ratio\"] )\ndata_dropped.head(1)","5fc13bf7":"numerical = list( data_dropped.describe().columns )\n\ncategorical = [ col for col in data_dropped.columns if col not in numerical and col != 'attrition_flag']\n\nprint( \"Numerical Columns:\", numerical, end=\"\\n\")\nprint()\nprint( \"Categorical Columns:\", categorical, end=\"\\n\")","507f7aba":"skewed_features = data_dropped[numerical].skew()[ (data_dropped[numerical].skew() > 1) | (data_dropped[numerical].skew() < -1) ]\nskewed_features","036d167f":"data_log = data_dropped.copy()\nfor skewed_col in skewed_features.index:\n    data_log[skewed_col] = np.log( data_log[skewed_col].mask( data_log[skewed_col] <=0 ) ).fillna(0)\n\ndata_log.head(5)","d8bb38e0":"from sklearn.preprocessing import MinMaxScaler\ndata_scaled = data_log.copy()\nscaler = MinMaxScaler()\n\ndata_scaled[numerical] = scaler.fit_transform( data_log[numerical] )\ndata_scaled.head()","e04a4324":"for cat in categorical:\n    print(cat, data[cat].unique())\n    print()","65b0d10b":"# Separate features and label\nprocessed_features = data_scaled.copy()\nprocessed_label = data_scaled['attrition_flag']\nprocessed_features.drop(columns=['attrition_flag'], inplace=True)","9554f001":"from sklearn.preprocessing import LabelEncoder\nlabel_enc = LabelEncoder()\n\nprint('Before encoding')\nprint(data['gender'].iloc[:5].values)\nprocessed_features[\"gender\"] = label_enc.fit_transform( processed_features[\"gender\"] )\n\nprint('After encoding')\nprint(processed_features['gender'].iloc[:5].values )","52a55b3a":"from category_encoders.target_encoder import TargetEncoder\n\nprint('Before encoding')\nprint(data['marital_status'].iloc[:5].values)\nprocessed_features[\"marital_status\"] = label_enc.fit_transform( processed_features[\"marital_status\"] )\n\nprint('After encoding')\nprint(processed_features['marital_status'].iloc[:5].values )","8df159f3":"# from sklearn.model_selection import RandomizedSearchCV\n\n# n_estimators = [ n_trees for n_trees in range(100, 1001, 200) ]\n\n# max_depth = [ depth for depth in range(5, 30, 5) ]\n# max_depth.append( None )\n\n# min_samples_split = [3, 6, 9]\n\n# min_samples_leaf = [1, 2, 4]\n\n# bootstrap = [True, False]\n\n# params_grid = {'n_estimators': n_estimators,\n#                'max_depth': max_depth,\n#                'min_samples_split': min_samples_split,\n#                'min_samples_leaf': min_samples_leaf,\n#                'bootstrap': bootstrap}\n\n# print(params_grid)","80da9a16":"# from sklearn.ensemble import RandomForestClassifier\n\n# rf = RandomForestRegressor()\n# rf_random = RandomizedSearchCV(estimator = rf,\n#                                param_distributions = params_grid,\n#                                n_iter = 100,\n#                                random_state = 2021,\n#                                n_jobs = -1,\n#                                cv = 3\n#                                refit = True,\n#                                scoring='recall')","c6abc591":"## 6.1 Dropping collinear features\nFeatures with a Pearson Coefficient value > 0.7 is dropped to avoid multicollinearity \\\nSummary of collinearity from above:\n1. High correlation (direct) \u2014 `avg_open_to_buy` and `credit_limit`\n2. High correlation (direct) \u2014 `total_trans_amt` and `total_trans_count`\n3. High correlation (direct) \u2014 `customer_age` and `months_on_book`\n4. High correlation (direct) `total_revolving_bal` and `avg_utilization_ratio`\n5. Moderate correlation (inverse) \u2014 `credit_limit` and `avg_utilization_ratio`\n6. Moderate correlation (inverse) \u2014 `avg_open_to_buy` and `avg_utilization_ratio`\n7. Moderate correlation (direct) \u2014 `total_count_change_q4_q1` and `total_amt_change_q4_q1`\n8. Moderate correlation (indirect) \u2014 `total_trans_amt` and `total_relationship_count`\n9. Moderate correlation (indirect) \u2014 `total_trans_count` and `total_relationship_count`","5c8f991a":"### Standardise column names to small case","f55c52a6":"Features: `credit_limit` and `avg_open_to_buy` <br>\nCorrelation: 1","2fbce220":"### Plotting pairwise scatterplots","7e0668b0":"### Display value_counts for each categorical column","8e73e6ae":"### Splitting into train, test sets","d1698bb2":"Features: `total_trans_amt` and `total_trans_count` <br>\nCorrelation: 0.81","3beea74d":"# 1. Basic Exploration","6d484fe7":"### Import libraries","6cec889d":"Features: `total_revolving_bal` and `avg_utilization_ratio` <br>\nCorrelation: 0.62","2130a8ed":"### Boxplot for attrition_flag against each numerical column","0009fa88":"# 7. RandomForest","e8d209da":"# 3. Exploring Categorical Features","bd8d0963":"### Closer look at collinear featuers","93cdad36":"### Import data\nAdded the code here for easy access","2fdfe3b0":"# 4. Bivariate plots","ca178b22":"# 2. Exploring Numerical columns","0c24de75":"Based on the features, they are encoded as follows: \\\n- Nominal: gender, marital_status\n- Ordinal: education_level, income_category, card_category","018021c3":"## 6.2 Transforming skewed numerical features","caa682af":"Features: `total_amt_change_q4_q1` and `total_count_change_q4_q1` <br>\nCorrelation: 0.38","f916a804":"Features: `customer_age` and `months_on_book` <br>\nCorrelation: 0.79","a363a4fe":"## 6.4 Encoding categorical features","066aa325":"# CS421: Introduction to Machine Learning\n## Project: Customer Churn Prediction based on Customer Profile\nHey there!\nI am a university student at Singapore Management University. This notebook is for one of my class's project! <br>\nCurrently chipping at it bit by bit, the contents of the notebook are as follows:\n\n**PART 1: Exploratory Data Analysis** <br>\n1. Setting up the notebook\n2. Exploring categorical columns\n3. Exploring numerical columns\n4. Bivariate plots\n5. Multivariate plots\n\n**PART 2: Modelling and Analysis** <br>\n6. Preprocessing\n- Dropping collinear features\n- Transforming skewed features\n- Feature scaling\n- Encoding categorical features\n    - Handling nominal categorical\n    - Handling ordinal categorical\n7. Random Forest\n\n<br><br>\n\n**Any comments on the notebook, and how I can do things better, is highly appreciated!**\n\n---","67ee1d4b":"Some findings:\n1. High correlation (direct) \u2014 `avg_open_to_buy` and `credit_limit`\n2. High correlation (direct) \u2014 `total_trans_amt` and `total_trans_count`\n3. High correlation (direct) \u2014 `customer_age` and `months_on_book`\n4. High correlation (direct) `total_revolving_bal` and `avg_utilization_ratio`\n5. Moderate correlation (inverse) \u2014 `credit_limit` and `avg_utilization_ratio`\n6. Moderate correlation (inverse) \u2014 `avg_open_to_buy` and `avg_utilization_ratio`\n7. Moderate correlation (direct) \u2014 `total_count_change_q4_q1` and `total_amt_change_q4_q1`\n8. Moderate correlation (indirect) \u2014 `total_trans_amt` and `total_relationship_count`\n9. Moderate correlation (indirect) \u2014 `total_trans_count` and `total_relationship_count`","ba835084":"### Check for collinearity","e507dcf9":"Features: `credit_limit` and `avg_utilization_ratio` <br>\nCorrelation: -0.48","f3216826":"## 6.3 Feature Scaling\nScaling features using Normalisation to transform data points between range of 0 and 1","1ebde867":"### 6.4.1 Handling nominal features","d4daec92":"### Kernel density plots for numerical features","d8ef8d0b":"### Calculate Probability Distribution for Existing and Attrited Customers for each categorical columns","3b0ec27f":"Features: `avg_open_to_buy` and `avg_utilization_ratio` <br>\nCorrelation: -0.54","10bef614":"### 3D Boxplots of categorical columns against numerical columns across attrition_flag","fb82f720":"# 6. Preprocessing","73b0865e":"### Import data","e6864ea4":"### Functions","0cc02e63":"## 7.1 Preparations","0217f47b":"### Plot distribution for numerical columns","1f962086":"# 1. Setting up the notebook","74e8edeb":"Since all the features are positively skewed, log transformation is applied to all features","add4b278":"# 5. Multivariate Plots"}}