{"cell_type":{"3e56a8d9":"code","1c81a8ae":"code","200a649d":"code","62ab2b6f":"code","f33b2ea9":"code","aee5b2a7":"code","de9ffa7b":"code","ff7c9176":"code","c1a67e25":"code","1e963520":"code","77b11827":"code","d3f77efc":"code","f76913ec":"code","713bc9e9":"code","9bb92a9b":"code","40e4e224":"code","bd4de40b":"code","62df56ed":"code","92d5af81":"code","c207f199":"code","d19024ce":"code","85aa7707":"code","95f0a3c8":"markdown","8b627032":"markdown","64ef20f4":"markdown","de827dd8":"markdown"},"source":{"3e56a8d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n# If you're working in Jupyter Notebook, include the following so that plots will display:\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1c81a8ae":"# create a DataFrame with the data\ndf = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv',sep=',')\ndf.head()\n","200a649d":"# check the shape of the df\nprint(df.shape)\n\n# check if df has nan\ndf.isnull().sum()","62ab2b6f":"# add a column with binary quality (limit at 6.5)\ndf['quality_binary'] = np.where(df['quality'] <= 6.5,0,1)\n# reset the index\ndf = df.reset_index()\ndf.head()","f33b2ea9":"# visualiize the data\nfig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality_binary', y = 'density', data = df)","aee5b2a7":"# visualiize the data\nfig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality_binary', y = 'fixed acidity', data = df)","de9ffa7b":"# visualiize the data\nfig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality_binary', y = 'pH', data = df)","ff7c9176":"# visualiize the data\nfig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality_binary', y = 'total sulfur dioxide', data = df)","c1a67e25":"# visualiize the data\nfig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality_binary', y = 'sulphates', data = df)\nlist(df)","1e963520":"# prepare the dataset for ML\ndf = df.drop(columns=['quality'])\ndf = df.rename(columns={'quality_binary':'quality'})\n# plot the class number to check imbalancing\nsns.countplot(df['quality'])\n","77b11827":"#Now seperate the dataset as response variable and feature variabes\nX = df.drop(['quality','density','pH'], axis = 1)\ny = df['quality']\nprint(y.value_counts())","d3f77efc":"#Train and Test splitting of data \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","f76913ec":"#Applying Standard scaling to get optimized result\nsc = StandardScaler()","713bc9e9":"# split the data\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","9bb92a9b":"# call the model and fit the data\nrfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train, y_train)\n","40e4e224":"# do the prediction\npred_rfc = rfc.predict(X_test)","bd4de40b":"# View accuracy score\naccuracy_score(y_test, pred_rfc)","62df56ed":"# check the performance\nprint(classification_report(y_test, pred_rfc))","92d5af81":"# Get and reshape confusion matrix data\nmatrix = confusion_matrix(y_test, pred_rfc)\nmatrix = matrix.astype('float') \/ matrix.sum(axis=1)[:, np.newaxis]\n\n# Build the plot\nplt.figure(figsize=(16,7))\nsns.set(font_scale=1.4)\nsns.heatmap(matrix, annot=True, annot_kws={'size':10},\n            cmap=plt.cm.Greens, linewidths=0.2)\n\n# Add labels to the plot\nclass_names = ['bad_wine','good_wine']\ntick_marks = np.arange(len(class_names))\ntick_marks2 = tick_marks + 0.5\nplt.xticks(tick_marks, class_names, rotation=25)\nplt.yticks(tick_marks2, class_names, rotation=0)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.title('Confusion Matrix for Random Forest Model')\nplt.show()","c207f199":"# Import SMOTE module\nfrom imblearn.over_sampling import SMOTE\n# Create model and fit the training set to create a new training set\nsm = SMOTE(random_state = 2) \nX_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n# Create random forest model\nforest = RandomForestClassifier(n_estimators=100,random_state = 1)\n# Fit the model to the new train set\nforest.fit(X_train_res, y_train_res.ravel())\n# # Test out-of-sample test set\ny_pred = forest.predict(X_test)\n","d19024ce":"# check the performance\nprint(classification_report(y_test, y_pred))","85aa7707":"# Get and reshape confusion matrix data\nmatrix = confusion_matrix(y_test, y_pred)\nmatrix = matrix.astype('float') \/ matrix.sum(axis=1)[:, np.newaxis]\n\n# Build the plot\nplt.figure(figsize=(16,7))\nsns.set(font_scale=1.4)\nsns.heatmap(matrix, annot=True, annot_kws={'size':10},\n            cmap=plt.cm.Greens, linewidths=0.2)\n\n# Add labels to the plot\nclass_names = ['bad_wine','good_wine']\ntick_marks = np.arange(len(class_names))\ntick_marks2 = tick_marks + 0.5\nplt.xticks(tick_marks, class_names, rotation=25)\nplt.yticks(tick_marks2, class_names, rotation=0)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.title('Confusion Matrix for Random Forest Model')\nplt.show()","95f0a3c8":"add the SMOTE to oversample the good quality class","8b627032":"Random forest","64ef20f4":"there is a strong data imbalance ","de827dd8":"current values:\n         precision    recall  f1-score   support\n\n           0       0.94      0.98      0.96       288\n           1       0.67      0.44      0.53        32\n\n    accuracy                           0.92       320\n   macro avg       0.80      0.71      0.74       320\nweighted avg       0.91      0.92      0.91       320"}}