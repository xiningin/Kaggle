{"cell_type":{"e6ae00da":"code","6053571f":"code","126d15fe":"code","d8cc5471":"code","13a6e5f3":"code","650e038c":"code","c0797f10":"code","2f61b410":"code","6d065f19":"code","da7f073b":"code","12809e79":"code","79f5cada":"code","27ca00cc":"code","205784cd":"code","54a3aaf6":"code","e6b88ea0":"code","c35140ee":"code","74772994":"code","5b62be6a":"code","6721ecc0":"code","6bddb87d":"code","180a0f12":"code","74a47f12":"code","c34e534c":"code","b5226b2b":"code","a33a8bc8":"code","c72bdf59":"code","adbf4523":"code","be2e0053":"code","d46be907":"code","2c4c455b":"markdown","bed87308":"markdown","cf6dee39":"markdown","31e1e182":"markdown","40a7ffe2":"markdown","639b415d":"markdown","914ef750":"markdown","7cfeed94":"markdown","c0d2d577":"markdown","64467513":"markdown","b90fff57":"markdown","e78676f5":"markdown","ff5da62f":"markdown","7ac92ca9":"markdown","c0d21b79":"markdown","ef382c02":"markdown","7f757fb4":"markdown","46044f6a":"markdown","5ea213aa":"markdown","09971ec8":"markdown","e985daa2":"markdown","fbc8ee59":"markdown","2e4b1d97":"markdown","7733dcea":"markdown","28ae956e":"markdown","dbc2304c":"markdown","4467722b":"markdown","e4e724e9":"markdown","9734a60d":"markdown","a2495543":"markdown","ebabf4c1":"markdown","80b20561":"markdown","744380d9":"markdown"},"source":{"e6ae00da":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport pandas as pd\n#import numpy as np\n\nMAX_ROWS = 10\npd.set_option('display.max_rows', MAX_ROWS)\npd.set_option('display.max_columns', 200)\n \nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\")\n\nplt.rcParams['figure.figsize'] = (12,5)","6053571f":"path_dataset = '..\/input\/datos_properati_limpios.csv'\ndf = pd.read_csv(path_dataset, parse_dates=['created_on'])","126d15fe":"df.columns","d8cc5471":"print(\"El dataset que vamos a trabajar aqu\u00ed tiene {} observaciones\".format(df.shape[0]))","13a6e5f3":"# Mostr\u00e1 la figura en esta celda\ndf.dropna(subset = ['price_usd_per_m2'], inplace = True)\nsns.distplot(df['price_usd_per_m2'])\n","650e038c":"df.shape","c0797f10":"# El boxplot debe estar en esta celda\nsns.boxplot(x = df['price_usd_per_m2'])","2f61b410":"# Describir la columna en esta celda\ndf.price_usd_per_m2.describe()","6d065f19":"# Realizar el filtrado intercuart\u00edlico en esta celda\ndf_filtered = df.copy()\nQ1 = df_filtered['price_usd_per_m2'].quantile(0.25)\nQ3 = df_filtered['price_usd_per_m2'].quantile(0.75)\nIQR = Q3 - Q1\nLR = Q1 -(1.5 * IQR)\nUR = Q3 + (1.5 * IQR)\n\nprint ('el valor Minimo es '+ str(LR))\nprint ('el valor Maximo es '+ str(UR))\n\n\ndf_filtered.drop(df_filtered[(df_filtered.price_usd_per_m2 > UR) | (df_filtered.price_usd_per_m2< LR)].index, inplace=True)\ndf_filtered\n","da7f073b":"#Otra forma de hacerlo \n\nq1_price_usd_per_m2=df.price_usd_per_m2.quantile(0.25)\nq3_price_usd_per_m2=df.price_usd_per_m2.quantile(0.75)\niqr = df.price_usd_per_m2.quantile(0.75) - df.price_usd_per_m2.quantile(0.25)\nmin = q1_price_usd_per_m2 - (iqr*1.5)\nmax = q3_price_usd_per_m2 + (iqr*1.5)\ndf_filtered = df[df.price_usd_per_m2.between(min,max)]\n\ndf_filtered = df\nQ1 = df_filtered['price_usd_per_m2'].quantile(0.25)\nQ3 = df_filtered['price_usd_per_m2'].quantile(0.75)\nIQR = Q3 - Q1\ndf_filtered = df.query('(@Q1 - 1.5 * @IQR) <= price_usd_per_m2 <= (@Q3 + 1.5 * @IQR)')\ndf_filtered\n","12809e79":"#\u00a0Hac\u00e9 el distplot \nsns.distplot(df_filtered['price_usd_per_m2'])","79f5cada":"# Hac\u00e9 el boxplot en esta celda\nsns.boxplot(x = df_filtered['price_usd_per_m2'])","27ca00cc":"df_filtered['price_usd_per_m2'].describe()","205784cd":"df = df_filtered","54a3aaf6":"df.surface_total_in_m2.isna().mean().round(4) # hacer el resto y concatenar","e6b88ea0":"# Mostr\u00e1 los valores faltantes en esta celda\npor_surface_total_in_m2 = ((df.surface_total_in_m2.isna().sum()) \/ df.shape[0]) * 100\npor_surface_covered_in_m2 = ((df.surface_covered_in_m2.isna().sum()) \/ df.shape[0]) * 100\npor_rooms = ((df.rooms.isna().sum()) \/ df.shape[0] ) * 100\npor_price_aprox_usd =((df.price_aprox_usd.isna().sum()) \/ df.shape[0]) * 100\npor_price_usd_per_m2 = ((df.price_usd_per_m2.isna().sum()) \/ df.shape[0]) * 100\npor_expenses = ((df.expenses.isna().sum()) \/ df.shape[0]) * 100\n\n\nprint('% Sup. Total NULOS = {a}\\n% Sup. Cubierta NULOS = {b}\\n% Ambientes NULOS = {c}\\n% Precio aprox U$D NULOS = {d}\\n% Precio aprox U$D\/M2 NULOS = {e}\\n% Expensas NULOS = {f}' .format(a=por_surface_total_in_m2, b=por_surface_covered_in_m2, c=por_rooms, d=por_price_aprox_usd, e=por_price_usd_per_m2, f=por_expenses))","c35140ee":"#Otra forma mas directa de hacerlo es de la siguiente manera\ndf.isna().mean().round(4) * 100","74772994":"#Otra forma mas directa de hacerlo es de la siguiente manera\ndf.isna().mean().sort_values(ascending=False)*100","5b62be6a":"df = df.drop(['floor', 'expenses'], axis = 1)","6721ecc0":"# Imputar los valores en esta celda\n\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\n\nimp_mean = SimpleImputer(strategy='mean')\n\nimp_mean = imp_mean.fit(df[['surface_total_in_m2']])\ndf[['surface_total_in_m2']] = imp_mean.transform(df[['surface_total_in_m2']])\ndf[['surface_covered_in_m2']] = imp_mean.transform(df[['surface_covered_in_m2']])\n\n\n\n","6bddb87d":"#Chequeamos que no haya valores nulos. para corroborar que el proceso funciono\ndf.loc[:,['surface_total_in_m2','surface_covered_in_m2']].isna().sum()\n","180a0f12":"#Otra forma \n\nimp_mean = SimpleImputer(strategy='mean', missing_values=np.nan)\ndf[['surface_total_in_m2','surface_covered_in_m2']] = imp_mean.fit_transform(df[['surface_total_in_m2','surface_covered_in_m2']])","74a47f12":"# Imputar con la mediana en esta celda\nimp_median = SimpleImputer(strategy='median')\n\nimp_median = imp_median.fit(df[['rooms']])\ndf[['rooms']] = imp_median.transform(df[['rooms']])\n\ndf.isna().sum() # chequer que no queden nulos","c34e534c":"# Utiliz\u00e1 LabelEncoder en esta celda\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(df[\"property_type\"])\n\nle.transform(df[\"property_type\"]) #ahora las variables caregoricas toman un indicador numerico","b5226b2b":"# Mostrar la propiedad classes_ del LabelEncoder que creaste\nlist(le.classes_)","a33a8bc8":"# Utiliz\u00e1 OneHotEncoder en esta celda \n\ndf_encoded = le.transform(df[\"property_type\"]) #Primero asignamos una variable el codigo realizado anteriormente\n\nfrom sklearn.preprocessing import OneHotEncoder\nonehot_encoder = OneHotEncoder(sparse=False)\n\ndf_encoded = df_encoded.reshape(len(df_encoded), 1)\n\ncategoricals_df = onehot_encoder.fit_transform(df_encoded)\n\ncategoricals_df = pd.DataFrame (categoricals_df, dtype = int, columns = le.classes_) #lo paso a entero para evitar futuros problemas en el modelado y uso label encoder para pasar el nombre de la columna\n\ncategoricals_df\n\n\n","c72bdf59":"categoricals_df = categoricals_df.set_index(df.index)\ndf = pd.concat([df, categoricals_df], axis=1)\ndf.head()","adbf4523":"def custom_division(x, y):\n    if y > 0:\n        res = x \/ y\n    else:\n        res = 0\n    return res\n\ndf['price_m2'] = df.apply(lambda x: custom_division(x['price_aprox_usd'], x['surface_total_in_m2']), axis = 1)\ndf.drop(['price_usd_per_m2'], axis=1, inplace=True)","be2e0053":"# Creamos un dataset con los porcentajes de nulos\ndf_faltantes = pd.DataFrame(df.isnull().sum() \/ df.shape[0], columns=['Porcentaje nulos'])\n# Solo mostramos los que tengan valores nulos. Si el porcentaje es 0 no se muestra\ndf_faltantes.loc[~(df_faltantes==0).all(axis=1)]","d46be907":"print(\"El dataset final luego del procesamiento tiene {} observaciones\".format(df.shape[0]))","2c4c455b":"__Calcular el precio por metro cuadrado (precio\/superficie total). Llamar a este atributo `price_m2`.__\n\nHay que tener cuidado en esta parte respecto de dividir por cero. Para ello, armemos una funci\u00f3n de divisi\u00f3n que contemple eso.\n\nEl hecho de crear una columna nueva y no imputar los faltantes es simplemente una decisi\u00f3n. Cuando veamos modelos predictivos, vamos a poder cuantificar el costo de las decisiones que tomemos en t\u00e9rminos de performance del modelo.","bed87308":"Podemos ver en los resultados que los atributos `floor` y `expenses` tienen un elevado porcentaje de faltantes.  Una opci\u00f3n ser\u00eda descartar estas columnas en el an\u00e1lisis. \nSi elimin\u00e1ramos las observaciones (filas) asociadas a estos, perder\u00edamos el 84.79% de los datos, mermando demasiado el conjunto de datos.\n\nOtra opci\u00f3n ser\u00eda por ejemplo considerar categor\u00edas como faltantes o no faltantes o en todo caso analizar si hay alg\u00fan patr\u00f3n para poder evitar quitarlos. \n\nPara avanzar con el proyecto, vamos a quitar esos atributos.","cf6dee39":"Unimos el nuevo dataframe `categorical_df` con el `dataframe` original `df`. Para esto, necesitamos que tengan el mismo \u00edndice.","31e1e182":"### Variables binarias","40a7ffe2":"Analicemos en primer lugar los valores extremos que puede haber en los precios y en las superficies. Esto nos va a ser \u00fatil para luego imputar usando medidas de tendencia central, como el promedio. \nRecordemos que las medidas de tendencia central pueden ser sensibles a outliers, por lo que la imputaci\u00f3n de valores faltantes puede verse afectada\n\nUna posible pregunta que surge es si conviene primero imputar faltantes y luego remover outliers, o lo contrario.  Cuando se imputa se modifica la distribuci\u00f3n de los datos. Por eso, las cotas que utilicemos para definir los outliers se ver\u00e1n afectadas por este cambio y modificar\u00e1n los resultados finales. Entonces comenzaremos quitando outliers.\n\nVamos a trabajar con `price_usd_per_m2`. Precios altos pueden corresponderse con grandes superficies, por lo que conviene analizar juntos ambos atributos. Veamos la distribuci\u00f3n de los valores y un boxplot para comenzar a identificar los outliers.","639b415d":"Analicemos estrategias para imputar los valores faltantes para los atributos `rooms`, `surface_total_in_m2` y `surface_covered_in_m2`.\n\nComo vimos en las actividades, entre las opciones que tenemos est\u00e1 la posibilidad de imputar por alg\u00fan medida de tendencia central, como el caso de la media o la mediana. Vamos a avanzar en esa direcci\u00f3n.","914ef750":"**9) Imputar las observaciones faltantes** de la columna `rooms` usando la **mediana**.","7cfeed94":"**8) Imputar las observaciones faltantes** de la columna `surface_total_in_m2 ` y `surface_covered_in_m2` usando la **media**. \n\n`Scikit-learn` nos provee la clase `Imputer` que implementa las formas m\u00e1s comunes de imputaci\u00f3n.","c0d2d577":"#### Generar variables binarias para el atributo `property_type`.\n\nHay que tener en cuenta en este caso que el atributo es categ\u00f3rico.\n\nPara hacerlo usando scikit-learn, por como vienen dados los valores (en formato string), primero conviene convertirlos en num\u00e9ricos. Para esto usamos `LabelEncoder`.\n\n**10) Convert\u00ed** las variables de `property_type` utilizando `LabelEncoder`","64467513":"Una de las limitaciones que presenta este tipo de imputaci\u00f3n es que provoca estimaciones sesgadas de la varianza. Esto impacta en los errores estandar y, por ende, en los tests estad\u00edstcos.\n\nEste tipo de t\u00e9cnicas es \u00fatil cuando los valores son completamente al azar.","b90fff57":"**RESPUESTA:** Podr\u00edamos llegar a una r\u00e1pida conclusi\u00f3n, de que los valores de **price_usd_per_m2** tienen demasiados valores at\u00edpicos o fuera de rango, esto puede generar  \"ruido\" en nuestro an\u00e1lisis, por lo que deber\u00edamos deshacernos de esos valores y volver a graficar.","e78676f5":"**5)** Volver a **plotear** con `distplot` y `boxplot` los precios sin los outliers y observ\u00e1 las diferencias con los anteriores ploteo.","ff5da62f":"Dado que ya lo trabajamos en el proyecto anterior, en este caso ya hemos filtrado observaciones para trabajar solo con casas (house), departamentos (apartment) y PH (PH).","7ac92ca9":"A diferencia del proyecto pasado, vamos a intentar imputar los valores faltantes para los atributos que consideramos importantes para el mercado inmobiliario. \n\nEstos atributos son los que informan **superficie (total o cubierta), cantidad de ambientes, precio y precio por metro cuadrado**. \n\nVeamos en primer lugar cu\u00e1ntos valores faltantes tiene cada atributo. Nos interesa verlo como un porcentaje en relaci\u00f3n a la cantidad de observaciones. Si un atributo tiene un elevado porcentaje de faltantes, puede ser mejor no considerarlo en el an\u00e1lisis.","c0d21b79":"# Proyecto: Engrasandonos las manos con datos","ef382c02":"**7) Mostrar** cual es el porcentaje de valores faltantes para cada columna.","7f757fb4":"En este proyecto, trabajaremos con una muestra del conjunto de datos de propiedades en venta mencionado. En este dataset, cada fila es una propiedad en venta. A continuaci\u00f3n vamos a describir los atributos que consideramos en esta muestra:\n\n* id: id de la propiedad\n* created_on: fecha en la que la propiedad ingres\u00f3 al sitio\n* operation: alquiler (rent) o venta (sell)\n* property_type: tipo de propiedad (casa, departamento, ph, etc\u00e9tera)\n* place_with_parent_names: nombre del lugar donde se encuentra la propiedad seg\u00fan el publicador\n* lat-lon: coordenadas concatenadas\n* lat: latitud\n* lon: longitud\n* price: precio en la moneda especificada en currency\n* currency: divisa en la que est\u00e1 expresada la publicaci\u00f3n\n* price_aprox_usd: precio aproximado en d\u00f3lares estadounidenses\n* surface_total_in_m2: superficie total (en metros cuadrados)\n* surface_covered_in_m2: superficie cubierta (en metros cuadrados)\n* price_usd_per_m2: precio por metro cuadrado en d\u00f3lares (precio d\u00f3lares \/ superficie)\n* floor: n\u00famero de piso (si corresponde)\n* rooms: cantidad de ambientes\n* expenses: expensas (si corresponde)\n* barrio: barrio seg\u00fan cartograf\u00eda oficial\n* properati_url: url de la publicaci\u00f3n en Properati\n\nA continuaci\u00f3n vamos a levantar el dataset para comenzar el procesamiento. Cabe destacar que en este caso ya fueron hechas las correcciones de coordenadas y superficies incorrectas que vimos en el proyecto anterior","46044f6a":"**2) Hac\u00e9** un `boxplot` de la columna `price_usd_per_m2`","5ea213aa":"De este modo, hemos limpiado valores extremos e imputado valores nulos. El costo de esto fue la p\u00e9rdida de 685 observaciones, 5% de la cantidad original de filas.","09971ec8":"Estamos ante la presencia de valores extremos en ambas puntas de la distribuci\u00f3n. Vamos a aplicar la t\u00e9cnica del rango intercuart\u00edlico para limpiarlos.\n\nPara obtener el rango tenemos que calcular la diferencia entre el tercer y el primer percentil. Luego en base a esto calcularemos los valores m\u00ednimos y m\u00e1ximos para definir qu\u00e9 observaciones ser\u00e1n descartadas.\n\n**4) Aplicar la t\u00e9cnica del rango intercuart\u00edlico** para limpiar el precio por metro cuadrado. El resultado deber\u00e1 ser un `dataframe` llamado `df_filtered` sin los outliers.","e985daa2":"__Verificar que ya no quedan atributos con valores faltantes__","fbc8ee59":"**11) Mostrar** las clases del `LabelEncoder`:","2e4b1d97":"Para confirmar la presencia de outliers vamos a utilizar los percentiles.\n\n**3) Describir** la columna mostrando sus estad\u00edsticos","7733dcea":"### Variables calculadas","28ae956e":"**1) Utiliz\u00e1** seaborn para hacer un `distplot` del precio por metro cuadrado. \n\nDeber\u00e1s hacer un `drop` de los valores `NaN` de esta columna antes de graficar.","dbc2304c":"Vamos a seguir trabajando con el `dataframe` filtrado","4467722b":"\u00bfA qu\u00e9 conclusi\u00f3n podemos llegar observando estas figuras?\n**Responder**","e4e724e9":"## Dataset: Propiedades en venta en Ciudad de Buenos Aires.","9734a60d":"### Outliers","a2495543":"### Valores Faltantes","ebabf4c1":"Luego con `OneHotEncoder` obtenemos las categor\u00edas expresadas como **variables binarias**. \n\n**12) Aplicar** `OneHotEncoder` sobre las variables categ\u00f3ricas para crear un dataframe `categoricals_df`","80b20561":"**6) Describir** nuevamente la columna mostrando sus estad\u00edsticos.","744380d9":"\u00a1Bienvenidos al segundo proyecto de la carrera de Data Science de Acamica! \n\nEn este proyecto vamos a seguir trabajando con el dataset de propiedades en venta publicadas en el portal [Properati](www.properati.com.ar). El objetivo en este caso es continuar con la limpieza de datos y avanzar en remover valores faltantes y remover outliers. Por otro lado, vamos a agregar nuevos atributos basados en los datos."}}