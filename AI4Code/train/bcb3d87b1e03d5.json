{"cell_type":{"a3f7d4a1":"code","0dedc305":"code","64d1f54a":"code","e6ea35d4":"code","4ce7fdca":"code","0f2738a1":"code","e29bd334":"code","e52ad899":"code","706523db":"code","c9738f6e":"code","5a0117c5":"code","5b84bdea":"code","5a9ab97f":"code","5fc81c8c":"code","fa83de34":"code","6552e75f":"code","b3d4f9f4":"code","9b6470a6":"code","0a5e03c3":"code","340eace0":"code","dae9a434":"markdown","4c994a67":"markdown","d2b10320":"markdown"},"source":{"a3f7d4a1":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nimport numpy as np\nimport tensorflow.keras.initializers as initer\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport pickle","0dedc305":"class InstanceNormalization(Layer):\n    def __init__(self, axis=(1, 2), epsilon=1e-6):\n        super().__init__()\n        self.epsilon = epsilon\n        self.axis = axis\n        self.beta, self.gamma = None, None\n\n    def build(self, input_shape):\n        shape = [1 for _ in range(len(input_shape))]\n        shape[-1] = input_shape[-1]\n        self.gamma = self.add_weight(\n            name='gamma',\n            shape=shape,\n            initializer='ones')\n\n        self.beta = self.add_weight(\n            name='beta',\n            shape=shape,\n            initializer='zeros')\n\n    def call(self, x, *args, **kwargs):\n        mean = tf.math.reduce_mean(x, axis=self.axis, keepdims=True)\n        x -= mean\n        variance = tf.reduce_mean(tf.math.square(x), axis=self.axis, keepdims=True)\n        x *= tf.math.rsqrt(variance + self.epsilon)\n        return x * self.gamma + self.beta","64d1f54a":"class AdaNorm(Layer):\n    def __init__(self, axis=(1, 2), epsilon=1e-6):\n        super().__init__()\n        # NHWC\n        self.axis = axis\n        self.epsilon = epsilon\n\n    def call(self, x, **kwargs):\n        mean = tf.math.reduce_mean(x, axis=self.axis, keepdims=True)\n        x -= mean\n        variance = tf.reduce_mean(tf.math.square(x), axis=self.axis, keepdims=True)\n        x *= tf.math.rsqrt(variance + self.epsilon)\n        return x","e6ea35d4":"class AdaMod(Layer):\n    def __init__(self):\n        super().__init__()\n        self.y = None\n\n    def call(self, inputs, **kwargs):\n        x, w = inputs\n        y = self.y(w)\n        o = (y[:, 0] + 1) * x + y[:, 1]\n        return o\n\n    def build(self, input_shape):\n        x_shape, w_shape = input_shape\n        self.y = keras.Sequential([\n            Dense(x_shape[-1]*2, input_shape=w_shape[1:], kernel_initializer=initer.HeNormal()),\n            Reshape([2, 1, 1, -1]),\n        ])  # [2, h, w, c] per feature map","4ce7fdca":"class AddNoise(Layer):\n    def __init__(self):\n        super().__init__()\n        self.s = None\n        self.x_shape = None\n\n    def call(self, inputs, **kwargs):\n        x, noise = inputs\n        noise_ = noise[:, :self.x_shape[1], :self.x_shape[2], :]\n        return self.s * noise_ + x\n\n    def build(self, input_shape):\n        self.x_shape, _ = input_shape\n        self.s = self.add_weight(name=\"noise_scale\", shape=[1, 1, self.x_shape[-1]],\n                                 initializer=initer.RandomNormal(0, 0.05))","0f2738a1":"class Map(Layer):\n    def __init__(self, size, num_layers, norm=None):\n        super().__init__()\n        self.size = size\n        self.num_layers = num_layers\n        self.norm_name = norm\n        self.f = None\n\n    def call(self, inputs, **kwargs):\n        w = self.f(inputs)\n        return w\n\n    def build(self, input_shape):\n        self.f = keras.Sequential()\n        for i in range(self.num_layers):\n            if i == 0:\n                self.f.add(Dense(self.size, input_shape=input_shape[1:], kernel_initializer=initer.HeNormal()))\n                continue\n            self.f.add(LeakyReLU(0.2))\n            if self.norm_name is not None:\n                if self.norm_name.lower() == \"batch\":\n                    self.f.add(BatchNormalization())    # batch norm also increase model collapse\n                elif self.norm_name.lower() == \"instance\":\n                    self.f.add(InstanceNormalization(axis=(1,)))        # instance norm increase model collapse\n\n            self.f.add(Dense(self.size, kernel_initializer=initer.HeNormal()))","e29bd334":"class Style(Layer):\n    def __init__(self, filters, upsampling=True):\n        super().__init__()\n        self.filters = filters\n        self.upsampling = upsampling\n        self.ada_mod, self.ada_norm, self.add_noise, self.up, self.conv, self.conv_expend = None, None, None, None, None, None\n\n    def call(self, inputs, **kwargs):\n        x, w, noise = inputs\n        # x = self.conv_expend(x)     #TODO: may help for styling\n        x = self.ada_mod((x, w))\n        if self.up is not None:\n            x = self.up(x)\n        x = self.conv(x)\n        x = LeakyReLU(0.2)(x)\n        x = self.add_noise((x, noise))\n        x = self.ada_norm(x)\n        return x\n\n    def build(self, input_shape):\n        self.ada_mod = AdaMod()\n        self.ada_norm = AdaNorm()\n        if self.upsampling:\n            self.up = UpSampling2D((2, 2), interpolation=\"bilinear\")\n        self.add_noise = AddNoise()\n        # self.conv_expend = Conv2D(self.filters*2, 1, 1, kernel_initializer=initer.HeNormal())\n        self.conv = Conv2D(self.filters, 3, 1, \"same\", kernel_initializer=initer.HeNormal())","e52ad899":"def get_generator(latent_dim, img_shape , num_layers ,base=256):\n    \n    n_style_block = 0\n    \n    const_size = _size = 4\n    \n    while _size <= img_shape[1]:\n        n_style_block += 1\n        _size *= 2\n\n    z = keras.Input((n_style_block, latent_dim,), name=\"z\") #(m,blocks,dim)\n    noise_ = keras.Input((img_shape[0], img_shape[1]), name=\"noise\") #(m,h,w)\n    ones = keras.Input((1,), name=\"ones\")#(m,1)\n\n    w = Map(size=base, num_layers=num_layers)(z)\n    noise = tf.expand_dims(noise_, axis=-1) #(m,h,w,1), pixel-wise noise\n    const = keras.Sequential([\n        Dense(const_size * const_size * base, use_bias=False, name=\"const\", kernel_initializer=initer.HeNormal()),\n        Reshape((const_size, const_size, -1)),\n    ], name=\"const\")(ones)\n\n    x = AddNoise()((const, noise))\n    x = AdaNorm()(x)\n    \n    \n    for i in range(n_style_block):\n        x = Style(base, upsampling=False if i == 0 else True)((x, w[:, i], noise))\n        \n        \n    o = Conv2D(img_shape[-1], 7, 1, \"same\", activation=keras.activations.tanh)(x)\n\n    g = keras.Model([ones, z, noise_], o, name=\"generator\")\n    return g, n_style_block","706523db":"def get_discriminator(img_shape):\n    def add_block(filters, do_norm=True, padding=\"same\"):\n        model.add(Conv2D(filters, 4, strides=2, padding=padding))\n        if do_norm: \n            model.add(InstanceNormalization())\n        model.add(LeakyReLU(alpha=0.2))\n\n    model = keras.Sequential([Input(img_shape)], name=\"d\")\n    # [n, 128, 128, 3]\n    # model.add(GaussianNoise(0.02))\n    add_block(32, do_norm=False)   # -> 64^2\n    add_block(64)                   # -> 32^2\n    add_block(128)                  # -> 16^2\n    add_block(256)                  # -> 8^2\n    add_block(512, padding=\"valid\")  # -> 4^2\n    model.add(Flatten())\n    # model.add(GlobalAveragePooling2D())\n    model.add(Dense(256))\n    model.add(Dense(1))\n    return model","c9738f6e":"class Trainer(keras.Model):\n    def __init__(self,img_shape,latent_dim,num_layers=5,lr=2e-4,\n                 beta1=0.5, beta2=0.99, lambda_=10, wgan=2):\n        '''\n        img_shape:(h,w,c)\n        z_dim: dim\n        '''\n        super().__init__()\n        self.img_shape=img_shape\n        self.latent_dim=latent_dim\n        self.wgan=wgan\n        self.lambda_=lambda_\n        \n        self.g,self.n_blocks=get_generator(latent_dim,img_shape,num_layers=num_layers)\n        self.d=get_discriminator(img_shape)\n        \n    \n        self.opt = keras.optimizers.Adam(lr, beta_1=beta1, beta_2=beta2)\n\n        \n        \n    def call(self, inputs, training=None, mask=None):\n        '''\n        inputs:[ones,z,noise]\n        '''\n        if isinstance(inputs[0], np.ndarray):\n            inputs = [tf.convert_to_tensor(i) for i in inputs]\n        return self.g(inputs, training=training)\n    \n    \n    def get_inputs(self, n):\n        if np.random.rand() < 0.5:\n            available_z = [tf.random.normal((n, 1, self.latent_dim)) for _ in range(2)]\n            z = tf.concat([available_z[np.random.randint(0, len(available_z))] for _ in range(self.n_blocks)], axis=1)\n        else:\n            z = tf.repeat(tf.random.normal((n, 1, self.latent_dim)), self.n_blocks, axis=1)\n        noise = tf.random.normal((n, self.img_shape[0], self.img_shape[1]))\n        return [tf.ones((n, 1)), z, noise]\n    \n    @staticmethod\n    def w_distance(real, fake):\n        # the distance of two data distributions\n        return tf.reduce_mean(real) - tf.reduce_mean(fake)\n    \n    def gp(self, real_img, fake_img):\n        e = tf.random.uniform((len(real_img), 1, 1, 1), 0, 1)\n        noise_img = e * real_img + (1. - e) * fake_img  # extend distribution space\n        with tf.GradientTape() as tape:\n            tape.watch(noise_img)\n            o = self.d(noise_img)\n        g = tape.gradient(o, noise_img)  # image gradients\n        g_norm2 = tf.sqrt(tf.reduce_sum(tf.square(g), axis=[1, 2, 3]))  # norm2 penalty\n        gp = tf.square(g_norm2 - 1.)\n        return tf.reduce_mean(gp)\n    \n    def train_d(self, img):\n        n = len(img)\n\n        with tf.GradientTape() as tape:\n            gimg = self.call(self.get_inputs(n), training=False) #(n,h,w,3)\n            gp = self.gp(img, gimg)\n            pred_fake = self.d(gimg, training=True)\n            pred_real = self.d(img, training=True)\n            w_distance = -self.w_distance(pred_real, pred_fake)  # maximize W distance\n            gp_loss = self.lambda_ * gp\n            loss = gp_loss + w_distance\n        grads = tape.gradient(loss, self.d.trainable_variables)\n        self.opt.apply_gradients(zip(grads, self.d.trainable_variables))\n        return gp, w_distance\n\n    def train_g(self, n):\n        with tf.GradientTape() as tape:\n            gimg = self.call(self.get_inputs(n), training=True)\n            pred_fake = self.d(gimg, training=False)\n            w_distance = tf.reduce_mean(-pred_fake)  # minimize W distance\n        grads = tape.gradient(w_distance, self.g.trainable_variables)\n        self.opt.apply_gradients(zip(grads, self.g.trainable_variables))\n        return w_distance\n    \n    @tf.function\n    def step(self, img):\n        gw = self.train_g(len(img)*2) #this is just a trick, not following original training method\n        for _ in range(self.wgan):\n            dgp, dw = self.train_d(img)\n        return gw, dgp, dw \n    \n    '''\n    gw: generator loss\n    dw: discriminator loss\n    dgp: gradient penalty\n    '''","5a0117c5":"batch_size=32\nepochs=4\nlatent_dim=128\nlr=2e-4\nb1=0\nb2=0.99\nw=2\nimage_size=128\nlam=10\nnum_layers=5","5b84bdea":"def show(model):\n    global z1, z2\n    n = 7\n    if \"z1\" not in globals():\n        z1 = np.random.normal(0, 1, size=(n, 1, model.latent_dim))\n    if \"z2\" not in globals():\n        z2 = np.random.normal(0, 1, size=(n, 1, model.latent_dim))\n    n_z1 = 3\n    assert n_z1 < model.n_blocks - 1\n    noise = np.random.normal(0, 1, [len(z1), model.img_shape[0], model.img_shape[1]])\n    \n    #mixing style\n    inputs = [\n        np.ones((len(z1)*n, 1)),\n        np.concatenate(\n            (z1.repeat(n, axis=0).repeat(n_z1, axis=1),\n             np.repeat(np.concatenate([z2 for _ in range(n)], axis=0), model.n_blocks - n_z1, axis=1)),\n            axis=1\n        ),\n        noise.repeat(n, axis=0),\n    ]\n    \n    #marginal style\n    z1_inputs = [np.ones((len(z1), 1)), z1.repeat(model.n_blocks, axis=1), noise]\n    z2_inputs = [np.ones((len(z2), 1)), z2.repeat(model.n_blocks, axis=1), noise]\n\n    imgs = model.predict(inputs)\n    z1_imgs = model.predict(z1_inputs)\n    z2_imgs = model.predict(z2_inputs)\n    imgs = np.concatenate([z2_imgs, imgs], axis=0)\n    rest_imgs = np.concatenate([np.ones([1, 128, 128, 3], dtype=np.float32), z1_imgs], axis=0)\n    for i in range(len(rest_imgs)):\n        imgs = np.concatenate([imgs[:i * (n+1)], rest_imgs[i:i + 1], imgs[i * (n+1):]], axis=0)\n    imgs = (imgs + 1) \/ 2\n\n    nc, nr = n+1, n+1\n    f = plt.figure(0, (nc*1.5, nr*1.5))\n    for c in range(nc):\n        for r in range(nr):\n            i = r * nc + c\n            plt.subplot(nr, nc, i + 1)\n            plt.imshow(imgs[i])\n            plt.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()","5a9ab97f":"pth='..\/input\/celeba-dataset\/img_align_celeba'\n\n\nds=tf.keras.preprocessing.image_dataset_from_directory(\n    directory=pth,\n    image_size=(image_size,image_size),\n    batch_size=batch_size,\n    seed=0,\n    shuffle=True\n)","5fc81c8c":"trainer=Trainer((image_size,image_size,3),latent_dim,num_layers,lr,b1,b2,lam,w)","fa83de34":"_=trainer.step(tf.random.normal((32,128,128,3))) #to prevent nontype error","6552e75f":"try:\n    trainer.load_weights('..\/input\/weights\/StyleGAN.pt')\n    print('load weights successfully')\nexcept:\n    print('no weights ')","b3d4f9f4":"track={'gw':[],'dgp':[],'dw':[]}","9b6470a6":"def main(ds):\n    aug=Rescaling(1\/127.5,offset=-1)\n    ds=ds.map(lambda x,y : (aug(x),y))\n    ckpt = tf.train.Checkpoint(trainer=trainer)\n    ckpt_manager = tf.train.CheckpointManager(ckpt,'.\/ckpt', max_to_keep=1)\n    i=0\n    for epoch in range(epochs):\n        show(trainer)\n        trainer.save_weights('.\/weights\/StyleGAN.pt')\n        i+=1\n            \n        loop=tqdm(ds)\n        for x,y in loop:\n            gw, dgp, dw = trainer.step(x)\n            \n            track['gw'].append(gw)\n            track['dgp'].append(dgp)\n            track['dw'].append(dw)\n            \n            loop.set_postfix(loss=f'epoch : {epoch}, gw:{gw}, dgp:{dgp}, dw:{dw}')","0a5e03c3":"main(ds)","340eace0":"with open('.\/track.pickle','wb') as file:\n    pickle.dump(track,file)","dae9a434":"* Train","4c994a67":"# Training","d2b10320":"# Model"}}