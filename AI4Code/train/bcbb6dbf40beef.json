{"cell_type":{"157e1cef":"code","ef9fcbc9":"code","b2cc6459":"code","8a7236ef":"code","b1a1bff3":"code","aa809a6d":"code","1ea14027":"code","9b9d9350":"code","0c5d9acc":"code","df5ac1fc":"code","8907ef96":"code","0afb1a58":"code","063db279":"code","40785dac":"code","c98a0a22":"code","45f21a0e":"code","2ef286ec":"code","01a9a521":"code","c4b25178":"code","b5bd4d28":"code","d4099067":"code","1a926030":"code","a4213a27":"code","4e2ea705":"code","99a9b860":"code","2d9d81a5":"code","905a8bfb":"code","c9279e5b":"code","5c366304":"code","d7a184c3":"code","e9853fd8":"markdown","aadcb29a":"markdown"},"source":{"157e1cef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef9fcbc9":"trainfile = '\/kaggle\/input\/rossmann-store-sales\/train.csv'\ntestfile = '\/kaggle\/input\/rossmann-store-sales\/test.csv'\nstorefile = '\/kaggle\/input\/rossmann-store-sales\/store.csv'\nsubfile = '\/kaggle\/input\/rossmann-store-sales\/sample_submission.csv'","b2cc6459":"train = pd.read_csv(trainfile)\ntest = pd.read_csv(testfile)\nstore = pd.read_csv(storefile)\nprint(train.shape, test.shape, store.shape)","8a7236ef":"train.head(2)","b1a1bff3":"test.drop('Id',axis=1,inplace=True)\ntest.head(2)","aa809a6d":"traindf = train.merge(store,on=[\"Store\"],how=\"inner\")\nprint(traindf.shape)\ntraindf.head()","1ea14027":"testdf = test.merge(store,on=[\"Store\"],how=\"inner\")\nprint(testdf.shape)\ntestdf.head()","9b9d9350":"store.head()","0c5d9acc":"competition_open = []\nfor index, value in store[['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear']].iterrows():\n    try:\n        year, month = int(value['CompetitionOpenSinceYear']), int(value['CompetitionOpenSinceMonth'])\n        date = pd.to_datetime(\"{}-{}-01\".format(year, month), format='%Y-%m')\n        competition_open.append(date)\n    except:\n        competition_open.append(np.nan)\ncompetition_open = pd.Series(competition_open)\ncompetition_open.shape","df5ac1fc":"store['CompetitionOpen'] = competition_open #converted int to datetime\nstore['CompetitionOpen'] = store.CompetitionOpen.dt.strftime('%Y%m%d')","8907ef96":"#### Create a new variable called promo ###\npromo = []\nfor index, value in store[['Promo2SinceWeek', 'Promo2SinceYear']].iterrows():\n    try:\n        year, week = int(value['Promo2SinceYear']), int(value['Promo2SinceWeek'])\n        date = pd.to_datetime(\"{}-{}-01\".format(year, week), format='%Y%W')\n        promo.append(date)\n    except:\n        promo.append(np.nan)\npromo = pd.to_datetime(pd.Series(competition_open))\nprint(promo.shape)","0afb1a58":"store['PromoSince'] = promo #converted int to datetime\nstore['PromoSince'] = store.PromoSince.dt.strftime('%Y%m%d')","063db279":"store_features = ['Store', 'StoreType', 'Assortment', 'CompetitionDistance', 'CompetitionOpen', \n                  'PromoSince',]\ntraindf = pd.merge(train, store[store_features], how='left', on=['Store'])\ntraindf.head()","40785dac":"testdf = pd.merge(test, store[store_features], how='left', on=['Store'])\ntestdf.head()","c98a0a22":"store_data_sales = traindf.groupby([traindf['Store']])['Sales'].sum()\nstore_data_customers = traindf.groupby([traindf['Store']])['Customers'].sum()\nstore_data_open = traindf.groupby([traindf['Store']])['Open'].count()\n\nstore_data_sales_per_day = store_data_sales \/ store_data_open\nstore_data_customers_per_day = store_data_customers \/ store_data_open\nstore_data_sales_per_customer_per_day = store_data_sales_per_day \/ store_data_customers_per_day\n\ndf_store = pd.merge(store, store_data_sales_per_day.reset_index(name='SalesPerDay'), how='left', on=['Store'])\ndf_store = pd.merge(df_store, store_data_customers_per_day.reset_index(name='CustomersPerDay'), how='left', on=['Store'])\ndf_store = pd.merge(df_store, store_data_sales_per_customer_per_day.reset_index(name='SalesPerCustomersPerDay'), how='left', on=['Store'])","45f21a0e":"store_features = ['Store', 'SalesPerDay', 'CustomersPerDay', 'SalesPerCustomersPerDay']\nfeatures_x = test.columns.tolist()\nfeatures_x = list(set(features_x + store_features))\ntraindf = pd.merge(traindf, df_store[store_features], how='left', on=['Store'])\ntestdf = pd.merge(testdf, df_store[store_features], how='left', on=['Store'])","2ef286ec":"traindf.drop('Customers', axis=1, inplace=True)\nprint(traindf.shape, testdf.shape)\ntraindf.head()","01a9a521":"testdf.head()","c4b25178":"!pip install featurewiz","b5bd4d28":"ts_column = 'Date'","d4099067":"import featurewiz as FW","1a926030":"traindf2, ts_adds_in = FW.FE_create_time_series_features(traindf, ts_column, ts_adds_in=[])\nprint(traindf2.shape)\ntraindf2.head()","a4213a27":"testdf2, _ = FW.FE_create_time_series_features(testdf, ts_column, ts_adds_in)\nprint(testdf2.shape)\ntestdf2.head()","4e2ea705":"testdf2.drop(['Date_minute', 'Date_hour'],axis=1,inplace=True)","99a9b860":"!pip install deep_autoviml","2d9d81a5":"from deep_autoviml import deep_autoviml as deepauto","905a8bfb":"#traindf2.to_csv('rossmann_train.csv', index=False)\n#testdf2.to_csv('rossmann_test.csv', index=False)","c9279e5b":"keras_model_type = \"auto\" ## always try \"fast\" first, then \"fast1\", \"fast2\", etc.\nproject_name = \"Rossmann\"\nmodel_options = {'nlp_char_limit':50,'max_trials': 10, }\nkeras_options = {'early_stopping': True,}\ntarget = \"Sales\"","5c366304":"model, cat_vocab_dict = deepauto.fit(traindf2, target, keras_model_type=keras_model_type,\n\t\tproject_name=\"deep_autoviml\", keras_options=keras_options,  \n\t\tmodel_options=model_options, save_model_flag=True, use_my_model='',\n\t\tmodel_use_case='', verbose=0)","d7a184c3":"predictions = deepauto.predict(model, project_name, test_dataset=testdf2,\n                                 keras_model_type=keras_model_type, \n                                 cat_vocab_dict=cat_vocab_dict)","e9853fd8":"# Let's use featurewiz to create new date-time columns","aadcb29a":"# Now Install Deep AutoViML"}}