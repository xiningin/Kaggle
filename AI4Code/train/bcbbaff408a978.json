{"cell_type":{"42290b11":"code","644bc864":"code","6b1a55fd":"code","9f275b19":"code","923c9e37":"code","00ec2b79":"code","adb52153":"code","4919794d":"code","abbe747d":"code","0f454e85":"code","a0375336":"code","7dde20d3":"code","6a9e2a4d":"code","af57e57b":"code","d9404d30":"code","ce552e93":"code","71ca1a7e":"code","bef56d21":"code","e5bd9d04":"code","f90ad054":"code","0319299d":"code","31267d50":"code","8a917f4d":"code","6a8aacdd":"code","cf09bba6":"code","f43255fc":"code","3f3a60d8":"code","32dc960c":"code","c4277299":"code","f3435cd6":"code","df070252":"code","6b9548ff":"code","fb25c754":"code","22b80351":"code","fb74b1a1":"code","f55d7aa1":"code","8f49fff1":"code","62997b5f":"code","f6374d9d":"code","c82f53e1":"code","02c14207":"code","3d8c847d":"code","60b21546":"code","23296159":"code","1cdbe552":"code","1391a156":"code","99e76892":"code","c1de4ac0":"code","4ab43d94":"code","9ab512a7":"code","990ac34e":"code","84a8d85a":"code","1df833d2":"code","3884c896":"code","c50a17e7":"code","523de2a2":"code","81c1a8d9":"code","079f810f":"code","60b11a1e":"code","c71f4212":"code","688c17bf":"markdown","93a75454":"markdown","86775bb5":"markdown","2da290c8":"markdown","570ef84c":"markdown","11448851":"markdown","ba30fea0":"markdown","0f7668ef":"markdown","bc2978b3":"markdown","086eae6e":"markdown","8ba1a4c8":"markdown","825f8c8d":"markdown","6db5036c":"markdown","8887b992":"markdown","e228d421":"markdown","78a5b2dd":"markdown","1d600d82":"markdown","08a92cbb":"markdown","25c45970":"markdown","06ba9686":"markdown","c046f535":"markdown","9f19288f":"markdown","9e689026":"markdown","6ae314f0":"markdown","56c56783":"markdown","6eeb5339":"markdown","3a03dc1e":"markdown","f0702507":"markdown","744a0dee":"markdown","57097cc4":"markdown","33afee87":"markdown","ee8bf4ea":"markdown","9fa571a9":"markdown","d9cde0c8":"markdown","9868ebd5":"markdown","a3090687":"markdown","42b3d432":"markdown","cf7660e3":"markdown","c0920f03":"markdown","06561a66":"markdown","8c38160b":"markdown","19f86871":"markdown","d02c0376":"markdown","10f62527":"markdown","da42014b":"markdown","7c41debb":"markdown","bc4b710d":"markdown","0916c4da":"markdown","6986cfd3":"markdown","8c12b0ea":"markdown","936ab6fa":"markdown","a693cc1d":"markdown","fad5cb44":"markdown","28b1c2e7":"markdown","6515593f":"markdown","a4822c22":"markdown"},"source":{"42290b11":"from sklearn import model_selection, preprocessing, metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pylab as pylab\nimport matplotlib.pyplot as plt\nfrom pandas import get_dummies\nimport lightgbm as lgb\nimport matplotlib as mpl\nimport xgboost as xgb\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport warnings\nimport sklearn\nimport scipy\nimport numpy\nimport json\nimport sys\nimport csv\nimport os","644bc864":"print('matplotlib: {}'.format(matplotlib.__version__))\nprint('sklearn: {}'.format(sklearn.__version__))\nprint('scipy: {}'.format(scipy.__version__))\nprint('seaborn: {}'.format(sns.__version__))\nprint('pandas: {}'.format(pd.__version__))\nprint('numpy: {}'.format(np.__version__))\nprint('Python: {}'.format(sys.version))\n","6b1a55fd":"sns.set(style='white', context='notebook', palette='deep')\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nsns.set_style('white')\npd.set_option('display.max_columns', 500)\n%matplotlib inline","9f275b19":"import os\nprint(os.listdir(\"..\/input\"))\n","923c9e37":"main_train = pd.read_csv('..\/input\/train.csv', parse_dates=[\"first_active_month\"] )\nmain_test = pd.read_csv('..\/input\/test.csv' ,parse_dates=[\"first_active_month\"] )\nmain_merchants=pd.read_csv('..\/input\/merchants.csv')\nmain_new_merchant_transactions=pd.read_csv('..\/input\/new_merchant_transactions.csv')\nmain_historical_transactions = pd.read_csv(\"..\/input\/historical_transactions.csv\")","00ec2b79":"sample_submission = pd.read_csv(\"..\/input\/sample_submission.csv\")","adb52153":"sample_submission.shape","4919794d":"sample_submission.head()","abbe747d":"print(main_train.info())","0f454e85":"print(main_test.info())","a0375336":"print(\"Shape of train set                 : \",main_train.shape)\nprint(\"Shape of test set                  : \",main_test.shape)\nprint(\"Shape of historical_transactions   : \",main_historical_transactions.shape)\nprint(\"Shape of merchants                 : \",main_merchants.shape)\nprint(\"Shape of new_merchant_transactions : \",main_new_merchant_transactions.shape)\n","7dde20d3":"data_dictionary_train=pd.read_excel('..\/input\/Data_Dictionary.xlsx',sheet_name='train')\ndata_dictionary_history=pd.read_excel('..\/input\/Data_Dictionary.xlsx',sheet_name='history')\ndata_dictionary_new_merchant_period=pd.read_excel('..\/input\/Data_Dictionary.xlsx',sheet_name='new_merchant_period')\ndata_dictionary_merchant=pd.read_excel('..\/input\/Data_Dictionary.xlsx',sheet_name='merchant')","6a9e2a4d":"main_train.tail()","af57e57b":"data_dictionary_train.head(10)\n# what we know about train:","d9404d30":"main_train.tail()","ce552e93":"main_train.describe()","71ca1a7e":"print('----- test set--------')\nprint(main_test.head(5))","bef56d21":"main_test.info()","e5bd9d04":"main_test.describe()","f90ad054":"data_dictionary_history.head(10)\n# what we know about history:","0319299d":"main_historical_transactions.head()","31267d50":"main_historical_transactions.shape","8a917f4d":"main_merchants.head()","6a8aacdd":"data_dictionary_merchant.head(30)\n# what we know about merchant:","cf09bba6":"main_new_merchant_transactions.head()","f43255fc":"data_dictionary_new_merchant_period.head(10)\n# what we know about new_merchant_period:","3f3a60d8":"def check_missing_data(df):\n    flag=df.isna().sum().any()\n    if flag==True:\n        total = df.isnull().sum()\n        percent = (df.isnull().sum())\/(df.isnull().count()*100)\n        output = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n        data_type = []\n        # written by MJ Bahmani\n        for col in df.columns:\n            dtype = str(df[col].dtype)\n            data_type.append(dtype)\n        output['Types'] = data_type\n        return(np.transpose(output))\n    else:\n        return(False)","32dc960c":"print ('for train :',check_missing_data(main_train))\nprint ('for test:',check_missing_data(main_test))","c4277299":"# remove rows that have NA's\nprint('Before Droping',main_train.shape)\nmain_train = main_train.dropna()\nprint('After Droping',main_train.shape)","f3435cd6":"main_train.columns","df070252":"main_train[\"target\"].hist();","6b9548ff":"main_train[main_train[\"target\"]<-29].count()","fb25c754":"# histograms\nmain_train.hist(figsize=(15,20))\nplt.figure()","22b80351":"f,ax=plt.subplots(1,2,figsize=(20,10))\nmain_train[main_train['feature_3']==0].target.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')\nax[0].set_title('feature_3= 0')\nx1=list(range(0,85,5))\nax[0].set_xticks(x1)\nmain_train[main_train['feature_3']==1].target.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')\nax[1].set_title('feature_3= 1')\nx2=list(range(0,85,5))\nax[1].set_xticks(x2)\nplt.show()","fb74b1a1":"f,ax=plt.subplots(1,2,figsize=(18,8))\nmain_train['feature_3'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('feature_3')\nax[0].set_ylabel('')\nsns.countplot('feature_3',data=main_train,ax=ax[1])\nax[1].set_title('feature_3')\nplt.show()","f55d7aa1":"f,ax=plt.subplots(1,2,figsize=(18,8))\nmain_train[['feature_3','feature_2']].groupby(['feature_3']).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs feature_2')\nsns.countplot('feature_3',hue='feature_2',data=main_train,ax=ax[1])\nax[1].set_title('feature_3:feature')\nplt.show()","8f49fff1":"sns.distplot(main_train['target'])","62997b5f":"sns.violinplot(data=main_train, x=\"feature_1\", y='target')","f6374d9d":"plt.figure(figsize=(8,6))\nplt.scatter(range(main_train.shape[0]), np.sort(main_train['target'].values),marker='o',c='green')\nplt.xlabel('index', fontsize=12)\nplt.ylabel('Loyalty Score', fontsize=12)\nplt.title('Explore: Target')\nplt.show();","c82f53e1":"# Modify the graph above by assigning each species an individual color.\ng = sns.FacetGrid(main_train, hue=\"feature_3\", col=\"feature_2\", margin_titles=True,\n                  palette={1:\"blue\", 0:\"red\"} )\ng=g.map(plt.scatter, \"first_active_month\", \"target\",edgecolor=\"w\").add_legend();","02c14207":"sns.boxplot(x=\"feature_3\", y=\"feature_2\", data=main_test )\nplt.show()","3d8c847d":"main_train.where(main_train ['target']==1).count()","60b21546":"main_train[main_train['target']<-32].head(5)","23296159":"main_train[main_train['target']==1].head(5)","1cdbe552":"main_train.feature_1.unique()","1391a156":"main_train.feature_2.unique()","99e76892":"main_train.feature_3.unique()","c1de4ac0":"main_train.first_active_month.unique()","4ab43d94":"df_train=main_train\ndf_test=main_test","9ab512a7":"df_train[\"year\"] = main_train[\"first_active_month\"].dt.year\ndf_test[\"year\"] = main_test[\"first_active_month\"].dt.year","990ac34e":"df_train[\"month\"] = main_train[\"first_active_month\"].dt.month\ndf_test[\"month\"] = main_test[\"first_active_month\"].dt.month","84a8d85a":"x_train = df_train.drop([\"target\",\"card_id\",\"first_active_month\"],axis=1)\nx_test = df_test.drop([\"card_id\",\"first_active_month\"],axis=1)","1df833d2":"y_train = df_train[\"target\"]\ndf_train = df_train.sample(frac=1, random_state = 7)","3884c896":"\nTrn_x,val_x,Trn_y,val_y = train_test_split(x_train,y_train,test_size =0.1,random_state = 7)\ntrn_x , test_x, trn_y, test_y = train_test_split(Trn_x , Trn_y, test_size =0.1, random_state = 7)","c50a17e7":"# rmse\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))","523de2a2":"# converting into xgb DMatrix\nTrain = xgb.DMatrix(trn_x,label = trn_y)\nValidation = xgb.DMatrix(val_x, label = val_y)\nTest = xgb.DMatrix(test_x)","81c1a8d9":"params = {\"booster\":\"gbtree\",\"eta\":0.1,'min_split_loss':0,'max_depth':6,\n         'min_child_weight':1, 'max_delta_step':0,'subsample':1,'colsample_bytree':1,\n         'colsample_bylevel':1,'reg_lambda':1,'reg_alpha':0,\n         'grow_policy':'depthwise','max_leaves':0,'objective':'reg:linear','eval_metric':'rmse',\n         'seed':7}\nhistory ={}  # This will record rmse score of training and test set\neval_list =[(Train,\"Training\"),(Validation,\"Validation\")]","079f810f":"clf = xgb.train(params, Train, num_boost_round=119, evals=eval_list, obj=None, feval=None, maximize=False, \n          early_stopping_rounds=40, evals_result=history);","60b11a1e":"prediction = clf.predict(xgb.DMatrix(x_test))","c71f4212":"submission = pd.DataFrame({\n        \"card_id\": main_test[\"card_id\"].values,\n        \"target\": np.ravel(prediction)\n    })","688c17bf":"As you can see in the below in python, it is so easy perform some query on the dataframe:","93a75454":"<a id=\"3\"><\/a> <br>\n## 3- Problem Definition\nI think one of the important things when you start a new machine learning project is Defining your problem. that means you should understand business problem.( **Problem Formalization**)\n<img src='http:\/\/s8.picofile.com\/file\/8344103134\/Problem_Definition2.png' width=400 height=400>\n ><font color=\"red\"><b>Note: <\/b><\/font>\nWe are predicting a **loyalty score** for each card_id represented in test.csv and sample_submission.csv.","86775bb5":"1. The train set  is approximately twice the test set\n2. The target data value is between -33.219281 and 17.965068","2da290c8":"<a id=\"6\"><\/a> <br>\n## 6- EDA\nBy the end of the section, you'll be able to answer these questions and more, while generating graphics that are both insightful and beautiful.  then We will review analytical and statistical operations:\n\n1. Data Collection\n1. Visualization\n1. Data Cleaning\n1. Data Preprocessing\n<img src=\"http:\/\/s9.picofile.com\/file\/8338476134\/EDA.png\" width=400 height=400>\n\n ###### [Go to top](#top)","570ef84c":"<a id=\"633\"><\/a> <br>\n## 6-3-3 violinplot","11448851":"<a id=\"8\"><\/a> <br>\n# 8- Conclusion\nThis kernel is not completed yet , I have tried to cover all the parts related to the process of **Elo  problem** with a variety of Python packages and I know that there are still some issues then I hope to get your feedback to improve it.\n","ba30fea0":"Go to first step: [**Course Home Page**](https:\/\/www.kaggle.com\/mjbahmani\/10-steps-to-become-a-data-scientist)\n\nGo to next step : [**Mathematics and Linear Algebra**](https:\/\/www.kaggle.com\/mjbahmani\/linear-algebra-for-data-scientists)\n","0f7668ef":"<a id=\"51\"><\/a> <br>\n## 5-1 Import","bc2978b3":"<a id=\"614\"><\/a> <br>\n## 6-1-4 Train Analysis","086eae6e":" <a id=\"1\"><\/a> <br>\n## 1- Introduction\n**[Elo](https:\/\/www.cartaoelo.com.br\/)** has defined a competition in **Kaggle**. A realistic and attractive data set for data scientists.\non this notebook, I will provide a **comprehensive** approach to solve Elo Recommendation problem for **Beginners**.\n <a id=\"11\"><\/a> <br>\n## 1-1 Kaggle kernels\nI have just listed some more important kernels that inspired my work and I've used them in this kernel:\n1. [simple-python-lightgbm-example](https:\/\/www.kaggle.com\/ezietsman\/simple-python-lightgbm-example)\n1. [simple-exploration-notebook-elo](https:\/\/www.kaggle.com\/sudalairajkumar\/simple-exploration-notebook-elo)\n1. [prediction-using-xgboost](https:\/\/www.kaggle.com\/harshit92\/prediction-using-xgboost-3-771)\n1. [elo-world](https:\/\/www.kaggle.com\/mjbahmani\/elo-world)\n1. [simple-lightgbm-without-blending](https:\/\/www.kaggle.com\/mfjwr1\/simple-lightgbm-without-blending)\n<br>\n<br>\nI am open to getting your feedback for improving this **kernel**.\n","8ba1a4c8":"<a id=\"62\"><\/a> <br>\n## 6-2 Data Cleaning\nWhen dealing with real-world data, dirty data is the norm rather than the exception.\n\n###### [Go to top](#top)","825f8c8d":"<a id=\"61\"><\/a> <br>\n## 6-1 Data Collection\nI start Collection Data by the training and testing datasets into **Pandas DataFrames**.\n###### [Go to top](#top)","6db5036c":"**<< Note 2 >>**\nin pandas's data frame you can perform some query such as \"where\"","8887b992":"we should be careful about them!","e228d421":"<a id=\"52\"><\/a> <br>\n## 5-2 version","78a5b2dd":"<a id=\"612\"><\/a> <br>\n## 6-1-2 Explorer Dataset\n1- Dimensions of the dataset.\n\n2- Peek at the data itself.\n\n3- Statistical summary of all attributes.\n\n4- Breakdown of the data by the class variable.\n\n ><font color=\"red\"><b>Note: <\/b><\/font> Don\u2019t worry, each look at the data is **one command**. These are useful commands that you can use again and again on future projects.\n###### [Go to top](#top)","1d600d82":"you can use tails command to explorer dataset, such as ","08a92cbb":"<a id=\"53\"><\/a> <br>\n## 5-3 Setup\n\nA few tiny adjustments for better **code readability**","25c45970":"### The kernel is not completed and will be updated soon  !!!","06ba9686":"<a id=\"63\"><\/a> <br>\n## 6-3 Data Visualization\n###### [Go to top](#top)","c046f535":"Most of the targets almost have the value between +8 or -8,please check the plot below. and some of data have value (-30)","9f19288f":"<a id=\"641\"><\/a> <br>\n## 6-4-1Some New Feature","9e689026":"<a id=\"6141\"><\/a> <br>\n### 6-1-4-1 Train Description\nsome info about train set","6ae314f0":"<a id=\"32\"><\/a> <br>\n## 3-2 Business View \n**Elo** has built machine learning models to understand the most important aspects and preferences in their customers\u2019 lifecycle, from food to shopping. But so far none of them is specifically tailored for an individual or profile. This is where you come in.\n\n###### [Go to top](#top)","56c56783":"<a id=\"5\"><\/a> <br>\n## 5- Select Framework\nAfter problem definition and problem feature, we should select our **framework** to solve the **problem**.\nWhat we mean by the framework is that  the programming languages you use and by what modules the problem will be solved.\n###### [Go to top](#top)","6eeb5339":"We have three features that they are **Anonymized** ","3a03dc1e":"\nWe can get a quick idea of how many instances (rows) and how many attributes (columns) the data contains with the shape property.","f0702507":"<a id=\"71\"><\/a> <br>\n## 7-1 Evaluation\nSubmissions are scored on the root mean squared error. RMSE(Root Mean Squared Error) is defined as:\n<img src='https:\/\/www.includehelp.com\/ml-ai\/Images\/rmse-1.jpg'>\nwhere y^ is the predicted loyalty score for each card_id, and y is the actual loyalty score assigned to a card_id.\n\n ><font color=\"red\"><b>Note: <\/b><\/font>\n You must answer the following question:\nHow does your company expect to use and benefit from **your model**.\n###### [Go to top](#top)","744a0dee":" ><font color=\"red\"><b>Note: <\/b><\/font>\n \n* All **data** is simulated and fictitious, and is not real customer data\n* Each **row** is an observation (also known as : sample, example, instance, record).\n* Each **column** is a feature (also known as: Predictor, attribute, Independent Variable, input, regressor, Covariate).\n###### [Go to top](#top)","57097cc4":"<a id=\"31\"><\/a> <br>\n## 3-1 About Elo\n [Elo](https:\/\/www.cartaoelo.com.br\/) is one of the largest **payment brands** in Brazil, has built partnerships with merchants in order to offer promotions or discounts to cardholders. But \n1. do these promotions work for either the consumer or the merchant?\n1. Do customers enjoy their experience? \n1. Do merchants see repeat business? \n\n ><font color=\"red\"><b>Note: <\/b><\/font>\n**Personalization is key**.\n","33afee87":"<a id=\"615\"><\/a> <br>\n## 6-1-5 Historical Transactions Analysis","ee8bf4ea":"<a id=\"7\"><\/a> <br>\n## 7- Apply Learning\nHow to understand what is the best way to solve our problem?!","9fa571a9":"After loading the data via **pandas**, we should checkout what the content is, description and via the following:","d9cde0c8":"<a id=\"2\"><\/a> <br>\n## 2- A Data Science Workflow for Elo\nOf course, the same solution can not be provided for all problems, so the best way is to create a **general framework** and adapt it to new problem.\n\n**You can see my workflow in the below image** :\n\n <img src=\"http:\/\/s8.picofile.com\/file\/8342707700\/workflow2.png\"  \/>\n\n**You should feel free\tto\tadjust \tthis\tchecklist \tto\tyour needs**\n###### [Go to top](#top)","9868ebd5":"<a id=\"614\"><\/a> <br>\n## 6-1-4 Merchant Analysis","a3090687":"**<< Note >>**\n>**Preprocessing and generation pipelines depend on a model type**","42b3d432":"# <div style=\"text-align: center\">Statistical Analysis for Elo<\/div>\n### <div align=\"center\"><b>Quite Practical and Far from any Theoretical Concepts<\/b><\/div>\n<div style=\"text-align:center\">last update: <b>19\/02\/2019<\/b><\/div>\n<img src='http:\/\/s8.picofile.com\/file\/8344134250\/KOpng.png'>\n\n>You are reading **10 Steps to Become a Data Scientist** and are now in the 8th step : \n\n1. [Leren Python](https:\/\/www.kaggle.com\/mjbahmani\/the-data-scientist-s-toolbox-tutorial-1)\n2. [Python Packages](https:\/\/www.kaggle.com\/mjbahmani\/the-data-scientist-s-toolbox-tutorial-2)\n3. [Mathematics and Linear Algebra](https:\/\/www.kaggle.com\/mjbahmani\/linear-algebra-for-data-scientists)\n4. [Programming &amp; Analysis Tools](https:\/\/www.kaggle.com\/mjbahmani\/20-ml-algorithms-15-plot-for-beginners)\n5. [Big Data](https:\/\/www.kaggle.com\/mjbahmani\/a-data-science-framework-for-quora)\n6. [Data visualization](https:\/\/www.kaggle.com\/mjbahmani\/top-5-data-visualization-libraries-tutorial)\n7. [Data Cleaning](https:\/\/www.kaggle.com\/mjbahmani\/machine-learning-workflow-for-house-prices)\n8. <font color=\"red\">You are in the 8th step<\/font>\n9. [A Comprehensive ML  Workflow with Python](https:\/\/www.kaggle.com\/mjbahmani\/a-comprehensive-ml-workflow-with-python)\n10. [Deep Learning](https:\/\/www.kaggle.com\/mjbahmani\/top-5-deep-learning-frameworks-tutorial)\n\nYou can Fork and Run this kernel on **Github**:\n> ###### [ GitHub](https:\/\/github.com\/mjbahmani\/10-steps-to-become-a-data-scientist)\n\n-------------------------------------------------------------------------------------------------------------\n **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES<\/b><\/font> would be very much appreciated**\n \n -----------","cf7660e3":"<a id=\"634\"><\/a> <br>\n## 6-3-4 Scatter plot\nScatter plot Purpose to identify the type of relationship (if any) between two quantitative variables","c0920f03":"-------------------------------------------------------------------------------------------------------------\n\n **I hope you find this kernel helpful and some <font color=\"red\"><b>UPVOTES<\/b><\/font> would be very much appreciated**\n \n -----------","06561a66":"<a id=\"613\"><\/a> <br>\n## 6-1-3 Features\nFeatures can be from following types:\n* numeric\n* categorical\n* ordinal\n* datetime\n* coordinates\n\nFind the type of features in **Elo dataset**?!\n\nFor getting some information about the dataset you can use **info()** command.","8c38160b":"<a id=\"9\"><\/a> <br>\n# 9- References & Credits\n1. [hackernoon](https:\/\/hackernoon.com\/choosing-the-right-machine-learning-algorithm-68126944ce1f)\n1. [medium](https:\/\/medium.com\/@pushkarmandot\/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc)\n1. [encoding-categorical-features](https:\/\/towardsdatascience.com\/encoding-categorical-features-21a2651a065c)","19f86871":"<a id=\"631\"><\/a> <br>\n## 6-3-1  Histogram","d02c0376":"<a id=\"4\"><\/a> <br>\n## 4- Problem Feature\nProblem Definition has four steps that have illustrated in the picture below:\n\n\n1. Aim\n1. Variable\n1. Inputs & Outputs\n1. Evaluation\n<a id=\"41\"><\/a> <br>\n\n### 4-1 Aim\nDevelop algorithms to identify and serve the most relevant opportunities to individuals, by uncovering signal in customer loyalty.\nWe are predicting a **loyalty score** for each card_id represented in test.csv and sample_submission.csv.\n\n<a id=\"42\"><\/a> <br>\n### 4-2 Variables\nThe data is formatted as follows:\n\ntrain.csv and test.csv contain card_ids and information about the card itself - the first month the card was active, etc. train.csv also contains the target.\n\nhistorical_transactions.csv and new_merchant_transactions.csv are designed to be joined with train.csv, test.csv, and merchants.csv. They contain information about transactions for each card, as described above.\n\nmerchants can be joined with the transaction sets to provide additional merchant-level information.\n\n\n<a id=\"43\"><\/a> <br>\n### 4-3 Inputs & Outputs\nwe use **train.csv** and **test.csv** as Input and we should upload a  **submission.csv** as Output","10f62527":"you can Fork and Run this kernel on **Github**:\n> ###### [ GitHub](https:\/\/github.com\/mjbahmani\/10-steps-to-become-a-data-scientist)\n","da42014b":"<a id=\"632\"><\/a> <br>\n## 6-3-2  distplot","7c41debb":"If you compare **describe()** function for  test and train, you find that they are so similar!","bc4b710d":"## 6-1-5 New Merchant Transactions Analysis","0916c4da":"## 6-1-5 Test Analysis","6986cfd3":" ><font color=\"red\"><b>Note: <\/b><\/font> But if we had , we can just use **dropna()**(be careful sometimes you should not do this!)","8c12b0ea":"<a id=\"6121\"><\/a> <br>\n## 6-1-2-1 data_dictionary Analysis\nElo Provides a excel file to describe about data(feature). It has four sheet and we have just read them with below code:","936ab6fa":"How many NA elements in every column!!\n\nGood news, it is Zero!\n\n ><font color=\"red\"><b>Note: <\/b><\/font> To check out how many null info are on the dataset, we can use **isnull().sum()**.","a693cc1d":"To print dataset **columns**, we can use columns atribute.","fad5cb44":"<a id=\"64\"><\/a> <br>\n## 6-4 Data Preprocessing\n\n\n>What methods of preprocessing can we run on  Elo?! \n###### [Go to top](#top)","28b1c2e7":"<a id=\"642\"><\/a> <br>\n## 6-4-2 Feature Encoding","6515593f":"<a id=\"top\"><\/a> <br>\n## Notebook  Content\n1. [Introduction](#1)\n    1. [Kaggle kernels](#11)\n1. [Data Science Workflow for Elo](#2)\n1. [Problem Definition](#3)\n    1. [About Elo](#31)\n    1. [Business View](#32)\n        1. [Real world Application Vs Competitions](#321)\n1. [Problem feature](#4)\n    1. [Aim](#41)\n    1. [Variables](#42)\n    1. [ Inputs & Outputs](#43)\n    1. [Evaluation](#44)\n1. [Select Framework](#5)\n    1. [Import](#51)\n    1. [Version](#52)\n    1. [Setup](#53)\n1. [Exploratory data analysis](#6)\n    1. [Data Collection](#61)\n        1. [data_dictionary Analysis](#611)\n        1. [Explorer Dataset](#612)\n    1. [Data Cleaning](#62)\n    1. [Data Visualization](#63)\n        1. [countplot](#631)\n        1. [pie plot](#632)\n        1. [Histogram](#633)\n        1. [violin plot](#634)\n        1. [kdeplot](#635)\n    1. [Data Preprocessing](#64)\n1. [Apply Learning](#7)\n    1. [Evaluation](#71)\n1. [Conclusion](#8)\n1. [References](#9)","a4822c22":"<a id=\"635\"><\/a> <br>\n## 6-3-5 Box\n"}}