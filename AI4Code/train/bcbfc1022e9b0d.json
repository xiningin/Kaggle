{"cell_type":{"db0fa162":"code","91dc03ec":"code","c55ceee7":"code","0dd299e7":"code","887feb0e":"code","e39cf946":"code","e7066a4d":"code","b81739ba":"code","82ad5267":"code","58fe5530":"code","a3a8d37e":"code","8ec26bbb":"code","9a7d7f1c":"code","3694eb4e":"code","b1386d77":"code","a1c3a30e":"code","73222e3c":"code","03e79a14":"code","ade2322f":"code","4b47014a":"code","f4e21e9e":"code","154968b7":"code","e79e40ab":"code","24fec3be":"code","2b832749":"code","74874887":"code","ed4d46e9":"code","9f256e92":"code","13209d3b":"code","651a532b":"code","eb547679":"code","ea07a0e1":"code","476afad1":"code","8da47f70":"code","06b91501":"code","290eacd4":"code","dedc60e5":"code","fa79eeb3":"code","d5d35646":"code","57ae0ff3":"code","59084f98":"code","f241c144":"code","e41bdf6d":"code","080cfe72":"code","e7367bf1":"code","dd4e103d":"code","55b17151":"code","bc6ec077":"code","7d5d5e0a":"code","e8f8262c":"code","2c03d121":"code","a567c3bf":"code","f0e84326":"code","0bd09aac":"code","36599059":"code","4a703dc4":"code","123e299a":"code","c8d1b345":"code","3ed9bb49":"code","39ebe4c2":"code","7474f5f5":"code","634ddaa7":"code","fdb7fa94":"code","15015344":"code","9b03a92f":"code","72a754e4":"code","c5fb3ba0":"code","def0480f":"markdown","6c86235d":"markdown","2f151024":"markdown","a72be399":"markdown","43f3df2c":"markdown","4082d1fc":"markdown","b9e534d4":"markdown","783be32b":"markdown","36c1f0d0":"markdown","66e37356":"markdown","57f36a41":"markdown","7af7210a":"markdown","ca1c82d0":"markdown","aeb21054":"markdown","d8b9f1e6":"markdown","0060f0f5":"markdown","106a78d6":"markdown","85f34172":"markdown","1dccc667":"markdown","2d8de6bc":"markdown","97c28d89":"markdown","0ff03c41":"markdown","7d3d72cb":"markdown","768e1217":"markdown","27da470e":"markdown","449823d0":"markdown","69056b7f":"markdown"},"source":{"db0fa162":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly as py\nimport os\nimport plotly.io as pio\npio.renderers.default='notebook'\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import AgglomerativeClustering, DBSCAN\nimport scipy.cluster.hierarchy as shc \n\n\nimport category_encoders as ce\n\nplt.style.use('seaborn-colorblind')\n%matplotlib inline","91dc03ec":"df = pd.read_csv('..\/input\/german-credit\/german_credit_data.csv', index_col = 'Unnamed: 0')\nprint(df.shape)\ndf.head()","c55ceee7":"df.info()","0dd299e7":"df.describe()","887feb0e":"df.describe(include=['object'])","e39cf946":"df.nunique()","e7066a4d":"numeric = ['Age', 'Job', 'Credit amount', 'Duration']\ncategorical = ['Sex', 'Housing', 'Saving accounts', 'Checking account', 'Purpose']","b81739ba":"def check_missing(data, output_path=None):\n    \"\"\"\u0421\u0447\u0438\u0442\u0430\u0435\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0438 \u0434\u043e\u043b\u044e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432.\"\"\"\n    result = pd.concat([data.isnull().sum(), data.isnull().mean()], axis=1)\n    result = result.rename(index=str, columns={0: 'total missing', 1: 'proportion'})\n    if output_path:\n        result.to_csv(f'{output_path}missing.csv')\n        print(output_path, 'missing.csv')\n    return result","82ad5267":"check_missing(data=df)","58fe5530":"df= df.fillna('unknown')","a3a8d37e":"df.hist(figsize = (20,15));","8ec26bbb":"for col in df[categorical].columns:\n    sns.countplot(y =col, data = df)\n    plt.show()","9a7d7f1c":"plt.figure(figsize=(20,8))\nplotnumber =1\nfor column in df[numeric]:\n    ax = plt.subplot(2,2,plotnumber)\n    sns.boxplot(data = df, x = column, palette='pastel')\n    plt.xlabel(column)\n    plotnumber+=1\nplt.show()","3694eb4e":"sns.pairplot(df)\nplt.show;","b1386d77":"corr = df.corr()\nplt.figure(figsize=(10,8));\nsns.heatmap(corr, annot=True, fmt='.2f');","a1c3a30e":"data = df.copy()","73222e3c":"np.log(data['Age']).hist()","03e79a14":"data['Age'] = np.log(data['Age'])","ade2322f":"np.log(data['Credit amount']).hist()","4b47014a":"data['Credit amount'] = np.log(data['Credit amount'])","f4e21e9e":"from sklearn.preprocessing import LabelEncoder","154968b7":"encoder = LabelEncoder()\nfrom sklearn.preprocessing import LabelEncoder\nfor label in categorical:\n    data[label] = encoder.fit_transform(data[label])","e79e40ab":"data[categorical]","24fec3be":"from sklearn.preprocessing import MinMaxScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(data)\ndata_scaled = pd.DataFrame(X_scaled, columns=data.columns)\ndata_scaled.head()","2b832749":"from sklearn.decomposition import PCA","74874887":"pca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)","ed4d46e9":"X_pca.shape","9f256e92":"import umap","13209d3b":"reducer = umap.UMAP(random_state=42)\nX_umap = reducer.fit_transform(X_scaled)","651a532b":"X_umap.shape","eb547679":"from sklearn.manifold import TSNE","ea07a0e1":"tsne = TSNE(n_components=2, random_state=10)\nX_tsne = tsne.fit_transform(X_scaled)","476afad1":"X_tsne.shape","8da47f70":"inertia = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters=i, random_state=10).fit(data_scaled)\n    labels = kmeans.labels_\n    inertia_i = kmeans.inertia_\n    inertia.append(inertia_i)","06b91501":"plt.plot(range(1,11), inertia, marker='o');","290eacd4":"D = []\nfor i in range(1,9):\n    Di = (inertia[i] - inertia[i+1])\/(inertia[i-1] - inertia[i])\n    D.append(Di)","dedc60e5":"plt.plot(range(2,10), D, marker='o');","fa79eeb3":"kmeans = KMeans(n_clusters=4, random_state=10).fit(X_scaled)\nlabels_kmeans = kmeans.labels_","d5d35646":"plt.title('K-means, 4 clusters')\nsns.scatterplot(x = X_pca[:,0], y = X_pca[:,1], hue=labels_kmeans, palette='rainbow');","57ae0ff3":"data_clustered = df.copy()\ndata_clustered['cluster_kmeans'] = labels_kmeans","59084f98":"from scipy.cluster.hierarchy import dendrogram, linkage\nplt.figure(figsize=(20,10))\nlinkage_ = linkage(X_scaled, method='ward')\ndendrogram_ = dendrogram(linkage_)","f241c144":"from tqdm import tqdm\nfrom sklearn.metrics import silhouette_score\nsilhouette = []\nfor i in tqdm(range(2,11)):\n    agg = AgglomerativeClustering(n_clusters=i).fit(X_scaled)\n    labels = agg.labels_\n    score = silhouette_score(X_scaled, labels)\n    silhouette.append(score)","e41bdf6d":"plt.plot(range(2,11), silhouette, marker='o');","080cfe72":"agg_cluster = AgglomerativeClustering(n_clusters = 3).fit(X_scaled)\nlabels_agg = agg_cluster.labels_","e7367bf1":"plt.title('Hierarchical clustering, 3 clusters')\nsns.scatterplot(x = X_tsne[:, 0], y = X_tsne[:, 1], hue=agg_cluster.labels_,  palette=['green','orange','blue']);","dd4e103d":"data_clustered['cluster_agg'] = labels_agg","55b17151":"def dbscan_clustering(eps_range, X):\n    eps_range = eps_range\n    silhouette = []\n    clusters = []\n    for i in tqdm(eps_range):\n        dbscan = DBSCAN(eps=i).fit(X)\n        labels = dbscan.labels_\n        uniq_labels = np.unique(labels)\n        n_clusters = len(uniq_labels[uniq_labels != -1])\n        if n_clusters > 1:\n            score = silhouette_score(X, labels)\n        else:\n            score = 0\n        silhouette.append(score)\n        clusters.append(n_clusters)\n        \n    fig, ax1 = plt.subplots()\n\n    color = 'tab:red'\n    ax1.plot(eps_range, silhouette, marker='o', color=color)\n    ax1.set_xlabel('eps')\n    ax1.set_ylabel('silhouette', color=color)\n    ax1.tick_params(axis='y', labelcolor=color)\n\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\n    color = 'tab:blue'\n    ax2.plot(eps_range, clusters, marker='o', color=color)\n    ax2.set_ylabel('n_clusters', color=color)  \n    ax2.tick_params(axis='y', labelcolor=color)\n\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    plt.show()","bc6ec077":"eps_range = np.arange(1,4,0.05)\ndbscan_clustering(eps_range, X_scaled)","7d5d5e0a":"eps_range = np.arange(1.5,2.5,0.05)\ndbscan_clustering(eps_range, X_scaled)","e8f8262c":"eps_range = np.arange(1.95,2.5,0.01)\ndbscan_clustering(eps_range, X_scaled)","2c03d121":"from sklearn.neighbors import NearestNeighbors\nneigh = NearestNeighbors(n_neighbors=3)\nnbrs = neigh.fit(X_scaled)\ndistances, indices = nbrs.kneighbors(X_scaled)\n\ndistances = np.sort(distances, axis=0)\ndistances = distances[:,1]\n\nplt.plot(distances)","a567c3bf":"dbscan = DBSCAN(eps=2.15, min_samples=10).fit(X_scaled)\nlabels_dbscan = dbscan.labels_","f0e84326":"plt.title('DBSCAN')\nsns.scatterplot(x = X_umap[:,0], y = X_umap[:,1], hue=labels_dbscan, palette='rainbow');","0bd09aac":"data_clustered['cluster_dbscan'] = labels_dbscan","36599059":"data_clustered.groupby('cluster_kmeans').mean()[['Age', 'Job', 'Credit amount', 'Duration']]","4a703dc4":"data_clustered['cluster_kmeans'].value_counts()","123e299a":"fig, ax  = plt.subplots(1,3,figsize=(20,5))\nsns.scatterplot(x = data_clustered['Duration'], y = data_clustered['Credit amount'], hue=labels_kmeans, ax=ax[0], palette='rainbow');\nsns.scatterplot(x = data_clustered['Age'], y = data_clustered['Credit amount'], hue=labels_kmeans, ax=ax[1], palette='rainbow');\nsns.scatterplot(x = data_clustered['Age'], y = data_clustered['Duration'], hue=labels_kmeans, ax=ax[2], palette='rainbow');","c8d1b345":"for col in data_clustered[numeric].columns:\n    sns.boxplot(data=data_clustered, x=col, y=labels_kmeans, orient='h')\n    plt.show();","3ed9bb49":"data_clustered[data_clustered['cluster_kmeans']==0]['Sex'].hist()","39ebe4c2":"data_clustered[data_clustered['cluster_kmeans']==0]['Job'].hist()","7474f5f5":"sns.countplot(y ='Purpose', data = data_clustered[data_clustered['cluster_kmeans']==0])\nplt.show()","634ddaa7":"data_clustered[data_clustered['cluster_kmeans']==1]['Sex'].hist()","fdb7fa94":"sns.countplot(y ='Purpose', data = data_clustered[data_clustered['cluster_kmeans']==1])\nplt.show()\n","15015344":"data_clustered[data_clustered['cluster_kmeans']==2]['Sex'].hist()","9b03a92f":"sns.countplot(y ='Purpose', data = data_clustered[data_clustered['cluster_kmeans']==2])\nplt.show()","72a754e4":"data_clustered[data_clustered['cluster_kmeans']==3]['Sex'].hist()","c5fb3ba0":"sns.countplot(y ='Purpose', data = data_clustered[data_clustered['cluster_kmeans']==3])\nplt.show()","def0480f":"## Conclusion","6c86235d":"#### Cluster 0","2f151024":"#### Cluster 2","a72be399":"For Clustering we need a way to compute the distance between pairs of data points. Data points that are close to each other will more likely belong to the same cluster.  \nThe reason we normalize the data is to make sure all dimensions are treated equally. In other words, we want each column to contribute the same impact on the distance. ","43f3df2c":"#### Scaling","4082d1fc":"#### tSNE","b9e534d4":"#### DBSCAN","783be32b":"Data:\n- Age (numeric)\n- Sex (text: male, female)\n- Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)\n- Housing (text: own, rent, or free)\n- Saving accounts (text - little, moderate, quite rich, rich)\n- Checking account (numeric, in DM - Deutsch Mark)\n- Credit amount (numeric, in DM)\n- Duration (numeric, in month)\n- Purpose (text: car, furniture\/equipment, radio\/TV, domestic appliances, repairs, education, business, vacation\/others)","36c1f0d0":"## Interpretation","66e37356":"#### K-means","57f36a41":"- **Cluster 0**  has the highest mean  `Credit amount` (6569.7 DM) and the longest mean `Duration` (35 months). There are mostly men in this cluster;\n- **Cluster 1** has mean  `Credit amount` = 2073.7 DM and the mean `Duration` = 35 months. There are only women in this cluster;\n- **Cluster 2** is the smallest cluster with mean  `Credit amount` = 3251.1 DM and the mean `Duration` = 20 months. There are mostly men in this cluster;\n- **Cluster 3** is the biggest cluster with the lowest mean  `Credit amount` = 1960.1 DM and the shortest mean `Duration` = 15 months. There are only men in this cluster;\n- Average `Age` is very similar throughout the clusters;\n- For all clusters main `Purpose` are car and radio\/TV.","7af7210a":"#### Categorical","ca1c82d0":"## Feature engineering","aeb21054":"We will use different dimensionality reduction techniques for data visualization after clustering.","d8b9f1e6":"#### Numerical","0060f0f5":"Considering two methods to find optimal parametrs for DBSCAN:\n- eps = 2.15\n- min_samples >= dimensinality + 1","106a78d6":"#### PCA","85f34172":"#### Hierarhical","1dccc667":"`Duration` and `Credit amount` are highly correlated","2d8de6bc":"## Clustering","97c28d89":"#### Cluster 3","0ff03c41":"- Distribution of `Age` is positively skewed, we will apply log-transformation for this feature;\n- There are twice as many male customers as female;\n- Most of customers are skilled;\n- Most of customers have their own house;\n- Most of customers have little saving accounts;\n- Distribution of `Credit amount` is positively skewed, we will apply log-transformation for this feature;\n- Duration is distributed from 4 to 72 months. Credits for a year or two are most common.","7d3d72cb":"#### Cluster 1","768e1217":"#### UMAP","27da470e":"Now, looking at the highest vertical and imagining a horizontal line crossing it would mean the best number of clusters would be 3-4.","449823d0":"## German Credit Risk","69056b7f":"## Exploratory Data Analysis"}}