{"cell_type":{"f686f169":"code","9e2864cf":"code","cb8a567a":"code","5bc61157":"code","7ebcb9f9":"code","9be0ad6c":"code","9d1c9d54":"code","8ece7ccf":"code","be0ffcb4":"code","565d683a":"code","af1c6df3":"code","52b75bf6":"code","76fc0af0":"code","121e19f5":"code","b43284be":"code","584ce227":"code","84dd1227":"code","4fb7eb2d":"code","71acc2cb":"code","0974e59f":"code","a4dc20be":"code","420338db":"code","13eaf599":"code","b26fa32b":"code","7bcdd489":"code","10c0dc9b":"markdown","282bfb62":"markdown","ab5a34ab":"markdown","a2d9c1a9":"markdown","7527bc4f":"markdown","8a64968e":"markdown","572d7071":"markdown","4b51d3ef":"markdown","0c17048a":"markdown","5581e798":"markdown","3d5e7157":"markdown","d040a823":"markdown","78a723c5":"markdown","21eab454":"markdown","466a7970":"markdown","ef26c614":"markdown","73a0d40d":"markdown","07edd273":"markdown","1260d1b1":"markdown","acc62029":"markdown","eb43b7bd":"markdown","73bcfb34":"markdown","18cc91ac":"markdown"},"source":{"f686f169":"# Check nvcc version\n!nvcc -V\n# Check GCC version\n!gcc --version","9e2864cf":"import torch","cb8a567a":"%%time\n\nprint(\"this will take around 9 mins\")\n# install dependencies: (use cu101 because colab has CUDA 10.1)\n# !pip install -U torch==1.7.0+cu101 torchvision==0.6.1+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n\n# install mmcv-full thus we could use CUDA operators\n!pip install mmcv-full\n\n\n","5bc61157":"ls","7ebcb9f9":"!rm -rf mmdetection\n!git clone --branch v2.7.0 https:\/\/github.com\/open-mmlab\/mmdetection.git\n%cd mmdetection\n\n!pip install -e .\n\n# install Pillow 7.0.0 back in order to avoid bug in colab\n!pip install Pillow==7.0.0","9be0ad6c":"# Check Pytorch installation\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n\n# Check MMDetection installation\nimport mmdet\nprint(mmdet.__version__)\n\n# Check mmcv installation\nfrom mmcv.ops import get_compiling_cuda_version, get_compiler_version\nprint(get_compiling_cuda_version())\nprint(get_compiler_version())","9d1c9d54":"ls","8ece7ccf":"!mkdir checkpoints\n!wget -c http:\/\/download.openmmlab.com\/mmdetection\/v2.0\/mask_rcnn\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n      -O checkpoints\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth","be0ffcb4":"from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n\n# Choose to use a config and initialize the detector\nconfig = 'configs\/mask_rcnn\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco.py'\n# Setup a checkpoint file to load\ncheckpoint = 'checkpoints\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n# initialize the detector\nmodel = init_detector(config, checkpoint, device='cuda:0')","565d683a":"# Use the detector to do inference\nimg = 'demo\/demo.jpg'\nresult = inference_detector(model, img)","af1c6df3":"# Let's plot the result\nshow_result_pyplot(model, img, result, score_thr=0.3)","52b75bf6":"from mmcv import Config\ncfg = Config.fromfile('.\/configs\/faster_rcnn\/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py')\n\n","76fc0af0":"from mmdet.apis import set_random_seed\n\ncfg.dataset_type = 'CocoDataset'\ncfg.classes = (\"Aortic_enlargement\", \"Atelectasis\", \"Calcification\", \"Cardiomegaly\", \"Consolidation\", \"ILD\", \"Infiltration\", \"Lung_Opacity\", \"Nodule\/Mass\", \"Other_lesion\", \"Pleural_effusion\", \"Pleural_thickening\", \"Pneumothorax\", \"Pulmonary_fibrosis\")\n\ncfg.data.train.img_prefix = '..\/..\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/'\ncfg.data.train.classes = cfg.classes\ncfg.data.train.ann_file = '..\/..\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/train_annotations.json'\ncfg.data.train.type='CocoDataset'\n\n\ncfg.data.val.img_prefix = '..\/..\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/'\ncfg.data.val.classes = cfg.classes\ncfg.data.val.ann_file = '..\/..\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/val_annotations.json'\ncfg.data.val.type='CocoDataset'\n\n\n\ncfg.data.test.img_prefix = '..\/..\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/'\ncfg.data.test.classes = cfg.classes\ncfg.data.test.ann_file = '..\/..\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/val_annotations.json'\ncfg.data.test.type='CocoDataset'\n\n\n\n\ncfg.model.roi_head.bbox_head.num_classes = 14\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.val.type = 'CocoDataset'\ncfg.data.test.type = 'CocoDataset'\n\ncfg.optimizer.lr = 0.02 \/ 8\ncfg.lr_config.warmup = None\ncfg.log_config.interval = 10\n\n# Change the evaluation metric since we use customized dataset.\ncfg.evaluation.metric = 'bbox'\n# We can set the evaluation interval to reduce the evaluation times\ncfg.evaluation.interval = 12\n# We can set the checkpoint saving interval to reduce the storage cost\ncfg.checkpoint_config.interval = 10\n\n# Set seed thus the results are more reproducible\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\n\n# we can use here mask_rcnn.\ncfg.load_from = '.\/checkpoints\/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\ncfg.work_dir = \"..\/vinbig_output\"\n\n# One Epoch takes around 18 mins\ncfg.total_epochs = 12","121e19f5":"# the dataset has been taken : https:\/\/www.kaggle.com\/sreevishnudamodaran\/vinbigdata-fusing-bboxes-coco-dataset\nimport os\nos.listdir(\"..\/..\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\")","b43284be":"# for saving checkpoint and plots\nimport os\nos.makedirs('..\/vinbig_output')","584ce227":"print(f'Config:\\n{cfg.pretty_text}')","84dd1227":"from mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector","4fb7eb2d":"print(cfg.__dict__)","71acc2cb":"model = build_detector(\n    cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n\n","0974e59f":"datasets = [build_dataset(cfg.data.train)]","a4dc20be":"print(datasets[0][0])","420338db":"# cfg.lr_config.policy='step'\ntrain_detector(model, datasets[0], cfg, distributed=False, validate=True)\n","13eaf599":"os.chdir('..\/')\n","b26fa32b":"\n!python mmdetection\/tools\/analyze_logs.py plot_curve .\/vinbig_output\/None.log.json --keys loss_cls --legend loss_cls --out \"loss_cls\"","7bcdd489":"# !rm -rf \".\/mmdetection\"","10c0dc9b":"# Training Detector With BBox Eval","282bfb62":"# Verifying Installation","ab5a34ab":"# Installing MMDet Framework","a2d9c1a9":"Dataset Source: https:\/\/www.kaggle.com\/sreevishnudamodaran\/vinbigdata-fusing-bboxes-coco-dataset","7527bc4f":"MMDetection is an open source object detection toolbox based on PyTorch. It is a part of the OpenMMLab project developed by Multimedia Laboratory, CUHK.","8a64968e":"# Plotting Classification Loss","572d7071":"# MMDet on VinBigData","4b51d3ef":"> # Building MMDet From Source","0c17048a":"# Prereq: MMCV(~9 mins)","5581e798":"# Configuration Settings On BaseConfig","3d5e7157":"![image.png](attachment:image.png)","d040a823":"The aim of this notebook is to install and run a training pipeline using MMDET Framework.","78a723c5":"# MMDet Framework","21eab454":"I am using here faster rcnn for the demo purpose but as listed above the training pipeline can be customized using different framework and backbones. Just need to change the config settings down here. The config dir of mmdet framework contains various implmentation. Do checkit out.","466a7970":"2. **Multiple Frameworks**(https:\/\/github.com\/open-mmlab\/mmdetection)\n    1. List of Supported Backbones\n    \n        1. ResNet (CVPR'2016)\n        2. ResNeXt (CVPR'2017)\n        3. VGG (ICLR'2015)\n        4. HRNet (CVPR'2019)\n        5. RegNet (CVPR'2020)\n        6. Res2Net (TPAMI'2020)\n        7. ResNeSt (ArXiv'2020)\n    2. Supported Frameworks\n        1. [RPN (NeurIPS'2015)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/rpn)\n        2. [Fast R-CNN (ICCV'2015)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/fast_rcnn)\n        3. [Faster R-CNN (NeurIPS'2015)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/faster_rcnn)\n        4. [Mask R-CNN (ICCV'2017)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/mask_rcnn)\n        5. [Cascade R-CNN (CVPR'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/cascade_rcnn)\n        6. [Cascade Mask R-CNN (CVPR'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/cascade_rcnn)\n        7. [SSD (ECCV'2016)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/ssd)\n        8. [RetinaNet (ICCV'2017)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/retinanet)\n        9. [GHM (AAAI'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/ghm)\n        10. [Mask Scoring R-CNN (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/ms_rcnn)\n        11. [Double-Head R-CNN (CVPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/double_heads)\n        12. [Hybrid Task Cascade (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/htc)\n        13. [Libra R-CNN (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/libra_rcnn)\n        14. [Guided Anchoring (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/guided_anchoring)\n        15. [FCOS (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/fcos)\n        16. [RepPoints (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/reppoints)\n        17. [Foveabox (TIP'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/foveabox)\n        18. [FreeAnchor (NeurIPS'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/free_anchor)\n        19. [NAS-FPN (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/nas_fpn)\n        20. [ATSS (CVPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/atss)\n        21. [FSAF (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/fsaf)\n        22. [PAFPN (CVPR'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/pafpn)\n        23. [Dynamic R-CNN (ECCV'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/dynamic_rcnn)\n        24. [PointRend (CVPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/point_rend)\n        25. [CARAFE (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/carafe\/README.md)\n        26. [DCNv2 (CVPR'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/dcn\/README.md)\n        27. [Group Normalization (ECCV'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/gn\/README.md)\n        28. [Weight Standardization (ArXiv'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/gn+ws\/README.md)\n        29. [OHEM (CVPR'2016)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/faster_rcnn\/faster_rcnn_r50_fpn_ohem_1x_coco.py)\n        30. [Soft-NMS (ICCV'2017)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/faster_rcnn\/faster_rcnn_r50_fpn_soft_nms_1x_coco.py)\n        31. [Generalized Attention (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/empirical_attention\/README.md)\n        32. [GCNet (ICCVW'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/gcnet\/README.md)\n        33. [Mixed Precision (FP16) Training (ArXiv'2017)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/fp16\/README.md)\n        34. [InstaBoost (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/instaboost\/README.md)\n        35. [GRoIE (ICPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/groie\/README.md)\n        36. [DetectoRS (ArXix'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/detectors\/README.md)\n        37. [Generalized Focal Loss (NeurIPS'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/gfl\/README.md)\n        38. [CornerNet (ECCV'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/cornernet\/README.md)\n        39. [Side-Aware Boundary Localization (ECCV'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/sabl\/README.md)\n        40. [YOLOv3 (ArXiv'2018)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/yolo\/README.md)\n        41. [PAA (ECCV'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/paa\/README.md)\n        42. [YOLACT (ICCV'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/yolact\/README.md)\n        43. [CentripetalNet (CVPR'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/centripetalnet\/README.md)\n        44. [VFNet (ArXix'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/vfnet\/README.md)\n        45. [DETR (ECCV'2020)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/detr\/README.md)\n        46. [CascadeRPN (NeurIPS'2019)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/cascade_rpn\/README.md)\n        47. [SCNet (AAAI'2021)](https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/configs\/scnet\/README.md)","ef26c614":"1. **Modular Design**\n    1. The detection framework is decomposed into different components. This gives the flexiblity to construct a customized object detection framework using different backbones and models.\n    \n    2. The framework mainly contains following parts:\n    \n        1. Config: This is the place where you get to set the configurations for the framwork like data dirs, num of epochs, gpus to use etc.\n        2. mmdet: This module contains the files related to backbones, necks, heads and losses etc.\n        \n        3. Tools: This is the directory that contains utilities for training, testing and computing the evaluation metric.\n","73a0d40d":"# Building Dataset","07edd273":"3. **High Efficiency**\n    1. All basic bbox and mask operations run on GPUs. The training speed is faster than or comparable to other codebases, including Detectron2, maskrcnn-benchmark and SimpleDet.","1260d1b1":"# Initializing Detector","acc62029":"# Features","eb43b7bd":"# Sample Inference Demo","73bcfb34":"Check the output dir for the plot.","18cc91ac":"# Downloading Checkpoint For Demo"}}