{"cell_type":{"796ac075":"code","1dbef0fd":"code","04255bc4":"code","0fd3a006":"code","4e64be54":"code","50858b66":"code","c3290f20":"code","aee0ec77":"code","70531364":"code","ead4623b":"code","5da72102":"code","194f8366":"code","74c66959":"code","bf538a61":"code","57443a6e":"code","ddedaba7":"code","daf916cd":"code","6b1d09df":"code","5aa6e2a6":"code","0f0924c0":"code","144b7c39":"code","d8c3097c":"code","35a46944":"code","bfb37da6":"code","2a27f113":"code","bdbd7488":"code","7f606fb5":"code","874291d5":"code","8deca2e0":"code","a2d0001e":"code","e89e9944":"code","738e69f7":"code","70eeef01":"code","37880d2b":"code","b338d069":"code","10ff61a2":"code","bbddd318":"code","7446033b":"code","7029ab87":"code","5a6e8770":"code","230c1497":"code","3c63e309":"code","99edae4d":"code","5a4c8b5f":"code","341efa71":"code","0dd9c9c0":"code","916f2a8c":"code","4df69843":"code","dcc23108":"code","5d21b388":"code","6068c980":"code","8f6398bf":"code","de0364ce":"code","ae5b8752":"code","fa653469":"code","e0814f1d":"code","a5a69f21":"code","9f4d566f":"code","c4fb78f4":"code","31a3f809":"code","d4493dc7":"code","9a3d923c":"code","14fa11f6":"code","87b45545":"code","820e87a1":"code","1cfb1940":"code","5218daf4":"code","bcd9ad2d":"code","2049c981":"code","aa72ada2":"code","136bfc1b":"code","2383951d":"code","07f9e875":"code","0755dbec":"code","ef1afba7":"code","fe68ddfb":"code","d1bccaee":"code","165a9e26":"code","884dbb07":"code","132bc720":"code","33bd151b":"code","d49b89bd":"code","38b0374b":"code","1b5e2150":"code","9b150fd5":"code","356dbd3a":"code","5887e4bc":"code","85637fad":"code","a204f8a4":"code","6c490f79":"code","634e1d38":"code","937ce6eb":"code","b78a842f":"code","66d85ac6":"code","5f4bdd7c":"code","9976bce3":"code","d2022cb3":"code","dc9531c3":"code","1e76fc19":"code","1eaefe38":"code","12714b5c":"code","fa0f920f":"code","f58d4c71":"code","ce2be125":"markdown","8ec86a8a":"markdown","01850f86":"markdown","ec453a39":"markdown","88dddaba":"markdown","bfbfd335":"markdown","ecea2638":"markdown","b9afb15a":"markdown","9939e7c1":"markdown","1616d97b":"markdown","33f6aa4d":"markdown","fe11df54":"markdown","a4f5857b":"markdown","bac01f06":"markdown","dd4c3c9a":"markdown","37661200":"markdown","a3ee0d14":"markdown","195c838b":"markdown","fb3460d2":"markdown","41072c88":"markdown","53266d4d":"markdown","9e64e579":"markdown","592e0a05":"markdown","6f46c152":"markdown","47fd1d31":"markdown","95ecc09d":"markdown","97e7eb11":"markdown","f3067e02":"markdown","8da0bcbb":"markdown","0f446d50":"markdown","88211ec6":"markdown","6dc3df21":"markdown","4e073cfd":"markdown","22f192f1":"markdown","953ed905":"markdown","199bdf0c":"markdown","09c26e11":"markdown","75041049":"markdown","26134ee3":"markdown","ee484855":"markdown","feb550b3":"markdown","134d161d":"markdown","dd4366d4":"markdown","1bc65901":"markdown","c3ddeff9":"markdown","3ac5dbb4":"markdown","b19db7dc":"markdown","6010d7d4":"markdown","90312811":"markdown","0845f5ab":"markdown","3d311894":"markdown","83ce50b6":"markdown","c1d7d59e":"markdown","dcef4369":"markdown","27266b37":"markdown","d2f42e0a":"markdown","d75ccd0b":"markdown","cab47fd8":"markdown","f5599865":"markdown","4b14e330":"markdown","17aad5f9":"markdown","1fd2c276":"markdown","ffdaa3e5":"markdown","638b0c10":"markdown","d8318e15":"markdown","145fda6b":"markdown","d79492ff":"markdown","2b8a317a":"markdown","c5181598":"markdown","e8f5fdbf":"markdown","434f99ad":"markdown","8fd09543":"markdown","e8f1612b":"markdown","9205a960":"markdown","d37bc34e":"markdown","7c8c1b9e":"markdown","21340d38":"markdown","2922e6c6":"markdown","218bb101":"markdown","7fc9db0b":"markdown","68ac1a13":"markdown","ea5a2def":"markdown","949cfc11":"markdown","4c23f96c":"markdown","aed74f7b":"markdown","7c311912":"markdown","5189ad17":"markdown","e2ed80b4":"markdown","09b8237b":"markdown","bb1434f8":"markdown","07a4c843":"markdown","7f8894ee":"markdown","7abee091":"markdown","16ef445a":"markdown","a1946480":"markdown","2245a095":"markdown","f17560ee":"markdown","eb315402":"markdown","4201c41a":"markdown","e0ca90ef":"markdown","9b4bd68a":"markdown","162df60f":"markdown","e7f36d2f":"markdown","8571b730":"markdown","3e53ba22":"markdown","9a7cbd70":"markdown","5a8a766b":"markdown","bc93f2b7":"markdown","d4339b63":"markdown","ab43cc68":"markdown","0f7ad089":"markdown","5ba38b8f":"markdown","fb027538":"markdown","deae6cc8":"markdown","a86d8025":"markdown","0f697ec5":"markdown","1953bf6a":"markdown","8afe0b5a":"markdown","744fd990":"markdown","1714c8d5":"markdown","053cd39d":"markdown","767abc6c":"markdown","0a57288b":"markdown","52f77b5d":"markdown","f4ff39ad":"markdown","341cd905":"markdown","f26d45f7":"markdown","0a5073f9":"markdown","1584f221":"markdown","1bee009b":"markdown","815234eb":"markdown","ffff45ac":"markdown","5f048275":"markdown","472d4065":"markdown","a2c999b1":"markdown","1ae6ac8d":"markdown","5d2f3dcf":"markdown","13b3f112":"markdown","8a183c02":"markdown","9c32740a":"markdown","4a84532f":"markdown","9c1930fe":"markdown","9beffafc":"markdown","3c811299":"markdown","fa6efd38":"markdown","13e689f4":"markdown","424cedf6":"markdown","9377a3bb":"markdown","f3a249d6":"markdown","bd0013ba":"markdown","b2850393":"markdown","98d87b66":"markdown","b95b2d7a":"markdown","13045be6":"markdown","ab2f0042":"markdown","a87ba8ec":"markdown","45bd7a5e":"markdown","202d602b":"markdown","1a5f8c28":"markdown","9d2dd32b":"markdown","edf10806":"markdown","669fce17":"markdown","1b652f4b":"markdown","37a2fb07":"markdown","4c7eb442":"markdown","c0b4942f":"markdown","9eb8cb14":"markdown","1585c13e":"markdown","c9a4a95b":"markdown","85839a00":"markdown","875a4669":"markdown","80e6fa31":"markdown","f286d8ad":"markdown","b3a6a4db":"markdown","5d5521f7":"markdown","31b60771":"markdown","4eab6291":"markdown"},"source":{"796ac075":"pip install plotly_express==0.4.0 #this one will be useful to hover on one of our scatter plots and obtain the exact information on the points","1dbef0fd":"# To support both python 2 and python 3\nfrom __future__ import division, print_function, unicode_literals\n\n# Common imports\nimport numpy as np\nimport numpy as em\nimport pandas as pd\nimport os\n\n# to make this notebook's output stable across runs\nnp.random.seed(42)\n\n# To plot pretty figures\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12\nimport plotly.express as px\n\n# Ignore useless warnings (see SciPy issue #5998)\nimport warnings\nwarnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n\nimport seaborn as sns\nsns.set_palette(\"Set2\")","04255bc4":"fat_quantity = pd.read_csv(\"..\/input\/covid19healthydietdataset\/Fat_Supply_Quantity_Data.csv\")\nfood_kcal = pd.read_csv(\"..\/input\/covid19healthydietdataset\/Food_Supply_kcal_Data.csv\")\nfood_kg = pd.read_csv(\"..\/input\/covid19healthydietdataset\/Food_Supply_Quantity_kg_Data.csv\")\nprotein_quantity = pd.read_csv(\"..\/input\/covid19healthydietdataset\/Protein_Supply_Quantity_Data.csv\")\nsupply_food = pd.read_csv(\"..\/input\/covid19-healthy-diet-dataset\/Supply_Food_Data_Descriptions.csv\")","0fd3a006":"fat_quantity.head()","4e64be54":"food_kcal.head()","50858b66":"food_kg.head()","c3290f20":"protein_quantity.head()","aee0ec77":"supply_food.head()","70531364":"fat_quantity.drop(['Obesity','Confirmed','Undernourished','Deaths','Recovered','Active', 'Population', 'Unit (all except Population)'], axis = 1, inplace = True)","ead4623b":"print('Sum of diet measures per Fat quantity :')\nprint(fat_quantity.sum(axis = 1))","5da72102":"food_kg.head()","194f8366":"food_kg['Confirmed'].round() == (food_kg['Active'] + food_kg['Deaths'] + food_kg['Recovered']).round()","74c66959":"food_kg.dtypes.value_counts()","bf538a61":"food_kg.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","57443a6e":"food_kg['Unit (all except Population)'].unique()","ddedaba7":"food_kg = food_kg.drop(['Unit (all except Population)'], axis=1)","daf916cd":"food_kg['Undernourished'].unique()","6b1d09df":"food_kg[\"Undernourished\"] = food_kg[\"Undernourished\"].replace('<2.5','2.5')\nfood_kg['Undernourished'].value_counts()","5aa6e2a6":"food_kg[\"Undernourished\"] = pd.to_numeric((food_kg[\"Undernourished\"]), downcast=\"float\")","0f0924c0":"food_kg.info()","144b7c39":"def missing_data(data):\n    nb_values = data.isnull().sum().sort_values(ascending = False) #contains the number of values missing\n    percent_values = (data.isnull().sum()\/data.isnull().count()*100).sort_values(ascending = False) #contains the percentage of values missing\n    return pd.concat([nb_values, percent_values], axis=1, keys=['Number of Missing Values', 'Percentage of Missing Values'])","d8c3097c":"missing_data(food_kg).head(6)","35a46944":"food_kg_missing = food_kg[food_kg.isna().any(axis=1)]\nfood_kg_missing","bfb37da6":"food_kg = food_kg.dropna(axis=0)","2a27f113":"food_kg.describe()","bdbd7488":"food_kg[food_kg['Alcoholic Beverages'] == food_kg['Alcoholic Beverages'].max()]","7f606fb5":"food_kg[food_kg['Undernourished'] == food_kg['Undernourished'].max()]","874291d5":"food_kg[food_kg['Obesity'] == food_kg['Obesity'].max()]","8deca2e0":"diet_mean = food_kg.describe().iloc[1]\ndiet_mean = pd.DataFrame(diet_mean).drop(['Deaths', 'Population','Undernourished','Obesity', 'Recovered', 'Confirmed', 'Active'], axis=0)\ndiet_mean = diet_mean.sort_values(by='mean', ascending=False).iloc[:11]","a2d0001e":"diet_mean_plot = diet_mean.plot.pie(subplots=True, figsize=(15, 15), autopct='%1.1f%%')","e89e9944":"covid_stats_plot = px.scatter(food_kg, x='Confirmed', y='Deaths', hover_name='Country', size_max=30)\ncovid_stats_plot.show()","738e69f7":"corr_food=food_kg.corr(method='pearson')\ncorr_final=corr_food.abs().unstack().sort_values(ascending = False)\ncorr_final.drop(corr_final.head(32).index, inplace=True)","70eeef01":"print('Confirmed')\ncorr_confirmed = corr_final['Confirmed'].head(15)\ncorr_confirmed = corr_confirmed.drop(['Recovered', 'Deaths', 'Active', 'Undernourished', 'Obesity'])\nprint(corr_confirmed)\nprint()\n\nprint('Deaths')\ncorr_deaths = corr_final['Deaths'].head(15)\ncorr_deaths = corr_deaths.drop(['Recovered', 'Confirmed', 'Active', 'Undernourished', 'Obesity'])\nprint(corr_deaths)\nprint()\n\nprint('Recovered')\ncorr_recovered = corr_final['Recovered'].head(14)\ncorr_recovered = corr_recovered.drop(['Confirmed', 'Deaths', 'Undernourished', 'Obesity'])\nprint(corr_recovered)","37880d2b":"corr_base = corr_deaths + corr_confirmed + corr_recovered\ncorr_base","b338d069":"corr_heatmap=food_kg[['Deaths','Animal Products','Animal fats','Cereals - Excluding Beer','Eggs','Meat','Milk - Excluding Butter','Pulses','Starchy Roots','Sugar & Sweeteners','Vegetal Products']]\nx=corr_heatmap.corr(method='pearson')\nplt.figure(figsize=(7,5), dpi= 80)\nsns.heatmap(x[['Deaths']].sort_values(by=['Deaths'],ascending=False),cmap='Pastel2_r',annot=True,linewidth=0.6)\nplt.title('Covid deaths cases diets')\nplt.xticks()\nplt.suptitle('Pearson Correlation Coefficient', size=18, va='top')\n\ncorr_heatmap=food_kg[['Confirmed','Animal Products','Animal fats','Cereals - Excluding Beer','Eggs','Meat','Milk - Excluding Butter','Pulses','Starchy Roots','Sugar & Sweeteners','Vegetal Products']]\nx=corr_heatmap.corr(method='pearson')\nplt.figure(figsize=(7,5), dpi= 80)\nsns.heatmap(x[['Confirmed']].sort_values(by=['Confirmed'],ascending=False),cmap='Pastel2_r',annot=True,linewidth=0.6)\nplt.title('Covid confirmed cases diets')\nplt.xticks()\n\ncorr_heatmap=food_kg[['Recovered','Animal Products','Animal fats','Cereals - Excluding Beer','Eggs','Meat','Milk - Excluding Butter','Pulses','Starchy Roots','Sugar & Sweeteners','Vegetal Products']]\nx=corr_heatmap.corr(method='pearson')\nplt.figure(figsize=(7,5), dpi= 80)\nsns.heatmap(x[['Recovered']].sort_values(by=['Recovered'],ascending=False),cmap='Pastel2_r',annot=True,linewidth=0.6)\nplt.title('Covid recovered cases diets')\nplt.xticks()","10ff61a2":"corr_heatmap=food_kg[['Deaths','Confirmed','Recovered','Obesity','Undernourished']]\nx=corr_heatmap.corr(method='pearson')\nplt.figure(figsize=(10,8), dpi= 80)\nsns.heatmap(x,cmap='Pastel2_r',annot=True,linewidth=0.6)\nplt.title('Pearson Correlation Coefficient')\nplt.xticks(rotation=45)","bbddd318":"food_kg[food_kg['Deaths'] == food_kg['Deaths'].max()]","7446033b":"food_kg[food_kg['Confirmed'] == food_kg['Confirmed'].max()]","7029ab87":"food_kg[food_kg['Deaths'] == food_kg['Deaths'].min()].sort_values(by='Population', ascending=False)","5a6e8770":"food_kg[food_kg['Confirmed'] == food_kg['Confirmed'].min()].sort_values(by='Population', ascending=False)","230c1497":"score_bins = [-0.1, 0.0375, 0.075, 0.1125, 0.15] #-1 because otherwise for some reason we don't get zeroes\ngrades = ['1','2','3','4']\ncats = pd.cut(food_kg.Deaths, score_bins, labels=grades)\nfood_kg['DeathsScore'] = cats\nfood_kg","3c63e309":"food_kg.DeathsScore.value_counts()","99edae4d":"food_kg['DeathsScore'] = food_kg['DeathsScore'].astype(str)\nfood_kg['DeathsScore'] = food_kg['DeathsScore'].astype(float)\ncovid_man_cluster_conf = px.scatter(food_kg, x='Confirmed', y='Deaths', color='DeathsScore', hover_name='Country', size_max=30)\ncovid_man_cluster_conf.show()","5a4c8b5f":"score_bins_2 = [-1, 1.5, 3, 4.5, 6] #-1 because otherwise for some reason we don't get zeroes\ngrades = ['1','2','3','4']\ncats_2 = pd.cut(food_kg.Confirmed, score_bins_2, labels=grades)\nfood_kg['ConfirmedScore'] = cats_2\nfood_kg","341efa71":"food_kg.ConfirmedScore.value_counts()","0dd9c9c0":"food_kg['ConfirmedScore'] = food_kg['ConfirmedScore'].astype(str)\nfood_kg['ConfirmedScore'] = food_kg['ConfirmedScore'].astype(float)\ncovid_man_cluster_conf = px.scatter(food_kg, x='Confirmed', y='Deaths', color='ConfirmedScore', hover_name='Country', size_max=30)\ncovid_man_cluster_conf.show()","916f2a8c":"food_kg_country = food_kg[['Country']]\nfood_kg_drop = food_kg.drop('Country', axis=1)","4df69843":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(food_kg_drop)\nfood_kg_scaled = scaler.transform(food_kg_drop)\nfood_kg_scaled","dcc23108":"food_kg_coun = food_kg[['Country']]\nfood_kg_coun.tail(3)","5d21b388":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nfood_kg_coun_encoded = encoder.fit_transform(food_kg_coun)","6068c980":"from sklearn.preprocessing import OneHotEncoder\ncat_encoder = OneHotEncoder(sparse=False)\nfood_kg_coun_1hot = cat_encoder.fit_transform(food_kg_coun)","8f6398bf":"print(\"Country:\",food_kg_coun_1hot.shape)","de0364ce":"food_kg_int = np.concatenate((food_kg_scaled, food_kg_coun_1hot), axis=1, out=None)\nfood_kg_int.shape","ae5b8752":"food_kg_ar = food_kg[['Confirmed','Deaths']].to_numpy()","fa653469":"food_kg_pd = pd.DataFrame(food_kg_int)\nfood_kg_pd.head()","e0814f1d":"food_kg_li = food_kg[['Confirmed','Deaths']]\nfood_kg_li.head()","a5a69f21":"from sklearn.cluster import KMeans\nkm = KMeans(n_clusters=5,\n            init='random',\n            n_init=10, \n            max_iter=300,\n            tol=1e-04,\n            random_state=0)","9f4d566f":"food_kg_km = km.fit_predict(food_kg_int)","c4fb78f4":"km.cluster_centers_","31a3f809":"km.labels_","d4493dc7":"plt.scatter(food_kg_int[food_kg_km==0,0], \n            food_kg_int[food_kg_km==0,1], \n            s=50, \n            c='lightgreen', \n            marker='o', \n            label='cluster 1')\n\nplt.scatter(food_kg_int[food_kg_km==1,0], \n            food_kg_int[food_kg_km==1,1], \n            s=50, \n            c='orange', \n            marker='o', \n            label='cluster 2')\n\nplt.scatter(food_kg_int[food_kg_km==2,0], \n            food_kg_int[food_kg_km==2,1], \n            s=50, \n            c='lightblue', \n            marker='o', \n            label='cluster 3')\n\nplt.scatter(food_kg_int[food_kg_km==3,0], \n            food_kg_int[food_kg_km==3,1], \n            s=50, \n            c='green', \n            marker='o', \n            label='cluster 4')\n\nplt.scatter(km.cluster_centers_[:,0], \n            km.cluster_centers_[:,1], \n            s=250, \n            marker='*', \n            c='red', \n            label='centroids')\n\nplt.ylabel('Deaths')\nplt.xlabel('Confirmed')\nplt.title('Country clusters')\n\nplt.legend()\nplt.grid()\nplt.tight_layout()\nplt.show()","9a3d923c":"print('Distortion: %.2f' % km.inertia_)","14fa11f6":"distortions = []\nfor i in range(1, 12):\n    km = KMeans(n_clusters=i, \n                init='k-means++', \n                n_init=10, \n                max_iter=300, \n                random_state=0)\n    km.fit(food_kg_ar)\n    distortions.append(km.inertia_)\nplt.plot(range(1, 12), distortions , marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Distortion')\nplt.title('Comparing the performance of different K-means clusterings')\nplt.tight_layout()\nplt.show()","87b45545":"import numpy as np\nfrom matplotlib import cm\nfrom sklearn.metrics import silhouette_samples\n\nsilhouette_vals = silhouette_samples(food_kg_int, food_kg_km, metric='euclidean')\nsilhouette_vals","820e87a1":"from sklearn.metrics import silhouette_score\nsilhouette_score_ = silhouette_score(food_kg_int, food_kg_km)\nsilhouette_score_","1cfb1940":"#Getting the clusters from food_kg_km\ncluster_labels = np.unique(food_kg_km)\nn_clusters = cluster_labels.shape[0]\n\ny_ax_lower, y_ax_upper = 0, 0\nyticks = []\n\n#For each cluster, getting the silhouette values and sort them\nfor i, c in enumerate(cluster_labels):\n    c_silhouette_vals = silhouette_vals[food_kg_km == c]\n    #sort them\n    c_silhouette_vals.sort()\n    \n    y_ax_upper += len(c_silhouette_vals)\n    \n    #specify the color with respect to the number of clusters\n    color = cm.jet(i \/ n_clusters)\n    plt.barh(range(y_ax_lower, y_ax_upper), c_silhouette_vals, height=1.0, \n            edgecolor='none', color=color)\n\n    yticks.append((y_ax_lower + y_ax_upper) \/ 2)\n    y_ax_lower += len(c_silhouette_vals)\n\n#Computing and plotting the average silhouette\nsilhouette_avg = silhouette_score(food_kg_int,food_kg_km)\n\n\nplt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n\nplt.yticks(yticks, cluster_labels + 1)\nplt.ylabel('Cluster')\nplt.xlabel('Silhouette coefficient')\n\nplt.tight_layout()\nplt.show()","5218daf4":"from sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(food_kg, test_size=0.2)","bcd9ad2d":"test_set.head()","2049c981":"food_kg_train = train_set.drop(\"Deaths\", axis=1) # drop labels for training set\nfood_kg_train_labels = train_set[\"Deaths\"].copy()\n\nfood_kg_test = test_set.drop(\"Deaths\", axis=1) # drop labels for test set\nfood_kg_test_labels = test_set[\"Deaths\"].copy()","aa72ada2":"food_kg_train_num = food_kg_train.drop('Country', axis=1)\nfood_kg_test_num = food_kg_test.drop('Country', axis=1)","136bfc1b":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(food_kg_train_num)\nfood_kg_train_num_scaled = scaler.transform(food_kg_train_num)\nfood_kg_test_num_scaled = scaler.transform(food_kg_test_num)","2383951d":"food_kg_train_num_scaled","07f9e875":"food_kg_train_coun = food_kg_train[['Country']]\nfood_kg_test_coun = food_kg_test[['Country']]\nfood_kg_test_coun.tail(3)","0755dbec":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nfood_kg_train_coun_encoded = encoder.fit_transform(food_kg_train_coun)\nfood_kg_test_coun_encoded = encoder.fit_transform(food_kg_test_coun)","ef1afba7":"from sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder(sparse=False)\nfood_kg_train_coun_1hot = cat_encoder.fit_transform(food_kg_train_coun)\nfood_kg_test_coun_1hot = cat_encoder.fit_transform(food_kg_test_coun)","fe68ddfb":"print(\"Country:\",food_kg_train_coun_1hot.shape)","d1bccaee":"food_kg_train_num_scaled.shape","165a9e26":"food_kg_train_prepared = np.concatenate((food_kg_train_num_scaled, food_kg_train_coun_1hot), axis=1, out=None)\nfood_kg_train_prepared.shape\nfood_kg_test_prepared = np.concatenate((food_kg_test_num_scaled, food_kg_test_coun_1hot), axis=1, out=None)\nfood_kg_test_prepared.shape","884dbb07":"food_kg_train_prepared","132bc720":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(food_kg_train_prepared, food_kg_train_labels)","33bd151b":"food_kg_train_predictions = lin_reg.predict(food_kg_train_prepared)","d49b89bd":"from sklearn.metrics import mean_squared_error\n\nlin_mse = mean_squared_error(food_kg_train_labels, food_kg_train_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","38b0374b":"from sklearn.metrics import mean_squared_error\n\nlin_mse = mean_squared_error(food_kg_train_labels, food_kg_train_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","1b5e2150":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(random_state=42)\nforest_reg.fit(food_kg_train_prepared, food_kg_train_labels)","9b150fd5":"food_kg_train_predictions = forest_reg.predict(food_kg_train_prepared)\nforest_mse = mean_squared_error(food_kg_train_labels, food_kg_train_predictions)\nforest_rmse = np.sqrt(forest_mse)\nforest_rmse","356dbd3a":"from sklearn.model_selection import cross_val_score\n\nforest_scores = cross_val_score(forest_reg, food_kg_train_prepared, food_kg_train_labels,\n                                scoring=\"neg_mean_squared_error\", cv=10)\nforest_rmse_scores = np.sqrt(-forest_scores)","5887e4bc":"def display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\", scores.mean())\n    print(\"Standard deviation:\", scores.std())","85637fad":"display_scores(forest_rmse_scores)","a204f8a4":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\n\ndef plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n    \n    if axes is None:\n        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n    axes[0].set_title(title)\n    if ylim is not None:\n        axes[0].set_ylim(*ylim)\n    axes[0].set_xlabel(\"Training examples\")\n    axes[0].set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores, fit_times, _ = \\\n        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n                       train_sizes=train_sizes,\n                       return_times=True)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n\n    # Plot learning curve\n    axes[0].grid()\n    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"r\")\n    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1,\n                         color=\"g\")\n    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n                 label=\"Training score\")\n    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n                 label=\"Cross-validation score\")\n    axes[0].legend(loc=\"best\")\n\n    # Plot n_samples vs fit_times\n    axes[1].grid()\n    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n                         fit_times_mean + fit_times_std, alpha=0.1)\n    axes[1].set_xlabel(\"Training examples\")\n    axes[1].set_ylabel(\"fit_times\")\n    axes[1].set_title(\"Scalability of the model\")\n\n    # Plot fit_time vs score\n    axes[2].grid()\n    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1)\n    axes[2].set_xlabel(\"fit_times\")\n    axes[2].set_ylabel(\"Score\")\n    axes[2].set_title(\"Performance of the model\")\n\n    return plt","6c490f79":"food_lc = food_kg.drop(['Country'], axis=1)\nfeatures = list(food_lc.columns)\ntarget = 'Country'\nX = food_kg[features]\ny = food_kg[target]","634e1d38":"from sklearn.model_selection import ShuffleSplit\ncross_val_strategy = ShuffleSplit(n_splits=100,test_size=0.2)\nplot_learning_curve(estimator=GaussianNB(), title='Learning Curves (Naive Bayes)', X=X, y=y, axes=None, ylim=None, cv=cross_val_strategy, n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5))\nplt.show()\n\ncv = ShuffleSplit(n_splits=10,test_size=0.2) \nplot_learning_curve(estimator=SVC(gamma=0.001), title=\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\", X=X, y=y, axes=None, ylim=None, cv=cv, train_sizes=np.linspace(.1, 1.0, 5))\nplt.show()","937ce6eb":"features = food_kg.columns\nimportances = forest_reg.feature_importances_\nindices = np.argsort(importances)[-9:]  # We focus on top 10 features","b78a842f":"plt.title('Feature Importances')\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel('Relative Importance')\nplt.show()","66d85ac6":"obesity_set = food_kg[food_kg['Obesity'] == food_kg['Obesity']].sort_values(by='Obesity', ascending=False).head(10)\nobesity_mean = obesity_set.describe().iloc[1]\nobesity_mean = pd.DataFrame(obesity_mean).drop(['Deaths', 'Population','Undernourished','Obesity', 'Recovered', 'Confirmed', 'Active', 'ConfirmedScore','DeathsScore'], axis=0)\nobesity_mean = obesity_mean.sort_values(by='mean', ascending=False).iloc[:11]\nobesity_mean_plot = obesity_mean.plot.pie(subplots=True, figsize=(25, 10), autopct='%1.1f%%')","5f4bdd7c":"undernutrition_set = food_kg[food_kg['Undernourished'] == food_kg['Undernourished']].sort_values(by='Undernourished', ascending=False).head(10)\nundernutrition_mean = undernutrition_set.describe().iloc[1]\nundernutrition_mean = pd.DataFrame(undernutrition_mean).drop(['Deaths', 'Population','Undernourished','Obesity', 'Recovered', 'Confirmed', 'Active', 'ConfirmedScore','DeathsScore'], axis=0)\nundernutrition_mean = undernutrition_mean.sort_values(by='mean', ascending=False).iloc[:11]\nundernutrition_mean_plot = undernutrition_mean.plot.pie(subplots=True, figsize=(25, 10), autopct='%1.1f%%')","9976bce3":"belgium_case = food_kg[food_kg['Deaths'] == food_kg['Deaths'].max()]\nbelgium_case","d2022cb3":"belgium_case = belgium_case.describe().iloc[1]\nbelgium_diet = pd.DataFrame(belgium_case).drop(['Deaths', 'Population','Undernourished','Obesity', 'Recovered', 'Confirmed', 'Active', 'ConfirmedScore','DeathsScore'], axis=0)\nbelgium_diet = belgium_diet.sort_values(by='mean', ascending=False).iloc[:11]\nbelgium_diet_plot = belgium_diet.plot.pie(subplots=True, figsize=(25, 10), autopct='%1.1f%%')","dc9531c3":"montenegro_diet = food_kg[food_kg['Confirmed'] == food_kg['Confirmed'].max()]\nmontenegro_diet","1e76fc19":"montenegro_diet = montenegro_diet.describe().iloc[1]\nmontenegro_diet = pd.DataFrame(montenegro_diet).drop(['Deaths', 'Population','Undernourished','Obesity', 'Recovered', 'Confirmed', 'Active', 'ConfirmedScore','DeathsScore'], axis=0)\nmontenegro_diet = montenegro_diet.sort_values(by='mean', ascending=False).iloc[:11]\nmontenegro_diet_plot = montenegro_diet.plot.pie(subplots=True, figsize=(25, 10), autopct='%1.1f%%')","1eaefe38":"vanuatu_diet = food_kg[food_kg['Confirmed'] == food_kg['Confirmed'].min()].sort_values(by='Population', ascending=False)\nvanuatu_diet ","12714b5c":"vanuatu_diet  = vanuatu_diet.describe().iloc[1]\nvanuatu_diet  = pd.DataFrame(vanuatu_diet).drop(['Deaths', 'Population','Undernourished','Obesity', 'Recovered', 'Confirmed', 'Active', 'ConfirmedScore','DeathsScore'], axis=0)\nvanuatu_diet  = vanuatu_diet.sort_values(by='mean', ascending=False).iloc[:11]\nvanuatu_diet_plot = vanuatu_diet.plot.pie(subplots=True, figsize=(25, 10), autopct='%1.1f%%')","fa0f920f":"cambodia_diet = food_kg[food_kg['Deaths'] == food_kg['Deaths'].min()].sort_values(by='Population', ascending=False)\ncambodia_diet","f58d4c71":"cambodia_diet = cambodia_diet.describe().iloc[1]\ncambodia_diet = pd.DataFrame(cambodia_diet).drop(['Deaths', 'Population','Undernourished','Obesity', 'Recovered', 'Confirmed', 'Active', 'ConfirmedScore','DeathsScore'], axis=0)\ncambodia_diet = cambodia_diet.sort_values(by='mean', ascending=False).iloc[:11]\ncambodia_diet_plot = cambodia_diet.plot.pie(subplots=True, figsize=(25, 10), autopct='%1.1f%%')","ce2be125":"Now **we predict.**","8ec86a8a":"The distortion begins to decrease with not much significant change for **k=2** so 2 clusters would have been a better choice for this dataset.","01850f86":"Now we can **easily spot the differences.** Here undernourished people consume **way less animal products** and **much more starchy roots** than the world's consumption in average or the obese people on average. Moreover, they seem to be **consuming a bit more alcoholic beverages.**","ec453a39":"It is important to underline that Belgium has a **24.5% obesity rate, which could partly explained the high mortality rate.**","88dddaba":"Now that we know our dataset a bit better, let's analyze **correlations**, and **challenge our own bias**, especially regarding **obesity being an aggravating factor of covid.**\nTo do so we are going to drop all the mirror correlation (ex population\/population, spices\/spices, etc.). To apply the function below we used two sources : <a href='https:\/\/stackoverflow.com\/questions\/17778394\/list-highest-correlation-pairs-from-a-large-correlation-matrix-in-pandas'> one for abs and unstack<\/a> and <a href='https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.unstack.html'> one for dropping the head rows<\/a>. \nThat way we now have all the *'true'* correlations.","bfbfd335":"We then proceed exploring the data by describing it ; it gives us a **data description**. ","ecea2638":"We start out test with the **Alcoholic Beverages** column ; one country average diet is supposedly composed of **15%** of alcoholic beverages. We first look at the corresponding country and then we do a short search on the internet to confirm or deny the information. ","b9afb15a":"### 1. Value Types  <a class=\"anchor\" id=\"section_3_1\"><\/a>","9939e7c1":"We start by **converting the string column 'Country' into an integer**, creating a new dataset called *food_kg_int.* This dataset in now an **array,** storing values of same data type.","1616d97b":"### 2. Performing feature scaling <a class=\"anchor\" id=\"Section_6_2\"><\/a>","33f6aa4d":"Let's create a function to **check missing data** and unveil **the percentage of data missing** for each dataframe, as seen in the python bootcamp.","fe11df54":"We create bins, knowing that covid mortality rates go from **0 to almost 15%** (from Cambodia to Belgium). We want to have **4 figures** (1 to 4 - 4 being the worse) so we **arbitrary** create **4 bins.** ","a4f5857b":"#### 2. Confirmed cases scoring <a class=\"anchor\" id=\"Section_5_1_2\"><\/a>","bac01f06":"Finally, we plot **the results of clustering.**","dd4c3c9a":"We can have a look at our 4 clusters **through a graph.** ","37661200":"### 3. Random forest filter <a class=\"anchor\" id=\"Section_8_3\"><\/a>","a3ee0d14":"Let's **separate the data into a training and testing sets** using random selection and setting the ratio to 0.2.","195c838b":"Just like we did above for obesity average diet we take the **top 10 countries in terms of undernourished rate** and put them in a variable so we can analyse and plot them :","fb3460d2":"### 4. Early visualizations  <a class=\"anchor\" id=\"section_3_4\"><\/a>","41072c88":"We have data on **170 countries,** and the **Undernourished and Unit columns are considered as objects,** let's modify that.\n<br> First, we look at the unique values of this column : this help us understand wether we can directly convert it to float or if there is one or more string elements blocking.","53266d4d":"First, we want to **visualize the world average diet**. To do so, we create a variable called \"diet_mean\" where we put the dataset description. We select the first row with *iloc* in order to only have the mean of all columns. Then, we *drop* the columns related to covid or health. We also only choose the columns having a mean superior to 1% ; we thus select 11 product categories.","9e64e579":"## Features Engineering <a class=\"anchor\" id=\"chapter5\"><\/a>","592e0a05":"Finally Cambodia has a **low obesity rate**, and a **high undernourished one.** ","6f46c152":"#### b.  K-Means <a class=\"anchor\" id=\"Section_5_2_2\"><\/a>","47fd1d31":"Let's **upload the packages we would like to use.** ","95ecc09d":"Then, we noticed that the **different rates for undernourished, obesity and COVID are in percentage of the total population.**","97e7eb11":"For this one we have several countries with very few covid-related deaths. For our analysis to be relevant we decided to choose among these countries the one with the largest population. To do so we sorted it by population.","f3067e02":"Such results are to be **interpreted carefully** as many other factors are to be taken into account - for example, undernourished patients are most likely to be in emerging countries, where the population is very young and most likely to survive. ","8da0bcbb":"## Problem definition <a class=\"anchor\" id=\"chapter2\"><\/a>","0f446d50":"#### b. World covid cases <a class=\"anchor\" id=\"section_3_4_2\"><\/a>","88211ec6":"The pie chart above **looks a lot like the average pie chart diet we made earlier for the world consumption.** The countries with the most obesity rate seem to consume more vegetables than people on average.","6dc3df21":"Then, we **merge these lists in one**, giving us the most interesting diet attributes to compare to the health states.","4e073cfd":"We want to create a list of the **strongest correlations with diets for 3 covid states**: confirmed, deaths, and recovered. We will not use the active covid state as it is part of the confirmed covid cases. \n\nTo do so we have to *drop* the health attributes for each list:","22f192f1":"And we measure this regression model\u2019s **RMSE** on the whole training set.","953ed905":"There seems to be some **anomalies** in the dataset, with notably strong extremes, that we see in the **max range**. To test if the data is accurate, we quickly test some of the most striking figures.","199bdf0c":"#### c. Vanuatu : the one with the less confirmed cases in relation to its population <a class=\"anchor\" id=\"Section_9_2_3\"><\/a>","09c26e11":"We transform our *food_kg* train categories and *food_kg* test categories **from categories into numerical data.**","75041049":"#### b. Undernourished  <a class=\"anchor\" id=\"section_3_3_2\"><\/a>","26134ee3":"The corresponding country is **Kiribati**, an archipelago republic in Central Pacific Ocean. After looking up on the internet, it is once again true : the obesity rate of the country was as high as **46%** in 2016 (<a href='https:\/\/bmcpublichealth.biomedcentral.com\/articles\/10.1186\/s12889-020-09217-z#:~:text=In%20fact%2C%20in%202016%2C%20the,of%201.96%25%20%5B5%5D'> source<\/a>).","ee484855":"Vanuatu is very interesting, as the country has also a **high obesity rate of 23.5%**. Nevertheless, its mortality rate and confirmed rate are one of the lowest. Thus, its **diet has to be quite different** than the others and could explain those differences : ","feb550b3":"Nonetheless it doesn't seem to give us any conclusive results, so we are going to **move on** and **refocus on the different diets and their impacts.**","134d161d":"Montenegro has a high obesity rate of **24.9%** too, and a **quite high mortality rate.**","dd4366d4":"And then we create a new dataset, called *food_kg_ar* **focusing on confirmed cases and deaths**, that we turn into an **array** as well.","1bc65901":"We compute the **silhouette score** of each sample to quantify the quality our clustering","c3ddeff9":"## Model Selection <a class=\"anchor\" id=\"chapter6\"><\/a>","3ac5dbb4":"Given this dataset and **the emphasis we have already laid on deaths** through clustering and classification, we thought it would be interesting to try identifying **the factors that are most likely to lead to a deceased person by modelling such data.**","b19db7dc":"Now we **concatenate** the processed numerical and categorical features into **one matrix.**","6010d7d4":"## Learning Curves analysis <a class=\"anchor\" id=\"chapter7\"><\/a>\n","90312811":"### 2. Extreme covid results and diet: back to our 4 extremes <a class=\"anchor\" id=\"Section_8_2\"><\/a>","0845f5ab":"We can test the repartition looking at the **occurrence of each grade.** The occurence is **not evenly shared** since the bins were arbitrary made.","3d311894":"The Unit column only contains the % sign, indicating that all the column except the Population one are in percentages. It is important to know the unit used, but now that we know this information we can **delete this column which is no longer useful.**","83ce50b6":"# Machine Learning - Final project - Kerbidi Kim Lou \/ Malka Laura\n\n## Context\n\n\nFor this final project you are required to choose and define a business problem of which you will apply machine learning to. \n\n## Data\nYou shall choose a dataset from the datasets available on <a href=\"https:\/\/www.kaggle.com\/datasets\">kaggle.com<\/a>.\n\nYou are free to choose any dataset you want, however, your choice should be motivated by something that interests you, for example:\n- your speciality or your future professional project\n- recent events in the world such as the USA election or the covid\n- etc.\n\nThe following are a selection of some datasets from Kaggle, you can choose one of them if you want. \n\n<a href=\"https:\/\/www.kaggle.com\/c\/home-credit-default-risk\/data\">Home Credit Default Risk<\/a>  \n\n<a href=\"https:\/\/www.kaggle.com\/mariaren\/covid19-healthy-diet-dataset\">COVID-19 Healthy Diet Dataset<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/volodymyrgavrysh\/bank-marketing-campaigns-dataset\">Bank marketing campaigns dataset<\/a>\n\n\n\n\n## What should you do ?\n\nMake a notebook telling interesting things about the data you have fetched, tell a story (or many) using everything you learned. Build predictive models and compare them.  \nYou have to submit at least a notebook and any resources you used (like images or any other files).\n\n\nYour final submission should include the following: \n\n- Problem definition\n- Data Exploration\n- Data Processing (Cleaning, etc.)\n- Features Selection\n- Features Engineering\n- Model Selection\n- Learning Curves analysis\n- Dimensionality Reduction\n- Results Visualization\n- Results Interpretation\n\n## Assessment \nHere are the criteria we will use to assess your work:\n\n### Is it meaningful?\nAs a machine learning expert you have to produce something meaningful enough, just plotting random data is not going to work. Like a story your analysis should have some kind of logical progression.\n\n### How well did you use the technical knowledge you\u2019ve been taught?\nObviously, the way you use everything you learned during the lectures is going to be assessed.\n\n### Cleanliness, aesthetics and clearness of your notebook\nIs your analysis full of unused code? Is it difficult to read? Have you tried to make it easy and enjoyable to read?\n\n### Innovation\nCreativity, surprising things or any good initiatives you take are potential bonus points.\n\n\n### Careful:\n\tThis work is individual, plagiarism is going to be measured by both machines and humans. Too many similarities between your work and any online or python buddy work will result in grade penalties.\n\n\nGood Luck!\n\n\n","c1d7d59e":"#### d.  Silhouette plots <a class=\"anchor\" id=\"Section_5_2_4\"><\/a>","dcef4369":"Eventually, we have Montenegro's polar opposite, Vanuatu, [the world's least affected country when it comes to the coronavirus confirmed cases rate](https:\/\/time.com\/5910456\/pacific-islands-covid-19-vanuatu\/).","27266b37":"Vanuatu's population consumes **much less animal products than the first two of our examples, and consumes much more starchy roots and oilcrops.**","d2f42e0a":"We take the **top 10 countries in terms of obesity rate** and put them in a variable so we can analyse and plot them :","d75ccd0b":"Now we know the **11 strongest correlations** of those 3 covid states, listed above.","cab47fd8":"### 2. The one with the most confirmed cases in relation to the population: Montenegro <a class=\"anchor\" id=\"Section_4_2\"><\/a>","f5599865":"To better understand the four countries that we have identified earlier and their dynamics we are going to **analyze each of their diet**, to see if it is linked to their results.","4b14e330":"Then, we have Montenegro **the world's worst affected country when it comes to the coronavirus confirmed cases rate**.","17aad5f9":"#### a. Mortality rate scoring <a class=\"anchor\" id=\"Section_5_1_1\"><\/a>","1fd2c276":"### 4. The one with the least confirmed cases in relation to the population: Vanuatu <a class=\"anchor\" id=\"Section_4_4\"><\/a>","ffdaa3e5":"Now, we want to **visualize the world average covid state**. To do so, we use *plotly express* to have the possibility to **hover** on a scatter plot and see the statistics per country clearer as explained [here](https:\/\/plotly.com\/python\/hover-text-and-formatting\/).  ","638b0c10":"Now that we have fixed the Unit column problem we are going to **focus on the Undernourished one.** Again, we proceed to firstly look at the unique values of this column: helping us understand wHether we can directly convert it to float or if there is one or more string elements blocking.","d8318e15":" ## Dataset chosen on Kaggle <a class=\"anchor\" id=\"chapter1\"><\/a>","145fda6b":"Random forest can also be used for dimensionality reduction, offering a **built-in feature importance measurer**, helping us to select a **smaller subset of features** [(source)](https:\/\/www.analyticsvidhya.com\/blog\/2018\/08\/dimensionality-reduction-techniques-python\/).","d79492ff":"Now **we predict.**","2b8a317a":"And we **create a plot of the silhouette coefficients** for a K-means clustering with **k=5.**","c5181598":"### 2. Missing Values  <a class=\"anchor\" id=\"section_3_2\"><\/a>","e8f5fdbf":"--------------------------","434f99ad":"#### a. Belgium : the one with the more deaths cases in relation to its population <a class=\"anchor\" id=\"Section_9_2_1\"><\/a>","8fd09543":"We now have Belgium's polar opposite, Cambodia, [one of the world's least affected country when it comes to the coronavirus mortality rate](https:\/\/www.abc.net.au\/news\/2020-12-04\/cambodia-handling-covid-19-community-transmission-zero-deaths\/12938226).","e8f1612b":"### 4. Random forest <a class=\"anchor\" id=\"Section_6_4\"><\/a>","9205a960":"Our handmade clustering works but it is **not very representative.**  ","d37bc34e":"#### d. Cambodia : the one with the less deaths cases in relation to its population <a class=\"anchor\" id=\"Section_9_2_4\"><\/a>","7c8c1b9e":"First, we have Belgium, \n[the world's worst affected country when it comes to the coronavirus mortality rate](https:\/\/www.bbc.com\/news\/world-europe-52491210).","21340d38":"Finally, we **turn back into a list rather than an array for both.**","2922e6c6":"### 1. Handmade clustering <a class=\"anchor\" id=\"Section_5_1\"><\/a>","218bb101":"We **now drop the labels** from the training set and **create a new variable for the labels.**","7fc9db0b":"First, we noticed that the different diet measures are described as their **percentage of prevalence in the total diet.** For Afghanistan for example, alcohol represents 0% of an inhabitant's diet. ","68ac1a13":"#### b. Health state vs covid <a class=\"anchor\" id=\"section_3_5_2\"><\/a>","ea5a2def":"In almost all dataset, the data are organized by countries. There are 170 countries in these datasets.\n<br>After we discovered the different columns in each dataset, we wanted to **focus on how each column data is calculated.**","949cfc11":"We have a **negative difference** here, meaning the point is on average closer to the neighboring group than to its own: it is therefore **misclassified.**\n\nAs underlined by the silhouette above, our clustering is **not so great**, therefore we will **not pursue clustering** to continue our explanation of covid deaths thanks to other models. ","4c23f96c":"Indeed, the problem seems to come from the **\"<2.5\"** value, as the float type does not support special characters. To fix that, we are going to replace all the \"<2.5\" values with **just \"2.5\".** ","aed74f7b":"Finally, the last surprising figure is related to the **Obesity column:**","7c311912":"Based on the above graph, the key features are the **active cases rate** (contained in the confirmed rate we focused on), the **undernourished feature** and the **confirmed cases feature.** \n\nThe **mortality rate is also among the top 10 important features**, and so are the **diet indicators** we kept through our correlation filter (*'Alcoholic Beverages'*, *'Milk - Excluding Butter'* and more).","5189ad17":"Again, we can test the repartition looking at the **occurrence of each grade.** The occurence is **not evenly shared** since the bins were arbitrary made.","e2ed80b4":"We now **compute the mean silhouette coefficient of all samples.**","09b8237b":"We have **six columns with missing values** (not reaching 170 values): obesity, undernourished, confirmed, deaths, recovered, and active.","bb1434f8":"Indeed, we can now see that **obesity has a stronger correlation with covid deaths than recovery** and **undernourished patients has a stronger correlation with covid recovery than deaths.**","07a4c843":"We start with **K-Means model,** since K-means is easy to implement and computationally very efficient. We **create 4 groups based on their feature similarities.**","7f8894ee":"Here, the corresponding country is **Burkina Faso.** After searching it on the internet, it appears that in spite of Islam being the most prevalent religion in Burkina Faso (nearly 60% of the population according to a survey conducted in 2006), there is a high consumption of alcohol in the country. Indeed, in 2018, **22** liters of pure alcohol were consumed per year and per inhabitant (<a href='https:\/\/movendi.ngo\/news\/2020\/07\/03\/burkina-faso-300000-liters-of-liquor-destroyed-in-ouagadougou\/#:~:text=Per%20capita%20alcohol%20intake%20of,adults%20that%20number%20is%2046%25'>source<\/a>). In comparaison, in 2016 in France, it is **11.7** liters that are consumed per year per inhabitant (<a href='https:\/\/www.stop-alcool.ch\/fr\/l-alcool-en-general-2\/statistiques-sur-la-consommation\/quelques-chiffres-pour-la-france#:~:text=Avec%2011%2C7%20litres%20d,2'>source<\/a>).","7abee091":"#### b. Montenegro : the one with the more confirmed cases in relation to its population <a class=\"anchor\" id=\"Section_9_2_2\"><\/a>","16ef445a":"We **concatenate** the processed numerical and categorical features **into one matrix.**","a1946480":"We can see here that Belgium population consumes **more animal products, milk (excluding butter) and alcohol than the average worlds' consumption**, or **even than the average obese diet.**","2245a095":"### 3. The most populated one with the least deaths in relation to the population: Cambodia <a class=\"anchor\" id=\"Section_4_3\"><\/a>","f17560ee":"#### c.  Elbow method <a class=\"anchor\" id=\"Section_5_2_3\"><\/a>","eb315402":"### 3. Linear Regression <a class=\"anchor\" id=\"Section_6_3\"><\/a>","4201c41a":"In the Data Exploration part, we created a *function* to show the **percentage of missing values** per category, and decided to **get rid** of the *Countries* that had missing values.\n\nIndeed, we were faced with **two choices**: imputing the missing values or dropping the variable. Knowing we could not recover the missing data due to the **uncertainty** in terms of extraction date and population count taken into account for calculation, we went for the second option. \n\n**Such filtering through missing values is was a form of dimensionality reduction.**","e0ca90ef":"We focus on one of the dataset since those are similar, and chose to **focus on the easiest to understand: food_kg.**","9b4bd68a":"## Results Visualization and Interpretation <a class=\"anchor\" id=\"chapter9\"><\/a>","162df60f":"Now let's **discover the different datasets.**","e7f36d2f":"--------------------------","8571b730":"Again, our handmade clustering works but it is **not very representative.** We can try to do better. ","3e53ba22":"#### a. Obesity average diet <a class=\"anchor\" id=\"Section_9_1_1\"><\/a>","9a7cbd70":"The test and train sets **seem representatives.**","5a8a766b":"And we check the **predicted clusters' centers (centroids).**","bc93f2b7":"#### a. Diet vs covid <a class=\"anchor\" id=\"section_3_5_1\"><\/a>","d4339b63":"# Table of Contents\n\n* [Dataset chosen on Kaggle](#chapter1)\n* [Problem definition](#chapter2)\n* [Data Exploration and Processing](#chapter3)\n    * [Value Types](#section_3_1)\n    * [Missing Values](#Section_3_2)\n    * [Analyzing extremes](#Section_3_3)\n        * [Alcoholic consumption](#section_3_3_1)\n        * [Undernourished](#section_3_3_2)\n        * [Obesity](#section_3_3_3)\n    * [Early visualizations](#Section_3_4)\n        * [World average diet](#section_3_4_1)\n        * [World covid cases](#section_3_4_2)   \n    * [Insights](#Section_3_5)  \n        * [Diet vs covid](#section_3_5_1)\n        * [Health state vs covid](#section_3_5_2)   \n* [Features Selection](#chapter4) \n    * [Most deaths: Belgium](#section_4_1)\n    * [Most confirmed cases: Montenegro](#Section_4_2)\n    * [Least deaths: Cambodia](#Section_4_3)\n    * [Least confirmed cases: Vanuatu](#Section_4_4)\n* [Features Engineering](#chapter5)\n    * [Handmade clustering](#section_5_1)\n        * [Mortality rate scoring](#section_5_1_1)\n        * [Confirmed cases scoring](#Section_5_1_2)\n    * [Unsupervised learning](#section_5_2)\n        * [Preparation](#section_5_2_1)\n        * [K-means](#Section_5_2_2)\n        * [Elbow method](#section_5_2_3)\n        * [Silhouette plots](#Section_5_2_4)\n* [Model Selection](#chapter6) \n    * [Creating train and test sets](#Section_6_1)\n    * [Performing features scaling](#Section_6_2)\n    * [Linear regression](#Section_6_3)\n    * [Random forest](#Section_6_4)\n* [Learning Curves analysis](#chapter7) \n* [Dimensionality Reduction](#chapter8)\n    * [Missing values filter](#Section_8_1)\n    * [High correlation filter](#Section_8_2)\n    * [Random forest](#Section_8_3)\n* [Results Visualization and Interpretation](#chapter9) \n    * [Obesity vs undernutrition: a happy medium?](#Section_9_1)\n        * [Obesity average diet](#Section_9_1_1)\n        * [Undernutrition average diet](#Section_9_1_2)    \n    * [Extreme covid results and diet: back to our 4 extremes](#Section_9_2)\n        * [Most deaths: Belgium](#section_9_2_1)\n        * [Most confirmed cases: Montenegro](#Section_9_2_2)\n        * [Least confirmed cases: Vanuatu](#Section_9_2_3)   \n        * [Least deaths: Cambodia](#Section_9_2_4)","ab43cc68":"<br>\n<b>Conclusions","0f7ad089":"Now that we have fixed the string elements in the column, we can actually **do the convertion to float.**","5ba38b8f":"https:\/\/www.kaggle.com\/mariaren\/covid19-healthy-diet-dataset","fb027538":"Now we plot the **feature importance graph.**","deae6cc8":"Cambodia's population **consume more starchy roots and cereals (excluding beer) than the average world's consumption.**","a86d8025":"Although some data seem to be anormal at first sight, there are **no anomalies nor abnormal extremes** ; it is a good sign. Indeed, despite the **variety** of the data set, it seems like it still holds **accurate data**, that will enable us to conduct a relevant analysis. ","0f697ec5":"## Dimensionality Reduction <a class=\"anchor\" id=\"chapter8\"><\/a>","1953bf6a":"We chose a dataset combining different types of **food,** world population **obesity and undernourished rate**, and **global covid cases count** from **around the world.** \n\nThe idea is to understand how a **healthy eating style could help combat the coronavirus,** distinguishing the diet patterns from countries with lower COVID infection rate.\n\nOur goal here is to **provide diet recommendations base on our findings.**\n\n\nEach dataset provides **different diet measure** different categories of food, depending on what we want to focus on, so we have \n- fat quantity, \n- energy intake (kcal), \n- food supply quantity (kg), \n- protein for different categories of food \n\nTo which have been added:\n- obesity rate\n- undernourished rate \n- the most up to date confirmed\/deaths\/recovered\/active cases.","8afe0b5a":"Let's go deeper and dig into **different data types for each variable.**","744fd990":"This table gives us an **approximation of how the world consumption under covid times**, as the data of over 170 countries are gathered here. \n\nThis help us get **an understanding of the world's average health**:\n- Obesity : 19% of the population of the 170 countries\n- Undernourished : 11% of the population of the 170 countries\n\nAnd learning more about the **covid pandemic**: \n- Confirmed : 1.2% of confirmed cases of covid among the latters\n- Deaths : 0.02% of deaths due to covid\n- Recovered : 0.8% of recovered patients from covid","1714c8d5":"Let's start by **loading the data.**","053cd39d":"#### a. World average diet <a class=\"anchor\" id=\"section_3_4_1\"><\/a>","767abc6c":"After having compared diets to covid results, we now do the **same covid comparison to the health state** to see if there is a pattern as well:","0a57288b":"Finally, we wanted to make sure that **confirmed cases** are the result of the **sum of deaths, recovered and active case.**","52f77b5d":"We use a graphical tool, the **elbow method,** to estimate the optimal number of clusters k for a given task.","f4ff39ad":"### 3. Analyzing extremes <a class=\"anchor\" id=\"section_3_3\"><\/a>","341cd905":"### 1. Obesity vs undernutrition: a happy medium? <a class=\"anchor\" id=\"Section_9_1\"><\/a>","f26d45f7":"### 1. Creating train and test sets <a class=\"anchor\" id=\"Section_6_1\"><\/a>","0a5073f9":"Now **onto linear regression.**","1584f221":"Now that we know more about each value, **we start to explore.**","1bee009b":"## Features Selection <a class=\"anchor\" id=\"chapter4\"><\/a>","815234eb":"## Data Exploration and Processing <a class=\"anchor\" id=\"chapter3\"><\/a>","ffff45ac":"### 5. Insights <a class=\"anchor\" id=\"section_3_5\"><\/a>","5f048275":"Since we **cannot approximate those values** nor find the exact missing values in terms of extraction date and population count taken into account for calculation. We thus decided we would **delete the countries** for which values are missing.","472d4065":"--------------------------","a2c999b1":"### 1. The one with the most deaths in relation to the population: Belgium <a class=\"anchor\" id=\"Section_4_1\"><\/a>","1ae6ac8d":"Now we dive into feature engineering, as we try to **create new input features from your existing ones**. In this sense, we thought about creating a new column in which we would **score countries based on their coronavirus results** (again, confirmed and deaths rates). Such grading would allow us to start clustering countries based on the way they handled the situation. ","5d2f3dcf":"We try to **model mortality** through linear regression. ","13b3f112":"Then we **have a look at the predicted clusters.**","8a183c02":"### 2. High Correlation filter <a class=\"anchor\" id=\"Section_8_2\"><\/a>","9c32740a":"### 2. Unsupervised clustering <a class=\"anchor\" id=\"Section_5_2\"><\/a>","4a84532f":"And display the **resulting scores:**","9c1930fe":"#### a. Preparation <a class=\"anchor\" id=\"Section_5_2_1\"><\/a>","9beffafc":"The **number of missing values is low** - from 3 to 9 missing values on 170 lines. Let's see which countries are concerned.","3c811299":"Montenegro's population consumes **even more animal products, meat and milk (excluding butter) than the Belgium one.** ","fa6efd38":"Now that we have try some handmade clustering through arbitrary bins, we can go for **unsupervised clustering** as we have seen in Lesson 5. ","13e689f4":"The corresponding country is **Central African Republic.** Again, this information is also accurate : **79%** of the country's population was estimated to be living in poverty in 2018, thus being more susceptible to be undernourished (<a href='https:\/\/www.wfp.org\/countries\/central-african-republic#:~:text=The%20Central%20African%20Republic%20'>source<\/a>).","424cedf6":"Let's train a **linear regression model** on the prepared *food_kg* training set.","9377a3bb":"To define below X and y we used this <a href='https:\/\/www.dataquest.io\/blog\/learning-curves-machine-learning\/'>source<\/a> to help us :","f3a249d6":"As seen in class 7, dimensionality reduction is a way to **reduce the number of features** in your dataset without having **to lose much information** and keep the model\u2019s performance \n[(source)](https:\/\/www.analyticsvidhya.com\/blog\/2018\/08\/dimensionality-reduction-techniques-python\/).\nOur dataset is quite small, so we **only seeked basic dimensionality reduction techniques.**","bd0013ba":"### 1. Missing Values filter <a class=\"anchor\" id=\"Section_8_1\"><\/a>","b2850393":"#### c. Obesity  <a class=\"anchor\" id=\"section_3_3_3\"><\/a>","98d87b66":"Here, **we don't need an imputer** or any additional manipulations since **we no longer have any missing values.** ","b95b2d7a":"We have established that **obesity and undernutrition are correlated to covid-cases.** We are now going to dive deeper analyzing the **diet in countries with each health attributes**, and see how covid impacted them.","13045be6":"The result is a bit **messy,** let's see if had chosen the right number of samples in the first place through the **elbow method.**","ab2f0042":"#### b. Undernutrition average diet  <a class=\"anchor\" id=\"Section_9_1_2\"><\/a>","a87ba8ec":"Another filtering we have used is the high correlation filter for  variables that have **similar trends** and are **likely to carry similar information.** \n\nIndeed, when we worked on correlations, we **focused on the most correlated diet attributes** to compare to the health states in different countries, and we **phased out some of them** (that were too similar or countained in one another).\n\nWe thus focused on **each covid state only** on *'Animal Products','Animal fats','Cereals - Excluding Beer','Eggs','Meat','Milk - Excluding Butter','Pulses','Starchy Roots','Sugar & Sweeteners'* and *'Vegetal Products'* **rather than the whole column assortment** provided in the first place.","45bd7a5e":"#### a. Alcoholic consumption  <a class=\"anchor\" id=\"section_3_3_1\"><\/a>","202d602b":"This could mean that in average, **obese patients are most likely to die from covid** while **undernourished are most likely to survive**. This is why [obesity worsens outcomes from covid](https:\/\/www.cdc.gov\/obesity\/data\/obesity-and-covid-19.html).","1a5f8c28":"In conclusion, now that we have studied those pie charts, there seem to be **some patterns**. Firstly, as we already highlighted it, **obesity is indeed a risk factor**, leading in most cases to a high mortality rate. Moreover, it seems that **alcoholic beverages could also be a factor** ; we can notice it in the case of Belgium, which is quite similar to Montenegro, but differs in terms of alcoholic beverages consumption. That could explain the differences in mortality rate between the two countries.\n\nNonetheless, our conclusions only rely on the factors accessible in this dataset. Other factors such as **age, other health problems**, as well as the **country's covid-related politics** could influence the confirmed and mortality rates. Indeed, the reaction from some country such as Cambodia, which **promptly instaured a national lockdown, helped to control the virus propagation** (<a href='https:\/\/blogs.worldbank.org\/health\/what-explains-cambodias-effective-emergency-health-response-covid-19-coronavirus'>source<\/a>).","9d2dd32b":"In order **to quantify the quality of our clustering**, we need to use **distortion** to **compare the performance of different K-means clusterings**. ","edf10806":"Let's try a **random forest model** on the prepared *food_kg* training set.","669fce17":"We are going to visualize it a bit better by making a **heatmap for each of them**, solely based on the diets' attributes listed above:","1b652f4b":"Let's apply the function. We display **6 rows as we know we have 6 columns with missing values**.","37a2fb07":"Let's perform a **10 fold cross validation.**","4c7eb442":"Same as above, we create bins, knowing that covid confirmed case rate go from **almost 0 to almost 6** (from Vanuatu to Montenegro). We want to have **4 figures** (1 to 4 - 4 being the worse) so we **arbitrary** create **4 bins.** ","c0b4942f":"Then, we move on the **Undernourished column:** ","9eb8cb14":"We decided to select **4 countries to focus on.** Those countries reflect extremes in terms of deaths and confirmed cases in relation to their population, and could therefore be **representative of some of our results.**","1585c13e":"To confirm that the Undernourished column is now a float type, and to dive a bit deeper in the composition of the data set, we now look at **an overview of all information.**","c9a4a95b":"This graph gives a sense of **repartition of countries in function of their covid deaths and confirmed case**. Extremes can be easily spotted. ","85839a00":"We will use the following function to **plot learning curves with cross validation.** \n\nAs seen in class 6, the function generates 3 plots: \n- the **test and training** learning curve, \n- the **training samples** vs **fit times curve,**\n- the **fit times vs score curve.**","875a4669":"Let's measure this regression model\u2019s **MAE** on the whole training set.","80e6fa31":"And we **preprocess the categorical input features.**","f286d8ad":"Let's dig into **different data types.**","b3a6a4db":"We can see that the first two diets, **confirmed and deaths cases diets, are very similar**. Indeed, the top 3 correlations are **animal products, milk (excluding butter), and animal fat**. When we compare that to the recovered cases diets, the **animal fat is significantly lower** in terms of correlation. Recovered cases diets have a **lesser correlation to meat** as well. \n\nThis could mean that in average, **recovered cases eat less meat and animal fat**. This is why [malnutrition is a threat-multiplier](https:\/\/globalnutritionreport.org\/blog\/nutrition-and-covid-19-malnutrition-threat-multiplier\/).","5d5521f7":"When looking through the diet details, we can see that **vegetal products** are the most consumed, followed by **animal products and cereals.** This pie chart will help us in our analysis later on ; it will serve as a **refferal** to understand the differences in covid cases between countries, based on alimentation.","31b60771":"Now we perform **features scaling** on the cleaned training and testing *food_kg* datasets.","4eab6291":"We get the **labels found of the K-means.**"}}