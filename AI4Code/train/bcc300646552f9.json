{"cell_type":{"0088596d":"code","25cfecab":"code","a8da8a56":"code","d665c360":"code","d3b1ee37":"code","e59bf3cd":"code","8ed4bdd0":"code","86d94dcd":"code","f1c31144":"code","2f6b09ad":"code","5a1b8afd":"code","66de4cab":"code","ab34c868":"code","f13e53fd":"code","9586dac0":"code","4fa5b640":"code","4a64f402":"code","5b2cd56d":"code","6466492f":"code","cf629262":"code","ebc6de38":"code","2d8f6279":"code","77abca67":"code","bb3d4d56":"code","d364885d":"code","dfa3e089":"code","124a75c5":"code","fa370e93":"markdown","dc7754f4":"markdown","563dcaa8":"markdown","f92d7cf8":"markdown","4ee32f40":"markdown","498b0c2a":"markdown","82f8e763":"markdown","e7f73860":"markdown","910d24c2":"markdown","cc3c3d6a":"markdown","d63679a4":"markdown","57326953":"markdown","365099df":"markdown","5fcce21d":"markdown","2b033187":"markdown"},"source":{"0088596d":"#This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly as py\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.subplots import make_subplots\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\npy.offline.init_notebook_mode(connected = False)\nimport os\npath = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        path.append(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current sessionn","25cfecab":"path.sort()\ncsvs = list(path[1:])\ncsv_13to15 = csvs[0:3] \ncsv_2016 = csvs[3:5] \ncsv_2017 = csvs[5:7]\ncsv_2018 = csvs[7:]\ncsvs ","a8da8a56":"columns_name = [\"tax_payer\",\"ntn\",\"tax_paid\"] # specifying names to enure consistency in names\ntax_2013 = pd.read_csv(csv_13to15[0], encoding=\"latin1\",names=columns_name,header=0)\ntax_2014 = pd.read_csv(csv_13to15[1], encoding=\"latin1\",names=columns_name,header=0)\ntax_2015 = pd.read_csv(csv_13to15[2], encoding=\"latin1\",names=columns_name,header=0)\ntax_2016 = pd.concat([pd.read_csv(file,encoding=\"latin1\",names=columns_name,header=0) for file in csv_2016])                  \ntax_2017 = pd.concat([pd.read_csv(file,encoding=\"latin1\",names=columns_name,header=0) for file in csv_2017])\ntax_2018 = pd.concat([pd.read_csv(file,encoding=\"latin1\",names=columns_name,header=0) for file in csv_2018])\ndata =  [tax_2013,tax_2014, tax_2015,tax_2016,tax_2017,tax_2018] # list of dataframes","d665c360":"for y,df in enumerate(data,start=2013) :\n    print(f\"\"\"Percentage % of Null values in {y} \n    \\n{(df.isnull().sum()\/len(df))*100}\n    \\n----------------------------------------\\nData Types of {y}\\n{df.dtypes}\n    \\n########################################\"\"\")","d3b1ee37":"def string_to_float(df,col,text=[\"-\",\"Tax Paid\",\"?\",'###########']):\n    df[\"paid\"] =  df[col].replace(text,\"0\").str.replace(\",\",\"\").astype(float)\n    return df[\"paid\"]","e59bf3cd":"for df in data:    \n    string_to_float(df,col=\"tax_paid\")","8ed4bdd0":"def tax_payer_category_1(tax_2013):\n    IND = tax_2013.tax_payer[tax_2013.tax_payer == \"INDIVIDUAL\"].index\n    ASSC = tax_2013.tax_payer[tax_2013.tax_payer == \"ASSOCIATION OF PERSONS\"].index\n    tax_2013[\"Category\"] = np.where(tax_2013.index>IND[0],\"Individual\",\"\")\n    tax_2013[\"Category\"] = np.where(tax_2013.index < ASSC[0],\"Companies & Other\",tax_2013[\"Category\"])\n    tax_2013[\"Category\"] = np.where((tax_2013.index < IND[0]) & (tax_2013.index >= ASSC[0]),\n                                    \"Companies & Other\",tax_2013[\"Category\"])\n    return tax_2013","86d94dcd":"for df in data[0:3]:\n    tax_payer_category_1(tax_2013=df)","f1c31144":"def tax_payer_category_2(tax_2013):\n    IND = tax_2013.tax_payer[tax_2013.tax_payer == \"INDIVIDUAL\"].index.sort_values(ascending=True)\n    ASSC = tax_2013.tax_payer[tax_2013.tax_payer == \"ASSOCIATION OF PERSON\"].index\n    tax_2013[\"Category\"] = np.where(tax_2013.index>=IND[0],\"Individual\",\"\")\n    tax_2013[\"Category\"] = np.where(tax_2013.index>IND[1],\"Individual\",tax_2013[\"Category\"])\n    tax_2013[\"Category\"] = np.where(tax_2013.index>IND[2],\"Individual\",tax_2013[\"Category\"])\n    tax_2013[\"Category\"] = np.where(tax_2013.index <= ASSC[0],\"Companies & Other\",tax_2013[\"Category\"])\n    tax_2013[\"Category\"] = np.where((tax_2013.index < IND[0]) & (tax_2013.index > ASSC[0]),\n                                        \"Companies & Other\",tax_2013[\"Category\"])\n    return tax_2013\ntax_payer_category_2(tax_2016)","2f6b09ad":"comp_2017_index_2_ends = 145024\ncomp_2017_index_2_start = 97618\ncomp_2017_index_1_end = 55856\nindividual_index_start = 55857\nindividual_index_end =  97619\ntax_2017[\"Category\"] = np.where(tax_2017.index <= comp_2017_index_1_end,\"Companies & Other\",\"\")\ntax_2017[\"Category\"] = np.where(\n    (tax_2017.index>=individual_index_start ) & (tax_2017.index <= individual_index_end),\n    \"Individual\",tax_2017[\"Category\"])\ntax_2017[\"Category\"] = np.where(\n    (tax_2017.index>=comp_2017_index_2_start ) & (tax_2017.index <= comp_2017_index_2_ends),\n    \"Companies & Other\",tax_2017[\"Category\"])\ntax_2017[\"Category\"] = np.where(tax_2017.index >= comp_2017_index_2_ends,\"Individual\",tax_2017[\"Category\"]) ","5a1b8afd":"compan_2018_index_end =  108950\ntax_2018[\"Category\"] = np.where(tax_2018.index <= compan_2018_index_end,\"Companies & Other\",\"Individual\")","66de4cab":"for i,df in enumerate(data):\n    df[\"year\"] = 2013 + i","ab34c868":"for df in data:\n    df.drop(index=df[df[\"tax_paid\"]==\"Tax Paid\"].index,inplace=True,axis=0)\n    df.drop(index=df[df[\"tax_payer\"]==\"INDIVIDUAL\"].index,inplace=True,axis=0)","f13e53fd":"pktax = pd.concat(data,keys=[2013,2014,2015,2016,2017,2018])\ndel pktax[\"tax_paid\"]\nprint(f\"Missing values % in concated dataset :{(pktax.isna().sum()\/len(pktax)*100)}\")","9586dac0":"\nyear_coll = pktax.groupby(\"year\").paid.sum().reset_index()\nyear_coll[\"cumsum\"] = year_coll.paid.cumsum()\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=year_coll[\"year\"], y=year_coll[\"paid\"], fill='tozeroy',\n                         name=\"Annual Tax Collection\"))\nfig.add_trace(\n    go.Scatter(x=year_coll[\"year\"], y=year_coll[\"cumsum\"],fill='tonexty', name=\"Cumsum Tax Collection\")\n)\nfig.update_layout(title_text=\"Year wise Tax Collection vs Cumsum Tax Collection\")","4fa5b640":"catwise = pktax.groupby([\"Category\",\"year\"]).sum().reset_index()\nfig1=px.bar(catwise,x=\"year\",y=\"paid\",color=\"Category\",template=\"seaborn\", height=350,width=700,\n           title=\"Year wise Tax Collection per Category \")\nfig1.add_trace(go.Scatter(x=year_coll[\"year\"], y=year_coll[\"paid\"],name=\"Annual Tax\"))","4a64f402":"province = {1 : \"Khyber Pakhtunkhwa\",2 : \"FATA\", 3 : \"Punjab\", 4 : \"Sindh\",5 : #keys are CNIC first digit as a province identifier\n            \"Balochistan\", 6 : \"Islamabad\", 7 : \"Gilgit-Baltistan\",8:\"Azad Kashmir\"}\ndef cnic_to_province(id):\n    id = str(id)\n    if len(id) >= 13:\n        if id.startswith(\"1\") :\n            id=province[1]\n        elif id.startswith(\"2\") :\n            id=province[2]\n        elif id.startswith(\"3\") :\n            id=province[3]  \n        elif id.startswith(\"4\") :\n            id=province[4]\n        elif id.startswith(\"5\") :\n            id=province[5]\n        elif id.startswith(\"6\") :\n            id=province[6]\n        elif id.startswith(\"7\") :\n            id=province[7]\n        elif id.startswith(\"8\") :\n            id=province[8]\n        else:\n            id=\"Misc\"\n    else:\n        id=\"NTN\"\n    return id","5b2cd56d":"tax_18to17 = pktax.loc[2017:2018]\nindividual_only = tax_18to17.loc[:,\"Category\"]==\"Individual\"\ntax_frm_indv = tax_18to17.iloc[:][individual_only]\ntax_frm_indv[\"province\"] = tax_frm_indv.ntn.apply(cnic_to_province)\n# filtering Taxpayer with CNIC only to extract regional information from CNIC\ntax_frm_indv = tax_frm_indv[tax_frm_indv.loc[:,\"province\"]!=\"NTN\"] ","6466492f":"province_wise = tax_frm_indv.groupby([\"province\",\"year\"]).paid.sum().reset_index().sort_values(by=\"paid\",\n    ascending=False)\nfig = px.bar(province_wise,x=\"province\",y=\"paid\",color=\"year\",text=\"paid\",title=\"Province wise Tax (2017-18)\",height=600,width=700,)\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","cf629262":"px.pie(province_wise,names=\"province\",values=\"paid\",title=\"Provincial Share in Tax collection 2017-18\",height=500,width=700)","ebc6de38":"pak_divs = pd.read_csv(r\"..\/input\/pak-cities-lat\/Pakdivisions.csv\")\npak_divs.drop(pak_divs.columns[5:],axis=1,inplace=True) \npak_divs.head()","2d8f6279":"city_dict = dict(pak_divs.set_index(\"cnic_identifier\").Divisions) \ndef cities_extractor(cnic):\n    if len(str(cnic))>=12:\n        for city_id in city_dict.keys():\n            if str(cnic).startswith(str(city_id)):\n                cnic = city_dict[city_id]\n    else:\n        cnic=\"NTN\"\n    return cnic","77abca67":"tax_frm_indv[\"divisions\"] = tax_frm_indv.ntn.apply(cities_extractor)","bb3d4d56":"divisions_wise = tax_frm_indv.groupby([\"divisions\",\"year\"]).paid.sum()\ndivs_wise = divisions_wise.reset_index()[3:]\ntop_ten_city = divs_wise.nlargest(20,\"paid\") ","d364885d":"fig=px.bar(top_ten_city,x=\"divisions\",y=\"paid\",text=\"paid\",color=\"year\")\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","dfa3e089":"top_divs = divisions_wise = tax_frm_indv.groupby([\"divisions\"]).paid.sum()[2:].reset_index()\ntop_divs['text'] = top_divs['divisions']  + \"  Tax Totals :  \" + top_divs['paid'].astype(str)\ntop_divs = pak_divs.merge(top_divs,right_on=\"divisions\",left_on=\"Divisions\")\ntop_divs = top_divs.sort_values(by=\"paid\",ascending=False).reset_index()","124a75c5":"colors = [\"#850707\",\"#556287\",\"#32f0a4\",\"#525004\"] # color for each rank\nranks = [(0,3),(3,9),(9,19),(19,38)] # 38 is max range as there are 38 cities in data\nscale = 1.0e+08\ngeo_plot = go.Figure()\nfor i in range(len(ranks)):\n    rnk = ranks[i]\n    top_divs_rank = top_divs[rnk[0]:rnk[1]]\n    geo_plot.add_trace(go.Scattergeo(\n        lon = top_divs_rank['lng'],\n        lat = top_divs_rank['lat'],\n        text = top_divs_rank['text'],\n        marker = dict(\n            size = top_divs_rank['paid']\/scale,\n            color = colors[i],\n            line_color='rgb(40,40,40)',\n            line_width=0.5,\n            sizemode = 'area'),\n        name = f'Division Ranking  {rnk[0]+1} - {rnk[1]}')) # + 1: both inclusive e.g.,(1-2)\ngeo_plot.update_layout(\n        title = \"Division wise Aggretated Tax Collection (Individuals only 2017 - 2018)\",\n        showlegend = True,\n        legend_title=\"Tax Collection\",\n        legend_title_font_size=14,\n        geo = dict(\n            scope = 'asia',\n            landcolor = '#d9e5ff',\n            lonaxis = dict(range = [60.578993, 82.65129]), # setting map display boundries using lat \n            lataxis = dict(range = [24.407138, 36.885931]))) # and long.\ngeo_plot.show()","fa370e93":"# Creating Categories of Taxpayers based on Indices or Positions","dc7754f4":"# Growth Analysis","563dcaa8":"#  To Be Continue!.....Its mighthy dataset of 8 Million records so errors and omissions are expected ","f92d7cf8":"# Getting CSVs files ready ","4ee32f40":"# Combining Dataset 2013-2018","498b0c2a":"# Typecasting Dataframes columns particularly \"Tax Paid\" to float ","82f8e763":"# Geographical maping of Tax collection","e7f73860":"# Year Feature","910d24c2":"### As per Geo analysis Lahore and Karachi are Top Contributor ","cc3c3d6a":"# Importing Libraries","d63679a4":"# Loading Pakistan Largest Tax 8M Records mighty\ud83d\ude0e Dataset","57326953":"# Deleting Duplicate Headers","365099df":"# Geographical Analysis","5fcce21d":"# Lets uncover Missing values first","2b033187":"# Division wise Analysis"}}