{"cell_type":{"d4b172ab":"code","df63ed43":"code","25744578":"code","fe5a1b29":"code","46392d67":"code","ec5830d8":"code","a933a89f":"code","69442ace":"code","06e06372":"code","38f3c585":"code","9c09c986":"code","556d5808":"code","01408f28":"code","1a79ba47":"code","df7bd3d5":"code","dd942bab":"code","b35fabe2":"code","7cd8b769":"code","d26eff49":"code","df2ba584":"code","e223752b":"code","e85622c8":"code","a96bafc4":"code","66643423":"code","574322cd":"code","d8d20282":"code","e149a652":"code","ca6d9d1d":"code","8f4ab048":"code","93b2a81d":"code","8cfce9dc":"code","14d80301":"code","53ba4312":"code","ff33e244":"code","bb6fdf38":"code","52448856":"code","635c8130":"code","43ced034":"code","bb3b266e":"code","69261e5c":"code","b0c0b922":"code","a043137c":"code","ebec1323":"code","f2d83a15":"code","55f17a7e":"code","014cffae":"code","3d8667f8":"code","6c795cc3":"code","522d1088":"code","409715f8":"code","03a70566":"code","d714a608":"code","5814ea0d":"code","f9e098a9":"code","4b232186":"code","432ab68b":"code","ec0ded78":"code","96ae42c0":"code","935ba00b":"code","52c708e5":"code","2d14dfa5":"code","f950c07f":"code","cd083d2a":"code","ae8a9eb9":"code","2360e003":"code","dc671381":"code","a615c52e":"code","5f1b6cc3":"code","f31aaa53":"code","148583a7":"code","27cd8a14":"code","31bb07ac":"code","f979a482":"code","9f5ed018":"code","8b2babb3":"code","4dc46f1f":"code","56d649a8":"code","b1440cb8":"code","9844e551":"code","c78b3d84":"code","9c5a6a64":"markdown","32ae4f36":"markdown","025e6e25":"markdown","5bc6f661":"markdown","11fdd815":"markdown","acfbcaa7":"markdown","2cd195a2":"markdown","0c8fee86":"markdown","a0e53cc7":"markdown","bb6a377c":"markdown","325b5ac9":"markdown","0606b671":"markdown","d564fec5":"markdown","2393cea6":"markdown","791ffcf5":"markdown","42578d8c":"markdown","e0c399cf":"markdown","473d50f5":"markdown","66a5987f":"markdown","e61cd5e1":"markdown","92f42ab2":"markdown","eacded5e":"markdown","5c027a4e":"markdown","35c62ad8":"markdown","940f1a3b":"markdown","9d61136e":"markdown","c2ddc8c6":"markdown","6b0eb607":"markdown","540d7a45":"markdown","ca875f9c":"markdown","04960033":"markdown","1deb6ab4":"markdown","6a1a8afc":"markdown"},"source":{"d4b172ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n# linear algebra\nimport numpy as np\n# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\n#plt.style.use(\"seaborn-whitegrid\")\nimport matplotlib.pyplot as plt\n# data visualization\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\n# Algorithms\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport warnings                                            # Ignore warning related to pandas_profiling\nwarnings.filterwarnings('ignore') \n\ndef annot_plot(ax,w,h):                                    # function to add data to plot\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    for p in ax.patches:\n         ax.annotate(f\"{p.get_height() * 100 \/ df_watson.shape[0]:.2f}%\", (p.get_x() + p.get_width() \/ 2., p.get_height()),\n         ha='center', va='center', fontsize=11, color='black', rotation=0, xytext=(0, 10),\n         textcoords='offset points')             \ndef annot_plot_num(ax,w,h):                                    # function to add data to plot\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    for p in ax.patches:\n        ax.annotate('{0:.1f}'.format(p.get_height()), (p.get_x()+w, p.get_height()+h))","df63ed43":"plt.style.available","25744578":"df_watson = pd.read_csv(\"\/kaggle\/input\/ibm-watson-marketing-customer-value-data\/WA_Fn-UseC_-Marketing-Customer-Value-Analysis.csv\")","fe5a1b29":"df1=df_watson[\"Customer\"]","46392d67":"df_watson.info","ec5830d8":"df_watson.columns","a933a89f":"df_watson.head()","69442ace":"df_watson.describe()","06e06372":"df_watson.shape","38f3c585":"df_watson.Response = df_watson.Response.apply(lambda X : 0 if X == 'No' else 1)","9c09c986":"df_watson.head()","556d5808":"total = df_watson.isnull().sum().sort_values(ascending=False)\npercent_1 = df_watson.isnull().sum()\/df_watson.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\nmissing_data.head(24)","01408f28":"df_watson.info()","1a79ba47":"def bar_plot(variable):\n    \"\"\"\n        input: variable ex:\"Gender\"\n        output: bar plot & value count\n    \"\"\"\n    #get feature\n    var = df_watson[variable]\n    #count number of categorical variable (value\/sample)\n    varValue=var.value_counts()\n    \n    #visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable, varValue))","df7bd3d5":"category1=[\"State\", \"Response\", \"Coverage\", \"Education\", \"EmploymentStatus\", \"Gender\", \"Location Code\", \"Marital Status\", \"Policy Type\", \"Renew Offer Type\", \"Sales Channel\", \"Vehicle Size\"]\nfor c in category1:\n    bar_plot(c)","dd942bab":"category2 = [\"Effective To Date\",\"Policy\",\"Vehicle Class\"]\nfor c in category2:\n    print(\"{} \\n\".format(df_watson[c].value_counts()))","b35fabe2":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(df_watson[variable], bins=50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","7cd8b769":"numericVar=[\"Customer\", \"Customer Lifetime Value\", \"Income\", \"Monthly Premium Auto\", \"Months Since Last Claim\", \"Months Since Policy Inception\", \"Number of Open Complaints\", \"Number of Policies\", \"Total Claim Amount\"]\nfor n in numericVar:\n    plot_hist(n)","d26eff49":"ax = sns.countplot('Response',data = df_watson)\nplt.ylabel('Total number of Response')\nannot_plot(ax, 0.08,1)\nplt.show()","df2ba584":"#Average response of Male and Female\n# Gender vs Response\ndf_watson[[\"Gender\", \"Response\"]].groupby([\"Gender\"], as_index = False).mean().sort_values(by=\"Response\", ascending=False)","e223752b":"def plot_hist(var):\n    ax = sns.countplot('Response', hue = var, data = df_watson)\n    plt.ylabel('Total number of Response')\n    annot_plot(ax,0.08,1)\n    plt.show()\n\ncategory1=[\"State\", \"Response\", \"Coverage\", \"Education\", \"EmploymentStatus\", \"Gender\", \"Location Code\", \"Marital Status\", \"Policy Type\", \"Renew Offer Type\", \"Sales Channel\", \"Vehicle Size\"]\n\nfor n in category1:\n    plot_hist(n)","e85622c8":"g = sns.FacetGrid(df_watson, col = \"Response\")\ng.map(sns.distplot, \"Total Claim Amount\", bins = 25)\nplt.show()","a96bafc4":"g = sns.FacetGrid(df_watson, col = \"Response\")\ng.map(sns.distplot, \"Customer Lifetime Value\", bins = 25)\nplt.show()","66643423":"g = sns.FacetGrid(df_watson, col = \"Response\")\ng.map(sns.distplot, \"Income\", bins = 25)\nplt.show()","574322cd":"# Marital Status vs Response\ndf_watson[[\"Marital Status\", \"Response\"]].groupby([\"Marital Status\"], as_index = False).mean().sort_values(by=\"Response\", ascending=False)","d8d20282":"# Renew Offer Type vs Response\ndf_watson[[\"Renew Offer Type\", \"Response\"]].groupby([\"Renew Offer Type\"], as_index = False).mean().sort_values(by=\"Response\", ascending=False)","e149a652":"# Education vs Response\ndf_watson[[\"Education\", \"Response\"]].groupby([\"Education\"], as_index = False).mean().sort_values(by=\"Response\", ascending=False)","ca6d9d1d":"# Sales Channel vs Response\ndf_watson[[\"Sales Channel\", \"Response\"]].groupby([\"Sales Channel\"], as_index = False).mean().sort_values(by=\"Response\", ascending=False)","8f4ab048":"plt.figure(figsize=(12,6))\nsns.boxplot(y = 'Total Claim Amount' , x = 'Response', data = df_watson)\nplt.ylabel('Total number of Response')\nplt.show()","93b2a81d":"plt.figure(figsize=(12,6))\nsns.boxplot(y = 'Income' , x = 'Response', data = df_watson)\nplt.show()","8cfce9dc":"# EmploymentStatus vs Response\ndf_watson[[\"EmploymentStatus\", \"Response\"]].groupby([\"EmploymentStatus\"], as_index = False).mean().sort_values(by=\"Response\", ascending=False)","14d80301":"plt.figure(figsize=(10,6))\nax = sns.countplot('Response',hue = 'EmploymentStatus' ,data = df_watson)\nplt.ylabel('Total number of Response')\nannot_plot(ax, 0.08,1)\nplt.show()","53ba4312":"# Vehicle Class of Response vs Response\ndf_watson[[\"Vehicle Class\", \"Response\"]].groupby([\"Vehicle Class\"], as_index = False).mean().sort_values(by=\"Response\", ascending=False)","ff33e244":"plt.figure(figsize=(10,6))\nax = sns.countplot('Response',hue = 'Vehicle Class' ,data = df_watson)\nplt.ylabel('Total number of Response')\nannot_plot(ax, 0.08,1)\nplt.show()","bb6fdf38":"# Policy vs Response\ndf_watson[[\"Policy\", \"Response\"]].groupby([\"Policy\"], as_index = False).mean().sort_values(by=\"Response\", ascending=False)","52448856":"plt.figure(figsize=(15,6))\nax = sns.countplot('Response',hue = 'Policy' ,data = df_watson)\nplt.ylabel('Total number of Response')\nannot_plot(ax, 0.08,1)\nplt.show()","635c8130":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        #1st quartile\n        Q1 = np.percentile(df[c],25)\n        #3rd quartile\n        Q3 = np.percentile(df[c],75)\n        #IQR\n        IQR = Q3 - Q1\n        #Outlier step\n        outlier_step = IQR * 1.5\n        #detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        #store indeces\n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","43ced034":"df_watson.loc[detect_outliers(df_watson,[\"Total Claim Amount\",\"Income\"])]\n","bb3b266e":"df_watson = df_watson.drop(['Customer','Effective To Date','Gender','Policy','Vehicle Class'], axis = 1)\n","69261e5c":"df_watson[\"State\"] = [0 if i == \"California\" else 1 if i == \"Oregon\"\n                     else 2 if i == \"Arizona\" else 3 if i == \"Nevada\" else 4 for i in df_watson[\"State\"]]","b0c0b922":"sns.countplot(x= \"State\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()","a043137c":"g=sns.factorplot(x=\"State\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"California\", \"Oregon\",\"Arizona\",\"Nevada\",\"Washington\"])\ng.set_ylabels(\"State Response Rate\")\nplt.show()","ebec1323":"df_watson = pd.get_dummies(df_watson,columns = [\"State\"])\ndf_watson.head()","f2d83a15":"df_watson[\"Coverage\"] = [0 if i == \"Basic\" else 1 if i == \"Extended\"\n                      else 2 for i in df_watson[\"Coverage\"]]\n\nsns.countplot(x= \"Coverage\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()\n\ng=sns.factorplot(x=\"Coverage\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"Basic\", \"Extended\",\"Premium\"])\ng.set_ylabels(\"Coverage Response Rate\")\nplt.show()\n\ndf_watson = pd.get_dummies(df_watson,columns = [\"Coverage\"])\ndf_watson.head()","55f17a7e":"df_watson[\"Education\"] = [0 if i == \"Bachelor\" else 1 if i == \"College\"\n                      else 2 if i == \"High School or Below\" else 3 if i == \"Master\" else 4 for i in df_watson[\"Education\"]]\n\nsns.countplot(x= \"Education\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()\n\ng=sns.factorplot(x=\"Education\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"Bachelor\", \"College\",\"High School or Below\", \"Master\", \"Doctor\"])\ng.set_ylabels(\"Education Response Rate\")\nplt.show()\n\ndf_watson = pd.get_dummies(df_watson,columns = [\"Education\"])\ndf_watson.head()","014cffae":"df_watson[\"EmploymentStatus\"] = [0 if i == \"Employed\" else 1 if i == \"Unemployed\"\n                      else 2 if i == \"Medical Leave\" else 3 if i == \"Disabled\" else 4 for i in df_watson[\"EmploymentStatus\"]]\n\nsns.countplot(x= \"EmploymentStatus\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()\n\ng=sns.factorplot(x=\"EmploymentStatus\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"Employed\", \"Unemployed\",\"Medical Leave\", \"Disabled\", \"Retired\"])\ng.set_ylabels(\"EmploymentStatus Response Rate\")\nplt.show()\n\ndf_watson = pd.get_dummies(df_watson,columns = [\"EmploymentStatus\"])\ndf_watson.head()","3d8667f8":"df_watson[\"Location Code\"] = [0 if i == \"Suburban\" else 1 if i == \"Rural\"\n                      else 2 for i in df_watson[\"Location Code\"]]\n\nsns.countplot(x= \"Location Code\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()\n\ng=sns.factorplot(x=\"Location Code\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"Suburban\", \"Rural\",\"Urban\"])\ng.set_ylabels(\"Location Code Response Rate\")\nplt.show()\n\ndf_watson = pd.get_dummies(df_watson,columns = [\"Location Code\"])\ndf_watson.head()","6c795cc3":"df_watson[\"Marital Status\"] = [0 if i == \"Married\" else 1 if i == \"Single\"\n                      else 2 for i in df_watson[\"Marital Status\"]]\n\nsns.countplot(x= \"Marital Status\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()\n\ng=sns.factorplot(x=\"Marital Status\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"Married\", \"Single\",\"Divorced\"])\ng.set_ylabels(\"Marital Status Response Rate\")\nplt.show()\n\ndf_watson = pd.get_dummies(df_watson,columns = [\"Marital Status\"])\ndf_watson.head()","522d1088":"df_watson[\"Policy Type\"] = [0 if i == \"Personal Auto\" else 1 if i == \"Corporate Auto\"\n                      else 2 for i in df_watson[\"Policy Type\"]]\n\nsns.countplot(x= \"Policy Type\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()\n\ng=sns.factorplot(x=\"Policy Type\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"Personal Auto\", \"Corporate Auto\",\"Special Auto\"])\ng.set_ylabels(\"Policy Type Response Rate\")\nplt.show()\n\ndf_watson = pd.get_dummies(df_watson,columns = [\"Policy Type\"])\ndf_watson.head()","409715f8":"df_watson[\"Renew Offer Type\"] = [0 if i == \"Offer1\" else 1 if i == \"Offer2\"\n                      else 2 if i == \"Offer3\" else 3 for i in df_watson[\"Renew Offer Type\"]]\n\nsns.countplot(x= \"Renew Offer Type\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()\n\ng=sns.factorplot(x=\"Renew Offer Type\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"Offer1\", \"Offer2\",\"Offer3\", \"Offer3\"])\ng.set_ylabels(\"Renew Offer Type Response Rate\")\nplt.show()\n\ndf_watson = pd.get_dummies(df_watson,columns = [\"Renew Offer Type\"])\ndf_watson.head()","03a70566":"df_watson[\"Sales Channel\"] = [0 if i == \"Agent\" else 1 if i == \"Branch\"\n                      else 2 if i == \"Call Center\" else 3 for i in df_watson[\"Sales Channel\"]]\n\nsns.countplot(x= \"Sales Channel\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()\n\ng=sns.factorplot(x=\"Sales Channel\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"Agent\", \"Branch\",\"Call Center\", \"Web\"])\ng.set_ylabels(\"Sales Channel Type Response Rate\")\nplt.show()\n\ndf_watson = pd.get_dummies(df_watson,columns = [\"Sales Channel\"])\ndf_watson.head()","d714a608":"df_watson[\"Vehicle Size\"] = [0 if i == \"Medsize\" else 1 if i == \"Small\"\n                      else 2 for i in df_watson[\"Vehicle Size\"]]\n\nsns.countplot(x= \"Vehicle Size\",data = df_watson)\nplt.xticks(rotation = 60)\nplt.show()\n\ng=sns.factorplot(x=\"Vehicle Size\", y=\"Response\", data=df_watson, kind=\"bar\")\ng.set_xticklabels([\"Medsize\", \"Small\",\"Large\"])\ng.set_ylabels(\"Vehicle Size Response Rate\")\nplt.show()\n\ndf_watson = pd.get_dummies(df_watson,columns = [\"Vehicle Size\"])\ndf_watson.head()","5814ea0d":"df_watson.info","f9e098a9":"df_watson.head()","4b232186":"list1 = [\"State_0\",\"State_1\",\"State_2\",\"State_3\",\"State_4\",\"Customer Lifetime Value\",\"Response\",\"Coverage_0\",\"Coverage_1\",\"Coverage_2\",\n       \"Education_0\",\"Education_1\",\"Education_2\",\"Education_3\",\"Education_4\",\"EmploymentStatus_0\",\"EmploymentStatus_1\",\"EmploymentStatus_2\",\"EmploymentStatus_3\",\"EmploymentStatus_4\",\"Income\",\n       \"Location Code_0\",\"Location Code_1\",\"Location Code_2\",\"Marital Status_0\",\"Marital Status_1\",\"Marital Status_2\",\"Monthly Premium Auto\",\n       \"Months Since Last Claim\", \"Months Since Policy Inception\",\n       \"Number of Open Complaints\", \"Number of Policies\", \"Policy Type_0\",\"Policy Type_1\", \"Policy Type_2\",\n       \"Renew Offer Type_0\",\"Renew Offer Type_1\",\"Renew Offer Type_2\",\"Renew Offer Type_3\",\"Sales Channel_0\",\"Sales Channel_1\",\"Sales Channel_2\",\"Sales Channel_3\",\"Total Claim Amount\",\"Vehicle Size_0\",\"Vehicle Size_1\",\"Vehicle Size_2\"]\nsns.heatmap(df_watson[list1].corr(),annot = True, fmt= \".2f\")\nplt.show()","432ab68b":"g = sns.FacetGrid(df_watson, col = \"Response\", row = \"Number of Open Complaints\", size = 3)\ng.map(plt.hist, \"Number of Policies\", bins = 25)\ng.add_legend()\nplt.show()","ec0ded78":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","96ae42c0":"import numpy as np\nfrom sklearn.model_selection import train_test_split","935ba00b":"#In order not to lose size\ntrain_df_len=len(df_watson)","52c708e5":"df_watson.head()","2d14dfa5":"test = df_watson[:train_df_len]\n#There won't be Response column in the test.\ntest.drop(labels = [\"Response\"],axis = 1, inplace = True)\ntest.head(10)","f950c07f":"train = df_watson[:train_df_len]\nX_train = train.drop(labels = \"Response\", axis = 1)\ny_train = train[\"Response\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","cd083d2a":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2)\nacc_log_test = round(logreg.score(X_test, y_test)*100,2)\nprint(\"Training Accuracy:%{}\".format(acc_log_train))\nprint(\"Testing Accuracy:%{}\".format(acc_log_test))","ae8a9eb9":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier()\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n","2360e003":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","dc671381":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], \n                       cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","a615c52e":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result,\n                           \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","5f1b6cc3":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\n#According to my votingC classifier, I predict X_test and then compare y_test to accuracy skore.\nprint(accuracy_score(votingC.predict(X_test),y_test))","f31aaa53":"test_response = pd.Series(votingC.predict(test), name = \"Response\").astype(int)\nresults = pd.concat([df1, test_response],axis = 1)\nresults.to_csv(\"watson.csv\", index = False)","148583a7":"test_response","27cd8a14":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\npredictions = cross_val_predict(votingC, X_train, y_train, cv=3)\nconfusion_matrix(y_train, predictions)","31bb07ac":"from sklearn.metrics import precision_score, recall_score\n\nprint(\"Precision:\", precision_score(y_train, predictions))\nprint(\"Recall:\",recall_score(y_train, predictions))","f979a482":"from sklearn.metrics import f1_score\nf1_score(y_train, predictions)","9f5ed018":"from sklearn.metrics import precision_recall_curve\n\n# getting the probabilities of our predictions\ny_scores = votingC.predict_proba(X_train)\ny_scores = y_scores[:,1]\n\nprecision, recall, threshold = precision_recall_curve(y_train, y_scores)\ndef plot_precision_and_recall(precision, recall, threshold):\n    plt.plot(threshold, precision[:-1], \"r-\", label=\"precision\", linewidth=5)\n    plt.plot(threshold, recall[:-1], \"b\", label=\"recall\", linewidth=5)\n    plt.xlabel(\"threshold\", fontsize=19)\n    plt.legend(loc=\"upper right\", fontsize=19)\n    plt.ylim([0, 1])\n\nplt.figure(figsize=(14, 7))\nplot_precision_and_recall(precision, recall, threshold)\nplt.show()","8b2babb3":"def plot_precision_vs_recall(precision, recall):\n    plt.plot(recall, precision, \"g--\", linewidth=2.5)\n    plt.ylabel(\"recall\", fontsize=19)\n    plt.xlabel(\"precision\", fontsize=19)\n    plt.axis([0, 1.5, 0, 1.5])\n\nplt.figure(figsize=(14, 7))\nplot_precision_vs_recall(precision, recall)\nplt.show()","4dc46f1f":"from sklearn.metrics import roc_curve\n# compute true positive rate and false positive rate\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, y_scores)\n# plotting them against each other\ndef plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n\nplt.figure(figsize=(14, 7))\nplot_roc_curve(false_positive_rate, true_positive_rate)\nplt.show()\n","56d649a8":"from sklearn.metrics import roc_auc_score\nr_a_score = roc_auc_score(y_train, y_scores)\nprint(\"ROC-AUC-Score:\", r_a_score)","b1440cb8":"from sklearn.linear_model import LinearRegression\nlinear_reg=LinearRegression()\nlinear_reg.fit(X_train, y_train)\ny_pred = linear_reg.predict(X_test)\nprint('Intercept: \\n', linear_reg.intercept_)\nprint('Coefficients: \\n', linear_reg.coef_)","9844e551":"import numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom distutils.version import LooseVersion","c78b3d84":"from sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.metrics import median_absolute_error, r2_score\n# `normed` is being deprecated in favor of `density` in histograms\nif LooseVersion(matplotlib.__version__) >= '2.1':\n    density_param = {'density': True}\nelse:\n    density_param = {'normed': True}\nX, y = make_regression(n_samples=10000, noise=100, random_state=0)\ny = np.exp((y + abs(y.min())) \/ 200)\ny_trans = np.log1p(y)\n\nf, (ax0, ax1) = plt.subplots(1, 2)\n\nax0.hist(y, bins=100, **density_param)\nax0.set_xlim([0, 2000])\nax0.set_ylabel('Probability')\nax0.set_xlabel('Response')\nax0.set_title('Response distribution')\n\nax1.hist(y_trans, bins=100, **density_param)\nax1.set_ylabel('Probability')\nax1.set_xlabel('Response')\nax1.set_title('Response target distribution')\n\nf.suptitle(\"Watson data\", y=0.035)\nf.tight_layout(rect=[0.05, 0.05, 0.95, 0.95])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\nf, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n\nregr = RidgeCV()\nregr.fit(X_train, y_train)\ny_pred = regr.predict(X_test)\n\nax0.scatter(y_test, y_pred)\nax0.plot([0, 2000], [0, 2000], '--k')\nax0.set_ylabel('Response predicted')\nax0.set_xlabel('True Response')\nax0.set_title('Ridge regression \\n without response transformation')\nax0.text(100, 1750, r'$R^2$=%.2f, MAE=%.2f' % (\n    r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)))\nax0.set_xlim([0, 2000])\nax0.set_ylim([0, 2000])\n\nregr_trans = TransformedTargetRegressor(regressor=RidgeCV(),\n                                        func=np.log1p,\n                                        inverse_func=np.expm1)\nregr_trans.fit(X_train, y_train)\ny_pred = regr_trans.predict(X_test)\n\nax1.scatter(y_test, y_pred)\nax1.plot([0, 2000], [0, 2000], '--k')\nax1.set_ylabel('Response predicted')\nax1.set_xlabel('True Response')\nax1.set_title('Ridge regression \\n with response transformation')\nax1.text(100, 1750, r'$R^2$=%.2f, MAE=%.2f' % (\n    r2_score(y_test, y_pred), median_absolute_error(y_test, y_pred)))\nax1.set_xlim([0, 2000])\nax1.set_ylim([0, 2000])\n\nf.suptitle(\"Watson data\", y=0.035)\nf.tight_layout(rect=[0.05, 0.05, 0.95, 0.95])","9c5a6a64":"# i) Response rate by Policy","32ae4f36":"<a id = \"7\"><\/a><br>\n# Outlier Detection","025e6e25":"# h) Response rate by Vehicle Class","5bc6f661":"# e) Response rate by Total Claim Amount","11fdd815":"# Introduction\n\nContext\nUsing Watson Analytics, you can predict behavior to retain your customers. You can analyze all relevant customer data and develop focused customer retention programs.\n\nInspiration\nUnderstand customer demographics and buying behavior. Use predictive analytics to analyze the most profitable customers and how they interact. Take targeted actions to increase profitable customer response, retention, and growth.\n\n<font color = 'blue' >\nContent:\n\n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n    * [Univariate Variable Analysis](#3)\n        * [Categorical Variable Analysis](#4)\n        * [Numerical Variable Analysis](#5)\n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Modeling](#29)\n     * [train_test_split](#30)\n     * [Simple Logistic Regression](#31)\n     * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n     * [Ensemble Modeling](#33)\n     * [Prediction and Submission](#34)","acfbcaa7":"<a id = \"6\"><\/a><br>\n# 3. Basic Data Analysis","2cd195a2":"# d) Response rate by Sales Channel","0c8fee86":"# b) Response rate by renew offer","a0e53cc7":"# f) Response rate by Income Distributions","bb6a377c":"# a) Response Rate:","325b5ac9":"# Hyperparameter Tuning -- Grid Search -- Cross Validation\nWe will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","0606b671":"<a id=\"2\"><\/a>\n# 2. Variable Description\n\n1. Customer\n2. State\n3. Customer Lifetime Value: In marketing, customer lifetime value (CLV) is a metric that represents the total net profit a company makes from any given customer. CLV is a projection to estimate a customer's monetary worth to a business after factoring in the value of the relationship with a customer over time. The most basic way to determine CLV is to add up the revenue earned from a customer (annual revenue multiplied by the average customer lifespan) minus the initial cost of acquiring them.\n4. Response: YES\/NO\n5. Coverage: Basic, Extended, Premium\n6. Education : Education level refers to the years of formal instruction received and successfully completed, usually based on passing formal exams.\n7. Effective To Date\n8. EmploymentStatus :Employment status is the status of a worker in a company on the basis of the contract of work or duration of work done.\n9. Gender\n10. Income\n11. Location Code: Urban, Suburban, Rural\n12. Marital Status: Single, Married, Divorced\n13. Monthly Premium Auto\n14. Months Since Last Claim: Son Talepten Bu Yana Aylar\n15. Months Since Policy Inception: Politika ba\u015flang\u0131c\u0131ndan bu yana ge\u00e7en aylar\n16. Number of Open Complaints: A\u00e7\u0131k \u015eikayet Say\u0131s\u0131\n17. Number of Policies\n18. Policy Type\n19. Policy\n20. Renew Offer Type\n21. Sales Channel\n22. Total Claim Amount: Toplam Talep Tutar\u0131\n23. Vehicle Class\n24. Vehicle Size","d564fec5":"* Customer Lifetime Value is concentrated between 2000 and 10000\n* Monthly Premium Auto is between 60 and 140 intense\n* Number of Open Complaints is largely 0\n* Total Claim Amount ranges from 0 to 1000","2393cea6":"Notice that out of 14% customers, 8% customers those who rsponded to marketing calls are from married category","791ffcf5":"# Decision Tree","42578d8c":"For Offer1 and Offer2 customers have responded to marketing calls,but for Offer3 and Offer4 almost nobody responded.","e0c399cf":"Notice that, ratio of male and female for responding to a marketing call is almost same.","473d50f5":"<a id=\"1\"><\/a>\n# 1. Load and Check Data","66a5987f":"# Simple Logistic Regression","e61cd5e1":" <a id=\"3\"><\/a>\n# Univariate Variable Analysis\n* **Categorical Variable:** State, Response, Coverage, Education, Effective To Date, EmploymentStatus, Gender, Location Code, Marital Status, Policy Type, Policy, Renew Offer Type, Sales Channel, Vehicle Class, Vehicle Size \n* **Numerical Variable:** Customer, Customer Lifetime Value, Income, Monthly Premium Auto, Months Since Last Claim, Months Since Policy Inception, Number of Open Complaints, Number of Policies, Total Claim Amount      ","92f42ab2":"# Linear Regression","eacded5e":"<a id = \"29\"><\/a><br>\n# Modeling","5c027a4e":"Notice that customers with Doctor and master degree are very less who responded to marketing calls, may be they are not intersted or busy. or we can say young people are most likely to respond to marketing calls.","35c62ad8":"Divorced people's YES rate of responce is higher.","940f1a3b":"Box plots are a great way to visualize the distribuation of countinous variables. They show the min, max, first quatile, meadian and third quartile, all in one view. The central rectangle spans from the first quartile to the third quartile, and the green line shows the median. The lower and upper ends show the minimum and the maximum of each distribution.\n\nThe dots above the upper boundry line show the suspected outliers that are decided based on the INterquartile range (IQR). The points that fall 1.5*IQR above the third quartile or 1.5*IQR below the quartile are suspected outliers and are drawn with the dots.","9d61136e":"# c) Response rate by Education","c2ddc8c6":"The response rates of men and women to marketing calls are almost equal.","6b0eb607":"We see that approximately 14.32% of customers respond to marketing calls and the remaining 85.68% do not.Those who answer no are in majority.","540d7a45":"# train_test_split","ca875f9c":"# g) Response rate by EmploymentStatus","04960033":"* California and Oregon contain more customers than other states\n* The overwhelming majority of the response is NO\n* More than half of the coverage is Basic\n* The number of customers with master and phd education is very few\n* Most customers are working\n* The number of men and women is almost equal\n* Those who order from the suburbans are more than others.\n* Almost half of the customers are married\n* The policy type is usually personal\n* Renew Offer Type number from large to small, respectively Offer1, Offer2, Offer3, Offer4\n* Renew the Sales Channel from large to small, respectively Agent, Branch, Call Center, Web\n* Vehicle Size is usually Medsize\n\n","1deb6ab4":"<a id=\"5\"><\/a>\n## Numerical Variable","6a1a8afc":"* float64(2):  Customer Lifetime Value, Total Claim Amount \n* int64(6): Income, Monthly Premium Auto, Months Since Last Claim, Months Since Policy Inception, Number of Open Complaints, Number of Policies     \n* object(16): Customer, State, Response, Coverage, Education, Effective To Date, EmploymentStatus, Gender, Location Code, Marital Status, Policy Type, Policy, Renew Offer Type, Sales Channel, Vehicle Class, Vehicle Size           "}}