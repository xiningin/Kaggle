{"cell_type":{"255763b1":"code","2ba21afd":"code","e97d6f33":"code","fbd0ad21":"code","34071369":"code","034f6178":"code","d6790e53":"code","c2e618c1":"code","824db592":"code","0b376a3e":"code","0da60983":"code","93b947a5":"code","94d4c9f0":"code","a3a48dea":"code","ab621052":"code","e04f9677":"code","fa972ae8":"code","4bbe7eab":"code","cc44ce6b":"code","5c18e963":"code","0d9cb0f1":"code","4de30fee":"code","0bcd6789":"code","8e47a087":"code","fe9f68cc":"code","947ac671":"code","053dd0dd":"code","a93326dc":"code","c4f9a40c":"code","94c18c60":"code","1586d928":"code","b74a12c0":"code","e6e522e3":"code","dc065889":"code","75be4c0c":"code","1333266a":"code","a8f500a4":"code","ea824e16":"code","d98a3bf6":"code","ca211f07":"code","771950ad":"code","1c96e51c":"code","8e4f9813":"code","72aec5d1":"code","703928f7":"code","b00b237e":"code","b043f6a4":"code","50dae907":"code","d1ad60a0":"code","77ff68b8":"code","037e1b37":"code","5ecc801f":"code","e373f585":"code","092c8e20":"code","be24d656":"code","c1194356":"code","d3006676":"code","570d7656":"code","25b57780":"code","c361d4f2":"code","efe2420e":"code","94e7b328":"code","ce24af92":"code","0dcbf16a":"code","cdb390b6":"code","98a0b5f3":"code","bff6cc4f":"code","081b0089":"code","b803d72b":"code","b475e8f3":"code","7c79abc9":"code","9500befd":"code","4aa0d758":"code","d6e1ac5e":"code","18ba2047":"code","32ebc672":"code","2fe88a17":"code","1da264a1":"code","91688ff5":"code","eace071b":"code","eef1056b":"code","f6152d79":"code","3d2c5592":"code","01942cce":"code","a3d49c29":"code","435bfd04":"code","c9b87240":"code","de5385a8":"code","6ed20056":"code","2a487ef7":"code","9818d989":"code","0c776877":"code","920f8294":"code","a5951d7f":"code","37c8d7f2":"code","427ff694":"code","fca96e5c":"code","3cb1f1ad":"code","aa54695d":"code","2cef5eba":"code","196c4248":"markdown","86fbb538":"markdown","dddb1303":"markdown","598e9f57":"markdown","e2c3454c":"markdown","1b3be7d9":"markdown","77adeefb":"markdown","5d85eb4a":"markdown","47971a77":"markdown","0b4650c9":"markdown","eb540de6":"markdown","61083e54":"markdown","58337abf":"markdown","127c9036":"markdown","334e8d39":"markdown","ea50b47b":"markdown","43863a0b":"markdown","b6add106":"markdown","92a04d17":"markdown","027c5047":"markdown","bf18683d":"markdown","22a63c64":"markdown","d758801a":"markdown","6ab5b496":"markdown","51f636f0":"markdown","83312c71":"markdown","ecaf9dce":"markdown","41c25bfb":"markdown","dc677ef4":"markdown","054ea208":"markdown"},"source":{"255763b1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2ba21afd":"sales_train = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nitems = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nitem_cats = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nshops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ntest = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\n","e97d6f33":"fig = plt.figure(figsize=(20,10)) # Establecer Tama\u00f1o\nplt.subplots_adjust(hspace= 0.5) # Ajusta la distancia de posici\u00f3n de la subimagen, hspace (espaciado vertical) = 0.4\n\n#Ver distribuci\u00f3n de shop_id\nplt.subplot2grid((1,1), (0,0))  \nsales_train['shop_id'].value_counts(normalize=True).plot(kind='bar', color='orangered') # Usar histograma\nplt.title('Estado de distribuci\u00f3n de la identificaci\u00f3n de la tienda (Figura 1)')\nplt.xlabel('ID de tienda')\nplt.ylabel('Apariciones normalizadas')\n\nplt.show()","fbd0ad21":"fig = plt.figure(figsize=(20,10)) # Establecer Tama\u00f1o\nplt.subplots_adjust(hspace= 0.5) # Ajusta la distancia de posici\u00f3n de la subimagen, hspace (espaciado vertical) = 0.4\n\n#Ver la distribuci\u00f3n de item_price\nplt.subplot2grid((1,1), (0,0))  \nsales_train['item_price'].plot(kind='hist', color='darkorange')  # Usar histograma\nplt.title('La distribuci\u00f3n de los precios de los productos (Figura 3)')\nplt.xlabel('precio del producto')\nplt.ylabel('El n\u00famero de ocurrencias')\nplt.show()","34071369":"fig = plt.figure(figsize=(20,10)) # Establecer Tama\u00f1o\nplt.subplots_adjust(hspace= 0.5) # Ajusta la distancia de posici\u00f3n de la subimagen, hspace (espaciado vertical) = 0.4\n\n#Ver la distribuci\u00f3n de item_cnt_day\nplt.subplot2grid((1,1), (0,0))  \nsales_train['item_cnt_day'].plot(kind='hist', color='cornflowerblue')  # Usar histograma\nplt.title('Estado de distribuci\u00f3n de las ventas de productos (Figura 4)')\nplt.xlabel('Venta de productos')\nplt.ylabel('El n\u00famero de ocurrencias')\nplt.show()","034f6178":"fig = plt.figure(figsize=(20,10)) # Establecer Tama\u00f1o\nplt.subplots_adjust(hspace= 0.5) # Ajusta la distancia de posici\u00f3n de la subimagen, hspace (espaciado vertical) = 0.4\n\n#Ver la distribuci\u00f3n de date_block_num\nplt.subplot2grid((1,1), (0,0))  \nsales_train['date_block_num'].value_counts(normalize=True).plot(kind='bar', color='darkseagreen') # Usar histograma\nplt.title('El n\u00famero de meses y el estado de distribuci\u00f3n de los registros de ventas (Figura 5)')\nplt.xlabel('N\u00famero de meses')\nplt.ylabel('N\u00famero de ocurrencias de registros de ventas estandarizados')\n\nplt.show()","d6790e53":"#Se revisan los precios de los cinco productos que mas tiene valor.\n\nsales_train['item_price'].sort_values(ascending=False)[:5]","c2e618c1":"#Se identifica el producto que mas se aporta al valor.\n\nsales_train[sales_train['item_price'] == 307980]","824db592":"#La informaci\u00f3n del producto 6066\n\nitems[items['item_id'] == 6066]","0b376a3e":"# Este producto es en espa\u00f1ol  \"Radmin 3 - 522 flash\" \n\n# Necesitamos verificar m\u00e1s a fondo si hay alg\u00fan registro de este producto en el conjunto de datos\n\nsales_train = sales_train[sales_train['item_price'] < 300000]","0da60983":"#Se revisan los productos de menor valor\n\nsales_train['item_price'].sort_values(ascending=True)[:5]","93b947a5":"#Hay un precio de venta negativo en el extremo muy peque\u00f1o, revisando en el conjunto de datos\n\nsales_train[sales_train['item_price'] == -1]","94d4c9f0":"#Ver la informaci\u00f3n correspondiente del producto\nsales_train[sales_train['item_id'] == 2973]","a3a48dea":"#Ver la informaci\u00f3n de precio correspondiente del producto\n\nprice_info = sales_train[sales_train['item_id'] == 2973]['item_price']\nprice_info.describe()","ab621052":"#Se puede ver que el precio de este producto no es razonable y el precio de venta promedio es superior a 2000, \n#por lo que otros valores deben eliminarse o completarse.\n\n#Teniendo en cuenta que el precio de venta del mismo producto en diferentes tiendas es diferente, \n#se debe utilizar en su lugar el precio medio del producto en la tienda N\u00b032 correspondiente.\n\nprice_median = sales_train[(sales_train['shop_id'] == 32) & (sales_train['item_id'] == 2973) & (sales_train['date_block_num'] == 4) & (sales_train['item_price'] > 0)].item_price.median()\nsales_train.loc[sales_train['item_price'] < 0, 'item_price'] = price_median","e04f9677":"#Ver la cantidad de ventas de los cinco productos principales\n\nsales_train['item_cnt_day'].sort_values(ascending=False)[:5]","fa972ae8":"#Se revisa la informaci\u00f3n de datos correspondiente al volumen m\u00e1ximo de ventas de 2169\n\nsales_train[sales_train['item_cnt_day'] == 2169]","4bbe7eab":"#En un d\u00eda de octubre, el producto No. 11373 se vendi\u00f3 2169 veces en la tienda n\u00famero 12.\n\n#Consulta la informaci\u00f3n correspondiente de este producto.\n\nitems[items['item_id'] == 11373]","cc44ce6b":"#Con la ayuda de la traducci\u00f3n, este es un tipo de bienes relacionados con la empresa de transporte rusa \"Boxberry\".\n\n#Continuar verificando las ventas de este producto en otras tiendas\n\nsales_train[sales_train['item_id'] == 11373]","5c18e963":"#La informaci\u00f3n del volumen de ventas correspondiente al producto\n\nsale_num = sales_train[sales_train['item_id'] == 11373]['item_cnt_day']\nsale_num.describe()","0d9cb0f1":"#Se puede ver que el 11373 generalmente se vende muy poco y el volumen de ventas es casi de un solo d\u00edgito (75% = 8 piezas).\n\n#Por tanto, el n\u00famero de ventas 2169 puede considerarse un valor anormal y debe eliminarse.\n\nsales_train = sales_train[sales_train['item_cnt_day'] < 2000]","4de30fee":"#Adem\u00e1s, hay otro producto que se ha vendido 1000 veces, por lo que debe buscar este producto para el seguro.\n\n#La informaci\u00f3n de datos correspondiente al volumen de ventas de 1000\n\nsales_train[sales_train['item_cnt_day'] == 1000]","0bcd6789":"#La informaci\u00f3n correspondiente de este producto.\n\nitems[items['item_id'] == 20949]","8e47a087":"#Con la ayuda de la traducci\u00f3n, esta es una peque\u00f1a camiseta blanca de la marca Mike.\n\n#Verificando las ventas de este producto en otras tiendas\n\nsales_train[sales_train['item_id'] == 20949]","fe9f68cc":"#La informaci\u00f3n del volumen de ventas correspondiente al producto\n\nsale_num = sales_train[sales_train['item_id'] == 20949]['item_cnt_day']\nsale_num.describe()","947ac671":"#Del mismo modo, para 20949 este producto se vende generalmente muy poco, \n#el volumen de ventas es casi de un solo d\u00edgito (75% = 7 piezas), e inesperadamente hay un volumen de ventas negativo.\n\n#Por lo tanto, el n\u00famero de ventas de 1000 puede considerarse un valor anormal y debe eliminarse.\nsales_train = sales_train[sales_train['item_cnt_day'] < 1000]","053dd0dd":"#La informaci\u00f3n anterior nos recuerda que debemos verificar qu\u00e9 productos tienen la menor cantidad de ventas\n\nsales_train['item_cnt_day'].sort_values(ascending=True)[:10]","a93326dc":"#Parece que muchos productos tienen valores de venta negativos, \n#lo que puede significar que estos productos no se venden sino que se compran, por lo que no nos ocupamos de este tema.","c4f9a40c":"fig = plt.figure(figsize=(20,10))  # Tablero\nplt.subplots_adjust(hspace=.4)  # Espaciado de subimagen\n\n#Ver la distribuci\u00f3n de shop_id\nplt.subplot2grid((1,1), (0,0), rowspan=1, colspan=3)\ntest['shop_id'].value_counts(normalize=True).plot(kind='bar', color='darkviolet')\nplt.title('El estado de distribuci\u00f3n del ID de tienda del conjunto de prueba (Figura 6)')\nplt.xlabel('ID de tienda')\nplt.ylabel('N\u00famero de ocurrencias de ID de tienda estandarizado')\n\nplt.show()","94c18c60":"fig = plt.figure(figsize=(20,10))  # Tablero\nplt.subplots_adjust(hspace=.4)  # Espaciado de subimagen\n\n\n#Ver la distribuci\u00f3n de item_id\nplt.subplot2grid((1,1), (0,0), rowspan=1, colspan=1)\ntest['item_id'].plot(kind='hist', color='sienna')\nplt.title('El estado de distribuci\u00f3n de los ID de productos en el conjunto de prueba (Figura 7)')\nplt.xlabel('ID de producto')\nplt.ylabel('N\u00famero de apariciones de ID de producto estandarizado')\n\nplt.show()","1586d928":"#Aunque el conjunto de entrenamiento tiene m\u00e1s ID que el conjunto de prueba, \n#no hay garant\u00eda de que el conjunto de entrenamiento contenga todas las tiendas que aparecen en el conjunto de prueba.\n\n#Por lo tanto, es necesario verificar si el ID del conjunto de prueba es un subconjunto del ID del conjunto de entrenamiento.\n\ndef is_subset(set0,set1):\n    if set0.issubset(set1):\n        print (\"Los dos son la relaci\u00f3n de inclusi\u00f3n del subconjunto\") \n    else:\n        print (\"Los dos no son un subconjunto de la relaci\u00f3n de inclusi\u00f3n\")\n\nshops_train_set = set(sales_train['shop_id'].unique())\nshops_test_set = set(test['shop_id'].unique())\n\nprint('El resultado del juicio es:')\nis_subset(shops_test_set,shops_train_set)","b74a12c0":"#Aqu\u00ed se determina que todos los ID de tienda en el conjunto de prueba est\u00e1n en el conjunto de entrenamiento.\n#Sin embargo, en la discusi\u00f3n de la competencia del proyecto, se mencion\u00f3 una pregunta sobre tiendas duplicadas, que puede requerir nuestro an\u00e1lisis.","e6e522e3":"#Comparar el nombre y la identificaci\u00f3n de la tienda\nshops","dc065889":"#Sorprendentemente, estos nombres de tiendas se basan en ciudades y regiones, lo que puede ser una caracter\u00edstica potencial\n\n#Adem\u00e1s, un an\u00e1lisis cuidadoso puede encontrar que los nombres de las tiendas con los ID 0 y 1 son casi los mismos que los que tienen los ID 57 y 58. La diferencia es que las tiendas 0 y 1 tambi\u00e9n tienen la palabra'\u0444\u0440\u0430\u043d '(Fran) adjunta.\n\n#Adem\u00e1s, el nombre de la tienda con ID 10 es casi el mismo que ID 11, ambos son \"\u0416\u0443\u043a\u043e\u0432\u0441\u043a\u0438\u0439 \u0443\u043b. \u0427\u043a\u0430\u043b\u043e\u0432\u0430 39\u043c\" (Zhukovsky Avenue Chkalov 39m)\n\n#La \u00fanica diferencia entre los dos es que los caracteres del sub\u00edndice final son diferentes, que son '? 'Y 2'","75be4c0c":"#Por lo tanto, creo que estos elementos de identificaci\u00f3n casi duplicados deber\u00edan fusionarse \n#(tanto el conjunto de entrenamiento como el conjunto de prueba)\n\nsales_train.loc[sales_train['shop_id'] == 0, 'shop_id'] = 57\ntest.loc[test['shop_id'] == 0, 'shop_id'] = 57\n\nsales_train.loc[sales_train['shop_id'] == 1, 'shop_id'] = 58\ntest.loc[test['shop_id'] == 1, 'shop_id'] = 58\n\nsales_train.loc[sales_train['shop_id'] == 10, 'shop_id'] = 11\ntest.loc[test['shop_id'] == 10, 'shop_id'] = 11","1333266a":"#Mire la cantidad de ID de tienda en el conjunto de entrenamiento y el conjunto de prueba despu\u00e9s de la fusi\u00f3n\n\nshops_train = sales_train['shop_id'].nunique()\nshops_test = test['shop_id'].nunique()\nprint('Los ID de tienda en el conjunto de entrenamiento son {} \u4e2a '.format(shops_train))\nprint('Los ID de tienda en el conjunto de prueba son {} \u4e2a '.format(shops_test))","a8f500a4":"#Extraemos la ciudad en el nombre de la tienda \n\n#Vemos el nombre de la tienda de los primeros cinco ID\nshops['shop_name'][:5]","ea824e16":"#Se extra el nombre de la ciudad en el nombre de la tienda\n\nshop_cities = shops['shop_name'].str.split(' ').str[0]\nshop_cities.unique()","d98a3bf6":"#Despu\u00e9s de una cuidadosa observaci\u00f3n, se descubri\u00f3 que Yakutsk usaba dos expresiones, '! \u042f\u043a\u0443\u0442\u0441\u043a' y'\u042f\u043a\u0443\u0442\u0441\u043a '.\n#Supongo que su significado deber\u00eda ser el mismo, as\u00ed que los fusionaremos en una categor\u00eda. \n#y se pone el nombre de la ciudad como una caracter\u00edstica nueva en los datos de las tiendas.\n\nshops['city'] = shop_cities\nshops.loc[shops.city == '!\u042f\u043a\u0443\u0442\u0441\u043a', 'city'] = '\u042f\u043a\u0443\u0442\u0441\u043a'\n\n#Ver datos de tiendas actuales\nshops","ca211f07":"#Se convierte las caracter\u00edsticas de la ciudad en etiquetas num\u00e9ricas\n\nfrom sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\nshops['shop_city'] = label_encoder.fit_transform(shops['city'])","771950ad":"#Ahora ya no necesitamos las dos variables de'hop_name 'y'city', as\u00ed que se eliminan\n\nshops = shops.drop(['shop_name', 'city'], axis = 1)\nshops.head()","1c96e51c":"#Se realizan operaciones de an\u00e1lisis similares en el ID de art\u00edculo \"item_ids\" ahora aplicado a la cantidad de productos\n\n#Verificaci\u00f3n de contenci\u00f3n similar\n\nitems_train_set = set(sales_train['item_id'].unique())\nitems_test_set = set(test['item_id'].unique())\n\nprint('El resultado del juicio es: ')\nis_subset(items_test_set,items_train_set) ","8e4f9813":"#La cantidad de estos ID de productos que no pertenecen a un subconjunto\n\nlen(items_test_set.difference(items_train_set))","72aec5d1":"#Puede verse que hay 363 elementos en el conjunto de prueba que no est\u00e1n en el conjunto de entrenamiento.\n#Pero esto no significa que el pron\u00f3stico de ventas para estos productos deba ser cero, \n#porque se pueden agregar nuevos productos a los datos de capacitaci\u00f3n, pero c\u00f3mo predecir su valor es un problema dif\u00edcil.\n\n#Antes de procesar, necesitamos comprender mejor los productos 5100 en este conjunto de prueba. \n\n#A qu\u00e9 categor\u00eda pertenecen y qu\u00e9 categor\u00edas no necesitamos predecir en el conjunto de prueba.\n\nitem_in_test = items.loc[items['item_id'].isin(sorted(test['item_id'].unique()))]\ncats_in_test = item_in_test.item_category_id.unique()","703928f7":"#La informaci\u00f3n de categor\u00eda en los datos de categor\u00eda item_cats que no est\u00e1n en la prueba (categor\u00edas comunes en el conjunto de entrenamiento)\n\nitem_cats.loc[~item_cats['item_category_id'].isin(cats_in_test)]","b00b237e":"#Ver datos de categor\u00eda en item_cats\n\nitem_cats['item_category_name']","b043f6a4":"\n#Separe los caracteres con'- '\ncats_ = item_cats['item_category_name'].str.split('-')\n\n#Extrae la categor\u00eda principal en item_cats\nitem_cats['main_category'] = cats_.map(lambda row: row[0].strip())  # Extraiga el car\u00e1cter anterior, use strip () para eliminar las unidades que no son caracteres\n\n#Extrae subcategor\u00edas en item_cats (si no hay una subcategor\u00eda, use la categor\u00eda principal como subcategor\u00eda)\nitem_cats['sub_category'] = cats_.map(lambda row: row[1].strip() if len(row) > 1 else row[0].strip())","50dae907":"#Se codifica digitalmente la nueva clase\n\nlabel_encoder = preprocessing.LabelEncoder()\n\nitem_cats['main_category_id'] = label_encoder.fit_transform(item_cats['main_category'])\nitem_cats['sub_category_id'] = label_encoder.fit_transform(item_cats['sub_category'])","d1ad60a0":"item_cats.head()","77ff68b8":"#Se generan pares de tuplas de datos de art\u00edculos de tienda cada mes en los datos de entrenamiento\n\n# Se convierte la proporci\u00f3n de tiempo en los datos de ventas para obtener la hora y la fecha en el formato especificado: 'd\u00eda \/ mes \/ a\u00f1o'\n\nsales_train['date'] = pd.to_datetime(sales_train['date'], format='%d.%m.%Y') ","037e1b37":"#Se crea un iterador para generar tuplas que representen el producto cartesiano de elementos en item1, item2, etc.\n\n\nfrom itertools import product \nshops_in_jan = sales_train.loc[sales_train['date_block_num']==0, 'shop_id'].unique()  # Ontiene la cantidad de ID de tienda que comienzan en 0\nitems_in_jan = sales_train.loc[sales_train['date_block_num']==0, 'item_id'].unique()  # Ontiene la cantidad de ID de producto a partir de 0 meses\njan = list(product(*[shops_in_jan, items_in_jan, [0]]))    # Genera una tupla del producto cartesiano del n\u00famero de ID de tienda y el n\u00famero de ID de producto, y luego lo convierte en una lista","5ecc801f":"#Los primeros cinco resultados de la tupla cartesiana, las posiciones de izquierda a derecha \n#representan respectivamente: (ID de tienda, ID de producto, n\u00famero de mes actual)\n\nprint(jan[:5])","e373f585":"#El n\u00famero total de tuplas cartesianas (que indica 0 mes)\n\nprint(len(jan))","092c8e20":"#Productos Descartes fabricados en febrero de 2013 (segundo mes)\n\nshops_in_feb = sales_train.loc[sales_train['date_block_num']==1, 'shop_id'].unique()\nitems_in_feb = sales_train.loc[sales_train['date_block_num']==1, 'item_id'].unique()\nfeb = list(product(*[shops_in_feb, items_in_feb, [1]]))","be24d656":"#Tupla cartesiana para el segundo mes\nprint(feb[:5])","c1194356":"#N\u00famero de tuplas cartesianas en el segundo mes\n\nprint(len(feb))","d3006676":"\n#Se utiliza el m\u00e9todo de apilamiento de matrices 'vstack' de numpy para fusionar los datos de la tupla cartesiana de los dos meses anteriores y crear un formato de marco de datos para facilitar la visualizaci\u00f3n\ncartesian_jf = np.vstack((jan, feb))    # vstack (direcci\u00f3n vertical) apila matrices.\ncartesian_jf_df = pd.DataFrame(cartesian_jf, columns=['shop_id', 'item_id', 'date_block_num'])   # Crea un marco de datos y nombra diferentes columnas\ncartesian_jf_df.head().append(cartesian_jf_df.tail())","570d7656":"#Se combinan los 33 meses con los mismos datos y crea df (data-frame)\n\nmonths = sales_train['date_block_num'].unique()\ncartesian = []\nfor month in months:\n    shops_in_month = sales_train.loc[sales_train['date_block_num']==month, 'shop_id'].unique()\n    items_in_month = sales_train.loc[sales_train['date_block_num']==month, 'item_id'].unique()\n    cartesian.append(np.array(list(product(*[shops_in_month, items_in_month, [month]])), dtype='int32'))\n    \ncartesian_df = pd.DataFrame(np.vstack(cartesian), columns = ['shop_id', 'item_id', 'date_block_num'], dtype=np.int32)","25b57780":"#Forma de datos consolidados para todos los meses\n\ncartesian_df.shape","c361d4f2":"cartesian_df.head()","efe2420e":"#Los objetos de secuencia shop_id, 'item_id' y'date_block_num 'para agrupar el conjunto de datos y luego se extrae la suma del volumen de ventas mensual'item_cnt_day'\n\n#Es decir, se puede obtener las ventas mensuales totales de productos espec\u00edficos en tiendas espec\u00edficas\n\nx = sales_train.groupby(['shop_id', 'item_id', 'date_block_num'])['item_cnt_day'].sum().rename('item_cnt_month').reset_index()\nx.head()","94e7b328":"x.shape","ce24af92":"#El m\u00e9todo pd.merge () fusiona y une. ''LEFT'' significa que solo se retiene la clave primaria izquierda y no se toman las filas que existen solo en la clave primaria derecha.\n\nnew_train = pd.merge(cartesian_df, x, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0) ","0dcbf16a":"#Se usa numpy.clip para escalar las ventas mensuales item_cnt_month a [0,20], que se menciona en la descripci\u00f3n del proyecto\n\nnew_train['item_cnt_month'] = np.clip(new_train['item_cnt_month'], 0, 20)\n","cdb390b6":"new_train.head()","98a0b5f3":"# sort_values reorganiza new_train de acuerdo con el orden de la clasificaci\u00f3n interna de 'date_block_num', 'shop_id' e'item_id '\n\nnew_train.sort_values(['date_block_num','shop_id','item_id'], inplace = True)  \nnew_train.head()","bff6cc4f":"#Elimina listas innecesarias del sistema y libera memoria\n\ndel x\ndel cartesian_df\ndel cartesian\ndel cartesian_jf\ndel cartesian_jf_df\ndel feb\ndel jan\ndel items_test_set\ndel items_train_set\ndel sales_train","081b0089":"#Ahora insertamos el atributo date_block_num (el mes 34) y el atributo de volumen de ventas'item_cnt_month '(tentativamente establecido en 0) para el conjunto de prueba.\n\n#Se usa el m\u00e9todo de inserci\u00f3n de pandas para colocar esta nueva columna en un \u00edndice espec\u00edfico. Esto hace que sea m\u00e1s f\u00e1cil conectar el equipo de prueba al equipo de entrenamiento m\u00e1s adelante.\n\n\ntest.insert(loc=3, column='date_block_num', value=34)        # Inserta el n\u00famero de meses en la tercera columna del conjunto de prueba y asigna un valor de 34\ntest['item_cnt_month'] = 0  # Inserta una nueva columna'item_cnt_month 'en el conjunto de prueba y asigna un valor de 0\ntest.head()","b803d72b":"#Elimina la columna de ID que no est\u00e1 incluida en el conjunto de prueba en relaci\u00f3n con new_train y combina con el conjunto de entrenamiento original\n\nnew_train = new_train.append(test.drop('ID', axis = 1)) \nnew_train.head().append(new_train.tail())","b475e8f3":"#Combina los datos de la tienda para obtener la categor\u00eda de la ciudad codificada con el ID correspondiente\n\nnew_train = pd.merge(new_train, shops, on=['shop_id'], how='left') \nnew_train.head()","7c79abc9":"#Combina los datos del nombre del producto para obtener la categor\u00eda de producto codificada con el ID correspondiente\n\nnew_train = pd.merge(new_train, items.drop('item_name', axis = 1), on=['item_id'], how='left')\nnew_train.head()","9500befd":"#Combina los datos de la categor\u00eda de producto para obtener la categor\u00eda padre-hijo del producto del n\u00famero de c\u00f3digo bajo el nombre correspondiente\n\nnew_train = pd.merge(new_train,  item_cats.drop('item_category_name', axis = 1), on=['item_category_id'], how='left')\nnew_train.head()","4aa0d758":"#Elimina columnas no num\u00e9ricas\n\nnew_train.drop(['main_category','sub_category'],axis=1,inplace=True)\nnew_train.head()","d6e1ac5e":"#Elimina datos in\u00fatiles y libera memoria\n\ndel items\ndel item_cats\ndel shops\ndel test","18ba2047":"#Se generan caracter\u00edsticas de retraso y codificaci\u00f3n promedio\n\n#Definir la funci\u00f3n de adici\u00f3n de caracter\u00edsticas de hist\u00e9resis\ndef generate_lag(train, months, lag_column):\n    for month in months:\n        # Crear una funci\u00f3n de retraso\n        train_shift = train[['date_block_num', 'shop_id', 'item_id', lag_column]].copy()\n        train_shift.columns = ['date_block_num', 'shop_id', 'item_id', lag_column+'_lag_'+ str(month)]\n        train_shift['date_block_num'] += month\n        #La nueva lista est\u00e1 conectada al conjunto de entrenamiento.\n        train = pd.merge(train, train_shift, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n    return train","32ebc672":"#Define la funci\u00f3n de conversi\u00f3n de tipo de datos descendente.\n#La funci\u00f3n es convertir el tipo float64 a float16 y convertir int64 a int16\n#(usado para reducir la cantidad de memoria)\n\nfrom tqdm import tqdm_notebook  \ndef downcast_dtypes(df):   \n    # Seleccina las columnas a procesar\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n    \n    #Inicia conversi\u00f3n de datos\n    df[float_cols] = df[float_cols].astype(np.float16)\n    df[int_cols]   = df[int_cols].astype(np.int16)\n    \n    return df","2fe88a17":"#Funcion de transformaci\u00f3n para cambiar los tipos de datos\nnew_train = downcast_dtypes(new_train)  ","1da264a1":"%%time\n#Agrega la funci\u00f3n de retraso de la variable objetivo (atributo de ventas mensuales) y agrega parte de los datos de ventas mensuales\nnew_train = generate_lag(new_train, [1,2,3,4,5,6,12], 'item_cnt_month')","91688ff5":"%%time\n#Agrega caracter\u00edsticas de retraso del producto de la media objetivo\n#Ordena por mes e identificaci\u00f3n de producto y toma el promedio de sus ventas mensuales\ngroup = new_train.groupby(['date_block_num', 'item_id'])['item_cnt_month'].mean().rename('item_month_mean').reset_index()\n\n#Agrega la nueva tabla a la derecha de new_train, correspondiente a los atributos 'date_block_num', 'item_id'\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'item_id'], how='left')\n\n#Agrega las ventas mensuales atrasadas a [1,2,3,6,12] meses (llenado promedio)\nnew_train = generate_lag(new_train, [1,2,3,6,12], 'item_month_mean')\n\n#Elimina el atributo'item_month_mean 'no deseado\nnew_train.drop(['item_month_mean'], axis=1, inplace=True)","eace071b":"%%time\n#Agrega la funci\u00f3n de retraso medio de destino de tienda\ngroup = new_train.groupby(['date_block_num', 'shop_id'])['item_cnt_month'].mean().rename('shop_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'shop_id'], how='left')\nnew_train = generate_lag(new_train, [1,2,3,6,12], 'shop_month_mean')\nnew_train.drop(['shop_month_mean'], axis=1, inplace=True)","eef1056b":"%%time\n#Agrega la funci\u00f3n de retraso de la media de destino de categor\u00eda de producto de tienda\ngroup = new_train.groupby(['date_block_num', 'shop_id', 'item_category_id'])['item_cnt_month'].mean().rename('shop_category_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'shop_id', 'item_category_id'], how='left')\nnew_train = generate_lag(new_train, [1, 2], 'shop_category_month_mean')\nnew_train.drop(['shop_category_month_mean'], axis=1, inplace=True)","f6152d79":"%%time\n#Agrega la categor\u00eda principal del producto: la caracter\u00edstica rezagada de la media objetivo\ngroup = new_train.groupby(['date_block_num', 'main_category_id'])['item_cnt_month'].mean().rename('main_category_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'main_category_id'], how='left')\nnew_train = generate_lag(new_train, [1], 'main_category_month_mean')\nnew_train.drop(['main_category_month_mean'], axis=1, inplace=True)","3d2c5592":"%time\n#Agrega caracter\u00edsticas de rezago de subcategor\u00eda de producto de la media objetivo\ngroup = new_train.groupby(['date_block_num', 'sub_category_id'])['item_cnt_month'].mean().rename('sub_category_month_mean').reset_index()\nnew_train = pd.merge(new_train, group, on=['date_block_num', 'sub_category_id'], how='left')\nnew_train = generate_lag(new_train, [1], 'sub_category_month_mean')\nnew_train.drop(['sub_category_month_mean'], axis=1, inplace=True)","01942cce":"#Morfolog\u00eda del conjunto de datos despu\u00e9s de agregar caracter\u00edsticas de hist\u00e9resis\nnew_train.tail()","a3d49c29":"#Agrega las caracter\u00edsticas de un atributo de mes\nnew_train['month'] = new_train['date_block_num'] % 12","435bfd04":"#Conversi\u00f3n de tipo de datos nuevamente\nnew_train = downcast_dtypes(new_train)\nnew_train.head().append(new_train.tail())","c9b87240":"#Debido a que no hay una caracter\u00edstica de datos de las transacciones de valores en el primer a\u00f1o, se utilizar\u00e1 como entrada a partir del segundo a\u00f1o.\nnew_train = new_train[new_train.date_block_num > 11]","de5385a8":"#Se usa  0 para completar, indicando una muestra sin datos\n\ndef fill_nan(df):\n    for col in df.columns:\n        if ('_lag_' in col) & (df[col].isna().any()):\n            df[col].fillna(0, inplace=True)         \n    return df\n\nnew_train =  fill_nan(new_train)","6ed20056":"\n#Extracci\u00f3n de caracter\u00edsticas de los datos de entrenamiento\ntrain_feature = new_train[new_train.date_block_num < 33].drop(['item_cnt_month'], axis=1)\n\n#Extracci\u00f3n de etiquetas de datos de entrenamiento\ntrain_label = new_train[new_train.date_block_num < 33]['item_cnt_month']","2a487ef7":"#Extracci\u00f3n de caracter\u00edsticas de datos de verificaci\u00f3n\nval_feature = new_train[new_train.date_block_num == 33].drop(['item_cnt_month'], axis=1)\n\n#Extracci\u00f3n de etiquetas de datos de verificaci\u00f3n\nval_label = new_train[new_train.date_block_num == 33]['item_cnt_month']","9818d989":"test_feature = new_train[new_train.date_block_num == 34].drop(['item_cnt_month'], axis=1)","0c776877":"train_feature.shape,train_label.shape,val_feature.shape,val_label.shape","920f8294":"train_feature.head()","a5951d7f":"import gc\ngc.collect()","37c8d7f2":"from xgboost import XGBRegressor","427ff694":"#Se establecen par\u00e1metros de modelo\n\nmodel = XGBRegressor(n_estimators=3000,\n                     max_depth=10,\n                     colsample_bytree=0.5, \n                     subsample=0.5, \n                     learning_rate = 0.01\n                    )","fca96e5c":"%%time\n#Se realiza el entrenamiento del modelo y configura la funci\u00f3n de parada anticipada.\n\nmodel.fit(train_feature.values, train_label.values, \n          eval_metric=\"rmse\", \n          eval_set=[(train_feature.values, train_label.values), (val_feature.values, val_label.values)], \n          verbose=True, \n          early_stopping_rounds = 50)","3cb1f1ad":"y_pred = model.predict(test_feature.values)","aa54695d":"#Vista de importancia de la funci\u00f3n\nimportances = pd.DataFrame({'feature':new_train.drop('item_cnt_month', axis = 1).columns,'importance':np.round(model.feature_importances_,3)}) \nimportances = importances.sort_values('importance',ascending=False).set_index('feature') \nimportances = importances[importances['importance'] > 0.01]\n\nimportances.plot(kind='bar',\n                 title = 'Feature Importance',\n                 figsize = (8,6),\n                 grid= 'both')","2cef5eba":"#Exportar resultado\nsubmission['item_cnt_month'] = y_pred\nsubmission.to_csv('future_sales_submission2.csv', index=False)","196c4248":"# 2. ****An\u00e1lisis de cantidad productos****","86fbb538":"Ahora necesitamos fusionar estos dos datos df (data.frame) para averiguar qu\u00e9 tiendas est\u00e1n disponibles para la venta: \n\n* Para tuplas cartesianas, simplemente pondremos el valor que existe en x. \n* Para las filas restantes, sub\u00edndice 0 para indicar que no hay ventas.\n\n- Se debe prestar atenci\u00f3n para recordar que las columnas que se fusionar\u00e1n son la intersecci\u00f3n de shop_id, item_id y date_block_num","dddb1303":"Podemos ver que en enero de 2013 hab\u00eda 365175 tuplas de tiendas y art\u00edculos.\n\nLuego, necesitamos generar productos cartesianos para los 33 meses del conjunto de capacitaci\u00f3n\n\nAhora se puede generar el producto cartesiano de febrero de 2013 y conectarlo con enero de 2013 para generar un marco de datos.","598e9f57":"Combina datos de tienda, producto y categor\u00eda para agregar etiquetas de categor\u00eda de ciudad procesadas previamente, atributos de categor\u00eda de producto (categor\u00eda principal y subcategor\u00eda):","e2c3454c":"Se puede ver que las tiendas en el conjunto de prueba no disminuyeron, pero se eliminaron las tres ID redundantes en el conjunto de entrenamiento.\n\n","1b3be7d9":"Conjunto de validaci\u00f3n","77adeefb":"# An\u00e1lisis y tratamiento de valores at\u00edpicos","5d85eb4a":"**Campos de informaci\u00f3n**\n\n* ID                 :Un ID que representa una tupla (tienda, art\u00edculo) dentro del conjunto de prueba\n* shop_id            :Identificador \u00fanico de una tienda\n* item_id            :Identificador \u00fanico de un producto\n* item_category_id   :Identificador \u00fanico de la categor\u00eda del art\u00edculo\n* item_cnt_day       :N\u00famero de productos vendidos. \n* item_price         :Precio actual de un art\u00edculo\n* date               :Fecha en formato dd\/mm\/aaaa\n* date_block_num     :Un n\u00famero de mes consecutivo, utilizado por conveniencia. Enero de 2013 es 0, febrero de 2013 es 1, ..., octubre de 2015 es 33\n* item_name          :Nombre del art\u00edculo\n* shop_name          :Nombre de la tienda\n* item_category_name :Nombre de la categor\u00eda del art\u00edculo","47971a77":"# Distribuci\u00f3n de datos del conjunto de prueba\n\n**Ahora, se revsia la distribuci\u00f3n del conjunto de prueba para ver si hay una diferencia entre el conjunto de entrenamiento**","0b4650c9":"# Resultados predicci\u00f3n","eb540de6":"**(2) Evaluando el volumen de ventas**","61083e54":"# # Construcci\u00f3n y optimizaci\u00f3n de modelos\n\nUsa el modelo XGBOOST para hacer predicciones ","58337abf":"Ahora, necesitamos generar los datos de ventas correspondientes para cada tienda y producto en el conjunto de capacitaci\u00f3n.\n\nDado que el pron\u00f3stico final es para las ventas mensuales de una tienda y un producto en particular, deber\u00edamos hacerlo mensualmente.","127c9036":"**An\u00e1lisis del n\u00famero de tienda:**","334e8d39":"**Descripciones de archivos**\n* sales_train.csv: El conjunto de formaci\u00f3n. Datos hist\u00f3ricos diarios desde enero de 2013 hasta octubre de 2015.\n* test.csv: El conjunto de pruebas. Debe pronosticar las ventas de estas tiendas y productos para noviembre de 2015.\n* sample_submission.csv: Un archivo de env\u00edo de muestra en el formato correcto.\n\n* items.csv: Informaci\u00f3n complementaria sobre los art\u00edculos \/ productos.\n* item_categories.csv: Informaci\u00f3n complementaria sobre las categor\u00edas de art\u00edculos.\n* shops.csv : Informaci\u00f3n complementaria sobre las tiendas.","ea50b47b":"**(1) Evaluando el precio de venta:**","43863a0b":"****Del an\u00e1lisis de la imagen, podemos ver:****\n\n* Figura 6: a diferencia del conjunto de entrenamiento, el ID de tienda del conjunto de prueba se distribuye uniformemente. Adem\u00e1s, la escasez de la distribuci\u00f3n tambi\u00e9n muestra que el ID de la tienda en el conjunto de prueba falta en el conjunto de entrenamiento, es decir, contiene solo una parte del ID. \n\n* Figura 7: En comparaci\u00f3n con el conjunto de entrenamiento, la distribuci\u00f3n de ID de los productos del conjunto de prueba es m\u00e1s uniforme, pero el n\u00famero de ocurrencias ser\u00e1 menor.\n\nSeg\u00fan un juicio preliminar, faltan algunos valores de shop_id y item_id en el conjunto de prueba. Necesitamos hacer estad\u00edsticas sobre los valores perdidos y hacer alg\u00fan procesamiento para estos valores perdidos.","b6add106":"# 1. ****An\u00e1lisis de \"tiendas duplicadas\" con diferentes ID****","92a04d17":"# ****Bibliotecas necesarias para el an\u00e1lisis****","027c5047":"Inesperadamente, descubrimos que algunos productos b\u00e1sicos solo existen en el conjunto de prueba y no en el conjunto de entrenamiento. \n\nDebemos realizar un an\u00e1lisis estad\u00edstico de estos productos b\u00e1sicos.","bf18683d":"Conjunto de prueba (para predecir) ","22a63c64":"Conjunto de entrenamiento\n","d758801a":"Con la ayuda de la traducci\u00f3n, los primeros cinco y los \u00faltimos cinco nombres de tiendas son: (seg\u00fan el n\u00famero de identificaci\u00f3n) \n\n* (0) Yakutsk Oldchnickize, 56 Fran \n* (1) Centro de Yakutsk Fran \n* (2) Adgaia Super Mall \n* (3) \"Mundo cinematogr\u00e1fico de octubre\" \n* (4) Centro comercial Volzhsky \"Centro comercial Volga\" \n* ......... \n* (55) Almac\u00e9n digital 1C-Online \n* (56) Carnaval de Ch\u00e9jov \n* (57) Yakutsk Aldecinikidze, 56 a\u00f1os. \n* (58) Centro de Yakutsk \n* (59) Centro comercial Yaroslavl Altair","6ab5b496":"# Agrupar categor\u00edas comunes y extraer sus subcategor\u00edas\n\nPuede verse en la lista anterior que tambi\u00e9n hay combinaciones de categor\u00edas y subcategor\u00edas principales en las categor\u00edas. \nLos dos est\u00e1n separados por un gui\u00f3n \"-\" y debemos extraerlos.","51f636f0":"# Obtener Archivos de Datos","83312c71":"# Exploraci\u00f3n de Datos","ecaf9dce":"# **Predecir Ventas Futuras**\n\n# Descripci\u00f3n de la competencia\n\nEn esta competencia, se trabajar\u00e1 con un **conjunto de datos de series de tiempo que consta de datos de ventas diarias, amablemente proporcionados por una de las firmas de software m\u00e1s grandes de Rusia: 1C Company.\n\nSe pide predecir las ventas totales de cada producto y tienda en el pr\u00f3ximo mes. \n\n\n# Descripci\u00f3n de Data\n\nSe proporcionan datos hist\u00f3ricos de ventas diarias. \nLa tarea es pronosticar la cantidad total de productos vendidos en cada tienda para el conjunto de prueba. \nSe debe tener en cuenta que la lista de tiendas y productos cambia ligeramente cada mes. \nCrear un modelo s\u00f3lido que pueda manejar tales situaciones es parte del desaf\u00edo.","41c25bfb":"1. Segmentaci\u00f3n de conjuntos de datos","dc677ef4":"Del an\u00e1lisis de la imagen, podemos ver:\n\nFigura 1: Tenemos alrededor de 60 ID de tiendas, pero no est\u00e1n distribuidas de manera uniforme en el conjunto de datos. La mayor\u00eda de los 4 ID ocupan aproximadamente el 25% de todo el ID, es decir, las tiendas 31, 25, 54, 28\n\nFigura 2: Los ID de productos var\u00edan ligeramente en frecuencia. Algunos ID aparecen con m\u00e1s frecuencia. Los ID de productos en el mismo cuadro pueden representar productos similares.\n\n\nFigura 3 \/ Figura 4: Se puede ver un \u00e1rea en blanco enorme en la distribuci\u00f3n del histograma de precios y ventas de productos, que muestra que hay valores at\u00edpicos extremos en las dos distribuciones (por ejemplo, el precio m\u00e1ximo del producto es m\u00e1s de 300,000, y el precio general Pero dentro de 25.000), se deben abordar estos valores at\u00edpicos.\n\n\nFigura 5: Estos son los datos de valor mensual desde enero de 2013 hasta octubre de 2015. Se puede encontrar que num = 11 (diciembre de 2013) tiene la mayor cantidad de registros de ventas y num = 23 (diciembre de 2014) tiene Con la segunda mayor cantidad de registros de ventas, se puede inferir que la mayor cantidad de ventas ocurri\u00f3 al final de cada a\u00f1o, lo que tiene cierto valor de referencia para nuestra previsi\u00f3n de los datos de noviembre de 2015.\n","054ea208":"**Resumen de los datos de ventas mensuales y ajuste de las variables objetivo**"}}