{"cell_type":{"5d3e3a68":"code","9d96c916":"code","5ecdffa6":"code","3192b2e3":"code","615c5eba":"code","c86b7bfc":"code","3ed784f3":"code","158dcd25":"code","76cdef39":"code","7134fa7f":"code","5e9dca6e":"code","73eb1428":"code","63e750ed":"code","b7ed00d5":"code","52c8b0a3":"code","5819ce0d":"code","a827cbff":"code","532965c7":"code","7c37f370":"code","37d8fe38":"code","29176191":"code","3442e117":"code","31f173fc":"code","a68f6325":"code","569f34aa":"code","18ac9482":"code","231d75e9":"code","ef5fefa8":"code","26495398":"code","825d18d8":"code","627fa2b9":"code","aa385d51":"code","b304ec65":"code","7b3187bb":"code","b0ddab36":"code","fac98482":"code","086fdf2a":"code","a8ccc312":"code","9e140e91":"code","8d388365":"code","262b74b1":"code","689b2fe7":"code","2c06dcea":"code","365ef91e":"code","32bb2eae":"code","f8fcaa65":"code","f0550949":"code","6fce72c4":"code","6df992aa":"markdown","4ad7c3e3":"markdown","44fbbf71":"markdown","f5287d44":"markdown","d54476d0":"markdown","69f01104":"markdown","d16b5649":"markdown","28f92ba9":"markdown","0f95466b":"markdown","89ddaa5c":"markdown","ebe4d621":"markdown","55a15c6b":"markdown","bb5ec9c9":"markdown","c22149c4":"markdown","680688b1":"markdown","c2b61006":"markdown","365a424b":"markdown","9927e64b":"markdown","953d5962":"markdown","1260c644":"markdown","7cc001ea":"markdown","1c4f15fa":"markdown","15eeb92e":"markdown","7ba6db73":"markdown","30c125e0":"markdown","baace158":"markdown","c7614d58":"markdown","e4ecd7b0":"markdown","ef173797":"markdown","d615c30e":"markdown","30a6f24b":"markdown","ac3d8e02":"markdown","f96e74c1":"markdown","e5cb8517":"markdown","479a92f1":"markdown","2ddbd760":"markdown","947ba47e":"markdown","11cf9004":"markdown","968efb01":"markdown","65786677":"markdown","58cd8471":"markdown","ba0e5016":"markdown","480d184f":"markdown","b43deb6f":"markdown","8a3dd4a3":"markdown","f5460542":"markdown","f2e0e901":"markdown","49dd31ba":"markdown","14a73a3c":"markdown","fb0f888c":"markdown","8f066663":"markdown","7f3b2660":"markdown","f9f11481":"markdown","8a4fe10e":"markdown","8febe679":"markdown","d6263c27":"markdown","63f911a7":"markdown","a7ed863f":"markdown","10e5219c":"markdown","dff1d357":"markdown","6c697613":"markdown","9fe1e0c5":"markdown","6f9267bb":"markdown","78e40fec":"markdown","e603741e":"markdown","6f2cb60b":"markdown","1bdc918c":"markdown","61b9afd4":"markdown","67b0abfa":"markdown","930ad6a7":"markdown"},"source":{"5d3e3a68":"# To analyse\nimport pandas as pd\nimport numpy as np\n\n#To visualise\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\n%matplotlib inline   \n#This will display the plots below the code and store it in the notebook itself\n\n#To ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","9d96c916":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","5ecdffa6":"print(train.columns)\ntrain.sample(5)\n","3192b2e3":"train.describe(include='all')","615c5eba":"print(pd.isnull(train).sum())\nprint(pd.isnull(train).mean())","c86b7bfc":"sns.barplot(x=\"Sex\",y=\"Survived\",data = train)\nplt.show()","3ed784f3":"train[['Sex','Survived']].groupby('Sex').mean()*100","158dcd25":"sns.barplot(x=\"Pclass\",y=\"Survived\",data = train)\nplt.show()","76cdef39":"train[['Pclass','Survived']].groupby('Pclass').mean()*100","7134fa7f":"sns.catplot(x='Sex', y='Survived',  kind='bar', data=train, hue='Pclass')\nplt.show()","5e9dca6e":"sns.barplot(x=\"SibSp\",y=\"Survived\",data = train)\nplt.show()","73eb1428":"train[['SibSp','Survived']].groupby(\"SibSp\").mean()*100","63e750ed":"train[\"Age\"] = train[\"Age\"].fillna(-0.5)\ntest[\"Age\"] = test[\"Age\"].fillna(-0.5)\nvalue = [-1, 0, 5, 12, 18, 30, 65, 100]\nnames = ['Missing', 'Baby', 'Child', 'Teen', 'Youth', 'Adult', 'Elder']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], value, labels = names)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], value, labels = names)\n\n\n","b7ed00d5":"sns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train)\nplt.show()","52c8b0a3":"train['Name'].head()","5819ce0d":"for item in [train,test]:\n    item['Title'] = item['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\n    # Here we split the second word from the name and stripped the excess whitespaces.","a827cbff":"pd.crosstab(train['Title'],train['Sex'])\n","532965c7":"train[\"Age\"] = train[\"Age\"].replace({-0.5:np.nan})\ntest[\"Age\"] = test[\"Age\"].replace({-0.5:np.nan})","7c37f370":"Null_List = train[train['Age'].isna()].groupby('Title').count()['Survived']\nNull_Title = Null_List.index.values\nNull_List","37d8fe38":"for item in Null_Title:\n        val = train[train.Title == item]['Age'].median()\n        train_list = train[(train.Title==item)& (train.AgeGroup == 'Missing')].index\n        for elem in train_list:\n            train.iloc[elem,train.columns.get_loc('Age')]=val\n    ","29176191":"Null_List = test[test['Age'].isna()].groupby('Title').count()['PassengerId']\nNull_Title = Null_List.index.values\nfor item in Null_Title:\n        val = train[train.Title == item]['Age'].median()\n        test_list = test[(test.Title==item) & (test.AgeGroup == 'Missing')].index\n        for elem in test_list:\n            test.iloc[elem,test.columns.get_loc('Age')]=val\n    ","3442e117":"# First we can fill the missing value\n\ntest[pd.isnull(test)['Fare']]\n\n\n","31f173fc":"val = int(test[pd.isnull(test)['Fare']].Pclass)\namount = round(test[test.Pclass ==val].Fare.mean())\nid = test[pd.isnull(test)['Fare']].index\ntest.iloc[id,test.columns.get_loc('Fare')]=amount","a68f6325":"train['Fare'] = pd.cut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['Fare'] = pd.cut(test['Fare'], 4, labels = [1, 2, 3, 4])","569f34aa":"pd.isnull(train).sum()","18ac9482":"train = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)","231d75e9":"print(train.groupby(\"Embarked\").count()[\"Survived\"])","ef5fefa8":"train = train.fillna({\"Embarked\": \"S\"})","26495398":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)","825d18d8":"sex_num = {\"male\":0,\"female\":1}\ntrain[\"Sex\"] = train[\"Sex\"].map(sex_num)\ntest[\"Sex\"] = test[\"Sex\"].map(sex_num)","627fa2b9":"embarked_num = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntrain['Embarked'] = train['Embarked'].map(embarked_num)\ntest['Embarked'] = test['Embarked'].map(embarked_num)\n","aa385d51":"print(pd.isnull(test).sum())\nprint(pd.isnull(train).sum())","b304ec65":"train.sample(5)","7b3187bb":"group = list(map(str,train.AgeGroup.unique().sort_values()))\nval = pd.Series(group)\nprint(val)","b0ddab36":"value = [0, 5, 12, 18, 30, 65, 100]\nnames = ['Baby', 'Child', 'Teen', 'Youth', 'Adult', 'Elder']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], value, labels = names)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], value, labels = names)\n","fac98482":"group = list(map(str,train.AgeGroup.unique().sort_values()))\nval = pd.Series(group)\nprint(val)","086fdf2a":"item = val.to_dict()\nitem","a8ccc312":"item = {v: k for k, v in item.items()}\nitem","9e140e91":"train['AgeGroup'] = train['AgeGroup'].map(item)\ntest['AgeGroup'] = test['AgeGroup'].map(item)\n","8d388365":"train['Title'] = train['Title'].replace('Ms', 'Miss').replace('Mme', 'Mrs').replace('Mlle', 'Miss').replace(['Countess', 'Lady', 'Sir'], 'Royal').replace(['Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Special')\ntest['Title'] = test['Title'].replace('Ms', 'Miss').replace('Mme', 'Mrs').replace('Mlle', 'Miss').replace(['Countess', 'Lady', 'Sir'], 'Royal').replace(['Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Special')\n\ntitle_num = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Special\": 6}\ntrain['Title'] = train['Title'].map(title_num)\ntrain['Title'] = train['Title'].fillna(0)\ntest['Title'] = test['Title'].map(title_num)\ntest['Title'] = test['Title'].fillna(0)","262b74b1":"from sklearn.model_selection import train_test_split\n\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_val, y_train, y_val = train_test_split(predictors, target, random_state = 0)","689b2fe7":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_predict = logreg.predict(x_val)\nresult1 = round(accuracy_score(y_predict, y_val) * 100, 2)\nprint(result1)","2c06dcea":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\nsvc = SVC()\nsvc.fit(x_train, y_train)\ny_predict = svc.predict(x_val)\nresult2 = round(accuracy_score(y_predict, y_val) * 100, 2)\nprint(result2)\n\n","365ef91e":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\ny_predict = knn.predict(x_val)\nresult3 = round(accuracy_score(y_predict, y_val) * 100, 2)\nprint(result3)","32bb2eae":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_predict = gbk.predict(x_val)\nresult4 = round(accuracy_score(y_predict, y_val) * 100, 2)\nprint(result4)","f8fcaa65":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_predict = randomforest.predict(x_val)\nresult5 = round(accuracy_score(y_predict, y_val) * 100, 2)\nprint(result5)","f0550949":"model = [\"Logistic Regression\",\"Support Vector Machines (SVM)\",\"K-Nearest Neighbours (KNN)\",\"Gradient Boosting Classifier\",\"Random Forest Classifier\"]\nvalue = [result1,result2,result3,result4,result5]\nresult = pd.DataFrame({\"Model\":model,\"Value\":value}).sort_values(by=\"Value\", ascending = False)\nresult","6fce72c4":"index = test['PassengerId']\nprediction = gbk.predict(test.drop('PassengerId', axis=1))\n\noutput = pd.DataFrame({ 'PassengerId' : index, 'Survived': prediction })\noutput.to_csv('submission.csv', index=False)","6df992aa":"### Creating the submission file","4ad7c3e3":"We can visualise the data on the basis of different columns. Age, Sex, Pclass and Sibsp are some of the important columns to be considered while visualising the data.","44fbbf71":"Babies had the highest chance to survive as they were looked after by the adults. A baby would always have an adult accompanying him and at the time of rescue, these babies will be given more priority.\n\nElders had the least chance to survive as they became extremely fatigued.","f5287d44":"We can see that 74.2% of females survived compared to 18.89% of males. So females have much higher chance of survival.","d54476d0":"#### Fare Column","69f01104":"There are 687 values missing in the cabin column which is too much to predict. So we can drop the cabin column.","d16b5649":"### 3. Analyse the data","28f92ba9":"From the above table we can see the relation between title and sex. We can compare it with the title of the passengers with the missing ages. We can replace the Nan value with the mode age of the correspoding title.","0f95466b":"#### Based on PClass","89ddaa5c":"First we need to split the train dataset to compare the prediction of models.","ebe4d621":"Next we can map fare values into four groups based on its values","55a15c6b":"We can drop both name and ticket column as they are no longer useful for us","bb5ec9c9":"#### 3. K-Nearest Neighbours","c22149c4":"So people in Pclass 1 had a higher chance of survival and as the Pclass level increased, the rate of survival decreased.","680688b1":"#### 4. Gradient Boosting Classifier","c2b61006":"So the fare of only one passenger is missing. To fill it, we can find the mean fare of the passengers in Pclass column.","365a424b":"Now the missing Age values are filled (At least somewhat accurately). Repeat the same for test dataset.\n","9927e64b":"### 5. Process the data ","953d5962":"Since we have already filled the missing ages, we don't require the missing column anymore.","1260c644":"#### 5.Random Forest Classifier","7cc001ea":"Now we can map AgeGroup with its respective numerical values","1c4f15fa":"#### Based on SibSp","15eeb92e":"The above output corresponds to the number of passengers with the age column as Nan. We can replace Nan with the mode age of the respective title","7ba6db73":"### Visualise the data","30c125e0":"#### 1. Logistic Regression","baace158":"#### Based on Sex","c7614d58":"Since AgeGroup and Title contains string values, we need to replace them with integer values before creating the model","e4ecd7b0":"For the title column, we can replace various titles with their column names","ef173797":"So the best model is Gradient Boosting Classifier. We can use it to predict the survival of test dataset.","d615c30e":"We can map values in the Embarked column with numerical values (0 for male and 1 for female)","30a6f24b":"### Selecting the best model","ac3d8e02":"34.53% of people with 0 sibilings or spouses survived.\n\n53.58% of people with 1 sibiling or spouse survived. (More chance to survive as they helped each other)\n\n46.42% of people with 2 sibilings or spouses survived \n\n","f96e74c1":"There are a total of 891 rows (passengers) in the dataset.\n\nThe cabin column has 687 (77.1%) null values. As the null values are higher, we can drop this column when we are training the model.\n\nThe age column has 177 (19.8%) null values. It is better to modify this column rather than dropping it because age is an important aspect in determining the survival rate.\n\nThe embarked column has 2 (0.2%) null values. We can ignore this column as it will not make that much impact when we are training our model.\n\nRest of the columns has no null values. ","e5cb8517":"SibSp denotes the number of siblings and spouses","479a92f1":"Now we should remove the Null values from the dataset and get them ready for training","2ddbd760":"We can map values in the sex column with numerical values (0 for male and 1 for female)\n","947ba47e":"Check a sample of the train dataset","11cf9004":"Check for any null values","968efb01":"#### Combining PClass and Sex","65786677":"Earlier we have replaced Nan values in the age column with -0.5. We should replace that with Nan as -0.5 would interfere when calculating mode age.","58cd8471":" #### Sex and Embarked column","ba0e5016":"First we will analyse the 'train' data. The following code shows a brief description about it.","480d184f":"Check to see if there are any null values in the train dataset.","b43deb6f":"We can simply map the values in the AgeGroup with numerical values","8a3dd4a3":"From the above graph, we can see that almost all of the females in Pclass 1 survived.\n\nSo the females in PClass 1 and 2 had the highest chance to survive.","f5460542":"First we should extract title from all the names and add another column (\"Title) to the dataset","f2e0e901":"Compare all the models","49dd31ba":"There are 2 missing values in Embarked column, we can fill that by taking the mode value in the Embarked column","14a73a3c":"The most repeating value in the Embarked column is S (Southampton) which is repeated 644 times.\n\nSo we can fill the missing values with \"S\"","fb0f888c":"I'm a beginner in the field of data science. I'm very much interested in data analytics. This is my first kernel on kaggle. I am using the titanic dataset, which is very popular among the beginners that are using kaggle. I will predict the survival rate of passengers. Since I'm a beginner, I'm using simple approaches to reach at a solution.","8f066663":"#### Based on age","7f3b2660":"Check for any null values","f9f11481":"### 1. Import the required packages","8a4fe10e":"#### Name and Ticket column","8febe679":"#### 2. Support Vector Matrices","d6263c27":"No null values means we are almost ready for creating a model from the data","63f911a7":"We need to invert this dict to properly map the AgeGroup column","a7ed863f":"Now we can compare the rate of survival based on age.\n\nBut as several values of the age column is null, we need to modify age column. Instead of finding the age of each and every person, we can group each person on the basis of their age group(Like child,adult,elder etc.)","10e5219c":"That's it we're good to go. Let's get to modelling.","dff1d357":"### 2. Read the input files","6c697613":"For the rest of the columns we can either drop them or map them with integer values(For better modelling)","9fe1e0c5":"People with 2 or less sibilings and spouses had more chance to survive as they looked after only less number of people.","6f9267bb":"We require two columns: PassengerId and Survived of the test dataset.","78e40fec":"62.96% of the people in Pclass 1 survived.\n\n47.28% of the people in Pclass 2 survived.\n\n24.23% of the people in Pclass 3 survived.\n\n","e603741e":"We can map fare column into four groups from 1 to 4 based on its value. We can also fill the missing fare value in the test dataset.","6f2cb60b":"By looking at the above output,we can see that the title is the second word. So we can extract the title from the second word of the name. Be careful to remove the punctuation marks.","1bdc918c":"We are inputting two files\n1. Test.csv\n2. Train.csv\n\nWe will train the model using 'Train.csv' and we are going to test it using 'Test.csv'","61b9afd4":"We have Null values in age column. To properly give a value to the missing places, we should compare it with the title(Mr, Mrs etc.) which is obtained from the name of the passenger.Through the title, we can estimate the approximate age of the passenger and add that value to the age column.","67b0abfa":"I will be using 5 different models to test the data and will select the best one out of it.\n\nThe models used are:\n\n1. Logistic Regression\n2. Support Vector Machines (SVM)\n3. K-Nearest Neighbours (KNN)\n4. Gradient Boosting Classifier\n5. Random Forest Classifier","930ad6a7":"# <center>Titanic Dataset for Beginners<\/center>"}}