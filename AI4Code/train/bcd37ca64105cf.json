{"cell_type":{"e48da807":"code","223794b4":"code","5c317d33":"code","86be3b3b":"code","97764fb5":"code","95d3a8f0":"code","b155c660":"code","68b944a5":"code","c96a20a2":"code","4f90ca46":"code","bb3e3a02":"code","51619f58":"code","78fc3d41":"markdown","fee51003":"markdown","dccadc8b":"markdown","d3d39f3e":"markdown","4212a8f6":"markdown","66c471fc":"markdown","3d82dd44":"markdown","a5366107":"markdown"},"source":{"e48da807":"import pandas as pd\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nimport re","223794b4":"rcc_train = pd.read_csv(\"\/kaggle\/input\/interbank20\/rcc_train.csv\")\nse_train = pd.read_csv(\"\/kaggle\/input\/interbank20\/se_train.csv\", index_col=\"key_value\")\ncenso_train = pd.read_csv(\"\/kaggle\/input\/interbank20\/censo_train.csv\", index_col=\"key_value\")\ny_train = pd.read_csv(\"\/kaggle\/input\/interbank20\/y_train.csv\", index_col=\"key_value\").target\n\nrcc_test= pd.read_csv(\"\/kaggle\/input\/interbank20\/rcc_test.csv\")\nse_test= pd.read_csv(\"\/kaggle\/input\/interbank20\/se_test.csv\", index_col=\"key_value\")\ncenso_test= pd.read_csv(\"\/kaggle\/input\/interbank20\/censo_test.csv\", index_col=\"key_value\")","5c317d33":"bins = [-1, 0, 10, 20, 30, 60, 90, 180, 360, 720, float(\"inf\")]\nrcc_train[\"condicion\"] = pd.cut(rcc_train.condicion, bins)\nrcc_test[\"condicion\"] = pd.cut(rcc_test.condicion, bins)","86be3b3b":"def makeCt(df, c, aggfunc=sum):\n    try:\n        ct = pd.crosstab(df.key_value, df[c].fillna(\"N\/A\"), values=df.saldo, aggfunc=aggfunc)\n    except:\n        ct = pd.crosstab(df.key_value, df[c], values=df.saldo, aggfunc=aggfunc)\n    ct.columns = [f\"{c}_{aggfunc.__name__}_{v}\" for v in ct.columns]\n    return ct","97764fb5":"train = []\ntest = []\naggfuncs = [len, sum]\nfor c in rcc_train.drop([\"codmes\", \"key_value\", \"saldo\"], axis=1):\n    print(\"haciendo\", c)\n    train.extend([makeCt(rcc_train, c, aggfunc) for aggfunc in aggfuncs])\n    test.extend([makeCt(rcc_test, c, aggfunc) for aggfunc in aggfuncs])","95d3a8f0":"train = pd.concat(train, axis=1)\ntest = pd.concat(test, axis=1)","b155c660":"train = train.join(censo_train).join(se_train)\ntest = test.join(censo_test).join(se_test)","68b944a5":"keep_cols = list(set(train.columns).intersection(set(test.columns)))\ntrain = train[keep_cols]\ntest = test[keep_cols]\nlen(set(train.columns) - set(test.columns)) , len(set(test.columns) - set(train.columns))","c96a20a2":"test = test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_-]+', '', x))\ntrain = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_-]+', '', x))","4f90ca46":"folds = [train.index[t] for t, v in KFold(5).split(train)]\ntest_probs = []\ntrain_probs = []\nfi = []\nfor i, idx in enumerate(folds):\n    print(\"*\"*10, i, \"*\"*10)\n    Xt = train.loc[idx]\n    yt = y_train.loc[Xt.index]\n\n    Xv = train.drop(Xt.index)\n    yv = y_train.loc[Xv.index]\n    \n    learner = LGBMClassifier(n_estimators=1000)\n    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n                eval_set=[(Xt, yt), (Xv, yv)], verbose=50)\n    test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n    train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n    fi.append(pd.Series(learner.feature_importances_ \/ learner.feature_importances_.sum(), index=Xt.columns))\n          \ntest_probs = pd.concat(test_probs, axis=1).mean(axis=1)\ntrain_probs = pd.concat(train_probs)\nfi = pd.concat(fi, axis=1).mean(axis=1)\n\nprint(\"*\" * 21)\nprint(\"roc auc estimado: \", roc_auc_score(y_train, train_probs.loc[y_train.index]))","bb3e3a02":"fi.sort_values(ascending=False).to_frame()","51619f58":"test_probs.name = \"target\"\ntest_probs.to_csv(\"benchmark1.csv\")","78fc3d41":"### Incorporamos la Informaci\u00f3n adicional existente en las tablas socio econ\u00f3micas y del censo. Es un simple join porque ambas tienen key_value \u00fanicos\n#### Por el momento no incorporamos la informaci\u00f3n tributaria porque requiere un tratamiento m\u00e1s complejo que queda para futuras revisiones","fee51003":"### Entrenamiento del Modelo\n\nPara entrenar nuestro modelo vamos a usar LightGBM","dccadc8b":"# Script para generar la soluci\u00f3n del Primer Benchmark de la Competencia\n\n## Si no presentaste a\u00fan tu primera soluci\u00f3n, tenes la oportunidad de hacerlo en pocos Clicks!\n\n**Hola! **  \n  \nEste Script es un Ejemplo de Procesamiento de los Datos, Modelado y Generaci\u00f3n de una Soluci\u00f3n.\n\nAgregamos una peque\u00f1a explicaci\u00f3n de lo que se hace en cada paso para ayudar a los que est\u00e1n comenzando ahora\n","d3d39f3e":"### Vamos a trabajar ahora con la base de **RCC**:\n* Discretizamos los d\u00edas de atraso para poder manipularla mejor\n* Hacemos tablas cruzadas sobre key_value y cada variable de inter\u00e9s, utilizando distintas funciones de agregaci\u00f3n sobre el saldo del producto","4212a8f6":"### Importamos las librer\u00edas que vamos a utilizar","66c471fc":"### Por la naturaleza de las variables creadas, nos aseguramos que solo se utilicen variables existentes en ambos conjuntos de datos (train y test)","3d82dd44":"### Lectura de las Bases\n\nObservamos los datos que tenemos disponibles en https:\/\/www.kaggle.com\/c\/interbank20\/data\n\nVamos a trabajar ahora con todas las bases disponibles","a5366107":"### Guardado del modelo para hacer la presentaci\u00f3n\n\nFinalmente creamos el archivo CSV que podemos subir como nuestra Soluci\u00f3n a la competencia\n\nEmpez\u00e1 con este archivo y luego podes seguir mejor\u00e1ndolo a ver si sub\u00eds en posiciones!"}}