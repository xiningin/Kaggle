{"cell_type":{"89a351b2":"code","ed53ae96":"code","a87868c0":"code","c2346159":"code","7fb87009":"code","59f30d7f":"code","86368887":"code","77e9dad6":"code","6f34d7b4":"code","1ccf6ffa":"code","6c4013c6":"code","0ac04ff8":"code","b7010fd7":"code","5996bc07":"code","a73501d8":"code","36577470":"code","1dbdda17":"code","a4b82a69":"code","2220784c":"code","67a18038":"code","ce9e0391":"code","c537da53":"code","7b8beb0f":"code","393c03f6":"code","c9b1e38c":"code","dbba01b9":"code","e89bac88":"code","cbdddcf9":"code","7d7235e1":"code","d23d7919":"code","b048c393":"code","f6c24357":"code","79eff06b":"code","baef2c4c":"code","dade4650":"code","f3c6c7fb":"code","9452399f":"code","7a9cf662":"code","7bdfbde6":"code","5bb95383":"code","1556205d":"code","ce258d51":"code","feb9ed45":"code","fab84174":"code","d550206e":"code","1a150a64":"code","d224de81":"code","ca46069f":"code","c9b7d2fa":"code","1bfbad9e":"code","d62d8243":"code","cb7ed074":"code","8d8fcc66":"markdown","a3ee4a1d":"markdown","26d0cb48":"markdown","36497e41":"markdown","435c113a":"markdown","21484fd9":"markdown","a7fd8acc":"markdown","9fbcf037":"markdown","9cc78df5":"markdown","a0176a61":"markdown","a97e204c":"markdown","b861a7b3":"markdown","9be17496":"markdown","66cf23e0":"markdown","ddf71ff4":"markdown","6016ff34":"markdown","444a5988":"markdown","9882b886":"markdown","9251875b":"markdown","bffd7135":"markdown","52fc077f":"markdown","953a6244":"markdown","f9beb4c8":"markdown","848049e6":"markdown","6d13d974":"markdown","1338b9b1":"markdown","16b960d2":"markdown","e10e4571":"markdown"},"source":{"89a351b2":"# import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npd.set_option('display.max_columns', 100)\n","ed53ae96":"# Import data set\n\ncars = pd.read_csv('..\/input\/usedcarscatalog\/cars.csv')\ncars.head()","a87868c0":"cars = cars.drop(columns=['feature_0','feature_1','feature_2','feature_3','feature_4','feature_5','feature_6','feature_7','feature_8','feature_9'], axis=1)\ncars.head()","c2346159":"cars.shape","7fb87009":"cars.describe()","59f30d7f":"cars.columns","86368887":"cars.dtypes","77e9dad6":"cars.isnull().sum()","6f34d7b4":"cars = cars.dropna()\ncars.isnull().sum()","1ccf6ffa":"# Calculate the age of the car\n\ncars['age'] = 2020 - cars['year_produced']\ncars.head()","6c4013c6":"# All numeric (float and int) variables in the dataset\ncars_numeric = cars.select_dtypes(include=['float64', 'int64'])\ncars_numeric.head()","0ac04ff8":"# Correlation matrix\ncor = cars_numeric.corr()\ncor","b7010fd7":"# Figure size\nplt.figure(figsize=(16,8))\n\n# Heatmap\nsns.heatmap(cor, cmap=\"YlGnBu\", annot=True)\nplt.show()","5996bc07":"plt.figure(figsize=(25, 6))\n\nplt.subplot(1,3,1)\nplt1 = cars.manufacturer_name.value_counts().plot(kind='bar')\nplt.title('Companies Histogram')\nplt1.set(xlabel = 'Car company', ylabel='Frequency of company')\n\nplt.subplot(1,3,2)\nplt1 = cars.body_type.value_counts().plot(kind='bar')\nplt.title('Body Type')\nplt1.set(xlabel = 'Body Type', ylabel='Frequency of Body Type')\n\nplt.subplot(1,3,3)\nplt1 = cars.engine_type.value_counts().plot(kind='bar')\nplt.title('Engine Type Histogram')\nplt1.set(xlabel = 'Engine Type', ylabel='Frequency of Engine type')\n\nplt.show()","a73501d8":"plt.figure(figsize=(30, 10))\n\ndf = pd.DataFrame(cars.groupby(['manufacturer_name'])['price_usd'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Company Name vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(cars.groupby(['engine_fuel'])['price_usd'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Fuel Type vs Average Price')\nplt.show()\n\ndf = pd.DataFrame(cars.groupby(['body_type'])['price_usd'].mean().sort_values(ascending = False))\ndf.plot.bar()\nplt.title('Car Type vs Average Price')\nplt.show()","36577470":"cars['price_usd'] = cars['price_usd'].astype('float64')\ntemp = cars.copy()\n\ntable = temp.groupby(['manufacturer_name'])['price_usd'].mean()\ntemp = temp.merge(table.reset_index(), how='left', on='manufacturer_name')\nbins = [0,10000,25000,50000]\ncars_bins = ['Budget','Medium', 'Highend']","1dbdda17":"temp.head()","a4b82a69":"cars['CarRange'] = pd.cut(temp['price_usd_y'], bins,  right=False, labels=cars_bins)\ncars.head()","2220784c":"## We will leave out variables like \"manufacturer_name\",\"model_name\",\"location region\" \n## We will be using CarsRange variable instead of these as discussed above.","67a18038":"cars_new = cars[['transmission','color','odometer_value','engine_fuel','engine_has_gas','engine_type','engine_capacity','body_type'\n                , 'has_warranty','state','drivetrain','is_exchangeable','number_of_photos', 'up_counter','duration_listed', 'age','CarRange','price_usd']]\ncars_new.head()","ce9e0391":"# Define a function to generate dummy variables and merging it with data frame\n\ndef dummies(x,df):\n    temp = pd.get_dummies(df[[x]], drop_first=True)\n    df = pd.concat([df,temp], axis=1)\n    df.drop([x], axis=1, inplace=True)\n    return df\n\n# Apply function to the cars_new df\ncars_new = dummies('transmission', cars_new)\ncars_new = dummies('color', cars_new)\ncars_new = dummies('engine_fuel', cars_new)\ncars_new = dummies('engine_has_gas', cars_new)\ncars_new = dummies('engine_type', cars_new)\ncars_new = dummies('body_type', cars_new)\ncars_new = dummies('has_warranty', cars_new)\ncars_new = dummies('state', cars_new)\ncars_new = dummies('drivetrain', cars_new)\ncars_new = dummies('is_exchangeable', cars_new)\ncars_new = dummies('CarRange', cars_new)","c537da53":"cars_new.head()","7b8beb0f":"cars_new.shape","393c03f6":"from sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(cars_new, train_size=0.7, random_state=42) ","c9b1e38c":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nnum_vars= ['odometer_value', 'engine_capacity', 'number_of_photos','up_counter','duration_listed', 'age','price_usd']\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])","dbba01b9":"df_train.head()","e89bac88":"# correlation\n\nplt.figure(figsize = (30, 25))\nsns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()","cbdddcf9":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","7d7235e1":"# dividing variables in to X and y\ny_train = df_train.pop('price_usd')\nX_train = df_train","d23d7919":"lm = LinearRegression()\nlm.fit(X_train, y_train)\nrfe = RFE(lm, 10)\nrfe = rfe.fit(X_train, y_train)","b048c393":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","f6c24357":"X_train.columns[rfe.support_]","79eff06b":"X_train_rfe = X_train[X_train.columns[rfe.support_]]\nX_train_rfe.head()","baef2c4c":"# Building a model\n\ndef build_Lr_model(X,y):\n    X = sm.add_constant(X) #add constant\n    lm = sm.OLS(y,X).fit() #fit the model\n    print(lm.summary())\n    return X\n\ndef checkingVIF(X):\n    vif = pd.DataFrame()\n    vif['features'] = X.columns\n    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n    vif['VIF'] = round(vif['VIF'], 2)\n    vif = vif.sort_values(by = \"VIF\", ascending = False)\n    return(vif)","dade4650":"X_train_1 = build_Lr_model(X_train_rfe, y_train)","f3c6c7fb":"checkingVIF(X_train_1)","9452399f":"lm = sm.OLS(y_train,X_train_1).fit()\ny_train_price = lm.predict(X_train_1)","7a9cf662":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_price), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18)  ","7bdfbde6":"num_vars= ['odometer_value', 'engine_capacity', 'number_of_photos','up_counter','duration_listed', 'age','price_usd']\ndf_test[num_vars] = scaler.fit_transform(df_test[num_vars])","5bb95383":"#Dividing into X and y\ny_test = df_test.pop('price_usd')\nX_test = df_test","1556205d":"# Now let's use our model to make predictions.\nX_train_1 = X_train_1.drop('const',axis=1)\n# Creating X_test_new dataframe by dropping variables from X_test\nX_train_1 = X_test[X_train_1.columns]\n\n# Adding a constant variable \nX_train_1 = sm.add_constant(X_train_1)","ce258d51":"# Making predictions\ny_pred = lm.predict(X_train_1)","feb9ed45":"from sklearn.metrics import r2_score \nr2_score(y_test, y_pred)","fab84174":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import r2_score,mean_squared_error","d550206e":"polynomial = PolynomialFeatures(degree=2)\npolynomial_model = polynomial.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(polynomial_model,y, train_size=0.7, random_state=42)\n\n# Build second LR model using polynomial features\nlr_model_2 = LinearRegression().fit(X_train,y_train)\n\n\n#PRedict the values\ny_train_pred = lr_model_2.predict(X_train)\n\n#Predict test values\ny_test_pred = lr_model_2.predict(X_test)","1a150a64":"print(lr_model_2.score(X_test, y_test))","d224de81":"#Dividing into X and y\ny = cars_new.pop('price_usd')\nX = cars_new","ca46069f":"X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7, random_state=42)","c9b7d2fa":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nrf = RandomForestRegressor()\n\nparam_grid = { \"criterion\" : [\"mse\"]\n              , \"min_samples_leaf\" : [1,5,1]\n              , \"min_samples_split\" : [1,5,1]\n              , \"max_depth\": [10]\n              , \"n_estimators\": [500]}\n\ngs = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\ngs = gs.fit(X_train, y_train)","1bfbad9e":"print(gs.best_score_)\nprint(gs.best_params_)","d62d8243":"bp = gs.best_params_\nforest = RandomForestRegressor(criterion=bp['criterion'],\n                              min_samples_leaf=bp['min_samples_leaf'],\n                              min_samples_split=bp['min_samples_split'],\n                              max_depth=bp['max_depth'],\n                              n_estimators=bp['n_estimators'])\nforest.fit(X_train, y_train)\n\nprint('Score: %.2f' % forest.score(X_test, y_test))","cb7ed074":"important_features = pd.Series(data=forest.feature_importances_,index=X_train.columns)\nimportant_features.sort_values(ascending=False,inplace=True)\nimportant_features","8d8fcc66":"**Inference:**\n1. `Volkswagen` is preffered than other cars.\n2. `Sedan` seems to be the popular type.\n3.  Vehicles with `gasoline` are preffered.","a3ee4a1d":"Error terms seem to be approximately normally distributed, so the assumption on the linear modeling seems to be fulfilled.","26d0cb48":"**2.2 Visualising Categorical Data**","36497e41":"**Using Polynomial Featurs, Accuracy increases upto 77% which is near good accuracy.**","435c113a":"**2.1 Visualizing Numerical Data**","21484fd9":"**Model 2 . Linear Regression Using Polynomial Features**","a7fd8acc":"**Residual Analysis of Model**","9fbcf037":"**Summary:**\n1. As predicted in EDA, `Age` is an important factor in Car Price Prediction.\n2. `DriveTrain Font, Odometer Value, Engine Capacity` are also in top 5 Features for Price Prediction. In EDA, we have identified these as the important features.\n3. We have obtained 88% Accuracy using Random Forest.","9cc78df5":"### Step 1:Basic Data Quality Checks","a0176a61":"No Null Values. We can proceed with EDA Now.","a97e204c":"**2.4 Dummy Variables**","b861a7b3":"**Prediction and Evaluation**","9be17496":"Here we can see that \"Year Produced\" or \"age\" has highest correlation with the Price of the car.\n\nAlso it is correlated with Odometer Value, Number of photos uploaded by user, and engine capacity.","66cf23e0":"### Step 2: EDA","ddf71ff4":"### Step 4 : Model Building","6016ff34":"P values are less than 0.05. \n\nHence checking the VIF values.","444a5988":"We dont what the features (0 to 9) are for. Hence dropping these features.","9882b886":"There are only 10 Null values for \"Engine Capacity\". \n\nDropping these null values.","9251875b":"`Age, Odometer Value, Engine Capacity` are some of the high correaltion variables.","bffd7135":"**Model 3 : Random Forest**","52fc077f":"**MODEL 1**","953a6244":"**We are getting accuracy of 88% using Random Forest Regressor which is pretty good accuracy.**","f9beb4c8":"### Step 3 : Train Test Split","848049e6":"**57% Accuracy is low for this model.**\n\nWe can train other models like Random Forest. Also we can try using polynomial features.","6d13d974":"**2.3 Binning Companies based on Average Price**\n\nWe have around 45 different Car Manufacturing Companies with Different Model Names. \nIf we create dummy variables for all these names, it will result in large number of coulmns which is not feasible for model building.\nHence, we will try and create different groups based on Average Price of the cars.","1338b9b1":"**Model 1 : Linear Regression**","16b960d2":"**Inference:**\n1. `Porsche and Jaguar` seems to have highest average price.\n2. `Hybrid` vehicles have high average price than both Diesel and Gasoline vehicles.\n3. `SUV` has the highest average price.\n","e10e4571":"**Building model using statsmodel, for the detailed statistics**"}}