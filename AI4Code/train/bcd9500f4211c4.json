{"cell_type":{"cf24e99d":"code","fcd7193f":"code","c8628618":"code","5dfa1409":"code","09cbe99c":"code","cb6a5ea6":"code","89b661ef":"code","2a63e93d":"code","66a30c72":"code","30951229":"code","74cf361f":"code","1503979d":"code","1164af5b":"code","59680b52":"code","74324ad2":"code","c91e2dbf":"code","88a76073":"code","c5ae3527":"code","ed8e4f49":"markdown","f8ac63ed":"markdown","5edb21f9":"markdown","250200e7":"markdown","a068684c":"markdown","8f992833":"markdown","d86f9957":"markdown","77066323":"markdown","2b590393":"markdown","7d3b5d7f":"markdown","47f46ce8":"markdown"},"source":{"cf24e99d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fcd7193f":"import pandas as pd\n#..\/input\/sms-spam-collection-dataset\/spam.csv\ndata = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv',encoding=\"ISO-8859-1\")","c8628618":"data.head()\n","5dfa1409":"data=data.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'])\ndata['length']=data['v2'].apply(len)\ndata.describe()","09cbe99c":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata['length'].plot(bins=50,kind='hist')","cb6a5ea6":"data.hist(column='length', by='v1',bins=50,figsize=(10,4))\nplt.show()","89b661ef":"import string\nfrom string import punctuation\ndef Nopunct():\n    global punc_cleared_F\n    punc_cleared_F=[]\n    for sms in data['v2']:\n        punc_cleared=[char for char in sms if char not in string.punctuation ] \n        punc_cleared= ''.join(punc_cleared)\n        punc_cleared_F.append(punc_cleared)\n    return punc_cleared_F\n","2a63e93d":" Nopunct()","66a30c72":"! pip install nltk\nfrom nltk.corpus import stopwords\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n","30951229":"NoStopwords_F=[]\nNoStopwords=[]\nword=\"\"\nfor sentence in  punc_cleared_F:\n  NoStopwords = [word for word in sentence.split() if word.lower() not in stopwords.words('english')]\n  NoStopwords_F.append(NoStopwords)\n","74cf361f":"def text_process(mess):\n    global punc_cleared_F\n    punc_cleared_F=[]\n    punc_cleared=[char for char in mess if char not in string.punctuation ] \n    punc_cleared= ''.join(punc_cleared)\n    return [word for word in punc_cleared.split() if word.lower() not in stopwords.words('english')]","1503979d":"data['v2'].head().apply(text_process)","1164af5b":"from sklearn.feature_extraction.text import CountVectorizer\n\nbow = CountVectorizer(analyzer=text_process).fit(data['v2'])\n","59680b52":"msg4= data['v2'][3]\nprint(msg4)","74324ad2":"bow4=bow.transform([msg4])\nprint(bow4.shape)","c91e2dbf":"data_bow=bow.transform(data['v2'])\nprint('Shape of Sparse Matrix: ', data_bow.shape)\nprint('none-zero occurrence amount: ', data_bow.nnz)\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer=TfidfTransformer().fit(data_bow)\ntfidf4=tfidf_transformer.transform(bow4)\nprint(tfidf4)\ndata_tfidf= tfidf_transformer.transform(data_bow)\nprint(data_bow.shape)\nfrom sklearn.naive_bayes import MultinomialNB\n\nspam_detector=MultinomialNB().fit(data_tfidf,data['v1'])\nprint(spam_detector.predict(tfidf4[0]))\nprint(data['v1'][3])\nall_predictions=spam_detector.predict(data_tfidf)\n\nprint(all_predictions)\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(data['v1'],all_predictions))\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test= train_test_split(data['v2'],data['v1'], test_size=0.2)\nfrom sklearn.pipeline import Pipeline \n\npipeline_sms=Pipeline([('bow',CountVectorizer(analyzer=text_process)),('tfidf',TfidfTransformer()),('classifier',MultinomialNB())])\npipeline_sms.fit(x_train,y_train)","88a76073":"prediction=pipeline_sms.predict(x_test)","c5ae3527":"print(classification_report(prediction,y_test))","ed8e4f49":"We want to use SMS datasets which is on kaggle ...\nThe files contain one message per line. Each line is composed by two columns: v1 contains the label (ham or spam) and v2 contains the raw text.","f8ac63ed":"# ***This is going to be a NLP tutorial for those who know nothing about NLP!***","5edb21f9":"## PreProcessing","250200e7":"there is two way for learning something : one is to start from scratch and learn basics and step by step go further and learn high level of that thing or start upside down which means like learning baseball you are in game from start!","a068684c":"### step2 : clear stop words","8f992833":"### Step 1 & 2 in one function","d86f9957":"**this tutorial is going to be like the second way: UPside down way**\nso you're gonno learn it through doing a simple project before ","77066323":"## ***Preprocessing***","2b590393":"## ***Importing Data***","7d3b5d7f":"### step 1: delete PUNCTUATION","47f46ce8":"### step 3 Count Vec"}}