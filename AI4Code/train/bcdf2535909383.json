{"cell_type":{"2d597cb6":"code","73b6ba16":"code","4987f954":"code","7a2f2849":"code","c4768157":"code","b7270e57":"code","6bd17b85":"code","8566da04":"code","d2670a14":"code","13582f13":"code","de8b5d29":"code","4cb63819":"code","5c7227ab":"code","9c4051c8":"code","59fa547c":"code","54b4a646":"code","f5b2c61a":"code","30f44086":"code","a7405945":"code","83eb7ce9":"code","ba9ab186":"code","87df8597":"code","87b50ad0":"code","3d55dac3":"markdown","afdcfec8":"markdown","03100d19":"markdown","a555de1f":"markdown","b0862052":"markdown","9ff0d5b2":"markdown","6a726490":"markdown","f881b079":"markdown","f90bf562":"markdown","55e0079d":"markdown","f60ba52c":"markdown","9b2b192c":"markdown","e5473099":"markdown","fe1a3c40":"markdown","06b820fe":"markdown","c32f5f8a":"markdown","c6784767":"markdown","2bb1cf09":"markdown","c479d5f9":"markdown","cec6c1c7":"markdown","f195cdfa":"markdown"},"source":{"2d597cb6":"\n# Import TensorFlow and TensorFlow Datasets\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Helper libraries\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n","73b6ba16":"train_dataset = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv').values\ntest_dataset = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv').values\n\nnum_train_examples = len(train_dataset)\nnum_test_examples = len(test_dataset)\n\nprint(\"Number of training examples: {}\".format(num_train_examples))\nprint(\"Number of test examples:     {}\".format(num_test_examples))","4987f954":"class_names = ['T-shirt\/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']\nnum_classes = len(class_names)","7a2f2849":"\n# The map function applies the normalize function to each element in the train\n# and test datasets\n\ntrain_dataset_x = train_dataset[:,1:] \/ 255\ntrain_dataset_x = train_dataset_x.reshape((num_train_examples, 28, 28, 1))\ntrain_dataset_y = train_dataset[:,0]\n\ntest_dataset_x = test_dataset[:,1:] \/ 255\ntest_dataset_x = test_dataset_x.reshape((num_test_examples, 28, 28, 1))\ntest_dataset_y = test_dataset[:,0]\n","c4768157":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n                           input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)\n])","b7270e57":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","6bd17b85":"BATCH_SIZE = 32\n\ntrain_datagen = ImageDataGenerator()\ntrain_generator = train_datagen.flow(train_dataset_x, train_dataset_y, shuffle=True, batch_size=BATCH_SIZE)\n\ntest_datagen = ImageDataGenerator()\ntest_generator = test_datagen.flow(test_dataset_x, test_dataset_y, shuffle=False, batch_size=BATCH_SIZE)\n","8566da04":"model.fit_generator(train_generator, epochs=5, steps_per_epoch=math.ceil(num_train_examples\/BATCH_SIZE))","d2670a14":"test_loss, test_accuracy = model.evaluate(test_generator, steps=math.ceil(num_test_examples\/32))\nprint('Accuracy on test dataset:', test_accuracy)","13582f13":"predictions = model.predict(test_generator)","de8b5d29":"predictions.shape\n","4cb63819":"predictions[0]","5c7227ab":"np.argmax(predictions[6])","9c4051c8":"test_dataset_y[6]","59fa547c":"def plot_image(i, predictions_array, true_labels, images):\n  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  \n  plt.imshow(img[...,0], cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n  \n  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n                                100*np.max(predictions_array),\n                                class_names[true_label]),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n  predictions_array, true_label = predictions_array[i], true_label[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n  plt.ylim([0, 1]) \n  predicted_label = np.argmax(predictions_array)\n  \n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label].set_color('blue')","54b4a646":"i = 0\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions, test_dataset_y, test_dataset_x)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, test_dataset_y)","f5b2c61a":"i = 12\nplt.figure(figsize=(6,3))\nplt.subplot(1,2,1)\nplot_image(i, predictions, test_dataset_y, test_dataset_x)\nplt.subplot(1,2,2)\nplot_value_array(i, predictions, test_dataset_y)","30f44086":"# Plot the first X test images, their predicted label, and the true label\n# Color correct predictions in blue, incorrect predictions in red\nnum_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i, predictions, test_dataset_y, test_dataset_x)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i, predictions, test_dataset_y)\n","a7405945":"# Grab an image from the test dataset\nimg = test_dataset_x[2,:]\n\nprint(img.shape)","83eb7ce9":"# Add the image to a batch where it's the only member.\nimg = np.array([img])\n\nprint(img.shape)","ba9ab186":"predictions_single = model.predict(img)\n\nprint(predictions_single)","87df8597":"plot_value_array(0, predictions_single, test_dataset_y)\n_ = plt.xticks(range(10), class_names, rotation=45)","87b50ad0":"np.argmax(predictions_single[0])","3d55dac3":"Finally, use the trained model to make a prediction about a single image. ","afdcfec8":"## Preprocess the data\n\nThe value of each pixel in the image data is an integer in the range `[0,255]`. For the model to work properly, these values need to be normalized to the range `[0,1]`. So here we create a normalization function, and then apply it to each image in the test and train datasets.","03100d19":"Let's look at the 0th image, predictions, and prediction array. ","a555de1f":"Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:","b0862052":"## Build the CNN model\n","9ff0d5b2":"### Compile the model\n\nBefore the model is ready for training, it needs a few more settings. These are added during the model's *compile* step:\n\n* *Loss function* \u2014 An algorithm for measuring how far the model's outputs are from the desired output. The goal of training is this measures loss.\n* *Optimizer* \u2014An algorithm for adjusting the inner parameters of the model in order to minimize loss.\n* *Metrics* \u2014Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified.","6a726490":"### Setup the layers\n","f881b079":"And, as before, the model predicts a label of 6 (shirt).","f90bf562":"We can graph this to look at the full set of 10 class predictions","55e0079d":"A prediction is an array of 10 numbers. These describe the \"confidence\" of the model that the image corresponds to each of the 10 different articles of clothing. We can see which label has the highest confidence value:","f60ba52c":"# Classifying Images of Clothing with CNNs","9b2b192c":"`model.predict` returns a list of lists, one for each image in the batch of data. Grab the predictions for our (only) image in the batch:","e5473099":"## Import the Fashion MNIST dataset","fe1a3c40":"## Evaluate accuracy","06b820fe":"## Train the model\n\nFirst, we define the iteration behavior for the train dataset:\n1. Repeat forever by specifying `dataset.repeat()` (the `epochs` parameter described below limits how long we perform training).\n2. The `dataset.shuffle(60000)` randomizes the order so our model cannot learn anything from the order of the examples.\n3. And `dataset.batch(32)` tells `model.fit` to use batches of 32 images and labels when updating the model variables.\n\nTraining is performed by calling the `model.fit` method:\n1. Feed the training data to the model using `train_dataset`.\n2. The model learns to associate images and labels.\n3. The `epochs=5` parameter limits training to 5 full iterations of the training dataset, so a total of 5 * 60000 = 300000 examples.\n\n(Don't worry about `steps_per_epoch`, the requirement to have this flag will soon be removed.)","c32f5f8a":"Let's plot several images with their predictions. Correct prediction labels are blue and incorrect prediction labels are red. The number gives the percent (out of 100) for the predicted label. Note that it can be wrong even when very confident. ","c6784767":"Now predict the image:","2bb1cf09":"So the model is most confident that this image is a shirt, or `class_names[6]`. And we can check the test label to see this is correct:","c479d5f9":"## Import dependencies","cec6c1c7":"`tf.keras` models are optimized to make predictions on a *batch*, or collection, of examples at once. So even though we're using a single image, we need to add it to a list:","f195cdfa":"## Make predictions and explore\n\nWith the model trained, we can use it to make predictions about some images."}}