{"cell_type":{"4d434a86":"code","88fa2f0a":"code","18e74f42":"code","a6b3c03c":"code","62083249":"code","a46fcd2b":"code","c4dcdd39":"code","a6772f67":"code","5168f7b8":"code","abfb58e9":"code","723ac096":"code","4d5f9dd9":"code","c787af18":"code","70579ead":"code","f15bec72":"code","66879c54":"code","1d31b443":"code","99be5098":"code","1b1dc334":"code","f05c7098":"code","63bdb3e0":"code","2b1eed72":"code","ff37f93d":"code","6929b9bc":"code","2ea1f05d":"code","d1d1d4c4":"code","db00c37f":"code","1ca98f8d":"code","3b9ebca5":"code","f3979e5b":"code","4b509175":"code","ad60f639":"code","70568233":"code","ac001c9b":"code","62627d2c":"code","6cd5fc25":"code","49117078":"code","8f9a900a":"code","dc0930ce":"code","f4d14417":"code","fbc5942f":"code","ad9316eb":"code","ee6e9926":"markdown","1d93f916":"markdown","cf7afe54":"markdown","7179d253":"markdown","94883d08":"markdown","201cbbd2":"markdown","e237d6fd":"markdown","8d35ab56":"markdown"},"source":{"4d434a86":"!ls ..\/input\/fire-test\/challenge1\/","88fa2f0a":"from fastai.vision import *\nfrom fastai import *","18e74f42":"path = Path('..\/input\/fire-test\/challenge1')","a6b3c03c":"smoke_path = path\/'smoke'\nno_smoke_path = path\/'no_smoke'","62083249":"smoke_filenames = get_files(smoke_path)\nno_smoke_filenames = get_files(no_smoke_path)\nlen(smoke_filenames),len(no_smoke_filenames)","a46fcd2b":"smoke_img = open_image(smoke_filenames[0])\nsmoke_img.size","c4dcdd39":"smoke_img","a6772f67":"no_smoke_img = open_image(no_smoke_filenames[0])\nno_smoke_img.size","5168f7b8":"no_smoke_img","abfb58e9":"tfms = get_transforms()","723ac096":"data = (ImageList\n        .from_folder(path,include=['smoke','no_smoke'])\n        .split_by_rand_pct()\n        .label_from_folder()\n        .transform(tfms,size=(128,128))\n        .databunch(bs=64)\n        .normalize(imagenet_stats)\n)","4d5f9dd9":"data.show_batch(rows=3,figsize=(12,10))","c787af18":"# loading imagenet pre-trained model, also using mix precision for training \nlearn = cnn_learner(data,models.resnet34,metrics=[accuracy],model_dir='\/kaggle\/working').to_fp16() ","70579ead":"learn.model[1] # customized Head","f15bec72":"# Finding best learning rate\nlearn.lr_find()","66879c54":"learn.recorder.plot(suggestion=True)","1d31b443":"lr = 3e-3\nlearn.fit_one_cycle(3,slice(lr))","99be5098":"learn.unfreeze() # Unfreeze the body, fine tune the whole model","1b1dc334":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","f05c7098":"learn.save('resnet34-stage-1-128')","63bdb3e0":"learn.fit_one_cycle(5,slice(1e-5,lr\/5))","2b1eed72":"data_256 = (ImageList\n        .from_folder(path,include=['smoke','no_smoke'])\n        .split_by_rand_pct()\n        .label_from_folder()\n        .transform(tfms,size=(256,256))\n        .databunch(bs=64)\n        .normalize(imagenet_stats)\n)","ff37f93d":"learn.save('res34-stage-2-128')","6929b9bc":"learn.data = data_256\nlearn.freeze_to(-1)","2ea1f05d":"learn.to_fp16(); # using mix precision ","d1d1d4c4":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","db00c37f":"lr = 1e-3\nlearn.fit_one_cycle(3,slice(lr))","1ca98f8d":"learn.unfreeze()","3b9ebca5":"learn.save('res34-stage-1-256')","f3979e5b":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","4b509175":"learn.fit_one_cycle(5,slice(1e-5,lr\/5))","ad60f639":"learn.save('res34-stage-2-256')","70568233":"y_p, y, loss = learn.get_preds(with_loss=True)","ac001c9b":"y_p.shape,y.shape","62627d2c":"pred = y_p.argmax(dim=-1).float()","6cd5fc25":"pred.shape","49117078":"from sklearn.metrics import f1_score","8f9a900a":"f1_score(y,pred)","dc0930ce":"learn.show_results()","f4d14417":"interp = ClassificationInterpretation(learn, y_p, y, loss)","fbc5942f":"interp.plot_confusion_matrix()","ad9316eb":"interp.plot_top_losses(9,figsize=(12,12))","ee6e9926":"Let's take a look of the first image in both folders","1d93f916":"Progressive resizing to 256","cf7afe54":"Therefore, the dataset is balanced, about 50% smoke and 50% non smoke images. Which is not what happend in the real world","7179d253":"Building piplines\n\nArgumentation:\n1. flip left and right\n2. rotate 10 degree\n3. lighting .2\n4. zoom 10%\n5. warp angle 20%\n\nResize img size to (128,128)","94883d08":"Reading the path of files","201cbbd2":"# Fin\n\n1. If we are fitting the model with the balanced dataset, it doesn't reflect the real world case (where you have maybe 99% of time no smoke, only 1% of time that has smoke)\n2. As you can see from the top losses, the model is not doing a very good job prediction the early fires. When the smokes are in the initial phase,the model is not able to capture the smoke.","e237d6fd":"# Next\n\n1. To build the early fire detector, we will need to remove the easy examples (the late fire with lots of smokes in the dataset)\n2. Use segmentation \/ bounding boxes \n3. To have more data","8d35ab56":"Using imagenet pretrained model resnet 34 with customized head (see head arch in the following cell)\n\n1. stacked [maxpool and avgpool]\n2. few drop out, batchnorm, linear layers for more calculation"}}