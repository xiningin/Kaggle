{"cell_type":{"531e2871":"code","0cd0936f":"code","133dc184":"code","149c7e00":"code","36c15ba0":"code","7dab9abb":"code","0849d9f4":"code","18638686":"markdown","9523471b":"markdown","0f4154a8":"markdown"},"source":{"531e2871":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\n\nfrom scipy.stats import describe\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","0cd0936f":"LABELS = [\"isFraud\"]\nall_files = glob.glob(\"..\/input\/lgmodels\/*.csv\")\nall_files","133dc184":"outs = [pd.read_csv(f, index_col=0) for f in all_files]\nconcat_sub = pd.concat(outs, axis=1)\ncols = list(map(lambda x: \"m\" + str(x), range(len(concat_sub.columns))))\nconcat_sub.columns = cols\nconcat_sub.reset_index(inplace=True)","149c7e00":"# check correlation\ncorr = concat_sub.iloc[:,1:].corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(len(cols)+2, len(cols)+2))\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr,mask=mask,cmap='prism',vmin=0.95,center=0,linewidths=1,annot=True,fmt='.4f')","36c15ba0":"rank = np.tril(concat_sub.iloc[:,1:].corr().values,-1)\nm = (rank>0).sum()\nm_gmean, s = 0, 0\nfor n in range(min(rank.shape[0],m)):\n    mx = np.unravel_index(rank.argmin(), rank.shape)\n    w = (m-n)\/(m+n)\n    print(w)\n    m_gmean += w*(np.log(concat_sub.iloc[:,mx[0]+1])+np.log(concat_sub.iloc[:,mx[1]+1]))\/2\n    s += w\n    rank[mx] = 1\nm_gmean = np.exp(m_gmean\/s)","7dab9abb":"describe(m_gmean)","0849d9f4":"concat_sub['isFraud'] = m_gmean\nconcat_sub[['TransactionID','isFraud']].to_csv('stack_gmean.csv', \n                                        index=False, float_format='%.4g')","18638686":"# Weighted GMEAN by inverse correlation","9523471b":"<pre>Credits to the Experts (Please like their kernels)\nAshish Gupta: https:\/\/www.kaggle.com\/roydatascience\/aggregating-the-light-gbm-models-0-9469\nNavaneetha: https:\/\/www.kaggle.com\/krishonaveen\/xtreme-boost-and-feature-engineering\nShugen: https:\/\/www.kaggle.com\/andrew60909\/lgb-starter-r\nKhan HBK: https:\/\/www.kaggle.com\/duykhanh99\/hust-lgb-starter-with-r \nKonstantin: https:\/\/www.kaggle.com\/kyakovlev\/ieee-gb-2-make-amount-useful-again\/output\nAvocado: https:\/\/www.kaggle.com\/iasnobmatsu\/xgb-model-with-feature-engineering\nDavid: https:\/\/www.kaggle.com\/davidcairuz\/feature-engineering-lightgbm-w-gpu\nLyalikov: https:\/\/www.kaggle.com\/timon88\/lgbm-baseline-small-fe-no-blend\nYuanrong: https:\/\/www.kaggle.com\/yw6916\/lgb-xgb-ensemble-stacking-based-on-fea-eng\n<\/pre>","0f4154a8":"# Stacking Approach using GMEAN"}}