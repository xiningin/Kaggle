{"cell_type":{"cfa1a01c":"code","4fbbbcb9":"code","52bd8244":"code","c10cfdff":"code","2e68c2ee":"code","e0cfebca":"code","efdc2361":"code","5cc36d42":"code","336d7273":"code","403bcc61":"code","6b84f539":"code","c1b86216":"code","d48db47a":"code","8d2f0485":"code","0c55cbff":"code","6171a518":"code","92ccc8fa":"code","d4757749":"code","96a8d658":"code","69bbcc67":"code","4a955848":"code","479f0027":"code","b4e17c1f":"code","500e19da":"code","13473369":"code","c425a014":"code","6cc3e138":"code","43a274e8":"code","f58335bd":"code","e903c658":"code","f076d1f9":"code","6185766c":"code","0477b6d6":"code","d829b9a8":"code","7e09fc6b":"code","e19303c8":"code","f6745589":"code","bc11fac1":"code","e078349f":"code","e47dbd09":"code","228923fe":"code","f8bff850":"code","0ee21374":"code","64e095eb":"code","729cb174":"code","23bd2511":"code","0f24f505":"code","88733f57":"code","c2eaf3b6":"code","bc5ee128":"code","2e32e864":"code","93be044f":"code","35d366f3":"code","f8b1c628":"code","cfeb7b98":"code","45b8c4bf":"code","af921b5a":"code","212c6781":"code","1da5914c":"markdown","a51094ab":"markdown","e364de63":"markdown","804256d4":"markdown","8a3afb60":"markdown","8737125c":"markdown","76c523c6":"markdown","b1b61a85":"markdown","99ef8e85":"markdown","c786c952":"markdown","485075b6":"markdown","fbe5fc1e":"markdown","b25baefd":"markdown"},"source":{"cfa1a01c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4fbbbcb9":"# Data preprocessing\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Spliting data \nfrom sklearn.model_selection import train_test_split\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\n\n# Machine Learning\nfrom sklearn.naive_bayes import BernoulliNB\n\n# Metrices\nfrom sklearn.metrics import confusion_matrix,classification_report\n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n# Ignore Warnings~aq\nimport warnings\nwarnings.filterwarnings('ignore')","52bd8244":"# Importing train Datasets\ndf_train=pd.read_csv('..\/input\/titanic\/train.csv')\n\n# Importing test Datasets\ndf_test=pd.read_csv('..\/input\/titanic\/test.csv')","c10cfdff":"df_train.head()","2e68c2ee":"df_test.head()","e0cfebca":"df_train.tail()","efdc2361":"df_test.tail()","5cc36d42":"df_train.sample(10)","336d7273":"df_test.sample(10)","403bcc61":"# Information about train datasets\ndf_train.info()","6b84f539":"# Impormation about test datasets\ndf_test.info()","c1b86216":"# Checking null values for train datasets\ndf_train.isna().sum()","d48db47a":"# Checking null values for test datasets\ndf_test.isna().sum()","8d2f0485":"# Check % of null values in train datasets\nprint(df_train.isna().sum()\/df_train.shape[0]*100)","0c55cbff":"# Check % of null values in test datasets\nprint(df_test.isna().sum()\/df_test.shape[0]*100)","6171a518":"# drop Cabin column because it has 77% missing values for train datasets\ndf_train.drop(columns='Cabin',inplace=True)","92ccc8fa":"# drop Cabin column because it has 77% missing values for test datasets\ndf_test.drop(columns='Cabin',inplace=True)","d4757749":"# fill age columns with mean value for train\ndf_train.Age.fillna(df_train.Age.mean(),inplace=True)","96a8d658":"# fill age columns with mean value for test\ndf_test.Age.fillna(df_train.Age.mean(),inplace=True)","69bbcc67":"# Embark Column has only 0.22% null values so drop some rows where Embark column has null values of train datasets\ndf_train.dropna(inplace=True)","4a955848":"df_test.Fare.fillna(df_test.Fare.mean(),inplace=True)","479f0027":"# Checking Shape of train datasets\ndf_train.shape","b4e17c1f":"# Checking Shape of test datasets\ndf_test.shape","500e19da":"# Checking PassengerId columns of train datasets\nprint(df_train.PassengerId.value_counts())\n\n# PassengerId has all Unique values so it is not important for the Prediction Hence drop it.\ndf_train.drop(columns='PassengerId',inplace=True)","13473369":"# Checking Ticket column  of train datasets\nprint(df_train.Ticket.value_counts())\n\n# Ticket has approximate all Unique values so it is not important for the Prediction Hence drop it.\ndf_train.drop(columns='Ticket',inplace=True)","c425a014":"# Checking Ticket column  of train datasets\nprint(df_test.Ticket.value_counts())\n\n# Ticket has approximate all Unique values so it is not important for the Prediction Hence drop it.\ndf_test.drop(columns='Ticket',inplace=True)","6cc3e138":"# Checking Name columns\nprint(df_train.Name.value_counts())\n\n# Name has all Unique values so it is not important for the Prediction Hence drop it.\ndf_train.drop(columns='Name',inplace=True)","43a274e8":"# Checking Name columns for test datasets\nprint(df_test.Name.value_counts())\n\n# Name has all Unique values so it is not important for the Prediction Hence drop it.\ndf_test.drop(columns='Name',inplace=True)","f58335bd":"# Describing train datasets\ndf_train.describe()","e903c658":"# Describing test Datasets\ndf_test.describe()","f076d1f9":"# information of train datasets\ndf_train.info()","6185766c":"# information of test datasets\ndf_test.info()","0477b6d6":"df_train.corr()","d829b9a8":"# Correlation between columns of test datasets\ndf2_test=df_test.drop(columns=\"PassengerId\")\ndf2_test.corr()","7e09fc6b":"# Ploting Correlation Heatmap\nplt.figure(figsize=(15,10))\nsns.heatmap(df_train.corr(),annot=True,cmap='Blues')","e19303c8":"# Ploting Correlation Heatmap\nplt.figure(figsize=(15,10))\nsns.heatmap(df2_test.corr(),annot=True,cmap='Blues')","f6745589":"# Ploting box plot\nplt.figure(figsize=(20,20))\nlst=df_train.columns[df_train.dtypes!='object']\nfor index,val in enumerate(lst):    \n    plt.subplot(2,3,index+1)\n    sns.boxplot(x=val,data=df_train,color='Orange')","bc11fac1":"# Ploting box plot\nplt.figure(figsize=(20,20))\nlst=df2_test.columns[df2_test.dtypes!='object']\nfor index,val in enumerate(lst):    \n    plt.subplot(2,3,index+1)\n    sns.boxplot(x=val,data=df2_test,color='Orange')","e078349f":"# Ploting violinplot plot\nplt.figure(figsize=(20,20))\nlst=df_train.columns[df_train.dtypes!='object']\nfor index,val in enumerate(lst):\n    plt.subplot(2,3,index+1)\n    sns.violinplot(x=val,data=df_train,palette='RdYlGn')","e47dbd09":"# Ploting violinplot plot\nplt.figure(figsize=(20,20))\nlst=df2_test.columns[df2_test.dtypes!='object']\nfor index,val in enumerate(lst):\n    plt.subplot(2,3,index+1)\n    sns.violinplot(x=val,data=df2_test,palette='RdYlGn')","228923fe":"sns.pairplot(df_train,hue='Sex')","f8bff850":"sns.pairplot(df_test,hue='Sex')","0ee21374":"sns.pairplot(df_train,hue='Embarked')","64e095eb":"sns.pairplot(df_test,hue='Embarked')","729cb174":"# Ploting countplot plot\nplt.figure(figsize=(10,5))\nlst=df_train.columns[df_train.dtypes=='object']\nfor index,val in enumerate(lst):\n    plt.subplot(1,2,index+1)\n    sns.countplot(df_train[val])    ","23bd2511":"# Ploting countplot plot\nplt.figure(figsize=(10,5))\nlst=df2_test.columns[df2_test.dtypes=='object']\nfor index,val in enumerate(lst):\n    plt.subplot(1,2,index+1)\n    sns.countplot(df2_test[val])    ","0f24f505":"# Ploting jointplot plot\nplt.figure(figsize=(10,5))\nlst=df_train.columns[df_train.dtypes!='object']\nfor index,val in enumerate(lst):\n    sns.jointplot(data=df_train,x=val,y='Fare',hue='Embarked',kind='scatter')    ","88733f57":"# Ploting jointplot plot\nplt.figure(figsize=(10,5))\nlst=df2_test.columns[df2_test.dtypes!='object']\nfor index,val in enumerate(lst):\n    sns.jointplot(data=df2_test,x=val,y='Fare',hue='Embarked',kind='scatter')    ","c2eaf3b6":"# Ploting jointplot plot\nplt.figure(figsize=(10,5))\nlst=df_train.columns[df_train.dtypes!='object']\nfor index,val in enumerate(lst[:-1]):\n    sns.jointplot(data=df_train,x=val,y='Fare',hue='Sex',kind='kde')    ","bc5ee128":"# Ploting jointplot plot\nplt.figure(figsize=(10,5))\nlst=df2_test.columns[df2_test.dtypes!='object']\nfor index,val in enumerate(lst[:-1]):\n    sns.jointplot(data=df2_test,x=val,y='Fare',hue='Sex',kind='kde')    ","2e32e864":"df_train=pd.get_dummies(df_train,drop_first=True)\ndf_train.head()","93be044f":"df2_test=pd.get_dummies(df2_test,drop_first=True)\ndf2_test.head()","35d366f3":"x=df_train.drop(columns='Survived')\ny=df_train['Survived']\n","f8b1c628":"xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=.10,random_state=42)","cfeb7b98":"bnb=BernoulliNB()\nbnb.fit(xtrain,ytrain)\nbnb.score(xtest,ytest)","45b8c4bf":"pred=bnb.predict(xtest)\nsns.heatmap(confusion_matrix(ytest,pred),annot=True)","af921b5a":"print(classification_report(ytest,pred))","212c6781":"main_pred=bnb.predict(df2_test)\ndf2=pd.DataFrame({'PassengerId':df_test.PassengerId,'Survived':main_pred})\ndf2.to_csv('gender_submission.csv',index=False)","1da5914c":"##### Handle Missing Values","a51094ab":"##### View the first, last, and random rows in the dataframe.","e364de63":"# Titanic Datasets","804256d4":"##### View the data information and Null Values","8a3afb60":"## Splitting Datasets","8737125c":"##### Describing Dataset","76c523c6":"## Import Important Libraries","b1b61a85":"##### Haddle Wrong values & Unusual Columns","99ef8e85":"## Get Dummies","c786c952":"## Apply Machine Learning","485075b6":"## Data Visualization","fbe5fc1e":"# Mohit Anand Srivastava\n","b25baefd":"## EDA"}}