{"cell_type":{"dcef681d":"code","b3389959":"code","57d919f7":"code","13060699":"code","305a8c6e":"code","78a6c0c1":"code","4a888b37":"code","5446ab83":"code","9be3c264":"code","65a14d4e":"code","9c73fef7":"code","54ba0f8a":"code","5bf71ae2":"code","f065b73e":"code","ce454fc6":"code","86f1bcb6":"code","4a2979ae":"code","dfea1c2e":"code","d11c4aba":"code","cf0a33e0":"code","0ccea1b2":"code","d80c924a":"code","96cbc66d":"code","d734e6f9":"code","c025f749":"markdown","52e9de32":"markdown","dda1f4c1":"markdown","51a5f00d":"markdown","78bab7c9":"markdown","2d2f183b":"markdown","29e462f7":"markdown","dab71d05":"markdown","c816fb83":"markdown","b532fbd6":"markdown","53d83c76":"markdown"},"source":{"dcef681d":"# Import necessary libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc","b3389959":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","57d919f7":"# Read data\ndf=pd.read_csv('\/kaggle\/input\/60k-stack-overflow-questions-with-quality-rate\/data.csv')","13060699":"df.Y.value_counts()","305a8c6e":"# Create feature CreationYear and remove feature CreationDate\ndf['CreationYear']=df.CreationDate.apply(lambda val:int(val.split()[0].split('-')[0]))\ndel df['CreationDate']\ngc.collect()\n\n# Label encode target feature\ndf.Y.replace({'LQ_CLOSE':0,'HQ':1,'LQ_EDIT':2},inplace=True)\n\n# Create train and test dataframes\ntrain_df=df[['Title','Body','Tags','Y']][df.CreationYear<2019].copy()\ntest_df=df[['Title','Body','Tags','Y']][df.CreationYear>=2019].copy()\n\n# Delete main dataframe to clear some memory\ndel df\ngc.collect()\n\ntrain_df.shape, test_df.shape","78a6c0c1":"def clean_tags(string):\n    return ((string.replace('><',' ')).replace('<','')).replace('>','')\n\nfor df in [train_df,test_df]:\n    df['Tags']=list(map(lambda val:clean_tags(val), df.Tags.values))","4a888b37":"from bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom tqdm.notebook import tqdm\nimport re","5446ab83":"def clean_body_text(df):\n    # Create list of english stopwords from nltk library\n    stop_words = set(stopwords.words('english'))\n\n    # Create a list to save body text of all questions\n    body_text=[]\n    # Create a list to indicate if code snippet is present in the body\n    code_indicator=[]\n    reference_link_indicator=[]\n    image_indicator=[]\n\n    for ind in tqdm(range(df.shape[0])):\n\n        # Create a BeautifulSoup object\n        q_body=df['Body'].values[ind].lower()\n        soup=BeautifulSoup(q_body)\n        \n        # To check if body contains code snippet\n        if len(soup.findAll('code'))>0:\n            code_indicator.append(1)\n            # Find all code tags and replace them with empty string ''\n            for code_text in soup.findAll('code'):\n                code_text.replace_with('')\n        else:\n            code_indicator.append(0)\n        \n        # To check if body contains reference link tag\n        if len(soup.findAll('a'))>0:\n            reference_link_indicator.append(1)\n        else:\n            reference_link_indicator.append(0)\n\n        # To check if body contains image\n        if len(soup.findAll('img'))>0:\n            image_indicator.append(1)\n        else:\n            image_indicator.append(0)            \n\n        # Create a list to save all <p> tag text of a question into a list\n        text=[]\n        for line in soup.findAll('p'):\n            line=line.get_text()\n            line=line.replace('\\n','')\n            line=re.sub(r'[^A-Za-z0-9]', ' ', line)\n            line=' '.join([word for word in line.split() if not word in stop_words])\n            text.append(line)\n\n        body_text.append(' '.join(text))\n\n    return body_text, code_indicator, reference_link_indicator, image_indicator","9be3c264":"train_df['body_text'],train_df['code_indicator'],train_df['reference_link_indicator'],train_df['image_indicator']=clean_body_text(train_df)\ntest_df['body_text'],test_df['code_indicator'],test_df['reference_link_indicator'],test_df['image_indicator']=clean_body_text(test_df)","65a14d4e":"def clean_title_text(df):\n    # Create list of english stopwords from nltk library\n    stop_words = set(stopwords.words('english'))\n    title_text=[]\n    for ind in range(df.shape[0]):\n        text=df.Title.values[ind].lower()\n        text=text.replace('\\n','')\n        text=re.sub(r'[^A-Za-z0-9]', ' ', text)\n        text=' '.join([word for word in text.split() if not word in stop_words])\n\n        title_text.append(text)\n        \n    return title_text","9c73fef7":"train_df['title_text']=clean_title_text(train_df)\ntest_df['title_text']=clean_title_text(test_df)","54ba0f8a":"del train_df['Title'], train_df['Body'], test_df['Title'], test_df['Body']\ngc.collect()","5bf71ae2":"train_y=train_df['Y']\ntest_y=test_df['Y']\n\ndel train_df['Y'], test_df['Y']\ngc.collect()","f065b73e":"train_df.shape, test_df.shape, train_y.shape, test_y.shape","ce454fc6":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport scipy","86f1bcb6":"train_tfidf=[]\ntest_tfidf=[]\nfor feat in tqdm(train_df.select_dtypes(include='object').columns):\n    vectorizer=TfidfVectorizer(ngram_range=(1,4),max_features=10000)\n    train_tfidf.append(vectorizer.fit_transform(train_df[feat]))\n    test_tfidf.append(vectorizer.transform(test_df[feat]))","4a2979ae":"train_tfidf=scipy.sparse.hstack(train_tfidf).tocsr()\ntest_tfidf=scipy.sparse.hstack(test_tfidf).tocsr()\n\ntrain_tfidf.shape, test_tfidf.shape","dfea1c2e":"train_x=scipy.sparse.hstack([train_tfidf, train_df[['code_indicator','reference_link_indicator','image_indicator']].values]).tocsr()\ntest_x=scipy.sparse.hstack([test_tfidf, test_df[['code_indicator','reference_link_indicator','image_indicator']].values]).tocsr()","d11c4aba":"train_x.shape, test_x.shape","cf0a33e0":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","0ccea1b2":"lr=LogisticRegression(max_iter=1000,n_jobs=-1)\nlr.fit(train_x,train_y)","d80c924a":"train_y_pred=lr.predict(train_x)\ntest_y_pred=lr.predict(test_x)","96cbc66d":"print('Mean accuracy score:',lr.score(train_x,train_y))\n\nfig,ax=plt.subplots(figsize=(8,8))\nsns.heatmap(metrics.confusion_matrix(train_y,train_y_pred),annot=True,cbar=False,fmt='d',cmap='Reds')\nax.set_ylabel('True label',fontsize=14)\nax.set_xlabel('Predicted label',fontsize=14)\nax.set_title('Confusion matrix: Train set prediction',fontsize=16);","d734e6f9":"print('Mean accuracy score:',lr.score(test_x,test_y))\n\nfig,ax=plt.subplots(figsize=(8,8))\nsns.heatmap(metrics.confusion_matrix(test_y,test_y_pred),annot=True,cbar=False,fmt='d',cmap='Reds')\nax.set_ylabel('True label',fontsize=14)\nax.set_xlabel('Predicted label',fontsize=14)\nax.set_title('Confusion matrix: Test set prediction',fontsize=16);","c025f749":"Our next task is going to be the most important section of the notebook. We now want to build some features that will help our model in prediction. Before we build any feature, we will clean-up the raw html text available in the data. Firstly, we will remove all tag brackets from the Tags feature.","52e9de32":"Surely, we have overfitted to the data as train mean accuracy is at 94% where test accuracy is at 79%.<br>\nNext, step is to apply advance machine learning models. So please upvote for the motivation. Update coming soon...","dda1f4c1":"Let's now convert list of tfidf vectors into a stacked sparse matrix. As our base model will be logistic regression, having sparse matrix speeds-up the training process.","51a5f00d":"We will now, perform tfidf vectorizer on the text features, i.e., title_text, body_text, Tags","78bab7c9":"Similarly, we will clean html titles from the Title feature of the dataframe.","2d2f183b":"For this purpose, we will set questions from year 2019 as our validation set and all questions before the year 2019 as our training set. Also, will do label encoding for target variable, where LQ_CLOSE becomes 0, HQ becomes 1, and LQ_EDIT becomes 2","29e462f7":"Let's now seperate target features from the predictor features from both the dataframes","dab71d05":"Let's now stack tfidf features and numeric features togather","c816fb83":"## Which stackoverflow questions should be closed?<br>\nNow, we have three types of question classes: high quality open questions (HQ), low quality close questions (LQ_CLOSE), and  low quality open questions (LQ_EDIT). We have 20k samples of each of these question types.<br>\nBut, considering from the organization's perspective, we want to build predictive model that will tell us types (class) of the question from the future date based on the historical samples we have in the organization.","b532fbd6":"Next, we want to extract useful text from the Body of the html code, that is available in the Body feature of the dataframe. For this task we are using libraries BeautifulSoup, nltk, re.<br>\nAlong with that, we will also add three new indicator features for code snippet, reference link tag, image tag.","53d83c76":"Let's use simplest of all classification models, logistic regression, as our baseline model"}}