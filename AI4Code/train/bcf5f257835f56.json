{"cell_type":{"419a54f3":"code","ad13bedb":"code","04529b81":"code","aa3c60fc":"code","2954d85b":"code","e54f11a1":"code","a3fdc69d":"code","c1ce9bd7":"code","600926b0":"code","849a76ab":"code","b824accb":"code","b2bd632b":"code","527130c1":"code","3879c3c0":"code","5d747eac":"code","715aaa92":"code","93224058":"code","c4572e17":"code","ffbe71c9":"code","c8234bca":"code","38f220d4":"code","18d2c2d4":"code","9165cc5d":"code","9ae4143d":"code","9888c8ba":"code","9c135ccc":"code","91ef057a":"code","39805b85":"code","84984833":"code","cd434c8a":"code","7c606967":"code","c0fcb165":"code","689119a5":"code","9edc3ee8":"code","9124d95a":"code","26200421":"code","bb009e1c":"code","20208e37":"code","0e5b3a44":"code","9327b88d":"code","c5552111":"code","5240d2e8":"code","40cc461c":"code","218dfdc2":"code","10ae57a8":"code","1ecb8725":"code","55b1ef6d":"code","b47a6c91":"code","716f9ae5":"code","594db12b":"code","0e3f8140":"code","f860625e":"code","e94f0546":"markdown","94819f5e":"markdown","ff941f45":"markdown","4d38fa11":"markdown","e15f1385":"markdown","93eac1da":"markdown","9e6dcf03":"markdown","459381bc":"markdown","06e04c97":"markdown"},"source":{"419a54f3":"import shutil\nimport numpy as np\nimport pandas as pd\nfrom random import random\n\n# Image operations and plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\n%matplotlib inline\n\n# File, path and directory operations\nimport os\nimport os.path\nimport shutil\n\n\n# Model building\nfrom fastai.vision import *\nfrom fastai.callbacks.hooks import *\nimport torchvision\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.metrics import classification_report\nfrom pathlib import PurePath\n\n# For reproducability\nfrom numpy.random import seed\nseed(108)\n","ad13bedb":"print(os.listdir(\"..\/input\/skin-cancer-mnist-ham10000\"))","04529b81":"# Create a new directory\nbase = \"base\"\nos.mkdir(base)","aa3c60fc":"\n#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n\n# now we create 7 folders inside 'base':\n\n# train\n    # nv\n    # mel\n    # bkl\n    # bcc\n    # akiec\n    # vasc\n    # df\n \n# valid\n    # nv\n    # mel\n    # bkl\n    # bcc\n    # akiec\n    # vasc\n    # df\n\n# create a path to 'base' to which we will join the names of the new folders\n# train\ntrain = os.path.join(base, 'train')\nos.mkdir(train)\n\n# valid\nvalid = os.path.join(base, 'valid')\nos.mkdir(valid)\n\n\n# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n# Inside each folder we create seperate folders for each class\n\n# create new folders inside train\nnv = os.path.join(train, 'nv')\nos.mkdir(nv)\nmel = os.path.join(train, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(train, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(train, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(train, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(train, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(train, 'df')\nos.mkdir(df)\n\n\n\n\n\n# test\ntest = os.path.join(base, 'test')\nos.mkdir(test)\n\nnv = os.path.join(test, 'nv')\nos.mkdir(nv)\nmel = os.path.join(test, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(test, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(test, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(test, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(test, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(test, 'df')\nos.mkdir(df)\n","2954d85b":"# create new folders inside valid\nnv = os.path.join(valid, 'nv')\nos.mkdir(nv)\nmel = os.path.join(valid, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(valid, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(valid, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(valid, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(valid, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(valid, 'df')\nos.mkdir(df)","e54f11a1":"import pandas as pd\ndf = pd.read_csv(\"..\/input\/skin-cancer-mnist-ham10000\/HAM10000_metadata.csv\")\n","a3fdc69d":"from numpy.random import seed\nseed(101)\ndf2=df.iloc[:,1:3]\nmsk = np.random.rand(len(df2)) < 0.85\ntrain1_df2 = df2[msk]\ntest_df2 = df2[~msk]\nmsk1 = np.random.rand(len(train1_df2)) < 0.85\ntrain_df2 = train1_df2[msk1]\nvalidation_df2 = train1_df2[~msk1]","c1ce9bd7":"train_df2['dx'].value_counts()","600926b0":"validation_df2['dx'].value_counts()","849a76ab":"test_df2['dx'].value_counts()","b824accb":"# Set the image_id as the index in df_data\ndf.set_index('image_id', inplace=True)","b2bd632b":"# Get a list of images in each of the two folders\nfolder_1 = os.listdir('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1')\nfolder_2 = os.listdir('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2')","527130c1":"# Get a list of train , val and test images \ntrain_df2_list = list(train_df2['image_id'])\nvalidation_df2_list = list(validation_df2['image_id'])\ntest_df2_list = list(test_df2['image_id'])","3879c3c0":"# Transfer the train images\n\nfor image in train_df2_list:\n    \n    fname = image + '.jpg'\n    label = df.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(train, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(train, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)","5d747eac":"# Transfer the val images\n\nfor image in validation_df2_list:\n    \n    fname = image + '.jpg'\n    label = df.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(valid, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(valid, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n   \n        ","715aaa92":"for image in test_df2_list:\n    \n    fname = image + '.jpg'\n    label = df.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(test, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(test, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)","93224058":"# check how many train images we have in each folder\nprint(\"..............................\")\nprint(\"Train folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/train\/nv')))\nprint(len(os.listdir('base\/train\/mel')))\nprint(len(os.listdir('base\/train\/bkl')))\nprint(len(os.listdir('base\/train\/bcc')))\nprint(len(os.listdir('base\/train\/akiec')))\nprint(len(os.listdir('base\/train\/vasc')))\nprint(len(os.listdir('base\/train\/df')))\nprint(\"..............................\")\n# check how many train images we have in each folder\nprint(\"validation folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/valid\/nv')))\nprint(len(os.listdir('base\/valid\/mel')))\nprint(len(os.listdir('base\/valid\/bkl')))\nprint(len(os.listdir('base\/valid\/bcc')))\nprint(len(os.listdir('base\/valid\/akiec')))\nprint(len(os.listdir('base\/valid\/vasc')))\nprint(len(os.listdir('base\/valid\/df')))\nprint(\"..............................\")\n# check how many train images we have in each folder\nprint(\"Test folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/test\/nv')))\nprint(len(os.listdir('base\/test\/mel')))\nprint(len(os.listdir('base\/test\/bkl')))\nprint(len(os.listdir('base\/test\/bcc')))\nprint(len(os.listdir('base\/test\/akiec')))\nprint(len(os.listdir('base\/test\/vasc')))\nprint(len(os.listdir('base\/test\/df')))","c4572e17":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        rotation_range=180,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest')\nimg_path = load_img('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_images_part_2\/ISIC_0029316.jpg',target_size=(224, 224))\n # this is a PIL image\nx = img_to_array(img_path)  # Numpy array with shape (224, 224, 3)\nx = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 224, 224, 3)\n\n# The .flow() command below generates batches of randomly transformed images\n# It will loop indefinitely, so we need to `break` the loop at some point!\ni = 0\nfor batch in datagen.flow(x, batch_size=1):\n  plt.figure(i)\n  imgplot = plt.imshow(array_to_img(batch[0]))\n  i += 1\n  if i % 5 == 0:\n    break","ffbe71c9":"# note that we are not augmenting class 'nv'\nclass_list = ['mel','bkl','bcc','akiec','vasc','df']\n\nfor item in class_list:\n    \n    # We are creating temporary directories here because we delete these directories later\n    # create a base\n    aug = 'aug'\n    os.mkdir(aug)\n    # create a dir within the base to store images of the same class\n    img_dir = os.path.join(aug, 'img_dir')\n    os.mkdir(img_dir)\n\n    # Choose a class\n    img_class = item\n\n    # list all images in that directory\n    img_list = os.listdir('base\/train\/' + img_class)\n\n    # Copy images from the class train dir to the img_dir e.g. class 'mel'\n    for fname in img_list:\n            # source path to image\n            src = os.path.join('base\/train\/' + img_class, fname)\n            # destination path to image\n            dst = os.path.join(img_dir, fname)\n            # copy the image from the source to the destination\n            shutil.copyfile(src, dst)\n\n\n    # point to a dir containing the images and not to the images themselves\n    path = aug\n    save_path = 'base\/train\/' + img_class\n\n    # Create a data generator\n    datagen = ImageDataGenerator(\n        rotation_range=180,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        #brightness_range=(0.9,1.1),\n        fill_mode='nearest')\n\n    batch_size = 50\n\n    aug_datagen = datagen.flow_from_directory(path,\n                                           save_to_dir=save_path,\n                                           save_format='jpg',\n                                                    target_size=(224,224),\n                                                    batch_size=batch_size)\n\n\n\n    # Generate the augmented images and add them to the training folders\n    \n    ###########\n    \n    num_aug_images_wanted = 5000 # total number of images we want to have in each class\n    \n    ###########\n    \n    num_files = len(os.listdir(img_dir))\n    num_batches = int(np.ceil((num_aug_images_wanted-num_files)\/batch_size))\n\n    # run the generator and create about 6000 augmented images\n    for i in range(0,num_batches):\n\n        imgs, labels = next(aug_datagen)\n        \n    # delete temporary directory with the raw image files\n    shutil.rmtree('aug')","c8234bca":"# check how many train images we have in each folder\nprint(\"..............................\")\nprint(\"Train folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/train\/nv')))\nprint(len(os.listdir('base\/train\/mel')))\nprint(len(os.listdir('base\/train\/bkl')))\nprint(len(os.listdir('base\/train\/bcc')))\nprint(len(os.listdir('base\/train\/akiec')))\nprint(len(os.listdir('base\/train\/vasc')))\nprint(len(os.listdir('base\/train\/df')))\nprint(\"..............................\")\n# check how many train images we have in each folder\nprint(\"validation folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/valid\/nv')))\nprint(len(os.listdir('base\/valid\/mel')))\nprint(len(os.listdir('base\/valid\/bkl')))\nprint(len(os.listdir('base\/valid\/bcc')))\nprint(len(os.listdir('base\/valid\/akiec')))\nprint(len(os.listdir('base\/valid\/vasc')))\nprint(len(os.listdir('base\/valid\/df')))\nprint(\"..............................\")\n# check how many train images we have in each folder\nprint(\"Test folder\")\nprint(\"..............................\")\nprint(len(os.listdir('base\/test\/nv')))\nprint(len(os.listdir('base\/test\/mel')))\nprint(len(os.listdir('base\/test\/bkl')))\nprint(len(os.listdir('base\/test\/bcc')))\nprint(len(os.listdir('base\/test\/akiec')))\nprint(len(os.listdir('base\/test\/vasc')))\nprint(len(os.listdir('base\/test\/df')))","38f220d4":"# Define transformations for data augmentation\ntfms = get_transforms(do_flip=True,  \n                      max_rotate=10,\n                      max_zoom=1.1,\n                      max_warp=0.2)\n\n# Build dataset by applying transforms to the data from our directory\ndata = (ImageList.from_folder(base)\n        .split_by_folder()          \n        .label_from_folder()\n        .add_test_folder('test')\n        .transform(tfms, size=224)\n        .databunch()\n        .normalize(imagenet_stats))","18d2c2d4":"wd=1e-2\n\nmobilenet_split = lambda m: (m[0][0][10], m[1])\narch  = torchvision.models.mobilenet_v2\nlearn = cnn_learner(data, arch, cut=-1, split_on=mobilenet_split, wd=wd, metrics=[accuracy])","9165cc5d":"learn.lr_find();\nlearn.recorder.plot();","9ae4143d":"# Set our learning rate to the value where learning is fastest and loss \n# is still decreasing.\n\n# This function uses our input lr as an anchor and sweeps through a range \n# in order to search out the best local minima.\nlearn.fit_one_cycle(5, max_lr=slice(3e-03), pct_start=0.9)","9888c8ba":"data.show_batch(rows=3, figsize=(4,4))","9c135ccc":"learn.recorder.plot_losses()","91ef057a":"# Exctract predictions and losses to evaluate model\npreds,y,losses = learn.get_preds(with_loss=True)\ninterp = ClassificationInterpretation(learn, preds, y, losses)","39805b85":"def top_k_spread(preds, y, spread):\n  for i in range(spread):\n    print(f\"Top {i+1} accuracy: {top_k_accuracy(preds, y, i+1)}\")","84984833":"# Top-1 accuracy of 86% is quite near the best models from the open competition\ntop_k_spread(preds, y, 5)","cd434c8a":"interp.plot_confusion_matrix()","7c606967":"# probs from log preds\nprobs = np.exp(preds[:,1])\n# Compute ROC curve\nfpr, tpr, thresholds = roc_curve(y, probs, pos_label=1)\n\n# Compute ROC area\nroc_auc = auc(fpr, tpr)\nprint('ROC area is {0}'.format(roc_auc))","c0fcb165":"plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlim([-0.01, 1.0])\nplt.ylim([0.0, 1.01])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")","689119a5":"learn.export()","9edc3ee8":"learn.path","9124d95a":"learn = load_learner(base,test=ImageList.from_folder('\/kaggle\/working\/base\/test'))","26200421":"preds,y = learn.get_preds(ds_type=DatasetType.Test)\npreds = np.argmax(preds, 1).tolist()","bb009e1c":"for i in range(0,7):\n    print('The count of element:', i ,'is ', preds.count(i))","20208e37":"y_true=[]\nfor i in list(data.test_ds.items):\n    if PurePath(i).parts[2]==\"akiec\":\n        y_true.append(int(str(0)))\n    elif PurePath(i).parts[2]==\"bcc\":\n        y_true.append(int(str(1)))\n    elif PurePath(i).parts[2]==\"bkl\":\n        y_true.append(int(str(2))) \n    elif PurePath(i).parts[2]==\"df\":\n        y_true.append(int(str(3)))  \n    elif PurePath(i).parts[2]==\"mel\":\n        y_true.append(int(str(4))) \n    elif PurePath(i).parts[2]==\"nv\":\n        y_true.append(int(str(5)))\n    else:\n        y_true.append(int(str(6)))","0e5b3a44":"target_names = ['akiec', 'bcc','bkl','df','mel','nv','vasc']\nprint(classification_report(y_true, preds, target_names=target_names))","9327b88d":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    import itertools\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","c5552111":"cnf_matrix = confusion_matrix(y_true, preds,labels=[0,1,2,3,4,5,6])\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['akiec', 'bcc','bkl','df','mel','nv','vasc'],\n                      title='Confusion matrix, without normalization')","5240d2e8":"def plot_prediction(learn, index):\n  data = learn.data.test_ds[index][0]\n  pred = learn.predict(data)\n  classes = learn.data.classes\n\n  prediction = pd.DataFrame(to_np(pred[2]*100), columns=['Confidence'])\n  prediction['Classes'] = classes\n  prediction = prediction.sort_values(by='Confidence', ascending=False)\n\n  fig = plt.figure(figsize=(12, 5))\n  ax1 = fig.add_subplot(121)\n  show_image(data, figsize=(5, 5), ax=ax1)\n  ax2 = fig.add_subplot(122)\n  sns.set_color_codes(\"pastel\")\n  sns.barplot(x='Confidence', y='Classes', data=prediction,\n              label=\"Total\", color=\"b\")\n  ax2.set_title(f'Actual: {PurePath(learn.data.test_ds.items[index]).parts[5]}')\n","40cc461c":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","218dfdc2":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","10ae57a8":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","1ecb8725":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","55b1ef6d":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","b47a6c91":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","716f9ae5":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","594db12b":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","0e3f8140":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","f860625e":"plot_prediction(learn, np.random.choice(len(learn.data.test_ds)))","e94f0546":"****Mobilenet Convolutional Architecture****","94819f5e":"**Plot of training and validation loss**","ff941f45":"****Loading HAM10000_metadata and splitting into train ,  validation and test**","4d38fa11":"**Confusion Matrix Report for validation data**","e15f1385":"**Analysis report for Test images.**","93eac1da":"**Predictions","9e6dcf03":"Using **MobileNet Architecture**","459381bc":"****Importing all neccessary librarys****","06e04c97":"**Balancing the unbalanced classes using Data Augmentation technique**"}}