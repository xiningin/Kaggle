{"cell_type":{"09f4f627":"code","f6ed67ca":"code","714ef3f7":"code","47dc1406":"code","95127d42":"code","f358fac2":"code","e7b98df9":"code","6f22ee5b":"code","e6d573fa":"code","808d6cfe":"code","d6239fc8":"code","2e17a285":"code","f0948860":"code","a51f875e":"code","957eba9c":"code","6b0256ec":"code","1bf87d7b":"code","ca3c8ed7":"code","e9cf05ee":"code","aae558e4":"code","2bcdef1c":"code","2162e15e":"code","93791cd2":"code","d411ff63":"code","c327f52f":"code","5a2f712e":"code","fbe0d7aa":"code","3ed6cb50":"code","51afe0ba":"code","e4c39ddc":"code","296336f6":"code","a84e8e31":"code","c70fb48a":"code","39a4b054":"code","dca4d0db":"code","6e8efe7d":"code","d08c8cae":"code","8fcea1b0":"code","e807ebea":"code","2960d135":"code","270e44f3":"code","a9f7137e":"code","02c39191":"code","f1b6eb5f":"code","a166d011":"code","cfa10672":"code","3467d15f":"code","d2076aed":"code","99bed988":"code","3cf6df44":"code","938b465e":"code","33d6c903":"code","cb30ec34":"code","fa0e49e5":"code","0814ed97":"code","16942117":"code","42687557":"code","040a6563":"code","667a2864":"code","1c0aeb2d":"code","b40a7f5b":"code","46c64080":"code","f6330402":"code","6e713af7":"code","a49078f2":"code","70f720da":"code","234018ef":"code","520b9618":"code","9006da1a":"code","75126e08":"code","bed77629":"code","43ad3af0":"code","1e398b95":"code","06065b93":"code","64d26dd9":"code","c3b6fe44":"code","f485ee16":"code","5c5c6e2e":"code","b5dcc6ab":"markdown","7c5709c0":"markdown","124fd930":"markdown","d80b5333":"markdown","321fb1c2":"markdown","b95c755f":"markdown"},"source":{"09f4f627":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f6ed67ca":"pip install openpyxl ","714ef3f7":"#reading data dictionary\ndata_dict = pd.read_excel('\/kaggle\/input\/car-price-prediction\/Data Dictionary - carprices.xlsx')\ndata_dict.head()","47dc1406":"#cleaning data dictionary file and creating another dataframe to show the values\ndata = data_dict[['Unnamed: 6','Unnamed: 7','Unnamed: 11']]\ndict_data = data.iloc[3:,:].dropna()\ndata_dictionary = dict_data\ndata_dictionary.columns = ['Index', 'Feature','Description']\ndata_dictionary.info()","95127d42":"#getting the data_dictionary\ndata_dictionary","f358fac2":"#reading car price data\ncar_price = pd.read_csv('\/kaggle\/input\/car-price-prediction\/CarPrice_Assignment.csv')\ncar_price.head().transpose()","e7b98df9":"#checking for duplicates\nduplicate = car_price.duplicated()\nduplicate\nsum(duplicate)","6f22ee5b":"# Removing Duplicates\ncar_price = car_price.drop_duplicates()","e6d573fa":"car_price.info()","808d6cfe":"#First we'll check for the variance in categoricsl columns. Since we have to convert categorical data into numerical form we need to be certain that only deserving columns are used as features.\n#calling the list of columns\ncar_price.columns","d6239fc8":"categorical_columns = ['CarName','fueltype', 'aspiration','doornumber', 'carbody', 'drivewheel', 'enginelocation','enginetype','cylindernumber','fuelsystem']\nfor i in categorical_columns:\n    print('Distinct value count for ', i ,'is : ', car_price[i].value_counts())","2e17a285":"'''From the above we can observe that the column CarName has more than 147 distinct values. Now if we create dummy variable for all the names it will increase our\ndimensionality. In the real world problems car brand is also a factor for pricing. However for the sake of convenience we'll drop that column from our analysis.'''\ncar_price.drop(columns = ['CarName','car_ID'], inplace = True)","f0948860":"#Lets generate dummy variables\ncar_price_en = pd.get_dummies(car_price, drop_first = True)\ncar_price_en.head().transpose()","a51f875e":"#So now that we are clear about which categorical variable we are going to use, let's proceed with analysing quantitative variables\ncar_price_en.describe()","957eba9c":"'''Lets generate correlation between the different features.\nPoints to be noted: \n    1. We dont need to normalize data for correlation. Pearson's correlation measures the linear component of association. \n    So  linear transformations of data will not affect the correlation between them.\n    '''\n","6b0256ec":"# select numeric columns\nnumerical_columns = car_price.select_dtypes(exclude=[np.object])\nnumerical_columns.head()","1bf87d7b":"numerical_columns.describe()","ca3c8ed7":"#generating pairplot to understand the pairwise relation in data\nimport seaborn as sn\nsn.pairplot(numerical_columns)","e9cf05ee":"import matplotlib.pyplot as plt\n%matplotlib inline","aae558e4":"#gathering moments data\nfor i in numerical_columns.columns:\n    print(\"Mean for\",i, \"is : \", numerical_columns[str(i)].mean())\n    print(\"Median for\",i, \"is : \", numerical_columns[str(i)].median())\n    print(\"Variance for\",i, \"is : \", numerical_columns[str(i)].var())\n    print(\"Standard Deviation for\",i, \"is : \", numerical_columns[str(i)].std())\n    print(\"Skewness for\",i, \"is : \", numerical_columns[str(i)].skew())\n    print(\"Kurtosis for\",i, \"is : \", numerical_columns[str(i)].kurt())\n    print(\"Mode for\",i, \"is : \", numerical_columns[str(i)].mode())\n    print('\\n')\n    ","2bcdef1c":"numerical_columns.columns","2162e15e":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['wheelbase'])","93791cd2":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['carlength'])","d411ff63":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['carwidth'])","c327f52f":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['carheight'])","5a2f712e":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['curbweight'])","fbe0d7aa":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['enginesize'])","3ed6cb50":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['boreratio'])","51afe0ba":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['stroke'])","e4c39ddc":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['compressionratio'])","296336f6":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['horsepower'])","a84e8e31":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['peakrpm'])","c70fb48a":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['highwaympg'])","39a4b054":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(numerical_columns['price'])","dca4d0db":"pip install feature_engine","6e8efe7d":"#creating a function to find outliers in all the numerical columns \ndef outlier_analyse(dataf):\n    import pandas as pd\n    iqr_data = []\n    l_limit = []\n    u_limit = []\n    outlier_d = []\n    outlier_per = []\n    for i in dataf.columns:\n        IQR = dataf[str(i)].quantile(0.75) - dataf[str(i)].quantile(0.25)\n        iqr_data.append(IQR)\n        lower_limit = dataf[str(i)].quantile(0.25) - (1.5 * IQR)\n        l_limit.append(lower_limit)\n        upper_limit = dataf[str(i)].quantile(0.75) + (1.5 * IQR)\n        u_limit.append(upper_limit)\n        outlier = ((dataf[str(i)] < lower_limit ) | (dataf[str(i)] > upper_limit)).sum()\n        outlier_d.append(outlier)\n        outlier_p = round(((outlier*100)\/(dataf[str(i)].count())),2)\n        outlier_per.append(outlier_p)     \n\n        \n        \n    outlier_data = {'Feature': dataf.columns,'IQR' : iqr_data, 'Lower_Limit' : l_limit,'Upper_Limit': u_limit,\n                    'Outlier_Count' : outlier_d, 'Outlier_Percent' : outlier_per}\n    outlier_data = pd.DataFrame(outlier_data)\n    return(outlier_data)\n    ","d08c8cae":"num_outliers = outlier_analyse(numerical_columns)\nnum_outliers","8fcea1b0":"list(num_outliers.Feature)","e807ebea":"#importing Winsorizer from sklearn\nfrom feature_engine.outliers import Winsorizer\nwinsor = Winsorizer(capping_method = 'iqr', tail = 'both', fold =1.5, variables = [\n 'wheelbase',\n 'carlength',\n 'carwidth',\n 'enginesize',\n 'stroke',\n 'compressionratio',\n 'horsepower',\n 'peakrpm',\n 'citympg',\n 'highwaympg',\n 'price'])        ","2960d135":"car_price_wins = winsor.fit_transform(car_price_en)","270e44f3":"car_price_wins.head().transpose()","a9f7137e":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['wheelbase'])","02c39191":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['carlength'])","f1b6eb5f":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['carwidth'])","a166d011":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['carheight'])","cfa10672":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['curbweight'])","3467d15f":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['enginesize'])","d2076aed":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['boreratio'])","99bed988":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['stroke'])","3cf6df44":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['compressionratio'])","938b465e":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['horsepower'])","33d6c903":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['peakrpm'])","cb30ec34":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['highwaympg'])","fa0e49e5":"#creating boxplots for all the columns from numerical_columns\nsn.boxplot(car_price_wins['price'])","0814ed97":"car_price_wins.corr()","16942117":"#creating a correlation heatmap\nfig, ax = plt.subplots(figsize=(30,30))\nsn.heatmap(car_price_wins.corr(), annot = True,linewidths=.5, ax=ax)","42687557":"#creating a normalization function\ndef norm_func(i):\n    x = (i-i.min())\/(i.max()-i.min())\n    return(x)","040a6563":"df_norm = norm_func(car_price_wins)","667a2864":"df_norm.describe().transpose()","1c0aeb2d":"#Splitting the data\nX_columns = list(df_norm.columns)\nX_columns.remove('price')\nX = df_norm[X_columns]\n#X.head().transpose()","b40a7f5b":"Y_columns = ['price']\nY = df_norm[Y_columns]\nY.head()","46c64080":"from sklearn.model_selection import train_test_split","f6330402":"X_train, X_test, y_train,y_test = train_test_split(X, Y, test_size=0.30, random_state=42)","6e713af7":"X_train.describe()","a49078f2":"#importing LinearRegression \nfrom sklearn.linear_model import LinearRegression","70f720da":"#Initializing the model\nlinreg = LinearRegression()","234018ef":"#Fitting training data\nlinreg.fit(X_train, y_train)\n","520b9618":"#getting intercept value\nlinreg.intercept_","9006da1a":"linreg.coef_","75126e08":"linear_reg_coef['Regression_coefficient'] = pd.DataFrame(np.round(linreg.coef_.transpose(),2))\n#liear_reg_coef","bed77629":"columns['Feature'] = pd.DataFrame(X_train.columns)\n#columns","43ad3af0":"columns_coef_df = pd.concat ( [ columns['Feature'], linear_reg_coef['Regression_coefficient'] ], axis = 1 )\n#columns_coef_df ","1e398b95":"#sorting the features by coefficient values\nsort_coef_values = columns_coef_df.sort_values( 'Regression_coefficient', ascending = False)","06065b93":"#plotting coefficient values\nplt.figure(figsize = (15,10))\nsn.barplot(x = \"Regression_coefficient\", y = \"Feature\", data = sort_coef_values)\nplt.xlabel(\"Coefficients\")\nplt.ylabel(\"Features\")","64d26dd9":"#Making prediction on test\ny_pred = linreg.predict(X_test)","c3b6fe44":"from sklearn import metrics\n#calculating R2 score\nr2 = metrics.r2_score(y_train, linreg.predict(X_train))\nprint(\"R Squared : \", r2)","f485ee16":"#Calculating RMSE values for training and test set to understand models efficiency to predict car price\ndef get_rmse( model ):    \n    \n    y_train_pred = model.predict(X_train) #predicting on train data\n    rmse_train = round(np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)),3) #calculating rmse for training data prediction\n    \n    \n    y_test_pred = model.predict(X_test) #predicting on test data\n    rmse_test = round(np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)),3) #calculating rmse for test data prediction\n    \n    print(\"Training Data RMSE : \", rmse_train, \"Test Data RMSE : \" , rmse_test)","5c5c6e2e":"get_rmse(linreg)","b5dcc6ab":"***We'll remove and check again for the outliers. As we will see that none of the following box plots will show outliers.***","7c5709c0":"# ***As we can see that there is difference between the RMSE values for test and train. We'll need to perform some regularization techniques, some data preprocessing and transformations to increase model efficiency.***","124fd930":"***Outliers needs to be handled carefully. We should always consult business before making any kind of changes to the data. Howerver, here we'll use Winsorization method for outlier treatment.***","d80b5333":"# ***Numerical Data EDA***","321fb1c2":"***Above bar plot helps us visualize the effect of coffiecients on price. Positive coefficients will have positive impact on price, whereas negative components will have reducing effect on priice.***","b95c755f":"# ***Categorical Data EDA***"}}