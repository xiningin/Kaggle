{"cell_type":{"d4d45d83":"code","ade0f79e":"code","6e12924e":"code","fc44122e":"code","39bb5b22":"code","0544b691":"code","4bb7626b":"code","dc84a55e":"code","42156e35":"code","31b2a5bd":"code","568cdedb":"code","cb413eba":"code","988d2572":"code","1a50b844":"code","f7e72131":"code","e997393c":"code","7d9fe18b":"code","a8c7185d":"code","7d3eefb2":"code","6938c80c":"code","011b1562":"code","77ab71bf":"code","1e97031f":"code","9834d4d9":"code","2cfc118e":"code","b9b6920c":"code","9ec2889f":"code","da2742af":"code","b48f2176":"code","f167612f":"code","bd23ce00":"code","b390d2e7":"code","7b7f0c68":"code","24d2e4be":"code","4cd6759a":"code","6c8cbd23":"code","ae8d11d4":"code","eb4f2cf8":"code","4a3b503a":"code","d44412b3":"code","9fdd3608":"markdown","e1006590":"markdown","9e86cdee":"markdown","08cf7d33":"markdown","c72af3bd":"markdown","80f29645":"markdown","8066d7a3":"markdown","a8de2707":"markdown","02d0f612":"markdown","f970841a":"markdown","48dd9dab":"markdown","4f4d3f32":"markdown","599e9e02":"markdown","ec0c2687":"markdown","9bd2deb6":"markdown","f39aeed4":"markdown","fec90694":"markdown","92a0a545":"markdown","f2a38af5":"markdown","33a43e8a":"markdown","2cb11271":"markdown","7c0feed4":"markdown","c92ccb35":"markdown","a783a77b":"markdown","86467513":"markdown","40d23eb8":"markdown","d3983454":"markdown","33149f01":"markdown","605576b6":"markdown","c4320001":"markdown","1fd819e6":"markdown","df1f9dba":"markdown"},"source":{"d4d45d83":"import os\nimport glob\nfrom pathlib import Path\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom sklearn.model_selection import train_test_split\n\n\nplt.style.use('ggplot')\n\nseed=42\ntf.random.set_seed(seed)","ade0f79e":"image_path = list(Path('..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset').glob(r'**\/*.png'))\nimage_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], image_path))","6e12924e":"image_path = pd.Series(image_path, name='path').astype(str)\nimage_labels = pd.Series(image_labels, name='label')","fc44122e":"# create Dataframe with path and labels\ndf_image = pd.concat([image_path, image_labels], axis=1)","39bb5b22":"df_image.head()","0544b691":"df_image = df_image.sample(frac=1).reset_index(drop = True)","4bb7626b":"df_image.info()","dc84a55e":"df_image.label.value_counts()","42156e35":"fig, axes = plt.subplots(3, 4, figsize=(12, 7), subplot_kw={'xticks': [], 'yticks': []})\nfor idx, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_image.path[idx]))\n    ax.set_title(df_image.label[idx])\nplt.tight_layout()\nplt.show()","31b2a5bd":"df_image = df_image[~df_image.label.str.contains(\"GT\")]","568cdedb":"df_image.info()","cb413eba":"df_image = df_image.sample(frac=1).reset_index(drop = True)","988d2572":"df_train, df_test = train_test_split(df_image, test_size=0.1, random_state=seed)","1a50b844":"print('Training size: {} images\\nTest size: {} images'.format(len(df_train), len(df_test)))","f7e72131":"train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n    validation_split=0.2 # 20% of the training data will be used for validation\n)","e997393c":"test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n)","7d9fe18b":"BATCH_SIZE = 64","a8c7185d":"train_images = train_generator.flow_from_dataframe(\n    dataframe=df_train,\n    x_col='path',\n    y_col='label',\n    color_mode='rgb',\n    class_mode='categorical',\n    target_size=(224, 224),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=seed,\n    subset='training'\n)","7d3eefb2":"val_images = train_generator.flow_from_dataframe(\n    dataframe=df_train,\n    x_col='path',\n    y_col='label',\n    color_mode='rgb',\n    class_mode='categorical',\n    target_size=(224, 224),\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=seed,\n    subset='validation'\n)","6938c80c":"test_images = test_generator.flow_from_dataframe(\n    dataframe=df_test,\n    x_col='path',\n    y_col='label',\n    color_mode='rgb',\n    class_mode='categorical',\n    target_size=(224, 224),\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","011b1562":"def create_model(input_shape=(224, 224, 3)):\n    \n    inputs = tf.keras.layers.Input(input_shape)\n    \n    base_model = tf.keras.applications.MobileNetV2(\n        input_shape=(224, 224, 3), # the images are 224 x 224 with 3 channels (RGB)\n        weights='imagenet',\n        pooling='avg',\n        include_top=False # we discard the last layer of the original net and replace it with 2 layers defined in the following\n        )\n    \n    base_model.trainable = False # We won't re-train all the base model parameters, but just those of the layers we will add.\n    \n    x = base_model(inputs)\n    x = tf.keras.layers.Dense(64, activation='relu')(x) # additional hidden layer\n    outputs =  tf.keras.layers.Dense(9, activation='softmax')(x) #output layer for the 9 classes\n    \n    \n    model = tf.keras.models.Model(inputs, outputs)\n    \n    return model","77ab71bf":"model = create_model(input_shape = (224, 224, 3))","1e97031f":"model.compile(\n            optimizer='adam',\n            loss='categorical_crossentropy',\n            metrics=['accuracy']\n        )","9834d4d9":"history = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=5, # since we are running on CPU, we keep the number of epoch low\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping( # we apply earlystopping to prevent overfitting\n            monitor='val_loss',\n            patience=1, # we choose patience=1 to stop the model fit if val_loss won't decrease for an epoch\n            restore_best_weights=True # choose the best weights when early-stopping\n        )\n    ]\n)","2cfc118e":"plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title('Accuracy Plot')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend()\nplt.show()","b9b6920c":"plt.plot(history.history[\"loss\"], label=\"train_loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val_loss\")\nplt.title('Loss Plot')\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.legend()\nplt.show()","9ec2889f":"results = model.evaluate(test_images)","da2742af":"print('Training Accuracy: {:.2f}%'.format(history.history[\"accuracy\"][-1:][0]*100))\nprint('Validation Accuracy: {:.2f}%'.format(history.history[\"val_accuracy\"][-1:][0]*100))\nprint('Testing Accuracy: {:.2f}%'.format(results[1]*100))","b48f2176":"print('Training Loss: {:.3f}'.format(history.history[\"loss\"][-1:][0]))\nprint('Validation Loss: {:.3f}'.format(history.history[\"val_loss\"][-1:][0]))\nprint('Testing Loss: {:.3f}'.format(results[0]))","f167612f":"pred = model.predict(test_images)","bd23ce00":"pred[0]","b390d2e7":"[i * 100 for i in pred[0]] # we multiply by 100 to transform these values into probabilities with percentage","7b7f0c68":"pred = np.argmax(pred,axis=1)","24d2e4be":"labels_1 = (train_images.class_indices)\nlabels_1","4cd6759a":"labels = {y:x for x, y in labels_1.items()}\nlabels","6c8cbd23":"pred = [labels[idx] for idx in pred] # create a list of the predicted labels","ae8d11d4":"y_test = list(df_test.label)\nprint(classification_report(y_test, pred))","eb4f2cf8":"conf_matrix = confusion_matrix(y_test, pred, normalize='true')","4a3b503a":"plt.figure(figsize = (7,5))\nsns.heatmap(conf_matrix, cmap='Blues',annot=True, xticklabels = sorted(set(y_test)), yticklabels = sorted(set(y_test)))\nplt.title('Confusion Matrix (Normalized)')\nplt.show()","d44412b3":"fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(12, 7), subplot_kw={'xticks': [], 'yticks': []})\nfor idx, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(df_test.path.iloc[idx]))\n    ax.set_title(\"True: {} \\nPredicted: {}\".format(df_test.label.iloc[idx], pred[idx]), color=(\"green\" if pred[idx]==df_test.label.iloc[idx] else \"red\"))\nplt.tight_layout()\nplt.show()","9fdd3608":"Before feeding the images to the model, we need to define generators for the images!","e1006590":"# Model Testing","9e86cdee":"# Model Training","08cf7d33":"The model predicts that the first image in the test set correponds to the fifth class with a probability of 97%<br>\nIn order to keep the most likely label for each predicted label, we will use 'np.argmax' function from numpy library.","c72af3bd":"The model resulted in a 100% accuracy on training, validation and testing datasets, showing the power of transfer learning as well as the convenience of using pre trained models.","80f29645":"Then we split the dataset into train and test sets","8066d7a3":"# Data Preparation","a8de2707":"It looks like the net predicted all the images correctly","02d0f612":"It looks like we should shuffle the dataset!","f970841a":"# Model definition: MobileNETV2 fine tuning","48dd9dab":"We define a 'create model' function with the base model (MobileNETV2) and two additional dense layers: one hidden layer with 64 neurons and the output layers with 9 layers, since there are 9 classes to be classified.","4f4d3f32":"We should definitely remove these GT pictures !","599e9e02":"![fish dashboard.jpg](attachment:bcddb039-d532-42d0-91d7-834503be8793.jpg)","ec0c2687":"We call the method 'predict' of the neural network model:","9bd2deb6":"We removed 9000 pictures ! This means that each class had the GT version of pictures, which we removed.","f39aeed4":"First we shuffle the dataset","fec90694":"Indeed all of these 8 pictures have been correctly classified.","92a0a545":"# Generators definition","f2a38af5":"# Files import","33a43e8a":"Finally, we will display some test images with the actual and predicted labels","2cb11271":"It looks like some pictures are labeled with 'GT'. By reading the Dataset documentation, we understand that GT stands for 'Ground Truth', but how do these pictures look like?","7c0feed4":"**If there are any questions or if you want me to check out your works let me know with a comment!**","c92ccb35":"We check out the first predicted label!","a783a77b":"This project aims to apply Transfer Learning technique for an image recognition problem of fish images from the 'A Large Scale Fish Dataset' Dataset.<br>\nThe idea of Transfer Learning is to use pre-trained models on different datasets, add some more layers and fine tune the model to the specific dataset in use.<br> In this case, we will use the popular MobileNetV2 CNN from the tensorflow library and fine tune by using the fish dataset.<br>","86467513":"By calling the class_indices method on train_images, we can see that we get a dictionary where the keys are the classes and the values are the indexes.<br> We actually want to switch the keys with the values!","40d23eb8":"Now we need to extract the labels and their indeces during testing","d3983454":"Loss and Accuracy look great ! Now we should check the performance on the test set !","33149f01":"**Thank you for checking out my notebook! I hope everything is clearly explained \ud83e\udd16!**","605576b6":"# Main Results Summary Dashboard:","c4320001":"We will plot some pictures to check the pictures !","1fd819e6":"# Model Prediction : Fish Recognition","df1f9dba":"Now we have the correct labels and indexes!"}}