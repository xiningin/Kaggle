{"cell_type":{"02820f95":"code","3b8e730a":"code","c3e0263d":"code","06e757a2":"code","1da623ac":"code","1a437d05":"code","4da72ab9":"code","a31c8364":"code","d44048fb":"code","680948eb":"code","b9e17057":"code","59d165cb":"code","f0182e42":"code","c62c6e6e":"code","fbd4aec9":"markdown","e00b2837":"markdown","07e1cdf4":"markdown","008b0a13":"markdown","88490f8c":"markdown","df87db80":"markdown","febccb01":"markdown","0d52fadc":"markdown","5706f36a":"markdown","737e87be":"markdown","b644bfef":"markdown","fd7d83b5":"markdown","29091370":"markdown","df4adb37":"markdown","b7e382a4":"markdown","c2924de2":"markdown","041173c9":"markdown"},"source":{"02820f95":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os # Miscellaneous operating system interfaces","3b8e730a":"fpath = '..\/input\/daily-total-female-births-in-california-1959\/daily-total-female-births-CA.csv'\ndf = pd.read_csv(fpath, names=['date', 'births'], header=0, parse_dates=['date'], index_col='date')","c3e0263d":"df.head()","06e757a2":"df.tail(10)","1da623ac":"df.info()","1a437d05":"print('There are {} elements in the DataFrame'.format(df.size))\ndf.count()","4da72ab9":"# Select all date from December 1959 (month 12)\ndf['1959-12']","a31c8364":"# Make a boolean mask. start_date and end_date can be datetime.datetimes, np.datetime64s, pd.Timestamps, or even datetime strings:\nstart_date = '1959-03-23'\nend_date = '1959-04-02'\nmask = (df.index >= start_date) & (df.index <= end_date)\ndf[mask]\n\n# Alternate approaches using .loc method\n# df.loc['1959-03-23':'1959-04-02']\n# df.loc[start_date:end_date]","d44048fb":"df.loc['1959-01-24']","680948eb":"# Create data frame\nhourly = pd.DataFrame()\n\n# Create random integer values using numpy.random\navg = df['births'].div(24).mean()\nstdev = df['births'].div(24).std()\nhourly['births'] = np.random.normal(loc=avg, scale=stdev, size=(24*365)).astype(int)\n\n# Create datetimes, one per hour for each day in 1959\nhourly.index = pd.date_range('1\/1\/1959', periods=(24*365), freq='H')\n\n# Select all rows from a single date\nhourly.loc['1959-07-04']","b9e17057":"df.describe()","59d165cb":"# Get a list 'filename' of all practice files\nfolder = '..\/input\/time-series-practice-datasets\/'\nfilename = os.listdir(folder)\nfilename","f0182e42":"# Create a new DataFrame 'df', referencing a file name from the list\ndf = pd.read_csv(folder+filename[4])\ndf.head()","c62c6e6e":"dfxl = pd.read_excel(folder+filename[3])\ndfxl.head()","fbd4aec9":"[Describe](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.describe.html) gives us descriptive statistics about the distribution of the data, including the centrality (mean), range (min & max), and spread (percentiles and standard deviation). These give us an initial overview of the data and can help us see if there might be outliers or anomalies in the observations.","e00b2837":"N.B. If we wanted to use and exclusive start or end date, we simply remove the equals operator from the comparison (e.g. '>=' goes to '>').","07e1cdf4":"# Using Machine Learning to Forecast Time Series (Tutorial Series)\n\n## Intro to the series:\n\nThis is a six part series based on the  \"Time Series Forecasting With Python Mini-Course\" by Jason Brownlee at [MachineLearningMastery.com](https:\/\/machinelearningmastery.com\/category\/time-series\/). We will start by exploring the basics of manipulating and visualising time series data, before moving on to persistent forecasting models, and then finally autoregressive (AR) and ARIMA models.\n\n**Lesson 1:** Import and Explore Data\n\n**Lesson 2:** Visualising Time Series\n\n**Lesson 3:** Persistence Forecast Model\n\n**Lesson 4:** Autoregressive Forecast Model\n\n**Lesson 5:** ARIMA Forecast Model\n\n**Lesson 6:** End to End Project","008b0a13":"**2. Check the Dataframe structure and values**\n\n**a)\tPrint the first few rows using the head() method.**\n\n*Print the first 5 rows of the dataframe using the [.head()](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.head.html) method:\nNote that .head() defaults to the first 5 rows.*","88490f8c":"**4. c) Select a single date**","df87db80":"Note that you can change the list index to practice with a different file, e.g.\n    *filename[4]*\nThere is also an Excel spreadsheet (.xlsx) file in the practice files folder so that you can practice loading data from a different file format.\n    e.g. *pd_read_excel(folder+filename[3])*\n   ","febccb01":"**5.\tPrint summary statistics of observations in the dataframe.**","0d52fadc":"**4.\tQuery the dataset using date-time strings:**\n\n**a) Select all dates from a single month.**","5706f36a":"It's important to check our data is imported properly, with no missing or unexpected values and the correct data types for each column. Using the [info()](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.info.html) method we can see that the dataframe has 365 entries between 1959-01-01 and 1959-12-31, and that there are no null values in the births column. We can also use the [.size](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.size.html) attribute of the dataframe to check the number of elements in the dataframe. \n\nAnother way to check that there are no missing values in our dataframe is to use the [.count()](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.count.html) method, this returns a count of the non null values and data type for each column:","737e87be":"## Lesson 1:    Import and Explore Data\n\n### Lesson objective: \n\n#### *Practice loading and exploring time series data in Python:*\n\nBefore we can develop models for forecasting time series, we must load our data and look at it's structure. We will also generate some simple descriptive statistics to get an idea of the distribution of data points.\n\nThe Pandas library offers excellent functionality for loading data from .csv files.\n\nIn this lesson, we will load a standard time series dataset in Pandas and explore it. To follow along properly, you should have some knowledge of the pandas package, as well as basic knowledge of python.\n\nThis lesson uses a time series dataset of Female Births in California 1959 that was sourced from [datamarket.com](https:\/\/datamarket.com).\n\n*In the next lesson, we will cover using plotting libraries to visualize our time series data.*","b644bfef":"*Now we can use pandas read_csv function. We will specify arguments to set the column names, and the row number of the csv header. We will also tell pandas that we want to parse the 'date' column as datetime64, and make it the index for the dataframe (this will make slicing our data easier later on).*","fd7d83b5":"**2. b) \t Look at the structure of the dataframe using the info() method.**","29091370":"**4. b) Select all records between the two dates (inclusive).**","df4adb37":"Using head allows us to verify that the dataframe and .csv have the same values for the first few rows. We can do the same for the last rows using [.tail()](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.DataFrame.tail.html), this time let's try specifying a parameter for how many rows to display:","b7e382a4":"**1. Import the data using the pandas.read_csv() function.**\n\n*First, import the necessary modules:*","c2924de2":"**Assignments**\n\nTo cement your learning I would suggest forking this kernel and playing with the parameters and data to get practice working with time series data.\nTry a few of your own date values for the data slicing, can you find alternate syntax for slicing the data?\nCan you successfully make changes to the code and fix any errors? \nHow does changing the parameters effect the output?\n*Finally, try repeating the steps above with the other datasets included with this kernel (see the code blocks below this one).*\n\n**Extra Credit**\n\nFind some time series datasets of your own to practice with, there are many availabe for free, you can find them in [Kaggle's datasets](https:\/\/www.kaggle.com\/datasets?sortBy=hottest&group=public&page=1&pageSize=20&size=all&filetype=all&license=all&tagids=6618) and [datamarket.com](https:\/\/datamarket.com\/data\/list\/?q=provider:tsdl)\n\n*A lot of the learning process for picking up a programming language involves solving unexpected problems to gain real understanding of the language's syntax and how it functions. The best way to pick up a programming langauge is by trial and error, and through debugging code.*\n\n**Acknowledgements**\n\nThis lesson was adapted from the first lesson in Jason Brownlee's free mini course \"Time Series Forecasting With Python Mini-Course\" at [MachineLearningMastery.com](https:\/\/machinelearningmastery.com\/category\/time-series\/).\nI'd also like to give a shout out to Chris Albon who runs a very good data science blog at [ChrisAlbon.com](https:\/\/chrisalbon.com\/). There are tonnes of tutorials  covering a diverse range of topics on pandas and machine learning, all with excellent explanations and easy to follow code snippets.\n\n**Thanks!**\n\nThank you for taking the time to read my first public kernel! I hope that you enjoyed it, and perhaps learned something too. If this was a bit basic for you, please check out the lessons later in the series (coming soon, links will be added to this kernel), where I explore more advanced topics.\nI encourage you all to leave your feedback and criticism in the comments below, particularly if you have any questions or feel that more could be added :).","041173c9":"We can also use the same method to select all rows of data from a single day when we have a time series with a higher frequency (e.g. in hours, minutes, or seconds)."}}