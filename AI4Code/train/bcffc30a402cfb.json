{"cell_type":{"78a320ad":"code","93e3e5b4":"code","a263d66c":"code","78be609b":"code","bfcb27cd":"code","854c8460":"code","ca70f316":"code","06774461":"code","bfcc44c4":"code","7f7a90d7":"markdown"},"source":{"78a320ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93e3e5b4":"!pip install selenium\n!pip install beautifulsoup4\n!pip install requests","a263d66c":"from bs4 import BeautifulSoup\nimport requests\n\nURL = 'http:\/\/membership.stateboards.ie\/'\npage = requests.get(URL)\nsoup = BeautifulSoup(page.content, 'html.parser')\n\n","78be609b":"departments=[]\nurl=[]\nfor child in soup.find_all('ul')[2]:\n    if child.name == 'li':\n        departments.append(child.string)\n        url.append(child.a['href'])","bfcb27cd":"df_depts = pd.DataFrame({'Department':departments,'URL':url})","854c8460":"depts=[]\nboards=[]\nboards_url=[]\n\nfor index, row in df_depts.iterrows():\n    dept = row['Department']\n    dept_url = row['URL']\n    # URL = 'http:\/\/membership.stateboards.ie\/'\n    dept_page = requests.get(dept_url)\n    soup = BeautifulSoup(dept_page.content, 'html.parser')\n    for child in soup.find_all('ul')[2]:\n        if child.name == 'li':\n            depts.append(dept)\n            boards.append(child.string)\n            boards_url.append(child.a['href'])\n    df_boards = pd.DataFrame({'Department':depts,'Board':boards,'URL':boards_url})    ","ca70f316":"depts=[]\nboards=[]\nName=[]\nFirst_Appointed=[]\nReappointed=[]\nExpiry_Date=[]\nPosition_type=[]\nBasis_of_appointment=[]\n#dept = 'Department of Agriculture, Food and the Marine'\n#board = 'An Bord Bia'\n#board_url = 'http:\/\/membership.stateboards.ie\/board\/An%20Bord%20Bia\/'\nfor index, row in df_boards.iterrows():\n    dept = row['Department']\n    board = row['Board']\n    board_url = row['URL']\n    board_page = requests.get(board_url)\n    soup = BeautifulSoup(board_page.content, 'html.parser')\n    for child in soup.find_all('table')[0]:\n        if child.name == 'tr':\n            depts.append(dept)\n            boards.append(board)\n            Name.append(child.contents[1].string) #print(child.contents[1].string) # Name\n            First_Appointed.append(child.contents[3].string) #print(child.contents[3].string) # First Appointed\n            Reappointed.append(child.contents[5].string) #print(child.contents[5].string) # Reappointed\n            Expiry_Date.append(child.contents[7].string) #print(child.contents[7].string) # Expiry Date\n            Position_type.append(child.contents[9].string) #print(child.contents[9].string) # Position type\n            Basis_of_appointment.append(child.contents[11].string) #print(child.contents[11].string)# Basis of appointment\ndf_members = pd.DataFrame({'Department':depts,'Board':boards,'Name':Name,'First_Appointed':First_Appointed,'Reappointed':Reappointed,'Expiry_Date':Expiry_Date,'Position_type':Position_type,'Basis_of_appointment':Basis_of_appointment})    ","06774461":"# df_members\ndf_members.to_csv(r'df_members.csv')  \n","bfcc44c4":"from IPython.display import FileLink\nFileLink(r'df_members.csv')","7f7a90d7":"Now loop over each department and get the list of Boards"}}