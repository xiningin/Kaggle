{"cell_type":{"2fd2b197":"code","2282efa9":"code","cc982d7c":"code","ae4381ed":"code","825931c9":"code","d1828de8":"code","b9a3301c":"code","a8cd6ec5":"code","6848df26":"code","5e7bc24b":"code","c0c8d058":"code","c8acb8ab":"code","cf41ff76":"code","533c6153":"code","0a371631":"code","09959697":"code","940166bf":"code","039f602d":"code","19574b41":"code","2920b63b":"code","6c31c6a6":"markdown","13f54133":"markdown","133176a1":"markdown"},"source":{"2fd2b197":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2282efa9":"import cv2\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import normalize\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras.utils import to_categorical\n%matplotlib inline","cc982d7c":"# Get the path of files\nimage_directory='..\/input\/brain-tumor-detection\/'\n\nno_tumor_images=os.listdir(image_directory+ 'no\/')\nyes_tumor_images=os.listdir(image_directory+ 'yes\/')\n# initialize dataset and label arrays\ndataset=[]\nlabel=[]\n# set input size\nINPUT_SIZE=64","ae4381ed":"#loop over each image in each category\nfor i , image_name in enumerate(no_tumor_images):\n    #read the image if its extension is .jpg\n    if(image_name.split('.')[1]=='jpg'):\n        image=cv2.imread(image_directory+'no\/'+image_name)\n        image=Image.fromarray(image,'RGB')\n        #resize the image\n        image=image.resize((INPUT_SIZE,INPUT_SIZE))\n        #append image arry in dataset list and its label in label list\n        dataset.append(np.array(image))\n        label.append(0)\n# same for yes images\nfor i , image_name in enumerate(yes_tumor_images):\n    if(image_name.split('.')[1]=='jpg'):\n        image=cv2.imread(image_directory+'yes\/'+image_name)\n        image=Image.fromarray(image, 'RGB')\n        image=image.resize((INPUT_SIZE,INPUT_SIZE))\n        dataset.append(np.array(image))\n        label.append(1)\n\ndataset=np.array(dataset)\nlabel=np.array(label)\n","825931c9":"no_tumor_images[1]","d1828de8":"plt.imshow(dataset[21])","b9a3301c":"from collections import Counter \n# counts the number of occures of each label and save them in a dictionary\nc = Counter(label)\n#rename the keys and delete the old one\nc[\"Healthy\"] = c[0]\ndel c[0]\nc['Tumor'] = c[1]\ndel c[1]\n#plot each key and value in c \nplot=plt.bar(c.keys(), c.values())\nplot[1].set_color('r')\n\nplt.savefig('DataDistribution.png')","a8cd6ec5":"# convert RGB image to LAB\nHealthy_image = cv2.cvtColor(dataset[21],cv2.COLOR_BGR2LAB)\n# get LAB\nl,a,b = cv2.split(Healthy_image)\nplt.imshow(Healthy_image)\nplt.show()","6848df26":"# apply equalization histogram to perceptual lightness (L)\nequ1= cv2.equalizeHist(l)\nplt.imshow(equ1)\nplt.show()","5e7bc24b":"# plot equalization hist\nplt.hist(equ1.flat, bins=100, range=(0,255))\nplt.show()","c0c8d058":"Tumor = cv2.cvtColor(dataset[2000],cv2.COLOR_BGR2LAB)\nl,a,b = cv2.split(Tumor)\nplt.imshow(Tumor)\nplt.show()","c8acb8ab":"equ = cv2.equalizeHist(l)\nplt.imshow(equ)\nplt.show()","cf41ff76":"plt.hist(equ.flat, bins=100, range=(0,255))\nplt.show()","533c6153":"# Initialise the subplots using number of rows and columns\nfigure, axis = plt.subplots(2, 4)\n#custom layout\nfigure.set_figheight(10)\nfigure.set_figwidth(15)\n\ndef ploty (row,col,idx):\n    \n    \"\"\"\n    Function takes the row, col of figure, idx of image \n    to plot LAB image, its hist of l\n    \"\"\"\n   \n    \n    img = cv2.cvtColor(dataset[idx],cv2.COLOR_BGR2LAB)\n    b,g,r = cv2.split(img)\n    equ = cv2.equalizeHist(b)\n    axis[row,col].imshow(equ)\n        \n    axis[row,col+1].hist(equ.flat, bins=100, range=(0,255))\n# image from first half (not affected)\nploty(0,0,200)\n# image from second (affected)\nploty(1,0,2200)\nploty(0,2,600)\nploty(1,2,2600)\nfigure.suptitle(\"Equ healthy VS Equ tumor\")\nplt.show()\nplt.savefig('equ.png')","0a371631":"x_train, x_test, y_train, y_test=train_test_split(dataset, label, test_size=0.2, random_state=0)","09959697":"x_train=normalize(x_train,axis=1)\nx_test=normalize(x_test,axis=1)","940166bf":"model=Sequential()\n# 1st conv2D layer\nmodel.add(Conv2D(32,(3,3),input_shape=(INPUT_SIZE,INPUT_SIZE,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# 2nd conv2D layer\nmodel.add(Conv2D(32,(3,3),kernel_initializer='he_uniform'))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# 3rd conv2D layer\nmodel.add(Conv2D(32,(3,3),kernel_initializer='he_uniform'))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","039f602d":"tf.keras.utils.plot_model(model,\n                          to_file=\"model.png\",\n                          show_shapes=True,\n                          expand_nested=True)","19574b41":"def tr_plot(tr_data, start_epoch):\n    #Plot the loss and accuracy curve\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)\n    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout\n\n    plt.show()\n","2920b63b":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nhistory=model.fit(x_train,y_train,batch_size=16,verbose=1,epochs=17\n          , validation_data=(x_test,y_test),\n          shuffle=False)\n# plot the history\ntr_plot(history,0)\nplt.savefig('history.png')\nmodel.save('BrainTumor.h5')","6c31c6a6":"## 1. Importing","13f54133":"## 3. Building the model","133176a1":"## 2. Preprocessing "}}