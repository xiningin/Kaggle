{"cell_type":{"54f65f82":"code","09fb6718":"code","49ace117":"code","5c2f11b7":"code","769c7f51":"code","a45bf67d":"code","744147e7":"code","5a602dc2":"code","7d96676f":"code","645a3b8b":"code","5709c471":"code","f9d764bb":"code","a2a04f89":"code","97f02f6e":"code","7a37319f":"code","5afca43c":"code","ff6be49b":"code","6b2b13bc":"code","22b04b14":"code","c47128dd":"code","4a265455":"code","ef772e0e":"code","a6eaef48":"code","d885e898":"code","0d7e856b":"code","9fe4d42e":"code","4912a39b":"code","9fad55c2":"code","ba65b644":"code","0a0b7214":"code","7eb2067a":"code","05b5181d":"code","5c74434f":"code","5fb0c8d3":"code","c9b11526":"code","9fd910ef":"code","8d64d313":"code","23211f12":"code","813be02e":"code","ebfdbe6b":"code","9c58fbd6":"code","fac36cb6":"code","78a52618":"code","f1489a11":"code","8ec65cb1":"code","ef9d24b9":"code","6cd90796":"code","3f2cac63":"code","35896a85":"code","b5a56799":"code","ed8b3f3a":"code","a4eb92b6":"code","071f2eb8":"code","a0ae634a":"code","a25afe7e":"code","20e25ba8":"code","394092a0":"code","31bab702":"code","434d5889":"code","cc23312d":"code","4ed86262":"code","5b20465a":"code","e0d6a887":"code","56c4aae8":"code","0a9ccabe":"code","32c6f8cc":"code","b1917c7e":"code","3f961b68":"code","ea7f0fba":"code","5fae63c8":"code","b3ebf2ad":"code","d14b509b":"code","13d521a6":"code","2a494cc1":"code","cb707828":"code","65fb8678":"code","f5c10beb":"code","6c263990":"code","d6b2d10d":"code","50b21ae1":"markdown","3fb24536":"markdown","d0ec75e6":"markdown","93b143fa":"markdown","37ef724d":"markdown","9625c235":"markdown","74573602":"markdown","ee50b5c3":"markdown","7aca27ea":"markdown","ece91d9d":"markdown","d2354617":"markdown","e2d4d1b3":"markdown"},"source":{"54f65f82":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport random\nimport time\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\nfrom scipy.io import loadmat\nimport nibabel as nib\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\nimport skimage\nfrom skimage.morphology import convex_hull_image, erosion\nfrom IPython import display\nfrom scipy.ndimage import gaussian_filter\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose,\\\nLeakyReLU, GaussianNoise, GlobalMaxPooling2D, ReLU, Input, Concatenate\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\nfrom keras.models import Model\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","09fb6718":"Example_Train_NII_Path = \"..\/input\/heart-mri-image-dataset-left-atrial-segmentation\/imagesTr\/la_016.nii\"\nExample_Label_NII_Path = \"..\/input\/heart-mri-image-dataset-left-atrial-segmentation\/labelsTr\/la_016.nii\"","49ace117":"Example_Reading_Train_NII = nib.load(Example_Train_NII_Path)\nExample_Reading_Label_NII = nib.load(Example_Label_NII_Path)","5c2f11b7":"print(type(Example_Reading_Train_NII))","769c7f51":"print(Example_Reading_Train_NII) # general info","a45bf67d":"print(Example_Reading_Train_NII.affine)","744147e7":"print(Example_Reading_Train_NII.extra)","5a602dc2":"print(Example_Reading_Train_NII.dataobj.dtype)","7d96676f":"print(Example_Reading_Train_NII.get_data_dtype())","645a3b8b":"print(Example_Reading_Train_NII.get_filename())","5709c471":"print(Example_Reading_Train_NII.get_fdata())","f9d764bb":"print(Example_Reading_Train_NII.file_map.keys())","a2a04f89":"print(Example_Reading_Train_NII.file_map.items())","97f02f6e":"print(Example_Reading_Train_NII.file_map[\"image\"].filename)","7a37319f":"print(Example_Reading_Train_NII.get_qform())","5afca43c":"print(Example_Reading_Train_NII.get_data()) # image","ff6be49b":"print(Example_Reading_Train_NII.get_data().shape)","6b2b13bc":"print(Example_Reading_Train_NII.get_data()[0].shape)","22b04b14":"Example_ALL_Images = Example_Reading_Train_NII.get_data()\nExample_ALL_Labels = Example_Reading_Label_NII.get_data()","c47128dd":"print(Example_ALL_Images[0].shape)\nprint(Example_ALL_Labels[0].shape)","4a265455":"print(Example_ALL_Images[Example_ALL_Images.shape[0]\/\/2].shape)","ef772e0e":"print(Example_ALL_Images.shape[0]\/\/2)","a6eaef48":"print(Example_ALL_Images[Example_ALL_Images.shape[0]\/\/2])","d885e898":"print(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2].shape)","0d7e856b":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPlot_Color_Op = axis[0].imshow(Example_ALL_Images[Example_ALL_Images.shape[0]\/\/2])\naxis[0].set_xlabel(Example_ALL_Images.shape)\naxis[0].set_ylabel(Example_ALL_Images.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2])\naxis[1].set_xlabel(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2].shape)\naxis[1].set_ylabel(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2].size)\naxis[1].set_title(\"MASK\")\n\nfigure.colorbar(Plot_Color_Op, ax=axis.ravel().tolist(), shrink=0.3, ticks=range(10),label='LAYER')","9fe4d42e":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPlot_Color_Op = axis[0].imshow(Example_ALL_Images[Example_ALL_Images.shape[0]\/\/2],cmap=\"jet\")\naxis[0].set_xlabel(Example_ALL_Images.shape)\naxis[0].set_ylabel(Example_ALL_Images.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2],cmap=\"jet\")\naxis[1].set_xlabel(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2].shape)\naxis[1].set_ylabel(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2].size)\naxis[1].set_title(\"MASK\")\n\nfigure.colorbar(Plot_Color_Op, ax=axis.ravel().tolist(), shrink=0.3, ticks=range(10),label='LAYER')","4912a39b":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPlot_Color_Op = axis[0].imshow(Example_ALL_Images[Example_ALL_Images.shape[0]\/\/2],cmap=\"hot\")\naxis[0].set_xlabel(Example_ALL_Images.shape)\naxis[0].set_ylabel(Example_ALL_Images.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2],cmap=\"hot\")\naxis[1].set_xlabel(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2].shape)\naxis[1].set_ylabel(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2].size)\naxis[1].set_title(\"MASK\")\n\nfigure.colorbar(Plot_Color_Op, ax=axis.ravel().tolist(), shrink=0.3, ticks=range(10),label='LAYER')","9fad55c2":"figure,axis = plt.subplots(1,2,figsize=(10,10))\n\nPlot_Color_Op = axis[0].imshow(Example_ALL_Images[Example_ALL_Images.shape[0]\/\/2],cmap=\"Spectral\")\naxis[0].set_xlabel(Example_ALL_Images.shape)\naxis[0].set_ylabel(Example_ALL_Images.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2],cmap=\"Spectral\")\naxis[1].set_xlabel(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2].shape)\naxis[1].set_ylabel(Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2].size)\naxis[1].set_title(\"MASK\")\n\nfigure.colorbar(Plot_Color_Op, ax=axis.ravel().tolist(), shrink=0.3, ticks=range(10),label='LAYER')","ba65b644":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\nPicking_Example_IMG = Example_ALL_Images[Example_ALL_Images.shape[0]\/\/2] \/ 255.\nPicking_Example_Label = Example_ALL_Labels[Example_ALL_Images.shape[0]\/\/2] \/ 255.\n\naxis[0].imshow(Picking_Example_IMG)\naxis[0].set_xlabel(Picking_Example_IMG.shape)\naxis[0].set_ylabel(Picking_Example_IMG.size)\naxis[0].set_title(\"IMAGE\")\n\nPlot_Color_Op = axis[1].imshow(Picking_Example_Label)\naxis[1].set_xlabel(np.mean(Picking_Example_Label))\naxis[1].set_ylabel(Picking_Example_Label.size)\naxis[1].set_title(\"MASK\")\n\nfigure.colorbar(Plot_Color_Op, ax=axis.ravel().tolist(), shrink=0.3, ticks=range(10),label='LAYER')","0a0b7214":"Main_NII_Path = Path(\"..\/input\/heart-mri-image-dataset-left-atrial-segmentation\/imagesTr\")\nLabel_NII_Path = Path(\"..\/input\/heart-mri-image-dataset-left-atrial-segmentation\/labelsTr\")","7eb2067a":"NII_Images = list(Main_NII_Path.glob(r\"*.nii\"))\nNII_Labels = list(Label_NII_Path.glob(r\"*.nii\"))","05b5181d":"print(len(NII_Images))\nprint(len(NII_Labels))","5c74434f":"Images_Series = pd.Series(NII_Images,name=\"IMAGE\").astype(str)\nLabels_Series = pd.Series(NII_Labels,name=\"LABEL\").astype(str)","5fb0c8d3":"Main_Data = pd.concat([Images_Series,Labels_Series],axis=1)","c9b11526":"print(Main_Data.head(-1))","9fd910ef":"Or_1_0 = []\nImage_List = []\nLabel_List = []\n\nfor i_img,i_mask in zip(Main_Data[\"IMAGE\"].values,Main_Data[\"LABEL\"].values):\n\n    Reading_Train_NII = nib.load(i_img)\n    Reading_Label_NII = nib.load(i_mask)\n    \n    X_Images = Reading_Train_NII.get_data()\n    X_Labels = Reading_Label_NII.get_data()\n     \n    Selecting_Image = X_Images[X_Images.shape[0]\/\/2] \/ 255.\n    Selecting_Label = X_Labels[X_Images.shape[0]\/\/2] \/ 255.\n    \n    if np.mean(Selecting_Label) > 0:\n        Or_1_0.append(1)\n        Selecting_Image = Selecting_Image.astype(\"float32\")\n        Selecting_Label = Selecting_Label.astype(\"float32\")\n    \n        Image_List.append(Selecting_Image)\n        Label_List.append(Selecting_Label)\n    else:\n        Or_1_0.append(0)","8d64d313":"    \nfor i_img,i_mask in zip(Main_Data[\"IMAGE\"].values,Main_Data[\"LABEL\"].values):\n    Reading_Train_NII = nib.load(i_img)\n    Reading_Label_NII = nib.load(i_mask)\n    \n    X_Images = Reading_Train_NII.get_data()\n    X_Labels = Reading_Label_NII.get_data()\n     \n    Selecting_Image = X_Images[X_Images.shape[0]\/\/2] \/ 255.\n    Selecting_Label = X_Labels[X_Images.shape[0]\/\/2] \/ 255.\n    \n    print(np.shape(Selecting_Image))\n    print(np.shape(Selecting_Label))\n    print(\"---\"*20)","23211f12":"print(Or_1_0)","813be02e":"print(len(Or_1_0))","ebfdbe6b":"Main_Data[\"1_OR_0\"] = Or_1_0","9c58fbd6":"print(Main_Data.head(-1))","fac36cb6":"print(len(Image_List))\nprint(len(Label_List))","78a52618":"print(Image_List[0].shape)\nprint(Label_List[0].shape)","f1489a11":"print(type(Image_List[0]))\nprint(type(Label_List[0]))","8ec65cb1":"Testing_Trans = cv2.resize(Image_List[8],(256,256))","ef9d24b9":"print(Testing_Trans.shape)","6cd90796":"plt.imshow(Testing_Trans)","3f2cac63":"True_Seg = Main_Data[Main_Data[\"1_OR_0\"] == 1]","35896a85":"Image_List = []\nLabel_List = []\n\nfor i_img,i_mask in zip(True_Seg[\"IMAGE\"].values,True_Seg[\"LABEL\"].values):\n\n    Reading_Train_NII = nib.load(i_img)\n    Reading_Label_NII = nib.load(i_mask)\n    \n    X_Images = Reading_Train_NII.get_data()\n    X_Labels = Reading_Label_NII.get_data()\n     \n    Selecting_Image = X_Images[X_Images.shape[0]\/\/2] \/ 255.\n    Selecting_Label = X_Labels[X_Images.shape[0]\/\/2] \/ 255.\n    \n    Selecting_Image = Selecting_Image.astype(\"float32\")\n    Selecting_Label = Selecting_Label.astype(\"float32\")\n    \n    Resized_IMG = cv2.resize(Selecting_Image,(256,256))\n    Resized_LABEL = cv2.resize(Selecting_Label,(256,256))\n    \n    Image_List.append(Resized_IMG)\n    Label_List.append(Resized_LABEL)","b5a56799":"print(len(Image_List))\nprint(len(Label_List))","ed8b3f3a":"for indexing_i in range(len(Image_List)):\n    print(\"---\"*10)\n    print(Image_List[indexing_i].shape)\n    print(Label_List[indexing_i].shape)","a4eb92b6":"print(np.shape(np.array(Image_List)))\nprint(np.shape(np.array(Label_List)))","071f2eb8":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\nPicking_Example_IMG = Image_List[0]\nPicking_Example_Label = Label_List[0]\n\naxis[0].imshow(Picking_Example_IMG)\naxis[0].set_xlabel(Picking_Example_IMG.shape)\naxis[0].set_ylabel(Picking_Example_IMG.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Picking_Example_Label)\naxis[1].set_xlabel(np.mean(Picking_Example_Label))\naxis[1].set_ylabel(Picking_Example_Label.size)\naxis[1].set_title(\"MASK\")","a0ae634a":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\nPicking_Example_IMG = Image_List[2]\nPicking_Example_Label = Label_List[2]\n\naxis[0].imshow(Picking_Example_IMG)\naxis[0].set_xlabel(Picking_Example_IMG.shape)\naxis[0].set_ylabel(Picking_Example_IMG.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Picking_Example_Label)\naxis[1].set_xlabel(np.mean(Picking_Example_Label))\naxis[1].set_ylabel(Picking_Example_Label.size)\naxis[1].set_title(\"MASK\")","a25afe7e":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\nPicking_Example_IMG = Image_List[8]\nPicking_Example_Label = Label_List[8]\nPicking_Example_Label = Picking_Example_Label.astype(\"uint8\")\nPicking_Example_IMG = Picking_Example_IMG.astype(\"uint8\")\n\nCanny_Image = cv2.Canny(Picking_Example_Label,10,100)\n\nNP_Kernel = np.ones((5,5),np.uint8)\nDilation_Image = cv2.dilate(Canny_Image,NP_Kernel,iterations = 5)\n\nBlend_Image = cv2.addWeighted(Picking_Example_IMG,0.8,Dilation_Image,0.4,0.5)\n\naxis[0].imshow(Picking_Example_IMG)\naxis[0].set_xlabel(Picking_Example_IMG.shape)\naxis[0].set_ylabel(Picking_Example_IMG.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Blend_Image)\naxis[1].set_xlabel(np.mean(Blend_Image))\naxis[1].set_ylabel(Blend_Image.size)\naxis[1].set_title(\"MASK\")","20e25ba8":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\nPicking_Example_IMG = Image_List[0]\nPicking_Example_Label = Label_List[0]\nPicking_Example_Label = Picking_Example_Label.astype(\"uint8\")\nPicking_Example_IMG = Picking_Example_IMG.astype(\"uint8\")\n\nCanny_Image = cv2.Canny(Picking_Example_Label,10,100)\n\nNP_Kernel = np.ones((5,5),np.uint8)\nDilation_Image = cv2.dilate(Canny_Image,NP_Kernel,iterations = 5)\n\nBlend_Image = cv2.addWeighted(Picking_Example_IMG,0.8,Dilation_Image,0.4,0.5)\n\naxis[0].imshow(Picking_Example_IMG)\naxis[0].set_xlabel(Picking_Example_IMG.shape)\naxis[0].set_ylabel(Picking_Example_IMG.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Blend_Image,cmap=\"jet\")\naxis[1].set_xlabel(np.mean(Blend_Image))\naxis[1].set_ylabel(Blend_Image.size)\naxis[1].set_title(\"MASK\")","394092a0":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\nPicking_Example_IMG = Image_List[0]\nPicking_Example_Label = Label_List[0]\nPicking_Example_Label = Picking_Example_Label.astype(\"uint8\")\nPicking_Example_IMG = Picking_Example_IMG.astype(\"uint8\")\n\nCanny_Image = cv2.Canny(Picking_Example_Label,10,100)\n\nNP_Kernel = np.ones((5,5),np.uint8)\nDilation_Image = cv2.dilate(Canny_Image,NP_Kernel,iterations = 5)\n\nBlend_Image = cv2.addWeighted(Picking_Example_IMG,0.8,Dilation_Image,0.4,0.5)\n\naxis[0].imshow(Picking_Example_IMG)\naxis[0].set_xlabel(Picking_Example_IMG.shape)\naxis[0].set_ylabel(Picking_Example_IMG.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Blend_Image,cmap=\"hot\")\naxis[1].set_xlabel(np.mean(Blend_Image))\naxis[1].set_ylabel(Blend_Image.size)\naxis[1].set_title(\"MASK\")","31bab702":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\nPicking_Example_IMG = Image_List[11]\nPicking_Example_Label = Label_List[11]\nPicking_Example_Label = Picking_Example_Label.astype(\"uint8\")\nPicking_Example_IMG = Picking_Example_IMG.astype(\"uint8\")\n\nBlend_Image = cv2.addWeighted(Picking_Example_IMG,0.8,Picking_Example_Label,0.4,0.5)\n\naxis[0].imshow(Picking_Example_IMG)\naxis[0].set_xlabel(Picking_Example_IMG.shape)\naxis[0].set_ylabel(Picking_Example_IMG.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Blend_Image)\naxis[1].set_xlabel(np.mean(Blend_Image))\naxis[1].set_ylabel(Blend_Image.size)\naxis[1].set_title(\"MASK\")","434d5889":"figure,axis = plt.subplots(1,2,figsize=(12,12))\n\nPicking_Example_IMG = Image_List[11]\nPicking_Example_Label = Label_List[11]\nPicking_Example_Label = Picking_Example_Label.astype(\"uint8\")\nPicking_Example_IMG = Picking_Example_IMG.astype(\"uint8\")\n\nBlend_Image = cv2.addWeighted(Picking_Example_IMG,0.8,Picking_Example_Label,0.4,0.5)\n\naxis[0].imshow(Picking_Example_IMG)\naxis[0].set_xlabel(Picking_Example_IMG.shape)\naxis[0].set_ylabel(Picking_Example_IMG.size)\naxis[0].set_title(\"IMAGE\")\n\naxis[1].imshow(Blend_Image,cmap=\"gray\")\naxis[1].set_xlabel(np.mean(Blend_Image))\naxis[1].set_ylabel(Blend_Image.size)\naxis[1].set_title(\"MASK\")","cc23312d":"X_TRAIN = np.array(Image_List,dtype=\"float32\")\nX_LABEL = np.array(Label_List,dtype=\"float32\")","4ed86262":"print(X_TRAIN.shape)\nprint(X_LABEL.shape)","5b20465a":"X_TRAIN = X_TRAIN.reshape(X_TRAIN.shape[0],X_TRAIN.shape[1],X_TRAIN.shape[2],1)\nX_LABEL = X_LABEL.reshape(X_LABEL.shape[0],X_LABEL.shape[1],X_LABEL.shape[2],1)","e0d6a887":"print(X_TRAIN.shape)\nprint(X_LABEL.shape)","56c4aae8":"print(X_TRAIN[0:-1].shape)","0a9ccabe":"Encoder = Sequential()\n#\nEncoder.add(Conv2D(32,(5,5),kernel_initializer = 'he_normal',use_bias=True,name=\"ENCODER_INPUT\"))\nEncoder.add(BatchNormalization())\nEncoder.add(ReLU())\n#\nEncoder.add(Conv2D(64,(5,5),kernel_initializer = 'he_normal',use_bias=True))\nEncoder.add(BatchNormalization())\nEncoder.add(ReLU())\n#\nEncoder.add(Conv2D(128,(2,2),kernel_initializer = 'he_normal',use_bias=True))\nEncoder.add(BatchNormalization())\nEncoder.add(ReLU())\n#\nEncoder.add(Conv2D(128,(2,2),kernel_initializer = 'he_normal',use_bias=True))\nEncoder.add(BatchNormalization())\nEncoder.add(ReLU())\n\n\n\nDecoder = Sequential()\n#\nDecoder.add(Conv2DTranspose(128,(2,2)))\nDecoder.add(ReLU())\n#\nDecoder.add(Conv2DTranspose(64,(2,2)))\nDecoder.add(ReLU())\n#\nDecoder.add(Conv2DTranspose(32,(5,5)))\nDecoder.add(ReLU())\n#\nDecoder.add(Conv2DTranspose(1,(5,5),name=\"DECODER_OUTPUT\"))","32c6f8cc":"AE_Structure = Sequential([Encoder,Decoder])","b1917c7e":"AE_Structure.compile(loss=\"binary_crossentropy\",optimizer=Adam(lr=0.0000001),metrics=[\"accuracy\"])","3f961b68":"AE_Model = AE_Structure.fit(X_TRAIN[0:-1],X_LABEL[0:-1],epochs=100)","ea7f0fba":"Prediction_MASK = AE_Structure.predict(X_TRAIN[:10])","5fae63c8":"figure,axis = plt.subplots(1,2,figsize=(14,14))\nimg_number = 1\n\nOriginal_Img = X_TRAIN[img_number]\nPredict_Mask = Prediction_MASK[img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"IMAGE\")\naxis[1].imshow(Predict_Mask,cmap=\"jet\")\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"PREDICTION\")","b3ebf2ad":"figure,axis = plt.subplots(1,2,figsize=(14,14))\nimg_number = 2\n\nOriginal_Img = X_TRAIN[img_number]\nPredict_Mask = Prediction_MASK[img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"IMAGE\")\naxis[1].imshow(Predict_Mask,cmap=\"hot\")\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"PREDICTION\")","d14b509b":"figure,axis = plt.subplots(1,2,figsize=(14,14))\nimg_number = 3\n\nOriginal_Img = X_TRAIN[img_number]\nPredict_Mask = Prediction_MASK[img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"IMAGE\")\naxis[1].imshow(Predict_Mask,cmap=\"jet\")\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"PREDICTION\")","13d521a6":"figure,axis = plt.subplots(1,2,figsize=(14,14))\nimg_number = 7\n\nOriginal_Img = X_TRAIN[img_number]\nPredict_Mask = Prediction_MASK[img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"IMAGE\")\naxis[1].imshow(Predict_Mask,cmap=\"jet\")\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"PREDICTION\")","2a494cc1":"figure,axis = plt.subplots(1,3,figsize=(14,14))\nimg_number = 9\n\nOriginal_Img = X_TRAIN[img_number]\nPredict_Mask = Prediction_MASK[img_number]\nMain_Mask = X_LABEL[img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"IMAGE\")\naxis[1].imshow(Main_Mask)\naxis[1].set_xlabel(Main_Mask.shape)\naxis[1].set_ylabel(Main_Mask.size)\naxis[1].set_title(\"MASKING\")\naxis[2].imshow(Predict_Mask,cmap=\"jet\")\naxis[2].set_xlabel(Predict_Mask.shape)\naxis[2].set_ylabel(Predict_Mask.size)\naxis[2].set_title(\"PREDICTION\")","cb707828":"figure,axis = plt.subplots(1,3,figsize=(14,14))\nimg_number = 1\n\nOriginal_Img = X_TRAIN[img_number]\nPredict_Mask = Prediction_MASK[img_number]\nMain_Mask = X_LABEL[img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"IMAGE\")\naxis[1].imshow(Main_Mask)\naxis[1].set_xlabel(Main_Mask.shape)\naxis[1].set_ylabel(Main_Mask.size)\naxis[1].set_title(\"MASKING\")\naxis[2].imshow(Predict_Mask,cmap=\"jet\")\naxis[2].set_xlabel(Predict_Mask.shape)\naxis[2].set_ylabel(Predict_Mask.size)\naxis[2].set_title(\"PREDICTION\")","65fb8678":"figure,axis = plt.subplots(1,3,figsize=(14,14))\nimg_number = 5\n\nOriginal_Img = X_TRAIN[img_number]\nPredict_Mask = Prediction_MASK[img_number]\nMain_Mask = X_LABEL[img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"IMAGE\")\naxis[1].imshow(Main_Mask)\naxis[1].set_xlabel(Main_Mask.shape)\naxis[1].set_ylabel(Main_Mask.size)\naxis[1].set_title(\"MASKING\")\naxis[2].imshow(Predict_Mask,cmap=\"jet\")\naxis[2].set_xlabel(Predict_Mask.shape)\naxis[2].set_ylabel(Predict_Mask.size)\naxis[2].set_title(\"PREDICTION\")","f5c10beb":"print(X_TRAIN[17:].shape)","6c263990":"Prediction_NON_SEEN = AE_Structure.predict(X_TRAIN[17:])","d6b2d10d":"figure,axis = plt.subplots(1,2,figsize=(14,14))\nimg_number = 17\n\nOriginal_Img = X_TRAIN[img_number]\nPredict_Mask = Prediction_NON_SEEN[0]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"IMAGE\")\naxis[1].imshow(Predict_Mask,cmap=\"jet\")\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"PREDICTION\")","50b21ae1":"#### READING PROCESS","3fb24536":"#### EXAMPLE PATH","d0ec75e6":"# OVERVIEW","93b143fa":"# DATA PROCESS","37ef724d":"# MODEL","9625c235":"# HISTORY\n\n* This repository is associated with the Left Atrial Segmentation Challenge 2013 (LASC'13). LASC'13 was part of the STACOM'13 workshop, held in conjunction with MICCAI'13. Seven international research groups, comprising 11 algorithms, participated in the challenge.\n\n* For a detailed report, please refer to:\n\n* Tobon-Gomez C, Geers AJ, Peters, J, Weese J, Pinto K, Karim R, Ammar M, Daoudi A, Margeta J, Sandoval Z, Stender B, Zheng Y, Zuluaga, MA, Betancur J, Ayache N, Chikh MA, Dillenseger J-L, Kelm BM, Mahmoudi S, Ourselin S, Schlaefer A, Schaeffter T, Razavi R, Rhode KS. Benchmark for Algorithms Segmenting the Left Atrium From 3D CT and MRI Datasets. IEEE Transactions on Medical Imaging, 34(7):1460\u20131473, 2015.\n\n* The challenge is also featured on Cardiac Atlas Project.\n\n* The Python scripts in this repository take as input a segmentation and output the two evaluation metrics described in the paper.\n\n* The data and code of the challenge have been made publicly available to serve as a benchmark for left atrial segmentation algorithms.\n\n\n* **CT**: Computed tomography\n* **GT**: Ground truth\n* **MRI**: Magnetic resonance imaging\n* **LA**: Left atrium\n* **LASC**'13: Left Atrial Segmentation Challenge 2013\n* **PV**: Pulmonary vein\n\n\n* The benchmark consists of 30 CT and 30 MRI datasets. Per modality, 10 datasets are for training of segmentation algorithms and 20 datasets are for testing.\n\n#### The MRI datasets are publicly available on Figshare:\n* Training\n* Testing\n* Results","74573602":"#### PATH PROCESS","ee50b5c3":"# PACKAGES AND LIBRARIES","7aca27ea":"#### TO ARRAY","ece91d9d":"#### CHECKING","d2354617":"#### EXAMPLE VISION","e2d4d1b3":"#### WHAT IS NII\n\n\n* NII files mostly belong to NIfTI-1 Data Format by Neuroimaging Informatics Technology Initiative. NIfTI-1 is adapted from the widely used ANALYZE 7.5 file format. The hope is that older non-NIfTI-aware software that uses the ANALYZE 7.5 format will still be compatible with NIfTI-1.\n\n\n**Identifier:**\tHex: 00 00 01 5C 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\n\n\n* You need a suitable software like NIfTI-1 Data Format from Neuroimaging Informatics Technology Initiative to open a NII file. Without proper software you will receive a Windows message \"How do you want to open this file?\" or \"Windows cannot open this file\" or a similar Mac\/iPhone\/Android alert."}}