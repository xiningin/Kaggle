{"cell_type":{"7bc8e952":"code","46e39b2d":"code","f160632f":"code","3b900bb1":"code","c280cc0e":"code","ab34cce1":"code","92f29bf0":"code","69d210c8":"code","3b98e86e":"code","95ebd1c3":"code","22b3a2c3":"code","f721c71b":"code","cbefd5bb":"code","0740402c":"code","f5ad90b9":"code","22da017b":"code","a4b41aeb":"code","b30aedda":"code","7a383fb6":"code","acee1fd3":"code","fa2fb369":"code","2fc694a0":"code","55d0b189":"markdown","a2e0bdfa":"markdown","95d949d3":"markdown","d80252c6":"markdown","9a62484b":"markdown","fc4ef75e":"markdown","2c5f9b2f":"markdown","7ffc945c":"markdown","b66815d2":"markdown","26265713":"markdown"},"source":{"7bc8e952":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Layer\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","46e39b2d":"disease_types = ['Pepper__bell___Bacterial_spot','Pepper__bell___healthy','Potato___Early_blight',\n                 'Potato___Late_blight','Potato___healthy','Tomato_Bacterial_spot',\n                 'Tomato_Early_blight','Tomato_Late_blight','Tomato_Leaf_Mold',\n                 'Tomato_Septoria_leaf_spot','Tomato_Spider_mites_Two_spotted_spider_mite','Tomato__Target_Spot',\n                 'Tomato__Tomato_YellowLeaf__Curl_Virus','Tomato__Tomato_mosaic_virus','Tomato_healthy'\n                ]\n\ndata_dir = '..\/input\/plantdisease\/PlantVillage\/'\ntrain_dir = os.path.join(data_dir)","f160632f":"train_data = []\nfor diseases, sp in enumerate(disease_types):\n    for file in os.listdir(os.path.join(train_dir, sp)):\n        train_data.append(['{}\/{}'.format(sp, file), diseases, sp])\n        \ntrain = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])\ntrain.head(5)","3b900bb1":"seed = 45\ntrain = train.sample(frac=1, random_state = seed)\ntrain_index = np.arange(len(train)) #to reset the indices\ntrain.head()","c280cc0e":"def disease_type(disease_type, rows, cols):\n    fig,ax = plt.subplots(rows, cols, figsize=(12,12))\n    disease_type = train['File'][train['Disease Type'] == disease_type].values\n    n = 0\n    for i in range(rows):\n        for j in range(cols):\n            image_path = os.path.join(data_dir, disease_type[n])\n            ax[i, j].set_xticks([])\n            ax[i, j].set_yticks([])\n            ax[i, j].imshow(cv2.imread(image_path))\n            n += 1\n# Displays first n images of class from training set\ndisease_type('Tomato_Bacterial_spot', 5, 5)","ab34cce1":"disease_type('Tomato_healthy', 5, 5) ","92f29bf0":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255, validation_split = 0.2)\nvalidation_generator = datagen.flow_from_directory(\n    data_dir, \n    shuffle=False, \n    seed=42,\n    color_mode=\"rgb\",\n    class_mode=\"categorical\")\n\ntrain_generator = datagen.flow_from_directory(\n    data_dir, \n    subset=\"training\", \n    shuffle=True, \n    seed=42,\n    color_mode=\"rgb\", \n    class_mode=\"categorical\")","69d210c8":"module_selection = (\"inception_v3\", 299, 2048) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\nhandle_base, pixels, FV_SIZE = module_selection\nMODULE_HANDLE =\"https:\/\/tfhub.dev\/google\/tf2-preview\/{}\/feature_vector\/2\".format(handle_base)\nIMAGE_SIZE = (pixels, pixels)\nprint(\"Using {} with input size {} and output dimension {}\".format(\n  MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))\nBATCH_SIZE = 64\n","3b98e86e":"import tensorflow_hub as hub\nfeature_extractor = hub.KerasLayer(MODULE_HANDLE,\n                                   input_shape=IMAGE_SIZE+(3,),\n                                   output_shape=[FV_SIZE])","95ebd1c3":"do_fine_tuning = False #@param {type:\"boolean\"}\nif do_fine_tuning:\n    feature_extractor.trainable = True\n  # unfreeze some layers of base network for fine-tuning\n    for layer in base_model.layers[-30:]:\n        layer.trainable =True\nelse:\n    feature_extractor.trainable = False","22b3a2c3":"print(\"Building model with\", MODULE_HANDLE)\nmodel = tf.keras.Sequential([\n    feature_extractor,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(rate=0.5),\n    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax',\n                           kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n])\n#model.build((None,)+IMAGE_SIZE+(3,))\n\nmodel.summary()","f721c71b":"#LEARNING_RATE = 0.001 #@param {type:\"number\"}\n\nmodel.compile(\n   optimizer=tf.keras.optimizers.Adam(), \n   loss='categorical_crossentropy',\n   metrics=['accuracy'])","cbefd5bb":"EPOCHS=5 #@param {type:\"integer\"}\n\n#annealer = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('plant_model.h5', verbose=1, save_best_only=True)\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)\n\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch=train_generator.samples\/\/train_generator.batch_size,\n        epochs=EPOCHS,\n        validation_data=validation_generator,\n    callbacks = [checkpoint, callback],\n        validation_steps=validation_generator.samples\/\/validation_generator.batch_size)","0740402c":"preds = model.predict_generator(validation_generator, steps=5)\nlabel = validation_generator.classes\npred = model.predict(validation_generator)\n\npredicted_class_indices=np.argmax(pred,axis=1)","f5ad90b9":"labels = (validation_generator.class_indices)\nlabels2 = dict((v,k) for k,v in labels.items())\npredictions = [labels2[k] for k in predicted_class_indices]","22da017b":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\ncf_report = classification_report(predicted_class_indices,label)\ncm = confusion_matrix(predicted_class_indices,label)\n\nprint(cf_report)","a4b41aeb":"plt.figure(figsize=(15,15))\nax = sns.heatmap(cm, cmap=plt.cm.plasma, annot=True, square=True, xticklabels=disease_types, yticklabels=disease_types)\n\nax.set_ylabel('Actual', fontsize=40)\nax.set_xlabel('Predicted', fontsize=40)","b30aedda":"image_path = '..\/input\/plantdisease\/PlantVillage\/Pepper__bell___Bacterial_spot\/01613cd0-d3cd-4e96-945c-a312002037bf___JR_B.Spot 3262.JPG'\nimage = tf.keras.preprocessing.image.load_img(image_path)\ninput_arr = tf.keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr])  # Convert single image to a batch.\npreds1 = model.predict_classes(input_arr)","7a383fb6":"preds1","acee1fd3":"converter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_float_model = converter.convert()\n\n# Show model size in KBs.\nfloat_model_size = len(tflite_float_model) \/ 1024\nprint('Float model size = %dKBs.' % float_model_size)","fa2fb369":" # Re-convert the model to TF Lite using quantization.\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\ntflite_quantized_model = converter.convert()\n\n# Show model size in KBs.\nquantized_model_size = len(tflite_quantized_model) \/ 1024\nprint('Quantized model size = %dKBs,' % quantized_model_size)\nprint('which is about %d%% of the float model size.'\\\n      % (quantized_model_size * 100 \/ float_model_size))\n","2fc694a0":"f = open('plant_model.tflite', \"wb\")\nf.write(tflite_quantized_model)\nf.close()","55d0b189":"# Converting to Tensorflow Lite","a2e0bdfa":"**Let's look at some healthy samples**","95d949d3":"**Let's create Helper functions for visualizing diseases**","d80252c6":"# Specifying Loss Functions","9a62484b":"# Image Data Augmentation","fc4ef75e":"**7 is tomato late blight image**","2c5f9b2f":"# Introduction","7ffc945c":"# Randomizing the Training Sample","b66815d2":"# Random Image testing","26265713":"# Build Model"}}