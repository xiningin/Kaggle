{"cell_type":{"d2d4e50b":"code","35883cb4":"code","3bbbb38f":"code","dd3d9f31":"code","43ea950e":"code","c3d4850b":"code","8e927dc9":"code","58482ac8":"code","e642a56f":"code","eb534d2c":"code","f89e6c8e":"code","6753927d":"code","7c26be23":"code","66c7c0d4":"code","a7a02b17":"code","72c8f876":"code","bb413e54":"code","38fbdcb0":"code","8ba5f932":"code","97a626f8":"markdown","c9876898":"markdown","f9e7c1ce":"markdown","295bba28":"markdown","f0d096e3":"markdown","22fea224":"markdown","da0a19b8":"markdown","c5f8143c":"markdown","b91c5756":"markdown","6a0dbfee":"markdown","740f28fe":"markdown","23d4a230":"markdown","51765dd2":"markdown","a0d3cf4c":"markdown","bfdd4816":"markdown","3534194e":"markdown","6ae21877":"markdown","1fadd80f":"markdown","389188df":"markdown","d41d6f89":"markdown","1c55ec63":"markdown","01126f41":"markdown"},"source":{"d2d4e50b":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split, ParameterGrid, cross_val_score, RepeatedKFold, RepeatedStratifiedKFold\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","35883cb4":"# load the dataframe\ndf = pd.read_csv(\"..\/input\/diabetes-data-set\/diabetes-dataset.csv\")","3bbbb38f":"# print out the head of the dataframe and the shape\ndf.head()","dd3d9f31":"# get the shape\ndf.shape","43ea950e":"df[\"Outcome\"].value_counts()","c3d4850b":"# check for null entries\ndf.isna().sum()","8e927dc9":"# check for duplicate entries\nnum_duplicate_entries = df.duplicated(subset=None, keep='first').sum()\nnum_duplicate_entries","58482ac8":"# to which class do the duplicates belong to\nduplicate_data = df[df.duplicated(subset=None, keep='first')]\nduplicate_data.Outcome.value_counts()","e642a56f":"corr = df.corr() # compute the correlation matrix\nmask = np.triu(np.ones_like(corr, dtype=bool)) # define the upper-triangular mask for the heatmap\ncmap = sns.color_palette(\"Blues\", as_cmap=True) # define the color palette to use\nplt.figure(figsize=(12, 10)) # update the figure size to dispaly nicely\nsns.heatmap(corr, mask=mask, cmap=cmap, square=True, annot=True)","eb534d2c":"# use pairplot to show relationships between features and individual distributions\nplt.figure(figsize=(12, 10))\nsns.pairplot(data=df, hue=\"Outcome\", corner=True, diag_kind=\"kde\")","f89e6c8e":"df.describe()","6753927d":"for column in df.columns[:-1]:\n    plt.figure(figsize=(12, 10))\n    plt.title(f\"{column} Boxplot\")\n    sns.boxplot(data=df, x=column)","7c26be23":"for column in df.columns[:-1]:\n    Q1 = df[column].quantile(0.25)\n    Q3 = df[column].quantile(0.75)\n    IQR = Q3 - Q1\n    outlier_range = (df[column] < (Q1 - 1.5*IQR)) | (df[column] > (Q3 + 1.5 * IQR))\n    num_outliers = df[column][outlier_range].count()\n    \n    print(f\"{column}: {num_outliers} outliers\")","66c7c0d4":"# split our data into train\/test sets to avoid data leakage\ntrain_df, test_df = train_test_split(df, test_size=0.25, random_state=0)","a7a02b17":"train_df[\"Outcome\"].value_counts()","72c8f876":"# get all the duplicated rows\ntrain_dups = train_df[train_df.duplicated(subset=None, keep='first')]\n# get the index of all the healthy duplicates\nhealthy_dups = train_dups.loc[train_df[\"Outcome\"] == 0].index\n# drop the healthy duplicates\ntrain_df = train_df.drop(healthy_dups)","bb413e54":"# separate the data from the labels\nX_train, y_train = train_df.drop(columns=[\"Outcome\"], axis=1), train_df[\"Outcome\"]\nX_test, y_test = test_df.drop(columns=[\"Outcome\"], axis=1), test_df[\"Outcome\"]\n\n# create the scaler\nscaler = RobustScaler()\n# fit the scaler and transform our data\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","38fbdcb0":"def get_train_test_accuracy(X_train, y_train, X_test, y_test, model, param_grid):\n    \"\"\"Function to compute and return the training accuracy for the given model\n    \n    Args:\n        X_train: The training data.\n        y_train: The training labels.\n        X_test: The testing data.\n        y_test: The testing labels.\n        model: The model name to train.\n        param_grid: The set of parameters to train the model on.\n    \n    Returns:\n        train_acc: The training accuracy of the given model.\n        test_acc: The testing accuracy of the given model.\n    \"\"\"\n    \n    # create the parameter grid to iterate over\n    params = ParameterGrid(param_grid)\n\n    mean_cv_scores = [] # maintain the cross-validation scores\n    # iterate over each of the parameters\n    for param in params:\n        # create the model using the specified param\n        clf = model(**param)\n\n        # compute the cross-validation score\n        cv_scores = cross_val_score(\n                estimator=clf,\n                X=X_train,\n                y=y_train,\n                scoring=\"accuracy\",\n                cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=10),\n        )\n\n        # compute the mean sore\n        mean_cv_score = np.mean(cv_scores)\n\n        # append the mean score to the array\n        mean_cv_scores.append(mean_cv_score)\n\n    # get the best model's index, cv score, and parameter dict\n    best_model_index = np.argmax(mean_cv_scores)\n    best_mean_cv_score = round(mean_cv_scores[best_model_index] * 100, 3)\n    best_params = params[best_model_index]\n\n    # recreate model using best parameters\n    best_clf = model(**best_params)\n\n    # refit the model on full training set\n    best_clf.fit(X_train, y_train)\n\n    # get predictions\n    train_pred = best_clf.predict(X_train)\n    test_pred = best_clf.predict(X_test)\n\n    # compute the accuracies\n    train_acc = round(accuracy_score(y_train, train_pred) * 100, 3)\n    test_acc = round(accuracy_score(y_test, test_pred) * 100, 3)\n\n    # return the scores\n    return train_acc, best_mean_cv_score, test_acc","8ba5f932":"model_names = [\n    \"KNN\",\n    \"Decision Tree\",\n    \"Logisitc Regression\",\n    \"SVM\",\n    \"Random Forest\"\n]\nmodel_classes = [\n    KNeighborsClassifier,\n    DecisionTreeClassifier,\n    LogisticRegression,\n    SVC,\n    RandomForestClassifier\n]\n\nparam_grids = [\n    {\"n_neighbors\": np.arange(1, 6, 1)},\n    {\"max_depth\": [i for i in range(1, 11)] + [None]},\n    {\"C\": np.arange(0.1, 5.1, 0.1)},\n    {\"C\": np.arange(0.1, 5.1, 0.1)},\n    {\"n_estimators\": np.arange(250, 325, 25)}\n]\n\nresults = []\nfor model_name, model_class, param_grid in zip(model_names, model_classes, param_grids):\n    train_acc, mean_val_acc, test_acc = get_train_test_accuracy(X_train, y_train, X_test, y_test, model_class, param_grid)\n    \n    # add results to array\n    results.append([model_name, train_acc, mean_val_acc, test_acc])\n\nfinal_df = pd.DataFrame(results, columns=[\"Model\",\"Training Accuracy\",\"Mean Validation Accuracy\", \"Test Accuracy\"])\nfinal_df","97a626f8":"**Insight**: We don't have any null\/missing values, however, we do have 1256 duplicate values--825 of which belong to the healthy class, and 431 of which belong to the diabetic class.","c9876898":"### Addressing Class Imbalance\nAs we saw earlier, our data is severely imbalanced; we have a greater number of healthy individuals in our data set than diabetic individuals. If this is still the case in our training set, we will perform [random undersampling](https:\/\/machinelearningmastery.com\/random-oversampling-and-undersampling-for-imbalanced-classification\/#:~:text=Random%20undersampling%20involves%20randomly%20selecting,more%20balanced%20distribution%20is%20reached.) to balance our training set. One way we can achieve this is by removing all duplicate entries that were classified as healthy individuals from our training set.","f9e7c1ce":"**Insight**: Our data set consists of 1316 healthy individuals and only 684 diabetic individuals; evidently, our data set is imbalanced. We will need to deal with this later.","295bba28":"To make things even more concrete, we can compute the number of outliers present in each of the columns of our data set:","f0d096e3":"## Exploratory Data Analysis","22fea224":"### Outlier Detection\nLet's confirm our assumption that outliers exist in the data set by taking a quick glance at the distribution of the data using panda's `describe` method:","da0a19b8":"### Surface-level information and Shape","c5f8143c":"# Diabetes Prediction","b91c5756":"## Preparing the Data\nNow that we a have a solid understanding of our data, we can begin to clean and prepare it for our models. Because all of our data is already numeric and no two features have a high correlation, there is not much left for us to do, other than address our class imbalance and standardize our data. ","6a0dbfee":"**Insight**: Looks like our data set contains a large number of outliers; we will need to deal with this later.","740f28fe":"**Insight**: The features neither have a strong correlation with one another nor the target variable. Thus, we should be able to incorporate all of them when building our final model. Let's take a closer look at their correlations and distributions.","23d4a230":"### Feature Analysis\nNow that we have a decent understanding of the structure of our data, let's dive deeper by exploring the features themselves and how they might impact our target variable. To start, we can take a look at the correlation of the features:","51765dd2":"Now that we've performed random sampling, we can standardize our data. Because we have a large number of outliers, we will be using sklearn's [RobustScaler](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.RobustScaler.html).","a0d3cf4c":"### Splitting our Data\nWe begin by splitting our data into train and test sets; we must do this *before* any preprocessing so as to avoid any type of [data leakage](https:\/\/machinelearningmastery.com\/data-leakage-machine-learning\/).","bfdd4816":"Thanks for following along!","3534194e":"## Model Predictions\nNow all that we have left to do is generate some models and make predictions!","6ae21877":"### Checking for Null and Duplicate Entries","1fadd80f":"**Insight**: We have 2000 rows\/samples and 9 columns. 8 of the 9 columns are our *feature* columns, while the last column (Outcome) represents our *target* column. Moreover, all of our columns appear to consist of numeric data. Let's look at how much of each class we have:","389188df":"**Insight**: From the scatter plots, we can see that outliers are prevalent within the data set. Moreover, from the KDE distributions on the diagonal, there is a great deal of overlap between healthy and diabetic patients. In other words, there is no subset of features that easily discern healthy individuals from diabetic individuals.","d41d6f89":"Evidently, our training set is still heavily imbalanced. Hence, random undersampling needs to be done. One way we can achieve this is by removing all the duplicate entries that were classified as healthy individuals from our training set.","1c55ec63":"To get a sense for just how many outliers we are dealing with, we can use a box and whisker plot over each of the features:","01126f41":"**Insight**: In the Glucose, BloodPressure, and BMI columns, there is a large gap from the minimum value to the 25th percentile. Moreover, in many of these columns, the minimum value is zero, which makes little sense in the context of the task (for example, a BloodPressure value of zero indicates that the patient's heart is no longer beating!). In a similar matter, In the Pregnancies, BloodPressure, SkinThickness, Insulin, BMI, and Age columns, there is a large gap from between the 75th percentile to the maximum value, indicating the presence of outliers."}}