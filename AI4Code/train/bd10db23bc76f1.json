{"cell_type":{"13063112":"code","e9524a1c":"code","1447f1fe":"code","a2e89ca6":"code","447a3c39":"code","00d3e95f":"code","a5948764":"code","55688ea7":"code","1adf7242":"code","ee9c0f4d":"code","d1090331":"code","91328dbd":"code","a2ee073c":"code","734a8aa7":"code","c9367de7":"code","268209cf":"code","c0b13342":"code","9233c32c":"code","8a9a7f43":"code","99b42e2d":"code","177e8e62":"code","457d1ced":"code","69d3826b":"code","07dde7ea":"code","d0c753fc":"code","39e9b979":"code","ee8f5938":"code","27e6883a":"code","42798571":"code","d9284899":"code","950fea68":"code","7827b8ae":"code","41b080b8":"code","51e2f1be":"code","642dea48":"code","b1649555":"code","dfb093c4":"code","09ddd228":"code","907e9804":"code","37aba335":"code","85ba37af":"code","4434aaa8":"code","282a8a4f":"code","6923fabe":"code","8005d9eb":"code","271f7be5":"markdown","0a93ba62":"markdown","33ceaaf4":"markdown","afd9b6aa":"markdown","07faffe5":"markdown","f4da6e11":"markdown","c2f4f6e1":"markdown","0894ff0c":"markdown","3f3920e6":"markdown","ab9816c2":"markdown","f71ada52":"markdown","dc907261":"markdown","1706e6b3":"markdown","c5416a27":"markdown","d80c69f6":"markdown","554a667b":"markdown","a711a9f6":"markdown","2b0b0072":"markdown","328ba032":"markdown","1e90a155":"markdown","ff8f4fac":"markdown","5940b91c":"markdown","fc3861a9":"markdown","ea4411eb":"markdown","02c2a675":"markdown","e80ed357":"markdown","1f10c01f":"markdown","ef91214c":"markdown","fdaeeac8":"markdown","2a4f91f7":"markdown","a58101bb":"markdown","ad41abe4":"markdown","6093be6d":"markdown","427ba5d5":"markdown"},"source":{"13063112":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# import useful libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import linear_model\nimport statsmodels.api as sm\nimport scipy as sp\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.externals import joblib\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e9524a1c":"df1 = pd.read_csv(\"..\/input\/Admission_Predict.csv\")\ndf2 = pd.read_csv(\"..\/input\/Admission_Predict_Ver1.1.csv\")  ","1447f1fe":"print(df1.shape)\nprint(df2.shape)","a2e89ca6":"# find how many rows which instances are in df1 but not\n# in df2. Note: longer dataset.isin(shorter dataset)\nlen(df2[~df2.isin(df1)].dropna())","447a3c39":"df_train = df1\ndf_test = df2.iloc[400:]\ndf_test.shape","00d3e95f":"# check columns in train data\ndf_train.columns","a5948764":"# change some column names to the simple style\ndf_train = df_train.rename(columns={'Serial No.':'SerialNo','GRE Score':'GREScore',\n                         'TOEFL Score':'TOEFLScore','LOR ':'LOR',\n                         'University Rating':'UniversityRating',\n                         'Chance of Admit ':'ChanceOfAdmit'})","55688ea7":"# check train dataset info\ndf_train.info()","1adf7242":"# get statistics of train dataset\ndf_train.describe()","ee9c0f4d":"df_train['GREScore'].hist()","d1090331":"df_train['TOEFLScore'].hist()","91328dbd":"df_train['UniversityRating'].hist()","a2ee073c":"df_train['SOP'].hist()","734a8aa7":"df_train['LOR'].hist()","c9367de7":"df_train['Research'].hist()","268209cf":"df_train['CGPA'].hist()","c0b13342":"# Firstly check relationship between TOEFLScore(GREScore has high correlation with\n# TOEFLScore, so just check TOEFLScore), Research, SOP(\n# LOR has high correlation with SOP) and UniversityRating seperately.\nbins = [0, 92, 102, 112, 122]\ndf_train['TOEFL_binned'] = pd.cut(df_train['TOEFLScore'], bins)\nsns.countplot(x='TOEFL_binned', hue='UniversityRating', data=df_train)\nplt.show()","9233c32c":"sns.countplot(x='SOP', hue='UniversityRating', \n              data=df_train)\nplt.show()","8a9a7f43":"sns.countplot(x='Research', hue='UniversityRating', data=df_train)\nplt.show()","99b42e2d":"# Here to check the relationship between SOP, UniversityRating, \n# Research and ChanceofAdmit seperately.\nbins = [0.2, 0.4, 0.6, 0.8, 1.0]\ndf_train['ChanceOfAdmit_binned'] = pd.cut(df_train['ChanceOfAdmit'], bins)","177e8e62":"sns.countplot(x='SOP', hue='ChanceOfAdmit_binned', data=df_train)\nplt.show()","457d1ced":"sns.countplot(x='UniversityRating', hue='ChanceOfAdmit_binned', data=df_train)\nplt.show()","69d3826b":"sns.countplot(x='Research', hue='ChanceOfAdmit_binned', data=df_train)\nplt.show()","07dde7ea":"# split cols into two parts num_cols and rest_cols\nnum_cols = ['GREScore', 'TOEFLScore', 'CGPA']\nrest_cols = ['UniversityRating', 'SOP','LOR','Research']\nnum_cols_target = num_cols + ['ChanceOfAdmit']\nrest_cols_target = rest_cols + ['ChanceOfAdmit']","d0c753fc":"sns.pairplot(df_train[num_cols_target])","39e9b979":"sns.pairplot(df_train[rest_cols_target])","ee8f5938":"fig,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(df_train[num_cols+rest_cols+['ChanceOfAdmit']].corr(),\n            ax=ax, annot=True, linewidths=0.05, fmt= '.2f',cmap=\"magma\")\nplt.show()","27e6883a":"# Before build a linear model, we need to scale the data\ndef scaling(df, train=True):\n    '''use StandardScaler to scale raw data'''\n    cols = df.columns\n    scaler = StandardScaler()\n    if train:\n        scaler.fit(df)\n        joblib.dump(scaler, \"scaler.save\")          \n    else:\n        scaler = joblib.load(\"scaler.save\")\n    scaled_df = scaler.transform(df)\n    df_X = pd.DataFrame(scaled_df, columns=cols)\n    \n    return df_X","42798571":"# sklearn modeling\ndef model_sklearn(x, y):\n    '''Use sklearn to build model'''\n    reg = linear_model.LinearRegression()\n    reg.fit(x, y)\n    joblib.dump(reg, 'model.h5')\n    print('Intercept: \\n', reg.intercept_)\n    print('Coefficients: \\n', reg.coef_)","d9284899":"# statsmodels modeling\ndef model_stats(x, y):\n    x = sm.add_constant(x) # adding a constant\n\n    model = sm.OLS(y, x).fit()\n    predictions = model.predict(x) \n\n    print_model = model.summary()\n    print(print_model)\n    \n    return predictions","950fea68":"# Use sklearn to build the model  \nX = scaling(df_train[num_cols]) \nY = df_train['ChanceOfAdmit']\nmodel_sklearn(X, Y)\n","7827b8ae":"# Use statsmodels to build the model\ny_pred = model_stats(X, Y)\n","41b080b8":"def dia_res(y_true, y_pred):\n    residual = y_true - y_pred\n    fig, ax = plt.subplots(figsize=(6,2.5))\n    _, (__, ___, r) = sp.stats.probplot(residual, plot=ax, fit=True)","51e2f1be":"dia_res(df_train['ChanceOfAdmit'], y_pred)","642dea48":"# Do the same preprocess for test data\ndf_test = df_test.rename(columns={'Serial No.':'SerialNo','GRE Score':'GREScore',\n                         'TOEFL Score':'TOEFLScore','LOR ':'LOR',\n                         'University Rating':'UniversityRating',\n                         'Chance of Admit ':'ChanceOfAdmit'})\ndf_test_y = df_test['ChanceOfAdmit']","b1649555":"# calculate MSE\ndef evaluate_model(x, y_true):\n    model = joblib.load('model.h5')\n    pred = model.predict(x)\n    mse = mean_squared_error(df_test_y, pred)\n    \n    return mse","dfb093c4":"test_X = scaling(df_test[num_cols], train=False)\nmse = evaluate_model(test_X, df_test_y)\nprint(mse)","09ddd228":"# Use sklearn to build the model  \nX = scaling(df_train[rest_cols]) \nY = df_train['ChanceOfAdmit']\nmodel_sklearn(X, Y)","907e9804":"# Use statsmodels to build the model\ny_pred = model_stats(X, Y)","37aba335":"dia_res(df_train['ChanceOfAdmit'], y_pred)","85ba37af":"test_X = scaling(df_test[rest_cols], train=False)\nmse = evaluate_model(test_X, df_test_y)\nprint(mse)","4434aaa8":"# Use sklearn to build the model  \nX = scaling(df_train[num_cols + rest_cols]) \nY = df_train['ChanceOfAdmit']\nmodel_sklearn(X, Y)","282a8a4f":"# Use statsmodels to build the model\ny_pred = model_stats(X, Y)","6923fabe":"dia_res(df_train['ChanceOfAdmit'], y_pred)","8005d9eb":"test_X = scaling(df_test[num_cols + rest_cols], train=False)\nmse = evaluate_model(test_X, df_test_y)\nprint(mse)","271f7be5":"# Columns explanation \n1. GRE Scores ( out of 340 ) \n2. TOEFL Scores ( out of 120 ) \n3. University Rating ( out of 5 ) \n4. Statement of Purpose and Letter of Recommendation Strength ( out of 5 ) \n5. Undergraduate GPA ( out of 10 ) \n6. Research Experience ( either 0 or 1 ) \n7. Chance of Admit ( ranging from 0 to 1 )","0a93ba62":"## Build multiple linear regression model","33ceaaf4":"Each pair in the above plot has positive correlation.","afd9b6aa":"## Make sure train and test datasets.","07faffe5":"From the histogram, GREScore, TOEFLScore, and CGPA are close to the normal distribution. UniversityRating is the discrete varibale. SOP and LOR are kind of normal distribution except no value is in (2.5, 3.0). Research is a boolean varibale.","f4da6e11":"### Evaluate model using test data","c2f4f6e1":"The relationship is not so obvious.But we could know SOP and LOR have positive correlation. SOP and ChanceOfAdmit have positive correlation.LOR and ChanceOfAdmit have positive correlation.","0894ff0c":"### Evaluate model using test data","3f3920e6":"The higher SOP, the higher proportion of appling the good universities.","ab9816c2":"### Draw Q-Q plot of residual to check the normality.","f71ada52":"# Conclusion\nThe linear model with num_cols + rest_cols as independent variables has the smallest MSE. So it is the best multiple model for this regression problem.","dc907261":"### Draw Q-Q plot of residual to check the normality.","1706e6b3":"# Contents\n1. make sure train data and test data\n2. EDA\n3. use sklearn and statsmodel build linear regression models based on different independent variables\n4. check the residual\n5. evaluate the model","c5416a27":"The higher SOP, the higher chance of adimission.","d80c69f6":"From the info() function, we know no NAN value is in dataset. In my opinion, University Rating, SOP, and LOR should be ordinal categorical variables. Research should be boolean variable. \nIn the dataset, it is already converted the form that we want.","554a667b":"### Plot histograms for each column","a711a9f6":"### Draw Q-Q plot of residual to check the normality.","2b0b0072":"Explain of above results. \nThe coefficients are same as Sklearn. So these two package will give us the same results. That's we expect.\nFor GREScore, TOEFLScore and CGPA, p-values of t-test are very small so we have evidence to reject the null hypothesis(b1=0, b2=0, b3=0). It means these 3 independent variables are significant.","328ba032":"So there are 100 rows which are in df2 not in df1. We will use these 100 rows as the test data.","1e90a155":"### Just modeling based on rest_cols","ff8f4fac":"## EDA","5940b91c":"We could know GREScore, TOEFLScore, and CGPA have high correlation with chance of admit seperately. But the high correlation among some of the predictors suggests that data-based multicollinearity exists.\n\nA good news! If the primary purpose of your regression analysis is to estimate a mean response \u03bcY or to predict a new response y, you don't have to worry much about multicollinearity. In order words, high multicollinearity among predictor variables does not prevent good, precise predictions of the response within the scope of the model.","fc3861a9":"Still, having research experience will increase the chance of admission.","ea4411eb":"Not bad!","02c2a675":"The higher university rating, the higher chance of admission. I guess the reason is students who applied the high rating university are excellent. The universities want these kind of students. Thus, the chance is higher.","e80ed357":"### Plot pairplot","1f10c01f":"### Just modeling based on num_cols","ef91214c":"The tail and head are not like normal distribution. But the middle part is good enough.","fdaeeac8":"### two variables histograms","2a4f91f7":"### Plot heatmap","a58101bb":"If students have the research experience, we will apply good universities.Because they are more competitive.","ad41abe4":"### Evaluate model using test data","6093be6d":"We could say the higher TOEFLScore, the higher proportion of appling to the good universities. This consist to our common.","427ba5d5":"### Modeling based on num_cols + rest_cols"}}