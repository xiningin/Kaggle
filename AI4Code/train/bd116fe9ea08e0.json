{"cell_type":{"33a130d1":"code","cdb5388f":"code","19c09a21":"code","3328a94c":"code","876c8205":"code","3d03a897":"code","11c6feec":"code","3cc9a783":"code","2c525472":"code","1d1da723":"code","d30fc7f2":"code","5dba18db":"markdown","dbba77c5":"markdown","d3c4db0b":"markdown","95d44f46":"markdown","005044e1":"markdown","f52f6bca":"markdown"},"source":{"33a130d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport cv2\nimport glob\nimport torch\nimport shutil\nimport itertools\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom torch import nn\nfrom torch import optim\nfrom torchvision import transforms, datasets, models\nfrom keras.models import Sequential\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Flatten, Dense, Conv2D, BatchNormalization, MaxPooling2D, Dropout\nfrom tensorflow.keras.applications import EfficientNetB1, VGG19, ResNet50, InceptionV3, MobileNet, DenseNet201\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cdb5388f":"i = 0\nfig, axes = plt.subplots(3, 3, figsize=(10, 10))\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/face-mask-detection'):\n    for filename in filenames[:9]:\n        img = cv2.imread(os.path.join(dirname, filename))\n        if img is not None:\n            img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n            ax = list(axes.flatten())[i]\n            ax.imshow(img)\n            ax.set_title('Image ' + str(i+1))\n            ax.axis('off')\n            i += 1\nplt.show()","19c09a21":"images = []\naugmented = []\npath = '..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset'\n\nfor set_ in os.listdir(path):\n    i, j = 4, 4\n    \n    for img in os.listdir(path+'\/'+set_+'\/WithMask'):\n        if img[0] != 'A':\n            if i > 0:\n                images.append(path+'\/'+set_+'\/WithMask\/'+img)\n                i -= 1\n        else:\n            if j > 0:\n                augmented.append(path+'\/'+set_+'\/WithMask\/'+img)\n                j -= 1","3328a94c":"fig, axes = plt.subplots(3, 4, figsize=(15, 15))\nfig.tight_layout()\nfig.subplots_adjust(hspace=-0.5)\n\nfor ax in axes.flatten():\n    ax = axes.flatten()[list(axes.flatten()).index(ax)]\n    img = cv2.imread(images[list(axes.flatten()).index(ax)])\n    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    ax.imshow(img)\n    ax.axis('off')\n\nplt.suptitle('Original Images', size=30)\nplt.show()","876c8205":"fig, axes = plt.subplots(3, 4, figsize=(15, 15))\nfig.tight_layout()\nfig.subplots_adjust(hspace=-0.5)\n\nfor ax in axes.flatten():\n    ax = axes.flatten()[list(axes.flatten()).index(ax)]\n    img = cv2.imread(augmented[list(axes.flatten()).index(ax)])\n    img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n    ax.imshow(img)\n    ax.axis('off')\n\nplt.suptitle('Augmented Images', size=30)\nplt.show()","3d03a897":"path, batch_size = '..\/input\/withwithout-mask\/maskdata\/maskdata', 16\n\ntrain_datagen = ImageDataGenerator(rescale=1.0\/255, horizontal_flip=True, zoom_range=0.2,\n                                  shear_range=0.2)\ntest_datagen = ImageDataGenerator(rescale=1.0\/255)\n\ntrain_generator = train_datagen.flow_from_directory(path+'\/train', target_size=(128, 128), \n                                               batch_size=batch_size, class_mode='categorical')\ntest_generator = test_datagen.flow_from_directory(path+'\/test', target_size=(128, 128), \n                                             batch_size=batch_size, class_mode='categorical')","11c6feec":"path = '..\/input\/withwithout-mask\/maskdata\/maskdata'\nfig, axes = plt.subplots(1, 2, figsize=(15, 9))\n\nfor set_ in os.listdir(path):\n    counts = []\n    ax = axes[os.listdir(path).index(set_)]\n    for class_ in os.listdir(path+'\/'+set_):\n        count=len(os.listdir(path+'\/'+set_+'\/'+class_))\n        counts.append(count)\n    ax.bar(['With Mask', 'Without Mask'], counts, color='skyblue')\n    ax.set_title(set_)\n    ax.set_xlabel('Classes')\n    ax.set_ylabel('Number of samples')\n\nplt.suptitle('Distribution of classes', size=25)\nplt.show()","3cc9a783":"histories = []\nfor i in range(3):\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    \n    if i > 0: \n        model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)))\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.2))\n    \n        if i > 1: \n            model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)))\n            model.add(BatchNormalization())\n            model.add(MaxPooling2D(pool_size=(2, 2)))\n            model.add(Dropout(0.2))\n    \n    model.add(Flatten())\n    model.add(Dense(2, activation='sigmoid'))\n    model.summary()\n\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n    histories.append(model.fit_generator(generator=train_generator, \n                                         validation_data=test_generator, \n                                         steps_per_epoch=len(train_generator)\/\/3, \n                                         validation_steps=len(test_generator)\/\/3, \n                                         epochs=10))","2c525472":"fig, axes = plt.subplots(2, 2, figsize=(15, 10))\nfor metric in histories[0].history:\n    index = list(histories[0].history).index(metric)\n    ax = axes.flatten()[index]\n    layer_num = 0\n    for history in histories:\n        layer_num += 1\n        ax.plot(history.history[metric], label=str(layer_num)+' layer(s)')\n    ax.set_title(metric)\n    ax.legend()\nplt.show()","1d1da723":"model_histories = []\nmodels = [InceptionV3(include_top=False, input_shape=(128, 128, 3)), \n                   MobileNet(include_top=False, input_shape=(128, 128, 3)), \n                   DenseNet201(include_top=False, input_shape=(128, 128, 3)),\n                   VGG19(include_top=False, input_shape=(128, 128, 3))]\nnames = ['ConvNet', 'InceptionV3', 'MobileNet', 'DenseNet', 'VGG19']\n\nfor layer in [Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3))]:\n    model = Sequential()\n    model.add(layer)\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Flatten())\n    model.add(Dense(2, activation='sigmoid'))\n    model.summary()\n\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n    model_histories.append(model.fit_generator(generator=train_generator, \n                                         validation_data=test_generator, \n                                         steps_per_epoch=len(train_generator)\/\/3, \n                                         validation_steps=len(test_generator)\/\/3, \n                                         epochs=10))\n\nfor functional in models:\n    \n    for layer in functional.layers:\n        layer.trainable = False\n\n    model = Sequential()\n    model.add(functional)\n    model.add(Flatten())\n    model.add(Dense(2, activation='sigmoid'))\n    model.summary()\n\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')\n    model_histories.append(model.fit_generator(generator=train_generator, \n                                         validation_data=test_generator, \n                        steps_per_epoch=len(train_generator)\/\/3, \n                        validation_steps=len(test_generator)\/\/3, epochs=10))","d30fc7f2":"fig, axes = plt.subplots(2, 2, figsize=(15, 10))\nfig.subplots_adjust(hspace=0.3)\nfor metric in model_histories[0].history:\n    index = list(model_histories[0].history).index(metric)\n    ax = axes.flatten()[index]\n    name_index = 0\n    for history in model_histories:\n        ax.plot(history.history[metric], label=names[name_index])\n        name_index += 1\n    ax.set_title(metric+' over epochs', size=15)\n    ax.set_xlabel('epochs')\n    ax.set_ylabel(metric)\n    ax.legend()\nplt.show()","5dba18db":"# Testing layers with ConvNet","dbba77c5":"# Distribution of classes","d3c4db0b":"## Thank you for reading my notebook.\n## If you enjoyed this notebook and found it helpful, please give it an upvote and provide feedback as it would help me make more of these.","95d44f46":"# Displaying sample images","005044e1":"# Face Mask Image Detection","f52f6bca":"# Comparing model performance"}}