{"cell_type":{"37278a8c":"code","e91e24b1":"code","d314b26c":"code","ded3bdab":"code","844cc9af":"code","89a9d9db":"code","0ebbbfd5":"code","82900005":"code","0a054835":"code","9cd3a651":"code","6cbc3160":"code","f478f9d3":"code","9073c701":"code","96b5d240":"code","35da06dd":"code","0584015f":"code","b5aa57e7":"code","7442f5f3":"code","a4e46b28":"markdown","911cbf9d":"markdown","270bca0a":"markdown","25fe4261":"markdown","bc3ccca7":"markdown","55e2b081":"markdown","51c4c9d8":"markdown"},"source":{"37278a8c":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\nimport os\nimport random\n\nimport cv2\n\nimport tensorflow as tf\n","e91e24b1":"print(os.listdir(\"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/\"))\nprint(os.listdir(\"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\/\"))\nprint(os.listdir(\"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/\"))","d314b26c":"# Number of images in the dataset\n\nprint('Images in the training dataset:\\n')\nprint(\"Mask Images count - \", len(os.listdir(\"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask\")))\nprint(\"Non Mask Images count - \", len(os.listdir(\"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithoutMask\")))","ded3bdab":"train_dir = \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/\"\nval_dir = \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\/\"\ntest_dir = \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/\"","844cc9af":"directory=os.listdir('\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train')\nfor each in directory:\n    plt.figure()\n    currentFolder = '\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/'+ each\n    print(currentFolder)\n    for i, file in enumerate(os.listdir(currentFolder)[0:5]):\n        fullpath = currentFolder + \"\/\" + file\n        print(fullpath)\n        img=mpimg.imread(fullpath)\n        plt.subplot(2,3 , i+1)\n        plt.imshow(img)","89a9d9db":"HEIGHT = 150\nWEIGHT = 150\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                         zoom_range=0.2,\n                                         shear_range=0.2,\n                                         rotation_range=0.2)\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255,\n                                         zoom_range=0.2,\n                                         shear_range=0.2,\n                                        rotation_range=0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain = train_datagen.flow_from_directory(directory=train_dir,\n                                          target_size=(HEIGHT,WEIGHT),\n                                          class_mode=\"categorical\",\n                                          batch_size=64\n                                          )\n\nval = validation_datagen.flow_from_directory(directory=val_dir,\n                                            target_size=(HEIGHT,WEIGHT),\n                                            class_mode=\"categorical\",\n                                            batch_size=64)\n\ntest = test_datagen.flow_from_directory(directory=test_dir,\n                                            target_size=(HEIGHT,WEIGHT),\n                                            class_mode=\"categorical\",\n                                            batch_size=64)","0ebbbfd5":"from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n\nmobilenet = MobileNetV2(weights = \"imagenet\",include_top = False,input_shape=(150,150,3))\n\nfor layer in mobilenet.layers:\n    layer.trainable = False","82900005":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten,Dense,GlobalAveragePooling2D,Dropout\n\nmodel = Sequential()\nmodel.add(mobilenet)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(300, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(100,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2,activation=\"softmax\"))\n\nprint(model.summary())","0a054835":"# compile\n\nmodel.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics =\"accuracy\")\n","9cd3a651":"history = model.fit(train,\n                              validation_data=val,\n                              steps_per_epoch=len(train)\/\/64,\n                              epochs=30,\n                              validation_steps=len(val)\/\/64,\n                              verbose=2)","6cbc3160":"loss, accuracy = model.evaluate(test)\n","f478f9d3":"sample_mask_img = cv2.imread('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithMask\/1565.png')\nsample_mask_img = cv2.resize(sample_mask_img,(128,128))\nplt.imshow(sample_mask_img)\nsample_mask_img = np.reshape(sample_mask_img,[1,128,128,3])\nsample_mask_img = sample_mask_img\/255.0","9073c701":"model.save(\"face_mask.h5\")\n","96b5d240":"#loading haarcascade_frontalface_default.xml\nface_model = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')","35da06dd":"img = cv2.imread('..\/input\/face-mask-detection\/images\/maksssksksss244.png')\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\nfaces = face_model.detectMultiScale(img,scaleFactor=1.03, minNeighbors=6) #returns a list of (x,y,w,h) tuples\n\nout_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n\n#plotting\nfor (x,y,w,h) in faces:\n    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),1)\nplt.figure(figsize=(12,12))\nplt.imshow(out_img)","0584015f":"from scipy.spatial import distance\n\nMIN_DISTANCE = 130\n\nlabel = [0 for i in range(len(faces))]\nfor i in range(len(faces)-1):\n    for j in range(i+1, len(faces)):\n        dist = distance.euclidean(faces[i][:2],faces[j][:2])\n        if dist<MIN_DISTANCE:\n            label[i] = 1\n            label[j] = 1\nnew_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\nfor i in range(len(faces)):\n    (x,y,w,h) = faces[i]\n    if label[i]==1:\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),(255,0,0),1)\n    else:\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,255,0),1)\nplt.figure(figsize=(10,10))\nplt.imshow(new_img)\n","b5aa57e7":"mask_label = {0:'MASK',1:'NO MASK'}\ndist_label = {0:(0,255,0),1:(255,0,0)}","7442f5f3":"\nlabel = [0 for i in range(len(faces))]\nfor i in range(len(faces)-1):\n    for j in range(i+1, len(faces)):\n        dist = distance.euclidean(faces[i][:2],faces[j][:2])\n        if dist<MIN_DISTANCE:\n            label[i] = 1\n            label[j] = 1\nnew_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\nfor i in range(len(faces)):\n    (x,y,w,h) = faces[i]\n    crop = new_img[y:y+h,x:x+w]\n    crop = cv2.resize(crop,(150,150))\n    crop = np.reshape(crop,[1,150,150,3])\/255.0\n    mask_result = model.predict(crop)\n    #mask_result = np.argmax(mask_result_x, axis=1)\n    cv2.putText(new_img,mask_label[mask_result.argmax()],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n    cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\nplt.figure(figsize=(10,10))\nplt.imshow(new_img)\n\n\n    ","a4e46b28":"### Social distance violation","911cbf9d":"### Incorporating mask detection model with Haarcascades classifier","270bca0a":"### Haarcascades model to detect faces\n\nObject Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images. We'll be using a Haar Cascade Model trained to detect faces in order to obtain the bounding box coordinates of faces in an image.","25fe4261":"### Introduction\n\nThis dataset is used for Face Mask Detection Classification with images. The dataset consists of almost 12K images which are almost 328.92MB in size.\n\nThe dataset consists of 3 folders - train, validation and testing dataset.\nEach folder has 2 subfolders containing images of mask and no mask.\n","bc3ccca7":"### Model","55e2b081":"### Visualization","51c4c9d8":"### Preprocessing - Image data Generator"}}