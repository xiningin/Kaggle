{"cell_type":{"36822f20":"code","d053202b":"code","e685a847":"code","10bc5bc2":"code","5329cc41":"code","4ea6c46a":"code","266e1d54":"code","9405b4c2":"code","ce10ff76":"code","b83a6a0f":"code","a6381c06":"code","95e2157d":"code","c4e3202f":"code","4e81bec1":"code","85a90f63":"code","3266fd9c":"code","c0b772e3":"code","6ec81267":"code","437a20d5":"code","21fd9b8c":"code","ce8dfb44":"code","54bf67c0":"code","81aef57c":"code","88ed86c6":"code","6393b456":"code","4838116e":"code","63409c6d":"code","2c4e54d7":"code","018043c7":"markdown"},"source":{"36822f20":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(len(os.listdir(\"..\/input\/train\")))\n\n# Any results you write to the current directory are saved as output.","d053202b":"os.mkdir(\"modifiedtrain\")\nos.mkdir(\"modifiedtrain\/cat\")\nos.mkdir(\"modifiedtrain\/dog\")","e685a847":"os.listdir(\"modifiedtrain\")","10bc5bc2":"from shutil import copyfile\nfor file in os.listdir(\"..\/input\/train\"):\n    name=file.split('.')[0]\n    filename=\"..\/input\/train\/\"+file\n    if name=='cat':\n        copyfile(filename,\"modifiedtrain\/cat\/\"+file)\n    elif name=='dog':\n        copyfile(filename,\"modifiedtrain\/dog\/\"+file)\n    \n    ","5329cc41":"os.listdir(\"modifiedtrain\/dog\/\")","4ea6c46a":"%pylab inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimage = Image.open('modifiedtrain\/dog\/dog.411.jpg')\nplt.imshow(image)\nplt.show()","266e1d54":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","9405b4c2":"train_datagen=ImageDataGenerator(rescale=1.\/255)\n","ce10ff76":"train_generator=train_datagen.flow_from_directory(\"modifiedtrain\/\",batch_size=20,target_size=(150,150),\n                                                  class_mode='binary')","b83a6a0f":"model=tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,150,3)),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])","a6381c06":"model.summary()","95e2157d":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=0.001),metrics=['accuracy'])","c4e3202f":"history=model.fit_generator(train_generator,steps_per_epoch=100,epochs=15)","4e81bec1":"!pip install wget","85a90f63":"import wget\nurl='https:\/\/ichef.bbci.co.uk\/images\/ic\/720x405\/p0517py6.jpg'\nwget.download(url, 'test_image.jpg')","3266fd9c":"import matplotlib.pyplot as plt","c0b772e3":"def load_image(img_path, show=False):\n\n    img = image.load_img(img_path, target_size=(150, 150))\n    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n    img_tensor \/= 255.                                      # imshow expects values in the range [0, 1]\n\n    if show:\n        plt.imshow(img_tensor[0])                           \n        plt.axis('off')\n        plt.show()\n\n    return img_tensor","6ec81267":"from tensorflow.keras.preprocessing import image\nimg = load_image('test_image.jpg',True)\nmodel.predict(img)","437a20d5":"train_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')","21fd9b8c":"train_generator=train_datagen.flow_from_directory(\"modifiedtrain\/\",batch_size=20,target_size=(150,150),\n                                                  class_mode='binary')","ce8dfb44":"history=model.fit_generator(train_generator,steps_per_epoch=100,epochs=5)","54bf67c0":"import os\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O \/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\nlocal_weights_file = '\/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(input_shape = (256, 256, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n  \n# pre_trained_model.summary()\n\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","81aef57c":"from tensorflow.keras.optimizers import RMSprop\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc'])","88ed86c6":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')","6393b456":"train_generator=train_datagen.flow_from_directory(\"modifiedtrain\/\",batch_size=20,target_size=(256,256),\n                                                  class_mode='binary')","4838116e":"history=model.fit_generator(train_generator,steps_per_epoch=100,epochs=5)","63409c6d":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nloss = history.history['loss']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.legend(loc=0)\nplt.figure()","2c4e54d7":"plt.plot(epochs, loss, 'b', label='Training loss')\nplt.legend(loc=0)\nplt.figure()","018043c7":"import libs"}}