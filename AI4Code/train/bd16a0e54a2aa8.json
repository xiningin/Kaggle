{"cell_type":{"c5493c79":"code","3eaf910c":"code","d38a4de0":"code","6aa93cd4":"code","c64776a8":"code","d055fd60":"code","dfd4c008":"code","f93759d3":"code","47899a50":"code","de322261":"code","f6767fc9":"code","09a31da1":"code","bb2b3c96":"code","72bee25d":"code","12b6a9b7":"code","1d9f6677":"code","ae593c52":"code","036bf500":"code","04670732":"code","54a41b3c":"code","c2587807":"code","8336de71":"code","86774f36":"code","fcb450dc":"code","3df711d5":"code","8c5cb1f7":"code","095185aa":"code","7841272c":"code","20fbf2e3":"code","8fdc65fa":"code","7364c1f7":"code","322e3ce9":"code","0112788a":"code","e48af35a":"code","bb70663b":"code","559f63e0":"code","cf5cdd0c":"code","1e1a1973":"code","6cf3a24d":"code","3db14008":"code","da5d1553":"code","2a358ff5":"code","86041efa":"code","969b57c7":"code","5658b09c":"code","b251fcf3":"code","8654b1d4":"code","4da8c557":"code","2d226d48":"code","6bde775e":"code","73443354":"code","b8eb04e3":"code","f7f780c2":"code","432902b3":"code","68023ab2":"code","df30fec0":"code","2e690882":"code","8a0851be":"code","83f1287a":"code","31de107b":"code","38fd3014":"code","b8cff739":"markdown","fb0535ab":"markdown","3224a330":"markdown","915dba03":"markdown","4cf88da0":"markdown","922c341a":"markdown","6bb302c9":"markdown","d398d5d8":"markdown","301fce95":"markdown","0e947f68":"markdown","bd6807c2":"markdown","2d77f28c":"markdown","1ade7eb3":"markdown","0e5045ef":"markdown","dd256a2b":"markdown","cd997a4b":"markdown","8aeea8fe":"markdown","1973150c":"markdown","d7aab460":"markdown","404e544c":"markdown","39385732":"markdown","d76a65ec":"markdown","8dd9ebd5":"markdown","d3c831d3":"markdown","e0036df1":"markdown","0061e5b5":"markdown","c49f7fe6":"markdown","d5b59d8e":"markdown","c330a48f":"markdown","11fd429d":"markdown","13e5b32f":"markdown","cc6a38c0":"markdown","60159169":"markdown","0978ef25":"markdown","f2758846":"markdown","c2733d09":"markdown","49e35a49":"markdown","fc3b2fd2":"markdown","c900e90a":"markdown","3b76ec4d":"markdown"},"source":{"c5493c79":"import os\nimport re\nimport json\nimport numpy as np \nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches","3eaf910c":"single_song_path = '..\/input\/singlesong\/single_song.json'\nwith open(single_song_path, 'rb') as f:\n    song_json = json.load(f)\n# print(song_json)","d38a4de0":"# print(json.dumps(song_json, indent=4, sort_keys=True))","6aa93cd4":"dictionary = {'dog': 'woof',\n              'cat': 'meow',\n              'lazer': 'zapppp',\n              'list_of_things': ['a', 3, dict()],\n              'numbers': 10012}\ndictionary","c64776a8":"dictionary.keys()","d055fd60":"dictionary['dog']","dfd4c008":"dictionary['list_of_things']","f93759d3":"list_of_things = dictionary['list_of_things']\nlist_of_things[0]","47899a50":"dictionary['list_of_things'][0]","de322261":"song_json.keys()","f6767fc9":"song_json['meta']","09a31da1":"# song_json['segments']","bb2b3c96":"# Access the first element (dictionary) in the list\nfirst_segment = song_json['segments'][0]\nfirst_segment","72bee25d":"#\u00a0Then access the timbre values\nfirst_segment['timbre']","12b6a9b7":"song_timbres = []\nfor segment in song_json['segments']:\n    song_timbres.append(segment['timbre'])","1d9f6677":"training_data_path = '..\/input\/musicdata\/'\nos.listdir(training_data_path)","ae593c52":"with open(os.path.join(training_data_path,'hiphop.json'), 'rb') as f:\n    hiphop = json.load(f)","036bf500":"# Each key is a unique identifer for a song known as a URI\nhiphop.keys()","04670732":"hiphop['spotify:track:3MnwLa9KRUiv2gNFtWPvib'].keys()","54a41b3c":"hiphop['spotify:track:3MnwLa9KRUiv2gNFtWPvib']['artist']","c2587807":"hiphop['spotify:track:3MnwLa9KRUiv2gNFtWPvib']['song']","8336de71":"hiphop['spotify:track:3MnwLa9KRUiv2gNFtWPvib']['meta'].keys()","86774f36":"hiphop['spotify:track:3MnwLa9KRUiv2gNFtWPvib']['meta']['segments'][0]","fcb450dc":"hiphop['spotify:track:3MnwLa9KRUiv2gNFtWPvib']['meta']['segments'][0]","3df711d5":"def get_song_name(json_data, song_uri):\n    '''Returns song name from song URI key\n     Args:\n     * json_data- (JSON) \n     * song_uri- (str) URI\n     \n     Return\n     * (str)- Song name\n     '''\n    return json_data[song_uri]['song']\n\ndef get_artist_name(json_data, song_uri):\n    '''Returns Artist name from song URI key\n     Args:\n     * json_data- (JSON) \n     * song_uri- (str) URI\n     \n     Return:\n     * (str)- Artist name\n     '''\n\n    return json_data[song_uri]['artist']\n\ndef get_timbre_values(json_data, song_uri):\n    '''Returns timbre values from a song\n    Args:\n    * json_data- (JSON) \n    * song_uri- (str) URI \n    \n    Return:\n    * (list) Each element is a list of timbre values\n    '''\n    timbre_data = []\n    for segment in json_data[song_uri]['meta']['segments']:\n        timbre_data.append(segment['timbre'])\n    return timbre_data\n\ndef get_segment_start_time(json_data, song_uri):\n    '''Returns start times of segments from a song\n    Args:\n    * json_data- (JSON) \n    * song_uri- (str) URI \n    \n    Return:\n    * (list) Each element is float representing time in milliseconds\n    '''\n    start_times = []\n    for segment in json_data[song_uri]['meta']['segments']:\n        start_times.append(segment['start'])\n    return start_times\n\ndef get_segment_duration(json_data, song_uri):\n    '''Returns duration of segments from a song\n    Args:\n    * json_data- (JSON) \n    * song_uri- (str) URI \n    \n    Return:\n    * (list) Each element is float representing the duration of a segment\n    '''\n    durations = [] \n    for segment in json_data[song_uri]['meta']['segments']:\n        durations.append(segment['duration'])\n    return durations","8c5cb1f7":"def get_genre_data(genre_data, genre_type):\n    '''\n    Processes a JSON object of a single genre\n    Args:\n    * genre data (JSON)\n    * single genre (str) Name of genre\n    \n    Returns:\n    * pandas DataFrame containing training data and label for ML\n    '''\n    genre_dataframes = []\n    for song_uri in genre_data.keys():\n        # Extract the relevant data\n        timbres = get_timbre_values(genre_data, song_uri)\n        start_times = get_segment_start_time(genre_data, song_uri)\n        durations = get_segment_duration(genre_data, song_uri)\n        artist_name = get_artist_name(genre_data, song_uri)\n        song_name = get_song_name(genre_data, song_uri)\n        # Create a dataframe per song\n        # We'll build the timbre parts first then add columns\n        song_df = pd.DataFrame(timbres)\n        song_df['start'] = start_times\n        song_df['durations'] = durations\n        song_df['song_name'] = song_name\n        song_df['artist'] = artist_name\n        # Remember to add the genre so we can use it for supervised learning later!\n        song_df['genre'] = genre_type\n        #\u00a0Now we need to store\/append all the songs in a genre dataframe\n        genre_dataframes.append(song_df)\n    # Now concatenate the song dataframes into a single genre specific dataframe\n    genre_df = pd.concat(genre_dataframes)\n    return genre_df","095185aa":"get_genre_data(hiphop, 'hiphop').head()","7841272c":"genre_data_path = '..\/input\/musicdata\/'\ngenre_list = os.listdir(genre_data_path)","20fbf2e3":"all_genre_list = []\nfor genre in genre_list:\n    # Get rid of the pesky .DS_Store files with this clause\n    if not genre.endswith('.DS_Store'):\n        path = os.path.join(genre_data_path, genre)\n        with open(path, 'rb') as f:\n            genre_json = json.load(f)\n        # Extract the genre from the file name    \n        genre_label = genre.replace('.json', '')   \n        # Apply our function\n        genre_data = get_genre_data(genre_json, genre_label)\n        all_genre_list.append(genre_data)\n\ndf = pd.concat(all_genre_list)\ndf.head()","8fdc65fa":"df.rename(columns={i: 'timbre_value_'+str(i) for i in range(0,12)}, inplace=True)","7364c1f7":"df.rename(columns={'timbre_value_0':'loudness',\n                   'timbre_value_1': 'brightness',\n                   'timbre_value_2': 'flatness'}, inplace=True)","322e3ce9":"def get_genre_df(genre_data_path):\n    genre_list = os.listdir(genre_data_path)\n    all_genre_list = []\n    for genre in genre_list:\n    # Get rid of the pesky .DS_Store files with this clause\n        if not genre.endswith('.DS_Store'):\n            path = os.path.join(genre_data_path, genre)\n            with open(path, 'rb') as f:\n                genre_json = json.load(f)\n            # Extract the genre from the file name    \n            genre_label = genre.replace('.json', '')   \n            # Apply our function\n            genre_data = get_genre_data(genre_json, genre_label)\n            all_genre_list.append(genre_data)\n\n    df = pd.concat(all_genre_list)\n    df.rename(columns={i: 'timbre_value_'+str(i) for i in range(0,12)}, inplace=True)\n    df.rename(columns={'timbre_value_0':'loudness',\n                   'timbre_value_1': 'brightness',\n                   'timbre_value_2': 'flatness'}, inplace=True)\n    return df\n\n    ","0112788a":"df = get_genre_df(genre_data_path)\ndf.head()","e48af35a":"df_pop = df[df['genre']=='pop']\ndf = df[df['genre']!='pop']","bb70663b":"training_colummns = ['loudness', 'brightness', 'flatness', 'timbre_value_3',\n                     'timbre_value_4', 'timbre_value_5', 'timbre_value_6', 'timbre_value_7',\n                     'timbre_value_8', 'timbre_value_9', 'timbre_value_10',\n                     'timbre_value_11']\nX = df[training_colummns]\ny = df['genre']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","559f63e0":"clf = LogisticRegression(random_state=0, solver='lbfgs',\n                         multi_class='multinomial')\nclf.fit(X_train, y_train)\ny_pred_log_reg = clf.predict(X_test)","cf5cdd0c":"print('f1 score {}'.format(f1_score(y_test, y_pred_log_reg, average='weighted')))\nprint('recall score {}'.format(recall_score(y_test, y_pred_log_reg, average='weighted')))\nprint('precision score {}'.format(precision_score(y_test, y_pred_log_reg, average='weighted')))","1e1a1973":"{key:value for key, value in zip(sorted(df['genre'].unique()), f1_score(y_test, y_pred_log_reg, average=None))}\n","6cf3a24d":"log_reg_results = pd.DataFrame({'y_Actual':y_test,\n                        'y_Predicted':y_pred_log_reg})\nconfusion_matrix_log_reg = pd.crosstab(log_reg_results['y_Actual'], log_reg_results['y_Predicted'], rownames=['Actual'], colnames=['Predicted'], margins = True)\nconfusion_matrix_log_reg","3db14008":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)","da5d1553":"y_pred_rf = rf.predict(X_test)","2a358ff5":"print('f1 score {}'.format(f1_score(y_test, y_pred_rf, average='weighted')))\nprint('recall score {}'.format(recall_score(y_test, y_pred_rf, average='weighted')))\nprint('precision score {}'.format(precision_score(y_test, y_pred_rf, average='weighted')))","86041efa":"{key:value for key, value in zip(sorted(df['genre'].unique()), f1_score(y_test, y_pred_log_reg, average=None))}\n","969b57c7":"y_pred_rf = rf.predict(X_test)\nresults_rf = pd.DataFrame({'y_Actual':y_test,\n                           'y_Predicted':y_pred_rf})\n","5658b09c":"confusion_matrix_rf = pd.crosstab(results_rf['y_Actual'], results_rf['y_Predicted'], rownames=['Actual'], colnames=['Predicted'], margins = True)\nconfusion_matrix_rf","b251fcf3":"pop_timbre = df_pop[training_colummns]\ndf_pop['predicted_genre'] = rf.predict(pop_timbre)","8654b1d4":"df_pop['song_name'].unique()","4da8c557":"pop_song = df_pop[df_pop['song_name']=='CHopstix (with Travis Scott)']","2d226d48":"pop_song['predicted_genre'].value_counts().plot(kind='bar')\n\nplt.title('Genre Composition for CHopstix by ScHoolboy Q with Travis Scott')","6bde775e":"plt.rcParams[\"figure.figsize\"] = (10,10)\n\ncolors = {'hiphop':'m',\n           'funk': 'g',\n           'metal': 'k',\n           'jazz':'y',\n           'blues':'b',\n           'classical':'r',\n           'electronic': 'C1'}\n\nfor segment in range(len(pop_song)):\n    prediction = pop_song.iloc[segment]['predicted_genre']\n    start = pop_song.iloc[segment]['start']\n    duration = pop_song.iloc[segment]['durations']\n    plt.hlines(xmin=start, xmax= start+duration, y=1,\n               colors=colors[prediction], linewidth= 200)\nplt.yticks([])\nplt.xlabel='Seconds'\npatches = [mpatches.Patch(color=color, label=genre) for genre, color in colors.items()]\nplt.legend(handles=patches, bbox_to_anchor=(0.5, -0.05),\n           fancybox=True, shadow=True, ncol=7,\n           loc='upper center')\nplt.title('{} by {}'.format(pop_song.iloc[segment]['song_name'],\n                            pop_song.iloc[segment]['artist']))\n\nplt.show()","73443354":"test_songs = get_genre_df('..\/input\/testsongdata\/')","b8eb04e3":"test_songs.head()","f7f780c2":"# Predict the genre\ntest_songs_timbre = test_songs[training_colummns]\ntest_songs['predicted_genre'] = rf.predict(test_songs_timbre)","432902b3":"def get_song_data(song_dataframe, genre=None, song_name=None):\n    if song_name:\n        song_df = song_dataframe[song_dataframe['song_name']==song_name]\n        return song_df\n    else:\n        genre_df = song_dataframe[song_dataframe['genre']==genre]\n        random_song = np.random.choice(genre_df['song_name'].unique())\n        random_song_data = genre_df[genre_df['song_name']==random_song]\n        return random_song_data\n        ","68023ab2":"def get_song_composition_bar(song_data):\n    song_data['predicted_genre'].value_counts().plot(kind='bar')\n    plt.title('{} by {}'.format(song_data.iloc[0]['song_name'],\n                                song_data.iloc[0]['artist']))\n    plt.show()","df30fec0":"def get_song_composition_timeline(song_data):\n    plt.rcParams[\"figure.figsize\"] = (10,10)\n    colors = {'hiphop':'m',\n               'funk': 'g',\n               'metal': 'k',\n               'jazz':'y',\n               'blues':'b',\n               'classical':'r',\n               'electronic': 'C1'}\n\n    for segment in range(len(song_data)):\n        prediction = song_data.iloc[segment]['predicted_genre']\n        start = song_data.iloc[segment]['start']\n        duration = song_data.iloc[segment]['durations']\n        plt.hlines(xmin=start, xmax= start+duration, y=1,\n                   colors=colors[prediction], linewidth= 200)\n    plt.yticks([])\n    plt.xlabel='Seconds'\n    patches = [mpatches.Patch(color=color, label=genre) for genre, color in colors.items()]\n    plt.legend(handles=patches, bbox_to_anchor=(0.5, -0.05),\n               fancybox=True, shadow=True, ncol=7,\n               loc='upper center')\n    plt.title('{} by {}'.format(song_data.iloc[segment]['song_name'],\n                                song_data.iloc[segment]['artist']))\n\n    plt.show()","2e690882":"def song_composition(song_dataframe, genre=None, song_name=None):\n    song_data = get_song_data(song_dataframe, genre, song_name=song_name)\n    get_song_composition_bar(song_data)\n    get_song_composition_timeline(song_data)\n    ","8a0851be":"song_composition(test_songs, 'classical')","83f1287a":"test_songs[test_songs['genre']=='metal']['song_name'].unique()","31de107b":"song_composition(test_songs, genre=None, song_name='My Own Summer (Shove It)')","38fd3014":"genre_types = ['metal','hiphop', 'funk', 'jazz', 'blues', 'classical', 'electronic']\nfor g in genre_types:\n    print(g)\n    song_composition(test_songs, g)","b8cff739":"We'll create a function that either picks a random or chosen song  to process from our test_songs dataframe.","fb0535ab":"Kinda gross, right? Let's make this a bit easier on the eyes.\n\nTry using the `json.dumps()` function.","3224a330":"This is neat, we can see the majority of the song is made up of hiphop, electronic and a bit of funk.\nCheck the song out for yourself [here](https:\/\/www.youtube.com\/watch?v=5xvxgUE_pTA)\n\nChopstiiiiicks, chopsticks, chopsticks....\n\nLyrical genius.[](http:\/\/)\n","915dba03":"# Now we have the model trained, we can now test it on pop songs\n\nCreate a predicted genre column for our pop dataframe","4cf88da0":"Here we have a dictionary built of key-value pairs. You can access each value stored in the dictionary using the keys.","922c341a":"```\n# use requests to interact with an API\nimport requests\n\n# The API path should be stated in the documentation \napi_path = 'https:\/\/dog.ceo\/api\/breeds\/image\/random'\n\n# use the get to collect data from the access point.\nr = requests.get(api_path).json()\n# Copy the url from the message and enjoy the view\nprint(r['message'])\n\n```\n","6bb302c9":"Looks like the funk class is really letting itself down.\n\nIf we look closer we can see our model is having trouble distinguishing between funk and hiphop.\n\nThese genres are quite similar in terms of the timbre. A lot of samples will be used in hiphop that have definitely been derived from funk, so we'll let it slide for now. \n\nMaybe we can introduce nes features\/more data later to boost our performance.\n\nBut right now, we'll continue with the project...","d398d5d8":"Rename the first three timbre values according to the documentation","301fce95":"Or access the list object directly...","0e947f68":"Let's tidy the name columns up.\n\nCheck out this page on what the timbre values correspond to\n\nhttps:\/\/developer.spotify.com\/documentation\/web-api\/reference\/tracks\/get-audio-analysis\/#timbre\n\nFrom this we know what some of the values correspond to, but not all of them...","bd6807c2":"# Train a logistic regression model","2d77f28c":"Neat, we've just navigated and stored the relevant data for our model.\n\nHowever, this is only one song, we'll need to get a few more samples to play with.\n\nWe've collected about 50 songs from some well known genres:\n* jazz\n* blues\n* funk,\n* metal\n* classical\n* hiphop\n* pop\n* electronic\n\nAnd streamlined the data to include the information we'll need for the rest of the exercise.\n\nLet's use our knowledge of dictionary naviagation to wrangle the data into a Dataframe so we can model it.\n\nWithin the `musicdata` folder we have a few JSON files, each one contains songs and their segment data from a single genre.","1ade7eb3":"# Just as promised here's a quick tutorial on calling an API\nA lot of companies open up their APIs to the public so it's always worth checking their dev pages.\n\nA great example of this is [TFL](https:\/\/api.tfl.gov.uk\/)- The level of detail in this API is outrageous.\n\nIf your just looking to flex your API muscles then have a look at this website [apilist](https:\/\/apilist.fun\/)\n\nThere's an API that gives us images of dogs, so of course we're going to use that...\n\nhttps:\/\/dog.ceo\/dog-api\/\n\nThe dataset is based on the Stanford Dogs Dataset so hopefully we get some dog images back.\n\n**NOTE** Kaggle notebooks do not support calling an API directly- So if you want to try this code out, just copy it into a local jupyter notebook\/script.\n\n","0e5045ef":"See you all next time! \ud83d\udc4b\ud83d\udc4b\ud83d\udc4b\ud83d\udc4b","dd256a2b":"We have our extraction functions, lets get extracting!\n\nEverything that we return from these functions should go straight into a pandas DataFrame.\n\nFor anyone that hasn't used a pandas DataFrame, it's basically a table similiar to that of an Excel\/Sheets spreadsheet.\nIf you want more information about them, check out https:\/\/pandas.pydata.org\/","cd997a4b":"Lets create a couple of functions to extract this data.","8aeea8fe":"# Sourcing data online\n\nSourcing data for a project can be tricky, one option is to scower the internet looking for datasets to download. Another option is to use an Application Programming Interface (API).\n\n\n### APIs\nAn API allows different applications to share data between each another. By calling an API we gain access to data held on a server.\n\n### So why are these good for a data scientist?\n\nSay you wanted to keep up-to-date the National Leage promotion race (abosulte nail biter). You could search for the hashtag #LeytonOrient and copy and paste each of the tweets into a document. This will take forever.\n\nThe next best thing would be to email twitter and ask for a dataset of the twitter stream, but again this would waste even more peoples peoples time. \n\nInstead, companies create these access points known as APIs that let you query available data. This reduces up the time needed to collect the data you need for your project. Great!\n\n### What to expect from an API\nInformation returned from an API can come in a couple of formats, but the one that we'll be using today is JavaScript Object Notation- JSON. \n\nJSON is ubiquitous throughout the web. It's human readable, lightweight and can be interpreted by a tonne of languages, including python. \n","1973150c":"# Welcome to this months Central London Data Science Meetup! \n\nIf you've ever read a data science related blog before, you'll probably have read either:\n* 'AI is the new electricity' (I'm looking at you Andrew Ng)\n* '90% of a data scientist time is spent sourcing and then cleaning the data'\n\nIn tonights notebook we will be delving into predicting the genre of songs using spotify data. From this you'll see that a data scientist really does spend a lot of time collecting and wrangling data.\n\n\n\nSo without further ado lets get started!","d7aab460":"It returns a `list`, we can either associate this value with a variable and work with it elsewhere like so....","404e544c":"Pop music isn't necessarily a genre onto itself, it's whats popular right now. So it's kinda cool that we can see whats currently influencing current music.\n\nWe'll now test out our model with separate data from our original genres and see how it copes.\n\nWe have another dataset waiting in the wing- `testsongdata`...\n\nLet's use our original `get_genre_df` function to save some time wrangling.","39385732":"We want to combine all these data sources into one big dataframe.\n\nEach one has the same structure, let's look at an example fo how to get the data.","d76a65ec":"Now we'll wrap all this in a function. ","8dd9ebd5":"OK, this stuff is a bit boring, let's get into the data that we'll be using for our model.\nHead on over to the [doumentation](https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/tracks\/get-audio-analysis\/) and check out what `segments` represents.\n\n**\"Audio segments attempts to subdivide a song into many segments, with each segment containing a roughly consitent sound throughout its duration.\"**","d3c831d3":"We can combine the two lines and pass it through a for loop to get all the timbre values across each segment for this song...\n","e0036df1":"We'll go through each genre and pick a random song...","0061e5b5":"Lets look at the meta data values...","c49f7fe6":"# Sourcing our data\nSo now that we know what an API is and what to expect from it, the next hurdle is understanding how to get it and what it'll contain. \n\nWith this in mind let's jump over to the spotify API documentation- https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/\n\nIn order to source and naviagate the data needed for a project you will need to understand what each key and value represent, so get used to jumping between your code and API documentation.\n\nHave a look for yourself across all the documentation- (It might give you a bit of inspiration for your own project).\n\nFor our project we will be living on these two pages: \n\n* https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/tracks\/get-audio-analysis\/\n\n* https:\/\/developer.spotify.com\/documentation\/web-api\/reference\/tracks\/get-audio-features\/\n\n\nThese pages are incredibly useful- we get a description of what the data represent, but a map of how to access it.\n\nIn the interest of time, (and also ensuring we don't bring CodeNodes internet crashing down). All the data for tonights excercise is stored locally in the environment. \n\nHowever, at the end of the exercise we'll have a mini tutorial on how to call an API by yourself.\n\nLet's jump into a single songs audio analysis.\n","d5b59d8e":"* Not amazing performance here, let's see which genre's the model is having problems with...","c330a48f":"Try and explore and pick a song from the test dataframe","11fd429d":"Phew...\n\nOK that's the main part of the exercise complete, congratz! \ud83c\udf89\n\nThese visualisation look pretty cool, you can even see the main parts like- intro, verses, chorus and even bridges!\n\nIf you have time to spare, or want to dive a bit deeper be our guest. \ud83c\udf75\ud83d\udd6f\n\nAlso, we mentioned about the `'90% of a data scientist time is spent sourcing and then cleaning the data'`\n\nIn this notebook we wrote `30` lines of code dedicated to ML, the rest (`284` lines) was getting and displaying the data.\n\nThat's approx `89.5%`, pretty close to the `90%` quote.\n\nHere's a few suggestions:\n\n* Try and cluster the data \n* Bring in the start time as a feature used to predict \n* Play around with the original data and see if you can extract other meaningful information for your model\n* What could we use to distinguish hiphop from funk better? Maybe time signatures, or tempo, if we had a bigger dataset we could try and bring in artist name?\n* Predict the verse, chorus, bidge, outros of a song or genre\n* Try other predictive models\n* Tune the hyperparams to optimise the current random forrest\n> * Explore other APIs\n","13e5b32f":"Here's how we would access the value associated with the key `dog`","cc6a38c0":"Now the super cool thing about dictionary object is that you can store a tonne of inforation in a variety of formats. Lets check out `list_of_things`.","60159169":"Cool! So now we have the basics of how to naviagate our way across a dictionary, let's put it to use.\n\nHere are the keys to our audio analysis","0978ef25":"To give you an idea on the end goal of this wrangling- Check out how the dataframe will look like later...\n\n![](https:\/\/github.com\/Blair-Young\/PredictingMusicGenresFromSpotifyData\/blob\/master\/images\/Screen%20Shot%202019-04-21%20at%2015.43.03.png?raw=true)","f2758846":"# Not great :S\nLet's bring in the cavalry...","c2733d09":"We'll pick a song from the list and see the breakdown of the composition","49e35a49":"Still a bit intimadating though...\n\nWhen we load in a json object- python interprets it as a dictionary. So lets use some python 101 to navigate the struture.\n\nA dictionary consists of a collection of key-value pairs. Each key-value pair maps the key to its associated value.\n\nYou can build a dictionary by wrapping a `key` joined by a colon `:` to an asscoicated `value` using curly braces `{}`.\n\nLet's build a simple dictionary","fc3b2fd2":"**Check out the last line of the documentation**\n\n* `Timbre vectors are best used in comparison with each other.`\n\nLooks like they've already been normalised for us, thanks Spotify.\n\nThis means we can get straight into the machine learning (about time!)\n\nOne more thing (I promise). We'll separate the pop music from the rest of the data, we'll try and use our model to break them down.","c900e90a":"Segments returns a list of dictionaries, each of these dictionaries contains string data and lists.\n\nGreat, our dictionary contains a list of other dictionaries, that isn't confusing at all...\n\nWhat we want is the timbre values.\n\n**Timbre is the quality of a musical note or sound that distinguishes different types of musical instruments, or voices. Timbre vectors are best used in comparison with each other.**","3b76ec4d":"Let's scale it up so we can use it across all genres."}}