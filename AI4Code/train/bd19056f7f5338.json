{"cell_type":{"9a4a8b77":"code","79d7cae1":"code","536e065f":"code","4ebdb82e":"code","1a344349":"code","9940eda4":"code","2da13002":"code","dca592ef":"code","d5692831":"code","852fcae2":"code","bc2a059e":"code","4cf3775c":"code","6c01891f":"code","1526b164":"code","3973ff82":"code","3a7b3883":"code","8b76f37b":"code","83848755":"code","81e2e8c7":"code","3f5fb3f5":"code","4ad36943":"code","c6237d08":"code","e7eda795":"code","a6d8121c":"code","d810c09f":"code","b3477a34":"code","35306d2f":"code","e4f9b260":"code","e9c01c67":"code","cd5d8735":"code","f2549366":"code","24562734":"code","52a93589":"code","e194e7ea":"code","b8d84f12":"code","6311f37c":"markdown","16ecd878":"markdown"},"source":{"9a4a8b77":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import random_split\nfrom torch.utils.data.dataloader import DataLoader\n\nfrom torchvision import datasets, transforms, models \nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid","79d7cae1":"data_dir = '..\/input\/furniture-images-dataset\/furniture_images'","536e065f":"labels=pd.read_csv('..\/input\/furniture-images-dataset\/furniture_data_img.csv')\nlabels","4ebdb82e":"Name = labels['Furniture_Type'].unique().tolist()\nprint(Name)\nprint(len(Name))","1a344349":"N=list(range(len(Name)))    \nnormal_mapping=dict(zip(Name,N)) \nreverse_mapping=dict(zip(N,Name)) ","9940eda4":"labels['label']=labels['Furniture_Type'].map(normal_mapping)","2da13002":"files = labels['Image_File'].unique().tolist()\nprint(files[0:10])\nprint(len(files))","dca592ef":"dataset=[]\nfor i in tqdm(range(len(labels))):\n    labeli=labels.loc[i,'label']\n    filei=labels.loc[i,'Image_File']\n    path=os.path.join(data_dir,filei[1:])\n    img1=cv2.imread(path)\n    img2=cv2.resize(img1,dsize=(100,100),interpolation=cv2.INTER_CUBIC)\n    img3=img2.astype(np.float32)\n    image=torch.from_numpy(img3)\n    dataset+=[[image,labeli]]","d5692831":"dataset[100]","852fcae2":"# view one image shape of the dataset.\nimg, label = dataset[100]\nprint(img.shape)\nprint(label)","bc2a059e":"def show_image(img,label):\n    plt.imshow(img.numpy().astype(int))","4cf3775c":"show_image(*dataset[20])","6c01891f":"torch.manual_seed(20)\nval_size = len(dataset)\/\/10\ntest_size = len(dataset)\/\/5\ntrain_size = len(dataset) - val_size - test_size","1526b164":"train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\nlen(train_ds), len(val_ds), len(test_ds)   ","3973ff82":"batch_size = 64\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_ds, batch_size, num_workers=4, pin_memory=True)","3a7b3883":"m=len(dataset)\nM=list(range(m))\nrandom.seed(2021)\nrandom.shuffle(M)","8b76f37b":"fig, axs = plt.subplots(3,3,figsize=(9,9))\nfor i in range(9):\n    r=i\/\/3\n    c=i%3\n    img1,label=dataset[M[i]]\n    ax=axs[r][c].axis(\"off\")\n    ax=axs[r][c].set_title(reverse_mapping[label])\n    ax=axs[r][c].imshow(img1.numpy().astype(int))\nplt.show()","83848755":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","81e2e8c7":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","3f5fb3f5":"torch.cuda.is_available()","4ad36943":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","c6237d08":"device = get_default_device()\ndevice","e7eda795":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(val_loader, device)\ntest_loader = DeviceDataLoader(test_loader, device)","a6d8121c":"input_size = 3*100*100\noutput_size = len(Name)","d810c09f":"class Model(ImageClassificationBase):\n    def __init__(self, input_size, output_size):\n        super().__init__()\n        # hidden layer\n        self.in_layer = nn.Linear(input_size, 8384)\n        self.hidden1 = nn.Linear(8384, 4192)\n        self.hidden2 = nn.Linear(4192, 2096)\n        self.hidden3 = nn.Linear(2096, 1048)\n        self.out_layer = nn.Linear(1048, output_size)\n        \n    def forward(self, xb):\n        # Flatten images into vectors\n        out = xb.view(xb.size(0), -1)\n        out = self.in_layer(out)\n        out = self.hidden1(F.relu(out))\n        out = self.hidden2(F.relu(out))\n        out = self.hidden3(F.relu(out))\n        out = self.out_layer(F.relu(out))\n        return out","b3477a34":"model = to_device(Model(input_size, output_size), device)","35306d2f":"model","e4f9b260":"history = [evaluate(model, val_loader)]\nhistory","e9c01c67":"history += fit(8, 0.01, model, train_loader, val_loader)","cd5d8735":"history += fit(8, 0.001, model, train_loader, val_loader)","f2549366":"history += fit(4, 0.0001, model, train_loader, val_loader)","24562734":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')\n    plt.show()\n    \n    \ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs')\n    plt.show()","52a93589":"plot_accuracies(history)","e194e7ea":"plot_losses(history)","b8d84f12":"evaluate(model, test_loader)","6311f37c":"# Furniture Images Classify Torch Linear","16ecd878":"# Linear Model"}}