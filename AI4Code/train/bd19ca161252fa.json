{"cell_type":{"b83f8d79":"code","77b44f66":"code","6ae272fa":"code","f444c68e":"code","27d02ce0":"code","075c67ac":"code","f716e95f":"code","c6aec2f3":"code","a3438e7c":"code","f8ecfc03":"code","b0ad805f":"code","6dfc1edb":"code","eecbb616":"code","ca866088":"code","319445b7":"code","51aff48e":"code","bd8ecfa8":"code","b384362c":"markdown","a5f51dba":"markdown","63e726a7":"markdown","b7b81d5d":"markdown","165fe4af":"markdown","deb07fac":"markdown"},"source":{"b83f8d79":"!pip install openpyxl","77b44f66":"import itertools\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns","6ae272fa":"def load_data(dir_name: str, file_name: str, sheet_name: str) -> pd.DataFrame:\n    _df = pd.read_excel('{}\/{}'.format(dir_name, file_name), sheet_name = sheet_name)\n    _df = _df.set_index('Unnamed: 0')\n\n    # data cleansing\n    _df.index = [s.strip() for s in _df.index]\n    _df.columns = [s.strip() for s in _df.columns]\n\n    # Validation\n    assert _df.shape == (1000, 1000)\n    assert list(_df.index) == list(_df.columns)\n\n    return _df","f444c68e":"def df_to_graph(df: pd.DataFrame) -> nx.Graph:\n    _graph = nx.from_pandas_adjacency(df)\n    assert _graph.number_of_nodes() == 1000\n    return _graph","27d02ce0":"dir_name = '\/kaggle\/input\/huawei-social-network-data'\nservice_names = ['Facebook', 'Twitter', 'Instagram']\nfile_names = ['{}_Data.xlsx'.format(service_name) for service_name in service_names]\nsheet_name = 'Sheet1'\n\nfb_df, tw_df, ig_df = [load_data(dir_name, file_name, sheet_name) for file_name in file_names]\nensembled_df = fb_df + tw_df + ig_df\n# ensembled_df = fb_df * tw_df * ig_df\n\ngraph_list = [df_to_graph(df) for df in [fb_df, tw_df, ig_df, ensembled_df]]\nfb_graph, tw_graph, ig_graph, ensembled_graph = graph_list\nservice_names += ['Ensembled']","075c67ac":"# All graph is undirected\nfor _df in [fb_df, tw_df, ig_df]:\n    assert np.mean([list(_df[key]) == list(_df.transpose()[key]) for key in _df.index]) == 1.0","f716e95f":"fb_df","c6aec2f3":"_, axes = plt.subplots(ncols = 4, figsize = (400, 100))\nfor (index, (service_name, graph)) in enumerate(zip(service_names, graph_list)):\n    axes[index].set_title(service_name, fontsize = 200)\n    nx.draw(graph, node_size = 1, ax = axes[index])","a3438e7c":"def degree_list(graph: nx.Graph) -> list:\n    return list(dict(graph.degree()).values())\n\ndef degree_analysis(graph: nx.Graph) -> tuple:\n    _degree_list = degree_list(graph)\n    return round(np.mean(_degree_list), 3), max(_degree_list), min(_degree_list)\n\nresult_df = pd.DataFrame(\n    index = service_names,\n    columns = ['Node', 'Edge', 'Average Distance', 'Average Clustering', 'Average Degree', 'Max Degree', 'Min Degree']\n)\n\nresult_df['Node'] = [graph.number_of_nodes() for graph in graph_list]\nresult_df['Edge'] = [graph.number_of_edges() for graph in graph_list]\nresult_df['Average Distance'] = [round(nx.average_shortest_path_length(graph), 3) for graph in graph_list]\nresult_df['Average Clustering'] = [round(nx.average_clustering(graph), 3) for graph in graph_list]\nresult_df[['Average Degree', 'Max Degree', 'Min Degree']] = [degree_analysis(graph) for graph in graph_list]\nresult_df","f8ecfc03":"fig, axes = plt.subplots(ncols = 4, figsize = (20, 5), sharey = True)\nfig.suptitle('Degree Distribution')\n\nfor (index, (service_name, graph)) in enumerate(zip(service_names, graph_list)):\n    axes[index].hist(degree_list(graph), bins=25)\n    axes[index].set_title(service_name)\n    axes[index].set_xlabel('Degree')\n    if index == 0:\n        axes[index].set_ylabel('Frequency of Degree')","b0ad805f":"fig, axes = plt.subplots(ncols = 4, figsize = (20, 5), sharey = True)\nfig.suptitle('Cumulative Degree Distribution')\n\nfor (index, (service_name, graph)) in enumerate(zip(service_names, graph_list)):\n    n = int(result_df.loc[service_name]['Node'])\n    min_degree = int(result_df.loc[service_name]['Min Degree'])\n    max_degree = int(result_df.loc[service_name]['Max Degree'])\n\n    xs = list(range(min_degree, max_degree + 1))\n    ys = [len([degree for degree in degree_list(graph) if degree >= x]) \/ n for x in xs]\n    axes[index].scatter(xs, ys)\n    axes[index].set_title(service_name)\n    axes[index].set_xlim(min_degree, max_degree + 1)\n    axes[index].set_xlabel('Degree (log)')\n    if index == 0:\n        axes[index].set_ylabel('Frequency of Degree (log)')\n    axes[index].set_xscale('log')\n    axes[index].set_yscale('log')","6dfc1edb":"def centrality(_func, service_names: list, graph_list: list) -> pd.DataFrame:\n    centrality_dict_list = [_func(graph) for graph in graph_list]\n    centrality_sr_list = [pd.Series(centrality_dict.values(), index = centrality_dict.keys()) for centrality_dict in centrality_dict_list]\n\n    _df = pd.DataFrame(index = centrality_dict_list[0].keys(), columns = service_names)\n    for (service_name, centrality_sr) in zip(service_names, centrality_sr_list):\n        _df[service_name] = centrality_sr\n\n    return _df","eecbb616":"degree_centrality_df = centrality(nx.degree_centrality, service_names[0:3], graph_list[0:3])\ncloseness_centrality_df = centrality(nx.closeness_centrality, service_names[0:3], graph_list[0:3])","ca866088":"g = sns.pairplot(degree_centrality_df, corner = True)\ng.fig.suptitle('Correlation of degree centrality')\ndegree_centrality_df.corr()","319445b7":"g = sns.pairplot(closeness_centrality_df, corner=True)\ng.fig.suptitle('Correlation of closeness centrality')\ncloseness_centrality_df.corr()","51aff48e":"comp = nx.algorithms.community.girvan_newman(fb_graph)","bd8ecfa8":"# %%time\n# for communities in itertools.islice(comp, 5):\n#     print(tuple(sorted(c) for c in communities))","b384362c":"### Degree Distribution","a5f51dba":"# SNS Data Analysis\n\nAs an exercise of network analysis, degree distribution and centrality analysis are shown.\n\n## 1. Load and transform data","63e726a7":"### Centrality Analysis","b7b81d5d":"## 3. Data Analysis\n\n### Basic Stats","165fe4af":"### Community Analysis","deb07fac":"## 2. Visualization"}}