{"cell_type":{"ced56b8e":"code","2a048223":"code","a41b3860":"code","eee2569e":"code","d433b5bb":"code","2b35b093":"code","5e974104":"code","10aa217e":"code","7515a527":"code","68fb6f09":"code","605ef132":"code","93ecfe1e":"code","9b8317e7":"code","6f0c0c4a":"code","8766366e":"code","c3250592":"code","a465fe0e":"code","fa7de7a0":"code","a63da42b":"code","b182d612":"code","aee48c24":"code","765e1694":"code","31d859b1":"code","87bc11c5":"code","45820ae1":"code","b30f5444":"code","ba10e2df":"code","db0fc2a8":"code","48849d64":"code","9109806d":"code","ac214266":"code","c773e930":"code","fe92960c":"code","02002225":"code","31501ffb":"code","e5574884":"code","7c8009a8":"code","6ce60b33":"code","4eb96a00":"code","80493fe3":"code","d1bc1a16":"code","86276cde":"markdown","d5410efa":"markdown","12d17ce6":"markdown","7b2c7359":"markdown","325d94da":"markdown","8ffe0b48":"markdown","ff1867c0":"markdown","06c36f64":"markdown","1a2148df":"markdown"},"source":{"ced56b8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2a048223":"# Reading .csv file \nimport pandas as pd\ndata = pd.read_csv('..\/input\/large-random-tweets-from-pakistan\/Random Tweets from Pakistan- Cleaned- Anonymous.csv', encoding='ISO-8859-1')","a41b3860":"# To get the dimentions of the dataset.\ndata.shape","eee2569e":"# To get the column names of the dataset\ndata.columns","d433b5bb":"# to print the consise summary of the data set\ndata.info()","2b35b093":"# to compute a summary of statistics pertaining to the DataFrame columns\ndata.describe()","5e974104":"# to return the first five rows of the data frame\ndata.head()","10aa217e":"# To get the data types of the different features\/ columns\ndata.dtypes","7515a527":"# to check the missing or null values in the data set \ndata.isnull().sum()                                                     \nmiss_val = data.isnull().sum().sort_values(ascending=False)\nmiss_val = pd.DataFrame(data=data.isnull().sum().sort_values(ascending=False), columns=['MissvalCount'])\n\n# Add a new column to the dataframe and fill it with the percentage of missing values\nmiss_val['Percent'] = miss_val.MissvalCount.apply(lambda x : '{:.2f}'.format(float(x)\/data.shape[0] * 100)) \nmiss_val = miss_val[miss_val.MissvalCount > 0]\nmiss_val","68fb6f09":"# to check the the text of tweet at specified row\ndata['full_text'][10]","605ef132":"# to compute a summary of statistics pertaining to the DataFrame column full_text\ndata['full_text'].describe()","93ecfe1e":"# to compute a summary of statistics pertaining to the DataFrame location\ndata['location'].describe()","9b8317e7":"text = data['full_text']\nlocation = data['location']\n\nfor i in np.random.randint(1000, size=10):\n    print(f'Tweet # {i}: ', text[i], '=> Location: ', location[i], end='\\n' * 3)","6f0c0c4a":"location = data.groupby('location')\nlocation.head()","8766366e":"# drop rows with any missing values\ndata.dropna(inplace=True)","c3250592":"# Removing duplicates\ndata.drop_duplicates()","a465fe0e":"data.head()","fa7de7a0":"# drop the columns with highest missing values \ndata = data.drop(['Unnamed: 0', 'created_at_tweet', 'retweet_count', 'favorite_count','reply_count', 'location'], axis=1)\ndata.head()","a63da42b":"from sklearn import decomposition\nfrom scipy import linalg\nimport re\n\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport string\nimport nltk\nimport warnings \nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n%matplotlib inline","b182d612":"def remove_pattern(input_txt, pattern):\n    r = re.findall(pattern, input_txt)\n    for i in r:\n        input_txt = re.sub(i, '', input_txt)\n        \n    return input_txt ","aee48c24":"# remove twitter handles (@user)\ndata['tidy_text'] = np.vectorize(remove_pattern)(data['full_text'], \"@[\\w]*\")","765e1694":"# remove special characters, numbers, punctuations\ndata['tidy_text'] = data['tidy_text'].str.replace(\"[^a-zA-Z#]\", \" \")","31d859b1":"#Removing Short Words\ndata['tidy_text'] = data['tidy_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))","87bc11c5":"from textblob import TextBlob","45820ae1":"def getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity","b30f5444":"def getpolarity(text):\n    return TextBlob(text).sentiment.polarity","ba10e2df":"data['Subjectivity'] = data['tidy_text'].apply(getSubjectivity)","db0fc2a8":"data['Polarity'] = data['tidy_text'].apply(getpolarity)","48849d64":"data.head(10)","9109806d":"def getPositiveNegativeWordCount(score):\n    if score < 0:\n        return 'Negative'\n    else:\n        return 'Positive'","ac214266":"data['Positive Negative Word Count'] =  data['Polarity'].apply(getPositiveNegativeWordCount)","c773e930":"import matplotlib.pyplot as plt \nimport seaborn as sns\nimport string\nimport nltk\nimport warnings \nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n%matplotlib inline\nfrom wordcloud import WordCloud ","fe92960c":"negative_words =' '.join([text for text in data['tidy_text'][data['Positive Negative Word Count'] == 'Negative']])\n\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(negative_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()\n","02002225":"positive_words =' '.join([text for text in data['tidy_text'][data['Positive Negative Word Count'] == 'Positive']])\n\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(positive_words)\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","31501ffb":"def wordcount_extract(x):\n    wordCount = []\n    # Loop over the words in the tweet\n    for i in x:\n        ht = re.findall(r\"#(\\w+)\", i)\n        wordCount.append(ht)\n\n    return wordCount","e5574884":"negativeWordCount = wordcount_extract(data['tidy_text'][data['Positive Negative Word Count'] == 'Negative'])\n\n# extracting hashtags from racist\/sexist tweets\npositiveWordCount = wordcount_extract(data['tidy_text'][data['Positive Negative Word Count'] == 'Positive'])\n\n# unnesting list\nnegativeWordCount = sum(negativeWordCount,[])\npositiveWordCount = sum(positiveWordCount,[])","7c8009a8":"neg = nltk.FreqDist(negativeWordCount)\nnegWordCount = sum(list(neg.values()))","6ce60b33":"pos = nltk.FreqDist(positiveWordCount)\nposWordCount = sum(list(pos.values()))","4eb96a00":"print(\"Negative Word Count: \",negWordCount)","80493fe3":"print(\"Positive Word Count: \",posWordCount)","d1bc1a16":"data['Positive Negative Word Count'].value_counts()\n\nplt.title('Positive Negative Word Count')\nplt.xlabel('')\nplt.ylabel('Counts')\ndata['Positive Negative Word Count'].value_counts().plot(kind='bar')\nplt.show()","86276cde":"# Check the missing or null values in the data set ","d5410efa":"# EXPLORATORY DATA ANALYSIS","12d17ce6":"# Create a plot between positive and negative word counts","7b2c7359":"# Removing rows with missing values","325d94da":"**Positive Words**","8ffe0b48":"# Removing Duplicates from Dataset","ff1867c0":"# Droping Columns ","06c36f64":"# Cleaning tweets","1a2148df":"**Negative Words**"}}