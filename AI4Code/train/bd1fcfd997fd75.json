{"cell_type":{"b8837508":"code","424e35af":"code","cdc441ff":"code","8faaab34":"code","e0643f46":"code","e75cd49b":"code","88458afd":"code","21d148fd":"code","cb741c4f":"code","25ff0597":"code","9c91fdcf":"code","3bbbe8c9":"code","2a4598e0":"code","80772682":"code","fc4dee32":"code","966a6c0b":"code","c08679df":"code","7ef08415":"code","33a5a4ce":"code","c05aa443":"code","2ab88719":"code","63ee3663":"code","8f0b2d83":"code","7d4c76cf":"code","5d4a0245":"code","6b79e248":"code","2cda4749":"code","6599d5d5":"code","930eaefa":"code","e06eae05":"code","b7c5496b":"code","4f2780f5":"code","e372cac4":"code","c11eaf4a":"code","91816a83":"code","fc6a0f19":"code","f2466601":"code","62b369bb":"code","4608b689":"code","28483068":"code","dcfed513":"code","77bce998":"code","e177323d":"code","f0dfdb63":"code","2df7a4ce":"code","31198495":"code","b62538cf":"code","332f596a":"code","0493db89":"code","f3c1f242":"code","81cc5b63":"code","ac69afe8":"code","2408c391":"code","2da8fe95":"code","252ed187":"code","4bc5c946":"code","6f108590":"code","21b4b575":"code","4f4115ea":"code","2ed0b0be":"code","5c0b0009":"code","a7ed7650":"code","f2d6fc89":"code","5622f95a":"code","0ba075bd":"code","db3b8e28":"code","8366a170":"code","0dab06c2":"code","3a3d11b3":"code","360c1f69":"code","d4726a67":"code","5d037d9b":"code","65635695":"code","19ee3b5f":"code","c7dcbf1f":"code","1aa0bff3":"code","ef80e0cb":"code","9892b93c":"code","01a54912":"code","fc923be0":"code","35c4fe44":"code","e0aab482":"code","cdcc9a69":"code","917fd15a":"code","cf02dbbc":"code","0c4862ba":"code","2114fcef":"code","8f92b5d1":"code","005ee935":"code","00c78292":"code","6299eece":"code","5507353c":"code","6c8ea34e":"code","c32c8428":"code","af2c4715":"code","2e6efdcf":"code","5c5c2287":"code","f2183eb8":"code","7061eda1":"code","b534d4bd":"code","5769726b":"code","d6411208":"code","f8146b90":"code","cf7c4c8d":"code","3614c0e8":"code","b3c82d55":"code","4d29cbce":"code","6cb98bdc":"code","19a41f6a":"code","d6ff041a":"code","4811d177":"code","b395be97":"code","aaedfcd1":"code","c4e1e3b7":"code","647a856c":"code","536e1bbb":"code","106f57ac":"code","5c6085ab":"code","e997be95":"markdown","1dfa1e0d":"markdown","ec7179e0":"markdown","befaf4b2":"markdown","5cdf4cd9":"markdown","e24bfc91":"markdown","f540b857":"markdown","7feb907d":"markdown","8acf0f96":"markdown","065e5b1a":"markdown","b711c6b6":"markdown","4d0f6aa8":"markdown","a474ebee":"markdown","91c4e8cc":"markdown","fed99a63":"markdown","9363ddae":"markdown","a1161af4":"markdown","b09f3bdf":"markdown","6d32b88b":"markdown","0dcfc470":"markdown","d2fe80be":"markdown","1960b367":"markdown","43d39162":"markdown","21c6c754":"markdown","34c83991":"markdown","e7ae8336":"markdown","81c4a7f8":"markdown","ecdff848":"markdown","fe12fff4":"markdown","663271c0":"markdown","5ba673bc":"markdown","e68642a5":"markdown","89f0fb29":"markdown","a13db512":"markdown","54dba1b9":"markdown","13bb3da6":"markdown","7c14ebca":"markdown","c599992b":"markdown","88a9e0ac":"markdown","e134dc4e":"markdown","d9cad0f2":"markdown","6d901f55":"markdown","6b3e2753":"markdown"},"source":{"b8837508":"#imported the necessary libraries\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","424e35af":"#imported the train.csv\nhouse_data= pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')","cdc441ff":"house_data.head()","8faaab34":"house_data.shape","e0643f46":"house_data.info()","e75cd49b":"sns.heatmap(house_data.isnull(),yticklabels=False,cbar=False,cmap= 'Oranges')","88458afd":"pd.set_option('display.max_rows', None)\nhouse_data.isnull().sum()","21d148fd":"#extracting features with any null values using list comprehension\nnull_features= [features for features in house_data.columns if house_data[features].isnull().any()==True]","cb741c4f":"for feature in null_features:\n    data=house_data.copy()\n    \n    #converting null features values with 0: non null values and 1: null values in features\n    data[feature]=np.where(data[feature].isnull(),1,0)\n    \n    #now we will plot the features wrt Median Sales price for 0 and 1 values in features\n    data.groupby(feature)['SalePrice'].median().plot.bar(color=['darkorange','lightblue'])\n    print(data.groupby(feature)['SalePrice'].median())\n    plt.show()","25ff0597":"#now we will extract all the numerical features from the dataset\nnumerical_features= [feature for feature in house_data.columns if house_data[feature].dtypes !='O']\n\nprint('Number of Numerical Features:',len(numerical_features))\n\nhouse_data[numerical_features].head(5)","9c91fdcf":"#now we will extract datatime features from the dataset\nyear_feature=[feature for feature in numerical_features if 'Year' in feature or 'Yr' in feature]\n\nprint('Number of Yearly Features:',len(year_feature))\nhouse_data[year_feature].head(5)","3bbbe8c9":"#now we will analyze yearly features wrt SalePrice which is our independent feature\nfor feature in year_feature:\n    data=house_data.copy()\n    \n    data.groupby(feature)['SalePrice'].median().plot()\n    plt.show()","2a4598e0":"discrete_feature=[feature for feature in numerical_features if len(house_data[feature].unique())<25 and feature not in year_feature+['Id']]\n\nprint('Number of discrete feature:',len(discrete_feature))\n\nhouse_data[discrete_feature].head(5)","80772682":"#Lets find the relationship between discrete feature and SalePrice\nfor feature in discrete_feature:\n    data=house_data.copy()\n    \n    data.groupby(feature)['SalePrice'].median().plot.bar(color=['red','orange','green','skyblue','purple','turquoise','blue','darkorange'])\n    plt.ylabel('SalePrice')\n    plt.show()","fc4dee32":"#now we will extract Continuos feature\ncontinuous_features= [feature for feature in numerical_features if feature not in discrete_feature +year_feature +['Id']]\n\nprint('Number of Continuous Feature:',len(continuous_features))\n\nhouse_data[continuous_features].head(5)","966a6c0b":"#now lets do data analysis for continuous feature with the help of histograms\nfor feature in continuous_features:\n    data=house_data.copy()\n    \n    data[feature].hist(bins=15)\n    plt.ylabel('count')\n    plt.xlabel(feature)\n    plt.show()","c08679df":"for feature in continuous_features:\n    data=house_data.copy()\n    data[feature]=np.log1p(data[feature])\n    data['SalePrice']=np.log1p(data['SalePrice'])\n    if feature=='SalePrice':\n        pass\n    else:\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()","7ef08415":"for feature in continuous_features:\n    data=house_data.copy()\n    data[feature]=np.log1p(data[feature])\n    data.boxplot(column=feature)\n    plt.ylabel(feature)\n    plt.show()","33a5a4ce":"categorical_features=[feature for feature in house_data.columns if house_data[feature].dtypes=='O']\n\nprint('Number of categorical features:',len(categorical_features))\nhouse_data[categorical_features].head(5)","c05aa443":"for feature in categorical_features:\n    data=house_data.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar(color=['red','orange','green','skyblue','purple','turquoise','blue','darkorange'])\n    plt.show()\n    ","2ab88719":"house_data.head(5)","63ee3663":"cat_features=[feature for feature in house_data.columns if house_data[feature].dtypes=='O']\n\nhouse_data[cat_features].head(5)","8f0b2d83":"# % of missing values in categorical features\npct_miss=house_data[cat_features].isnull().sum()\/len(house_data)*100","7d4c76cf":"#dropping categorical features where missing values is more than half\nmiss_features=pct_miss[pct_miss>70]\n#now we need to drop thest columns \nmiss_features","5d4a0245":"for feature in miss_features.index:\n    house_data.drop([feature],axis=1,inplace=True)","6b79e248":"null_features=[feature for feature in house_data.columns if house_data[feature].isnull().sum().any()==True]\nnull_features","2cda4749":"numerical_features=[feature for feature in null_features if house_data[feature].dtypes!='O']\nhouse_data[numerical_features].isnull().sum()\/len(house_data)*100","6599d5d5":"house_data.head()","930eaefa":"X=house_data.drop(['SalePrice'],axis=1)\ny=house_data['SalePrice']","e06eae05":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)","b7c5496b":"X_train.shape,X_test.shape","4f2780f5":"train=pd.concat([X_train,y_train],axis=1)\ntest=pd.concat([X_test,y_test],axis=1)","e372cac4":"#features with nan values in training set\nnull_features= [features for features in train.columns if train[features].isnull().any()==True]","c11eaf4a":"null_features","91816a83":"null_numerical=[feature for feature in null_features if train[feature].dtypes!='O']\n\nprint('Number of null numerical feature:',len(null_numerical))\n\ntrain[null_numerical].head()","fc6a0f19":"train[null_numerical].isnull().sum()","f2466601":"#replacing nan values in numerical feature\nfor feature in null_numerical:\n    train[feature].fillna(train[feature].median(),inplace=True)\n    \ntrain[null_numerical].isnull().sum()","62b369bb":"train[null_numerical].head()","4608b689":"train.head(5)","28483068":"skew_num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea','SalePrice']\n\nfor feature in skew_num_features:\n    train[feature]=np.log(train[feature])","dcfed513":"train[year_feature].isnull().sum()","77bce998":"train[['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold']].head()","e177323d":"for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n    train[feature]=train['YrSold']-train[feature]","f0dfdb63":"train[['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold']].head()","2df7a4ce":"null_categorical_feature=[feature for feature in null_features if train[feature].dtypes=='O']\n\nprint('number of null categorical features:',len(null_categorical_feature))\ntrain[null_categorical_feature].head()","31198495":"train[null_categorical_feature].isnull().sum()\/len(train)","b62538cf":"#replacing nan values in categorical feature with a new label\nfor feature in null_categorical_feature:\n    mode_value=train[feature].mode()[0]\n    train[feature].fillna(mode_value,inplace=True)\ntrain[null_categorical_feature].isnull().sum()","332f596a":"categorical_features=[feature for feature in train.columns if train[feature].dtypes=='O']","0493db89":"#now we will perform feature label encoding\nfor feature in categorical_features:\n    labels_order=train.groupby(feature)['SalePrice'].mean().sort_values().index\n    labels_order={k:i for i,k in enumerate(labels_order,0)}\n    train[feature]=train[feature].map(labels_order)","f3c1f242":"train.head(5)","81cc5b63":"train.isnull().sum()","ac69afe8":"#featurea with nan values\nnull_features= [features for features in test.columns if test[features].isnull().any()==True]\nnull_features","2408c391":"null_numerical=[feature for feature in null_features if test[feature].dtypes!='O']\n\nprint('Number of null numerical feature:',len(null_numerical))\n\ntest[null_numerical].isnull().sum()","2da8fe95":"#replacing nan values in numerical feature\nfor feature in null_numerical:\n    test[feature].fillna(test[feature].median(),inplace=True)\n    \ntest[null_numerical].isnull().sum()","252ed187":"skew_num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea','SalePrice']\n\nfor feature in skew_num_features:\n    test[feature]=np.log(test[feature])","4bc5c946":"test.head(5)","6f108590":"for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n    test[feature]=test['YrSold']-test[feature]\n\ntest[['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold']].head()","21b4b575":"null_categorical_feature=[feature for feature in null_features if test[feature].dtypes=='O']\n\nprint('number of null categorical features:',len(null_categorical_feature))\n\ntest[null_categorical_feature].head()","4f4115ea":"#replacing nan values in categorical feature with a new label\nfor features in null_categorical_feature:\n    mode_value=test[features].mode()[0]\n    test[features].fillna(mode_value,inplace=True)\n        \ntest[null_categorical_feature].isnull().sum()","2ed0b0be":"categorical_features=[feature for feature in test.columns if test[feature].dtypes=='O']\n\n#now we will perform feature label encoding\nfor feature in categorical_features:\n    labels_order=test.groupby(feature)['SalePrice'].mean().sort_values().index\n    labels_order={k:i for i,k in enumerate(labels_order,0)}\n    test[feature]=test[feature].map(labels_order)","5c0b0009":"pd.set_option('display.max_columns',None)\ntest.head(5)","a7ed7650":"test.isnull().sum()","f2d6fc89":"#lets perform Feature Scaling on train data\nscale_feature=[feature for feature in train.columns if feature not in ['Id','SalePrice']]\n\nfrom sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\ntrain_scaled=scaler.fit_transform(train[scale_feature])","5622f95a":"#lets perform Feature Scaling on test data\ntest_scaled=scaler.transform(test[scale_feature])","0ba075bd":"X=pd.DataFrame(train_scaled,columns=scale_feature)","db3b8e28":"train=pd.concat([X,train['SalePrice'].reset_index(drop=True)],axis=1)","8366a170":"train.head(5)","0dab06c2":"train.isnull().sum()","3a3d11b3":"X1=pd.DataFrame(test_scaled,columns=scale_feature)","360c1f69":"test=pd.concat([X1,test['SalePrice'].reset_index(drop=True)],axis=1)","d4726a67":"test.head(5)","5d037d9b":"test.isnull().sum()","65635695":"#importing libraries to be used for feature selection\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel","19ee3b5f":"X_train=train.drop(['SalePrice'],axis=1)\ny_train=train['SalePrice']","c7dcbf1f":"#now we will use Lasso regression model\n#and use the SelectFromModel this will select the features with non-zero coefficients\nfeature_sel_model = SelectFromModel(Lasso(alpha=0.01,random_state=0))\nfeature_sel_model.fit(X_train, y_train)","1aa0bff3":"#.get_support() will show u which all features are important\nfeature_sel_model.get_support()","ef80e0cb":"# list of the selected features\nselected_feat = X_train.columns[(feature_sel_model.get_support())]\n\nprint('selected features:',len(selected_feat))","9892b93c":"selected_feat","01a54912":"X_train=X_train[selected_feat]","fc923be0":"X_train.head(5)","35c4fe44":"X_test=test[selected_feat]\ny_test=test['SalePrice']","e0aab482":"X_test.head(5)","cdcc9a69":"X_test.isnull().sum()","917fd15a":"from sklearn.ensemble import RandomForestRegressor\nrf_reg=RandomForestRegressor()\nrf_reg.fit(X_train,y_train)","cf02dbbc":"prediction=rf_reg.predict(X_test)","0c4862ba":"from sklearn.metrics import mean_absolute_error,mean_squared_error\nprint('MAE:', mean_absolute_error(y_test, prediction))\nprint('MSE:', mean_squared_error(y_test, prediction))\nprint('RMSE:', np.sqrt(mean_squared_error(y_test, prediction)))","2114fcef":"#test data which is required to generate output submission file\nhouse_test=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","8f92b5d1":"house_test.head(5)","005ee935":"#features with nan values\nnull_features= [features for features in house_test.columns if house_test[features].isnull().any()==True]\nnull_features","00c78292":"null_numerical=[feature for feature in null_features if house_test[feature].dtypes!='O']\n\nprint('Number of null numerical feature:',len(null_numerical))\n\nhouse_test[null_numerical].isnull().sum()","6299eece":"#replacing nan values in numerical feature\nfor feature in null_numerical:\n    house_test[feature].fillna(house_test[feature].median(),inplace=True)\n    \nhouse_test[null_numerical].isnull().sum()","5507353c":"skew_num_features=['LotFrontage', 'LotArea', '1stFlrSF', 'GrLivArea']\n\nfor feature in skew_num_features:\n    house_test[feature]=np.log(house_test[feature])","6c8ea34e":"for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n       \n    house_test[feature]=house_test['YrSold']-house_test[feature]\n\nhouse_test[['YearBuilt','YearRemodAdd','GarageYrBlt','YrSold']].head()","c32c8428":"null_categorical_feature=[feature for feature in null_features if house_test[feature].dtypes=='O']\n\nprint('number of null categorical features:',len(null_categorical_feature))\n\nnull_categorical_feature","af2c4715":"#percentage of missing values in each categorical column\npct=house_test[null_categorical_feature].isnull().sum()\/len(house_test)","2e6efdcf":"miss_feature=pct[pct>0.7]\nmiss_feature.index","5c5c2287":"for feature in miss_feature.index:\n    house_test.drop([feature],inplace=True,axis=1)","f2183eb8":"house_test.head()","7061eda1":"null_feature=[feature for feature in house_test.columns if house_test[feature].isnull().sum().any()==True]\nnull_feature","b534d4bd":"null_categorical_feature=[feature for feature in null_feature if house_test[feature].dtypes=='O']\n#replacing nan values in categorical feature with a new label\nfor feature in null_categorical_feature:\n    mode_value=house_test[feature].mode()[0]\n    house_test[feature]=house_test[feature].fillna(mode_value)","5769726b":"house_test.isnull().sum()","d6411208":"house_test.head()","f8146b90":"categorical_features=[feature for feature in house_test.columns if house_test[feature].dtypes=='O']\n#performing label encoding\nfrom sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nfor feature in categorical_features:\n    house_test[feature]=le.fit_transform(house_test[feature])","cf7c4c8d":"house_test.head(5)","3614c0e8":"house_test_scaled=scaler.transform(house_test[scale_feature])","b3c82d55":"X_house=pd.DataFrame(house_test_scaled,columns=scale_feature)","4d29cbce":"X_house.head(5)","6cb98bdc":"X_house=X_house[selected_feat]","19a41f6a":"X_house.head(5)","d6ff041a":"price_prediction=rf_reg.predict(X_house)","4811d177":"price_prediction","b395be97":"np.exp(price_prediction)","aaedfcd1":"sample=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","c4e1e3b7":"y_test=sample['SalePrice']","647a856c":"print('MAE:', mean_absolute_error(np.log(y_test),price_prediction))\nprint('MSE:', mean_squared_error(np.log(y_test), price_prediction))\nprint('RMSE:', np.sqrt(mean_squared_error(np.log(y_test), price_prediction)))","536e1bbb":"house_test['SalePrice']=np.exp(price_prediction)","106f57ac":"submission=house_test[['Id','SalePrice']]","5c6085ab":"submission.to_csv('.\/submission1.csv',index=False)","e997be95":"# Feature Scaling","1dfa1e0d":"**Missing Values**","ec7179e0":"log normalise skewed Numerical feature which we have seen during our data analysis of continuous feature distribution","befaf4b2":"so we dont have enough null values to drop so we will perform its feature engineering after split","5cdf4cd9":"**featurea with nan values**","e24bfc91":"**Numerical Feature** for test data","f540b857":"no null values but we have to handle ['YearBuilt','YearRemodAdd','GarageYrBlt'] on the basis of year it was sold","7feb907d":"we have log normalised all the features and then plotting a relationship b\/w features and SalePrice","8acf0f96":"# House Prices With Advanced Regression Techniques","065e5b1a":"But before performing all these steps we need to first split our house prices data which we got from train.csv into train and validation data to avoid overfitting and data leakage it is a good practice to split data first so that data doesnt get leaked.\n\nto know more about data leakage refer to this below url\nData Leakage:https:\/\/machinelearningmastery.com\/data-leakage-machine-learning\/","b711c6b6":"**log normalise skewed Numerical feature which we have seen during our data analysis of continuous feature distribution**","4d0f6aa8":"**year features**","a474ebee":"**featurea with nan values**","91c4e8cc":"In this notebook I have performed a solution with all the best practices.\nAnd I have covered life cycle of a data science projects\n\nIn this Problem we have to predict house prices based on various features\n\nTable of Content:\n1. Importing Dataset\n2. Data Analysis\n3. Feature Engineering\n4. Feature Selection\n5. Modelling data\n6. HyperParameter Tuning(if required)\n7. Prediction metrics\n8. Saving the submission file\n\nThis notebook is fully explained and this approach can be used for any regression technique.\n\n**plz upvote and show ur appreciation and comment down if any queries**","fed99a63":"# Importing Dataset","9363ddae":"**performing feature engineering on house test dataset for output**","a1161af4":"Handling categorical feature","b09f3bdf":"**Numerical Feature**","6d32b88b":"Now we will repeat all the steps for Test data set to avoid data leakage","0dcfc470":"**insights**\nSo we can infer from this relationship between null features and dependent variable that null values in feature are also contributing towards SalePrice and even more than non null values in some features so we cant drop them we need fill them.","d2fe80be":"**Categorical Feature**","1960b367":"# Feature Engineering","43d39162":"**Datetime Features**","21c6c754":"# Fitting model to dataset","34c83991":"# Feature Selection","e7ae8336":"**Feature engineering on test data**","81c4a7f8":"**performing feature scaling in house test data**","ecdff848":"**numerical feature for house_test data**","fe12fff4":"now we have converted the year values to numerical values on the basis of YrSold Feature like Built recently or built 47 years ago or remodelled or garage built 47 years ago","663271c0":"**Categorical variable**","5ba673bc":"In feature Engineering we will handle:\n1. numerical missing values\n4. year_features missing values\n3. Categorical missing values\n4. And apply standard scaler to standardise the values of all the features","e68642a5":"**Year Features**","89f0fb29":"**Numerical Features**","a13db512":"So as we can see only few of the features follows gausian distribution while other are skewed distribution\nwe will apply normalization to fix this","54dba1b9":"**Year Features**","13bb3da6":"# Prediction Metrics","7c14ebca":"We can draw insights from the above given graphs that\n1. In MSSubClass type of dwelling which is labled as 60 has the highest average Sale Price\n2. Average Sale Price has exponentially increased for Overall quality and finish of the houses\n3. In Overall Condition the average Sale price is higher for Label 5 which means Average condition of the house\n\nand this is how we can draw insights form all of the graphs","c599992b":"**Continuous Features**","88a9e0ac":"# Exploratory Data Analysis","e134dc4e":"now in Numerical Feature we have two types of variables continuos and discrete\n\n**Discrete Feature**","d9cad0f2":"**Insights**\n* Now what we can deduce from here is that newly built or remodelled houses and newly built garage house has more median Sale Price\n* And overtime the median Sale Price has decreased for houses sold in recent years","6d901f55":"**Categorical features**","6b3e2753":"log normalise skewed Numerical feature which we have seen during our data analysis of continuous feature distribution"}}