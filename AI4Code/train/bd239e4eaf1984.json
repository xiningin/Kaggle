{"cell_type":{"a0fd25bb":"code","ca4acca3":"code","60fd30a9":"code","ca938deb":"code","155128c0":"code","5deef847":"code","a0de126e":"code","93aa0884":"code","704dd96e":"code","98be837d":"code","c34a6dea":"code","a4bfd5de":"code","9f4b0571":"code","0e7cb1e3":"code","117da8e8":"code","cbdaeee0":"code","4e4fc93d":"code","3418c89d":"code","fccce799":"code","e77ef9d8":"code","ef34557e":"code","458c0d19":"code","2490445f":"code","ed697dd0":"code","fc9ac09b":"code","53c7a65a":"code","ae434a2b":"code","b2fab2cb":"code","c89a208f":"code","fe2d7329":"code","06c1a9c0":"markdown","04ddb093":"markdown","1a4e352e":"markdown","d582bb9c":"markdown","8522b2ca":"markdown","84414ee1":"markdown","617edf27":"markdown","afb5254c":"markdown","ce2c7270":"markdown","3f86baaf":"markdown","a22cc01e":"markdown","e7f8fd8c":"markdown"},"source":{"a0fd25bb":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport datetime\n\n# Pretty display for notebooks\n%matplotlib inline","ca4acca3":"# Upload data file into dataframe df\ndf = pd.read_csv(\"..\/input\/Airplane_Crashes_and_Fatalities_Since_1908_DV_03032020.csv\")\n","60fd30a9":"df.head()","ca938deb":"df.info()","155128c0":"# Convert DATE column to datetime format\ndf['DATE'] = pd.to_datetime(df['DATE'])\ndf.info()","5deef847":"df.describe()","a0de126e":"df.describe(include='object')","93aa0884":"df.isnull().sum() # missing data\n","704dd96e":"# Nbr of accident per aircraft type (top 25)\n\nacc_per_ac_type = df['AIRCRAFT_TYPE'].value_counts().head(25)\nacc_per_ac_type.plot(kind='barh', figsize=(12,8), title='Nbr of accidenteds per aircraft type (top 25)', grid=True)\nacc_per_ac_type.head(25)","98be837d":"# Nbr of accidents per airline \/ operator (top 25)\n\nacc_per_operator = df['OPERATOR'].value_counts().head(25)\nacc_per_operator.plot(kind='barh', figsize=(12,8), title='Nbr of fatal accidentes per operator (top 25)', grid=True)\nacc_per_operator.head(25)","c34a6dea":"# Nbr of aviation accidents per year since 1908\ndf['DATE'].groupby(df.DATE.dt.year).agg('count').plot(figsize=(12,8), title='Nbr of aviation fatal accidents per year since 1908', grid=True)","a4bfd5de":"# Nbr of aviation fatalities per year since 1908\ndf['TOTAL_FATALITIES'].groupby(df.DATE.dt.year).agg('sum').plot(figsize=(12,8), title='Nbr of aviation fatalities per year since 1908', grid=True)","9f4b0571":"# Nbr of aviation ground fatalities per year since 1908 - note the sharp peak in 2001, rest in peace those who died on Sept 11 2001 \ndf['GROUND_CASUALTIES'].groupby(df.DATE.dt.year).agg('sum').plot(figsize=(12,8), title='Nbr of aviation ground fatalities per year since 1908', grid=True)","0e7cb1e3":"# Accidents per year of the top 10 accidented operators\n\ntop10_acc_operator = acc_per_operator.head(10)\n\nplt.figure(figsize=(32,12))\nplt.xlabel ('YEAR')\nplt.ylabel('NUMBER OF ACCIDENTS')\n\ndf_accidents = df[['DATE', 'OPERATOR']]\n\nfor op in top10_acc_operator.index:\n  \n  df_accidents_py = df_accidents[df_accidents.OPERATOR == op].groupby(df.DATE.dt.year).agg('count')\n  plt.plot(df_accidents_py.index, df_accidents_py.DATE, linewidth=0.5, marker='*')\n\nplt.legend(top10_acc_operator.index, loc='upper left')\nplt.show()\n","117da8e8":"df_summary = df['SUMMARY_OF_EVENTS']\ndf_summary","cbdaeee0":"import spacy\nimport string\n#from spacy.lang.en.stop_words import STOP_WORDS\n#from spacy.lang.en import English\n\nnlp = spacy.load(\"en_core_web_sm\")\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\nprint(\"Nbr. of stop words: %d\" %len(stop_words))","4e4fc93d":"punctuation = string.punctuation\npunctuation","3418c89d":"# Create a tokenizer function for pre-processing each accident summary\n\ndef spacy_tokenizer(sentence):\n    # Create token object\n    mytokens = nlp(sentence)\n    #mytokens = parser(sentence)\n\n    # Lemmatize each token and convert it into lowercase\n    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n\n    # Remove stop words and punctuations\n    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuation ]\n\n    # return preprocessed list of tokens\n    return mytokens","fccce799":"test_sentence = \"While attempting to land in rain and fog, the aircraft ran out of fuel, stalled and crashed at Lunghwa field.\"\ntokens = spacy_tokenizer(test_sentence)\ntokens","e77ef9d8":"# Create a new column in the dataframe and assign the tokens for each accident\n\ntokens = []\n\nfor x in df.SUMMARY_OF_EVENTS:\n  tokens.append(spacy_tokenizer(str(x)))\n  \ndf['TOKENS'] = tokens","ef34557e":"df['TOKENS'].head(20)","458c0d19":"# Create a dictionary with pairs of words and their frequencies\n# to count how relevant each of these words are\n\nhash_map = {}\n\nfor tokens in df['TOKENS']:\n  for word in tokens:\n    if word in hash_map:\n      hash_map[word] = hash_map[word] + 1\n    else:\n      hash_map[word] = 1\n\n# Order the dictionary by highest values first\n#hash_map = {k: v for k, v in sorted(hash_map.items(), key=lambda item: item[1], reverse=True)}\n\n# Search for the frequency of specific relevant words\nwords_list = ['rain', 'fog', 'wind', 'snow', 'turbulence', 'storm', 'clear', \n              'midair', 'sea', 'ocean', 'mountain', 'hill', 'building', \n              'residential', 'hijack', 'missile', 'failure', 'malfunction', \n              'explosion', 'collision', 'overload', 'takeoff', 'climb',\n              'cruise', 'descend', 'landing']\n\nfor w in words_list:\n  print(w + \" : \" + str(hash_map[w]))","2490445f":"# Create a mini-dataframe with weather conditions stats\nweather_words = {'rain', 'fog', 'wind', 'snow', 'turbulence', 'storm', 'clear'}\nweather_df = []\n\nfor w in weather_words:\n  print(w + \" : \" + str(hash_map[w]))\n  weather_df.append([w, hash_map[w]])\n\nweather_df = pd.DataFrame(weather_df, columns=['WEATHER_CONDITION', 'NBR_ACCIDENTS'])\nweather_df","ed697dd0":"# Plot a pie chart with % values\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 8,8\n\nfig1, ax1 = plt.subplots()\nax1.pie(weather_df.NBR_ACCIDENTS, labels=weather_df.WEATHER_CONDITION, autopct='%1.1f%%', startangle=180)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.title('Percentage of accidents in specific weather conditions')\nplt.show()","fc9ac09b":"# Create a mini-dataframe with phase of the flight stats\nflight_phase_words = {'takeoff', 'climb', 'cruise', 'descend', 'landing'}\nflight_phase_df = []\n\nfor f in flight_phase_words:\n  print(f + \" : \" + str(hash_map[f]))\n  flight_phase_df.append([f, hash_map[f]])\n  \nflight_phase_df = pd.DataFrame(flight_phase_df, columns=['FLIGHT_PHASE', 'NBR_ACCIDENTS'])\nflight_phase_df","53c7a65a":"# Plot a pie chart with % values\n\nfig2, ax2 = plt.subplots()\nax2.pie(flight_phase_df.NBR_ACCIDENTS, labels=flight_phase_df.FLIGHT_PHASE, autopct='%1.1f%%', startangle=90)\nax2.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.title('Percentage of accidents in each phase of the flight')\nplt.show()","ae434a2b":"# Create a mini-dataframe with crash zone stats\n# Some words are counted together: \n#   sea & ocean --> sea\n#   montain & hill --> mountain\n#   building & residential --> residential\n\ncrash_zone_words = {'midair', 'sea', 'mountain', 'residential'}\ncrash_zone_df = []\n\nfor z in crash_zone_words:\n  print(z + \" : \" + str(hash_map[z]))\n  if (z == 'sea'):\n    crash_zone_df.append([z, hash_map[z] + hash_map['ocean']])\n  elif (z == 'mountain'):\n    crash_zone_df.append([z, hash_map[z] + hash_map['hill']])\n  elif (z == 'residential'):\n    crash_zone_df.append([z, hash_map[z] + hash_map['building']])\n  else:\n    crash_zone_df.append([z, hash_map[z]])\n\n  \ncrash_zone_df = pd.DataFrame(crash_zone_df, columns=['CRASH_ZONE', 'NBR_ACCIDENTS'])\ncrash_zone_df","b2fab2cb":"# Plot a pie chart with % values\n\nfig3, ax3 = plt.subplots()\nax3.pie(crash_zone_df.NBR_ACCIDENTS, labels=crash_zone_df.CRASH_ZONE, autopct='%1.1f%%', startangle=0)\nax3.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.title('Percentage of accidents per crash zone')\nplt.show()","c89a208f":"# Create a mini-dataframe with crash reason stats\ncrash_reason_words = {'hijack', 'missile', 'failure', 'malfunction', 'explosion', 'overload'}\ncrash_reason_df = []\n\nfor r in crash_reason_words:\n  print(r + \" : \" + str(hash_map[r]))\n  crash_reason_df.append([r, hash_map[r]])\n  \ncrash_reason_df = pd.DataFrame(crash_reason_df, columns=['CRASH_REASON', 'NBR_ACCIDENTS'])\ncrash_reason_df","fe2d7329":"# Pie chart with % values\n\nfig4, ax4 = plt.subplots()\nax4.pie(crash_reason_df.NBR_ACCIDENTS, labels=crash_reason_df.CRASH_REASON, autopct='%1.1f%%')\nax3.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.title('Percentage of accidents per crash reason')\nplt.show()","06c1a9c0":"## Introduction","04ddb093":"This is my very first notebook in Kaggle, so my main motivation is to learn how Kaggle works. But at the same time, I have been learning Python for data science and machine learning for just a few months, so if you are looking for expert analysis, look elsewhere :-)\n\nBut hey, don't go just yet. The dataset used is the commonly available *\"Airplane_Crashes_and_Fatalities_Since_1908.csv\"* which I have improved by adding new accident data up to Feb 2020, and by visually analysing and improving it with a spreadsheet. This has uncovered evidence that was otherwise hidden under errors and misspellings. So given you will go through it in less than 3 minutes, I reckon it will be worth browsing it.","1a4e352e":"## Data preparation","d582bb9c":"### Phase of flight","8522b2ca":"Naturally, the language is way more complicated than this and the current analysis is veeeery basic, not accounting for example for composed words such as 'emergency landing', 'shot down', 'midair collision', or 'en route', nor differentiating betweeen 'engine failure' and 'structural failure', let alone some more specialized words such as 'nosedive' and 'stall.\n\nBut all that for the next day.","84414ee1":"### Crash zone","617edf27":"From here, time and inspiration permiting, I have some ideas to dig deeper:\n\n    - combine the dataset with new aircraft accident data with no casualties (the dataset this analysis is based on includes only accidents with casualties) - from there a model to predict survivors is a must.\n\n    - further work can be done to refine the data so that things like 737-xyz are aggregated as a single 737 aircraft type  (whether that has any scientific interest I am not sure).\n    \n    - whilst there is already plenty of work out there on causes of accidents and the like, applying some NLP processing to the SUMMARY_OF_EVENTS column of the dataset and drafting some charts from the results will surely yield some interesting insights too.","afb5254c":"## Some more descriptive stats\n### Weather conditions","ce2c7270":"## So what now??","3f86baaf":"## Descriptive stats\nSome basic stats about the most accidented aircraft types and operators. Note how after revising the data some key players such as the UK Royal Air Force have come to light.\n\nThe plot of ground casualties reminds us right away of the mad times we live in.","a22cc01e":"## Analysis of the SUMMARY_OF_EVENTS column with NLP spaCy\n\nThere is valuable information in the summary column about the circumstances surrounding the accident, including the phase of the flight when the accident occurred, the weahter conditions, or if the aircraft was shot down by a missile. So here is a first attempt at processing this information and drawing some conclusions.","e7f8fd8c":"### Crash reason"}}