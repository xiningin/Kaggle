{"cell_type":{"f6ba627b":"code","bd5763bb":"code","af766e59":"code","57fd9fe7":"code","4b837e33":"code","cc3a3794":"code","6bc102fb":"code","f3e5f2c5":"code","3cb85530":"code","c5f626ee":"code","7dca4cd0":"code","261aad8d":"code","5ccbf72a":"code","8e16c1ed":"code","d9bf4a9c":"code","eca892e1":"code","b3f74856":"code","f9588e27":"code","355f3f1c":"code","140a30b5":"code","358ad987":"code","622a4cca":"code","8aaeb232":"code","e3ba1ad7":"code","6f37fcf8":"code","2ff27cb7":"code","d59544e6":"code","72e3ec6d":"code","d9e793fa":"code","634e1fa8":"code","a78ac1bd":"code","fc4b475b":"code","88510e68":"code","431afccb":"code","091a9e12":"code","53e4616b":"code","d5b2e5b2":"code","8dcf1252":"code","54f0e0c8":"code","4b371c9f":"code","e3fb1f4e":"code","6f24fed1":"code","103e88f9":"code","fc0a7132":"code","2afaaf21":"code","11ed676c":"code","9dffb884":"code","bc022795":"code","fc8f6db1":"code","45cc304a":"code","12fb3426":"code","bb45590f":"code","6073d91a":"code","bebeb1d9":"code","9c1eb9ce":"code","6cbf900f":"code","c00009a7":"code","a909460c":"code","5fe848d7":"code","fb6a410e":"code","307de747":"code","e7cbfb31":"code","e1242476":"code","c37f2e2a":"code","7e02648d":"code","b3f27d5f":"code","55dced08":"code","766d1f18":"code","babdd4e3":"code","0b7d9907":"code","76840446":"code","f7fd7430":"code","82b95e88":"code","dd56cd3d":"code","0f294f6f":"code","2ddcd133":"code","e67d0265":"code","031ba480":"code","f8659282":"code","a1f4eed0":"code","1861ca9d":"code","9a5acddd":"code","a1d3d357":"markdown","9bdddee6":"markdown","d6054a73":"markdown","71b642f8":"markdown","f57ab7a8":"markdown","6efa6ab2":"markdown","4b8517d1":"markdown","267b4287":"markdown","5f68112a":"markdown","73ea4c10":"markdown","94882fad":"markdown","60ca5a77":"markdown","751efce7":"markdown","791bf3f3":"markdown","0e13ee8a":"markdown","bfd400e8":"markdown","1e2e698c":"markdown","71686072":"markdown","7b9ddd32":"markdown","80d805da":"markdown","c0933d0d":"markdown","fb57e3e5":"markdown","deed5280":"markdown","f784965f":"markdown","ab7d227d":"markdown","486392f5":"markdown","f23bbb18":"markdown","3e6cb791":"markdown","63900e22":"markdown","bff4d484":"markdown","4052fe1b":"markdown","23b74da8":"markdown","a6460cb9":"markdown","116ded1c":"markdown","58754b8b":"markdown","82768f93":"markdown","7cfe45b9":"markdown","4909091f":"markdown","b97b1859":"markdown","ae02312a":"markdown","fb27713f":"markdown","06f5c83f":"markdown","14fbb512":"markdown","d8ed2fe9":"markdown","92871ac4":"markdown","e95476ca":"markdown","57649a40":"markdown","9174c302":"markdown","4066657c":"markdown","c11f38f8":"markdown","1058aae9":"markdown","9f29d809":"markdown","6b51419e":"markdown","9ba5642d":"markdown","0969504d":"markdown","91cf1a60":"markdown","2731c822":"markdown","ba168974":"markdown","da19af83":"markdown","a7f65e14":"markdown","41e9ff23":"markdown","84d40272":"markdown","9c629b25":"markdown","d0e6af87":"markdown"},"source":{"f6ba627b":"#libraries\nimport numpy as np \nimport pandas as pd \nimport os\nimport json\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')\nimport lightgbm as lgb\nimport xgboost as xgb\nimport time\nimport datetime\nfrom PIL import Image\nfrom wordcloud import WordCloud\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nimport gc\nfrom catboost import CatBoostClassifier\nfrom tqdm import tqdm_notebook\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom functools import partial\npd.set_option('max_colwidth', 500)\npd.set_option('max_columns', 500)\npd.set_option('max_rows', 100)\nimport os\nimport scipy as sp\nfrom math import sqrt\nfrom collections import Counter\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.ensemble import RandomForestClassifier\nimport langdetect\nimport eli5\nfrom IPython.display import display \n\nfrom sklearn.metrics import cohen_kappa_score\ndef kappa(y_true, y_pred):\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')","bd5763bb":"breeds = pd.read_csv('..\/input\/breed_labels.csv')\ncolors = pd.read_csv('..\/input\/color_labels.csv')\nstates = pd.read_csv('..\/input\/state_labels.csv')\n\ntrain = pd.read_csv('..\/input\/train\/train.csv')\ntest = pd.read_csv('..\/input\/test\/test.csv')\nsub = pd.read_csv('..\/input\/test\/sample_submission.csv')\n\ntrain['dataset_type'] = 'train'\ntest['dataset_type'] = 'test'\nall_data = pd.concat([train, test])","af766e59":"print(os.listdir(\"..\/input\"))","57fd9fe7":"train.drop('Description', axis=1).head()","4b837e33":"train.info()","cc3a3794":"train['AdoptionSpeed'].value_counts().sort_index().plot('barh', color='teal');\nplt.title('Adoption speed classes counts');","6bc102fb":"plt.figure(figsize=(14, 6));\ng = sns.countplot(x='AdoptionSpeed', data=all_data.loc[all_data['dataset_type'] == 'train'])\nplt.title('Adoption speed classes rates');\nax=g.axes #annotate axis = seaborn axis\nfor p in ax.patches:\n     ax.annotate(f\"{p.get_height() \/ train.shape[0]:.2f}%\", (p.get_x() + p.get_width() \/ 2., p.get_height()),\n         ha='center', va='center', fontsize=11, color='gray', rotation=0, xytext=(0, 10),\n         textcoords='offset points')  ","f3e5f2c5":"all_data['Type'] = all_data['Type'].apply(lambda x: 'Dog' if x == 1 else 'Cat')\nplt.figure(figsize=(10, 6));\nsns.countplot(x='dataset_type', data=all_data, hue='Type');\nplt.title('Number of cats and dogs in train and test data');","3cb85530":"main_count = train['AdoptionSpeed'].value_counts(normalize=True).sort_index()\ndef prepare_plot_dict(df, col, main_count):\n    main_count = dict(main_count)\n    plot_dict = {}\n    for i in df[col].unique():\n        val_count = dict(df.loc[df[col] == i, 'AdoptionSpeed'].value_counts().sort_index())\n\n        for k, v in main_count.items():\n            if k in val_count:\n                plot_dict[val_count[k]] = ((val_count[k] \/ sum(val_count.values())) \/ main_count[k]) * 100 - 100\n            else:\n                plot_dict[0] = 0\n\n    return plot_dict\n\ndef make_count_plot(df, x, hue='AdoptionSpeed', title='', main_count=main_count):\n    # plt.figure(figsize=(18, 8));\n    g = sns.countplot(x=x, data=df, hue=hue);\n    plt.title(f'AdoptionSpeed {title}');\n    ax = g.axes\n\n    plot_dict = prepare_plot_dict(df, x, main_count)\n\n    for p in ax.patches:\n        h = p.get_height() if str(p.get_height()) != 'nan' else 0\n        text = f\"{plot_dict[h]:.0f}%\" if plot_dict[h] < 0 else f\"+{plot_dict[h]:.0f}%\"\n        ax.annotate(text, (p.get_x() + p.get_width() \/ 2., h),\n             ha='center', va='center', fontsize=11, color='green' if plot_dict[h] > 0 else 'red', rotation=0, xytext=(0, 10),\n             textcoords='offset points')  ","c5f626ee":"plt.figure(figsize=(18, 8));\nmake_count_plot(df=all_data.loc[all_data['dataset_type'] == 'train'], x='Type', title='by pet Type')","7dca4cd0":"fig, ax = plt.subplots(figsize = (16, 12))\nplt.subplot(1, 2, 1)\ntext_cat = ' '.join(all_data.loc[all_data['Type'] == 'Cat', 'Name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white',\n                      width=1200, height=1000).generate(text_cat)\nplt.imshow(wordcloud)\nplt.title('Top cat names')\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\ntext_dog = ' '.join(all_data.loc[all_data['Type'] == 'Dog', 'Name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white',\n                      width=1200, height=1000).generate(text_dog)\nplt.imshow(wordcloud)\nplt.title('Top dog names')\nplt.axis(\"off\")\n\nplt.show()","261aad8d":"print('Most popular pet names and AdoptionSpeed')\nfor n in train['Name'].value_counts().index[:5]:\n    print(n)\n    print(train.loc[train['Name'] == n, 'AdoptionSpeed'].value_counts().sort_index())\n    print('')","5ccbf72a":"train['Name'] = train['Name'].fillna('Unnamed')\ntest['Name'] = test['Name'].fillna('Unnamed')\nall_data['Name'] = all_data['Name'].fillna('Unnamed')\n\ntrain['No_name'] = 0\ntrain.loc[train['Name'] == 'Unnamed', 'No_name'] = 1\ntest['No_name'] = 0\ntest.loc[test['Name'] == 'Unnamed', 'No_name'] = 1\nall_data['No_name'] = 0\nall_data.loc[all_data['Name'] == 'Unnamed', 'No_name'] = 1\n\nprint(f\"Rate of unnamed pets in train data: {train['No_name'].sum() * 100 \/ train['No_name'].shape[0]:.4f}%.\")\nprint(f\"Rate of unnamed pets in test data: {test['No_name'].sum() * 100 \/ test['No_name'].shape[0]:.4f}%.\")","8e16c1ed":"pd.crosstab(train['No_name'], train['AdoptionSpeed'], normalize='index')","d9bf4a9c":"plt.figure(figsize=(18, 8));\nmake_count_plot(df=all_data.loc[all_data['dataset_type'] == 'train'], x='No_name', title='and having a name')","eca892e1":"all_data[all_data['Name'].apply(lambda x: len(str(x))) == 3]['Name'].value_counts().tail()","b3f74856":"all_data[all_data['Name'].apply(lambda x: len(str(x))) < 3]['Name'].unique()","f9588e27":"fig, ax = plt.subplots(figsize = (16, 6))\nplt.subplot(1, 2, 1)\nplt.title('Distribution of pets age');\ntrain['Age'].plot('hist', label='train');\ntest['Age'].plot('hist', label='test');\nplt.legend();\n\nplt.subplot(1, 2, 2)\nplt.title('Distribution of pets age (log)');\nnp.log1p(train['Age']).plot('hist', label='train');\nnp.log1p(test['Age']).plot('hist', label='test');\nplt.legend();","355f3f1c":"train['Age'].value_counts().head(10)","140a30b5":"plt.figure(figsize=(10, 6));\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and age');","358ad987":"data = []\nfor a in range(5):\n    df = train.loc[train['AdoptionSpeed'] == a]\n\n    data.append(go.Scatter(\n        x = df['Age'].value_counts().sort_index().index,\n        y = df['Age'].value_counts().sort_index().values,\n        name = str(a)\n    ))\nlayout = go.Layout(dict(title = \"AdoptionSpeed trends by Age\",\n                  xaxis = dict(title = 'Age (months)'),\n                  yaxis = dict(title = 'Counts'),\n                  )\n                  )\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","622a4cca":"train['Pure_breed'] = 0\ntrain.loc[train['Breed2'] == 0, 'Pure_breed'] = 1\ntest['Pure_breed'] = 0\ntest.loc[test['Breed2'] == 0, 'Pure_breed'] = 1\nall_data['Pure_breed'] = 0\nall_data.loc[all_data['Breed2'] == 0, 'Pure_breed'] = 1\n\nprint(f\"Rate of pure breed pets in train data: {train['Pure_breed'].sum() * 100 \/ train['Pure_breed'].shape[0]:.4f}%.\")\nprint(f\"Rate of pure breed pets in test data: {test['Pure_breed'].sum() * 100 \/ test['Pure_breed'].shape[0]:.4f}%.\")","8aaeb232":"def plot_four_graphs(col='', main_title='', dataset_title=''):\n    plt.figure(figsize=(20, 12));\n    plt.subplot(2, 2, 1)\n    make_count_plot(df=train, x=col, title=f'and {main_title}')\n\n    plt.subplot(2, 2, 2)\n    sns.countplot(x='dataset_type', data=all_data, hue=col);\n    plt.title(dataset_title);\n\n    plt.subplot(2, 2, 3)\n    make_count_plot(df=train.loc[train['Type'] == 1], x=col, title=f'and {main_title} for dogs')\n\n    plt.subplot(2, 2, 4)\n    make_count_plot(df=train.loc[train['Type'] == 2], x=col, title=f'and {main_title} for cats')\n    \nplot_four_graphs(col='Pure_breed', main_title='having pure breed', dataset_title='Number of pets by pure\/not-pure breed in train and test data')","e3ba1ad7":"breeds_dict = {k: v for k, v in zip(breeds['BreedID'], breeds['BreedName'])}","6f37fcf8":"train['Breed1_name'] = train['Breed1'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else 'Unknown')\ntrain['Breed2_name'] = train['Breed2'].apply(lambda x: '_'.join(breeds_dict[x]) if x in breeds_dict else '-')\n\ntest['Breed1_name'] = test['Breed1'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else 'Unknown')\ntest['Breed2_name'] = test['Breed2'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else '-')\n\nall_data['Breed1_name'] = all_data['Breed1'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else 'Unknown')\nall_data['Breed2_name'] = all_data['Breed2'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else '-')","2ff27cb7":"fig, ax = plt.subplots(figsize = (20, 18))\nplt.subplot(2, 2, 1)\ntext_cat1 = ' '.join(all_data.loc[all_data['Type'] == 'Cat', 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text_cat1)\nplt.imshow(wordcloud)\nplt.title('Top cat breed1')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 2)\ntext_dog1 = ' '.join(all_data.loc[all_data['Type'] == 'Dog', 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text_dog1)\nplt.imshow(wordcloud)\nplt.title('Top dog breed1')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 3)\ntext_cat2 = ' '.join(all_data.loc[all_data['Type'] == 'Cat', 'Breed2_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text_cat2)\nplt.imshow(wordcloud)\nplt.title('Top cat breed1')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 4)\ntext_dog2 = ' '.join(all_data.loc[all_data['Type'] == 'Dog', 'Breed2_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text_dog2)\nplt.imshow(wordcloud)\nplt.title('Top dog breed2')\nplt.axis(\"off\")\nplt.show()","d59544e6":"(all_data['Breed1_name'] + '__' + all_data['Breed2_name']).value_counts().head(15)","72e3ec6d":"plt.figure(figsize=(18, 6));\nplt.subplot(1, 2, 1)\nmake_count_plot(df=train, x='Gender', title='and gender')\n\nplt.subplot(1, 2, 2)\nsns.countplot(x='dataset_type', data=all_data, hue='Gender');\nplt.title('Number of pets by gender in train and test data');","d9e793fa":"sns.factorplot('Type', col='Gender', data=all_data, kind='count', hue='dataset_type');\nplt.subplots_adjust(top=0.8)\nplt.suptitle('Count of cats and dogs in train and test set by gender');","634e1fa8":"colors_dict = {k: v for k, v in zip(colors['ColorID'], colors['ColorName'])}\ntrain['Color1_name'] = train['Color1'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\ntrain['Color2_name'] = train['Color2'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\ntrain['Color3_name'] = train['Color3'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\n\ntest['Color1_name'] = test['Color1'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\ntest['Color2_name'] = test['Color2'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\ntest['Color3_name'] = test['Color3'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\n\nall_data['Color1_name'] = all_data['Color1'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\nall_data['Color2_name'] = all_data['Color2'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\nall_data['Color3_name'] = all_data['Color3'].apply(lambda x: colors_dict[x] if x in colors_dict else '')","a78ac1bd":"def make_factor_plot(df, x, col, title, main_count=main_count, hue=None, ann=True, col_wrap=4):\n\n    if hue:\n        g = sns.factorplot(col, col=x, data=df, kind='count', col_wrap=col_wrap, hue=hue);\n    else:\n        g = sns.factorplot(col, col=x, data=df, kind='count', col_wrap=col_wrap);\n    plt.subplots_adjust(top=0.9);\n    plt.suptitle(title);\n    ax = g.axes\n    plot_dict = prepare_plot_dict(df, x, main_count)\n    if ann:\n        for a in ax:\n            for p in a.patches:\n                text = f\"{plot_dict[p.get_height()]:.0f}%\" if plot_dict[p.get_height()] < 0 else f\"+{plot_dict[p.get_height()]:.0f}%\"\n                a.annotate(text, (p.get_x() + p.get_width() \/ 2., p.get_height()),\n                     ha='center', va='center', fontsize=11, color='green' if plot_dict[p.get_height()] > 0 else 'red', rotation=0, xytext=(0, 10),\n                     textcoords='offset points')  ","fc4b475b":"sns.factorplot('dataset_type', col='Type', data=all_data, kind='count', hue='Color1_name', palette=['Black', 'Brown', '#FFFDD0', 'Gray', 'Gold', 'White', 'Yellow']);\nplt.subplots_adjust(top=0.8)\nplt.suptitle('Counts of pets in datasets by main color');","88510e68":"make_factor_plot(df=train, x='Color1_name', col='AdoptionSpeed', title='Counts of pets by main color and Adoption Speed')","431afccb":"train['full_color'] = (train['Color1_name'] + '__' + train['Color2_name'] + '__' + train['Color3_name']).str.replace('__', '')\ntest['full_color'] = (test['Color1_name'] + '__' + test['Color2_name'] + '__' + test['Color3_name']).str.replace('__', '')\nall_data['full_color'] = (all_data['Color1_name'] + '__' + all_data['Color2_name'] + '__' + all_data['Color3_name']).str.replace('__', '')\n\nmake_factor_plot(df=train.loc[train['full_color'].isin(list(train['full_color'].value_counts().index)[:12])], x='full_color', col='AdoptionSpeed', title='Counts of pets by color and Adoption Speed')","091a9e12":"gender_dict = {1: 'Male', 2: 'Female', 3: 'Mixed'}\nfor i in all_data['Type'].unique():\n    for j in all_data['Gender'].unique():\n        df = all_data.loc[(all_data['Type'] == i) & (all_data['Gender'] == j)]\n        top_colors = list(df['full_color'].value_counts().index)[:5]\n        j = gender_dict[j]\n        print(f\"Most popular colors of {j} {i}s: {' '.join(top_colors)}\")","53e4616b":"plot_four_graphs(col='MaturitySize', main_title='MaturitySize', dataset_title='Number of pets by MaturitySize in train and test data')","d5b2e5b2":"make_factor_plot(df=all_data, x='MaturitySize', col='Type', title='Count of cats and dogs in train and test set by MaturitySize', hue='dataset_type', ann=False)","8dcf1252":"images = [i.split('-')[0] for i in os.listdir('..\/input\/train_images\/')]\nsize_dict = {1: 'Small', 2: 'Medium', 3: 'Large', 4: 'Extra Large'}\nfor t in all_data['Type'].unique():\n    for m in all_data['MaturitySize'].unique():\n        df = all_data.loc[(all_data['Type'] == t) & (all_data['MaturitySize'] == m)]\n        top_breeds = list(df['Breed1_name'].value_counts().index)[:5]\n        m = size_dict[m]\n        print(f\"Most common Breeds of {m} {t}s:\")\n        \n        fig = plt.figure(figsize=(25, 4))\n        \n        for i, breed in enumerate(top_breeds):\n            # excluding pets without pictures\n            b_df = df.loc[(df['Breed1_name'] == breed) & (df['PetID'].isin(images)), 'PetID']\n            if len(b_df) > 1:\n                pet_id = b_df.values[1]\n            else:\n                pet_id = b_df.values[0]\n            ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n\n            im = Image.open(\"..\/input\/train_images\/\" + pet_id + '-1.jpg')\n            plt.imshow(im)\n            ax.set_title(f'Breed: {breed}')\n        plt.show();","54f0e0c8":"plot_four_graphs(col='FurLength', main_title='FurLength', dataset_title='Number of pets by FurLength in train and test data')","4b371c9f":"fig, ax = plt.subplots(figsize = (20, 18))\nplt.subplot(2, 2, 1)\ntext_cat1 = ' '.join(all_data.loc[(all_data['FurLength'] == 1) & (all_data['Type'] == 'Cat'), 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text_cat1)\nplt.imshow(wordcloud)\nplt.title('Top cat breed1 with short fur')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 2)\ntext_dog1 = ' '.join(all_data.loc[(all_data['FurLength'] == 1) & (all_data['Type'] == 'Dog'), 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text_dog1)\nplt.imshow(wordcloud)\nplt.title('Top dog breed1 with short fur')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 3)\ntext_cat2 = ' '.join(all_data.loc[(all_data['FurLength'] == 2) & (all_data['Type'] == 'Cat'), 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text_cat2)\nplt.imshow(wordcloud)\nplt.title('Top cat breed1 with medium fur')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 4)\ntext_dog2 = ' '.join(all_data.loc[(all_data['FurLength'] == 2) & (all_data['Type'] == 'Dog'), 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text_dog2)\nplt.imshow(wordcloud)\nplt.title('Top dog breed2 with medium fur')\nplt.axis(\"off\")\nplt.show()","e3fb1f4e":"c = 0\nstrange_pets = []\nfor i, row in all_data[all_data['Breed1_name'].str.contains('air')].iterrows():\n    if 'Short' in row['Breed1_name'] and row['FurLength'] == 1:\n        pass\n    elif 'Medium' in row['Breed1_name'] and row['FurLength'] == 2:\n        pass\n    elif 'Long' in row['Breed1_name'] and row['FurLength'] == 3:\n        pass\n    else:\n        c += 1\n        strange_pets.append((row['PetID'], row['Breed1_name'], row['FurLength']))\n        \nprint(f\"There are {c} pets whose breed and fur length don't match\")","6f24fed1":"strange_pets = [p for p in strange_pets if p[0] in images]\nfig = plt.figure(figsize=(25, 12))\nfur_dict = {1: 'Short', 2: 'Medium', 3: 'long'}\nfor i, s in enumerate(random.sample(strange_pets, 12)):\n    ax = fig.add_subplot(3, 4, i+1, xticks=[], yticks=[])\n\n    im = Image.open(\"..\/input\/train_images\/\" + s[0] + '-1.jpg')\n    plt.imshow(im)\n    ax.set_title(f'Breed: {s[1]} \\n Fur length: {fur_dict[s[2]]}')\nplt.show();","103e88f9":"plt.figure(figsize=(20, 12));\nplt.subplot(2, 2, 1)\nmake_count_plot(df=train, x='Vaccinated', title='Vaccinated')\nplt.xticks([0, 1, 2], ['Yes', 'No', 'Not sure']);\nplt.title('AdoptionSpeed and Vaccinated');\n\nplt.subplot(2, 2, 2)\nmake_count_plot(df=train, x='Dewormed', title='Dewormed')\nplt.xticks([0, 1, 2], ['Yes', 'No', 'Not sure']);\nplt.title('AdoptionSpeed and Dewormed');\n\nplt.subplot(2, 2, 3)\nmake_count_plot(df=train, x='Sterilized', title='Sterilized')\nplt.xticks([0, 1, 2], ['Yes', 'No', 'Not sure']);\nplt.title('AdoptionSpeed and Sterilized');\n\nplt.subplot(2, 2, 4)\nmake_count_plot(df=train, x='Health', title='Health')\nplt.xticks([0, 1, 2], ['Healthy', 'Minor Injury', 'Serious Injury']);\nplt.title('AdoptionSpeed and Health');\n\nplt.suptitle('Adoption Speed and health conditions');","fc0a7132":"train['health'] = train['Vaccinated'].astype(str) + '_' + train['Dewormed'].astype(str) + '_' + train['Sterilized'].astype(str) + '_' + train['Health'].astype(str)\ntest['health'] = test['Vaccinated'].astype(str) + '_' + test['Dewormed'].astype(str) + '_' + test['Sterilized'].astype(str) + '_' + test['Health'].astype(str)\n\n\nmake_factor_plot(df=train.loc[train['health'].isin(list(train.health.value_counts().index[:5]))], x='health', col='AdoptionSpeed', title='Counts of pets by main health conditions and Adoption Speed')","2afaaf21":"plt.figure(figsize=(20, 16))\nplt.subplot(3, 2, 1)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", data=train);\nplt.title('Age distribution by Age');\nplt.subplot(3, 2, 3)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Vaccinated\", data=train);\nplt.title('Age distribution by Age and Vaccinated');\nplt.subplot(3, 2, 4)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Dewormed\", data=train);\nplt.title('Age distribution by Age and Dewormed');\nplt.subplot(3, 2, 5)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Sterilized\", data=train);\nplt.title('Age distribution by Age and Sterilized');\nplt.subplot(3, 2, 6)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Health\", data=train);\nplt.title('Age distribution by Age and Health');","11ed676c":"train.loc[train['Quantity'] > 11][['Name', 'Description', 'Quantity', 'AdoptionSpeed']].head(10)","9dffb884":"train['Quantity'].value_counts().head(10)","bc022795":"train['Quantity_short'] = train['Quantity'].apply(lambda x: x if x <= 5 else 6)\ntest['Quantity_short'] = test['Quantity'].apply(lambda x: x if x <= 5 else 6)\nall_data['Quantity_short'] = all_data['Quantity'].apply(lambda x: x if x <= 5 else 6)\nplot_four_graphs(col='Quantity_short', main_title='Quantity_short', dataset_title='Number of pets by Quantity_short in train and test data')","fc8f6db1":"train['Free'] = train['Fee'].apply(lambda x: 'Free' if x == 0 else 'Not Free')\ntest['Free'] = test['Fee'].apply(lambda x: 'Free' if x == 0 else 'Not Free')\nall_data['Free'] = all_data['Fee'].apply(lambda x: 'Free' if x == 0 else 'Not Free')\nplot_four_graphs(col='Free', main_title='Free', dataset_title='Number of pets by Free in train and test data')","45cc304a":"all_data.sort_values('Fee', ascending=False)[['Name', 'Description', 'Fee', 'AdoptionSpeed', 'dataset_type']].head(10)","12fb3426":"plt.figure(figsize=(16, 6));\nplt.subplot(1, 2, 1)\nplt.hist(train.loc[train['Fee'] < 400, 'Fee']);\nplt.title('Distribution of fees lower than 400');\n\nplt.subplot(1, 2, 2)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Fee\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and Fee');","bb45590f":"plt.figure(figsize=(16, 10));\nsns.scatterplot(x=\"Fee\", y=\"Quantity\", hue=\"Type\",data=all_data);\nplt.title('Quantity of pets and Fee');","6073d91a":"states_dict = {k: v for k, v in zip(states['StateID'], states['StateName'])}\ntrain['State_name'] = train['State'].apply(lambda x: '_'.join(states_dict[x].split()) if x in states_dict else 'Unknown')\ntest['State_name'] = test['State'].apply(lambda x: '_'.join(states_dict[x].split()) if x in states_dict else 'Unknown')\nall_data['State_name'] = all_data['State'].apply(lambda x: '_'.join(states_dict[x].split()) if x in states_dict else 'Unknown')","bebeb1d9":"all_data['State_name'].value_counts(normalize=True).head()","9c1eb9ce":"make_factor_plot(df=train.loc[train['State_name'].isin(list(train.State_name.value_counts().index[:3]))], x='State_name', col='AdoptionSpeed', title='Counts of pets by states and Adoption Speed')","6cbf900f":"all_data['RescuerID'].value_counts().head()","c00009a7":"make_factor_plot(df=train.loc[train['RescuerID'].isin(list(train.RescuerID.value_counts().index[:5]))], x='RescuerID', col='AdoptionSpeed', title='Counts of pets by rescuers and Adoption Speed', col_wrap=5)","a909460c":"train['VideoAmt'].value_counts()","5fe848d7":"print(F'Maximum amount of photos in {train[\"PhotoAmt\"].max()}')\ntrain['PhotoAmt'].value_counts().head()","fb6a410e":"make_factor_plot(df=train.loc[train['PhotoAmt'].isin(list(train.PhotoAmt.value_counts().index[:5]))], x='PhotoAmt', col='AdoptionSpeed', title='Counts of pets by PhotoAmt and Adoption Speed', col_wrap=5)","307de747":"plt.figure(figsize=(16, 6));\nplt.subplot(1, 2, 1)\nplt.hist(train['PhotoAmt']);\nplt.title('Distribution of PhotoAmt');\n\nplt.subplot(1, 2, 2)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"PhotoAmt\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and PhotoAmt');","e7cbfb31":"fig, ax = plt.subplots(figsize = (12, 8))\ntext_cat = ' '.join(all_data['Description'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white',\n                      width=1200, height=1000).generate(text_cat)\nplt.imshow(wordcloud)\nplt.title('Top words in description');\nplt.axis(\"off\");","e1242476":"tokenizer = TweetTokenizer()\nvectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\n\nvectorizer.fit(all_data['Description'].fillna('').values)\nX_train = vectorizer.transform(train['Description'].fillna(''))\n\nrf = RandomForestClassifier(n_estimators=20)\nrf.fit(X_train, train['AdoptionSpeed'])","c37f2e2a":"for i in range(5):\n    print(f'Example of Adoption speed {i}')\n    text = train.loc[train['AdoptionSpeed'] == i, 'Description'].values[0]\n    print(text)\n    display(eli5.show_prediction(rf, doc=text, vec=vectorizer, top=10))","7e02648d":"train['Description'] = train['Description'].fillna('')\ntest['Description'] = test['Description'].fillna('')\nall_data['Description'] = all_data['Description'].fillna('')\n\ntrain['desc_length'] = train['Description'].apply(lambda x: len(x))\ntrain['desc_words'] = train['Description'].apply(lambda x: len(x.split()))\n\ntest['desc_length'] = test['Description'].apply(lambda x: len(x))\ntest['desc_words'] = test['Description'].apply(lambda x: len(x.split()))\n\nall_data['desc_length'] = all_data['Description'].apply(lambda x: len(x))\nall_data['desc_words'] = all_data['Description'].apply(lambda x: len(x.split()))","b3f27d5f":"plt.figure(figsize=(16, 6));\nplt.subplot(1, 2, 1)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"desc_length\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and description length');\n\nplt.subplot(1, 2, 2)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"desc_words\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and count of words in description');","55dced08":"sentiment_dict = {}\nfor filename in os.listdir('..\/input\/train_sentiment\/'):\n    with open('..\/input\/train_sentiment\/' + filename, 'r') as f:\n        sentiment = json.load(f)\n    pet_id = filename.split('.')[0]\n    sentiment_dict[pet_id] = {}\n    sentiment_dict[pet_id]['magnitude'] = sentiment['documentSentiment']['magnitude']\n    sentiment_dict[pet_id]['score'] = sentiment['documentSentiment']['score']\n    sentiment_dict[pet_id]['language'] = sentiment['language']\n\nfor filename in os.listdir('..\/input\/test_sentiment\/'):\n    with open('..\/input\/test_sentiment\/' + filename, 'r') as f:\n        sentiment = json.load(f)\n    pet_id = filename.split('.')[0]\n    sentiment_dict[pet_id] = {}\n    sentiment_dict[pet_id]['magnitude'] = sentiment['documentSentiment']['magnitude']\n    sentiment_dict[pet_id]['score'] = sentiment['documentSentiment']['score']\n    sentiment_dict[pet_id]['language'] = sentiment['language']","766d1f18":"train['lang'] = train['PetID'].apply(lambda x: sentiment_dict[x]['language'] if x in sentiment_dict else 'no')\ntrain['magnitude'] = train['PetID'].apply(lambda x: sentiment_dict[x]['magnitude'] if x in sentiment_dict else 0)\ntrain['score'] = train['PetID'].apply(lambda x: sentiment_dict[x]['score'] if x in sentiment_dict else 0)\n\ntest['lang'] = test['PetID'].apply(lambda x: sentiment_dict[x]['language'] if x in sentiment_dict else 'no')\ntest['magnitude'] = test['PetID'].apply(lambda x: sentiment_dict[x]['magnitude'] if x in sentiment_dict else 0)\ntest['score'] = test['PetID'].apply(lambda x: sentiment_dict[x]['score'] if x in sentiment_dict else 0)\n\nall_data['lang'] = all_data['PetID'].apply(lambda x: sentiment_dict[x]['language'] if x in sentiment_dict else 'no')\nall_data['magnitude'] = all_data['PetID'].apply(lambda x: sentiment_dict[x]['magnitude'] if x in sentiment_dict else 0)\nall_data['score'] = all_data['PetID'].apply(lambda x: sentiment_dict[x]['score'] if x in sentiment_dict else 0)","babdd4e3":"plot_four_graphs(col='lang', main_title='lang', dataset_title='Number of pets by lang in train and test data')","0b7d9907":"plt.figure(figsize=(16, 6));\nplt.subplot(1, 2, 1)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"score\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and score');\n\nplt.subplot(1, 2, 2)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"magnitude\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and magnitude of sentiment');","76840446":"cols_to_use = ['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'No_name', 'Pure_breed', 'health', 'Free', 'desc_length', 'desc_words', 'score', 'magnitude']\ntrain = train[[col for col in cols_to_use if col in train.columns]]\ntest = test[[col for col in cols_to_use if col in test.columns]]","f7fd7430":"cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'State', 'RescuerID',\n       'No_name', 'Pure_breed', 'health', 'Free']","82b95e88":"more_cols = []\nfor col1 in cat_cols:\n    for col2 in cat_cols:\n        if col1 != col2 and col1 not in ['RescuerID', 'State'] and col2 not in ['RescuerID', 'State']:\n            train[col1 + '_' + col2] = train[col1].astype(str) + '_' + train[col2].astype(str)\n            test[col1 + '_' + col2] = test[col1].astype(str) + '_' + test[col2].astype(str)\n            more_cols.append(col1 + '_' + col2)\n            \ncat_cols = cat_cols + more_cols","dd56cd3d":"%%time\nindexer = {}\nfor col in cat_cols:\n    # print(col)\n    _, indexer[col] = pd.factorize(train[col].astype(str))\n    \nfor col in tqdm_notebook(cat_cols):\n    # print(col)\n    train[col] = indexer[col].get_indexer(train[col].astype(str))\n    test[col] = indexer[col].get_indexer(test[col].astype(str))\n","0f294f6f":"y = train['AdoptionSpeed']\ntrain = train.drop(['AdoptionSpeed'], axis=1)","2ddcd133":"n_fold = 5\nfolds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=15)","e67d0265":"def train_model(X=train, X_test=test, y=y, params=None, folds=folds, model_type='lgb', plot_feature_importance=False, averaging='usual', make_oof=False):\n    result_dict = {}\n    if make_oof:\n        oof = np.zeros(len(X))\n    prediction = np.zeros(len(X_test))\n    scores = []\n    feature_importance = pd.DataFrame()\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        gc.collect()\n        print('Fold', fold_n + 1, 'started at', time.ctime())\n        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        \n        \n        if model_type == 'lgb':\n            train_data = lgb.Dataset(X_train, label=y_train, categorical_feature = cat_cols)\n            valid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature = cat_cols)\n            \n            model = lgb.train(params,\n                    train_data,\n                    num_boost_round=2000,\n                    valid_sets = [train_data, valid_data],\n                    verbose_eval=100,\n                    early_stopping_rounds = 200)\n\n            del train_data, valid_data\n            \n            y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration).argmax(1)\n            del X_valid\n            gc.collect()\n            y_pred = model.predict(X_test, num_iteration=model.best_iteration).argmax(1)\n            \n        if model_type == 'xgb':\n            train_data = xgb.DMatrix(data=X_train, label=y_train)\n            valid_data = xgb.DMatrix(data=X_valid, label=y_valid)\n\n            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n            y_pred_valid = model.predict(xgb.DMatrix(X_valid), ntree_limit=model.best_ntree_limit)\n            y_pred = model.predict(xgb.DMatrix(X_test), ntree_limit=model.best_ntree_limit)\n            \n        if model_type == 'lcv':\n            model = LogisticRegressionCV(scoring='neg_log_loss', cv=3, multi_class='multinomial')\n            model.fit(X_train, y_train)\n\n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test)\n            \n        if model_type == 'cat':\n            model = CatBoostClassifier(iterations=20000,  loss_function='MultiClass', **params)\n            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n\n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test).reshape(-1,)\n        \n        if make_oof:\n            oof[valid_index] = y_pred_valid.reshape(-1,)\n            \n        scores.append(kappa(y_valid, y_pred_valid))\n        print('Fold kappa:', kappa(y_valid, y_pred_valid))\n        print('')\n        \n        if averaging == 'usual':\n            prediction += y_pred\n        elif averaging == 'rank':\n            prediction += pd.Series(y_pred).rank().values\n        \n        if model_type == 'lgb':\n            # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = X.columns\n            fold_importance[\"importance\"] = model.feature_importance()\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    prediction \/= n_fold\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    \n    if model_type == 'lgb':\n        \n        if plot_feature_importance:\n            feature_importance[\"importance\"] \/= n_fold\n            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n                by=\"importance\", ascending=False)[:50].index\n\n            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n            plt.figure(figsize=(16, 12));\n            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n            plt.title('LGB Features (avg over folds)');\n            \n            result_dict['feature_importance'] = feature_importance\n            \n    result_dict['prediction'] = prediction\n    if make_oof:\n        result_dict['oof'] = oof\n    \n    return result_dict","031ba480":"params = {'num_leaves': 128,\n        #  'min_data_in_leaf': 60,\n         'objective': 'multiclass',\n         'max_depth': -1,\n         'learning_rate': 0.05,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 3,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n        #  \"lambda_l1\": 0.1,\n         # \"lambda_l2\": 0.1,\n         \"random_state\": 42,          \n         \"verbosity\": -1,\n         \"num_class\": 5}","f8659282":"result_dict_lgb = train_model(X=train, X_test=test, y=y, params=params, model_type='lgb', plot_feature_importance=True, make_oof=True)","a1f4eed0":"xgb_params = {'eta': 0.01, 'max_depth': 10, 'subsample': 0.9, 'colsample_bytree': 0.9, \n          'objective': 'multi:softmax', 'eval_metric': 'merror', 'silent': True, 'nthread': 4, 'num_class': 5}\nresult_dict_xgb = train_model(params=xgb_params, model_type='xgb', make_oof=True)","1861ca9d":"prediction = (result_dict_lgb['prediction'] + result_dict_xgb['prediction']) \/ 2\nsubmission = pd.DataFrame({'PetID': sub.PetID, 'AdoptionSpeed': [int(i) for i in prediction]})\nsubmission.head()","9a5acddd":"submission.to_csv('submission.csv', index=False)","a1d3d357":"### Name\nI don't really think that names are important in adoption, but let's see.\n\nAt first let's look at most common names.","9bdddee6":"We can see that most pets are young - maybe after the birth. Also there a lot of pets with an age equal to multiples of 12 - I think than owners didn't bother with the exact age.","d6054a73":"Sometimes there is a huge amount of pets in some advertisements! But at the same time sometimes text and the quantity don't match. For example:\n\n    Pancho and Tita are 2 adorable, playful kittens. They can be shy at first but once they get to know you they are the sweetest pets anyone could ask for. Available for adoption now. They are very, very close so we are looking for someone who can take them both.\n    \n Obvously there are only two kittens, but the quantity is 12 for some reason.\n \n One thing worth noticing that sometimes all these pet are adopted which is great!\n \n For the sake of plotting I'll create a new variable, where 6 pets in one advertizement will the the max amount.","71b642f8":"### VideoAmt","f57ab7a8":"I think that we could create a new feature, showing that name is meaningless - pets with these names could have less success in adoption.","6efa6ab2":"And here are names with 1 or 2 characters...","4b8517d1":"It seems that quantity has little to do with adoption speed. This is good, it means that abandoned cats\/dogs with kittens\/puppies have chances of being adopted! Though it seems that single cats have somewhat higher chances that single dogs.","267b4287":"## Main data exploration","5f68112a":"* We have almost 15 thousands dogs and cats in the dataset;\n* Main dataset contains all important information about pets: age, breed, color, some characteristics and other things;\n* Desctiptions were analyzed using Google's Natural Language API providing sentiments and entities. I suppose we could do a similar thing ourselves;\n* There are photos of some pets;\n* Some meta-information was extracted from images and we can use it;\n* There are separate files with labels for breeds, colors and states;\n\nLet's start with the main dataset.\n\nI have also created a full dataset by combining train and test data. This is done purely for more convenient visualization. Column \"dataset_type\" shows which dataset the data belongs to.","73ea4c10":"* Healthy, dewormed and non-sterilized pets tend to be adopted faster!\n* Completely healthy pets are... more likely to be not adopted! I suppose that means that a lot of people pay attention to other characteristics;\n* And healthy pets with no information (not sure value) also tend to be adopted less frequently. Maybe people prefer having information, even if it is negative;","94882fad":"### Gender\n 1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets","60ca5a77":"### MaturitySize\nSize at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)","751efce7":"Well, English is the most common language by far, so language feature will hardly help.","791bf3f3":"### State","0e13ee8a":"* We can see that young pets are adopted quite fast and most of them are adopted;\n* Most pets are less than 4 months old with a huge spike at 2 months;\n* It seems that a lot of people don't input exact age and write age in years (or multiples of 12);\n* It could make sense to create some binary variables based on age;","bfd400e8":"### Colors","1e2e698c":"#### \"Bad\" names\n\nI have noticed that shorter names tend to be meaningless. Here is an example of some names with 3 characters.","71686072":"## General information\n\nThis kernel is dedicated to EDA of PetFinder.my Adoption Prediction challenge as well as feature engineering and modelling.\n\n![](https:\/\/i.imgur.com\/rvSWCYO.png)\n(a screenshot of the PetFinder.my site)","7b9ddd32":"* It is interesting that pets with high fee tend to be adopted quite fast! Maybe people prefer to pay for \"better\" pets: healthy, trained and so on;\n* Most pets are given for free and fees are usually lower than 100 $;\n* Fees for dogs tend to be higher, though these are rare cases anyway.","80d805da":"Intetestingly top-2 and top-3 states have lower rates of adoption.","c0933d0d":"It seems that non-pure breed pets tend to be adopted more and faster, especially cats.\n\nLet's look at the breeds themselves","fb57e3e5":"### Sentiment\nWe have run each pet profile's description through Google's Natural Language API, providing analysis on sentiment and key entities. You may optionally utilize this supplementary information for your pet description analysis. There are some descriptions that the API could not analyze. As such, there are fewer sentiment files than there are rows in the dataset. ","deed5280":"We can see that there are some differences based on color, but the number of pets in most colors isn't very high, so this could be due to randomness.","f784965f":"Wow! The resquer with the highest amount of resqued pets has the best adoption rate! On the other hand the third one has the worst rate :(","ab7d227d":"We can see that the rate of dogs in train dataset is higher that in test set. But I don't think the difference is seriuos.","486392f5":"### Description\n\nDescription contains a lot of important information, let' analyze it!","f23bbb18":"* Almost all pets are healthy! Pets with minor injuries are rare and sadly they aren't adopted well. Number of pets with serious injuries is negligible.\n* It is interesting that people prefer non-vaccinated pets. Maybe they want to bring pets to vets themselves...\n* People also prefer non-sterilized pets! Maybe they want puppies\/kittens :)\n* Quite important is the fact that when there is no information about health condition, the probability of not being adopted is much higher;\n\nLet's have a look at most popular health conditions.","3e6cb791":"### Fee\nOne of interesting features is adoption fee. Some pets can be gotten for free, adopting some required paying a certain amount.","63900e22":"### FurLength\n\n (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)","bff4d484":"### Basic model\n\nThere are much more interesting things in the dataset and I'm going to explore them, but for now let's build a simple model as a baseline.","4052fe1b":"Interestingly pets with short text in ads are adopted quickly. Or maybe longer descriptions mean more problems in the pets, therefore adoption speed is lower?","23b74da8":"Less than 10% of pets don't have names, but they have a higher possibility of not being adopted.","a6460cb9":"It seems that male pets are adopted faster than female. Having no information about the gender really decreases chances.","116ded1c":"It seems that almost one thousand pets have mismatch in breeds and fur lengths. Let's see!","58754b8b":"### Age","82768f93":"#### Comparison of rates\n\nFrom here on I'll compare not only counts of pets in different categories, but also compate adoption speed rates with base ones.\n\nThis is how it works:\n* As we saw earlier the base rate of pets with Adoption speed 0 is 410 \/ 14993 = 0.027;\n* Now look at the next graph: there are 6861 cats in train dataset and 240 of them have Adoption Speed 0. So the rate is 240 \/ 6861 = 0.035;\n* 0.035 \/ 0027 = 1.2792 so cats have 27, 92% more chances to have Adoption Speed 0;","7cfe45b9":"Cute names! :) I like some of them!\n\nIt is worth noticing some things:\n* Often we see normal pet names like \"Mimi\", \"Angel\" and so on;\n* Quite often people write simply who is there for adoption: \"Kitten\", \"Puppies\";\n* Vety often the color of pet is written, sometimes gender;\n* And it seems that sometimes names can be strange or there is some info written instead of the name;\n\nOne more thing to notice is that some pets don't have names. Let's see whether this is important","4909091f":"Some words\/phrases seem to be useful, but it seems that different adoption speed classes could have similar important words...","b97b1859":"Quite interesting:\n* We can see that maturity size isn't very important. Medium sized pets are most common and they have slightly more chances to be not adopted;\n* There are almost no Extra Large pets. I hope it means that their owners like them and there is no need for them to be adopted :)\n* I wanted to gave a look at different pets, so I showed examples of pictures of most common breeds for each maturity size of cats and dogs;\n* I think not all data is entirely correct: sometimes short haired cats have breed with \"medium hair\", not sure that all breeds are entirely correct. Some photoes have bad quality;","ae02312a":"It seems that not all values of these features are really breeds. Sometimes people simply write that the dogs has a mixed breed, cats often are described as domestic with certain hair length.\n\nNow let's have a look at the combinations of breed names.","fb27713f":"### Quantity\nSometimes there are several pets in one advertisement.","06f5c83f":"### Target: Adoption speed\n\n* 0 - Pet was adopted on the same day as it was listed.\n* 1 - Pet was adopted between 1 and 7 days (1st week) after being listed.\n* 2 - Pet was adopted between 8 and 30 days (1st month) after being listed.\n* 3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.\n* 4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days). ","14fbb512":"* We can see that most of the pets have short fur and long fur is the least common;\n* Pets with long hair tend to have a higher chance of being adopted. Though it could be because of randomness due to low count;\n\nAs I said earlier, some breed have hair length in the text, let's check these values!","d8ed2fe9":"## Data overview\n\nLet's have a quick look at the data first!","92871ac4":"Everybody lies!\n\nSometimes breed is more correct, sometimes fur length... I suppose we could create a feature showing whether breed and fur length match.","e95476ca":"Top-5 resquers managed a lot of pets!\nI wonder whether these are individual people or organizations. Let's have a look at them.","57649a40":"It seems that most dogs aren't pure breeds, but mixed breeds! My first assumption was wrong.\n\nSometimes people write \"mixed breed\" in the first fiels, sometimes in both, and sometimes main breed is in the first field and is marked as mixed breed in the second field.\n\nI think we can create new features based on this information. And later we can verify the hair length of pets.","9174c302":"Hm. In most cases there are no videos at all. Sometimes there is one video, more than one video is quite rare. We don't have videos and considering a huge disbalance in values I'm not sure this variable will be useful.","4066657c":"### Breeds\nThere is a main breed of the pet and secondary if relevant.\n\nAt first let's see whether having secondary breed influences adoption speed.","c11f38f8":"Pets can have up to 30 photos! That's a lot! But I'm not convinced that amount of photoes has any real influence.","1058aae9":"It seems that the lower is the magnitude of score, the faster pets are adopted.","9f29d809":"#### No name","6b51419e":"### Type\n1 - Dog, 2 - Cat","9ba5642d":"### Rescuer\nWe have unique hashes for resquers.","0969504d":"There are too many similar general words like \"cat\". We need to go deeper.\n\nLet's use ELI5 library for prediction explanation. I'll fit a basic vectorizer on desctriptions and build a simple Random Forest model. Then we will look at words which caused certain labels to be predicted.","91cf1a60":"### PhotoAmt","2731c822":"Sadly I don't know anything about Malaysia\u2019s states, so I can only say that top three states account for ~90% of ads. Let's have a look at them.","ba168974":"Most pets are free and it seems that asking for a fee slightly desreased the chance of adoption. Also free cats are adopted faster than free dogs","da19af83":"### Health\n\nThere are four features showing health of the pets:\n\n* Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n* Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n* Sterilized - Pet has been spayed \/ neutered (1 = Yes, 2 = No, 3 = Not Sure)\n* Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n\nI think that these features are very important - most people would prefer a healthy pet. While sterilization isn't the main concern, having healty and dewormed pet should have a great importance. Let's see whether I'm right!","a7f65e14":"It seems that fees and pet quantity have inversely proportional relationship. The less pets, the higher is the fee. I suppose these single pets are better trained and prepared than most others.","41e9ff23":"We can see that most common colors are black and brown. Interesting to notice that there are almost no gray or yellow dogs :)\n\nNow let's see whether colors influence adoption speed","84d40272":"## Naive multiclass LGB","9c629b25":"We can see that some pets were adopted immediately, but these are rare cases: maybe someone wanted to adopt any pet, or the pet was lucky to be seen by person, who wanted a similar pet.\nA lot of pets aren't adopted at all, which is quite sad :( I hope our models and analysis will help them to find their home!\n\nIt is nice that a lot of pets are adopted within a first week of being listed!\n\nOne more interesting thing is that the classes have a linear relationship - the higher the number, the worse situation is. So it could be possible to build not only multiclass classification, but also regression.","d0e6af87":"We can see that cats are more likely to be adopted early than dogs and overall the percentage of not adopted cats is lower. Does this mean people prefer cats? Or maybe this dataset is small and could contain bias.\nOn the other hand more dogs are adopted after several months."}}