{"cell_type":{"0cf060ff":"code","24b457b4":"code","18602bce":"code","e016e816":"code","1ab4bbf3":"code","55266add":"code","f31b9214":"code","d33e2443":"code","c6d6c7ff":"code","40ecbf6d":"code","78d5b825":"code","68f022d6":"code","894bc564":"code","29058bf0":"code","40146939":"code","c6820e4f":"code","f6790050":"code","8ea309e8":"code","cd421c27":"code","91fd7165":"code","346a10a9":"code","0b69ba60":"code","b635e5fe":"code","8bb3e287":"code","424b6149":"code","e473c954":"code","e3593cda":"code","955a5709":"markdown","de4b34f5":"markdown","fe051f06":"markdown","ad4b0238":"markdown","bab12368":"markdown","b9dd8915":"markdown","6d1a72c2":"markdown","5ba3afca":"markdown","971acc4f":"markdown","1eb84fcb":"markdown"},"source":{"0cf060ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","24b457b4":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_train.info()","18602bce":"df_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_test.info()","e016e816":"df_gender_sumbission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ndf_gender_sumbission.info()","1ab4bbf3":"all(df_test['PassengerId'] == df_gender_sumbission['PassengerId'])","55266add":"df_train.head()","f31b9214":"to_be_dropped_cols = ['Name', 'Age', 'Ticket', 'Cabin']\n\ndf_train.drop(columns=to_be_dropped_cols, inplace=True)\ndf_test.drop(columns=to_be_dropped_cols, inplace=True)\n\nprint(df_train.columns)\nprint(df_test.columns)","d33e2443":"df_train.tail()","c6d6c7ff":"df_train['Survived'].value_counts()","40ecbf6d":"df_train['Pclass'].value_counts()","78d5b825":"df_train['Sex'].value_counts()","68f022d6":"df_train['Embarked'].value_counts()","894bc564":"df_train[df_train.isna().any(axis=1)]","29058bf0":"df_train.dropna(axis=0, how='any', inplace=True)","40146939":"df_test[df_test.isna().any(axis=1)]","c6820e4f":"gb = df_test.groupby(['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'])['Fare'].mean()\ngb[(3, 'male', 0, 0, 'S')]","f6790050":"df_test.loc[152, 'Fare'] = gb[(3, 'male', 0, 0, 'S')]","8ea309e8":"df_test[df_test.isna().any(axis=1)]","cd421c27":"df_test.loc[152]","91fd7165":"df_train.info()","346a10a9":"feature_cols = ['Sex', 'Embarked', 'Pclass', 'SibSp', 'Parch', 'Fare']\ntarget_col = ['Survived']\n\nX_train = df_train[feature_cols]\ny_train = df_train[target_col].values.ravel() # to be 1-D array\n\nX_test = df_test[feature_cols]\ny_test = df_gender_sumbission[target_col].values.ravel() # to be 1-D array","0b69ba60":"# Features Transformation\nfrom sklearn.compose import make_column_transformer # Instance, easier\nfrom sklearn.preprocessing import OneHotEncoder     # 1st\nfrom sklearn.preprocessing import StandardScaler    # 2nd\n\n# Classification Algorithm\nfrom sklearn.neural_network import MLPClassifier # Multi-Layer Perceptron Classifier (with default Parameters)\n\n# Making Pipeline\nfrom sklearn.pipeline import make_pipeline\n\n# Cross-Validation Application\nfrom sklearn.model_selection import cross_validate # cv=5 (KFold=5)\n\n# Metrics\nfrom sklearn.metrics import classification_report","b635e5fe":"# Step 1: Features Transformation\ncol_tran_instance = make_column_transformer(\n    (OneHotEncoder(), ['Sex', 'Embarked']), # 1st: Object Dtype to OneHotEncoded Value\n    remainder=StandardScaler() # 2nd: Standard Scaling for Remainders\n)\n\n# Step 2: Classifier Pipelining\nclassifier = make_pipeline(\n    col_tran_instance, # 1st\n    MLPClassifier(max_iter=1000, random_state=42) # 2nd\n)\n\n# Step 3: CV Application\ncv_results = cross_validate(\n    estimator=classifier,\n    X=X_train,\n    y=y_train,\n    scoring='accuracy',\n    cv=5,\n    verbose=1, # display something\n    return_estimator=True # return trained estimators for each split\n)","8bb3e287":"cv_results","424b6149":"# Step 4: Testing\nselected_estimator = cv_results['estimator'][-1]\ny_pred = selected_estimator.predict(X_test)","e473c954":"# Step 5: Evaluation\nprint(classification_report(y_test, y_pred))","e3593cda":"output = pd.DataFrame({'PassengerId': df_test.PassengerId, 'Survived': y_pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","955a5709":"<h1> Take a Look at Datasets","de4b34f5":"<h3> Replace Nan in df_test","fe051f06":"<h1> Data Preparation","ad4b0238":"<h3> Drop 'Name', 'Age', 'Ticket' and 'Cabin' columns","bab12368":"<h3> Value Counts","b9dd8915":"<h1> Submission","6d1a72c2":"Ref: http:\/\/rstudio-pubs-static.s3.amazonaws.com\/24969_894d890964fd4308ab537bfde1f784d2.html\n\nData description:\n\nSurvival - Survival (0 = No; 1 = Yes). Not included in test.csv file.\nPclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\nName - Name\nSex - Sex\nAge - Age\nSibsp - Number of Siblings\/Spouses Aboard\nParch - Number of Parents\/Children Aboard\nTicket - Ticket Number\nFare - Passenger Fare\nCabin - Cabin\nEmbarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)","5ba3afca":"<h3> DataFrame Displaying","971acc4f":"<h3> Drop NaN rows","1eb84fcb":"<h3> X_train, y_train then X_test, y_test"}}