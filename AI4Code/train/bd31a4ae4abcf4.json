{"cell_type":{"0f49e925":"code","a4e0e284":"code","c7ee5ca4":"code","a82b53de":"code","c88f2f9c":"code","7ab3146d":"code","efb97d3a":"code","552aaa20":"code","7db605ab":"code","67c9b18b":"code","9fcd1b83":"code","656b23ef":"code","479372d0":"code","12ffbd7e":"code","42058996":"code","e73f919f":"code","d05d4959":"code","ee5088f8":"code","8926b047":"code","5028b4d1":"code","ca2c184f":"code","62c6acad":"code","1911eab1":"code","b402ac3f":"code","892251e2":"code","91e67ce0":"code","4d431f7a":"code","1f8cac07":"code","25fd8c02":"code","8ed77280":"code","d56d76bc":"code","e1fdd4c2":"code","d70a1e85":"code","9c0b4224":"code","53477a29":"code","4feb2543":"code","65c2704b":"code","a22f3b55":"code","210f68f0":"code","2488a3de":"code","638af2c8":"code","c8098344":"code","870af194":"code","de0d502b":"code","1c142189":"code","f0c99971":"code","08e8e821":"code","acc5684e":"code","8ec5bfc9":"code","3bb20264":"code","8d5a63df":"code","0c1293a9":"code","e07f6166":"code","4baa84bc":"code","6fa9ae01":"code","f2d7e0ad":"code","f4434220":"code","c16309fc":"code","be9897dd":"code","5df2a297":"code","0a8e5716":"code","d3ae7e6f":"code","b808a9b0":"markdown","39d0c0ac":"markdown","557f9eb4":"markdown","1ae92a1f":"markdown","e45e32b7":"markdown","5dda84d6":"markdown","59540f98":"markdown","fdd987e8":"markdown","e315a836":"markdown","0edec0ed":"markdown","7cd3fe70":"markdown","c4b3ec4e":"markdown","7cdaa304":"markdown","a54865f5":"markdown","9ed61a27":"markdown","f65c0c81":"markdown","2868b533":"markdown","1529deb3":"markdown","40ddf770":"markdown","e4046fec":"markdown","f07a10d3":"markdown","f7fde8d7":"markdown","7ab615e5":"markdown","59651a00":"markdown","9a44e11b":"markdown","481e301f":"markdown","0a151f3a":"markdown","e4f0083c":"markdown","7768e3c4":"markdown","9ce9c0a5":"markdown","a134273a":"markdown","3c76fb52":"markdown","d08d2677":"markdown","fb04b28c":"markdown","70ade260":"markdown","7b108c1b":"markdown","3d8339c0":"markdown","17b273ac":"markdown","d69dd0f0":"markdown","26555be3":"markdown","cd271348":"markdown","6cf478b4":"markdown","e34274bd":"markdown","e2d46ea5":"markdown","cd11bffc":"markdown","61800024":"markdown","c0571955":"markdown","92a15fc5":"markdown","754a52e2":"markdown","1a87b1d6":"markdown","c424f3cd":"markdown","b824ab1b":"markdown","2ca211ee":"markdown","5ace5a81":"markdown","601ec66a":"markdown","e391c87e":"markdown","1e2a3e62":"markdown","6db8cc68":"markdown","773900a7":"markdown","78d4da7f":"markdown","ffb7ee02":"markdown","23375a14":"markdown","edfc9aa5":"markdown","b51850f9":"markdown"},"source":{"0f49e925":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style('whitegrid')","a4e0e284":"# Creating empty dataframe with all the needed columns\nbooks = pd.DataFrame(columns = pd.read_csv('..\/input\/goodreads-book-datasets-10m\/book1000k-1100k.csv', index_col = 'Id').columns)\nbooks","c7ee5ca4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if \"_\" not in filename:\n            books = pd.concat([books, pd.read_csv(os.path.join(dirname, filename), index_col = 'Id')])\n            print(os.path.join(dirname, filename), 'OK')","a82b53de":"books.sort_index(inplace = True)\nbooks.head(3)","c88f2f9c":"books.info()","7ab3146d":"books['Name'].nunique()","efb97d3a":"books[books['Name'].duplicated(keep = False)].sort_values('Name')","552aaa20":"books[books.duplicated(keep = False)]","7db605ab":"# Droping duplicates\nbooks.drop_duplicates(inplace = True)","67c9b18b":"plt.figure(figsize = (12,6))\npopular_names = sns.barplot(books[~books[['Name', 'Authors']].duplicated()]['Name'].value_counts().head(20).index, books[~books[['Name', 'Authors']].duplicated()]['Name'].value_counts().head(20).values)\npopular_names.set_xticklabels(popular_names.get_xticklabels(), rotation=90)\npopular_names.set_xlabel('Book name')\npopular_names.set_ylabel('Number of books')","9fcd1b83":"books[~books[['Name', 'Authors']].duplicated()]['Name'].value_counts().head(20)","656b23ef":"# Checking number of unique authors is dataset\nbooks['Authors'].nunique()","479372d0":"books.groupby('Authors')['Name'].count().sort_values(ascending = False).head(20)","12ffbd7e":"# Let's take a look on missing values, maybe those books are problematic and can be removed\nbooks[books['ISBN'].isnull()]","42058996":"books['Rating'].describe()","e73f919f":"sns.distplot(books['Rating'], bins = 15, kde = False)","d05d4959":"books['PublishYear'] = books['PublishYear'].astype('int')\nbooks['PublishMonth'] = books['PublishMonth'].astype('int')\nbooks['PublishDay'] = books['PublishDay'].astype('int')","ee5088f8":"# Looking for descriptive statistics\nbooks[['PublishYear', 'PublishMonth', 'PublishDay']].describe()","8926b047":"# Replacing day and month\nbooks['PublishMonth'], books['PublishDay'] = books['PublishDay'], books['PublishMonth']","5028b4d1":"# Looking into years\nbooks['PublishYear'].unique()","ca2c184f":"books[(books['PublishYear'] < 1400) | (books['PublishYear'] > 2020)]['Name'].count()","62c6acad":"# In details\nbooks[(books['PublishYear'] < 1400) | (books['PublishYear'] > 2020)]","1911eab1":"# Removing books with errors in years\nbooks.drop((books[(books['PublishYear'] < 1800) | (books['PublishYear'] > 2020)].index).tolist(), inplace = True)","b402ac3f":"# Checking missing values in Publisher column\nbooks[books['Publisher'].isnull()].head(10)","892251e2":"# How many unique published are there?\nbooks['Publisher'].nunique()","91e67ce0":"# Which publisher issued the biggest variety of books?\nbooks['Publisher'].value_counts().head(10)","4d431f7a":"books.head(3)","1f8cac07":"books['RatingDistTotal'] = books['RatingDistTotal'].apply(lambda rating: rating.split(':')[1]).astype('int')\nbooks['RatingDist1'] = books['RatingDist1'].apply(lambda rating: rating.split(':')[1]).astype('int')\nbooks['RatingDist2'] = books['RatingDist2'].apply(lambda rating: rating.split(':')[1]).astype('int')\nbooks['RatingDist3'] = books['RatingDist3'].apply(lambda rating: rating.split(':')[1]).astype('int')\nbooks['RatingDist4'] = books['RatingDist4'].apply(lambda rating: rating.split(':')[1]).astype('int')\nbooks['RatingDist5'] = books['RatingDist5'].apply(lambda rating: rating.split(':')[1]).astype('int')","25fd8c02":"books[['RatingDistTotal', 'RatingDist1', 'RatingDist2', 'RatingDist3', 'RatingDist4', 'RatingDist5']].describe()","8ed77280":"#Changing data type\nbooks['CountsOfReview'] = books['CountsOfReview'].astype('int')","d56d76bc":"books['CountsOfReview'].describe()","e1fdd4c2":"books['CountsOfReview'].value_counts()","d70a1e85":"# And let's check Count of text reviews right away\nbooks['Count of text reviews'] = books['Count of text reviews'].astype('float')\nbooks['Count of text reviews'].describe()","9c0b4224":"books['Language'].unique()","53477a29":"books['Language'] = books['Language'].str.replace('en-US', 'eng').str.replace('en-GB', 'eng').str.replace('en-CA', 'eng').str.replace('nl', 'nld')","4feb2543":"books[books['Language'] == '--']","65c2704b":"books.loc[[211273, 806815], 'Language'] = 'eng'\nbooks.loc[[229808], 'Language'] = np.nan","a22f3b55":"books['Language'].value_counts()","210f68f0":"plt.figure(figsize = (12,6))\nlangs = sns.barplot(x = books['Language'].value_counts().head(5), y = books['Language'].value_counts().head(5).index)\nlangs.set_xlabel('Number of books')\nlangs.set_ylabel('Language')","2488a3de":"#Changing data type\nbooks['pagesNumber'] = books['pagesNumber'].astype('int')","638af2c8":"books['pagesNumber'].describe()","c8098344":"books[books['pagesNumber'] > 100000]","870af194":"books.drop((books[books['pagesNumber'] > 100000].index).tolist(), inplace = True)","de0d502b":"books['Description']","1c142189":"# Checking information again\nbooks.info()","f0c99971":"# Let's check the book with biggest number of rates (total)\nbooks[books['RatingDistTotal'] == books['RatingDistTotal'].max()]","08e8e821":"# And let's check the book with biggest number of 5-star rates\nbooks[books['RatingDist5'] == books['RatingDist5'].max()]","acc5684e":"books[books['Rating'] == 5]","8ec5bfc9":"books[(books['Rating'] == 5) & (books['RatingDistTotal'] > 1000)]","3bb20264":"books[(books['Rating'] > 4.5) & (books['RatingDistTotal'] > 1000)].sort_values('Rating', ascending = False).head(3)","8d5a63df":"# Let's check authors with biggest number of rates (total number for all books)\nbooks.groupby('Authors')['RatingDistTotal'].sum().sort_values(ascending = False).head(5)","0c1293a9":"books.groupby('Authors')['RatingDist5'].sum().sort_values(ascending = False).head(5)","e07f6166":"books.groupby('Authors')['Name'].count().sort_values(ascending = False).head(10)","4baa84bc":"books[['RatingDistTotal', 'RatingDist1', 'RatingDist2', 'RatingDist3', 'RatingDist4', 'RatingDist5', 'CountsOfReview', 'pagesNumber']].corr()","6fa9ae01":"plt.figure(figsize = (12,6))\nbooks_years = sns.barplot(y = books.groupby(['PublishYear'])['Name'].count().tail(60), x = books.groupby(['PublishYear'])['Name'].count().tail(60).index)\nbooks_years.set_xticklabels(books_years.get_xticklabels(), rotation=90)\nbooks_years.set_xlabel('Publish Year')\nbooks_years.set_ylabel('Number of books')","f2d7e0ad":"books.groupby(['PublishYear'])['pagesNumber'].mean().tail(10)","f4434220":"plt.figure(figsize = (12,8))\nsns.lineplot(x = 'PublishYear', y = 'pagesNumber', data = books)","c16309fc":"from wordcloud import WordCloud, STOPWORDS","be9897dd":"# Setting stopwords for names\nstopwords_names = set(STOPWORDS)\nstopwords_names.update(['book', 'story'])\n\n# Creating words list for names\nwords_from_names = [word for rows in books['Name'].str.lower().str.split() for word in rows if word not in stopwords_names]\nnames = \" \".join(name for name in words_from_names)","5df2a297":"# Creating a cloud with words from names:\nplt.figure(figsize = (10,6))\nwordcloud = WordCloud(max_words=30, background_color=\"white\", colormap = 'copper').generate(names)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","0a8e5716":"# Creating words list from descriptions\nwords_from_description = [word for rows in books['Description'].dropna().str.replace('\/','').str.replace('\\\\','').str.replace('<br>','').str.replace('<p>','').str.replace('><br','').str.replace('<br','').str.replace('<','').str.replace('>','').str.replace('--','').str.replace('.','').str.replace(',','').str.lower().str.split() for word in rows if word not in STOPWORDS]","d3ae7e6f":"# Creating a cloud with words from descriptions taken top 200 words:\nplt.figure(figsize = (10,6))\nwordcloud = WordCloud(max_words=60, background_color=\"white\", colormap = 'copper').generate_from_frequencies(frequencies = pd.Series(words_from_description).value_counts().head(100))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","b808a9b0":"- We can see that mostly 3-letter format is used for languages, however 'en-US', 'en-GB' and 'en-CA' have special format. As in this analysis it doesn't matter if english is british or canadian, let's just replace them with 'eng'.\n\n- I'll also replace 'nl' with 'nld' (Dutch language).\n\n- And I'll investigate '--' values.","39d0c0ac":"Here we can see, that the book with the best rating and number of reviews from 1000, is *The Complete Calvin and Hobbes* by\tBill Watterson. Next two are different editions of *Harry Potter* sets.","557f9eb4":"True. A lot of books were published multiple times. However let's check 100% duplicates.","1ae92a1f":"In first output we saw 130k duplicated rows and here only 224 (including original ones). At this point I'm going to drop duplicated rows from last subset and leave only uniques ones. Also I'm still curious about duplicated Names from first subset. Are there any especially popular names or books were just several times published? ","e45e32b7":"### Time Data: PublishYear, PublishMonth, PublishDay    ","5dda84d6":"Isn't it interesting to see Poems, Cinderella, Dinosaurs and Microeconomics in one list of popular names?) ","59540f98":"Routledge is a British publisher, that specialises in providing academic books, journals and online resources in the fields of humanities, behavioural science, education, law and social science. It was founded in 1836 and no wonder, that for almost 200 years they published so many works!\n\nBut that is interesting, that these works are available on GoodReads!","fdd987e8":"### Authors","e315a836":"And here again we see, that if book is reviewed, then it is reviewed a lot - as there is a big difference between 75-percentile and 100. From the other side - there are a lot of books with no or only few reviews. ","0edec0ed":"Definitely Rowling is the most rated author. Let's just confirm, that if we check 5-star rating, then picture is still similar:","7cd3fe70":"Thank you for reviewing. Hope you found interesting insights there!","c4b3ec4e":"### ISBN","7cdaa304":"There are 3 times less authors than books. Can we say, that in avarage 1 author writes or wrote 3 books? Let's find the best 'performed' authors.","a54865f5":"There are a lot of missing values in this colums, but in general this is just a text, that I'm going to check soon.","9ed61a27":"### 5. Which year were the biggest number of books written?","f65c0c81":"### 2. Which author is the most popular?","2868b533":"Books *The Dinosaur Heresies* and *Did You Say Twins?!* are written in English (I'll fix that), however *Inkosana Encini* is in rare african language, so I'll just remove the language.","1529deb3":"### 6. Is there tendency to reduce number of pages in nowaday books?","40ddf770":"If we ignore 'Anonymous', then 'William Shakespeare' was the most productive author!","e4046fec":"### 4. Is number of pages correlated with rating or number of reviews?","f07a10d3":"# Data preparation","f7fde8d7":"As it was mentioned above, I'm going to get rid of that redundant part like '5:', '4:', etc. ","7ab615e5":"So there are a lot of common names, that were used for several books, that are not related to each other. ","59651a00":"### Rating","9a44e11b":"There are a lot of numerical data, that was interpreted as strigs, which I'm going to fix.\n\nRating columns (RatingDist5, RatingDist4, RatingDist3, RatingDist2, RatingDist1, RatingDistTotal) start with redundant part like '5:', '4:', etc. This information need to be checked and removed, if it is not needed. \n\nPublishMonth = 16 - looks strange. Maybe data was wrongly assotiated?\n\nThere are also a lot of missing values in Language, Description and Count of text reviews columns. \n\nLet's go further.","481e301f":"For me it was expected that the average number of pages is between 200-300 pages (mean - 280, median - 240). However, it is strange to see books with million number of pages. Let's find them.","0a151f3a":"## Data Upload","e4f0083c":"1. Minimal and maximal Years look quite strange. I need to investigate that.\n2. Maximal Day is 12, but maximal Month is 31, so it is obvious, that data was mislabeled. Need to be fixed.","7768e3c4":"Books seems to be fine and I don't want to remove them, but since I also can't replace missing values with anything, let's leave it as it is for now. ","9ce9c0a5":"I started to investigate some of these books:\n\n1. A Book *The correct year for The Secret of the Old Mill* by Dixon, Franklin W. was published in 1927. [Amazon](https:\/\/www.amazon.com\/Secret-Mill-Hardy-Boys-Book\/dp\/0448089033)\n2. *Disney Princess: Look and Find* by John Kurtz Studios was published in 2003. [Amazon](https:\/\/www.amazon.com\/Disney-Princess-John-Kurtz-Studios\/dp\/0785379185)\n3. *The Virtuous Knight* by Margo Maguire was published in 2003. [Amazon](https:\/\/www.amazon.com\/Virtuous-Knight-Margo-Maguire\/dp\/0373292813)\n4. *El futuro del espaciotiempo* by Stephen W. Hawking was published in 2001. [Amazon](https:\/\/www.amazon.com\/El-Futuro-del-Espaciotiempo-Spanish\/dp\/8484323994)\n5. *Discover Your Passion: An Intuitive Search to Find Your Purpose in Life* by Gail A. Cassidy was published in 2000. [Amazon](https:\/\/www.amazon.com\/Discover-Your-Passion-Intuitive-Purpose\/dp\/0967743702)\n6. *Gala* by Dominique Bona was published in 1993. [Amazon](https:\/\/www.amazon.in\/Gala-la-muse-redoutable\/dp\/208066817X)\n7. *Agatha Raisin and the Witch of Wyckhadden* by M. C. Beaton was published in 1999. [Amazon](https:\/\/www.amazon.sg\/Agatha-Raisin-Witch-Wyckhadden-Beaton\/dp\/0312204949)\n\nBut as investigation is timeconsuming, I'm removing those rows from dataset.","a134273a":"Within my analysis I'll answer the questions, that I raised at the beginning:\n\n1. Which book is the most popular?\n2. Which author is the most popular?\n3. Which author wrote the biggest number of books?\n4. Is number of pages correlated with rating or number of reviews?\n5. Is there tendency to reduce number of pages in nowaday books? \n6. Which words are more likely to be used in description?","3c76fb52":"First of all let's create a dataset with all the books available.","d08d2677":"Unfortunately we don't have any statistics about how many people read the book, so again we will rely on ratings.","fb04b28c":"Before 1900 number of pages was randomly distributed, then we can see that in 1900-1915 years books were mostly near 100-200 pages. After World War I and till mid of the century there is a distribution peak. During these years we got a lot of works of Lost Generation (Ernest Hemingway, F. Scott Fitzgerald, Erich Maria Remarque, John O'Hara, etc.), who wrote about wars, broken dreams, broken lives. I suppose, that their books were full of experiences, thoughts, frustration, which made book more volume. \n\nAfter 1950 we see decaying curve and already nowadays number of pages is more or less stable and is near 250-300. It is hard for me to explain the fall to 200 pages near 2010-2015 years. Again - maybe there is lack of daya. Or maybe it is somehow related to active transition to electronic devices, but at the same time slow process of e-books supply (at least in my country). Everyday people have less and less time for reading, so authors dedicate themselves less for writing. However that is terrifying situation and already a lot of organisations noticed that, so last few years I can see more actions, that attract youth to read books, more apps that make reading easier, more e-books are now available. \n\nAnyway - I'm not an expert in literature, so I can only make assumptions.","70ade260":"### 3. Which author wrote the biggest number of books?","7b108c1b":"And now let's take a look on languages distribution","3d8339c0":"### 7. Book names and descriptions analysis","17b273ac":"Seems, that number of reviews doesn't depend on number of pages and it's good news for authors.","d69dd0f0":"### End","26555be3":"### Numbers of different rating points: RatingDistTotal, RatingDist1, RatingDist2, RatingDist3, RatingDist4 RatingDist5 ","cd271348":"At first let's convert date's to numerical data. ","6cf478b4":"Now we can finally get more information about ratings.","e34274bd":"### Description","e2d46ea5":"Can see here some familiar names.. Interesting.","cd11bffc":"### Name","61800024":"One copy of first book exists only on [Amazon](https:\/\/www.amazon.com\/gp\/product\/1422004805\/ref=x_gr_w_bb_sout?ie=UTF8&tag=x_gr_w_bb_sout-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=1422004805&SubscriptionId=1MGPYB6YW3HWK55XCGG2) with only one copy. I have big conserns if it is a real book\/\n\nProbably there is an error with second book. Because on [Amazon](https:\/\/www.amazon.com\/Sholokovs-Tikhii-Don-B-Murphy\/dp\/0704417707) book *Sholokov's \"Tikhii Don\": A Commentary* with ISBN 0704417707 written by A.B. Murphy has only 510 pages. \n\nHowever book *425 Heartwarmin' Expressions For Crafting, Painting, Stitching & Scrapbooking. Book # 1 Spiral-bound* with ISBN 0704417707 written by Shelly Ehbrecht has really 4517845 pages ([Amazon](https:\/\/www.amazon.com\/Heartwarmin-Expressions-Crafting-Stitching-Scrapbooking\/dp\/0969941048)), which is very strange.\n\nTo avoid such a big outliers I decided to remove these books with more than 100,000 pages from the dataset. ","c0571955":"### Pages Number","92a15fc5":"A lot of data.. Also books with good ratings. I cannot remove it.","754a52e2":"### Publisher","1a87b1d6":"No matches... Let's reduce rate.","c424f3cd":"This information was already mentioned above, but let's repeat. ","b824ab1b":"Hmmm.. all these books have just few assessments. Let's restrict the search. Maybe we should check books with at least 1000 reviews. ","2ca211ee":"### Language","5ace5a81":"So mostly there is either no rating, or quite good one with average ~4. If we omit 0 Ratings, then distribution is negatively skewed, which is quite typical for rankings of services.","601ec66a":"Here we can see the same picture as we saw before - high ratings are more likely to be given.","e391c87e":"Not all the names are unique. Probably there are some books, that were published with the same name, but from different Publishers.","1e2a3e62":"Years 162, 200, 299, 208, 20099, 162, 200, 299, 208, 20099, 19769, 2100, 3002, 4989, 20040, 20067 and 1384  look like errors. Also 2021 and 2030 can be wrong. Let's find out, how many books were publish those years. \n\n*Note:* After I started this investigation several more non-typical years were added (20099, 65535, 1376). Unfortunately that's not possible to re-check every book with strange year all the time, so I decided to change part of the code and remove suspisios rows from analysis. I'll leave only books between 1800 and 2020 years. ","6db8cc68":"Book by J.K. Rowling on Japanese! Maybe that's Harry Potter? Amazing.\n\nHowever, total Rating is not 5. Let's find book with 5.0 Rating.","773900a7":"### 1. Which book is the most popular?","78d4da7f":"# EDA","ffb7ee02":"# Objectives\n\nIn this notebooks I'd like to find out:\n1. Which book is the most popular?\n2. Which author is the most popular?\n3. Which author wrote the biggest number of books?\n4. Is number of pages correlated with rating or number of reviews?\n5. Is there tendency to reduce number of pages in nowaday books? \n6. Which words are more likely to be used in description?\n\nP.S. I'll be very grateful for review and feedback. ","23375a14":"Now let's check what do we have...","edfc9aa5":"That's very interesting, that since 2008 such a big decrease has place! Maybe data is not full for that period? ","b51850f9":"### Counts of review and Count of text reviews"}}