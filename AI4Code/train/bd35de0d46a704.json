{"cell_type":{"756a773b":"code","bd81b171":"code","212092ec":"code","c6884950":"code","b6b45998":"code","a4164a44":"code","d8cacecf":"code","c678e974":"code","b91baf48":"code","e4bbde0d":"code","d3623756":"code","83a490ec":"code","1465bf4b":"code","e8bde569":"markdown","7df59fcc":"markdown","c91c5e0a":"markdown","e55e401e":"markdown","d436485f":"markdown","80b2c727":"markdown","3c78a1ce":"markdown","149172cf":"markdown"},"source":{"756a773b":"!wget https:\/\/github.com\/google-research-datasets\/gap-coreference\/raw\/master\/gap-development.tsv -q\n!wget https:\/\/github.com\/google-research-datasets\/gap-coreference\/raw\/master\/gap-test.tsv -q\n!wget https:\/\/github.com\/google-research-datasets\/gap-coreference\/raw\/master\/gap-validation.tsv -q","bd81b171":"import pandas as pd\nimport re\nimport spacy\nfrom IPython.core.display import display, HTML","212092ec":"train_df = pd.concat([pd.read_csv(\"gap-test.tsv\", index_col=0, delimiter=\"\\t\"),\n                      pd.read_csv(\"gap-validation.tsv\", index_col=0, delimiter=\"\\t\"),\n                      pd.read_csv(\"gap-development.tsv\", index_col=0, delimiter=\"\\t\")])\ntest_df = pd.read_csv(\"..\/input\/test_stage_2.tsv\", index_col=0, delimiter=\"\\t\")","c6884950":"nlp = spacy.load('en')\ndef get_sentence(text, offset, token_after=\"[PRONOUN]\"):\n    \"\"\"\n    Extract a sentence containing a word at position offset by character and\n    replace the word with token_after.\n    output: Transformed sentence\n            token_before\n            a pos tag of the word.\n    \"\"\"\n    doc = nlp(text)\n    # idx: Character offset\n    idx_begin = 0\n    for token in doc:\n        if token.sent_start:\n            idx_begin = token.idx\n        if token.idx == offset:\n            sent = token.sent.string\n            pos_tag = token.pos_\n            idx_token = offset - idx_begin\n            break\n    # word_s = sent[idx_token:].split()\n    # n = len(sent)\n    token_before = token.string.strip()\n    subtxt_transformed = re.sub(\"^\" + token_before, token_after, sent[idx_token:])\n    sent_transformed = sent[:idx_token] + subtxt_transformed\n    # n_diff = len(sent_transformed) - n - len(token_after) + len(token_before)\n    return sent_transformed, token_before, pos_tag","b6b45998":"%%time\ntrain_preprocessed_before = []\nfor obj in train_df.iterrows():\n    train_preprocessed_before.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","a4164a44":"%%time\ntest_preprocessed = []\nfor e, obj in enumerate(test_df.iterrows()):\n    test_preprocessed.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","d8cacecf":"ID = obj[0]\ntext = obj[1][\"Text\"]\noffset = obj[1][\"Pronoun-offset\"]\nhtml_text = \"<BLOCKQUOTE>\" + text[:offset] + \"<font color='red'>\" + text[offset:offset + 2] + \"<\/font>\" + text[offset + 2:] + \"<\/BLOCKQUOTE>\" \ndisplay(HTML(\"An error occured during preprocessing ID: \" +  \"<I>\" + ID + \"<\/I>.\" + html_text))","c678e974":"doc = nlp(text)\n\nprint(\"Pronoun-offset:\", offset)\nfor token in doc:\n    if token.idx > offset - 10 and token.idx < offset + 10:\n        print(token.idx, token.pos_, \":\", token)\n    ","b91baf48":"%%time\nfor obj in test_df.iloc[e + 1:].iterrows():\n    test_preprocessed.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","e4bbde0d":"def get_sentence(text, offset, token_after=\"[PRONOUN]\"):\n    \"\"\"\n    Extract a sentence containing a word at position offset by character and\n    replace the word with token_after.\n    output: Transformed sentence\n            A word starting at offset\n            A pos tag of the word.\n            If the word cannot be extracted it returns default values.\n    \"\"\"\n    doc = nlp(text)\n    # idx: Character offset\n    idx_begin = 0\n    sent = None\n    for token in doc:\n        if token.sent_start:\n            idx_begin = token.idx\n        if token.idx == offset:\n            sent = token.sent.string\n            pos_tag = token.pos_\n            idx_token = offset - idx_begin\n            break\n    # word_s = sent[idx_token:].split()\n    # n = len(sent)\n    if sent is None:\n        # Default values\n        sent_transformed = token_after\n        token_before = \"it\"\n        pos_tag = \"PRON\"\n    else:\n        token_before = token.string.strip()\n        subtxt_transformed = re.sub(\"^\" + token_before, token_after, sent[idx_token:])\n        sent_transformed = sent[:idx_token] + subtxt_transformed\n    # n_diff = len(sent_transformed) - n - len(token_after) + len(token_before)\n    return sent_transformed, token_before, pos_tag","d3623756":"%%time\ntrain_preprocessed_after = []\nfor obj in train_df.iterrows():\n    train_preprocessed_after.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","83a490ec":"%%time\ntest_preprocessed = []\nfor obj in test_df.iterrows():\n    test_preprocessed.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","1465bf4b":"all([before == after for before, after in zip(train_preprocessed_before, train_preprocessed_after)])","e8bde569":"No errors.","7df59fcc":"The function assumes that **token.idx == offset** somewhere in doc, which is wrong.","c91c5e0a":"No error after that. Only one case caused error.\n\nHere is a fixed code.","e55e401e":"The reason for the error is that spacy'tokenizer couldn't extract \"**he**\" at position 313 and *get_sentence* doesn't properly handle that case.\n","d436485f":"The change doesn't affect training.","80b2c727":"This is the original code.","3c78a1ce":"No errors.","149172cf":"In this kernel I will explain what caused error during preprocessing *test_stage_2.tsv* and a fixed code doesn't affect training."}}