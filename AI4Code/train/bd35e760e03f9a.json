{"cell_type":{"9f3ea498":"code","1c9f6bd1":"code","90eb82fe":"code","be787671":"code","a671caed":"code","6645d1e7":"code","a3dde898":"code","cfbf9ae2":"code","cdd5f5eb":"code","ec4f4743":"code","bde83401":"code","03d47428":"code","25ebe88c":"code","62862fd6":"code","864d924a":"code","f6cdfe3e":"code","bfdbaaae":"code","f9c85112":"code","493c2e36":"code","4180407c":"markdown","ef60d566":"markdown","b2c7f90f":"markdown","cb55f6de":"markdown","5a00f1e3":"markdown","88a939d5":"markdown","436a926f":"markdown"},"source":{"9f3ea498":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# For Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom ipywidgets import Dropdown,Accordion,Label,link\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1c9f6bd1":"df = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")","90eb82fe":"df.info()","be787671":"df.isnull().sum()","a671caed":"df.head()","6645d1e7":"df.drop([\"id\"],axis=1,inplace=True)","a3dde898":"clean = df.dropna().reset_index().drop([\"index\"],axis=1)","cfbf9ae2":"px.imshow(clean.corr())","cdd5f5eb":"sns.countplot(x=\"stroke\",data=clean)","ec4f4743":"plt.figure(figsize=(30,35))\nn=0\nfor i in ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married','work_type', 'Residence_type', 'avg_glucose_level', 'bmi','smoking_status']:\n    n+=1\n    plt.subplot(5,2,n)\n    sns.histplot(clean,x=i,hue=\"stroke\")\nplt.show()","bde83401":"plt.figure(figsize=(10,10))\nsns.scatterplot(x=\"bmi\",y=\"avg_glucose_level\",data=clean,hue=\"stroke\")\nplt.xlabel(\"BMI\")\nplt.ylabel(\"AVG-GLUCOSE-LEVEL\")\nplt.title(\"BMI vs AVG-GLUCOSE-LEVEL\")","03d47428":"yes = clean.where(clean[\"stroke\"]==1).dropna()","25ebe88c":"for i in ['gender', 'hypertension', 'heart_disease', 'ever_married','work_type', 'Residence_type','smoking_status']:\n    fig = px.scatter(yes, x=\"avg_glucose_level\", y=\"bmi\",size=\"age\",title= f\"Effects of {i}\" ,color=i,hover_name=i, log_x=True, size_max=10)\n    fig.show()","62862fd6":"# most people in the 30 to 40 range, so I am filling values with the mean\ndf[\"bmi\"].replace({np.nan:np.mean(df[\"bmi\"])},inplace=True)\ndf.isnull().sum()","864d924a":"# One-Hot Encoding\ndf = pd.get_dummies(df)\nreorder = list(df.columns)\nreorder.remove(\"stroke\")\nreorder.append(\"stroke\")\ndf = df[reorder]\ndf.head()","f6cdfe3e":"# Handling low distribution\nfrom sklearn.utils import resample\ndf_majority = df[df.stroke == 0]\ndf_minority = df[df.stroke == 1]\n\ndf_upsampled = resample(df_minority,\n                       replace=True,\n                       n_samples=4861,\n                       random_state=0)\n\ndf_upsampled = pd.concat([df_majority,df_upsampled])\n\ndf_upsampled.stroke.value_counts()","bfdbaaae":"# Splitting the Data\nX = df.iloc[:,:-1].values\ny = df.iloc[:,-1].values\n\nfrom sklearn.model_selection import train_test_split as tts\n\nx_train,x_val,y_train,y_val = tts(X,y,test_size=0.4,random_state=0)\nx_val,x_test,y_val,y_test = tts(x_val,y_val,test_size=0.5,random_state=0)\n\nprint([s.shape for s in [x_train,x_val,x_test,y_train,y_val,y_test]])","f9c85112":"# Classification using Gradient_Boosting Algorithm\nfrom sklearn.ensemble import GradientBoostingClassifier\nmodel= GradientBoostingClassifier(n_estimators=100, learning_rate=0.01,max_depth=1, random_state=0).fit(x_train, y_train)\nmodel.score(x_test,y_test)","493c2e36":"from sklearn.metrics import classification_report\ny_pred = model.predict(x_test)\ntarget_names = [\"NO\",\"YES\"]\nprint(classification_report(y_test, y_pred, target_names=target_names,zero_division=1))","4180407c":"## Preprocessing","ef60d566":"OBSERVATIONS\n\n*  There is a greater chance of Stroke in \n        \n        self-employed people.\n        In people having BMI around the range of 30\n        In people of age more than 70\n        In former smokers and almost equally likely in smokers\n        In males","b2c7f90f":"## Effects of Categorical Variables","cb55f6de":"The Data is not much correlated","5a00f1e3":"# EDA","88a939d5":"# Analysis and Model","436a926f":"Average Glucose Level of more than 150 while having a BMI of 20 to 40 might lead to Stroke"}}