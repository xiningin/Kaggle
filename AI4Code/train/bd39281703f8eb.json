{"cell_type":{"c8248fb3":"code","85253fb6":"code","211df6c3":"code","40568ff8":"code","97ae4eb8":"code","36333743":"code","876c339d":"code","8101ae7b":"code","73a69604":"code","474d8078":"code","3ff74410":"code","ddd2e3eb":"code","3f5a11e1":"code","7ffa7ad9":"code","76889b9f":"code","95d18e0e":"code","532add26":"code","79c87b84":"code","4cf22e7e":"markdown"},"source":{"c8248fb3":"import nltk\nimport pandas as pd","85253fb6":"\n#To check the encoding of the CSV in order to avoid issue while reading CSV using Pandas.\n\nimport chardet\nwith open('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv', 'rb') as rawdata:\n    result = chardet.detect(rawdata.read(100000))\nresult","211df6c3":"data=pd.read_csv('\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv',encoding='Windows-1252')\ndata.head()","40568ff8":"\n#Remove the unwanted columns from dataset and change the label v1 and v2 to label and message respectively\ndata=data[['v1','v2']]\ndata.columns=['label','message']\ndata","97ae4eb8":"import nltk\nimport re\n\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords","36333743":"corpus=[]\nps=PorterStemmer()\n\n\nfor i in range(0,len(data)):\n    \n    review=re.sub('[^a-zA-Z]',' ', data['message'][i])\n    review.lower()\n    reviews=review.split(' ')\n    review=[ps.stem(word) for word in reviews if  not word in set(stopwords.words('english'))]\n    \n    \n    review=' '.join(review)\n    corpus.append(review)\n    \n    ","876c339d":"\n\n#using Bag Of Word\n\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer()\n\nX=cv.fit_transform(corpus).toarray()\nX.shape\n\n","8101ae7b":"y=pd.get_dummies(data['label'])\ny=y.iloc[:,1].values\ny","73a69604":"## Train Test Split\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train , X_test, y_train , y_test=train_test_split(X,y,test_size=0.3,random_state=2)","474d8078":"# Model Selection Naive Bayes\n\nfrom sklearn.naive_bayes import MultinomialNB\n\nmodel=MultinomialNB().fit(X_train,y_train)\n","3ff74410":"y_pred=model.predict(X_test)","ddd2e3eb":"from sklearn.metrics import confusion_matrix\n\nconfusionM=confusion_matrix(y_test,y_pred)\nconfusionM","3f5a11e1":"TP=confusionM[0][0]\nFP=confusionM[0][1]\nFN=confusionM[1][0]\nTN=confusionM[1][1]\n\n\n\naccuracy=((TP + TN)\/(TP+FP+FN+TN)) * 100\nprint(accuracy)\n\n#Precision tells us how many of the correctly predicted cases actually turned out to be positive.\nprecision=(TP\/(TP +FP) ) * 100\nprint(precision)\n\n#Recall tells us how many of the actual positive cases we were able to predict correctly with our model.\nrecall= (TP \/ (TP + FN)) * 100\nprint(recall)\n","7ffa7ad9":"\n#Or we can use direct library avaiable to get accuracy of the prediction.\nfrom sklearn.metrics import accuracy_score\n\naccuracyscore=accuracy_score(y_test,y_pred)\naccuracyscore","76889b9f":"\n\n#apply LogisticRegression classfier\nfrom sklearn.linear_model import LogisticRegression\nlg = LogisticRegression(class_weight='balanced').fit(X_train, y_train)\nprint (lg.coef_)\nprint('training set score obtained Logistic Regression: {:.2f}'.format(lg.score(X_train, y_train)))\nprint('test set score obtained Logistic Regression: {:.2f}'.format(lg.score(X_test, y_test)))\n\n","95d18e0e":"y_pred = lg.predict(X_test)\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","532add26":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))\n","79c87b84":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\n\nlogit_roc_auc = roc_auc_score(y_test, lg.predict_proba(X_test)[: ,1])\nfpr, tpr, thresholds = roc_curve(y_test, lg.predict_proba(X_test)[:,1])\n# print(thresholds)\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","4cf22e7e":"# Logistic Regression"}}