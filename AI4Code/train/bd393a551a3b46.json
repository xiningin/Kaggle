{"cell_type":{"93647a32":"code","f4842aeb":"code","e7f5a8d9":"code","179f07ac":"code","e33a504f":"code","231b803f":"code","b9493ad6":"code","f9bc3568":"code","d42b1e6a":"code","0348f305":"code","d177500a":"code","99d5e326":"markdown","ea55940e":"markdown","194cf104":"markdown"},"source":{"93647a32":"import numpy as np \nimport pandas as pd \nfrom xgboost import XGBRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f4842aeb":"train = pd.read_csv('..\/input\/tps-sep-train-kfold\/train_10_folds.csv',index_col=0)\ntest = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv',index_col=0)\nsample_submission = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv')","e7f5a8d9":"train['n_missing'] = train[train.columns].isna().sum(axis=1)\ntest['n_missing'] = test[test.columns].isna().sum(axis=1)","179f07ac":"print(train.shape)\nprint(test.shape)\nuseful_features = [column for column in train.columns if column not in [\"claim\", \"kfold\"]]","e33a504f":"my_imputer = SimpleImputer(strategy = 'mean')\n\ntrain[useful_features] = my_imputer.fit_transform(train[useful_features])\ntest[useful_features] = my_imputer.transform(test[useful_features])","231b803f":"fold = 0\nxtrain = train[train.kfold != fold].reset_index(drop = True)\nxvalid = train[train.kfold == fold].reset_index(drop = True)\nvalid_ids = xvalid.index.values.tolist()\nlen(valid_ids)","b9493ad6":"final_predictions = []\nfinal_valid_predictions = {}\nscores = []\nfor fold in range(10):\n    xtrain = train[train.kfold != fold].reset_index(drop = True)\n    xvalid = train[train.kfold == fold].reset_index(drop = True)\n    xtest = test.copy()\n    \n    valid_ids = xvalid.index.values.tolist()\n    \n    ytrain = xtrain.claim\n    yvalid = xvalid.claim\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    \n    my_scaler = StandardScaler()\n    xtrain[useful_features] = my_scaler.fit_transform(xtrain[useful_features])\n    xvalid[useful_features] = my_scaler.transform(xvalid[useful_features])\n    xtest[useful_features] = my_scaler.transform(xtest[useful_features])\n    \n    parameter = {\n    \"verbosity\":0,\n    \"objective\": \"binary:logistic\",\n    \"tree_method\": 'gpu_hist',\n    \"booster\":'gbtree',\n    'learning_rate': 0.053412516326389936,\n    'max_depth': 3,\n    'gamma': 0.21936641952157981,\n    'subsample': 0.9978683971251602,\n    'colsample_bytree': 0.8718594096500578,\n    'n_estimators': 3000,\n    'reg_alpha': 0.01631769681569393,\n    'min_child_weight': 7\n    }\n\n    model = XGBRegressor(**parameter, random_state = fold)\n    model.fit(xtrain,ytrain,verbose = False, eval_set = [(xtrain,ytrain),(xvalid,yvalid)],\n             eval_metric = \"auc\",early_stopping_rounds=200)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids,preds_valid)))\n    \n    temp = roc_auc_score(yvalid,preds_valid)\n    scores.append(temp)\n    print(fold, temp)","f9bc3568":"print(np.mean(scores), np.std(scores))","d42b1e6a":"final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_xgb\"]\nfinal_valid_predictions.to_csv(\"train_pred_xgb.csv\", index = False)\nfinal_valid_predictions.head()","0348f305":"preds = np.mean(np.column_stack(final_predictions), axis = 1)","d177500a":"sample_submission.claim = preds\nsample_submission.to_csv(\"test_pred_xgb.csv\", index = False)\nsample_submission.head()","99d5e326":"# Output","ea55940e":"# Model Learning","194cf104":"# Data Preprocessing"}}