{"cell_type":{"99eb3b84":"code","ce8609b4":"code","94362230":"code","317fbd40":"code","a332937c":"code","7af7cbf1":"code","2aa940ca":"code","a10bdf15":"code","26da18f5":"code","b5138f0c":"code","a5e585ef":"code","83d99410":"code","30f06b22":"code","e6905fb4":"code","84482858":"code","cb9a14de":"code","20b66ea3":"code","b71e0447":"code","e9f539e9":"code","b8688d2e":"code","ae39381d":"code","04bfd91e":"code","7f12829f":"code","aefcf527":"code","b4ee6038":"code","5b499801":"code","afb3de4d":"code","b3f6257b":"code","f229654c":"markdown","4c402025":"markdown","b9b673b7":"markdown","f298b744":"markdown","9dd14d44":"markdown","6c6b0197":"markdown","f7980e32":"markdown","411a1335":"markdown","a72dad2a":"markdown","1b1dff56":"markdown","4bb30980":"markdown","d57b76a4":"markdown","5926162c":"markdown","89076af5":"markdown","eab83f88":"markdown"},"source":{"99eb3b84":"import os\nimport zipfile\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img","ce8609b4":"np.random.seed(9)\ntf.random.set_seed(9)","94362230":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","317fbd40":"weights_file = '\/kaggle\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(weights_file)\n#pre_trained_model.summary()","a332937c":"for layer in pre_trained_model.layers:\n    layer.trainable = False\n\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","7af7cbf1":"with zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\",\"r\") as z:\n    z.extractall(\"..\/kaggle\/working\/train_unzip\")\n    \nprint(f\"We have total {len(os.listdir('..\/kaggle\/working\/train_unzip\/train'))} images in our training data.\")","2aa940ca":"filenames = os.listdir('..\/kaggle\/working\/train_unzip\/train')\nlabels = [str(fname)[:3] for fname in filenames]\ntrain_df = pd.DataFrame({'filename': filenames, 'label': labels})\ntrain_df.head()","a10bdf15":"print((train_df['label']).value_counts())","26da18f5":"train_set_df, dev_set_df = train_test_split(train_df[['filename', 'label']], test_size=0.3, random_state = 42, shuffle=True, stratify=train_df['label'])\nprint(train_set_df.shape, dev_set_df.shape)","b5138f0c":"print('Training Set image counts:')\nprint(train_set_df['label'].value_counts())\nprint('Validation Set image counts:')\nprint(dev_set_df['label'].value_counts())","a5e585ef":"train_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\nvalidation_datagen  = ImageDataGenerator( rescale = 1.0\/255 )","83d99410":"train_generator = train_datagen.flow_from_dataframe(\n    train_set_df, \n    directory=\"..\/kaggle\/working\/train_unzip\/train\/\", \n    x_col='filename',\n    y_col='label',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=32,\n    validate_filenames=False \n)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    dev_set_df, \n    directory=\"..\/kaggle\/working\/train_unzip\/train\/\", \n    x_col='filename',\n    y_col='label',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=32,\n    validate_filenames=False \n)","30f06b22":"x = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x ) \n\nmodel.summary()","e6905fb4":"model.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['accuracy'])","84482858":"history = model.fit(\n            train_generator,\n            validation_data = validation_generator,\n            steps_per_epoch = 100,\n            epochs = 20,\n            validation_steps = 50)","cb9a14de":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs   = range(len(acc))\n\nplt.plot(epochs, acc, label=\"Training accuracy\")\nplt.plot(epochs, val_acc, label=\"Validation accuracy\")\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\n\nplt.plot(epochs, loss, label=\"Training loss\")\nplt.plot(epochs, val_loss, label=\"Validation loss\")\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","20b66ea3":"loss, accuracy = model.evaluate_generator(validation_generator)\nprint(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))","b71e0447":"dev_true = dev_set_df['label'].map({'dog': 1, \"cat\": 0})\ndev_predictions =  model.predict_generator(validation_generator)\ndev_set_df['pred'] = np.where(dev_predictions>0.5, 1, 0)\ndev_pred = dev_set_df['pred']\ndev_set_df.head()","e9f539e9":"dev_set_predictions_plot = dev_set_df['pred'].value_counts().plot.bar(title='Predicted number of Dog vs Cat Images in dev set')","b8688d2e":"confusion_mtx = confusion_matrix(dev_true, dev_pred) \n\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Blues\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","ae39381d":"with zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\",\"r\") as z:\n    z.extractall(\"..\/kaggle\/working\/test1_unzip\")\n    \nprint(f\"We have total {len(os.listdir('..\/kaggle\/working\/test1_unzip\/test1'))} images in our test1.zip\")","04bfd91e":"test_filenames = os.listdir('..\/kaggle\/working\/test1_unzip\/test1')\ntest_df = pd.DataFrame({'filename': test_filenames})\ntest_df.head()","7f12829f":"test_generator = validation_datagen.flow_from_dataframe(\n    test_df, \n    directory=\"..\/kaggle\/working\/test1_unzip\/test1\/\", \n    x_col='filename',\n    y_col=None,\n    target_size=(150, 150),\n    class_mode=None,\n    batch_size=32,\n    validate_filenames=False \n)","aefcf527":"predictions = model.predict_generator(test_generator, steps=np.ceil(len(test_filenames)\/32))","b4ee6038":"test_df['id'] = test_df['filename'].str.split('.').str[0]\ntest_df['label'] = np.where(predictions>0.5, 1, 0)\nresult_df = test_df[['id','label']]\nresult_df.head()","5b499801":"test_set_predictions_plot = dev_set_df['pred'].value_counts().plot.bar(title='Predicted number of Dog vs Cat Images in test set')","afb3de4d":"result_df.to_csv(\"cats_vs_dogs.csv\",index=False)","b3f6257b":"sample_test = test_df.sample(n=9)\n\nplt.figure(figsize=(12, 12))\nlabels ={0:'cat', 1:'dog'}\nfor i, row in sample_test.reset_index(drop=True).iterrows():\n    filename = row['filename']\n    category = labels[row['label']]\n    img = load_img(\"..\/kaggle\/working\/test1_unzip\/test1\/\"+filename, target_size=(150, 150))\n    plt.subplot(3, 3, i+1)\n    plt.imshow(img)   \n    plt.xlabel('(' + \"{}\".format(category) + ')')\n \n    \nplt.tight_layout()\nplt.show()","f229654c":"Saving results in cats_vs_dogs.csv file:","4c402025":"# 5. Image Augmentation","b9b673b7":"# 7. Model Fitting","f298b744":"We take the layers from the existing model, and freeze\/lock (by setting layer.trainable = False) the already learned convolutions into our model so that their weight don't get updated while training. ","9dd14d44":"# 2. Loading Pretrained Model\nWhile working in Kaggle kernel, to add any Keras Pretrained Models data click on the kernel's Data tab, search and add it.","6c6b0197":"Let's instantiate our pretrained model. By setting include_top to False we are ignoring the fully connected layer at the top of Inception V3 so that we straightly get to convolutional layers.","f7980e32":"# 6. Adding DNN\nNow we'll need to add our own DNN at the bottom of pretrained layers, which we can retrain to our data.","411a1335":"# 8. Accuracy and Loss Curves","a72dad2a":"And finally let's look at some predictions made by our model:","1b1dff56":"Making predictions on test data:","4bb30980":"# 8. Predictions and Submission File\nWe first extract test data from test1.zip","d57b76a4":"# 4. Splitting Training Data","5926162c":"# 3. Extracting Training Data","89076af5":"# 9. Model Evaluation","eab83f88":"In [Cats vs Dogs 1 | Learning from scratch](https:\/\/www.kaggle.com\/sejalkshirsagar\/cats-vs-dogs-1-learning-from-scratch) notebook we explored training data, built CNN Model and trained it from scratch. In this notebook we will be implementing Transfer Learning using the pretrained model InceptionV3.\n# 1. Importing Libraries"}}