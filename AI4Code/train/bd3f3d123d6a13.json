{"cell_type":{"b1016be1":"code","5397660b":"code","6ce0148a":"code","3c690c32":"code","2e4c708c":"code","8a2e8f1f":"code","09cf8617":"markdown","eb6f3a9d":"markdown","5f6a678f":"markdown","5fa1e786":"markdown","76e236d5":"markdown"},"source":{"b1016be1":"# LA\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\n# Keras\nfrom keras.preprocessing import image\nfrom keras import applications\nfrom keras.models import Model\nfrom keras import layers, initializers, optimizers, regularizers\nfrom keras import datasets, models, callbacks, applications, utils\n\n#  Supress warnings\nimport warnings\nwarnings.filterwarnings(\"always\")\nwarnings.filterwarnings('ignore')\n\n# Misc.\nimport os\nimport glob\nimg_path_train = '..\/input\/train\/train'\nimg_path_test = '..\/input\/test\/test'","5397660b":"# Load the labels:\nlabels = pd.read_csv('..\/input\/{}'.format('train_labels.csv'))\n\n# Encoding:\nle = LabelEncoder(); \nlabels['Classes'] = le.fit_transform(labels['Category'])\n\n# Show classes:\nfor i, c in enumerate(le.classes_): \n    print(i, '=', c)\n    \nlabels.head(3)","6ce0148a":"# Load the data for Mobilenet:\n# ----------------------------------\n# Load train data:\nX = []\nfor image_path in np.sort(glob.glob(img_path_train + \"\/*.jpg\")):\n    img = image.load_img(image_path, target_size=(224, 224))\n    img_data = image.img_to_array(img)\n    img_data = applications.mobilenet.preprocess_input(img_data)\n    X.append(img_data)\n\nX = np.array(X)\ny = labels.Classes.values\n# ----------------------------------\n# Load test data:\nX_test = []\nfor image_path in np.sort(glob.glob(img_path_test + \"\/*.jpg\")):\n    img = image.load_img(image_path, target_size=(224, 224))\n    img_data = image.img_to_array(img)\n    img_data = applications.mobilenet.preprocess_input(img_data)\n    X_test.append(img_data)\n\nX_test = np.array(X_test)\n# ----------------------------------\n\nprint('Data has been loaded.\\n')\n\n# Generating the folds:\ncv_n = 5 # number of folders\nfolds = StratifiedKFold(n_splits=cv_n, random_state=42).split(X, y)\npred_1 = np.zeros((X.shape[0], 5)) # empty array for Stage 1 predictions\n\n# Getting Stage 1 predictions on Train:\nfor train_index, test_index in folds:\n    \n    # Model 1\n    # ---------------------------\n    # pretrained model without top layer\n    base_model1 = applications.MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n    #fix weights\n    base_model1.trainable = False\n\n    # and our model become simple\n    inp = layers.Input((224, 224, 3))\n    mobilenet = base_model1(inp)\n\n    gap = layers.GlobalAveragePooling2D()(mobilenet)\n    fc = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.1))(gap)\n    #fc = layers.Dense(64, activation='relu')(fc)\n    do = layers.Dropout(0.4)(fc)\n    fc = layers.Dense(5, activation='softmax')(do)\n\n    model1 = models.Model(inp, fc)\n\n    model1.compile(optimizer='adam', \n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    # train only dense layer on top\n    model1.fit(X[train_index], y[train_index],\n              batch_size=16,\n              epochs=1,\n              verbose=1, \n              callbacks=[callbacks.ReduceLROnPlateau(patience=2, verbose=1)])\n    \n    # unfreeze all weights and train \n    base_model1.trainable = True\n    model1.compile(optimizer=optimizers.Adam(1e-4), \n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    model1.fit(X[train_index], y[train_index],\n              batch_size=16,\n              epochs=10,\n              verbose=1, \n              callbacks=[callbacks.ReduceLROnPlateau(patience=2, verbose=1)])\n    # ---------------------------\n    \n    pred_part = model1.predict(X[test_index])\n    pred_1[test_index] = pred_part\n    print('\\nOOB accurasy =', accuracy_score(pred_part.argmax(axis=1), y[test_index]), end='\\n\\n')\n\nprint('\\nTolal accurasy on train=', accuracy_score(pred_1.argmax(axis=1), y), end='\\n\\n')\n\n# Getting Stage 1 predictions on Test:\nbase_model1.trainable = False\n\n# Model 1\n# ---------------------------\n# train only dense layer on top\nmodel1.fit(X, y,\n           batch_size=16,\n           epochs=1,\n           verbose=1, \n           callbacks=[callbacks.ReduceLROnPlateau(patience=2, verbose=1)])\n\n# unfreeze all weights and train \nbase_model1.trainable = True\nmodel1.fit(X, y,\n           batch_size=16,\n           epochs=10,\n           verbose=1, \n           callbacks=[callbacks.ReduceLROnPlateau(patience=2, verbose=1)])\n# ---------------------------\n\npred_test_1 = model1.predict(X_test)\n\nprint('\\nStage 1 predictions on Test has been obtained.')","3c690c32":"# Load the data for ResNet50:\n# ----------------------------------\n# Load train data:\nX = []\nids = []\nfor image_path in np.sort(glob.glob(img_path_train + \"\/*.jpg\")):\n    img = image.load_img(image_path, target_size=(224, 224))\n    img_data = image.img_to_array(img)\n    img_data = applications.resnet50.preprocess_input(img_data)\n    X.append(img_data)\n    ids.append(image_path.split('\/')[-1][:-4]) # load ids\n    \nX = np.array(X)\nids = np.array(ids) # save ids\ny = labels.Classes.values\n# ----------------------------------\n# Load test data:\nX_test = []\nids_test = []\nfor image_path in np.sort(glob.glob(img_path_test + \"\/*.jpg\")):\n    img = image.load_img(image_path, target_size=(224, 224))\n    img_data = image.img_to_array(img)\n    img_data = applications.resnet50.preprocess_input(img_data)\n    X_test.append(img_data)\n    ids_test.append(image_path.split('\/')[-1][:-4]) # load ids\n    \nX_test = np.array(X_test)\nids_test = np.array(ids_test) # save ids\n# ----------------------------------\n\nprint('Data has been loaded.\\n')\n\n# Generating the folds:\ncv_n = 5 # number of folders\nfolds = StratifiedKFold(n_splits=cv_n, random_state=42).split(X, y)\npred_2 = np.zeros((X.shape[0], 5)) # empty array for Stage 1 predictions\n\n# Getting Stage 1 predictions on Train:\nfor train_index, test_index in folds:\n    \n    # Model 2\n    # ---------------------------\n    #pretrained model without top layer\n    base_model2 = applications.ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3), pooling='avg')\n    #fix weights\n    base_model2.trainable = False\n\n    #and our model become simple\n    inp = layers.Input((224, 224, 3))\n    resnet = base_model2(inp)\n\n    fc = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.2))(resnet)\n    do = layers.Dropout(0.3)(fc)\n    fc = layers.Dense(5, activation='softmax')(do)\n\n    model2 = models.Model(inp, fc)\n\n    model2.compile(optimizer='adam', \n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    #train only dense layer on top\n    model2.fit(X[train_index], y[train_index],\n              batch_size=16,\n              epochs=1,\n              verbose=1, \n              callbacks=[callbacks.ReduceLROnPlateau(patience=2, verbose=1)])\n\n    #unfreeze all weights and train \n    base_model2.trainable = True\n    model2.compile(optimizer=optimizers.Adam(1e-4), \n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n\n    model2.fit(X[train_index], y[train_index],\n              batch_size=16,\n              epochs=10,\n              verbose=1, \n              callbacks=[callbacks.ReduceLROnPlateau(patience=2, verbose=1)])\n    # ---------------------------\n    \n    pred_part = model2.predict(X[test_index])\n    pred_2[test_index] = pred_part\n    print('\\nOOB accurasy =', accuracy_score(pred_part.argmax(axis=1), y[test_index]), end='\\n\\n')\n\nprint('\\nTolal accurasy on train=', accuracy_score(pred_2.argmax(axis=1), y), end='\\n\\n')\n\n# Getting Stage 1 predictions on Test:\nbase_model2.trainable = False\n\n# Model 2\n# ---------------------------\n# train only dense layer on top\nmodel2.fit(X, y,\n           batch_size=16,\n           epochs=1,\n           verbose=1, \n           callbacks=[callbacks.ReduceLROnPlateau(patience=2, verbose=1)])\n\n# unfreeze all weights and train \nbase_model2.trainable = True\nmodel2.fit(X, y,\n           batch_size=16,\n           epochs=10,\n           verbose=1, \n           callbacks=[callbacks.ReduceLROnPlateau(patience=2, verbose=1)])\n# ---------------------------\n\npred_test_2 = model2.predict(X_test)\n\nprint('\\nStage 1 predictions on Test has been obtained.')","2e4c708c":"pred = np.hstack((pred_1, pred_2, pred_1*pred_2, pred_1\/pred_2))\nX_st2 = pd.DataFrame(pred, columns=['f0','f1','f2','f3','f4','q0','q1','q2','q3','q4','fq0','fq1','fq2','fq3','fq4', 'f:g0', 'f:g1', 'f:g2', 'f:g3', 'f:g4'])\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nrf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\nprint(cross_val_score(rf, X_st2, y, cv=5, scoring='accuracy')) \nrf.fit(X_st2, y)","8a2e8f1f":"pred_test = np.hstack((pred_test_1, pred_test_2, pred_test_1*pred_test_2, pred_test_1\/pred_test_2))\nX_test_st2 = pd.DataFrame(pred_test, columns=['f0','f1','f2','f3','f4','q0','q1','q2','q3','q4','fq0','fq1','fq2','fq3','fq4', 'f:g0', 'f:g1', 'f:g2', 'f:g3', 'f:g4'])\npred_sub_test = pd.DataFrame({'Id':ids_test, 'Category': rf.predict(X_test_st2)})\npred_sub_test['Category'] = pred_sub_test.Category.map({0: 'daisy', 1: 'dandelion', 2: 'rose', 3: 'sunflower', 4: 'tulip'})\n\n# Save output\npred_sub_test.to_csv('csv_test.csv', index=False)","09cf8617":"### 2. ResNet50","eb6f3a9d":"## Stage 1","5f6a678f":"### 1. Mobilenet","5fa1e786":"## Predict on Test","76e236d5":"## Stage 2"}}