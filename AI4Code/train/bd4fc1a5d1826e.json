{"cell_type":{"35b6c8be":"code","1676fc5f":"code","ffc1723a":"code","397e19f1":"code","73c04fdc":"code","60b49fc0":"code","8fd2a0b3":"code","15cfa26e":"code","e877e5a6":"code","373f38db":"code","971cb2c1":"code","c3bbac43":"code","f04856f9":"code","9e833475":"code","381d3c96":"code","dedaa45f":"code","e50ad0c0":"markdown","a3fa4d3b":"markdown","0487c246":"markdown","c8dbd7d5":"markdown","cf377d83":"markdown","2ab37278":"markdown","d0417d0a":"markdown","c480d357":"markdown","17ca7307":"markdown","9e21c3db":"markdown","a7b9a0ac":"markdown","39688375":"markdown","f15f00d3":"markdown","196ce94c":"markdown","88042acd":"markdown","63ddbb9a":"markdown","d8fb50dd":"markdown","01414ab5":"markdown","9347be58":"markdown","675668df":"markdown","038d21db":"markdown","451b2ccb":"markdown","a6f6b26d":"markdown","a66e1b58":"markdown","e85ff0c7":"markdown","7d563674":"markdown","54b18ec6":"markdown","1521a9b8":"markdown","b07d64d4":"markdown","1a332a30":"markdown","9cd8bee3":"markdown"},"source":{"35b6c8be":"import pandas as pd\nimport numpy as np\nimport nltk\nimport re\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom collections import Counter","1676fc5f":"# Load the data\ndata = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')\n# Drop unavailable data\ndata = data.dropna()\ndata.head(5)","ffc1723a":"# Count the number of samples in each class\ncnt = data['sentiment'].value_counts()\nplt.figure(figsize=(10,6))\nsns.barplot(cnt.index, cnt.values, alpha=0.8)\nsns.set(style='darkgrid')\nplt.ylabel('Number of Occurrences', fontsize=15)\nplt.xlabel('Classes', fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","397e19f1":"print('=========================Before preprocessing:===========================\\n', data['review'][0])","73c04fdc":"# Get the stopwords\nstopwords = set(nltk.corpus.stopwords.words('english'))\n# Initialize a stemmer to stem each word\nstemmer = nltk.stem.snowball.EnglishStemmer()\n# Add all words that appear in the document into the corpus list\ncorpus = []\n    \n# Define a preprocessing function to convert the raw textual data to cleaned textual data    \ndef Preprocessing(data):\n    # remove all hyperlinks, HTML tags and symbols from the text using regular expression\n    data = re.sub(r\"http\\S+\", \" \", data)\n    data = re.sub(r\"<.*?>\", \" \", data)\n    punctuations ='[\u2019!\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_`{|}~]+'\n    data=re.sub(punctuations,' ',data)\n    words = data.split()\n    processed_words = []\n    # remove stopwords and stem each word\n    for word in words:\n        if word not in stopwords:\n            word = stemmer.stem(word)\n            processed_words.append(word)\n    corpus.extend(processed_words)\n    cleaned_sentence = (\" \").join(processed_words)\n    return cleaned_sentence","60b49fc0":"review = [Preprocessing(i) for i in data['review']]\ndata['review'] = review\nprint('=========================After preprocessing:===========================\\n', data['review'][0])","8fd2a0b3":"review = data['review']\nsentiment = data['sentiment']\n# replace the label with the numerical value: 1 for positive, 0 for negative\nsentiment = sentiment.apply(lambda x: 1 if x == \"positive\" else 0)\nX_train,X_test,y_train,y_test = train_test_split(review,sentiment,test_size=0.1)","15cfa26e":"plt.figure(figsize=(12, 6))\nplt.hist([len(sample.split()) for sample in list(data['review'])], 25)\nplt.xlabel('Length of samples',fontsize=15)\nplt.ylabel('Number of samples',fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nsns.set(style=\"darkgrid\")\nplt.show()","e877e5a6":"counter = Counter(corpus)\n# Get the top 20 common words \nmost_common_words = dict(counter.most_common(20))\nfreq = pd.DataFrame(columns = [\"word\" , 'count'])\nfreq[\"word\"] = list(most_common_words.keys())\nfreq[\"count\"] = list(most_common_words.values())\nplt.figure(figsize=(12, 8))\nplt.xlabel('Count',fontsize=15)\nplt.ylabel('Word',fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nsns.set(style=\"darkgrid\")\nsns.barplot(y = 'word',x = 'count', data = freq, palette=\"Blues_d\")\nplt.show()","373f38db":"# vectorize the data using feature frequency based on unigram\nvectorizer1 = CountVectorizer(analyzer=\"word\",max_features = 10000)\n\n# vectorize the data using feature presence based on unigram\nvectorizer2 = CountVectorizer(analyzer=\"word\",max_features = 10000, binary = True)\n\n# vectorize the data using TF-IDF based on unigram\nvectorizer3 = TfidfVectorizer(analyzer=\"word\",max_features = 10000)\n\n# vectorize the data using feature frequency based on unigram + bigram\nvectorizer4 = CountVectorizer(analyzer=\"word\",max_features = 10000, ngram_range=(1,2))\n\n# vectorize the data using feature presence based on unigram + bigram\nvectorizer5 = CountVectorizer(analyzer=\"word\",max_features = 10000, binary = True, ngram_range=(1,2))\n\n# vectorize the data using TF-IDF based on unigram + bigram\nvectorizer6 = TfidfVectorizer(analyzer=\"word\",max_features = 10000, ngram_range=(1,2))\n\nvectorizers = [vectorizer1, vectorizer2, vectorizer3, vectorizer4, vectorizer5, vectorizer6]","971cb2c1":"accs_val = []\n# Explore the effects of different vectorizers (Feature extraction method)\nfor vectorizer in vectorizers:\n    X_vectorized_train = vectorizer.fit_transform(X_train)\n    X_vectorized_test = vectorizer.transform(X_test)\n    # Support Vector Machine model\n    n_fold = 10\n    model = SGDClassifier(loss=\"hinge\",penalty=\"l2\",shuffle=True, n_jobs=-1)\n    model.fit(X_vectorized_train,y_train)\n    # Cross validate the model\n    acc_val = cross_val_score(model,X_vectorized_train,y_train,cv=n_fold).mean()\n    acc_val = round(acc_val,3)\n    accs_val.append(acc_val)\n    \nresult = pd.DataFrame(np.array(accs_val).reshape((2,3)),columns=['Frequency','Presence', 'TF-IDF'],index=['unigram','unigram+bigram'])\nresult.head().style.format(\"{0:.1%}\")","c3bbac43":"# Test the model based on the best feature extraction method\nX_vectorized_train = vectorizer6.fit_transform(X_train)\nX_vectorized_test = vectorizer6.transform(X_test)\nmodel = SGDClassifier(loss=\"hinge\",penalty=\"l2\",shuffle=True, n_jobs=-1)\nmodel.fit(X_vectorized_train,y_train)\ny_pred = model.predict(X_vectorized_test)\ncm = confusion_matrix(y_test,y_pred)\nsns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\")","f04856f9":"print(classification_report(y_test, y_pred,target_names = ['Negative','Positive']))","9e833475":"accs_val = []\n# Explore the effects of different vectorizers (Feature extraction method)\nfor vectorizer in vectorizers:\n    X_vectorized_train = vectorizer.fit_transform(X_train)\n    X_vectorized_test = vectorizer.transform(X_test)\n    # Logistic Regression model\n    model = SGDClassifier(loss='log',penalty=\"l2\",shuffle=True, n_jobs=-1)\n    model.fit(X_vectorized_train,y_train)\n    n_fold = 10\n    # Cross validate the model\n    acc_val = cross_val_score(model,X_vectorized_train,y_train,cv=n_fold).mean()\n    acc_val = round(acc_val,3)\n    accs_val.append(acc_val)\nresult = pd.DataFrame(np.array(accs_val).reshape((2,3)),columns=['Frequency','Presence', 'TF-IDF'],index=['unigram','unigram+bigram'])\nresult.head().style.format(\"{0:.1%}\")","381d3c96":"# Test the model based on the best feature extraction method\nX_vectorized_train = vectorizer6.fit_transform(X_train)\nX_vectorized_test = vectorizer6.transform(X_test)\nmodel = SGDClassifier(loss=\"log\",penalty=\"l2\",shuffle=True, n_jobs=-1)\nmodel.fit(X_vectorized_train,y_train)\ny_pred = model.predict(X_vectorized_test)\ncm = confusion_matrix(y_test,y_pred)\nsns.heatmap(cm,annot=True,cmap=\"Blues\",fmt=\"d\")","dedaa45f":"print(classification_report(y_test, y_pred, target_names = ['Negative','Positive']))","e50ad0c0":"As shown in the data distribution figure, this dataset is balanced. Each class contains the same amount of data. \nThe dataset includes 25,000 samples for each class, for a total of 50,000 samples","a3fa4d3b":"After the preprocessing, the length distribution figure shows that the length of each sample is typically centralized in the interval of 0 - 400 words.","0487c246":"******\n# 7. Biliography\n\n[1] Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. \"Thumbs up? Sentiment classification using machine learning techniques.\" arXiv preprint cs\/0205070, 2002.\n\n[2] Trstenjak, Bruno, Sasa Mikac, and Dzenana Donko. \"KNN with TF-IDF based framework for text categorization.\" Procedia Engineering 69, 2014.\n\n[3] Medhat, Walaa, Ahmed Hassan, and Hoda Korashy. \"Sentiment analysis algorithms and applications: A survey.\" Ain Shams engineering journal 5.4, 2014.\n\n[4] Hossin, Mohammad, and M. N. Sulaiman. \"A review on evaluation metrics for data classification evaluations.\" International Journal of Data Mining & Knowledge Management Process 5.2, 2015.\n\n[4] Sci-kit Learn Library\n\n[5] Natural Language Toolkit Library\n\n[6] Python Data Analysis Library\n\n[7] NumPy Library\n\n[8] Seaborn Library\n\n[9] Matplotlib Library\n\n[10] Collections Library","c8dbd7d5":"******\n## 3.2 Data preprocessing","cf377d83":"The document demonstrated above is the first sample (raw textual data) from the dataset. It is necessary to preprocess the data before feature extraction:\n1. **HTML tags, punctuations removal**\n\nThere are several HTML tags such as '<br \/ >' and punctuations such as '.', which should be removed from the original text since they are not English words and cannot be considered as features. This process can be done using the regular expression.\n\n2. **Stop words removal**\n\nIt is obvious that there are many words, such as 'of' and 'was', which are not informative. These words are called stop words, which should also be removed to eliminate undesirable features.\n\n3. **Word stemming**\n\nEach word in the original text should also be transformed to its root form.(For example, 'mentioned' in this document is transformed to 'mention') This process is called stemming, which can reasonably reduce the feature complexity. The Python nltk module, a powerful language processing toolkit, provides an English stemmer to stem English words, which is employed in this project. ","2ab37278":"******\n## 4.3 Stochastic Gradient Descent\n\nThe principle of Stochastic Gradient Descent is that we stochastically select a misclassified point and update the weight and offset using formula (obtained from the courseware of lecture 4. page 24):  \n\n$w_{t+1} = w_t - \\epsilon \\frac{dL}{dw_t}$\n\n$\\alpha_{t+1} = \\alpha_t - \\epsilon \\frac{dL}{d\\alpha_t}$,\n\nwhere $\\epsilon$ is the learning rate, which decides how fast the model learns.\n\nThese steps are repeated T times. Since the cost function is convex, the stochastic gradient descent is able to solve the problem. \n","d0417d0a":"******\n# 1. Introduction\nIn recent years, natural language processing has gained huge popularity. Sentiment Analysis, a natural language processing task, is one of the rapidly developing fields of study in computer science. It is a well-known classi\ufb01cation process that extracts and analyses the expressed emotions from the textual data that can be classified as positive or negative polarity according to the underlying sentiment. It is clear that the movie review data can reflect public opinions towards a speci\ufb01c movie. Thus, this is reasonably helpful for mining public opinions. There are several applications that sentiment analysis can contribute to: recommender systems and business intelligence systems. Sentiment analysis is an important task that can be further researched.\nThe input of the proposed model is a movie review, a text document containing several sentences. We preprocess the textual data, utilize several feature engineering techniques to extract features. Two machine learning algorithms: Support Vector Machine and Logistic Regression will be used to predict the corresponding sentiment.\n","c480d357":"Initially, The dataset is loaded in the workspace. The table demonstrates the first 5 rows of the dataset, which contains 2 columns: 'review' and 'sentiment'. \n'review' is the input textual data and 'sentiment' is the corresponding target class.","17ca7307":"******\n# 6. Conclusion and future works\n\n## 6.1 Conclusion\n\nIn this project, several machine learning models are constructed to solve a binary sentiment classification problem. Support Vector Machine and Logistic Regression algorithms are used as two baselines. Moreover, we compare the performance of 6 different feature engineering methods (combinations). It is noticeable that the combination of TF-IDF and Unigram + Bigram gives the best result for both two machine learning techniques. It is assumed that this combination can best identify the importance of a feature in a document. Based on the best combination, the Support Vector Machine can outperform the Logistic Regression by 1%. The best result for this task so far is 89.6% accuracy.\n\n## 6.2 Future works\n\n- There exist words in documents whose first letters are capitalised, which may not be a word but a name of a movie or a role in the movie. This can be replaced by a special symbol in the preprocessing part to further refine the features.\n\n\n- Some negations such as 'not good' or 'not bad' that appear may influence the accuracy of the classification. Thus, in future work, this kind of problem should be mitigated.\n\n\n- It may be better if the contextual information in a document can be taken into consideration for this project rather than merely considering the frequency or presence of features. The feature engineering part is yet to be improved\n","9e21c3db":"# Sentiment Analysis from Movie Review Data\n\n# Name: Yuqi Wang\n\n# ID: 1718891\n\nThe dataset used in this project can be downloaded from kaggle. \n\nhttps:\/\/www.kaggle.com\/lakshmi25npathi\/imdb-dataset-of-50k-movie-reviews. ","a7b9a0ac":"## 5.1 Results of Support Vector Machine","39688375":"Here is the cleaned textual data after preprocessing. Compared with the raw textual data, a significant amount of unwanted features are removed from the original text.","f15f00d3":"From the validation result of the Support Vector Machine model, it is clear that the model based on the combination of TF-IDF and unigram + bigram gives the best result among all combinations. Moreover, the comparison of the feature frequency method and feature presence method does not show much difference. It is not in agreement with Pang and Lee's finding. The overfitting problem does not occur. This is because: 1) The validation accuracy is relatively high. 2) The quantity of the training data is large. 3) We add a $l2$ regularization term to avoid the overfitting problem.","196ce94c":"From the validation result of the Logistic Regression model, it is clear that the model based on the combination of TF-IDF and unigram + bigram gives the best result among all combinations. From the comparison of the unigram model and unigram + bigram model, the unigram + bigram model performs better in this task than the unigram model. We assume that some features which consist of two words are also important for the Logistic Regression model. The overfitting problem does not occur. This is because: 1) The validation accuracy is relatively high. 2) The quantity of the training data is large. 3) We add an l2 regularization term to avoid the overfitting problem.\n","88042acd":"This is a confusion matrix that shows the performance on the testing set of the Support Vector Machine based on the best comibination. According to the color in heatmap, We can see this model can classifiy most of the data correctly.","63ddbb9a":"This is a confusion matrix that shows the performance on the testing set of the Support Vector Machine based on the best comibination. According to the color in heatmap, We can see this model can classifiy most of the data correctly. ","d8fb50dd":"******\nAccording to the feature engineering approaches described above, 6 different vectorizers are constructed to extract features in documents. Then the effects of these methods will be explored in the experiment part.","01414ab5":"Then, 'positive' and 'negative' labels are replaced by the numerical targets: 1 and 0 using the lambda expression. The dataset is split into two subsets: training set and testing set, with 90% of the data and 10% of the data, respectively. ","9347be58":"******\n# 4. Methods\n\nBoth Support Vector Machine and Logistic Regression are trained using Stochastic Gradient Descent. This can be implemented by using the SGDClassifier from the sklearn module in Python. As for Support Vector Machine, we set the parameter 'loss' to 'hinge'. As for Logistic Regression, we set the parameter 'loss' to 'log'.","675668df":"******\n## 3.4 Feature engineering\n### 3.4.1 N-gram model\n\n- **Unigram model**\n\nA unigram model is the most basic case where each feature contains exactly one word \n\n- **Unigram + Bigram model**\n\nThe combination of a Unigram (where each feature contains one word) and a Bigram (where each feature conatins two words) models.","038d21db":"## 4.1. Support Vector Machine\n\n### 4.1.1 Description\n\nSupport Vector Machine can determine a hyperplane to separate the linearly-separable data into different classes. With respect to the non-linearly separable data, Support Vector Machine can \ufb01rstly use a kernel function to map it to a new feature space where the data can be linearly separable and then create a decision surface. Apart from this, it also maximizes the margin between support vectors and the decision surface.\n\n\n### 4.1.2 Loss and Cost function\n\nThis formula is from the courseware of lecture 2, page 37.\n\n$z = y^{(i)}(w\u00b7x^{(i)}+\\alpha)$\n\n$L_h(z) = \\left\\{ \\begin{array}{cl}\n0 & \\text{if} \\ z \\geq 1 \\\\\n1-z & \\text{if}\\ z < 1\n\\end{array} \\right.$\n\nAccording to the hinge loss, points that are inside the slab or misclassified get penalized.\n\n$J(w,\\alpha) = \\frac{1}{n}\\sum_{i=1}^{n}L_h(z^{(i)})+\\frac{\\lambda}{2} \\parallel{w}\\parallel^2 $\n\nThe goal is to minimize the mean loss and maximize the margin (which is $\\frac{1}{\\parallel{w}\\parallel}$), equivalently, minimize the $\\parallel{w}\\parallel^2$","451b2ccb":"## 5.3 Comparison of 2 baselines\n\nFrom the experimental results of two baselines, we could get observations as follows:\n\n1. Based on the feature frequency and feature presence method, the Logistic Regression outperforms the Support Vector Machine.\n\n2. Based on the TF-IDF method, the Support Vector Machine outperforms the Logistic Regression.\n\n3. Based on the best combination feature extraction method for both two techniques, the Support Vector Machine outperforms the Logistic Regression by 1%.","a6f6b26d":"******\n## 4.2. Logistic Regression\n\n### 4.2.1 Description\n\nLogistic Regression firstly calculates the probability using the multiplication of the input and the corresponding linear coefficients followed by a sigmoid function. It uses Binary Cross Entropy Loss as the loss function. This technique is useful for the binary classification problem.\n\n\n### 4.2.2 Loss and Cost function\n\nThis formula is from the courseware of lecture 4, pages 7-10.\n\n$z  =  \\sigma (w\u00b7x +  \\alpha )$ ,where $\\sigma$ is the sigmoid function $\\sigma(\\delta) = \\frac{1}{1 + e^{-\\delta}}$\n\nThis step is to calculate the probability that the point belongs to one class\n\n$L(z,y) = -ylnz - (1 - y) ln ( 1 - z)$\n\nThis is Binary Cross Entropy Loss, where $y\\in (0,1)$ and $z\\in [0,1]$\n\n$J(w,\\alpha) =  \\frac{1}{n}\\sum_{i=1}^nL(z^{(i)},y^{(i)}) $\n\nThe goal is to minimize the mean loss. However, in order to avoid the overfitting problem, in the experimental part, the $l2$-penalty is added to the cost function.","a66e1b58":"The frequency of each word is recorded. This figure shows the top 20 common words that appear in the dataset. Some of them may be fairly essential features from the corpus that can be used to determine the sentiment, while some of them are not related to the polarity but repeat many times.","e85ff0c7":"******\n## 5.2 Results of Logistic Regression","7d563674":"******\n## 3.3 Data visulization","54b18ec6":"******\n# 5. Experiment and results\n\nIn this section, Several machine learning models are constructed. In order to verify the quality of how these models perform this sentiment analysis task, these models firstly are fitted with training data, then 10-fold cross-validation is applied to evaluate their performances using the accuracy metrics:\n\n $accuracy = \\frac{TP + TN}{TP+TN+FP+FN}$ [4],\n \n where TP and TN stand for True Positive and True Negative, FP and FN stand for False Positive and False Negative.\n \n Then, the model with the best performance is selected. It is tested with the testing data. A confusion matrix chart is plotted and a classification report is generated to demonstrate the testing result. In the classification report, precision, recall and f1-score are important metrics. \n \n $precision = \\frac{TP}{TP+FP}$ [4]\n \n $recall = \\frac{TP}{TP+FN}$ [4]\n \n $f1-score = 2 * \\frac{precision*recall}{precision+recall}$ [4]\n \n Since this project aims to find the best approaches to extract the features, the hyperparameters are remained unchanged. We choose the optimal learning rate schedule for each model. Moreover, in the initial exploration, we found that the default setting is the best choice for these two models.\n \nIn the interim report, the preliminary result shows that the highest accuracy of the Support Vector Machine is 84%. This time, after training the model with more data, and applying better data preprocessing and feature extraction methods, we estimate that 87%+ accuracy can be achieved with respect to the data in the testing set. ","1521a9b8":"This model gives a relatively nice performance according to the classification report.","b07d64d4":"******\n### 3.4.2 Feature extraction\nEach sample should be converted to the numerical representation that a machine learning model can accept. Several feature extraction approaches are described in the following:\n\n- **Feature Frequency**\n\nIt mainly counts the number that each feature appears in a document. In this way, each sample can be represented by a vector of feature counts. \n\n- **Feature Presence**\n\nThe feature Presence method is quite similar to the feature frequency method. However, it only takes the presence of a feature in a document into consideration. In this way, each sample can be represented by a vector of feature presence.\n\n\n- **TF-IDF**\n\nTF-IDF is the combination of the feature frequency and the inverse document frequency. It is calculated using this formula:\n\n$tf\\text{-}idf =tf_n(t,d)\u00b7idf(t)$,\n\nwhere $idf(t) = log\\left( \\frac{n_d}{n_d(t)} \\right)$ [2].\n\n$tf_n(t,d)$ is the frequency of feature t in the document d. $n_d$ stands for the number of all documents. $n_d(t)$ stands for the number of documents where the feature t appears\n\nTwo observations can be obtained from the formula: 1). The more frequently a word appears in a document, the more representative it is of the content. 2). The more documents the term appears in, the less discriminating it is. TF-IDF method can directly reflect the relevance of each word in a document. Hence, it has been widely used for document queries and information retrieval.\n","1a332a30":"******\n# 3. Problem Formulation\n\n## 3.1 Dataset description\n\nThe dataset in this project is available at: https:\/\/www.kaggle.com\/lakshmi25npathi\/imdb-dataset-of-50k-movie-reviews. It is a binary sentiment classi\ufb01cation dataset with highly polar movie reviews.","9cd8bee3":"******\n# 2. Related Work\n\nWith the rapid development of advanced and emerging technology, there has been a significant amount of research regarding sentiment analysis and text classification. As Pang and Lee described in their work [1], they make comparisons of different models based on feature frequency and feature presence as feature extraction methods. They found that as for the sentiment analysis task, better performance can be achieved based on feature presence methods. This project also takes these two feature extraction methods into account and explores whether the result is consistent with their work. Trstenjak et al.proposed a KNN model with TF-IDF feature extraction method for text classification [2], which gives a relatively good result. Inspired by this work, we may consider using TF-IDF in the feature engineering part. However, the KNN model may not be suitable for a large dataset and we need to find a better machine learning algorithm instead. Medhat et al. presented several supervised machine learning techniques in a survey paper [3], among which Support Vector Machine is commonly used. Hence, this project employs the Support Vector Machine as one baseline. Besides, we also consider using Logistic Regression which may not be as popular as other machine learning algorithms for the sentiment analysis task.\n"}}