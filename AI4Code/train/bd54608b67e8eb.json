{"cell_type":{"7d8f14ea":"code","c0968e4a":"code","62b570bf":"code","3bb33fb8":"code","e2faabef":"code","bd639154":"code","82456462":"code","2240872c":"code","688d8ce1":"code","8914d6ff":"code","6f6e6ec0":"code","4e6aa396":"code","f5fcd872":"code","95dbc070":"code","87248d6d":"code","362c01a5":"code","684e7165":"code","54c33a9b":"code","4ac50064":"code","ab56d0ad":"code","1d501b26":"code","cfdb3f35":"code","dec6db6f":"code","d1d1e7da":"code","1bb4b889":"code","70074f33":"code","242ddee4":"markdown","ecc5eb04":"markdown","fdb47b35":"markdown","748c801a":"markdown","74826866":"markdown","e0f03264":"markdown"},"source":{"7d8f14ea":"!pip install -q efficientnet_pytorch","c0968e4a":"import time\nimport random\nimport datetime\nimport os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport efficientnet_pytorch\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport matplotlib.pyplot as plt","62b570bf":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(2021)","3bb33fb8":"class DataLoaderConfig:\n    batch_size = 64\n    num_workers = 8\n\n\nclass TrainConfig:\n    criterion = nn.CrossEntropyLoss \n    n_epochs = 2\n    lr = 0.001\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau\n    scheduler_params = dict(\n        mode='min',\n        factor=0.5,\n        patience=1,\n        verbose=False, \n        threshold=0.0001,\n        threshold_mode='abs',\n        cooldown=0, \n        min_lr=1e-8,\n        eps=1e-08\n    )\n    \n\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","e2faabef":"df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\nprint(df.shape)\ndf.head()","bd639154":"y = df['label'].values\nX = df.drop(['label'], axis=1).values","82456462":"X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","2240872c":"class DatasetRetriever(Dataset):\n    def __init__(self, X, y, transforms=None):\n        super().__init__()\n        self.X = X.reshape(-1,28,28).astype(np.float32)\n        self.y = y\n        self.transforms = transforms\n\n    def __getitem__(self, index):\n        image, target = self.X[index], self.y[index]\n        image = np.stack([image] * 3, axis=-1)\n        image \/= 255.\n        if self.transforms:\n            image = self.transforms(image=image)['image']\n            \n        return image, torch.tensor(target, dtype=torch.long)\n\n    def __len__(self):\n        return self.y.shape[0]","688d8ce1":"def get_train_transforms():\n    return A.Compose(\n        [\n            A.Rotate(limit=10, border_mode=cv2.BORDER_REPLICATE, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=2, max_w_size=2, fill_value=0, p=0.5),\n            A.Cutout(num_holes=8, max_h_size=1, max_w_size=1, fill_value=1, p=0.5),\n            A.Resize(28,28, p=1.),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0)\n\ndef get_valid_transforms():\n    return A.Compose(\n        [\n            A.Resize(28,28, p=1.),\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0\n    )","8914d6ff":"train_dataset = DatasetRetriever(\n    X = X_train,\n    y = y_train,\n    transforms=get_train_transforms(),\n)\n\nvalid_dataset = DatasetRetriever(\n    X = X_valid,\n    y = y_valid,\n    transforms=get_valid_transforms(),\n)","6f6e6ec0":"plt.figure(figsize=(12,12))\n\nfor i in range(16):    \n    image, target = train_dataset[random.randint(0, len(train_dataset))]\n    numpy_image = image.permute(1,2,0).cpu().numpy()\n\n    plt.subplot(4,4, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(target.cpu().numpy(), fontsize=10)\n    plt.imshow(numpy_image);","4e6aa396":"train_loader = DataLoader(\n    train_dataset,\n    batch_size=DataLoaderConfig.batch_size,\n    shuffle=True,\n    num_workers=DataLoaderConfig.num_workers,\n)\n\nvalid_loader = DataLoader(\n    valid_dataset, \n    batch_size=DataLoaderConfig.batch_size,\n    shuffle=False,\n    num_workers=DataLoaderConfig.num_workers,\n)","f5fcd872":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n        \nclass AccMeter:\n    def __init__(self):\n        self.true_count = 0\n        self.all_count = 0\n        self.avg = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy().argmax(axis=1).astype(int)\n        self.true_count += (y_true == y_pred).sum()\n        self.all_count += y_true.shape[0]\n        self.avg = self.true_count \/ self.all_count","95dbc070":"class Fitter:\n    def __init__(\n        self, model, device, criterion, n_epochs, \n        lr, sheduler=None, scheduler_params=None\n    ):\n        self.epoch = 0\n        self.n_epochs = n_epochs\n        self.base_dir = '.\/'\n        self.log_path = f'{self.base_dir}\/log.txt'\n        self.best_summary_loss = np.inf\n\n        self.model = model\n        self.device = device\n\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n        \n        if sheduler:\n            self.scheduler = sheduler(self.optimizer, **scheduler_params)\n            \n        self.criterion = criterion().to(self.device)\n        \n        self.log(f'Fitter prepared. Device is {self.device}')\n\n    def fit(self, train_loader, valid_loader):\n        for e in range(self.n_epochs):\n            current_lr = self.optimizer.param_groups[0]['lr']\n            self.log(f'\\n{datetime.datetime.utcnow().isoformat()}\\nLR: {current_lr}')\n\n            t = int(time.time())\n            summary_loss, final_scores = self.train_one_epoch(train_loader)\n            self.log(\n                f'[RESULT]: Train. Epoch: {self.epoch}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s'\n            )\n\n            t = int(time.time())\n            summary_loss, final_scores = self.validation(valid_loader)\n            self.log(\n                f'[RESULT]: Valid. Epoch: {self.epoch}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s'\n            )\n            \n            f_best = 0\n            if summary_loss.avg < self.best_summary_loss:\n                self.best_summary_loss = summary_loss.avg\n                f_best = 1\n            \n            self.scheduler.step(metrics=summary_loss.avg)        \n            self.save(f'{self.base_dir}\/last-checkpoint.bin')\n            \n            if f_best:\n                self.save(f'{self.base_dir}\/best-checkpoint.bin')\n                print('New best checkpoint')\n\n            self.epoch += 1\n\n    def validation(self, val_loader):\n        self.model.eval()\n        summary_loss = LossMeter()\n        final_scores = AccMeter()\n        \n        t = int(time.time())\n        for step, (images, targets) in enumerate(val_loader):\n            print(\n                f'Valid Step {step}\/{len(val_loader)}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s', end='\\r'\n            )\n            \n            with torch.no_grad():\n                targets = targets.to(self.device)\n                images = images.to(self.device)\n                batch_size = images.shape[0]\n                \n                outputs = self.model(images)\n                loss = self.criterion(outputs, targets)\n                \n                final_scores.update(targets, outputs)\n                summary_loss.update(loss.detach().item(), batch_size)\n\n        return summary_loss, final_scores\n\n    def train_one_epoch(self, train_loader):\n        self.model.train()\n        summary_loss = LossMeter()\n        final_scores = AccMeter()\n        \n        t = int(time.time())\n        for step, (images, targets) in enumerate(train_loader):\n            print(\n                f'Train Step {step}\/{len(train_loader)}, ' + \\\n                f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n                f'final_score: {final_scores.avg:.5f}, ' + \\\n                f'time: {int(time.time()) - t} s', end='\\r'\n            )\n            \n            targets = targets.to(self.device)\n            images = images.to(self.device)\n            batch_size = images.shape[0]\n\n            self.optimizer.zero_grad()\n            outputs = self.model(images)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            final_scores.update(targets, outputs.detach())\n            summary_loss.update(loss.detach().item(), batch_size)\n            \n            self.optimizer.step()\n\n        return summary_loss, final_scores\n    \n    def save(self, path):\n        self.model.eval()\n        torch.save({\n            'model_state_dict': self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'scheduler_state_dict': self.scheduler.state_dict(),\n            'best_summary_loss': self.best_summary_loss,\n            'epoch': self.epoch,\n        }, path)\n\n    def load(self, path):\n        checkpoint = torch.load(path)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        self.best_summary_loss = checkpoint['best_summary_loss']\n        self.epoch = checkpoint['epoch'] + 1\n        \n    def log(self, message):\n        print(message)\n        with open(self.log_path, 'a+') as logger:\n            logger.write(f'{message}\\n')","87248d6d":"def get_net():\n    net = efficientnet_pytorch.EfficientNet.from_pretrained('efficientnet-b7')\n    net._fc = nn.Linear(in_features=2560, out_features=10, bias=True)\n    return net\n\nnet = get_net().to(DEVICE)","362c01a5":"fitter = Fitter(\n    model=net, \n    device=DEVICE, \n    criterion=TrainConfig.criterion, \n    n_epochs=TrainConfig.n_epochs, \n    lr=TrainConfig.lr, \n    sheduler=TrainConfig.scheduler, \n    scheduler_params=TrainConfig.scheduler_params\n)","684e7165":"fitter.fit(train_loader, valid_loader)","54c33a9b":"checkpoint = torch.load('..\/working\/best-checkpoint.bin')\nnet.load_state_dict(checkpoint['model_state_dict']);\nnet.eval();","4ac50064":"dfT = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\nprint(dfT.shape)\ndfT.head()","ab56d0ad":"X = dfT.iloc[:,1:].values\ny = dfT.iloc[:,0].values","1d501b26":"class DatasetRetriever(Dataset):\n    def __init__(self, X, transforms=None):\n        super().__init__()\n        self.X = X.reshape(-1, 28,28).astype(np.float32)\n        self.transforms = transforms\n\n    def __getitem__(self, index):\n        image = self.X[index]\n        image = np.stack([image] * 3, axis=-1)\n        image \/= 255.\n        if self.transforms:\n            image = self.transforms(image=image)['image']\n            \n        return image\n\n    def __len__(self):\n        return self.X.shape[0]","cfdb3f35":"test_dataset = DatasetRetriever(\n    X = X,\n    transforms=get_valid_transforms(),\n)","dec6db6f":"test_loader = DataLoader(\n    test_dataset, \n    batch_size=DataLoaderConfig.batch_size,\n    shuffle=False,\n    num_workers=DataLoaderConfig.num_workers\n)","d1d1e7da":"result = []\nfor step, images in enumerate(test_loader):\n    print(step, end='\\r') \n    y_pred = net(images.to(DEVICE)).detach().cpu().numpy().argmax(axis=1).astype(int)    \n    result.extend(y_pred)","1bb4b889":"plt.figure(figsize=(12,12))\n\nfor i in range(16):    \n    image = test_dataset[i]\n    numpy_image = image.permute(1,2,0).cpu().numpy()\n\n    plt.subplot(4,4, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.title(f'Predict: {result[i]}', fontsize=10)\n    plt.imshow(numpy_image);","70074f33":"ANS=y\nPRED=result\naccuracy=accuracy_score(ANS,PRED)\nprint(accuracy)","242ddee4":"## Build Model","ecc5eb04":"## Create DataLoader","fdb47b35":"## Inference Model","748c801a":"## Configuration","74826866":"## Split data","e0f03264":"#### This notebook referred to YAROSLAV ISAIENKOV's notebook 'PyTorch EfficientNet CutOut Augmentation'\nhttps:\/\/www.kaggle.com\/ihelon\/pytorch-efficientnet-cutout-augmentation"}}