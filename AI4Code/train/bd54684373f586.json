{"cell_type":{"64a8ddec":"code","1ffaa900":"code","f9f9fc88":"code","59093d7e":"code","58534538":"code","69bda994":"code","f89ddaf8":"code","647d6ecc":"code","546d160a":"code","083717c2":"code","9738d934":"code","aca313d8":"code","a7b9847f":"code","5e502e49":"code","022d1cde":"code","f2e37acd":"code","23607e38":"code","7ff70de6":"code","21ef7b5f":"code","460148a5":"code","08a6f713":"code","e3290447":"code","dee42aee":"code","788596a8":"code","eabf11ef":"code","2fc06f5a":"code","e008be0a":"code","bb9ca539":"code","04795e5c":"code","f70ed18d":"code","517f1079":"code","4de0413f":"code","3705f35b":"code","6d3e2834":"code","89759d9b":"code","12367c0f":"code","9f929e0b":"code","d4389911":"code","d464b588":"code","cb56c3fe":"code","13806215":"code","7277635e":"code","77004c95":"code","8dfcd73c":"code","849fcd0d":"markdown","71fa26a0":"markdown","5117e206":"markdown","c61c79e9":"markdown","3ab317c9":"markdown","0e75cd73":"markdown","0723e469":"markdown","d41c1187":"markdown","dd0d9b7a":"markdown","69c1cbd4":"markdown","74b459e5":"markdown","1686d6b5":"markdown","a1585ae4":"markdown","d87c80fd":"markdown","a469c17c":"markdown","a666f492":"markdown","e31df64c":"markdown"},"source":{"64a8ddec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for plotting\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ffaa900":"train_data = pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/test.csv\")","f9f9fc88":"print(train_data.shape)\nprint(test_data.shape)\n\nprint('Features : ', train_data.columns.values)\nprint('Features : ', test_data.columns.values)\ntrain_data.head()","59093d7e":"train_data.info()","58534538":"train_data.isnull().sum()","69bda994":"test_data.isnull().sum()","f89ddaf8":"train_data.nunique()","647d6ecc":"train_data[\"Response\"].value_counts(normalize= True)","546d160a":"train_data.describe().transpose()","083717c2":"sns.countplot(train_data[\"Response\"])","9738d934":"sns.distplot(train_data.Age)","aca313d8":"sns.boxplot(y = 'Age', data = train_data)","a7b9847f":"plt.figure(figsize=(12,8))\nsns.scatterplot(x=train_data['Age'],y=train_data['Annual_Premium'])","5e502e49":"sns.countplot(train_data.Gender)","022d1cde":"sns.countplot(train_data.Previously_Insured)","f2e37acd":"sns.countplot(train_data.Vehicle_Age)","23607e38":"sns.countplot(train_data.Vehicle_Damage)","7ff70de6":"sns.distplot(train_data.Annual_Premium)","21ef7b5f":"sns.boxplot(y = 'Annual_Premium', data = train_data)","460148a5":"sns.distplot(train_data.Vintage)","08a6f713":"train_data['Gender'] = train_data['Gender'].map( {'Female': 0, 'Male': 1} ).astype(int)","e3290447":"train_data=pd.get_dummies(train_data,drop_first=True)","dee42aee":"train_data.head()","788596a8":"train_data=train_data.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_lt_1_Year\", \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_gt_2_Years\"})\ntrain_data['Vehicle_Age_lt_1_Year']=train_data['Vehicle_Age_lt_1_Year'].astype('int')\ntrain_data['Vehicle_Age_gt_2_Years']=train_data['Vehicle_Age_gt_2_Years'].astype('int')\ntrain_data['Vehicle_Damage_Yes']=train_data['Vehicle_Damage_Yes'].astype('int')","eabf11ef":"train_data.head()","2fc06f5a":"numeric_features = ['Age','Vintage']\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\nss = StandardScaler()\ntrain_data[numeric_features] = ss.fit_transform(train_data[numeric_features])\n\n\nmm = MinMaxScaler()\ntrain_data[['Annual_Premium']] = mm.fit_transform(train_data[['Annual_Premium']])","e008be0a":"train_data=train_data.drop('id',axis=1)","bb9ca539":"test_data['Gender'] = test_data['Gender'].map( {'Female': 0, 'Male': 1} ).astype(int)\ntest_data=pd.get_dummies(test_data,drop_first=True)\ntest_data=test_data.rename(columns={\"Vehicle_Age_< 1 Year\": \"Vehicle_Age_lt_1_Year\", \n                                    \"Vehicle_Age_> 2 Years\": \"Vehicle_Age_gt_2_Years\"})\ntest_data['Vehicle_Age_lt_1_Year']=test_data['Vehicle_Age_lt_1_Year'].astype('int')\ntest_data['Vehicle_Age_gt_2_Years']=test_data['Vehicle_Age_gt_2_Years'].astype('int')\ntest_data['Vehicle_Damage_Yes']=test_data['Vehicle_Damage_Yes'].astype('int')","04795e5c":"test_data[numeric_features] = ss.transform(test_data[numeric_features])\n\n\nmm = MinMaxScaler()\ntest_data[['Annual_Premium']] = mm.fit_transform(test_data[['Annual_Premium']])","f70ed18d":"plt.figure(figsize=(12,8))\nsns.heatmap(train_data.corr(), annot=True, cmap='viridis')","517f1079":"plt.figure(figsize=(12,6))\ntrain_data.corr()['Response'].drop('Response').sort_values(ascending=False).plot(kind='bar')","4de0413f":"id=test_data.id\ntest_data=test_data.drop('id',axis=1)","3705f35b":"from sklearn.model_selection import train_test_split\n\ntrain_target=train_data['Response']\ntrain_data=train_data.drop(['Response'], axis = 1)\nx_train,x_test,y_train,y_test = train_test_split(train_data,train_target, random_state = 0)","6d3e2834":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=2)\nx_train, y_train = sm.fit_sample(x_train, y_train)","89759d9b":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.metrics import r2_score\nfrom keras import backend as K","12367c0f":"K.clear_session()","9f929e0b":"model = Sequential()\nmodel.add(Dense(11, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(6, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(3, activation='relu'))\nmodel.add(Dropout(0.2))","d4389911":"model.add(Dense(units=1, activation='sigmoid'))","d464b588":"opt = Adam(learning_rate=0.01)\nmodel.compile(loss='binary_crossentropy', optimizer=opt)","cb56c3fe":"early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\nmodel.fit(x=x_train, y=y_train, epochs=100, batch_size=72, validation_data=(x_test, y_test), callbacks=[early_stop])","13806215":"pred = model.predict_classes(x_test)","7277635e":"from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, f1_score, \\\n    recall_score, classification_report, precision_score\n\nprint(classification_report(y_test, pred))\nprint('-----------------------------------------------------------------')\naccuracy = accuracy_score(y_test, pred)\nprecision = precision_score(y_test, pred)\nconfusion = confusion_matrix(y_test, pred)\nrecall = recall_score(y_test, pred)\nf1 = f1_score(y_test, pred)\nprint('-----------------------------------------------------------------')\nprint('accuracy: ', accuracy)\nprint('-----------------------------------------------------------------')\nprint('recall: ', recall)\nprint('-----------------------------------------------------------------')\nprint('precision: ', precision)\nprint('-----------------------------------------------------------------')\nprint('f1_score: ', f1)\nprint('-----------------------------------------------------------------')\nprint('ROC AUC Score:', roc_auc_score(y_test, pred, average = 'weighted'))\nprint('-----------------------------------------------------------------')\nprint('confusion matrix:')\nprint(confusion)\nprint('-----------------------------------------------------------------')\nprint('-----------------------------------------------------------------')","77004c95":"pred = model.predict_classes(test_data)","8dfcd73c":"submission = None\nsubmission = pd.concat([id, pd.DataFrame(columns = ['Prediction'], data = pred)], axis=1)\nsubmission.to_csv('vehicle_insurance_predicted.csv', index = False)\nsubmission.head()","849fcd0d":"# Data Preprocessing","71fa26a0":"<div style=\"text-align:center;color:white;font-size:150%;border-radius:5px;display:fill;background-color:#5642C5;font-family:Verdana;letter-spacing:0.5px;padding: 10px;\" > <br> If you find this is useful make sure to appriciate me with an <b>UPVOTE<\/b> !!! \ud83d\udc4d \n    <br>\n<\/div>\n\n<br>\n\n\n![Suranga Nanayakkara](https:\/\/cdn1.bbcode0.com\/uploads\/2020\/12\/26\/553f26c97fcdb5d167020f64ea95fa51-full.png) \n\n[Lets Connect on LinkedIn!](https:\/\/www.linkedin.com\/in\/surangan\/)","5117e206":"* The most relevant is the relation between \"Response\" and the rest of the variables. \n* We can see some good correlation between Response and \"Vehicle_Damage\"\n* There is a negative relation with binary \"Previously_Insured\" variable.","c61c79e9":"# Problem Statement\n\nOur client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n\nAn insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.\n\nFor example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000\/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000\/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n\nJust like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called \u2018sum assured\u2019) to the customer.","3ab317c9":"* Majority of 20 - 26 Young generation tends to buy a vehicle with a lesser amount\n* There are some cusotmers 40 - 50 Tends to get higher value vehicles","0e75cd73":"Since the target variable is inbalance as a Oversample method used SMOTE to oversample minor class","0723e469":"# Exploratory Data Analysis","d41c1187":"### Encoding Variables for model","dd0d9b7a":"![Health Insurance](https:\/\/image.freepik.com\/free-vector\/health-insurance-vector-illustration_159144-57.jpg)","69c1cbd4":"* There is class inbalnce problem here. Less records for targert variable \"1\"","74b459e5":"* Most of the customer are in 20-27 age group","1686d6b5":"# Import Dataset","a1585ae4":"# Submition Result Data ","d87c80fd":"# Task\n\nBuilding a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue.\n\nNow, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.","a469c17c":"# Create Nural Network","a666f492":"* From above graph it displays there is a negative relationship with Previously Insured Feature and Customers tends to intrested in a Health Insurance when they met with an accident","e31df64c":"## Train Test Split"}}