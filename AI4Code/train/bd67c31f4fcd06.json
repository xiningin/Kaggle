{"cell_type":{"54284379":"code","236710fa":"code","0ff13412":"code","f487ac54":"code","c5cefdb6":"code","ab5b0d4e":"code","fcefd16c":"code","52d29719":"code","4abde06e":"code","da722222":"code","3c99fee9":"code","2c461cbc":"code","a7ee0b02":"code","be8b0fa0":"code","fce60e31":"code","a31d86fe":"code","09d8f885":"markdown","da17af7d":"markdown"},"source":{"54284379":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n# #         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","236710fa":"import os","0ff13412":"imagepaths = []\nfor root,dirs,files in os.walk(\"\/kaggle\/input\/soli-data\/dsp\/\",topdown=False):\n    for name in files:\n        path = os.path.join(root,name)\n        if path.endswith(\"h5\"):\n            imagepaths.append(path)","f487ac54":"print(len(imagepaths))","c5cefdb6":"import h5py\nimport numpy as np","ab5b0d4e":"raw_data=np.empty((1,1024))#creating enpty np\nlabels=np.empty(1)\nfor hfile in imagepaths[:100]: # loading only 10 data\n    with h5py.File(hfile,'r') as f:\n        for channel in range(4):\n            x=f['ch{}'.format(channel)][()]\n            y=f['label'][()]\n           \n            raw_data=np.vstack((raw_data,x)) # stacking row wise\n            labels=np.vstack((labels,y))\n\nraw_data=np.delete(raw_data,0,0)# delete first element\nlabels=np.delete(labels,0,0)","fcefd16c":"print(raw_data.shape, labels.shape)\n","52d29719":"data=raw_data.reshape(raw_data.shape[0],32,32,1)","4abde06e":"from sklearn.model_selection import train_test_split","da722222":"X_train,X_val_test,y_train, y_val_test=train_test_split(data,labels,test_size=.5)","3c99fee9":"X_test,X_val,y_test,y_val=train_test_split(X_val_test,y_val_test,test_size=0.5)","2c461cbc":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense,Flatten","a7ee0b02":"model = Sequential()\nmodel.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,1)))\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dense(12,activation='softmax'))","be8b0fa0":"model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","fce60e31":"history = model.fit(X_train, y_train, epochs=10, batch_size= 32, verbose = 2, validation_data = (X_val, y_val))\n","a31d86fe":"model.evaluate(X_test,y_test)","09d8f885":"total of 5500 .h5 file","da17af7d":"load paths"}}