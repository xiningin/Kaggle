{"cell_type":{"2b29dd34":"code","34b6d5b4":"code","7a4546b6":"code","b7a4c2f2":"code","5ec85908":"code","922712cb":"code","cb561c76":"code","71abe4f4":"code","a38ab854":"code","6a267a06":"code","100bcbad":"code","ec132949":"code","2173428a":"code","eeb78f8c":"code","d30897b4":"code","1548d61a":"code","030c94a0":"code","da3d8593":"code","9a539813":"code","a52c7482":"code","d89556e9":"code","808d15ef":"code","5c612a34":"markdown","e3bf4974":"markdown","7e3c2417":"markdown","765926b1":"markdown"},"source":{"2b29dd34":"##### DEEP LEARNING FOR TABULAR DATA  ##########################\n# The functions used in this Kernel are based on:\n# https:\/\/github.com\/lmassaron\/deep_learning_for_tabular_data\n# You can watch the full tutorial presented at the DEVFEST 2019\n# explaining how to process tabular data with TensorFlow:\n# https:\/\/www.youtube.com\/watch?v=nQgUt_uADSE\n################################################################\n\n!wget https:\/\/raw.githubusercontent.com\/lmassaron\/deep_learning_for_tabular_data\/master\/tabular.py","34b6d5b4":"!pip install scikit-learn -U","7a4546b6":"# Importing core libraries\nimport numpy as np\nimport pandas as pd\nfrom functools import partial\nimport matplotlib.pyplot as plt\nfrom scipy.stats.mstats import winsorize\n\n# Importing from Scikit-Learn\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA, FactorAnalysis\n\n# Importing TensorFlow and Keras\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam, Nadam\nfrom tensorflow.keras.layers import Input, Embedding, Reshape, GlobalAveragePooling1D\nfrom tensorflow.keras.layers import Flatten, concatenate, Concatenate, Lambda, Dropout, SpatialDropout1D\nfrom tensorflow.keras.layers import Reshape, MaxPooling1D,BatchNormalization, AveragePooling1D, Conv1D\nfrom tensorflow.keras.layers import Activation, LeakyReLU\nfrom tensorflow.keras.optimizers import SGD, Adam, Nadam\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2, l1_l2\nfrom keras.losses import MeanSquaredError\nfrom tensorflow.keras.models import load_model\n\nfrom tensorflow.keras.utils import get_custom_objects\nfrom tensorflow.keras.layers import Activation, LeakyReLU\n\n# Importing from Tabular\nfrom tabular import gelu, Mish, mish\nfrom tabular import TabularTransformer, DataGenerator","b7a4c2f2":"# Registering custom activations suitable for tabular problems\n\n# Add gelu so we can use it as a string\nget_custom_objects().update({'gelu': Activation(gelu)})\n\n# Add mish so we can use it as a string\nget_custom_objects().update({'mish': Mish(mish)})\n\n# Add leaky-relu so we can use it as a string\nget_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})","5ec85908":"# Loading data \nX_train = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\")\nX_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")","922712cb":"# Preparing data as a tabular matrix\ny_train = X_train.target\nX_train = X_train.set_index('id').drop('target', axis='columns')\nX_test = X_test.set_index('id')","cb561c76":"# Pointing out categorical features\ncategoricals = [item for item in X_train.columns if 'cat' in item]","71abe4f4":"# Dealing with categorical data using get_dummies\ndummies = pd.get_dummies(X_train.append(X_test)[categoricals])\nX_train[dummies.columns] = dummies.iloc[:len(X_train), :]\nX_test[dummies.columns] = dummies.iloc[len(X_train): , :]\ndel(dummies)","a38ab854":"# Dealing with categorical data using OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\nX_train[categoricals] = ordinal_encoder.fit_transform(X_train[categoricals])\nX_test[categoricals] = ordinal_encoder.transform(X_test[categoricals])","6a267a06":"numerics = [item for item in X_train.columns if 'cont' in item]\n\nfa = FactorAnalysis(rotation='varimax', random_state=0)\nfa.fit(X_train[numerics])\n\nfa_feats = [f'fa_{i}'for i in range(len(numerics))][:2]\n\nX_train[fa_feats] = fa.transform(X_train[numerics])[:,:2]\nX_test[fa_feats] = fa.transform(X_test[numerics])[:,:2]","100bcbad":"# Fixing the numeric variables by quantile transformation\nqt = QuantileTransformer(output_distribution='uniform')\nX_train[numerics] = qt.fit_transform(X_train[numerics])\nX_test[numerics] = qt.transform(X_test[numerics])","ec132949":"# Stratifying the data\nkm = KMeans(n_clusters=32, random_state=0)\npca = PCA(n_components=16, random_state=0)\n\npca.fit(X_train)\nkm.fit(pca.transform(X_train))\n\nprint(np.unique(km.labels_, return_counts=True))\n\ny_stratified = km.labels_","2173428a":"# Feature selection (https:\/\/www.kaggle.com\/lucamassaron\/tutorial-feature-selection-with-boruta-shap)\nimportant_features = ['cat8_E', 'cont0', 'cont5', 'cont7', 'cont8', 'cat1_A', 'cont2', 'cont13', \n                      'cont3', 'cont10', 'cont1', 'cont9', 'cont11', 'cat1', 'cat8_C', 'cont6', \n                      'cont12', 'cat5', 'cat3_C', 'cont4', 'cat8'] + fa_feats\n\nX_train = X_train[important_features]\nX_test = X_test[important_features]","eeb78f8c":"# Classifying variables so we can use appropriately\nnumeric_variables = [item for item in X_train.columns if 'cont' in item] + fa_feats\nlow_card_categoricals = ['cat1', 'cat8_E', 'cat1_A', 'cat8_C', 'cat3_C']\nhigh_card_categoricals = ['cat5', 'cat8']\nordinals = ['cat5', 'cat8']","d30897b4":"# Parametric DNN architecture\n\ndef tabular_dnn(numeric_variables, categorical_variables=None, categorical_counts=None,\n                feature_selection_dropout=0.2, categorical_dropout=0.1,\n                first_dense = 256, second_dense = 256, dense_dropout = 0.2, \n                activation_type=gelu):\n    \n    # Here we pratically deal with everything that is numeric but high cardinality features\n    numerical_inputs = Input(shape=(numeric_variables,))\n    numerical_normalization = BatchNormalization()(numerical_inputs)\n    numerical_feature_selection = Dropout(feature_selection_dropout)(numerical_normalization)\n\n    # Here for each high cardinality feature we build an embedding layer\n    if categorical_variables is not None:\n        categorical_inputs = []\n        categorical_embeddings = []\n        for category in  categorical_variables:\n            categorical_inputs.append(Input(shape=[1], name=category))\n            category_counts = categorical_counts[category]\n            categorical_embeddings.append(\n                Embedding(category_counts+1, \n                          int(np.log1p(category_counts)+1),  # Heuristic for the embedding dimension\n                                                             # feel free to tweak it!\n                          name = category + \"_embed\")(categorical_inputs[-1]))\n\n        if len(categorical_embeddings)==1:\n            categorical_logits = Flatten()(SpatialDropout1D(categorical_dropout)(categorical_embeddings[0]))\n        else:\n            categorical_logits = Concatenate(name = \"categorical_conc\")([Flatten()(SpatialDropout1D(categorical_dropout)(cat_emb)) \n                                                                         for cat_emb in categorical_embeddings])\n    \n        xs = concatenate([numerical_feature_selection, categorical_logits])\n    else:\n        xs = numerical_feature_selection\n        \n    x = Dense(first_dense, activation=activation_type)(xs)\n    x = BatchNormalization()(x)\n    x = Dropout(dense_dropout)(x)  \n    x = Dense(second_dense, activation=activation_type)(x)\n    x = concatenate([x, xs]) # Skip layer, so we present both the original features \n                             # and the DNN processed ones\n    x = BatchNormalization()(x)\n    x = Dropout(dense_dropout)(x)\n    output = Dense(1)(x)\n    \n    if categorical_variables is not None:\n        model = Model([numerical_inputs] + categorical_inputs, output)\n    else:\n        model = Model([numerical_inputs], output)\n    \n    return model\n","1548d61a":"# Useful functions\n\ndef RMSE(y_true, y_pred):\n    return tf.py_function(partial(mean_squared_error, squared=False), (y_true, y_pred), tf.double)\n\ndef MSE(y_true, y_pred):\n    return tf.py_function(partial(mean_squared_error, squared=True), (y_true, y_pred), tf.double)\n\ndef compile_model(model, loss, metrics, optimizer):\n    model.compile(loss=loss, metrics=metrics, optimizer=optimizer)\n    return model\n\ndef plot_keras_history(history, measures):\n    \"\"\"\n    history: Keras training history\n    measures = list of names of measures\n    \"\"\"\n    rows = len(measures) \/\/ 2 + len(measures) % 2\n    fig, panels = plt.subplots(rows, 2, figsize=(15, 5))\n    plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.4, wspace=0.2)\n    try:\n        panels = [item for sublist in panels for item in sublist]\n    except:\n        pass\n    for k, measure in enumerate(measures):\n        panel = panels[k]\n        panel.set_title(measure + ' history')\n        panel.plot(history.epoch, history.history[measure], label=\"Train \"+measure)\n        panel.plot(history.epoch, history.history[\"val_\"+measure], label=\"Validation \"+measure)\n        panel.set(xlabel='epochs', ylabel=measure)\n        panel.legend()\n        \n    plt.show(fig)","030c94a0":"# Global training settings\n\nclass Config:\n    seed = 0\n    folds = 10\n    epochs = 50\n    batch_size = 512","da3d8593":"# Callbacks\n\nmeasure_to_monitor = 'val_RMSE' \nmodality = 'min'\n\nearly_stopping = EarlyStopping(monitor=measure_to_monitor, \n                               mode=modality, \n                               patience=5, \n                               verbose=0)\n\nreduce_lr_on_plateau = ReduceLROnPlateau(monitor=measure_to_monitor,\n                                         mode=modality,\n                                         patience=2,\n                                         factor=0.5,\n                                         verbose=0)\n\nmodel_checkpoint = ModelCheckpoint('best.model', \n                                   monitor=measure_to_monitor, \n                                   mode=modality, \n                                   save_best_only=True, \n                                   verbose=0)","9a539813":"# Setting the CV strategy\nskf = StratifiedKFold(n_splits=Config.folds, \n                      shuffle=True, \n                      random_state=Config.seed)\n\n# CV Iteration\nscore = list()\noof = np.zeros(len(X_train))\nbest_iteration = list()\ntest_preds = np.zeros(len(X_test))\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X_train, y_stratified)):\n    \n    tb = TabularTransformer(numeric = numeric_variables,\n                            ordinal = ordinals,\n                            lowcat  = low_card_categoricals,\n                            highcat = high_card_categoricals)\n\n    tb.fit(X_train.iloc[train_idx])\n    sizes = tb.shape(X_train.iloc[train_idx])\n    categorical_levels = dict(zip(high_card_categoricals, sizes[1:]))\n    print(f\"Input array sizes: {sizes}\")\n    print(f\"Categorical levels: {categorical_levels}\\n\")\n    \n    model = tabular_dnn(numeric_variables=sizes[0],\n                        categorical_variables=high_card_categoricals,\n                        categorical_counts=categorical_levels, \n                        feature_selection_dropout=0.0,\n                        categorical_dropout=0.0,\n                        first_dense = 128,\n                        second_dense = 128,\n                        dense_dropout = 0.1,\n                        activation_type='mish')\n    \n    model = compile_model(model, \n                          loss='mean_squared_error', \n                          metrics=[MSE, RMSE], \n                          optimizer=Adam(learning_rate=0.001)\n                         )\n    \n    train_batch = DataGenerator(X_train.iloc[train_idx],\n                                np.array(winsorize(y_train[train_idx], [0.002, 0.0])),\n                                tabular_transformer=tb,\n                                batch_size=Config.batch_size,\n                                shuffle=True)\n    \n    history = model.fit(train_batch,\n                        validation_data=(tb.transform(X_train.iloc[test_idx]), y_train[test_idx]),\n                        epochs=Config.epochs,\n                        callbacks=[model_checkpoint, reduce_lr_on_plateau, early_stopping],\n                        verbose=1)\n    \n    print(\"\\nFOLD %i\" % fold)\n    plot_keras_history(history, measures=['RMSE', 'MSE'])\n    \n    best_iteration.append(np.argmin(history.history['val_RMSE']) + 1)\n    model = load_model('best.model', custom_objects = {\"gelu\": gelu, \"mish\": mish, 'MSE': MSE, 'RMSE': RMSE})\n\n    preds = model.predict(tb.transform(X_train.iloc[test_idx]),\n                          verbose=1,\n                          batch_size=1024).flatten()\n\n    oof[test_idx] = preds\n    score.append(mean_squared_error(y_true=y_train[test_idx], y_pred=preds, squared=False))\n    \n    # For each fold we make a prediction\n    test_preds += model.predict(tb.transform(X_test[X_train.columns]),\n                                verbose=1,\n                                batch_size=1024).flatten()\n\n# Since we cumulated predictions, we divide them by the number of folds \ntest_preds \/= Config.folds","a52c7482":"print(\"Average RMSE %0.3f \u00b1 %0.3f\" % (np.mean(score), np.std(score)))\nprint(\"RMSE OOF %0.3f\" % mean_squared_error(y_true=y_train, y_pred=oof, squared=False))","d89556e9":"# Predicting and submission\nsubmission = pd.DataFrame({'id':X_test.index, \n                           'target': test_preds.ravel()})\n\nsubmission.to_csv(\"submission.csv\", index=False)","808d15ef":"submission","5c612a34":"If you would like a more step-by-step explanation of all the solution in this notebook, just a look at the presentation I gave at the 2019 DevFest in Venice: \n\nhttps:\/\/www.youtube.com\/watch?v=nQgUt_uADSE\n\nand consult the Github repository:\n\nhttps:\/\/github.com\/lmassaron\/deep_learning_for_tabular_data\n\nI've also tried to comment as much as possible the code, but if you have specific questions, just write to me in the comments!","e3bf4974":"If a categorical variable as many different levels, convert it into numeric labels and use an embedding layer (*Guo, Cheng, and Felix Berkhahn. \"Entity embeddings of categorical variables.\"\u00a0arXiv preprint arXiv:1604.06737, 2016*).\n\nAn embedding layers is just a matrix of weights, converting the input size (a numbered dictionary) to a lower dimensionality output (the embedding size).\n\nIt is a weighted linear combination whose weights are optimized to prediction.\n\nThe resulting embedding is exportable and reusable for other problems.\n\nHow does and embedding layer work? Here is simple example:\n\n![image.png](attachment:5227e368-db33-46d6-9957-98ebffd7c7b7.png)\n\nThe interesting part of this approach is that you can store away the embeddings and re-use them for other problems of yours if based on the same or similar variabiles (a kind of pre-training). Just have a look at these inspiring examples:\n\nPinterest: \u201cApplying deep learning to Related Pins\u201d (Pin2vec : https:\/\/medium.com\/the-graph\/applying-deep-learning-to-related-pins-a6fee3c92f5e)\n\nInstacart: \u201cDeep Learning with Emojis (not Math)\u201d (embeddings for grocery items: https:\/\/tech.instacart.com\/deep-learning-with-emojis-not-math-660ba1ad6cdc)","7e3c2417":"Apart from feature engineering (more on this a following tutorial), the most effective action that you can take with your data when building a DNN for a tabular problem is to treat your variables accordinly to their type:\n\n* numeric variables -> clean and standardize\n* ordinal data -> transform into multiple variables: ordinal encode + one hot encoding\n* categorical data with few levels (low categorical) -> one hot encode\n* categorical data with many levels (high categorical) -> use embedding layers","765926b1":"![image.png](attachment:7c0608e5-7f7b-4af9-ae54-1f360f2b007e.png)\n\nAs the competition goes on, GBMs seem to dominate the scene. But I believe that Deep Learning can still play its part in the game. I've already seen some notebook that applied TabNet, but with this notebook I would like to provide you with the basics to create your own deep neural network (DNN) for this problem.\n\nFirst of all, it is not really easy to create a DNN for tabular data:\n\n* Mixed features data types\n* Sparse data which is not the best for DNN\n* No SOTA\/ best practice architecture\n* Less data than in image recognition problems\n* There\u2019s suspect from non technical people because DNN are less interpretable than simpler ML algorithms\n* Often no best in class solution, because GBM might perform better\n\nBut in the end, if you follow these suggestions (some already covered by 30 Days of ML), you will surely succeed:\n\n* It takes some effort, don\u2019t expect an automated process or great results at once\n* Don\u2019t re-invent the wheel: use TensorFlow\/Keras, Scikit-learn, Pandas for your project\n* Process and pipeline input accordingly to its type\n* Create a suitable neural architecture keeping into account the number of available examples\n* Encode prior knowledge (do feature engineering)\n* Test and tune your network using cross validation"}}