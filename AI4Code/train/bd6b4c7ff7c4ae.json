{"cell_type":{"cab50bf3":"code","60a8a6e6":"code","e27d8f5e":"code","1b2a3423":"code","ddb2f991":"code","5c744525":"code","cc0c0103":"code","c9a07261":"code","690629d2":"code","0cfd76ac":"code","885253dd":"code","3b5e6f24":"code","78a73b3c":"code","42cd4c0d":"code","8c9c0650":"code","d28f0972":"code","86a413b8":"code","a01af8c6":"code","9abeedc8":"markdown","92c56326":"markdown","4e473adf":"markdown","2542fceb":"markdown","6130504a":"markdown"},"source":{"cab50bf3":"package_path = '..\/input\/pytorch-image-models\/pytorch-image-models-master' #'..\/input\/efficientnet-pytorch-07\/efficientnet_pytorch-0.7.0'\nimport sys; sys.path.append(package_path)","60a8a6e6":"from glob import glob\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport cv2\nfrom skimage import io\nimport torch\nfrom torch import nn\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport torchvision\nfrom torchvision import transforms\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom  torch.cuda.amp import autocast, GradScaler\n\nimport sklearn\nimport warnings\nimport joblib\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn import metrics\nimport warnings\nimport cv2\nimport pydicom\nimport timm #from efficientnet_pytorch import EfficientNet\nfrom scipy.ndimage.interpolation import zoom\nfrom sklearn.metrics import log_loss","e27d8f5e":"train = pd.read_csv('..\/input\/cassava-leaf-disease-merged\/merged.csv')\ntrain.head()","1b2a3423":"train.label.value_counts()","ddb2f991":"submission = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\nsubmission.head()","5c744525":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \ndef get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    #print(im_rgb)\n    return im_rgb\n\nimg = get_img('..\/input\/cassava-leaf-disease-classification\/train_images\/1000015157.jpg')\nplt.imshow(img)\nplt.show()","cc0c0103":"class CassavaDataset(Dataset):\n    def __init__(\n        self, df, data_root, transforms=None, output_label=True\n    ):\n        \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.output_label = output_label\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.df.iloc[index]['label']\n          \n        path = \"{}\/{}\".format(self.data_root, self.df.iloc[index]['image_id'])\n        \n        img  = get_img(path)\n        \n        if self.transforms:\n            img = self.transforms(image=img)['image']\n            \n        # do label smoothing\n        if self.output_label == True:\n            return img, target\n        else:\n            return img","c9a07261":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_train_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n  \n        \ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\ndef get_inference_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","690629d2":"def inference_one_epoch(model, data_loader, device):\n    model.eval()\n\n    image_preds_all = []\n    \n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs) in pbar:\n        imgs = imgs.to(device).float()\n        \n        image_preds = model(imgs)   #output = model(input)\n        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n        \n    \n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","0cfd76ac":"# ld-efficientnet-b4-best\n\nCFG = {\n    'fold_num': 6,\n    'n_class':5,\n    'seed': 42,\n    'model_arch': 'tf_efficientnet_b4_ns',\n    'img_size': 512,\n    'epochs': 32,\n    'train_bs': 8,\n    'valid_bs': 8,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'tta': 3,\n    'used_epochs': [0,1,2,3],\n    'weights': [1,1,1,1]\n}\n\nclass CustomEfficientNet(nn.Module):\n    def __init__(self, model_name=CFG['model_arch'], pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(CFG['model_arch'], pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, CFG['n_class'])\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nseed_everything(CFG['seed'])\n\nfolds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n\nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    # we'll train fold 0 first\n    if fold > 0:\n        break \n\n    print('Inference fold {} started'.format(fold))\n    \n    test = pd.DataFrame()\n    test['image_id'] = list(os.listdir('..\/input\/cassava-leaf-disease-classification\/test_images\/'))\n    test_ds = CassavaDataset(test, '..\/input\/cassava-leaf-disease-classification\/test_images\/', transforms=get_inference_transforms(), output_label=False)\n    \n    tst_loader = torch.utils.data.DataLoader(\n        test_ds, \n        batch_size=CFG['valid_bs'],\n        num_workers=CFG['num_workers'],\n        shuffle=False,\n        pin_memory=False,\n    )\n\n    device = torch.device(CFG['device'])\n    model = CustomEfficientNet(CFG['model_arch']).to(device)\n    \n    tst_preds = []\n    \n    for i, epoch in enumerate(CFG['used_epochs']):    \n        model.load_state_dict(torch.load('..\/input\/ld-efficientnet-b4-best\/{}_fold{}_{}'.format(CFG['model_arch'], fold, epoch)))\n        \n        with torch.no_grad():\n            for _ in range(CFG['tta']):\n                tst_preds += [CFG['weights'][i]\/sum(CFG['weights'])\/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n\n    tst_preds = np.mean(tst_preds, axis=0) \n    \n    del model\n    torch.cuda.empty_cache()\n    \ntst_preds_0 = tst_preds","885253dd":"# ld-efficientnet-b3-best\n\nCFG = {\n    'fold_num': 6,\n    'n_class':5,\n    'seed': 42,\n    'model_arch': 'tf_efficientnet_b3_ns',\n    'img_size': 512,\n    'epochs': 32,\n    'train_bs': 8,\n    'valid_bs': 8,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'tta': 3,\n    'used_epochs': [0,1,2,3],\n    'weights': [1,1,1,1]\n}\n\nclass CustomEfficientNet(nn.Module):\n    def __init__(self, model_name=CFG['model_arch'], pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(CFG['model_arch'], pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, CFG['n_class'])\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nseed_everything(CFG['seed'])\n\nfolds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n\nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    # we'll train fold 0 first\n    if fold > 0:\n        break \n\n    print('Inference fold {} started'.format(fold))\n    \n    test = pd.DataFrame()\n    test['image_id'] = list(os.listdir('..\/input\/cassava-leaf-disease-classification\/test_images\/'))\n    test_ds = CassavaDataset(test, '..\/input\/cassava-leaf-disease-classification\/test_images\/', transforms=get_inference_transforms(), output_label=False)\n    \n    tst_loader = torch.utils.data.DataLoader(\n        test_ds, \n        batch_size=CFG['valid_bs'],\n        num_workers=CFG['num_workers'],\n        shuffle=False,\n        pin_memory=False,\n    )\n\n    device = torch.device(CFG['device'])\n    model = CustomEfficientNet(CFG['model_arch']).to(device)\n    \n    tst_preds = []\n    \n    for i, epoch in enumerate(CFG['used_epochs']):    \n        model.load_state_dict(torch.load('..\/input\/ld-efficientnet-b3-best\/{}_fold{}_{}'.format(CFG['model_arch'], fold, epoch)))\n        \n        with torch.no_grad():\n            for _ in range(CFG['tta']):\n                tst_preds += [CFG['weights'][i]\/sum(CFG['weights'])\/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n\n    tst_preds = np.mean(tst_preds, axis=0) \n    \n    del model\n    torch.cuda.empty_cache()\n    \n    \ntst_preds_1 = tst_preds","3b5e6f24":"# ld-pytrch-effnet-b3-lr-lbs-valprv\n\nCFG = {\n    'fold_num': 6,\n    'n_class':5,\n    'seed': 42,\n    'model_arch': 'tf_efficientnet_b3_ns',\n    'img_size': 512,\n    'epochs': 32,\n    'train_bs': 8,\n    'valid_bs': 8,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'tta': 3,\n    'used_epochs': [5,6,8,9],\n    'weights': [1,1,1,1]\n}\n\nclass CassvaImgClassifier(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nseed_everything(CFG['seed'])\n\nfolds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n\nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    # we'll train fold 0 first\n    if fold > 0:\n        break \n\n    print('Inference fold {} started'.format(fold))\n    \n    test = pd.DataFrame()\n    test['image_id'] = list(os.listdir('..\/input\/cassava-leaf-disease-classification\/test_images\/'))\n    test_ds = CassavaDataset(test, '..\/input\/cassava-leaf-disease-classification\/test_images\/', transforms=get_inference_transforms(), output_label=False)\n    \n    tst_loader = torch.utils.data.DataLoader(\n        test_ds, \n        batch_size=CFG['valid_bs'],\n        num_workers=CFG['num_workers'],\n        shuffle=False,\n        pin_memory=False,\n    )\n\n    device = torch.device(CFG['device'])\n    model = CassvaImgClassifier(CFG['model_arch'], CFG['n_class']).to(device)\n    \n    tst_preds = []\n    \n    for i, epoch in enumerate(CFG['used_epochs']):    \n        model.load_state_dict(torch.load('..\/input\/ld-pytrch-effnet-b3-lr-lbs-valprv-train\/{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch)))\n        \n        with torch.no_grad():\n            for _ in range(CFG['tta']):\n                tst_preds += [CFG['weights'][i]\/sum(CFG['weights'])\/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n\n    tst_preds = np.mean(tst_preds, axis=0) \n    \n    del model\n    torch.cuda.empty_cache()\n    \ntst_preds_2 = tst_preds","78a73b3c":"# ld-pytorch-tpu-vit-base-patch16-tcel-vldprv-train\n\nCFG = {\n    'fold_num': 6,\n    'n_class':5,\n    'seed': 42,\n    'model_arch': 'vit_base_patch16_384',\n    'img_size': 384,\n    'epochs': 32,\n    'train_bs': 8,\n    'valid_bs': 8,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'tta': 3,\n    'used_epochs': [3,5,7,11],\n    'weights': [1,1,1,1]\n}\n\nclass CustomViT(nn.Module):\n    def __init__(self, model_name=CFG['model_arch'], pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, CFG['n_class'])\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nseed_everything(CFG['seed'])\n\nfolds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n\nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    # we'll train fold 0 first\n    if fold > 0:\n        break \n\n    print('Inference fold {} started'.format(fold))\n    \n    test = pd.DataFrame()\n    test['image_id'] = list(os.listdir('..\/input\/cassava-leaf-disease-classification\/test_images\/'))\n    test_ds = CassavaDataset(test, '..\/input\/cassava-leaf-disease-classification\/test_images\/', transforms=get_inference_transforms(), output_label=False)\n    \n    tst_loader = torch.utils.data.DataLoader(\n        test_ds, \n        batch_size=CFG['valid_bs'],\n        num_workers=CFG['num_workers'],\n        shuffle=False,\n        pin_memory=False,\n    )\n\n    device = torch.device(CFG['device'])\n    model = CustomViT(CFG['model_arch']).to(device)\n    \n    tst_preds = []\n    \n    for i, epoch in enumerate(CFG['used_epochs']):    \n        model.load_state_dict(torch.load('..\/input\/ld-pytorch-tpu-vit-base-patch16-tcel-vldprv-train\/{}_fold{}_{}'.format(CFG['model_arch'], fold, epoch)))\n        \n        with torch.no_grad():\n            for _ in range(CFG['tta']):\n                tst_preds += [CFG['weights'][i]\/sum(CFG['weights'])\/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n\n    tst_preds = np.mean(tst_preds, axis=0) \n        \n    del model\n    torch.cuda.empty_cache()\n    \ntst_preds_3 = tst_preds","42cd4c0d":"# ld-pytorch-tpu-resnext50-tcel-1-vldprv-train\n\nCFG = {\n    'fold_num': 6,\n    'n_class':5,\n    'seed': 42,\n    'model_arch': 'resnext50_32x4d',\n    'img_size': 512,\n    'epochs': 32,\n    'train_bs': 8,\n    'valid_bs': 8,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'tta': 3,\n    'used_epochs': [3,4,6,10],\n    'weights': [1,1,1,1]\n}\n\nclass CustomResNext(nn.Module):\n    def __init__(self, model_name=CFG['model_arch'], pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(CFG['model_arch'], pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, CFG['n_class'])\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nseed_everything(CFG['seed'])\n\nfolds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n\nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    # we'll train fold 0 first\n    if fold > 0:\n        break \n\n    print('Inference fold {} started'.format(fold))\n    \n    # overwrite to point to prev data\n    val_idx = train[train[\"source\"]==2019].index\n    \n    test = pd.DataFrame()\n    test['image_id'] = list(os.listdir('..\/input\/cassava-leaf-disease-classification\/test_images\/'))\n    test_ds = CassavaDataset(test, '..\/input\/cassava-leaf-disease-classification\/test_images\/', transforms=get_inference_transforms(), output_label=False)\n    \n    tst_loader = torch.utils.data.DataLoader(\n        test_ds, \n        batch_size=CFG['valid_bs'],\n        num_workers=CFG['num_workers'],\n        shuffle=False,\n        pin_memory=False,\n    )\n\n    device = torch.device(CFG['device'])\n    model = CustomResNext(CFG['model_arch']).to(device)\n    \n    tst_preds = []\n    \n    for i, epoch in enumerate(CFG['used_epochs']):    \n        model.load_state_dict(torch.load('..\/input\/ld-pytorch-tpu-resnext50-tcel-vldprv-train\/{}_fold{}_{}'.format(CFG['model_arch'], fold, epoch)))\n        \n        with torch.no_grad():\n            for _ in range(CFG['tta']):\n                tst_preds += [CFG['weights'][i]\/sum(CFG['weights'])\/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n\n    tst_preds = np.mean(tst_preds, axis=0) \n    \n    del model\n    torch.cuda.empty_cache()\n    \ntst_preds_4 = tst_preds","8c9c0650":"# ld-pytorch-tpu-effnet-b4-gws-prtr-vldprv\n\nCFG = {\n    'fold_num': 6,\n    'n_class':5,\n    'seed': 42,\n    'model_arch': 'tf_efficientnet_b4_ns',\n    'img_size': 512,\n    'epochs': 32,\n    'train_bs': 8,\n    'valid_bs': 8,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'tta': 3,\n    'used_epochs': [2,4,10,13],\n    'weights': [1,1,1,1]\n}\n\nclass CustomEfficientNet(nn.Module):\n    def __init__(self, model_name=CFG['model_arch'], pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(CFG['model_arch'], pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, CFG['n_class'])\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n\nseed_everything(CFG['seed'])\n\nfolds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n\nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    # we'll train fold 0 first\n    if fold > 0:\n        break \n\n    print('Inference fold {} started'.format(fold))\n    \n    test = pd.DataFrame()\n    test['image_id'] = list(os.listdir('..\/input\/cassava-leaf-disease-classification\/test_images\/'))\n    test_ds = CassavaDataset(test, '..\/input\/cassava-leaf-disease-classification\/test_images\/', transforms=get_inference_transforms(), output_label=False)\n    \n    tst_loader = torch.utils.data.DataLoader(\n        test_ds, \n        batch_size=CFG['valid_bs'],\n        num_workers=CFG['num_workers'],\n        shuffle=False,\n        pin_memory=False,\n    )\n\n    device = torch.device(CFG['device'])\n    model = CustomEfficientNet(CFG['model_arch']).to(device)\n    \n    tst_preds = []\n    \n    for i, epoch in enumerate(CFG['used_epochs']):    \n        model.load_state_dict(torch.load('..\/input\/ld-pytorch-tpu-effnet-b4-gws-prtr-vldprv\/{}_fold{}_{}'.format(CFG['model_arch'], fold, epoch)))\n        \n        with torch.no_grad():\n            for _ in range(CFG['tta']):\n                tst_preds += [CFG['weights'][i]\/sum(CFG['weights'])\/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n\n    tst_preds = np.mean(tst_preds, axis=0) \n    \n    del model\n    torch.cuda.empty_cache()\n    \ntst_preds_5 = tst_preds","d28f0972":"# blend - CV scores used to otimise the weights =============================================================\ntst_preds = (tst_preds_0*0.7 + tst_preds_1*0.3)*0.25 + tst_preds_2*0.25 + tst_preds_3*0.25 + tst_preds_4*0.1 + tst_preds_5*0.15","86a413b8":"test['label'] = np.argmax(tst_preds, axis=1)\ntest.head()","a01af8c6":"test.to_csv('submission.csv', index=False)","9abeedc8":"# Dataset","92c56326":"# Define Train\\Validation Image Augmentations","4e473adf":"# Helper Functions","2542fceb":"## My best submission Private LB 0.902\/Public LB 0.901 - would have been in the money\/gold medal zone\n![image.png](attachment:image.png)\n\n### General approach\n* Final models were trained on the FULL data.\n* Still used CV for validation\/evaluation purposes only.\n\n### Models\neffnet b3\/b4, vit, resnext50 architectures\nLabel Smoothing\nVarious loss functions: CE, Symmetric CE, Taylor CE\nVarious schedulers: Gradual Warmup\/CosineAnnealingWarmRestarts\nAugmentation: played mostly around crops\/cutmix apart from the standard techniques.\nData:\nonly 2020\npretrain on 2019, train on 2020\ntrain on both (one pass)\n\n### Ensemble:\nHierarchical blend:\n* Blended different epoch\/best of kind models first\n* Then blended the already blended \u201csuper\u201d models\n* Used CV to optimise the weights\n\nYou can find more details on my approach here: https:\/\/www.kaggle.com\/c\/cassava-leaf-disease-classification\/discussion\/220752\n\nInference code taken with modifications from this wonderful notebook (please upvote it): https:\/\/www.kaggle.com\/khyeh0719\/pytorch-efficientnet-baseline-inference-tta","6130504a":"# Model"}}