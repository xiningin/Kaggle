{"cell_type":{"4243c503":"code","80d956fa":"code","0a740906":"code","9d1e0789":"code","a5b97316":"code","7b55b2bb":"code","0819c215":"code","d63ffd83":"code","df870acf":"code","cca8c333":"code","c3e1428b":"code","44619934":"code","4b03feee":"code","4a9bb8be":"code","06fdca04":"markdown","5623a8bd":"markdown","636c67db":"markdown","38276647":"markdown","94ba456a":"markdown"},"source":{"4243c503":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","80d956fa":"data = pd.read_csv('..\/input\/horse-colic\/horse.csv')","0a740906":"data","9d1e0789":"data.info()","a5b97316":"X['mucous_membrane']","7b55b2bb":"def binary_encode(df, columns, positive_values):\n    df = df.copy()\n    for column, positive_value in zip(columns, positive_values):\n        df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n    return df\n\ndef ordinal_encode(df, columns, orderings):\n    df = df.copy()\n    for column, ordering in zip(columns, orderings):\n        df[column] = df[column].apply(lambda x: ordering.index(x))\n    return df\n\ndef onehot_encode(df, columns, prefixes):\n    df = df.copy()\n    for column, prefix in zip(columns, prefixes):\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","0819c215":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Categorize categorical features\n    binary_features = [\n        'surgery',\n        'age',\n        'surgical_lesion',\n        'cp_data'\n    ]\n    positive_values = [\n        'yes',\n        'adult',\n        'yes',\n        'yes'\n    ]\n    \n    ordinal_features = [\n        'temp_of_extremities',\n        'peripheral_pulse',\n        'capillary_refill_time',\n        'pain',\n        'peristalsis',\n        'abdominal_distention',\n        'nasogastric_tube',\n        'nasogastric_reflux',\n        'rectal_exam_feces'    \n    ]\n    orderings = [\n        ['cold', 'cool', 'normal', 'warm'],\n        ['absent', 'reduced', 'normal', 'increased'],\n        ['less_3_sec', '3', 'more_3_sec'],\n        ['alert', 'depressed', 'mild_pain', 'severe_pain', 'extreme_pain'],\n        ['absent', 'hypomotile', 'normal', 'hypermotile'],\n        ['none', 'slight', 'moderate', 'severe'],\n        ['none', 'slight', 'significant'],\n        ['none', 'less_1_liter', 'more_1_liter'],\n        ['absent', 'decreased', 'normal', 'increased']\n    ]\n    \n    nominal_features = [\n        'hospital_number',\n        'mucous_membrane',\n        'abdomen',\n        'abdomo_appearance'\n    ]\n    prefixes = [\n        'HN',\n        'MM',\n        'AB',\n        'AA'\n    ]\n    \n    # Fill missing values\n    for column in df.columns:\n        if column in df.select_dtypes('object').columns:\n            if column not in nominal_features:\n                df[column] = df[column].fillna(df[column].mode()[0])\n        else:\n            df[column] = df[column].fillna(df[column].mean())\n    \n    # Encode categorical feature columns\n    df = binary_encode(df, columns=binary_features, positive_values=positive_values)\n    df = ordinal_encode(df, columns=ordinal_features, orderings=orderings)\n    df = onehot_encode(df, columns=nominal_features, prefixes=prefixes)\n    \n    # Encode labels\n    label_mapping = {'lived': 0, 'died': 1, 'euthanized': 2}\n    df['outcome'] = df['outcome'].replace(label_mapping)\n    \n    # Split df into X and y\n    y = df['outcome'].copy()\n    X = df.drop('outcome', axis=1).copy()\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n    \n    return X, y","d63ffd83":"X, y = preprocess_inputs(data)","df870acf":"{column: list(X[column].unique()) for column in X.select_dtypes('object').columns}","cca8c333":"X","c3e1428b":"y.value_counts()","44619934":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)","4b03feee":"model = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\nprint(\"Decision Tree Accuracy: {:.2f}%\".format(model.score(X_test, y_test) * 100))","4a9bb8be":"ensemble_model = RandomForestClassifier()\nensemble_model.fit(X_train, y_train)\n\nprint(\"Random Forest Accuracy: {:.2f}%\".format(ensemble_model.score(X_test, y_test) * 100))","06fdca04":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/oXUDU101e2c","5623a8bd":"# Preprocessing","636c67db":"# Getting Started","38276647":"# Training","94ba456a":"# Task for Today  \n\n***\n\n## Horse Survival Prediction  \n\nGiven *medical data about horses*, let's try to predict whether a given horse will **survive** or not.  \n  \nWe will use a descision tree classifier and a random forest classifier to make our predictions."}}