{"cell_type":{"5ebbd54b":"code","f38e0337":"code","00d37602":"code","156542ca":"code","1615c33a":"code","f46b1272":"markdown","3c7a0569":"markdown","ec93c514":"markdown","9dd14a89":"markdown","b656254d":"markdown","eea9c2b7":"markdown"},"source":{"5ebbd54b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nfrom matplotlib_venn import venn2\nimport seaborn as sns\nsns.set_context(\"talk\")\n# sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\nstyle.use('fivethirtyeight')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f38e0337":"train = pd.read_csv(\"\/kaggle\/input\/data-without-drift-with-kalman-filter\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/data-without-drift-with-kalman-filter\/test.csv\")","00d37602":"train_signal = train[\"signal\"].values.reshape(-1,500000)\ntest_signal = test[\"signal\"].values.reshape(-1,500000)","156542ca":"fig, ax = plt.subplots(5, 2, figsize=(15, 18), sharey=\"all\")\nax = ax.flatten()\nfor i, a in enumerate(ax):\n    a.acorr(train_signal[i,::1000], usevlines=False, normed=True, maxlags=50, lw=.5, alpha=0.2, color=\"k\");\n    a.set_xlabel(\"lag ($x10^{3}$)\")\n    a.set_title(f\"train batch {i}\")\n    if i % 2 == 0:\n        a.set_ylabel(\"cross correlation\")\nplt.tight_layout()","1615c33a":"fig, ax = plt.subplots(2, 2, figsize=(15, 8), sharey=\"all\")\nax = ax.flatten()\nfor i, a in enumerate(ax):\n    a.acorr(test_signal[i,::1000], usevlines=False, normed=True, maxlags=50, lw=.5, alpha=0.2, color=\"k\");\n    a.set_xlabel(\"lag ($x10^{3}$)\")\n    a.set_title(f\"test batch {i}\")\n    if i % 2 == 0:\n        a.set_ylabel(\"cross correlation\")\nplt.tight_layout()","f46b1272":"# Observations","3c7a0569":"Interesting, the auto-correlation structure is very different across the \"batches\"! We might want to think about how to deal with them rather than just fitting a single model across the \"batches\".","ec93c514":"# Autocorrelation","9dd14a89":"# Load data","b656254d":"# Libraries","eea9c2b7":"Although the signal data are separated by a batch whose size is 500,000, we cannot be sure if the signal is similar within the batch and distinctively different across the batch. One naive way to see this is **auto- correlation**, which is helpful finding a repeated pattern.\n\nThe data are from [Data Without Drift with Kalman filter](https:\/\/www.kaggle.com\/michaln\/data-without-drift-with-kalman-filter)."}}