{"cell_type":{"2e10e1d3":"code","079288cd":"code","8ca90e52":"code","1a31aaa8":"code","755df554":"code","9104b5be":"code","25c8363e":"code","163d6007":"code","66e1a8f9":"code","a0ca60f6":"code","a421e139":"code","0798cb7d":"code","cb69921b":"code","95da80f6":"code","10e699f0":"code","b4be6ffb":"code","45dcb891":"code","68d764c7":"code","b0dbc92c":"code","1c83b5ee":"code","645e0cbe":"markdown","3b8f7bb5":"markdown","8783786c":"markdown","6f3a51be":"markdown","a399f728":"markdown","a34431ff":"markdown"},"source":{"2e10e1d3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n# apply ignore\nimport warnings\nwarnings.filterwarnings('ignore')","079288cd":"#load train data\ntrain_data = pd.read_csv('..\/input\/learn-together\/train.csv')\ntrain_data.head()","8ca90e52":"import eli5\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error\nfrom eli5.sklearn import PermutationImportance\n\n# define api\n\ndef get_model():\n    return RandomForestClassifier(n_estimators=1000,\n                                   criterion='gini',\n                                   max_features='auto',\n                                   random_state=42,\n                                   max_depth=50,\n                                   bootstrap=False)\n\ndef get_score(model, X, y):\n    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n    model.fit(train_X, train_y)\n    preds = model.predict(val_X)\n    # validate model\n    print('val size {0}, mse {1}'.format(len(val_y), mean_absolute_error(val_y, preds)))\n\ndef get_importance(model, X, y):\n    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n    model.fit(train_X, train_y)\n    return PermutationImportance(model, random_state=1).fit(val_X, val_y)","1a31aaa8":"# 'Id' is a false feature, although adding it makes smaller mse error\nforest_features = [cname for cname in train_data.columns if cname not in ['Id','Cover_Type']]\nX = train_data[forest_features]\ny = train_data.Cover_Type\n\nmy_model = get_model()\nget_score(my_model, X, y)","755df554":"def get_feature_importances(model, feature_list, treshold):\n    # Get numerical feature importances\n    importances = list(model.feature_importances_)\n    # List of tuples with variable and importance\n    feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(feature_list, importances)]\n    # Sort the feature importances by most important first\n    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n    # Print out the feature and importances \n    return [(key, value) for (key, value) in feature_importances if value > treshold]\n\nimportances = get_feature_importances(my_model, X.columns.tolist(), 0.005)\nprint(*['Variable: {:40} Importance: {}'.format(k,v) for k,v in importances], sep = \"\\n\")\n","9104b5be":"# show feature importance\nperm = get_importance(my_model, X, y)\neli5.show_weights(perm, feature_names = X.columns.tolist()) ","25c8363e":"# select manually features with importance higher than 0.005\nselect_features = ['Elevation', 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Horizontal_Distance_To_Hydrology',\n'Wilderness_Area4','Soil_Type3','Wilderness_Area1','Vertical_Distance_To_Hydrology','Soil_Type10',\n'Hillshade_9am','Hillshade_Noon','Soil_Type39','Aspect','Soil_Type38','Soil_Type4','Soil_Type32','Wilderness_Area3']","163d6007":"X = train_data[select_features]\ny = train_data.Cover_Type\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\nmodel = get_model()\nmodel.fit(train_X, train_y)","66e1a8f9":"import shap \n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(val_X)","a0ca60f6":"shap.summary_plot(shap_values, val_X)","a421e139":"shap.summary_plot(shap_values[0], val_X, title='Hi')        ","0798cb7d":"shap.summary_plot(shap_values[1], val_X)","cb69921b":"shap.summary_plot(shap_values[2], val_X)","95da80f6":"shap.summary_plot(shap_values[3], val_X)","10e699f0":"shap.summary_plot(shap_values[4], val_X)","b4be6ffb":"shap.summary_plot(shap_values[5], val_X)","45dcb891":"shap.summary_plot(shap_values[6], val_X)","68d764c7":"preds = model.predict(val_X)\n# validate model\nprint('val size {0}, mse {1}'.format(len(val_y), mean_absolute_error(val_y, preds)))\n","b0dbc92c":"test_model = get_model()\n\n# use select_features\nX = train_data[select_features]\ny = train_data.Cover_Type\ntest_model.fit(X, y) # retrain on full dataset\n\n# read test data\ntest_data = pd.read_csv('..\/input\/learn-together\/test.csv')\ntest_X = test_data[select_features]\n\n# make predictions used to submit. \ntest_preds = test_model.predict(test_X)\n\n# The lines below shows how to save predictions in competition format\n\noutput = pd.DataFrame({'Id': test_data.Id,\n                       'Cover_Type': test_preds})\noutput.to_csv('submission.csv', index=False)","1c83b5ee":"output.head()","645e0cbe":"### Building Model","3b8f7bb5":"### SHAP","8783786c":"### Interpreting Permutation Importances\n\nThe values towards the top are the most important features, and those towards the bottom matter least. The first number in each row shows how much model performance decreased with a random shuffling (in this case, using \"accuracy\" as the performance metric). The most important feature is Elevation.","6f3a51be":"### Choosing \"Features\"","a399f728":"### Build Model","a34431ff":"#### Make Predictions\nRead the file of \"test\" data. And apply model to make predictions"}}