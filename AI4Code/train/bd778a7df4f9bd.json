{"cell_type":{"525f39c6":"code","32714515":"code","376f5f49":"code","a7ea3239":"code","c38316d4":"code","0c3c9eb8":"code","7310b7cd":"code","56ed87a9":"code","4ab0eb3f":"code","47d102b6":"code","1d336177":"code","885e1983":"code","39b3eede":"code","8c3e5f2a":"code","0803f7f6":"code","ee97e764":"code","5a5721d8":"code","8fc41724":"code","638474ea":"code","d46fd489":"code","383d31c6":"markdown","ac8a815e":"markdown","c525be67":"markdown","ac040c21":"markdown","fec79eff":"markdown","fcea4323":"markdown"},"source":{"525f39c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","32714515":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\n\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","376f5f49":"def name_check(x):\n\tif x['Name'].lower().find('mr.')\t>=0:\n\t\treturn 'mr'\n\telif x['Name'].lower().find('mrs.')>=0:\n\t\treturn 'mrs'\n\telif x['Name'].lower().find('miss')>=0:\n\t\treturn 'miss'\n\telif x['Name'].lower().find('master')>=0:\n\t\treturn 'master'\n\telif (x['Sex'].lower() == 'female'):\n\t\treturn 'mrs'\n\treturn 'other'\n\t\n\n\ntrain['name_c'] = train.apply(lambda x: name_check(x),axis=1)\ntest['name_c'] = test.apply(lambda x: name_check(x),axis=1)","a7ea3239":"train['cabin_c'] = train.apply(lambda x: 0 if pd.isna(x['Cabin']) else 1, axis=1)\ntest['cabin_c'] = test.apply(lambda x: 0 if pd.isna(x['Cabin']) else 1, axis=1)","c38316d4":"def ticket_number(x,i):\n\tif i == 0 :\n\t\ttemp = len(train.groupby(['Ticket']).get_group(x['Ticket']))\n\telse :\n\t\ttemp = len(test.groupby(['Ticket']).get_group(x['Ticket']))\n#\tprint(temp)\n\treturn temp\t","0c3c9eb8":"train['ticket_no_c'] = train.apply(lambda x : ticket_number(x,0), axis=1)\ntest['ticket_no_c'] = test.apply(lambda x : ticket_number(x,1), axis=1)","7310b7cd":"def fare_range(x) :\n\tif x['Fare'] <= 30.0 :\n\t\treturn '0-30'\n\telif x['Fare']>30.0 and x['Fare'] <= 50.0 :\n\t\treturn '30-50'\n\treturn '>50'\n\ntrain['fare_c'] = train.apply(lambda x : fare_range(x), axis=1)\ntest['fare_c'] = test.apply(lambda x : fare_range(x), axis=1)","56ed87a9":"def count(x,s):\n\tif x[s] > 2 :\n\t\treturn '>2'\n\telif x[s] == 0 :\n\t\treturn '0'\n\telif x[s] == 1 :\n\t\treturn '1'\n\treturn '2'\n#\treturn x[s]\n\t\ntrain['parch_c'] = train.apply(lambda x : count(x,'Parch'), axis = 1)\ntrain['sibsp_c'] = train.apply(lambda x : count(x,'SibSp'), axis = 1)\n\ntest['parch_c'] = test.apply(lambda x : count(x,'Parch'), axis = 1)\ntest['sibsp_c'] = test.apply(lambda x : count(x,'SibSp'), axis = 1)","4ab0eb3f":"train.drop(columns = ['Name','Cabin','Ticket','Fare','Parch','SibSp'], inplace = True)\ntest.drop(columns = ['Name','Cabin','Ticket','Fare','Parch','SibSp'], inplace = True)","47d102b6":"from sklearn.impute import SimpleImputer\nimp_mean = SimpleImputer(missing_values = np.nan, strategy = 'mean')\nimp_mf = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')","1d336177":"cols_train = ['PassengerId','Pclass','Sex','Embarked','name_c','cabin_c','ticket_no_c','fare_c','parch_c','sibsp_c','Age','Survived']\ntrain = train[cols_train]\ncols_test = ['PassengerId','Pclass','Sex','Embarked','name_c','cabin_c','ticket_no_c','fare_c','parch_c','sibsp_c','Age']\ntest = test[cols_test]\n\nimp_mf = imp_mf.fit(train.iloc[:,3:4])\ntrain.iloc[:,3:4] = imp_mf.transform(train.iloc[:,3:4])\ntest.iloc[:,3:4] = imp_mf.transform(test.iloc[:,3:4])\n\nimp_mean = imp_mean.fit(train.iloc[:,10:11])\n\n#enc = enc.fit(train.iloc[:,1:10])\n\n#\n#from sklearn.compose import ColumnTransformer\n#ct = ColumnTransformer([('one_hot_encoding',enc,slice(0,9)),('impute',imp_mean,[9])],remainder = 'passthrough')\n\n#train.iloc[:,1:11] = ct.fit_transform(train.iloc[:,1:11])\n#test = ct.transform(test)\n\ntrain.iloc[:,10:11] = imp_mean.transform(train.iloc[:,10:11])\ntest.iloc[:,10:11] = imp_mean.transform(test.iloc[:,10:11])","885e1983":"from sklearn.preprocessing import StandardScaler\nsd = StandardScaler()\ntrain.iloc[:,10:11] = sd.fit_transform(train.iloc[:,10:11])\ntest.iloc[:,10:11] = sd.transform(test.iloc[:,10:11])","39b3eede":"def age_transform(x):\n\tif x['Age'] >= 1.0 :\n\t\treturn '>=1'\n\telif 0 <= x['Age'] < 1.0 :\n\t\treturn '0-1'\n\telif -1.0 <= x['Age'] < 0.0 :\n\t\treturn '-1-0'\n\treturn \"<-1\"\n\t\ntrain['age_c'] = train.apply(lambda x : age_transform(x), axis = 1)\ntest['age_c'] = test.apply(lambda x : age_transform(x), axis = 1)","8c3e5f2a":"train.drop(columns = ['Age'], inplace = True)\ntest.drop(columns = ['Age'], inplace = True)\n\ncols_train = ['PassengerId','Pclass','Sex','Embarked','name_c','cabin_c','ticket_no_c','fare_c','parch_c','sibsp_c','age_c','Survived']\ntrain = train[cols_train]\ncols_test = ['PassengerId','Pclass','Sex','Embarked','name_c','cabin_c','ticket_no_c','fare_c','parch_c','sibsp_c','age_c']\ntest = test[cols_test]","0803f7f6":"X = train.iloc[:,1:11]\ny = train.iloc[:,11:12]\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.20,random_state = 0)\n\n\n#from sklearn.preprocessing import OneHotEncoder\n#enc = OneHotEncoder(handle_unknown = 'ignore')\n#\n##enc.fit(X_train)\n#X_train = enc.fit_transform(X_train)\n#X_test = enc.transform(X_test)\nfrom sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\nX_train = enc.fit_transform(X_train)\nX_test = enc.transform(X_test)\n\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()","ee97e764":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state = 42)\nX_train,y_train = sm.fit_resample(X_train,y_train)","5a5721d8":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.tree import DecisionTreeClassifier\npdtc = [{'criterion' : ['gini','entropy'], 'max_depth' : [3,200],'max_features' : ['auto','sqrt','log2']}]\nclf1 = GridSearchCV(DecisionTreeClassifier(random_state = 0),pdtc)\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nprfc = [{'n_estimators' : [3,300],'criterion' : ['gini','entropy'], 'max_depth' : [3,200],'max_features' : ['auto','sqrt','log2']}]\nclf2 = GridSearchCV(RandomForestClassifier(random_state = 0),prfc)\n\nfrom sklearn.svm import SVC\npsvc = [{'C' : [0.1,5.0], 'kernel' : ['linear','poly','rbf','sigmoid']}]\nclf3 = GridSearchCV(SVC(random_state = 0),psvc)\n\nfrom sklearn.ensemble import GradientBoostingClassifier\npgbc = [{'loss' : ['deviance','exponential'], 'learning_rate' : [0.1,1],'n_estimators' : [10,300],'warm_start' : [True, False]}]\n#for a in range()\nclf4 = GridSearchCV(GradientBoostingClassifier(random_state = 0),pgbc)\n\n#estimator = [('dtc',clf1),('rfc',clf2),('svc',clf3)]\nestimator = [('dtc',clf1),('rfc',clf2),('svc',clf3),('gbc',clf4)]\n\nfrom sklearn.ensemble import StackingClassifier\nclf5 = StackingClassifier(estimators = estimator,final_estimator = clf4,passthrough = True)","8fc41724":"clf1.fit(X_train,y_train)\nclf2.fit(X_train,y_train)\nclf3.fit(X_train,y_train)\nclf4.fit(X_train,y_train)","638474ea":"y_pred = ((clf1.predict(X_test)+clf2.predict(X_test)+clf3.predict(X_test)+clf4.predict(X_test))>=2)*1\nfrom sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))\n# print(cr)","d46fd489":"test_X = enc.transform(test.iloc[:,1:])\ny_temp = clf1.predict(test_X)+clf2.predict(test_X)+clf3.predict(test_X)+clf4.predict(test_X)\ny_ans = (y_temp>=4)*1\ntest_y = pd.DataFrame({'PassengerId' : test.iloc[:,0].to_numpy(), 'Survived' : y_ans})\ntest_y.to_csv('\/kaggle\/output\/v1.csv',index = False)","383d31c6":"Data Preproccessing and feature engineering","ac8a815e":"**Cabin present or not (1\/0)**","c525be67":"**Number of people on that particular ticket**","ac040c21":"**Fare Range divided between 3 segments**","fec79eff":"**Function for finding mr\/mrs\/miss\/master in the name column**","fcea4323":"**Count of Parents\/Childern\/Siblings**"}}