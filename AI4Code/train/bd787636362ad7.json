{"cell_type":{"b0420258":"code","23b11658":"code","e5e2f890":"code","b05561a0":"code","383bb229":"code","fa9b3731":"code","acd9ddb5":"code","5c6f0a9d":"code","935ac817":"code","4e864873":"code","4f26d322":"code","1156c775":"code","323db01a":"code","54c735e5":"code","bf33f5f4":"code","21beacc5":"code","9f285e13":"code","493f4666":"code","1a6a5a7e":"code","ed007cd7":"code","f009668e":"code","dbffa508":"code","d8d7848c":"code","043652f6":"code","81e3f5fa":"code","64b5cf2b":"code","8d652982":"code","c83ed795":"code","2c1f7854":"code","68676693":"code","2eb6a3f4":"code","2f17f0e4":"code","164655df":"code","9e258602":"code","be9ea34a":"code","aa157010":"code","89398a16":"code","07845f6d":"code","ddc35b53":"code","cadd97c1":"code","67b1d4d2":"code","2f4afc76":"code","89295e4a":"markdown","ccdb1ab6":"markdown","b7ae1561":"markdown","9f2d6e99":"markdown","d2c46549":"markdown","f265265b":"markdown","a3af618f":"markdown","27a648f3":"markdown","80fa15d6":"markdown","a9349773":"markdown","46fdc045":"markdown","d9792bba":"markdown","874b5053":"markdown","d6487f56":"markdown","b9c615fb":"markdown","e23c7138":"markdown","a26736e2":"markdown","d5673c8b":"markdown","e2e03773":"markdown","df2e60d1":"markdown","c489f9d1":"markdown","30c5ce0b":"markdown","7bd00ccb":"markdown","5c1533a6":"markdown","60793968":"markdown","857d3f96":"markdown","3ab45c5a":"markdown","d7bf432d":"markdown","df7c01f1":"markdown","9d274bcb":"markdown","9f299062":"markdown","dd252030":"markdown","c59a45c4":"markdown","1257d1fa":"markdown","02d4266b":"markdown","0f5dae1a":"markdown","bf3adf29":"markdown","2754c1a8":"markdown","098a03bf":"markdown","7c0b3ba8":"markdown","988b244f":"markdown","73d0e084":"markdown","edf9a08e":"markdown","7b74011f":"markdown","4792e310":"markdown"},"source":{"b0420258":"import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nimport scipy.stats as sci\nimport matplotlib.pyplot as matplt\nimport seaborn as sb\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.mlab as matlab\n%matplotlib inline","23b11658":"tubes2_HeartDisease_train = pd.read_csv(\"..\/input\/tubes2_HeartDisease_train.csv\")\ntubes2_HeartDisease_train.head()","e5e2f890":"tubes2_HeartDisease_train.dtypes","b05561a0":"tubes2_HeartDisease_train['Column4'] = pd.to_numeric(tubes2_HeartDisease_train['Column4'], errors = 'coerce')\ntubes2_HeartDisease_train['Column5'] = pd.to_numeric(tubes2_HeartDisease_train['Column5'], errors = 'coerce')\ntubes2_HeartDisease_train['Column6'] = pd.to_numeric(tubes2_HeartDisease_train['Column6'], errors = 'coerce')\ntubes2_HeartDisease_train['Column7'] = pd.to_numeric(tubes2_HeartDisease_train['Column7'], errors = 'coerce')\ntubes2_HeartDisease_train['Column8'] = pd.to_numeric(tubes2_HeartDisease_train['Column8'], errors = 'coerce')\ntubes2_HeartDisease_train['Column9'] = pd.to_numeric(tubes2_HeartDisease_train['Column9'], errors = 'coerce')\ntubes2_HeartDisease_train['Column10'] = pd.to_numeric(tubes2_HeartDisease_train['Column10'], errors = 'coerce')\ntubes2_HeartDisease_train['Column11'] = pd.to_numeric(tubes2_HeartDisease_train['Column11'], errors = 'coerce')\ntubes2_HeartDisease_train['Column12'] = pd.to_numeric(tubes2_HeartDisease_train['Column12'], errors = 'coerce')\ntubes2_HeartDisease_train['Column13'] = pd.to_numeric(tubes2_HeartDisease_train['Column13'], errors = 'coerce')","383bb229":"tubes2_HeartDisease_train.dtypes","fa9b3731":"tubes2_HeartDisease_train.head()","acd9ddb5":"len(tubes2_HeartDisease_train.index)","5c6f0a9d":"tubes2_HeartDisease_train.rename(columns={'Column1' : 'age', 'Column2' : 'sex', 'Column3' : 'chest_pain_type', 'Column4' : 'resting_bp', 'Column5' : 'ser_chol', 'Column6' : 'fast_glucose', 'Column7' : 'rest_ecg', 'Column8' : 'heart_rate', 'Column9' : 'exc_angina', 'Column10' : 'depression', 'Column11' : 'peak_exc', 'Column12' : 'maj_vessels', 'Column13' : 'thal', 'Column14' : 'heart_disease'}, inplace = True)\ntubes2_HeartDisease_train.head()","935ac817":"tubes2_HeartDisease_train.isnull().sum()","4e864873":"count = 0\nfor i in tubes2_HeartDisease_train.isnull().sum(axis = 1):\n    if i > 0:\n        count = count + 1\nprint(\"%i instances have missing values which is %i%% of the total data\" %(count, round((float(count)\/len(tubes2_HeartDisease_train.index))*100)))","4f26d322":"tubes2_HeartDisease_train.drop(columns = ['peak_exc', 'maj_vessels', 'thal'], inplace = True)","1156c775":"tubes2_HeartDisease_train.isnull().sum()","323db01a":"count = 0\nfor i in tubes2_HeartDisease_train.isnull().sum(axis = 1):\n    if i > 0:\n        count = count + 1\nprint(\"%i instances have missing values which is %i%% of the total data\" % (count, round((float(count)\/len(tubes2_HeartDisease_train.index))*100)))","54c735e5":"tubes2_HeartDisease_train.dropna(inplace = True)","bf33f5f4":"tubes2_HeartDisease_train.isnull().sum()","21beacc5":"len(tubes2_HeartDisease_train.index)","9f285e13":"tubes2_HeartDisease_train['heart_disease'] = (tubes2_HeartDisease_train['heart_disease'] >= 1).astype(int)","493f4666":"tubes2_HeartDisease_train = tubes2_HeartDisease_train.astype(int)","1a6a5a7e":"tubes2_HeartDisease_train.dtypes","ed007cd7":"def histograms(df, ft, rw, cl):\n    fig = matplt.figure(figsize = (20,20))\n    for i, feature in enumerate (ft):\n        ax = fig.add_subplot(rw, cl, i+1)\n        df[feature].hist(bins = 20, ax = ax, facecolor = 'red')\n        ax.set_title(feature)\n    fig.tight_layout()\n    matplt.show()\nhistograms(tubes2_HeartDisease_train, tubes2_HeartDisease_train.columns, 6, 3)","f009668e":"sb.countplot(x = tubes2_HeartDisease_train['heart_disease'], data = tubes2_HeartDisease_train, palette = 'hls')\n(tubes2_HeartDisease_train['heart_disease'].value_counts()\/tubes2_HeartDisease_train['heart_disease'].count())*100","dbffa508":"tubes2_HeartDisease_train.describe()","d8d7848c":"import sklearn\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nx = tubes2_HeartDisease_train.iloc[:,:-1]\ny = tubes2_HeartDisease_train.iloc[:,-1]\n\n# train_test_split will return the 4 array\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 3)\n\n# fit the model\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)","043652f6":"# predict disease from x_test set\ny_pred = logreg.predict(x_test)\n\naccuracy = sklearn.metrics.accuracy_score(y_test,y_pred)\n\nprint('Accuracy of logistic Regression classifier on test set is: {}%'.format(round(accuracy,2)*100))","81e3f5fa":"y_pred_count = np.unique(y_pred, return_counts = True)\ny_pred_count","64b5cf2b":"from sklearn.metrics import confusion_matrix\n\ncfmx = confusion_matrix(y_test, y_pred)\nconf_matrix = pd.DataFrame(data = cfmx, columns = ['Predicted: 0', 'Predicted: 1'], index = ['Actual: 0', 'Actual: 1'])\n\nsb.heatmap(data = conf_matrix, annot = True, fmt = 'd', cmap = \"YlGnBu\", square = True)","8d652982":"TN = cfmx[0,0]\nTP = cfmx[1,1]\nFN = cfmx[1,0]\nFP = cfmx[0,1]\n\nprint(\"The confusion matrix shows %i correct predictions and %i incorrect predictions\" % ((TN + TP), (FN + FP)))","c83ed795":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred))","2c1f7854":"from sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\n\nmatplt.plot(fpr,tpr)\nmatplt.xlim([0.0, 1.0])\nmatplt.ylim([0.0, 1.0])\nmatplt.plot([0, 1], [0, 1], 'r--')\nmatplt.title('ROC curve for Heart disease classifier')\nmatplt.xlabel('False positive rate (1-Specificity)')\nmatplt.ylabel('True positive rate (Sensitivity)')\nmatplt.grid(True)","68676693":"roc_auc_score = sklearn.metrics.roc_auc_score(y_test,logreg.predict_proba(x_test)[:,1])\n\nif roc_auc_score >= 0.70:\n    print(\"ROC Curve Covers almost %i%% Area\" % (round(roc_auc_score, 2)*100))\nelse:\n     print(\"ROC Curve Covers almost %i%% Area Which is not Satisfactory\" % (round(roc_auc_score, 2)*100))  ","2eb6a3f4":"x_test['y_test'] = y_test\nx_test['y_pred'] = y_pred\n\nx_test = x_test.drop(x_test[x_test.y_test == x_test.y_pred].index)\n\nx_test.head()","2f17f0e4":"tubes2_HeartDisease_test = pd.read_csv(\"..\/input\/tubes2_HeartDisease_test.csv\")\ntubes2_HeartDisease_test.head()","164655df":"tubes2_HeartDisease_test.dtypes","9e258602":"tubes2_HeartDisease_test['Column4'] = pd.to_numeric(tubes2_HeartDisease_test['Column4'], errors = 'coerce')\ntubes2_HeartDisease_test['Column5'] = pd.to_numeric(tubes2_HeartDisease_test['Column5'], errors = 'coerce')\ntubes2_HeartDisease_test['Column6'] = pd.to_numeric(tubes2_HeartDisease_test['Column6'], errors = 'coerce')\ntubes2_HeartDisease_test['Column8'] = pd.to_numeric(tubes2_HeartDisease_test['Column8'], errors = 'coerce')\ntubes2_HeartDisease_test['Column9'] = pd.to_numeric(tubes2_HeartDisease_test['Column9'], errors = 'coerce')\ntubes2_HeartDisease_test['Column10'] = pd.to_numeric(tubes2_HeartDisease_test['Column10'], errors = 'coerce')\ntubes2_HeartDisease_test['Column11'] = pd.to_numeric(tubes2_HeartDisease_test['Column11'], errors = 'coerce')\ntubes2_HeartDisease_test['Column12'] = pd.to_numeric(tubes2_HeartDisease_test['Column12'], errors = 'coerce')\ntubes2_HeartDisease_test['Column13'] = pd.to_numeric(tubes2_HeartDisease_test['Column13'], errors = 'coerce')","be9ea34a":"tubes2_HeartDisease_test.rename(columns={'Column1' : 'age', 'Column2' : 'sex', 'Column3' : 'chest_pain_type', 'Column4' : 'resting_bp', 'Column5' : 'ser_chol', 'Column6' : 'fast_glucose', 'Column7' : 'rest_ecg', 'Column8' : 'heart_rate', 'Column9' : 'exc_angina', 'Column10' : 'depression', 'Column11' : 'peak_exc', 'Column12' : 'maj_vessels', 'Column13' : 'thal'}, inplace = True)\n\ntubes2_HeartDisease_test.drop(columns = ['peak_exc', 'maj_vessels', 'thal'], inplace = True)\n\ntubes2_HeartDisease_test.head()","aa157010":"len(tubes2_HeartDisease_test.index)","89398a16":"tubes2_HeartDisease_test.isnull().sum()","07845f6d":"count = 0\nfor i in tubes2_HeartDisease_test.isnull().sum(axis = 1):\n    if i > 0:\n        count = count + 1\nprint(\"%i instances have missing values which is %i%% of the total data\" % (count, round((float(count)\/len(tubes2_HeartDisease_train.index))*100, 2)))","ddc35b53":"tubes2_HeartDisease_test.dropna(inplace = True)","cadd97c1":"tubes2_HeartDisease_test.isnull().sum()","67b1d4d2":"tubes2_HeartDisease_test = tubes2_HeartDisease_test.astype(int)\ntubes2_HeartDisease_test.head()","2f4afc76":"y_pred = logreg.predict(tubes2_HeartDisease_test)\n\ntubes2_HeartDisease_test['heart_disease'] = y_pred\n\ntubes2_HeartDisease_test.head()","89295e4a":"### **Total Number of 1 (yes) and 0 (no) Predictions**","ccdb1ab6":"### **Correct & Incorrect Prediction**","b7ae1561":"### **Checking Missing Value Again**","9f2d6e99":"### **Predict the Angiographic Disease in Test Dataset**","d2c46549":"### **Implementing Logistic Regression and Fit the Model**","f265265b":">***Column4 to Column13 have string values, basically '?' which can not be used machine learning model***","a3af618f":"### **ROC Curve Coverage Area**","27a648f3":"### **Dropout Missing Instances**","80fa15d6":"### **Checking Total Instances**","a9349773":"### **Checking Missing Values**","46fdc045":"### **Changing Data Types to Integer**","d9792bba":"### **Understanding Data Structure**","874b5053":"### **Dropout Missing Instances**","d6487f56":"### **Changing Attributes Name**","b9c615fb":"### **Total Instances**","e23c7138":"### **Model Accuracy**","a26736e2":">***Here, it is clearly visible that, class label distribution is balnced***","d5673c8b":"### **Dropout Attributes**","e2e03773":"### **Checking Total Instances Again**","df2e60d1":"### **Changing Data Types**\n\nChange all data types and convert all '?' values to Nan values","c489f9d1":">***There are many missing values specially in peak_exc, maj_vessels, thal attributes. These three attributes will not give any meaningful model***","30c5ce0b":">***Red dot line is the essential factor. ROC curve must be to the upper left corner and make a good distance with red dotted line to make a perfect model.\nIn this case ROC curve is in almost perfect condition***","7bd00ccb":"### **Importing Libraries**","5c1533a6":"### **Changing Data Type to Integer**","60793968":">***f1-score for 0 and 1 both cases are almost 0.80 which is impressive and a good indication of good model***","857d3f96":"### **Loading Test Dataset**","3ab45c5a":"### **Checking Missing Values**","d7bf432d":"### **Confusion Matrix**","df7c01f1":"### **Changing Class Attributes**\n\n>***angiographic_disease has 5 types of values (0 = No, 1,2,3,4 = Yes)***<br>\n>***Change all 1,2,3,4 values to 1 (1 = yes)***","9d274bcb":"### **Class Balance-Imbalance Check**","9f299062":"## **Heart Disease Prediction using Logistic Regression**\n\n>***Heart disease is a common disease specially for aged people. There are some certain factors which cause angiographic disease. There are two csv files in kaggle (training and test). As we all know, data prepocessing, cleaning, feature selection and aggregation is very crucial to design a perfect model. Thus, I will try to do data preprocessing step by step and then Logistic Model will be used to train the dataset. Afterthat, as test dataset does not have class label, I will fit the test into training dataset and put a label whether they have heart disease or not***","dd252030":"### **Checking Missing Value Again**","c59a45c4":"### **ROC Curve**","1257d1fa":"### **Checking Incorrect Instances**\n\n>***There are total 32 incorrect instances. We can observe their behavior and change the model to get higher accuracy and f1-score***","02d4266b":"### **Classification Report**","0f5dae1a":" ### **Loading Training Dataset**\n\n>#### **Independent Variables <font>**\n\nColumn1: **age** as years <br>\nColumn2: **sex** as 1 = male, 0 = female <br>\nColumn3: **chest-pain type** as 1 = typical angina, 2 = atypical angina, 3 = non-anginal pain, 4 = asymptotic <br>\nColumn4: **resting blood pressure** as mmHg (on hospital admission) <br>\nColumn5: **serum cholestrol** as mg\/dl <br>\nColumn6: **fasting blood sugar** as (>120 mg\/dl), 1 = true, 0 = false <br>\nColumn7: **resting ECG** 0 = normal, 1 = having ST-T wave abnormality, 2 = left ventricular hyperthrophy <br>\nColumn8: **max-heart rate achieved** as arbitrary value<br>\nColumn9: **exercise induced angina** as 1 = yes, 0 = no <br>\nColumn10: **ST depression induced by exercise relative to rest** as arbitrary value <br>\nColumn11: **peak exercise ST segment** as 1 = upsloping, 2 = flat, 3 = downsloping <br>\nColumn12: **number of major vessels (0-3) colored by flourosopy** as 0-3 value <br>\nColumn13: **thal** as 3 = normal, 6 = fixed defect, 7 = reversable defect <br>\n\n>#### **Class Attributes**\n\nColumn14: **heart disease status** 0 = absence, 1,2,3,4 = presence","bf3adf29":"### **Total Instances**","2754c1a8":"### **Visualizing the Data**","098a03bf":"### **Changing Data Types**","7c0b3ba8":">***Now, here all datatypes have been changed from string to float***","988b244f":"### **Checking Data Types**","73d0e084":">***I used to split 75% for tarining the model and 25% for testing the model***","edf9a08e":"### **Changing Features Name & Delete Meaningless Features Same as Training Set**","7b74011f":"### **Checking Data Types**","4792e310":">***Here model predicted in the test dataset (splitted from training dataset) 76 instaces have no angiographic disease, whereas 82 instances have it***"}}