{"cell_type":{"9d460573":"code","ea780d3b":"code","183e7082":"code","274fa82b":"code","64925652":"code","46b14f6b":"code","a5484cd6":"code","5ff8d8d2":"code","866518cc":"code","2cbedddd":"code","965f739e":"code","cfc12fe0":"code","86b4eead":"code","aa537aa8":"code","d6f2d3d0":"code","66a57ba6":"code","ac6e135d":"code","f6800be9":"code","9c6f3453":"code","d0654828":"code","59ad243d":"code","bac13b6d":"code","c82b854c":"code","56b0d446":"code","a637a6fa":"code","838dedff":"code","e2c81fc1":"code","fde2cfae":"code","5924e4fc":"code","dd4c3ecd":"code","e3df36c3":"code","e3082292":"code","d4a08d35":"code","1de561be":"code","668956f9":"code","c51dfe0a":"code","fd26c683":"code","6b6e3a75":"code","33e87f98":"code","d7ee5c00":"code","4f9e634c":"code","e34c533a":"code","4d6c4aba":"code","4e3b1614":"code","fa66e283":"code","72567117":"code","44eb391e":"code","00681f19":"code","448a8df5":"code","a1ac9d22":"code","72361d78":"code","f6ce11aa":"code","c93237af":"code","a5ff4475":"code","6089a2bb":"code","fbed2a91":"code","abf57b3f":"code","6ec84589":"code","270dd2a6":"code","4bf0d1a2":"code","b578ee8a":"code","11b8e0db":"code","a621a800":"code","33dcb708":"code","ba1026c6":"code","563402a6":"code","988cbb0d":"code","a13aa48f":"code","48e8dab6":"code","9e1529b1":"code","e789d9b9":"code","4a0bd158":"code","180230a3":"code","0399877d":"code","db03e8d0":"code","9bc34c0e":"code","b65c410c":"code","10ec531d":"code","68f1a773":"code","bffc861f":"code","55d94ef1":"code","ee84007a":"code","23f16b75":"code","6ac3909a":"code","77466f6c":"code","eaafacd9":"code","1dfea103":"code","5112ac02":"code","9c92f113":"code","25d28048":"code","ccb83011":"code","e7153289":"code","61f11e01":"code","51fefb67":"code","28c76b28":"code","cb0e9b18":"code","674aad4f":"code","0e268cb9":"code","3a67e9e6":"code","ae50a9bc":"markdown","0d516d4b":"markdown","b550f374":"markdown","bcc75930":"markdown","c7e3513b":"markdown","8a2d3c8e":"markdown","c44e3e17":"markdown","153e5607":"markdown","f64505f8":"markdown","e6bbb8a8":"markdown","b3c89d06":"markdown","c2d8c44e":"markdown","5ac1a37e":"markdown","3ab8d346":"markdown","71163a90":"markdown","d174dbd9":"markdown","de11396e":"markdown","4912b4fc":"markdown","3cb51237":"markdown","c2f8509d":"markdown","11ef1126":"markdown","9ebaced9":"markdown","07a34a97":"markdown","c634f925":"markdown","071852fa":"markdown","31af604d":"markdown","a3a256d8":"markdown","e7bd40f1":"markdown","4f1a00d7":"markdown","2808822e":"markdown","cfebb955":"markdown","9ae983e6":"markdown","8cf84daa":"markdown","eeebc735":"markdown","f7c0ab61":"markdown","0e5ccfa5":"markdown","bf6d2e30":"markdown","d2040adf":"markdown","d3dc7594":"markdown","2750baa2":"markdown","e94326ac":"markdown","c5532338":"markdown","486d4fc2":"markdown","971c8c43":"markdown","322c9924":"markdown","79f051da":"markdown","2c5ef6aa":"markdown","a471546f":"markdown","d128c46d":"markdown","d88c25b0":"markdown","2762b9e3":"markdown","07996310":"markdown"},"source":{"9d460573":"import os","ea780d3b":"train_img_dir = '..\/input\/train\/images\/'\ntrain_mask_dir = '..\/input\/train\/masks\/'\ntest_img_dir = '..\/input\/test\/images\/'","183e7082":"train_img_names = [x.split('.')[0] for x in os.listdir(train_img_dir)]","274fa82b":"train_img_names[:5]","64925652":"train_num = len(train_img_names)","46b14f6b":"train_num","a5484cd6":"train_img_dict_i_to_names = dict()\ntrain_img_dict_names_to_i = dict()\nfor i in range(train_num):\n    train_img_dict_i_to_names[i] = train_img_names[i]\n    train_img_dict_names_to_i[train_img_names[i]] = i","5ff8d8d2":"#train_img_dict_i_to_names","866518cc":"#train_img_dict_names_to_i","2cbedddd":"train_mask_names = [x.split('.')[0] for x in os.listdir(train_mask_dir)]","965f739e":"train_img_names == train_mask_names","cfc12fe0":"from skimage.data import imread","86b4eead":"train_img_shape = imread(train_img_dir + train_img_names[0]+'.png').shape\ntrain_mask_shape = imread(train_mask_dir + train_img_names[0]+'.png').shape","aa537aa8":"train_img_shape,train_mask_shape","d6f2d3d0":"import numpy as np","66a57ba6":"train_img = np.zeros((train_num, train_img_shape[0], train_img_shape[1], train_img_shape[2]))\ntrain_mask = np.zeros((train_num, train_mask_shape[0], train_mask_shape[1]))","ac6e135d":"for i in range(train_num):\n    train_img[i] = i\n    train_mask[i] = i\n    train_img[i,:,:,:] = imread(train_img_dir + train_img_names[i]+'.png')\n    train_mask[i,:,:] = imread(train_mask_dir + train_img_names[i]+'.png')","f6800be9":"train_img.shape,train_mask.shape","9c6f3453":"train_img[100,:,:,0],train_mask[100,:,:]","d0654828":"chk = 0\nfor i in range(train_num):\n    chk = chk + (train_img[i,:,:,0]*2-train_img[i,:,:,1]-train_img[i,:,:,2]).sum()","59ad243d":"chk","bac13b6d":"train_img_mono = np.zeros((train_num, train_img_shape[0], train_img_shape[1]))","c82b854c":"train_img_mono = train_img[:,:,:,0]","56b0d446":"train_img_mono.shape","a637a6fa":"train_img.sum()\/3 == train_img_mono.sum()","838dedff":"train_img_mono.max(),train_mask.max()","e2c81fc1":"train_mask_8bit = np.zeros((train_mask.shape[0],train_mask.shape[1],train_mask.shape[1]))","fde2cfae":"for i in range(train_num):\n    train_mask_8bit[i,:,:]= np.maximum(train_mask[i,:,:]\/255-2,0)","5924e4fc":"train_mask_8bit[100,:,:]","dd4c3ecd":"train_mask.sum()\/65535 == train_mask_8bit.sum()\/255","e3df36c3":"train_img_mono.shape,train_img_mono.max(),train_mask_8bit.shape,train_mask_8bit.max()","e3082292":"import pandas as pd","d4a08d35":"train_dir = '..\/input\/'","1de561be":"train = pd.read_csv(train_dir + 'train.csv')","668956f9":"train.head(7)","c51dfe0a":"def rle_to_mask(rle_list, SHAPE):\n    tmp_flat = np.zeros(SHAPE[0]*SHAPE[1])\n    if len(rle_list) == 1:\n        mask = np.reshape(tmp_flat, SHAPE).T\n    else:\n        strt = rle_list[::2]\n        length = rle_list[1::2]\n        for i,v in zip(strt,length):\n            tmp_flat[(int(i)-1):(int(i)-1)+int(v)] = 255\n        mask = np.reshape(tmp_flat, SHAPE).T\n    return mask","fd26c683":"for i in range(train_num):\n    rle = train.loc[i,'rle_mask']\n    rle_list = str(rle).split()\n    mask = rle_to_mask(rle_list, train_mask_shape)\n    img_name = train.loc[i,'id']\n    num = train_img_dict_names_to_i[img_name]\n    mask_ans = train_mask_8bit[num]\n    mask_ans = mask_ans.reshape(train_mask_shape[0],train_mask_shape[1])\n    if (mask-mask_ans).sum() != 0:\n        print('{} is NG'.format(img_name))","6b6e3a75":"train_img_mono = train_img_mono.reshape(train_img_mono.shape[0],train_img_mono.shape[1],train_img_mono.shape[2],1)\ntrain_mask_8bit = train_mask_8bit.reshape(train_mask_8bit.shape[0],train_mask_8bit.shape[1],train_mask_8bit.shape[2],1)","33e87f98":"train_img_mono.shape,train_mask_8bit.shape","d7ee5c00":"train_img_mono_pad = np.zeros((train_img_mono.shape[0],128,128,train_img_mono.shape[3]))\ntrain_mask_8bit_pad = np.zeros((train_img_mono.shape[0],128,128,train_img_mono.shape[3]))","4f9e634c":"top_pad = 13\nbottom_pad = 14\nleft_pad = 13\nright_pad = 14","e34c533a":"for i in range(train_num):\n    train_img_mono_pad[i,top_pad:-bottom_pad,left_pad:-right_pad,0] = train_img_mono[i,:,:,0]\n    train_mask_8bit_pad[i,top_pad:-bottom_pad,left_pad:-right_pad,0] = train_mask_8bit[i,:,:,0]","4d6c4aba":"train_img_mono_pad.shape,train_mask_8bit_pad.shape","4e3b1614":"train_img_mono.sum() == train_img_mono_pad.sum()","fa66e283":"train_mask_8bit.sum() == train_mask_8bit_pad.sum()","72567117":"train_img_mono_pad = train_img_mono_pad.astype('float32')\/255\ntrain_mask_8bit_pad = train_mask_8bit_pad.astype('float32')\/255","44eb391e":"def calc_IoU(A,B):\n    AorB = np.logical_or(A,B).astype('int')\n    AandB = np.logical_and(A,B).astype('int')\n    IoU = AandB.sum() \/ AorB.sum()\n    return IoU","00681f19":"import math\ndef calc_metric_oneimage(mask, mask_pred):\n    score = 0.0\n    if mask.sum() == 0:\n        if mask_pred.sum() == 0:\n            score = 1.0\n        else:\n            score = 0.0\n    else:\n        IoU = calc_IoU(mask,mask_pred)\n        score = math.ceil((max(IoU-0.5,0))\/0.05)\/10\n    return score","448a8df5":"def calc_metric_allimage(masks, mask_preds_prod):\n    num = masks.shape[0]\n    tmp = mask_preds_prod > 0.5\n    mask_preds = tmp.astype('int')\n    scores = list()\n    for i in range(num):\n        score = calc_metric_oneimage(masks[i], mask_preds[i])\n        scores.append(score)\n    return np.mean(scores)","a1ac9d22":"import tensorflow as tf\ndef my_metric(masks, mask_preds_prod):\n    return tf.py_func(calc_metric_allimage, [masks, mask_preds_prod], tf.float64)","72361d78":"from keras.models import *\nfrom keras.layers import *","f6ce11aa":"inputs = Input(shape=(train_img_mono_pad.shape[1],train_img_mono_pad.shape[2],train_img_mono_pad.shape[3]))\nconv1 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\nconv1 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\npool1 = MaxPooling2D(pool_size=(2,2))(conv1)\nconv2 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\nconv2 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\npool2 = MaxPooling2D(pool_size=(2,2))(conv2)\nconv3 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\nconv3 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\npool3 = MaxPooling2D(pool_size=(2,2))(conv3)\nconv4 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\nconv4 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\npool4 = MaxPooling2D(pool_size=(2,2))(conv4)\nconv5 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\nconv5 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\nupcv6 = UpSampling2D(size=(2,2))(conv5)\nupcv6 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv6)\nmrge6 = concatenate([conv4, upcv6], axis=3)\nconv6 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge6)\nconv6 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\nupcv7 = UpSampling2D(size=(2,2))(conv6)\nupcv7 = Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv7)\nmrge7 = concatenate([conv3, upcv7], axis=3)\nconv7 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge7)\nconv7 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\nupcv8 = UpSampling2D(size=(2,2))(conv7)\nupcv8 = Conv2D(16, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv8)\nmrge8 = concatenate([conv2, upcv8], axis=3)\nconv8 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge8)\nconv8 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\nupcv9 = UpSampling2D(size=(2,2))(conv8)\nupcv9 = Conv2D(8, 2, activation='relu', padding='same', kernel_initializer='he_normal')(upcv9)\nmrge9 = concatenate([conv1, upcv9], axis=3)\nconv9 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(mrge9)\nconv9 = Conv2D(8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\nconv10 = Conv2D(1, 1, activation='sigmoid')(conv9)","c93237af":"model = Model(inputs=inputs, outputs=conv10)","a5ff4475":"from keras.optimizers import *","6089a2bb":"model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [my_metric])","fbed2a91":"model.summary()","abf57b3f":"model.fit(train_img_mono_pad, train_mask_8bit_pad, epochs=20, batch_size=32)","6ec84589":"model.save('first_180924.h5')","270dd2a6":"def calc_metric_allimage_with_threshold(masks, mask_preds_prod, threshold):\n    num = masks.shape[0]\n    tmp = mask_preds_prod > threshold\n    mask_preds = tmp.astype('int')\n    scores = list()\n    for i in range(num):\n        score = calc_metric_oneimage(masks[i], mask_preds[i])\n        scores.append(score)\n    return np.mean(scores)","4bf0d1a2":"threshold_list = [x\/100 for x in range(0,100,5)]\npred_train_img = model.predict(train_img_mono_pad)\nmetric_tmp = dict()\nfor threshold in threshold_list:\n    tmp = calc_metric_allimage_with_threshold(train_mask_8bit_pad, pred_train_img, threshold)\n    metric_tmp[threshold] = tmp\nbest_threshold = max(metric_tmp, key=metric_tmp.get)","b578ee8a":"best_threshold, metric_tmp[best_threshold]","11b8e0db":"test_img_names = [x.split('.')[0] for x in os.listdir(test_img_dir)]","a621a800":"test_num = len(test_img_names)","33dcb708":"test_num","ba1026c6":"test_img_dict_i_to_names = dict()\ntest_img_dict_names_to_i = dict()\nfor i in range(test_num):\n    test_img_dict_i_to_names[i] = test_img_names[i]\n    test_img_dict_names_to_i[test_img_names[i]] = i","563402a6":"test_img_shape = imread(test_img_dir + test_img_names[0]+'.png').shape","988cbb0d":"test_img_shape","a13aa48f":"test_img = np.zeros((test_num, test_img_shape[0], test_img_shape[1], test_img_shape[2]))","48e8dab6":"for i in range(test_num):\n    test_img[i] = i\n    test_img[i,:,:,:] = imread(test_img_dir + test_img_names[i]+'.png')","9e1529b1":"test_img.shape","e789d9b9":"chk = 0\nfor i in range(test_num):\n    chk = chk + (test_img[i,:,:,0]*2-test_img[i,:,:,1]-test_img[i,:,:,2]).sum()","4a0bd158":"chk","180230a3":"test_img_mono = np.zeros((test_num, test_img_shape[0], test_img_shape[1]))","0399877d":"test_img_mono = test_img[:,:,:,0]","db03e8d0":"test_img_mono.shape","9bc34c0e":"test_img.sum()\/3 == test_img_mono.sum()","b65c410c":"test_img_mono.max()","10ec531d":"test_img_mono = test_img_mono.reshape(test_img_mono.shape[0],test_img_mono.shape[1],test_img_mono.shape[2],1)","68f1a773":"test_img_mono.shape","bffc861f":"test_img_mono_pad = np.zeros((test_img_mono.shape[0],128,128,test_img_mono.shape[3]))","55d94ef1":"for i in range(test_num):\n    test_img_mono_pad[i,top_pad:-bottom_pad,left_pad:-right_pad,0] = test_img_mono[i,:,:,0]","ee84007a":"test_img_mono_pad.shape","23f16b75":"test_img_mono.sum() == test_img_mono_pad.sum()","6ac3909a":"test_img_mono_pad = test_img_mono_pad.astype('float32')\/255","77466f6c":"predict = model.predict(test_img_mono_pad)","eaafacd9":"predict.shape","1dfea103":"predict_mod = np.zeros((predict.shape[0],101,101))","5112ac02":"for i in range(test_num):\n    predict_mod[i,:,:] = predict[i,top_pad:-bottom_pad,left_pad:-right_pad,0]","9c92f113":"predict_mod.shape","25d28048":"predict_mask = np.zeros((predict_mod.shape[0],predict_mod.shape[1],predict_mod.shape[2]))","ccb83011":"predict_mask = predict_mod > best_threshold","e7153289":"def mask_to_rle(mask):\n    mask_flat = mask.flatten('F')\n    flag = 0\n    rle_list = list()\n    for i in range(mask_flat.shape[0]):\n        if flag == 0:\n            if mask_flat[i] == 1:\n                flag = 1\n                starts = i+1\n                rle_list.append(starts)\n        else:\n            if mask_flat[i] == 0:\n                flag = 0\n                ends = i\n                rle_list.append(ends-starts+1)\n    if flag == 1:\n        ends = mask_flat.shape[0]\n        rle_list.append(ends-starts+1)\n    #sanity check\n    if len(rle_list) % 2 != 0:\n        print('NG')\n    if len(rle_list) == 0:\n        rle = np.nan\n    else:\n        rle = ' '.join(map(str,rle_list))\n    return rle","61f11e01":"import math\n\nfor i,name in train_img_dict_i_to_names.items():\n    mask = train_mask_8bit[i]\/255\n    rle = mask_to_rle(mask)\n    rle_ans = train['rle_mask'][train['id']==name].values[0]\n    if rle == rle_ans:\n        continue\n    elif math.isnan(rle) == True and math.isnan(rle_ans) == True:\n        continue\n    else:\n        print('NG')","51fefb67":"submit_name = list()\nsubmit_rle = list()","28c76b28":"for i in range(test_num):\n    name = test_img_dict_i_to_names[i]\n    rle = mask_to_rle(predict_mask[i])\n    submit_name.append(name)\n    submit_rle.append(rle)","cb0e9b18":"submit_df = pd.DataFrame({'id':submit_name, 'rle_mask':submit_rle})","674aad4f":"submit_df.head()","0e268cb9":"submit_df.shape","3a67e9e6":"submit_df.to_csv('first_180929.csv', index=False)","ae50a9bc":"change color image to monochrome image","0d516d4b":"encode mask to rle","b550f374":"save model","bcc75930":"change probability to zero-one (threshold = best threshold)","c7e3513b":"zero padding 101 to 128","8a2d3c8e":"sanity check","c44e3e17":"How many bits color representation?","153e5607":"### search best threshold","f64505f8":"normalization","e6bbb8a8":"### create dict of filename to number and number to filename from test_image name list","b3c89d06":"remove zero padding and change axis-4 to axis-3","c2d8c44e":"search best threshold","5ac1a37e":"### get test_image name list","3ab8d346":"sanity check: Is train_image name list same with train_mask name list?","71163a90":"build model","d174dbd9":"get size of train_image and train_mask","de11396e":"Is train_image monochrome?","4912b4fc":"change 16bit to 8bit for train_mask","3cb51237":"reshape 3-axis to 4-axis","c2f8509d":"V12: add search of best threshold\n\nV11: add calculation metric","11ef1126":"get train_image name list","9ebaced9":"### get train_image name list","07a34a97":"### check and modify data","c634f925":"reshape 3-axis to 4-axis","071852fa":"### predict","31af604d":"### create dict of  filename to number and number to filename  from train_image name list","a3a256d8":"predict","e7bd40f1":"sanity check","4f1a00d7":"create function of metric","2808822e":"create rle_decode (rle to mask)","cfebb955":"### load test_image","9ae983e6":"## Next Step\n- split train-val\n- augmentation, reguralization","8cf84daa":"create metric function ","eeebc735":"sanity check","f7c0ab61":"check","0e5ccfa5":"change color image to monochrome image","bf6d2e30":"normalization","d2040adf":"set directory path","d3dc7594":"remove zero-padding zone","2750baa2":"get number of train samples","e94326ac":"sanity check","c5532338":"#### Are mask(image) and mask(rle) equal?","486d4fc2":"### build model","971c8c43":"Is test_image monochrome?","322c9924":"### check and modify data","79f051da":"load train.csv","2c5ef6aa":"sanity check","a471546f":"How many bits color representation?","d128c46d":"check","d88c25b0":"### load train images and masks","2762b9e3":"load train_images and masks","07996310":"create submission file"}}