{"cell_type":{"9b64d2d6":"code","6e9a18d0":"code","b4da2e0c":"code","2ad78aae":"code","fee66726":"code","a1ab0960":"code","498a7e12":"code","a1881b05":"code","350f801c":"code","feb08b41":"code","1d7e2742":"code","7f49117b":"code","e14374cb":"code","a2385e93":"code","d2bc6f54":"code","d35cd044":"code","05676972":"code","333116b7":"code","a8e5896c":"code","acca000f":"code","56f6d279":"code","9e57f037":"code","f71a2f5a":"code","5b38aaa7":"code","a8551186":"code","4117736c":"code","ccdf2a2e":"code","9fe7a112":"code","30a5763d":"code","db8d0ac5":"code","fb9c75c7":"code","5ba2a0ce":"code","a478fc45":"code","0001ba35":"code","b1e37943":"code","c5b74d74":"code","bcafa691":"code","25aa676f":"code","02aa176f":"code","cba52d1c":"code","7197da78":"code","33d44d19":"code","d2339559":"code","5e3c65e6":"code","80904b16":"code","66d488e4":"code","bcdd3eb4":"code","3d929b80":"code","0db97d81":"code","4b09b199":"code","68cd4c50":"code","d6bf514d":"code","6120bfab":"code","55d19b33":"code","1e289dab":"code","b8a9ddf7":"code","7b257e7a":"code","6f1d4835":"code","6aa465ce":"code","f342a0a3":"code","a032eb5d":"code","0dcc8b0b":"code","6befbb55":"code","ba2b2f65":"code","9961dac4":"code","46e98cd0":"code","836f587b":"code","756095b9":"markdown","b4a9b116":"markdown","938d7706":"markdown","fcfb87df":"markdown","c70341ab":"markdown","50a9e0f9":"markdown","6af4feb3":"markdown","00995af3":"markdown","35cbf5b8":"markdown","535f3cff":"markdown","3084316b":"markdown","93ffaede":"markdown","9775cc30":"markdown","fa692227":"markdown","2d728d5f":"markdown","54f4d998":"markdown","8b21a8a4":"markdown","95443216":"markdown","092f57d0":"markdown","d0d79243":"markdown","949b8414":"markdown","1ccfb26d":"markdown","44ce4056":"markdown","8a71571f":"markdown","8a9417b6":"markdown","a486641a":"markdown","c6587c97":"markdown","8124b102":"markdown","51601461":"markdown","3014dc13":"markdown","6c5a1ceb":"markdown","0612155e":"markdown","742af3a4":"markdown","e05645d8":"markdown","814c3656":"markdown","287847c1":"markdown","35084e87":"markdown","9c583d3c":"markdown","c9976aba":"markdown","b562d97a":"markdown","e5ebf1ed":"markdown","28cf0457":"markdown","dee16a60":"markdown","9d96105a":"markdown","ee8bdcd8":"markdown","c05c6e6f":"markdown","e4b9a5a3":"markdown","11aa2a0c":"markdown","24ad1f8d":"markdown","1548a6f3":"markdown","7780ba1e":"markdown","09c1a70b":"markdown","3d1f5d3d":"markdown","c3dccc6a":"markdown","4d73f63d":"markdown","c29f3e1d":"markdown","a2722196":"markdown","5725c16a":"markdown","6b79b056":"markdown"},"source":{"9b64d2d6":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy.stats import zscore","6e9a18d0":"data = pd.read_csv('..\/input\/vehicle.csv')\ndata.head()","b4da2e0c":"data.shape","2ad78aae":"data.isnull().sum()","fee66726":"data.describe().transpose()","a1ab0960":"data.info()","498a7e12":"data.fillna(data.mean(), axis = 0, inplace = True)\nprint(data.isnull().sum())\nprint(data.shape)","a1881b05":"#class is target column\ndata.groupby('class').count()","350f801c":"plt.figure(figsize = (15,15))\nsns.pairplot(data = data, diag_kind = 'kde', hue = 'class')","feb08b41":"fig, (g1, g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['compactness'], ax = g1)\ng1.set_title('Distribution Plot')\n\nsns.boxplot(data['compactness'], ax = g2)\ng2.set_title('Box Plot')","1d7e2742":"fig, (g1, g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['circularity'], ax = g1)\ng1.set_title('Distribution Plot')\n\nsns.boxplot(data['circularity'], ax = g2)\ng2.set_title('Box Plot')","7f49117b":"fig, (g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['distance_circularity'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['distance_circularity'], ax = g2)\ng2.set_title(\"Box Plot\")","e14374cb":"fig, (g1, g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['radius_ratio'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['radius_ratio'], ax = g2)\ng2.set_title(\"Box Plot\")","a2385e93":"q1 = np.quantile(data['radius_ratio'], 0.25)\nq2 = np.quantile(data['radius_ratio'], 0.50)\nq3 = np.quantile(data['radius_ratio'], 0.75)\nIQR = q3 - q1\n#outlier = q1 - 1.5*IQR and q3 + 1.5*IQR... here as outliers are in the 4th quartile hence using 2 formula\n#Printing the quartile\n\nprint(\"Quartile q1: \", q1)\nprint(\"Quartile q2: \", q2)\nprint(\"Quartile q3: \", q3)\nprint(\"Inter Quartile Range: \", IQR)\n\nprint(\"radius_ratio above \", data['radius_ratio'].quantile(0.75) + (1.5*IQR), \"are outliers\")\nprint(\"No. of outliers \", data[data['radius_ratio'] > 276]['radius_ratio'].shape[0])\n","d2bc6f54":"fig, (g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['pr.axis_aspect_ratio'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['pr.axis_aspect_ratio'], ax = g2)\ng2.set_title(\"Box Plot\")","d35cd044":"#Performing Outlier analysis\n\nq1 = np.quantile(data['pr.axis_aspect_ratio'], 0.25)\nq2 = np.quantile(data['pr.axis_aspect_ratio'], 0.50)\nq3 = np.quantile(data['pr.axis_aspect_ratio'], 0.75)\nIQR = q3 - q1\n#outlier = q1 - 1.5*IQR and q3 + 1.5*IQR... here as outliers are in the 4th quartile hence using 2 formula\n#Printing the quartile\n\nprint(\"Quartile q1: \", q1)\nprint(\"Quartile q2: \", q2)\nprint(\"Quartile q3: \", q3)\nprint(\"Inter Quartile Range: \", IQR)\n\nprint(\"pr.axis_aspect_ratio above \", data['pr.axis_aspect_ratio'].quantile(0.75) + (1.5*IQR), \"are outliers\")\nprint(\"No. of outliers \", data[data['pr.axis_aspect_ratio'] > 77.0]['pr.axis_aspect_ratio'].shape[0])","05676972":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['max.length_aspect_ratio'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['max.length_aspect_ratio'], ax = g2)\ng2.set_title(\"Box Plot\")","333116b7":"#Performing Outlier analysis\n\nq1 = np.quantile(data['max.length_aspect_ratio'], 0.25)\nq2 = np.quantile(data['max.length_aspect_ratio'], 0.50)\nq3 = np.quantile(data['max.length_aspect_ratio'], 0.75)\nIQR = q3 - q1\n#outlier = q1 - 1.5*IQR and q3 + 1.5*IQR... here as outliers are in the 4th quartile hence using 2 formula\n#Printing the quartile\n\nprint(\"Quartile q1: \", q1)\nprint(\"Quartile q2: \", q2)\nprint(\"Quartile q3: \", q3)\nprint(\"Inter Quartile Range: \", IQR)\n\nprint(\"max.length_aspect_ratio above \", data['max.length_aspect_ratio'].quantile(0.75) + (1.5*IQR), \"are outliers\")\nprint(\"max.length_aspect_ratio below \", data['max.length_aspect_ratio'].quantile(0.25) - (1.5*IQR), \"are outliers\")\n\nprint(\"No. of outliers above  are\",data[data['max.length_aspect_ratio']>14.5]['max.length_aspect_ratio'].shape[0])\nprint(\"No. of outliers below are\",data[data['max.length_aspect_ratio']<2.5]['max.length_aspect_ratio'].shape[0])","a8e5896c":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['scatter_ratio'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['scatter_ratio'], ax = g2)\ng2.set_title(\"Box Plot\")","acca000f":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['elongatedness'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['elongatedness'], ax = g2)\ng2.set_title(\"Box Plot\")","56f6d279":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['pr.axis_rectangularity'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['pr.axis_rectangularity'], ax = g2)\ng2.set_title(\"Box Plot\")","9e57f037":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['max.length_rectangularity'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['max.length_rectangularity'], ax = g2)\ng2.set_title(\"Box Plot\")","f71a2f5a":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['scaled_variance'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['scaled_variance'], ax = g2)\ng2.set_title(\"Box Plot\")","5b38aaa7":"#Performing Outlier analysis\n\nq1 = np.quantile(data['scaled_variance'], 0.25)\nq2 = np.quantile(data['scaled_variance'], 0.50)\nq3 = np.quantile(data['scaled_variance'], 0.75)\nIQR = q3 - q1\n#outlier = q1 - 1.5*IQR and q3 + 1.5*IQR... here as outliers are in the 4th quartile hence using 2nd formula\n#Printing the quartile\n\nprint(\"Quartile q1: \", q1)\nprint(\"Quartile q2: \", q2)\nprint(\"Quartile q3: \", q3)\nprint(\"Inter Quartile Range: \", IQR)\n\nprint(\"scaled_variance above \", data['scaled_variance'].quantile(0.75) + (1.5*IQR), \"are outliers\")\nprint(\"No. of outliers \", data[data['scaled_variance'] > 292]['scaled_variance'].shape[0])","a8551186":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['scaled_variance.1'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['scaled_variance.1'], ax = g2)\ng2.set_title(\"Box Plot\")","4117736c":"#Performing Outlier analysis\n\nq1 = np.quantile(data['scaled_variance.1'], 0.25)\nq2 = np.quantile(data['scaled_variance.1'], 0.50)\nq3 = np.quantile(data['scaled_variance.1'], 0.75)\nIQR = q3 - q1\n#outlier = q1 - 1.5*IQR and q3 + 1.5*IQR... here as outliers are in the 4th quartile hence using 2 formula\n#Printing the quartile\n\nprint(\"Quartile q1: \", q1)\nprint(\"Quartile q2: \", q2)\nprint(\"Quartile q3: \", q3)\nprint(\"Inter Quartile Range: \", IQR)\n\nprint(\"scaled variance.1 above \", data['scaled_variance.1'].quantile(0.75) + (1.5*IQR), \"are outliers\")\nprint(\"No. of outliers \", data[data['scaled_variance.1'] > 989.5]['scaled_variance.1'].shape[0])","ccdf2a2e":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['scaled_radius_of_gyration'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['scaled_radius_of_gyration'], ax = g2)\ng2.set_title(\"Box Plot\")","9fe7a112":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['scaled_radius_of_gyration.1'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['scaled_radius_of_gyration.1'], ax = g2)\ng2.set_title(\"Box Plot\")","30a5763d":"#Performing Outlier analysis\n\nq1 = np.quantile(data['scaled_radius_of_gyration.1'], 0.25)\nq2 = np.quantile(data['scaled_radius_of_gyration.1'], 0.50)\nq3 = np.quantile(data['scaled_radius_of_gyration.1'], 0.75)\nIQR = q3 - q1\n#outlier = q1 - 1.5*IQR and q3 + 1.5*IQR... here as outliers are in the 4th quartile hence using 2 formula\n#Printing the quartile\n\nprint(\"Quartile q1: \", q1)\nprint(\"Quartile q2: \", q2)\nprint(\"Quartile q3: \", q3)\nprint(\"Inter Quartile Range: \", IQR)\n\nprint(\"scaled radius of gyration.1 above \", data['scaled_radius_of_gyration.1'].quantile(0.75) + (1.5*IQR), \"are outliers\")\nprint(\"No. of outliers \", data[data['scaled_radius_of_gyration.1'] > 87]['scaled_radius_of_gyration.1'].shape[0])","db8d0ac5":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['skewness_about'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['skewness_about'], ax = g2)\ng2.set_title(\"Box Plot\")","fb9c75c7":"#Performing Outlier analysis\n\nq1 = np.quantile(data['skewness_about'], 0.25)\nq2 = np.quantile(data['skewness_about'], 0.50)\nq3 = np.quantile(data['skewness_about'], 0.75)\nIQR = q3 - q1\n#outlier = q1 - 1.5*IQR and q3 + 1.5*IQR... here as outliers are in the 4th quartile hence using 2 formula\n#Printing the quartile\n\nprint(\"Quartile q1: \", q1)\nprint(\"Quartile q2: \", q2)\nprint(\"Quartile q3: \", q3)\nprint(\"Inter Quartile Range: \", IQR)\n\nprint(\"skewness_about above \", data['skewness_about'].quantile(0.75) + (1.5*IQR), \"are outliers\")\nprint(\"No. of outliers \", data[data['skewness_about'] > 19.5]['skewness_about'].shape[0])","5ba2a0ce":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['skewness_about.1'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['skewness_about.1'], ax = g2)\ng2.set_title(\"Box Plot\")","a478fc45":"#Performing Outlier analysis\n\nq1 = np.quantile(data['skewness_about.1'], 0.25)\nq2 = np.quantile(data['skewness_about.1'], 0.50)\nq3 = np.quantile(data['skewness_about.1'], 0.75)\nIQR = q3 - q1\n#outlier = q1 - 1.5*IQR and q3 + 1.5*IQR... here as outliers are in the 4th quartile hence using 2 formula\n#Printing the quartile\n\nprint(\"Quartile q1: \", q1)\nprint(\"Quartile q2: \", q2)\nprint(\"Quartile q3: \", q3)\nprint(\"Inter Quartile Range: \", IQR)\n\nprint(\"skewness about.1 above \", data['skewness_about.1'].quantile(0.75) + (1.5*IQR), \"are outliers\")\nprint(\"No. of outliers \", data[data['skewness_about.1'] > 40]['skewness_about.1'].shape[0])","0001ba35":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['skewness_about.2'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['skewness_about.2'], ax = g2)\ng2.set_title(\"Box Plot\")","b1e37943":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(data['hollows_ratio'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(data['hollows_ratio'], ax = g2)\ng2.set_title(\"Box Plot\")","c5b74d74":"data.groupby('class').count()","bcafa691":"sns.countplot(data['class'])","25aa676f":"plt.figure(figsize = (15,10))\nsns.heatmap(data.corr(), annot = True)","02aa176f":"#Preparing X independent columns, y dependent columns\ndata_attr = data.drop('class', axis = 1)\ndata_target = data['class']\n\nprint(data_attr.shape)\nprint(data_target.shape)","cba52d1c":"#Scaling the attribute data\n\ndata_attr_s = data_attr.apply(zscore)","7197da78":"#Replacing Target column into numbers\n\ndata_target.replace({\"car\": 0, \"bus\": 1, \"van\": 2}, inplace = True)\n\nprint(data_target.shape)","33d44d19":"#Applying Covariance matrix\n\ncov_mat = np.cov(data_attr_s, rowvar = False)\nprint(cov_mat)","d2339559":"#Shape of Covariance matrix\nprint(cov_mat.shape)","5e3c65e6":"#Applying Principal Component Analysis for all 18 columns\n\nfrom sklearn.decomposition import PCA\npca_18 = PCA(n_components = 18)\n\npca_18.fit(data_attr_s)","80904b16":"#Eigen values\nprint(pca_18.explained_variance_)","66d488e4":"#Eigen vectors\nprint(pca_18.components_)","bcdd3eb4":"#Variance ratio\nprint(pca_18.explained_variance_ratio_)","3d929b80":"#Plot Eigen values\nplt.bar(list(range(1,19)), pca_18.explained_variance_ratio_, alpha = 0.5, align = 'center')\nplt.ylabel('Variation explained')\nplt.xlabel('Eigen values')\nplt.show()","0db97d81":"#Plot using step function\n\nplt.step(list(range(1,19)), np.cumsum(pca_18.explained_variance_ratio_), where = 'mid')\nplt.ylabel('Cum of variation explained')\nplt.xlabel('Eigen value')\nplt.show()","4b09b199":"#Applying PCA for 8 components this time\npca_8 = PCA(n_components = 8)\npca_8.fit(data_attr_s)\nprint(pca_8.components_)\nprint(pca_8.explained_variance_ratio_)","68cd4c50":"#Transform the raw data with 18 dim into 8 dims\ndata_attr_s_pca_8 = pca_8.transform(data_attr_s)\ndata_attr_s_pca_8.shape","d6bf514d":"#Draw pairplot to find correlation\nsns.pairplot(pd.DataFrame(data_attr_s_pca_8))","6120bfab":"from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import accuracy_score,confusion_matrix, classification_report\nfrom sklearn.svm import SVC","55d19b33":"accuracies = {}\nmodel = SVC()\n\nX_train, X_test, y_train, y_test = train_test_split(data_attr_s_pca_8, data_target, test_size = 0.30, random_state = 1)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nacc_svm = model.score(X_test, y_test) *100\n\naccuracies['SVM'] = acc_svm\nprint(model.score(X_train, y_train))\nprint(model.score(X_test, y_test))","1e289dab":"print(classification_report(y_test,y_pred))","b8a9ddf7":"#Finding best parameters for our SVM model\n\nparam = {\n    'C' : [0.01,0.05,0.5,1],\n    'kernel' :['linear','rbf']\n}\n\ngrid_svm = GridSearchCV(model, param_grid = param, scoring = 'accuracy', cv = 10)","7b257e7a":"grid_svm.fit(X_train,y_train)","6f1d4835":"grid_svm.best_params_","6aa465ce":"#Running our kernel with best parameters\n\n\n#Kernel = rbf, C = 1\nmodel_svm = SVC(C = 1, kernel = 'rbf', gamma = 1)\nX_train, X_test, y_train, y_test = train_test_split(data_attr_s_pca_8, data_target, test_size = 0.30, random_state = 1)\nmodel_svm.fit(X_train, y_train)\ny_pred = model_svm.predict(X_test)\n\nacc_svm_gs = model_svm.score(X_test, y_test) * 100\naccuracies['SVM_GS'] = acc_svm_gs\nprint(model.score(X_test, y_test))\nprint(classification_report(y_test, y_pred))\n","f342a0a3":"#Cross validation score for SVM\n\nsvm_eval = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10)\nsvm_eval.mean()","a032eb5d":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\n\n\nnb_model = GaussianNB()\nnb_model.fit(X_train, y_train)\nexpected = y_test\npredicted = nb_model.predict(X_test)\n\nacc_nb = nb_model.score(X_test, y_test) * 100\naccuracies['NB'] = acc_nb","0dcc8b0b":"#Determine Model score\n\nprint(metrics.classification_report(expected, predicted))\nprint('Total accuracy: ', np.round(metrics.accuracy_score(expected, predicted), 2))","6befbb55":"sns.set_style('whitegrid')\nplt.figure(figsize = (8,5))\nplt.yticks(np.arange(0,100,10))\nsns.barplot(x = list(accuracies.keys()), y = list(accuracies.values()))","ba2b2f65":"models = pd.DataFrame({\n    'Model': ['SVM', 'SVM_GS','Naive Bayes'],\n    \n    'Score': [acc_svm, acc_svm_gs, acc_nb]\n    })\n\nmodels.sort_values(by='Score', ascending=False)","9961dac4":"y_cm_svm = model.predict(X_test)\ny_cm_svm_gs = model_svm.predict(X_test)\ny_cm_nb = nb_model.predict(X_test)","46e98cd0":"from sklearn.metrics import confusion_matrix\n\ncm_svm = confusion_matrix(y_test, y_cm_svm)\ncm_svm_gs = confusion_matrix(y_test, y_cm_svm_gs)\ncm_nb = confusion_matrix(y_test, y_cm_nb)","836f587b":"plt.figure(figsize = (16,4))\nplt.suptitle(\"Confusion Matrices\",fontsize=12)\nplt.subplots_adjust(wspace = 0.8, hspace = 0.8)\n\nplt.subplot(1,3,1)\nplt.title(\"SVM Confusion Matrix\")\nsns.heatmap(cm_svm, annot = True, cmap = \"Blues\", fmt = 'd', cbar = False, annot_kws = {\"size\": 12})\n\n\nplt.subplot(1,3,2)\nplt.title(\"SVM Grid Search Confusion Matrix\")\nsns.heatmap(cm_svm_gs, annot = True, cmap = \"Blues\", fmt = 'd', cbar = False, annot_kws = {\"size\": 12})\n\nplt.subplot(1,3,3)\nplt.title(\"NB Confusion Matrix\")\nsns.heatmap(cm_nb, annot = True, cmap = \"Blues\", fmt = 'd', cbar = False, annot_kws = {\"size\": 12})","756095b9":"# 4. Principal Component Analysis","b4a9b116":"## 2.15 Skewness about","938d7706":"## 2.10 Max length rectangularity","fcfb87df":"# 8. Confusion Matrix","c70341ab":"## 2.13 Scaled radius of gyration","50a9e0f9":"# 7. Model Comparison","6af4feb3":"Let's analyze every column in detail.","00995af3":"The distribution plot has 3 peaks and is right skewed.","35cbf5b8":"## 2.18 Hollows ratio","535f3cff":"# 3. EDA Summary of Independent and dependent variables","3084316b":"The distribution plot shows 2 peaks with outliers.","93ffaede":"## 2.9 Pr.Axis rectangularity","9775cc30":"## 2.5 Pr.Axis aspect ratio","fa692227":"Compactness column shows an approximately normal distribution curve while having no outliers.","2d728d5f":"There are 3 peaks observed and no outliers in the data.","54f4d998":"Here there are some columns which share high collinearity while some share low collinearity. We can drop the columns whichever share high collinearity as there's no use in considering multiple columns. We will use Principal Component Analysis to determine which columns can be dropped.","8b21a8a4":"There are 2 peaks observed and the distribution is right skewed.","95443216":"## 2.12 Scaled variance.1","092f57d0":"## 2.4 Radius Ratio","d0d79243":"We can infer,\n\n* compactness - Approx normal distribution, no outliers\n* circularity - Slightly right skewed\n* distance_circularity - Left skewed\n* radius_ratio - Approx normal distribution, with 3 outliers\n* pr.axis_aspect_ratio - Approx normal distribution, with 8 outliers\n* max.length_aspect_ratio - 2 peak, 13 outliers\n* scatter_ratio - 2 peaks, right skewed\n* elongatedness - 2 peaks, left skewed\n* pr.axis_rectangularity - 2 peaks, right skewed\n* max.length_rectangularity - 3 peaks, no outliers\n* scaled_variance - 2 peaks, 1 outlier\n* scaled_variance.1 - 2 peaks, 2 outliers\n* scaled_radius_of_gyration - Slightly right skewed\n* scaled_radius_of_gyration.1 - 15 Outliers\n* skewness_about - right skewed, 12 outliers\n* skewness_about.1 - 1 outlier\n* skewness_about.2 - No outlier\n* hollows_ratio - 2 peaks, no outlier\n* class - more no. of car > bus > van\n\n\nWe have chosen to not remove the outliers as the no. of outliers is insignificant and it wouldn't bias the model. However dropping these outliers may give us a better model. Assuming these outliers were artificially introduced during data collection.\n","949b8414":"## 2.6 Max length aspect ratio","1ccfb26d":"## 2.11 Scaled variance","44ce4056":"There are few null values in almost every column,we will try to impute this with mean value this would slightly bias the dataset but won't impact the model significantly.  ","8a71571f":"**Using Grid Search we can infer the model accuracy is 83%.**","8a9417b6":"There are 2 peaks observed and no outliers in the data.","a486641a":"**We can conclude SVM is the best suited algorithm as it gives a good accuracy score of 93% on test data and confusion matrix gives a good classification.**\n\n\n**To conclude PCA helps to reduced 18 dimension data into 8 dimension data with SVM score of 93% accuracy**","c6587c97":"We have imputed all the rows with their mean values.","8124b102":"There is a data imbalance as car has a significantly higher count as compared to bus and van. While van has the lowest count.","51601461":"# 5. Support Vector Machines","3014dc13":"### Performing outlier analysis","6c5a1ceb":"## 2.14 Scaled radius of gyration.1","0612155e":"**SVM model gives an accuracy of 93%**","742af3a4":"There are many missing values. We will choose to impute these null values instead of dropping them.","e05645d8":"**Naive Bayes model gives an accuracy of 76%**","814c3656":"## 2.19 Class","287847c1":"## 2.16 Skewness about.1","35084e87":"There are 2 peaks observed and the distribution is left skewed.","9c583d3c":"## 2.1 Compactness","c9976aba":"## Correlation Matrix","b562d97a":"There are 2 peaks observed and the distribution is right skewed.","e5ebf1ed":"Most of these columns share a strong correlation with each other. We can also notice certain outliers in this data. ","28cf0457":"# 2.EDA","dee16a60":"Here the distribution plot has 2 peaks and is left skewed","9d96105a":"Here it is right skewed and there is presence of outliers.","ee8bdcd8":"The distribution is approx normally distributed as well as right skewed and there is presence of outliers.","c05c6e6f":"## 2.3 Distance Circularity ","e4b9a5a3":"There are 2 peaks and significant no. of outliers are observed.","11aa2a0c":"## 2.2 Circularity","24ad1f8d":"## 2.17 Skewness about.2","1548a6f3":"There is some imbalance in terms of class. This will have some impact on model.","7780ba1e":"## 2.7 Scatter ratio","09c1a70b":"We have 8 components in this model that explain 95% variation in this data.","3d1f5d3d":"**Accuracy score is 83% using Grid Search, however SVM gives an accuracy of 93%**","c3dccc6a":"# 1. Observe dataset","4d73f63d":"It has an approximate normal distribution with no outliers.","c29f3e1d":"# Using Grid Search","a2722196":"The purpose of the case study is to classify a given silhouette as one of three different types of vehicle, using a set of features extracted from the silhouette. The vehicle may be viewed from one of many different angles.\n\nFour \"Corgie\" model vehicles were used for the experiment: a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400 cars. This particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars.","5725c16a":"# 6. Naive Bayes Algorithm","6b79b056":"## 2.8 Elongatedness"}}