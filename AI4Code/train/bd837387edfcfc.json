{"cell_type":{"5c4dfd17":"code","66d6ace2":"code","be01c9db":"code","3554d80f":"code","e22a228d":"code","3ad3b2bf":"code","80fed643":"code","bb97d90a":"code","72ec2ec0":"code","9e36e8ab":"code","b14de452":"code","25c9b5a7":"code","378ce772":"code","56852f46":"code","22c721bf":"code","a8f6627b":"markdown","5bae8077":"markdown","a6fa3f4d":"markdown"},"source":{"5c4dfd17":"from keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import regularizers\nfrom tensorflow.keras import optimizers\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport gc\nimport pickle","66d6ace2":"gc.collect()","be01c9db":"def append_ext(fn):\n    return fn + \".jpg\"\n\ntraindf = pd.read_csv('..\/input\/planet-understanding-the-amazon-from-space\/train_v2.csv\/train_v2.csv', dtype=str)\ntestdf = pd.read_csv('..\/input\/planet-understanding-the-amazon-from-space\/sample_submission_v2.csv\/sample_submission_v2.csv', dtype=str)\n\ntraindf[\"image_name\"] = traindf[\"image_name\"].apply(append_ext)\ntestdf[\"image_name\"] = testdf[\"image_name\"].apply(append_ext)\n\ndatagen = ImageDataGenerator(rescale = 1.\/255.,\n                             validation_split = 0.25,\n                             rotation_range = 10,\n                             width_shift_range = 0.2,\n                             height_shift_range = 0.2,\n                             zoom_range = 0.2,\n                             horizontal_flip = True,\n                             brightness_range = [0.2,1.2])","3554d80f":"train_generator = datagen.flow_from_dataframe(\n    dataframe = traindf,\n    directory = '..\/input\/d\/prosperchuks\/amazonsatelliteimages\/train-jpg\/train-jpg',\n    x_col = 'image_name',\n    y_col = 'tags',\n    subset = 'training',\n    batch_size = 340,\n    seed = 42,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32, 32))\n\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe = traindf,\n    directory = '..\/input\/d\/prosperchuks\/amazonsatelliteimages\/train-jpg\/train-jpg',\n    x_col = 'image_name',\n    y_col = 'tags',\n    subset = 'validation',\n    batch_size = 340,\n    seed = 42,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32, 32))\n\n","e22a228d":"test_generator = datagen.flow_from_dataframe(\n    dataframe = testdf,\n    directory = '..\/input\/d\/prosperchuks\/amazonsatelliteimages\/test-jpg\/test-jpg',\n    x_col = 'image_name',\n    y_col = None,\n    batch_size = 340,\n    seed = 42,\n    shuffle = False,\n    class_mode = None,\n    target_size = (32, 32))\n\ntest_generator2 = datagen.flow_from_dataframe(\n    dataframe = testdf,\n    directory = '..\/input\/d\/prosperchuks\/amazonsatelliteimages\/test-jpg-additional\/test-jpg-additional',\n    x_col = 'image_name',\n    y_col = None,\n    batch_size = 340,\n    seed = 42,\n    shuffle = False,\n    class_mode = None,\n    target_size = (32, 32))","3ad3b2bf":"# using the VGG16 Architecture\nmodel = Sequential()\n\n# model.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3)))\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), padding='same'))\nmodel.add(Conv2D(128, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.5))\n\nmodel.add(Conv2D(256, (3, 3), padding='same'))\nmodel.add(Conv2D(256, (3, 3), padding='same'))\nmodel.add(Conv2D(256, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.5))\n\nmodel.add(Conv2D(512, (3, 3), padding='same'))\nmodel.add(Conv2D(512, (3, 3), padding='same'))\nmodel.add(Conv2D(512, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.5))\n\nmodel.add(Conv2D(512, (3, 3), padding='same'))\nmodel.add(Conv2D(512, (3, 3), padding='same'))\nmodel.add(Conv2D(512, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(4096))\nmodel.add(Dense(4096))\nmodel.add(Activation('relu'))\n# model.add(Dropout(0.5))\n\nmodel.add(Dense(449, activation='softmax'))\nopt = optimizers.RMSprop(learning_rate=0.0001)\nmodel.compile(optimizer=opt,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","80fed643":"model.summary()","bb97d90a":"STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_TEST = test_generator.n\/\/test_generator.batch_size\n\ntrain = model.fit(train_generator,\n          steps_per_epoch = STEP_SIZE_TRAIN,\n          validation_data = valid_generator,\n          validation_steps = STEP_SIZE_VALID,\n          epochs=5)","72ec2ec0":"plt.figure()\nplt.plot(train.history['loss'], 'blue')\nplt.plot(train.history['val_loss'], 'red')\nplt.legend(['Training Loss', 'Validation Loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.figure()\nplt.plot(train.history['accuracy'], 'blue')\nplt.plot(train.history['val_accuracy'], 'red')\nplt.legend(['Training Accuracy', 'Validation Accuracy'])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')","9e36e8ab":"model.evaluate(valid_generator, steps=STEP_SIZE_TEST)","b14de452":"test_generator.reset()\npred = model.predict(test_generator, steps=STEP_SIZE_TEST, verbose=1)","25c9b5a7":"test_generator2.reset()\npred2 = model.predict(test_generator2, steps=STEP_SIZE_TEST, verbose=1)","378ce772":"predicted_class_indices = np.argmax(pred, axis=1)\npredicted_class_indices2 = np.argmax(pred2, axis=1)\n\nlabels = (train_generator.class_indices)\nlabels = dict((v, k) for k, v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\n\nfilenames = test_generator.filenames\npredict = pd.DataFrame(predictions, columns=['tags'])\nfilename = pd.DataFrame(filenames, columns=['image_name'])[:40460]","56852f46":"labels2 = (train_generator.class_indices)\nlabels2 = dict((v, k) for k, v in labels2.items())\npredictions2 = [labels2[k] for k in predicted_class_indices2]\n\nfilenames = test_generator2.filenames\npredict2 = pd.DataFrame(predictions2, columns=['tags'])\nfilename2 = pd.DataFrame(filenames, columns=['image_name'])\n\n# saving predictions to csv file\nresults = pd.concat([filename, predict], axis=1)\nresults2 = pd.concat([filename2, predict2], axis=1)\nfinal_result = pd.concat([results, results2])","22c721bf":"final_result\nfinal_result.to_csv(\".\/final-results.csv\", index=False)","a8f6627b":"#### building the model","5bae8077":"#### making predictions","a6fa3f4d":"##### mapping the predicted class indices\/labels with the filenames"}}