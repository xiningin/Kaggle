{"cell_type":{"402e8300":"code","bcb1b311":"code","c628c045":"code","d81fe9b7":"code","b286dfb5":"code","9cc1068f":"code","9722b9d9":"code","f1769d21":"code","ad74a4d4":"code","6f76c0f2":"code","de712952":"code","65eabf10":"code","c50afef7":"code","234f5b97":"code","e0ed93e8":"code","8857b213":"code","a8a9e9ac":"code","c1f5dc11":"code","f4c9f386":"code","5c50c05b":"code","bb4a90be":"markdown","a0873045":"markdown"},"source":{"402e8300":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bcb1b311":"!pip install pyspark","c628c045":"column_names = [\n    'age',\n    'workclass',\n    'fnlwgt',\n    'education',\n    'education-num',\n    'marital-status',\n    'occupation',\n    'relationship',\n    'race',\n    'sex',\n    'capital-gain',\n    'capital-loss',\n    'hours-per-week',\n    'native-country',\n    'salary'\n]\ntrain_df = pd.read_csv('\/kaggle\/input\/adult-datset-master-iuma\/adult.data', names=column_names)\ntest_df = pd.read_csv('\/kaggle\/input\/adult-datset-master-iuma\/adult.test', names=column_names)","d81fe9b7":"train_df.head()","b286dfb5":"test_df.head()","9cc1068f":"train_df = train_df.apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\ntrain_df_cp = train_df.copy()\n#no hay 'Holand-Netherlands' en el conjunto de test\ntrain_df_cp = train_df_cp.loc[train_df_cp['native-country'] != 'Holand-Netherlands']\ntrain_df_cp.to_csv('train.csv', index=False, header=False)\n\ntest_df = test_df.apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n\n# de las 16282 instancias de test, hay una con NaN... la elimino \ntest_df.dropna(how='any',axis=0, inplace=True) \n\ntest_df.to_csv('test.csv', index=False, header=False)","9722b9d9":"print('Training data shape: ', train_df.shape)\ntrain_df.head()","f1769d21":"print('Testing data shape: ', test_df.shape)\ntest_df.head()","ad74a4d4":"train_df.select_dtypes('object').apply(pd.Series.nunique, axis=0)","6f76c0f2":"test_df.select_dtypes('object').apply(pd.Series.nunique, axis=0)","de712952":"train_df['salary'] = train_df['salary'].apply(lambda x: 0 if x == '<=50K' else 1)\ntest_df['salary'] = test_df['salary'].apply(lambda x: 0 if x == '<=50K' else 1)\ntrain_df = pd.get_dummies(train_df)\ntest_df = pd.get_dummies(test_df)\nprint('Training Features shape: ', train_df.shape)\nprint('Testing Features shape: ', test_df.shape)","65eabf10":"# Align the training and testing data, keep only columns present in both dataframes\ntrain_df, test_df = train_df.align(test_df, join = 'inner', axis = 1)\nprint('Training Features shape: ', train_df.shape)\nprint('Testing Features shape: ', test_df.shape)","c50afef7":"print('Testing Features shape: ', test_df.shape)","234f5b97":"X_train = train_df.drop('salary', axis=1)\ny_train = train_df['salary']\nX_test = test_df.drop('salary', axis=1)\ny_test = test_df['salary']","e0ed93e8":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0, 1))\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","8857b213":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(solver='lbfgs', max_iter=10000)\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test, lr_pred)","a8a9e9ac":"from pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType\nfrom pyspark.sql.functions import isnan, when, count, col\n\n","c1f5dc11":"spark = SparkSession.builder.appName(\"Predict Adult Salary\").getOrCreate()","f4c9f386":"schema = StructType([\n    StructField(\"age\", IntegerType(), True),\n    StructField(\"workclass\", StringType(), True),\n    StructField(\"fnlwgt\", IntegerType(), True),\n    StructField(\"education\", StringType(), True),\n    StructField(\"education-num\", IntegerType(), True),\n    StructField(\"marital-status\", StringType(), True),\n    StructField(\"occupation\", StringType(), True),\n    StructField(\"relationship\", StringType(), True),\n    StructField(\"race\", StringType(), True),\n    StructField(\"sex\", StringType(), True),\n    StructField(\"capital-gain\", IntegerType(), True),\n    StructField(\"capital-loss\", IntegerType(), True),\n    StructField(\"hours-per-week\", IntegerType(), True),\n    StructField(\"native-country\", StringType(), True),\n    StructField(\"salary\", StringType(), True)\n])","5c50c05b":"train_df = spark.read.csv('train.csv', header=False, schema=schema)\ntest_df = spark.read.csv('test.csv', header=False, schema=schema)","bb4a90be":"## PySpark","a0873045":"## Pandas and Numpy"}}