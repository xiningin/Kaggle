{"cell_type":{"852de5dc":"code","92a21266":"code","b6272263":"code","9aa23450":"code","a3598a9c":"code","aa1aa5e6":"code","11d0869a":"code","6d1e7515":"code","cd326a72":"code","d2b5440d":"code","6e97a4f9":"code","efe71eb6":"code","265fc4d4":"code","3dcb212e":"code","d4db8ab0":"code","0a843adf":"markdown","7a0ead5e":"markdown"},"source":{"852de5dc":"# -- 0. import libraries -- \nimport os\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import DBSCAN, KMeans\nfrom sklearn.metrics import silhouette_score, silhouette_samples","92a21266":"# -- 1. loading dataset --\ndata = pd.read_csv('\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\ndata.head()","b6272263":"# -- 2. data preprocessing --\ndata = data.drop(columns='CustomerID')\ndata.Gender = data.Gender.replace({'Female': 1, 'Male': 0})\ndata.head()","9aa23450":"# -- 3. data visualization --\n\n# 3.1. Gender ratio:\ngender_counts = data.Gender.value_counts()\nfig = px.pie(gender_counts, title='Gender Ratio', values='Gender', names=['Male', 'Female'], hole=0.5)\nfig.show()","a3598a9c":"# 3.2. distribution of 'age', 'annual income', and 'spending score'\nplt.figure(1, figsize=(15, 6))\nfor i, x in enumerate(['Age', 'Annual Income (k$)','Spending Score (1-100)']):\n    plt.subplot(1, 3, i+1)\n    sns.histplot(data[x])\n    plt.title('{} distribution'.format(x))\nplt.show()","aa1aa5e6":"# 3.3. correlation matrix\nsns.heatmap(data.corr(),square=True, vmax=1, vmin =-1)\nplt.show()","11d0869a":"# 3.4. variables relationships.\nsns.pairplot(data, height = 2.5, hue='Gender')\n#plt.show()","6d1e7515":"# -- 4. scaling dataset -- \nscaler = StandardScaler()\nx = scaler.fit_transform(data)","cd326a72":"# plot 3d of 'age', 'annual income' and 'spending score', color is the gender.\nfig = px.scatter_3d(x=x[:,1], y=x[:,2], z=x[:,3], color=x[:,0])\nfig.show()","d2b5440d":"# for visualization purposes, I will delete the gender column, \n# but it doesn't mean that it's not important for prediction.\nx = x[:,1:4]","6e97a4f9":"# -- 4. modeling --\n\n# -- dbscan --\nmodel = DBSCAN(eps=0.5,min_samples=5)\ncluster_labels = model.fit_predict(x)\n\nn_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\nn_noise = list(cluster_labels).count(-1)\nprint('Estimated number of clusters: %d' % n_clusters)\nprint('Estimated number of noise points: %d' % n_noise)","efe71eb6":"# -- 5. evaluating -- \nfig, (ax1, ax2) = plt.subplots(1,2)\nfig.set_size_inches(18, 7)\n\n\n# ax1 - the silhouette plot\nax1.set_xlim([-1,1])\nax1.set_ylim([0, len(x)+(n_clusters+1)*10])\nsilhouette_avg = silhouette_score(x, cluster_labels)\nprint('for ', n_clusters, ' clusters, the average silhouette score is: ',  silhouette_avg)\n#silhouette score for each sample\nsample_silhouette_values = silhouette_samples(x, cluster_labels)\n\ny_lower=10\nfor i in range(n_clusters):\n    ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n    ith_cluster_silhouette_values.sort()\n    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n    y_upper = y_lower + size_cluster_i\n\n    color = cm.Set3(float(i)\/n_clusters)\n    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n                     -1, ith_cluster_silhouette_values,\n                     facecolor=color, edgecolor=color, alpha=0.7)\n    ax1.text(-0.95, y_lower+0.5*size_cluster_i, str(i))\n    y_lower=y_upper+10\n    \nax1.set_title('The silhouette plot for the various clusters.')\nax1.set_xlabel('The silhouette coeffocoent values')\nax1.set_ylabel('Cluster label')\n\n#vertical line for the average score\nax1.axvline(x=silhouette_avg, color='red',linestyle='--')\n\n\n# ax2 - the actual clusters formed\nidx=np.where(cluster_labels==-1)\nnew_labels=np.delete(cluster_labels, idx)\nnew_x=np.delete(x, idx, axis=0)\ncolors = cm.Set3(new_labels\/n_clusters)\nax2.scatter(new_x[:,1], new_x[:,2], marker='.', s=200, lw=0, alpha=0.7, c=colors, edgecolor='k')\nax2.set_title('The visualization of the clustered data.')\n\nplt.show()","265fc4d4":"fig = px.scatter_3d(x=x[:,0],y=x[:,1], z=x[:,2], color=cluster_labels)\nfig.show()","3dcb212e":"# -- kmean --\n# now let's try kmean and see the difference.\n\n# first we need to pick the number of clusters, according to the last elbow.\nwcss=[] #within cluster sum of squares\nfor k in range(2,10):\n    model = KMeans(n_clusters=k, init='k-means++', random_state=42)\n    model.fit(x)\n    wcss.append(model.inertia_)\n\nplt.plot(range(2,10), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('number of clusters')\nplt.ylabel('wcss')\nplt.show()","d4db8ab0":"# let's pick k=6\nmodel=KMeans(n_clusters=6, init='k-means++', random_state=42)\ncluster_labels=model.fit_predict(x)\n\nprint('silhouette score is: ', silhouette_score(x, cluster_labels).round(2))\nfig = px.scatter_3d(x=x[:,0],y=x[:,1], z=x[:,2], color=cluster_labels)\nfig.show()","0a843adf":"It seems that in this specific dataset kmeans gives a higher silhouette score, and produces better clusters.","7a0ead5e":"**References:**\n- dataset: https:\/\/www.kaggle.com\/vjchoudhary7\/customer-segmentation-tutorial-in-python\n- silhouette plot: https:\/\/scikit-learn.org\/stable\/auto_examples\/cluster\/plot_kmeans_silhouette_analysis.html"}}