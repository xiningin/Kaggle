{"cell_type":{"52344d26":"code","51b7c486":"code","b0afa035":"code","a379cb19":"code","993e6ecb":"code","d7769a1b":"code","1a01eba6":"code","6930684e":"code","39b0b2a5":"code","df892ade":"code","4fb86677":"code","40a0ca4e":"code","27e610e6":"code","f99f71c0":"code","e4920d0f":"code","673c74a5":"code","ef5360b9":"code","756a3823":"code","867b9936":"code","e7fdd16d":"code","48796e10":"code","067d92d3":"code","37b3f40c":"code","02376953":"code","bf0f67ef":"code","9244ddda":"code","d8eb8574":"code","a3b2b6be":"code","71a43bd5":"code","8e332ce3":"code","0fd2a6e6":"code","f61ada74":"code","5e4d4c85":"code","d894a458":"code","fdda8de0":"code","b1e082e8":"code","0f0ace0a":"code","eb9c91fe":"code","b1f7f71b":"code","0ef4e73d":"code","3a7ac610":"code","c818b425":"code","56b139c4":"code","26eb2ac3":"code","96855beb":"code","3470e9b1":"code","861cef8d":"code","95954164":"code","206f588b":"code","6cdd0535":"code","83836bfb":"code","5abd8cca":"code","6a0ad174":"code","3c04a14e":"code","c6fd6782":"code","83ab3497":"code","ecc46ffa":"code","3c61c858":"code","de946253":"code","f6a910d4":"code","90675815":"code","3d4e2473":"code","2c33ef36":"code","50671cc4":"code","7438a433":"code","8381cb2d":"code","fc3d7a2c":"code","ee3108aa":"code","4cd0d747":"code","79dce5b5":"code","0e3fcf37":"code","ca3e87c7":"code","2312143e":"code","adcee49d":"code","bd9f8d34":"code","1dd4ec61":"code","3660efa6":"code","b021e598":"code","15d285ac":"code","8fdda389":"code","f0b08d71":"code","77247e65":"code","dc0a6885":"code","53a7324b":"code","1d8431f5":"code","c3207790":"code","79ccb6b6":"code","ac63e0f5":"code","b3a22457":"code","4d3d8b3c":"code","78e2531c":"code","81f2f615":"code","1a394440":"code","adaa29c0":"code","19b8cd2b":"code","57429947":"code","b00e2b0b":"code","f38d6f36":"code","178ec733":"markdown","0af97833":"markdown","753fe3d3":"markdown"},"source":{"52344d26":"import pandas as pd\nimport numpy as np","51b7c486":"df = pd.read_csv('..\/input\/test-data\/data.csv')\ndf.head()","b0afa035":"df = pd.read_csv('..\/input\/test-data\/data.csv',names=['key1','key2','text','name_col','extra_col'])\ndf.head()","a379cb19":"df = pd.read_csv('..\/input\/test-data\/data.csv',names=['key1','key2','text','name_col'],index_col=['key1','key2'])\ndf","993e6ecb":"#Skip rows in a dataset\ndf = pd.read_csv('..\/input\/test-data\/data.csv',skiprows=[0,3])\ndf","d7769a1b":"#To check the null values\ndf = pd.read_csv('..\/input\/test-data\/data.csv',names=['key1','key2','text','name_col','extra_col'])\ndf.isnull()","1a01eba6":"#HTML reads only tabular format and stores each table in a seperate list index\nscore = pd.read_html('https:\/\/www.basketball-reference.com\/leagues\/NBA_2015_totals.html')\ntype(score)","6930684e":"#Correct way to read a data from html page\nscore[0]","39b0b2a5":"#Read only single column from the data\ndf = score[0]\ndf['Player']","df892ade":"#Read multiple columns\ndf[['Player','Age']]","4fb86677":"# To read all column names\ndf.columns","40a0ca4e":"titanic = pd.read_csv('..\/input\/titanic\/train_and_test2.csv')\ntitanic.head()","27e610e6":"#Read datatypes of each\ntitanic.dtypes","f99f71c0":"titanic.isnull().sum() #To take sum of all the null values","e4920d0f":"titanic = pd.read_csv('..\/input\/titanic\/train_and_test2.csv',nrows = 15) #Restricted to only 15 records\ntitanic","673c74a5":"titanic.to_csv(\".\/out.csv\")","ef5360b9":"titanic.to_csv(\".\/@seperated_data.csv\",sep='@')","756a3823":"df = pd.read_csv('..\/input\/test-data\/data.csv',names=['key1','key2','text','name_col','extra_col'])\ndf","867b9936":"import sys","e7fdd16d":"df.to_csv(sys.stdout,na_rep = 'utsav') \n#na_rep means\" NaN replacement\n#stdout is used to print the data in a standard format which can be copied easily","48796e10":"df","067d92d3":"df.to_csv('out1.csv', index = False, header = False) #No index No header","37b3f40c":"date = pd.date_range('1\/1\/2020',periods = 7)\ndate","02376953":"ts = pd.Series(np.arange(7),index=date)\nts","bf0f67ef":"ts = pd.Series(np.arange(3),index=['a','b','c'])\nts","9244ddda":"obj = \"\"\"\n{\n\t\"id\": \"0001\",\n\t\"type\": \"donut\",\n\t\"name\": \"Cake\",\n\t\"image\":\n\t\t{\n\t\t\t\"url\": \"images\/0001.jpg\",\n\t\t\t\"width\": 200,\n\t\t\t\"height\": 200\n\t\t},\n\t\"thumbnail\":\n\t\t{\n\t\t\t\"url\": \"images\/thumbnails\/0001.jpg\",\n\t\t\t\"width\": 32,\n\t\t\t\"height\": 32\n\t\t}\n}\"\"\"\ntype(obj)","d8eb8574":"#loads to convert the string into a dict\nimport json\nresult = json.loads(obj)\nprint(type(result))\nresult","a3b2b6be":"#loads to convert the dict into string \nresult1 = json.dumps(result)\nprint(type(result1))\nresult1","71a43bd5":"import requests","8e332ce3":"resp = requests.get('https:\/\/api.github.com\/repos\/pandas-dev\/pandas\/issues')\nresp","0fd2a6e6":"data = resp.json()\ndata[0]['user']","f61ada74":"titanic_train = pd.read_csv(\"https:\/\/gist.githubusercontent.com\/michhar\/2dfd2de0d4f8727f873422c5d959fff5\/raw\/ff414a1bcfcba32481e4d4e8db578e55872a2ca1\/titanic.csv\",\n                           sep='\\t')   \ntitanic_train","5e4d4c85":"titanic_train.describe() #Only describes Numeric values","d894a458":"titanic_train.isnull().sum()","fdda8de0":"np.where(titanic_train['Age'].isnull())","b1e082e8":"a = titanic_train.dtypes[titanic_train.dtypes == 'object'].index\na","0f0ace0a":"titanic_train[a].describe() #Described the object values","eb9c91fe":"titanic_train['Name'][:20] #First 20 names","b1f7f71b":"sorted(titanic_train['Name'][0:20]) #First 20 names in sorted order","0ef4e73d":"titanic_train['Name'].describe() #Describe only 1 column","3a7ac610":"#Convert Numeric to catagorical\np_class_new = pd.Categorical(titanic_train['Pclass'])\np_class_new","c818b425":"p_class_new.dtype","56b139c4":"np.where(titanic_train[\"Fare\"]==max(titanic_train[\"Fare\"]))","26eb2ac3":"#Using iloc to retrieve the rows of the given condition\ntitanic_train.iloc[np.where(titanic_train[\"Fare\"]==max(titanic_train[\"Fare\"]))]","96855beb":"from numpy.random import randn as rn","3470e9b1":"#Random seed helps to give same random numbers every time\nnp.random.seed(101)\nmatrix_data = rn(5,4)\nmatrix_data","861cef8d":"#to convert data into dataframes\nmatrix_data = rn(5,4)\nrow_labels = ['A','B','C','D','E']\ncolumn_headings = ['W','X','Y','Z']\n\ndf = pd.DataFrame(matrix_data,row_labels,column_headings)\ndf","95954164":"#iloc (ilocation) is used to retrieve rows using the index number\n#loc is used to retrieve rows using row labels\nprint(df.iloc[3],'\\n')\nprint(df.loc['D'])","206f588b":"#Rows and column extraction together\n#1st and second rows with 2nd column\ndf.iloc[[0,1],[1]]","6cdd0535":"#Above data in loc\ndf.loc[['A','B'],['X']]","83836bfb":"#axis = 0 means rows and axis = 1 means columns\ndf.drop('X',axis = 1)","5abd8cca":"df #if you do not write inplace = True, the drop is not permanent","6a0ad174":"df.drop('X',axis = 1, inplace = True)","3c04a14e":"df","c6fd6782":"#Alternative of inplace = True is to resign the complete database to another variable\nvariable = df.drop('W',axis = 1)","83ab3497":"print(variable,'\\n')\nprint(df)","ecc46ffa":"matrix_data = np.matrix('22,66,140;42,70,148;30,62,125;35,68,160;25,62,152')\nrow_labels = ['A','B','C','D','E']\ncolumn_headings = ['Age', 'Height', 'Weight']","3c61c858":"df = pd.DataFrame(data=matrix_data, index=row_labels, columns=column_headings)\ndf","de946253":"df['Height']<65","f6a910d4":"df[df['Height']<65]","90675815":"df","3d4e2473":"#Remove indexes\ndf.reset_index(drop = True)","2c33ef36":"df['xyz'] = 'hello world My nameis Utsav'.split()","50671cc4":"df","7438a433":"df.set_index('xyz')","8381cb2d":"#Note : zip operation creates list of the tuples","fc3d7a2c":"#multi-indexing\n# Index Levels\noutside = ['G1','G1','G1','G2','G2','G2']\ninside = [1,2,3,1,2,3]\nhier_index = list(zip(outside,inside))","ee3108aa":"print(hier_index)","4cd0d747":"hier_index = pd.MultiIndex.from_tuples(hier_index)\nprint(hier_index)\nprint(type(hier_index))","79dce5b5":"df1 = pd.DataFrame(data=np.round(rn(6,3)), index= hier_index, columns= ['A','B','C'])\ndf1","0e3fcf37":"#Retrive data from multi-indexing\ndf1.loc['G1'].iloc[[0,1],1]","ca3e87c7":"df = pd.DataFrame({'A':[1,2,np.nan],'B':[5,np.nan,np.nan],'C':[1,2,3]})\ndf['States']=\"CA NV AZ\".split()\ndf.set_index('States',inplace=True)\ndf","2312143e":"#Require that many non-NA values.\n#dropna removes null values\ndf.dropna(thresh = 2)","adcee49d":"df","bd9f8d34":"df.fillna('NA Filled')","1dd4ec61":"df.fillna(value = df['A'].mean())","3660efa6":"data = {'Company':['GOOG','GOOG','MSFT','MSFT','FB','FB'],\n       'Person':['Sam','Charlie','Amy','Vanessa','Carl','Sarah'],\n       'Sales':[200,120,340,124,243,350]}\ndf = pd.DataFrame(data)\ndf","b021e598":"group_operation = df.groupby('Company')\ngroup_operation.mean()","15d285ac":"df1=group_operation.describe()","8fdda389":"group_operation.describe().iloc[[0,1],[1,2]] #extract only 1st 2 rows mean and std","f0b08d71":"df1.transpose()","77247e65":"df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n                        'B': ['B0', 'B1', 'B2', 'B3'],\n                        'C': ['C0', 'C1', 'C2', 'C3'],\n                        'D': ['D0', 'D1', 'D2', 'D3']},\n                        index=[0, 1, 2, 3])","dc0a6885":"df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n                        'B': ['B4', 'B5', 'B6', 'B7'],\n                        'C': ['C4', 'C5', 'C6', 'C7'],\n                        'D': ['D4', 'D5', 'D6', 'D7']},\n                         index=[0, 1, 2, 3])\n","53a7324b":"df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n                        'B': ['B8', 'B9', 'B10', 'B11'],\n                        'C': ['C8', 'C9', 'C10', 'C11'],\n                        'D': ['D8', 'D9', 'D10', 'D11']},\n                        index=[8,9,10,11])","1d8431f5":"#concatenation\n#Note : Rows names or column names (depending on the axis selected) must be same. Else it will add NaN values\ndf_cat1 = pd.concat([df1,df2,df3], axis=0)\nprint(df_cat1)","c3207790":"left = pd.DataFrame({'key': ['K0', 'K8', 'K2', 'K3'],\n                     'A': ['A0', 'A1', 'A2', 'A3'],\n                     'B': ['B0', 'B1', 'B2', 'B3']})\n   \nright = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n                          'C': ['C0', 'C1', 'C2', 'C3'],\n                          'D': ['D0', 'D1', 'D2', 'D3']})\nprint(left,'\\n',right)","79ccb6b6":"#Merge operation\nmerge = pd.merge(left,right,how = 'inner',on = 'key')\nmerge","ac63e0f5":"merge = pd.merge(left,right,how = 'outer',on = 'key')\nmerge","b3a22457":"#All left and only right merged\nmerge = pd.merge(left,right,how = 'left',on = 'key')\nmerge","4d3d8b3c":"left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n                     'B': ['B0', 'B1', 'B2']},\n                      index=['K0', 'K1', 'K2']) \n\nright = pd.DataFrame({'C': ['C0', 'C2', 'C3'],\n                    'D': ['D0', 'D2', 'D3']},\n                      index=['K0', 'K2', 'K3'])","78e2531c":"print(left,'\\n\\n',right)","81f2f615":"left.join(right)","1a394440":"# use of apply functions. It helps to call a external function or lambda function","adaa29c0":"# Define a function\ndef testfunc(x):\n    if (x> 500):\n        return (10*np.log10(x))\n    else:\n        return (x\/10)","19b8cd2b":"df = pd.DataFrame({'col1':[1,2,3,4,5,6,7,8,9,10],\n                   'col2':[444,555,666,444,333,222,666,777,666,555],\n                   'col3':'aaa bb c dd eeee fff gg h iii j'.split()})\ndf","57429947":"df['col10'] = df['col2'].apply(testfunc)\ndf","b00e2b0b":"df['FuncApplied'] = df['col2'].apply(lambda x : np.log(x))\nprint(df)","f38d6f36":"#Sorting\ndf.sort_values('col2')","178ec733":"## Json Data","0af97833":"# Pandas Data Manipulation","753fe3d3":"### Merge operation merges the column keys while the Join operation joins using the indexed"}}