{"cell_type":{"e72a8f3e":"code","0e453265":"code","4d14b575":"code","35733c7f":"code","02335621":"code","570e575e":"code","d86ff00a":"code","8e29b903":"code","f578ae4b":"code","a738bced":"code","27d568bd":"code","5d6fb98f":"code","17e4b49e":"code","9ee717c8":"code","722459dc":"code","b948cbd6":"code","a508a719":"code","45a52e43":"markdown","0f162d91":"markdown","c1b295a9":"markdown","ad1f7f26":"markdown","fb703197":"markdown","2a31203b":"markdown","853e09f7":"markdown","a821a475":"markdown","3929c2eb":"markdown","3b19d405":"markdown","80852600":"markdown"},"source":{"e72a8f3e":"import tarfile\ntar = tarfile.open(\"..\/input\/train-seq\/train_seq.tgz\", \"r:gz\")\ntar.extractall()\ntar.close()\n\nfrom shutil import copyfile\ncopyfile(src = \"..\/input\/dataloader-seq\/dataset_seq.py\", dst = \"..\/working\/dataset_seq.py\")","0e453265":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport copy\n\nimport dataset_seq as d_loader\nimport torch.utils.data as torch_d\n\n#!pip install torchsummary\n#from torchsummary import summary","4d14b575":"BATCHSIZE=50\n\ndataset = d_loader.Balls_CF_Seq (\"mini_balls_seq\", 7000)\ntrain_dataset, test_dataset = torch_d.random_split(dataset, [int(7000*0.9), int(7000*0.1)])\n\ndataloaders = {}\ndataloaders['train'] = torch.utils.data.DataLoader(train_dataset,batch_size=BATCHSIZE, shuffle=True)\ndataloaders['val'] = torch.utils.data.DataLoader(test_dataset,batch_size=BATCHSIZE, shuffle=True)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","35733c7f":"COLORS = ['red', 'green', 'blue', 'yellow', 'lime', 'purple', 'orange', 'cyan', 'magenta']\nfirst_batch = next(iter(dataloaders[\"train\"]))\n_, bb = first_batch\nbb = bb.to(device)\nbb_0 = bb[0]\nfor i in range(bb.size(1)):\n    plt.xlim(0, 100)\n    plt.ylim(100, 0)\n    plt.axes()\n    for j in range(bb.size(2)):\n        rectangle = plt.Rectangle((bb_0[i][j][0].item(),bb_0[i][j][1].item()), \n                                  bb_0[i][j][2].item()-bb_0[i][j][0].item(), \n                                  bb_0[i][j][3].item()-bb_0[i][j][1].item(),\n                                  fc=COLORS[j],ec=\"black\")\n        plt.gca().add_patch(rectangle)\n    plt.gca().set_aspect('equal')\n    print(\"TIME = \", i+1)\n    plt.show()","02335621":"class myLSTM(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, lstm_layers, batch_first, output_size):\n        super(myLSTM, self).__init__()\n        self.output_size = output_size\n        self.lstm_layers = lstm_layers\n        self.hidden_dim = hidden_dim\n        self.lstm = nn.LSTM(input_dim, hidden_dim, lstm_layers, batch_first = batch_first)\n        #self.fc = nn.Linear(hidden_dim, output_size)\n        self.fc = nn.Sequential(\n          nn.Linear(hidden_dim, 500),\n          nn.ReLU(),\n          nn.Linear(500, output_size),\n        )\n\n    def forward(self, x, hidden):\n        out, hidden = self.lstm(x, hidden)\n        fc_input = out[-1]\n        output = self.fc(fc_input)\n        return output\n    \n    def init_hidden(self, batch_size):\n        hidden = torch.zeros(self.lstm_layers, batch_size, self.hidden_dim).to(device)\n        cell = torch.zeros(self.lstm_layers, batch_size, self.hidden_dim).to(device)\n        return (hidden, cell)","570e575e":"def intersect(box_a, box_b):\n    \"\"\" We resize both tensors to [A,B,2] without new malloc:\n    [A,2] -> [A,1,2] -> [A,B,2]\n    [B,2] -> [1,B,2] -> [A,B,2]\n    Then we compute the area of intersect between box_a and box_b.\n    Args:\n      box_a: (tensor) bounding boxes, Shape: [A,4].\n      box_b: (tensor) bounding boxes, Shape: [B,4].\n    Return:\n      (tensor) intersection area, Shape: [A,B].\n    \"\"\"\n    A = box_a.size(0)\n    B = box_b.size(0)\n    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),\n                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))\n    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),\n                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))\n    inter = torch.clamp((max_xy - min_xy), min=0)\n    return inter[:, :, 0] * inter[:, :, 1]","d86ff00a":"def IOU(box_a, box_b):\n    \"\"\"Compute the jaccard overlap of two sets of boxes.  The jaccard overlap\n    is simply the intersection over union of two boxes.  Here we operate on\n    ground truth boxes and default boxes.\n    E.g.:\n        A \u2229 B \/ A \u222a B = A \u2229 B \/ (area(A) + area(B) - A \u2229 B)\n    Args:\n        box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]\n        box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]\n    Return:\n        jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]\n    \"\"\"\n    inter = intersect(box_a, box_b)\n    area_a = ((box_a[:, 2]-box_a[:, 0]) *\n              (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n    area_b = ((box_b[:, 2]-box_b[:, 0]) *\n              (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]\n    union = area_a + area_b - inter\n    return inter \/ union  # [A,B]","8e29b903":"def customLoss(outputs, groundtruth_bb):\n    bb = groundtruth_bb.view(-1, 9*4)\n    iou = 0\n    bb = bb.view(-1, 9, 4)\n    outputs = outputs.view(-1, 9, 4)\n    for i in range(outputs.size(0)):\n        iou += IOU(outputs[i], bb[i])\n    iou = iou \/ outputs.size(0)\n    return (1 - iou.mean())","f578ae4b":"def calcLoss (net, dataloader, customLoss, mse):\n    correct = 0\n    iou = 0\n    with torch.no_grad():\n        for data in dataloader:\n            _, bb= data\n            hidden_0 = net.init_hidden(bb.size(0))\n            bb = bb.view(bb.size(0), bb.size(1), 9*4)\n            bb = bb.permute(1, 0, 2)\n            bb_input = bb[:-1]\n            #bb_input = bb_input.permute(1, 0, 2) #if batch_first = true\n            bb_input = bb_input.to(device)\n            bb_output = bb[-1]\n            bb_output = bb_output.to(device)\n            outputs = net(bb_input, hidden_0)\n            correct += (customLoss(outputs, bb_output) + mse(outputs, bb_output)) * outputs.size(0)\n    return (correct \/ len(dataloader.dataset))","a738bced":"def train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=25):\n    train_accuracies = []\n    valid_accuracies = []\n    \n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = calcLoss(model, dataloaders[\"val\"], customLoss, criterion)\n    print('Initial val loss: {:.4f}'.format(best_loss))\n\n    for epoch in range(1, num_epochs+1):\n        print('Epoch {}\/{}'.format(epoch, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for _ , bb in dataloaders[phase]:\n                hidden_0 = model.init_hidden(bb.size(0))\n                bb = bb.view(bb.size(0), bb.size(1), 9*4)\n                bb = bb.permute(1, 0, 2)\n                bb_input = bb[:-1]\n                bb_input = bb_input.to(device)\n                bb_output = bb[-1]\n                bb_output = bb_output.to(device)\n                \n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(bb_input, hidden_0)\n                    loss = customLoss(outputs, bb_output) + criterion(outputs, bb_output)\n                    #loss = criterion(outputs, bb_output)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * bb_output.size(0)\n            if phase == 'train' and scheduler != None:\n                scheduler.step()\n\n            epoch_loss = running_loss \/ (len(dataloaders[phase].dataset))\n            \n            if phase == 'train':\n                train_accuracies.append(epoch_loss)\n            else:\n                valid_accuracies.append(epoch_loss)\n\n            print('{} Loss: {:.4f} '.format(\n                phase, epoch_loss))\n\n            # deep copy the model\n            if phase == 'val' and epoch_loss < best_loss:\n                best_loss = epoch_loss\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val loss: {:4f}'.format(best_loss))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, train_accuracies, valid_accuracies","27d568bd":"input_dim = 9*4\nhidden_dim = 1000\nlstm_layers = 1 \nbatch_first = False\n\nmodel = myLSTM(input_dim, hidden_dim, lstm_layers, batch_first, input_dim).to(device)\n\nprint(model)","5d6fb98f":"criterion = torch.nn.MSELoss()\n\noptimizer = optim.Adam(model.parameters(), 0.0001)","17e4b49e":"EPOCH_NUMBER = 30\n\nmodel, train_accs, val_accs = train_model(dataloaders, model, criterion, optimizer, None,\n                       num_epochs=EPOCH_NUMBER)\n\ntorch.save(model.state_dict(), \".\/model\")","9ee717c8":"f = plt.figure(figsize=(10, 8))\nplt.plot(train_accs, label='training loss')\nplt.plot(val_accs, label='validation loss')\nplt.legend()\nplt.show()","722459dc":"first_batch = next(iter(dataloaders[\"val\"]))\n_, bb = first_batch\nbb = bb.view(bb.size(0), bb.size(1), 9*4)\nbb = bb.permute(1, 0, 2)\nbb_input = bb[:-1]\nbb_input = bb_input.to(device)\n\nbb_pred = model(bb_input, model.init_hidden(bb.size(1)))\nbb_pred = bb_pred.view(-1, 9, 4)\nbb_groundtruth = bb[-1].view(-1, 9, 4)\n\nfor i in range(5):\n    plt.xlim(0, 100)\n    plt.ylim(100, 0)\n    plt.axes()\n    for j in range(bb_groundtruth.size(1)):\n        rectangle_groundtruth = plt.Rectangle((bb_groundtruth[i][j][0].item(),bb_groundtruth[i][j][1].item()), \n                                  bb_groundtruth[i][j][2].item()-bb_groundtruth[i][j][0].item(), \n                                  bb_groundtruth[i][j][3].item()-bb_groundtruth[i][j][1].item(),\n                                  fc=COLORS[j],ec=\"black\")\n        rectangle_pred = plt.Rectangle((bb_pred[i][j][0].item(),bb_pred[i][j][1].item()), \n                                  bb_pred[i][j][2].item()-bb_pred[i][j][0].item(), \n                                  bb_pred[i][j][3].item()-bb_pred[i][j][1].item(),\n                                  fc=COLORS[j],ec=\"red\")\n        \n        plt.gca().add_patch(rectangle_groundtruth)\n        plt.gca().add_patch(rectangle_pred)\n    plt.gca().set_aspect('equal')\n    print(\"TIME = 20\")\n    plt.show()","b948cbd6":"!rm -rf mini_balls_seq","a508a719":"#SOME TESTS\n\"\"\"\ninput_dim = 9*4\nhidden_dim = 10\nlstm_layers = 1 \nbatch_first = False\n\n#lstm_layer = nn.LSTM(input_dim, hidden_dim, lstm_layers)#, batch_first=True)\nlstm_layer = myLSTM(input_dim, hidden_dim, lstm_layers, batch_first, input_dim)\n\nseq_len = 20\n\n_, bb  = next(iter(dataloaders[\"val\"]))\nbb = bb.view(bb.size(0), bb.size(1), 9*4)#bb.view(BATCHSIZE, seq_len, input_dim)\nbb = bb.permute(1, 0, 2)\nbb = bb[:-1]\nprint(bb.shape)\n\nhidden_state_0 = torch.randn(lstm_layers, BATCHSIZE, hidden_dim)\ncell_state_0 = torch.randn(lstm_layers, BATCHSIZE, hidden_dim)\nhidden = (hidden_state_0, cell_state_0)\n\nprint(bb.shape, hidden[0].shape)\n\nout = lstm_layer(bb, hidden)\n#out = out.permute(1,0,2)\n#fc_input = out[-1]\n#print(fc_input.shape)\n\nprint(\"Output shape: \", out.shape)\nprint(\"Output : \", out[:5])\nprint(calcLoss(lstm_layer, dataloaders[\"val\"], customLoss, torch.nn.MSELoss()))\n#print(\"Hidden: \", len(hidden))\n\"\"\"","45a52e43":"## Split the dataset and define the dataloaders","0f162d91":"## Instantiate our model","c1b295a9":"## Define loss and optimizer","ad1f7f26":"## Training schedule definition","fb703197":"## Model definition","2a31203b":"## Train !","853e09f7":"## Training monitoring plots","a821a475":"## Custom accuracy metrics definition","3929c2eb":"## Double check the model performance","3b19d405":"# RNN LSTM on the balls future forecasting problem","80852600":"## Let's have a glance at the data"}}