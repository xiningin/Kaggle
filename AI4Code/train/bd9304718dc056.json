{"cell_type":{"7ade1d66":"code","acd5c6d4":"code","56a9fb54":"code","1536d124":"code","fa548f30":"code","a239281a":"code","a580180f":"code","f18d4246":"code","b48d24f3":"code","f06a6965":"code","bbf9fa09":"code","90625316":"markdown","d051cf0d":"markdown","4fefb097":"markdown","d98656bd":"markdown","f7f92436":"markdown"},"source":{"7ade1d66":"!pip install simpletransformers","acd5c6d4":"import os, re, string\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport sklearn\n\nimport torch\n\nfrom simpletransformers.classification import ClassificationModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold","56a9fb54":"seed = 1337\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","1536d124":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fa548f30":"# Zero pre-processing of training data\n# I have tried doing some preprcessing\/cleaning but the result \n# does not seem significant\ntrain_data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntrain_data = train_data[['text', 'target']]","a239281a":"# Using 'bert-large-uncased' here. For a list of other models, please refer to \n# https:\/\/github.com\/ThilinaRajapakse\/simpletransformers\/#current-pretrained-models \nbert_uncased = ClassificationModel('bert', 'bert-large-uncased') \n\n# Print out all the default arguments for reference\nbert_uncased.args","a580180f":"# This is where we can tweak based on the default arguments above\ncustom_args = {'fp16': False, # not using mixed precision \n               'train_batch_size': 4, # default is 8\n               'gradient_accumulation_steps': 2,\n               'do_lower_case': True,\n               'learning_rate': 1e-05, # using lower learning rate\n               'overwrite_output_dir': True, # important for CV\n               'num_train_epochs': 2} # default is 1","f18d4246":"n=5\nkf = KFold(n_splits=n, random_state=seed, shuffle=True)\nresults = []\n\nfor train_index, val_index in kf.split(train_data):\n    train_df = train_data.iloc[train_index]\n    val_df = train_data.iloc[val_index]\n    \n    model = ClassificationModel('bert', 'bert-base-uncased', args=custom_args) \n    model.train_model(train_df)\n    result, model_outputs, wrong_predictions = model.eval_model(val_df, acc=sklearn.metrics.accuracy_score)\n    print(result['acc'])\n    results.append(result['acc'])","b48d24f3":"for i, result in enumerate(results, 1):\n    print(f\"Fold-{i}: {result}\")\n    \nprint(f\"{n}-fold CV accuracy result: Mean: {np.mean(results)} Standard deviation:{np.std(results)}\")","f06a6965":"model = ClassificationModel('bert', 'bert-base-uncased', args=custom_args) \nmodel.train_model(train_data)","bbf9fa09":"test_data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\npredictions, raw_outputs = model.predict(test_data['text'])\n\nsample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\nsample_submission[\"target\"] = predictions\nsample_submission.to_csv(\"submission.csv\", index=False)","90625316":"# Full Training","d051cf0d":"# 5-Fold CV","4fefb097":"# Check default value of model and tweak","d98656bd":"# Predict","f7f92436":"A minimal approach to use transformers using the simpletransformers  that allows for:\n1. Easy switching between different pre-trained models\n2. Simple hyperparameter tuning\n3. Basic k-fold cross validation\n4. Zero pre-processing of data\n\nHowever, language model fine-tuning is not available with this method.\n\n"}}