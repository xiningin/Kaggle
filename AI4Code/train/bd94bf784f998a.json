{"cell_type":{"a3575443":"code","af5bbe93":"code","05875b67":"code","1e31e5e3":"code","1146cf91":"code","4f7b484e":"code","580eb8f2":"code","6dff9f1d":"code","e489dd28":"code","3372e4eb":"code","ba2d14cd":"code","30221ce3":"code","d7a338bf":"code","0fc01397":"code","7a42c04a":"code","69193144":"code","f89235d8":"code","49467b67":"code","545bcba3":"code","728d51e5":"code","dcc6a7ec":"code","84de51c1":"code","b10a0cf7":"code","ca7b82ec":"code","7e169114":"code","a8135201":"code","dfbb286f":"code","bebd63a3":"code","6b386b6b":"code","b9b0b3ac":"code","12a5c02a":"code","6e92c76b":"code","02e10c13":"code","c122abc1":"code","2344c635":"markdown","d4b83002":"markdown","025f8f42":"markdown","14f5a426":"markdown","7d1e7b48":"markdown"},"source":{"a3575443":"!wget https:\/\/www.dropbox.com\/s\/si11cws2pyho1bp\/archive.zip","af5bbe93":"!unzip -q \"\/content\/archive.zip\"","05875b67":"# Imports required for this project\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\ntf.random.set_seed(4)","1e31e5e3":"# Creating the Pathlib PATH objects\ntrain_path = Path(\"\/content\/train\")\ntest_path = Path(\"\/content\/test\")","1146cf91":"# Getting Image paths \ntrain_image_paths = list(train_path.glob(\"*\/*\"))\ntrain_image_paths = list(map(lambda x : str(x) , train_image_paths))\n\ntrain_image_paths[:10]","4f7b484e":"# Getting their respective labels \n\ndef get_label(image_path):\n    return image_path.split(\"\/\")[-2]\n\ntrain_image_labels = list(map(lambda x : get_label(x) , train_image_paths))\ntrain_image_labels[:10]","580eb8f2":"from sklearn.preprocessing import LabelEncoder \n\nLe = LabelEncoder()\ntrain_image_labels = Le.fit_transform(train_image_labels)\n\ntrain_image_labels[:10]","6dff9f1d":"train_image_labels = tf.keras.utils.to_categorical(train_image_labels)\n\ntrain_image_labels[:10]","e489dd28":"from sklearn.model_selection import train_test_split \n\nX_train , X_val , y_train , y_val = train_test_split(train_image_paths , train_image_labels , test_size = 0.25)","3372e4eb":"# Compute class weights \n\nclassTotals = y_train.sum(axis=0)\nclassWeight = classTotals.max() \/ classTotals\n\nclass_weight = {e : weight for e , weight in enumerate(classWeight)}\nprint(class_weight)","ba2d14cd":"# Function used for Transformation\n\ndef load(image , label):\n    image = tf.io.read_file(image)\n    image = tf.io.decode_jpeg(image , channels = 3)\n    return image , label","30221ce3":"# Define IMAGE SIZE and BATCH SIZE \nIMG_SIZE = 96 \nBATCH_SIZE = 32\n\n# Basic Transformation\nresize = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE)          \n])\n\n# Data Augmentation\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(height_factor = (-0.1, -0.05))\n])","d7a338bf":"# Function used to Create a Tensorflow Data Object\nAUTOTUNE = tf.data.experimental.AUTOTUNE\ndef get_dataset(paths , labels , train = True):\n    # convert paths and labels to tensor\n    image_paths = tf.convert_to_tensor(paths)\n    labels = tf.convert_to_tensor(labels)\n\n    # create dataset objects for images and labels\n    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n\n    # zip them to be able to iterate on both at once\n    dataset = tf.data.Dataset.zip((image_dataset , label_dataset))\n\n    # apply load and resize on dataset\n    dataset = dataset.map(lambda image , label : load(image , label))\n    dataset = dataset.map(lambda image, label: (resize(image), label) , num_parallel_calls=AUTOTUNE)\n\n    # shuffle and batch the dataset\n    dataset = dataset.shuffle(1000)\n    dataset = dataset.batch(BATCH_SIZE)\n\n    # if train = True apply data augmentation\n    if train:\n        dataset = dataset.map(lambda image, label: (data_augmentation(image), label) , num_parallel_calls=AUTOTUNE)\n    \n    # if not training repeat over the dataset and return\n    dataset = dataset.repeat()\n    return dataset","0fc01397":"# Creating Train Dataset object and Verifying it\n%time train_dataset = get_dataset(X_train , y_train)\n\nimage , label = next(iter(train_dataset))\nprint(image.shape)\nprint(label.shape)","7a42c04a":"# View a sample Training Image\nprint(Le.inverse_transform(np.argmax(label , axis = 1))[0])\nplt.imshow((image[0].numpy()\/255).reshape(96 , 96 , 3))","69193144":"%time val_dataset = get_dataset(X_val , y_val , train=False)\n\nimage , label = next(iter(val_dataset))\nprint(image.shape)\nprint(label.shape)","f89235d8":"# View a sample Validation Image\nprint(Le.inverse_transform(np.argmax(label , axis = 1))[0])\nplt.imshow((image[0].numpy()\/255).reshape(96 , 96 , 3))","49467b67":"# Building EfficientNet model\nfrom tensorflow.keras.applications import EfficientNetB2\n\nbackbone = EfficientNetB2(\n    input_shape=(96, 96, 3),\n    include_top=False  # not including a final layers of EfficientNetB2\n)\n\nmodel = tf.keras.Sequential([\n    backbone,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(7, activation='softmax')\n])\n\nmodel.summary()","545bcba3":"# Compiling your model by providing the Optimizer , Loss and Metrics\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    loss = 'categorical_crossentropy',\n    metrics=['accuracy' , tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall')]\n)","728d51e5":"# Train the model\nhistory = model.fit(\n    train_dataset,\n    steps_per_epoch=len(X_train)\/\/BATCH_SIZE,\n    epochs=12,\n    validation_data=val_dataset,\n    validation_steps = len(X_val)\/\/BATCH_SIZE,\n    class_weight=class_weight\n)","dcc6a7ec":"# we expect our model to just learn patterns in current data.\n# then we freeze all the layers and train only on last layer where we do classification, \n# this gives more importance to the classification layer, thus making it more accurate","84de51c1":"# turnoff the backbone after tuning weights - to ensure the lesser chance of overfitting\nmodel.layers[0].trainable = False","b10a0cf7":"# Defining our callbacks \ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"best_weights.h5\",\n                                                verbose=1,\n                                                save_best_only=True,\n                                                save_weights_only = True)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=4)","ca7b82ec":"model.summary()","7e169114":"# Train the model\nhistory = model.fit(\n    train_dataset,\n    steps_per_epoch=len(X_train)\/\/BATCH_SIZE,\n    epochs=8,\n    callbacks=[checkpoint , early_stop],\n    validation_data=val_dataset,\n    validation_steps = len(X_val)\/\/BATCH_SIZE,\n    class_weight=class_weight\n)","a8135201":"from tensorflow.keras.applications import EfficientNetB2\n\nbackbone = EfficientNetB2(\n    input_shape=(96, 96, 3),\n    include_top=False\n)\n\nmodel = tf.keras.Sequential([\n    backbone,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(7, activation='softmax')\n])\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n    loss = 'categorical_crossentropy',\n    metrics=['accuracy' , tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall')]\n)","dfbb286f":"model.load_weights(\"best_weights.h5\")","bebd63a3":"# Create a Dataset Object for 'Testing' Set just the way we did for Training and Validation\ntest_image_paths = list(test_path.glob(\"*\/*\"))\ntest_image_paths = list(map(lambda x : str(x) , test_image_paths))\ntest_labels = list(map(lambda x : get_label(x) , test_image_paths))\n\ntest_labels = Le.transform(test_labels)\ntest_labels = tf.keras.utils.to_categorical(test_labels)\n\ntest_image_paths = tf.convert_to_tensor(test_image_paths)\ntest_labels = tf.convert_to_tensor(test_labels)\n\ndef decode_image(image , label):\n    image = tf.io.read_file(image)\n    image = tf.io.decode_jpeg(image , channels = 3)\n    image = tf.image.resize(image , [96 , 96] , method=\"bilinear\")\n    return image , label\n\ntest_dataset = (\n     tf.data.Dataset\n    .from_tensor_slices((test_image_paths, test_labels))\n    .map(decode_image)\n    .batch(BATCH_SIZE)\n)","6b386b6b":"# Verify Test Dataset Object\nimage , label = next(iter(test_dataset))\nprint(image.shape)\nprint(label.shape)","b9b0b3ac":"# View a sample Validation Image\nprint(Le.inverse_transform(np.argmax(label , axis = 1))[0])\nplt.imshow((image[0].numpy()\/255).reshape(96 , 96 , 3))","12a5c02a":"# Evaluating the loaded model\nloss, acc, prec, rec = model.evaluate(test_dataset)\n\nprint(\" Testing Acc : \" , acc)\nprint(\" Testing Precision \" , prec)\nprint(\" Testing Recall \" , rec)","6e92c76b":"# Save Model\nmodel.save(\"FacialExpressionModel.h5\")","02e10c13":"# Save Label Encoder \nimport pickle\n\ndef save_object(obj , name):\n    pickle_obj = open(f\"{name}.pck\",\"wb\")\n    pickle.dump(obj, pickle_obj)\n    pickle_obj.close()","c122abc1":"save_object(Le, \"LabelEncoder\")","2344c635":"## Data Loading and Augmentation","d4b83002":"## Evaluating the model","025f8f42":"Face Expression Recognizer: Use Cases- Market Research, Gaming Industry, Behaviour Testing  \nEmotions: seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)  \n","14f5a426":"## Import Data and Dependencies","7d1e7b48":"## Model Training"}}