{"cell_type":{"8a13d301":"code","dc9b41e4":"code","18ce9197":"code","e2429feb":"code","7dce65cc":"code","f053b721":"code","a4697d82":"code","b230b586":"code","0c2eb9e9":"code","babaa334":"code","e7f0fa9b":"code","68c6adfe":"code","9e5c6b46":"markdown","924acad9":"markdown","531daf8f":"markdown","058323b0":"markdown","af91d062":"markdown","0c2bf5fc":"markdown","10096694":"markdown","49a40223":"markdown","e235cd13":"markdown","756cf23e":"markdown"},"source":{"8a13d301":"import pandas as pd\nimport tqdm\nimport math\nimport torch\nimport glob\nfrom collections import defaultdict","dc9b41e4":"YOLO_CONFIDENCE = 0.5","18ce9197":"df_train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ndf_train","e2429feb":"yolov5 = torch.hub.load('..\/input\/yolov5-git\/yolov5-master\/yolov5-master', 'yolov5m', source='local')\nyolov5.conf = YOLO_CONFIDENCE  # confidence threshold","7dce65cc":"photos = glob.glob('..\/input\/shopee-product-matching\/train_images\/*.jpg')","f053b721":"def get_area(x1, x2, y1, y2):\n    return round(abs(x1-x2) * abs(y1-y2), 2)\n\ndef get_distance_to_center(x1, x2, y1, y2):\n    # Distance of normalized coordinates to image center (0.5, 0.5)\n    return round(((x1+x2)\/2 - 0.5)**2 + ((y1+y2)\/2 - 0.5)**2, 4)","a4697d82":"elements_per_batch = 70\nn_batches = math.ceil(len(photos)\/elements_per_batch)\nlast_index = 0\nlast_slash = photos[0].rfind('\/')  # Index for last slash is always the same\n\npredictions_dict = {}\n\nfor _ in tqdm.tqdm(range(n_batches)):\n    if last_index + elements_per_batch > len(photos):\n        current_photos = photos[last_index:]\n    else:\n        current_photos = photos[last_index:last_index+elements_per_batch]\n    current_photos_names = list(current_photos)  # the model modifies this list, so we keep a copy\n    \n    results = yolov5(current_photos)\n    \n    for photo_index, (photo_name, predictions) in enumerate(zip(current_photos_names, results.pred)):\n        photo_name = photo_name[last_slash+1:]\n        predictions_by_photo = defaultdict(list)\n        for prediction_index, p in enumerate(predictions):\n            x1, y1, x2, y2, confidence, class_index = [round(element, 2) for element in p.tolist()]\n            class_index = int(class_index)\n            predictions_by_photo['class_index'].append(class_index)\n            predictions_by_photo['coordinates'].append([x1, y1, x2, y2])\n            predictions_by_photo['confidence'].append(confidence)\n            # Get normalized coordinates to compute distance to center and area\n            x1_n, y1_n, x2_n, y2_n = results.xyxyn[photo_index][prediction_index].tolist()[:4]\n            predictions_by_photo['norm_area'].append(get_area(x1_n, x2_n, y1_n, y2_n))\n            predictions_by_photo['norm_dis_to_org'].append(get_distance_to_center(x1_n, x2_n, y1_n, y2_n))\n            \n        predictions_dict[photo_name] = predictions_by_photo\n                \n    last_index += elements_per_batch\n    ","b230b586":"features = ['class_index', 'confidence', 'norm_area', 'coordinates', 'norm_dis_to_org']\nnew_cols = [f'objects_{feature}' for feature in features]\n\ndf_train = df_train.reindex(columns=df_train.columns.tolist() + new_cols, fill_value=[])","0c2eb9e9":"def get_values_for_row(row):\n    predictions = predictions_dict[row['image']]\n    return pd.Series([predictions[feature] for feature in features])","babaa334":"df_train[new_cols] = df_train.apply(get_values_for_row, axis=1)","e7f0fa9b":"df_train","68c6adfe":"df_train.to_csv(f'train_obj_0{int(YOLO_CONFIDENCE*10)}.csv')","9e5c6b46":"Auxiliary functions","924acad9":"Create empty columns for all objects to then get values with .apply per row","531daf8f":"Predict objects. For each element, the following is obtained:\n* class_index: list of objects detected. Each object is identified by an index. To access the name of the object, do yolov5.names[index]\n* coordinates: coordinates of the bounding box in [x1, y1, x2, y2] format (not normalized)\n* confidence: confidence of prediction\n* norm_area: normalized area (computed with normalized coordinates, which go from 0 to 1)\n* norm_dis_to_org: normalized distance to the origin of the image from the center of the object (computed with normalized coordinates, which go from 0 to 1)","058323b0":"Auxiliary function to transfer data to DataFrame","af91d062":"# Predict objects","0c2bf5fc":"Notebook that detects objects in Shopee train set and outputs information in lists. Note that when reading the csv you will need to convert these lists back to a Python list using the *eval* function","10096694":"# Load Object Detector","49a40223":"# Objects to DataFrame","e235cd13":"Get names of photos","756cf23e":"# Load data"}}