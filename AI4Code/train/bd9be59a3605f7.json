{"cell_type":{"a219f761":"code","136dfe2d":"code","a3c7f223":"code","3c583349":"code","1c3efb4e":"code","9cbb4212":"code","df59887b":"code","64eed327":"code","a4a35951":"code","755eeffe":"code","74d48a02":"code","3adf7cd4":"code","8f08f68c":"code","87423988":"code","e7b0de2d":"code","bf6ea6ca":"code","a35d4693":"markdown","cc7415b2":"markdown","fdbdc909":"markdown","1dce8af8":"markdown","3239b1a4":"markdown","8aac07bf":"markdown","34ec7d03":"markdown","f2e14d49":"markdown","74e03df3":"markdown"},"source":{"a219f761":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n%matplotlib inline\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","136dfe2d":"iris=pd.read_csv('..\/input\/iris\/Iris.csv')","a3c7f223":"iris.head()","3c583349":"sns.pairplot(data=iris.drop('Id',axis=1),hue='Species',kind='reg')","1c3efb4e":"corre=iris.drop('Id',axis=1).corr()","9cbb4212":"sns.heatmap(data=corre)","df59887b":"sns.scatterplot(x=\"PetalLengthCm\",y=\"SepalLengthCm\",data=iris,hue=\"Species\")","64eed327":"sns.jointplot(x=\"PetalLengthCm\",y=\"SepalLengthCm\",data=iris)","a4a35951":"from sklearn.model_selection import train_test_split","755eeffe":"dat=iris.drop('Id',axis=1)\nfea=dat.drop('Species',axis=1)\ntar=iris['Species']\n","74d48a02":"x_train,x_test,y_train,y_test=train_test_split(fea,tar,test_size=0.3)","3adf7cd4":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","8f08f68c":"rfc=RandomForestClassifier()","87423988":"rfc.fit(fea,tar)\nres=rfc.predict(x_test)","e7b0de2d":"res1=accuracy_score(y_test,res)\nprint(\"Random Forest Classifier Success Rate :\", \"{:.2f}%\".format(100*res1))","bf6ea6ca":"from sklearn.neighbors import KNeighborsClassifier\nscorelist=[]\nfor i in range(1,100):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(x_train,y_train)\n    p5=knn.predict(x_test)\n    s5=accuracy_score(y_test,p5)\n    scorelist.append(round(100*s5, 2))\nprint(\"K Nearest Neighbors Top 5 Success Rates:\")\nprint(sorted(scorelist,reverse=True)[:30])","a35d4693":"testing my accuracy score","cc7415b2":"Getting an overview of the data","fdbdc909":"Corelations might give an insight on how the data is conneced","1dce8af8":"Trying Random forest classifier","3239b1a4":"tearing down the data into features and target columns","8aac07bf":"# **Getting the max accuracy of 100%**","34ec7d03":"Creating split in the data","f2e14d49":"Trying KneighbourClassifier","74e03df3":"Fitting the data and predicting the outcome"}}