{"cell_type":{"2a46fe4c":"code","6c33290b":"code","5452971c":"code","21d47607":"code","730d0378":"code","21b4450a":"code","d6b42261":"code","241890ac":"code","fa5d3bc6":"code","988835de":"code","eb8a8087":"code","0ef3b76e":"code","b6ccde49":"code","0783cae7":"markdown","7421955d":"markdown","d9638fc4":"markdown","2dfe586b":"markdown","29b8fb57":"markdown"},"source":{"2a46fe4c":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nprint(tf.__version__)","6c33290b":"sentences = {\n    'I love my dog',\n    'I love my car',\n    'You love my dog',\n    'You love my cat'\n}","5452971c":"tokenizer = Tokenizer(num_words = 100, oov_token='<OOV>')\ntokenizer.fit_on_texts(sentences)\nword_index = tokenizer.word_index\nsequences = tokenizer.texts_to_sequences(sentences)\npadded = pad_sequences(sequences, padding='post', truncating='post', maxlen=5)\n\nprint(word_index)\nprint(sequences)\nprint(padded)","21d47607":"test_data = [\n    'i really love my dog',\n    'my dog loves my manatee'\n]\n\ntest_seq = tokenizer.texts_to_sequences(test_data)\nprint(test_seq)","730d0378":"import pandas as pd\n\ndatastore = pd.read_json('..\/input\/news-headlines-dataset-for-sarcasm-detection\/Sarcasm_Headlines_Dataset.json', lines = True)\n\nsentences = datastore['headline'].tolist()\nlabels = datastore['is_sarcastic'].tolist()\nurls = datastore['article_link'].tolist()\n\nvocab_size = 10000\nembedding_dim = 16\nmax_length = 100\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"\ntraining_size = 20000","21b4450a":"training_sentences = sentences[0:training_size]\ntesting_sentences = sentences[training_size:]\ntraining_labels = labels[0:training_size]\ntesting_labels = labels[training_size:]","d6b42261":"tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(training_sentences)\nword_index = tokenizer.word_index\n\ntraining_sequences = tokenizer.texts_to_sequences(training_sentences)\ntraining_padded = pad_sequences(training_sequences,maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\ntesting_sequences = tokenizer.texts_to_sequences(testing_sentences)\ntesting_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","241890ac":"# Need this block to get it to work with TensorFlow 2.x\nimport numpy as np\n\ntraining_padded = np.array(training_padded)\ntraining_labels = np.array(training_labels)\ntesting_padded = np.array(testing_padded)\ntesting_labels = np.array(testing_labels)\n","fa5d3bc6":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","988835de":"model.summary()","eb8a8087":"num_epochs = 30\nhistory = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)","0ef3b76e":"import matplotlib.pyplot as plt\n\ndef plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n  \nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")","b6ccde49":"sentence = [\"granny starting to fear spiders in the garden might be real\", \"game of thrones season finale showing this sunday night\"]\nsequences = tokenizer.texts_to_sequences(sentence)\npadded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\nprint(model.predict(padded))","0783cae7":"## Natural Language Processing - Tokenization (NLP Zero to Hero - Part 1 \/ 2)","7421955d":"##### If help you, please upvote! Thak you \ud83d\ude03","d9638fc4":"### Training a model to recognize sentiment in text (NLP Zero to Hero - Part 3)","2dfe586b":"## This code is from NLP Zero to Hero from tensorflow with some modifications\nCode explanation in this videos:\n<a href=\"https:\/\/www.youtube.com\/playlist?list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S\n\" target=\"_blank\"><img src=\"https:\/\/i.ytimg.com\/vi\/fNxaJsNG3-s\/hqdefault.jpg?sqp=-oaymwEXCNACELwBSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLCCPWFf5dlgclLSASw0WCvwTHeQaQ\" \nalt=\"IMAGE ALT TEXT HERE\" width=\"240\" height=\"180\" border=\"10\" \/><\/a>","29b8fb57":"## Modeling a Sarcasm Prediction"}}