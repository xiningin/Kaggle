{"cell_type":{"aa0cbbd6":"code","bcfadd67":"code","be449e7d":"code","3c960af9":"code","8eb1b7f8":"code","2de91a31":"code","8a209231":"code","27aed2d4":"code","41ef8614":"code","4fe89069":"code","581cb899":"code","079a3862":"code","4dd1bb22":"code","239706bb":"code","92ad8480":"code","c9d075d7":"code","72adbb07":"code","ce8651e7":"code","66da2bea":"code","b600c49f":"code","0c0a60e3":"code","5a78e96c":"markdown","2023fd21":"markdown","f6607c63":"markdown","7b1e1303":"markdown","659d11ee":"markdown","c9640b61":"markdown","3a4994f2":"markdown","25c1d5ff":"markdown","8bafc47f":"markdown"},"source":{"aa0cbbd6":"## plot the image from class C as example to plot the images \n\nfrom matplotlib import pyplot as plt\nimport os\nimport random\n\n\n_, _, sign_images = next(os.walk('..\/input\/handsignimages\/Train\/C\/'))\n\n### prepare a 4x4 plot (total of 16 images)\nfig, ax = plt.subplots(3, 2, figsize=(10,10))\n\n### randomly select and plot an image\nfor idx, img in enumerate(random.sample(sign_images, 6)):\n    img_read = plt.imread('..\/input\/handsignimages\/Train\/C\/'+img)\n    ax[int(idx\/2), idx%2].imshow(img_read)\n    ax[int(idx\/2), idx%2].axis('off')\n    ax[int(idx\/2), idx%2].set_title('Train\/C'+img)\nplt.show()","bcfadd67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n #       print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be449e7d":"from keras.preprocessing.image import ImageDataGenerator\n\ntraining_data_generator = ImageDataGenerator(rescale =1\/255, validation_split=0.1)\n\ntraining_set = training_data_generator.flow_from_directory('..\/input\/handsignimages\/Train', target_size =(28, 28), batch_size = 16 , class_mode ='categorical',  subset='training')\n\nvalidation_set = training_data_generator.flow_from_directory('..\/input\/handsignimages\/Train', target_size =(28, 28), batch_size = 16 , class_mode ='categorical',  subset='validation')\n\nprint(training_set)\nprint(training_set)\n","3c960af9":"from random import uniform\nfrom keras.layers.normalization import BatchNormalization\n\n\ninput_size = 28\nfilter_size = 3\nnum_filter = 8\nmaxpool_size = 2\nbatch_size = 16\nepochs = 10\nsteps_per_epoch = 24720\/batch_size\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dropout, Flatten, Dense\n\n\nmodel = Sequential()\nmodel.add(Conv2D(16, (filter_size,filter_size), \n                 input_shape= (input_size,input_size,3), \n                 activation ='relu',\n                 padding='same'))\n\nmodel.add(MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=1))\n\n\nmodel.add(Conv2D(32, (filter_size,filter_size), \n                 activation='relu', \n                 padding='valid'))\n\n\nmodel.add(MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(120, activation='relu'))\nmodel.add(Dense(24,activation='softmax'))\n\n \n\n\n","8eb1b7f8":"METRICS = [ 'accuracy']#, 'precision','recall']\n\n\nmodel.compile( optimizer= keras.optimizers.Adam(lr=0.001),loss='categorical_crossentropy',metrics=METRICS)\n\n#\nmodel.summary()","2de91a31":"history = model.fit_generator(\ntraining_set,\nsteps_per_epoch= steps_per_epoch,\nepochs= epochs,\nvalidation_data=validation_set,\nvalidation_steps= 2735  \/\/ batch_size\n\n)\n","8a209231":"testing_data_generator = ImageDataGenerator(rescale =1\/255)\n\ntesting_set = training_data_generator.flow_from_directory('..\/input\/handsignimages\/Test', \n                                                          target_size =(28, 28), \n                                                          batch_size = 16 , \n                                                          class_mode ='categorical')\n\nscore = model.evaluate_generator(testing_set, steps= len(testing_set))\nfor idx, metric in enumerate(model.metrics_names):\n    print(metric, score[idx])","27aed2d4":"from random import uniform\nfrom keras.layers.normalization import BatchNormalization\n\n\ninput_size = 28\nfilter_size = 3\nnum_filter = 8\nmaxpool_size = 2\nbatch_size = 16\nepochs = 10\nsteps_per_epoch = 24720\/batch_size\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dropout, Flatten, Dense\n\n\nmodel = Sequential()\nmodel.add(Conv2D(16, (filter_size,filter_size), \n                 input_shape= (input_size,input_size,3), \n                 activation ='relu',\n                 padding='same'))\nmodel.add(Conv2D(16, (filter_size,filter_size), \n                 input_shape= (input_size,input_size,3), \n                 activation ='relu',\n                 padding='same'))\nmodel.add(MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=1))\nmodel.add(Dropout(uniform(0, 1)))\n\nmodel.add(Conv2D(32, (filter_size,filter_size), \n                 activation='relu', \n                 padding='valid'))\nmodel.add(Conv2D(32, (filter_size,filter_size), \n                 activation='relu', \n                 padding='valid'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\nmodel.add(Dropout(uniform(0, 1)))  \n\nmodel.add(Flatten())\nmodel.add(Dense(120, activation='relu'))\nmodel.add(Dense(24,activation='softmax'))\n\n \n\n\n","41ef8614":"METRICS = [ 'accuracy']#, 'precision','recall']\n\n\nmodel.compile( optimizer= keras.optimizers.Adam(lr=0.001),loss='categorical_crossentropy',metrics=METRICS)\n\n#\nmodel.summary()","4fe89069":"\nhistory = model.fit_generator(\ntraining_set,\nsteps_per_epoch= steps_per_epoch,\nepochs= epochs,\nvalidation_data=validation_set,\nvalidation_steps= 2735  \/\/ batch_size\n\n)\n","581cb899":"testing_data_generator = ImageDataGenerator(rescale =1\/255)\n\ntesting_set = training_data_generator.flow_from_directory('..\/input\/handsignimages\/Test', \n                                                          target_size =(28, 28), \n                                                          batch_size = 16 , \n                                                          class_mode ='categorical')\n\nscore = model.evaluate_generator(testing_set, steps= len(testing_set))\nfor idx, metric in enumerate(model.metrics_names):\n    print(metric, score[idx])","079a3862":"from random import uniform\nfrom keras.layers.normalization import BatchNormalization\n\n\ninput_size = 28\nfilter_size = 3\nnum_filter = 8\nmaxpool_size = 2\nbatch_size = 16\nepochs = 10\nsteps_per_epoch = 24720\/batch_size\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dropout, Flatten, Dense\n\n\nmodel = Sequential()\nmodel.add(Conv2D(16, (filter_size,filter_size), \n                 input_shape= (input_size,input_size,3), \n                 activation ='relu',\n                 padding='same'))\nmodel.add(Conv2D(16, (filter_size,filter_size), \n                 input_shape= (input_size,input_size,3), \n                 activation ='relu',\n                 padding='same'))\nmodel.add(MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=1))\nmodel.add(Dropout(uniform(0, 1)))\n\nmodel.add(Conv2D(32, (filter_size,filter_size), \n                 activation='relu', \n                 padding='valid'))\nmodel.add(Conv2D(32, (filter_size,filter_size), \n                 activation='relu', \n                 padding='valid'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\nmodel.add(Dropout(uniform(0, 1)))  \n\nmodel.add(Flatten())\nmodel.add(Dense(120, activation='relu'))\nmodel.add(Dense(24,activation='softmax'))\n\n \n","4dd1bb22":"METRICS = [ 'accuracy']#, 'precision','recall']\n\n\nmodel.compile( optimizer= keras.optimizers.Adam(lr=0.001),loss='categorical_crossentropy',metrics=METRICS)\n\n#\nmodel.summary()","239706bb":"from keras.callbacks import EarlyStopping\n\nes = EarlyStopping(monitor='val_loss', mode='max', verbose=1, patience=2)\n\nhistory = model.fit_generator(\ntraining_set,\nsteps_per_epoch= steps_per_epoch,\nepochs= epochs,\nvalidation_data=validation_set,\nvalidation_steps= 2735  \/\/ batch_size,\ncallbacks=[es]\n)\n#callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler]","92ad8480":"testing_data_generator = ImageDataGenerator(rescale =1\/255)\n\ntesting_set = training_data_generator.flow_from_directory('..\/input\/handsignimages\/Test', \n                                                          target_size =(28, 28), \n                                                          batch_size = 16 , \n                                                          class_mode ='categorical')","c9d075d7":"score = model.evaluate_generator(testing_set, steps= len(testing_set))\nfor idx, metric in enumerate(model.metrics_names):\n    print(metric, score[idx])","72adbb07":"input_size = 28\nfilter_size = 3\nnum_filter = 8\nmaxpool_size = 2\nbatch_size = 16\nepochs = 10\nsteps_per_epoch = 24720\/batch_size\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dropout, Flatten, Dense\n\n\nmodel = Sequential()\nmodel.add(Conv2D(16, (filter_size,filter_size), \n                 input_shape= (input_size,input_size,3), \n                 activation ='relu',\n                 padding='same'))\nmodel.add(MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\n\n\nmodel.add(Conv2D(32, (filter_size,filter_size), \n                 input_shape= (input_size,input_size,3), \n                 activation ='relu',\n                 padding='same'))\nmodel.add(MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\nmodel.add(Dropout(uniform(0, 1)))  \n\nmodel.add(Conv2D(64, (filter_size,filter_size), \n                 activation='relu', \n                 padding='valid'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(maxpool_size, maxpool_size),strides=2))\nmodel.add(Dropout(uniform(0, 1)))  \n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(24,activation='softmax'))\n","ce8651e7":"METRICS = [ 'accuracy']#, 'precision','recall']\n\n\nmodel.compile( optimizer= keras.optimizers.Adam(lr=0.001),loss='categorical_crossentropy',metrics=METRICS)\n\n#\nmodel.summary()","66da2bea":"from keras.callbacks import EarlyStopping\n\nes = EarlyStopping(monitor='val_loss', mode='max', verbose=1, patience=2)\n\nhistory = model.fit_generator(\ntraining_set,\nsteps_per_epoch= steps_per_epoch,\nepochs= epochs,\nvalidation_data=validation_set,\nvalidation_steps= 2735  \/\/ batch_size,\ncallbacks=[es]\n)\n","b600c49f":"testing_data_generator = ImageDataGenerator(rescale =1\/255)\n\ntesting_set = training_data_generator.flow_from_directory('..\/input\/handsignimages\/Test', \n                                                          target_size =(28, 28), \n                                                          batch_size = 16 , \n                                                          class_mode ='categorical')","0c0a60e3":"score = model.evaluate_generator(testing_set, steps= len(testing_set))\nfor idx, metric in enumerate(model.metrics_names):\n    print(metric, score[idx])","5a78e96c":"Building a simple CNN model with Conv2D, Maxpool, Conv2D, maxpool trend ","2023fd21":"we will use EarlyStopping ","f6607c63":"we will build a nother model with trend Conv2D, Conv2D, Maxpool, Conv2D, Conv2D, maxpool and using Dropout to reduce overfitting","7b1e1303":"We can notice that the accuracy of this model has improved ","659d11ee":"We can see that there is overfitting for this model as the testing accuracy was 90% ","c9640b61":"# The Task\n\nThe dataset contains 28x28 images of hand sign Contains 24,720 images in training set and 2,735 images in the test set\nOur task is to classify images into 24 different classes.","3a4994f2":"# Pre-Process Data\nwe read the training and validation dataset using ImageDataGenerator \n","25c1d5ff":"# **Explore the data**\nPlot the images to better understand the kind of data we are working with \n","8bafc47f":"Now we try a nother model using Conv2D, pool,Conv2D,pool, Conv2D, pool with dropout and BatchNormalization"}}