{"cell_type":{"e5f2ad80":"code","8fee5d66":"code","9f811b99":"code","ebc92786":"code","c069e8ab":"code","630fa7f8":"code","9b424bf9":"code","01287927":"code","7bbb3c8a":"code","f3849865":"code","48cb61da":"code","e2483755":"code","bc3b1774":"code","28b871bf":"code","af4043db":"code","7dc2886f":"code","59308b59":"code","3b824fa5":"markdown","bd21230f":"markdown","78b765d6":"markdown","e7e7c70b":"markdown","a4338847":"markdown","9851d70e":"markdown"},"source":{"e5f2ad80":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport timm\nimport os\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\n\nfrom sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torch.nn.functional as F\nimport torchvision.models as model\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","8fee5d66":"class CFG:\n    DEVICE= 'cuda' if torch.cuda.is_available() else 'cpu'\n    SEED= 1234\n    PROBLEM= 'regression'\n    MODEL_NAME= 'efficientnet_b3'\n    IMG_SIZE= 512\n    IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n    IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n    N_FOLDS= 5\n    LEARNING_RATE= 1e-3\n    WEIGHT_DECAY= 0\n    T_MAX= 10\n    T_0= 5\n    ETA_MIN= 0\n    SCHEDULER= 'CosineAnnealingLR'\n    BATCH_SIZE= 16\n    BATCH_SIZE_TEST= 4\n    EPOCHS= 5","9f811b99":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic= True\n\n    \nset_seed(CFG.SEED)","ebc92786":"train= pd.read_csv('..\/input\/pawpreds-eda-fe-folds-and-stacking-meta-data\/train_folds.csv')\ntrain_ids= train['Id']\ntrain_targets= train['Pawpularity']\ntest= pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\n\ndef get_test_file_path(image_id):\n    return f'..\/input\/petfinder-pawpularity-score\/test\/{image_id}.jpg'\n\n\ntest['image_path']= test['Id'].apply(get_test_file_path)\ntest_ids= test['Id']","c069e8ab":"def preprocess(df):\n    df['size']= df['image_path'].apply(lambda x: Image.open(x).size)\n    df['width']= df['size'].apply(lambda x: x[0])\n    df['height']= df['size'].apply(lambda x: x[1])\n    df= df.drop('size', axis= 1)\n    return df\n\ntest= preprocess(test)","630fa7f8":"meta_features= ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'width', 'height']","9b424bf9":"class PawDataset:\n    def __init__(self, df, augmentations= None):\n        self.df= df\n        self.image_paths= df['image_path'].values\n        self.targets= df['Pawpularity'].values\n        self.meta_df= df[meta_features].values\n        if (CFG.PROBLEM == 'classification'):\n            self.targets= df['Pawpularity'].values \/ 100\n        self.augmentations= augmentations\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        target= self.targets[idx]\n        meta_data= self.meta_df[idx, :]\n        image= cv2.imread(self.image_paths[idx])  #BGR \n        image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #RGB\n        if self.augmentations:\n            image= self.augmentations(image= image)['image']\n        return image, torch.tensor(meta_data, dtype= torch.float), torch.tensor(target, dtype= torch.float)","01287927":"augmentations= {\n    'train': A.Compose([\n        A.RandomResizedCrop(height= CFG.IMG_SIZE, width= CFG.IMG_SIZE, scale= (0.85, 1.0)),\n        A.Flip(p= 0.7),\n        A.Perspective(p= 0.7),\n        A.Rotate(limit= 40, p= 0.5, border_mode= cv2.BORDER_CONSTANT),\n        A.Normalize(mean= CFG.IMAGENET_MEAN, std= CFG.IMAGENET_STD),\n        ToTensorV2()]),\n    \n    'valid': A.Compose([\n        A.Resize(height= CFG.IMG_SIZE, width= CFG.IMG_SIZE),\n        A.Normalize(mean= CFG.IMAGENET_MEAN, std= CFG.IMAGENET_STD),\n        ToTensorV2()])\n}","7bbb3c8a":"test['Pawpularity']= np.zeros(test.shape[0])","f3849865":"class PawpularityModel(nn.Module):\n    def __init__(self, model_name, pretrained= True):\n        super(PawpularityModel, self).__init__()\n        self.image_model= timm.create_model(model_name, pretrained= pretrained)\n        self.input_dim= self.image_model.classifier.in_features\n        self.image_model.classifier= nn.Identity() \n        \n        self.fc1= nn.Linear(self.input_dim, self.input_dim\/\/2)\n        self.fc2= nn.Linear(self.input_dim\/\/2, 1)\n        \n    def forward(self, image):\n        emb= self.image_model(image)    #[N, 1280]\n        output= F.relu(self.fc1(emb))\n        output= torch.flatten(self.fc2(output))       #[N]\n        return emb, output","48cb61da":"def get_embeddings(dataloader, model):\n    model.eval()\n    embs= np.empty(shape= (0, model.input_dim))\n    \n    with torch.no_grad():\n        for image, meta, target in dataloader:\n            image= image.to(CFG.DEVICE)\n            meta= meta.to(CFG.DEVICE)\n            target= target.to(CFG.DEVICE)\n            \n            emb, _= model(image)\n            emb= emb.cpu().numpy()\n            embs= np.concatenate((embs, emb))\n            \n    return embs","e2483755":"def get_embeddings_df(train, test, fold):\n    embeddings= np.zeros((train.shape[0]))\n    train_dataset= PawDataset(train, augmentations= augmentations['train'])\n    train_loader= data.DataLoader(train_dataset, batch_size= CFG.BATCH_SIZE)\n    model= PawpularityModel(CFG.MODEL_NAME, pretrained= False).to(CFG.DEVICE)\n    model.load_state_dict(torch.load('..\/input\/pawpreds-efficientnetb3-rmse-training\/effnetb3_rmse%d.pth'% fold, map_location= CFG.DEVICE))\n    embeddings= get_embeddings(train_loader, model)\n    train_df= pd.DataFrame(embeddings, columns= [i for i in range(model.input_dim)])\n    \n    embeddings= np.zeros((test.shape[0]))\n    test_dataset= PawDataset(test, augmentations= augmentations['valid'])\n    test_loader= data.DataLoader(test_dataset, batch_size= CFG.BATCH_SIZE_TEST)\n    model= PawpularityModel(CFG.MODEL_NAME, pretrained= False).to(CFG.DEVICE)\n    model.load_state_dict(torch.load('..\/input\/pawpreds-efficientnetb3-rmse-training\/effnetb3_rmse%d.pth'% fold, map_location= CFG.DEVICE))\n    embeddings= get_embeddings(test_loader, model)\n    test_df= pd.DataFrame(embeddings, columns= [i for i in range(model.input_dim)])\n    return train_df, test_df","bc3b1774":"kfold= KFold(n_splits= 10)\ntest_preds= np.zeros(test.shape[0])\nfor fold in range(CFG.N_FOLDS):\n    train_df, test_df= get_embeddings_df(train, test, fold)\n    oof_preds= np.zeros(train_df.shape[0])\n    \n    for train_idx, val_idx in kfold.split(train_df):\n        X_train, X_val= train_df.iloc[train_idx], train_df.iloc[val_idx]\n        y_train, y_val= train_targets.iloc[train_idx], train_targets.iloc[val_idx]\n        \n        lgbr= lgb.LGBMRegressor(objective= 'rmse', n_estimators= 1000)\n        lgbr.fit(X_train, y_train, eval_metric= 'rmse', \n                 eval_set= [(X_val, y_val)], early_stopping_rounds= 100, verbose= 10)\n    \n        test_preds += (lgbr.predict(test_df)\/10)\n        oof_preds[val_idx]= lgbr.predict(X_val)\n\ntest_preds \/= CFG.N_FOLDS","28b871bf":"oof_loss= mean_squared_error(train_targets, oof_preds, squared= False)\noof_loss","af4043db":"test_preds","7dc2886f":"sub= pd.DataFrame({'Id': test_ids, 'Pawpularity': test_preds})","59308b59":"sub.to_csv('submission.csv', index= False)","3b824fa5":"# CONFIG CLASS","bd21230f":"# MODEL","78b765d6":"# GET EMBEDDINGS","e7e7c70b":"[EDA, FE, folds and stacking (meta data)](https:\/\/www.kaggle.com\/sagarikajadon\/pawpreds-eda-fe-folds-and-stacking-meta-data)\n\n[[pawpreds] efficientnetB3(RMSE) training](https:\/\/www.kaggle.com\/sagarikajadon\/pawpreds-efficientnetb3-rmse-training)","a4338847":"# DATASET CLASS","9851d70e":"# READ DATA AND PREPROCESS"}}