{"cell_type":{"0e92f811":"code","18f0c457":"code","9d9caa15":"code","c6a08851":"code","bb237bc5":"code","baa06bf6":"code","80f1a6c2":"code","41ed798c":"code","2eccfe2c":"code","ba18dd64":"code","f4859cde":"code","f4132ec7":"code","0a01f314":"code","40925085":"code","231151ee":"code","1c8dfeab":"code","df908882":"code","19fefcfb":"code","d1f86242":"code","d1bed5d7":"code","775b0a9a":"code","875418c0":"code","4a120ae0":"code","3049745f":"code","c62e6868":"markdown","348bdecf":"markdown","24417101":"markdown","a5642d2e":"markdown","5746b6df":"markdown","706c31ee":"markdown","434dedc7":"markdown","b44bc68e":"markdown"},"source":{"0e92f811":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","18f0c457":"# Load the train data\ntrain = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)\ntrain.head()","9d9caa15":"# Load the test data\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)\ntest.head()","c6a08851":"X_train = (train.iloc[:,1:].values).astype(\"float32\") # all pixel values\ny_train = train.iloc[:,0].values.astype(\"int32\") # only labels i.e targets digits\nX_test = test.values.astype(\"float32\")","bb237bc5":"X_train","baa06bf6":"y_train","80f1a6c2":"# Convert train dataset to (num_images, img_rows, img_cols) format\nX_train = X_train.reshape(X_train.shape[0], 28, 28)\n\nfor i in range(6, 9):\n    plt.subplot(330 + (i+1))\n    plt.imshow(X_train[i], cmap=plt.get_cmap(\"gray\"))\n    plt.title(y_train[i]);","41ed798c":"# Expand 1 more dimension as 1 for color channel gray and check the shape of the data\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_train.shape","2eccfe2c":"# Check the shape of the data\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\nX_test.shape","ba18dd64":"# Standardize the data to centralize the data around zero mean and unit variance\nmean_px = X_train.mean().astype(np.float32)\nstd_px = X_train.std().astype(np.float32)\n\ndef standardize(x):\n    return (x - mean_px) \/ std_px","f4859cde":"# One-hot encoding\nfrom keras.utils.np_utils import to_categorical\n\ny_train = to_categorical(y_train)\nnum_classes = y_train.shape[1]\nnum_classes","f4132ec7":"# Fix random seed for reproducibility\nseed = 43\nnp.random.seed(seed)","0a01f314":"# Define the model function\ndef get_model():\n    \"\"\"\n    The model comprised of three convolution blocks with a max pool layer in each of them.\n    There is fully connected layer with 512 units on top of it that is activated by a relu\n    activation function.\n    \"\"\"\n    model = Sequential([\n        layers.Lambda(standardize, input_shape=(28, 28, 1)),\n        layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.MaxPooling2D(),\n        layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.MaxPooling2D(),\n        layers.Dropout(0.2),\n        layers.Flatten(),\n        layers.Dense(512, activation=\"relu\"),\n        layers.Dense(10, activation=\"softmax\")\n    ])\n    model.compile(\n        optimizer=RMSprop(learning_rate=0.001),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model\n\n\nmodel = get_model()","40925085":"# Check input and output shape\nprint(f\"input shape: {model.input_shape}\")\nprint(f\"output shape: {model.output_shape}\")","231151ee":"# View all the layers of the network using the model's summary method\nmodel.summary()","1c8dfeab":"# Split dataset into train and test\nfrom keras.preprocessing import image\ngen = image.ImageDataGenerator()\n\nX = X_train\ny = y_train\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train,\n    y_train,\n    test_size=0.10,\n    random_state=42\n)\n\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches = gen.flow(X_val, y_val, batch_size=64)","df908882":"# Train the model\nepochs=3\nhistory = model.fit(\n    batches,\n    steps_per_epoch=batches.n,\n    epochs=epochs,\n    validation_data=val_batches,\n    validation_steps=val_batches.n\n)","19fefcfb":"acc = history.history[\"accuracy\"]\nval_acc = history.history[\"val_accuracy\"]\n\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(1, len(loss) + 1)\n\nplt.figure(figsize=(15, 5))\nplt.subplot(1, 2, 1)\nplt.plot(epochs, acc, \"bo\", label=\"Training Accuracy\") # \"bo\" is for \"blue dot\"\nplt.plot(epochs, val_acc, \"b+\", label=\"Validation Accuracy\") # \"b+\" is for \"blue crosses\"\nplt.legend(loc=\"lower right\")\nplt.title(\"Training and Validation Accuracy\")\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs, loss, \"bo\", label='Training Loss') # \"bo\" is for \"blue dot\"\nplt.plot(epochs, val_loss, \"b+\", label='Validation Loss') # \"b+\" is for \"blue crosses\"\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","d1f86242":"# Use of data augmentation to improve the performance and avoid overfitting\ngen = ImageDataGenerator(\n    rotation_range=8,\n    width_shift_range=0.08,\n    shear_range=0.3,\n    height_shift_range=0.08,\n    zoom_range=0.08\n)\n\nbatches = gen.flow(X_train, y_train, batch_size=64)\nval_batches = gen.flow(X_val, y_val, batch_size=64)","d1bed5d7":"# Define the model function\ndef get_bn_model():\n    \"\"\"\n    Add batch normalization to fine tune hyperparameters more better\n    and train deep neural networks\n    \"\"\"\n    model = Sequential([\n        layers.Lambda(standardize, input_shape=(28, 28, 1)),\n        layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(axis=1),\n        layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.MaxPooling2D(),\n        layers.BatchNormalization(axis=1),\n        layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.BatchNormalization(axis=1),\n        layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"),\n        layers.MaxPooling2D(),\n        layers.Dropout(0.2),\n        layers.Flatten(),\n        layers.BatchNormalization(),\n        layers.Dense(512, activation=\"relu\"),\n        layers.BatchNormalization(),\n        layers.Dense(10, activation=\"softmax\")\n    ])\n    model.compile(\n        optimizer=\"adam\",\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model\n\n\nmodel = get_bn_model()\nmodel.optimizer.lr=0.01","775b0a9a":"# View all the layers of the network using the model's summary method\nmodel.summary()","875418c0":"# Train the model\nepochs=3\nhistory = model.fit(\n    batches,\n    steps_per_epoch=batches.n,\n    epochs=epochs,\n    validation_data=val_batches,\n    validation_steps=val_batches.n\n)","4a120ae0":"# Train the model\nepochs=3\nmodel.optimizer.lr=0.01\ngen = image.ImageDataGenerator()\nbatches = gen.flow(X, y, batch_size=64)\nhistory = model.fit(\n    batches,\n    steps_per_epoch=batches.n,\n    epochs=epochs\n)","3049745f":"predictions = np.argmax(model.predict(X_test), axis=-1)\n\nsubmission = pd.DataFrame({\n    \"ImageId\": list(range(1, len(predictions) + 1)),\n    \"Label\": predictions\n})\nsubmission.to_csv(\n    \"digit_recognizer_submission.csv\",\n    index=False,\n    header=True\n)\nsubmission.head()","c62e6868":"# Preprocess the data","348bdecf":"# Create the model","24417101":"# Cross Validation","a5642d2e":"# Load train and test data","5746b6df":"# Create a submission file","706c31ee":"# Visualize training results","434dedc7":"# Data Visualization","b44bc68e":"# Import required dependencies"}}