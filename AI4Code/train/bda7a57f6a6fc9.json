{"cell_type":{"4c8c55a9":"code","fe460337":"code","1ba50971":"code","b5955e10":"code","c1649f66":"code","49071ac5":"code","9c55709b":"code","a37f0d78":"code","aa3d4393":"code","29ed01ae":"code","ed616fb4":"code","e981fd4f":"code","849433a4":"code","cb7f92cb":"code","756c41e4":"code","31c76e36":"code","69139ba7":"code","1b03a324":"code","0b690923":"code","2e70b409":"code","e184b077":"code","2a8f04e2":"code","ec86769f":"code","432a1ea2":"code","e5a903a9":"code","cfbeb944":"code","40eac903":"code","ca157930":"code","bc4ae37d":"code","2bae196e":"code","2f3197b8":"code","b2bf3f5f":"code","9a885282":"code","f8524143":"code","3abe0099":"code","231c6dc5":"code","6a6e5851":"code","e6cc5703":"code","58b47782":"code","4e746f3a":"code","fd42a99d":"code","1b20f883":"code","49d37cf0":"code","3798d4ca":"code","b17f4b6e":"code","aea34475":"code","5a10c4ac":"code","b7bd3e94":"code","5243046b":"code","a3af6f7d":"code","4514f76c":"code","dbfa8d42":"code","a1a870f2":"code","f54c3419":"code","0cca3b3f":"code","ad79f37c":"code","70620019":"code","57be0712":"code","1d66a8cf":"code","d038bf12":"code","5e7453f5":"code","a9f92047":"code","6fba645d":"code","ad35b10a":"code","a9374ceb":"code","b7c60abe":"code","b2d8a5a5":"code","98398171":"code","588fda4a":"code","e0453ab4":"code","90faee25":"code","1526adfb":"code","1c1fa31b":"code","ded61773":"code","ec172992":"code","34ea4052":"code","07686e4c":"code","8c2b50fa":"code","eefe1baa":"code","2389dc10":"code","60948a20":"code","1e97385b":"code","93a839bb":"code","b993795d":"code","0bc65a37":"code","b49c7685":"code","6a145a80":"code","d223d847":"code","cdf68ead":"code","363e9366":"code","f9cbacd0":"code","6b875c0a":"code","4ba77e8b":"code","46bcd264":"code","337b532a":"code","4095f4d6":"code","a1ef2c67":"code","82657983":"code","1ab00c8f":"code","ecff010c":"markdown","fc935963":"markdown","1387a3c0":"markdown","75c1a44d":"markdown","b07bbe29":"markdown","3b0ac838":"markdown","c4c87199":"markdown","8bfd2b0d":"markdown","88cb5f0d":"markdown","56ff3a23":"markdown","e488a8a5":"markdown","cc586e4e":"markdown","4a1711e9":"markdown","a74ac9f5":"markdown","7b5558e5":"markdown","a5a7ff23":"markdown","58f70734":"markdown","2aff5135":"markdown","eb8f41bf":"markdown","c7a5c38c":"markdown","823b5bc8":"markdown","6f70460b":"markdown","32083be2":"markdown"},"source":{"4c8c55a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fe460337":"# Carregando os dados\ntreino = pd.read_csv('\/kaggle\/input\/big-mart-sales-prediction\/Train.csv')\nteste = pd.read_csv('\/kaggle\/input\/big-mart-sales-prediction\/Test.csv')","1ba50971":"# Verificando o tamanho dos dataframes\ntreino.shape, teste.shape","b5955e10":"# Juntando os dataframes\ndf = treino.append(teste)","c1649f66":"# Quantidade de linhas e colunas :treino.info(), teste.info(), df.info()\ntreino.shape, teste.shape, df.shape","49071ac5":"# quantidade de id por dataset\ntreino[\"Item_Identifier\"].nunique(), teste[\"Item_Identifier\"].nunique(), df[\"Item_Identifier\"].nunique()","9c55709b":"df.sample(8).T # Olhando os dados aleatoriamente\n# df.head(8).T # ver cabe\u00e7a transposta","a37f0d78":"# Dados\ndf.info()","aa3d4393":"# contar valores nulos\n'NULOS', df.isnull().sum()","29ed01ae":"# colunas\n# df.columns","ed616fb4":"# Verificando os valores nulos\n# describe da vari\u00e1vel\n# distribui\u00e7\u00e3o de frequencia\n'itens nulos',df['Item_Weight'].isnull().sum(), 'describe', df['Item_Weight'].describe(), df['Item_Weight'].plot.hist(bins=30)","e981fd4f":"# Verificando os valores nulos. # describe da vari\u00e1vel, # distribui\u00e7\u00e3o de frequencia\n'itens nulos',df['Item_Visibility'].isnull().sum(), 'describe', df['Item_Visibility'].describe(), df['Item_Visibility'].plot.hist(bins=30)","849433a4":"# Verificando os valores nulos. # describe da vari\u00e1vel, # distribui\u00e7\u00e3o de frequencia\n'itens nulos',df['Item_MRP'].isnull().sum(), 'describe', df['Item_MRP'].describe(), df['Item_MRP'].plot.hist(bins=30)","cb7f92cb":"# Verificando os valores nulos. # describe da vari\u00e1vel, # distribui\u00e7\u00e3o de frequencia\n'itens nulos',df['Item_Outlet_Sales'].isnull().sum(), 'describe', df['Item_Outlet_Sales'].describe(), df['Item_Outlet_Sales'].plot.hist(bins=30)","756c41e4":"# vendo as categorias das vari\u00e1veis objeto ou categ\u00f3ricas:\ndf['Item_Fat_Content'].unique(),df['Item_Type'].unique(),df['Outlet_Identifier'].unique(),df['Outlet_Establishment_Year'].unique(), df['Outlet_Size'].unique(), df['Outlet_Location_Type'].unique(), df['Outlet_Type'].unique()","31c76e36":"# df['Item_Fat_Content'].value_counts().head().sort_values(ascending=True).plot.barh()\ndf['Item_Fat_Content'].unique(), df['Item_Fat_Content'].value_counts().plot.barh()","69139ba7":"# df['Item_Fat_Content'].value_counts().head().sort_values(ascending=True).plot.barh()\ndf['Item_Type'].unique(), df['Item_Type'].value_counts().plot.barh()","1b03a324":"# df['Outlet_Identifier'].value_counts().head().sort_values(ascending=True).plot.barh()\ndf['Outlet_Identifier'].unique(), df['Outlet_Identifier'].value_counts().plot.barh()","0b690923":"# df['Outlet_Establishment_Year'].value_counts().head().sort_values(ascending=True).plot.barh()\ndf['Outlet_Establishment_Year'].unique(), df['Outlet_Establishment_Year'].value_counts().plot.barh()","2e70b409":"# df['Outlet_Size'].value_counts().head().sort_values(ascending=True).plot.barh()\ndf['Outlet_Size'].unique(), df['Outlet_Size'].value_counts(dropna=False).plot.barh()","e184b077":"# df['Outlet_Location_Type'].value_counts().head().sort_values(ascending=True).plot.barh()\ndf['Outlet_Location_Type'].unique(), df['Outlet_Location_Type'].value_counts(dropna=False).plot.barh()","2a8f04e2":"# df['Outlet_Type'].value_counts().head().sort_values(ascending=True).plot.barh()\ndf['Outlet_Type'].unique(), df['Outlet_Type'].value_counts(dropna=False).plot.barh()","ec86769f":"# df.nlargest(5, 'Item_Outlet_Sales')","432a1ea2":"df.columns","e5a903a9":"# contar valores nulos\n'NULOS', df.isnull().sum(), 'NULOS PERCENTUAL', (df.isnull().sum()\/len(df['Item_Identifier']))*100","cfbeb944":"df['Outlet_Size'].value_counts(dropna=False)","40eac903":"#outlet_size vazios\ndf[(df['Outlet_Size'].isnull())].pivot_table(index=['Outlet_Identifier','Outlet_Type','Outlet_Location_Type'],aggfunc=\"count\" ,values='Item_Identifier', dropna=True)","ca157930":"# Outlet_size preechidos\ndf.pivot_table(index=['Outlet_Size','Outlet_Identifier','Outlet_Type','Outlet_Location_Type'],aggfunc=\"count\" ,values='Item_Identifier', dropna=True)","bc4ae37d":"#Nulos do dataframe\n# df.isnull().sum()","2bae196e":"# contagem dos mulos\ndf[(df['Item_Weight'].isnull())]['Item_Weight'].value_counts(dropna=False)","2f3197b8":"df[df['Item_Weight'].isnull()]['Item_Identifier']","b2bf3f5f":"df[df['Item_Identifier']=='FDP10'].sample(8).T","9a885282":"df[~df['Item_Weight'].isnull()].pivot_table(index='Item_Identifier',aggfunc=['count','min','max','mean'] ,values='Item_Weight', dropna=False)","f8524143":"# Situa\u00e7\u00e3o da vari\u00e1vel antes\ndf['Outlet_Size'].value_counts(dropna=False)","3abe0099":"# Substituir NAN por \"Small\"\ndf['Outlet_Size'].fillna(value=\"Small\", inplace=True)","231c6dc5":"# Conferir a substituia\u00e7\u00e3o\ndf['Outlet_Size'].value_counts(dropna=False)","6a6e5851":"# Situa\u00e7\u00e3o da vari\u00e1vel antes = nulos\ndf['Item_Weight'].isnull().value_counts(dropna=False)","e6cc5703":"#visualizando NAN\n# df[df['Item_Weight'].isnull()].sample(8).T","58b47782":"#Criando Tabela refer\u00eanica do Item_Weight\nt1=df[~df['Item_Weight'].isnull()].pivot_table(index='Item_Identifier', values='Item_Weight', aggfunc='mean')\n# t1","4e746f3a":"#Convertendo a d\u00edcion\u00e1rio\nt2=t1.to_dict()['Item_Weight']\n#t2","fd42a99d":"df['Item_Weight']=df['Item_Identifier'].map(t2)","1b20f883":"# Situa\u00e7\u00e3o da vari\u00e1vel DEPOIS\ndf['Item_Weight'].isnull().value_counts(dropna=False)","49d37cf0":"# df.sample(8).T","3798d4ca":"df['Item_Fat_Content'].unique()","b17f4b6e":"df['Item_Fat_Content'].value_counts()","aea34475":"# Vamos transformar a coluna Item_Fat_Content\n\nmapa1={'Low Fat':1, 'Regular': 2, 'LF': 1, 'reg': 2, 'low fat':1}\n\ndf['Item_Fat_Content'] = df['Item_Fat_Content'].replace(mapa1).astype(int)\n\ndf['Item_Fat_Content'].value_counts()","5a10c4ac":"df['Item_Type'].unique()","b7bd3e94":"df['Item_Type'].value_counts()","5243046b":"# Vamos transformar a coluna Item_Type\n\nmapa2={'Fruits and Vegetables': 1,'Snack Foods': 2,'Household': 3,'Frozen Foods':4,'Dairy':5,'Baking Goods':6,'Canned':7,'Health and Hygiene':8,'Meat':9,'Soft Drinks':10,'Breads':11,'Hard Drinks':12,'Others':13,'Starchy Foods':14,'Breakfast': 15,'Seafood':16}\n\ndf['Item_Type'] = df['Item_Type'].replace(mapa2).astype(int)\n\ndf['Item_Type'].value_counts()","a3af6f7d":"# df['Outlet_Identifier'].unique()","4514f76c":"# df['Outlet_Identifier'].value_counts()","dbfa8d42":"# # Vamos transformar a coluna Outlet_Identifier\n\n# mapa3={'OUT027': 27,'OUT013': 13,'OUT049': 49,'OUT046': 46,'OUT035': 35,'OUT045': 45,'OUT018': 18,'OUT017': 17,'OUT010': 10,'OUT019': 19}\n\n# df['Outlet_Identifier'] = df['Outlet_Identifier'].replace(mapa3).astype(int)\n\n# df['Outlet_Identifier'].value_counts()","a1a870f2":"df['Outlet_Size'].unique()","f54c3419":"df['Outlet_Size'].value_counts()","0cca3b3f":"# Vamos transformar a coluna Outlet_Size\n\nmapa3={'Small':1,'Medium':2,'High':3}\n\ndf['Outlet_Size'] = df['Outlet_Size'].replace(mapa3).astype(int)\n\ndf['Outlet_Size'].value_counts()","ad79f37c":"df['Outlet_Location_Type'].unique()","70620019":"df['Outlet_Location_Type'].value_counts()","57be0712":"# Vamos transformar a coluna Outlet_Location_Type\n\nmapa3={'Tier 3': 3,'Tier 2': 2,'Tier 1': 1}\n\ndf['Outlet_Location_Type'] = df['Outlet_Location_Type'].replace(mapa3).astype(int)\n\ndf['Outlet_Location_Type'].value_counts()","1d66a8cf":"df['Outlet_Type'].unique()","d038bf12":"df['Outlet_Type'].value_counts()","5e7453f5":"# Vamos transformar a coluna Outlet_Type\n\nmapa3={'Supermarket Type1':4, 'Grocery Store': 1, 'Supermarket Type3': 3, 'Supermarket Type2':2}\n\ndf['Outlet_Type'] = df['Outlet_Type'].replace(mapa3).astype(int)\n\ndf['Outlet_Type'].value_counts()","a9f92047":"df.info()","6fba645d":"df.nunique()","ad35b10a":"# SEPARANDO NOS ORIGINAIS\ntrei=df[~df['Item_Outlet_Sales'].isnull()] #Treino original: Item_Outlet_Sales n\u00e3o nulo\ntest=df[df['Item_Outlet_Sales'].isnull()] #Teste original: Item_Outlet_Sales nulo","a9374ceb":"trei.T","b7c60abe":"# Separando o dataframe em train, valid\n\n#importar fun\u00e7\u00e3o\nfrom sklearn.model_selection import train_test_split\n\n# Separando trei em train e valid\ntrain, valid = train_test_split(trei, test_size=0.25, random_state=42)\n\ntrain.shape, valid.shape, test.shape","b2d8a5a5":"test.sample(10).T","98398171":"# Definindo as Features\nrecursos=['Item_Weight', 'Item_Fat_Content', 'Item_Visibility','Item_MRP','Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n       'Outlet_Type']\ntarget='Item_Outlet_Sales'","588fda4a":"# Importando o modelo\nfrom sklearn.ensemble import RandomForestRegressor","e0453ab4":"# Instanciar o modelo\nrf = RandomForestRegressor(random_state=42, n_jobs=-1)","90faee25":"# Treinando o modelo\nrf.fit(train[recursos], train[target])","1526adfb":"# Fazendo previs\u00f5es em cima dos dados de valida\u00e7\u00e3o\npredrf = rf.predict(valid[recursos])","1c1fa31b":"# lendo valores preditos na valida\u00e7\u00e3o\npredrf[:5], valid['Item_Outlet_Sales'].head(5)","ded61773":"#Calculando a ERRO QUADRADO M\u00c9DIO\n\nfrom sklearn.metrics import mean_squared_error\ny_true = list(valid['Item_Outlet_Sales'])\ny_pred = list(predrf)\nmean_squared_error(y_true, y_pred, squared=False)","ec172992":"## Fazendo previs\u00f5es em cima dos dados de teste\npredrfteste = rf.predict(test[recursos])","34ea4052":"#Gravando predi\u00e7\u00f5es de teste na tabela de teste\ntest['Item_Outlet_Sales']=predrfteste","07686e4c":"test[['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales']]","8c2b50fa":"# Gerando o arquivo para submeter ao kaggle\ntest[['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales']].to_csv('rfr_novo1.csv', index=False)","eefe1baa":"# Definindo as Features\nrecursos=['Item_Weight', 'Item_Fat_Content', 'Item_Visibility','Item_MRP','Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n       'Outlet_Type']\ntarget='Item_Outlet_Sales'","2389dc10":"train.shape, valid.shape, test.shape","60948a20":"# Importando o modelo\nfrom sklearn.tree import DecisionTreeRegressor","1e97385b":"# Instanciando a \u00c1rvore de Decis\u00e3o\nad = DecisionTreeRegressor(random_state = 42)\n# Carregamos o modelo vazio numa vari\u00e1vel","93a839bb":"# Treinando o modelo\nad.fit(train[recursos], train[target])","b993795d":"# Fazendo previs\u00f5es em cima dos dados de valida\u00e7\u00e3o\npredad = ad.predict(valid[recursos])","0bc65a37":"# lendo valores preditos na valida\u00e7\u00e3o\npredad[:5], valid['Item_Outlet_Sales'].head(5)","b49c7685":"#Calculando a ERRO QUADRADO M\u00c9DIO\n\nfrom sklearn.metrics import mean_squared_error\ny_true = list(valid['Item_Outlet_Sales'])\ny_pred = list(predad)\nmean_squared_error(y_true, y_pred, squared=False)","6a145a80":"## Fazendo previs\u00f5es em cima dos dados de teste\npredadteste = ad.predict(test[recursos])","d223d847":"#Gravando predi\u00e7\u00f5es de teste na tabela de teste\ntest['Item_Outlet_Sales_ad']=predadteste","cdf68ead":"test[['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales']]","363e9366":"# Gerando o arquivo para submeter ao kaggle\ntest[['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales']].to_csv('adr_novo1.csv', index=False)","f9cbacd0":"# Definindo as Features\nrecursos2=['Item_Weight', 'Item_Fat_Content', 'Item_Visibility','Item_MRP','Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n       'Outlet_Type']\ntarget2='Item_Outlet_Sales'","6b875c0a":"train.shape, valid.shape, test.shape","4ba77e8b":"# Importando o modelo\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# Instanciando o modelo GBM\ngbm = GradientBoostingRegressor(n_estimators=200, max_depth=1, random_state=42)\n\n# Treinando o modelo\ngbm.fit(train[recursos2], train[target2])\n\n# Fazendo previs\u00f5es em cima dos dados de valida\u00e7\u00e3o\npredgbm = gbm.predict(valid[recursos2])","46bcd264":"# lendo valores preditos na valida\u00e7\u00e3o\npredgbm[:5], valid['Item_Outlet_Sales'].head(5)","337b532a":"#Calculando a ERRO QUADRADO M\u00c9DIO\n\nfrom sklearn.metrics import mean_squared_error\ny_true = list(valid['Item_Outlet_Sales'])\ny_pred = list(predgbm)\nmean_squared_error(y_true, y_pred, squared=False)","4095f4d6":"## Fazendo previs\u00f5es em cima dos dados de teste\npredgbmteste = gbm.predict(test[recursos2])\n\n# Gravando predi\u00e7\u00f5es de teste na tabela de teste\ntest['Item_Outlet_Sales']=predgbmteste","a1ef2c67":"test[['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales']].sample(10)","82657983":"test[test['Item_Outlet_Sales']<0]['Item_Outlet_Sales']","1ab00c8f":"# Gerando o arquivo para submeter ao kaggle\ntest[['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales']].to_csv('gbmr_novo1.csv', index=False)","ecff010c":"# USANDO O MODELO GradientBoostingRegressor\u00b6\n","fc935963":"**Vari\u00e1veis quantitativas**","1387a3c0":"**Item_Weight <BR>\nVER PELO Item_Identifier** <BR>\nPREENCHER PELO Item_Identifier","75c1a44d":"# **Juntar bases e marcar treino e teste**","b07bbe29":"# **Explorando os dados, estimando transforma\u00e7\u00f5es**","3b0ac838":"# RANDOM FOREST REGRESSOR - RESULTADO 1\nSUBMETIDO AO: https:\/\/datahack.analyticsvidhya.com\/contest\/practice-problem-big-mart-sales-iii\/ <BR>\n**Mon, Dec-20-2021, 08:19:14 PM\trfr primeiro\t1201.49780549998\t**","c4c87199":"# **USANDO O MODELO RANDOM FOREST REGRESSOR**\n    -> ser\u00e1 predito um valor (regress\u00e3o)<br>","8bfd2b0d":"**VAZIOS A PREENCHER**","88cb5f0d":"**Treino, Valida\u00e7\u00e3o e Teste SEPARADOS**","56ff3a23":"# ARVORE DE DECIS\u00c3O - RESULTADO 2\nSUBMETIDO AO: https:\/\/datahack.analyticsvidhya.com\/contest\/practice-problem-big-mart-sales-iii\/ <BR>\n**Mon, Dec-20-2021, 09:43:12 PM\tadr novo1\t1580.65364120397**","e488a8a5":"# **>>>AJUSTANDO VARI\u00c1VEL**","cc586e4e":"**Preencher Outlet_Size com \"Small\"**","4a1711e9":"# **>>>PREENCHER OS NULOS**","a74ac9f5":"**Preencher Item_Weight pelo correspondente por Item_Identifier**","7b5558e5":"# **Carregando datasets**","a5a7ff23":"# USANDO O MODELO ARVORE DE DECIS\u00c3O","58f70734":"**Outlet_Size <BR>\nVER PELO Outlet_Location_Type OU Outlet_Identifier OU Outlet_Type <BR>\nConclus\u00e3o: tudo \u00e9 small por semelhan\u00e7a aos outlet_size preenchidos**","2aff5135":"**Item_Fat_Content**","eb8f41bf":"**Categorias objeto ou categ\u00f3ricas**","c7a5c38c":"# GradientBoostingRegressor - RESULTADO 3\nSUBMETIDO AO: https:\/\/datahack.analyticsvidhya.com\/contest\/practice-problem-big-mart-sales-iii\/ <BR>\n**Mon, Dec-20-2021, 15:51:17 PM\tgbmr novo1\tN\u00c3O FOI POSSIVEL AVALIAR POIS EXISTEM VALORES NEGATIVOS**","823b5bc8":"# **SEPARANDO TREINO (TREINO E VALIDA\u00c7\u00c3O - originais) E TESTE**","6f70460b":"# **Valores Nulos**","32083be2":"# **Base do Trabalho**\n\nhttps:\/\/www.kaggle.com\/devashish0507\/big-mart-sales-prediction"}}