{"cell_type":{"5518a215":"code","f81bb43b":"code","62561f0e":"code","91b6e819":"code","12a15945":"code","012ae5a0":"code","8fb93dbc":"code","9b03375e":"code","f4ff0eeb":"code","e1a91143":"code","8e02244f":"code","18109d2b":"code","8cc182fb":"code","0bf41cde":"code","40783c10":"code","d9258e2b":"code","b0638413":"code","2e6e01b1":"code","1aa7c3be":"code","8f20fb0c":"markdown","47800d15":"markdown","59d864d8":"markdown","92c2bb95":"markdown"},"source":{"5518a215":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport random\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f81bb43b":"traindir = \"..\/input\/gender-classification-dataset\/Training\"\nvaliddir = \"..\/input\/gender-classification-dataset\/Validation\"\nos.listdir(traindir)","62561f0e":"def show_image(dir):\n    plt.figure(figsize=(12,7))\n    for i in range(10):\n        plt.subplot(2,5,i+1)\n        img = random.choice(os.listdir(dir))\n        img = load_img(os.path.join(dir,img))\n        plt.subplots_adjust(hspace=0.2)\n        x =dir.split(\"\/\")[-1]\n        if x == \"male\":\n            plt.suptitle(\"Male Images\",fontsize=15)\n        else:\n            plt.suptitle(\"Female Images\",fontsize=15)\n        plt.imshow(img)\n    plt.tight_layout()","91b6e819":"show_image(\"..\/input\/gender-classification-dataset\/Training\/male\")","12a15945":"show_image(\"..\/input\/gender-classification-dataset\/Training\/female\")","012ae5a0":"height = 150\nwidth = 150\ntrain_datagen =  ImageDataGenerator(rescale = 1\/255.0,rotation_range=45,height_shift_range=0.2,shear_range=0.2,\n                              zoom_range=0.2,validation_split=0.2,horizontal_flip=True)\n\ntrain_data = train_datagen.flow_from_directory(directory = traindir,target_size=(height,width),\n                                               class_mode = \"categorical\",batch_size=32,subset=\"training\")\n\nval_datagen = ImageDataGenerator(rescale = 1\/255.0)\n\nval_data = train_datagen.flow_from_directory(directory = traindir,target_size=(height,width),\n                                               class_mode = \"categorical\",batch_size=32,subset=\"validation\")","8fb93dbc":"from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nmobilenet = MobileNetV2(weights = \"imagenet\",include_top = False,input_shape=(height,width,3))","9b03375e":"for layer in mobilenet.layers:\n    layer.trainable = False","f4ff0eeb":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,Conv2D,MaxPool2D,BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping","e1a91143":"model = Sequential()\nmodel.add(mobilenet)\nmodel.add(Dense(128,activation=\"relu\"))\n#model.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(2,activation = \"softmax\"))\n\nmodel.compile(optimizer=Adam(lr=0.001),loss = \"categorical_crossentropy\",metrics =[\"accuracy\"])\nmodel.summary()","8e02244f":"model.compile(optimizer=Adam(lr=0.001),loss = \"categorical_crossentropy\",metrics =[\"accuracy\"])\nmodel.summary()","18109d2b":"checkpoint = ModelCheckpoint(\"Gender.h5\",monitor = \"val_accuracy\",save_best_only = True,verbose=1)\nearlystop = EarlyStopping(monitor='val_acc',patience=5,verbose=1)","8cc182fb":"batch_size = 32\nhistory = model.fit_generator(train_data,steps_per_epoch = len(train_data)\/\/ batch_size,epochs=15,\n                              validation_data = val_data,validation_steps = len(val_data)\/\/batch_size,\n                              callbacks = [checkpoint,earlystop],verbose=1)","0bf41cde":"model.evaluate_generator(val_data)","40783c10":"\ndef checking(img):\n    label = {0:\"female\",1:\"male\"} \n    image =cv2.imread(img)\n    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n    cascade = cv2.CascadeClassifier(\"..\/input\/additional-data\/haarcascade_frontalface_default.xml\")\n    faces = cascade.detectMultiScale(gray,1.1,7)#1.1\n    \n    for x,y,w,h in faces:\n        face = image[y:y+h,x:x+w]\n        face = cv2.resize(face,(150,150))\n        img_scaled = face\/255.0\n        reshape = np.reshape(img_scaled,(1,150,150,3))\n        img = np.vstack([reshape])\n        result = model.predict_classes(img)\n        \n        if result == 0:\n            cv2.rectangle(image,(x-10,y),(x+w,y+h),(0,255,0),4)\n            cv2.rectangle(image,(x-10,y-50),(x+w,y),(255,0,0),-1)\n            cv2.putText(image,label[0],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2)\n            \n            \n            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n            plt.imshow(image)\n            \n        \n            \n        elif result == 1:\n            cv2.rectangle(image,(x-10,y),(x+w,y+h),(0,255,0),4)\n            cv2.rectangle(image,(x-10,y-50),(x+w,y),(255,0,0),-1)\n            cv2.putText(image,label[1],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2)\n            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n            plt.imshow(image)\nplt.show()\ncv2.destroyAllWindows()\n            ","d9258e2b":"checking(\"..\/input\/additional-data\/ryan.jpeg\")","b0638413":"checking(\"..\/input\/additional-data\/LilyCollins.jpg\")","2e6e01b1":"checking(\"..\/input\/additional-data\/Zac.jpg\")","1aa7c3be":"checking(\"..\/input\/additional-data\/Couples-Face.jpg\")","8f20fb0c":"> <h3> Model Building:<\/h3>","47800d15":"---\n\n<h1 style=\"text-align: center;font-size: 40px;\">Gender Classification using OpenCV & Keras<\/h1>\n\n---\n","59d864d8":"---\n\n<h1 style=\"text-align: center;font-size: 20px;\">Thanks for Reading!!<\/h1>\n\n---\n","92c2bb95":"- Here, we can see that our model correctly classify Gender of a Person!!"}}