{"cell_type":{"0322714d":"code","2b7d5359":"code","087a2350":"code","e30a4a98":"code","7e15522f":"code","32015f19":"code","2ddf4c37":"code","ecfac8d2":"code","f6c4faf7":"code","0f800afb":"code","330718e4":"code","1346af91":"code","07eacba9":"code","b813983d":"code","462d1318":"markdown","ef1bba88":"markdown","6b0cbc73":"markdown","f96a715d":"markdown","8ffedb9c":"markdown","936fd24e":"markdown","2e0d6ea2":"markdown","b36bedde":"markdown","46b86e22":"markdown","9d92dff3":"markdown"},"source":{"0322714d":"import numpy as np, pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm import tqdm_notebook\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\ntrain_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')","2b7d5359":"train_data.head()","087a2350":"cols = [c for c in train_data.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n\nmagic_idx = []\nmagic_pred = []\nmagic_auc = []\n\nfor i in tqdm_notebook(range(512)):\n    train2 = train_data[train_data['wheezy-copper-turtle-magic'] == i]\n    train2.reset_index(drop=True, inplace=True)\n\n    clf = LogisticRegression(solver='liblinear', penalty='l1', C=0.05)\n    clf.fit(train2[cols], train2['target'])\n\n    for j in range(0, 512):\n        val = train_data[train_data['wheezy-copper-turtle-magic'] == j]\n        preds = clf.predict_proba(val[cols])[:, 1]\n        auc = roc_auc_score(val['target'], preds)\n        magic_idx.append(i)\n        magic_pred.append(j)\n        magic_auc.append(auc)","e30a4a98":"magic_mx = pd.DataFrame({'magic_fit':magic_idx, 'magic_pred':magic_pred, 'auc':magic_auc})\nmagic_mx = magic_mx[['magic_fit', 'magic_pred', 'auc']]\nmagic_mx.head()","7e15522f":"magic_mx_pt = pd.pivot_table(magic_mx, index='magic_fit', columns='magic_pred', values='auc')\n\nplt.style.use({'figure.figsize':(18, 15), 'font.size':15}) # set the size of plots\nsns.heatmap(magic_mx_pt)","32015f19":"sns.heatmap(magic_mx_pt > 0.6) # higher correlated","2ddf4c37":"cols = [c for c in train_data.columns if c not in ['id', 'wheezy-copper-turtle-magic']]\n\nmagic_num = []\ncol_name = []\ncorr_ls = []\nfor i in tqdm_notebook(range(512)):\n    tmp = train_data[train_data['wheezy-copper-turtle-magic'] == i]\n    correlations = tmp[cols].corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n    correlations = correlations[correlations['level_0'] != correlations['level_1']]\n    corr = correlations[correlations['level_0'] == 'target']\n    magic_num.append(i)\n    col_name.append(corr['level_1'].iloc[0])\n    corr_ls.append(corr[0].iloc[0])","ecfac8d2":"corr_under_magic = pd.DataFrame({'magic':magic_num, 'feature':col_name, 'corr':corr_ls})\ncorr_under_magic.head()","f6c4faf7":"corr_under_magic['feature'].nunique()","0f800afb":"corr_under_magic['feature'].value_counts()","330718e4":"cols = [c for c in train_data.columns if c not in ['id', 'wheezy-copper-turtle-magic']]\n\nmagic_num = []\ncol_name = []\ncorr_ls = []\nfor i in tqdm_notebook(range(512)):\n    tmp = train_data[train_data['wheezy-copper-turtle-magic'] == i]\n    correlations = tmp[cols].corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=True).reset_index()\n    correlations = correlations[correlations['level_0'] != correlations['level_1']]\n    corr = correlations[correlations['level_0'] == 'target']\n    magic_num.append(i)\n    col_name.append(corr['level_1'].iloc[0])\n    corr_ls.append(corr[0].iloc[0])","1346af91":"corr_under_magic = pd.DataFrame({'magic':magic_num, 'feature':col_name, 'corr':corr_ls})\ncorr_under_magic.head()","07eacba9":"corr_under_magic['feature'].nunique()","b813983d":"corr_under_magic['feature'].value_counts()","462d1318":"### Highly correlated","ef1bba88":"This illustrates the auc when we train the model on magic_fit and predict magic_pred.  \nWe can plot that as heatmap shown as following:","6b0cbc73":"Well, looks like there might be something with \"beady-lilac-hornet-expert\"?","f96a715d":"## 1. Interconnection between magics","8ffedb9c":"I just put the most highly correlated feature in the table here. (either positive or negative correlated)","936fd24e":"In senkin13's EDA https:\/\/www.kaggle.com\/senkin13\/eda-starter (Thanks to him), we saw that the correlation between the features and target were very low. But how will it be under different magics? Let's see.","2e0d6ea2":"### Uncorrelated ones","b36bedde":"## 2. Feature and Target correlation under different magics","46b86e22":"Thanks for Vladislav and his kernel https:\/\/www.kaggle.com\/speedwagon\/are-magics-interconnected  \nJust wanna dive deeper into this interconnection thing.","9d92dff3":"Looks like there is something here, but I just can't name it. Maybe I'm just not clever enough to find it out. Hope it could give you guys some insight. :)"}}