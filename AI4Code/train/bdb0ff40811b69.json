{"cell_type":{"eefe1b2c":"code","20da9bd6":"code","1932f327":"code","46aa944c":"code","84a91d3a":"code","e661d3cc":"code","ae79aeb8":"code","c6ca6c5b":"code","af8c3732":"code","593f2d24":"code","87a6591d":"code","31d11c06":"code","c897311e":"code","92e54368":"code","0a2ff7d1":"code","d6c0537b":"code","d0617e42":"code","5276a8a0":"code","9621f2f6":"code","bf668525":"code","b6a041b5":"code","ce147201":"code","c5a776f8":"code","5f5019ee":"code","a9e2ce2b":"code","f4fca6b8":"code","2b79a9d9":"code","5b0e7d7b":"code","2c0f5f27":"code","03f6a252":"code","17869fa4":"code","b983a603":"markdown","cd11cfb1":"markdown","b061d400":"markdown","ea4e3e26":"markdown","3a749e51":"markdown","05bc7c28":"markdown","03447078":"markdown","7f24e28e":"markdown","1db9727a":"markdown","a492f78e":"markdown","4d247a15":"markdown","8c4e284e":"markdown","c386638e":"markdown","e06c00e3":"markdown","db88af62":"markdown","c5c4edff":"markdown","e9e54dc1":"markdown","396e2131":"markdown","63c15556":"markdown","2819f6f7":"markdown","4aa2bf0c":"markdown","01b2bb4e":"markdown","30e04eb6":"markdown","77d9a3c9":"markdown","72acbf39":"markdown"},"source":{"eefe1b2c":"!pip install vaderSentiment\n","20da9bd6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport re\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1932f327":"df = pd.read_csv('\/kaggle\/input\/ipl2020-tweets\/IPL2020_Tweets.csv')\ndf.head()","46aa944c":"df.shape","84a91d3a":"df.info()","e661d3cc":"df.isnull().sum()","ae79aeb8":"df['senttext'] = df['text']\n","c6ca6c5b":"df = df.apply(lambda x: x.astype(str).str.lower())","af8c3732":"loc_df = df[df.user_location != 'nan']\nloc_df.user_location.value_counts().nlargest(20).plot(kind='bar',figsize=(20,8))\n# df..value_counts().nlargest(20).plot(kind='bar')","593f2d24":"indian_cities = {}\nindian_metros = ['mumbai', 'bangalore', 'delhi', 'kolkata', 'chennai', 'ahmedabad', 'hyderabad']\nfor city in indian_metros: \n    indian_cities[city] = df.user_location.str.count(city).sum()\n","87a6591d":"plt.figure(figsize=(20, 8))\nplt.bar(*zip(*indian_cities.items()))\n\nplt.show()","31d11c06":"ipl_countries = {}\ncountries = ['usa', 'uk', 'united arab emirates', 'canada', 'australia', 'south africa', 'pakistan']\nfor country in countries: \n    ipl_countries[country] = df.user_location.str.count(country).sum()\n\n    \nplt.figure(figsize=(20, 8))\nplt.bar(*zip(*ipl_countries.items()))\n\nplt.show()","c897311e":"df.user_verified.value_counts().plot(kind='bar', rot=0)","92e54368":"df.source.value_counts().nlargest(10).plot(kind='bar', rot=0, figsize=(20,8))","0a2ff7d1":"hashtag_df = df[df.hashtags != 'nan']\nhashtag_df.hashtags.value_counts().nlargest(10).plot(kind='bar', rot=0, figsize=(20,8))","d6c0537b":"from nltk.corpus import stopwords\n\nstop_words = stopwords.words('english')\ndf.text = df.text.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))","d0617e42":"df.text = df.text.apply(lambda x: ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", x).split()))","5276a8a0":"df.text = df.text.apply(lambda x: ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", x).split()))","9621f2f6":"df.text = df.text.apply(lambda x: ' '.join(re.sub(r'http\\S+', '', x).split()))","bf668525":"wordcloud = WordCloud(\n                          background_color='white',\n                          colormap='Blues',\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(df['text']))\n\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","b6a041b5":"df['tweet_date']=pd.to_datetime(df['date']).dt.date\ntweet_date=df['tweet_date'].value_counts().to_frame().reset_index().rename(columns={'index':'date','tweet_date':'count'})\ntweet_date['date']=pd.to_datetime(tweet_date['date'])\ntweet_date=tweet_date.sort_values('date',ascending=False)\n","ce147201":"plt.figure (figsize=(50,20))\nplt.xlabel('xlabel', fontsize=18)\nplt.ylabel('ylabel', fontsize=16)\nplt.plot(tweet_date['date'], tweet_date['count'])","c5a776f8":"try:\n    # UCS-4\n    e = re.compile(u'[\\U00010000-\\U0010ffff]')\nexcept re.error:\n    # UCS-2\n    e = re.compile(u'[\\uD800-\\uDBFF][\\uDC00-\\uDFFF]')\nemojis = []\nfor x in df.text:\n    match  = e.search(x)\n    if match:\n        emojis.append(match.group())","5f5019ee":"dfe =  pd.DataFrame(emojis,columns=['text'])\npd.Series(' '.join(dfe['text']).lower().split()).value_counts()[:10]\n","a9e2ce2b":"# Set values for various parameters\nnum_features = 400    # Word vector dimensionality                      \nmin_word_count = 5   # Minimum word count                        \nnum_workers = 4       # Number of threads to run in parallel\ncontext = 10          # Context window size                                                                                    \ndownsampling = 1e-3   # Downsample setting for frequent words\n\nwt = [list(x.split()) for x in df.text]\nfrom gensim.models import word2vec\nprint (\"Training model...\")\nwv_model = word2vec.Word2Vec(wt, workers=num_workers, \\\n            size=num_features, min_count = min_word_count, \\\n            window = context, sample = downsampling)\n\nwv_model.init_sims(replace=True)","f4fca6b8":"wv_model.most_similar('hardik',topn =15)","2b79a9d9":"wv_model.most_similar('yorker',topn =15)","5b0e7d7b":"wv_model.most_similar('virat',topn =15)","2c0f5f27":"analyser = SentimentIntensityAnalyzer()\n\ndf['sentiment_score'] = df['senttext'].apply(lambda x: analyser.polarity_scores(str(x)))\n","03f6a252":"def sentiment_func(sentiment):\n#     print(s['pos'])\n    for k,v in sentiment.items():\n        if (k == 'pos' or k or 'neg' or k == 'neu') == True:\n            if (sentiment['pos'] > 0.5 and sentiment['neg'] < 0.5 and sentiment['neu'] < 0.5) == True:\n                return 'positive'\n            elif (sentiment['pos'] < 0.5 and sentiment['neg'] > 0.5 and sentiment['neu'] < 0.5) == True:\n                return 'negative'\n            elif (sentiment['pos'] < 0.5 and sentiment['neg'] < 0.5 and sentiment['neu'] > 0.5) == True:\n                return 'neutral'\n\ndf['sentiment'] = df['sentiment_score'].apply(sentiment_func)","17869fa4":"df.sentiment.value_counts().plot(kind='bar', rot=0)","b983a603":"### Top 10 Emojis used in tweets","cd11cfb1":"### Replacing the emojis with unicode","b061d400":"### Users in Indian metro cities who have teams in IPL are most active. Other cities like Ahmedabad have much less tweets","ea4e3e26":"## Removing all the stop words, mentions, hashtags and URLs to create a word cloud","3a749e51":"## Now applying the VADER sentiment analyzer","05bc7c28":"### Finding more details about the data set","03447078":"### Most the tweets are neutral. This can be due to most tweets just containing score updates or match updates.\n\n### Number of positive tweets are more than negative. Seems like people were very happy with tournament happening at such difficult time and people got excited and happy to see their favorite cricketers back on pitch.","7f24e28e":"### Time wise plot of all tweets","1db9727a":"### Installing and importing Required libraries","a492f78e":"### Most of the users are not verified on twitter","4d247a15":"### People used the tournament hashtag the most, with some specific match based and team hashtags also making an appearance","8c4e284e":"We can see that some tweets dont involve any hashtags. Also for some the user location and description and source of tweet is missing, but text column which is required for sentiment analysis doesn't contain any null values.","c386638e":"### Users used twitter app on android the most. iPhone users come after Website\/app users","e06c00e3":"### Words like peach, toe length are getting correctly associated whereas bouncer is the exact opposite","db88af62":"### Creating a copy of text so that we can make changes and perform EDA","c5c4edff":"### Using Word2vec to find out similar words","e9e54dc1":"### We can see words like kung,fu as he is commonly known as Kungfu pandya. Brothers also pops up as he and his brother play for same team","396e2131":"# IPL 2020 Tweets Sentiment Analysis","63c15556":"# PLEASE UPVOTE ^^^","2819f6f7":"### Comparing tweets from countries with top cricket teams and where indian population is high.","4aa2bf0c":"### Converting all the data to lowercase","01b2bb4e":"### the word king being similar to virat kohli aka king kohli. ABD who is a teammate also appears","30e04eb6":"### Taking a glance at the data","77d9a3c9":"### Indian cities dominate the top 20 user locations as expected. 'global' and 'worldwide' locations also make it in top 20.","72acbf39":"### Tweets started flowing in when the tournament announcement was made, and saw a steep increase once the tournament started"}}