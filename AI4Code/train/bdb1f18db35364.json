{"cell_type":{"8ef0e7e3":"code","2b580e66":"code","b9f88a75":"code","26fe06f1":"code","2e29ff4a":"code","b3f33a0f":"code","f4fa1abb":"code","851350fd":"code","e7520006":"code","57980ef4":"code","80cc9ad7":"code","085cb34b":"code","e7472af9":"code","4ddcb911":"code","0e597085":"code","e04453b6":"code","a671b757":"code","42a32774":"code","9bd5c966":"markdown","2baaac80":"markdown","3b9b3dfa":"markdown","b97565f7":"markdown","8cdc231e":"markdown","502c6dfa":"markdown","760a82e0":"markdown","155b6b5f":"markdown","46d7a1a0":"markdown"},"source":{"8ef0e7e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os,cv2,keras\nimport json\nimport math\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import ResNet50#, preprocess_input\nimport numpy as np\nimport tensorflow as tf\nimport time\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n#Set random seeds\nseed = 232\nnp.random.seed(seed)\n#tf.set_random_seed(seed)\n\n#set image inputs\ndataset_path = '\/kaggle\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/'\ntrainingImageDirPath = '\/kaggle\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/train_images\/'\ntrainingAnnotationsPath = '\/kaggle\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/train_annotations.json'\ntestingImageDirPath = '\/kaggle\/input\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/vinbigdata-coco-dataset-with-wbf-3x-downscaled\/val_images\/'\n#trainingAnnotationsPath = '\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv'\n\n#RCNN Constants\n#We will only use square images, what is the n in nxn?\nN_img_size = 64","2b580e66":"#Plot some examples\n\nfig, ax = plt.subplots(2, 1, figsize=(15, 7))\nax = ax.ravel()\nplt.tight_layout()\n\nfor i, _set in enumerate(['train_images\/', 'val_images\/']):\n    set_path = dataset_path+_set\n    ax[i].imshow(plt.imread(set_path+os.listdir(set_path)[0]), cmap='gray')\n    ax[i].set_title('Example Image'.format(_set))","b9f88a75":"#Perform Preprocessing on Rect Proposals\ndef GetRectImageData(rects, image):\n    props = []\n    \n    (x, y, w, h) = rects\n    (x, y, w, h) = (int(x), int(y), int(w), int(h))\n        \n    #extract rect from image\n    rect = image[y:y + h, x:x + w]\n    #convert color\n    RGBrect = cv2.cvtColor(rect, cv2.COLOR_BGR2RGB)\n    #Resize rects to NxN\n    squareRect = cv2.resize(RGBrect, (N_img_size, N_img_size))\n        \n    return squareRect\n        ","26fe06f1":"#def trainRPN(imgData):\n    ","2e29ff4a":"#load images into Local memory\ntrainingImagePaths = os.listdir(trainingImageDirPath)\n\nindex = 0\nimgDirSize = len(trainingImagePaths)\n\nannotationsFile = open(trainingAnnotationsPath)\ntrainingMetadata = json.load(annotationsFile)\n\nx_bboxesImageData = []\ny_labels = []\nfor imgPath in trainingImagePaths:\n    matchedImageMetadata = None\n    for imageMetadata in trainingMetadata['images']:\n        if imageMetadata['file_name'] == str(\"train_images\/\" + imgPath):\n            matchedImageMetadata = imageMetadata\n            break\n    \n        \n    #print(str(training_image_path + '\/' + img_path))\n    img = cv2.imread(trainingImageDirPath + '\/' + imgPath)\n    #print(img)\n    (H, W) = img.shape[:2]\n    \n    for annotationsData in trainingMetadata['annotations']:\n        if (annotationsData['image_id'] != matchedImageMetadata['id']):\n            continue\n            \n        bboxDims = annotationsData[\"bbox\"]\n        x_bboxesImageData.append(GetRectImageData(bboxDims, img))\n        \n        y_labels.append(annotationsData[\"category_id\"])\n    \n    if (math.remainder(index,250) == 0):\n        print(\"Progress: \" + str(index) + \" out of \" + str(imgDirSize) + \" images processed\")\n    index += 1\n\nprint(\"Done Loading\")\n#loop over images","b3f33a0f":"#x_bboxesImageData\n#y_labels\n\n# preprocessedInput = tf.preprocess_input(regionRects)\n\n# RpnNetwork = tf.Resnet50()","f4fa1abb":"def computeIou(rect1, rect2):\n    #Get X, y coordinates of intersecting rectangle\n    xMin = max(rect1[0], rect2[0])\n    yMin = max(rect1[1], rect2[1])\n    xMax = min(rect1[2], rect2[2])\n    yMax = min(rect1[3], rect2[3])\n    \n    #get area of intersecting rectangle\n    rectArea = max(0, xMax - xMin + 1) * max(0, yMax - yMin + 1)\n    \n    ","851350fd":"# #load images into Local memory\n# testingImgPaths = os.listdir(testingImageDirPath)\n\n# index = 0\n# imgDirSize = len(testingImgPaths)\n# regionProps = {}\n# for imgPaths in testingImgPaths:\n#     #print(str(training_image_path + '\/' + img_path))\n#     img = cv2.imread(testingImageDirPath + '\/' + imgPaths)\n#     #print(img)\n#     (H, W) = img.shape[:2]\n    \n#     #run selective search on image\n#     rects = selectiveSearch(img)\n    \n#     regionProps = {imgPaths, PreProcessRects(rects, img)}\n    \n#     if (math.remainder(index,5) == 0):\n#         print(\"Progress: \" + str(index) + \" out of \" + str(imgDirSize) + \" images processed\")\n#     if (index >= 50):\n#         break\n#     index += 1\n    \n# print(\"Images Loaded for testing\")","e7520006":"#These are the region proposals for each test image\n\n#npProps = np.array(regionProps)","57980ef4":"print(len(x_bboxesImageData))\nprint(len(y_labels))\nx = np.empty([18024,N_img_size,N_img_size,3])\ny = np.zeros([18024,15])\nfor i in range (18024):\n    x[i,:,:,:] = x_bboxesImageData[i]\n    y[i,y_labels[i]] = 1\n    \nprint(y[4,:])\ndel(x_bboxesImageData)\ndel(y_labels)","80cc9ad7":"from tensorflow.keras import layers\n\ninput_shape = (N_img_size, N_img_size, 3)\nclasses = 15\n# Augment images\n#x = data_augmentation(inputs)\n# Rescale image values to [0, 1]\n#x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(inputs)\n# Add the rest of the model\n# outputs = keras.applications.ResNet50(\n#     weights=None, input_shape=input_shape, classes=classes\n# )(inputs)\n#model = keras.Model(inputs, outputs)\n\nmodel = tf.keras.models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64,activation='relu'))\nmodel.add(layers.Dense(15))\nmodel.summary()\nop = tf.keras.optimizers.Adam(\n    learning_rate=.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n    name='Adam')\nmodel.compile(optimizer=op, loss='mean_squared_error', metrics=['accuracy'])\n\n","085cb34b":"history = model.fit(x, y, epochs=5)","e7472af9":"plt.plot(history.history['accuracy'])\ny_pred = model.predict(x)\nprint(y[0,:],y_pred[0])","4ddcb911":"print(y[5,:],y_pred[5])","0e597085":"model2 = tf.keras.models.Sequential()\nmodel2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\nmodel2.add(layers.MaxPooling2D((2, 2)))\nmodel2.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel2.add(layers.MaxPooling2D((2, 2)))\nmodel2.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel2.add(layers.MaxPooling2D((2, 2)))\nmodel2.add(layers.Conv2D(16, (3, 3), activation='relu'))\nmodel2.add(layers.Flatten())\nmodel2.add(layers.Dense(64,activation='relu'))\nmodel2.summary()","e04453b6":"model3 = tf.keras.models.Sequential()\nfor i, layer in enumerate(model.layers):\n    #print(i)\n    model3.add(layer)\n    if i==8:\n        break\n    \nmodel3.summary()\ny_pred2 = model3.predict(x)","a671b757":"print(y_pred2)\n#y_pred2 18024 training examples by 64 features\n#y 18024 training examples by 15 catagories\nnp.save(\"feature_vectors\", y_pred2)\n#np.save(\"feature_vectors\", y)\n","42a32774":"from numpy import load\n# load array\ndata = load('feature_vectors.npy')\nfrom numpy import asarray\nfrom numpy import savetxt\nsavetxt('submission.csv', data, delimiter=',')\n\n","9bd5c966":"**TRAIN THE NETWORK**","2baaac80":"**Train RPN**","3b9b3dfa":"First we load the training images and convert to a numpy array","b97565f7":"**HELPER FUNCTIONS**","8cdc231e":"**TEST THE TRAINED NETWORK**","502c6dfa":"***Rpn functions***","760a82e0":"Check out some xrays","155b6b5f":"#Create Selective Search Function\n!pip uninstall opencv-contrib-python opencv-python --y\n!pip install opencv-contrib-python\n\nsearchFunction = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n\n\ndef selectiveSearch(image):\n    #Use opencv to selective search\n    searchFunction.setBaseImage(image)\n    \n    searchFunction.switchToSelectiveSearchFast()\n    \n    rects = searchFunction.process()\n    \n    return rects","46d7a1a0":"Generate Bounding Boxes"}}