{"cell_type":{"00d4ed37":"code","a3170271":"code","6b594af5":"code","3da59cd7":"code","6adccbdb":"code","b0ab1901":"code","435b424a":"code","17883eab":"code","b3dc5b6b":"code","7ec89777":"code","8e6f4818":"code","3bff2eb5":"code","0ecd9ea0":"code","fbbbf3ac":"code","37e90550":"code","60af8a2a":"code","8f567773":"code","96b7288f":"code","9aabe3e1":"code","f1ab8f36":"code","1bb43e48":"code","5cc7efbd":"code","83c03ee9":"code","c72126d6":"code","210d8cd3":"code","841e0ce8":"code","3857b091":"code","7dd5f3cd":"code","99e44755":"code","32ce7893":"code","4379fea1":"markdown","f18de7fe":"markdown","be7083ec":"markdown","d24555c9":"markdown","00667e04":"markdown","420183a2":"markdown"},"source":{"00d4ed37":"import numpy as np\nimport os ","a3170271":"path =\"\/kaggle\/input\/movie-review-polarity\/txt_sentoken\/\"","6b594af5":"from nltk.corpus import stopwords \nfrom collections import Counter\nimport string\nimport re\nfrom os import listdir\nfrom numpy import array\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils.vis_utils import plot_model\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Embedding\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\nfrom keras.models import load_model","3da59cd7":"stop_words = stopwords.words('english')","6adccbdb":"# i have to make a document and label s\n\ndef load_doc(filename):\n    file = open(filename,'r')\n    text = file.read()\n    file.close()\n    return text","b0ab1901":"def clean_doc(doc):\n    \n    table = str.maketrans(dict.fromkeys(string.punctuation))\n    doc =  doc.translate(table)\n    doc = doc.split()\n    token = [word for word in doc   if word.isalpha()]\n    token = [word for word in token if word not in stop_words] \n    token = [word for word in token if len(word)>1]\n    \n    return token ","435b424a":"min_occurence =2","17883eab":"def process_doc(directory,vocab):\n    for filename in os.listdir(directory):\n        \n        doc =  load_doc(os.path.join(directory,filename))\n        token = clean_doc(doc)\n        vocab.update(token)","b3dc5b6b":"path = '\/kaggle\/input\/movie-review-polarity\/txt_sentoken\/'\n\nvocab = Counter()\n\npos_tokens = process_doc(path+'pos',vocab)\nneg_tokens = process_doc(path+'neg',vocab)\n\nvocab.most_common(10)","7ec89777":"tokens = [k for k,v in vocab.items() if v>=min_occurence]","8e6f4818":"def save_list(lines,filename):\n    data = '\\n'.join(lines)\n    file = open(filename,'w')\n    file.write(data)\n    file.close()\nsave_list(tokens,'vocab.txt')","3bff2eb5":"vocab = load_doc('vocab.txt')\nvocab = set(vocab.split())","0ecd9ea0":"def updated_clean_doc(doc,vocab):\n    \n    table = str.maketrans(dict.fromkeys(string.punctuation))\n    doc =  doc.translate(table)\n    doc = doc.split()\n    token = [word for word in doc   if word.isalpha()]\n    token = [word for word in token if word not in stop_words] \n    token = [word for word in token if len(word)>1]\n    token = [word for word in token if word in vocab]\n    return token ","fbbbf3ac":"def updated_process_doc(directory,vocab):\n    documents = list()\n    for filename in os.listdir(directory):\n        \n        doc =  load_doc(os.path.join(directory,filename))\n        token = updated_clean_doc(doc,vocab)\n        lines = ' '.join(token)\n        documents.append(lines)\n    return documents\n        ","37e90550":"path = '\/kaggle\/input\/movie-review-polarity\/txt_sentoken\/'\npos =  updated_process_doc(path+'pos',vocab)\nneg =  updated_process_doc(path+'neg',vocab)","60af8a2a":"document = pos+ neg \nlabels = [1]* len(pos ) + [0]*len(neg)\n\nassert len(labels) == len(pos)+len(pos)","8f567773":"def create_tokenizer(doc):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(doc)\n    return tokenizer","96b7288f":"def create_encoding(doc,tokenizer,length):\n    tokens = tokenizer.texts_to_sequences(doc)\n    padded = pad_sequences(tokens,length,padding='post')\n    return padded","9aabe3e1":"max_length = max([len(i.split()) for i in document])\nmax_length","f1ab8f36":"tokenizer = create_tokenizer(document)\npadded = create_encoding(document,tokenizer,max_length)","1bb43e48":"padded = np.array(padded)\nlabels = np.array(labels)","5cc7efbd":"vocab_size = len(tokenizer.word_index) +1","83c03ee9":"def define_model(vocab_size,max_length):\n\n    model = Sequential() \n    model.add(Embedding(vocab_size,100,input_length=max_length))\n\n    model.add(Conv1D(32,kernel_size=8,activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n\n    model.add(Flatten())\n\n    model.add(Dense(10,activation='relu'))\n\n    model.add(Dense(1,activation='sigmoid'))\n\n    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\n    model.summary() \n    plot_model(model,to_file='model.png',show_shapes=True)\n    return model","c72126d6":"os.environ[\"KMP_SETTINGS\"] = \"false\"","210d8cd3":"model = define_model(vocab_size,max_length)","841e0ce8":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nmodel.fit(padded,labels,epochs=10,validation_split=0.3)","3857b091":"model.save('model.h5')","7dd5f3cd":"def predict_sentiment(review,vocab,tokenizer,max_length,model):\n    \n    line = updated_clean_doc(review,vocab)\n    padded = create_encoding([line],tokenizer,max_length)\n    \n    yhat = model.predict(padded)\n    percent_pos = yhat[0,0]\n    if round(percent_pos) == 0:\n        return (1-percent_pos), 'NEGATIVE' \n    return percent_pos, 'POSITIVE'","99e44755":"test_file = '\/kaggle\/input\/movie-review-polarity\/txt_sentoken\/neg\/cv001_19502.txt'","32ce7893":"test_doc = load_doc(test_file)\nloaded_model = load_model('model.h5')\npredict_sentiment(test_doc,vocab,tokenizer,max_length,loaded_model)","4379fea1":"Save model parameters","f18de7fe":"# abc","be7083ec":"1. Movie Review Datset \n2. Data Preparation \n3. Trian CNN with Embedding Layer \n4. Evaluate Model ","d24555c9":"Define Model","00667e04":"Data Preparation \n* Load and clean reviews","420183a2":"Movie Review Data "}}