{"cell_type":{"dcf09383":"code","94372afa":"code","1bd8f54d":"code","a5303de4":"code","f1f5ed90":"code","c2590d15":"code","dce46b66":"code","a6e0fae2":"code","044ca305":"code","86ed4478":"code","110655fc":"code","4d55463a":"code","9dc88396":"code","5508821c":"markdown","fad05568":"markdown","b9a2f20d":"markdown","a5c551e5":"markdown","f98135be":"markdown","442eb2df":"markdown","9d17a2a0":"markdown","5cd1c206":"markdown","728b7dae":"markdown","f84b3fcd":"markdown","699c1623":"markdown","70725d79":"markdown","66239379":"markdown","cfada7a1":"markdown","c652f644":"markdown","10a76612":"markdown","39fbb66d":"markdown"},"source":{"dcf09383":"import torch\nfrom torch import nn, optim\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import transforms\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nimport time\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","94372afa":"class Inception(nn.Module):\n    # c1 - c4 \u4e3a\u6bcf\u6761\u7ebf\u8def\u91cc\u7684\u5c42\u7684\u8f93\u51fa\u901a\u9053\u6570\n    def __init__(self, in_c, c1, c2, c3, c4):\n        super(Inception, self).__init__()\n        # \u7ebf\u8def1\uff0c\u53551x1\u5377\u79ef\u5c42\n        self.p1_1 = nn.Conv2d(in_c, c1, kernel_size=1)\n        # \u7ebf\u8def2\uff0c1x1\u5377\u79ef\u540e\u63a53x3\u5377\u79ef\n        self.p2_1 = nn.Conv2d(in_c, c2[0], kernel_size=1)\n        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n        # \u7ebf\u8def3\uff0c1x1\u5377\u79ef\u540e\u63a55x5\u5377\u79ef\n        self.p3_1 = nn.Conv2d(in_c, c3[0], kernel_size=1)\n        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n        # \u7ebf\u8def4\uff0c3x3\u6700\u5927\u6c60\u5316\u540e\u63a51x1\u5377\u79ef\n        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n        self.p4_2 = nn.Conv2d(in_c, c4, kernel_size=1)\n        \n    def forward(self, x):\n        p1 = F.relu(self.p1_1(x))\n        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))\n        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))\n        p4 = F.relu(self.p4_2(self.p4_1(x)))\n        return torch.cat((p1, p2, p3, p4), dim=1)   # \u5728\u901a\u9053\u7ef4\u4e0a\u8fde\u7ed3\u8f93\u51fa","1bd8f54d":"class FlattenLayer(nn.Module):\n    def __init__(self):\n        super(FlattenLayer, self).__init__()\n    def forward(self, x): # x shape: (batch, *, *, ...)\n        return x.view(x.shape[0], -1)\n\nclass GlobalAvgPool2d(nn.Module):      # Global\u7684\u610f\u601d\u5c31\u662f\u7a97\u53e3\u5f62\u72b6\u7b49\u4e8e\u8f93\u5165\u7a7a\u95f4\u7ef4\u7684\u5f62\u72b6\uff08\u94fa\u6ee1\uff09\n     # \u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\u53ef\u901a\u8fc7\u5c06\u6c60\u5316\u7a97\u53e3\u5f62\u72b6\u8bbe\u7f6e\u6210\u8f93\u5165\u7684\u9ad8\u548c\u5bbd\u5b9e\u73b0\n        def __init__(self):\n            super(GlobalAvgPool2d, self).__init__()\n        \n        def forward(self, x):\n            return F.avg_pool2d(x, kernel_size=x.shape[2:])","a5303de4":"b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n                   nn.ReLU(),\n                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n                  )","f1f5ed90":"b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1),\n                   nn.Conv2d(64, 192, kernel_size=3, padding=1),\n                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n                  )","c2590d15":"b3 = nn.Sequential(Inception(192, 64, (96, 128), (16, 32), 32),\n                   Inception(256, 128, (128, 192), (32, 96), 64),\n                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n                  )","dce46b66":"b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n                   Inception(512, 160, (112, 224), (24, 64), 64),\n                   Inception(512, 128, (128, 256), (24, 64), 64),\n                   Inception(512, 112, (144, 288), (32, 64), 64),\n                   Inception(528, 256, (160, 320), (32, 128), 128),\n                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))","a6e0fae2":"b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n                   Inception(832, 384, (192, 384), (48, 128), 128),\n                   GlobalAvgPool2d())\nnet = nn.Sequential(b1, b2, b3, b4, b5, FlattenLayer(), nn.Linear(1024, 10))","044ca305":"net = nn.Sequential(b1, b2, b3, b4, b5, FlattenLayer(), nn.Linear(1024, 10))\nX = torch.rand(1, 1, 96, 96)\nfor blk in net.children(): \n    X = blk(X)\n    print('output shape: ', X.shape)","86ed4478":"# \u6ce8\uff1a\u6b64\u7248\u672c\u7528\u5230\u4e86PIL\u5e93\uff0c\u5229\u7528\u63d2\u503c\u5c06\u56fe\u50cf\u653e\u5927\u4e86\uff01\nclass MyFashionMnistDataset(Dataset):\n    def __init__(self, train=True, transform=None):\n        super(MyFashionMnistDataset, self).__init__()\n        if train == True:\n            self.csv_data = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\n        else:\n            self.csv_data = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')\n        self.labels = torch.tensor(self.csv_data.label.values)\n        self.data = self.csv_data.iloc[:, 1:].values.reshape((-1, 28, 28)).astype('uint8')  # pd\u8f6cnumpy\n        self.transform = transform\n    \n    def __getitem__(self, index):       # \u8fd9\u4e2a\u65b9\u6cd5\u662f\u5fc5\u987b\u8981\u6709\u7684\uff0c\u7528\u4e8e\u6309\u7167\u7d22\u5f15\u8bfb\u53d6\u6bcf\u4e2a\u5143\u7d20\u7684\u5177\u4f53\u5185\u5bb9\n        img = Image.fromarray(self.data[index], 'L')    # numpy\u8f6cpillow img\n        tag = self.labels[index]\n        if(self.transform is not None):\n            data_tensor = self.transform(img)\n        return data_tensor, tag     # return\u5f88\u5173\u952e\uff0creturn\u56de\u54ea\u4e9b\u5185\u5bb9\uff0c\u90a3\u4e48\u6211\u4eec\u5728\u8bad\u7ec3\u65f6\u5faa\u73af\u8bfb\u53d6\u6bcf\u4e2abatch\u65f6\uff0c\u5c31\u80fd\u83b7\u5f97\u54ea\u4e9b\u5185\u5bb9!\n        \n    def __len__(self):                  # \u8fd9\u4e2a\u51fd\u6570\u4e5f\u5fc5\u987b\u8981\u5199\uff0c\u5b83\u8fd4\u56de\u7684\u662f\u6570\u636e\u96c6\u7684\u957f\u5ea6\n        return len(self.data)\n\ndef get_fashion_mnist_dataset(batch_size, resize, num_workers=0):\n    trans = []\n    if resize:\n        trans.append(transforms.Resize(size=resize))\n    trans.append(transforms.ToTensor())\n    transform = transforms.Compose(trans)\n\n    train_dataset = MyFashionMnistDataset(train=True, transform=transform)\n    test_dataset = MyFashionMnistDataset(train=False, transform=transform)\n    \n    train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n    test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    \n    return train_iter, test_iter","110655fc":"def evaluate_accuracy(data_iter, net, device=None):\n    if device is None and isinstance(net, torch.nn.Module):\n        # \u5982\u679c\u6ca1\u6307\u5b9adevice\u5c31\u4f7f\u7528net\u7684device\n        device = list(net.parameters())[0].device\n    acc_sum, n = 0.0, 0\n    with torch.no_grad():\n        for X, y in data_iter:\n            if isinstance(net, torch.nn.Module):\n                net.eval() # \u8bc4\u4f30\u6a21\u5f0f, \u8fd9\u4f1a\u5173\u95eddropout\n                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n                net.train() # \u6539\u56de\u8bad\u7ec3\u6a21\u5f0f\n            else: # \u81ea\u5b9a\u4e49\u7684\u6a21\u578b, 3.13\u8282\u4e4b\u540e\u4e0d\u4f1a\u7528\u5230, \u4e0d\u8003\u8651GPU\n                if('is_training' in net.__code__.co_varnames): # \u5982\u679c\u6709is_training\u8fd9\u4e2a\u53c2\u6570\n                    # \u5c06is_training\u8bbe\u7f6e\u6210False\n                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n                else:\n                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n            n += y.shape[0]\n    return acc_sum \/ n\n\ndef train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n    net = net.to(device)\n    print(\"training on \", device)\n    loss = torch.nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n        bar = tqdm(train_iter)\n        for X, y in bar:\n            bar.set_description(f\"epoch {epoch + 1}\")\n            X = X.to(device)\n            y = y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n            train_l_sum += l.cpu().item()\n            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n            n += y.shape[0]\n            batch_count += 1\n        test_acc = evaluate_accuracy(test_iter, net)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n              % (epoch + 1, train_l_sum \/ batch_count, train_acc_sum \/ n, test_acc, time.time() - start))","4d55463a":"batch_size = 128\ntrain_iter, test_iter = get_fashion_mnist_dataset(batch_size, resize=96)","9dc88396":"lr, num_epochs = 0.001, 5\noptimizer = torch.optim.Adam(net.parameters(), lr=lr)\ntrain_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)","5508821c":"# 3. GooLeNet\u6a21\u578b","fad05568":"GoogLeNet\u4e2d\u7684\u57fa\u7840\u5377\u79ef\u5757\u53eb\u4f5cInception\u5757\uff0c\u5f97\u540d\u4e8e\u540c\u540d\u7535\u5f71\u300a\u76d7\u68a6\u7a7a\u95f4\u300b\uff08Inception\uff09\u3002\u4e0e\u4e0a\u4e00\u8282\u4ecb\u7ecd\u7684NiN\u5757\u76f8\u6bd4\uff0c\u8fd9\u4e2a\u57fa\u7840\u5757\u5728\u7ed3\u6784\u4e0a\u66f4\u52a0\u590d\u6742\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002","b9a2f20d":"# 4. \u83b7\u53d6\u6570\u636e\u548c\u8bad\u7ec3\u6a21\u578b","a5c551e5":"GoogLeNet\u8ddfVGG\u4e00\u6837\uff0c\u5728\u4e3b\u4f53\u5377\u79ef\u90e8\u5206\u4e2d\u4f7f\u75285\u4e2a\u6a21\u5757\uff08block\uff09\uff0c\u6bcf\u4e2a\u6a21\u5757\u4e4b\u95f4\u4f7f\u7528\u6b65\u5e45\u4e3a2\u76843\u00d73\u6700\u5927\u6c60\u5316\u5c42\u6765\u51cf\u5c0f\u8f93\u51fa\u9ad8\u5bbd\u3002\u7b2c\u4e00\u6a21\u5757\u4f7f\u7528\u4e00\u4e2a64\u901a\u9053\u76847\u00d77\u5377\u79ef\u5c42\u3002","f98135be":"# 1. GooLeNet\u80cc\u666f","442eb2df":"\u57282014\u5e74\u7684ImageNet\u56fe\u50cf\u8bc6\u522b\u6311\u6218\u8d5b\u4e2d\uff0c\u4e00\u4e2a\u540d\u53ebGoogLeNet\u7684\u7f51\u7edc\u7ed3\u6784\u5927\u653e\u5f02\u5f69 [1]\u3002\u5b83\u867d\u7136\u5728\u540d\u5b57\u4e0a\u5411LeNet\u81f4\u656c\uff0c\u4f46\u5728\u7f51\u7edc\u7ed3\u6784\u4e0a\u5df2\u7ecf\u5f88\u96be\u770b\u5230LeNet\u7684\u5f71\u5b50\u3002**GoogLeNet\u5438\u6536\u4e86NiN\u4e2d\u7f51\u7edc\u4e32\u8054\u7f51\u7edc\u7684\u601d\u60f3\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u505a\u4e86\u5f88\u5927\u6539\u8fdb\u3002**\u5728\u968f\u540e\u7684\u51e0\u5e74\u91cc\uff0c\u7814\u7a76\u4eba\u5458\u5bf9GoogLeNet\u8fdb\u884c\u4e86\u6570\u6b21\u6539\u8fdb\uff0c\u672c\u8282\u5c06\u4ecb\u7ecd\u8fd9\u4e2a\u6a21\u578b\u7cfb\u5217\u7684\u7b2c\u4e00\u4e2a\u7248\u672c\u3002","9d17a2a0":"\u7b2c\u4e09\u6a21\u5757\u4e32\u80542\u4e2a\u5b8c\u6574\u7684Inception\u5757\uff0c\u7b2c\u4e00\u4e2aInception\u5757\u7684\u8f93\u51fa\u901a\u9053\u6570\u4e3a64+128+32+32 = 256\uff0c\u7b2c\u4e8c\u4e2aInception\u5757\u7684\u8f93\u51fa\u901a\u9053\u6570\u662f128+192+96+64=480","5cd1c206":"# 5. \u5c0f\u7ed3","728b7dae":"\u7b2c\u4e94\u6a21\u5757\u6709\u4e24\u4e2aInception\u5757\u3002**\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u7b2c\u4e94\u6a21\u5757\u7684\u540e\u9762\u7d27\u8ddf\u8f93\u51fa\u5c42\uff0c\u8be5\u6a21\u5757\u540cNiN\u4e00\u6837\u4f7f\u7528\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5c42\u6765\u5c06\u6bcf\u4e2a\u901a\u9053\u7684\u9ad8\u548c\u5bbd\u53d8\u62101\u3002\u6700\u540e\u6211\u4eec\u5c06\u8f93\u51fa\u53d8\u6210\u4e8c\u7ef4\u6570\u7ec4\u540e\u63a5\u4e0a\u4e00\u4e2a\u8f93\u51fa\u4e2a\u6570\u4e3a\u6807\u7b7e\u7c7b\u522b\u6570\u7684\u5168\u8fde\u63a5\u5c42\u3002**","f84b3fcd":"# 2. Inception\u5757","699c1623":"\u7531\u56fe5.8\u53ef\u4ee5\u770b\u51fa\uff0cInception\u5757\u91cc\u67094\u6761\u5e76\u884c\u7684\u7ebf\u8def\u3002\u524d3\u6761\u7ebf\u8def\u4f7f\u7528\u7a97\u53e3\u5927\u5c0f\u5206\u522b\u662f1\u00d71\u30013\u00d73\u548c5\u00d75\u7684\u5377\u79ef\u5c42\u6765\u62bd\u53d6\u4e0d\u540c\u7a7a\u95f4\u5c3a\u5bf8\u4e0b\u7684\u4fe1\u606f\uff0c\u5176\u4e2d\u4e2d\u95f42\u4e2a\u7ebf\u8def\u4f1a**\u5bf9\u8f93\u5165\u5148\u505a1\u00d71\u5377\u79ef\u6765\u51cf\u5c11\u8f93\u5165\u901a\u9053\u6570\uff0c\u4ee5\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u3002**\u7b2c\u56db\u6761\u7ebf\u8def\u5219\u4f7f\u75283\u00d73\u6700\u5927\u6c60\u5316\u5c42\uff0c\u540e\u63a51\u00d71\u5377\u79ef\u5c42\u6765\u6539\u53d8\u901a\u9053\u6570\u3002**4\u6761\u7ebf\u8def\u90fd\u4f7f\u7528\u4e86\u5408\u9002\u7684\u586b\u5145\u6765\u4f7f\u8f93\u5165\u4e0e\u8f93\u51fa\u7684\u9ad8\u548c\u5bbd\u4e00\u81f4\u3002\u6700\u540e\u6211\u4eec\u5c06\u6bcf\u6761\u7ebf\u8def\u7684\u8f93\u51fa\u5728\u901a\u9053\u7ef4\u4e0a\u8fde\u7ed3\uff0c\u5e76\u8f93\u5165\u63a5\u4e0b\u6765\u7684\u5c42\u4e2d\u53bb\u3002**","70725d79":"\u7b2c\u4e8c\u6a21\u5757\u4f7f\u75282\u4e2a\u5377\u79ef\u5c42\uff1a\u9996\u5148\u662f64\u901a\u9053\u76841\u00d71\u5377\u79ef\u5c42\uff0c\u7136\u540e\u662f\u5c06\u901a\u9053\u589e\u59273\u500d\u76843\u00d73\u5377\u79ef\u5c42\u3002\u5b83\u5bf9\u5e94Inception\u5757\u4e2d\u7684\u7b2c\u4e8c\u6761\u7ebf\u8def\u3002","66239379":"GoogLeNet\u6a21\u578b\u7684\u8ba1\u7b97\u590d\u6742\uff0c\u800c\u4e14\u4e0d\u5982VGG\u90a3\u6837\u4fbf\u4e8e\u4fee\u6539\u901a\u9053\u6570\u3002**\u672c\u8282\u91cc\u6211\u4eec\u5c06\u8f93\u5165\u7684\u9ad8\u548c\u5bbd\u4ece224\u964d\u523096\u6765\u7b80\u5316\u8ba1\u7b97**\u3002\u4e0b\u9762\u6f14\u793a\u5404\u4e2a\u6a21\u5757\u4e4b\u95f4\u7684\u8f93\u51fa\u7684\u5f62\u72b6\u53d8\u5316\u3002","cfada7a1":"Inception\u5757\u4e2d\u53ef\u4ee5\u81ea\u5b9a\u4e49\u7684\u8d85\u53c2\u6570\u662f\u6bcf\u4e2a\u5c42\u7684\u8f93\u51fa\u901a\u9053\u6570\uff0c\u6211\u4eec\u4ee5\u6b64\u6765\u63a7\u5236\u6a21\u578b\u590d\u6742\u5ea6\u3002","c652f644":"\u7b2c\u56db\u6a21\u5757\u66f4\u52a0\u590d\u6742\u3002\u5b83\u4e32\u8054\u4e865\u4e2aInception\u5757\u3002\u8fd9\u4e9b\u7ebf\u8def\u7684\u901a\u9053\u6570\u5206\u914d\u548c\u7b2c\u4e09\u6a21\u5757\u4e2d\u7684\u7c7b\u4f3c\uff0c\u9996\u5148\u542b3\u00d73\u5377\u79ef\u5c42\u7684\u7b2c\u4e8c\u6761\u7ebf\u8def\u8f93\u51fa\u6700\u591a\u901a\u9053\uff0c\u5176\u6b21\u662f\u4ec5\u542b1\u00d71\u5377\u79ef\u5c42\u7684\u7b2c\u4e00\u6761\u7ebf\u8def\uff0c\u4e4b\u540e\u662f\u542b5\u00d75\u5377\u79ef\u5c42\u7684\u7b2c\u4e09\u6761\u7ebf\u8def\u548c\u542b3\u00d73\u6700\u5927\u6c60\u5316\u5c42\u7684\u7b2c\u56db\u6761\u7ebf\u8def\u3002\u5176\u4e2d\u7b2c\u4e8c\u3001\u7b2c\u4e09\u6761\u7ebf\u8def\u90fd\u4f1a\u5148\u6309\u6bd4\u4f8b\u51cf\u5c0f\u901a\u9053\u6570\u3002\u8fd9\u4e9b\u6bd4\u4f8b\u5728\u5404\u4e2aInception\u5757\u4e2d\u90fd\u7565\u6709\u4e0d\u540c\u3002","10a76612":"- Inception\u5757\u76f8\u5f53\u4e8e\u4e00\u4e2a\u67094\u6761\u7ebf\u8def\u7684\u5b50\u7f51\u7edc\u3002**\u5b83\u901a\u8fc7\u4e0d\u540c\u7a97\u53e3\u5f62\u72b6\u7684\u5377\u79ef\u5c42\u548c\u6700\u5927\u6c60\u5316\u5c42\u6765\u5e76\u884c\u62bd\u53d6\u4fe1\u606f\uff0c\u5e76\u4f7f\u75281\u00d71\u5377\u79ef\u5c42\u51cf\u5c11\u901a\u9053\u6570\u4ece\u800c\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\u3002**\n- GoogLeNet\u5c06\u591a\u4e2a\u8bbe\u8ba1\u7cbe\u7ec6\u7684Inception\u5757\u548c\u5176\u4ed6\u5c42\u4e32\u8054\u8d77\u6765\u3002**\u5176\u4e2dInception\u5757\u7684\u901a\u9053\u6570\u5206\u914d\u4e4b\u6bd4\u662f\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u901a\u8fc7\u5927\u91cf\u7684\u5b9e\u9a8c\u5f97\u6765\u7684\u3002**\n- GoogLeNet\u548c\u5b83\u7684\u540e\u7ee7\u8005\u4eec\u4e00\u5ea6\u662fImageNet\u4e0a\u6700\u9ad8\u6548\u7684\u6a21\u578b\u4e4b\u4e00\uff1a\u5728\u7c7b\u4f3c\u7684\u6d4b\u8bd5\u7cbe\u5ea6\u4e0b\uff0c\u5b83\u4eec\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u5f80\u5f80\u66f4\u4f4e\u3002","39fbb66d":"![image.png](attachment:image.png)"}}