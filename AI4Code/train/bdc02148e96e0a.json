{"cell_type":{"6c759fdd":"code","445c0792":"code","54d02881":"code","73a0cfc7":"code","bdd80d91":"code","d448a726":"code","2b5ed9b9":"code","20077b8e":"code","62bd707c":"code","2cbf2c1b":"code","0c846f1f":"code","012cc7f3":"code","b7ab2b27":"code","239e0d04":"code","832775a7":"code","a33c9b1a":"code","bdd5c88d":"code","29ad371a":"code","950c7484":"markdown","e39eafb2":"markdown","1b70c718":"markdown"},"source":{"6c759fdd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","445c0792":"#Importing Libraries\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU, PReLU, ELU\nfrom keras.layers import Dropout","54d02881":"#Importing dataset\n\ndataset = pd.read_csv(\"..\/input\/churn-modelling\/Churn_Modelling.csv\")","73a0cfc7":"dataset.head()","bdd80d91":"#Separating independent variables from dependent variables\n\nx = dataset.iloc[:, 3:-1].values\ny = dataset.iloc[:,-1].values","d448a726":"#Converting categorical data to numeric data\n\n#Getting dummy variables\ngeography = pd.get_dummies(dataset[\"Geography\"], drop_first = True).to_numpy()\ngender = pd.get_dummies(dataset[\"Gender\"], drop_first = True).to_numpy()\n\n#Adding the dummy variable columns to original dataset\nx = np.concatenate([x, geography, gender], axis = 1)\n\n#Deleting the extra categorical column from original dataset\nx = np.delete(x, [1,2], 1)","2b5ed9b9":"#Splitting dataset into traiing and test dataset\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 13)","20077b8e":"#Scalling columns of training and test dataset\n\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","62bd707c":"#Initializing ANN\n\nclassifier = Sequential()","2cbf2c1b":"#Add the input layer and the first hidden layer\n\nclassifier.add(Dense(units = 6, kernel_initializer =  \"he_uniform\", activation = \"relu\", input_dim = 11))","0c846f1f":"#Adding second hidden layer\n\nclassifier.add(Dense(units = 6, kernel_initializer = \"he_uniform\", activation = \"relu\"))","012cc7f3":"#Adding the output layer\n\nclassifier.add(Dense(units = 1, kernel_initializer = \"glorot_uniform\", activation = \"sigmoid\"))","b7ab2b27":"classifier.summary()","239e0d04":"#Compiling the ANN\n\nclassifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])","832775a7":"#Fitting the ANN to the Trainig set\n\nmodel_history = classifier.fit(x_train, y_train, validation_split = 0.33, batch_size = 10, epochs = 100)","a33c9b1a":"#Predicting Test set results\n\ny_pred = classifier.predict(x_test)\ny_pred = (y_pred>0.5)","bdd5c88d":"#Creating confusion matrix\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","29ad371a":"#Checking accuracy score\n\nscore = accuracy_score(y_test, y_pred)\nprint(score)","950c7484":"# **CHECKING ACCURACY OF THE MODEL**","e39eafb2":"# **CREATING AN ARTIFICIAL NEURAL NETWORK**","1b70c718":"# **PREPARING DATASET**"}}