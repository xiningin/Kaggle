{"cell_type":{"19e55296":"code","24782cda":"code","f145362c":"code","c67535bc":"code","47eeeb30":"code","9cb87ffa":"code","14e2336c":"code","cba5700f":"code","8ef314e6":"code","28eb8a76":"code","3407dad9":"code","d334ec5c":"code","afec2088":"code","b4a88b33":"code","35e54684":"code","cf5c93bb":"code","3242ea8b":"code","5384a393":"code","7fd8af52":"code","6e44f268":"code","819a53df":"code","6e433ce9":"code","e215f7c9":"code","9f45b32b":"code","db765da9":"code","ea72ee80":"code","f990864d":"markdown","3732a23b":"markdown","7c942b23":"markdown","928e909c":"markdown"},"source":{"19e55296":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt","24782cda":"print(os.listdir(\"..\/input\"))","f145362c":"Data = pd.read_csv(\"..\/input\/amazon_alexa.tsv\",sep='\\t')\nData.head()","c67535bc":"Data.groupby('rating').describe()","47eeeb30":"Data = Data[Data.rating!=5]\nData = Data[Data.rating!=4]","9cb87ffa":"Data.head()","14e2336c":"Data.shape","cba5700f":"Data[\"index\"] = range(0,409)\nData = Data.set_index(\"index\")\nData.head()","8ef314e6":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import word_tokenize","28eb8a76":"# It is a process of normalization\ntext2 = \"Kiss kissed kisses know knowing last lasting\"\nstemmer = PorterStemmer()\nNorm_Word= stemmer.stem(text2)\nTokens = text2.split()\n\" \".join(stemmer.stem(token) for token in Tokens)","3407dad9":"STOPWORDS = set(stopwords.words('english'))\ncorpus=[]\nfor i in range(0,409):\n    review = re.sub('[^a-zA-Z]', ' ', Data['verified_reviews'][i])\n    review = review.lower()\n    review = review.split()\n    stemmer = PorterStemmer()\n    review = [stemmer.stem(token) for token in review if not token in STOPWORDS]\n    #contain all words that are not in stopwords dictionary\n    review=' '.join(review)\n    corpus.append(review)\ncorpus","d334ec5c":"words = []\nfor i in range(0,len(corpus)):\n    words = words + (re.findall(r'\\w+', corpus[i]))# words cantain all the words in the dataset\nwords","afec2088":"from collections import Counter\nwords_counts = Counter(words)\nprint(words_counts)","b4a88b33":"most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)\nmost_common_words","35e54684":"most_commmom_wordList = []\nmost_commmom_CountList = []\nfor x, y in most_common_words:\n    most_commmom_wordList.append(x)\n    most_commmom_CountList.append(y)","cf5c93bb":"import seaborn as sns\nplt.figure(figsize=(20,18))\nplot = sns.barplot(np.arange(20), most_commmom_CountList[0:20])\nplt.ylabel('Word Count',fontsize=20)\nplt.xticks(np.arange(20), most_commmom_wordList[0:20], fontsize=20, rotation=40)\nplt.title('Most Common Word used in Bad Review.', fontsize=20)\nplt.show()","3242ea8b":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\ntexts = [\"good movie\",\n         \"not a good movie\",\n         \"did not like\",\n         \"I like it\",\n         \"good one\"]\ntfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\nfeatures = tfidf.fit_transform(texts)\ntfidf.get_feature_names()","5384a393":"Vectorize = TfidfVectorizer(analyzer='word',stop_words='english',ngram_range=(1, 2),min_df=2)\nX = Vectorize.fit_transform(corpus).toarray()\ny = Data['feedback']","7fd8af52":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score,roc_curve,auc","6e44f268":"x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)","819a53df":"model1 = RandomForestClassifier(n_estimators=200, max_features=\"auto\")\nmodel1.fit(x_train,y_train)","6e433ce9":"y_pred1 = model1.predict(x_test)\naccuracy1 = accuracy_score(y_test,y_pred1)\nprint(\"Accuracy for RandomForest:\\t\"+str(accuracy1))\nprint(\"Precision for RandomForest:\\t\"+str(precision_score(y_test,y_pred1)))\nprint(\"Recall for RandomForest:\\t\"+str(recall_score(y_test,y_pred1)))","e215f7c9":"model2 = GradientBoostingClassifier(learning_rate=1.5, verbose=1, max_features='auto')\nmodel2.fit(x_train,y_train)","9f45b32b":"y_pred2 = model2.predict(x_test)\naccuracy2 = accuracy_score(y_test,y_pred2)\nprint(\"Accuracy for GradientBoosting:\\t\"+str(accuracy2))\nprint(\"Precision for GradientBoosting:\\t\"+str(precision_score(y_test,y_pred2)))\nprint(\"Recall for GradientBoosting:\\t\"+str(recall_score(y_test,y_pred2)))","db765da9":"prob_1=model1.predict_proba(x_test)\nprob_1 = prob_1[:,1]# Probalility prediction for Rangomforest classifier\nprob_2=model2.predict_proba(x_test)\nprob_2 = prob_2[:,1]# Probalility prediction for GradientBoosting classifier","ea72ee80":"fpr1, tpr1, _ = roc_curve(y_test, prob_1)\nfpr2, tpr2, _ = roc_curve(y_test, prob_2)\nplt.figure(figsize=(14,12))\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr1, tpr1, label = 'AUC(Randomforest Classifier) = %0.3f' % auc(fpr1, tpr1))\nplt.plot(fpr2, tpr2, label = 'AUC(GradientBoosting Classifier) = %0.3f' % auc(fpr2, tpr2))\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","f990864d":"# It looks like there need to be a lot of improvement in the Audio system from both hardware and software perspective especially improvement in the audio Output system.","3732a23b":"## What porterStemmer actually does...","7c942b23":"## Lets try to classify and Analyze the bad reviews through out this dataset and lets see if we could soulve some problem....","928e909c":"\n\n##  Lets find the most commonly used words"}}