{"cell_type":{"77ae7b13":"code","eb4cb5bc":"code","d8749cf0":"code","236fa257":"code","4bf71cb2":"code","41bb1802":"code","5818623b":"code","79d2796e":"code","88b91413":"code","9568a27f":"code","f12fd7b7":"code","7e255bbb":"code","f3ceb59b":"code","9b51c59f":"code","a18f162a":"code","6d165001":"code","f7a7e8b1":"code","4d0155f8":"code","b1a00e86":"code","73b497d4":"code","ec7f7452":"code","c1f83375":"code","8c6626f3":"code","2de7425f":"code","0f55f295":"code","6e8e4669":"code","5ec478d9":"code","acbd4fe3":"code","c540a59f":"markdown","93454fda":"markdown","b8c45ad2":"markdown","66d69a99":"markdown","54ca5266":"markdown","fc026a33":"markdown","b32d9379":"markdown","de77d33c":"markdown"},"source":{"77ae7b13":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eb4cb5bc":"import seaborn as sns\nimport matplotlib.pyplot as plt","d8749cf0":"df = pd.read_csv('\/kaggle\/input\/ascvd-heart-risk\/heartRisk.csv')","236fa257":"df.info()","4bf71cb2":"df.head()","41bb1802":"df.isnull().sum()","5818623b":"plt.figure(figsize = (12,8))\nsns.heatmap(df.corr(), annot = True, cmap = 'Spectral')","79d2796e":"# near even split between smokers and nonsmokers\nsns.countplot(x = 'isSmoker', data = df)","88b91413":"# reasonable represenation of ages between 40 and 80 within dataset\nsns.displot(x = 'Age', data = df, bins = 40)","9568a27f":"# close to even split between male and female subjects\nsns.countplot(x = 'isMale', data = df)","f12fd7b7":"# data is slighlty more skewed towards the black population\nsns.countplot(x = 'isBlack', data = df)","7e255bbb":"# slightly more diabetics in dataset than non\nsns.countplot(x = 'isDiabetic', data = df)","f3ceb59b":"# even split between high and low blood presures.\nsns.countplot(x = 'isHypertensive', data = df)","9b51c59f":"# even range of blood pressures\nsns.displot(x = 'Systolic', data = df)","a18f162a":"# data slightly skewed towards lower cholesterols\nsns.displot(x = 'Cholesterol', data = df)","6d165001":"# data slightly skewed towards lower cholesterols\nsns.displot(x = 'HDL', data = df)","f7a7e8b1":"# positive skew corresponds to the false column in categorical data\ndf.skew()","4d0155f8":"# data split\n\nX = df.drop('Risk', axis = 1)\ny = df['Risk']","b1a00e86":"# train test split\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)","73b497d4":"# Linear Regression training\n\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_test)","ec7f7452":"# Linear Regression evaluation\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nlr_mae = mean_absolute_error(y_test, lr_pred)\nlr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\nlr_r2 = r2_score(y_test, lr_pred)\n\nprint(lr_mae, lr_rmse, lr_r2)","c1f83375":"# Decision Tree Regressor training\n\nfrom sklearn.tree import DecisionTreeRegressor\ndtr = DecisionTreeRegressor()\ndtr.fit(X_train, y_train)\ndtr_pred = dtr.predict(X_test)","8c6626f3":"#Decision tree evaluation\n\ndtr_mae = mean_absolute_error(y_test, dtr_pred)\ndtr_rmse = np.sqrt(mean_squared_error(y_test, dtr_pred))\ndtr_r2 = r2_score(y_test, dtr_pred)\n\nprint(dtr_mae, dtr_rmse, dtr_r2)","2de7425f":"# Random Forest training \n\nfrom sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(n_estimators=200)\nrfr.fit(X_train, y_train)\nrfr_pred = rfr.predict(X_test)","0f55f295":"#Random forest evaluation\n\nrfr_mae = mean_absolute_error(y_test, rfr_pred)\nrfr_rmse = np.sqrt(mean_squared_error(y_test, rfr_pred))\nrfr_r2 = r2_score(y_test, rfr_pred)\n\nprint(rfr_mae, rfr_rmse, rfr_r2)","6e8e4669":"# XGBoost Regressor training\n\nfrom xgboost import XGBRegressor\nxgbr = XGBRegressor()\nxgbr.fit(X_train, y_train)\nxgbr_pred = xgbr.predict(X_test)","5ec478d9":"#XGBoost Regressor evaluation \n\nxgbr_mae = mean_absolute_error(y_test, xgbr_pred)\nxgbr_rmse = np.sqrt(mean_squared_error(y_test, xgbr_pred))\nxgbr_r2 = r2_score(y_test, xgbr_pred)\n\nprint(xgbr_mae, xgbr_rmse, xgbr_r2)","acbd4fe3":"results = pd.DataFrame({'Model': ['Linear Regression', 'Decision Tree Regressor',\\\n                                 'Random Forest Regressor', 'XGBoost Regressor'], 'MAE' :\\\n                      [lr_mae, dtr_mae, rfr_mae, xgbr_mae], 'RMSE' :\\\n                        [lr_rmse, dtr_rmse, rfr_rmse, xgbr_rmse], 'r2':\\\n                        [lr_r2, dtr_r2, rfr_r2, xgbr_r2]})\n\nresults","c540a59f":"# Data is very clean and ready for EDA and training","93454fda":"# Data is clean, evenly distributed and not wildly scaled. We're ready for regression prediction of the risk.","b8c45ad2":"# training regression models","66d69a99":"# no strong correlations between features","54ca5266":"# Broad correlation searching","fc026a33":"# Correlations in order of greatest to least risk: Age, Systolic blood pressure, Diabetic, Smoker, High blood pressure, gender is male","b32d9379":"# XGBoost Regressor wins!","de77d33c":"# numerical data skew"}}