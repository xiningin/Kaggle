{"cell_type":{"a393596b":"code","bd0c4a4b":"code","e463f07d":"code","46eca9b4":"code","83e169ec":"code","01476e8f":"code","22545e46":"code","978e6d89":"code","c7242004":"code","96375848":"code","1e0c6d7d":"code","7272ea0d":"code","b056a63a":"code","9c710d2b":"code","a1a18208":"code","246515be":"code","f9c0abf9":"code","2b8a3b24":"code","0dd2031e":"code","a947f8f7":"code","9d39d7fe":"code","6f2ce63a":"code","91747faa":"code","75e03a96":"code","c7bc5b1d":"code","3e610465":"code","91a2918c":"code","10af0d0e":"code","908f12ca":"code","ea09d25d":"code","da3509d4":"code","0f2a640d":"markdown","1390be90":"markdown","5ce14ba1":"markdown","c9f080ba":"markdown","534f4db6":"markdown","6a1f3063":"markdown","78e8224e":"markdown","9eb1264b":"markdown","cc0c9482":"markdown","41eae389":"markdown","12edb30d":"markdown","a1f429c6":"markdown","d1b50003":"markdown","80bc796e":"markdown"},"source":{"a393596b":"#IMPORTING LIBRARIES  \nimport tensorflow as tf\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator","bd0c4a4b":"#train_data is used for feature scaling and image augmentation (image augmentation is applied to avoid overfitting).\ntrain_data = ImageDataGenerator(rescale = 1.\/255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n\n#defining training set, here size of image is reduced to 64x64, batch of images is kept as 64 and class is defined as 'binary'.\ntraining_set = train_data.flow_from_directory('..\/input\/cat-and-dog\/training_set\/training_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","e463f07d":"#!\/usr\/bin\/python                                                  \nfrom PIL import Image                                              \nimport os, sys                       \n\npath = \"..\/input\/cat-and-dog\/training_set\/training_set\"\ndirs = os.listdir( path )                                       \n\ndef resize():\n    for item in dirs:\n        if os.path.isfile(path+item):\n            im = Image.open(path+item)\n            f, e = os.path.splitext(path+item)\n            imResize = im.resize((200,100), Image.ANTIALIAS)\n            imResize.save(f+'.png', 'png', quality=80)\n\nresize()","46eca9b4":"#!\/usr\/bin\/python\nfrom PIL import Image\nimport os, sys, glob\n\npath = os.path.abspath(os.path.join('..', 'input'))\noutpath1 = os.path.abspath('.\/')\nprint(\"out path- \"+ outpath1)\nSOURCE_IMAGES1 = os.path.join(path, \"cat-and-dog\", \"training_set\")\nSOURCE_IMAGES2 = os.path.join(SOURCE_IMAGES1, \"training_set\")\nprint(\"input path- \"+ SOURCE_IMAGES2)\ndirs = os.listdir(SOURCE_IMAGES2)\ndef resize():\n    for item in dirs:\n        SOURCE_IMAGES = os.path.join(SOURCE_IMAGES2, item)\n        os.mkdir(os.path.join(item))\n        outpath2 = os.path.join(outpath1, item)\n        if os.listdir(SOURCE_IMAGES):\n            listOfFile = glob(os.path.join(SOURCE_IMAGES, \"*.jpg\"))\n            for file in listOfFile:\n                outpath = os.path.join(outpath2, item)\n                im = Image.open(os.path.join(SOURCE_IMAGES, file))\n                f, e = os.path.splitext(SOURCE_IMAGES)\n                imResize = im.resize((200,200), Image.ANTIALIAS)\n                os.remove(os.path.join(outpath, file))\n                imResize.save( os.path.join(outpath, file), 'JPEG', quality=90)\n\nresize()","83e169ec":"#applying same scale as training set, but only feature scaling is applied. image augmentation is avoided to prevent leakage of testing data.\ntest_data = ImageDataGenerator(rescale = 1.\/255)\n\n#defining testing set\ntesting_set = test_data.flow_from_directory('..\/input\/cat-and-dog\/test_set\/test_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","01476e8f":"data_dir ='..\/input\/cat-and-dog\/test_set\/test_set' \nimage  = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(224, 224),\n  batch_size=64)","22545e46":"#defining the CNN as a sequence of layers.\ncnn = tf.keras.models.Sequential()","978e6d89":"#adding 1st Convolutional layer\n#note that in image augmentation we kept the image size as 64x64, therefore input_shape should also be same [64,64,3] (here 3 signifies that this is a colorful image (R,G,B))\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, input_shape = [64,64,3],activation = 'relu'))\n#activation function relu is applied to decrease any linearity that might have arrised while applying filters.","c7242004":"# applying max pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","96375848":"#adding 2nd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","1e0c6d7d":"#adding 3rd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","7272ea0d":"#the input of step 4 is an flattened array,\ncnn.add(tf.keras.layers.Flatten())","b056a63a":"#forming an ann with 128 input neurons\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))","9c710d2b":"#adding ouput layer of the ann\ncnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))","a1a18208":"#compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","246515be":"#training the model\ncnn.fit(x = training_set, validation_data = testing_set, epochs = 25)","f9c0abf9":"cnn.save('catdog_cnn_model.h5')","2b8a3b24":"from keras.models import load_model \nclassifier = load_model('catdog_cnn_model.h5')","0dd2031e":"import numpy as np\nfrom keras.preprocessing import image\ntraining_set.class_indices","a947f8f7":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg')","9d39d7fe":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","6f2ce63a":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4021.jpg')","91747faa":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4021.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","75e03a96":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4036.jpg')","c7bc5b1d":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4036.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","3e610465":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg')","91a2918c":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","10af0d0e":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4022.jpg')","908f12ca":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4022.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","ea09d25d":"image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4054.jpg')","da3509d4":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4054.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","0f2a640d":"# **PREDICTING VALUES**","1390be90":"**STEP - 4 ) FULL CONNECTION**","5ce14ba1":"**0 MEANS CATS AND 1 MEANS DOGS**","c9f080ba":"**IT'S A CAT**","534f4db6":"**STEP - 2) APPLYING MAX POOLING**","6a1f3063":"**IT'S A DOG**","78e8224e":"# Sequential model: It allows us to create a deep learning model by adding layers to it","9eb1264b":"# class_mode = \"binary\" or \"sparse\" it must include the given y_col column with class values as strings\n# y_col = string or list, column\/s in dataframe that has the target data\n# horizontal_flip = Boolean. Randomly flip inputs horizontally\n# zoom_range = Float or [lower, upper]. Range for random zoom\n# shear_range = Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)","cc0c9482":"**CLASSIFYING WHETHER THEIR IS A DOG OR A CAT IN A PICTURE USING CNN.**","41eae389":"# HERE CNN IS DIVIDED INTO 4 STEPS\n**1. CONVOLUTION**\n\n**2. POOLING**\n\n**3. FLATTENING**\n\n**4. FULL CONNECTION**","12edb30d":"# #Generate batches of tensor image data with real-time data augmentation","a1f429c6":"**STEP - 1) ADDING CONVOLUTIONAL LAYER**","d1b50003":"# A convolution is an integral that expresses the amount of overlap of one function as it is shifted over another function\n# A convolutional neural network consists of an input layer, hidden layers and an output layer\n# Max pooling is a pooling operation that selects the maximum element from the region of the feature map covered by the filter\n# Flattening a tensor means to remove all of the dimensions except for one\n# Full Connection acts as a \"classifier\" throughout the convolutional neural network","80bc796e":"**STEP -3 ) FLATTENING**"}}