{"cell_type":{"71c703da":"code","2ddb317a":"code","8a2032c8":"code","7e79b952":"code","e3067b05":"code","c5620ba4":"code","e77d419e":"code","8cc9b704":"code","1838f47a":"code","32a13632":"code","3ffed35b":"code","1dd97e6e":"code","811400cd":"code","95294fc5":"code","77b4067c":"code","f294e076":"code","c49e1ffa":"code","4bd8dcf1":"code","ce1b51ed":"code","402ca50d":"code","8979d576":"code","12b4dc87":"code","f08d0248":"code","bb82cc11":"code","8f4a14c7":"code","f0d2fff6":"code","af03e5b8":"code","1032a8c7":"code","3eec164c":"code","b5cd71f4":"code","aa7cfd4c":"code","5e5891ea":"code","e7a32cb6":"code","edb7aeba":"code","45deedec":"code","99950dcd":"markdown","761d6346":"markdown","e5ac9562":"markdown","c2bbb3ac":"markdown","47864021":"markdown","7ebf1e99":"markdown","0ad198be":"markdown","eb086e1f":"markdown","de3d9d72":"markdown","080c0b4b":"markdown","42a2bb61":"markdown","15ba5ee5":"markdown"},"source":{"71c703da":"# importing necessary tools\nimport datetime\nimport os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPool2D\n\nimport tensorflow as tf\nprint(\"TF version: \", tf.__version__)","2ddb317a":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"No\")\nelse:\n    print(device_name)","8a2032c8":"print(tf.test.is_gpu_available())","7e79b952":"train_df = pd.read_csv('\/kaggle\/input\/gtsrb-german-traffic-sign\/Train.csv')\ntrain_df.describe()","e3067b05":"train_df = train_df.drop(['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2'], axis = 1)\ntrain_df.head()","c5620ba4":"train_df['ClassId'].value_counts().plot.bar(figsize=(20, 10))\ntrain_df['ClassId'].value_counts().median()","e77d419e":"# Create pathnames from image Id's\nfilenames = ['\/kaggle\/input\/gtsrb-german-traffic-sign\/' + fname for fname in train_df['Path']]\nfilenames[:10]","8cc9b704":"labels = train_df['ClassId'].to_numpy()\nlabels","1838f47a":"unique_signs = np.unique(labels)\nlen(unique_signs)","32a13632":"# Converting the labels into one hot encoding\nlabels = tf.keras.utils.to_categorical(labels, 43)\nlabels[0]","3ffed35b":"len(labels)","1dd97e6e":"# Create X & y variables\nX = filenames\ny = labels\n\n# Splitting our data into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)\nlen(X_train), len(y_train), len(X_val), len(y_val)","811400cd":"IMG_SIZE = 32\n\ndef process_image(image_path):\n    \"\"\"\n    Takes an image file path and turns the image into a Tensor.\n    \"\"\"\n    # Read in an image file\n    image = tf.io.read_file(image_path)\n    # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n    image = tf.image.decode_png(image, channels=3)\n    # Convert the colour channel values from 0-255 to 0-1 values\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    # Resize the image to our desired value (32, 32)\n    image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n    return image","95294fc5":"# Create a simple function to return tuple\ndef get_image_label (image_path, label):\n    \"\"\"\n    Takes an image file path name and the assosciated label,\n    processes the image and reutrns a typle of (image, label).\n    \"\"\"\n    image = process_image(image_path)\n    return image, label","77b4067c":"# Define batch size\nBATCH_SIZE = 64\n\n# Create a function to turn data into batches\ndef create_data_batches (X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n    \"\"\"\n    Creates batches of data out of image (X) and label (y) pairs.\n    Shuffles the data if it's training data but doesn't shuffle if it's validation dat\n    a.\n    Also accepts test data as input (no labels).\n    \"\"\"\n    # If the data is a test dataset, we probably don't have have labels\n    if test_data:\n        print(\"Creating test data batches...\")\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(X)))\n        data_batch = data.map(process_image).batch(BATCH_SIZE)\n    # If the data is a valid dataset, we don't need to shuffle it\n    elif valid_data:\n        print(\"Creating validation dataset batches...\")\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n        # Create (image, label) tuples (this also turns the iamge path into a preprocessed image)\n        data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n    else:\n        print(\"Creating training dataset batches...\")\n        # Turn filepaths and labels into Tensors\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n        # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n        data = data.shuffle(buffer_size=len(X))\n        # Create (image, label) tuples (this also turns the iamge path into a preprocessed image) and turning into batches\n        data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n    return data_batch","f294e076":"# Creating training and validation batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val, valid_data=True)","c49e1ffa":"# Check out the different attributes of our data batches\ntrain_data.element_spec, val_data.element_spec","4bd8dcf1":"# Create a function for viewing images in a data batch\ndef show_25_images (images, labels):\n    \"\"\"\n    Displays a plot of 25 images and their labels from a data batch.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    for i in range(25):\n        ax = plt.subplot(5, 5, i+1)\n        plt.imshow(images[i])\n        plt.title(unique_signs[labels[i].argmax()])\n        plt.axis(\"off\")","ce1b51ed":"# Visualizing traing batch\ntrain_images, train_labels = next(train_data.as_numpy_iterator())\nshow_25_images(train_images, train_labels)","402ca50d":"# Visualizing validation data\nval_images, val_labels = next(val_data.as_numpy_iterator())\nshow_25_images(val_images, val_labels)","8979d576":"# Setup input shape to the model\nINPUT_SHAPE = [IMG_SIZE, IMG_SIZE, 3]\n\n# Setup the output shape\nOUTPUT_SHAPE = len(unique_signs)","12b4dc87":"# Creating CNN Model\ndef traffic_sign_net(input_shape):\n    model = Sequential()\n    model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n    model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(rate=0.25))\n    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(rate=0.25))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(rate=0.5))\n    model.add(Dense(43, activation='softmax'))\n    return model","f08d0248":"# Create a function that creates model\ndef create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE):\n    # Setup the model layers\n    model = traffic_sign_net(input_shape=input_shape)\n    # Compile the model\n    print(\"Compiling the model\")\n    model.compile(\n        loss = tf.keras.losses.CategoricalCrossentropy(),\n        optimizer = tf.keras.optimizers.Adam(),\n        metrics = [\"accuracy\"]\n    )\n    return model","bb82cc11":"model = create_model()\nmodel.summary()","8f4a14c7":"# Create early stopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)","f0d2fff6":"NUM_EPOCHS = 30","af03e5b8":"# Build a fn to train and return a trained model\ndef train_model():\n    \"\"\"\n    Trains a given model and returns the trained version.\n    \"\"\"\n    # Create a model\n    model = create_model()\n    # Fit the model to the data passing it the callbacks we created\n    model.fit(x=train_data,\n        epochs=NUM_EPOCHS,\n        validation_data=val_data,\n        validation_freq=1,\n        callbacks=[early_stopping]\n             )\n    return model","1032a8c7":"# Fit the model to data\nmodel = train_model()","3eec164c":"test_df = pd.read_csv('\/kaggle\/input\/gtsrb-german-traffic-sign\/Test.csv')\ntest_df = test_df.drop(['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2'], axis=1)\ntest_df.head()","b5cd71f4":"test_img_paths = ['\/kaggle\/input\/gtsrb-german-traffic-sign\/' + path for path in test_df['Path']]\ntest_img_paths[:10]","aa7cfd4c":"X_test = create_data_batches(test_img_paths, test_data=True)\ny_test = list(test_df['ClassId'])\ny_test[:10]","5e5891ea":"predictions = model.predict(X_test, verbose=1)","e7a32cb6":"# Function to convert probabilities to labels\ndef get_pred_label(prediction_probabilities):\n    \"\"\"\n    Turns an array of prediction probabilities into a label.\n    \"\"\"\n    return unique_signs[np.argmax(prediction_probabilities)]","edb7aeba":"# Turning probabilities to labels\npred_labels = []\nfor i in predictions:\n    pred_labels.append(get_pred_label(i))\npred_labels[:10]","45deedec":"# Getting the accuracy of the model on test data\nacc = accuracy_score(y_test, pred_labels)\nacc","99950dcd":"## Getting our data ready (turning into tensors)","761d6346":"## Building the model","e5ac9562":"## Processing image and turning into Tensors","c2bbb3ac":"## Training our model","47864021":"### Turning data into batches","7ebf1e99":"## Visualizing Data Batches","0ad198be":"## Creating Early Stopping callback","eb086e1f":"## Making and Evaluating predictions using a trained model on test data","de3d9d72":"## Creating test dataset batches","080c0b4b":"## Creating Validation set","42a2bb61":"## Getting images and their labels","15ba5ee5":"## Get our workspace ready"}}