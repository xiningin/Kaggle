{"cell_type":{"d8f7970c":"code","d2ebe4b8":"code","7a8fad3f":"code","cea78cb3":"code","f3a5b15a":"code","a9679593":"code","6fc12da5":"code","ab803255":"code","10014bbb":"code","061ac794":"code","5673c8c3":"code","184be8da":"code","66da3d33":"code","2bd302c6":"code","114bda20":"code","410e8f40":"code","e80f2e7e":"code","f8dd952b":"code","648658e6":"markdown","5e5043c4":"markdown","d35f98ba":"markdown","dd7b7c66":"markdown","8a1ffa4c":"markdown"},"source":{"d8f7970c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d2ebe4b8":"import warnings\nimport matplotlib.pylab as plt\nimport PIL\nwarnings.filterwarnings('ignore')\nimage_size = 224","7a8fad3f":"# \uc774\ubbf8\uc9c0 \ud3f4\ub354 \uacbd\ub85c\nDATA_PATH = '..\/input\/'\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\n\n# CSV \ud30c\uc77c \uacbd\ub85c\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_train = df_train.iloc[:50] # \ud3b8\uc758\uc0c1 50\uac1c\uae4c\uc9c0\ub9cc \uc774\uc6a9 \ndf_train.head()","cea78cb3":"def crop_boxing_img(img_name, margin=16, size=(image_size, image_size)):\n    if img_name.split('_')[0] == 'train':\n        PATH = TRAIN_IMG_PATH\n        data = df_train\n    else:\n        PATH = TEST_IMG_PATH\n        data = df_test\n\n    img = PIL.Image.open(os.path.join(PATH, img_name))\n    pos = data.loc[data[\"img_file\"] == img_name, \\\n                   ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n\n    width, height = img.size\n    x1 = max(0, pos[0] - margin)\n    y1 = max(0, pos[1] - margin)\n    x2 = min(pos[2] + margin, width)\n    y2 = min(pos[3] + margin, height)\n\n    return img.crop((x1, y1, x2, y2)).resize(size)","f3a5b15a":"TRAIN_CROP_PATH = \".\/train_crop\"\n!mkdir {TRAIN_CROP_PATH}","a9679593":"# train_set\uc758 \ubaa8\ub4e0 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574 \uc801\uc6a9\ud560 \uacbd\uc6b0 \uc2dc\uac04\uc774 \uc880 \uac78\ub9bd\ub2c8\ub2e4.\nfor i, row in df_train.iterrows():\n    cropped = crop_boxing_img(row['img_file'])\n    cropped.save(f\"{TRAIN_CROP_PATH}\/{row['img_file']}\")","6fc12da5":"from sklearn.model_selection import train_test_split\n\ndf_train[\"class\"] = df_train[\"class\"].astype('str')\ndf_train = df_train[['img_file', 'class']]\n\nX_val = df_train.copy()\n# its = np.arange(df_train.shape[0])\n# train_idx, val_idx = train_test_split(its, test_size = 0.8, shuffle= False)\n# X_train = df_train.iloc[train_idx, :]\n# X_val = df_train.iloc[val_idx, :]\n\n# print(X_train.shape)\nprint(X_val.shape)","ab803255":"import keras \nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator","10014bbb":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nvalid_datagen = ImageDataGenerator(rescale=1.\/255) ","061ac794":"img_size = (image_size, image_size)\nbatch_size = 10\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe = X_val, \n    directory = TRAIN_CROP_PATH,\n    x_col = 'img_file',\n    y_col = 'class',\n    target_size = img_size,\n    color_mode ='rgb',\n    class_mode ='categorical',\n    batch_size =batch_size,\n    shuffle =False\n)\n\nvalidation_generator = valid_datagen.flow_from_dataframe(\n    dataframe = X_val, \n    directory = TRAIN_CROP_PATH,\n    x_col ='img_file',\n    y_col ='class',\n    target_size = img_size,\n    color_mode ='rgb',\n    class_mode ='categorical',\n    batch_size =batch_size,\n    shuffle =False\n)","5673c8c3":"# \uc544\ub798\uc640 \uac19\uc774 augmentation \ucc98\ub9ac\ub41c \uc774\ubbf8\uc9c0\ub4e4\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n\nfor data1, label1 in train_generator:\n    print('\ubc30\uce58 \ub370\uc774\ud130 \ud06c\uae30:', data1.shape)\n    print('\ubc30\uce58 \ub808\uc774\ube14 \ud06c\uae30:', label1.shape)\n    break\n    \nfor data2, label2 in validation_generator:\n    print('\ubc30\uce58 \ub370\uc774\ud130 \ud06c\uae30:', data2.shape)\n    print('\ubc30\uce58 \ub808\uc774\ube14 \ud06c\uae30:', label2.shape)\n    break    \n\n       ","184be8da":"# \uc67c\ucabd\uc740 \uc99d\uc2dd\ub41c(\ubcc0\ud615\ub41c)\uc774\ubbf8\uc9c0, \uc624\ub978\ucabd\uc740 \uae30\uc874 \uc774\ubbf8\uc9c0\uc785\ub2c8\ub2e4.\n\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\n\nfor i in range(4):   \n    fig, axs = plt.subplots(ncols=2, figsize=(8,4), sharex=True, sharey=True)\n    axs[0].imshow(image.array_to_img(data1[i]))\n    axs[1].imshow(image.array_to_img(data2[i]))\n    fig.tight_layout()\n    plt.show()\n","66da3d33":"# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\n# Only required if featurewise_center or featurewise_std_normalization or zca_whitening are set to True.\n# train_datagen.fit(train_features)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    featurewise_center= True,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    #rotation_range=40, # randomly rotate images in the range (degrees, 0 to 180)\n    #zoom_range = 0.2, # Randomly zoom image \n    #shear_range=0.2,\n    #width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n    #height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=True)  # randomly flip images\n\n# train_datagen.fit() # \uc774 \ubd80\ubd84\uc5d0\uc11c \uc2e4\ud589\ub418\uc9c0 \uc54a\ub294\ub2e4.\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe = X_val, \n    directory = TRAIN_CROP_PATH,\n    x_col = 'img_file',\n    y_col = 'class',\n    target_size = img_size,\n    color_mode ='rgb',\n    class_mode ='categorical',\n    batch_size =batch_size,\n    shuffle =False\n)\n\ntrain_generator.reset()\nvalidation_generator.reset()\n","2bd302c6":"from skimage.transform import warp, AffineTransform, ProjectiveTransform\nfrom skimage.exposure import equalize_adapthist, equalize_hist, rescale_intensity, adjust_gamma, adjust_log, adjust_sigmoid\nfrom skimage.filters import gaussian\nfrom skimage.util import random_noise\nimport random\n\ndef randRange(a, b):\n    return np.random.rand() * (b - a) + a\n\ndef randomIntensity(im):\n    # rescales the intesity of the image to random interval of image intensity distribution\n    return rescale_intensity(im,\n                             in_range=tuple(np.percentile(im, (randRange(0,10), randRange(90,100)))),\n                             out_range=tuple(np.percentile(im, (randRange(0,10), randRange(90,100)))))\n\ndef randomGamma(im):\n    # Gamma filter for contrast adjustment with random gamma value.\n    return adjust_gamma(im, gamma=randRange(1, 2.5))\n\ndef randomGaussian(im):\n    # Gaussian filter for bluring the image with random variance.\n    return gaussian(im, sigma=randRange(0, 5))\n\ndef randomNoise(im):\n    # random gaussian noise with random variance.\n    var = randRange(0.005, 0.01)\n    return random_noise(im, var=var)\n\n# \uc704 4\uac00\uc9c0 \ud568\uc218\ub97c \ub123\uc5b4 random\ud558\uac8c \uc801\uc6a9\uc2dc\ud0a8\ub2e4.\ndef augment(im, Steps= [randomGamma, randomGaussian, randomNoise]):\n    \n    im \/= 255. # \ucd94\uac00    \n    i= np.random.randint(3)\n    step = Steps[i]\n    im = step(im)\n    return im\n","114bda20":"# augment \ud568\uc218 \ub0b4\ubd80\uc801\uc73c\ub85c \uc2a4\ucf00\uc77c\ub9c1\uc744 \ud558\uae30 \ub54c\ubb38\uc5d0 rescale\uc744 \ube80\ub2e4.\ntrain_datagen = ImageDataGenerator(preprocessing_function=augment) \nvalid_datagen = ImageDataGenerator(rescale=1.\/255) \n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe = X_val, \n    directory = TRAIN_CROP_PATH,\n    x_col = 'img_file',\n    y_col = 'class',\n    target_size = img_size,\n    color_mode ='rgb',\n    class_mode ='categorical',\n    batch_size =batch_size,\n    shuffle =False\n)\n\ntrain_generator.reset()\nvalidation_generator.reset()\n","410e8f40":"for data1, label1 in train_generator:\n    print('\ubc30\uce58 \ub370\uc774\ud130 \ud06c\uae30:', data1.shape)\n    print('\ubc30\uce58 \ub808\uc774\ube14 \ud06c\uae30:', label1.shape)\n    break\n    \nfor data2, label2 in validation_generator:\n    print('\ubc30\uce58 \ub370\uc774\ud130 \ud06c\uae30:', data2.shape)\n    print('\ubc30\uce58 \ub808\uc774\ube14 \ud06c\uae30:', label2.shape)\n    break    ","e80f2e7e":"import matplotlib.pyplot as plt\nfrom keras.preprocessing import image\n\nfor i in range(8):   \n    fig, axs = plt.subplots(ncols=2, figsize=(8,4), sharex=True, sharey=True)\n    axs[0].imshow(image.array_to_img(data1[i]))\n    axs[1].imshow(image.array_to_img(data2[i]))\n    fig.tight_layout()\n    plt.show()\n\n","f8dd952b":"!rm -rf *_crop","648658e6":"```\n\uba3c\uc800 rotaion, shift, zoom, flip\uc5d0 \ub300\ud55c \ubcc0\ud615\uc744 \uc2e4\ud589\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \n\uac01 \uc778\uc790\ub4e4\uc5d0 \ub300\ud55c \uc0c1\uc138\ud55c \ub0b4\uc6a9\uc740 \uc544\ub798 \uc0ac\uc774\ud2b8\uc5d0\uc11c \uc0b4\ud3b4\ubcf4\uc2dc\uba74 \ub429\ub2c8\ub2e4.\nhttps:\/\/keras.io\/preprocessing\/image\/ \n\n\uadf8\ub9ac\uace0 \uc911\uc694\ud55c \uc0ac\ud56d\uc73c\ub85c rescaled\uc744 \uc774\uc6a9\ud558\uc5ec \uc774\ubbf8\uc9c0\uc758 \ud589\ub82c\uac12\uc744 0~255\uc5d0\uc11c 0~1\ub85c \ubcc0\uacbd\ud558\ub294 \ubd80\ubd84\uc785\ub2c8\ub2e4. \uc2e0\uacbd\ub9dd\ubaa8\ub378\uc5d0\uc11c\ub294 \ub370\uc774\ud130\uc758 \ud2b9\uc131\uc5d0 \ub300\ud574\uc11c \uc2a4\ucf00\uc77c\ub9c1\ud55c\ub2e4\uc74c \ud559\uc2b5\ud558\ub294 \uac83\uc774 \ub9e4\uc6b0 \uc911\uc694\ud569\ub2c8\ub2e4.\n```","5e5043c4":"```\nfeaturewise_center\nsamplewise_center\nfeaturewise_std_normalization\nsamplewise_std_normalization\nzca_whitening\n\n\ud574\ub2f9 \uc778\uc790\ub4e4\uc744 True\ub85c \ud65c\uc131\ud654\ud558\ub824\uba74 train_datagen.fit(train_x)\uc744 \ud574\uc918\uc57c\ud569\ub2c8\ub2e4.\n\ud558\uc9c0\ub9cc \uc5ec\uae30\uc11c\ub294 flow_from_dataframe\uc744 \uc774\uc6a9\ud558\uae30\ub54c\ubb38\uc5d0 (\uc774\ubbf8\uc9c0\uac00 \uc544\ub2cc \uacbd\ub85c\ub85c \uc811\uadfc) \uc544\ub798 \ucf54\ub4dc\uc640 \uac19\uc774 \ubc14\ub85c \uc124\uc815\ud558\uc9c0\ub294 \ubabb\ud569\ub2c8\ub2e4. \npreprocessing_function\uc744 \uc774\uc6a9\ud558\uc5ec \ub3d9\uc77c\ud55c \ud6a8\uacfc\ub97c \ub0b4\ub294 \ubcc4\ub3c4\uc758 \ud568\uc218\ub97c \ub9cc\ub4e4\uc5b4 \uc9c1\uc811 \uc774\ubbf8\uc9c0 \ucc98\ub9ac\ub97c \ud560\uc218 \ubc16\uc5d0 \uc5c6\uc2b5\ub2c8\ub2e4.\n\ud574\ub2f9 \uc778\uc790\ub4e4\uc758 \ud6a8\uacfc\ub294 \uc544\ub798 \uc0ac\uc774\ud2b8\uc5d0\uc11c \ud655\uc778\ubc14\ub78d\ub2c8\ub2e4.\nhttps:\/\/machinelearningmastery.com\/image-augmentation-deep-learning-keras\/\n```","d35f98ba":"# Image Augmentation examples \n\n---------------\n```\n\uc774\ubc88 \ucc28\uc885 \uc774\ubbf8\uc9c0 \ubd84\ub958 \ub300\ud68c\ub294 train set \uc774\ubbf8\uc9c0\uac00 10,000\uac1c, \ucc28\uc885 class\uac00 196\uac1c\ub85c class\ub2f9 \ub300\ub7b5 51\uac1c \uc815\ub3c4\uc758 \uc774\ubbf8\uc9c0\ub97c \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ub9e4\uc6b0 \uc791\uc740 \uc591\uc758 \uc774\ubbf8\uc9c0\ub85c \ud559\uc2b5\ub418\uae30 \ub54c\ubb38\uc5d0 \uacfc\ub300\uc801\ud569\uc744 \ud53c\ud558\uace0 \uc77c\ubc18\ud654\ub41c \uc131\ub2a5\uc744 \ub04c\uc5b4\ub0b4\uae30 \uc704\ud574\uc11c\ub294 Image Augmentation(\uc774\ubbf8\uc9c0 \uc99d\uc2dd)\uc740 \ud544\uc218\uc870\uac74\uc785\ub2c8\ub2e4.\nkeras\uc5d0\ub294 Image Augmentation\uc744 \uc704\ud55c ImageDataGenerator \ud568\uc218\uac00 \uc788\uc73c\uba70 \uc9c0\uae08\uae4c\uc9c0 \ucc3e\uc544\ubcf4\uace0 \uc2e4\uc2b5\ud55c \ub0b4\uc6a9\uc744 \uc815\ub9ac\ud574\uc11c \uc62c\ub9bd\ub2c8\ub2e4. \ud754\ud788 \uc0ac\uc6a9\ud558\ub294 rotate, shift, zoom, flip \ubfd0\ub9cc\uc544\ub2c8\ub77c \uc870\uae08 \ub354 \ub2e4\uc591\ud55c \ub178\uc774\uc988 \uc801\uc6a9\ubc29\uc2dd\uc744 \uad6c\ud604\ud574\ubcf4\uace0 \uc0d8\ud50c\uc744 \ud655\uc778\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. (\uae30\ubcf8\uc801\uc778 \uc774\ubbf8\uc9c0\ub85c\ub529 \uacfc\uc815\uacfc \ubf08\ub300\ub294 \uae30\uc874 \ucee4\ub110\ub4e4\uc744 \ucc38\uace0\ud558\uc600\uc2b5\ub2c8\ub2e4.)\n\n- \ucee4\ub110 \ucc38\uace0\n    - Daehun Gwak, Keras, How to use pretrained model?\n    - Jang, Car Model Classification (Xception)\n- Augmentation \ud568\uc218 \uad00\ub828\n    - https:\/\/keras.io\/preprocessing\/image\/\n    - https:\/\/www.kaggle.com\/safavieh\/image-augmentation-using-skimage\n    - https:\/\/www.kaggle.com\/gaborfodor\/augmentation-methods \n    - https:\/\/machinelearningmastery.com\/image-augmentation-deep-learning-keras\/\n```\n---------------\n ","dd7b7c66":"```\n\uc704 \uc0ac\uc9c4\uc744 \ubcf4\uba74 \ud544\ud130\uac12\uc774 \ub108\ubb34 \uc138\uc11c \uc544\uc608 \ubb49\uac1c\uc838\ubc84\ub9b0 \uacbd\uc6b0\ub3c4 \ubc1c\uc0dd\ud569\ub2c8\ub2e4. \n\ud574\ub2f9 \ud544\ud130\ud568\uc218\ub0b4 \ud30c\ub77c\uba54\ud0c0\uac12 \uc870\uc815\uc774 \ud544\uc694\ud574\ubcf4\uc785\ub2c8\ub2e4.\n\n\ucee4\ub110\ud558\ub098 \uc791\uc131\ud558\ub294\uac83\ub3c4 \uc2dc\uac04\uc774 \ub9cc\ub9cc\uce58\uc54a\uac8c \uc18c\uc694\ub418\ub124\uc694.\n\uc774\ubbf8\uc9c0 \uc0c9\uc0c1\ubcc0\uacbd (color noise) , Fancy PCA \n\uc640 \uac19\uc740 \ubcc0\ud615\uae30\ubc95\ub3c4 \uc788\ub294\ub370 \ucd94\ud6c4 \uc2dc\uac04\uc774 \ub418\uba74 \uc5c5\ub370\uc774\ud2b8\ud558\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\n```","8a1ffa4c":"```\n\ubcc4\ub3c4\ud568\uc218\ub97c \uad6c\uc131\ud558\uace0 preprocessing_function\ub97c \uc774\uc6a9\ud574 \ub178\uc774\uc988 \ud544\ud130\ub97c \uc801\uc6a9\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\uc774\ubbf8\uc9c0 \ucc98\ub9ac\ub97c \uc704\ud574 skimage\ub77c\ub294 \ud328\ud0a4\uc9c0\ub97c \uc774\uc6a9\ud558\uc600\uc73c\uba70 random\ud558\uac8c \ud544\ud130\uc758 \uc124\uc815\uac12\uc744 \uc801\uc6a9\ud569\ub2c8\ub2e4.\n\uc544\ub798\ucf54\ub4dc\ub294 https:\/\/www.kaggle.com\/safavieh\/image-augmentation-using-skimage \uc744 \ucc38\uace0\ud558\uc600\uc2b5\ub2c8\ub2e4.\n```"}}