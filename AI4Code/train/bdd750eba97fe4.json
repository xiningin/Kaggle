{"cell_type":{"556a1397":"code","b518d004":"code","c1c84cc0":"code","59efaa5a":"code","4012a7f2":"code","e1c5a485":"code","077729ca":"code","3bb19148":"code","9ff43c85":"code","c8832961":"code","7f1ecb74":"code","4356f23d":"code","a0fbda31":"code","adad3146":"code","937c0869":"code","ebe265de":"code","38337d59":"code","37698083":"code","49152220":"code","a6dc4b53":"markdown","9966dacf":"markdown"},"source":{"556a1397":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom tqdm import tqdm\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport matplotlib.pyplot as plt\n\nfrom fastai.basic_data import *\nfrom fastai.basic_train import Learner\nfrom fastai.train import fit_one_cycle\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b518d004":"%%time\ndf = pd.read_csv('..\/input\/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})","c1c84cc0":"print(df.shape)\ndf.head()","59efaa5a":"class RnnBasedLAN(nn.Module):\n    def __init__(self, D_in, H, layers=3, dropout=0.2, bidirectional=False):\n        super(RnnBasedLAN, self).__init__()\n        self.rnn = torch.nn.LSTM(\n            D_in,\n            H,\n            num_layers=layers,\n            batch_first=True,\n            dropout=dropout,\n        )\n        self.norm = nn.LayerNorm(H)\n        self.conv = nn.Conv2d(H, 1, 1)\n        \n    def forward(self, x):\n        \"\"\"x.shape = (batch_size, seq_len, features)\"\"\"\n        x, (h_n, c_n) = self.rnn(x)\n        x = self.norm(x)\n        x = x.transpose(1,2)\n        return self.conv(x[:,:,:,None]).squeeze()\n    \ndef test_rnn():\n    x = torch.rand(32,150,12)\n    mdl = RnnBasedLAN(12,16)\n    print(mdl(x).shape)\ntest_rnn()","4012a7f2":"def extract_features(z):\n    array = [z.mean(axis=1), z.min(axis=1), z.max(axis=1), z.std(axis=1), z.sum(axis=1), [len(z[i,np.abs(z[i,:]) > 500]) for i in range(z.shape[0])], \n             z.max(axis=1) - np.abs(z.min(axis=1)), np.quantile(z, 0.05,axis=1), ]\n    return np.c_[array].T.astype(np.float32)\n\nextract_features(np.random.rand(150,100))\n\n# For a given ending position \"last_index\", we split the last 150'000 values \n# of \"x\" into 150 pieces of length 1000 each. So n_steps * step_length should equal 150'000.\n# From each piece, a set features are extracted. This results in a feature matrix \n# of dimension (150 time steps x features).  \ndef create_X(x, last_index=None, n_steps=150, step_length=1000):\n    if last_index == None:\n        last_index=len(x)\n       \n    assert (last_index - (n_steps * step_length)) >= 0\n\n    # Reshaping and approximate standardization with mean 5 and std 3.\n    temp = (x[(last_index - n_steps * step_length):last_index].reshape(n_steps, -1) - 5 ) \/ 3\n    # Extracts features of sequences of full length 1000, of the last 100 values and finally also of the last 10 observations. \n    return np.c_[extract_features(temp),\n                 extract_features(temp[:, -step_length \/\/ 10:]),\n                 extract_features(temp[:, -step_length \/\/ 100:])].astype(np.float32)\n\n# Query \"create_X\" to figure out the number of features\nn_features = create_X(df.values, n_steps=10).shape[1]\nprint(\"This RNN model is based on %i features\"% n_features)","e1c5a485":"class LANL_Dataset(Dataset):\n    def __init__(\n        self,\n        df,\n        seq_len=150,\n        rand=False\n    ):\n        self.x =  df.loc[:,'acoustic_data'].values\n        self.y = df.loc[:,'time_to_failure'].values\n        self.seq_len = seq_len\n        self.rand = rand\n        \n    def __len__(self):\n        return int(self.x.shape[0]\/1000\/self.seq_len)-1\n        \n\n    def __getitem__(self, idx):\n        idx +=1\n        idx *= 150*1000\n        if self.rand:\n            idx += int(np.random.randn()*999)\n        sample = {\n            \"x\": create_X(self.x, last_index=idx, n_steps=self.seq_len, step_length=1000),\n            \"y\": self.y[np.arange(idx - self.seq_len*1000,idx,1000)],\n        }\n        \n\n        return sample['x'],sample['y'].astype(np.float32)\n    \nds = LANL_Dataset(df)\nfor i in tqdm(range(len(ds))):\n    dct = [o.shape for o in ds[i]]\nprint(dct)","077729ca":"idx = 150*1000*64\nprint(idx- 150*1000,idx)\nnp.arange(idx - 150*1000,idx,1000).shape","3bb19148":"def plot_sample(sample):    \n    plt.plot(sample[0])\n    print(sample[1])\n    plt.show()\nplot_sample(ds[0])\nsecond_earthquake = 50085877\nvalid_ds = LANL_Dataset(df.iloc[second_earthquake-150*1000*295:second_earthquake,:])\nresult = []\nfor i in range(len(valid_ds)):\n    result.append(valid_ds[i][1][-1])\nprint(result[0])\nplt.figure()\nplt.plot(result)","9ff43c85":"# between train and validation\nsecond_earthquake = 50085877\n\ntrain_dl = DataLoader(LANL_Dataset(df.iloc[:-150*1000*65,:],rand = True), batch_size= 64, num_workers=4)\nvalid_dl = DataLoader(LANL_Dataset(df.iloc[second_earthquake-150*1000*295:second_earthquake,:]), batch_size= 32, num_workers=2)\n\nloss = torch.nn.MSELoss()","c8832961":"def last_step_acc(preds, targs):\n    return torch.mean(torch.abs( preds[:,-1]-targs[:,-1]))","7f1ecb74":"data_bunch = DataBunch(train_dl, valid_dl)","4356f23d":"learn = Learner(data_bunch, RnnBasedLAN(24,32), loss_func=loss, metrics = [last_step_acc])","a0fbda31":"learn.fit_one_cycle(10,0.01)","adad3146":"learn.validate()","937c0869":"learn.recorder.plot_losses()","ebe265de":"mdl = learn.model","38337d59":"# Prepare submission\nsubmission = pd.read_csv('..\/input\/sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float32})\n\n# Load each test data, create the feature matrix, get numeric prediction\nfor i, seg_id in enumerate(tqdm(submission.index)):\n    seg = pd.read_csv('..\/input\/test\/' + seg_id + '.csv')\n    x = seg['acoustic_data'].values\n    x = torch.tensor(create_X(x))[None,:,:].to(torch.device('cuda'))\n    pred = mdl(x).cpu().detach().numpy()[0]\n    submission.time_to_failure[i] = pred\n","37698083":"submission.to_csv('submission.csv')","49152220":"submission.head()","a6dc4b53":"### Feature Extraction","9966dacf":"### Modeling - Recurrent Neural Network "}}