{"cell_type":{"78fb2663":"code","030f4578":"code","7918cfc8":"code","ad3477ab":"code","c9a0b0e2":"code","f620b517":"code","a12f3293":"code","bfdb8cb8":"code","6132cf32":"code","32361207":"code","d77a96fa":"code","cccb91c9":"code","89665674":"code","907e0789":"code","8f030f3f":"code","7a765267":"code","85f8251d":"code","24b279ca":"code","710543ce":"code","ed01bd03":"code","aea6e55e":"code","0f693dda":"code","4488a70f":"code","1f5e9460":"code","82c28e90":"code","59c26462":"code","221858f6":"code","702216bd":"code","2703c0aa":"code","0b8ee59b":"code","671045a6":"code","b0932f90":"code","a406cd19":"code","bb15f3d0":"code","c2750588":"code","68ed5d2a":"code","77c9cfe5":"code","b5642427":"code","0b0da18b":"code","9fa0d139":"code","1984df52":"code","0160f0e2":"code","f7f0f4b0":"code","9ccb5de7":"code","b5509a37":"code","4fa72489":"code","5ffd0f57":"code","6ce5f73b":"code","fdbfc1c2":"markdown","fdf8ea08":"markdown","85d33c00":"markdown","9a853b40":"markdown","78f7ca6f":"markdown","ed88463c":"markdown","c23be1d9":"markdown","3927c814":"markdown","48b54c2b":"markdown","5098afbd":"markdown","15a76201":"markdown","61d6f484":"markdown","81ccee48":"markdown","2b32d42d":"markdown","3c4ca7b5":"markdown","ed0ba36b":"markdown","e2b4a998":"markdown","bf6a6a46":"markdown","1509bd06":"markdown","735400d3":"markdown","f82e15d2":"markdown","6e39ab7d":"markdown","0c05e146":"markdown"},"source":{"78fb2663":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport numpy as np\nimport pandas as pd\nfrom textblob import TextBlob\nfrom nltk.corpus import wordnet\nimport seaborn as sns\nimport re\nimport nltk\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport plotly.express as px\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import LinearSVC ,SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n\nplt.style.use('fivethirtyeight')","030f4578":"#get the data\ndf =  pd.read_csv('..\/input\/cyberbullying-classification\/cyberbullying_tweets.csv')\n\n#show the top 5 data\ndf.head()","7918cfc8":"df.info()","ad3477ab":"stemmer = SnowballStemmer(\"english\")\nlematizer=WordNetLemmatizer()\n\nfrom wordcloud import STOPWORDS\nSTOPWORDS.update(['rt', 'mkr', 'didn', 'bc', 'n', 'm', \n                  'im', 'll', 'y', 've', 'u', 'ur', 'don', \n                  'p', 't', 's', 'aren', 'kp', 'o', 'kat', \n                  'de', 're', 'amp', 'will'])\n\ndef lower(text):\n    return text.lower()\n\ndef remove_hashtag(text):\n    return re.sub(\"#[A-Za-z0-9_]+\", ' ', text)\n\ndef remove_twitter(text):\n    return re.sub('@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+', ' ', text)\n\ndef remove_stopwords(text):\n    return \" \".join([word for word in \n                     str(text).split() if word not in STOPWORDS])\n\ndef stemming(text):\n    return \" \".join([stemmer.stem(word) for word in text.split()])\n\ndef lemmatizer_words(text):\n    return \" \".join([lematizer.lemmatize(word) for word in text.split()])\n\ndef cleanTxt(text):\n    text = lower(text)\n    text = remove_hashtag(text)\n    text = remove_twitter(text)\n    text = remove_stopwords(text)\n    text = stemming(text)\n    text = lemmatizer_words(text)\n    return text\n\n#cleaning the text\ndf['tweet_clean'] = df['tweet_text'].apply(cleanTxt)\n\n#show the clean text\ndf.head()","c9a0b0e2":"df.shape\ndf.cyberbullying_type.value_counts()","f620b517":"df[\"tweet_clean\"].duplicated().sum()","a12f3293":"df.drop_duplicates(\"tweet_clean\", inplace=True)","bfdb8cb8":"df.cyberbullying_type.value_counts()","6132cf32":"df['tweet_list'] = df['tweet_clean'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in df['tweet_list'] for item in sublist])\ntweet_list1 = pd.DataFrame(top.most_common(20))\ntweet_list1.columns = ['Words','Count']\ntweet_list1.style.background_gradient(cmap='Greens')","32361207":"figure = px.bar(tweet_list1, x=\"Count\", y=\"Words\", title='Top 20 words in cyberbullying tweet', orientation='h', \n             width=700, height=700,color='Words')\nfigure.show()","d77a96fa":"not_cyberbullying_type = df[df['cyberbullying_type']=='not_cyberbullying']\ngender_type = df[df['cyberbullying_type']=='gender']\nreligion_type = df[df['cyberbullying_type']=='religion']\nother_cyberbullying_type = df[df['cyberbullying_type']=='other_cyberbullying']\nage_type = df[df['cyberbullying_type']=='age']\nethnicity_type = df[df['cyberbullying_type']=='ethnicity']","cccb91c9":"#Top 20 Words in not cyberbullying Tweet\ntop20 = Counter([item for sublist in not_cyberbullying_type['tweet_list'] for item in sublist])\ntype_nc = pd.DataFrame(top20.most_common(20))\ntype_nc.columns = ['Top of Words','Count']\ntype_nc.style.background_gradient(cmap='Greens')","89665674":"nc_fig = px.bar(type_nc, x=\"Count\", y=\"Top of Words\", title='Top 20 Words in not cyberbullying Tweet', orientation='h', \n             width=700, height=700,color='Top of Words')\nnc_fig.show()","907e0789":"#Top 20 Words in Gender cyberbullying Tweet\ntop20_gender = Counter([item for sublist in gender_type['tweet_list'] for item in sublist])\ntype_g = pd.DataFrame(top20_gender.most_common(20))\ntype_g.columns = ['Top of Words','Count']\ntype_g.style.background_gradient(cmap='Greens')","8f030f3f":"g_fig = px.bar(type_g, x=\"Count\", y=\"Top of Words\", title='Top 20 Words in Gender Cyberbullying Tweet', orientation='h', \n             width=700, height=700,color='Top of Words')\ng_fig.show()","7a765267":"#Top 20 Words in religion cyberbullying Tweet\ntop20_r = Counter([item for sublist in religion_type['tweet_list'] for item in sublist])\ntype_r = pd.DataFrame(top20_r.most_common(20))\ntype_r.columns = ['Top of Words','Count']\ntype_r.style.background_gradient(cmap='Greens')","85f8251d":"r_fig = px.bar(type_r, x=\"Count\", y=\"Top of Words\", title='Top 20 Words in Religion Cyberbullying Tweet', orientation='h', \n             width=700, height=700,color='Top of Words')\nr_fig.show()","24b279ca":"#Top 20 Words in others cyberbullying Tweet\ntop20_o = Counter([item for sublist in other_cyberbullying_type['tweet_list'] for item in sublist])\ntype_o = pd.DataFrame(top20_o.most_common(20))\ntype_o.columns = ['Top of Words','Count']\ntype_o.style.background_gradient(cmap='Greens')","710543ce":"o_fig = px.bar(type_o, x=\"Count\", y=\"Top of Words\", title='Top 20 Words in Other Cyberbullying Tweet', orientation='h', \n             width=700, height=700,color='Top of Words')\no_fig.show()","ed01bd03":"#Top 20 Words in Age Cyberbullying Tweet\ntop20_a = Counter([item for sublist in age_type['tweet_list'] for item in sublist])\ntype_a = pd.DataFrame(top20_a.most_common(20))\ntype_a.columns = ['Top of Words','Count']\ntype_a.style.background_gradient(cmap='Greens')","aea6e55e":"a_fig = px.bar(type_a, x=\"Count\", y=\"Top of Words\", title='Top 20 Words in Age cyberbullying Tweet', orientation='h', \n             width=700, height=700,color='Top of Words')\na_fig.show()","0f693dda":"#Top 20 Words in Ethnicity Cyberbullying Tweet\ntop20_e = Counter([item for sublist in ethnicity_type['tweet_list'] for item in sublist])\ntype_e = pd.DataFrame(top20_e.most_common(20))\ntype_e.columns = ['Top of Words','Count']\ntype_e.style.background_gradient(cmap='Greens')","4488a70f":"e_fig = px.bar(type_e, x=\"Count\", y=\"Top of Words\", title='Top 20 Words in Ethnicity Cyberbullying Tweet', orientation='h', \n             width=700, height=700,color='Top of Words')\ne_fig.show()","1f5e9460":"labels = df['cyberbullying_type'].tolist()\ndf.cyberbullying_type.unique()","82c28e90":"ClassIDMap = {'not_cyberbullying': 1, 'gender':2, \n              'religion':3, 'other_cyberbullying': 4, \n              'age': 5, 'ethnicity': 6 }\nClassIDMap","59c26462":"corpus, target_labels, target_names = (df['tweet_clean'], \n                                       [ClassIDMap[label] for \n                                        label in df['cyberbullying_type']], \n                                       df['cyberbullying_type'])\n\ndf = pd.DataFrame({'tweet text': corpus, 'cyberbullying Label': \n                        target_labels, 'cyberbulying Name': target_names})","221858f6":"df","702216bd":"df.info()","2703c0aa":"train_corpus, test_corpus, train_label_nums, test_label_nums, train_label_names, test_label_names =\\\n                                 train_test_split(np.array(df['tweet text']), np.array(df['cyberbullying Label']),\n                                                       np.array(df['cyberbulying Name']), test_size=0.33, random_state=42)\n\ntrain_corpus.shape, test_corpus.shape","0b8ee59b":"# build BOW features on train articles\ntv = TfidfVectorizer(use_idf=True, min_df=0.00002, max_df=0.6)\ntv_train_features = tv.fit_transform(train_corpus.astype('U'))\n\n# transform test articles into features\ntv_test_features = tv.transform(test_corpus.astype('U'))\n\nprint('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)","671045a6":"svm_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n                        ('svm', LinearSVC(random_state=42))])\n\nparam_grid = {'tfidf__ngram_range': [(1, 1), (1, 1)],\n              'svm__C': [1e-5, 1e-4, 1e-2, 1e-1, 1]\n}\n\ngs_svm = GridSearchCV(svm_pipeline, param_grid, cv=5, verbose=2)\ngs_svm = gs_svm.fit(train_corpus.astype('U'), train_label_names)","b0932f90":"gs_svm.best_estimator_.get_params()","a406cd19":"best_svm_test_score = gs_svm.score(test_corpus.astype('U'), test_label_names)\nprint('Test Accuracy :', best_svm_test_score)","bb15f3d0":"mnb_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n                        ('mnb', MultinomialNB())\n                       ])\n\nparam_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n              'mnb__alpha': [1e-5, 1e-4, 1e-2, 1e-1, 1]\n}\n\ngs_mnb = GridSearchCV(mnb_pipeline, param_grid, cv=5, verbose=2)\ngs_mnb = gs_mnb.fit(train_corpus, train_label_names)","c2750588":"gs_mnb.best_estimator_.get_params()","68ed5d2a":"best_mnb_test_score = gs_mnb.score(test_corpus, test_label_names)\nprint('Test Accuracy :', best_mnb_test_score)","77c9cfe5":"lr_pipeline = Pipeline([('tfidf', TfidfVectorizer()),\n                        ('lr', LogisticRegression(penalty='l2', max_iter=100, random_state=42))\n                       ])\n\nparam_grid = {'tfidf__ngram_range': [(1, 1), (1, 2)],\n              'lr__C': [1e-5, 1e-4, 1e-2, 1e-1, 1]\n}\n\ngs_lr = GridSearchCV(lr_pipeline, param_grid, cv=5, verbose=2)\ngs_lr = gs_lr.fit(train_corpus, train_label_names)","b5642427":"gs_lr.best_estimator_","0b0da18b":"best_lr_test_score = gs_lr.score(test_corpus, test_label_names)\nprint('Test Accuracy :', best_lr_test_score)","9fa0d139":"svm_results = gs_svm.cv_results_\nresults_df = pd.DataFrame({'rank': svm_results['rank_test_score'],\n                           'params': svm_results['params'], \n                           'cv score (mean)': svm_results['mean_test_score'], \n                           'cv score (std)': svm_results['std_test_score']} \n              )\nresults_df = results_df.sort_values(by=['rank'], ascending=True)\npd.set_option('display.max_colwidth', 100)\nresults_df","1984df52":"svm_predictions = gs_svm.predict(test_corpus.astype('U'))\n\nplot_confusion_matrix(estimator=gs_svm, X=test_corpus, y_true=test_label_names, \n                      xticks_rotation='vertical', cmap='Greys', ax=None, include_values=True)","0160f0e2":"print(classification_report(test_label_names, svm_predictions, target_names=list(set(test_label_names))))","f7f0f4b0":"mnb_results = gs_mnb.cv_results_\nresults_df = pd.DataFrame({'rank': mnb_results['rank_test_score'],\n                           'params': mnb_results['params'], \n                           'mnb score (mean)': mnb_results['mean_test_score'], \n                           'mnb score (std)': mnb_results['std_test_score']} \n              )\nresults_df = results_df.sort_values(by=['rank'], ascending=True)\npd.set_option('display.max_colwidth', 100)\nresults_df","9ccb5de7":"mnb_predictions = gs_mnb.predict(test_corpus.astype('U'))\n\nplot_confusion_matrix(estimator=gs_mnb, X=test_corpus, y_true=test_label_names, \n                      xticks_rotation='vertical', cmap='Greys', ax=None, include_values=True)","b5509a37":"print(classification_report(test_label_names, mnb_predictions, target_names=list(set(test_label_names))))","4fa72489":"lr_results = gs_lr.cv_results_\nresults_df = pd.DataFrame({'rank': lr_results['rank_test_score'],\n                           'params': lr_results['params'], \n                           'lr score (mean)': lr_results['mean_test_score'], \n                           'lr score (std)': lr_results['std_test_score']} \n              )\nresults_df = results_df.sort_values(by=['rank'], ascending=True)\npd.set_option('display.max_colwidth', 100)\nresults_df","5ffd0f57":"lr_predictions = gs_lr.predict(test_corpus.astype('U'))\n\nplot_confusion_matrix(estimator=gs_lr, X=test_corpus, y_true=test_label_names, \n                      xticks_rotation='vertical', cmap='Greys', ax=None, include_values=True)","6ce5f73b":"print(classification_report(test_label_names, lr_predictions, target_names=list(set(test_label_names))))","fdbfc1c2":"# <a id='4'> 4. Data Visualization<\/a>","fdf8ea08":" # <a id='9'> 9. Conclusion<\/a>","85d33c00":"**Top 20 on Cyberbullying tweet**","9a853b40":"**Multinomial Naive Bayes Classifier**","78f7ca6f":" # <a id='2'> 2. Dataset<\/a>","ed88463c":" # <a id='7'> 7. Classification<\/a>","c23be1d9":"There are 3018 duplicated data, and after remove the duplicated data, the most duplicate data is in others cyberbullying.","3927c814":"# ****Predict Multi Cyberbullying Tweets with Multiclassifier****\n\nThis project aims to predict cyberbullying tweets using the Support Vector Machine classifier, multinomial Naive Bayes classifier, and Logistic Regression classifier. There are six types of bullying used: not bullying, gender, ethnicity, age, religion, and others cyberbullying. In achieving the goal, the steps that will carry out are as follows.\n## Contents\n<a href='#1'>1. Import Library <\/a> <br>\n<a href='#2'>2. Dataset <\/a> <br>\n<a href='#3'>3. Data Preprocessing <\/a> <br>\n<a href='#4'>4. Data Visualization <\/a> <br>\n<a href='#5'>5. Spliting Data <\/a> <br>\n<a href='#6'>6. Features Extractions <\/a> <br>\n<a href='#6'>7. Classification <\/a> <br>\n<a href='#7'>8. Evaluation <\/a> <br>\n<a href='#8'>9. Conclusion <\/a> <br>\n","48b54c2b":"**Top 20 in type of cyberbullying tweet**","5098afbd":"# <a id='1'> 1. Import Library<\/a>","15a76201":"The support vector machine is the best machine learning model for predicting cyberbullying tweets. The accuracy obtained using the SVM model is about 83%, with a weighted average precision percentage of 82%. Even so, the sensitivity obtained is 83%. It means that about 17% of positive cases missed the model's predictions.","61d6f484":" # <a id='6'> 6. Features Exctractions<\/a>","81ccee48":"**Spliting data**","2b32d42d":"**Support Vector Machine classifier**","3c4ca7b5":"****Logistic Regression Classifier****","ed0ba36b":"**Multinomial Naive Bayes**","e2b4a998":" # <a id='8'> 8. Evaluation<\/a>","bf6a6a46":" # <a id='5'> 5. Spliting the data<\/a>","1509bd06":"The dataset used contains 47692 rows, where the distribution of data for each type of cyberbullying is balanced. However, it is necessary to check whether there are duplicated tweets.","735400d3":"**Support Vector Machine classifier**","f82e15d2":" # <a id='3'> 3.Data Preprocessing <\/a>","6e39ab7d":"**Logistic Regression Classifier**","0c05e146":"### Cleaning the data"}}