{"cell_type":{"dbf89d63":"code","f175155e":"code","82a304b9":"code","9aea5b5e":"code","935252e3":"code","510388db":"code","3f32af76":"code","efd70fd2":"code","d7418deb":"code","9f72829d":"code","a419018b":"code","6a19375e":"code","222d8dab":"code","14042ae5":"code","22857848":"code","0c353056":"code","0713f4e6":"code","48115ebc":"code","07585306":"code","a996e0d3":"code","9f7168d1":"code","d94a7ee0":"code","7d8f8dc6":"code","a263034b":"code","32182f28":"code","20ca7085":"code","9a68be80":"code","135ad485":"code","d4b89459":"code","124115dd":"markdown","8dc3027b":"markdown","f2e59e41":"markdown","952bd3e8":"markdown","539fb842":"markdown","6fd19b47":"markdown"},"source":{"dbf89d63":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.graph_objects as go\n\n# Print the current directory\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Dataframe 'players' contains basic information such as name, height, weight, birth_date, etc.\n# Dataframe 'stats' contains players' performance metrics over the years\nplayers = pd.read_csv(\"..\/input\/nba-players-stats\/player_data.csv\")\nstats = pd.read_csv(\"..\/input\/nba-players-stats\/Seasons_Stats.csv\")","f175155e":"# Print the basic overview of 'players' df\nprint(players.info())\nprint(players.head())","82a304b9":"# Print the basic overview of 'stats' df\nprint(stats.info())\nprint(stats.head())","9aea5b5e":"# Dropping and renaming some columns in player dataframe for simplicity\nplayers.drop(['year_start', 'year_end', 'birth_date', 'college'], axis=1, inplace=True)\nplayers.rename(columns={'name': 'Name', 'position': 'Position', 'height': 'Height', 'weight': 'Weight'}, inplace=True)\nplayers.set_index('Name')","935252e3":"# Clean name column by stripping white space\n# Removing all duplicated names to avoid confusion\nplayers['Name'].str.strip()\nplayers = players[players['Name'].duplicated(keep=False)!=True]","510388db":"# Converting heights from feet-inches to centimetres; weight from pounds to kg\nconversions = [30.48, 2.54]\nplayers['Height'] = players['Height'].dropna().str.split('-').apply(pd.Series).astype(int).dot(conversions)\nplayers['Weight'] = players['Weight']*0.454\nprint(players.columns)\nprint(players.head())","3f32af76":"# Restrict the number of attributes wihtin stats dataframe as some games data were \n# not collected in the past; also limit feature set for simplicity\nstats.drop(['Unnamed: 0', 'Year', 'Pos', 'Age', 'Tm', 'GS', '3PAr', 'FTr', 'ORB%', \n            'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'blanl', 'OWS', \n            'DWS', 'WS', 'WS\/48', 'blank2', 'OBPM', 'DBPM', 'BPM', 'VORP', 'FG', 'FGA', \n            '3P', '3PA', '2P', '2PA', 'FT', 'FTA', 'ORB', 'DRB'],\n            axis=1, inplace=True)","efd70fd2":"# Group by players names spanning multiple teams and years; aggregate the stats appropriately\naggregation_functions = {'GamesPlayed': 'sum', 'MinutesPlayed': 'sum', 'PER': 'mean', 'TS%': 'mean', \n                         'FG%': 'mean', '3P%': 'mean', '2P%': 'mean', 'eFG%': 'mean',\n                         'FT%': 'mean', 'TRB': 'sum', 'AST': 'sum', 'STL': 'sum', \n                         'BLK': 'sum', 'TOV': 'sum', 'PF': 'sum', 'PTS': 'sum'}\nstats.rename(columns={'Player': 'Name', 'G': 'GamesPlayed', 'MP': 'MinutesPlayed'}, inplace=True)\nstats = stats.groupby(by=['Name']).aggregate(aggregation_functions)\nstats = stats.reset_index()\nprint(stats.columns)\nprint(stats.head())","d7418deb":"# Combine the players' basic informaiton with their career stats\ncombined = pd.merge(players, stats, how='outer', on='Name')\nprint(combined.info())\nprint(combined.head())","9f72829d":"# Display a few players' statistics\ncombined.loc[combined['Name'] == 'LeBron James']","a419018b":"combined.loc[combined['Name'] == 'Stephen Curry']","6a19375e":"combined.loc[combined['Name'] == 'Kobe Bryant']","222d8dab":"# Plotting players' height against weight.\nfig = go.Figure(data=go.Scatter(x=combined['Weight'],\n                                y=combined['Height'],\n                                mode='markers',\n                                text=combined['Name'],\n                                marker=dict(color='#34eb3a')))\nfig.update_layout(\n    title='NBA Player: Height vs Weight',\n    xaxis_title='Weight (kg)',\n    yaxis_title='Height (cm)',\n    plot_bgcolor='rgba(0,0,0,0)'\n)\nfig.show()","14042ae5":"# Plotting players' points scored vs games played.\nfig = go.Figure(data=go.Scatter(x=combined['GamesPlayed'],\n                                y=combined['PTS'],\n                                mode='markers',\n                                text=combined['Name'],\n                                marker=dict(color='#34eb3a')))\nfig.update_layout(\n    title='NBA Player: Points scored vs games played',\n    xaxis_title='Games Played',\n    yaxis_title='Points Scored',\n    plot_bgcolor='rgba(0,0,0,0)'\n)\nfig.show()","22857848":"# Create dataset with no null values (excluding missing statistics)\ncombinedClean = combined.drop(['Position'], axis=1).dropna().reset_index(drop=True)\ncombinedClean.info()","0c353056":"# Using the sklearn StandardScalar function to mean normalise the data\n# Set mean of each column to zero and standard deviation to 1 ()\nfrom sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(combinedClean.drop(['Name'], axis=1).values)\nprint(X.mean(axis=0)) # Close to 0\nprint(X.std(axis=0)) # Exactly 1","0713f4e6":"# Using Principal Component Analysis to reduce the dimensionality of the data \n# in order to better visualise results and optimise the result of the clustering.\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2) # Choose 2 components to allow easy visualisation\nprincipalComponents = pca.fit_transform(X)\nprincipalComponents","48115ebc":"# Creating a dataframe for the PCA components; concatenate the names back to the set\nPCA_df = pd.DataFrame(data = principalComponents, columns = ['Component1', 'Component2'] )\nPCA_df = pd.concat([combinedClean['Name'],PCA_df], axis=1)\nPCA_df.head()","07585306":"# Plotting out two PCA components from dataset of reduced dimension\nplt.figure()\nplt.figure(figsize=(10,10))\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.title('2 Component PCA')\nplt.scatter(PCA_df['Component1'], PCA_df['Component2'])","a996e0d3":"# Importing the KMeans algorithm from sklearn.cluster\nfrom sklearn.cluster import KMeans\nkmeans_model = KMeans(n_clusters = 10, init = 'k-means++', random_state = 1)\nkmeans_model.fit(principalComponents) # Fit the model on our PCA components\nkmeans_labels = kmeans_model.labels_ # Get the labels of each cluster","9f7168d1":"# Merge cluster results with other variables for visualisation\ninterest_df = combined[['Name', 'PTS']] # Vary the element of interest here\ntemp = pd.merge(PCA_df, interest_df, how='left', on='Name')\nkmeans_results = pd.concat([temp, pd.DataFrame(data=kmeans_labels, columns=['ClusterNumber'])], axis=1)\nkmeans_results.head()","d94a7ee0":"# Plotting players' clusters from kmeans.\nfig = go.Figure(data=go.Scatter(x=kmeans_results['Component1'],\n                                y=kmeans_results['Component2'],\n                                mode='markers',\n                                text=kmeans_results['PTS'], # Change the text label to see what each cluster represents\n                                marker=dict(color=\n                                    kmeans_results['ClusterNumber']) # Set colour according to clusters\n                               ))\nfig.update_layout(\n    title='NBA Player: kmeans clusters',\n    xaxis_title='Component1',\n    yaxis_title='Component2',\n    plot_bgcolor='rgba(0,0,0,0)'\n)\nfig.show()","7d8f8dc6":"# Importing the dendrogram visualiser to find closest Euclidean distances\nimport scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(principalComponents, method = 'ward'))\nplt.title('Dendrogram')\nplt.xlabel('Compounds')\nplt.ylabel('Euclidean distances')\nplt.show()","a263034b":"# Importing the AgglomerativeClustering (hierarchical) algorithm from skleanr.cluster\nfrom sklearn.cluster import AgglomerativeClustering\nhc_model = AgglomerativeClustering(n_clusters = 10, affinity = 'euclidean', linkage = 'ward') # Set Euclidean distance\nhc_model = hc_model.fit(principalComponents) # Fit the model on our PCA components\nhc_labels = hc_model.labels_ # Get the labels of each cluster","32182f28":"# Merge cluster results with other variables for visualisation\ninterest_df = combined[['Name', 'PTS']] # Vary the element of interest here\ntemp = pd.merge(PCA_df, interest_df, how='left', on='Name')\nhc_results = pd.concat([temp, pd.DataFrame(data=hc_labels, columns=['ClusterNumber'])], axis=1)\nhc_results.head()","20ca7085":"# Plotting players' clusters from hierarchichal\nfig = go.Figure(data=go.Scatter(x=hc_results['Component1'],\n                                y=hc_results['Component2'],\n                                mode='markers',\n                                text=hc_results['PTS'], # Change the text label to see what each cluster represents\n                                marker=dict(color=\n                                    hc_results['ClusterNumber']) # Set colour according to clusters\n                               ))\nfig.update_layout(\n    title='NBA Player: hierarchical clusters',\n    xaxis_title='Component1',\n    yaxis_title='Component2',\n    plot_bgcolor='rgba(0,0,0,0)'\n)\nfig.show()","9a68be80":"# Import the MeanShift algorithm from sklearn.cluster\nfrom sklearn.cluster import MeanShift\nms_model = MeanShift(bandwidth=1) # Set the bandwidth for this model\nms_model = ms_model.fit(principalComponents) # Fit the model on our PCA components\nms_labels = ms_model.labels_ # Get the labels of each cluster","135ad485":"# Merge cluster results with other variables for visualisation\ninterest_df = combined[['Name', 'PTS']] # Vary the element of interest here\ntemp = pd.merge(PCA_df, interest_df, how='left', on='Name')\nms_results = pd.concat([temp, pd.DataFrame(data=ms_labels, columns=['ClusterNumber'])], axis=1)\nms_results.head()","d4b89459":"# Plotting players' clusters from meanshift\nfig = go.Figure(data=go.Scatter(x=ms_results['Component1'],\n                                y=ms_results['Component2'],\n                                mode='markers',\n                                text=ms_results['PTS'], # Change the text label to see what each cluster represents\n                                marker=dict(color=\n                                    ms_results['ClusterNumber']) # Set colour according to clusters\n                               ))\nfig.update_layout(\n    title='NBA Player: mean-shift clusters',\n    xaxis_title='Component1',\n    yaxis_title='Component2',\n    plot_bgcolor='rgba(0,0,0,0)'\n)\nfig.show()","124115dd":"### Initialisation\nImporting packages and datasets. Carrying out data cleaning and organising. Plotting a few visualisations for initial checking.","8dc3027b":"### Hierarchical Clustering\nHierarchical clustering is an iterative process that joins data points with the shortest distance into clusters. The process repeats until large linkages\/clusters are formed. The main variable is the closest distance cutoff instead of the number of clusters. This sets the number of clusters. Again, this could be quite arbitary but the algorithm allows us to handpick the number of clusters while automatically adjusting the cutoff.\n\nClusters seem very similar to the kmeans clusters with slight differences along the boundaries in the densely populated region. Perhaps picking a higher number of clusters would lead to more refined results.","f2e59e41":"### Mean-Shift Clustering\nMean shift uses a window with a set bandwidth to assign data points to each cluster then subsequently moves the window towards the centroids of each window during iterations. It has an assignment step and a movement step similar to kmeans. The main variable is the bandwidth. As our data seems very densly populated in the middle, I chose an arbitarily small bandwith of 1 in hopes of getting more refined clusters.\n\nVarying the bandwidth would achieve different results but the general trend is that there are 2-3 big clusters in the centre of the plot with just a few smaller cluster on the peripheries.","952bd3e8":"### Mean Normalisation and PCA Dimensionality Reduction\nAs the combined dataset contiains a range of statistics with different ranges (in particular, the percentages are within the 0-1 range while points could go up to 10000s), we need to mean normalise the data before carrying out PCA reduction.\n\nPrincipal Component Analysis reduces the dimension of analysis by finding the correlations between attributes.","539fb842":"## NBA Clustering Project\n### Applying clustering algorithm (Kmeans, Hierarchical, Mean-shift) on NBA dataset\n\n**Ching Hong Fung**\n\n**23\/11\/2021**\n\nThis project looks at different clustering algorithms on an nba player dataset. I have just started data science and want to try out some of the new theories on an area of interest. Please leave a comment if you find my analysis interesting.","6fd19b47":"### K-Means Clustering\nK-means algorithm has two steps in each iteration. It randomises starting locations of the centroids and assigns data points to each centroid based on shortest Euclidean distance. It then moves the centroids based on the average of the datapoints. The main variable is the number of clusters. It isn't obvious from the plot above how many to go for. I picked 10 as an arbitary number."}}