{"cell_type":{"4550c1d4":"code","9b3987e5":"code","2fa47c94":"code","cc67bb6a":"code","3da745ee":"code","56649d52":"code","16793796":"code","e62a83b1":"code","63d1ba6d":"code","3b79477d":"code","b51ea749":"code","f98da324":"code","53d7b272":"code","56545b4b":"code","fc05053c":"code","78b93212":"code","e2b14049":"code","e7b504af":"code","3c0c5037":"code","a58795e3":"code","ef011d70":"code","d325273b":"code","7864e002":"code","04c9f4a9":"code","75457691":"markdown","9a4e74fd":"markdown","73ad9d27":"markdown","59222fbc":"markdown","d2647315":"markdown","327ac965":"markdown","1d8fd75c":"markdown","763539db":"markdown"},"source":{"4550c1d4":"import numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, cross_val_score\nfrom sklearn.metrics import (accuracy_score, roc_auc_score, roc_curve, roc_auc_score ,recall_score, \n                             precision_score, confusion_matrix, classification_report, f1_score, auc)\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n# setting the size of the dataframe to disply\npd.set_option('max_columns', 25)","9b3987e5":"# loading the data\n\nmushroom_df = pd.read_csv('..\/input\/mushroom-classification\/mushrooms.csv')\n\n# printing the first five row of the dataframe\nmushroom_df.head()","2fa47c94":"# no of rows and columns\n\nmushroom_df.shape","cc67bb6a":"# checking for any null values\n\nmushroom_df.isnull().sum()","3da745ee":"# check information about dataset \n\nmushroom_df.info()","56649d52":"# detail about dataset\n\nmushroom_df.describe()","16793796":"# function to print the value coutn go each columm\n\ncols = mushroom_df.columns.to_list()\ndef value_count(cols):\n    each_cols = mushroom_df[cols]\n    for i in each_cols:\n        print('Number of unique value in column \"{}\" is : {} -->  {} \\n'.format(i.upper(), len(dict(each_cols[i].value_counts())) ,dict(each_cols[i].value_counts())))\n        #print(dict(each_cols['class'].value_counts()))\n\n     \nvalue_count(cols)","e62a83b1":"# Convert categories to numbers using one hot encoder\n\nx = pd.get_dummies(mushroom_df[mushroom_df.columns[1:]])\nx.head()","63d1ba6d":"# converting output value to numberic\nlabe_encode = LabelEncoder()\ny = labe_encode.fit_transform(mushroom_df['class'])","3b79477d":"# checking the no or columns after one hot encoding\n\nx.shape[1]\n\n# there are 117 columsn, excluding output column class","b51ea749":"# spliting data into train and test\n\nx_train,x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state=1, stratify = y)","f98da324":"print('x_train:', x_train.shape)\nprint('y_train:', y_train.shape)\nprint('x_test:', x_test.shape)\nprint('y_train:', y_test.shape)","53d7b272":"# create an instance of decision tree\n\ntree_classifier = DecisionTreeClassifier(criterion='gini', random_state=42)\n\n# fit the data to model\n\ntree_classifier.fit(x_train, y_train)","56545b4b":"# make a prediction with testing data\n\ny_predict = tree_classifier.predict(x_test)\ny_predict_train = tree_classifier.predict(x_train)","fc05053c":"# checking model accuracy\n\nprint('Model accuracy: ', accuracy_score(y_test, y_predict))","78b93212":"# cross validation to evaluate model\n\ncross_metrix = cross_val_score(tree_classifier, x, y, scoring='accuracy')\n\nprint(cross_metrix)\nprint(cross_metrix.mean())\nprint(cross_metrix.std())","e2b14049":"# confusion matrix\n\nconfusion_score = confusion_matrix(y_test, y_predict)\nconfusion_score","e7b504af":"# plotting confusion matrix\n\nsns.heatmap(confusion_score, annot=True, annot_kws={'size':16})","3c0c5037":"# slice confusion matrix into four pieces\n\nTP = confusion_score[1, 1]\nTN = confusion_score[0, 0]\nFP = confusion_score[0, 1]\nFN = confusion_score[1, 0]\n","a58795e3":"# classification Erroe rate\n\nprint('Error rate: ', 1 - accuracy_score(y_test, y_predict))\n\n# 0.0 shwos that there is no error, out model is perfect","ef011d70":"# True positive (Recall or sensitivity)\nprint('True positive (Recall or sensitivity)', recall_score(y_test, y_predict))\n\n\n# True Negative (sensitivity)\nprint('True positive (specificity)', TN\/ (TN + FP))\n\n\n# False Positive \nprint('False positive (Recall or sensitivity)', FP\/ (FP + TN))\n\n\n# Precision\nprint('Precision', precision_score(y_test, y_predict))","d325273b":"# print classification report\n\nprint('classification report: \\n', classification_report(y_test, y_predict))","7864e002":"#  predicted responses\n\nfpr,tpr,thresholds=roc_curve(y_test,y_predict)\n\n# calculate acu curv\nroc_auc=auc(fpr,tpr)","04c9f4a9":"# we pass y_test and y_pred_prob\n# we do not use y_pred_class, because it will give incorrect results without generating an error\n# roc_curve returns 3 objects fpr, tpr, thresholds\n# fpr: false positive rate\n# tpr: true positive rate\n\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr,tpr, color='red',label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],linestyle='--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\n","75457691":"## spliting data into train and test","9a4e74fd":"Use both of these whenever possible\n\n**Confusion matrix advantages:**\n\n- Allows you to calculate a variety of metrics\n- Useful for multi-class problems (more than two response classes)\n\n**ROC\/AUC advantages:**\n\n- Does not require you to set a classification threshold\n- Still useful when there is high class imbalance","73ad9d27":"## Metrics computed from a confusion matrix","59222fbc":"## check no of row and columns in train and test","d2647315":"## Importing Libraries","327ac965":"## Exploring Data","1d8fd75c":"# Model Evaluation","763539db":"## Modeling"}}