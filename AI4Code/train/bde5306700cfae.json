{"cell_type":{"cb9969d1":"code","39cd9046":"code","b9d56df9":"code","91551869":"code","556295f3":"code","9d79e35a":"code","642e8212":"code","cf947071":"code","6047746a":"code","fec23087":"code","d94fad34":"code","1cde7ad6":"code","73b868b8":"code","7cde198e":"code","6444daa0":"code","9b0ee6d0":"markdown","998ad94b":"markdown","7edfab0a":"markdown","f0c9577f":"markdown","4be2e0a6":"markdown","3ac7fcc8":"markdown","876377db":"markdown","01f4de63":"markdown"},"source":{"cb9969d1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.metrics import accuracy_score\nfrom kaggle.competitions import twosigmanews","39cd9046":"env = twosigmanews.make_env()\n(market_train, _) = env.get_training_data()","b9d56df9":"cat_cols = ['assetCode']\nnum_cols = [ \n            'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevRaw10','returnsOpenPrevRaw10', # Raw returns\n            'returnsOpenPrevMktres1', 'returnsClosePrevMktres1','returnsClosePrevMktres10','returnsOpenPrevMktres10',  # Residualized returns\n            'volume', 'close', 'open', # Other\n            'close_to_open', 'std1', 'std10', 'std_res1', 'std_res10', 'res_raw1', 'res_raw10', 'raw_res1', 'raw_res10', 'ma10', 'ma50', 'ma200' # Custom Inputs\n]\n\n# # Custom Inputs\nreturns = market_train['returnsClosePrevRaw1']\nres_returns = market_train['returnsClosePrevMktres1']\n\ndf_close_to_open = np.abs(market_train['close'] \/ market_train['open'])\nstd1 =  np.abs(returns) \/ np.mean(np.abs(market_train['returnsClosePrevRaw1'])) \nstd10 =  np.abs(returns) \/ np.mean(np.abs(market_train['returnsClosePrevRaw10']))\n\nstd_res1 = np.abs(res_returns) \/ np.mean(np.abs(market_train['returnsClosePrevMktres1']))\nstd_res10 = np.abs(res_returns) \/ np.mean(np.abs(market_train['returnsClosePrevMktres10']))\n\nres_raw1 = np.abs(res_returns) \/ np.mean(np.abs(market_train['returnsClosePrevRaw1']))\nres_raw10 = np.abs(res_returns) \/ np.mean(np.abs(market_train['returnsClosePrevRaw10']))\n\nraw_res1 = np.abs(returns) \/ np.mean(np.abs(market_train['returnsClosePrevMktres1']))\nraw_res10 = np.abs(returns) \/ np.mean(np.abs(market_train['returnsClosePrevMktres10']))\n    \nN = 10\nma10 = np.convolve(returns, np.ones((N,))\/N, mode='valid')\nma10_fix = [sum(ma10)\/len(ma10)] * 9\nma10 = np.insert(ma10, 0, ma10_fix)\n\nN = 50\nma50 = np.convolve(returns, np.ones((N,))\/N, mode='valid')\nma50_fix = [sum(ma50)\/len(ma50)] * 49\nma50 = np.insert(ma50, 0, ma50_fix)\n\nN = 200\nma200 = np.convolve(returns, np.ones((N,))\/N, mode='valid')\nma200_fix = [sum(ma200)\/len(ma200)] * 199\nma200 = np.insert(ma200, 0, ma200_fix)","91551869":"from sklearn.model_selection import train_test_split\ntrain_indices, val_indices = train_test_split(market_train.index.values,test_size=0.25, random_state=23)","556295f3":"def encode(encoder, x):\n    len_encoder = len(encoder)\n    try:\n        id = encoder[x]\n    except KeyError:\n        id = len_encoder\n    return id\n\nencoders = [{} for cat in cat_cols]\n\n\nfor i, cat in enumerate(cat_cols):\n    print('encoding %s ...' % cat, end=' ')\n    encoders[i] = {l: id for id, l in enumerate(market_train.loc[train_indices, cat].astype(str).unique())}\n    market_train[cat] = market_train[cat].astype(str).apply(lambda x: encode(encoders[i], x))\n    print('Done')\n\nembed_sizes = [len(encoder) + 1 for encoder in encoders] #+1 for possible unknown assets\n","9d79e35a":"from sklearn.preprocessing import StandardScaler\n \n# Add our engineered features to dataset\nmarket_train['close_to_open'] = df_close_to_open\nmarket_train['std1'] = std1\nmarket_train['std10'] = std10\nmarket_train['std_res1']  = std_res1\nmarket_train['std_res10']  = std_res10\nmarket_train['res_raw1'] = res_raw1\nmarket_train['res_raw10'] = res_raw10\nmarket_train['raw_res1'] = raw_res1\nmarket_train['raw_res10'] = raw_res1\nmarket_train['ma10'] = ma10\nmarket_train['ma50'] = ma50\nmarket_train['ma200'] = ma200\n\n# Clean Our Data:\nmarket_train[num_cols] = market_train[num_cols].replace([np.inf, -np.inf], np.nan)\nmarket_train[num_cols] = market_train[num_cols].fillna(0)\n\nmarket_train['std_res1'] = market_train['std_res1'].replace(0, np.mean(market_train['std_res1']))\nmarket_train['std_res10'] = market_train['std_res10'].replace(0, np.mean(market_train['std_res10']))\nmarket_train['res_raw1'] = market_train['res_raw1'].replace(0, np.mean(market_train['res_raw1']))\nmarket_train['res_raw10'] = market_train['res_raw10'].replace(0, np.mean(market_train['res_raw10']))\nmarket_train['raw_res1'] = market_train['raw_res1'].replace(0, np.mean(market_train['raw_res1']))\nmarket_train['raw_res10'] = market_train['raw_res10'].replace(0, np.mean(market_train['raw_res10']))\n\nmarket_train['returnsOpenPrevMktres1'] = market_train['returnsOpenPrevMktres1'].replace(0, np.mean(market_train['returnsOpenPrevMktres1']))\nmarket_train['returnsClosePrevMktres1'] = market_train['returnsClosePrevMktres1'].replace(0, np.mean(market_train['returnsClosePrevMktres1']))\nmarket_train['returnsClosePrevMktres10'] = market_train['returnsClosePrevMktres10'].replace(0, np.mean(market_train['returnsClosePrevMktres10']))\nmarket_train['returnsOpenPrevMktres10'] = market_train['returnsOpenPrevMktres10'].replace(0, np.mean(market_train['returnsOpenPrevMktres10']))\n\nprint('scaling numerical columns')\nscaler = StandardScaler()\n# market_train[num_cols] = scaler.fit_transform(market_train[num_cols])\nmarket_train[num_cols[:-3]] = scaler.fit_transform(market_train[num_cols[:-3]])","642e8212":"from keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, Concatenate, Flatten, BatchNormalization\nfrom keras.losses import binary_crossentropy, mse\n\ncategorical_inputs = []\nfor cat in cat_cols:\n    categorical_inputs.append(Input(shape=[1], name=cat))\n\ncategorical_embeddings = []\nfor i, cat in enumerate(cat_cols):\n    categorical_embeddings.append(Embedding(embed_sizes[i], 10)(categorical_inputs[i]))\n\n\n# Categorical layer (asset code)\ncategorical_logits = Flatten()(categorical_embeddings[0])\ncategorical_logits = Dense(64,activation='relu')(categorical_logits)\n\n# Numeric layer describing assets (returns, std, etc)\nnumerical_inputs = Input(shape=(23, ), name='num') # 18 numeric inputs.  11 from data set, 10 hand engineered. \nnumerical_logits = numerical_inputs\nnumerical_logits = BatchNormalization()(numerical_logits)\n\nnumerical_logits = Dense(248,activation='relu')(numerical_logits)\nnumerical_logits = Dense(124,activation='relu')(numerical_logits)\nnumerical_logits = Dense(64,activation='relu')(numerical_logits)\n\n# Combine our numeric and catergoic layers:\nlogits = Concatenate()([numerical_logits,categorical_logits])\nlogits = Dense(64,activation='relu')(logits)\nlogits = Dense(32,activation='relu')(logits)\nout = Dense(1, activation='sigmoid')(logits) # Single output\n\nmodel = Model(inputs = categorical_inputs + [numerical_inputs], outputs=out)\nmodel.compile(optimizer='adam',loss=binary_crossentropy)","cf947071":"# Lets print our model\nmodel.summary()","6047746a":"def get_input(market_train, indices):\n    X_num = market_train.loc[indices, num_cols].values\n    X = {'num':X_num}\n    for cat in cat_cols:\n        X[cat] = market_train.loc[indices, cat_cols].values\n    y = (market_train.loc[indices,'returnsOpenNextMktres10'] >= 0).values\n    r = market_train.loc[indices,'returnsOpenNextMktres10'].values\n    u = market_train.loc[indices, 'universe']\n    d = market_train.loc[indices, 'time'].dt.date\n    return X,y,r,u,d\n\n# r, u and d are used to calculate the scoring metric\nX_train,y_train,r_train,u_train,d_train = get_input(market_train, train_indices)\nX_valid,y_valid,r_valid,u_valid,d_valid = get_input(market_train, val_indices)","fec23087":"from keras.callbacks import EarlyStopping, ModelCheckpoint\n\ncheck_point = ModelCheckpoint('model.hdf5',verbose=True, save_best_only=True)\nearly_stop = EarlyStopping(patience=12,verbose=True)\nmodel.fit(X_train,y_train.astype(int),\n          validation_data=(X_valid,y_valid.astype(int)),\n          epochs=100,\n          verbose=True,\n          callbacks=[early_stop,check_point]) ","d94fad34":"# distribution of confidence that will be used as submission\nmodel.load_weights('model.hdf5')\nconfidence_valid = model.predict(X_valid)[:,0]*2 -1\nprint(accuracy_score(confidence_valid>0,y_valid))\nplt.hist(confidence_valid, bins='auto')\nplt.title(\"predicted confidence\")\nplt.show()","1cde7ad6":"# calculation of actual metric that is used to calculate final score\nr_valid = r_valid.clip(-1,1) # get rid of outliers. Where do they come from??\nx_t_i = confidence_valid * r_valid * u_valid\ndata = {'day' : d_valid, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_valid = mean \/ std\nprint(score_valid)","73b868b8":"days = env.get_prediction_days()","7cde198e":"# NEEDS WORKS.  PLZ HELP.\n\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\npredicted_confidences = np.array([])\n\n# market_obs_df[num_cols] = market_obs_df[num_cols].fillna(0)\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n        n_days +=1\n        print(n_days,end=' ')\n        t = time.time()\n\n        market_obs_df['assetCode_encoded'] = market_obs_df[cat].astype(str).apply(lambda x: encode(encoders[i], x))\n        market_obs_df['close_to_open'] = market_train['close_to_open']\n        market_obs_df['std1'] = market_train['std1']\n        market_obs_df['std10'] = market_train['std10']\n        market_obs_df['std_res1']  = market_train['std_res1']\n        market_obs_df['std_res10']  = market_train['std_res10']\n        market_obs_df['res_raw1'] = market_train['res_raw1']\n        market_obs_df['res_raw10'] = market_train['res_raw10']\n        market_obs_df['raw_res1'] = market_train['raw_res1']\n        market_obs_df['raw_res10'] = market_train['raw_res1']\n        market_obs_df['ma10'] = market_train['ma10']\n        market_obs_df['ma50'] = market_train['ma50']\n        market_obs_df['ma200'] = market_train['ma200']\n        \n        market_obs_df[num_cols] = market_obs_df[num_cols].fillna(0)\n#         market_obs_df[num_cols] = scaler.fit_transform(market_obs_df[num_cols])\n        market_obs_df[num_cols[:-3]] = scaler.fit_transform(market_obs_df[num_cols[:-3]])\n        \n        X_num_test = market_obs_df[num_cols].values\n        X_test = {'num':X_num_test}\n        X_test['assetCode'] = market_obs_df['assetCode_encoded'].values\n\n        prep_time += time.time() - t\n\n        t = time.time()\n        market_prediction = model.predict(X_test)[:,0]*2 -1\n        predicted_confidences = np.concatenate((predicted_confidences, market_prediction))\n        prediction_time += time.time() -t\n\n        t = time.time()\n        preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':market_prediction})\n        # insert predictions to template\n        predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n        env.predict(predictions_template_df)\n        packaging_time += time.time() - t\n        \nenv.write_submission_file()\ntotal = prep_time + prediction_time + packaging_time\nprint(f'Preparing Data: {prep_time:.2f}s')\nprint(f'Making Predictions: {prediction_time:.2f}s')\nprint(f'Packing: {packaging_time:.2f}s')\nprint(f'Total: {total:.2f}s')","6444daa0":"# distribution of confidence as a sanity check: they should be distributed as above\nplt.hist(predicted_confidences, bins='auto')\nplt.title(\"predicted confidence\")\nplt.show()","9b0ee6d0":"# Prediction","998ad94b":"# Market Data Only Baseline\n\nUsing a lot of ideas from XGBoost Baseline Kernel.\n\nThis is a fit of market data only (no news data used) showing relatively good results. ","7edfab0a":"# Define NN Architecture","f0c9577f":"# Handling categorical variables","4be2e0a6":"# Evaluation of Validation Set","3ac7fcc8":"# Train NN model","876377db":"Todo: add explanaition of architecture","01f4de63":"# Handling numerical variables"}}