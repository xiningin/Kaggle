{"cell_type":{"ee2e51fc":"code","76b207b0":"code","c7a0a946":"code","0b0ad109":"code","de4edbd8":"code","db15c44d":"code","e00ab950":"code","5a4d5ddd":"code","1e284f64":"code","ce9f2834":"code","3d73b695":"code","a3134cb7":"code","e9b8066f":"code","69264895":"code","2147c3b1":"code","f649ce6a":"code","3a89f229":"code","3cc96d1a":"code","2fe9295f":"code","391e3e73":"code","563b9c42":"code","3454c6d4":"code","664e8ac1":"code","11ff8f9e":"code","b876b77f":"code","d60cce2c":"code","7c8f395b":"code","b2430cec":"code","e3e18e5d":"code","834b6cb2":"code","db174580":"code","968ffada":"code","273c0b1b":"code","2353ddee":"code","684414bb":"code","b02ce2d1":"code","777a9165":"code","17b0bb71":"code","d65b8508":"code","9baa1a4a":"code","4336a2c3":"code","a3aa956a":"code","7c08cf11":"code","499f9932":"code","281e9ac9":"code","b777a235":"code","49b470f3":"markdown","36ea5b5b":"markdown","e61a99ac":"markdown","56b868f2":"markdown","35d22509":"markdown","7e452fbf":"markdown","4f382eee":"markdown","6aa575aa":"markdown","c6bdb181":"markdown","776da924":"markdown"},"source":{"ee2e51fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76b207b0":"import pandas as pd\ndata = pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\ndata.head(13)","c7a0a946":"data.describe()","0b0ad109":"data.info()","de4edbd8":"n = data.isna().sum()\nn = n.reset_index()\nn","db15c44d":"n['%'] = n[0]*100\/len(data)\nn","e00ab950":"data['RainToday'] = data['RainToday'].replace(\"No\",0).replace(\"Yes\",1)\ndata['RainToday'].head(13)","5a4d5ddd":"data['RainTomorrow'] = data['RainTomorrow'].replace(\"No\",0).replace(\"Yes\",1)\ndata['RainTomorrow'].head(13)","1e284f64":"import seaborn as sns\nsns.histplot(data,x=\"RainTomorrow\")","ce9f2834":"data = data.dropna(subset=[\"RainTomorrow\"],axis=0)\ndata.shape\ndata.isna().sum()","3d73b695":"objects_data = data.select_dtypes(include=\"object\")\nobjects_data.info()","a3134cb7":"objects_data.nunique()\n# objects_data = objects_data.fillna(objects_data.mode()[0]) \n# objects_data.isna().sum()","e9b8066f":"objects_data.Location.value_counts()","69264895":"data = data.iloc[:,1:]\ndata.head(40)","2147c3b1":"#Filling the NAN Values with mean and mode\n#Mean if values are regressive and mode if values are categorical or discrete\ndata = data.fillna(data.mean())\n# for col in data.columns:\n#     data[col] = data[col].fillna(data[col].mean())\n# data.isna().sum()\ndata.head(13)","f649ce6a":"data.isna().sum()","3a89f229":"data['WindGustDir'] = data['WindGustDir'].fillna(data['WindGustDir'].mode()[0])\ndata['WindDir9am'] = data['WindDir9am'].fillna(data['WindDir9am'].mode()[0])\ndata['WindDir3pm'] = data['WindDir3pm'].fillna(data['WindDir3pm'].mode()[0])\ndata['WindDir3pm'].isna().sum()","3cc96d1a":"data.isna().sum()","2fe9295f":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\ndata['Location'] = label_encoder.fit_transform(data['Location'])\ndata['WindGustDir'] = label_encoder.fit_transform(data['WindGustDir'])\ndata['WindDir9am'] = label_encoder.fit_transform(data['WindDir9am'])\ndata['WindDir3pm'] = label_encoder.fit_transform(data['WindDir3pm'])\ndata.head()","391e3e73":"y = data.iloc[:,-1]\ny.head()","563b9c42":"data = data.iloc[:,:-1]\ndata.head()","3454c6d4":"from imblearn.over_sampling import SMOTE\noversample = SMOTE()\ndata, y = oversample.fit_resample(data, y)","664e8ac1":"from collections import Counter\nc = Counter(y)\nc","11ff8f9e":"data.info()","b876b77f":"import matplotlib.pyplot as plt\ncorr = data.corr()\nplt.figure(figsize=(20, 20))\nsns.heatmap(corr, annot=True,fmt = '.1f');","d60cce2c":"cols = ['Temp9am','Temp3pm','Humidity9am']\ndata = data.drop(['Temp9am','Temp3pm','Humidity9am'],axis=1)","7c8f395b":"data.columns","b2430cec":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=42)","e3e18e5d":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(penalty = 'elasticnet',solver='saga', random_state=0,l1_ratio=0.4)\nclf.fit(X_train, y_train)","834b6cb2":"y_pred = clf.predict(X_test)\ny_pred","db174580":"params = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5],\n        'learning_rate':[0.01, 0.03, 0.05],\n        'n_estimators': [100,300,600,700]\n        }","968ffada":"#XGBoost\n \nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport xgboost as xgb\nxgb_model= xgb.XGBClassifier()\nxgb_model.fit(X_train,y_train)","273c0b1b":"skf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)","2353ddee":"random_search = RandomizedSearchCV(xgb_model, param_distributions=params, n_iter=5, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=42 )\n\n# Uncomment the below line when you run the model\nrandom_search.fit(X_train,y_train)\n","684414bb":"random_search.cv_results_\nrandom_search.best_params_","b02ce2d1":"xgb_random_pred = random_search.predict(X_test)\nxgb_random_pred","777a9165":"xgb_pred = xgb_model.predict(X_test)\nxgb_pred","17b0bb71":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import accuracy_score, classification_report\nprecision, recall, fscore, support = score(y_test,y_pred,average='weighted')","d65b8508":"accuracy_score(y_pred,y_test)","9baa1a4a":"lg = {\n    'precision':precision,\n    'recall':recall,\n    'fscore':fscore,\n    'support':support\n}\nlg","4336a2c3":"xgb_precision, xgb_recall, xgb_fscore, xgb_support = score(y_test,xgb_pred,average='weighted')","a3aa956a":"accuracy_score(xgb_pred,y_test)","7c08cf11":"xgb_= {\n    'precision':xgb_precision,\n    'recall':xgb_recall,\n    'fscore':xgb_fscore,\n    'support':xgb_support\n}\nxgb_","499f9932":"rs_precision, rs_recall, rs_fscore, rs_support = score(y_test,xgb_random_pred,average='weighted')","281e9ac9":"accuracy_score(xgb_random_pred,y_test)","b777a235":"rs_= {\n    'precision':rs_precision,\n    'recall':rs_recall,\n    'fscore':rs_fscore,\n    'support':rs_support\n}\nrs_","49b470f3":"# **Balance the Data using SMOTE**","36ea5b5b":"# Correlation","e61a99ac":"**Imputation**","56b868f2":"> The below plot shows that our output data is biased for category 0 i.e. No. Upsampling should be done to make it equal","35d22509":"# **Model Training**","7e452fbf":"# Preprocessing","4f382eee":"**If we look at the above heatmap it is evident that:**\n\n* Temp9am Temp3pm are highly correlated with MinTemp and MaxTemp\n* Humidity9am and humidity3pm are highly correlated\n","6aa575aa":"# **Accuracy & Error Metrics**","c6bdb181":"# **Encoding**","776da924":"**Dropping the rows which have output variable as NAN**"}}