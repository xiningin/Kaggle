{"cell_type":{"efa42d04":"code","30df7d8c":"code","8cf7753a":"code","950ba759":"code","c14857c6":"code","847f3416":"code","3101ac82":"code","c6b02179":"code","19920672":"code","170e8173":"code","cc2e9f97":"code","463ef13e":"code","0903193d":"code","f8381176":"code","8f49c971":"code","41e7a225":"code","299673f7":"code","76727dd9":"code","17ac7e53":"code","381d61a5":"code","f0d822f2":"code","0a52e6aa":"code","2c6144e9":"code","c83d9e20":"code","c6c1bcae":"code","d694f60d":"code","327116c7":"code","cbbe475c":"code","d4503c24":"code","839e5a9c":"code","626140d7":"code","58cbf0a2":"code","b192e2a1":"code","4cbc91ed":"code","ac0a068c":"code","4cd6cf18":"markdown","f7af55d5":"markdown","8a6fbab4":"markdown","9d6a701f":"markdown","57e85c0c":"markdown","759e48e7":"markdown","5a9a416e":"markdown","9ef3a453":"markdown","21eacc09":"markdown","c7c0b164":"markdown","acf27e59":"markdown","9b28cf41":"markdown","eb23a1dd":"markdown","61f50038":"markdown","283682bb":"markdown","9a6230fb":"markdown","0c22d5a6":"markdown","e1400d5a":"markdown","fa3728f6":"markdown","daf605d6":"markdown","eb3f74ff":"markdown","f23b1c05":"markdown","773b6e0e":"markdown","61a0e47f":"markdown","8d9b408e":"markdown","0291bb34":"markdown","dadc68ae":"markdown","923edeba":"markdown","797c5e6e":"markdown","841eb1d5":"markdown","b6d50653":"markdown","001dcb66":"markdown","597fb010":"markdown","49612cb5":"markdown","58e0aef8":"markdown","28bf4499":"markdown"},"source":{"efa42d04":"from pandas import read_csv\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nimport seaborn as sn\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV,train_test_split\nimport numpy as np\nimport imblearn\nfrom imblearn.over_sampling import RandomOverSampler\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import StandardScaler","30df7d8c":"zoo = pd.read_csv('..\/input\/zoo-animal-classification\/zoo.csv')\n","8cf7753a":"zoo.head(5)","950ba759":"zoo.shape","c14857c6":"zoo.info()","847f3416":"zoo[zoo.duplicated()]","3101ac82":"zoo.describe()","c6b02179":"zoo = pd.get_dummies(zoo,columns=['legs'])","19920672":"zoo.head()","170e8173":"zoo['class_type'].value_counts()","cc2e9f97":"sn.set(style = 'whitegrid', font_scale = 1.4)\nplt.subplots(figsize = (12,7))\nsn.countplot(x = 'class_type', data = zoo, palette = 'Pastel1')","463ef13e":"Y = zoo['class_type']\nY.head()","0903193d":"X = zoo.drop('animal_name',axis=1)","f8381176":"X = X.drop('class_type',axis=1)","8f49c971":"X.head()","41e7a225":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .2, random_state = 30, stratify = Y)","299673f7":"X_train.head()","76727dd9":"X_test.head()","17ac7e53":"Y_train.head()","381d61a5":"Y_test.head()","f0d822f2":"n_neighbors = np.array(range(1,40))\nparam_grid = dict(n_neighbors=n_neighbors)\nparam_grid","0a52e6aa":"model = KNeighborsClassifier()\ngrid = GridSearchCV(estimator=model, param_grid=param_grid,cv=10)\ngrid.fit(X_train, Y_train)\nprint(grid.best_params_)","2c6144e9":"import matplotlib.pyplot as plt \n%matplotlib inline\n# choose k between 1 to 41\nk_range = range(1, 41)\nk_scores = []\n# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, Y_train, cv=10)\n    k_scores.append(scores.mean())\n# plot to see clearly\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Accuracy')\nplt.show()","c83d9e20":"model = KNeighborsClassifier(n_neighbors =1).fit(X_train,Y_train)\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(Y_test,y_pred)\nprint(accuracy)","c6c1bcae":"confusion_matrix = confusion_matrix(Y_test,y_pred)\nprint (confusion_matrix)","d694f60d":"print(classification_report(Y_test,y_pred))","327116c7":"ros = RandomOverSampler(random_state = 30)","cbbe475c":"x_resample, y_resample = ros.fit_resample(X, Y)\ny_df = pd.DataFrame(y_resample)","d4503c24":"y_df.value_counts()","839e5a9c":"X_train, X_test, Y_train, Y_test = train_test_split(x_resample, y_resample, test_size = .2, random_state = 30, stratify = y_resample)","626140d7":"n_neighbors = np.array(range(1,40))\nparam_grid = dict(n_neighbors=n_neighbors)\n\nmodel = KNeighborsClassifier()\ngrid = GridSearchCV(estimator=model, param_grid=param_grid,cv=10)\ngrid.fit(X_train, Y_train)\nprint(grid.best_params_)","58cbf0a2":"import matplotlib.pyplot as plt \n%matplotlib inline\n# choose k between 1 to 41\nk_range = range(1, 41)\nk_scores = []\n# use iteration to caclulator different k in models, then return the average accuracy based on the cross validation\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    scores = cross_val_score(knn, X_train, Y_train, cv=10)\n    k_scores.append(scores.mean())\n# plot to see clearly\nplt.plot(k_range, k_scores)\nplt.xlabel('Value of K for KNN')\nplt.ylabel('Cross-Validated Accuracy')\nplt.show()","b192e2a1":"model = KNeighborsClassifier(n_neighbors =1).fit(X_train,Y_train)\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(Y_test,y_pred)\nprint(accuracy)","4cbc91ed":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(Y_test,y_pred)\nprint (confusion_matrix)","ac0a068c":"print(classification_report(Y_test,y_pred))","4cd6cf18":"# Using Over Sampling for balancing the data","f7af55d5":"# Using GridSearch for Algorithm Tuning after resampling","8a6fbab4":"##### After applying GridSearch, we got the best K (n_neighbors) value as 1, so we will be using the k= 1 for KNN Classifier algorithm","9d6a701f":"##### We can see the count of type 1 is very high","57e85c0c":"##### Our main objective is to be able to predict the classification(type) of the animals, based upon the variables.\n\n##### value_counts() method shows how many samples it is for the animal type. \n","759e48e7":"##### The precison and f1 score for type 5 is  low. Since the data is imbalanced, we can see the precision values are affected. We will use oversamping technique as the data is very less and undersampling will cause data loss","5a9a416e":"##### We will use RandomOverSampler (ROS) for sampling the the data to balance our data","9ef3a453":"##### Fitting the data using ROS ","21eacc09":"# Data Insights","c7c0b164":"##### We could see that the type 1 counts is very high and there is huge difference between the next highest count wich is 20 for type 2. The sets of data in which classes are not evenly distributed are called imbalanced datasets.The imbalance dataset can cause high\/low accuracy value of the model due to a certain class.","acf27e59":"##### The accuracy value is high for low values of k (less than 5) and it descreases as we increase values of k","9b28cf41":"##### We could see the data is resampled now and all the type values are 41 now. Previously only type 1 was 41. We will split the resampled data into training and test data and build a KNN model","eb23a1dd":"# Importing the libraries","61f50038":"##### We had identified the k=1 is best parameter with GridSearch so using k as 1","283682bb":"##### We could see that the model accuracy is very good for k values smaller than 5 and as the value increases the accuracy goes on decreasing","9a6230fb":"##### We could see the precision and recall values is 1 for all 7 types which is an excellent score. ","0c22d5a6":"# Using KNN with k=1 for model classification ","e1400d5a":"##### There are no duplicate values in our data","fa3728f6":"# Understanding the target variable","daf605d6":"# Separating feature data and Label data  and train-test split","eb3f74ff":"##### We can see there are no null values in our dataset. There are 16 variables with various traits to describe the animals. The traits are hair, feathers, eggs, milk, .......domestic,catsize.\n\n\n##### The purpose for this dataset is to be able to predict the classification(type) of the animals, based upon the variables.\n","f23b1c05":"##### We could see that all the feature attributes are encoded into 0 and 1 except legs. So we will use encoding technique on legs attribute as well.\n\n##### As all the other attributes are encoded using dummy encoding, we will use the same encoding for legs as well.","773b6e0e":"##### The accuracy is 1 which is 100% after applying sampling.  We will use confusion matrix and classification report to further check our accuracy","61a0e47f":"### Visualizing CV results","8d9b408e":"# Using KNN Classifier for prediction","0291bb34":"We can just peek into few data points by using head function of pandas. By default, head function return top 5 values ","dadc68ae":"# Summary statistics ","923edeba":"##### Implement a KNN model to classify the animals and predict they are of which animal type. The 7 Class Types are: Mammal, Bird, Reptile, Fish, Amphibian, Bug and Invertebrate\n","797c5e6e":"##### After applying GridSearch, we got the best K (n_neighbors) value as 1, so we will be using the k= 1 for KNN Classifier algorithm","841eb1d5":"# Loading the dataset","b6d50653":"##### We can see that the accuracy score which we have got for our model is 0.76 which is 76%. It is decent accuracy score. But the accuracy score can be misleading for imbalanced data. So we will use confusion matrix and classification report metrics further","001dcb66":"### Visualizing the accuracy with different k values on sampled data","597fb010":"### Observations :-","49612cb5":"# Problem statement","58e0aef8":"##### We will separate the class label data (type) and features data as Y and X respectively. Also, we will split the dataset into training and test data. The animal_name column is not required for classification as it is not a feature, so we will drop that column as well.","28bf4499":"# Grid search for Algorithm Tuning"}}