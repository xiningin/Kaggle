{"cell_type":{"f0368555":"code","0f75b806":"code","718224aa":"code","83271ff7":"code","58e6e037":"code","e08d4513":"code","fc3d1201":"code","54825e62":"code","00807879":"code","7d5badea":"code","2d451be2":"code","f693596f":"code","32d3c7e4":"code","58b274c2":"code","a70521b7":"markdown","db923a44":"markdown","e68c9119":"markdown","2bfafc5c":"markdown","2a189780":"markdown","a06c3807":"markdown","61a1c0e5":"markdown","88b85197":"markdown","11d7b4dc":"markdown","08afa72d":"markdown","dfc1cd87":"markdown","102b98f1":"markdown","bdf2b0eb":"markdown","09ad32aa":"markdown","ace4b93e":"markdown","29c45b26":"markdown","1a33f795":"markdown","59620a51":"markdown","c0e03f64":"markdown","1dbac6d4":"markdown"},"source":{"f0368555":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport pickle\nimport time\nimport gc\ngc.enable()\nimport warnings\nwarnings.filterwarnings(\"ignore\")","0f75b806":"print(os.listdir(\"..\/input\"))\n!ls -GFlash  ..\/input","718224aa":"%%time\n# import Dataset to play with it\ntrain_identity= pd.read_csv(\"..\/input\/train_identity.csv\", index_col='TransactionID')\ntrain_transaction= pd.read_csv(\"..\/input\/train_transaction.csv\", index_col='TransactionID')\ntest_identity= pd.read_csv(\"..\/input\/test_identity.csv\", index_col='TransactionID')\ntest_transaction = pd.read_csv('..\/input\/test_transaction.csv', index_col='TransactionID')\nprint (\"Done!\")","83271ff7":"print('Shape of Data:')\nprint(train_transaction.shape)\nprint(test_transaction.shape)\nprint(train_identity.shape)\nprint(test_identity.shape)","58e6e037":"# Creat our train & test dataset\n#%%time\ntrain = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)","e08d4513":"del train_identity,train_transaction,test_identity, test_transaction","fc3d1201":"train.info()","54825e62":"test.info()","00807879":"#Based on this great kernel https:\/\/www.kaggle.com\/arjanso\/reducing-dataframe-memory-size-by-65\ndef reduce_mem_usage(df):\n    start_mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in df.columns:\n        if df[col].dtype != object:  # Exclude strings            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",df[col].dtype)            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = df[col].max()\n            mn = df[col].min()\n            print(\"min for this col: \",mn)\n            print(\"max for this col: \",mx)\n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(df[col]).all(): \n                NAlist.append(col)\n                df[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = df[col].fillna(0).astype(np.int64)\n            result = (df[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < 65535:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        df[col] = df[col].astype(np.uint32)\n                    else:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)    \n            # Make float datatypes 32 bit\n            else:\n                df[col] = df[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",df[col].dtype)\n            print(\"******************************\")\n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return df, NAlist","7d5badea":"train, NAlist = reduce_mem_usage(train)\nprint(\"_________________\")\nprint(\"\")\nprint(\"Warning: the following columns have missing values filled with 'df['column_name'].min() -1': \")\nprint(\"_________________\")\nprint(\"\")\nprint(NAlist)","2d451be2":"test, NAlist = reduce_mem_usage(test)\nprint(\"_________________\")\nprint(\"\")\nprint(\"Warning: the following columns have missing values filled with 'df['column_name'].min() -1': \")\nprint(\"_________________\")\nprint(\"\")\nprint(NAlist)","f693596f":"train.info()","32d3c7e4":"test.info()","58b274c2":"train.to_pickle('train.pkl')\ntest.to_pickle('test.pkl')","a70521b7":"Then we shoud just delete some dt!","db923a44":"\n___MEMORY USAGE  BEFORE AND AFTER COMPLETION FOR TEST:___\n<br\/>\nMemory usage before running this script : 1693.867820739746  MB\n<br\/>\nMemory usage after running this script: ~ **480  MB**\n<br\/>\nThis is ~  28  % of the initial size","e68c9119":"What do we have in input","2bfafc5c":"Check again! our RAM. 2 GB has got free!","2a189780":"___MEMORY USAGE  BEFORE AND AFTER COMPLETION FOR TRAIN:___\n<br\/>\nMemory usage before running this script : 1975.3707885742188  MB\n<br\/>\nMemory usage after running this script  : ~ **480  MB**\n<br\/>\nThis is ~ 28 % of the initial size","a06c3807":"## How about other ways!\nI have used this [great kernel](https:\/\/www.kaggle.com\/arjanso\/reducing-dataframe-memory-size-by-65) but there are also other ways such as:\n1. https:\/\/www.dataquest.io\/blog\/pandas-big-data\/\n2. [optimizing-the-size-of-a-pandas-dataframe-for-low-memory-environment](https:\/\/medium.com\/@vincentteyssier\/optimizing-the-size-of-a-pandas-dataframe-for-low-memory-environment-5f07db3d72e)\n3. [pandas-making-dataframe-smaller-faster](https:\/\/www.ritchieng.com\/pandas-making-dataframe-smaller-faster\/)","61a1c0e5":"Reducing for test data set:","88b85197":" #  <div style=\"text-align: center\">  Reducing  Memory Size for IEEE <\/div> \n <div style=\"text-align:center\">  <\/div>\n![mem](http:\/\/s8.picofile.com\/file\/8367719234\/mem.png) \n<div style=\"text-align:center\"> last update: <b> 19\/07\/2019<\/b><\/div>\n","11d7b4dc":"## Import","08afa72d":"## Add this kernel as Dataset\nNow we just save our output as csv files. then you can simply add them to your own kernel.you will save time and  memory.","dfc1cd87":"![ram1](http:\/\/s9.picofile.com\/file\/8366931918\/ram1.png)","102b98f1":"## Import Dataset to play with it","bdf2b0eb":"### Before Reducing Memory\nWhen I have just read the data set and join them!I saw that the status of my RAM is more than 9GB!","09ad32aa":"# IEEE Reducing  Memory Size\nIt is necessary that after using this code, carefully check the output results for each column.","ace4b93e":"Reducing for train data set:","29c45b26":"![ram2](http:\/\/s8.picofile.com\/file\/8366932526\/ram2.png)\n3GB of RAM has got free! now just check the size of our train & test","1a33f795":"### Creat our train & test dataset","59620a51":"![ram3](http:\/\/s8.picofile.com\/file\/8366940442\/ram3.png)","c0e03f64":"Input - Competition Data\nOutput - Shortened transaction + Identity files for train & test \nNext kernel - https:\/\/www.kaggle.com\/priteshshrivastava\/ieee-pipeline-1-create-validation-set","1dbac6d4":"## Objective of the Kernel: Save Time & Memory\nIf you would like to create a kernel for this Competition. this is a good idea to add this kernel as a **data set** to your own kernel. due to you can save your time and memory."}}