{"cell_type":{"a3c66d05":"code","d6f17345":"code","f3e0c29e":"code","83cc26d0":"code","aad852ca":"code","93f1d6a8":"code","a1bdec22":"code","9a261da1":"code","efb2c04c":"code","83b408ce":"code","60cd8f9f":"code","184287a0":"code","07bb782a":"code","d2ec9080":"code","a638e903":"code","2dde4e28":"code","bd092bd2":"code","c5fa3dd6":"code","564036a6":"code","03a3f9e7":"code","66a59d39":"code","e75d15e1":"code","6658df2d":"code","1450d98f":"code","cce98a3e":"code","115b8b1f":"code","51c6a87e":"code","d0b82fec":"code","5499a88a":"code","66491b9e":"code","adef083c":"code","5587b10b":"code","a1d1bf36":"code","e1b73693":"code","836de25d":"markdown","7e661931":"markdown","d49fb495":"markdown","146033be":"markdown","575cb5c5":"markdown","80bb5a1d":"markdown","a5070b90":"markdown","5be2cf88":"markdown","618c6a02":"markdown","b72f4063":"markdown","8c2d16a7":"markdown","9a063b8f":"markdown","198ce399":"markdown","c7d289c4":"markdown","85e264e0":"markdown","354a8223":"markdown","75c10aae":"markdown","1c27aa98":"markdown","dd99a49f":"markdown","5af3596b":"markdown","fbef3a01":"markdown","b73ff619":"markdown","58b15132":"markdown","34d71e74":"markdown","e435b288":"markdown","1ea881db":"markdown","0cfa684a":"markdown","2d2a69bb":"markdown","a4927c3a":"markdown","a819773c":"markdown","ce8a8ee3":"markdown","c2a5bf97":"markdown","1738239d":"markdown","c6838432":"markdown","c3d7cb8f":"markdown","d0f5e26d":"markdown","607d13f1":"markdown","3660c491":"markdown","45c684c5":"markdown","3b08f3ca":"markdown","f1b32407":"markdown","bf9a15a5":"markdown","942b84d3":"markdown","46eddf18":"markdown","ee60e55b":"markdown","ee9dab68":"markdown","f132d40b":"markdown","8656663e":"markdown","df3010fe":"markdown","9fec87c7":"markdown","197e2c8d":"markdown","55779f16":"markdown","af170cc5":"markdown","6a8aa21c":"markdown","f7607807":"markdown","90a720ba":"markdown","54af9200":"markdown","4cc8fff2":"markdown","1901786d":"markdown"},"source":{"a3c66d05":"# importing the libraries\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","d6f17345":"# reading the dataset\ndf = pd.read_csv('..\/input\/amazon-baby-products\/amazon_baby.csv')","f3e0c29e":"# viewing the first few rows\ndf.head()","83cc26d0":"# checking for number of reviews received by each product\ndf.name.value_counts()","aad852ca":"# checking for products that recieved more than 15 reviews\ndf.name.value_counts().loc[lambda x : x > 15]","93f1d6a8":"# checking for missing values\ndf.isnull().sum()","a1bdec22":"# removing the entries with missing reviews\ndf = df[df.review.notna()]","9a261da1":"# creating a dictionary with contractions and their expansions\ncontractions = {\n\"a'ight\":\"alright\",\n\"ain't\":\"are not\",\n\"amn't\":\"am not\",\n\"aren't\":\"are not\",\n\"can't\":\"cannot\",\n\"'cause\": \"because\",\n\"could've\":\"could have\",\n\"couldn't\":\"could not\",\n\"couldn't've\":\"could not have\",\n\"daren't\":\"dare not\",\n\"daresn't\":\"dare not\",\n\"dasn't\":\"dare not\",\n\"didn't\":\"did not\",\n\"doesn't\":\"does not\",\n\"don't\":\"do not\",\n\"everybody's\":\"everybody is\",\n\"everyone's\":\"everyone is\",\n\"giv'n\":\"given\",\n\"gonna\":\"going to\",\n\"gon't\":\"go not\", \n\"gotta\":\"got to\",\n\"hadn't\":\"had not\",\n\"had've\":\"had have\",\n\"hasn't\":\"has not\",\n\"haven't\":\"have not\",\n\"he'd\":\"he had\", \n\"he'll\":\"he will\",\n\"he's\":\"he is\",\n\"here's\":\"here is\",\n\"how'd\":\"how did\",\n\"how'll\":\"how will\",\n\"how're\":\"how are\",\n\"how's\":\"how is\",\n\"I'd\":\"I had\",\n\"I'd've\":\"I would have\",\n\"I'd'nt\":\"I would not\",\n\"I'd'nt've\":\"I would not have\",\n\"I'll\":\"I will\",\n\"I'm\":\"I am\",\n\"I've\":\"I have\",\n\"isn't\":\"is not\",\n\"it'd\":\"it would\",\n\"it'll\":\"it will\",\n\"it's\":\"it is\",\n\"let's\":\"let us\",\n\"ma'am\":\"madam\",\n\"mayn't\":\"may not\",\n\"may've\":\"may have\",\n\"mightn't\":\"might not\",\n\"might've\":\"might have\",\n\"mustn't\":\"must not\",\n\"mustn't've\":\"must not have\",\n\"must've\":\"must have\",\n\"needn't\":\"need not\",\n\"needn't've\":\"need not have\",\n\"o'clock\":\"of the clock\",\n\"oughtn't\":\"ought not\",\n\"oughtn't've\":\"ought not have\",\n\"shan't\":\"shall not\",\n\"she'd\":\"she would\",\n\"she'll\":\"she will\",\n\"she's\":\"she is\",\n\"should've\":\"should have\",\n\"shouldn't\":\"should not\",\n\"shouldn't've\":\"should not have\",\n\"somebody's\":\"somebody is\",\n\"someone's\":\"someone is\",\n\"something's\":\"something is\",\n\"so're\":\"so are\",\n\"so\u2019s\":\"so is\",\n\"so\u2019ve\":\"so have\",\n\"that'll\":\"that will\",\n\"that're\":\"that are\",\n\"that's\":\"that is\",\n\"that'd\":\"that would\",\n\"there'd\":\"there would\",\n\"there'll\":\"there will\",\n\"there're\":\"there are\",\n\"there's\":\"there is\",\n\"these're\":\"these are\",\n\"these've\":\"these have\",\n\"they'd\":\"they would\",\n\"they'll\":\"they will\",\n\"they're\":\"they are\",\n\"they've\":\"they have\",\n\"this's\":\"this is\",\n\"those're\":\"those are\",\n\"those've\":\"those have\",\n\"to've\":\"to have\",\n\"wasn't\":\"was not\",\n\"we'd\":\"we would\",\n\"we'd've\":\"we would have\",\n\"we'll\":\"we will\",\n\"we're\":\"we are\",\n\"we've\":\"we have\",\n\"weren't\":\"were not\",\n\"what'd\":\"what did\",\n\"what'll\":\"what will\",\n\"what're\":\"what are\",\n\"what's\":\"what is\",\n\"what've\":\"what have\",\n\"when's\":\"when is\",\n\"where'd\":\"where did\",\n\"where'll\":\"where will\",\n\"where're\":\"where are\",\n\"where's\":\"where is\",\n\"where've\":\"where have\",\n\"which'd\":\"which would\",\n\"which'll\":\"which will\",\n\"which're\":\"which are\",\n\"which's\":\"which is\",\n\"which've\":\"which have\",\n\"who'd\":\"who would\",\n\"who'd've\":\"who would have\",\n\"who'll\":\"who will\",\n\"who're\":\"who are\",\n\"who's\":\"who is\",\n\"who've\":\"who have\",\n\"why'd\":\"why did\",\n\"why're\":\"why are\",\n\"why's\":\"why is\",\n\"won't\":\"will not\",\n\"would've\":\"would have\",\n\"wouldn't\":\"would not\",\n\"wouldn't've\":\"would not have\",\n\"y'at\":\"you at\",\n\"yes\u2019m\":\"yes madam\",\n\"you'd\":\"you would\",\n\"you'll\":\"you will\",\n\"you're\":\"you are\",\n\"you've\":\"you have\"}","efb2c04c":"# custom made function to convert contraction to expansion\ndef cont_to_exp(x):\n    if type(x) is str:\n        x = x.replace('\\\\','')\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key, value)\n        return x\n    else:\n        return x","83b408ce":"# converting contraction to expansion in every row of the review column\ndf['review'] = df['review'].apply(lambda x:cont_to_exp(x))","60cd8f9f":"# importing the text blob package\nfrom textblob import TextBlob","184287a0":"# polarity column\ndf['polarity'] = df['review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n\n# review length column\ndf['review_len'] = df['review'].apply(lambda x:len(x))\n\n# word count column\ndf['word_count'] = df['review'].apply(lambda x: len(x.split()))","07bb782a":"# custom made function to calculate and return average word length\ndef get_avg_word_len(x):\n    words = x.split()\n    word_len = 0\n    for word in words:\n        word_len = word_len + len(word)\n        \n    return word_len\/len(words) ","d2ec9080":"# calculating average word length of every review\ndf['avg_word_len'] = df['review'].apply(lambda x: get_avg_word_len(x))","a638e903":"# histogram for polarity\ndf['polarity'].hist(bins=20)\nplt.xlabel('polarity')\nplt.ylabel('count')\nplt.title('Sentiment Polarity Distribution')","2dde4e28":"# histogram for review length\ndf['review_len'].hist(bins=20)\nplt.xlabel('review length')\nplt.ylabel('count')\nplt.title('Review Text Length Distribution')","bd092bd2":"# histogram for word count\ndf['word_count'].hist(bins=20)\nplt.xlabel('word count')\nplt.ylabel('count')\nplt.title('Word Count Distribution')","c5fa3dd6":"# line chart for polarity considering rating\ndf.groupby(by='rating').polarity.agg([np.mean]).plot()\nplt.xlabel('rating')\nplt.ylabel('polarity')\nplt.title('Polarity considering Rating')","564036a6":"# barplot for count of reviews for each rating\ndf.groupby(by='rating').review.count().plot.bar()\nplt.xlabel('rating')\nplt.ylabel('no. of reviews')\nplt.title('count of the reviews of each rating')","03a3f9e7":"# obtaining top 20 products based on polarity\ndf.sort_values(by='polarity', ascending=False)[0:20]","66a59d39":"# checking for change in review length\nsns.barplot(x='rating', y='review_len', data=df, ci=None)\nplt.xlabel('rating')\nplt.ylabel('review length')\nplt.title('Review Length vs Rating')","e75d15e1":"# importing CountVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer","6658df2d":"# custom made function to return the top n unigrams\ndef get_top_n_words(x, n=25):\n    vec = CountVectorizer(stop_words='english').fit(x)\n    bag_of_words = vec.transform(x)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","1450d98f":"# calling function and storing result in a variable\ncommon_words = get_top_n_words(df['review'], 25)\ncommon_words","cce98a3e":"# creating a dataframe from the returned list\ndf1 = pd.DataFrame(common_words, columns = ['Unigram Text' , 'Count'])\n\n# setting index to be unigrams\ndf1.set_index('Unigram Text', drop=True, inplace=True)","115b8b1f":"# barplot to represent the frequency of unigrams\ndf1.plot.bar()\nplt.xlabel('unigrams')\nplt.ylabel('count')\nplt.title('Unigrams Count')","51c6a87e":"# custom made function to return the top n bigrams\ndef get_top_n_bigram(x, n=25):\n    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(x)\n    bag_of_words = vec.transform(x)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","d0b82fec":"# calling function and storing result in a variable\ncommon_words = get_top_n_bigram(df['review'], 25)\ncommon_words","5499a88a":"# creating a dataframe from the returned list\ndf2 = pd.DataFrame(common_words, columns = ['Bigram Text' , 'Count'])\n\n# setting index to be bigrams\ndf2.set_index('Bigram Text', drop=True, inplace=True)","66491b9e":"# barplot to represent the frequency of bigrams\ndf2.plot.bar()\nplt.xlabel('bigrams')\nplt.ylabel('count')\nplt.title('Bigrams Count')","adef083c":"# custom made function to return the top n trigrams\ndef get_top_n_trigram(x, n=25):\n    vec = CountVectorizer(ngram_range=(3, 3), stop_words=\"english\").fit(x)\n    bag_of_words = vec.transform(x)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","5587b10b":"# calling function and storing result in a variable\ncommon_words = get_top_n_trigram(df['review'], 25)\ncommon_words","a1d1bf36":"# creating a dataframe from the returned list\ndf3 = pd.DataFrame(common_words, columns = ['Trigram Text' , 'Count'])\n\n# setting index to be trigrams\ndf3.set_index('Trigram Text', drop=True, inplace=True)","e1b73693":"# barplot to represent the frequency of trigrams\ndf3.plot.bar()\nplt.xlabel('trigrams')\nplt.ylabel('count')\nplt.title('Trigrams Count')","836de25d":"As we can see, there are 829 missing values in the review column. To remove them, we filter the dataframe by using the notna() function from the Pandas library on the review column.","7e661931":"As we can see, except rating 5, the review length for ratings 1, 2, 3 and 4 is more or less the same, and the review length for rating 5 is significantly lesser than the other ratings.","d49fb495":"To sovle Question 8, we use the groupby() function from the Pandas library to group the dataset by rating, then we use the count() function to count the number of reviews received by each rating, and finally we use the plot.bar() function from the Pandas library to plot a barplot to display the number of reviews received by each rating. We also use matplotlib aesthetic functions to enhance the readability of the graph.","146033be":"To solve Question 2, we use the value_counts() function from the Pandas library on the name column in the dataframe and then use the loc() and lambda functions to extract all those items having more than 15 reviews.","575cb5c5":"After that, we call the previously created function and pass the review column and specify n to be 25, and store the returned value in a variable.","80bb5a1d":"After that, we use the plot.bar() function from the Pandas library to plot a barplot of the trigrams and their frequencies. We also use matplotlib aesthetic functions to enhance the readability of the chart.","a5070b90":"Next, we create a custom made function to convert the contractions to expansions. This function loops over the previously created dictionary and uses the replace() function from the string library to replace the contractions with the expansions.","5be2cf88":"Next, we create three new columns,\n\n-   polarity: to store polarity by using the sentiment polarity parameter of the TextBlob function and lambda function\n-   review_len: to store review length by using the len() and lambda functions\n-   word_count: to store word count by using the len(), split() and lambda functions","618c6a02":"As we can see, the distribution of review length is highly right skewed. ","b72f4063":"Next, we read the dataset. To do this, we use the read_csv() function from the Pandas library.","8c2d16a7":"To solve Question 1, we use the value_counts() function from the Pandas library on the name column in the dataframe.","9a063b8f":"Next, we create a dataframe of the returned list using the DataFrame() function from the Pandas library and set the index to be the Trigrams to make our further analysis easier.","198ce399":"#### *Q5.* Add the Polarity, length of the review, the word count and average word length of each review.","c7d289c4":"#### *Q10.* Visualize to check whether the review length changes with rating.","85e264e0":"As we can see, the bigram 'car seat' has the highest frequency, and is closely followed by 'month old'.","354a8223":"To solve Question 10, we use the barplot() function from the Seaborn library, and plot the rating column on the x-axis and review length on the y-axis. We also use aesthetic functions from the matplotlib library to make the plot more readable.","75c10aae":"To visualize the distribution of unigrams, we create a custom made function to get the top n unigrams\/ words. This function uses CountVectorizer to generate unigrams from the review after removing the stop words, calculates the frequency of each unigram, then splices and returns the top n unigrams and their frequency sorted in the descending order based on frequency.","1c27aa98":"#### *Q2.* Check the products that have more than 15 reviews.","dd99a49f":"To start, we import the following packages:\n\n-   NumPy: for data manipulation\n-   Pandas: for data manipulation\n-   MatPlotLib: for data visualization\n-   Seaborn: for data visualization","5af3596b":"After that, we call the previously created function and pass the review column and specify n to be 25, and store the returned value in a variable.","fbef3a01":"To solve Question 3, we use the isnull() function from the Pandas library and then sum over them using the sum() function.","b73ff619":"To solve Question 4, we first create a dictionary with all the contractions and their expansions. ","58b15132":"#### *Q4.* Clean the data and replace the contractions with their expansions.","34d71e74":"To solve Question 9, we use the sort_values() function from the Pandas library, and set the parameters by to polarity and ascending to False to sort the dataframe by the polarity column in the descening order. Then we splice the resultant dataset to obtain the top 20 values.","e435b288":"After that, we use the plot.bar() function from the Pandas library to plot a barplot of the bigrams and their frequencies. We also use matplotlib aesthetic functions to enhance the readability of the chart.","1ea881db":"#### *Q8.* Visualize the count of the reviews of each rating available in the dataset.","0cfa684a":"After that, we apply the function on every observation in the review column. To do that, we use the apply() function from the Pandas library and the lambda function.","2d2a69bb":"As we can see, we have received a list of tuples containing the top 25 trigrams and their frequencies.","a4927c3a":"To solve Question 5, we first import the textblob package.","a819773c":"#### *Q3.* Find any missing review are present or not, If present remove those data.","ce8a8ee3":"As we can see, the trigram 'month old son' has the highest frequency.","c2a5bf97":"As we can see, the distribution of word count is highly right skewed.","1738239d":"As we can see, the distribution of polarity is more or less normal, may be slightly left skewed. Also, since the graph peaks in the first quadrant, most of the reviews are positive.","c6838432":"As we can see, as the rating increases, the polarity also increases positively.","c3d7cb8f":"After that, we view the first few rows of the dataset using the head() function from the Pandas library.","d0f5e26d":"To solve Question 11, we first import the CountVectorizer module from the sklearn library.","607d13f1":"After that, we call the previously created function and pass the review column and specify n to be 25, and store the returned value in a variable.","3660c491":"To solve Question 7, we use the groupby() function to group the dataframe based on rating, the agg() function on the polarity column of the grouped dataframe to aggregate the polarity based on mean, calculated using np.mean, and then the plot() function to plot a line chart of polarity considering rating. All these functions are from the Pandas library. We also use matplotlib aesthetic functions to enhance the readability of the plot.","45c684c5":"Author: Khushee Kapoor\n\nLast Updated: 4\/1\/22","3b08f3ca":"#### *Q6.* Visualize the distribution of the word count, review length, and polarity.","f1b32407":"To visualize the distribution of trigrams, we create a custom made function to get the top n trigrams. This function uses CountVectorizer to generate trigrams from the review after removing the stop words, calculates the frequency of each trigram, then splices and returns the top n trigrams and their frequency sorted in the descending order based on frequency.","bf9a15a5":"As we can see, the number of items has drastically reduced and there are only 2339 products now.","942b84d3":"As we can see, we have received a list of tuples containing the top 25 bigrams and their frequencies.","46eddf18":"#### *Q1.*  Check the number of the reviews received for each product.","ee60e55b":"To visualize the distribution of bigrams, we create a custom made function to get the top n bigrams. This function uses CountVectorizer to generate bigrams from the review after removing the stop words, calculates the frequency of each bigram, then splices and returns the top n bigrams and their frequency sorted in the descending order based on frequency.","ee9dab68":"As we can see, there are 32415 items in the dataset and Vulli Sophie the Giraffe Teether has the highest reviews, and Bloom Universal Snug, Coconut White has the lowest reviews.","f132d40b":"As we can see, we have received a list of tuples containing the top 25 unigrams and their frequencies.","8656663e":"As we can see, the word 'baby' has the highest freqency in all the reviews.","df3010fe":"After that, we apply the function on every observation in the review column. To do that, we use the apply() function from the Pandas library and the lambda function.","9fec87c7":"As we can see, the highest rating has received the highest number of reviews, followed by rating 4, rating 3, rating 1, and rating 2. ","197e2c8d":"Next, we create a dataframe of the returned list using the DataFrame() function from the Pandas library and set the index to be the Unigrams to make our further analysis easier.","55779f16":"Following that, we create a custom made function to calculate the average word length. This function divided the total length of all the words combined by the total number of words in every entry.","af170cc5":"Next, we create a dataframe of the returned list using the DataFrame() function from the Pandas library and set the index to be the Bigrams to make our further analysis easier.","6a8aa21c":"#### *Q11.* Visualize the distribution of Top 25 Unigram, Bigram and Trigram.","f7607807":"#### *Q9.* List the Top 20 products based on the polarity.","90a720ba":"#### *Q7.* Visualize polarity considering the rating.","54af9200":"After that, we use the plot.bar() function from the Pandas library to plot a barplot of the unigrams and their frequencies. We also use matplotlib aesthetic functions to enhance the readability of the chart.","4cc8fff2":"To solve Question 6, we use the hist() function from the Pandas library and matplotlib aesthetic functions to plot histograms for every column.","1901786d":"# Text Analysis"}}