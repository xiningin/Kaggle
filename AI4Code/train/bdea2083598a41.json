{"cell_type":{"e98911be":"code","8d882baf":"code","8459ba77":"code","3505faa7":"code","c3e33982":"code","f6e29b9c":"code","3246182d":"code","52a76417":"code","2cb551b1":"code","368dd8dd":"code","f1beaecc":"code","d583acf2":"code","5424a9c7":"code","135dfdc3":"code","b135d765":"code","e71a5098":"code","12e5b9a3":"code","cb6c8787":"markdown","15c316d3":"markdown"},"source":{"e98911be":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8d882baf":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\nimport tensorflow as tf \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, LeakyReLU, Dense, Dropout\nimport matplotlib.pyplot as plt \nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau","8459ba77":"#We don't have train\/test so let's see how  it works\n\ntrain_path = \"\/kaggle\/input\/manga-facial-expressions\"\ntest_path = \"\/kaggle\/input\/manga-facial-expressions\"","3505faa7":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\nx = plt.imread(\"\/kaggle\/input\/manga-facial-expressions\/pleased\/003_437_960_366_366.png\")\nx.shape","c3e33982":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255.)","f6e29b9c":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\ntrain = datagen.flow_from_directory(train_path,target_size=(48,48),class_mode=\"sparse\", seed=1, color_mode=\"grayscale\", batch_size=128)\ntest = datagen.flow_from_directory(test_path,target_size=(48,48),class_mode=\"sparse\", seed=1, color_mode=\"grayscale\", batch_size=128)","3246182d":"dir(train)","52a76417":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\nprint(train.class_indices)\nemotion_dict = {0: \"angry\", 1: \"crying\", 2: \"embarassed\", 3: \"happy\", 4: \"pleased\", 5: \"sad\", 6: \"shock\"}","2cb551b1":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\nx, y = train.next()\nprint(x.shape, y.shape)\ntrain.reset()","368dd8dd":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\nmodel = Sequential([\n    Conv2D(32, (3,3), input_shape=(48,48,1),padding=\"same\"),\n    LeakyReLU(),\n    Conv2D(32, (3,3), padding=\"same\"),\n    LeakyReLU(),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n    Dropout(0.2),\n    \n    Conv2D(64,(3,3),padding=\"same\"),\n    LeakyReLU(),\n    Conv2D(64,(3,3), padding=\"same\"),\n    LeakyReLU(),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n    Dropout(0.3),\n    \n    Conv2D(128,(3,3),padding=\"same\"),\n    LeakyReLU(),\n    Conv2D(128,(3,3), padding=\"same\"),\n    LeakyReLU(),\n    Conv2D(128,(3,3), padding=\"same\"),\n    LeakyReLU(),\n    BatchNormalization(),\n    MaxPooling2D((2,2)),\n    Dropout(0.4),\n    \n    Flatten(),\n#     tf.keras.layers.GlobalAveragePooling2D(),\n#     Dropout(0.4),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.4),\n#     Dense(64, activation=\"relu\"),\n    \n    Dense(len(train.class_indices), activation=\"softmax\")\n])\nmodel.summary()\nmodel.compile(\n    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), \n    loss='sparse_categorical_crossentropy', \n    metrics=['accuracy']\n)","f1beaecc":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\nnet = Sequential(name='DCNN')\n\nnet.add(\n    Conv2D(\n        filters=64,\n        kernel_size=(5,5),\n        input_shape=(48, 48, 1),\n        activation='elu',\n        padding='same',\n        kernel_initializer='he_normal',\n        name='conv2d_1'\n    )\n)\nnet.add(BatchNormalization(name='batchnorm_1'))\nnet.add(\n    Conv2D(\n        filters=64,\n        kernel_size=(5,5),\n        activation='elu',\n        padding='same',\n        kernel_initializer='he_normal',\n        name='conv2d_2'\n    )\n)\nnet.add(BatchNormalization(name='batchnorm_2'))\n\nnet.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\nnet.add(Dropout(0.4, name='dropout_1'))\n\nnet.add(\n    Conv2D(\n        filters=128,\n        kernel_size=(3,3),\n        activation='elu',\n        padding='same',\n        kernel_initializer='he_normal',\n        name='conv2d_3'\n    )\n)\nnet.add(BatchNormalization(name='batchnorm_3'))\nnet.add(\n    Conv2D(\n        filters=128,\n        kernel_size=(3,3),\n        activation='elu',\n        padding='same',\n        kernel_initializer='he_normal',\n        name='conv2d_4'\n    )\n)\nnet.add(BatchNormalization(name='batchnorm_4'))\n\nnet.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\nnet.add(Dropout(0.4, name='dropout_2'))\n\nnet.add(\n    Conv2D(\n        filters=256,\n        kernel_size=(3,3),\n        activation='elu',\n        padding='same',\n        kernel_initializer='he_normal',\n        name='conv2d_5'\n    )\n)\nnet.add(BatchNormalization(name='batchnorm_5'))\nnet.add(\n    Conv2D(\n        filters=256,\n        kernel_size=(3,3),\n        activation='elu',\n        padding='same',\n        kernel_initializer='he_normal',\n        name='conv2d_6'\n    )\n)\nnet.add(BatchNormalization(name='batchnorm_6'))\n\nnet.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\nnet.add(Dropout(0.5, name='dropout_3'))\n\nnet.add(Flatten(name='flatten'))\n\nnet.add(\n    Dense(\n        128,\n        activation='elu',\n        kernel_initializer='he_normal',\n        name='dense_1'\n    )\n)\nnet.add(BatchNormalization(name='batchnorm_7'))\n\nnet.add(Dropout(0.6, name='dropout_4'))\n\nnet.add(\n    Dense(\n        7,\n        activation='softmax',\n        name='out_layer'\n    )\n)\n\nnet.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nnet.summary()","d583acf2":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","5424a9c7":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00005,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n]","135dfdc3":"model.fit(train, validation_data=test, epochs=20, callbacks=callbacks)","b135d765":"model.save('63.h5')","e71a5098":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\nx,y = test.next()\npreds = model.predict(x)\nidx = np.argmax(preds, axis = 1)\n# idx.shape\nprint('correct prediction:', np.sum((y == idx)*1)\/128)","12e5b9a3":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection\n\nfig = plt.figure(1, (14, 14))\n\nk = 0\nfor j in range(49):\n    px = x[j]\n    k += 1\n    ax = plt.subplot(7, 7, k)\n    ax.imshow(px, cmap='gray')\n    ax.set_xticks([])\n    ax.set_yticks([])\n    \n    if  emotion_dict[y[j]] == emotion_dict[idx[j]]:\n        for axis in ['top','bottom','left','right']:\n            ax.spines[axis].set_linewidth(5)\n            ax.spines[axis].set_color('green')\n        ax.set_title(emotion_dict[idx[j]])\n\n    else:\n        for axis in ['top','bottom','left','right']:\n            ax.spines[axis].set_linewidth(5)\n            ax.spines[axis].set_color('red')\n        ax.set_title('P:'+emotion_dict[idx[j]]+\" C:\"+emotion_dict[y[j]])\n    plt.tight_layout()","cb6c8787":"#Code by Hitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection","15c316d3":"#Acknowledgement\n\nHitesh Kumar https:\/\/www.kaggle.com\/hitzz97\/emotion-detection"}}