{"cell_type":{"60f574a0":"code","c75746c7":"code","d3b13740":"code","3312d898":"code","5fd9765d":"code","88bebf3f":"code","ba975695":"code","fd3420cc":"code","3b0e71ef":"code","66c68a46":"code","6b1aee43":"code","7c9e1d41":"code","5b583f3d":"code","3bd22b6e":"code","78943d21":"code","0d2616ce":"code","4e3f5848":"code","ed390c44":"code","b267e8af":"code","5cc702c1":"markdown","ef8ac28e":"markdown","84e3164e":"markdown","90ff650b":"markdown","3306238f":"markdown","b2996d08":"markdown","bfe2858e":"markdown","a47d8367":"markdown","a1be081d":"markdown","cd0f7fc4":"markdown","44d25434":"markdown","a76b6ade":"markdown","8d4e84f9":"markdown","f243697d":"markdown","a1cbdce5":"markdown","a845b2f4":"markdown"},"source":{"60f574a0":"import numpy as np\nimport pandas as pd\nimport os\nimport math\nimport matplotlib.pyplot as plt\nimport cv2\nimport random\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n\nfrom skimage import data\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization, Input\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping","c75746c7":"MONET_JPG_PATH = '..\/input\/gan-getting-started\/monet_jpg\/'\nPHOTO_JPG_PATH = '..\/input\/gan-getting-started\/photo_jpg\/'\n\nprint('Number of images in Monet directory: ', len(os.listdir(MONET_JPG_PATH)))\nprint('Number of images in Photo directory: ', len(os.listdir(PHOTO_JPG_PATH)))","d3b13740":"shapes_set = set()\nimage_names = os.listdir(MONET_JPG_PATH)\nfor img_name in image_names:\n    img = cv2.imread(os.path.join(MONET_JPG_PATH, img_name))\n    shapes_set.add(img.shape)\n\nprint('Number of unique image shapes inside Monet directory: ', len(shapes_set))\nprint('Image shape sizes: ', shapes_set.pop())\n\nshapes_set = set()\nimage_names = os.listdir(PHOTO_JPG_PATH)\nfor img_name in image_names:\n    img = cv2.imread(os.path.join(PHOTO_JPG_PATH, img_name))\n    shapes_set.add(img.shape)\n    \nprint('Number of unique image shapes inside Photo directory: ', len(shapes_set))\nprint('Image shape sizes: ', shapes_set.pop())","3312d898":"def visualize_images(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    w = int(n_images ** .5)\n    h = math.ceil(n_images \/ w)\n    \n    all_names = os.listdir(path)\n    image_names = all_names[:n_images]   \n    if is_random:\n        image_names = random.sample(all_names, n_images)\n            \n    for ind, image_name in enumerate(image_names):\n        img = cv2.imread(os.path.join(path, image_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        plt.subplot(h, w, ind + 1)\n        plt.imshow(img)\n        plt.xticks([])\n        plt.yticks([])\n    \n    plt.show()","5fd9765d":"visualize_images(MONET_JPG_PATH, 9)","88bebf3f":"visualize_images(PHOTO_JPG_PATH, 9)","ba975695":"def show_color_histogram(path):\n    image_names = os.listdir(path)\n    image_name = random.choice(image_names)\n    img = cv2.imread(os.path.join(path, image_name))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    fig = make_subplots(1, 2)\n\n    fig.add_trace(go.Image(z=img), 1, 1)\n    for channel, color in enumerate(['red', 'green', 'blue']):\n        fig.add_trace(\n            go.Histogram(\n                x=img[..., channel].ravel(), \n                opacity=0.5,\n                marker_color=color, \n                name='%s channel' %color), \n            1, \n            2\n        )\n    fig.update_layout(height=400)\n    fig.show()","fd3420cc":"show_color_histogram(MONET_JPG_PATH)","3b0e71ef":"show_color_histogram(PHOTO_JPG_PATH)","66c68a46":"X = list()\ny = list()\n\nimage_names = os.listdir(MONET_JPG_PATH)\nfor img_name in image_names:\n    img = cv2.imread(os.path.join(MONET_JPG_PATH, img_name))\n    X.append(img)\n    y.append(1)\n\nimage_names = os.listdir(PHOTO_JPG_PATH)\nfor img_name in image_names:\n    img = cv2.imread(os.path.join(PHOTO_JPG_PATH, img_name))\n    X.append(img)\n    y.append(0)\n    \nX = np.stack(X)\ny = np.stack(y)","6b1aee43":"X = X.astype('float32') \/ 255.\ny = to_categorical(y)\nX, X_test, y, y_test = train_test_split(X, y, random_state=666, test_size=0.2, shuffle=True)","7c9e1d41":"def recall_score(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    return recall\n\ndef precision_score(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    return precision\n\ndef keras_f1_score(y_true, y_pred):\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","5b583f3d":"data_augmentation = tf.keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        layers.experimental.preprocessing.RandomRotation(0.2),\n        layers.experimental.preprocessing.RandomRotation(0.5),\n    ]\n)","3bd22b6e":"def create_model():\n    input_img = Input(shape=(256, 256, 3))\n    x = data_augmentation (input_img)\n    x = Conv2D(16, kernel_size=(3, 3), activation='elu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = BatchNormalization()(x)\n\n    x = Conv2D(32, kernel_size=(3, 3), activation='elu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = BatchNormalization()(x)\n    \n    x = Conv2D(16, kernel_size=(3, 3), activation='elu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.2)(x)\n    \n    x = Flatten()(x)\n    x = Dense(128, activation='sigmoid')(x)\n    out = Dense(2, activation = 'softmax')(x)\n\n    model = tf.keras.Model(input_img, out)\n    model.compile(\n        loss=tf.keras.losses.binary_crossentropy, \n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n        metrics=[keras_f1_score]\n    )\n    \n    return model","78943d21":"class_weight = {\n    0: 1.,\n    1: 20.\n}","0d2616ce":"model = create_model()","4e3f5848":"early_stopping = EarlyStopping(\n    patience=4, \n    verbose=1\n)\n\nmodel.fit(\n    X, \n    y, \n    validation_split=0.2, \n    batch_size=18, \n    epochs=100,\n    verbose=1, \n    class_weight=class_weight,  \n    callbacks=[early_stopping]\n)","ed390c44":"preds = model.predict(X_test)\npreds = np.argmax(preds, axis=1)\ny_test = np.argmax(y_test, axis=1)\nconfusion_matrix(y_test, preds)","b267e8af":"print('Accuracy: ', accuracy_score(y_test, preds))\nprint('F1-score: ', f1_score(y_test, preds))","5cc702c1":"To fight with imbalanced data let's try to use class_weights.","ef8ac28e":"Let's see number of images for every directory. We wiill work here only with .jpg images.","84e3164e":"<h1><center>Monet masterpieces. EDA and image classification<\/center><\/h1>\n\n<center><img src=\"https:\/\/painting-planet.com\/images\/1\/image178.jpg\"><\/center>","90ff650b":"Monet pictures","3306238f":"Let's see image woth corresponded color's histogram","b2996d08":"Now it is time to check shapes of images.","bfe2858e":"<a id=\"2\"><\/a>\n<h2 style='background:Caribbean green; border:0; color:white'><center>Classifier training<center><h2>","a47d8367":"So all images in our dataser have the same shapes.","a1be081d":"Photos","cd0f7fc4":"Photos","44d25434":"<a id=\"1\"><\/a>\n<h2 style='background:Caribbean green; border:0; color:white'><center>1. Data overview<center><h2>","a76b6ade":"Let's visualize some images from both sets. Code for this is taken from https:\/\/www.kaggle.com\/ihelon\/monet-eda.","8d4e84f9":"Let's build simple image classifier and see how difficult to detect Monet's pictures.","f243697d":"Monet picture","a1cbdce5":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Caribbean green; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h3>\n\n* [1. Data overview](#1)\n* [2. Classifier training](#2)","a845b2f4":"Here we drfine metrics for imbalanced data"}}