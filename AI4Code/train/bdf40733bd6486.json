{"cell_type":{"ada470d7":"code","56211000":"code","52206bff":"code","7f3eb78e":"code","ed13766f":"code","e48e8364":"code","9d4668f7":"code","515abf98":"code","fa0f323e":"code","773b6868":"code","41051dea":"code","830562b7":"code","33b3193a":"code","1f744a07":"code","7c60cb0d":"code","7ffb4635":"code","2dbc29e8":"code","b49249ba":"code","7e3b8efe":"code","015531c3":"code","a6f253d1":"code","768e0c8a":"code","db0859d3":"code","52e518d1":"code","af8ad398":"code","b35ccc7d":"code","059a7939":"code","2c6ea1c4":"code","bcc87764":"code","20c12b21":"code","f0a5ff53":"code","3f579a94":"code","ea7eb826":"code","d2d12a68":"code","a39fb23e":"code","4d9b9062":"code","708e633f":"code","42076498":"code","7e5e6b48":"code","2d395098":"code","f3f5c23d":"markdown","b4591966":"markdown","e99118d1":"markdown","353c211c":"markdown","e7be35d0":"markdown","24561849":"markdown","3c8837f7":"markdown","74245c01":"markdown","6bc84d55":"markdown","37e371fe":"markdown","d5969ef1":"markdown","39c1f4d4":"markdown","80f7782c":"markdown","00bf1b13":"markdown","84780269":"markdown","fecc6841":"markdown","794a6a92":"markdown","040e17ac":"markdown","ff9888b3":"markdown"},"source":{"ada470d7":"import os\nimport gc\nimport time\nimport copy\nfrom pathlib import Path\nimport multiprocessing as mp\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\n\n\nimport torch\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport torchvision.transforms as T\nfrom sklearn.metrics import f1_score\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\nfrom skmultilearn.model_selection import IterativeStratification\n%matplotlib inline\n\n      \nROOT = Path('\/kaggle\/input\/jovian-pytorch-z2g\/')\nDIR = ROOT \/ 'Human protein atlas'\nTRAIN = DIR \/ 'train'\nTEST = DIR \/ 'test'\nbatch_size = 64\nsize = 256\nnfolds = 5\nthreshold = 0.3\nSEED = 2020","56211000":"def show_sample(img, target, invert=True):\n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    print('Labels:', decode_target(target, text_labels=True))\n    \ndef show_batch(dl, invert=True):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(16, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        data = 1-images if invert else images\n        ax.imshow(make_grid(data, nrow=16).permute(1, 2, 0))\n        break\n\ndef F_score(output, label, threshold=0.5, beta=1):\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP \/ (TP + FP + 1e-12))\n    recall = torch.mean(TP \/ (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)\n\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)\n    \nclass MultilabelImageClassificationBase(nn.Module):\n\n    def training_step(self, batch):\n        images, targets = batch \n        out = self(images)                      \n        loss = F.binary_cross_entropy(out, targets)      \n        return loss\n    \n    def validation_step(self, batch):\n        images, targets = batch \n        out = self(images)                           # Generate predictions\n        loss = F.binary_cross_entropy(out, targets)  # Calculate loss\n        score = F_score(out, targets)\n        return {'val_loss': loss.detach(), 'val_score': score.detach() }\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_scores = [x['val_score'] for x in outputs]\n        epoch_score = torch.stack(batch_scores).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_score': epoch_score.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.4f}, train_loss: {:.4f}, val_loss: {:.4f}, val_score: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_score']))\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\ndef encode_label(label):\n    target = torch.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target\n\ndef decode_target(target, text_labels=False, threshold=0.5):\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)\n\nseed_everything(SEED)","52206bff":"df = pd.read_csv(DIR \/ 'train.csv').set_index(\"Image\").sort_index()\nsubmission = pd.read_csv(ROOT \/ 'submission.csv') # Don't change the order in the submission\nDEVICE = get_default_device()","7f3eb78e":"train_images = {int(x.stem): x for x in TRAIN.iterdir() if x.suffix == '.png'}\ntest_images = {int(x.stem): x for x in TEST.iterdir() if x.suffix == '.png'}","ed13766f":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)","e48e8364":"def encode_label(label):\n    target = torch.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target\n\ndef decode_target(target, text_labels=False, threshold=0.5):\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)","9d4668f7":"labels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}","515abf98":"indexes = {v:k for k,v in labels.items()}","fa0f323e":"df.Label.value_counts().tail(10)","773b6868":"df['Label'] = df.Label.str.split(\" \") ; df.head()","41051dea":"df = df.explode('Label') ; df.head(10)","830562b7":"df.Label.value_counts()","33b3193a":"df = pd.get_dummies(df) ; df.head()","1f744a07":"df = df.groupby(df.index).sum() ; df.head()","7c60cb0d":"df.columns = labels.keys() ; df.head()","7ffb4635":"X, y = df.index.values, df.values","2dbc29e8":"k_fold = IterativeStratification(n_splits=nfolds, order=2)\n\nsplits = list(k_fold.split(X, y))","b49249ba":"splits[0][0].shape , splits[0][1].shape","7e3b8efe":"fold_splits = np.zeros(df.shape[0]).astype(np.int)\n\nfor i in range(nfolds):\n    fold_splits[splits[i][1]] = i\n\ndf['Split'] = fold_splits\n\ndf.head(10)","015531c3":"fold = 0\n\ntrain_df = df[df.Split != fold]\nval_df = df[df.Split == fold]","a6f253d1":"train_df.head()","768e0c8a":"val_df.head()","db0859d3":"decoded_train_df = pd.DataFrame({'Label' : list(map(decode_target, train_df.values))}, index=train_df.index)\ndecoded_val_df = pd.DataFrame({'Label' : list(map(decode_target, val_df.values))}, index=val_df.index)","52e518d1":"decoded_train_df.Label.value_counts().tail(10)","af8ad398":"decoded_val_df.Label.value_counts().tail(10)","b35ccc7d":"def create_split_df(nfolds=5, order=1):\n\n    df = pd.read_csv(DIR \/ 'train.csv').set_index(\"Image\")\n\n    submission = pd.read_csv(ROOT \/ 'submission.csv')\n\n    split_df = pd.get_dummies(df.Label.str.split(\" \").explode())\n\n    split_df = split_df.groupby(split_df.index).sum() \n\n    X, y = split_df.index.values, split_df.values\n\n    k_fold = IterativeStratification(n_splits=nfolds, order=order)\n\n    splits = list(k_fold.split(X, y))\n\n    fold_splits = np.zeros(df.shape[0]).astype(np.int)\n\n    for i in range(nfolds):\n        fold_splits[splits[i][1]] = i\n\n    split_df['Split'] = fold_splits    \n\n    df_folds = []\n\n    for fold in range(nfolds):\n\n        df_fold = split_df.copy()\n            \n        train_df = df_fold[df_fold.Split != fold].drop('Split', axis=1).reset_index()\n        \n        val_df = df_fold[df_fold.Split == fold].drop('Split', axis=1).reset_index()\n        \n        df_folds.append((train_df, val_df))\n\n    return df_folds","059a7939":"splits = create_split_df(5, order=2)","2c6ea1c4":"#train_set = set(TRAIN.iterdir())\n#test_set = set(TEST.iterdir())\n#whole_set = train_set.union(test_set)\n\n#x_tot, x2_tot = [], []\n#for file in tqdm(whole_set):\n#    img = cv2.imread(str(file), cv2.COLOR_RGB2BGR)\n#    img = img\/255.0\n#    x_tot.append(img.reshape(-1, 3).mean(0))\n#    x2_tot.append((img**2).reshape(-1, 3).mean(0))\n\n#image stats\n#img_avr =  np.array(x_tot).mean(0)\n#img_std =  np.sqrt(np.array(x2_tot).mean(0) - img_avr**2)\n#print('mean:',img_avr, ', std:', np.sqrt(img_std))\n#mean = torch.as_tensor(x_tot)\n#std =torch.as_tensor(x2_tot)","bcc87764":"mean = torch.tensor([0.05438065, 0.05291743, 0.07920227])\nstd = torch.tensor([0.39414383, 0.33547948, 0.38544176])\nimagenet_mean = torch.tensor([0.485, 0.456, 0.406])\nimagenet_std = torch.tensor([0.229, 0.224, 0.225])","20c12b21":"\ntrain_tfms = T.Compose([\n    T.Resize(size),\n    T.RandomHorizontalFlip(), \n    T.RandomRotation(90), # Since the images are squares I experimented with 90\u00ba Rotation\n    T.ToTensor(), \n    T.Normalize(mean, std, inplace=True), \n    T.RandomErasing(inplace=True)\n])\n\nvalid_tfms = T.Compose([\n    T.Resize(size), \n    T.ToTensor(), \n    T.Normalize(mean, std)\n])","f0a5ff53":"class HumanProteinDataset(Dataset):\n    def __init__(self, df, transform=None, is_test=False):\n        self.df = df\n        self.transform = transform\n        self.files = test_images if is_test else train_images\n        \n    def __len__(self):\n        return len(self.df)    \n    \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_id, img_label = int(row['Image']), row.drop('Image').values.astype(np.float32)\n        img = self.files[img_id] \n        img = Image.open(img)\n        if self.transform:\n            img = self.transform(img)\n        return img, img_label","3f579a94":"class Proteinmodel(MultilabelImageClassificationBase):\n    def __init__(self, encoder):\n        super().__init__()\n        # Use a pretrained model\n        self.network = encoder(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 10)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n    \n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.fc.parameters():\n            param.require_grad = True\n    \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True","ea7eb826":"def get_split_dataloaders(split):\n    train_df, val_df = split\n    \n    train_ds = HumanProteinDataset(train_df, transform=train_tfms)\n    val_ds = HumanProteinDataset(val_df, transform=valid_tfms)\n    \n    train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=mp.cpu_count(), pin_memory=True)\n    val_dl = DataLoader(val_ds, batch_size*2, num_workers=mp.cpu_count(), pin_memory=True)\n    \n    \n    train_dl = DeviceDataLoader(train_dl, DEVICE)\n    val_dl = DeviceDataLoader(val_dl, DEVICE)\n    \n    return train_dl, val_dl","d2d12a68":"def get_test_dl():\n    test_ds = HumanProteinDataset(submission, transform=valid_tfms, is_test=True)\n    test_dl = DataLoader(test_ds, batch_size*2, num_workers=mp.cpu_count(), pin_memory=True)\n    return DeviceDataLoader(test_dl, DEVICE)","a39fb23e":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in tqdm(val_loader)]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD, save_best='val_loss'):\n    \n    since = time.time()\n    \n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss, best_score = 1e4, 0.0\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        \n        if result['val_loss'] < best_loss:   \n            best_loss = result['val_loss']\n            if save_best == 'val_loss':\n                best_model_wts = copy.deepcopy(model.state_dict())\n        \n            \n        if result['val_score'] > best_score:\n            best_score = result['val_score']                   \n            if save_best == 'val_score':            \n                best_model_wts = copy.deepcopy(model.state_dict())          \n        \n        history.append(result)\n        \n    time_elapsed = time.time() - since\n    \n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    \n    print(f'Best val Score: {best_score:4f}')\n    \n    print(f'Best val loss: {best_loss:4f}')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n        \n    \n    return model, history","4d9b9062":"def predict_single(image):\n    xb = image.unsqueeze(0)\n    xb = to_device(xb, device)\n    preds = model(xb)\n    prediction = preds[0]\n    print(\"Prediction: \", prediction)\n    show_sample(image, prediction)\n    \n@torch.no_grad()\ndef predict_dl(dl, model):\n    torch.cuda.empty_cache()\n    batch_probs = []\n    for xb, _ in tqdm(dl):\n        probs = model(xb)\n        batch_probs.append(probs.cpu().detach())\n    batch_probs = torch.cat(batch_probs)\n    return batch_probs","708e633f":"device = get_default_device()","42076498":"max_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam\n\n\nhistories = []\npredictions = []\n\ntest_dl = get_test_dl()\n\nsince = time.time()\n\n\nfor i, split in enumerate(splits):\n    \n    history = []\n    \n    train_dl, val_dl = get_split_dataloaders(split)\n    \n    # initialize parameters of model to train each fold from scratch and not leak info from different folds\n    model = to_device(Proteinmodel(models.resnet50), device)\n    \n    model.freeze()    \n    model, hist = fit_one_cycle(6, max_lr, model, train_dl, val_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)\n    \n    history += hist\n    \n    model.unfreeze()   \n    model, hist  = fit_one_cycle(4, max_lr\/10, model, train_dl, val_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)\n    \n    history += hist\n    \n    test_preds = predict_dl(test_dl, model)\n    \n    predictions.append(test_preds)\n    \n    del model\n    \n    gc.collect()\n    \nprint(f'Total Training time: {(time.time() - since)\/60:.2f} minutes')","7e5e6b48":"prediction_cv = torch.stack(predictions).mean(axis=0)\ndecoded_predictions = test_preds > threshold\nsubmission[\"Label\"] = [decode_target(t.tolist()) for t in  decoded_predictions]\nsubmission.to_csv(\"submission.csv\", index=False)","2d395098":"submission.head(10)","f3f5c23d":"## Expand the labels","b4591966":"## Count the distributions of individual classes","e99118d1":"In addition to having multiple labels in each image, the other challenge in this competition is the existence of rare classes and combinations of different classes.\n\nOne technique to deal with this is to guarantee a balanced spliting between training and validation set. The usual random `train_test_split` is not ideal in this case because you can end up putting rare cases in the validation set and your model will never learn about them. The stratification present in the `scikit-learn` is also not equipped to deal with multilabel targets. The library `scikit-multilearn` does exactly that.\n\nUpdate 1: in the previous example I've just showed how to create the splitted dataframe. This is not much help if you are not used to create datasets in Pytorch. In this version I show how to use this in conjunction with the Advanced Transfer Learning Notebook","353c211c":"In the previous example I've used the `order=1` option. Reading the documentation it says is better advised to use higher orders for the model to sample with replacement for more rare classes. Experiment with these values","e7be35d0":"## How to use this for cross-validation and training\nThe following function organizes the code above return a list with `nfolds` where each item is a tuple with the `train_df` and `val_df` for that fold","24561849":"So, for example for our `fold=0`, all the examples with `Split == 0` is our validation set, all the other are our training set for that fold.","3c8837f7":"## Turn labels into one-hot encoding columns","74245c01":"## Ensemble the models by averaging the predictions from each fold","6bc84d55":"The following decoded dataframes are for visualization purposes only. We will pass the above dataframes with one-hot encoded labels to our models.","37e371fe":"Turn the index (image names) and columns (one-hot target) into np.arrays to feed the stratification algorithm","d5969ef1":"Now we have a list with 5 arrays to index and split our dataset. Each array has 2 dimensions, the 1st dimension are the indices of our training set ( 80% of the data ) and the second dimension are the indices of our validation set (20% of the data). A better way to index our data frame is to create a new column in our DataFrame with the split for that fold.","39c1f4d4":"## Statistics of the DataSet\nTo normalize your Dataset you can use the Imagenet Statistics or another way is to calculate the stats of your current images, train + test and instead use those. The following snippet of code does these. \nUncomment if you want to try it yourself but I already provided the values. You can see the values are very different from imagenet. Experiment with both!","80f7782c":"We can see we have combinations with only one example, this is certainly harder for our model to generalize.","00bf1b13":"The following is and adaptation from [Advanced Transfer Learning Starter Notebook](https:\/\/www.kaggle.com\/aakashns\/advanced-transfer-learning-starter-notebook) using the Stratified Splits, Cross Validation and saving the best model weights per fold.","84780269":"I've trained for a few epochs with image_size=256 just for the sharing purposes. Training for longer times with bigger images and tweaked hyperparameters can make your model a lot better.","fecc6841":"## Count the distribution of combinations","794a6a92":"## Helper Functions","040e17ac":"## Split the label strings","ff9888b3":"## Combine the vectors of the same index and sum them"}}