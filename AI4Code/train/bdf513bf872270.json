{"cell_type":{"5b18ebce":"code","e645b67a":"code","6acf96e8":"code","77abb1ca":"code","5de5f693":"code","449b9d95":"code","784722ce":"code","28c239ec":"code","86ea98af":"code","7729cd6d":"code","34396c61":"code","7377b43e":"code","d904db46":"code","bf47dd42":"code","5fa5fa3a":"code","79139f8b":"code","2895146d":"code","fe91442c":"code","75382953":"code","038ae5c0":"code","dd48e735":"code","54eb58fb":"code","f083d00c":"code","7cc66bfa":"markdown","f4a9cf70":"markdown"},"source":{"5b18ebce":"#!pip install pytorchcv","e645b67a":"import numpy as np\nimport pandas as pd\nimport os\nimport fastai\nfrom fastai.vision import *\nfrom fastai.callbacks import MixedPrecision\npath = Path('..\/input')","6acf96e8":"'''from pytorchcv.model_provider import get_model as ptcv_get_model\ndef xcp(f=None):\n    n = ptcv_get_model('resnet18_wd4', pretrained=True)\n    n.features.final_pool = nn.AvgPool2d(kernel_size=7, stride=1, padding=3)\n    n = n.features\n    return n'''","77abb1ca":"train_df = pd.read_csv(path\/\"train.csv\")","5de5f693":"def lb_fnc(j):\n    #print(len(j[1]))\n    return j[1]\nlbf = lambda x: x[1]\ncodes = list(train_df['ClassId'].values)\ntrain_df['code'] = train_df['ClassId'].apply(lambda x: x.split('_')[0])\ntrs = train_df.sample(frac=0.01).reset_index(drop=True)\ncode = list(set(trs['code'].values))","449b9d95":"def open_mask_rle(mask_rle:str, shape:Tuple[int, int])->ImageSegment:\n    \"Return `ImageSegment` object create from run-length encoded string in `mask_lre` with size in `shape`.\"\n    x = FloatTensor(rle_decode(str(mask_rle), shape).astype(np.uint8))\n    x = x.view(shape[1], shape[0], -1)\n    return ImageSegment(x.permute(2,1,0))","784722ce":"class SegRleItem(ItemBase):\n    def __init__(self, image, mask):\n        self.image = image\n        self.mask = mask\n        self.obj,self.data = (image, mask),(image.data,mask.data)\n        \n    def apply_tfms(self, tfms, *args, **kwargs):\n        self.mask = self.mask.apply_tfms(tfms, *args, **kwargs)\n        self.image = self.image.apply_tfms(tfms, *args, **kwargs)\n        self.data = self.image.data,self.mask.data\n        return self\n    \n    def __repr__(self): return f'{self.__class__.__name__} {self.image.shape, self.mask.shape}'\n    \n    def to_one(self): return (Image(self.image.data), ImageSegment(self.mask.data))","28c239ec":"def open_mask_rle(mask_rle:str, shape:Tuple[int, int])->ImageSegment:\n    \"Return `ImageSegment` object create from run-length encoded string in `mask_lre` with size in `shape`.\"\n    x = FloatTensor(rle_decode(str(mask_rle), shape).astype(np.uint8))\n    x = x.view(shape[1], shape[0], -1)\n    return ImageSegment(x.permute(2,1,0))","86ea98af":"class SegRleLabel(ItemBase):\n    def __init__(self, mask):\n        self.mask = mask\n        self.obj,self.data = mask,mask.data\n        \n    def apply_tfms(self, tfms, *args, **kwargs):\n        self.mask = self.mask.apply_tfms(tfms, *args, **kwargs)\n        self.data = self.mask.data\n        return self\n    \n    def __repr__(self): return f'{self.__class__.__name__} {self.mask.shape}'\n    \n    def to_one(self): return ImageSegment(self.mask.data)","7729cd6d":"class SegRleImage(ItemBase):\n    def __init__(self, image):\n        self.image = image\n        self.obj,self.data = image,image.data\n        \n    def apply_tfms(self, tfms, *args, **kwargs):\n        self.image = self.image.apply_tfms(tfms, *args, **kwargs)\n        self.data = self.image.data\n        return self\n    \n    def __repr__(self): return f'{self.__class__.__name__} {self.image.shape}'\n    \n    def to_one(self): return Image(self.image.data)","34396c61":"class ImageList(ItemList):\n    \"`ItemList` suitable for computer vision.\"\n    _bunch,_square_show,_square_show_res = ImageDataBunch,True,True\n    def __init__(self, *args, convert_mode='RGB', after_open:Callable=None, **kwargs):\n#        print('ImageList_init')\n        super().__init__(*args, **kwargs)\n\n    def open(self, fn):\n        \"Open image in `fn`, subclass and overwrite for custom behavior.\"\n        return open_image(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n\n    def get(self, i):\n        fn = super().get(i)\n        mn = fn[1]\n        fn = fn[0]\n        res = self.open(fn)\n        self.sizes[i] = res.size \n        res = SegRleItem(res, mn)\n        return res\n    \n    @classmethod\n    def from_folder(cls, path:PathOrStr='.', extensions:Collection[str]=None, **kwargs)->'ItemList':\n        \"Get the list of files in `path` that have an image suffix. `recurse` determines if we search subfolders.\"\n        extensions = ifnone(extensions, image_extensions)\n        return super().from_folder(path=path, extensions=extensions, **kwargs)\n\n    @classmethod\n    def from_df(cls, df:DataFrame, path:PathOrStr, cols:IntsOrStrs=0, folder:PathOrStr=None, suffix:str='', **kwargs)->'ItemList':\n        \"Get the filenames in `cols` of `df` with `folder` in front of them, `suffix` at the end.\"\n        suffix = suffix or ''\n        res = super().from_df(df, path=path, cols=cols[0], **kwargs)\n        msk = ItemList.from_df(df, path, cols=[1,2,3])\n        pref = f'{res.path}{os.path.sep}'\n        if folder is not None: pref += f'{folder}{os.path.sep}'\n        res.items = np.char.add(np.char.add(pref, res.items.astype(str)), suffix)\n        res.items = np.array([(res.items[i], msk[i]) for i in range(len(res.items))])\n        return res\n    \n    def label_from_func(self, func:Callable, label_cls:Callable=None, **kwargs)->'LabelListTpl':\n        \"Apply `func` to every input to get its label.\"\n        return self._label_from_list([func(o) for o in self.items], label_cls=label_cls, **kwargs)\n\n    @classmethod\n    def from_csv(cls, path:PathOrStr, csv_name:str, header:str='infer', **kwargs)->'ItemList':\n        \"Get the filenames in `path\/csv_name` opened with `header`.\"\n        path = Path(path)\n        df = pd.read_csv(path\/csv_name, header=header)\n        return cls.from_df(df, path=path, **kwargs)\n\n    def reconstruct(self, t:Tensor): return Image(t.float().clamp(min=0,max=1))\n\n    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        \"Show the `xs` (inputs) and `ys` (targets) on a figure of `figsize`.\"\n        rows = int(np.ceil(math.sqrt(len(xs))))\n        axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize)\n        for x,y,ax in zip(xs, ys, axs.flatten()): x.show(ax=ax, y=y, **kwargs)\n        for ax in axs.flatten()[len(xs):]: ax.axis('off')\n        plt.tight_layout()\n\n    def show_xyzs(self, xs, ys, zs, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n        \"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\"\n        if self._square_show_res:\n            title = 'Ground truth\\nPredictions'\n            rows = int(np.ceil(math.sqrt(len(xs))))\n            axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=12)\n            for x,y,z,ax in zip(xs,ys,zs,axs.flatten()): x.show(ax=ax, title=f'{str(y)}\\n{str(z)}', **kwargs)\n            for ax in axs.flatten()[len(xs):]: ax.axis('off')\n        else:\n            title = 'Ground truth\/Predictions'\n            axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=14)\n            for i,(x,y,z) in enumerate(zip(xs,ys,zs)):\n                x.show(ax=axs[i,0], y=y, **kwargs)\n                x.show(ax=axs[i,1], y=z, **kwargs)","7377b43e":"class SegRleItems(ItemBase):\n    def __init__(self, image, mask_arr):\n        self.image = image\n        self.mask_arr = mask_arr\n        self.mask = open_mask_rle(self.mask_arr[0], (self.mask_arr[1], self.mask_arr[2]))\n        self.obj,self.data = (self.image, self.mask),(self.image.data,self.mask.data)\n        \n    def apply_tfms(self, tfms, *args, **kwargs):\n        self.mask = self.mask.apply_tfms(tfms, *args, **kwargs)\n        self.image = self.image.apply_tfms(tfms, *args, **kwargs)\n        self.data = self.image.data,self.mask.data\n        return self\n    \n    def __repr__(self): return f'{self.__class__.__name__} {self.image.shape, self.mask.shape}'\n    \n    def to_one(self): return (Image(self.image.data), ImageSegment(self.mask.data))","d904db46":"class SegmentationProcessor(PreProcessor):\n    \"`PreProcessor` that stores the classes for segmentation.\"\n    def __init__(self, ds:ItemList): \n        self.classes = ds.classes\n    def process(self, ds:ItemList):  \n        ds.classes,ds.c = self.classes,len(self.classes)\n\nclass SegmentationLabelList(ItemList):\n    \"`ItemList` for segmentation masks.\"\n    _processor=SegmentationProcessor\n    def __init__(self, items:Iterator, classes:Collection=None, **kwargs):\n        super().__init__(items, **kwargs)\n        self.copy_new.append('classes')\n        self.classes,self.loss_func = classes,CrossEntropyFlat(axis=1)\n\n    def get(self, i):\n        fn = super().get(i)\n        res = self.open(fn)\n        return res\n        \n    def open(self, fn): \n        fn = open_mask_rle(fn[0], (fn[1], fn[2]))\n        fn = SegRleLabel(fn)\n        return fn\n    def analyze_pred(self, pred, thresh:float=0.5): return pred.argmax(dim=0)[None]\n    def reconstruct(self, t:Tensor): return SegRleLabel(t)\n\nclass SegmentationItemList(ImageList):\n    \"`ItemList` suitable for segmentation tasks.\"\n    _label_cls,_square_show_res = SegmentationLabelList,False","bf47dd42":"class SegRleList(SegmentationItemList):\n    \"`ItemList` suitable for computer vision.\"\n    _bunch,_square_show,_square_show_res = ImageDataBunch,True,True\n    def __init__(self, *args, convert_mode='RGB', after_open:Callable=None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.convert_mode,self.after_open = convert_mode,after_open\n        self.copy_new.append('convert_mode')\n        self.c,self.sizes = 3,{}\n        \n    def create(cls, labels:Collection=None, classes:dict=None)->'SegRleList':\n        \"Create an ImageLabeled object with `labels`.\"\n        return cls(labels=labels, classes=classes)\n    \n    def get(self, i):\n        res = super().get(i)\n        res = SegRleImage(Image(res.data[0])) \n        return res\n\n    def reconstruct(self, t:Tensor): \n        return SegRleImage(t)\n    \n    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(12,6), **kwargs):\n        \"Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method.\"\n        rows = int(math.sqrt(len(xs)))\n        fig, axs = plt.subplots(rows,rows,figsize=figsize)\n        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n            ym = ys[i].to_one()\n            xs[i].to_one().show(ax=ax, y=ym, **kwargs, alpha=0.7)\n        plt.tight_layout()\n\n    def show_xyzs(self, xs, ys, zs, figsize:Tuple[int,int]=None, **kwargs):\n        \"\"\"Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`.\n        `kwargs` are passed to the show method.\"\"\"\n        figsize = ifnone(figsize, (12,3*len(xs)))\n        fig,axs = plt.subplots(len(xs), 2, figsize=figsize)\n        fig.suptitle('Ground truth \/ Predictions', weight='bold', size=14)\n        for i,(x,z) in enumerate(zip(xs,zs)):\n            x.to_one().show(ax=axs[i,0], **kwargs)\n            z.to_one().show(ax=axs[i,1], **kwargs)\n","5fa5fa3a":"db = (SegRleList.from_df(trs, path, cols=[0,1,2,3], folder='train')\n     .split_by_rand_pct()\n     .label_from_func(lbf, classes=code) \n     .transform(get_transforms(), tfm_y=True, size=224)\n     .databunch(bs=16, num_workers=0)\n     .normalize(imagenet_stats)\n     )","79139f8b":"len(db.train_ds)","2895146d":"db.valid_ds","fe91442c":"db.show_batch(rows=4, figsize=(12,12))","75382953":"acc_05 = partial(accuracy_thresh, thresh=0.5)","038ae5c0":"learn = unet_learner(db, \n                     models.resnet18, \n                     metrics=[acc_05], \n                     #loss_func=nn.BCEWithLogitsLoss(),\n                     wd=1e-2,\n                     model_dir=\"\/kaggle\/working\/models\")","dd48e735":"#learn = learn.to_fp16()\n#learn.lr_find() \n#learn.recorder.plot() ","54eb58fb":"lr = 1e-3 \nlearn.fit_one_cycle(1, slice(lr), pct_start=0.9, callbacks=[MixedPrecision(learn)])","f083d00c":"pr,yt = learn.get_preds()","7cc66bfa":"That being said, this competition seems like a great opportunity to learn about segmentation. I wanted to try the fastai dynamic unet here, but the tutorials on segmentation with fastai I could find all relied on the masks existing as seperate image files with names that could be easily inferred from the image files in some way. I could not find a method for generating ImageSegment objects automatically from run-encoded pixels to drop into a databunch, so after some *unknown* amount of effort I made one (I think).\n\nThis is the first time I tried customizing fastai code so I'm sure there are both more elegant and efficient ways of doing it, if you know any please don't hesitate to let me know.","f4a9cf70":"**This is a work in progress. Training set is sampled at 5% and image size is set far smaller than optimal in order to run in a reasonable amount of time. Code to generate appropriate RLE output for submission is not ready yet, I will add it when it is. **"}}