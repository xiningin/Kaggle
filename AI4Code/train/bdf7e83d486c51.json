{"cell_type":{"3e5eb15f":"code","eed3b597":"code","002e99c2":"code","451c9476":"code","533dde49":"code","0a8980ad":"code","a2a54419":"code","10571bdd":"code","63a3cff8":"code","a2476d18":"code","fe3e4246":"code","bddebc87":"code","9fcf26ac":"code","392cf337":"code","7dd8d99f":"code","96363046":"code","b9247cf0":"markdown","1b28cb9d":"markdown","8e764ddf":"markdown","7ffc5e5a":"markdown","3947f984":"markdown","892df8e8":"markdown","3fb248b0":"markdown","ff4b5651":"markdown","ec0a4398":"markdown","e3badddd":"markdown","adba8f20":"markdown","ce56f0a7":"markdown","17c5c03c":"markdown","fb2410d4":"markdown","3fa08b6f":"markdown"},"source":{"3e5eb15f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport glob\nfrom PIL import Image\nfrom numpy import expand_dims,zeros,ones\nfrom numpy.random import randn,randint\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.datasets.mnist import load_data\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, ReLU\nfrom tensorflow.keras.layers import Dropout, Embedding, Concatenate, BatchNormalization\nfrom tensorflow.keras.initializers import RandomNormal","eed3b597":"IMAGE_SIZE = (28,28,1)\nBATCH_SIZE = 200\nSTEPS = 500\nEPOCHS = 20\nLATENT_DIM = 100\nN_CLASSES = 10","002e99c2":"z_vis = tf.random.normal([10, LATENT_DIM])\ny_vis = tf.constant(np.eye(10), dtype='float32')","451c9476":"train_df = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ny = train_df['label']\ntrain_df.drop('label',axis=1,inplace=True)\ntraining_images=train_df.to_numpy()\ntraining_images = training_images.reshape(42000, 28, 28, 1)","533dde49":"x_train, x_test, y_train, y_test = train_test_split(training_images,y,test_size=0.2)\nx_train = x_train \/ 255.0\ny_train = tf.one_hot(y_train, depth=10, dtype='float32')\ndata_iter = iter(tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(4 * BATCH_SIZE).batch(BATCH_SIZE).repeat())","0a8980ad":"for i in range(25):\n    plt.subplot(5, 5, 1 + i)\n    plt.axis('off')\n    plt.imshow(x_train[i], cmap='gray_r')\nplt.show()","a2a54419":"def Generator():\n    z = Input(shape=(LATENT_DIM,), dtype='float32')#input for noize vector\n    y = Input(shape=(10,), dtype='float32')#input for the label\n\n    x = Concatenate()([z, y])\n    x = Dense(7 * 7 * 128)(x)\n    x = Reshape((7, 7, 128))(x)\n\n    x = Conv2DTranspose(128, 5, 2, 'same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(0.2)(x)\n    \n    x = Conv2DTranspose(64, 5, 2, 'same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(0.2)(x)\n\n    out = Conv2DTranspose(1,  5, 1, 'same', activation='sigmoid')(x)\n\n    return tf.keras.Model(inputs=[z, y], outputs=out)","10571bdd":"def Discriminator():\n    X = Input(shape=(28, 28), dtype='float32')#input for real or fake images\n    Y = Input(shape=(10,), dtype='float32')#input for the label\n\n    y = tf.tile(tf.reshape(Y,[-1, 1, 1, 10]), [1, 28, 28, 1])\n    x = Reshape((28, 28, 1))(X)\n    x = Concatenate()([x, y])\n\n    x = Conv2D(32,  5, 2, 'same')(x)\n\n    x = Conv2D(64,  4, 2, 'same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(0.2)(x)\n    \n    x = Conv2D(128,  3, 2, 'same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(0.2)(x)\n    \n    x = Flatten()(x)\n    x = Dense(128)(x)\n    x = BatchNormalization()(x)\n\n    out = Dense(1)(x)\n\n    return tf.keras.Model(inputs=[X, Y], outputs=out)","63a3cff8":"G = Generator()\nD = Discriminator()","a2476d18":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)\ndef G_loss(D, x_fake, y):\n    return cross_entropy(tf.ones_like(D([x_fake, y])), D([x_fake, y]))\ndef D_loss(D, x_real, x_fake, y):\n    return cross_entropy(tf.ones_like(D([x_real, y])), D([x_real, y])) + cross_entropy(tf.zeros_like(D([x_fake, y])), D([x_fake, y]))","fe3e4246":"G_opt = Adam(2e-4,0.5)\nD_opt = Adam(2e-4,0.5)","bddebc87":"def generate_and_save_images(model, epoch, noise,label):\n    predictions = model([noise,label])\n\n    fig = plt.figure(figsize=(8, 2))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(2, 5, i+1)\n        plt.imshow(model([noise,label])[i,:,:] * 255.0)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","9fcf26ac":"for epoch in range(EPOCHS):\n    for step in range(STEPS):\n        z_mb = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n        x_real, y = next(data_iter)\n        with tf.GradientTape() as G_tape, tf.GradientTape() as D_tape:  \n            x_fake = G([z_mb, y])\n            G_loss_curr = G_loss(D, x_fake, y)\n            D_loss_curr = D_loss(D, x_real, x_fake, y)\n\n        G_grad = G_tape.gradient(G_loss_curr, G.trainable_variables)\n        D_grad = D_tape.gradient(D_loss_curr, D.trainable_variables)\n\n        G_opt.apply_gradients(zip(G_grad, G.trainable_variables))\n        D_opt.apply_gradients(zip(D_grad, D.trainable_variables))\n    \n    print('epoch: {}; G_loss: {:.6f}; D_loss: {:.6f}'.format(epoch+1, G_loss_curr, D_loss_curr))\n    generate_and_save_images(G,epoch,z_vis,y_vis)","392cf337":"new_noise = tf.random.normal([100, LATENT_DIM])\nlabels = np.asarray([np.eye(10)[i\/\/10] for i in range(100)])\npred = G([new_noise,labels])\nfor i in range(100):\n    plt.subplot(10, 10, 1 + i)\n    plt.axis('off')\n    plt.imshow(pred[i, :, :], cmap='gray_r')\nplt.show()","7dd8d99f":"fp_in = \".\/image_*.png\"\nfp_out = \".\/MNIST_training.gif\"\n\nimg, *imgs = [Image.open(f) for f in sorted(glob.glob(fp_in))]\nimg.save(fp=fp_out, format='GIF', append_images=imgs,\n         save_all=True, duration=200, loop=0)","96363046":"G.save('mnist_gen.hdf5')\nD.save('mnist_dis.hdf5')","b9247cf0":"We will be splitting the data into train and test sets. We will then be normalizing our training data for better performance. We will also one hot encode the labels which will improve our training process.","1b28cb9d":"# Fixed Values\n\nHere we are fixing z_vis which is basically a noise vector. At every epoch we will pass this to the generator to see how the generator is improving for the same set of noise. \n\ny_vis is basically a one hot encoded array of out labels (0-9). We will use to see how effective the model is for generating the images of the different labels. ","8e764ddf":"# Setting up basic parameters","7ffc5e5a":"# Save the models for future use","3947f984":"# Loss Functions\n\nFor the generator the goal is to make as realisitc images as possible. For it the loss is high when discriminates labels its generated images as fake. \n\nFor the discriminator the goal is to label the fake images as fake and real as real. For it loss is high when the generator creates realisitic images and fools the the discriminator.","892df8e8":"# Importing Libraries we will need.","3fb248b0":"# Function to save images at specific epochs","ff4b5651":"# Generator\n\nIn a GAN the role of a generator is to  take noise as input and create as realistic image as possible. In a conditional gan we also provide the label alongside the noise to tell the model what type of image it should try to generate.","ec0a4398":"# Loading the Dataset\n\nWe will load the data from the csv and then reshape it into how the images were. ","e3badddd":"# Custom Training Loop\n\nreference: https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan","adba8f20":"# Discriminator\n\nIn GANs the role of the discriminator is to differentiate between the real and fake images.","ce56f0a7":"If you found this notebook helpful please dont forget to leave an upvote!!!","17c5c03c":"# Evaluation\n\nHere we will check the performance of our model by seeing how well it is performing in generating images of each label","fb2410d4":"# Save the images generated during training as a gif","3fa08b6f":"# Visualize the Data"}}