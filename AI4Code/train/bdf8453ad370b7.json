{"cell_type":{"f4261a01":"code","32630c6d":"code","e10b8eb2":"code","7bcdf5e9":"code","44b51a6a":"code","bb55b972":"code","dd97f1a0":"code","8a177798":"code","9f99b625":"code","79eadc02":"code","7dc6dcb0":"code","9fdc63b4":"code","cfeba883":"code","22e29e07":"code","3a0b7c37":"markdown","d0022ad1":"markdown","c7fb441a":"markdown","c0842059":"markdown","0e3817ae":"markdown","93a33a5c":"markdown","59ce522a":"markdown","a37e6853":"markdown","6ca42537":"markdown"},"source":{"f4261a01":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json,cv2\nfrom glob import glob as gb\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf","32630c6d":"#global parameters\nimage_size = (224,224)\nnum_classes = 212\nbatch_size = 64\nnum_samples = 174367\nstp_per_epoch = num_samples\/\/batch_size\nval_num_sample = 43592\nval_stp = val_num_sample\/\/batch_size\ncurrupted_files = ['883572ba-21bc-11ea-a13a-137349068a90.jpg',\n                  '8792549a-21bc-11ea-a13a-137349068a90.jpg',\n                  '99136aa6-21bc-11ea-a13a-137349068a90.jpg',\n                  '87022118-21bc-11ea-a13a-137349068a90.jpg',\n                  '8f17b296-21bc-11ea-a13a-137349068a90.jpg',\n                  '896c1198-21bc-11ea-a13a-137349068a90.jpg']\n\n# for i in enumerate(currupted_files):\n#     currupted_files[i[0]] = '..\/input\/iwildcam-2020-fgvc7\/train\/'+i[1]\n    \naccelerator = None","e10b8eb2":"if accelerator == 'tpu':\n    # detect and init the TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n\n    # instantiate a distribution strategy\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","7bcdf5e9":"#0.11loading the generators\ngen_t = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\ngen_v = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)","44b51a6a":"#0.12building the dataframe\nwith open('..\/input\/iwildcam-2020-fgvc7\/iwildcam2020_train_annotations.json') as j_data:\n    data = json.load(j_data)\nlabels_dataframe = pd.DataFrame.from_dict(data['annotations'])\n# labels_dataframe.head()","bb55b972":"# '''Just a check:\n# 1- make 10 random numbers\n# 2- get the image corresponding to this 10 numbers in the glob list of images\n# 3- show them with their cat ID in the DF\n# '''\nimages = gb('..\/input\/iwildcam-2020-fgvc7\/train\/*.jpg')\nrandom_numbers = np.random.randint(0,len(images),3)\n\nselected_images = [images[i] for i in random_numbers]\n\nfor i in selected_images:\n    array = cv2.imread(i)\n    category = labels_dataframe.loc[labels_dataframe['image_id'] == i[35:-4]]['category_id'].iloc[0]\n    cv2.cvtColor(array, cv2.COLOR_BGR2RGB)\n    plt.imshow(array)\n    plt.title(category)\n    plt.show()","dd97f1a0":"#0.13flow from dataframe\n\n#making the dataframe\nlabels_dataframe = labels_dataframe.drop(['id','count'],\n                                        axis = 1)\n#suffle the dataframe\nlabels_dataframe = labels_dataframe.sample(frac=1)\n\n#split the dataframe into validation and training dataset\n\n#finding the number of all the samples\nn_total = len(labels_dataframe.index)\nn_train = round(0.8 * n_total)\nn_valid = n_total - n_train\n\n#defining the dataframes\ndf_train = labels_dataframe.head(n_train)\ndf_valid = labels_dataframe.tail(n_valid)\n\n#changing category IDs to str\ndf_train,df_valid = df_train.astype('str'),df_valid.astype('str')\n\n#adding '.jpg' to all image names\ndf_train['image_id'] = df_train['image_id']+'.jpg'\ndf_valid['image_id'] = df_valid['image_id']+'.jpg'\nfor currupted_image_id in currupted_files:\n    df_train = df_train[df_train.image_id != currupted_image_id]\n    df_valid = df_valid[df_valid.image_id != currupted_image_id]\n\n#show the dataframes\ndf_train.head()","8a177798":"df_valid.head()","9f99b625":"#get all the classes\nclass_generator_df = pd.concat([df_valid,df_train])\n\nclasses = list(set(class_generator_df['category_id']))\nnum_classes = len(classes)\nclasses[:20]","79eadc02":"#making the generator\n\ntrain_generator = gen_t.flow_from_dataframe(df_train,\n                                            x_col='image_id',\n                                            y_col='category_id',\n                                            target_size=image_size,\n                                            class_mode='categorical',\n                                            classes = classes,\n                                           directory = i[:35])\n\nvalid_generator = gen_v.flow_from_dataframe(df_valid,\n                                            x_col='image_id',\n                                            y_col='category_id',\n                                            target_size=image_size,\n                                            class_mode='categorical',\n                                            classes = classes,\n                                           directory = i[:35])","7dc6dcb0":"if accelerator == 'tpu':\n    # instantiating the model in the strategy scope creates the model on the TPU\n    with tpu_strategy.scope():\n        model = tf.keras.models.Sequential()\n        model.add(tf.keras.applications.ResNet50(include_top = False, \n                                              pooling = 'avg', \n                                              weights = 'imagenet'))\n        model.add(tf.keras.layers.Dense(num_classes,\n                                     activation='softmax'))\n        model.layers[0].trainable = False\n        model.compile(optimizer = 'adam',\n                     loss = 'categorical_crossentropy',\n                     metrics=['accuracy'])\n        \nelse:\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.applications.ResNet50(include_top = False, \n                                          pooling = 'avg', \n                                          weights = 'imagenet'))\n    model.add(tf.keras.layers.Dense(num_classes,\n                                 activation='softmax'))\n    model.layers[0].trainable = False\n    model.compile(optimizer = 'adam',\n                 loss = 'categorical_crossentropy',\n                 metrics=['accuracy'])\n\n\n        \nmodel.summary()","9fdc63b4":"#overfit on 1 sample\nov_data,ov_label = next(train_generator)\nov_history = model.fit(ov_data,ov_label,\n                       epochs=50,\n                      verbose = 0)\npd.DataFrame.from_dict(ov_history.history).plot()","cfeba883":"#callbacks\ncsvlogger = tf.keras.callbacks.CSVLogger('.\/v1_1_1_log.csv',append = True)\nchk_point = tf.keras.callbacks.ModelCheckpoint('.\/v1_1_1_ckp.h5',save_best_only=True)","22e29e07":"\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\nhistory_resnet50v1 = model.fit_generator(train_generator,\n                                       steps_per_epoch=stp_per_epoch,\n                                       validation_data=valid_generator,\n                                       validation_steps=val_stp,\n                                       epochs=5,\n                                       callbacks=[csvlogger,chk_point],\n                                       verbose=1)","3a0b7c37":"<h2>V1:Build the model<\/h2>","d0022ad1":"Found 174367 validated image filenames belonging to 212 classes.\nFound 43592 validated image filenames belonging to 45 classes.","c7fb441a":"This is my first attempt to participiate in Kaggle. I am sure I have made mistakes.\nIt would be nice if you read and let me know my stupidities:D","c0842059":"<h4>V1.11:resnet50<\/h4>","0e3817ae":"<h5>V1.111:resnet50v1<\/h5>","93a33a5c":"**Versions**\n\n0. Loading and preprocessing data\n    1. making a generator\n        1. using keras image utiles, like the document\n        2. building class dataframe from JSON file\n        3. flow from dataframe\n    2. preprocessing as simple as possible\n        1. making the sizes equal(!)\n1. Building the model\n    1. transfer learning\n        1. resnet50\n            1. v1\n            2. v2\n        2. resnet101\n            1. v1\n            2. v2\n        3. resnet152\n            1. v1\n            2. v2\n        4. squeeznet\n        5. alexnet\n        6. inception\n        7. VGG\n        8. ZFNet\n     2. developing my own model\n        1. Create a 50 layer CNN\/each layer 500 Units to see how it will work...\n        2. start for reducing","59ce522a":"<h2>V0.1: making a generator<\/h2>","a37e6853":"<h3>V1.1:transfer learning<\/h3>","6ca42537":"<h2>V0.12: preprocessing<\/h2>\n<p>\nAlready done.<\/p>"}}