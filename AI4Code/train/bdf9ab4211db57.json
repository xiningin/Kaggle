{"cell_type":{"506d115c":"code","94eae13f":"code","f426aeb0":"code","059e5658":"code","7798c3ce":"code","8dc532cb":"code","faf66d41":"code","42522869":"code","de40100a":"code","72919999":"code","6cdb1359":"code","38bff9aa":"code","6c4e35fc":"code","e7fec4a9":"code","5668d57d":"code","da56f79e":"code","fa8e4fd9":"code","6e2612a9":"code","b573b766":"code","da615d3f":"code","4ad0261b":"code","c4001724":"code","c8808edf":"code","d1851ae3":"code","528cac63":"code","3ef76296":"code","170cec03":"code","81c4f774":"code","970ada03":"code","f3fe7619":"code","34612f22":"code","e9d6425c":"code","d25ed19c":"code","c2ac0f32":"markdown","14e8f040":"markdown","43f30593":"markdown","d6d89c9b":"markdown"},"source":{"506d115c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","94eae13f":"data = pd.read_csv('\/kaggle\/input\/graduate-admissions\/Admission_Predict.csv')","f426aeb0":"data.head()","059e5658":"data['University Rating'].value_counts()","7798c3ce":"data['Research'].value_counts()","8dc532cb":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nfor column in data.columns:\n    fig_column = plt.hist(data[column])\n    plt.xlabel(column)\n    plt.ylabel('Frequency')\n    plt.show()","faf66d41":"import seaborn as sns\n\nsns.pairplot(data)","42522869":"data.columns","de40100a":"from scipy import stats\n \ndata['g_mean_score'] = stats.gmean(data.iloc[:,:6],axis=1)","72919999":"data.head()","6cdb1359":"plt.hist(data['g_mean_score'])","38bff9aa":"plt.scatter(data['g_mean_score'], data['Chance of Admit '])\nplt.xlabel('g_mean_score')\nplt.ylabel('Chance of Admit')\nplt.show()","6c4e35fc":"plt.scatter(data['University Rating'], data['CGPA'])\nplt.xlabel('University rating')\nplt.ylabel('CGPA')\nplt.show()","e7fec4a9":"uni_gpa = data[['University Rating', 'CGPA']]","5668d57d":"Uni_cgpa_avg = uni_gpa.groupby('University Rating').mean().to_dict()","da56f79e":"uni_cgpa_avg = Uni_cgpa_avg.get('CGPA')","fa8e4fd9":"uni_cgpa_avg","6e2612a9":"data['avg_cgpa'] = data['University Rating'].map(uni_cgpa_avg)","b573b766":"data.head()","da615d3f":"def f(row):\n    if row['CGPA'] > row['avg_cgpa']:\n        val = 1\n    else:\n        val = 0\n    return val","4ad0261b":"data['present_chance'] = data.apply(f, axis=1)","c4001724":"data.head()","c8808edf":"X = data.drop(['Chance of Admit ','Serial No.', 'avg_cgpa'], axis = 1)\ny = data.iloc[:,8]","d1851ae3":"X.head()","528cac63":"from sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\n\nss_scaled_X = ss.fit_transform(X)","3ef76296":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(ss_scaled_X, y, test_size = 0.2, random_state = 42)","170cec03":"from sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.svm import LinearSVR\nfrom sklearn.tree import DecisionTreeRegressor \nfrom sklearn.ensemble import RandomForestRegressor\n\nmodels = []\nmodels += [['Ridge', Ridge(alpha = 0.9, solver = \"cholesky\")]]\nmodels += [['Lasso', Lasso(alpha = 1)]]\nmodels += [['Elastic Net', ElasticNet(alpha = 0.1, l1_ratio = 0.25)]]\nmodels += [['SVM', LinearSVR()]]\nmodels += [['Tree', DecisionTreeRegressor()]]\nmodels += [['Rforest', RandomForestRegressor()]]","81c4f774":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\n\nkfold = KFold(n_splits = 5, random_state = 42)\nresult_MM =[]\nnames = []\n\nfor name, model in models:\n    cv_score = -1 * cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'neg_root_mean_squared_error')\n    result_MM +=[cv_score]\n    names += [name]\n    print('%s: %f (%f)' % (name,cv_score.mean(), cv_score.std()))","970ada03":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score\n\nkfold = KFold(n_splits = 10, random_state = 42)\nresult_MM =[]\nnames = []\n\nfor name, model in models:\n    cv_score = -1 * cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'neg_root_mean_squared_error')\n    result_MM +=[cv_score]\n    names += [name]\n    print('%s: %f (%f)' % (name,cv_score.mean(), cv_score.std()))","f3fe7619":"Ridge_model = Ridge(alpha = 0.9, solver = \"cholesky\").fit(X_train, y_train)","34612f22":"y_preds = Ridge_model.predict(X_test)","e9d6425c":"from sklearn.metrics import mean_squared_error\nridge_rmse = np.sqrt(mean_squared_error(y_test, y_preds))","d25ed19c":"print(f'the RMSE obtained for the Ridge Regression is:{ridge_rmse}.')","c2ac0f32":"increasing the splits have further increased the RMSE of the ridge regression","14e8f040":"find the geometric mean of scores to help predictig the probabilities of admission\n","43f30593":"we can observe that the new feature geometric mean score has a positive correlation with Chance of admit.","d6d89c9b":"creating new column to check if the CGPA is higher or lower than the average for the university rating"}}