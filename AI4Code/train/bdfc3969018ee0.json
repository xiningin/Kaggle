{"cell_type":{"34604a02":"code","3cec9ede":"code","2380b54f":"code","42cbc4e9":"code","74f65f0c":"code","96687cd1":"code","e050d297":"code","b4e820d7":"code","ff84429a":"code","bdd34468":"code","3705c262":"code","4180a2a3":"code","e796b5ab":"code","98aa138e":"markdown","fadf302a":"markdown","c11d924e":"markdown","3dcc61a5":"markdown","dd83e2ef":"markdown"},"source":{"34604a02":"# standard\nimport pandas as pd\nimport numpy as np\n\n#visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\npd.set_option(\"display.max_columns\",None)","3cec9ede":"df = pd.read_csv('..\/input\/bouts_out_new.csv')\ndf.head()","2380b54f":"fil = ((df.height_A < 224) & (df.height_A > 147) &\n      (df.height_B < 224) & (df.height_B > 147) &\n      (df.weight_B > 70) & (df.weight_A > 70) &\n      (df.age_A < 60) & (df.age_A > 14) &\n      (df.age_B < 60) & (df.age_B > 14) &\n      (df.reach_A < 250) & (df.reach_A > 130) &\n      (df.reach_B < 250) & (df.reach_B > 130)) \ndf = df[fil]","42cbc4e9":"df['Diff_age'] = df.age_A - df.age_B\ndf['Diff_weight'] = df.weight_A - df.weight_B\ndf['Diff_height'] = df.height_A - df.height_B\ndf['Diff_reach'] = df.reach_A - df.reach_B\n\ndf['Tot_fight_A'] = df.won_A + df.lost_A + df.drawn_A\ndf['Tot_fight_B'] = df.won_B + df.lost_B + df.drawn_B\ndf['Diff_exp'] = df.Tot_fight_A - df.Tot_fight_B\n\ndf['Win_per_A'] = df.won_A \/ df.Tot_fight_A\ndf.loc[df.Tot_fight_A == 0, 'Win_per_A'] = 0 #because maybe it is the first fight\ndf['Win_per_B'] = df.won_B \/ df.Tot_fight_B\ndf.loc[df.Tot_fight_B == 0, 'Win_per_B'] = 0\ndf['KO_perc_A'] = df.kos_A \/ df.won_A\ndf.loc[df.won_A == 0, 'KO_perc_A'] = 0\ndf['KO_perc_B'] = df.kos_B \/ df.won_B\ndf.loc[df.won_B == 0, 'KO_perc_B'] = 0\n\ndf.loc[df.stance_A == df.stance_B, 'Stance'] = 0\ndf.loc[(df.stance_A == 'orthodox') & (df.stance_B == 'southpaw'), 'Stance'] = 1\ndf.loc[(df.stance_B == 'orthodox') & (df.stance_A == 'southpaw'), 'Stance'] = -1","74f65f0c":"# A number of these columns don't seem to make a difference now I have \n# differences between boxer A and boxer B\nml = df.copy()\ntry:\n    ml.drop(['judge1_A', 'judge1_B', 'judge2_A', 'judge2_B', 'judge3_A', 'judge3_B', 'decision'], axis=1, inplace=True)\n    ml.drop(['age_A','age_B', 'height_A','height_B','reach_A', 'reach_B','stance_A', 'stance_B'], axis=1, inplace=True)\n    ml.drop(['weight_A', 'weight_B','won_A','won_B','lost_A','lost_B','drawn_A','drawn_B','Stance'], axis=1, inplace=True) \nexcept:\n    print('already dropped judges')\n    \nml.head()","96687cd1":"ml_dummies = pd.get_dummies(ml)\nml_dummies.fillna(value=0, inplace=True)\nml_dummies.head()","e050d297":"# Remove the label from the dataframe\ntry:\n    label = ml_dummies['result_win_A']\n    del ml_dummies['result_win_A']\n    del ml_dummies['result_win_B']\n    del ml_dummies['result_draw']\nexcept:\n    print(\"label already removed\")\nml_dummies.head()","b4e820d7":"# import random column\nml_dummies['---randomColumn---'] = np.random.randint(0,1000, size=len(ml_dummies))","ff84429a":"from sklearn.model_selection import train_test_split\nfeature_train, feature_test, label_train, label_test = train_test_split(ml_dummies, label, test_size=0.3)\n\n# Classifiers\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifiers = [\n    RandomForestClassifier(),\n    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=17, max_features=6, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=70, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=True)    \n]\n\n# iterate over classifiers\nfor item in classifiers:\n    classifier_name = ((str(item)[:(str(item).find(\"(\"))]))\n    print (classifier_name)\n    \n    # Create classifier, train it and test it.\n    clf = item\n    clf.fit(feature_train, label_train)\n    score = clf.score(feature_test, label_test)\n    print (round(score,3),\"\\n\", \"- - - - - \", \"\\n\")\n    \nimportance_df = pd.DataFrame()\nimportance_df['feature'] = ml_dummies.columns\nimportance_df['importance'] = clf.feature_importances_    \n\n# importance_df.sort_values('importance', ascending=False)\nimportance_df.set_index(keys='feature').sort_values(by='importance', ascending=True).plot(kind='barh', figsize=(20, 15))","bdd34468":"from sklearn.model_selection import GridSearchCV\n\nmax_depth_range = range(2,20,5)\nleaf_range = range(1,5,2)\nn_estimators_range = range(10,140,20)\nmax_features_range = range(1,len(ml_dummies.columns),5)\n\n\nparam_grid = dict(max_depth = max_depth_range,\n                 min_samples_leaf = leaf_range,\n                 n_estimators = n_estimators_range,\n                 max_features = max_features_range\n                )\n\n\n### Warning, can take some time\n# d_tree = RandomForestClassifier()\n# grid = GridSearchCV(d_tree, param_grid, cv=5, scoring = 'accuracy', verbose=1, return_train_score=True)\n# grid.fit(feature_train, label_train)\n# print (grid.best_score_)\n# print (grid.best_params_)\n# print (grid.best_estimator_)","3705c262":"corr_table = ml_dummies.copy()\ncorr_table['result_win_A'] = label","4180a2a3":"corr_table.corr()","e796b5ab":"fig = plt.figure(figsize = (20,10))\ncorr = corr_table.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","98aa138e":"# Understand and clean the data","fadf302a":"Some data is either too high or low. Filter for realistic data.","c11d924e":"# Preprocessing","3dcc61a5":"## Grid Search to tweak parameters","dd83e2ef":"# New features"}}