{"cell_type":{"d88e36c3":"code","a9c7f49c":"code","6b8706a3":"code","c6fa88a8":"code","b069367a":"code","6be7c83b":"code","f7a77b05":"code","6a600a19":"code","233967e3":"code","3d9541af":"code","7ca78b79":"code","47278f37":"code","ee116bcf":"code","f79dc2e1":"code","70f8b0f8":"code","8a0798d2":"code","f5da8952":"code","621f9f26":"code","4a3b9d2a":"code","3189db09":"markdown","40beb52d":"markdown","89ae1a45":"markdown","61ddeab5":"markdown","dd483ac4":"markdown","af08d970":"markdown","2e94a1fd":"markdown","7ce9f71e":"markdown"},"source":{"d88e36c3":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport json\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","a9c7f49c":"def read_json(json_path):\n    \"\"\" args = takes the Json files \n        returns = create the five dataframes for the five tables in the annotations json file\n    \"\"\"\n    # # Opening JSON file\n    f = open(json_path, )\n\n    # returns JSON object as\n    # a dictionary\n    \n    data = json.load(f)\n\n    # Create different lists from the data dictionary\n\n    annotations = pd.DataFrame(data[\"annotations\"])\n    category = pd.DataFrame(data[\"categories\"])\n    info = pd.DataFrame.from_dict(data[\"info\"], orient='index')\n    images = pd.DataFrame(data['images'])\n    licenses = pd.DataFrame(data['licenses'])\n    # Closing file\n    f.close()\n    return annotations, category, info, images, licenses","6b8706a3":"json_train_path = '\/kaggle\/input\/fungi-annotations\/train.json'\njson_val_path = '\/kaggle\/input\/fungi-annotations\/val.json'\ntr_annotation, tr_category, tr_info, tr_images, tr_licenses = read_json(json_train_path)\nval_annotation, val_category, val_info, val_images, val_licenses = read_json(json_val_path)","c6fa88a8":"def create_merged_json_df(images, annotations, category):\n    \"\"\" args = takes the three important dataframes\n    returns = create a merged dataframe with all the important data\n    \"\"\"\n    data_df = images.copy()\n\n    ## to the images dataframe, we add the category_id column - our target\n    data_df['category_id'] = annotations[annotations['image_id'] == data_df['id']]['category_id']\n    category.set_index('id')\n    data_df = pd.merge(left=data_df, right=category, how='left', left_on='category_id', right_on='id')\n    data_df.drop(columns = ['id_y'], inplace=True)\n    #change the column to a string?\n    data_df['category_id'] = data_df['category_id'].astype(str) \n    # Add the columns of image name and its subdirectory\/catefory\n    data_df['image_name'] = data_df['file_name'].str.split('\/').str[2]\n    data_df['subdir'] = data_df['file_name'].str.split('\/',1).str[1]\n    return data_df","b069367a":"tr_data = create_merged_json_df(tr_images, tr_annotation, tr_category)\nval_data = create_merged_json_df(val_images, val_annotation, val_category)","6be7c83b":"tr_data","f7a77b05":"tr_data.dtypes","6a600a19":"len(tr_data['category_id'].unique())","233967e3":"len(val_data['category_id'].unique())","3d9541af":"tr_data['category_id'].value_counts()","7ca78b79":"tr_data['name'].describe()","47278f37":"tr_data['freq'] = tr_data.groupby('category_id')['category_id'].transform('count')","ee116bcf":"tr_data","f79dc2e1":"fig_dims = (15,15)\n\nfig, ax = plt.subplots(figsize=fig_dims)\n\nax = sns.barplot(x = 'category_id', y = 'freq',data = tr_data)\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()","70f8b0f8":"fig_dims = (15,15)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.boxplot(x=tr_data['freq'])\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()","8a0798d2":"fig_dims = (15,15)\n\nfig, ax = plt.subplots(figsize=fig_dims)\n\nax = sns.countplot(x = 'category_id', data = tr_data)\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()","f5da8952":"fig_dims = (15,15)\nfig, ax = plt.subplots(figsize=fig_dims)\nsns.boxplot(x=tr_data['category_id'].value_counts())\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()","621f9f26":"fig_dims = (15,15)\n\nfig, ax = plt.subplots(figsize=fig_dims)\n\nsns.distplot(val_data['category_id'])\nplt.show()","4a3b9d2a":"fig_dims = (15,15)\n\nfig, ax = plt.subplots(figsize=fig_dims)\n\nax = sns.countplot(x = 'category_id', data = val_data)\nplt.title('Distribution of the target Category_id')\nplt.xlabel('Category_id')\nplt.ylabel('Count of images')\nplt.show()","3189db09":"ok so there is the same number of categories between the train and the validation data: 1394 classes","40beb52d":"So we have an imbalanced training dataset. yay! ","89ae1a45":"Let's check the distribution of our data by the target column","61ddeab5":"This is a bad distribution so far!","dd483ac4":"In this notebook I'll try a simple EDA to understand the composition of our data. I already did a first EDA in my previous notebook [here](https:\/\/www.kaggle.com\/amelnozieres\/eda-sweetviz-profiling)","af08d970":"So the distribution is not equivalent between categories so it will skwed our predictions. Let's check it is the same for the validation data","2e94a1fd":"So here we can see that there isn't the same number of images for each class in the training data. But it is balanced in the validation data.","7ce9f71e":"# Explore the JSON files"}}