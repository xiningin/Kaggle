{"cell_type":{"ed96bff1":"code","976f26be":"code","14ad0723":"code","c2209b31":"code","3fb74069":"code","839cef7a":"code","54250dd6":"code","3547640a":"code","04929ba6":"code","dd15bc35":"code","96d4f06a":"code","06498007":"code","e4737736":"code","7954c204":"code","f701f9c0":"code","271ce5ea":"markdown","828fa3cd":"markdown","6378e206":"markdown","9d6284b8":"markdown","e28ab14a":"markdown","bbf2050d":"markdown","d3b9050d":"markdown","c1d1ff9d":"markdown","c61532eb":"markdown","d7fea21d":"markdown","d25971dc":"markdown","d77eb8c3":"markdown","d68c54d4":"markdown","6112861f":"markdown"},"source":{"ed96bff1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","976f26be":"import csv\nimport matplotlib.pyplot as plt\n\nfields = ['timestamp', 'text']\n\ntweets = pd.read_csv('..\/input\/bitcoin-tweets-20160101-to-20190329\/tweets.csv', delimiter=';', usecols=fields, nrows=1000000)\ntweets.tail()","14ad0723":"tweets.head()","c2209b31":"for index, row in tweets.iterrows():\n    row['timestamp'] = row['timestamp'][0:10]\ntweets","3fb74069":"fields = ['Date', 'Open', 'Close']\ncoin = pd.read_csv('..\/input\/cryptocurrencypricehistory\/coin_Bitcoin.csv', usecols=fields)","839cef7a":"coin","54250dd6":"dates = []\nchange_positive = []\nfor index, row in coin.iterrows():\n    dates.append(row['Date'][0:10])\n    change_positive.append(row['Open'] < row['Close'])\n","3547640a":"coin_price = {}\n\nfor i in range(len(dates)):\n    coin_price[dates[i]] = change_positive[i]","04929ba6":"tweet_rise = []\n\nfor index, row in tweets.iterrows():\n    if row['timestamp'] in coin_price.keys():\n        tweet_rise.append(coin_price[row['timestamp']])\n    else:\n        tweet_rise.append(np.NaN)","dd15bc35":"tweets['rise'] = tweet_rise","96d4f06a":"for i in range(20):\n    print(tweets.loc[[i]])","06498007":"cleaned = tweets[['text', 'rise']].copy()\ncleaned","e4737736":"cleaned.to_csv('bitcoin_tweet_output.csv', index = False)","7954c204":"select_indices = list(np.where(cleaned[\"rise\"] == False)[0])\nfall_data = select_indices[0:10000]\nfall = cleaned.iloc[fall_data,:] \n\nfall.to_csv('fall.csv', index = False)","f701f9c0":"select_indices = list(np.where(cleaned[\"rise\"] == True)[0])\nrise_data = select_indices[0:10000]\nrise = cleaned.iloc[rise_data,:] \n\nrise.to_csv('rise.csv', index = False)","271ce5ea":"### Output all data and export as \"bitcoin_tweet_output.csv\"","828fa3cd":"### Create new lists of dates and price fluctuations","6378e206":"### Create a dictionary of historical bitcoin price changes by day from the lists","9d6284b8":"### Remove time frome timestamp","e28ab14a":"### Create new dataframe from only the tweet text and the pricing change data columns","bbf2050d":"## Data Cleaning:","d3b9050d":"# Link to PDF of Project Documentation: \n## https:\/\/drive.google.com\/file\/d\/15mWlqqjN-Agscu5fVHOxtt2uU-yGsPan\/view?usp=sharing","c1d1ff9d":"### Import historical bitcoin price data","c61532eb":"### Add a new column in the bit coin pricing data to indicate whether bit coin rose or fell that day","d7fea21d":"### Import Bitcoin Tweet Data","d25971dc":"### Output 10000 tweets from days when prices rose and export as \"rise.csv\"","d77eb8c3":"### Output 10000 tweets from days when prices fell and export as \"fall.csv\"","d68c54d4":"<hr>","6112861f":"### Add the price change of that day to each tweet data"}}