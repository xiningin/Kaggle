{"cell_type":{"cfd1c3dd":"code","7ec8832a":"code","85791e56":"code","a8f0050c":"code","2e71bfd8":"code","7f4748dc":"code","2dfa8955":"code","1867c960":"code","f8c0a31a":"code","be40607e":"code","59a7073e":"code","a13d5734":"code","132816db":"code","9a0a1aab":"code","f8ac2007":"code","792746b9":"code","535722d1":"code","1ac649c0":"markdown","2c0fba33":"markdown"},"source":{"cfd1c3dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sklearn.preprocessing\nimport seaborn as sns\nimport plotly.graph_objects as go\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ec8832a":"!pip install openpyxl","85791e56":"import matplotlib.pyplot as plt\nplt.style.use('ggplot')","a8f0050c":"#reading the data\npath = '\/kaggle\/input\/anomaly-detection-smart-meter-data-sample\/Lastgang Elektroverbruche 160101-170511.xlsx'\ndf = pd.read_excel(path, engine='openpyxl', index_col=0)","2e71bfd8":"df.isnull().sum()","7f4748dc":"#renaming the columns\ndf.index.name ='datetime'\ndf.columns = ['energy']\ndf.head()","2dfa8955":"df['date'] = df.index.date\ndf['time'] = df.index.time\ndf['year'] = df.index.year\ndf['weekday'] = df.index.strftime(\"%A\")\ndf.head()","1867c960":"#Entire load curve and the daily load trends\n_ = df.pivot_table(index=df.index, \n                     values='energy').plot(figsize=(15,4),\n                     title='Entire Load Curve')\n_ = df.pivot_table(index=df['time'], \n                     values='energy',\n                     aggfunc=np.mean).plot(figsize=(15,4),\n                     title='Daily Load Trends')","f8c0a31a":"#Load distributions & daily load curve\n_ = df['energy'].plot.hist(figsize=(15, 5), bins=100, title='Load Distribution')\n\n_ = df.pivot_table(index=df['time'], \n                     columns='weekday', \n                     values='energy',\n                     aggfunc=np.mean).plot(figsize=(15,4),\n                     title='Energy Daily Load Curve Trends')","be40607e":"#normalize the energy data\ndef normalize_data(df):\n    scaler = sklearn.preprocessing.MinMaxScaler()\n    df['energy']=scaler.fit_transform(df['energy'].values.reshape(-1,1))\n    return df\n\ndf_norm = normalize_data(df)\ndf_norm = df_norm.drop(columns=['date','time','year','weekday'])\ndf_norm.shape","59a7073e":"df_norm.head()","a13d5734":"#data_loading\ndef load_data(stock, seq_len):\n    X_train = []\n    y_train = []\n    for i in range(seq_len, len(stock)):\n        X_train.append(stock.iloc[i-seq_len : i, 0])\n        y_train.append(stock.iloc[i, 0])\n    \n    X_test = X_train[40000:]             \n    y_test = y_train[40000:]\n    \n    X_train = X_train[:40000]           \n    y_train = y_train[:40000]\n    \n    X_train = np.array(X_train)\n    y_train = np.array(y_train)\n    \n    X_test = np.array(X_test)\n    y_test = np.array(y_test)\n    \n    #4 reshape data to input into RNN models\n    X_train = np.reshape(X_train, (40000, seq_len, 1))\n    X_test = np.reshape(X_test, (X_test.shape[0], seq_len, 1))\n    \n    return [X_train, y_train, X_test, y_test]","132816db":"seq_len = 20\n\nX_train, y_train, X_test, y_test = load_data(df_norm, seq_len)\n\nprint('X_train.shape = ',X_train.shape)\nprint('y_train.shape = ', y_train.shape)\nprint('X_test.shape = ', X_test.shape)\nprint('y_test.shape = ',y_test.shape)","9a0a1aab":"from sklearn.metrics import r2_score\n\nfrom keras.layers import Dense,Dropout,SimpleRNN,LSTM\nfrom keras.models import Sequential\n\nrnn_model = Sequential()\n\nrnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True, input_shape=(X_train.shape[1],1)))\nrnn_model.add(Dropout(0.15))\n\nrnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=True))\nrnn_model.add(Dropout(0.15))\n\nrnn_model.add(SimpleRNN(40,activation=\"tanh\",return_sequences=False))\nrnn_model.add(Dropout(0.15))\n\nrnn_model.add(Dense(1))\n\nrnn_model.summary()","f8ac2007":"rnn_model.compile(optimizer=\"adam\",loss=\"MSE\")\nrnn_model.fit(X_train, y_train, epochs=10, batch_size=80)","792746b9":"rnn_predictions = rnn_model.predict(X_test)\n\nrnn_score = r2_score(y_test,rnn_predictions)\nprint(\"R2 Score of RNN model = \",rnn_score)","535722d1":"def plot_predictions(test, predicted, title):\n    plt.figure(figsize=(16,4))\n    plt.plot(test, color='blue',label='Actual power consumption data')\n    plt.plot(predicted, alpha=0.7, color='orange',label='Predicted power consumption data')\n    plt.title(title)\n    plt.xlabel('Time')\n    plt.ylabel('Normalized power consumption scale')\n#     plt.xlim(0,200)\n    plt.legend()\n    plt.show()\n    \nplot_predictions(y_test, rnn_predictions, \"Load Predictions Validation\")","1ac649c0":"# Simple RNN Model by ignoring the anomalies","2c0fba33":"# Anomalies Detection Model\nWill be done in another notebook"}}