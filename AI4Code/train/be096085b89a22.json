{"cell_type":{"059e9330":"code","9b143692":"code","6de4ad6f":"code","e20b6d46":"code","92c1afc7":"code","91050fb5":"code","3f3bd129":"code","8a40eb42":"code","7cf189f0":"code","bc7ca43a":"code","f8a282f9":"code","4cdb6024":"code","3747eac3":"code","6924551f":"code","ed3ea66f":"code","4ab5af98":"code","495fa941":"code","75e40802":"code","2012e988":"code","e23aa264":"code","dc07339f":"code","ab85cee5":"code","e427b7fb":"code","d16fe9b2":"code","551da1e2":"code","dcb2d7a7":"code","f809671a":"code","096bce35":"code","77888d8f":"code","2609a8fe":"code","d22e12c9":"code","ceb6903d":"markdown","da4e05c9":"markdown","50fa622e":"markdown","00c50b04":"markdown","5b9cff59":"markdown","689ac5b8":"markdown","1d4312b3":"markdown","8ae8b815":"markdown","96cc9bd4":"markdown","986494aa":"markdown","10ab4aa7":"markdown","42a12a51":"markdown","34390552":"markdown","c9f69219":"markdown","02d35ded":"markdown","f64d93fb":"markdown","d79f7ce6":"markdown","62cca56f":"markdown","cb8208ed":"markdown","72951f82":"markdown","77620dd1":"markdown","18950d5e":"markdown"},"source":{"059e9330":"# Importing the main libraries\nimport numpy as np\nimport pandas as pd\n\n# Notebook settings\n%matplotlib inline\n\n# Importing data visualization libraries\nimport plotly.express as px\nimport seaborn as sns\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport folium\n\n# Data visualization settings\nsns.set_style(\"whitegrid\")\n\n# Disable warnings\nimport warnings\nwarnings.filterwarnings('ignore')","9b143692":"# Loading the first dataset\ndf = pd.read_csv('\/kaggle\/input\/housing-in-london\/housing_in_london_monthly_variables.csv')","6de4ad6f":"# Checking the dataset variables\ndf.info()","e20b6d46":"# Viewing a sample of the dataset\ndf.head()","92c1afc7":"# Showing min and max dates\nprint(df['date'].min())\nprint(df['date'].max())","91050fb5":"# Viewing the available areas in the dataset that aren't london boroughs\ndf[df['borough_flag'] == 0]['area'].unique()","3f3bd129":"# Viewing the london boroughs\ndf[df['borough_flag'] == 1]['area'].unique()","8a40eb42":"# Converting the date variable to a date object\ndf['date'] = pd.to_datetime(df['date'])","7cf189f0":"# Now let's see the number of houses sold in London over time\nhouses_sold_london = df[df['area'] == 'london'] \\\n                       .groupby('date')['houses_sold'] \\\n                       .sum() \\\n                       .reset_index() \\\n                       .rename(columns={'date':'Date', 'houses_sold':'Houses Sold'})\nhouses_sold_london","bc7ca43a":"# Let's plot the information above in the past two decades\nfig = px.line(houses_sold_london[(houses_sold_london['Date'] >= '2000-01-01') & \\\n             (houses_sold_london['Date'] < '2019-12-01')],\n              x=\"Date\", y=\"Houses Sold\",\n              template='seaborn', title='Sold Houses in London')\n\nfig","f8a282f9":"# In order to represent this events, we can plot them in the graph below\nfig.add_shape( # Shape representing the decrease\n    type=\"rect\",\n    xref=\"x\",\n    yref=\"paper\",\n    x0=\"2007-08-01\",\n    y0=0,\n    x1=\"2009-02-01\",\n    y1=1,\n    fillcolor=\"lightpink\",\n    opacity=0.5,\n    layer=\"below\",\n    line_width=0,\n)\n\nfig.add_shape( # Shape representing the surge\n    type=\"rect\",\n    xref=\"x\",\n    yref=\"paper\",\n    x0=\"2016-02-01\",\n    y0=0,\n    x1=\"2016-04-01\",\n    y1=1,\n    fillcolor=\"lightgreen\",\n    opacity=0.5,\n    layer=\"below\",\n    line_width=0\n)","4cdb6024":"# Getting the avg for each decade and plotting in the graph\navg_first_decade = houses_sold_london[(houses_sold_london['Date'] >= '2000-01-01') & \\\n                                      (houses_sold_london['Date'] <= '2009-12-01')]['Houses Sold'] \\\n                                      .mean()\n\navg_first_decade = round(avg_first_decade, 0)\n\nfig.add_shape( # add a horizontal line, representing the avg in the first decade\n    type=\"line\", line_color=\"coral\", line_width=2, opacity=1, line_dash=\"dot\",\n    x0=0, x1=1, xref=\"paper\", y0=avg_first_decade,\n    y1=avg_first_decade, yref=\"y\"\n)\n\nfig.add_annotation( # add a text \n    text=\"2000s average\", x='2020-01-01', y=12000 \n)\n\navg_second_decade = houses_sold_london[(houses_sold_london['Date'] >= '2010-01-01') & \\\n                                      (houses_sold_london['Date'] <= '2019-12-01')]['Houses Sold'] \\\n                                      .mean()\n\navg_second_decade = round(avg_second_decade, 0)\n\nfig.add_shape( # add a horizontal line, representing the avg in the second decade\n    type=\"line\", line_color=\"darkcyan\", line_width=2, opacity=1, line_dash=\"dash\",\n    x0=0, x1=1, xref=\"paper\", y0=avg_second_decade,\n    y1=avg_second_decade, yref=\"y\",  \n)\n\nfig.add_annotation( # add a text \n    text=\"2010s average\", x='2020-01-01', y=8300 \n)","3747eac3":"# First, let's create a new dataframe with the required information for the plot\navg_price_df = df[df['area'].isin(['south east', 'north east', 'north west',\n                                    'yorks and the humber', 'east midlands', \n                                    'east of england', 'london', 'south west', 'west midlands'])] \\\n                            .filter(['date','area','average_price']) \\\n                            .rename(columns={'date':'Date','area':'Region','average_price':'Average Price'}) \\\n                            .sort_values(by='Date')\n\navg_price_df","6924551f":"# Let's plot the information above in the past two decades\npx.line(avg_price_df[(avg_price_df['Date'] >= '2000-01-01') & \\\n       (avg_price_df['Date'] < '2019-12-01')],\n        x=\"Date\", y=\"Average Price\", color=\"Region\",\n        template='seaborn', title='Average House Price in England by Region')\n","ed3ea66f":"# First we need to calculate the growth rate between the two periods for all the regions\ngrowth_rate_df = avg_price_df[avg_price_df['Date'].isin(['2013-01-01','2016-07-01'])] \\\n                             .pivot(index='Region', columns='Date', values='Average Price') \\\n                             .rename(columns=lambda t: t.strftime('%Y-%m')) \\\n                             .reset_index() \\\n                             .rename(columns={'2013-01':'P1','2016-07':'P2'}) \\\n                             .eval('GR=((P2-P1)\/P1)*100') \\\n                             .rename(columns={'GR':'Growth Rate'}) \\\n                             .round({'Growth Rate': 2})","4ab5af98":"# Loading the map file containing England's regions with the geopandas library\nengland_map = gpd.read_file(\"https:\/\/github.com\/martinjc\/UK-GeoJSON\/blob\/master\/json\/electoral\/eng\/eer.json?raw=truen\")\nengland_map.head(10)","495fa941":"# Standardizing the regions' names and merging them in a unique dataframe\ngrowth_rate_df['Region'] = growth_rate_df['Region'].str.title()\ngrowth_rate_df['Region'] = growth_rate_df['Region'].replace({'Yorks And The Humber':'Yorkshire and The Humber', \n                                                             'East Of England':'East of England'})\nengland_map['EER13NM'] = england_map['EER13NM'].replace({'Eastern':'East of England'})\n\nmerged_df = pd.merge(england_map, growth_rate_df, how='left', left_on='EER13NM', right_on='Region')\nmerged_df.head(10)","75e40802":"# Now, we can use the folium library to plot an interactive choropleth map\n\n# Setting the coordinates for the map\ngrowth_rate_map = folium.Map(location=[52.6033, -1.4183], zoom_start=6)\n\n# Creating the choropleth layer\nchoropleth = folium.Choropleth(merged_df, data=merged_df,\n                  key_on='feature.properties.Region',\n                  columns=['Region', 'Growth Rate'], \n                  fill_color='Reds', fill_opacity = 1,\n                  line_opacity=0.3, highlight=True,\n                  name='England', legend_name='% Growth Rate - Jan\/13 to Jul\/16').add_to(growth_rate_map)\n\n# Adding the layers to the map\nfolium.LayerControl().add_to(growth_rate_map)\n\n# Adding the tooltip to the map\nchoropleth.geojson.add_child(\n    folium.features.GeoJsonTooltip(['Region','Growth Rate'])\n)\n\n# Displaying the map\ngrowth_rate_map","2012e988":"# Loading the geojson file containing the city boroughs with the geopandas library\nlondon_map = gpd.read_file('https:\/\/skgrange.github.io\/www\/data\/london_boroughs.json')","e23aa264":"# Creating a dataframe with the data to be used in the map\nborough_df = df[(df['borough_flag'] == 1) & (df['date'] >= '2000-01-01') & (df['date'] <= '2019-12-01')] \\\n               .groupby('area')['houses_sold'] \\\n               .sum() \\\n               .reset_index() \\\n               .rename(columns={'area':'Borough','houses_sold':'Houses Sold'})","dc07339f":"# Merging the dataframe with the dataframe containing geographical information\nlondon_map['name'] = london_map['name'].str.lower()\n\nborough_map = pd.merge(london_map, borough_df, how='left', left_on='name', right_on='Borough')\nborough_map.head()","ab85cee5":"# Now, in the same way as we did with the growth rate map, we can plot the borough map\n# Setting the coordinates for the map\nhouses_sold_borough_map = folium.Map(location=[51.509865,  -0.118092], zoom_start=10)\n\n# Creating the choropleth layer\nchoropleth_borough = folium.Choropleth(borough_map, data=borough_map,\n                     key_on='feature.properties.Borough',\n                     columns=['Borough', 'Houses Sold'], \n                     fill_color='Blues', fill_opacity = 1, bins=8,\n                     line_opacity=0.3, highlight=True, \n                     name='Houses Sold', legend_name='# Houses Sold').add_to(houses_sold_borough_map)\n\n# Adding the layers to the map\nfolium.LayerControl().add_to(houses_sold_borough_map)\n\n# Adding the tooltip to the map\nchoropleth_borough.geojson.add_child(\n    folium.features.GeoJsonTooltip(['Borough','Houses Sold'])\n)\n\n# Displaying the map\nhouses_sold_borough_map","e427b7fb":"# We will plot a heatmap in order to show this information\n# Data for the plot\nbyYearBorough_df = df.copy()\n\nbyYearBorough_df['Year'] = byYearBorough_df['date'].dt.year\n\nbyYearBorough_df = byYearBorough_df[(byYearBorough_df['Year'] >= 2000) & (byYearBorough_df['Year'] <= 2019) & \\\n                                    (byYearBorough_df['borough_flag'] == 1)] \\\n                                   .groupby(['Year','area'])['houses_sold'] \\\n                                   .sum() \\\n                                   .reset_index() \\\n                                   .rename(columns={'area':'Borough','houses_sold':'Houses Sold'})\n\nbyYearBorough_df = pd.pivot_table(data=byYearBorough_df,values='Houses Sold',index='Borough',\n                                  columns='Year',aggfunc='sum')\n\n# Plot\nplt.figure(figsize=(15,8))\nsns.heatmap(data = byYearBorough_df, cmap='viridis', linecolor='grey', linewidth=0.2)\nplt.title('Houses Sold in London by Borough \\n2000-2019')","d16fe9b2":"# Plotting sold houses and average prices between Inner and Outer London areas\ninner_outer_df = df[(df['area'].isin(['inner london','outer london'])) & (df['date'].dt.year >= 2000) & (df['date'].dt.year <= 2019)] \\\n                   .groupby(['date','area'])['houses_sold','average_price'] \\\n                   .agg({'houses_sold':'sum','average_price':'mean'}) \\\n                   .reset_index() \\\n                   .rename(columns={'date':'Date','area':'Area','houses_sold':'Houses Sold','average_price':'Average Price'}) \\\n                   .melt(id_vars=['Date','Area'])\n\nfig = px.line(inner_outer_df, x='Date', y='value', color='Area', facet_row='variable',\n              title = 'Sold Houses and Average Price - Inner and Outer London')\n\nfig.update_yaxes(matches=None) # Allows the y axes on both facets to be independent from each other","551da1e2":"# Loading the second dataset\ndf_yearly = pd.read_csv('\/kaggle\/input\/housing-in-london\/housing_in_london_yearly_variables.csv')","dcb2d7a7":"# Checking the dataset variables\ndf_yearly.info()","f809671a":"# Viewing a sample of the dataset\ndf_yearly.head()","096bce35":"# Data cleaning \n\n# Replacing incorrect strings in numeric columns\ndf_yearly.replace(['','-','#','na'], np.nan, inplace=True)\n\n# Converting data types\ndf_yearly['mean_salary'] = df_yearly['mean_salary'].astype(float)\ndf_yearly['recycling_pct'] = df_yearly['recycling_pct'].astype(float)","77888d8f":"# Data preparation\n\n# Aggregating the first dataset\ndf_aggregated = df.groupby([df['date'].dt.year,'area'])['houses_sold','average_price', 'no_of_crimes'] \\\n                  .agg({'houses_sold':'sum','average_price':'mean','no_of_crimes':'sum'}) \\\n                  .reset_index()\n\n# Converting date in the second dataset\ndf_yearly['date'] = pd.to_datetime(df_yearly['date']).dt.year\n\n# Merging the dataframes on date and area\nconsolidated_df = pd.merge(df_aggregated, df_yearly, how='inner', on=['date','area'])\n\n# Viewing the result\nconsolidated_df.head()","2609a8fe":"# Plotting a correlation matrix\nplt.figure(figsize=(15,8))\nsns.heatmap(consolidated_df.corr(), annot=True, fmt='.2g', vmin=-1, vmax=1, center=0,\n            mask=np.triu(consolidated_df.corr()), cmap='cividis', )\nplt.title('Correlation Matrix')","d22e12c9":"plot_df = consolidated_df[(consolidated_df['area'] == 'london') & (df['date'] >= '2000-01-01') & (df['date'] <= '2019-12-01')] \\\n                         .filter(['date','average_price','median_salary']) \\\n                         .melt('date') \\\n                         .rename(columns={'date':'Date','variable':'Indicator','value':'Value'})\n                             \nvsPlot = px.line(plot_df, x='Date', y='Value', color='Indicator',\n                 title = 'Cost of Living vs Income')\n\nvsPlot.update_layout(yaxis_type=\"log\", yaxis_title='Value (Log)')","ceb6903d":"Analyzing the plot above we can see that while the **median salary grew 61%** in the period, the **average price of a house in the city grew an astonishing 232%**","da4e05c9":"From the plot above we see that Outer London had a higher number of houses sold and a lower average price in comparison to Inner London. Now let's explore the relationship between these two variables and other ones.","50fa622e":"Observing the correlation matrix, we can draw some conclusions:\n\n- The number of sold houses has an expected strong correlation to the size (area and number of houses) and the population of the area\n- The number of sold houses also has a strong correlation to the number of jobs of the area, showing that the area's economy is a important determinant to this indicator\n- The average price indicator has a high correlation to the median salary, or in other terms, the highest income a person has, the most expensive is the area she lives in","00c50b04":"#### How many houses were sold in Inner and Outer London areas? What about the average price in both regions?","5b9cff59":"From both plots above, we can see that the boroughs with the highest number of houses sold in the period were **Wandsworth**, **Bromley** and **Croydon**. Besides that, looking into the heatmap we can say that boroughs that had the most positive results in the pre-crisis period continued to show good results in the 2010s compared to the other boroughs. ","689ac5b8":"#### How many houses were sold in London by Borough?","1d4312b3":"Now we will plot a correlation matrix, to see if we can get some insights.","8ae8b815":"#### How many houses were sold in London over time?","96cc9bd4":"First we will see how many houses were sold in each borough in the past two decades.","986494aa":"#### How the average house price behave in the same period? How did it behave in the other regions?","10ab4aa7":"As the granularity of the information presented in the datasets are differents, we have to aggregate the information in the monthly dataset.","42a12a51":"We can also see with the plot that the average number of houses sold monthly in the first decade is higher than in the second decade. So let's confirm that.","34390552":"#### Bonus: Was the growth in the cost of living in London followed by a proper growth in income?","c9f69219":"## Exploratory Data Analysis","02d35ded":"## Setup","f64d93fb":"From this plot, the two things that most grabs our attention is the sharp decrease occured in the 2007-2008 period and the unusual surge that occured in March\/2016. From a search on Google we can see that:\n\n1. The Sharp decrease seen in the 2007-2008 period was due to the global financial crisis.\n2. The surge in March\/2016 occured because of a rush to beat an increase in the tax bill on buying a second home, that came into effect in April\/2016.\n\n![surge_housing.png](attachment:surge_housing.png)","d79f7ce6":"## Overview","62cca56f":"#### Relationship between number of houses sold and average price with another variables","cb8208ed":"Analyzing the plot above, we confirmed that London had the highest growth rate (~ 53%) among all the regions in the period.","72951f82":"From observing the plot, we see that London had a higher average price in the past two decades, followed by the Southeast and the East of England regions. We can say that it seems that the regions had a similar trend regarding house prices in the period. The most visible exception is London, that appears to have had a higher growth rate compared to the other regions in the period from January\/2013 to July\/2016. So let's confirm that by plotting a map.","77620dd1":"From the plot above we see that the average monthly sales in the 2000s decade (~ 11950 sales\/month) was 44% higher than in the second decade of the century (~ 8260 sales\/month), showing that the market didn't recover to pre-crisis levels.","18950d5e":"Now, let's see how those sales occured over time."}}