{"cell_type":{"072f290f":"code","f546d58b":"code","57f2a4fc":"code","aa3a2326":"code","0a537be4":"code","90be0d81":"code","3145412e":"code","3aa7f7f7":"code","3a273755":"code","ecb8b8d7":"code","14fb0fec":"code","b1d175c9":"code","038198b7":"code","b31e3928":"code","47a89646":"code","78ac9ba3":"code","f2436c49":"code","6e7811a2":"code","abd4590b":"code","ae28b116":"code","62292071":"code","51ff21bd":"code","1242cea8":"code","30a567d8":"code","a13a74ca":"markdown","a2699524":"markdown","52d489f4":"markdown","755eb33b":"markdown","be3f31cf":"markdown"},"source":{"072f290f":"!nvidia-smi","f546d58b":"!pip install -q glob2\nimport glob2","57f2a4fc":"import numpy as np\nfrom tensorflow.keras.utils import Sequence\nimport cv2\nimport pandas as pd \nimport tensorflow as tf \nimport pickle\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport sklearn\nfrom sklearn.cluster import KMeans\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import models\nfrom tensorflow.keras.callbacks import * \nfrom tensorflow.keras.applications import ResNet50\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt \nfrom tensorflow.keras.metrics import MeanIoU\nimport os ","aa3a2326":"class DataGenerator(Sequence):\n    def __init__(self, all_filenames, input_size = (256, 256), batch_size = 32, shuffle = True, seed = 123, encode: dict = None, encode_with_kmean = None, color_mode = 'hsv', function = None) -> None:\n        super(DataGenerator, self).__init__()\n        assert (encode != None and encode_with_kmean == None) or (encode == None and encode_with_kmean != None), 'Not empty !'\n        assert color_mode == 'hsv' or color_mode == 'rgb' or color_mode == 'gray'\n        self.all_filenames = all_filenames\n        self.input_size = input_size\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.color_mode = color_mode\n        self.encode = encode\n        self.function = function\n        self.kmean = encode_with_kmean\n        np.random.seed(seed)\n        self.on_epoch_end()\n    def processing(self, mask):\n        d = list(map(lambda x: self.encode[tuple(x)], mask.reshape(-1,3)))\n        return np.array(d).reshape(*self.input_size, 1)\n    def __len__(self):\n        return int(np.floor(len(self.all_filenames) \/ self.batch_size))\n    def __getitem__(self, index):\n        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n        all_filenames_temp = [self.all_filenames[k] for k in indexes]\n        X, Y = self.__data_generation(all_filenames_temp)\n        return X, Y\n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.all_filenames))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    def __data_generation(self, all_filenames_temp):\n        batch = len(all_filenames_temp)\n        if self.color_mode == 'gray':\n            X = np.empty(shape=(batch, *self.input_size, 1))\n        else:\n            X = np.empty(shape=(batch, *self.input_size,3))\n        Y = np.empty(shape=(batch, *self.input_size, 1))\n        for i, (fn, label_fn) in enumerate(all_filenames_temp):\n            # img\n            img = cv2.imread(fn)\n            if self.color_mode == 'hsv':\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n            elif self.color_mode == 'rgb':\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            elif self.color_mode == 'gray':\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n                img = tf.expand_dims(img, axis = 2)\n            img = tf.image.resize(img, self.input_size, method = 'nearest')\n            img = tf.cast(img, tf.float32)\n            img \/= 255.\n            \n            #mask\n            mask = cv2.imread(label_fn, 0)\n            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n            mask = tf.image.resize(mask, self.input_size, method= 'nearest')\n            mask = np.array(mask)\n            if self.function:\n                mask = self.function(mask)\n            if self.encode:\n                mask = self.processing(mask)\n            if self.kmean:\n                mask = self.kmean.predict(mask.reshape(-1,3)).reshape(*self.input_size, 1)\n            mask = tf.cast(mask, tf.float32)\n            X[i,] = img\n            Y[i,] = mask\n        return X, Y","0a537be4":"def encode_label(mask):\n    # input (batch, rows, cols, channels)\n    colors = np.unique(mask.reshape(-1,3), axis = 0)\n    encoder = dict((tuple(j),i) for i,j in enumerate(colors)) # key is tuple \n    _label = dict((j, list(i)) for i,j in encoder.items())\n    with open('label.pickle', 'wb') as handel:\n        pickle.dump(_label, handel, protocol= pickle.HIGHEST_PROTOCOL)\n    return encoder\ndef encode_label_with_Kmeans(mask, classes):\n    kmean = KMeans(classes, max_iter= 400)\n    kmean.fit(mask)\n    pred = kmean.predict(mask)\n    classes_real =  len(set(pred))\n    print(f'classes: {classes_real}')\n    label = dict((j, i.tolist()) for i,j in list(zip(mask, pred))) # key is tuple \n    with open('label.pickle', 'wb') as handel:\n        pickle.dump(label, handel, protocol= pickle.HIGHEST_PROTOCOL)\n    with open('kmean.pickle', 'wb') as handle:\n        pickle.dump(kmean, handle, protocol= pickle.HIGHEST_PROTOCOL)\n    return kmean\ndef decode_label(predict, label):\n    d = list(map( lambda x: label[int(x)], predict.reshape(-1,1)))\n    img =  np.array(d).reshape(predict.shape[0], predict.shape[1], 3)\n    return img\ndef DataLoader(all_train_filename, all_mask,  all_valid_filename = None, input_size = (256,256), batch_size = 4, shuffle = True, seed = 123, color_mode = 'hsv', function = None, encode_with_kmeans = False, classes = 0) -> None:\n    mask_folder = sklearn.utils.shuffle(all_mask, random_state = 47)[:16]\n    mask = [tf.image.resize(cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB), (128,128), method = 'nearest') for img in mask_folder ]\n    mask = np.array(mask)\n    kmean = None\n    encode = None\n    if function and encode_with_kmeans == False:\n        mask = function(mask)\n    if encode_with_kmeans == False:\n        encode = encode_label(mask)\n    elif encode_with_kmeans == True:\n        kmean = encode_label_with_Kmeans(mask.reshape(-1,3), classes)\n    train = DataGenerator(all_train_filename, input_size, batch_size , shuffle, seed, encode, kmean, color_mode, function)\n    if all_valid_filename == None: \n        return train, None\n    else:\n        valid = DataGenerator(all_valid_filename, input_size, batch_size, shuffle, seed, encode, kmean, color_mode, function)\n        return train, valid","90be0d81":"class m_iou():\n    def __init__(self, classes: int) -> None:\n        self.classes = classes\n    def mean_iou(self,y_true, y_pred):\n        y_pred = np.argmax(y_pred, axis = 3)\n        miou_keras = MeanIoU(num_classes= self.classes)\n        miou_keras.update_state(y_true, y_pred)\n        return miou_keras.result().numpy()\n    def miou_class(self, y_true, y_pred):\n        y_pred = np.argmax(y_pred, axis = 3)\n        miou_keras = MeanIoU(num_classes= self.classes)\n        miou_keras.update_state(y_true, y_pred)        \n        values = np.array(miou_keras.get_weights()).reshape(self.classes, self.classes)\n        for i in  range(self.classes):\n            class_iou = values[i,i] \/ (sum(values[i,:]) + sum(values[:,i]) - values[i,i])\n            print(f'IoU for class{str(i + 1)} is: {class_iou}')","3145412e":"def decoder_block(x, y, filters):\n    x = UpSampling2D()(x)\n    x = Concatenate(axis = 3)([x,y])\n    x = Conv2D(filters, 3, padding= 'same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    x = Conv2D(filters, 3, padding= 'same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n\n    return x\n\ndef resnet50_unet(input_shape, *, classes, dropout):\n    \"\"\" Input \"\"\"\n    inputs = Input(input_shape)\n\n    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n\n    \"\"\" Encoder \"\"\"\n    s1 = resnet50.get_layer(\"input_1\").output          \n    s2 = resnet50.get_layer(\"conv1_relu\").output       \n    s3 = resnet50.get_layer(\"conv2_block3_out\").output \n    s4 = resnet50.get_layer(\"conv3_block4_out\").output  \n\n    x = resnet50.get_layer(\"conv4_block6_out\").output  \n\n    \"\"\" Decoder \"\"\"\n    x = decoder_block(x, s4, 512)                     \n    x = decoder_block(x, s3, 256)                    \n    x = decoder_block(x, s2, 128)                    \n    x = decoder_block(x, s1, 64)                      \n\n    x = Dropout(dropout)(x)\n    outputs = Conv2D(classes, 1, activation=\"softmax\")(x)\n    model = models.Model(inputs, outputs, name=\"ResNet50_U-Net\")\n    model.summary()\n    return model","3aa7f7f7":"def show_history(history, validation : bool = False):\n    if validation:\n        # Loss\n        fig, axes = plt.subplots(figsize= (20,5))\n        # Train\n        axes.plot(history.epoch, history.history['loss'], color= 'r',  label = 'Train')\n        axes.plot(history.epoch, history.history['val_loss'], color = 'b', label = 'Val')\n        axes.set_xlabel('Epoch')\n        axes.set_ylabel('Loss')\n        axes.legend()\n        # Acc\n        fig, axes = plt.subplots(figsize= (20,5))\n        # Train\n        axes.plot(history.epoch, history.history['acc'], color= 'r',  label = 'Train')\n        axes.plot(history.epoch, history.history['val_acc'], color = 'b', label = 'Val')\n        axes.set_xlabel('Epoch')\n        axes.set_ylabel('Acc')\n        axes.legend()\n        # Mean Iou\n        fig, axes = plt.subplots(figsize= (20,5))\n        # Train\n        axes.plot(history.epoch, history.history['mean_iou'], color= 'r',  label = 'Train')\n        axes.plot(history.epoch, history.history['val_mean_iou'], color = 'b', label = 'Val')\n        axes.set_xlabel('Epoch')\n        axes.set_ylabel('MeanIoU')\n        axes.legend()\n    else:\n        fig, axes = plt.subplots(1,4, figsize= (20,5))\n        # loss\n        axes[0].plot(history.epoch, history.history['loss'])\n        axes[0].set_title('Train')\n        axes[0].set_xlabel('Epoch')\n        axes[0].set_ylabel('Loss')\n        # Acc\n        axes[1].plot(history.epoch, history.history['acc'])\n        axes[1].set_title('Train')\n        axes[1].set_xlabel('Epoch')\n        axes[1].set_ylabel('Acc')\n        # Mean Iou\n        axes[2].plot(history.epoch, history.history['mean_iou'])\n        axes[2].set_title('Train')\n        axes[2].set_xlabel('Epoch')\n        axes[2].set_ylabel('MeanIoU')","3a273755":"def predict(model, image_test, label, color_mode, size):\n    image = cv2.imread(image_test)\n    if color_mode == 'hsv':\n        image_cvt = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    elif color_mode == 'rgb':\n        image_cvt = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    elif color_mode == 'gray':\n        image_cvt = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image_cvt = tf.expand_dims(image_cvt, axis = 2)\n    image_cvt = tf.image.resize(image_cvt, size, method= 'nearest')\n    image_cvt = tf.cast(image_cvt, tf.float32) \n    image_norm = image_cvt \/ 255.\n    image_norm = tf.expand_dims(image_norm, axis= 0)\n    new_image = model(image_norm)\n    image_argmax = np.argmax(tf.squeeze(new_image, axis = 0), axis = 2)\n    image_decode = decode_label(image_argmax, label)\n    predict_img = tf.cast(tf.image.resize(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), size, method = 'nearest'), tf.float32) * 0.7 + image_decode * 0.3\n    return np.floor(predict_img).astype('int'), new_image","ecb8b8d7":"def show_example(image, mask, model, label, inp_size, color_mode, function = None, kmean = None):\n    img = cv2.cvtColor(cv2.imread(image),cv2.COLOR_BGR2RGB)\n    img = tf.image.resize(img, inp_size, method ='nearest')\n    pred, _pred= predict(model, image, label, color_mode, inp_size)\n    if mask != None:\n        msk= cv2.cvtColor(cv2.imread(mask), cv2.COLOR_BGR2RGB)\n        msk= tf.image.resize(msk, inp_size, method = 'nearest')\n        if function:\n            y_true = tf.convert_to_tensor(function(msk.numpy()))\n        if kmean:\n            y_true = kmean.predict(msk.numpy().reshape(-1,3)).reshape(*inp_size, 1)\n        else:\n            y_true = train_data.processing(msk.numpy())\n        m.miou_class(y_true, _pred)\n        y_true = decode_label(y_true, label)\n        ground_truth = np.floor(img.numpy() * 0.7 + y_true * 0.3).astype('int')\n        fig, axes = plt.subplots(1,3, figsize = (12,3))\n        axes[0].imshow(img)\n        axes[0].set_title('Original Image')\n        axes[1].set_title('Ground truth')\n        axes[1].imshow(ground_truth)\n        axes[2].set_title('Prediction')\n        axes[2].imshow(pred)\n\n    else:\n        fig, axes = plt.subplots(1,2, figsize = (12,3))\n        axes[0].imshow(img)\n        axes[0].set_title('Original Image')\n        axes[1].set_title('Prediction')\n        axes[1].imshow(pred)","14fb0fec":"images = glob2.glob('..\/input\/car-segmentation\/car-segmentation\/images\/*')\nmasks = glob2.glob('..\/input\/car-segmentation\/car-segmentation\/masks\/*')\n\ndata = list(zip(images, masks))\ndata = shuffle(data, random_state= 42)\nsplit = int(0.8 * len(data))\nall_train_filenames = data[:split]\nall_valid_filenames = data[split:]","b1d175c9":"train_data, valid_data = DataLoader(all_train_filenames, masks, all_valid_filenames, (224, 224), 8, True, 47, 'hsv', None, True, 5)","038198b7":"len(all_train_filenames), len(all_valid_filenames)","b31e3928":"inp_size = (224, 224, 3)\nunet = resnet50_unet(inp_size, classes= 5, dropout= 0.3)","47a89646":"m = m_iou(5)","78ac9ba3":"checkpoint = ModelCheckpoint('resunet.h5', monitor= 'val_mean_iou', save_best_only= True, verbose= 1, mode = 'max')\nlr_R = ReduceLROnPlateau(monitor= 'loss', patience= 3, verbose= 1, factor= 0.3, min_lr= 0.00001)","f2436c49":"unet.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(), optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01), metrics= [m.mean_iou, 'acc'], run_eagerly= True)\nhistory = unet.fit(train_data, validation_data= valid_data, epochs= 110, verbose= 1, callbacks = [checkpoint, lr_R])","6e7811a2":"with open('label.pickle', 'rb') as handel:\n    label = pickle.load(handel)","abd4590b":"label","ae28b116":"with open('kmean.pickle', 'rb') as handel:\n    kmean = pickle.load(handel)","62292071":"# Change color mask \nlabel[0] = [0,0,0] \nlabel[1] = [245,0,0] \nlabel[2] = [255, 194, 7] \nlabel[3] = [155, 238, 223] \nlabel[4] = [224, 120, 35] \nlabel","51ff21bd":"show_history(history, True)","1242cea8":"from tensorflow.keras.models import load_model\nmodel = load_model('resunet.h5', custom_objects = {'mean_iou': m.mean_iou})","30a567d8":"show_example(*all_train_filenames[110], model, label, (224,224), 'hsv', kmean= kmean)","a13a74ca":"# III. Prepare data to train","a2699524":"# I. Setup","52d489f4":"# II. Defind function and Class","755eb33b":"# IV. Training","be3f31cf":"# V. Predict and show history"}}