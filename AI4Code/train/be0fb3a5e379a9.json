{"cell_type":{"fdeaee5b":"code","562d06b6":"code","8a4685cf":"code","bf0ce844":"code","8e4d54bd":"code","3c644c1c":"code","fec42009":"code","ab54ff95":"code","76b345fc":"code","2fe55de1":"code","21e313ed":"code","fe89c363":"code","91fa540a":"code","8710e471":"code","0da8a35d":"code","c3b443a2":"code","78654962":"code","3144720d":"markdown","24ccc310":"markdown","8c971833":"markdown","8a1d5f15":"markdown","aed33579":"markdown"},"source":{"fdeaee5b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","562d06b6":"%matplotlib inline\n\nimport fastai\nfrom fastai.vision.all import *\nfastai.__version__","8a4685cf":"import zipfile\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\", 'r') as zip_ref:\n    zip_ref.extractall(\".\/\")\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\", 'r') as zip_ref:\n    zip_ref.extractall(\".\/\")","bf0ce844":"path = \".\/train\"\nfiles = get_image_files(path)","8e4d54bd":"len(files)","3c644c1c":"files[:5]","fec42009":"dls = ImageDataLoaders.from_name_re(\n        path=path,\n        fnames=files,\n        pat=r'(.+)\\.\\d+.jpg$',\n        valid_pct=0.2, \n        seed=13,\n        item_tfms=Resize(224))\n\ndls.show_batch()","ab54ff95":"learn = cnn_learner(dls, resnet34, pretrained=True, metrics=[accuracy])","76b345fc":"learn.lr_find()","2fe55de1":"learn.fine_tune(1, 1e-3)","21e313ed":"learn.lr_find()","fe89c363":"learn.fine_tune(3, 7e-7)","91fa540a":"interp = ClassificationInterpretation.from_learner(learn)","8710e471":"interp.plot_confusion_matrix()","0da8a35d":"interp.plot_top_losses(9, figsize=(9,9))","c3b443a2":"learn.predict(files[1])","78654962":"learn.show_results()","3144720d":"# Prediction","24ccc310":"# Evaluate Model","8c971833":"# Unzip File","8a1d5f15":"# Check Data & Build Dataloaders","aed33579":"# Build CNN Model & Start Training"}}