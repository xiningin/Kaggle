{"cell_type":{"d1938cf6":"code","35be6e67":"code","961d115a":"code","be72e7a9":"code","ed69c169":"code","d572f103":"code","eaec3add":"code","aadaaa37":"code","0c385598":"code","46da5246":"code","60ab8e5d":"code","eeffa665":"code","e7b26cd3":"code","5be653db":"code","4d38ddde":"code","d1b0e5b7":"markdown","ade7ca0a":"markdown","f0f15da7":"markdown"},"source":{"d1938cf6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","35be6e67":"import seaborn as sb\nfrom matplotlib import pyplot as plt \nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n\n\n\ndata = pd.read_csv(\"\/kaggle\/input\/indian-migration-history\/IndianMigrationHistory1.3.csv\")\n\ndata.info()","961d115a":"# Change the name of columns \ndata = data.rename(columns ={'Migration by Gender Name' : 'Gender_Name', 'Country Dest Name' : 'Destination',\n                             '1960 [1960]' : '1960', '1970 [1970]' : '1970', '1980 [1980]' : '1980',\n                             '1990 [1990]' : '1990', '2000 [2000]': '2000' } )","be72e7a9":"# Delete unused columns\ndata.drop(['Country Origin Name', 'Country Origin Code', 'Migration by Gender Code', 'Country Dest Code'] ,\n          inplace = True , axis = 1)","ed69c169":"data.head(10)","d572f103":"data.isnull().sum()","eaec3add":"data.duplicated().sum()","aadaaa37":"# some of field fill by .. then we change them to 0 \n# also change data type from object to int \ncolumns_list = ['1960', '1970','1980','1990','2000']\ndata[columns_list] = np.where (data[columns_list] == '..' , 0 , data[columns_list])\ndata[columns_list] = data[columns_list].astype(int) \ndata.info()","0c385598":"# calculate number of people who migrate to ohter country \n# also we have some row which all decade fields are 0 in them thus we delete all of them\ndata['sum'] = data[columns_list].sum(axis = 1)\ndata.drop(data[data['sum'] == 0].index, inplace = True)\ndata.shape","46da5246":"data.describe()","60ab8e5d":"# data in dataset brings seperately by sex then as its shows down we have duplicated in 'Destination' columns\ndata['Destination'].duplicated().sum()","eeffa665":"# you can find which countries are first destination for indain \ndata_sum = data.groupby(data['Destination']).sum()\ndf_sum = pd.DataFrame(data_sum).reset_index()\ndf_sum.sort_values(by = 'sum' , ascending = False, inplace = True)\ndf_sum","e7b26cd3":"# make a dataframe based on each decade, show each decadehow many people migrate totaly \ndata.sort_values(by = 'sum' , ascending = False, inplace = True)\ndecad = {'1960' , '1970' , '1980', '1990', '2000'}\nperyear = []\nfor i in decad:\n    row = [i , data[i].sum()]\n    peryear.append(row)\ndf_peryear = pd.DataFrame(peryear)\ndf_peryear.columns =['Decade' ,'Sum']\ndf_peryear.sort_values(by= 'Decade', inplace = True)\ndf_peryear","5be653db":"df_peryear.plot.bar(x = 'Decade' , y = 'Sum')","4d38ddde":"# you can find the first destination for migration based on sex\ndata_sex = data.groupby(['Gender_Name', 'Destination']).sum().sort_values(by = 'sum' , ascending = False)\ndata_sex.head(10)","d1b0e5b7":"from 1980 the rage of migration increases every decade after a trough in 1980","ade7ca0a":"This is my first analysis, please upvote if you like.","f0f15da7":"dataset doesnt have any duplicated or null data"}}