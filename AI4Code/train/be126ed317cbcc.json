{"cell_type":{"b7990068":"code","9acb03da":"code","dc34b70c":"code","d855958d":"code","907184b3":"code","8905762c":"code","ebe42c44":"code","ff398b38":"code","3f626f9d":"code","d01a421c":"code","efbff51b":"code","99d75c18":"code","a0842882":"code","b018eb16":"code","8e2f7f7e":"code","cc7a5359":"code","2d92ab7b":"code","a559867a":"code","043e9c28":"code","86713c74":"code","07607021":"code","b1beeb2d":"code","77b8b2e9":"code","e4a0610b":"code","7bc2d929":"code","a494bd27":"code","a44207e1":"code","ae553301":"code","5bb82e0e":"code","c57de03b":"code","e98775c6":"code","2e599577":"code","3c7d5d6f":"code","bef0d0b5":"code","17f8b63b":"code","55b154d7":"code","f223b839":"code","9dffd1c0":"code","fa75c5ce":"code","79a3772a":"code","3ffc01b9":"code","4af1be54":"code","afb5dd1e":"code","6fe137bc":"code","24bfc33d":"code","7f0dc57b":"code","9f96b792":"code","e91d4ccc":"code","8e6273b7":"code","5b47d7f8":"code","c4434b27":"code","ab05df59":"code","4fb699c5":"code","f74c0780":"code","0e6874b0":"code","c1bdffe1":"code","4084b9eb":"code","9e614009":"code","4bfb42e4":"code","181b13f7":"code","3c12437d":"code","31d1dc59":"code","d7541a09":"code","8c02532f":"code","a8676090":"code","0d69ad1e":"markdown","d7004b00":"markdown","0b26aba4":"markdown"},"source":{"b7990068":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9acb03da":"data = pd.read_csv('\/kaggle\/input\/heart-failure-prediction\/heart.csv')\ndata","dc34b70c":"data.isnull().sum()#isnll counts all thezeros in the column\n#sum will count the total zeros","d855958d":"data[[\"Sex\"]]","907184b3":"x=data.drop(columns=['HeartDisease'])\nx","8905762c":"y=data.HeartDisease\ny","ebe42c44":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n","ff398b38":"x_train","3f626f9d":"y_train","d01a421c":"y_test","efbff51b":"x_test","99d75c18":"nom_cols=[1,2,8,10]\nord_cols=[6]#something goes in order","a0842882":"from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import set_config\n\ntrans=make_column_transformer((OneHotEncoder(sparse=False),nom_cols),\n                             (OrdinalEncoder(),ord_cols),\n                              remainder=\"passthrough\")\nset_config(display=\"diagram\")\ntrans","b018eb16":"from sklearn.neighbors import KNeighborsClassifier\nalgorithm=KNeighborsClassifier(11)\nalgorithm","8e2f7f7e":"from sklearn.pipeline import make_pipeline\npipe=make_pipeline(trans,algorithm)\npipe","cc7a5359":"pipe.fit(x_train,y_train)","2d92ab7b":"pred=pipe.predict(x_test)\npred","a559867a":"y_test","043e9c28":"from sklearn.metrics import accuracy_score, plot_confusion_matrix\naccuracy_score(pred,y_test)*100\nplt=plot_confusion_matrix(pipe,x_test,y_test)\nplt","86713c74":"accuracy_score(pred,y_test)*100","07607021":"x_train\n","b1beeb2d":"new=np.array([45,'F','NAP',150,354,1,'Normal',140,'Y',1.3,'Up']).reshape(1,11)\npipe.predict(new)","77b8b2e9":"from sklearn.model_selection import KFold, cross_val_score\nkf=KFold(n_splits=4)\nnp.mean(cross_val_score(pipe,x,y,cv=kf)*100)","e4a0610b":"kf=KFold(n_splits=4)\ncross_val_score(pipe,x,y,cv=kf)","7bc2d929":"kf=KFold(n_splits=4)\nnp.mean(cross_val_score(pipe,x,y,cv=kf,scoring='accuracy')*100)","a494bd27":"import seaborn as sns\nsns.countplot(y)","a44207e1":"from imblearn.under_sampling import RandomUnderSampler\nunder=RandomUnderSampler()\nu_x, u_y = under.fit_resample(x,y)\nu_y.value_counts()","ae553301":"import seaborn as sns\nsns.countplot(u_y)","5bb82e0e":"from imblearn.over_sampling import RandomOverSampler\nover=RandomOverSampler()\no_x, o_y = over.fit_resample(x,y)\no_y.value_counts()","c57de03b":"import seaborn as sns\nsns.countplot(o_y)","e98775c6":"from imblearn.over_sampling import SMOTE\ns = SMOTE()\no_x, o_y = over.fit_resample(x,y)\no_y.value_counts()","2e599577":"import seaborn as sns\nsns.countplot(o_y)","3c7d5d6f":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.pipeline import make_pipeline\nalgorithm1 = KNeighborsClassifier(5)\nalgorithm2 = DecisionTreeClassifier()\nalgorithm3 = LogisticRegression(solver = 'liblinear')\nmodel = VotingClassifier(estimators = [('x1',algorithm1),('x2',algorithm2),('x3',algorithm3)],voting = 'hard',verbose = True)\nmodel\npipe = make_pipeline(trans,model)","bef0d0b5":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\n\nparams = {'criterion':['gini','entropy'],\n         'max_depth':[None,2,5,10],\n         'min_sample_split':[2,10,100]}\n#g = GridSearchCV(DecisionTreeClassifier(),params, verbose=3)\n#g\n#pipe=make_pipeline(trans,GridSearchCV(model5,params, verbose=3,refit=True))\n#pipe","17f8b63b":"pipe.fit(x_train,y_train)","55b154d7":"pipe","f223b839":"pipe.fit(x_train,y_train)","9dffd1c0":"pred = pipe.predict(x_test)\npred","fa75c5ce":"from sklearn.metrics import accuracy_score\naccuracy_score(pred,y_test)*100","79a3772a":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(pipe,x_test,y_test)","3ffc01b9":"DecisionTreeClassifier().get_params().keys()","4af1be54":"data.head()","afb5dd1e":"new = pd.DataFrame(np.array([22,'F','ASY',140,195,1,'Normal',98,'N',1.5,'Flat']).reshape(1,11))\npipe.predict(new)","6fe137bc":"y.value_counts()","24bfc33d":"import seaborn as sns\nsns.countplot(y)","7f0dc57b":"from imblearn.under_sampling import RandomUnderSampler\nunder = RandomUnderSampler()\nu_x,u_y = under.fit_resample(x,y)\nu_y.value_counts()","9f96b792":"from imblearn.over_sampling import RandomOverSampler,SMOTE\nover = RandomOverSampler()\no_x,o_y = over.fit_resample(x,y)\no_y.value_counts()","e91d4ccc":"from imblearn.pipeline import make_pipeline\ns = SMOTE()\nn_pipe = make_pipeline(trans,s,algorithm1)\nn_pipe","8e6273b7":"n_pipe.fit(x_train,y_train)","5b47d7f8":"pred2 = n_pipe.predict(x_test)\npred2","c4434b27":"accuracy_score(pred2,y_test)*100","ab05df59":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(n_pipe,x_test,y_test)","4fb699c5":"from sklearn.svm import SVC\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.pipeline import make_pipeline\nmodel_7 = SVC(kernel='linear')\nmodel_8 = BaggingClassifier(base_estimator = SVC())\nmodel_8","f74c0780":"from sklearn.tree import DecisionTreeClassifier\nmodel_z = DecisionTreeClassifier()\nfrom sklearn.pipeline import make_pipeline\npipe_z = make_pipeline(trans,model_z)","0e6874b0":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nparams = {'criterion':['gini','entropy'],\n          'max_depth':[None,2,6,8,12],\n          'min_samples_split':[2,4,7,10],\n            'min_samples_leaf':[15,100]}\ng_pipe = make_pipeline(trans,GridSearchCV(model_z,params,cv = 3,n_jobs = -1,verbose = 3))\ng_pipe","c1bdffe1":"g_pipe.fit(x_train,y_train)","4084b9eb":"pred_g = g_pipe.predict(x_test)\npred_g","9e614009":"from sklearn.metrics import accuracy_score\naccuracy_score(pred_g,y_test)*100","4bfb42e4":"g_pipe.named_steps","181b13f7":"g_pipe.named_steps['gridsearchcv'].best_params_","3c12437d":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nparams = {'criterion':['gini'],\n          'max_depth':[None],\n          'min_samples_split':[2],\n            'min_samples_leaf':[15]}\ng1_pipe = make_pipeline(trans,GridSearchCV(model_z,params,cv = 3,n_jobs = -1,verbose = 3))\ng1_pipe","31d1dc59":"g1_pipe.fit(x_train,y_train)","d7541a09":"g1_pred = g1_pipe.predict(x_test)","8c02532f":"from sklearn.metrics import accuracy_score\naccuracy_score(g1_pred,y_test)*100","a8676090":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import make_pipeline\nparams = {'criterion':['gini','entropy'],\n          'max_depth':[None,2,9,8,7,12],\n          'min_samples_split':[2,5,6,15],\n            'min_samples_leaf':[25,90]}\ny_pipe = make_pipeline(trans,RandomizedSearchCV(model_z,params,cv = 3,verbose = 3))\ny_pipe\nPipeline\ncolumntransformer: ColumnTransformer\nonehotencoder\n\nOneHotEncoder\nordinalencoder\n\nOrdinalEncoder\nrandomizedsearchcv: RandomizedSearchCV\n\nDecisionTreeClassifier\n","0d69ad1e":"  # random oversampling\n  # (1st method)","d7004b00":"#  SMOTE\n# (2nd method)\n\n","0b26aba4":"# random undersampling"}}