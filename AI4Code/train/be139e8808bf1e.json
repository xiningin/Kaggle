{"cell_type":{"333e8afd":"code","bd84e05d":"code","13ccbd25":"code","1e03791e":"code","4e77f347":"code","3f8cc3fb":"code","7b12beb4":"code","27c49f8a":"code","8412fef3":"code","50e65f98":"code","b3332d13":"code","eeba1ce5":"code","e613984b":"code","992417e6":"code","102eaf3b":"code","59885e26":"code","9808455b":"code","ec1a7dec":"markdown"},"source":{"333e8afd":"import numpy as np \nimport pandas as pd \n\nfrom scipy import sparse\nimport scipy\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom scipy.sparse import coo_matrix, csr_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import LabelEncoder\n\n#Let\u2019s now calculate the Item-Item cosine similarity:\n\nfrom numpy import savez_compressed\nimport sklearn","bd84e05d":"data_job_details = pd.read_csv('..\/input\/datathon-guess-the-last-one\/data_job_details.csv')\ndata_cv_details = pd.read_csv('..\/input\/datathon-guess-the-last-one\/data_cv_details.csv')\ndata_aday_log = pd.read_csv('..\/input\/datathon-guess-the-last-one\/data_aday_log.csv')\nsample_ = pd.read_csv('..\/input\/datathon-guess-the-last-one\/sample_.csv')\nson2_basvurular_test = pd.read_csv('..\/input\/datathon-guess-the-last-one\/son2_basvurular_test.csv')\n\ndata_aday_log = data_aday_log.iloc[:,1:3]\ndata_aday_log.loc[:,'rating'] = 1\n#data_aday_log['jobId'] = 'J' + data_aday_log['jobId'].astype(str)","13ccbd25":"data_aday_log_with_cand_city = data_aday_log.merge(data_cv_details,on='jobseekerId')\ndata_aday_log_with_both_city = data_aday_log_with_cand_city.merge(data_job_details,on='jobId')\ndf = data_aday_log_with_both_city.copy()\ndf['city_match']= [x[0] in x[1] for x in zip(df['jobseekerCity'], df['jobCity'])]\ndf['jobseekerCity_wout_parant'] = df['jobseekerCity'].str.replace(r\"\\(.*\\)\",\"\")\ndf['city_match_wout_parant']= [x[0] in x[1] for x in zip(df['jobseekerCity_wout_parant'], df['jobCity'])]\nbasvuru_sayilari = df[['jobseekerId','jobseekerLastPosition','jobPosition']].groupby('jobseekerId').nunique().jobPosition","1e03791e":"exclude_job_seekers = basvuru_sayilari[basvuru_sayilari>60].index\nexclude_job_seekers","4e77f347":"data_aday_log = data_aday_log[~data_aday_log.jobseekerId.isin(exclude_job_seekers)]","3f8cc3fb":"user_label_encoder = LabelEncoder()\nuser_ids = user_label_encoder.fit_transform(data_aday_log.jobseekerId)\nproduct_label_encoder = LabelEncoder()\nproduct_ids = product_label_encoder.fit_transform(data_aday_log.jobId)","7b12beb4":"jobIdJobseekerIdMatrix = csr_matrix(([1]*len(user_ids), (product_ids, user_ids)))\nsimilarity = cosine_similarity(jobIdJobseekerIdMatrix,dense_output=False)\nsimilarity = similarity.astype(np.float32)\njobseekerIdjobIdMatrix = csr_matrix(jobIdJobseekerIdMatrix.T)\njobseekerIdjobIdMatrix = jobseekerIdjobIdMatrix.astype(np.float32)\nsparse_dot_prod = sklearn.utils.extmath.safe_sparse_dot(jobseekerIdjobIdMatrix,similarity,dense_output=False)","27c49f8a":"def reccom_generator(top_n):\n    for user_id in range(sparse_dot_prod.shape[0]):\n        scores = sparse_dot_prod[user_id, :].toarray()[0]\n        purchased_items = jobseekerIdjobIdMatrix.indices[jobseekerIdjobIdMatrix.indptr[user_id]:\n        jobseekerIdjobIdMatrix.indptr[user_id+1]]\n        scores[purchased_items] = -1 # do not recommend already purchased jobIds\n        top_products_ids = np.argsort(scores)[-top_n:][::-1]\n        recommendations = dict(zip(range(10),top_products_ids))\n        yield recommendations","8412fef3":"dictionary_list = []\n\nfor dicts in reccom_generator(10):\n    dictionary_list.append(dicts)\n    \ndf_final = pd.DataFrame.from_dict(dictionary_list)","50e65f98":"df_final.index = user_label_encoder.inverse_transform(df_final.index)\nfor i in range(df_final.shape[1]):\n    df_final.iloc[:, i] = product_label_encoder.inverse_transform(df_final.iloc[:, i])","b3332d13":"df_final.to_csv('df_final_cosine_simil.csv')","eeba1ce5":"submission_ = pd.melt(df_final,ignore_index=False)","e613984b":"submission_ = submission_.reset_index().iloc[:,[0,2]]\n#submission_['value'] = submission_['value'].str[1:]\nsubmission_ = submission_.rename(columns={\"index\": \"jobseekerId\", \"value\": \"jobId\"})","992417e6":"submission_ = submission_[submission_.jobseekerId.isin(son2_basvurular_test.jobseekerId.unique())]","102eaf3b":"submission_.to_csv('submission_serious_tum.csv',index=False)\npd.read_csv('submission_serious_tum.csv')\nold_submission = pd.read_csv('..\/input\/baseline-model\/submission_serious_tum.csv')","59885e26":"elenenler = son2_basvurular_test[~son2_basvurular_test.jobseekerId.isin(submission_.jobseekerId.unique())].jobseekerId.unique()\nold_submission = pd.read_csv('..\/input\/baseline-model\/submission_serious_tum.csv')\nek_submission = old_submission[old_submission['jobseekerId'].isin(elenenler)]","9808455b":"last_subm = pd.concat([submission_,ek_submission]).reset_index(drop=True)\nlast_subm.to_csv('last_subm_submission_serious_tum.csv',index=False)\npd.read_csv('last_subm_submission_serious_tum.csv')","ec1a7dec":"#### Stratejim jobseeker-job sparse matrixi \u00fczerinden job baz\u0131nda cosine similarity hesaplay\u0131p ba\u015fvurulan i\u015flere en yak\u0131n on i\u015fi bulmakt\u0131. \u00c7al\u0131\u015fanlar\u0131n benzerli\u011fi \u00fczerinden \u00f6neriler verdi\u011fimde ba\u015far\u0131l\u0131 olmad\u0131\u011f\u0131n\u0131 g\u00f6rd\u00fcm. Job similarity \u00fczerinden yapt\u0131\u011f\u0131m ilk ba\u015far\u0131l\u0131 submission sonras\u0131nda \u00e7ok fazla ba\u015fvuru yapan baz\u0131 ki\u015filerin outlier de\u011ferlendirilebilece\u011fini d\u00fc\u015f\u00fcn\u00fcp kendilerini \u00e7\u0131kard\u0131m. Minik bir ilerleme sa\u011flad\u0131 bu i\u015flem de. Final score i\u00e7in kulland\u0131\u011f\u0131m notebook budur. \n\n#### \u00c7ok fazla y\u00f6ntem\/paket\/kod denedi\u011fim bir yar\u0131\u015fma oldu, \u00e7o\u011funda da RAM problemi ya\u015fad\u0131m :) Onlar\u0131n da nispeten daha derli toplu olanlar\u0131n\u0131 eklemeye \u00e7al\u0131\u015faca\u011f\u0131m. "}}