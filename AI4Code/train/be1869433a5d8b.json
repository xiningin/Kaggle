{"cell_type":{"e82ec56f":"code","310bd8dd":"code","77a5da4d":"code","e11e057d":"code","26e862f8":"code","b7d02c99":"code","0db6363c":"code","3d3a448c":"code","d3a47178":"code","dff2b0d2":"code","9971fd31":"code","db582c50":"code","a0a9603e":"code","a306d639":"code","656c8e1d":"code","2faf1e42":"code","50eb5cde":"code","dc666c2e":"code","4970fa7a":"code","1ac320fe":"code","cf0b074b":"code","2e6c1a2f":"code","ed6d18d6":"code","a8211edf":"code","c3321f47":"code","f6e371b8":"code","134d10c9":"code","2c64c3dd":"code","ccc27426":"code","31333171":"code","cd508458":"code","89fe907a":"code","3e26501a":"code","eb2e9a10":"code","d0f59ce6":"code","39ee874b":"code","b28b596f":"code","fc5939a0":"code","f80667d7":"code","cdcf3707":"code","a072ad15":"code","c82953e8":"code","78a13b65":"code","147467ef":"code","b19b837a":"code","1a1fd339":"code","07678df3":"code","ff050ca0":"code","1b2349c4":"code","152ad5cc":"code","4f07764b":"code","bc36de89":"code","10c3e1f7":"code","42feed3d":"code","58d041ff":"code","dd53435e":"markdown","bf5f23ad":"markdown","a93de233":"markdown","9aaf8170":"markdown","8dedd3ae":"markdown","b72156a1":"markdown","bb796829":"markdown","2be77315":"markdown","1d49afda":"markdown","48c7dceb":"markdown","5a384a7c":"markdown","cfd55ca2":"markdown"},"source":{"e82ec56f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport gc\nimport sys\nimport math\n\nfrom pandas.io.json import json_normalize\nfrom datetime import datetime\n\nimport os\nprint(os.listdir(\"..\/input\"))","310bd8dd":"gc.enable()\n\nfeatures = ['channelGrouping', 'date', 'fullVisitorId', 'visitId',\\\n       'visitNumber', 'visitStartTime', 'device.browser',\\\n       'device.deviceCategory', 'device.isMobile', 'device.operatingSystem',\\\n       'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\\\n       'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\\\n       'geoNetwork.subContinent', 'totals.bounces', 'totals.hits',\\\n       'totals.newVisits', 'totals.pageviews', 'totals.transactionRevenue',\\\n       'trafficSource.adContent', 'trafficSource.campaign',\\\n       'trafficSource.isTrueDirect', 'trafficSource.keyword',\\\n       'trafficSource.medium', 'trafficSource.referralPath',\\\n       'trafficSource.source', 'customDimensions']\n\ndef load_df(csv_path):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    ans = pd.DataFrame()\n    dfs = pd.read_csv(csv_path, sep=',',\n            converters={column: json.loads for column in JSON_COLUMNS}, \n            dtype={'fullVisitorId': 'str'}, # Important!!\n            chunksize=100000)\n    for df in dfs:\n        df.reset_index(drop=True, inplace=True)\n        for column in JSON_COLUMNS:\n            column_as_df = json_normalize(df[column])\n            column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n            df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n\n        #print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n        use_df = df[features]\n        del df\n        gc.collect()\n        ans = pd.concat([ans, use_df], axis=0).reset_index(drop=True)\n        #print(ans.shape)\n    return ans","77a5da4d":"%%time\ntrain = load_df('..\/input\/train_v2.csv')\ntest = load_df('..\/input\/test_v2.csv')\n\nprint('train date:', min(train['date']), 'to', max(train['date']))\nprint('test date:', min(test['date']), 'to', max(test['date']))","e11e057d":"# Thanks and credited to https:\/\/www.kaggle.com\/gemartin\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","26e862f8":"# only train feature\nfor c in train.columns.values:\n    if c not in test.columns.values: print(c)","b7d02c99":"train['totals.transactionRevenue'].fillna(0, inplace=True)\ntrain['totals.transactionRevenue'] = np.log1p(train['totals.transactionRevenue'].astype(float))\nprint(train['totals.transactionRevenue'].describe())","0db6363c":"test['totals.transactionRevenue'] = np.nan","3d3a448c":"all_data = train.append(test, sort=False).reset_index(drop=True)","d3a47178":"print(all_data.info())","dff2b0d2":"null_cnt = train.isnull().sum().sort_values()\nprint(null_cnt[null_cnt > 0])","9971fd31":"# fillna object feature\nfor col in ['trafficSource.keyword',\n            'trafficSource.referralPath',\n            'trafficSource.adContent']:\n    all_data[col].fillna('unknown', inplace=True)\n\n# fillna numeric feature\nall_data['totals.pageviews'].fillna(1, inplace=True)\nall_data['totals.newVisits'].fillna(0, inplace=True)\nall_data['totals.bounces'].fillna(0, inplace=True)\nall_data['totals.pageviews'] = all_data['totals.pageviews'].astype(int)\nall_data['totals.newVisits'] = all_data['totals.newVisits'].astype(int)\nall_data['totals.bounces'] = all_data['totals.bounces'].astype(int)\n\n# fillna boolean feature\nall_data['trafficSource.isTrueDirect'].fillna(False, inplace=True)","db582c50":"# drop constant column\nconstant_column = [col for col in all_data.columns if all_data[col].nunique() == 1]\n#for c in constant_column:\n#    print(c + ':', train[c].unique())\n\nprint('drop columns:', constant_column)\nall_data.drop(constant_column, axis=1, inplace=True)","a0a9603e":"# pickup any visitor\nall_data[all_data['fullVisitorId'] == '7813149961404844386'].sort_values(by='visitNumber')[\n    ['date','visitId','visitNumber','totals.hits','totals.pageviews']].head(20)","a306d639":"train_rev = train[train['totals.transactionRevenue'] > 0].copy()\nprint(len(train_rev))\ntrain_rev.head()","656c8e1d":"def plotCategoryRateBar(a, b, colName, topN=np.nan):\n    if topN == topN: # isNotNan\n        vals = b[colName].value_counts()[:topN]\n        subA = a.loc[a[colName].isin(vals.index.values), colName]\n        df = pd.DataFrame({'All':subA.value_counts() \/ len(a), 'Revenue':vals \/ len(b)})\n    else:\n        df = pd.DataFrame({'All':a[colName].value_counts() \/ len(a), 'Revenue':b[colName].value_counts() \/ len(b)})\n    df.sort_values('Revenue').plot.barh(colormap='jet')","2faf1e42":"print('unique customDimensions count:', train['customDimensions'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'customDimensions')","50eb5cde":"format_str = '%Y%m%d'\nall_data['formated_date'] = all_data['date'].apply(lambda x: datetime.strptime(str(x), format_str))\nall_data['_year'] = all_data['formated_date'].apply(lambda x:x.year)\nall_data['_month'] = all_data['formated_date'].apply(lambda x:x.month)\nall_data['_quarterMonth'] = all_data['formated_date'].apply(lambda x:x.day\/\/8)\nall_data['_day'] = all_data['formated_date'].apply(lambda x:x.day)\nall_data['_weekday'] = all_data['formated_date'].apply(lambda x:x.weekday())\n\nall_data.drop(['date','formated_date'], axis=1, inplace=True)","dc666c2e":"plotCategoryRateBar(all_data, train_rev, 'channelGrouping')","4970fa7a":"print('train all:', len(train))\nprint('train unique fullVisitorId:', train['fullVisitorId'].nunique())\nprint('train unique visitId:', train['visitId'].nunique())\nprint('-' * 30)\nprint('test all:', len(test))\nprint('test unique fullVisitorId:', test['fullVisitorId'].nunique())\nprint('test unique visitId:', test['visitId'].nunique())\n\n#print('common fullVisitorId:', len(pd.merge(train, test, how='inner', on='fullVisitorId'))) # 183434","1ac320fe":"print(all_data['visitNumber'].value_counts()[:5])\nprint('-' * 30)\nprint(all_data['totals.newVisits'].value_counts())\nprint('-' * 30)\nprint(all_data['totals.bounces'].value_counts())","cf0b074b":"#maxVisitNumber = max(all_data['visitNumber'])\n#fvid = all_data[all_data['visitNumber'] == maxVisitNumber]['fullVisitorId']\n#all_data[all_data['fullVisitorId'] == fvid.values[0]].sort_values(by='visitNumber')","2e6c1a2f":"all_data['_visitStartHour'] = all_data['visitStartTime'].apply(\n    lambda x: str(datetime.fromtimestamp(x).hour))","ed6d18d6":"print('unique browser count:', train['device.browser'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'device.browser', 10)","a8211edf":"pd.crosstab(all_data['device.deviceCategory'], all_data['device.isMobile'], margins=False)\n\nall_data['isMobile'] = True\nall_data.loc[all_data['device.deviceCategory'] == 'desktop', 'isMobile'] = False","c3321f47":"print('unique operatingSystem count:', train['device.operatingSystem'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'device.operatingSystem', 10)","f6e371b8":"print('unique geoNetwork.city count:', train['geoNetwork.city'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.city', 10)","134d10c9":"print('unique geoNetwork.region count:', train['geoNetwork.region'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.region', 10)","2c64c3dd":"print('unique geoNetwork.subContinent count:', train['geoNetwork.subContinent'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.subContinent', 10)","ccc27426":"print('unique geoNetwork.continent count:', train['geoNetwork.continent'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.continent')","31333171":"print('unique geoNetwork.metro count:', train['geoNetwork.metro'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.metro', 10)","cd508458":"print('unique geoNetwork.networkDomain count:', train['geoNetwork.networkDomain'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'geoNetwork.networkDomain', 10)","89fe907a":"print(all_data['totals.hits'].value_counts()[:10])\n\nall_data['totals.hits'] = all_data['totals.hits'].astype(int)","3e26501a":"print(all_data['totals.pageviews'].value_counts()[:10])\n\nall_data['totals.pageviews'] = all_data['totals.pageviews'].astype(int)","eb2e9a10":"#print(all_data['totals.visits'].value_counts())","d0f59ce6":"print('unique trafficSource.adContent count:', train['trafficSource.adContent'].nunique())\n\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.adContent', 10)\n\nall_data['_adContentGMC'] = (all_data['trafficSource.adContent'] == 'Google Merchandise Collection').astype(np.uint8)","39ee874b":"print('unique trafficSource.campaign count:', train['trafficSource.campaign'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.campaign', 10)\n\nall_data['_withCampaign'] = (all_data['trafficSource.campaign'] != '(not set)').astype(np.uint8)","b28b596f":"print(all_data['trafficSource.isTrueDirect'].value_counts())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.isTrueDirect')","fc5939a0":"print('unique trafficSource.keyword count:', train['trafficSource.keyword'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.keyword', 10)","f80667d7":"print('unique trafficSource.medium count:', train['trafficSource.medium'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.medium')","cdcf3707":"print('unique trafficSource.referralPath count:', train['trafficSource.referralPath'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.referralPath', 10)\n\nall_data['_referralRoot'] = (all_data['trafficSource.referralPath'] == '\/').astype(np.uint8)","a072ad15":"print('unique trafficSource.source count:', train['trafficSource.source'].nunique())\nplotCategoryRateBar(all_data, train_rev, 'trafficSource.source', 10)\n\nall_data['_sourceGpmall'] = (all_data['trafficSource.source'] == 'mall.googleplex.com').astype(np.uint8)","c82953e8":"_='''\n'''\nall_data['_meanHitsPerDay'] = all_data.groupby(['_day'])['totals.hits'].transform('mean')\nall_data['_meanHitsPerWeekday'] = all_data.groupby(['_weekday'])['totals.hits'].transform('mean')\nall_data['_meanHitsPerMonth'] = all_data.groupby(['_month'])['totals.hits'].transform('mean')\nall_data['_sumHitsPerDay'] = all_data.groupby(['_day'])['totals.hits'].transform('sum')\nall_data['_sumHitsPerWeekday'] = all_data.groupby(['_weekday'])['totals.hits'].transform('sum')\nall_data['_sumHitsPerMonth'] = all_data.groupby(['_month'])['totals.hits'].transform('sum')\n\nfor feature in ['totals.hits', 'totals.pageviews']:\n    info = all_data.groupby('fullVisitorId')[feature].mean()\n    all_data['_usermean_' + feature] = all_data.fullVisitorId.map(info)\n    \nfor feature in ['visitNumber']:\n    info = all_data.groupby('fullVisitorId')[feature].max()\n    all_data['_usermax_' + feature] = all_data.fullVisitorId.map(info)\n\ndel info","78a13b65":"all_data['_source.country'] = all_data['trafficSource.source'] + '_' + all_data['geoNetwork.country']\nall_data['_campaign.medium'] = all_data['trafficSource.campaign'] + '_' + all_data['trafficSource.medium']\nall_data['_browser.category'] = all_data['device.browser'] + '_' + all_data['device.deviceCategory']\nall_data['_browser.os'] = all_data['device.browser'] + '_' + all_data['device.operatingSystem']","147467ef":"null_cnt = all_data.isnull().sum().sort_values()\nprint(null_cnt[null_cnt > 0])","b19b837a":"all_data.drop(['visitId','visitStartTime'],axis=1,inplace=True)\n\nfor i, t in all_data.loc[:, all_data.columns != 'fullVisitorId'].dtypes.iteritems():\n    if t == object:\n        all_data[i].fillna('unknown', inplace=True)\n        all_data[i] = pd.factorize(all_data[i])[0]\n        #all_data[i] = all_data[i].astype('category')","1a1fd339":"all_data.info()","07678df3":"train = all_data[all_data['totals.transactionRevenue'].notnull()]\ntest = all_data[all_data['totals.transactionRevenue'].isnull()].drop(['totals.transactionRevenue'], axis=1)","ff050ca0":"test.shape","1b2349c4":"train_id = train['fullVisitorId']\ntest_id = test['fullVisitorId']\n\nY_train_reg = train.pop('totals.transactionRevenue')\n#Y_train_cls = (Y_train_reg.fillna(0) > 0).astype(np.uint8)\nX_train = train.drop(['fullVisitorId'], axis=1)\nX_test  = test.drop(['fullVisitorId'], axis=1)\n\nprint(X_train.shape, X_test.shape)","152ad5cc":"del all_data, train, test, train_rev\ngc.collect()\n\nprint(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True)[:10])","4f07764b":"from sklearn.model_selection import StratifiedKFold, GroupKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb","bc36de89":"params={'learning_rate': 0.01,\n        'objective':'regression',\n        'metric':'rmse',\n        'num_leaves': 31,\n        'verbose': 1,\n        'random_state':42,\n        'bagging_fraction': 0.6,\n        'feature_fraction': 0.6\n       }\n\nfolds = GroupKFold(n_splits=5)\n\noof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds.split(X_train, Y_train_reg, groups=train_id)):\n    trn_x, trn_y = X_train.iloc[trn_], Y_train_reg.iloc[trn_]\n    val_x, val_y = X_train.iloc[val_], Y_train_reg.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(**params, n_estimators=3000)\n    reg.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], early_stopping_rounds=50, verbose=500)\n    \n    oof_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    sub_preds += reg.predict(X_test, num_iteration=reg.best_iteration_) \/ folds.n_splits\n\npred = sub_preds","10c3e1f7":"# Plot feature importance\nfeature_importance = reg.feature_importances_\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\nsorted_idx = sorted_idx[len(feature_importance) - 30:]\npos = np.arange(sorted_idx.shape[0]) + .5\n\nplt.figure(figsize=(12,8))\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X_train.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()","42feed3d":"submission = pd.DataFrame({'fullVisitorId':test_id, 'PredictedLogRevenue':pred})\n\nsubmission[\"PredictedLogRevenue\"] = np.expm1(submission[\"PredictedLogRevenue\"])\nsubmission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"].apply(lambda x : 0.0 if x < 0 else x)\nsubmission[\"PredictedLogRevenue\"] = submission[\"PredictedLogRevenue\"].fillna(0.0)\n\nsubmission_sum = submission[['fullVisitorId', 'PredictedLogRevenue']].groupby('fullVisitorId').sum().reset_index()\nsubmission_sum[\"PredictedLogRevenue\"] = np.log1p(submission_sum[\"PredictedLogRevenue\"])\nsubmission_sum.to_csv(\"submission.csv\", index=False)\nsubmission_sum.head(20)","58d041ff":"submission_sum['PredictedLogRevenue'].describe()","dd53435e":"## trafficSource","bf5f23ad":"## Aggregate","a93de233":"## device","9aaf8170":"## customDimensions","8dedd3ae":"## geoNetwork","b72156a1":"## Select feature","bb796829":"## channelGrouping\n* The channel via which the user came to the Store.","2be77315":"# Prediction","1d49afda":"## fullVisitorId\n* A unique identifier for each user of the Google Merchandise Store.\n\n## visitId\n* An identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user.   \nFor a completely unique ID, you should use a combination of fullVisitorId and visitId.\n\n## newVisits\n","48c7dceb":"## date","5a384a7c":"# ","cfd55ca2":"## totals"}}