{"cell_type":{"02226349":"code","147415f5":"code","d8407188":"code","9498a7de":"code","244f78f5":"code","4a51a5c2":"code","02bf77f3":"code","632780b7":"code","1a33eee9":"code","87d34131":"code","70f92d39":"code","05a0e0b2":"code","eb09d077":"code","5f465277":"code","f15965bd":"code","ad3d845d":"code","c2f88212":"code","e85bbaa2":"code","93d2f30d":"code","6b407c3f":"code","ca49bae4":"code","e9db2d08":"code","fab6679f":"code","4b3a2008":"code","632aed93":"code","2da96d3b":"code","c2b866f8":"code","824fdae4":"code","bc2bc562":"markdown","1cac5f52":"markdown","bbf810bb":"markdown","faac719d":"markdown","f4dab00c":"markdown","474899b3":"markdown"},"source":{"02226349":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns\nfrom sklearn import datasets\nfrom sklearn.decomposition import PCA\n\nfrom pandas.plotting import scatter_matrix\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nfrom sklearn import neighbors, datasets\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\n# Import necessary modules\nfrom scipy.stats import randint\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.metrics import roc_curve\nfrom sklearn.linear_model import LogisticRegression\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","147415f5":"\ndf_diabetes = pd.read_csv(os.path.join(dirname, filename))","d8407188":"df_diabetes.head()","9498a7de":"df_diabetes.info()","244f78f5":"\n_ = scatter_matrix(df_diabetes, alpha=0.2, figsize  = [15, 15],\n    marker   = \".\")\nplt.show()","4a51a5c2":"histogram_intersection = lambda a, b: 1\/(np.minimum(a, b).sum().round(decimals=1))\n\ndf_diabetes.corr(method=histogram_intersection)","02bf77f3":"\ndf_diabetes =  df_diabetes.loc[df_diabetes['Glucose']!=0]\ndf_diabetes.plot.scatter(x='Outcome', y='Glucose')\nplt.show()\nMedianGlucose0 = np.median(df_diabetes.loc[df_diabetes.Outcome==0].Glucose.values)\nprint('MedianGLucose for non diabetic')\nprint(str(MedianGlucose0))\nMedianGlucose1 = np.median(df_diabetes.loc[df_diabetes.Outcome==1].Glucose.values)\nprint('MedianGLucose for diabetic')\nprint(str(MedianGlucose1))","632780b7":"# # Create arrays for the features and the response variable\ny = df_diabetes['Outcome'].values\nX = df_diabetes.drop('Outcome',axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","1a33eee9":"\n# Setup the hyperparameter grid\nc_space = np.logspace(-5, 8, 15)\nparam_grid = {'C': c_space}\n\n\nlog_reg = LogisticRegression(random_state=42, solver='lbfgs', max_iter=10000)\n# Instantiate the GridSearchCV object: logreg_cv\nlog_reg_cv = GridSearchCV(log_reg, param_grid, cv=5)\n","87d34131":"\n# Fit it to the data\n\nlog_reg_cv.fit(X_train, y_train)\n\n# Print the tuned parameters and score\nprint(\"Tuned Logistic Regression Parameters: {}\".format(log_reg_cv.best_params_)) \nprint(\"Best score is {}\".format(log_reg_cv.best_score_))\n","70f92d39":"log_reg_cv.score(X_test, y_test)","05a0e0b2":"y_pred = log_reg_cv.predict(X_test)","eb09d077":"# Generate the confusion matrix and classification report\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","5f465277":"from sklearn.linear_model import LogisticRegression\n\nfrom yellowbrick.classifier import DiscriminationThreshold\nfrom yellowbrick.datasets import load_spam\n\n\n# Instantiate the classification model and visualizer\nmodel = LogisticRegression(multi_class=\"auto\", solver=\"liblinear\")\nvisualizer = DiscriminationThreshold(model)\n\nvisualizer.fit(X, y)        # Fit the data to the visualizer\n#      visualizer.show()      # Finalize and render the figure","f15965bd":"y_pred_prob = log_reg_cv.predict_proba(X_test)[:,1]","ad3d845d":"fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)","c2f88212":"plt.plot([0,1],[0,1], 'k--', label = 'Random choice..')\nplt.plot(fpr, tpr, label = 'Logistic Regression')\nplt.xlabel('False positive rate')\nplt.legend()\nplt.ylabel('True positive rate')\nplt.title(' Logistic Regression ROC curve')\nplt.show()","e85bbaa2":"from sklearn.model_selection import cross_val_score\n\ncv_score = cross_val_score(log_reg,X, y, cv=20, scoring='roc_auc')","93d2f30d":"np.mean(cv_score)","6b407c3f":"np.std(cv_score)","ca49bae4":"np.std(cv_score)","e9db2d08":"log_reg = LogisticRegression(C=30,random_state=42, solver='lbfgs', max_iter=10000)","fab6679f":"log_reg.fit(X_train, y_train)","4b3a2008":"pred_log_reg = log_reg.predict(X_test)\ny_log_reg_proba = log_reg.predict_proba(X_test)\nlog_reg.score(X_test,y_test)","632aed93":"log_reg.score(X,y)","2da96d3b":"cv_score = cross_val_score(log_reg,X, y, cv=10, scoring='roc_auc')","c2b866f8":"cv_score","824fdae4":"np.mean(cv_score)","bc2bc562":"## EDA","1cac5f52":"## Checking on Unseen data","bbf810bb":"## Using Logistic Regression","faac719d":"## If a person has a glucose of 0 is dead. \n## So I will take those points as errors and get rid of them","f4dab00c":"# Seems like this classifier is better than random choice\n\n\n# Now lets check the performance on the whole dataset","474899b3":"# Now lets check on the best performing value of C"}}