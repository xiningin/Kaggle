{"cell_type":{"0d865b12":"code","fe76cda7":"code","b10eec16":"code","31ad4a5a":"code","551c0229":"code","9cbd9c24":"code","eaaa8415":"code","7f1981a0":"code","b7a17891":"code","0795ec8a":"code","6ee9d4b1":"code","be56ad78":"code","ee4310d7":"code","d8ee3494":"code","d2eca06c":"code","4b38d67f":"code","772d01ad":"code","ae42e701":"code","df1bf472":"code","ad888b21":"code","c9aae1db":"code","b1cdfb2f":"code","418db095":"code","40622a2d":"code","8e3e3b13":"code","f5cdee49":"code","5809a802":"code","37f1338d":"code","e0b81c29":"code","58d7343d":"code","9c0095c9":"code","06a57d9e":"code","8c060483":"code","21ee5b5f":"code","1771de3b":"code","f9ad1a46":"code","3ddd61c3":"code","4d07e236":"code","dc38826b":"code","3db77297":"code","b7fc8257":"code","74a54259":"code","b8d6a669":"code","8ddfbdeb":"code","5cee1b50":"code","69cbbbc7":"code","5b39b8bf":"code","316b7faf":"code","383aec1b":"code","a66ff5c1":"code","8ba35149":"code","2ff652ee":"code","2da19d9d":"code","afaa2e51":"code","a3658938":"code","f5b0538d":"code","4a3c06ae":"code","4f8378b1":"code","237fa56b":"code","f78ea72d":"code","c1825379":"code","f3938753":"code","193523d7":"code","1996fa7c":"code","664392c2":"code","55774d06":"code","fb4038d1":"code","30223bda":"code","04f88aba":"code","3a0a2376":"code","aeac7c93":"code","24950b2a":"code","8093274e":"code","99290921":"code","16490bc1":"code","d8d8c1a6":"code","37123f4f":"code","ed1410f6":"code","60322774":"code","e1f75ef8":"code","3a81a32c":"code","d6160ed3":"code","406ef8d4":"code","5cb31cb0":"code","4624a7a0":"code","c8e9c6d7":"code","5b86b6ff":"markdown","799dc8ed":"markdown","95b112d7":"markdown","e1035889":"markdown","f014170f":"markdown","6460b23b":"markdown","14cc8af9":"markdown","747b0035":"markdown","3bc3ec28":"markdown","e5524d73":"markdown","8187677d":"markdown","6369ad56":"markdown","5ba2078b":"markdown","1840459a":"markdown","0447c46e":"markdown","660a1bcf":"markdown","398cbd46":"markdown","93485e0c":"markdown","40902bfe":"markdown","87821ec8":"markdown","f6e0f824":"markdown","3892397d":"markdown","4357ef89":"markdown","8ab8b8c5":"markdown","cf13b032":"markdown","23b754f4":"markdown","61781def":"markdown","88ffcb1e":"markdown","9a89a035":"markdown","e9d780f1":"markdown","d6a6b8d5":"markdown","b2e8e1a2":"markdown","714d67dc":"markdown","2d9f1355":"markdown","cd255ee5":"markdown","4cc3cdb8":"markdown"},"source":{"0d865b12":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly\nimport plotly.express as px","fe76cda7":"# read dataset\ndata=pd.read_csv('..\/input\/countries-population-from-1955-to-2020\/Countries Population from 1995 to 2020.csv')\nps = data\nds=data","b10eec16":"#to display first 5 rows of dataset\ndata.head()","31ad4a5a":"#to display last 5 rows of dataset\ndata.tail()","551c0229":"data.shape","9cbd9c24":"data.info()","eaaa8415":"data.describe()","7f1981a0":"#checking for null values\ndata.dropna(axis=0,inplace=True)","b7a17891":"sns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","0795ec8a":"#Plotting boxplot (displaying the distribution of data based on a five number summary )\nsns.set(style=\"whitegrid\")\nfig,ax = plt.subplots(nrows=2, ncols=2, figsize=(8,8))\nplt.suptitle('Box Plot',fontsize=24)\nsns.boxplot(x=\"Country Global Rank\", data=data,ax=ax[0,0],palette='Set2')\nsns.boxplot(x=\"Urban Pop %\", data=data,ax=ax[0,1],palette='Set1')\nsns.boxplot (x ='Fertility Rate', data=data, ax=ax[1,0], palette='Set1')\nsns.boxplot(x='Median Age', data=data, ax=ax[1,1],palette='Set2')\nplt.show()","6ee9d4b1":"#Finding correlation between all attributes of dataset\nfig, ax = plt.subplots(figsize=(10,9))\nsns.heatmap(data.corr(), center=0, cmap='BrBG', annot=True)\nax.set_title('HEAT MAP')","be56ad78":"sns.jointplot(x=\"Urban Pop %\",y=\"Year\",data=data,kind=\"hex\",color=\"magenta\")","ee4310d7":"#plotting histogram\ndata.hist(figsize=(20,30),color=\"orange\")","d8ee3494":"#graph showing population of top 30 countries in 2020\ncurrent_population = data[data['Year'] == 2020][:20]\nplt.rcParams['figure.figsize'] = (25, 7)\nax = sns.barplot(x = current_population['Country'][:20], y = current_population['Population'][:20], palette = 'dark')\nax.set_xlabel(xlabel = 'Countries', fontsize = 10)\nax.set_ylabel(ylabel = 'Population in Billion', fontsize = 10)\nax.set_title(label = 'Population of top 30 countries in 2020', fontsize = 20)\nplt.xticks(rotation = 90)\nplt.show()","d2eca06c":"population_2020 = data[data['Year'] == 2020]","4b38d67f":"fig = px.choropleth(population_2020, locations=\"Country\", \n                    locationmode='country names', color=\"Density (P\/Km\u00b2)\", \n                    hover_name=\"Country\", \n                    color_continuous_scale=\"blues\", \n                    title='Density of Countries in 2020')\nfig.update(layout_coloraxis_showscale=True)\nfig.show()","772d01ad":"#plot showing Total Share of in World's Population for the top 10 countries\nunique_countries = data['Country'].unique()\nplt.style.use(\"seaborn-talk\")\n# set year\nyear = 2020\ndf_last_year = data[data['Year'] == year]\nseries_last_year = df_last_year.groupby('Country')['Population'].sum().sort_values(ascending=False)\nprint(series_last_year)\nlabels = []\nvalues = []\ncountry_count = 10\nother_total = 0\nfor country in series_last_year.index:\n    if country_count > 0:\n        labels.append(country)\n        values.append(series_last_year[country])\n        country_count -= 1\nelse:\n    other_total += series_last_year[country]\nlabels.append(\"Other\")\nvalues.append(other_total)\nwedge_dict = {\n'edgecolor': 'black',\n'linewidth': 2\n}\nexplode = (0, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0)\nplt.title(f\"Total Share of in World's Population for the top 10 countries in {year}\")\nplt.pie(values, labels=labels, explode=explode, autopct='%1.2f%%', wedgeprops=wedge_dict)\nplt.show()","ae42e701":"india=data[data['Country'] == \"India\"]","df1bf472":"#plot showing population of India in different years\nfig = plt.figure(figsize=(10,5))\nplt.plot(india['Year'], india['Yearly Change'])\nplt.title('Yearly Population Change in India')\nplt.xlabel('Year')\nplt.ylabel('Population in 10 Million')\nplt.show()","ad888b21":"#plotting violin plots to visualise the distribution of the data and its probability density\nfig,ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\nplt.suptitle('Violin Plots',fontsize=24)\nsns.violinplot(x=\"Migrants (net)\", data=data,ax=ax[0,0],palette=\"Set1\")\nsns.violinplot(x=\"World Population\", data=data,ax=ax[0,1],palette=\"Set2\")\nsns.violinplot (x ='Yearly Change', data=data, ax=ax[1,0],palette=\"Set2\")\nsns.violinplot(x='Country\\'s Share of World Pop %', data=data, ax=ax[1,1],palette=\"Set1\")\n\nplt.show()","c9aae1db":"data.drop(['Country'], axis=1, inplace=True)\ndata.drop(['Migrants (net)'], axis=1,inplace=True)\ndata.drop(['Density (P\/Km\u00b2)'], axis=1,inplace=True)","b1cdfb2f":"from sklearn.preprocessing import StandardScaler\nstandard_scaler = StandardScaler()\nscaled_data = standard_scaler.fit_transform(data)","418db095":"from sklearn.cluster import KMeans","40622a2d":"np.nan_to_num(scaled_data)","8e3e3b13":"# Using the elbow method to find the optimal number of clusters\nX =scaled_data[: , :]   #taking all the columns into account\nwcss = []\nfor n in range(1 , 11):\n    algorithm = (KMeans(n_clusters = n ,init='k-means++', n_init = 10 ,max_iter=300))\n    algorithm.fit(X)\n    wcss.append(algorithm.inertia_)\nplt.figure(1 , figsize = (15 ,6))\nplt.plot(np.arange(1 , 11) , wcss , 'o')\nplt.plot(np.arange(1 , 11) , wcss , '-' )\nplt.xlabel('Number of Clusters') , plt.ylabel('WCSS')\nplt.title('Elbow Method Diagram')\nplt.show()\n","f5cdee49":"data['Urban Pop %'].astype('int64')","5809a802":"# Fitting K-Means to the dataset\nalgorithm = (KMeans(n_clusters = 3 ,init='k-means++', n_init = 10 ,max_iter=300, \n                        tol=0.0001,  random_state= 823) )\nalgorithm.fit(X)\nlabels = algorithm.labels_","37f1338d":"data['Cluster'] = labels\ndata.tail(10)","e0b81c29":"#representing which features are important to the clustering using RandomForest Feature Importance Plot\nfrom sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state = 823)\ndf_dv = data.copy()\ndf_dv.drop('Cluster', axis = 1, inplace = True)\nrfc.fit(df_dv,data['Cluster'])\nfeatures = df_dv.columns.tolist()\nfeature_value = rfc.feature_importances_\nd = {'Features' : features, 'Values' : feature_value}\nfi = pd.DataFrame(d).sort_values('Values', ascending = False).reset_index()\nfi\nplt.rcParams['figure.figsize'] = (20.0, 5.0)\nax = sns.barplot(x=fi['Features'], y = fi['Values'], data = fi, palette=\"Blues_d\")","58d7343d":"data","9c0095c9":"X = data.iloc[:, [0,4,5,9]].values  ","06a57d9e":"#Some zoomed in biplots\nfig, axs = plt.subplots(ncols=2,nrows=2, figsize = (15,15))\nsns.scatterplot(x=\"Fertility Rate\", y=\"Year\", hue=\"Cluster\",\n                     palette = 'colorblind',data =data , legend = False, s = 100, ax=axs[0][0])\nsns.scatterplot(x=\"Fertility Rate\", y=\"Population\", hue=\"Cluster\",\n                     palette = 'colorblind', data=data , legend = False, s = 100, ax=axs[0][1])\nsns.scatterplot(x=\"Median Age\", y=\"World Population\", hue=\"Cluster\",\n                     palette = 'colorblind', data = data, legend = False, s = 100,  ax=axs[1][0])\nsns.scatterplot(x=\"Year\", y=\"World Population\", hue=\"Cluster\",\n                     palette = 'colorblind', data = data, legend = False, s = 100, ax=axs[1][1])","8c060483":"#visualisation of pairplots using top 5 important features for the clusters\nsns.pairplot(data[['Fertility Rate','Median Age','Year','World Population','Urban Pop %','Cluster']],palette = 'colorblind',hue='Cluster');","21ee5b5f":"#obtain the principal components\nfrom sklearn.decomposition import PCA\npca=PCA(n_components=2)\nprincipal_comp=pca.fit_transform(X)\nprincipal_comp","1771de3b":"#create dataframe with two components\npca_df=pd.DataFrame(data=principal_comp,columns=['pca1','pca2'])\npca_df.head()","f9ad1a46":"preds=pd.Series(KMeans(n_clusters=3).fit_predict(pca_df))","3ddd61c3":"#concatenate the cluster labels to the dataframe\npca_df=pd.concat([pca_df,preds],axis=1)","4d07e236":"pca_df.columns=['pca1','pca2','Cluster']","dc38826b":"pca_df","3db77297":"plt.figure(figsize=(7,7))\nax=sns.scatterplot(x='pca1',y='pca2',hue=pca_df.Cluster.tolist(),data=pca_df,palette=['red','blue','green'])\nax.legend(title='Cluster')\nplt.show()\n","b7fc8257":"from sklearn.cluster import AgglomerativeClustering\nfrom scipy.cluster.hierarchy import dendrogram,linkage","74a54259":"# Using the dendrogram to find the optimal number of clusters(ward linkage)\nimport scipy.cluster.hierarchy as sch\nfig = plt.figure(figsize =(12,12),facecolor='w')\ndendrogram=sch.dendrogram(sch.linkage(X,method='ward'))\nplt.title(\"Dendrogram\",fontsize=20)\nplt.xlabel('X',fontsize=12)\nplt.ylabel('Euclidean Distances',fontsize=12)\nplt.show()","b8d6a669":"from sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage = 'ward')\ny_hc = hc.fit_predict(X)","8ddfbdeb":"#obtain the principal components\nfrom sklearn.decomposition import PCA\npca=PCA(n_components=2)\nprincipal_comp=pca.fit_transform(X)\nprincipal_comp","5cee1b50":"#create dataframe with two components\npca_df_agglomerative=pd.DataFrame(data=principal_comp,columns=['pca1','pca2'])\npca_df_agglomerative.head()","69cbbbc7":"preds=pd.Series(AgglomerativeClustering(n_clusters=3).fit_predict(pca_df_agglomerative))","5b39b8bf":"pca_df_agglomerative=pd.concat([pca_df_agglomerative,preds],axis=1)","316b7faf":"pca_df_agglomerative.columns=['pca1','pca2','Cluster']","383aec1b":"pca_df_agglomerative","a66ff5c1":"pca_df_agglomerative.columns=['pca1','pca2','Cluster']\npca_df_agglomerative.head()","8ba35149":"plt.figure(figsize=(7,7))\nax=sns.scatterplot(x='pca1',y='pca2',hue=pca_df_agglomerative.Cluster.tolist(),data=pca_df_agglomerative,palette=['red','blue','green'])\nax.legend(title='Cluster')\nplt.show()","2ff652ee":"# Using the dendrogram to find the optimal number of clusters(complete linkage)\nimport scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'complete'))\nplt.title('Dendrogram')\nplt.xlabel('data points')\nplt.ylabel('Euclidean distances')\nplt.show()","2da19d9d":"# Using the dendrogram to find the optimal number of clusters(single linkage)\nimport scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'single'))\nplt.title('Dendrogram')\nplt.xlabel('data points')\nplt.ylabel('Euclidean distances')\nplt.show()\nfig = plt.figure(figsize =(12,12),facecolor='w')","afaa2e51":"best_cols = ['Fertility Rate','Median Age','World Population','Year']\ndata_final = pd.DataFrame(data[best_cols])","a3658938":"# create a 'cluster' column\ndata_final['cluster'] = labels\nbest_cols.append('cluster')","f5b0538d":"data_final['cluster'].value_counts().plot.bar(figsize=(10,5),color = list('rgbkymc'), title='Entries by cluster');\n","4a3c06ae":"sns.pairplot(data_final[best_cols], hue='cluster', x_vars=['Fertility Rate','Median Age','World Population','Year'],\n            y_vars=['cluster'],\n            height=3, aspect=1)","4f8378b1":"from sklearn.metrics import silhouette_score  \nno_of_clusters = [3,4, 5,6] \nsilhouette_coeff = []\nfor n_clusters in no_of_clusters: \n  \n    cluster = KMeans(n_clusters = n_clusters) \n    cluster_labels = cluster.fit_predict(X) \n  \n    # The silhouette_score gives the  \n    # average value for all the samples. \n    silhouette_avg = silhouette_score(X, cluster_labels) \n    silhouette_coeff.append(silhouette_avg)\n    print(\"For no of clusters =\", n_clusters, \n          \" The average silhouette_score is :\", silhouette_avg)","237fa56b":"from sklearn.metrics import silhouette_score  \nsilhouette_coefficients = []\nfor k in range(3, 6):\n    kmeans = KMeans(n_clusters = k, init = 'k-means++', max_iter=300, n_init=10)\n    kmeans.fit(data)\n    score = silhouette_score(data, kmeans.labels_)\n    silhouette_coefficients.append(score)","f78ea72d":"from sklearn.metrics import davies_bouldin_score ","c1825379":"kmeans=KMeans(n_clusters=3,random_state=1).fit(X)\n# to store the cluster labels \nklabels = kmeans.labels_ \n\nprint(davies_bouldin_score(X, klabels)) ","f3938753":"from sklearn.cluster import DBSCAN","193523d7":"#taking fertility rate and yearly % change\nX = data.iloc[:, [2,5]].values \nX","1996fa7c":"model=DBSCAN(eps=0.25, min_samples=10)\nmodel.fit(X)","664392c2":"model.labels_","55774d06":"fig,ax = plt.subplots(figsize=(6,5))\nax.scatter(X[:,0], X[:,1] , c=model.labels_)\nfig.show()","fb4038d1":"# Storing the value of India in new Dataframe\nInd=pd.DataFrame()\nInd=ps.loc[ps['Country']=='India']","30223bda":"Ind.head()","04f88aba":"plt.plot(Ind['Year'], Ind['Population'], color='g')\nplt.plot(Ind['Year'], Ind['World Population'], color='orange')\nplt.xlabel('Year')\nplt.ylabel('Population')\nplt.title('Population Change')\nplt.show()","3a0a2376":"plt.plot(Ind['Year'], Ind['Density (P\/Km\u00b2)'])\nplt.gca().invert_yaxis()\nplt.show()","aeac7c93":"# creating new dataframe\nds1=pd.DataFrame()\nds1['Year']=Ind['Year']\nds1['Fertility Rate']=Ind['Fertility Rate']\nds1['Migrants (net)']=Ind['Migrants (net)']\nds1['Population']=Ind['Population']","24950b2a":"ds1.head()","8093274e":"# our features\nX = ds1[['Fertility Rate', 'Migrants (net)']]\ny = ds1['Population']","99290921":"# Testing and training dataset split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)","16490bc1":"# Building model\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)","d8d8c1a6":"# Beta coefficients of our model\ncoeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])\ncoeff_df","37123f4f":"# predicting the value\ny_pred = regressor.predict(X_test)","ed1410f6":"# Actual and Predicted value\ndf = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndf1=df\ndf","60322774":"# Diffference in actual and predicted value\ndf1.plot(kind='bar')","e1f75ef8":"# accuracy check\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error, r2_score\nrmsd = np.sqrt(mean_squared_error(y_test, y_pred))      \nr2_value = r2_score(y_test, y_pred)                     \n\nprint(\"Root Mean Square Error :\", rmsd)\nprint(\"R^2 Value :\", r2_value)","3a81a32c":"ds1.head()","d6160ed3":"# Dropping irrelevant features\nds1.drop(['Fertility Rate','Migrants (net)'],axis=1,inplace=True)","406ef8d4":"# making year as index\nds1.set_index('Year',inplace=True)","5cb31cb0":"ds1.head()","4624a7a0":"Test=ds1[:5] \nTrain=ds1[5:]","c8e9c6d7":"# Naive forecast - It gives our forecast value seeing our past few values\ndd= np.asarray(Test.Population)\ny_hat = Test.copy()\ny_hat['naive'] = dd[len(dd)-1]\nplt.plot(Train.index, Train['Population'], label='Train')\nplt.plot(Test.index,Test['Population'], label='Test')\nplt.plot(y_hat.index,y_hat['naive'], label='Naive Forecast')\nplt.legend(loc='best')\nplt.title(\"Naive Forecast\")\nplt.show()","5b86b6ff":"> # Forecasting ","799dc8ed":"# Data Preprocessing","95b112d7":"**INFERENCE**:\n> #### Attributes having highest correlation(0.95) are Country's share of world pop % and Population.","e1035889":"**INFERENCE**\n> **It can be seen that India has the highest population in 2000**","f014170f":"**DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a popular learning method utilized in model building and machine learning algorithms. This is a clustering method that is used in machine learning to separate clusters of high density from clusters of low density.**","6460b23b":"> **It can be seen that optimal number of clusters are 3**","14cc8af9":"> **The white dot in the middle is the median value and the thick black bar in the centre represents the interquartile range. The thin black line extended from it represents the upper (max) and lower (min) adjacent values in the data.**","747b0035":"> **There are no null values in the dataset**","3bc3ec28":"This dataset consists of 4195 observations on the following 14 columns (features):\n - **Year**\n - **Country**\n - **Population**\n - **Yearly %change**\n - **Yearly change**\n - **Migrants(net)**\n - **Median age**\n - **Fertility Rate**\n - **Density(P\/Km2)**\n - **Urban Pop%**\n - **Urban Population**\n - **Country's Share of World Pop %**\n - **World Population**\n - **Country Global Rank** ","e5524d73":"## a) Silhouette Analysis","8187677d":"##### Our  \u03b2 Coefficients value in Multiple Regression","6369ad56":"# DBSCAN","5ba2078b":"## THANK YOU !!!","1840459a":"> **Fertility Rate has the highest importance in the dataset followed by Median Age**","0447c46e":"#### Population change and India's contribution in it","660a1bcf":"# K Means Clustering","398cbd46":"##### R^2 value ~ 1 tells how good our regression model is.\n","93485e0c":"**INFERENCE:**\n> **In this plot, the hexagon with most number of points gets darker color. So it can be infered that the percentage of urban pop % which donate the most is around 50%  and the corresponding year for the same is between 2015 and 2020**","40902bfe":"#### Change in population Density with years of India","87821ec8":"# Exploratory Data Analysis","f6e0f824":"## Countries Population from 1995 to 2020 dataset","3892397d":"#  Performance measures","4357ef89":"# Multiple Regression","8ab8b8c5":"> **It shows the distribution of various attributes in the dataset**","cf13b032":"##### Our Regression model performs quite well as can be seen from the graph\n\n**R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model**\n\n**Root mean squared error tells you how concentrated the data is around the line of best fit.**","23b754f4":"> **The median (middle quartile) marks the mid-point of the attribute (eg - around 50 in case of urban pop %) and is shown by the line that divides the box into two parts.**","61781def":"**INFERENCE**\n> **It can be seen that China accounts for the highest share in World's population followed by India in 2020**","88ffcb1e":"# INDIA","9a89a035":"##### Sudden change in past few years","e9d780f1":"**INFERENCE**\n> **As the DB index shrinks, the clustering is considered \u2018better'.**","d6a6b8d5":"## STEPS :\n1. Perform Data Pre-processing and Data Visualization on your data set to develop a thorough understanding of the data. \n\n2. Regression\n\n3. Apply clustering techniques","b2e8e1a2":"**INFERENCE**\n> **It can be seen that China has the highest population in 2020 followed by India**","714d67dc":"##### So, we can see our around what our country population will vary in coming future","2d9f1355":"# Heirarchical Clustering","cd255ee5":"## b)Davies-Bouldin Index","4cc3cdb8":"## Naive Forecasting : \n**Estimating technique in which the last period's actuals are used as this period's forecast, without adjusting them or attempting to establish causal factors. It is used only for comparison with the forecasts generated by the better (sophisticated) techniques.**"}}