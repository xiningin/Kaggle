{"cell_type":{"f3af36c6":"code","61faf080":"code","7e5466b9":"code","f47dc5ec":"code","5dc5524e":"code","d3ff06a3":"code","e17b555b":"code","c8876828":"code","69c2eef6":"code","85b061ad":"code","bbe99ce3":"code","974b16f0":"code","e5ae07a5":"code","b147f06a":"code","7dd40fee":"code","37794b6e":"code","e8c5da8a":"code","ece4781a":"code","aa6a01fe":"code","58b25dcc":"code","99888631":"code","c74eadc4":"code","ffb90416":"code","440729a2":"code","fe01b332":"code","c30d92e7":"code","6ac521e9":"code","2aadcd2e":"code","3ade623b":"code","b70953ff":"code","5362b0c2":"code","eb0b8b60":"code","5ded3001":"code","1ee1b4e0":"code","38efaf2c":"code","e911b7bf":"code","d432ddc6":"markdown","66ac6821":"markdown","eff63366":"markdown","bc8f244e":"markdown","b6e7a2ef":"markdown","b601f510":"markdown","9b26b11b":"markdown","eabcdfec":"markdown","7ebcb35e":"markdown","d7e3f0de":"markdown","cc35dfc4":"markdown","b765cd3b":"markdown","9759e1ac":"markdown","26488439":"markdown","e915d8c3":"markdown"},"source":{"f3af36c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61faf080":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')","7e5466b9":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nplt.style.use('fivethirtyeight')\nsns.set_style('darkgrid')\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go","f47dc5ec":"# library to clean the text \nimport re  \n  \n# Natural Language Tool Kit \nimport nltk  \n  \n# stopwords is a list of unwanted words like the,and,of,etc...\nnltk.download('stopwords') \n  \n# to remove stopword; corpus is a collection of text.\nfrom nltk.corpus import stopwords \n  \n# for Stemming propose  \n# Stemming means taking the root of the word eg. loved, loving, will love -> love\n# This will reduce different versions of the same word and will hence reduce the sparsity of matrix\nfrom nltk.stem.porter import PorterStemmer\n\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize","5dc5524e":"train = pd.read_csv(\"\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_train.csv\", encoding='latin_1')\ntest = pd.read_csv(\"\/kaggle\/input\/covid-19-nlp-text-classification\/Corona_NLP_test.csv\", encoding='latin_1')","d3ff06a3":"display(train.head())\ndisplay(test.head())","e17b555b":"display(train.shape)\ndisplay(test.shape)","c8876828":"display(train.info())\nprint(\"\\n------------------------------------\\n\")\ndisplay(test.info())","69c2eef6":"train_original = train.copy()\ntest_original = test.copy()","85b061ad":"display(train.isnull().sum())\nprint(\"\\n-----------------------\\n\")\ndisplay(test.isnull().sum())","bbe99ce3":"train.dropna(inplace=True)\ntest.dropna(inplace=True)","974b16f0":"train[train.duplicated()]","e5ae07a5":"train.duplicated().value_counts()","b147f06a":"display(train[\"Sentiment\"].value_counts())\nprint(\"\\n---------------------------------\\n\")\ndisplay(test[\"Sentiment\"].value_counts())","7dd40fee":"fig = make_subplots(1,2,subplot_titles=('Train','Test'))\nx = train['Sentiment'].value_counts()\n\nfig.add_trace(go.Bar(x=x.index, y=x.values, marker_color=['#17C37B','#F92969','#FACA0C'], name='train'), row=1, col=1)\nx = test['Sentiment'].value_counts()\n\nfig.add_trace(go.Bar(x=x.index, y=x.values, marker_color=['#17C37B','#F92969','#FACA0C'], name='test'), row=1, col=2)","37794b6e":"def change_sen(sentiment):\n    if sentiment == \"Extremely Positive\":\n        return 'positive'\n    elif sentiment == \"Extremely Negative\":\n        return 'negative'\n    elif sentiment == \"Positive\":\n        return 'positive'\n    elif sentiment == \"Negative\":\n        return 'negative'\n    else:\n        return 'netural'","e8c5da8a":"train['Sentiment']=train['Sentiment'].apply(lambda x:change_sen(x))\ntest['Sentiment']=test['Sentiment'].apply(lambda x:change_sen(x))","ece4781a":"plt.figure(figsize=(8,7))\nsns.countplot(train['Sentiment']);","aa6a01fe":"train['text'] = train[\"OriginalTweet\"]\ntrain[\"text\"] = train[\"text\"].astype(str)\n\ntarget = train.groupby('Sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntarget.style.background_gradient(cmap='YlOrRd')","58b25dcc":"percent_target = target['text']\nlabels = target['Sentiment']\n\ncolors = ['#17C37B','#F92969','#FACA0C']\n\nmy_pie,_,_ = plt.pie(percent_target, radius = 1.9, labels=labels, colors=colors, autopct=\"%.1f%%\")\n\nplt.setp(my_pie, width=1.0, edgecolor='white') \n\nplt.show()","99888631":"fig = make_subplots(1,2,subplot_titles=('Train','Test'))\nx = train['Sentiment'].value_counts()\n\nfig.add_trace(go.Bar(x=x.index, y=x.values, marker_color=['#17C37B','#F92969','#FACA0C'], name='train'), row=1, col=1)\nx = test['Sentiment'].value_counts()\n\nfig.add_trace(go.Bar(x=x.index, y=x.values, marker_color=['#17C37B','#F92969','#FACA0C'], name='test'), row=1, col=2)","c74eadc4":"fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15,5))\n\ntweet_len=train[train['Sentiment']==\"positive\"]['text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len, color='#17C37B')\nax1.set_title('Positive Sentiments')\n\ntweet_len=train[train['Sentiment']==\"negative\"]['text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='#F92969')\nax2.set_title('Negative Sentiments')\n\ntweet_len=train[train['Sentiment']==\"netural\"]['text'].str.split().map(lambda x: len(x))\nax3.hist(tweet_len,color='#FACA0C')\nax3.set_title('Neutral Sentiments')\n\nfig.suptitle('Words in a tweet')\nplt.show()","ffb90416":"fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15,5))\n\ntweet_len=train[train['Sentiment']==\"positive\"]['text'].str.len()\nax1.hist(tweet_len, color='#17C37B')\nax1.set_title('Positive Sentiments')\n\ntweet_len=train[train['Sentiment']==\"negative\"]['text'].str.len()\nax2.hist(tweet_len, color='#F92969')\nax2.set_title('Negative Sentiments')\n\ntweet_len=train[train['Sentiment']==\"netural\"]['text'].str.len()\nax3.hist(tweet_len, color='#FACA0C')\nax3.set_title('Neutral Sentiments')\n\nfig.suptitle('Characters in tweets')\nplt.show()","440729a2":"# load stop words\nstop_word = stopwords.words('english')","fe01b332":"# load stop words\nstop_word = stopwords.words('english')","c30d92e7":"def corpus(target):\n    \n    # remove urls\n    target = re.sub(r'http\\S+', \" \", target)\n\n    # remove mentions\n    target = re.sub(r'@\\w+',' ', target)\n\n    # remove hastags\n    target = re.sub(r'#\\w+', ' ', target)\n\n    # remove digits\n    target = re.sub(r'\\d+', ' ', target)\n\n    # remove html tags\n    target = re.sub('r<.*?>',' ', target)\n    \n    # remove stop words \n    target = target.split()\n    target = \" \".join([word for word in target if not word in stop_word])    \n      \n    return target","6ac521e9":"train['OriginalTweet'] = train['OriginalTweet'].apply(lambda x: corpus(x))\ntest['OriginalTweet'] = test['OriginalTweet'].apply(lambda x: corpus(x))","2aadcd2e":"train.head()","3ade623b":"train = train.iloc[:,4:]\ntest = test.iloc[:,4:]","b70953ff":"display(train.head())\ndisplay(test.head())","5362b0c2":"#train['Sentiment'] = train['Sentiment'].map({'positive':2, 'negative':0, 'neutral':1})\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n  \n# Encode labels in column 'Sentiment'.\ntrain['Sentiment'] = le.fit_transform(train['Sentiment'])\n  \ntrain['Sentiment'].unique()","eb0b8b60":"train.head()","5ded3001":"# Split sentiment groups \nPositive = train[train['Sentiment'] == 2].OriginalTweet\nNeutral  = train[train['Sentiment'] == 1].OriginalTweet\nNegative = train[train['Sentiment'] == 0].OriginalTweet","1ee1b4e0":"# Worldcould of  Negative Tweets \nplt.figure(figsize = (20,20)) \nwordcould = WordCloud(min_font_size = 3,  max_words = 3000 , width = 1600 , height = 680).generate(\" \".join(Negative))\nplt.imshow(wordcould,interpolation = 'bilinear')\nplt.grid(None)","38efaf2c":"# Wordcould of Neutral Tweets \nplt.figure(figsize = (20,20)) \nwordcould = WordCloud(min_font_size = 3,  max_words = 3000 , width = 1600 , height = 680).generate(\" \".join(Neutral))\nplt.imshow(wordcould,interpolation = 'bilinear')\nplt.grid(None)","e911b7bf":"# Wordcould of Positive Tweets \nplt.figure(figsize = (20,20)) \nwordcould = WordCloud(min_font_size = 3,  max_words = 3000 , width = 1600 , height = 680).generate(\" \".join(Positive))\nplt.imshow(wordcould,interpolation = 'bilinear')\nplt.grid(None)","d432ddc6":"**Coronavirus tweets NLP - Text Classification (Multi-Class Classification)**\n\n- The tweets have been pulled from Twitter and manual tagging has been done them.","66ac6821":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 2) Load Required Libraries <\/h1>","eff63366":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left; border-radius: 0px 0px;\"> 4.1) Missing Values <\/h1>","bc8f244e":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left; border-radius: 0px 0px;\"> 4.3) Target Column <\/h1>","b6e7a2ef":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 5) Pre-processing <\/h1>","b601f510":"<h1 style=\"background-color:#f9b208;  color:#34656d; font-family:Comic Sans MS; font-size:200%; text-align:center; border-radius: 10px 10px;\"> Table of Contents <\/h1>\n\n* [1) Introduction](#1)\n\n* [2) Load Required Libraries](#2)\n\n* [3) Read Data](#3)\n\n* [4) EDA (Exploratory Data Analysis)](#4)\n\n     * [4.1) Missing Values](#4.1)\n\n     * [4.2) Duplicate rows](#4.2)\n     \n     * [4.3) Target Column](#4.3)\n     \n     * [4.4) Number of words in a tweet](#4.4)\n     \n     * [4.5) Number of characters](#4.5)","9b26b11b":"- we have 5 types of sentiment (make extremely positive into positive and extremely negative into negative)","eabcdfec":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left; border-radius: 0px 0px;\"> 4.2) Duplicate rows <\/h1>","7ebcb35e":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left; border-radius: 0px 0px;\"> 4.4) Number of words in a tweet <\/h1>","d7e3f0de":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 4) EDA (Exploratory Data Analysis) <\/h1>","cc35dfc4":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\"> 3) Read Data <\/h1>","b765cd3b":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left; border-radius: 0px 0px;\"> Wordclouds <\/h1>","9759e1ac":"train['Sentiment'] = train['Sentiment'].map({'Extremely Positive':'positive', 'Extremely Negative':'negative', 'Neutral':'neutral'})","26488439":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:170%; text-align:left; border-radius: 0px 0px;\"> 4.5) Number of characters <\/h1>","e915d8c3":"<h1 style=\"background-color:#fbc6a4; color:#34656d; font-family:Comic Sans MS; font-size:200%; text-align:center; border-radius: 10px 10px;\"> 1) Introduction <\/h1>"}}