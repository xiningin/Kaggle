{"cell_type":{"0ca9c0d4":"code","d7ebc883":"code","ae459291":"code","06d355a6":"code","c14a9d5f":"code","5da2742e":"code","7228bea1":"code","af627df1":"code","1e7a115f":"code","15204e82":"code","e750b632":"code","2d5f6e05":"code","9eb43743":"code","c2e0c295":"code","db1e1dfe":"code","7a2b6e81":"code","abf655e1":"code","47eb5ee5":"code","d55813d3":"code","cfd0dc6e":"markdown","c70adbcf":"markdown","9e04b912":"markdown","c0dc5c4e":"markdown","3f893874":"markdown","18be986f":"markdown","dc230c59":"markdown","22e1cb03":"markdown","b40edf4b":"markdown","b0d95675":"markdown"},"source":{"0ca9c0d4":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np \nfrom PIL import Image\nimport seaborn as sns\nimport cv2\nimport torch\nfrom torchvision import models\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom sklearn.metrics import confusion_matrix","d7ebc883":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\nfrom albumentations.pytorch import ToTensorV2","ae459291":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntorch.manual_seed(1234)\nif device =='cuda':\n    torch.cuda.manual_seed_all(1234)","06d355a6":"PATH = '..\/input\/cassava-leaf-disease-classification'\ntrain_img_path = PATH+ '\/train_images'\ntest_img_ath = PATH + '\/test_images'\n# Load dataset\ndf_train = pd.read_csv(PATH + '\/train.csv')\n","c14a9d5f":"def path_extracter(df):\n    x = [train_img_path + '\/' + str(k) for k in df.image_id]\n    y = [s for s in df.label]\n    \n    return x,y","5da2742e":"x_train,y_train = path_extracter(df_train)","7228bea1":"del df_train","af627df1":"from sklearn.model_selection import train_test_split\ntrain_idx, val_idx = train_test_split(list(range(len(x_train))), test_size = 0.2)","1e7a115f":"x_val = [x_train[k] for k in val_idx]\ny_val = [y_train[k] for k in val_idx]\n\nx_train = [x_train[k] for k in train_idx]\ny_train = [y_train[k] for k in train_idx]","15204e82":"class dataset(torch.utils.data.Dataset):\n     \n        def __init__(self, file_list, labels, transform = None):\n            self.file_list = file_list\n            self.transforms = transform\n            self.label_list = labels\n            \n            \n        def __len__(self):\n            self.filelength = len(self.file_list)\n            return self.filelength\n        \n        def __getitem__(self,idx):\n            img_path = self.file_list[idx]\n            x = cv2.imread(img_path)\n            if self.transforms:\n                x = self.transforms(image=x)['image']\n            \n            if self.label_list[idx] == 1:\n                label = 1\n            else:\n                label = 0\n                \n            return x, label","e750b632":"img_transforms = Compose([\n            RandomResizedCrop(224,224),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)","2d5f6e05":"train_data = dataset(x_train, y_train, transform = img_transforms)\nval_data  = dataset(x_val, y_val, transform = img_transforms)\n","9eb43743":"train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=16, shuffle=True )\nval_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=16, shuffle=True )\n","c2e0c295":"class Net(nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3,16,kernel_size=3, padding=0,stride=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16,32, kernel_size=3, padding=0, stride=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n            )\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32,64, kernel_size=3, padding=0, stride=2),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        \n        self.fc1 = nn.Linear(3*3*64,10)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(10,5)\n        self.relu = nn.ReLU()\n        \n        \n    def forward(self,x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.view(out.size(0),-1)\n        out = self.relu(self.fc1(out))\n        out = self.fc2(out)\n        return out","db1e1dfe":"# ----------------------------------------\n# Initialize model\nmodel = Net().to(device)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)","7a2b6e81":"model.train()","abf655e1":"# ----------------------------------------\nhistory = {'training_acc' : [],'val_loss' : [],'val_acc' : [],'train_loss' : []}\ndef train(epoch):\n    epoch_loss = 0\n    epoch_accuracy = 0\n    \n    for data, label in train_loader:\n        data = data.to(device)\n        label = label.to(device)\n        \n        output = model(data)\n        loss = criterion(output, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        acc = ((output.argmax(dim=1) == label).float().mean())\n        epoch_accuracy += acc\/len(train_loader)\n        epoch_loss += loss\/len(train_loader)\n        \n    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch+1, epoch_accuracy,epoch_loss))\n    \n    \n    with torch.no_grad():\n        epoch_val_accuracy=0\n        epoch_val_loss =0\n        for data, label in val_loader:\n            data = data.to(device)\n            label = label.to(device)\n            \n            val_output = model(data)\n            val_loss = criterion(val_output,label)\n            \n            \n            acc = ((val_output.argmax(dim=1) == label).float().mean())\n            epoch_val_accuracy += acc\/ len(val_loader)\n            epoch_val_loss += val_loss\/ len(val_loader)\n            \n        print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch+1, epoch_val_accuracy,epoch_val_loss))\n    history['training_acc'].append(epoch_accuracy)\n    history['val_acc'].append(epoch_val_accuracy)\n    history['train_loss'].append(epoch_loss)\n    history['val_loss'].append(epoch_val_loss)","47eb5ee5":"\n\nfor epoch in range(0, 1):\n    train(epoch)\n\n","d55813d3":"df = pd.DataFrame.from_dict(history, orient='columns')\n# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(df.train_loss, color='b', label=\"Training loss\")\nax[0].plot(df.val_loss, color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(df.training_acc, color='b', label=\"Training accuracy\")\nax[1].plot(df.val_acc, color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","cfd0dc6e":"#### 3.3 Optimizer","c70adbcf":"\nCNN model of Digit Recognizer using Pytoch\n\nHoon Kim (id : KeyboardWarrior6969)\n\n13\/1\/2020\n","9e04b912":"### 4. Model Performance","c0dc5c4e":"#### 3.2 Model Definition","3f893874":"### 3. CNN Model","18be986f":"#### 4.1 Training and Validation Curves","dc230c59":"**1. Introduction**\n\n**2. Data Preparation**\n\n**3. CNN Model**\n\n- 3.1 Annealer\n- 3.2 Model Definition\n- 3.3 Optimizer\n\n**4. Model Performance**\n\n- 4.1 Validation and Training curves","22e1cb03":"### 1. Introduction\n\nThe aim of this notebook is to showcase a simple CNN build using the keras framework. 10 epochs were run utilising the Kaggle GPU architecture.","b40edf4b":"### 2. Data Preparation","b0d95675":"#### 3.1 Annealer"}}