{"cell_type":{"5db08596":"code","19dd27ce":"code","55e6df46":"code","ec6284f7":"code","7ec7d759":"code","ce0b348f":"code","2b4144a4":"code","87d7eec7":"code","373f9d6e":"code","f0e16df8":"code","802a05a4":"code","d738c670":"code","7892e440":"code","af597eb4":"code","b28053ac":"code","ba406f28":"code","9ad8638e":"code","19ca1ca8":"code","b6bdbb76":"code","1f5a7a1f":"code","28b2cbb5":"code","8328e832":"code","911a39f6":"code","c7a25642":"code","5864672b":"code","d4a65281":"code","0ee3eef7":"code","4a79fd99":"code","846c1be9":"code","21361d06":"code","bfbf6be0":"code","954469ac":"code","26e8fcf3":"code","8f17730c":"code","5bae3da8":"code","d957513e":"code","f226d463":"markdown","18339ccf":"markdown","15e9672d":"markdown","49a09ce1":"markdown","198621d2":"markdown","92c22f30":"markdown","01316455":"markdown","4577f338":"markdown","1ca26c58":"markdown"},"source":{"5db08596":"import os\n\n# \uae30\ubcf8\ud3f4\ub354(base folder)\ndir_ad = '..\/input\/..\/input\/home-credit-default-risk'\n# dir_ad = os.getcwd()\n\n# \ud559\uc2b5\ub370\uc774\ud130, predict data \ud30c\uc77c\uba85(train, test file name)\ntrain = 'application_train.csv'\ntest = 'application_test.csv'\n\n# \uc5b4\ub5a4\uac83\uc744 \ubd84\uc11d \ubc0f \ub370\uc774\ud130 \ucd94\ucd9c\ud560\uc9c0 \uad6c\ubd84\ud560 \uc218 \uc788\ub294 \ud30c\uc77c\uba85 \uc120\ud0dd \n# tag = 'train_MAU_3M_pred_MAUX_4M'\u2190 \uc774\ub7f0 \ubc29\uc2dd\uc73c\ub85c \ub098\uc62c \uac83\uc73c\ub85c \uc608\uc0c1\ntag = 's_result'\n\n# \ubaa8\ub378 \ubc0f \uac01\uc885 \uc0b0\ucd9c\ubb3c\uc774 \uc800\uc7a5\ub420 \ud3f4\ub354\nmodel_dir = os.path.join(dir_ad, tag + '_v')\n\n# \ub808\uc774\ube14\uc5d0 \ud574\ub2f9\ud558\ub294 \uceec\ub7fc(column corresponding to label: Y value)\ntarget = 'TARGET'\n\n# \ud0c0\uac9f\ud305 \ub300\uc0c1\uc744 \uc2dd\ubcc4\ud558\uae30 \uc704\ud55c \uceec\ub7fc(Column to identify the target)\nindex_col = 'SK_ID_CURR'\n\n# \ud3c9\uac00\ubc29\ubc95 \"accuracy\", \"roc_auc\",\"f1\" \ub4f1 \uc120\ud0dd\nchoice = \"roc_auc\"","19dd27ce":"import seaborn as sns\nimport sys\nimport csv\nimport datetime\nimport operator\nimport joblib\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.svm import SVC\n\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier","55e6df46":"df_train = pd.read_csv(os.path.join(dir_ad, train))\ndf_test = pd.read_csv(os.path.join(dir_ad, test))","ec6284f7":"num_cols = [col for col in df_test.columns if df_test[col].dtype in [\"float16\",\"float32\",\"float64\", \"int64\", \"int32\"]]\ncat_cols = [col for col in df_test.columns if df_test[col].dtype not in [\"float16\",\"float32\",\"float64\", \"int64\", \"int32\"]]","7ec7d759":"def detect_outliers(data, col_name):\n    outlier_indices = []\n    # iterate over features(columns)\n    for col in col_name:\n        Q1 = np.percentile(data[col], 25)\n        Q3 = np.percentile(data[col],75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR\n        outlier_list_col = data[(data[col] < Q1 - outlier_step) | (data[col] > Q3 + outlier_step )].index\n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","ce0b348f":"def outlier_replace(data, col_name, q1=0.25, q3=0.75):\n    quartile1 = data[col_name].quantile(q1)\n    quartile3 = data[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    data.loc[(data[col_name] < low_limit), col_name] = low_limit\n    data.loc[(data[col_name] > up_limit), col_name] = up_limit","2b4144a4":"for i in num_cols:\n    outlier_replace(df_train,i)\n    outlier_replace(df_test, i)","87d7eec7":"df_train = df_train.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)\ndf_test = df_test.apply(lambda x: x.fillna(x.median()) if x.dtype != \"O\" else x, axis=0)","373f9d6e":"def count_plot(d, y, x):\n    plt.figure(figsize=(12,6))\n    sns.countplot(x = d[y], hue = x, data=d)\n    plt.ylabel('Number of people')\n    plt.title('Survival count by '+ x)","f0e16df8":"over_column_name = list()\n\nfor i in num_cols:\n    if (len(df_train[i].value_counts())<20):\n        count_plot(df_train, target, i)\n    elif (len(df_train[i].value_counts())>20):\n        over_column_name.append(i)\n\n# print('Column\ub0b4 \ubcc0\uc218\uac00 10\uac1c \uc774\uc0c1\uc758 Column\uc740 \ud558\ub2e8\uacfc \uac19\uc2b5\ub2c8\ub2e4.\\n\ubcc0\uc218 10\uac1c \ubbf8\ub9cc\uc758 Column\uacfc Survived \uc22b\uc790 \ubd84\ud3ec\ub294 \uadf8\ub798\ud504\uc640 \uac19\uc2b5\ub2c8\ub2e4.')\n# print(over_column_name)","802a05a4":"df_train = pd.get_dummies(df_train)\ndf_test = pd.get_dummies(df_test)","d738c670":"test_col = []\ndelete_train = []\n\nfor i in df_test.columns:\n    test_col.append(i)\nfor j in df_train.columns:\n    if j not in test_col:\n        delete_train.append(j)\ndelete_train.remove(target)","7892e440":"train_col = []\ndelete_test = []\n\nfor i in df_train.columns:\n    train_col.append(i)\nfor j in df_test.columns:\n    if j not in train_col:\n        delete_test.append(j)","af597eb4":"for delete in delete_train:\n    df_train = df_train.drop([delete],axis=1)\n    \nfor delete in delete_test:\n    df_test = df_test.drop([delete],axis=1)","b28053ac":"for i in num_cols:\n    sns.factorplot(x=target, y = i,data = df_train, kind=\"violin\")","ba406f28":"random_state_val =777\ntest_size_val =0.1\n\ndf_train, df_val = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val)\n\ndrop_col = [target, index_col]\ny_nm = target\n\ndf_train_x = df_train.drop(drop_col, axis = 1)\ndf_train_y = pd.DataFrame(df_train[y_nm])\n\ndf_val_x = df_val.drop(drop_col, axis = 1)\ndf_val_y = pd.DataFrame(df_val[y_nm])","9ad8638e":"LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   nthread=4,\n                                   n_estimators=10000,\n                                   learning_rate=0.02,\n                                   num_leaves=34,\n                                   colsample_bytree=0.9497036,\n                                   subsample=0.8715623,\n                                   max_depth=8,\n                                   reg_alpha=0.041545473,\n                                   reg_lambda=0.0735294,\n                                   min_split_gain=0.0222415,\n                                   min_child_weight=39.3259775,\n                                   silent=-1,\n                                   random_state = 42)","19ca1ca8":"start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)], \n                       eval_metric ='auc',\n                       early_stopping_rounds = 200,\n                       verbose = True)\nend = datetime.datetime.now()\nend-start","b6bdbb76":"feature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_train_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp[:10].sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()\n# plt.savefig('lightGBM_ Importances.png')","1f5a7a1f":"fpr, tpr, _ = roc_curve(df_val_y, lgbm.predict_proba(df_val_x.values)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nresult_lst =[]\nmax_value =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4),'roc_auc': round(roc_auc,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if choice == 'Accuracy':\n        if max_value <= accuracy:\n            max_value = accuracy\n            opt_threshold = threshold\n    elif choice == 'Precision':\n        if max_value <= precision:\n            max_value = precision\n            opt_threshold = threshold\n    elif choice == 'Recall':\n        if max_value <= recall:\n            max_value = recall\n            opt_threshold = threshold\n    elif choice == 'F1_Score':\n        if max_value <= f1_score:\n            max_value = f1_score\n            opt_threshold = threshold\n    elif choice == 'roc_auc':\n        if max_value <= roc_auc:\n            max_value = roc_auc\n            opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Max_value =%f, optimized_threshold=%f'%(max_value, opt_threshold))\nprint('Complete')","28b2cbb5":"predict_lgbm = lgbm.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()","8328e832":"conf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nAccuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","911a39f6":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","c7a25642":"XGBClassifier = xgb.XGBClassifier(max_depth = 6,\n                                 learning_rate = 0.01,\n                                 n_estimators = 10000,\n                                 objective = 'binary:logistic',\n                                 tree_method = 'gpu_hist',\n                                 booster = 'gbtree',\n                                 seed = 23,\n                                 min_child_weight = 35,\n                                 subsample = 0.7,\n                                 alpha = 0.25,\n                                 n_jobs = -1\n                                 )","5864672b":"start = datetime.datetime.now()\nxgb = XGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)], \n                       eval_metric = 'auc',\n                       early_stopping_rounds = 200,\n                       verbose = True)\nend = datetime.datetime.now()\nend-start","d4a65281":"fi_vals = xgb.get_booster().get_score(importance_type = 'weight')\nfi_dict = {df_train_x.columns[i]:float(fi_vals.get('f'+str(i),0.)) for i in range(len(df_train_x.columns))}\nfeature_importance_ = sorted(fi_dict.items(), key=operator.itemgetter(1), reverse=True)\nfeature_importance_result = OrderedDict(feature_importance_)\n\nimportance = pd.DataFrame(feature_importance_)\nimportance.columns = ['feature','weight']\nimportance.head(10)","0ee3eef7":"importance_ten = importance[:10]\nimportance_ten.set_index('feature').sort_values(by='weight').plot(kind='barh', figsize=(5, 5))","4a79fd99":"fpr, tpr, _ = roc_curve(df_val_y, xgb.predict_proba(df_val_x.values)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nresult_lst =[]\nmax_value =0.\nopt_threshold_2 =0.\nval_y_prob = xgb.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4),'roc_auc': round(roc_auc,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if choice == 'Accuracy':\n        if max_value <= accuracy:\n            max_value = accuracy\n            opt_threshold_2 = threshold\n    elif choice == 'Precision':\n        if max_value <= precision:\n            max_value = precision\n            opt_threshold_2 = threshold\n    elif choice == 'Recall':\n        if max_value <= recall:\n            max_value = recall\n            opt_threshold_2 = threshold\n    elif choice == 'F1_Score':\n        if max_value <= f1_score:\n            max_value = f1_score\n            opt_threshold_2 = threshold\n    elif choice == 'roc_auc':\n        if max_value <= roc_auc:\n            max_value = roc_auc\n            opt_threshold_2 = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Max_value =%f, optimized_threshold=%f'%(max_value, opt_threshold_2))\nprint('Complete')","846c1be9":"predict_xgb = xgb.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_xgb > opt_threshold_2, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nAccuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","21361d06":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_xgb)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","bfbf6be0":"df_test = df_test.drop(index_col, axis = 1)\n\ntest_xgb = pd.Series(xgb.predict(df_test.values), name=\"XGB\")\ntest_lgbm = pd.Series(lgbm.predict(df_test.values), name=\"LGBM\")\n\n# Concatenate all classifier results\nensemble_results = pd.concat([test_xgb,test_lgbm],axis=1)\n\ng= sns.heatmap(ensemble_results.corr(),annot=True)","954469ac":"votingC = VotingClassifier(estimators=[('xgb', xgb),('lgbm', lgbm)], voting='soft')\nvotingC = votingC.fit(df_train_x.values, df_train_y.values)","26e8fcf3":"fpr, tpr, _ = roc_curve(df_val_y, votingC.predict_proba(df_val_x.values)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nresult_lst =[]\nmax_value =0.\nopt_threshold_3 =0.\nval_y_prob = votingC.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,60):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4),'roc_auc': round(roc_auc,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if choice == 'Accuracy':\n        if max_value <= accuracy:\n            max_value = accuracy\n            opt_threshold_3 = threshold\n    elif choice == 'Precision':\n        if max_value <= precision:\n            max_value = precision\n            opt_threshold_3 = threshold\n    elif choice == 'Recall':\n        if max_value <= recall:\n            max_value = recall\n            opt_threshold_3 = threshold\n    elif choice == 'F1_Score':\n        if max_value <= f1_score:\n            max_value = f1_score\n            opt_threshold_3 = threshold\n    elif choice == 'roc_auc':\n        if max_value <= roc_auc:\n            max_value = roc_auc\n            opt_threshold_3 = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Max_value =%f, optimized_threshold=%f'%(max_value, opt_threshold_3))\nprint('Complete')","8f17730c":"predict_votingC = votingC.predict_proba(df_val_x.values)[:,1]\npred_val = np.where(predict_votingC > opt_threshold_3, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_val_y.values.ravel(), pred_val, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_val_y.values.ravel(), pred_val),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_val_y.values.ravel(), pred_val))\n\nAccuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","5bae3da8":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_val_y.values.ravel(), predict_votingC)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","d957513e":"predict_votingC = votingC.predict_proba(df_test.values)[:,1]\n\ndf_test = pd.read_csv(os.path.join(dir_ad, test))\ntest_result= pd.DataFrame(predict_votingC)\ntest_result.columns = [target]\npredict = test_result[target]\nId_No = df_test[index_col]\nsubmission = pd.DataFrame({index_col: Id_No, target: predict})\n# submission[target] = submission[target].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","f226d463":"**\uba38\uc2e0\ub7ec\ub2dd\uc744 \ubab0\ub77c\ub3c4 \"Config\"\uc5d0 5\uac00\uc9c0\ub9cc \ub123\uc73c\uba74, \uc2e4\ud589\ud560 \uc218 \uc788\uac8c \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4.<br>\nEven if you don't know machine learning, you can submit only 5 things in \"config\"**\n\n\ud68c\uc0ac\uc5d0\uc11c \ub9ce\uc774 \uc0ac\uc6a9\ud558\uac8c \ub9cc\ub4e4\uc5c8\uc5c8\uace0, \ub3c4\uc6c0\uc774 \ub9ce\uc774 \ub420 \uac81\ub2c8\ub2e4.<br> \nI made a lot of use of it in company, and it will help a lot.","18339ccf":"# Introduction","15e9672d":"\ucf54\ub4dc \uacf5\uc720\ub41c \uc804\ucc98\ub9ac \uc801\uc6a9 \ud639\uc740 \ud14c\uc774\ube14 \uacb0\ud569\uc2dc 0.79\uc218\uc900\uc758 AUROC\uacb0\uacfc\uac00 \ub098\uc624\uc9c0\ub9cc, \uacf5\uc720 \ucf54\ub4dc\uc5d0\ub294 \uadf8\ub0e5 TRAIN Data\ud558\ub098\ub85c\ub9cc \ub098\uc628 \uacb0\uacfc\ub97c \ubcf4\uc5ec\ub4dc\ub9ac\uaca0\uc2b5\ub2c8\ub2e4.<br>\nCode When applying shared preprocessing or combining tables, an AUROC result of 0.79 level is obtained, but in the shared code, only one TRAIN Data will be shown.","49a09ce1":"\ud0c0\uc774\ud0c0\ub2c9 \ub370\uc774\ud130 \uae30\uc900\uc73c\ub85c \ubaa8\ub378\ub9c1\uc744 \uc9c4\ud589\ud558\uc600\uace0, \uc774\ud6c4 \ubd84\ub958 \ubb38\uc81c\uc5d0 \ub300\ud558\uc5ec \ud14c\uc2a4\ud2b8 \uc9c4\ud589\ud574 \ubcf4\uc558\uc2b5\ub2c8\ub2e4.<br>\n\uc5b4\ub5a4\ud55c \ubd84\ub958 \ubb38\uc81c\uc5d0 \ub300\ud558\uc5ec\ub3c4 \ud574\uacb0\ud560 \uc218 \uc788\ub294 \uc790\ub3d9\uc801\uc778 \ubaa8\ub378\uc744 \ub9cc\ub4dc\ub294 \ubaa9\ud45c\ub85c \uc791\uc5c5\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.<br> \n\ube44\uae30\ub2a5\uc801\uc778 \uc694\uc18c\uc778 \uc18d\ub3c4 \ubd80\ubd84\ub3c4 \uac10\uc548\ud558\uc600\uace0, \ucd5c\ub300\ud55c \uac04\uacb0\ud558\uac8c \uc791\uc131\ud558\ub3c4\ub85d \ub178\ub825 \ud588\uc2b5\ub2c8\ub2e4.<br>\n<br>\nModeling was performed based on the Titanic data, and then the classification problem was tested.<br>\nWe are working with the goal of creating an automatic model that can solve any classification problem.<br>\nThe speed part, which is a non-functional factor, was also taken into consideration, and I tried to write it as concisely as possible.","198621d2":"# Config","92c22f30":"![image.png](attachment:c779999c-5cb4-4189-840a-1c7595da1c27.png)","01316455":"# Home Credit Default Risk Data Analysis","4577f338":"# Modeling","1ca26c58":"![image.png](attachment:d7dea6b1-ad77-4e04-aa8e-a6f7899a8e46.png)"}}