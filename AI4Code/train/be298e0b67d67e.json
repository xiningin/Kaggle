{"cell_type":{"5dd1bdd2":"code","2cf28aca":"code","6e19bf24":"code","f5009c20":"code","16a6f1c4":"code","ae346ae8":"code","e779d28f":"code","0ee06819":"code","4d87502b":"code","c6b7a909":"code","d2a179e9":"code","859113fe":"code","b76a7c3b":"code","996006df":"markdown","ac745c56":"markdown","09766105":"markdown","b2acb01a":"markdown","ef181d05":"markdown","c9e61058":"markdown","d58ca75a":"markdown","75dbafc1":"markdown","5e09d568":"markdown"},"source":{"5dd1bdd2":"!pip install evalml","2cf28aca":"import evalml\nfrom evalml import AutoMLSearch\nimport pandas as pd","6e19bf24":"X = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv',nrows=1000)\n#limiting rows here because of computational bottlenecks\ny = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/example_test.csv')","f5009c20":"# Only selecting the columns where missing values is less than7 percent\nfinal_cols = X.isnull().mean()[X.isnull().mean() < 0.07]","16a6f1c4":"# Selecting only the required columns\nX = X[final_cols.index]","ae346ae8":"# Filling NA values with median\nX = X.fillna(X.median())\nimport numpy as np","e779d28f":"X['action'] = np.where((X.resp_1 > 0) & (X.resp_2 > 0) & (X.resp_3 > 0) & (X.resp_4 > 0) & (X.resp > 0),1,0)","0ee06819":"X_train, X_test, y_train, y_test = evalml.preprocessing.split_data(X.drop(columns = ['date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4','resp', 'ts_id','action']),X['action'], problem_type='binary')\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","4d87502b":"#limiting search for efficiency\nautoml = AutoMLSearch(X_train=X_train, y_train=y_train,   problem_type='binary',allowed_model_families=['xgboost', 'lightgbm','catboost'],max_batches=5)\nautoml.search() ","c6b7a909":"automl.rankings","d2a179e9":"automl.describe_pipeline(automl.rankings.iloc[0][\"id\"])","859113fe":"winner = automl.best_pipeline\ndf_submission = winner.predict_proba(y.drop(columns=['ts_id'])).to_dataframe()\ndf_submission['ts_id'] = y['ts_id']","b76a7c3b":"df_submission.set_index('ts_id').to_csv('submission.csv')","996006df":"<h1> Installation from Pypi <\/h1>","ac745c56":"Hello.\n\nI find AutoML tools the best for baseline models, so here I'm trying another one called EvalML. You may find my other AutoML notebooks [here ](https:\/\/www.kaggle.com\/kritidoneria\/code?userId=1260510&sortBy=dateRun&tab=profile&language=Python&privacy=public)\n\nA huge shoutout to [this](https:\/\/www.kaggle.com\/gauravduttakiit\/automate-the-ml-pipelines-with-evalml) Notebook for introducing me to this library.\n[I've also used EvalML to compete in TPS May](https:\/\/www.kaggle.com\/kritidoneria\/automl-tps-may21-using-evalml)\nAnother reference for this work is [here](https:\/\/www.kaggle.com\/tsnarendran14\/jane-street-simple-xgb-model\/data)","09766105":"# Run the search for the best classification model.","b2acb01a":"<h2> Preprocessing<\/h2>","ef181d05":"<h1> Introduction to library <\/h1>","c9e61058":"<h1> Making predictions <\/h1>","d58ca75a":"Source: https:\/\/github.com\/alteryx\/evalml\n\nEvalML is an AutoML library which builds, optimizes, and evaluates machine learning pipelines using domain-specific objective functions.\n\n**Key Functionality**\n\n1. Automation - Makes machine learning easier. Avoid training and tuning models by hand. Includes data quality checks, cross-validation and more.\n2. Data Checks - Catches and warns of problems with your data and problem setup before modeling.\n3. End-to-end - Constructs and optimizes pipelines that include state-of-the-art preprocessing, feature engineering, feature selection, and a variety of modeling techniques.\n4. Model Understanding - Provides tools to understand and introspect on models, to learn how they'll behave in your problem domain.\n5. Domain-specific - Includes repository of domain-specific objective functions and an interface to define your own.","75dbafc1":"<h1> Model rankings and best pipeline <\/h1>","5e09d568":"<h1> Load the Dataset <\/h1>"}}