{"cell_type":{"9f34de2e":"code","2baadf73":"code","248273d6":"code","1a2e38f9":"code","5816d6fb":"code","ac411fa1":"code","958af87c":"code","e9622ba8":"code","ce7a67f1":"code","e15c222a":"code","753833a6":"code","c1fd79f8":"code","4301c43f":"code","e032d1b8":"code","b96247d8":"code","2e270e11":"code","31c010bf":"code","08bb3981":"code","200e8eda":"code","5f1f80bf":"code","3f1c0682":"code","d0a90e63":"code","ca3be2a8":"code","7a6b8984":"code","671bc0fd":"code","15446b76":"code","97c45d87":"code","8c90b75d":"code","1af88e4d":"code","c1ac6069":"code","2971781e":"code","0584cca6":"code","2331d289":"code","559903fb":"markdown","e915ad9a":"markdown","6f8f6213":"markdown","bc42acb4":"markdown","db7cb2ec":"markdown","0700a6d9":"markdown","85ff25bb":"markdown","c12e9c16":"markdown","9a0e0d95":"markdown","3322bfbf":"markdown","4fb09562":"markdown","9bc38a2f":"markdown","c0d175bf":"markdown","4f7d9477":"markdown","1aa61b98":"markdown","2e2c3132":"markdown","77a5738a":"markdown","0f7b6cfc":"markdown","c2b7e8bb":"markdown","12009881":"markdown","a210e4bb":"markdown","3c3e3ed8":"markdown","2523f536":"markdown"},"source":{"9f34de2e":"# Load libraries on Python 3 environment \n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sb \nimport matplotlib.pyplot as plt\nimport matplotlib.dates as dates\nfrom PIL import Image\nimport requests\nfrom io import StringIO\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nfrom datetime import datetime\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n%matplotlib inline","2baadf73":"# Lookup given features on train and test data\n\n# LOCAL_PATH = '~\/Downloads\/nyc-taxi-trip-duration'\nKAGGLE_PATH = '..\/input'\ndata_train = pd.read_csv(KAGGLE_PATH + '\/train.csv')\ndata_test = pd.read_csv(KAGGLE_PATH + '\/test.csv')\nsample_sub = pd.read_csv(KAGGLE_PATH + '\/sample_submission.csv')\n\nPLAN_URL = 'http:\/\/taxomita.com\/wp-content\/uploads\/2017\/12\/map-of-areas-in-nyc-highway-map-of-new-york-city-metropolitan-area-highways.gif';\nprint(data_train.info())\nprint(data_test.info())\n","248273d6":"print('We have {} training rows and {} test rows.'.format(data_train.shape[0], data_test.shape[0]))\nprint('We have {} training columns and {} test columns.'.format(data_train.shape[1], data_test.shape[1]))\ndata_train.head(3)","1a2e38f9":"\"\"\"\nExtract date, year, month, weekday, hour from columns\n\"\"\"\ndef datetime_extract(df, columns, modeling=False):\n    df_ = df.copy()\n    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    for col in columns:\n        try:\n            prefix = col\n            if \"_\" in col:\n                prefix = col.split(\"_\")[0]\n            ts = f\"{prefix}_ts\"\n            df_[ts] = pd.to_datetime(df_[col])\n            df_[f\"{prefix}_month\"] = df_[ts].dt.month\n            df_[f\"{prefix}_weekday\"] = df_[ts].dt.weekday\n            df_[f\"{prefix}_day\"] = df_[ts].dt.day\n            df_[f\"{prefix}_hour\"] = df_[ts].dt.hour\n            df_[f\"{prefix}_minute\"] = df_[ts].dt.minute\n            if not modeling: \n                df_[f\"{prefix}_date\"] = df_[ts].dt.date\n                df_[f\"{prefix}_dayname\"] = df_[f\"{prefix}_weekday\"].apply(lambda x: day_names[x])\n            else:\n                df_.drop(columns=[ts, col], axis = 1)\n        except:\n            pass\n    return df_\n\n\"\"\"\nExtract delta between two timestamps in minutes\n\"\"\"\ndef timedelta_extract(df, colname, start, end):\n    df_= df.copy()\n    df_[f'{colname}'] = (df_[end] - df_[start]).astype('timedelta64[m]')\n    return df_\n\n","5816d6fb":"df_train = datetime_extract(data_train, ['pickup_datetime', 'dropoff_datetime'])\ndf_train = timedelta_extract(df_train, 'delta_m', 'pickup_ts', 'dropoff_ts')","ac411fa1":"df_train.head(3)","958af87c":"df_train.vendor_id.value_counts()","e9622ba8":"fig, ax = plt.subplots(ncols=2, sharey=True, figsize=(14, 5))\nfor i, col in enumerate(['pickup', 'dropoff']):\n    ax[i].plot(df_train.groupby(f'{col}_date').count()['id'], 'o-')\n    ax[i].set(xlabel='Months', ylabel=f'{col} count'.title(), title=f'{col}s per date'.title())\nplt.show()","ce7a67f1":"fig, ax = plt.subplots(ncols=2, figsize=(14, 5))\nfor i, col in enumerate(['pickup', 'dropoff']):\n    ax[i].plot(df_train.groupby([f'{col}_date']).sum()['passenger_count'])\n    ax[i].set(xlabel='Months', ylabel=\"Total passengers\", title=\"Total passengers per date\")\n","e15c222a":"    sb.distplot(df_train.passenger_count, kde=False, bins=df_train.passenger_count.max(), \n                vertical=True, axlabel=\"Passengers distribution\");\n    df_train.passenger_count.value_counts(sort=False)\n","753833a6":"# Download not working on Kaggle.. Try the PLAN_URL directly at the top of the page \ntry:\n    plan = requests.get(PLAN_URL)\n    img = Image.open(BytesIO(plan.content))\n    fig, ax = plt.subplots(figsize=(14, 12))\n    ax.imshow(np.asarray(img), aspect='auto')\nexcept:\n    pass","c1fd79f8":"# Some pickups \/ dropoffs are outside NYC area, we are dropping outliers (geopoint > 95% and < 5%)\n# https:\/\/www.kaggle.com\/misfyre\/in-depth-nyc-taxi-eda-also-w-animation\n\ndef rm_geo_outliers(df, columns):\n    df_ = df.copy()\n    for i, col in enumerate(columns):\n        col_lat = f\"{col}_latitude\"\n        col_lng = f\"{col}_longitude\"\n        df_ = df_[(\n             df_[col_lng]>df_[col_lng].quantile(0.005))\n           &(df_[col_lng]<df_[col_lng].quantile(0.995))\n           &(df_[col_lat]>df_[col_lat].quantile(0.005))                           \n           &(df_[col_lat]<df_[col_lat].quantile(0.995))]\n    return df_\n\ndef display_geo(df, columns):\n    for i, col in enumerate(columns):\n        col_lat = f\"{col}_latitude\"\n        col_lng = f\"{col}_longitude\"\n        sb.lmplot(x=col_lng, y=col_lat, fit_reg=False, height=9, scatter_kws={'alpha':0.3,'s':5},\n                       data=df)\n\n        plt.xlabel(f'{col} Longitude'.title());\n        plt.ylabel(f'{col} Latitude'.title());\n        plt.show()\n    return\n\ngeo_columns = ['pickup', 'dropoff'];\ndf_train = rm_geo_outliers(df_train, geo_columns)\ndisplay_geo(df_train, geo_columns)\n","4301c43f":"df_train.store_and_fwd_flag.value_counts()","e032d1b8":"vendor_counts = df_train['vendor_id'].value_counts()\n\nsb.barplot(vendor_counts.index, vendor_counts.values)\nplt.xlabel('vendor_id')\nplt.ylabel('Total rides')\nplt.show()","b96247d8":"df_train.nlargest(5, 'trip_duration')[['id', 'trip_duration', 'delta_m']]","2e270e11":"# We have some outliers, let's remove them (> .97 quantile)\n\nfig, ax = plt.subplots(figsize=(14, 4))\ntripduration = df_train[df_train.trip_duration < df_train.trip_duration.quantile(.97)]\ntripduration.groupby('delta_m').count()['id'].plot()\n\nplt.xlabel('Trip duration in minutes')\nplt.ylabel('Trip count')\nplt.title('Duration distribution')\nplt.show()","31c010bf":"fig, ax = plt.subplots(figsize=(14, 4))\npd.pivot_table(tripduration, index='pickup_hour' ,aggfunc=np.mean)['trip_duration'].plot(label='mean')\n\nplt.legend(loc=0)\nplt.xlabel('Pickup hours (24h)')\nplt.ylabel('Rides')\nplt.title('Rides vs. pickup hours')\nplt.show()","08bb3981":"df_train = datetime_extract(data_train, ['pickup_datetime', 'dropoff_datetime'], modeling=True)\ndf_test = datetime_extract(data_test, ['pickup_datetime'], modeling=True)","200e8eda":"def label_encode(df, column):\n    df_ = df.copy();\n    try:\n        le = LabelEncoder()\n        le.fit(data_train[column])\n        df_train[column] = le.transform(df_train[column])\n        df_test[column] = le.transform(df_test[column])\n    except:\n        pass\n    return df_\n\ndf_train = label_encode(df_train, 'store_and_fwd_flag')\ndf_test = label_encode(df_test, 'store_and_fwd_flag')","5f1f80bf":"predict_ids = df_test['id']","3f1c0682":"s_train, s_test = train_test_split(df_train, test_size = 0.2)\n# Locally : s_train, s_test = train_test_split(df_train[0:100000], test_size = 0.2)","d0a90e63":"DROP_TRAIN = ['id', 'pickup_datetime', 'pickup_ts', 'dropoff_datetime', 'dropoff_ts']\nDROP_PREDICT = DROP_TRAIN + ['trip_duration', 'dropoff_month', 'dropoff_weekday', 'dropoff_day',  'dropoff_hour', 'dropoff_minute'];","ca3be2a8":"X_train = s_train.drop(DROP_PREDICT + ['trip_duration'], axis = 1)\nY_train = s_train[\"trip_duration\"]\nY_train = Y_train.reset_index().drop('index', axis = 1)\n\nX_test = s_test.drop(DROP_PREDICT + ['trip_duration'], axis = 1)\nY_test = s_test[\"trip_duration\"]\nY_test = Y_test.reset_index().drop('index', axis = 1)","7a6b8984":"dtrain = xgb.DMatrix(X_train, label=np.log(Y_train+1))","671bc0fd":"dvalid = xgb.DMatrix(X_test, label=np.log(Y_test+1))","15446b76":"dtest = xgb.DMatrix(df_test.drop(['id', 'pickup_datetime', 'pickup_ts'], axis = 1))","97c45d87":"watchlist = [(dtrain, 'train'), (dvalid, 'valid')]","8c90b75d":" # https:\/\/www.kaggle.com\/karelrv\/nyct-from-a-to-z-with-xgboost-tutorial\n\"\"\"\nmd = [6]\nlr = [0.1,0.3]\nmcw = [20,25,30]\nfor d in md:\n    for l in lr:\n        for w in mcw:\n            t0 = datetime.now()\n            \n            xgb_pars = {'min_child_weight': w, 'eta': l, 'colsample_bytree': 0.9, \n                        'max_depth': d,\n            'subsample': 0.9, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n            print('min_child_weight: {} | eta: {} | max-depth: {}.'.format(w, l, d))\n\n            model = xgb.train(xgb_pars, dtrain, 50, watchlist, early_stopping_rounds=10,\n                  maximize=False, verbose_eval=1)\n  \"\"\"","1af88e4d":"nrounds = 200\nparams = {'min_child_weight': 20, 'eta': 0.3, 'colsample_bytree': 0.9, \n            'max_depth': 6,\n            'subsample': 0.9, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}\nmodel = xgb.train(params, dtrain, nrounds, watchlist, early_stopping_rounds=2,\n      maximize=False, verbose_eval=1)\nprint('Modeling RMSLE %.5f' % model.best_score)\n","c1ac6069":"xgb.plot_importance(model, max_num_features=14, height=.5)","2971781e":"#n_folds = 5\n#early_stopping = 10\n#cv = xgb.cv(params, dtrain, 500, nfold=n_folds, early_stopping_rounds=early_stopping, verbose_eval=1)\n","0584cca6":"pred = np.exp(model.predict(dtest)) - 1","2331d289":"df_pred = pd.DataFrame({'id': predict_ids, 'trip_duration': pred})\n# Locally : df_pred = pd.DataFrame({'id': predict_ids[:20000], 'trip_duration': pred}) \ndf_pred = df_pred.set_index('id')\ndf_pred.to_csv('submission.csv', index = True)\n","559903fb":"#### Geo points vizualisation","e915ad9a":"#### Training","6f8f6213":"#### K means cross validation","bc42acb4":"### pickups and dropoffs geopoint features","db7cb2ec":"## Modeling","0700a6d9":"#### NYC Roadmap","85ff25bb":"# New York City Taxi Trip Duration (2016)","c12e9c16":"#### Features weight","9a0e0d95":"### train test split","3322bfbf":"### store_and_fwd_flag feature","4fb09562":"## Data analysis","9bc38a2f":"##  Data loading and overview","c0d175bf":"### vendor_id feature","4f7d9477":"### XGBoost","1aa61b98":"### trip_duration feature","2e2c3132":"## Date related feature extract","77a5738a":"We do not have null or nan values throughout the dataset.\nAs expected, \"dropoff_datetime\" and \"trip_duration\" columns are missing from test train.","0f7b6cfc":"### pickup and dropoff date features","c2b7e8bb":"### ids to predict extract","12009881":"#### Tuning parameters","a210e4bb":"#### Predict ","3c3e3ed8":"### store_and_fwd_flag labeling ","2523f536":"### passenger_count feature"}}