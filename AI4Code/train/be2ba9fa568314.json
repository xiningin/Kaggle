{"cell_type":{"ea992384":"code","474cb2b4":"code","369ad35b":"code","8f52a006":"code","83b8474f":"code","f721897a":"code","5550a8da":"code","d1b51532":"code","74eee441":"code","110add66":"code","5b43c4a7":"code","fe6b52fa":"markdown","d080a07f":"markdown","4e101834":"markdown","cbeb2dbe":"markdown","8a609f3c":"markdown","6c864f31":"markdown","2006db5c":"markdown","28274b30":"markdown","3adb3828":"markdown"},"source":{"ea992384":"# Import necessary libraries\nimport os\nimport pathlib\nfrom time import time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (Dense, Conv2D, Flatten, Dropout,\n                                     MaxPooling2D, Activation, BatchNormalization)\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nprint('TensorFlow Version: ', tf.__version__)\nprint('GPU Available: ', tf.test.is_gpu_available())\nprint('Using GPU: ', tf.config.experimental.list_physical_devices('GPU'))","474cb2b4":"PATH = '..\/input\/train-val-test-tcga-coad-msi-mss\/tcga_coad_msi_mss\/'\ntrain_dir = os.path.join(PATH, 'train')\nval_dir = os.path.join(PATH, 'val')\ntest_dir = os.path.join(PATH, 'test')\n\ntrain_msimut_dir = os.path.join(train_dir, 'MSIMUT')\ntrain_mss_dir = os.path.join(train_dir, 'MSS')\nval_msimut_dir = os.path.join(val_dir, 'MSIMUT')\nval_mss_dir = os.path.join(val_dir, 'MSS')\ntest_msimut_dir = os.path.join(test_dir, 'MSIMUT')\ntest_mss_dir = os.path.join(test_dir, 'MSS')","369ad35b":"# Check how many images are in each directory\nnum_msimut_train, num_mss_train = len(os.listdir(train_msimut_dir)), len(os.listdir(train_mss_dir))\n\nnum_msimut_val, num_mss_val = len(os.listdir(val_msimut_dir)), len(os.listdir(val_mss_dir))\n\nnum_msimut_test, num_mss_test = len(os.listdir(test_msimut_dir)), len(os.listdir(test_mss_dir))\n\ntotal_train = num_msimut_train + num_mss_train\ntotal_val = num_msimut_val + num_mss_val\ntotal_test = num_msimut_test + num_mss_test\n\nprint('Total training MSIMUT images: ', num_msimut_train)\nprint('Total training MSS images: ', num_mss_train)\nprint('Total validation MSIMUT images: ', num_msimut_val)\nprint('Total validation MSS images: ', num_mss_val)\nprint('Total testing MSIMUT images: ', num_msimut_test)\nprint('Total testing MSS images: ', num_mss_test)\nprint('---------------------------------')\nprint('Total training images: ', total_train)\nprint('Total validation images: ', total_val)\nprint('Total testing images: ', total_test)","8f52a006":"# Set up variables for pre-processing\nbatch_size = 64\nepochs = 5\nIMG_HEIGHT = 224\nIMG_WIDTH = 224","83b8474f":"# Visualize some images\ntrain_root = pathlib.Path(train_dir)\nclass_names = sorted([j.name.split('\/')[-1] for j in train_root.iterdir()])\nclass_names = np.array(class_names)\nprint('Class names: ', class_names)\n\nimg_gen = ImageDataGenerator(rescale = 1.\/255)\nsample_train_data_gen = img_gen.flow_from_directory(batch_size = batch_size,\n                                                    directory = train_dir,\n                                                    shuffle = True,\n                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\n                                                    classes = list(class_names))\n                                                 \nsample_images, sample_labels = next(sample_train_data_gen)\n\ndef show_batch(img_batch, label_batch):\n    plt.figure(figsize = (10, 10))\n    for i in range(25):\n        ax = plt.subplot(5, 5, i + 1)\n        plt.imshow(sample_images[i])\n        plt.title(class_names[sample_labels[i] == 1][0])\n        plt.axis('off')\n        \nshow_batch(sample_images, sample_labels)","f721897a":"train_image_generator = ImageDataGenerator(rescale = 1.\/255,\n                                           rotation_range = 45,\n                                           width_shift_range = 0.20,\n                                           height_shift_range = 0.20,\n                                           horizontal_flip = True,\n                                           zoom_range = 0.5)\n\nval_image_generator = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_data_gen = train_image_generator.flow_from_directory(batch_size = batch_size,\n                                                           directory = train_dir,\n                                                           shuffle = True,\n                                                           target_size = (IMG_HEIGHT, IMG_WIDTH),\n                                                           class_mode = 'binary')\n\nval_data_gen = val_image_generator.flow_from_directory(batch_size = batch_size,\n                                                       directory = val_dir,\n                                                       target_size = (IMG_HEIGHT, IMG_WIDTH),\n                                                       class_mode = 'binary')","5550a8da":"# Create CNN\nmodel = Sequential([\n    # Conv layer 1\/Input layer\n    Conv2D(64, kernel_size = (5, 5),padding = 'same', activation = 'relu', \n           input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)),\n    BatchNormalization(),\n    MaxPooling2D(pool_size = (2, 2)),\n    Dropout(0.25),\n    \n    # Conv layer 2\n    Conv2D(64, kernel_size = (5, 5), padding = 'same', activation = 'relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size = (2, 2)),\n    Dropout(0.25),\n\n    # Conv layer 3\n    Conv2D(128, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n    Dropout(0.25),\n    \n    # Conv layer 4\n    Conv2D(128, kernel_size = (3, 3), padding = 'same', activation = 'relu'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size = (2, 2), strides = (2, 2)),\n    Dropout(0.25),\n\n    # Fully connected layer 1\n    Flatten(),\n    Dense(256, activation = 'relu'),\n    BatchNormalization(),\n    Dropout(0.25),\n    \n    # Fully connected last layer\n    Dense(1, activation = 'sigmoid')\n])\n\n# Standard metrics for binary classification \nmetrics = [\n    tf.keras.metrics.TruePositives(name = 'tp'),\n    tf.keras.metrics.FalsePositives(name = 'fp'),\n    tf.keras.metrics.TrueNegatives(name = 'tn'),\n    tf.keras.metrics.BinaryAccuracy(name = 'accuracy'),\n    tf.keras.metrics.Precision(name = 'precision'),\n    tf.keras.metrics.Recall(name = 'recall'),\n    tf.keras.metrics.AUC(name = 'auc')\n]\n\ninitial_lr = 0.1\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_lr,\n    decay_steps = 100000,\n    decay_rate = 0.96,\n    staircase = True\n)\n\nmodel.compile(optimizer = tf.keras.optimizers.SGD(learning_rate = lr_schedule,\n                                                  momentum = 0.9,\n                                                  nesterov = True),\n              loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n              metrics = metrics)\n\nmodel.summary()","d1b51532":"print('Starting training...')\nprint('====================\\n')\n\nstart = time()\n\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor = 'val_loss',\n        min_delta = 1e-2,\n        patience = 2,\n        verbose = 1\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        filepath = '..\/output\/cnn.ckpt',\n        save_best_only = True,\n        monitor = 'val_loss',\n        verbose = 0\n    )\n]\n\nhistory = model.fit(train_data_gen,\n                    steps_per_epoch = total_train \/\/ batch_size,\n                    epochs = epochs,\n                    validation_data = val_data_gen,\n                    validation_steps = total_val \/\/ batch_size,\n                    callbacks = callbacks)\n\nend = time()\n\ntime_elapsed = end - start\n\nprint('\\nTraining took {:.0f}h {:.0f}m {:.0f}s.'.format(time_elapsed\/\/(60*60),\n                                                        time_elapsed\/\/60, \n                                                        time_elapsed % 60))","74eee441":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(5)\n\nplt.figure(figsize = (8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(epochs_range, acc, label = 'Training Accuracy')\nplt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\nplt.legend(loc = 'lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(epochs_range, loss, label = 'Training Loss')\nplt.plot(epochs_range, val_loss, label = 'Validation Loss')\nplt.legend(loc = 'upper right')\nplt.title('Training and Validation Loss')\nplt.show()","110add66":"test_image_generator = ImageDataGenerator(rescale = 1.\/255)\ntest_data_gen = test_image_generator.flow_from_directory(batch_size = batch_size,\n                                                         directory = test_dir,\n                                                         shuffle = False,\n                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\n                                                         class_mode = 'binary')\n\nresult = model.evaluate(test_data_gen)\nprint('Test Loss: ', result[0])\nprint('Test Accuracy: ', result[4])\nprint('Test AUC: ', result[7])","5b43c4a7":"test_image, test_label = next(test_data_gen)\n\npredicted_batch = model.predict(test_image)\npredicted_id = np.argmax(predicted_batch, axis = -1)\npredicted_label_batch = class_names[predicted_id]\n\nplt.figure(figsize = (10, 10))\nplt.subplots_adjust(hspace = 0.5)\nfor n in range(30):\n    plt.subplot(6, 5, n + 1)\n    plt.imshow(test_image[n])\n    color = \"blue\" if predicted_id[n] == test_label[n] else \"red\"\n    plt.title(predicted_label_batch[n], color = color)\n    plt.axis('off')\n_ = plt.suptitle(\"CNN Predictions (blue: correct, red: incorrect)\")","fe6b52fa":"### Evaluation","d080a07f":"### Thoughts","4e101834":"### Visualize Loss and Accuracy","cbeb2dbe":"### Data Augmentation","8a609f3c":"Interesting.....\n\nI don't believe that's right...","6c864f31":"My CNN's performance on the unseen test data set is not ideal. An accuracy of 46% and an AUC of 0.57 is poor.\n\nTo improve performance:\n- Train longer with more epochs on more GPU's \n    - This is a very large dataset with hundreds of thousands of histopathology images of size 224x224, so training on a single GPU is very slow.\n    - Distributed\/Parallel training would be faster\n- Designing a CNN from scratch requires an even bigger dataset and more resources, so Transfer Learning is more appropriate.\n    - I will apply transfer learning (DenseNet) in another notebook to compare performance. \n- Try the Adam or RMSProp optimizer\n- Loading the images into a `tf.data.Dataset` or `TFRecords` format would be more efficient","2006db5c":"### Convolutional Neural Network","28274b30":"### Load data","3adb3828":"### Model Training"}}