{"cell_type":{"93ada147":"code","8d534922":"code","f30cf4e9":"code","03bd26ee":"code","45580303":"code","9c5edcfd":"code","e28f8439":"code","d2c7f021":"code","fff35d8f":"code","6b67621a":"code","a0debf7e":"markdown","42941eae":"markdown","f84d9dad":"markdown","b01173b5":"markdown","e5380b09":"markdown"},"source":{"93ada147":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport csv\nimport re\nfrom tqdm.notebook import tqdm\nimport nltk # Natural Language Toolkit\n\n\n# Optional packages:\n# import pandas_profiling\n# import fuzzywuzzy\n# import requests\n# from bs4 import BeautifulSoup\n# from datetime import datetime as dt","8d534922":"# Raouf\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage before optimization is {:.2f} MB'.format(start_mem))\n    print('-' * 45)\n\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('-' * 45)\n\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n\n\ndef import_data(csv,index):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(csv,low_memory=False,index_col=index)\n    df = reduce_mem_usage(df)\n    return df\n\ndef rename_cols(df):\n    \"\"\"rename columns of a DF\"\"\"\n\n    df.columns = df.columns.str.replace(' ', '_') \n    df.columns = df.columns.str.lower()    \n    return df.columns\n\ndef convert_col_int8(df):\n    \"\"\"conert cols to int8\"\"\"\n\n    temp_df = pd.DataFrame()\n    for column in df.columns:\n        temp_df[column] = df[column].astype(\"int8\")\n\n    return temp_df\n\ndef gender_features(word): \n    return {'last_letter':word[-1]} \n  \n\n\n  \n","f30cf4e9":"# Raouf\ndf = import_data(\"..\/input\/metobjects\/MetObjects.csv\",4)","03bd26ee":"df.sample(10)","45580303":"df.info()","9c5edcfd":"# Raouf\ndf.columns = rename_cols(df)\ndf.columns","e28f8439":"df = df[pd.notnull(df['artist_display_bio'])]","d2c7f021":"nat_file = \"..\/input\/nationalitylistcsv\/CH_Nationality_List_20171130_v1.csv\"\ndf_nationalities = pd.read_csv(nat_file)\ndf_nationalities.head()\nnats = df_nationalities.values.tolist()\nlen(nats)\ndf['artist_nationality_new'] = \"\"\nfor index,row in tqdm(df[df.notnull()].iterrows()):\n    for ind,nat in df_nationalities.iterrows():\n        if str(df_nationalities.iloc[ind,0]) in str(row[18]):\n            df.loc[index,'artist_nationality_new'] = df_nationalities.iloc[ind,0]","fff35d8f":"mlname_df = pd.read_csv(\"..\/input\/males-females\/males.csv\")\nfname_df = pd.read_csv(\"..\/input\/males-females\/females.csv\")\n# preparing a list of examples and corresponding class labels\nlabeled_names = ([(name, 'male') for name in mlname_df[\"name\"]]+ [(name, 'female') for name in fname_df[\"name\"]]) \n# we use the feature extractor to process the names data \nfeaturesets = [(gender_features(name), gender)  for (name, gender)in labeled_names] \n# divide into a training set and a test set \ntrain_set, test_set = featuresets[1500:], featuresets[:1500] \n# train a new \"naive Bayes\" classifier \nclassifier = nltk.NaiveBayesClassifier.train(train_set) \n\n  \n\n  \n\ndf[\"artist_gender\"] = df[\"artist_gender\"].str.lower()\ndf[\"artist_gender\"] = df[\"artist_gender\"].str.replace(\"|\",\"\")\n\nfor index, row in tqdm(df.iterrows()):\n        if str(row[24]).find(\"female\") != -1:\n            df.loc[index,\"artist_gender\"] = \"female\"\n        elif str(row[24])== '':\n            df.loc[index,\"artist_gender\"] = classifier.classify(gender_features((str(df.loc[350,\"artist_display_name\"]).split(maxsplit=1)[0])))","6b67621a":"df.to_csv(\"new_dataset.csv\")","a0debf7e":"## Step 1: Pick a dataset\nPreliminary pick: The Database of The Metropolitan Museum of Art Open Access with the file \"MetObjects.csv\"\n____________","42941eae":"## Step 2: Load the database to Python using an appropriate library (pandas, sqllite3, etc.)\nSince we are handling a csv-file we will import via csv-package\n____________","f84d9dad":"<a id='top'><\/a>\n\n# M3-W5 Project: Make your Data shine!\n--------\n##  Assignment Steps:\n\nStep 1: In this module project your task is to pick a dataset from the link below <br>\nStep 2: Load it to Python using an appropriate library (pandas, sqllite3, etc.) <br>\nStep 3: Understand the issues (take a look at the issues section for each dataset on the given URL)  <br>\nStep 4: Clean the data (take care of outliers, missing values, data types, etc.) and provide explanations for all steps you took while cleaning the data  <br>\nStep 5: Explore and visualize your data <br>\n\n\nOverarching: Submit your work as a Jupyter Notebook with all the code and narrative. \n\nNote: [Summary](#sum)\n__________","b01173b5":"# [*Column Cleaning Notes*](#cleaning)[](http:\/\/)\n<a id='top'><\/a>","e5380b09":"**Issues: Missing values, inconsistent information, missing documentation, possible duplication, mixed text and numeric data.**"}}