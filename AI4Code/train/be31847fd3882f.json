{"cell_type":{"55e55af8":"code","3f066a14":"code","f0f41c60":"code","bfa7ed9b":"code","88f3151e":"code","dd805a58":"code","5c812a83":"code","d1b2f724":"code","f6377e36":"markdown","586d3b67":"markdown","3274b350":"markdown","54732486":"markdown","3a21a3d1":"markdown","6a56d15d":"markdown","7626ecb1":"markdown","bc7d2ca4":"markdown","016e7d4d":"markdown","5859849f":"markdown"},"source":{"55e55af8":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport sklearn.preprocessing as preprocessing\nimport sklearn.model_selection as model_selection\nimport matplotlib.pyplot as plt","3f066a14":"races_df = pd.read_csv(r\"..\/input\/hkracing\/races.csv\", delimiter=\",\", header=0, index_col='race_id')\nraces_df = races_df[['venue', 'config', 'surface', 'distance', 'going', 'race_class']]\n\n# check to see if we have NaN, then drop NaN\nprint(races_df[races_df.isnull().any(axis=1)])\nraces_df = races_df.dropna()\n\n# encode ordinal columns: config, going, \nconfig_encoder = preprocessing.OrdinalEncoder()\nraces_df['config'] = config_encoder.fit_transform(races_df['config'].values.reshape(-1, 1))\ngoing_encoder = preprocessing.OrdinalEncoder()\nraces_df['going'] = going_encoder.fit_transform(races_df['going'].values.reshape(-1, 1))\n\n# encode nominal column: venue\nvenue_encoder = preprocessing.LabelEncoder()\nraces_df['venue'] = venue_encoder.fit_transform(races_df['venue'])\n\nprint(races_df.dtypes)\nprint(races_df.shape)\nprint(races_df.head())","f0f41c60":"runs_df = pd.read_csv(r\"..\/input\/hkracing\/runs.csv\", delimiter=\",\", header=0)\nruns_df = runs_df[['race_id', 'draw', \n                   'horse_age', 'horse_country', 'horse_type', 'horse_rating', 'declared_weight', 'actual_weight', 'win_odds', \n                   'result']] \n\n# check to see if we have NaN, then drop NaN\nprint(runs_df[runs_df.isnull().any(axis=1)])\nruns_df = runs_df.dropna()\n\n# not sure why, but we got some strange draw in the dataset. Maximum shall be 14\nstrange_draw_index = runs_df[runs_df['draw'] > 14].index\n# delete these row indexes from dataFrame\nruns_df = runs_df.drop(strange_draw_index)\n\n# encode nominal columns: horse_country, horse_type\nhorse_country_encoder = preprocessing.LabelEncoder()\nruns_df['horse_country'] = horse_country_encoder.fit_transform(runs_df['horse_country'])\nhorse_type_encoder = preprocessing.LabelEncoder()\nruns_df['horse_type'] = horse_type_encoder.fit_transform(runs_df['horse_type'])\n\nprint(runs_df.dtypes)\nprint(runs_df.shape)\nprint(runs_df.head())","bfa7ed9b":"def group_horse_and_result(element):\n    if element[0] == 'result':\n        return 100 + element[1] # to make sure results are put near the end\n    else:\n        return element[1]   \n\nruns_df = runs_df.pivot(index='race_id', columns='draw', values=runs_df.columns[2:])\nrearranged_columns = sorted(list(runs_df.columns.values), key=group_horse_and_result)\nruns_df = runs_df[rearranged_columns]\nprint(runs_df.head())\n\n# quite some NaNs appreared in the dataframe, reason is some races didnt have full 14 horses participating\n# fill with 0\nruns_df = runs_df.fillna(0)","88f3151e":"data = races_df.join(runs_df, on='race_id', how='right')\nX = data[data.columns[:-14]] \nss = preprocessing.StandardScaler()\nX = pd.DataFrame(ss.fit_transform(X),columns = X.columns)\n\ny_won = data[data.columns[-14:]].applymap(lambda x: 1.0 if 0.5 < x < 1.5 else 0.0) \n\nprint(X.shape)\nprint(y_won.shape)\n\n# split data into train and test sets\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_won, train_size=0.8, test_size=0.2, random_state=1)\nprint('X_train', X_train.shape)\nprint('y_train', y_train.shape)\nprint('X_test', X_test.shape)\nprint('y_test', y_test.shape)","dd805a58":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(96, activation='relu', input_shape=(104,)),\n    tf.keras.layers.Dense(14, activation='softmax')\n])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(5e-04),\n              loss=tf.keras.losses.CategoricalCrossentropy(),\n              metrics=[tf.keras.metrics.Precision(name='precision')])","5c812a83":"dataset = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\ntrain_dataset = dataset.shuffle(len(X_train)).batch(500)\ndataset = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))\nvalidation_dataset = dataset.shuffle(len(X_test)).batch(500)\n\nprint(\"Start training..\\n\")\nhistory = model.fit(train_dataset, epochs=200, validation_data=validation_dataset)\nprint(\"Done.\")","d1b2f724":"precision = history.history['precision']\nval_precision = history.history['val_precision']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(precision) + 1)\n\nplt.plot(epochs, precision, 'b', label='Training precision')\nplt.plot(epochs, val_precision, 'r', label='Validation precision')\nplt.title('Training and validation precision')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","f6377e36":"## Prepare races data from races.csv\nOnly select several columns that make sense for this kernel. Then, use different encoders for different types of attribute.","586d3b67":"## Plot the result\n","3274b350":"## Prepare training\/test data \nHere, we combine races data and runs data by `join` two data frames above. \n\n### Standardization\nIf you look at the data closely, if will find that features are not in the same scale, e.g. weight can go to 1000+. Standardize the data for to make training easier. \n\n### Select right columns for X, y\n- Select all the data except last 28 columns, because last 28 columns is about 'result' and 'won'\n- Select last 14 columns for y_won. Each row shall have one '1.0' and rest are 0. \n- Select second last 14 columns for y_top3. It used to the the column 'result', e.g. 1~14, which is horses' final positions when the race finishes. Apply a function to convert it to 1.0 if the horse is in top 3, else 0. \n\n### Split data into train\/test sets\n\nsklearn comes with such a handy method `train_test_split`. We split the data as following:\n- 80% for training\n- 20% for testing(validation)\n","54732486":"## Further preprocessing for runs data\nWe are targeting to put all the 14 horses' features into the one input, but it expands into multiple rows now. Luckily, pandas has a nice method called `pivot`. `pivot` aggregates horses data from multiple rows, which belongs to a single race, into one row. \n\nAfter `pivot`, some races may not have 14 horses, so let's fill NaN with 0.","3a21a3d1":"## Train the model","6a56d15d":"## Build the model\n\nUse keras to build the model with easy-to-use api `Sequential`. \n\nHave to mention that input layer has 104 inputs. The calculation is following:\n- 6 features from races dataframe: 'venue', 'config', 'surface', 'distance', 'going', 'race_class'\n- 14 horses per races, and each horse has 7 features; 'horse_age', 'horse_country', 'horse_type', 'horse_rating', 'declared_weight', 'actual_weight', 'win_odds'\n- so total 104 features = 6 + 14 x 7\n\n\nOutput layer has 14 nodes, as each node stands for each horse's result.","7626ecb1":"## Import packages\nHere, we import common packages for deep learning. \n- pandas: for data reading and preprocessing\n- tensorflow: for neural network construction \n- sklearn.preprocessing: for data encoding\n- sklearn.model_selection: it has convenient method for training\/test data spliting \n- matplotlib.pyplot: to plot performance of the training process.","bc7d2ca4":"## Conclusion\n\nWith the 2 layer nerual network, we reached 0.92 precision on the the training dataset. However, best precision on the testing dataset was about 0.3, which happened around epoch 70~80. Then overfitting happened. \n\nprecision = 0.3, means If we bet 'Win' 10 times based on the model's prediction, only 3 times is correct.  ","016e7d4d":"This is an improved kernel on [previous one](https:\/\/www.kaggle.com\/cullensun\/deep-learning-model-for-horse-racing). In previous kernel, I tried to predict on every single horse run. However, I found it makes more sense to predict winner horse for every race because winning is **relative** to other horses performance. ","5859849f":"## Prepare races data from runs.csv\nSimilar to races data, only select columns that are relevant to the model. \n\n### Data cleaning\n- two rows that includes NaN, so just drop them.\n- strange data for 'draw', e.g. 15. As we only deal with standard 14 horses racing, so let's drop it.\n\n### Encoding \nThen, use label encoders for 'horse_country' and 'horse_type'."}}