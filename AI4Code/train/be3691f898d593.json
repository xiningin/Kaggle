{"cell_type":{"3aeb8114":"code","b045bcef":"code","ecc288cc":"code","d227c961":"code","3fdeeceb":"code","7284e2d6":"code","553b34bd":"code","306fe12f":"code","f467274d":"code","ad657861":"code","d8d72bc9":"code","8f0861dc":"code","4e6c4b65":"code","c0d652ed":"code","1e9adc41":"code","7762de31":"code","039f99dc":"code","95e61f54":"code","62e7dd03":"code","2d04ce09":"markdown"},"source":{"3aeb8114":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D\n\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n\nfrom tensorflow.keras.applications.vgg16 import VGG16,preprocess_input,decode_predictions\n\nfrom tensorflow.keras.preprocessing.image import load_img,img_to_array","b045bcef":"BATCH_SIZE = 32\nEPOCH = 50","ecc288cc":"(X_train_raw, y_train), (X_test_raw, y_test) = tf.keras.datasets.cifar10.load_data() ","d227c961":"print('Example of image in array',X_train_raw[0,::])","3fdeeceb":"print('Data shape : ',X_train_raw.shape)","7284e2d6":"print('Number of trainning set : ',X_train_raw.shape[0])\nprint('Number of testing set : ',X_test_raw.shape[0])","553b34bd":"class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']","306fe12f":"X_train_raw = X_train_raw.astype('float32')\nX_test_raw = X_test_raw.astype('float32')\n\n\nX_train_raw \/= 255\nX_test_raw \/= 255\n\ny_train_cat = tf.keras.utils.to_categorical(y_train, len(class_names))\ny_test_cat = tf.keras.utils.to_categorical(y_test, len(class_names))","f467274d":"y_train_cat[0]","ad657861":"def random_display(isTrain = True):\n    fig = plt.figure(figsize=(10,5))\n\n    for i in range(len(class_names)):\n        ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n        if isTrain:\n            idx = np.where(y_train[:]==i)[0]\n            features_idx = X_train_raw[idx,::]\n        else:\n            idx = np.where(y_test[:]==i)[0]\n            features_idx = X_test_raw[idx,::]            \n        im = (features_idx[0,::])\n        ax.set_title(class_names[i])\n        plt.imshow(im)\n    plt.show()\nrandom_display(True)","d8d72bc9":"model = Sequential()\nmodel.add(Conv2D(64, (3, 3),input_shape=(32,32,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(len(class_names)))\nmodel.add(Activation('softmax'))","8f0861dc":"model.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train_raw, y_train_cat,\n              batch_size=BATCH_SIZE,\n              epochs=EPOCH,\n              validation_data=(X_test_raw, y_test_cat),\n              shuffle=True)","4e6c4b65":"plt.figure(figsize=[20,8])\n\n\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy', size=25, pad=20)\nplt.ylabel('Accuracy', size=15)\nplt.xlabel('Epoch', size=15)\nplt.legend(['train', 'test'], loc='upper left')\n\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss', size=25, pad=20)\nplt.ylabel('Loss', size=15)\nplt.xlabel('Epoch', size=15)\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","c0d652ed":"predictions = model.predict(X_test_raw)\n\nrandom_display(False)","1e9adc41":"tf.math.confusion_matrix(y_test, np.argmax(predictions, axis=-1))","7762de31":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, np.argmax(predictions, axis=-1), target_names=class_names))","039f99dc":"model = Sequential()\nmodel.add(Conv2D(64, (3, 3),input_shape=(32,32,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(4, 4)))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(len(class_names)))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train_raw, y_train_cat,\n              batch_size=BATCH_SIZE,\n              epochs=EPOCH,\n              validation_data=(X_test_raw, y_test_cat),\n              shuffle=True)\n\nplt.figure(figsize=[20,8])\n\n\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Epoch VS Model Accuracy', size=25, pad=20)\nplt.ylabel('Accuracy', size=15)\nplt.xlabel('Epoch', size=15)\nplt.legend(['train', 'test'], loc='upper left')\n\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Epoch VS Model Loss', size=25, pad=20)\nplt.ylabel('Loss', size=15)\nplt.xlabel('Epoch', size=15)\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\npredictions = model.predict(X_test_raw)\n\nrandom_display(False)\n\ntf.math.confusion_matrix(y_test, np.argmax(predictions, axis=-1))\nprint(classification_report(y_test, np.argmax(predictions, axis=-1), target_names=class_names))","95e61f54":"model = Sequential()\n\nvgg_layer = VGG16(input_shape=(32,32,3),include_top=False,weights='imagenet')\nvgg_layer.trainable = False\nmodel.add(vgg_layer)\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(len(class_names),activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n\nhistory = model.fit(X_train_raw,y_train_cat,\n              batch_size=BATCH_SIZE,\n              epochs=EPOCH,\n              validation_data=(X_test_raw, y_test_cat),\n              shuffle=True)\nplt.figure(figsize=[20,8])\n\n\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Epoch VS Model Accuracy', size=25, pad=20)\nplt.ylabel('Accuracy', size=15)\nplt.xlabel('Epoch', size=15)\nplt.legend(['train', 'test'], loc='upper left')\n\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Epoch VS Model Loss', size=25, pad=20)\nplt.ylabel('Loss', size=15)\nplt.xlabel('Epoch', size=15)\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\npredictions = model.predict(X_test_raw)\n\nrandom_display(False)\n\ntf.math.confusion_matrix(y_test, np.argmax(predictions, axis=-1))\nprint(classification_report(y_test, np.argmax(predictions, axis=-1), target_names=class_names))","62e7dd03":"rabbit_image = load_img('..\/input\/cat-vs-rabbit\/train-cat-rabbit\/rabbit\/rabbit.1.jpg', target_size=(224, 224))\n\nplt.imshow(rabbit_image)\n\nrabbit_image_arr = img_to_array(rabbit_image)\n\nrabbit_image_arr = rabbit_image_arr.reshape((1, rabbit_image_arr.shape[0], rabbit_image_arr.shape[1], rabbit_image_arr.shape[2]))\n\nrabbit_image_arr = preprocess_input(rabbit_image_arr)\n\nmodel = VGG16(include_top=True,weights='imagenet')\n\nprediction = model.predict(rabbit_image_arr)\n\nlabel = decode_predictions(prediction)\n\nlabel = label[0][0]\n\nprint('%s (%.2f%%)' % (label[1], label[2]*100))","2d04ce09":"Unpickle data and load data"}}