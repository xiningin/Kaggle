{"cell_type":{"942fb379":"code","0dc4b46a":"code","311419d1":"code","812a99a4":"code","197aedee":"code","bdfdfc6e":"code","877f9719":"code","9ddafca0":"code","6d1c5c35":"code","2cc2fb34":"code","f453d3e7":"code","854c706d":"code","e3d19696":"markdown","787561ee":"markdown","e3c68378":"markdown","010f01a2":"markdown","8da2659a":"markdown","4ec30b71":"markdown","ea078c42":"markdown","35826ebc":"markdown","46b7992d":"markdown","a860d253":"markdown","783135ac":"markdown","a2ea694c":"markdown","6adb632d":"markdown"},"source":{"942fb379":"#!pip install joypy\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n#from joypy import joyplot for matplotlib\nimport tensorflow as tf\nimport tqdm\nimport optuna\nimport time\nimport lightgbm as lgb\nfrom sklearn import metrics\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize, StandardScaler\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\n%matplotlib inline","0dc4b46a":"path = '..\/input\/ventilator-pressure-prediction'\ntrain = pd.read_csv(f\"{path}\/train.csv\")\ntest = pd.read_csv(f\"{path}\/test.csv\")","311419d1":"time_step_diff_limit = 0.04\nnon_liner_timestep_breath_ids = list()\nfor k, grp in train.groupby(\"breath_id\"):\n    diff_se = grp[\"time_step\"].diff()\n    diff_chk = diff_se[diff_se > time_step_diff_limit]\n    if len(diff_chk) != 0:\n        non_liner_timestep_breath_ids.append(k)\n\n#print(non_liner_timestep_breath_ids)\n## results are following:\n## [803, 2327, 3178, 4199, 5830, 10277, 11502, 13238, 15803, 16315, 16634, 18117, 18600, 24127, 25397, 28189, 28942, 30181, 32296, 36128, 36175, 37711, 38237, 38415, 39045, 39722, 42317, 42988, 43344, 44245, 45197, 46324, 49849, 53877, 54129, 55244, 55851, 61454, 64662, 67422, 67748, 72104, 74766, 76037, 78768, 79105, 80375, 87127, 87776, 89084, 91883, 93186, 98677, 102063, 104001, 106034, 107067, 109693, 111439, 112027, 115588, 119689, 120878, 121135, 125136]","812a99a4":"non_liner_timestep_df = train[train[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\nfig = go.Figure()\nfor k,grp in non_liner_timestep_df.groupby(\"breath_id\"):\n    grp = grp.reset_index(drop=True)\n    fig.add_trace(go.Scatter(x=grp.index, y=grp[\"time_step\"], mode='lines', name=k))\nfig.show()","197aedee":"liner_timestep_df = train[~train[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\nfig = go.Figure()\nfor k,grp in liner_timestep_df[:80*10000].groupby(\"breath_id\"):\n    grp = grp.reset_index(drop=True)\n    fig.add_trace(go.Scatter(x=grp.index, y=grp[\"time_step\"], mode='lines', name=k))\nfig.show()","bdfdfc6e":"def data_clean(df):\n    ## drop non liner time_step data.\n    time_step_diff_limit = 0.04\n    non_liner_timestep_breath_ids = list()\n    for k, grp in df.groupby(\"breath_id\"):\n        diff_se = grp[\"time_step\"].diff()\n        diff_chk = diff_se[diff_se > time_step_diff_limit]\n        if len(diff_chk) != 0:\n            non_liner_timestep_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(non_liner_timestep_breath_ids)]\n    \n    ## drop minus pressure data.\n    minus_pressure_breath_ids = list()\n    for k, grp in df.groupby(\"breath_id\"):\n        m = grp[\"pressure\"].min()\n        if m < 0:\n            minus_pressure_breath_ids.append(k)\n    df = df[~df[\"breath_id\"].isin(minus_pressure_breath_ids)]   \n    \n    return df\n\ndef change_type(df):\n    df = df.merge(pd.get_dummies(df['R'], prefix='R'), left_index=True, right_index=True).drop(['R'], axis=1)\n    df = df.merge(pd.get_dummies(df['C'], prefix='C'), left_index=True, right_index=True).drop(['C'], axis=1)\n\n    return df\n\ndef add_features(df):\n    df['u_in_cumsum'] = df.groupby('breath_id')['u_in'].cumsum()\n    df['u_in_lag1']   = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1']  = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag2']   = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2']  = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_diff1']  = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2']  = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    return df","877f9719":"path = '..\/input\/ventilator-pressure-prediction'\ntrain = pd.read_csv(f\"{path}\/train.csv\")\ntest = pd.read_csv(f\"{path}\/test.csv\")\nsubmission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\n\ndebug_mode = True","9ddafca0":"if debug_mode:\n    train = train[:80*1000]","6d1c5c35":"train = data_clean(train)\ntrain = add_features(train)\ntrain = change_type(train)\n\ntest = add_features(test)\ntest = change_type(test)","2cc2fb34":"y = train[['pressure']]\nX = train.drop(['pressure', 'id', 'breath_id'], axis=1)\ntest_X = test.drop(['id', 'breath_id'], axis=1)","f453d3e7":"scores = []\nmodels = []\nfeature_importance = pd.DataFrame()\nparams = {'objective': 'regression',\n          'learning_rate': 0.10,\n          \"boosting_type\": \"gbdt\",\n          'min_data_in_leaf':600,\n          'max_bin': 196,\n          #'device':'gpu',\n          'feature_fraction':0.4,\n          'lambda_l1':36, 'lambda_l2':80,\n          'max_depth':16,\n          'num_leaves':1000,\n          \"metric\": 'mae',\n          'n_jobs': -1\n         }\n\nfolds = GroupKFold(n_splits=5)\n\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(train, y, groups=train['breath_id'])):\n    print(f'Fold {fold_n} started at {time.ctime()}')\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    model = lgb.LGBMRegressor(**params, n_estimators=8000)\n    model.fit(X_train, y_train, \n            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n            verbose=100, early_stopping_rounds=10)\n    score = metrics.mean_absolute_error(y_valid, model.predict(X_valid))\n    \n    models.append(model)\n    scores.append(score)\n\n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] = X.columns.tolist()\n    fold_importance[\"importance\"] = model.feature_importances_\n    fold_importance[\"fold\"] = fold_n + 1\n    feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n    \nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))","854c706d":"for model in models:\n    submission['pressure'] += model.predict(test_X)\nsubmission['pressure'] \/= 5\n\nsubmission.to_csv('submission.csv', index=False)","e3d19696":"# Visualize liner \"time_step\"\n\nThere are several gradient of \"time_step\",,,.","787561ee":"# Visualize NON linier \"time_step\"","e3c68378":"# Prepare data for LGBM","010f01a2":"# In Debug mode\n\nreduce data size","8da2659a":"# Read data again and set config\n","4ec30b71":"# Read Data","ea078c42":"<br>\n<br>\n\n# END Visualize\n\n<br>\n<br>","35826ebc":"# Utilitys","46b7992d":"# glossary\n\n### LGBMRegressor\nLGBM for regression<br>\n\nhttps:\/\/lightgbm.readthedocs.io\/en\/latest\/pythonapi\/lightgbm.LGBMRegressor.html\n\n### LGBMClassifier\nLGBM for Classifier\n","a860d253":"# apply utilitys for data","783135ac":"# Note\n\nThis Notebook specializes in finding hints to get better score with using simple data, strategy and visualize.\n\n## strategy of this notebook\n\nThere non liner time_step data and minus pressure data.\nI ignore these data and simplify data for finding low score reason.\n\nOverview:\n* ignore non liner time_step data\n* ignore minus pressure data\n* use puls shift lag data only. do not use future data. \n\n## refer to\nFor visualization<br>\nhttps:\/\/www.kaggle.com\/tfukuda675\/data-visualization-plotly-seaborn-matplot","a2ea694c":"# Confirm linearity of time_step","6adb632d":"# Read library"}}