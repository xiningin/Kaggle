{"cell_type":{"7a69e10a":"code","87c5dea4":"code","cfe84b88":"code","897bd7e7":"code","57b01dd2":"code","81204f28":"code","079dfc57":"code","640787c9":"code","3bbec8a7":"code","26c25f03":"code","7679ee94":"code","3d99b3cd":"code","a4c32c40":"code","dd0c3167":"code","dfdadff9":"code","45a36209":"code","803c60d1":"code","334e6e7d":"code","777e0336":"code","a089a2ea":"code","016df3e5":"code","c58bc1e2":"code","f1d32d11":"code","fefadd9c":"code","4ce3e8e2":"code","0e47f714":"code","f7d06c52":"code","06836af4":"code","ee47387c":"code","7e59df95":"code","a5b05739":"code","6dd0eb17":"code","7ece8732":"code","819aa756":"code","2e57329b":"code","84c36639":"markdown","8c25d50c":"markdown","41efa289":"markdown","30ddafb4":"markdown","8b35e637":"markdown","18365be6":"markdown","9c7c7424":"markdown","87b098bd":"markdown","a20614e7":"markdown","8d74ce08":"markdown","2c08e57c":"markdown","570588ca":"markdown","ebe83b0f":"markdown","85dd0242":"markdown","1b799fc5":"markdown","69599957":"markdown","911ca516":"markdown","26fa4272":"markdown","cc724a24":"markdown","9911cfe6":"markdown","ac6f3729":"markdown","481714e2":"markdown","f5b5af65":"markdown","2e791664":"markdown","dc74c1f8":"markdown","8f016d44":"markdown","38357fb0":"markdown","b7dc4188":"markdown","6c83038e":"markdown","a3669937":"markdown","e8bccc86":"markdown","7dcd8805":"markdown","c952b06e":"markdown","c1f992e2":"markdown","4e3b965a":"markdown","faf31793":"markdown","54feeb4d":"markdown","7b505d02":"markdown","7d5aa365":"markdown","60e1b1d4":"markdown","6042ac3d":"markdown","908d3973":"markdown","1dc637b7":"markdown","4d184838":"markdown","83658f58":"markdown","fc1f52f0":"markdown","057dbab4":"markdown"},"source":{"7a69e10a":"# Data handling tools\nimport numpy as np\nimport pandas as pd\n\n# Visualization tools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Pre-machine learning tools\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder  # Perform data standardization and auto values encoder\nfrom sklearn.model_selection import train_test_split  # Split data\n\n# Machine learning algorithms and tools\nfrom sklearn.neighbors import KNeighborsClassifier  # KNN Classifier\nfrom sklearn.tree import DecisionTreeClassifier  # Decision Tree for classification\nfrom sklearn.model_selection import GridSearchCV  # Exhaustive search over specified parameter values for an estimator\n\n# Post-machine learning analysis\nfrom sklearn.metrics import classification_report, plot_confusion_matrix, accuracy_score  # Report precision, recall, f1-score, and more\n\n# Other\nfrom warnings import filterwarnings  # Warning filters\nfilterwarnings(action='ignore') # Prevent convergence warning and math errors","87c5dea4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        df = pd.read_csv(os.path.join(dirname, filename))","cfe84b88":"np.bincount(df.isna().any())","897bd7e7":"df.duplicated().any()","57b01dd2":"df.dtypes.value_counts()","81204f28":"df.head()","079dfc57":"# 1. Removal of index column.\ndf.drop(labels='Unnamed: 0', axis=1, inplace=True)","640787c9":"# 2. label encoding of names.\nkey_encoder = LabelEncoder()\ndf['Name'] = key_encoder.fit_transform(df['Name'])","3bbec8a7":"# 3. Convert Crystal Structure from float to int\ndf['Crystal Structure'] = df['Crystal Structure'].astype(int)","26c25f03":"display(df.dtypes.value_counts(), df.head())","7679ee94":"df_len = len(df)\nfor column in df.columns:\n    if df_len != np.bincount(pd.to_numeric(df[column], errors='coerce').isnull()):\n        print('Non-numeric in column: column', column)\nprint('Search completed...')\n","3d99b3cd":"mat_chars_list = ['Crystal Structure', 'Mohs Hardness', 'Diaphaneity', 'Specific Gravity', 'Optical',\n                  'Refractive Index', 'count', 'Molar Mass', 'Molar Volume', 'Calculated Density']\n                ","a4c32c40":"df_mat_chars = df[mat_chars_list].iloc[0:809]","dd0c3167":"fig, axs = plt.subplots(ncols=2, nrows=5, figsize=(15, 15))\nindex = 0\naxs = axs.flatten()\nfor k, v in df_mat_chars.items():\n    g = sns.distplot(v, ax=axs[index], color='darkcyan')\n    index += 1\nplt.tight_layout(pad = 0.4, w_pad = 0.5, h_pad = 5.0)","dfdadff9":"len(df_mat_chars)","45a36209":"df_mat_chars = df_mat_chars.loc[df['Mohs Hardness'] > 0]\ndf_mat_chars = df_mat_chars.loc[df['Diaphaneity'] > 0]\ndf_mat_chars = df_mat_chars.loc[df['Specific Gravity'] > 0]\ndf_mat_chars = df_mat_chars.loc[df['Refractive Index'] > 0]","803c60d1":"len(df_mat_chars)","334e6e7d":"np.bincount(df['Crystal Structure'])","777e0336":"scaler = StandardScaler()\nscaler.fit(df_mat_chars[mat_chars_list[1:]])\ndf_mat_chars[mat_chars_list[1:]] = scaler.transform(df_mat_chars[mat_chars_list[1:]])  ","a089a2ea":"fig, axes = plt.subplots(figsize=(10, 10))\ng = sns.boxplot(data=df_mat_chars, palette='ch:start=.2,rot=-.3')\ng.set_title('Stacked Box Plots of All Materials characteristics')\nplt.xticks(rotation=90)\nsns.set(font_scale=2)","016df3e5":"plt.figure(figsize=(18, 18))\nsns.heatmap(df_mat_chars.corr(), cmap='GnBu', annot=True)","c58bc1e2":"# Create subplots net.\nfig, axes = plt.subplots(ncols=1, nrows=9, figsize=(15, 60))\n\n# Fill subplots.\nfor idx, feature in enumerate(df_mat_chars.drop('Crystal Structure', axis=1)):\n    g = sns.violinplot(ax=axes[idx], x='Crystal Structure', y=feature,\n                    data=df_mat_chars)\n    plt.sca(axes[idx])\n    sns.set(font_scale=1)","f1d32d11":"x = []\nx.append(df_mat_chars[['Optical', 'Calculated Density']])\nx.append(df_mat_chars[['Optical', 'Mohs Hardness','Calculated Density', 'Molar Mass']])\n\ny = df_mat_chars['Crystal Structure'].map({0: 0, 1: 1, 2: 1, 3: 1, 4: 2, 5: 3, 6: 4})\n","fefadd9c":"models = []\n\nmodels.append(('KNN', KNeighborsClassifier))\nmodels.append(('DecisionTree', DecisionTreeClassifier))","4ce3e8e2":"models_parameters = []\n\n\n# KNeighborsClassifier\nmodels_parameters.append([{'leaf_size': [1, 2, 3, 5],\n                           'n_neighbors': [3, 5, 9, 11],\n                           'weights': ['uniform', 'distance']}])\n\n# DecisionTree\nmodels_parameters.append([{'criterion': ['gini', 'entropy'],\n                           'max_depth': [3, 5, 7, 11, 13],\n                          'min_samples_split': [2, 3, 7],\n                           'min_samples_leaf': [1, 2, 3, 7]}])\n","0e47f714":"models_all_data = np.concatenate((np.array(models), np.array(models_parameters)), axis=1)\nmodels_all_data","f7d06c52":"obj_model_list = []\nmodels_score_table = []\ny_prediction_train = []\n\nfor x_features in x:\n\n    x_train, x_test, y_train, y_test = train_test_split(x_features, y, test_size=0.33, random_state=42, stratify=y)\n    print('_'*50)\n    print(x_features.columns, '\\n')\n\n    for name, model, parameters in models_all_data:\n        model_starter = model()\n        obj_model_list.append(GridSearchCV(estimator=model_starter, param_grid=parameters))\n        obj_model_list[-1].fit(x_train, y_train)\n        y_prediction_train.append(obj_model_list[-1].predict(x_train).astype(int))\n        accuracy_score_train = accuracy_score(y_train, y_prediction_train[-1])\n        models_score_table.append([name, obj_model_list[-1].best_params_, round(accuracy_score_train * 100, 2), round(obj_model_list[-1].best_score_ * 100, 2)])\n        print(models_score_table[-1])","06836af4":"# Convert output table to NumPy and extract methods with the best train and validate scores.\nscore = np.array(models_score_table)\ntrain_score = score[:,2].astype(float)\nvalidate_score = score[:,3].astype(float)\n\nprint('Best train score', score[np.where(train_score == np.amax(train_score)), :])\nprint('\\nBest validate score', score[np.where(validate_score == np.amax(validate_score)), :])\ntrain_position = np.where(train_score == np.amax(train_score))\nvalidate_position = np.where(validate_score == np.amax(validate_score))\nbest_model_index = int(validate_position[0])\n\n# Find the best balance between train to validate.\nbalanced_model = np.inf\nbalanced_idx = 0\nfor idx, data in enumerate(score):\n    new_balanced_model = float(data[2]) - float(data[3])\n    if new_balanced_model < balanced_model:\n        balanced_model = new_balanced_model\n        balanced_idx = idx\n\nprint('\\nMost balanced model: ', score[balanced_idx, :])","ee47387c":"fig, axs = plt.subplots(figsize=(5, 5))\nplot_confusion_matrix(estimator=obj_model_list[best_model_index], X=x_train, y_true=y_train, ax=axs, cmap='GnBu', normalize='true')","7e59df95":"y = df_mat_chars['Crystal Structure'].map({0: 0, 1: 1, 2: 1, 3: 1, 4: 2, 5: 2, 6: 3})\nx_train, x_test, y_train, y_test = train_test_split(x[1], y, test_size=0.33, random_state=42, stratify=y)","a5b05739":"decision_tree_obj = models_all_data[1, 1]()\nobj_model = GridSearchCV(estimator=decision_tree_obj, param_grid=[models_all_data[1, 2]], cv=5)\nobj_model.fit(x_train, y_train)\ny_prediction_train = obj_model.predict(x_train).astype(int)\naccuracy_score_train = accuracy_score(y_train, y_prediction_train)\n\nprint('Decision tree')\nprint('Optimal parameters: ', obj_model.best_params_)\nprint('Train')\nprint('Accuracy score: ', round(accuracy_score_train * 100, 2))\nprint('Validation')\nprint('Accuracy score: ', round(obj_model.best_score_ * 100, 2))","6dd0eb17":"fig, axs = plt.subplots(figsize=(5, 5))\nplot_confusion_matrix(estimator=obj_model, X=x_train, y_true=y_train, ax=axs, cmap='GnBu', normalize='true')","7ece8732":"y_prediction_test = obj_model.predict(x_test).astype(int)\naccuracy_score_test = accuracy_score(y_test, y_prediction_test)\ntest_classification_report = classification_report(y_test, y_prediction_test)","819aa756":"print('Model description with train and validate scores:')\nprint(models_score_table[best_model_index])\nprint('_'*50)\nprint('Test accuracy score:', round(accuracy_score_test * 100, 2))\nprint('_'*50)\nprint(test_classification_report)","2e57329b":"fig, axs = plt.subplots(figsize=(5, 5))\nplot_confusion_matrix(estimator=obj_model, X=x_test, y_true=y_test, ax=axs, cmap='GnBu', normalize='true')","84c36639":"#### Box-plot Discussion:","8c25d50c":"#### Heat-map Highlights:","41efa289":"## The code lines below display a heat-map of the characteristics of the materials used to detect linearity between features:","30ddafb4":"**Summary**\n\n* Data was analyzed, cleaned, and organized.\n\n* 2 machine learning classifiers models were examined with multiple hyperparameters.\n\n* The best model, by validation score, was applied to analyze the test dataset.\n\n* Final prediction had ~94 accuracy.","8b35e637":"# Chapter 2: Import protocol, acquire training and testing data","18365be6":"**Crystal Structure:** \n\n\nProvides limited information as it represents the most basic crystal family. No spcific space group is given. Thus, the crystals structure histogram distribution and usability are limited.\n\n**Nevertheless, it provides crucial information, which is that it is unbalanced.**\n\nList of crystals families:\n\n1-Triclinic,2-Monoclinic, 3-Orthorhombic, 4-Tetragonal, 5-Hexagonal, 6-Trigonal, 7-Cubic. \n\n\n**Mohs Hardness:**\n\nThe resistance of a smooth surface to scratching or abrasion is scaled from 0 to 10.\n\nBy definition, it can be deduced that all zero values are missing values as minerals are not of the softest materials in nature. \n\n\n**Diaphaneity:**\n\nLevel of Transparency. The description of this feature allows 1, 2, or 3 as legit values.\n\nTherefore, all zeros and missing data.\n\n\nDiaphaneity options:\n\n1. Opaque 2. Translucent 3. Transparent\n\n\n**Specific Gravity:**\n\nThe density of the mineral is divided by the density of water.\n\nSince we do not expect zero density, their values need to be removed.\n\n\n**Optical:**\n\nThis feature represents the reaction of the mineral to incoming light.\n\nBased on possible options, zero is not defined.\n\nOptical options:\n\n1-Anisotropic, 2-Isotropic, 3-Uniaxial, 4-Biaxial\n\n\n**Refractive Index:**\n\nThe Refractive index defines the ratio of the speed of light in the mineral divided by its speed in free space. \n\nZero refractive indexes have physical meaning, and it is studied in academia, but we do not expect to find zero refractive index material in our database.\n\n\n**The following features only require standardization:**\n\n**Count:**\n\nThe total number of atoms in a formula unit of the mineral. \n\n\n**Molar Mass:**\n\nSummation(no of atoms * mass of each atom).\n\n\n**Molar Volume:**\n\nSummation(no of atoms * volume of each atom).\n\n\n**Calculated Density:**\n\nMolar mass\/ mass volume.\n\n","9c7c7424":"**Positively correlated  features:**\n\nCount, molar mass, and volume.\n\nSpecific gravity and calculated density with refractive Index.\n\n\n**Negatively correlated features:**\n\nCrystal structure and optical.\n\nCrystal structure and molar volume.\n\nCrystal structure and count.\n\nMolar volume and calculated density.\n","87b098bd":"**Future Tasks:** \n\n* Examine material properties based on the crystals' structure and the other characteristics.","a20614e7":"# Chapter 4: Analyze, identify patterns, and explore the data","8d74ce08":"## The code lines below display the distributions of the materials characteristics:\n","2c08e57c":"## The code lines below display a combined box-plot and kernel density estimate (KDE) that visualize the distribution of all material characteristics per crystal structure:","570588ca":"## Data scaling","ebe83b0f":"#### Histograms and KDE Discussion:","85dd0242":"# Predict Minerals Structure From Materials Characteristics\nA list of of 3112 minerals, their chemical composition and properties","1b799fc5":"**Model selection**\n\nWe have 6 crystal structures merged into wide or narrow sets.\n\nWide option:\nGroup num. 0: 0\nGroup num. 1: 1, 2 and 3 \nGroup num. 2: 4\nGroup num. 3: 5\nGroup num. 4: 6\n\nNarrow option:\nGroup num. 0: 0\nGroup num. 1: 1, 2 and 3 \nGroup num. 2: 4 and 5\nGroup num. 3: 6\n\nThe optical feature will be used along with various Calculated Density or Mohs Hardness, Calculated Density, and Molar Mass.\n\nDue to the small size dataset and feature quantity, KNN and decision tree models will be tested. The algorithm behind the two is very different as NKK calculates distances between points, and the decision tree splits the samples based on Gini\/entropy calculations of the features relative to the labels of the samples.\n","69599957":"## Operative actions deduced from the above discussion:\n\n* Remove all samples valued zero in the following features:\n\n    * Mohs Hardness, Diaphaneity, Specific Gravity, and Refractive Index.\n    ","911ca516":"## Test:","26fa4272":"Workflow stages:\n\n    1. Question or problem definition.\n    2. Import protocol, acquire training and testing data.\n    3. Wrangle, prepare, cleanse the data.\n    4. Analyze, identify patterns, and explore the data.\n    5. Model, predict and solve the problem.\n    6. Visualize, report, and present the problem-solving steps and final solution.\n    7. Supply or submit the results.\n","cc724a24":"No empty Cell.","9911cfe6":"The vast majority of features count the element per element type per mineral (118 features).\n\nBelow, a list of materials characteristics.\n\nDispersion is primarily empty and thus will not be used.","ac6f3729":"## The code lines below display box-plot distributions of the characteristics of the materials used for outliners analysis:","481714e2":"# Chapter 5: Model, predict and solve the problem","f5b5af65":"#### Combined Box-plot and KDE Discussion:","2e791664":"Materials characteristics are available only to 809 minerals.","dc74c1f8":"No test file is available to predict and submit.","8f016d44":"# Chapter 3: Wrangle, prepare, cleanse the data","38357fb0":"While it is crucial to identify outliers in the dataset, no outliners will be removed in this project as they may represent unique materials.","b7dc4188":"A second run of train and validate with group 2 and 32 merged on the best model and features set.","6c83038e":"385 items were removed.\n### Only 437 minerals have a complete set of material characteristics.","a3669937":"### The values above show that the structural groups are unbalanced and require stratification before modeling.","e8bccc86":"**Taking Action:**\n\n    1. Removal of index column.\n\n    2. label encoding of names.\n    \n    3. Convert Crystal Structure from float to int","7dcd8805":"Checking actions:","c952b06e":"## Confusion Matrix Discussion:\nWhile differences were seen between groups 2 and 3, the model fails to separate the two.","c1f992e2":"# Chapter 7: Supply or submit the results.","4e3b965a":"# Chapter 6: Visualize, report, and present the problem-solving steps and final solution","faf31793":"## Confusion Matrix Discussion:\nMerging groups 3 and 4 led to 6% improvment in the model.","54feeb4d":"Groups 1, 2, and 3 are almost identical in their characteristics, available in this dataset, and should be merged for better overall performance.\n\n**Optical:**\n\nCan separate the structures into 4 different groups: 0, 1-3, 4-5, and 6.\n\n\n**Mohs Hardness, Calculated Density, Molar Mass:**\n\nAn apparent to separate groups 4 and 5 may be feasible by any of the features above.\n\nAmong the three, Calculated Density is the most significant due to differences in center of mass.\n\n\n**Note:**\nGroups 0 and 6 are visibly different from all others in most features.","7b505d02":"Search below found no non-numericl value in the dataset.","7d5aa365":"# Chapter 1: Question or problem definition","60e1b1d4":"Predict minerals structure from materials characteristics.","6042ac3d":"List of models and hyperparameters for grid search:","908d3973":"**Discussion:**\n\n* Dataset:\n    \n    * Only 437 minerals have a complete set of material characteristics. Group 0 in the test dataset shows the effect of the undersized quantity of constructive samples. Increasing the database size will enable better machine learning output.\n    \n    * Optical is the single most significant feature. It can predict 4 different structural groups at once.\n\n\n* Models performance:\n    \n    * KNN: K-nearest Neighbors classifier presented good results with the smaller features set of only two optical, calculated Density. Adding Mohs Hardness and Molar Mass created a mixture of distances between points that caused over-fitting.\n    \n    * Decision Tree: Decision tree performance was the highest. This model is efficient in a multi-classes environment due to its indifference to the number of classes. Adding more features to its pool allowed better performances.","1dc637b7":"**Outliners free:**\n\nCrystal Structure, Mohs Hardness, and Diaphaneity.\n\n\n**Contain some outliners:**\n\nOptical.\n\n\n**Contain outliners:**\n\nSpecific Gravity, Refractive Index, Count, Molar Mass, Molar Volume, and Calculated Density.\n\n\n","4d184838":"The dataset contains a single int indexes column to be removed.\nOne object type column contains minerals names, which will be labeled encoded.\nThe remainder of the dataset (138 columns) is float type.","83658f58":"No duplicants.","fc1f52f0":"## Crystal structure:\nHigher crystal structure value represented higher structural symmetry, which led to lower molar volume and atom count; This could be circumstantial. \n\nNotably, the data also shows opposite optical properties, which is intriguing.\n\n\n## Refractive Index:\n\nThere is a correlation between the refractive index and the two features relevant to density (specific gravity and calculated density).\n","057dbab4":"**Results:**\n  \nThe analysis of the material properties had shown diffeculities in seperation between part of the structures.\nBy merging 7 groups to 5 an ~87% accuracy was obtained and additional ~6% accuracy can be gained by 4 structures groups."}}