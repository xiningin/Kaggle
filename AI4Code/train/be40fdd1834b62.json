{"cell_type":{"00ae932e":"code","75ba49c4":"code","0407f113":"code","d9078ac2":"code","c6e6c329":"code","42b54bfe":"code","c64f21c6":"code","68355f70":"code","7a02a95e":"code","c3bf40dc":"code","a789d83c":"code","057543c4":"code","f747d5ba":"code","50dbc600":"code","84a21e19":"code","d796fb0b":"code","120732c8":"code","67c69e18":"code","f0edf901":"code","79098550":"code","afa4c9c7":"code","6698806b":"code","8edc8c4f":"code","b750c6dd":"code","78f7182b":"code","d327b2c6":"code","c8a2bac9":"code","d9abd18e":"code","766f0b42":"code","1508b7a8":"code","2f077d42":"code","1b255221":"code","0dc70646":"code","81703094":"code","f9a0bfe0":"code","69c07aec":"code","bed3bace":"code","4830cbc4":"code","bba88dd0":"markdown","236f6afa":"markdown","3e6b19c3":"markdown","bcab9e62":"markdown","e39f8648":"markdown","46b57de0":"markdown","8371f003":"markdown","00907659":"markdown","305f8ad4":"markdown","fbb5231d":"markdown","9d052fab":"markdown","c345f710":"markdown","b242dcac":"markdown","ee3577fb":"markdown","e79c04ea":"markdown","bebff21a":"markdown","d32fa49b":"markdown","9f99a477":"markdown","aa38101d":"markdown","fa86ddd0":"markdown","08175763":"markdown","6e0db80f":"markdown","25a6dfc8":"markdown","27aa12e7":"markdown","4360fd05":"markdown","9ffdb3b8":"markdown","ee1976f0":"markdown","a2d112c0":"markdown","fea1eacd":"markdown","daa46e1d":"markdown","0a544ba7":"markdown","f14fbda8":"markdown","d3be9b25":"markdown","1f139463":"markdown","2c4012e7":"markdown","ea2b4723":"markdown","9ba2bfeb":"markdown","a4191c0d":"markdown","365f3abb":"markdown","707bdf03":"markdown"},"source":{"00ae932e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","75ba49c4":"import datetime\nimport xgboost as xgb\nfrom scipy import stats\nimport plotly.express as px\nimport pandas_profiling as pp\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.model_selection import train_test_split, GridSearchCV","0407f113":"df_train = pd.read_csv('\/kaggle\/input\/logical-rythm-2k20-game-price-prediction\/steam_train.csv')\ndf_train.describe()","d9078ac2":"df_train.columns","c6e6c329":"#pp.ProfileReport(df_train)","42b54bfe":"for i in df_train.columns:\n    print( i+\" \\t: \" +str(df_train[i].isnull().sum()))","c64f21c6":"column = 'appid'\nname = 'App-ID'\na= []\nfor i in df_train.index:\n    a.append(name +' : '+ str(df_train[column][i]))\ndf_train[column+'_visual'] = a","68355f70":"fig = px.box(data_frame = df_train.reset_index(),hover_name = 'appid_visual',\n             y = 'price',hover_data = ['name'],height = 800,color = 'owners',\n             width = 1000,labels = {'price':'Sale Price in \"$\"',\"owners\":\"Total Downloads\", \n                                    'name':'Name'},\n             title = 'Box plot of the sale price(Hover for details)')\nfig.show()","7a02a95e":"removed = 0\nthreshold = 32.5\nfor i in df_train.index:\n    if df_train['price'][i]>threshold:\n        df_train = df_train.drop(i)\n        removed+=1\nprint('Total number of data points removed till now are: '+str(removed))","c3bf40dc":"fig = px.box(data_frame = df_train.reset_index(),hover_name = 'appid_visual',\n             y = 'price',hover_data = ['name'],height = 800,color = 'owners',\n             width = 1000,labels = {'price':'Sale Price in \"$\"',\"owners\":\"Total Downloads\", \n                                    'name':'Name'},\n             title = 'Box plot of the sale price(Hover for details)')\nfig.show()","a789d83c":"encoding_columns = ['platforms', 'categories','genres','steamspy_tags']\nunique_sets = []\ncategory_ll = 250\ncategory_ul = 24500\n\nfor column in encoding_columns:\n    unique_vals = set()\n    for i in df_train[column]:\n        for j in i.split(\";\"):\n            unique_vals.add(j)\n    unique_vals = list(unique_vals)\n    unique_set = []\n    for i in unique_vals:\n        encode = []\n        for j in df_train[column]:\n            if i in j.split(\";\"):\n                encode.append(1)\n            else:\n                encode.append(0)\n        if sum(encode)>category_ll and sum(encode)< category_ul:\n            unique_set.append(column+\"_\"+i)\n            df_train[column+\"_\"+i] = encode\n    unique_sets.append(unique_set)\nencode = []\nfor i in df_train['owners']:\n    x = i.split('-')\n    encode.append(sum([int(i) for i in x])\/len(x))\ndf_train['Owners'] = encode\nencode = []\nfor i in df_train['release_date']:\n    x,y,z = i.split('-')\n    i = datetime.date(int(x),int(y),int(z))\n    diff = (datetime.date.today() - i).days\n    encode.append(diff)\ndf_train['days_in_store'] = encode\ndf_train","057543c4":"df_train.columns\nuseful_classes = set() #A list to store classes that show significant relation with price.\ncorrelation_threshold = 0.05 #Any class with a correlation with more than 0.05 will be considered significant.","f747d5ba":"height = 550\ntitle = '<b>Correlation Matrix for the dataset:<\/b>'\ncolors = 'Viridis'\n#-------------------------------------------------------------------------#\ndf_train = df_train\nclasses = ['required_age', 'achievements', 'days_in_store', 'positive_ratings',\n           'negative_ratings','average_playtime','Owners','price']\n#-------------------------------------------------------------------------#\ncorrelation = df_train[classes].corr()\ncorrelation_mat = df_train[classes].corr().to_numpy()\ncorrelation_mat = (correlation_mat\/\/0.0001)\/10000\ncorrelation_mat_norm = (correlation_mat\/\/0.01)\/100\n\nfig = ff.create_annotated_heatmap(correlation_mat, x=classes, y=classes,\n                                  annotation_text=correlation_mat_norm,\n                                  colorscale=colors,text = correlation_mat,\n                                  hovertemplate='Column: %{x}<br>'+\n                                                'Row: %{y}<br>'+\n                                                'Correlation: %{text}<extra><\/extra>')\n\n\nfig.update_layout(title_text= title,width = (height*(1.618))\/\/1,height = height,\n                  xaxis = {'title':'Columns'},\n                  yaxis = {'title':'Rows','autorange':'reversed'})\nfig.update_traces(showscale = True)\nfig.show()","50dbc600":"df_train['positive_ratings_norm'] = df_train['positive_ratings']\/df_train['Owners']\ndf_train['negative_ratings_norm'] = df_train['negative_ratings']\/df_train['Owners']\n\ndf_train['likeliness'] = (df_train['positive_ratings']-df_train['negative_ratings'])\/df_train['Owners']\ndf_train['likeliness_norm'] = df_train['likeliness']\/df_train['Owners']","84a21e19":"height = 700\ntitle = '<b>Correlation Matrix for the dataset:<\/b>'\ncolors = 'Viridis'\n#-------------------------------------------------------------------------#\ndf_train = df_train\nclasses = ['required_age', 'achievements', 'days_in_store', 'positive_ratings', \n           'negative_ratings','positive_ratings_norm','negative_ratings_norm',\n           'average_playtime','Owners','likeliness','likeliness_norm','price']\n#-------------------------------------------------------------------------#\ncorrelation = df_train[classes].corr()\ncorrelation_mat = df_train[classes].corr().to_numpy()\ncorrelation_mat = (correlation_mat\/\/0.0001)\/10000\ncorrelation_mat_norm = (correlation_mat\/\/0.01)\/100\n\nfig = ff.create_annotated_heatmap(correlation_mat, x=classes, y=classes,\n                                  annotation_text=correlation_mat_norm,\n                                  colorscale=colors,text = correlation_mat,\n                                  hovertemplate='Column: %{x}<br>'+\n                                                'Row: %{y}<br>'+\n                                                'Correlation: %{text}<extra><\/extra>')\n\nfig.update_layout(title_text= title,width = (height*(1.618))\/\/1,height = height,\n                  xaxis = {'title':'Columns'},\n                  yaxis = {'title':'Rows','autorange':'reversed'})\nfig.update_traces(showscale = True)\nfig.show()\n\nfor i in classes:\n    if abs(correlation[i]['price'])>= correlation_threshold:\n        useful_classes.add(i)","d796fb0b":"values = sorted(list(df_train['Owners'].unique()))\nencoding = []\nfor i in df_train['Owners']:\n    encoding.append(values.index(i)+1)\ndf_train['owners_color'] = encoding    ","120732c8":"fig = go.Figure()\nclasses = [x for x in classes if x != 'price']\nfor step in range (len(classes)):\n    fig.add_trace(\n        go.Scattergl(\n            visible = False,mode = 'markers',\n            marker = {'color' : df_train['owners_color']},\n            text = df_train[['appid_visual']],x = df_train[classes[step]],y = df_train['price'],\n            hovertemplate = '<b>%{text}<\/b><br>Sale Price in \"$\": %{y}<br>'+\n                            \" \".join([x.capitalize() for x in classes[step].split(\"_\")]) + \n                            ': %{x}<extra><\/extra>' \n        ))\nfig.data[0].visible = True\n\nsteps = []\nfor i in range(len(fig.data)):\n    step = dict(\n        method = \"update\",\n        label  = \" \".join([x.capitalize() for x in classes[i].split(\"_\")]),\n        args=[{\"visible\": [False] * len(fig.data)},\n              {\"title\": \"Slider switched to step: \" + str(classes[i])}],\n    )\n    step[\"args\"][0][\"visible\"][i] = True\n    steps.append(step)\n    \nsliders = [dict(\n    active=0,\n    currentvalue={\"prefix\": \"Scatter plot for Price vs \"},\n    pad={\"t\": 50},\n    steps=steps\n)]\n\nfig.update_layout(\n    sliders=sliders\n)\n\nfig.show()","67c69e18":"height = 500\ntitle = '<b>Correlation Matrix for the dataset:<\/b>'\ncolors = 'Viridis'\n#-------------------------------------------------------------------------#\ndf_train = df_train\nclasses = unique_sets[0]+['price']\n#-------------------------------------------------------------------------#\ncorrelation = df_train[classes].corr()\ncorrelation_mat = df_train[classes].corr().to_numpy()\ncorrelation_mat = (correlation_mat\/\/0.0001)\/10000\ncorrelation_mat_norm = (correlation_mat\/\/0.01)\/100\n\nfig = ff.create_annotated_heatmap(correlation_mat, x=classes, y=classes,\n                                  annotation_text=correlation_mat_norm,\n                                  colorscale=colors,text = correlation_mat,\n                                  hovertemplate='Column: %{x}<br>'+\n                                                'Row: %{y}<br>'+\n                                                'Correlation: %{text}<extra><\/extra>')\n\n\nfig.update_layout(title_text= title,width = (height*(1.618))\/\/1,height = height,\n                  xaxis = {'title':'Columns'},\n                  yaxis = {'title':'Rows','autorange':'reversed'})\nfig.update_traces(showscale = True)\nfig.show()\n\nfor i in classes:\n    if abs(correlation[i]['price'])>= correlation_threshold:\n        useful_classes.add(i)","f0edf901":"height = 700\ntitle = '<b><\/b>'\ncolors = 'Viridis'\n#-------------------------------------------------------------------------#\ndf_train = df_train\nclasses = unique_sets[1]+['price']\n#-------------------------------------------------------------------------#\ncorrelation = df_train[classes].corr()\ncorrelation_mat = df_train[classes].corr().to_numpy()\ncorrelation_mat = (correlation_mat\/\/0.0001)\/10000\ncorrelation_mat_norm = (correlation_mat\/\/0.01)\/100\n\nfig = ff.create_annotated_heatmap(correlation_mat, x=classes, y=classes,\n                                  annotation_text=correlation_mat_norm,\n                                  colorscale=colors,text = correlation_mat,\n                                  hovertemplate='Column: %{x}<br>'+\n                                                'Row: %{y}<br>'+\n                                                'Correlation: %{text}<extra><\/extra>')\n\n\nfig.update_layout(title_text= title,width = (height*(1.618))\/\/1,height = height,\n                  xaxis = {'title':'Columns'},\n                  yaxis = {'title':'Rows','autorange':'reversed'})\nfig.update_traces(showscale = True)\nfig.show()\n\nfor i in classes:\n    if abs(correlation[i]['price'])>= correlation_threshold:\n        useful_classes.add(i)","79098550":"height = 700\ntitle = '<b>Correlation Matrix for the dataset:<\/b>'\ncolors = 'Viridis'\n#-------------------------------------------------------------------------#\ndf_train = df_train\nclasses = unique_sets[2]+['price']\n#-------------------------------------------------------------------------#\ncorrelation = df_train[classes].corr()\ncorrelation_mat = df_train[classes].corr().to_numpy()\ncorrelation_mat = (correlation_mat\/\/0.0001)\/10000\ncorrelation_mat_norm = (correlation_mat\/\/0.01)\/100\n\nfig = ff.create_annotated_heatmap(correlation_mat, x=classes, y=classes,\n                                  annotation_text=correlation_mat_norm,\n                                  colorscale=colors,text = correlation_mat,\n                                  hovertemplate='Column: %{x}<br>'+\n                                                'Row: %{y}<br>'+\n                                                'Correlation: %{text}<extra><\/extra>')\n\n\nfig.update_layout(title_text= title,width = (height*(1.618))\/\/1,height = height,\n                  xaxis = {'title':'Columns'},\n                  yaxis = {'title':'Rows','autorange':'reversed'})\nfig.update_traces(showscale = True)\nfig.show()\n\nfor i in classes:\n    if abs(correlation[i]['price'])>= correlation_threshold:\n        useful_classes.add(i)","afa4c9c7":"height = 900\ntitle = ''\ncolors = 'Viridis'\n#-------------------------------------------------------------------------#\ndf_train = df_train\nclasses = unique_sets[3]+['price']\n#-------------------------------------------------------------------------#\ncorrelation = df_train[classes].corr()\ncorrelation_mat = df_train[classes].corr().to_numpy()\ncorrelation_mat = (correlation_mat\/\/0.0001)\/10000\ncorrelation_mat_norm = (correlation_mat\/\/0.01)\/100\n\nfig = ff.create_annotated_heatmap(correlation_mat, x=classes, y=classes,\n                                  annotation_text=correlation_mat_norm,\n                                  colorscale=colors,text = correlation_mat,\n                                  hovertemplate='Column: %{x}<br>'+\n                                                'Row: %{y}<br>'+\n                                                'Correlation: %{text}<extra><\/extra>')\n\n\nfig.update_layout(title_text= title,width = (height*(1.618))\/\/1,height = height,\n                  xaxis = {'title':'Columns'},\n                  yaxis = {'title':'Rows','autorange':'reversed'})\nfig.update_traces(showscale = True)\nfig.show()\n\nfor i in classes:\n    if abs(correlation[i]['price'])>= correlation_threshold:\n        useful_classes.add(i)","6698806b":"useful_classes","8edc8c4f":"print (\"The total number of useful classes are:\",len(useful_classes))","b750c6dd":"df_train_x = df_train[useful_classes].drop(['price'],axis = 1)\ndf_train_x.describe()","78f7182b":"df_train_y = df_train[['price']]\ndf_train_y.describe()","d327b2c6":"x_train,x_test,y_train,y_test = train_test_split(df_train_x, df_train_y,test_size=0.10,\n                                                 random_state=42)","c8a2bac9":"def custom_scorer(y_true,y_pred):\n    return mean_squared_error(y_true,y_pred,squared = False)\nscorer = make_scorer(custom_scorer,greater_is_better = False)","d9abd18e":"xg = xgb.XGBRegressor()\n#parameters = {\"max_depth\": [5,6,7],\n#              \"eta\": [0.01,0.03,0.05],\n#              \"alpha\":[0,1],\n#              'n_estimators': [100,500,800]}\n\n#xg = GridSearchCV(xg,parameters,cv=5,verbose = 2 , scoring = scorer, n_jobs = -1)\nxg.fit(x_train, y_train)\npredictions_xg = xg.predict(x_test)\npredictions_xg = [max(0,x) for x in predictions_xg]","766f0b42":"#print(\"The best parameters for the model are:\",xg.best_params_)","1508b7a8":"print(\"The MSE obtained is:\",mean_squared_error(y_test,predictions_xg,squared = False))","2f077d42":"predictions = xg.predict(df_train_x)\npredictions = [max(0,x) for x in predictions]\ndf_train['price_predicted'] = predictions","1b255221":"df_train['Residuals'] = (df_train['price'] - df_train['price_predicted'])\/\/0.01\/100\ndf_train['mod_Residuals'] = abs(df_train['Residuals'])","0dc70646":"dic_residuals = {'price_predicted':'Value predicted by the model',\n                 'Residuals':'Residual value','mod_Residuals':'Divergence'}\nfig = px.scatter(data_frame = df_train,x = 'price_predicted',y = 'Residuals',\n                 hover_name ='appid_visual',hover_data = ['price'],opacity = 1,\n                 trendline = 'ols',trendline_color_override = 'darkred',\n                 color= 'mod_Residuals',marginal_y ='box',labels = dic_residuals,\n                 marginal_x ='violin',\n                 title = 'Residual value plot when using XGBoost Regression Model (Hover for more details.)')\nfig.show()","81703094":"df_test = pd.read_csv('\/kaggle\/input\/logical-rythm-2k20-game-price-prediction\/steam_test.csv')\ndf_test.describe()","f9a0bfe0":"for column,unique_vals in zip (encoding_columns, unique_sets):\n    for i in unique_vals:\n        encode = []\n        for j in df_test[column]:\n            if i in [column+\"_\"+ x for x in j.split(\";\")]:\n                encode.append(1)\n            else:\n                encode.append(0)\n        df_test[i] = encode\n\nencode = []\nfor i in df_test['owners']:\n    x = i.split('-')\n    encode.append(sum([int(i) for i in x])\/len(x))\ndf_test['Owners'] = encode\nencode = []\nfor i in df_test['release_date']:\n    x,y,z = i.split('-')\n    i = datetime.date(int(x),int(y),int(z))\n    diff = (datetime.date.today() - i).days\n    encode.append(diff)\ndf_test['days_in_store'] = encode\ndf_test","69c07aec":"df_test['positive_ratings_norm'] = df_test['positive_ratings']\/df_test['Owners']\ndf_test['negative_ratings_norm'] = df_test['negative_ratings']\/df_test['Owners']\ndf_test['average_playtime_norm'] = df_test['average_playtime']\/df_test['days_in_store']\n\ndf_test['likeliness'] = (df_test['positive_ratings']-df_test['negative_ratings'])\/df_test['Owners']\ndf_test['likeliness_norm'] = df_test['likeliness']\/df_test['Owners']","bed3bace":"predictions = xg.predict(df_test[[x for x in useful_classes if x != 'price']])\npredictions = [max(0,x) for x in predictions]\ndf_test['price'] = predictions\ndf_test","4830cbc4":"df_test[['appid','price']].to_csv('submission.csv',index=False)","bba88dd0":"## Categorical data fields:","236f6afa":"ince we  do not want to remove too many data ponts, we will keep a track of how many data points have been removed. Here we have removed less than 1% of the most total dataset which seem like outliers.","3e6b19c3":"## Correlation matrix for platform variables","bcab9e62":"## Defining a custom scorer function","e39f8648":"# Predicting over the testset","46b57de0":"The variable price does not show any significant correlation with any of the platforms.","8371f003":"## 2. Testing set ","00907659":"As we can see from the box plot there are a lot of outliers so we set a threshold for the price. \n\nHere I have taken it to be $50 (Purely arbitary choice)","305f8ad4":"We see 4 more columns that show a significant correlation with price which are positive_ratings_norm, negative_ratings_norm, difference, difference_norm out of which the correlation for normalised positive ratings was expected. For normalised negative ratings it is positive because games that are popular have more of both positive and negative ratigs. \n\nThe positive correlation for normalised likeliness I think has more to do with the derived nature of the variable than its significance as a whole but the positive correlation for likeliness is something new as neither positive_ratings nor negative_ratings\nhave any significant correlation with price directly.","fbb5231d":"### One hot encoding of all purely categorical data columns","9d052fab":"There are mainly 6 categorical columns that we really care about so we do preprocessing on those only.\n\n1. The four columns **platforms, categories, genres and steamspy_tags** need to be separated for the values given in these columns.\n\n2. **Owners**: For this column we can take the number of owners as the  average of upper and lower limits of the class. Although this will not be completely accurate but will definitely give us more flexibility to work with the column. \n\n3. **Release_date**: For this column what we can do is take the difference in number of days from today which will give us a number of how many days the app has been on the play store.","c345f710":"# Data preprocessing","b242dcac":"## Exporting output to CSV","ee3577fb":"Since there are no null values in the dataset so we do not need to do any kind of data cleaning. Thus we will move on to feature engineering.","e79c04ea":"## Correlation matrix for Categories","bebff21a":"## Hyper-parameter tuning for XGBoost","d32fa49b":"# Machine Learning Model","9f99a477":"# Data Visualisation and removing of outliers: ","aa38101d":"## Preprocessing of the test file","fa86ddd0":"## Predicting over the whole dataset","08175763":"## 1. Training set","6e0db80f":"# Creating a Profile Report","25a6dfc8":"## Predicting over the test set","27aa12e7":"# Importing important libraries","4360fd05":"In this most columns do not have any significant relationship but any columns with a significant relationship have been added to useful_classes","9ffdb3b8":"## Reading the test file","ee1976f0":"## Plotting the residual plot for the model","a2d112c0":"## Price:","fea1eacd":"Now we can see that only two columns show a significant correlation with price which are required_age and days_in_store. The reason that these show correlation are:\n\n1. **required_age:** The reson behng this correlation is that the people who are older and earn are more likely to spend on the app and thus the game companies keep the price of such apps more.\n\n2. **days_in_store:** At first it might seem counter-intuitive for this column to show a positive correlation considering inflation but it seems obvious considering the rise of free-to-play games which according to many studies make more money through in-app-purchases compared to pay-to-play games. \n\nThe columns positive_ratings and negative_ratings do not seem to have any significant correlation woth price but have a huge correlation with number of owners so it seems reasonable to normalise these columns by dividing them with the owners. \n\nWe can also introduce a new variable likeliness defined as the difference of the positive and negative ratings and normalised likeliness when likeliness is divided by the number of owners ","daa46e1d":"### Box Plot of the price over the whole dataset.","0a544ba7":"# Loading the training dataset","f14fbda8":"## Splitting into train and test sets ","d3be9b25":"We have removed any fields where more than 99% values are the same as these are not useful for the model","1f139463":"## Correlation matrix for main varibles in the dataset","2c4012e7":"## Checking and removal of null values","ea2b4723":"Studying the profile report for various variables we can comment on many of the variables:\n\n1. **appid:** Unique field only for identification and doesn't contribute to price.\n\n2. **name,developer and publisher:** High cardinality fields that can't possibly be used for any kind of feature extraction which might be useful for price prediction.\n\n3. **median_playtime:** Has a very high correlation with average_playtime and therefore one of them can be safely eliminated.\n\n4. **platforms, categories, genres and steamspy_tags:** These columns need to be separated for the values given in these columns using ';' as separater.","9ba2bfeb":"# Preparing training and testing sets","a4191c0d":"### Removing of outliers in Sale Price","365f3abb":"In this the columns that are show the most significant correlation are:\n\n1. **genres_Free to Play:** This is the most obvious correlation that these games are most likely free and therefore show a negative correlation.\n\n2. **generes_Casual:** This is also quite self explanatory. Casual games generally more for a relaxed gameplay rather than competitive gaming and therefore would not be priced higher.\n\n3. **generes_Indie:** These are those games that are developed by individual developers or small groups of developers and lack high sophistication and thus are not priced high.","707bdf03":"As you can see the resulting plot looks much more well scaled over the dataset."}}