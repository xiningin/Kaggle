{"cell_type":{"1aed5201":"code","1d95a4f9":"code","e6728a84":"code","19e2a919":"code","b47804a7":"code","c574b004":"code","5048c417":"code","ab76a12b":"code","9f306bfc":"code","844c942d":"code","ad80ba5b":"code","0bedb057":"code","025c88d4":"code","e908bb79":"code","8afdfa87":"code","6da4f6c5":"code","b4a5c9cc":"code","6f25d148":"code","27a82f03":"code","3686a410":"code","746c25c7":"code","47af57f4":"code","f51d3518":"code","b27ec1df":"code","9f7925ad":"markdown","c24f043b":"markdown","56502167":"markdown","fe9827b4":"markdown","86d91b7b":"markdown","9d4ef941":"markdown","6366fc5a":"markdown","0ad4924d":"markdown","f763f3a4":"markdown","b762ad5d":"markdown","8190623b":"markdown","d7341362":"markdown","55a03964":"markdown","7d45fb79":"markdown","6da2a997":"markdown"},"source":{"1aed5201":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib.pyplot import figure\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import BaggingRegressor\n\nimport warnings\nwarnings.filterwarnings('ignore')","1d95a4f9":"train=pd.read_csv('..\/input\/bike-sharing-demand\/train.csv', parse_dates = ['datetime'])\ntest=pd.read_csv('..\/input\/bike-sharing-demand\/test.csv', parse_dates = ['datetime'])\nsampsub = pd.read_csv(\"..\/input\/bike-sharing-demand\/sampleSubmission.csv\")","e6728a84":"train.head()","19e2a919":"train.shape","b47804a7":"train.dtypes","c574b004":"figure(figsize=(12, 8))\nsns.heatmap(train.corr())","5048c417":"train['year'] = train['datetime'].dt.year\ntrain['month'] = train['datetime'].dt.month\ntrain['day'] = train['datetime'].dt.day\ntrain['hour'] = train['datetime'].dt.hour\ntrain['weekday'] = train['datetime'].dt.weekday","ab76a12b":"train = train.drop('datetime', axis = 1)","9f306bfc":"test['year'] = test['datetime'].dt.year\ntest['month'] = test['datetime'].dt.month\ntest['day'] = test['datetime'].dt.day\ntest['hour'] = test['datetime'].dt.hour\ntest['weekday'] = test['datetime'].dt.weekday","844c942d":"test = test.drop('datetime', axis = 1)","ad80ba5b":"col = ['temp', 'atemp', 'humidity', 'windspeed']","0bedb057":"for i in col:\n    scaler = StandardScaler()\n    train[col]=scaler.fit_transform(train[col])\n    test[col]=scaler.transform(test[col])   ","025c88d4":"train['count'].hist()","e908bb79":"X_train = train.drop(['count', 'casual','registered'], axis = 1)\ny_train = train['count']","8afdfa87":"y_train = np.log(y_train.values)","6da4f6c5":"X_train.shape, y_train.shape, test.shape","b4a5c9cc":"model_rf = RandomForestRegressor(random_state=2021)","6f25d148":"model_bg = BaggingRegressor(base_estimator = model_rf, random_state=2021,oob_score=True, max_features=X_train.shape[1], n_estimators = 15,\n                             max_samples=X_train.shape[0])","27a82f03":"model_bg.fit( X_train , y_train )","3686a410":"y_pred = model_bg.predict(test)","746c25c7":"y_pred =np.exp(y_pred)","47af57f4":"submission = pd.DataFrame({ \"datetime\": sampsub.datetime, \"count\": y_pred})","f51d3518":"submission.head()","b27ec1df":"submission.to_csv(\"submission_random_forest_bagging.csv\", index=False)","9f7925ad":"checking final shape of train and test data","c24f043b":"Reading data","56502167":"Here temp, atemp, humidity and windspeed features available are not in binary form so using Normalization method for this four column","fe9827b4":"Applying same conversion on test data also","86d91b7b":"Creating submission file","9d4ef941":"Created random forest algorithm for predictions","6366fc5a":"Splitting data into X_train and y_train datasets","0ad4924d":"In y_train data is in skewed form so using log transform to manage data","f763f3a4":"applying bagging regression concept for random forest algorithm","b762ad5d":"Taking anti log transform of predicted result","8190623b":"Removing date column","d7341362":"fitting this model with random forest and bagging regression concept","55a03964":"Predicting results from above model","7d45fb79":"**Importing required libraries**","6da2a997":"**Taking date as a fratures. Converted date columns to year, month, day, hour and weekday column**"}}