{"cell_type":{"a9477fd8":"code","7affa7dc":"code","682116bf":"code","550b60c0":"code","63328cc9":"code","4269ec61":"code","6366882d":"code","70e91bd5":"code","20b4629d":"code","2379b9a3":"code","334da04b":"code","239e2fe2":"code","a7860826":"code","69e855bf":"code","52c9813f":"code","5994df40":"code","2e5645d8":"code","452611c8":"code","f1110634":"code","3e17371b":"code","1f651d2c":"code","41d9f7b6":"code","4a587302":"code","eab60c88":"code","f460a078":"code","1b4d3766":"code","80f8cc47":"code","9d16248e":"code","b35cf836":"markdown","0ffcb1d1":"markdown","dcde28a3":"markdown","f828cb33":"markdown","8abea611":"markdown","5c73e64f":"markdown","3105ac8b":"markdown","7a45dcc9":"markdown","760a89f1":"markdown","330bfd6f":"markdown","1df9df3f":"markdown","790e93bb":"markdown","09aa9c36":"markdown"},"source":{"a9477fd8":"# Importing the libraries\nimport os                                                                  #for read & manipulate files\nimport pandas as pd                                                        #for read & manipulate dataset\nimport numpy as np                                                         #for fast operations on arrays\nimport seaborn as sns                                                      #for Data visualization\nimport matplotlib.pyplot as plt                                            #for Data visualization\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport nltk                                                                 #NLP analysis\nnltk.downloader.download('vader_lexicon')                                   #NLP analysis\nimport re                                                                   #NLP analysis\nfrom textblob import TextBlob                                               #NLP analysis\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer                 #NLP analysis\nfrom sklearn.preprocessing import MinMaxScaler                              #Normalization\n\nfrom sklearn.metrics import mean_squared_error                              #Evaluation Model Performance\nfrom sklearn.model_selection import train_test_split                        #split dataset\nimport xgboost                                                              #Model\n","7affa7dc":"# Load the first dataset\ncolumns=['Date','Category','News']\ndataset_news = pd.read_csv(\"..\/input\/stockmarket\/india-news-headlines.csv\",names=columns)\ndataset_news.head()","682116bf":"#**lets drop category column no need it in our work and create a copy from dataset**\ndataset_news.drop(0, inplace=True)\ndataset_news.drop('Category', axis = 1, inplace=True)\ndf_news = dataset_news.copy()\ndf_news.head()","550b60c0":"# Load the second dataset\ndataset_price = pd.read_csv(\"..\/input\/stockmarket\/AAPL.csv\")\ndf_price = dataset_price.copy()\ndf_price.head()","63328cc9":"#modify date format in 2 dataset\ndf_news[\"Date\"] = pd.to_datetime(df_news[\"Date\"],format='%Y%m%d')\ndf_price[\"Date\"]= pd.to_datetime(df_price[\"Date\"])\n\n#removing unwanted characters from the News\ndf_news.replace(\"[^a-zA-Z']\",\" \",regex=True,inplace=True)","4269ec61":"df_news.head(2)","6366882d":"df_price.head(2)","70e91bd5":"# Group the headlines for each day\ndf_news['News'] = df_news.groupby(['Date']).transform(lambda x : ' '.join(x)) \ndf_news = df_news.drop_duplicates() \ndf_news.reset_index(inplace=True,drop=True)","20b4629d":"df_news.head(3)","2379b9a3":"df_news.info()","334da04b":"df_news.describe()","239e2fe2":"print(\"Nimber of rows : {}\".format(df_news.shape[0]))","a7860826":"#Check Missing Values\ndef check_missing(data):\n    total = data.isnull().sum().sort_values(ascending=False)\n    percent = (data.isnull().sum()\/data.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data.head(20)\n\ncheck_missing(df_news)","69e855bf":"df_price.info()","52c9813f":"df_price.describe()","5994df40":"print(\"Nimber of rows : {}\".format(df_price.shape[0]))","2e5645d8":"check_missing(df_price)","452611c8":"# Figure plot\nplt.figure(figsize=(20,10))\ndf_price['Close'].plot()\nplt.ylabel('APPL')","f1110634":"#Functions to get the subjectivity and polarity\ndef getSubjectivity(text):\n      return TextBlob(text).sentiment.subjectivity\n\ndef getPolarity(text):\n      return  TextBlob(text).sentiment.polarity","3e17371b":"#Adding subjectivity and polarity columns\ndf_news['Subjectivity'] = df_news['News'].apply(getSubjectivity)\ndf_news['Polarity'] = df_news['News'].apply(getPolarity)\ndf_news","1f651d2c":"#Adding sentiment score to df_news\nsia = SentimentIntensityAnalyzer()\ndf_news['Compound'] = [sia.polarity_scores(v)['compound'] for v in df_news['News']]\ndf_news['Negative'] = [sia.polarity_scores(v)['neg'] for v in df_news['News']]\ndf_news['Neutral'] = [sia.polarity_scores(v)['neu'] for v in df_news['News']]\ndf_news['Positive'] = [sia.polarity_scores(v)['pos'] for v in df_news['News']]\ndf_news","41d9f7b6":"df_merge = pd.merge(df_price, df_news, how='inner', on='Date')\ndf_merge","4a587302":"df_final = df_merge[['Close','Subjectivity', 'Polarity', 'Compound', 'Negative', 'Neutral', 'Positive']]\ndf_final","eab60c88":"scaler = MinMaxScaler()\n\ndf_scaled = pd.DataFrame(scaler.fit_transform(df_final))\ndf_scaled.columns = df_final.columns\ndf_scaled.index = df_final.index\ndf_scaled.head()","f460a078":"X=df_scaled.drop('Close',axis=1)\ny=df_scaled['Close']","1b4d3766":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)","80f8cc47":"xgb = xgboost.XGBRegressor()\nxgb.fit(x_train, y_train)\npredictions = xgb.predict(x_test)","9d16248e":"print(mean_squared_error(y_test,predictions))","b35cf836":"### XGBRegressor Model Performance","0ffcb1d1":"### Normalization","dcde28a3":"### EDA News","f828cb33":"### Split Train & Test Data","8abea611":"### EDA Prices","5c73e64f":"### Stock Market Prediction using Numerical and Textual Analysis \n\n**Objective: Create a hybrid model for stock price\/performance prediction using numerical analysis of historical stock prices, and sentimental analysis of news headlines**\n\n**Stock to analyze and predict - SENSEX (S&P BSE SENSEX)**","3105ac8b":"### Split Dataset to input and output","7a45dcc9":"### Analysis Textual","760a89f1":"### Preprocessing","330bfd6f":"**A perfect mean squared error value is 0.0, which means that all predictions matched the expected values exactly.**\n\n**We observe that Xgboost model performs the best for the sentiment analysis**","1df9df3f":"### Combining the Prices and Textual Data","790e93bb":"**it contains date of publishing and news headline and category**","09aa9c36":"### XGBRegressor Model"}}