{"cell_type":{"c8da3881":"code","7b1bc538":"code","4d73b55f":"code","bf27f025":"code","c292be10":"code","01887258":"code","07741504":"code","dbe5589b":"code","b1215088":"code","4b0ba3b7":"code","4322fdb5":"code","cd2397d5":"code","168ec95f":"code","a143cf69":"code","9f88db9e":"code","3a2ef082":"code","7a1f6867":"code","4268c4b4":"code","e1e3aea9":"code","e3017f04":"code","966caa79":"code","211d8f13":"code","02010fd2":"code","1905c97f":"code","c50cf0e7":"code","1b0c891b":"code","02ec372b":"code","3918f829":"code","3d7ed8ee":"code","a5602696":"code","21cbd425":"code","ae10f767":"code","98a427dc":"code","8f17f85e":"code","972936dc":"code","07dc157f":"code","024053b7":"code","a6d55fb4":"code","f49bd34b":"code","a9baa160":"code","2602923c":"code","ef1ddd1d":"code","3f39fa35":"code","486f2e0f":"code","e33e13b5":"code","1b117de6":"code","4154c223":"code","55851889":"markdown","af03d294":"markdown","fc0ce6b0":"markdown","963f6fea":"markdown","7da2a039":"markdown","e8cb28eb":"markdown","cfcf5d77":"markdown","e2dbdfb8":"markdown","e613a37f":"markdown","9ce22e5b":"markdown","58b7abd7":"markdown","df908a77":"markdown","15a2ae67":"markdown","e5314351":"markdown","c57de005":"markdown","4baeaf61":"markdown","0bd91b42":"markdown","1690756d":"markdown","2fff0e78":"markdown","6b104ec9":"markdown","ad3e52f5":"markdown","852bbc5d":"markdown","66e46c70":"markdown","0184aaa7":"markdown","6a6cb49d":"markdown","9b33dac8":"markdown","529ce641":"markdown","a81cecae":"markdown","2f5ee979":"markdown","dcaf21f8":"markdown","7873d9b4":"markdown"},"source":{"c8da3881":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import preprocessing \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import cross_val_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","7b1bc538":"data_dir = '\/content\/'\nos.listdir(data_dir)","4d73b55f":"train_dataset = pd.read_csv('\/content\/train.csv')","bf27f025":"train_dataset.head()","c292be10":"temp = pd.DataFrame(index=train_dataset.columns)\ntemp['data_type'] = train_dataset.dtypes\ntemp['null_count'] = train_dataset.isnull().sum()\ntemp['unique_count'] = train_dataset.nunique()\ntemp","01887258":"categorical_dtypes = ['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\nfor i in categorical_dtypes:\n    print('************ Value Count in', i, '************')\n    print(train_dataset[i].value_counts())\n    print('')","07741504":"embarked_mode = train_dataset['Embarked'].mode()\nembarked_mode[0]","dbe5589b":"train_dataset['Embarked'].fillna(value=embarked_mode[0], inplace=True)","b1215088":"#Copied: https:\/\/www.codeastar.com\/data-wrangling\/\nindex_NaN_age = list(train_dataset[\"Age\"][train_dataset[\"Age\"].isnull()].index)\n \nfor i in index_NaN_age:\n  age_mean = train_dataset[\"Age\"].mean()\n  age_std = train_dataset[\"Age\"].std()\n  age_pred_w_spc = train_dataset[\"Age\"][((train_dataset['SibSp'] == train_dataset.iloc[i][\"SibSp\"]) & (train_dataset['Parch'] == train_dataset.iloc[i][\"Parch\"]) & (train_dataset['Pclass'] == train_dataset.iloc[i][\"Pclass\"]))].mean()\n  age_pred_wo_spc = np.random.randint(age_mean - age_std, age_mean + age_std)\n \n  if not np.isnan(age_pred_w_spc):\n        train_dataset['Age'].iloc[i] = age_pred_w_spc\n  else:\n    train_dataset['Age'].iloc[i] = age_pred_wo_spc","4b0ba3b7":"all_heat = sns.heatmap(train_dataset[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\",\"Embarked\",\"Survived\"]].corr(), annot=True)\nplt.show()","4322fdb5":"train_dataset = train_dataset.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1)","cd2397d5":"train_dataset.head()","168ec95f":"from sklearn import preprocessing \nlabel_encoder = preprocessing.LabelEncoder() \n\n\n#Sex Column  \ntrain_dataset['Sex']= label_encoder.fit_transform(train_dataset['Sex']) \n\n#Embarked Column\ntrain_dataset['Embarked']= label_encoder.fit_transform(train_dataset['Embarked'])\n\n# # Pclass Column\n# train_dataset = train_dataset.astype({'Pclass': 'object'})\n# train_dataset['Pclass']= label_encoder.fit_transform(train_dataset['Pclass'])","a143cf69":"x_train_dataset = train_dataset.drop(['Survived'], axis = 1)\ny_train_dataset = train_dataset['Survived']","9f88db9e":"x_train_dataset.head()","3a2ef082":"y_train_dataset","7a1f6867":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train_dataset = sc.fit_transform(x_train_dataset)","4268c4b4":"test_dataset = pd.read_csv('\/content\/test.csv')","e1e3aea9":"test_dataset.isnull().sum()\n\n# checktestDataset = test_dataset[test_dataset['Age'] >= 60]\n# checktestDataset.head(20)\n\n# checktestDataset = test_dataset[test_dataset['Fare'].isnull()==True]\n# checktestDataset","e3017f04":"mean_fare = test_dataset['Fare'].mean()\nmean_fare","966caa79":"test_dataset['Fare'].fillna(value=mean_fare, inplace=True)","211d8f13":"embarked_mode = test_dataset['Embarked'].mode()\nembarked_mode[0]","02010fd2":"test_dataset['Embarked'].fillna(value=embarked_mode[0], inplace=True)","1905c97f":"#Copied: https:\/\/www.codeastar.com\/data-wrangling\/\nindex_NaN_age = list(test_dataset[\"Age\"][test_dataset[\"Age\"].isnull()].index)\n \nfor i in index_NaN_age:\n  age_mean = test_dataset[\"Age\"].mean()\n  age_std = test_dataset[\"Age\"].std()\n  age_pred_w_spc = test_dataset[\"Age\"][((test_dataset['SibSp'] == test_dataset.iloc[i][\"SibSp\"]) & (test_dataset['Parch'] == test_dataset.iloc[i][\"Parch\"]) & (test_dataset['Pclass'] == test_dataset.iloc[i][\"Pclass\"]))].mean()\n  age_pred_wo_spc = np.random.randint(age_mean - age_std, age_mean + age_std)\n \n  if not np.isnan(age_pred_w_spc):\n        test_dataset['Age'].iloc[i] = age_pred_w_spc\n  else:\n    test_dataset['Age'].iloc[i] = age_pred_wo_spc","c50cf0e7":"test_dataset.shape","1b0c891b":"test_dataset.columns","02ec372b":"test_dataset = test_dataset.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1)","3918f829":"test_dataset","3d7ed8ee":"from sklearn import preprocessing \nlabel_encoder = preprocessing.LabelEncoder() \n\n#Sex Column  \ntest_dataset['Sex']= label_encoder.fit_transform(test_dataset['Sex']) \n\n#Embarked Column\ntest_dataset['Embarked']= label_encoder.fit_transform(test_dataset['Embarked'])\n\n# # Pclass Column\n# train_dataset = train_dataset.astype({'Pclass': 'object'})\n# train_dataset['Pclass']= label_encoder.fit_transform(train_dataset['Pclass'])","a5602696":"test_dataset","21cbd425":"from sklearn.preprocessing import StandardScaler\nsc_test = StandardScaler()\ntest_dataset = sc_test.fit_transform(test_dataset)","ae10f767":"Accuracy_Scores = []","98a427dc":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(x_train_dataset, y_train_dataset)","8f17f85e":"y_pred_Logistic = classifier.predict(test_dataset)\nacc_Logistic = cross_val_score(classifier, x_train_dataset, y_train_dataset, cv=10, scoring='accuracy').mean()\nAccuracy_Scores.append(acc_Logistic)\nacc_Logistic","972936dc":"len(y_pred_Logistic), len(test_dataset)","07dc157f":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=15)\nclassifier.fit(x_train_dataset, y_train_dataset)\ny_pred = classifier.predict(test_dataset)","024053b7":"y_pred_KNN = classifier.predict(test_dataset)\nacc_KNN = cross_val_score(classifier, x_train_dataset, y_train_dataset, cv=10, scoring='accuracy').mean()\nAccuracy_Scores.append(acc_KNN)\nacc_KNN","a6d55fb4":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(x_train_dataset, y_train_dataset)","f49bd34b":"y_pred_RF = classifier.predict(test_dataset)\nacc_RF = cross_val_score(classifier, x_train_dataset, y_train_dataset, cv=10, scoring='accuracy').mean()\nAccuracy_Scores.append(acc_RF)\nacc_RF","a9baa160":"from sklearn.svm import SVC\nclassifier = SVC()\nclassifier.fit(x_train_dataset, y_train_dataset)\ny_pred = classifier.predict(test_dataset)","2602923c":"y_pred_SVC = classifier.predict(test_dataset)\nacc_SVC = cross_val_score(classifier, x_train_dataset, y_train_dataset, cv=10, scoring='accuracy').mean()\nAccuracy_Scores.append(acc_SVC)\nacc_SVC","ef1ddd1d":"len(y_pred_SVC), test_dataset.shape","3f39fa35":"print(\"Accuracy Scores:\")\nModel_Names = ['Logistic Regresion', 'KNN', 'Random Forest', 'SVC']\nfor i in range(len(Model_Names)):\n    print(Model_Names[i],'---->',Accuracy_Scores[i])","486f2e0f":"stop\nAccuracy Scores:\n\nLogistic Regresion ----> 0.7979900124843945\nKNN ----> 0.8036329588014981\nRandom Forest ----> 0.8058926342072409\nSVC ----> 0.823820224719101\n\nAccuracy Scores:\nLogistic Regresion ----> 0.7879026217228464\nKNN ----> 0.8238451935081148\nRandom Forest ----> 0.8160049937578027\nSVC ----> 0.8260299625468166\n\nAccuracy Scores:\nLogistic Regresion ----> 0.7879026217228464\nKNN ----> 0.8092134831460674\nRandom Forest ----> 0.8160049937578027\nSVC ----> 0.8260299625468166","e33e13b5":"# test_df = pd.read_csv('\/content\/test.csv')\n# submission = pd.DataFrame({\n#                             'PassengerId': test_df['PassengerId'],\n#                             'Survived': y_pred_SVC\n#                           })\n\n# submission.to_csv('prediction_without_Ensemble2.csv', index = False)\n# print('Done Saving')","1b117de6":"# from statistics import mode\n# final_pred_Max_Voting = np.array([])\n# for i in range(0, len(test_dataset)):\n#     final_pred_Max_Voting = np.append(final_pred_Max_Voting, mode([y_pred_Logistic[i], y_pred_KNN[i], y_pred_RF[i], y_pred_SVC[i], y_pred_SVC[i]]))","4154c223":"# test_df = pd.read_csv('\/content\/test.csv')\n# submission = pd.DataFrame({\n#                             'PassengerId': test_df['PassengerId'],\n#                             'Survived': final_pred_Max_Voting\n#                           })\n\n# submission.to_csv('prediction_with_Ensemble_Max_Voting3.csv', index = False)\n# print('Done Saving')","55851889":"### Droping all the unwanted column","af03d294":"### Max Voting","fc0ce6b0":"## Imports","963f6fea":"## Lets have a look at each of their Accuracies","7da2a039":"### Encoding the categorical data","e8cb28eb":"### Droping all the unwanted Columns","cfcf5d77":"## Lets Create the Submission File","e2dbdfb8":"#### For `Age` column","e613a37f":"## Different Models","9ce22e5b":"### Lets Impute the missing values","58b7abd7":"## test_dataset","df908a77":"#### For the `Fare` column","15a2ae67":"### Lets Impute the missing values","e5314351":"#### Before that let's have a lok at the heat Map and the correlation of varibaled on each other","c57de005":"### Encoding the categorical data","4baeaf61":"### Random Forest","0bd91b42":"### Assigning `x_train_dataset` and `y_train_dataset`","1690756d":"## train_dataset","2fff0e78":"### Feature Scaling on `test_dataset`","6b104ec9":"### Let's have a look at the categorical variable","ad3e52f5":"#### For `Embarked` column","852bbc5d":"### KNN","66e46c70":"Creating the submission file","0184aaa7":"### Feature Scaling on `x_train_dataset`","6a6cb49d":"#### For the `Embarked` column","9b33dac8":"#### For the `Age` column","529ce641":"## Applying Ensemble Techniques","a81cecae":"### SVC","2f5ee979":"### Logistic Regression","dcaf21f8":"### Data Exploration","7873d9b4":"## Data dir's"}}