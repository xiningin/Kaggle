{"cell_type":{"8aed5c70":"code","c314bf14":"code","eefee397":"code","86100d3e":"code","d0196c7b":"code","4088391b":"code","440d18f8":"code","9c43bf0d":"code","cd254ec0":"code","9683e72a":"code","cc8da367":"code","358525cd":"code","0d13a8c6":"code","1aab9422":"code","23197a00":"code","57b612f8":"code","de745db4":"code","c41b9df5":"code","1f1f61bd":"code","df67d3d0":"code","f6de0b8f":"code","b132bd62":"code","c9a35eac":"code","f736f42b":"code","6a3991cd":"code","62691e5a":"code","98ef6141":"code","add76fc2":"code","ea05f33f":"code","5aaaa031":"code","3dc65520":"code","38c12fb8":"code","dafc83d4":"code","1e4a15bf":"code","7ce73738":"code","891e7524":"code","ed5ab5cf":"code","79e53108":"code","b4f09a8b":"code","a4d4b4cd":"code","19bbd04c":"code","d0f3a757":"code","1e6a1b63":"markdown","69308faf":"markdown"},"source":{"8aed5c70":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport missingno as msno\nfrom datetime import date\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_validate\n\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 20)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 170)","c314bf14":"def grab_col_names(dataframe, cat_th=10, car_th=20, printable = False):\n    \"\"\"\n    Veri setindeki kategorik, numerik ve kategorik fakat kardinal de\u011fi\u015fkenlerin isimlerini verir.\n    Not: Kategorik de\u011fi\u015fkenlerin i\u00e7erisine numerik g\u00f6r\u00fcn\u00fcml\u00fc kategorik de\u011fi\u015fkenler de dahildir.\n    Parameters\n    ------\n        dataframe: dataframe\n                De\u011fi\u015fken isimleri al\u0131nmak istenilen dataframe\n        cat_th: int, optional\n                numerik fakat kategorik olan de\u011fi\u015fkenler i\u00e7in s\u0131n\u0131f e\u015fik de\u011feri\n        car_th: int, optinal\n                kategorik fakat kardinal de\u011fi\u015fkenler i\u00e7in s\u0131n\u0131f e\u015fik de\u011feri\n    Returns\n    ------\n        cat_cols: list\n                Kategorik de\u011fi\u015fken listesi\n        num_cols: list\n                Numerik de\u011fi\u015fken listesi\n        cat_but_car: list\n                Kategorik g\u00f6r\u00fcn\u00fcml\u00fc kardinal de\u011fi\u015fken listesi\n    Examples\n    ------\n        import seaborn as sns\n        df = sns.load_dataset(\"iris\")\n        print(grab_col_names(df))\n    Notes\n    ------\n        cat_cols + num_cols + cat_but_car = toplam de\u011fi\u015fken say\u0131s\u0131\n        num_but_cat cat_cols'un i\u00e7erisinde.\n        Return olan 3 liste toplam\u0131 toplam de\u011fi\u015fken say\u0131s\u0131na e\u015fittir: cat_cols + num_cols + cat_but_car = de\u011fi\u015fken say\u0131s\u0131\n    \"\"\"\n\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n    if printable:\n        print(f\"Observations: {dataframe.shape[0]}\")\n        print(f\"Variables: {dataframe.shape[1]}\")\n        print(f'cat_cols: {len(cat_cols)}')\n        print(f'num_cols: {len(num_cols)}')\n        print(f'cat_but_car: {len(cat_but_car)}')\n        print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ndef outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n    \"\"\"Returns outlier threshold limits: min and max\n    Args:\n        dataframe (pd.DataFrame): A dataframe\n        col_name (str): The column name for creating threshold values\n        q1 (float, optional): Q1 value for setting the minimum threshold. Defaults to 0.25.\n        q3 (float, optional): Q3 value for setting the maximum thresold. Defaults to 0.75.\n    Returns:\n        int, int: min threshold and max threshold\n    \"\"\"\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\n\ndef grab_outliers(dataframe, col_name, index=False, q1=0.25, q3=0.75):\n    \"\"\"Prints the outlier observations\n    Args:\n        dataframe (pd.DataFrame): A dataframe\n        col_name (str): The column name for seacrhing outlier values\n        index (bool, optional): If it's true, returns the indices of outliers. Defaults to False.\n    Returns:\n        list: array of outliers' indices\n    \"\"\"\n    low, up = outlier_thresholds(dataframe, col_name, q1, q3)\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low)\n              | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low)\n              | (dataframe[col_name] > up))])\n\n    if index:\n        outlier_index = dataframe[(\n            (dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index\n\n\ndef check_outlier(dataframe, col_name, q1=0.25, q3=0.75):\n    \"\"\"Is there any outlier in the column\n    Args:\n        dataframe (pd.DataFrame): A dataframe\n        col_name (str): The column name for checking the outliers\n    Returns:\n        bool: Returns True if there is outlier in the column name else False\n    \"\"\"\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n\n\ndef replace_with_thresholds(dataframe, variable, q1=0.25, q3=0.75):\n    \"\"\"Replace outliers by thresholds\n    Args:\n        dataframe (pd.DataFrame): A dataframe\n        variable (str): The column name for applying the thresold process\n    \"\"\"\n    low_limit, up_limit = outlier_thresholds(dataframe, variable, q1, q3)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\n\ndef remove_outlier(dataframe, col_name, q1=0.25, q3=0.75):\n    \"\"\"Remove the outlier observations\n    Args:\n        dataframe (pd.DataFrame): A dataframe\n        col_name (str): The column name for removing the outliers\n    Returns:\n        pd.DataFrame: The dataframe which removed the outliers\n    \"\"\"\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n    df_without_outliers = dataframe[~(\n        (dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n    return df_without_outliers\n\n    \n\ndef plot_importance(model, features, num=5, save=False):\n    \"\"\"It shows the most important features on the model\n    Args:\n        model (ML Model): The model which we'll examine\n        features (pd.DataFrame): The features dataframe (X)\n        num (int, optional): How many features will be displayed. Defaults to 5.\n        save (bool, optional): Will you export the plot to local . Defaults to False.\n    \"\"\"\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                     ascending=False)[0:num])\n    plt.title('Features')\n    plt.tight_layout()\n    plt.show()\n    if save:\n        plt.savefig('importances.png')\n\n        \ndef target_summary_with_num(dataframe, target, numerical_col):\n    \"\"\"Prints mean of numerical_col\n\n    Args:\n        dataframe (pd.DataFrame): A dataframe\n        target (str): The target column name\n        numerical_col (str): The numerical column name\n    \"\"\"\n    print(dataframe.groupby(target).agg({numerical_col: \"mean\"}), end=\"\\n\\n\\n\")\n    \n\n    \ndef target_summary_with_cat(dataframe, target, categorical_col):\n    \"\"\"Prints relationship between the target column and classes of the categorical_col\n\n    Args:\n        dataframe (pd.DataFrame): A dataframe\n        target (str): Target column name\n        categorical_col (str): Categorical column name\n    \"\"\"\n    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")","eefee397":"def load_dataset():\n    df = pd.read_csv(\"..\/input\/airline-passenger-satisfaction\/train.csv\")\n    return df.iloc[:, 1:]\n\n\ndf_ = load_dataset()\ndf = df_.copy()\n\ndf.head()","86100d3e":"# VER\u0130YE BA\u015eTAN VE SONDAN BAKIYORUZ\ndf.head()","d0196c7b":"df.tail()","4088391b":"# info\ndf.info()","440d18f8":"# SHAPE\ndf.shape","9c43bf0d":"# EKS\u0130K VER\u0130\ndf.isna().sum()","cd254ec0":"# \u015fimdilik eksik verileri silelim\ndf.dropna(inplace=True)","9683e72a":"# ya\u015fa g\u00f6re hedefin boxplotu\nplt.figure(figsize=(10, 7))\nsns.boxplot(x='satisfaction', y='Age', data=df, palette='GnBu_d').set_title('Ya\u015fa G\u00f6re Memnuniyet')\nplt.show()","cc8da367":"# u\u00e7u\u015f mesafesine g\u00f6re m\u00fc\u015fteri memnuniyeti\nplt.figure(figsize=(10, 7))\nsns.boxplot(x='satisfaction', y='Flight Distance', data=df, palette='GnBu_d').set_title('U\u00e7u\u015f Mesafesine G\u00f6re Memnuniyet')\nplt.show()","358525cd":"# Veri Seti Tekil mi\ndf[\"id\"].nunique() == df.shape[0]","0d13a8c6":"# id s\u00fctununu kald\u0131ral\u0131m\ndf = df.drop(\"id\", axis=1)","1aab9422":"# hedef de\u011fi\u015fken analizi\nprint('Target Variable')\nprint(df.groupby('satisfaction').agg({'satisfaction':'count'}))","23197a00":"sns.set_style('darkgrid')\nplt.figure(figsize=(10, 5))\nsns.countplot(df['satisfaction'], alpha=.80, palette=['grey', 'lightgreen'])\nplt.title('(neutral veya dissatisfied) ve satisfied')\nplt.ylabel('# M\u00fc\u015fteriler')\nplt.show()","57b612f8":"# SAYISALLARI \u0130NCELEME\nsns.set_style('darkgrid')\nfig = plt.figure(figsize=(20,20))\nfig.subplots_adjust(hspace=.30)\n\nax2 = fig.add_subplot(323)\nax2.hist(df['Age'], bins=10, alpha=.50, edgecolor='black', color='teal')\nax2.set_xlabel('Age', fontsize=15)\nax2.set_ylabel('# Yolcular', fontsize=15)\nax2.set_title('Yolcu Ya\u015flar\u0131', fontsize=15)\nplt.show()","de745db4":"# SAYISALLARI \u0130NCELEME\nsns.set_style('darkgrid')\nfig = plt.figure(figsize=(20,20))\nfig.subplots_adjust(hspace=.30)\n\nax2 = fig.add_subplot(323)\nax2.hist(df['Flight Distance'], bins=10, alpha=.50, edgecolor='black', color='teal')\nax2.set_xlabel('Flight Distance', fontsize=15)\nax2.set_ylabel('# Yolcular', fontsize=15)\nax2.set_title('U\u00e7u\u015f Mesafeleri', fontsize=15)\nplt.show()","c41b9df5":"# SAYISALLARI \u0130NCELEME\nsns.set_style('darkgrid')\nfig = plt.figure(figsize=(20,20))\nfig.subplots_adjust(hspace=.30)\n\nax2 = fig.add_subplot(323)\nax2.hist(df['Arrival Delay in Minutes'], bins=10, alpha=.50, edgecolor='black', color='teal')\nax2.set_xlabel('Arrival Delay in Minutes', fontsize=15)\nax2.set_ylabel('# Yolcular', fontsize=15)\nax2.set_title('Var\u0131\u015f Gecikme S\u00fcreleri', fontsize=15)\nplt.show()","1f1f61bd":"# ayk\u0131r\u0131 de\u011ferleri G\u00d6RSELLE\u015eT\u0130R\ncat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=10, car_th=20)\n\nfor col in num_cols:\n    sns.boxplot(x=df[col], whis=[0.05, 0.95])\n    plt.show()","df67d3d0":"# ayk\u0131r\u0131 de\u011fer s\u0131n\u0131rlar\u0131na bak\nq1 = df[\"Departure Delay in Minutes\"].quantile(0.01)\nq3 = df[\"Departure Delay in Minutes\"].quantile(0.99)\n\niqr = q3 - q1\nup = q3 + 1.5 * iqr\nlow = q1 - 1.5 * iqr\ndf[(df[\"Departure Delay in Minutes\"] < low) | (df[\"Departure Delay in Minutes\"] > up)][\"Departure Delay in Minutes\"]","f6de0b8f":"# describe\ncat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=10, car_th=20)\n\ndf[num_cols].describe([0.10, .20, .30, .40, .50, .60, .70, .80, .90, .95, .99]).T","b132bd62":"\n# SAYISAL DE\u011e\u0130\u015eKENLERLE HEDEF DE\u011e\u0130\u015eKEN\u0130 \u0130NCELEYEL\u0130M\nfor i in num_cols:\n    dummy = df.groupby('satisfaction').agg({f'{i}':'mean'})\n    sns.barplot(dummy.index, dummy[i]).set_title(f'{i} Mean')\n    plt.show()","c9a35eac":"# ENCODE TARGET\nencoder = LabelEncoder()\ndf[\"satisfaction\"] = encoder.fit_transform(df[\"satisfaction\"])\n# Satisfied: 1\n# neutral or dissatisfied: 0\n\nfor i in cat_cols:\n    target_summary_with_cat(df, \"satisfaction\", i)","f736f42b":"df.groupby(\"Type of Travel\").agg({\"Age\": [\"mean\", \"max\", \"min\"]})","6a3991cd":"cat_cols = [col for col in cat_cols if \"satisfaction\" not in col]\n\n# HEATMAP - KORELASYON\ncat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5, car_th=20)\n\nplt.figure(figsize=(15, 15))\nf = df[num_cols].corr()\nax = sns.heatmap(f, annot=True)\nplt.show()","62691e5a":"# H\u0130ST\ncat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=10, car_th=20)\n\ndf.loc[:, num_cols].hist(color=\"purple\", figsize=(10, 10))\nplt.show()","98ef6141":"for cc in cat_cols:\n    sns.catplot(x=cc, y=\"satisfaction\", kind=\"bar\", data=df)\n    plt.show()","add76fc2":"# VALUE COUNT BAKMA G\u00d6RSEL OLARAK DA\nfor cc in cat_cols:\n    dummy = pd.DataFrame(df[cc].value_counts())\n    sns.barplot(dummy.index, dummy[cc]).set_title(cc)\n    plt.show()","ea05f33f":"def get_data():\n    return pd.read_csv('..\/input\/airline-passenger-satisfaction\/train.csv').drop(['Unnamed: 0','id'], axis=1)\n\n\n\ndef get_corr_matrix(df):\n    f, ax = plt.subplots(figsize=[20, 15])\n    sns.heatmap(df.corr(), annot=True, fmt=\".2f\", ax=ax, cmap=\"magma\")\n    ax.set_title(\"Correlation Matrix\", fontsize=20)\n    plt.show()\n\n\ndef age_engineering(df):\n    # ERGEN ERKEK - KADIN 0-17\n    df.loc[(df[\"Age\"] <= 17) & (df[\"Gender\"] == \"Male\"),\n           \"NEW_GENDER_CAT\"] = \"AdolescentMale\"\n    df.loc[(df[\"Age\"] <= 17) & (df[\"Gender\"] == \"Female\"),\n           \"NEW_GENDER_CAT\"] = \"AdolescentFemale\"\n    # GEN\u00c7 ERKEK-KADIN 18-65\n    df.loc[(df[\"Age\"] >= 18) & (df[\"Age\"] <= 65) & (\n        df[\"Gender\"] == \"Male\"), \"NEW_GENDER_CAT\"] = \"YouthMale\"\n    df.loc[(df[\"Age\"] >= 18) & (df[\"Age\"] <= 65) & (\n        df[\"Gender\"] == \"Female\"), \"NEW_GENDER_CAT\"] = \"YouthFemale\"\n    # ORTA YA\u015e ERKEK-KADIN 66-79\n    df.loc[(df[\"Age\"] >= 66) & (df[\"Age\"] <= 79) & (\n        df[\"Gender\"] == \"Male\"), \"NEW_GENDER_CAT\"] = \"MiddleAgeMale\"\n    df.loc[(df[\"Age\"] >= 66) & (df[\"Age\"] <= 79) & (\n        df[\"Gender\"] == \"Female\"), \"NEW_GENDER_CAT\"] = \"MiddleAgeFemale\"\n    # YA\u015eLI\n    df.loc[(df[\"Age\"] > 79) & (df[\"Gender\"] == \"Female\"),\n           \"NEW_GENDER_CAT\"] = \"OldAgeFemale\"\n    df.loc[(df[\"Age\"] > 79) & (df[\"Gender\"] == \"Male\"),\n           \"NEW_GENDER_CAT\"] = \"OldAgeMale\"\n    return df\n\n\ndef customer_value_engineering(df):\n    df.loc[:, 'New_Value'] = 'Normal'\n    df.loc[((df['Customer Type'] == 'Loyal Customer') | (df['Customer Type'] == 'disloyal Customer')) & ((df['Type of Travel'] == 'Business Travel') | (\n        df['Type of Travel'] == 'Personal Travel')) & (df['Class'] == 'Business') & (df['satisfaction'] == 'satisfied'), 'New_Value'] = 'Most Valuable'\n    df.loc[(df['Customer Type'] == 'Loyal Customer') & ((df['Type of Travel'] == 'Business Travel') | (df['Type of Travel']\n                                                                                                       == 'Personal Travel')) & (df['Class'] == 'Eco Plus') & (df['satisfaction'] == 'satisfied'), 'New_Value'] = 'Valuable'\n    df.loc[((df['Customer Type'] == 'Loyal Customer') | (df['Customer Type'] == 'disloyal Customer')) & ((df['Type of Travel'] == 'Business Travel') | (\n        df['Type of Travel'] == 'Personal Travel')) & (df['Class'] == 'Eco Plus') & (df['satisfaction'] == 'satisfied'), 'New_Value'] = 'Average Valuable'\n    df.loc[(df['Departure Delay in Minutes'] > df['Departure Delay in Minutes'].mean()) & (df['Arrival Delay in Minutes'] > df['Arrival Delay in Minutes'].mean()) & (\n        df['Flight Distance'] > df['Flight Distance'].mean()) & (df['satisfaction'] == 'satisfied'), 'New_Value'] = 'Best Valuable'\n    return df\n\n\ndef asel_mebaysan_preprocess(df, na='drop', fix_outlier=True):\n    cat_cols, num_cols, cat_but_car = grab_col_names(df,cat_th=5)\n    num_cols = [col for col in num_cols if col not in \"id\"]\n    #################################\n    #### * Missing Values ####\n    #################################\n    if na == 'drop':\n        df = df.dropna()\n    elif na == 'group':\n        df[\"Arrival Delay in Minutes\"].fillna(df.groupby(['Customer Type', 'Type of Travel', 'Class', 'satisfaction'])[\n                                              \"Arrival Delay in Minutes\"].transform(\"mean\"), inplace=True)\n    elif na == 'knn':\n        dff = pd.get_dummies(df[cat_cols + num_cols], drop_first=True)\n        scaler = MinMaxScaler()\n        dff = pd.DataFrame(scaler.fit_transform(dff), columns=dff.columns)\n        imputer = KNNImputer(n_neighbors=5)\n        dff = pd.DataFrame(imputer.fit_transform(dff), columns=dff.columns)\n        dff = pd.DataFrame(scaler.inverse_transform(dff), columns=dff.columns)\n        df[\"Arrival Delay in Minutes\"] = dff[[\"Arrival Delay in Minutes\"]]\n\n    #################################\n    #### * Outliers ####\n    #################################\n    if fix_outlier:\n        for num in num_cols:\n            q1 = 0.05\n            q3 = 0.95\n            if check_outlier(df, num, q1, q3):\n                # sns.boxplot(x=f'{num}',data=df, whis=[0.05, 0.95])\n                # plt.show()\n                # grab_outliers(df,num,True,0.05,0.95)\n                # df[num].describe([0.10, 0.20, 0.30, 0.40, 0.50,\n                #              0.60, 0.70, 0.80, 0.90, 0.95, 0.99])\n                replace_with_thresholds(df, num, q1, q3)\n                # print('+++++++++++++++++++++++++++++++++++++++++++++++++++++')\n    else:\n        pass\n\n    #################################\n    #### * Feature Engineering ####\n    #################################\n    df = age_engineering(df)\n    df = customer_value_engineering(df)\n    cat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5)\n    num_cols = [col for col in num_cols if col not in \"id\"]\n    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n    return df","5aaaa031":"\"\"\"\ndef random_forest_classifier(X, y):\n    rf_model = RandomForestClassifier(\n        random_state=34).fit(X, y)  # model nesnesi olu\u015fturuyoruz\n\n    # hyperparameter optimizasyonu yapmak i\u00e7in hiperparametreleri yaz\u0131yorum\n    rf_params = {\"max_depth\": [5, 8, None],  # max a\u011fa\u00e7 derinli\u011fi\n                 # b\u00f6l\u00fcnme i\u015flemi yap\u0131l\u0131rken g\u00f6z \u00f6n\u00fcnde bulundurulacak olan de\u011fi\u015fken say\u0131s\u0131\n                 \"max_features\": [3, 5, 7, \"auto\"],\n                 # bir node'u dala ay\u0131rmak i\u00e7in gerekli minimum g\u00f6zlem say\u0131s\u0131\n                 \"min_samples_split\": [2, 5, 8, 15, 20],\n                 \"n_estimators\": [100, 200, 500]}  # a\u011fa\u00e7 say\u0131s\u0131, kolektif (topluluk) \u00f6\u011frenme metodu oldu\u011fundan ka\u00e7 adet a\u011fa\u00e7 olmas\u0131n\u0131 istiyoruz\n\n    # en iyi parametreleri ar\u0131yoruz\n    rf_best_grid = GridSearchCV(rf_model,  # hangi model\n                                rf_params,  # hangi parametreler\n                                cv=3  # ka\u00e7 katl\u0131 \u00e7aprazlama\n                                ).fit(X, y)\n\n    # final model kuruyoruz\n    rf_final = rf_model.set_params(**rf_best_grid.best_params_,  # en iyi hiperparametreleri modele set ediyorum\n                                   random_state=34).fit(X, y)\n\n    # final model cv ile test ediyoruz\n    cv_results = cross_validate(rf_model,  # final modelin cross validation hatas\u0131\n                                X, y,\n                                cv=3,\n                                scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n\n    return {\n        'model': rf_final,\n        'train_accuracy': cv_results['test_accuracy'].mean(),\n        'train_f1': cv_results['test_f1'].mean(),\n        'train_roc_auc': cv_results['test_roc_auc'].mean()\n    }\n\n\ndef xgbm_classifier(X, y):\n    xgboost_model = XGBClassifier(random_state=34).fit(X, y)\n\n    xgboost_params = {\"learning_rate\": [0.1, 0.01, 0.001],  # b\u00fcy\u00fcme \u015fiddeti\n                      \"max_depth\": [5, 8, 12, 15, 20],\n                      # a\u011fa\u00e7 say\u0131s\u0131, iterasyon say\u0131s\u0131..\n                      \"n_estimators\": [100, 500, 1000],\n                      # y\u00fczdelik olarak ka\u00e7 g\u00f6zlem bulunsun\n                      \"colsample_bytree\": [0.5, 0.7, 1]\n                      }\n\n    xgboost_best_grid = GridSearchCV(xgboost_model,\n                                     xgboost_params,\n                                     cv=5,\n                                     verbose=True).fit(X, y)\n\n    xgboost_best_grid.best_score_\n\n    xgboost_final = xgboost_model.set_params(**xgboost_best_grid.best_params_,\n                                             random_state=17).fit(X, y)\n\n    cv_results = cross_validate(xgboost_final,\n                                X, y,\n                                cv=10,\n                                scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n    return {\n        'model': xgboost_model,\n        'train_accuracy': cv_results['test_accuracy'].mean(),\n        'train_f1': cv_results['test_f1'].mean(),\n        'train_roc_auc': cv_results['test_roc_auc'].mean()\n    }\n\"\"\"","3dc65520":"def random_forest_classifier_basemodel(hyperparameters, X, y):\n    rf_ = RandomForestClassifier(random_state=34)\n    rf_final = rf_.set_params(**hyperparameters).fit(X, y)\n\n    cv_results = cross_validate(rf_final,  # final modelin cross validation hatas\u0131\n                                X, y,\n                                cv=3,\n                                n_jobs=-1,\n                                scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n\n    return {\n        'model': rf_final,\n        'train_accuracy': cv_results['test_accuracy'].mean(),\n        'train_f1': cv_results['test_f1'].mean(),\n        'train_roc_auc': cv_results['test_roc_auc'].mean()\n    }\n\n\ndef xgbm_classifier_basemodel(hyperparameters, X, y):\n    xgboost_ = XGBClassifier(random_state=34, use_label_encoder=False)\n    xgboost_final = xgboost_.set_params(**hyperparameters).fit(X, y)\n\n    cv_results = cross_validate(xgboost_final,\n                                X, y,\n                                cv=3,\n                                n_jobs=-1,\n                                scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n\n    return {\n        'model': xgboost_final,\n        'train_accuracy': cv_results['test_accuracy'].mean(),\n        'train_f1': cv_results['test_f1'].mean(),\n        'train_roc_auc': cv_results['test_roc_auc'].mean()\n    }","38c12fb8":"def get_test_data(na='group', fix_outlier=True):\n    df = pd.read_csv('..\/input\/airline-passenger-satisfaction\/test.csv').drop(['Unnamed: 0','id'], axis=1)\n    df = asel_mebaysan_preprocess(df, na, fix_outlier)\n    X = df.drop('satisfaction_satisfied', axis=1)\n    y = df['satisfaction_satisfied']\n    return df, X, y\n\n\ndef predict(X, y, model):\n    y_pred = model.predict(X)\n    return {\n        'model':model,\n        'accuracy': accuracy_score(y, y_pred),\n        'f1-score': f1_score(y, y_pred),\n        'recall': recall_score(y, y_pred),\n        'precision': precision_score(y, y_pred)\n    }","dafc83d4":"#################################\n#### * Train ####\n#################################\ndf = get_data()\ndf = asel_mebaysan_preprocess(df, 'group')\nX = df.drop('satisfaction_satisfied', axis=1)\ny = df['satisfaction_satisfied']\n\n\n\"\"\"\nresult_dict_rf = random_forest_classifier(X, y)\nresult_dict_xgbm = xgbm_classifier(X, y)\n\"\"\"\n\nparameters_rf = {\"max_features\": 7,\n                 \"n_estimators\": 500,\n                 \"random_state\": 34}\n\nparameters_xgb = {\"booster\": \"gbtree\",\n                  \"learning_rate\": 0.01,\n                  \"max_depth\": 12,\n                  \"n_estimators\": 1000}","1e4a15bf":"result_dict_rf_base = random_forest_classifier_basemodel(parameters_rf, X, y)","7ce73738":"result_dict_xgbm_base = xgbm_classifier_basemodel(parameters_xgb, X, y)","891e7524":"#################################\n#### * Test ####\n#################################\ntest_df, test_X, test_y = get_test_data(na='group')","ed5ab5cf":"test_dict_rf = predict(test_X, test_y, result_dict_rf_base['model'])","79e53108":"test_dict_rf","b4f09a8b":"test_dict_xgbm = predict(test_X, test_y, result_dict_xgbm_base['model'])","a4d4b4cd":"test_dict_xgbm","19bbd04c":"#################################\n#### * Plot Importance for Random Forest ####\n#################################\nplot_importance(test_dict_rf['model'],test_X,num=15)","d0f3a757":"#################################\n#### * Plot Importance for XGBM ####\n#################################\nplot_importance(test_dict_xgbm['model'],test_X,num=15)","1e6a1b63":"# Modeller","69308faf":"# \u00d6zet Bilgiler"}}