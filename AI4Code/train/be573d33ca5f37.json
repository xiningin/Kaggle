{"cell_type":{"71198b47":"code","4ecd62ec":"code","b0570e75":"code","76d435f3":"code","62b91d68":"code","2e037d2a":"code","9bb49374":"code","bd38983f":"code","e663970f":"code","88a6ecd8":"code","c4184c4f":"code","50552008":"code","a22fb9c7":"code","4de5efec":"code","c7681638":"code","5fd73c0d":"code","b54673e8":"code","66a56e61":"code","e3c7d2d5":"markdown","dca1588f":"markdown","e89f89d7":"markdown","317c6c6a":"markdown","d17accb6":"markdown","24288243":"markdown","b18cbb8f":"markdown","c8af9ab7":"markdown","8c54a82f":"markdown","3edd1599":"markdown"},"source":{"71198b47":"# GPU\nimport torch\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint('GPU State:', device)","4ecd62ec":"import os\n\n# Local\n# data_path = '.\/Datasets\/'\n\n# Path for Kaggle\ndata_path = '\/kaggle\/input\/beginners-cats-and-dogs\/'\n\ntest_data_path = os.path.join(data_path, 'testing_set\/testing_set')\ntrain_data_path = os.path.join(data_path, 'training_set\/training_set')","b0570e75":"%matplotlib inline\nfrom PIL import Image\nfrom matplotlib.pyplot import imshow\n\n# check pictures\nimg_path = os.path.join(test_data_path, 'testing_3.jpg')\nim = Image.open(img_path)\nimshow(im)","76d435f3":"import pandas as pd\n\ntrain_df = pd.read_csv(os.path.join(data_path , 'Train.csv'))\ntrain_df.head()","62b91d68":"test_df = pd.read_csv(os.path.join(data_path , 'Test.csv'))\ntest_df.head()","2e037d2a":"from collections import defaultdict\nfrom collections import Counter\nimport numpy as np\n\n# get all the filename and use them to load .jpg\ntrain_x_files = train_df['filename']\nshape_dict = defaultdict(int)\n\n\nsize = 128, 128\nfor idx, filename in enumerate(train_x_files):\n    \n    # use Image.open() to load JPG, and using np.array to transform it to matrix.\n    img_path = os.path.join(train_data_path, filename)\n    im = Image.open(img_path)\n      \n    # resize image to the largest \"size\"\n    im.thumbnail(size, Image.ANTIALIAS)\n\n    # .conver('L') could get gray scale image\n    numeric_gray_x = np.array(im.convert('L'), dtype='float32')\n    shape_dict[numeric_gray_x.shape] += 1\n    \ncounter = Counter(shape_dict)","9bb49374":"counter.most_common(10)","bd38983f":"# function for transform figure into matrix\n\ndef fig2matrix(data_df, data_path, size=(128,128), channel=1, is_train:bool=True):\n    # get all the filename and use them to load .jpg\n    x_files = data_df['filename']\n\n    # prepare a list to store matrix\n    matrix_x = []\n    data_idx = []\n    \n    show = True\n    for idx, filename in enumerate(x_files):\n\n        # use Image.open() to load JPG, and using np.array to transform it to matrix.\n        img_path = os.path.join(data_path, filename)\n        im = Image.open(img_path)\n\n        # resize image to the largest \"size\"\n        im.thumbnail(size, Image.ANTIALIAS)\n\n        # using np.array to transform it to matrix\n        # turn them into torch Tensor for utilize permute() function\n        numeric_rgb_x = np.array(im, dtype='float32')\n        if numeric_rgb_x.shape == (96, 128, 3):\n\n            data_idx.append(idx)  \n            if channel == 3:\n                matrix_x.append(torch.as_tensor(numeric_rgb_x).permute(2, 0, 1))\n\n            elif channel == 1:\n                # .conver('L') could get gray scale image\n                numeric_gray_x = np.array(im.convert('L'), dtype='float32')\n                matrix_x.append(torch.as_tensor(numeric_gray_x).unsqueeze(0))\n\n            if show:\n                print(f'matrix_x[0] type: {type(matrix_x[0])}')\n                print(f'matrix_x[0] shape: {matrix_x[0].shape}')\n                show = False\n\n    labels = torch.as_tensor(data_df['label'].values[data_idx]) if is_train else None\n    return torch.stack(matrix_x), labels, data_idx","e663970f":"print(f'Process training data...')\ntrain_x, train_y, train_data_idx = fig2matrix(train_df, data_path=train_data_path, is_train=True)\n\nprint(f'\\nProcess testing data...')\ntest_x, _, test_data_idx = fig2matrix(test_df, data_path=test_data_path, is_train=False)","88a6ecd8":"print('In training set:')\nprint(f' train_y type: {type(train_y)}')\nprint(f' train_y shape: {train_y.shape}')\n\nn_dogs = sum([1 for y in train_y if y==0])\nprint(f'   n_dogs: {n_dogs}')\nprint(f'   n_cats: {len(train_y) - n_dogs}')","c4184c4f":"import torch\nimport torch.nn as nn\n\nimport torch\nimport torch.nn as nn\n\nclass testNet(nn.Module):\n    def __init__(self):\n        super(testNet, self).__init__()\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=5, \n                             stride=2, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n        self.act = nn.ReLU()\n        \n        self.cnn2 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, \n                              stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n        \n        self.fc = nn.Linear(2640, 128)\n        self.fc2 = nn.Linear(128, 32)\n        self.fc3 = nn.Linear(32, 2)\n\n    def forward(self, x_3D):\n        x1 = self.act(self.cnn1(x_3D))\n        x2 = self.act(self.cnn2(x1))\n        x_flat = torch.flatten(x2, 1)\n#         print('x_flat:',x_flat.shape)\n        x3 = self.act(self.fc(x_flat))\n        x4 = self.act(self.fc2(x3))\n        x5 = self.fc3(x4)\n        return x5","50552008":"from sklearn.preprocessing import OneHotEncoder\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# onehotencoder = OneHotEncoder()\n# train_Y = onehotencoder.fit_transform(torch.as_tensor(train_y).unsqueeze(-1)).toarray()\n\ntrainLoader = DataLoader(TensorDataset(train_x, train_y), batch_size=32, shuffle=True)","a22fb9c7":"for data in trainLoader:\n    print('x:', data[0])\n    print('y:', data[1])    \n    break","4de5efec":"import torch.optim as optim\n\nmodel = testNet()\nmodel.to(device)\n\n# Parameters\nepochs = 300\nlr = 0.001\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=lr)","c7681638":"# Train\nfor epoch in range(epochs):\n    running_loss = 0.0\n\n    for times, data in enumerate(trainLoader):\n        inputs, labels = data[0].to(device), data[1].to(device)\n#         print('inputs:',inputs)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Foward + backward + optimize\n        outputs = model(inputs)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # Print statistics\n        running_loss += loss.item()\n    print('[%d\/%d, %d\/%d] loss: %.5f' % (epoch+1, epochs, times+1, len(trainLoader), running_loss\/2000))\n\nprint('Training Finished.')","5fd73c0d":"# prediction\npred_y = []\nfor times, data in enumerate(test_x):\n    inputs = data.to(device)\n    # Foward + backward + optimize\n    outputs = model(inputs.unsqueeze(0))\n\n    # Print statistics\n    pred_y.append(torch.argmax(outputs).item())","b54673e8":"f = open('prediction.csv', 'w')\nprint(f'filename,label', file=f)\n\ni = 0\nfor idx, file in enumerate(test_df['filename']):\n    if idx in test_data_idx:\n        print(f'{file},{pred_y[i]}',file=f)\n        i += 1\n    else:\n        print(f'{file},0', file=f)\n        \nf.close()","66a56e61":"pred_df = pd.read_csv('prediction.csv')\npred_df.head()","e3c7d2d5":"The input (**x**) need some preprocessing:\n* load JPG transform to numerical matrix \n* permute the dimension to match the input format of nn.Conv2d\n* padding data to the same size\n\n\n\u5b58\u53c3:https:\/\/towardsdatascience.com\/data-preprocessing-and-network-building-in-cnn-15624ef3a28b","dca1588f":"#### Set file path ","e89f89d7":"## Build Classifier","317c6c6a":"#### Geberate (data, label) for training\n\nThe label (**y**) of data could derive from Train.csv directly.  ","d17accb6":"## Train","24288243":"## Prepare dataloader\nUsing dataloader, we could manipulate data more easily. For example, dataloader can do shuffle for us. ","b18cbb8f":"### Exploring data format","c8af9ab7":"Almost all picture has different shape.","8c54a82f":"#### Take a look at data","3edd1599":"## Prediciton"}}