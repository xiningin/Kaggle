{"cell_type":{"6ad40b1b":"code","bbf1d0b1":"code","c267f8f2":"code","2c3a0381":"code","b5673734":"code","c4d79769":"code","dbc9ec3b":"code","639eb8b8":"markdown","2572f564":"markdown"},"source":{"6ad40b1b":"import numpy as np  \nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img  \nfrom keras.models import Sequential  \nfrom keras.layers import GlobalAveragePooling2D, Dense\nfrom keras import applications  \nfrom keras.utils.np_utils import to_categorical  \nimport matplotlib.pyplot as plt  \nimport math ","bbf1d0b1":"# dimensions of our image  \nimg_width, img_height = 100, 100  \n   \ntop_model_weights_path = 'bottleneck_fruits_model.h5'  \ntrain_data_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Training'  \nvalidation_data_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Test'  \n    \nepochs = 20  # number of epochs to train top model \nbatch_size = 16  ","c267f8f2":"# save bottleneck features\nmodel = applications.VGG16(include_top=False, weights='imagenet')  \n    \ndatagen = ImageDataGenerator(rescale=1. \/ 255) \n    \ngenerator = datagen.flow_from_directory(  \n     train_data_dir,  \n     target_size=(img_width, img_height),  \n     batch_size=batch_size,  \n     class_mode=None,  \n     shuffle=False)  \n    \nnb_train_samples = len(generator.filenames)  \n    \npredict_size_train = int(math.ceil(nb_train_samples \/ batch_size)) \n    \nbottleneck_features_train = model.predict_generator(  \n     generator, predict_size_train) \n    \nprint(bottleneck_features_train.shape)\n    \nnp.save('bottleneck_features_train.npy', bottleneck_features_train) \n    \n    \n    \ngenerator = datagen.flow_from_directory(  \n     validation_data_dir,  \n     target_size=(img_width, img_height),  \n     batch_size=batch_size,  \n     class_mode=None,  \n     shuffle=False)  \n    \nnb_validation_samples = len(generator.filenames)  \npredict_size_validation = int(math.ceil(nb_validation_samples \/ batch_size))  \n    \nbottleneck_features_validation = model.predict_generator(  \n    generator, predict_size_validation)  \n\nprint(bottleneck_features_validation.shape)\n    \nnp.save('bottleneck_features_validation.npy', bottleneck_features_validation)","2c3a0381":"#extract bottleneck features for training\nfrom keras.callbacks import ModelCheckpoint\n\ndatagen_top = ImageDataGenerator(rescale=1.\/255) \n    \ngenerator_top = datagen_top.flow_from_directory(  \n         train_data_dir,  \n         target_size=(img_width, img_height),  \n         batch_size=batch_size,  \n         class_mode='categorical',  \n         shuffle=False)  \n    \n    \nnb_train_samples = len(generator_top.filenames)  \nnum_classes = len(generator_top.class_indices)  \n    \n# load the bottleneck features saved earlier  \ntrain_data = np.load('bottleneck_features_train.npy')  \n    \n# get the class labels for the training data, in the original order  \ntrain_labels = generator_top.classes\n    \n# convert the training labels to categorical vectors  \ntrain_labels = to_categorical(train_labels, num_classes=num_classes)  \ntrain_labels[0] # array of 81 elements","b5673734":"#extract bottleneck features for validation\ngenerator_top = datagen_top.flow_from_directory(  \n         validation_data_dir,  \n         target_size=(img_width, img_height),  \n         batch_size=batch_size,  \n         class_mode=None,  \n         shuffle=False)  \nnb_validation_samples = len(generator_top.filenames)  \nvalidation_data = np.load('bottleneck_features_validation.npy')  \n    \nvalidation_labels = generator_top.classes  \nvalidation_labels = to_categorical(validation_labels, num_classes=num_classes) \nvalidation_labels.shape\nvalidation_labels[0] # array of 81 elements","c4d79769":"#build the top model and start training\n\ncheckpointer = ModelCheckpoint('best_model.hdf5',save_best_only = True,verbose = 1)\n    \nmodel = Sequential()  \n# NOTE the shape given is the shape of the train_data saved in bottleneck features\nmodel.add(GlobalAveragePooling2D(input_shape=train_data.shape[1:]))\nmodel.add(Dense(81, activation='softmax'))\nmodel.summary()\n    \nmodel.compile(optimizer='rmsprop',  \n              loss='categorical_crossentropy', metrics=['accuracy']) \n    \nhistory = model.fit(train_data, train_labels,  \n          epochs=epochs,  \n          batch_size=batch_size,  \n          validation_data=(validation_data, validation_labels),\n          callbacks = [checkpointer])  \n    \nmodel.load_weights('best_model.hdf5')\n    \n(eval_loss, eval_accuracy) = model.evaluate(  \n     validation_data, validation_labels, batch_size=batch_size, verbose=1)\n\nprint(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))  \nprint(\"[INFO] Loss: {}\".format(eval_loss))","dbc9ec3b":"import matplotlib.pyplot as plt \nplt.figure(1)  \n   \n # summarize history for accuracy  \n   \nplt.subplot(211)  \nplt.plot(history.history['acc'])  \nplt.plot(history.history['val_acc'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \n   \n # summarize history for loss  \n   \nplt.subplot(212)  \nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.show()","639eb8b8":"In this kernel, I am going to build a model using VGG-16 bottleneck features.  When we say that we are going to use bottleneck features of a pre-trained model like VGG-16, we mean that we are going to remove the final layers of the VGG-16 model i.e. we are going to remove the high level classification layers(specific to the VGG 16 model labels). We will then pass our training and validation data through this model once and record the output into two arrays (one for training set and one for validation set) which are the bottleneck features for training and validation data. It is basically extracting patterns out of our dataset using the VGG-16 architecture. Then, we train a small fully connected model on top of these features. Let's get started !\n\nIn this dataset, we have a total of 55244 images which are divided into two folders - training set of 41322 images and testing set of 13877 images. The size of the given images is 100 * 100. We have 81 classes of fruits. Let's get started!\n","2572f564":"We have got validation accuracy of ~95% in just 20 epochs using VGG-16 bottleneck features. We can visualize the loss and accuracy wrt epochs with graph below."}}