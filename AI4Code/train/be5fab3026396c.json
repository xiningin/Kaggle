{"cell_type":{"f8560da2":"code","c7b04e05":"code","ad43fc50":"code","adac1e63":"code","f39d45f0":"code","bb73e24d":"code","073c71c8":"code","d2bd2e73":"code","b424420c":"code","3571d8a0":"code","9118849c":"code","7dc24d84":"code","eee132e0":"code","bfad6801":"code","bd826a78":"code","b19128d0":"code","2beb84aa":"code","b20038d5":"code","12bb419a":"code","6fde3738":"code","1282c96f":"code","803a9df3":"code","0c2ef5ef":"code","19f656a1":"code","3dd3a971":"code","82363d42":"code","3b444100":"code","6f61c422":"code","52a2259b":"code","d0d548b8":"code","e2172062":"code","c1ee7c8b":"code","f34af1ac":"code","15ff9188":"code","ebe5b9a2":"code","28868b69":"code","99babb7f":"code","d834b42d":"code","f39f6a3e":"code","804e3edf":"code","274ff249":"code","e943940c":"code","7c2c901b":"code","23a26f6c":"markdown","9fda278f":"markdown","6ad6b795":"markdown","86d7b336":"markdown","c777df38":"markdown","f671c491":"markdown","70a00839":"markdown"},"source":{"f8560da2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c7b04e05":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","ad43fc50":"df=pd.read_csv('..\/input\/heart-disease-data\/heart_disease_uci.csv')\ndf.sample(5)","adac1e63":"df.info()","f39d45f0":"df.duplicated().sum()","bb73e24d":"df.isna().sum()","073c71c8":"#dropping null values\ndf.dropna(inplace=True)\ndf.isnull().sum()","d2bd2e73":"df.sex.value_counts()","b424420c":"df['sex']=df['sex'].apply(lambda x:0 if x=='Male' else 1)\ndf['sex'].value_counts()","3571d8a0":"df['dataset'].value_counts()","9118849c":"df['dataset']=df['dataset'].apply(lambda x:0 if x== 'Cleveland' else 1 if x=='Hungary'else 2)\ndf['dataset'].value_counts()","7dc24d84":"df['cp'].value_counts()","eee132e0":"df['cp']=df['cp'].apply(lambda x:0 if x== 'typical angina' else 1 if x=='asymptomatic'else 2 if x=='non-anginal'else 3)\ndf['cp'].value_counts()","bfad6801":"df['fbs'].value_counts()","bd826a78":"df['fbs']=pd.get_dummies(df['fbs'],drop_first=True)","b19128d0":"df['exang'].value_counts()","2beb84aa":"df['exang']=pd.get_dummies(df['exang'],drop_first=True)","b20038d5":"df['restecg'].value_counts()","12bb419a":"df['restecg']=df['restecg'].apply(lambda x:0 if x== 'lv hypertrophy' else 1 if x=='normal'else 2)\ndf['restecg'].value_counts()","6fde3738":"df['slope'].value_counts()","1282c96f":"df['slope']=df['slope'].apply(lambda x:0 if x== 'downsloping' else 1 if x=='flat'else 2)\ndf['slope'].value_counts()","803a9df3":"df['thal'].value_counts()","0c2ef5ef":"df['thal']=df['thal'].apply(lambda x:0 if x== 'fixed defect' else 1 if x=='normal'else 2)\ndf['thal'].value_counts()","19f656a1":"for i in df.iloc[0:,:-1].columns:\n    sns.boxplot(df[i],data=df)\n    print(i)\n    plt.show()","3dd3a971":"l=[5,6,9,11,13]\ndef outlier(df):\n    for x in df.iloc[:,l].columns :        \n        Q1=df[x].quantile(0.25)\n        Q3=df[x].quantile(0.75)\n        IQR=Q3-Q1\n        Lower = Q1-(1.5*IQR)\n        Upper = Q3+(1.5*IQR)\n        df.loc[:,x]= np.where(df[x].values > Upper, Upper-1, df[x].values)\n        df.loc[:,x]= np.where(df[x].values < Lower, Lower+1, df[x].values)\n\noutlier(df)","82363d42":"for i in df.iloc[0:,:-1].columns:\n    sns.boxplot(df[i],data=df)\n    print(i)\n    plt.show()","3b444100":"# heatmap \n\ncorr = df.corr()\nplt.figure(figsize=(14,14))\nsns.heatmap(corr, annot=True, fmt= '.2f',annot_kws={'size': 15}, cmap= 'coolwarm')\nplt.show()\nprint(corr)","6f61c422":"df.corr()['num']","52a2259b":"# Plot a histogram\n\ndf.num.hist(bins=30, alpha=0.5)\nplt.show()","d0d548b8":"df['num'].unique()","e2172062":"from sklearn.model_selection import train_test_split","c1ee7c8b":"X=df.drop(['num','id'],axis=1)\ny=df['num']\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=2)","f34af1ac":"from sklearn.tree import DecisionTreeClassifier\n\nclf=DecisionTreeClassifier(criterion= 'entropy', max_depth= 10, max_features= 10, min_samples_leaf= 12, min_samples_split= 25)","15ff9188":"#Scaling the data\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nmin_max=MinMaxScaler()\n\nX_train_transformed=min_max.fit_transform(X_train)\n\nX_test_transformed=min_max.transform(X_test)","ebe5b9a2":"clf.fit(X_train_transformed,y_train)","28868b69":"pred=clf.predict(X_test_transformed)\npred","99babb7f":"train_pred=clf.predict(X_train_transformed)\ntrain_pred","d834b42d":"from sklearn.metrics import accuracy_score","f39f6a3e":"accuracy_score(y_test,pred)","804e3edf":"accuracy_score(y_train,train_pred)","274ff249":"from sklearn import metrics","e943940c":"print(metrics.classification_report(y_test,pred))","7c2c901b":"print(metrics.classification_report(y_train,train_pred))","23a26f6c":"**Importing Libraries**","9fda278f":"**Building A Model**","6ad6b795":"**Converting DataTypes Of Features**","86d7b336":"**Splitting Data**","c777df38":"**Treating Outliers**","f671c491":"**Reading Data**","70a00839":"**Evaluating The Model**"}}