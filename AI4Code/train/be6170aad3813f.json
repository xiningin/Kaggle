{"cell_type":{"03fca704":"code","98a10214":"code","d3c0e11c":"code","eab10a66":"code","9875f877":"code","bf44de97":"code","c6deee8e":"code","a037dd1d":"code","a25b36cb":"code","e8a022ae":"code","dd319b55":"markdown","cdfd91df":"markdown","4f477411":"markdown","914aa9e0":"markdown"},"source":{"03fca704":"!pip install lofo-importance","98a10214":"import pandas as pd\nfrom sklearn.model_selection import KFold\nfrom lightgbm import LGBMRegressor\nfrom lofo import LOFOImportance, plot_importance\nimport numpy as np\nfrom tqdm import tqdm_notebook\nimport matplotlib.pylab as plt\n%matplotlib inline","d3c0e11c":"TARGET_COL = \"scalar_coupling_constant\"\nGIBA_TO_DROP_COLS = [\"id\", \"molecule_name\",\n                     \"atom_index_0\", \"atom_index_1\",\n                     \"scalar_coupling_constant\",\n                     \"type\",\n                     \"ID\",\n                     \"structure_atom_0\", \"structure_atom_1\",\n                     \"structure_x_0\", \"structure_y_0\", \"structure_z_0\",\n                     \"structure_x_1\", \"structure_y_1\", \"structure_z_1\",\n                     \"typei\", \"pos\",\n                     \"R0\", \"R1\", \"E0\", \"E1\", \"Unnamed: 0\",\n                     \"molecule_name.1\", \"atom_index_1.1\", \n                     \"dataset\"]\n\nPARAMS = {\n     \"boosting_type\":\"gbdt\",\n     \"objective\": \"regression_l2\",\n     \"learning_rate\": 0.15,\n     \"num_leaves\": 255,\n     \"sub_feature\": 0.50,\n     \"sub_row\": 0.75,\n     \"bagging_freq\": 1,\n     \"metric\": 'mae'\n}\n\nSEED = 314\nN_SPLITS = 3","eab10a66":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(\n            end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","9875f877":"df = pd.read_csv(\"..\/input\/giba_features.csv.gz\")\ntrain_df = df.loc[lambda df: ~(df[TARGET_COL].isnull()), :]\ntrain_df = reduce_mem_usage(train_df)","bf44de97":"FEATURES_COLS = train_df.drop(GIBA_TO_DROP_COLS, axis=1, errors=\"ignore\").columns.tolist()","c6deee8e":"# Fix the CV seed for reproducibilty\nCV = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)","a037dd1d":"dfs = []\n\nfor _type in tqdm_notebook(train_df['type'].unique()):\n    print(f'LOFO importance for {_type}')\n    type_train_df = train_df.loc[lambda df: df['type'] == _type].reset_index(drop=True)\n    model = LGBMRegressor(**PARAMS)\n    lofo_imp = LOFOImportance(type_train_df, FEATURES_COLS, TARGET_COL, cv=CV, \n                              scoring=\"neg_mean_absolute_error\", model=model)\n    _df = lofo_imp.get_importance()\n    _df['type'] = _type\n    dfs.append(_df)\n\nimportance_df = pd.concat(dfs)\nimportance_df.to_csv('lofo_giba_features.csv', index=False)","a25b36cb":"# I have adapted the one from the LOFO lib to add a title and get the figure.\ndef plot_importance(importance_df, figsize=(8, 8), ax=None):\n    if ax is None:\n        fig, ax = plt.subplots(1, 1)\n    importance_df = importance_df.copy()\n    importance_df[\"color\"] = (importance_df[\"importance_mean\"] > 0).map({True: 'g', False: 'r'})\n    importance_df.sort_values(\"importance_mean\", inplace=True)\n\n    importance_df.plot(x=\"feature\", y=\"importance_mean\", xerr=\"importance_std\",\n                       kind='barh', color=importance_df[\"color\"], figsize=figsize, ax=ax)\n    return ax","e8a022ae":"for _type in importance_df['type'].unique():\n    ax = plot_importance(importance_df.loc[lambda df: df['type'] == _type].drop('type', axis=1), \n                    figsize=(12, 20))\n    ax.set_title(f'LOFO importance plot for {_type}')\n    ax.get_figure().savefig(f'lofo_importance_{_type}.png')","dd319b55":"As promised in this [thread](https:\/\/www.kaggle.com\/c\/champs-scalar-coupling\/discussion\/99125#latest-571188), here is a notebook to get the [LOFO](https:\/\/github.com\/aerdem4\/lofo-importance) importance using [Giba's features](https:\/\/www.kaggle.com\/titericz\/giba-r-data-table-simple-features-1-17-lb). [](http:\/\/)","cdfd91df":"# Import Giba's features","4f477411":"# Build the features' importance DataFrame","914aa9e0":"# Plot the results"}}