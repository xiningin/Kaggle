{"cell_type":{"8fa8ee2e":"code","5738919a":"code","38cf4ab1":"code","89086369":"code","6751cc81":"code","cbef480e":"code","6c5cc4e4":"code","7609a06d":"code","c5937a97":"code","3d2f3270":"code","0ae8876d":"code","bbf00377":"code","e8c45d29":"code","4bc3e26a":"code","8604ff61":"code","1abe9674":"code","597fa114":"code","396efbbe":"code","81cd716f":"code","345b92e9":"markdown","729aee20":"markdown","55555c88":"markdown","e1eaa1c1":"markdown","644ac005":"markdown","648555d9":"markdown","201b3409":"markdown","8c9c9cdb":"markdown","b5ed16a2":"markdown","51c9a550":"markdown","f51cd5f6":"markdown","b31ba9a3":"markdown","7c7cb5fb":"markdown","46b3c758":"markdown","c88cf235":"markdown","47ec9e4d":"markdown"},"source":{"8fa8ee2e":"# Import Libraries\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB","5738919a":"# Load the course data files for English into a dataframe using Pandas\ndataframe_english = pd.read_csv(r\"..\/input\/concretext-dataset\/CONcreTEXT_trial_EN.tsv\", sep = \"\\t\")\ndataframe_english","38cf4ab1":"# Add a new column to the dataframe with the same value\ndataframe_english['LANGUAGE'] = 'ENGLISH'\ndataframe_english","89086369":"# Load the course data files for Italian into a dataframe using Pandas\ndataframe_italian = pd.read_csv(r\"..\/input\/concretext-dataset\/CONcreTEXT_trial_IT.tsv\", sep = \"\\t\")\ndataframe_italian","6751cc81":"# Add a new column to the dataframe with the same value\ndataframe_italian['LANGUAGE'] = 'ITALIAN'\ndataframe_italian","cbef480e":"# Question-1\n# Combining both the dataframes using concat function in pandas\ncombined_dataframe = pd.concat([dataframe_english, dataframe_italian])\ncombined_dataframe","6c5cc4e4":"combined_text_column = combined_dataframe['TEXT']\ncombined_text_column.head(5)","7609a06d":"# # Spliting the training and test data set in 80% : 20% using train_test_split\n\n# combined_df_train, combined_df_test = train_test_split(combined_dataframe['TEXT'], test_size=0.2, shuffle=True, random_state=42)\n\n# print(\"\\t English Language Train data: \\n\\n\", combined_df_train.head(5), \"\\n\\n Length of the Train data is: \", len(combined_df_train))\n# print('\\n')\n# print(\"***********************************************************\")\n# print('\\n')\n# print(\"\\t English Language Test data: \\n\\n\", combined_df_test.head(5), \"\\n\\n Length of the Train data is: \", len(combined_df_test))","c5937a97":"# # X = combined_dataframe['TEXT'].values\n# # y = combined_dataframe['LANGUAGE'].values\n\n# # X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, shuffle=True, random_state=42)\n\n# # print('X_train:', X_train.shape)\n# # print('X_test:', X_test.shape)\n# # print('y_train:', y_train.shape)\n# # print('y_test:', y_test.shape)","3d2f3270":"# CountVectorizer() is used for Text preprocessing, tokenizing and filtering of stopwords in the given text.\ncount_vect = CountVectorizer()\ncombined_text_column_count_vect = count_vect.fit_transform(combined_text_column)\ncombined_text_column_count_vect.shape","0ae8876d":"count_vect","bbf00377":"combined_text_column_count_vect","e8c45d29":"# TfidfTransformer() is used for converting the words occurrences to frequencies\ntfidf_transformer = TfidfTransformer()\ncombined_text_column_count_vect_tfidf = tfidf_transformer.fit_transform(combined_text_column_count_vect)\ncombined_text_column_count_vect_tfidf.shape","4bc3e26a":"naive_bayes_model = MultinomialNB().fit(combined_text_column_count_vect_tfidf, combined_dataframe['LANGUAGE'])\nnaive_bayes_model","8604ff61":"category = combined_dataframe['LANGUAGE'].unique()\ncategory\n# category = ['ENGLISH', 'ITALIAN']","1abe9674":"docs_new = ['Why does a rose smell sweet?', 'Pensa ai tuoi sentimenti di amore.']\nX_new_counts = count_vect.transform(docs_new)\nX_new_tfidf = tfidf_transformer.transform(X_new_counts)\n\npredicted = naive_bayes_model.predict(X_new_tfidf)\npredicted\n\nfor doc, category in zip(docs_new, predicted):\n    #print(predicted)\n    print('%r => %s' % (doc, category))","597fa114":"# Testing the model with the sentences in the dataset\ndocs_new = ['In questo modo non dovrai creare spazio sul tuo cellulare per il file di aggiornamento .', \n            'Please list people you have helped', \n            'Se la ricetta ti indica di cucinare il pollo non spellato', \n            'Expand your repertoire of brain games', \n            'Part of loving life is to not be ruled by fear , which will suffocate you in unhappiness .']\nX_new_counts = count_vect.transform(docs_new)\nX_new_tfidf = tfidf_transformer.transform(X_new_counts)\n\npredicted = naive_bayes_model.predict(X_new_tfidf)\n\nfor doc, category in zip(docs_new, predicted):\n    print('%r => %s' % (doc, category))","396efbbe":"# Testing the model with the sentences of my own\ndocs_new = ['The team played really well and they won the match with full domination.', \n            'Una bella ragazza cammina per strada', \n            'Lucia ha paura', \n            'Cricket is an International game followed by many people', \n            'The problem is not that big as you think !!']\nX_new_counts = count_vect.transform(docs_new)\nX_new_tfidf = tfidf_transformer.transform(X_new_counts)\n\npredicted = naive_bayes_model.predict(X_new_tfidf)\n\nfor doc, category in zip(docs_new, predicted):\n    print('%r => %s' % (doc, category))","81cd716f":"docs_new = ['stesse frasi brodo', \n            'Hai Bravo, pizza?', \n            'Lucia Credibile Prestazione ',\n            'Domani pioggia intensa', \n            'Carla parla inglese?', \n            'Amo MS Dhoni']\nX_new_counts = count_vect.transform(docs_new)\nX_new_tfidf = tfidf_transformer.transform(X_new_counts)\n\npredicted = naive_bayes_model.predict(X_new_tfidf)\n\nfor doc, category in zip(docs_new, predicted):\n    print('%r => %s' % (doc, category))","345b92e9":"<a id=\"Question 2 Answer_CV\">\n<\/a>\n\n## Question-2 Answer - Count Vectorizer","729aee20":"<a id=\"Question 3 Answer_Naive_Bayes\">\n<\/a>\n\n## Question-3 Answer - Multinomial Naive Bayes","55555c88":"<a id=\"Question 1 Answer\">\n<\/a>\n\n## Question-1 Answer - Combined Dataframe - English & Italian","e1eaa1c1":"## Observation\nFrom the above result, we can see that all the 5 sentences were guessed correctly by the model and predicted the correct language appropriately with 100% accuracy.","644ac005":"<a id=\"Question 2 Answer_TFIDF\">\n<\/a>\n\n## Question-2 Answer - TFIDF","648555d9":"<a href=\"#Question 5 Answer_predict_the_language_5_sentences\" style=\"color:blue;\">Click here to have a look at Answer to Predict the language for 5 other sentences<\/a>","201b3409":"<a href=\"#Extra_credit\" style=\"color:blue;\">Click here to have a look at the Extra Credit - Testing the model on a sentence of your own that the model predicts incorrectly<\/a>","8c9c9cdb":"<a href=\"#Question 2 Answer_TFIDF\" style=\"color:blue;\">Click here to have a look at Answer to Question-2 TFIDF<\/a>","b5ed16a2":"<a id=\"Question 5 Answer_predict_the_language_5_sentences\">\n<\/a>\n\n## Question-5 Answer - Predict the language for 5 other sentences","51c9a550":"<a id=\"Question 4 Answer_predict_the_language\">\n<\/a>\n\n## Question-4 Answer - Predict the language","f51cd5f6":"<a href=\"#Question 4 Answer_predict_the_language\" style=\"color:blue;\">Click here to have a look at Answer to Question-4 -Predict the language TFIDF<\/a>","b31ba9a3":"## Observation\n\nIn the above result, first, third, fourth and final sentences are actaully Italian but the model predicted them wrongly as English.\nThe second sentence is English but the model predicted it wrongly as Italian.","7c7cb5fb":"<a href=\"#Question 1 Answer\" style=\"color:blue;\">Click here to have a look at Answer to Question-1 Combined dataframe<\/a>","46b3c758":"<a href=\"#Question 3 Answer_Naive_Bayes\" style=\"color:blue;\">Click here to have a look at Answer to Question-3 Multinomial Naive Bayes<\/a>","c88cf235":"<a id=\"Extra_credit\">\n<\/a>\n\n## Extra Credit - Testing the model on a sentence of your own that the model predicts incorrectly","47ec9e4d":"<a href=\"#Question 2 Answer_CV\" style=\"color:blue;\">Click here to have a look at Answer to Question-2 Count Vectorizer<\/a>"}}