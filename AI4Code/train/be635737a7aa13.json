{"cell_type":{"5c794597":"code","945c82b5":"code","3256c2ed":"code","8356ce0f":"code","78113671":"code","4ef8a007":"code","153edccf":"code","f3199d5e":"code","33dda32d":"code","c71e58f2":"code","44774352":"code","0a9a074f":"code","b8630c3c":"code","9cb94c12":"code","27e2e5dd":"code","733308bc":"code","e5abd98a":"code","32873fda":"code","9fb1751d":"code","102043ce":"code","1286d2a1":"code","209f45db":"code","5ae911a9":"code","66bfa421":"code","3f01d5ff":"code","77c49bf7":"code","8eb00a21":"code","1ce0cc8e":"code","11c6dc6b":"code","a303ccb5":"markdown","8d3986ec":"markdown","b95aff4e":"markdown","a2e145f2":"markdown","0524dc25":"markdown","c8a728fd":"markdown","764a52f8":"markdown","a50035f4":"markdown","832c53be":"markdown","ee2e917b":"markdown","67013aef":"markdown","585f8840":"markdown"},"source":{"5c794597":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom collections import OrderedDict\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\nfrom xgboost import plot_importance\nfrom sklearn.model_selection import train_test_split as split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve, auc,roc_auc_score\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","945c82b5":"colspecs=[[12,14],[78,79],[106,107],\n          [119,120],[123,124],[148,150],[152,153],[162,163],[170,172],[173,174],\n          [174,176],[181,182],[200,202],[216,218],[223,225],[241,243],\n          [250,251],[260,261],[261,262],[262,263],[263,264],[268,269],[279,281],[286,287],[291,294],\n          [312,313],[313,314],[314,315],[315,316],[316,317],[317,318],\n          [324,325],[325,326],[326,327],[331,333],[336,337],[342,343],[343,344],[344,345],\n          [345,346],[346,347],[352,353],[359,360],[360,361],[474,475],[491,493]]\nnames=['birth_month','mother_age9','mother_race6',\n       'marital_status','mother_edu','father_age11','father_race6','father_edu','prior_births_living','prior_births_dead',\n       'prior_terminations','birth_order_num','interval_last_birth11','interval_last_pregn11','month_prenatal_care','prenatal_visits',\n       'WIC','cig_before','cig_1_trim','cig_2_trim','cig_3_trim','smoker','mother_height','mother_BMI','mother_pre_weight',\n       'pre_diabetes','gest_diabetes','pre_hypertension','gest_hypertension','hypertasion_eclampsia','prev_preterm_births',\n       'infertility_treat','fert_enhancing','asst_reproduct','num_prev_cesarean','no_risk_factors','gonorrhea','syphilis','chlamydia',\n       'hepat_B','hepat_C','no_infections','successful_external_cephalic','failed_external_cephalic','infant_sex','gest_weeks10']\ndata2016 = pd.read_fwf('..\/input\/us-birth-data-from-cdc\/Nat2016PublicUS.c20170517.r20170913.txt',header=None,colspecs=colspecs,names=names)\ndata2016.head()","3256c2ed":"data2016 = data2016.replace({'N': 0, 'Y': 1, 'U': np.nan, 'X':np.nan})\ndata2016['mother_race6'] = data2016['mother_race6'].replace({6:np.nan})\ndata2016['father_race6'] = data2016['father_race6'].replace({6:np.nan,9:np.nan})\ndata2016['marital_status'] = data2016['marital_status'].replace({3:2, 9:np.nan})\ndata2016['father_age11'] = data2016['father_age11'].replace({11:np.nan})\ndata2016['mother_BMI'] = data2016['mother_BMI'].replace({99.9:np.nan})\ndata2016 = pd.get_dummies(data2016, columns=['infant_sex'])\ndata2016['target'] = np.where(data2016['gest_weeks10']<6, 1, 0)\n\ncols9 = ['mother_edu','father_edu','birth_order_num','no_risk_factors','no_infections']\nfor i in cols9:\n    data2016[i] = data2016[i].replace({9:np.nan})\ncols99 = ['prior_births_living','prior_births_dead','prior_terminations','month_prenatal_care','prenatal_visits','cig_before'\n         ,'cig_1_trim','cig_2_trim','cig_3_trim','mother_height','num_prev_cesarean','gest_weeks10']\nfor i in cols99:\n    data2016[i] = data2016[i].replace({99:np.nan})\ncols88 = ['interval_last_birth11','interval_last_pregn11']\nfor i in cols88:\n    data2016[i] = data2016[i].replace({88:np.nan,99:np.nan})\ncols999 = ['mother_pre_weight']\nfor i in cols999:\n    data2016[i] = data2016[i].replace({999:np.nan})","8356ce0f":"def missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns\n    \n    \n    \nmissing_values_table(data2016)","78113671":"missing_df = missing_values_table(data2016);\nmissing_columns = list(missing_df[missing_df['% of Total Values'] > 10].index)\ndata2016 = data2016.drop(columns = list(missing_columns))\ndata2016 = data2016.dropna()","4ef8a007":"data2016 = data2016.drop(columns = ['birth_month','no_risk_factors','no_infections','smoker','prenatal_visits'])","153edccf":"data2016 = pd.get_dummies(data2016, columns=['marital_status','WIC','pre_diabetes','gest_diabetes','pre_hypertension',\n                                            'gest_hypertension','hypertasion_eclampsia','prev_preterm_births','infertility_treat',\n                                            'gonorrhea','syphilis','chlamydia','hepat_B','successful_external_cephalic'\n                                            ,'failed_external_cephalic'])","f3199d5e":"data2016.shape","33dda32d":"c = ['r' if i <6 else 'b' for i in list(range(1,11))]\ndata2016.groupby(['gest_weeks10']).size().plot(kind='bar',color = c, title = 'Gestation weeks bins')\nplt.show()","c71e58f2":"#corr = data2016.drop(columns = ['gest_weeks10']).corr()\n#corr.style.background_gradient().set_precision(2)","44774352":"t = data2016['target'].size\ngr_tab = pd.DataFrame()\ngr_tab['qnt'] = data2016.groupby(['target']).size() \ngr_tab['per'] = (data2016.groupby(['target']).size() \/t)*100\ngr_tab","0a9a074f":"train,test = split(data2016.drop(columns = ['gest_weeks10']),train_size = 0.8)","b8630c3c":"t = train['target'].size\ngr_tab = pd.DataFrame()\ngr_tab['qnt'] = train.groupby(['target']).size() \ngr_tab['per'] = (train.groupby(['target']).size() \/t)*100\nprint ('train: \\n ',gr_tab)","9cb94c12":"data2016all = train\ntrain = data2016all[data2016all['target']==1]\nd = data2016all[data2016all['target']==0].sample(n=314000)\ntrain = train.append(d)\n\nt = train['target'].size\ngr_tab = pd.DataFrame()\ngr_tab['qnt'] = train.groupby(['target']).size() \ngr_tab['per'] = (train.groupby(['target']).size() \/t)*100\nprint ('train: \\n ',gr_tab)\n\nt = test['target'].size\ngr_tab = pd.DataFrame()\ngr_tab['qnt'] = test.groupby(['target']).size() \ngr_tab['per'] = (test.groupby(['target']).size() \/t)*100\nprint ('test: \\n ',gr_tab)","27e2e5dd":"X_train = train.drop(columns = ['target'])\ny_train = train.target\nX_test = test.drop(columns = ['target'])\ny_test = test.target","733308bc":"scaler = MaxAbsScaler()\nsclr = scaler.fit(X_train)\nX_train = sclr.transform(X_train)\nX_test = sclr.transform(X_test)","e5abd98a":"rfc = RandomForestClassifier(max_depth=8,n_estimators=10).fit(X_train,y_train)\nrfc_auc = roc_auc_score(y_test, rfc.predict(X_test))\n","32873fda":"#knn = KNeighborsClassifier(n_neighbors=5).fit(X_train,y_train)\n#knn_auc = roc_auc_score(y_test, knn.predict(X_test))","9fb1751d":"logrg = LogisticRegression().fit(X_train,y_train)\nlog_auc = roc_auc_score(y_test, logrg.predict(X_test))","102043ce":"linrg = LinearRegression().fit(X_train,y_train)\nlin_auc = roc_auc_score(y_test, linrg.predict(X_test).round())","1286d2a1":"#svc = SVC(kernel='linear', class_weight='balanced',probability=True).fit(X_train,y_train)\n#svc_auc = roc_auc_score(y_test, svc.predict(X_test))","209f45db":"xgbm = xgb.XGBModel().fit(X_train,y_train)\nxgb_auc = roc_auc_score(y_test, xgbm.predict(X_test).round())","5ae911a9":"print('RandomForest test AUC: ',rfc_auc)\n#print('K nearest neighbors test AUC: ',knn_auc)\nprint('Logistic regression test AUC: ',log_auc)\nprint('Linear regression test AUC: ',lin_auc)\nprint('XGBoost test AUC: ',xgb_auc)","66bfa421":"def report(clf, X, y):\n    acc = accuracy_score(y_true=y, y_pred=clf.predict(X).round())\n    auc = roc_auc_score(y, clf.predict(X).round())\n    cm = confusion_matrix(y_true=y, y_pred=clf.predict(X).round())\n    rep = classification_report(y_true=y,y_pred=clf.predict(X).round())\n    return 'accuracy {:.3f}\\nauc {:.3f}\\n\\n{}\\n\\n{}'.format(acc,auc, cm, rep)","3f01d5ff":"print('train report: ',report(xgbm,X_train,y_train))\nprint('test report: ',report(xgbm,X_test,y_test))","77c49bf7":"plot_importance(xgbm)\nplt.show()","8eb00a21":"cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\nind_params = {'learning_rate': 0.3, 'n_estimators': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, \n             'objective': 'binary:logistic'}\n\ngbm = xgb.XGBClassifier(**ind_params).fit(X_train, y_train)\n\noptimized_GBM = GridSearchCV(gbm, cv_params, scoring = 'roc_auc', cv = 5, n_jobs = 1) \n\noptimized_GBM.fit(X_train, y_train)\n\npredictions_opt = optimized_GBM.predict(X_test)\n#best_est = rs.best_estimator_\n#print(best_est)","1ce0cc8e":"opt_xgb_auc = roc_auc_score(y_test, predictions_opt)\nprint ('Test auc: ',opt_xgb_auc)","11c6dc6b":"best_est = optimized_GBM.best_estimator_\nprint(best_est)","a303ccb5":"I decided to drop a few more columns: \n* month (don't seem to have value for prediction)\n* no_risk_factors, no_infections, smoker (reflecting other features)\n* prenatal_visits (feature affected by pregnancy length)","8d3986ec":"# Preprocessing","b95aff4e":"\nWe have unbalanced data. I'll solve it by sampling over-presented class in train data (test data will remain unbalanced). ","a2e145f2":"# Exploration","0524dc25":"Basic models evaluation:","c8a728fd":"Checking for missing values: ","764a52f8":"This kernel based on CDC data for US births in 2016.\nThe purpose was to predict preterm birth.\nPreterm is [defined](https:\/\/www.who.int\/news-room\/fact-sheets\/detail\/preterm-birth) as babies born alive before 37 weeks of pregnancy are completed. ","a50035f4":"Droping columns with more then 10% missing values.\nThen droping rows with remining missing values, since I have enough obsevations. ","832c53be":"Gestation codes:\n01 Under 20 weeks \n02 20-27 weeks\n03 28-31 weeks\n04 32-33 weeks\n05 34-36 weeks\n06 37-38 weeks\n07 39 weeks \n08 40 weeks\n09 41 weeks\n10 42 weeks and over\n99 Unknown ","ee2e917b":"I'll continue with XGBoost","67013aef":"# Modeling","585f8840":"First, I go through all columns and replace any type of missing value with \"nan\".\nI can't run simple \"replace\" for all \"other\" values (\"9\",\"99\",\"U\" etc.) because depending on columns, it can be a valid info (for example in columns of height, BMI etc.).\nAlso I replace N\/Y values with 0\/1. "}}