{"cell_type":{"1330bbf2":"code","190fac8d":"code","fe00eba7":"code","7e43e39c":"code","4293234a":"code","765de171":"code","8057b01e":"code","1133c1b0":"code","207eaec7":"code","8d363639":"code","f7cbe4d1":"code","b37a038d":"code","b86ae906":"code","7c71ac3e":"code","567d1241":"code","29088566":"code","3654deba":"code","c1a73dc7":"code","6fc3eba5":"code","0fa76381":"code","521a9fd8":"code","e09c73f5":"code","f9bec5a5":"code","ba7daaea":"code","f051d402":"code","b4fb35ab":"code","183c0c15":"code","7418b5aa":"code","dd8b66cd":"code","7dfd6ed1":"code","dcf68c00":"code","94c82a4e":"code","abdb4df4":"code","2d719fbf":"code","e5e19469":"code","d8684ba4":"code","3ef33001":"markdown","d3acedc5":"markdown","fc5debb0":"markdown","7a902d3f":"markdown","0a801845":"markdown","c45bac70":"markdown","c15c2511":"markdown","7cab6f57":"markdown"},"source":{"1330bbf2":"import os\nimport cv2\nfrom glob import glob\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport PIL\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nimport torchvision\nfrom torchvision import transforms","190fac8d":"labels = pd.read_csv ('..\/input\/data\/Data_Entry_2017.csv')\nlabels.sample (3)","fe00eba7":"pathology_list = ['Cardiomegaly', 'Emphysema', 'Effusion', 'Hernia', 'Nodule', 'Pneumothorax', 'Atelectasis',\n                  'Pleural_Thickening', 'Mass','Edema', 'Consolidation', 'Infiltration', 'Fibrosis', 'Pneumonia']\n\n# multi hot encoding\nfor pathology in pathology_list :\n    labels [pathology] = labels ['Finding Labels'].apply (lambda x: 1 if pathology in x else 0)\n\nlabels ['No Findings'] = labels ['Finding Labels'].apply (lambda x: 1 if 'No Finding' in x else 0)\nlabels.sample (3)","7e43e39c":"labels = labels.drop (list (labels.iloc [:,1:12].columns.values), axis = 1) #12\nlabels.head (3)","4293234a":"# removing No Finding patient images and its label\nindexes = []\nfor i in range (len (labels)):\n    if labels.iloc [i, 15] == 1:\n        indexes.append (i)\n# remove indexes\nlabels = labels.drop (indexes, axis = 0)\n# remove column\nlabels = labels.drop(['No Findings'],axis = 1)\n# reset indexes\nlabels = labels.reset_index ()\n\nprint ('number of patients:', len (labels))\nlabels.head (3)","765de171":"# removing multi label patients\nidxs = []\nfor i in range (len (labels)):\n    if len (np.where (labels.iloc [i] == 1)[0]) > 1:\n        idxs.append (i)\nlabels = labels.drop (idxs, axis = 0)\nlabels = labels.reset_index ()\n\nprint ('number of unique patients:', len (labels))\nlabels.head (3)","8057b01e":"# adding path to dataframe\nall_image_paths = {os.path.basename(x): x for x in glob ('..\/input\/data\/images_*\/images\/*.png')}\nlabels ['path'] = labels ['Image Index'].map(all_image_paths.get)\nlabels.head (3)","1133c1b0":"# adding class idx to dataframe\nidx = []\nfor i in range (len (labels)):\n    idx.append (np.where (labels.iloc [i, 3:] == 1)[0].item ())\n    \nlabels ['class_idx'] = idx\nlabels.head (3)","207eaec7":"# remove additional columns\nlabels = labels.drop (list (labels.iloc [:,:17].columns.values), axis = 1)\nlabels.head (3)","8d363639":"# ploting distribution of classes\ncounts = labels.class_idx.value_counts ()\nclass_idx = counts.index\n\nplt.bar (class_idx, counts)","f7cbe4d1":"# img_dir = '..\/input\/sample\/sample\/sample\/images'\n# print ('number of images:', len (os.listdir (img_dir)))\nimg_channels = 1\n# from WGAN paper\nz_dim = 100\nbatch_size = 64\nimg_size = 64\n# features_c = 16\n# features_g = 16\n# lr = 5e-5 for WGAN\n# lr = 1e-4 for WPGAN\n# num_classes = 10\n# gen_embedding = 100\n# could also use two lrs, one for gen and one for critic\n# critic_iterations = 5\n# weight_clip = 0.01 for WGAN\n# lambda_gp = 10 for WPGAN","b37a038d":"class lungDataset (Dataset):\n    \"\"\" create dataset by using image path and their labels \"\"\"\n    def __init__ (self, labels, transform = None):\n        self.labels = labels\n        self.transform = transform\n        \n    def __len__ (self):\n        return len (self.labels)\n    \n    def __getitem__ (self, index):\n        image_path = self.labels.iloc [index][0]\n        image = PIL.Image.open (image_path).convert ('L')\n        \n        label = self.labels.iloc [index][1]\n\n        if self.transform is not None:\n            image = self.transform (image)\n            \n        return image, label","b86ae906":"# class lungDataset (Dataset):\n#     \"\"\"Create Unsupervised Dataset from sample NIH\"\"\"\n#     def __init__ (self, image_dir, transform = None):\n#         self.image_dir = image_dir\n#         self.images = os.listdir (image_dir)\n#         self.transform = transform\n        \n#     def __getitem__ (self, index):\n#         image_path = self.image_dir + '\/' + self.images [index]\n#         image = PIL.Image.open (image_path).convert ('L')\n        \n#         if self.transform is not None:\n#             image = self.transform (image)\n            \n#         return image\n    \n#     def __len__ (self):\n#         return len (self.images)","7c71ac3e":"tfms = transforms.Compose ([\n    transforms.Resize ((64, 64)),\n    transforms.ToTensor (),\n    transforms.Normalize (\n        [0.5 for _ in range (img_channels)], [0.5 for _ in range (img_channels)]\n    )\n])","567d1241":"# Create dataset and dataloader\ndataset = lungDataset (labels, transform = tfms)\ndataloader = DataLoader (dataset, batch_size = batch_size, shuffle = True)","29088566":"def imshow (img, title = None):\n    \"\"\" a function to show tensor images \"\"\"\n    img = img.numpy ().transpose (1, 2, 0)\n    mean = 0.5\n    std = 0.5\n    img = img * std + mean\n    img = np.clip (img, 0, 1)\n    \n    plt.figure (figsize = (10, 8))\n    plt.axis ('off')\n    plt.imshow (img)\n    if title:\n        plt.title (title)","3654deba":"# Visualize random batch of dataset\nimg, lbl = next (iter (dataloader))\nprint (img.shape)\nprint (lbl.shape)\nimg = torchvision.utils.make_grid (img, nrow = 8)\nimshow (img, 'Random Batch of Images')","c1a73dc7":"class Critic (nn.Module):\n    \"\"\" a model that judges between real and fake images \"\"\"\n    def __init__ (self, img_channels, features_c, num_classes = 14, img_size = 64):\n        super (Critic, self).__init__ ()\n        \n        # Input: N x channels_img x 64 x 64\n        self.critic = nn.Sequential (\n            nn.Conv2d (img_channels + 1, features_c, kernel_size = 4, stride = 2, padding = 1), # 32x32\n            nn.LeakyReLU (0.2),\n            self._block (features_c , features_c * 2, 4, 2, 1),                             # 16x16\n            self._block (features_c * 2, features_c * 4, 4, 2, 1),                          # 8x8\n            self._block (features_c * 4, features_c * 8, 4, 2, 1),                          # 4x4\n            nn.Conv2d (features_c * 8, 1, kernel_size = 4, stride = 2, padding = 0),        # 1x1\n        )\n        self.embed = nn.Embedding (num_classes, img_size * img_size)\n        self.img_size = img_size\n      \n    def _block (self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential (\n            nn.Conv2d (in_channels, out_channels, kernel_size, stride, padding, bias = False),\n            # for WGAN\n            # nn.BatchNorm2d (out_channels),\n            # for WPGAN\n            nn.InstanceNorm2d (out_channels, affine = True),\n            nn.LeakyReLU (0.2)\n        )\n    \n    def forward (self, x, labels):\n        embedding = self.embed (labels).view (labels.shape [0], 1, self.img_size, self.img_size)\n        x = torch.cat ([x, embedding], dim = 1) # N x C x img_size (H) x img_size (W)\n        return self.critic (x)","6fc3eba5":"class Generator (nn.Module):\n    \"\"\" a model generates fake images \"\"\"\n    def __init__ (self, z_dim, img_channels, features_g, embed_size, img_size = 64, num_classes = 14):\n        super (Generator, self).__init__ ()\n        self.img_size = img_size\n        # Input: N x z_dim x 1 x 1\n        self.gen = nn.Sequential (\n            self._block (z_dim + embed_size, features_g * 16, 4, 2, 0),                               # 4x4\n            self._block (features_g * 16, features_g * 8, 4, 2, 1),                      # 8x8\n            self._block (features_g * 8, features_g * 4, 4, 2, 1),                       # 16x16\n            self._block (features_g * 4, features_g * 2, 4, 2, 1),                       # 32x32\n            nn.ConvTranspose2d (\n                features_g * 2, img_channels, kernel_size = 4, stride = 2, padding = 1), # 64x64\n            nn.Tanh ()\n        )\n        self.embed = nn.Embedding (num_classes, embed_size)\n        \n    def _block (self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential (\n            nn.ConvTranspose2d (in_channels, out_channels, kernel_size, stride, padding, bias = False),\n            nn.BatchNorm2d (out_channels),\n            nn.ReLU ()\n        )\n    \n    def forward (self, x, labels):\n        # latent vector z: N x noise_dim x 1 x 1\n        embedding = self.embed (labels).unsqueeze (2).unsqueeze (3)\n        x = torch.cat ([x, embedding], dim = 1)\n        return self.gen (x)","0fa76381":"def initialize_weights (model):\n    for m in model.modules ():\n        if isinstance (m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n            nn.init.normal_ (m.weight.data, 0.0, 0.02)","521a9fd8":"def gradient_penalty (critic, images, labels, fake_images, device):\n    batch_size, C, W, H = images.shape\n    epsilon = torch.rand ((batch_size, 1, 1, 1)).repeat (1, C, H, W).to(device)\n    interpolated_images = images * epsilon + fake_images * (1 - epsilon)\n    \n    # calculate critic scores\n    mixed_scores = critic (interpolated_images, labels)\n    \n    gradient = torch.autograd.grad (\n        inputs = interpolated_images,\n        outputs = mixed_scores,\n        grad_outputs = torch.ones_like (mixed_scores),\n        create_graph = True,\n        retain_graph = True,\n    )[0]\n    \n    gradient = gradient.view (gradient.shape [0], -1)\n    gradient_norm = gradient.norm (2, dim = 1)\n    gradient_penalty = torch.mean ((gradient_norm - 1) ** 2)\n    \n    return gradient_penalty","e09c73f5":"def test ():\n    \"\"\" test function to test models \"\"\"\n    N, in_channels, H, W = 8, 1, 64, 64\n    x = torch.randn ((N, in_channels, H, W))\n    y = torch.randint (0, 9, (8,))\n    z_dim = 100\n    C = Critic(in_channels, 8)\n    initialize_weights (C)\n    assert C (x, y).shape == (N, 1, 1, 1)\n    G = Generator (z_dim, in_channels, 8, 100)\n    initialize_weights (G)\n    z = torch.randn ((N, z_dim, 1, 1))\n    assert G(z, y).shape == (N, in_channels, H, W)\n    print ('Succes')\n    \ntest ()","f9bec5a5":"# Hyper Function and Initializiation\ndevice = torch.device ('cuda' if torch.cuda.is_available () else 'cpu')\n\ncritic = Critic(img_channels = 1, features_c = 64).to(device)\ngen = Generator (z_dim = 100, img_channels = 1, features_g = 64, embed_size = 100).to(device)\n\ninitialize_weights (critic)\ninitialize_weights (gen)\n\n# WPGAN\ncritic_optimizer = torch.optim.Adam (critic.parameters (), lr = 1e-4, betas = (0.0, 0.9))\ngen_optimizer = torch.optim.Adam (gen.parameters (), lr = 1e-4, betas = (0.0, 0.9))\n\n# WGAN\n# critic_optimizer = torch.optim.RMSprop (critic.parameters (), lr = 5e-5)\n# gen_optimizer = torch.optim.RMSprop (gen.parameters (), lr = 5e-5)","ba7daaea":"def denorm (x):\n    out = x * 0.5 + 0.5\n    return out.clamp (0, 1)","f051d402":"def train_critic (critic, images, labels, critic_iteration, device):\n    critic.train ()\n    \n    batch_size = images.shape [0]\n    images = images.to(device)\n    labels = labels.to(device)\n    \n    for _  in range (critic_iteration):\n        z = torch.randn (batch_size, z_dim, 1, 1).to(device)\n        fake_images = gen (z, labels).to(device)\n        \n        # scores\n        real_score = critic (images, labels).reshape (-1)\n        fake_score = critic (fake_images, labels).reshape (-1)\n        \n        # gradiant penalty\n        gp = gradient_penalty (critic, images, labels, fake_images, device)\n        \n        # calculate loss\n        critic_loss = -(torch.mean (real_score) - torch.mean (fake_score)) + 10 * gp\n\n        # Reset gradients\n        critic.zero_grad ()\n\n        # Compute gradients\n        critic_loss.backward (retain_graph = True)\n\n        # Adjust the parameters using backprop\n        critic_optimizer.step ()\n        \n        # for WGAN\n#         for p in critic.parameters ():\n#             p.data.clamp_ (-0.01, 0.01)\n    \n    return fake_images, labels, critic_loss, real_score, fake_score","b4fb35ab":"def train_generator (gen, critic, fake_images, labels):\n    gen.train ()\n\n    # calculate generator score and loss\n    output = critic (fake_images, labels).reshape (-1)\n    gen_loss = -torch.mean (output)\n    \n    # Backprop and optimize\n    gen.zero_grad ()\n    gen_loss.backward ()\n    gen_optimizer.step ()\n    \n    return gen_loss","183c0c15":"from IPython.display import Image\nfrom torchvision.utils import save_image\n\ndef save_fake_images (index, sample_dir = 'samples'):\n    if not os.path.exists (sample_dir):\n        os.makedirs (sample_dir)\n        \n    fixed_noise = torch.randn (25, z_dim, 1, 1).to(device)\n    labels = torch.randint (0, 13, (25,)).to(device)\n    fake = gen (fixed_noise, labels)\n    \n    fake_fname = 'fake_images-{0:0=4d}.png'.format (index)\n    print ('Svaing', fake_fname)\n    save_image (denorm (fake), os.path.join (sample_dir, fake_fname), nrow = 5)","7418b5aa":"# Befor training\nsample_dir = 'samples'\nsave_fake_images (0, sample_dir)\nImage (os.path.join (sample_dir, 'fake_images-0000.png'))","dd8b66cd":"def fit (critic, gen, dataloader, num_epochs, critic_iteration, device, save_fn = None):\n    \n    writer_real = SummaryWriter (f'logs\/real')\n    writer_fake = SummaryWriter (f'logs\/fake')\n    step = 0\n    \n    d_losses, g_losses, real_scores, fake_scores = [], [], [], []\n    total_step = len (dataloader)\n    \n    for epoch in range (num_epochs):\n        for i, (images, labels) in enumerate (dataloader):\n\n            # Train the descriminator and generator\n            fake_images, labels, critic_loss, real_score, fake_score = train_critic (critic, images, labels, critic_iteration, device)\n            gen_loss = train_generator (gen, critic, fake_images, labels)\n\n            # Inspect the losses\n            if (i + 1) % 100 == 0:\n                d_losses.append (critic_loss.item ())\n                g_losses.append (gen_loss.item ())\n                real_scores.append (real_score.mean ().item ())\n                fake_scores.append (fake_score.mean ().item ())\n                print ('Epoch [{}\/{}], Step [{}\/{}], critic_loss: {:.4f}, gen_loss: {:.4f}, D(x): {:.2f}, D (G(z)): {:.2f}'\n                .format (epoch + 1, num_epochs, i + 1, total_step, critic_loss.item (), gen_loss.item (), real_score.mean ().item (), fake_score.mean ().item ()))\n                \n                with torch.no_grad ():\n                    \n                    img_grid_real = torchvision.utils.make_grid (images [:16], normalize = True)\n                    img_grid_fake = torchvision.utils.make_grid (fake_images [:16], normalize = True)\n                    \n                    writer_real.add_image ('Real', img_grid_real, global_step = step)\n                    writer_real.add_image ('Fake', img_grid_fake, global_step = step)\n                    \n                step += 1\n                    \n\n        # Sample and save images\n        if save_fn is not None:\n            save_fn (epoch + 1)\n        \n    return dict (critic_loss = d_losses, gen_loss = g_losses, real_score = real_scores, fake_score = fake_scores)","7dfd6ed1":"history = fit (critic, gen, dataloader, 29, 5, device, save_fake_images)","dcf68c00":"# Save the model checkpoints\ntorch.save (gen.state_dict (), 'NIHGen.pth')\ntorch.save (critic.state_dict (), 'NIHCrit.pth')","94c82a4e":"from IPython.display import FileLink\n\nvid_fname = 'lung_wpgan_training.avi'\n\nfiles = [os.path.join (sample_dir, f) for f in os.listdir (sample_dir) if 'fake_images' in f]\nfiles.sort ()\nfiles","abdb4df4":"# create a video that show training results\nout = cv2.VideoWriter (vid_fname, cv2.VideoWriter_fourcc (*'FMP4'), 8, (332, 332))\n[out.write (cv2.imread (fname)) for fname in files]\nout.release ()\nFileLink ('lung_wpgan_training.avi')","2d719fbf":"plt.plot (history ['critic_loss'], '-')\nplt.plot (history ['gen_loss'], '-')\nplt.xlabel ('epoch')\nplt.ylabel ('loss')\nplt.legend (['Discriminator', 'Generator'])\nplt.title ('Losses');","e5e19469":"plt.plot (history ['real_score'], '-')\nplt.plot (history ['fake_score'], '-')\nplt.xlabel ('epoch')\nplt.ylabel ('score')\nplt.legend (['Real Score', 'Fake Score'])\nplt.title ('Scores');","d8684ba4":"fixed_noise = torch.randn (16, 100, 1, 1).to(device)\nlabels = torch.randint (0, 13, (16,)).to(device)\nfake = gen (fixed_noise, labels)\nimgs = denorm (fake).cpu ().detach ()\n\nplt.figure (figsize = (20, 20))\nfor i in range (16):\n    plt.subplot (4, 4, i + 1)\n    plt.imshow (imgs [i][0], cmap = 'gray')\n    plt.title (pathology_list [labels [i]])\n    \nplt.show ()","3ef33001":"# Preprocess","d3acedc5":"# Models","fc5debb0":"# Training","7a902d3f":"# Visualize","0a801845":"## Create training video","c45bac70":"## show gernerated images","c15c2511":"# Train","7cab6f57":"## ploting results"}}