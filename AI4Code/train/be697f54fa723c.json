{"cell_type":{"a6ab82f0":"code","ac35bbc7":"code","fc45f6bc":"code","229a1af3":"code","85e47a6a":"code","d2e4148f":"code","79827fa1":"code","c040aaa2":"code","db84c920":"code","e303d55d":"code","b3dee275":"code","ce86dc4c":"code","55b896e8":"code","c6f1011f":"code","0315b3b0":"code","1106ea41":"code","7343b2a5":"code","2c57d452":"code","a793fe08":"code","162b3024":"code","5d5cb53e":"code","76101d79":"code","61b32b05":"code","4c86ae63":"code","a91e95be":"code","fc83f6a0":"code","0427ac29":"code","f74847dd":"code","bb1b60c4":"code","b5089657":"code","87fd0b70":"code","7f68615c":"code","b0091e96":"code","aba607cf":"code","1ea62489":"markdown","88e60dbb":"markdown","5a02b5ff":"markdown","22f05d08":"markdown","387bf592":"markdown","77bfd291":"markdown","388c6418":"markdown","cb125d4e":"markdown","3f92ad43":"markdown","e1c36e93":"markdown","56c1e676":"markdown","6918fa05":"markdown","d8d6bcf7":"markdown","84417de8":"markdown","8f663e5e":"markdown","d5e15746":"markdown","4c7205e3":"markdown","5b81d124":"markdown","c7e85f28":"markdown","b33e9726":"markdown","17820cab":"markdown","b226a039":"markdown","1c73fbff":"markdown","70f4d30d":"markdown","4c161f0a":"markdown","ed95b204":"markdown","98c82e6d":"markdown","51e00b71":"markdown"},"source":{"a6ab82f0":"# Import necessary tools\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport re\nimport os\nimport shutil\nimport itertools\nimport math\nimport time\nimport PIL\nfrom PIL import Image\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n","ac35bbc7":"cwd = os.getcwd() # get the current working directory\nfiles = os.listdir(cwd) # get all files in cwd\nprint(\"Files in %r: %s\" % (cwd, files))","fc45f6bc":"image = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/person1_virus_6.jpeg\"\nPIL.Image.open(image)","229a1af3":"image_norm = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/IM-0005-0001.jpeg\"\nPIL.Image.open(image_norm)","85e47a6a":"train_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"\ntraining_generator = ImageDataGenerator(rescale=1\/255, featurewise_center=False, # set input mean to 0\n                                    samplewise_center=False, # sent sample mean to 0\n                                    featurewise_std_normalization=False, # divide input by std\n                                    samplewise_std_normalization=False, # divide each input by std\n                                    zca_whitening=False, rotation_range = 30, # apply zca whitening and randomly rotate\n                                    zoom_range = 0.2, width_shift_range = 0.1, # randomly zoom and shift image \n                                    height_shift_range= 0.1, horizontal_flip=False, # random shift \n                                    vertical_flip=False) \ntrain_generator = training_generator.flow_from_directory(train_dir, target_size=(200,200), \n                                                         batch_size=4, class_mode='binary')","d2e4148f":"validation_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/val\"\nvalidation_generator = ImageDataGenerator(rescale=1\/255)\nval_generator = validation_generator.flow_from_directory(validation_dir, target_size=(200,200), \n                                                         batch_size=4, class_mode='binary')","79827fa1":"test_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"\ntest_generator = ImageDataGenerator(rescale=1\/255)\ntest_generator = test_generator.flow_from_directory(test_dir, target_size=(200,200),\n                                                   batch_size=4, class_mode='binary')","c040aaa2":"cnn_baseline_model=tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32,(3,3),input_shape=(200,200,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), # First Convolution and Pooling Layers\n    \n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), # Second Convolution and Pooling Layers\n    \n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2), # Third Convolution and Pooling Layers\n    \n    tf.keras.layers.Flatten(), # Flatten the Layers and Add Fully Connected Layers\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n    \n])\n# Compile the model using the adam optimizer, because it's essentially RMSProp with momentum. \ncnn_baseline_model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])","db84c920":"# Look at the model summary of the layers\ncnn_baseline_model.summary()","e303d55d":"# Run the model\ncnn_baseline_model_hist = cnn_baseline_model.fit_generator(train_generator,\n                                             validation_data = val_generator,\n                                             epochs = 30, verbose = 1)","b3dee275":"# Plot the training and validation accuracy related to the number of epochs\nacc = cnn_baseline_model_hist.history['accuracy']\nval_acc = cnn_baseline_model_hist.history['val_accuracy']\nloss = cnn_baseline_model_hist.history['loss']\nval_loss = cnn_baseline_model_hist.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure();","ce86dc4c":"print(\"Loss of the model is: \", \n      cnn_baseline_model.evaluate(test_generator)[0]*100, \"%\")\nprint(\"Accuracy of the model is: \",\n     cnn_baseline_model.evaluate(test_generator)[1]*100, \"%\")","55b896e8":"cnn_model_drop=tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32,(3,3),input_shape=(200,200,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), # First Convolution and Pooling Layers\n    \n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), # Second Convolution and Pooling Layers\n    tf.keras.layers.Dropout(0.2), # First dropout\n    \n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2), # Third Convolution and Pooling Layers\n    tf.keras.layers.Dropout(0.2), # Second dropout\n    \n    tf.keras.layers.Flatten(), # Flatten the Layers and Add Fully Connected Layers\n    tf.keras.layers.Dropout(0.2), # Third dropout\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n    \n])\n# Compile the model using the adam optimizer, because it's essentially RMSProp with momentum. \ncnn_model_drop.compile(optimizer = tf.keras.optimizers.Adam(lr=0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])","c6f1011f":"cnn_model_drop_hist = cnn_model_drop.fit(train_generator, \n                                        validation_data = val_generator, \n                                        epochs = 30, verbose = 1)","0315b3b0":"# Plot the training and validation accuracy related to the number of epochs\nacc = cnn_model_drop_hist.history['accuracy']\nval_acc = cnn_model_drop_hist.history['val_accuracy']\nloss = cnn_model_drop_hist.history['loss']\nval_loss = cnn_model_drop_hist.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure();","1106ea41":"print(\"Loss of the model is: \", \n      cnn_model_drop.evaluate(test_generator)[0]*100, \"%\")\nprint(\"Accuracy of the model is: \",\n     cnn_model_drop.evaluate(test_generator)[1]*100, \"%\")","7343b2a5":"predictions = cnn_model_drop.predict_classes(test_generator)\npredictions = predictions.reshape(1, -1)[0]\npredictions[:10]","2c57d452":"true_classes = test_generator.classes","a793fe08":"print(classification_report(true_classes, predictions, target_names= ['Pneumonia(class 0)', 'Normal (class 1)'] ))","162b3024":"cm = confusion_matrix(true_classes, predictions)\ncm","5d5cb53e":"cm = pd.DataFrame(cm, index = ['0','1'], columns = ['0','1'])","76101d79":"labels = ['PNEUMONIA', 'NORMAL']\nplt.figure(figsize=(10,10))\nax = sns.heatmap(cm, cmap= \"Blues\", linecolor = 'black', linewidth = 1,\n           annot = True, fmt = '', xticklabels = labels, yticklabels = labels)\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)","61b32b05":"# Save the model for future use\n#cnn_model_drop.save_weights(\"model.h5\")\n#print(\"Saved model to SSD\")","4c86ae63":"LRR_model = Sequential()\nLRR_model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (200,200,3)))\nLRR_model.add(BatchNormalization())\nLRR_model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\nLRR_model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nLRR_model.add(Dropout(0.1))\nLRR_model.add(BatchNormalization())\nLRR_model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\nLRR_model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nLRR_model.add(BatchNormalization())\nLRR_model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\nLRR_model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nLRR_model.add(Dropout(0.2))\nLRR_model.add(BatchNormalization())\nLRR_model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\nLRR_model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\nLRR_model.add(Dropout(0.2))\nLRR_model.add(BatchNormalization())\nLRR_model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n\nLRR_model.add(Flatten())\nLRR_model.add(Dense(units = 128 , activation = 'relu'))\nLRR_model.add(Dropout(0.2))\nLRR_model.add(Dense(units = 1 , activation = 'sigmoid'))\nLRR_model.compile(optimizer = \"adam\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\nLRR_model.summary()","a91e95be":"# use the reduceLROnPlateau \nlearning_rate_redux = ReduceLROnPlateau(monitor='val_accuracy',\n                                       patience = 2, verbose = 1, factor = 0.3, min_lr=0.000001)","fc83f6a0":"LRR_model_hist = LRR_model.fit(train_generator, validation_data = val_generator,\n                               epochs = 30, verbose = 1, callbacks=[learning_rate_redux])","0427ac29":"# Plot the training and validation accuracy related to the number of epochs\nacc = LRR_model_hist.history['accuracy']\nval_acc = LRR_model_hist.history['val_accuracy']\nloss = LRR_model_hist.history['loss']\nval_loss = LRR_model_hist.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure();","f74847dd":"print(\"Loss of the model is: \", \n      LRR_model.evaluate(test_generator)[0]*100, \"%\")\nprint(\"Accuracy of the model is: \",\n     LRR_model.evaluate(test_generator)[1]*100, \"%\")","bb1b60c4":"predictions1 = LRR_model.predict_classes(test_generator)\npredictions1 = predictions1.reshape(1, -1)[0]\npredictions1[:10]","b5089657":"print(classification_report(true_classes, predictions1, target_names= ['Pneumonia(class 0)', 'Normal (class 1)'] ))","87fd0b70":"cm = confusion_matrix(true_classes, predictions1)\ncm","7f68615c":"cm = pd.DataFrame(cm, index = ['0','1'], columns = ['0','1'])","b0091e96":"labels = ['PNEUMONIA', 'NORMAL']\nplt.figure(figsize=(10,10))\nax = sns.heatmap(cm, cmap= \"Blues\", linecolor = 'black', linewidth = 1,\n           annot = True, fmt = '', xticklabels = labels, yticklabels = labels)\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)","aba607cf":"epochs = [i for i in range(30)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = LRR_model_hist.history['accuracy']\ntrain_loss = LRR_model_hist.history['loss']\nval_acc = LRR_model_hist.history['val_accuracy']\nval_loss = LRR_model_hist.history['val_loss']\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\nax[0].set_title('Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\nax[1].set_title('Testing Accuracy & Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Training & Validation Loss\")\nplt.show()","1ea62489":"### CNN Model with Dropout  \nIn this next attempt, I'll add dropout layers to help prevent overfitting and hopefully improve the loss and accuracy of the model.  ","88e60dbb":"At epoch 8 the validation(0.8750) and training accuracy(0.9316) are very close, which shows the algorithm is ideally tuned at this iteration. ","5a02b5ff":"#### Test the model on test data","22f05d08":"# Model the Data\nAs a baseline model, I'll build a simple Convolutional Neural Network to see how it performs.  \nAfter those baseline results are reviewed, I'll adjust the process to increase accuracy and ensure our model is not over or underfitting our data.  ","387bf592":"Great! The dropout prevented this model from overfitting as much and reduced the loss of the model to 23.7%. The accuracy also rose to 91.2%.","77bfd291":"There are still a lot of type 1 and type 2 errors, but the algorithm is decent at best, at detecting healthy lungs. ","388c6418":"#### Test the dropout model on the test data","cb125d4e":"## Business Case\n#### Background\nFor this project, I assumed the role of a Data Scientist working with a medical research firm. The goal is to train a machine learning model to classify whether a patient has pneumonia or not, given images of their chest x-rays.  \n\n#### What is Pneumonia?\nPneumonia is an inflammatory infection that primarily affects small air sacks in the lungs known as alveoli. In more severe cases, these sacks may fill with fluid. Symptoms include coughing, chest pain, fever, and labored breathing. Each year, ~450 million people are infected globally and about 4 million of those die. The 20th century brought antibiotics and vaccines, which greatly increase survival rates, however pneumonia remains the leading cause of death in developing nations, as well as infants, seniors, and the chronically ill. Further reading can be found [here](https:\/\/en.wikipedia.org\/wiki\/Pneumonia).\n\n#### Overall Goal:  \nWhile generally the overall goal is to build the best model possible, I will be forgoing the use of a TPU or other distributed computing system and will focus more on demonstrating my understanding of neural networks. I will be working with a downsampled dataset in this case, and look to use AWS or a Google TPU in the future to continue where this project left off. ","3f92ad43":"## Business Value  \nMachine learning is a quickly growing part of the healthcare industry, from the diagnosis stage, drug development, epidemiology, and all the way to treatment. There is significant potential for machine learning to redefine regions of the medical landscape.  So far, the heuristic nature of medicine puts a cap on the fields ability to grow. With computational improvements and the growth of big data, there are now ways to use intelligent, trainable systems to assist us in modeling the variable-heavy data present in the healthcare environment.  ","e1c36e93":"# Interpret the Data - Conclusion","56c1e676":"It looks like 26 epochs gives us the best training accuracy but the validation accuracy is less than impressive. The highest validation accuracy, found at 8 epochs, has a decent training accuracy of .9394. This still however may still be slightly overfit.","6918fa05":"## Data Science Workflow\n##### I generally prefer to use the OSEMiN process but in the context of deep learning, some adjustments need to be made. \n##### (Obtain, Scrub, Explore, Model, Interpret) \n\n- **Obtain** - This part was simple for this project, the full dataset can be found online at [Mendelay](https:\/\/data.mendeley.com\/datasets\/rscbjbr9sj\/3) and a downsampled set can be found on [Kaggle](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia).\n- **Scrub** - There isn't much scrubbing or cleaning to be done here, the dataset came labelled and filed into intuitive directories. \n- **Explore** - In the context of this project, this is just familiarizing myself with the directories and importing the data under the correct label. In this step, I preprocessed the image data to be uniform. \n- **Model** - In this step, I built a baseline CNN to see what the results would be. After plotting and examining those results, I tweaked the layers of the algorithm, and then dropped off the epochs that were shown to bring diminishing returns. \n- **Interpret** - In the final step, I reviewed the findings from our final classification algorithm and present ideas for future work. \n","d8d6bcf7":"# Image Classification with Deep Learning\n#### Building a Convolutional Neural Network to Classify Chest X-Rays","84417de8":"### Learning rate reduction on plateau with batch normalization model\nExpanding upon the dropout model above, I added Batch Normalization after the dropouts.  \nBatch normalization standardizes the inputs to a layer for each mini-batch, which helps reduce the amount of epochs needed to train the model.  \nI also incorporate the ReduceLROnPlateau callback API to help slow the learning rate when the validation accuracy stops improving. \n","8f663e5e":"# Table of Contents\n#### Data Science Workflow\nAn introduction and summary of the approach I took to complete this project\n#### Business Case and Business Value  \nBackground  \nWhat is Pneumonia?  \nOverall goal  \n#### Obtain and Import the Data\nImport libraries   \nFind label the directories where the data is located   \n#### Explore and Prepare The Data\nLook at example image of a normal lung and an infected lung    \nLoad the training, validation, and test data  \n#### Modeling The Data\nBuild a baseline CNN  \nPlot and examine results  \nTweak layers of the baseline model - add dropouts  \nComplete final model  \nPlot and review results of final model  \n#### Conclusion\nConclusion and opinion on my model    \nPotential future work  \nReferences","d5e15746":"This model performed best at the first epoch, then producing some pretty plateaued results through the rest of the iterations. The best training accuracy was .9684 and a validation accuracy of .8750. ","4c7205e3":"### Import Libraries","5b81d124":"#### Below is an image of lungs belonging to a pneumonia patient. ","c7e85f28":"In the case of this project, the data has been properly labelled and filed into labelled folders. This is very convenient and saved a lot of time, compared to having to do this oneself or source the data other ways. ","b33e9726":"# Obtain and Import the Data","17820cab":"### Baseline CNN Model","b226a039":"#### Below is an image of normal lungs. ","1c73fbff":"### References\n\n\n[1] Kermany D, Goldbaum M, Cai W et al. Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning. Cell. 2018; 172(5):1122-1131. doi:10.1016\/j.cell.2018.02.010","70f4d30d":"Not bad! Now to tweak the model and see if there is room for improvement. ","4c161f0a":"# Explore and Prepare the Data","ed95b204":"### Model Performance  \n| Model | Recall | Accuracy |  \n| --- | --- | --- |\n| Baseline CNN | 42.39365 | 88.94230 |\n| CNN with Dropout | 23.68644 | 91.18589 |\n| LRRonPlateau, Batch Normalized, Dropout CNN | 28.10528 | 92.30769 |\n\nThe learning rate reduction on plateau\/batch normalization with dropout model performed the best. It was the most stable of the models trained, but had slightly higher recall than the dropout model without batch normalization or LRReduction on plateau but it also boasted higher accuracy.  \nIt was also pretty consistent through the epochs, which is likely due to the batch normalization. The dropout assisted in preventing overfitting, and the learning rate reduction on plateau kept the validation accuracy high through all the epochs.  \n\n### Recommendations and Potential Future Work\n#### Model Selection\nThe third model I made performed the best, but there is still some work to be done to manage recall. In the future, I'll train another model and pass a different loss function, like a softmax classifier to see if there are improvements to be had over my chosen binary crossentropy classifier.  \n\n#### Larger Dataset\nTo better train the model, it would be advantageous to use the entire dataset rather than the downsampled set used in this notebook. With more images, the model would be trained significantly better.  \n\n#### More Computing Power\nRelated to the above point of using the whole dataset, I'd need to make use of a Tensor Processing Unit or other distributed system to handle that amount of data. ","98c82e6d":"### Load the training, validation, and test directories","51e00b71":"For this project, I used the \"Large Dataset of Labeled Optical Coherence Tomography and Chest X-Ray Images\" dataset found on [Mendelay](https:\/\/data.mendeley.com\/datasets\/rscbjbr9sj\/3). [1]  \nThe downsampled dataset used is available on [Kaggle](https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia)."}}