{"cell_type":{"ba41511d":"code","44778bbd":"code","3505dcc6":"code","69944fd0":"code","5510e926":"code","21f30dcd":"code","379fec36":"code","4b2012eb":"code","479ab8c8":"code","10f335eb":"code","3a8d42bc":"code","096f0b02":"code","f7ffdad9":"code","5eae5e2d":"code","428f8601":"code","3793fcd7":"code","f1e28c22":"code","9bb205aa":"code","1629d013":"code","624d2bfe":"markdown","b655a86c":"markdown","2e2b9e08":"markdown","e42d06c8":"markdown","22664066":"markdown","695e177a":"markdown","9e7af7ec":"markdown","024a27b0":"markdown","240681bd":"markdown","9d9d6861":"markdown","0c250e99":"markdown","b2718ad3":"markdown","43629e38":"markdown","a0f64786":"markdown","f4177301":"markdown","572a371c":"markdown","d9d741dd":"markdown","136c7477":"markdown","53e58768":"markdown"},"source":{"ba41511d":"# Display the Folders\/Classes\n\nimport numpy as np\nimport pandas as pd \nimport os\nfrom shutil import copyfile\n\n# copy .py file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"..\/input\/model-evaluation-utils\/model_evaluation_utils.py\", dst = \"..\/working\/model_evaluation_utils.py\")\n\nprint(os.listdir('..\/input\/stanford-dogs-dataset\/images\/Images\/'))\ndog_classes = os.listdir('..\/input\/stanford-dogs-dataset\/images\/Images\/')","44778bbd":"# Get the dog labels\n\nbreeds = [breed.split('-',1)[1] for breed in dog_classes] # get labels by splitting the folder name at dash\nbreeds[:10] # view some of the labels","3505dcc6":"# Get images full path and their labels\n\nfrom itertools import chain\n\nX = []\ny = []\n\nfullpaths = ['..\/input\/stanford-dogs-dataset\/images\/Images\/{}'.format(dog_class) for dog_class in dog_classes]\n\nfor counter, fullpath in enumerate(fullpaths):\n    for imgname in os.listdir(fullpath):\n        X.append([fullpath + '\/' + imgname])\n        y.append(breeds[counter])\n\nX = list(chain.from_iterable(X)) # unnest the lists and join together into one list\n\nlen(X) # number of pictures","69944fd0":"# Random shuffle the images for learning\n\nimport random\n\n# shuffle X and y\ncombined = list(zip(X, y))\nrandom.shuffle(combined)\n\nX[:], y[:] = zip(*combined)","5510e926":"# Display random dogs pictures \n\nimport matplotlib.pyplot as plt\n%matplotlib inline \nfrom matplotlib.image import imread\n\nplt.figure(figsize=(30,40))\nfor counter, i in enumerate(random.sample(range(0, len(X)), 25)): # random 25 images\n    plt.subplot(5, 5, counter+1)\n    plt.subplots_adjust(hspace=0.1)\n    filename = X[i]\n    image = imread(filename)\n    plt.imshow(image)\n    plt.title(y[i], fontsize=20)\n\n    \nplt.show()","21f30dcd":"# Choose a subset to test code\n\nX = X[:4000]\ny = y[:4000]","379fec36":"# Convert labels to one-hot encoded labels\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\n\n# Label and one-hot encoding y labels\nle = LabelEncoder()\nle.fit(y)\ny_ohe = to_categorical(le.transform(y), len(breeds))\ny_ohe = np.array(y_ohe)","4b2012eb":"# Prepare train, validation and test data\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import img_to_array, load_img\n\nimg_data = np.array([img_to_array(load_img(img, target_size = (299,299)))\n                     for img in X]) # load, resize images, and store as array\n\nx_train, x_test, y_train, y_test = train_test_split(img_data, y_ohe,\n                                                   test_size = 0.2,\n                                                   stratify=np.array(y), # stratify makes sure that proportion of each class in the output is same as the input\n                                                   random_state = 2) \n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n                                                 test_size = 0.2,\n                                                 stratify=np.array(y_train),\n                                                 random_state = 2)\n\nprint('Training Dataset Size: ', x_train.shape)\nprint('Validation Dataset Size: ', x_val.shape)\nprint('Testing Dataset Size: ', x_test.shape)\nprint('Training Label Size: ', y_train.shape)\nprint('Validation Label Size: ', y_val.shape)\nprint('Testing Label Size: ', y_test.shape)\n\n# clear some space from memory\nimport gc\ndel img_data\ngc.collect()","479ab8c8":"# Data Augmentation\n\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n\nbatch_size = 32\n\n# Create train generator\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, # only use rescale=1.\/255 if training from scratch\n                                  rotation_range = 30,\n                                  width_shift_range = 0.2,\n                                  height_shift_range = 0.2,\n                                  horizontal_flip = True) # CHECK\n\ntrain_generator = train_datagen.flow(x_train, y_train,\n                                     shuffle = False, batch_size = batch_size, seed = 1)\n\n# Create validation generator\nval_datagen = ImageDataGenerator(preprocessing_function=preprocess_input) # do not augment validation data\n\nval_generator = val_datagen.flow(x_val, y_val,\n                                shuffle = False, batch_size = batch_size, seed = 1)\n","10f335eb":"img_id = 16\n\ndog_generator = train_datagen.flow(x_train[img_id:img_id+1], y_train[img_id:img_id+1],\n                                     shuffle = False, batch_size = batch_size, seed = 1)\n\nplt.figure(figsize=(30,20))\ndogs = [next(dog_generator) for i in range(0,5)]\nfor counter, dog in enumerate(dogs): \n    plt.subplot(1, 5, counter+1)\n    plt.imshow(dog[0][0])\n    #plt.axis('off')\n    \nplt.show()","3a8d42bc":"# Build Model Using Pre-trained Model\n\nfrom keras import models\nfrom keras import layers\nfrom keras.optimizers import Adam\nfrom keras.layers import GlobalAveragePooling2D, Dense, Flatten, Dropout\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils.vis_utils import plot_model\n\n# load InceptionV3 pre-trained model\nbase_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (299,299,3))\n\nmodel = models.Sequential()\nmodel.add(base_model) # add pre_trained layers\nmodel.add(GlobalAveragePooling2D())\n#model.add(Flatten()) # flatten to 1-D vector to prepare for fully connected layers\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dense(len(breeds), activation = 'softmax'))\n\n\n# Freeze pre-trained layers\nprint('Number of trainable weights before freezing the base layer:', len(model.trainable_weights))\nmodel.layers[0].trainable = False\nprint('Number of trainable weights after freezing the base layer:', len(model.trainable_weights))","096f0b02":"# Compile the Model\n\nmodel.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy']) \nmodel.summary()","f7ffdad9":"plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)","5eae5e2d":"# Train Model\n\ntrain_steps_per_epoch = x_train.shape[0] \/\/ batch_size\nval_steps_per_epoch = x_val.shape[0] \/\/ batch_size\nepochs = 20\n\nhistory = model.fit_generator(train_generator,\n                             steps_per_epoch = train_steps_per_epoch,\n                             validation_data = val_generator,\n                             validation_steps = val_steps_per_epoch,\n                             epochs = epochs, verbose = 1)","428f8601":"# Plot Accuracy and Loss \n\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Transfer Learning Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,epochs+1))\nax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\nax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, epochs+1, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, history.history['loss'], label='Train Loss')\nax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\nax2.set_xticks(np.arange(0, epochs+1, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","3793fcd7":"# Evaluate Model on Test Data\n\nx_test1 = x_test \/ 255. # rescale to 0-1. Divide by 255 as its the max RGB value\ntest_predictions = model.predict(x_test1)\n\n# get model predictions\npredictions = le.classes_[np.argmax(test_predictions,axis=1)] # get labels and reverse back to get the text labels\n# get target labels\ntarget_labels = le.classes_[np.argmax(y_test,axis=1)]\n\n# Store in dataframe\npredict_df = pd.DataFrame({'Target_Labels': target_labels, 'Predictions': predictions})\npredict_df.head(20)\n","f1e28c22":"# Get accuracy of measure\n\ncorrect = (target_labels == predictions)\naccuracy = correct.sum() \/ correct.size\nprint(accuracy)","9bb205aa":"# Evaluate Model Performance\n\nfrom model_evaluation_utils import get_metrics\n\nget_metrics(true_labels=target_labels,\n            predicted_labels=predictions)","1629d013":"# Plot Actual vs Predicted Images with Confidence Levels\n    \nplt.figure(figsize=(30,40))\nfor counter, i in enumerate(random.sample(range(0, len(y_test)), 30)): # random 30 images\n    plt.subplot(6, 5, counter+1)\n    plt.subplots_adjust(hspace=0.6)\n    actual = str(target_labels[i])\n    predicted = str(predictions[i])\n    conf = str(max(test_predictions[i]))\n    plt.imshow(x_test[i]\/255.0)\n    plt.axis('off')\n    plt.title('Actual: ' + actual + '\\nPredict: ' + predicted + '\\nConf: ' + conf, fontsize=18)\n    \nplt.show()","624d2bfe":"And look at a sample batch of the dog images with their associated labels. Notice that the images have different dimensions, so we will have to resize them later before putting them into the model.","b655a86c":"<a id='Encoding_data'><\/a>\n## **4. Encoding Data** ##\n\nIt is also very important that we encode the classes\/breeds. Here we will use one-hot encoding, so that for each image, there will be 120 columns, with all but 1 column with a value of 0. The only column with a value of 1 is the image's associated class\/breed\/label.","2e2b9e08":"<a id='Preparing_data'><\/a>\n## **5. Preparing Train, Validation & Test Data** ##\n\nNow it's time to prepare our training, validation and testing dataset. We do this using the *train_test_split* function from the *sklearn* module. But before that, we load the images to the same dimensions and convert them into an image array, each containing the rgb values of every pixel.\n\n*Note: It's important to convert the images into a dimension that is similar to the ones that the pre-trained model is trained on.*","e42d06c8":"<a id='Shuffle_plot'><\/a>\n## **2. Shuffle and Plot Images** ##\n\nHere, we shuffle the images and their labels together so that they are not grouped by their breeds.","22664066":"We can see that we have 2560 training, 640 validation,and 800 testing images. Each image has a 299x299 dimension, with 3 channels, representing the RGB channels.\n\n<a id='Data_augmentation'><\/a>\n## **6. Data Augmentation** ##\nWe also perform **data augmentation**, especially if we have a small dataset, to give us significantly more diverse data without collecting them. This works by applying some transformation to our images (e.g., rotation, axis flipping) to produce 'new' versions of existing images, thus giving us more data to train with.","695e177a":"Below is an example of an image that was transformed into 'new' images. The model can then extract features from them and learn that these features are associated with this particular breed of dog.","9e7af7ec":"A better way is to calculate the precision, recall and F1 score of the classification in addition to accuracy. Looking at the combination of these model evaluation metrics will always give us a better idea of our model performance.","024a27b0":"# **Stanford Dog Breeds Classification Using Transfer Learning** <br>\nTeYang<br>\nCreated: 14\/12\/2019<br>\nLast update: 14\/12\/2019<br>\n\n<img src = 'https:\/\/www.rd.com\/wp-content\/uploads\/2019\/09\/group-of-dogs-e1568141002252-760x506.jpg'>\n\nThis kernel was created by following the transfer learning article [here](http:\/\/towardsdatascience.com\/image-detection-from-scratch-in-keras-f314872006c9) written by Rising Odegua.<br>\n\nThis is my first kernel after taking a deep learning course and I am still trying to understand the concepts and how to tune the parameters of my model. Huge shoutout to the Kaggle team for the website and micro-courses, as well as Jessica Li for sharing the dataset!\n\nWe will be looking at the Stanford Dogs dataset, which contains around 20,000 images categorized into 120 dog breeds from all over the world. Here, we will be leveraging the power of **transfer learning** by using a pre-trained model to build our **convolutional neural network** for classifying different dog breeds. This allows us to 'transfer' the weights of low-level features that are inherent in most images (e.g., lines, shapes etc) and apply it to the initial layer of our CNN. Doing so saves us the need to train a model from scrach, which can be challenging for those who do not have a 'big' enough dataset or computational resources. \n\n\nThe process is as follows:\n1. [Data Loading and Structure](#Data_loading_structure)\n2. [Shuffle and Plot Images](#Shuffle_plot)\n3. [Subset Data](#Subset_data)\n4. [Encoding Data](#Encoding_data)\n5. [Preparing Train, Validation & Test Data](#Preparing_data)\n6. [Data Augmentation](#Data_augmentation)\n7. [Model Building](#Model_building)\n8. [Train Model](#Train_model)    \n9. [Accuracy and Loss Plots](#Accuracy_loss_plots)\n10. [Predicting on Test Set](#Predict_test)\n11. [Model Evaluation Metrics](#Evaluation_metrics)\n12. [Plot Predictions against Actual Labels](#Plot_predictions)\n13. [Conclusions](#Conclusions)","240681bd":"<a id='Accuracy_loss_plots'><\/a>\n## **9. Accuracy and Loss Plots** ##\n\nWe made plots of the accuracy and loss for the training and validation data. This gives us an idea of how our model is performing (e.g., underfitting, overfitting).","9d9d6861":"<a id='Predict_test'><\/a>\n## **10. Predicting on Test Set** ##\n\nWe then apply our model to a dataset that it has not seen before. This is important, as we want a model that can generalize to other datasets other than what it is trained on. A model that only does well on the training and validation dataset but not on a testing dataset is not a useful one.","0c250e99":"<a id='Model_building'><\/a>\n## **7. Model Building** ##\n\nThe next part is building the model. For this process, we are using Google's Inception V3 model. There are other models available to use in Keras as well. We remove the last layer of the Inception V3 model, and feed the output of it to our own set of layers, ending with a final *Dense* layer to classify or predict which of the 120 breeds the images belong to. We also freeze the initial Inception V3 model as it has already been trained before and compile the model.","b2718ad3":"<a id='Subset_data'><\/a>\n## **3. Subset Data** ##\n\nThe next step is not necessary if you have sufficient computational power. I am running this on a laptop with 8gb of RAM, so everytime the kernel RAM exceeds its memory quota, it shuts down. To deal with that, I subsetted a portion of the dataset. However, this will lower the model performance.\n\n*Note: If you are facing this issue as well, proper memory management is highly recommended using the gc.collect() function. This involves deleting the unnecessary variables that you do not need anymore and clearing them from memory.*","43629e38":"<a id='Data_loading_structure'><\/a>\n## **1. Data Loading and Structure** ##\n\nWe start by exploring the dataset to look at the classes\/breeds of the dogs to understand more about its structure.","a0f64786":"<a id='Conclusions'><\/a>\n## **13. Conclusions** ##\n\nI believe that our model did pretty good on the testing dataset with ~86% prediction rate, considering that we only trained it on around 2560 images. This again shows the power of transfer learning. Training on more images will definitely increase the performance. However, I am still trying to figure out a way to store more images in arrays without it showing an error. I am not sure if this is a Kaggle limitation or my computer. Let me know if you have any insights!\n\nMachine learning is an iterative process, with lots of trial and error to improve our model. We might try to optimize our models by tuning the parameters of the model such as the number of layers in the network, the number of nodes, the learning rate etc. Go try it out for yourselves--train some models for deep learning!","f4177301":"There are 120 subfolders, each belonging to 1 of the 120 dog breeds. For example, images of the Chow breed are under the subfolder *n02112137-chow*. \nWe then proceed to extract the name of the dog breeds by splitting the folder name.","572a371c":"We store the correct labels and predictions into a dataframe. The first few cases showed that our model did pretty alright with the predictions.\n\n<a id='Evaluation_metrics'><\/a>\n## **11. Model Evaluation Metrics** ##\n\nNext, we get a measure of how well our model is performing by calculating the accuracy of the predictions against the actual target_labels.","d9d741dd":"<a id='Plot_predictions'><\/a>\n## **12. Plot Predictions against Actual Labels** ##\n\nTo better visualize our prediction performance, we plot out a small batch of our testing dataset, together with their actual labels, predictions as well as the probability values that our model predict they are in the category.","136c7477":"<a id='Train_model'><\/a>\n## **8. Train Model** ##\n\nIt's finally time to train our model. The batch size is the number of images passed to the model for training during every iteration. Therefore, the number of iterations\/steps is the number of images divided by the batch size, which constitues one epoch. After each iteration, weights of the nodes will be updated. An epoch ends when the entire dataset has been passed through. The more epoch we have, the more the model will train on the data.","53e58768":"Then, for each of the images, we get the full path to the image (stored in X), as well as its associated label\/class\/breed (stored in y). This allows us to load the images easily. "}}