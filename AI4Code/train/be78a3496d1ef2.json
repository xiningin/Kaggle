{"cell_type":{"413a5ac1":"code","6d9de80d":"code","a5975081":"code","81ad9d9e":"code","2a4fd3f8":"code","2993d628":"code","508c25e1":"code","710bbbfb":"code","ebb0889c":"code","113ebdf2":"code","7560b2da":"code","b114986d":"code","6daee48c":"code","ca4ac56c":"code","7440fd0a":"markdown","2435f3c3":"markdown","c3695292":"markdown","2a974e68":"markdown","885d5c73":"markdown","bffc2334":"markdown","0b983638":"markdown","29924e1e":"markdown","1eca6a30":"markdown","8d588b72":"markdown","65989293":"markdown","1317eb8a":"markdown"},"source":{"413a5ac1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC","6d9de80d":"df = pd.read_csv(\"\/kaggle\/input\/phl-exoplanet-catalog\/phl_exoplanet_catalog_2019.csv\")\ndf.head()","a5975081":"Null_values=list(zip(df.columns.values.tolist(),df.isnull().sum().tolist()))\nNull_values","81ad9d9e":"j=0\nfor i in df.columns.values.tolist():\n    if Null_values[j][1]>=df.shape[0]*0.1225:      \n        df = df.drop(columns=i)\n    j=j+1\n\nm = np.core.defchararray.find(df.columns.values.astype(str), 'ERROR') >= 0\ndf=df.loc[:,~m]\n\ndf=df.dropna()\ndf[df != 'nan']","2a4fd3f8":"plt.figure(figsize=(16,9))\n\nheatmap = sns.heatmap(df.corr(), vmin=-1,vmax=1, annot=False, cmap='viridis')\n\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)\nplt.show()","2993d628":"df = df.drop(columns=['P_DISTANCE', 'P_APASTRON', 'P_DISTANCE_EFF', 'P_FLUX_MAX', 'P_FLUX_MIN',\n                      'P_TEMP_EQUIL_MAX', 'P_TEMP_EQUIL_MIN','S_RA','S_DEC','S_RA_H','S_RA_T','S_DEC_T', 'S_RADIUS_EST', 'S_HZ_OPT_MIN',\n                      'S_HZ_OPT_MAX', 'S_HZ_CON_MIN', 'S_HZ_CON_MAX','S_HZ_CON0_MIN', 'S_HZ_CON0_MAX',\n                      'S_HZ_CON1_MIN', 'S_HZ_CON1_MAX', 'S_SNOW_LINE'])\ndf[\"P_TYPE_TEMP\"] = LabelEncoder().fit_transform(df[\"P_TYPE_TEMP\"])\ndf[\"P_TYPE\"] = LabelEncoder().fit_transform(df[\"P_TYPE\"])\ndf[\"S_TYPE_TEMP\"] = LabelEncoder().fit_transform(df[\"S_TYPE_TEMP\"])\ndf[\"P_DETECTION\"] = LabelEncoder().fit_transform(df[\"P_DETECTION\"])\ndf.head()","508c25e1":"plt.figure(figsize=(16,9))\n\nheatmap = sns.heatmap(df.corr(), vmin=-1,vmax=1, annot=False, cmap='viridis')\n\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)\nplt.show()","710bbbfb":"fig1 = px.density_heatmap(df, x='S_MAG', y='S_LOG_G', z='P_HABITABLE')\nfig2 = px.density_heatmap(df,x='P_TYPE',y='P_TYPE_TEMP',z='P_HABITABLE')\nfig3 = px.scatter(df,x='P_TEMP_EQUIL',y='P_ESI',color='P_HABITABLE')\nfig4 = px.density_heatmap(df,x='P_SEMI_MAJOR_AXIS_EST',y='S_TYPE_TEMP',z='P_HABITABLE')\n\nfig1.show()\nfig2.show()\nfig3.show()\nfig4.show()","ebb0889c":"df.columns.values.tolist()","113ebdf2":"Target = df.P_HABITABLE\nPredictors = df.drop(columns=['P_NAME','P_YEAR','P_DETECTION','S_NAME','S_ALT_NAMES','S_CONSTELLATION','S_CONSTELLATION_ABR',\n                              'S_CONSTELLATION_ENG','P_UPDATED','P_HABITABLE'])\n\nX_tr1, X_tst1, Y_tr1, Y_tst1 = train_test_split(Predictors,Target, random_state=0)\nX_tr2, X_tst2, Y_tr2, Y_tst2 = train_test_split(Predictors,Target, random_state=10)\nX_tr3, X_tst3, Y_tr3, Y_tst3 = train_test_split(Predictors,Target, random_state=42)","7560b2da":"DTR = DecisionTreeClassifier()\n\nDTR.fit(X_tr1,Y_tr1)\nY_pred1 = DTR.predict(X_tst1)\nDTR.fit(X_tr2,Y_tr2)\nY_pred2 = DTR.predict(X_tst2)\nDTR.fit(X_tr3,Y_tr3)\nY_pred3 = DTR.predict(X_tst3)\n\nconf_mat1 = confusion_matrix(Y_tst1,Y_pred1, normalize='all')\nconf_mat2 = confusion_matrix(Y_tst2,Y_pred2, normalize='all')\nconf_mat3 = confusion_matrix(Y_tst3,Y_pred3, normalize='all')\n\nsns.set_style(style='dark')\nfig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\nsns.heatmap(ax=ax1, data=conf_mat1, vmin=np.min(conf_mat1.all()),vmax=np.max(conf_mat1), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax1.set_title('Confusion Matrix 1', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax2,data=conf_mat2, vmin=np.min(conf_mat2.all()),vmax=np.max(conf_mat2), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax2.set_title('Confusion Matrix 2', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax3,data=conf_mat3, vmin=np.min(conf_mat3.all()),vmax=np.max(conf_mat3), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax3.set_title('Confusion Matrix 3', fontdict={'fontsize':12}, pad=12)\n\nerror1= (1-np.diag(conf_mat1).sum())*100\nerror2= (1-np.diag(conf_mat2).sum())*100\nerror3= (1-np.diag(conf_mat3).sum())*100\nmean_error = np.mean([error1,error2,error3])\nprint(\"Errors = ({0:.2f}, {1:.2f}, {2:.2f})%\".format(error1,error2,error3))\nprint(\"Mean Error = {:.2f} %\".format(mean_error))","b114986d":"RFC = RandomForestClassifier(n_jobs=2)\n\nRFC.fit(X_tr1,Y_tr1)\nY_pred1 = RFC.predict(X_tst1)\nRFC.fit(X_tr2,Y_tr2)\nY_pred2 = RFC.predict(X_tst2)\nRFC.fit(X_tr3,Y_tr3)\nY_pred3 = RFC.predict(X_tst3)\n\nconf_mat1 = confusion_matrix(Y_tst1,Y_pred1, normalize='all')\nconf_mat2 = confusion_matrix(Y_tst2,Y_pred2, normalize='all')\nconf_mat3 = confusion_matrix(Y_tst3,Y_pred3, normalize='all')\n\nsns.set_style(style='dark')\nfig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\nsns.heatmap(ax=ax1, data=conf_mat1, vmin=np.min(conf_mat1.all()),vmax=np.max(conf_mat1), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax1.set_title('Confusion Matrix 1', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax2,data=conf_mat2, vmin=np.min(conf_mat2.all()),vmax=np.max(conf_mat2), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax2.set_title('Confusion Matrix 2', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax3,data=conf_mat3, vmin=np.min(conf_mat3.all()),vmax=np.max(conf_mat3), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax3.set_title('Confusion Matrix 3', fontdict={'fontsize':12}, pad=12)\n\nerror1= (1-np.diag(conf_mat1).sum())*100\nerror2= (1-np.diag(conf_mat2).sum())*100\nerror3= (1-np.diag(conf_mat3).sum())*100\nmean_error = np.mean([error1,error2,error3])\nprint(\"Errors = ({0:.2f}, {1:.2f}, {2:.2f})%\".format(error1,error2,error3))\nprint(\"Mean Error = {:.2f} %\".format(mean_error))","6daee48c":"KNNC = KNeighborsClassifier(n_jobs=3)\n\nKNNC.fit(X_tr1,Y_tr1)\nY_pred1 = KNNC.predict(X_tst1)\nKNNC.fit(X_tr2,Y_tr2)\nY_pred2 = KNNC.predict(X_tst2)\nKNNC.fit(X_tr3,Y_tr3)\nY_pred3 = KNNC.predict(X_tst3)\n\nconf_mat1 = confusion_matrix(Y_tst1,Y_pred1, normalize='all')\nconf_mat2 = confusion_matrix(Y_tst2,Y_pred2, normalize='all')\nconf_mat3 = confusion_matrix(Y_tst3,Y_pred3, normalize='all')\n\nsns.set_style(style='dark')\nfig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\nsns.heatmap(ax=ax1, data=conf_mat1, vmin=np.min(conf_mat1.all()),vmax=np.max(conf_mat1), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax1.set_title('Confusion Matrix 1', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax2,data=conf_mat2, vmin=np.min(conf_mat2.all()),vmax=np.max(conf_mat2), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax2.set_title('Confusion Matrix 2', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax3,data=conf_mat3, vmin=np.min(conf_mat3.all()),vmax=np.max(conf_mat3), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax3.set_title('Confusion Matrix 3', fontdict={'fontsize':12}, pad=12)\n\nerror1= (1-np.diag(conf_mat1).sum())*100\nerror2= (1-np.diag(conf_mat2).sum())*100\nerror3= (1-np.diag(conf_mat3).sum())*100\nmean_error = np.mean([error1,error2,error3])\nprint(\"Errors = ({0:.2f}, {1:.2f}, {2:.2f})%\".format(error1,error2,error3))\nprint(\"Mean Error = {:.2f} %\".format(mean_error))","ca4ac56c":"SVCC = SVC(kernel='linear',C=100)\n\nSVCC.fit(X_tr1,Y_tr1)\nY_pred1 = SVCC.predict(X_tst1)\nSVCC.fit(X_tr2,Y_tr2)\nY_pred2 = SVCC.predict(X_tst2)\nSVCC.fit(X_tr3,Y_tr3)\nY_pred3 = SVCC.predict(X_tst3)\n\nconf_mat1 = confusion_matrix(Y_tst1,Y_pred1, normalize='all')\nconf_mat2 = confusion_matrix(Y_tst2,Y_pred2, normalize='all')\nconf_mat3 = confusion_matrix(Y_tst3,Y_pred3, normalize='all')\n\nsns.set_style(style='dark')\nfig, (ax1,ax2,ax3)=plt.subplots(1,3,figsize=(16,4))\nsns.heatmap(ax=ax1, data=conf_mat1, vmin=np.min(conf_mat1.all()),vmax=np.max(conf_mat1), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax1.set_title('Confusion Matrix 1', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax2,data=conf_mat2, vmin=np.min(conf_mat2.all()),vmax=np.max(conf_mat2), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax2.set_title('Confusion Matrix 2', fontdict={'fontsize':12}, pad=12)\nsns.heatmap(ax=ax3,data=conf_mat3, vmin=np.min(conf_mat3.all()),vmax=np.max(conf_mat3), annot=True,annot_kws={\"fontsize\":20},cmap='Spectral')\nax3.set_title('Confusion Matrix 3', fontdict={'fontsize':12}, pad=12)\n\nerror1= (1-np.diag(conf_mat1).sum())*100\nerror2= (1-np.diag(conf_mat2).sum())*100\nerror3= (1-np.diag(conf_mat3).sum())*100\nmean_error = np.mean([error1,error2,error3])\nprint(\"Errors = ({0:.2f}, {1:.2f}, {2:.2f})%\".format(error1,error2,error3))\nprint(\"Mean Error = {:.2f} %\".format(mean_error))","7440fd0a":"### Decission Tree Classifier","2435f3c3":"Here is observed that the P_HABITABLE which confirm the exoplanet as non-habitable(0), conservatively habitable (1), optmistically habitable(2) is strongly correlated to:\n* P_HABZONE_OPT\n* P_HABZONE_CON\n* P_ESI\n\nIn the other hand, the predictor components have correlations of 1 in some cases so the information obtained is duplicated. That ones are:\n\n* P_SEMI_MAJOR_AXIS_EST, P_DISTANCE, P_APASTRON, P_DISTANCE_EFF\n* P_FLUX, P_FLUX_MAX, P_FLUX_MIN\n* P_TEMP_EQUIL, P_TEMP_EQUIL_MAX, P_TEMP_EQUIL_MIN\n* S_RA, S_RA_H\n* S_RADIUS, S_RADIUS_EST, S_HZ_OPT_MIN, S_HZ_OPT_MAX, S_HZ_CON0_MIN, S_HZ_CON0_MAX, S_HZ_CON1_MIN, S_HZ_CON1_MAX, S_SNOW_LINE\n\nIs worth keeping only one of each group.\nWill drop the coordenates of the Star because that doesn't give information of habitability just location:\n\n* S_RA, S_RA_H, S_DEC, S_RA_T, S_DEC_T","c3695292":"## KNN Classifier","2a974e68":"## Random Forest Classifier","885d5c73":"# Exoplanets confirmation values and habitability","bffc2334":"## Support Vector Classifier","0b983638":"## Classification","29924e1e":"### Correlations","1eca6a30":"## Visualzation","8d588b72":"With the known correlations of 'P_HABITABLE' and 'P_ESI' is accurate to say that the most important factors for habitability are:\n\n* S_MAG\n* S_LOG_G\n* S_TYPE_TEMP \/\/ S_TEMPERATURE\n* P_TYPE_TEMP \/\/ P_TEMP_EQUIL\n* P_TYPE\n\nAdded to the three previous values the most important factors are some properties of the star and type and temperature of the planet. ","65989293":"### Train Test Split","1317eb8a":"### Methods and errors given:\n* Random Forest Classifier: 0.12 % error\n* Support Vector Classifier: 0.20 % error\n* Decission Tree Classifier: 0.28 % error\n* K Nearest Neighbours Classifier: 0.88 % error"}}