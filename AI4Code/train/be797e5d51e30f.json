{"cell_type":{"7325f6d7":"code","4d9498dd":"code","30ef43a4":"code","78bbda2b":"code","bb7c229f":"code","d9782bc0":"markdown","84c3b36c":"markdown","40d86e99":"markdown"},"source":{"7325f6d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm_notebook as tqdm\n\nimport category_encoders as ce\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport gc\nimport os","4d9498dd":"# ----------\n# Load Data\n# ----------\ndef load_data():\n    print('------------------------')\n    print('exec load_data() ... ')\n    # Input data files are available in the \"..\/input\/\" directory.\n    # read files\n    df_train = pd.read_csv('..\/input\/train.csv', index_col=0)\n    df_test = pd.read_csv('..\/input\/test.csv', index_col=0)\n\n    #state_latlong = pd.read_csv('..\/input\/statelatlong.csv')\n    #state_gdp = pd.read_csv('..\/input\/US_GDP_by_State.csv')\n\n    # save train & test index\n    train_idx = df_train.index\n    test_idx = df_test.index\n\n    # Split to \"train & test data(X)\" , \"label data(y_train)\"\n    X_train = df_train.drop('ConvertedSalary', axis=1)\n    y_train = df_train['ConvertedSalary']\n    # merge train & test data\n    X = pd.concat([X_train,df_test],sort=False)\n\n    # inner join {train,test} & state_latlong\n    #df = df.reset_index().merge(state_latlong.rename(columns={\"State\":\"addr_state\"})).set_index(df.index.names)\n\n    return X, y_train, train_idx, test_idx\n\n\ndef sprit_X_y(df, train_idx, test_idx):\n    print('------------------------')\n    print('exec sprit_X_y() ... ')\n\n    # Split to \"train & test data(X)\" , \"label data(y_train)\"\n    y_train = df.loan_condition.drop(test_idx)\n    X = df.drop('loan_condition', axis=1)\n    \n    return X, y_train\n\n\n# -------------------\n# Create New Feature \n# -------------------\ndef create_new_f(X):\n    print('------------------------')\n    print('exec create_nef_f() ... ')\n\n    # create new feature: ratio(loan_amnt \/ annual_inc)\n    X['loan_per_inc'] = X.loan_amnt \/ (X.annual_inc + 100)\n\n    # create new feature: NaN indicate flag\n    for col in X.columns:\n        if X[col].isnull().any():\n            X['nanflg_'+col] = X[col].isnull().astype(int)\n\n    # create new feature: count NaN columns\n    X['nan_cnt'] = X.isnull().sum(axis=1)\n\n    # split year and month\n    X['issue_d'] = pd.to_datetime(X.issue_d, format=\"%b-%Y\")\n    X['issue_d_year'] = X['issue_d'].dt.year\n    X['issue_d_month'] = X['issue_d'].dt.month.astype(str)\n    X['issue_d'] = X['issue_d'].astype(int)\n\n    # split year and month\n    X['earliest_cr_line'] = pd.to_datetime(X.earliest_cr_line, format=\"%b-%Y\")\n    X['earliest_cr_line_year'] = X['earliest_cr_line'].dt.year\n    X['earliest_cr_line_month'] = X['earliest_cr_line'].dt.month.astype(str)\n    X['earliest_cr_line'] = X['earliest_cr_line'].astype(int)\n\n    X['relative_earliest_cr_line'] = X['issue_d'] - X['earliest_cr_line']\n    \n    return X\n\n\n# ------------------\n# Numerical Feature \n# ------------------\ndef proc_num_f(X):\n    print('------------------------')\n    print('exec proc_num_f() ... ')\n\n    # char to num\n    X.CompanySize.fillna('-999', inplace=True)\n    X.CompanySize = X.CompanySize.str.replace(\"Fewer than 10 employees\", \"5\")\n    X.CompanySize = X.CompanySize.str.replace(\"10 to 19 employees\", \"15\")\n    X.CompanySize = X.CompanySize.str.replace(\"20 to 99 employees\", \"50\")\n    X.CompanySize = X.CompanySize.str.replace(\"100 to 499 employees\", \"300\")\n    X.CompanySize = X.CompanySize.str.replace(\"500 to 999 employees\", \"750\")\n    X.CompanySize = X.CompanySize.str.replace(\"1,000 to 4,999 employees\", \"3000\")\n    X.CompanySize = X.CompanySize.str.replace(\"5,000 to 9,999 employees\", \"7500\")    \n    X.CompanySize = X.CompanySize.str.replace(\"10,000 or more employees\", \"15000\")\n    X.CompanySize = X.CompanySize.astype(int)\n\n    X.YearsCoding.fillna('-999', inplace=True)\n    X.YearsCoding = X.YearsCoding.str.replace(\"0-2 years\", \"1\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"3-5 years\", \"4\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"6-8 years\", \"7\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"9-11 years\", \"10\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"12-14 years\", \"13\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"15-17 years\", \"16\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"18-20 years\", \"19\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"21-23 years\", \"22\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"24-26 years\", \"25\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"27-29 years\", \"28\")\n    X.YearsCoding = X.YearsCoding.str.replace(\"30 or more years\", \"33\")\n    X.YearsCoding = X.YearsCoding.astype(int)\n    \n    X.YearsCodingProf.fillna('-999', inplace=True)\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"0-2 years\", \"1\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"3-5 years\", \"4\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"6-8 years\", \"7\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"9-11 years\", \"10\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"12-14 years\", \"13\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"15-17 years\", \"16\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"18-20 years\", \"19\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"21-23 years\", \"22\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"24-26 years\", \"25\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"27-29 years\", \"28\")\n    X.YearsCodingProf = X.YearsCodingProf.str.replace(\"30 or more years\", \"33\")\n    X.YearsCodingProf = X.YearsCodingProf.astype(int)\n\n    X.LastNewJob.fillna('-1', inplace=True)\n    X.LastNewJob = X.LastNewJob.str.replace(\"I've never had a job\", \"0\")\n    X.LastNewJob = X.LastNewJob.str.replace(\"Less than a year ago\", \"1\")\n    X.LastNewJob = X.LastNewJob.str.replace(\"Between 1 and 2 years ago\", \"2\")\n    X.LastNewJob = X.LastNewJob.str.replace(\"Between 2 and 4 years ago\", \"4\")\n    X.LastNewJob = X.LastNewJob.str.replace(\"More than 4 years ago\", \"7\")\n    X.LastNewJob = X.LastNewJob.astype(int)\n    \n    X.NumberMonitors.fillna('-1', inplace=True)\n    X.NumberMonitors = X.NumberMonitors.str.replace(\"More than 4\", \"5\")\n    X.NumberMonitors = X.NumberMonitors.astype(int)\n    \n    X.Age.fillna('0', inplace=True)\n    X.Age = X.Age.str.replace(\"Under 18 years old\", \"15\")\n    X.Age = X.Age.str.replace(\"18 - 24 years old\", \"20\")\n    X.Age = X.Age.str.replace(\"25 - 34 years old\", \"30\")\n    X.Age = X.Age.str.replace(\"35 - 44 years old\", \"40\")\n    X.Age = X.Age.str.replace(\"45 - 54 years old\", \"50\")\n    X.Age = X.Age.str.replace(\"55 - 64 years old\", \"60\")\n    X.Age = X.Age.str.replace(\"65 years or older\", \"65\")\n    X.Age = X.Age.astype(int)\n    \n    # columns of numeric(int or float)\n    numerics = []\n    for col in X.columns:\n        if X[col].dtype == 'float64' or X[col].dtype == 'int64':\n            numerics.append(col)\n            print(col, X[col].nunique())\n\n    # NaN processing\n    X[numerics] = X[numerics].fillna(-999)\n\n    return X, numerics\n\n# ---------------------\n# Standarize\/Normarize \n# ---------------------\ndef std_num_f(X, numerics):\n    print('------------------------')\n    print('exec std_num_f() ... ')\n    # NaN processing\n    X[numerics] = X[numerics].fillna(-999)\n\n    std = StandardScaler()\n    X[numerics] = pd.DataFrame(std.fit_transform(X[numerics].astype(float)), index=X.index, columns=X[numerics].columns)\n    del std\n\n    return X\n\n\n# --------------------\n# Categorical Feature \n# --------------------\ndef proc_cat_f(X, numerics, test_idx):\n    print('------------------------')\n    print('exec proc_cat_f() ... ')\n\n    # columns of string(=object)\n    cats = []\n    for col in X.columns:\n        if X[col].dtype == 'object':\n            if col not in rm_list:\n                cats.append(col)\n                print(col,X[col].nunique())\n\n    # NaN processing\n    X[cats] = X[cats].fillna('#')\n\n    # one hot encoding\n    oh_list = ['Student', 'Gender', 'Country']\n    #X = pd.concat([X.drop(columns=oh_list, axis=1), pd.get_dummies(X[oh_list])], axis=1)\n    X = pd.concat([X[numerics], pd.get_dummies(X[oh_list])], axis=1)\n    \n    return X,oh_list\n\n\n# -------------\n# Text Feature \n# -------------\ndef proc_txt_f(X, test_idx):\n    print('------------------------')\n    print('exec proc_txt_f() ... ')\n    # NaN processing\n    X[['emp_title', 'title']] = X[['emp_title', 'title']].fillna('a')\n\n    tmp_X_train = X.emp_title.drop(index=test_idx)\n\n    # TFIDF\n    #tfidf = TfidfVectorizer(strip_accents='ascii', stop_words='english', max_features=330, ngram_range=(1,2), lowercase=True)\n    tfidf = TfidfVectorizer(strip_accents='ascii', stop_words='english', max_features=200)\n    tfidf.fit(tmp_X_train)\n    TXT = tfidf.transform(X.emp_title)\n\n    X = pd.concat([X, pd.DataFrame(TXT.todense(), index=X.index)], axis=1)\n\n    del tfidf\n    del tmp_X_train\n    del TXT\n\n    X.drop(['emp_title', 'title'], axis=1, inplace=True)\n    \n    return X\n\n\n\n# -----------\n# Data prepare\n# -----------\ndef split_train_test(X, train_idx, test_idx):\n    print('------------------------')\n    print('exec split_train_test() ... ')\n    X_train = X.drop(index=test_idx)\n    X_test = X.drop(index=train_idx)\n    del X\n    #del df\n    \n    return X_train, X_test\n\n# -------------------\n# Validation Function\n# -------------------\ndef rmsle(y_true, y_pred):\n    return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False\n\n#---------\n# Train & Test\n#---------\ndef train_test(X_train, X_test, y_train):\n    print('------------------------')\n    print('exec train_test() ... ')\n    scores = []\n    total_score = 0\n    y_tests = np.zeros(len(X_test.index))\n\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n    epochs = [512, 560, 498, 488, 567] # magic number\n\n    # training phase\n    for i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n        X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n        X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n\n        # learning\n        lr = LinearRegression()\n        lr.fit(X_train_, y_train_)\n\n        # \u4e88\u6e2c\n        #y_pred = lr.predict(X_val).clip(min=0)\n        y_pred = lr.predict(X_val)\n        #score = np.sqrt(mean_squared_log_error(y_val, y_pred))\n        #scores.append(score)\n        y_tests += lr.predict(X_test)\n\n    #for i in range(0, len(scores)):\n    #    print('CV Score of Fold_%d is %f' % (i, scores[i]))\n    #    total_score += scores[i]\n    #print('Avg CV Socore: %f' % (total_score\/len(scores)))\n\n    y_test = pd.DataFrame(y_tests\/5, index=X_test.index)\n\n    return y_test\n\n# --------------\n# Submit \n# --------------\ndef test_submit(X_test, y_test):\n    print('------------------------')\n    print('exec test_submit() ... ')\n\n    # assemble result\n    df_submission = pd.DataFrame(index=X_test.index)\n    df_submission['ConvertedSalary'] = y_test\n    print(df_submission)\n\n    # write file\n    df_submission.to_csv('submission.csv')","30ef43a4":"%%time\n##############\n# main routine\n##############\n# load data\nX, y_train, train_idx, test_idx = load_data()\n\n# numeric features\n#X = create_new_f(X)\nX, numerics = proc_num_f(X)\n\n# categorical features\n#X,cats = proc_cat_f(X, numerics, test_idx)\n\n# text features\n#X = proc_txt_f(X, test_idx)\n# rm\n#rm_list = ['DevType', 'Country', 'CurrencySymbol', 'CommunicationTools','FrameworkWorkedWith']\n#for col in rm_list:\n#    X.drop(col,inplace=True,axis=1)\n\n# split data\nX_train, X_test = split_train_test(X[numerics], train_idx, test_idx)\n\n# train\ny_test = train_test(X_train, X_test, y_train)\n\n# submit\ntest_submit(X_test, y_test)\n","78bbda2b":"X","bb7c229f":"    # columns of string(=object)\n    for col in X.columns:\n        if X[col].dtype == 'object':\n            print(col,X[col].nunique())","d9782bc0":"**\u30fb\u51e6\u7406\uff08\u30d5\u30a1\u30f3\u30af\u30b7\u30e7\u30f3\uff09**","84c3b36c":"**\u30fb\u30e1\u30a4\u30f3\u30eb\u30fc\u30c1\u30f3**","40d86e99":"**\u30fbpython\u30e9\u30a4\u30d6\u30e9\u30eaimport**"}}