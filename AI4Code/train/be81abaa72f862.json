{"cell_type":{"a4b0e502":"code","746080d0":"code","9a4fcca3":"code","f84411d6":"code","8b14c1aa":"code","612f5b7a":"code","f386aa67":"code","a61f95ac":"code","d6b1904f":"code","31b7babf":"code","9a098ad5":"code","58cda1d7":"code","cb9e220c":"markdown","821ed2f2":"markdown","12210c49":"markdown","26a29a2e":"markdown","69fa0301":"markdown","ca4eb9e4":"markdown"},"source":{"a4b0e502":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","746080d0":"import pandas as pd\nimport numpy as np\n\nblood_transfusion = pd.read_csv(\"..\/input\/bloodtransfusioncsv\/blood_transfusion.csv\")\ndata = blood_transfusion.drop(columns=\"Class\")\ntarget = blood_transfusion[\"Class\"]","9a4fcca3":"data.head()","f84411d6":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\n\nmodel = make_pipeline(StandardScaler(), SVC())","8b14c1aa":"from sklearn.model_selection import cross_validate, ShuffleSplit\ncv = ShuffleSplit(random_state = 0)\ncv_results = cross_validate(model, data, target, cv=cv, n_jobs = 2)\ncv_results = pd.DataFrame(cv_results)\ncv_results\n","612f5b7a":"print(\n    f\"Accuracy score of our model: \\n\"\n    f\"{cv_results['test_score'].mean(): .3f} + \/ -\"\n     f\"{cv_results['test_score'].std(): .3f}\"\n     )","f386aa67":"model.get_params().keys()","a61f95ac":"from sklearn.model_selection import validation_curve\n\ngammas = np.logspace(-3, 2, num=30)\n\nparam_name = \"svc__gamma\"\n\ntrain_scores, test_scores = validation_curve(\n    model, data, target, param_name = param_name, param_range = gammas, cv = cv,\n    n_jobs = 2)\n","d6b1904f":"import matplotlib.pyplot as plt\n\nplt.errorbar(gammas, train_scores.mean(axis=1),\n             yerr=train_scores.std(axis=1), label='Training score')\nplt.errorbar(gammas,test_scores.mean(axis=1),\n            yerr=test_scores.std(axis=1), label='Test score')\nplt.legend()\nplt.xscale(\"log\")\n_=plt.title(\"Validation score of support vector machine\")\nplt.xlabel(r\"Value of hyperparameter $\\gamma$\")\nplt.ylabel(\"Accuracy score\")\n","31b7babf":"from sklearn.model_selection import learning_curve\n\ntrain_sizes = np.linspace(0.1, 1, num=10)\nresults = learning_curve(\n    model, data, target, train_sizes=train_sizes, cv=cv, n_jobs=2)\ntrain_size, train_scores, test_scores = results[:3]\n","9a098ad5":"plt.errorbar(train_size, train_scores.mean(axis=1),\n            yerr=train_scores.std(axis=1), label = 'Training score')\nplt.errorbar(train_size, test_scores.mean(axis=1),\n            yerr=test_scores.std(axis=1), label= 'Testing score')\n\nplt.legend()\n\n\n_=plt.title(\"Learning curve for support vector machine\")\nplt.xlabel(\"Number of sample in the trainig set\")\nplt.ylabel(\"Accuracy\")","58cda1d7":"By scikit-learn developers\n\u00a9 Copyright 2021.","cb9e220c":"We will use a support vector machine classifier (SVM). In its most simple form, a SVM classifier is a linear classifier behaving similarly to a logistic regression. Indeed, the optimization used to find the optimal weights of the linear model are different but we don\u2019t need to know these details for the exercise.\n\nAlso, this classifier can become more flexible\/expressive by using a so-called kernel that makes the model become non-linear. Again, no requirement regarding the mathematics is required to accomplish this exercise.\n\nWe will use an RBF kernel where a parameter gamma allows to tune the flexibility of the model.\n\nFirst let\u2019s create a predictive pipeline made of:\n\na sklearn.preprocessing.StandardScaler with default parameter;\n\na sklearn.svm.SVC where the parameter kernel could be set to \"rbf\". Note that this is the default.","821ed2f2":"As previously mentioned, the parameter gamma is one of the parameters controlling under\/over-fitting in support vector machine with an  RBF kernel.(radial basis function)\n\nEvaluate the effect of the parameter gamma by using the sklearn.model_selection.validation_curve function. You can leave the default scoring=None which is equivalent to scoring=\"accuracy\" for classification problems. You can vary gamma between 10e-3 and 10e2 by generating samples on a logarithmic scale with the help of np.logspace(-3, 2, num=30).\n\nSince we are manipulating a Pipeline the parameter name will be set to svc__gamma instead of only gamma. You can retrieve the parameter name using model.get_params().keys(). We will go more into detail regarding accessing and setting hyperparameter in the next section.","12210c49":"Plot the validation curve for the train and test scores.","26a29a2e":"## Exercise M2.01\u00b6\nThe aim of this exercise is to make the following experiments:\n\ntrain and test a support vector machine classifier through cross-validation;\n\nstudy the effect of the parameter gamma of this classifier using a validation curve;\n\nuse a learning curve to determine the usefulness of adding new samples in the dataset when building a classifier.\n\nTo make these experiments we will first load the blood transfusion dataset.","69fa0301":"Looking at the curve, we can clearly identify the over-fitting regime of the SVC classifier when gamma > 1. The best setting is around gamma = 1 while for gamma < 1, it is not very clear if the classifier is under-fitting but the testing score is worse than for gamma = 1.\n\nNow, you can perform an analysis to check whether adding new samples to the dataset could help our model to better generalize. Compute the learning curve (using sklearn.model_selection.learning_curve) by computing the train and test scores for different training dataset size. Plot the train and test scores with respect to the number of samples.","ca4eb9e4":"Evaluate the generalization performance of your model by cross-validation with a ShuffleSplit scheme. Thus, you can use sklearn.model_selection.cross_validate and pass a sklearn.model_selection.ShuffleSplit to the cv parameter. Only fix the random_state=0 in the ShuffleSplit and let the other parameters to the default."}}