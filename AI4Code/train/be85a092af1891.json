{"cell_type":{"cd7d829b":"code","1f3c66da":"code","63ecc897":"code","d4dbf03c":"code","61211bb5":"code","15c2272c":"code","95115cd2":"code","88798d1d":"code","af1ec528":"code","26936b0c":"code","c103f3c5":"code","c5d178bf":"code","c4a7ff08":"code","4a8f09ff":"code","fb32c0de":"code","02a57d89":"code","243607de":"code","ee21b90e":"code","812cd42d":"code","e8bd1e3b":"code","eff6500d":"code","2a242f33":"markdown","d17a483f":"markdown","c6a51a95":"markdown","cab148e8":"markdown","2a21bcb8":"markdown","03aee01f":"markdown","22418dbd":"markdown","6953b9bf":"markdown","a8304bfe":"markdown","10ecbb31":"markdown","ad09ffdf":"markdown","d451470f":"markdown","ec412d6a":"markdown","4f21a8e6":"markdown","2f89cb4c":"markdown","a7982ea3":"markdown","d3187aa7":"markdown","d66bb87d":"markdown"},"source":{"cd7d829b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#Split Data Train and Test\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n\n#Modelling\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import accuracy_score, classification_report, roc_auc_score, plot_roc_curve","1f3c66da":"redwine = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\nredwine.sample()","63ecc897":"redwine.info()","d4dbf03c":"redwine.describe()","61211bb5":"plt.figure(figsize=(10, 6))\nsns.scatterplot(x='density', y='alcohol', data= redwine, hue='quality')","15c2272c":"plt.figure(figsize=(18, 8))\nsns.heatmap(redwine.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\nplt.title('Correlation Map Of Red Wine Quality', fontdict={'fontsize':12}, pad=12);","95115cd2":"redwine['quality'].unique()","88798d1d":"redwine['quality'] = np.where(redwine['quality'] > 6, 1, 0)\nredwine['quality'].value_counts()","af1ec528":"X = redwine.drop(['quality'], axis = 1)\ny = redwine['quality']","26936b0c":"X.shape","c103f3c5":"X_train, X_test, y_train, y_test = train_test_split(X,y,\n                                                   stratify = y,\n                                                   test_size = 0.3,\n                                                   random_state = 1111)","c5d178bf":"k = range(1,50,2)\ntesting_accuracy = []\ntraining_accuracy = []\nscore = 0\n\nfor i in k:\n    knn = KNeighborsClassifier(n_neighbors = i)\n    pipe_knn = Pipeline([('scale', MinMaxScaler()), ('knn', knn)])\n    pipe_knn.fit(X_train, y_train)\n    \n    y_pred_train = pipe_knn.predict(X_train)\n    training_accuracy.append(accuracy_score(y_train, y_pred_train))\n    \n    y_pred_test = pipe_knn.predict(X_test)\n    acc_score = accuracy_score(y_test,y_pred_test)\n    testing_accuracy.append(acc_score)\n    \n    if score < acc_score:\n        score = acc_score\n        best_k = i\n        \nprint('Best Accuracy Score', score, 'Best K-Score', best_k)","c4a7ff08":"sns.lineplot(k, testing_accuracy)\nsns.scatterplot(k, testing_accuracy)\n\nsns.lineplot(k, training_accuracy)\nsns.scatterplot(k, training_accuracy)\nplt.legend(['testing accuracy', 'training accuracy'])","4a8f09ff":"knn = KNeighborsClassifier(n_neighbors = 3)\npipe_knn = Pipeline([('scale', MinMaxScaler()), ('knn', knn)])\npipe_knn.fit(X_train, y_train)","fb32c0de":"def model_evaluation(model, metric):\n    skfold = StratifiedKFold(n_splits = 5)\n    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric)\n    return model_cv\n\npipe_knn_cv = model_evaluation(pipe_knn, 'roc_auc')\n\nscore_mean = [pipe_knn_cv.mean()]\nscore_std = [pipe_knn_cv.std()]\nscore_roc_auc = [roc_auc_score(y_test, pipe_knn.predict(X_test))]\nmethod_name = ['K-Neighbors Classifier']\nsummary = pd.DataFrame({'method': method_name, 'mean score': score_mean,\n                        'std score': score_std, 'roc auc score': score_roc_auc})\nsummary","02a57d89":"plot_roc_curve(pipe_knn, X_test, y_test)","243607de":"knn = KNeighborsClassifier(n_neighbors = 3)\nestimator = Pipeline([('scale', MinMaxScaler()), ('knn', knn)])\n\nhyperparam_space = {\n    'knn__n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17],\n    'knn__leaf_size': [10, 20, 30, 40, 50],\n    'knn__weights': ['uniform', 'distance']\n}\n\ngrid = GridSearchCV(\n                estimator,\n                param_grid = hyperparam_space,\n                cv = StratifiedKFold(n_splits = 5),\n                scoring = 'roc_auc',\n                n_jobs = -1)\n\ngrid.fit(X_train, y_train)","ee21b90e":"print('best score', grid.best_score_)\nprint('best param', grid.best_params_)","812cd42d":"estimator.fit(X_train, y_train)\ny_pred_estimator = estimator.predict(X_test)\nprint(classification_report(y_test, y_pred_estimator))","e8bd1e3b":"grid.best_estimator_.fit(X_train, y_train)\ny_pred_grid = grid.best_estimator_.predict(X_test)\nprint(classification_report(y_test, y_pred_grid))","eff6500d":"score_list = [roc_auc_score(y_test, y_pred_estimator), roc_auc_score(y_test, y_pred_grid)]\naccuracy = [score, accuracy_score(y_test, y_pred_grid)]\nmethod_name = ['K-Neighbors Classifier Before Tuning', 'K-Neighbors Classifier After Tuning']\nbest_summary = pd.DataFrame({\n    'method': method_name,\n    'roc auc score': score_list,\n    'accuracy score': accuracy\n})\nbest_summary","2a242f33":"# PreProcessing","d17a483f":"*Splitting Data*","c6a51a95":"# HyperParameter Tuning","cab148e8":"*Cross Validation*","2a21bcb8":"## *Find Best K-Score*","03aee01f":"# Modeling","22418dbd":"A large K value has benefits which include reducing the variance due to the noisy data, the side effect being developing a bias due to which the learner tends to ignore the smaller patterns which may have useful insights. The data indicates underfitting.","6953b9bf":"After HyperParameter Tuning, the best score is 0.88616, which getting higher. Leaf size is 10, N neighbors is 17, and Weights is distance. Let's compare the result.","a8304bfe":"# Before VS After Tuning Comparison","10ecbb31":"Now, see if the HyperParameter Tuning process can boost until getting the maximum score.","ad09ffdf":"I use 0.3 as default score for test_size and X.shape for random_state so the data will be devided equally.","d451470f":"*Define Model Using Best K-Score*","ec412d6a":"*The red wine variant of the Portuguese \"Vinho Verde\" wine refers to Portuguese wine that originated in the historic Minho province in the far north of the country. The main goal of this problem is to find which features of these kinds of wine are the ones that provide the most information about its quality. We will also try to make a prediction of a wine's quality and check if it matches with the real quality. Although this dataset can be viewed as a classification (multiclass classification) or a regression problem, we will solve it using regression techniques.*","4f21a8e6":"# Simple EDA","2f89cb4c":"***The red wine industry shows a recent exponential growth as social drinking is on the rise. This is a time-consuming process and requires the assessment given by human experts, which makes this process very expensive. A vital factor in red wine certification and quality assessment is physicochemical tests, which are laboratory-based and consider factors like acidity, pH level, sugar, and other chemical properties. The red wine market would be of interest if the human quality of tasting can be related to wine\u2019s chemical properties so that certification and quality assessment and assurance processes are more controlled. This project aims to determine which features are the best quality red wine indicators and generate insights into each of these factors to red wine quality.***","a7982ea3":"From this score, I see that the roc auc score after tuning is getting lower, even the accuracy score is getting higher. First thing, the data is imbalanced, so it could cause this, and the second thing is the data indicates underfitting training dataset.","d3187aa7":"- *If the **quality value > 6**, it means the quality is **good** and I define it as **1**.*\n- *If the **quality value < 6,** it means the quality is **bad** and I define it as **0**.*","d66bb87d":"From this actual data, there are **more bad qualities than good ones**. Also indicated that the data is **imbalanced**."}}