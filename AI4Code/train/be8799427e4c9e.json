{"cell_type":{"9a452d55":"code","5adc7083":"code","2bb8662e":"code","2e41b832":"code","e9b82c44":"code","3506adf2":"code","fb90f672":"code","530adcc1":"code","c75d9e5c":"code","ead4c192":"code","e4914039":"code","f67e9aa3":"code","3a9aed1c":"code","0cf411db":"code","f1c08a72":"code","c8ae7806":"code","3cc31245":"code","a1620636":"code","c158bc00":"code","993bd0aa":"code","1e2ef109":"code","78f345f2":"code","3cff9e88":"code","b03fbed2":"code","e6145500":"code","044ae29a":"code","56c5e4f8":"code","35e7b188":"code","63f6fc18":"code","6348b804":"code","41c3cc3d":"markdown","9da96c11":"markdown","bafd3dfb":"markdown","0c5fb429":"markdown","b4fcec66":"markdown","fc9cccfb":"markdown","648e5770":"markdown","9014e6dc":"markdown","873adf89":"markdown","5b8efcd6":"markdown","b538d509":"markdown","c2ba8fff":"markdown","09095086":"markdown","ce6aec4d":"markdown","653c8b4a":"markdown","7bee2654":"markdown","f61ee14d":"markdown","e6d8fb07":"markdown","ca02a57d":"markdown","0d60cb36":"markdown","aff66d67":"markdown","c9078731":"markdown","6c12389a":"markdown","352265f3":"markdown","51a69a54":"markdown","0c9baecb":"markdown","3273c9c1":"markdown","fa14bb0b":"markdown","719b2252":"markdown"},"source":{"9a452d55":"# Imports\nimport numpy as np \nimport pandas as pd \nimport bq_helper\nimport matplotlib.pyplot as plt\nimport seaborn as sns","5adc7083":"london = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\", dataset_name=\"london_crime\")","2bb8662e":"london.list_tables()","2e41b832":"london.head('crime_by_lsoa') ","e9b82c44":"# Write the query that we want to perform\n# Select the distinct boroughs from our one table\nboroughs_count = \"\"\"\nSELECT DISTINCT borough\nFROM `bigquery-public-data.london_crime.crime_by_lsoa`;\n        \"\"\"\n\n# Perform the query and store the result\nboroughs = london.query_to_pandas_safe(boroughs_count)\nboroughs","3506adf2":"lsoa_per_borough = \"\"\"\nSELECT borough, count(DISTINCT lsoa_code) as n_codes\nFROM `bigquery-public-data.london_crime.crime_by_lsoa`\nGROUP BY borough\nORDER BY count(DISTINCT lsoa_code) desc;\n        \"\"\"\n\ncodes_per_borough = london.query_to_pandas_safe(lsoa_per_borough)\ncodes_per_borough","fb90f672":"average_codes_per_borough = np.mean(codes_per_borough['n_codes'])\nprint(\"Average LSOA codes per borough: {}\".format(round(average_codes_per_borough)))","530adcc1":"sns.set_style(\"whitegrid\")\nfig, axes = plt.subplots(1, 1, figsize = (10,4))\nsns.barplot(x = \"borough\", y = 'n_codes', data = codes_per_borough.head(10), ax = axes, color = '#ffeaa7')\nplt.axhline(average_codes_per_borough, label = 'Average LSOA codes', color = '#d63031')\nplt.legend()\nplt.xlabel('Borough')\nplt.ylabel('Number of LSOA codes within borough')\nplt.title('Top 10 Boroughs with most LSOA codes')\nplt.show()","c75d9e5c":"# Query to select Camden's crime stats by year and month\ncamden_crime_query = \"\"\"\nSELECT year, month, sum(value) AS `total_crime`\nFROM `bigquery-public-data.london_crime.crime_by_lsoa`\nWHERE borough = 'Camden'\nGROUP BY year, month;\n        \"\"\"\n\n# Perform and store the query results \ncamden_crime = london.query_to_pandas_safe(camden_crime_query)\ncamden_crime.head()","ead4c192":"camden_crime.describe().total_crime","e4914039":"camden_crime = camden_crime.sort_values(['year', 'month']) # Sort the data frame by year and month to make them chronological\ncamden_crime.head()","f67e9aa3":"camden_crime.index","3a9aed1c":"camden_crime['date'] = pd.to_datetime(camden_crime.year.map(str) + '-' + camden_crime.month.map(str), format = '%Y-%m')\ncamden_crime.set_index('date', inplace=True)","0cf411db":"camden_crime.total_crime.plot(figsize=(15, 6))\nplt.title('Total crime in Camden')\nplt.ylabel('Total crime per month')\nplt.xlabel('')\nplt.show()","f1c08a72":"cc08_10 = camden_crime.loc['2008':'2010',] # Filter using the datetime index","c8ae7806":"cc08_10.total_crime.plot(figsize=(15, 6))\nplt.title('Total crime in Camden')\nplt.ylabel('Total crime per month')\nplt.show()","3cc31245":"# Query adapted from previous to also group by major_category of crime\ncamden_major_query = \"\"\"\nSELECT year, month, major_category, sum(value) AS `total_crime`\nFROM `bigquery-public-data.london_crime.crime_by_lsoa`\nWHERE borough = 'Camden'\nGROUP BY year, month, major_category\nORDER BY year, month;\n        \"\"\"\n# Perform and store the query results\ncamden_major = london.query_to_pandas_safe(camden_major_query)\ncamden_major.head()","a1620636":"camden_major['date'] = pd.to_datetime(camden_major.year.map(str) + '-' + camden_major.month.map(str), format = '%Y-%m')\ncamden_major.drop(columns = ['year', 'month'], inplace = True)\ncamden_major.head()","c158bc00":"camden_major_pivot = camden_major.pivot(index = 'date', columns = 'major_category', values = 'total_crime')","993bd0aa":"camden_major_pivot.plot(subplots = True, figsize=(15, 15))\nplt.show()","1e2ef109":"camden_major_pivot.head()","78f345f2":"sanity_check_query = \"\"\"\nSELECT year, month, borough, major_category, minor_category, value\nFROM `bigquery-public-data.london_crime.crime_by_lsoa`\nWHERE borough = 'Camden' \nAND (major_category = 'Sexual Offences' OR major_category = 'Fraud or Forgery')\nAND year > 2008\nORDER BY year, month;\n        \"\"\"\nsanity_check = london.query_to_pandas_safe(sanity_check_query)","3cff9e88":"sanity_check","b03fbed2":"# Write our query to track the changes in yearly crime count per major_category\ngrowing_crime_query = \"\"\"\nSELECT year, major_category, sum(value) as `total_crime` \nFROM `bigquery-public-data.london_crime.crime_by_lsoa`\nGROUP BY major_category, year\nORDER BY major_category, year;\n        \"\"\"\n\nlondon.estimate_query_size(growing_crime_query) #\u00a0We can estimate the size of our query this way\ngrowing_crime = london.query_to_pandas(growing_crime_query) # Execute the query and gather the results ","e6145500":"growing_crime.head(15)","044ae29a":"growing_crime.set_index(pd.to_datetime(growing_crime.year, format = '%Y'), inplace = True)\ngrowing_crime.head()","56c5e4f8":"growing_crime.drop(columns = ['year'], inplace = True) # Remove the year column since the information is now held in the index\ngrowing_crime_pivot = growing_crime.pivot(columns = 'major_category', values = 'total_crime') # Pivot to make each category a column\ngrowing_crime_pivot.plot(subplots = True, figsize=(20, 15), layout = (5, 2)) # Subplotting to see all plots separately - important since vastly different scales\nplt.show() # Show plot","35e7b188":"# Calculate the percent change from the previous year's figure\ngrowing_crime['percent_change'] = growing_crime['total_crime'] \/ growing_crime['total_crime'].groupby(growing_crime['major_category']).shift(1) - 1\n# NB I tried to use pct_change() but couldn't get it to work with a groupby() as well\ngrowing_crime.head(20)","63f6fc18":"# Write our query to track the changes in yearly crime count per major_category\ngrowing_crime_query_2 = \"\"\"\nSELECT \n    year, \n    major_category, \n    SUM(value) as `total_crime`,\n    CASE WHEN SUM(value) > 0\n        THEN SUM(value) \/ LAG(SUM(value) , 1 , NULL) OVER (PARTITION BY major_category ORDER BY year ASC) - 1\n        ELSE 0 END AS `percent_change`\nFROM `bigquery-public-data.london_crime.crime_by_lsoa`\nGROUP BY major_category, year\nORDER BY major_category, year;\n        \"\"\"\n\ngrowing_crime_2 = london.query_to_pandas(growing_crime_query_2) # Execute the query and gather the results ","6348b804":"growing_crime_2.head(20)","41c3cc3d":"- - - - -\n### Conclusions and final comments\nThis is just a simple introduction to querying the Big Query datasets using `bq_helper`. I may explore further over time so it may become more fleshed out in the coming weeks\/months. \n\nThank you for taking the time to have a look through, and follow my workflow through the process of learning some more about Big Query. Please consider leaving an upvote if you think it is worth it, and please leave a comment if you have any feedback, constructive comments and suggestions are always welcome and appreciated!","9da96c11":"I have added an additional grouping of `major_category` after the `year` and `month`. This adds a further breakdown to the `total_crime` column that we had from the previous query. \n\nNow that we have the results in a pandas data frame, we are able to perform some cleaning and manipulations easily in preparation for plotting in a moment. The steps that I'm going to get to that stage are: \n1. Create a column for the datetime object (as I previously did with the other query) (Set the date time as the index using `set_index`)\n2. Spread the major category to make the data wide, rather than long using the `pivot` function (This will allow for us to use the `subplots=True` argument with `matplotlib`)","bafd3dfb":"The crimes that appear to be increasing are:\n- Violence against the person\n- Other notifiable offences \n\nAll the other crimes appear to be in reasonable decline; although note the scaling for the y axis being different for each plot, so while we can see trends, the scales aren't truly comparable. We could calculate the percentage change for each of the major categories, which would give us a better indication as to the true problem crimes that aren't being tackled. \n\n*NB: we have double checked our thoughts about the Sexual Offences and Fraud or Forgery major categories here, with records of them seemingly disappearing after the first year (2008).*","0c5fb429":"# Starting point: Big Query and London Crime\nThis is my first attempt looking at a dataset where the data is provided in the Big Query format on Kaggle. Getting to know how to use the Big Query datasets on Kaggle will allow me, in the future, to tackle some of the larger datasets and provide an opportunity to practise SQL queries. This is intended as a starting point for those that are keen to tackle Big Query datasets but aren't quite sure where to start; I think that there is enough content here that you could fork this and then continue on with your analysis.  \n\nFirstly, let's see if we can read some of the data in to the session and extract some insight using some basic data visualisation. ","b4fcec66":"Having performed a secondary check to make sure I hadn't accidentally removed data with my pivot table, it seems as though there is a lack of information regarding those major categories of crime for Camden after February 2008. \n\nIf you can see a mistake that I've made, or I've done something stupid, then please leave a comment and let me know! ","fc9cccfb":"We can check whether this was an error I have after the query, or whether the information for those months hasn't been recorded in the data for whatever reason. ","648e5770":"It appears as though crime was roughly on the rise between 2008 and 2011, and then dropped steeply after 2012, before re-establishing an upward trend post-2014. It also appears to fluctuate wildly throughout the months, so I imagine there is some seasonal impact here. ","9014e6dc":"## How many boroughs?\nNow that we have a better understanding of the data at our disposable, we can start thinking about the sort of questions that we might be able to ask. \n\nLet's start with a simple query to get started to see how many boroughs are represented in the `crime_by_lsoa` table. \n\nQuerying the data takes, at its simplest, two steps:\n1. Writing a query to perform\n2. Performing the query and storing the information (in my case as a pandas data frame)","873adf89":"The most striking insight that we have gained from this plot is the complete lack of *Fraud or Forgery* or *Sexual Offences* after the first few months of data. This can be seen if we view the first 10 rows of our pivot table as well.  ","5b8efcd6":"Let's perform another grouped query to see what is happening with general crime rates in Camden over time. \n\n## Crime in Camden\nTo track this over time, we are going to filter by `borough`, group by the `year` and `month` and get the sum of all recorded crimes (I will alias this as `total_crime`). ","b538d509":"We have now reindexed the data frame with a datetime version of the `year` and `month` column. Let's plot the trend and see if there is anything interesting at play here. ","c2ba8fff":"`camden_crime` is currently just using the basic index, which appears to be all over the place because we have sorted the data to follow the `year` and `month` columns. The first step we can do is to convert the year and month information that we have to a datetime format. Once we have that, then we can use `set_index` to complete the process and have `camden_crime` indexed by a date for easier manipulation. ","09095086":"There we go! We can see that we have produced, essentially, the same results through the two different methods that I talked about. ","ce6aec4d":"We can immediately see that there are more than 1 `lsoa_code` per `borough` telling us that this represents a smaller more confined geographical area within a borough; this may seem straightforward and obvious, but the relationship between the variables here might help us pose some questions that we can later answer using the information available to us. ","653c8b4a":"Lower Layer Super Output Area (LSOA) is a geographical area. This is telling us, if the table naming convention is sensible, that this data is going to be grouped primarily by the area where the crime\/s happened. ","7bee2654":"I have sorted the data frame purely so that things now appear in chronilogical order. Let's have a look at the current indexing to see if we can leverage the power of `pandas` and use the dates that we have as the index. ","f61ee14d":"We can visualise the top 10 boroughs using `seaborn` and `matplotlib` to have a look at which boroughs contain the most LSOA codes. ","e6d8fb07":"## Initial exploration and get some data\nNow that we have access to the big query database (`london`) we can see what tables are included using the `.list_tables()` method. In our case we have just the one table, so the reading in is simple with no joins required to get our hands on all the information that we want to have a look at. If you aren't familiar with SQL joins, you can find some simple examples [here](http:\/\/www.sql-join.com\/sql-join-types). ","ca02a57d":"We can see that we have  7 columns: \n- **lsoa_code**: this represents a policing area \n- **borough**: the london borough for which the statistic is related\n- **major_category**: the major crime category\n- **minor_category**: the minor crime category\n- **value**: the count of the crime for that particular borough, in that particular month\n- **year**: the year of the summary statistic\n- **month**: the month of the summary statistic","0d60cb36":"The City of London is significantly smaller than the other boroughs, and Camden has the most LSOA codes for a single borough; *perhaps this is indicative of size? *","aff66d67":"There are no clear seasonal trends to my eye, perhaps they are clearer when the data is subsetted by the type of crime; some crimes happen more when it is hot, while others thrive in the cold. However, to have that information, we will have to go back and change the initial query so that we also group by the `major_category` (we could also include the `minor_category` but the numbers may be high enough for certain crime types to yeild informative results).\n\nEven if we don't unearth any significant seasonal trends, it will be good to have a deeper look at crime rates in Camden across the years. \n\n### Delving deeper using `major_category`","c9078731":"Having a look at the `total_crime` column of our summary table for Camden, we can tell immediately that we have 108 months worth of data that has been collected (9 years), with a mean of 2547 recorded crimes per month, but a range of over 1000. Let's see if visualising the data can tell us anything more interesting about the trends. Remember that we don't need to run the query again, we should have all the information that we need already in the `camden_crime` data frame. ","6c12389a":"### What types of crimes are growing the fastest? \nInstead of looking at it from a borough-centric view as an example, we can have a look at the changes for total `major_category` across time. ","352265f3":"We can see that we have the total crime counts for the major categories across all the years in the data set. Lets plot them and see which crimes are on the rise in London. \n","51a69a54":"We are working with Big Query, so we are going to use a special package that allows us to the connect to the database, see things about the database, and run queries against it using SQL to extract information. From what I have seen, this appears to be the way that most people go about accessing the BigQuery datasets and reading the data into Python, where you are subsequently able to do further analysis on it.  \n\nMore information about the package can be found [here](https:\/\/www.kaggle.com\/sohier\/introduction-to-the-bq-helper-package), and more generally getting started with Big Query can be found [here](https:\/\/www.kaggle.com\/dansbecker\/getting-started-with-sql-and-bigquery).","0c9baecb":"### SQL (change the original query):","3273c9c1":"Let's have a look at the first few rows of this `crime_by_lsoa` to get our bearings, using the `head()` method on our `london` object. ","fa14bb0b":"## Analysis Flexibility \nWhile working with Big Query, we are really given two options to how we are able to conduct our analysis and do our calculations:\n1. Within the original SQL query\n2. Working with the pandas data frame that is produced when the query is run\n\nI suppose which you preference is probably a personal choice, depending on the task and your strengths with the languages involved. I just wanted to demonstrate this through solving one problem using both methods: by changing the original query to add the column, or adding it afterwards using python. \n\n__*Can we add a column that shows the percentage change from the previous year for each major cirme category?*__\n\n### Python (use pandas):\n\n","719b2252":"This tells us that we 33 boroughs that we could potentially investigate. \n\nWe can build on our first observation about the `lsoa_code`s by performing a grouping query now to see how many codes there are per borough. "}}