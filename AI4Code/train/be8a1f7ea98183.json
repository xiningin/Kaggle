{"cell_type":{"ca83a685":"code","e759707f":"code","2f6b064f":"code","e93882f9":"code","88baf70a":"code","af5dcc89":"code","1f24138c":"code","cd0086db":"code","2d47e288":"code","5e7f65aa":"code","1f7aeae9":"code","59d91950":"code","30056b76":"code","64f7d19b":"code","b463c050":"code","324ab021":"code","439c407e":"code","37207858":"code","4bedcd62":"code","dc136244":"code","83d54408":"code","265a8df8":"code","46ae034f":"code","d1fabc6b":"code","69d81145":"code","482921e9":"code","71fe5f05":"code","4019d19d":"code","c00f13bf":"code","3423ddd1":"code","7e12af41":"code","dc9983a2":"code","0d36b07c":"markdown","f96baf5c":"markdown","00c19044":"markdown","abf162db":"markdown","f1632e9e":"markdown","e81f323d":"markdown","fb1abcfd":"markdown","1e36ba85":"markdown","2f62a5ea":"markdown","d0629f19":"markdown","1dff3a9a":"markdown"},"source":{"ca83a685":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    \n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e759707f":"import pandas as pd\nimport numpy as np\nimport keras\nfrom matplotlib import pyplot as plt\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","2f6b064f":"df_train=pd.read_csv('..\/input\/imdb-dataset-sentiment-analysis-in-csv-format\/Train.csv')\ndf_val=pd.read_csv('..\/input\/imdb-dataset-sentiment-analysis-in-csv-format\/Valid.csv')\ndf_train.head()","e93882f9":"df_val.head()","88baf70a":"X_train=df_train['text'].values\nY_train=df_train['label'].values","af5dcc89":"X_val=df_val['text'].values\nY_val=df_val['label'].values","1f24138c":"(X_train.shape,Y_train.shape),(X_val.shape,Y_val.shape)","cd0086db":"df_train.iloc[:,1].describe()","2d47e288":"df_val.iloc[:,1].describe()","5e7f65aa":"df1=pd.DataFrame(X_val_len,columns=['len'])\ndf1.describe()","1f7aeae9":"df=pd.DataFrame(X_train_len,columns=['len'])\ndf.describe()","59d91950":"X_train_len=[len(str(i).split()) for i in X_train]\nplt.hist(X_train_len)","30056b76":"X_val_len=[len(str(i).split()) for i in X_val]\nplt.hist(X_val_len)","64f7d19b":"vocab_size=30000 #went for an average vocab size \nembedding_dimension=64 #high dimensions would result in finding better parameters for similarity \nmax_length=120 #used a maximum length of 120 words\nturnc='post'#preprocessing step for pad_sequences\noov_tok='<OOV>'#oov stands for out of vocabulary tokens","b463c050":"tokenizer=Tokenizer(num_words=vocab_size,filters='''!\"#$%&'()*+,-.\/:;<=>?@[\\]^_`{|}~\u00a1\u00a2\u00a3\u00a4\u00a6\u00a7\u00a8\u00ab\u00ad\u00ae\u00b0\u00b3\u00b4\u00b7\u00ba\u00bb\u00bd\u00be\u00bf\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e5\u00e6\u00e7\u00e8\u00e9\u00ea\u00eb\u00ec\u00ed\u00ee\u00ef\u00f0\u00f1\u00f2\u00f3\u00f4\u00f5\u00f6\u00f8\u00f9\u00fa\u00fb\u00fc\u00fd\u00fe\u011f\u0131\u014d\u017c\u05d0\u05d2\u05d5\u05d9\u05db\u05dc\u05de\u05df\u05e8\u2013\u2018\u2019\u201c\u201d\u2026\u2033\u20a4\u2605\u3001''',oov_token=oov_tok)\ntokenizer.fit_on_texts(X_train)\nX=tokenizer.texts_to_sequences(X_train)\nX_padded=pad_sequences(X,maxlen=max_length,padding='post',truncating=turnc)\nX_val_seq=tokenizer.texts_to_sequences(X_val)\nX_val_padded=pad_sequences(X_val_seq,maxlen=max_length,padding='post',truncating=turnc)","324ab021":"X_padded.shape,X_val_padded.shape","439c407e":"from keras.layers import LSTM,Bidirectional,Embedding,Dense,SpatialDropout1D,Flatten,Dropout\nfrom keras.models import Sequential","37207858":"model=Sequential()\nmodel.add(Embedding(vocab_size,embedding_dimension,input_length=max_length))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(Bidirectional(LSTM(120,activation='tanh',return_sequences=True)))\nmodel.add(Dropout(0.3))\nmodel.add(Bidirectional(LSTM(120,activation='tanh',return_sequences=False)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(300,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nprint(model.summary())","4bedcd62":"model.compile(optimizer=\"rmsprop\",loss='binary_crossentropy',metrics=['accuracy'])","dc136244":"hist=model.fit(X_padded,Y_train,epochs=7,batch_size=16,validation_data=(X_val_padded,Y_val))#10 #best at 9","83d54408":"hist=model.fit(X_padded,Y_train,epochs=2,batch_size=16,validation_data=(X_val_padded,Y_val))#10 #best at 9","265a8df8":"plt.plot(hist.history['accuracy'],c='b')\nplt.plot(hist.history['val_accuracy'],c='r')\nplt.show()","46ae034f":"plt.plot(hist.history['loss'],c='b')\nplt.plot(hist.history['val_loss'],c='r')\nplt.show()","d1fabc6b":"df_test=pd.read_csv('..\/input\/imdb-dataset-sentiment-analysis-in-csv-format\/Test.csv')\ndf_test","69d81145":"X_test=df_test['text'].values\nY_test=df_test['label'].values","482921e9":"X_test_seq=tokenizer.texts_to_sequences(X_test)","71fe5f05":"X_test_padded=pad_sequences(X_test_seq,maxlen=max_length,padding='post',truncating=turnc)\nX_test_padded[0]","4019d19d":"X_test_padded.shape","c00f13bf":"model.evaluate(X_test_padded,Y_test)","3423ddd1":"def Check(x):\n    test_case1=[x]\n    test_case=tokenizer.texts_to_sequences(test_case1)\n    test_case_padded=pad_sequences(test_case,padding='post',truncating=turnc)\n    x=model.predict_classes(test_case_padded)\n    if x==1:print(\"Positive\", (model.predict(test_case_padded)))\n    else:print(\"Negative\", (model.predict(test_case_padded)))","7e12af41":"test_review=str(input(\"Enter the review :  \"))\nCheck(test_review)","dc9983a2":"test_review=\"You will get A to Z all details of this scam, i may be wrong but due to this series, i don't think that i need to watch the upcoming movie big bull because 2 to 3 hours too less for explain the story. If you are at home, just watch this web series, you will not bore for even 1 second, All actors played their role excellently, i like reporter character as w\"\nCheck(test_review)","0d36b07c":"# Converting into Sequential Data","f96baf5c":"# The Model","00c19044":"#  Tokenizing  and converting the data into Sequences","abf162db":"# Setting the parameters","f1632e9e":"# Analyse the Data","e81f323d":"# Read the Data","fb1abcfd":"# I just checked for one random imdb review ","1e36ba85":"# This Plot is for the last two Epochs","2f62a5ea":"# Reading the Test Data","d0629f19":"# Import the required libraries","1dff3a9a":"# Check for your own Reviews"}}