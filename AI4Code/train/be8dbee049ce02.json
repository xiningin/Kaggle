{"cell_type":{"b8f05291":"code","0432d93c":"code","b117856b":"code","50b3a39e":"code","56834509":"code","c8794193":"code","5d0b5818":"code","7aa9fcb3":"code","fa74a21d":"code","7b0016fa":"code","61163927":"code","f81e43a3":"code","9a8d705f":"code","0eaee5b3":"code","96b28934":"code","717dc421":"code","aaef489c":"code","a63637dc":"code","c9ef9fe3":"code","c02372d7":"code","b9d749ed":"code","fa07ecb4":"code","834074b2":"code","816ca6fe":"code","c47fe845":"code","484dbea3":"code","17068548":"code","b297d980":"code","2559c58d":"code","da2f74e8":"code","b48dd506":"code","334078ae":"code","c53f8ce8":"code","afa996e3":"code","48e99605":"code","8c1ec27d":"code","c7b93586":"code","a664424b":"code","b03b0ec3":"code","6c84808a":"code","0fbca244":"code","43594243":"code","011c3065":"code","7d49347b":"markdown"},"source":{"b8f05291":"#import libraries\nimport io \nimport pandas as pd\ntrainG = pd.read_excel('..\/input\/train-test-sentiment-analysis\/trainG_clean.xlsx')\ntest = pd.read_excel('..\/input\/train-test-sentiment-analysis\/test_clean.xlsx') ","0432d93c":"trainG","b117856b":"test = test[test['ItemID'].map(len) < 10]\ntest","50b3a39e":"data = trainG.copy()\ndata.drop('ItemID', axis=1, inplace=True)\nprint(data.isnull().any())\ndata['Sentiment'] = data['Sentiment'].astype('category')\nprint(type(data['Sentiment'][0]))\ndata['label_id'] = data['Sentiment'].cat.codes\ndata['label_id'].head()","56834509":"import re\n\nREPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\nREPLACE_WITH_SPACE = re.compile(\"(<br\\s*\/><br\\s*\/>)|(\\-)|(\\\/)\")\n\ndef preprocess_reviews(reviews):\n    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n    \n    return reviews\n\ndata['SentimentText']  = data['SentimentText'].astype(str)\ntest['SentimentText'] = test['SentimentText'].astype(str)\ndata['SentimentText'] = preprocess_reviews(data['SentimentText'])\n\ntest['SentimentText'] = preprocess_reviews(test['SentimentText'])","c8794193":"from sklearn import svm\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report,accuracy_score\nimport six.moves.cPickle as pickle\n","5d0b5818":"\nimport numpy as np \nimport pandas as pd\n\nimport spacy\nfrom spacy.matcher import Matcher\nfrom spacy.tokens import Span\nfrom spacy import displacy","7aa9fcb3":"nlp=spacy.load(\"en_core_web_sm\")","fa74a21d":"from spacy.lang.en.stop_words import STOP_WORDS\nstopwords = list(STOP_WORDS)\nimport string\npunct=string.punctuation\n\ndef text_data_cleaning(sentence):\n    doc = nlp(sentence)\n    \n    tokens = []\n    for token in doc:\n        if token.lemma_ != \"-PRON-\":\n            temp = token.lemma_.lower().strip()\n        else:\n            temp = token.lower_\n        tokens.append(temp)\n    \n    cleaned_tokens = []\n    for token in tokens:\n        if token not in stopwords and token not in punct:\n            cleaned_tokens.append(token)\n    return cleaned_tokens","7b0016fa":"from sklearn.svm import LinearSVC\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","61163927":"tfidf = TfidfVectorizer(tokenizer = text_data_cleaning)\nclassifier = LinearSVC()","f81e43a3":"x = trainG['SentimentText']\ny = trainG['Sentiment']","9a8d705f":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)","0eaee5b3":"clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])","96b28934":"clf.fit(X_train,y_train)","717dc421":"y_pred = clf.predict(X_test)","aaef489c":"print(classification_report(y_test, y_pred))","a63637dc":"y_pred=clf.predict(test['SentimentText'])","c9ef9fe3":"y_pred","c02372d7":"y_pred[1]","b9d749ed":"sub_file=pd.DataFrame({'id':test['ItemID'],'target':y_pred.round().astype(int)})","fa07ecb4":"prediction = list() \nfor i in range(len(test['SentimentText'])):\n  prediction.append(y_pred[i]) \n\n\ntest['prediction'] = prediction  ","834074b2":"\n\ntest.to_excel('resultat_SVM.xlsx' , index=False)\n","816ca6fe":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport pickle\nfrom multiprocessing import Pool","c47fe845":"tfidf = TfidfVectorizer(encoding='utf-8',\n                       ngram_range=(1,3),\n                       max_df=1.0,\n                       min_df=10,\n                       max_features=500,\n                       norm='l2',\n                       sublinear_tf=True)","484dbea3":"train_features = tfidf.fit_transform(X_train).toarray()\nprint(train_features.shape)","17068548":"test_features = tfidf.transform(X_test).toarray()\nprint(test_features.shape)","b297d980":"train_labels = y_train\ntest_labels = y_test","2559c58d":"import pandas as pd\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","da2f74e8":"mnb_classifier = MultinomialNB()","b48dd506":"mnb_classifier.fit(train_features, train_labels)","334078ae":"mnb_prediction = mnb_classifier.predict(test_features)","c53f8ce8":"training_accuracy = accuracy_score(train_labels, mnb_classifier.predict(train_features))\nprint(training_accuracy)","afa996e3":"testing_accuracy = accuracy_score(test_labels, mnb_prediction)\nprint(testing_accuracy)","48e99605":"print(classification_report(test_labels, mnb_prediction))","8c1ec27d":"conf_matrix = confusion_matrix(test_labels, mnb_prediction)\nprint(conf_matrix)","c7b93586":"test_vectorizer =tfidf.transform(test['SentimentText']).toarray()","a664424b":"test_vectorizer.shape","b03b0ec3":"final_predictions = mnb_classifier.predict(test_vectorizer)","6c84808a":"submission_df = pd.DataFrame()","0fbca244":"submission_df['Id'] = test['ItemID']\nsubmission_df['target'] = final_predictions","43594243":"submission_df['target'].value_counts()","011c3065":"submission = submission_df.to_csv('resultat_NB.csv',index = False)\n","7d49347b":" Another Model : Naive bayes "}}