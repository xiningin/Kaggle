{"cell_type":{"8e1a1087":"code","884e8523":"code","9a0a1d7f":"code","f542dbb1":"code","8acd1cbe":"code","79f540b9":"code","f729d9ac":"code","ef058968":"code","49840ecc":"code","0ae08320":"code","dc6e094d":"code","e609a90f":"code","f006f390":"code","ac2fa372":"code","539e9f4f":"code","a487c151":"code","164b08d5":"code","cc93eb62":"code","f2522a2c":"code","0efe029e":"code","cf9986c5":"code","ec72a4bf":"code","787d30e0":"code","522c10ef":"code","725b58ee":"code","a76c47f0":"markdown","2b9f7870":"markdown","a2bd99f5":"markdown","042c51b5":"markdown","aefaed74":"markdown","5a151d13":"markdown"},"source":{"8e1a1087":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nplt.rcParams['figure.figsize'] = (20,15)\nimport seaborn as sns\nimport math\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM, GRU","884e8523":"df = pd.read_csv('..\/input\/monthly-milk-production\/monthly-milk-production-pounds.csv',\n                parse_dates=['Month'])\ndf","9a0a1d7f":"df.dropna(inplace=True)\ndf","f542dbb1":"df.Month = pd.to_datetime(df.Month)\ndf.index = df.Month\ndf.info()","8acd1cbe":"df.drop(columns=['Month'], axis=1, inplace=True)\ndf","79f540b9":"df.columns = ['Production']\ndf","f729d9ac":"df['Year'] = df.index.year\na = df.groupby('Year').mean()\nsns.barplot(x=a.index, y = a.Production)","ef058968":"df = df.iloc[:,:-1]\ndf","49840ecc":"df.plot()","0ae08320":"scaler = MinMaxScaler()\ndf = scaler.fit_transform(df)\n\n# Split\ntrain = int(len(df)*.9)\n\nXtrain, Xtest = df[:train,:], df[train:,:]","dc6e094d":"# Making a X, y for modeling\n\ndef make_dataset(data, window=1):\n    X, y = [], []\n    for i in range(len(data) - window -1):\n        X.append(data[i:i + window,:])\n        y.append(data[i + window,:])\n    return np.array(X), np.array(y)","e609a90f":"Xtrain, ytrain = make_dataset(Xtrain, 3)\nXtest, ytest = make_dataset(Xtest, 3)","f006f390":"model=Sequential()\nmodel.add(LSTM(60,return_sequences=True,input_shape=(3,1)))\nmodel.add(LSTM(60))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')\nmodel.fit(Xtrain,ytrain,validation_data=(Xtest,ytest),epochs=100,batch_size=1,verbose=1)","ac2fa372":"pred = scaler.inverse_transform(model.predict(Xtest))\nytest = scaler.inverse_transform(ytest)","539e9f4f":"mean_squared_error(pred, ytest)","a487c151":"plt.plot(ytest, label='Original Test')\nplt.plot(pred, label='Test Predictions')","164b08d5":"ytrain, pred_train = scaler.inverse_transform(ytrain), scaler.inverse_transform(model.predict(Xtrain))","cc93eb62":"plt.plot(ytrain, label='Original')\nplt.plot(pred_train, label='Train Predictions')\nplt.legend()","f2522a2c":"mean_squared_error(ytrain, pred_train)","0efe029e":"ytrain, ytest = scaler.transform(ytrain), scaler.transform(ytest)","cf9986c5":"model=Sequential()\nmodel.add(GRU(60,return_sequences=True,input_shape=(3,1)))\nmodel.add(GRU(60))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')\nmodel.fit(Xtrain,ytrain,validation_data=(Xtest,ytest),epochs=100,batch_size=1,verbose=1)","ec72a4bf":"pred_train, ytrain = scaler.inverse_transform(model.predict(Xtrain)), scaler.inverse_transform(ytrain)\n\nplt.plot(ytrain, label='Original Training')\nplt.plot(pred_train, label='Train Predictions')\nplt.legend()\n","787d30e0":"mean_squared_error(pred_train, ytrain)","522c10ef":"pred, ytest = scaler.inverse_transform(model.predict(Xtest)), scaler.inverse_transform(ytest)\nplt.plot(ytest, label='Test Original')\nplt.plot(pred, label='Test Predictions')\nplt.legend()","725b58ee":"mean_squared_error(pred, ytest)","a76c47f0":"On test also GRU seem to be better than LSTM.","2b9f7870":"So there is seasonality and trend. Trend seem additive.","a2bd99f5":"# LSTM Model","042c51b5":"GRU seem to be doing better than LSTM on training.","aefaed74":"# GRU Model","5a151d13":"# Scaling and Train test split"}}