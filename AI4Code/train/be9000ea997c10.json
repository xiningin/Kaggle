{"cell_type":{"6dd5d4c7":"code","aeee0046":"code","c784218a":"code","5b1cf1de":"code","0cd8803e":"code","9a326e31":"code","4e21a7da":"code","2166b563":"code","bc160d29":"code","97cd74b9":"code","f8a86486":"code","96a9e5e2":"code","179fe897":"code","80a53131":"code","28c04bdb":"code","94920cef":"code","009b5a68":"code","4e22f873":"markdown","e192f20d":"markdown","9b2ed68f":"markdown","a9eb416f":"markdown","f55d0f47":"markdown","15e2752e":"markdown","1678bc4d":"markdown","422b4fba":"markdown","8c5411b2":"markdown","906baeb9":"markdown","fe83b5bf":"markdown","57af4c25":"markdown","257a8c38":"markdown","9fc516a4":"markdown","6592231f":"markdown","d9c42932":"markdown","c2be8e5b":"markdown","c3d83413":"markdown"},"source":{"6dd5d4c7":"import numpy as np # linear algebra\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndef loadCombinedArray(cases,field):\n    data = np.concatenate([np.load('\/kaggle\/input\/ml-turbulence-dataset\/'+dataset+'\/'+dataset+'_'+case+'_'+field + '.npy') for case in cases])\n    return data","aeee0046":"dataset = 'komegasst' \ncases = ['PHLL_case_1p0']","c784218a":"x = loadCombinedArray(cases,'Cx')\ny = loadCombinedArray(cases,'Cy')\nfig = plt.figure(figsize=(12,4))\nax = fig.add_subplot(111)\nax.scatter(x,y,c='k',s=0.1)\nax.set_aspect(1)","5b1cf1de":"Ux = loadCombinedArray(cases,'Ux')\nUy = loadCombinedArray(cases,'Uy')\np = loadCombinedArray(cases,'p')\n\nfig = plt.figure(figsize=(12,12))\nax1 = fig.add_subplot(311)\nax2 = fig.add_subplot(312)\nax3 = fig.add_subplot(313)\n\nax1.tricontourf(x,y,Ux,levels=50)\nax1.set_aspect(1)\nax2.tricontourf(x,y,Uy,levels=50)\nax2.set_aspect(1)\nax3.tricontourf(x,y,p,levels=50)\nax3.set_aspect(1)","0cd8803e":"from sklearn import preprocessing\nimport pandas as pd\n\ndata_combined = np.column_stack((Ux,Uy,p))\ndf = pd.DataFrame(data=data_combined)\ndf.columns=['Ux','Uy','p']\nprint('Dataframe head: ')\nprint(df.head())\nprint('Dataframe summary: ')\nprint(df.describe())\nprint('Dataframe histograms: ')\ndf.hist(bins=30)\n","9a326e31":"df_features = df[['Ux','Uy']]\ndf_labels = df['p']\n\nscaler_features = preprocessing.MinMaxScaler()\nscaler_labels = preprocessing.MinMaxScaler()\n\ndf_features = pd.DataFrame(scaler_features.fit_transform(df_features), columns = ['Ux','Uy'])\ndf_labels = pd.DataFrame(scaler_labels.fit_transform(df_labels.values.reshape(-1,1)), columns = ['p'])\n\ndf_features.hist(bins=30)\ndf_labels.hist(bins=30)","4e21a7da":"import tensorflow as tf\nfrom tensorflow import keras\nkeras.backend.clear_session()\n\n#The model has two inputs: Ux,Uy\ninput_layer = keras.layers.Input(shape=(2),name ='input_layer')\n\n#Hidden layer definition\nhidden1 = keras.layers.Dense(20,name='Hidden1', kernel_initializer=\"lecun_normal\", activation = \"selu\")(input_layer)\nhidden2 = keras.layers.Dense(20,name='Hidden2', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden1)\nhidden3 = keras.layers.Dense(20,name='Hidden3', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden2)\nhidden4 = keras.layers.Dense(20,name='Hidden4', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden3)\nhidden5 = keras.layers.Dense(20,name='Hidden5', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden4)\n\noutput_layer = keras.layers.Dense(1,name='output_layer')(hidden5)\n\nmodel=keras.Model(inputs=[input_layer], outputs=[output_layer])\nmodel.summary()","2166b563":"optimizer = tf.keras.optimizers.Nadam(learning_rate = 5E-4)\nmodel.compile(optimizer,loss='mse',metrics=['mae', 'mse'])\n\nhistory = model.fit([df_features], df_labels, \n                    epochs=100, \n                    verbose=1, \n                   )","bc160d29":"predictions = model.predict(df_features).reshape(len(df_features))\ntruth = df_labels['p']\n\nfig = plt.figure(figsize=(12,12))\nax1 = fig.add_subplot(211)\nax2 = fig.add_subplot(212)\n\nax1.tricontourf(x,y,predictions,levels=50,vmin=0,vmax=1)\nax1.set_aspect(1)\nax1.set_title('Predictions')\nax2.tricontourf(x,y,truth,levels=50,vmin=0,vmax=1)\nax2.set_aspect(1)\nax2.set_title('Truth')\n","97cd74b9":"gradU = loadCombinedArray(cases,'gradU')\n\ngradUxx = gradU[:,0,0]\ngradUxy = gradU[:,0,1]\ngradUyy = gradU[:,1,1]\nfig = plt.figure(figsize=(12,12))\nax1 = fig.add_subplot(311)\nax2 = fig.add_subplot(312)\nax3 = fig.add_subplot(313)\n\nax1.tricontourf(x,y,gradUxx,levels=50)\nax1.set_aspect(1)\nax2.tricontourf(x,y,gradUxy,levels=50)\nax2.set_aspect(1)\nax3.tricontourf(x,y,gradUyy,levels=50)\nax3.set_aspect(1)\n","f8a86486":"data_combined = np.column_stack((Ux,Uy,gradUxx,gradUxy,gradUyy,p))\ndf = pd.DataFrame(data=data_combined)\ndf.columns=['Ux','Uy','gradUxx','gradUxy','gradUyy','p']\nprint('Dataframe head: ')\nprint(df.head())\nprint('Dataframe summary: ')\nprint(df.describe())\nprint('Dataframe histograms: ')\ndf.hist(bins=30)\n\ndf_features = df[['Ux','Uy','gradUxx','gradUxy','gradUyy']]\ndf_labels = df['p']\n\nscaler_features = preprocessing.MinMaxScaler()\nscaler_labels = preprocessing.MinMaxScaler()\n\ndf_features = pd.DataFrame(scaler_features.fit_transform(df_features), columns = ['Ux','Uy','gradUxx','gradUxy','gradUyy'])\ndf_labels = pd.DataFrame(scaler_labels.fit_transform(df_labels.values.reshape(-1,1)), columns = ['p'])\n\ndf_features.hist(bins=30)\ndf_labels.hist(bins=30)","96a9e5e2":"import tensorflow as tf\nfrom tensorflow import keras\nkeras.backend.clear_session()\n\n#The model has two inputs: Ux,Uy\ninput_layer = keras.layers.Input(shape=(5),name ='input_layer')\n\n#Hidden layer definition\nhidden1 = keras.layers.Dense(20,name='Hidden1', kernel_initializer=\"lecun_normal\", activation = \"selu\")(input_layer)\nhidden2 = keras.layers.Dense(20,name='Hidden2', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden1)\nhidden3 = keras.layers.Dense(20,name='Hidden3', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden2)\nhidden4 = keras.layers.Dense(20,name='Hidden4', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden3)\nhidden5 = keras.layers.Dense(20,name='Hidden5', kernel_initializer=\"lecun_normal\", activation = \"selu\")(hidden4)\n\noutput_layer = keras.layers.Dense(1,name='output_layer')(hidden5)\n\nmodel=keras.Model(inputs=[input_layer], outputs=[output_layer])\nmodel.summary()","179fe897":"optimizer = tf.keras.optimizers.Nadam(learning_rate = 5E-4)\nmodel.compile(optimizer,loss='mse',metrics=['mae', 'mse'])\n\nhistory = model.fit([df_features], df_labels, \n                    epochs=100, \n                    verbose=1, \n                   )","80a53131":"predictions = model.predict(df_features).reshape(len(df_features))\ntruth = df_labels['p']\n\nfig = plt.figure(figsize=(12,12))\nax1 = fig.add_subplot(211)\nax2 = fig.add_subplot(212)\n\nax1.tricontourf(x,y,predictions,levels=50,vmin=0,vmax=1)\nax1.set_aspect(1)\nax1.set_title('Predictions')\nax2.tricontourf(x,y,truth,levels=50,vmin=0,vmax=1)\nax2.set_aspect(1)\nax2.set_title('Truth')","28c04bdb":"dataset = 'komegasst' \ncases = ['PHLL_case_0p5']\nx = loadCombinedArray(cases,'Cx')\ny = loadCombinedArray(cases,'Cy')\nfig = plt.figure(figsize=(12,4))\nax = fig.add_subplot(111)\nax.scatter(x,y,c='k',s=0.1)\nax.set_aspect(1)","94920cef":"data_combined = np.column_stack((Ux,Uy,gradUxx,gradUxy,gradUyy,p))\ndf = pd.DataFrame(data=data_combined)\ndf.columns=['Ux','Uy','gradUxx','gradUxy','gradUyy','p']\nprint('Dataframe head: ')\nprint(df.head())\nprint('Dataframe summary: ')\nprint(df.describe())\nprint('Dataframe histograms: ')\ndf.hist(bins=30)\n\ndf_features = df[['Ux','Uy','gradUxx','gradUxy','gradUyy']]\ndf_labels = df['p']\n\ndf_features = pd.DataFrame(scaler_features.transform(df_features), columns = ['Ux','Uy','gradUxx','gradUxy','gradUyy'])\ndf_labels = pd.DataFrame(scaler_labels.transform(df_labels.values.reshape(-1,1)), columns = ['p'])\n\npredictions = model.predict(df_features).reshape(len(df_features))\ntruth = df_labels['p']\n\nfig = plt.figure(figsize=(12,12))\nax1 = fig.add_subplot(211)\nax2 = fig.add_subplot(212)\n\nax1.tricontourf(x,y,predictions,levels=50,vmin=0,vmax=1)\nax1.set_aspect(1)\nax1.set_title('Predictions')\nax2.tricontourf(x,y,truth,levels=50,vmin=0,vmax=1)\nax2.set_aspect(1)\nax2.set_title('Truth')","009b5a68":"model.evaluate(df_features,df_labels)","4e22f873":"For this simple example, we will use one case from the periodic hills dataset, simulated using the $k$-$\\omega$-SST model in OpenFOAM.","e192f20d":"Adding these velocity gradients have improved the pressure field prediction. This is reflected in the better matching contour field, and the lower training mse in the second model.","9b2ed68f":"Now, we build a neural network that takes the two velocity components as inputs, and outputs the pressure.","a9eb416f":"We train the model now, for 100 epochs:","f55d0f47":"Note that the scaler command has changed from fit_transform to transform (we use the same scaler the model was trained with, which has been fit on the $\\alpha=1.0$ case.","15e2752e":"Finally, let's see how well this model generalizes to a different periodic hills case: the steep $\\alpha=0.5$ case.","1678bc4d":"For our example here, we aim to predict the pressure field from the velocity field. We separate the dataframe into a features and labels dataframe, and use the min-max scaler on both. This scales all the features and labels to range between 0 and 1.","422b4fba":"Let's see what these gradient fields looks like:","8c5411b2":"These metrics are the loss (equal to mse in this case), mae, and mse for the test case.","906baeb9":"We can check the error on this test case:","fe83b5bf":"Interestingly, the model seems to predict similar trends in the pressure fields as for the $\\alpha = 1.0$ case.","57af4c25":"Here, we load the $x$ and $y$ coordinates of the fields, so we can visualize them later on.","257a8c38":"Now, we re-generate our input feature dataframe, which now includes 5 inputs (Ux,Uy, gradUxx, gradUxy, and gradUyy).","9fc516a4":"Our model struggles to predict the pressure field in the separated region, but does identify the acceleration on the right hill. Maybe, if we add the gradient of U as an input feature, the predictions will be better.","6592231f":"In this notebook, we will train a simple model to predict the pressure field from the velocity field. This is a simple example to demonstrate the use of the fields in this dataset.","d9c42932":"Now, let's load and visualize the velocity and pressure fields. Note that the tricontourf algorithm fills some areas below the curve of the hill, but the actual x and y coordinates our data are given on are shown above.","c2be8e5b":"Now, let's visualize our model predictions.","c3d83413":"Let's prepare Ux and Uy as input features for a simple model to predict the pressure field."}}