{"cell_type":{"b17d6587":"code","3fb7a76c":"code","b2a41a6a":"code","2c723fb7":"code","9cf1f281":"code","fa7bc522":"code","78630247":"code","a2361575":"code","3bb7fe39":"code","79fd57ae":"code","b4449b89":"code","21cfe6e8":"code","2b598590":"code","04bc1493":"code","cc0ae878":"code","876d0102":"code","46943500":"code","0ac73c8b":"code","a04f1152":"code","bd923997":"code","4db24ec2":"code","e837ab37":"code","d4ce4d5f":"code","997aad1c":"code","1b498df2":"code","84a4d0ef":"code","5e6454a3":"code","95a3e86a":"code","5595d882":"code","d9d9b165":"code","0e51ef05":"code","62b36cc4":"code","e593a36f":"code","0cca78c1":"code","125e3b5b":"code","2aa086d3":"code","75a889fc":"code","b982e2ba":"code","327309a5":"code","c240178f":"code","acbe4784":"code","31afdf70":"code","c170379c":"code","961c7817":"code","b8b46e2c":"code","f1635461":"code","82cb7f19":"code","180e1de1":"code","2b92a47c":"code","815ee3c7":"code","73a64951":"code","9fb2ea2d":"code","91c58eb2":"code","22f46f0f":"code","2e490bde":"code","cab7d8ca":"code","e8935efd":"code","2e6ea5d9":"code","4b229b76":"code","590ca80b":"code","2d9652b4":"code","e3712f0b":"code","c9089078":"code","fa3679ce":"code","9f293653":"code","7643140a":"code","8d24adab":"code","5ed27091":"code","12a47655":"code","7bc23f42":"code","d8b6a097":"code","02aa206c":"code","0374efc8":"code","a7203b7a":"code","d5b6fe2a":"code","1ba4ba25":"markdown","63347486":"markdown","b179f885":"markdown","de9f1293":"markdown","ae7d7579":"markdown","1000c283":"markdown","52bb9984":"markdown","f3aa604f":"markdown","b090f4b1":"markdown","f8a34cae":"markdown","11cee638":"markdown","5a73cd48":"markdown","3705fc4a":"markdown","bd31141d":"markdown","60ba7f4b":"markdown","1a8c901c":"markdown","4fdfbd19":"markdown","96fd5195":"markdown","a9f0e329":"markdown","52db05be":"markdown","20f1fd53":"markdown","bf99e7cf":"markdown","c6c110b5":"markdown","6105c5d3":"markdown","8808ad84":"markdown","9beadecf":"markdown","98e40b17":"markdown","fdf0d4e2":"markdown","86ee2411":"markdown","30027538":"markdown"},"source":{"b17d6587":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom colorama import Fore,Back,Style","3fb7a76c":"#Importing Data\ndf=pd.read_csv(\"..\/input\/fetal-health-classification\/fetal_health.csv\")\ndf.head()","b2a41a6a":"print(\"SHAPE OF OUR DATA IS : \",df.shape)\nprint(\" \")\nprint(\"***** DTYPES IN OUR DATA *****\")\nprint(df.dtypes)\n      ","2c723fb7":"#COLUMN NAMES\nprint(list(df.columns))","9cf1f281":"df.describe()","fa7bc522":"df.isnull().sum()","78630247":"df_dup=df.copy()\ndf_dup.drop_duplicates(inplace=True)\nprint(\"NEW SHAPE AFTER REMOVING DUPLICATES : \",df_dup.shape)\ndf_dup.head()\n","a2361575":"def with_hue(data,feature,ax):\n    \n    #Number of categories\n    num_of_cat=len([x for x in data[feature].unique() if x==x])\n    \n    bars=ax.patches\n    \n    for ind in range(num_of_cat):\n        ##     Get every hue bar\n        ##     ex. 8 X categories, 4 hues =>\n        ##    [0, 8, 16, 24] are hue bars for 1st X category\n        hueBars=bars[ind:][::num_of_cat] \n        # Get the total height (for percentages)\n        total=sum([x.get_height() for x in hueBars])\n        #Printing percentages on bar\n        for bar in hueBars:\n            percentage='{:.1f}%'.format(100 * bar.get_height()\/total)\n            ax.text(bar.get_x()+bar.get_width()\/2.0,\n                   bar.get_height(),\n                   percentage,\n                    ha=\"center\",va=\"bottom\",fontweight='bold',fontsize=15)\n    \n\n    \ndef without_hue(data,feature,ax):\n    \n    total=float(len(data))\n    bars_plot=ax.patches\n    \n    for bars in bars_plot:\n        percentage = '{:.1f}%'.format(100 * bars.get_height()\/total)\n        x = bars.get_x() + bars.get_width()\/2.0\n        y = bars.get_height()\n        ax.text(x, y,(percentage,bars.get_height()),ha='center',fontweight='bold',fontsize=15)","3bb7fe39":"sns.set_theme(context='notebook',style='white')\nplt.figure(figsize=(20,10))\nplt.text(0.7,1100,\"Data is imbalanced between three classes\",fontweight='bold',fontsize=25,fontstyle='oblique')\nplt.title(\"Countplot of fetal_health\",fontweight='bold',fontsize=25,fontstyle='oblique')\nax=sns.countplot(data=df_dup,x=\"fetal_health\",palette='rocket')\nplt.xticks(fontweight='bold',fontsize=15)\nplt.yticks(fontweight='bold',fontsize=15)\nplt.xlabel(\"fetal_health\",fontweight='bold',fontsize=20,fontstyle='oblique')\nplt.ylabel(\"fetal_health\",fontweight='bold',fontsize=20,fontstyle='oblique')\nwithout_hue(df_dup,\"fetal_health\",ax)","79fd57ae":"plt.figure(figsize=(20,20))\nplt.title(\"HEATMAP OF DATA\",fontsize=25,fontweight='bold')\nsns.heatmap(df_dup.corr(),cmap=\"vlag\",annot=True,annot_kws={'size':13})\nplt.yticks(fontweight='bold',fontsize=20)\nplt.xticks(fontweight='bold',fontsize=20)\nplt.show()","b4449b89":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nimport optuna\nfrom sklearn.metrics import f1_score, roc_auc_score,accuracy_score,confusion_matrix,precision_recall_curve, auc, roc_curve, recall_score, classification_report,plot_confusion_matrix,precision_score","21cfe6e8":"df_dup_ori=df_dup.copy()\n#df_dup_ori=df_dup_ori.drop(['histogram_mode','histogram_median'],axis=1)\ndf_dup_ori","2b598590":"X_ori=df_dup_ori.copy()\nY_ori=X_ori.pop('fetal_health')","04bc1493":"Y_ori.value_counts() #Checking for value counts in our targets","cc0ae878":"#Splitting the data into train and test sets\nx_train_ori,x_test_ori,y_train_ori,y_test_ori=train_test_split(X_ori,Y_ori,test_size=0.3,random_state=42)","876d0102":"def objective_rf_ori(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    max_depth = int(trial.suggest_int('max_depth', 1, 40))\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,class_weight='balanced')\n    return cross_val_score(clf, x_train_ori, y_train_ori, \n           n_jobs=-1, cv=5,scoring=\"f1_micro\").mean()","46943500":"study=optuna.create_study(direction='maximize',study_name=\"RANDOM FOREST\")\nstudy.optimize(objective_rf_ori,n_trials=50)","0ac73c8b":"trial_ori=study.best_trial\nprint(\"Best accuracy  : \",trial_ori.values)\nprint(\"Best Parameter : \",trial_ori.params)","a04f1152":"#Training of the model\nmodel_ori_rf=RandomForestClassifier(n_estimators=158,max_depth=27,class_weight='balanced')\nmodel_ori_rf.fit(x_train_ori,y_train_ori)","bd923997":"pred_ori_rf=model_ori_rf.predict(x_test_ori)\naccuracy_rf=accuracy_score(y_test_ori,pred_ori_rf)\nprecision_rf=precision_score(y_test_ori,pred_ori_rf,average='weighted')\nrecall_rf=recall_score(y_test_ori,pred_ori_rf,average='weighted')\nf1_rf=f1_score(y_test_ori,pred_ori_rf,average='micro')\n\nprint(\"******* RANDOM FOREST CLASSIFIER RESULTS ********\")\nprint(\"Accuracy  :\", accuracy_rf)\nprint(\"Precision : \", precision_rf)\nprint(\"Recall    : \",recall_rf)\nprint(\"F1 Score  : \",f1_rf)","4db24ec2":"print('** CLASSIFICATION REPORT OF RANDOM FOREST CLASSIFIER **')\nprint(\" \")\nprint(classification_report(y_test_ori,pred_ori_rf))","e837ab37":"y_test_ori.value_counts()","d4ce4d5f":"plot_confusion_matrix(model_ori_rf,x_test_ori,y_test_ori)","997aad1c":"import lightgbm as lgb","1b498df2":"def objective_lgbm(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 300)\n    max_depth = int(trial.suggest_int('max_depth', 2, 50))\n    learning_rate=trial.suggest_loguniform('learning_rate',0.001,1)\n    colsample_bytree=trial.suggest_loguniform(\"colsample_bytree\",0.1, 1)\n    num_leaves=trial.suggest_int('num_leaves',10,300)\n    reg_alpha= trial.suggest_loguniform('reg_alpha',0.1,1)\n    reg_lambda= trial.suggest_loguniform('reg_lambda',0.1,1)\n    min_split_gain=trial.suggest_loguniform('min_split_gain',0.1,1)\n    subsample=trial.suggest_loguniform('subsample',0.1,1)    \n    clf = lgb.LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth,\n                            learning_rate=learning_rate,colsample_bytree=colsample_bytree,\n                            num_leaves=num_leaves,reg_alpha=reg_alpha,reg_lambda=reg_lambda,\n                            min_split_gain=min_split_gain,subsample=subsample,class_weight='balanced')\n    \n    return cross_val_score(clf, x_train_ori, y_train_ori, \n           n_jobs=-1, cv=5).mean()","84a4d0ef":"study=optuna.create_study(direction='maximize',study_name='LIGHTGBM')\nstudy.optimize(objective_lgbm,n_trials=50)","5e6454a3":"trial=study.best_trial\nprint(\"Best F1   :\", trial.values)\nprint(\"Best parameters :\",trial.params)","95a3e86a":"model_lgbm=lgb.LGBMClassifier(n_estimators=92, max_depth=6, learning_rate=0.15906569428502207, \n                              colsample_bytree=0.9814279100755071, num_leaves=127, reg_alpha=0.16318429872212306, \n                              reg_lambda=0.10256590944837159, \n                              min_split_gain=0.10060819627698767,subsample=0.5115021752468786,class_weight='balanced')","5595d882":"model_lgbm.fit(x_train_ori,y_train_ori)","d9d9b165":"pred_lgbm=model_lgbm.predict(x_test_ori)\naccuracy_lgbm=accuracy_score(y_test_ori,pred_lgbm)\nprecision_lgbm=precision_score(y_test_ori,pred_lgbm,average='weighted')\nrecall_lgbm=recall_score(y_test_ori,pred_lgbm,average='weighted')\nf1_lgbm=f1_score(y_test_ori,pred_lgbm,average='micro')\n\nprint(\"******* LGBM CLASSIFIER RESULTS ********\")\nprint(\"Accuracy  :\" ,  accuracy_lgbm)\nprint(\"Precision : \", precision_lgbm)\nprint(\"Recall    : \", recall_lgbm)\nprint(\"F1 Score  : \", f1_lgbm)","0e51ef05":"print('** CLASSIFICATION REPORT OF LIGHTGBM CLASSIFIER **')\nprint(\" \")\nprint(classification_report(y_test_ori,pred_lgbm))","62b36cc4":"plot_confusion_matrix(model_lgbm,x_test_ori,y_test_ori)","e593a36f":"df['fetal_health'].value_counts()","0cca78c1":"#Importing mutual information library from sklearn feature selection\nfrom sklearn.feature_selection import mutual_info_classif,mutual_info_regression","125e3b5b":"X=df_dup.copy()\nY=X.pop(\"fetal_health\")\n\n#ENCODING CATEGORICAL FEATURES\n'''for columns in X.select_dtypes('object'):\n    X[columns],_=X[columns].factorize()'''\n\n#Evaluating Mutual information score for each feature    \ndef make_mi_scores(X,Y):\n    mi_scores=mutual_info_classif(X,Y)\n    mi_scores=pd.Series(mi_scores ,name=\"MI_scores\",index=X.columns)\n    mi_scores=mi_scores.sort_values(ascending=False)\n    return(mi_scores)\n\nmi_scores=make_mi_scores(X,Y)\nmi_scores\n    ","2aa086d3":"#Plotting mutual information bar graph \ndef plot_mi_scores(scores):\n    scores=scores.sort_values(ascending=True)\n    width=np.arange(len(scores))\n    ticks=scores.index\n    plt.barh(width,scores)\n    plt.yticks(width,ticks,fontweight='bold',fontsize=20)\n    plt.xticks(fontweight='bold',fontsize=20)\nplt.figure(figsize=(16,18))\nplot_mi_scores(mi_scores)","75a889fc":"#WE CAN SEE HOW MUCH 'histogram_mean' , 'histogram_mode' , 'histogram_median' features are highly correlated\nf,ax=plt.subplots(nrows=1,ncols=3,figsize=(25,10))\nsns.regplot(data=df_dup,x=\"histogram_mean\",y=\"histogram_mode\",ax=ax[0])\nsns.regplot(data=df_dup,x=\"histogram_mean\",y=\"histogram_median\",ax=ax[1])\nsns.regplot(data=df_dup,x=\"histogram_median\",y=\"histogram_mode\",ax=ax[2])","b982e2ba":"#VISUALIZING CHOSEN IMPORTANT W.R.T TARGET FEATURE\nf,ax1=plt.subplots(nrows=5,ncols=2,figsize=(18,40))\n\nsns.stripplot(data=df_dup,x='fetal_health',y='mean_value_of_short_term_variability',palette='cool',ax=ax1[0][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='mean_value_of_short_term_variability',palette='gnuplot',ax=ax1[0][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='abnormal_short_term_variability',palette='cool',ax=ax1[1][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='abnormal_short_term_variability',palette='gnuplot',ax=ax1[1][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='percentage_of_time_with_abnormal_long_term_variability',palette='cool',ax=ax1[2][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='percentage_of_time_with_abnormal_long_term_variability',palette='gnuplot',ax=ax1[2][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_mean',palette='cool',ax=ax1[3][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_mean',palette='gnuplot',ax=ax1[3][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_min',palette='cool',ax=ax1[4][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_min',palette='gnuplot',ax=ax1[4][1])\n","327309a5":"f,ax1=plt.subplots(nrows=4,ncols=2,figsize=(18,40))\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_variance',palette='cool',ax=ax1[0][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_variance',palette='gnuplot',ax=ax1[0][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='accelerations',palette='cool',ax=ax1[1][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='accelerations',palette='gnuplot',ax=ax1[1][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_width',palette='cool',ax=ax1[2][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_width',palette='gnuplot',ax=ax1[2][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='baseline value',palette='cool',ax=ax1[3][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='baseline value',palette='gnuplot',ax=ax1[3][1])\n","c240178f":"f,ax1=plt.subplots(nrows=6,ncols=2,figsize=(18,40))\n\nsns.stripplot(data=df_dup,x='fetal_health',y='mean_value_of_long_term_variability',palette='cool',ax=ax1[0][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='mean_value_of_long_term_variability',palette='gnuplot',ax=ax1[0][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='prolongued_decelerations',palette='cool',ax=ax1[1][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='prolongued_decelerations',palette='gnuplot',ax=ax1[1][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='fetal_movement',palette='cool',ax=ax1[2][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='fetal_movement',palette='gnuplot',ax=ax1[2][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='uterine_contractions',palette='cool',ax=ax1[3][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='uterine_contractions',palette='gnuplot',ax=ax1[3][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='light_decelerations',palette='cool',ax=ax1[4][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='light_decelerations',palette='gnuplot',ax=ax1[4][1])\n\nsns.stripplot(data=df_dup,x='fetal_health',y='histogram_tendency',palette='cool',ax=ax1[5][0])\nsns.boxplot(data=df_dup,x='fetal_health',y='histogram_tendency',palette='gnuplot',ax=ax1[5][1])\n\n","acbe4784":"sns.lmplot(data=df_dup,x='abnormal_short_term_variability',y='fetal_movement',palette='cool'\n           ,hue='fetal_health')","31afdf70":"sns.lmplot(data=df_dup,x='mean_value_of_short_term_variability',y='fetal_movement',palette='cool'\n           ,hue='fetal_health')\n","c170379c":"sns.lmplot(data=df_dup,x='prolongued_decelerations',y='fetal_movement',palette='cool'\n           ,hue='fetal_health')\n","961c7817":"sns.lmplot(data=df_dup,x='accelerations',y='fetal_movement',palette='cool'\n           ,hue='fetal_health')","b8b46e2c":"df_dup.head()","f1635461":"mi_scores1=pd.DataFrame(mi_scores)\nmi_scores2=pd.DataFrame({'Features':mi_scores1.index,'MI':mi_scores1.MI_scores})\nmi_scores2.reset_index(drop=True,inplace=True)\nmi_scores2=mi_scores2[mi_scores2[\"MI\"]>0.0100]\n\nmi_scores2","82cb7f19":"#CREATING NEW DATAFRAME\ndf_dup_new=pd.DataFrame()\n\nfor i in mi_scores2.Features:\n    df_dup_new[i]=df_dup[i]\n    \ndf_dup_new","180e1de1":"#PLOTTING CORRELATION \ndf_heatmap=df_dup_new.copy()\ndf_heatmap['Fetal_health']=Y\nplt.figure(figsize=(18,18))\nsns.heatmap(data=df_heatmap.corr(),annot=True,cmap='vlag',annot_kws={\"size\":14})\nplt.yticks(fontweight='bold',fontsize=20)\nplt.xticks(fontweight='bold',fontsize=20)\nplt.show()","2b92a47c":"x_train,x_test,y_train,y_test=train_test_split(df_dup_new,Y,test_size=0.3,random_state=42)","815ee3c7":"y_train.value_counts()","73a64951":"lis=list(x_train.columns)\nprint(lis)","9fb2ea2d":"def objective(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    max_depth = int(trial.suggest_int('max_depth', 1, 40))\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,class_weight='balanced')\n    return cross_val_score(clf, x_train, y_train, \n           n_jobs=-1, cv=5,scoring=\"f1_micro\").mean()","91c58eb2":"study=optuna.create_study(direction='maximize')\nstudy.optimize(objective,n_trials=50)","22f46f0f":"trial=study.best_trial\nprint(\"Best F1   : \",trial.values)\nprint(\"Best parameterst: \",trial.params)","2e490bde":"model_rf=RandomForestClassifier(n_estimators=163,max_depth=30,class_weight='balanced')\nmodel_rf.fit(x_train,y_train)","cab7d8ca":"pred_rf=model_rf.predict(x_test)\naccuracy_rf=accuracy_score(y_test,pred_rf)\nprecision_rf=precision_score(y_test,pred_rf,average='weighted')\nrecall_rf=recall_score(y_test,pred_rf,average='weighted')\nf1_rf=f1_score(y_test,pred_rf,average='micro')\n\nprint(\"******* RANDOM FOREST CLASSIFIER RESULTS ********\")\nprint(\"Accuracy  :\", accuracy_rf)\nprint(\"Precision : \", precision_rf)\nprint(\"Recall    : \",recall_rf)\nprint(\"F1 Score  : \",f1_rf)","e8935efd":"print(classification_report(y_test,pred_rf))","2e6ea5d9":"plot_confusion_matrix(model_rf,x_test,y_test)","4b229b76":"import lightgbm as lgb","590ca80b":"def objective_lgbm(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 300)\n    max_depth = int(trial.suggest_int('max_depth', 2, 50))\n    learning_rate=trial.suggest_loguniform('learning_rate',0.001,1)\n    colsample_bytree=trial.suggest_loguniform(\"colsample_bytree\",0.1, 1)\n    num_leaves=trial.suggest_int('num_leaves',10,300)\n    reg_alpha= trial.suggest_loguniform('reg_alpha',0.1,1)\n    reg_lambda= trial.suggest_loguniform('reg_lambda',0.1,1)\n    min_split_gain=trial.suggest_loguniform('min_split_gain',0.1,1)\n    subsample=trial.suggest_loguniform('subsample',0.1,1)    \n    clf = lgb.LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth,\n                            learning_rate=learning_rate,colsample_bytree=colsample_bytree,\n                            num_leaves=num_leaves,reg_alpha=reg_alpha,reg_lambda=reg_lambda,\n                            min_split_gain=min_split_gain,subsample=subsample,class_weight='balanced')\n    \n    return cross_val_score(clf, x_train, y_train, \n           n_jobs=-1, cv=5,scoring='f1_micro').mean()","2d9652b4":"study=optuna.create_study(direction='maximize')\nstudy.optimize(objective_lgbm,n_trials=50)","e3712f0b":"trial=study.best_trial\nprint(\"Best accuarcy : \",trial.values)\nprint(\"Best Params   : \",trial.params)","c9089078":"model_lgbm=lgb.LGBMClassifier(n_estimators=232, max_depth=19, learning_rate=0.6892271434058066, \n                              colsample_bytree=0.7209642378652753, num_leaves=58, reg_alpha=0.2789929636049069, \n                              reg_lambda=0.22306483739443742, \n                              min_split_gain=0.10007706931197725,subsample=0.3982537512515395,class_weight='balanced')","fa3679ce":"model_lgbm.fit(x_train,y_train)","9f293653":"pred_lgbm=model_lgbm.predict(x_test)\naccuracy_lgbm=accuracy_score(y_test,pred_lgbm)\nprecision_lgbm=precision_score(y_test,pred_lgbm,average='weighted')\nrecall_lgbm=recall_score(y_test,pred_lgbm,average='weighted')\nf1_lgbm=f1_score(y_test,pred_lgbm,average='micro')\n\nprint(\"******* LGBM CLASSIFIER RESULTS ********\")\nprint(\"Accuracy  :\" ,  accuracy_lgbm)\nprint(\"Precision : \", precision_lgbm)\nprint(\"Recall    : \", recall_lgbm)\nprint(\"F1 Score  : \", f1_lgbm)","7643140a":"print(classification_report(y_test,pred_lgbm))","8d24adab":"plot_confusion_matrix(model_lgbm,x_test,y_test)","5ed27091":"sm=SMOTE()\nx_train_samp,y_train_samp=sm.fit_resample(x_train,y_train)","12a47655":"def objective(trial):\n    \n    n_estimators = trial.suggest_int('n_estimators', 2, 200)\n    max_depth = int(trial.suggest_int('max_depth', 1, 40))\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n    return cross_val_score(clf, x_train_samp, y_train_samp, \n           n_jobs=-1, cv=5,scoring=\"f1_micro\").mean()","7bc23f42":"study=optuna.create_study(direction='maximize')\nstudy.optimize(objective,n_trials=50)","d8b6a097":"trial=study.best_trial\nprint(\"Best F1   : \",trial.values)\nprint(\"Best parameterst: \",trial.params)","02aa206c":"model_rf_samp=RandomForestClassifier(n_estimators=195,max_depth=22)\nmodel_rf_samp.fit(x_train_samp,y_train_samp)","0374efc8":"pred_rf=model_rf_samp.predict(x_test)\naccuracy_rf=accuracy_score(y_test,pred_rf)\nprecision_rf=precision_score(y_test,pred_rf,average='weighted')\nrecall_rf=recall_score(y_test,pred_rf,average='weighted')\nf1_rf=f1_score(y_test,pred_rf,average='micro')\n\nprint(\"******* RANDOM FOREST CLASSIFIER RESULTS WITH UPSAMPLING********\")\nprint(\"Accuracy  :\", accuracy_rf)\nprint(\"Precision : \", precision_rf)\nprint(\"Recall    : \",recall_rf)\nprint(\"F1 Score  : \",f1_rf)","a7203b7a":"print(classification_report(y_test,pred_rf))","d5b6fe2a":"plot_confusion_matrix(model_rf_samp,x_test,y_test)","1ba4ba25":"<html>\n    <p style='color:pink;'><b>GETTING IMPORTANT FEATURES INTO DATAFRAME<\/b><\/p>\n<\/html>\n","63347486":"<html>\n    <p style='color:green;'><b>REMOVING DUPLICATES<\/b><\/p>\n<\/html>\n","b179f885":"<html>\n    <h1 style='color:pink;'><b>FINISH<\/b><\/h1>\n<\/html>\n\n* **I WAS TRYING TO DO SOMETHING DIFFERENT ABOVE , BUT IN MY OPINION DATASET AND OUR ENSEMBLERS ARE SO GOOD , THAT EVEN WITHOUT DOING ANYTHING ON DATA WE ARE GETTING GOOD RESULTS**\n\n* **WE EVEN GOT VERY GOOD RESULTS WITH SMOTE UPSAMPLING**\n\n* **IF YOU HAVE ANY DOUBTS OR I HAVE DONE ANY MISTAKE , PLEASE TELL ME I WILL EDIT THIS NOTEBOOK AGAIN , I AM ALWAYS READY TO IMPROVE MYSELF**\n\n* **IF YOU REALLY LIKE MY NOTEBOOOK DO PROVIDE FEEDBACK AND UPVOTE , MAY BE IT WILL BE HELP TO GET A JOB**\n\n* **I LOVE TO DO EXPERIMENTS AND TRYING OUT NEW THINGS , IF YOU WANT ME TO DO SOMETHING LET ME KNOW IN THE COMMENTS SECTION**\n\n* **IF YOU WANT TO KNOW ABOUT MUTUAL INFORMATION PLEASE VISIT FEATURE ENGINEERING MINI COURSE ON KAGGLE AND I HAVE DECIDED TO APPLY THAT IN THIS NOTEBOOK**\n\n* **LET'S MEET ONTO NEXT NOTEBOOK**\n","de9f1293":"* **AS WE CAN SEE BELOW IN BOX PLOTS THERE ARE LOT OF OUTLIERS PRESENT IN THE DATA FOR MANY FEATURES IF WE REMOVE THEM THERE WILL LOSS OF DATA , SO WE WILL MOVE FORWARD WITHOUT REMOVING OUTLIERS**","ae7d7579":"<html>\n    <h1 style='color:pink;'>MOTIVATION<\/h1>\n<\/html>","1000c283":"**WE HAVE 2126 ROWS and 22 COLUMNS**\n\n* **THREE TARGET FEATURES**\n  * **NORMAL**\n  * **SUSPECT**\n  * **PATHOLOGICAL**","52bb9984":"<html>\n    <p style='color:pink;'><b>RANDOMFOREST CLASSIFIER<\/b><\/p>\n<\/html>","f3aa604f":"<html>\n    <p style='color:pink;'><b>LIGHT GBM CLASSIFIER<\/b><\/p>\n<\/html>","b090f4b1":"<html>\n    <h1 style='color:green;'>PREDICTING WITHOUT REMOVING ANY FEATURES<\/h1>\n<\/html>","f8a34cae":"\n<html>\n    <p style='color:pink;'><b>LET'S DO PREDICTIONS AND SEE HOW OUR MUTUAL INFORMATION METHOD WORKS<\/b><\/p>\n<\/html>\n","11cee638":"<html>\n    <p style='color:green;'><b>WHAT WILL BE THE RESULTS IF WE USE UPSAMPLING<\/b><\/p>\n<\/html>\n","5a73cd48":"<html>\n    <p style='color:green;'><b>CHECKING NULL VALUES<\/b><\/p>\n<\/html>\n\n* **There is no null values in this data**","3705fc4a":"**WE HAVE 22 FEATURES AND WE WON'T ANALYSE EACH AND EVERY COLUMN , SO WHAT WE ARE GOING TO DO?**\n\n* **FIRST OF ALL WE WILL DO PREDCITIONS WITHOUT REMOVING ANY FEATURES AND OBSERVE OUR RESULTS, I WILL USE ENSEMBLING METHODS TO OBTAIN RESULTS (RANDOM FOREST AND LIGHT GBM)**\n\n* **SECOND , WE WILL ANALYSE WHICH ARE THE MOST IMPORTANT FEATURES ACCORDING TO OUR TARGET \"fetal_health\" (THIS TIME WILL TRY SOMETHING NEW , YEAH I LOVE TO DO EXPERIMENTS)**\n\n* **THEN WE WILL REMOVE THOSE FEATURES WHICH ARE LEAST IMPORTANT AND NOT EFFECTIVELY CONTRIBUTING TOWARDS TARGET , WE WILL ALSO CHECK WHETHER LEAST CONTRIBUTING TARGETS ARE INTERACTING FEATURES BETWEEN ANY TWO FEATURES OR NOT AND DECIDE WHETHER TO KEEP THOSE FEATURES OR NOT**\n\n* **WE WIL BE USING \"MUTUAL INFORMATION\" RATHER THAN CORRELATION TO GET MOST IMPORTANT FEATURES**\n\n* **WELL I AM ASLO LEARNING NEW THINGS :) , IF YOU FIND ANY MISTAKES PLEASE LET ME KNOW AND I WILL TRY MY BEST TO MAKE YOU UNDERSTAND**\n","bd31141d":"<html>\n    <p style='color:green;'><b>LIGHT GBM CLASSIFIER<\/b><\/p>\n<\/html>\n","60ba7f4b":"<html>\n    <p style='color:green;'><b>IMPORTING LIBRARIES<\/b><\/p>\n<\/html>","1a8c901c":"* **Cardiotocography can be used to monitor a baby's heart rate and a mother's contractions while the baby is in the uterus**\n\n* **CTG is used both before birth and during labour, to monitor the baby for any signs of distress. By looking at various different aspects of the baby's heart rate, doctors can see the condition of a baby**\n\n* **The vast majority of these deaths (94%) occurred in low-resource settings, and most could have been prevented**\n\n* **I have worked on data and trying to predict the well being of baby**","4fdfbd19":"<html>\n    <p style='color:green;'><b>HYPERPARAMETER TUNING USING OPTUNA<\/b><\/p>\n<\/html>","96fd5195":"<html>\n    <h1 style='color:pink;'>TABLE OF CONTENTS<\/h1>\n<\/html>\n\n* **ANALYSIS**\n\n\n* **PREDICTING WITHOUT REMOVING ANY FEATURES**\n   * **RANDOM FOREST CLASSIFIER**\n   * **LIGHT GBM**\n   \n* **ANALYSING WITH MUTUAL INFORMATION**\n   * **PLOTTING MI SCORES**\n   * **VISUALIZING IMPORTANT FEATURES**\n   * **PREDICTIONS ON THE BASIS OF MUTUAL INFORMATION**\n     * **RANDOM FOREST CLASSIFIER**\n     * **LIGHT GBM CLASSIFIER**\n     \n* **CONCLUSIONS**\n\n\n   \n","a9f0e329":"**CONCLUSION**\n* **LGBM CLASSIFIER PROVIDES US EXTREMELY GOOD RESULTS AS COMPARED TO RANDOM FOREST CLASSIIFIER**\n* **NOW THE QUESTION ARISES WHAT IF WE REMOVE SOME FEATURES BASED ON \"MUTUAL INFORMATION\" AND OBSERVE THE RESULTS , LET'S START WITH THIS EXPERIMENT AND OBSERVE WILL IT MAKE MORE IMPACT?**\n","52db05be":"* **AFTER REMOVING SOME FEATURES THERE IS NO AS SUCH IMPROVEMENT IN THE F1_SCORE**\n\n* **BUT WE ARE ABLE TO GET GOOD SCORE WITH LESS FEATURES , THAT MEANS THE FEATURES WE REMOVED ARE NOT CONTRIBUTING TOWARDS TARGET**\n\n* **LIGHT GBM CLASSIFIER WORKS BETTER THAN RANDOM FOREST CLASSIFIER**","20f1fd53":"**PLOTTING MI SCORES**","bf99e7cf":"![FETAL](https:\/\/media.istockphoto.com\/vectors\/pregnancy-fertilization-related-vector-id975895412?k=6&m=975895412&s=612x612&w=0&h=L-uCk_0_OJsVAedKwijXtRfxJ0NkZaqOsfX20K9Hq-s=)","c6c110b5":"<html>\n    <p style='color:green;'><b>RANDOM FOREST CLASSIFIER<\/b><\/p>\n<\/html>\n","6105c5d3":"<html>\n    <h1 style='color:pink;'>ANALYSIS<\/h1>\n<\/html>\n\n* **METRICS WE WILL FOCUS ON**\n  * **F1 SCORE**\n  * **PRECISION AND RECALL**","8808ad84":"<html>\n    <p style='color:green;'><b>VISUALIZING IMPORTANT FEATURES<\/b><\/p>\n<\/html>","9beadecf":"<html>\n    <h1 style='color:pink;'>CONCLUSIONS<\/h1>\n<\/html>","98e40b17":"**FROM THE ABOVE BAR GRAPH WE WILL TAKE THOSE FEATURES WHOSE MI SCORES ARE NEAR TO 0.0**\n\n* **THERE IS SOMETHING I WANT TO SHARE IS THAT:**\n\n    1. **'histogram_mean' , 'histogram_mode' , 'histogram_median' features are highly correlated with       each other, these features will lead to the problem of multicollinearity,but we should consider       this problem while using regression models , here we will use ensemble methods so this               multicollinearity won't effect much**","fdf0d4e2":"<html>\n    <p style='color:pink;'><b>IMPORTING LIBRARIES FOR PREDICTION<\/b><\/p>\n<\/html>","86ee2411":"<html>\n    <h1 style='color:pink;'>ANALYSING WITH \"MUTUAL INFORMATION\"<\/h1>\n<\/html>","30027538":"<html>\n    <p style='color:pink;'><b>SOME PLOTS THAT MIGHT BE USEFUL<\/b><\/p>\n<\/html>\n"}}