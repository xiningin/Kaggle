{"cell_type":{"62a920a6":"code","1127d727":"code","c4209e99":"code","03cf3d25":"code","14176940":"code","6567694d":"code","1631c5c4":"code","7f940b0b":"code","9d082951":"code","894af587":"code","0c91a279":"code","5aa88720":"code","b2b20286":"code","973ec36b":"code","ea1c6db1":"code","b6ef66dc":"code","bea0e53e":"code","62303411":"code","f647d98a":"code","c66f36ce":"code","5d68f8d2":"code","5a675860":"code","df95f3c1":"code","8e546a88":"code","98ea0b54":"code","c9075341":"code","452fb563":"code","9a1ec194":"code","76e09325":"code","ae0dd496":"code","64ccd6d1":"code","1a49204c":"code","1c0c12d0":"code","3e4b797b":"code","71715aba":"code","4fb1b21b":"code","59c55ec6":"code","8d027c5c":"code","8672d095":"code","1c5f17ba":"code","00ca6d23":"code","991a7bc8":"code","973a675e":"code","baa6325e":"code","7c9ae741":"code","4477b422":"code","54374b2f":"code","9e49288f":"code","f6ba6603":"code","9c53eb4a":"code","a8ff2212":"code","8f47836f":"code","56e16e4c":"code","1b63bfa3":"code","e495cd44":"code","7796f11b":"code","ec838b17":"code","ac118cd9":"code","c8eb680f":"code","aa20a065":"code","e7b9439b":"code","9ed78d89":"code","e98cd07b":"code","1271b67f":"code","7cbfd570":"code","133de2bd":"code","9f2cefbd":"code","b87d013c":"code","9cf380dd":"code","c6d5c1d4":"code","d5b83848":"code","64d43d10":"code","e9298a15":"code","409c3d64":"code","e4b1206d":"code","91ea6e24":"code","90ba25d1":"code","009bb125":"code","71b1e154":"code","0cebe3ff":"code","75071062":"code","8a9deb6b":"code","50456569":"code","1a593fdc":"code","92a0c0b3":"code","fa81b11b":"code","33e10829":"code","f749c4d9":"code","cc2cbf63":"code","53ae70a5":"code","cca4938e":"code","f7cdfb9c":"code","99025898":"code","bc4ff30a":"code","ce1dede0":"code","5ea1ffc4":"code","1a30044c":"code","a64aa857":"code","2c1b44e7":"code","c143fcda":"code","53c5cfb2":"code","611f405c":"code","50b68ace":"code","c99e3dce":"code","3e930bcf":"code","fc44e84a":"code","67bb77ba":"code","14fc2a7a":"code","93a72aca":"code","559b1af8":"code","11675cca":"code","2c963e36":"code","7a489525":"code","079aa737":"code","7ffe72cd":"code","d2fbbbe6":"code","49d24b1f":"code","54ad64ee":"code","5c4dc15d":"code","ad71d291":"code","28523499":"code","03689761":"code","bec5abda":"code","f98f4d20":"code","0feac1de":"markdown","ac276773":"markdown","dec613cd":"markdown","82598935":"markdown","d4d01da0":"markdown","b07bf740":"markdown","7c5b25f4":"markdown","c260a87f":"markdown","def71e8a":"markdown","252c173b":"markdown","188c0dda":"markdown","5294cbc6":"markdown","77c8065e":"markdown","f228cb1f":"markdown","138ca73e":"markdown","e4499456":"markdown","79f94ee4":"markdown","482600ed":"markdown","acc31803":"markdown","04b647d8":"markdown","100472b9":"markdown","1e005254":"markdown","8ebc9454":"markdown","08017414":"markdown","b32d4858":"markdown","cb915441":"markdown","4b10ec3a":"markdown","517fa88b":"markdown","4ac5a285":"markdown","fa3b9e75":"markdown","cde0a21f":"markdown","12067f81":"markdown","a8e76bdb":"markdown","fabb996d":"markdown","63fd11ce":"markdown","fa60cafc":"markdown","78540051":"markdown","3fd96d50":"markdown"},"source":{"62a920a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1127d727":"#arrays and dataframes operations \nimport os\nimport math\nfrom pprint import pprint\nimport statistics\nimport numpy as np\nimport pandas as pd\nfrom datetime import date\n#visualization imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n#consistent plot sizes\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 12,5\nrcParams['axes.labelsize'] = 12\nrcParams['xtick.labelsize'] = 12\nrcParams['ytick.labelsize'] = 12\n#handle unwanted warnings\nimport warnings\nwarnings.filterwarnings(action='ignore',category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore',category=FutureWarning)\n#display all the columns\npd.options.display.max_columns = False\n#import label encoder\nfrom sklearn.preprocessing import LabelEncoder\n#import transformer\nfrom sklearn.preprocessing import PowerTransformer\n#import the modeling libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\n#linear models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import Ridge\n#ensemble techniqques\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n#xgboost\nfrom xgboost import XGBRegressor\n#pipeline\nfrom sklearn.pipeline import Pipeline\n#model evaluation\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\n#dimensionality reduction\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import KernelPCA\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.manifold import LocallyLinearEmbedding\n\n#helper function\n#create a feature with the number of occurences\n\ndef num_sightseeing(dataset,col='Sightseeing Places Covered'):\n    \n    '''This function returns the number of attributes separated by |. \n    The function was written later in the code but found its usefulness for multiple features.\n    Hence it is added here and the name of the function resembles it is only for sight seeing \n    feature which is not the case in reality. '''\n    \n    num_sightseeing = []\n    for i in range(len(dataset)):\n        if dataset[col][i] == 'Not Available':\n            num_sightseeing.append(-1)\n        else:\n            num_sightseeing.append(dataset[col][i].count('|'))    \n    return num_sightseeing ","c4209e99":"#load as pandas dataframe\ntrain = pd.read_csv('\/kaggle\/input\/work-vacation-price-prediction-dataset\/Train.csv',delimiter=',',engine='python')\ntest =  pd.read_csv('\/kaggle\/input\/work-vacation-price-prediction-dataset\/Test.csv',delimiter=',',engine='python')","03cf3d25":"#check the few top rows\ntrain.head()","14176940":"test.head(3)","6567694d":"#check the info .. \ntrain.info()","1631c5c4":"test.info()","7f940b0b":"#check for number of rows where we have Not Available string\nif train['Airline'].str.contains('Not Available').any():\n    print (\"Not Available is present\")","9d082951":"#check the frequency of 'Not Available' in the train dataset\ncat_features = train.select_dtypes(include='object').columns.tolist()\nfor col in cat_features:\n    NA_count= train[col].str.contains('Not Available').sum()\n    if NA_count>0:\n        print (\"In {} there are {} 'Not Available'\".format(col,NA_count))","894af587":"#check the frequency of 'Not Available' in the test dataset \nfor col in cat_features:\n    NA_count= test[col].str.contains('Not Available').sum()\n    if NA_count>0:\n        print (\"In {} there are {} 'Not Available'\".format(col,NA_count))","0c91a279":"#check for duplicates in the train data\ntrain.duplicated().sum()","5aa88720":"#check the number of unique id's\nlen(train['Uniq Id'].unique())","b2b20286":"#basic stats of the numerical features\ntrain.describe()","973ec36b":"#check the skew of the target variable \ntrain['Per Person Price'].skew()","ea1c6db1":"#explore the price per person \nplt.hist(train['Per Person Price'],bins=30,histtype='stepfilled',color='green',alpha=0.3)\nplt.title('Histogram of Per Person Price')\nplt.xlabel('Per Person Price')\nplt.ylabel('Frequency')\nplt.show()","b6ef66dc":"#check for the normality of the target variable using Shapiro Wilk test\nfrom scipy.stats import shapiro\nwarnings.filterwarnings(action='ignore')\ndata = train['Per Person Price']\nstat, p = shapiro(data)\nprint('stat=%.3f, p=%.3f' % (stat, p))\nif p > 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')","bea0e53e":"#create a list of numerical features\nnum_features = train.select_dtypes(exclude='object').columns.tolist()\nnum_features","62303411":"#explore the Flight stops\nsns.countplot(train['Flight Stops'])\nplt.title('Countplot of Flight Stops')\nplt.xlabel('Number of Flight Stops')\nplt.show()","f647d98a":"#explore the price per person \nsns.countplot(train['Meals'])\nplt.title('Countplot for Meals')\nplt.xlabel('Number of Meals')\nplt.show()","c66f36ce":"#check the correlation between the numerical features\ntrain.corr()['Per Person Price']","5d68f8d2":"#check the correlation b\/n meals and flight stops\ntrain[['Meals','Flight Stops']].corr()","5a675860":"#check the travel package for which the price per person is very high\ntrain[train['Per Person Price'] == train['Per Person Price'].min()]","df95f3c1":"#check the travel package for which the price per person is very high\ntrain[train['Per Person Price'] == train['Per Person Price'].max()]","8e546a88":"#price per person vs package type and categorised by start city\nsns.stripplot(x='Meals',y='Per Person Price',hue='Flight Stops',data=train)\nplt.title('Price per person vs the #Meals categorised by Flight Stops')\nplt.xlabel('Number of Meals')\nplt.show()","98ea0b54":"#list of categorical features\ncat_features","c9075341":"#number of cancellation policies \/ rules\ntrain['Cancellation Rules'].nunique()","452fb563":"#check frequency of various cancellation rules\ntrain['Count'] = 1\npd.pivot_table(data=train,index='Cancellation Rules',values='Count',aggfunc='sum')","9a1ec194":"#frequency of each package type\ntrain['Package Type'].value_counts()","76e09325":"#check the mean per person price for different package type \npackage_price = pd.pivot_table(data=train,values='Per Person Price',index='Package Type',aggfunc='mean')\npackage_price.sort_values(by='Per Person Price',ascending=False)","ae0dd496":"#price per person vs package type and categorised by start city\nsns.stripplot(x='Package Type',y='Per Person Price',hue='Start City',data=train)\nplt.title('Price per person vs the Package Type')\nplt.show()","64ccd6d1":"#look at the data again\ntrain.tail(2)","1a49204c":"#unique number of packages\ntrain['Package Name'].nunique()","1c0c12d0":"#check the most frequent \/ booked packages\ntrain['Package Name'].value_counts().sort_values(ascending=False)","3e4b797b":"#check the start city -- > determine whether all travels start from India or elsewhere\ntrain['Start City'].value_counts()","71715aba":"#unique destinations \/ combination of destinations managed by the travel company\ntrain['Destination'].nunique()","4fb1b21b":"#frequency of the destinations \ntrain['Destination'].value_counts()","59c55ec6":"#average per person price when destination is Goa alone .. \ntrain[train['Destination']=='Goa'].groupby('Destination')['Per Person Price'].apply(np.mean)","8d027c5c":"#hotel details\ntrain['Hotel Details'].nunique()","8672d095":"#top 5 hotel details .. \ntrain['Hotel Details'].value_counts()[:5]","1c5f17ba":"#check all the hotel details when the destination is in Goa\ntrain[train['Destination']=='Goa']['Hotel Details'].value_counts()","00ca6d23":"#check a few of the travels where the hotel detail is not available \ntrain[train['Hotel Details'] ==  'Not Available'][:3]","991a7bc8":"train[train['Hotel Details'] ==  'Not Available'].loc[13]['Package Name']","973a675e":"#start city and no airline booking to the destinations .. \nno_airline = train[train['Airline']=='Not Available']\nno_airline['Start City'].value_counts().plot(kind='bar')\nplt.title('Start City without Airline Booking')\nplt.show()","baa6325e":"train['Itinerary'].value_counts()","7c9ae741":"#convert the date column to a datetime object\ntrain['Travel Date'] = pd.to_datetime(train['Travel Date'])\ntest['Travel Date'] = pd.to_datetime(test['Travel Date'])","4477b422":"#create a new featute based on travel month \ntrain['Travel Month'] = train['Travel Date'].dt.month_name()","54374b2f":"test['Travel Month'] = test['Travel Date'].dt.month_name()","9e49288f":"#preferred month to Goa \ntrain[train['Destination']=='Goa']['Travel Month'].value_counts().plot(kind='bar',color='green',alpha=0.4)\nplt.title('Month wise booking to destination Goa')\nplt.xlabel('Month')\nplt.ylabel('Number of Travels')\nplt.grid(False)\nplt.show()","f6ba6603":"#price per person vs package type and categorised by start city\nplt.figure(figsize=(15,5))\nsns.stripplot(x='Travel Month',y='Per Person Price',data=train,alpha=0.4,hue='Start City',dodge=True)\nplt.title('Price per person vs the Travel Month')\nplt.show()","9c53eb4a":"#price per person vs travel month and destination is goa\nplt.figure(figsize=(15,5))\nsns.stripplot(x='Travel Month',y='Per Person Price',data=train[train['Destination']=='Goa'],alpha=0.6)\nplt.title('Price per person vs the Travel Month for Destination Goa')\nplt.show()","a8ff2212":"#check whether Destination and Places Covered are identical series\ntrain['Destination'].equals(train['Places Covered'])","8f47836f":"#drop the Places covered from the train and test dataset\ntrain.drop('Places Covered',axis=1,inplace=True)\ntest.drop('Places Covered',axis=1,inplace=True)","56e16e4c":"train.head(1)","1b63bfa3":"#create a new featute based on travel weekday\ntrain['Travel Start Day'] = train['Travel Date'].dt.weekday\ntest['Travel Start Day'] = test['Travel Date'].dt.weekday","e495cd44":"#for modeling the integer representation of the month will be more appropriate .. \ntrain['Travel Month'] = train['Travel Date'].dt.month\ntest['Travel Month'] = test['Travel Date'].dt.month","7796f11b":"#create a new featute based on travel year\ntrain['Travel Year'] = train['Travel Date'].dt.year\ntest['Travel Year'] = test['Travel Date'].dt.year","ec838b17":"#conver to float -- better for neural network models\ntrain['Travel Start Day'] = train['Travel Start Day'].astype('float')\ntest['Travel Start Day'] = test['Travel Start Day'].astype('float')\n\ntrain['Travel Month'] = train['Travel Month'].astype('float')\ntest['Travel Month'] = test['Travel Month'].astype('float')\n\ntrain['Meals'] = train['Meals'].astype('float')\ntest['Meals'] = test['Meals'].astype('float')\n\ntrain['Flight Stops'] = train['Flight Stops'].astype('float')\ntest['Flight Stops'] = test['Flight Stops'].astype('float')","ac118cd9":"#one hot encoding for the Start City feature\nstart_city = pd.get_dummies(train['Start City'],drop_first=True)\ntrain = pd.concat([train,start_city],axis=1)\ntrain.drop('Start City',axis=1,inplace=True)\ntrain.head(1)","c8eb680f":"#one hot encoding for the Start City feature in test dataset\nstart_city = pd.get_dummies(test['Start City'],drop_first=True)\ntest = pd.concat([test,start_city],axis=1)\ntest.drop('Start City',axis=1,inplace=True)\ntest.head(1)","aa20a065":"#one hot encoding for the package type in the train dataset\npackage_type = pd.get_dummies(train['Package Type'],drop_first=True)\ntrain = pd.concat([train,package_type],axis=1)\ntrain.drop('Package Type',axis=1,inplace=True)\n\n#one hot encoding of the package type in the test dataset\npackage_type = pd.get_dummies(test['Package Type'],drop_first=True)\ntest = pd.concat([test,package_type],axis=1)\ntest.drop('Package Type',axis=1,inplace=True)","e7b9439b":"#drop the uniq id from the feature set\ntrain.drop('Uniq Id',axis=1,inplace=True)\ntest.drop('Uniq Id',axis=1,inplace=True)","9ed78d89":"#drop the dummy count column created earlier\ntrain.drop('Count',axis=1,inplace=True)","e98cd07b":"#view the new dataframe \ntrain.head(2)","1271b67f":"#convert travel year to object and one hot encode , there are only two years 2021 and 2022\ntrain['Travel Year'] = train['Travel Year'].astype(str)\ntest['Travel Year'] = test['Travel Year'].astype(str)\n\ntravel_year = pd.get_dummies(train['Travel Year'],drop_first=True)\ntrain = pd.concat([train,travel_year],axis=1)\ntrain.drop('Travel Year',axis=1,inplace=True)\n\ntravel_year = pd.get_dummies(test['Travel Year'],drop_first=True)\ntest = pd.concat([test,travel_year],axis=1)\ntest.drop('Travel Year',axis=1,inplace=True)","7cbfd570":"# new data frame with split value columns on the destination feature\nnew = train['Destination'].str.split('|',expand = True) \nnew.head(3)","133de2bd":"#check the info \nnew.info()","9f2cefbd":"new.columns = ['place_1','place_2','place_3','place_4','place_5','place_6','place_7','place_8',\n              'place_9','place_10','place_11']\nnew.head(2)","b87d013c":"new.drop(['place_5','place_6','place_7','place_8','place_9','place_10','place_11'],axis=1,\n        inplace=True)\nnew.head(2)\n","9cf380dd":"#append to the train column .. \ntrain = pd.concat([train,new],axis=1)","c6d5c1d4":"new = test['Destination'].str.split('|',expand = True) \nnew.info()","d5b83848":"#repeat the steps on the test dataset \nnew = test['Destination'].str.split('|',expand = True) \nnew.columns = ['place_1','place_2','place_3','place_4','place_5','place_6','place_7','place_8',\n              'place_9','place_10','place_11']\nnew.drop(['place_5','place_6','place_7','place_8','place_9','place_10','place_11'],axis=1,\n        inplace=True)\n#append to the test column .. \ntest = pd.concat([test,new],axis=1)","64d43d10":"#add a new feature = number of places covered durign the trip \n'''The function definition is below. This feature was added later.'''\n#create the new feature -- > number of hotels booked during the trip\ntrain['num_destination'] = num_sightseeing(dataset=train,col='Destination')\ntest['num_destination'] =  num_sightseeing(dataset=test,col='Destination')","e9298a15":"#drop the redundant Destination column from the train and test dataset\ntrain.drop('Destination',axis=1,inplace=True)\ntest.drop('Destination',axis=1,inplace=True)","409c3d64":"#replace the None in place_* with Not Available string\nplaces = ['place_1','place_2','place_3','place_4']\nfor col in places:\n    train[col].replace([None],np.nan,inplace=True)\n    test[col].replace([None],np.nan,inplace=True)\n    train[col].fillna('Not Available',inplace=True)\n    test[col].fillna('Not Available',inplace=True)","e4b1206d":"train.head(3)","91ea6e24":"test.head(2)","90ba25d1":"#create separate columns for the various airlines in the train dataset \nairline = train['Airline'].str.split('|',expand = True) \nairline.columns = ['airline_1','airline_2','airline_3','airline_4','airline_5','airline_6','airline_7','airline_8',\n                   'airline_9','airline_10','airline_11']\nairline.drop(['airline_5','airline_6','airline_7','airline_8','airline_9','airline_10','airline_11'],\n             axis=1,inplace=True)\n\n#append to the train column .. \ntrain = pd.concat([train,airline],axis=1)\n\n#create separate columns for the various airlines in the test dataset \nairline = test['Airline'].str.split('|',expand = True) \nairline.columns = ['airline_1','airline_2','airline_3','airline_4','airline_5','airline_6','airline_7']\nairline.drop(['airline_5','airline_6','airline_7'],\n             axis=1,inplace=True)\n\n#append to the test column .. \ntest = pd.concat([test,airline],axis=1)\n\n#new feature = number of airlines booked\n#create the new feature -- > number of hotels booked during the trip\ntrain['num_airlines'] = num_sightseeing(dataset=train,col='Airline')\ntest['num_airlines'] =  num_sightseeing(dataset=test,col='Airline')\n\n\n#drop the redundant airline column\ntrain.drop('Airline',axis=1,inplace=True)\ntest.drop('Airline',axis=1,inplace=True)\n\n#replace the None in place_* with Not Available string\nairlines = ['airline_1','airline_2','airline_3','airline_4']\nfor col in airlines:\n    train[col].replace([None],np.nan,inplace=True)\n    test[col].replace([None],np.nan,inplace=True)\n    train[col].fillna('Not Available',inplace=True)\n    test[col].fillna('Not Available',inplace=True)\n","009bb125":"#drop the Travel Date column from both the train and test dataset \ntrain.drop('Travel Date',axis=1,inplace=True)\ntest.drop('Travel Date',axis=1,inplace=True)","71b1e154":"train.head()","0cebe3ff":"#create the new feature -- > number of sight seeing places\ntrain['num_sightseeing'] = num_sightseeing(train)\ntest['num_sightseeing'] =  num_sightseeing(test)","75071062":"train.head(2)","8a9deb6b":"#drop the original Sightseeing column from both the train and test dataset \ntrain.drop('Sightseeing Places Covered',axis=1,inplace=True)\ntest.drop('Sightseeing Places Covered',axis=1,inplace=True)","50456569":"train.info()","1a593fdc":"#check the new dataframe\ntrain.head(2)","92a0c0b3":"#lets drop the cancellation rules in the first iteration of the modeling\ntrain.drop('Cancellation Rules',axis=1,inplace=True)\ntest.drop('Cancellation Rules',axis=1,inplace=True)","fa81b11b":"#drop the package name\ntrain.drop('Package Name',axis=1,inplace=True)\ntest.drop('Package Name',axis=1,inplace=True)","33e10829":"#create a column with list of all the night stay at different hotels .. \nimport re\n\ntrain['num_nights'] = ''\nfor i in range(len(train)):\n    temp = sum(list(map(int,re.findall(r'\\d+',train['Itinerary'][i]))))\n    train['num_nights'][i] = temp","f749c4d9":"test['num_nights'] = ''\nfor j in range(len(test)):\n    temp_test = sum(list(map(int,re.findall(r'\\d+',test['Itinerary'][j]))))\n    test['num_nights'][j] = temp_test","cc2cbf63":"#drop the itinerary column from the train and test set\ntrain.drop('Itinerary',axis=1,inplace=True)\ntest.drop('Itinerary',axis=1,inplace=True)","53ae70a5":"train.head(2)","cca4938e":"#create the new feature -- > number of hotels booked during the trip\ntrain['num_hotels'] = num_sightseeing(dataset=train,col='Hotel Details')\ntest['num_hotels'] =  num_sightseeing(dataset=test,col='Hotel Details')","f7cdfb9c":"train.head(1)","99025898":"train['avg_rating'] = ''\nfor i in range(len(train)):\n    temp = np.mean(list(map(int,re.findall(r'\\d+',train['Hotel Details'][i]))))\n    train['avg_rating'][i] = temp\n    \ntest['avg_rating'] = ''\nfor i in range(len(test)):\n    temp = np.mean(list(map(int,re.findall(r'\\d+',test['Hotel Details'][i]))))\n    test['avg_rating'][i] = temp","bc4ff30a":"train['avg_rating'].median()","ce1dede0":"train.head(2)","5ea1ffc4":"test.head(2)","1a30044c":"#fill the NaN values in avg_rating to 0 \ntrain['avg_rating'].fillna(0,inplace=True)\ntest['avg_rating'].fillna(0,inplace=True)","a64aa857":"#drop the Hotel Details\ntrain.drop('Hotel Details',axis=1,inplace=True)\ntest.drop('Hotel Details',axis=1,inplace=True)","2c1b44e7":"train.head(2)","c143fcda":"encode_features=['place_1','place_2','place_3','place_4','airline_1','airline_2','airline_3','airline_4']\nfrom sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nfor col in encode_features:\n    encoder.fit(list(train[col].values) + list(test[col].values))\n    train[col] = encoder.transform(list(train[col].values))\n    test[col] = encoder.transform(list(test[col].values))","53c5cfb2":"train.head()","611f405c":"test.head()","50b68ace":"train.info()","c99e3dce":"#conver the num_nights to numerical\ntrain['num_nights'] = train['num_nights'].astype(int)\ntrain['num_nights'] = train['num_nights'].astype(int)","3e930bcf":"train.info()","fc44e84a":"#check the correlation with the numerical features \ntrain.corr()['Per Person Price'].sort_values(ascending=False)","67bb77ba":"#construct the heatmap\nsns.heatmap(train.corr(),cmap='viridis')\nplt.show()","14fc2a7a":"#split the dataset into train and test set\nseed = 21\nX = train.drop('Per Person Price',axis=1)\ny = train['Per Person Price']\n\nX_train,X_test,y_train,y_test =  train_test_split(X,y,test_size=0.1,random_state=seed)\nX_train.shape, X_test.shape","93a72aca":"from sklearn.model_selection import GridSearchCV\nrf_reg = RandomForestRegressor(random_state=seed)\nparams = {'n_estimators':[100,300,500],'max_depth':[14,21,25]}\ngrid = GridSearchCV(estimator=rf_reg,param_grid=params,cv=10,scoring='neg_mean_squared_log_error')\ngrid_fit = grid.fit(X_train,y_train)","559b1af8":"grid_fit.best_estimator_","11675cca":"grid_fit.best_score_","2c963e36":"rf_reg = grid_fit.best_estimator_\nrf_reg.fit(X_train,y_train)\nrf_reg_train_pred = rf_reg.predict(X_test)\nmsle = mean_squared_log_error(y_test,rf_reg_train_pred)\nprint('RMSLE: %.3f'%(np.sqrt(msle)))","7a489525":"#fit the model on the entire training dataset before the final predictions\nrf_reg.fit(X,y)\nfinal_pred = rf_reg.predict(test)","079aa737":"#create a submission df based on the submission format .. \nsubmission = pd.DataFrame(data=final_pred,columns=['Per Person Price'])","7ffe72cd":"#create the submission file -- >  yields 0.19474 (top30% on the Public Leaderboard)\nsubmission.to_csv('rf_submission.csv')","d2fbbbe6":"plt.hist(submission['Per Person Price'],bins=30,color='green',alpha=0.3)\nplt.title('Predicted Price')\nplt.show()","49d24b1f":"#scale the data before feeding to the dense neural network \nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","54ad64ee":"#Deep Neural Network for Per Person Price Prediction\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.callbacks import EarlyStopping","5c4dc15d":"#define the early stopping callback\ncallback = EarlyStopping(monitor='val_loss',patience=50,restore_best_weights=True)\n\n#define the model\nmodel = Sequential()\n#add the layers \nmodel.add(Dense(500,input_dim=X_train.shape[1],activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(300,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(150,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(75,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(25,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1))\n#compile the model\nmodel.compile(optimizer='adam',loss='mean_squared_logarithmic_error',metrics=['mse'])\n#print summary\nmodel.summary()\n#fit the model\nhistory = model.fit(X_train,y_train,epochs=500,callbacks=[callback],verbose=0,batch_size=32,validation_data=(X_test,y_test))","ad71d291":"loss = pd.DataFrame(history.history)\nloss.head(3)","28523499":"#prediction on the tet data .. \ntest =  scaler.transform(test)\npredictions = model.predict(test)","03689761":"nn_pred = pd.DataFrame(predictions,columns=['Per Person Price'])\nnn_pred.to_csv('nn_submission.csv')","bec5abda":"plt.hist(nn_pred['Per Person Price'],bins=30,color='green',alpha=0.3)\nplt.title('Neural Network Predicted Price')\nplt.show()","f98f4d20":"plt.plot(loss[['loss','val_loss']])\nplt.show()","0feac1de":"_This is expected as the number of meals per day will reduce with more flight stops. Only those meals are counted which are offered in the hotel stay or offered during the sight seeing. This also summarises the fact there is high multicollinearity in the dataset due to these two features._","ac276773":"**_There are features which have a lot of occurrences which mentions 'Not Available'.  Secondly, there are no duplicate rows in the dataset. Third there are as many number of unique id's as is the number of observations_**","dec613cd":"_There are specific travels which do not require an air ticket as in this case. Volvo is commonly referred as the bus type used for the travel which is generally air conditioned, comfortable and considered premium over the rest._","82598935":"## _Load the data and Basic Sanity Checks_","d4d01da0":"<font color = blue> **_The mean priceis highest for Premium and lowest for Budget. However, it is important to note that there is a mix of international and domestic travel package in the dataset. This could be one of the feature to be added to the dataset and could be an important factor to decide the final per price person.The more expensive travel packages are starting from New Delhi_** <\/font>","b07bf740":"## _Feature Extraction_","7c5b25f4":"_Goa is the most favored destination and hence we can see that Goa hotels are where the max stay is booked_","c260a87f":"<font color = blue>_The minimum number of meals is 2 and max is 5 with 3 as the median value. Flight stops on the other hand is 0 as min and 2 as max with median of 1_<\/font>","def71e8a":"#### _Airline Feature_","252c173b":"**_The target variable is not Gaussian. Before building the prediction model, the target variable can be normalized so that the loss function can be optimized_**","188c0dda":"#### _Sight Seeing Places_","5294cbc6":"**_There is no feature which states the end of the travel. The duration of the vacation can be derived from the Itinerary which mentions the number of nights_**","77c8065e":"\n_The Destination and Place Covered feature have identical information_","f228cb1f":"## _Deep Neural Network_","138ca73e":"## _Transformation, Dimensionality Reduction and Modeling_","e4499456":"**_The cancellation rules are as per the travel company policy. The dataset belongs to a single travel company. Cancellation policy do affect the price per person as the travel company would like to offer the flexi policy for a premium. This is also true in case of booking the flight tickets and the travel agent would book a flexi fare tour with the flights depending on the cancellation policy opted by their customers_**","79f94ee4":"### _Explore the categorical features_","482600ed":"**_There is negative correlation between the price per person and the number of flight stops. On the other hand there is positive correlation between the price per person and the number of meals selected as part of the package. This is expected as the non direct flights are usually cheaper than the direct ones_**","acc31803":"<font color = blue> **_All the hotel details here show the ratings of the hotel as well. Novotel Goa and Resort is occurring twice due the variation in its overall rating. This could be explained by the fact the booking in this hotel could have been done at two separte cluster of times and the average rating would have changed between these two time clusters._**<\/font>","04b647d8":"#### _Itinerary_","100472b9":"**_This one has 10N booked and is a trip to the south east Asian countries. The airlines are all international fliers. The package type is also Deluxe which might also have a bearing on the price.The sight seeing places is not available. Another important consideration is the travel date which is in the month of May. The start city is New Delhi. Most of the cities in India have school summer vacation starting from the month of May all the way till the end of June. In case of the southern states in India the vacation starts in April till end of May. Some of the colder states however have winter vacation instead of summer vacation usually in Dec and Jan._** ","1e005254":"<font color=blue> _The first 3 columns contains the maximum information of the key places a person would visit. The number of rows where the number of places is 10 is only 6. May be retaining upto the 4th place column would be more justified_<\/font>","8ebc9454":"_There are more travellers having 3 meals per day as part of the package_","08017414":"_The per person price median is 17765 and mean is 20059. The max value is 171062 rupees and the minimum is 791 rupees. The data at first glance appears to be right skewed_","b32d4858":"<font color = blue> **_Goa, Shimla, Manali, Munnar are the favorite destinations. The less frequent destunations are the international destinations which can be very expensive depending on the number of places included_**<\/font>","cb915441":"## _Load the Libraries_","4b10ec3a":"<b> _There are 21000 entries in the train dataset with 13 features and 1 target variable which is the price of the travel package. Flight stops, Meals are integers, price is in float whereas all teh rest of the features are of object\/string type including the Travel Date. There are no null\/NaN values in the dataset. However, there are feature rows where it mentions 'Not Available'. These are as good as NaNs_ <\/b>","517fa88b":"_Package Name information is well reflected in the destination feature. Hence this could be a redundant or very similar feature. For simplicity lets drop this column as well_","4ac5a285":"_There are more direct flight detsinations that the travellers have picked_","fa3b9e75":"<font color = blue> **_There are 966 unique Itinerary. The destinations are repeating in various and various combination is adding to the uniqueness.By the way 3 Nights in Goa seems to be the favorite_** <\/font>","cde0a21f":"<font color=blue> **_All the travel starts from New Delhi and Mumbai_**<\/font>","12067f81":"<b> _Now we have two very important features from which features can be extracted. From the itinerary, the number of nights will be an important feature that can be derived. From the hotel details, the number of hotels and average rating of the hotels would also be an important feature. Good rating of hotels yields higher booking numbers and amount_ <\/b>","a8e76bdb":"#### _Hotel Details_\n- Number of Hotels Booked\n- Average Rating of the Hotels selected\n","fabb996d":"**_The start city is New Delhi and the destionation is Wayanad in way south of India. The Airline information is not available. Perhaps the airline booking option was not selected by the customer. The package name is young and free. While it cannot be ruled out the possibility of driving\/train to this location, the fair assumption is that the flight booking would be done at a later date by the person_**","63fd11ce":"### _Feature extraction_\n#### _Destination feature_\n***\n_The places in the Destination feature can be converted to separate columns and then lable encoded_","fa60cafc":"_December is the least as it becomes very expensive during this month in Goa due to new year celebration. Off seasons like May, July and Sep are the top 3 most visited_","78540051":"# <font color = blue> _Workation Price Prediction_<\/font>\n****\n**_Overview_**\n***\nThe new covid-era has provided a new way of living the work-life balance. We have seen a lot of different websites providing packages to work from different locations. From Kashmir to Kanyakumari, from Gujarat to Assam we have collected packages in and around India. It becomes really difficult to find the best place with all the amenities such as high-speed internet, a comfortable stay as well as within the budget. To solve the real-world problem of finding the best deals for a calm and enjoying workation trip. Workation is the best way to work at a remote location with a recreational and rejuvenating vacation for the team.\n\nIn this competition, one has to use the knowledge of machine learning, deep learning, and model building to predict the price per person for your next workstation trip. The data has more than 18000+ rows of different packages with the details like start location, hotel type, cost per person, destination, Itinerary, and many more.","3fd96d50":"## _Exploratory Data Analysis_\n\n### _Explore the numerical features_"}}