{"cell_type":{"418cbcb6":"code","38e9ead9":"code","d671c033":"code","0dc93af1":"code","4cffa4fe":"code","9caf0466":"code","70081ced":"code","0c65ece9":"code","be4214fc":"code","4027fad3":"code","dca5f962":"code","14f6530f":"code","b5be54b7":"code","82b21b17":"code","52df7d24":"code","0c44f73f":"code","53856368":"code","25bd6d90":"code","e50ac238":"code","3b88a58f":"code","a1d88923":"code","204ac70a":"code","8ae8abc4":"code","dbb4a6d5":"code","30136a00":"code","72aa6f13":"code","3e93dc2f":"code","e9ddcce9":"code","db58f141":"code","a0502fe2":"code","bb4f0770":"code","777994c2":"code","b1970674":"code","1d2cc2a3":"code","84a25d90":"code","0a27e4b5":"code","e0dfe53a":"code","8456a46c":"code","9d963c77":"code","ffd45f6b":"markdown","1b8bb094":"markdown","6f0c92de":"markdown","0cfa3dea":"markdown","a31b29fb":"markdown","5c78bedf":"markdown"},"source":{"418cbcb6":"# !pip install torchio\n# import torchio as tio","38e9ead9":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport torch.nn.functional as F\nfrom torchvision import transforms, utils\n\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom skimage import exposure\n\nfrom albumentations import Resize, Normalize, Compose\nfrom albumentations.pytorch import ToTensorV2\nimport albumentations as album\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.style.use(\"dark_background\")\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","d671c033":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using {device} device\")","0dc93af1":"# pip install --upgrade batchgenerators","4cffa4fe":"# train_data_retriever = Dataset(df_train[\"BraTS21ID\"].values, df_train[\"MGMT_value\"].values)\n\n# train_loader = torch_data.DataLoader(train_data_retriever, batch_size=4, shuffle=True, num_workers=1,)\n# batch = next(iter(train_loader))","9caf0466":"# def plot_batch(batch):\n#     batch_size = batch['X'].shape[0]\n#     plt.figure(figsize=(16, 10))\n#     for i in range(batch_size):\n#         plt.subplot(1, batch_size, i+1)\n#         plt.imshow(batch['X'][i, 0, 0, :, :], cmap=\"gray\") # only grayscale image here\n#     plt.show()\n\n# plot_batch(batch)","70081ced":"# array = batch['X'][0, 0, :, :, :].numpy().astype(np.float32)","0c65ece9":"# from batchgenerators.transforms.color_transforms import ContrastAugmentationTransform\n# from batchgenerators.transforms.spatial_transforms import MirrorTransform\n# from batchgenerators.transforms.abstract_transforms import Compose\n# from batchgenerators.dataloading.multi_threaded_augmenter import MultiThreadedAugmenter\n\n# my_transforms = []\n# brightness_transform = ContrastAugmentationTransform((0.3, 3.), preserve_range=True)\n# my_transforms.append(brightness_transform)\n# mirror_transform = MirrorTransform(axes=(0, 1))\n# my_transforms.append(mirror_transform)\n\n# all_transforms = Compose(my_transforms)\n\n# multithreaded_generator = MultiThreadedAugmenter(array, all_transforms, 4, 1, seeds=None)\n# plot_batch(next(iter(multithreaded_generator)))\n# multithreaded_generator._finish()\n","be4214fc":"if os.path.exists(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n    data_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"..\/input\/efficientnetpyttorch3d\/EfficientNet-PyTorch-3D\"\nelse:\n    data_directory = '\/media\/roland\/data\/kaggle\/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"EfficientNet-PyTorch-3D\"\n    \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nSIZE = 128\nNUM_IMAGES = 64\n\nsys.path.append(pytorch3dpath)\nfrom efficientnet_pytorch_3d import EfficientNet3D","4027fad3":"def load_dicom_image(path, img_size=SIZE):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    \n    if np.min(data)==np.max(data):\n        data = np.zeros((img_size,img_size))\n        return data\n    \n#     data = exposure.equalize_adapthist(data, clip_limit=0.08)\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = cv2.resize(data, (img_size, img_size))\n    \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n\n    return data.astype(np.uint8)","dca5f962":"def load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"))\n    \n    middle = len(files) \/\/ 2\n    num_imgs2 = num_imgs \/\/ 2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]]).T \n    \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n            \n    return img3d","14f6530f":"images = []\nfor i in mri_types:\n    images.append(load_dicom_images_3d(scan_id=\"00000\", mri_type=i))\nfour_channel_pack = np.stack(images)\nfour_channel_pack = np.transpose(four_channel_pack, (0, 3, 1, 2))\n\nprint(four_channel_pack.shape)\nplt.imshow(four_channel_pack[0, 10, :, :])","b5be54b7":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(42)","82b21b17":"train_df = pd.read_csv(f\"{data_directory}\/train_labels.csv\")\ndisplay(train_df)\n\ndf_train, df_valid = sk_model_selection.train_test_split(\n    train_df, \n    test_size=0.3, \n    random_state=42, \n    stratify=train_df[\"MGMT_value\"],\n)","52df7d24":"def get_training_augmentation():\n    train_transform = [\n        album.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ]\n    return album.Compose(train_transform,)","0c44f73f":"# _transforms = {\n#     tio.RandomFlip(axes=['LR', 'AP', 'IS'], p=0.8),\n#     tio.RandomElasticDeformation(p=0.2),\n# #     tio.RandomAffine(scales=(0.9, 1.2), degrees=10, isotropic=True, image_interpolation=\"nearest\", p=1),\n# #     tio.RandomNoise(p=0.2),\n# #     tio.RandomMotion(p=0.3),\n# #     tio.RandomGhosting(p=0.4),\n# #     tio.RandomSpike(p=0.2),\n#     tio.ZNormalization(masking_method=tio.ZNormalization.mean, p=1),\n#     tio.RescaleIntensity(out_min_max=(0, 1), p=1),\n    \n# #     tio.OneOf([\n# # #         tio.RandomMotion(p=0.2),\n# #         tio.RandomBiasField(p=0.3),\n# # #         tio.RandomNoise(p=0.5),\n# #     ]),\n    \n# #     tio.OneOf([\n# #         tio.ZNormalization(masking_method=tio.ZNormalization.mean, p=0.5),\n# #         tio.RescaleIntensity(out_min_max=(0, 1), p=0.5),  \n# #     ])\n# }\n\n# outer_transforms = _transforms\n# transform = tio.Compose(outer_transforms)","53856368":"class Dataset(torch_data.Dataset):\n    def __init__(self, paths, labels=None, mri_type=None, label_smoothing=0.01, augmentation=None, transformation=None, split=\"train\"):\n        self.paths = paths\n        self.labels = labels\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.augmentation = augmentation\n        self.transformation = transformation\n        self.split = split\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        label = self.labels[index]\n        \n#         inner_transform = transforms.Compose([\n#             transforms.ToTensor(), \n# #             transforms.Normalize((0.5,) * NUM_IMAGES, (0.5,) * NUM_IMAGES)\n#         ])\n    \n\n        images = []\n        for i in mri_types:\n            image_3d = load_dicom_images_3d(scan_id=str(scan_id).zfill(5), mri_type=i)\n            \n#             normalization\n            if self.augmentation:\n                for i in range(image_3d.shape[-1]):\n                    temp_img = image_3d[:, :, i].astype(np.uint8)\n                    temp_img = cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB)\n#                     temp_img = cv2.fastNlMeansDenoisingColored(temp_img, None, 3, 3, 7, 21)\n                    temp_img = self.augmentation(image=temp_img)['image'][:, :, 0]\n                    image_3d[:, :, i] = temp_img\n            images.append(image_3d)\n        four_channel_pack = np.stack(images)\n        \n        # transformation\n        if self.transformation:\n            four_channel_pack = self.transformation(four_channel_pack)\n        \n        four_channel_pack = np.transpose(four_channel_pack, (0, 3, 1, 2))\n        y = self.labels[index]\n#         y = torch.tensor(self.labels[index], dtype=torch.float)\n        \n        return {\"X\": torch.tensor(four_channel_pack).float(), \"y\": y}","25bd6d90":"train_data_retriever = Dataset(\n    paths=df_train[\"BraTS21ID\"].values, \n    labels=df_train[\"MGMT_value\"].values,\n    augmentation=get_training_augmentation(),\n#     transformation=transform,\n)\n\ntrain_loader = torch_data.DataLoader(train_data_retriever, batch_size=4, shuffle=False, num_workers=8,)\na = train_data_retriever[5][\"X\"]","e50ac238":"plt.imshow(a[0, 12, :, :])\nprint(a[0, 14, :, :].max(), a[0, 14, :, :].min())","3b88a58f":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=4)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=2, bias=True)\n\n#         self.net._fc = nn.Sequential(nn.Linear(n_features, 256),\n#                                         nn.SELU(),\n#                                         nn.Dropout(p=0.5),\n#                                         nn.Linear(256, 64),\n#                                         nn.SELU(),\n#                                         nn.Dropout(p=0.5),\n#                                         nn.Linear(64, 2),\n#                                         nn.LogSigmoid()\n#                                 )\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","a1d88923":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n\n        self.best_valid_score = np.inf\n        self.n_patience = 0\n        self.lastmodel = None\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_acc, train_loss, train_time = self.train_epoch(train_loader)\n            valid_acc, valid_loss, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                \"[Epoch Train: {}] accuracy: {:.4f}, loss: {:.4f}, time: {:.2f} s            \",\n                n_epoch, train_acc, train_loss, train_time\n            )\n            \n            self.info_message(\n                \"[Epoch Valid: {}] accuracy: {:.4f}, loss: {:.4f}, time: {:.2f} s\",\n                n_epoch, valid_acc, valid_loss, valid_time\n            )\n\n            # if True:\n            # if self.best_valid_score < valid_auc: \n            if self.best_valid_score > valid_loss: \n                self.save_model(n_epoch, save_path, valid_loss)\n                self.info_message(\n                     \"loss has decresed from {:.4f} to {:.4f}. Saved model to '{}'\", \n                    self.best_valid_score, valid_loss, self.lastmodel\n                )\n                self.best_valid_score = valid_loss\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(\"\\nValid auc didn't improve last {} epochs.\", patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        sum_loss = 0\n        train_acc = 0.0\n\n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            \n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            print(torch.nn.functional.softmax(outputs, dim=1)[0] * 100)\n#             print(outputs.argmax())\n        \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n            sum_loss += loss.detach().item()\n            self.optimizer.step()\n            \n            _, pred = torch.max(outputs, dim=1)\n#             print(pred, targets)\n            train_acc += sum((pred == targets).cpu().numpy())\n            \n            message = 'Train Step {}\/{}, train_loss: {:.4f}'\n            self.info_message(message, step, len(train_loader), sum_loss\/step, end=\"\\r\")\n#         print(train_acc \/ len(train_loader.dataset))\n        return train_acc \/ len(train_loader.dataset), sum_loss \/ len(train_loader), int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        sum_loss = 0\n        y_all = []\n        outputs_all = []\n        \n        valid_acc = 0.0\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X)\n                print(torch.nn.functional.softmax(outputs, dim=1)[0] * 100)\n#                 print(outputs.argmax())\n                \n                loss = self.criterion(outputs, targets)\n                sum_loss += loss.detach().item()\n                y_all.extend(batch[\"y\"].tolist())\n                outputs_all.extend(outputs.tolist())\n                \n                _, pred = torch.max(outputs, dim=1)\n#                 print(pred, targets)\n                valid_acc += sum((pred == targets).cpu().numpy())\n\n            message = 'Valid Step {}\/{}, valid_loss: {:.4f}'\n            self.info_message(message, step, len(valid_loader), sum_loss\/step, end=\"\\r\")\n\n        return valid_acc \/ len(valid_loader.dataset), sum_loss\/len(valid_loader), int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, loss):\n        self.lastmodel = f\"{save_path}-e{n_epoch}-loss{loss:.3f}.pth\"\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            self.lastmodel,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","204ac70a":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# torch.cuda.empty_cache()\n\n# def train_mri_type(df_train, df_valid):\n    \n#     train_data_retriever = Dataset(\n#         paths=df_train[\"BraTS21ID\"].values, \n#         labels=df_train[\"MGMT_value\"].values,\n#         augmentation=get_training_augmentation(),\n# #         transformation=transform,\n#     )\n#     valid_data_retriever = Dataset(\n#         paths=df_valid[\"BraTS21ID\"].values, \n#         labels=df_valid[\"MGMT_value\"].values,\n#         augmentation=get_training_augmentation(),\n# #         transformation=transform,\n#     )\n\n#     train_loader = torch_data.DataLoader(train_data_retriever, batch_size=8, shuffle=True, num_workers=12,)\n#     valid_loader = torch_data.DataLoader(valid_data_retriever, batch_size=8, shuffle=True, num_workers=8,)\n\n#     model = Model()\n#     model.to(device)\n\n#     # UPTRAIN\n#     checkpoint_file = \"..\/input\/3dbrainmrimodels\/classification_model-e5-loss0.683.pth\"\n#     if torch.cuda.is_available():\n#         checkpoint = torch.load(checkpoint_file)\n#     else:\n#         checkpoint = torch.load(checkpoint_file, map_location=torch.device('cpu'))    \n#     model.load_state_dict(checkpoint[\"model_state_dict\"])\n\n\n#     optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n# #     optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n# #     criterion = torch_functional.binary_cross_entropy_with_logits\n#     criterion = nn.CrossEntropyLoss()\n# #     criterion = nn.BCEWithLogitsLoss()\n\n#     trainer = Trainer(\n#         model, \n#         device, \n#         optimizer, \n#         criterion\n#     )\n\n#     history = trainer.fit(\n#         10, \n#         train_loader, \n#         valid_loader, \n#         \"classification_model\",\n#         10,\n#     )\n    \n#     return trainer.lastmodel\n\n# train_mri_type(df_train, df_valid)","8ae8abc4":"# Extra save the model\n\n# lastmodel = f\"classification_model-e10-loss0.5304.pth\"\n# torch.save(\n#     {\n#         \"model_state_dict\": model.state_dict(),\n#         \"n_epoch\": 10,\n#     },\n#     lastmodel,\n# )","dbb4a6d5":"df_train = df_train.set_index(\"BraTS21ID\")\ndf_train[\"MGMT_pred\"] = 0","30136a00":"df_valid = df_valid.set_index(\"BraTS21ID\")\ndf_valid[\"MGMT_pred\"] = 0","72aa6f13":"# modelfile = \".\/classification_model-e5-loss0.683.pth\"\nmodelfile = \".\/classification_model-e10-loss0.5304.pth\"\nmodel = Model()\nmodel.to(device)\n\nif torch.cuda.is_available():\n    checkpoint = torch.load(modelfile)\nelse:\n    checkpoint = torch.load(modelfile, map_location=torch.device('cpu'))    \nmodel.load_state_dict(checkpoint[\"model_state_dict\"])","3e93dc2f":"class TestDataset(torch_data.Dataset):\n    def __init__(self, paths, labels=None, mri_type=None, label_smoothing=0.01, augmentation=None, split=\"train\"):\n        self.paths = paths\n        self.labels = labels\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.augmentation = augmentation\n        self.split = split\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        label = self.labels[index]\n        \n        transform = transforms.Compose([\n            transforms.ToTensor(), \n            transforms.Normalize((0.5,) * NUM_IMAGES, (0.5,) * NUM_IMAGES)\n        ])\n        \n        images = []\n        for i in mri_types:\n            image_3d = load_dicom_images_3d(scan_id=str(scan_id).zfill(5), mri_type=i)\n            image_3d = transform(image_3d)\n            images.append(image_3d)\n            \n        four_channel_pack = np.stack(images)        \n        \n        y = self.labels[index]\n        return torch.tensor(four_channel_pack).float(), y","e9ddcce9":"test_data_retriever = TestDataset(\n    df_train.index.values, \n    df_train[\"MGMT_value\"].values,\n    augmentation=get_training_augmentation(),\n    split=\"test\",\n)\n\ntest_data_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=16,\n    shuffle=False,\n    num_workers=8,\n)","db58f141":"a, b = test_data_retriever[0]\nplt.imshow(a[0, 10, :, :])","a0502fe2":"# fig, axis = plt.subplots(4, 4, figsize=(8, 10))\n# with torch.no_grad():\n#     model.eval()\n#     for i, ax in enumerate(axis.flat):\n#         image, label = test_fetures[i].to(device), test_labels[i].to(device)\n#         ax.imshow(image[0, 20, :, :].cpu())\n        \n# #         image_tensor = image.unsqueeze_(0)\n#         output_ = model(image).squeeze(1)\n#         _, pred = torch.max(output_, dim=1)\n#         print(pred, label)\n        \n\n#         print(\n#             torch.nn.functional.softmax(model(image), dim=1)[0] * 100,\n#         )\n#         _, index = torch.max(output_, 1)\n        \n#         percentage = torch.nn.functional.softmax(output_, dim=1)[0] * 100\n#         result = output_.argmax()\n        \n#         print(index, percentage[0], percentage[1])\n#         print(sum([percentage[0], percentage[1]]), \"\\n\")\n#         ax.set(title = f\"actual:{label}\\nprediction:{result}\")","bb4f0770":"data_retriever = Dataset(\n    df_valid.index.values, \n    df_valid[\"MGMT_value\"].values,\n    split=\"test\",\n)\n\ndata_loader = torch_data.DataLoader(\n    data_retriever,\n    batch_size=1,\n    shuffle=False,\n    num_workers=8,\n)\n\ny_preds = []\ny = []\noutputs = []\n\nfor e, batch in enumerate(data_loader):\n    print(f\"{e}\/{len(data_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        model.eval()\n        image, label = batch[\"X\"].to(device), batch[\"y\"]\n        \n#         plt.imshow(image.cpu()[0, 0, 30, :, :])\n#         plt.show()\n        \n        output_ = model(image).squeeze(1)\n        _, pred = torch.max(output_, dim=1)\n\n        _, index = torch.max(output_, 1)\n        percentage = torch.nn.functional.softmax(output_, dim=1)[0]\n        print(percentage * 100)\n#         tmp_pred = torch.nn.functional.softmax(model(image), dim=1)[0] * 100\n    \n    \n        label = label.detach().cpu().numpy()[0]\n        prediction = float(percentage[1].detach().cpu().numpy())\n        y.append(label)\n        y_preds.append(prediction)\n        outputs.append(index)","777994c2":"# score\ny = np.array(y)\ny_preds = np.array(y_preds)\n\nfpr, tpr, thresholds = metrics.roc_curve(y, y_preds, pos_label=1)\nroc_auc = metrics.auc(fpr, tpr)\nacc = (sum([x == y for x, y in zip(outputs, y)]) \/ len(y)).detach()[0]\n\nprint(f\"AUC score is: {roc_auc}\")\nprint(f\"Accuracy score is: {acc}\")","b1970674":"lr_fpr, lr_tpr, _ = metrics.roc_curve(y, y_preds)\nplt.plot(lr_fpr, lr_tpr, marker='.', label='abc')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","1d2cc2a3":"class SUBMISSIONDataset(torch_data.Dataset):\n    def __init__(self, \n                 augmentation=None, \n                 preprocessing=None,\n                ):\n        self.indexes = sorted(os.listdir(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\"))\n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n          \n    def __len__(self):\n        return len(self.indexes)\n    \n    def __getitem__(self, index):\n        scan_id = self.indexes[index]\n        four_channel_pack = None\n    \n        transform = transforms.Compose([\n            transforms.ToTensor(), \n            transforms.Normalize((0.5,) * NUM_IMAGES, (0.5,) * NUM_IMAGES)\n        ])\n        images = []\n        \n        try:\n            for i in mri_types:\n                try:\n                    image_3d = load_dicom_images_3d(scan_id=str(scan_id).zfill(5), split=\"test\", mri_type=i)\n                    image_3d = transform(image_3d)\n                    images.append(image_3d)\n                except:\n                    pass\n                four_channel_pack = np.stack(images)\n        except:\n            pass\n\n        return {\"X\": torch.tensor(four_channel_pack).float(), \"id\": scan_id}","84a25d90":"submission = pd.read_csv(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv\")\n\ntest_dataset = SUBMISSIONDataset(\n#     augmentation=get_validation_augmentation(),\n)\n\ndata_loader = torch_data.DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=8,\n)","0a27e4b5":"ids = []\npreds = []\n\nfor e, batch in enumerate(data_loader):\n    print(f\"{e}\/{len(data_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n#         model.eval()\n        image, id = batch[\"X\"].to(device), str(batch[\"id\"][0])\n        \n        try:\n            output_ = model(image).squeeze(1)\n            percentage = torch.nn.functional.softmax(output_, dim=1)[0]\n\n            prediction = float(percentage[1].detach().cpu().numpy())\n        except:\n            prediction = 0.5\n            \n        preds.append(prediction)\n        ids.append(id)","e0dfe53a":"df = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": preds})\n# df['MGMT_value'] = preds\ndf[['BraTS21ID', 'MGMT_value']].to_csv(\"submission.csv\", index=False)","8456a46c":"df","9d963c77":"sns.displot(df[\"MGMT_value\"])","ffd45f6b":"### AUC Score","1b8bb094":"### 3D Augmenatation and Transformation","6f0c92de":"### Dataset and Dataloader","0cfa3dea":"### Test Transformations and Normalization","a31b29fb":"### Testing the model","5c78bedf":"### Model and Training"}}