{"cell_type":{"bb0beedb":"code","890fcb6a":"code","8f13e50e":"code","0ca1470c":"code","f392b80d":"code","e71110eb":"code","d54c5fb6":"code","818777ae":"code","cca72616":"code","b620e880":"code","2b83f31d":"code","68f772d2":"code","e448a5f2":"code","dc129e85":"code","2218549c":"code","cb5255c1":"code","34b5506f":"code","dcce6c78":"code","40e3368e":"code","050a7180":"code","88f7cadf":"code","e36e5fa7":"code","7aa8a1b1":"code","25de22c7":"code","349747eb":"code","6ec15852":"code","054c0c30":"code","03bd3536":"code","6f067352":"code","e38344e2":"code","8c0dcfae":"code","f5ca89d3":"code","aabe2fff":"markdown"},"source":{"bb0beedb":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom os import listdir\nimport imutils\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, load_model\nfrom sklearn.model_selection import train_test_split","890fcb6a":"#method for cropping image i.e. for getting brain area\ndef crop_brain_contour(image, plot=False):\n    \n    \n    # Convert the image to grayscale, and blur it slightly\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n    # Threshold the image, then perform a series of erosions +\n    # dilations to remove any small regions of noise\n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    # Find contours in thresholded image, then grab the largest one\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    c = max(cnts, key=cv2.contourArea)\n    \n\n    # Find the extreme points\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n    \n    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n\n    if plot:\n        plt.figure()\n\n        plt.subplot(1, 2, 1)\n        plt.imshow(image)\n        \n        plt.tick_params(axis='both', which='both', \n                        top=False, bottom=False, left=False, right=False,\n                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n        \n        plt.title('Original Image')\n            \n        plt.subplot(1, 2, 2)\n        plt.imshow(new_image)\n\n        plt.tick_params(axis='both', which='both', \n                        top=False, bottom=False, left=False, right=False,\n                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n\n        plt.title('Preprocessed Image')\n        \n        plt.show()\n    \n    return new_image","8f13e50e":"# function for loading images and labels into X and y..in X, it will store images.. \n#and in y it will store actual image label (0 or 1) for each image..if 0 no tumor,1 then tumorous image\ndef load_data(dir_list, image_size):\n    \n    # load all images in a directory\n    X = []\n    y = []\n    \n    image_width, image_height = image_size\n    \n    for directory in dir_list:\n        for filename in listdir(directory):\n            # load the image\n            image = cv2.imread(directory + '\/' + filename)\n            \n            # crop the brain and ignore the unnecessary rest part of the image\n            image = crop_brain_contour(image, plot=False)\n            # resize image\n            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n            # normalize values\n            image = image \/ 255.\n            # convert image to numpy array and append it to X\n            X.append(image)\n            # append a value of 1 to the target array if the image\n            # is in the folder named 'yes', otherwise append 0.\n            if directory[-3:] == 'yes':\n                y.append([1])\n            else:\n                y.append([0])\n                \n    X = np.array(X)\n    y = np.array(y)\n    \n    # Shuffle the data\n    X, y = shuffle(X, y)\n    \n    print(f'Number of examples is: {len(X)}')\n    print(f'X shape is: {X.shape}')\n    print(f'y shape is: {y.shape}')\n    \n    return X, y\n","0ca1470c":"#code for mounting drive into the google colab..so that we can use any folder, file inside our drive\nfrom google.colab import drive\ndrive.mount('\/content\/drive')","f392b80d":"#path for yes and no folder\nyes = \"\/content\/drive\/My Drive\/augmented_data\/yes\"\nno = \"\/content\/drive\/My Drive\/augmented_data\/no\"\n","e71110eb":"#image size specified\nIMG_WIDTH, IMG_HEIGHT = (256, 256)\n#calling load function for loading X,y data by passing both folder paths\nX, y = load_data([yes,no], (IMG_WIDTH, IMG_HEIGHT))\n#here we can see it is showing 2065,256,256,3...means 2065 images, and each image of size is (256,256,3)\n# y shape is 2065,1 means it stores labels for 2065 images respective to X data..","d54c5fb6":"def split_data(X, y, test_size=0.2):\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n    \n    return X_train, y_train, X_test, y_test","818777ae":"#data splitting\nX_train, y_train,X_test, y_test = split_data(X, y, test_size=0.3)","cca72616":"#loading vgg16 pretrained model\nfrom keras.applications.vgg16 import VGG16\nSIZE=256\nVGG_model=VGG16(input_shape=(SIZE,SIZE,3),include_top=False,weights='imagenet')","b620e880":"#we are not not using VGG16 model for training...so we made all layers as non trainable\nfor layer in VGG_model.layers:\n    layer.trainable=False","2b83f31d":"VGG_model.summary()","68f772d2":"#saving vgg model into file for further use\nVGG_model.save(\"\/content\/drive\/My Drive\/VGG_model.h5\")","e448a5f2":"#extract features for training data\nfeature_ex=VGG_model.predict(X_train)\n","dc129e85":"feature_ex.shape","2218549c":"features=feature_ex.reshape(feature_ex.shape[0],-1)\n","cb5255c1":"features.shape","34b5506f":"#extract features for testing data\ntest_feature_ex=VGG_model.predict(X_test)\ntest_features=test_feature_ex.reshape(test_feature_ex.shape[0],-1)","dcce6c78":"#Pass features to classifier model","40e3368e":"from sklearn import svm\n\n#Create a svm Classifier\nclf = svm.SVC(kernel='linear') # Linear Kernel\n\n#Train the model using thetraining features extracted by VGG16 i.e.features...and the labels i.e y_train\nclf.fit(features, y_train)\n\n#Predict the response for test features\ny_pred = clf.predict(test_features)","050a7180":"#testing accuracy\nfrom sklearn import metrics\nmetrics.accuracy_score(y_test,y_pred)","88f7cadf":"from sklearn.datasets import make_circles\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\n\n\n# accuracy: (tp + tn) \/ (p + n)\naccuracy_svm = accuracy_score(y_test, y_pred)\nprint('Accuracy: %f' % accuracy_svm)\n# precision tp \/ (tp + fp)\nprecision_svm = precision_score(y_test, y_pred)\nprint('Precision: %f' % precision_svm)\n# recall: tp \/ (tp + fn)\nrecall_svm = recall_score(y_test, y_pred)\nprint('Recall: %f' % recall_svm)\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1_svm = f1_score(y_test, y_pred)\nprint('F1 score: %f' % f1_svm)","e36e5fa7":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n    plt.savefig('\/content\/drive\/My Drive\/accuracy_plot.pdf',dpi=300,bbox_inches='tight')","7aa8a1b1":"labels = ['yes','no']\nconfusion_mtx = confusion_matrix(y_test, y_pred) \ncm = plot_confusion_matrix(confusion_mtx, classes = labels, normalize=False)","25de22c7":"print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))","349747eb":"import pickle\n# save the model to disk\nfilename = '\/content\/drive\/My Drive\/finalized_model.sav'\npickle.dump(clf, open(filename, 'wb'))","6ec15852":"#How to see output on new input image\n","054c0c30":"#read image and preprocess it\npath=\"\/content\/drive\/My Drive\/augmented_data\/no\/aug_48 no._0_370.jpg\"\nimg=cv2.imread(path)\nimg = crop_brain_contour(img, plot=False)\nimg = cv2.resize(img, dsize=(256,256), interpolation=cv2.INTER_CUBIC)\nimg = img \/ 255.\nfrom keras.preprocessing import image\ntest_image = image.img_to_array(img)\ntest_image = np.expand_dims(test_image, axis = 0)","03bd3536":"vggmodel = load_model(\"\/content\/drive\/My Drive\/VGG_model.h5\")","6f067352":"#get features for input image\ntest_f=vggmodel.predict(test_image)\n","e38344e2":"#reshape features\ntest_f=test_f.reshape(test_f.shape[0],-1)","8c0dcfae":"#load svm model which is generated already\nfilename = '\/content\/drive\/My Drive\/finalized_model.sav' \nsvm_model = pickle.load(open(filename, 'rb'))","f5ca89d3":"# why no detected, bcz we passed image from no folder...try givving image from yes folder also within the augmented data folder\nprediction_svm=svm_model.predict(test_f)\nif(prediction_svm[0]==0):\n   print(\"No tumor detected\")\nelse:\n   print(\"Tumor detected\")\n","aabe2fff":"# Testing accuracy is 98.70"}}