{"cell_type":{"8ebcf969":"code","06e09373":"code","c9617f2a":"code","45320f7b":"code","d5e0a247":"code","f36b2fa6":"code","d8b2b45b":"code","905228f1":"markdown","11370976":"markdown","32d75b79":"markdown","527830db":"markdown","1e88175e":"markdown","5c90b741":"markdown","c0deac91":"markdown","60be0e5c":"markdown"},"source":{"8ebcf969":"############## Necessary imports #################\nimport pandas as pd\n\n########################\n# Common \n########################\nimport sys\nimport random\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n########################\n##### Image processing\n########################\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\n#from skimage.transform import rescale, resize, downscale_local_mean\nimport numpy as np\nimport scipy\n\n########################\n# Plotting\n########################\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n########################\n# ML libs\n########################\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\nimport tensorflow\n\n########################\n# Global variables and settings\n########################\nimg_folder='..\/input\/bee_imgs\/bee_imgs\/'\nimg_width=100\nimg_height=100\nimg_channels=3\n\n# Set NumPy and TensorFlow random seed to make results reproducable\nnp.random.seed(42)\ntensorflow.set_random_seed(2)","06e09373":"bees=pd.read_csv('..\/input\/bee_data.csv', \n                index_col=False,  \n                parse_dates={'datetime':[1,2]},\n                dtype={'subspecies':'category', 'health':'category','caste':'category'})\n\ndef read_or_skip(file):\n    \"\"\"This function is to supress imageio exception if file doesn't exist\"\"\"\n    try:\n        img = skimage.io.imread(img_folder + file)\n        img = skimage.transform.resize(img, (img_width, img_height), mode='reflect')\n        return img[:,:,:img_channels]\n    except:\n        #print('Skipping %s. %s' %(file, sys.exc_info()[1]))\n        return None\n\nbees['img'] = bees['file'].apply(read_or_skip)\nbees.dropna(inplace=True)\n\n# Print sample data without img array\nbees.drop('img',axis=1).head()\n\nplt.style.use('seaborn')","c9617f2a":"# Plot count by subspecies\nbees.subspecies.value_counts().plot.bar(title=\"Subspecies count in dataset\")\nplt.ylabel(\"Count\")\nplt.show()\nbees.subspecies.value_counts()","45320f7b":"# The plan\n# 1. Split all bees to train and test subsets, unbalanced.\n# 2. Balance train and test subsets separately by subspecies categories\n# 3. Extract features and labels from balanced train and balanced test datasets. \n# The data is prepared to CNN now.\n\n# 1. Split bees considering train\/test ratio. Labels are kept in features \n# Ignore labels output from train_test_split, we'll need to balance train\/test data \n# before getting labels\ntrain_bees_unbalanced, test_bees_unbalanced, _train_labels_unbalanced, _test_labels_unbalanced = train_test_split(bees, bees.subspecies)\n# Delete not needed data to avoid memory error\ndel _train_labels_unbalanced\ndel _test_labels_unbalanced\n\n# 2. Balance train and test subsets separately by subspecies categories.\n\n# Set variables\n# Subspecies categories for rebalancing by them\nss_names = train_bees_unbalanced.subspecies.values.unique() \nss_num = ss_names.size\n# Total rows in rebalanced dataset. Can be lower or higher than original data rows.\nn_samples = bees.size \/ 2\nratio = 0.25\n\n# Train\/test rows nums\ntest_num = n_samples * ratio\ntrain_num = n_samples - test_num\n\n# Resample each subspecies category and add to resulting train dataframe\ntrain_bees_balanced = pd.DataFrame()\ntest_bees_balanced = pd.DataFrame()\nfor ss in ss_names:\n    # Resample category in train bees\n    bees_cur = train_bees_unbalanced[train_bees_unbalanced.subspecies == ss]\n    bees_cur_resampled = resample(bees_cur, n_samples=int(train_num\/ss_num))\n    train_bees_balanced = pd.concat([train_bees_balanced, bees_cur_resampled])\n    # Resample category in test bees\n    bees_cur = test_bees_unbalanced[test_bees_unbalanced.subspecies == ss]\n    bees_cur_resampled = resample(bees_cur, n_samples=int(test_num\/ss_num))\n    test_bees_balanced = pd.concat([test_bees_balanced, bees_cur_resampled])\n\n# Delete not needed data to avoid memory error\ndel train_bees_unbalanced\ndel test_bees_unbalanced\n\n# 3. Extract features and labels from balanced train, test\n\n# Get train features and labels from train rebalanced bees\ntrain_labels = pd.get_dummies(train_bees_balanced.subspecies)\ntrain_data=np.stack(train_bees_balanced.img)\n\n# Get test features and one hot encoded labels from balanced test\ntest_labels = pd.get_dummies(test_bees_balanced.subspecies)\ntest_data = np.stack(test_bees_balanced.img)\n    \n\n# Plot resampled data to check\nf, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,3))\ntrain_bees_balanced.subspecies.value_counts().plot.bar(title =\"Balanced train subspecies\", ax=ax[0])\nax[0].set_ylabel(\"Count\")\ntest_bees_balanced.subspecies.value_counts().plot.bar(title =\"Balanced test subspecies\", ax=ax[1])\nax[1].set_ylabel(\"Count\")\n\nplt.show()\n\n# Delete not needed data to avoid memory error\ndel train_bees_balanced\ndel test_bees_balanced\n\ngc.collect()","d5e0a247":"# Data augmentation - rotate, zoom and shift input images.\ngenerator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\ngenerator.fit(train_data)\n\n# Split train data to features and labels\ntrain_data, train_data_val, train_labels, train_labels_val = train_test_split(train_data, \n                                                                              train_labels,\n                                                                              test_size=0.1)  \n# Build and train CNN model\nmodel = Sequential()\nmodel.add(Conv2D(6, kernel_size=3, input_shape=(img_width, img_height,3), activation='relu'))\nmodel.add(MaxPool2D(2))\nmodel.add(Conv2D(12, kernel_size=3, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(train_labels.columns.size, activation='softmax'))\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# We'll stop training if no improvement after some epochs\nearlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n# Save the best model during the traning\ncheckpointer = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n\n# Train\ntraining = model.fit_generator(generator.flow(train_data,train_labels, batch_size=100),\n                               epochs = 30,\n                               validation_data=(train_data_val, train_labels_val),\n                               steps_per_epoch=100,  # batch_size\n                               callbacks=[earlystopper, checkpointer])\n\n# Load the best model\nmodel.load_weights('best_model.h5')","f36b2fa6":"## Trained model analysis and evaluation\nf, ax = plt.subplots(2,1, figsize=(5,5))\nax[0].plot(training.history['loss'])\nax[0].set_title('Detect kind of Bee: loss')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\n\n# Accuracy\nax[1].plot(training.history['acc'])\nax[1].set_title('Detect kind of Bee: accuracy')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nplt.tight_layout()\nplt.show()\n\n# Accuracy by subspecies\ntest_pred = model.predict(test_data)\nacc_by_subspecies = np.logical_and((test_pred > 0.5), test_labels).sum()\/test_labels.sum()\nacc_by_subspecies.plot(kind='bar', title='Subspecies prediction accuracy')\nplt.ylabel('Accuracy')\nplt.show()\n\n# Loss function and accuracy\ntest_res = model.evaluate(test_data, test_labels)\nprint('Evaluation: loss function: %s, accuracy:' % test_res[0], test_res[1])","d8b2b45b":"# Load my Kaggle avatar\nmy_img_url = 'https:\/\/storage.googleapis.com\/kaggle-avatars\/images\/701733-kg.jpg'\nmy_img_full = skimage.io.imread(my_img_url)\n\n# Prepare image for prediction\nmy_img = skimage.transform.resize(my_img_full, (img_width, img_height), mode='reflect')[:,:,:img_channels]\n# Predict my subspecies with already well-trained CNN\nmy_pred_index = model.predict(my_img[None,...]).argmax()\nmy_subspecies = test_labels.columns[my_pred_index]\n\n# Use default style wo grid lines\nplt.style.use('default')\n\n# Draw the photo titled by subspecies recognized\nplt.figure(figsize=(2,2))\nplt.imshow(my_img_full)\nplt.title(my_subspecies)\nplt.show()\n","905228f1":"It is really unbalanced, need to figure it out before we feed this to CNN.","11370976":"## 6. Evaluate trained model","32d75b79":"## 5. Create and train CNN","527830db":"# 2. Read the data","1e88175e":"# 3. Bee data EDA\n<b>Subspecies<\/b> column is of interest for this kernel's goal.\n## 3.1 Distribution of bees by subspecies\nCheck how much Bees we have in each subspecies","5c90b741":"# 4. Data preprocessing\n## 4.1. Balance by subspecies \nLet's make the count of each subspecies to be equal. It seems there is no standard function to do <b>balanced<\/b> train_test_split. But <b>sklearn.utils.resample<\/b> will do the job for each subspecies category separately, in a loop. We don't worry about upsampling duplicates, hoping that later image augmentation will vary the input enough. But we should split all bees to train and test <b>before balancing<\/b> to prevent upsampled duplicates occur in both train and test.","c0deac91":"# 1. Kernel objectives\n\nThis kernel is created for 2 reasons:\n\n1. Train CNN to recognize subspecies of Bee\n\n2. Feed <b>my photo<\/b> to trained CNN and determine what subspecies of Bee I actually am :)\n","60be0e5c":"> # 7. Who am I?\nNow I am coming to the very end of my research and can apply the whole power of modern artificial intelligence to classify myself."}}