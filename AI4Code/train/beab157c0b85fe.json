{"cell_type":{"70c0aa2d":"code","a9497bdf":"code","1ff63d7c":"code","df5601bc":"code","3769115c":"code","f6e1d0e9":"code","4b9554bf":"code","ce615521":"code","f40f5c2a":"code","7181f074":"code","c5982c59":"code","01c514cb":"code","1903f481":"code","e95c7666":"code","9c4875fa":"code","df41dc96":"markdown","8d33ec86":"markdown","24f84b69":"markdown","fb4bd45d":"markdown","72011c37":"markdown","46f22b17":"markdown","761538ef":"markdown","79d6ba25":"markdown","3fa94870":"markdown","d14172a2":"markdown"},"source":{"70c0aa2d":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings(\"ignore\")\n#general\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import RobustScaler\nimport pickle\nfrom tqdm.auto import tqdm\nfrom collections import defaultdict\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport gc\nimport cv2\ngc.enable()\nimport glob\npd.set_option('display.max_columns', None) \nfrom sklearn.linear_model import RidgeCV\n\n# visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# augmentation\nfrom albumentations.pytorch import ToTensorV2\nimport albumentations as A\n\n# deep learning\nimport timm\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR, ReduceLROnPlateau, StepLR, LambdaLR\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport imageio\nfrom PIL import Image\nfrom tqdm import tqdm\ntqdm.pandas()\n\n# metrics\nfrom sklearn.metrics import mean_squared_error","a9497bdf":"if not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'","1ff63d7c":"class Config:\n    base_dir = \"\/content\/drive\/MyDrive\/petfinder\"\n    data_dir = \"..\/input\/petfinder-pawpularity-score\/\"\n    meta_data_dir = \"..\/input\/trainmeta\/\"\n    model_dir = \".\"\n    output_dir = \".\"\n    random_seed = 555\n    n_epoch = 5\n    n_fold = 5\n    tta = 1 # 1 or 4\n    model_path = \"swin_large_patch4_window7_224\"\n    pretrained = True\n    inp_channels = 3\n    im_size =  224\n    lr = 2e-5\n    opt_wd_non_norm_bias = 0.01\n    opt_wd_norm_bias = 0 # same as Adam in Fastai\n    opt_beta1 = 0.9\n    opt_beta2 = 0.99 # same as Adam in Fastai\n    opt_eps = 1e-5 # same as Adam in Fastai\n    batch_size = 32\n    epoch_step_valid = 3\n    num_workers = 8\n    out_features = 1\n    dropout = 0\n    mixup = False\n    mixup_alpha =1.0\n    debug = False\n    if debug:\n        n_epoch = 1\n        n_fold = 2\n        n_sample_debug = 500","df5601bc":"def seed_everything(seed=Config.random_seed):\n    #os.environ['PYTHONSEED'] = str(seed)\n    np.random.seed(seed%(2**32-1))\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic =True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything()\n# device optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n\nprint(f'Using device: {device}')","3769115c":"img_train_dir = os.path.join(Config.data_dir, 'train')\ndef return_imgfilepath(name, folder=img_train_dir):\n    path = os.path.join(folder, f'{name}.jpg')\n    return path\n\ntrain_file_path = os.path.join(Config.data_dir, 'train.csv')\ntrain_df = pd.read_csv(train_file_path)\n\n# set image filepath\ntrain_df['file_path'] = train_df['Id'].progress_apply(lambda x: return_imgfilepath(x))\ntrain_df.head()","f6e1d0e9":"if Config.debug:\n    train_df = train_df.sample(500).reset_index(drop = True)\ntrain_df['norm_score'] = train_df['Pawpularity'] \/ 100\n#Sturges' rule\nnum_bins = int(np.floor(1+(3.3)*(np.log2(len(train_df)))))\ntrain_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['fold'] = -1\n\nskf = StratifiedKFold(n_splits = Config.n_fold, shuffle=True, random_state =Config.random_seed)\nfor i, (_, train_index) in enumerate(skf.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()","4b9554bf":"train_df[train_df['fold']==0].head()","ce615521":"class PetDataset(Dataset):\n    def __init__(self, image_filepaths, targets, transform=None):\n        self.image_filepaths = image_filepaths\n        self.targets = targets\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_filepaths)\n\n    def __getitem__(self, idx):\n        image_filepath = self.image_filepaths[idx]\n        with open(image_filepath, 'rb') as f:\n            image = Image.open(f)\n            image_rgb = image.convert('RGB')\n        image = np.array(image_rgb) \/ 255 # convert to 0-1\n\n        if self.transform is not None:\n            image = self.transform(image = image)[\"image\"]\n        \n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        target = self.targets[idx]\n\n        image = torch.tensor(image, dtype = torch.float)\n        target = torch.tensor(target, dtype = torch.float)\n        return image, target\n    \ndef get_transforms(dim = Config.im_size):\n    return A.Compose(\n        [            \n            A.Resize(height=dim, width=dim)\n        ]\n    )","f40f5c2a":"class PetNet(nn.Module):\n    def __init__(\n        self,\n        model_name = Config.model_path,\n        out_features = Config.out_features,\n        inp_channels=Config.inp_channels,\n        pretrained=Config.pretrained\n    ):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n    \n    def forward(self, image):\n        output = self.model(image)\n        return output","7181f074":"def divice_norm_bias(model): \n    norm_bias_params = []\n    non_norm_bias_params = []\n    except_wd_layers = ['norm', '.bias']\n    for n, p in model.model.named_parameters():\n        if any([nd in n for nd in except_wd_layers]):\n            norm_bias_params.append(p)\n        else:\n            non_norm_bias_params.append(p)\n    return norm_bias_params, non_norm_bias_params\n\ndef usr_rmse_score(output, target):\n    y_pred = torch.sigmoid(output).cpu()\n    y_pred = y_pred.detach().numpy()*100\n    target = target.cpu()*100\n    \n    return mean_squared_error(target, y_pred, squared=False)\n\ndef rmse_oof(_oof_df, fold=None):\n    oof_df = _oof_df.copy()\n    if fold is not None:\n        oof_df = oof_df[oof_df[\"fold\"] == fold]\n    target = oof_df['Pawpularity'].values\n    y_pred = oof_df['pred'].values\n    if fold is not None:\n        print(f'fold {fold}: {mean_squared_error(target, y_pred, squared=False)}')\n    else:\n        print(f'overall: {mean_squared_error(target, y_pred, squared=False)}')\n\nclass MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] \/ metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"],\n                    float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )\n    \n","c5982c59":"def train_fn(train_loader, model, criterion, optimizer, epoch):\n    metric_monitor = MetricMonitor()\n    model.train()\n    scaler = GradScaler()\n    stream = tqdm(train_loader)\n\n    for batch_idx, (images, target) in enumerate(stream, start = 1):\n        images = images.to(device, non_blocking = True).float()\n        target = target.to(device, non_blocking = True).float().view(-1, 1)\n\n\n        with autocast(): # mixed precision\n            output = model(images)\n        \n        loss = criterion(output, target)\n        rmse_score = usr_rmse_score(output, target)\n        metric_monitor.update('Loss', loss.item())\n        metric_monitor.update('RMSE', rmse_score)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n        stream.set_description(f'Epoch: {epoch:02}. Train. {metric_monitor}')\n\ndef valid_fn(valid_loader, model, criterion, epoch):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(valid_loader)\n    final_targets = []\n    final_preds = []\n    for i, (images, target) in enumerate(stream, start=1):\n        images = images.to(device, non_blocking = True).float()\n        target = target.to(device, non_blocking = True).float().view(-1, 1)\n        with torch.no_grad():\n            output = model(images)\n        \n        loss = criterion(output, target)\n        rmse_score = usr_rmse_score(output, target)\n        metric_monitor.update('Loss', loss.item())\n        metric_monitor.update('RMSE', rmse_score)\n        stream.set_description(f\"Epoch: {epoch:02}. Valid. {metric_monitor}\")\n        target = (target.detach().cpu().numpy() * 100).ravel().tolist()\n        pred = (torch.sigmoid(output).detach().cpu().numpy() * 100).ravel().tolist()\n\n        final_preds.extend(pred)\n        final_targets.extend(target)\n    final_preds = np.array(final_preds)\n    final_targets = np.array(final_targets)\n    del valid_loader, target, output, images\n    gc.collect()\n    torch.cuda.empty_cache()\n    return final_targets, final_preds","01c514cb":"oof_df = pd.DataFrame()\nfor fold in range(Config.n_fold):\n    print(f'=== fold {fold}: training ===')\n    train = train_df[train_df['fold'] != fold]\n    valid = train_df[train_df['fold'] == fold]\n    valid_idx = valid.index\n    \n    X_train_paths = train['file_path'].values\n    y_train = train['norm_score'].values\n    X_valid_paths = valid['file_path'].values\n    y_valid = valid['norm_score'].values\n    \n    train_dataset = PetDataset(\n      image_filepaths = X_train_paths,\n      targets = y_train,\n      transform = get_transforms()\n    )\n    \n    train_loader = DataLoader(\n      train_dataset,\n      batch_size = Config.batch_size,\n      shuffle = True,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    \n    valid_dataset = PetDataset(\n      image_filepaths = X_valid_paths,\n      targets = y_valid,\n      transform = get_transforms()\n    )\n    \n    valid_loader = DataLoader(\n      valid_dataset,\n      batch_size = Config.batch_size,\n      shuffle = True,\n      num_workers = Config.num_workers,\n      pin_memory = True\n    )\n    \n    model = PetNet()\n    model = model.to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    norm_bias_params, non_norm_bias_params = divice_norm_bias(model)\n    optimizer = torch.optim.AdamW(\n      [\n          {'params': norm_bias_params, 'weight_decay': Config.opt_wd_norm_bias},\n          {'params': non_norm_bias_params, 'weight_decay': Config.opt_wd_non_norm_bias},\n      ],\n      betas=(Config.opt_beta1, Config.opt_beta2),\n      eps=Config.opt_eps,\n      lr = Config.lr,\n      amsgrad = False\n    )\n    \n    best_rmse = np.inf\n    for epoch in range(1, Config.n_epoch + 1):\n        print(f'=== fold:{fold} epoch: {epoch}: training ===')\n        train_fn(train_loader, model, criterion, optimizer, epoch)\n        valid_targets, preds = valid_fn(valid_loader, model, criterion, epoch)\n        valid_rmse = round(mean_squared_error(valid_targets, preds, squared=False), 3)\n        print(f'epoch {epoch}: rmse: {valid_rmse}')\n        \n        if valid_rmse < best_rmse:\n            best_rmse = valid_rmse\n            torch.save(model.state_dict(), f'{Config.model_dir}\/model_fold{fold}.pth')\n            print(\"saved model.\")\n            _oof_df = pd.DataFrame(data={'Pawpularity':valid_targets, 'pred':preds, 'fold':fold}, index=valid_idx)\n            \n    del model, train_dataset, train_loader, valid_dataset, valid_loader\n    gc.collect()\n    torch.cuda.empty_cache()\n    oof_df = pd.concat([oof_df, _oof_df])","1903f481":"for i in range(Config.n_fold):\n    rmse_oof(oof_df, i)\nrmse_oof(oof_df)","e95c7666":"oof_df.sort_index().to_csv('oof.csv', index=False)","9c4875fa":"plt.hist(oof_df['Pawpularity'].values, alpha = 0.4, color = 'b', label = 'target', bins = 50)\nplt.hist(oof_df['pred'].values, alpha = 0.4, color = 'g', label = 'prediction', bins = 50)\nplt.show()","df41dc96":"## StratifiedKFold","8d33ec86":"## libraries","24f84b69":"## training loop\n\n- scheduler: none\n- optimizer: AdamW\nhyper parameters are the same as Adam in Fastai","fb4bd45d":"## Dataset & augmentation\n\n### PetDataset\nchannels of image converted to 0-1\n\n### get_transforms\nOnly resizing is applied to both train and valid data ","72011c37":"## set up environments & prepare data\n\n- set_seed\nSet random seed for random, torch, and numpy\n\nhttps:\/\/docs.fast.ai\/torch_core.html#set_seed\n\nif reproducible is True:\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","46f22b17":"## cv score","761538ef":"This notebook is based on the following notebook, thanks.\n\nhttps:\/\/www.kaggle.com\/manabendrarout\/transformers-classifier-method-starter-train#Train-and-Validation-Functions","79d6ba25":"## model","3fa94870":"## helper function\n\n### divice_norm_bias\nfunction to divide parameters at BatchNorm layer and all bias or not.\n\n### usr_rmse_score\ncalculate competition metrics\n\nreference\n- https:\/\/docs.fast.ai\/learner.html#Learner\n- https:\/\/docs.fast.ai\/optimizer.html#Adam\n- https:\/\/pytorch.org\/docs\/stable\/generated\/torch.optim.AdamW.html\n- https:\/\/docs.fast.ai\/losses.html#BCEWithLogitsLossFlat\n","d14172a2":"## Config"}}