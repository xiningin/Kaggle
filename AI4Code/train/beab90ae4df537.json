{"cell_type":{"e66a2e86":"code","e027d42c":"code","1a581b4a":"code","01653400":"code","b87bf31e":"code","e0ded4fb":"code","b4258cf2":"code","a5a10378":"code","6e91260c":"code","0ffbd49f":"code","09546dcc":"code","7722426e":"code","8ff4f66b":"code","19e71d16":"code","584a94a0":"code","af677b4e":"code","2914ec98":"markdown","5871442d":"markdown","caa2faac":"markdown","e15b427c":"markdown","c89db82d":"markdown","b9e079bb":"markdown","b7ee1439":"markdown","b59f1e46":"markdown","bd7baa70":"markdown","1c0288f4":"markdown","faa7d657":"markdown","92515c38":"markdown","f9b64fd4":"markdown","2b6a75d0":"markdown","bc27c388":"markdown","1a072810":"markdown","b4e536f5":"markdown","f37384e7":"markdown","de01e41f":"markdown","0c5ac354":"markdown","b31746a9":"markdown","fc8de518":"markdown"},"source":{"e66a2e86":"%%html\n<link rel=\"stylesheet\" href=\"https:\/\/kangarooaifr.github.io\/kangaroo-factory\/src\/css\/k-notebook.css\">","e027d42c":"# Import\nimport pathlib\nimport os\n\nimport PIL\nimport PIL.Image\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport tensorflow as tf\n\n#from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\n\n# Import utility script\nfrom plot_binary_accuracy import plot_binary_accuracy\n\n# Print TensorFlow version\nprint(tf.__version__)","1a581b4a":"# -- dataset directory\ndata_dir = '..\/input\/coffee-images\/256x'\ndata_dir = pathlib.Path(data_dir)\n\n# -- test directory\ntest_dir = '..\/input\/coffee-images\/256x_test'\ntest_dir = pathlib.Path(test_dir)\n\n# -- dataset image parameters\nimg_height = 256\nimg_width = 256\n\n# -- target size of the image (to feed model)\nimg_target_height = 150\nimg_target_width = 150\n\n# -- TF training parameters\nvalidation_split = 0.2\nbatch_size = 32\nepochs = 20\n\n# -- TF fine tune training parameters\nepochs_tune = 10\nlearning_rate_tune = 1e-5","01653400":"# check image count\nimage_count = len(list(data_dir.glob('*\/*.jpg')))\nprint('There are', image_count, 'images in the dataset.')","b87bf31e":"# load training set\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=validation_split,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","e0ded4fb":"# load validation set\nvalidation_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=validation_split,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","b4258cf2":"# check training set class names\nclass_names = train_ds.class_names\nprint('Training classes =', class_names)","a5a10378":"# check a few images from training set\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","6e91260c":"# define target size\nsize = (img_target_width, img_target_height)\n\n# resize training and validation set\ntrain_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\nvalidation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))","0ffbd49f":"# Define the base model for transfer learning\nbase_model = tf.keras.applications.Xception(\n    # Load weights pre-trained on ImageNet\n    weights = \"imagenet\",  \n    input_shape = (img_target_width, img_target_height, 3),\n    # Do not include the ImageNet classifier at the top\n    include_top = False) \n\n# Freeze the base_model to keep it's knowledge safe\nbase_model.trainable = False\n\n# Create new model on top\ninputs = tf.keras.Input(shape=(img_target_width, img_target_height, 3))\nx = inputs\n#x = data_augmentation(inputs)  # Apply random data augmentation -- update above LINE\n\n# Rescale input (0, 255) to a range of (-1., +1.)\n# outputs: `(inputs * scale) + offset`\nscale_layer = tf.keras.layers.experimental.preprocessing.Rescaling(scale=1 \/ 127.5, offset=-1)\nx = scale_layer(x)\n\n# The base model contains batchnorm layers. We want to keep them in inference mode\n# when we unfreeze the base model for fine-tuning, so we make sure that the\n# base_model is running in inference mode here.\nx = base_model(x, training = False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dropout(0.2)(x)  # Regularize with dropout\noutputs = tf.keras.layers.Dense(1)(x)\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.summary()","09546dcc":"# define compile options\nmodel.compile(\n    optimizer = tf.keras.optimizers.Adam(),\n    loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n    metrics = [tf.keras.metrics.BinaryAccuracy()])","7722426e":"# train model\nhistory = model.fit(train_ds, epochs = epochs, validation_data = validation_ds)","8ff4f66b":"plot_binary_accuracy(history)","19e71d16":"# Unfreeze the base_model\nbase_model.trainable = True\nmodel.summary()\n\n# Update compile options (low learning rate)\nmodel.compile(\n    # Low learning rate\n    optimizer = tf.keras.optimizers.Adam(learning_rate_tune),\n    loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n    metrics = [tf.keras.metrics.BinaryAccuracy()])\n\n\n# Train model\nmodel.fit(train_ds, epochs = epochs_tune, validation_data = validation_ds)","584a94a0":"# image list\nimages = []\n\n# load all images from folder\nfor img in os.listdir(test_dir):\n    img = os.path.join(test_dir, img)\n    img = image.load_img(img, target_size=(img_target_width, img_target_height))\n    images.append(img)\n\n# cast image list into a list of np arrays\nimg_arr = [image.img_to_array(x) for x in images] \n\n# expand dim\ninput_stack = np.expand_dims(img_arr, axis = 0)\n\n# stack up images list to pass for prediction\ninput_stack = np.vstack(input_stack)\n\n# make predictions\npredictions = model.predict(input_stack, batch_size = 10)\n\n# Apply a sigmoid since our model returns logits\npredictions = tf.nn.sigmoid(predictions)\npredictions = tf.where(predictions < 0.5, 0, 1)","af677b4e":"# define labels\nlabels = ['espresso', 'longblack']\n\n# check test images & prediction label\nplt.figure(figsize=(20, 10))\nfor i in range(30):\n    ax = plt.subplot(5, 6, i + 1)\n    plt.imshow(images[i])\n    plt.title(labels[predictions[i,0]])\n    plt.axis(\"off\")","2914ec98":"<div class=\"flex-row-container\"> \n    <!-- Component: GREY BOX -->\n    <div class=\"k-gbox\">\n        <h3>Base model<\/h3>\n        <p>Okay, remember we want to use transfer learning. <br>\n            That means we will reuse an already trained model as a basis of our model. Here the Xception model available in Keras.<\/p>\n        <h3>Build on top<\/h3>\n        <p>\n    We will create additional layers on top of that pre-trained model to specialize it in detecting the two types of coffees. <br>\n    If you run the notebook and skip the training (model.fit) steps and directly jump to the Make prediction & check section, <br>\n    you will be able to see that the base model gives random predictions on the test set.\n    <\/p>\n    <\/div>\n        <div class=\"flex-col-container\" style=\"width:51%;margin-left:20px;\">\n        <!-- Component: HORIZONTAL BOX -->\n        <div class=\"k-hbox\">\n          <div class=\"k-hbox-left\">\n            <h2>Xception<\/h2>\n            <div class=\"k-tag\">\n              <p>model<\/p>\n            <\/div>\n          <\/div>\n          <div class=\"k-hbox-right\">\n            <p>You can get more information about this model here: <\/p>\n            <a href=\"https:\/\/arxiv.org\/abs\/1610.02357#\">https:\/\/arxiv.org\/abs\/1610.02357#<\/a>\n          <\/div>\n        <\/div>\n    <\/div>\n<\/div>","5871442d":"<div class=\"k-gbox\" style=\"width:auto;\">\n    <p>We're going to give a final training round to the whole model (not just the top layers).<br>\nThis will be done with low learning rate and for a few epochs.<\/p>\n\n<p>\n    You can check in the training log that the validation binary accuracy is going to improve.\n<\/p>\n    <\/div>","caa2faac":"<div class=\"flex-row-container\"> \n    <div class=\"flex-col-container\" style=\"width:51%;\">\n        <!-- Component: VERTICAL BOX -->\n        <div class=\"k-vbox\" style=\"margin-bottom:20px;\">\n            <div class=\"k-vbox-header\">\n                <h2>Espresso<\/h2>\n                <div class=\"k-tag\">\n                    <p>label<\/p>\n                <\/div>\n            <\/div>\n            <div class=\"k-vbox-body\">\n                <p>This is a short coffee extracted in its pure state from the bean.<br>\n                    This is the italian word.<\/p>\n            <\/div>\n        <\/div>\n        <!-- Component: VERTICAL BOX -->\n        <div class=\"k-vbox\">\n            <div class=\"k-vbox-header\">\n                <h2>LongBlack<\/h2>\n                <div class=\"k-tag\">\n                    <p>label<\/p>\n                <\/div>\n            <\/div>\n            <div class=\"k-vbox-body\">\n                <p>This is a shot of espresso extracted on top of hot water.<br>\n                Similar to Americano, except the coffee is on top to avoid burning it and keep the crema.<\/p>\n            <\/div>\n        <\/div>\n    <\/div>\n    <!-- Component: GREY BOX -->\n    <div class=\"k-gbox\" style=\"margin-left:20px;\">\n        <h3>Coffee<\/h3>\n        <p>I'm one of these coffee lovers. <br>\n        I started to take photos of my coffees at home to work on my own data and see how much images I need to be able to train a binary classification model on them.<\/p>\n        <h3>Small dataset<\/h3>\n        <p>Transfer Learning immedialety appears to be a great option since the dataset is very small, and growing at low pace (a few pictures on daily basis).<br>\n            Data Augmentation is also a great way to extend such a small dataset, given that images can easily be transformed with random operations (flip, rorate, ...) that are already provided with Keras - hence no need to code them.<\/p>\n        <h3>GPU<\/h3>\n        <p>Last point - even if it's not Kaggle related - I wanted to setup the GPU support for TensorFlow on my local computer with CUDA Toolkit.<\/p>\n    <\/div>\n<\/div>","e15b427c":"<p>The images are going to be scaled to a lower size in order to save computation time.<\/p>","c89db82d":"<div class=\"k-section\">\n    <h1>Make prediction, check result<\/h1>\n<\/div>","b9e079bb":"<div class=\"k-section\">\n    <h1>Introduction<\/h1>\n<\/div>","b7ee1439":"<div class=\"flex-row-container\"> \n    <!-- Component: GREY BOX -->\n    <div class=\"k-gbox\">\n        <h3>Conclusion<\/h3>\n        <p>Well... so far it's great to see the whole pipeline works.<\/p>\n        <h3>Next steps<\/h3>\n        <p>For sure the test set is way to small to draw further conclusions (this is why I put no test metric).<br>\n            I will see in the future as the dataset grows how it behaves, and add metrics then.<\/p>\n    <\/div>\n        <div class=\"flex-col-container\" style=\"width:51%;margin-left:20px;\">\n        <!-- Component: HORIZONTAL BOX -->\n        <div class=\"k-hbox\">\n          <div class=\"k-hbox-left\">\n            <h2>CSS<\/h2>\n            <div class=\"k-tag\">\n              <p>theme<\/p>\n            <\/div>\n          <\/div>\n          <div class=\"k-hbox-right\">\n            <h3>About the CSS Theme<\/h3>\n              <p>The CSS file is hosted on GitHub repository, with a HTML template file.<\/p>\n              <a href=\"https:\/\/github.com\/kangarooaifr\/kangaroo-factory\/blob\/main\/samples\/Notebook%20CSS%20Theme.html\">link<\/a>\n          <\/div>\n        <\/div>\n    <\/div>\n<\/div>","b59f1e46":"<p>As you can see, the Xception model is there and all its parameters are not trainable since frozen.<\/p>","bd7baa70":"<div class=\"k-section\">\n<h1>Fine tune training<\/h1>\n<\/div>","1c0288f4":"<div class=\"k-gbox\" style=\"width:auto;\">\n    <h3>Load dataset, check and resize<\/h3>\n    <p>We're going to check how many images we have in the dataset.<\/p>\n    <p>Then load those files into both training and validation set.<br>\n    The image_dataset_from_directory() method from Keras directly puts the labels from the folder names to the training and validation sets.<br>\n    It will also split the dataset into training and validation based on the validation_split parameter we defined before.<\/p>\n    <p>Finally a sample of images will be displayed.<\/p>\n<\/div>","faa7d657":"<div class=\"k-section\">\n    <h1>Declare parameters<\/h1>\n<\/div>","92515c38":"Let's first make this notebook beautifull by running the cell below (external CSS import).","f9b64fd4":"<div class=\"k-section\">\n    <h1>Define model and compile options<\/h1>\n<\/div>","2b6a75d0":"<p>Now let's check the training set class names as well as a few images<\/p>","bc27c388":"<div class=\"k-gbox\" style=\"width:auto;\">\n<p>\n    Now is time to train the model and check the training history (accuracy and loss).\n<\/p>\n<\/div>","1a072810":"<div class=\"k-header\">\n    <h1>Espresso or Longblack?<\/h1>\n    <h2>Transfer Learning Image Classification<\/h2>\n    <div class=\"k-tag\">\n        <p>Transfer learning<\/p>\n    <\/div>\n<\/div>","b4e536f5":"<div class=\"k-section\">\n    <h1>Train model<\/h1>\n<\/div>","f37384e7":"<div class=\"k-gbox\" style=\"width:auto;\">\n    <h3>Packages<\/h3>\n    <p>Here are the main packages used in this notebook:<\/p>\n    <ul>\n        <li>PIL package will be used to load images.<\/li>\n        <li>matplotlib to plot those images<\/li>\n        <li>tensorflow to build, train and test model.<\/li>\n    <\/ul>\n<\/div","de01e41f":"<div class=\"k-section\">\n    <h1>Dataset<\/h1>\n<\/div>","0c5ac354":"<div class=\"k-section\">\n    <h1>Import<\/h1>\n<\/div>","b31746a9":"<div class=\"k-gbox\" style=\"width:auto;\">\n    <p>Okay, now let's check the model with new images.<br>\nNote: I'm putting ~10% of the new pictures into the test folder each time I add new images to the dataset.<\/p>\n    <\/div>","fc8de518":"<div class=\"k-footer\">\n    <h1>Thank You<\/h1>\n<\/div>"}}