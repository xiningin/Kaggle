{"cell_type":{"479491e3":"code","8be5b079":"code","2e1b884c":"code","83693b9a":"code","2e27f4f8":"code","446803c4":"code","973c6f5b":"code","97bf4a04":"code","a764942f":"code","620eb3ac":"code","0700ff30":"code","318f0b5f":"code","0b9ed642":"markdown"},"source":{"479491e3":"#imports\nimport pandas as pd\nimport json\nimport numpy as np\nimport keras\nfrom keras.layers import Dense, Input\nfrom keras.models import Model\nfrom keras import regularizers","8be5b079":"#Read the data\nlegit_grams = pd.read_csv('..\/input\/cmpgramslegit\/compressed_legit_min_max_grams.csv')\nmals_grams = pd.read_csv('..\/input\/cmpgramsmals\/compressed_mals_min_max_grams.csv')\n\n#Generate labels\nlegit_labels = np.zeros(legit_grams.shape[0])\nmals_labels = np.ones(mals_grams.shape[0])","2e1b884c":"#Delete unsused columns\ndel legit_grams['Unnamed: 0']\ndel legit_grams['path']\ndel mals_grams['Unnamed: 0']\ndel mals_grams['path']","83693b9a":"#Concat data\ndataset = pd.concat([legit_grams, mals_grams], sort = False)\ndataset_labels = np.concatenate([legit_labels, mals_labels])","2e27f4f8":"#HyperParameters\ninput_dim = dataset.shape[1]\noutput_dim = 1\nlayers_configs = [[1024, 1024]]\ntraining_algorithms = ['adam']\nlosses = ['mean_squared_error']\ndropouts = [1]\nregularization = ['dropout', 'early']\nregularizers_v = [regularizers.l2(0.)]\nhidden_activations = ['relu']\noutput_activations = ['sigmoid']\ncallbacks = []\nmetrics = ['accuracy']\ninitializers = ['random_normal']\nepochs = 100\nbatch_size = 512","446803c4":"#return configuration for keras network\ndef configs_builder(input_dim, output_dim, layers_configs, training_algorithms, \n                    losses, dropouts, regularizers, \n                    hidden_activations, output_activations, \n                    callbacks, metrics, initializers):\n    configs = []\n    for layers_config in layers_configs:\n        for training_algorithm in training_algorithms:\n            for loss in losses:\n                for dropout in dropouts:\n                    for regularizer in regularizers_v:\n                        for hidden_activation in hidden_activations:\n                            for output_activation in output_activations:\n                                for initializer in initializers:\n                                    config = {\n                                        'layers': {\n                                            'dtype' : 'float32',\n                                            'input dim': input_dim,\n                                            'number': len(layers_config),\n                                            'dims': layers_config,\n                                            'names': ['dense'+str(x) for x in range(1, len(layers_config)+1, 1)],\n                                            'initializers': [initializer for x in range(len(layers_config))],\n                                            'bias initializers': [initializer for x in range(len(layers_config))],\n                                            'activations': [hidden_activation for x in range(len(layers_config))],\n                                            'kernel regulizers': [regularizer for x in range(len(layers_config))],\n                                            'output dim': output_dim,\n                                            'output activation' : output_activation,\n                                            'ouput initializer' : initializer,\n                                            'output bias initializer': initializer,\n                                            'output regulizer': regularizer,\n                                        },\n\n                                        'compile': {\n                                            'optimizer': training_algorithm,\n                                            'metrics': metrics,\n                                            'loss': loss,\n                                            'callbacks': callbacks,\n                                        },\n                                    }\n                                    configs.append(config)\n    return configs","973c6f5b":"#build a feedforward network using the configuration\ndef feed_forward_builder(config):\n    input_layer = Input(shape=(config['layers']['input dim'],), dtype = config['layers']['dtype'], name = 'InputLayer')\n    if config['layers']['number'] == 0:\n        print('No Hidden Layers')\n    else:\n        layer = Dense(config['layers']['dims'][0], \n                      dtype = config['layers']['dtype'], \n                      name = config['layers']['names'][0], \n                      activation = config['layers']['activations'][0], \n                      kernel_initializer = config['layers']['initializers'][0], \n                      bias_initializer = config['layers']['bias initializers'][0], \n                      kernel_regularizer = config['layers']['kernel regulizers'][0])(input_layer)\n        for n in range(1,config['layers']['number'],1):\n            layer =   Dense(config['layers']['dims'][n], \n                      dtype = config['layers']['dtype'], \n                      name = config['layers']['names'][n], \n                      activation = config['layers']['activations'][n], \n                      kernel_initializer = config['layers']['initializers'][n], \n                      bias_initializer = config['layers']['bias initializers'][n], \n                      kernel_regularizer = config['layers']['kernel regulizers'][n])(layer)\n    output_layer = Dense(config['layers']['output dim'], \n                         dtype =  config['layers']['dtype'], \n                         name = 'OutputLayer', \n                         activation = config['layers']['output activation'], \n                         kernel_initializer = config['layers']['ouput initializer'], \n                         bias_initializer = config['layers']['output bias initializer'], \n                         kernel_regularizer = config['layers']['output regulizer'])(layer)\n    fnn = Model(inputs = input_layer, outputs = output_layer)\n    fnn.compile(optimizer = config['compile']['optimizer'], \n                metrics = config['compile']['metrics'], \n                loss = config['compile']['loss'])\n    return fnn","97bf4a04":"#train\ndef fnn_trainer(model, params, data, labels):\n    return model.fit(data, labels, validation_split = params['validation'], \n                        batch_size = params['batch_size'], epochs = params['epochs'])","a764942f":"#start trainer and return history of error\ndef fnn_evaluate(configs, data, labels):\n    params = {\n        'epochs' : 10,\n        'batch_size' : 512,\n        'validation': 0.15,\n    }\n    histories = []\n    for config in configs:\n        model = feed_forward_builder(config)\n        model.summary()\n        histories.append(fnn_trainer(model, params, data, labels))\n    return histories, model","620eb3ac":"#Get the configuration for the network\nconfigs = configs_builder(input_dim, output_dim, layers_configs, training_algorithms, \n                    losses, dropouts, regularizers, \n                    hidden_activations, output_activations, \n                    callbacks, metrics, initializers)","0700ff30":"#Launch training \nhistories, model = fnn_evaluate(configs, dataset, dataset_labels)","318f0b5f":"#print history\nfor h in histories:\n    print(h.history)","0b9ed642":"# Malware detection using 4-grams of bytes\n* First you need to include two data sets, the one of malwares (cmpgramsmals) and the one of benign files (cmpgramslegit)\n* You can find both data sets in the following links: https:\/\/www.kaggle.com\/isuremu\/cmpgramsmals & https:\/\/www.kaggle.com\/isuremu\/cmpgramslegit\n* For more information how we extracted this data, consider checking my github repository, it contains other useful notebooks about malware detection\n* The following code is just an example of use and it's not meant to be a very sophisticated one.\n"}}