{"cell_type":{"26411846":"code","67fbb4ec":"code","f28ece03":"code","0686495c":"code","f06ea4ba":"code","8bde115b":"code","ee49f74e":"code","073b6325":"code","6c1013eb":"code","b351d91e":"code","e28696db":"code","d8ba2980":"code","fbb00f63":"code","f437e0a3":"code","d5443453":"code","eff3fe09":"code","4556cc8a":"code","4b863559":"code","2be03b40":"code","6a95bba7":"markdown","2eaa28c3":"markdown","296b72bb":"markdown","393add2f":"markdown","b88f768d":"markdown","d0015134":"markdown","3b0f0069":"markdown","21f7d0d6":"markdown","8e0dfe4e":"markdown"},"source":{"26411846":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","67fbb4ec":"df_train = pd.read_csv(\"..\/input\/train.csv\") ","f28ece03":"df_train.shape","0686495c":"df_train.head()","f06ea4ba":"molecule_name_counts = df_train[\"molecule_name\"].value_counts()\nmolecule_name_counts","8bde115b":"print(\"Max: \" + molecule_name_counts.idxmax() + \": \" + str(molecule_name_counts[molecule_name_counts.idxmax]))\nprint(\"Min: \" + molecule_name_counts.idxmin() + \": \" + str(molecule_name_counts[molecule_name_counts.idxmin]))","ee49f74e":"molecule_str = pd.DataFrame(molecule_name_counts.keys().str.split(\"_\").tolist(), columns=[\"str\", \"digit\"])","073b6325":"molecule_str.head()","6c1013eb":"molecule_str[\"str\"].value_counts()","b351d91e":"molecule_str_train = pd.DataFrame(df_train[\"molecule_name\"].str.split(\"_\").tolist(), columns=[\"str\", \"digit\"])\ndf_train[\"molecule_digit\"] = molecule_str_train[\"digit\"]","e28696db":"df_train.head()","d8ba2980":"print(\"Max: \" + str(df_train[\"scalar_coupling_constant\"].loc[df_train[\"scalar_coupling_constant\"].idxmax()]))\nprint(\"Min: \" + str(df_train[\"scalar_coupling_constant\"].loc[df_train[\"scalar_coupling_constant\"].idxmin()]))","fbb00f63":"plt.figure(figsize=(15,20))\ndf_train[\"scalar_coupling_constant\"].plot.hist(bins=range(-50, 240, 10))","f437e0a3":"# Check values between 20 & 70. \nplt.figure(figsize=(15,20))\ndf_train.loc[ (df_train[\"scalar_coupling_constant\"] > 20) & (df_train[\"scalar_coupling_constant\"] < 70)][\"scalar_coupling_constant\"].plot.hist(bins=range(20, 70, 10))","d5443453":"# Check values between 20 & 70. \nplt.figure(figsize=(15,20))\ndf_train.loc[ (df_train[\"scalar_coupling_constant\"] > 150) & (df_train[\"scalar_coupling_constant\"] < 190)][\"scalar_coupling_constant\"].plot.hist(bins=range(150, 190, 10))","eff3fe09":"from matplotlib import pyplot as plt\nplt.figure(figsize=(15,20))\ndf_train[\"type\"].value_counts().plot.bar()","4556cc8a":"struct_df = pd.read_csv(\"..\/input\/structures.csv\")","4b863559":"struct_df.shape","2be03b40":"display(struct_df.head())","6a95bba7":"Counts are much less than the global hist, but values are still represented. ","2eaa28c3":"**Molecule Name column exploration**","296b72bb":"Most values are around 0. It is interesting how there is almost no value between 20 & 70, then grouped around 70. Then no values between 150 & 190. Let us check this. ","393add2f":"To be continued...","b88f768d":"**Type column exploration**","d0015134":"Seems like the string is actually the same every where, so we can easily consider it as useless for now. Of course, we should check if this is the case in the test set as well. \nLet us append the \"digit\" column to the main test_df","3b0f0069":"**Scalar coupling constant**","21f7d0d6":"**Structure File**","8e0dfe4e":"The difference is much more visible here. Only 200 vals between 150 & 160, & less than 20 for higher vals. "}}