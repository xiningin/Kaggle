{"cell_type":{"1865b474":"code","607ca8ee":"code","65ad2081":"code","e028cb1b":"code","2b4e7c0e":"code","800796b4":"code","d25e3885":"code","54b266cb":"code","be1f2dee":"code","8ec507a6":"code","052c9dc5":"code","31564005":"code","c4b008e8":"code","ecd0935a":"code","0e7c2cfd":"code","6596c46d":"code","08f9de14":"code","c80f1bab":"code","8705e7ae":"code","9a48025d":"code","65fb7c8d":"code","dbd84719":"code","208919f4":"code","cb3ed95f":"code","95fe2f78":"code","672bc241":"code","5891fc3b":"code","9a00e3dc":"code","cdd803aa":"code","029d8ae5":"code","f5c2276b":"code","5b1a3ebb":"code","1b90be17":"code","3723e2bb":"code","cefde35d":"code","95356c6e":"code","f25454e8":"code","d631da55":"code","bafba770":"code","3d79be8a":"code","8dbc09e3":"code","255d4038":"code","630a9d77":"code","36f7c473":"code","9f095d1f":"code","6134d21d":"code","1a278320":"code","b515e1c4":"code","62ed379c":"code","f19872ee":"code","a7331624":"code","6b69a314":"code","2cdbc181":"code","34446329":"code","485839cb":"code","a4af0364":"code","07147cdf":"code","1b56a8ce":"code","1403c31b":"code","c5c1a2cc":"code","1d8fa84a":"code","96439073":"markdown","a8f21005":"markdown","1e15763a":"markdown","424dbd53":"markdown","97abb5be":"markdown","8e97af8d":"markdown","2564d7d1":"markdown","e7b9fa11":"markdown","03c04db2":"markdown","848a9b9e":"markdown","010c2f22":"markdown","86ed4100":"markdown","07be46f6":"markdown","85885409":"markdown","691215c4":"markdown","48c6e77f":"markdown","b5547b17":"markdown","932af37d":"markdown","84690940":"markdown","a4411de3":"markdown","0255968a":"markdown","79fb55c6":"markdown","a9aac911":"markdown","648ce3b4":"markdown","ba590f35":"markdown","3e561d0a":"markdown","413762b3":"markdown","335ea69e":"markdown","92e399f1":"markdown","52a3650a":"markdown","effab62a":"markdown","99c937a0":"markdown"},"source":{"1865b474":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n# importing necessary libraries","607ca8ee":"df = pd.read_csv(\"..\/input\/hmeq.csv\")\ndf_i = pd.read_csv(\"..\/input\/hmeq.csv\")\n# lecture de l'entr\u00e9e\n# En le stockant dans 2 dataframes, nous effectuerons nos op\u00e9rations sur df En cas de besoin de table initiale sans aucun changement nous pouvons utiliser df_i","65ad2081":"df.head()\n\n# Aper\u00e7u du jeu de donn\u00e9esv, les diff\u00e9rentes colonnes","e028cb1b":"df.shape","2b4e7c0e":"df.info()\n\n# nombre d'entr\u00e9es qui ne sont pas c'est \u00e0 dire  non null ","800796b4":"df.describe()\n# Statistiques descriptives\n# Distribution des donn\u00e9es\n# Il n'y a pas d'anomalies dans les donn\u00e9es (respecter les maximums et les moyennes dans chaque cas)","d25e3885":"df.columns\n# Colonnes de l'ensemble de donn\u00e9es","54b266cb":"print(df[\"BAD\"].value_counts())\ndf[\"BAD\"].value_counts().plot(\"barh\")\n# distribution de la variable cible \"BAD\"\n# La classe cible est un peu d\u00e9s\u00e9quilibr\u00e9e - les z\u00e9ros sont d'environ 80% et les uns sont d'environ 20%","be1f2dee":"print(df[\"REASON\"].value_counts())\n\n# Ceci est une fonctionnalit\u00e9 nominale, elle doit \u00eatre modifi\u00e9e de mani\u00e8re \u00e0 pouvoir l'utiliser.","8ec507a6":"print(df[\"JOB\"].value_counts())\n\n# Identique au cas ci-dessus, nous devons trouver un moyen de l'utiliser.","052c9dc5":"df[\"LOAN\"].plot.hist(bins = 20,figsize=(15,7.5))\n\n# distribution de la variable de pr\u00eat\n# la densit\u00e9 entre 10000-30000 est \u00e9lev\u00e9e","31564005":"df[\"DEBTINC\"].plot.hist(bins = 20,figsize=(15,5))\n \n# Highly populated around 25-50\n# We may cap off the end values if required.","c4b008e8":"df[\"CLAGE\"].plot.hist(bins = 20,figsize=(15,7.5))\n\n# La densit\u00e9 est \u00e9lev\u00e9e autour de 100-300 # Nous pouvons plafonner les valeurs> = 600 pour obtenir de meilleurs r\u00e9sultats","ecd0935a":"df[\"CLNO\"].plot.hist(bins = 20,figsize=(15,5))\n\n# Cette distribution semble bonne et nous n'avons rien \u00e0 modifier ici.","0e7c2cfd":"df[\"VALUE\"].plot.hist(bins = 80,figsize=(15,7.5))\n\n# La concentration est \u00e9lev\u00e9e autour de 80000-100000 # Il y a tr\u00e8s moins de valeurs \u00e0 la fin (> = 400000) qui sont un peu \u00e9lev\u00e9es par rapport \u00e0 la moyenne. Nous pouvons les plafonner.","6596c46d":"df[\"MORTDUE\"].plot.hist(bins = 40,figsize=(15,7.5))\n\n# La concentration est \u00e9lev\u00e9e autour de 40000-100000 # Les valeurs \u00e0 la fin (> = 300000) peuvent \u00eatre plafonn\u00e9es.","08f9de14":"df[\"YOJ\"].plot.hist(bins = 40,figsize=(15,7.5))\n# C'est tr\u00e8s biais\u00e9. Il serait pr\u00e9f\u00e9rable de modifier cette variable pour diminuer l'asym\u00e9trie.","c80f1bab":"df[\"DEROG\"].value_counts()\n\n# Des incidents d\u00e9rogatoires n'ont \u00e9t\u00e9 signal\u00e9s que dans quelques cas. # Ainsi, cr\u00e9er une variable binaire avec des valeurs 1 pour au moins un incident d\u00e9sobligeant et 0 pour aucun rapport de ce type peut \u00eatre utile.","8705e7ae":"df[\"DELINQ\"].value_counts()\n\n# La plupart d'entre eux sont nuls. # Identique au cas ci-dessus, la cr\u00e9ation d'une variable binaire serait utile.","9a48025d":"df[\"NINQ\"].value_counts()\n# Distribu\u00e9 principalement entre les cinq premi\u00e8res valeurs","65fb7c8d":"df.isnull().sum()\n\n# Nombre de cas avec Nan.","dbd84719":"df[\"DEROG\"].fillna(value=0,inplace=True)\ndf[\"DELINQ\"].fillna(value=0,inplace=True)","208919f4":"# Caract\u00e9ristiques nominales # Remplacement par classe majoritaire # classe majoritaire en cas de variable JOB est Other # classe majoritaire en cas de REASON varibale est DebtCon\n\ndf[\"REASON\"].fillna(value = \"DebtCon\",inplace = True)\ndf[\"JOB\"].fillna(value = \"Other\",inplace = True)","cb3ed95f":"# Caract\u00e9ristiques num\u00e9riques # Remplacement en utilisant la moyenne de chaque classe\n\ndf.fillna(value=df.mean(),inplace=True)","95fe2f78":"df.isnull().sum()\n# Caract\u00e9ristiques num\u00e9riques\n# Remplacement en utilisant la moyenne de chaque classe","672bc241":"df.head()","5891fc3b":"# importer les modules requis\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\n# suppression des fonctionnalit\u00e9s BAD, JOB, REASON de l'ensemble des fonctionnalit\u00e9s d'entr\u00e9e\nx_basic = df.drop(columns=[\"BAD\",\"JOB\",\"REASON\"])\ny = df[\"BAD\"]\n\n# Fractionnement des donn\u00e9es en ensembles de test et de train\nx_basic_tr,x_basic_te,y_tr,y_te = train_test_split(x_basic,y,test_size =.33,random_state=1)\nlogreg_basic = LogisticRegression()\n\n# Formation du mod\u00e8le de r\u00e9gression logistique de base avec un ensemble de formation\nlogreg_basic.fit(x_basic_tr,y_tr)\n\n\nprint(\"intercept \")\nprint(logreg_basic.intercept_)\nprint(\"\")\nprint(\"coefficients \")\nprint(logreg_basic.coef_)\n\n# Pr\u00e9dire la sortie des cas de test \u00e0 l'aide de l'algorithme cr\u00e9\u00e9 ci-dessus\ny_pre = logreg_basic.predict(x_basic_te)\n\n# Validating the algorithm using various Performance metrics\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nprint(\"\")\na1 = accuracy_score(y_te,y_pre)\nf1 = f1_score(y_te, y_pre, average=\"macro\")\np1 = precision_score(y_te, y_pre, average=\"macro\")\nr1 = recall_score(y_te, y_pre, average=\"macro\")\nprint(\"accuracy score : \",a1)\nprint(\"f1 score : \",f1)\nprint(\"precision score : \",p1)\nprint(\"recall score : \",r1)","9a00e3dc":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    Cette fonction imprime et trace la matrice de confusion.\n    La normalisation peut \u00eatre appliqu\u00e9e en d\u00e9finissant `normalize = True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('V\u00e9ritable \u00e9tiquette')\n    plt.xlabel('\u00e9tiquette pr\u00e9dite')","cdd803aa":"# Calcul de la matrice de confusion pour l'algorithme ci-dessus\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n\n# Tracer une matrice de confusion non normalis\u00e9e\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"],\n                      title='Matrice de confusion - Algorithme de r\u00e9gression logistique')\n\nplt.show()","029d8ae5":"# importer les modules requis\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\ndectree_basic = DecisionTreeClassifier()\ndectree_basic.max_depth = 100\n# Formation du mod\u00e8le d'arbre de d\u00e9cision de base avec un ensemble de formation\ndectree_basic.fit(x_basic_tr,y_tr)\n# Pr\u00e9dire la sortie des cas de test \u00e0 l'aide de l'algorithme cr\u00e9\u00e9 ci-dessus\ny_pre = dectree_basic.predict(x_basic_te)\n# Validation de l'algorithme \u00e0 l'aide de diverses m\u00e9triques de performances\n\na2 = accuracy_score(y_te,y_pre)\nf2 = f1_score(y_te, y_pre, average=\"macro\")\np2 = precision_score(y_te, y_pre, average=\"macro\")\nr2 = recall_score(y_te, y_pre, average=\"macro\")\nprint(\"accuracy score : \",a2)\nprint(\"f1 score : \",f2)\nprint(\"precision score : \",p2)\nprint(\"recall score : \",r2)\n\n# Calcul de la matrice de confusion pour l'algorithme ci-dessus\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"],\n                      title='Confusion matrix,Decision Tree Algorithm')\n\nplt.show()","f5c2276b":"# Couronnement des fonctionnalit\u00e9s CLAGE (valeurs> = 600 \u00e0 600), VALUE (valeurs> = 400000 \u00e0 400000), MORTDUE (valeurs> = 300000 \u00e0 300000) et DEBTINC (valeurs> = 100 \u00e0 100)\ndf.loc[df[\"CLAGE\"]>=600,\"CLAGE\"] = 600\ndf.loc[df[\"VALUE\"]>=400000,\"VALUE\"] = 400000\ndf.loc[df[\"MORTDUE\"]>=300000,\"MORTDUE\"] = 300000\ndf.loc[df[\"DEBTINC\"]>=100,\"DEBTINC\"] = 100","5b1a3ebb":"# Cr\u00e9ation de nouvelles variables binaires B_DEROG, B_DELINQ \u00e0 partir de DEROG, DELINQ\n\ndf[\"B_DEROG\"] = (df[\"DEROG\"]>=1)*1\ndf[\"B_DELINQ\"] = (df[\"DELINQ\"]>=1)*1","1b90be17":"df[\"JOB\"].unique()","3723e2bb":"# Nous devons convertir les caract\u00e9ristiques nominales JOB et RAISON en une forme utilisable et les supprimer de la table de donn\u00e9es\ndf[\"REASON_1\"] = (df[\"REASON\"] == \"HomeImp\")*1\ndf[\"REASON_2\"] = (df[\"REASON\"] != \"HomeImp\")*1\ndf[\"JOB_1\"] = (df[\"JOB\"]==\"Other\")*1\ndf[\"JOB_2\"] = (df[\"JOB\"]==\"Office\")*1\ndf[\"JOB_3\"] = (df[\"JOB\"]==\"Sales\")*1\ndf[\"JOB_4\"] = (df[\"JOB\"]==\"Mgr\")*1\ndf[\"JOB_5\"] = (df[\"JOB\"]==\"ProfExe\")*1\ndf[\"JOB_6\"] = (df[\"JOB\"]==\"Self\")*1\ndf.drop([\"JOB\",\"REASON\"],axis = 1,inplace = True)\n\n# L'affectation ci-dessus cr\u00e9e de nouvelles fonctionnalit\u00e9s pour chaque JOB et chaque RAISON","cefde35d":"# Nous devons diminuer l'asym\u00e9trie de la fonctionnalit\u00e9 YOU, pour cela nous pouvons appliquer le log de YOU mais comme certains d'entre eux sont 0, nous utiliserons log (constante YOJ)\ndf[\"YOJ\"] = df[\"YOJ\"].apply(lambda t : np.log(t+1))","95356c6e":"df.head()","f25454e8":"# Recherche de corr\u00e9lation entre toutes les fonctionnalit\u00e9s et la fonctionnalit\u00e9 cible \"BAD\"\n\ndf.corr(method='pearson')","d631da55":"# Rassembler les 2 ensembles de fonctionnalit\u00e9s avec une valeur de corr\u00e9lation \u00e9lev\u00e9e, une avec 7 et l'autre avec 10 fonctionnalit\u00e9s\n\nfeat1=[\"DEROG\",\"DELINQ\",\"CLAGE\",\"NINQ\",\"DEBTINC\",\"YOJ\",\"LOAN\"]\n#feat2=[\"DEROG\",\"DELINQ\",\"CLAGE\",\"NINQ\",\"DEBTINC\",\"LOAN\",\"JOB_2\",\"YOJ\",\"JOB_3\",\"MORTDUE\"]","bafba770":"# R\u00e9gression logistique \u00e0 l'aide de l'ensemble de fonctionnalit\u00e9s 1 ci-dessus\n\nx = df[feat1]\ny = df[\"BAD\"]\nx_tr,x_te,y_tr,y_te = train_test_split(x,y,test_size = 0.33,random_state=1)\nlogreg = LogisticRegression()\nlogreg.fit(x_tr,y_tr)\ny_pre = logreg.predict(x_te)\na3 = accuracy_score(y_te,y_pre)\nf3 = f1_score(y_te, y_pre, average=\"macro\")\np3 = precision_score(y_te, y_pre, average=\"macro\")\nr3 = recall_score(y_te, y_pre, average=\"macro\")\nprint(\"accuracy score : \",a3)\nprint(\"f1 score : \",f3)\nprint(\"precision score : \",p3)\nprint(\"recall score : \",r3)\n\n# Calcul de la matrice de confusion pour l'algorithme ci-dessus\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n\n# Tracer une matrice de confusion non normalis\u00e9e\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"],\ntitle='Matrice de confusion - Algorithme de r\u00e9gression logistique avec Pearson corr_f')\n\nplt.show()","3d79be8a":"# Classificateur d'arbre de d\u00e9cision utilisant feat1\n\nclf_tree=DecisionTreeClassifier()\nclf_tree.max_depth = 100\nclf_tree.fit(x_tr,y_tr)\ny_pre = clf_tree.predict(x_te)\na4 = accuracy_score(y_te,y_pre)\nf4 = f1_score(y_te, y_pre, average=\"macro\")\np4 = precision_score(y_te, y_pre, average=\"macro\")\nr4 = recall_score(y_te, y_pre, average=\"macro\")\nprint(\"accuracy score : \",a4)\nprint(\"f1 score : \",f4)\nprint(\"precision score : \",p4)\nprint(\"recall score : \",r4)\nprint(\"\")\n# Calcul de la matrice de confusion pour l'algorithme ci-dessus\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n\n# Tracer une matrice de confusion non normalis\u00e9e\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"],\ntitle='Matrice de confusion - Algorithme d\\'arbre de d\u00e9cision utilisant Pearson corr_f')\n\nplt.show()","8dbc09e3":"# Trouver les 10 meilleures fonctionnalit\u00e9s \u00e0 l'aide du test chi2\n\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\ndf_new = pd.DataFrame(SelectKBest(chi2, k=10).fit_transform(df.drop([\"BAD\"],axis = 1),df[\"BAD\"]))","255d4038":"# dataframe contenant les fonctionnalit\u00e9s s\u00e9lectionn\u00e9es\n\ndf_new.head()","630a9d77":"# Ex\u00e9cution de l'algorithme de r\u00e9gression logistique en utilisant les fonctionnalit\u00e9s s\u00e9lectionn\u00e9es \u00e0 partir du test chi2\nx = df_new\ny = df[\"BAD\"]\nx_tr,x_te,y_tr,y_te = train_test_split(x,y,test_size = .33,random_state=1)\nlogreg = LogisticRegression()\nlogreg.fit(x_tr,y_tr)\ny_pre = logreg.predict(x_te)\ny_pre = logreg.predict(x_te)\na5 = accuracy_score(y_te,y_pre)\nf5 = f1_score(y_te, y_pre, average=\"macro\")\np5 = precision_score(y_te, y_pre, average=\"macro\")\nr5 = recall_score(y_te, y_pre, average=\"macro\")\nprint(\"accuracy score : \",a5)\nprint(\"f1 score : \",f5)\nprint(\"precision score : \",p5)\nprint(\"recall score : \",r5)\n\n# Calcul de la matrice de confusion pour l'algorithme ci-dessus\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n\n# Tracer une matrice de confusion non normalis\u00e9e\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"],\n title='Matrice de confusion - Algorithme de r\u00e9gression logistique avec test chi2')\n\nplt.show()\n","36f7c473":"# Classificateur d'arbre de d\u00e9cision utilisant les fonctionnalit\u00e9s du test chi2\n\nclf_tree=DecisionTreeClassifier()\nclf_tree.max_depth = 100\nclf_tree.fit(x_tr,y_tr)\ny_pre = clf_tree.predict(x_te)\na6 = accuracy_score(y_te,y_pre)\nf6 = f1_score(y_te, y_pre, average=\"macro\")\np6 = precision_score(y_te, y_pre, average=\"macro\")\nr6 = recall_score(y_te, y_pre, average=\"macro\")\nprint(\"accuracy score : \",a6)\nprint(\"f1 score : \",f6)\nprint(\"precision score : \",p6)\nprint(\"recall score : \",r6)\n# Calcul de la matrice de confusion pour l'algorithme ci-dessus\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n\n# Calcul de la matrice de confusion pour l'algorithme ci-dessus\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"],\ntitle='Matrice de confusion - Algorithme d\\'arbre de d\u00e9cision utilisant le test chi2 pour la s\u00e9lection des fonctionnalit\u00e9s')\n\nplt.show()","9f095d1f":"df.head()","6134d21d":"from sklearn.feature_selection import f_classif\n\ndf_new2 = pd.DataFrame(SelectKBest(f_classif, k=10).fit_transform(df.drop([\"BAD\"],axis=1),df[\"BAD\"]))\ndf_new2.head()","1a278320":"# Ex\u00e9cution de l'algorithme de r\u00e9gression logistique en utilisant les fonctionnalit\u00e9s s\u00e9lectionn\u00e9es dans le test f_classif\nx = df_new2\ny = df[\"BAD\"]\nx_tr,x_te,y_tr,y_te = train_test_split(x,y,test_size = .33,random_state=1)\nlogreg = LogisticRegression()\nlogreg.fit(x_tr,y_tr)\ny_pre = logreg.predict(x_te)\na7 = accuracy_score(y_te,y_pre)\nf7 = f1_score(y_te, y_pre, average=\"macro\")\np7 = precision_score(y_te, y_pre, average=\"macro\")\nr7 = recall_score(y_te, y_pre, average=\"macro\")\nprint(\"accuracy score : \",a7)\nprint(\"f1 score : \",f7)\nprint(\"precision score : \",p7)\nprint(\"recall score : \",r7)\n\n# Calcul de la matrice de confusion pour l'algorithme ci-dessus\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n\n# Tracer une matrice de confusion non normalis\u00e9e\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"],\ntitle='Confusion matrix - Logistic Regression Algorithm with f_classif')\n\nplt.show()","b515e1c4":"# Decision Tree classifier using features from f_classif test\n\nclf_tree=DecisionTreeClassifier()\nclf_tree.max_depth = 100\nclf_tree.fit(x_tr,y_tr)\ny_pre = clf_tree.predict(x_te)\na8 = accuracy_score(y_te,y_pre)\nf8 = f1_score(y_te, y_pre, average=\"macro\")\np8 = precision_score(y_te, y_pre, average=\"macro\")\nr8 = recall_score(y_te, y_pre, average=\"macro\")\nprint(\"accuracy score : \",a8)\nprint(\"f1 score : \",f8)\nprint(\"precision score : \",p8)\nprint(\"recall score : \",r8)\n# Calcul de la matrice de confusion pour l'algorithme ci-dessus\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n\n# Tracer une matrice de confusion non normalis\u00e9e\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"],\n                      title='Confusion matrix - Decision Tree Algorithm using f_classif feature selector')\n\nplt.show()","62ed379c":"from sklearn import tree\nimport graphviz \ndot_dat = tree.export_graphviz(clf_tree, out_file=None) \ngraph = graphviz.Source(dot_dat) \ngraph","f19872ee":"from sklearn.feature_selection import f_regression\n\ndf_new3 = pd.DataFrame(SelectKBest(f_regression, k=10).fit_transform(df.drop([\"BAD\"],axis=1),df[\"BAD\"]))\ndf_new3.head()","a7331624":"# Ex\u00e9cution de l'algorithme de r\u00e9gression logistique en utilisant les fonctionnalit\u00e9s s\u00e9lectionn\u00e9es dans le test de f_regression\n\nx = df_new3\ny = df[\"BAD\"]\nx_tr,x_te,y_tr,y_te = train_test_split(x,y,test_size = .33,random_state=1)\nlogreg = LogisticRegression()\nlogreg.fit(x_tr,y_tr)\ny_pre2 = logreg.predict(x_te)\na9 = accuracy_score(y_te,y_pre2)\nf9 = f1_score(y_te, y_pre2, average=\"macro\")\np9 = precision_score(y_te, y_pre2, average=\"macro\")\nr9 = recall_score(y_te, y_pre2, average=\"macro\")\nprint(\"accuracy score : \",a9)\nprint(\"f1 score : \",f9)\nprint(\"precision score : \",p9)\nprint(\"recall score : \",r9)\n\n# Calcul de la matrice de confusion pour l'algorithme ci-dessus\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"],\n                      title='Matrice de confusion - Algorithme de r\u00e9gression logistique avec f_regression')\n\nplt.show()","6b69a314":"# Classificateur d'arbre de d\u00e9cision utilisant les fonctionnalit\u00e9s du test f_regression\n\nclf_tree=DecisionTreeClassifier()\nclf_tree.max_depth = 100\nclf_tree.fit(x_tr,y_tr)\ny_pre = clf_tree.predict(x_te)\na10 = accuracy_score(y_te,y_pre)\nf10 = f1_score(y_te, y_pre, average=\"macro\")\np10= precision_score(y_te, y_pre, average=\"macro\")\nr10 = recall_score(y_te, y_pre, average=\"macro\")\nprint(\"accuracy score : \",a10)\nprint(\"f1 score : \",f10)\nprint(\"precision score : \",p10)\nprint(\"recall score : \",r10)\n\n# Computing Confusion matrix for the above algorithm\n\ncnf_matrix = confusion_matrix(y_te, y_pre)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"], \n                      title='Confusion matrix - Decision Tree Algorithm using f_regression feature selector')\n\nplt.show()","2cdbc181":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Decision Tree','Logistic Regression', 'Decision Tree','Logistic Regression', 'Decision Tree','Logistic Regression', 'Decision Tree','Logistic Regression', 'Decision Tree'],\n    'Feature Selection Method' : ['None','None','Pearson corr_fact','Pearson corr_fact','chi2 test','chi2 test','f_classif','f_classif','f_regression','f_regression'],\n    'Accuracy Score': [a1,a2,a3,a4,a5,a6,a7,a8,a9,a10],\n    'Recall Score' : [r1,r2,r3,r4,r5,r6,r7,r8,r9,r10],\n    'F1 Score' : [f1,f2,f3,f4,f5,f6,f7,f8,f9,f10],\n    'Precision Score' : [p1,p2,p3,p4,p5,p6,p7,p8,p9,p10]\n})","34446329":"models","485839cb":"pd.pivot_table(models,index = [\"Feature Selection Method\",\"Model\"])","a4af0364":"lr = LogisticRegression()\nlr.fit(x_tr,y_tr)\ny_pred_proba = lr.predict_proba(x_te)\n\nthresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n\nplt.figure(figsize=(10,10))\n\nj = 1\nfor i in thresholds:\n    y_test_predictions_high_recall = y_pred_proba[:,1] >= i\n    \n    plt.subplot(3,3,j)\n    j += 1\n    \n    # Compute confusion matrix\n    cnf_matrix = confusion_matrix(y_te,y_test_predictions_high_recall)\n    np.set_printoptions(precision=2)\n    rec1 = recall_score(y_te, y_test_predictions_high_recall)\n    acc= 1.0*(cnf_matrix[0,0]+cnf_matrix[1,1])\/(cnf_matrix[0,0]+cnf_matrix[1,0]+cnf_matrix[1,1]+cnf_matrix[0,1])\n    print(\"Recall metric in the testing dataset: \",rec1)\n    print(\"Accuracy score for the testing dataset: \",acc)\n    # Plot non-normalized confusion matrix\n    class_names = [0,1]\n    plot_confusion_matrix(cnf_matrix\n                          , classes=class_names\n                          , title='Threshold >= %s'%i)\n    print(\"\")","07147cdf":"# obtenir la longueur et les indices de la classe minoritaire.\ndefault_len = len(df[df[\"BAD\"]==1])\ndefault_indices = np.array(df[df[\"BAD\"]==1].index)\n\n# s\u00e9lectionner le m\u00eame nombre d'\u00e9l\u00e9ments de la classe majoritaire au hasard.\ngood_indices = np.array(df[df[\"BAD\"]==0].index)\nrand_good_indices = np.random.choice(good_indices, default_len, replace = False)\nrand_good_indices = np.array(rand_good_indices)\n\n# combing the indices\ncombined_indices = np.concatenate([rand_good_indices,default_indices])\n\n# getting the corresponding dataset with above indices.\ncomb_df = df.iloc[combined_indices,:]\ncomb_y = comb_df[\"BAD\"]","1b56a8ce":"# en utilisant la m\u00e9thode de s\u00e9lection de fonctionnalit\u00e9s f_classif qui a produit de bons r\u00e9sultats dans les cas ci-dessus\n\nfrom sklearn.feature_selection import f_classif\n\ncomb_x = pd.DataFrame(SelectKBest(f_classif, k=10).fit_transform(comb_df.drop([\"BAD\"],axis=1),comb_df[\"BAD\"]))\ncomb_x.head()","1403c31b":"# fractionnement des donn\u00e9es en ensembles de donn\u00e9es de train et de test\n\nx_trc,x_tec,y_trc,y_tec = train_test_split(comb_x,comb_y,test_size =.33,random_state=1000)","c5c1a2cc":"# utiliser les scores Kfold pour entra\u00eener les donn\u00e9es car tr\u00e8s peu de donn\u00e9es sont disponibles\n\nfrom sklearn.cross_validation import KFold, cross_val_score\n\nlr = LogisticRegression()\n\ndef printing_Kfold_scores(x_trc,y_trc):\n    fold = KFold(len(y_trc),4,shuffle=False) \n    for train,test in fold :  \n        x1 = x_trc.iloc[train,:]\n        y1 = y_trc.iloc[train]\n        x2 = x_trc.iloc[test,:]\n        y2 = y_trc.iloc[test]\n        lr.fit(x1,y1)\n        y_pred_undersample = lr.predict(x2)\n        recall_acc = recall_score(y2,y_pred_undersample)\n        print(recall_acc)  \n        \nprinting_Kfold_scores(x_trc,y_trc)\n\ny_predr = lr.predict(x_tec)\n\nprint(\"\")\nprint('Accuracy Score = ',accuracy_score(y_tec,y_predr))\nprint('F1 Score = ',f1_score(y_tec, y_predr, average=\"macro\"))\nprint('Precision Score = ',precision_score(y_tec, y_predr, average=\"macro\"))\nprint('Recall Score = ',recall_score(y_tec, y_predr, average=\"macro\"))\nprint(\"\")\ncnf_matrix = confusion_matrix(y_tec, y_predr)\nnp.set_printoptions(precision=2)\n\n# Tracer une matrice de confusion non normalis\u00e9e\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"], \n                      title='Confusion matrix - Logistic Regression Algorithm after Resampling the data')\n\nplt.show()","1d8fa84a":"lr = DecisionTreeClassifier()\n\ndef printing_Kfold_scores(x_trc,y_trc):\n    \n    print(\"# Tracer une matrice de confusion non normalis\u00e9e\")\n    fold = KFold(len(y_trc),4,shuffle=False) \n    for train,test in fold :  \n        x1 = x_trc.iloc[train,:]\n        y1 = y_trc.iloc[train]\n        x2 = x_trc.iloc[test,:]\n        y2 = y_trc.iloc[test]\n        lr.fit(x1,y1)\n        y_pred_undersample = lr.predict(x2)\n        recall_acc = recall_score(y2,y_pred_undersample)\n        print(recall_acc)\n        \nprinting_Kfold_scores(x_trc,y_trc)\n\ny_predr = lr.predict(x_tec)\nprint(\"\")\nprint('Accuracy Score = ',accuracy_score(y_tec,y_predr))\nprint('F1 Score = ',f1_score(y_tec, y_predr, average=\"macro\"))\nprint('Precision Score = ',precision_score(y_tec, y_predr, average=\"macro\"))\nprint('Recall Score = ',recall_score(y_tec, y_predr, average=\"macro\"))\nprint(\"\")\n\ncnf_matrix = confusion_matrix(y_tec, y_predr)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[\"BAD\"], \n                      title='Confusion matrix - Decision Tree Algorithm after Resampling the data')\n\nplt.show()","96439073":"# Transformation des fonctionnalit\u00e9s ","a8f21005":"#### Import des du fichiers dans deux dataFrames differents","1e15763a":"- Comme mentionn\u00e9 pr\u00e9c\u00e9demment, nous pouvons utiliser le r\u00e9\u00e9chantillonnage pour am\u00e9liorer les performances des algorithmes d'apprentissage.\n- Dans cette m\u00e9thode, nous allons diviser les donn\u00e9es pour obtenir le rapport de classe cible 1: 1.\n- Il s'agit essentiellement d'une m\u00e9thode qui traitera les donn\u00e9es pour avoir un rapport d'environ 50-50.\n- Il existe 2 processus pour ce faire, sous-\u00e9chantillonnage et sur-\u00e9chantillonnage. Ici, nous allons utiliser UNDER-SAMPLING.","424dbd53":"## Utilisation de f_classif pour la s\u00e9lection des fonctionnalit\u00e9s","97abb5be":"#### Using decision tree with f_classif feature selector would give the best results!!","8e97af8d":"### Utilisation du test chi2 pour la s\u00e9lection des fonctionnalit\u00e9s","2564d7d1":"# Pour visualiser l'arbre de d\u00e9cision cr\u00e9\u00e9 -","e7b9fa11":"## Distributions de diverses variables","03c04db2":"#### Conclusion :\n- Comme vous pouvez le voir, Recall a AUGMENT\u00c9 d'environ 5 \u00e0 7% en cas de r\u00e9gression logistique en r\u00e9\u00e9chantillonnant les donn\u00e9es. C'est une \u00e9norme r\u00e9ussite !!\n<br>\n- En cas d'algorithme d'arbre de d\u00e9cision, le rappel est plus ou moins le m\u00eame.","848a9b9e":"Utilisation de f_regression pour la s\u00e9lection des fonctionnalit\u00e9s","010c2f22":"# Application des mod\u00e8les sur les donn\u00e9es apr\u00e8s imputation\n- Application de la classification de base aux donn\u00e9es apr\u00e8s remplacement \/ imputation. V\u00e9rifions la performance en appliquant \u00e0 la fois les algorithmes de r\u00e9gression logistique et d'arbre de d\u00e9cision.\n- Avant d'appliquer les algorithmes, les donn\u00e9es sont divis\u00e9es en ensembles d'apprentissage et de test dans le rapport 2: 1, soit 33% des donn\u00e9es de test et 67% des donn\u00e9es de train.\n- Et aussi en prenant toutes les colonnes sauf JOB, RAISON comme caract\u00e9ristiques d'entr\u00e9e (comme ce sont des caract\u00e9ristiques nominales, elles doivent \u00eatre transform\u00e9es en d'autres variables pour \u00eatre utilisables, ce qui est pris en compte dans la section suivante).","86ed4100":" distribution de la variable cible \"BAD\"\n# La classe cible est un peu d\u00e9s\u00e9quilibr\u00e9e - les z\u00e9ros sont d'environ 80% et les uns sont d'environ 20%","07be46f6":"### Conclusions: - Les distributions sont correctes et il n'y a pas d'anomalies dans les donn\u00e9es. <br> - DEBTINC a un nombre tr\u00e8s \u00e9lev\u00e9 de donn\u00e9es manquantes (sera trait\u00e9 dans la section suivante - Imputation des variables). <br> - La fonction YOJ est fortement biais\u00e9e et peut \u00eatre modifi\u00e9e pour r\u00e9duire l'asym\u00e9trie. <br> - Caract\u00e9ristiques nominales: JOB et REASON doivent \u00eatre modifi\u00e9s de mani\u00e8re \u00e0 pouvoir les utiliser pour le mod\u00e8le de r\u00e9gression logistique. <br> - DELINQ, DEROG peut \u00eatre divis\u00e9 en 2 classes pour cr\u00e9er de nouvelles variables binaires. <br> - VALUE, MORTDUE, CLAGE, DEBTINC peuvent \u00eatre plafonn\u00e9s \u00e0 la fin, c'est-\u00e0-dire que les valeurs tr\u00e8s \u00e9lev\u00e9es seront r\u00e9gl\u00e9es sur une valeur inf\u00e9rieure s\u00e9lectionn\u00e9e. -------------------------------------------------- -------------------------------------------------- ---------------------------","85885409":"# Discussion et id\u00e9es:\n- La r\u00e9gression logistique a produit des r\u00e9sultats avec une bonne pr\u00e9cision mais les performances globales ne sont pas tr\u00e8s bonnes.\n<br>\n- L'arbre de d\u00e9cision a domin\u00e9 la r\u00e9gression logistique dans tous les cas.\n<br>\n- Comme mentionn\u00e9 pr\u00e9c\u00e9demment, les performances de l'arbre de d\u00e9cision sont rest\u00e9es presque les m\u00eames depuis le d\u00e9but car il s\u00e9lectionne les fonctionnalit\u00e9s de mani\u00e8re h\u00e9r\u00e9ditaire.Les performances de la r\u00e9gression logistique se sont \u00e9galement am\u00e9lior\u00e9es apr\u00e8s le processus de s\u00e9lection des fonctionnalit\u00e9s.\n<br>\n- Enfin, le mod\u00e8le d'arbre de d\u00e9cision avec le s\u00e9lecteur de fonctionnalit\u00e9s f_classf serait la meilleure m\u00e9thode \u00e0 utiliser car il a la valeur RECALL la plus \u00e9lev\u00e9e\n<br>\n- La profondeur maximale de l'arbre de d\u00e9cision est fix\u00e9e \u00e0 100 dans tous les cas, donc le nombre de niveaux est de 101 dans tous les cas. Et puisque nous n'avons pas fix\u00e9 le nombre minimum d'observations dans la feuille sera de 1 car il s'agit d'un probl\u00e8me de classification.\n<br>\n- Le seuil est d\u00e9fini par d\u00e9faut sur 0,5 dans la r\u00e9gression logistique!\n<br>\n- \u00c9videmment, la modification du seuil affecte les performances du mod\u00e8le et cela peut \u00eatre observ\u00e9 dans la section suivante.\n<br>\n- Cela peut \u00eatre encore \u00e9tendu en r\u00e9\u00e9chantillonnant les donn\u00e9es pour augmenter le score RECALL","691215c4":"# Modification du seuil et observation des performances:","48c6e77f":"### Pratique, explication du code et r\u00e9sultats","b5547b17":"## Maintenant que nous avons les fonctionnalit\u00e9s avec une forte corr\u00e9lation avec la fonctionnalit\u00e9 BAD, nous allons ex\u00e9cuter les algorithmes de classification et les comparer","932af37d":"#### Quelques discussions sur les mesures de performance:\n- G\u00e9n\u00e9ralement, le test de pr\u00e9cision peut \u00eatre utilis\u00e9 pour \u00e9valuer les algorithmes. Mais dans ce cas, le simple fait d'utiliser la CLASSE DE MAJORIT\u00c9 (0) pour pr\u00e9dire la sortie donnera une pr\u00e9cision \u00e9lev\u00e9e (79,2%).\n<br>\n- Par cons\u00e9quent, d'autres mesures de performance doivent \u00eatre utilis\u00e9es pour \u00e9valuer le mod\u00e8le.\n    - Score F1: moyenne pond\u00e9r\u00e9e de rappel et de pr\u00e9cision\n    - Rappel: (TP \/ TP + FN)\n    - Pr\u00e9cision: (TP \/ TP + FP)\n      TP est vrai positif, FN est faux n\u00e9gatif, FP est faux positif\n<br>\n- Ici, nous voulons diminuer le nombre de faux n\u00e9gatifs, c'est-\u00e0-dire que nous pr\u00e9voyons que le cr\u00e9dit sera rembours\u00e9 mais qu'il s'agit en fait d'un fraudeur. Diminuer FN implique d'augmenter le rappel.Par cons\u00e9quent, RECALL sera la mesure de performance parfaite pour \u00e9valuer ce mod\u00e8le.\n<br>\n- La pr\u00e9cision peut diminuer dans le processus pour augmenter le rappel, mais il est normal de pr\u00e9dire quelques faux positifs suppl\u00e9mentaires.\n##### Nous pouvons \u00e9galement REMPLACER les donn\u00e9es (nous y reviendrons \u00e0 la fin).\n\n#### Conclusions:\n\n- En utilisant la r\u00e9gression logistique bien que la pr\u00e9cision soit bonne (79%), le mod\u00e8le n'a pas bien fonctionn\u00e9 sur les autres mesures de performance.Recal est juste au-dessus de 0,5 et ce n'est pas bon.Cela peut \u00eatre d\u00fb \u00e0 un surajustement et nous allons essayer de le supprimer dans la section suivante.\n<br>\n- \u00c9tonnamment, l'algorithme de l'arbre de d\u00e9cision a tr\u00e8s bien fonctionn\u00e9 par rapport \u00e0 la r\u00e9gression logistique avec un RAPPEL d'environ 0,78 et une tr\u00e8s bonne PR\u00c9CISION, car ce mod\u00e8le effectue implicitement une s\u00e9lection de variables \/ de fonctionnalit\u00e9s en divisant les n\u0153uds sup\u00e9rieurs en fonction des caract\u00e9ristiques les plus importantes du la s\u00e9lection des donn\u00e9es et des fonctionnalit\u00e9s se fait automatiquement.\n<br>\n- Enfin ce que je veux dire c'est:\n    - Il y aura une bonne am\u00e9lioration du mod\u00e8le de r\u00e9gression logistique apr\u00e8s la s\u00e9lection des fonctionnalit\u00e9s.\n    - Les r\u00e9sultats resteront presque les m\u00eames dans le cas du mod\u00e8le Arbre de d\u00e9cision, m\u00eame apr\u00e8s la s\u00e9lection des fonctionnalit\u00e9s.\n<br>\n- Nous allons prouver l'hypoth\u00e8se ci-dessus en cr\u00e9ant des mod\u00e8les avec des caract\u00e9ristiques s\u00e9lectionn\u00e9es et les comparer aux mod\u00e8les ci-dessus.","84690940":"- Au fur et \u00e0 mesure que nous avons termin\u00e9 la partie transformation, nous passons maintenant \u00e0 la s\u00e9lection des fonctionnalit\u00e9s. Nous allons maintenant d\u00e9couvrir les fonctionnalit\u00e9s d'importation les plus affectant la variable cible \"MAUVAIS\".\n- Nous utiliserons les \u00e9l\u00e9ments suivants \u00e0 cette fin:\n    - Facteur de corr\u00e9lation de Pearson Pearson\n    - test du chi carr\u00e9\n    - f_r\u00e9gression\n    - f_classif","a4411de3":"#### Objectif: cr\u00e9er un algorithme de notation du cr\u00e9dit qui pr\u00e9dit la probabilit\u00e9 qu'un demandeur de pr\u00eat soit en d\u00e9faut de remboursement.","0255968a":"# Imputation des variables d'entr\u00e9e\n<br>","79fb55c6":"# Comparaison de tous les mod\u00e8les\n - Nous pouvons maintenant classer notre \u00e9valuation de tous les mod\u00e8les pour choisir le meilleur pour notre probl\u00e8me.","a9aac911":"# # Comprendre les donn\u00e9es","648ce3b4":"#### Distribution de la variable de pr\u00eat\n#### la densit\u00e9 entre 10000-30000 est \u00e9lev\u00e9e","ba590f35":"* # S\u00e9lection de fonctionnalit\u00e9","3e561d0a":"#### Observations: - Sauf dans le cas de DEBTINC, dans tous les autres cas, seules quelques valeurs n'ont pas \u00e9t\u00e9 rapport\u00e9es - Pour imputer les valeurs manquantes, nous pouvons penser \u00e0 quelques id\u00e9es comme: - En cas de caract\u00e9ristiques nominales, les remplacer par la majorit\u00e9 classe - Dans le cas de variables num\u00e9riques comme DEROG et DELINQ, la plupart des cas sont 0. Nous pouvons les remplacer par la classe majoritaire. - Dans le cas d'autres entr\u00e9es num\u00e9riques, nous pouvons les remplacer par la m\u00e9diane ou la moyenne sans en modifier le plus. Dans ce cahier, je vais les remplacer par la colonne respective.","413762b3":"- Avant la s\u00e9lection des fonctionnalit\u00e9s, comme indiqu\u00e9 dans la section \"Distribution des diff\u00e9rentes fonctionnalit\u00e9s\", nous devons transformer certaines variables afin d'am\u00e9liorer la pr\u00e9visibilit\u00e9.\n- Nous avons transform\u00e9 l'ensemble de donn\u00e9es, pas seulement l'ensemble de formation.","335ea69e":"# Credit scoring model\n","92e399f1":"### Utilisation du facteur de corr\u00e9lation de Pearson pour la s\u00e9lection des fonctionnalit\u00e9s","52a3650a":"### Regard final sur les donn\u00e9es apr\u00e8s avoir rempli les valeurs manquantes","effab62a":"# Plus \u00e0 ce sujet: Utilisation du RESAMPLING pour augmenter la valeur de rappel","99c937a0":"#### Conclusion :\n- Les valeurs de rappel et de pr\u00e9cision varient en fonction du seuil s\u00e9lectionn\u00e9.\n- Sur la base de la pr\u00e9cision requise et des valeurs de rappel, il faut d\u00e9cider et s\u00e9lectionner un seuil.\n- Il est sugg\u00e9r\u00e9 de passer au seuil par d\u00e9faut qui est de 0,5 dans les cas g\u00e9n\u00e9raux.\n<br>\n-------------------------------------------------- -------------------------------------------------- --------------------------"}}