{"cell_type":{"946ab408":"code","a528dd5f":"code","6ba4821a":"code","bc4bd5b0":"code","3c413d7c":"code","1034689e":"code","4cd66c76":"code","d3a113e6":"code","52c39bf1":"code","7321e33e":"code","349dc59e":"code","e70a3cbe":"code","42cadffb":"code","f0bb243f":"code","851a2392":"code","6a36ed85":"code","e4680408":"code","e77e2cc2":"code","81fc50de":"code","ccdc9c5b":"code","e196f329":"code","01de220e":"code","219a74bd":"code","458f6f8e":"code","59f2007d":"code","c6b7e257":"code","46b5e870":"code","79e82864":"code","5cdd24f4":"code","4e47dbc1":"code","1b03df41":"code","c0ac98e8":"code","da6c7058":"code","ee649bdb":"code","0f36dbc2":"code","52ea442f":"code","1b28c09b":"code","6092cbbc":"code","383170dd":"code","649cfe96":"code","47ad64d0":"code","93f7a31f":"code","1022e71c":"code","5a0b7683":"code","3fd008fe":"code","041fde15":"code","38e26ede":"code","38fdef1c":"code","cc6fe51c":"code","4350dda9":"code","02d18670":"code","9673d513":"code","5c59d759":"code","53b17f09":"code","a8e2b00f":"code","9595412d":"code","c72ce2a6":"code","19e77c01":"code","726680c0":"code","44e48bcf":"code","8cbdf444":"code","56d2c307":"markdown","488df8ea":"markdown","2c815948":"markdown","78ab4228":"markdown","c37d06b0":"markdown","f41ed222":"markdown","cfafc8b4":"markdown"},"source":{"946ab408":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a528dd5f":"# Load and Read DataSets\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\", index_col='PassengerId')\n# Return the first n rows (n=5 (default))\ntrain_data.head()\n# # method for prints information about a DataFrame including the index dtype and columns, non-null values and memory usage\n# train_data.info()# rows = 891 , columns = 12","6ba4821a":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()\n\n#test_data.info()  #rows= 418 , columns=11","bc4bd5b0":"test_data.shape","3c413d7c":"# check shape of dataset\ntrain_data.shape","1034689e":"#name of columns\ntrain_data.columns","4cd66c76":"train_data.info()","d3a113e6":"# check imbalance data for target values\n# Survived no=0, yes=1\nsns.countplot(x='Survived', data=train_data)","52c39bf1":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","7321e33e":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","349dc59e":"train_data['Pclass'].value_counts()","e70a3cbe":"# pclass , Ticket class,  = 1st, 2 = 2nd, 3 = 3rd\n# show that large number of people unsurvival in pclass 3,   number of people in (pclass =3 )=491\n# in pclass=3, the probability of survival is low\nsns.countplot(x='Pclass', hue='Survived', data=train_data)","42cadffb":"sns.countplot(x='Sex', hue = 'Survived',data= train_data)","f0bb243f":"# column of age continous\nsns.boxplot(x=\"Survived\", y=\"Age\", data= train_data)","851a2392":"sns.boxplot(x=\"Pclass\", y=\"Age\", data= train_data)","6a36ed85":"#check correlation\nsns.pairplot(train_data, hue='Survived')","e4680408":"#create correlation\ncorr = train_data.corr()\ncorr[\"Survived\"].sort_values()","e77e2cc2":"sns.heatmap(corr,  annot = True)","81fc50de":"#to mask the repetitive value for each pair\n#convert correlation to numpy array\nmask = np.array(corr)\nmask[np.tril_indices_from(mask)] = False\nfig, ax = plt.subplots(figsize = (15,12))\nfig.set_size_inches(15,15)\nsns.heatmap(corr, mask = mask, vmax = 0.9, square = True, annot = True)","ccdc9c5b":"# from hist, intuition about how fill missing values\ntrain_data[['Survived', 'Pclass', 'Age', 'SibSp',\n       'Parch',  'Fare' ]].hist(figsize = (20,20))","e196f329":"# Handle categorical and numerical features\ncat_name_features = [col for col in train_data.columns if train_data[col].dtype == object ]\nnum_name_features = [col for col in train_data.columns if train_data[col].dtype != object]\ntotat_features = cat_name_features + num_name_features\n\nprint(f\"categorical Datat :{cat_name_features}\")\nprint(f\"Numerical Datat :{num_name_features}\")","01de220e":"train_data[num_name_features].describe()","219a74bd":"train_data[cat_name_features].describe()","458f6f8e":"#Looking out for missing values and handling them\ncheck_missing_values = train_data.isnull().sum()\n# drop column with no missing values and sort it descending\nmiss_values = check_missing_values[check_missing_values>0]\nmiss_values.sort_values(ascending=False).plot.bar()","59f2007d":"# from distribution , fill missing value in Age column by Median each pclass\n#train_data['Age'] = train_data['Age'].fillna(  train_data['Age'].median(), inplace=True)\n## function for fill\ndef median_age_class(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    if pd.isnull(Age): # if age is null, fill by meadian of pclass it belong to\n        condition= train_data['Pclass'] == Pclass\n        return int(train_data[condition]['Age'].median())\n    else:\n        return Age","c6b7e257":"train_data['Age'] = train_data[['Age', 'Pclass']].apply(median_age_class, axis=1)","46b5e870":"train_data['Embarked'].value_counts()","79e82864":"sns.countplot(x='Embarked', data=train_data)","5cdd24f4":"# fill most freq\n#titanic['Embarked'].fillna('S', inplace=True)\n#train_data['Embarked'] = train_data['Embarked'].fillna('S', inplace = True)\ntrain_data['Embarked'].fillna('S', inplace = True)","4e47dbc1":"train_data.isnull().sum()","1b03df41":"#check duplicated data\ntrain_data.duplicated().sum()","c0ac98e8":"#check outliers","da6c7058":"train_data.head()","ee649bdb":"encoded_train = pd.get_dummies(train_data, columns=[\"Embarked\", \"Sex\"] )\n \n","0f36dbc2":"encoded_train.head()","52ea442f":"encoded_train.columns","1b28c09b":"# drop Cabin, Name, Ticket\n#[\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\ny= encoded_train['Survived']\nx= encoded_train.drop(columns = ['Survived', 'Name', 'Cabin', 'Ticket', 'Fare'], axis=1)","6092cbbc":"x.shape","383170dd":"x.columns","649cfe96":"# drop features like Id, Name","47ad64d0":"# from sklearn.ensemble import RandomForestClassifier\n\n# y = train_data[\"Survived\"]\n\n# features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]   \n# X = pd.get_dummies(train_data[features]) #Work with Categorical Data\n# X_test = pd.get_dummies(test_data[features])\n\n# model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n# model.fit(X, y)\n# predictions = model.predict(X_test)\n\n# output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n# output.to_csv('my_submission.csv', index=False)\n# print(\"Your submission was successfully saved!\")","93f7a31f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","1022e71c":"#model = RandomForestClassifier(n_estimators=100 , random_state=1)","5a0b7683":"# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)\n","3fd008fe":"# model.fit(X_train,y_train)\n# train_predictions = model.predict(X_train)\n# test_predictions = model.predict(X_test)","041fde15":"# print(accuracy_score(y_train, train_predictions))\n# print(accuracy_score(y_test, test_predictions))","38e26ede":"# confusion_matrix(y_test, test_predictions)","38fdef1c":"import sklearn.pipeline as pip\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.feature_selection import SelectKBest, chi2\nfrom catboost import CatBoostClassifier\n","cc6fe51c":"\n# pipeline_xgb =pip.Pipeline(steps=[('feature_select', SelectKBest(chi2 , k = 'all')),\n#                                   ('classifier',XGBClassifier(learning_rate=0.01 ,\n#                                                               n_estimators=700,\n#                                                               max_depth=3,\n#                                                               subsample=1,\n#                                                               colsample_bytree=1,\n#                                                               gamma=6,\n#                                                               reg_alpha = 14,\n#                                                               reg_lambda = 3))\n#                                   ])\n# #--------------------------\n# pipeline_log =pip.Pipeline(steps=[('feature_select',SelectKBest(chi2, k = 'all' )),\n#                                   ('classifier',LogisticRegression(penalty = 'l2',\n#                                                                    solver = 'liblinear',\n#                                                                    C = 0.25))\n#                                   ])\n# model = VotingClassifier(estimators=[('XGB', pipeline_xgb),('log', pipeline_log)])\n ","4350dda9":"# from sklearn.model_selection import GridSearchCV\n# pipe=pip.Pipeline([('select',SelectKBest(k='all')), \n#                ('classify', RandomForestClassifier(random_state = 10, max_features = 'sqrt'))])\n# param_test = {\n#               'classifier__C':[0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6]\n#              }\n\n# param_test_xgb = {\n# #                'classifier__max_depth':list(range(2,12,1)) \n# #     'classifier__n_estimators':list(range(100,500,50)) \n    \n#                'classifier__colsample_bytree':[0.8,0.9,1] \n# #                'classifier__colsample_bytree':list(range(1,5,1)) ,\n# #                'classifier__gamma':list(range(3,9,1)) ,\n#              } \n# model = GridSearchCV(estimator = pipeline_xgb, param_grid = param_test_xgb, scoring='accuracy', cv=5, verbose=10)\n ","02d18670":"weights = {0:1.0, 1:2.0}\nlog = LogisticRegression(penalty = 'l2',solver = 'liblinear', C = 0.25, class_weight=weights)\nrandom_forest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n \n    \n \n# xgb = XGBClassifier(learning_rate=0.01 ,\n#                                                               n_estimators=860,\n#                                                               max_depth=3,\n#                                                               subsample=1,\n#                                                               colsample_bytree=1,\n#                                                               gamma=6,\n#                                                               reg_alpha = 14,\n#                                                               reg_lambda = 3)\nmodel= VotingClassifier(estimators=[('RFC',random_forest  ),('log', log)])\n ","9673d513":"### used cross validation rather than split\n\nmodel.fit(x, y)\naccuracy = cross_val_score(model, x, y, cv=10)","5c59d759":"print(accuracy.mean())\n","53b17f09":"test_data.shape","a8e2b00f":"encoded_test = pd.get_dummies(test_data, columns=[\"Embarked\", \"Sex\"] )","9595412d":"encoded_test.columns","c72ce2a6":"x_test= encoded_test.drop(columns = ['PassengerId', 'Name', 'Cabin', 'Ticket', 'Fare'], axis=1)","19e77c01":"x_test.columns","726680c0":"x_test.isnull().sum()","44e48bcf":"x_test['Age'] = x_test[['Age', 'Pclass']].apply(median_age_class, axis=1)","8cbdf444":"predictions = model.predict(x_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\n","56d2c307":"## **Random Forest Model**","488df8ea":"## **Explore a pattern**","2c815948":"## **Encoding the categorical features**","78ab4228":"## **Load the data**","c37d06b0":"## **Submission File Generation**","f41ed222":"## **Exploratory Data Analysis**","cfafc8b4":"## **Data Splitting & Model Training**"}}