{"cell_type":{"3a0c545b":"code","052e2435":"code","35a741ba":"code","ff2ee2fb":"code","d83bc0a8":"code","0ce39594":"code","1fecd728":"code","6e2766c6":"code","ecfa591f":"code","0923bd55":"markdown","274cd8a5":"markdown","2a9a4f9e":"markdown","0c20da5f":"markdown","869095b6":"markdown","b7db70ee":"markdown","708e2f56":"markdown"},"source":{"3a0c545b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","052e2435":"\nimport os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n\ntrain_dir = '\/kaggle\/input\/cityscapes-image-pairs\/cityscapes_data\/cityscapes_data\/train'\ntest_dir = '\/kaggle\/input\/cityscapes-image-pairs\/cityscapes_data\/cityscapes_data\/val' \n\ndef dirs_to_tensors(directory, iterations,  iteration = 0 ):\n    '''\n    This function converts images \n    from directory into two tensors: images and masks \n    every iterartion by batch \n    Arguments:\n        directory(str):base directory with images\n        iterations(int): number of iterations\n        iteration(int): current iteration\n    Returns:\n        Two tensors\n    '''\n    filenames = os.listdir(directory)\n    size = int(len(filenames) \/ iterations)\n    start = size * iteration\n    end = size * (iteration + 1)\n    print(f'start: {start}; end: {end};')\n    filebatch = filenames[start : end]\n    base_dirs = [directory + '\/' + filename for filename in filebatch]\n    instant_img =   cv2.imread(base_dirs[0])\n    # images is squared thus width == height = image_size\n    image_size = int(instant_img.shape[1] \/ 2)\n    imgs_numb = len(base_dirs)\n    channels = 3\n    # zero-values tensors shape\n    shape = (imgs_numb, image_size, image_size, channels)\n    # zero-values tensors\n    images = np.zeros(shape = shape)\n    masks = np.zeros(shape = shape)\n\n    for index, filename in enumerate(base_dirs):\n        # get source img\n        current_img = cv2.imread(filename)\n        current_img = cv2.cvtColor(current_img, cv2.COLOR_BGR2RGB)\n        # separate image and mask\n        image = current_img[:, :256]\n        mask = current_img[:, 256:]\n\n        # put images into tensors\n        images[index] = image\n        masks[index] = mask\n\n    return images, masks","35a741ba":"def plot_pixels(data, title, colors = None, N = 100000):\n    if colors is None:\n        colors = data\n    \n    rng = np.random.RandomState(0)\n    i = rng.permutation(data.shape[0])[:N]\n    colors = colors[i]\n    pixel = data[i].T\n\n    R, G, B = pixel[0], pixel[1], pixel[2]\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = plt.axes(projection='3d', xlabel = 'Red', zlabel = 'Blue', ylabel = 'Green', )\n    ax.scatter3D( R, G, B, c=colors, )\n\n    fig.suptitle(title, size=20)\n\n    \nimages, masks = dirs_to_tensors(train_dir, \n                                iteration=0, \n                                iterations = 25)\n\nimg_data = np.array([masks[i].reshape(-1, 3) for i in range(100)]) \/ 255\nimg_data = np.concatenate(img_data).astype(np.float32)\n\nplot_pixels(img_data, title='all colors in mask')","ff2ee2fb":"criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\nflags = cv2.KMEANS_RANDOM_CENTERS\nimg_data = img_data.astype(np.float32)\ncampactness, labels, centers = cv2.kmeans(img_data, 16, None, criteria, 10,flags)\nnew_colors = centers[labels].reshape((-1, 3))\nplot_pixels(img_data, colors = new_colors, title = \"Reduced color space: 16 colors\")","d83bc0a8":"i = 100\nreduced_img = array_to_img(np.array(np.split(new_colors, i)).reshape((i, 256, 256, 3))[i - 1])\nimg = array_to_img(masks[i - 1])\nplt.figure(figsize=(10, 16))\nplt.subplot(1, 3, 1)\nplt.title('image')\nplt.axis('off')\nplt.imshow(array_to_img(images[i - 1]))\nplt.subplot(1, 3, 2)\nplt.title('reduced color')\nplt.axis('off')\nplt.imshow(reduced_img)\nplt.subplot(1, 3, 3)\nplt.title('full colors')\nplt.axis('off')\nplt.imshow(img)","0ce39594":"import tensorflow\nimport numpy as np\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import Input, Reshape, concatenate\nfrom tensorflow.keras.layers import UpSampling2D, BatchNormalization\nfrom tensorflow.keras.layers import Activation, LeakyReLU, Lambda, Convolution2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Flatten, Add, ReLU\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.applications import ResNet50V2\nimport tensorflow.keras.backend as K\n\nimages, masks = dirs_to_tensors(train_dir, \n                                iteration=0, \n                                iterations = 20)\n\nexam_img = images[1] \/ 255\nexam_mask = masks[1] \/ 255\n\n\ndef conv_block(X,filters,block):\n    # resiudal block with dilated convolutions\n    # add skip connection at last after doing convoluion operation to input X\n    \n    b = 'block_'+str(block)+'_'\n    f1,f2,f3 = filters\n    X_skip = X\n    # block_a\n    X = Convolution2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n                      padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n    X = BatchNormalization(name=b+'batch_norm_a')(X)\n    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n    # block_b\n    X = Convolution2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n                      padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n    X = BatchNormalization(name=b+'batch_norm_b')(X)\n    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n    # block_c\n    X = Convolution2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),\n                      padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n    X = BatchNormalization(name=b+'batch_norm_c')(X)\n    # skip_conv\n    X_skip = Convolution2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n    # block_c + skip_conv\n    X = Add(name=b+'add')([X,X_skip])\n    X = ReLU(name=b+'relu')(X)\n    return X\n    \ndef base_feature_maps(input_layer):\n    # base covolution module to get input image feature maps \n    \n    # block_1\n    base = conv_block(input_layer,[32,32,64],'1')\n    # block_2\n    base = conv_block(base,[64,64,128],'2')\n    # block_3\n    base = conv_block(base,[128,128,256],'3')\n    return base\n\ndef pyramid_feature_maps(input_layer):\n    # pyramid pooling module\n    \n    base = base_feature_maps(input_layer)\n    # red\n    red = GlobalAveragePooling2D(name='red_pool')(base)\n    red = tensorflow.keras.layers.Reshape((1,1,256))(red)\n    red = Conv2D(filters=64,kernel_size=(1,1),name='red_1_by_1')(red)\n    red = UpSampling2D(size=256,interpolation='bilinear',name='red_upsampling')(red)\n    # yellow\n    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n    yellow = Conv2D(filters=64,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n    # blue\n    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n    blue = Conv2D(filters=64,kernel_size=(1,1),name='blue_1_by_1')(blue)\n    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n    # green\n    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n    green = Convolution2D(filters=64,kernel_size=(1,1),name='green_1_by_1')(green)\n    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n    # base + red + yellow + blue + green\n    return concatenate([base,red,yellow,blue,green])\n\ndef last_conv_module(input_layer):\n    X = pyramid_feature_maps(input_layer)\n    X = Convolution2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n    X = Activation('sigmoid' ,name='last_conv_relu')(X)\n    # X = Flatten(name='last_conv_flatten')(X)\n    return X\n\ninput_layer = tensorflow.keras.Input(shape=np.squeeze(images[0]).shape,name='input')\noutput_layer = last_conv_module(input_layer)\nmodel = tensorflow.keras.Model(inputs=input_layer,outputs=output_layer)\n\noptimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.01)\nIoU = tensorflow.keras.metrics.MeanIoU(num_classes=30)\nmetrics = ['accuracy', IoU]\nmodel.compile(optimizer=optimizer,loss='mse', metrics = metrics)","1fecd728":"def train_model(model = model, iterations = 10):\n    '''\n    training model procces\n\n    Arguments:\n        model = current model\n        iterations(int): number of iterations\n    '''\n    from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n    import os\n    callbacks = [\n        ModelCheckpoint(filepath='\/PSPnet\/model_best_weights.h5'),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.0001)\n    ]\n    try:\n        os.mkdir('\/PSPnet')\n        os.mkdir('\/PSPnet\/progress')\n    except FileExistsError:\n        pass\n\n    history = []\n    epochs = 5\n    \n    for iteration in range(iterations):\n        print('-' * 20, f'iteration: {iteration}', '-' * 20 )\n        # model.load_weights('\/content\/drive\/MyDrive\/PSPnet\/model_best_weights.h5')\n\n        images, masks = dirs_to_tensors(train_dir, \n                                        iteration=iteration, \n                                        iterations = iterations)\n        test_images, test_masks = dirs_to_tensors(test_dir,\n                                                  iteration=iteration, \n                                                  iterations = iterations) \n        \n        images, masks = images \/ 255, masks \/ 255 \n        test_images, test_masks = test_images \/ 255, test_masks \/ 255\n\n        \n\n        cur_history = model.fit(\n                images, \n                masks,\n                validation_data = (test_images, test_masks),\n                epochs=epochs,\n                verbose=1,\n                batch_size=10,\n                callbacks = callbacks, )\n        \n\n        history.append(cur_history.history)\n\n        model.load_weights('\/PSPnet\/model_best_weights.h5')    \n        \n        pred_mask = model.predict(exam_img.reshape(1, 256, 256, 3)).reshape(256,256, 3) * 255\n        cv2.imwrite(f'\/PSPnet\/progress\/iteration_{iteration}.jpg', pred_mask, )\n\ntrain_model()","6e2766c6":"def show_predictions(pred_number):\n    model.load_weights('\/PSPnet\/model_best_weights.h5')\n    # pred_mask = cv2.cvtColor(pred_mask, cv2.COLOR_BGR2RGB)\n    for i in range(pred_number):\n        pred_mask = model.predict((images[i * 4] \/ 255).reshape(1, 256, 256, 3)).reshape(256,256, 3) * 255\n        mask = array_to_img(masks[i * 4])\n        img = images[i *4] \n        title = '{1}predicted mask{0}ground truth{0}original image{0}instance segmentation'.format(' ' * 17, ' '* 10)\n        instance_seg = array_to_img(img + pred_mask) \n        result = np.hstack([pred_mask, mask,img, instance_seg]) \/ 255\n        plt.figure(figsize=(30, 20))\n        plt.subplot(pred_number, 1, i + 1)\n        plt.axis('off')\n        plt.title(title)\n        plt.imshow(result)\n    plt.savefig('figure.png')\n\nshow_predictions(5)","ecfa591f":"def show_progress(pred_number):\n    import os, cv2\n    import numpy as np\n    from tensorflow.keras.preprocessing.image import array_to_img\n    pred_dir = '\/PSPnet\/progress'\n    prediction_names = [pred_dir + '\/' + filename  for filename in os.listdir(pred_dir)]\n    mask = array_to_img(masks[1])\n    img = images[1]\n    \n    for i in range(len(prediction_names)):\n        pred_mask = cv2.imread(prediction_names[1], )\n        title = 'iteration: ' + str(i + 1) \n        instance_seg = array_to_img(img + pred_mask) \n        result = np.hstack([pred_mask, mask,img, instance_seg]) \/ 255\n        plt.figure(figsize=(40, 40))\n        plt.subplot(pred_number, 1, i + 1)\n        plt.axis('off')\n        plt.title(title)\n        plt.imshow(result)\n\nshow_progress(10)","0923bd55":"# Let's build the model","274cd8a5":"So it's expensive operation for looping","2a9a4f9e":"let's see all possible colors in masks","0c20da5f":"# Image Clustering ","869095b6":"# image preprocessing, generator function","b7db70ee":"![](https:\/\/hszhao.github.io\/projects\/pspnet\/figures\/pspnet.png)","708e2f56":"# Plot results"}}