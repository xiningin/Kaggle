{"cell_type":{"4e1c3118":"code","abd7290d":"code","6e03b6f4":"code","bf5d7a1f":"code","57a330e7":"code","0de7374c":"code","3608722b":"code","7dc231b1":"code","d787a5e5":"code","775d2259":"code","93e6562d":"code","6630514e":"code","b5beef56":"code","31d47d76":"code","fc4db18b":"code","eeca02a8":"code","3902f63b":"code","e0f46e20":"code","7b4171cc":"code","aee45d06":"code","2cc86943":"code","954084a3":"code","8ce6800b":"code","7dd44500":"code","bf590eb8":"markdown","d52803cd":"markdown","720a252e":"markdown","777d457c":"markdown","653fc7c8":"markdown","ffc24bc8":"markdown","f4c7d99b":"markdown","1bfb15e8":"markdown"},"source":{"4e1c3118":"import os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import datasets, transforms, models\nfrom torchvision.utils import make_grid,save_image\nimport cv2\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader, ConcatDataset\n%matplotlib inline","abd7290d":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","6e03b6f4":"#Hyperparameter\nbatch_size = 8\nimage_size = 64\nnormalization_stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\ndata_dir = r'..\/input\/pokemon-images-dataset\/pokemon'\nnormal_dataset = datasets.ImageFolder(data_dir, transform=transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.CenterCrop(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(*normalization_stats)]))\n\n# Augment the dataset with mirrored images\nmirror_dataset = datasets.ImageFolder(data_dir, transform=transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.CenterCrop(image_size),\n    transforms.RandomHorizontalFlip(p=1.0),\n    transforms.ToTensor(),\n    transforms.Normalize(*normalization_stats)]))\n\n# Augment the dataset with color changes\ncolor_jitter_dataset = datasets.ImageFolder(data_dir, transform=transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.CenterCrop(image_size),\n    transforms.ColorJitter(0.5, 0.5, 0.5),\n    transforms.ToTensor(),\n    transforms.Normalize(*normalization_stats)]))","bf5d7a1f":"data_loader = DataLoader(dataset=ConcatDataset([normal_dataset,mirror_dataset,color_jitter_dataset]), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=False)","57a330e7":"def denorm(image):\n    return image * normalization_stats[1][0] + normalization_stats[0][0]","0de7374c":"def show_images(images, nmax=64):\n    fig, ax = plt.subplots(figsize=(20, 20))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n    \ndef show_batch(dataloader, nmax=64):\n    for images, _ in dataloader:\n        show_images(images, nmax)\n        break","3608722b":"show_batch(data_loader)","7dc231b1":"discriminator = nn.Sequential(\n    # Input is 3 x 64 x 64\n    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2, inplace=True),\n    # Layer Output: 64 x 32 x 32\n    \n    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    # Layer Output: 128 x 16 x 16\n    \n    nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    # Layer Output: 128 x 8 x 8\n    \n    nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    # Layer Output: 128 x 4 x 4\n    \n    # With a 4x4, we can condense the channels into a 1 x 1 x 1 to produce output\n    nn.Conv2d(128, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    nn.Flatten(),\n    nn.Sigmoid()\n)\ndiscriminator.to(device)","d787a5e5":"seed_size = 16","775d2259":"generator = nn.Sequential(\n    # Input seed_size x 1 x 1\n    nn.ConvTranspose2d(seed_size, 128, kernel_size=4, padding=0, stride=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    # Layer output: 256 x 4 x 4\n    \n    nn.ConvTranspose2d(128, 128, kernel_size=4, padding=1, stride=2, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    # Layer output: 128 x 8 x 8\n    \n    nn.ConvTranspose2d(128, 128, kernel_size=4, padding=1, stride=2, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    # Layer output: 64 x 16 x 16\n    \n    nn.ConvTranspose2d(128, 64, kernel_size=4, padding=1, stride=2, bias=False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    # Layer output: 32 x 32 x 32\n    \n    nn.ConvTranspose2d(64, 3, kernel_size=4, padding=1, stride=2, bias=False),\n    nn.Tanh()\n    # Output: 3 x 64 x 64\n)\ngenerator.to(device)","93e6562d":"def train_discriminator(real_pokemon, disc_optimizer):\n    # Reset the gradients for the optimizer\n    disc_optimizer.zero_grad()\n    \n    # Train on the real images\n    real_predictions = discriminator(real_pokemon)\n    # real_targets = torch.zeros(real_pokemon.size(0), 1, device=device) # All of these are real, so the target is 0.\n    real_targets = torch.rand(real_pokemon.size(0), 1, device=device) * (0.1 - 0) + 0 # Add some noisy labels to make the discriminator think harder.\n    real_loss = F.binary_cross_entropy(real_predictions, real_targets) # Can do binary loss function because it is a binary classifier\n    real_score = torch.mean(real_predictions).item() # How well does the discriminator classify the real pokemon? (Higher score is better for the discriminator)\n    \n    # Make some latent tensors to seed the generator\n    latent_batch = torch.randn(batch_size, seed_size, 1, 1, device=device)\n    \n    # Get some fake pokemon\n    fake_pokemon = generator(latent_batch)\n    \n    # Train on the generator's current efforts to trick the discriminator\n    gen_predictions = discriminator(fake_pokemon)\n    # gen_targets = torch.ones(fake_pokemon.size(0), 1, device=device)\n    gen_targets = torch.rand(fake_pokemon.size(0), 1, device=device) * (1 - 0.9) + 0.9 # Add some noisy labels to make the discriminator think harder.\n    gen_loss = F.binary_cross_entropy(gen_predictions, gen_targets)\n    gen_score = torch.mean(gen_predictions).item() # How well did the discriminator classify the fake pokemon? (Lower score is better for the discriminator)\n    \n    # Update the discriminator weights\n    total_loss = real_loss + gen_loss\n    total_loss.backward()\n    disc_optimizer.step()\n    return total_loss.item(), real_score, gen_score","6630514e":"def train_generator(gen_optimizer):\n    # Clear the generator gradients\n    gen_optimizer.zero_grad()\n    \n    # Generate some fake pokemon\n    latent_batch = torch.randn(batch_size, seed_size, 1, 1, device=device)\n    fake_pokemon = generator(latent_batch)\n    \n    # Test against the discriminator\n    disc_predictions = discriminator(fake_pokemon)\n    targets = torch.zeros(fake_pokemon.size(0), 1, device=device) # We want the discriminator to think these images are real.\n    loss = F.binary_cross_entropy(disc_predictions, targets) # How well did the generator do? (How much did the discriminator believe the generator?)\n    \n    # Update the generator based on how well it fooled the discriminator\n    loss.backward()\n    gen_optimizer.step()\n    \n    # Return generator loss\n    return loss.item()","b5beef56":"import os\nfrom torchvision.utils import save_image\n\nRESULTS_DIR = 'results'\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\ndef save_results(index, latent_batch, show=True):\n    # Generate fake pokemon\n    fake_pokemon = generator(latent_batch)\n    \n    # Make the filename for the output\n    fake_file = \"result-image-{0:0=4d}.png\".format(index)\n    \n    # Save the image\n    save_image(denorm(fake_pokemon), os.path.join(RESULTS_DIR, fake_file), nrow=8)\n    print(\"Result Saved!\")\n    \n    if show:\n        fig, ax = plt.subplots(figsize=(20, 20))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(fake_pokemon.cpu().detach(), nrow=8).permute(1, 2, 0))","31d47d76":"from tqdm.notebook import tqdm\nimport torch.nn.functional as F\n\n# Static generation seed batch\nfixed_latent_batch = torch.randn(64, seed_size, 1, 1, device=device)\n\ndef train(epochs, learning_rate, start_idx=1):\n    # Empty the GPU cache to save some memory\n    torch.cuda.empty_cache()\n    \n    # Track losses and scores\n    disc_losses = []\n    disc_scores = []\n    gen_losses = []\n    gen_scores = []\n    \n    # Create the optimizers\n    disc_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n    gen_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n    \n    # Run the loop\n    for epoch in range(epochs):\n        # Go through each image\n        for real_img, _ in tqdm(data_loader):\n            real_img = real_img.to(device)\n            # Train the discriminator\n            disc_loss, real_score, gen_score = train_discriminator(real_img, disc_optimizer)\n\n            # Train the generator\n            gen_loss = train_generator(gen_optimizer)\n        \n        # Collect results\n        disc_losses.append(disc_loss)\n        disc_scores.append(real_score)\n        gen_losses.append(gen_loss)\n        gen_scores.append(gen_score)\n        \n        # Print the losses and scores\n        print(\"Epoch [{}\/{}], gen_loss: {:.4f}, disc_loss: {:.4f}, real_score: {:.4f}, gen_score: {:.4f}\".format(\n            epoch+start_idx, epochs, gen_loss, disc_loss, real_score, gen_score))\n        \n        # Save the images and show the progress\n        save_results(epoch + start_idx, fixed_latent_batch, show=False)\n    \n    # Return stats\n    return disc_losses, disc_scores, gen_losses, gen_scores","fc4db18b":"learning_rate = 3e-4\nepochs = 50","eeca02a8":"history = train(epochs, learning_rate)","3902f63b":"from IPython.display import Image\nImage('.\/results\/result-image-0010.png')","e0f46e20":"Image('.\/results\/result-image-0025.png')","7b4171cc":"Image('.\/results\/result-image-0050.png')","aee45d06":"# Image('.\/results\/result-image-0075.png')","2cc86943":"# Image('.\/results\/result-image-0100.png')","954084a3":"disc_losses, disc_scores, gen_losses, gen_scores = history","8ce6800b":"# Plot generator and discriminator losses\nplt.plot(disc_losses, '-')\nplt.plot(gen_losses, '-')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","7dd44500":"# Plots scores vs. epochs\nplt.plot(disc_scores, '-')\nplt.plot(gen_scores, '-')\nplt.xlabel('Epoch')\nplt.ylabel('Score')\nplt.legend(['Real', 'Fake'])\nplt.title('Scores');","bf590eb8":"# Plotting","d52803cd":"# Display some image","720a252e":"# Show some fake images","777d457c":"# Prepare data","653fc7c8":"# Save result","ffc24bc8":"# Training","f4c7d99b":"# Model","1bfb15e8":"# Import library"}}