{"cell_type":{"f930ffa7":"code","456e7923":"code","312edecb":"code","e0e110d7":"code","3053c950":"code","5a1e7fce":"code","6af178df":"code","a650eec4":"code","ea434755":"code","a1e71e4b":"code","1a0e4871":"code","c7bf346b":"code","7e7f639e":"code","ce62ddf6":"code","9dcffd60":"code","9ceff71f":"code","97ff5380":"code","ebc1796a":"code","f8c3457f":"code","9c73ea31":"code","b1801cd8":"code","2b442c41":"code","763f2b83":"code","1958b721":"code","8a112bbd":"code","7a9fb064":"code","b606ac4f":"code","9b74aaa4":"code","4c3f45cf":"code","be1f18d1":"code","e8dfbe66":"code","625d5aed":"code","e2e2d8fa":"code","a09bcd5a":"code","3bec273c":"code","aeb8800c":"code","ceb7a6c7":"code","e003c5f9":"code","4a245dc0":"code","6190ab6d":"code","5a5e699a":"code","2776cca9":"code","67d4c549":"code","aa99558a":"code","aaeabaa1":"code","0513ef95":"code","b3c24ca8":"code","17a56a79":"code","6a3c999b":"code","e2ed78ad":"code","96e3ab79":"code","c8f99d7a":"code","a956262f":"code","d4355615":"code","7c3e3161":"code","8be10bd3":"code","94416637":"code","4f723f28":"code","5ee5ade4":"code","25fd22eb":"code","92913376":"code","b21da9ea":"code","c1e814ed":"code","d9f1ae00":"code","fd78ec27":"code","70c2db6a":"code","dc402eb6":"code","284e79ca":"markdown","c65717e7":"markdown","ea8d6fde":"markdown","90beae88":"markdown","35a058cf":"markdown","e1282487":"markdown","079d872a":"markdown","f7c34bc1":"markdown","a0c9dd0a":"markdown","f8502f04":"markdown","40211fc0":"markdown","ea385264":"markdown","2a42fb7e":"markdown","a39353db":"markdown","314e657f":"markdown","82eaa5a6":"markdown","e0ecb2f8":"markdown","0d2bcfba":"markdown","8b1b29b3":"markdown","c4da7e62":"markdown","e8147ebc":"markdown","8da1da40":"markdown","2cb778cc":"markdown","54775a40":"markdown"},"source":{"f930ffa7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","456e7923":"import matplotlib.pyplot as plt","312edecb":"def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n    plt.plot(time[start:end], series[start:end], format, label=label)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    if label:\n        plt.legend(fontsize=14)\n    plt.grid(True)","e0e110d7":"def trend(time, slope=0): #Lets define trend\n    return slope * time","3053c950":"time = np.arange(365)\nprint(time)","5a1e7fce":"trend(time, 0.1)","6af178df":"#Let's create a time series that just trends upward:\ntime = np.arange(4 * 365 + 1)\nbaseline = 10\nseries = trend(time, 0.1)\n\nplt.figure(figsize=(10, 6))\nplot_series(time, series)\nplt.show()","a650eec4":"def seasonal_pattern(season_time):\n    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n    return np.where(season_time < 0.4,\n                    np.cos(season_time * 2 * np.pi),\n                    1 \/ np.exp(3 * season_time))\n\ndef seasonality(time, period, amplitude=1, phase=0):\n    \"\"\"Repeats the same pattern at each period\"\"\"\n    season_time = ((time + phase) % period) \/ period\n    return amplitude * seasonal_pattern(season_time)","ea434755":"baseline = 10\namplitude = 40\nseries = seasonality(time, period=365, amplitude=amplitude)\n\nplt.figure(figsize=(10, 6))\nplot_series(time, series)\nplt.show()","a1e71e4b":"slope = 0.05\nseries = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n\nplt.figure(figsize=(12, 8))\nplot_series(time, series)\nplt.show()","1a0e4871":"def white_noise(time, noise_level=1, seed=None):\n    rnd = np.random.RandomState(seed)\n    return rnd.randn(len(time)) * noise_level","c7bf346b":"noise_level = 5\nnoise = white_noise(time, noise_level, seed=42)\n\nplt.figure(figsize=(10, 6))\nplot_series(time, noise)\nplt.show()","7e7f639e":"#Now let's add this white noise to the time series:\nseries += noise\n\nplt.figure(figsize=(10, 6))\nplot_series(time, series)\nplt.show()","ce62ddf6":"split_time = 1000\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]","9dcffd60":"def autocorrelation(time, amplitude, seed=None):\n    rnd = np.random.RandomState(seed)\n    \u03c61 = 0.5\n    \u03c62 = -0.1\n    ar = rnd.randn(len(time) + 50)\n    ar[:50] = 100\n    for step in range(50, len(time) + 50):\n        ar[step] += \u03c61 * ar[step - 50]\n        ar[step] += \u03c62 * ar[step - 33]\n    return ar[50:] * amplitude","9ceff71f":"def autocorrelation(time, amplitude, seed=None):\n    rnd = np.random.RandomState(seed)\n    \u03c6 = 0.8\n    ar = rnd.randn(len(time) + 1)\n    for step in range(1, len(time) + 1):\n        ar[step] += \u03c6 * ar[step - 1]\n    return ar[1:] * amplitude","97ff5380":"series = autocorrelation(time, 10, seed=42)\nplot_series(time[:200], series[:200])\nplt.show()","ebc1796a":"series = autocorrelation(time, 10, seed=42) + trend(time, 2)\nplot_series(time[:200], series[:200])\nplt.show()","f8c3457f":"series = autocorrelation(time, 10, seed=42) + seasonality(time, period=50, amplitude=150) + trend(time, 2)\nplot_series(time[:200], series[:200])\nplt.show()","9c73ea31":"series = autocorrelation(time, 10, seed=42) + seasonality(time, period=50, amplitude=150) + trend(time, 2)\nseries2 = autocorrelation(time, 5, seed=42) + seasonality(time, period=50, amplitude=2) + trend(time, -1) + 550\nseries[200:] = series2[200:]\n#series += noise(time, 30)\nplot_series(time[:300], series[:300])\nplt.show()","b1801cd8":"def impulses(time, num_impulses, amplitude=1, seed=None):\n    rnd = np.random.RandomState(seed)\n    impulse_indices = rnd.randint(len(time), size=10)\n    series = np.zeros(len(time))\n    for index in impulse_indices:\n        series[index] += rnd.rand() * amplitude\n    return series  ","2b442c41":"series = impulses(time, 10, seed=42)\nplot_series(time, series)\nplt.show()","763f2b83":"def autocorrelation(source, \u03c6s):\n    ar = source.copy()\n    max_lag = len(\u03c6s)\n    for step, value in enumerate(source):\n        for lag, \u03c6 in \u03c6s.items():\n            if step - lag > 0:\n              ar[step] += \u03c6 * ar[step - lag]\n    return ar","1958b721":"signal = impulses(time, 10, seed=42)\nseries = autocorrelation(signal, {1: 0.99})\nplot_series(time, series)\nplt.plot(time, signal, \"k-\")\nplt.show()","8a112bbd":"signal = impulses(time, 10, seed=42)\nseries = autocorrelation(signal, {1: 0.70, 50: 0.2})\nplot_series(time, series)\nplt.plot(time, signal, \"k-\")\nplt.show()","7a9fb064":"series_diff1 = series[1:] - series[:-1]\nplot_series(time[1:], series_diff1)","b606ac4f":"from pandas.plotting import autocorrelation_plot\n\nautocorrelation_plot(series)","9b74aaa4":"from statsmodels.tsa.arima_model import ARIMA\n\nmodel = ARIMA(series, order=(5, 1, 0))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","4c3f45cf":"df = pd.read_csv(\"..\/input\/sunspots\/Sunspots.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\nseries = df[\"Monthly Mean Total Sunspot Number\"].asfreq(\"1M\")\nseries.head()","be1f18d1":"series.plot(figsize=(12, 5),c=\"red\")","e8dfbe66":"series.diff(1).plot(c=\"red\")\nplt.axis([0, 100, -50, 50])","625d5aed":"from pandas.plotting import autocorrelation_plot\n\nautocorrelation_plot(series)","e2e2d8fa":"autocorrelation_plot(series.diff(1)[1:])","a09bcd5a":"autocorrelation_plot(series.diff(1)[1:].diff(11 * 12)[11*12+1:])\nplt.axis([0, 500, -0.1, 0.1])","3bec273c":"autocorrelation_plot(series.diff(1)[1:])\nplt.axis([0, 50, -0.1, 0.1])","aeb8800c":"def plot_series(time, series, format=\"-\", start=0, end=None):\n    plt.plot(time[start:end], series[start:end], format)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    plt.grid(True)\n\ndef trend(time, slope=0):\n    return slope * time\n\ndef seasonal_pattern(season_time):\n    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n    return np.where(season_time < 0.4,\n                    np.cos(season_time * 2 * np.pi),\n                    1 \/ np.exp(3 * season_time))\n\ndef seasonality(time, period, amplitude=1, phase=0):\n    \"\"\"Repeats the same pattern at each period\"\"\"\n    season_time = ((time + phase) % period) \/ period\n    return amplitude * seasonal_pattern(season_time)\n\ndef noise(time, noise_level=1, seed=None):\n    rnd = np.random.RandomState(seed)\n    return rnd.randn(len(time)) * noise_level\n\ntime = np.arange(4 * 365 + 1, dtype=\"float32\")\nbaseline = 10\nseries = trend(time, 0.1)  \nbaseline = 10\namplitude = 40\nslope = 0.05\nnoise_level = 5\n\n# Create the series\nseries = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n# Update with noise\nseries += noise(time, noise_level, seed=42)\n\nplt.figure(figsize=(10, 6))\nplot_series(time, series)\nplt.show()","ceb7a6c7":"#we have the time series, let's split it so we can start forecasting\nsplit_time = 1000\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]\nplt.figure(figsize=(10, 6))\nplot_series(time_train, x_train)\nplt.show()\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplt.show()","e003c5f9":"naive_forecast = series[split_time - 1:-1]","4a245dc0":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, naive_forecast)","6190ab6d":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid, start=0, end=150)\nplot_series(time_valid, naive_forecast, start=1, end=151)\n#You can see that the naive forecast lags 1 step behind the time series.","5a5e699a":"import tensorflow.keras\nprint(tensorflow.keras.metrics.mean_squared_error(x_valid, naive_forecast).numpy())\nprint(tensorflow.keras.metrics.mean_absolute_error(x_valid, naive_forecast).numpy())","2776cca9":"#Forecasts the mean of the last few values.If window_size=1, then this is equivalent to naive forecast\"\"\"\ndef moving_average_forecast(series, window_size):\n    forecast = []\n    for time in range(len(series) - window_size):\n        forecast.append(series[time:time + window_size].mean())\n    return np.array(forecast)","67d4c549":"moving_avg = moving_average_forecast(series, 30)[split_time - 30:]\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, moving_avg)","aa99558a":"print(tensorflow.keras.metrics.mean_squared_error(x_valid, moving_avg).numpy())\nprint(tensorflow.keras.metrics.mean_absolute_error(x_valid, moving_avg).numpy())","aaeabaa1":"diff_time = time[365:]\ndiff_series = (series[365:] - series[:-365])\nplt.figure(figsize=(10, 6))\nplot_series(diff_time, diff_series)\nplt.show()","0513ef95":"diff_moving_avg = moving_average_forecast(diff_series, 50)[split_time - 365 - 50:]\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, diff_series[split_time - 365:])\nplot_series(time_valid, diff_moving_avg)\nplt.show()","b3c24ca8":"# let's bring back the trend and seasonality by adding the past values from t \u2013 365:\ndiff_moving_avg_plus_past = series[split_time - 365:-365] + diff_moving_avg\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, diff_moving_avg_plus_past)\nplt.show()","17a56a79":"print(tensorflow.keras.metrics.mean_squared_error(x_valid, diff_moving_avg_plus_past).numpy())\nprint(tensorflow.keras.metrics.mean_absolute_error(x_valid, diff_moving_avg_plus_past).numpy())","6a3c999b":"diff_moving_avg_plus_smooth_past = moving_average_forecast(series[split_time - 370:-360], 10) + diff_moving_avg\n\nplt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, diff_moving_avg_plus_smooth_past)","e2ed78ad":"print(tensorflow.keras.metrics.mean_squared_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())\nprint(tensorflow.keras.metrics.mean_absolute_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())","96e3ab79":"import tensorflow as tf\nimport seaborn as sns","c8f99d7a":"df= pd.read_csv(\"..\/input\/sunspots\/Sunspots.csv\")\ndf.head()","a956262f":"def plot_series(time, series, format=\"-\", start=0, end=None):\n    plt.plot(time[start:end], series[start:end], format)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    plt.grid(True)","d4355615":"series = df[\"Monthly Mean Total Sunspot Number\"]\ntime = df[\"Date\"].values\nplt.figure(figsize=(20, 15))\nplot_series(time, series)","7c3e3161":"split_time = 3000\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]\n\nwindow_size = 30\nbatch_size = 32\nshuffle_buffer_size = 1000","8be10bd3":"series[:5]","94416637":"tf.expand_dims(series, axis=-1)[:5]","4f723f28":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    series = tf.expand_dims(series, axis=-1)\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n    ds = ds.shuffle(shuffle_buffer)\n    ds = ds.map(lambda w: (w[:-1], w[1:]))\n    return ds.batch(batch_size).prefetch(1)","5ee5ade4":"def model_forecast(model, series, window_size):\n    ds = tf.data.Dataset.from_tensor_slices(series)\n    ds = ds.window(window_size, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size))\n    ds = ds.batch(32).prefetch(1)\n    forecast = model.predict(ds)\n    return forecast","25fd22eb":"window_size = 64\nbatch_size = 256\ntrain_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\nprint(train_set)\nprint(x_train.shape)\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n                      strides=1, padding=\"causal\",\n                      activation=\"relu\",\n                      input_shape=[None, 1]),\n  tf.keras.layers.LSTM(64, return_sequences=True),\n  tf.keras.layers.LSTM(64, return_sequences=True),\n  tf.keras.layers.Dense(30, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"relu\"),\n  tf.keras.layers.Dense(1),\n  tf.keras.layers.Lambda(lambda x: x * 400)\n])\n\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch \/ 20))\noptimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\nmodel.compile(loss=tf.keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nhistory = model.fit(train_set, epochs=100, callbacks=[lr_schedule])","92913376":"pd.DataFrame(model.history.history).plot()","b21da9ea":"rnn_forecast1 = model_forecast(model, series[..., np.newaxis], window_size)\nrnn_forecast1 = rnn_forecast1[split_time - window_size:-1, -1, 0]","c1e814ed":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, rnn_forecast1)","d9f1ae00":"# we make some changes in the neural network, we will use the size of window, filter and LSTM layers as 60\ntf.keras.backend.clear_session()\ntrain_set = windowed_dataset(x_train, window_size=60, batch_size=100, shuffle_buffer=shuffle_buffer_size)\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv1D(filters=60, kernel_size=5,\n                      strides=1, padding=\"causal\",\n                      activation=\"relu\",\n                      input_shape=[None, 1]),\n  tf.keras.layers.LSTM(60, return_sequences=True),\n  tf.keras.layers.LSTM(60, return_sequences=True),\n  tf.keras.layers.Dense(30, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"relu\"),\n  tf.keras.layers.Dense(1),\n  tf.keras.layers.Lambda(lambda x: x * 400)\n])\n\n\noptimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\nmodel.compile(loss=tf.keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\nhistory = model.fit(train_set,epochs=500)","fd78ec27":"rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\nrnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]","70c2db6a":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, rnn_forecast)","dc402eb6":"print(tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast1).numpy())\nprint(tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy())","284e79ca":"That's worse than naive forecast! The moving average does not anticipate trend or seasonality, so let's try to remove them by using differencing","c65717e7":"<font color=\"red\">\n2.3. Differencing:","ea8d6fde":"Better than naive forecast, good. However the forecasts look a bit too random, because we're just adding past values, which were noisy. Let's use a moving averaging on past values to remove some of the noise:","90beae88":"## 1. Understanding teh Concepts in Time Series:","35a058cf":"<font color=\"red\">\n2.1. Naive Forecasting:","e1282487":"<font color=\"red\">\n2.2. Moving Average:","079d872a":"\nAn overall consistent upward direction for data\n\n","f7c34bc1":"Since the seasonality period is 365 days, we will subtract the value at time t \u2013 365 from the value at time t.","a0c9dd0a":"<font color=\"red\">\n1.2. Seasonality:","f8502f04":"Na\u00efve forecasts are the most cost-effective forecasting model, and provide a benchmark against which more sophisticated models can be compared. This forecasting method is only suitable for time series data.[4] Using the na\u00efve approach, forecasts are produced that are equal to the last observed value. This method works quite well for economic and financial time series, which often have patterns that are difficult to reliably and accurately predict.[4] If the time series is believed to have seasonality, the seasonal na\u00efve approach may be more appropriate where the forecasts are equal to the value from last season.","40211fc0":"Autocorrelation means Data that follows a predictable shape, even if the scale is different\n\n","ea385264":"## 3. Deep Neural Networks for Time Series","2a42fb7e":"Unpredictable changes in time series data\n","a39353db":"In statistics, a moving average is a calculation used to analyze data points by creating a series of averages of different subsets of the full data set. In finance, a moving average (MA) is a stock indicator that is commonly used in technical analysis. The reason for calculating the moving average of a stock is to help smooth out the price data by creating a constantly updated average price.\n\nThe reason for calculating the moving average of a stock is to help smooth out the price data over a specified period of time by creating a constantly updated average price.\nA simple moving average (SMA) is a calculation that takes the arithmetic mean of a given set of prices over the specific number of days in the past; for example, over the previous 15, 30, 100, or 200 days.","314e657f":"## 2. Time Series in Use","82eaa5a6":"Let's try to forecast it. We will split it into two periods: the training period and the validation period (in many cases, you would also want to have a test period). The split will be at time step 1000.","e0ecb2f8":"In practice few real-life time series have such a smooth signal. They usually have some noise, and the signal-to-noise ratio can sometimes be very low. Let's generate some white noise:","0d2bcfba":"Let's generate a time series with a seasonal pattern:","8b1b29b3":"Lets make some impulses:","c4da7e62":"\nA regular change in shape of the data","e8147ebc":"Let's create a time series with both trend and seasonality","8da1da40":"<font color=\"red\">\n3.1. Implementation 1:","2cb778cc":"<font color=\"red\">\n1.1. Trend:","54775a40":"<font color=\"red\">\n1.3. Noise:"}}