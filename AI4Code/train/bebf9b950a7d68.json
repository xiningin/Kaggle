{"cell_type":{"717322e4":"code","173bb741":"code","2afa14d9":"code","5df3cca3":"code","26895044":"code","b170b89e":"code","e3e78453":"code","4ddca8d1":"code","0da03987":"code","cb46334d":"markdown","9b905cef":"markdown","0652ae0b":"markdown","2893609a":"markdown","ca127a43":"markdown","d47e37bb":"markdown"},"source":{"717322e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","173bb741":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.optim as optim\n\nxy_train=pd.read_csv('..\/input\/housing-price\/train_data.csv',header=None,skiprows=1,dtype=np.float32)\nprint(xy_train)\nx_data=xy_train.loc[:,1:6]\ny_data=xy_train[7]\n\nprint(x_data)\nprint(y_data)\n","2afa14d9":"x_data=np.array(x_data)\ny_data=np.array(y_data)\nx_train=torch.FloatTensor(x_data)\ny_train=torch.FloatTensor(y_data)","5df3cca3":"SGD \ubc29\uc2dd\uc744 \ud65c\uc6a9\ud574 \ud559\uc2b5\uc744 \ud588\uc2b5\ub2c8\ub2e4. \ub2e4\ub9cc lr(learning rate)\uac00 \ub9e4\uc6b0 \ub0ae\uc2b5\ub2c8\ub2e4. lr=1*10^(-11) \ubcf4\ub2e4 \ud06c\uba74 \uc804\ubd80 NaN\uc73c\ub85c \ubc1c\uc0b0\ud558\ub2c8 \ucc38\uace0 \ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4.","26895044":"W = torch.zeros((6, 1), requires_grad=True)\nb = torch.zeros(1, requires_grad=True)\noptimizer = optim.SGD([W, b], lr=10e-12)\n\nnb_epochs = 32000\nfor epoch in range(nb_epochs + 1):\n    hypothesis = x_train.matmul(W) + b\n    cost = torch.mean((hypothesis - y_train) ** 2)\n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n\n    if epoch%8000==0:\n      print('Epoch {:4d}\/{} hypothesis: {} Cost: {:.1f}'.format(\n          epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n      ))","b170b89e":"def f(x):\n    return float(x)\nx_test=pd.read_csv('..\/input\/housing-price\/test_data.csv',header=None,dtype=np.float32)\nprint(x_test)\nx_test=x_test.loc[:,1:6]\nprint(x_test)","e3e78453":"x_test=np.array(x_test)\nx_train1=torch.FloatTensor(x_test)\nhypothesis = x_train1.matmul(W) + b \nprint(hypothesis)","4ddca8d1":"result=pd.read_csv('..\/input\/housing-price\/test-result data.csv',sep=',',skiprows=1,header=None,dtype='float32')\ny_test=result[1]\nsum=0\nfor i in range(0,5):\n  error=(y_test[i]-hypothesis.data.numpy()[i])\/y_test[i]\n  if error<0:\n    error=error*-1\n  sum+=error\nprint(sum\/5*100)","0da03987":"test=pd.read_csv('..\/input\/housing-price\/test_sample.csv')\nfor i in range(len(hypothesis)):\n  test['ID'][i]=i\n  test['Expected'][i]=hypothesis[i].item()\ntest.to_csv('Submission.csv',mode='w',index=False)\ntest","cb46334d":"Kaggle DataSet\uc744 \ubc1b\uc2b5\ub2c8\ub2e4. ","9b905cef":"\uc81c\ucd9c\ud574\uc57c \ud558\ub294 cvc file\uc744 \ud615\uc2dd\uc5d0 \ub9de\ucdb0 \uc81c\uc791\ud569\ub2c8\ub2e4.","0652ae0b":"\uc62c\ub824\ub454 result-data \uc548\uc5d0 \uc788\ub294 \uc815\ub2f5 \uac12 test-result data.csv\ub97c file path\ub97c \ubcf5\uc0ac\ud574\uc11c \ubd88\ub7ec\uc635\ub2c8\ub2e4. cost\uac12\uc774 \ub9e4\uc6b0 \ud06c\uae30 \ub54c\ubb38\uc5d0 \uadf8\ub0e5 error\ub9cc \ud655\uc778\ud558\uc5ec \uc131\ub2a5 test\ub97c \ud558\uaca0\uc2b5\ub2c8\ub2e4. error\uc758 \uc815\uc758\ub294 |\uc815\ub2f5\uac12-\uc608\uce21\uac12|\/\uc815\ub2f5\uac12\uc785\ub2c8\ub2e4. \uadf8\ub9ac\ud558\uc5ec \uac01 error\uc758 \ud569\uc744 \uad6c\ud55c \ud6c4 \uadf8 error\uac12\ub4e4\uc758 \ud3c9\uade0\uc744 \uad6c\ud55c \ud6c4 *100\uc744 \ud558\uc5ec %\uac12\uc744 \uad6c\ud558\ub3c4\ub85d \ud569\ub2c8\ub2e4.","2893609a":"\ubc1b\uc740 \uc2e4\ud5d8\ub370\uc774\ud130\uac12 x_test\ub97c \ubc29\uae08 \uad6c\ud55c W\uc640 b\uac12\uc744 \uacf1\ud558\uace0 \ub354\ud55c \uacc4\uc0b0\uc744 \uc2e4\ud589\ud558\uae30 \uc704\ud574 \uacc4\uc0b0\ud560 \uc218 \uc788\ub294 \uac19\uc740 data\ud615 Tensor\ud615\uc73c\ub85c \ubc14\uafd4\uc900 \ub2e4\uc74c \n\uc774\ub860 \uac12 x_test*W+b\uac12\uc744 \uad6c\ud569\ub2c8\ub2e4.","ca127a43":"\ubc1b\uc544\uc628 \ub370\uc774\ud130\uc758 \uacc4\uc0b0\uc744 \uc704\ud574 tensor\ud615\uc73c\ub85c datatype\uc744 \ubc14\uafd4\uc90d\ub2c8\ub2e4.","d47e37bb":"test\uac12 cvc\uc5d0 \uc22b\uc790\ud615\ud0dc\ub85c \uc800\uc7a5\uc774 \uc548\ub418\uc5b4\uc11c pd.read_csv\uc5d0\uc11c \uc77d\uc740 data\ub97c \uc22b\uc790 \ud615\ud0dc\ub85c \ubc14\uafd4\uc918\uc57c\ub9cc \ud569\ub2c8\ub2e4. \uadf8\uac83\uc744 \uc704\ud55c \ud568\uc218 f\uc640 read_csv\uc758 \uc778\uc790 converter\uc785\ub2c8\ub2e4. Kaggle\uc5d0\uc11c \ub3cc\ub9ac\ub294 \ud615\ud0dc\uc5ec\uc11c filepath\ub97c \ud1b5\ud574 csv\ub97c \uc77d\uc5b4\uc624\uac8c \ub418\uc5c8\uc2b5\ub2c8\ub2e4."}}