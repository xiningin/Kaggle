{"cell_type":{"be059f82":"code","74184d60":"code","9ed31421":"code","8bd092d3":"code","0b4e48f6":"code","e5da9f9e":"code","5c599169":"code","337bd579":"markdown","d796d132":"markdown","f1398288":"markdown","c10bf8b2":"markdown","f37214c1":"markdown","7a92b45d":"markdown","1f0fcbad":"markdown"},"source":{"be059f82":"import torch\nimport torchvision\nfrom torchvision import datasets, transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nimport os","74184d60":"# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    # transforms >> image transformations ,, chained together by Compose\n    #\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","9ed31421":"data_dir = '..\/input\/hymenoptera-data\/hymenoptera_data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\n\n# training data\ntrainloader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in 'train'}\ndataset_sizes = {x: len(image_datasets[x]) for x in 'train'}\n\n# test data ??\ntestset = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in 'val'}\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n\nclass_names = image_datasets['train'].classes\n\n\nclasses = ('ant', 'bee')\n\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nprint('\\n0-trainloader:  {}\/n1-dataset_sizes:  {} \/n2-testset:  {} \/n3-testloader:  {} \/n3-class_names:  {}'.format(\ntrainloader, dataset_sizes, testset, testloader, class_names))","8bd092d3":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","0b4e48f6":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nnet = Net()","e5da9f9e":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","5c599169":"for epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","337bd579":"## Defining a CNN","d796d132":"### Data augmentation and normalization for training","f1398288":"    RandomResizedCrop\nCrop a random portion of image and resize it to a given size.","c10bf8b2":"### Define a Loss function and optimizer","f37214c1":"### Visualizing data","7a92b45d":"## Training the network","1f0fcbad":"### loading data"}}