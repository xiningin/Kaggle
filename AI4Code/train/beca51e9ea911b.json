{"cell_type":{"2aafd10f":"code","f3b05e50":"code","4f1318a9":"code","9d7bc417":"code","76ec6408":"code","ea5c1a98":"code","a2187a43":"code","7f9396f8":"code","6148baa4":"code","27dadd49":"code","1e179993":"code","ba094b4f":"code","ed554f15":"code","bcd4ac6c":"code","50a17fa4":"code","8513409c":"code","8c59709e":"code","32de4ab7":"code","b90f7ddb":"code","1c16ce8d":"code","45dec57a":"code","8ec8fade":"code","b41f68f9":"code","e679f435":"code","5f9ffc58":"code","f5647b58":"code","5feae452":"code","24cac599":"code","a501cce0":"code","646eb61c":"code","fa6df13a":"code","d285b487":"code","bf7ea221":"code","b17a5c9e":"code","cb9cab49":"code","5015f6eb":"code","baa7d9bb":"code","88f0b346":"code","ed62f411":"code","58c6a2ad":"code","b42ea2e2":"code","f3d9842e":"code","eca6f4d6":"code","8b6957ee":"code","09beb991":"code","28d80d33":"code","4ac19dff":"code","ae25963b":"code","8f6487a6":"code","ba189a7a":"code","ef28ddfd":"code","477942c4":"code","3facd325":"code","c4ba4ac8":"code","4554d3ec":"code","b4c7dc13":"code","e2462d8d":"code","3582d741":"code","95fdcf84":"code","2367e135":"code","d033ab4e":"code","7a343fdf":"code","dafeee4c":"code","75a7f1c3":"code","b569ed01":"code","b1474b38":"code","e55f2f34":"code","085d8a56":"code","47cf8ba0":"code","69bda57b":"markdown","73bb8b98":"markdown","cb0b81a2":"markdown","9004422e":"markdown","814b591f":"markdown","7e50d8b2":"markdown","7e678c3c":"markdown","db5298d2":"markdown"},"source":{"2aafd10f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom itertools import combinations\n\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f3b05e50":"train_full = pd.read_csv('..\/input\/titanic\/train.csv', index_col='PassengerId')\ntest_full = pd.read_csv('..\/input\/titanic\/test.csv', index_col='PassengerId')\n\ntrain_NA = train_full.isna().sum()\ntest_NA = test_full.isna().sum()\n\npd.concat([train_NA, test_NA], axis=1, sort = False, keys = ['Train NA', 'Test NA'])","4f1318a9":"train_full.Embarked.unique()","9d7bc417":"train_full[train_full.Embarked.isnull()]","76ec6408":"train_full.loc[830, 'Embarked'] = 'S'\ntrain_full.loc[62, 'Embarked'] = 'S'\n# print(train_full.loc[830], train_full.loc[62])","ea5c1a98":"print('Passenger count from ')\nprint('Southampton: %d' %train_full[train_full.Embarked=='S'].Embarked.count())\nprint('Cherbourg: %d' %train_full[train_full.Embarked=='C'].Embarked.count())\nprint('Queenstown (Cork): %d' %train_full[train_full.Embarked=='Q'].Embarked.count())","a2187a43":"print('Passenger count from (test)')\nprint('Southampton: %d' %test_full[test_full.Embarked=='S'].Embarked.count())\nprint('Cherbourg: %d' %test_full[test_full.Embarked=='C'].Embarked.count())\nprint('Queenstown (Cork): %d' %test_full[test_full.Embarked=='Q'].Embarked.count())","7f9396f8":"sns.catplot(x=\"Pclass\", y=\"Fare\", hue=\"Sex\", kind=\"bar\", data=train_full);\nplt.title('Fare by class and gender (all)')\nplt.ylabel('Fare')\nplt.xlabel('Class')","6148baa4":"missing_age = train_full[train_full.Age.isnull()]\nmissing_age","27dadd49":"sns.catplot(x=\"Pclass\", y=\"Fare\", hue=\"Sex\", kind=\"bar\", data=missing_age);\nplt.title('Fare by class and gender (missing age)')\nplt.ylabel('Fare')\nplt.xlabel('Class')","1e179993":"plt.figure(figsize=(10,6))\nplt.title('Missing age by class')\n\nx = missing_age.Pclass\nsns.countplot(x=\"Pclass\", hue=\"Sex\", data=missing_age)\n\nplt.ylabel('Count')\nplt.xlabel('Class')","ba094b4f":"plt.figure(figsize=(10,6))\nplt.title('Missing age by embark')\n\nx = missing_age.Pclass\nsns.countplot(x=\"Embarked\", hue=\"Sex\", data=missing_age)\n\nplt.ylabel('Count')\nplt.xlabel('Embark')","ed554f15":"med_age_S = train_full[(train_full.Embarked=='S')].Age.median()\nmed_age_C = train_full[(train_full.Embarked=='C')].Age.median()\nmed_age_Q = train_full[(train_full.Embarked=='Q')].Age.median()\n\nprint('Median age in ')\nprint('Southampton: %d' %med_age_S)\nprint('Cherbourg: %d' %med_age_C)\nprint('Queenstown (Cork): %d' %med_age_Q)","bcd4ac6c":"sns.relplot(x=\"Age\", y=\"Fare\", data=train_full);","50a17fa4":"missing_age.info()","8513409c":"age_X = train_full[train_full.Age.notnull()]\n# age_X.info()","8c59709e":"age_X = age_X[age_X.columns.drop('Survived')]\nage_X = age_X[age_X.columns.drop('Cabin')]","32de4ab7":"age_X.info()","b90f7ddb":"age_y = age_X.Age.astype(int)\nage_X = age_X[age_X.columns.drop('Age')]\n\nma_X, va_X, ma_y, va_y = train_test_split(age_X, age_y, random_state=1)\n\n# ma_X.info()","1c16ce8d":"# va_X.info()","45dec57a":"# convert categorical features to numerical features using label encoder\nle = LabelEncoder()\n\nle_train_X = ma_X.copy()\nle_valid_X = va_X.copy()\n\n# Encode categorical features\ns = ma_X.dtypes=='object'\ncat_features = list(s[s].index)\n# print(cat_features)\n\nfor col in cat_features:\n    le_train_X[col] = le.fit_transform(ma_X[col])\n    le_valid_X[col] = le.fit_transform(va_X[col])\n    \nma_X = le_train_X\nva_X = le_valid_X","8ec8fade":"# print(ma_X.info(), va_X.info())","b41f68f9":"rf_ma_model = RandomForestClassifier(n_estimators=100, random_state=0).fit(ma_X, ma_y)\n\npred_valid = rf_ma_model.predict(va_X)\nprint('Mean absolute error: %.2f' %mean_absolute_error(pred_valid, va_y))\nprint(accuracy_score(va_y, pred_valid))","e679f435":"missing_age = missing_age[missing_age.columns.drop('Survived')]\nmissing_age = missing_age[missing_age.columns.drop('Age')]\nmissing_age = missing_age[missing_age.columns.drop('Cabin')]","5f9ffc58":"# convert categorical features to numerical features using label encoder\nle = LabelEncoder()\n\nle_train_X = missing_age.copy()\n\n# Encode categorical features\ns = missing_age.dtypes=='object'\ncat_features = list(s[s].index)\nprint(cat_features)\n\nfor col in cat_features:\n    le_train_X[col] = le.fit_transform(missing_age[col])\n    \nmissing_age = le_train_X","f5647b58":"missing_age.info()","5feae452":"pred_test = rf_ma_model.predict(missing_age)\noutput = pd.DataFrame({'Age': pred_test}, index=missing_age.index)\noutput","24cac599":"missing_age.info()","a501cce0":"sns.distplot(pred_test, kde=False)","646eb61c":"sns.distplot(train_full.Age, kde=False)","fa6df13a":"train_full[train_full.Age.isnull()].head()","d285b487":"test = train_full.copy()\ntest.head()","bf7ea221":"test = test.combine_first(output)\ntrain_full = test\n# train_full.info()","b17a5c9e":"y = train_full.Survived\nX = train_full[train_full.columns.drop('Survived')]\n\ntrain_X_full, valid_X_full, train_y, valid_y = train_test_split(X, y, random_state=1)","cb9cab49":"# Drop the cabin value\ntrain_X = train_X_full[train_X_full.columns.drop('Cabin')]\nvalid_X = valid_X_full[valid_X_full.columns.drop('Cabin')]\n# train_X.info()","5015f6eb":"train_X.head()","baa7d9bb":"# convert categorical features to numerical features using label encoder\nle = LabelEncoder()\n\nle_train_X = train_X.copy()\nle_valid_X = valid_X.copy()\n\n# Encode categorical features\ns = train_X.dtypes=='object'\ncat_features = list(s[s].index)\n\nfor col in cat_features:\n    le_train_X[col] = le.fit_transform(train_X[col])\n    le_valid_X[col] = le.fit_transform(valid_X[col])\n    \n# le_train_X.info()","88f0b346":"train_X = le_train_X\nvalid_X = le_valid_X","ed62f411":"train_X.head()","58c6a2ad":"# choose categorical features\ncols = train_X.columns\ninteractions_train = pd.DataFrame(index=train_X.index)\ninteractions_valid = pd.DataFrame(index=valid_X.index)\n\n# create the interactions for two categorical featuers at a time\nfor col1, col2 in combinations(cols, 2):\n    col_name = '_'.join([col1, col2])\n    \n    values1 = train_X[col1].map(str) + '_' + train_X[col2].map(str)\n    values2 = valid_X[col1].map(str) + '_' + valid_X[col2].map(str)\n    \n    encoder = preprocessing.LabelEncoder()\n    \n    interactions_train[col_name] = encoder.fit_transform(values1)\n    interactions_valid[col_name] = encoder.fit_transform(values2)\n    \ninteractions_train.head()","b42ea2e2":"train_X = train_X.join(interactions_train)\n# train_X.info()","f3d9842e":"valid_X = valid_X.join(interactions_valid)\n# valid_X.info()","eca6f4d6":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier(n_estimators=100,\n                                  random_state=0).fit(train_X, train_y)","8b6957ee":"# for i in range(1,10):\n#     rf_model = RandomForestClassifier(n_estimators=i*50,\n#                                   random_state=0).fit(train_X, train_y)","09beb991":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rf_model, random_state=1).fit(valid_X, valid_y)\neli5.show_weights(perm, feature_names=valid_X.columns.tolist())","28d80d33":"train_X.shape","4ac19dff":"from sklearn.metrics import mean_absolute_error\n\npred_valid = rf_model.predict(valid_X)\nprint('Mean absolute error: %.2f' %mean_absolute_error(pred_valid, valid_y))","ae25963b":"from sklearn.metrics import accuracy_score\n\npred_valid = rf_model.predict(valid_X)\nprint(accuracy_score(valid_y, pred_valid))\nprint(pred_valid.tolist())","8f6487a6":"print(valid_y.tolist())","ba189a7a":"# # How many unique values of the top 10 features\n# print('Gender and family (sibling\/spouse): %d' %train_X.Sex_SibSp.nunique())\n# print('Gender and embark location: %d' %train_X.Sex_Embarked.nunique())\n# print('Class and embark location: %d' %train_X.Pclass_Embarked.nunique())\n# print('Family (parent\/children) and ticket: %d' %train_X.Parch_Ticket.nunique())\n# print('Gender and family (parent\/children): %d' %train_X.Sex_Parch.nunique())\n# print('Class and gender: %d' %train_X.Pclass_Sex.nunique())\n# print('Gender: %d' %train_X.Sex.nunique())\n# print('Age and embark location: %d' %train_X.Age_Embarked.nunique())\n# print('Age: %d' %train_X.Age.nunique())\n# print('Ticket and fare cost: %d' %train_X.Ticket_Fare.nunique())\n\n# print('\\nNumber of passengers: %d \\n  # of unique tickets: %d \\n  people travelling alone: %d' %(len(train_X), \n#                                                                train_X.Ticket.nunique(), \n#                                                                len(train_X) - train_X.Ticket.nunique()))","ef28ddfd":"print('Unique values of the top 10 features')\nprint('Gender and family (sibling\/spouse): %d' %train_X.Sex_SibSp.nunique())\nprint('Gender: %d' %train_X.Sex.nunique())\nprint('Gender and ticket: %d' %train_X.Sex_Ticket.nunique())\nprint('Family (parent\/children) and gender: %d' %train_X.Parch_Sex.nunique())\nprint('Age: %d' %train_X.Age.nunique())\nprint('Class and gender: %d' %train_X.Pclass_Sex.nunique())\nprint('Age and class: %d' %train_X.Age_Pclass.nunique())\nprint('Class and family (sibling\/spouse): %d' %train_X.Pclass_SibSp.nunique())\nprint('Age and ticket: %d' %train_X.Age_Ticket.nunique())\nprint('Embark location and name: %d' %train_X.Embarked_Name.nunique())","477942c4":"# train_X.Fare.nunique()","3facd325":"plt.figure(figsize=(10,6))\nplt.title('Age by gender\/family (sibling\/spouse)')\n\nsns.barplot(x=train_X.Sex_SibSp, y=train_X.Age)\n\nplt.xlabel('Family (sibling\/spouse)')\nplt.ylabel('Age')","c4ba4ac8":"# Male=1, Female=0\n# Survived=1, not_survived=0\nsns.swarmplot(y=train_X.SibSp, x=train_X.Sex, hue=train_y)","4554d3ec":"# Male=1, Female=0\n# Survived=1, not_survived=0\nsns.swarmplot(y=train_X.Parch, x=train_X.Sex, hue=train_y)","b4c7dc13":"test_full.info()","e2462d8d":"# Drop 'Cabin' from the test set\ntest_X = test_full[valid_X_full.columns.drop('Cabin')]\n\n# Fill in missing embark values with the most frequent value of the test set\nmost_freq = test_X.Embarked.mode().iloc[0]\nprint(most_freq)\ntest_X.Embarked = test_X.Embarked.fillna(most_freq)","3582d741":"# test_X.info()","95fdcf84":"# convert categorical features to numerical features using label encoder\nle = LabelEncoder()\n\nle_test_X = test_X.copy()\n\n# Encode categorical features\ns = test_X.dtypes=='object'\ncat_features = list(s[s].index)\nprint(cat_features)\n\nfor col in cat_features:\n    le_test_X[col] = le.fit_transform(test_X[col])\n    \n# le_test_X.info()","2367e135":"test_X = le_test_X\n# test_X.info()","d033ab4e":"missing_age = test_X[test_X.Age.isnull()]\nmissing_age = missing_age[missing_age.columns.drop('Age')]\nmissing_age.head()","7a343fdf":"pred_test = rf_ma_model.predict(missing_age)\noutput = pd.DataFrame({'Age': pred_test}, index=missing_age.index)\nprint(output.Age.tolist())\ntest_X = test_X.combine_first(output)\n# test_X.info()","dafeee4c":"# choose categorical features\ncols = test_X.columns\ninteractions_test = pd.DataFrame(index=test_X.index)\n\n# create the interactions for two categorical featuers at a time\nfor col1, col2 in combinations(cols, 2):\n    col_name = '_'.join([col1, col2])\n    \n    values = test_X[col1].map(str) + '_' + test_X[col2].map(str)\n    \n    encoder = preprocessing.LabelEncoder()\n    \n    interactions_test[col_name] = encoder.fit_transform(values)\n    \ninteractions_test.head()","75a7f1c3":"test_X = test_X.join(interactions_test)","b569ed01":"test_X.head()","b1474b38":"# Drop the missing fare value\ntest_X = test_X.fillna(0)","e55f2f34":"# test_X.info()","085d8a56":"pred_test = rf_model.predict(test_X)\n# pred_test","47cf8ba0":"output = pd.DataFrame({'PassengerId': test_X.index,\n                       'Survived': pred_test})\noutput.to_csv('titanic_pred2.csv', index=False)","69bda57b":"**Missing age values**","73bb8b98":"It doesn't seem like there is a relationship between age and fare, so we can't use fare to try and fill in age.","cb0b81a2":"# Cleaning the training and validation data set","9004422e":"One passenger whose embark was unknown in the training data set was Mrs. George Nelson (Martha Evelyn) Stone and she is 62 years old. A quick Google search not only tells us that she embarked from Southampton, but that she was also a widowed first class passenger in cabin B28, and paid 80 for her fare which agrees with the data above. All we have to do is fill in her embark value with 'S'. The other passenger is Mrs. Stone's personal maid, Miss Amelie Icard from France. She also embarked from Southampton with Mrs. Stone. We also saw that they were both rescued on boat 6.","814b591f":"# Eploratory Data Analysis\n\n**Missing embark value**\n\nThe Titanic left Belfast on the 2nd of April, 1912. It made its way to Southampton, England then Cherbourg in France and finally Queenstown (Cork), Ireland. These are the 3 'Embarked' values: S, C, Q. ","7e50d8b2":"**Dealing with missing 'Cabin' values**\n\nOne method would be to drop the 'Cabin' column. One discussion topic explained that first letter of the 'Cabin' related to the deck as well as the 'Pclass' of each passenger. Here, the first letters of the 'Cabin' column will be extracted and tested against the 'Pclass' of each passenger. The 'Cabin' will then be replaced by the letter that appears most frequent depending on the class of the passenger.","7e678c3c":"# Cleaning up the test data set","db5298d2":"# Setup"}}