{"cell_type":{"e1ba7e67":"code","96f9e0f4":"code","24605e18":"code","0072e3e2":"code","99730802":"code","57317bb2":"code","a5cb838f":"code","37251e52":"code","51b6bd31":"code","8e1183a4":"code","ed85c23e":"code","27ec4807":"code","37c4d7f9":"code","8d7543b9":"markdown","5b5105ce":"markdown","6af02793":"markdown","4e4477f5":"markdown","804b4094":"markdown","9aa1b7c7":"markdown","ff0e3523":"markdown","14616a43":"markdown","c69dc2e9":"markdown","e4bfc51a":"markdown","10857dc2":"markdown","2a357868":"markdown"},"source":{"e1ba7e67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","96f9e0f4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.model_selection import cross_val_score","24605e18":"stars = pd.read_csv(\"..\/input\/star-dataset\/6 class csv.csv\")\nstars.head()","0072e3e2":"stars[\"Star color\"].value_counts()","99730802":"stars[\"Star color\"] = stars[\"Star color\"].str.lower().str.replace(\" \", \"\").str.replace(\"-\", \"\")\nstars[\"Star color\"].value_counts()","57317bb2":"stars[\"Star color\"] = stars[\"Star color\"].str.replace(\"yellowishwhite\", \"yellowwhite\").str.replace(\"whiteyellow\", \"yellowwhite\").str.replace(\"whitish\", \"white\")\nstars[\"Star color\"] = stars[\"Star color\"].str.replace(\"orangered\", \"orange\").str.replace(\"paleyelloworange\", \"orange\")","a5cb838f":"stars['Star color'].value_counts()","37251e52":"stars.hist(bins=20, figsize=(20,15));","51b6bd31":"corr_mat = stars.corr()\nsns.heatmap(corr_mat, annot=True)","8e1183a4":"X = stars.drop(\"Star type\", axis=1)\ny = stars[\"Star type\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.head()","ed85c23e":"enc = OneHotEncoder(handle_unknown='ignore')\n\ncat_columns = [\"Star color\", 'Spectral Class']\nnum_columns = [\"Temperature (K)\", \"Luminosity(L\/Lo)\", \"Radius(R\/Ro)\", \"Absolute magnitude(Mv)\"]\n\none_hot = ColumnTransformer([(\"one_hot\", enc, cat_columns)], remainder=\"passthrough\")\nscaler = StandardScaler()\npreprocessor = ColumnTransformer(\n                transformers=[\n                    (\"cat\", one_hot, cat_columns),\n                    (\"scale\", scaler, num_columns)\n                ])\nmodel = Pipeline(steps=\n                [(\"preprocessor\", preprocessor),\n                (\"model\", RandomForestClassifier())\n                ])\n","27ec4807":"model.fit(X_train, y_train)","37c4d7f9":"model.score(X_test, y_test)","8d7543b9":"I am going to use a Random Forest for this problem. If that does not prove terribly useful, I will reasses and try another model.","5b5105ce":"Looks like most of the stars are actually not too different from our own sun, at least in terms of temperature, luminosity, and radius. The sun's abolute magnitude is ~4.83, so it actually exists in the region of the Absolute Magnitude plot that is less occupied by the general population.","6af02793":"So our accuracy is 1.0, which means that the model accurately classified every star in the test set. This is good, and I think for a simpler data set like this one, it is OK to leave it at that. I think was a good exercise in getting used to typing out ML code.","4e4477f5":"I am personally OK with this set up. I am willing to believe that someone legitimately classified the remaining categories as separate entities. Anyway, let's continue with the data exploration.","804b4094":"How do some of the features correlate with each other?","9aa1b7c7":"These colors are not uniform. That is, what is the difference between Blue-white and Blue White? I can fix these up and reduce the number of features. ","ff0e3523":"Now, we do need to handle the object columns so that our algorith will handle them properly.","14616a43":"It looks like there is a failr negative correlation between Absolute Magnitude and Star Type, with lots of other featues in between $\\pm 0.5$","c69dc2e9":"# Now let's get into some preprocessing.","e4bfc51a":"Mostly numerical data, but star color is a categorical data. Let's take a look at it a little closer.","10857dc2":"This has reduced the number of columns that are bad, but there are still a few weird things. This might be taking a bit of a leap, but I am of the opinion that yellowwhite, yellowishwhite, and whiteyellow are the same, and whitish can be grouped into white.","2a357868":"First, split the data into training and test data"}}