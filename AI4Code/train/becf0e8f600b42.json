{"cell_type":{"1a281834":"code","e7b5acc7":"code","631606e7":"code","128b01ee":"code","94b0ad0e":"code","72dd2b69":"code","76be77a9":"code","edbb1024":"code","34fce69c":"code","ece513aa":"code","7a26197d":"code","093a69aa":"code","90223733":"code","52fec5e4":"code","243c02e2":"code","c46c8ffd":"code","fdbb3ab4":"code","ce91ac8b":"code","265806f1":"code","972cbbce":"code","2700b0bd":"code","ae299906":"code","2ddfdecc":"code","cf6bc23f":"code","2200569c":"code","33e0b053":"code","1039d6d3":"code","a2929d9f":"code","b8782f0f":"code","468cee11":"code","9e7911e0":"code","7f0731a8":"code","3014579a":"code","160206c3":"code","bbfb3a9b":"code","6cba1b64":"code","6baf0d99":"code","a02cabfa":"code","816c855b":"code","c8d1d721":"code","9a7f2214":"markdown","fec35beb":"markdown","d61f9ee5":"markdown"},"source":{"1a281834":"# This Python 3 environment  comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e7b5acc7":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n","631606e7":"from fastai import *\nfrom fastai.vision import *\nimport pandas as pd\nimport matplotlib.pyplot as plt","128b01ee":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/tmp\/.cache\/torch\/checkpoints\/'):\n        os.makedirs('\/tmp\/.cache\/torch\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth'","94b0ad0e":"import os\nos.listdir('..\/input')","72dd2b69":"print('Make sure cudnn is enabled:', torch.backends.cudnn.enabled)","76be77a9":"PATH = Path('..\/input\/aptos2019-blindness-detection')","edbb1024":"df = pd.read_csv(PATH\/'train.csv')\ndf.head()","34fce69c":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 999\nseed_everything(SEED)","ece513aa":"base_image_dir = os.path.join('..', 'input\/aptos2019-blindness-detection\/')\ntrain_dir = os.path.join(base_image_dir,'train_images\/')\ndf = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\ndf['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\ndf = df.drop(columns=['id_code'])\ndf = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ndf.head(10)","7a26197d":"len_df = len(df)\nlen_df","093a69aa":"#checking for imbalance \ndf['diagnosis'].hist(figsize = (10, 5))","90223733":"#checking for sample images\nfrom PIL import Image\n\nim = Image.open(df['path'][1])\nwidth, height = im.size\nprint(width,height) \nim.show()","52fec5e4":"plt.imshow(np.asarray(im))","243c02e2":"bs = 64 #smaller batch size is better for training, but may take longer\nsz=224","c46c8ffd":"#resizing and transforming the images\ntfms = get_transforms(do_flip=True,flip_vert=True,max_rotate=360,max_warp=0,max_zoom=1.1,max_lighting=0.1,p_lighting=0.5)\nsrc = (ImageList.from_df(df=df,path='.\/',cols='path') #get dataset from dataset\n        .split_by_rand_pct(0.2) #Splitting the dataset\n        .label_from_df(cols='diagnosis',label_cls=FloatList) #obtain labels from the level column\n      )\ndata= (src.transform(tfms,size=sz,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') #Data augmentation\n        .databunch(bs=bs,num_workers=4) #DataBunch\n        .normalize(imagenet_stats) #Normalize     \n       )","fdbb3ab4":"data.show_batch(rows=3, figsize=(7,6))","ce91ac8b":"#Cohen's quadratically weighted kappa\n#implementation based on the scikit-learn's implementation, but converted to a pytorch tensor, as that is what fastai uses\n\nfrom sklearn.metrics import cohen_kappa_score\ndef quadratic_kappa(y_hat, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')","265806f1":"learn = cnn_learner(data, base_arch=models.resnet50, metrics = [quadratic_kappa])","972cbbce":"learn.lr_find()\n","2700b0bd":"learn.recorder.plot(suggestion=True)","ae299906":"learn.fit_one_cycle(5,max_lr = 1e-2)","2ddfdecc":"learn.recorder.plot_losses()","cf6bc23f":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","2200569c":"learn.fit_one_cycle(6, max_lr=slice(1e-6,1e-3))","33e0b053":"learn.recorder.plot_losses()\n# learn.recorder.plot_metrics()","1039d6d3":"learn.export()\nlearn.save('stage-2')","a2929d9f":"#evaluate model\ninterp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","b8782f0f":"valid_preds = learn.get_preds(ds_type=DatasetType.Valid)","468cee11":"import numpy as np\nimport pandas as pd\nimport os\nimport scipy as sp\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json","9e7911e0":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","7f0731a8":"optR = OptimizedRounder()\noptR.fit(valid_preds[0],valid_preds[1])","3014579a":"coefficients = optR.coefficients()\nprint(coefficients)","160206c3":"from fastai.core import *\nfrom fastai.basic_data import *\nfrom fastai.basic_train import *\nfrom fastai.torch_core import *\ndef _tta_only(learn:Learner, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10) -> Iterator[List[Tensor]]:\n    \"Computes the outputs for several augmented inputs for TTA\"\n    dl = learn.dl(ds_type)\n    ds = dl.dataset\n    old = ds.tfms\n    aug_tfms = [o for o in learn.data.train_ds.tfms]\n    try:\n        pbar = master_bar(range(num_pred))\n        for i in pbar:\n            ds.tfms = aug_tfms\n            yield get_preds(learn.model, dl, pbar=pbar)[0]\n    finally: ds.tfms = old\n\nLearner.tta_only = _tta_only\n\ndef _TTA(learn:Learner, beta:float=0, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10, with_loss:bool=False) -> Tensors:\n    \"Applies TTA to predict on `ds_type` dataset.\"\n    preds,y = learn.get_preds(ds_type)\n    all_preds = list(learn.tta_only(ds_type=ds_type, num_pred=num_pred))\n    avg_preds = torch.stack(all_preds).mean(0)\n    if beta is None: return preds,avg_preds,y\n    else:            \n        final_preds = preds*beta + avg_preds*(1-beta)\n        if with_loss: \n            with NoneReduceOnCPU(learn.loss_func) as lf: loss = lf(final_preds, y)\n            return final_preds, y, loss\n        return final_preds, y\n\nLearner.TTA = _TTA","bbfb3a9b":"sample_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')\nsample_df.head()","6cba1b64":"learn.data.add_test(ImageList.from_df(sample_df,'..\/input\/aptos2019-blindness-detection',folder='test_images',suffix='.png'))","6baf0d99":"preds,y = learn.TTA(ds_type=DatasetType.Test)","a02cabfa":"test_predictions = optR.predict(preds, coefficients)","816c855b":"sample_df.diagnosis = test_predictions.astype(int)\nsample_df.head()","c8d1d721":"sample_df.to_csv('submission.csv',index=False)","9a7f2214":"### TTA","fec35beb":"### optimize metrics","d61f9ee5":"### Training "}}