{"cell_type":{"324b4eeb":"code","d622718b":"code","396e0d7d":"code","34b9a636":"code","1c1a4dbf":"code","a08b9a40":"code","ff48295d":"code","afd3277c":"code","3d4eb079":"code","00acdef7":"code","46f78917":"code","aaf5321e":"markdown","75b196eb":"markdown","f2619542":"markdown","97586bbe":"markdown","151747e3":"markdown","663b6b78":"markdown","7df86cc9":"markdown","917f5913":"markdown","cf0d2e48":"markdown","97696eef":"markdown","3839b631":"markdown","ec40d4b0":"markdown","c069096f":"markdown"},"source":{"324b4eeb":"import pandas as pd\nimport numpy as np\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\nimport cv2\nfrom nltk.tokenize import TweetTokenizer,RegexpTokenizer\nimport string\nimport re","d622718b":"data=pd.read_csv('..\/input\/150-famous-movie-catchphrases-with-context\/Catchphrase.csv')\ndata.head()","396e0d7d":"mask=cv2.imread('..\/input\/multicoloredflower\/Multi coloured flower.jpg')\nmask=cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\nstopwords = set(STOPWORDS)\ncorpus=''\nfor i in data['Catchphrase'].values:\n    corpus+=' '+i\nwordcloud_spa = WordCloud(stopwords=stopwords, background_color=\"white\", max_words=1000, mask=mask).generate(corpus)\n\n# create coloring from image\nimage_colors = ImageColorGenerator(mask)\nplt.figure(figsize=[18,8])\nplt.imshow(wordcloud_spa.recolor(color_func=image_colors), interpolation=\"bilinear\")\nplt.axis(\"off\");\nplt.show();","34b9a636":"corpus=re.sub(r'(?is)[+,\":.!?]','',corpus)\ncorpus=corpus.lower()","1c1a4dbf":"# Preprocess the data\ntknzr = TweetTokenizer(strip_handles=True, reduce_len=True)\ntokens=tknzr.tokenize(corpus)\ntokens=tknzr.tokenize(corpus)","a08b9a40":"dict_df = pd.DataFrame(columns = ['lead', 'follow', 'freq'])\ndict_df['lead']=tokens\nfollow = tokens[1:]\nfollow.append('EndWord')\ndict_df['follow']=follow","ff48295d":"dict_df['freq']= dict_df.groupby(by=['lead','follow'])['lead','follow'].transform('count').copy()","afd3277c":"dict_df = dict_df.drop_duplicates()\npivot_df = dict_df.pivot(index = 'lead', columns= 'follow', values='freq')","3d4eb079":"sum_words = pivot_df.sum(axis=1)\npivot_df = pivot_df.apply(lambda x: x\/sum_words)","00acdef7":"from numpy.random import choice\ndef make_a_sentence(start,n=10):\n    word= start\n    sentence=[word]\n    while len(sentence) < n:\n        next_word = choice(a = list(pivot_df.columns), p = (pivot_df.iloc[pivot_df.index ==word].fillna(0).values)[0])\n        if next_word == 'EndWord':\n                next_word=choice(a=list(pivot_df.columns))\n                sentence.append(next_word)\n        else :\n            sentence.append(next_word)\n        word=next_word\n    sentence = ' '.join(sentence)\n    return sentence","46f78917":"sentence = make_a_sentence('know',6)\nsentence","aaf5321e":"# Hope you liked it :)","75b196eb":"## This data seems fun , so many catchphrases :) ","f2619542":"# Welcome to the world of Catchphrases","97586bbe":"![](https:\/\/media2.giphy.com\/media\/S5ciiTMG3U1Qrt1IQ6\/giphy.gif)","151747e3":"![](https:\/\/media4.giphy.com\/media\/39ChmjbAML62wn3vW9\/200.gif)","663b6b78":"<p style=\"font-family: Garamond, serif;font-size:200%;\">Well Well Well , Looking at all these cool catchphrases i wanna make one too :)\n    <li style=\"font-family: Garamond, serif;font-size:150%;\"> One Never Know Time?? <\/li>\n    <li style=\"font-family: Garamond, serif;font-size:150%;\">Time never waits for one?? <\/li><\/p>\n<p style=\"font-family: Garamond, serif;font-size:200%;\">Well these were some weird catchphrases i made using this word cloud . <br>\n    Let's make a code which can make us some cool random catchphrases on it's own\n<\/p>\n","7df86cc9":"# I'M gonna use Markov Chain To Generate Random Catchphrases","917f5913":"# Importing Data","cf0d2e48":"![](https:\/\/media1.giphy.com\/media\/3o7abDIKBIJNXtktJm\/giphy.gif)","97696eef":"![](https:\/\/i.pinimg.com\/474x\/c2\/4f\/c2\/c24fc21a2ba2f9e8847616ae0424788f.jpg)","3839b631":"# Importing Packages","ec40d4b0":"# Let's Make A word cloud of all these catchphrases","c069096f":"## Reference For Markov Chain was taken from https:\/\/towardsdatascience.com\/using-a-markov-chain-sentence-generator-in-python-to-generate-real-fake-news-e9c904e967e \n"}}