{"cell_type":{"4fea6fff":"code","4609f09d":"code","e789061c":"code","3fc2badc":"code","8885f09d":"code","9aa9f2c5":"code","dfd6c4f8":"code","831447a8":"code","5977b282":"code","0545da87":"code","beaa084d":"code","70e61d72":"code","b665f6bc":"code","0d8f4391":"code","0f0a7328":"code","90e1d0b6":"code","e8deb255":"code","2f1a1198":"code","4045ab4a":"code","a5dbace2":"code","f7d77d73":"code","d779abe5":"code","07ce311a":"code","66d8569a":"code","e0287bf9":"code","01fe34b0":"code","e18b9fb9":"markdown"},"source":{"4fea6fff":"import numpy as np\nimport pandas as pd\nimport scipy\nimport sklearn\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import mean_squared_error\n\nfrom itertools import product\n\nfrom sklearn.cluster import KMeans\n\nimport lightgbm as lgb","4609f09d":"dpath  = '..\/input\/competitive-data-science-predict-future-sales\/'\nadpath ='..\/input\/predict-future-sales\/'","e789061c":"# Basic data loading\n\ndf_train = pd.read_csv(dpath + 'sales_train.csv')\ndf_test = pd.read_csv(dpath + 'test.csv', index_col='ID')\n\ndf_shops = pd.read_csv(dpath + 'shops.csv', index_col='shop_id')\n\ndf_items = pd.read_csv(dpath + 'items.csv', index_col='item_id')\ndf_itemcat = pd.read_csv(dpath + 'item_categories.csv', index_col='item_category_id')\n\nsample_submission = pd.read_csv(dpath + 'sample_submission.csv', index_col='ID')","3fc2badc":"# Calendar\n\ncalendar = pd.read_csv(adpath + 'calendar.csv', dtype='int16')","8885f09d":"# Shops\n\ndef shop_name2city(sn):\n    sn = sn.split()[0]\n    if sn == '\u0426\u0438\u0444\u0440\u043e\u0432\u043e\u0439' or sn == '\u0418\u043d\u0442\u0435\u0440\u043d\u0435\u0442-\u043c\u0430\u0433\u0430\u0437\u0438\u043d': sn = 'Internet'\n    if sn[0] == '!': sn = sn[1:]  \n    return sn\n\ndf_shops['city'] = df_shops['shop_name'].apply(shop_name2city)\ndf_shops['city_enc'] = LabelEncoder().fit_transform(df_shops['city']).astype('int8')\n\ncity_info = pd.read_pickle(adpath + 'city_info.pkl')\n\ndf_shops['city_size'] = df_shops['city'].map(city_info['city_size'])","9aa9f2c5":"# Define items class\n\nclass Items():\n\n    def __init__(self, df_items, df_itemcat):\n        \n        self.df_items    = df_items\n        self.df_itemcat  = df_itemcat\n        \n        self.set_hl_cat()\n        self.make_items_ext()\n        \n        self.item_features = ['item_category_id', 'hl_cat_id']\n\n    def set_hl_cat(self):\n        \n        self.df_itemcat['hl_cat_id'] = self.df_itemcat['item_category_name'].str.split(n=1, expand=True)[0]\n        self.df_itemcat['hl_cat_id'] = LabelEncoder().fit_transform(self.df_itemcat['hl_cat_id'])\n        \n    def make_items_ext(self):\n    \n        self.df_items = df_items.merge(self.df_itemcat, how = 'left', \n                                       left_on = 'item_category_id', right_index = True)\n\n    def get_items_df(self):\n        \n        return self.df_items[self.item_features].astype('int32')","dfd6c4f8":"items = Items(df_items, df_itemcat)","831447a8":"# Define train-test class\n\nclass TT_Extended():\n    \n    def __init__(self, df_train, df_test, items, df_shops, calendar, cmode, verbose=True):\n        \n        self.info = verbose\n        \n        self.df_train  = df_train.copy()\n        self.df_test   = df_test.copy()\n        self.df_shops  = df_shops.copy()\n        self.calendar  = self.set_calender(calendar.copy())\n        \n        self.idx_columns = ['date_block_num', 'shop_id', 'item_id']\n        \n        self.df_test['date_block_num'] = 34\n        self.df_test['item_cnt_month'] = 0.\n        self.df_test['item_cnt_month'] = self.df_test['item_cnt_month'].astype('float32')\n        \n        self.df_train[self.idx_columns] = self.df_train[self.idx_columns].astype('int32')\n        self.df_test[self.idx_columns]  = self.df_test[self.idx_columns].astype('int32')\n        \n        self.df_train_cleaning(cmode)\n        \n        self.item_mean_features = []\n        self.shop_mean_features = []\n        self.lag_names_to_clip  = []\n        \n        self.df_items = items.get_items_df()\n        self.item_ext_features = list(self.df_items.columns)\n        self.df_items_ext = self.items_ext()\n        \n        self.df_bb = self.build_bb()\n        \n        # Critical point: 0 or None\n        self.df_train_ext = self.df_train_agg(cmin = 0, cmax = 1000, drop = None)\n        \n        self.add_test_df()\n        \n        self.df_train_ext = self.df_train_extention()\n        \n    def df_train_cleaning(self, mode):\n        \n        assert mode in ['keep', 'drop', 'block', 'total', 't+b']\n        \n        # 'keep'  - do nothing\n        # 'drop'  - drop all negative rows\n        # 'block' - remove item_id if its sum is negative in a block\n        # 'total' - remove item_id if its total sum is negative\n        # 't+b'   - 'total' + 'block'\n        \n        if self.info: print('Cleaning train dataframe... ( Mode -', mode, ')')\n         \n        # Remove very noisy shops \n        \n        shop_idx = self.df_train[(self.df_train['shop_id'] == 9)  | \n                                 (self.df_train['shop_id'] == 20)].index\n        self.df_train.drop(shop_idx, inplace=True)\n        \n        \n        self.df_train = self.df_train[(self.df_train['item_price'] > 0) & \n                                      (self.df_train['item_price'] < 51000)]\n        self.df_train = self.df_train[self.df_train['item_cnt_day'] <= 1000]\n\n        shop_repl_dict = {0 : 57, 1 : 58, 11 : 10, 40 : 39}\n    \n        self.df_train['shop_id'] = self.df_train['shop_id'].apply(\n                                   lambda s: shop_repl_dict.get(s) if s in shop_repl_dict else s)    \n            \n            \n        if   mode == 'drop':\n            self.df_train = self.df_train[self.df_train['item_cnt_day'] > 0]\n            \n        elif mode == 'block':\n            item_block_cnt = self.df_train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day'].sum()\n            items_to_drop = item_block_cnt[item_block_cnt <= 0].index\n            self.df_train = self.df_train[~self.df_train.set_index(\n                                            ['date_block_num', 'shop_id', 'item_id']).index.isin(items_to_drop)]\n        elif mode == 'total':\n            item_total_cnt = self.df_train.groupby(['shop_id', 'item_id'])['item_cnt_day'].sum()\n            items_to_drop = item_total_cnt[item_total_cnt <= 0].index\n            self.df_train = self.df_train[~self.df_train.set_index(\n                                            ['shop_id', 'item_id']).index.isin(items_to_drop)]\n            \n        elif mode == 't+b':\n            item_total_cnt = self.df_train.groupby(['shop_id', 'item_id'])['item_cnt_day'].sum()\n            items_to_drop = item_total_cnt[item_total_cnt <= 0].index\n            self.df_train = self.df_train[~self.df_train.set_index(\n                                            ['shop_id', 'item_id']).index.isin(items_to_drop)]\n            \n            item_block_cnt = self.df_train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day'].sum()\n            items_to_drop = item_block_cnt[item_block_cnt <= 0].index\n            self.df_train = self.df_train[~self.df_train.set_index(\n                                            ['date_block_num', 'shop_id', 'item_id']).index.isin(items_to_drop)]\n            \n            \n        return\n        \n    def set_calender(self, calendar):\n        \n        calendar['date_block_num'] = (calendar['year'] - 2013)*12 + (calendar['month'] - 1)\n        calendar['hdays'] = calendar['mdays'] - calendar['wdays']\n        calendar.set_index('date_block_num', inplace=True)\n        \n        return calendar\n    \n    def items_ext(self):\n        \n        dfi = self.df_items.copy()\n        \n        dfi['fsb'] = self.df_train.groupby('item_id')['date_block_num'].min()\n        \n        dfi['fsb'].fillna(34, inplace=True)\n        dfi['fsb'] = dfi['fsb'].astype('int8')\n        \n        self.item_ext_features += ['fsb']\n        \n        return dfi\n    \n    def build_bb(self):\n        \n        if self.info: print('Building index dataframe...')\n\n        df_work = []\n\n        for block_num in self.df_train['date_block_num'].unique():\n    \n            cur_shops = self.df_train.loc[self.df_train['date_block_num'] == block_num, 'shop_id'].unique()\n            cur_items = self.df_train.loc[self.df_train['date_block_num'] == block_num, 'item_id'].unique()\n    \n            df_work.append(np.array(list(product(*[[block_num], cur_shops, cur_items])), dtype='int32'))\n\n        df_work = pd.DataFrame(np.vstack(df_work), columns = self.idx_columns)\n            \n        return df_work\n    \n    def df_train_agg(self, cmin = 0, cmax = 20, drop = None):\n        \n        if self.info: print('Aggregation...')\n        \n        df_work = self.df_train.groupby(self.idx_columns).agg({'item_price'  : np.mean, \n                                                               'item_cnt_day': np.sum})\n        df_work.reset_index(inplace=True)\n        df_work = df_work.rename(columns={'item_cnt_day': 'item_cnt_month'})\n        \n        df_work = pd.merge(self.df_bb, df_work, on=self.idx_columns, how='left')\n        \n        df_work['item_cnt_month'] = df_work['item_cnt_month'].astype('float32').fillna(0.).clip(cmin, cmax)\n        df_work['item_price'] = df_work['item_price'].astype('float32').fillna(0.)\n        \n        df_tmp = self.df_train[self.df_train['item_cnt_day'] > 0].groupby(self.idx_columns).agg({'item_cnt_day': 'count'})\n        df_tmp.reset_index(inplace=True)\n        df_tmp = df_tmp.rename(columns={'item_cnt_day': 'item_rate_month'})\n        \n        df_work = pd.merge(df_work, df_tmp, on=self.idx_columns, how='left')\n        \n        df_work['item_rate_month'] = df_work['item_rate_month'].astype('float32').fillna(0.)\n        \n        del df_tmp\n        \n        if drop: df_work.drop(drop, axis=1, inplace=True)\n        \n        return df_work\n    \n    def add_test_df(self):\n        \n        self.df_train_ext = pd.concat([self.df_train_ext, self.df_test], ignore_index=True,\n                                      sort=False, keys=self.idx_columns)\n    \n    def add_item_means(self, df, feature = None):\n        \n        # Adding item means\n        \n        if feature == None :\n            group_items = ['date_block_num','item_id']\n            feature = 'item_cnt'\n        else:\n            group_items = ['date_block_num','item_id'] + [feature]\n            \n        feature_mean_name = feature + '_mean'\n            \n        if self.info: print('Adding item means for', feature, '...')\n        \n        df_tmp = df.groupby(group_items)['item_cnt_month'].mean()\n        df_tmp = df_tmp.reset_index().rename(columns = {'item_cnt_month': feature_mean_name})\n        \n        df = pd.merge(df, df_tmp, on=group_items, how='left')\n        \n        self.item_mean_features.append(feature_mean_name)\n        \n        del df_tmp\n        \n        return df\n    \n    def add_shop_means(self, df, feature):\n        \n        # Adding shop means\n        \n        group_items = ['date_block_num', 'shop_id'] + [feature]\n            \n        feature_mean_name = feature + '_mean'\n            \n        if self.info: print('Adding shop means for', feature, '...')\n        \n        df_tmp = df.groupby(group_items)['item_cnt_month'].mean()\n        df_tmp = df_tmp.reset_index().rename(columns = {'item_cnt_month': feature_mean_name})\n        \n        df = pd.merge(df, df_tmp, on=group_items, how='left')\n        \n        self.shop_mean_features.append(feature)\n        \n        del df_tmp\n        \n        return df\n        \n    \n    def df_train_extention(self, test_cat_only = False):\n        \n        df_work = self.df_train_ext.merge(df_shops[['city_enc', 'city_size']], how = 'left', on = 'shop_id')\n        \n        df_work = df_work.merge(self.calendar[['mdays', 'wdays', 'hdays']], \n                                how = 'left', left_on = 'date_block_num', right_index = True)\n        \n        df_work = df_work.merge(self.df_items_ext[self.item_ext_features],\n                                how = 'left', left_on = 'item_id', right_index = True)\n        \n        # Shop start block number\n        \n        ssbn = self.df_train.groupby('shop_id')['date_block_num'].min().astype('int8')\n        ssbn.name = 'ssbn'\n        df_work = df_work.merge(ssbn, how = 'left', on = 'shop_id')\n        \n        if test_cat_only:\n            test_cat = df_work[df_work['date_block_num'] == 34]['item_category_id'].unique()\n            df_work = df_work[df_work['item_category_id'].isin(test_cat)]\n\n        return df_work\n    \n    def make_base_df(self, keepnans = False):\n        \n        # Make base dataframe\n        \n        df_work = self.df_train_ext.copy()\n        \n        if keepnans:\n            fill_value = None\n        else:\n            fill_value = 0    \n            \n        df_work = pd.pivot_table(df_work, values='item_cnt_month', index=['shop_id', 'item_id'], \n                                     columns = 'date_block_num', aggfunc=np.sum, fill_value = fill_value)\n        df_work.columns.name = ''\n        \n        return df_work\n    \n    def add_total_cnt(self, df):\n        \n        if self.info: print('Adding total count...')\n        \n        df_base = self.make_base_df()\n        \n        for i in range(1, 33):\n            df_base[i + 1] += df_base[i]\n            \n        df_base = df_base.shift(1, axis=1).loc[:, 1:].astype('int32')\n        df_base = df_base.melt(var_name='date_block_num', value_name='total_cnt', ignore_index=False)\n        \n        df = df.merge(df_base, how='left', on=self.idx_columns)\n        \n        del df_base\n        \n        return df\n    \n    def add_item_lags(self, df, feature_name, nlags=3, keepnans=False, dnc=False):\n        \n        if self.info: print('Adding item lags for', feature_name, '...')\n    \n        df_tmp = df[['date_block_num', 'shop_id', 'item_id', feature_name]]\n    \n        for i in range(nlags, 0, -1):\n        \n            lag_feature_name = feature_name +'_lag-' + str(i)\n            if not dnc: self.lag_names_to_clip.append(lag_feature_name)\n        \n            df_shifted = df_tmp.copy()\n            df_shifted.columns = ['date_block_num', 'shop_id', 'item_id', lag_feature_name]\n            df_shifted['date_block_num'] += i\n            df = pd.merge(df, df_shifted, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n            \n            if keepnans:\n                df[lag_feature_name] = df[lag_feature_name].astype('float32')\n            else:\n                df[lag_feature_name] = df[lag_feature_name].fillna(0).astype('float32')\n        \n        del df_tmp\n    \n        return df\n    \n    def add_shop_lags(self, df, feature_name, nlags=3, dnc=False):\n        \n        mean_feature_name = feature_name + '_mean'\n        \n        if self.info: print('Adding lags for', mean_feature_name, '...')\n    \n        df_tmp = df[['date_block_num', 'shop_id', feature_name, mean_feature_name]]\n    \n        for i in range(nlags, 0, -1):\n        \n            lag_feature_name = mean_feature_name + '_lag-' + str(i)\n            if not dnc: self.lag_names_to_clip.append(lag_feature_name)\n        \n            df_shifted = df_tmp.copy()\n            df_shifted.columns = ['date_block_num', 'shop_id', feature_name, lag_feature_name]\n            df_shifted['date_block_num'] += i\n            df = pd.merge(df, df_shifted.drop_duplicates(), on=['date_block_num', 'shop_id', feature_name], how='left')\n            df[lag_feature_name] = df[lag_feature_name].fillna(0).astype('float32')\n        \n        del df_tmp\n        del df_shifted\n    \n        return df\n    \n    def shop_clustering(self, df_work):\n        \n        # Clustering algorithm can be defined at run time\n        \n        print('No shop clusters provided')\n        \n        return df_work\n    \n    def build_work_db(self, hd, item_mean_features = [], shop_mean_features = [], add_total_cnt = False):\n        \n        if self.info: print('Building work dataframe...')\n        \n        df_work = self.df_train_ext.copy()\n        \n        df_work = self.add_item_means(df_work)\n        \n        for mf in item_mean_features:\n            \n            df_work = self.add_item_means(df_work, mf)\n            \n        for mf in shop_mean_features:\n            \n            df_work = self.add_shop_means(df_work, mf)\n        \n        # Critical point: True or False (Affects qmean calculation)\n        df_work = self.add_item_lags(df_work, 'item_cnt_month', hd, keepnans=False)\n        df_work = self.add_item_lags(df_work, 'item_rate_month', hd, dnc=True)\n        df_work = self.add_item_lags(df_work, 'item_price', hd, dnc=True)\n            \n        for mf in self.item_mean_features:\n            \n            df_work = self.add_item_lags(df_work, mf, hd)\n            \n        for mf in self.shop_mean_features:\n            \n            df_work = self.add_shop_lags(df_work, mf, hd)\n        \n        df_work.drop(df_work[df_work['date_block_num'] < hd].index, inplace=True)\n        \n        df_work.drop(self.item_mean_features, axis=1, inplace=True)\n        df_work.drop(['item_category_id_mean', 'item_price', 'item_rate_month'], axis=1, inplace=True)\n        \n        self.item_mean_features = []\n        self.shop_mean_features = []\n        \n    \n        df_work['qmean'] = df_work[['item_cnt_month_lag-1', \n                                    'item_cnt_month_lag-2', \n                                    'item_cnt_month_lag-3']].mean(skipna=True, axis=1)\n        \n        df_work['new'] = df_work['fsb'] ==  df_work['date_block_num']\n        \n        df_work['fsb'] = df_work['date_block_num'] - df_work['fsb']\n        df_work['ssbn'] = df_work['date_block_num'] - df_work['ssbn']\n        \n        df_work['month'] = (df_work['date_block_num']%12).astype('int8')\n        \n        \n        idx = df_work[(df_work['item_price_lag-1'] == 0) & (df_work['item_price_lag-2'] != 0)].index\n        df_work.loc[idx, 'item_price_lag-1'] = df_work.loc[idx, 'item_price_lag-2']\n        idx = df_work[(df_work['item_price_lag-2'] == 0) & (df_work['item_price_lag-3'] != 0)].index\n        df_work.loc[idx, 'item_price_lag-2'] = df_work.loc[idx, 'item_price_lag-3']\n        \n        df_work['grad-1'] = df_work['item_cnt_month_lag-1']\/df_work['item_cnt_month_lag-2']\n        df_work['grad-1'] = df_work['grad-1'].replace([np.inf, -np.inf], np.nan).fillna(0.)\n\n        df_work['grad-2'] = df_work['item_cnt_month_lag-2']\/df_work['item_cnt_month_lag-3']\n        df_work['grad-2'] = df_work['grad-2'].replace([np.inf, -np.inf], np.nan).fillna(0.)\n        \n        # Shop clustering\n        \n        df_work = self.shop_clustering(df_work)\n        \n        # Moving total\n        \n        if add_total_cnt: df_work = self.add_total_cnt(df_work)\n            \n        # Clipping    \n  \n        col2clip = ['item_cnt_month', 'qmean'] + self.lag_names_to_clip\n        df_work[col2clip] = df_work[col2clip].clip(0, 20)\n        \n        return df_work\n    \n    def get_work_db(self, hd = 3, item_mean_features = [], \n                                  shop_mean_features = [], \n                                  drop_features = None,\n                                  add_total_cnt = False):\n        \n        df_work = self.build_work_db(hd, item_mean_features, shop_mean_features, add_total_cnt)\n\n        if drop_features == None:\n            return df_work\n        else:\n            return df_work.drop(drop_features, axis = 1)","5977b282":"%%time\n\npfs = TT_Extended(df_train, df_test, items, df_shops, calendar, cmode='total')","0545da87":"pfs.df_train_ext.info()","beaa084d":"#-----------------------------------------------------","70e61d72":"# Define shop clustering methods\n\ndef simple_shop_clustering(df_work):\n    \n    noisy_shops = [25, 31, 42]\n    df_work['shop_group'] = df_work['shop_id'].isin(noisy_shops)\n    \n    return df_work\n\ndef knn_shop_clustering(df_work):\n    \n    df_sg = pd.pivot_table(df_work[df_work['item_cnt_month'] != 0], \n                           values='item_cnt_month', index=['shop_id'], \n                           columns = 'date_block_num', aggfunc='count', fill_value = 0)\n    \n    kmeans = KMeans(n_clusters=6, random_state=0).fit(df_sg)\n    df_sg['shop_group'] = kmeans.labels_.astype('int8')\n    df_work['shop_group'] = df_work['shop_id'].map(df_sg['shop_group'])\n    \n    del df_sg\n    \n    assert list(df_work[df_work['shop_group'].isna()]['shop_id'].unique()) == [], 'Missing shop found'\n    \n    return df_work","b665f6bc":"pfs.shop_clustering = simple_shop_clustering","0d8f4391":"%%time\n\ndf_work = pfs.get_work_db(hd = 3, \n                          item_mean_features = ['city_enc'], \n                          shop_mean_features = ['item_category_id'], \n                          drop_features = ['wdays', 'hdays', 'ssbn'],\n                          add_total_cnt = False).copy()","0f0a7328":"df_work.info()","90e1d0b6":"#-----------------------------------------------------","e8deb255":"# New features to test","2f1a1198":"df_work['city_size'] = df_work['city_size'].round(1) # less noisy","4045ab4a":"#-----------------------------------------------------","a5dbace2":"# Train","f7d77d73":"X_train = df_work[df_work.date_block_num < 33].drop(['item_cnt_month'], axis=1)\ny_train = df_work[df_work.date_block_num < 33]['item_cnt_month']\nX_valid = df_work[df_work.date_block_num == 33].drop(['item_cnt_month'], axis=1)\ny_valid = df_work[df_work.date_block_num == 33]['item_cnt_month']\nX_test = df_work[df_work.date_block_num == 34].drop(['item_cnt_month'], axis=1)","d779abe5":"X_train.info()","07ce311a":"# This cell was added to deal with Kaggle VM memory limitation\ndel df_work","66d8569a":"%%time\n\nfeature_names = X_train.columns.tolist()\n\nparams = {\n    'objective': 'mse',\n    'metric': 'rmse',\n    'num_leaves':100,\n    'learning_rate': 0.0001,\n    'feature_fraction': 0.5,\n    'bagging_fraction': 0.5,\n    'bagging_freq': 5,\n    'n_estimators':1000,\n    'seed': 1,\n    'verbose': 1,\n    #'device':'gpu',\n    'force_row_wise' : True\n}\n\ncategorical_feature_names = [ \n                            'item_category_id',\n                            'hl_cat_id', \n                            'city_enc',\n                            'month',\n                            'shop_group',\n                            'shop_id'\n                            ]\n\nlgb_train = lgb.Dataset(X_train[feature_names], y_train, categorical_feature=None)\nlgb_eval  = lgb.Dataset(X_valid[feature_names], y_valid, categorical_feature=None, reference=lgb_train)\n\nevals_result = {}\ngbm = lgb.train(\n        params, \n        lgb_train,\n        num_boost_round = 10000,\n        valid_sets = (lgb_train, lgb_eval), \n        feature_name = feature_names,\n        categorical_feature = categorical_feature_names,\n        verbose_eval = 200, \n        evals_result = evals_result,\n        early_stopping_rounds = 1000)","e0287bf9":"lgb.plot_importance(\n    gbm, \n    max_num_features=50, \n    importance_type='gain', \n    figsize=(12,8));","01fe34b0":"sample_submission['item_cnt_month'] = gbm.predict(X_test[feature_names]).clip(0, 20)\nsample_submission.to_csv('submission_k4.csv')","e18b9fb9":"This is the core part of my framework I use to test different ideas and features. I didn't include all the code as it would make the competition less exciting. "}}