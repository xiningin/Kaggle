{"cell_type":{"2dd82e98":"code","df3d61a7":"code","46f60d35":"code","d3bb8f16":"code","2f14ccd8":"code","6f97fbf4":"code","6fcbebad":"code","6d9a4e06":"code","17f91a26":"code","2bc13880":"code","65d3ae45":"code","7f85ee4e":"code","55a8d036":"code","ae6028fc":"code","be9ff130":"code","961e00b5":"code","3ceaf3f6":"code","c6856cf4":"code","e58851f5":"code","1360363c":"code","155acea8":"code","dbb0a1a3":"code","b6bffbc0":"code","d8e28d9a":"code","68f125f3":"code","10f26707":"code","80b79419":"code","40b9e20f":"code","7663091e":"code","34218261":"markdown","bcd7bfb0":"markdown","bd795388":"markdown","645d8bf3":"markdown","b97aed03":"markdown","0c1b7eeb":"markdown","7126636b":"markdown","7307f9d2":"markdown","6803b3cb":"markdown","97191b88":"markdown","64b17df6":"markdown","b85c351a":"markdown","5dc6382f":"markdown","f88d0a78":"markdown","0bee1eed":"markdown","e0a6c544":"markdown"},"source":{"2dd82e98":"# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","df3d61a7":"# Loading the data\ndata = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\ndata.head(5)","46f60d35":"data.info()","d3bb8f16":"data.hist(bins=50, figsize=(20,15))","2f14ccd8":"data.describe()","6f97fbf4":"# Visualisation of corellations between columns\ncorr_matrix = data.corr()\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.heatmap(data.corr(), cmap=sns.diverging_palette(240, 10, n=9), annot = True, ax = ax, center = 0)","6fcbebad":"# Correlations between target and other columns\ncorr_matrix['output'].sort_values()","6d9a4e06":"# Separating target column and create train and test sets.\ncol_names = ['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n       'exng', 'oldpeak', 'slp', 'caa', 'thall']\nX = data[col_names]\ny = data['output']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)","17f91a26":"# Normalization of data\nfrom sklearn import preprocessing\nsca = preprocessing.StandardScaler()\nX_train = pd.DataFrame(sca.fit_transform(X_train),columns = col_names)\nX_test = pd.DataFrame(sca.fit_transform(X_test),columns = col_names)","2bc13880":"from sklearn.model_selection import cross_val_score\n# Function to print data scores of model\ndef print_scores (model):\n    if str(type(model)) == \"<class 'sklearn.model_selection._search.GridSearchCV'>\":\n        roc = cross_val_score(model.best_estimator_, X_train, y_train, cv=7, scoring ='roc_auc')\n        recall = cross_val_score(model.best_estimator_, X_train, y_train, cv=7, scoring ='recall')\n        print (model.estimator)\n    else:\n        print(model)\n        roc = cross_val_score(model, X_train, y_train, cv=7, scoring ='roc_auc')\n        recall = cross_val_score(model, X_train, y_train, cv=7, scoring ='recall') \n    print (\"Scores on training data:\")\n    print (\"ROC AUC : {}\".format(roc.mean()))\n    print (\"Recall : {}\".format(recall.mean()))\n# Function to print test scores of model\nfrom sklearn import metrics\ndef print_final_scores (model):\n    if str(type(model)) == \"<class 'sklearn.model_selection._search.GridSearchCV'>\":\n        final_predictions = model.best_estimator_.predict(X_test)\n        print (model.estimator)\n    else: \n        final_predictions = model.predict(X_test)\n    roc = metrics.roc_auc_score(final_predictions, y_test)\n    recall = metrics.recall_score(final_predictions, y_test)\n    print (\"Scores on test data:\")\n    print (\"ROC AUC : {}\".format(roc))\n    print (\"Recall : {}\".format(recall))","65d3ae45":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'class_weight': [None, 'balanced'], \n     'max_features': [5, 6, 7, 8, 10, None], 'bootstrap': [True, False]}]\n\nrnd_clf = RandomForestClassifier(n_estimators = 100)\nrnd_clf_grid = GridSearchCV(rnd_clf, param_grid, cv=7, scoring = 'roc_auc', return_train_score=True)\nrnd_clf_grid.fit(X_train, y_train)","7f85ee4e":"rnd_clf_grid.best_params_","55a8d036":"print_scores (rnd_clf_grid)","ae6028fc":"print_final_scores(rnd_clf_grid)","be9ff130":"rnd_clf = RandomForestClassifier(n_estimators = 200, **rnd_clf_grid.best_params_, min_samples_leaf =50)\nrnd_clf.fit(X_train, y_train)","961e00b5":"print_scores (rnd_clf)","3ceaf3f6":"print_final_scores (rnd_clf)","c6856cf4":"# Let's check which features was most important for the model.\nfeat_importances = pd.Series(rnd_clf.feature_importances_, index=X.columns)\nfeat_importances.nlargest(13).plot(kind='barh')","e58851f5":"from sklearn.neighbors import KNeighborsClassifier\nparam_grid = [ {'n_neighbors' : [2,3,5,7,10,12,13,14], 'metric' : ['minkowski', 'euclidean', 'manhattan'], \n                'weights':['uniform','distance']}]\nknc = KNeighborsClassifier()\nknc_grid = GridSearchCV(knc, param_grid, cv=7, scoring = 'roc_auc', return_train_score=True)\nknc_grid.fit(X_train, y_train)","1360363c":"knc_grid.best_params_","155acea8":"print_scores (knc_grid)","dbb0a1a3":"print_final_scores(knc_grid)","b6bffbc0":"from sklearn.svm import SVC\nparam_grid = [ {'class_weight' : [None, 'balanced'], \n                'decision_function_shape':['ovr','ovo'], 'tol' : [0.001, 0.002]}]\nsvc = SVC(probability = True)\nsvc_grid = GridSearchCV(svc, param_grid, cv=7, scoring = 'roc_auc', return_train_score=True)\nsvc_grid.fit(X_train, y_train)","d8e28d9a":"svc_grid.best_params_","68f125f3":"print_scores (svc_grid)","10f26707":"print_final_scores (svc_grid)","80b79419":"from sklearn.ensemble import VotingClassifier\nvoting_clf = VotingClassifier(\nestimators = [('Random_forest', rnd_clf), (\"KNeighbours\", knc_grid.best_estimator_), \n              (\"SVC\", svc_grid.best_estimator_)], voting = 'soft')\nvoting_clf.fit(X_train, y_train)","40b9e20f":"print_scores (voting_clf)","7663091e":"print_final_scores(voting_clf)","34218261":"Voting classifier achieve scores exactly like KNeighbours suggesting that this classifier was the best predictor for every data point in this data set.","bcd7bfb0":"# Voting Classifier","bd795388":"All three classifier above was quite good achieving AUC value on test data around 0.88. I'll create Voting classifier which will combine all three models above.","645d8bf3":"There is 9 percent disrepency between training data and test data suggesting overfitting, setting min_samples_leaf = 50 for a better generalisation.","b97aed03":"# Measure metrics","0c1b7eeb":"For measure metrics I choose area under the curve and recall, AUC for comparing models, recall because false negative in Hearth Attack risk categorisation would be fatal.","7126636b":"# Hearth Attack Prediction","7307f9d2":"Goal : Build model which classify patients to either 'High Risk of Hearth Attack' category or 'Low Risk of Hearth Attack' Category, also explore which patient parameters strongly affects patients categorization.","6803b3cb":"# EDA","97191b88":"# Creating test and training data, standarisation","64b17df6":"# About data:","b85c351a":"About data set\nThe \"output\" field refers to the presence of heart disease in the patient. <br>\nIt is integer valued 0 = no\/less chance of heart attack and 1 = more chance of heart attack<br>\n\nAttribute Information<br>\n1) age n<br>\n2) sex:<br>\n&emsp;0: female<br>\n    &emsp;1: male<br>\n3) cp - chest pain type (4 values):<br>\n    &emsp;1: typical angina<br>\n    &emsp;2: atypical angina<br>\n    &emsp;3: non-anginal pain<br>\n    &emsp;4: asymptomatic<br>\n4) trtbps - resting blood pressure (in mm Hg)<br>\n5) chol -  serum cholestoral in mg\/dl<br>\n6) fbs - fasting blood sugar<br>\n    &emsp;0 : >= 120 mg\/dl<br>\n    &emsp;1 : <= 120 mg\/dl<br>\n7) restecg - resting electrocardiographic results (values 0,1,2)<br>\n    &emsp;0: normal<br>\n    &emsp;1: having ST-T wave abnormality<br>\n    &emsp;2: showing probable or definite left ventricular hypertrophy<br>\n8) thalachh - maximum heart rate achieved<br>\n9) exng - exercise induced angina:<br>\n    &emsp;0: yes<br>\n    &emsp;1: no<br>\n10) oldpeak - ST depression induced by exercise relative to rest<br>\n11) slp - the slope of the peak exercise ST segment<br>\n    &emsp;1: upsloping<br>\n    &emsp;2: flat<br>\n    &emsp;3: downsloping<br>\n12) caa - number of major vessels (0-3) colored by flourosopy<br>\n13) thall - thalassemia- <br>\n    &emsp;0 : normal<br>\n    &emsp;1 : fixed defect <br>\n    &emsp;2 : reversable defect<br>\n14) output: <br>\n    &emsp;0 : less chance of heart attack <br>\n    &emsp;1 : more chance of heart attack<br","5dc6382f":"# KNeighbors","f88d0a78":"# SVC","0bee1eed":"Because the dataset is relatively small i will use param grid for every model to find optimal parameters and cross-validate to avoid overfitting.","e0a6c544":"# Random Forest"}}