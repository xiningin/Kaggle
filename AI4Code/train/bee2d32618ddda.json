{"cell_type":{"544e3ad7":"code","e195a07e":"code","8e95221e":"code","da7e90e3":"code","61cb78f3":"code","9bfd2cf7":"code","6f7c814f":"code","9567aec2":"code","e34395ed":"code","23e5aa90":"code","2d53fae8":"code","da5da65a":"code","92664e48":"code","1c1458f1":"code","156fcd86":"code","606e476c":"code","3e6ab4bf":"code","b3257c0c":"code","98cfa447":"code","daca556d":"code","ad52c0e1":"code","12ee4877":"code","ae9bced9":"code","eb91fa86":"code","9ba12524":"code","ef5e088e":"code","d0f3c059":"code","2018b7a9":"code","005e5666":"code","2fc67eee":"code","d604e206":"code","1762adca":"code","4640b593":"code","f1b75053":"code","ddd50e8b":"code","5e38920f":"code","434c0455":"code","f7bb5345":"code","47762f98":"code","bc10324c":"code","5f890afd":"code","22ec1765":"code","e6babfa8":"markdown","ba360731":"markdown","de70cb45":"markdown","9f31007e":"markdown","bcc698c9":"markdown","887fa94d":"markdown","4185310f":"markdown","5c98f23b":"markdown","74d9d684":"markdown","27e1cb52":"markdown","4cc38405":"markdown","a7789502":"markdown","7d5556ae":"markdown","d56ea468":"markdown","3c5f02f2":"markdown","27932a93":"markdown","e39f2ba5":"markdown","08230067":"markdown","406ee3ca":"markdown","b8677175":"markdown","2eb42004":"markdown","e90bd240":"markdown","d6056588":"markdown","64b687db":"markdown","6762112a":"markdown","043f0169":"markdown","3afb36e6":"markdown","f7b61a87":"markdown","4d9229a5":"markdown","f1b9c4ae":"markdown","7c85c960":"markdown","7094bda2":"markdown","c59cbd00":"markdown","c643e31a":"markdown"},"source":{"544e3ad7":"pip install visualkeras","e195a07e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport visualkeras\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nimport pydot\nimport graphviz\nfrom PIL import Image","8e95221e":"train_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntest_df = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","da7e90e3":"train_df.head()","61cb78f3":"test_df.head()","9bfd2cf7":"classes = {0 : 'T-shirt\/top',\n1 :  'Trouser',\n2 : 'Pullover',\n3 : 'Dress',\n4 : 'Coat',\n5 : 'Sandal',\n6 : 'Shirt',\n7 : 'Sneaker',\n8 : 'Bag',\n9 : 'Ankle boot'}","6f7c814f":"train_df['label_names'] = train_df['label'].map(classes)\n\nplt.figure(figsize=(10,6))\nsns.countplot(x = 'label_names', data = train_df, facecolor=(0, 0, 0, 0),\n                   linewidth=5,\n                   edgecolor=sns.color_palette(\"dark\", 3))\nplt.xlabel('Class Names')\nplt.ylabel('Count')\nplt.title('Distribution of Training set images wrt classes')\nplt.show()","9567aec2":"test_df['label_names'] = test_df['label'].map(classes)\n\nplt.figure(figsize=(10,6))\nsns.countplot(x = 'label_names', data = test_df, facecolor=(0, 0, 0, 0),\n                   linewidth=5,\n                   edgecolor=sns.color_palette(\"dark\", 3))\nplt.xlabel('Class Names')\nplt.ylabel('Count')\nplt.title('Distribution of Test set images wrt classes')\nplt.show()","e34395ed":"train_df.shape","23e5aa90":"test_df.shape","2d53fae8":"X_train = train_df.drop(['label', 'label_names'], axis = 1)\ny_train = train_df.label","da5da65a":"X_test = test_df.drop(['label', 'label_names'], axis = 1)\ny_test = test_df.label","92664e48":"X_train = X_train.values.reshape(X_train.shape[0], 28, 28)\nX_test = X_test.values.reshape(X_test.shape[0], 28, 28)","1c1458f1":"X_train.shape","156fcd86":"X_test.shape","606e476c":"single_image = X_train[1]\nplt.imshow(single_image)","3e6ab4bf":"y_train","b3257c0c":"y_cat_train = to_categorical(y_train, num_classes= 10)\ny_cat_test = to_categorical(y_test, num_classes= 10)","98cfa447":"y_cat_train[0]","daca556d":"def plot_digit(digit, dem = 28, font_size = 12):\n    max_ax = font_size * dem\n    \n    fig = plt.figure(figsize=(13, 13))\n    plt.xlim([0, max_ax])\n    plt.ylim([0, max_ax])\n    plt.axis('off')\n    black = '#000000'\n    \n    for idx in range(dem):\n        for jdx in range(dem):\n\n            t = plt.text(idx * font_size, max_ax - jdx*font_size, digit[jdx][idx], fontsize = font_size, color = black)\n            c = digit[jdx][idx] \/ 255.\n            t.set_bbox(dict(facecolor=(c, c, c), alpha = 0.5, edgecolor = 'black'))\n            \n    plt.show()","ad52c0e1":"plot_digit(X_train[1])","12ee4877":"X_train = X_train\/255\nX_test = X_test\/255","ae9bced9":"X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","eb91fa86":"X_train.shape","9ba12524":"X_test.shape","ef5e088e":"X_train, X_val, y_cat_train, y_val = train_test_split(X_train, y_cat_train, test_size=0.2, random_state=42)","d0f3c059":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size= (4,4), padding = 'same', input_shape = (28,28,1), activation= 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 64, kernel_size= (4,4), padding = 'same', input_shape = (28,28,1), activation= 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(rate = 0.3))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 128, kernel_size= (4,4), padding = 'same', input_shape = (28,28,1), activation= 'relu'))\nmodel.add(Conv2D(filters = 128, kernel_size= (4,4), padding = 'same', input_shape = (28,28,1), activation= 'relu'))\nmodel.add(Dropout(rate = 0.3))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(rate = 0.3))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(rate = 0.3))\nmodel.add(Dense(10, activation='softmax'))\n\nopt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n\nmodel.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])","2018b7a9":"model.summary()","005e5666":"visualkeras.layered_view(model)","2fc67eee":"early_stop = EarlyStopping(monitor = 'val_loss', patience = 18)","d604e206":"model.fit(x = X_train, y = y_cat_train, batch_size = 128, epochs = 100, validation_data = (X_val, y_val), \n         callbacks = [early_stop])","1762adca":"metrics = pd.DataFrame(model.history.history)","4640b593":"metrics.head()","f1b75053":"metrics[['loss', 'val_loss']].plot()","ddd50e8b":"metrics[['accuracy', 'val_accuracy']].plot()","5e38920f":"model.metrics_names","434c0455":"model.evaluate(X_test, y_cat_test, verbose = 0)","f7bb5345":"predictions = model.predict(X_test)\nX_test_reshape = X_test.reshape(X_test.shape[0], 28, 28)\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test_reshape[i], cmap='binary')\n    ax.set(title = f\"Real Class is {classes[y_cat_test[i].argmax()]}\\nPredict Class is {classes[predictions[i].argmax()]}\");","47762f98":"predictions = model.predict(X_test)\n# Convert predictions classes to one hot vectors \npredictions_classes = np.argmax(predictions, axis = 1)\n# Convert test set observations to one hot vectors\ny_true = np.argmax(y_cat_test, axis = 1)","bc10324c":"print(classification_report(y_true, predictions_classes))","5f890afd":"print(confusion_matrix(y_true, predictions_classes))","22ec1765":"plt.figure(figsize = (12, 8))\nsns.heatmap(confusion_matrix(y_true, predictions_classes), annot=True)","e6babfa8":"**References:-**\n* plot_digit() from [https:\/\/www.kaggle.com\/jedrzejdudzicz\/mnist-dataset-100-top-6](http:\/\/)\n* visualkeras from [https:\/\/www.kaggle.com\/rutvikdeshpande\/fashion-mnist-cnn-beginner-98](http:\/\/)\n* dataset from [https:\/\/www.kaggle.com\/zalando-research\/fashionmnist](http:\/\/)","ba360731":"# Fashion MNIST\n\nI'm going to explain in this notebook the step-by-step proces of **image preprocessing** and training a **Convolutional Neural Network**. The dataset which I've taken is [Fashion MNIST](https:\/\/www.kaggle.com\/zalando-research\/fashionmnist)\n\n\n**Table of Content:-**\n* [Importing required libraries and training and test data](#section-import)\n* [Classes distribution visualization](#section-classes)\n* [Image Data Preprocessing](#section-pre)\n* [Training a Convolutional Neural Network](#section-nn)\n* [Visualizing accuracy and loss metric](#section-acc)\n* [Visualizing true and predicted classes](#section-true)\n* [Classification Report and Confusion Matrix](#section-class)","de70cb45":"**We're gonna use the second method**","9f31007e":"*Visualizing the network*","bcc698c9":"OK, now back to data preprocessing. We're gonna convert our data from **class vector to a binary matrix**. So, we're gonna use Keras's **to_categorical** method to **convert our labels into one-hot vectors**.","887fa94d":"**Evaluating the model on the test set**","4185310f":"<a id=\"section-true\"><\/a>\n**Let's visualize the true and predicted classes**","5c98f23b":"# If you like my notebook, don't forget to upvote ;)","74d9d684":"<a id=\"section-import\"><\/a>\n*Importing training and test datasets*","27e1cb52":"***Storing the labels in a dictionary***","4cc38405":"Now we're going to normalize our images. Right now the pixel values ranges from **0** to **255**, where **255 represents the lighest colour cell** and **0 represents the darkest colour cell**. We're gonna convert them into the values from **0 to 1**. ","a7789502":"**filters:-** how many filters to apply on an image\n\n**kernel_size:-** size of the matrix which strides through the whole image\n\n**stride:-** (x,y) steps while moving the kernel\n\n**padding:-** Padding is the extra layer we add to the corner of the image to prevent shrinkage and loss of info, such as add a padding of 0 on the outside of the image matrix, so that the corner matrix is also covered more than once while striding.\n\n**flatten:**- flattens our layer, eg, our image is 28x28 so the flattened image will be 28*28=784 pixels.\n\n**dropout:-** It is a regularization technique which shuts off neurons randomly at each epoch to prevent overfitting.Here we've set rate to 0.3, so it means that 30% of neurons will be shut off randomly while training at each epoch.\n\n**batch normalization:-** this technique makes neural networks faster and more stable through normalization of the input layer by re-centering and re-scaling.\n\n**Adam:-** Adam is an optimizer used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses.","7d5556ae":"<a id=\"section-classes\"><\/a>\n**Let's map these classes to the training and test dataframes to visualize the distribution of different labels**","d56ea468":"**Precision:-** Precision is the number of positive class predictions that actually belong to the positive class.\n\n**Recall:-** Recall is the number of positive class predictions made out of all positive examples in the dataset.\n\n**F1-score:-** It provides a single score that balances both the concerns of precision and recall in one number.","3c5f02f2":"**Now let's structure our Convolutional Neural Network model which we will train**","27932a93":"<a id=\"section-pre\"><\/a>\n**Let's prepare our data for preprocessing. First, we're going to divide training and test sets into features and labels.**","e39f2ba5":"**Let's check the shapes again**","08230067":"*I'm going to visualize that **Ankle shoe** image in the form of pixels now*","406ee3ca":"**Now we're gonna add a colour channel. Since the images are grey scale, we'll add 1 colour channel**","b8677175":"**Confusion Matrix:-** It is a tabular summary of the number of correct and incorrect predictions made by a classifier.","2eb42004":"Index **1** has **9** as a value which is the **key of Ankle boot** as per **classes dictionary**, so we stand correct","e90bd240":"*We can **normalize\/scale the image by two methods**, **first one** is using **Scikit learn's MinMaxScaler** function to scale the images and then **fit_transform the training set** and **transform the test set** and the **other method** is just **dividing both training and test set features by 255**.*","d6056588":"**to_categorical** takes number of classes on its own based on the **label's unique values**, here it was from **0 to 9**, hence, **it took 10**. You can specify them too, like I did using **num_classes**","64b687db":"<a id=\"section-class\"><\/a>\n***Let's create Confusion Matrix and Classification report to get a summary of how accurate our model was***","6762112a":"*It has a **93.2**% accuracy on the test set which is not that bad. As you can see from the **loss metric graph** that the **val_loss** started to go up a little bit. To prevent that, you can apply **some more regularizations** in the neural network. You can **reduce the patience level in Early stopping** or use more **dropout** layers.*","043f0169":"**Let's see the shape of training and test set.**","3afb36e6":"<a id=\"section-acc\"><\/a>\n*Plotting the loss and accuracy metrics*","f7b61a87":"**Now we're going to reshape our images**","4d9229a5":"*This looks like an ankle boot to me. Let's check the labels to confirm it*","f1b9c4ae":"*Let's visualize a single image from our training set*","7c85c960":"*Using **Early Stopping to monitor the validation loss** and **stop the training when the loss begins to increase**. **Patience** let's us set the number of epochs after which the training should be stopped in case of validation loss. We're setting it at 18.*","7094bda2":"<a id=\"section-nn\"><\/a>\n*Now we're done with our image preprocessing step, let's divide our data into training and validation set. We're gonna set validation set size to 20%*","c59cbd00":"*Let's check a single example from our training set, how it looks like*","c643e31a":"Notice here, the **first value of y_train** was **2**(check the cell below the ankle boot image), so **to_categorical()** has transformed that into an entire row. So, now at **index no. 2**, we have **1** and all the other values are **0**."}}