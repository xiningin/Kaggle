{"cell_type":{"d4b76f9d":"code","aeac4857":"code","9587e78e":"code","bbcec3a9":"code","b6fa5d2a":"code","153a55f4":"code","5983cb1d":"code","b720351a":"code","ac1e2602":"code","5c73cc1f":"code","98f40650":"code","f35a754b":"markdown","ff5616cc":"markdown","25c8ac6e":"markdown","ee0b45fc":"markdown","70653fd9":"markdown"},"source":{"d4b76f9d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json\nimport matplotlib.pyplot as plt\n\n\nfrom pandas.io.json import json_normalize\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","aeac4857":"def load_df(csv_path='..\/input\/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df","9587e78e":"train_df = load_df()#nrows=20000)\ntest_df = load_df(\"..\/input\/test.csv\")#,nrows=20000)","bbcec3a9":"train_df.head()","b6fa5d2a":"features_not_available = []\nfor a,b in zip(train_df.loc[0], train_df.columns):\n    if a == 'not available in demo dataset':\n        features_not_available.append(b)\ntrain_df = train_df.drop(features_not_available, axis=1)\ntrain_df.head()","153a55f4":"channel_density = train_df.groupby(['channelGrouping']).channelGrouping.count().sort_values()\nplt.xticks(rotation=60)\nplt.xlabel('Channels')\nplt.ylabel('Visits')\nplt.title('Channel Density')\nx_den = channel_density.index\ny_den = channel_density\nfor a,b in zip(x_den, y_den):\n    plt.text(a, b+60, str(round(100*b\/train_df.shape[0]))+'%')\nplt.bar(x_den, y_den)","5983cb1d":"train_df[\"totals.transactionRevenue\"] = train_df[\"totals.transactionRevenue\"].astype('float')\nchannel_revenue = train_df.groupby('channelGrouping')['totals.transactionRevenue'].sum().sort_values().reset_index()\nplt.xticks(rotation=60)\nplt.xlabel('Channels')\nplt.ylabel('Revenue')\nplt.title('Revenue per channel')\nplt.bar(channel_revenue['channelGrouping'], channel_revenue['totals.transactionRevenue'])","b720351a":"device_browser = train_df.groupby('device.browser')['totals.transactionRevenue'].agg(['count', 'size', 'mean']).sort_values('count', ascending=False)[0:8]\ndevice_browser.head()","ac1e2602":"plt.xticks(rotation=60)\nplt.xlabel('Browser')\nplt.ylabel('Count')\nplt.title('Device browser count')\nplt.bar(device_browser.index, device_browser['count'])","5c73cc1f":"plt.xticks(rotation=60)\nplt.xlabel('Browser')\nplt.ylabel('Revenue')\nplt.title('Device browser total revenue')\nplt.bar(device_browser.index, device_browser['size'])","98f40650":"plt.xticks(rotation=60)\nplt.xlabel('Browser')\nplt.ylabel('Mean revenue')\nplt.title('Device browser mean revenue')\nplt.bar(device_browser.index, device_browser['mean'])","f35a754b":"This kernel is a beginners approach to exploring the data set, in order to prepare for the development of a predicting model. This is my first Kernel and competition, and would love to hear everyone's feedback! \n\nIn this kernel, I will be going through each feature of the data and discussing its relevance when trying to predict revenue per customer.","ff5616cc":"Channel breakdown:\n- Referral: Traffic that occurs when a user finds you through a site other than a major search engine\n- Social: Traffic from a social network, such as Facebook, LinkedIn, Twitter, or Instagram\n- Organic search: Traffic from search engine results that is earned, not paid\n- Paid search: Traffic from search engine results that is the result of paid advertising via Google AdWords or another paid search platform\n- Email: Traffic from email marketing that has been properly tagged with an email parameter\n- Other: If traffic does not fit into another source or has been tagged as \u201cOther\u201d via a URL parameter, it will be bucketed into \u201cOther\u201d traffic.\n- Direct: Any traffic where the referrer or source is unknown.\n\n## 2. Device\nThe specifications for the device used to access the Store.\n### 2.1 device.browser\nWhat internet browser was used to access the store.","25c8ac6e":"Import train and test data frames. Specify a number of rows for quicker execution. ","ee0b45fc":"# Data fields\n## 1. channelGrouping\n\nThe channel via which the user came into the store. Here we want to explore:\n- Channel density i.e. how many visits per channel\n- Channel revenue i.e. how much revenue each channel generates","70653fd9":"To flatten the JSON fields in the data set, I used Juli\u00e1n Peller's \"1 - Quick start: read csv and flatten json fields\", thanks for this!\n\n"}}