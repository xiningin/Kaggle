{"cell_type":{"18c36040":"code","6fa9ce8b":"code","1f6cc2d9":"code","0bd4c38a":"code","41055b32":"code","fe3ee1e6":"code","33977468":"code","f10a43e0":"code","c04997e5":"code","efa3a87b":"code","98942be2":"code","cea42618":"code","84b13c58":"code","fe5be717":"code","0072d9e0":"code","f4083a65":"code","e8a1f758":"code","16135cdd":"code","168f89fa":"code","d095174e":"code","a5a4b157":"code","758b633b":"code","377248c9":"code","7715d631":"code","d32839c2":"code","76d5af5e":"code","64d6fed4":"code","1b438d5d":"code","671f915b":"code","6dc00bc5":"code","3823ce70":"code","9baea866":"code","f8fbc178":"code","dd9a1c9d":"code","8468eca1":"code","1e8b9fa9":"code","8bc5b0f0":"code","e01cc344":"markdown","7d82a548":"markdown","fdca2e99":"markdown","e4593c84":"markdown","de24fb14":"markdown","4bd36d05":"markdown","089121d4":"markdown","6962b13e":"markdown","9ae5ed12":"markdown","4f91b419":"markdown","503ba5f8":"markdown","1f859909":"markdown","4cfe0b39":"markdown","cd46da65":"markdown","f00ddb36":"markdown","9a5e0d7d":"markdown","6b730b21":"markdown","eaa141a7":"markdown","be9dedc2":"markdown","042069ab":"markdown","bb852c14":"markdown","d13d48ff":"markdown","30c27da7":"markdown","e82bcf7f":"markdown","baf575ee":"markdown","6ccf224f":"markdown","02cb21d4":"markdown","51196282":"markdown","6cfd9e9a":"markdown","d54e6dda":"markdown","e2d92e72":"markdown","82979654":"markdown"},"source":{"18c36040":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    classification_report,\n    f1_score,\n    make_scorer,\n    precision_recall_fscore_support,\n    precision_score,\n    recall_score,\n)\nfrom sklearn.model_selection import (\n    GridSearchCV,\n    cross_validate,\n    train_test_split,\n)\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.svm import LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier","6fa9ce8b":"df = pd.read_csv(\"..\/input\/120-years-of-olympic-history-athletes-and-results\/athlete_events.csv\")","1f6cc2d9":"df.isna().mean().round(4) * 100","0bd4c38a":"df_cats = (\n    df[[\"Sex\", \"Season\"]]\n    .melt()\n    .groupby([\"variable\", \"value\"])\n    .size()\n    .to_frame(name=\"n\")\n)\ndf_cats[\"proportion\"] = df_cats[\"n\"].div(df_cats.n.sum(level=0), level=0)\ndf_cats","41055b32":"sex_per_year = (\n    df.groupby([\"Year\", \"Sex\"])[\"ID\"].count() \/\n    df.groupby([\"Year\"])[\"ID\"].count()\n)\nsex_per_year = sex_per_year.reset_index()\nsex_per_year = sex_per_year[sex_per_year[\"Sex\"] == \"M\"].rename(\n    columns={\"ID\": \"Male_Porportion\"}\n)\nsns.lineplot(x=\"Year\", y=\"Male_Porportion\", data=sex_per_year)","fe3ee1e6":"sns.pairplot(df.drop(columns=[\"ID\"]))","33977468":"df.drop(columns=[\"ID\"]).corr()","f10a43e0":"df[\"Sport\"].value_counts().head(10)","c04997e5":"# import csv, filtered this time.\ndf = pd.read_csv(\n    \"..\/input\/120-years-of-olympic-history-athletes-and-results\/athlete_events.csv\",\n    usecols=[\"Season\", \"Year\", \"Sex\", \"Age\",\n             \"Height\", \"Weight\", \"Sport\", \"Event\"],\n).dropna()\n\n# remove Winter Olympics for simplicity.\ndf = df[df[\"Season\"] == \"Summer\"]\n\n# remove sports without stongly physique-dependent elements\ndf = df[\n    ~df[\"Sport\"].isin(\n        [\"Shooting\", \"Art Competitions\", \"Motorboating\", \"Sailing\", \"Equestrianism\"]\n    )\n]\n\n# Split athletics into sprints\/jumps, throws and endurance to increase accuracy and reduce imbalance\ndf.loc[\n    (df[\"Sport\"] == \"Athletics\")\n    & (\n        df[\"Event\"].str.contains(\n            \"jump|vault|60 |100 |200 |400 |athlon|all-round\", case=False\n        )\n    ),\n    \"Sport\",\n] = \"Athletics Sprints\"\ndf.loc[\n    (df[\"Sport\"] == \"Athletics\") & (\n        df[\"Event\"].str.contains(\"put|throw\", case=False)),\n    \"Sport\",\n] = \"Athletics Throws\"\ndf.loc[\n    (df[\"Sport\"] == \"Athletics\")\n    & ~(\n        df[\"Event\"].str.contains(\n            \"jump|vault|60 |100 |200 |400 |athlon|all-round\", case=False\n        )\n    )\n    & ~(df[\"Event\"].str.contains(\"put|throw\", case=False)),\n    \"Sport\",\n] = \"Athletics Endurance\"\n# just remove multi-events for simplicity\ndf = df[\n    ~(\n        (df[\"Sport\"] == \"Athletics\")\n        & (df[\"Event\"].str.contains(\"athlon|all-round\", case=False))\n    )\n]\ndf[\"Sport\"] = df[\"Sport\"].str.replace(\"Men's |Women's \", \"\")\n\n# Pick top 10 sports by athlete count\ndf = df[df[\"Sport\"].isin(df[\"Sport\"].value_counts().head(10).index)]\ndf = df.drop(columns=[\"Season\", \"Event\"])","efa3a87b":"df[\"Sport\"].value_counts()","98942be2":"sns.lineplot(\n    x=\"Year\",\n    y=\"count\",\n    hue=\"Sport\",\n    data=df.groupby(\"Year\")[\"Sport\"]\n    .value_counts()\n    .to_frame()\n    .rename(columns={\"Sport\": \"count\"})\n    .reset_index(),\n)","cea42618":"sns.lineplot(x=\"Year\", y=\"Height\", hue=\"Sport\", data=df)","84b13c58":"sns.lineplot(x=\"Year\", y=\"Weight\", hue=\"Sport\", data=df)","fe5be717":"df = df[df[\"Year\"] >= 1960]","0072d9e0":"df[\"Sport\"].value_counts()","f4083a65":"df = pd.get_dummies(df, columns=[\"Sex\"]).drop(\n    columns=[\"Sex_F\"]\n)  # convert Sex to just Male or not-Male","e8a1f758":"le = LabelEncoder()\ndf[\"Sport\"] = le.fit_transform(df[\"Sport\"])","16135cdd":"df_train, df_test = train_test_split(df, train_size=0.7, random_state=48)\n\ndf_train_X = df_train.drop(\"Sport\", axis=1)\nmin_max_scaler = MinMaxScaler().fit(df_train_X)  # used to normalise later\ndf_train_Y = df_train[\"Sport\"]\n\ndf_test_X = df_test.drop(\"Sport\", axis=1)\ndf_test_Y = df_test[\"Sport\"]","168f89fa":"len(df_train_Y)","d095174e":"train_counts = df_train_Y.value_counts()\ntrain_counts.index = le.inverse_transform(train_counts.index)\ntrain_counts","a5a4b157":"len(df_test_Y)","758b633b":"test_counts = df_test_Y.value_counts()\ntest_counts.index = le.inverse_transform(test_counts.index)\ntest_counts","377248c9":"scoring = {\n    \"accuracy\": \"accuracy\",\n    \"weighted_precision\": make_scorer(precision_score, average=\"weighted\"),\n    \"weighted_recall\": make_scorer(recall_score, average=\"weighted\"),\n    \"weighted_F1\": make_scorer(f1_score, average=\"weighted\"),\n}\n\nclassifiers = [\n    (\n        \"DT\",\n        DecisionTreeClassifier(),\n        {\"max_depth\": [3, 5, 10, None]},\n    ),  # trying different max tree depths.\n    (\n        \"RF\",\n        RandomForestClassifier(),\n        {\"max_depth\": [3, 5, 10, None]},\n    ),  # trying different max tree depths.\n    (\n        \"LOGREG\",\n        LogisticRegression(),\n        {\"C\": np.logspace(-5, 5, 5 + 5 + 1, base=10)},\n    ),  # C ranges from 10^-5 - 10^5 in powers of 10.\n    (\n        \"KNN\",\n        # number of nearest neighbours ranges from 1 to 1000 in powers of 10.\n        KNeighborsClassifier(),\n        {\n            \"n_neighbors\": np.append(\n                np.logspace(0, 3, 3 + 0 + 1, base=10).astype(\"int\"),\n                np.sqrt(len(df_train_X)).astype(\"int\"),\n            )\n        },\n    ),\n    (\n        \"SVM\",\n        LinearSVC(),\n        {\"C\": np.logspace(-5, 5, 5 + 5 + 1, base=10)},\n    )  # C ranges from 10^-5 - 10^5 in powers of 10.\n]\n\nresults = pd.DataFrame([])\nmodels = []","7715d631":"for name, classifier, params in classifiers:\n\n    if name in (\"SVM\", \"LOGREG\", \"KNN\"):\n        train_X = min_max_scaler.transform(df_train_X)\n        train_Y = df_train_Y\n    else:\n        train_X = df_train_X\n        train_Y = df_train_Y\n\n    clf = GridSearchCV(\n        estimator=classifier,\n        param_grid=params,\n        scoring=scoring,\n        cv=None,\n        n_jobs=-1,\n        refit=\"weighted_F1\",\n        verbose=3,\n    )\n\n    print(\"model = \" + str(name))\n    fit = clf.fit(train_X, train_Y)\n    models.append((name, fit.best_estimator_))\n    search = pd.DataFrame.from_dict(fit.cv_results_)[\n        [\n            \"params\",\n            \"mean_test_accuracy\",\n            \"mean_test_weighted_precision\",\n            \"mean_test_weighted_recall\",\n            \"mean_test_weighted_F1\",\n        ]\n    ]\n    search[\"model\"] = name\n    search.columns = search.columns.str.replace(\"mean_test_\", \"\")\n\n    # baseline classifier\n    dum_class = DummyClassifier(\"uniform\", random_state=48)\n    dum = cross_validate(dum_class, train_X, train_Y, cv=5, scoring=scoring)\n    dum = pd.DataFrame.from_dict(dum).drop(columns=[\"fit_time\", \"score_time\"])\n    dum[\"model\"] = name\n    dum = dum.assign(**dum.mean()).iloc[[0]]\n    dum.columns = dum.columns.str.replace(\"test_\", \"base_\")\n\n    search = pd.merge(search, dum, how=\"left\", on=[\"model\"])\n\n    results = results.append(search, ignore_index=True)","d32839c2":"best_models = results.loc[results.groupby(\"model\")[\"weighted_F1\"].idxmax()]\nbest_models","76d5af5e":"for model_name, model in models:\n\n    test_X = df_test_X\n    test_Y = df_test_Y\n\n    Y_pred = model.predict(test_X)\n    Y_pred = le.inverse_transform(Y_pred)\n    Y_actual = test_Y\n    Y_actual = le.inverse_transform(Y_actual)\n    print(\"Classification Report:    \" + model_name)\n    print(classification_report(Y_actual, Y_pred))\n    print(\n        \"Overall:    \"\n        + str(precision_recall_fscore_support(Y_actual, Y_pred, average=\"weighted\"))\n    )","64d6fed4":"df_train, df_test = train_test_split(df, train_size=0.7, random_state=48)\n\ndf_train_X = df_train.drop(\"Sport\", axis=1)\nmin_max_scaler = MinMaxScaler().fit(df_train_X)  # used to normalise later\ndf_train_Y = df_train[\"Sport\"]\n\n# number of athletes per sport is imbalanced, use SMOTE to balance classes\nsm = SMOTE(random_state=42)\ndf_train_X_SMOTE, df_train_Y_SMOTE = sm.fit_resample(df_train_X, df_train_Y)\n\ndf_test_X = df_test.drop(\"Sport\", axis=1)\ndf_test_Y = df_test[\"Sport\"]","1b438d5d":"len(df_train_Y_SMOTE)","671f915b":"train_counts = df_train_Y_SMOTE.value_counts()\ntrain_counts.index = le.inverse_transform(train_counts.index)\ntrain_counts","6dc00bc5":"len(df_test_Y)","3823ce70":"test_counts = df_test_Y.value_counts()\ntest_counts.index = le.inverse_transform(test_counts.index)\ntest_counts","9baea866":"scoring = {\n    \"accuracy\": \"accuracy\",\n    \"weighted_precision\": make_scorer(precision_score, average=\"weighted\"),\n    \"weighted_recall\": make_scorer(recall_score, average=\"weighted\"),\n    \"weighted_F1\": make_scorer(f1_score, average=\"weighted\"),\n}\n\nclassifiers = [\n    (\"RF\", RandomForestClassifier(), {\"max_depth\": [3, 5, 10, None]})\n]  # trying different max tree depths.\n\nSMOTE_results = pd.DataFrame([])\nSMOTE_models = []","f8fbc178":"for name, classifier, params in classifiers:\n\n    train_X = df_train_X_SMOTE\n    train_Y = df_train_Y_SMOTE\n\n    clf = GridSearchCV(\n        estimator=classifier,\n        param_grid=params,\n        scoring=scoring,\n        cv=None,\n        n_jobs=-1,\n        refit=\"weighted_F1\",\n        verbose=3,\n    )\n\n    print(\"model = \" + str(name))\n    fit = clf.fit(train_X, train_Y)\n    SMOTE_models.append((name, fit.best_estimator_))\n    search = pd.DataFrame.from_dict(fit.cv_results_)[\n        [\n            \"params\",\n            \"mean_test_accuracy\",\n            \"mean_test_weighted_precision\",\n            \"mean_test_weighted_recall\",\n            \"mean_test_weighted_F1\",\n        ]\n    ]\n    search[\"model\"] = name\n    search.columns = search.columns.str.replace(\"mean_test_\", \"\")\n\n    # baseline classifier\n    dum_class = DummyClassifier(\"uniform\", random_state=48)\n    dum = cross_validate(dum_class, train_X, train_Y, cv=5, scoring=scoring)\n    dum = pd.DataFrame.from_dict(dum).drop(columns=[\"fit_time\", \"score_time\"])\n    dum[\"model\"] = name\n    dum = dum.assign(**dum.mean()).iloc[[0]]\n    dum.columns = dum.columns.str.replace(\"test_\", \"base_\")\n\n    search = pd.merge(search, dum, how=\"left\", on=[\"model\"])\n\n    SMOTE_results = SMOTE_results.append(search, ignore_index=True)","dd9a1c9d":"SMOTE_results.loc[SMOTE_results.groupby(\"model\")[\"weighted_F1\"].idxmax()]","8468eca1":"for model_name, model in SMOTE_models:\n\n    test_X = df_test_X\n    test_Y = df_test_Y\n\n    Y_pred = model.predict(test_X)\n    Y_pred = le.inverse_transform(Y_pred)\n    Y_actual = df_test_Y\n    Y_actual = le.inverse_transform(Y_actual)\n    print(\"Classification Report:    \" + model_name)\n    print(classification_report(Y_actual, Y_pred))\n    print(\n        \"Overall:    \"\n        + str(precision_recall_fscore_support(Y_actual, Y_pred, average=\"weighted\"))\n    )","1e8b9fa9":"RF = models[1][1]\nRF.fit(df_train_X, df_train_Y)\n\nfeatures = {}\n\nfor feature, importance in zip(df_train_X.columns, RF.feature_importances_):\n    features[feature] = importance\n\nimportances = (\n    pd.DataFrame.from_dict(features, orient=\"index\")\n    .reset_index()\n    .rename(columns={\"index\": \"Attribute\", 0: \"Gini Importance\"})\n    .sort_values(by=\"Gini Importance\", ascending=False)\n)\n\nsns.barplot(x=\"Attribute\", y=\"Gini Importance\", data=importances, color=\"blue\")","8bc5b0f0":"data = {\"Age\": 24, \"Height\": 182, \"Weight\": 79, \"Year\": 2021, \"Sex_M\": 1}\n\npred_event = RF.predict(pd.DataFrame([data]))\nall_events = le.inverse_transform(np.arange(0, df[\"Sport\"].nunique(), 1))\nall_probs = RF.predict_proba(pd.DataFrame([data]))[0]\npred_proba = all_probs[pred_event]\nprint(\n    \"Your predicted sport for the \"\n    + str(data[\"Year\"])\n    + \" Olympic Games is \"\n    + str(le.inverse_transform(pred_event)[0])\n    + \" with a probability of \"\n    + str(round(100 * pred_proba[0], 1))\n    + \"%\"\n)\nprint(\"All probabilities:\")\nprint([i for i in zip(all_events, all_probs)])","e01cc344":"### Test best model on unseen test data","7d82a548":"Height over the years.","fdca2e99":"## Data Pre-Processing","e4593c84":"Based on the EDA thus far, I will remove Olympics before 1960 due to low athlete count and high variance.","de24fb14":"* Different sports had quite different numbers of athletes on different years.\n* Dropping events prior to 1960 could improve the model.","4bd36d05":"### Feature Importance","089121d4":"### Train the Models","6962b13e":"Weight over the years.","9ae5ed12":"### Define the Model","4f91b419":"Proportion of gender per year.\n* Steady rate of increase in female Olympians, not just in early years.","503ba5f8":"There is a considerable imbalance in the number of athletes per sport.","1f859909":"table of best hyperparameters for each model.","4cfe0b39":"#### SMOTE results: training accuracy increased while test accuracy remained the same.","cd46da65":"create dummies for categorical columns.","f00ddb36":"Test best models on unseen test data.","9a5e0d7d":"encode Sport into integers for the model.","6b730b21":"Pearson correlations for each attribute.\n* Year is slightly positively correlated to height, and negatively to age.\n* Height has a strong positive correlation to Weight, as expected.","eaa141a7":"Display Gini importances for the best performing model, Random Forest.","be9dedc2":"### Train-Test Split","042069ab":"### Train the Model","bb852c14":"One more look at the target variable.","d13d48ff":"### Testing","30c27da7":"### Train-Test Split\n70% training set due to use of cross validation.","e82bcf7f":"Percentage missing per attribute.\n* ~20% of Height and Weight are missing.\n* Age is within missing tolerance. This is likely fine as there is enough data remaining.","baf575ee":"Distributions and relationships between the numeric variables.\n* Age, Height and Weight appear acceptably normally distributed for Pearson correlations.\n* No visible outliers in the data.","6ccf224f":"## Exploratory Data Analysis","02cb21d4":"import data","51196282":"# What Sport Will You Compete In?\n## Based on your height, weight, age and gender, what sport are you most likely to compete in in the Olympic Games?","6cfd9e9a":"## Attempt 2: Using SMOTE\n### I will now balance the data with Synthetic Minority Class Oversampling and compare the results.","d54e6dda":"### Define the Models","e2d92e72":"For categorical column, the proportion per value.\n* Sex is mainly Male, assuming the imbalance comes from earlier years.\n* Season is mainly Summer Olympics.","82979654":"### Predict your sport for the 2021 Olympics... (I run competitively in the 100m\/200m sprints)"}}