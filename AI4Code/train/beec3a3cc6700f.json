{"cell_type":{"261a3297":"code","d64f7f4d":"code","1ec8cce8":"code","b090ee0b":"code","ec57aed0":"code","012a5f67":"code","e7208e7b":"code","265255f0":"code","845a1bd5":"code","e29213a4":"code","16ebbb53":"code","37646f6b":"code","09199cc4":"code","bbf95b3a":"code","436a8ce8":"code","c9d887fc":"code","f41a6284":"code","0ba4f839":"code","e439b07f":"code","11b34bae":"markdown","1519178c":"markdown","541f4a95":"markdown","b031b5e3":"markdown"},"source":{"261a3297":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d64f7f4d":"#**AutoEncoder on Dimension Reduction**","1ec8cce8":"import numpy as np\nimport os\nimport cv2","b090ee0b":"path = '..\/input\/ntt-data-global-ai-challenge-06-2020\/NTL-dataset\/tif\/*.tif'","ec57aed0":"\nimport glob","012a5f67":"data=[]\nimgsize = 28\nfor file in glob.glob(path):\n        img = cv2.imread(file)\n        img = cv2.cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img = cv2.resize(img,(imgsize,imgsize))\n        data.append(img)","e7208e7b":"data=np.array(data)\nprint(data.shape)\nprint(data[5].shape)","265255f0":"x_train=data","845a1bd5":"from keras.layers import Input, Dense\nfrom keras.models import Model\n\n# this is the size of our encoded representations\nencoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n\n# this is our input placeholder\ninput_img = Input(shape=(784,))\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu')(input_img)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(784, activation='sigmoid')(encoded)\n\n# this model maps an input to its reconstruction\nautoencoder = Model(input_img, decoded)","e29213a4":"encoder = Model(input_img, encoded)","16ebbb53":"encoded_input = Input(shape=(encoding_dim,))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))","37646f6b":"autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')","09199cc4":"x_train = x_train.astype('float32') \/ 255","bbf95b3a":"x_train= np.reshape(x_train,(724,784))\n","436a8ce8":"print( x_train.shape)","c9d887fc":"autoencoder.fit(x_train,x_train,epochs=5)","f41a6284":"from sklearn.model_selection import train_test_split\nX_train, X_test = train_test_split(x_train,test_size=0.3, random_state=42)","0ba4f839":"encoded_imgs = encoder.predict(X_test)\ndecoded_imgs = decoder.predict(encoded_imgs)","e439b07f":"import matplotlib.pyplot as plt\n\nn = 10  # how many digits we will display\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_train[i].reshape(28,28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28,28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","11b34bae":"In the training set image shapes are altered to 1000 x 1000 pixel","1519178c":"Importing all depended libraries","541f4a95":"Autoencoders are learned automatically from data examples, which is a useful property: it means that it is easy to train specialised instances of the algorithm that will perform well on a specific type of input. It doesn\u2019t require any new engineering, just appropriate training data","b031b5e3":"**More dataset and more epochs of training will give better result**"}}