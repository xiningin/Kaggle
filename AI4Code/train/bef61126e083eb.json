{"cell_type":{"0caa2d64":"code","7ce72c37":"code","0aced42b":"code","c702b8a7":"code","c6d16ead":"code","ca25caa2":"code","99f000e7":"code","85f56ba8":"code","0b7506f0":"code","40b4bee5":"code","f822ce43":"code","76ced031":"code","dd338023":"code","9f68849f":"code","e2851b03":"code","c7146ce4":"code","01712915":"code","65a743ab":"code","187b6708":"code","c73633d2":"code","c185afa4":"code","c3f763ac":"code","d596aab8":"code","2cd30667":"code","63f06988":"code","cf52bb44":"code","71df7c82":"code","8b539dc0":"code","57e47b70":"code","a4d32726":"code","32f24c83":"code","58ea76dc":"code","2942e027":"code","c60b0eaf":"code","60ac0963":"code","ab3af5a6":"code","79e4e680":"code","85aaf7ca":"code","15dbd4aa":"code","d8e9b217":"code","d9035ea4":"code","7654924e":"code","d6aac568":"code","534e901b":"markdown","0a75f3ab":"markdown","5b5a7971":"markdown","dbaebad5":"markdown","78d7784e":"markdown","2e88d5fa":"markdown","32cf1f84":"markdown","2105076a":"markdown","6001008a":"markdown","ca061459":"markdown","04732dea":"markdown","a035a58c":"markdown","359ab939":"markdown","9d281f8e":"markdown","35bfb3ac":"markdown","cacf2645":"markdown","b4c39419":"markdown","d91cf77f":"markdown","d060bf2b":"markdown","616a76b6":"markdown"},"source":{"0caa2d64":"import os\nprint(os.listdir('..\/input\/123456\/'))","7ce72c37":"print(os.listdir('..\/input\/123456\/'))","0aced42b":"dataPath = '..\/input\/123456\/'","c702b8a7":"# Load the original model\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nmodel = MobileNetV2()","c6d16ead":"import numpy as np\nfrom PIL import Image\n\ndef prepare_image(filepath):\n    img = Image.open(filepath)\n    img_resized = img.resize((224,224))\n    return np.asarray(img_resized)","ca25caa2":"import matplotlib.pyplot as plt\ntestPath = '..\/input\/123456\/'","99f000e7":"# choose a test image\nimageFile = testPath+'KOALA\/1.jpg'\nplt.imshow(prepare_image(testPath+'KOALA\/1.jpg'))","85f56ba8":"# Load original trained model\nfrom tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\nmodel = MobileNetV2()","0b7506f0":"from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n\n# check model prediction\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nresults = decode_predictions(predictions)\nprint(results)","40b4bee5":"# choose another test image\nimageFile = testPath+'KOALA\/10.jpg'\nplt.imshow(prepare_image(testPath+'KOALA\/10.jpg'))","f822ce43":"# check model prediction\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nresults = decode_predictions(predictions)\nprint(results)","76ced031":"import glob\ndirList = glob.glob(dataPath+'*') # list of all directories in dataPath\ndirList.sort() # sorted in alphabetical order\nprint(dirList)","dd338023":"Y_data = []\nfor i in range(len(dirList)):\n    fileList = glob.glob(dirList[i]+'\/*.jpg')\n    [Y_data.append(i) for file in fileList]\nprint(Y_data)","9f68849f":"X_data = []\nfor i in range(len(dirList)):\n    fileList = glob.glob(dirList[i]+'\/*.jpg')\n    [X_data.append(prepare_image(file)) for file in fileList]\n\nX_data = np.asarray(X_data)\nprint(X_data.shape)","e2851b03":"## random shuffle\nfrom sklearn.utils import shuffle\nX_data, Y_data = shuffle(X_data, Y_data, random_state=0)","c7146ce4":"print(Y_data)","01712915":"# randomly select a picture to show\nimport random\ntestNum = random.randint(0,len(X_data)-1)\nprint(testNum)\n\nplt.imshow(X_data[testNum])","65a743ab":"labels = os.listdir(dataPath)\nprint(labels)\n\nnum_classes = len(labels)\nprint(num_classes)","187b6708":"# counting number of pictures of each class\nequilibre = []\n[equilibre.append(Y_data.count(i)) for i in range(len(labels))]\nprint(equilibre)","c73633d2":"# plot the circle of value counts in dataset\nplt.figure(figsize=(5,5))\nmy_circle=plt.Circle( (0,0), 0.5, color='white')\nplt.pie(equilibre, labels=labels, colors=['red','green'],autopct='%1.1f%%')\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.show()","c185afa4":"X_train = X_data \/ 255.0\nprint(X_train.shape)","c3f763ac":"from tensorflow.keras.utils import to_categorical\nY_train = to_categorical(Y_data)\nprint(Y_train.shape)","d596aab8":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense","2cd30667":"base_model=MobileNetV2(input_shape=(224,224,3),weights='imagenet',include_top=False) ","63f06988":"x=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) # FC layer 1\nx=Dense(64,activation='relu')(x)   # FC layer 2\nout=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n\nmodel=Model(inputs=base_model.input,outputs=out)","cf52bb44":"# show all layers no. & name\nfor i,layer in enumerate(model.layers):\n    print(i,layer.name)","71df7c82":"# set extra layers to trainable \n#for layer in model.layers[:155]:\n#    layer.trainable=False\n#for layer in model.layers[155:]:\n#    layer.trainable=True\n\nbase_model.trainable = False\n\nmodel.summary()","8b539dc0":"# Compile Model\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])","57e47b70":"# Train Model (target is loss <0.01)\nbatch_size = 10\nnum_epochs = 10\nhistory = model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs)","a4d32726":"# Save Model\nmodel.save('tl_birds2.h5')","32f24c83":"# select one bird picture to test\nimageFile = testPath+'KOALA\/1.jpg'\nplt.imshow(prepare_image(imageFile))","58ea76dc":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","2942e027":"# select another picture to test \nimageFile=testPath+'Manidae\/1.jpg'\nplt.imshow(prepare_image(imageFile))","c60b0eaf":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","60ac0963":"# select a untrained picture to test the model\nimageFile=testPath+'PANDA\/1.jpg'\nplt.imshow(prepare_image(imageFile))","ab3af5a6":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","79e4e680":"# select another untrained picture to test\nimageFile=testPath+'RAT\/1.jpg'\nplt.imshow(prepare_image(imageFile))","85aaf7ca":"# test model\ntestData = prepare_image(imageFile).reshape(1,224,224,3)\ntestData = testData \/ 255.0\npredictions = model.predict(testData)\nmaxindex = int(np.argmax(predictions))\nprint(predictions[0][maxindex],labels[maxindex])","15dbd4aa":"from sklearn.metrics import confusion_matrix\n\nY_pred = model.predict(X_train) # check the train dataset\ny_pred = np.argmax(Y_pred,axis=1)\n#y_label= [labels[k] for k in y_pred]\ncm = confusion_matrix(Y_data, y_pred)\nprint(cm)","d8e9b217":"from sklearn.metrics import classification_report\nprint(classification_report(Y_data, y_pred, target_names=labels))","d9035ea4":"# plot confusion matrix\nfig, ax = plt.subplots()\nax.matshow(cm,cmap='Blues')\n\nfor (i, j), z in np.ndenumerate(cm):\n    ax.text(j, i, '{:d}'.format(z), ha='center', va='center')\n\nplt.show()","7654924e":"import itertools\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n        \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()","d6aac568":"plot_confusion_matrix(cm, \n                      normalize=False,\n                      target_names = labels,\n                      title=\"Confusion Matrix, not Normalized\")","534e901b":"## Prepare Data","0a75f3ab":"![image.png](attachment:image.png)","5b5a7971":"## Train Model","dbaebad5":"*Confirm the model don't recognize Blue Tit !*","78d7784e":"## Dataset = birds2 (blue_tit, pica_pica)","2e88d5fa":"## Confusion Matrix","32cf1f84":"### add Fully-Connected Layers","2105076a":"### Data Normalization","6001008a":"### test the original model \nto confirm its recognition of a dog and a bird","ca061459":"## Classification Report","04732dea":"### Load MobileNetV2 model","a035a58c":"### Plot Confusion Matrix","359ab939":"### Shuffle Data","9d281f8e":"## Save Model","35bfb3ac":"## Build Model\n","cacf2645":"## Test MobileNetV2 model","b4c39419":"## Test Model","d91cf77f":"*Confirm the model recognize German Shepherd !*","d060bf2b":"### set for transfer learning","616a76b6":"# Image Classification\n## MobileNetV2 transfer learning"}}