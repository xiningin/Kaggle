{"cell_type":{"3fc73728":"code","d2c52117":"markdown"},"source":{"3fc73728":"import matplotlib.pyplot\nimport seaborn\nimport pandas\nimport string\nimport numpy\nimport nltk\nimport time\nimport gc\n%matplotlib inline\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom mpl_toolkits.basemap import Basemap\nfrom sklearn.svm import LinearSVC\nfrom collections import Counter\n\ndef clear_sentence(sentence: str) -> str:\n    sentence = sentence.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n    sentence = sentence.lower()\n    return sentence\n\ndef train_our_model_in_tweets():\n    # Load the data and take a look at how tweet datasets usually look like\n    Sentiments = pandas.read_csv('..\/input\/sentiment140\/training.1600000.processed.noemoticon.csv', encoding=\"ISO-8859-1\", names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])\n\n    # Now, we won't be using any other data other than the text and the sentiment. \n    Sentiments = Sentiments[['target','text']]\n\n    # Make the sentiments strings\n    sentiment_value = {0: \"negative\", 2: \"neutral\", 4: \"positive\"}\n    decode = lambda label: sentiment_value[int(label)]\n    x = Sentiments['text'].apply(clear_sentence).tolist()\n    y = Sentiments['target'].apply(decode).tolist()\n\n    # Let's use the SVC model we used before.\n    starting_time = time.time()   \n    vector = TfidfVectorizer(ngram_range=(1, 2))\n    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n    X_training = vector.fit_transform(X_train) \n    X_testing = vector.transform(X_test)\n    model = LinearSVC()\n    model.fit(X_training, y_train)\n    y_prediction = model.predict(X_testing)\n    accuracy = accuracy_score(y_test, y_prediction)\n    ending_time = time.time()\n    print('Trained our model in',len(Sentiments.index),'tweets')\n    print('Accuracy:',\"{:.2f}\".format(accuracy*100) + \" in {:.2f}s\".format(ending_time-starting_time))\n    return model,vector\n\ndef plot_support(model,vector):\n    # Get the dataset\n    Trump = pandas.read_csv('..\/input\/us-election-2020-tweets\/hashtag_donaldtrump.csv', lineterminator='\\n')\n    Biden = pandas.read_csv('..\/input\/us-election-2020-tweets\/hashtag_joebiden.csv', lineterminator='\\n')\n    Trump = Trump[['tweet','lat','long']]\n    Biden = Biden[['tweet','lat','long']]\n\n    # And let's clean our reviews\n    Trump['tweet'] = Trump['tweet'].dropna().apply(clear_sentence)\n    Biden['tweet'] = Biden['tweet'].dropna().apply(clear_sentence)\n\n    # A function to get only the data inside the USA (there are many tweets from abroad)\n    def get_region(data, bot_lat, top_lat, left_lon, right_lon):\n        top = data.lat <= top_lat\n        bot = data.lat >= bot_lat\n        left = data.long >= left_lon\n        right = data.long <= right_lon\n        index = top&bot&left&right \n        return data[index]\n\n    Trump = get_region(Trump,24,50,-126,-65)\n    Biden = get_region(Biden,24,50,-126,-65)\n\n    trump_sentiment = pandas.DataFrame(model.predict(vector.transform(Trump['tweet'].tolist())),columns=['sentiment'])\n    biden_sentiment = pandas.DataFrame(model.predict(vector.transform(Biden['tweet'].tolist())),columns=['sentiment'])\n\n    Trump = pandas.concat([Trump.reset_index(drop=True), trump_sentiment], axis=1)\n    Biden = pandas.concat([Biden.reset_index(drop=True), biden_sentiment], axis=1)\n\n    trump_positive = Trump[Trump['sentiment'] == 'positive']\n    biden_positive = Biden[Biden['sentiment'] == 'positive']\n\n    Map = Basemap(llcrnrlat=24,urcrnrlat=50,llcrnrlon=-126,urcrnrlon=-65)\n    matplotlib.pyplot.figure(figsize=(12,10))\n    Map.bluemarble(alpha=0.6)\n\n    seaborn.scatterplot(x='long', y='lat', data=biden_positive, linewidth=0, s=40, alpha=1, label='Support for Biden')\n    seaborn.scatterplot(x='long', y='lat', data=trump_positive, linewidth=0, s=40, alpha=0.01, label='Support for Trump')\n\n    matplotlib.pyplot.gca().get_legend().legendHandles[1].set_alpha(1)\n    matplotlib.pyplot.title(\"Tweets positive towards presidential candidates\")\n    matplotlib.pyplot.show()\n    \ntrained_model,fitted_vector = train_our_model_in_tweets()\nplot_support(trained_model,fitted_vector)","d2c52117":"Hello, this is a small notebook\/code to do a sentiment analysis and then plot a map of support for each presidential. It is based on my other code about the [Australian Elections with Tweets](https:\/\/www.kaggle.com\/andreispurim\/challenge-botando-pra-quebrar) (which yielded pretty good results). I just copied and adjusted the code but this time it didn't worked quite that well.\n\nSo, here's the idea: make a TFIDF\/LinearSVC learn with the sentiment140's 160.000.000 tweets (which are positive or negative), with the model fitted, apply the model to the tweets about Biden and Trump and plot the map.\n\nI'll promise that later I'll document the code a little better, but it should be clear enough to have some idea. If you'd like to use it and improve it, please go ahead.\n\nNow, a few ideas on improving this code:\n- The idea of using sentiment140 is quite sound, but instead of using LinearSVC you can use much **better models**.\n- The clean_sentence function is designed to be fast, but it is not the **best cleaner**. It can be improved, specially considering a good chunk of the words in tweets are @mentions and #hashtags. It would be a great improvement to keep mentions and hashtags as different phrase entities. \n- **Removing stopwords?** I don't think it works well with so few words (The current accuracy in sentiment140 is 82%, without the stopwords it fell down to 77%) because it helps understand the text better.\n- Maybe make Biden and Trump concatened in the same dataset. This might speed up things a little.\n- Sentiment140 used to have 'neutral' feeling. If our model was fitted, maybe the map would look better.\n- Speaking of the map, it would be also smart to 'normalize' the colors. To balance Trump's orange (which is plotted above Biden) I had to alter the alpha. Maybe the best would to make an average of each region.\n- Also, remember the demographic distribution of the USA and remember that Twitter is used usually by younger, more liberal, college students than it is by other demographics. So that's why in the midwest there's so much support for Biden: the only people using twitter in those regions are young biden voters.\n"}}