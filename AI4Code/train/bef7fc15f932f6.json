{"cell_type":{"afa15299":"code","5c1d8b1b":"code","3c859659":"code","9ee1f64e":"code","58eab389":"code","45df8f06":"code","d09aae6b":"code","722fa0b9":"code","53622572":"code","3c69b907":"code","f319caed":"code","f77fb2bb":"code","a5c15898":"code","a593dcd0":"code","5857f954":"code","c2273c00":"code","799ffa32":"code","ce661e48":"code","cdff32dd":"code","4983bcde":"code","4a403bd8":"code","6da67aee":"code","c98ba21b":"code","a39e9bf6":"code","44eb0e56":"code","e7d9d057":"code","804590b2":"code","ac31b2dd":"code","29dc6d1d":"code","b7620a0d":"code","794638fe":"code","a62c0e8a":"code","7fc0f903":"code","b72c4687":"code","d8850d14":"code","ec2b7a46":"code","c217964a":"code","e881df91":"code","b631f3dc":"code","6826c3e8":"code","363ded31":"code","7e150933":"code","795601a0":"code","6039d069":"code","0a005f7c":"code","3814cdf8":"code","8a8c7536":"code","74f68aad":"code","db2b128d":"code","85ebacf0":"markdown","c119b7da":"markdown","bb009067":"markdown","fbe81e2e":"markdown","4a5b7bfb":"markdown","3835dff4":"markdown","decfa201":"markdown","7cf0a270":"markdown","8ffb710f":"markdown","3fdf9f3f":"markdown","8ff961ec":"markdown","5e655389":"markdown","88729c5f":"markdown","9a09c0b6":"markdown","df32ff42":"markdown","2c5be657":"markdown","6f179e6b":"markdown","76dc634f":"markdown","3de2a79f":"markdown","63854957":"markdown","ef6dde64":"markdown","bcdf48ab":"markdown","f21eef78":"markdown","59d50424":"markdown","c87c772c":"markdown","6fa00c43":"markdown","20b9e949":"markdown","05feec0e":"markdown","28d9dc31":"markdown","1da27962":"markdown","f0657df7":"markdown","63a5844e":"markdown","1dcafd51":"markdown","df268b35":"markdown","f1bd21d6":"markdown","60480dbb":"markdown","4d4f6dbb":"markdown","25066941":"markdown"},"source":{"afa15299":"'''\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n'''","5c1d8b1b":"#!git clone https:\/\/github.com\/google-research\/simclr.git","3c859659":"'''\nimport matplotlib.pyplot as plt\n\nplt.figure()\ntrain_sample = plt.imread('\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/1000015157.jpg')\nplt.subplot(121)\nplt.imshow(train_sample)\ntest_sample = plt.imread('\/kaggle\/input\/cassava-leaf-disease-classification\/test_images\/2216849948.jpg')\nplt.subplot(122)\nplt.imshow(test_sample)\nprint(train_sample.shape)\nprint(test_sample.shape)\n'''","9ee1f64e":"'''\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nplt.figure()\nsample = Image.open('\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/1000015157.jpg')\nplt.subplot(121)\nplt.imshow(sample)\nsample_resize = sample.resize((600, 600))\nplt.subplot(122)\nplt.imshow(sample_resize)\n'''","58eab389":"'''\nimport pandas as pd\n\ntrain = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\ntrain.head()\n'''","45df8f06":"#train.label.value_counts()","d09aae6b":"#!python \/kaggle\/working\/simclr\/tf2\/run.py --train_mode=pretrain --train_batch_size=256 --train_epochs=1 --dataset=cifar10 --image_size=32 --resnet_depth=18 --model_dir=\/kaggle\/working\/simclr\/tf2\/cache --eval_split=test --use_tpu=False","722fa0b9":"'''\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nbuilder = tfds.builder('cifar10', data_dir='\/kaggle\/working\/data')\nbuilder.download_and_prepare()\nprint('num_train_examples:', builder.info.splits['train'].num_examples)\nprint('num_eval_examples: ', builder.info.splits['test'].num_examples)\nprint('num_classes: ', builder.info.features['label'].num_classes)\ndataset = builder.as_dataset(as_supervised=True) # \u3053\u308c\u306b\u3088\u308a\u8f9e\u66f8\u578b\u3067\u306f\u306a\u304f\u306a\u308b\ntrain_dataset, test_dataset = dataset['train'], dataset['test']\nassert isinstance(train_dataset, tf.data.Dataset)\n'''","53622572":"#print(train_dataset)","3c69b907":"'''\ndef map_fn(image, label):\n      \"\"\"Produces multiple transformations of the same batch.\"\"\"\n      print(type(image))\n      label = tf.one_hot(label, 10)\n      return image, label\n'''","f319caed":"#train_dataset = train_dataset.map(map_fn)\n#train_dataset","f77fb2bb":"'''\nimport pandas as pd\n\ntrain = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\ntrain.head()\n'''","a5c15898":"#from sklearn.model_selection import train_test_split\n#train, test = train_test_split(train, stratify=train['label'])","a593dcd0":"#train","5857f954":"#test","c2273c00":"'''\nall_image_paths = list(train['image_id'])\nall_image_paths = ['..\/input\/cassava-leaf-disease-classification\/train_images\/' + str(path) for path in all_image_paths]\nall_image_labels = list(train['label'])\n'''","799ffa32":"#print(all_image_paths[:5])\n#print(all_image_labels[:5])","ce661e48":"'''\nimport tensorflow as tf\ndef preprocess_image(image):\n  image = tf.image.decode_jpeg(image, channels=3)\n  image = tf.image.resize(image, [600, 600])\n  image = tf.cast(image, tf.uint8)\n  #image \/= 255.0  # normalize to [0,1] range\n  return image\n\ndef load_and_preprocess_image(path):\n  image = tf.io.read_file(path)\n  return preprocess_image(image)\n'''","cdff32dd":"'''\npath_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\nimage_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\nlabel_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\nimage_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\nprint(image_label_ds)\n'''","4983bcde":"'''\nBATCH_SIZE = 32\nimage_count = len(all_image_paths)\nds = image_label_ds.shuffle(buffer_size=image_count)\nds = ds.repeat()\nds = ds.batch(BATCH_SIZE)\n'''\n# `prefetch`\u3092\u4f7f\u3046\u3053\u3068\u3067\u3001\u30e2\u30c7\u30eb\u306e\u8a13\u7df4\u4e2d\u306b\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u30d0\u30c3\u30c1\u3092\u53d6\u5f97\u3067\u304d\u307e\u3059\u3002\n#ds = image_label_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n#print(ds)","4a403bd8":"# \u753b\u50cf\u3092normalize\u3057\u306a\u3044\u3068\u8868\u793a\u3067\u304d\u306a\u3044\n'''\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6,6))\nfor n,image in enumerate(image_ds.take(2)):\n  plt.subplot(1,2,n+1)\n  plt.imshow(image)\nplt.show()\n'''","6da67aee":"'''\ndef map_fn(image, label):\n      \"\"\"Produces multiple transformations of the same batch.\"\"\"\n      print(type(image))\n      label = tf.one_hot(label, 4)\n      return image, label\n'''","c98ba21b":"#ds = ds.map(map_fn)","a39e9bf6":"#ds","44eb0e56":"#!git clone https:\/\/github.com\/ta9ryuWalrus\/simclr.git","e7d9d057":"#!python \/kaggle\/working\/simclr\/tf2\/run.py --train_mode=pretrain --train_batch_size=32 --train_epochs=5 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model --eval_split=test --use_tpu=False","804590b2":"#!python \/kaggle\/working\/simclr\/tf2\/run.py --mode=train_then_eval --train_mode=finetune --train_batch_size=32 --train_epochs=10 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model --eval_split=test --use_tpu=False","ac31b2dd":"#!python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-3 --optimizer=adam --train_mode=pretrain --train_batch_size=32 --train_epochs=40 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model --eval_split=test --use_tpu=False","29dc6d1d":"#!python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-3 --optimizer=adam --mode=train_then_eval --train_mode=finetune --train_batch_size=32 --train_epochs=10 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model --eval_split=test --use_tpu=False","b7620a0d":"#! git clone https:\/\/github.com\/ta9ryuWalrus\/simclr.git","794638fe":"#! cp -r ..\/input\/trained-model\/trained_model \/kaggle\/working\/trained_model","a62c0e8a":"#!python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-3 --optimizer=adam --train_mode=pretrain --train_batch_size=32 --train_epochs=70 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model --eval_split=test --use_tpu=False","7fc0f903":"#! python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-3 --optimizer=adam --mode=train_then_eval --train_mode=finetune --train_batch_size=32 --train_epochs=10 --pretrain_steps=19188 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model --eval_split=test --use_tpu=False","b72c4687":"#! python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-4 --optimizer=adam --train_mode=pretrain --train_batch_size=32 --train_epochs=10 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model2 --eval_split=test --use_tpu=False","d8850d14":"#! python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-4 --optimizer=adam --mode=train_then_eval --train_mode=finetune --train_batch_size=32 --train_epochs=10 --pretrain_steps=4681 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model2 --eval_split=test --use_tpu=False","ec2b7a46":"#! cp -r ..\/input\/trained-model\/trained_model \/kaggle\/working\/trained_model","c217964a":"#! python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-3 --optimizer=adam --mode=train_then_eval --train_mode=finetune --train_batch_size=32 --train_epochs=10 --supervised_ratio=0.5 --pretrain_steps=19188 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model --eval_split=test --use_tpu=False","e881df91":"#! git clone https:\/\/github.com\/ta9ryuWalrus\/simclr.git\n#! cp -r ..\/input\/trained-model\/trained_model \/kaggle\/working\/trained_model\n#! cp -r ..\/input\/trained-model\/trained_model \/kaggle\/working\/trained_model70epochs # \u53e4\u3044\u3084\u3064\u306f\u3053\u3053\u306b\u4fdd\u7ba1\u3059\u308b","b631f3dc":"#! python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-3 --optimizer=adam --mode=train_then_eval --train_mode=finetune --train_batch_size=32 --train_epochs=10 --pretrain_steps=33228 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model --eval_split=test --use_tpu=False","6826c3e8":"#! git clone https:\/\/github.com\/ta9ryuWalrus\/simclr.git\n#! cp -r ..\/input\/trained-model\/trained_small_model \/kaggle\/working\/trained_small_model","363ded31":"#!python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-3 --optimizer=adam --train_mode=pretrain --train_batch_size=64 --train_epochs=40 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_small_model --eval_split=test --use_tpu=False","7e150933":"#! python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-3 --optimizer=adam --mode=train_then_eval --train_mode=finetune --train_batch_size=64 --train_epochs=10 --pretrain_steps=9360 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_small_model --eval_split=test --use_tpu=False","795601a0":"! git clone https:\/\/github.com\/ta9ryuWalrus\/simclr.git","6039d069":"#! python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-4 --seed=0 --fold=4 --optimizer=adam --train_mode=pretrain --train_batch_size=64 --train_epochs=40 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model_seed0_fold4 --eval_split=test --use_tpu=False","0a005f7c":"! cp -r ..\/input\/trained-model\/trained_model_seed0_fold4 \/kaggle\/working\/trained_model_seed0_fold4","3814cdf8":"! python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-4 --seed=0 --fold=4 --optimizer=adam --mode=train_then_eval --train_mode=finetune --train_batch_size=64 --train_epochs=40 --pretrain_steps=10947 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model_seed0_fold4 --eval_split=test --use_tpu=False","8a8c7536":"! python \/kaggle\/working\/simclr\/tf2\/run.py --learning_rate=1e-4 --seed=0 --fold=4 --optimizer=adam --mode=check --train_batch_size=64 --resnet_depth=18 --model_dir=\/kaggle\/working\/trained_model_seed0_fold4 --eval_split=test --use_tpu=False","74f68aad":"! rm -r \/kaggle\/working\/simclr","db2b128d":"'''\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\ndf = pd.read_csv('\/kaggle\/input\/cassava-leaf-disease-classification\/train.csv')\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\nfor train_idx, test_idx in kf.split(df['image_id'], df['label']):\n  train_df = df.iloc[train_idx]\n  test_df = df.iloc[test_idx]\n  train_labels = np.array(train_df['label'])\n  labeled_idx, _ = train_test_split(train_labels, train_size=0.1, random_state=0)\n  labeled_df = train_df.iloc[labeled_idx]\n  print()\n  print('labeled train set:')\n  print(labeled_df['label'].value_counts())\n  print()\n  print('test set:')\n  print(test_df['label'].value_counts())\n'''","85ebacf0":"### pretrain\u3092\u5c11\u3057\u77ed\u3081\u306b\u3057\u305f\u5834\u5408 ###","c119b7da":"## \u30c7\u30fc\u30bf\u306e\u5206\u5e03\u3092\u30c1\u30a7\u30c3\u30af","bb009067":"# **\u5165\u529b\u306e\u5f62\u5f0f**","fbe81e2e":"* 40epoch\u4e8b\u524d\u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u3092\u8aad\u307f\u8fbc\u3093\u3067finetuning\u3057\u3066\u307f\u308b\n* input\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bdataset\u3068\u3057\u3066\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092load\u3057\u3066\u3044\u308b\u304c\u3001permission\u306e\u95a2\u4fc2\u3067\u3053\u3053\u304b\u3089\u76f4\u63a5\u8aad\u307f\u8fbc\u3093\u3067finetuning\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u304b\u3063\u305f\u306e\u3067\u3001\u4e00\u5ea6output\u306e\u65b9\u306b\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u30b3\u30d4\u30fc\u3057\u3066\u304b\u3089finetuning\u3057\u3066\u3044\u308b","4a5b7bfb":"70epoch\u306e\u4e8b\u524d\u5b66\u7fd2\u306e\u5f8c\u300110epoch\u306efinetuning\u3092\u3057\u305f\u7d50\u679c\n* accuracy: 0.639","3835dff4":"# **\u8f9e\u66f8\u578b\u3067\u306a\u304f\u3066\u3082\u52d5\u304f\u304b\u306e\u78ba\u8a8d**","decfa201":"# ***\u8ab2\u984c***\n* \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\u65b9\u6cd5\n* \/kaggle\/working\/\u306e\u4e0b\u306b\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u3088\u3046\u306b\u306f\u306a\u3063\u3066\u3044\u308b\u304c\u3001notebook\u3092\u518d\u8d77\u52d5\u3059\u308b\u3068\u6d88\u3048\u3066\u3057\u307e\u3046","7cf0a270":"* \u4e0a\u306e\u30bb\u30eb\u306e\u5b9f\u884c\u3067GPU\u306eRAM\u306f15.2GB\/15.9GB\u4f7f\u7528\u3057\u3066\u304a\u308a\u304b\u306a\u308a\u30ae\u30ea\u30ae\u30ea\n* CPU\u3082GPU\u3082\u4f7f\u7528\u7387100%\u306b\u306a\u3063\u3066\u3044\u305f","8ffb710f":"* 10epoch\u306efine-tuning\n* acc=0.614\n* supervised\u30c7\u30fc\u30bf\u306e\u5272\u5408\u304c10%\u306a\u306e\u304c\u554f\u984c\u8a2d\u5b9a\u3068\u3057\u3066\u96e3\u3057\u3059\u304e\u308b\u53ef\u80fd\u6027","3fdf9f3f":"* 10epoch\u306e\u5b66\u7fd2\u3067contrast acc\u304c26.6%\u307e\u3067\u5411\u4e0a\u3057\u305f\n* supervised acc\u306f\u76f8\u5909\u308f\u3089\u305a61%\u7a0b\u5ea6\n* 15epoch\u5b66\u7fd2\u3059\u308b\u3068\u3001contrast acc\u304c41.6%\u3001supervised acc\u304c61.4%\n* \u4e0a\u306e\u30b3\u30fc\u30c9\u3067pretrain\u3057\u305f\u30e2\u30c7\u30eb\u304ctrained_model\u306b\u4fdd\u5b58\u3055\u308c\u3066\u3044\u308b","8ff961ec":"40epoch\u306e\u4e8b\u524d\u5b66\u7fd2->10epoch\u306efine-tuning\n* accuracy = 0.643","5e655389":"# ***\u5b66\u7fd2\u7387\u3068optimizer\u3092\u5909\u66f4\u3057\u3066\u307f\u308b***","88729c5f":"# **cassava\u306e\u30c7\u30fc\u30bf\u3092\u4e0a\u306e\u5f62\u5f0f\u306b\u5408\u308f\u305b\u308b**","9a09c0b6":"# \u753b\u50cf\u30b5\u30a4\u30ba\u3092\u5c0f\u3055\u304f\u3059\u308b(600->400)","df32ff42":"# 1\/25\nk-fold\u3067\u8a55\u4fa1","2c5be657":"40epoch\u306e\u4e8b\u524d\u5b66\u7fd2\n* contrast_acc = 0.641\n* supervised_acc = 0.630","6f179e6b":"## 1\/13","76dc634f":"* \u4e0a\u8a18\u306e\u8a2d\u5b9a\u3067GPU\u306e\u30e1\u30e2\u30ea\u30fc\u306f15.2GB\/15.9GB\u4f7f\u3046\n* GPU\u4f7f\u7528\u7387\u306e\u4e0a\u9650\u306b\u95a2\u308f\u3089\u305a\u30e1\u30e2\u30ea\u306e\u4f7f\u7528\u91cf\u306f\u4e00\u5b9a\u306a\u306e\u3067\u3001\u7121\u99c4\u306a\u8aad\u307f\u8fbc\u307f\u304c\u767a\u751f\u3057\u3066\u3044\u305d\u3046(?)\n* \u307e\u305fGPU\u4f7f\u7528\u7387\u306f0~100%\u3067\u5468\u671f\u7684\u306b\u5909\u52d5\u3057\u3066\u3044\u308b\u306e\u3067\u3001iteration\u306e\u5207\u308c\u76ee\u3068\u304bCPU\u306e\u51e6\u7406\u304c\u5f8b\u901f\u306b\u306a\u3063\u3066\u3057\u307e\u3063\u3066\u3044\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b(CPU\u4f7f\u7528\u7387\u306f\u5e38\u306b150%\u524d\u5f8c(\u2190?))\n* CPU\u306e\u30e1\u30e2\u30ea\u3084Disk\u306f\u307b\u3068\u3093\u3069\u4f7f\u308f\u308c\u3066\u3044\u306a\u3044\n* batch size32\u306f\u52d5\u304f(48\u306f\u52d5\u304b\u306a\u3044)\n* batch size32\u3060\u306815\u5206\u304f\u3089\u3044\u30671epoch\u304c\u7d42\u308f\u308b\n* \u8a66\u3057\u306b5epoch\u3084\u3063\u3066\u307f\u305f\u304c\u7cbe\u5ea6\u306f\u5411\u4e0a\u305b\u305a->pretrain\u306a\u306e\u3067\u305d\u308c\u306f\u554f\u984c\u306a\u3044(\u5be7\u308dlabel\u3092\u4e00\u5207\u4f7f\u308f\u305a\u306b60%\u304f\u3089\u3044\u5f53\u3066\u3066\u308b\u306e\u3059\u3054\u3044)\n* contrast acc\u304c\u3069\u308c\u304f\u3089\u3044\u4e0a\u304c\u308b\u307e\u3067\u5b66\u7fd2\u3059\u3079\u304d\u306a\u306e\u304b\uff1f5epoch\u3067\u306f15%\u7a0b\u5ea6\u3057\u304b\u5f53\u3066\u3089\u308c\u3066\u3044\u306a\u3044","3de2a79f":"# 1\/20","63854957":"# Cassava\u30c7\u30fc\u30bf\u3067SimCLR\u3092\u691c\u8a3c(12\/21)","ef6dde64":"# \u30c7\u30fc\u30bf\u306e\u4f7f\u3044\u65b9\u306e\u65b9\u91dd\n* train\u3068test\u306b\u5206\u3051\u308b(7:3\u3068\u304b)\n* pretrain\u3067\u306flabel\u306f\u4f7f\u308f\u306a\u3044\u306e\u3067train\u3092\u305d\u306e\u307e\u307e\u4f7f\u3046\n* fine-tuning\u306e\u969b\u306blabel\u3092\u4f7f\u3046\u304c\u3001\u3053\u3053\u3067\u306fsemi-supervised\u306e\u6027\u80fd\u3092\u691c\u8a3c\u3057\u305f\u3044\u306e\u3067\u3001train\u306e\u3046\u306110%\u7a0b\u5ea6\u306e\u307f\u3092fine-tuning\u306b\u4f7f\u3046\n\n\u3053\u3046\u3044\u3046\u611f\u3058\uff1f\n* \u3042\u304f\u307e\u3067\u3082SimCLR\u306fself-supervised\u306e\u624b\u6cd5\u306a\u306e\u3067\u3001pretrain\u306e\u3068\u3053\u308d\u3057\u304b\u3061\u3083\u3093\u3068\u8a18\u8ff0\u3055\u308c\u3066\u3044\u306a\u3044\u611f\n* \u305d\u306e\u5f8c\u306fsemi-supervised\u3068\u3057\u3066\u4f7f\u3046\u3082\u3001\u5225\u306e\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066supervised\u3067fine-tuning\u3059\u308b\u3082\u3001\u5404\u3005\u306e\u81ea\u7531\u3068\u3044\u3046\u611f\u3058\u304b\uff1f","bcdf48ab":"fine-tuning","f21eef78":"* 15epoch\u306epretrain\u306e\u5f8c\u306b20epoch\u306efine-tuning\n* \u5b66\u7fd2\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u89e3\u7387\u306f66.2%\u3067\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u6b63\u89e3\u7387\u306f62.0%(\u3042\u307e\u308a\u5b66\u7fd2\u3067\u304d\u3066\u3044\u306a\u3044\uff1f)","59d50424":"* \u5b66\u7fd2\u7387\u3084epoch\u6570\u306a\u3069\u3092\u5909\u3048\u3066\u3082acc\u304c0.622\u304b\u3089\u5168\u7136\u5909\u308f\u3089\u306a\u3044\u306e\u3067finetuning\u3055\u308c\u3066\u3044\u306a\u3044\u53ef\u80fd\u6027\n* log\u3092\u8aad\u3080\u306b\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306e\u8aad\u307f\u8fbc\u307f\u306f\u6b63\u3057\u304f\u884c\u308f\u308c\u3066\u3044\u305d\u3046\n* global step=19188\u3068\u3044\u3046\u306e\u304cpretrain\u304b\u3089\u5f15\u304d\u7d99\u304c\u308c\u3066\u3044\u3066\u3001finetuning\u306etrain_steps=469\u3092\u4e0a\u56de\u3063\u3066\u3057\u307e\u3063\u3066\u3044\u308b\u3053\u3068\u304b\u3089\u5b66\u7fd2\u304c\u884c\u308f\u308c\u305a\u306b\u3044\u308b\u3002\n* -> finetuning\u6642\u306eepoch\u6570\u306fpretrain\u306eepoch\u6570+finetuning\u306eepoch\u6570\u3068\u3057\u3066\u6307\u5b9a\u3059\u308b\uff1f->\u7d50\u5c40finetuning\u306e\u30c7\u30fc\u30bf\u6570\u304c\u5c11\u306a\u304fstep\u6570\u304c\u5c0f\u3055\u304f\u898b\u7a4d\u3082\u3089\u308c\u308b\u306e\u3067\u3053\u308c\u3067\u306f\u30c0\u30e1\n* -> \u66f8\u304d\u63db\u3048\u305f\u3002--pretrain\u3067pretrain\u3067\u5b66\u7fd2\u3057\u305fstep\u6570\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u3067\u3001train_steps\u3092\u6b63\u3057\u304f\u8a08\u7b97\u3067\u304d\u308b\u3002--train_epochs\u306e\u3068\u3053\u308d\u306ffinetuning\u3092\u884c\u3046epoch\u6570\u3092\u6307\u5b9a\u3059\u308b\u3002\n* \u3068\u308a\u3042\u3048\u305a\u671f\u5f85\u901a\u308a\u306b\u52d5\u304f\u3053\u3068\u306f\u78ba\u8a8d\u3067\u304d\u305f\n* 40epoch\u306epretrain\u306e\u3042\u306810epoch\u306efinetuning\u3092\u3057\u305f\u3068\u304d\u306e\u7cbe\u5ea6\u306f0.628\u7a0b\u5ea6(finetuning\u9014\u4e2d\u306etrain\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u7cbe\u5ea6\u306f0.68\u304f\u3089\u3044)","c87c772c":"* lr=1e-4\u3001epoch=10\u3067pretrain\n* contrast_acc=0.170\u3001supervised_acc=0.614","6fa00c43":"40epoch\u4e8b\u524d\u5b66\u7fd2\u3057\u305f\u3084\u3064\u3092\u3055\u3089\u306b\u8ffd\u52a0\u306730epoch\u4e8b\u524d\u5b66\u7fd2\u3059\u308b\n-> \u53e4\u3044\u30e2\u30c7\u30eb\u306f\u524a\u9664\u3055\u308c\u308b\u3088\u3046\u306a\u30b3\u30fc\u30c9\u306b\u306a\u3063\u3066\u3044\u305f\u306e\u3067\u3001\u6b8b\u3057\u305f\u3051\u308c\u3070\u53e4\u3044\u3084\u3064\u3068\u65b0\u3057\u304f\u4fdd\u5b58\u3059\u308b\u3084\u3064\u3092\u5225\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u6b8b\u3059\u5fc5\u8981\u304c\u3042\u308a\u305d\u3046(\u3053\u3053\u3092\u66f8\u304d\u63db\u3048\u308b\u306e\u306f\u9762\u5012)","20b9e949":"\u30c7\u30fc\u30bf\u306e\u96c6\u8a08","05feec0e":"# ***log***\n* pretrain5epoch\u3067acc\u304c60\uff05\u304f\u3089\u3044\u306b\u306a\u308a\n* finetuning10epoch\u306770%\u5f31\u304f\u3089\u3044\u307e\u3067\u4e0a\u6607","28d9dc31":"70epoch\u5b66\u7fd2\u3057\u305f\u30e2\u30c7\u30eb\u3067fine-tuning\u3092\u3057\u3066\u307f\u308b\u3002\n\n\u4e8b\u524d\u5b66\u7fd2\u6642\u306e\u6027\u80fd\u306f\u3001\n* contrast_acc: 0.815\n* supervised_acc: 0.628","1da27962":"label count\n* 0: 1087\n* 1: 2189\n* 2: 2386\n* 3: 13158\n* 4: 2577","f0657df7":"* supervised ratio=50%\u306e\u5834\u5408\u3092\u8a66\u3057\u3066\u307f\u308b\n* supervised ratio\u306fpretrain\u306b\u306f\u95a2\u4fc2\u306a\u3044\u306e\u3067\u3001\u3059\u3067\u306b40epoch\u5b66\u7fd2\u6e08\u307f\u306e\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3059\u308b","63a5844e":"* seed=0\n* 5-fold\u306e1\u3064\u3081\n* \u3053\u306e\u8a2d\u5b9a\u3060\u306820epoch\u304f\u3089\u3044\u3067contrast acc\u304c92%\u304f\u3089\u3044\u306b\u53ce\u675f\u3059\u308b","1dcafd51":"* 40epoch pretrain\u3057\u305f\u3068\u3053\u308d\u3001contrast acc\u304c0.745\u3001supervised acc\u304c0.621\u3068\u306a\u3063\u305f\n* \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3067\u304d\u305f","df268b35":"* lr=1e-3\n* supervised_ratio=0.5\n* epochs=10\n* \u4e0a\u8a18\u306e\u8a2d\u5b9a\u3067finetuning\u3057\u3066acc\u306f0.628(supervised_ratio=0.1\u306e\u6642\u3068\u5909\u308f\u3063\u3066\u306a\u3044)","f1bd21d6":"10epoch\u306efinetuning\u3067\n* loss 0.00245\n* acc 0.614","60480dbb":"## \u51fa\u529b\u306e\u30c1\u30a7\u30c3\u30af","4d4f6dbb":"\u305d\u3082\u305d\u3082cifar10\u3082\u8f9e\u66f8\u578b\u3067\u306f\u306a\u304f\u306a\u308b\u3053\u3068\u304c\u5224\u660e\u3057\u305f\u306e\u3067\u5927\u4e08\u592b","25066941":"* top1 accuracy: 0.61\n* top5 accuracy: 1.0(5class\u306a\u306e\u3067\u5f53\u305f\u308a\u524d)\n\n* train\u3068test\u306e\u5206\u3051\u65b9\u3068labeled\u3068unlabeled\u306e\u5206\u3051\u65b9\u304c\u9055\u3046\u3063\u307d\u3044\u3002\n* train:test\u30921:9\u306b\u3057\u305f\u3089\u4e0a\u8a18\u306e\u3088\u3046\u306b\u306a\u3063\u305f\u304c\u3001eval\u6642\u306b\u5168\u4f53\u306e9\u5272\u3092\u5360\u3081\u308btest\u306elabel\u60c5\u5831\u3092\u4f7f\u3063\u3066fine-tuning\u3057\u3066\u3057\u307e\u3063\u3066\u3044\u308b\u6c17\u304c\u3059\u308b\n* labeled\u3068unlabeled\u306e\u5206\u3051\u65b9\u306f\u3069\u3053\u3067\u6c7a\u3081\u3066\u3044\u308b\uff1f\n* \u2191data.py\u306e_input_fn\u306b\u3042\u308bbuilder.as_dataset(as_supervised=True)\u304c\u602a\u3057\u3044\u6c17\u304c\u3059\u308b->as_supervised\u306f\u8f9e\u66f8\u578b\u304b\u3089image\u3068label\u306etuple\u306b\u5909\u63db\u3057\u3066\u3044\u308b\u3060\u3051"}}