{"cell_type":{"f1ef16fb":"code","47907f6f":"code","62840d1a":"code","a7072ecc":"code","c8c5d28e":"code","59567a84":"code","8db2b93a":"code","b0603e75":"code","f9891f80":"markdown","c61351ed":"markdown","072064ab":"markdown","a9b73946":"markdown","02d4e0cd":"markdown"},"source":{"f1ef16fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport sklearn.decomposition as skde\nimport sklearn.model_selection as ms\nfrom sklearn import linear_model\nimport sklearn.metrics as sklm\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","47907f6f":"#import required datasets\ntest_data = pd.read_csv(\"..\/input\/test.csv\")\ntrain_data= pd.read_csv(\"..\/input\/train.csv\")\ntrain_data.head()","62840d1a":"#view Data shape\nprint(train_data.shape,test_data.shape)\n#check for missing values\nprint(train_data.isnull().values.any(),test_data.isnull().values.any())\n#check data correlation \nprint(train_data.corr())\n#Visualize class distribution\nsns.countplot(train_data['target'])","a7072ecc":"# check class distribution in percentage\ncount_0 = len(train_data[train_data[\"target\"] == 0])\ncount_1 = len(train_data[train_data[\"target\"] == 1])\npercentage_count_0 = ((count_0)\/(count_0+count_1)) * 100\npercentage_count_1 = 100-percentage_count_0\nprint(\"{}{}{}{}{}\".format(\"Percentage of 0 class is \",percentage_count_0,\"\\n\",\"Percentage of 1 class is \",percentage_count_1))\n","c8c5d28e":"labels = train_data[\"target\"]\nnew_train_data = train_data.drop([\"target\",\"ID_code\"],axis =1)\nnew_train_data.head()\nx_train, x_test, y_train, y_test = train_test_split(new_train_data, labels, test_size = 0.25, random_state = 0)\nprint(x_train.shape,x_test.shape)\nprint(y_train.shape,y_test.shape)\nx_train.head()","59567a84":"folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=2319)\nparam = {\n    'bagging_freq': 5, \n    'bagging_fraction': 0.33,\n    'boost_from_average':'false',   \n    'boost': 'gbdt',\n    'feature_fraction': 0.0405,\n    'learning_rate': 0.083,\n    'max_depth': -1,\n    'metric':'auc',\n    'min_data_in_leaf': 80,     \n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 13,\n    'num_threads': 4,            \n    'tree_learner': 'serial',\n    'objective': 'binary',\n    'verbosity': 1\n}\noof = np.zeros(len(train_data))\npredictions = np.zeros(len(test_data))\nfeatures = [c for c in train_data.columns if c not in ['ID_code', 'target']]\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train_data.values, labels.values)):\n    trn_data = lgb.Dataset(train_data.iloc[trn_idx][features], label=labels.iloc[trn_idx])\n    val_data = lgb.Dataset(train_data.iloc[val_idx][features], label=labels.iloc[val_idx])\n    clf = lgb.train(param, trn_data, 1000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n    oof[val_idx] = clf.predict(train_data.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    predictions += clf.predict(test_data[features], num_iteration=clf.best_iteration) \/ folds.n_splits\n","8db2b93a":"target = train_data.iloc[val_idx]['target']\nprint(\"\\n >> CV score: {:<8.5f}\".format(roc_auc_score(target, oof[val_idx])))\n","b0603e75":"ID_code = test_data[\"ID_code\"]\nsubmission = pd.DataFrame({'ID_code' : ID_code,\n                            'target' : predictions})\nsubmission.to_csv('.\/version1.csv', index=False)\nsub = pd.read_csv('.\/version1.csv')\nsub.head()","f9891f80":"**Split train_data into train and validation sets**","c61351ed":"Import Datasets****\n","072064ab":"Use StratifiedKFold to ensure test and train datasets contains equal percentage of both classes","a9b73946":"**Explore Datasets**\n- View Data information\n- Check for missing values\n- Check correlation \n- Visualize class distribution","02d4e0cd":"**Deductions from the above**\n- There are no missing vallues in either the test or train sets\n- The train set contains an extra column which is the known target to be used in training our model\n- There is no correlation between the features in the train dataset\n- There is a significant class imbalance between the 0s and 1s\n\nThe percentage of each class is calculated in the cell below"}}