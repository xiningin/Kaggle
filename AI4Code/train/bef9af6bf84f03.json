{"cell_type":{"4d67e2b7":"code","a10ef824":"code","83158db9":"code","4333ef7b":"code","5a0e609d":"code","87f2b8ad":"code","b450db56":"code","0e2c5968":"code","e2fd3a18":"code","4d6fb106":"code","02e12294":"code","447d77fd":"code","9da0dba6":"code","7d50e4c4":"code","da52ea40":"code","e39b01a3":"code","fee1b662":"code","e23e2daf":"code","fcf7a8bb":"code","74c9e0e5":"markdown"},"source":{"4d67e2b7":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras import regularizers\nfrom tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax","a10ef824":"train_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/train' #path of training data\ntest_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/test' #path of testing data\nvalidation_dir = '..\/input\/chest-xray-pneumonia\/chest_xray\/val' #path of validation data","83158db9":"img_size = 150 #initializing the size of the image\ndata = [] #empty list to store the data\nassign_dict = {\"NORMAL\":0,\"PNEUMONIA\":1} #our labels\n\ndef load_data(directory): #this method will help in reading our data from the directories\n    for sub_directory in os.listdir(directory):\n        if sub_directory == \"NORMAL\":\n            inner_directory = os.path.join(directory,sub_directory)\n            for i in os.listdir(inner_directory):\n                img = cv2.imread(os.path.join(inner_directory,i),0)\n                img = cv2.resize(img,(img_size,img_size))\n                data.append([img,assign_dict[sub_directory]])\n                \n        if sub_directory == \"PNEUMONIA\":\n            inner_directory = os.path.join(directory,sub_directory)\n            for i in os.listdir(inner_directory):\n                img = cv2.imread(os.path.join(inner_directory,i),0)\n                img = cv2.resize(img,(img_size,img_size))\n                data.append([img,assign_dict[sub_directory]])\n                \n    return np.array(data) #converting our data into an array","4333ef7b":"train_data = load_data(train_dir) #getting our training data in array \ntest_data = load_data(test_dir) #getting our testing data in array\nval_data = load_data(validation_dir) #getting our validation data","5a0e609d":"print(train_data.shape) #printing the shape of our training, validation and testing data\nprint(test_data.shape)\nprint(val_data.shape)","87f2b8ad":"#printing the total images present in our training data along with number of images in each category\ntotal_images = 0 \nnum_normal = 0\nnum_pneumonia = 0\nnormal = []\npneumonia = []\nfor i in train_data:\n    if i[1]==0:\n        total_images +=1\n        num_normal+=1\n        normal.append(i[0])\n    else:\n        total_images+=1\n        num_pneumonia+=1\n        pneumonia.append(i[0])\n        \nprint(\"Total Images = \",total_images)\nprint(\"Total Normal Images = \",num_normal)\nprint(\"Total Pneumonia Images = \",num_pneumonia)","b450db56":"x_train = [] #creating our training data\ny_train = []\nfor x,y in train_data:\n    x_train.append(x)\n    y_train.append(y)","0e2c5968":"x_val = [] #creating our validation data\ny_val = []\nfor x,y in train_data:\n    x_val.append(x)\n    y_val.append(y)","e2fd3a18":"x_test = [] #creating our testing data\ny_test = []\nfor x,y in test_data:\n    x_test.append(x)\n    y_test.append(y)","4d6fb106":"#normalizing our data\nx_train = np.array(x_train)\/255\nx_train = x_train.reshape(-1,img_size,img_size,1)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\nx_test = np.array(x_test)\/255\nx_test = x_test.reshape(-1,img_size,img_size,1)\nx_val = np.array(x_val)\/255\nx_val = x_val.reshape(-1,img_size,img_size,1)\ny_val = np.array(y_val)","02e12294":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nprint(x_val.shape)\nprint(y_val.shape)","447d77fd":"#performing data augmentation\nimage_generator = ImageDataGenerator(rotation_range = 90,\n                                     zoom_range = 0.2,\n                                     width_shift_range = 0.2,\n                                     height_shift_range = 0.2,\n                                     horizontal_flip = True,\n                                     )","9da0dba6":"#creating our model\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32,kernel_size = (3,3),padding = 'same',activation = 'relu',input_shape=(img_size,img_size,1)))\nmodel.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\n\nmodel.add(Conv2D(filters = 128,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(units = 512,activation = 'relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1,activation = 'sigmoid'))\n\nmodel.compile(\n    optimizer = Adam(lr=0.0001), \n    loss='binary_crossentropy', \n    metrics=['accuracy']\n  )","7d50e4c4":"model.summary() #printing the summary of our model","da52ea40":"history = model.fit(image_generator.flow(x_train,y_train,batch_size  = 32),epochs = 30,validation_data = image_generator.flow(x_val,y_val))","e39b01a3":"epochs = [i for i in range(30)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\nax[0].set_title('Training & Validation Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\nax[1].set_title('Testing Accuracy & Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Training & Validation Loss\")\nplt.show()","fee1b662":"print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0]) #checking the performance of our model\nprint(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1])","e23e2daf":"model.save('Pneumonia.h5')","fcf7a8bb":"model.save_weights('Pneumonia_weights.h5')","74c9e0e5":"# Pneumonia Detection"}}