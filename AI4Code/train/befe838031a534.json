{"cell_type":{"bb890bdc":"code","0d3f5a03":"code","ef248f6d":"code","70c8992a":"code","4929b3e6":"code","ba2c9709":"code","d367d794":"code","7705b0d6":"code","39a0868e":"code","b5368ccf":"code","c6ab1ce4":"code","dd4145dd":"code","a0af0d37":"code","a8acac33":"code","63a270a7":"code","f1046612":"code","9eeabe59":"code","c38477d3":"code","5495b253":"code","5c8418e6":"code","61dd20bd":"code","dc4c73e8":"code","eb20e546":"code","37fb8fa8":"code","616f5b77":"code","b15b2f3c":"code","1f7dcdd6":"code","f771ffbc":"code","31e1af42":"markdown","413b41fc":"markdown","22139abb":"markdown","8441285b":"markdown","b7988386":"markdown","9d9a7a88":"markdown","d997325e":"markdown","d582a710":"markdown"},"source":{"bb890bdc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0d3f5a03":"\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","ef248f6d":"\ntrain = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\ntest = pd.read_csv('..\/input\/mobile-price-classification\/train.csv')\n\nX_train = train.drop([\"price_range\"],axis=1)\ny_train = train[\"price_range\"]","70c8992a":"print(train.columns)\nprint(train.head())\n\n","4929b3e6":"print(test.columns)\nprint(test.head())","ba2c9709":"train.info()\ntrain.describe()","d367d794":"#buliding the optimal data using automatic backward elimnation\nimport statsmodels.api as sm\nSL = 0.05\nX_train_arr=X_train.values\nX_opt = X_train_arr[:, [0, 1, 2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]]\nX=np.append(arr=np.ones((2000,1)).astype(int),values=X_train,axis=1)\nregressor_ols=sm.OLS(endog=y_train,exog=X_opt).fit()\n\nprint(regressor_ols.summary())\nli=[]\ndef backwardElimination(x, sl):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        regressor_OLS = sm.OLS(y_train, x).fit()\n        maxVar = max(regressor_OLS.pvalues)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (regressor_OLS.pvalues[j] == maxVar):\n                    x = np.delete(x, j, 1)\n                    li.append(j)\n    regressor_OLS.summary()\n    return x\nX_Modeled = backwardElimination(X_opt, SL)\ntest=test.values\ntest=np.delete(test,5,1)\ntest=np.delete(test,6,1)\ntest=np.delete(test,12,1)","7705b0d6":"len(X_Modeled[0])","39a0868e":"#Applying feature scaling\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_Modeled= sc.fit_transform(X_Modeled)\ntest = sc.fit_transform(test)","b5368ccf":"len(test[0])","c6ab1ce4":"from sklearn.model_selection import train_test_split\nX_train1, X_test1, y_train1, y_test1 = train_test_split(X_Modeled, y_train, test_size = 0.3, random_state = 0)","dd4145dd":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train1, y_train1)","a0af0d37":"# Predicting the Test set results\ny_pred_SVC= classifier.predict(X_test1)","a8acac33":"#calculating accuracy\nacc_SVC= round(classifier.score(X_train1,y_train1) * 100, 2)\nprint(acc_SVC)","63a270a7":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_SVC= confusion_matrix(y_test1, y_pred_SVC)\nprint(cm_SVC)","f1046612":"import sklearn","9eeabe59":"from sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression(random_state=0)\nclassifier.fit(X_train1,y_train1)","c38477d3":"# Predicting the Test set results\ny_pred_logistic= classifier.predict(X_test1)","5495b253":"#calculating accuracy\nacc_logistic= round(classifier.score(X_train1,y_train1) * 100, 2)\nprint(acc_SVC)","5c8418e6":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_logistic= confusion_matrix(y_test1, y_pred_logistic)\nprint(cm_logistic)","61dd20bd":"from sklearn.neighbors import KNeighborsClassifier\nclassifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\nclassifier.fit(X_train1,y_train1)","dc4c73e8":"# Predicting the Test set results\ny_pred_knn= classifier.predict(X_test1)","eb20e546":"#calculating accuracy\nacc_knn= round(classifier.score(X_train1,y_train1) * 100, 2)\nprint(acc_knn)","37fb8fa8":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_knn= confusion_matrix(y_test1, y_pred_knn)\nprint(cm_knn)","616f5b77":"from sklearn.ensemble import RandomForestClassifier\nclassifier=RandomForestClassifier(n_estimators=10,criterion=\"entropy\",random_state=0)\nclassifier.fit(X_train1,y_train1)","b15b2f3c":"# Predicting the Test set results\ny_pred_random= classifier.predict(X_test1)","1f7dcdd6":"#calculating accuracy\nacc_random= round(classifier.score(X_train1,y_train1) * 100, 2)\nprint(acc_random)","f771ffbc":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm_random= confusion_matrix(y_test1, y_pred_random)\nfrom sklearn.metrics import classification_report,confusion_matrix\nprint(classification_report(y_test1,y_pred_random))","31e1af42":"# Fitting Random forest classifier to the Training set","413b41fc":"# Splitting the dataset into the Training set and Test set","22139abb":"# Importing the dataset","8441285b":"# Importing the libraries","b7988386":"# Fitting the knn_calssifier to the training set","9d9a7a88":"# Fitting Kernel SVM to the Training set","d997325e":"# Analyzing the data","d582a710":"# Fitting logistic regression to the training set"}}