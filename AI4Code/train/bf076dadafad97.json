{"cell_type":{"83b52882":"code","980f3cd8":"code","034937de":"code","3fd70922":"code","a9707d5d":"code","0243ba65":"code","4a427b63":"code","24556cf7":"code","732b7862":"code","dfb5c4c1":"code","695221d8":"code","4f16302b":"code","9cb34d1c":"code","dd68d566":"code","f6d5776c":"code","b0088618":"code","7f688c6a":"code","c379bc83":"code","6d1092a8":"code","ad5c1b4f":"code","5b40d296":"code","1264c877":"code","3cf4a899":"code","567d955f":"code","7f877899":"code","ddfc4766":"code","f0f08e83":"code","2a93ea0d":"code","7eba9fde":"code","5640f1ef":"code","770a500b":"code","c1845a3f":"code","b21dafdf":"code","5db04eb6":"code","c2dfc399":"code","14307851":"code","7db8915c":"code","fc636ad3":"code","4b4a8370":"code","2919cf13":"code","a213f383":"code","0e0f6067":"code","1324e952":"code","3b92db8e":"code","f9db3cfc":"code","3a7c14df":"code","c1c9a618":"code","fb853d79":"code","a4c29c36":"code","396c8cdd":"code","d493c7f8":"code","553166a3":"code","2477eb1d":"code","00718fd9":"code","45b080bb":"code","e93ece28":"code","65edf500":"code","b22eb89f":"code","85158921":"code","c8be379e":"markdown","901919a9":"markdown","fc3d6bfe":"markdown","21418e10":"markdown","68b07e3e":"markdown","5c7ebbb2":"markdown","025dc1e2":"markdown","cf627f51":"markdown","83e2675f":"markdown","7270b9a4":"markdown","28a9b9c7":"markdown","9b590cab":"markdown","06dea2b2":"markdown","92240e71":"markdown","75449431":"markdown","0b789aa0":"markdown","f70cd5ce":"markdown","151aea4b":"markdown","84cc8b75":"markdown","daec5814":"markdown","aa93d941":"markdown","3a9645bc":"markdown","ad3d3772":"markdown","11ab07ca":"markdown","5bfc3650":"markdown","a419d234":"markdown","1b1317e5":"markdown","0fc817eb":"markdown","87608ce0":"markdown","e849fe65":"markdown"},"source":{"83b52882":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk # wonderful tutorial can be found here https:\/\/pythonprogramming.net\/tokenizing-words-sentences-nltk-tutorial\/\n\n%matplotlib inline","980f3cd8":"df = pd.read_csv('..\/input\/amazon-alexa-reviews\/amazon_alexa.tsv', sep='\\t')","034937de":"df.head(10)","3fd70922":"df.describe()","a9707d5d":"#omitting unnecessary columns\ncdf = df[['rating', 'verified_reviews']]\n\nprint(cdf['rating'].value_counts())","0243ba65":"cdf = pd.concat([cdf[cdf['rating'] < 5], cdf[cdf['rating'] == 5].sample(frac=1).iloc[:300]])\ncdf['rating'].describe()","4a427b63":"cdf['rating'].hist(bins=5)","24556cf7":"text_body = ''\nfor row in cdf.iterrows():\n    text_body += row[1]['verified_reviews'] + ' '\n    \ncleaned_text_body = re.sub('[^a-zA-Z]', ' ', text_body)\nword_list = nltk.tokenize.word_tokenize(cleaned_text_body.lower())\nword_set = set(word_list)","732b7862":"len(word_set)","dfb5c4c1":"embeddings = {}\nf = open('..\/input\/glove6b100dtxt\/glove.6B.100d.txt', 'r', encoding='utf-8')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    vector = np.asarray(values[1:], dtype='float32')\n    embeddings[word] = vector\nf.close()","695221d8":"def assess_embeddings(set_of_words):\n    c = 0\n    missing_embeddings = []\n    for word in set_of_words:\n        if word in embeddings:\n            c+=1\n        else:\n            missing_embeddings.append(word)\n\n    print(c\/len(set_of_words)*100, 'percents of words in reviews are covered in embeddings')\n    return missing_embeddings\n\nmissing_embeddings = assess_embeddings(word_set)    ","4f16302b":"print(sorted(missing_embeddings))","9cb34d1c":"import keras","dd68d566":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","f6d5776c":"tokenizer = Tokenizer(num_words=len(word_set))\ntokenizer.fit_on_texts([cleaned_text_body])\nprint('Words in word_index:', len(tokenizer.word_index))","b0088618":"_ = assess_embeddings(set([kvp for kvp in tokenizer.word_index]))","7f688c6a":"cdf['cleaned_text'] = cdf['verified_reviews'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\ncdf['cleaned_text'] = cdf['cleaned_text'].apply(lambda x: re.sub(' +',' ', x)) #remove consecutive spacing","c379bc83":"cdf['sequences'] = cdf['cleaned_text'].apply(lambda x: tokenizer.texts_to_sequences([x])[0])\ncdf['sequences'].head(10)","6d1092a8":"# Need to know max_sequence_length to pad other sequences\nmax_sequence_length = cdf['sequences'].apply(lambda x: len(x)).max()\ncdf['padded_sequences'] = cdf['sequences'].apply(lambda x: pad_sequences([x], max_sequence_length)[0])","ad5c1b4f":"print(cdf['padded_sequences'][2])","5b40d296":"train = cdf.sample(frac=0.8)\ntest_and_validation = cdf.loc[~cdf.index.isin(train.index)]\nvalidation = test_and_validation.sample(frac=0.5)\ntest = test_and_validation.loc[~test_and_validation.index.isin(validation.index)]\n\nprint(train.shape, validation.shape, test.shape)","1264c877":"def get_arrayed_data(df_set):\n    setX = np.stack(df_set['padded_sequences'].values, axis=0)\n    setY = pd.get_dummies(df_set['rating']).values #using one-hot encoding\n    \n    return (setX, setY)\n\ntrainX, trainY = get_arrayed_data(train)\nvalidationX, validationY = get_arrayed_data(validation)\ntestX, testY = get_arrayed_data(test)","3cf4a899":"from keras.layers import Embedding","567d955f":"embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\nfor word, i in tokenizer.word_index.items():\n    # words that are not in pretrained embedding will be zero vectors.\n    if word in embeddings:\n        embedding_matrix[i] = embeddings[word]","7f877899":"embedding_layer = Embedding(len(tokenizer.word_index) + 1, 100,\n                            weights=[embedding_matrix],\n                            input_length=max_sequence_length,\n                            trainable=False)","ddfc4766":"from keras.models import Sequential\nfrom keras.layers import Dense, Input, LSTM, Flatten, Dropout","f0f08e83":"def simple_reccurent_model(input_shape, output_shape):\n    model = Sequential()\n    model.add(embedding_layer)\n    model.add(LSTM(64, dropout=0.2))\n    #model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(output_shape, activation='softmax'))\n    return model","2a93ea0d":"model = simple_reccurent_model(trainX.shape[1], trainY.shape[1])\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])","7eba9fde":"model.summary()","5640f1ef":"model.fit(trainX, trainY, batch_size=64, epochs=100)","770a500b":"score, accuracy = model.evaluate(validationX, validationY, batch_size=64)\nprint(accuracy)","c1845a3f":"reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))","b21dafdf":"for i, y in enumerate(validationY):\n    #p = model.predict(np.array([validationX[i]])).round()[0].astype('int32')\n    prediction = model.predict(np.array([validationX[i]])).argmax()\n    actual = y.argmax()\n    if prediction != actual:\n        print(\"Validation\", i)\n        print(\"Predicted review:\", prediction + 1, \", actual review:\", actual + 1)\n        #print(validationX[i])\n        text = []\n        for word_i in validationX[i]:\n            if word_i in reverse_word_map:\n                text.append(reverse_word_map[word_i])\n        print(' '.join(text))\n        print()","5db04eb6":"def tunable_reccurent_model(input_shape, output_shape, hyperparams):\n    model = Sequential()\n    model.add(embedding_layer)\n    \n    for i, lstm_size in enumerate(hyperparams['lstm_sizes']):\n        model.add(LSTM(lstm_size, dropout=hyperparams['dp']))\n    \n    for i, dense_size in enumerate(hyperparams['dense_sizes']):\n        model.add(Dense(dense_size, activation=hyperparams['dense_activation']))\n        model.add(Dropout(hyperparams['dp']))\n    \n    model.add(Dense(output_shape, activation='softmax'))\n    return model","c2dfc399":"def evaluate_model(input_shape, output_shape,\n                   hyperparams, train_set, validation_set,\n                   train_epochs=100):\n    model = simple_reccurent_model(trainX.shape[1], trainY.shape[1])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=hyperparams['optimizer'],\n                  metrics=['accuracy'])\n    \n    model.fit(train_set[0], train_set[1], batch_size=hyperparams['batch_size'], epochs=train_epochs, verbose=0)\n    _, train_accuracy = model.evaluate(train_set[0], train_set[1])\n    _, validation_accuracy = model.evaluate(validation_set[0], validation_set[1])\n    print(\"Train accuaracy:\", train_accuracy, \"Validation Accuracy:\", validation_accuracy)\n    return validation_accuracy","14307851":"lstm_sizes = [[32], [64], [128], [64, 32]]\ndense_sizes = [[32], [64], [128], [64, 32]]\ndense_activations = ['relu', 'tanh', 'sigmoid']\ndps = [0.1, 0.2, 0.3]\noptimizers = ['Adam', 'SGD', 'RMSprop']\nepochs = [100, 125, 150]\nbatch_sizes = [32, 64, 128]\n\nresults = []\ncounter=1\n# all hyperparameters here are enumerated not in random order - the least important are closer to outer cycle\nfor ep in epochs:\n    for optimizer in optimizers:\n        for dense_activation in dense_activations:\n            for batch_size in batch_sizes:\n                for dp in dps:\n                    for dense_size in dense_sizes:\n                        for lstm_size in lstm_sizes:\n                            hyperparams = {\n                                'lstm_sizes': lstm_size,\n                                'dp': dp,\n                                'dense_sizes': dense_size,\n                                'dense_activation': dense_activation,\n                                'optimizer': optimizer,\n                                'batch_size': batch_size\n                            }\n                            #print(\"Interation\", counter)\n                            #acc = evaluate_model(trainX.shape[1], trainY.shape[1],\n                            #                    hyperparams, (trainX, trainY), (validationX, validationY),\n                            #                    ep)\n                            #results.append((acc, hyperparams, {'ep': ep, 'batch_size': batch_size}))\n                            #counter+=1\n                            #print()\n                            ","7db8915c":"import copy","fc636ad3":"lstm_sizes = [[32], [64], [64, 32]]\ndense_sizes = [[32], [64], [64, 32]]\ndense_activations = ['relu', 'tanh', 'sigmoid']\ndps = [0.1, 0.2, 0.3]\noptimizers = ['Adam', 'SGD', 'RMSprop']\nepochs = 10\nbatch_sizes = [32, 64, 128]\n\nhyperparams = {\n    'lstm_size': lstm_sizes,\n    'dense_size': dense_sizes,\n    'dense_activation': dense_activations,\n    'dp': dps,\n    'optimizer': optimizers,\n    'batch_size': batch_sizes\n}\n\ndefault_hyperparams = {\n    'lstm_size': [64],\n    'dp': 0.2,\n    'dense_size': [64],\n    'dense_activation': 'relu',\n    'optimizer': 'adam',\n    'batch_size': 64\n}\n\ncounter = 1\nvalidation_results = []\nfor hp_name, hp_list in hyperparams.items():\n    accs = []\n    for hp_val in hp_list:\n        hp = copy.deepcopy(default_hyperparams)\n        hp[hp_name] = hp_val\n        print(\"Interation\", counter)\n        acc = evaluate_model(trainX.shape[1], trainY.shape[1],\n                            hp, (trainX, trainY), (validationX, validationY), epochs)\n        counter+=1\n        accs.append(acc)\n        print()\n    validation_results.append((hp_name, accs))","4b4a8370":"fig = plt.figure(figsize=(6, 18))\n\nfor i, result in enumerate(validation_results):\n    ax = fig.add_subplot(len(validation_results), 1, i+1)\n    hp_name = result[0]\n    hp_errors = result[1]\n    \n    ax.set_title(hp_name)\n    ax.plot(range(0, len(hp_errors)), hp_errors)\n    plt.sca(ax)\n    x_labels = hyperparams[hp_name]\n    plt.xticks(range(0, len(hp_errors)), x_labels)\n    \nfig.tight_layout()\nplt.show()","2919cf13":"# edited function to return model\ndef evaluate_model(input_shape, output_shape,\n                   hyperparams, train_set, validation_set,\n                   train_epochs=100, verbose=0):\n    model = simple_reccurent_model(trainX.shape[1], trainY.shape[1])\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=hyperparams['optimizer'],\n                  metrics=['accuracy'])\n    \n    model.fit(train_set[0], train_set[1], batch_size=hyperparams['batch_size'], epochs=train_epochs, verbose=verbose)\n    _, train_accuracy = model.evaluate(train_set[0], train_set[1])\n    _, validation_accuracy = model.evaluate(validation_set[0], validation_set[1])\n    print(\"Train accuaracy:\", train_accuracy, \"Validation Accuracy:\", validation_accuracy)\n    return validation_accuracy, model","a213f383":"tuned_hyperparams = {\n    'lstm_size': [32],\n    'dp': 0.2,\n    'dense_size': [64],\n    'dense_activation': 'relu',\n    'optimizer': 'adam',\n    'batch_size': 32\n}\n\nacc, model = evaluate_model(trainX.shape[1], trainY.shape[1],\n    tuned_hyperparams, (trainX, trainY), (validationX, validationY), 100, 0)","0e0f6067":"tuned_hyperparams = {\n    'lstm_size': [32],\n    'dp': 0.5,\n    'dense_size': [64],\n    'dense_activation': 'relu',\n    'optimizer': 'adam',\n    'batch_size': 32\n}\n\nacc, model2 = evaluate_model(trainX.shape[1], trainY.shape[1],\n    tuned_hyperparams, (trainX, trainY), (validationX, validationY), 50, 0)","1324e952":"error_count = 0\nfor i, y in enumerate(validationY):\n    #p = model.predict(np.array([validationX[i]])).round()[0].astype('int32')\n    prediction = model2.predict(np.array([validationX[i]])).argmax() > 3\n    actual = y.argmax() > 3\n    if prediction != actual:\n        print(\"Validation\", i)\n        print(\"Predicted review is good:\", prediction, \", actual review is good:\", actual)\n        #print(validationX[i])\n        text = []\n        for word_i in validationX[i]:\n            if word_i in reverse_word_map:\n                text.append(reverse_word_map[word_i])\n        print(' '.join(text))\n        print()\n        error_count+=1","3b92db8e":"print(\"Accuracy of prediction whether review was good:\",(validationY.shape[0] - error_count)\/validationY.shape[0] * 100)","f9db3cfc":"predicted = [x > 3 for x in model2.predict(validationX).argmax(axis=1)]\nactual = [x > 3 for x in validationY.argmax(axis=1)]","3a7c14df":"from sklearn.metrics import confusion_matrix","c1c9a618":"cnf_matrix = confusion_matrix(actual, predicted)\nsns.heatmap(cnf_matrix)\ntn, fp, fn, tp = cnf_matrix.ravel()\nprint(\"True positive:\", tp, \", True negative:\", tn,\n      \", False positive:\", fp, \", False negative:\", fn)","fb853d79":"_, test_accuracy = model2.evaluate(testX, testY)\nprint(test_accuracy)","a4c29c36":"def check_general_accuracy(model, setX, setY):\n    predicted = [x > 3 for x in model.predict(setX).argmax(axis=1)]\n    actual = [x > 3 for x in setY.argmax(axis=1)]\n\n    cnf_matrix = confusion_matrix(actual, predicted)\n    sns.heatmap(cnf_matrix)\n    tn, fp, fn, tp = cnf_matrix.ravel()\n    print(\"True positive:\", tp, \", True negative:\", tn,\n          \", False positive:\", fp, \", False negative:\", fn)\n\n    print(\"Total accuracy:\", (tp+tn)\/testX.shape[0]*100)","396c8cdd":"check_general_accuracy(model2, testX, testY)","d493c7f8":"from keras.layers import Conv1D, MaxPooling1D","553166a3":"def simple_conv_model(input_shape, output_shape):\n    model = Sequential()\n    model.add(embedding_layer)\n    \n    model.add(Conv1D(32, 5, activation='relu'))\n    model.add(Conv1D(64, 5, activation='relu'))\n    model.add(MaxPooling1D(5))\n    model.add(Dropout(0.2))\n        \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.4))\n    \n    model.add(Dense(output_shape, activation='softmax'))\n    return model","2477eb1d":"model = simple_conv_model(trainX.shape[1], trainY.shape[1])\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy'])","00718fd9":"model.summary()","45b080bb":"from keras.callbacks import ModelCheckpoint\ncheckpoint = ModelCheckpoint(\"weights-improvements.hdf5\",\n     monitor='val_acc', verbose=1, save_best_only=True, mode='max')","e93ece28":"model.fit(trainX, trainY, validation_data=(validationX, validationY),\n          batch_size=64, callbacks=[checkpoint], epochs=100)","65edf500":"model.load_weights(\"weights-improvements.hdf5\")","b22eb89f":"_, test_accuracy = model.evaluate(testX, testY)\nprint(test_accuracy)","85158921":"check_general_accuracy(model, testX, testY)","c8be379e":"One of the most precise method when analysing natural language is to use word2vec approach. Let's check how many different words there is and create a full set of all used words in review. That would be useful later when chosing pre-trained word vectors.","901919a9":" **80%** of accuracy in predicting general moods of reviews.","fc3d6bfe":"Not too great in precise rating predictions.","21418e10":"That's more like it! 82% accuracy in prediction whether the review was good or bad.\n\nThe other helpful thing to use when analizing results is confusion matrix.","68b07e3e":"# Conclusion\nThe task of precise prediction how many stars a person gave to a product based on their review is especially hard because people aren't obliged to be explain in reviews all their thoughts, and even then there are no strict rules for machine to learn. Much easier task, however, is to determine whether the review was good (>3 stars) or bad. The improvements could be made if it was the task from the beginning, and model could be trained specifically to determine that.","5c7ebbb2":"## First try conclusion\nWhile in some cases the model cannot be really guilty for misunderstanding (validation example 1, validation example 13), in many cases there could be some improvement. Time to tune model.","025dc1e2":"As we could expect, keras' tokenizer uses an algorithm that is somewhat different from the one we chose earlier. However, the amount of words in created word_index is bigger only by 1. Generally, it is better to use already made solutions than to create something from scratch. Let's quickly assess this word_index and make a decision whether it is reasonable to use it.","cf627f51":"# Initial data exploration","83e2675f":"It seems like the validation set is severely unbalanced - it contains far more negative reviews than positive.\n\nRegardless the confusion matrix results, in our case, for Amazon it would be worse to have False positive review than False negative, so our model's errors are rather acceptable.\n\nNow let's check our model against the test data. If it is not as unbalanced as validation set, there are good chances that model will perform better.","7270b9a4":"This method would find the best model among all the combinations, but it will take a lot of time. If every training would take similar amount of time that the original simple model took (about 10 minutes on 100 epochs), trying only the combinations of lstm_sizes and dense_sizes would take 6 * 6 * 10 = 360 minutes = 6 hours, and we got combinations of other hyperparameters. The required time would be enourmous.\n\nAlternative is to try every hyperparameter with default model, measure the impact on accuracy and then, judging on how good model performed with certain parameter, try to manually find the required combination.\n\nPros of the second tactics are that it is much more computationally efficient. Cons are that some hyperparameters might improve performance only with combination with others, and we are likely to miss it.\n\nNevertheless, we have to choose the computationally efficient path.","28a9b9c7":"Let's evaluate this simple model on validation set:","9b590cab":"# Convolutional model","06dea2b2":"Before wrapping up, let's try to solve this problem using another architecture of model.\n\nWe had a choice to treat each word in sentence as just another value and feed it into plain neural network, or treat it as a sequence in RNN, and we used it as such.\n\nNow, we can try a somewhat middleground at this. Convolutional neural network, due to it's nature will have an effect of a sequence model with rolling window of chosen width.","92240e71":"Third model and it didn't improve accuracy on validation set. We have a huge overfitting. Small dataset is the main suspect in that.\n\nWe have to reconsider the problem. Choosing the rating on 1-5 scale is quite arbitrary proccess. As we saw earlier when we inspected errors, there are misleading samples.\n\nThis time let's assume that rating of 1-3 is bad and of 4-5 is good. What is percentage of error in that case?","75449431":"# Building the model","0b789aa0":"It seems unreasonable to use any data except for the reviews and their rating. We could have product variation categorized and then create chart which one is the best, but it is outside the scope of the problem. Feedback and date are also unnecessary.","f70cd5ce":"We will use the Keras library to solve the problem","151aea4b":"# Assessing word vectors data","84cc8b75":"### 64% of accuracy\nIt is much better than random guessing, though. Let's check the failed predictions manually.","daec5814":"Possible ways to improve model:\n* get bigger dataset\n* balance dataset better\n* perform more diligent search for optimal hyperparameters\n* try other models","aa93d941":"The results are just as good, so the tokenizer's word_index stays.","3a9645bc":"Perfect dataset supposed to have equal amount of items with every rating, and their mean should be 3.0. Constructing such dataset would shrink dataset to 480 entries. Instead we can have dataset with 1164 entries with a mean of 3.5. That could create a shift in models predictions, but more data will help prevent overfitting and help model generalize data better.","ad3d3772":"## 48% of accuracy in precise predictions.\nNow let's check how model generally predicts whether reviews are good or not.","11ab07ca":"Now split into train, validation and test subsets","5bfc3650":"# Preparing data","a419d234":"# 77% of general accuracy for convolutional network\nConvolutional neural network predictions was slightly less accurate comparing to LSTM-based network, but no major tuning was performed.\n\nPossible improvements stay same as for LSTM-based network:\n* get bigger dataset\n* balance dataset better\n* perform more diligent search for optimal hyperparameters","1b1317e5":"Now that we got complete set of words used in dataset we can estimate how good or bad a certain vectorization of words could serve.","0fc817eb":"Embeddings successfully cover almost all word set, except for some typos. Since typos are only ~3% of words, we can ignore the problem unless we would want to improve accuracy.","87608ce0":"Additional time optimization is to cut the amount of epochs here. On 10 epochs the results probably would not be very much impressive, but it could be enough for us to determine if those hyperparameters are comparatively work or not.\n\nWe will not try here total grid search of hyperparameters. Instead we focus on how each hyperparameter changes performance individually, and then try to finish tuning manually.","e849fe65":"Second, the distribution of ratings in dataset is way off. 25-th percentile already has value of 4, and 50-th - of 5. If there is enough data for different ratings, it would seem reasonable to construct a subset with better distribution."}}