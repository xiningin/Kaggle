{"cell_type":{"d967fcaf":"code","09cef5a9":"code","41a04a82":"code","63112840":"code","9ad74d3c":"code","3bfcbbbf":"code","5730450d":"code","e5dd37c7":"code","df44ccc5":"code","6aba08af":"code","be7c9923":"code","e79161a9":"code","1cb8d352":"code","4bc35074":"code","79932b18":"code","5e0e7190":"code","3f461c1a":"code","f46e91c4":"code","7b6d039c":"markdown","ad5f07ed":"markdown","b97e6fb8":"markdown","3142978e":"markdown","c51dd789":"markdown","5ff1c326":"markdown","98980859":"markdown","cdbc3b71":"markdown","240c207c":"markdown"},"source":{"d967fcaf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport altair as alt\nalt.renderers.enable('notebook')\nprint(os.listdir(\"..\/input\"))\nfrom IPython.display import HTML\n\n\n# The below is great for working but if you publish it, no charts show up.\n# The workaround in the next cell deals with this.\n#alt.renderers.enable('notebook')\n\nHTML(\"This code block contains import statements and setup.\")\n# Any results you write to the current directory are saved as output.","09cef5a9":"## Dont worry about the code in this block. This is just the setup for showing Altair graphs in Kaggle Notebooks\n\n\nfrom  altair.vega import v3\nimport json\nfrom IPython.display import HTML\n\n\nvega_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega@' + v3.SCHEMA_VERSION\nvega_lib_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lib'\nvega_lite_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-lite@' + alt.SCHEMA_VERSION\nvega_embed_url = 'https:\/\/cdn.jsdelivr.net\/npm\/vega-embed@3'\nnoext = \"?noext\"\n\npaths = {\n    'vega': vega_url + noext,\n    'vega-lib': vega_lib_url + noext,\n    'vega-lite': vega_lite_url + noext,\n    'vega-embed': vega_embed_url + noext\n}\n\nworkaround = \"\"\"\nrequirejs.config({{\n    baseUrl: 'https:\/\/cdn.jsdelivr.net\/npm\/',\n    paths: {}\n}});\n\"\"\"\n\ndef add_autoincrement(render_func):\n    # Keep track of unique <div\/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n            \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    chart_str = \"\"\"\n    <div id=\"{id}\"><\/div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    <\/script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\nHTML(\"\".join((\n    \"<script>\",\n    workaround.format(json.dumps(paths)),\n    \"<\/script>\",\n    \"This code block sets up embedded rendering in HTML output and<br\/>\",\n    \"provides the function `render(chart, id='vega-chart')` for use below.\"\n)))\n","41a04a82":"#!pip install fbprophet","63112840":"from fbprophet import Prophet\n\n#!mkdir -p dataset\n#!wget -c -b http:\/\/www-personal.umich.edu\/~mejn\/cp\/data\/sunspots.txt -P dataset\ndata = pd.read_excel('..\/input\/maruti-infrastructure\/HCL.xlsx', header=0, index_col=0, parse_dates=True, squeeze=True)","9ad74d3c":"#!ls dataset\/","3bfcbbbf":"# View the data as a table\ndata_as_frame = pd.DataFrame(data, columns=['Maruti_Infrastructure', 'Day'])\ndata_as_frame.tail(10)","5730450d":"data_as_frame['ds']=data_as_frame['Day'].astype(int)","e5dd37c7":"data_as_frame.head()","df44ccc5":" data_as_frame['time_stamp']=data_as_frame.apply(lambda x:(pd.Timestamp('01-01-2008')+pd.DateOffset(days = int(x['ds']))),axis=1)","6aba08af":"#Cleaning the df, we only need two columns date time and the data\nclean_df=data_as_frame.drop(['Day','ds'],axis=1)","be7c9923":"clean_df.head()","e79161a9":"render(alt.Chart(clean_df).mark_line(size=15, opacity=0.8, color = 'Orange').encode(\n        x='yearmonthdate(time_stamp):T',\n        y=alt.Y('Maruti_Infrastructure', title='Maruti_Infrastructure'),    \n        tooltip=['yearmonthdate(time_stamp)', 'Maruti_Infrastructure']\n    ).interactive().properties(width=900, height=450,title='Maruti_Infrastructure Stock Price')\\\n              .configure_title(fontSize=20))","1cb8d352":"## Prophet requires two columns, one is ds (the date time) and y (variable to be forecasted)\nclean_df.columns = ['y', 'ds']","4bc35074":"def fit_predict_model(dataframe, interval_width = 0.99, changepoint_range = 0.99):\n    m = Prophet(daily_seasonality = False, yearly_seasonality = False, weekly_seasonality = False,\n                seasonality_mode = 'multiplicative', \n                interval_width = interval_width,\n                changepoint_range = changepoint_range)\n    m = m.fit(dataframe)\n    \n    forecast = m.predict(dataframe)\n    forecast['fact'] = dataframe['y'].reset_index(drop = True)\n    print('Displaying Prophet plot')\n    fig1 = m.plot(forecast)\n    return forecast\n    \npred = fit_predict_model(clean_df)\n","79932b18":"def detect_anomalies(forecast):\n    forecasted = forecast[['ds','trend', 'yhat', 'yhat_lower', 'yhat_upper', 'fact']].copy()\n    #forecast['fact'] = df['y']\n\n    forecasted['anomaly'] = 0\n    forecasted.loc[forecasted['fact'] > forecasted['yhat_upper'], 'anomaly'] = 1\n    forecasted.loc[forecasted['fact'] < forecasted['yhat_lower'], 'anomaly'] = -1\n\n    #anomaly importances\n    forecasted['importance'] = 0\n    forecasted.loc[forecasted['anomaly'] ==1, 'importance'] = \\\n        (forecasted['fact'] - forecasted['yhat_upper'])\/forecast['fact']\n    forecasted.loc[forecasted['anomaly'] ==-1, 'importance'] = \\\n        (forecasted['yhat_lower'] - forecasted['fact'])\/forecast['fact']\n    \n    return forecasted\n\npred = detect_anomalies(pred)","5e0e7190":"pred.head()","3f461c1a":"pred[pred.anomaly == 1]","f46e91c4":"def plot_anomalies(forecasted):\n    interval = alt.Chart(forecasted).mark_area(interpolate=\"basis\", color = '#7FC97F').encode(\n    x=alt.X('ds:T',  title ='date'),\n    y='yhat_upper',\n    y2='yhat_lower',\n    tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive().properties(\n        title='Anomaly Detection'\n    )\n\n    fact = alt.Chart(forecasted[forecasted.anomaly==0]).mark_circle(size=15, opacity=0.7, color = 'Black').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper']\n    ).interactive()\n\n    anomalies = alt.Chart(forecasted[forecasted.anomaly!=0]).mark_circle(size=30, color = 'Red').encode(\n        x='ds:T',\n        y=alt.Y('fact', title='Sunspots'),    \n        tooltip=['yearmonthdate(ds)', 'fact', 'yhat_lower', 'yhat_upper'],\n        size = alt.Size( 'importance', legend=None)\n    ).interactive()\n\n    return render(alt.layer(interval, fact, anomalies)\\\n              .properties(width=870, height=450)\\\n              .configure_title(fontSize=20))\n              \nplot_anomalies(pred)","7b6d039c":"# Detecting Anomalies:\n* The light blue boundaries in the above graph are yhat_upper and yhat_lower.\n* If y value is greater than yhat_upper and less than yhat lower then it is an anomaly.\n* Also getting the importance of that anomaly based on its distance from yhat_upper and yhat_lower.","ad5f07ed":"## Lets Predict","b97e6fb8":"References:\n* http:\/\/www-personal.umich.edu\/~mejn\/cp\/programs.html\n* https:\/\/towardsdatascience.com\/anomaly-detection-time-series-4c661f6f165f\n* https:\/\/github.com\/altair-viz\/altair\/issues\/1270\n","3142978e":"### Converting the months column in format acceptable for Prophet, starting from 1749 ","c51dd789":"# Plotting the anomalies for a better view","5ff1c326":"### Converting data to Pandas dataframe","98980859":"## Lets view the data in graphical format","cdbc3b71":"# Preparing data for modelling in Prophet","240c207c":"# Getting the data"}}