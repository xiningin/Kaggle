{"cell_type":{"102f3ca3":"code","a16b433b":"code","72183f26":"code","b6090705":"code","5046a4d5":"code","95eb7928":"code","ab0b3d8d":"code","1346dce8":"code","06e19c20":"code","46b067e8":"code","2584d9b3":"code","5dfb4cc0":"code","4a4da390":"code","fef68fd9":"code","1683090d":"code","bd09af62":"code","d77d43a0":"code","b08e677d":"code","510fc7a3":"code","9673ed64":"code","f61cb6e3":"code","955d0e4b":"code","6fa65de4":"code","62fa4dcc":"code","6f076257":"markdown","7a08444e":"markdown","1df1155d":"markdown","6263013c":"markdown","4f78f224":"markdown","4ab8a5c4":"markdown","b0afcec7":"markdown","f812a7b3":"markdown","ae37e88c":"markdown"},"source":{"102f3ca3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nos.getcwd()\nfiles = list()\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n     for filename in filenames:\n         files.append(os.path.join(dirname, filename))\nfiles[0:5]\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a16b433b":"#!pip install lime shap","72183f26":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nimport lime\nimport shap\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport random","b6090705":"def create_stack(lst):\n    temp_list = list()\n    for file in lst:\n        img = cv2.imread(file)\n        img = cv2.resize(img, (150,150))\n        temp_list.append(img)\n    return np.array(temp_list)","5046a4d5":"# files = random.sample(files, len(files))\n# files[0:5]\nfiles_train = list()\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/messy-vs-clean-room\/images\/train\/clean\/'):\n     for filename in filenames:\n         files_train.append(os.path.join(dirname, filename))\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/messy-vs-clean-room\/images\/train\/messy\/'):\n     for filename in filenames:\n         files_train.append(os.path.join(dirname, filename))\n# print(files_train[:5])\nfiles_train = random.sample(files_train, len(files_train))\n# print(files_train[:5])","95eb7928":"x_train = create_stack(files_train)\n#x_train.shape","ab0b3d8d":"files_test = list()\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/messy-vs-clean-room\/images\/test\/'):\n     for filename in filenames:\n         files_test.append(os.path.join(dirname, filename))\n#files_test","1346dce8":"x_test = create_stack(files_test)\n#x_test.shape","06e19c20":"plt.imshow(x_train[0])","46b067e8":"train_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\ntrain_dir = '\/kaggle\/input\/messy-vs-clean-room\/images\/train'\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size = (150,150),\n                                                   batch_size = 10,\n#                                                    color_mode = 'grayscale',\n                                                   class_mode = 'binary')","2584d9b3":"validation_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\nval_dir = '\/kaggle\/input\/messy-vs-clean-room\/images\/val'\n\nval_generator = validation_datagen.flow_from_directory(val_dir, \n                                    target_size = (150,150),\n                                    batch_size = 10,\n#                                     color_mode = 'grayscale',\n                                    class_mode = 'binary',\n                                    shuffle=False)","5dfb4cc0":"def RoomModel(input_shape):\n  X_input = Input(input_shape)\n  X = X_input\n    \n  #Layer 1 - Conv>BN>RELU>MaxPool\n  \n  X = Conv2D(256,(5,5),strides = (1,1), name = 'conv0', padding = 'same')(X)\n  X = BatchNormalization(axis = 3, name = 'bn0')(X)\n  X = Activation('relu')(X)\n  X = MaxPooling2D((2,2),strides = (2,2), name = 'maxpool0')(X)\n  \n  #Layer 2 - Conv>BN>RELU>MaxPool\n  \n  X = Conv2D(128,(5,5),strides = (1,1), name = 'conv1', padding = 'same')(X)\n  X = BatchNormalization(axis = 3, name = 'bn1')(X)\n  X = Activation('relu')(X)\n  X = MaxPooling2D((2,2),strides = (2,2), name = 'maxpool1')(X)\n  X = Dropout(rate = 0.25)(X)\n  \n  #Layer 3 - Conv>BN>RELU>MaxPool\n  \n  X = Conv2D(64,(3,3),strides = (1,1), name = 'conv2', padding = 'valid')(X)\n  X = BatchNormalization(axis = 3, name = 'bn2')(X)\n  X = Activation('relu')(X)\n  X = MaxPooling2D((2,2),strides = (2,2), name = 'maxpool2')(X)\n  X = Dropout(rate = 0.25)(X)\n  \n  #Layer 4 - Conv>BN>RELU>MaxPool\n\n  X = Conv2D(32,(3,3),strides = (1,1), name = 'conv3', padding = 'same')(X)\n  X = BatchNormalization(axis = 3, name = 'bn3')(X)\n  X = Activation('relu')(X)\n  X = MaxPooling2D((2,2),strides = (2,2), name = 'maxpool3')(X)\n  X = Dropout(rate = 0.25)(X)\n\n  #Layer 5 - Conv>BN>RELU>MaxPool\n\n  X = Conv2D(16,(3,3),strides = (1,1), name = 'conv4', padding = 'same')(X)\n  X = BatchNormalization(axis = 3, name = 'bn4')(X)\n  X = Activation('relu')(X)\n  X = MaxPooling2D((2,2),strides = (2,2), name = 'maxpool4')(X)\n  X = Dropout(rate = 0.25)(X)\n  \n  #FC layers with flattening\n\n  X = Flatten()(X)\n  X = Dense(128, activation = 'relu', name = 'fc1')(X)\n  X = Dropout(rate = 0.25)(X)\n  X = Dense(32, activation = 'relu', name = 'fc2')(X)\n  X = Dropout(rate = 0.25)(X)\n  X = Dense(1, activation = 'sigmoid', name = 'preds')(X)\n  \n  #model instance creator\n  model = Model(inputs = X_input, outputs = X, name = 'RoomModel')\n  model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n  \n  return model","4a4da390":"input_shape = [150,150,3]\nroomModel = RoomModel(input_shape)\nmy_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n    tf.keras.callbacks.TensorBoard(log_dir='.\/logs'),\n]\nhistory = roomModel.fit(train_generator,\n                              epochs=100,\n                              validation_data = val_generator,\n                              verbose=1,\n                              callbacks = my_callbacks)","fef68fd9":"%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(epochs, loss, 'r', \"Training Loss\")\nplt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n\n\nplt.title('Training and validation loss')","1683090d":"from sklearn.metrics import classification_report, confusion_matrix\n\nroomModel.load_weights('\/kaggle\/working\/model.84-0.34.h5')\n\nY_pred = roomModel.predict(val_generator, verbose = 0)\nprint(Y_pred)\ny_pred = (Y_pred>0.5) \nprint(y_pred)\nclass_labels = {v: k for k, v in val_generator.class_indices.items()}\n\nprint('Confusion Matrix')\nprint(confusion_matrix(val_generator.classes, y_pred))\n\nprint('Classification Report')\ntarget_names = list(class_labels.values())\nprint(classification_report(val_generator.classes, y_pred, target_names=target_names))","bd09af62":"from lime import lime_image\nimport time","d77d43a0":"def predict_fn(image):\n#     for image in images:\n#         if(image.shape[2]==3):\n#             image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#         image = cv2.resize(image, (150,150))\n    image = ((image.astype(float))\/255)\n    image = image.reshape((-1,150,150,3))\n    return roomModel.predict(image)","b08e677d":"explainer = lime_image.LimeImageExplainer()","510fc7a3":"plt.imshow(x_test[0])","9673ed64":"predict_fn(x_test[0])","f61cb6e3":"explanation_0 = explainer.explain_instance(x_test[0], predict_fn, top_labels=5, hide_color=0, num_samples=1000)","955d0e4b":"from skimage.segmentation import mark_boundaries\n\ntemp, mask = explanation_0.get_image_and_mask(explanation_0.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\nplt.imshow(mark_boundaries(temp, mask))","6fa65de4":"ind =  explanation_0.top_labels[0]\n\n#Map each explanation weight to the corresponding superpixel\ndict_heatmap = dict(explanation_0.local_exp[ind])\nheatmap = np.vectorize(dict_heatmap.get)(explanation_0.segments) \n\n#Plot. The visualization makes more sense if a symmetrical colorbar is used.\nplt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())\nplt.colorbar()","62fa4dcc":"# temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n# plt.imshow(mark_boundaries(temp, mask))","6f076257":"Towards and against - green and red respectively.","7a08444e":"# **Initializing in an explainer**","1df1155d":"**Creating Image Data Generators for training and validation**","6263013c":"# **Utility function and preprocessing**","4f78f224":"Heatmap - The more blue it is, the higher positive impact","4ab8a5c4":"# **Model Development And Training**","b0afcec7":"Let's take a look at a faulty prediction","f812a7b3":"# **Importing Libraries**","ae37e88c":"# **Plotting the explanations**"}}