{"cell_type":{"0afa4e2c":"code","cd073a4a":"code","d572368a":"code","6c2c574b":"code","81f2c65b":"code","1406b1f0":"code","f0f32634":"code","2c16ce10":"code","b8b89a77":"code","1aaabe8d":"code","ef9337e5":"code","c8230107":"code","db7ae059":"code","fa4d6338":"code","603ea7f3":"code","0b714fb9":"code","00fca807":"code","1641ff92":"code","75dfa7a0":"code","2bddf43b":"code","a1246f1d":"markdown","e2d454af":"markdown","5bf849e3":"markdown","4245241b":"markdown","916ffcda":"markdown","9dcc240f":"markdown","852416f7":"markdown","f79af0f1":"markdown","1dc87076":"markdown","693aac60":"markdown","3aff2fbd":"markdown","ed5fe71b":"markdown"},"source":{"0afa4e2c":"import numpy as np\nimport pandas as pd\n\nimport torch\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import transforms\nfrom torch import optim\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport time\nfrom time import process_time","cd073a4a":"batch_size = 300\nepochs = 30\ntest_size = 0.15\nlearning_rate = 0.0001","d572368a":"# Im\u00e1genes y labels de entrenamiento (Training Set)\ntrain_images = np.load(\"..\/input\/kuzushiji\/kmnist-train-imgs.npz\")[\"arr_0\"]\ntrain_labels = np.load(\"..\/input\/kuzushiji\/kmnist-train-labels.npz\")[\"arr_0\"]","6c2c574b":"print(\"Tama\u00f1o Set de Entrenamiento antes:\" ,train_images.shape)\n\ntrain_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size = test_size)\n# #Imprimimos para confirmar\nprint(\"Tama\u00f1o Set de Entrenamiento despu\u00e9s: \", train_images.shape)\nprint(\"Tama\u00f1o Set de Validacion: \", test_images.shape)","81f2c65b":"def normalizar(dataset, labels):\n    data = dataset.astype('float32')\n    data \/= 255\n    data = np.reshape(data, (len(data), 1, 28, 28))\n    newLabels = labels.astype('int64')\n    return data, newLabels","1406b1f0":"train_images, train_labels = normalizar(train_images, train_labels)\ntest_images, test_labels = normalizar(test_images, test_labels)","f0f32634":"x_train_images = torch.Tensor(train_images)\ny_train_images = torch.Tensor(train_labels).type(torch.LongTensor)\nx_valid_images = torch.Tensor(test_images)\ny_valid_images = torch.Tensor(test_labels).type(torch.LongTensor)\n\nprint(\"Set de Entrenamiento: \" + str(x_train_images.shape))\nprint(\"Labels del Set de Entrenamiento: \" + str(y_train_images.shape))\nprint(\"Set de Validaci\u00f3n: \" + str(x_valid_images.shape))\nprint(\"Labels del Set de Validaci\u00f3n: \" + str(y_valid_images.shape))","2c16ce10":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","b8b89a77":"# Training Dataset\ntrain_dataset = torch.utils.data.TensorDataset(x_train_images, y_train_images)\ntrainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n\n#Validation Dataset\nvalid_dataset = torch.utils.data.TensorDataset(x_valid_images, y_valid_images)\nvalidloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)","1aaabe8d":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1), # output dim = (28x28x32)\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Dropout(p=0.2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1), # output dim = (28x28x32)\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.Dropout(p=0.2)\n        )\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0), # output = (26x26x64)\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2,stride=2), # output = (13x13x64)\n            nn.Dropout(p=0.2)\n        )\n        \n        \n        self.fc1 = nn.Sequential(\n            nn.Linear(10816, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 10),\n            nn.LogSoftmax(dim=1)\n        )\n        \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        \n        return x","ef9337e5":"model = CNN()\nmodel.cuda()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\ntraining_loss = []\nvalid_loss = []\ntraining_accuracy = []\nvalid_accuracy = []","c8230107":"trainingTimeStart = time.process_time()","db7ae059":"for epoch in range(epochs):\n    model.train()\n    running_loss = 0\n    accuracy = 0\n    steps = 0\n    \n    for images, labels in trainloader:    \n        images = images.cuda()\n        labels = labels.cuda()\n        #Training pass\n        output = model(images)\n        loss = criterion(output, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        _, predicted = torch.max(output, 1)\n        accuracy += (predicted == labels).sum()\n        steps += 1\n        \n    training_loss.append(running_loss\/steps)\n    training_accuracy.append(100 * accuracy.cpu().numpy()\/len(train_dataset))\n    model.eval()\n    \n    with torch.no_grad():\n        iter_loss = 0\n        accuracy = 0\n        steps = 0\n        \n        for images, labels in validloader:\n            images = images.cuda()\n            labels = labels.cuda()\n            output = model(images)\n            loss = criterion(output, labels)\n            \n            iter_loss += loss.item()\n            _, predicted = torch.max(output, 1)\n            accuracy += (predicted == labels).sum()\n            steps += 1\n            \n        valid_loss.append(iter_loss\/steps)\n        valid_accuracy.append(100 * accuracy.cpu().numpy()\/len(valid_dataset))\n        \n    print ('Epoch {}\/{}, Training Loss: {:.3f}, Training Accuracy: {:.2f}%, Validation Loss: {:.3f}, Validation Acc: {:.2f}%'\n            .format(epoch+1, epochs, training_loss[-1], training_accuracy[-1], valid_loss[-1], valid_accuracy[-1]))\n    \ntrainingTimeStop = time.process_time() - trainingTimeStart\nprint('Tiempo de ejecuci\u00f3n: ' + str(trainingTimeStop))","fa4d6338":"plt.plot(training_loss, color='red', label=\"Training loss\")\nplt.plot(valid_loss, color='blue',label=\"Validation loss\")\nplt.legend()\nplt.show()","603ea7f3":"plt.plot(training_accuracy, color='red', label=\"Training acc\")\nplt.plot(valid_accuracy, color='blue',label=\"Validation acc\")\nplt.legend()\nplt.show()","0b714fb9":"testing_images = np.load(\"..\/input\/kuzushiji\/kmnist-test-imgs.npz\")[\"arr_0\"]\ntesting_labels = np.load(\"..\/input\/kuzushiji\/kmnist-test-labels.npz\")[\"arr_0\"]","00fca807":"new_testing_images, new_testing_labels = normalizar(testing_images, testing_labels)","1641ff92":"x_testing_images = torch.Tensor(new_testing_images)\ny_testing_images = torch.Tensor(new_testing_labels).type(torch.LongTensor)\nprint(\"Set de Prueba: \" + str(x_testing_images.shape))\nprint(\"Labels del Set de Prueba: \" + str(y_testing_images.shape))","75dfa7a0":"test_dataset = torch.utils.data.TensorDataset(x_testing_images, y_testing_images)\ntestloader = torch.utils.data.DataLoader(test_dataset, batch_size=300, shuffle=False)","2bddf43b":"model.eval()\ntestingTimeStart = time.process_time()\nwith torch.no_grad():\n    accuracy = 0\n    total = 0\n    test_loss = 0\n    \n    for images, labels in testloader:\n        images = images.cuda()\n        labels = labels.cuda()\n        output = model(images)\n        loss = criterion(output, labels)\n        test_loss += loss.item()\n        test_loss = test_loss\/len(testloader)\n        \n        _, predicted = torch.max(output.data, 1)\n        total += labels.size(0)\n        accuracy += (predicted == labels).sum().item()\n        test_accuracy = (100 * accuracy)\/total\n    \n    print('Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(test_loss, test_accuracy))\ntestingTimeStop = time.process_time() - testingTimeStart\nprint(\"Tiempo de ejecuci\u00f3n: \" + str(testingTimeStop))","a1246f1d":"## Definici\u00f3n de Variables","e2d454af":"## Normalizaci\u00f3n de Datos","5bf849e3":"# Entrenamiento de la Red","4245241b":"## Carga de paquetes","916ffcda":"# Resultado","9dcc240f":"# Proyecto 1 Computaci\u00f3n Emergente\nIntegrantes:\n- Samuel Mari\u00f1a\n- Mar\u00eda G. Cafarelli","852416f7":"## Carga de Data (Training Set)","f79af0f1":"## Separaci\u00f3n de Datos","1dc87076":"## Agregar Device si se tiene GPU","693aac60":"## Conversi\u00f3n a Tensores","3aff2fbd":"# Arquitectura del Modelo","ed5fe71b":"## Obtener Datasets"}}