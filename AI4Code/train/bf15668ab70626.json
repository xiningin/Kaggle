{"cell_type":{"e4eef056":"code","27dc1453":"code","2fe10a45":"code","1b6e4fd9":"code","9d6cc48c":"code","852e8e2e":"code","e4b98da6":"code","d4216cb8":"code","d8a4fc74":"code","b79804d9":"code","32b64cd7":"code","41ed5476":"code","8973d572":"code","c1994ccf":"code","15b320a4":"code","fe76f055":"code","b2432b16":"code","0ae5493b":"code","f567b5e8":"code","c547cb60":"code","2f97a66a":"code","def5a23b":"code","0546449d":"code","2437103f":"code","a1ff77c5":"code","70478c4f":"code","a75c4a0a":"code","4b63dc31":"code","752b7d4b":"code","e21037ee":"code","049e77e1":"code","ef83f817":"code","aa64daee":"code","0725cef5":"code","30a274b3":"code","3a3c49c2":"code","8e0521b7":"code","c53f4d62":"code","aaed2daf":"code","4cff9dc2":"code","da8a735f":"code","62efbdbb":"code","dae1b883":"code","5479a43a":"code","af7cee4e":"code","e2b08a28":"code","25c74900":"markdown","3faa2a31":"markdown","f41d5f7e":"markdown","2c6ac6ac":"markdown","62a8cd54":"markdown","9dc6dcf5":"markdown","6522d904":"markdown","3aa5a731":"markdown","3bd2bce7":"markdown","3c579dfc":"markdown","95dee665":"markdown","0564108b":"markdown","ab024b0e":"markdown","228418cc":"markdown","5cf0ad3d":"markdown","1b8f64cb":"markdown","557a17ce":"markdown","f7ed6302":"markdown","a4285cf2":"markdown","0a88f8c0":"markdown","da4dee70":"markdown","ed9986df":"markdown"},"source":{"e4eef056":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split","27dc1453":"df = pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')","2fe10a45":"df.head()","1b6e4fd9":"df.info()","9d6cc48c":"corr = df.corr()[\"HeartDisease\"]\ncorr.sort_values(ascending=False)","852e8e2e":"%matplotlib inline\ndf.hist(bins=50, figsize=(20,15))\nplt.show()","e4b98da6":"print(df[[\"FastingBS\", \"HeartDisease\"]].groupby(\"FastingBS\").mean().sort_values(by=\"HeartDisease\", ascending=False))\nprint('-'*40)\nprint(df[[\"ChestPainType\", \"HeartDisease\"]].groupby(\"ChestPainType\").mean().sort_values(by=\"HeartDisease\", ascending=False))\nprint('-'*40)\nprint(df[[\"RestingECG\", \"HeartDisease\"]].groupby(\"RestingECG\").mean().sort_values(by=\"HeartDisease\", ascending=False))\nprint('-'*40)\nprint(df[[\"ExerciseAngina\", \"HeartDisease\"]].groupby(\"ExerciseAngina\").mean().sort_values(by=\"HeartDisease\", ascending=False))\nprint('-'*40)\nprint(df[[\"ST_Slope\", \"HeartDisease\"]].groupby(\"ST_Slope\").mean().sort_values(by=\"HeartDisease\", ascending=False))","d4216cb8":"sns.displot(df[\"Age\"], label=\"Skewness: %.2f\"%(df[\"Age\"].skew()))\nplt.legend(loc=\"best\")\nplt.title(\"Patient age distribution\")","d8a4fc74":"sns.displot(df[\"RestingBP\"], label=\"Skewness: %.2f\"%(df[\"RestingBP\"].skew()))\nplt.legend(loc=\"best\")\nplt.title(\"Patient resting blood pressure distribution\")","b79804d9":"sns.displot(df[\"Cholesterol\"], label=\"Skewness: %.2f\"%(df[\"Cholesterol\"].skew()))\nplt.legend(loc=\"best\")\nplt.title(\"Patient cholesterol distribution\")","32b64cd7":"df.loc[df['Cholesterol'] == 0]","41ed5476":"df['Cholesterol'] = df['Cholesterol'].replace(0, np.nan)\ndf['Oldpeak'] = df['Oldpeak'].replace(0, np.nan)","8973d572":"df_new = df.drop(columns=['Sex', 'ChestPainType', 'RestingBP', 'RestingECG', 'MaxHR', 'ExerciseAngina', 'ST_Slope'])","c1994ccf":"imputer = KNNImputer(n_neighbors=3, missing_values=np.nan)\ndf_new = pd.DataFrame(imputer.fit_transform(df_new), columns = df_new.columns)","15b320a4":"sns.histplot(df_new['Cholesterol'], label='Skewness: %.2f'%(df_new['Cholesterol'].skew()))\nplt.legend(loc=\"best\")\nplt.show()","fe76f055":"sns.histplot(df_new['Oldpeak'], label='Skewness: %.2f'%(df_new['Oldpeak'].skew()))\nplt.legend(loc=\"best\")\nplt.show()","b2432b16":"df['Cholesterol'] = np.log(df_new['Cholesterol'])\ndf['Oldpeak'] = (df_new['Oldpeak'])","0ae5493b":"df[\"RateTooHigh\"] = 220 - df[\"Age\"]\ndf.head()","f567b5e8":"df[\"RateTooHigh\"] = df[\"RateTooHigh\"] - df[\"MaxHR\"]\nsns.histplot(df[\"RateTooHigh\"])","c547cb60":"df.loc[(df[\"RateTooHigh\"] >= 0), 'RateTooHigh'] = 0\ndf.loc[(df[\"RateTooHigh\"] < 0), 'RateTooHigh'] = 1\nsns.histplot(df[\"RateTooHigh\"])","2f97a66a":"print(df[[\"RateTooHigh\", \"HeartDisease\"]].groupby(\"RateTooHigh\").mean().sort_values(by=\"HeartDisease\", ascending=False))","def5a23b":"df = pd.get_dummies(df, columns=['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope', 'RateTooHigh'])\ndf.head()","0546449d":"df_new = df[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']]\n\nscaler = MinMaxScaler()\ndf_new = pd.DataFrame(scaler.fit_transform(df_new), columns=df_new.columns)\ndf_new.head()","2437103f":"df[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']] = df_new[['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']]\n\ndf.head()","a1ff77c5":"targets = df[\"HeartDisease\"]\ndf = df.drop(\"HeartDisease\", axis=1)","70478c4f":"x_train, x_test, y_train, y_test = train_test_split(df, targets, test_size=0.2, random_state=42)","a75c4a0a":"from sklearn import tree\n\ntreeClass = tree.DecisionTreeClassifier()\ntreeClass.fit(x_train, y_train)","4b63dc31":"round(treeClass.score(x_test, y_test), 2)","752b7d4b":"from sklearn import svm\n\nsvmClass = svm.SVC()\nsvmClass.fit(x_train, y_train)","e21037ee":"round(svmClass.score(x_test, y_test), 2)","049e77e1":"from sklearn.linear_model import LogisticRegression\n\nlogistReg = LogisticRegression()\nlogistReg.fit(x_train, y_train)","ef83f817":"round(logistReg.score(x_test, y_test), 2)","aa64daee":"from sklearn.naive_bayes import GaussianNB\n\ngaussian_classifier = GaussianNB()\ngaussian_classifier.fit(x_train, y_train)","0725cef5":"round(gaussian_classifier.score(x_test, y_test), 2)","30a274b3":"from sklearn.linear_model import SGDClassifier\n\nsgd_class = SGDClassifier()\nsgd_class.fit(x_train, y_train)","3a3c49c2":"round(sgd_class.score(x_test, y_test), 2)","8e0521b7":"from sklearn.ensemble import RandomForestClassifier\n\nrfc1 = RandomForestClassifier(max_depth=2, random_state=0)\nrfc1.fit(x_train, y_train)","c53f4d62":"round(rfc1.score(x_test, y_test), 2)","aaed2daf":"rfc3 = RandomForestClassifier(max_depth=4, random_state=0)\nrfc3.fit(x_train, y_train)","4cff9dc2":"round(rfc3.score(x_test, y_test), 2)","da8a735f":"#We will do hyperparameter tuning on the model with the highest accuracy.\n#This is the logistic regression\n#Let's make a dictionary of the hyperparameter values to search\n\nsearch_space = {\n    \"penalty\": [\"l1\", \"l2\", \"elasticnet\", \"none\"],\n    \"C\": [1.0, 1.5, 0.5],\n    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n    \"max_iter\": [100, 150, 180]\n}","62efbdbb":"from sklearn.model_selection import GridSearchCV\n\nGS = GridSearchCV(estimator = logistReg,\n                 param_grid = search_space,\n                 scoring = \"accuracy\",\n                 refit = True,\n                 verbose = 4)","dae1b883":"GS.fit(x_train, y_train)","5479a43a":"round(GS.score(x_train, y_train), 2)","af7cee4e":"round(GS.score(x_test, y_test), 2)","e2b08a28":"from sklearn.metrics import recall_score\n\ntest_pred = GS.predict(x_test)\nrecall_score(test_pred, y_test)","25c74900":"<h3>Cleaning the data<\/h3>","3faa2a31":"<h3>Support Vector Machines<\/h3>","f41d5f7e":"<h3>Stochastic Gradient Descent<\/h3>","2c6ac6ac":"<p>The test and train accuracy are very similar, so overfitting was not a problem in this case.<\/p>","62a8cd54":"<p>There are clearly problems with the Cholesterol and Oldpeak columns - at 0, they are essentially null values. We will deal with them later on<\/p>","9dc6dcf5":"<h3>Feature engineering: max heart-rate for age<\/h3>\n<p>\"To estimate your maximum age-related heart rate, subtract your age from 220\". We will put a 1 (true) if the maximum heart rate (MaxHR) is higher than 220 - age.<\/p>","6522d904":"<p>We now replace the Cholesterol and Oldpeak 0-values with the new computed values<\/p>","3aa5a731":"<p>A log transformation of the cholesterol column (shown above) will be applied to account for the skewness.<\/p>","3bd2bce7":"<h3>Label encoding<\/h3>","3c579dfc":"<h3>Gaussian Naive Bayes<\/h3>","95dee665":"<h2>Trying out different classifier models<\/h2>","0564108b":"<h3>Feature scaling (normalization) using MinMax<\/h3>\n<p>StandardScaler could also be used<\/p>","ab024b0e":"<h3>Decision Forests<\/h3>","228418cc":"<h3>Decision tree<\/h3>","5cf0ad3d":"<h3>Hyperparameter tuning<\/h3>","1b8f64cb":"<h3>Exploratory Data Analysis<\/h3>","557a17ce":"<h3>Splitting training and testing<\/h3>","f7ed6302":"<p>df.info() is useful to know the number of missing (null) values. We have 918 entries (rows), and all the columns have 918 non-null values.<\/p>","a4285cf2":"<p>Clearly, the cholesterol column having 0 values is indicative of null values. The same can be said for the Oldpeak column.<\/p>\n<p>We will first replace 0's by null (np.nan), then use the KNNImputer to estimate their values.<\/p>","0a88f8c0":"<h3>Logistic Regression<\/h3>","da4dee70":"<h3>Final results<\/h3>\n<ul>\n    <li>Accuracy: 86%<\/li>\n    <li>Recall: 90%<\/li>\n<\/ul>","ed9986df":"<p>The highest accuracy we got was from using logistic regression. We will now try to use hyperparameter tuning on it.<\/p>"}}