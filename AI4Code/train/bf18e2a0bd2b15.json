{"cell_type":{"310c5aad":"code","703b22b2":"code","b324f7c8":"code","82b826b4":"code","9ad71f3a":"code","8aa60566":"code","767fcea5":"code","705ad412":"code","2a2930de":"code","d29cf4b1":"code","dd9c497b":"code","e3d8956b":"code","0adda99f":"code","714deb2e":"code","1543f01a":"code","e4754a74":"code","822e611f":"code","5f3e2fbf":"code","f66641cd":"code","4774ad45":"code","156a09e7":"code","5fa0636a":"code","9ac562b2":"code","422537d3":"code","63840760":"markdown","7210f03b":"markdown","aa2827bf":"markdown","57d34534":"markdown","e845c24a":"markdown","40eabeb9":"markdown","5fc994e7":"markdown"},"source":{"310c5aad":"import pandas as pd\nimport numpy as np\nimport plotnine \nfrom plotnine import *\nimport os, sys, gc\nfrom tqdm.notebook import tqdm","703b22b2":"# \uacbd\ub85c\uc758 \uacbd\uc6b0 \uac01\uc790\uc758 \ud658\uacbd\uc5d0 \ub9de\uac8c \uc124\uc815\ud574\uc8fc\uba74 \ub429\ub2c8\ub2e4. \npath = '..\/input\/t-academy-recommendation2\/books\/'","b324f7c8":"books = pd.read_csv(path + \"books.csv\")\nbook_tags = pd.read_csv(path + \"book_tags.csv\")\ntrain = pd.read_csv(path + \"train.csv\")\ntest = pd.read_csv(path + \"test.csv\")\ntags = pd.read_csv(path + \"tags.csv\")\nto_read = pd.read_csv(path + \"to_read.csv\")","82b826b4":"train['book_id'] = train['book_id'].astype(str)\ntest['book_id'] = test['book_id'].astype(str)\nbooks['book_id'] = books['book_id'].astype(str)","9ad71f3a":"sol = test.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\ngt = {}\nfor user in tqdm(sol['user_id'].unique()): \n    gt[user] = list(sol[sol['user_id'] == user]['unique'].values[0])","8aa60566":"rec_df = pd.DataFrame()\nrec_df['user_id'] = train['user_id'].unique()","767fcea5":"books.sort_values(by='books_count', ascending=False)[0:5]","705ad412":"popular_rec_model = books.sort_values(by='books_count', ascending=False)['book_id'].values[0:500]","2a2930de":"total_rec_list = {}\nfor user in tqdm(rec_df['user_id'].unique()):\n    rec_list = []\n    for rec in popular_rec_model[0:200]: \n        rec_list.append(rec)\n    total_rec_list[user] = rec_list","d29cf4b1":"import six\nimport math\n\n# https:\/\/github.com\/kakao-arena\/brunch-article-recommendation\/blob\/master\/evaluate.py\n\nclass evaluate():\n    def __init__(self, recs, gt, topn=100):\n        self.recs = recs\n        self.gt = gt \n        self.topn = topn \n        \n    def _ndcg(self):\n        Q, S = 0.0, 0.0\n        for u, seen in six.iteritems(self.gt):\n            seen = list(set(seen))\n            rec = self.recs.get(u, [])\n            if not rec or len(seen) == 0:\n                continue\n\n            dcg = 0.0\n            idcg = sum([1.0 \/ math.log(i + 2, 2) for i in range(min(len(seen), len(rec)))])\n            for i, r in enumerate(rec):\n                if r not in seen:\n                    continue\n                rank = i + 1\n                dcg += 1.0 \/ math.log(rank + 1, 2)\n            ndcg = dcg \/ idcg\n            S += ndcg\n            Q += 1\n        return S \/ Q\n\n\n    def _map(self):\n        n, ap = 0.0, 0.0\n        for u, seen in six.iteritems(self.gt):\n            seen = list(set(seen))\n            rec = self.recs.get(u, [])\n            if not rec or len(seen) == 0:\n                continue\n\n            _ap, correct = 0.0, 0.0\n            for i, r in enumerate(rec):\n                if r in seen:\n                    correct += 1\n                    _ap += (correct \/ (i + 1.0))\n            _ap \/= min(len(seen), len(rec))\n            ap += _ap\n            n += 1.0\n        return ap \/ n\n\n\n    def _entropy_diversity(self):\n        sz = float(len(self.recs)) * self.topn\n        freq = {}\n        for u, rec in six.iteritems(self.recs):\n            for r in rec:\n                freq[r] = freq.get(r, 0) + 1\n        ent = -sum([v \/ sz * math.log(v \/ sz) for v in six.itervalues(freq)])\n        return ent\n    \n    def _evaluate(self):\n        print('MAP@%s: %s' % (self.topn, self._map()))\n        print('NDCG@%s: %s' % (self.topn, self._ndcg()))\n        print('EntDiv@%s: %s' % (self.topn, self._entropy_diversity()))","dd9c497b":"evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\nevaluate_func._evaluate()","e3d8956b":"train = pd.merge(train, books[['book_id', 'authors', 'ratings_count']], how='left', on='book_id')","0adda99f":"agg = train.groupby(['user_id','authors'])['authors'].agg({'count'}).reset_index()\nagg = agg.sort_values(by='count', ascending=False)\nagg.head()","714deb2e":"author_books = books[['book_id', 'authors', 'ratings_count']].sort_values(by=['authors', 'ratings_count'], ascending=[True, False])\nauthor_books = author_books.reset_index(drop=True)\n\nauthor_books.head()","1543f01a":"author_rec_model = agg.merge(author_books, how='left', on=['authors'])","e4754a74":"author_rec_model.head()","822e611f":"author_rec_model[author_rec_model['user_id'] == 30944]['book_id'].values","5f3e2fbf":"total_rec_list = {}\nfor user in tqdm(rec_df['user_id'].unique()):\n    rec_list = []\n    author_rec_model_ = author_rec_model[author_rec_model['user_id'] == user]['book_id'].values\n    for rec in author_rec_model_: \n        rec_list.append(rec)\n    \n    if len(rec_list) < 200:\n        for i in popular_rec_model[0:200]:\n            rec_list.append(rec)\n        \n    total_rec_list[user] = rec_list[0:200]","f66641cd":"evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\nevaluate_func._evaluate()","4774ad45":"# \ub0b4\uac00 \uc77d\uc740 \ucc45\uc758 \ubaa9\ub85d\uc744 \ucd94\ucd9c \nread_list = train.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\nread_list.head()","156a09e7":"total_rec_list = {}\nfor user in tqdm(rec_df['user_id'].unique()):\n    rec_list = []\n    author_rec_model_ = author_rec_model[author_rec_model['user_id'] == user]['book_id'].values\n    seen = read_list[read_list['user_id'] == user]['unique'].values[0]\n    for rec in author_rec_model_: \n        if rec not in seen:\n            rec_list.append(rec)\n    \n    if len(rec_list) < 200:\n        for i in popular_rec_model[0:200]:\n            if rec not in seen:\n                rec_list.append(rec)\n\n    total_rec_list[user] = rec_list[0:200]","5fa0636a":"evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\nevaluate_func._evaluate()","9ac562b2":"# \ub0b4\uac00 \uc77d\uc744 \uc218 \uc788\ub294 \uc5b8\uc5b4\uc758 \ubaa9\ub85d\uc744 \ucd94\ucd9c \n## User\uc5d0 \ub300\ud55c \uba54\ud0c0\uc815\ubcf4\uac00 \uc788\uc73c\uba74 \uc27d\uac8c \ucd94\ucd9c\uac00\ub2a5\ud558\uc9c0\ub9cc, \ud604\uc7ac\ub294 \uc5c6\uc73c\ubbc0\ub85c \uc9c1\uc811 \uc0dd\uc131 \n## Ratings\uc5d0\uc11c \uc77d\uc740 \ucc45\ub4e4\uc758 \uc5b8\uc5b4\ub97c \uc804\ubd80 \uc218\uc9d1\ud574\uc11c \ud574\ub2f9 \uc5b8\uc5b4\uc758 \ucc45\ub4e4\uc744 \uac00\ub2a5\ud55c \uc5b8\uc5b4\ub85c \uc124\uc815 \nlanguage = pd.merge(train, books[['book_id', 'language_code']], how='left', on='book_id')","422537d3":"language_list = language.groupby(['user_id'])['language_code'].agg({'unique'}).reset_index()\nlanguage_list.head()","63840760":"## Baseline \n- \ud1b5\uacc4\uae30\ubc18\uc758 \ubaa8\ub378 ","7210f03b":"MAP@200: 0.010888309165191986\nNDCG@200: 0.004074971802873805\nEntDiv@200: 5.844823927882108","aa2827bf":"## \ud55c \uc0ac\ub78c\ub2f9 100\uad8c\uc758 \ucc45\uc744 \ucd94\ucc9c\ud574\uc8fc\ub294 \uc0c1\ud669 ","57d34534":"## \ud6c4\ucc98\ub9ac\n- \ub0b4\uac00 \uc77d\uc740 \ucc45\uc740 \ucd94\ucc9c\ud574\uc8fc\uba74 \uc548\ub428 \n- \ub0b4\uac00 \uc77d\uc740 \uc5b8\uc5b4\uc640 \ub9de\ub294 \ucc45\uc744 \ucd94\ucc9c\ud574\uc918\uc57c\ud568 ","e845c24a":"- books.csv : \ucc45\uc758 \uba54\ud0c0\uc815\ubcf4 \n- book_tags.csv : \ucc45-\ud14c\uadf8\uc758 \ub9e4\ud551\uc815\ubcf4 \n- ratings.csv : \uc0ac\uc6a9\uc790\uac00 \ucc45\uc5d0 \ub300\ud574 \uc810\uc218\ub97c \uc900 \ud3c9\uc810\uc815\ubcf4 \n- tags.csv : \ud14c\uadf8\uc758 \uc815\ubcf4 \n- to_read.csv : \uc0ac\uc6a9\uc790\uac00 \uc77d\uc73c\ub824\uace0 \uae30\ub85d\ud574\ub454 \ucc45 (\uc7a5\ubc14\uad6c\ub2c8) ","40eabeb9":"## Baseline \uc751\uc6a9 \n- \ub9ce\uc774 \uae00\uc740 \uae00\uc911\uc5d0\uc11c\ub3c4 \ud3c9\uc810\uc774 \ub192\uc740 \uae00\ub4e4\uc744 \uc6b0\uc120\uc801\uc73c\ub85c \ucd94\ucc9c \n- \ub0b4\uac00 \uc88b\uc544\ud558\ub294 \uc791\uac00\uc758 \uae00\uc744 \uc6b0\uc120\uc801\uc73c\ub85c \ucd94\ucc9c \n- \uc7a5\ubc14\uad6c\ub2c8\uc5d0 \ub2f4\uae34 \uae00\uacfc \uc791\uac00\uc758 \uae00\uc744 \uc6b0\uc120\uc801\uc73c\ub85c \ucd94\ucc9c \n- \uc77d\uc740 \uae00\uc758 \uc2dc\ub9ac\uc988\uae00\uc774 \ub098\uc624\uba74 \ucd94\ucc9c (\ud574\ub9ac\ud3ec\ud130 \ub9c8\ubc95\uc0ac\uc758 \ub3cc -> \ube44\ubc00\uc758 \ubc29)\n- \ucd5c\uc2e0\uc758 \uae00\uc744 \ucd94\ucc9c","5fc994e7":"# 1. Goodbooks-10k \n- Link : https:\/\/www.kaggle.com\/zygmunt\/goodbooks-10k"}}