{"cell_type":{"22d2b594":"code","d36c5d0c":"code","a105acb7":"code","5a36eed9":"code","c3ec5fcd":"code","cb3bab8e":"code","295485cf":"code","50f04795":"code","0988df61":"code","08a94ac0":"code","7d7a6895":"code","f6308757":"code","cb2728b3":"code","60537cd2":"code","77562991":"code","58ec5439":"code","de819a8d":"code","25664738":"code","c3f31391":"code","9fa94b99":"code","fc6de27e":"code","e13f22a1":"code","08ae980a":"code","d38c695e":"code","0d173424":"code","5320d0b9":"code","8936adf9":"code","f1f854ef":"code","1458cb04":"code","7b8c1cb8":"markdown","6272e361":"markdown","34f500ab":"markdown","a92504ff":"markdown","12395997":"markdown","4157a193":"markdown","25340655":"markdown","8c35eeec":"markdown"},"source":{"22d2b594":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport scipy\nimport numpy as np\nfrom wordcloud import WordCloud\nimport sklearn as sk\nfrom PIL import Image\nimport nltk\nfrom nltk import FreqDist\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom string import punctuation\nfrom gensim import corpora, models, similarities\nfrom gensim.models import CoherenceModel\nimport unicodedata\nfrom operator import itemgetter\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics.pairwise import euclidean_distances\n\n# Plotting tools\nimport pyLDAvis\nimport pyLDAvis.gensim  # don't skip this\n\nfrom ggplot import *","d36c5d0c":"df = pd.read_csv('..\/input\/wine-reviews\/winemag-data-130k-v2.csv')\ndf.head(10)","a105acb7":"df.info()","5a36eed9":"df.describe(include = 'all')","c3ec5fcd":"topCountriesList = df['country'].value_counts(ascending=False).reset_index().head(10)['index'].tolist()\ntopCountries = df[(df['country'].isin(topCountriesList))]\n\nmpl.rcParams[\"figure.figsize\"] = \"15, 8\"\np = ggplot(aes(x='factor(country)'), data=topCountries) + \\\n     geom_bar() + \\\n     xlab('Country') +\\\n     ylab('Review Count') #+\\\n     #ggtitle('Top 10 countries based on review count')\np.save('review_count.png')","cb3bab8e":"topVarieties = df['variety'].value_counts().head(30).to_frame()\nprint(topVarieties)\ntuples = topVarieties.to_records(index=True).tolist()\nprint(tuples)\nd = {x:y for x,y in tuples}\nwordcloud = WordCloud(background_color=\"white\", width=800, height=400).generate_from_frequencies(d)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.savefig('most_popular.png')\nplt.show()","295485cf":"mpl.rcParams[\"figure.figsize\"] = \"15, 8\"\nsns.jointplot(x='price', y='points', data=df[df['price'] < 100], kind = 'hex', gridsize=20)\nplt.savefig('jointplot.png')","50f04795":"#tvec = TfidfVectorizer(min_df=0.0025, max_df = .1, stop_words='english')\n#tvec_weights = tvec.fit_transform(df['description'].dropna())\n#weights = np.asarray(tvec_weights.mean(axis=0)).ravel().tolist()\n#weights_df = pd.DataFrame({'term': tvec.get_feature_names(), 'weight': weights})\n#weights_df.sort_values(by='weight', ascending=False).head(10)","0988df61":"rawText = df['description'].to_string()\nraw = rawText.replace('\\n',' ') \ntokens = nltk.word_tokenize(raw)\n\n#change all tokens into lower case \nwords1 = [w.lower() for w in tokens]\n\n#only keep text words, no numbers \nwords = [w for w in words1 if w.isalpha()]\n\n#remove stopwords\nstopwords_list = stopwords.words('english')\nwords_nostopwords = [w for w in words if w not in stopwords_list]\n\n#remove morphological affixes from words, leave only the word stem\nstemmed_words = []\nfor x in words_nostopwords:\n    stemmed_words.append(PorterStemmer().stem(x))\nstemmed_words = filter(lambda a: a != 'wine', stemmed_words)","08a94ac0":"#generate a frequency dictionary for all tokens \nfreq = FreqDist(stemmed_words)\n\n#sort the frequency list in decending order\nsorted_freq = sorted(freq.items(),key = lambda k:k[1], reverse = True)\ntop_list = []\nfor x in sorted_freq[0:40]:\n    top_list.append((x[0],x[1]))","7d7a6895":"wine_mask = np.array(Image.open(\"..\/input\/wine_mask\/wine_mask.png\"))\n\ndef transform_format(val):\n    if val == 0:\n        return 255\n    else:\n        return val\n    \n# Transform mask into a new one that will work with the function:\ntransformed_wine_mask = np.ndarray((wine_mask.shape[0],wine_mask.shape[1]), np.int32)\n\nfor i in range(len(wine_mask)):\n    transformed_wine_mask[i] = list(map(transform_format, wine_mask[i]))","f6308757":"d = {x:y for x,y in top_list}\nprint(d)\nwordcloud = WordCloud(background_color=\"white\", max_words=1000, mask=transformed_wine_mask,\n               stopwords=stopwords, contour_width=3, contour_color='firebrick').generate_from_frequencies(d)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","cb2728b3":"freq.plot(40,title=\"Top 40 Frequently Occuring Terms\")\n","60537cd2":"wines = df.variety.unique().tolist()\n\ndef words_nostop(column, value):\n    df2 = df[(df[column]==value)]\n    valueNew = value.lower()\n    raw1 = df2['description'].to_string()\n    raw = raw1.replace('\\n',' ') \n    tokens = nltk.word_tokenize(raw)\n    words1 = [w.lower() for w in tokens]\n    words2 = [w for w in words1 if w.isalpha()]\n    words3 = list(filter(lambda a: a != valueNew, words2))\n    words4 = list(filter(lambda a: a != 'wine', words3))\n    stopwords2 = stopwords.words('english') + list(punctuation) + wines\n    words_nostopwords = [w for w in words4 if w not in stopwords2]\n    return words_nostopwords\n    \ndef word_counter(column,value):\n    words_nostopwords = words_nostop(column, value)\n    stemmed_words = []\n    for x in words_nostopwords:\n        stemmed_words.append(PorterStemmer().stem(x))\n    freq = FreqDist(stemmed_words)\n    #sort the frequency list in decending order\n    sorted_freq = sorted(freq.items(),key = lambda k:k[1], reverse = True)\n    top_list = []\n    for x in sorted_freq[0:40]:\n        top_list.append((x[0],x[1]))\n    d = {x:y for x,y in top_list}\n    wordcloud = WordCloud(background_color=\"white\", max_words=1000, mask=transformed_wine_mask,\n               stopwords=stopwords, contour_width=3, contour_color='firebrick').generate_from_frequencies(d)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.savefig('france.png')\n    plt.axis(\"off\")\n    plt.show()\n    freq.plot(40,title=\"Top 40 Frequently Occuring Terms\")","77562991":"word_counter('country','France')","58ec5439":"#fixing the wine varieties that are in non-english languages.\nwine_ml = df.copy()\nwine_ml['variety'] = wine_ml['variety'].replace(['weissburgunder'], 'chardonnay') \nwine_ml['variety'] = wine_ml['variety'].replace(['spatburgunder'], 'pinot noir') \nwine_ml['variety'] = wine_ml['variety'].replace(['grauburgunder'], 'pinot gris')\nwine_ml['variety'] = wine_ml['variety'].replace(['garnacha'], 'grenache')\nwine_ml['variety'] = wine_ml['variety'].replace(['pinot nero'], 'pinot noir')\nwine_ml['variety'] = wine_ml['variety'].replace(['alvarinho'], 'albarino')\n\n#145\n","de819a8d":"wines = df.variety.unique().tolist()\nstoplist = stopwords.words('english') + list(punctuation) + wines\n\ndef build_corpus(col, stoplist):\n    corpus = [desc.lower() for desc in col]\n    return [[word for word in str(desc).split() if word not in stoplist] for desc in corpus]\n\ncorpuss = build_corpus(wine_ml.description, stoplist)\ndictionary = corpora.Dictionary(corpuss)\nprint(dictionary)\n#tuples with words and number of occurance\ncorpus = [dictionary.doc2bow(text) for text in corpuss]\nprint(corpus)","25664738":"#Objects of this class realize the transformation between word-document co-occurrence matrix (int) \n#into a locally\/globally weighted TF-IDF matrix (positive floats).\ntfidf = models.TfidfModel(corpus)\ncorpus_tfidf = tfidf[corpus]\n#print(wine_ml.variety.value_counts()[wine_ml.variety.value_counts() > 500])\n#len(wine_ml.variety.value_counts()[wine_ml.variety.value_counts() > 500])      #40\n#wine_ml.variety.value_counts()[wine_ml.variety.value_counts() > 500].index.str.contains('Blend').sum()  #8\ntotal_topics = 32","c3f31391":"#use Latent Dirichlet Allocation to essneitally bin our words \n#in to topics in a way similar to a probability distribution.\nlda = models.LdaModel(corpus, id2word=dictionary, num_topics=total_topics)\nprint(lda.print_topics())\ncorpus_lda = lda[corpus_tfidf]\n#wine_ml_topics = wine_ml[['title', 'variety', 'description', 'points', 'price', 'winery']]\nwine_ml_topics = wine_ml[['variety', 'description', 'points', 'price', 'country']]\n#print(wine_ml_topics)","9fa94b99":"#Evaluation\n\n# Compute Perplexity\nprint('\\nPerplexity: ', lda.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n\n# Compute Coherence Score\ncoherence_model_lda = CoherenceModel(model=lda, texts=corpuss, dictionary=dictionary, coherence='c_v')\ncoherence_lda = coherence_model_lda.get_coherence()\nprint('\\nCoherence Score: ', coherence_lda)","fc6de27e":"mallet_path = '\/home\/zz\/mallet-2.0.8\/bin\/mallet' # update this path\n#ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=dictionary)","e13f22a1":"import gensim\ndef compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n    \"\"\"\n    Compute c_v coherence for various number of topics\n\n    Parameters:\n    ----------\n    dictionary : Gensim dictionary\n    corpus : Gensim corpus\n    texts : List of input texts\n    limit : Max num of topics\n\n    Returns:\n    -------\n    model_list : List of LDA topic models\n    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n    \"\"\"\n    coherence_values = []\n    model_list = []\n    for num_topics in range(start, limit, step):\n        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=dictionary)\n        model_list.append(model)\n        coherencemodel = CoherenceModel(model=model, texts=corpuss, dictionary=dictionary, coherence='c_v')\n        coherence_values.append(coherencemodel.get_coherence())\n\n    return model_list, coherence_values\n\n# Can take a long time to run.\nmodel_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=corpuss, start=30, limit=50, step=2)\n\n# Show graph\nlimit=60; start=10; step=5;\nx = range(start, limit, step)\nplt.plot(x, coherence_values)\nplt.xlabel(\"Num Topics\")\nplt.ylabel(\"Coherence score\")\nplt.legend((\"coherence_values\"), loc='best')\nplt.savefig('evaluat.png')\nplt.show()","08ae980a":"for m, cv in zip(x, coherence_values):\n    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))","d38c695e":"#use Latent Dirichlet Allocation to essneitally bin our words \n#in to topics in a way similar to a probability distribution.\n#Num Topics = 46  has Coherence Value of 0.5355\ntotal_topics = 25\nlda = models.LdaModel(corpus, id2word=dictionary, num_topics=total_topics)\nprint(lda.print_topics())\ncorpus_lda = lda[corpus_tfidf]\n#wine_ml_topics = wine_ml[['title', 'variety', 'description', 'points', 'price', 'winery']]\nwine_ml_topics = wine_ml[['variety', 'description', 'points', 'price', 'country']]","0d173424":"# Visualize the topics\npyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\nvis","5320d0b9":"#use our LDA model to return the most likely topic for each description in the dataset. \n#This and price will be the values we use to recommend a few wines below.\nlikely_topics = [max(lda[corpus[row]], key = itemgetter(1))[0] for row in range(wine_ml_topics.shape[0])]\nwine_ml_topics = wine_ml_topics.assign(topic = likely_topics)\nrecommend_df = wine_ml_topics.dropna()\nrecommend_df","8936adf9":"def what_wine_to_drink(desc, price_point, df=recommend_df, num_response=5):\n    \n    wines = recommend_df.variety.unique().tolist()\n    stoplist = stopwords.words('english') + list(punctuation) + wines\n    \n    #narrow by our price points first\n    if isinstance(price_point, (int, float)):\n        price_mask = (df.price < price_point+4.5*df.price.std()) & (df.price > price_point-4.5*df.price.std())\n        predict_df = df[df.price == price_point]\n        price = price_point\n    else:\n        price_dict = {'500 - 3300': (3300, 500), \n                      '100 - 500': (500, 100),\n                      '25 - 100': (100,25), \n                      '0 - 25': (25,0)}\n        \n        price_mask = (df.price < price_dict[price_point][0]) & (df.price > price_dict[price_point][1])\n        predict_df = df[price_mask]\n        #choose average price of category\n        price = np.mean(price_dict[price_point])\n    \n    #get most likely topic\n    texts = [word for word in str(desc).lower().split() if word not in stoplist]\n    desc_v = dictionary.doc2bow(texts)\n    topic = max(lda[desc_v], key = itemgetter(1))[0]\n    predict_df = predict_df[predict_df.topic==topic]\n    predict_df = predict_df[['price','topic']]\n    \n    user_wine = np.array([price, topic])\n    try:\n        predict_df = predict_df.assign(sim_score = cosine_similarity(predict_df, user_wine.reshape(1, -1)))\n    except ValueError:\n        predict_df = recommend_df[['price','topic']]\n        predict_df = predict_df.assign(sim_score = cosine_similarity(predict_df, user_wine.reshape(1, -1)))  \n    return recommend_df.loc[predict_df.nlargest(5, 'sim_score').index].drop('topic', axis=1)","f1f854ef":"def wine_input():\n    desc = input('Enter a short description of what kind of wine you want to drink: \\n')\n    desc = list(desc)\n    \n    price_point = input('''Enter a price interval (in dollars) of \"500 - 3300\", \"100 - 500\", \"25 - 100\", \"0 - 25\", \n                        or an actual numerical price: \\n''')\n    if len(price_point) < 5:\n        price_point = float(price_point)\n    \n    return what_wine_to_drink(desc, price_point)","1458cb04":"wine_input()","7b8c1cb8":"The goal of the project was to analyze data called Wine Reviews collected from winemag.com and published on kaggle platform, consisting of 130 000 rows. Research consists of some exploratory data analysis, especially reviews, based on which, in the next step, a simple wine recommender was built.\nChosen programming language was Python and used libraries among others are:\n- matplotlib, wordcloud, PIL and seaborn for visualization\n- pandas and numpy for data exploring\n- nltk for text analysis\n- sklearn and gensim for making predictions","6272e361":"In the next step, the dictionary of tokens was transfered into occurance-weighted TF-IDF matrix. Then, usage of Latent Dirichlet Allocation to essentially bin words into topics in a way similar to probability distribution, where chosen topics number was equal to 32, which is number of wine varieties which occur more than 500 times. Later, the LDA model was used to return the most likely topic for each description in the dataset. This compared to analogical processed input description and price are the values applied to our recommender.\n\n","34f500ab":"Firstly top wine varieties were check (fig. ). Three the most popular are Pinot Noir, Chardonnay, Carbenet Cauvignon. All those come from France. To see people of which nationality rate wine, a barplot of top 10 countries based on review count was made (fig. ). It can be clearly seen that most of reviewers are from USA, probably because source website is american. About 2,5 times less reviewers are from France and nextly from Italy, presumably as an effect of good wines origin.","a92504ff":"Variables taken into consideration here were variety of wine, country, price, description and points. After dealing with some missing prices and points (inserting mean in its place), removing few rows without variety or description and fixing the wine varieties that are in non-english languages (f. e. changing 'alvarinho' into 'albarino'), some plots were made.","12395997":"In the next step, in order to observe if it is possible to buy a bottle of delicious wine without spending a lot of money, a jointplot of points dependent on price (with upper bound equal to 100 dollars) was made. The main conclusions here are that most of scored wines cost less than 20 dollars and people are usually satisfied with them, grading with 85-90 points but there is also a tendency the more expensive, the better.","4157a193":"Text analysis","25340655":"The recommender takes a short description of dreamed-of wine and price or prices interval as arguments. Based on price, mask of possible wines was created, then lda models described in the previous section, were compared by using of cosine similarity measure. The function is shown below (fig. ).","8c35eeec":"Nextly, the descriptions were analyzed with nltk library. After some preprocessing, including removing stopwords, wine variety name and word 'wine', frequency wordmaps drawing function was created, where arguments are column name and value. For example, on the next plot characteristics of wine from four different countries are compared."}}