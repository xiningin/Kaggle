{"cell_type":{"0d3dc576":"code","302d2218":"code","05091eaa":"code","3888f37e":"code","985e0c4a":"code","e9563069":"code","60d987b5":"code","4008de89":"code","bf4471c2":"code","6532ae7f":"code","5d89c4d5":"code","f33b5bb8":"code","8b3f3125":"code","62e2041a":"code","b40261c4":"code","f6ea37a8":"code","bbc18cf5":"code","40ba6291":"code","2866012d":"code","baca8ec9":"code","98e341af":"code","59fc3c5c":"code","d55a60bb":"code","95be1b5d":"code","8e86c98c":"code","7426826c":"code","11ec87cd":"code","88ded478":"code","53def76d":"code","49c9c731":"code","c55c6a46":"code","fbbb76bf":"code","b982f687":"code","aabceae7":"code","63dbd496":"code","ed3b3bfd":"code","71427426":"code","dc410249":"code","c9ca1886":"code","f8f0d96f":"code","c43c215b":"code","a8a9275f":"code","2b498300":"code","fafa9765":"code","83b8108c":"code","374e6723":"code","0c393e31":"code","1950f598":"code","45865da7":"code","6d601df0":"code","9791dfc6":"code","ebf111e8":"code","245a9363":"code","e87913ec":"code","1e819928":"code","f82d7954":"code","2acbe018":"code","16669027":"code","366daaaf":"code","e1f67688":"code","a4ec079e":"code","39f4e6d4":"code","f0b66b96":"code","1932a4e6":"code","b4ed5802":"code","7e1e8fda":"code","28119ced":"code","0eb999ed":"code","7b827a09":"code","f10079fa":"code","d3afd1ff":"code","8e5d2b43":"code","e767e403":"code","60f0740b":"code","e714fd69":"code","9eaaf37d":"code","a3a7e7db":"code","0fd279fd":"code","2aa1adf1":"code","9d7c19eb":"markdown","fd40a8f4":"markdown","08a8d09c":"markdown","a6ae3c05":"markdown","293824c0":"markdown","d7042f4a":"markdown","832cab44":"markdown","e57baa2f":"markdown","b63e9377":"markdown","73ec295a":"markdown","3ead09e4":"markdown","b2cd6d20":"markdown","1dff67b5":"markdown","34443810":"markdown","9a94d9b7":"markdown","e87d8ef2":"markdown","4022efb0":"markdown","a25c2aaf":"markdown","caef2c3c":"markdown","59dc915c":"markdown","35f205c8":"markdown","30153eb0":"markdown","c47d362b":"markdown","fa69d95d":"markdown","25af4956":"markdown","f46f0502":"markdown","c282afbe":"markdown","fa05bdc4":"markdown","295ca049":"markdown","50c8f0b1":"markdown","79bfab9c":"markdown","4d543211":"markdown","7e9418c2":"markdown","e2c719a2":"markdown","c8b4cdc8":"markdown","c5934d6c":"markdown","ec70be37":"markdown","16bb5457":"markdown","5d1132c5":"markdown","dba14a9c":"markdown","aa14591e":"markdown","b9098f40":"markdown","25af40ad":"markdown","03d6ec04":"markdown","42b5bb59":"markdown","a1609f8d":"markdown","e856a0fb":"markdown","1b1f5624":"markdown","6ac65460":"markdown","66b6ef03":"markdown","33c307da":"markdown","559ca5df":"markdown","310847c0":"markdown","55c50cc1":"markdown","84b3828d":"markdown","e5b7d674":"markdown","fd01ecde":"markdown","43b9e494":"markdown","eb9fd6e9":"markdown","d7d6a26f":"markdown","f673cb19":"markdown","20ec72bf":"markdown","81b483c1":"markdown","d75b6ced":"markdown","2cad0421":"markdown","163d5e70":"markdown","6c3de806":"markdown","17930af8":"markdown","fc85c0cc":"markdown","31195f76":"markdown","77086d68":"markdown","72af1de0":"markdown","b2b5f881":"markdown","f2b3da72":"markdown","27f0c4c9":"markdown","63963493":"markdown","f35757c8":"markdown","73bcd06a":"markdown","df57e7ee":"markdown","a7f286e0":"markdown","be17e1bc":"markdown","291f887e":"markdown","d7dbf49e":"markdown","5802872e":"markdown","51afa113":"markdown","fb50bd39":"markdown","2ff7a113":"markdown","6b2aa612":"markdown","afd4ac77":"markdown","7923f46b":"markdown","b9db09f8":"markdown","77553d56":"markdown","fdb55eb6":"markdown","d5117ce1":"markdown","0230ca26":"markdown","be8cf7f4":"markdown","d4b3829e":"markdown","25973b15":"markdown","0857eab5":"markdown","2359b46e":"markdown","bda8a044":"markdown","64bab444":"markdown","49295bfc":"markdown","82944d04":"markdown","970545b6":"markdown","b99b7c3c":"markdown","1eef127f":"markdown","2bb08f41":"markdown","34b94380":"markdown","111564a8":"markdown","65541776":"markdown","0ce7e66f":"markdown","25632014":"markdown","c1b5ac2c":"markdown","4d909ad1":"markdown","05e18dd0":"markdown","6c12b108":"markdown","6b914932":"markdown","0a6c029b":"markdown","c9261ba5":"markdown","4cbcdaa8":"markdown"},"source":{"0d3dc576":"pip install bioinfokit","302d2218":"import pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport plotly.express as px\nimport numpy as np\nfrom colorsys import hsv_to_rgb\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom scipy.stats import shapiro\nfrom bioinfokit.analys import stat\nimport plotly.figure_factory as ff\n\n# from plotly.offline import plot, iplot, init_notebook_mode\n# init_notebook_mode(connected=True)\n\n\n# colorpalettes\n\ncolors = [\"f72585\",\"b5179e\",\"7209b7\",\"560bad\",\"480ca8\",\"3a0ca3\",\"3f37c9\",\"4361ee\",\"4895ef\",\"4cc9f0\"]\ncolors = ['#' + color for color in colors]\n\ncolors2 = [\"03045e\",\"023e8a\",\"0077b6\",\"0096c7\",\"00b4d8\",\"48cae4\",\"90e0ef\",\"ade8f4\",\"caf0f8\"]\ncolors2 = ['#' + color for color in colors2]\n\ncolors3 = [\"0466c8\",\"0353a4\",\"023e7d\",\"002855\",\"001845\",\"001233\",\"33415c\",\"5c677d\",\"7d8597\",\"979dac\"]\ncolors3 = ['#' + color for color in colors3]","05091eaa":"df = pd.read_csv('..\/input\/makeup-shades-dataset\/shades.csv')","3888f37e":"df.head()","985e0c4a":"df.info()","e9563069":"print(f'DataFrame contains {df.shape[0]} rows (records) and {df.shape[1]} columns (attributes).')","60d987b5":"sns.heatmap(df.isnull(), cmap=colors2)\nplt.show()","4008de89":"def missing_values(df):\n  '''\n  Count missing values per column\n  Return df with columns: num_missing, percent_missing; index - column with NaNs\n  \n  '''\n  # num of missing values per column\n  num_missing = df.isnull().sum()\n  # percent of missing values per column, rounded\n  percent_missing = round(df.isnull().sum() * 100 \/ len(df), 2)\n  # create a dataframe\n  missing_value_df = pd.DataFrame({'num_missing': num_missing,\n                                  'percent_missing': percent_missing})\n  # sort by largest percent of missing values\n  missing_value_df.sort_values('percent_missing', inplace=True, ascending=False)\n\n  # select only columns that contain missing values\n  return missing_value_df[missing_value_df.percent_missing > 0]","bf4471c2":"missing_df = missing_values(df)\nmissing_df","6532ae7f":"missing_df_explore = pd.DataFrame({\n    'H_NaN BRAND': df['brand'][df['H'].isnull()],\n    'H_NaN INDEX': df['brand'][df['H'].isnull()].index,\n\n    #'S_NaN BRAND': df['brand'][df['S'].isnull()],\n    'S_NaN INDEX': df['brand'][df['S'].isnull()].index,\n\n    #'V_NaN BRAND': df['brand'][df['V'].isnull()],\n    'V_NaN INDEX': df['brand'][df['V'].isnull()].index,\n})\n\nmissing_df_explore","5d89c4d5":"df.dropna(inplace=True)","f33b5bb8":"group_dict = {\n    0: 'Fenty Beauty\\'s PRO FILT\\'R Foundation Only',\n    1: 'Make Up For Ever\\'s Ultra HD Foundation Only',\n    2: 'US Best Sellers',\n    3: 'BIPOC-recommended Brands with BIPOC Founders',\n    4: 'BIPOC-recommended Brands with White Founders',\n    5: 'Nigerian Best Sellers',\n    6: 'Japanese Best Sellers',\n    7: 'Indian Best Sellers'\n}\n\ndf['group_definition'] = df.group.map(group_dict)","8b3f3125":"group_dict_short = {\n    0: 'Fenty Beauty',\n    1: 'Make Up For Ever\\'s',\n    2: 'US BS',\n    3: 'BIPOC Brands - BIPOC Founders',\n    4: 'BIPOC Brands - White Founders',\n    5: 'Nigerian BS',\n    6: 'Japanese BS',\n    7: 'Indian BS'\n}\n\ndf['group_def_short'] = df['group'].map(group_dict_short)","62e2041a":"df.head()","b40261c4":"groups = df.group_definition.unique().tolist()\ncontinuous = ['L', 'H', 'S', 'V']\ncontinuos_names = ['Lightness', 'Hue', 'Saturation', 'Value']","f6ea37a8":"sns.set(style='white')\n\nfrom scipy.stats import pearsonr\n\ndef corrfunc(x, y, ax=None, **kws):\n    r, _ = pearsonr(x, y)\n    ax = ax or plt.gca()\n    ax.annotate(f'\u03c1 = {r:.2f}', xy=(.1, .9), xycoords=ax.transAxes)\n    \n\n# generate pairplot\ng = sns.pairplot(df[continuous], kind='reg',\n            corner=True,\n            plot_kws={'line_kws':{'color':colors3[-3]}, \n                      'marker':\"+\",\n                      'color': colors3[-1],\n                      'scatter_kws': {'alpha': 0.2}},\n            diag_kws={'color': colors3[-1]})\n\n# annotate with Pearson's correlation coefficient \ng.map_lower(corrfunc)\nplt.show()","bbc18cf5":"def top_count(df, column, top_n=None):\n  '''\n  Count number of records per column\n  Return df with columns: column, count\n  \n  '''\n  # count records per group\n  top_counts = df.groupby([column]).size().reset_index(name='counts')\n  # sort by number of records (counts) desc\n  top_counts.sort_values('counts', inplace=True, ascending=False)\n  # select top\n  if top_n:\n    top_counts = top_counts.head(top_n).reset_index(drop=True)\n  return top_counts","40ba6291":"# count number of records (shades) per group\nplot_df = top_count(df, 'group_definition')\n# sort values\nplot_df.sort_values('counts', inplace=True, ascending=True)\n\nax = plot_df.plot.barh(y='counts', x='group_definition', color='#8e9aaf',\n                  title='Groups by Count of Bestsellers', figsize=(8, 6))\n\nax.bar_label(ax.containers[0], padding=7, fontsize=11)\nax.set_xlim(right=175)\nax.set_ylabel('')\nax.get_legend().remove()","2866012d":"plot_df = top_count(df, 'brand', 20)\nplot_df.sort_values('counts', inplace=True, ascending=True)\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(plot_df.counts, plot_df.brand, s=180, color='#ffcad4', zorder=100)\nax.barh(plot_df.brand, plot_df.counts, color='#979dac', height=0.1, edgecolor='none')\n\nax.set(title='Brands with Biggest Count of Bestsellers')\nax.set_yticklabels(plot_df['brand'])\n\nax.bar_label(ax.containers[0], padding=10, color='#777F92', fontsize=10)\n\nax.set_xlim(right=58)\nplt.grid(False)\nplt.show()","baca8ec9":"groups = df.group_definition.unique().tolist()\ngroups.remove('Fenty Beauty\\'s PRO FILT\\'R Foundation Only')\ngroups.remove('Make Up For Ever\\'s Ultra HD Foundation Only')","98e341af":"#sns.set_context(rc={\"axes.titlesize\":12}) \n\nfig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n\n\nfor i, ax in enumerate(axes.flatten()):\n  \n  # subset of records for each group\n  sub = df[df['group_definition'] == groups[i]]\n  plot_df = top_count(sub, 'brand', 5)\n\n  # add more space for count labels\n  ax.axis(xmax=max(plot_df.counts) + max(plot_df.counts)\/10)\n  \n  # barplot\n  sns.barplot(y=plot_df.brand, x=plot_df.counts, \n              palette=['#FFDCE2', '#FFEDF1', '#D9DDE4', '#B4BCCA', '#8e9aaf'][::-1], \n              alpha=0.9, ax=ax, edgecolor='black')\n  ax.bar_label(ax.containers[0], padding=5, fontsize=10)\n    \n  ax.set_title(groups[i], size=12)\n  ax.set_ylabel('')\n  ax.set_xlabel('')\n\nfig.tight_layout()\nfig.subplots_adjust(hspace = 0.5, wspace=0.4)\nplt.show() ","59fc3c5c":"groups = df.group_def_short.unique().tolist()\n\ndef show_violin(column):\n    fig = go.Figure()\n    \n    # 8 groups and 8 colors - hard-coded here\n    for group, color in zip(groups, colors[:8]):\n        # add violin plot for group\n        fig.add_trace(go.Violin(x=df['group_def_short'][df['group_def_short'] == group],\n                                y=df[column][df['group_def_short'] == group],\n                                name=group,\n                                # boxplot with mean\n                                box_visible=True,\n                                meanline_visible=True,\n                                # color\n                                line_color=color\n                               ))\n\n\n    fig.update_layout(template='plotly_white', width=1200)\n    fig.show()\n    \n    \ndef show_distribution(column, title=''):\n    fig = go.Figure()\n    fig = make_subplots(rows=1, cols=2, \n                        shared_yaxes=True, horizontal_spacing = 0.01)\n\n    for group, color in zip(groups, colors[:8]):\n        fig.add_trace(go.Box(y=df['group_def_short'][df['group_def_short'] == group],\n                                x=df[column][df['group_def_short'] == group],\n                                name=group,\n                                boxpoints='outliers', # only outliers\n                                marker_color='black',\n                                line_color='black',\n                                fillcolor=color,\n                                marker=dict(symbol=\"diamond\"),\n                                opacity=0.6), \n                      row=1, col=1)\n\n    for group, color in zip(groups, colors[:8]):\n      fig.add_trace(go.Violin(y=df['group_def_short'][df['group_def_short'] == group],\n                              x=df[column][df['group_def_short'] == group], \n                              line_color=color), \n                    row=1, col=2)\n\n\n    # more space between group label and boxplot\n    fig.update_yaxes(ticksuffix = ' '* 10) \n    \n    fig.update_layout(template='plotly_white', width=1000, showlegend=False,\n                      title=title,  title_x=0.5)\n    fig.update_traces(orientation='h')\n    fig.update_traces(side='positive', width=2, points=False, col=2)\n    fig.show()","d55a60bb":"show_violin('L')","95be1b5d":"show_distribution('L', 'Lightness')","8e86c98c":"!pip install prettytable","7426826c":"print('Shapiro-Wilk test\\n')\n\nfrom prettytable import PrettyTable\nt = PrettyTable(['group', 'fail \/ pass', 'p-value'])\nt.float_format['p-value'] = '0.6'\n\npassed = []\nfor group in groups:\n  data = df['L'][df['group_def_short'] == group]\n  # Shapiro-Wilk test\n  _, p_value = shapiro(data)\n  if p_value < 0.05:\n    # reject H0\n    # data isn't drawn from normal distribution\n    t.add_row([group, 'fail',  p_value])\n  else:\n    # not enough evidence to reject H0\n    t.add_row([group, 'pass',  p_value])\n    passed.append(group)\n\nprint(t)\n    \nprint('\\nPassed:', ', '.join(passed))","11ec87cd":"japanese = df.loc[df['group_def_short'] == 'Japanese BS',  :]\nindian = df.loc[df['group_def_short'] == 'Indian BS', :]\n\n# remove outliers\nindian = indian.loc[indian['L'] > 58, :]\n\n# len of japanese > indian\nmin_len = min(len(japanese), len(indian))\n\n# randomly select samples\n# to make equal number of records\njapanese = japanese.sample(n=min_len)\n\njapanese_and_indian = pd.concat([japanese, indian])","88ded478":"from bioinfokit.analys import stat\nres = stat()\nres.ttest(evar=False, df=japanese_and_indian, xfac='group_def_short', res='L', test_type=2)\nprint(res.summary)","53def76d":"group_labels = ['Indian BS', 'Japanese BS']\n\n# Create distplot with curve_type set to 'normal'\nfig = ff.create_distplot([indian['L'], japanese['L']], group_labels, \n                         curve_type='normal', # override default 'kde'\n                         colors=['#ffcad4', '#979dac'])\n\n# Add title\nfig.update_layout(title_text='Japanese and Indian Bestsellers (L)',\n                  width=700, template='plotly_white', title_x=0.5)\nfig.show()","49c9c731":"res = stat()\nres.levene(df=japanese_and_indian, res_var='L', xfac_var='group_def_short')\nres.levene_summary","c55c6a46":"dist1 = df.loc[df['group_def_short'] == 'Nigerian BS', 'L']\ndist2 = df.loc[df['group_def_short'] == 'BIPOC Brands - BIPOC Founders', 'L']\n\nmean1 = np.mean(dist1) \nmean2 = np.mean(dist2)\n\ngroup_labels = [f'Nigerian BS<br>(mean = {mean1:.2f}, var = {dist1.var():.2f})<br>', \n                f'BIPOC Brands - BIPOC Founders<br>(mean = {mean2:.2f}, var = {dist2.var():.2f})<br>']\n\n# Create distplot with curve_type set to 'normal'\nfig = ff.create_distplot([dist1, dist2],\n                         group_labels, bin_size=5,\n                         curve_type='normal', # override default 'kde'\n                         colors=['#ffcad4', '#979dac'])\n\nfig.add_shape(type=\"line\",x0=mean1, x1=mean1, y0 =0, y1=0.04 , xref='x', yref='y',\n               line = dict(color = '#ffcad4', dash = 'dash'))\n\nfig.add_shape(type=\"line\",x0=mean2, x1=mean2, y0 =0, y1=0.04 , xref='x', yref='y',\n               line = dict(color = '#979dac', dash = 'dash'))\n\n\n# Add title\nfig.update_layout(title_text='Nigerian and BIPOC-recommended brands with BIPOC founders (L)',\n                  width=800, template='plotly_white')\n\n\nfig.show()","fbbb76bf":"from statsmodels.formula.api import ols\nothers = df.loc[(df['group_def_short'] == 'US BS') | \n               (df['group_def_short'] == 'BIPOC Brands - White Founders') |\n               (df['group_def_short'] == 'Make Up For Ever\\'s') |\n               (df['group_def_short'] == 'Fenty Beauty'), :]\n\nmodel = ols('L ~ C(group_def_short)', data=others).fit()\n\nw, pvalue = shapiro(model.resid)\nprint('p-value of Shapiro-Wilks test:', pvalue)","b982f687":"import scipy.stats as stats\nfvalue, pvalue = stats.kruskal(df.loc[(df['group_def_short'] == 'US BS'), 'L'],\n                                df.loc[(df['group_def_short'] == 'BIPOC Brands - White Founders'), 'L'], \n                                df.loc[(df['group_def_short'] == 'Make Up For Ever\\'s'), 'L'], \n                                df.loc[(df['group_def_short'] == 'Fenty Beauty'), 'L'])\nprint('p-value of Kruskal-Wallis test:', pvalue)","aabceae7":"show_distribution('H', 'Hue')","63dbd496":"hue = df.groupby(['group_def_short'])['H'].agg(['median', 'min', 'max', 'std']).reset_index()\nhue","ed3b3bfd":"first_row = hue.loc[[0]]\n\n# repeat first record\nappended = pd.concat([hue, first_row]) \n\nangles = np.linspace(0, 2*np.pi, len(appended) - 1, endpoint=False)\nangles = np.concatenate((angles, [angles[0]]))\n\ncolumn = appended['std']\n\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 6),\n                                    subplot_kw={'projection': 'polar'})\n\n\nax.plot(angles, column, 'o-', color=colors3[4], markersize=8)\nax.set_title('Std Hue', {'fontsize': 20})\n\nax.fill(angles, column, alpha=0.3, color=colors3[5])\n\nax.set_thetagrids(angles * 180 \/ np.pi, appended.group_def_short, fontsize=13)\n\nfor x,y in zip(angles, column):\n\n  label = \"{:.1f}\".format(y)\n\n  ax.annotate(label, # text\n              (x,y), # coordinates to position the label\n              textcoords=\"offset points\", # how to position the text\n              xytext=(0, 10), # distance from text to points (x,y)\n              ha='center', color='#979dac') # text horizontal alignment, color\n\nax.set_yticklabels([])\nax.set_theta_zero_location('N')\nax.set_ylim([0, max(column) + max(column)\/5])\n\nplt.subplots_adjust(hspace = 2)\nplt.tight_layout()\nplt.show()","71427426":"columns = ['min', 'max']\n\nfig, axes = plt.subplots(ncols=2, nrows=1, subplot_kw={'projection': 'polar'}, figsize=(12, 14))\n\nfor i, ax in enumerate(axes.flatten()):\n\n    column = appended[columns[i]]\n\n    colors_hue = [hsv_to_rgb(i\/100, 1, 1) for i in column.values]\n\n    ax.scatter(angles, column, c=colors_hue, edgecolors= \"black\", s=200, zorder=5)\n    ax.plot(angles, column, color='#979dac')\n\n\n    ax.set_title(columns[i] +' Hue', {'fontsize': 20, 'color': 'black'})\n\n    ax.fill(angles, column, alpha=0.3, color='#979dac')\n\n    ax.set_thetagrids(angles * 180 \/ np.pi, appended.group_def_short, fontsize=13, zorder=100)\n\n    for x,y in zip(angles, column):\n\n        label = \"{:.1f}\".format(y)\n\n        ax.annotate(label, # text\n                    (x,y), # coordinates to position the label\n                    textcoords=\"offset points\", # how to position the text\n                    xytext=(0, 10), # distance from text to points (x,y)\n                    ha='center', color=colors3[5]) # text horizontal alignment, color\n\n    ax.set_yticklabels([])\n    ax.set_theta_zero_location('N')\n    ax.set_ylim([0, max(column) + max(column)\/5])\n\n#plt.subplots_adjust(hspace = 2)\nplt.tight_layout()\nplt.show()","dc410249":"fig, ax = plt.subplots(ncols=1, nrows=1, subplot_kw={'projection': 'polar'}, figsize=(7, 7))\n\n\ncolumn = appended['median']\n\ncolors_hue = [hsv_to_rgb((i-13)\/100, 1, 1) for i in column.values]\n\nax.scatter(angles, column, c=colors_hue, edgecolors= \"black\", s=200, zorder=5)\nax.plot(angles, column, color='#979dac')\n\n\nax.set_title('median' +' Hue', {'fontsize': 20, 'color': 'black'})\n\nax.fill(angles, column, alpha=0.3, color='#979dac')\n\nax.set_thetagrids(angles * 180 \/ np.pi, appended.group_def_short, fontsize=13, zorder=100)\n\nfor x,y in zip(angles, column):\n\n    label = \"{:.1f}\".format(y)\n\n    ax.annotate(label, # text\n                (x,y), # coordinates to position the label\n                textcoords=\"offset points\", # how to position the text\n                xytext=(0, 10), # distance from text to points (x,y)\n                ha='center', color=colors3[5]) # text horizontal alignment, color\n\nax.set_yticklabels([])\nax.set_theta_zero_location('N')\nax.set_ylim([0, max(column) + max(column)\/5])\n\n#plt.subplots_adjust(hspace = 2)\nplt.tight_layout()\nplt.show()","c9ca1886":"show_distribution('S', 'Saturation')","f8f0d96f":"saturation = df.groupby(['group_def_short'])['S'].agg(['median', 'mean', 'std', 'skew']).reset_index()\nsaturation.sort_values(by='median')","c43c215b":"japanese = df.loc[df['group_def_short'] == 'Japanese BS',  :]\nindian = df.loc[df['group_def_short'] == 'Indian BS', :]\n\n# remove outliers\nindian = indian.loc[indian['S'] < 0.7, :]\n\n# len of japanese >\nmin_len = min(len(japanese), len(indian))\n\n# randomly select samples\n# to make equal number of records\njapanese = japanese.sample(n=min_len)\nindian = indian.sample(n=min_len)\n\njapanese_and_indian = pd.concat([japanese, indian])\n\nres = stat()\nres.ttest(evar=False, df=japanese_and_indian, xfac='group_def_short', res='L', test_type=2)\nprint(res.summary)","a8a9275f":"bipoc = df.loc[df['group_def_short'] == 'BIPOC Brands - White Founders',  :]\nus = df.loc[df['group_def_short'] == 'US BS', :]\n\n# len of japanese  is more\nmin_len = min(len(bipoc), len(us))\n\n# randomly select samples\n# to make equal number of records\nbipoc = bipoc.sample(n=min_len)\nus = us.sample(n=min_len)\n\nus_bipoc = pd.concat([us, bipoc])\n\nres = stat()\nres.ttest(evar=False, df=us_bipoc, xfac='group_def_short', res='L', test_type=2)\nprint(res.summary)","2b498300":"r, p = pearsonr(df['S'], df['L'])\nprint(f'Pearson\\'s correlation coefficient between lightness and saturation:\\n\u03c1 = {r:.2f}, p-value = {p}')","fafa9765":"from sklearn.preprocessing import MinMaxScaler\n\ndf_scaled = df.copy()\ndf_scaled[['L', 'S', 'H']] = MinMaxScaler().fit_transform(df[['L', 'S', 'H']])\n\n\nfig = px.parallel_coordinates(df_scaled, color='group',\n                              dimensions=['group', 'L', 'S', 'H'],\n                              color_continuous_scale=colors[::-1],\n                              title=\"Parallel Coorinates Plot for All Groups\")\nfig.update_layout(width=800, title_x=0.5)\nfig.show()","83b8108c":"fig = px.parallel_coordinates(df_scaled[df_scaled['group'].isin([3, 6])], color='group',\n                              dimensions=['group', 'L', 'S', 'H'],\n                              color_continuous_scale=colors[::-1],\n                              title=\"Japanese (#6) Vs BIPOC-recommended Brands with BIPOC Founders (#3)\")\nfig.update_layout(width=800, title_x=0.5)\nfig.show()","374e6723":"from scipy.stats import skew\nstats = df.groupby(['brand', 'group', 'group_definition'])[['L', 'S', 'H', 'V']]\\\n.agg(['mean', 'median', 'min', 'max', 'std', 'count', 'var', skew]).reset_index()","0c393e31":"stats.head()","1950f598":"stats.columns = ['_'.join(col).strip('_') for col in stats.columns.values]","45865da7":"stats.columns","6d601df0":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nX = stats.iloc[:, 3:]\nY = stats.iloc[:, :3]\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","9791dfc6":"pca = PCA()\npca.fit(X_scaled)\npca.n_components = 2\nX_reduced = pca.fit_transform(X_scaled)\ndf_X_reduced = pd.DataFrame(X_reduced)","ebf111e8":"total_var = pca.explained_variance_ratio_.sum() * 100\nprint(f'Total Explained Variance: {total_var:.2f}%')","245a9363":"df_reduced = pd.concat([Y, df_X_reduced], axis=1)\ndf_reduced.head(2)","e87913ec":"from sklearn.cluster import KMeans\n\ndef cluster(n_clusters, df):\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    kmeans.fit(df)\n    Z = kmeans.predict(df)\n    return kmeans, Z\n\nmax_clusters = len(X_reduced)\n\ninertias = np.zeros(max_clusters)\n\nfor i in range(1, max_clusters):\n    kmeans, Z = cluster(i, X_reduced)\n    inertias[i] = kmeans.inertia_","1e819928":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=list(range(1, 25)),\n                        y=inertias[1:25], mode='lines+markers',\n                         marker=dict(size=8, color=colors3[5])))\n\nfig.add_trace(go.Scatter(x=[3],\n                        y=[inertias[3]],\n                        marker=dict(size=20, symbol='x', color=colors[-1], line=dict(\n                color='black',\n                width=0.5\n            )),\n                        text='Optimal num of clusters by elbow method'))\n\nfig.add_trace(go.Scatter(x=[7],\n                        y=[inertias[7]],\n                        marker=dict(size=20, symbol='x', color='#A4E7F4', line=dict(\n                color='black',\n                width=0.5)),\n                        text='Suggested num of clusters'))\n\nfig.update_layout(template='plotly_white', height=400, width=600, \n                  showlegend=False, title='Sum of Squared Distances to Cluster Center (Inertia) Plot',\n                  title_x=0.5)\n\nfig.show()","f82d7954":"n_clusters = 7\nmodel, Z = cluster(n_clusters, X_reduced)","2acbe018":"Z","16669027":"df_reduced['cluster'] = Z","366daaaf":"# Add marker symbol - just for better visualization.\n\nsymbols_dict = {\n    'Fenty Beauty\\'s PRO FILT\\'R Foundation Only': 1, \n    'Make Up For Ever\\'s Ultra HD Foundation Only': 2, \n    'US Best Sellers': 13, \n    'BIPOC-recommended Brands with BIPOC Founders': 14, \n    'BIPOC-recommended Brands with White Founders': 15, \n    'Nigerian Best Sellers': 18, \n    'Japanese Best Sellers': 21, \n    'Indian Best Sellers': 16\n}\n\ndf_reduced['symbols'] = df_reduced['group_definition'].map(symbols_dict)","e1f67688":"fig = go.Figure()\n\nclusters = pd.Series([str(i) for i in range(n_clusters)])\n\nfig.add_trace(go.Scatter(x=df_reduced[0],\n                        y=df_reduced[1], \n                        mode='markers',\n                        marker=dict(color=df_reduced['cluster'], # color\n                                    size=15, opacity=0.4,        # size, opacity\n                                    # change marker symbol per group\n                                    symbol=df_reduced['symbols'], \n                                    colorscale=colors),          # colors\n                        # hover text -> brand, cluster, group\n                        text='<\/br><b>' + df_reduced['brand'] + '<\/b>' + '<\/br>' +\n                        'Cluster #' + df_reduced['cluster'].astype(str) + '<\/br>' +\n                        df_reduced['group_definition'], \n                        showlegend=False)) # hide legend\n\n# add cluster centroids\nfig.add_trace(go.Scatter(x=model.cluster_centers_[:, 0],\n                         y=model.cluster_centers_[:, 1], mode='markers',\n                         marker=dict(color=list(range(n_clusters)), \n                                     size=25, symbol='x',\n                                     colorscale=colors),\n                        # hover text -> number of cluster\n                        text= 'Cluster center #' + clusters, \n                        # legend \n                        showlegend=False))\n\n# Legend ----------------------------------------------------------------\nfig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',\n                        marker=dict(size=25, color='#979dac', symbol='x'),\n                        showlegend=True, name='Cluster centers', legendgroup='1'))\n\nfor key, value in symbols_dict.items():\n  fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',\n                        marker=dict(size=15, color='#979dac', symbol=value),\n                        showlegend=True, name=key))\n\n# -----------------------------------------------------------------------\n\nfig.update_layout(template='plotly_white', height=600, width=1200)\nfig.show()","a4ec079e":"fig = go.Figure()\n\n# Add traces, one for each slider step\nfor n_clusters in np.arange(3, 11):\n    \n    model, Z = cluster(n_clusters, X_reduced)\n    df_reduced['cluster'] = Z\n\n    fig.add_trace(go.Scatter(x=df_reduced[0],\n                            y=df_reduced[1], visible=False,\n                             mode='markers',\n                            marker=dict(color=df_reduced['cluster'], \n                                        size=18, opacity=0.8, \n                                        symbol=df_reduced['symbols'], # marker shape\n                                        colorscale=colors),\n                            # HOVER TEXT\n                            text='<\/br><b>' + df_reduced['brand'] + '<\/b>' + '<\/br>' +\n                            'Cluster #' + df_reduced['cluster'].astype(str) +\n                            '<\/br>' + df_reduced['group_definition']))\n\n\n\n# Make 1st trace visible\nfig.data[0].visible = True\n\n# Create and add slider\nsteps = []\nfor i in range(len(fig.data)):\n    step = dict(\n        method=\"update\",\n        args=[{\"visible\": [False] * len(fig.data)},\n              {\"title\": \"Num clusters: \" + str(i + 3) +\n               \"<br><sup>Shapes represent groups<\/sup>\"}], \n              label=str(i + 3) # layout attribute\n    )\n    step[\"args\"][0][\"visible\"][i] = True  # Toggle i'th trace to \"visible\"\n    \n    steps.append(step)\n\nsliders = [dict(\n    active=0,\n    currentvalue={\"prefix\": \"Num clusters: \"},\n    pad={\"t\": 50},\n    steps=steps\n)]\n\nfig.update_layout(\n    sliders=sliders\n)\nfig.update_layout(template='plotly_white', height=600, width=800, showlegend=False)\n\nfig.show()","39f4e6d4":"pca = PCA()\npca.fit(X_scaled)\npca.n_components = 3\n\n# perform PCA\nX_reduced_3d = pca.fit_transform(X_scaled)\ndf_X_reduced_3d = pd.DataFrame(X_reduced_3d)\n\n# \ntotal_var = pca.explained_variance_ratio_.sum() * 100\nprint(f'Total Explained Variance: {total_var:.2f}%')\n\n# concatenate group, brand, group definition and transformed data\ndf_reduced_3d = pd.concat([Y, df_X_reduced_3d], axis=1)\n\nn_clusters = 3\n# perform clustering\nmodel, Z = cluster(n_clusters, X_reduced_3d)\n# add column\ndf_reduced_3d['cluster'] = Z\n\n\n# 3D plot -------------------------------------------------------\n\nfig = go.Figure(data=[go.Scatter3d(\n    x=df_reduced_3d[0],\n    y=df_reduced_3d[1],\n    z=df_reduced_3d[2],\n    mode='markers',\n    marker=dict(\n        size=10,\n        color=df_reduced_3d['cluster'], \n        opacity=0.9,\n        colorscale=colors\n    ),\n    text='<\/br><b>' + df_reduced_3d['brand'] + '<\/b>' + '<\/br>' +\n    'Cluster #' + df_reduced_3d['cluster'].astype(str) + '<\/br>' +\n    df_reduced_3d['group_definition']\n)])\n\n\nfig.update_layout(margin=dict(l=0, r=0, b=0, t=0),\n                  template='seaborn', height=500, width=500)\nfig.show()","f0b66b96":"df_scaled_all_dims = pd.concat([Y, pd.DataFrame(X_scaled)], axis=1)\n\nn_clusters = 3\n# perform clustering\nmodel, Z = cluster(n_clusters, X_scaled)\n# add column\ndf_scaled_all_dims['cluster'] = Z\n\n\ndf_scaled_all_dims.head()","1932a4e6":"df_scaled_all_dims.loc[26:27, :]","b4ed5802":"df_scaled_all_dims.loc[(df_scaled_all_dims['brand'] == 'Maybelline') & (df_scaled_all_dims['group'] == 2), 'brand'] = 'Maybelline_US'\ndf_scaled_all_dims.loc[(df_scaled_all_dims['brand'] == 'Maybelline') & (df_scaled_all_dims['group'] == 7), 'brand'] = 'Maybelline_India'\n\ndf_scaled_all_dims.loc[(df_scaled_all_dims['brand'] == 'L\\'Or\u00e9al') & (df_scaled_all_dims['group'] == 2), 'brand'] = 'L\\'Or\u00e9al_US'\ndf_scaled_all_dims.loc[(df_scaled_all_dims['brand'] == 'L\\'Or\u00e9al') & (df_scaled_all_dims['group'] == 7), 'brand'] = 'L\\'Or\u00e9al_India'\n\ndf.loc[(df['brand'] == 'Maybelline') & (df['group'] == 2), 'brand'] = 'Maybelline_US'\ndf.loc[(df['brand'] == 'Maybelline') & (df['group'] == 7), 'brand'] = 'Maybelline_India'\n\ndf.loc[(df['brand'] == 'L\\'Or\u00e9al') & (df['group'] == 2), 'brand'] = 'L\\'Or\u00e9al_US'\ndf.loc[(df['brand'] == 'L\\'Or\u00e9al') & (df['group'] == 7), 'brand'] = 'L\\'Or\u00e9al_India'","7e1e8fda":"df_scaled_all_dims.loc[26:27, :]","28119ced":"# dictionary: {brand: cluster}\ncluster_dict = {}\n\nfor i in df_scaled_all_dims.index:\n  br = df_scaled_all_dims.loc[i, 'brand']\n  cl = df_scaled_all_dims.loc[i, 'cluster']\n  cluster_dict[br] = cl\n\ndf['cluster'] = df['brand'].map(cluster_dict)\ndf.head()","0eb999ed":"# dictionary: {brand: cluster}\ntemp = pd.DataFrame.from_dict(cluster_dict, orient='index', columns=['cluster'])\n# brand is initially saved as index\ntemp['brand'] = temp.index\n# reset index\ntemp.reset_index(inplace=True)\n# group brands by cluster, join strings\ntemp = temp.groupby('cluster')['brand'].agg(list).transform(', '.join).reset_index()\n\n\nwith pd.option_context('display.max_colwidth', None):\n  display(temp)","7b827a09":"bins = list(range(0, 101, 10)) # [0, 10, ..., 100]\nlabels = [str(item) for item in bins[1:]]\n\nprint(f'L max: {df.L.max()}, L min: {df.L.min()}')\nprint('L bins:', bins)\n\ndf['L_bins'] = pd.cut(df['L'], bins=bins, labels=labels)\ndf['L_bins'] = df['L_bins'].astype(int)\n\n# ------------------------------------------------------\n\nbins = list(range(0, 51, 5)) # [0, 5, 10, 15, ..., 45]\nlabels = [str(item) for item in bins[1:]]\n\nprint(f'\\nH max: {df.H.max()}, H min: {df.H.min()}')\nprint('H bins:', bins)\n\ndf['H_bins'] = pd.cut(df['H'], bins=bins, labels=labels)\ndf['H_bins'] = df['H_bins'].astype(int)\n\n# ------------------------------------------------------\n\nbins = list(np.arange(0, 1.1, 0.1, dtype=np.float32)) # [0.0, 0.1, 0.2, ..., 1.0]\nlabels = [str(item) for item in bins[1:]]\n\nprint(f'\\nS max: {df.S.max()}, S min: {df.S.min()}')\nprint('S bins:', bins)\n\ndf['S_bins'] = pd.cut(df['S'], bins=bins, labels=labels)\ndf['S_bins'] = df['S_bins'].astype(float)","f10079fa":"df.head(10)","d3afd1ff":"def dot_plot(bins_column, groupby_column, groupby_values, title='', height=600, width=1000):\n\n    fig = make_subplots(rows=1, cols=len(groupby_values))\n\n    for i, value in enumerate(groupby_values):\n\n      # select brand, cluster or group\n      sel = df[df[groupby_column] == value]\n\n      # loop through bins\n      for bin in sel[bins_column].unique():\n\n        # len(colors) == num of records in bin\n        colors = sel.loc[sel[bins_column] == bin, 'hex']\n        colors_hex = ['#'+c for c in colors]\n        \n        brands = sel.loc[sel[bins_column] == bin, 'brand']\n        groups = sel.loc[sel[bins_column] == bin, 'group_definition']\n\n        # repeat bin value for each color\n        x = [bin for _ in colors]\n        # color count\n        y = [i for i in range(len(colors))]\n\n        # hover text --> brand and group     \n        fig.add_trace(go.Scatter(\n                  x=x,\n                  y=y,\n                  marker=dict(color=colors_hex, size=20),\n                  mode=\"markers\", \n                  text=brands + '<br>' + groups,\n                ), row=1, col=i+1)\n\n      # update axis titles\n      for current_axis in fig.select_xaxes(row=1, col=i+1):\n        if type(value) == int:\n          current_axis.update(title_text='Cluster ' + str(value))\n        else:\n          current_axis.update(title_text=value)\n\n        # x_ticks --> bins\n        current_axis.update(tickmode = 'array', tickvals = sel[bins_column].unique())\n\n    # size, title, theme    \n    fig.update_layout(title=title, title_x=0.5, # common title\n                      width=width, height=height, \n                      showlegend=False, # also common settings\n                      template='plotly_white')\n    \n    # does not return anything\n    fig.show()","8e5d2b43":"dot_plot(bins_column='L_bins', \n         groupby_column='cluster', \n         groupby_values=[0, 1, 2], \n         title='Shades per cluster, sorted by lightness')","e767e403":"dot_plot('H_bins', 'cluster', [0, 1, 2], 'Shades per cluster, sorted by hue')","60f0740b":"dot_plot('S_bins', 'cluster', [0, 1, 2], 'Shades per cluster, sorted by saturation')","e714fd69":"dot_plot('L_bins', 'group_def_short', ['Indian BS', 'Japanese BS', 'BIPOC Brands - BIPOC Founders','Nigerian BS'], \n         'Shades of groups that have similar distributions (pair 1, 2)', height=400)","9eaaf37d":"dot_plot('L_bins', 'brand', ['Maybelline_India', 'Maybelline_US'], \n         'Shades by Maybelline in US and India', 400, 600)","a3a7e7db":"dot_plot('L_bins', 'brand', ['L\\'Or\u00e9al_India', 'L\\'Or\u00e9al_US'], \n         'Shades by L\\'Or\u00e9al in US and India', 400, 600)","0fd279fd":"dot_plot('L_bins', 'brand', ['Fenty', 'Make Up For Ever', 'MAC', 'Est\u00e9e Lauder'], \n         'Brands with biggest num of products represented in the dataset', height=500)","2aa1adf1":"dot_plot('L_bins', 'brand', ['Trim & Prissy', 'Kuddy', 'Lakm\u00e9', 'Olivia'], \n         'Shades by Trim & Prissy', height=400, width=700)","9d7c19eb":"<a id=\"subsection-32\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Count Bestsellers per Brand, Group<\/h3>","fd40a8f4":"<div style=\"border-radius:7px;\n            border: 2px dashed #8e9aaf;\n            padding: 28px 18px 18px 18px;\">\n    <p span style='font-size: 16px;'> \ud83d\udccc Maybelline, MAC, Est\u00e9e Lauder are in top-3 brands.<\/span><\/p>\n    <\/div>","08a8d09c":"<p><span style='font-size: 16px;'>Plot missing values with heatmap:<\/span><\/p>","a6ae3c05":"<p><span style='font-size: 16px;'><b>Null hypothesis:<\/b> Two group means are equal.<\/span><\/p> \n<p><span style='font-size: 16px;'><b>Alternative hypothesis:<\/b> Two group means are different (two-tailed or two-sided test).<\/span><\/p> \n<span style='font-size: 16px;'>Assumptions: <br><ul>\n  <li>Observations in two groups have an approximately normal distribution.<\/li>\n  <li>Homogeneity of variances (variances are equal between groups) (Levene or Bartlett Test).<\/li>\n  <li>The two groups are sampled independently from each other from the same population. [<a href=\"https:\/\/www.reneshbedre.com\/blog\/ttest.html\">1<\/a>]<\/li>\n<\/ul><\/span><\/p>","293824c0":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d What brands are more popular <b> per group<\/b>?<\/span><\/p>","d7042f4a":"<p><span style='font-size: 16px;'>Create a DataFrame with number and percent of missing values per column:<\/span><\/p>","832cab44":"<div style=\"border-radius:7px; border: 2px dashed #8e9aaf; padding: 28px 18px 18px 18px;\">\n    \n<p><span style='font-size: 16px;'>Results:<\/span><\/p>\n    \n\n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #BB9DDE;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span>Fenty, Make Up For Ever, Bobbi Brown, Est\u00e9e Lauder, L'Or\u00e9al, Maybelline, Lanc\u00f4me, Beauty Bakerie - all brands are in top 10 popular brands with biggest number of bestsellers.\n  <\/p>\n\n    \n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #B5CAF9;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span>L'Or\u00e9al, MAC, bareMinerals - similar to previous cluster.\n  <\/p>\n    \n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #D49FDD;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span>Japanese and Indian brands.\n  <\/p>\n    \n    \n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #B7E9F9;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span>Also Japanese and Indian brands ;)\n  <\/p>\n    \n\n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #B39EDB;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span>2 Indian brands: Lakm\u00e9 and Olivia, 2 Nigerian - Kuddy, Trim &amp Prissy. These brands have less than 5 products represented in the dataset (except the last one).\n  <\/p>\n    \n    \n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #B2AFE9;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span>Mosly Nigerian brands.\n  <\/p>\n\n    \n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #FCA8CE;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span>BIPOC-recommended brands with BIPOC Founders.\n  <\/p>\n    \n<\/div>\n\n","e57baa2f":"<p><span style='font-size: 16px;'>\ud83d\udccc Inertia - sum of squared distances of samples to their closest cluster center.<br><br>The elbow method of selecting number of clusters is to select k when inertia starts to decrease linearly.<\/span><\/p>  ","b63e9377":"<p><span style='font-size: 16px;'>Thus, we can drop missing values as the columns with hue, saturation, value contain the most essential information.<\/span><\/p> ","73ec295a":"<p><span style='font-size: 16px;'>Display available shades, sorted by lightness and grouped by cluster the corresponding brand belongs to.<\/span><\/p>\n<p><span style='font-size: 16px;'>Hover over the shades to see brand and group.<\/span><\/p>","3ead09e4":"<a id=\"subsection-44\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">KMeans for 7 Clusters<\/h3>","b2cd6d20":"<p><span style='font-size: 16px;'>Similarly to the previous 2d plot, brand Trim & Prissy appears to be located almost at the centre. Also, brand Iman can be noticed as an outlier in its group.<\/span><\/p>","1dff67b5":"In a context of a makeup, lightness indicates whether a foundation line caters toward lighter or darker skin tones. [[Pudding essay Beauty Brawl](https:\/\/pudding.cool\/2018\/06\/makeup-shades\/)]\n\nHigh saturation means that the colors appear to be more pure. As the saturation decreases, the colors appear to be more washed-out or pale.\n\nHue - the more yellow, red, green etc. the tone is.","34443810":"<p><span style='font-size: 16px;'>Scatter plot with correlation line and Pearson's correlation coefficient:<\/span><\/p> ","9a94d9b7":"<p><span style='font-size: 16px;'>Taking into consideration the fact that only one group out of 4 passed the normality test, I need to use a non-parametric test.<\/span><\/p> ","e87d8ef2":"<p><span style='font-size: 16px;'>Levene\u2019s test can be used to check the homogeneity of variances when the data is not drawn from normal distribution. [<a href=\"https:\/\/www.reneshbedre.com\/blog\/anova.html\">2<\/a>]<\/span><\/p>","4022efb0":"<p><span style='font-size: 16px;'>Soo, I want to compare Indian and Japanese bestsellers groups first.<\/span><\/p><p><span style='font-size: 16px;'>To compare two groups, I'll use t-test. However, these groups failed normality test.<br>Luckily, two sample t-test is relatively robust to the assumption of normality and homogeneity of variances when sample size is large (n \u2265 30) and there are equal number of samples (n1 = n2) in both groups. [<a href=\"https:\/\/www.reneshbedre.com\/blog\/ttest.html\">1<\/a>]<br>So I remove an outlier from Indian bestsellers and randomly select n_records from Japanese BS, which is equal to number or records in Indian bestsellers.<br>For all statistical tests I set a 95% confidence level.<\/span><\/p>","a25c2aaf":"<p><span style='font-size: 14px;'>*In context of shades, present in this dataset.<\/span><\/p> ","caef2c3c":"<p><span style='font-size: 16px;'> \ud83d\udccc The p value obtained from both t-tests is not significant (p > 0.05), and therefore, we can't reject null hypothesis that states that means are equal.<\/span><\/p> ","59dc915c":"<a id=\"section-5\"><\/a>\n<h1 style=\";font-size:220%;text-align:center;\">Makeup Shades<\/h1>","35f205c8":"<p><span style='font-size: 16px;'>As the p value is non-significant, we fail to reject the null hypothesis and conclude that groups have equal variances.<\/span><\/p> ","30153eb0":"<p><span style='font-size: 16px;'>Some key points here:<\/span><\/p>  \n<p><span style='font-size: 16px;'>\u25b6\ufe0f Plotly provides awesome functionality for interactive plots: <b>hovering the markers<\/b> on the plot tell us the brand title, cluster and group the brand belongs to.<\/span><\/p>\n<p><span style='font-size: 16px;'>\u25b6\ufe0f Each shape of a marker represents the group of the brand.<\/span><\/p>\n<p><span style='font-size: 16px;'>\u25b6\ufe0f The brands were clustered regardless of the group they belong to, meaning <b>group label was given to the model<\/b>.<\/span><\/p>","c47d362b":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d There were some similar groups, what about them?<\/span><\/p>","fa69d95d":"<a id=\"subsection-22\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Add Group Definition<\/h3>","25af4956":"<p><span style='font-size: 16px;'> \ud83d\udccc Hue - the more yellow, red, green etc. the tone is.<\/span><\/p> ","f46f0502":"<p><span style='font-size: 16px;'> While performing the Shapiro-Wilks test on normality of the residuals, I discovered that the first assumption is violated (p-value is significant).<\/span><\/p> ","c282afbe":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d What about the other groups?<\/span><\/p>","fa05bdc4":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d Fenty Beauty and Make Up For Ever both were represented in separate groups - what about them?<\/span><\/p>","295ca049":"<a id=\"subsection-35\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Saturation<\/h3>","50c8f0b1":"<p><span style='font-size: 16px;'> \ud83d\udccc As the saturation decreases, the colors appear to be more washed-out or pale.<\/span><\/p> ","79bfab9c":"<p><span style='font-size: 16px;'>Same shades, sorted by hue:<\/span><\/p>","4d543211":"<div style=\"border-radius:7px;\n            border: 2px dashed #8e9aaf;\n            padding: 28px 18px 18px 18px;\">\n<p><span style='font-size: 16px;'> \ud83d\udccc The largest number of bestsellers belong to US Bestsellers and BIPOC-Brands with White Founders.<\/span><\/p> \n<p><span style='font-size: 16px;'> \ud83d\udccc These groups are more likely to cover a wider variety of tones.<\/span><\/p><\/div>","7e9418c2":"<p><span style='font-size: 16px;'>A Kruskal-Wallis Test is considered to be the non-parametric equivalent of the ANOVA.<\/span><\/p> \n<p><span style='font-size: 16px;'><b>Null hypothesis:<\/b> The median is equal across all groups.<\/span><\/p> \n<p><span style='font-size: 16px;'><b>Alternative hypothesis:<\/b> The median is not equal across all groups.<\/span><\/p> ","e2c719a2":"<p><span style='font-size: 16px;'> We can see that this is true if we plot these groups one beside another:<\/span><\/p> ","c8b4cdc8":"<p><span style='font-size: 16px;'>For clustering I create a new table with descriptive statistics for each continuous column and aggregate the values by brand.<br>\nAlso count number of bestsellers per brand.<\/span><\/p>  ","c5934d6c":"<p><span style='font-size: 16px;'>As the p-value is non significant only for <b>Fenty Beauty<\/b> and <b>Nigerian BS<\/b>, we fail to reject null hypothesis and conclude that this data is drawn from normal distribution.<\/span><\/p> \n<p><span style='font-size: 16px;'>For the other groups, we reject null hypothesis (data isn't drawn from normal distribution).<\/span><\/p> ","ec70be37":"<a id=\"section-3\"><\/a>\n<h1 style=\";font-size:220%;text-align:center;\">Exploratory Data Analysis<\/h1>","16bb5457":"<p><span style='font-size: 16px;'>Again, visually I notice several similar distributions: Japanese BS &amp Indian BS, BIPOC Brands with White Founders and US BS.<\/span><\/p> \n<p><span style='font-size: 16px;'>Again, I use t-test to check if means of the distributions are equal.<\/span><\/p> \n<p><span style='font-size: 16px;'>I delete few outliers for Indian Bestsellers and select equal number of records per each group.<\/span><\/p> \n<p><span style='font-size: 16px;'>T-test for saturation of Indian and Japanese brands products:<\/span><\/p> ","5d1132c5":"<p><span style='font-size: 16px;'>Descriptive stats per group:<\/span><\/p> ","dba14a9c":"<p><span style='font-size: 16px;'>For example, brands that belong to the group BIPOC-recommended Brands with BIPOC Founders (group #3) cover a much much wider range of tones than brands \/ products that belong to Japane Bestsellers (group #6).<\/span><\/p>","aa14591e":"<a id=\"subsection-46\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">3 Clusters in 3D<\/h3>","b9098f40":"<p><span style='font-size: 16px;'> \ud83d\udccc Ligthness and Value are highly correlated, so I'll presume that I can focus on lightness only in futher exploration.<\/span><\/p> ","25af40ad":"<a id=\"subsection-45\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Interactive KMeans Plot<\/h3>","03d6ec04":"<p><span style='font-size: 16px;'>Product by both Fenty Beauty and Make Up For Ever have 40 shades, represented in the dataset.<\/span><\/p>\n<p><span style='font-size: 16px;'>Aside from Maybelline, MAC and Est\u00e9e Lauder also have 42 shades represented. These are the top brands, and I want to compare their shades too.<\/span><\/p>","42b5bb59":"<p><span style='font-size: 16px;'>Same shades, sorted by saturation:<\/span><\/p>","a1609f8d":"<a id=\"subsection-36\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Parallel Plot<\/h3>","e856a0fb":"<a id=\"section-2\"><\/a>\n<h1 style=\";font-size:220%;text-align:center;\">Load & Preprocess<\/h1>","1b1f5624":"One possible explanation here can be that some shades appear to be visually similar, however, this brand has more represented shades in this dataset rather than its nearest neighbours.","6ac65460":"Note: I am not a professional data scientist and neither do I claim that received results are correct.\n\n<b>This is not a final version<\/b>, I will update it if I notice any mistakes.\nSo whether you liked it or hated - please, let me know, 'cause your feedback is extremely important to me!  (\u273f\u25d5\u203f\u25d5\u273f)","66b6ef03":"<p><span style='font-size: 16px;'> I want to combine the other groups (Fenty Beauty, Make Up For Ever, BIPOC-recommended Brands with White Founders, US Best Sellers) and check if there are any major differences.<\/span><\/p> ","33c307da":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d What brands are more popular?<\/span><\/p>","559ca5df":"<p><span style='font-size: 16px;'>Now I copy cluster data to the original DataFrame:<\/span><\/p>","310847c0":"<div style=\"border-radius:7px;\n            border: 2px dashed #8e9aaf;\n            padding: 28px 18px 18px 18px;\">\n<p><span style='font-size: 16px;'> \ud83d\udccc Japanese and BIPOC-recommended Brands with White Founders cater more towards yellow.<\/span><\/p>\n<p><span style='font-size: 16px;'> \ud83d\udccc Whereas tones by Make Up For Ever and Nigerian brands are more skewed towards red.<\/span><\/p>\n<p><span style='font-size: 16px;'> \ud83d\udccc Products of groups, that were similar in lightness, are not similar in hue.<\/span><\/p><\/div>","55c50cc1":"<a id=\"subsection-43\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Select k (num of clusters)<\/h3>","84b3828d":"<p><span style='font-size: 16px;'> \ud83d\udccc The p value obtained from the t-test is not significant (p > 0.05), and therefore, Indian bestsellers group is <b>not significantly different<\/b> than Japanese bestsellers group.<\/span><\/p> ","e5b7d674":"<div style=\"border-radius:7px;\n            border: 2px dashed #8e9aaf;\n            padding: 28px 18px 18px 18px;\">\n<p><span style='font-size: 16px;'> \ud83d\udccc Tones of Japanese and Indian brands products are similar in lightness.<\/span><\/p> \n<p><span style='font-size: 16px;'> \ud83d\udccc Japanese and Indian brands products cater towards lighter skin tones.<\/span><\/p> \n<p><span style='font-size: 16px;'> \ud83d\udccc Indian brands differ by only one darker tone (the outlier).<\/span><\/p> <\/div>","fd01ecde":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d Are there any differences between shades of Maybelline and L'Or\u00e9al products, sold in US and India?<\/span><\/p>","43b9e494":"<div style=\"border-radius:7px;\n            border: 2px dashed #8e9aaf;\n            padding: 28px 18px 18px 18px;\">\n<p><span style='font-size: 16px;'> \ud83d\udccc There are notably less bestsellers among Nigerian, Japanese, Indian brands.<\/span><\/p>\n<p><span style='font-size: 16px;'> \ud83d\udccc Fenty Beauty and Make Up For Ever are in separate groups with products that have 40 shades \/ colors each.<\/span><\/p>\n<p><span style='font-size: 16px;'> \ud83d\udccc Maybelline and L'Oreal appear in two groups.<\/span><\/p><\/div>","eb9fd6e9":"<p><span style='font-size: 16px;'>Clustering error may be caused by the PCA which was first performed and the explained variance is not large enough (only 74% for 3 components).<\/span><\/p>\n<p><span style='font-size: 16px;'>To eliminate the influence of the aforementioned factor, I apply k-means analysis on all scaled columns of the <a href=\"#subsection-41\">created table<\/a>.<\/span><\/p>\n","d7d6a26f":"<p><span style='font-size: 16px;'>Another way to visualize tones of bestsellers is parralel plot.<\/span><\/p> \n<p><span style='font-size: 16px;'>The more 'sparse' the group is --> the bigger range of tones is covered by the brand that belongs to it.<\/span><\/p> \n<p><span style='font-size: 16px;'>Before creating a parallel coordinates plot, data should be normalized to range  [0, 1].<\/span><\/p> ","f673cb19":"<a id=\"subsection-21\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Check Missing Values<\/h3>","20ec72bf":"<p><span style='font-size: 16px;'>T-test for saturation of US and BIPOC brands with White Founders products:<\/span><\/p> ","81b483c1":"And that's it! Thank you for reading till the end!","d75b6ced":"<p><span style='font-size: 16px;'>\nNote: as only one product of both Fenty Beauty and Make Up For Ever is represented in the dataset, these brands are excluded from the bar chart.<\/span><\/p> ","2cad0421":"<p><span style='font-size: 16px;'> \ud83d\udccc Lightness indicates whether a foundation line caters toward lighter or darker skin tones.<\/span><\/p> ","163d5e70":"<a id=\"subsection-42\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">PCA (2 components)<\/h3>","6c3de806":"<p><span style='font-size: 16px;'>\ud83d\udccc Some of clusters are very similar so 3 clusters really make sence now.<\/span><\/p>","17930af8":"<p><span style='font-size: 16px;'>... and also adding a shortened group description:<\/span><\/p> ","fc85c0cc":"Note: the clustering error may be also caused by the initial table with descriptive statistics of lightness, value, hue, saturation columns.\n\nAs lightness is highly correlated with value and saturation, clustering results will strongly depend on whether the brand caters towards darker or lighter skin tones.","31195f76":"<p><span style='font-size: 16px;'>Convert names of columns from MultiIndex to simple values:<\/span><\/p> ","77086d68":"<p><span style='font-size: 16px;'> The only thing that's left is to check the homogeneity of variances.<\/span><\/p> ","72af1de0":"<a id=\"subsection-33\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Lightness<\/h3>","b2b5f881":"<p><span style='font-size: 16px;'>The continuous columns are <code>lightness<\/code>, <code>hue<\/code>, <code>saturation<\/code>, <code>value<\/code>.<\/span><\/p> ","f2b3da72":"<p><span style='font-size: 16px;'>\ud83d\udccc Products sold in the US generally cover more shades and provide wider choice of tones.<\/span><\/p>\n<p><span style='font-size: 16px;'>\ud83d\udccc Maybelline products were clustered into different clustesters whereas L'Or\u00e9al products belong to the same cluster.<\/span><\/p>","27f0c4c9":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d Which shades are there in every cluster?<\/span><\/p>","63963493":"<div style=\"border-radius:7px; border: 2px dashed #8e9aaf; padding-top: 28px;padding: 28px 18px 18px 18px;\">\n    \n    \n<p><span style='font-size: 16px;'>\ud83d\udccc Cluster 0: Japanese and Indian brands.<\/span><\/p>\n<p><span style='font-size: 16px;'>\ud83d\udccc Cluster 1: Nigerian Best Sellers, BIPOC-recommended brands with BIPOC founders.<\/span><\/p>\n<p><span style='font-size: 16px;'>\ud83d\udccc Cluster 2: Brands that offer a widest range of tones.<\/span><\/p> \n   \n<\/div>","f35757c8":"<p><span style='font-size: 16px;'>According to the elbow method, k should be equal to 3.<br><br>However, I'd like to start with 7 clusters first.<\/span><\/p> ","73bcd06a":"<p><span style='font-size: 16px;'>... and median:<\/span><\/p> ","df57e7ee":"<p><span style='font-size: 16px;'>The following DataFrame shows that missing values in the columns \"H\", \"S\", \"V\" correspond to the brand \"Covergirl + Olay\" and have same index:<\/span><\/p> ","a7f286e0":"<p><span style='font-size: 16px;'>Distributions of these groups do not have equal variances, which violates one of the assumptions of t-test.<\/span><\/p>\n<p><span style='font-size: 16px;'>So I simply plot them side by side :)<\/span><\/p>","be17e1bc":"<p><span style='font-size: 16px;'>Here both saturation and value are set to 100%. On the last chart median is shifted by value of 13 so as to get a clearer visualization.<\/span><\/p> ","291f887e":"<p><span style='font-size: 16px;'>That's how brands were clustered:<\/span><\/p>","d7dbf49e":"<a id=\"subsection-34\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Hue<\/h3>","5802872e":"<a id=\"section-4\"><\/a>\n<h1 style=\";font-size:220%;text-align:center;\">Brands Clustering<\/h1>","51afa113":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d So what does change in hue exactly mean for each group?<\/span><\/p>","fb50bd39":"<p><span style='font-size: 16px;'><b>Null hypothesis<\/b>: samples have equal variances.<\/span><\/p> ","2ff7a113":"<div style=\"border-radius:7px; border: 2px dashed #8e9aaf; padding: 28px 18px 18px 18px;\">\n    \n<p><span style='font-size: 16px;'>For 3 clusters:<\/span><\/p>\n    \n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #70D4F3;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span> Brands that offer a widest range of tones.\n  <\/p>\n\n    \n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #673DB8;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span> Nigerian Best Sellers, BIPOC-recommended brands with BIPOC founders.\n  <\/p>\n    \n  <p style='font-size: 16px;'>\n    <span style=\"display: inline-block;\n                 vertical-align: center;\n                 margin: 0 10px 0 0;\n                 background-color: #F9519D;\n                 border-color: white;\n                 border-radius: 50%;\n                 border-width: 5px;\n                 height: 15px;\n                 width: 15px;\">\n      <\/span> Japanese and Indian brands.\n  <\/p>\n    \n   \n<\/div>","6b2aa612":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d Trim &amp Prissy - this brand was far away from other brands on the plot, why?<\/span><\/p>","afd4ac77":"<p><span style='font-size: 16px;'>Next step is decoding <code>group<\/code> column with it's definition:<\/span><\/p> ","7923f46b":"<a id=\"subsection-41\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">New Table<\/h3>","b9db09f8":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d How similar are Nigerian and BIPOC-recommended brands with BIPOC founders in terms of lightness?<\/span><\/p>","77553d56":"\n**Hue** represents a shift in the color.\n\n**Saturation** refers to how pure or intense a given hue is. 100% saturation means there\u2019s no addition of gray to the hue. The color is completely pure. At the other extreme a hue with 0% saturation appears as a medium gray. \n\n**Brightness** and Value are the same thing. They\u2019re the perception of an object\u2019s luminance. It\u2019s how our eyes see the intensity of light. Brightness or Value is perceived luminance.\n\n**Lightness** is the brightness relative to the brightness of a similarly illuminated white. It\u2019s perceived brightness or brightness with color information removed. [[source1](https:\/\/vanseodesign.com\/web-design\/hue-saturation-and-lightness\/), [source2](https:\/\/https:\/\/vanseodesign.com\/web-design\/color-luminance\/)]\n\n","fdb55eb6":"<div style=\"border-radius:7px;\n            border: 2px dashed #8e9aaf;\n            padding: 28px 18px 18px 18px;\">\n<p><span style='font-size: 16px;'> \ud83d\udccc Fenty Beauty, Make Up For Ever, BIPOC-recommended Brands with White Founders, US Best Sellers are similar in terms of lightness.<\/span><\/p>\n<p><span style='font-size: 16px;'> \ud83d\udccc Brands of these groups offer wide range of tones.<\/span><\/p><\/div>","d5117ce1":"# Table of Contents\n\n* [0. Domain Knowledge](#section-1)\n* [1. Load & Preprocess](#section-2)\n    - [Check Missing Values](#subsection-21)\n    - [Add Group Definition](#subsection-22)\n* [2. Exploratory Data Analysis](#section-3)\n    - [Pairlot of Continous Data](#subsection-31)\n    - [Count Bestsellers per Brand, Group](#subsection-32)\n    - [Lightness](#subsection-33)\n    - [Hue](#subsection-34)\n    - [Saturation](#subsection-35)\n    - [Compare by Group (Parallel Plot)](#subsection-36)\n* [3. Brands Clustering](#section-4)\n    - [New Table](#subsection-41)\n    - [PCA (2 components)](#subsection-42)\n    - [Select k (num of clusters)](#subsection-43)\n    - [KMeans for 7 Clusters](#subsection-44)\n    - [Interactive KMeans Plot](#subsection-45)\n    - [3 Clusters in 3D](#subsection-46)\n    - [Final Clustering](#subsection-47)\n* [4. Makeup Shades](#section-5)","0230ca26":"<div style=\"border-radius:7px;\n            border: 2px dashed #8e9aaf;\n            padding: 28px 18px 18px 18px;\">\n<p><span style='font-size: 16px;'> \ud83d\udccc Groups, that were similar by lightness, also similar by hue.<\/span><\/p>\n<p><span style='font-size: 16px;'> \ud83d\udccc No wonder why: saturation and lightness are highly correlated!*<\/span><\/p><\/div>","be8cf7f4":"<p><span style='font-size: 16px;'>Final version of the dataset:<\/span><\/p>","d4b3829e":"<p><span style='font-size: 16px;'>In context of lightness, Indian and Japanese brands were similar.<\/span><\/p>\n<p><span style='font-size: 16px;'>BIPOC Brands with BIPOC Founders and Nigerian brands had same mean.<\/span><\/p>","25973b15":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d Which groups do have the largest number of bestsellers?<\/span><\/p>","0857eab5":"<p><span style='font-size: 16px;'>Z denotes the cluster the corresponding record belongs to<\/span><\/p>","2359b46e":"<p><span style='font-size: 16px;'>And the fun part! I want to display makeup shades by cluster, group or brand.<\/span><\/p>\n<p><span style='font-size: 16px;'>Before that, one last step is to bin values of hue, saturation and lightness.<\/span><\/p>","bda8a044":"<p><span style='font-size: 16px;'>... min and max values ...<\/span><\/p> ","64bab444":"<p><span style='font-size: 16px;'>It is also important to note that some brands appear in two groups:<\/span><\/p>","49295bfc":"<p><span style='font-size: 16px;'>Principal component analysis for 2 principal components is needed to plot data on a 2-dimentional plot:<\/span><\/p>  ","82944d04":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d How lighter and darker tones are distributed<b> per group<\/b>?<\/span><\/p>","970545b6":"<p><span style='font-size: 16px;'>The p value obtained from Kruskal-Wallis test analysis is not significant (p > 0.05), and therefore, we conclude that there are no significant differences among groups.<\/span><\/p> ","b99b7c3c":"<p><span style='font-size: 16px;'>Some distributions seem visually similar to me. I want to compare them with t-test and ANOVA.<\/span><\/p> \n<p><span style='font-size: 16px;'>As both of these tests assume approximately normal distribution, I will use Shapiro-Wilks test. <\/span><\/p> \n<p><span style='font-size: 16px;'><b>Null hypothesis:<\/b> data is drawn from normal distribution. <\/span><\/p> ","1eef127f":"<a id=\"section-1\"><\/a>\n<h1 style=\";font-size:220%;text-align:center;\">Domain Knowledge<\/h1>","2bb08f41":"<p><span style='font-size: 16px;'>That is how PCA-processed data looks now:<\/span><\/p>  ","34b94380":"<p><span style='font-size: 16px;'>Radar chart helps to explore standart deviation of hue per group...<\/span><\/p> ","111564a8":"<div style=\"border-radius:7px;\n            border: 2px dashed #8e9aaf;\n            padding: 28px 18px 18px 18px;\">\n<p><span style='font-size: 16px;'> \ud83d\udccc Mean doesn't differ much, but variance does:<br><ul style='font-size: 16px;'>\n  <li>Products by both Nigerian and BIPOC-recommended brands with BIPOC founders cater towards darker skin tones.<\/li>\n  <li>BIPOC-recommended brands with BIPOC founders offer the widest variety of tones - from darkest to lightest.<\/li>\n<\/ul> <\/span><\/p> <\/div>","65541776":"<a id=\"subsection-31\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Pairlot of Continous Data<\/h3>","0ce7e66f":"<p><span style='font-size: 16px;'>Distributions of hue values are not-so-easy-to-interpret for me and I want to see what change in hue exactly means.<br><br>So I select mean, min, max, standart deviation of hue regarding the group:<\/span><\/p> ","25632014":"<p><span style='font-size: 16px;'>Before proceeding, I need to rename these brands according to the group:<\/span><\/p>","c1b5ac2c":"<p><span style='font-size: 16px;'>This brand is more 'correctly' (subjectively) classified in case of 3 clusters.<br><br>In case of clustering with k = 7 these are all members of the same cluster which the aforementioned brand belongs to:<\/span><\/p>","4d909ad1":"<a id=\"subsection-47\"><\/a>\n<h3 style=\"font-size:180%;text-align:center;\">Final Clustering<\/h3>","05e18dd0":"<p><span style='font-size: 16px;'>Why select k, when we can make clusters for k = 3, 4, ..., 10 at once!<\/span><\/p>","6c12b108":"<p><span style='font-size: 16px;'>To compare the means of more than 2 groups, ANOVA is used.<\/span><\/p> \n<span style='font-size: 16px;'>Assumptions: <br><ul>\n  <li>Residuals (experimental error) are approximately normally distributed.<\/li>\n  <li>Homoscedasticity or Homogeneity of variances (variances are equal between groups).<\/li>\n    <li>Observations are sampled independently from each other (no relation in observations between the groups and within the groups).<\/li>\n  <li>The dependent variable should be continuous. [<a href=\"https:\/\/www.reneshbedre.com\/blog\/anova.html\">2<\/a>]<\/li>\n<\/ul><\/span><\/p>","6b914932":"<p><span style='font-size: 16px;'> \ud83d\udccc Perform a k-means cluster analysis on brands <b>regardless of the group<\/b> that they belong to.<\/span><\/p> ","0a6c029b":"<p style=\"text-align: center;\"><span style='font-size: 18px;'>\ud83d\udd0d How similar are Indian and Japanese bestsellers in terms of lightness?<\/span><\/p>","c9261ba5":"<p><span style='font-size: 16px;'>And the result is...<\/span><\/p>  ","4cbcdaa8":"<p><span style='font-size: 16px;'>\ud83d\udccc Fenty certainly does some decent job in representing a wide range of skin tones.<\/span><\/p>"}}