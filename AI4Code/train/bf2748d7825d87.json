{"cell_type":{"20cf86f5":"code","91587ae7":"code","9132edea":"code","48b03ca6":"code","d5b3382d":"code","e718a188":"code","2c6fb342":"code","6f5e2bad":"code","54796218":"code","2be932b0":"code","3bd7a79e":"code","358c965b":"code","e75f3e95":"code","ad205334":"markdown","dd7099c9":"markdown","97354a8d":"markdown","fadc12d6":"markdown","ad76bac3":"markdown","87ed1252":"markdown"},"source":{"20cf86f5":"import numpy as np\nimport pandas as pd\nimport seaborn as sns","91587ae7":"#PIMA diabetes dataset\n#column_names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndata = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndata.head()","9132edea":"sns.countplot(data['Outcome'])","48b03ca6":"# class count\nclass_count_0, class_count_1 = data['Outcome'].value_counts()\n\n# Separate class\nclass_0 = data[data['Outcome'] == 0]\nclass_1 = data[data['Outcome'] == 1]\n\n# print the shape of the class\nprint('class 0 : ', class_0.shape)\nprint('class 1 : ', class_1.shape)","d5b3382d":"#Random Under-Smapling\nclass_0_under = class_0.sample(class_count_1)\n\n# print the shape of the class\nprint(\"class_0_under : \",class_0_under.shape)\nprint('class 1 : ', class_1.shape)","e718a188":"#Random Over-Smapling\nclass_1_over = class_1.sample(class_count_0,replace=True)\n\n# print the shape of the class\nprint('class 0 : ', class_0.shape)\nprint(\"class_1_over : \",class_1_over.shape)","2c6fb342":"type(class_0_under)","6f5e2bad":"#import imblearn","54796218":"from imblearn.under_sampling import RandomUnderSampler\nrus = RandomUnderSampler(random_state=10)\n\nX = data.drop(['Outcome'],axis=1)\ny = data[['Outcome']]\n\nX_rus, y_rus = rus.fit_resample(X,y)\n\n# plot\nsns.countplot(y_rus['Outcome'])","2be932b0":"sns.countplot(y['Outcome'])","3bd7a79e":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=10)\n\nX = data.drop(['Outcome'],axis=1)\ny = data[['Outcome']]\n\nX_ros, y_ros = ros.fit_resample(X,y)\n\n# plot\nsns.countplot(y_ros['Outcome'])","358c965b":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE(random_state=10)\n\nX = data.drop(['Outcome'],axis=1)\ny = data[['Outcome']]\n\nX_smote, y_smote = smote.fit_resample(X,y)\n\n# plot\nsns.countplot(y_smote['Outcome'])","e75f3e95":"from imblearn.under_sampling import NearMiss\nnm = NearMiss()\n\nX = data.drop(['Outcome'],axis=1)\ny = data[['Outcome']]\n\nX_nm, y_nm = nm.fit_resample(X,y)\n\n# plot\nsns.countplot(y_nm['Outcome'])","ad205334":"# Balance data with the imbalanced-learn python module\nLet\u2019s apply some of these resampling techniques, using the Python library imbalanced-learn.\nIt is compatible with scikit-learn and is part of scikit-learn-contrib projects.\n\nInstall imblearn model\n\n1. Command : pip install -U imbalanced-learn\n\n2. Command : conda install -c conda-forge imbalanced-learn (I have used this.)","dd7099c9":"# Techniques to handle imbalance data","97354a8d":"# NearMiss\nNearMiss is an under-sampling technique. Instead of resampling the Minority class, using a distance, this will make the majority class equal to the minority class.","fadc12d6":"# Techniques\n1. Random Under-Sampling\n2. Random Over-Sampling","ad76bac3":"*RandomUnderSampler* is a fast and easy way to balance the data by randomly selecting a subset of data for the targeted classes. Under-sample the majority class(es) by randomly picking samples with or without replacement.\n","87ed1252":"# Synthetic Minority Oversampling Technique (SMOTE)\nThis technique generates synthetic data for the minority class.\n\nSMOTE (Synthetic Minority Oversampling Technique) works by randomly picking a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors."}}