{"cell_type":{"6254c650":"code","d67e160b":"code","4b45bde0":"code","ed5aebb4":"code","e3caef40":"code","31a5c894":"code","2bfb8a1d":"code","6fdf6978":"code","f825a6f1":"code","3d0b5b08":"code","d23612de":"code","190979a4":"code","dba19ed8":"code","7212d5e3":"code","172bb87a":"code","cde2b62e":"code","180c1393":"code","a3e76efd":"code","ad337b34":"code","16d02d52":"code","9b8e9a1f":"code","17c76f54":"code","441126f1":"code","7d3bfad6":"code","00ffff1f":"code","615d33b3":"code","0de34771":"code","0c03198e":"code","83919f27":"code","b90c308d":"code","0343a60d":"code","c7262928":"code","43396d19":"code","6d1dfbd5":"code","d2fa669b":"code","70ff121f":"code","0724ece9":"code","09c1687b":"code","e39d8b0d":"code","af4066cd":"code","e771b5e8":"code","a93a5527":"code","43e7556d":"code","c5c643c0":"code","deac32e6":"code","975b3115":"code","9a60837d":"code","1f650d6c":"code","d04b69a3":"code","09e3b016":"code","bfc5f321":"code","a24bb25a":"code","24adfdd5":"code","391e1035":"code","775ff80f":"code","a62b4b0b":"code","038090d4":"code","2ce15416":"code","f1ddf620":"code","df1c1453":"code","e516921f":"code","be3c6561":"code","6a87901a":"code","a82d0e31":"code","7b1f0b0e":"code","026f59de":"code","80e2bb95":"code","a524a0b2":"code","3d501b8d":"code","72660900":"code","e76d2bb1":"code","63cd1e5f":"code","6e00033b":"code","0fc7c300":"code","834aac88":"code","bb5fd257":"code","63e86f52":"code","3ab81b1b":"code","65e93a04":"code","7896fcf6":"code","433be195":"code","55075804":"code","afd1438b":"code","c4433f9d":"code","eba55a7d":"code","060fc316":"code","461decd4":"code","6cf1a061":"code","c30c9cad":"code","72a1d604":"code","1e33cf17":"code","26d06b0c":"code","f4c41851":"code","6b4fe613":"code","f40bb982":"code","1a07b5ce":"code","3b9267bf":"code","bf563786":"code","23e0a007":"code","0507318c":"code","a31a20b2":"code","de2d0ad8":"code","48a2f1ed":"code","dd7fa667":"code","b5038e66":"code","842ad667":"code","160aef20":"code","dda59016":"code","5dfd2378":"code","15185d40":"code","09039934":"code","c6df94d0":"code","2875680e":"code","9a56e6ab":"code","a49a44dd":"code","51ceef22":"code","0d8ef726":"code","92ef1295":"code","bb382a64":"markdown","e6a467cc":"markdown","69976d5b":"markdown","5e671aef":"markdown","ba7b8605":"markdown","b17facd8":"markdown","e32a3344":"markdown","17cb19d6":"markdown","7cd83f0b":"markdown","db930811":"markdown","2c3a6ab3":"markdown","3242b11b":"markdown","49e63080":"markdown","af1f951f":"markdown","9ba62bec":"markdown","d72ba96a":"markdown","50da3d53":"markdown","4fc6b690":"markdown","8d985ecb":"markdown","e48f40ed":"markdown","e2f7019a":"markdown","ab8f53f1":"markdown","7ea71ea6":"markdown","9f607d99":"markdown","b139c463":"markdown","8e4c60d8":"markdown","b4f8ffbc":"markdown","a9c2a47b":"markdown","16190e6a":"markdown","1b520a2f":"markdown"},"source":{"6254c650":"# A high-level plotting API for the PyData ecosystem built on HoloViews.\n! pip install hvplot","d67e160b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport hvplot.pandas\nfrom scipy import stats\nimport missingno as msno\n\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.metrics import( accuracy_score,\n                           confusion_matrix,\n                           classification_report,\n                          roc_auc_score,\n                          roc_curve,\n                          auc,\n                          plot_confusion_matrix,\n                          plot_roc_curve)\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import AUC\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.style.use(\"fivethirtyeight\")\nsns.set_style('whitegrid')\n%matplotlib inline\n\npd.set_option ('display.float','{:0.2f}'.format)\npd.set_option('display.max_columns',50)\npd.set_option('display.max_rows',50)","4b45bde0":"data= pd.read_csv('..\/input\/lending-club-dataset\/lending_club_loan_two.csv')\ndata.head()","ed5aebb4":"data.info()","e3caef40":"data.isnull().sum()","31a5c894":"data.describe()","2bfb8a1d":"# Displaying Missing Data\nmsno.bar(data)","6fdf6978":"msno.matrix(data)","f825a6f1":"data['loan_status'].value_counts().hvplot.bar()","3d0b5b08":"plt.figure(figsize=(12,8))\nsns.heatmap(data.corr(),annot=True,cmap='viridis')","d23612de":"data.hvplot.hist(y='installment', by='loan_status',\n                 subplots=False, width=600, height=300, bins=50, alpha=0.4)\n","190979a4":"data.hvplot.hist(y='loan_amnt', by='loan_status',\n                 subplots=False, width=600, height=300, bins=30, alpha=0.4)\n","dba19ed8":"data.hvplot.box(y='loan_amnt', subplots=True, by='loan_status', width=600, height=300)","7212d5e3":"data.hvplot.box(y='installment',subplot=True, by='loan_status',width=600, height=300)","172bb87a":"data.groupby(by='loan_status')['loan_amnt'].describe()","cde2b62e":"data['grade'].unique()","180c1393":"data['sub_grade'].unique()","a3e76efd":"data['grade'].value_counts().hvplot.bar()","ad337b34":"data['sub_grade'].value_counts().hvplot.bar()","16d02d52":"plt.figure(figsize=(15,10))\ngrade=sorted(data.grade.unique().tolist())\nsns.countplot(x='grade',data=data,hue='loan_status',order =grade)","9b8e9a1f":"plt.figure(figsize=(15,10))\nsub_grade=sorted(data.sub_grade.unique().tolist())\nsns.countplot(x='sub_grade',data=data,hue='loan_status',order =sub_grade)","17c76f54":"df = data[(data.grade == 'F') | (data.grade == 'G')]\n\nplt.figure(figsize=(15, 10))\n\nplt.subplot(2, 2, 1)\ngrade = sorted(df.grade.unique().tolist())\nsns.countplot(x='grade', data=df, hue='loan_status', order=grade)\n\nplt.subplot(2, 2, 2)\nsub_grade = sorted(df.sub_grade.unique().tolist())\nsns.countplot(x='sub_grade', data=df, hue='loan_status', order=sub_grade)\n","441126f1":"data.home_ownership.value_counts().hvplot.bar()","7d3bfad6":"fully_paid = data.loc[data['loan_status']=='Fully Paid', 'home_ownership'].value_counts().hvplot.bar() \ncharged_off = data.loc[data['loan_status']=='Charged Off', 'home_ownership'].value_counts().hvplot.bar()\nfully_paid * charged_off","00ffff1f":"data.home_ownership.value_counts()","615d33b3":"plt.figure(figsize=(15,20))\n\nplt.subplot(4,2,1)\nsns.countplot(x='term',data=data,hue='loan_status')\n\nplt.subplot(4,2,2)\nsns.countplot(x='home_ownership',data=data,hue='loan_status')\n\nplt.subplot(4,2,3)\nsns.countplot(x='verification_status', data=data, hue='loan_status')\n\nplt.subplot(4,2,4)\ng=sns.countplot(x='purpose', data=data, hue='loan_status')\ng.set_xticklabels(g.get_xticklabels(),rotation=90);\n","0de34771":"data.hvplot.hist(y='int_rate', by='loan_status', alpha=0.3)","0c03198e":"data.hvplot.hist(y='annual_inc', by='loan_status', bins=50, alpha=0.3)","83919f27":"data[data.annual_inc >= 1000000].hvplot.hist(y='annual_inc', by='loan_status', bins=35, alpha=0.3)","b90c308d":"data[data.annual_inc >= 1000000].shape","0343a60d":"data['emp_title'].isnull().sum()","c7262928":"# Converting emp_title to lowercase\n\ndata['emp_title']=data['emp_title'].str.lower()\ndata['emp_title'].head()","43396d19":"data.emp_title.value_counts()[:40]","6d1dfbd5":"def manager(string):\n    if type(string) is str:\n        return 'manager' if 'manager' in string else string\n\ndef president(string):\n    if type(string) is str:\n        return 'president' if 'president' in string else string\n    \ndef nurse(string):\n    if type(string) is str:\n        return 'nurse' if 'nurse' in string else string\n    \ndef driver(string):\n    if type(string) is str:\n        return 'driver' if 'driver' in string else string\n    \ndef assistant(string):\n    if type(string) is str:\n        return 'assistant' if 'assistant' in string else string\n\ndef engineer(string):\n    if type(string) is str:\n        return 'engineer' if 'engineer' in string else string    \n\nfunctions = [manager, president, nurse, driver, assistant, engineer]\nfor func in functions:\n    data['emp_title'] = data.emp_title.apply(func)\n","d2fa669b":"plt.figure(figsize=(15, 12))\n\nplt.subplot(2, 2, 1)\norder = ['< 1 year', '1 year', '2 years', '3 years', '4 years', '5 years', \n          '6 years', '7 years', '8 years', '9 years', '10+ years',]\ng = sns.countplot(x='emp_length', data=data, hue='loan_status', order=order)\ng.set_xticklabels(g.get_xticklabels(), rotation=90);\n\nplt.subplot(2, 2, 2)\nplt.barh(data.emp_title.value_counts()[:30].index, data.emp_title.value_counts()[:30])\nplt.title(\"The most 30 jobs title afforded a loan\")\nplt.tight_layout()","70ff121f":"fully_paid = data.loc[data['loan_status']=='Fully Paid', 'issue_d'].value_counts().hvplot.hist(bins=35) \ncharged_off = data.loc[data['loan_status']=='Charged Off', 'issue_d'].value_counts().hvplot.hist(bins=35)\nfully_paid * charged_off","0724ece9":"fully_paid = data.loc[data['loan_status']=='Fully Paid', 'earliest_cr_line'].value_counts().hvplot.hist(bins=35) \ncharged_off = data.loc[data['loan_status']=='Charged Off', 'earliest_cr_line'].value_counts().hvplot.hist(bins=35)\nfully_paid * charged_off","09c1687b":"plt.figure(figsize=(15, 12))\n\nplt.subplot(2, 2, 1)\ng = data.issue_d.value_counts().sort_index().plot()\ng.set_xticklabels(g.get_xticklabels(), rotation=45);\n\nplt.subplot(2, 2, 2)\ng = data.earliest_cr_line.value_counts().sort_index().plot()\ng.set_xticklabels(g.get_xticklabels(), rotation=45);","e39d8b0d":"data.title.isnull().sum()","af4066cd":"data['title'] = data.title.str.lower()\ndata['title'].head()","e771b5e8":"data.title.value_counts()[:30]","a93a5527":"data.dti.value_counts()","43e7556d":"data[data.open_acc > 40].shape","c5c643c0":"data[data.total_acc > 80].shape","deac32e6":"data[data.revol_bal < 10000].shape","975b3115":"data[data.revol_util > 200]","9a60837d":"data.hvplot.hist(y='open_acc', by='loan_status', bins=35, alpha=0.3)","1f650d6c":"data.hvplot.hist(y='revol_bal', by='loan_status', bins=35, alpha=0.3)","d04b69a3":"data.hvplot.hist(y='revol_util', by='loan_status', bins=35, alpha=0.3)","09e3b016":"data.hvplot.hist(y='total_acc', by='loan_status', bins=35, alpha=0.3)","bfc5f321":"fully_paid = data.loc[data['loan_status']=='Fully Paid', 'pub_rec'].value_counts().hvplot.bar() \ncharged_off = data.loc[data['loan_status']=='Charged Off', 'pub_rec'].value_counts().hvplot.bar()\nfully_paid * charged_off","a24bb25a":"fully_paid = data.loc[data['loan_status']=='Fully Paid', 'initial_list_status'].value_counts().hvplot.bar() \ncharged_off = data.loc[data['loan_status']=='Charged Off', 'initial_list_status'].value_counts().hvplot.bar()\nfully_paid * charged_off","24adfdd5":"fully_paid = data.loc[data['loan_status']=='Fully Paid', 'application_type'].value_counts().hvplot.bar() \ncharged_off = data.loc[data['loan_status']=='Charged Off', 'application_type'].value_counts().hvplot.bar()\nfully_paid * charged_off","391e1035":"data.mort_acc.value_counts()[:30]","775ff80f":"fully_paid = data.loc[data['loan_status']=='Fully Paid', 'pub_rec_bankruptcies'].value_counts().hvplot.bar() \ncharged_off = data.loc[data['loan_status']=='Charged Off', 'pub_rec_bankruptcies'].value_counts().hvplot.bar()\nfully_paid * charged_off","a62b4b0b":"def pub_rec(number):\n    if number==0.0:\n        return 0\n    else:\n        return number\n\ndef mort_acc(number):\n    if number ==0.0:\n        return 0\n    elif number >=1.0:\n            return 1\n    else:\n            return number\n        \ndef pub_rec_bankruptcies(number):\n    if number == 0.0:\n        return 0\n    elif number >= 1.0:\n        return 1\n    else:\n        return number\n        \n        ","038090d4":"data['pub_rec'] = data.pub_rec.apply(pub_rec)\ndata['mort_acc'] = data.mort_acc.apply(mort_acc)\ndata['pub_rec_bankruptcies'] = data.pub_rec_bankruptcies.apply(pub_rec_bankruptcies)","2ce15416":"plt.figure(figsize=(12, 30))\n\nplt.subplot(6, 2, 1)\nsns.countplot(x='pub_rec', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 2)\nsns.countplot(x='initial_list_status', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 3)\nsns.countplot(x='application_type', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 4)\nsns.countplot(x='mort_acc', data=data, hue='loan_status')\n\nplt.subplot(6, 2, 5)\nsns.countplot(x='pub_rec_bankruptcies', data=data, hue='loan_status')","f1ddf620":"data['loan_status'] = data.loan_status.map({'Fully Paid':0, 'Charged Off':1})","df1c1453":"data.corr()['loan_status'].drop('loan_status').sort_values().hvplot.barh()","e516921f":"print(' The Lenght of the Data:',data.shape)","be3c6561":"for column in data.columns:\n    if data[column].isnull().sum() !=0:\n        missing=data[column].isnull().sum()\n        portion=(missing\/data.shape[0])*100\n        print(f\" '{column}',: Number of Missing_values '{missing}'== '{portion:.3f}%'\")","6a87901a":"# Dropping title column\ndata.drop('emp_title',axis=1,inplace=True)","a82d0e31":"data.emp_length.unique()","7b1f0b0e":"for year in data.emp_length.unique():\n    print(f\"{year} years in this position:\")\n    print(f\"{data[data.emp_length == year].loan_status.value_counts(normalize=True)}\")\n    print('==========================================')\n","026f59de":"data.drop('emp_length',axis=1,inplace= True)","80e2bb95":"data.title.value_counts()[:10]","a524a0b2":"data.purpose.value_counts()[:10]","3d501b8d":"# Dropping the title column\ndata.drop('title',axis=1,inplace= True)","72660900":"data.mort_acc.value_counts()","e76d2bb1":"data.mort_acc.isna().sum()","63cd1e5f":"data.corr()['mort_acc'].drop('mort_acc').sort_values().hvplot.barh()","6e00033b":"total_acc_avg=data.groupby(by='total_acc').mean().mort_acc","0fc7c300":"def fill_mort_acc(total_acc,mort_acc):\n    if np.isnan(mort_acc):\n        return total_acc_avg[total_acc].round()\n    else:\n        return mort_acc\n\n","834aac88":"data['mort_acc'] = data.apply(lambda x: fill_mort_acc(x['total_acc'], x['mort_acc']), axis=1)","bb5fd257":"# dropping the remaining null values\ndata.dropna(inplace= True)","63e86f52":"data.isnull().sum()","3ab81b1b":"print([column for column in data.columns if data[column].dtype==object] )","65e93a04":"data['term'].unique()","7896fcf6":"term_values = {' 36 months': 36, ' 60 months': 60}\ndata['term'] = data.term.map(term_values)","433be195":"data.term.unique()","55075804":"data.drop('grade',axis=1,inplace=True)","afd1438b":"data.shape","c4433f9d":"dummies = ['sub_grade', 'verification_status', 'purpose', 'initial_list_status', \n           'application_type', 'home_ownership']\ndata=pd.get_dummies(data, columns=dummies, drop_first= True)","eba55a7d":"data.head()","060fc316":"data.address.head()","461decd4":"data['zipcode']=data.address.apply(lambda x: x[-5:] )\ndata['zipcode'].head()","6cf1a061":"data=pd.get_dummies(data, columns=['zipcode'], drop_first=True)","c30c9cad":"data.head()","72a1d604":"data.drop('address', axis=1,inplace= True)","1e33cf17":"# dropping issue_d column\ndata.drop('issue_d',axis=1,inplace =True)","26d06b0c":"data.earliest_cr_line.nunique()","f4c41851":"data['earliest_cr_line'] = data.earliest_cr_line.str.split('-', expand=True)[1]","6b4fe613":"data.earliest_cr_line.value_counts()","f40bb982":"\"\"\"print(f\"Data shape: {data.shape}\")\n\n#  Remove duplicate Features\ndata = data.T.drop_duplicates()\ndata = data.T\n\n# # Remove Duplicate Rows\ndata.drop_duplicates(inplace=True)\n\nprint(f\"Data shape: {data.shape}\")\"\"\"","1a07b5ce":"positive_values=data.loan_status.value_counts()[0]\/data.shape[0]\nnegative_values=data.loan_status.value_counts()[1]\/data.shape[1]\n\nprint(\" Postive Values\",positive_values)\nprint(\" Negative values\",negative_values)","3b9267bf":"X=data.drop('loan_status', axis=1)\ny=data.loan_status","bf563786":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n","23e0a007":"scaler= MinMaxScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.fit_transform(X_test)","0507318c":"X_train","a31a20b2":"X_train= np.array(X_train).astype(np.float32)\nX_test=np.array(X_test).astype(np.float32)\ny_train=np.array(y_train).astype(np.float32)\ny_test=np.array(y_test).astype(np.float32)","de2d0ad8":"X_train","48a2f1ed":"def print_score(true, pred, train=True):\n    if train:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n        \n    elif train==False:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n","dd7fa667":"def evaluate_nn(true, pred ,train=True):\n    if train:\n        clf_report=pd.DataFrame(classification_report(true,pred, output_dict=True))\n        \n        print(\" Train Result: \\n--------------------------------------------------------------\")\n        print(f\"Accuracy: {accuracy_score(true,pred)*100:.2f}%\")\n        print(\"-------------------------------------------------------------------------------\")\n        print(f\"Classification Report:\\n { clf_report}\") \n        print(\"-------------------------------------------------------------------------------\")\n        print(f\" Confusion Matrix:\\n {confusion_matrix(true,pred)}\\n\")\n        \n    elif train==False:\n        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix:\\n {confusion_matrix(true, pred)}\\n\")\n        \ndef plot_learning_evolution(r):\n    plt.figure(figsize=(12,8))\n    plt.subplot(2,2,1)\n    plt.plot(r.history['loss'],label=\"Loss\")\n    plt.plot(r.history['val_loss'],label='Val_Loss')\n    plt.title(\" Loss Evaluation during Training\")\n    plt.legend()\n    \n    plt.subplot(2, 2, 2)\n    plt.plot(r.history['AUC'], label='AUC')\n    plt.plot(r.history['val_AUC'], label='val_AUC')\n    plt.title('AUC score evolution during trainig')\n    plt.legend();\n    \ndef nn_model(num_columns, num_labels,hidden_units,dropout_rates,learning_rate):\n    inp= tf.keras.layers.Input(shape=(num_columns,))\n    x=BatchNormalization()(inp)\n    x=Dropout(dropout_rates[0])(x)\n    \n    for i in range (len(hidden_units)):\n        x= Dense(hidden_units[i],activation='relu')(x)\n        x=BatchNormalization()(x)\n        x=Dropout(dropout_rates[i+1])(x)\n        x = Dense(num_labels, activation='sigmoid')(x)\n  \n    model = Model(inputs=inp, outputs=x)\n    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=[AUC(name='AUC')])\n    return model\n","b5038e66":"num_columns = X_train.shape[1]\nnum_labels = 1\nhidden_units = [150, 150, 150]\ndropout_rates = [0.1, 0, 0.1, 0]\nlearning_rate = 1e-3\n\n\n\nmodel = nn_model(\n    num_columns=num_columns, \n    num_labels=num_labels,\n    hidden_units=hidden_units,\n    dropout_rates=dropout_rates,\n    learning_rate=learning_rate\n)\nr = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=5,\n    batch_size=32\n)\n","842ad667":"plot_learning_evolution(r)","160aef20":"y_train_pred = model.predict(X_train)\nevaluate_nn(y_train, y_train_pred.round(), train=True)","dda59016":"y_test_pred = model.predict(X_test)\nevaluate_nn(y_test, y_test_pred.round(), train=False)","5dfd2378":"scores_dict = {\n    'ANNs': {\n        'Train': roc_auc_score(y_train, model.predict(X_train)),\n        'Test': roc_auc_score(y_test, model.predict(X_test)),\n    },\n}\n","15185d40":"# Hyperparameter Tunning\n\"\"\"param_grid = dict(\n     n_estimators=stats.randint(10, 500),\n     max_depth=stats.randint(1, 10),\n     learning_rate=stats.uniform(0, 1)\n )\n\nxgb_clf = XGBClassifier()\nxgb_cv = RandomizedSearchCV(\n     xgb_clf, param_grid, cv=3, n_iter=60, \n     scoring='roc_auc', n_jobs=-1, verbose=1\n )\nxgb_cv.fit(X_train, y_train)\nbest_params = xgb_cv.best_params_\nbest_params['tree_method'] = 'gpu_hist'\nbest_params = {'n_estimators': 50, 'tree_method': 'gpu_hist'}\nprint(f\"Best Parameters: {best_params}\")\n\nxgb_clf = XGBClassifier(**best_params)\nxgb_clf.fit(X_train, y_train)\n\ny_train_pred = xgb_clf.predict(X_train)\ny_test_pred = xgb_clf.predict(X_test)\n\nprint_score(y_train, y_train_pred, train=True)\nprint_score(y_test, y_test_pred, train=False)\"\"\"\n","09039934":"xgb_clf = XGBClassifier()\nxgb_clf.fit(X_train, y_train)\ny_train_pred = xgb_clf.predict(X_train)\ny_test_pred = xgb_clf.predict(X_test)\n\nprint_score(y_train, y_train_pred, train=True)\nprint_score(y_test, y_test_pred, train=False)","c6df94d0":"disp = plot_confusion_matrix(xgb_clf, X_test, y_test, \n                             cmap='Blues', values_format='d', \n                             display_labels=['Fully-Paid', 'Default'])\n\ndisp = plot_roc_curve(xgb_clf, X_test, y_test)","2875680e":"scores_dict['XGBoost'] = {\n        'Train': roc_auc_score(y_train, xgb_clf.predict(X_train)),\n        'Test': roc_auc_score(y_test, xgb_clf.predict(X_test)),\n    }\n","9a56e6ab":"# param_grid = dict(\n#     n_estimators=stats.randint(100, 1500),\n#     max_depth=stats.randint(10, 100),\n#     min_samples_split=stats.randint(1, 10),\n#     min_samples_leaf=stats.randint(1, 10),\n# )\n\nrf_clf = RandomForestClassifier(n_estimators=100)\n# rf_cv = RandomizedSearchCV(\n#     rf_clf, param_grid, cv=3, n_iter=60, \n#     scoring='roc_auc', n_jobs=-1, verbose=1\n# )\n# rf_cv.fit(X_train, y_train)\n# best_params = rf_cv.best_params_\n# print(f\"Best Parameters: {best_params}\")\n# rf_clf = RandomForestClassifier(**best_params)\nrf_clf.fit(X_train, y_train)\n\ny_train_pred = rf_clf.predict(X_train)\ny_test_pred = rf_clf.predict(X_test)\n\nprint_score(y_train, y_train_pred, train=True)\nprint_score(y_test, y_test_pred, train=False)","a49a44dd":"disp = plot_confusion_matrix(rf_clf, X_test, y_test, \n                             cmap='Blues', values_format='d', \n                             display_labels=['Fully-Paid', 'Default'])\n\ndisp = plot_roc_curve(xgb_clf, X_test, y_test)\nplot_roc_curve(rf_clf, X_test, y_test, ax=disp.ax_)\n","51ceef22":"scores_dict['Random Forest'] = {\n        'Train': roc_auc_score(y_train, rf_clf.predict(X_train)),\n        'Test': roc_auc_score(y_test, rf_clf.predict(X_test)),\n    }\n","0d8ef726":"ml_models = {\n    'Random Forest': rf_clf, \n    'XGBoost': xgb_clf, \n    'ANNs': model\n}\n\nfor model in ml_models:\n    print(f\"{model.upper():{30}} roc_auc_score: {roc_auc_score(y_test, ml_models[model].predict(X_test)):.3f}\")\n","92ef1295":"scores_df = pd.DataFrame(scores_dict)\nscores_df.hvplot.barh()\n","bb382a64":"Looks like the total_acc feature correlates with the mort_acc , this makes sense! Let's try this fillna() approach. We will group the dataframe by the total_acc and calculate the mean value for the mort_acc per total_acc entry. To get the result below:","e6a467cc":"**Goals**\n\n---\n* Remove or fill any missing data.\n* Remove unnecessary or repetitive features.\n* Convert categorical string features to dummy variables.\n---","69976d5b":"## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:220%; text-align:center; border-radius: 12px 50px;\">Loan \ud83d\udcb0\ud83d\udcb0Defaulters Prediction<\/p>","5e671aef":"## 4. Model Building","ba7b8605":"Let's have a Look into Data\n\n![Image](https:\/\/media0.giphy.com\/media\/26n79n7q1wMz6pjLq\/giphy.gif)","b17facd8":"**Observation:** It looks like F and G subgrades don't get paid back that often. Isloate those and recreate the countplot just for those subgrades.\n\n  ","e32a3344":"### Categorical Variables and Dummy Variables","17cb19d6":"# \ud83d\udcddIntroduction\nLendingClub is a US peer-to-peer lending company, headquartered in San Francisco, California. It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. LendingClub is the world's largest peer-to-peer lending platform.\n\nSolving this case study will give us an idea about how real business problems are solved using EDA and Machine Learning. In this case study, we will also develop a basic understanding of risk analytics in banking and financial services and understand how data is used to minimise the risk of losing money while lending to customers.","7cd83f0b":"**Observation:-**\n* The Loan with hight Interest rate are more likely to be unpaid.\n* Only 75 borrower's having an annual income more than 1 Million","db930811":"### Splitting Data into train & test","2c3a6ab3":"**Observation:**\n* It seems that the smaller the dti the more likely that the loan will not be paid.\n* Only 217 borrower have more than 40 open credit lines.\n* Only 266 borrower have more than 80 credit line in the borrower credit file.","3242b11b":"**Observation:**\n---\n* Features related to the applicant (demographic variables such as occupation, employment details etc.)\n* Features related to the applicant (demographic variables such as occupation, employment details etc.)\n---","49e63080":"# 4.2 XGBoost Classifier","af1f951f":"### Scaling the Data","9ba62bec":"## 3. Data Preprocessing","d72ba96a":"Charge off rates are extremely similar across all employment lengths. So we are going to drop the emp_length column.\n","50da3d53":"**Successfully removed all the null Values**","4fc6b690":"# 5. Comparing Models Performance ","8d985ecb":"### \ud83d\udd16 Checking for duplicates columns & features\n","e48f40ed":"\nAddress: <br>\nWe are going to feature engineer a zip code column from the address in the data set. Create a column called 'zip_code' that extracts the zip code from the address column.","e2f7019a":"grade & sub_grade <br>\nWe know that grade is just a sub feature of sub_grade, So we are goinig to drop it.\n","ab8f53f1":"mort_acc <br>\nThere are many ways we could deal with this missing data. We could attempt to build a simple model to fill it in, such as a linear model, we could just fill it in based on the mean of the other columns, or you could even bin the columns into categories and then set NaN as its own category. There is no 100% correct approach!\n\nLet's review the other columsn to see which most highly correlates to mort_acc","7ea71ea6":"# 4.3  Random Forest Classifier\n","9f607d99":"## 1. Importing Required Libraries","b139c463":"# \ud83d\udcddProblem Statement\n\nYou work for the LendingClub company which specialises in lending various types of loans to urban customers. When the company receives a loan application, the company has to make a decision for loan approval based on the applicant\u2019s profile. Two types of risks are associated with the bank\u2019s decision:\n\n* If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\n* If the applicant is not likely to repay the loan, i.e. he\/she is likely to default, then approving the loan may lead to a financial loss for the company\n\nThe data given contains the information about past loan applicants and whether they \u2018defaulted\u2019 or not. The aim is to identify patterns which indicate if a person is likely to default, which may be used for takin actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc.\n\nWhen a person applies for a loan, there are two types of decisions that could be taken by the company:\n\n\n1. Loan accepted: If the company approves the loan, there are 3 possible scenarios described below:\n    * Fully paid: Applicant has fully paid the loan (the principal and the interest rate)\n    * Current: Applicant is in the process of paying the instalments, i.e. the tenure of the loan is       not yet completed. These candidates are not labelled as 'defaulted'.\n    * Charged-off: Applicant has not paid the instalments in due time for a long period of time, i.e.       he\/she has defaulted on the loan\n    \n2. Loan rejected: The company had rejected the loan (because the candidate does not meet their requirements etc.). Since the loan was rejected, there is no transactional history of those applicants with the company and so this data is not available with the company (and thus in this dataset)\n     \n## Business Objectives\n* LendingClub is the largest online loan marketplace, facilitating personal loans, business loans, and financing of medical procedures. Borrowers can easily access lower interest rate loans through a fast online interface.\n* Like most other lending companies, lending loans to \u2018risky\u2019 applicants is the largest source of financial loss (called credit loss). The credit loss is the amount of money lost by the lender when the borrower refuses to pay or runs away with the money owed. In other words, borrowers who defaultcause the largest amount of loss to the lenders. In this case, the customers labelled as 'charged-off' are the 'defaulters'.\n* If one is able to identify these risky loan applicants, then such loans can be reduced thereby cutting down the amount of credit loss. Identification of such applicants using EDA and machine learning is the aim of this case study.\n* In other words, the company wants to understand the driving factors (or driver variables) behind loan default, i.e. the variables which are strong indicators of default. The company can utilise this knowledge for its portfolio and risk assessment.\n* To develop your understanding of the domain, you are advised to independently research a little about risk analytics (understanding the types of variables and their significance should be enough).\n","8e4c60d8":"## 2. Exploratory Data Analysis\n\n**OVERALL GOAL:**\n\n* Get an understanding for which variables are important, view summary statistics, and visualize the   data\n","b4f8ffbc":"## \ud83d\udcc2About Data","a9c2a47b":"\ud83d\udccc**Observation:** We noticed almost perfect correlation between \"loan_amnt\" the \"installment\" ","16190e6a":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>LoanStatNew<\/th>\n      <th>Description<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>loan_amnt<\/td>\n      <td>The listed amount of the loan applied for by the borrower. If at some point in time, the credit department reduces the loan amount, then it will be reflected in this value.<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>term<\/td>\n      <td>The number of payments on the loan. Values are in months and can be either 36 or 60.<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>int_rate<\/td>\n      <td>Interest Rate on the loan<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>installment<\/td>\n      <td>The monthly payment owed by the borrower if the loan originates.<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>grade<\/td>\n      <td>LC assigned loan grade<\/td>\n    <\/tr>\n    <tr>\n      <th>5<\/th>\n      <td>sub_grade<\/td>\n      <td>LC assigned loan subgrade<\/td>\n    <\/tr>\n    <tr>\n      <th>6<\/th>\n      <td>emp_title<\/td>\n      <td>The job title supplied by the Borrower when applying for the loan.*<\/td>\n    <\/tr>\n    <tr>\n      <th>7<\/th>\n      <td>emp_length<\/td>\n      <td>Employment length in years. Possible values are between 0 and 10 where 0 means less than one year and 10 means ten or more years.<\/td>\n    <\/tr>\n    <tr>\n      <th>8<\/th>\n      <td>home_ownership<\/td>\n      <td>The home ownership status provided by the borrower during registration\u00a0or obtained from the credit report.\u00a0Our values are: RENT, OWN, MORTGAGE, OTHER<\/td>\n    <\/tr>\n    <tr>\n      <th>9<\/th>\n      <td>annual_inc<\/td>\n      <td>The self-reported annual income provided by the borrower during registration.<\/td>\n    <\/tr>\n    <tr>\n      <th>10<\/th>\n      <td>verification_status<\/td>\n      <td>Indicates if income was verified by LC, not verified, or if the income source was verified<\/td>\n    <\/tr>\n    <tr>\n      <th>11<\/th>\n      <td>issue_d<\/td>\n      <td>The month which the loan was funded<\/td>\n    <\/tr>\n    <tr>\n      <th>12<\/th>\n      <td>loan_status<\/td>\n      <td>Current status of the loan<\/td>\n    <\/tr>\n    <tr>\n      <th>13<\/th>\n      <td>purpose<\/td>\n      <td>A category provided by the borrower for the loan request.<\/td>\n    <\/tr>\n    <tr>\n      <th>14<\/th>\n      <td>title<\/td>\n      <td>The loan title provided by the borrower<\/td>\n    <\/tr>\n    <tr>\n      <th>15<\/th>\n      <td>zip_code<\/td>\n      <td>The first 3 numbers of the zip code provided by the borrower in the loan application.<\/td>\n    <\/tr>\n    <tr>\n      <th>16<\/th>\n      <td>addr_state<\/td>\n      <td>The state provided by the borrower in the loan application<\/td>\n    <\/tr>\n    <tr>\n      <th>17<\/th>\n      <td>dti<\/td>\n      <td>A ratio calculated using the borrower\u2019s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower\u2019s self-reported monthly income.<\/td>\n    <\/tr>\n    <tr>\n      <th>18<\/th>\n      <td>earliest_cr_line<\/td>\n      <td>The month the borrower's earliest reported credit line was opened<\/td>\n    <\/tr>\n    <tr>\n      <th>19<\/th>\n      <td>open_acc<\/td>\n      <td>The number of open credit lines in the borrower's credit file.<\/td>\n    <\/tr>\n    <tr>\n      <th>20<\/th>\n      <td>pub_rec<\/td>\n      <td>Number of derogatory public records<\/td>\n    <\/tr>\n    <tr>\n      <th>21<\/th>\n      <td>revol_bal<\/td>\n      <td>Total credit revolving balance<\/td>\n    <\/tr>\n    <tr>\n      <th>22<\/th>\n      <td>revol_util<\/td>\n      <td>Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.<\/td>\n    <\/tr>\n    <tr>\n      <th>23<\/th>\n      <td>total_acc<\/td>\n      <td>The total number of credit lines currently in the borrower's credit file<\/td>\n    <\/tr>\n    <tr>\n      <th>24<\/th>\n      <td>initial_list_status<\/td>\n      <td>The initial listing status of the loan. Possible values are \u2013 W, F<\/td>\n    <\/tr>\n    <tr>\n      <th>25<\/th>\n      <td>application_type<\/td>\n      <td>Indicates whether the loan is an individual application or a joint application with two co-borrowers<\/td>\n    <\/tr>\n    <tr>\n      <th>26<\/th>\n      <td>mort_acc<\/td>\n      <td>Number of mortgage accounts.<\/td>\n    <\/tr>\n    <tr>\n      <th>27<\/th>\n      <td>pub_rec_bankruptcies<\/td>\n      <td>Number of public record bankruptcies<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>","1b520a2f":"## 4.1 ANN (Artificial Neural Network)"}}