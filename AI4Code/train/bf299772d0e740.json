{"cell_type":{"0fd59863":"code","878d8711":"code","f7d05768":"code","d5d87239":"code","1b8225de":"code","fc7b95cd":"code","e176987f":"code","279a946d":"code","ff9a6601":"code","3b03a1c7":"code","e8b95c1d":"code","25e61d9d":"code","6d513dc5":"code","86a2cb09":"code","d43508ea":"code","6c291a1f":"code","ae2abf47":"code","412788b9":"code","d4146d4d":"code","b5b7edc8":"code","a654bd61":"code","534df475":"code","91df5840":"code","4b9cb887":"code","3e7fbf7f":"code","78cf6448":"markdown","626083fd":"markdown","58f966a0":"markdown","8f758ff2":"markdown","92954e1f":"markdown","63cd50cb":"markdown","0c7d7dde":"markdown","4b411717":"markdown","88f8f173":"markdown","c1ff7148":"markdown","365bb2f2":"markdown","3981a024":"markdown","e4d2b191":"markdown","5fd62f56":"markdown","8f5906ce":"markdown"},"source":{"0fd59863":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","878d8711":"data = pd.read_csv('..\/input\/usa-housing-dataset\/housing_train.csv')","f7d05768":"data.head()","d5d87239":"data.describe()","1b8225de":"data.info()","fc7b95cd":"plt.figure(figsize=(10,7))\nsns.heatmap(data.isna())","e176987f":"nullCols = []\n\nfor i in data.columns:\n    if(data[i].isna().sum()>=146):\n        data.drop(i,inplace=True,axis=1)\n    else:\n        data[i] = data[i].fillna(method='ffill')","279a946d":"sns.heatmap(data.isna())","ff9a6601":"len(data.columns)","3b03a1c7":"data.duplicated().sum()","e8b95c1d":"data.info()","25e61d9d":"plt.figure(figsize=(15,10))\nsns.heatmap(data.corr(),annot=True,fmt='.1f')","6d513dc5":"sns.countplot(data=data,x='SaleCondition')","86a2cb09":"dt = data.dtypes==object\ncol = data.columns[dt].tolist()","d43508ea":"from sklearn.preprocessing import LabelEncoder,OneHotEncoder","6c291a1f":"le = LabelEncoder()\nx = data[col].apply(le.fit_transform)","ae2abf47":"oneList=[]\none = OneHotEncoder()\noneData = one.fit_transform(x).toarray()","412788b9":"oneData.shape","d4146d4d":"data.drop('Id',inplace=True,axis=1)\ndt = data.dtypes!=object\ncol = data.columns[dt].tolist()\n","b5b7edc8":"new_x = np.append(data[col],x,axis=1)\nnew_x.shape","a654bd61":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","534df475":"train_x,test_x,train_y,test_y = train_test_split(new_x,data['SalePrice'],test_size=0.1,random_state=101)","91df5840":"sc = StandardScaler()\ntrain_x = sc.fit_transform(train_x)\ntest_x = sc.transform(test_x)","4b9cb887":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score","3e7fbf7f":"lr = LinearRegression()\nlr.fit(train_x,train_y)\npredict = lr.predict(test_x)\nprint('MAE ',mean_absolute_error(test_y,predict))\nprint('MSE ',mean_squared_error(test_y,predict))\nprint('R2 Score ',r2_score(test_y,predict))\nprint('RMSE ',np.sqrt(mean_squared_error(test_y,predict)))","78cf6448":"This notebook is dedicated towards predicting sale price of plots.\nIn this tutorial our focus is purely on predicting sales price","626083fd":"Applied Label Encoder","58f966a0":"In this code block if any column contains null value greater than 146(10% of our dataset) we will remove those columns and for rest we will fix it forward fix method","8f758ff2":"Applied Standard Scaler for normalising\/scaling our dataset","92954e1f":"This dataset contains plenty of null values. Lets remove\/fix it","63cd50cb":"One Hot Encoding","0c7d7dde":"Checking for null values ","4b411717":"Creates list of columns whose data type is object","88f8f173":"Checking for correlation","c1ff7148":"Spliting our data into train and test","365bb2f2":"loading csv file data to our DataFrame df","3981a024":"First thing first, lets import necessary libraries","e4d2b191":"Let's convert categorical data into numeric","5fd62f56":"Droping column Id as it is of no use","8f5906ce":"You can plot such more plot, using countplot, FacetGrid for data visualization"}}