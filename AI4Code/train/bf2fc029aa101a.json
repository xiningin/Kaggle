{"cell_type":{"4826c4bf":"code","ff8d1bee":"code","79503fb5":"code","29ab29ef":"code","8a2698bf":"code","f47ce772":"code","a158259d":"code","27b19a8b":"code","4b920979":"code","7dfc3f23":"code","0ae92ddf":"code","8a183e57":"code","dc24c6ed":"code","8c88ea43":"code","b1f5a3c6":"code","1f53cd94":"code","1fbefffa":"code","c7afcf06":"code","67b7d999":"code","c286be6a":"markdown"},"source":{"4826c4bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff8d1bee":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer, Flatten, BatchNormalization, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.regularizers import l2","79503fb5":"df_train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","29ab29ef":"df_train.head()","8a2698bf":"df_train.label.unique()","f47ce772":"from matplotlib.pyplot import imshow\n\nwidth=5\nheight=5\nrows = 3\ncols = 3\naxes=[]\n\nfig=plt.figure()\nfig.set_size_inches(6,8)\n\nfor i in range(rows*cols):\n    sample=np.reshape(df_train[df_train.columns[1:]].iloc[i].values\/255,(28,28))\n    axes.append(fig.add_subplot(rows,cols,i+1))\n    plt.title(\"Labeled class : {}\".format(df_train[\"label\"].iloc[i]))\n    plt.imshow(sample, 'gray')\nfig.tight_layout()\nplt.show()","a158259d":"#Explanatory Data Analysis\n\nplt.figure(figsize=(8,6))\nax = sns.countplot(x='label',data=df_train)\n\nplt.title(\"Label Distribution\")\ntotal= len(df_train.label)\nfor p in ax.patches:\n    percentage = f'{100 * p.get_height() \/ total:.1f}%\\n'\n    x = p.get_x() + p.get_width() \/ 2\n    y = p.get_height()\n    ax.annotate(percentage, (x, y), ha='center', va='center')","27b19a8b":"# separate target values from df_train\ntargets = df_train.label\nfeatures = df_train.drop(\"label\",axis=1)","4b920979":"features = features\/255\ndf_test = df_test\/255","7dfc3f23":"X_train , X_val , Y_train , Y_val = train_test_split(features , targets , test_size=0.2 ,random_state = 1)","0ae92ddf":"from tensorflow.keras.utils import to_categorical\n\ny_train = to_categorical(Y_train,10)\ny_val =  to_categorical(Y_val,10)\n\nprint(y_train[2])\nprint(len(y_train))","8a183e57":"X_train = X_train.values.reshape(len(X_train),28,28,1)\nX_val = X_val.values.reshape(len(X_val),28,28,1)\n\ndf_test = df_test.values.reshape(len(df_test),28,28,1)\n\ninput_shape = (28,28,1)","dc24c6ed":"import tensorflow as tf\n\nmodel = tf.keras.Sequential()\n\n#Conv1\nmodel.add(tf.keras.layers.Conv2D(32 , 3 , input_shape=input_shape , activation = 'relu' , padding = 'same') )\nmodel.add(tf.keras.layers.MaxPool2D(2))\n\n#Conv2\nmodel.add(tf.keras.layers.Conv2D(64 , 3  , activation = 'relu' , padding = 'same') )\nmodel.add(tf.keras.layers.MaxPool2D(2))\n\n#Conv3\nmodel.add(tf.keras.layers.Conv2D(128 , 3  , activation = 'relu' , padding = 'same') )\nmodel.add(tf.keras.layers.MaxPool2D(2))\nmodel.add(tf.keras.layers.Dropout(0.3))\n\n#Conv4\nmodel.add(tf.keras.layers.Conv2D(128 , 3  , activation = 'relu' , padding = 'same') )\nmodel.add(tf.keras.layers.MaxPool2D(2))\nmodel.add(tf.keras.layers.Dropout(0.25))\n\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(256 , activation = 'relu'))\nmodel.add(tf.keras.layers.Dropout(0.25))\n\nmodel.add(tf.keras.layers.Dense(10 , activation = 'softmax'))\n\n\nmodel.summary()","8c88ea43":"#Take a look at any layer in the model by changing layer_name below.\n\nlayer_name = 'conv2d_2'\nlayer_dict = {layer.name : layer for layer in model.layers}\nmodelslice = tf.keras.Model(model.inputs, layer_dict[layer_name].output)\nimage = np.reshape(df_train[df_train.columns[1:]].iloc[2].values\/255,(28,28))\nimage = np.expand_dims(image, axis=0)\nfeature_maps = modelslice.predict(image)\nplt.figure(figsize=(20, 10))\n\nfor i in range(16): # This is itterating through the 16 filter of the convolution!\n    plt.subplot(4,8,i+1)\n    plt.axis('off')\n    plt.imshow(feature_maps[0, :, :, i-1], cmap='inferno')\n    plt.tight_layout(pad=0.0)","b1f5a3c6":"# COMPILING\nmodel.compile(loss = 'categorical_crossentropy' , optimizer = 'adamax' , metrics=['accuracy'])\n\nmodel.summary()","1f53cd94":"history = model.fit(X_train , y_train , batch_size = 42 , epochs = 30 , validation_data = (X_val,y_val))","1fbefffa":"fig = plt.figure(figsize=(20,12))\n\nplt.subplot(211)\nplt.style.use('dark_background')\nplt.plot(history.history['accuracy'], color='c', label=\"Training accuracy\")\nplt.plot(history.history['val_accuracy'], color='r', label=\"Validation accuracy\")\n\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(loc='best')\n\nplt.subplot(212)\nplt.style.use('dark_background')\nplt.plot(history.history['loss'], color='m', label=\"Training loss\")\nplt.plot(history.history['val_loss'], color='r', label=\"Validation loss\")\nplt.ylabel('Loss')\nplt.legend(loc='best')","c7afcf06":"predictions = model.predict(df_test)\npredictions = [np.argmax(a) for a in predictions]","67b7d999":"output = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\noutput['Label'] = predictions\noutput.to_csv('submission.csv',index=False)","c286be6a":"**PreProcessing**"}}