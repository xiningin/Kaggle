{"cell_type":{"eda54087":"code","e21756f0":"code","effa08dd":"code","75e4a151":"code","417f0f67":"code","f9f42ba8":"code","7275c294":"code","94595554":"code","83ddafb1":"code","1c017189":"code","28578563":"code","35e13889":"code","535ac447":"code","2ad2d975":"code","ffe6530d":"code","159adbcc":"code","1d4a4409":"code","ec723e59":"code","64c2709f":"code","76f76d77":"code","22f6ef4c":"code","4f3b8dbd":"code","1442c39b":"code","2612b264":"code","9135287a":"code","b84b3141":"code","154df182":"code","e461768c":"code","5a0cc963":"markdown","5dbe7cd3":"markdown","26e11a39":"markdown","e98b1a32":"markdown","d04e1fe0":"markdown","f981ead0":"markdown","f0c03eec":"markdown","4200c7a9":"markdown","76be8634":"markdown","40cb4bd9":"markdown","f51f9ffa":"markdown","ffea5b17":"markdown","b6c962b1":"markdown","825d04e3":"markdown","2fcea53d":"markdown","8d77cd48":"markdown","a582e923":"markdown","7fa56565":"markdown","fc9c5219":"markdown","73bce739":"markdown","826e349a":"markdown","d1a9b21f":"markdown","f8014f26":"markdown","ef9a52df":"markdown","3cc974da":"markdown","989b5785":"markdown","48e885de":"markdown","f151f481":"markdown","3001459d":"markdown","681da129":"markdown","96525df5":"markdown","74d82a22":"markdown","71c0471a":"markdown","02b9fc81":"markdown","af6693ce":"markdown","c5b26ef2":"markdown","787a03c7":"markdown","97b1eef1":"markdown","b720109a":"markdown","e2e487cd":"markdown","05955a03":"markdown","c8c977c0":"markdown","c9047aba":"markdown","cf3a6a8f":"markdown","e6958e2c":"markdown","bda182e2":"markdown","a9013bdc":"markdown","9d136c1d":"markdown","848b65d6":"markdown","97b8493f":"markdown","c37cc12d":"markdown","e38b5af1":"markdown","b32f15f0":"markdown","42c8ded7":"markdown","80105c45":"markdown","ee12e0d3":"markdown"},"source":{"eda54087":"!git clone --depth 1 https:\/\/github.com\/location-competition\/indoor-location-competition-20 indoor_location_competition_20\n    \n!rm -rf indoor_location_competition_20\/data","e21756f0":"import numpy as np\nimport pandas as pd\nimport scipy.sparse\nimport scipy.interpolate\n\nfrom tqdm import tqdm\nimport multiprocessing\nimport matplotlib.pyplot as plt\n\nfrom indoor_location_competition_20.io_f import read_data_file\nimport indoor_location_competition_20.compute_f as compute_f\n\n%matplotlib inline","effa08dd":"INPUT_PATH = '..\/input\/indoor-location-navigation'","75e4a151":"# Kernels Data (Public Score & File Path)\n\ndfk = pd.DataFrame({ \n    'Kernel ID': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],  \n    'Score':     [9.773, 9.530, 8.500, 8.418, 8.333, 8.073, 7.745, 7.661, 7.274, 7.285],   \n    'File Path': ['..\/input\/indoor9773\/Indoor9773.csv', '..\/input\/indoor9530\/Indoor9530.csv', '..\/input\/indoor8500\/Indoor8500.csv', '..\/input\/indoor8418\/Indoor8418.csv', '..\/input\/indoor8333\/Indoor8333.csv', '..\/input\/indoor8073\/Indoor8073.csv', '..\/input\/indoornav7745sub\/submission.csv', '..\/input\/indoor7661\/Indoor7661.csv', '..\/input\/indoor-wifi-floor\/submission.csv', '..\/input\/time-series-rnn-xy-prediction\/submission.csv']     \n})    \n    \ndfk","417f0f67":"def compute_rel_positions(acce_datas, ahrs_datas):\n    \n    step_timestamps, step_indexs, step_acce_max_mins = compute_f.compute_steps(acce_datas)\n    headings = compute_f.compute_headings(ahrs_datas)\n    stride_lengths = compute_f.compute_stride_length(step_acce_max_mins)\n    step_headings = compute_f.compute_step_heading(step_timestamps, headings)\n    rel_positions = compute_f.compute_rel_positions(stride_lengths, step_headings)\n    \n    return rel_positions","f9f42ba8":"def correct_path(args):\n    path, path_df = args\n    \n    T_ref  = path_df['timestamp'].values\n    xy_hat = path_df[['x', 'y']].values\n    \n    example = read_data_file(f'{INPUT_PATH}\/test\/{path}.txt')\n    rel_positions = compute_rel_positions(example.acce, example.ahrs)\n    if T_ref[-1] > rel_positions[-1, 0]:\n        rel_positions = [np.array([[0, 0, 0]]), rel_positions, np.array([[T_ref[-1], 0, 0]])]\n    else:\n        rel_positions = [np.array([[0, 0, 0]]), rel_positions]\n    rel_positions = np.concatenate(rel_positions)\n    \n    T_rel = rel_positions[:, 0]\n    delta_xy_hat = np.diff(scipy.interpolate.interp1d(T_rel, np.cumsum(rel_positions[:, 1:3], axis=0), axis=0)(T_ref), axis=0)\n\n    N = xy_hat.shape[0]\n    delta_t = np.diff(T_ref)\n    alpha = (8.1)**(-2) * np.ones(N)\n    beta  = (0.30 + 0.30 * 1e-3 * delta_t)**(-2)\n    A = scipy.sparse.spdiags(alpha, [0], N, N)\n    B = scipy.sparse.spdiags( beta, [0], N-1, N-1)\n    D = scipy.sparse.spdiags(np.stack([-np.ones(N), np.ones(N)]), [0, 1], N-1, N)\n\n    Q = A + (D.T @ B @ D)\n    c = (A @ xy_hat) + (D.T @ (B @ delta_xy_hat))\n    xy_star = scipy.sparse.linalg.spsolve(Q, c)\n\n    return pd.DataFrame({\n        'site_path_timestamp' : path_df['site_path_timestamp'],\n        'floor' : path_df['floor'],\n        'x' : xy_star[:, 0],\n        'y' : xy_star[:, 1],\n    })\n","7275c294":"sub = pd.read_csv(dfk.iloc[0, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","94595554":"simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\nsub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('a9773cm99.csv', index=False)\n\na9773cm99 = sub","83ddafb1":"sub = pd.read_csv(dfk.iloc[1, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","1c017189":"simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\nsub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('b9530cm99.csv', index=False)\n\nb9530cm99 = sub","28578563":"sub = pd.read_csv(dfk.iloc[2, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","35e13889":"simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\nsub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('c8500cm99.csv', index=False)\n\nc8500cm99 = sub","535ac447":"sub = pd.read_csv(dfk.iloc[3, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","2ad2d975":"simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\nsub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('d8418cm99.csv', index=False)\n\nd8418cm99 = sub","ffe6530d":"sub = pd.read_csv(dfk.iloc[4, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","159adbcc":"simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\nsub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('e8333cm99.csv', index=False)\n\ne8333cm99 = sub","1d4a4409":"sub = pd.read_csv(dfk.iloc[5, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","ec723e59":"# simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\n# sub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('f8073cm99.csv', index=False)\n\nf8073cm99 = sub","64c2709f":"sub = pd.read_csv(dfk.iloc[6, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","76f76d77":"simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\nsub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('g7745cm99.csv', index=False)\n\ng7745cm99 = sub","22f6ef4c":"sub = pd.read_csv(dfk.iloc[7, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","4f3b8dbd":"simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\nsub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('h7661cm99.csv', index=False)\n\nh7661cm99 = sub","1442c39b":"sub = pd.read_csv(dfk.iloc[8, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","2612b264":"simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\nsub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('i7274cm99.csv', index=False)\n\ni7274cm99 = sub","9135287a":"sub = pd.read_csv(dfk.iloc[9, 2])\n\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)    \nsub = pd.concat(dfs).sort_values('site_path_timestamp')","b84b3141":"simple_accurate_99 = pd.read_csv(dfk.iloc[5, 2])\n\nsub['floor'] = simple_accurate_99['floor'].values\n\nsub.to_csv('j7285cm99.csv', index=False)\n\nj7285cm99 = sub","154df182":"gfk = pd.DataFrame({ \n    \n    'Kernel ID'   : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],  \n    \n    'Before Score': [9.773, 9.530, 8.500, 8.418, 8.333, 8.073, 7.745, 7.661, 7.274, 7.285], \n    \n    'After Score' : [7.110, 6.674, 6.290, 6.189, 6.077, 6.062, 5.995, 5.694, 5.471, 5.847], \n    \n    'File Name'   : ['a9773cm99.csv', 'b9530cm99.csv', 'c8500cm99.csv', 'd8418cm99.csv', 'e8333cm99.csv', 'f8073cm99.csv', 'g7745cm99.csv', 'h7661cm99.csv', 'i7274cm99.csv', 'j7285cm99.csv'] \n    \n})    \n    \ngfk","e461768c":"sub = i7274cm99\nsub.to_csv(\"submission.csv\", index=False)\n\na9773cm99.to_csv(\"a9773cm99.csv\", index=False)\nb9530cm99.to_csv(\"b9530cm99.csv\", index=False)\nc8500cm99.to_csv(\"c8500cm99.csv\", index=False)\nd8418cm99.to_csv(\"d8418cm99.csv\", index=False)\ne8333cm99.to_csv(\"e8333cm99.csv\", index=False)\nf8073cm99.to_csv(\"f8073cm99.csv\", index=False)\ng7745cm99.to_csv(\"g7745cm99.csv\", index=False)\nh7661cm99.to_csv(\"h7661cm99.csv\", index=False)\ni7274cm99.to_csv(\"i7274cm99.csv\", index=False)\nj7285cm99.to_csv(\"j7285cm99.csv\", index=False)\n\n!ls","5a0cc963":"<div class=\"alert alert-success\">  \n<\/div>","5dbe7cd3":"### Fix the floor prediction","26e11a39":"To combine machine learning (wifi features) predictions with sensor data (acceleration, attitude heading),\nI defined cost function as follows,\n$$\nL(X_{1:N}) = \\sum_{i=1}^{N} \\alpha_i \\| X_i - \\hat{X}_i \\|^2 + \\sum_{i=1}^{N-1} \\beta_i \\| (X_{i+1} - X_{i}) - \\Delta \\hat{X}_i \\|^2\n$$\nwhere $\\hat{X}_i$ is absolute position predicted by machine learning and $\\Delta \\hat{X}_i$ is relative position predicted by sensor data.\n\nSince the cost function is quadratic, the optimal $X$ is solved by linear equation $Q X = c$\n, where $Q$ and $c$ are derived from above cost function.\nBecause the matrix $Q$ is tridiagonal,\neach machine learning prediction is corrected by *all* machine learning predictions and sensor data.\n\nThe optimal hyperparameters ($\\alpha$ and $\\beta$) can be estimated by expected error of machine learning and sensor data,\nor just tuned by public score.","e98b1a32":"<div class=\"alert alert-success\">  \n<\/div>","d04e1fe0":"# Results","f981ead0":"### After \"Cost Minimizat\" & \"Fix the floor prediction\"\n\n### j7285cm99.csv |  Public Score: 5.847","f0c03eec":"<div class=\"alert alert-success\">  \n<\/div>","4200c7a9":"### After \"Cost Minimizat\" & \"Fix the floor prediction\"\n\n### i7274cm99.csv |  Public Score: 5.471","76be8634":"### After \"Cost Minimizat\" & \"Fix the floor prediction\"\n\n### g7745cm99.csv |  Public Score: 5.995","40cb4bd9":"<div>\n    <h1 align=\"center\">Cost Minimization & Floor - Part(1)<\/h1><\/h1>\n    <h2 align=\"center\">Identify the position of a smartphone in a shopping mall<\/h2>\n    <h3 align=\"center\">By: Somayyeh Gholami & Mehran Kazeminia<\/h3>\n<\/div>","f51f9ffa":"<div class=\"alert alert-success\">  \n<\/div>","ffea5b17":"<div class=\"alert alert-success\">  \n<\/div>","b6c962b1":"<div class=\"alert alert-success\">  \n<\/div>","825d04e3":"### Fix the floor prediction","2fcea53d":"<div class=\"alert alert-success\">  \n<\/div>","8d77cd48":"### After \"Cost Minimization\" & \"Fix the floor prediction\"\n\n### b9530cm99.csv |  Public Score: 6.674","a582e923":"# Kernel: B\n\nhttps:\/\/www.kaggle.com\/byfone\/indoor-location-wi-fi-features-catboost-starter\n\nPublic Score: 9.530","7fa56565":"# Kernel: I\n\nhttps:\/\/www.kaggle.com\/therocket290\/lstm-unified-wi-fi-training-x-and-y-with-floor\n\nPublic Score: 7.274","fc9c5219":"# Submission","73bce739":"### After \"Cost Minimization\" & \"Fix the floor prediction\"\n\n### c8500cm99.csv |  Public Score: 6.290\n","826e349a":"<div class=\"alert alert-success\">  \n<\/div>","d1a9b21f":"<div class=\"alert alert-success\">  \n<\/div>","f8014f26":"# Kernel: E\n\nhttps:\/\/www.kaggle.com\/hiro5299834\/wifi-features-with-lightgbm-kfold\n\nPublic Score: 8.333","ef9a52df":"# If you find this work useful, please don't forget upvoting :)","3cc974da":"# Kernel: A\n\nhttps:\/\/www.kaggle.com\/deepijongwonkim\/wifi-features-neural-networks-starter\n\nPublic Score: 9.773","989b5785":"### Fix the floor prediction","48e885de":"### Fix the floor prediction","f151f481":"# Kernel: D\n\nhttps:\/\/www.kaggle.com\/hiro5299834\/wifi-features-with-lightgbm-and-xgboost-kfold\n\nPublic Score: 8.418","3001459d":"<div class=\"alert alert-success\">  \n<\/div>","681da129":"# Description:","96525df5":"<div class=\"alert alert-success\">  \n<\/div>","74d82a22":"### After \"Cost Minimization\" & \"Fix the floor prediction\"\n\n### f8073cm99.csv |  Public Score: 6.062","71c0471a":"# Functions\n\nThese descriptions and codes are copied from the following notebook:\n\nhttps:\/\/www.kaggle.com\/saitodevel01\/indoor-post-processing-by-cost-minimization\n","02b9fc81":"# Kernel: H\n\nhttps:\/\/www.kaggle.com\/kokitanisaka\/lstm-by-keras-with-unified-wi-fi-feats\n\nPublic Score: 7.661","af6693ce":"### After \"Cost Minimization\" & \"Fix the floor prediction\"\n\n### d8418cm99.csv |  Public Score: 6.189","c5b26ef2":"<div class=\"alert alert-success\">  \n<\/div>","787a03c7":"### After \"Cost Minimization\" & \"Fix the floor prediction\"\n\n### a9773cm99.csv |  Public Score: 7.110","97b1eef1":"<div class=\"alert alert-success\">  \n<\/div>","b720109a":"### - In this notebook (No. 1), we used the following magic notebook for \"Cost Minimization\".\n\nhttps:\/\/www.kaggle.com\/saitodevel01\/indoor-post-processing-by-cost-minimization\n\n### - We used the following creative notebook for \"Fix the floor prediction\".\n\nhttps:\/\/www.kaggle.com\/nigelhenry\/simple-99-accurate-floor-model\n\n### - In this notebook (No. 1), we improve the results of ten public notebooks by the above methods. Then in the notebook (No. 2) we will use \"Ensembling\" and \"Comparative Method\". Finally, the so-called \"Snap to Grid\" notebook (No. 3) produces the final result. Thanks to everyone who shared their notebooks, the addresses of some of the used notebooks are as follows:\n\nhttps:\/\/www.kaggle.com\/robikscube\/indoor-navigation-snap-to-grid-post-processing\n\nhttps:\/\/www.kaggle.com\/therocket290\/lstm-unified-wi-fi-training-x-and-y-with-floor\n\nhttps:\/\/www.kaggle.com\/kokitanisaka\/lstm-by-keras-with-unified-wi-fi-feats\n\nhttps:\/\/www.kaggle.com\/oxzplvifi\/indoor-gbm-postprocessing-xy-prediction\n\nhttps:\/\/www.kaggle.com\/nigelhenry\/simple-99-accurate-floor-model\n\nhttps:\/\/www.kaggle.com\/hiro5299834\/wifi-features-with-lightgbm-kfold\n\nhttps:\/\/www.kaggle.com\/ebinan92\/time-series-rnn-xy-prediction\n\n\n### - As we explained in previous notebooks; If you upgrade the score of all notebooks with the \"Snap to Grid\" method before \"Ensembling\" and then perform the \"Ensembling\" operation, all the errors will add up and you will not get a good result. This means using the \"Snap to Grid\" method only in the last step. But \"Cost Minimization\" can be done before or after \"Ensembling\". Of course, as you can see, we do \"Cost Minimization\" for all results from the beginning.\n\n### =======================================================\n\n### For more information, you can refer to the following address:\n\nhttps:\/\/www.kaggle.com\/c\/indoor-location-navigation\/discussion\/230153\n\n## >>> Good Luck <<<\n","e2e487cd":"# Kernel: F\n\nhttps:\/\/www.kaggle.com\/nigelhenry\/simple-99-accurate-floor-model\n\nPublic Score: 8.073","05955a03":"### Fix the floor prediction","c8c977c0":"### Fix the floor prediction","c9047aba":"<div class=\"alert alert-success\">  \n<\/div>","cf3a6a8f":"# Kernel: J\n\nhttps:\/\/www.kaggle.com\/ebinan92\/time-series-rnn-xy-prediction\n\nPublic Score: 7.285","e6958e2c":"### Fix the floor prediction","bda182e2":"### Fix the floor prediction","a9013bdc":"<div class=\"alert alert-success\">  \n<\/div>","9d136c1d":"<div class=\"alert alert-success\">  \n<\/div>","848b65d6":"### After \"Cost Minimizat\" & \"Fix the floor prediction\"\n\n### h7661cm99.csv |  Public Score: 5.694\n","97b8493f":"# Import & Data Set","c37cc12d":"### Fix the floor prediction","e38b5af1":"<div class=\"alert alert-success\">  \n<\/div>","b32f15f0":"# Kernel: C\n\nhttps:\/\/www.kaggle.com\/hiro5299834\/wifi-features-with-lightgbm-groupkfold\n\nPublic Score: 8.500","42c8ded7":"### Fix the floor prediction","80105c45":"# Kernel: G\n\nhttps:\/\/www.kaggle.com\/oxzplvifi\/indoor-gbm-postprocessing-xy-prediction\n\nPublic Score: 7.745","ee12e0d3":"### After \"Cost Minimization\" & \"Fix the floor prediction\"\n\n### e8333cm99.csv |  Public Score: 6.077\n"}}