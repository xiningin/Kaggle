{"cell_type":{"86485c9e":"code","b4bdebc6":"code","058bab40":"code","932be44e":"code","85b798aa":"code","d2c24b89":"code","ae8bc237":"code","451aacc3":"code","26dfbd20":"code","f21d0899":"code","636426eb":"code","c77302dc":"code","88604938":"code","29289e89":"code","8bb6badb":"code","ef1aa2d0":"code","ff9033d9":"code","23b9c037":"code","825c3ee7":"code","1e67ba89":"code","d112fa4e":"code","e1609155":"code","0285f386":"code","117b0d39":"code","e66241d3":"code","f001c524":"code","51d2c0a0":"code","5ef4790b":"code","5dff561f":"code","b8623d16":"code","3c0554cc":"code","3fa3f02d":"code","5b59a04a":"code","0153ec80":"code","b27c7537":"code","c65e7ca1":"code","6a831a45":"code","28877cb4":"code","9dcf0559":"code","3d31e2d5":"code","53d0098f":"code","e8e12b34":"code","0d537403":"code","6ab382e9":"code","d63030c2":"code","13a78256":"code","689c7b37":"code","a704a60b":"code","a11fb115":"code","9b5c5700":"code","567e152a":"code","3d831662":"code","f8fffbb5":"code","f99b2e4f":"code","14db445a":"code","9e4f28ef":"code","2e190136":"markdown","235466df":"markdown","5b15e30f":"markdown","779d7dfb":"markdown","2bce2b1d":"markdown","1c526e19":"markdown","15eb8643":"markdown","5582fe39":"markdown","4ea4eb18":"markdown","95c09c15":"markdown","7c1af731":"markdown","1c17ed16":"markdown","fb8d99f9":"markdown","c2f1de0b":"markdown","45a4a015":"markdown","e23404b2":"markdown","21ab2f68":"markdown","bb9cbaa2":"markdown","9d5dcb4e":"markdown","18e1dcd9":"markdown","4c5a84fb":"markdown","dcd6aee4":"markdown","26b1120f":"markdown","577b3781":"markdown","d2afc34f":"markdown","5d9d4e30":"markdown","b2908446":"markdown","76fe95a1":"markdown","7705ef45":"markdown","56f09211":"markdown","798fbfda":"markdown","807b63af":"markdown","2f00d115":"markdown"},"source":{"86485c9e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b4bdebc6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","058bab40":"df = pd.read_csv(\"\/kaggle\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv\")","932be44e":"df.head()","85b798aa":"#Number of unique values\ndf.nunique()","d2c24b89":"df.isnull().sum()\/len(df)*100","ae8bc237":"df.describe().T","451aacc3":"df.drop(['Clothing ID', 'Title', 'Unnamed: 0'], axis = 1, inplace = True)","26dfbd20":"df[df['Review Text'].isnull()]","f21d0899":"df = df[~df['Review Text'].isnull()]","636426eb":"df.shape","c77302dc":"df.head()","88604938":"plt.figure(figsize = (20,6))\nsns.countplot(x = 'Age', data = df)\nplt.show()","29289e89":"plt.figure(figsize = (20,6))\nsns.countplot(x = 'Rating', data = df)\nplt.show()","8bb6badb":"plt.figure(figsize = (20,6))\nsns.countplot(x = 'Class Name', data = df)\nplt.xticks(rotation = 45)\nplt.show()","ef1aa2d0":"plt.figure(figsize = (15,6))\nsns.barplot(x ='Age',y= 'Positive Feedback Count',data = df, palette = 'viridis')\nplt.title('Age vs Positive Feedback', fontsize = 20)\nplt.xticks(rotation = 90)\nplt.show()","ff9033d9":"plt.figure(figsize = (15,6))\nsns.distplot(df['Positive Feedback Count'])\nplt.show()","23b9c037":"plt.figure(figsize = (15,6))\n\nsns.barplot(x ='Age',y= 'Rating',data = df, palette = 'viridis')\nplt.title('Age vs Rating', fontsize = 20)\nplt.xticks(rotation = 90)\nplt.show()","825c3ee7":"plt.figure(figsize = (15,10))\nsns.boxplot(x=\"Recommended IND\", y=\"Rating\", hue = \"Recommended IND\", data = df)\nplt.xlabel(\"3-G\", fontsize = 20)\nplt.ylabel(\"RAM\", fontsize = 20)\n\nplt.show()","1e67ba89":"import string\nstring.punctuation\ndef remove_punctuation(text):\n    no_punct=[words for words in text if words not in string.punctuation]\n    words_wo_punct=''.join(no_punct)\n    return words_wo_punct\ndf['Review Text']=df['Review Text'].apply(lambda x: remove_punctuation(x))\ndf.head()","d112fa4e":"!pip install TextBlob\nfrom textblob import *\n\ndf['polarity'] = df['Review Text'].map(lambda text: TextBlob(text).sentiment.polarity)\ndf['polarity']","e1609155":"import plotly.express as px\npx.histogram(df, x = 'polarity',color=\"Rating\", opacity = 0.5)","0285f386":"plt.figure(figsize = (15,10))\nsns.boxplot(x=\"polarity\", y=\"Department Name\", hue = \"Recommended IND\", data = df)\nplt.xlabel(\"Polarity of the review\", fontsize = 20)\nplt.ylabel(\"Department Name\", fontsize = 20)\n\nplt.show()","117b0d39":"example = df.loc[df.polarity == 1,['Review Text']].sample(3).values\nfor i in example:\n    print(i[0])","e66241d3":"example = df.loc[df.polarity == 0.5,['Review Text']].sample(3).values\nfor i in example:\n    print(i[0])","f001c524":"example = df.loc[df.polarity < 0,['Review Text']].sample(3).values\nfor i in example:\n    print(i[0])","51d2c0a0":"negative = (len(df.loc[df.polarity < 0, ['Review Text']].values)\/len(df))*100\npositive = (len(df.loc[df.polarity > 0.5, ['Review Text']].values)\/len(df))*100\nneutral = len(df.loc[df.polarity >0 ,['Review Text']].values) - len(df.loc[df.polarity >0.5 ,['Review Text']].values)\nneutral = neutral\/len(df)*100\nplt.figure(figsize =(10, 7)) \nplt.pie([positive,negative,neutral], labels = ['Positive','Negative','Neutral']) \nplt.show()","5ef4790b":"from sklearn.feature_extraction.text import CountVectorizer\ndef top_n_ngram(corpus,n = None,ngram = 1):\n    vec = CountVectorizer(stop_words = 'english',ngram_range=(ngram,ngram)).fit(corpus)\n    bag_of_words = vec.transform(corpus) #Have the count of  all the words for each review\n    sum_words = bag_of_words.sum(axis =0) #Calculates the count of all the word in the whole review\n    words_freq = [(word,sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n    words_freq = sorted(words_freq,key = lambda x:x[1],reverse = True)\n    return words_freq[:n]","5dff561f":"common_words= top_n_ngram(df['Review Text'], 10,1)\ndata = pd.DataFrame(common_words, columns = ['ReviewText' , 'count'])\nplt.figure(figsize =(10,5))\ndata.groupby('ReviewText').sum()['count'].sort_values(ascending=False).plot(\nkind='bar', title='Top 10 unigrams in review after removing stop words')","b8623d16":"common_words = top_n_ngram(df['Review Text'], 20,2)\ndata = pd.DataFrame(common_words, columns = ['ReviewText' , 'count'])\nplt.figure(figsize =(10,5))\ndata.groupby('ReviewText').sum()['count'].sort_values(ascending=False).plot(\nkind='bar', title='Top 10 unigrams in review after removing stop words')","3c0554cc":"blob= TextBlob(str(df['Review Text']))\npos = pd.DataFrame(blob.tags,columns =['word','pos'])\npos1 = pos.pos.value_counts()[:20]\nplt.figure(figsize = (10,5))\npos1.plot(kind='bar',title ='Top 20 Part-of-speech taggings')\n","3fa3f02d":"df['review_len'] = df['Review Text'].astype(str).apply(len)","5b59a04a":"y = df['Recommended IND']\nX = df.drop(columns = 'Recommended IND')","0153ec80":"sns.heatmap(X.corr(), annot = True )","b27c7537":"class1 = []\nfor i in X.polarity:\n    if float(i)>=0.0:\n        class1.append(1)\n        \n    elif float(i)<0.0:\n        class1.append(0)\nX['sentiment'] = class1\n\nX.groupby(X['sentiment']).describe().T","c65e7ca1":"print(\"Shape of X: \" , X.shape)\nprint(\"Shape of y: \" , y.shape)","6a831a45":"import re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n","28877cb4":"X.index = np.arange(len(X))\ncorpus = []\nfrom tqdm import tqdm\nfor i in tqdm(range(len(X))):\n  review = re.sub('[^a-zA-Z]', ' ', X['Review Text'][i])\n  review = review.lower()\n  review = review.split()\n  ps = PorterStemmer()\n  all_stopwords = stopwords.words('english')\n  all_stopwords.remove('not')\n  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n  review = ' '.join(review)\n  corpus.append(review)","9dcf0559":"corpus","3d31e2d5":"# from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS\n# wc= WordCloud(background_color=\"white\", random_state=1,stopwords=STOPWORDS, max_words = 2000, width =1000, height = 1500)\n# wc.generate(review)\n# plt.figure(figsize=[10,10])\n# plt.imshow(wc,interpolation=\"bilinear\")\n# plt.axis('off')\n# plt.show()","53d0098f":"from sklearn.feature_extraction.text import CountVectorizer as CV\ncv  = CV(max_features = 3000,ngram_range=(1,1))\nX_cv = cv.fit_transform(corpus).toarray()\ny = y.values\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_cv, y, test_size = 0.20, random_state = 0)\nfrom sklearn.naive_bayes import BernoulliNB\nclassifier = BernoulliNB()\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nacc = accuracy_score(y_test, y_pred)\nprint(\"Accuracy of the classifier: \",acc)\nprint(\"Confusion matrix is :\\n\",metrics.confusion_matrix(y_test,y_pred))\nprint(\"Classification report: \\n\" ,metrics.classification_report(y_test,y_pred))\n","e8e12b34":"acc","0d537403":"from sklearn.feature_extraction.text import TfidfVectorizer as TV\ntv  = TV(ngram_range =(1,1),max_features = 3000)\nX_tv = tv.fit_transform(corpus).toarray()","6ab382e9":"X_train, X_test, y_train, y_test = train_test_split(X_tv, y, test_size = 0.20, random_state = 0)\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)","d63030c2":"y_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)","13a78256":"acc","689c7b37":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","a704a60b":"tokenizer = Tokenizer(num_words = 3000)\ntokenizer.fit_on_texts(corpus)","a11fb115":"sequences = tokenizer.texts_to_sequences(corpus)\npadded = pad_sequences(sequences, padding='post')","9b5c5700":"word_index = tokenizer.word_index\ncount = 0\nfor i,j in word_index.items():\n    if count == 11:\n        break\n    print(i,j)\n    count = count+1","567e152a":"embedding_dim = 64\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(3000, embedding_dim),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(6, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.summary()","3d831662":"num_epochs = 10\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","f8fffbb5":"model.fit(padded,y,epochs= num_epochs)","f99b2e4f":"sample_string = \"I Will tell my friends for sure\"\nsample = tokenizer.texts_to_sequences(sample_string)\npadded_sample = pad_sequences(sample, padding='post')","14db445a":"padded_sample.T","9e4f28ef":"model.predict(padded_sample.T)","2e190136":"An accuracy of 83.55% from the TF-IDF technique, which is less than that of Bag of Words Technique.","235466df":"# Cleaning the text for visualization of polarity","5b15e30f":"Adding Review Length as a feature","779d7dfb":"Removing the unwanted null values.","2bce2b1d":"# Create N-grams","1c526e19":"Here 1 means recommended. 0 means not recommended.\n\nWomen recommend a product if they rate it to be more than or equal to 3.","15eb8643":"Dresses, Knits and Blouses are bought the most by women. ","5582fe39":"This plot looks right because all **the polarities of \"not recommended\" are less than that of polarities of the \"recommended\".**","4ea4eb18":"# Reviews with positive polarity","95c09c15":"# Visualizing Top 20 Bigrams","7c1af731":"# Reviews with neutral polarity","1c17ed16":"There's a 99.45% accuracy that this review will result in recommendation.","fb8d99f9":"# Checking for missing values","c2f1de0b":"# Reviews with negative polarity","45a4a015":"We won't be using Title feature since it has a lot of missing values.","e23404b2":"We are dropping these features because they hold very less significance to sentiment analysis of the review.","21ab2f68":"There's no noteable relation between Age and Rating, excluding some outliers. Same as Age vs Positive Feedback.","bb9cbaa2":"# Polarity Pie-Chart","9d5dcb4e":"# Visualizing Top 10 POS Tagging","18e1dcd9":"# TF-IDF Technique","4c5a84fb":"# Visualizing Top 10 Unigrams","dcd6aee4":"# Data Analysis and Visualization","26b1120f":"# Creating Bag Of Words Model","577b3781":"There's no noteable relation between Age and Positive Feedback, excluding some outliers.  \n\n","d2afc34f":"Term Frequency - Inverse Document Frequency is used to measure the originality of a word. It converts sentences to vectors(after tokenization, stemming\/lemmatization). \n\nBag of Words technique doesn't provide us with the semantic meaning of the word, here TF-IDF comes in play as it provides us the semantic meaning of the word.\n","5d9d4e30":"There's not a strong correleation between any of the features.","b2908446":"# Loading the data","76fe95a1":"# Statistical Description","7705ef45":"An accuracy score of 87.28% is pretty good.","56f09211":"# Deep Learning Model","798fbfda":"These are the Top 11 most frequent words.","807b63af":"# Correlation of fetaures using Heatmaps ","2f00d115":"Removing all the punctuations from the review text."}}