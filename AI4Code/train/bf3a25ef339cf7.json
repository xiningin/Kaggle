{"cell_type":{"74ff0134":"code","850b8821":"code","82f2022d":"code","375a7964":"code","fa3ce1d4":"code","fcbf311c":"code","db9972f4":"code","8dda4786":"code","f59c326f":"code","f88cb42f":"code","f720e7fa":"code","acc414da":"markdown"},"source":{"74ff0134":"import numpy as np\nimport pandas as pd\n\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display","850b8821":"DEBUG = False\n\ntrain = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\nsubmission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\n","82f2022d":"\n\ndef add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag'] = df['u_in'].shift(2).fillna(0)\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df = pd.get_dummies(df)\n    df['ewm_u_in_mean'] = df.groupby('breath_id')['u_in'].ewm(halflife=8).mean().reset_index(level=0,drop=True)\n    df['ewm_u_in_std'] = df.groupby('breath_id')['u_in'].ewm(halflife=9).std().reset_index(level=0,drop=True) ## could add covar?\n    df['ewm_u_in_corr'] = df.groupby('breath_id')['u_in'].ewm(halflife=14).corr().reset_index(level=0,drop=True) # self umin corr\n    #df['ewm_u_in_corr'] = df.groupby('breath_id')['u_in'].ewm(halflife=6).corr(df.groupby('breath_id')[\"u_out\"]).reset_index(level=0,drop=True) # corr with u_out # error\n    ## rolling window of 15 periods\n    df[[\"15_in_max\",\"15_out_std\"]] = df.groupby('breath_id')['u_in'].rolling(window=15,min_periods=1).agg({\"15_in_max\":\"max\",\"15_in_std\":\"std\"}).reset_index(level=0,drop=True)\n\n    #df[[\"45_in_sum\",\"45_in_min\",\"45_in_max\",\"45_in_mean\",\"45_out_std\"]] = df.groupby('breath_id')['u_in'].rolling(window=45,min_periods=1).agg({\"45_in_sum\":\"sum\",\"45_in_min\":\"min\",\"45_in_max\":\"max\",\"45_in_mean\":\"mean\",\"45_in_std\":\"std\"}).reset_index(level=0,drop=True)\n    #df[[\"15_out_mean\"]] = df.groupby('breath_id')['u_out'].rolling(window=15,min_periods=1).agg({\"15_out_mean\":\"mean\"}).reset_index(level=0,drop=True)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)","375a7964":"train=train.fillna(0)\ntest=test.fillna(0)\ntrain.shape,test.shape","fa3ce1d4":"targets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)","fcbf311c":"test.shape,train.shape","db9972f4":"RS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)","8dda4786":"train = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","f59c326f":"EPOCH = 225\nBATCH_SIZE = 1024\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\ntest_preds = []\n\nwith tpu_strategy.scope():\n    kf = KFold(n_splits=5, shuffle=True, random_state=2021)\n\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        model = keras.models.Sequential([\n            keras.layers.Input(shape=train.shape[-2:]),\n            keras.layers.Bidirectional(keras.layers.LSTM(500, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(375, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(200, return_sequences=True)),\n            keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences=True)),\n            keras.layers.Dense(100, activation='selu'),\n            keras.layers.Dense(1),\n        ])\n        model.compile(optimizer=\"adam\", loss=\"mae\")\n\n        scheduler = ExponentialDecay(1e-3, 400*((len(train)*0.8)\/BATCH_SIZE), 1e-5)\n        lr = LearningRateScheduler(scheduler, verbose=1)\n\n        es = EarlyStopping(monitor=\"val_loss\", patience=15, verbose=1, mode=\"min\", restore_best_weights=True)\n\n        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr])\n        #model.save(f'Fold{fold+1} RNN Weights')\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())","f88cb42f":"print('done')","f720e7fa":"submission[\"pressure\"] = sum(test_preds)\/5\nsubmission.to_csv('submission.csv', index=False)","acc414da":"\nadditional features from here @Dan Ofer\n\nhttps:\/\/www.kaggle.com\/danofer\/lgbm-lover-s"}}