{"cell_type":{"ad64e672":"code","f6b7e978":"code","14d57388":"code","faba6bc9":"code","6aab35ca":"code","1d0a4a3a":"code","9e3588b1":"code","384c34f1":"code","02148359":"code","b72520aa":"code","36d60c01":"code","293391f9":"code","1b9dacd7":"code","0963a27c":"code","baedf4f9":"code","70d3ad9c":"code","563e8b55":"code","dea1924b":"code","ff320247":"code","20d2baea":"code","b679c771":"code","0329e102":"code","c7c0ecb3":"code","acb5884d":"code","fef2afbe":"code","6a671c7e":"markdown","9cb9f2e1":"markdown","40b128f5":"markdown","1f1ac46e":"markdown","615f99ff":"markdown","4b28cfad":"markdown","007bc82f":"markdown","c79146e3":"markdown","0ad63451":"markdown","1b1dadab":"markdown","a053a3f3":"markdown","20516b93":"markdown","637cd79d":"markdown","c3c4ae2e":"markdown","c811202f":"markdown","7098d010":"markdown","76ba8deb":"markdown","00b213c0":"markdown","9cbf9670":"markdown","ffbb66c6":"markdown","420df647":"markdown","7080f535":"markdown","bdcdb9e3":"markdown","7729c231":"markdown","4ae6eeba":"markdown","a88e768b":"markdown","cb28a629":"markdown","573f77ce":"markdown","3e1fccc8":"markdown","1369d4aa":"markdown","39ce15e0":"markdown","5ed47a02":"markdown","7c32d1dd":"markdown","4f1320dc":"markdown","2269c423":"markdown","d9512a9d":"markdown","7a144c64":"markdown","100f7aca":"markdown","7c0d1405":"markdown","0255f1f8":"markdown","8a66f6d9":"markdown","86dae1db":"markdown","8b616c8d":"markdown","1ddfe270":"markdown","536b234d":"markdown","3ef885a3":"markdown","10701657":"markdown"},"source":{"ad64e672":"import numpy as np \nimport pandas as pd\n\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nfrom textblob import TextBlob\n\nimport seaborn as sns\nimport matplotlib.style as style \nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import set_config\nset_config(display=\"diagram\")\n\nimport eli5\n\n","f6b7e978":"!pip install better_profanity \nfrom better_profanity import profanity","14d57388":"df = pd.read_csv(\"\/kaggle\/input\/sarcasm\/train-balanced-sarcasm.csv\")","faba6bc9":"df.head()","6aab35ca":"df['comment'] = df['comment'].dropna(axis=0)\n","1d0a4a3a":"df_sarcasm = df.loc[df['label']==1]\ndf_non_sarcasm = df.loc[df['label']==0]\n","9e3588b1":"nlp.max_length = 3000000  #Override the default allowed max length for a doc object\n\ndf_sarcasm = df_sarcasm.sample(50000,replace=False,random_state=1)\ndf_sarcasm['comment'] = df_sarcasm['comment'].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\ndf_sarcasm_text = df_sarcasm['comment'].tolist()\ndf_sarcasm_text = \" \".join(df_sarcasm_text)\n\nsarcasm_doc = nlp(df_sarcasm_text)\n\n\ndf_non_sarcasm  = df_non_sarcasm.sample(50000,replace=False,random_state=1)\ndf_non_sarcasm['comment'] = df_non_sarcasm['comment'].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\ndf_non_sarcasm_text = df_non_sarcasm['comment'].tolist()\ndf_non_sarcasm_text = \" \".join(df_non_sarcasm_text)\n\nnon_sarcasm_doc = nlp(df_non_sarcasm_text)","384c34f1":"def average(doc):\n    average_word_length =sum(len(word) for word in doc) \/ len(doc)\n    return (average_word_length)\n\nprint(f\"Average word length of sarcastic comments: {average(sarcasm_doc)}\")\nprint(f\"Average word length of non sarcastic comments: {average(non_sarcasm_doc)}\")","02148359":"print(f\"The average sentence length for sarcastic comments is: {(len(df_sarcasm['comment'].sum())\/len(df_sarcasm))}\")\nprint(f\"The average sentence length for non sarcastic comments is: {(len(df_non_sarcasm['comment'].sum())\/len(df_non_sarcasm))}\")","b72520aa":"def count_character_type(str):\n    specialChar = 0\n    for i in range(0, len(str)):\n        ch = str[i]\n        if ch == \"!\":\n            specialChar+=1\n        \n    return specialChar\n\nexcl_count_sarcasm = count_character_type(df_sarcasm_text)\nexcl_count_non = count_character_type(df_non_sarcasm_text)\n\nprint(f\"Count of exclamation marks for sarcastic comments: {excl_count_sarcasm}\")\nprint(f\"Count of exclamation marks for non sarcastic comments: {excl_count_non}\")","36d60c01":"def count_question_mark(str):\n    specialChar = 0\n    for i in range(0, len(str)):\n        ch = str[i]\n        if ch == \"?\":\n            specialChar+=1\n        \n    return specialChar\n\nqnmark_count_sarcasm = count_question_mark(df_sarcasm_text)\nqnmark_count_non = count_question_mark(df_non_sarcasm_text)\n\nprint(f\"Count of question marks for sarcastic comments: {qnmark_count_sarcasm}\")\nprint(f\"Count of question marks for non sarcastic comments: {qnmark_count_non}\")","293391f9":"def get_subjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n\ndf_sarcasm['Subjectivity'] = df_sarcasm['comment'].astype(str).apply(get_subjectivity)\ndf_non_sarcasm['Subjectivity'] = df_non_sarcasm['comment'].astype(str).apply(get_subjectivity)\n\nprint(f\"Subjectivity score for sarcastic comments:{df_sarcasm['Subjectivity'].sum()}\")\nprint(f\"Subjectivity score for for non sarcastic comments: {df_non_sarcasm['Subjectivity'].sum()}\")\n","1b9dacd7":"def pos_counter(doc):\n    verb_count = 0\n    adj_count = 0\n    pron_count = 0\n    noun_count=0\n    for tok in doc:\n        if tok.pos_ == \"VERB\":\n            verb_count=verb_count+1\n        elif tok.pos_ == \"ADJ\":\n            adj_count=adj_count+1\n        elif tok.pos_ == \"PRON\":\n            pron_count=pron_count+1\n        elif tok.pos_ == \"PROPN\":\n            noun_count=noun_count+1\n    return (verb_count,adj_count,pron_count,noun_count)\n\n\nsarcasm_pos_list = list(pos_counter(sarcasm_doc))\nnon_sarcasm_pos_list = list(pos_counter(non_sarcasm_doc))\n\nsarcasm_pos_df = {'Parts-of-speech':['Verb', 'Adjective', 'Pronoun', 'Proper Nouns'],\n        'Count':sarcasm_pos_list}\n\nnon_sarcasm_pos_df = {'Parts-of-speech':['Verb', 'Adjective', 'Pronoun', 'Proper Nouns'],\n        'Count':non_sarcasm_pos_list}\n\nsarcasm_pos_df = pd.DataFrame(sarcasm_pos_df)\nnon_sarcasm_pos_df = pd.DataFrame(non_sarcasm_pos_df)\n\nsarcasm_pos_df['Type'] = \"Sarcasm\"\nnon_sarcasm_pos_df['Type'] = 'Non Sarcasm'\n\njoined = sarcasm_pos_df.append(non_sarcasm_pos_df)\n\n\nsns.set_style('darkgrid')\nstyle.use('seaborn-poster')\n\nplot = sns.catplot(\n    data=joined, kind=\"bar\",\n    x=\"Parts-of-speech\", y=\"Count\", hue=\"Type\",\n    palette=\"summer\",height=10, aspect=11.7\/8.27, legend=False\n)\n\nplot.fig.suptitle(\"Part-of-Speech Composition\",\n                  fontsize=16, fontdict={\"weight\": \"light\"},fontfamily='Lato')\n\nplt.savefig('Part-of-speech.png')\n","0963a27c":"def count_profane_words(text):\n    count = 0\n    for sent in text.split():\n        if profanity.contains_profanity(sent) == True:\n            count = count+1\n    return count\n\nprint(f\"Count of profane words in sarcastic comments: {count_profane_words(df_sarcasm_text)}\")\nprint(f\"Count of profane words in non sarcastic comments: {count_profane_words(df_non_sarcasm_text)}\")","baedf4f9":"df['subreddit'].value_counts()","70d3ad9c":"def entity_wordcloud(df):\n    named_entities = []\n    for sent in df:\n        sent = nlp(sent)\n        for ent in sent.ents:\n            if ent.label_ == 'PERSON' or 'ORG' or 'GPE':\n                named_entities.append(ent.text)\n            \n    doc = \" \".join(named_entities)\n    \n    plt.figure(figsize=(10,5))\n    wordcloud = WordCloud(background_color=\"white\",\n                      max_words=45,\n                      max_font_size=30,\n                      random_state=42\n                     ).generate(doc)\n    plt.imshow(wordcloud)\n    plt.axis(\"off\")\n    plt.show()\n    ","563e8b55":"df_askreddit = df.loc[(df['subreddit']=='AskReddit') & (df['label']==1)]\nentity_wordcloud(df_askreddit['comment'].astype(str))\n","dea1924b":"df_worldnews = df.loc[(df['subreddit']=='worldnews') & (df['label']==1)]\nentity_wordcloud(df_worldnews['comment'].astype(str))\n","ff320247":"df_pcmasterrace = df.loc[(df['subreddit'] == 'pcmasterrace') & (df['label']==1)]\nentity_wordcloud(df_pcmasterrace['comment'].astype(str))\n","20d2baea":"df_league_of_legends = df.loc[(df['subreddit'] == 'leagueoflegends') & (df['label']==1)]\nentity_wordcloud(df_league_of_legends['comment'].astype(str))\n","b679c771":"df_politics = df.loc[(df['subreddit'] == 'politics') & (df['label']==1)]\nentity_wordcloud(df_politics['comment'].astype(str))","0329e102":"X_train,X_test,Y_train,Y_test = train_test_split(df['comment'].astype(str),df['label'],random_state=42)\nlr_clf = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2))),('clf',  LogisticRegression(random_state= 42, solver='liblinear'))])\nlr_clf.fit(X_train,Y_train)\n\n","c7c0ecb3":"print(f\"The accuracy on the training set is: {lr_clf.score(X_train,Y_train)}\")\nprint(f\"The accuracy on the test set is:  {lr_clf.score(X_test,Y_test)}\")","acb5884d":"Y_pred = lr_clf.predict(X_test)\nreport = classification_report(Y_pred,Y_test, output_dict=True)\nreport = pd.DataFrame(report).transpose()\nreport = report.rename({\"0\": \"Sarcastic Comments\", \"1\": \"Non Sarcastic Comments\"})\nreport","fef2afbe":"eli5.explain_weights(lr_clf)","6a671c7e":"#### That's it for EDA, let's move onto modelling.","9cb9f2e1":"### The 'comment' columns contains the actual text and the label column indicates sarcastic comments with 1 and non sarcastic comments with 0.","40b128f5":"### ---> AskReddit is a general forum to pose questions, but even here politics dominates. Guess,the hyper-polarizing 2016 election talk spilled into many subreddits\n\n### ---> Lot of terms indicating nationality, Asian, Chinese, British, not uncommon to see sarcastic comments target at specific demographics. ","1f1ac46e":"### Let's commence the EDA with a simple average of the word length for sarcastic and non sarcastic comments","615f99ff":"### ---> Same again, so sarcastic comments don't tend to be much shorter or longer than non sarcastic comments","4b28cfad":"### For performing EDA, we sample 50k data points at random from each dataframe, remove stopwords and create a spaCY doc object containing all the \"comments\"","007bc82f":"### Let's relegate our anlaysis to the top 5 subreddits, as only they have sufficient data points","c79146e3":"### ---> So, sarcastic comments have a higher degree of subjectivity overall, this is to be expected as the goal of sarcasm is antithetical to being factual","0ad63451":"<img src=\"https:\/\/www.missmalini.com\/content\/images\/size\/w760\/wp-content\/uploads\/2018\/02\/shutterstock_693688192.jpg\" style=\"width:500px;height:500px;img-align:center;\">","1b1dadab":"# __Introduction__\n\nThe Dataset: __Self-Annotated Reddit Sarcasm Dataset (SARC)__ is considered the gold standard for datasets used to train sarcasm detection models. Comments are collected from Reddit, spread across subreddits. Data collected is for the period ranging from January 2009 - April 2017. It has already underwent preprocessing, such as removing URL's, HTTP tags and only including ASCII characters. \n\nThe Notebook: Comprised of two parts, the first part is linguistically motivated EDA of both sarcastic and non sarcastic comments. The aim here is to surface any patterns that sarcastic comments might contain and see how it contrasts with non sarcastic comments. Second part is building a binary classification model trained to predict whether a comment is sarcastic or not. The model achieves an accuracy of __81%__ on the training set and __72%__ on the test set.","a053a3f3":"### \"better-profanity\" library is used to detect and count profane words, so let's install and import it","20516b93":"### ---> Korean, Chinese, American lot of nationalities, probably used as a negative connotator when players trash talk.\n\n### ---> TSM, Doubelift refer to League of Legend teams\/elite players, other terms like Yasuo are charcaters in the game's lore.","637cd79d":"### Sarcastic comments tend to have profanity interspersed within, let's get a count of both sarcastic and non sarcastic and see how they compare","c3c4ae2e":"### ---> Sarcastic comments have slightly more profane words, with their average sentence length being the same, its safe to assume that profane words are found more frequently in sarcastic comments","c811202f":"### ---> As expected from the Worldnews subreddit, most entities fall into the Geopolitical category\n\n### ---> Israel, China, Saudi Arabia are all very polarizing topics, not surprising they were the subject of many sarcastic comments\n\n### ---> Russian interferance in the 2016 election was a major topic covered extensively by the media\n\n### ---> Islam, Zionist, Muslim all keywords relating to topics that are perpetually contentious","7098d010":"### ---> Well the politics subreddit only contain terms pertaining to American politics.\n\n### ---> All the inflammatory news stories that characterized the 2016 election seems to be taking the centre stage again","76ba8deb":"### The distribution of the 4 most important parts-of-speech (Noun, Verb, Adjective,Pronoun) in sarcastic and non sarcastic comments might shed some light, so let's plot it as a grouped bar chart ","00b213c0":"### Using the head method to get a quick overview of the dataframe ","9cbf9670":"### Drop rows that have null values for the 'comment' column","ffbb66c6":"### ---> Sarcastic comments have a higer precision rate while Non Sarcastic comments have a higher recall rate; Non sarcastic comments could be literally anything and hence difficult to pinpont with precision.\n\n### ---> Sarcastic comments have slightly higher precision because they carry common distinguishing features. ","420df647":"### Let's use the Classification Report function in Sci-kit learn to get a better idea of how our model is doing.","7080f535":"### Read in the dataset as a DataFrame","bdcdb9e3":"### __League of Legends__ Subreddit","7729c231":"### --->  A substantial difference of more than 4000, so an excess of __\"!\"__ marks could be a good predictor to detect sarcasm","4ae6eeba":"### Now let's sort by subreddit and generate an entity WordCloud for each of them.\n\n### A subreddit revolves around a particular topic, so while we might not see much variance in the syntax of sarcastic comments across subreddits; there is a lot of variation involved in which entitites tend to be included frequently in sarcastic comments ","a88e768b":"### Let's do the same for the question mark (\"?\") token","cb28a629":"### __PC Master Race__ Subreddit","573f77ce":"### Scoring the model on the training and test set","3e1fccc8":"### Eli5 library will assist us in getting the words to which the model assigns the highest weights","1369d4aa":"### ---> Counts are close, subreddits like AskReddit are for posing questions, which could have contributed a disproportionate number of question marks for non sarcastic comments","39ce15e0":"### Importing required libraries \ud83d\udcda","5ed47a02":"### __Politics__ Subreddit\n","7c32d1dd":"### Splitting the dataframe into 2, one for sarcastic and one for non-sarcastic comments; for convenient EDA.","4f1320dc":"### __AskReddit__ Subreddit ","2269c423":"### ---> 60fps, 4k, Nvidia, Console; yeah pretty much the terms we expect to see in sarcastic comments used by PC gamers.\n\n### ---> Minecraft is the only term here that's also a game title, the subreddit probably must not be fond of it.","d9512a9d":"### __Worldnews__ Subreddit","7a144c64":"### Now let's compute the average sentence length for sarcastic and non sarcastic comments","100f7aca":"### Split the dataset into training and test set at a 80:20 ratio, then create TF-IDF vectors out of the corpus. The vectors are then passed onto a Logistic Regression model for classification","7c0d1405":"# __Conclusion__\n\nSarcasm detection is a difficult task; what gets defined as sarcasm and how\/when it's used varies greatly across cultures. Sarcasm also relies heavily on intonation by the speaker to make it clear that they are being sarcastic, making it more difficult for the ML model to detect. Syntactically, they are very similar to the average generic sentence, so syntax-based rules are rendered mostly ineffective. The current SOTA model, a Py-Torch based DL model reaches only 77% accuracy on its test set(trained and tested on this very same dataset). \n\nThere are few features of Sarcastic sentences that we managed to find here, such as a higher count of ***exclamation marks***, a propensity to include ***profane words***, very high ***degree of subjectivity*** (as sarcasm by definition is exaggerating to mock), key commonly occuring ***phrases and words*** \n\nThe way forward is to collate data from much varied sources(including real life settings, not just online forums), with sarcastic comments made by demographics that have little in common and on topics very different from each other. This injects the much needed variance we need and could help large DL-based models generalize better. ","0255f1f8":"### ---> The average word length of the English language is indeed 4, so not much deviation here","8a66f6d9":"### ---> There is a count difference of 3k for every part-of-speech here, probably due to non sarcastic comments being longer than sarcastic ones. \n\n### ---> We can safely assume that there is not much compositional difference between sarcastic and non sarcastic comments.  ","86dae1db":"<h1 style=\"text-align:center;color:green;\">Understanding Sarcasm<\/h1>","8b616c8d":"# __Modelling__ \u2699\ufe0f","1ddfe270":"### The Python NLP library, __TextBlob__ has a method to roughly quantify if a sentence is fact or opinion. \n\n### The method outputs a number ranging from 0 to 1, an output close to 0 indicates the sentence is highly factual and close to 1 means the sentence is highly subjective. Here, we take the sum for every comment, an overall higher sum then, will be indicative of higher subjectivity ","536b234d":"# __EDA__ \ud83d\udcca","3ef885a3":"### ---> Obviously has the highest weight among all the words in our corpus, _obviously_.\n\n### ---> Short phrases like 'yes because', 'how dare', 'good thing' contribute signficantly to the prediction too,not surprising as we hear them used often while being sarcastic\n\n### ---> Terms like 'shitlord', 'amirite' , 'duh' are more likely to be used online than in actual speech, but neverthless serve as good features\n\n### ---> Clever heuristics could be designed around phrases\/words like this to bolster precision; depending upon the context of the corpus source","10701657":"### Sarcastic comments often tend to contain excalmation marks(!), used to express incredulity, let's see if that's the case"}}