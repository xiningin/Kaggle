{"cell_type":{"91ffbab7":"code","8129a7af":"code","12259a85":"code","fc978cc4":"code","38e8c95d":"code","862f720e":"code","13015712":"code","cb8cf7b5":"code","e69dae29":"code","5d1f77c9":"code","688cfb17":"code","d7d59114":"code","56899aa9":"code","86f91697":"code","23360655":"code","84c2755a":"code","dfe18f54":"code","389676fd":"code","c229718f":"code","e49ea2fd":"code","44d3c411":"code","989b9b36":"code","84a70b91":"code","818a1b98":"code","ac900e73":"code","b7e2c77e":"code","6079ff76":"code","887eb2c0":"code","954d353c":"code","0c79ed45":"code","fca8b4c9":"code","21718605":"code","5e57311a":"code","c23a0342":"code","8ce3ace5":"code","a5528d8d":"code","d1e793cd":"code","6562e1d8":"code","db27d6d3":"code","5fd625c0":"code","33b9abc5":"code","89a926af":"code","354fcde7":"code","dab7ca7b":"code","bb03525b":"code","d3bd8ddd":"code","d4d844c9":"markdown","a90ebb6e":"markdown","a38a0f71":"markdown","241d631a":"markdown","30f4dfda":"markdown","a070aa93":"markdown","a81304fa":"markdown","9e68a5c2":"markdown","61f746bb":"markdown","b372d89f":"markdown","3f989dce":"markdown"},"source":{"91ffbab7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8129a7af":"import warnings  \nwarnings.filterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns","12259a85":"train_data = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/train.csv')\ntest_data = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/test.csv')\ntrain_data","fc978cc4":"test_data","38e8c95d":"train_data.isnull().sum()","862f720e":"print (\"Rows     : \" ,train_data.shape[0])\nprint (\"Columns  : \" ,train_data.shape[1])\nprint (\"\\nFeatures : \\n\" ,train_data.columns.tolist())\nprint (\"\\nMissing values :  \", train_data.isnull().any())\nprint (\"\\nUnique values :  \\n\",train_data.nunique())","13015712":"train_data.info()","cb8cf7b5":"train_data.head()","e69dae29":"train_data.tail()","5d1f77c9":"train_data.head().T","688cfb17":"train_data.describe()","d7d59114":"plt.figure(figsize=(12, 6))\nsns.heatmap(train_data.isnull())\nplt.show()","56899aa9":"plt.figure(figsize=(12, 6))\nsns.heatmap(train_data.isnull())\nplt.show()","86f91697":"sns.countplot(train_data['Vehicle_Age'])","23360655":"sns.countplot(train_data['Gender'])","84c2755a":"sns.countplot(train_data['Driving_License'])","dfe18f54":"sns.countplot(train_data['Previously_Insured'])","389676fd":"sns.countplot(train_data['Vehicle_Damage'])","c229718f":"sns.distplot(x=train_data['Age'])","e49ea2fd":"sns.distplot(x=train_data['Region_Code'])","44d3c411":"sns.kdeplot(\n   data=train_data, x=\"Annual_Premium\", hue=\"Response\",\n   fill=True, common_norm=False, palette=\"crest\",\n   alpha=.5, linewidth=0,\n)","989b9b36":"sns.kdeplot(\n   data=train_data, x=\"Policy_Sales_Channel\", hue=\"Response\",\n   fill=True, common_norm=False, palette=\"crest\",\n   alpha=.5, linewidth=0,\n)","84a70b91":"sns.kdeplot(\n   data=train_data, x=\"Vintage\", hue=\"Response\",\n   fill=True, common_norm=False, palette=\"crest\",\n   alpha=.5, linewidth=0,\n)","818a1b98":"sns.catplot(x='Gender', y='Age', hue = 'Response', kind = 'bar', data = train_data)","ac900e73":"sns.catplot(x='Driving_License', y='Previously_Insured', hue='Gender', kind = 'bar', data = train_data)","b7e2c77e":"sns.catplot(x='Vehicle_Age', y='Annual_Premium', hue='Response', kind = 'bar', data = train_data)","6079ff76":"sns.catplot(x='Vehicle_Damage', y='Vintage', hue='Response', kind = 'box', data = train_data)","887eb2c0":"sns.lineplot(data= train_data, x='Vintage',y='Annual_Premium', color='goldenrod')","954d353c":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_data['Age'] = le.fit_transform(train_data['Age'])\ntrain_data['Vehicle_Age'] = le.fit_transform(train_data['Vehicle_Age'])\ntrain_data['Vehicle_Damage'] = le.fit_transform(train_data['Vehicle_Damage'])\ntrain_data['Gender'] = le.fit_transform(train_data['Gender'])\ntest_data['Age'] = le.fit_transform(test_data['Age'])\ntest_data['Vehicle_Age'] = le.fit_transform(test_data['Vehicle_Age'])\ntest_data['Vehicle_Damage'] = le.fit_transform(test_data['Vehicle_Damage'])\ntest_data['Gender'] = le.fit_transform(test_data['Gender'])","0c79ed45":"del test_data['id']\ndel train_data['id']","fca8b4c9":"plt.figure(figsize = (10,10))\nplt.title(\"Correlation Plot\")\nsns.heatmap(train_data.corr(), linewidth = 5, annot = True, square = True, annot_kws={'size': 10}, cmap=\"YlGnBu\")","21718605":"fig, ax = plt.subplots(figsize=(18, 12))\ncorr = train_data.corr()\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\nax.text(-1.1, -0.7, 'Correlation between the Features', fontsize=20, fontweight='bold', fontfamily='serif')\nsns.heatmap(corr, mask=mask, annot=False, fmt='.2f', linewidth=0.2, cbar=True, cmap='coolwarm');","5e57311a":"# kendall\nfig, ax = plt.subplots(1, 3, figsize=(17 , 5))\n\n\n\ncorr = train_data.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nfor idx, method in enumerate(['pearson', 'kendall', 'spearman']):\n    sns.heatmap(train_data.corr(method=method), ax=ax[idx],\n            square=True, annot=True, fmt='.1f', center=0, linewidth=2,\n            cbar=False, cmap=sns.diverging_palette(240, 10, as_cmap=True),\n            mask=mask\n           ) \n    ax[idx].set_title(f'{method.capitalize()} Correlation', loc='left', fontweight='bold')     \n\nplt.show()","c23a0342":"a = train_data.drop(['Response'], axis=1)\na.corrwith(train_data['Response']).plot(kind='bar', figsize=(18,11), color=['salmon'])\nplt.title('Correlation b\/n target and Independant features')\nplt.xticks(size=15)\nplt.yticks(size=15)\nplt.show()","8ce3ace5":"from pandas.plotting import scatter_matrix\nfig = plt.figure()\nscatter_matrix(train_data,figsize =(25,25),alpha=0.9,diagonal=\"kde\",marker=\"o\");","a5528d8d":"\ntrain_data.hist(figsize=(25,25),bins=50);","d1e793cd":"!pip install sweetviz","6562e1d8":"   import sweetviz as sv\n   my_report = sv.analyze(train_data)\n   my_report.show_notebook(w=\"100%\", h=\"full\")","db27d6d3":"!pip install -U lightautoml","5fd625c0":"# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\nfrom lightautoml.utils.profiler import Profiler\n\nimport torch# Imports from our package\nfrom lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\nfrom lightautoml.dataset.roles import DatetimeRole\nfrom lightautoml.tasks import Task\nfrom lightautoml.utils.profiler import Profiler\n\nimport torch\nfrom tqdm.notebook import tqdm\nfrom copy import deepcopy\n\n# Installed libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","33b9abc5":"N_THREADS = 4 # threads cnt for lgbm and linear models\nN_FOLDS = 5 # folds cnt for AutoML\nRANDOM_STATE = 42 # fixed random state for various reasons\nTEST_SIZE = 0.2 # Test size for metric check\nTIMEOUT = 300 # Time in seconds for automl run\n\nnp.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","89a926af":"def acc_score(y_true, y_pred, **kwargs):\n    return accuracy_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\ndef f1_metric(y_true, y_pred, **kwargs):\n    return f1_score(y_true, (y_pred > 0.5).astype(int), **kwargs)\n\ntask = Task('binary', metric = f1_metric)\n\nroles = {\n    'target': 'Response',\n}","354fcde7":"%%time \nautoml = TabularUtilizedAutoML(task = task, \n                       timeout = TIMEOUT,\n                       cpu_limit = N_THREADS,\n                       general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n                       reader_params = {'n_jobs': N_THREADS})\noof_pred = automl.fit_predict(train_data, roles = roles)\nprint('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))","dab7ca7b":"%%time\ntest_pred = automl.predict(test_data)\nprint('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n\nprint('Check scores...')\nprint('OOF score: {}'.format(acc_score(train_data['Response'].values, oof_pred.data[:, 0])))","bb03525b":"submission = pd.read_csv('..\/input\/health-insurance-cross-sell-prediction\/sample_submission.csv')","d3bd8ddd":"submission['Response'] = (test_pred.data[:, 0] > 0.5).astype(int)\nsubmission.to_csv('lightautoml_utilized_300s_f1_metric.csv', index = False)\nsubmission.head()","d4d844c9":"**Scatter Plot**","a90ebb6e":"# **EDA**","a38a0f71":"# **Check For Missing Values**","241d631a":"# ***Installing and Importing library for LightAutoml***","30f4dfda":"# **Lable Encoding Categorical Data**","a070aa93":"# **Histogram For All**","a81304fa":"# ***EDA WITH SWEETVIZ LIBRARY***","9e68a5c2":"# **Read Dataset**","61f746bb":"#  ***Saving Sample***","b372d89f":"# ***EDA-Dataset***","3f989dce":"Done###############################"}}