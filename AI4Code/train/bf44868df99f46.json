{"cell_type":{"24b5767f":"code","d424029f":"code","e0dac64d":"code","1ff382b7":"code","c5b2d7b8":"code","ccb3b8ea":"code","35d12672":"code","259fe71b":"code","ed3eca0e":"code","e06dbea6":"code","c3bf5758":"code","b3fd53d1":"code","23169d34":"code","d8a365ab":"code","1dcd6c0c":"code","08e4284f":"code","565d7e3e":"code","758b1822":"code","217ed15a":"code","64983ebe":"code","847fa3a5":"code","b37b447c":"markdown","fb2bb23d":"markdown","8ed0fb75":"markdown","e1b32988":"markdown","f1a0d21f":"markdown","4066446d":"markdown","80ec7be4":"markdown","e27c9152":"markdown","0629b998":"markdown","a8741ebd":"markdown","3d504d12":"markdown","328abe14":"markdown"},"source":{"24b5767f":"import numpy as np\nfrom scipy.fft import fft, fftshift, ifft, ifftshift\nimport plotly.express as xp\nimport plotly.graph_objects as go\n\nimport matplotlib.pyplot as plt","d424029f":"from compressed_sensing_functions_py import plot_nyquist_demo\n\nplot_nyquist_demo()","e0dac64d":"l = 128\nn = 5\nsigma = 0.05\nnp.random.seed(42)\n\n#generate sparse signal\nx = np.concatenate( (np.ones(n) \/ n , np.zeros(l-n)) , axis=0 )\nx = np.random.permutation(x)\n# add random noise\ny = x + sigma * np.random.randn(l)\n\nfig = go.Figure()\nfig.add_trace(\n    go.Scatter( x=  np.arange(l) , y = x , name='x')\n)\nfig.add_trace(\n    go.Scatter( x=  np.arange(l) , y = y , name='y')\n)","1ff382b7":"fig = go.Figure()\nfor lam in [0.01,0.05, 0.1, 0.2]:\n    fig.add_trace(\n        go.Scatter( x=  np.arange(l) , y = 1\/(1+lam) * y , name=f\"lambda = {str(lam)}\")\n    )\nfig.show()","c5b2d7b8":"def soft_thresh(x, lam):\n    if ~(isinstance(x[0], complex)):\n        return np.zeros(x.shape) + (x + lam) * (x<-lam) + (x - lam) * (x>lam) \n    else:\n        return np.zeros(x.shape) + ( abs(x) - lam ) \/ abs(x) * x * (abs(x)>lam) ","ccb3b8ea":"\nfig = go.Figure()\nfor i, lam in enumerate([0.01,0.05, 0.1, 0.2]):\n    fig.add_trace(\n        go.Scatter( x=  np.arange(l) , y = soft_thresh(y, lam)+i\/10 , name=f\"lambda = {str(lam)}\")\n    )\nfig.show()","35d12672":"def fftc(x):\n    \"\"\"Computes the centered Fourier transform\"\"\"\n    return fftshift( fft(x) )\n\ndef ifftc(X):\n    \"\"\"Inverses the centered Fourier transform\"\"\"\n    return ifft( ifftshift(X) )","259fe71b":"X = fftc(x)\nY = fftc(y)\nfig = go.Figure()\nfig.add_trace( go.Scatter(x = np.arange(-l\/2,l-1),y=abs(X) , name='X') )\nfig.add_trace( go.Scatter(x = np.arange(-l\/2,l-1),y=abs(Y) , name='Y') )\nfig.show()","ed3eca0e":"#uniformly sampled k-space\nXu = 4 * X\nfor i in range(1,4):\n    Xu[i::4] = 0\n#reconstructed signal\nxu = ifftc(Xu)\n\n#randomly sampled k-space\nXr = 4 * X * np.random.permutation(np.repeat([1,0,0,0], l\/4) )\nxr = ifftc( Xr )\n\n#plot the comparison\nfig = go.Figure()\nfig.add_trace( go.Scatter(y=x*1.5, name='original signal (scaled)'))\nfig.add_trace( go.Scatter(y=xu.real, name='uniform sampling'))\nfig.add_trace( go.Scatter(y=xr.real, name='random sampling'))","e06dbea6":"# undersampled noisy signal in k-space and let this be first order Xhat\nY = 4 * fftc(x) * np.random.permutation(np.repeat([1,0,0,0], l\/4) )\nXhat = Y.copy()\n\n\n# Repeat steps 1-4 until change is below a threshold\neps = 1e-4\nlam = 0.05\n\ndef distance(x,y):\n    return abs(sum(x-y))\ndiff=[]\nerr = []\nitermax = 10000\nwhile True:\n    itermax -= 1\n    xhat_old = ifftc(Xhat)\n    xhat = soft_thresh(xhat_old, lam)\n    diff.append(distance(xhat, xhat_old))\n    err.append(distance(xhat.real\/4,x))\n    if ( diff[-1] < eps ) | ( itermax == 0 ):\n        break\n    Xhat = fftc(xhat)\n    Xhat[Y!=0] = Y[Y!=0]\n    \n    \n","c3bf5758":"fig = go.Figure()\nfig.add_trace( go.Scatter( y = x , name = 'true signal') )\nfig.add_trace( go.Scatter( y = ifftc(Y).real, name = 'reconstruction before noise reduction'))\nfig.add_trace( go.Scatter( y = xhat.real\/4, name = 'reconstructed after noise reduction'))\n","b3fd53d1":"fig = go.Figure()\nfig.add_trace( go.Scatter( y = err) )\nfig.update_layout( title = 'Error at each step' )\nfig.show()","23169d34":"fig = go.Figure()\nfig.add_trace( go.Scatter( y = diff) )\nfig.update_layout( title = 'Differential error at each step' )\nfig.show()","d8a365ab":"import pywt\nimport pywt.data","1dcd6c0c":"# Load image\noriginal = pywt.data.camera()\n\n# Wavelet transform of image, and plot approximation and details\ntitles = ['Approximation', ' Horizontal detail',\n          'Vertical detail', 'Diagonal detail']\ncoeffs2 = pywt.dwt2(original, 'bior1.3')\nLL, (LH, HL, HH) = coeffs2\nfig = plt.figure(figsize=(10, 10*4))\nfor i, a in enumerate([LL, LH, HL, HH]):\n    ax = fig.add_subplot(4, 1, i + 1)\n    ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n    ax.set_title(titles[i], fontsize=10)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfig.tight_layout()\nplt.show()","08e4284f":"undersample_rate = .5\nn = original.shape[0] * original.shape[1]\noriginal_undersampled = ( original.reshape(-1) \\\n    * np.random.permutation( \n        np.concatenate( \n            (np.ones( int( n * undersample_rate ) ), \n             np.zeros( int( n * ( 1-undersample_rate )) )) \n        ) \n    ) \n                        ).reshape(512,512)","565d7e3e":"fig,ax = plt.subplots(1,2,figsize=(20,10))\nax[0].imshow(original, cmap=plt.cm.gray)\nax[1].imshow(original_undersampled,cmap=plt.cm.gray)","758b1822":"def flat_wavelet_transform2(x, method='bior1.3'):\n    \"\"\"For a 2D image x, take the wavelet \"\"\"\n    coeffs = pywt.wavedec2( x, method )\n    output = coeffs[0].reshape(-1)\n    for tups in coeffs[1:]:\n        for c in tups:\n            output = np.concatenate((output, c.reshape(-1)))\n    return output\n\ndef inverse_flat_wavelet_transform2(X,  shape, method='bior1.3'):\n    shapes = pywt.wavedecn_shapes( shape , method)\n    nx = shapes[0][0]\n    ny = shapes[0][1]\n    n = nx * ny\n    coeffs = [X[:n].reshape(nx,ny) ]\n    for i, d in enumerate(shapes[1:]):\n        vals=list(d.values())\n        nx = vals[0][0]\n        ny = vals[0][1]\n        coeffs.append( (X[ n : n + nx * ny].reshape( nx, ny ), \n                        X[ n + nx * ny : n + 2 * nx * ny ].reshape( nx, ny ), \n                        X[ n + 2 * nx * ny : n + 3 * nx * ny ].reshape( nx, ny ))  )\n        n += 3 * nx * ny\n    return pywt.waverec2(coeffs, method)","217ed15a":"plt.figure(figsize=(15,10))\nplt.plot(flat_wavelet_transform2(original_undersampled, 'bior1.3')[-100:] )\nplt.title('A small sample of the wavelet transform')","64983ebe":"plt.figure(figsize=(15,10))\nplt.hist(flat_wavelet_transform2(original_undersampled, 'bior1.3') , range=(-300,300), bins=30)\nplt.title('A small sample of the wavelet transform')","847fa3a5":"methods = ['haar','coif1','coif2','coif3','bior1.1','bior1.3','bior3.1','bior3.3','rbio1.1','rbio1.3','rbio3.1','rbio3.3']\ndef distance(x,y):\n    return sum(abs(x.reshape(-1)-y.reshape(-1)))\n\n# undersampled noisy signal in image-space and let this be first order Xhat\ny = original_undersampled\n\n# Repeat steps 1-4 until change is below a threshold\neps = 1e-2\nlam = 100\nlam_decay = 0.995\nminlam = 1\n\nerr2=[]\n\n\nlam = 100\n\n\nxhat = y.copy()\nfor i in range(80):\n    method = 'sym3'\n    xhat_old = xhat\n    Xhat_old = flat_wavelet_transform2(xhat, method)\n    Xhat = soft_thresh(Xhat_old, lam)\n    xhat = inverse_flat_wavelet_transform2(Xhat, (512,512), method)\n    xhat[y!=0] = y[y!=0]   \n\n\n    xhat = xhat.astype(int)\n    xhat[xhat<0] = 0\n    xhat[xhat>255] = 255\n    err2.append(distance(original, xhat))\n    lam *= lam_decay \n#     if (distance(xhat, xhat_old)<eps):\n#         break\n\n\n\n    \nfig = plt.figure(figsize=(10,10))  \nplt.loglog(err2)\n\n\nfig,ax = plt.subplots(1,2,figsize=(20,10))\nax[0].imshow(original, cmap=plt.cm.gray)\nax[1].imshow(xhat,cmap=plt.cm.gray, vmin=0, vmax=255)","b37b447c":"## CS applied to 2d images\n\nAt this point, the tutorial starts talking about MRI aquisition in which \"images\" are aquired in k-space, which is not sparse, and converted into image space, which is also not sparse. However, images are very often sparse under some transformation. \n\nAs far as MR is concerned, it is hopefully sufficient to say that CS has made enabled certain image acquisition sequences much faster without a big loss of information. As this is a tutorial on compressed sensing and not MR physics, we will assume that the audience has mastered the concept of aquiring an undersampled signal in a non-sparse space to apply the principles of CS, and use this knowledge to apply CS directly to undersampled images.\n\n### Wavelet transform\/decomposition\n\nWhile images are not very sparse in the frequency domain (Fourier Transform), they are often sparse under a [wavelet](https:\/\/en.wikipedia.org\/wiki\/Wavelet) transformation. \n\nPyWavelets is the primary python library for doing wavelet transformations. In my opinion, it is not implemented very cleanly, so the illustration here of the wavelet transform is incomplete, but hopefully demonstrates the sparsity.","fb2bb23d":"## Sparse Signals and the $\\ell^1$ Norm\n\nLet's see what happens if instead of penalizing the $\\ell^2$ Norm, we penalize the $\\ell^1$ Norm: $$argmin\\frac{1}{2}||\\hat{x}-y||^2_1+\\lambda||\\hat{x}||_1 $$ \nThis has the closed-form solution $$\\hat{x} = \\begin{cases} y + \\lambda & (y<-\\lambda) \\\\ 0 & (|y|<\\lambda) \\\\ y - \\lambda & (y>\\lambda) \\end{cases}$$\n\nLet's see it in action:","8ed0fb75":"Many approaches for denoising and regularization use the Tychonov penalty to estimate thesignal from noisy data.  Specifically, they try to solve $$argmin\\frac{1}{2}||\\hat{x} - y||^2_2 + \\lambda \\frac{1}{2} ||\\hat{x}||^2_2 $$, where $||x||_2$ is the Euclidean Norm (or $\\ell^2 Norm$).\n\nConveniently, this has the following closed-form solution: $$\\hat{x}=\\frac{1}{1+\\lambda}y$$\n\nLet's look at what happens to our noisy signal for various lambdas.","e1b32988":"In compressed sensing, we undersample the measurements.  We measure a subset of k-space (Fourier space), $X_u=F_u x$ where $F_u$ is a Fourier transform evaluated only at a subset of frequency domain samples.  This is an underdetermined data set for which there is an infinite number of possible signals.  However,we do know that the original signal is sparse, so there is hope we will be able to reconstruct it.\n\nThe theory of compressed sensing suggests random undersampling.  To see why, we will lookat equispaced undersampling and compare it to random undersampling.  To do this we will undersample k-space by taking 32 equispaced samples, then compute the inverse Fourier transform, filling the missing data withzeroes, and multiply by 4 to correct for the fact that we have only 1\/4 the samples. We also undersample randomly, and compare the reconstructed signal for both cases.","f1a0d21f":"In order to do CS, we need a inversible transform function. Because PyWavelets implementation annoyingly returns tuples inside lists, we need to create our own transform functions, so that we can apply the soft_thresh function to it.","4066446d":"# An Introduction to Compressed Sensing\n\nThis notebook borrows heavily from the Michael Lustig's [Compressed Sensing Exercise](https:\/\/people.eecs.berkeley.edu\/~mlustig\/CS.html).\n\nCompressed Sensing might be the closest thing to magic there is when it comes to signal processing. Let's explore it together from the fundamentals to applications! \n\nLet's start with some background that will hopefully help you to realize why compressed sensing is so ground breaking.\n\nDisclaimer: I am not an expert in this field, and this notebook is partly an excercise for myself.\n\n## The Shannon-Nyquist Theorem\n\nIn the world of digital signal processing, the goal is to represent a continuous signal (such as audio or video) as a discrete set of values. Often, the values are sampled periodically. For example, pixels of an image sensor are usually evenly spaced, and audio is usually sampled at 44.1 kHz. The Shannon-Nyquist Theorem gives us a limit to the granularity of the original signal that can be captured by that sampling frequency (where frequency is used in the general sense, not only as an inverse time). Put simply, the highest frequency signal that can be captured by digital signal processing is half the frequency of the sampling. So 44.1 kHz audio sampling can not capture audio frequencies higher than 22.05 kHz. \n\nNow, that is NOT to say that these higher frequencies are filtered out. There is just aliasing of the data. \n\nLet's see these in action.\n\nStarting with a sinusoidal signal, we will sample it at different rates and see what conclusions we draw.","80ec7be4":"## Reconstruction from Randomly Sampled Frequency Domain Data\n\nInspired by the denoising example, we will add an $\\ell^1$ penalty and solve $$argmin\\frac{1}{2}||\\hat{X}-Y||^2_2+\\lambda||\\hat{x}||_1 $$ , where $\\hat{X} = F \\hat{x}$ the Fourier transform of the reconstructed signal, and Y are the samples aquired in Fourier space.\n\nNow  the  variables  are coupled  through  the  Fourier  transform,  and  there  is  no  closed-form  solution.   Therefore  we  will solve it iteratively applying soft-thresholding and constraining data consistency.  We initially set $\\hat{X}_0=Y$ , and implement the following iteration\n\n1. Compute the inverse Fourier transform to get an estimate of the signal  $\\hat{x}_i=F^{-1}\\hat{X}$\n2. Apply SoftThresh  $\\hat{x}_i = S( \\hat{x}_i, \u03bb)$ in the signal domain\n3. Compute the Fourier transform $\\hat{X}=F\\hat{x}_i$\n4. Enforce data consistency in the frequency domain $$\\hat{X} = \\begin{cases}\\hat{X}_i[j] & Y[j]=0 \\\\ Y[j] & otherwise  \\end{cases} $$\n5. Repeat until $||\\hat{x}_{i+1}\u2212\\hat{x}_i||< \\epsilon$\n","e27c9152":"### Application of CS to an image\n\nLet's start by undersampling our image (randomly!)","0629b998":"We can take a peak in the sparse domain to try to estimate the noise level for setting out threshold. \nAlso, sometimes learning can be improved by setting a decay on the lambda threshold as the noise starts going down.","a8741ebd":"## Random Frequency Domain Sampling and Aliasing\n\nThere is a strong connection between compressed sensing and denoising. We\u2019ll now explore this connection and the importance of incoherent sampling. First, let\u2019s set up the undersampled data.  To do so, let's compute the centered Fourier transform of the sparse signal, $X=Fx$ where $F$ is a Fourier transform operator.","3d504d12":"When our sampling frequency drops below twice the signal frequency, due to aliasing, we cannot detect the signal's true frequency. \n\n>\"The sampling theory of Shannon can be generalized for the case of nonuniform sampling, that is, samples not taken equally spaced in time. The Shannon sampling theory for non-uniform sampling states that a band-limited signal can be perfectly reconstructed from its samples if the average sampling rate satisfies the Nyquist condition\" - Wikipedia\n\n### Data wastage\n\nIn signal processing, the information of interest often (or almost always) has a much lower dimensionality than the data captured. For example, a 21 Megapixel sensor captures roughly 25MB of raw data, which can be compressed to about a 5MB jpeg file. JPEG is a lossy compression method (meaning the raw data cannot be fully reconstructed), but even lossless compression can significantly reduce a file's memory footprint. \n\nWith that in mind, we can reason that there should be a way to sample a signal in such a way that the compression is already built into the sampling method.\n\n\n## Sparsity \n\nBefore we start with compressed sensing, we\u2019ll look at sparse signal de-noising.  There\u2019s a strong connection between CS and denoising.  Here will attempt to denoise asparse signal that is corrupted by random noise.\n\nWe'll start by generating a 1x128 vector with 5 randomly placed non-zero coeficients, and then add some random noise with a $\\sigma=0.05$ to it.","328abe14":"The reconstructed signal from uniformly undersampled k-space is periodic in nature (we see a pattern repeated 4 times), whereas the reconstructed signal from the randomly undersampled k-space is not periodic. The randomly undersampled signal is very noisy, but we have a method of dealing with that.\n\nBy random undersampling, we\u2019ve turned the ill-conditioned problem into a sparse signal denoising problem.  However, the \u201cnoise\u201d is not really noise, but incoherent aliasing that is contributed by the signal itself.  Therefore, we might be able to EXACTLY recover the sparse signal."}}