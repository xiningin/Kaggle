{"cell_type":{"af4e8cbd":"code","f4d6dcf4":"code","57be8fc1":"code","6b8ef544":"code","fed76dbc":"code","c7b3911c":"code","6d65aff4":"code","099d41c5":"code","15f15877":"code","dcfc22ce":"code","05040def":"code","2bc6fcbe":"code","261e012d":"code","a6b89ec0":"code","02031239":"code","46a88ab9":"code","2f48ca9b":"code","db70719f":"code","6b80f5fc":"code","c4fbbb83":"code","faf7691a":"code","3fa2b8d6":"code","0685aeac":"code","0d8c1190":"code","6cd17045":"code","74662b71":"code","f0febaf3":"code","81b19b4e":"code","1ad1c9fd":"code","f358e77a":"code","997543ef":"code","6b448236":"code","0e57404f":"code","d6e15567":"code","7b59f681":"code","caad3301":"markdown"},"source":{"af4e8cbd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f4d6dcf4":"from keras.layers import Input, Lambda, Dense, Flatten, Dropout\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom keras.models import Sequential\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport os\nimport cv2","57be8fc1":"df = pd.read_csv('..\/input\/identifythedanceform\/train.csv')","6b8ef544":"df.head()","fed76dbc":"# resize all the images to this\nIMAGE_SIZE = [224, 224]","c7b3911c":"train_path = '..\/input\/identifythedanceform\/train'\ntest_path = '..\/input\/identifythedanceform\/test'\n","6d65aff4":"df['target'].value_counts()","099d41c5":"images = []\nlabels = list(df['target'])\nfor filename in list(df['Image']):\n    image = cv2.imread(os.path.join(train_path, filename))\n    image = cv2.resize(image, (224,224))\n    image = preprocess_input(image)\n    images.append(image)\n    ","15f15877":"images = np.array(images)\nlabels = np.array(labels)","dcfc22ce":"labels","05040def":"lb = LabelEncoder()\nlabels = lb.fit_transform(labels)\nprint(labels[:10])\nlabels = to_categorical(labels)\nprint(labels[:10])","2bc6fcbe":"(trainX, testX, trainY, testY) = train_test_split(images, labels,\n                                test_size=0.20, stratify=labels, random_state=42)","261e012d":"print(len(trainX))\nprint(len(trainY))\nprint(len(testX))\nprint(len(testY))\n","a6b89ec0":"testX.shape","02031239":"data_gen = ImageDataGenerator(\n    rescale = 1\/255.0,\n    rotation_range = 20,\n    zoom_range = 0.2,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    fill_mode = 'nearest',\n    horizontal_flip = True\n)","46a88ab9":"# add preprocessing layer to the fromt of VGG\nvgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","2f48ca9b":"# don't train existing weights\nfor layer in vgg.layers:\n    layer.trainable = False","db70719f":"# our layers - you can add more if you want\nx = Flatten()(vgg.output)\nx = Dense(1024, activation = 'relu')(x)\nx = Dropout(0.20)(x)\nprediction = Dense(8, activation='softmax')(x)","6b80f5fc":"# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)","c4fbbb83":"# view the structure of the model\nmodel.summary()","faf7691a":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer = 'adam',\n    metrics = ['accuracy']\n)","3fa2b8d6":"train_generator = data_gen.flow(trainX, trainY, batch_size=32)\ntest_generator = data_gen.flow(testX, testY, batch_size = 32)","0685aeac":"# Set a Learning Rate Annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n                                           patience=3,\n                                           verbose=1,\n                                           factor=0.5,\n                                           min_lr=0.00001)","0d8c1190":"history = model.fit_generator(train_generator,\n        validation_data = test_generator,\n        epochs = 100,\n        steps_per_epoch = len(train_generator),\n        validation_steps = len(test_generator),\n        callbacks = [learning_rate_reduction]\n)","6cd17045":"# loss\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss1')\n\n# accuracies\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AvvVal_acc1')","74662b71":"test_df = pd.read_csv('..\/input\/identifythedanceform\/test.csv')","f0febaf3":"test_df.head()","81b19b4e":"test_images = []\nfor filename in list(test_df['Image']):\n    image = cv2.imread(os.path.join(test_path, filename))\n    image = cv2.resize(image, (224,224))\n    image = preprocess_input(image)\n    test_images.append(image)","1ad1c9fd":"test_images = np.array(test_images)\n\n","f358e77a":"test_images.shape","997543ef":"test_labels = []","6b448236":"# create test labels \ndef create_test_labels():\n    for image in test_images:\n        image = cv2.resize(image, (224, 224))\n        image = image.reshape(-1,224,224,3)\n        image = preprocess_input(image)\n        predict = model.predict(image)\n        test_labels.append([image, predict])\n\ncreate_test_labels()\n","0e57404f":"Image = []\ntarget = []\nfor i, j in test_labels:\n    target.append(np.argmax(j))\n    Image.append(i)\ndf = pd.DataFrame(columns=['target'])\ndf['target'] = target\ndf['target'] = lb.inverse_transform(df['target'])\n","d6e15567":"datasets = pd.concat([test_df['Image'], df['target']], axis=1)\ndatasets.to_csv('sample_submission.csv', index=False)","7b59f681":"datasets","caad3301":"# Prediction !"}}