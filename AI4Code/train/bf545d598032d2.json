{"cell_type":{"3e2d25ec":"code","937fe1aa":"code","4eb8f105":"code","41a8a92c":"code","3919396b":"code","75a1eef7":"code","b683cee5":"code","bbae1425":"code","0c794553":"code","aa742e5a":"code","4436828e":"code","e7eac8f3":"code","cddb4030":"code","25420006":"code","87de1f02":"code","75ddabd3":"code","45461e38":"code","0556ced8":"code","153ee4d9":"code","868d8b04":"code","c14fdc35":"code","dcb330f2":"code","ba29b18d":"code","c656d01d":"code","81e02db5":"code","c3353cd5":"code","3a301a99":"code","910b312a":"code","182903c9":"markdown","d7167951":"markdown","e895f92c":"markdown","57788197":"markdown","a21edd5b":"markdown","99dd9b1f":"markdown","13e3827d":"markdown","ba0c8382":"markdown","7bb1c672":"markdown","5fe3da87":"markdown","69e1a468":"markdown","c509845e":"markdown","3fdaa36f":"markdown","d815d1ca":"markdown","b4ad5c14":"markdown","1d295e46":"markdown","d9a4cf1a":"markdown","51bc0e58":"markdown","0500100b":"markdown","ea42e3ed":"markdown","d7896278":"markdown","21b36565":"markdown","23247d40":"markdown","f77a219a":"markdown"},"source":{"3e2d25ec":"#View the distributio of categories in traning data\nimport json\nfrom collections import Counter\njson_file_path = '\/kaggle\/input\/cowboyoutfits\/train.json'\ndata = json.load(open(json_file_path, 'r'))\ndict_cat = {}\nfor cat in data[\"categories\"]:\n    dict_cat[cat[\"id\"]]= cat[\"name\"]\nlist_cat = []\nfor ann in data[\"annotations\"]:\n    list_cat.append(dict_cat[ann[\"category_id\"]])\nCounter(list_cat)","937fe1aa":"# Firstly, we must import some libs\nimport os\nimport numpy as np\nimport pandas as pd\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport json\nimport yaml\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE","4eb8f105":"# Split train dataset and test dataset according to annotation_id\nX = pd.DataFrame(data[\"annotations\"])\nY = pd.DataFrame(X[\"category_id\"])\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.1,random_state=1,stratify = Y)\nCounter(list(y_train[\"category_id\"]))","41a8a92c":"# Using the SOMTE to inflate the imbanlanced data, such as 'Belt'\nx_train_only_id = pd.DataFrame(x_train['id'])\nX_SMOTE, Y_SMOTE = SMOTE().fit_resample(x_train_only_id.values,y_train.values)\nCounter(Y_SMOTE)","3919396b":"# Let's install Yolov5 to exploring a wonderful trip \n%cd \/kaggle\/working\n!git clone https:\/\/github.com\/ultralytics\/yolov5\n%cd \/kaggle\/working\/yolov5\n%pip install -r requirements.txt","75a1eef7":"# Storing some dictionaries, {annotation_id:nubers}; {image_id:images in train.json}\ndf_annid = pd.DataFrame(X_SMOTE,columns=['ann_id'])\nprint(df_annid.head())\n# Storing the inflated annotations\ndict_annid = {}\nfor i,row in df_annid.iterrows():\n    annid = row['ann_id']\n    if annid in dict_annid:\n        dict_annid[annid] += 1\n    else:\n        dict_annid[annid] = 1\n# Storing the imageid and its json data\ndict_imgid = {}\nfor img in data[\"images\"]:\n    id = img['id']\n    dict_imgid[id] = img","b683cee5":"# Transfer the categories to continuous ids\ncate_id_map = {}\nfor i, category in enumerate(data['categories']):     \n    cate_id_map[category['id']] = i\n    #id_cat[i] = category['id']\ncate_id_map","bbae1425":"# convert the bounding box from COCO to YOLO format.\ndef cc2yolo_bbox(img_width, img_height, bbox):\n    dw = 1. \/ img_width\n    dh = 1. \/ img_height\n    x = bbox[0] + bbox[2] \/ 2.0\n    y = bbox[1] + bbox[3] \/ 2.0\n    w = bbox[2]\n    h = bbox[3]\n \n    x = x * dw\n    w = w * dw\n    y = y * dh\n    h = h * dh\n    return (x, y, w, h)","0c794553":"# Create the path for storing the txt files for yolov5\nyolo_anno_path = '\/kaggle\/working\/training\/yolo_anno\/'\nif not os.path.exists(yolo_anno_path):\n    os.makedirs(yolo_anno_path)","aa742e5a":"# Building the train and validation images list\ndict_imgid_count = {} # this dictionary records how many images are the same\nf = open('\/kaggle\/working\/train_valid.csv','w')\nf.write('id,file_name,split\\n')\nfor i in tqdm(range(len(data['annotations']))):\n    annid = data['annotations'][i]['id']\n    img_id = data['annotations'][i]['image_id']\n    filename = dict_imgid[img_id]['file_name']\n    yolo_txt_name = filename.split('.')[0] + '.txt' #remove .jpg\n    img_width = dict_imgid[img_id]['width']\n    img_height = dict_imgid[img_id]['height']\n    if annid in dict_annid:\n        temp_count = 1\n        if img_id in dict_imgid_count:\n            dict_imgid_count[img_id] += 1\n            temp_count = dict_imgid_count[img_id]\n        else:\n            dict_imgid_count[img_id] = 1        \n        arr = str(filename).split('.')\n        filename = arr[0] + '_' + str(temp_count) + '.' + arr[1]\n        f.write('{},{},train\\n'.format(img_id, filename))    \n    \n    yolo_txt_file = open(os.path.join(yolo_anno_path, yolo_txt_name), 'w')    \n    for anno in data['annotations']:\n        if anno['image_id'] == img_id:\n            yolo_bbox = cc2yolo_bbox(img_width, img_height, anno['bbox']) # \"bbox\": [x,y,width,height]        \n            yolo_txt_file.write('{} {} {} {} {}\\n'.format(cate_id_map[anno['category_id']], yolo_bbox[0], yolo_bbox[1], yolo_bbox[2], yolo_bbox[3]))\n    yolo_txt_file.close()\n\n# write validation files into the file train.csv\nfor i,row in x_test.iterrows():\n    img_id = row['image_id']\n    filename = dict_imgid[img_id]['file_name']\n    f.write('{},{},valid\\n'.format(img_id, filename))\n\nf.close()","4436828e":"# Then we got the training and tesing dataframe\ndf = pd.read_csv('\/kaggle\/working\/train_valid.csv')\nprint(df)","e7eac8f3":"# Preparing the data and structure directories for Yolov5\nos.makedirs('\/kaggle\/working\/training\/images\/train', exist_ok=True)\nos.makedirs('\/kaggle\/working\/training\/images\/valid', exist_ok=True)\n#\nos.makedirs('\/kaggle\/working\/training\/labels\/train', exist_ok=True)\nos.makedirs('\/kaggle\/working\/training\/labels\/valid', exist_ok=True)","cddb4030":"# copy the image files and annotations txt files to relevant folders\nfor i in tqdm(range(len(df))):\n    row = df.loc[i]\n    #name = row.file_name.split('.')[0]\n    \n    name_count = row.file_name.split('.')[0]\n    name = name_count.split('_')[0]\n    #if i<10:\n    #    print(name)\n    if row.split == 'train':        \n        copyfile(f'\/kaggle\/input\/cowboyoutfits\/images\/{name}.jpg', f'\/kaggle\/working\/training\/images\/train\/{name_count}.jpg')\n        copyfile(f'\/kaggle\/working\/training\/yolo_anno\/{name}.txt', f'\/kaggle\/working\/training\/labels\/train\/{name_count}.txt')\n    else:        \n        copyfile(f'\/kaggle\/input\/cowboyoutfits\/images\/{name}.jpg', f'\/kaggle\/working\/training\/images\/valid\/{name}.jpg')\n        copyfile(f'\/kaggle\/working\/training\/yolo_anno\/{name}.txt', f'\/kaggle\/working\/training\/labels\/valid\/{name}.txt')","25420006":"# Firstly we create the yaml file\ndata_yaml = dict(\n    train = '\/kaggle\/working\/training\/images\/train\/',\n    val = '\/kaggle\/working\/training\/images\/valid\/',\n    nc = 5,\n    names = ['belt', 'sunglasses', 'boot', 'cowboy_hat', 'jacket']\n)\n\n# we will make the file under the yolov5\/data\/ directory.\nwith open('\/kaggle\/working\/yolov5\/data\/data.yaml', 'w') as outfile:\n    yaml.dump(data_yaml, outfile, default_flow_style=True)\n    \n%cat \/kaggle\/working\/yolov5\/data\/data.yaml # show your YAML file","87de1f02":"# Before GO TRAIN, wandb must be set up and run\n# Install W&B \n##!pip install -q --upgrade wandb\n# Login with token, follow with the guide\n##import wandb\n##wandb.login()\n\n# For simply showing the code, I turn off W&B\nimport wandb\n!wandb off","75ddabd3":"# For showing the example code, I only select yolov5s model and 1 epoch to run.\nBATCH_SIZE = 16\nEPOCHS = 1 \nMODEL = 'yolov5s.pt' # this specify the model for training, you can use yolov5s.pt, yolov5l.pt, yolov5x.pt, etc.","45461e38":"# GO TRAIN\n!python train.py --batch {BATCH_SIZE} \\\n                 --epochs {EPOCHS} \\\n                 --data data.yaml \\\n                 --weights {MODEL} \\\n                 --save_period 1\\\n                 --project cowboy-detection\\\n                 --name exp","0556ced8":"# In the Dev phase, we will only use the valid data for predicition. \n# Don't forget change it to test data in the Final pahse.\nvalid_df = pd.read_csv('\/kaggle\/input\/cowboyoutfits\/valid.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/cowboyoutfits\/test.csv')\nvalid_df.head()","153ee4d9":"# make directory to store the validation data.\nos.makedirs('\/kaggle\/working\/inference\/valid', exist_ok=True)\nos.makedirs('\/kaggle\/working\/inference\/test', exist_ok=True)","868d8b04":"# copy the validation image to inference folder for detection process\nfor i in tqdm(range(len(valid_df))):\n    row = valid_df.loc[i]    \n    name = row.file_name.split('.')[0]\n    copyfile(f'\/kaggle\/input\/cowboyoutfits\/images\/{name}.jpg', f'\/kaggle\/working\/inference\/valid\/{name}.jpg')","c14fdc35":"VALID_PATH = '\/kaggle\/working\/inference\/valid\/'\n#MODEL_PATH = '\/kaggle\/working\/yolo\/cowboy-detection\/exp5\/weights\/best.pt'\nMODEL_PATH = '\/kaggle\/input\/bestmodelweights\/exp8-m-100ep-withonesplit-best.pt'\nIMAGE_PATH = '\/kaggle\/input\/cowboyoutfits\/images\/'","dcb330f2":"# Let's begin the amazing time to detect the cowboy outfits objects\n!python detect.py --weights {MODEL_PATH} \\\n                  --source {VALID_PATH} \\\n                  --conf 0.005 \\\n                  --iou-thres 0.45 \\\n                  --save-txt \\\n                  --save-conf \\\n                  --augment","ba29b18d":"# If you have run more than one times of detect.py, \n# the name of 'exp' in the path will be changed for storing the detecting results.\nPRED_PATH = '\/kaggle\/working\/yolov5\/runs\/detect\/exp\/labels\/'\n\n# list our prediction files path\nprediction_files = os.listdir(PRED_PATH)\nprint('Number of test images with detections: ', len(prediction_files))","c656d01d":"# convert yolo to coco annotation format\ndef yolo2cc_bbox(img_width, img_height, bbox):\n    x = (bbox[0] - bbox[2] * 0.5) * img_width\n    y = (bbox[1] - bbox[3] * 0.5) * img_height\n    w = bbox[2] * img_width\n    h = bbox[3] * img_height\n    \n    return (x, y, w, h)","81e02db5":"# reverse the categories numer to the origin id\nre_cate_id_map = dict(zip(cate_id_map.values(), cate_id_map.keys()))\nprint(re_cate_id_map)","c3353cd5":"def make_submission(df, PRED_PATH, IMAGE_PATH):\n    output = []\n    for i in tqdm(range(len(df))):\n        row = df.loc[i]\n        image_id = row['id']\n        file_name = row['file_name'].split('.')[0]\n        if f'{file_name}.txt' in prediction_files:\n            img = Image.open(f'{IMAGE_PATH}\/{file_name}.jpg')\n            width, height = img.size\n            with open(f'{PRED_PATH}\/{file_name}.txt', 'r') as file:\n                for line in file:\n                    preds = line.strip('\\n').split(' ')\n                    preds = list(map(float, preds)) #conver string to float\n                    cc_bbox = yolo2cc_bbox(width, height, preds[1:-1])\n                    result = {\n                        'image_id': image_id,\n                        'category_id': re_cate_id_map[preds[0]],\n                        'bbox': cc_bbox,\n                        'score': preds[-1]\n                    }\n\n                    output.append(result)\n    return output","3a301a99":"sub_data = make_submission(valid_df, PRED_PATH, IMAGE_PATH)\nop_pd = pd.DataFrame(sub_data)\nop_pd.sample(10)","910b312a":"import zipfile \nop_pd.to_json('\/kaggle\/working\/answer.json',orient='records')\nzf = zipfile.ZipFile('\/kaggle\/working\/sample_answer.zip', 'w')\nzf.write('\/kaggle\/working\/answer.json', 'answer.json')\nzf.close()","182903c9":"# Preface","d7167951":"I have tried all models including yolov5 S M L X with default hyperparameters, with trainning epochs are all 100. However, the best result in these models was from yolov5 M(yolov5m.pt). And even I enlarged the epoch times to 200 with model yolov5 M, the result was worsened than 100 epochs training in model yolov5 M. ","e895f92c":"Then, we will get the balanced training data by using SMOTE. And each category will has the same number of annotations.","57788197":"We can see from the above graph, that the distribution of category data is extremely imbalanced in this competition. Actually, in the training data, there are only 25 'Belt' category bboxes, while the 'Sunglasses' and 'Jacket' are in all more than 2000 bboxes. <br>\nSo it's a big challege for us to do machine learning and model training.","a21edd5b":"## Finally, got your submitting zip file.","99dd9b1f":"\nIn this notebook, I will apply the second technique to inflate the training data to reduce the bias from the imbalanced dataset. But firstly let me briefly introduce the resampling techniques.<br>\n1. Under-sampling<br>\nIt means balances the dataset by reducing the size of the abundant class. This method is used when quantity of data is sufficient. By keeping all samples in the rare class and randomly selecting an equal number of samples in the abundant class, a balanced new dataset can be retrieved for further modelling.<br>\n2. Over-sampling<br>\nOn the contrary, oversampling is used when the quantity of data is insufficient. It tries to balance dataset by increasing the size of rare samples. Rather than getting rid of abundant samples, new rare samples are generated by using e.g. repetition, bootstrapping or SMOTE (Synthetic Minority Over-Sampling Technique) <br>\n3. Customs Loss Function<br>\nIt means we can change weight of loss to account for imbalance. Taking log function as an example:<br>\n$\u2013(x*logp)+(1-x)log\u2061(1-p))$, in which x is true label, p means prediction\nWhile the custom loss function transfers the log function into:<br>\n$A*x*log\u2061(p)+(1-x)log\u2061(1-p)$,\n$A$ means how is the ratio we want to balance the dataset. So for the imbalaced dataset, we should relatively change our loss function to make our prediction more precisely.","13e3827d":"# Imbalanced Data Processing","ba0c8382":"### Amazing Detection Objects","7bb1c672":"##### Here you can change many parameter such as ***conf*** and ***iou-thres***. <br>\nIn my experiments, when ***conf*** changed from 0.546 to 0.005, it will improve my dev result 2-3 percent.","5fe3da87":"![image.png](attachment:d526af58-13e6-449a-a3c2-ecb579b7e865.png)","69e1a468":"Note that there is no absolute advantage of one resampling method over another. Application of these two methods depends on the use case it applies to and the dataset itself. A combination of over- and under-sampling is often successful as well.\nIn this competition, I only apply over-sampling, which means I amplify the least data based on the quantities of the biggest dataset. I repeated the least dataset over and over to reach the largest dataset by using SMOTE.","c509845e":"There are 3 kinds of techniques to deal with imbalanced data: <br>\n* under-sampling\n* over-sampling\n* Customs Loss Function","3fdaa36f":"Firstly, I want to thank Xichao Wang (https:\/\/www.kaggle.com\/sheepwang), whose code was my work basis. And I learn a lot from the communication with Xichao Wang via email. <br>\nBase on the code of Xichao Wang, I balance the data by using SMOTE and fine-tuning some parameters such as ***conf*** and ***iou-thres*** in detect.py. <br>\nSecondly, I want to thank my teammate jordon2000 (https:\/\/www.kaggle.com\/jordon2000), who provided great effort for coding support and GPU resource.<br>\nEven though this is a competition, but the original target given by Professor Mu Li is that we can communicate here together, and learn from each other. I hope that through this platform, we can learn a lot from others.<br>\nThere are so many excellent talents here that I can learn how to code from scratch. I hope that we can further communicate and learn from each other. ","d815d1ca":"<span style=\"color: #E45D00; font-family: Segoe UI; font-size: 1.9em; font-weight: 300;\">Overview<\/span>\n\n&nbsp;&nbsp;\u2705Imbalanced Data Processing<br>\n&nbsp;&nbsp;\u2705Experience of using YOLOv5<br>\n&nbsp;&nbsp;\u2705Train the YOLOv5 model<br>\n&nbsp;&nbsp;\u2705Inference and detect cowboy outfits objects<br>\n&nbsp;&nbsp;\u2705Make Submission<br>\n\n    ","b4ad5c14":"# Experience of using YOLOv5 ","1d295e46":"# Make Submission","d9a4cf1a":"### Now the numbers of all categories training data are the same and balanced.","51bc0e58":"### Choose some parameters for training\n> ##### For showing the code example, I only train one time. \n> ##### In my best training parameters, batch_size=24, epochs=100 and model=yolov5m.pt","0500100b":"##### In the following function ***train_test_split***, the parameter ***stratify*** can split all categories (such as 'Belt', 'Jacket') in this parameter into train set and test set respectly.","ea42e3ed":"# Train the YOLOv5 model","d7896278":"# Inference and detect cowboy outfits objects","21b36565":"# Preparing txt files and image files for YOLOv5","23247d40":"# Data format transfering (from COCO to YOLO)","f77a219a":"##### Here, by using {MODEL_PATH}, you could use your trained model to inference and detect objects.<br> \nHowever, Kaggle has made a limitation for free users, when your training time reach to 6 hours, you cannot save your notebook. And when your training time reached to 9 hours, your training will be stopped by kaggle immediately. \n##### So I only use my best trained model to show the code, and you can use your trained model or any other trained model in inference phrase."}}