{"cell_type":{"9f4731d9":"code","2e88a8d2":"code","bf5f0fde":"code","47aa0131":"code","c387666f":"code","552b8acb":"code","f6f51f25":"code","0c29a78f":"code","024e2f44":"code","ba820fa7":"code","277fa32a":"code","04783def":"markdown"},"source":{"9f4731d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2e88a8d2":"from google.colab import drive\ndrive.mount('\/content\/drive')","bf5f0fde":"#%cd \/content\/drive\/MyDrive\/super-ai\/level2\/week7\n#%cd wazzadu\/\n# !gdown --id 1rKTJTh8J3tR--W_KklZkF61j11ygZ0kq\n# !mkdir wazzadu\n# !mv \"\/content\/drive\/My Drive\/super-ai\/level2\/week7\/wazzadu_img_train.zip\" \"\/content\/drive\/My Drive\/super-ai\/level2\/week7\/wazzadu\/wazzadu_img_train.zip\"\n# %cd wazzadu\/\n# !unzip wazzadu_img_train.zip\n# !unzip wazzadu.zip\n# !mkdir images_test\n# upload test_images","47aa0131":"import pandas as pd\nimport numpy as np","c387666f":"def path_preprocess(path):\n  return 'images\/'+path.split('\/')[-1]\n\ndf_train = pd.read_csv('train.csv', encoding='utf8')\ndf_train['image_path'] = df_train.apply(lambda x: path_preprocess(x.image_path), axis=1)\n\ndf_cat = pd.read_csv('dim_cat_subcat_tag_key.csv', encoding='utf8')\n","552b8acb":"!pip install git+https:\/\/github.com\/openai\/CLIP.git\n!gdown --id 1Ovj3dQ9ZEDvSNj0aFQ8xjDteq0l6B9g3\n!unzip pic.zip","f6f51f25":"import torch\nimport clip\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport numpy as np\nimport os\nimport os.path\nimport numpy as np\nimport pickle\nfrom typing import Any, Callable, Optional, Tuple\n\nfrom torchvision.datasets.vision import VisionDataset\nfrom torchvision.datasets.utils import check_integrity, download_and_extract_archive\n\ndef path_preprocess(path): return 'images\/'+path.split('\/')[-1]\n# def path_preprocess_test(path): return 'images_test\/'+path.split('\/')[-1]\ndef path_preprocess_test(path): return 'pic\/'+path.split('\/')[-1]\ndef rectangle_crop(img, bl_x, br_x, tl_y, bl_y):\n    width, height = img.size\n    x_start = int(width * bl_x)\n    x_end = int(width * br_x)\n    y_start = int(height * tl_y)\n    y_end = int(height * bl_y)\n    crop_img = img.crop((x_start, y_start, x_end, y_end))\n    # crop_img = img[y_start:y_end, x_start:x_end]\n    return crop_img\n\nclass Wazadu(VisionDataset):\n    # base_folder = 'cifar-10-batches-py'\n    # url = \"https:\/\/www.cs.toronto.edu\/~kriz\/cifar-10-python.tar.gz\"\n    # filename = \"cifar-10-python.tar.gz\"\n    # tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n    # train_list = [\n    #     ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n    #     ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n    #     ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n    #     ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n    #     ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n    # ]\n\n    # test_list = [\n    #     ['test_batch', '40351d587109b95175f43aff81a1287e'],\n    # ]\n    # meta = {\n    #     'filename': 'batches.meta',\n    #     'key': 'label_names',\n    #     'md5': '5ff9c542aee3614f3951f8cda6e48888',\n    # }\n\n    def __init__(\n            self,\n            root: str,\n            train: bool = True,\n            transform: Optional[Callable] = None,\n            target_transform: Optional[Callable] = None,\n            sample_num: int = None,\n            random_num: int = None,\n    ) -> None:\n\n        super(Wazadu, self).__init__(root, transform=transform,\n                                      target_transform=target_transform)\n\n        self.train = train  # training set or test set\n        self.random_num = random_num\n        self.sample_num = sample_num\n\n        df_train = pd.read_csv(root, encoding='utf8')\n\n        self.data: Any = []\n        self.targets = []\n        self.crop_point = []\n\n        if self.train:\n            df_dim = pd.read_csv(\"dim_cat_subcat_tag_key.csv\", encoding='utf8', skiprows=1) #if load from kaggle row1 is show file name\n            df_train.rename(columns = {'subcategory_id':'subcate_id'}, inplace = True)\n            df_train.rename(columns = {'tag_name':'tag'}, inplace = True)\n            df_train = df_train.fillna(0)\n            df_dim = df_dim.fillna(0)\n            df_train = pd.merge( df_train, df_dim, how ='left', left_on=['subcate_id','tag'], right_on=['subcate_id','tag'])\n            if self.sample_num is not None:\n                df_train = df_train.groupby('key').sample(self.sample_num, random_state = self.random_num)\n            df_train['image_path'] = df_train.apply(lambda x: path_preprocess(x.image_path), axis=1)\n            self.data = df_train['image_path'].tolist()\n            self.targets = df_train['key'].tolist()\n        else:\n            df_train['url'] = df_train.apply(lambda x: path_preprocess_test(x.url), axis=1)\n            self.data = df_train['url'].tolist()\n            self.crop_point = [(float(row['tl_x']), float(row['tl_y']), float(row['tr_x']), float(row['tr_y']), float(row['bl_x']), float(row['bl_y']), float(row['br_x']), float(row['br_y'])) for _,row in df_train.iterrows()]\n            self.targets = df_train['url'].tolist()#df_train['cate'].apply(lambda x: int(x[1])).tolist()\n        # print(self.data)\n\n    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n        \"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"\n        # print('Index',index)\n        img, target = self.data[index], self.targets[index]\n\n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.open(img)\n\n        if not self.train:\n            img = rectangle_crop(img, self.crop_point[index][4], self.crop_point[index][6], self.crop_point[index][1], self.crop_point[index][5])\n                                 #self.bl_x, self.br_x, self.tl_y, self.bl_y)\n\n        # display(img)\n        if self.transform is not None:\n            img = self.transform(img)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, target\n\n    def __len__(self) -> int:\n        return len(self.data)\n\n    def extra_repr(self) -> str:\n        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")\nimport os\nimport clip\nimport torch\n\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom torch.utils.data import DataLoader\n# from torchvision.datasets import CIFAR100\nfrom tqdm import tqdm\nimport os\nimport clip\nimport torch\n\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom torch.utils.data import DataLoader\n# from torchvision.datasets import CIFAR100\nfrom tqdm import tqdm\n\n# Load the model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load('ViT-B\/32', device)\n\ntrain =  Wazadu('train.csv', train=True, transform=preprocess, sample_num=None, random_num=40)\ntest =  Wazadu('test.csv', train=False, transform=preprocess)\n\ndef get_features(dataset):\n    all_features = []\n    all_labels = []\n\n    with torch.no_grad():\n        for images, labels in tqdm(DataLoader(dataset, batch_size=100)):\n            features = model.encode_image(images.to(device)) ###\n\n            all_features.append(features)\n            all_labels.append(labels)\n    return all_features, all_labels \n    # return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()\n\n# Calculate the image features\n#train_features, train_labels = get_features(train)\ntest_features, test_labels = get_features(test)","0c29a78f":"train_features_np = torch.cat(train_features).cpu().numpy()\ntrain_labels_np = np.asarray([j for i in train_labels for j in i])\ntest_features_np = torch.cat(test_features).cpu().numpy()\ntest_labels_np = np.asarray([j for i in test_labels for j in i])","024e2f44":"# Perform logistic regression\nclassifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\nclassifier.fit(train_features_np, train_labels_np)\n\n# Evaluate using the logistic regression classifier\npredictions = classifier.predict(train_features_np)\naccuracy = np.mean((train_labels_np == predictions).astype(np.float)) * 100.\nprint(f\"Accuracy = {accuracy:.3f}\")\ntest_predictions = classifier.predict(test_features_np)","ba820fa7":"sub_list = []\ndf_sub = pd.read_csv('Sample-Submission.csv', encoding='utf8')\nfor idx, i in enumerate(df_sub.Answer):\n  # use from kaggle\n  #if idx <= 12:\n     sub_list.append(i)\n  if idx < len(test_predictions):\n    sub_list.append(test_predictions[idx])\n  else:\n    sub_list.append('0')\n    \n\ndf_sub['Answer2'] = sub_list\ndisplay(df_sub[df_sub['Answer'].notnull()])","277fa32a":"df_sub = df_sub[['id', 'Answer2']]\ndf_sub.rename(columns={'Answer2': 'Answer'}, inplace=True)\ndf_sub.to_csv('clip_logistic_1.csv', encoding='utf8', index=False)","04783def":"> You can see all in https:\/\/colab.research.google.com\/drive\/11238pVc_KccdrwaZ1gzkWN7SC8sXM8Gv?usp=sharing"}}