{"cell_type":{"57637e02":"code","aaefa524":"code","bd73361e":"code","470dcb60":"code","d546c701":"code","fedf9ae8":"code","c335a491":"code","7f20b916":"code","e1b6a704":"code","11492430":"code","a45453c3":"code","5a883412":"code","9102ba92":"code","fa08a079":"code","4e752b36":"code","7181b3e5":"code","0363ae30":"markdown","b6d33818":"markdown","a7a09ee2":"markdown","11ea4e76":"markdown","df542cc0":"markdown","5989bfc6":"markdown","2a72ff3a":"markdown","9582d654":"markdown","175b1ad6":"markdown","9a6abf56":"markdown"},"source":{"57637e02":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","aaefa524":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras import backend as K\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization\nfrom keras.activations import softmax, relu\nfrom keras.utils import to_categorical\nfrom keras.datasets import mnist\nfrom keras.callbacks import ReduceLROnPlateau, Callback, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras.optimizers import Adam\nfrom keras.initializers import RandomUniform, glorot_uniform\nfrom keras.constraints import max_norm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom sklearn import preprocessing\n\n\n%matplotlib inline","bd73361e":"df = pd.read_csv(\"..\/input\/devanagari-character-set\/data.csv\")","470dcb60":"char_names = df.character.unique()  \nrows =10;columns=5;\nfig, ax = plt.subplots(rows,columns, figsize=(8,16))\nfor row in range(rows):\n    for col in range(columns):\n        ax[row,col].set_axis_off()\n        if columns*row+col < len(char_names):\n            x = df[df.character==char_names[columns*row+col]].iloc[0,:-1].values.reshape(32,32)\n            x = x.astype(\"float64\")\n            x\/=255\n            ax[row,col].imshow(x, cmap=\"binary\")\n            ax[row,col].set_title(char_names[columns*row+col].split(\"_\")[-1])\n\n            \nplt.subplots_adjust(wspace=1, hspace=1)        ","d546c701":"le = preprocessing.LabelEncoder()\nlabel_vec = le.fit_transform(df.character)\n\nX = df.iloc[:, :-1].values\nX = X.reshape(X.shape[0], 32, 32, 1)\nX = X.astype(\"float64\")\nX \/= 255\n\ny = to_categorical(label_vec)","fedf9ae8":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nX_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.2, random_state=42)","c335a491":"print(\"X_train\",X_train.shape, \"\\ny_train\",y_train.shape, \"\\n\\nX_cv\", X_cv.shape, \"\\ny_cv\", y_cv.shape, \"\\n\\nX_test\", X_test.shape, \"\\ny_test\",y_test.shape)","7f20b916":"model = load_model(\"..\/input\/pretrained-cnn-model\/model.h5\")\nmodel.summary()","e1b6a704":"print(\"Accuracy:\",model.evaluate(X_test, y_test, verbose=1)[1])","11492430":"pred = model.predict(X_test, verbose=1)","a45453c3":"print(classification_report(np.argmax(y_test, axis=1),np.argmax(pred, axis=1), target_names=[c.split(\"_\")[-1] for c in le.classes_],digits=4))","5a883412":"def _low_confidence_idx(predicted, y, confidence=0.8):\n    \"\"\"Get indices of low confidence predictions\"\"\"\n    a = []\n    for i in range(predicted.shape[0]):\n        if predicted[i][np.argsort(predicted[i])[-1]]<confidence:\n            a.append(i)\n    return a\n\ndef get_low_confidence_predictions(predictions, X, y, confidence=0.8):\n    \"\"\"get all info about ambiguous predictions\"\"\"\n    idx = _low_confidence_idx(predictions, y, confidence=confidence)\n    results = []\n    for i in idx:\n        result = dict()\n        result[\"image\"] = X[i].reshape(X.shape[1],X.shape[2])\n        result[\"true_class\"] = le.inverse_transform(np.argmax(y[i]))\n        top2 = np.argsort(predictions[i])[-2:]\n        predicted_classes = []\n        for j in top2[::-1]:\n            predicted_classes.append((le.inverse_transform(j), predictions[i][j]))\n        result[\"predicted_classes\"]=predicted_classes\n        results.append(result)\n    return results\n\ndef _high_confidence_idx(predicted, y, confidence=0.9):\n    \"\"\"Get indices of high confidence incorrect predictions\"\"\"\n    a = []\n    for i in range(predicted.shape[0]):\n        if predicted[i][np.argsort(predicted[i])[-1]]>confidence and np.argmax(predicted[i]) != np.argmax(y[i]):\n            a.append(i)\n    return a\n\ndef get_high_confidence_errors(predictions, X, y, confidence=0.9):\n    \"\"\"get all info about ambiguous predictions\"\"\"\n    idx = _high_confidence_idx(predictions, y, confidence=confidence)\n    results = []\n    for i in idx:\n        result = dict()\n        result[\"image\"] = X[i].reshape(X.shape[1],X.shape[2])\n        result[\"true_class\"] = le.inverse_transform(np.argmax(y[i]))\n        top2 = np.argsort(predictions[i])[-2:]\n        predicted_classes = []\n        for j in top2[::-1]:\n            predicted_classes.append((le.inverse_transform(j), predictions[i][j]))\n        result[\"predicted_classes\"]=predicted_classes\n        results.append(result)\n    return results","9102ba92":"\"\"\"Display source image, true and predicted (top 2) classes with softmax score\"\"\"\nlow_conf = get_low_confidence_predictions(pred, X_test, y_test, confidence=0.8)\n\nrows =10;columns=8\nfig, ax = plt.subplots(rows,columns, figsize=(13,24))\nfor row in range(rows):\n    for col in range(columns):\n        ax[row,col].set_axis_off()\n        s = \"\"\n        for p in low_conf[row*columns+col][\"predicted_classes\"]:\n            s += \"{}:({:0.2f})\\n\".format(p[0].split(\"_\")[-1], p[1])\n        true_class = low_conf[row*columns+col][\"true_class\"].split(\"_\")[-1]\n        ax[row,col].set_title(\"True:{}\\n\\nPredicted:\\n{}\".format(true_class,s))\n        ax[row,col].imshow(low_conf[row*columns+col][\"image\"], cmap=\"binary\")\n\nplt.subplots_adjust(wspace=2, hspace=2)          ","fa08a079":"\"\"\"Display source image, true and predicted (top 2) classes with softmax score\"\"\"\nhigh_conf = get_high_confidence_errors(pred, X_test, y_test, confidence=0.9)","4e752b36":"plt.imshow(high_conf[6][\"image\"], cmap=\"binary\")\nplt.axis(\"off\");","7181b3e5":"rows =11;columns=5\nfig, ax = plt.subplots(rows,columns, figsize=(10,35))\nfor row in range(rows):\n    for col in range(columns):\n        ax[row,col].set_axis_off()\n        s = \"\"\n        for p in high_conf[row*columns+col][\"predicted_classes\"]:\n            s += \"{}:({:0.2f})\\n\".format(p[0].split(\"_\")[-1], p[1])\n        true_class = high_conf[row*columns+col][\"true_class\"].split(\"_\")[-1]\n        ax[row,col].set_title(\"True:{}\\n\\nPredicted:\\n{}\".format(true_class,s))\n        ax[row,col].imshow(high_conf[row*columns+col][\"image\"], cmap=\"binary\")\n\nplt.subplots_adjust(wspace=2, hspace=2)    ","0363ae30":"## High confidence predictions that are incorrect\n\nNext we look at predictions that our model made with high confidence, but did not match the true labels. On close inspection, we can see some labels are wrong. For instance this is a 4, but labeled 5.","b6d33818":"## Load pre-trained model\n\nLoad  the pre-trained deep convolutional network built using Keras. Model summary shows layer details. \n","a7a09ee2":"## Preview characters in the dataset\n\nDisplay one sample of each type of character in the dataset. This is a dataset of 36 consonants from the Devanagari script and numerals 0 through 9. There are 46 output classes. Each image is 32x32 pixels black and white (1 channel). Vowels are not seen in this dataset.","11ea4e76":"## Create Training, Cross Validation and Test sets\n\nTraining code is removed as it times out on kaggle.","df542cc0":"## Model Accuracy\n\nCheck classification accuracy of this model on the test set. This model is reasonably accurate, about 99.5%. More importantly, I want to look at low confidence predictions to make improvements to the model. ","5989bfc6":"## Introduction\n\nDevanagari is a writing system used by over 120 languages in India, Nepal and other parts of Asia. This data set is a collection of handwritten characters of the alphabet and numerals 0 thru 9. Only the consonants appear to be here, vowels are not. I have uploaded a deep convolutional neural network model trained using this dataset. In this notebook, I use that model for prediction and then visually inspect low confidence predictions.","2a72ff3a":"The _da_ and _dhaa_ are difficult to tell apart. Some of the letters labeled _da_ (pronounced like  _the_) below, appear more like  the predicted _dhaa_ (pronounced like _duh_ ), to me as a native reader.\n\nNot everything here is incorrectly labeled, though. As a human reader, I can tell the true label is correct and the prediction is indeed wrong.","9582d654":"## Inspect low confidence predictions\n\nRegardless of whether a prediction is correct or not, I want to look at predictions that were made with low confidence. The script below displays predictions that we made with less than 80% confidence, then prints the true label and top 2 predictions along with their confidence score.","175b1ad6":"## Prepare Data\n\nEncode character labels from strings to a numerical output vector\n\nTransform numerical output vector to categorical representation\n\nReshape features into _m_ samples x 32w x 32h x 1 channel\n\nScale features from 0-255 to 0-1 range","9a6abf56":"Training, Cross Validation and Test dataset shapes"}}