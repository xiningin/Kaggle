{"cell_type":{"c6950a4d":"code","d174348f":"code","6b59190a":"code","f746bce3":"code","724ba455":"code","2e1ecddb":"code","efb8eb6c":"code","a1d199c2":"code","d7bf7bf8":"code","85ff5c91":"code","e93abb46":"code","0945fc08":"code","3f3b335a":"code","9921a4bd":"code","d65b6c7d":"code","cdd6ee95":"code","c2723114":"code","3371a2e2":"code","bba354cc":"code","7f449262":"code","3761f77e":"code","a23101b4":"code","ec2a1a00":"code","06a834d9":"code","0e5a7948":"code","e97b2ee5":"code","434bab53":"code","176f6b04":"code","aed3d233":"code","c3fbc28b":"code","a43bafac":"code","86b1f6a2":"code","84617cb3":"code","d5b9211e":"code","0521f774":"code","b2cda4b1":"code","eb8a2a7c":"code","bba930da":"code","7a85db6a":"code","972c1726":"markdown","825667ea":"markdown","76a13f6e":"markdown","cbe48d15":"markdown","1af2f047":"markdown","30d2d3b7":"markdown","12cd6834":"markdown","d80494c1":"markdown","82fb25d4":"markdown","d680f77f":"markdown","5e96879b":"markdown","73a52f45":"markdown","6d7b2c99":"markdown","645a47b7":"markdown","d528ce85":"markdown","e2f97095":"markdown"},"source":{"c6950a4d":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","d174348f":"train_df = pd.read_csv('..\/input\/train.csv')","6b59190a":"train_df.head()","f746bce3":"test_df = pd.read_csv(\"..\/input\/test.csv\")","724ba455":"test_df.head()","2e1ecddb":"train_df.info()","efb8eb6c":"# Convert some columns into categorical data\ntrain_df[\"Survived\"] = train_df[\"Survived\"].astype('category')\ntrain_df[\"Pclass\"] = train_df[\"Pclass\"].astype('category')\ntest_df[\"Pclass\"] = test_df[\"Pclass\"].astype('category')\ntrain_df.describe()","a1d199c2":"train_df[train_df['Sex']=='male']['Sex'].count()","d7bf7bf8":"train_df[train_df['Sex']=='female']['Sex'].count()","85ff5c91":"train_df[\"Sex\"].value_counts().plot.pie(figsize=(4, 4),\n                                     autopct='%.2f',\n                                     title=\"Percentage of Male and Female passengers\",\n                                     fontsize = 10)","e93abb46":"train_df[train_df['Survived']==1]['Survived'].count()","0945fc08":"train_df['Survived'].value_counts().plot.pie(figsize=(4, 4),\n                                            autopct='%.2f',\n                                            title=\"Percentage of survivors\",\n                                            fontsize = 10)","3f3b335a":"train_df[(train_df['Sex']=='male') & (train_df['Survived']==1)]['Name'].count()","9921a4bd":"train_df[(train_df['Sex']=='female') & (train_df['Survived']==1)]['Name'].count()","d65b6c7d":"sns.countplot(x=\"Survived\", hue=\"Sex\", data=train_df)","cdd6ee95":"train_df['Pclass'].value_counts().plot.pie(figsize=(4, 4),\n                                            autopct='%.2f',\n                                            title=\"Percentage of Pclass passengers\",\n                                            fontsize = 10)","c2723114":"sns.countplot(x=\"Survived\", hue=\"Pclass\", data=train_df)","3371a2e2":"print('\\033[1m'+\"Checking if train_df contains any null value:-\"+'\\033[0m')\nprint(train_df.isnull().sum())\nprint('\\n')\nprint('\\033[1m'+\"Checking if test_df contains any null value:-\"+'\\033[0m')\nprint(test_df.isnull().sum())","bba354cc":"test_df['Age'].fillna(test_df['Age'].median(), inplace = True)\ntrain_df['Age'].fillna(train_df['Age'].median(), inplace = True)","7f449262":"drop_col=['Sex','Name','Cabin','Ticket','Embarked']\ntrain_df.drop(drop_col, axis=1, inplace=True)\ntest_df.drop(drop_col, axis=1, inplace=True)","3761f77e":"test_df['Fare'].fillna(test_df['Fare'].median(), inplace = True)","a23101b4":"from sklearn.model_selection import train_test_split #split the dat in test and train sets\nfrom sklearn.model_selection import cross_val_score #score evaluation with cross validation\nfrom sklearn.model_selection import cross_val_predict #prediction with cross validation\nfrom sklearn.metrics import confusion_matrix #for confusion matrix (metric of succes)\nfrom sklearn.model_selection import KFold #for K-fold cross validation\nkfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts","ec2a1a00":"all_features = train_df.drop(\"Survived\",axis=1)\ntargeted_feature = train_df[\"Survived\"]","06a834d9":"X_train,X_test,y_train,y_test = train_test_split(all_features,\n                                                 targeted_feature,\n                                                 test_size=0.3,random_state=42)","0e5a7948":"train_X = train_df.drop(\"Survived\", axis=1)\ntrain_Y=train_df[\"Survived\"]\ntest_X  = test_df\ntrain_X.shape, train_Y.shape, test_X.shape","e97b2ee5":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nn_estim=range(100,1000,100)\n#This is the grid\nparam_grid = {\"n_estimators\" :n_estim}\n\n\nmodel_rf = GridSearchCV(model,param_grid = param_grid, cv=5, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\nmodel_rf.fit(train_X,train_Y)\n","434bab53":"model_rf.best_score_","176f6b04":"print('Accuracy = ', round((model_rf.best_score_)*100,2))","aed3d233":"from sklearn.tree import DecisionTreeClassifier\nmodel= DecisionTreeClassifier(criterion='gini', \n                             min_samples_split=2,min_samples_leaf=1,\n                             max_features='auto')\n\nmodel.fit(X_train,y_train)\n\nprediction_tree=model.predict(X_test)\n\nprint('Accuracy =',round(accuracy_score(prediction_tree,y_test)*100,2))\n\nresult_tree=cross_val_score(model,all_features,targeted_feature,cv=10,scoring='accuracy')\n\nprint('Cross validated score =',round(result_tree.mean()*100,2))\n\ny_pred = cross_val_predict(model,all_features,targeted_feature,cv=10)\n\nsns.heatmap(confusion_matrix(targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"cool\")\n\nplt.title('Confusion matrix', y=1.05, size=15)","c3fbc28b":"from sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors = 7)\n\nmodel.fit(X_train,y_train)\n\nprediction_knn=model.predict(X_test)\n\nprint('Accuracy =',round(accuracy_score(prediction_knn,y_test)*100,2))\n\nresult_knn=cross_val_score(model,all_features,targeted_feature,cv=10,scoring='accuracy')\n\nprint('Cross validated score =',round(result_knn.mean()*100,2))\n\ny_pred = cross_val_predict(model,all_features,targeted_feature,cv=10)\n\nsns.heatmap(confusion_matrix(targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"cool\")\n\nplt.title('Confusion matrix', y=1.05, size=15)","a43bafac":"from sklearn.linear_model import LogisticRegression # Logistic Regression\nfrom sklearn.metrics import accuracy_score  #for accuracy_score\n\nmodel = LogisticRegression()\n\nmodel.fit(X_train,y_train)\n\nprediction_lr=model.predict(X_test)\n\nprint('Accuracy =',round(accuracy_score(prediction_lr,y_test)*100,2))\n\nresult_lr=cross_val_score(model,all_features,targeted_feature,cv=10,scoring='accuracy')\n\nprint('Cross validated score =',round(result_lr.mean()*100,2))\n\ny_pred = cross_val_predict(model,all_features,targeted_feature,cv=10)\n\nsns.heatmap(confusion_matrix(targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"cool\")\n\nplt.title('Confusion matrix', y=1.05, size=15)","86b1f6a2":"import xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nmodel = GradientBoostingClassifier()\nparam_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300,400],\n              'learning_rate': [0.1, 0.05, 0.01,0.001],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.2,0.1] \n              }\n\nmodelf = GridSearchCV(model,param_grid = param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\nmodelf.fit(X_train,y_train)\n\n\n# Best Estimator\nmodelf.best_estimator_\nprint('Accuracy = ', round((modelf.best_score_)*100,2))","84617cb3":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nmodel= LinearDiscriminantAnalysis()\nmodel.fit(X_train,y_train)\nprediction_lda=model.predict(X_test)\n\nprint('Accuracy',round(accuracy_score(prediction_lda,y_test)*100,2))\n\nresult_lda=cross_val_score(model,all_features,targeted_feature,cv=10,scoring='accuracy')\n\nprint('The cross validated score',round(result_lda.mean()*100,2))\n\ny_pred = cross_val_predict(model,all_features,targeted_feature,cv=10)\n\nsns.heatmap(confusion_matrix(targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"cool\")\n\nplt.title('Confusion matrix', y=1.05, size=15)","d5b9211e":"# Random Forests\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score \nmodel_rf = RandomForestClassifier(criterion='gini', n_estimators=100,\n                             min_samples_split=2,min_samples_leaf=1,\n                             max_features='auto',oob_score=True,\n                             random_state=1,n_jobs=-1)\n\nmodel_rf.fit(X_train,y_train)\n\nprediction_rm= model_rf.predict(X_test)\n\nprint('Accuracy =',round(accuracy_score(prediction_rm,y_test)*100,2))\n\nresult_rm=cross_val_score(model_rf,all_features,targeted_feature,cv=10,scoring='accuracy')\n\nprint('Cross validated score =',round(result_rm.mean()*100,2))\n\ny_pred = cross_val_predict(model_rf,all_features,targeted_feature,cv=10)\n\nsns.heatmap(confusion_matrix(targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"cool\")\n\nplt.title('Confusion matrix', y=1.05, size=15)","0521f774":"from sklearn.ensemble import GradientBoostingClassifier\nmodel= GradientBoostingClassifier()\nmodel.fit(X_train,y_train)\nprediction_gbc=model.predict(X_test)\n\nprint('Accuracy',round(accuracy_score(prediction_gbc,y_test)*100,2))\n\nresult_gbc=cross_val_score(model,all_features,targeted_feature,cv=10,scoring='accuracy')\n\nprint('The cross validated score',round(result_gbc.mean()*100,2))\n\ny_pred = cross_val_predict(model,all_features,targeted_feature,cv=10)\n\nsns.heatmap(confusion_matrix(targeted_feature,y_pred),annot=True,fmt='3.0f',cmap=\"cool\")\nplt.title('Confusion matrix', y=1.05, size=15)","b2cda4b1":"# Random Forests\nfrom sklearn.ensemble import RandomForestClassifier\nrandom_forest = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\nrandom_forest.fit(X_train, y_train)\nY_pred_rf = random_forest.predict(test_X)\nrandom_forest.score(X_train, y_train)\nacc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\nprint(acc_random_forest)","eb8a2a7c":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred_rf})","bba930da":"submission.head()","7a85db6a":"submission.to_csv('submission.csv', index=False)","972c1726":"**Reading test.csv**","825667ea":"<br>\n**From this first look at the data, it is easy to say that you have a better chance of survival if you are female and from the first class.**\n<\/br>","76a13f6e":"** Number of person survived on titanic according to data:-**","cbe48d15":"<br>\n**Filling median value of age on null values of age column:-**\n<\/br>","1af2f047":"** Number of females on titanic who survived according to train_df:-**","30d2d3b7":"**Reading train.csv**","12cd6834":"**Distribution of Pclass passengers on titanic:-**","d80494c1":"** Number of males on titanic who survived according to train_df:-**","82fb25d4":"**Distribution of males and females:-**","d680f77f":"** Number of males in train_df according to data:-**","5e96879b":"** Number of females in train_df according to data:-**","73a52f45":"** Above visualization shows most of the third class passengers died.**","6d7b2c99":"**We have seen that there are some null values in the data, for building models we have to remove these null values:-**","645a47b7":"**We are going to Drop the Sex, Name, Cabin and Ticket column from both train_df and test_df**","d528ce85":"**Fare is the column where test_df has missing values. Nevertheless we should impute it.**","e2f97095":"**Well according to above visualization, you have a better chance to survive if you are female.**"}}