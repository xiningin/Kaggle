{"cell_type":{"1af74452":"code","ebb457fc":"code","e8975272":"code","6bc860e2":"code","65920d8b":"code","2c115250":"code","f39adfca":"code","e130a1b3":"code","5320e9cd":"code","f0e29b2e":"code","e1fc31bf":"code","b4f3c98a":"code","c52ae113":"code","b951dbda":"code","a538cc3a":"code","585e3fab":"code","1fe03eac":"code","02dd81bb":"code","b3ee7cad":"code","e5721367":"markdown","9d14e55d":"markdown","c4c98ad2":"markdown","412e8e31":"markdown","2e2d9e5b":"markdown","6f17d30f":"markdown","dc9936d4":"markdown"},"source":{"1af74452":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ebb457fc":"pd.plotting.register_matplotlib_converters()\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns","e8975272":"!pip install xlrd","6bc860e2":"def read_multiIndex_xls(excel_file_path: str, sheet_number: list) -> pd.DataFrame:\n    new_df = pd.DataFrame(pd.read_excel(excel_file_path, sheet_name=sheet_number, header=[0, 1],index_col=[0]))\n    new_df = new_df.rename(columns=lambda c: c if not 'Unnamed' in str(c) else '')\n    return new_df","65920d8b":"earth_q_data_historical = read_multiIndex_xls('\/kaggle\/input\/irans-earthquakes\/data.xls', sheet_number='Historical')\nearth_q_data_1900_1963 = read_multiIndex_xls('\/kaggle\/input\/irans-earthquakes\/data.xls', sheet_number='1900-1963')\nearth_q_data_1964_2000 = read_multiIndex_xls('\/kaggle\/input\/irans-earthquakes\/data.xls', sheet_number='1964-2000')","2c115250":"earth_q_data_historical.head()","f39adfca":"earth_q_data_1900_1963.head()","e130a1b3":"earth_q_data_1964_2000.head()","5320e9cd":"def merge_date_columns(df: pd.DataFrame) -> pd.DataFrame:\n        full_date = df.Date\n        if ('Date', 'M') in df.columns:\n                # Drop rows with missing Year value\n                df[('Date', 'Y')].dropna(axis=0, inplace=True)\n\n                # Fill NA\/NaN values in Month and Day columns.\n                df[('Date', 'M')].fillna(method='backfill', inplace=True)\n                df[('Date', 'D')].fillna(method='backfill', inplace=True)\n                df[('Date', 'M')].fillna(method='ffill', inplace=True)\n                df[('Date', 'D')].fillna(method='ffill', inplace=True)\n\n                # Convert float columns to int\n                df[[('Date', 'M')]] = df[[('Date', 'M')]].astype(int)\n                df[[('Date', 'D')]] = df[[('Date', 'D')]].astype(int)\n\n                # Convert Month and Day with two digits format\n                df[[('Date', 'M')]] = df[[('Date', 'M')]].astype(str).apply(lambda x: x.str.zfill(2))\n                df[[('Date', 'D')]] = df[[('Date', 'D')]].astype(str).apply(lambda x: x.str.zfill(2))\n                \n                # Merge the full date from Year\/Month\/Day\n                full_date = pd.to_datetime(df['Date', 'Y'].astype(str) + \n                                        df['Date', 'M'].astype(str) +\n                                        df['Date', 'D'].astype(str), errors='ignore')\n\n\n        # Format the Time column\n        df['Time'] = pd.to_datetime(df.Time, format='%H%M%S', errors='coerce').dt.time\n\n        # Merge the date and time columns to DateTime column\n        datetime_col= pd.to_datetime(full_date.astype(str) + ' ' +\n                                      df['Time'].astype(str).apply(lambda x : '00:00' if x==\"NaT\" else x), errors='coerce')\n\n        # Insert new column, DateTime, into the DataFrame\n        df.insert(0, 'DateTime' , datetime_col)\n        \n        # Drop the Date and Time columns\n        df.drop('Date', inplace=True, axis=1)\n        df.drop('Time', inplace=True, axis=1)\n        \n        return df","f0e29b2e":"earth_q_data_historical = merge_date_columns(earth_q_data_historical)\nearth_q_data_1900_1963 = merge_date_columns(earth_q_data_1900_1963)\nearth_q_data_1964_2000 = merge_date_columns(earth_q_data_1964_2000)\n","e1fc31bf":"def flatten_columns(df: pd.DataFrame) -> pd.DataFrame:\n    df.columns = ['_'.join(x).rstrip('_') for x in df.columns.values]\n    return df","b4f3c98a":"earth_q_data_1964_2000 = flatten_columns(earth_q_data_1964_2000)\nearth_q_data_1900_1963 = flatten_columns(earth_q_data_1900_1963)\nearth_q_data_historical = flatten_columns(earth_q_data_historical)","c52ae113":"earth_q_data_1964_2000.head()","b951dbda":"earth_q_data_1964_2000.info()","a538cc3a":"plt.figure(figsize=(20,7))\nsns.scatterplot(x=earth_q_data_1964_2000.DateTime, y=earth_q_data_1964_2000.Magnitude_mb)","585e3fab":"x = list(range(0,24,1))\ny = earth_q_data_1964_2000.groupby(by=[earth_q_data_1964_2000.DateTime.dt.hour]).count()\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,5)\nax.set_xticks(x)\nsns.lineplot(y=y['DateTime'], x=x, ax=ax)\nplt.title(\"Number of earthquakes per hour 1964_2000\")\nplt.xlabel('Time of the day')\nplt.ylabel('Number of earthquakes')\nplt.show()","1fe03eac":"fig, ax = plt.subplots()\nfig.set_size_inches(15,5)\nax.set_xticks(x)\nsns.regplot(y=y['DateTime'], x=x, ax=ax)\nplt.title(\"Number of earthquakes per hour 1964_2000\")\nplt.xlabel('Time of the day')\nplt.ylabel('Number of earthquakes')\nplt.show()","02dd81bb":"fig, ax = plt.subplots()\nfig.set_size_inches(15,5)\nax.set_xticks(x)\nsns.lineplot(y=y['DateTime'], x=x, ax=ax)\nplt.title(\"Number of earthquakes per hour 1900_1963\")\nplt.xlabel('Time of the day')\nplt.ylabel('Number of earthquakes')\nplt.show()","b3ee7cad":"y = earth_q_data_1900_1963.groupby(by=[earth_q_data_1900_1963.DateTime.dt.hour]).count()\n\nfig, ax = plt.subplots()\nfig.set_size_inches(15,5)\nax.set_xticks(x)\nsns.regplot(y=y['DateTime'], x=x, ax=ax)\nplt.title(\"Number of earthquakes per hour 1900_1963\")\nplt.xlabel('Time of the day')\nplt.ylabel('Number of earthquakes')\nplt.show()","e5721367":"# Data Preprocessing and Analysis\nThe dataset is in .xls format with MultiIndex columns. For reading data and formatting information from Excel files in .xls format we need to install xlrd library. Then we can read the dataset as a pandas Dataframe.","9d14e55d":"Then we'd read each sheet into a separate DataFrame.","c4c98ad2":"Also we'd flatten the datasets MultiIndexs columns.","412e8e31":"# Exploratory\nHere we'd visualize the relation between time of the day and the chance of an earthquake happening. It seems that the closer we get to the night hours, the more likely an earthquake is to occur.","2e2d9e5b":"To check the strength of this relationship, we can use a regression line.","6f17d30f":"Then we'd clean the Date and Time columns and then merge them to a single column DateTime.","dc9936d4":"Now we'd repeat the same things for the 1900_1963 dataset. "}}