{"cell_type":{"00d26b29":"code","97d77549":"code","22104c51":"code","07cb376b":"code","0bb4f08f":"code","0ccfeb76":"code","8bea681b":"code","3d1754b9":"code","46924a8e":"code","ac4454ee":"code","363f8aca":"code","d921b92e":"code","b9f0f611":"code","661c0a08":"code","24321022":"code","dd69e1b1":"code","92b2dfc2":"code","aef6c17d":"code","3947f63e":"code","dd9bf087":"code","4d567d5c":"code","3a86a020":"code","91ef15b2":"code","42d9d1f3":"code","b658eb3f":"code","9332e586":"code","c6efb895":"code","021612f8":"code","091a47d0":"code","29c2a280":"code","8ce55efb":"code","78038880":"code","b8f845cc":"code","0bcb6019":"code","7e156d3e":"code","35bcc7f3":"code","ff5e873d":"code","afc740d2":"code","8445a1e2":"code","579fc1be":"code","e5e48538":"code","ff4a6a24":"code","f47ad2cb":"code","ab5f7652":"code","79317b63":"code","debc3e11":"code","b60c7687":"code","bb3dc898":"code","e38d1f24":"code","dafa7e2d":"code","84c696f9":"code","13ff9cb2":"code","1a32db56":"code","29d2dbeb":"code","f59c7065":"code","7a645f92":"code","61090dd4":"code","8f90eacf":"code","4bda879f":"code","fa113bf2":"code","c25d9bdd":"code","d193f660":"code","32bcc6e8":"code","f313f49d":"code","7584b783":"code","799844ab":"code","5dd252a4":"code","a17836ba":"code","01af4241":"markdown","3d242cf5":"markdown","ddbb14a4":"markdown","1fdcb9e6":"markdown","2b162d45":"markdown","c08e1ff4":"markdown","76f7aff8":"markdown","dd3d4463":"markdown","1bffb0b5":"markdown","5243fdad":"markdown","47d767f5":"markdown","f039e8b6":"markdown","a78b0a65":"markdown","2e14fee8":"markdown","1a259de1":"markdown","a6908023":"markdown","4996d824":"markdown","f7410429":"markdown","b534a6c6":"markdown","f6754a92":"markdown","d7f200c9":"markdown","805b8ea6":"markdown","8a8d417a":"markdown","288958de":"markdown","51b0e17f":"markdown","34d1ca21":"markdown","41cd71be":"markdown","50f06925":"markdown","7e7e730f":"markdown","fbdaf04d":"markdown","79a0fcf5":"markdown","74d10d61":"markdown","b005dff9":"markdown","066eadc3":"markdown","9b5ed06b":"markdown","e521d18f":"markdown","510ea899":"markdown","286c14b6":"markdown","986f509a":"markdown","bfc79039":"markdown","d53cef8c":"markdown","cfd06ec9":"markdown","057053a2":"markdown","04c62ff8":"markdown","2043dcda":"markdown","a5617822":"markdown","fb5723c5":"markdown"},"source":{"00d26b29":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string, re","97d77549":"sns.set()\nmodelling = False\nsubsampling = False # For speed up the iteration of development","22104c51":"#Check the dataset sizes(in MB)\n!du -lh ..\/input\/emoji-sentiment-data\/*","07cb376b":"# Multiple output printing in each cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","0bb4f08f":"if not modelling:\n    full_comments_df = pd.read_csv(\"..\/input\/commentscsv\/test_data.csv\")","0ccfeb76":"if not modelling:\n    emoji_sent_df = pd.read_csv(\"..\/input\/emoji-sentiment-data\/Emoji_Sentiment_Data_v1.0.csv\")","8bea681b":"if not modelling:\n    full_comments_df.shape","3d1754b9":"if not modelling:\n    if subsampling:\n        full_comments_df = full_comments_df.sample(5000, random_state=1234).reset_index()\n        full_comments_df.shape","46924a8e":"if not modelling:\n    full_comments_df.head()","ac4454ee":"if not modelling:\n    full_comments_df.tail()","363f8aca":"if not modelling:\n    full_comments_df.drop_duplicates(inplace=True)\n    full_comments_df.shape","d921b92e":"if not modelling:\n    full_comments_df.isnull().sum(axis = 0)","b9f0f611":"if not modelling:\n    full_comments_df[full_comments_df['translation'].isnull()]['language']","661c0a08":"if not modelling:\n    # Just copy the original text into the translation for the ones with empty translation field\n    full_comments_df['translation'].fillna(full_comments_df['comment'], inplace = True)\n    full_comments_df.isnull().sum(axis = 0)\n","24321022":"if not modelling:\n    f'[{string.punctuation}]' # Just to check what symbols are included\n    full_comments_df['translation']=full_comments_df['translation'].str.replace(f'[{string.punctuation}]','') # Removing punctuation symbols (Maybe exclamations of questions marks have any impact?)\n    full_comments_df['translation']=full_comments_df['translation'].str.replace('[\u2018\u2019\u201c\u201d\u2026]', '') # Removing more potential weird charactersa","dd69e1b1":"if not modelling:\n    full_comments_df['translation'].str.len().mean()\n    full_comments_df['translation'].str.len().std()\n    full_comments_df['translation'].str.len().quantile(q = [0,0.25,0.5,0.75,0.9,0.95,0.99,0.999,0.9999,1])","92b2dfc2":"if not modelling:\n    full_comments_df = full_comments_df[full_comments_df['translation'].str.len() < 500]\n    full_comments_df.shape","aef6c17d":"if not modelling:\n    sns.countplot(x = 'harmful', data = full_comments_df)","3947f63e":"if not modelling:\n    sns.countplot(x = 'harmful_type', data = full_comments_df[full_comments_df['harmful_type'] != 0])","dd9bf087":"if not modelling:\n    full_comments_df['contains_numbers'] = full_comments_df['translation'].str.contains('\\s\\d+\\s',regex=True) # Pure number words\n    full_comments_df['translation']=full_comments_df['translation'].str.replace('[0-9]',' ',regex=True) # Remove all numbers (even the ones between letters)\n    full_comments_df['contains_numbers'].mean()","4d567d5c":"if not modelling:\n    pd.crosstab(full_comments_df['contains_numbers'],full_comments_df['harmful'])","3a86a020":"if not modelling:\n    #def perc_capital_letters(text): return sum(1 for c in text if c.isupper())\/len(text)\n    full_comments_df['perc_capital'] = full_comments_df['translation'].apply(lambda text: sum(1 for c in text if c.isupper())\/(len(text)+1))","91ef15b2":"if not modelling:\n    full_comments_df['perc_capital'].describe()","42d9d1f3":"if not modelling:\n    sns.distplot(full_comments_df[(full_comments_df['harmful'] == 0)]['perc_capital'].dropna(),label='No harm')\n    sns.distplot(full_comments_df[(full_comments_df['harmful'] == 1)]['perc_capital'].dropna(),label='Harm')\n    plt.legend()\n    plt.xlim([0,0.4])\n    plt.show()","b658eb3f":"if not modelling:\n    full_comments_df['translation'] = full_comments_df['translation'].str.lower().str.strip() # Lower case and striping (Maybe capital letters have any predictive impact?f)","9332e586":"if not modelling:\n    full_comments_df['translation']","c6efb895":"if not modelling:\n    full_comments_df['char_length'] = full_comments_df['translation'].str.len()\n    full_comments_df['char_length_norm'] = full_comments_df['char_length']\/full_comments_df['char_length'].max()","021612f8":"if not modelling:\n    plot1 = sns.distplot(full_comments_df[(full_comments_df['harmful'] == 0)]['char_length'].dropna(),label='No harm')\n    plot2 = sns.distplot(full_comments_df[(full_comments_df['harmful'] == 1)]['char_length'].dropna(),label='Harm')\n    #plot1.set(xscale=\"log\")\n    #plot2.set(xscale=\"log\")\n    plt.legend()\n    plt.show()","091a47d0":"\nif not modelling:\n    with sns.axes_style('white'):\n        g = sns.jointplot(\"perc_capital\", \"char_length\", full_comments_df, kind='kde')\n        #g.ax_joint.set_xscale('log')\n        #g.ax_joint.set_yscale('log')\n        g.ax_joint.set_xlim([0,0.2]) \n        g.ax_joint.set_ylim([0,70])\n","29c2a280":"if not modelling:\n    with sns.axes_style('white'):\n        g = sns.jointplot(\"perc_capital\", \"char_length\", full_comments_df[full_comments_df['harmful'] == 0], kind='kde')\n        #g.ax_joint.set_xscale('log')\n        #g.ax_joint.set_yscale('log')\n        g.ax_joint.set_xlim([0,0.2]) \n        g.ax_joint.set_ylim([0,70])\n","8ce55efb":"if not modelling:\n    with sns.axes_style('white'):\n        g = sns.jointplot(\"perc_capital\", \"char_length\", full_comments_df[full_comments_df['harmful'] == 1], kind='kde')\n        #g.ax_joint.set_xscale('log')\n        #g.ax_joint.set_yscale('log')\n        g.ax_joint.set_xlim([0,0.2]) \n        g.ax_joint.set_ylim([0,70])\n","78038880":"if not modelling:\n    c = 5\n    print('Harmful comment:')\n    print(full_comments_df[full_comments_df['harmful'] == 1].reset_index(drop=True)['translation'][c])\n    print('Non-Harmful comment:')\n    print(full_comments_df[full_comments_df['harmful'] == 0].reset_index(drop=True)['translation'][c])","b8f845cc":"if not modelling:\n    emoji_sent_df.head()\n    emoji_sent_df.dtypes","0bcb6019":"if not modelling:\n    def emoji_sent(text):\n        negative = 0\n        neutral = 0\n        positive = 0\n        position = -1\n        has = 0\n        total = 0\n        for emoji in emoji_sent_df['Emoji']:\n            n_times = text.count(emoji)\n            if n_times > 0:\n                has += n_times\n                position += n_times*emoji_sent_df[emoji_sent_df['Emoji']==emoji]['Position'].values[0]\n                negative += n_times*emoji_sent_df[emoji_sent_df['Emoji']==emoji]['Negative'].values[0]\/10000\n                neutral += n_times*emoji_sent_df[emoji_sent_df['Emoji']==emoji]['Neutral'].values[0]\/10000\n                positive += n_times*emoji_sent_df[emoji_sent_df['Emoji']==emoji]['Positive'].values[0]\/10000\n                total += n_times\n        if total != 0:\n            negative = negative\/total\n            neutral = neutral\/total\n            positive = positive\/total\n            position = (position +1)\/total\n        return pd.Series([has,negative,neutral,positive,position])\n    \n    full_comments_df[['has_emoji','emoji_neg_sent','emoji_neut_sent','emoji_pos_sent','emoji_position']]=full_comments_df['translation'].apply(emoji_sent)","7e156d3e":"if not modelling:\n    full_comments_df.head(300)","35bcc7f3":"if not modelling:\n    pd.crosstab(full_comments_df['has_emoji'] > 0,full_comments_df['harmful'])","ff5e873d":"if not modelling:\n    #plt.rcParams['figure.figsize'] = [16, 6]\n    emoji_columns = ['emoji_neg_sent','emoji_neut_sent','emoji_pos_sent']\n    for emoji_col  in emoji_columns:\n        plot1 = sns.distplot(full_comments_df[(full_comments_df['harmful'] == 0) & (full_comments_df['has_emoji'] > 0)][emoji_col].dropna(),label='No harm')\n        plot2 = sns.distplot(full_comments_df[(full_comments_df['harmful'] == 1) & (full_comments_df['has_emoji'] > 0)][emoji_col].dropna(),label='Harm')\n        #plot1.set(xscale=\"log\")\n        #plot2.set(xscale=\"log\")\n        plt.legend()\n        plt.show()","afc740d2":"if not modelling:\n    from textblob import TextBlob\n    polarity = lambda x: TextBlob(x).sentiment.polarity\n    subjectivity = lambda x: TextBlob(x).sentiment.subjectivity\n    full_comments_df['polarity']=full_comments_df['translation'].apply(polarity)\n    full_comments_df['subjectivity']=full_comments_df['translation'].apply(subjectivity)\n","8445a1e2":"if not modelling:\n    sentiment_columns = ['polarity','subjectivity']\n    for sent_col  in sentiment_columns:\n        plot1 = sns.distplot(full_comments_df[(full_comments_df['harmful'] == 0)][sent_col].dropna(),label='No harm', kde = False)\n        plot2 = sns.distplot(full_comments_df[(full_comments_df['harmful'] == 1)][sent_col].dropna(),label='Harm', kde = False)\n        #plot1.set(xscale=\"log\")\n        #plot2.set(xscale=\"log\")\n        plt.legend()\n        plt.show()","579fc1be":"from wordcloud import WordCloud\nfrom sklearn.feature_extraction import text \n\nif not modelling:\n    stop_words = text.ENGLISH_STOP_WORDS\n\n    # Set two wordclouds images,one per class\n    plt.rcParams['figure.figsize'] = [16, 6]\n    wc = WordCloud(stopwords=stop_words, background_color=\"white\", colormap=\"Dark2\",max_font_size=150, random_state=12457)\n\n    wc.generate(full_comments_df[full_comments_df['harmful']==0]['translation'].str.cat(sep=' '))\n    plt.subplot(1,2,1)\n    plt.imshow(wc,interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.title('Non Harmful')\n    wc.generate(full_comments_df[full_comments_df['harmful']==1]['translation'].str.cat(sep=' '))\n    plt.subplot(1,2,2)\n    plt.imshow(wc,interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.title('Harmful')\n\n    plt.show()","e5e48538":"from sklearn.model_selection import train_test_split\nimport os, pickle\n\nexists = os.path.isfile('train_df.pkl') # Check if there is one of the supposed stored files\nif exists and modelling:\n    train_df = pd.read_pickle('train_df.pkl')\n    dev_df = pd.read_pickle('dev_df.pkl')\n    test_df = pd.read_pickle('test_df.pkl')   \nelse:\n    train_df, dev_test_df = train_test_split(full_comments_df, test_size=0.25, random_state = 4321) # 70% for training\n    dev_df, test_df = train_test_split(dev_test_df, test_size=0.4, random_state = 6789) # 15% for developping and 10% for final testing\n       \n    pickle.dump(train_df, open('train_df.pkl', 'wb'))\n    pickle.dump(dev_df, open('dev_df.pkl', 'wb'))\n    pickle.dump(test_df, open('test_df.pkl', 'wb'))","ff4a6a24":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# COUNTs\ncount_vec = CountVectorizer(stop_words=stop_words,strip_accents = 'unicode',ngram_range = [1,1], min_df = 3)\n\ntrain_dtm = count_vec.fit_transform(train_df['translation'])\ndev_dtm = count_vec.transform(dev_df['translation'])\ntest_dtm = count_vec.transform(test_df['translation'])\n\ntrain_dtm_df = pd.DataFrame(train_dtm.toarray(), columns=count_vec.get_feature_names())\ndev_dtm_df = pd.DataFrame(dev_dtm.toarray(), columns=count_vec.get_feature_names())\ntest_dtm_df = pd.DataFrame(test_dtm.toarray(), columns=count_vec.get_feature_names())\n\ntrain_dtm_df.index = train_df.index\ndev_dtm_df.index = dev_df.index\ntest_dtm_df.index = test_df.index\n\ntrain_dtm_df = pd.concat([train_df,train_dtm_df], axis = 1).reset_index()\ndev_dtm_df = pd.concat([dev_df,dev_dtm_df], axis = 1).reset_index()\ntest_dtm_df = pd.concat([test_df,test_dtm_df], axis = 1).reset_index()\n\n#TF-IDF\ncount_idf_vec = TfidfVectorizer(stop_words=stop_words,strip_accents = 'unicode',ngram_range = [1,1], min_df = 3)\n\ntrain_dtm_idf = count_idf_vec.fit_transform(train_df['translation'])\ndev_dtm_idf = count_idf_vec.transform(dev_df['translation'])\ntest_dtm_idf = count_idf_vec.transform(test_df['translation'])\n\ntrain_dtm_idf_df = pd.DataFrame(train_dtm_idf.toarray(), columns=count_idf_vec.get_feature_names())\ndev_dtm_idf_df = pd.DataFrame(dev_dtm_idf.toarray(), columns=count_idf_vec.get_feature_names())\ntest_dtm_idf_df = pd.DataFrame(test_dtm_idf.toarray(), columns=count_idf_vec.get_feature_names())\n\ntrain_dtm_idf_df.index = train_df.index\ndev_dtm_idf_df.index = dev_df.index\ntest_dtm_idf_df.index = test_df.index\n\ntrain_dtm_idf_df = pd.concat([train_df,train_dtm_idf_df], axis = 1).reset_index()\ndev_dtm_idf_df = pd.concat([dev_df,dev_dtm_idf_df], axis = 1).reset_index()\ntest_dtm_idf_df = pd.concat([test_df,test_dtm_idf_df], axis = 1).reset_index()","f47ad2cb":"harmful_words_serie = train_dtm_df[train_dtm_df['harmful']==0].sum(numeric_only = True).iloc[18:] # The index plus the other non proper word features are skipped\nnon_harmful_words_serie = train_dtm_df[train_dtm_df['harmful']==1].sum(numeric_only = True).iloc[18:] # The index plus the other non proper word features are skipped\nharm_top_serie = harmful_words_serie.sort_values(ascending=False).head(30)\nnon_harm_top_serie = non_harmful_words_serie.sort_values(ascending=False).head(30)\n\nharm_top_words = set(harm_top_serie.keys())\nnon_harm_top_words = set(non_harm_top_serie.keys())\nadd_stop_words = harm_top_words.intersection(non_harm_top_words)\nharm_top_serie\nnon_harm_top_serie\n\nadd_stop_words\n   ","ab5f7652":"# Computing the DTM_DFs (count and tf-idf representations) again adding this new stopwords\n\nstop_words_new = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n\n# COUNTs\ncount_vec = CountVectorizer(stop_words=stop_words_new,strip_accents = 'unicode',ngram_range = [1,1], min_df = 3)\n\ntrain_dtm = count_vec.fit_transform(train_df['translation'])\ndev_dtm = count_vec.transform(dev_df['translation']) # Check that dev and test are only applying the transformation did on the train set\ntest_dtm = count_vec.transform(test_df['translation'])\n\ntrain_dtm_df = pd.DataFrame(train_dtm.toarray(), columns=count_vec.get_feature_names())\ndev_dtm_df = pd.DataFrame(dev_dtm.toarray(), columns=count_vec.get_feature_names())\ntest_dtm_df = pd.DataFrame(test_dtm.toarray(), columns=count_vec.get_feature_names())\n\ntrain_dtm_df.index = train_df.index\ndev_dtm_df.index = dev_df.index\ntest_dtm_df.index = test_df.index\n\ntrain_dtm_df = pd.concat([train_df,train_dtm_df], axis = 1).reset_index()\ndev_dtm_df = pd.concat([dev_df,dev_dtm_df], axis = 1).reset_index()\ntest_dtm_df = pd.concat([test_df,test_dtm_df], axis = 1).reset_index()   \n\n#TF-IDF\ncount_idf_vec = TfidfVectorizer(stop_words=stop_words_new,strip_accents = 'unicode',ngram_range = [1,1], min_df = 3)\n\ntrain_dtm_idf = count_idf_vec.fit_transform(train_df['translation'])\ndev_dtm_idf = count_idf_vec.transform(dev_df['translation'])\ntest_dtm_idf = count_idf_vec.transform(test_df['translation'])\n\ntrain_dtm_idf_df = pd.DataFrame(train_dtm_idf.toarray(), columns=count_idf_vec.get_feature_names())\ndev_dtm_idf_df = pd.DataFrame(dev_dtm_idf.toarray(), columns=count_idf_vec.get_feature_names())\ntest_dtm_idf_df = pd.DataFrame(test_dtm_idf.toarray(), columns=count_idf_vec.get_feature_names())\n\ntrain_dtm_idf_df.index = train_df.index\ndev_dtm_idf_df.index = dev_df.index\ntest_dtm_idf_df.index = test_df.index\n\ntrain_dtm_idf_df = pd.concat([train_df,train_dtm_idf_df], axis = 1).reset_index()\ndev_dtm_idf_df = pd.concat([dev_df,dev_dtm_idf_df], axis = 1).reset_index()\ntest_dtm_idf_df = pd.concat([test_df,test_dtm_idf_df], axis = 1).reset_index()    ","79317b63":"print(train_dtm.sum(0))","debc3e11":"# First compute ad-hoc function the \ndef words_prob_vector(class_0_1):\n    p = X[y==class_0_1].sum(0)\n    return (p+1) \/ ((y==class_0_1).sum()+1)\n\ndef nb_prediction(dtm_matrix,w,b):\n    predictions = (dtm_matrix @ w +b)>0\n    return predictions","b60c7687":"X = train_dtm.toarray()\ny = train_df['harmful']\nw_nb = np.log(words_prob_vector(1)\/words_prob_vector(0)) # This weights in NB are learn based on \"first\" principles, assuming the \"naive\" of conditional independence given a comment is harmful or not\nbias = np.log((y ==1).mean()\/(y==0).mean())\n# Now given a comment, the prediction is = (term_representation*wb + b) and assuming a threshold of 50% of harmful\/non-harmful if this is greater than 0 => Class 1 else 0\ntrain_error=(nb_prediction(train_dtm.toarray(),w_nb,bias)==train_df['harmful']).mean()\ndev_error=(nb_prediction(dev_dtm.toarray(),w_nb,bias)==dev_df['harmful']).mean()\nprint(f'Naive Bayes ==> Train_Accuracy:{train_error} - Dev_Accuracy:{dev_error}')","bb3dc898":"X = train_dtm.sign().toarray() # All entries will be 0 or 1\ny = train_df['harmful']\nw_nb = np.log(words_prob_vector(1)\/words_prob_vector(0)) # This weights in NB are learn based on \"first\" principles, assuming the \"naive\" of conditional independence given a comment is harmful or not\nbias = np.log((y ==1).mean()\/(y==0).mean())\n# Now given a comment, the prediction is = (term_representation*wb + b) and assuming a threshold of 50% of harmful\/non-harmful if this is greater than 0 => Class 1 else 0\ntrain_error=(nb_prediction(train_dtm.sign().toarray(),w_nb,bias)==train_df['harmful']).mean()\ndev_error=(nb_prediction(dev_dtm.sign().toarray(),w_nb,bias)==dev_df['harmful']).mean()\nprint(f'Naive Bayes binary input ==> Train_Accuracy:{train_error} - Dev_Accuracy:{dev_error}')","e38d1f24":"from sklearn.linear_model import LogisticRegression\nm = LogisticRegression(C=1e8, dual=True) # C is the inverse of the reg coefficient, bigger values imply less regularization (this is like no regularization)\nm.fit(train_dtm.toarray(), train_df['harmful']) # It is already loaded the train values from the NB model\ntrain_error = (m.predict(train_dtm.toarray())==train_df['harmful']).mean()\ndev_error = (m.predict(dev_dtm.toarray())==dev_df['harmful']).mean()\nprint(f'Logistic Regression ==> Train_Accuracy:{train_error} - Dev_Accuracy:{dev_error}')","dafa7e2d":"from sklearn.linear_model import LogisticRegression\nm = LogisticRegression(C=0.5, dual=True)\nm.fit(train_dtm.toarray(), train_df['harmful'])\ntrain_error = (m.predict(train_dtm.toarray())==train_df['harmful']).mean()\ndev_error = (m.predict(dev_dtm.toarray())==dev_df['harmful']).mean()\nprint(f'Logistic Regression ==> Train_Accuracy:{train_error} - Dev_Accuracy:{dev_error}')","84c696f9":"m = LogisticRegression(C=0.5, dual=True)\nm.fit(train_dtm.sign().toarray(), train_df['harmful'])\ntrain_error = (m.predict(train_dtm.sign().toarray())==train_df['harmful']).mean()\ndev_error = (m.predict(dev_dtm.sign().toarray())==dev_df['harmful']).mean()\nprint(f'Logistic Regression binary input ==> Train_Accuracy:{train_error} - Dev_Accuracy:{dev_error}')","13ff9cb2":"m = LogisticRegression(C=0.5, dual=True)\nX = train_dtm.toarray() \ny = train_df['harmful']\nw_nb = np.log(words_prob_vector(1)\/words_prob_vector(0)).reshape([1,train_dtm.toarray().shape[1]])\nX_new = X*w_nb\nm.fit(X_new, train_df['harmful'])\ntrain_error = (m.predict(train_dtm.toarray()*w_nb)==train_df['harmful']).mean()\ndev_error = (m.predict(dev_dtm.toarray()*w_nb)==dev_df['harmful']).mean()\nprint(f'NB_LR ==> Train_Accuracy:{train_error} - Dev_Accuracy:{dev_error}')","1a32db56":"from sklearn.ensemble import RandomForestClassifier\n\ntarget = 'harmful'\nnon_word_features = ['contains_numbers', 'perc_capital', 'char_length','char_length_norm', 'has_emoji',\n                     'emoji_neg_sent', 'emoji_neut_sent','emoji_pos_sent', 'emoji_position', 'polarity', 'subjectivity']\n\nX_train_rf = train_df[non_word_features]\ny_train = train_df['harmful']\nX_dev_rf = dev_df[non_word_features]\ny_dev = dev_df['harmful']\n","29d2dbeb":"import sklearn\nfrom sklearn.metrics import recall_score\n\ndef print_score(m):\n    if isinstance(m, sklearn.ensemble.forest.RandomForestClassifier):\n        res = [recall_score(m.predict(X_train_rf), y_train), recall_score(m.predict(X_dev_rf), y_dev),m.score(X_train_rf, y_train), m.score(X_dev_rf, y_dev)]\n        if hasattr(m, 'oob_score_'): \n            res.append(m.oob_score_)\n            out_text = f'Recall_Train:{res[0]} - Recall_Dev:{res[1]} - Accuracy_train::{res[2]} - Accuracy_Dev:{res[3]} - OOB:{res[4]}'\n        else:\n            out_text = f'Recall_Train:{res[0]} - Recall_Dev:{res[1]} - Accuracy_train::{res[2]} - Accuracy_Dev:{res[3]}'\n            \n    print(out_text)","f59c7065":"m = RandomForestClassifier(n_estimators=20, n_jobs=-1)\nm.fit(X_train_rf, y_train)\nprint_score(m)","7a645f92":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1)\nm.fit(X_train_rf, y_train)\nprint_score(m)","61090dd4":"m = RandomForestClassifier(n_estimators=80, n_jobs=-1)\nm.fit(X_train_rf, y_train)\nprint_score(m)","8f90eacf":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True)\nm.fit(X_train_rf, y_train)\nprint_score(m)","4bda879f":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True, min_samples_leaf= 3)\nm.fit(X_train_rf, y_train)\nprint_score(m)","fa113bf2":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True, min_samples_leaf= 5)\nm.fit(X_train_rf, y_train)\nprint_score(m)","c25d9bdd":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True, min_samples_leaf= 10)\nm.fit(X_train_rf, y_train)\nprint_score(m)","d193f660":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True, min_samples_leaf= 25)\nm.fit(X_train_rf, y_train)\nprint_score(m)","32bcc6e8":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True, min_samples_leaf= 100)\nm.fit(X_train_rf, y_train)\nprint_score(m)","f313f49d":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True, min_samples_leaf= 15, max_features=0.5)\nm.fit(X_train_rf, y_train)\nprint_score(m)","7584b783":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True, min_samples_leaf= 15, max_features='sqrt')\nm.fit(X_train_rf, y_train)\nprint_score(m)","799844ab":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True, min_samples_leaf= 15, max_features='log2')\nm.fit(X_train_rf, y_train)\nprint_score(m)","5dd252a4":"fi = m.feature_importances_\nfi\nX_train_rf.shape\nX_train_rf = X_train_rf.loc[:,fi > 0.02] # Let's remove the less important ones\nX_dev_rf = X_dev_rf.loc[:,fi > 0.02] # Let's remove the less important ones\n","a17836ba":"m = RandomForestClassifier(n_estimators=40, n_jobs=-1, oob_score=True, min_samples_leaf= 15, max_features='log2')\nm.fit(X_train_rf, y_train)\nprint_score(m)","01af4241":"## Rule based polarity and subjectivity sentiment analysis\nJust compute the polarity and sentiment of each comment based on rules (Textblob pakcage by Steven Loria)  (https:\/\/textblob.readthedocs.io\/en\/dev\/)","3d242cf5":"### NB with binary inputs","ddbb14a4":"This words should be included in the stopwords list because they dont offer any discriminant information for the two classes","1fdcb9e6":"## NB_LR: Naive Bayes as \"prior\" of a regularized LR\nIn order to try more thing is to combine the Naive Bayes with a logistic regressor for example (other classifiers are also valid as SVM but for simplicity I will use LR). Paper by Sida Wang and Chris Manning in https:\/\/nlp.stanford.edu\/pubs\/sidaw12_simple_sentiment.pdf ** ","2b162d45":"## 1 - Contains numbers","c08e1ff4":"The binary classes are quite balanced (no conerns regarding unbalanced classes classification)","76f7aff8":"** With 40 trees seems to be enough **","dd3d4463":" ** There are some outliers (the ones longer that around 500 are very rare) ** <br \/>\n ** To speed up (less vocab) let's remove all comments longer than this **","1bffb0b5":"## Naive Bayes Classifier \n** First I am implementing the NB classifier with some variants like binarizing the input or not (sometimes it helps) and with the TF-IDF representation. I am immplementing directly instead of using sklearn for example so it will be easier for me to stack it with another classicator as Logistic Regression (one easy and fast). **","5243fdad":"## Random Forest with non proper words features\nNow let's try a RF over the features computed during the EDA to see if they have also patterns with predictive power as it seems in the analysis","47d767f5":"It seems that the harmful comments more subjective and a little bit more polarized => Could be a good extra feature","f039e8b6":"Find the top words in order to remove them if they belong to both classes. ","a78b0a65":"It seems that LR obtains slightly better results that NB, binary input doesn't seem to have much impact on performance (taking into account that comments are very short it almost no make difference on the input).","2e14fee8":"Let's regularize to avoid the overfitting","1a259de1":"In priciple it seems that having Emojis do not imply a clear difference betweeeen the two classes","a6908023":"## Modelling and Evaluation","4996d824":"Both the binary and the standard NB seems to have similar results. Let's try with a classifier that minimize a cost function (the weights are learned minimizing it) as LR","f7410429":"** For a quicky iteration a fucntion that prints the scores (in sklearn is the one used by default in classification, I consider that could be a good one but it depends on the \"cost\" considered for a False positive. Let's include also the Recall (how much of the Harmful comments does the model detect?, there is a trade off with the Precision but for now just include the Recall, the driven metric will be the accuracy, the recall alone can be pretty misleading if you make changes based only on it) **","b534a6c6":"It seems that 'contain_numbers' is a good feature","f6754a92":"# 5 - Most common words","d7f200c9":"The RF out of the box seems worse than NB or LR or NBLR. Lets try to tune it a little bit","805b8ea6":"It looks that the sentiment emojis features could be good features to discriminate classes. The thing is that some non-linear model would be needed (maybe trying a RForest).\n","8a8d417a":"## 4 - Emoji Features","288958de":"## Logistic Regression","51b0e17f":"It looks like with around at least 15 samples per leaf the overfitting is reduced drastically and improving the performance in Dev and OOB. It still seems that the OOB is slightly higher than DEV, let's try to improve it trying to build trees more uncorrelated with the max_features","34d1ca21":"## 6 - Document Term Matrix and Top words + Train\/Dev\/Test split\nBuilindg a DTM with sklearn is very easy and a quick way of removing stopwords (there may be better ways). \nLet's reasearch about the growth of features (vocab size) depending on the n-gram range => ~15k unigrams ~50k biramgs ~ 40k trigams: Let's do with the unigrams. Beofre doing this we have to split the comments data frame in the different sets in order to not overfit:","41cd71be":"# EDA + Feature Engineering","50f06925":"### NB with counts","7e7e730f":"It looks that both classes behave in the standard way, percentage of capital letters seems not to be a relevant feature for the binary classification","fbdaf04d":"The multiclass problem is quite unbalanced (some class agregations may be done or some hierarchiechal classifications, e.g 7 vs rest --> 8 vs rest that were not 7 etc.)","79a0fcf5":"It seems to improve slightly, getting to almost 78.5% of accuracy on Dev","74d10d61":"## DATA BASIC CLEANING\n\n**TODO: Explain here a litle bit the steps I am going to take**\n","b005dff9":"** After trying some modifications of the variables it looks that a deeply analysis of the variables (for example doing and agregation\/hierarchiecal clustering based on a spearman correlation metric would indicate what variables are very similar to each other and try to remove this variables instead of importance) should be done. The removal of less importance variables doesn't  help at all **","066eadc3":"# 3 - Character length","9b5ed06b":"** Because the OOB is almost equal (actually slightly greater) than the Accuracy Dev this shows that this RF model can be improved (OOB should be less because this error is computed using less trees per sample than the Accuracy). Also it can be seen that there is some degree of overfitting (Acc Train vs Accuracy Dev). So the idea is to try that the individual trees to not overfit so much (min leaf greatet) without trying to uncorrelated them for now (max_features = 'all' by default) **","e521d18f":"Now let's compute the intersection of the first 30 words","510ea899":"## Loading Data","286c14b6":"I define the **log-count ratio** $r$ for each word $f$:\n\n$r = \\log \\frac{\\text{ratio of feature $f$ in harmful comments}}{\\text{ratio of feature $f$ in non-harmful comments}}$\n\nwhere ratio of feature $f$ in harmful comments is the number of times a harmful comment has a feature divided by the number of harmful comments. The key is that here **there is no cost function minimization as in other classifiers like Logistic regression **","986f509a":"With this regularization seems to overfit less and improves slightly the dev performance. Lets try binarizing the input","bfc79039":"# Conclusion","d53cef8c":"It looks that trying to uncorrelate the trees is not helping very much. Now we should try to understand the feature importances to see possible redundances and try to simplify it and even include some interactions if suitable.","cfd06ec9":"It looks like the Harmful comments are a little bit longer","057053a2":"It looks like the relation is \"inverse\", I think this is normal behaviour (the longer the comment is, the less percentage of capitals it has) <br \/>\nLet's check if this behaviour is the same conditioning on each class","04c62ff8":"** Some visual inspection of the comments: **","2043dcda":"It looks like withe the harmful\/non-harmful comments there is no much difference in the percentage of capital letters.","a5617822":"With this analysis, it seems that the classical aproaches as NB, or LR give better performance that a tree based method as RF without using text and using only \"global\" features of the comments. In spite of this, the RF has some predictive power that may be not captured by NB or LR (something that with error analysis could be discovered). Alone, the best solution seems to be the NBLR (~79% of accuracy), other tests could be done as combining two models, the RF with the NBLR in some way (from a simple bagging averaging the probability predictions or something more advance as stacking them like the RF using as input the prediction of the NBLR). Also, NBLR could use as inputs too the non-word features <br \/>\nOf course more advance techniques like using some pre-trained NN (spacy models on web content) could be used to perform a much more tuned data preparation. I think that this is critical, try to normalize the words, the typos and this things could imply a great improvement, from a \"normalized\" semantically comments I am sure this would suppose that even training an ad-hoc RNN or CNN with more data could be successful","fb5723c5":"## 2 - Percentage of capital letters:\nCreate a new feature based on this before lowering the comments, it would be useful for the models"}}