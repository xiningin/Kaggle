{"cell_type":{"2cad8959":"code","85706c22":"code","e040b541":"code","7d93d007":"code","960e2a92":"code","72c75622":"code","2db83460":"code","a0957c2d":"code","7085bef0":"code","150431cc":"code","0c9fe7b8":"code","fde5d3ca":"code","ba0c095a":"markdown","1c5de6a1":"markdown","189be16a":"markdown","61f744ab":"markdown","508700af":"markdown","d43954ec":"markdown","b8aaf2e7":"markdown","8b7f0b6d":"markdown","6b1965fc":"markdown","88a44da4":"markdown","027e7694":"markdown"},"source":{"2cad8959":"import pandas as pd\nimport numpy as np\nimport keras \nimport keras.models as M\nimport keras.layers as L\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom colorama import Fore as f\nimport tensorflow_addons as tfa\nfrom tensorflow_addons.layers import InstanceNormalization as IN","85706c22":"original=Image.open('..\/input\/cg1050\/TRAINING_CG-1050\/TRAINING\/ORIGINAL\/Im100_2_cm.jpg')\noriginal","e040b541":"tampered=Image.open('..\/input\/cg1050\/TRAINING_CG-1050\/TRAINING\/TAMPERED\/Im100_cm2.jpg')\ntampered","7d93d007":"img_shape=(150,150)\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\ndatagen_valid=ImageDataGenerator()\n# Getting training data\ntraining_data=datagen.flow_from_directory('..\/input\/cg1050\/TRAINING_CG-1050\/TRAINING\/',target_size=img_shape,color_mode='rgb',batch_size=64,seed=32,interpolation='bicubic')\nvalidation_data=datagen_valid.flow_from_directory('..\/input\/cg1050\/VALIDATION_CG-1050\/VALIDATION\/',target_size=img_shape,color_mode='rgb',batch_size=64,seed=32,interpolation='bicubic')","960e2a92":"def make_model():\n    model=M.Sequential()\n    model.add(L.Conv2D(filters=32,kernel_size=(3,3),padding='same',strides=2,activation=\"relu\",input_shape=(150,150,3)))\n    model.add(IN(axis=-1))\n    model.add(L.MaxPooling2D(pool_size=(2,2)))\n    model.add(L.Conv2D(filters=64,kernel_size=(3,3),padding='same',strides=2))\n    model.add(L.MaxPooling2D(pool_size=(2,2)))\n    model.add(L.Dropout(0.4))\n    model.add(L.Conv2D(filters=128,kernel_size=(3,3),padding='same',strides=2))\n    model.add(L.MaxPooling2D(pool_size=(2,2)))\n    model.add(L.Flatten())\n    model.add(L.Dense(100,'relu'))\n    model.add(L.Dropout(0.4))\n    model.add(L.Dense(2,'softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    return model\n","72c75622":"model=make_model()\nmodel.summary()","2db83460":"early_stop=keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=4)\nreduce_lr=keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',patience=2)\nmodel.fit(training_data,validation_data=validation_data,epochs=40,callbacks=[early_stop,reduce_lr])","a0957c2d":"loss=model.history.history['loss']\nval_loss=model.history.history['val_loss']\nacc=model.history.history['accuracy']\nval_acc=model.history.history['val_accuracy']\nepochs=[i for i in range(len(loss))]\nplt.plot(epochs,loss)\nplt.plot(epochs,val_loss)\nplt.show();","7085bef0":"plt.plot(epochs,acc)\nplt.plot(epochs,val_acc)\nplt.show();","150431cc":"def predict_image(path):\n    image=cv2.imread(path)\n    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    image=cv2.resize(image,(150,150))\n    image=image.reshape(1,150,150,3)\n    prediction=np.argmax(model.predict(image))\n    labels=['Original','Tampered']\n    return labels[prediction]\n    ","0c9fe7b8":"predict_image('..\/input\/cg1050\/VALIDATION_CG-1050\/VALIDATION\/ORIGINAL\/Im100_1_cm.jpg')","fde5d3ca":"predict_image('..\/input\/cg1050\/VALIDATION_CG-1050\/VALIDATION\/TAMPERED\/Im100_cm1.jpg')","ba0c095a":"<p style=\"font-family:courier;font-size:200%;color:#184d47;background-color:#eeb76b;\">Tampered Image<\/p>","1c5de6a1":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Changes In Accuracy Over Epochs<\/p>","189be16a":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Importing Packages<\/p>","61f744ab":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Predicting some of the images<\/p>","508700af":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Defining Model<\/p>","d43954ec":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Using Image Data Generator<\/p>","b8aaf2e7":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Changes In Loss Over Epochs<\/p>","8b7f0b6d":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Fitting The Model<\/p>","6b1965fc":"![](https:\/\/i.pinimg.com\/236x\/d5\/7c\/b7\/d57cb72a6601047fc4385836b5fac072.jpg)","88a44da4":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Having a look at the data<\/p>\n<p style=\"font-family:courier;font-size:200%;color:#184d47;background-color:#eeb76b;\">Original Image<\/p>","027e7694":"<p style=\"font-family:courier;font-size:300%;color:#184d47;background-color:#e4d3cf;\">Thank You<\/p>"}}