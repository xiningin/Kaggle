{"cell_type":{"f999e946":"code","9655cd47":"code","9457ad45":"code","fd3ee53d":"code","54bfa9a7":"code","36ae1784":"code","982cec31":"code","abfdc05f":"code","f15cf5cc":"code","61e75ef1":"code","ed9fc270":"code","c66d0335":"code","385f1f76":"code","d396ecd1":"code","564ed2ea":"code","0cd53e25":"code","d1f24aa8":"code","50777bd8":"code","796d9c5a":"code","d69952b9":"markdown","9ca5c2c1":"markdown","0fd4cca4":"markdown","1c08ddcf":"markdown","34f70109":"markdown","5157bf49":"markdown","6dcbe236":"markdown","27f49d61":"markdown","4c163da3":"markdown"},"source":{"f999e946":"import os\nimport random\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn.metrics\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img","9655cd47":"base_dir = os.path.join(\"\/kaggle\/input\/kermany2018\/oct2017\/OCT2017 \/\")\nprint('Base directory --> ', os.listdir(base_dir))","9457ad45":"train_dir = os.path.join(base_dir + \"train\/\")\nprint(\"Train Directory --> \", os.listdir(train_dir))\n\nvalidation_dir = os.path.join(base_dir + \"val\/\")\nprint(\"Validation Directory --> \", os.listdir(validation_dir))\n\ntest_dir = os.path.join(base_dir + \"test\/\")\nprint(\"Test Directory --> \", os.listdir(test_dir))","fd3ee53d":"vgg19 = tf.keras.applications.VGG19(\n    include_top = False, \n    weights = 'imagenet', \n    input_tensor = None,\n    input_shape = (150,150,3), \n    pooling = None, \n    classes = 1000\n)","54bfa9a7":"vgg19.trainable = False\n# locking initial layer weights of the imported models","36ae1784":"model_vgg = tf.keras.models.Sequential([\n    \n    vgg19,\n    tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = 'same'),\n    tf.keras.layers.PReLU(alpha_initializer='zeros'),# modifying final layers of VGG-19\n    tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = 'same'),\n    tf.keras.layers.PReLU(alpha_initializer='zeros'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100),\n    tf.keras.layers.PReLU(alpha_initializer='zeros'),\n    tf.keras.layers.Dense(4, activation = 'softmax')\n])","982cec31":"metrics = ['accuracy',\n                tf.keras.metrics.AUC(),\n                tfa.metrics.CohenKappa(num_classes = 4),\n                tfa.metrics.F1Score(num_classes = 4),\n                tf.keras.metrics.Precision(), \n                tf.keras.metrics.Recall()]","abfdc05f":"model_vgg.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = metrics)\nmodel_vgg.summary()","f15cf5cc":"train_datagen = ImageDataGenerator(rescale = 1.\/255)\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 500)","61e75ef1":"validation_datagen = ImageDataGenerator(rescale = 1.\/255)\nvalidation_generator = validation_datagen.flow_from_directory(validation_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 16)","ed9fc270":"test_datagen = ImageDataGenerator(rescale = 1.\/255)\ntest_generator = test_datagen.flow_from_directory(test_dir, target_size = (150, 150), class_mode = 'categorical', batch_size = 50)","c66d0335":"history_vgg = model_vgg.fit(\n    train_generator,\n    steps_per_epoch = (83484\/500),\n    epochs = 15,\n    validation_data = validation_generator,\n    validation_steps = (32\/16),\n    max_queue_size=100,\n    workers = 4 ,\n    use_multiprocessing=True,\n    verbose = 1)","385f1f76":"print(\"Values for VGG-19 based ConvNet\")\nacc = history_vgg.history['accuracy']\nval_acc = history_vgg.history['val_accuracy']\nloss = history_vgg.history['loss']\nval_loss = history_vgg.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.figure(figsize=(12,12))\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training & validation accuracy')\nplt.legend()\n\nplt.figure(figsize = (12,12))\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training $ validation loss')\nplt.legend()\n\nplt.show()","d396ecd1":"model_vgg.evaluate(test_generator)","564ed2ea":"test_steps_per_epoch = np.math.ceil(test_generator.samples \/ test_generator.batch_size)\n\npredictions = model_vgg.predict_generator(test_generator, steps = test_steps_per_epoch)\n\npredicted_classes = np.argmax(predictions, axis=1)","0cd53e25":"true_classes = test_generator.classes\nclass_labels = list(test_generator.class_indices.keys())  ","d1f24aa8":"report = sklearn.metrics.classification_report(true_classes, predicted_classes, target_names = class_labels)\nprint(report) ","50777bd8":"cm = sklearn.metrics.confusion_matrix(true_classes, predicted_classes)\nplt.figure(figsize=(8,8))\nsns.heatmap(cm, fmt='.0f', annot=True, linewidths=0.2, linecolor='purple')\nplt.xlabel('predicted value')\nplt.ylabel('Truth value')\nplt.show()","796d9c5a":"from keras.models import load_model\nmodel_vgg.save(\"oct_network.h5\")","d69952b9":"# Loss and accuracy vs epochs","9ca5c2c1":"# Loading training, validation and test data","0fd4cca4":"# Defining the models","1c08ddcf":"# Defining transfer learning model VGG-19","34f70109":"# Save model","5157bf49":"# Importing dataset ","6dcbe236":"# VGG19 model classification report","27f49d61":"# Models evaluated","4c163da3":"# Training the models"}}