{"cell_type":{"4c08e7e7":"code","8529fe27":"code","dca90090":"code","b16e9869":"code","a1bdf621":"code","11b0671c":"code","f56a0ffc":"code","02177b27":"code","120530f3":"code","93dca974":"code","2813b016":"code","e0ad3e63":"code","2fdc270e":"code","b93fb154":"code","0e94286c":"code","f5ced20e":"code","c8396ce2":"code","d9e4f11a":"code","7903839b":"code","fbe24f3b":"code","7ff320b9":"code","591c7f95":"markdown","911f445d":"markdown","7be308ae":"markdown","107f6d23":"markdown","5fc61220":"markdown","49d79631":"markdown","741879eb":"markdown","1d042d1d":"markdown","02837eb5":"markdown","b43eb8d8":"markdown","87bb8f75":"markdown","c7e38cf2":"markdown","d569b6ee":"markdown","62f81e90":"markdown","e4a7e356":"markdown","e680fc48":"markdown","7a07be0a":"markdown","ba6d55bb":"markdown","39f93db4":"markdown","2743ca27":"markdown","466b4057":"markdown","74cb69f2":"markdown","106665f6":"markdown"},"source":{"4c08e7e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport timeit\nimport numpy as np\nimport random\nrandom.seed(42)\n\nfrom math import factorial\n# Any results you write to the current directory are saved as output.","8529fe27":"def wrapper(func, *args, **kwargs):\n    def wrapped():\n        return func(*args, **kwargs)\n    return wrapped\n\ndef timer(func, *args):\n    wrapped = wrapper(func, *args)\n    time = timeit.timeit(wrapped,number=10000)\n    return(\"Time of execution is {} ms\".format(time))","dca90090":"# Example from Ravi Ojha's post (see link above). \n# Adds 2 numbers\ndef O1_add(n1, n2):\n    return (n1 + n2)","b16e9869":"# No matter what the input, the function executes in one step, so roughly the same time complexity\nfor n in range(1,6):\n    print(n,\",\",n + random.randint(1,int(1e10)))\n    print(timer(O1_add, int(n), int(n) + random.randint(1,int(1e10))))\n    print()","a1bdf621":"# Checks whether a number is even or odd by checking last digit of binary representation\ndef O1_odd_check(num):\n    is_odd = False\n    if num & 1 == 1:\n        is_odd = True\n    return is_odd","11b0671c":"check_lst = [1,5,8,82,101]\nfor num in check_lst:\n    print(num,\"::\",O1_odd_check(num),\"::\",timer(O1_odd_check, num))","f56a0ffc":"# Finds an item in an unsorted list\ndef On_simple_search(lst,number):\n    is_found = False\n    for num in lst:\n        if num == number:\n            is_found = True\n    return is_found","02177b27":"lst1 = range(5)\nlst2 = range(500)\nlst3 = range(50000)\n\nnum1 = 2\nnum2 = -50\nnum3 = 4000\nprint(On_simple_search(lst1,num1),\"::\",timer(On_simple_search,lst1,num1))\nprint(On_simple_search(lst2,num2),\"::\",timer(On_simple_search,lst2,num2))\nprint(On_simple_search(lst3,num3),\"::\",timer(On_simple_search,lst3,num3))","120530f3":"def Ologn_binary_search(list,number):\n    first = 0\n    last = len(list) - 1\n    is_found = False\n    while first <= last and not is_found:\n        mid = (first + last)\/\/2\n        if list[mid] == number:\n            is_found = True\n        else:\n            if number < mid:\n                last = mid - 1\n            else:\n                first = mid + 1\n    return is_found","93dca974":"lst1 = range(5)\nlst2 = range(500)\nlst3 = range(50000)\n\nnum1 = 2\nnum2 = -50\nnum3 = 4000\nprint(Ologn_binary_search(lst1,num1),\"::\",timer(Ologn_binary_search,lst1,num1),\"::\",\"log value = {}\".format(np.log2(len(lst1))))\nprint(Ologn_binary_search(lst2,num2),\"::\",timer(Ologn_binary_search,lst2,num2),\"::\",\"log value = {}\".format(np.log2(len(lst2))))\nprint(Ologn_binary_search(lst3,num3),\"::\",timer(Ologn_binary_search,lst3,num3),\"::\",\"log value = {}\".format(np.log2(len(lst3))))","2813b016":"def Onlogn_merge_sort(sequence):\n    if len(sequence) < 2:\n        return sequence\n    \n    m = len(sequence) \/\/ 2\n    return Onlogn_merge(Onlogn_merge_sort(sequence[:m]), Onlogn_merge_sort(sequence[m:]))\n\n\ndef Onlogn_merge(left, right):\n    result = []\n    i = j = 0\n    while i < len(left) and j < len(right):\n        if left[i] < right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    result += left[i:]\n    result += right[j:]\n\n    return result","e0ad3e63":"array = [4, 2, 3, 8, 8, 43, 6,1, 0]\nar = Onlogn_merge_sort(array)\nprint (\" \".join(str(x) for x in ar))","2fdc270e":"lst1 = [4,2,3,8,8,43,6,1,0,83]\nlst2 = []\nfor i in range(100):\n    lst2.append(random.randint(0,i))","b93fb154":"print(\"Sorted lst1:: \",Onlogn_merge_sort(lst1))\nprint(timer(Onlogn_merge_sort,lst1),\" :: nlogn ~= {}\".format(len(lst1)*np.log2(len(lst1))))\n\nprint(\"Sorted lst2:: \",Onlogn_merge_sort(lst2))\nprint(timer(Onlogn_merge_sort,lst2),\" :: nlogn ~= {}\".format(len(lst2)*np.log2(len(lst2))))","0e94286c":"def On2_bubble_sort(lst):\n    for i in range(len(lst)-1):\n        for j in range(len(lst)-1-i):\n            if lst[j] > lst[j+1]:\n                lst[j], lst[j+1] = lst[j+1], lst[j]\n    return lst","f5ced20e":"lst1 = [4,2,3,8,8,43,6,1,0,83]\nlst2 = []\nfor i in range(100):\n    lst2.append(random.randint(0,i))","c8396ce2":"print(\"Sorted lst1:: \",On2_bubble_sort(lst1))\nprint(timer(On2_bubble_sort,lst1),\" :: n^2 ~= {}\".format(len(lst1)**2))\n\nprint(\"Sorted lst2:: \",On2_bubble_sort(lst2))\nprint(timer(On2_bubble_sort,lst2),\" :: n^2 ~= {}\".format(len(lst2)**2))","d9e4f11a":"# Sum of a Fibonacci series up to the nth term\ndef o2n_fibonacci(n):\n    if n<2:\n        return n\n    return o2n_fibonacci(n-1) + o2n_fibonacci(n-2)","7903839b":"for n in range(2,12,2):\n    print(\"Series sum for {} is {}\".format(n,o2n_fibonacci(n)),\" :: \",timer(o2n_fibonacci,n),\" :: 2^n = {}\".format(2**n))","fbe24f3b":"def onfac_perm(a, k=0):\n    if k==len(a):\n#         print(a) # Commendted out for display purposes\n        pass\n    else:\n        for i in range(k, len(a)):\n            a[k],a[i] = a[i],a[k]\n            onfac_perm(a, k+1)\n            a[k],a[i] = a[i],a[k]","7ff320b9":"lst1 = [1,2,]\nlst2 = [1,2,3,4]\nlst3 = [1,2,3,4,5,6]\n\nprint(\"List of {} items :: \".format(len(lst1)), timer(onfac_perm,lst1), \" :: factorial {} is {}\".format(len(lst1),factorial(len(lst1))))\nprint(\"List of {} items :: \".format(len(lst2)), timer(onfac_perm,lst2), \" :: factorial {} is {}\".format(len(lst2),factorial(len(lst2))))\nprint(\"List of {} items :: \".format(len(lst3)), timer(onfac_perm,lst3), \" :: factorial {} is {}\".format(len(lst3),factorial(len(lst3))))","591c7f95":"### So we see from the above, that for each run, across the sum of different pairs of numbers, the runtime remains approximately the same. ","911f445d":"# 3. O(log n) (Logarithmic)","7be308ae":"### The run-time or order complexity will double for every new addition to the input (https:\/\/stackoverflow.com\/questions\/1592649\/examples-of-algorithms-which-has-o1-on-log-n-and-olog-n-complexities). A classic example is the Fibonacci series, calculated recursively. Each function call makes 2 more function calls till we get to zero.","107f6d23":"### It's easy to understand why understand why bubble sort is O($n^2$), since there are two nested for loops, each running **n** times. The runtimes are also roughly scale with the order of the square of the input size. ","5fc61220":"### Again, this function always requires just one operation (i.e. checking the last digit of the binary representation) so the time complexity is constant","49d79631":"# 2. O(n) (Linear)","741879eb":"### So we see that the runtime for the merge sort algorithm scales as O (n log n)","1d042d1d":"# 6. O($2^n$) (Exponential)","02837eb5":"### One can see the run time trends clearly. \n\n### This brings this kernel to a close. An effort to retain and understand some of the most common Time complexity types, along with a check of the actual run-times of the algorithms. I will build on this and write another kernel which talks about the Big O for the various kinds of sorting algorithms.\n\n### Upvote it if you like it and let me know if you find it helpful.  If I have mentioned mention any faulty concepts that are in need of addressing please feel free to correct me! \n\n### Find me on LinkedIn at https:\/\/www.linkedin.com\/in\/panchajanya-banerjee\/","b43eb8d8":"### First we'll write a function to measure the time of execution","87bb8f75":"### This is linear time complexity, so the running time increases, at most, with the size of the input **n**. Once again, this is very neatly explained in https:\/\/www.rookieslab.com\/posts\/how-to-compute-time-complexity-order-of-growth-of-any-program","c7e38cf2":"### And why is this exponential?  Well, the definition of *e* is literally $\\lim_{n \\to \\infty} (1 +\\frac{1}{n} )^n $. ","d569b6ee":"# 1. O(1) (Constant)\n### Algorithms which always have the same running time","62f81e90":"# 7. O(n!) (Factorial)","e4a7e356":"### This will arise anytime we call an O(log n) algorithm inside a loop. A basic merge sort example is presented below. (https:\/\/stackoverflow.com\/questions\/18761766\/mergesort-python)","e680fc48":"### In this case, as is self-evident, the time complexity will go as the logarithm of the input size. For a very succinct explanation of why the order complexity in a Binary Search Tree is O(log n) see https:\/\/stackoverflow.com\/questions\/14426790\/why-lookup-in-a-binary-search-tree-is-ologn. Here  we will just illustrate a basic binary search.\n","7a07be0a":"### A bit of quick mental math tells us that the runtimes do indeed scale as the logarithm (to the base 2) of the input size","ba6d55bb":"### As you can see from the above, the runtimes scale linearly with the number of elements that the list has, i.e. the maximum number of elements that we have to look through to find the number we are searching for","39f93db4":"# 4. O(n log n) (Log-Linear)","2743ca27":"# 5. O ($n^2$) (Quadratic)","466b4057":"### Quadratic complexity is one general case of polynomial complexity (O($n^c$) where c is some positive integer). We test out the runtime on a basic bubble sort algorithm. ","74cb69f2":"As someone whose introduction to computation was always via Physics, I have had to teach myself Order complexity of algorithms. I found some great resources on the internet, namely https:\/\/www.rookieslab.com\/posts\/how-to-compute-time-complexity-order-of-growth-of-any-program and https:\/\/towardsdatascience.com\/a-data-scientists-guide-to-data-structures-algorithms-1176395015a0. So I figured I'd write a little kernel to test out the run-times of various programs (with varying time complexities) myself, just to internalize the information better. \n\nThe big O notation for algorithms (https:\/\/en.wikipedia.org\/wiki\/Big_O_notation) ends up giving us the slowest possible estimate for the run-time of the algorithm, and how that run-time scales with the input size **n**.  Also, in all cases, we are only interested in n >> c, where c is the set of any other constants that may add to the time complexity (say an initialization step) so we don't care about these. \n\nHere we just mention the most important and commonly encountered time complexities via some simple example codes in python","106665f6":"### A program to get all the permutations of an array (list) would be a simple example of this, since the number of lists you have is n! (https:\/\/stackoverflow.com\/questions\/104420\/how-to-generate-all-permutations-of-a-list-in-python)"}}