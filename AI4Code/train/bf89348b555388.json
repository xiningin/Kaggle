{"cell_type":{"12a44a40":"code","06570d16":"code","01142b1b":"code","29c3802d":"code","38b75bb8":"code","d81783a3":"code","0f1b381d":"code","c91568f8":"code","186dc68e":"code","6d2dc972":"code","b638dbe8":"code","9dcf8227":"code","77365629":"code","c042893f":"code","6589a55e":"code","39031bd8":"code","116cae38":"code","9f58fd61":"code","27af62c6":"code","a1e65c9b":"code","8144f786":"code","75cb6676":"code","a1a27633":"code","103bdedd":"code","eae7f471":"code","9fc6b72e":"code","91ea736e":"code","97b3a0e0":"code","133d379b":"code","7648a6ce":"code","63fb3db3":"code","1469afb9":"code","852861f7":"code","3c5078f3":"code","32d8e647":"code","e7c3733e":"code","ed092e19":"code","dd2182be":"code","d0a405b7":"code","ff3f7299":"code","86e40e6c":"code","a61f3a1f":"code","52e712f8":"code","19205671":"code","f0610380":"code","8bd70690":"code","8c8aec77":"markdown","37ba5ca8":"markdown","40a967d3":"markdown","8dcc90db":"markdown","f9b03825":"markdown","2251f238":"markdown","e26c08cf":"markdown","c99cd3af":"markdown","b12d2bb7":"markdown","cdee8107":"markdown","d7b6d8d6":"markdown","ad40a292":"markdown","35400a03":"markdown","0a9ffe1d":"markdown","e8d257bb":"markdown","98a82cac":"markdown","ceb21fc4":"markdown","7bee3802":"markdown","77077b9f":"markdown","8089a1ea":"markdown","41800602":"markdown","ee52a9e2":"markdown"},"source":{"12a44a40":"!nvidia-smi","06570d16":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","01142b1b":"import tensorflow.keras as keras\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.callbacks as C\nfrom tensorflow.keras.preprocessing import image","29c3802d":"from tensorflow.keras.applications import EfficientNetB7","38b75bb8":"!pip freeze > requirements.txt","d81783a3":"# \u0411\u0410\u0417\u041e\u0412\u042b\u0419 \u0412\u0410\u0420\u0418\u0410\u041d\u0422\n# \u0412 setup \u0432\u044b\u043d\u043e\u0441\u0438\u043c \u043e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438: \u0442\u0430\u043a \u0443\u0434\u043e\u0431\u043d\u0435\u0435 \u0438\u0445 \u043f\u0435\u0440\u0435\u0431\u0438\u0440\u0430\u0442\u044c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c.\n\n#EPOCHS               = 5  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\n#BATCH_SIZE           = 64 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\n#LR                   = 1e-4\n#VAL_SPLIT            = 0.15 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 15%\n\n#CLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\n#IMG_SIZE             = 224 # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\n#IMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\n#input_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\n#DATA_PATH = '..\/input\/'\n#PATH = \"..\/working\/car\/\" # \u0440\u0430\u0431\u043e\u0447\u0430\u044f \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f","0f1b381d":"# \u0412\u0430\u0440\u0438\u0430\u043d\u0442 \u043f\u043e\u0434\u0431\u043e\u0440\n\nEPOCHS               = 10  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 64 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.20 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 20%\n\nCLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\nIMG_SIZE             = 224 # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\nIMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/'\nPATH = \"..\/working\/car\/\" # \u0440\u0430\u0431\u043e\u0447\u0430\u044f \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f","c91568f8":"# \u0423\u0441\u0442\u0430\u043d\u0430\u043b\u0438\u0432\u0430\u0435\u043c \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 random seed \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\nos.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","186dc68e":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","6d2dc972":"train_df.info()","b638dbe8":"train_df.Category.value_counts()\n# \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0435 - \u044d\u0442\u043e \u0445\u043e\u0440\u043e\u0448\u043e","9dcf8227":"print('\u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"..\/input\/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","77365629":"print('\u041f\u0440\u0438\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train\/{random_image_cat[index]}\/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","c042893f":"image = PIL.Image.open(PATH+'\/train\/0\/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","6589a55e":"# \u0412\u044b \u043f\u043e\u043c\u043d\u0438\u0442\u0435, \u0447\u0442\u043e \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u0430\u0436\u043d\u0430, \u043a\u043e\u0433\u0434\u0430 \u043c\u044b \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u0441 \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0438\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u043e\u043c. \u042d\u0442\u043e \u043a\u0430\u043a \u0440\u0430\u0437 \u043d\u0430\u0448 \u0441\u043b\u0443\u0447\u0430\u0439.\n# \u0427\u0442\u043e\u0431\u044b \u043b\u0443\u0447\u0448\u0435 \u043f\u043e\u043d\u044f\u0442\u044c \u0440\u0430\u0431\u043e\u0442\u0443 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432, \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0438\u0445 \u0438\u0437\u043c\u0435\u043d\u0438\u0442\u044c. \u041a \u043a\u0430\u043a\u043e\u043c\u0443 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0443 \u044d\u0442\u043e \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u0442?\n# \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0434\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f: https:\/\/keras.io\/preprocessing\/image\/\n\n#train_datagen = ImageDataGenerator(\n#    rescale=1. \/ 255,\n#    rotation_range = 5,\n#    width_shift_range=0.1,\n#    height_shift_range=0.1,\n#    validation_split=VAL_SPLIT, # set validation split\n#    horizontal_flip=False)\n\n#test_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\n#\u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f \u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0438\u0442\u0435 \u0431\u043e\u043b\u0435\u0435 \u043f\u0440\u043e\u0434\u0432\u0438\u043d\u0443\u0442\u044b\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440: albumentations \u0438\u043b\u0438 imgaug, \u0434\u043b\u044f \u043d\u0438\u0445 \u0435\u0441\u0442\u044c \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \"\u043e\u0431\u0435\u0440\u0442\u043a\u0438\" \u043f\u043e\u0434 Keras, \u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440: https:\/\/github.com\/mjkvaak\/ImageDataAugmentor)","39031bd8":"!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor","116cae38":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations","9f58fd61":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1.\/255,\n        augment = AUGMENTATIONS,\n        validation_split=VAL_SPLIT,\n        )\n        \ntest_datagen = ImageDataAugmentor(rescale=1.\/255)","27af62c6":"# \u0417\u0430\u0432\u0435\u0440\u043d\u0435\u043c \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',      # \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f \u0433\u0434\u0435 \u0440\u0430\u0441\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u044b \u043f\u0430\u043f\u043a\u0438 \u0441 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u043c\u0438 \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload\/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n\n# \u041e\u0431\u0440\u0430\u0442\u0438\u0442\u0435 \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435, \u0447\u0442\u043e \u0434\u043b\u044f \u0441\u0430\u0431\u043c\u0438\u0442\u0430 \u043c\u044b \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0434\u0440\u0443\u0433\u043e\u0439 \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a test_datagen.flow_from_dataframe. \u041a\u0430\u043a \u0432\u044b \u0434\u0443\u043c\u0430\u0435\u0442\u0435, \u043f\u043e\u0447\u0435\u043c\u0443?","a1e65c9b":"base_model = Xception(weights ='imagenet', include_top=False, input_shape = input_shape)","8144f786":"#base_model = EfficientNetB7(include_top=False, weights='imagenet', input_shape=input_shape)","75cb6676":"base_model.summary()\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f: \u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0438 \u0434\u0440\u0443\u0433\u0438\u0435 \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u044b \u0441\u0435\u0442\u0435\u0439","a1a27633":"# \u0437\u0430\u043c\u043e\u0440\u043e\u0437\u0438\u043c \u0432\u0435\u0441\u0430 \u0438 \u043e\u0431\u0443\u0447\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e \"\u0433\u043e\u043b\u043e\u0432\u0443\". \n# \u0414\u0435\u043b\u0430\u0435\u043c \u0434\u043b\u044f \u0442\u043e\u0433\u043e, \u0447\u0442\u043e\u0431\u044b \u0445\u043e\u0440\u043e\u0448\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438 \u043d\u0430 Imagenet \u043d\u0435 \u0437\u0430\u0442\u0438\u0440\u0430\u043b\u0438\u0441\u044c \u0432 \u0441\u0430\u043c\u043e\u043c \u043d\u0430\u0447\u0430\u043b\u0435 \u043d\u0430\u0448\u0435\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\nbase_model.trainable = False","103bdedd":"# \u0411\u0410\u0417\u041e\u0412\u042b\u0419\n# \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043d\u043e\u0432\u0443\u044e \"\u0433\u043e\u043b\u043e\u0432\u0443\" (head)\n# \u0414\u041e\u0411\u0410\u0412\u041b\u042f\u0415\u041c Batch Normalization\n\n#x = base_model.output\n#x = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\n#x = Dense(256, activation='relu')(x)\n#x = BatchNormalization()(x)\n#base_model.add(L.BatchNormalization())\n#x = Dropout(0.25)(x)\n# and a logistic layer -- let's say we have 10 classes\n#predictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n# this is the model we will train\n#model = Model(inputs=base_model.input, outputs=predictions)\n#model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","eae7f471":"# \u0412\u0430\u0440\u0438\u0430\u043d\u0442 \u043f\u043e\u0434\u0431\u043e\u0440\u0430\n# \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043d\u043e\u0432\u0443\u044e \"\u0433\u043e\u043b\u043e\u0432\u0443\" (head)\n# \u0414\u041e\u0411\u0410\u0412\u041b\u042f\u0415\u041c Batch Normalization\n\nmodel=M.Sequential()\nmodel.add(base_model)\nmodel.add(L.GlobalAveragePooling2D(),)\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(L.BatchNormalization())\nmodel.add(L.Dropout(0.25))\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","9fc6b72e":"model.summary()","91ea736e":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","97b3a0e0":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\ncallbacks_list = [checkpoint]\n\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f 1. \u0414\u043e\u0431\u0430\u0432\u044c\u0442\u0435 \u0434\u0440\u0443\u0433\u0438\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0438\u0437 https:\/\/keras.io\/callbacks\/\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f 2. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 \u0440\u0430\u0437\u043d\u044b\u0435 \u0442\u0435\u0445\u043d\u0438\u043a\u0438 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f Learning Rate\n# https:\/\/towardsdatascience.com\/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng)\n# http:\/\/teleported.in\/posts\/cyclic-learning-rate\/ (eng)","133d379b":"history = model.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)\n\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f: \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0438\u0442\u044c transfer learning \u0441 fine-tuning","7648a6ce":"# \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u0441\u0435\u0442\u044c \u0438 \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u044e \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 (best_model)\nmodel.save('..\/working\/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","63fb3db3":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","1469afb9":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","852861f7":"base_model.trainable = True\n\n# \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u0443 \u0432\u0435\u0441\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0438\nfine_tune_at = len(base_model.layers)\/\/2\n\n# \u0437\u0430\u043c\u043e\u0440\u0430\u0436\u0438\u0432\u0430\u0435\u043c \u0432\u0441\u0435 \u0432\u0435\u0441\u0430 \u043a\u0440\u043e\u043c\u0435 \u0432\u044b\u0431\u0440\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0448\u0435\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","3c5078f3":"from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping","32d8e647":"EPOCHS               = 10  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 32 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.2 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 20%\n\nCLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\nIMG_SIZE             = 224 # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\nIMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/'\nPATH = \"..\/working\/car\/\" # \u0440\u0430\u0431\u043e\u0447\u0430\u044f \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f\n\n# \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 random seed \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0\n\n# \u0417\u0430\u0432\u0435\u0440\u043d\u0435\u043c \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',      # \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f \u0433\u0434\u0435 \u0440\u0430\u0441\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u044b \u043f\u0430\u043f\u043a\u0438 \u0441 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u043c\u0438 \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])\n\n# \u0414\u043e\u0431\u0430\u0432\u0438\u043c ModelCheckpoint \u0447\u0442\u043e\u0431 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u043f\u0440\u043e\u0433\u0440\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u043f\u043e\u0442\u043e\u043c \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c.    \ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]\n\n# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples\/\/train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples\/\/test_generator.batch_size,\n    epochs = EPOCHS,\n    callbacks = callbacks_list\n    )","e7c3733e":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","ed092e19":"# \u0421\u043e\u0445\u0440\u0430\u043d\u044f\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c\nmodel.save('..\/working\/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')","dd2182be":"base_model.trainable = True\n\nEPOCHS               = 5  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 16 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.2 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 20%\n\nCLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\nIMG_SIZE             = 224 # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\nIMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/'\nPATH = \"..\/working\/car\/\" # \u0440\u0430\u0431\u043e\u0447\u0430\u044f \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f\n\n# \u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 random seed \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0\n\n# \u0417\u0430\u0432\u0435\u0440\u043d\u0435\u043c \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',      # \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f \u0433\u0434\u0435 \u0440\u0430\u0441\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u044b \u043f\u0430\u043f\u043a\u0438 \u0441 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u043c\u0438 \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])\n\n# \u0414\u043e\u0431\u0430\u0432\u0438\u043c ModelCheckpoint \u0447\u0442\u043e\u0431 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u043f\u0440\u043e\u0433\u0440\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u043f\u043e\u0442\u043e\u043c \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c.    \ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\ncallbacks_list = [checkpoint, earlystop]\n\n# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples\/\/train_generator.batch_size,\n    validation_data = test_generator, \n    validation_steps = test_generator.samples\/\/test_generator.batch_size,\n    epochs = EPOCHS,\n    callbacks = callbacks_list\n    )","d0a405b7":"model.save('..\/working\/model_step3.hdf5')\nmodel.load_weights('best_model.hdf5')","ff3f7299":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","86e40e6c":"test_sub_generator.samples","a61f3a1f":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","52e712f8":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')\n\n# \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u044f: \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0434\u043e\u0431\u0430\u0432\u0438\u0442\u044c Test Time Augmentation (TTA)\n# https:\/\/towardsdatascience.com\/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","19205671":"submission.head()","f0610380":"# Clean PATH\nimport shutil\nshutil.rmtree(PATH)","8bd70690":"\u042d\u0442\u0430\u043f\u044b \u043f\u043e \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044e\\\u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u044e \u0432 \u043c\u043e\u0434\u0435\u043b\u044c:\n1. \u0414\u043e\u0431\u0430\u0432\u0438\u043b BatchNormalization \u0432 \u043c\u043e\u0434\u0435\u043b\u044c. \u041d\u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043f\u043e\u0432\u043b\u0438\u044f\u043b\u043e \u0441\u043d\u0438\u0436\u0435\u043d\u0438\u0435\u043c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043d\u0430 1%\n2. \u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0438\u043b \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0443 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 albumentations. \u041d\u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u043f\u043e\u0432\u043b\u0438\u044f\u043b\u043e \u0441\u043d\u0438\u0436\u0435\u043d\u0438\u0435\u043c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u043d\u0430 1%\n3. \u0414\u043e\u0431\u0430\u0432\u0438\u043b FineTuning \u043d\u0430 5 EPOCHS. \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u0441\u0442\u0430\u043b 0.94756. \u0421\u0443\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u0443\u043b\u0443\u0447\u0448\u0438\u043b\u0441\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\n4. \u041f\u043e\u043c\u0435\u043d\u044f\u043b \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 EfficientNetB7. \u0422\u043e\u0447\u043d\u043e\u0441\u0442\u044c 0.86786\n5. \u0412\u0435\u0440\u043d\u0443\u043b\u0441\u044f \u043a \u043c\u043e\u0434\u0435\u043b\u0438 Xception. \u041f\u043e\u043f\u0440\u0430\u0432\u0438\u043b \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b EPOCHS= 10 +LerningRate \u0441\u0434\u0435\u043b\u0430\u043b -4 \u0441\u0442\u0435\u043f\u0435\u043d\u0438. \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 0.94771. \u0427\u0443\u0442\u044c \u043b\u0443\u0447\u0448\u0435\n6. \u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0438\u0440\u0443\u044e. BATCH_SIZE \u043d\u0430 \u0433\u043e\u043b\u043e\u0432\u0435 64. \u041d\u0430 \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u0435 \u0432\u0435\u0441\u043e\u0432 32. \u0412\u0441\u044f \u0441\u0435\u0442\u044c 16. \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 0.94202\n\u041b\u0443\u0447\u0448\u0438\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 0.94756\n\n\ngithub https:\/\/github.com\/IgorChurakov87\/Project_7.git","8c8aec77":"\u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0438\u043b\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0443 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 albumentations","37ba5ca8":"### \u0423\u0436\u0435 \u0434\u043e\u0433\u0430\u0434\u044b\u0432\u0430\u0435\u0442\u0435\u0441\u044c, \u0447\u0442\u043e \u043e\u0437\u043d\u0430\u0447\u0430\u044e\u0442 \u043a\u043b\u0430\u0441\u0441\u044b?","40a967d3":"> \u042d\u0442\u043e \u043f\u0440\u0438\u043c\u0435\u0440 \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0437\u0430\u0434\u0430\u0447\u0438 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c Keras. \u0412\u044b \u043c\u043e\u0436\u0435\u0442\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u044d\u0442\u043e\u0442 \u043a\u0435\u0440\u043d\u0435\u0440 \u0434\u043b\u044f \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0438\u0445 \u0438\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u0439 \u0438 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432.\n# \u041a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439\n\n### \u041e\u0441\u043d\u043e\u0432\u043d\u0430\u044f \u0438\u0434\u0435\u044f \u044d\u0442\u043e\u0433\u043e \u0440\u0435\u0448\u0435\u043d\u0438\u044f: \u0432\u0437\u044f\u0442\u044c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0443\u044e \u043d\u0430 ImageNet \u0441\u0435\u0442\u044c Xception \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043f\u043e\u0434 \u043d\u0430\u0448\u0443 \u0437\u0430\u0434\u0430\u0447\u0443. \n\u041f\u043e \u0445\u043e\u0434\u0443 \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0434\u0430\u0432\u0430\u0442\u044c \u0432\u0430\u043c \u0440\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u043c\u043e\u0433\u0443\u0442 \u0443\u043b\u0443\u0447\u0448\u0438\u0442\u044c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u043c\u043e\u0434\u0435\u043b\u0438. \n\n\n\u0423\u0434\u0430\u0447\u0438 \u0438 \u041f\u043e\u0435\u0445\u0430\u043b\u0438!","8dcc90db":"**\u0420\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u0441 Tensorflow v2**","f9b03825":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f:","2251f238":"# 1.\u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","e26c08cf":"\u043f\u043e\u0432\u0442\u043e\u0440\u044f\u0435\u043c \u0442\u043e\u0436\u0435 \u0447\u0442\u043e \u0438 \u0441 \"\u0433\u043e\u043b\u043e\u0432\u043e\u0439\"","c99cd3af":"# 2.\u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","b12d2bb7":"# \u0412\u044b\u0432\u043e\u0434\u044b","cdee8107":"# 3.\u041e\u0431\u0443\u0447\u0430\u0435\u043c \u0433\u043e\u043b\u043e\u0432\u0443","d7b6d8d6":"### \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445","ad40a292":"#  4.FineTuning - \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u044b \u0432\u0435\u0441\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0438","35400a03":"\u0423\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u0434\u043e\u043f \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438\n","0a9ffe1d":"\u0414\u043e\u0431\u0430\u0432\u0438\u043c ModelCheckpoint \u0447\u0442\u043e\u0431 \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u043f\u0440\u043e\u0433\u0440\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u043f\u043e\u0442\u043e\u043c \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c.","e8d257bb":"# \u041e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438","98a82cac":"### \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c Xception:","ceb21fc4":"# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","7bee3802":"\u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0438 \u0438\u0445 \u0440\u0430\u0437\u043c\u0435\u0440\u044b \u0447\u0442\u043e\u0431 \u043f\u043e\u043d\u0438\u043c\u0430\u0442\u044c \u043a\u0430\u043a \u0438\u0445 \u043b\u0443\u0447\u0448\u0435 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0438 \u0441\u0436\u0438\u043c\u0430\u0442\u044c.","77077b9f":"# 6.\u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445","8089a1ea":"# 5.FineTuning - \u0440\u0430\u0437\u043c\u043e\u0440\u043e\u0437\u043a\u0430 \u0432\u0441\u0435\u0439 \u0441\u0435\u0442\u0438","41800602":"# EDA \/ \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445","ee52a9e2":"### \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445"}}