{"cell_type":{"864498ca":"code","401532ef":"code","f6f9274d":"code","53958cba":"code","4164cde2":"code","097f4fdf":"code","fd8027e6":"code","c352bd31":"code","2c028d19":"code","d389d001":"code","18ff8150":"code","3d47dc35":"code","531d5425":"code","aabff685":"code","400f5396":"code","e02ae1dc":"code","8533c51b":"code","21a90330":"code","918f13f9":"code","a4e4e741":"code","1bc4c3a1":"code","168c9b6c":"code","aeaee365":"code","ca995a9c":"code","b9ec3aa2":"code","99e92433":"code","858ee63a":"code","ff9a26d3":"code","b38df05d":"code","551c831e":"code","735acb27":"code","ca963d3a":"code","260d8f9c":"code","2846ade5":"code","e7d1093d":"code","53afed49":"code","039ec0a7":"code","f30a4d01":"code","1acbb73a":"code","ba81988e":"code","9008d2d2":"code","e6e5cfff":"code","55323321":"code","660e10c5":"code","f819c316":"code","82eabab0":"code","88218c77":"code","43c49fec":"code","802dba12":"code","798c6bff":"code","cf5f9d3f":"code","05df4ffe":"markdown","44f43c0c":"markdown","320c3e65":"markdown","d22dc66c":"markdown","87a7c284":"markdown","3ef4d32d":"markdown","9567b1c7":"markdown","627fa6e9":"markdown","92bc2096":"markdown","b374519e":"markdown","7e2e18a8":"markdown","15f1bcbe":"markdown","3ad2d27b":"markdown","517a7407":"markdown","b2a761b3":"markdown","b439a41b":"markdown","ba1e7057":"markdown","ea0ff3b1":"markdown","f5313a17":"markdown","0a18d910":"markdown","c3ceba83":"markdown","4e35d728":"markdown","35ee554e":"markdown","461d0c90":"markdown","16a42263":"markdown","423446bb":"markdown","cc5d6750":"markdown","9fa89df4":"markdown","82097ab9":"markdown","69eed5c6":"markdown","89cd0ac5":"markdown","7927aade":"markdown","0370229c":"markdown","4be30a89":"markdown","462e8b3d":"markdown","16c88e3f":"markdown","d286cfdc":"markdown","413f42d0":"markdown"},"source":{"864498ca":"import sqlite3\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import normalize\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\n\n\n#3. Read sqlite as panda dataframe with sql query\ncon = sqlite3.connect(\"..\/input\/database.sqlite\")\n#filtering only positive and negative reviews i.e. \n# not taking into consideration those reviews with Score=3\n\nfilter_data = pd.read_sql_query('SELECT * FROM REVIEWS WHERE Score != 3',con)\n\n# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\ndef partition(x):\n    if x < 3:\n        return 'negative'\n    return 'positive'\n\n#changing reviews with score less than 3 to be positive and vice-versa\nactualScore = filter_data['Score']\npositiveNegative = actualScore.map(partition) \nfilter_data['Score'] = positiveNegative\n","401532ef":"print(filter_data.shape)\nfilter_data.head(3)","f6f9274d":"display = pd.read_sql_query('''\nSELECT *\nFROM Reviews\nWHERE UserId = \"A395BORC6FGVXV\"''',con)\ndisplay","53958cba":"sorted_data = filter_data.sort_values('ProductId',axis = 0,ascending = True, inplace=False, kind = 'quicksort',na_position = 'last')","4164cde2":"#Deduplication of entries\nfinal=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\nfinal.shape\n","097f4fdf":"(final['Id'].size*1.0)\/(filter_data['Id'].size*1.0)*100","fd8027e6":"#data with HelpfulnessNumerator > HelpfulnessDenominator\n\ndisplay = pd.read_sql_query('''\nSELECT *\nFROM Reviews\nWHERE HelpfulnessNumerator > HelpfulnessDenominator and score !=3''',con)\ndisplay.head()","c352bd31":"final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n","2c028d19":"#Before starting the next phase of preprocessing lets see the number of entries left\nprint(final.shape)\n\n#How many positive and negative reviews are present in our dataset?\nfinal['Score'].value_counts()","d389d001":"# find sentences containing HTML tags\n#import regular expressions\nimport re\ni=0;\nfor sent in final['Text'].values:\n    if (len(re.findall('<.*?>', sent))):\n        print(i)\n        print(sent)\n        break;\n    i += 1; ","18ff8150":"import re\n# Tutorial about Python regular expressions: https:\/\/pymotw.com\/2\/re\/\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nstop = set(stopwords.words('english')) #set of stopwords\nsno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n\ndef cleanhtml(sentence): #function to clean the word of any html-tags\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|\/]',r' ',cleaned)\n    return  cleaned\n\nprint('Some stop words are:')\nprint(stop)\n","3d47dc35":"#Code for implementing step-by-step the checks for data pre-processing\ni=0\nstr1=' '\nfinal_string=[]\nall_positive_words=[] # store words from +ve reviews here\nall_negative_words=[] # store words from -ve reviews here.\ns=''\nfor sent in final['Text'].values:\n    filtered_sentence=[]\n    #print(sent);\n    sent=cleanhtml(sent) # remove HTMl tags\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n                if(cleaned_words.lower() not in stop):\n                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n                    filtered_sentence.append(s)\n                    if (final['Score'].values)[i] == 'positive': \n                        all_positive_words.append(s) #list of all words used to describe positive reviews\n                    if(final['Score'].values)[i] == 'negative':\n                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n                else:\n                    continue\n            else:\n                continue \n    #print(filtered_sentence)\n    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n    final_string.append(str1)\n    i+=1","531d5425":"final['CleanedText'] = final_string #adding a column of CleanedText which displays the data after pre-processing of the review","aabff685":"final.head(3)","400f5396":"#define style for seaborn\ndef style():\n    plt.subplots(figsize=(15,6))\n    sns.set_style(\"whitegrid\")\n    sns.despine()\n    sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n    sns.color_palette('dark')","e02ae1dc":"sns.countplot(data=final,x='Score')","8533c51b":"#length of text of each review\ndef length(x):\n    return len(x)\nleng=final['Text'].map(length)\nleng=list(leng)\n#pdf of reviews\nstyle()\nsns.distplot(leng,hist=False).set_title('pdf for length of reviews')","21a90330":"#convert time stamp to date and column as data\nfinal['date'] = pd.to_datetime(final['Time'], unit='s',)\ndate = final['date']\nstyle()\na = pd.to_datetime(final['Time'], unit='s')\nyears=a.map(lambda x:x.year)\nyears=years.reset_index()\nyears.columns=['count','year']\nsns.countplot(data=years,x='year').set_title('Reviews given by users each year')","918f13f9":"\nstyle()\na = pd.to_datetime(final['Time'], unit='s')\nmonths=a.map(lambda x:x.month)\nmonths=months.reset_index()\nmonths.columns =['count','month']\nmonths\nsns.countplot(data=months,x='month').set_title('Reviews given by users each month')","a4e4e741":"#Build wordcloud\nfrom wordcloud import WordCloud,STOPWORDS\n\n#get all words\nwords = str(final['Text'].values)\n\n# Generate a word cloud image\nwordcloud = WordCloud(width=1000,height=600,max_font_size=95,max_words=6000,background_color='black',colormap='Spectral').generate(words)\n\n# Display the generated image:\n# the matplotlib way:\nplt.figure(figsize=(10,15))\nplt.title('Word cloud for the words in reviews')\nplt.imshow(wordcloud,cmap='gist_rainbow')\nplt.axis('off');\n","1bc4c3a1":"#top users\ntop= final.groupby(by='ProfileName')['Id'].count().reset_index()\ntop=top.sort_values('Id',ascending=False)[:15]\nstyle()\nsns.barplot(data=top,x='Id',y='ProfileName',palette='bright').set_title('Users given more reviews')","168c9b6c":"#top positive rated product\npositive = final[final['Score']=='positive']\ntop= positive.groupby(by='ProductId')['Id'].count().reset_index()\ntop=top.sort_values('Id',ascending=False)[:10]\ntop.columns=['ProductId','positive_count']\ntop\n","aeaee365":"from IPython.display import Image\nfrom IPython.core.display import HTML\nprint(\"Top Positive product from reviews\")\nImage(url= \"https:\/\/images-na.ssl-images-amazon.com\/images\/I\/81c-m39Qt0L._SX522SX522_SY450_CR,0,0,522,450_PIbundle-12,TopRight,0,0_SX522_SY450_CR,0,0,522,450_SH20_.jpg\")","ca995a9c":"#Top negative rated products\nnegative = final[final['Score']=='negative']\ntop= negative.groupby(by='ProductId')['Id'].count().reset_index()\ntop=top.sort_values('Id',ascending=False)[:10]\ntop.columns=['ProductId','positive_count']\ntop\n","b9ec3aa2":"from IPython.display import Image\nfrom IPython.core.display import HTML\nprint(\"Top negative product from reviews\")\nImage(url= \"https:\/\/images-na.ssl-images-amazon.com\/images\/I\/81N3dYbSCWL._SL1500_.jpg\")","99e92433":"#We take a sample of 100000 data points\nfrom sklearn.utils import resample\nsample = resample(final,n_samples=100000)","858ee63a":"# sort our sampled data based on time in ascending order\nsample = sample.sort_values(by='Time',kind='quicksort')\n\n#splitting 64% as train 16% as cv and 25% as test data\na = int(sample.shape[0] * 0.80)\nb = int(a * 0.8)\n\ntrain = sample.iloc[:b,:]\ncv = sample.iloc[b:a]\ntest = sample.iloc[a:,:]\n\n# print train,cv and test size\nprint('train size is:',train.shape)\nprint('cv size is:',cv.shape)\nprint('test size is:',test.shape)","ff9a26d3":"#convert positive label as 1 and negative as 0\ndef convert(x):\n    if x == 'positive':\n        return 1\n    else:\n        return 0\n#train y labels    \ny_train = train['Score'].map(convert)\ny_cv = cv['Score'].map(convert)\ny_test = test['Score'].map(convert)\n","b38df05d":"#Convert text to Bag of words for each word in the corpus.\nbow = CountVectorizer()\nbow_counts = bow.fit_transform(train['CleanedText'].values)\nbow_counts.shape","551c831e":"#don't forgot to normalize train data\nX_bow = normalize(bow_counts,axis=0)\n#convert cv text to Bow vectors\nX_cv_bow = bow.transform(cv['CleanedText'].values)\n#don't forgot to normalize cv data\nX_cv_bow = normalize(X_cv_bow,axis=0)\n#convert test text to Bow vectors\nX_test_bow = bow.transform(test['CleanedText'].values)\n#don't forgot to normalize cv data\nX_test_bow = normalize(X_test_bow,axis=0)\n","735acb27":"#Convert text to tfidf for each word in the corpus.\n#We consider only uni-grams as computing time and space is less.\ntfidf_vect = TfidfVectorizer(ngram_range=(1,1))\nfinal_tfidf = tfidf_vect.fit_transform(train['CleanedText'].values)","ca963d3a":"#print top tfidf words.\n#High tfidf value implies word is more important compared to less tfidf value word.\nfeatures = tfidf_vect.get_feature_names()\nlen(features)\n\n# source: https:\/\/buhrmann.github.io\/tfidf-analysis.html\ndef top_tfidf_feats(row, features, top_n=15):\n    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n    topn_ids = np.argsort(row)[::-1][:top_n]\n    top_feats = [(features[i], row[i]) for i in topn_ids]\n    df = pd.DataFrame(top_feats)\n    df.columns = ['feature', 'tfidf']\n    return df\n","260d8f9c":"#don't forgot to normalize train data\nX_tfidf = normalize(final_tfidf,axis=0)\n#convert cv text to tfidf vectors\nX_cv_tfidf = tfidf_vect.transform(cv['CleanedText'].values)\n#don't forgot to normalize cv data\nX_cv_tfidf = normalize(X_cv_tfidf,axis=0)\n#convert test text to tfidf vectors\nX_test_tfidf = tfidf_vect.transform(test['CleanedText'].values)\n#don't forgot to normalize cv data\nX_test_tfidf = normalize(X_test_tfidf,axis=0)\n","2846ade5":"#function to give various scores on test data for a given model.\ndef cal_metrics(predicted,actual):\n  conf = confusion_matrix(predicted,actual)\n  TN,FN,FP,TP = conf[0][0],conf[0][1],conf[1][0],conf[1][1]\n  P = TP+FN\n  N = TN+FP\n  TPR = TP\/P\n  FPR = FP\/P\n  FNR = FN\/N\n  TNR = TN\/N\n  precision = TP\/(TP+FP)\n  recall = TP\/(TP+FN)\n  f1_score =  2 * (precision * recall) \/ (precision + recall)\n  acc = accuracy_score(predicted,actual)\n  print('Various metrics of model:')\n  print('TPR is:',TPR)\n  print('FPR is:',FPR)\n  print('TNR is:',TNR)\n  print('FPR is:',FPR)\n  print('Precision is:',precision*100)\n  print('Recall is:',recall*100)\n  \n  print('F1 score is:',f1_score*100)\n  print('Accuracy is:',acc*100,'\\n')\n  \n  print('Confusion Matrix is:')\n  ax = sns.heatmap(confusion_matrix(predicted,actual),annot=True,fmt='g',cbar=None)\n  plt.show()\n","e7d1093d":"#function to print top 10 positive and negative features\ndef imp_features(vectorizer,clf):\n  feature_names = vectorizer.get_feature_names()\n  n = clf.coef_[0].shape[0]\n  coefs_with_features = sorted(zip(clf.coef_[0], feature_names))\n  positive = coefs_with_features[:n-11:-1]\n  negative = coefs_with_features[:10]\n  positive = [i[1] for i in positive]\n  negative = [i[1] for i in negative]\n\n  top = {'positive':positive,'negative':negative}\n  print('Top positive and negative features\/words')\n  top = pd.DataFrame(data=top)\n  return top","53afed49":"cv_error = []\nmy_alpha = [10**x for x in range(-6,4)]\n\nfor i in my_alpha:\n    clf = MultinomialNB(alpha=i,fit_prior=None)\n    clf.fit(X_bow,y_train)\n    score = clf.score(X_cv_bow,y_cv)\n    print('For alpha = %f, cv score is : %f' %(i,score))\n    cv_error.append(1-score)\n    \n#plot errors and cv scores\nplt.figure(figsize=(10,25))\nfig, ax = plt.subplots()\nax.plot(my_alpha, cv_error,c='g')\nfor i, txt in enumerate(np.round(cv_error,3)):\n    ax.annotate((my_alpha[i],str(txt)), (my_alpha[i],cv_error[i]))\nplt.grid()\nplt.title(\"Cross Validation Error for each alpha\")\nplt.xlabel(\"Alpha i's\")\nplt.ylabel(\"Error measure\")\nplt.show()\n\n# changing to misclassification error\nMSE = [x for x in cv_error]\n# determining best alpha\noptimal_alpha = my_alpha[MSE.index(min(MSE))]\nprint('\\nThe optimal alpha is %f.' % optimal_alpha)\n","039ec0a7":"#train model with alpha.\nclf = MultinomialNB(alpha=optimal_alpha,fit_prior=None)\nclf.fit(X_bow,y_train)\n#predict y labels with model on test data\npredict = clf.predict(X_test_bow)\n#Performance of the model on the test data\ncal_metrics(predict,y_test)\n","f30a4d01":"#Lets get some of the important features\/words for both positive and negative classes\nimp_features(bow,clf)","1acbb73a":"#Visualize most positive and negative words on cloudcloud\n\n#get all words\n\ntop = imp_features(bow,clf)\npos = top['positive']\nneg = top['negative']\n\nwords = str(pos.values)\nwords1 = str(neg.values)\n\n# Generate a word cloud image\nwordcloud = WordCloud(width=1200,height=600,max_font_size=95,max_words=6000,background_color='black',colormap='Greens').generate(words)\nwordcloud1 = WordCloud(width=1200,height=600,max_font_size=95,max_words=6000,background_color='black',colormap='Reds').generate(words1)\n\n# Display the generated image:\n# the matplotlib way:\nprint('Top positive and negative features\/words of Naive Bayes classifier using Bag Of Words')\n\nplt.figure(figsize=(15,20))\nplt.subplot(121)\nplt.axis('off')\nplt.title(\"Important positve words\")\nplt.imshow(wordcloud);\nplt.subplot(122)\nplt.axis('off')\nplt.title(\"Important negative words\")\nplt.imshow(wordcloud1);","ba81988e":"cv_error = []\nmy_alpha = [10**x for x in range(-6,4)]\n\nfor i in my_alpha:\n    clf = MultinomialNB(alpha=i,fit_prior=None)\n    clf.fit(X_tfidf,y_train)\n    score = clf.score(X_cv_tfidf,y_cv)\n    print('For alpha = %f, cv score is : %f' %(i,score))\n    cv_error.append(1-score)\n    \n#plot errors and cv scores\nfig, ax = plt.subplots()\nax.plot(my_alpha, cv_error,c='g')\nfor i, txt in enumerate(np.round(cv_error,3)):\n    ax.annotate((my_alpha[i],str(txt)), (my_alpha[i],cv_error[i]))\nplt.grid()\nplt.title(\"Cross Validation Error for each alpha\")\nplt.xlabel(\"Alpha i's\")\nplt.ylabel(\"Error measure\")\nplt.show()\n\n# changing to misclassification error\nMSE = [x for x in cv_error]\n# determining best alpha\noptimal_alpha = my_alpha[MSE.index(min(MSE))]\nprint('\\nThe optimal alpha is %f.' % optimal_alpha)\n","9008d2d2":"#train model with alpha.\nclf = MultinomialNB(alpha=optimal_alpha,fit_prior=None)\nclf.fit(X_tfidf,y_train)\n#predict y labels with model on test data\npredict = clf.predict(X_test_tfidf)\n#Performance of the model on the test data\ncal_metrics(predict,y_test)\n","e6e5cfff":"#Lets get some of the important features\/words for both positive and negative classes\nimp_features(tfidf_vect,clf)","55323321":"#Visualize most positive and negative words on cloudcloud\n\n#get all words\n\ntop = imp_features(tfidf_vect,clf)\npos = top['positive']\nneg = top['negative']\n\nwords = str(pos.values)\nwords1 = str(neg.values)\n\n# Generate a word cloud image\nwordcloud = WordCloud(width=1200,height=600,max_font_size=95,max_words=6000,background_color='black',colormap='Greens').generate(words)\nwordcloud1 = WordCloud(width=1200,height=600,max_font_size=95,max_words=6000,background_color='black',colormap='Reds').generate(words1)\n\n# Display the generated image:\n# the matplotlib way:\nprint('Top positive and negative features\/words of Naive Bayes classifier using Tf-idf')\nplt.figure(figsize=(15,20))\nplt.subplot(121)\nplt.axis('off')\nplt.title(\"Important positve words\")\nplt.imshow(wordcloud);\nplt.subplot(122)\nplt.axis('off')\nplt.title(\"Important negative words\")\nplt.imshow(wordcloud1);","660e10c5":"cv_error = []\nmy_c = [0.00001,0.0001,0.001,0.01,0.1,1,10,100]\nfor i in my_c:\n    clf = LogisticRegression(C=i,class_weight='balanced')\n    clf.fit(X_bow,y_train)\n    score = clf.score(X_cv_bow,y_cv)\n    print('For C = %f, cv score is : %f' %(i,score))\n    cv_error.append(1-score)\n    \n#plot errors and cv scores\nfig, ax = plt.subplots()\nax.plot(my_c, cv_error,c='g')\nfor i, txt in enumerate(np.round(cv_error,3)):\n    ax.annotate((my_c[i],str(txt)), (my_c[i],cv_error[i]))\nplt.grid()\nplt.title(\"Cross Validation Error for each C\")\nplt.xlabel(\"C 's\")\nplt.ylabel(\"Error measure\")\nplt.show()\n\n# changing to misclassification error\nMSE = [x for x in cv_error]\n# determining best C\noptimal_c = my_c[MSE.index(min(MSE))]\nprint('\\nThe optimal C is %f.' % optimal_c)\n    ","f819c316":"#train model with C.\nclf = LogisticRegression(C=optimal_c,class_weight='balanced')\nclf.fit(X_bow,y_train)\n#predict y labels with model on test data\npredict = clf.predict(X_test_bow)\n#Performance of the model on the test data\ncal_metrics(predict,y_test)\n","82eabab0":"#Lets get some of the important features\/words for both positive and negative classes\nimp_features(bow,clf)","88218c77":"#Visualize most positive and negative words on cloudcloud\n\n#get all words\n\ntop = imp_features(bow,clf)\npos = top['positive']\nneg = top['negative']\n\nwords = str(pos.values)\nwords1 = str(neg.values)\n\n# Generate a word cloud image\nwordcloud = WordCloud(width=1200,height=600,max_font_size=95,max_words=6000,background_color='black',colormap='Greens').generate(words)\nwordcloud1 = WordCloud(width=1200,height=600,max_font_size=95,max_words=6000,background_color='black',colormap='Reds').generate(words1)\n\n# Display the generated image:\n# the matplotlib way:\nprint('Top positive and negative features\/words of Logistic Regression classifier using Bag Of Words')\nplt.figure(figsize=(15,20))\nplt.subplot(121)\nplt.axis('off')\nplt.title(\"Important positve words\")\nplt.imshow(wordcloud);\nplt.subplot(122)\nplt.axis('off')\nplt.title(\"Important negative words\")\nplt.imshow(wordcloud1);","43c49fec":"cv_error = []\nmy_c = [0.00001,0.0001,0.001,0.01,0.1,1,10,100]\nfor i in my_c:\n    clf = LogisticRegression(C=i,class_weight='balanced')\n    clf.fit(X_tfidf,y_train)\n    score = clf.score(X_cv_tfidf,y_cv)\n    print('For C = %f, cv score is : %f' %(i,score))\n    cv_error.append(1-score)\n    \n#plot errors and cv scores\nfig, ax = plt.subplots()\nax.plot(my_c, cv_error,c='g')\nfor i, txt in enumerate(np.round(cv_error,3)):\n    ax.annotate((my_c[i],str(txt)), (my_c[i],cv_error[i]))\nplt.grid()\nplt.title(\"Cross Validation Error for each C\")\nplt.xlabel(\"C 's\")\nplt.ylabel(\"Error measure\")\nplt.show()\n\n# changing to misclassification error\nMSE = [x for x in cv_error]\n# determining best C\noptimal_c = my_c[MSE.index(min(MSE))]\nprint('\\nThe optimal C is %f.' % optimal_c)\n    ","802dba12":"#train model with C.\nclf = LogisticRegression(C=optimal_c,class_weight='balanced')\nclf.fit(X_tfidf,y_train)\n#predict y labels with model on test data\npredict = clf.predict(X_test_tfidf)\n#Performance of the model on the test data\ncal_metrics(predict,y_test)\n","798c6bff":"#Lets get some of the important features\/words for both positive and negative classes\nimp_features(tfidf_vect,clf)","cf5f9d3f":"#Visualize most positive and negative words on cloudcloud\n\n#get all words\n\ntop = imp_features(tfidf_vect,clf)\npos = top['positive']\nneg = top['negative']\n\nwords = str(pos.values)\nwords1 = str(neg.values)\n\n# Generate a word cloud image\nwordcloud = WordCloud(width=1200,height=600,max_font_size=95,max_words=6000,background_color='black',colormap='Greens').generate(words)\nwordcloud1 = WordCloud(width=1200,height=600,max_font_size=95,max_words=6000,background_color='black',colormap='Reds').generate(words1)\n\n# Display the generated image:\n# the matplotlib way:\nprint('Top positive and negative features\/words of Logistic Regression classifier using Tf-idf')\nplt.figure(figsize=(15,20))\nplt.subplot(121)\nplt.axis('off')\nplt.title(\"Important positve words\")\nplt.imshow(wordcloud);\nplt.subplot(122)\nplt.axis('off')\nplt.title(\"Important negative words\")\nplt.imshow(wordcloud1);","05df4ffe":"###  Logistic regression for Bag Of Words","44f43c0c":"<b> Obseravtions-:<\/b>\n1. Length of  reviews is in power law distribution and 80% of data lies in first 20% region.","320c3e65":"###  Naive Bayes for tfidf","d22dc66c":"We consider Train => 64% , CV => 16%, and test =>20% ","87a7c284":"\n<br>We perform vectorization on the cleaned text(pre-processed text)","3ef4d32d":"<p3> Given data contain time split and also reviews might have an impact on the time of the review given. So we consider <b>time based splitting<\/b> for train, cv, test.\n<\/p3>","9567b1c7":"##  Train, CV ,Test Split","627fa6e9":"# EDA and Simple models on Amazon Fine Food Review\n","92bc2096":"\n#  Machine Learning models","b374519e":"<b>Observation:-<\/b> \n1. After removing\nduplicates we are now left over with 70% of data.\n2. It was also seen that in two rows given below the value of HelpfulnessNumerator is greater than HelpfulnessDenominator which is not practically possible hence these two rows too are removed from calcualtions","7e2e18a8":"<b> Obseravtions-:<\/b>\n1. More number of reviews were given by users in the year 2012.\n2. Every year the number of given by users are increasing.","15f1bcbe":"Since we have very huge data we just take a sample of data and build machine learning models.","3ad2d27b":"1. From all above models we can clearly understand that Logistic regression with Bag of words performs better with f1-score 93%.\n2. If we observe the feature importance (positive and negative words) they are more reasonable and good.\n3. From the confusion matrix we can conclude that more positive lables are mis classified as negative, So False Negative value is high compared to False Positive.\n4. Performance can be greatly improved using NLP and deep learning techniques","517a7407":"###  Covert text to vectors using BoW","b2a761b3":"# Conclusion","b439a41b":"<b> Obseravtions-:<\/b>\n1. Last column of the dataframe is the cleaned text after text preprocessing like stemming, stop-word removal and lemmatization.","ba1e7057":"###  Prepare y labels","ea0ff3b1":"Generally for most of the text classification problems works fair, So lets try with naive bayes","f5313a17":"###  Text Preprocessing: Stemming, stop-word removal and Lemmatization.\n\nNow that we have finished deduplication our data requires some preprocessing before we go on further with analysis and making the prediction model.\n\nHence in the Preprocessing phase we do the following in the order below:-\n\n1. Begin by removing the html tags\n2. Remove any punctuations or limited set of special characters like , or . or # etc.\n3. Check if the word is made up of english letters and is not alpha-numeric\n4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n5. Convert the word to lowercase\n6. Remove Stopwords\n1. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)<br>\n\nAfter which we collect the words used to describe positive and negative reviews\n","0a18d910":"###  Visualizing Data","c3ceba83":"###  Naive Bayes for Bag Of Words","4e35d728":"\n###  Data Cleaning: Deduplication\n\nIt is observed (as shown in the table below) that the reviews data had many duplicate entries. Hence it was necessary to remove duplicates in order to get unbiased results for the analysis of the data.  Following is an example:","35ee554e":"##  Sampling Data","461d0c90":"<b>Given features are text words we can convert text into numerical vectors<\/b><br>\n1. Bag Of Words\n2. Tfidf vectors\n<br><b>Apply Naive Bayes classifer and Logistic Regression for both vectorizations and visualize important features\/words<\/b>","16a42263":"Given data is highly imbalance data with 84% positive and 16% negative score. Taking accuracy as a metric to measure perfomance of the model is a wrong idea because even a dumb model can have an accuracy of 84%. So we take f1 score, precision score and recall score. And also plot connfusion matrix to clearly understand about performance of model. ","423446bb":"###  Logistic regression for Tfidf","cc5d6750":"##  Loading the data\n\nThe dataset is available in two forms\n1. .csv file\n2. SQLite Database\n\nIn order to load the data, We have used the SQLITE dataset as it easier to query the data and visualise the data efficiently.\n<br> \n\nHere as we only want to get the global sentiment of the recommendations (positive or negative), we will purposefully ignore all Scores equal to 3. If the score id above 3, then the recommendation wil be set to \"positive\". Otherwise, it will be set to \"negative\".","9fa89df4":"<b>Observation:-<\/b> \n1. Helpfulness Numerator is greater than Helpfulness Denominator which is practically impossible so remove such data.","82097ab9":"##  Exploratory Data Analysis***","69eed5c6":"<b>Task<\/b>:<br> Build a Machine learning model such that given a new review our model should predict the polarity of the review without any information about product and user.","89cd0ac5":"<b>Observation:-<\/b> \n1. Data set is imbalance dataset with 16% reviews are negative and 84% belongs to positive lable.","7927aade":"##  Prepare Data for Machine Learning Model","0370229c":"###  Convert text to vectors using TF-IDF","4be30a89":"<b>Given text words we can pre-processed then convert text into numerical vectors with following<\/b><br>\n    1. Bag Of Words\n    2. Tfidf vectors\n<br>\n<b>And then applied Naive Bayes classifer and Logistic Regression for both vectorizations and visualize important features\/words<\/b>","462e8b3d":"<b> Obseravtions-:<\/b>\n1. The dataset contains two lables positive and negative. Dataset is highly imbalanced dataset with 16% negative and 86% positive.","16c88e3f":"##  Logistic Regression","d286cfdc":"##  Naive Bayes model","413f42d0":"As can be seen above the same user has multiple reviews of the with the same values for HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary and Text and on doing analysis it was found that \n\nProductId=B000UA0QIQ was Faeries Finest Flavor Extract, Cherry, 2.04 Ounce\n\nProductId=B002Y7526Y was Faeries Finest Flavor Extract, Cherry, 16.36 Ounce and so on\n\nIt was inferred after analysis that reviews with same parameters other than ProductId belonged to the same product just having different flavour or quantity. Hence in order to reduce redundancy it was decided to eliminate the rows having same parameters.\n\nThe method used for the same was that we first sort the data according to ProductId and then just keep the first similar product review and delelte the others. for eg. in the above just the review for ProductId=B000HDL1RQ remains. This method ensures that there is only one representative for each product and deduplication without sorting would lead to possibility of different representatives still existing for the same product."}}