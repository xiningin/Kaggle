{"cell_type":{"400f7e81":"code","7e909822":"code","0daa3948":"code","9edb3fa6":"code","dd9ed0fe":"code","8dfa425d":"code","96ab5ba1":"code","d1e6b7e3":"code","27c54666":"code","999b9e66":"code","2f674d67":"code","a8b76f0f":"code","09fddf62":"code","a1ef3d22":"code","42a1a536":"code","4b7277a3":"code","21e2e584":"code","9115ad0e":"code","2ce28d57":"code","914f4178":"code","05f27f77":"code","f60851cb":"code","cc3933e4":"code","2afabdd5":"code","1508ae1c":"code","5f95db05":"code","2b3c6a38":"code","f2ecd813":"code","db557031":"code","0b24acc5":"code","ebe45779":"code","1cd19d8d":"code","7dc92d3b":"code","5c0cb285":"code","e59d4de7":"code","1a7e409c":"code","94dfd531":"code","b8ef22e7":"code","61760280":"code","4ccefd0f":"code","63970871":"code","db2ff3fc":"code","6ca323ce":"code","d9338b9f":"markdown","ff269493":"markdown","ac6ef887":"markdown","182953b6":"markdown","65be4354":"markdown","27e59301":"markdown","02828393":"markdown","8b799b49":"markdown","be881188":"markdown","3172fdb2":"markdown","0f54b158":"markdown","f0344e39":"markdown"},"source":{"400f7e81":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, Flatten, Dense, MaxPool1D, Dropout\nfrom tensorflow.keras.utils import to_categorical \n\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom numpy import hstack, array\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder","7e909822":"sample_submission = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sample_submission.csv\")","0daa3948":"cal = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/calendar.csv\")\ncal.shape","9edb3fa6":"cal.head()","dd9ed0fe":"train = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv\")\ntrain.shape","8dfa425d":"train.head(10)","96ab5ba1":"sale = pd.read_csv(\"..\/input\/m5-forecasting-accuracy\/sell_prices.csv\")\nsale.shape","d1e6b7e3":"sale.head()","27c54666":"ids = [i for i in range(train[\"id\"].shape[0])]\nlen(ids)","999b9e66":"# Only numerical data taken from train data\n\nnum = train.select_dtypes(exclude = [\"object\"]).columns\nprint(num)","2f674d67":"train['item_sum'] = train[num].sum(axis=1)\ntrain.head()","a8b76f0f":"mix = pd.concat([train, cal], axis =1)\nmix.head()","09fddf62":"plt.figure(figsize=(10,6))\nplt.title(\"Total Sale of Items in Store\")\n\nsns.barplot(x = mix[\"store_id\"], y = mix[\"item_sum\"])","a1ef3d22":"plt.figure(figsize=(10,6))\nplt.title(\"Total Sale of Categorical Items in Stores\")\n\nsns.barplot(x = mix[\"store_id\"], y = mix[\"item_sum\"], hue = mix[\"cat_id\"])","42a1a536":"plt.figure(figsize=(10,6))\nplt.title(\"Sale of Item by Year and Category\")\n\nsns.lineplot(x = mix[\"year\"], y = mix[\"item_sum\"], hue = mix[\"cat_id\"])","4b7277a3":"plt.figure(figsize=(10,6))\nplt.title(\"Sale of items by Month\")\n\nsns.lineplot(x = mix[\"month\"], y = mix[\"item_sum\"], hue = mix[\"cat_id\"])","21e2e584":"plt.figure(figsize=(10,6))\nplt.title(\"Sale of items by Month\")\n\nsns.barplot(x = mix[\"month\"], y = mix[\"item_sum\"], hue = mix[\"cat_id\"])","9115ad0e":"plt.figure(figsize=(10,6))\nplt.title(\"Sale of items by Day of Week\")\n\nsns.lineplot(x = mix[\"weekday\"], y = mix[\"item_sum\"], hue = mix[\"cat_id\"])","2ce28d57":"train.head()","914f4178":"# item_id = train['item_id']\n# del train['item_id']\n# del train['dept_id']\n# del train['id']","05f27f77":"# train = train.drop(['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'], axis=1)\n# train = train.drop(['snap_CA', 'snap_TX', 'snap_WI', 'date', 'wm_yr_wk'], axis=1)","f60851cb":"# train = train.drop(['item_sum'], axis=1)","cc3933e4":"# train[\"cat_id\"] = train[\"cat_id\"].apply(cat)","2afabdd5":"def cat(str):\n    if str == 'HOBBIES':\n        return 1\n    elif str == 'HOUSEHOLD':\n        return 2\n    else:\n        return 3","1508ae1c":"def melt_sales(df):\n    df = df.drop([\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"item_sum\"], axis=1).melt(\n        id_vars=['id'], var_name='d', value_name='demand')\n    return df\n\nsales = melt_sales(train)","5f95db05":"sales.head()","2b3c6a38":"sales_trend = train.drop(columns = ['id','item_id','dept_id','cat_id','store_id','state_id', 'item_sum']).mean().reset_index()\nsales_trend.plot()","f2ecd813":"sales_trend.rename(columns={'index':'d', 0: 'sales'}, inplace=True)\nsales_trend = sales_trend.merge(cal[[\"wday\",\"month\",\"year\",\"d\"]], on=\"d\",how='left')\nsales_trend = sales_trend.drop(columns = [\"d\"])","db557031":"sales_trend.head()","0b24acc5":"sales.head()","ebe45779":"def split_sequences(sequences, n_steps):\n    X, y = list(), list()\n    for i in range(len(sequences)):\n        # find the end of this pattern\n        end_ix = i + n_steps\n        # check if we are beyond the dataset\n        if end_ix > len(sequences):\n            break\n        # gather input and output parts of the pattern\n        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)","1cd19d8d":"in_seq1 = np.array(sales_trend['wday'])\nin_seq2 = np.array(sales_trend['month'])\nin_seq3 = np.array(sales_trend['year'])\nout_seq = np.array(sales_trend['sales'])\nin_seq1 = in_seq1.reshape((len(in_seq1), 1))\nin_seq2 = in_seq2.reshape((len(in_seq2), 1))\nin_seq3 = in_seq3.reshape((len(in_seq3), 1))\nout_seq = out_seq.reshape((len(out_seq), 1))\ndataset = hstack((in_seq1, in_seq2, in_seq3, out_seq))\nn_steps = 7\nX, y = split_sequences(dataset, n_steps)","7dc92d3b":"X = X\nY = y","5c0cb285":"X_train = X[:-30]\nY_train = Y[:-30]\nX_test = X[-30:]\nY_test = Y[-30:]","e59d4de7":"X_train.shape","1a7e409c":"for i in range(Y_train.shape[0]):\n    if Y_train[i] >=1 :\n        Y_train[i] = 1\n    else:\n        Y_train[i] = 0","94dfd531":"for i in range(Y_test.shape[0]):\n    if Y_test[i] >=1 :\n        Y_test[i] = 1\n    else:\n        Y_test[i] = 0","b8ef22e7":"n_features = X_train.shape[2]","61760280":"model = Sequential()","4ccefd0f":"model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps, n_features)))\nmodel.add(MaxPool1D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(1024, activation='tanh'))\nmodel.add(Dense(1, activation = \"softmax\"))","63970871":"model.compile(optimizer = 'adam', loss = 'mse', metrics = [\"accuracy\"])","db2ff3fc":"model.fit(X_train, Y_train, epochs = 100, batch_size = 50)","6ca323ce":"predictions = model.predict(X_test)\nscore = model.evaluate(X_test, Y_test)\nprint(score)","d9338b9f":"##### Calendar - Dates on which products sold.","ff269493":"# Importing Libraries and Loading Data","ac6ef887":"##### Sales Price","182953b6":"In this competition, we need to predict the sales for [d_1942 - d_1969]. These rows form the evaluation set. The rows [d_1914 - d_1941] form the validation set, and the remaining rows form the training set. Now since we understand the dataset and know what to predict, let us visualize the dataset.","65be4354":"# Training Model","27e59301":"#### Using Calendar to analyse time series data","02828393":"#### Number of sales of each item vs Store","8b799b49":"# Preparation of Data for prediction","be881188":"1. id: Validation ID\n\n2. item_id: Item ID\n\n3. cat_id: Category (Hobbies, Household, Foods)\n\n4. store_id: Store ID\n\n5. state_id: State (CA, TX, WI)","3172fdb2":"##### Sales Data","0f54b158":"##### Results\n\n1. Stores in California perform much better than those in Texas and Wisconsin. CA_3 outperforms all.\n2. Food Items are the highest selling products.\n3. First two months and the last 4 months have much higher sale record.\n4. Sunday and Thursday are the days when sales peak the most.","f0344e39":"# EDA (Exploratory Data Analysis)"}}