{"cell_type":{"f134d28c":"code","efcd25e6":"code","a858a334":"code","8fe3c2b8":"code","ebc8f9ae":"code","f0fd2ab8":"code","0c2a37fe":"code","4e654921":"code","fe24d6fa":"code","543bddc3":"code","7dc6c1c9":"code","250ce95c":"code","c9ad7393":"code","f18bca62":"code","f0e79598":"code","aaac6a3d":"code","17610e89":"markdown"},"source":{"f134d28c":"import os,shutil\nimport glob\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nimport keras\nimport matplotlib.pyplot as plt\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.preprocessing.image import *\nfrom keras.callbacks import EarlyStopping\nfrom keras import regularizers,optimizers\nfrom keras.callbacks import LearningRateScheduler\nfrom keras import *\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.inception_v3 import InceptionV3\n#walk is 1, run is 0\noriginal_dataset_dir = \"..\/input\/walk-or-run\"\n\ntrain_dir = os.path.join(original_dataset_dir,'walk_or_run_train\/train')\n#'..\/input\/walk_or_run_train\/train'\ntest_dir= os.path.join(original_dataset_dir,'walk_or_run_test\/test')\n#'..\/input\/walk_or_run_test\/test'\n","efcd25e6":"os.listdir(train_dir)","a858a334":"BATCH_SIZE=16\nEPOCHS=50","8fe3c2b8":"LR_START = 0.00001\nLR_MAX = 0.00005 \nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = keras.callbacks.LearningRateScheduler(lrfn(30), verbose = True)\n","ebc8f9ae":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 15)","f0fd2ab8":"def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1\/0.3, v_l=0, v_h=255, pixel_level=False):\n    def eraser(input_img):\n        img_h, img_w, img_c = input_img.shape\n        p_1 = np.random.rand()\n\n        if p_1 > p:\n            return input_img\n\n        while True:\n            s = np.random.uniform(s_l, s_h) * img_h * img_w\n            r = np.random.uniform(r_1, r_2)\n            w = int(np.sqrt(s \/ r))\n            h = int(np.sqrt(s * r))\n            left = np.random.randint(0, img_w)\n            top = np.random.randint(0, img_h)\n\n            if left + w <= img_w and top + h <= img_h:\n                break\n\n        if pixel_level:\n            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n        else:\n            c = np.random.uniform(v_l, v_h)\n\n        input_img[top:top + h, left:left + w, :] = c\n\n        return input_img\n\n    return eraser","0c2a37fe":"train_datagen = ImageDataGenerator(rotation_range=30,width_shift_range=0.1,\\\n                             height_shift_range=0.1,shear_range=0.1,zoom_range=0.1,\\\n                                 horizontal_flip=True,vertical_flip=False,validation_split=0.2,\n                                  preprocessing_function = get_random_eraser(v_l=0, v_h=255))\ntest_datagen = ImageDataGenerator()\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical',\n    seed=2019,\n    color_mode='rgb'\n)\nvalidation_generator = train_datagen.flow_from_directory(\n    train_dir, # same directory as training data\n    target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical',color_mode='rgb',\n    subset='validation')\ntest_generator = test_datagen.flow_from_directory(test_dir,target_size=(224, 224),\n    batch_size=16,\n    class_mode='categorical',color_mode='rgb')","4e654921":"import tensorflow as tf, tensorflow.keras.backend as K\n","fe24d6fa":"from keras.applications import DenseNet201","543bddc3":"strategy = tf.distribute.get_strategy()","7dc6c1c9":"def get_model():\n    with strategy.scope():\n        model = keras.Sequential([\n                    DenseNet201(input_shape=(224,224, 3),include_top=False,weights='imagenet'),\n                    keras.layers.GlobalAveragePooling2D(),\n                    keras.layers.Dense(2, activation='softmax')\n        ])\n        model.compile(\n                optimizer='adam',\n                loss = 'categorical_crossentropy',\n                metrics=['categorical_accuracy']\n        )\n    return model","250ce95c":"D_net = get_model()","c9ad7393":"STEPS_PER_EPOCH = 600\/BATCH_SIZE\n","f18bca62":"history = D_net.fit_generator(train_generator,epochs = 30,\n            callbacks = [keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor = 0.5, patience =3, \n                                                           min_lr=0.00001, verbose=1, mode='min'),early_stopping],\n                              validation_data=test_generator)","f0e79598":"res = D_net.evaluate_generator(test_generator)","aaac6a3d":"print(\"test_loss:\",res[0],\"test acc:\",res[1])","17610e89":"I will add, description of code.. soon. Sorry**"}}