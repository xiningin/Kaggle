{"cell_type":{"4d9ec505":"code","08b6f3ea":"code","44424250":"code","26c960b0":"code","16ab2745":"code","0831abfe":"code","2dc45b3c":"code","296e528d":"code","5ec90daf":"code","a4f71471":"code","9658fc1e":"code","5121e3e4":"code","7881f46b":"code","2314951c":"code","f9ade2f5":"code","fd0256ac":"code","e0172948":"code","e316c9b9":"code","a747075e":"code","d02e2138":"code","69901836":"markdown","bd230dac":"markdown","42797d7b":"markdown","5ae4b9fb":"markdown","83bfe651":"markdown","0e8a0b60":"markdown","88b0b1bd":"markdown","92b21b19":"markdown","d07764df":"markdown","678e0f11":"markdown","aa63472c":"markdown","ddcc93a7":"markdown","f4ac975e":"markdown","9fab6e9c":"markdown","d0c9988e":"markdown","42c01f50":"markdown","786ca54f":"markdown","476345a8":"markdown","a3ccab8d":"markdown","47f9e621":"markdown"},"source":{"4d9ec505":"%pylab inline --no-import-all\n\nimport os\nfrom pathlib import Path\n\nimport pandas as pd\n\n\n# Change this path to adapt to where you downloaded the data\nBASE_PATH = Path(\"..\/input\/geolifeclef-2021\/\")\nDATA_PATH = BASE_PATH \/ \"data\"\n\n# Create the path to save submission files\nSUBMISSION_PATH = Path(\"submissions\")\nos.makedirs(SUBMISSION_PATH, exist_ok=True)\n\n# Clone the GitHub repository\n!rm -rf GLC\n!git clone https:\/\/github.com\/maximiliense\/GLC","08b6f3ea":"from GLC.metrics import top_30_error_rate\nhelp(top_30_error_rate)","44424250":"from GLC.metrics import top_k_error_rate_from_sets\nhelp(top_k_error_rate_from_sets)","26c960b0":"from GLC.metrics import predict_top_30_set\nhelp(predict_top_30_set)","16ab2745":"df_fr = pd.read_csv(DATA_PATH \/ \"observations\" \/ \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\ndf_us = pd.read_csv(DATA_PATH \/ \"observations\" \/ \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\ndf = pd.concat((df_fr, df_us))","0831abfe":"obs_id_train = df.index[df[\"subset\"] == \"train\"].values\nobs_id_val = df.index[df[\"subset\"] == \"val\"].values\n\ny_train = df.loc[obs_id_train][\"species_id\"].values\ny_val = df.loc[obs_id_val][\"species_id\"].values\n\nn_val = len(obs_id_val)\nprint(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val \/ len(df)))","2dc45b3c":"df_fr_test = pd.read_csv(DATA_PATH \/ \"observations\" \/ \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\ndf_us_test = pd.read_csv(DATA_PATH \/ \"observations\" \/ \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n\ndf_test = pd.concat((df_fr_test, df_us_test))\n\nobs_id_test = df_test.index\n\nprint(\"Number of observations for testing: {}\".format(len(df_test)))\n\ndf_test.head()","296e528d":"df_test_obs_id_mapping = pd.read_csv(BASE_PATH \/ \"test_observation_ids_mapping.csv\", sep=\";\")\ndf_test_obs_id_mapping.head()","5ec90daf":"def generate_submission_file(filename, corrected_observation_ids, s_pred):\n    s_pred = [\n        \" \".join(map(str, pred_set))\n        for pred_set in s_pred\n    ]\n    \n    df = pd.DataFrame({\n        \"Id\": corrected_observation_ids,\n        \"Predicted\": s_pred\n    })\n    df.to_csv(filename, index=False)","a4f71471":"first_30_species = np.arange(30)\ns_pred = np.tile(first_30_species[None], (len(df_test), 1))","9658fc1e":"generate_submission_file(SUBMISSION_PATH \/ \"sample_submission.csv\", df_test_obs_id_mapping[\"Id\"], s_pred)","5121e3e4":"species_distribution = df.loc[obs_id_train][\"species_id\"].value_counts(normalize=True)\ntop_30_most_observed = species_distribution.index.values[:30]","7881f46b":"s_pred = np.tile(top_30_most_observed[None], (n_val, 1))\nscore = top_k_error_rate_from_sets(y_val, s_pred)\nprint(\"Top-30 error rate: {:.1%}\".format(score))","2314951c":"# Compute baseline on the test set\nn_test = len(df_test)\ns_pred = np.tile(top_30_most_observed[None], (n_test, 1))\n\n# Generate the submission file\ngenerate_submission_file(SUBMISSION_PATH \/ \"constant_top_30_most_present_species_baseline.csv\", df_test_obs_id_mapping[\"Id\"], s_pred)","f9ade2f5":"df_env = pd.read_csv(DATA_PATH \/ \"pre-extracted\" \/ \"environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\n\nX_train = df_env.loc[obs_id_train].values\nX_val = df_env.loc[obs_id_val].values\nX_test = df_env.loc[obs_id_test].values","fd0256ac":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\nimp.fit(X_train)\n\nX_train = imp.transform(X_train)\nX_val = imp.transform(X_val)\nX_test = imp.transform(X_test)","e0172948":"from sklearn.ensemble import RandomForestClassifier\nest = RandomForestClassifier(n_estimators=16, max_depth=10, n_jobs=-1)\nest.fit(X_train, y_train)","e316c9b9":"def batch_predict(predict_func, X, batch_size=1024):\n    res = predict_func(X[:1])\n    n_samples, n_outputs, dtype = X.shape[0], res.shape[1], res.dtype\n    \n    preds = np.empty((n_samples, n_outputs), dtype=dtype)\n    \n    for i in range(0, len(X), batch_size):\n        X_batch = X[i:i+batch_size]\n        preds[i:i+batch_size] = predict_func(X_batch)\n            \n    return preds","a747075e":"def predict_func(X):\n    y_score = est.predict_proba(X)\n    s_pred = predict_top_30_set(y_score)\n    return s_pred\n\ns_val = batch_predict(predict_func, X_val, batch_size=1024)\nscore_val = top_k_error_rate_from_sets(y_val, s_val)\nprint(\"Top-30 error rate: {:.1%}\".format(score_val))","d02e2138":"# Compute baseline on the test set\ns_pred = batch_predict(predict_func, X_test, batch_size=1024)\n\n# Generate the submission file\ngenerate_submission_file(SUBMISSION_PATH \/ \"random_forest_on_environmental_vectors.csv\", df_test_obs_id_mapping[\"Id\"], s_pred)","69901836":"For submissions, we will also need to predict the top-30 sets for which we also provide an efficient implementation:","bd230dac":"# Constant baseline: 30 most observed species\n\nThe first baseline consists in predicting the 30 most observed species on the train set which corresponds exactly to the \"Top-30 most present species\":","42797d7b":"We can then generate the associated submission file using:\n\n**(NOTE that we need to use the adjusted test ids mapping here)**","5ae4b9fb":"We now predict the top-30 sets on the test data and save them in a submission file:","83bfe651":"# Sample submission file\n\nIn this section, we will demonstrate how to generate the sample submission file provided.\n\nTo do so, we will use this function:","0e8a0b60":"Then, we retrieve the train\/val split provided:","88b0b1bd":"We can now start training our Random Forest (as there are a lot of observations, over 1.8M, this can take a while):","92b21b19":"For submissions, we also need the following mapping to correct a slight misalignment in the test observation ids:","d07764df":"# Random forest on environmental vectors\n\nA classical approach in ecology is to train Random Forests on environmental vectors.\n\nWe show here how to do so using [scikit-learn](https:\/\/scikit-learn.org\/).\n\nWe start by loading the environmental vectors:","678e0f11":"We also load the observation data for the test set:","aa63472c":"We will however generate the associated submission file on the test using:","ddcc93a7":"This notebook presents some code to compute some basic baselines.\n\nIn particular, it shows how to:\n1. Use the provided validation set\n2. Compute the top-30 metric\n3. Save the predictions on the test in the right format for submission","f4ac975e":"We also load the official metric, top-30 error rate, for which we provide efficient implementations:","9fab6e9c":"As there are a lot of classes (over 30K), we need to be cautious when predicting the scores of the model.\n\nThis can easily take more then 10Go on the validation set.\n\nFor this reason, we will be predict the top-30 sets by batches using the following generic function:","d0c9988e":"We can know compute the top-30 error rate on the validation set:","42c01f50":"The sample submission consists in always predicting the first 30 species for all the test observations:","786ca54f":"As expected, it does not perform very well on the validation set:","476345a8":"Then, we need to handle properly the missing values.\n\nFor instance, using `SimpleImputer`:","a3ccab8d":"We first need to load the observation data:","47f9e621":"# Observation data loading"}}