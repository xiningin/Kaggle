{"cell_type":{"486afd98":"code","1a3f84f4":"code","e9ee0076":"code","bbfe8764":"code","11dca4a7":"code","4f84f7e6":"code","335c6e5f":"code","290b2a3c":"code","1f620256":"code","864cd11a":"code","73d1da6f":"code","695ece32":"code","3a310059":"code","fb02b6c4":"code","5f91727a":"code","faeafbb4":"code","3368c613":"code","515dcfec":"code","a72b0eed":"code","340b1259":"code","5c7c97ba":"code","31368ba0":"code","86e4614e":"code","d7a84ee5":"code","f2c29328":"code","a41ecb00":"code","79d71ace":"code","a1f1f5e7":"code","5be78ed3":"code","8bbb63f2":"markdown"},"source":{"486afd98":"# Install padelpy package which will be used to decode molecular finger prints\n!pip install padelpy -q","1a3f84f4":"!wget https:\/\/github.com\/dataprofessor\/padel\/raw\/main\/fingerprints_xml.zip\n!unzip fingerprints_xml.zip\n#listing and sorting the downloaded files\nimport glob\nxml_files = glob.glob(\"*.xml\")\nxml_files.sort()\nxml_files","e9ee0076":"FP_list = ['AtomPairs2DCount',\n 'AtomPairs2D',\n 'EState',\n 'CDKextended',\n 'CDK',\n 'CDKgraphonly',\n 'KlekotaRothCount',\n 'KlekotaRoth',\n 'MACCS',\n 'PubChem',\n 'SubstructureCount',\n 'Substructure']","bbfe8764":"#Creating Data Dictionary\nfp = dict(zip(FP_list, xml_files))\nfp","11dca4a7":"import glob\n\nall_files = (glob.glob(\"..\/input\/betalactamase\/*.csv\"))","4f84f7e6":"import pandas as pd\n\ndf = pd.concat( (pd.read_csv( f ) for f in all_files ) )","335c6e5f":"print(df.shape)\ndf = df[~df['canonical_smiles'].isnull()]\ndf.shape","290b2a3c":"# Bar plot of Missing vs Non-Missing Data\n\nimport matplotlib.pyplot as plt\n\n# Data\nmissing = df.pchembl_value.isnull().sum()\nnonmissing = df.pchembl_value.notnull().sum()\n\nx = ['Missing', 'Non-Missing']\ny = [missing, nonmissing]\n\n# Setup plot\nfig, ax = plt.subplots()\n\n# Make bar plot\np = ax.bar(x, y, color = ['#F8766D', '#00BFC4'], ec = 'black')\n\nax.set_title('pChEMBL Missing Data', fontsize=14, fontweight='bold', pad=15)\n#ax.set_xticklabels(x, fontweight='bold')\n\nax.set_ylim(0,70000)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\n\n# Label above bar\nfor index, data in enumerate(y):\n    plt.text(x=index-0.1 , y =data+1000 , s=f\"{data}\" , fontdict=dict(fontsize=14))\n\nfig.set_size_inches(5,4.5)\nplt.show()","1f620256":"# Non-missing data with pChEMBL value\ndf2 = df[df.pchembl_value.notnull()]\ndf2","864cd11a":"df2.groupby('molecule_chembl_id').mean()","73d1da6f":"df2.groupby('molecule_chembl_id').std()","695ece32":"df3 = df2.groupby('molecule_chembl_id').std()\ndf3[(df3.pchembl_value < 2) & (df3.pchembl_value == pd.NA)]","3a310059":"import numpy as np\n\ndf3 = df2.groupby('molecule_chembl_id').std()\ndf3[df3.pchembl_value == np.nan]","fb02b6c4":"print('Number of unique ChEMBL ID:', str(len(df.molecule_chembl_id.unique()) )  )\nprint('Total number of ChEMBL ID: ', str(len(df)) )\nprint('Number of missing ChEMBL ID: ', str(df.molecule_chembl_id.isnull().sum()) )","5f91727a":"import matplotlib.pyplot as plt\n\nunique = len(df.molecule_chembl_id.unique())\nnot_unique = len(df) - unique\n\nx = ['Unique', 'Redundant']\ny = [unique, not_unique]\n\n","faeafbb4":"df2.target_pref_name.value_counts()[0:50].plot.bar(figsize=(24,4), color='#00BFC4', ec='black')\n\nplt.title('Top 50 Targets', fontsize=14, fontweight='black', pad=15)\nplt.show()","3368c613":"# Top 10 Bioactivity units\ndf2.standard_type.value_counts()[:10].plot.bar(figsize=(8,4), color='#00BFC4', ec='black')\n\nplt.title('Top Bioactivity Units', fontsize=14, fontweight='black', pad=15)\nplt.show()","515dcfec":"bao_labels = df2.bao_label.value_counts()\nbao_labels.plot.bar(figsize=(8,4), color='#00BFC4', ec='black')\n\nplt.title('Histogram of BioAssay Ontology', fontsize=14, fontweight='black', pad=15)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","a72b0eed":"bao_labels","340b1259":"df2.pchembl_value.hist(bins=40, figsize=(8,4), color='#00BFC4', ec='black')\n\nplt.title('Histogram of pChEMBL values', fontsize=14, fontweight='black', pad=15)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","5c7c97ba":"df2.head()","31368ba0":"df4 = pd.concat( [df2['canonical_smiles'],df2['molecule_chembl_id']], axis=1 )\n#df4 = df2['canonical_smiles'].reset_index(drop=True)\ndf4.to_csv('molecule.smi', sep='\\t', index=False, header=False)\ndf4","86e4614e":"from padelpy import padeldescriptor\n \nfingerprint = 'Substructure'\n \nfingerprint_output_file = ''.join([fingerprint,'.csv']) #Substructure.csv\nfingerprint_descriptortypes = fp[fingerprint]\n \npadeldescriptor(mol_dir='\/kaggle\/working\/molecule.smi', \n                d_file=fingerprint_output_file, #'Substructure.csv'\n                #descriptortypes='SubstructureFingerprint.xml', \n                descriptortypes= fingerprint_descriptortypes,\n                detectaromaticity=True,\n                standardizenitro=True,\n                standardizetautomers=True,\n                threads=2,\n                removesalt=True,\n                log=True,\n                fingerprints=True)","d7a84ee5":"new_df = pd.read_csv('\/kaggle\/working\/Substructure.csv')\nnew_df.shape","f2c29328":"from sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import train_test_split\n\ndescriptors = pd.read_csv(fingerprint_output_file)\nprint(descriptors.shape)\n\nX = descriptors.drop('Name', axis=1)\ny = df2['pchembl_value'].values #feature being predicted\n\n#removing the low variance features\n \ndef remove_low_variance(input_data, threshold=0.1):\n    selection = VarianceThreshold(threshold)\n    selection.fit(input_data)\n    return input_data[input_data.columns[selection.get_support(indices=True)]]\n \nX = remove_low_variance(X, threshold=0.1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n#Printing Shape\nX_train.shape, X_test.shape","a41ecb00":"rows_with_nan = []\nfor index, row in X_train.iterrows():\n    is_nan_series = row.isnull()\n    if is_nan_series.any():\n        rows_with_nan.append(index)\nrows_with_nan","79d71ace":"X_train = X_train.dropna()\nX_train.shape,y_train.shape","a1f1f5e7":"import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = lgb.LGBMRegressor()\nmodel.fit(X_train,y_train,eval_set=[(X_test,y_test)],verbose=10,eval_metric='rmse')\npreds = model.predict(X_test)\nprint('RMSE: ',np.sqrt(mean_squared_error(y_test,preds)))","5be78ed3":"fig,ax = plt.subplots(1,2,figsize=(15,5))\nax[0].hist(y_train,label='y_train')\nax[0].hist(y_test,label='y_test')\nax[0].hist(preds,label='prediction')\nax[0].legend()\nax[1].scatter(y_test,preds)","8bbb63f2":"#**This is a notebook on Open Bio-informatics project using Beta-Lactamase Data**\n\n#*LightGBM Model*\n\nNotebook author: Aninda Goswamy\n\nOriginal idea and concept:Chanin Nantasenamat\n\n[Data Professor YouTube channel](https:\/\/youtube.com\/dataprofessor)"}}