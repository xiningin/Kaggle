{"cell_type":{"91b81242":"code","7b0e9fa4":"code","0f382ac5":"code","715dda24":"code","ebdec299":"code","5a19ba5e":"code","d70f863d":"code","c4f190c5":"code","b3e175a5":"code","0f497dad":"code","6735d2ae":"code","1f467348":"code","5b84fbb8":"code","3eb46fb5":"code","9df1915e":"code","acea65a5":"code","51719603":"code","21d845aa":"code","e5893960":"markdown","c4fc7545":"markdown","2f1bbb6a":"markdown","b65f18fa":"markdown"},"source":{"91b81242":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","7b0e9fa4":"from shutil import copyfile\nos.makedirs('..\/working\/readability\/') # create folder\ncopyfile(src = \"..\/input\/package-readability\/readability-master\/readability-master\/readability\/__init__.py\", dst = \"..\/working\/readability\/__init__.py\")\ncopyfile(src = \"..\/input\/package-readability\/readability-master\/readability-master\/readability\/langdata.py\", dst = \"..\/working\/readability\/langdata.py\")\ncopyfile(src = \"..\/input\/package-readability\/readability-master\/readability-master\/setup.py\", dst = \"..\/working\/setup.py\")\ncopyfile(src = \"..\/input\/package-readability\/readability-master\/readability-master\/README.rst\", dst = \"..\/working\/README.rst\")","0f382ac5":"import readability","715dda24":"to_test = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\ntrain = pd.read_csv(\"..\/input\/commonlitreadabilityprize\/train.csv\")","ebdec299":"df = pd.DataFrame(columns = [\"target\"] + [\"excerpt\"] + \n                  [i for i in readability.getmeasures(to_test.excerpt[0], lang='en')['readability grades']] +\n                  [i for i in readability.getmeasures(to_test.excerpt[0], lang='en')[\"sentence info\"]] + \n                 [i for i in readability.getmeasures(to_test.excerpt[0], lang='en')['word usage']] \n                 )\ndf.target = train.target\ndf.excerpt = train.excerpt\ndf_to_test = pd.DataFrame(columns = [\"excerpt\"] + \n                  [i for i in readability.getmeasures(to_test.excerpt[0], lang='en')['readability grades']] +\n                  [i for i in readability.getmeasures(to_test.excerpt[0], lang='en')[\"sentence info\"]] + \n                 [i for i in readability.getmeasures(to_test.excerpt[0], lang='en')['word usage']]  \n                 )\ndf_to_test.excerpt = to_test.excerpt\nbl = [\"readability grades\", \"sentence info\", \"word usage\"]\n# \"readability grades\"  train\nfor i in (df.columns[2:11]):\n    for j in range(df.shape[0]):\n        df.loc[j, i] = readability.getmeasures(df.excerpt[j], lang='en')[bl[0]][i]\n# \"readability grades\"  test\nfor i in (df_to_test.columns[1:10]):\n    for j in range(df_to_test.shape[0]):\n        df_to_test.loc[j, i] = readability.getmeasures(df_to_test.excerpt[j], lang='en')[bl[0]][i]\n# 'sentence info'  train\nfor i in (df.columns[11: 25]):\n    for j in range(df.shape[0]):\n        df.loc[j, i] = readability.getmeasures(df.excerpt[j], lang='en')[bl[1]][i]\n# \"sentence info\"  test\nfor i in (df_to_test.columns[10: 24]):\n    for j in range(df_to_test.shape[0]):\n        df_to_test.loc[j, i] = readability.getmeasures(df_to_test.excerpt[j], lang='en')[bl[1]][i]\n# \"word usage\" train\nfor i in (df.columns[25: 31]):\n    for j in range(df.shape[0]):\n        df.loc[j, i] = readability.getmeasures(df.excerpt[j], lang='en')[bl[2]][i]\n# \"word usage\" test\nfor i in (df_to_test.columns[24: 30]):\n    for j in range(df_to_test.shape[0]):\n        df_to_test.loc[j, i] = readability.getmeasures(df_to_test.excerpt[j], lang='en')[bl[2]][i]\nfor i in range(df.shape[0]):\n    df.loc[i, \"pronoun_b\"] =  readability.getmeasures(df.excerpt[[i]])['sentence beginnings']['pronoun']\nfor i in range(df_to_test.shape[0]):\n    df_to_test.loc[i, \"pronoun_b\"] =  readability.getmeasures(df_to_test.excerpt[[i]])['sentence beginnings']['pronoun']\nfor i in range(df.shape[0]):\n    df.loc[i, \"interrogative\"] =  readability.getmeasures(df.excerpt[[i]])['sentence beginnings']['interrogative']\nfor i in range(df_to_test.shape[0]):\n    df_to_test.loc[i, \"interrogative\"] =  readability.getmeasures(df_to_test.excerpt[[i]])['sentence beginnings']['interrogative']\nfor i in range(df.shape[0]):\n    df.loc[i, 'article'] =  readability.getmeasures(df.excerpt[[i]])['sentence beginnings']['article']\nfor i in range(df_to_test.shape[0]):\n    df_to_test.loc[i, 'article'] =  readability.getmeasures(df_to_test.excerpt[[i]])['sentence beginnings']['article']\nfor i in range(df.shape[0]):\n    df.loc[i, \"subordination\"] =  readability.getmeasures(df.excerpt[[i]])['sentence beginnings']['subordination']\nfor i in range(df_to_test.shape[0]):\n    df_to_test.loc[i, \"subordination\"] =  readability.getmeasures(df_to_test.excerpt[[i]])['sentence beginnings']['subordination']\nfor i in range(df.shape[0]):\n    df.loc[i, \"conjunction_b\"] =  readability.getmeasures(df.excerpt[[i]])['sentence beginnings']['conjunction']\nfor i in range(df_to_test.shape[0]):\n    df_to_test.loc[i, \"conjunction_b\"] =  readability.getmeasures(df_to_test.excerpt[[i]])['sentence beginnings']['conjunction']\nfor i in range(df.shape[0]):\n    df.loc[i, \"preposition_b\"] =  readability.getmeasures(df.excerpt[[i]])['sentence beginnings']['preposition'] \nfor i in range(df_to_test.shape[0]):\n    df_to_test.loc[i, \"preposition_b\"] =  readability.getmeasures(df_to_test.excerpt[[i]])['sentence beginnings']['preposition'] ","5a19ba5e":"df.head()","d70f863d":"df_to_test.head()","c4f190c5":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport lightgbm as lgb\nfrom pathlib import Path\nimport seaborn\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom warnings import simplefilter","b3e175a5":"!pip install kaggler","0f497dad":"import kaggler\nfrom kaggler.model import AutoLGB\nprint(kaggler.__version__)\nplt.style.use('fivethirtyeight')\npd.set_option('max_columns', 100)\nsimplefilter('ignore')","6735d2ae":"df = pd.concat([df, df_to_test])\ndf = df.reset_index(drop = True)","1f467348":"# the logic behind this is that, the given training data set \n# and hidden test data set were originally from a whole data set. \n# Staff graded the whole data set first, then split it \n# into training data set and test data set. Now we are \n# inversing the process to see the distribution between \n# training data set and test data set. The split way is\n# hard coded right now, so we can use train_test_split\n# many times in different seeds to check the average auc \n# score for being more rigorous.","5b84fbb8":"trn = df.iloc[:1400, ]\ntst = df.iloc[1400:, ]\ntarget_col = 'target'\nn_fold = 5\nseed = 42","3eb46fb5":"print(trn.shape)\nprint(tst.shape)","9df1915e":"n_trn = trn.shape[0]\ndf = pd.concat([trn.drop([target_col,\"excerpt\"], axis=1), tst.drop(\"excerpt\", axis=1)], axis=0)\nprint(df.shape)","acea65a5":"df = df.astype(float)\ndf.head()","51719603":"cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\nX = df\ny = pd.Series(np.concatenate([np.zeros(n_trn,), np.ones(df.shape[0] - n_trn,)]))\np = np.zeros_like(y, dtype=float)\nfor i, (i_trn, i_val) in enumerate(cv.split(X, y)):\n    if i == 0:\n        clf = AutoLGB(objective='binary', metric='auc', random_state=seed)\n        clf.tune(X.iloc[i_trn], y[i_trn])\n        features = clf.features\n        params = clf.params\n        n_best = clf.n_best\n        print(f'{n_best}')\n        print(f'{params}')\n        print(f'{features}')\n    \n    trn_data = lgb.Dataset(X.iloc[i_trn], y[i_trn])\n    val_data = lgb.Dataset(X.iloc[i_val], y[i_val])\n    clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100)\n    p[i_val] = clf.predict(X.iloc[i_val])\n    print(f'CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}')","21d845aa":"print(f'CV AUC: {roc_auc_score(y, p):.6f}')","e5893960":"# Extract features from excerpt by the readability library","c4fc7545":"# Split the whole data set into balanced training data set and test data set","2f1bbb6a":"# Adversarial validation AUC score is far way from 50%. Therefore, we can say that the training and test data sets are not similar in terms of basic feature distributions. In other words, should be careful of a big shake-up at the end of the competition","b65f18fa":"# Concat the training data set and the test data set"}}