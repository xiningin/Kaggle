{"cell_type":{"d0e6f09e":"code","2086cdee":"code","a322ab31":"code","94899000":"code","0c6a75e2":"code","d229af25":"code","dfb14bad":"code","605ea1e4":"code","662af799":"code","1748d4b7":"code","e1d4c467":"code","5c206756":"code","9ec9c4c1":"code","074989b9":"code","ea280cc3":"code","ec503e59":"code","3c51a132":"markdown","4e9eabd9":"markdown","01f7db4e":"markdown","49dc4972":"markdown","773e1c43":"markdown","90e9d0a6":"markdown","1793177c":"markdown","c70946f4":"markdown","edd9e753":"markdown","a2d50d9e":"markdown"},"source":{"d0e6f09e":"import numpy as np\nimport pandas as pd\n\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\n# from sklearn.impute import SimpleImputer     # verified that there're no null values accordingly we don't need SimpleImputer\n\nfrom sklearn.metrics import roc_auc_score, classification_report\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\n\nimport optuna\nfrom optuna.samplers import TPESampler\nfrom tqdm import tqdm\n\n\nplt.rcParams['axes.unicode_minus'] = False\nplt.style.use('seaborn') \nsns.set(font_scale=1)  \npd.set_option('display.max_columns', None)\nwarnings.filterwarnings('ignore')\n\nprint(\"Let's start!\")","2086cdee":"trn = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv', index_col = 'id')\ntst = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv', index_col = 'id')\n\ndisplay(trn.shape, trn.head(3), tst.shape, tst.head(3))","a322ab31":"# null data check\n\nnull_trn = trn.isnull().sum().sort_values(ascending = False)\nnull_tst = tst.isnull().sum().sort_values(ascending = False)\n\nprint(\"null data list of trn set\\n\")\nfor idx in null_trn.index:\n    if null_trn[idx] > 0:\n        print(idx, null_trn[idx]) \n        \nprint(\"================================\\n\")\nprint(\"null data list of tst set\")\nfor idx in null_tst.index:\n    if null_tst[idx] > 0:\n        print(idx, null_tst[idx])     ","94899000":"# Target values distribution\n\nax = sns.countplot(trn['target'])\n\nax.bar_label(ax.containers[0])\nax.set_ylim(0, 350000)\n\nplt.show()","0c6a75e2":"features = trn.columns[:-1]\ntarget = trn.columns[-1]","d229af25":"# Thanks to https:\/\/www.kaggle.com\/maximkazantsev\/tps-11-21-eda-xgboost-optuna#Data-preprocessing\n\n\ndf = pd.concat([trn[features], tst[features]], axis=0)\n\ncolumns = df.columns.values\n\ncols = 5\nrows = len(columns) \/\/ cols + 1\n\nfig, axs = plt.subplots(ncols=cols, nrows=rows, figsize=(16,65), sharex=False)\n\nplt.subplots_adjust(hspace = 0.3)\ni=0\n\nfor r in np.arange(0, rows, 1):\n    for c in np.arange(0, cols, 1):\n        if i >= len(columns):\n            axs[r, c].set_visible(False)\n        else:\n            hist1 = axs[r, c].hist(trn[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"deepskyblue\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Train Dataset\")\n            hist2 = axs[r, c].hist(tst[columns[i]].values,\n                                   range=(df[columns[i]].min(),\n                                          df[columns[i]].max()),\n                                   bins=40,\n                                   color=\"palevioletred\",\n                                   edgecolor=\"black\",\n                                   alpha=0.7,\n                                   label=\"Test Dataset\")\n            axs[r, c].set_title(columns[i], fontsize=12, pad=5)\n            axs[r, c].set_yticks(axs[r, c].get_yticks())\n            axs[r, c].set_yticklabels([str(int(i\/1000))+\"k\" for i in axs[r, c].get_yticks()])\n            axs[r, c].tick_params(axis=\"y\", labelsize=10)\n            axs[r, c].tick_params(axis=\"x\", labelsize=10)\n            axs[r, c].grid(axis=\"y\")\n            if i == 0:\n                axs[r, c].legend(fontsize=10)\n                                  \n        i+=1\n\nplt.show();","dfb14bad":"# scaling\n\nss = StandardScaler()\n\nfor col in features:\n    trn[col] = ss.fit_transform(trn[[col]])\n    tst[col] = ss.fit_transform(tst[[col]])\n    \ndisplay(trn.head(3), tst.head(3))","605ea1e4":"# train_test_split\n\nX_trn = trn[features]\ny_trn = trn[target]\nX_tst = tst[features]\n\ndisplay(X_trn.shape, y_trn.shape, X_tst.shape)","662af799":"# k-fold cross validation, trial with the default parameter.\n\n\n# RANDOM_SEED = 42\n# n_splits = 5\n# skf = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state = RANDOM_SEED)\n\n# tst_preds = []\n# mean_auc = 0\n\n# model = LGBMClassifier(random_state = RANDOM_SEED)\n\n# for fold, (trn_idx, val_idx) in tqdm(enumerate(skf.split(X_trn, y_trn))):\n#     X_train, X_val = X_trn.loc[trn_idx], X_trn.loc[val_idx]\n#     y_train, y_val = y_trn.loc[trn_idx], y_trn.loc[val_idx]\n    \n#     model.fit(X_train, y_train,\n#              verbose = False,\n#              eval_set = [(X_train, y_train), (X_val, y_val)],\n#              eval_metric = 'auc',\n#              early_stopping_rounds = 100)\n    \n#     y_pred = model.predict_proba(X_val)\n#     score = roc_auc_score(y_val, y_pred[:,1])\n#     mean_auc += score\n    \n#     print(f\"Fold {fold}'s score: {score}\")\n        \n#     tst_preds.append(model.predict_proba(X_tst)[:, 1])\n\n# print(\"==========================================\")\n# print(f\"Mean auc of all folds: {mean_auc \/ n_splits}\")","1748d4b7":"# # HPO using opuna\n\n# def lgb_objective(trial):\n#     params = {\n#         'boosting_type': 'gbdt',\n#         'objective': 'binary',\n#         'n_estimators': trial.suggest_int(\"n_estimators\", 64, 8192),\n#         'learning_rate': trial.suggest_float(\"learning_rate\", 1e-3, 0.25, log=True),\n#         'num_leaves': trial.suggest_int(\"num_leaves\", 20, 3000),\n#         'max_depth': trial.suggest_int(\"max_depth\", 3, 12),\n#         'feature_fraction': trial.suggest_float(\"feature_fraction\", 0.1, 1.0),\n#         'min_gain_to_split' : trial.suggest_int('min_gain_to_split', 0, 15),\n#         'min_data_in_leaf' : trial.suggest_int(\"min_data_in_leaf\", 100, 1000),\n#         'lambda_l1': trial.suggest_loguniform(\"lambda_l1\", 1e-8, 100.0),\n#         'lambda_l2': trial.suggest_loguniform(\"lambda_l2\", 1e-8, 100.0),\n#         'bagging_fraction' : trial.suggest_float(\"bagging_fraction\", 0, 0.8),\n#         'bagging_freq' : trial.suggest_int(\"bagging_freq\", 1, 100),\n#         'seed': 42,\n#         'deterministic': True,\n#         'metric' : 'auc',\n#         'verbose':-1\n#     }\n    \n#     X_train, X_val, y_train, y_val = train_test_split(X_trn, y_trn, test_size = 0.3, random_state = 42)\n    \n#     model = LGBMClassifier(**params)\n#     model.fit(X_train, y_train,\n#              eval_set = [(X_train, y_train), (X_val, y_val)],\n#              early_stopping_rounds = 100,\n#              eval_metric = 'auc',\n#              verbose = False\n#              )\n#     pred_val = model.predict(X_val)\n    \n#     return roc_auc_score(y_val, pred_val)","e1d4c467":"# sampler = TPESampler(seed = 42)\n# study = optuna.create_study(study_name = 'lgbm_hpo',\n#                            direction = 'maximize',\n#                            sampler = sampler)\n# study.optimize(lgb_objective, n_trials = 10)\n\n# print(\"Best AUC:\", study.best_value)\n# print(\"Best params:\", study.best_params)","5c206756":"# params = study.best_params","9ec9c4c1":"params = {'boosting_type': 'gbdt',\n          'objective': 'binary',\n          'n_estimators': 7276, \n          'learning_rate': 0.013562603384785458,\n          'num_leaves': 376,\n          'max_depth': 10,\n          'feature_fraction': 0.7847065437552077,\n          'min_gain_to_split': 8,\n          'min_data_in_leaf': 794,\n          'lambda_l1': 0.0008668739724852811,\n          'lambda_l2': 0.0016878284140548435,\n          'bagging_fraction': 0.3420328146868397,\n          'bagging_freq': 3,\n          'seed': 42,\n          'deterministic': True,\n          'metric' : 'auc',\n          'verbose':-1\n         }","074989b9":"RANDOM_SEED = 42\nn_splits = 5\nskf = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state = RANDOM_SEED)\n\ntst_preds = []\nmean_auc = 0\n\nmodel = LGBMClassifier(**params)\n\nfor fold, (trn_idx, val_idx) in tqdm(enumerate(skf.split(X_trn, y_trn))):\n    X_train, X_val = X_trn.loc[trn_idx], X_trn.loc[val_idx]\n    y_train, y_val = y_trn.loc[trn_idx], y_trn.loc[val_idx]\n    \n    model.fit(X_train, y_train,\n             verbose = False,\n             eval_set = [(X_train, y_train), (X_val, y_val)],\n             eval_metric = 'auc',\n             early_stopping_rounds = 100)\n    \n    y_pred = model.predict_proba(X_val)\n    score = roc_auc_score(y_val, y_pred[:,1])\n    mean_auc += score\n    \n    print(f\"Fold {fold}'s score: {score}\")\n        \n    tst_preds.append(model.predict_proba(X_tst)[:, 1])\n\nprint(\"==========================================\")\nprint(f\"Mean auc of all folds: {mean_auc \/ n_splits}\")","ea280cc3":"final_preds = np.mean(tst_preds, axis = 0)\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\nsubmission['target'] = final_preds\nsubmission","ec503e59":"submission.to_csv('submission.csv', index = False)","3c51a132":"### Data Load","4e9eabd9":"### Hyperparameter optimization using Optuna","01f7db4e":"### Out Of Folds ensemble","49dc4972":"### Library import","773e1c43":"### Target variable","90e9d0a6":"### Standardization of the numerical variables using StandardScaler","1793177c":"### Check for the existence of null data","c70946f4":"### Prediction and submission","edd9e753":"### Compare the distribution of train data and that of test data","a2d50d9e":"### "}}