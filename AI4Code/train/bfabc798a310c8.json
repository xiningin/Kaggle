{"cell_type":{"3878702a":"code","e6907b2f":"code","c516ae4e":"code","3d604ffe":"code","9b001781":"code","733bfcbb":"code","b01e8f39":"code","0cede57f":"code","cdc43280":"code","6d0d3d94":"code","128e25fd":"code","27b45eab":"code","a2fc1dbc":"code","714d4225":"code","5492da92":"code","f26d4f43":"code","462e20b5":"code","174d0519":"code","5de0b532":"code","8a939863":"code","61239e79":"code","d19ad096":"code","92816281":"code","eff0b430":"code","0d05dd77":"code","73cf1455":"code","edf2aba8":"code","424fa2b9":"code","70f46393":"code","eb751d7e":"code","fd584722":"code","a5edd5b4":"code","a0f364f6":"code","f40a05f8":"code","caf2c9f2":"code","b600a68b":"code","c5b2ec36":"code","033d3d51":"markdown","b184071a":"markdown","ee043e99":"markdown","2c766949":"markdown","97a1f979":"markdown","23551826":"markdown"},"source":{"3878702a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom itertools import combinations\nfrom catboost import CatBoostClassifier\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom datetime import datetime\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e6907b2f":"df = pd.read_csv('..\/input\/bank-classification.csv')","c516ae4e":"def examine_columns(df: pd.DataFrame):\n    for col in df.columns:\n        print(col, df[col].nunique())\n        if df[col].nunique() < 100:\n            print(df[col].value_counts(dropna=False))\n        else:\n            print(df[col].agg(['mean', 'std', 'min', 'max', 'kurtosis', 'skew']))\n        print()","3d604ffe":"examine_columns(df)","9b001781":"dt_birth = pd.to_datetime(df['birth_date'])\ndt_contact = pd.to_datetime(df['contact_date'])\n\ndf['age_days'] = (datetime.now() - dt_birth).dt.days\ndf['contacted_age_days'] = (dt_contact - dt_birth).dt.days\ndel df['birth_date']\n\ndf['contact_year'] = dt_contact.dt.year\ndf['contact_month'] = dt_contact.dt.month\ndf['contact_weekday'] = dt_contact.dt.weekday\ndf['since_contacted'] = (datetime.now() - dt_contact).dt.days\ndel df['contact_date']","733bfcbb":"df.head()","b01e8f39":"df.shape","0cede57f":"examine_columns(df)","cdc43280":"from sklearn.preprocessing import PolynomialFeatures, minmax_scale","6d0d3d94":"df['lots_of_pdays'] = (df['pdays'] == 999).astype(np.int)","128e25fd":"numeric_features = [\n    'age_days',\n    'contacted_age_days',\n    'since_contacted',\n    'pdays',\n]","27b45eab":"for col in numeric_features:\n    df[f'{col}_log'] = np.log(df[col].values).astype(df[col].dtype)","a2fc1dbc":"poly_colnames = list(set(numeric_features) | set(map(lambda col: col+'_log', numeric_features)))\npoly = PolynomialFeatures(degree=3)\ndf_poly = pd.DataFrame(poly.fit_transform(df[poly_colnames].values), index=df.index).add_prefix('poly_')\ndf_poly.head()","714d4225":"%%time\ndf = df.join(df_poly)","5492da92":"df_cols_num = [\n    *[col for col in df.columns if 'poly' in col or 'log' in col],\n    *list(set(numeric_features) & set(df.columns))\n]\n\ndf_cols_unknown_to_na = [\n    'y',\n    'age_days',\n    'contacted_age_days',\n    'contact_year',\n    'contact_month',\n    'contact_weekday',\n    'since_contacted',\n    *df_cols_num\n]  # other columns will treat 'unknown' as a separate category\n","f26d4f43":"df[df_cols_unknown_to_na] = df[df_cols_unknown_to_na].replace('unknown', np.nan)","462e20b5":"df.index = df['id']\ndel df['id']\ntest_df = df[df['y'].isna()]\ntrain_df = df[~df['y'].isna()]\nlabels = train_df['y'].map({'yes': 1, 'no': 0}).copy()\ndel train_df['y']\ndel test_df['y']","174d0519":"test_df.shape","5de0b532":"train_df.shape","8a939863":"labels.shape","61239e79":"df.head()","d19ad096":"assert(train_df[list(set(df_cols_unknown_to_na) & set(train_df.columns))].isna().sum().sum() == 0)","92816281":"from catboost import cv, Pool","eff0b430":"cat_features_nunique_threshold = 1000  # keeping days since contacted as a categorical feature","0d05dd77":"below_threshold = train_df.nunique() < cat_features_nunique_threshold\nnumerical = pd.Series(map(lambda col: col in set(df_cols_num), train_df.columns), index=below_threshold.index)","73cf1455":"cat_features_ids = np.where(below_threshold & ~numerical)[0].tolist()\npool = Pool(train_df, label=labels, cat_features=cat_features_ids)","edf2aba8":"len(cat_features_ids)","424fa2b9":"params = {}\nparams['loss_function'] = 'Logloss'\nparams['iterations'] = 128\nparams['custom_loss'] = 'AUC'\nparams['random_seed'] = 42\nparams['learning_rate'] = 0.2137\nparams['early_stopping_rounds'] = 24","70f46393":"cv_data = cv(\n    params = params,\n    pool = pool,\n    fold_count=5,\n    shuffle=True,\n    partition_random_seed=42,\n    plot=True,\n    stratified=False,\n    verbose=False\n)","eb751d7e":"cv_data['test-AUC-mean'].agg(['mean', 'std'])","fd584722":"model_save_filename = f\"catboost-{cv_data['test-AUC-mean'].mean()}.csv\"\nmodel_save_filename","a5edd5b4":"from sklearn.model_selection import train_test_split","a0f364f6":"X_train, X_val, y_train, y_val = train_test_split(train_df, labels, test_size=0.2, shuffle=True, random_state=42)\n\nmodel = CatBoostClassifier(**params)\nmodel.fit(Pool(X_train, y_train, cat_features=cat_features_ids), eval_set=(X_val, y_val), verbose=False, plot=True, use_best_model=True)","f40a05f8":"preds = model.predict_proba(test_df)","caf2c9f2":"pd.read_csv('..\/input\/sample_submission.csv').head()","b600a68b":"subm = pd.DataFrame({'id': test_df.index.values, 'y': preds[:, 1]})\nsubm.head()","c5b2ec36":"subm.to_csv(model_save_filename, index=False)","033d3d51":"# Some feature magic","b184071a":"# CatBoost\nThis notebook showcases my use of CatBoost as a quality, low effort tool to make predictions.\n\n### Latest version\nContains experiment that I conducted after competition end, fixing some bugs from Version 3 to see how well could it score if I had enough time to complete it.\n\n### Version 2\nIs my top submission in this competition.","ee043e99":"# Datetime basic features","2c766949":"# Low effort CatBoost","97a1f979":"# Generating predictions","23551826":"# Final preprocessing before training"}}