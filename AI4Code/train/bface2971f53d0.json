{"cell_type":{"e2a8296b":"code","cc0b9d42":"code","1a147f34":"code","0e2ccda9":"code","d733d097":"code","76a9a70b":"code","fa3bae6a":"code","40cbc466":"code","679f9475":"code","0f8ed232":"markdown","f5a45aef":"markdown","52c7a1ca":"markdown"},"source":{"e2a8296b":"!pip install kaggle-environments -U > \/dev\/null 2>&1\n!cp -r ..\/input\/lux-ai-2021\/* .","cc0b9d42":"import numpy as np\nimport json\nfrom pathlib import Path\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split","1a147f34":"model = torch.jit.load(\"..\/input\/lux-ai-with-il-decreasing-learning-rate\/model.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_il.pth')","0e2ccda9":"model = torch.jit.load(\"..\/input\/models-lux\/model_toad.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_toad.pth')","d733d097":"model = torch.jit.load(\"..\/input\/d\/bachngoh\/luxai-models\/submission_unet_v6_updated_ctile\/model.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), (torch.rand(1, 14, 32, 32), torch.rand(1,14,4,4)))\ntraced.save('model_unet.pth')","76a9a70b":"model = torch.jit.load(\"..\/input\/d\/bachngoh\/luxai-models\/submission_unet_v6_updated_ctile\/model_ct.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), (torch.rand(1, 14, 32, 32), torch.rand(1,14,4,4)))\ntraced.save('model_unet_ct.pth')","fa3bae6a":"%%writefile agent.py\nimport os\nimport numpy as np\nimport torch\nfrom lux.game import Game\nfrom collections import Counter\nfrom torch import nn\n\n\npath = '\/kaggle_simulations\/agent' if os.path.exists('\/kaggle_simulations') else '.'\n\nmodel = torch.jit.load(f\"{path}\/model_il.pth\")\nmodel.eval()\n\nmodel2 = torch.jit.load(f\"{path}\/model_unet.pth\")\nmodel2.eval()\n\nmodel4 = torch.jit.load(f\"{path}\/model_toad.pth\")\nmodel4.eval()\n\nmodel_ct = torch.jit.load(f\"{path}\/model_unet_ct.pth\")\nmodel_ct.eval()\n\n\ndef make_input(obs, unit_id):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) \/\/ 2\n    y_shift = (32 - height) \/\/ 2\n    cities = {}\n    \n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,\n                    (wood + coal + uranium) \/ 100\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown \/ 6,\n                    (wood + coal + uranium) \/ 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]   \n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt \/ 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) \/ 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel \/ lightupkeep, 10) \/ 10\n    \n    # Day\/Night Cycle\n    b[17, :] = obs['step'] % 40 \/ 40\n    # Turns\n    b[18, :] = obs['step'] \/ 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\ndef make_input_unet(obs):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) \/\/ 2\n    y_shift = (32 - height) \/\/ 2\n    cities = {}\n    global_features = np.zeros((14,4,4))\n    \n    b = np.zeros((14, 32, 32), dtype=np.float32)\n    \n    friendly_unit_cnt = 0\n    opponent_unit_cnt = 0\n    friendly_ctile_cnt = 0\n    opponent_ctile_cnt = 0\n    total_wood = 0\n    total_coal = 0\n    total_uranium = 0\n    \n    can_mine_coal = 0\n    can_mine_uranium = 0\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            \n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            \n            # Units\n            team = int(strs[2])\n            \n            if (team - obs['player']) % 2 == 0:\n                friendly_unit_cnt += 1\n            else:\n                opponent_unit_cnt += 1\n            \n            cooldown = float(strs[6])\n            idx = (team - obs['player']) % 2 * 3\n            b[idx:idx + 3, x, y] = (\n                1,\n                cooldown \/ 6,\n                (wood + coal + uranium) \/ 100\n            )\n        elif input_identifier == 'ct':\n            # CityTiles\n            \n            team = int(strs[1])\n            \n            if (team - obs['player']) % 2 == 0:\n                friendly_ctile_cnt += 1\n            else:\n                opponent_ctile_cnt += 1\n            \n            city_id = strs[2]\n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 6 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 10, 'coal': 11, 'uranium': 12}[r_type], x, y] = amt \/ 800\n            if r_type == 'wood': total_wood += amt\n            elif r_type == 'coal': total_coal += amt\n            elif r_type == 'uranium': total_uranium += amt\n            \n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            if team - obs['player'] % 2 == 0:\n                if rp >= 50:\n                    can_mine_coal = 1\n                if rp >= 200:\n                    can_mine_uranium = 1\n            \n            global_features[(team - obs['player']) % 2, :] = min(rp, 200) \/ 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel \/ lightupkeep, 10) \/ 10\n    \n    # Day\/Night Cycle\n    global_features[2, :] = obs['step'] % 40 \/ 40\n    # Turns\n    global_features[3, :] = obs['step'] \/ 360\n    # Number of friendly unit \n    global_features[4, :] = friendly_unit_cnt \/ 50\n    # Number of opponent unit\n    global_features[5, :] = opponent_unit_cnt \/ 50\n    # Number of friendly ctiles\n    global_features[6, :] = friendly_ctile_cnt \/ 50\n    # Number of opponent unit\n    global_features[7, :] = opponent_ctile_cnt \/ 50\n    # Total Wood\n    global_features[8, :] = total_wood \/ 24000\n    # Total Coal\n    global_features[9, :] = total_coal \/ 24000\n    # Total Uranium\n    global_features[10, :] = total_uranium \/ 12000\n    global_features[11, :] = can_mine_coal\n    global_features[12, :] = can_mine_uranium\n    # Map Size\n    global_features[13, :] = width \n    \n    # Map Size\n    b[13, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b, global_features\n\n\ngame_state = None\ndef get_game_state(observation):\n    global game_state\n    \n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation[\"player\"]\n    else:\n        game_state._update(observation[\"updates\"])\n    return game_state\n\n\ndef in_city(pos):    \n    try:\n        city = game_state.map.get_cell_by_pos(pos).citytile\n        return city is not None and city.team == game_state.id\n    except:\n        return False\n\n\ndef call_func(obj, method, args=[]):\n    return getattr(obj, method)(*args)\n\n\nunit_actions = [('move', 'n'), ('move', 's'), ('move', 'w'), ('move', 'e'), ('build_city',)]\ndef get_action(policy, unit, dest):\n\n    for label in np.argsort(policy)[::-1]:\n        act = unit_actions[label]\n        pos = unit.pos.translate(act[-1], 1) or unit.pos\n        if pos not in dest or in_city(pos):\n            return call_func(unit, *act), pos \n            \n    return unit.move('c'), unit.pos\n\ndef get_action_unet(policy, unit, dest, shift):\n    logits = nn.Softmax(policy[:, unit.pos.x + shift, unit.pos.y + shift] )\n    action = unet_unit_actions[ np.argmax( policy[:, unit.pos.x + shift, unit.pos.y + shift] )]\n    pos = unit.pos.translate(action[-1], 1) or unit.pos\n    if pos not in dest or in_city(pos):\n        return call_func(unit, *action), pos\n    \n    return unit.move('c'), unit.pos \n\ndef get_shift(observation):\n    width, height = observation['width'], observation['height']\n    shift = (32 - width) \/\/ 2\n    return shift\n\n\ndef agent(observation, configuration):\n    global game_state\n    \n    game_state = get_game_state(observation)    \n    player = game_state.players[observation.player]\n    actions = []\n    \n    shift = get_shift(observation)\n    #print(shift)\n    state_1, state_2 = make_input_unet(observation)\n    with torch.no_grad():\n        p_ct = model_ct(torch.from_numpy(state_1).unsqueeze(0).float(), torch.from_numpy(state_2).unsqueeze(0).float())\n        policy_ct = p_ct.squeeze(0).numpy()\n        \n    # City Actions\n    unit_count = len(player.units)\n    for city in player.cities.values():\n        for city_tile in city.citytiles:\n            if city_tile.can_act():\n                action = np.argmax( policy_ct[:, city_tile.pos.x + shift, city_tile.pos.y + shift] )\n                if action == 0:\n                    actions.append(city_tile.research())\n                    player.research_points += 1\n                elif action == 1:\n                    actions.append(city_tile.build_worker())\n                    unit_count += 1\n    \n    # Worker Actions\n    dest = []\n\n    with torch.no_grad():\n        p1 = model2(torch.from_numpy(state_1).unsqueeze(0).float(), torch.from_numpy(state_2).unsqueeze(0).float())\n        policy_unet = p1.squeeze(0).numpy()\n\n    \n    for unit in player.units:\n        if unit.can_act() and (game_state.turn % 40 < 30 or not in_city(unit.pos)):\n            state = make_input(observation, unit.id)\n            with torch.no_grad():\n                p = model(torch.from_numpy(state).unsqueeze(0))\n            \n                p2 = model4(torch.from_numpy(state).unsqueeze(0))\n\n            policy = p.squeeze(0).numpy()\n            policy2 = policy_unet[:, unit.pos.x + shift, unit.pos.y + shift] \n            policy4 = p2.squeeze(0).numpy()\n\n            softmax = nn.Softmax(dim=0)\n            logits1 = softmax(torch.from_numpy(policy))\n            logits2 = softmax(torch.from_numpy(policy2))\n            logits4 = softmax(torch.from_numpy(policy4))\n\n            ensemble_logits = np.array( logits1 * 0.4 + logits2 * 0.4 + logits4 * 0.2)\n\n            action, pos = get_action(policy, unit, dest)\n\n            actions.append(action)\n            dest.append(pos)\n\n    return actions","40cbc466":"from kaggle_environments import make\n\nenv = make(\"lux_ai_2021\", configuration={\"width\": 24, \"height\": 24, \"loglevel\": 0, \"annotations\": True}, debug=True)\nsteps = env.run(['agent.py', 'agent.py'])\nenv.render(mode=\"ipython\", width=1200, height=800)","679f9475":"!tar -czf submission.tar.gz *","0f8ed232":"# Introduction\nSince the competition is now over, I want to share my (hopefully **silver**, or bronze) solution. My agent is an ensemble of 3 IL agents, I borrowed that idea from the [lux-ai-with-il-ensemble-of-models](https:\/\/www.kaggle.com\/realneuralnetwork\/lux-ai-with-il-ensemble-of-models) notebook but instead of choosing the most common action, I take the softmax function and choose the action with highest probability. 3 IL models are:\n- [lux-ai-with-il-decreasing-learning-rate](https:\/\/www.kaggle.com\/realneuralnetwork\/lux-ai-with-il-decreasing-learning-rate) \n- [toad model from the orginal ensemble notebook](https:\/\/www.kaggle.com\/realneuralnetwork\/lux-ai-with-il-ensemble-of-models) I tried to use many different models but somehow this one gave the best performance\n- [unet immitation learning](https:\/\/www.kaggle.com\/bachngoh\/luxai-unet-immitationlearning-lb-1100) I was inspired by [this](https:\/\/www.kaggle.com\/c\/lux-ai-2021\/discussion\/289540) amazing post by nosound.\n\nI also use unet to train the city tile actions:\n- [unet for ctiles](https:\/\/www.kaggle.com\/bachngoh\/luxai-unet-for-ctiles)","f5a45aef":"# Submission","52c7a1ca":"[lux-ai-with-il-decreasing-learning-rate](https:\/\/www.kaggle.com\/realneuralnetwork\/lux-ai-with-il-decreasing-learning-rate) amazing notebook!"}}