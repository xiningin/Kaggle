{"cell_type":{"232bc312":"code","60ff32a6":"code","a6ad87b4":"code","78a858a6":"code","0d76da61":"code","f3e11ea8":"code","b45a71c5":"code","b35ed02f":"code","afc2c750":"code","b5e5a55b":"code","d5014544":"code","d22bb88b":"code","062f7de5":"code","7d7bfbd2":"code","568017d9":"code","908bcbdf":"code","95210e28":"code","5e664d22":"code","4b13e595":"code","7d1bc6f1":"code","d5061481":"code","60993b07":"code","3dd48f1d":"code","2974b891":"code","5b017ced":"code","edbc5412":"code","33979625":"code","cd6d0cd9":"code","769aedd9":"code","6a9bc98a":"code","4a82df17":"code","9de7b326":"code","f851ebcd":"code","dcf9e97b":"code","1c032c29":"markdown","f41ebde1":"markdown","e47f78af":"markdown","01fb27b5":"markdown","86e236b2":"markdown","52c0bb6e":"markdown"},"source":{"232bc312":"import numpy as np \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport librosa\nimport IPython\nimport tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom datetime import datetime\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nimport soundfile as sf\nimport shutil\n\nfrom tensorflow import keras \nfrom tensorflow.keras import layers","60ff32a6":"metadata_train = pd.read_csv('\/kaggle\/input\/moroccan-darija-trigger-word-classification-ed-2\/train.csv')\n\nmetadata_test = pd.read_csv('\/kaggle\/input\/moroccan-darija-trigger-word-classification-ed-2\/test.csv')","a6ad87b4":"print(\"Training DataFrame : \\n\")\nprint(metadata_train.info(), \"\\n\")\nwith pd.option_context('display.max_rows', 5):\n    display(metadata_train)\n    \nprint(\"\"\"\\n\\n-------------------------------------\n\\n\\nTesting DataFrame :\n\"\"\")\nprint(metadata_test.info(), \"\\n\")\nwith pd.option_context('display.max_rows', 5):\n    display(metadata_test)","78a858a6":"metadata_train['label'].unique()","0d76da61":"counts = metadata_train['label'].value_counts().to_dict()\n\nbar_df = pd.DataFrame({\n    'label' : [1, 0],\n    'count' : [counts[1], counts[0]]\n}) \n\nbar_df","f3e11ea8":"bar_df.plot.bar(x = 'label', y = 'count', rot = 0)","b45a71c5":"trainpath = '\/kaggle\/input\/moroccan-darija-trigger-word-classification-ed-2\/data\/train\/'\n\ndirname = list(os.walk(trainpath))[0][0]\nfilenames = list(os.walk(trainpath))[0][2]\n\nfilenames[:5]","b35ed02f":"IPython.display.Audio(trainpath + '\/' + 'a3tqxrhku5ds4pg2fzi7j.wav')","afc2c750":"augmented_dataset_path = '\/kaggle\/working\/out\/train\/'","b5e5a55b":"try :\n    shutil.rmtree('\/kaggle\/working\/out\/')\nexcept OSError as e:\n    print(\"Error: %s - %s.\" % (e.filename, e.strerror))","d5014544":"os.makedirs(augmented_dataset_path)","d22bb88b":"audio_files = []\n\nfor dirname, _, filenames in os.walk(trainpath):\n    for filename in filenames:\n        audio_files.append(augmented_dataset_path + filename)\n        audio_files.append(augmented_dataset_path + filename[:-4] + '-' + 'manipulated' + '.wav' )\n        shutil.copy(dirname + filename, augmented_dataset_path)\n        audio_data, sr = librosa.load( dirname + filename )\n        audio_manipulated = librosa.effects.pitch_shift(audio_data, sr, n_steps = 4, bins_per_octave = 24)\n        sf.write(augmented_dataset_path + filename[:-4] + '-' + 'manipulated' + '.wav', audio_manipulated, sr, 'PCM_24')\n        print(augmented_dataset_path + filename[:-4] + '-' + 'manipulated' + '.wav')","062f7de5":"IPython.display.Audio( augmented_dataset_path + 'vyxf60zbo87nlgcu542tm-manipulated.wav')","7d7bfbd2":"IPython.display.Audio(augmented_dataset_path + 'vyxf60zbo87nlgcu542tm.wav')","568017d9":"cp = metadata_train.copy()\ncp ['id'] = cp['id'].apply(lambda x : x + \"-manipulated\")\nmetadata_train = pd.concat([ metadata_train, cp ])\nmetadata_train","908bcbdf":"def features_extractor(file_name):\n    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n    \n    return mfccs_scaled_features","95210e28":"extracted_features = []\n\nfor index_num,row in tqdm.tqdm(metadata_train.iterrows()):\n    file_name = os.path.join(augmented_dataset_path, row['id'] + '.wav')\n    audio_class = row['label']\n    data = features_extractor(file_name)\n    extracted_features.append( [data, audio_class] )","5e664d22":"extracted_features_df = pd.DataFrame( extracted_features, columns=['feature','class'] )\nextracted_features_df.head(10)","4b13e595":"X = np.array(extracted_features_df['feature'].tolist())\ny = np.array(extracted_features_df['class'].tolist())","7d1bc6f1":"extracted_features_df.iloc[0]","d5061481":"X_train,X_test,y_train,y_test = train_test_split( X, y, test_size=0.2, random_state=42 )","60993b07":"model = keras.Sequential([\n    layers.BatchNormalization(input_shape = (40,)),\n    layers.Dense(100, activation = 'relu'),\n    layers.Dropout(0.2),\n    \n    layers.BatchNormalization(),\n    layers.Dense(200, activation = 'relu'),\n    layers.Dropout(0.2),\n    \n    layers.BatchNormalization(),\n    layers.Dense(100, activation = 'relu'),\n    layers.Dropout(0.2),\n    \n    layers.BatchNormalization(),\n    layers.Dense(1, activation = 'sigmoid'),\n    \n])","3dd48f1d":"model.compile(\n    optimizer = 'adam',\n    loss = 'binary_crossentropy',\n    metrics = ['binary_accuracy']\n)","2974b891":"early_stopping = keras.callbacks.EarlyStopping(\n    monitor = 'val_loss',\n    patience = 5,\n    min_delta = 0.001,\n    restore_best_weights = True,\n)","5b017ced":"num_batch_size = 50\nnum_epochs = 200\n\nstart = datetime.now()\n\nhistory = model.fit(\n    X_train, y_train, \n    batch_size = num_batch_size, \n    epochs = num_epochs, \n    validation_data = (X_test, y_test), \n    callbacks = [ early_stopping ], \n)\n\nduration = datetime.now() - start\nprint(\"Training Time :\", duration)","edbc5412":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\nhistory_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")","33979625":"testpath = '\/kaggle\/input\/moroccan-darija-trigger-word-classification-ed-2\/data\/test\/'\n\ntest_audio_files = []\n\nextracted_features_test_df = []\n\nfor index_num,row in tqdm.tqdm(metadata_test.iterrows()):\n    file_name = os.path.join(testpath, row['id'] + '.wav')\n    test_audio_files.append(file_name)\n    data = features_extractor(file_name)\n    extracted_features_test_df.append(data)","cd6d0cd9":"test_X = np.array(extracted_features_test_df)","769aedd9":"test_X[0]","6a9bc98a":"y_pred = model.predict(test_X)\ny_pred","4a82df17":"IPython.display.Audio(test_audio_files[2])","9de7b326":"metadata_test","f851ebcd":"## Get the classes\n\npredictions = list(map(lambda x: 1 if x>= 0.5 else 0, y_pred))\n\nsubmissions = {\n    'id' : metadata_test['id'].tolist(),\n    'label' : predictions\n}\n\nsubmissions_df = pd.DataFrame.from_dict(submissions)\n\nsubmissions_df","dcf9e97b":"submissions_df.to_csv('\/kaggle\/working\/out\/submission.csv', index = False)","1c032c29":"# Exploratory Data Analysis","f41ebde1":"The `metatadata_train` contains records of the audio filenames labeled with 1 or 0. The label 1 means the word \"safi7bess\" and 0 the word \"yallahbda\" ","e47f78af":"# Predicting","01fb27b5":"# Modeling ","86e236b2":"## Data Augmentation \n\nBy changing the pitch","52c0bb6e":"# Preparing the data"}}