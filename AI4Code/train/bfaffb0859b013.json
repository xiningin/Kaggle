{"cell_type":{"4ad123c0":"code","f564fcb7":"code","8d79b459":"code","54779e00":"code","a80281e1":"code","f0c461cf":"code","70e48c2a":"code","cbc85ccd":"code","54e8426a":"code","ba338f95":"code","7f329c6a":"code","f96666c9":"code","171f3736":"code","7120b243":"code","f76c9a05":"code","cc7293a2":"code","7a304e7c":"code","9d929c52":"code","e1c1fdd5":"code","3f0e4f14":"code","074cb759":"code","7f5ac156":"code","4ed9f846":"code","9f26fcfa":"code","a1760370":"code","f482536b":"code","18ac664c":"code","acc7e39d":"code","1497f5fa":"code","06cd1598":"code","fac1564a":"code","5070bcdb":"code","16d1fe9d":"code","4674801e":"code","a0078238":"code","a64db638":"code","1d24941d":"code","75901b91":"code","626ba24f":"code","15c7d91f":"markdown","b305fc17":"markdown","cc174259":"markdown","f976dcd9":"markdown","98498a7a":"markdown","ad964aef":"markdown","23712c6d":"markdown","a828f1b4":"markdown","69dbad86":"markdown","c45da27f":"markdown","427ee924":"markdown","1b8ebbc3":"markdown","71c0de74":"markdown","81706458":"markdown","1984bd7a":"markdown","a4d3de14":"markdown","ffec5440":"markdown","6c293cbb":"markdown","aad0d432":"markdown","f98cc6b6":"markdown","3b586b97":"markdown","7a377355":"markdown","35228434":"markdown","276ffb5e":"markdown","d15e618c":"markdown","bdf6e661":"markdown","cd7ac934":"markdown","6dc216bd":"markdown","d6f5e96a":"markdown","29115d7b":"markdown","ed96d982":"markdown","64feae62":"markdown","4700a7d8":"markdown","50c5d2a8":"markdown","dea91e5b":"markdown","1247aff4":"markdown"},"source":{"4ad123c0":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport re\nimport warnings\nfrom statistics import mode\nwarnings.filterwarnings('ignore')\nplt.style.use('fivethirtyeight')\nfrom copy import deepcopy","f564fcb7":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","8d79b459":"train.head()","54779e00":"plt.style.use('seaborn')\nplt.figure(figsize=(10,5))\nsns.heatmap(train.isnull(), yticklabels = False, cmap='plasma')\nplt.title('Null Values in Training Set');","a80281e1":"train.drop(columns=['Cabin', 'Name', 'Ticket'], inplace=True)\ntest.drop(columns=['Cabin', 'Name', 'Ticket'], inplace=True)","f0c461cf":"train.head()","70e48c2a":"test.head()","cbc85ccd":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.countplot(train.Survived)\nplt.title('Number of passengers Survived');\n\nplt.subplot(1,2,2)\nsns.countplot(x='Survived', hue='Pclass', data=train)\nplt.title('Number of passengers Survived');","54e8426a":"pclass1 = train[train.Pclass == 1]['Survived'].value_counts(normalize=True).values[0]*100\npclass2 = train[train.Pclass == 2]['Survived'].value_counts(normalize=True).values[1]*100\npclass3 = train[train.Pclass == 3]['Survived'].value_counts(normalize=True).values[1]*100\n\n\nprint(\"Pclass-1: {:.1f}% People Survived\".format(pclass1))\nprint(\"Pclass-2: {:.1f}% People Survived\".format(pclass2))\nprint(\"Pclass-3: {:.1f}% People Survived\".format(pclass3))","ba338f95":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.countplot(train.Survived)\nplt.title('Number of passengers Survived');\n\nplt.subplot(1,2,2)\nsns.countplot(x='Survived', hue='Sex', data=train)\nplt.title('Number of passengers Survived');","7f329c6a":"train['Age'].hist(bins=40)\nplt.title('Age Distribution');","f96666c9":"# set plot size\nplt.figure(figsize=(15, 3))\n\n# plot a univariate distribution of Age observations \nsns.distplot(train[(train[\"Age\"] > 0)].Age, kde_kws={\"lw\": 3}, bins = 50)\n\n# set titles and labels\nplt.title('Distrubution of passengers age',fontsize= 14)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\n# clean layout\nplt.tight_layout()","171f3736":"plt.figure(figsize=(15,5))\n\n#Draw a box plot to show Age distributions with respect to survival status\nsns.boxplot(y='Survived', x='Age', data=train, palette=[\"#3f3e6fd1\", \"#85c6a9\"], fliersize = 0, orient = 'h')\n\n#Add a scatterplot for each category\nsns.stripplot(y='Survived', x='Age', data=train, palette=[\"#3f3e6fd1\", \"#85c6a9\"], linewidth = 0.6, orient = 'h')\n\nplt.yticks(np.arange(2), ['Drowned', 'Survived'])\nplt.title('Age distribution grouped by surviving status')\nplt.ylabel('Surviving status')\nplt.tight_layout()","7120b243":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.countplot(train['SibSp'])\nplt.title('Number of siblings\/spouses aboard');\n\nplt.subplot(1,2,2)\nsns.countplot(x='Survived', hue='SibSp', data=train)\nplt.legend(loc='right')\nplt.title('Number of siblings\/spouses aboard');","f76c9a05":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.countplot(train['Parch'])\nplt.title('Number of parents\/children aboard');\n\nplt.subplot(1,2,2)\nsns.countplot(x='Survived', hue='Parch', data=train)\nplt.legend(loc='right')\nplt.title('Number of parents\/children aboard');","cc7293a2":"# set plot size\nplt.figure(figsize=(15, 3))\n\n# plot a univariate distribution of Age observations \nsns.distplot(train[(train[\"Fare\"] > 0)].Fare, kde_kws={\"lw\": 3}, bins = 50)\n\n# set titles and labels\nplt.title('Distrubution of fare',fontsize= 14)\nplt.xlabel('Fare')\nplt.ylabel('Frequency')\n# clean layout\nplt.tight_layout()","7a304e7c":"plt.figure(figsize=(15,5))\n\n#Draw a box plot to show Age distributions with respect to survival status\nsns.boxplot(y='Survived', x='Fare', data=train, palette=[\"#3f3e6fd1\", \"#85c6a9\"], fliersize = 0, orient = 'h')\n\n#Add a scatterplot for each category\nsns.stripplot(y='Survived', x='Fare', data=train, palette=[\"#3f3e6fd1\", \"#85c6a9\"], linewidth = 0.6, orient = 'h')\n\nplt.yticks(np.arange(2), ['Drowned', 'Survived'])\nplt.title('Fare distribution grouped by surviving status')\nplt.ylabel('Surviving status')\nplt.tight_layout()","9d929c52":"plt.figure(figsize=(15,5))\nplt.subplot(1,2,1)\nsns.countplot(train['Embarked'])\nplt.title('Name of Port of embarkation')\n\nplt.subplot(1,2,2)\nsns.countplot(x='Survived', hue='Embarked', data=train)\nplt.legend(loc='right')\nplt.title('Name of passenger Survived');","e1c1fdd5":"embark1 = train[train.Embarked == 'S']['Survived'].value_counts(normalize=True).values[1]*100\nembark2 = train[train.Embarked == 'C']['Survived'].value_counts(normalize=True).values[0]*100\nembark3 = train[train.Embarked == 'Q']['Survived'].value_counts(normalize=True).values[1]*100\n\n\nprint(\"S: {:.1f}% People Survived\".format(embark1))\nprint(\"C: {:.1f}% People Survived\".format(embark2))\nprint(\"Q: {:.1f}% People Survived\".format(embark3))","3f0e4f14":"sns.heatmap(train.corr(), annot=True);","074cb759":"train.loc[train.Age.isnull(), 'Age'] = train.groupby('Pclass').Age.transform('median')\ntest.loc[test.Age.isnull(), 'Age'] = test.groupby('Pclass').Age.transform('median')","7f5ac156":"train.Embarked.value_counts()","4ed9f846":"train['Embarked'] = train['Embarked'].fillna(mode(train['Embarked']))\ntest['Embarked'] = test['Embarked'].fillna(mode(test['Embarked']))","9f26fcfa":"train.loc[train.Fare.isnull(), 'Fare'] = train.groupby('Pclass').Fare.transform('median')\ntest.loc[test.Fare.isnull(), 'Fare'] = test.groupby('Pclass').Fare.transform('median')\n","a1760370":"train['Sex'][train['Sex']=='male'] = 0\ntrain['Sex'][train['Sex']=='female'] = 1\n\ntest['Sex'][test['Sex']=='male'] = 0\ntest['Sex'][test['Sex']=='female'] = 1","f482536b":"from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder()\ntemp = pd.DataFrame(encoder.fit_transform(train[['Embarked']]).toarray(), columns=['S', 'C', 'Q'])\ntrain = train.join(temp)\ntrain.drop(columns='Embarked', inplace=True)\n\ntemp = pd.DataFrame(encoder.transform(test[['Embarked']]).toarray(), columns=['S', 'C', 'Q'])\ntest = test.join(temp)\ntest.drop(columns='Embarked', inplace=True)","18ac664c":"train.head()","acc7e39d":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train.drop(['Survived', 'PassengerId'], axis=1), train['Survived'], test_size = 0.2, random_state=2)","1497f5fa":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\n\n# We must apply the scaling to the test set that we computed for the training set\nX_test_scaled = scaler.transform(X_test)","06cd1598":"from sklearn.ensemble import RandomForestClassifier\nrfclf = RandomForestClassifier(random_state=2)","fac1564a":"# Set our parameter grid\nparam_grid = { \n    'criterion' : ['gini', 'entropy'],\n    'n_estimators': [300, 400],\n    'max_features': ['auto', 'log2'],\n    'max_depth' : [6, 7]    \n}","5070bcdb":"from sklearn.model_selection import GridSearchCV\n\nrandomForest_CV = GridSearchCV(estimator = rfclf, param_grid = param_grid, cv = 5)\nrandomForest_CV.fit(X_train, y_train)\n\nrandomForest_CV.best_params_","16d1fe9d":"rf_clf = RandomForestClassifier(random_state = 2, criterion = 'entropy', max_depth = 7, max_features = 'auto', n_estimators = 400)\n\nrf_clf.fit(X_train, y_train)","4674801e":"predictions = rf_clf.predict(X_test)","a0078238":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, predictions) * 100","a64db638":"scaler = MinMaxScaler()\n\ntrain_conv = scaler.fit_transform(train.drop(['Survived', 'PassengerId'], axis=1))\ntest_conv = scaler.transform(test.drop(['PassengerId'], axis = 1))","1d24941d":"rf_clf = RandomForestClassifier(random_state = 2, criterion = 'entropy', max_depth = 7, max_features = 'auto', n_estimators = 400)\n\nrf_clf.fit(train_conv, train['Survived'])","75901b91":"test2 = deepcopy(test)\n\ntest2['Survived'] = rf_clf.predict(test_conv)","626ba24f":"test2[['PassengerId', 'Survived']].to_csv('MySubmissionRandomForest.csv', index = False)","15c7d91f":"**Age column has a non-uniform data and many outliers.**\n\n**Outlier:** An outlier is an observation that lies an abnormal distance from other values in a random sample from a population. ","b305fc17":"Passengers with no parents or children on board were more likely to drown. \n\n*Conclusion: Parch is a relevant information to decide whether the passenger will survive of not.* ","cc174259":"Concerning the port of embarcation, we will encode the data with OneHotEncoder technique.","f976dcd9":"## Number of Siblings\/Spouses aboard","98498a7a":"## Scale the data","ad964aef":"I will use the Random Forest algorithm for this classification problem.","23712c6d":"# Training the model","a828f1b4":"## Pclass","69dbad86":"## Sex","c45da27f":"## Number of parents\/children aboard","427ee924":"Cabin data has to much null values to be interesting. It would not make any sense to replace these null values since they are too numerous. Let's just ignore this column!","1b8ebbc3":"As maximum values in train set is 'S', let's replace null values by 'S'.","71c0de74":"Now, we just need to replace Sex and Embarked values by numbers in order to use it correctly.\n\nConcerning the sex, we can replace 'male' by 0 and 'female' by 1.","81706458":"Passengers with no sibling or spouse on board were more likely to drown. \n\n*Conclusion: SibSp is a relevant information to decide whether the passenger will survive of not.* ","1984bd7a":"## Age","a4d3de14":"# Exploratory Data Analysis (EDA)","ffec5440":"It seems that third class passengers were a lot more likely to die than the other passengers. On the contrary, first class passengers were more likely to survive.\n\n*Conclusion: Pclass is a relevant information to decide whether the passenger will survive of not.* ","6c293cbb":"Let's visualize the importance of the different parameters for the survival of the passengers.","aad0d432":"Passengers who embarked in Cherbourg seemed more likely to survive!\n\n*Conclusion: Embarked is a relevant information to decide whether the passenger will survive of not.* ","f98cc6b6":"## Fare","3b586b97":"Firstly, we need to replace the null values in the Age column.\n\nAs we saw in the correlation heatmap, Age was most correlated with Pclass (in absolute value). So we will replace missing age values with median age for the passenger's Pclass.","7a377355":"The higher the fare, the more likely to survive was the passenger!\n\n*Conclusion: Fare is a relevant information to decide whether the passenger will survive of not.* ","35228434":"It seems that younger passengers had a slightly better chance of surviving than the older ones.\n\n*Conclusion: Age seems to have a slight influence on the survival of the passenger.* ","276ffb5e":"The 'Name' column does not seem interesting as well since it will be difficult to analyse it in order to determine the influence of the passenger's name on his survival.\n\nIt is the same for the 'Ticket' column.\n\nLet's just get rid of these columns to clear the data as early as possible!","d15e618c":"# Submitting the solution","bdf6e661":"# Data treatment","cd7ac934":"## Hyperparameter Tuning\n\nBelow, we set the hyperparameter grid with 4 lists of values:\n\n'criterion': A function which measures the quality of a split.\n'n_estimators': The number of trees of our random forest.\n'max_features': The number of features to choose when looking for the best way of splitting.\n'max_depth': the maximul depth of a decision tree.","6dc216bd":"## Correlation Heatmap","d6f5e96a":"Fare was most correlated with Pclass, so we will replace missing values of Fare by the median fare for the passenger's Pclass.","29115d7b":"| Variable name | Description |\n| --- | --- |\n| PassengerId | Survived (1) or died (0) |\n| Pclass | Passenger's class |\n| Name | Passenger's name |\n| Sex | Passenger's sex |\n| Age | Passenger's age |\n| SibSp | Number of siblings\/spouses aboard |\n| Parch | Number of parents\/children aboard |\n| Ticket | Ticket number |\n| Fare | Fare |\n| Cabin | Cabin |\n| Embarked | Port of embarcation |","ed96d982":"# Notebook for the Titanic Competition\n\nI will use the Random Forest Model in this challenge. If you have any suggestion, leave a comment!\n\n\n## *Summary:*\n* Exploratory Data Analysis (EDA)\n* Data treatment (handling missing values, cleaning data)\n* Training the model\n* Submitting the solution","64feae62":"This heatmap allows us to easily spot the correlations between the different columns.\n\nFor example, there is a strong negative correlation between Pclass avec Fare. That was expected since first class passengers usually pay a higher fare than third class ones.","4700a7d8":"## Port of embarcation","50c5d2a8":"It looks like women were a lot more likely to survive the accident than men.\n\n*Conclusion: Sex is a relevant information to decide whether the passenger will survive of not.* ","dea91e5b":"Let's first visualize null values on our training set on graph.","1247aff4":"**Dataset is completely ready now!**"}}