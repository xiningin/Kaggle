{"cell_type":{"a4ad0ce3":"code","85b307b8":"code","0294cd98":"code","a4e8e2b9":"code","3338024f":"code","6dfd0dd9":"code","15afc185":"code","a027f2ce":"code","8e5c156c":"code","23248c5b":"code","fa5d26c3":"code","6202fc42":"code","b84f64ab":"code","e7bcabfd":"code","46ff6767":"code","87c85efb":"code","ee789b1d":"code","96fc72ca":"code","c6282e8c":"code","0a3c1d43":"code","568b3a35":"code","eeba8021":"code","a1183466":"code","29808102":"code","65c150bf":"code","8337fba5":"code","b0c82aef":"code","860e94af":"code","8c6901fc":"code","f86918d8":"code","2295aa3c":"code","051c2066":"code","b7712957":"code","a7e4d5f6":"code","89edecb7":"code","57cc7bde":"code","ee1afe61":"code","56134659":"code","a58b6dec":"code","6ff8987d":"code","17c729e0":"code","5bd770f8":"code","3e3ec19b":"code","fa69530e":"markdown","93271650":"markdown","88603c95":"markdown","2463ee8f":"markdown","5381052c":"markdown","d20a7854":"markdown","e7446760":"markdown","164b272e":"markdown","16d4571f":"markdown","178433d8":"markdown","2c801025":"markdown","376c5d5f":"markdown","dcab37fc":"markdown","4fdb4f41":"markdown","6eac1d3b":"markdown"},"source":{"a4ad0ce3":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport ipywidgets as widgets\nfrom sklearn.preprocessing import StandardScaler\nimport gc\nfrom pathlib import Path","85b307b8":"# Start with input file path\ninput_file_path = Path('\/kaggle\/input\/mlb-player-digital-engagement-forecasting\/')\n\n\n# Create table with list of CSV files to be read in, w\/ corresponding df name\n# This does include large 'train' data set (read in separately)\ncsv_and_df_names = pd.DataFrame(data = {\n  'csv_name': ['seasons', 'teams', 'players', 'awards'],\n  'df_name': ['seasons', 'teams', 'players', 'awards_pre2018'] \n  })\n\n# Set up for tabbed output\nkaggle_data_tabs = widgets.Tab()\n\n# Add Output widgets for each (eventual) DF as tabs' children\nkaggle_data_tabs.children = list([widgets.Output() for df_name \n  in csv_and_df_names['df_name']])\n\nfor index, row in csv_and_df_names.iterrows():\n    \n    csv_name = row['csv_name']\n    df_name = row['df_name']\n    \n    # Read from CSV and create df with specified name in environment\n    globals()[df_name] = pd.read_csv(input_file_path \/ f\"{csv_name}.csv\")\n\n    # Set tab title to df name\n    kaggle_data_tabs.set_title(index, df_name)\n    \n    # Display corresponding table output for this tab name\n    with kaggle_data_tabs.children[index]:\n        display(eval(df_name))\n\ndisplay(kaggle_data_tabs)","0294cd98":"train = pd.read_csv(input_file_path \/'train.csv')\n\n# Convert training data date field to pandas datetime type\ntrain['date'] = pd.to_datetime(train['date'], format = \"%Y%m%d\")\n\ndisplay(train.info())\n\ndisplay(train)","a4e8e2b9":"# Get names of all \"nested\" data frames in daily training set\ndaily_data_nested_df_names = train.drop('date', axis = 1).columns.values.tolist()\n\nfor df_name in daily_data_nested_df_names:\n    date_nested_table = train[['date', df_name]]\n\n    date_nested_table = (date_nested_table[\n      ~pd.isna(date_nested_table[df_name])\n      ].\n      reset_index(drop = True)\n      )\n    \n    daily_dfs_collection = []\n    \n    for date_index, date_row in date_nested_table.iterrows():\n        daily_df = pd.read_json(date_row[df_name])\n        \n        daily_df['dailyDataDate'] = date_row['date']\n        \n        daily_dfs_collection = daily_dfs_collection + [daily_df]\n\n    # Concatenate all daily dfs into single df for each row\n    unnested_table = (pd.concat(daily_dfs_collection,\n      ignore_index = True).\n      # Set and reset index to move 'dailyDataDate' to front of df\n      set_index('dailyDataDate').\n      reset_index()\n      )\n    \n    # Creates 1 pandas df per unnested df from daily data read in, with same name\n    globals()[df_name] = unnested_table    \n    \n    # Clean up tables and collection of daily data frames for this df\n    del(date_nested_table, daily_dfs_collection, unnested_table)\n\n# Set up for tabbed output\ndaily_data_unnested_tabs = widgets.Tab()\n\n# Add Output widgets for each (eventual) DF as tabs' children\ndaily_data_unnested_tabs.children = list([widgets.Output() \n  for df_name in daily_data_nested_df_names])\n\nfor index in range(0, len(daily_data_nested_df_names)):\n    df_name = daily_data_nested_df_names[index]\n    \n    # Rename tab bar titles to df names\n    daily_data_unnested_tabs.set_title(index, df_name)\n\n    # Display corresponding table output for this tab name\n    with daily_data_unnested_tabs.children[index]:\n        display(eval(df_name))\n\ndisplay(daily_data_unnested_tabs)","3338024f":"del(train)\n\ngc.collect()","6dfd0dd9":"plt.figure(figsize=(8,6))\ncor = nextDayPlayerEngagement[['target1','target2','target3','target4']].corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","15afc185":"player_eng_info = nextDayPlayerEngagement.copy()\nplayer_eng_info['target1To4Avg'] = np.mean(\n  player_eng_info[['target1', 'target2', 'target3', 'target4']],\n  axis = 1)","a027f2ce":"player_eng_info = player_eng_info[player_eng_info['dailyDataDate'] >='2018-03-29']\nplayer_eng_info = pd.merge(\n  player_eng_info,\n  playerBoxScores[['dailyDataDate','playerId','gamePk','teamId', 'playerName', 'runsScored', 'atBats', 'homeRuns','flyOuts','hits','strikes',\n                   'balks','errors','chances','rbi']],\n   on = ['dailyDataDate','playerId'],\n   how = 'inner'\n   )\n","8e5c156c":"player_eng_info.head()","23248c5b":"plt.figure(figsize=(10,8))\ncor = player_eng_info[['target1To4Avg','runsScored','atBats','homeRuns','flyOuts','hits','strikes',\n                   'balks','errors','chances','rbi']].corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","fa5d26c3":"standings_stats = pd.merge(\n  player_eng_info,\n  standings[['dailyDataDate','teamId','wins','losses','pct','xWinLossPct','divisionRank',\n             'leagueRank','wildCardRank','lastTenWins','lastTenLosses']],\n   on = ['dailyDataDate','teamId'],\n   how = 'inner'\n   )","6202fc42":"plt.figure(figsize=(8,6))\ncor = standings_stats[['target1To4Avg','wins','losses','pct','xWinLossPct','divisionRank',\n                       'leagueRank','wildCardRank','lastTenWins','lastTenLosses']].corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","b84f64ab":"averaged_data = standings_stats.groupby('dailyDataDate', as_index=True)[['target1To4Avg','runsScored','atBats','homeRuns','flyOuts','hits','strikes',\n                   'balks','errors','chances','rbi','pct','xWinLossPct','divisionRank','leagueRank','wildCardRank','lastTenWins','lastTenLosses']].mean()","e7bcabfd":"averaged_data.head()","46ff6767":"averaged_data[['target1To4Avg','strikes']].plot()\nplt.show()","87c85efb":"averaged_data['atBats'] = averaged_data['atBats']*10","ee789b1d":"averaged_data[['target1To4Avg','atBats']].plot()\nplt.show()","96fc72ca":"sns.distplot(averaged_data['xWinLossPct'])\nplt.show()","c6282e8c":"averaged_data['xWinLossPct'] = averaged_data['xWinLossPct']*50","0a3c1d43":"averaged_data[['target1To4Avg','xWinLossPct']].plot()\nplt.show()","568b3a35":"plt.figure(figsize=(12,10))\ncor = averaged_data[['target1To4Avg','runsScored','atBats','homeRuns','hits',\n        'balks','chances','rbi','pct','xWinLossPct','divisionRank','leagueRank','wildCardRank','lastTenWins','lastTenLosses']].corr()\nsns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\nplt.show()","eeba8021":"averaged_data['divisionRank'] = averaged_data['divisionRank']*10","a1183466":"averaged_data[['target1To4Avg','divisionRank']].plot()\nplt.show()","29808102":"averaged_data['pct'] = averaged_data['pct']*50","65c150bf":"averaged_data[['target1To4Avg','pct']].plot()\nplt.show()","8337fba5":"final_data = standings_stats.drop(['engagementMetricsDate','target1To4Avg'],axis=1)\n\nfinal_data = pd.merge(\n  final_data,\n  awards[['dailyDataDate','awardName','playerId']],\n   on = ['dailyDataDate','playerId'],\n   how = 'left'\n   )\n\nfinal_data = final_data.fillna(0)\n\nfinal_data['awardName'] = [1 if x!=0 else 0 for x in final_data['awardName'] ]\n\nfinal_data = pd.merge(\n  final_data,\n  playerTwitterFollowers[['dailyDataDate','numberOfFollowers','playerId']],\n   on = ['dailyDataDate','playerId'],\n   how = 'left'\n   )\n\nfinal_data = pd.merge(\n  final_data,\n  teamTwitterFollowers[['dailyDataDate','numberOfFollowers','teamId']],\n   on = ['dailyDataDate','teamId'],\n   how = 'left'\n   )\n\nfinal_data = pd.merge(\n  final_data,\n  games[['dailyDataDate','gamePk','isTie','gamesInSeries','seriesDescription','homeWinPct','awayWinPct','homeId','awayId']],\n   on = ['dailyDataDate','gamePk'],\n   how = 'left'\n   )\n\nfinal_data['pct_diff'] = (final_data['homeWinPct'] - final_data['awayWinPct']).abs()\n\nfinal_data = pd.merge(\n  final_data,\n  standings[['dailyDataDate','teamId','divisionRank', 'leagueRank','wildCardRank']],\n   left_on = ['dailyDataDate','homeId'],\n   right_on= ['dailyDataDate','teamId'],\n   how = 'left'\n   )\n\nfinal_data = pd.merge(\n  final_data,\n  standings[['dailyDataDate','teamId','divisionRank', 'leagueRank','wildCardRank']],\n   left_on = ['dailyDataDate','awayId'],\n   right_on= ['dailyDataDate','teamId'],\n   how = 'left'\n   )\n\nfinal_data = final_data.rename(columns={'divisionRank_x': 'player_divisionRank', 'divisionRank_y': 'home_divisionRank', \n                                       'divisionRank' : 'away_divisionRank'})\nfinal_data = final_data.rename(columns={'leagueRank_x': 'player_leagueRank', 'leagueRank_y': 'home_leagueRank', \n                                       'leagueRank' : 'away_leagueRank'})\nfinal_data = final_data.rename(columns={'wildCardRank_x': 'player_wildCardRank', 'wildCardRank_y': 'home_wildCardRank', \n                                       'wildCardRank' : 'away_wildCardRank'})\n\nfinal_data['divisionRank_diff'] = (final_data['home_divisionRank'] - final_data['away_divisionRank']).abs()\nfinal_data['leagueRank_diff'] = (final_data['home_leagueRank'] - final_data['away_leagueRank']).abs()\nfinal_data['wildCardRank_diff'] = (final_data['home_wildCardRank'] - final_data['away_wildCardRank']).abs()\n\nfinal_data = final_data.drop(['playerName','homeId', 'awayId'],axis=1)\nfinal_data = final_data.drop(['seriesDescription'],axis=1)\nfinal_data = final_data.drop(['teamId_x','teamId_y', 'teamId'],axis=1)\n","b0c82aef":"data = final_data.copy()\ndata = pd.merge(\n  data,\n  playerBoxScores[['dailyDataDate','playerId','assists', 'balls', 'baseOnBalls',\n       'baseOnBallsPitching', 'battersFaced', 'battingOrder', 'blownSaves',\n       'catchersInterference', 'catchersInterferencePitching',\n       'caughtStealing', 'caughtStealingPitching',\n       'completeGamesPitching', 'doubles', 'doublesPitching', 'earnedRuns','totalBases', 'triples', 'triplesPitching', 'wildPitches',\n       'winsPitching']],\n   on = ['dailyDataDate','playerId'],\n   how = 'left'\n   )","860e94af":"data.shape","8c6901fc":"data = data.drop(['gamePk'],axis=1)","f86918d8":"data = data.fillna(0)\nfeature_columns = [x for x in data.columns[7:]]\ntarget_columns = [x for x in data.columns[2:6]]\ndata[feature_columns] = data[feature_columns].astype(np.float32)\n\ndata = data.fillna(0)","2295aa3c":"def remove_outliers(data):\n    Q1 = data.quantile(0.25)\n    Q3 = data.quantile(0.75)\n    IQR = Q3 - Q1\n    data = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]\n    \nremove_outliers(data[feature_columns])","051c2066":"def log_transform(data,feature_columns):\n    for x in feature_columns:\n        data[x] = np.log10(data[x] + 1)","b7712957":"from sklearn.model_selection import train_test_split            \nx_train, x_test, y_train, y_test = train_test_split(data[feature_columns],data[target_columns],test_size=0.2, random_state=42)","a7e4d5f6":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","89edecb7":"x_train.shape","57cc7bde":"y_train.iloc[:,1]","ee1afe61":"'''from sklearn.ensemble import GradientBoostingRegressor\ngb = GradientBoostingRegressor()\ngb.fit(x_train,y_train.iloc[:,1])\ngb.score(x_train,y_train.iloc[:,1])'''","56134659":"from tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense\nfrom keras.layers import Dense, Conv1D, Flatten\nfrom keras import backend as K\n\n#_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n#_test=x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n\nmodel = Sequential()\nmodel.add(Dense(64,input_dim=55, kernel_initializer='he_uniform', activation='relu'))\n#odel.add(Conv1D(32,16,activation=\"relu\", input_shape=(59, 1)))\n#odel.add(Flatten())\nmodel.add(Dense(32, activation=\"relu\"))\nmodel.add(Dense(16,activation=\"relu\"))\nmodel.add(Dense(32, activation=\"relu\"))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation='linear'))\n\nmodel.compile(loss='mae', optimizer='sgd',metrics=['mae'])\n#K.set_value(model.optimizer.learning_rate, 0.001)\n\nhistory = model.fit(x_train, y_train, epochs=50,batch_size=100, verbose=1, validation_data=(x_test,y_test))","a58b6dec":"print(history.history.keys())\n# \"Loss\"\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","6ff8987d":"import mlb\n\nenv = mlb.make_env() # initialize the environment\niter_test = env.iter_test() # iterator which loops over each date in test set\n\n#target_columns = ['target1', 'target2', 'target3', 'target4']\n\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    test_df = test_df.reset_index().rename(columns = {'index':'date'})\n    sample_prediction_df = sample_prediction_df.reset_index()\n    sample_prediction_df = sample_prediction_df.rename(columns={'date':'ddate'})\n    sample_prediction_df['date'] = pd.to_datetime(sample_prediction_df['ddate'], format='%Y%m%d')\n    sample_prediction_df['playerId'] = sample_prediction_df['date_playerId'].apply(lambda x: x.split('_')[1]).astype(int)\n\n    #games\n    \n    games_nested_table = test_df[['date','games']]\n    games_nested_table = (games_nested_table.reset_index(drop = True))\n    games_test = [] \n    for date_index, date_row in games_nested_table.iterrows():\n        daily_df = pd.read_json(date_row['games'])   \n        daily_df['date'] = date_row['date']\n        games_test = games_test + [daily_df] \n        \n    games_test = (pd.concat(games_test,\n      ignore_index = True).\n      reset_index()\n      )\n    #games_test['date'] = sample_prediction_df['date']\n    games_test = games_test[['date','gamePk','isTie','gamesInSeries','seriesDescription',\n                             'homeWinPct','awayWinPct','homeId','awayId']]\n    \n    #players\n    \n    players_nested_table = test_df[['date','playerBoxScores']]\n    players_nested_table = (players_nested_table.reset_index(drop = True))\n    players_test = []    \n    for date_index, date_row in players_nested_table.iterrows():\n        daily_df = pd.read_json(date_row['playerBoxScores'])  \n        daily_df['date'] = date_row['date']\n        players_test = players_test + [daily_df]   \n    players_test = (pd.concat(players_test,\n      ignore_index = True).\n      reset_index()\n      )\n    #players_test['date'] = sample_prediction_df['date']\n    players_test = players_test[['date','playerId','gamePk','teamId','runsScored', 'atBats', 'homeRuns',\n                             'flyOuts','hits','strikes','balks','errors','chances','rbi','assists', 'balls',\n       'baseOnBalls', 'baseOnBallsPitching', 'battersFaced', 'battingOrder',\n       'blownSaves', 'catchersInterference', 'catchersInterferencePitching',\n       'caughtStealing', 'caughtStealingPitching', 'completeGamesPitching',\n       'doubles', 'doublesPitching', 'earnedRuns', 'totalBases', 'triples',\n       'triplesPitching', 'wildPitches', 'winsPitching']]\n\n    \n    #standings\n    \n    \n    standings_nested_table = test_df[['date','standings']]\n    standings_nested_table = (standings_nested_table.reset_index(drop = True))\n    standings_test = [] \n    for date_index, date_row in standings_nested_table.iterrows():\n        daily_df = pd.read_json(date_row['standings']) \n        daily_df['date'] = date_row['date']\n        standings_test = standings_test + [daily_df]    \n    standings_test = (pd.concat(standings_test,\n      ignore_index = True).\n      reset_index()\n      )\n    #standings_test['date'] = sample_prediction_df['date']\n    standings_test = standings_test[['date','teamId','wins','losses','pct','xWinLossPct','divisionRank'\n             ,'leagueRank','wildCardRank','lastTenWins','lastTenLosses']]\n    \n    \n    players_test['date'] = pd.to_datetime(players_test['date'], format='%Y%m%d')\n    final_test4 = pd.merge(\n    sample_prediction_df,\n    players_test.drop_duplicates(subset=['date','playerId']),\n    on = ['playerId','date'],\n    how = 'left'\n    )\n\n\n    games_test['date'] = pd.to_datetime(games_test['date'], format='%Y%m%d')\n    final_test3 = pd.merge(\n    final_test4,\n    games_test,\n    on = ['date','gamePk'],\n    how = 'left'\n    )\n    \n    standings_test['date'] = pd.to_datetime(standings_test['date'], format='%Y%m%d')\n    final_test2 = pd.merge(\n    final_test3,\n    standings_test,\n    on = ['date','teamId'],\n    how = 'left'\n    )\n    \n    final_test1 = pd.merge(\n    final_test2,\n    standings_test[['date','teamId','divisionRank', 'leagueRank','wildCardRank']],\n    left_on = ['date','homeId'],\n    right_on= ['date','teamId'],\n    how = 'left'\n    )\n    \n    final_test = pd.merge(\n    final_test1,\n    standings_test[['date','teamId','divisionRank', 'leagueRank','wildCardRank']],\n    left_on = ['date','awayId'],\n    right_on= ['date','teamId'],\n    how = 'left'\n    )\n    \n    final_test = final_test.rename(columns={'divisionRank_x': 'player_divisionRank', 'divisionRank_y': 'home_divisionRank', \n                                       'divisionRank' : 'away_divisionRank'})\n    final_test = final_test.rename(columns={'leagueRank_x': 'player_leagueRank', 'leagueRank_y': 'home_leagueRank', \n                                       'leagueRank' : 'away_leagueRank'})\n    final_test = final_test.rename(columns={'wildCardRank_x': 'player_wildCardRank', 'wildCardRank_y': 'home_wildCardRank', \n                                       'wildCardRank' : 'away_wildCardRank'})\n\n    final_test['divisionRank_diff'] = (final_test['home_divisionRank'] - final_test['away_divisionRank']).abs()\n    final_test['leagueRank_diff'] = (final_test['home_leagueRank'] - final_test['away_leagueRank']).abs()\n    final_test['wildCardRank_diff'] = (final_test['home_wildCardRank'] - final_test['away_wildCardRank']).abs()\n    final_test['pct_diff'] = (final_test['homeWinPct'] - final_test['awayWinPct']).abs()\n    \n    final_test = final_test.drop(['awayId','teamId','homeId','playerId','gamePk'],axis=1)\n    final_test['numberOfFollowers_x'] = 0\n    final_test['numberOfFollowers_y'] = 0\n    final_test['awardName'] = 0\n    final_test = final_test.rename(columns={'chances' : 'chances_x'})\n    final_test = final_test.fillna(0)  \n    \n    cols = ['atBats',\n 'homeRuns',\n 'flyOuts',\n 'hits',\n 'strikes',\n 'balks',\n 'errors',\n 'chances_x',\n 'rbi',\n 'wins',\n 'losses',\n 'pct',\n 'xWinLossPct',\n 'player_divisionRank',\n 'player_leagueRank',\n 'player_wildCardRank',\n 'lastTenWins',\n 'lastTenLosses',\n 'awardName',\n 'numberOfFollowers_x',\n 'numberOfFollowers_y',\n 'isTie',\n 'gamesInSeries',\n 'homeWinPct',\n 'awayWinPct',\n 'pct_diff',\n 'home_divisionRank',\n 'home_leagueRank',\n 'home_wildCardRank',\n 'away_divisionRank',\n 'away_leagueRank','away_wildCardRank', 'divisionRank_diff','leagueRank_diff','wildCardRank_diff','assists','balls',\n 'baseOnBalls', 'baseOnBallsPitching','battersFaced','battingOrder','blownSaves',\n 'catchersInterference','catchersInterferencePitching','caughtStealing','caughtStealingPitching','completeGamesPitching','doubles',\n 'doublesPitching','earnedRuns','totalBases','triples', 'triplesPitching','wildPitches','winsPitching']\n    \n    final_test = final_test[cols]\n    \n    \n    final_test = sc.transform(final_test)\n    \n    final_test = final_test.astype(np.float32)\n    sample_prediction_df = sample_prediction_df.drop(['playerId'],axis=1)\n    sample_prediction_df = sample_prediction_df.set_index('date')\n    sample_prediction_df = sample_prediction_df.rename(columns={'ddate':'date'})\n    sample_prediction_df = sample_prediction_df[['date','date_playerId','target1', 'target2', 'target3', 'target4']]\n    sample_prediction_df = sample_prediction_df.drop(['date'],axis=1)\n    sample_prediction_df['target1'] = np.clip(model.predict(final_test)[:,0], 0, 100)\n    sample_prediction_df['target2'] = np.clip(model.predict(final_test)[:,1], 0, 100)\n    sample_prediction_df['target3'] = np.clip(model.predict(final_test)[:,2], 0, 100)\n    sample_prediction_df['target4'] = np.clip(model.predict(final_test)[:,3], 0, 100)\n    sample_prediction_df = sample_prediction_df.fillna(0.)\n    env.predict(sample_prediction_df)","17c729e0":"'''sample_prediction_df = sample_prediction_df.drop(['date'],axis=1)\nsample_prediction_df = sample_prediction_df.rename(columns={'ddate':'date'})\nsample_prediction_df = sample_prediction_df[['date','date_playerId','target1', 'target2', 'target3', 'target4']]\nsample_prediction_df = sample_prediction_df.drop(['date'],axis=1)'''","5bd770f8":"sample_prediction_df.head()","3e3ec19b":"#sample_prediction_df.to_csv('submission.csv',index=False)","fa69530e":"*note : There is some similarity in their behavior across time*","93271650":"**Plot Average of targets of all players for each day across time and compare it with average of strikes**","88603c95":"**Correlation between important stats from standings data and target**","2463ee8f":"*note : There are some features highly correlated with each other and we may choose only one from them and neglect the other*","5381052c":"**Relationship between important player-level stats with our target**","d20a7854":"*note : There is some similarity in their behavior across time*","e7446760":"**We can also see here that 'divisionRank' variable has completely opposite behavior compared to target across time **","164b272e":"**We see here that 'pct' variable has strong positive correlation with target variable after computing averages of them per every unique day**\n\n**'lastTenWins' variable has strong positive correlation with target and of course 'lastTenLosses' has negative correlation with target also**\n\n**Also 'divisionRank' variable has strong negative correlation with target**\n\n**'leagueRank' variable has strong negative correlation with target**\n\n**'wildCardRank' variable has strong negative correlation with target**\n\n\n*Before grouping data by unique days and computing averages of variables, the correlation between target and 'pct' was only **0.16** and was **-0.16** with 'divisionRank'*","16d4571f":"**Correlation matrix between them**","178433d8":"**Plot Average of targets of all players for each day across time and compare it with average of xWinLossPct**","2c801025":"**Plot Average of targets of all players for each day across time and compare it with average of atBats**","376c5d5f":"**Correlation between targets**","dcab37fc":"*note : There is some similarity in their behavior across time*","4fdb4f41":"**And here we see that 'Current winning percentage' or 'pct' variable has almost the same behavior as target**","6eac1d3b":"*Compute averagre of the four targets*"}}