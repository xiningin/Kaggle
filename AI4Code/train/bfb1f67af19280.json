{"cell_type":{"de2d7e22":"code","0e5bb32d":"code","8e427b8f":"code","a504766e":"code","b55af6b1":"code","d47e9759":"code","6ad66aad":"code","85302981":"code","90b0102e":"code","2ea01d5a":"code","c511f27e":"code","0a1d302e":"code","e5e819ed":"code","5dd64e3d":"code","d17890c5":"code","93f48811":"code","d2b5bf32":"code","7baf1c09":"code","c62a1e40":"code","c2edf49e":"code","e6a6eb8d":"code","ef656b81":"code","580320a9":"code","36f52652":"code","928221df":"code","2f4b61c2":"code","89ddb897":"code","a4e016e4":"code","63b37fd5":"code","4d6c8401":"code","f33ee1cd":"code","941be4ad":"code","273ec5b1":"code","e02f2955":"code","9937cb94":"code","a0a0fe29":"code","5e07b898":"code","786f6597":"code","a51449b7":"code","b59f771e":"code","cd0f29d5":"code","b51e4259":"code","07fa7543":"code","b7cb9b2c":"code","975488af":"markdown","4a8b538c":"markdown","b1771e87":"markdown","7a4a2ee9":"markdown","2daa579f":"markdown","8b28a36a":"markdown","114fd58d":"markdown","8ec93629":"markdown","2134ef5f":"markdown","2c1d4e79":"markdown"},"source":{"de2d7e22":"import pandas as pd\nimport nltk\nimport re\nimport string\n\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import defaultdict\nfrom collections import  Counter\n\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nimport string\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom keras.initializers import Constant\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\n\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nimport nltk\nfrom nltk.tokenize import word_tokenize,RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer","0e5bb32d":"train=pd.read_csv('..\/input\/traindata2\/train3.csv', delimiter=';',header= 'infer',encoding='utf-8')\ntest =pd.read_csv('..\/input\/ses-test-data\/out.csv',delimiter=';',header= 'infer', encoding='utf-8')\n\n","8e427b8f":"test","a504766e":"test.head()","b55af6b1":"train.head()","d47e9759":"test.info()","6ad66aad":"test.head()","85302981":"test.tail()","90b0102e":"# shape s\u00fctun ve sat\u0131rlar\u0131n say\u0131s\u0131n\u0131 verir\ntrain.shape","2ea01d5a":"test.describe()","c511f27e":"# creating a dict file  \nkonu = {'e\u011fitim': 1,'sa\u011fl\u0131k': 2} \n  \n# traversing through dataframe \n# konu column and writing \n# values where key matches \ntrain.konu = [konu[item] for item in train.konu] \nprint(train) \ntext = train.iloc[:,0]\nlabel = train.iloc[:,1]\nlabel = label.astype('int64')\nprint(\"text is: \",text)\nprint(\"label is: \",label)\nprint(\"type of text is: \", type(text))\nprint(\"type of label is: \", type(label))","0a1d302e":"train.cov()","e5e819ed":"import seaborn as sns\ncorr = train.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","5dd64e3d":"train.plot(x='text', y='konu', style='-')","d17890c5":"test.isnull().sum().sum()\ntrain.isnull().sum().sum()","93f48811":"#KONU \u00f6zniteli\u011fini \u00f6l\u00e7eklendirmek istiyoruz\nx = train[['konu']].values.astype(float)\n\n#\u00d6l\u00e7eklendirme i\u00e7in MinMaxScaler fonksiyonunu kullan\u0131yoruz.\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ntrain['konu2'] = pd.DataFrame(x_scaled)\n\ntrain","d2b5bf32":"#Quartile (Kartiller) ve IQR ile Ayk\u0131r\u0131 De\u011fer Tespiti\n\nimport seaborn as sns\nsns.boxplot(x=train['konu'])","7baf1c09":"test","c62a1e40":"#download stopwords (English) from NLTK\nnltk.download('stopwords')\nstop_words = nltk.corpus.stopwords.words('english')\n\n#word tokenization\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\n\n\n\n\ndef pre_process(txt):\n lowered_text = txt.lower() #lowercase\n  \n without_numbers = re.sub(r'\\d+','', lowered_text) #remove numbers\n without_punctuation = without_numbers.translate(str.maketrans('','',string.punctuation)) #remove punctuation\n word_tokens = word_tokenize(without_punctuation) #tokenize words\n processed_text = ' '.join([word for word in word_tokens if word not in stop_words]) #remove stop words\n return processed_text\n\n","c2edf49e":"test['text']=test['text'].apply(lambda x : pre_process(x))\ntrain['text']=train['text'].apply(lambda x : pre_process(x))\ntest","e6a6eb8d":"train","ef656b81":"count_vectorizer=CountVectorizer()\ntrain_cv=count_vectorizer.fit_transform(train[\"text\"])\ntest_cv=count_vectorizer.transform(test[\"text\"])\nprint(train_cv[0].todense())","580320a9":"from sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf=TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,2))\ntrain_tf=tfidf.fit_transform(train[\"text\"])\ntest_tf=tfidf.transform(test[\"text\"])\n","36f52652":"X_train_cv, X_test_cv, y_train_cv, y_test_cv =train_test_split(train_cv,train.konu,test_size=0.2,random_state=2020)","928221df":"from sklearn.model_selection import cross_val_score\ndef fit_and_predict(model,X_train,y_train,X_test,y_test):\n    \n    '''Input- model=model to be trained\n              X_train, y_train= traing data set\n              X_test,  y_test = testing data set\n       Output- Print accuracy of model for training and test data sets   \n    '''\n    \n    # Fitting a simple Logistic Regression on Counts\n    clf = model\n    clf.fit(X_train, y_train)\n    predictions=clf.predict(X_test)\n    confusion_matrix(y_test,predictions)\n    print(classification_report(y_test,predictions))\n   \n    print('-'*50)\n    print(\"{}\" .format(model))\n    print('-'*50)\n    print('Accuracy of classifier on training set:{}%'.format(round(clf.score(X_train, y_train)*100)))\n    print('-'*50)\n    print('Accuracy of classifier on test set:{}%' .format(round(accuracy_score(y_test,predictions)*100)))\n    print('-'*50)\n    \n  \n","2f4b61c2":"models=[LogisticRegression(C=1.0),SVC(),MultinomialNB(),DecisionTreeClassifier(),\n        KNeighborsClassifier(n_neighbors=5),RandomForestClassifier()]","89ddb897":"for model in models:\n    fit_and_predict(model,X_train_cv, y_train_cv,X_test_cv,y_test_cv)","a4e016e4":"X_train_tf, X_test_tf, y_train_tf, y_test_tf =train_test_split(train_tf,train.konu,test_size=0.2,random_state=2020)","63b37fd5":"# Loop through the list of models and use 'fit_and_predict()' function to train and make predictions on the TFDIF vectororized data\nfor model in models:\n    fit_and_predict(model,X_train_tf, y_train_tf,X_test_tf,y_test_tf)","4d6c8401":"clf_logreg = MultinomialNB()\nclf_logreg.fit(X_train_cv, y_train_cv)\npred=clf_logreg.predict(X_test_cv)\nconfusion_matrix(y_test_cv,pred)\nprint(classification_report(y_test_cv,pred))\nprint('Accuracy of classifier on training set:{}%'.format(round(clf_logreg.score(X_train_cv, y_train_cv)*100)))\nprint('Accuracy of classifier on test set:{}%' .format(round(accuracy_score(y_test_cv,pred)*100)))","f33ee1cd":"#feature extraction uses count vectorization method\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\ninput_data = vectorizer.fit_transform(text)\nprint(input_data)","941be4ad":"#build the model\nfrom sklearn.linear_model import LogisticRegression\nclf=LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\nclf.fit(input_data,label)","273ec5b1":"import numpy as np\nimport pandas as pd\n\nveri = np.array([[\"LogisticRegression\", \"%98\",\"%100\"],[\"SVC\", \"%98\",\"%100\"],[\"MultinomialNB\", \"%98\",\"%100\"],[\"DecisionTreeClassifier\", \"%98\",\"%75\"],[\"KNeighborsClassifier\", \"%92\",\"%100\"],[\"RandomForestClassifier\", \"%98\",\"%100\"]])\nsutun_isimleri = ['model','training set', ' test set']\nveriseti = pd.DataFrame(data=veri, columns=sutun_isimleri)\nprint(veriseti)","e02f2955":"def predictionOutput(sentence):\n    prediction = clf.predict(vectorizer.transform([pre_process(sentence)]))\n    if(prediction[0] == 1):\n        print(\"Bu text egitim ile akalaki\")\n    elif (prediction[0] == 2):\n        print(\"Bu text saglik ile alakali\")\n \n","9937cb94":"predictionOutput(\"sa\u011fl\u0131kl\u0131 olmak i\u00e7in bol bol su i\u00e7melisin\")","a0a0fe29":"array = train.values\nX = array[:,0:1]\ny = array[:,2]\nX_train_tf, X_test_tf, y_train_tf, y_test_tf =train_test_split(train_tf,train.konu,test_size=0.2,random_state=2020)\ny","5e07b898":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n#Decision Trees\ncellTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nprint(cellTree) # it shows the default parameters\n  #I fit the data with the training\ncellTree.fit(X_train_tf,y_train_tf)\n  #now predictions\nyhat_dt = cellTree.predict(X_test_tf)\n\n  #Accuracy evaluation\nacc = metrics.accuracy_score(y_test_tf, yhat_dt)\nprint('karar agaci icin accuracy: ',acc)\n\n#karar agaci icin confusion matrix ve metrik degerler\ncellTree_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_dt = cross_val_score(cellTree_dt, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_dt)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_dt)))\nfrom sklearn.metrics import classification_report\nprec_dt = classification_report(yhat_dt,y_test_tf)\nprint(prec_dt)","786f6597":"from sklearn.neighbors import KNeighborsClassifier\nknn_model = KNeighborsClassifier(n_neighbors = 3)\n# fit the models\nneigh = knn_model.fit(X_train_tf,y_train_tf)\n#predict the mode;\nyhatknn=neigh.predict(X_test_tf)\n\n  #Accuracy evaluation\naccknn = metrics.accuracy_score(y_test_tf, yhatknn)\nprint('en yakin komsular icin accuracy',accknn)\n\n#knn=3 icin confusion matrix ve metrik degerler\nknn_knn = KNeighborsClassifier(n_neighbors = 3)\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_knn = cross_val_score(knn_knn, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_knn)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_knn)))\n\n#knn scores\nfrom sklearn.metrics import classification_report\nprec_knn = classification_report(yhatknn,y_test_tf)\nprint(prec_knn)","a51449b7":"#lojistik regresyon\nfrom sklearn.linear_model import LogisticRegression\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train_tf,y_train_tf)\nLR\n#predict\nyhatlr = LR.predict(X_test_tf)\n#print('yhat', yhat)\n  #Accuracy evaluation\nacclr = metrics.accuracy_score(y_test_tf, yhatlr)\nprint('lojistik regresyon icin accuracy',acclr)\n\n\n#lojistik regresyon icin confusion matrix ve metrik degerler\nlr_lr = LogisticRegression(C=0.01, solver='liblinear')\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_lr = cross_val_score(lr_lr, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_lr)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_lr)))\n\n\nfrom sklearn.metrics import classification_report\nprec_lr = classification_report(yhatlr,y_test_tf)\nprint(prec_lr)","b59f771e":"#SVM \nfrom sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit((X_train_tf,y_train_tf) \n#predict\nyhatsvm = clf.predict(X_test_tf)\n#yhat [0:5]\naccsvm = metrics.accuracy_score(y_test_tf, yhatsvm)\nprint('svm icin accuracy',accsvm)\n\n\n\n#svm icin confusion matrix ve metrik degerler\nclf_svm = svm.SVC(kernel='rbf')\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_svm = cross_val_score(clf_svm, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_svm)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_svm)))\n\n\nfrom sklearn.metrics import classification_report\nprec_svm = classification_report(yhatsvm,y_test_tf)\nprint(prec_svm)","cd0f29d5":"#gaussian NB \n# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n#call the models\ngnb = GaussianNB()\n  #fit the model\ngnb.fit(X_train_tf,y_train_tf) \n  #predict\nyhatgnb = gnb.predict(X_test_tf)\naccgnb = metrics.accuracy_score(y_test_tf, yhatgnb)\nprint('gaussian naive bayes icin accuracy',accgnb)\n\n\n#gaussian naive bayes icin confusion matrix ve metrik degerler\nclf_gnb = GaussianNB()\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_gnb = cross_val_score(clf_gnb, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_gnb)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_gnb)))\n\n#klasifikasyon tablosu\nfrom sklearn.metrics import classification_report\nprec_gnb = classification_report(yhatgnb,y_test_tf)\nprint(prec_gnb)","b51e4259":"#linear discriminant analysis \nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nlda = LinearDiscriminantAnalysis()\n#fit the model\nlda.fit(X_train_tf,y_train_tf) \n#predict\nyhatlda = lda.predict(X_test_tf)\nacclda = metrics.accuracy_score(y_test_tf, yhatlda)\nprint('linear discriminant analiz icin accuracy',acclda)\n\n\n\n\n#linear discrimant icin confusion matrix ve metrik degerler\nclf_ld = LinearDiscriminantAnalysis()\n#train model with cv of 10 burda modeli 10 cross validasyon ile scorelari verdik\ncv_scores_ld = cross_val_score(clf_ld, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores_ld)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores_ld)))\n\n#klasifikasyon linear diskrimannt\nfrom sklearn.metrics import classification_report\nprec_lda = classification_report(yhatlda,y_test_tf)\nprint(prec_lda)","07fa7543":"# RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nrfc = RandomForestClassifier(max_depth=5, n_estimators=100, max_features='auto')\nrfc.fit(X_train_tf,y_train_tf) \n#predict\nyhat1 = rfc.predict(X_test_tf)\n#yhat [0:5]\n#evaluate\n\n#create a new SVM model\nrfc_cv = RandomForestClassifier(max_depth=5, n_estimators=100, max_features='auto')\n#train model with cv of 10\ncv_scores = cross_val_score(rfc_cv, X,y, cv=10)\n#print each cv score (accuracy) and average them\nprint(cv_scores)\nprint('cv_scores mean:{}'.format(np.mean(cv_scores)))\n\n\n\n\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport itertools\nfrom sklearn.metrics import f1_score\nprint('f1_score for Random Forest Classifier:',f1_score(y_test_tf, yhat1, average='weighted'))\n#print(\"Train set Accuracy for Random Forest Classifier: \", metrics.accuracy_score(Y_validation, rfc.predict(X_train)))\n#print(\"Test set Accuracy for Random Forest Classifier: \", metrics.accuracy_score(Y_validation, yhat1))\nfrom sklearn.metrics import classification_report\nprec_rec = classification_report(yhat1,y_test_tf)\nprint(prec_rec)","b7cb9b2c":"basar\u0131m = np.array([[\"LogisticRegression\", \"0.75\"],[\"DecisionTreeClassifier\", \"0.87\"],[\"KNeighborsClassifier\", \"0.87\"],[\"RandomForestClassifier\", \"0.93\"]])\nsutun_isimleri = ['model','accuracy']\nbasar\u0131mdrm = pd.DataFrame(data=basar\u0131m, columns=sutun_isimleri)\nprint(basar\u0131mdrm)","975488af":"Text pre-processing;\n\n* convert to lower case\n* remove numbers\n* remove punctuation\n* remove stopwords","4a8b538c":"Veriyi \u00d6l\u00e7eklendirme (Scaling) ve Normalize Etme (Normalization)\n\nVeri \u00f6l\u00e7eklendirme ve normalize etme ad\u0131mlar\u0131 birbirlerine benzer i\u015fler gibi g\u00f6r\u00fcnseler de (hatta birbirleri yerine kullan\u0131lsalar da) uygulanma \u015fekilleri farkl\u0131d\u0131r. \u00d6l\u00e7eklendirme i\u015fleminde elimizdeki verinin sadece aral\u0131\u011f\u0131n\u0131 (range) de\u011fi\u015ftirirken (\u00f6rne\u011fin 0\u20131 aras\u0131 ya da 1\u2013100 aras\u0131 gibi), veriyi normalize etme s\u00fcrecinde verinin da\u011f\u0131l\u0131m\u0131n\u0131 normal bir da\u011f\u0131l\u0131m olarak de\u011fi\u015ftiriyoruz.\n","b1771e87":"text ile konu aras\u0131ndaki ili\u015fkiyi basit\u00e7e \u00e7izdirerek, mevcut durumu g\u00f6rmek istersek a\u015fa\u011f\u0131daki gibi kod par\u00e7as\u0131n\u0131 kullanabiliriz.","7a4a2ee9":"predictionOutput(\"Bu konu saglik ve doktor ile alakali\")","2daa579f":"Kategorik De\u011ferleri D\u00f6n\u00fc\u015ft\u00fcrme (Label \/ One-hot Encoding)\n\nBilgisayar bilimlerinde kategorik verilerle \u00e7al\u0131\u015fmak, hesaplama ve bilgisayar\u0131n bu de\u011ferleri anlamas\u0131 a\u00e7\u0131s\u0131ndan zorluklar i\u00e7erir. \u00d6zellikle makine \u00f6\u011frenmesi modellerinin do\u011fru \u00e7al\u0131\u015fabilmesi i\u00e7in kategorik verileri, say\u0131sal kar\u015f\u0131l\u0131klar\u0131na (temsillerine) d\u00f6n\u00fc\u015ft\u00fcrmemiz gerekmektedir.\n\nLabel Encoder\n\nElimizdeki verileri direk say\u0131sal temsillerine d\u00f6n\u00fc\u015ft\u00fcrmeye yarar ve kategorik her veriye say\u0131sal bir de\u011fer atar. Genelde sadece iki de\u011fere sahip \u00f6zniteliklerde kullan\u0131l\u0131r. \n\u2022\te\u011fitim de\u011ferleri \u21921\n\u2022\tsa\u011fl\u0131k de\u011ferleri \u2192 0\nBu d\u00f6n\u00fc\u015f\u00fcm\u00fc ger\u00e7ekle\u015ftirmek i\u00e7in preprocessing k\u00fct\u00fcphanesi alt\u0131nda yer alan LabelEncoder s\u0131n\u0131f\u0131n\u0131 kullanan a\u015fa\u011f\u0131daki kod sat\u0131rlar\u0131n\u0131 \u00e7al\u0131\u015ft\u0131rabiliriz\n","8b28a36a":"Korelasyon G\u00f6sterim\n\u0130ki veya daha fazla ba\u011f\u0131ms\u0131z de\u011fi\u015fken (\u00f6znitelik)aras\u0131ndaki ili\u015fkinin varl\u0131\u011f\u0131, bu ili\u015fkinin y\u00f6n\u00fc ve \u015fiddeti korelasyon analizi ve sonucunda elde edilen korelasyon katsay\u0131s\u0131 ile belirlenir.\n\nDe\u011fi\u015fkenler (\u00f6znitelikler) aras\u0131ndaki korelasyon katsay\u0131s\u0131 de\u011ferlerini g\u00f6sterirken en \u00e7ok kullan\u0131lan y\u00f6ntemlerden birisi de \u0131s\u0131 haritas\u0131 ile g\u00f6rselle\u015ftirme yapmakt\u0131r. seaborn paketinde yer alan heatmap() fonksiyonu a\u015fa\u011f\u0131daki gibi kullan\u0131larak de\u011fi\u015fkenler aras\u0131ndaki korelasyon de\u011ferleri \u0131s\u0131 haritas\u0131 \u00fczerinde g\u00f6r\u00fclebilir.\n\nIs\u0131 haritas\u0131 grafi\u011fi, negatif y\u00f6nl\u00fc ili\u015fkinin \u015fiddeti artt\u0131k\u00e7a rengin koyula\u015ft\u0131\u011f\u0131n\u0131, pozitif y\u00f6nl\u00fc ili\u015fkinin \u015fiddeti artt\u0131k\u00e7a rengin krem rengine do\u011fru a\u00e7\u0131ld\u0131\u011f\u0131n\u0131 ifade etmektedir.","114fd58d":"predictionOutput(\"Bu konu spor sporcunun dostu\")","8ec93629":"Verimizde toplam ka\u00e7 h\u00fccrede eksik veri vard\u0131r sorusunun cevab\u0131n\u0131 \u00f6\u011frenmemiz gerekir","2134ef5f":"**KOVARYAN G\u00d6STER\u0130M\u0130**\n\nVeri k\u00fcmesinde yer alan t\u00fcm \u00f6znitelikler aras\u0131ndaki kovaryans de\u011ferlerini i\u00e7eren matris a\u015fa\u011f\u0131daki kod par\u00e7as\u0131yla hesaplanabilir.\n","2c1d4e79":"Farkl\u0131 algoritmalar i\u00e7in ba\u015fa bela olabilen ayk\u0131r\u0131 de\u011ferleri her zaman k\u00f6t\u00fclemek ve veriden \u00e7\u0131karaca\u011f\u0131m\u0131z\u0131 d\u00fc\u015f\u00fcnmek do\u011fru bir yakla\u015f\u0131m de\u011fildir. Bazen tek amac\u0131m\u0131z bu de\u011ferleri bulmak hatta bunlar\u0131 gruplayarak, (yapabilirsek) s\u00fcre\u00e7 ya da olay bazl\u0131 bu durumlar\u0131n\u0131 analiz etmektir."}}