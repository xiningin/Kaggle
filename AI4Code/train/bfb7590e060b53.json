{"cell_type":{"a96815e6":"code","e75cd3ab":"code","3c6b02af":"code","3439bf67":"code","dd6757d9":"code","a0166608":"code","e533407d":"code","6ca178c0":"code","2901aa3a":"code","181606e6":"code","fdca8ae6":"code","a5229562":"code","301866a8":"code","2272aa4a":"code","0b97b995":"code","5ce5b81c":"code","bd1465a5":"code","4fe45c41":"markdown"},"source":{"a96815e6":"import math                      # providing access to the mathematical functions defined by the C standard\nimport matplotlib.pyplot as plt  # plotting library\nimport scipy                     # scientific computnig and technical computing\nimport cv2                       # working with, mainly resizing, images\nimport numpy as np               # dealing with arrays\nimport glob                      # return a possibly-empty list of path names that match pathname\nimport os                        # dealing with directories\nimport pandas as pd              # providing data structures and data analysis tools\nimport tensorflow as tf       \nimport itertools\nimport random\nfrom random import shuffle       # mixing up or currently ordered data that might lead our network astray in training.\nfrom tqdm import tqdm            # a nice pretty percentage bar for tasks. Thanks to viewer Daniel B\u00fchler for this suggestion\nfrom PIL import Image\nfrom scipy import ndimage\nfrom pathlib import Path\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn import metrics\n%matplotlib inline\nnp.random.seed(1)","e75cd3ab":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping","3c6b02af":"train_dir = Path('..\/input\/training\/training\/')\ntest_dir = Path('..\/input\/validation\/validation\/')","3439bf67":"#label info\ncols = ['Label','Latin Name', 'Common Name','Train Images', 'Validation Images']\nlabels = pd.read_csv(\"..\/input\/monkey_labels.txt\", names=cols, skiprows=1)\nlabels","dd6757d9":"labels = labels['Common Name']\nlabels","a0166608":"def image_show(num_image,label):\n    for i in range(num_image):\n        imgdir = Path('..\/input\/training\/training\/' + label)\n        #print(imgdir)\n        imgfile = random.choice(os.listdir(imgdir))\n        #print(imgfile)\n        img = cv2.imread('..\/input\/training\/training\/'+ label +'\/'+ imgfile)\n       # print(img.shape)\n        #print(label)\n        plt.figure(i)\n        plt.imshow(img)\n        plt.title(imgfile)\n    plt.show()","e533407d":"print(labels[4])\nimage_show(3,'n4')","6ca178c0":"LR = 1e-3\nheight=150\nwidth=150\nchannels=3\nseed=1337\nbatch_size = 64\nnum_classes = 10\nepochs = 200\ndata_augmentation = True\nnum_predictions = 20\n\n# Training generator\ntrain_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, \n                                                    target_size=(height,width),\n                                                    batch_size=batch_size,\n                                                    seed=seed,\n                                                    shuffle=True,\n                                                    class_mode='categorical')\n\n# Test generator\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = test_datagen.flow_from_directory(test_dir, \n                                                  target_size=(height,width), \n                                                  batch_size=batch_size,\n                                                  seed=seed,\n                                                  shuffle=False,\n                                                  class_mode='categorical')\n\ntrain_num = train_generator.samples\nvalidation_num = validation_generator.samples ","2901aa3a":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))","181606e6":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['acc'])\nmodel.summary()","fdca8ae6":"filepath=str(os.getcwd()+\"\/model.h5f\")\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n# = EarlyStopping(monitor='val_acc', patience=15)\ncallbacks_list = [checkpoint]#, stopper]","a5229562":"history = model.fit_generator(train_generator,\n                              steps_per_epoch= train_num \/\/ batch_size,\n                              epochs=epochs,\n                              validation_data=train_generator,\n                              validation_steps= validation_num \/\/ batch_size,\n                              callbacks=callbacks_list, \n                              verbose = 1\n                             )","301866a8":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\n\nplt.show()","2272aa4a":"def plot_confusion_matrix(cm, target_names,title='Confusion matrix',cmap=None,normalize=False):\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n    plt.figure(figsize=(10, 8))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float32') \/ cm.sum(axis=1)\n        cm = np.round(cm,2)\n        \n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel(\"Predicted label\\naccuracy={:0.4f}\\n misclass={:0.4f}\".format(accuracy, misclass))\n    plt.show()","0b97b995":"from keras.models import load_model\nmodel_trained = load_model(filepath)\n# Predict the values from the validation dataset\nY_pred = model_trained.predict_generator(validation_generator, validation_num \/\/ batch_size+1)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred, axis = 1)\n# Convert validation observations to one hot vectors\n#Y_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true = validation_generator.classes,y_pred = Y_pred_classes)\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, normalize=True, target_names=labels)","5ce5b81c":"print(metrics.classification_report(validation_generator.classes, Y_pred_classes,target_names=labels))","bd1465a5":"test_list = os.listdir(\"..\/input\/test-monkeys\/\")\ntest_list.sort()\nprint(test_list)\nmodel_test = load_model(filepath)","4fe45c41":"The model needs to be compiled before training can start. As our loss function, we use logloss which is called ''categorical_crossentropy\" in Keras. Metrics is only used for evaluation. As optimizer, we could have used ordinary stochastic gradient descent (SGD), but Adam is faster."}}