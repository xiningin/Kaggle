{"cell_type":{"6903368f":"code","88b4c52a":"code","aee8c99a":"code","b18b22e6":"code","47b6bf5f":"code","1acc7d01":"code","7b7c731a":"code","92db25ab":"code","bad0c502":"code","fcf006cc":"code","741e50c3":"code","83ecbab9":"code","8ac7d803":"code","7a021033":"code","b4ee7cb8":"code","bd93b6fe":"code","e1e80328":"code","7943a07b":"code","458db6a0":"code","a3d9b2c3":"code","ce8bfa86":"code","32f8aada":"code","9e803e3a":"markdown","36d84d18":"markdown","e26e471d":"markdown","2efaa38c":"markdown","7bf54702":"markdown","0dae88c2":"markdown","286ef18e":"markdown","ace32cd1":"markdown","10154b01":"markdown","e940025c":"markdown","d22aaa7f":"markdown","1b47ca2b":"markdown","5b124955":"markdown","68f15e04":"markdown","1dc79bdf":"markdown","d0057f46":"markdown","d84cc6cf":"markdown","6d227333":"markdown","739fc3e3":"markdown","05c1a4b0":"markdown","0fc27692":"markdown","34cabcfa":"markdown","c8e624d7":"markdown","d9c56a0c":"markdown","41de87b5":"markdown","b42904e5":"markdown","c32fd24e":"markdown","12596703":"markdown","e06a032d":"markdown","65b3df2d":"markdown","ceba0b5a":"markdown","dcd391d4":"markdown","4de983dd":"markdown","7b4a5f25":"markdown","488a8651":"markdown","da42df63":"markdown","ceff8574":"markdown","b47ae79d":"markdown","234c489f":"markdown","32d8d0cb":"markdown","db9bae99":"markdown"},"source":{"6903368f":"import pandas as pd\npd.set_option('display.max_columns', None)\n# pd.set_option('display.max_rows', None)\npd.set_option('display.width', 500)\n# \u00e7\u0131kt\u0131n\u0131n tek bir sat\u0131rda olmas\u0131n\u0131 sa\u011flar.\npd.set_option('display.expand_frame_repr', False)\nfrom mlxtend.frequent_patterns import apriori, association_rules","88b4c52a":"def load_onlineretail(path):\n    df = pd.read_csv(path)\n    return (df)\n\ndf = load_onlineretail(\"..\/input\/online-retail-ii-uci\/online_retail_II.csv\")\ndf.head()","aee8c99a":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\ndef retail_data_prep(dataframe):\n    dataframe.dropna(inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe = dataframe[dataframe[\"Price\"] > 0]\n    dataframe.drop(dataframe[dataframe[\"StockCode\"] == \"POST\"].index, inplace=True)\n    replace_with_thresholds(dataframe, \"Quantity\")\n    replace_with_thresholds(dataframe, \"Price\")\n    return dataframe\n\ndf = retail_data_prep(df)\n\ndf.head()","b18b22e6":"df_gr = df[df['Country'] == \"Germany\"]","47b6bf5f":"df_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).head(20)","1acc7d01":"df_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().iloc[0:5, 0:5]","7b7c731a":"df_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().fillna(0).iloc[0:5, 0:5]","92db25ab":"df_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().fillna(0).applymap(\n    lambda x: 1 if x > 0 else 0).iloc[0:5, 0:5]","bad0c502":"def check_id(dataframe, stock_code):\n    product_name = dataframe[dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0].tolist()\n    print(product_name)\n\n\ncheck_id(dataframe=df_gr, stock_code=\"15036\")","fcf006cc":"def create_invoice_product_df(dataframe, id=False):\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n\ngr_inv_pro_df = create_invoice_product_df(df_gr, id=True)\n\ngr_inv_pro_df.head()","741e50c3":"frequent_itemsets = apriori(gr_inv_pro_df, min_support=0.01, use_colnames=True)","83ecbab9":"frequent_itemsets.sort_values(\"support\", ascending=False).head(5)","8ac7d803":"rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\nrules.sort_values(\"support\", ascending=False).head()","7a021033":"#Lets observe the relatinship between the product number 20719 and 22326 \n\n\ncheck_id(dataframe=df_gr, stock_code=\"20719\")\ncheck_id(dataframe=df_gr, stock_code=\"22326\")","b4ee7cb8":"rules.sort_values(\"lift\", ascending=False).head(10)","bd93b6fe":"check_id(dataframe=df_gr, stock_code=\"21242\")\ncheck_id(dataframe=df_gr, stock_code=\"21244\")\ncheck_id(dataframe=df_gr, stock_code=\"20674\")","e1e80328":"check_id(dataframe=df_gr, stock_code=\"20676\")\ncheck_id(dataframe=df_gr, stock_code=\"21245\")\ncheck_id(dataframe=df_gr, stock_code=\"21238\")\ncheck_id(dataframe=df_gr, stock_code=\"20675\")","7943a07b":"# StockID: 22492\n\nproduct_id = \"22492\"\ncheck_id(df_gr, product_id)","458db6a0":"sorted_rules = rules.sort_values(\"lift\", ascending=False)","a3d9b2c3":"recommendation_list = []\n\nfor i, product in enumerate(sorted_rules[\"antecedents\"]):\n    for j in list(product):\n        if j == product_id:\n            recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"])[0])\n\nrecommendation_list[0:3]","ce8bfa86":"check_id(df_gr, '22328')\n\ncheck_id(df_gr, '22556')\n\ncheck_id(df_gr, '22328')","32f8aada":"def arl_recommender(rules_df, product_id, rec_count=1):\n\n    sorted_rules = rules_df.sort_values(\"lift\", ascending=False)\n\n    recommendation_list = []\n\n    for i, product in sorted_rules[\"antecedents\"].items():\n        for j in list(product):\n            if j == product_id:\n                recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"]))\n\n    recommendation_list = list({item for item_list in recommendation_list for item in item_list})\n\n    return recommendation_list[:rec_count]","9e803e3a":"Association rules are a method used to examine whether there are significant correlations between items that occur simultaneously and frequently, and to present the significant correlations determined through certain rules.","36d84d18":"# Lift\n\nIt is the strength of any rule, which can be defined as below formula:\n\n![image.png](attachment:045c8729-b370-49ad-b49d-f6147351198c.png)\n\nIt is the ratio of the observed support measure and expected support if X and Y are independent of each other. \n\nIf the lift value of two products is 1, it means that there is no relationship between these products. If the lift value is greater than 1, it means that these products are more likely to be purchased together.","e26e471d":"# Association Rule Learning","2efaa38c":"# 2.1 - Invoice Product Matrix","7bf54702":"For example, if the customer has the following product in his shopping cart","0dae88c2":"# Apriori Algorithm","286ef18e":"The product we will recommend to our user who buys the above product will be as follows. We look at the antecedent column, which shows the products purchased. indexes are also i.","ace32cd1":"# 4 - Suggesting a Product to Users at the Basket Stage","10154b01":"# Support\n\nSupport is the frequency of A or how frequently an item appears in the dataset. It is defined as the fraction of the transaction T that contains the itemset X. If there are X datasets, then for transactions T, it can be written as:\n\n![image.png](attachment:3076f7be-4782-47c5-aeae-d8f52016e219.png)","e940025c":"We aim to recommend these products to this customer, whatever the products that are most purchased and added to the cart with this product.\n","d22aaa7f":"Association rules are used to reveal products that are related to each other and to determine the relationship between them. \n\nFor example, if the relationships between the products are revealed in a market, the shelves can be arranged according to these rules. If we detect that the customer who buys product A tends to products B and C, we can place B and C products on nearby shelves. Campaigns and various sales strategies can be developed between product A and B.\n\nMarket basket analysis shows which product combinations are preferred most frequently in orders. It allows stores to better understand customer preferences and ultimately serve them better by predicting their customers' purchasing behavior. For example, a customer who buys bread is more likely to buy butter, while a customer who buys diapers is also more likely to buy products such as wet wipes and baby food.\n\nStores that successfully apply the market basket analysis can increase the amount of sales by positioning the products on the most suitable shelves and determining the discounts according to the results of this analysis.","1b47ca2b":"The name of the Apriori Algorithm means \"prior\" as it obtains the information from the previous step. Apriori Algorithm has been developed especially for data mining studies on very large-scale databases. It is an algorithm used in general association rule inference. The purpose of the algorithm is to reveal the connection between the rows in the databases.\n\nThe algorithm uses the bottom-up approach as a structure and examines one element at a time and tries to reveal the relationship between this element and the other candidates.\n\nIn addition, it is possible to liken the operation of the algorithm for each element to a search algorithm. In this sense, the algorithm is in the structure of Breadth-First Search.\n\nAssociation Rules work on the basis of if\/then statements. These statements help to reveal associations between independent data in a database, relational database or other information repositories. These rules are used to identify the relationships between the objects which are usually used together.\n\nThe two primary patterns that association rules use are support and confidence. The method finds similarities and rules formed by decomposing data for often used if\/then patterns. Association rules are normally used to satisfy a user-specified minimum support and a use- specified minimum resolution simultaneously. There are various algorithms that are used to implement association rule learning.","5b124955":"# Confidence\n\nConfidence indicates how often the rule has been found to be true. Or how often the items X and Y occur together in the dataset when the occurrence of X is already given. It is the ratio of the transaction that contains X and Y to the number of records that contain X.\n\n![image.png](attachment:7595c6a9-ad3c-43a8-af00-985a4f01deab.png)","68f15e04":"# 1 - Preparing The Data Set","1dc79bdf":"While choosing the algorithm, the algorithm with the highest performance is preferred depending on the most important factor data type. Among the algorithms developed for association rules analysis, Apriori and FP-Growth algorithms are generally preferred in studies.","d0057f46":"[1] https:\/\/www.kdnuggets.com\/2019\/12\/market-basket-analysis.html\n\n[2] Mueller, A. (1998). Fast sequential and parallel algorithms for association rule mining: A comparison.\n\n[3] Kumbhare, T. A., & Chobe, S. V. (2014). An overview of association rule mining algorithms. International Journal of Computer Science and Information Technologies, 5(1), 927-930.\n\n[4] Yadav, C., Wang, S., & Kumar, M. (2013, July). An approach to improve apriori algorithm based on association rule mining. In 2013 Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT) (pp. 1-9). IEEE.","d84cc6cf":"# 2 - Apriori Coding","6d227333":"For example, the purchase of 21242 and 21244, 20674 triples increases the probability of purchasing the other 4 products 85 times.","739fc3e3":"![image.png](attachment:0c789d62-c51e-41c1-8c79-603346ef02e2.png)","05c1a4b0":"Probability of only WOODLAND CHARLOTTE BAG appearing in the whole basket = 0.171242\n\nProbability of showing only ROUND SNACK BOXES ,SET4, WOODLAND in the whole basket = 0.271895\n\nProbability of WOODLAND CHARLOTTE BAG and ROUND SNACK BOXES ,SET4, WOODLAND appearing in the whole basket = 0.086275\n\nProbability of getting ROUND SNACK BOXES ,SET4, WOODLAND when WOODLAND CHARLOTTE BAG is purchased = 0.503817\n\nWe observe that when WOODLAND CHARLOTTE BAG is purchased, the probability of getting ROUND SNACK BOXES ,SET4, WOODLAND increases 1.852980 times.","0fc27692":"# REFERENCES","34cabcfa":"To create the Invoice Product Matrix, we first create the lines. Invoices are our baskets. We group the the previous baskets according to Invoice and then group by according to the description. In this way, we get the sum of the quantities in the invoices with the sum method, we also bring the information of how many of the relevant products are in a basket.","c8e624d7":"# Apriori Algorithm Steps\n\nStep-1: Determine the support of itemsets in the transactional database, and select the minimum support and confidence.\n\nStep-2: Take all supports in the transaction with higher support value than the minimum or selected support value.\n\nStep-3: Find all the rules of these subsets that have higher confidence value than the threshold or minimum confidence.\n\nStep-4: Sort the rules as the decreasing order of lift.","d9c56a0c":"![](https:\/\/www.striped-giraffe.com\/wp-content\/uploads\/2019\/05\/grocery-basket-analysis.jpg)","41de87b5":"However, the *Apriori Algorithm* wants the pivoted version of this table as input. To get the matrix we need, we need to take the pivot of it. We do that with the help of unstack method. Thus, we bring NAN expression for products that are not in the baskets but if there are, we bring the information of how many pieces are there.","b42904e5":"We have created the matrix we need, but we do not need long product names here. Instead, we need to write a function that will convert the Stock Code (ID) to the product name whenever we want them.","c32fd24e":"For this, first let's define a simple function that will check the IDs, when we enter the id we are interested in, it will bring us the product description.","12596703":"I use fillna method to write zero in cells that seem as NAN","e06a032d":"We created the **Invoice Product Matrix**, in other words the **Market Product Matrix.**","65b3df2d":"# 3 - Setting of Association Rules\n\nWe will calculate the probabilities of association of all possible products with a priori, with a minimum support value of 0.01. Normally, in real life, these support values are expected to be very low like here. Since this data set is a real data set, it is very normal for it to be so small.","ceba0b5a":"Now we have a nice table so that we can observe the baskets. However, how many of that product is in a basket is not our concern in this algorithm, so if there is one of that product in the basket, it will be enough for us to write 1. We are navigating all the cells with the applymap function. If it is greater than 0, we write 1, otherwise we say 0.","dcd391d4":"The functionalized version of the recommendation operation will be as follows:","4de983dd":"In order to find out interesting rules out of multiple possible rules from this small business scenario, we will be using the following matrices:\n\n \n**1. Support: Its the default popularity of an item. In mathematical terms, the support of item A is nothing but the ratio of transactions involving A to the total number of transactions.**\n\nSupport(Grapes) = (Transactions involving Grapes)\/(Total transaction)\n\nSupport(Grapes) = 0.666\n\n \n**2. Confidence: Likelihood that customer who bought both A and B. Its divides the number of transactions involving both A and B by the number of transactions involving B.**\n\nConfidence(A => B) = (Transactions involving both A and B)\/(Transactions involving only A)\n\nConfidence({Grapes, Apple} => {Mango}) = Support(Grapes, Apple, Mango)\/Support(Grapes, Apple)\n\n= 2\/6 \/ 3\/6\n\n= 0.667\n\n \n**3. Lift : Increase in the sale of A when you sell B.**\n\nLift(A => B) = Confidence(A, B) \/ Support(B)\n\nLift ({Grapes, Apple} => {Mango}) = 1\n\nSo, likelihood of a customer buying both A and B together is \u2018lift-value\u2019 times more than the chance if purchasing alone.\n\nLift (A => B) = 1 means that there is no correlation within the itemset.\nLift (A => B) > 1 means that there is a positive correlation within the itemset, i.e., products in the itemset, A, and B, are more likely to be bought together.\nLift (A => B) < 1 means that there is a negative correlation within the itemset, i.e., products in itemset, A, and B, are unlikely to be bought together.\n \nAssociation Rule-based algorithms are viewed as a two-step approach:\n\n**Frequent Itemset Generation:** Find all frequent item-sets with support >= pre-determined min_support count\n\n\n**Rule Generation:** List all Association Rules from frequent item-sets. Calculate Support and Confidence for all rules. Prune rules that fail min_support and min_confidence thresholds. \n[1]","7b4a5f25":"Association algorithms used to create rules are divided into 2 main groups as **sequential** and **parallel**.","488a8651":"We will use Online Retail dataset and suggest products to users at the basket stage.\n\nInvoiceNo: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'C', it indicates a cancellation.\n\nStockCode: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product.\n\nDescription: Product (item) name. Nominal.\n\nQuantity: The quantities of each product (item) per transaction. Numeric.\n\nInvoiceDate: Invice date and time. Numeric. The day and time when a transaction was generated.\n\nUnitPrice: Unit price. Numeric. Product price per unit in sterling (\u00a3).\n\nCustomer ID: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer.\n\nCountry: Country name. Nominal. The name of the country where a customer resides.","da42df63":"Let's select the transactions whose country field is Germany and prepare a model that will be specific to them.","ceff8574":"We assigned the association rule, which we gave the minimum threshold to ourselves, to the variable named frequent_itemset. We sort the frequent_itemset matrix we obtained according to the support metric.\n\nBelow is a probability value for all possible combinations. For example, the support value of the product numbered 22326 is 0.263625, the support value alone for the product numbered 22328 is 0.177778, and the probability of both being in a basket is the value of 0.142484 in the support column.\n\n\n\nWhen 22326 is purchased, the probability of obtaining 22328, that is, the '*confidence*' value, is calculated as 0.52403, and when 22326 is purchased, the probability of buying 22328 increases by 2.94 times (*lift*). *Lift* and *leverage* refer to similar situations. However, we will focus only on *lift*, as *Leverage* has a greater leverage effect for those with higher support, thus causing bias. *Conviction* is the expected frequency for antecedents without consequents.\n","b47ae79d":"![](https:\/\/derrickmartins.files.wordpress.com\/2015\/07\/picture1.png)","234c489f":"# 3.1 - Interpretation of Association Rules\n\n1. Antecendents: Item in basket\n\n2. Consequents: Product to be recommended in accordance with the antecendents.\n\n3. Antecendents Support: Support value for only the item in the basket.\n\n4. Consequents Support: Support value for only the the recommended product.\n\n5. Support: Probability that the product in the basket and the product to be recommended will appear in the basket together\n\n6. Confidence: Probability of buying the recommended product when the product in the cart is purchased\n\n7. Lift: Shows how many times the probability of buying the product to be recommended increases when the product in the basket is purchased.","32d8d0cb":"The libraries I will use for Association Rules Analysis on Python are the main libraries: mlxtend, pandas and numpy\n\nMLXTEND (Machine Learning Extensions)\nIn the MLXTEND module; classifier, cluster, regressor, evaluate, feature extraction&selection, frequent_patterns, general concepts, image, preprocessing, , math, plotting etc. extensions are included.","db9bae99":"We list the support values we bring in descending order. All possible product pairs in the dataset will be included in this matrix."}}