{"cell_type":{"9d86cf0a":"code","d2bdc15d":"code","243904d9":"code","66c15072":"code","620e7dae":"code","cf01ee9b":"code","bfcf3a20":"code","62025ecd":"code","c0f16ff3":"code","640b80a9":"code","2c5d49d3":"code","6550a00b":"code","47e67ded":"code","cf7458a2":"code","1ef1508c":"code","1fd56341":"code","6a96c3c2":"code","dbad2f8e":"code","4e01e4b1":"code","bb2c1c70":"markdown","a3191cd3":"markdown","cbd67bfd":"markdown","f3bffa33":"markdown","3b88a11f":"markdown","8298c1cb":"markdown","f198bf17":"markdown","e88b15fa":"markdown","8bd41227":"markdown","a2bb352c":"markdown"},"source":{"9d86cf0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d2bdc15d":"train = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/train.csv')","243904d9":"test = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/test.csv')","66c15072":"sample_sub = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/sample_submission.csv')","620e7dae":"from sklearn.model_selection import train_test_split\nX, y = train.drop(columns='label'), train.label\nX_train,X_val,y_train,y_val = train_test_split(X, y, test_size=0.2, random_state=42)\nX_train.shape, y_train.shape","cf01ee9b":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten\nfrom keras.layers import Activation, Dense, Dropout\nfrom keras.utils import to_categorical, model_to_dot, plot_model\nfrom keras.datasets import mnist\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import SVG\nnp.random.seed(42)","bfcf3a20":"import matplotlib.pyplot as plt\nimport matplotlib\nsome_digit = np.array(X_train.iloc[44,:])\nsome_digit_image = some_digit.reshape(28,28)\nplt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = 'nearest')\nplt.axis('off')\nplt.show()","62025ecd":"num_labels = len(np.unique(y_train))\nnum_labels","c0f16ff3":"y_train = to_categorical(y_train)\ny_val = to_categorical(y_val)\ny_train.shape, y_val.shape","640b80a9":"import math\nimage_size = int(math.sqrt(X_train.shape[1]))\nimage_size","2c5d49d3":"X_train = np.array(X_train)\nX_val = np.array(X_val)\nX_test = np.array(test.drop(columns='id'))\nX_train.shape","6550a00b":"# Resize\nX_train = np.reshape(X_train, [-1, image_size, image_size, 1])\nX_val = np.reshape(X_val, [-1, image_size, image_size, 1])\nX_test = np.reshape(X_test, [-1, image_size, image_size, 1])\n# Normalize\nX_train = X_train.astype('float32') \/ 255\nX_val = X_val.astype('float32') \/ 255\nX_test = X_test.astype('float32')\/255\nX_train.shape, X_val.shape","47e67ded":"input_shape = (image_size, image_size, 1)\nbatch_size = 128\nkernel_size = 3 \npool_size = 2\nfilters = 64\ndropout = 0.2","cf7458a2":"Model = Sequential()\nModel.add(Conv2D(filters = filters, kernel_size = kernel_size,\n                activation ='relu', input_shape = input_shape))\nModel.add(MaxPooling2D(pool_size))\nModel.add(Conv2D(filters = filters, kernel_size = kernel_size,\n                activation = 'relu'))\nModel.add(MaxPooling2D(pool_size))\nModel.add(Conv2D(filters = filters, kernel_size = kernel_size,\n                activation = 'relu'))\nModel.add(Flatten())\n# Dropout added as regularizer\nModel.add(Dropout(dropout))\n# Output layer is 10-dim one hot vector\nModel.add(Dense(num_labels))\nModel.add(Activation('softmax'))\nModel.summary()\n# loss function for one-hot vector # use of adam optimizer\n# accuracy is good metric for classification tasks \nModel.compile(loss='categorical_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy'])\nModel.fit(X_train, y_train, epochs=40, batch_size=batch_size)","1ef1508c":"_, acc = Model.evaluate(X_val,\n                        y_val,\n                        batch_size=batch_size,\n                        verbose=0)\nprint(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))","1fd56341":"result = Model.predict(X_test)\nresult.shape","6a96c3c2":"result = np.argmax(result,axis=1)","dbad2f8e":"sample_sub['label'] = result","4e01e4b1":"sample_sub.to_csv('submission.csv', index = False)","bb2c1c70":"**Evaluate Model**","a3191cd3":"**CNN parameter**","cbd67bfd":"**Model stack of CNN => ReLU => Maxpooling**","f3bffa33":"**Visualize some Digit**","3b88a11f":"**Read all Data**","8298c1cb":"**Resize and Normalize**","f198bf17":"**Calculate Image size**","e88b15fa":"**Predict**","8bd41227":"**Split to Train set and Test set**","a2bb352c":"**Convert to one hot vector**\n"}}