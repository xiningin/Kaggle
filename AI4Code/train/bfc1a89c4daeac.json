{"cell_type":{"6b722864":"code","4f6591c7":"code","9cf07e3b":"code","d8a5431a":"code","d6e3be85":"code","90db78be":"code","f4856c1f":"code","799b7ac5":"code","c9583b23":"code","e78937aa":"code","2c8fcf55":"code","bf2ac3fa":"code","41df348d":"code","a38414f9":"code","7c6d8544":"code","3ceb2bff":"code","2250cd97":"code","54aa1b42":"code","9c320be4":"code","cced8385":"code","0f0770b1":"markdown","94d35421":"markdown","85049e0c":"markdown","c267096c":"markdown","e03564f2":"markdown","070e4a47":"markdown","54ffc161":"markdown","f447652e":"markdown","1b494893":"markdown","07c5f096":"markdown"},"source":{"6b722864":"import pandas as pd\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import accuracy_score","4f6591c7":"df = pd.read_csv(\"..\/input\/mnist-in-csv\/mnist_test.csv\")","9cf07e3b":"df.shape","d8a5431a":"df_test = pd.read_csv(\"..\/input\/mnist-in-csv\/mnist_train.csv\")","d6e3be85":"inputs_test = np.ones([df_test.shape[0], df_test.shape[1]])\ninputs_test[:, 1:] = df_test.drop(['label'], axis = 1)\ny_test = np.array(df_test['label']).reshape(-1, 1)","90db78be":"np.random.seed(4)\n# number of input, hidden & output units\nn_input = df.shape[1] - 1\nn_hidden = 100\nn_output = len(df['label'].unique())\ninput_weights = np.random.randn(n_hidden, n_input+1)\nhidden_weights = np.random.randn(n_output, n_hidden+1)\nprint(input_weights.shape, hidden_weights.shape)","f4856c1f":"def sigmoid(z):\n    return 1.0 \/ (1.0 + np.exp(-z))","799b7ac5":"inputs = np.ones([df.shape[0], df.shape[1]])\ninputs[:, 1:] = df.drop(['label'], axis = 1)\ny = np.array(df['label']).reshape(-1, 1)","c9583b23":"def cost_function(initial_weights, n_input, n_hidden, n_output, X, y, lamb):\n    input_weights = np.reshape(initial_weights[:n_hidden * (n_input+1)], (n_hidden, n_input+1))\n    hidden_weights = np.reshape(initial_weights[(n_hidden * (n_input+1)):], (n_output, n_hidden+1))\n    #print(input_weights.shape, hidden_weights.shape)\n    \n    m = len(y)\n    y_mat = to_categorical(y)\n    \n    a1 = X\n    \n    z2 = np.dot(a1, input_weights.T)\n    a2 = np.ones([z2.shape[0], z2.shape[1]+1])\n    a2[:, 1:] = sigmoid(z2)\n    \n    z3 = np.dot(a2, hidden_weights.T)\n    a3 = sigmoid(z3)\n    \n    J = np.sum(np.dot(y_mat, np.log(a3).T) + np.dot((1-y_mat), np.log(1-a3).T))\/(-m) + (np.sum(input_weights[:, 1:]**2) + np.sum(hidden_weights[:, 1:]**2)) * (lamb\/(2*m))\n    \n    d3 = a3 - y_mat\n    d2 = np.dot(d3, hidden_weights[:, 1:]) * sigmoid(z2) * (1 - sigmoid(z2))\n    \n    delta1 = np.dot(d2.T, a1)\n    delta2 = np.dot(d3.T, a2)\n    \n    input_weights_grad = delta1 \/ m\n    input_weights_grad[:, 1:] += (input_weights[:, 1:] * lamb) \/ m\n    hidden_weights_grad = delta2 \/ m\n    hidden_weights_grad[:, 1:] += (hidden_weights[:, 1:] * lamb) \/ m\n    #print(input_weights_grad.shape, hidden_weights_grad.shape)\n    \n    grads = np.concatenate([input_weights_grad.ravel(), hidden_weights_grad.ravel()])\n    #print(grads.shape)\n    #print(J)\n    return J, grads","e78937aa":"def cal_accuracy(inputs, y, best_in_weights, best_hid_weights):\n    h1 = sigmoid(np.dot(inputs, best_in_weights.T))\n    pred1 = np.ones([h1.shape[0], h1.shape[1]+1])\n    pred1[:, 1:] = h1\n    pred2 = sigmoid(np.dot(pred1, best_hid_weights.T))\n    preds = []\n    for i in range(pred2.shape[0]):\n        arr = list(pred2[i, :])\n        idx = arr.index(max(arr))\n        preds.append(idx)\n    return accuracy_score(y, preds)","2c8fcf55":"initial_weights = np.concatenate([input_weights.ravel(), hidden_weights.ravel()], axis = 0)\nprint(initial_weights.shape)","bf2ac3fa":"lambda_ = 1\ncostfunction = lambda w: cost_function(w, n_input, n_hidden, n_output, inputs, y, lambda_)","41df348d":"#options = {\"maxiter\": 200}\nres = minimize(fun = costfunction, x0 = initial_weights, jac = True, method = 'TNC')#, options = options)\nprint(res)","a38414f9":"final_weights = res.x\ninput_weights_ = np.reshape(final_weights[:n_hidden * (n_input+1)], (n_hidden, n_input+1))\nhidden_weights_ = np.reshape(final_weights[(n_hidden * (n_input+1)):], (n_output, n_hidden+1))\nprint(input_weights_.shape, hidden_weights_.shape)","7c6d8544":"print(f\"train accuracy: {cal_accuracy(inputs, y, input_weights_, hidden_weights_)}\")\nprint(f\"test accuracy: {cal_accuracy(inputs_test[:3000, :], y_test[:3000, :], input_weights_, hidden_weights_)}\")","3ceb2bff":"def gradient_descent(initial_weights, n_input, n_hidden, n_output, X, y, alpha, lamb, epochs):\n    input_weights = np.reshape(initial_weights[:n_hidden * (n_input+1)], (n_hidden, n_input+1))\n    hidden_weights = np.reshape(initial_weights[(n_hidden * (n_input+1)):], (n_output, n_hidden+1))\n    #print(input_weights.shape, hidden_weights.shape)\n    \n    m = len(y)\n    y_mat = to_categorical(y)\n    \n    a1 = X\n    \n    for i in range(epochs):\n        z2 = np.dot(a1, input_weights.T)\n        a2 = np.ones([z2.shape[0], z2.shape[1]+1])\n        a2[:, 1:] = sigmoid(z2)\n\n        z3 = np.dot(a2, hidden_weights.T)\n        a3 = sigmoid(z3)\n\n        J = np.sum(np.dot(y_mat, np.log(a3).T) + np.dot((1-y_mat), np.log(1-a3).T))\/(-m) + (np.sum(input_weights[:, 1:]**2) + np.sum(hidden_weights[:, 1:]**2)) * (lamb\/(2*m))\n\n        d3 = a3 - y_mat\n        d2 = np.dot(d3, hidden_weights[:, 1:]) * sigmoid(z2) * (1 - sigmoid(z2))\n\n        delta1 = np.dot(d2.T, a1)\n        delta2 = np.dot(d3.T, a2)\n\n        input_weights_grad = delta1 \/ m\n        input_weights_grad[:, 1:] += (input_weights[:, 1:] * lamb) \/ m\n        hidden_weights_grad = delta2 \/ m\n        hidden_weights_grad[:, 1:] += (hidden_weights[:, 1:] * lamb) \/ m\n        input_weights -= alpha * input_weights_grad\n        hidden_weights -= alpha * hidden_weights_grad\n    \n    return J, input_weights, hidden_weights","2250cd97":"n_hidden = 500\nalpha = [0.01, 0.1, 1, 10]\nlambda_ = [0.1, 1, 10, 100]\nfor a in alpha:\n    for l in lambda_:\n        np.random.seed(4)\n        input_weights = np.random.randn(n_hidden, n_input+1)\n        hidden_weights = np.random.randn(n_output, n_hidden+1)\n        initial_weights = np.concatenate([input_weights.ravel(), hidden_weights.ravel()], axis = 0)\n\n        print(f\"alpha: {a}, lambda: {l}\")\n        J_min, best_in_weights, best_hid_weights = gradient_descent(initial_weights, n_input, n_hidden, n_output,\n                                                                    inputs, y, a, l, 10)\n        \n        print(f\"epochs: 10\")\n        print(f\"train accuracy: {cal_accuracy(inputs, y, best_in_weights, best_hid_weights)}\")\n        print(f\"test accuracy: {cal_accuracy(inputs_test[:3000, :], y_test[:3000, :], best_in_weights, best_hid_weights)}\")\n        print()","54aa1b42":"def gradient_descent_for_getting_epoch(initial_weights, n_input, n_hidden, n_output, X, y, alpha, lamb, epochs):\n    input_weights = np.reshape(initial_weights[:n_hidden * (n_input+1)], (n_hidden, n_input+1))\n    hidden_weights = np.reshape(initial_weights[(n_hidden * (n_input+1)):], (n_output, n_hidden+1))\n    #print(input_weights.shape, hidden_weights.shape)\n    \n    m = len(y)\n    y_mat = to_categorical(y)\n    \n    a1 = X\n    \n    epoch_list = [e for e in range(0, 2001, 100)]\n    ins = []\n    hids = []\n    accs = []\n    J_mins = []\n    \n    for i in range(epochs):\n        z2 = np.dot(a1, input_weights.T)\n        a2 = np.ones([z2.shape[0], z2.shape[1]+1])\n        a2[:, 1:] = sigmoid(z2)\n\n        z3 = np.dot(a2, hidden_weights.T)\n        a3 = sigmoid(z3)\n\n        J = np.sum(np.dot(y_mat, np.log(a3).T) + np.dot((1-y_mat), np.log(1-a3).T))\/(-m) + (np.sum(input_weights[:, 1:]**2) + np.sum(hidden_weights[:, 1:]**2)) * (lamb\/(2*m))\n\n        d3 = a3 - y_mat\n        d2 = np.dot(d3, hidden_weights[:, 1:]) * sigmoid(z2) * (1 - sigmoid(z2))\n\n        delta1 = np.dot(d2.T, a1)\n        delta2 = np.dot(d3.T, a2)\n\n        input_weights_grad = delta1 \/ m\n        input_weights_grad[:, 1:] += (input_weights[:, 1:] * lamb) \/ m\n        hidden_weights_grad = delta2 \/ m\n        hidden_weights_grad[:, 1:] += (hidden_weights[:, 1:] * lamb) \/ m\n        input_weights -= alpha * input_weights_grad\n        hidden_weights -= alpha * hidden_weights_grad\n        if i+1 in epoch_list:\n            train_acc = cal_accuracy(inputs, y, input_weights, hidden_weights)\n            test_acc = cal_accuracy(inputs_test[:3000, :], y_test[:3000, :], input_weights, hidden_weights)\n            ins.append(input_weights)\n            hids.append(hidden_weights)\n            accs.append(test_acc)\n            J_mins.append(J)\n            print(f\"epochs: {i+1}\")\n            print(f\"train accuracy: {train_acc}\")\n            print(f\"test accuracy: {test_acc}\")\n            \n    idx = accs.index(max(accs))\n    return J_mins[idx], ins[idx], hids[idx]","9c320be4":"np.random.seed(4)\ninput_weights = np.random.randn(n_hidden, n_input+1)\nhidden_weights = np.random.randn(n_output, n_hidden+1)\ninitial_weights = np.concatenate([input_weights.ravel(), hidden_weights.ravel()], axis = 0)\nJ, best_in_weights, best_hid_weights = gradient_descent_for_getting_epoch(initial_weights, n_input, n_hidden, n_output, inputs, y, 1, 10, 2000)","cced8385":"print(f\"train accuracy: {cal_accuracy(inputs, y, best_in_weights, best_hid_weights)}\")\nprint(f\"test accuracy: {cal_accuracy(inputs_test[:3000, :], y_test[:3000, :], best_in_weights, best_hid_weights)}\")","0f0770b1":"# Sigmoid Function","94d35421":"# Features & labels","85049e0c":"# Regularized Cost Function","c267096c":"# Initializing Weights","e03564f2":"# Finding suitable learning rate & regularization param","070e4a47":"# Minimizing Cost Function using scipy","54ffc161":"**Best parameters for high accuracy**\n- alpha = 1\n- lambda = 10","f447652e":"# Minimizing Cost Function using Gradient Descent","1b494893":"## Train Accuracy & Test Accuracy","07c5f096":"# Finding suitable epochs for highest test accuracy"}}