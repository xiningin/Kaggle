{"cell_type":{"d286733e":"code","cd0f6765":"code","2f94c311":"code","9968b6eb":"code","2171c980":"code","1b76f765":"code","6f100411":"code","e92e7215":"code","44480472":"code","837b5ba2":"code","94b49586":"markdown","ca75decf":"markdown","9a32a479":"markdown","ad065874":"markdown","3629903d":"markdown","0b09056c":"markdown","4ccac0af":"markdown","3d8754f6":"markdown","da609fea":"markdown","ad831f6b":"markdown"},"source":{"d286733e":"import numpy as np\nimport os\nimport shutil\nimport PIL\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,BatchNormalization, Input\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)","cd0f6765":"def tr_plot(tr_data, start_epoch):\n    #Plot the training and validation data\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)   \n    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout\n    #plt.style.use('fivethirtyeight')\n    plt.show()\n","2f94c311":"def print_in_color(txt_msg,fore_tupple,back_tupple,):\n    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n    rf,gf,bf=fore_tupple\n    rb,gb,bb=back_tupple\n    msg='{0}' + txt_msg\n    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n    print(msg .format(mat), flush=True)\n    print('\\33[0m', flush=True) # returns default print color to back to black\n    return","9968b6eb":"sdir=r'..\/input\/100-bird-species'\ntrain_dir=os.path.join(sdir, 'train')\ntest_dir=os.path.join(sdir, 'test')\nvalid_dir=os.path.join(sdir, 'valid')\n","2171c980":"img_shape=(128,128,3) # use 128 X128 versus 224 X224 to reduce training time\nimg_size=(img_shape[0], img_shape[1])\nmsg='For training set'\nprint_in_color(msg, (0,255,255), (55,65,80))\ntrain_ds=tf.keras.preprocessing.image_dataset_from_directory(\n            train_dir, image_size=img_size, seed=123, batch_size=30)\nmsg=' For validation set'\nprint_in_color(msg, (0,255,255), (55,65,80))\nvalid_ds=tf.keras.preprocessing.image_dataset_from_directory(\n            valid_dir, image_size=img_size, seed=123, batch_size=30)\nmsg='For the test set'\nprint_in_color(msg, (0,255,255), (55,65,80))\ntest_ds=tf.keras.preprocessing.image_dataset_from_directory(\n            valid_dir, image_size=img_size, shuffle=False, batch_size=30) # set shuffle=False to keep file order","1b76f765":"class_names=train_ds.class_names\nclass_count=len(class_names)\nplt.figure(figsize=(20,20))\nfor images, labels in test_ds.take(1):\n    for i in range (25):\n        plt.subplot(5,5,i +1)\n        img=images[i]\/255  \n        plt.title(class_names[labels[i]], color='blue', fontsize=12)\n        plt.imshow(img)\n        plt.axis('off')\n    plt.show()\n","6f100411":"input=Input(shape=img_shape)\nx=tf.keras.applications.EfficientNetB3(include_top=False, weights=\"imagenet\", pooling='max')(input) \nx=tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\nx = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\nx=Dropout(rate=.4, seed=123)(x)        \noutput=Dense(class_count, activation='softmax')(x)\nmodel=Model(inputs=input, outputs=output)\nmodel.compile(Adamax(lr=.001), loss='sparse_categorical_crossentropy', metrics=['accuracy']) # note labels are integers use sparse_categorical_crossentropy","e92e7215":"rlronp=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5,  patience=1, verbose=1)\nepochs=10\nhistory=model.fit( train_ds, validation_data=valid_ds, epochs=epochs, verbose=1, callbacks=[rlronp])\n  ","44480472":"tr_plot(history, 0)","837b5ba2":"ytrue=[]\nfor images, label in test_ds:   \n    for e in label:\n        ytrue.append(class_names[e]) # list of class names associated with each image file in test dataset \nypred=[]\nerrors=0\ncount=0\npreds=model.predict(test_ds, verbose=1) # predict on the test data\nfor i, p in enumerate(preds):\n    count +=1\n    index=np.argmax(p) # get index of prediction with highest probability\n    klass=class_names[index] \n    ypred.append(klass)  \n    if klass != ytrue[i]:\n        errors +=1\nacc= (count-errors)* 100\/count\nmsg=f'there were {count-errors} correct predictions in {count} tests for an accuracy of {acc:6.2f} % '\nprint_in_color(msg, (0,255,255), (55,65,80)) \nypred=np.array(ypred)\nytrue=np.array(ytrue)\nclr = classification_report(ytrue, ypred, target_names=class_names)\nprint(\"Classification Report:\\n----------------------\\n\", clr)    ","94b49586":"### make predictions on test set, compute accuracy and create classification report","ca75decf":"### define the directories ","9a32a479":"### create reduce learning rate on plateau callback and train the model","ad065874":"## considering the training set is not balanced and we did not use image augmentation the results are good.\n## could also pobably do better using the full image size of 224 X 244 but with 300 classes the training\n## time would be excessive","3629903d":"### define function to print text in RGB foreground and background colors","0b09056c":"### create the Datasets","4ccac0af":"### create a function to plot training data from model.fit","3d8754f6":"### plot the training data","da609fea":"### show some test images- Note with shuffle=False test images remain in original order","ad831f6b":"### create the model"}}