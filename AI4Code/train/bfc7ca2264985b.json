{"cell_type":{"ee92a929":"code","f4d6d358":"code","7c0b9290":"code","4cf6715a":"code","cf608d8e":"code","0458255b":"code","47931550":"code","75c5d138":"code","327f070b":"code","e55c7195":"code","15562858":"code","c5f5ba7c":"code","72b4f977":"code","08778ffa":"code","d5b703dc":"code","f9a67ac1":"code","14536438":"code","7b27c8e5":"code","f3d1f997":"code","a3fc9903":"code","817d90e2":"code","4688cd25":"code","eea54140":"code","d12ca631":"code","ea5608fc":"code","b073a51b":"code","ac8866c6":"code","f7f0eb25":"markdown","4f260b2e":"markdown","d8e1314d":"markdown","3feea4e1":"markdown","9af991ad":"markdown","4169377b":"markdown","e32df4ab":"markdown","1a63bf17":"markdown","d3a6105a":"markdown","95213b70":"markdown","57ad2571":"markdown","79f0937f":"markdown","a55c5630":"markdown","2a5db7e5":"markdown","36aae4c5":"markdown","91bf204c":"markdown","3afe118f":"markdown","eac9f817":"markdown","2d5d8cf6":"markdown","1a34974f":"markdown","ccc59ee9":"markdown","2a5f3c1b":"markdown","587a67c7":"markdown","bea22cb4":"markdown","009d8be4":"markdown","e8794ab1":"markdown","eb87eee9":"markdown","156579b6":"markdown","e052dd84":"markdown","1fa2e415":"markdown","13c79b02":"markdown","a1c7c3ed":"markdown","90bf65e2":"markdown","29e2ed10":"markdown","3e1059a9":"markdown","5e2185fc":"markdown","ec660fe8":"markdown"},"source":{"ee92a929":"[10.5, 5.2, 3.25, 7.0]","f4d6d358":"import numpy as np\nvideo = np.array([10.5, 5.2, 3.25, 7.0])\nvideo","7c0b9290":"video.size","4cf6715a":"video[2]  # 3rd element","cf608d8e":"%matplotlib inline\nimport matplotlib.pyplot as plt","0458255b":"u = np.array([2, 5])\nv = np.array([3, 1])","47931550":"x_coords, y_coords = zip(u, v)\nplt.scatter(x_coords, y_coords, color=[\"r\",\"b\"])\nplt.axis([0, 9, 0, 6])\nplt.grid()\nplt.show()","75c5d138":"def plot_vector2d(vector2d, origin=[0, 0], **options):\n    return plt.arrow(origin[0], origin[1], vector2d[0], vector2d[1],\n              head_width=0.2, head_length=0.3, length_includes_head=True,\n              **options)","327f070b":"plot_vector2d(u, color=\"r\")\nplot_vector2d(v, color=\"b\")\nplt.axis([0, 9, 0, 6])\nplt.grid()\nplt.show()","e55c7195":"a = np.array([1, 2, 8])\nb = np.array([5, 6, 3])","15562858":"from mpl_toolkits.mplot3d import Axes3D\n\nsubplot3d = plt.subplot(111, projection='3d')\nx_coords, y_coords, z_coords = zip(a,b)\nsubplot3d.scatter(x_coords, y_coords, z_coords)\nsubplot3d.set_zlim3d([0, 9])\nplt.show()","c5f5ba7c":"def plot_vectors3d(ax, vectors3d, z0, **options):\n    for v in vectors3d:\n        x, y, z = v\n        ax.plot([x,x], [y,y], [z0, z], color=\"gray\", linestyle='dotted', marker=\".\")\n    x_coords, y_coords, z_coords = zip(*vectors3d)\n    ax.scatter(x_coords, y_coords, z_coords, **options)\n\nsubplot3d = plt.subplot(111, projection='3d')\nsubplot3d.set_zlim([0, 9])\nplot_vectors3d(subplot3d, [a,b], 0, color=(\"r\",\"b\"))\nplt.show()","72b4f977":"def vector_norm(vector):\n    squares = [element**2 for element in vector]\n    return sum(squares)**0.5\n\nprint(\"||\", u, \"|| =\")\nvector_norm(u)","08778ffa":"import numpy.linalg as LA\nLA.norm(u)","d5b703dc":"radius = LA.norm(u)\nplt.gca().add_artist(plt.Circle((0,0), radius, color=\"#DDDDDD\"))\nplot_vector2d(u, color=\"red\")\nplt.axis([0, 8.7, 0, 6])\nplt.grid()\nplt.show()","f9a67ac1":"print(\" \", u)\nprint(\"+\", v)\nprint(\"-\"*10)\nu + v","14536438":"plot_vector2d(u, color=\"r\")\nplot_vector2d(v, color=\"b\")\nplot_vector2d(v, origin=u, color=\"b\", linestyle=\"dotted\")\nplot_vector2d(u, origin=v, color=\"r\", linestyle=\"dotted\")\nplot_vector2d(u+v, color=\"g\")\nplt.axis([0, 9, 0, 7])\nplt.text(0.7, 3, \"u\", color=\"r\", fontsize=18)\nplt.text(4, 3, \"u\", color=\"r\", fontsize=18)\nplt.text(1.8, 0.2, \"v\", color=\"b\", fontsize=18)\nplt.text(3.1, 5.6, \"v\", color=\"b\", fontsize=18)\nplt.text(2.4, 2.5, \"u+v\", color=\"g\", fontsize=18)\nplt.grid()\nplt.show()","7b27c8e5":"t1 = np.array([2, 0.25])\nt2 = np.array([2.5, 3.5])\nt3 = np.array([1, 2])\n\nx_coords, y_coords = zip(t1, t2, t3, t1)\nplt.plot(x_coords, y_coords, \"c--\", x_coords, y_coords, \"co\")\n\nplot_vector2d(v, t1, color=\"r\", linestyle=\":\")\nplot_vector2d(v, t2, color=\"r\", linestyle=\":\")\nplot_vector2d(v, t3, color=\"r\", linestyle=\":\")\n\nt1b = t1 + v\nt2b = t2 + v\nt3b = t3 + v\n\nx_coords_b, y_coords_b = zip(t1b, t2b, t3b, t1b)\nplt.plot(x_coords_b, y_coords_b, \"b-\", x_coords_b, y_coords_b, \"bo\")\n\nplt.text(4, 4.2, \"v\", color=\"r\", fontsize=18)\nplt.text(3, 2.3, \"v\", color=\"r\", fontsize=18)\nplt.text(3.5, 0.4, \"v\", color=\"r\", fontsize=18)\n\nplt.axis([0, 6, 0, 5])\nplt.grid()\nplt.show()","f3d1f997":"print(\"1.5 *\", u, \"=\")\n\n1.5 * u","a3fc9903":"k = 2.5\nt1c = k * t1\nt2c = k * t2\nt3c = k * t3\n\nplt.plot(x_coords, y_coords, \"c--\", x_coords, y_coords, \"co\")\n\nplot_vector2d(t1, color=\"r\")\nplot_vector2d(t2, color=\"r\")\nplot_vector2d(t3, color=\"r\")\n\nx_coords_c, y_coords_c = zip(t1c, t2c, t3c, t1c)\nplt.plot(x_coords_c, y_coords_c, \"b-\", x_coords_c, y_coords_c, \"bo\")\n\nplot_vector2d(k * t1, color=\"b\", linestyle=\":\")\nplot_vector2d(k * t2, color=\"b\", linestyle=\":\")\nplot_vector2d(k * t3, color=\"b\", linestyle=\":\")\n\nplt.axis([0, 9, 0, 9])\nplt.grid()\nplt.show()","817d90e2":"plt.gca().add_artist(plt.Circle((0,0),1,color='c'))\nplt.plot(0, 0, \"ko\")\nplot_vector2d(v \/ LA.norm(v), color=\"k\")\nplot_vector2d(v, color=\"b\", linestyle=\":\")\nplt.text(0.3, 0.3, \"$\\hat{u}$\", color=\"k\", fontsize=18)\nplt.text(1.5, 0.7, \"$u$\", color=\"b\", fontsize=18)\nplt.axis([-1.5, 5.5, -1.5, 3.5])\nplt.grid()\nplt.show()","4688cd25":"def dot_product(v1, v2):\n    return sum(v1i * v2i for v1i, v2i in zip(v1, v2))\n\ndot_product(u, v)","eea54140":"np.dot(u,v)","d12ca631":"u.dot(v)","ea5608fc":"print(\"  \",u)\nprint(\"* \",v, \"(NOT a dot product)\")\nprint(\"-\"*10)\n\nu * v","b073a51b":"def vector_angle(u, v):\n    cos_theta = u.dot(v) \/ LA.norm(u) \/ LA.norm(v)\n    return np.arccos(np.clip(cos_theta, -1, 1))\n\ntheta = vector_angle(u, v)\nprint(\"Angle =\", theta, \"radians\")\nprint(\"      =\", theta * 180 \/ np.pi, \"degrees\")","ac8866c6":"u_normalized = u \/ LA.norm(u)\nproj = v.dot(u_normalized) * u_normalized\n\nplot_vector2d(u, color=\"r\")\nplot_vector2d(v, color=\"b\")\n\nplot_vector2d(proj, color=\"k\", linestyle=\":\")\nplt.plot(proj[0], proj[1], \"ko\")\n\nplt.plot([proj[0], v[0]], [proj[1], v[1]], \"b:\")\n\nplt.text(1, 2, \"$proj_u v$\", color=\"k\", fontsize=18)\nplt.text(1.8, 0.2, \"$v$\", color=\"b\", fontsize=18)\nplt.text(0.8, 3, \"$u$\", color=\"r\", fontsize=18)\n\nplt.axis([0, 8, 0, 5.5])\nplt.grid()\nplt.show()","f7f0eb25":"It is a bit hard to visualize exactly where in space these two points are, so let's add vertical lines. We'll create a small convenience function to plot a list of 3d vectors with vertical lines attached:","4f260b2e":"## Norm\nThe norm of a vector $\\textbf{u}$, noted $\\left \\Vert \\textbf{u} \\right \\|$, is a measure of the length (a.k.a. the magnitude) of $\\textbf{u}$. There are multiple possible norms, but the most common one (and the only one we will discuss here) is the Euclidian norm, which is defined as:\n\n$\\left \\Vert \\textbf{u} \\right \\| = \\sqrt{\\sum_{i}{\\textbf{u}_i}^2}$\n\nWe could implement this easily in pure python, recalling that $\\sqrt x = x^{\\frac{1}{2}}$","d8e1314d":"Let's look at what vector addition looks like graphically:","3feea4e1":"Vector addition is **commutative**, meaning that $\\textbf{u} + \\textbf{v} = \\textbf{v} + \\textbf{u}$. You can see it on the previous image: following $\\textbf{u}$ *then* $\\textbf{v}$ leads to the same point as following $\\textbf{v}$ *then* $\\textbf{u}$.\n\nVector addition is also **associative**, meaning that $\\textbf{u} + (\\textbf{v} + \\textbf{w}) = (\\textbf{u} + \\textbf{v}) + \\textbf{w}$.","9af991ad":"## Zero, unit and normalized vectors\n* A **zero-vector ** is a vector full of 0s.\n* A **unit vector** is a vector with a norm equal to 1.\n* The **normalized vector** of a non-null vector $\\textbf{u}$, noted $\\hat{\\textbf{u}}$, is the unit vector that points in the same direction as $\\textbf{u}$. It is equal to: $\\hat{\\textbf{u}} = \\dfrac{\\textbf{u}}{\\left \\Vert \\textbf{u} \\right \\|}$\n\n","4169377b":"Looks about right!","e32df4ab":"### Projecting a point onto an axis\nThe dot product is also very useful to project points onto an axis. The projection of vector $\\textbf{v}$ onto $\\textbf{u}$'s axis is given by this formula:\n\n$\\textbf{proj}_{\\textbf{u}}{\\textbf{v}} = \\dfrac{\\textbf{u} \\cdot \\textbf{v}}{\\left \\Vert \\textbf{u} \\right \\| ^2} \\times \\textbf{u}$\n\nWhich is equivalent to:\n\n$\\textbf{proj}_{\\textbf{u}}{\\textbf{v}} = (\\textbf{v} \\cdot \\hat{\\textbf{u}}) \\times \\hat{\\textbf{u}}$\n","1a63bf17":"However, it is much more efficient to use NumPy's `norm` function, available in the `linalg` (**Lin**ear **Alg**ebra) module:","d3a6105a":"To Be continued ...! next is on Matrices ","95213b70":"## Addition\nVectors of same size can be added together. Addition is performed *elementwise*:","57ad2571":"Since we plan to do quite a lot of scientific calculations, it is much better to use NumPy's `ndarray`, which provides a lot of convenient and optimized implementations of essential mathematical operations on vectors (for more details about NumPy, check out the [NumPy tutorial](tools_numpy.ipynb)). For example:","79f0937f":"If you have a shape defined by a number of points (vectors), and you add a vector $\\textbf{v}$ to all of these points, then the whole shape gets shifted by $\\textbf{v}$. This is called a [geometric translation](https:\/\/en.wikipedia.org\/wiki\/Translation_%28geometry%29):","a55c5630":"### Main properties\n* The dot product is **commutative**: $\\textbf{u} \\cdot \\textbf{v} = \\textbf{v} \\cdot \\textbf{u}$.\n* The dot product is only defined between two vectors, not between a scalar and a vector. This means that we cannot chain dot products: for example, the expression $\\textbf{u} \\cdot \\textbf{v} \\cdot \\textbf{w}$ is not defined since $\\textbf{u} \\cdot \\textbf{v}$ is a scalar and $\\textbf{w}$ is a vector.\n* This also means that the dot product is **NOT associative**: $(\\textbf{u} \\cdot \\textbf{v}) \\cdot \\textbf{w} \u2260 \\textbf{u} \\cdot (\\textbf{v} \\cdot \\textbf{w})$ since neither are defined.\n* However, the dot product is **associative with regards to scalar multiplication**: $\\lambda \\times (\\textbf{u} \\cdot \\textbf{v}) = (\\lambda \\times \\textbf{u}) \\cdot \\textbf{v} = \\textbf{u} \\cdot (\\lambda \\times \\textbf{v})$\n* Finally, the dot product is **distributive** over addition of vectors: $\\textbf{u} \\cdot (\\textbf{v} + \\textbf{w}) = \\textbf{u} \\cdot \\textbf{v} + \\textbf{u} \\cdot \\textbf{w}$.","2a5db7e5":"### Calculating the angle between vectors\nOne of the many uses of the dot product is to calculate the angle between two non-zero vectors. Looking at the dot product definition, we can deduce the following formula:\n\n$\\theta = \\arccos{\\left ( \\dfrac{\\textbf{u} \\cdot \\textbf{v}}{\\left \\Vert \\textbf{u} \\right \\| \\times \\left \\Vert \\textbf{v} \\right \\|} \\right ) }$\n\nNote that if $\\textbf{u} \\cdot \\textbf{v} = 0$, it follows that $\\theta = \\dfrac{\u03c0}{2}$. In other words, if the dot product of two non-null vectors is zero, it means that they are orthogonal.\n\nLet's use this formula to calculate the angle between $\\textbf{u}$ and $\\textbf{v}$ (in radians):","36aae4c5":"## Vectors in python\nIn python, a vector can be represented in many ways, the simplest being a regular python list of numbers:","91bf204c":"## Plotting vectors\nTo plot vectors we will use matplotlib, so let's start by importing it (for details about matplotlib, check the matplotlib tutorial:","3afe118f":"These vectors each have 2 elements, so they can easily be represented graphically on a 2D graph, for example as points:","eac9f817":"**Math - Linear Algebra**\nLinear Algebra is the branch of mathematics that studies vector spaces and linear transformations between vector spaces, such as rotating a shape, scaling it up or down, translating it (ie. moving it), etc.\n\nMachine Learning relies heavily on Linear Algebra, so it is essential to understand what vectors and matrices are, what operations you can perform with them, and how they can be useful.","2d5d8cf6":"But a *much* more efficient implementation is provided by NumPy with the `dot` function:","1a34974f":"Let's plot a little diagram to confirm that the length of vector $\\textbf{v}$ is indeed $\\approx5.4$:","ccc59ee9":"### 3D vectors\nPlotting 3D vectors is also relatively straightforward. First let's create two 3D vectors:","2a5f3c1b":"The $i^{th}$ element (also called *entry* or *item*) of a vector $\\textbf{v}$ is noted $\\textbf{v}_i$.\n\nNote that indices in mathematics generally start at 1, but in programming they usually start at 0. So to access $\\textbf{video}_3$ programmatically, we would write:","587a67c7":"**Caution**: the `*` operator will perform an *elementwise* multiplication, *NOT* a dot product:","bea22cb4":"Graphically, scalar multiplication results in changing the scale of a figure, hence the name *scalar*. The distance from the origin (the point at coordinates equal to zero) is also multiplied by the scalar. For example, let's scale up by a factor of `k = 2.5`:","009d8be4":"## Vectors\n\nDefinition:\n\nA vector is a quantity defined by a magnitude and a direction. For example, a rocket's velocity is a 3-dimensional vector: its magnitude is the speed of the rocket, and its direction is (hopefully) up. A vector can be represented by an array of numbers called scalars. Each scalar corresponds to the magnitude of the vector with regards to each dimension.\n\nFor example, say the rocket is going up at a slight angle: it has a vertical speed of 5,000 m\/s, and also a slight speed towards the East at 10 m\/s, and a slight speed towards the North at 50 m\/s. The rocket's velocity may be represented by the following vector:\n\n\n**velocity** $= \\begin{pmatrix}\n10 \\\\\n50 \\\\\n5000 \\\\\n\\end{pmatrix}$\n\nNote: by convention vectors are generally presented in the form of columns. Also, vector names are generally lowercase to distinguish them from matrices (which we will discuss below) and in bold (when possible) to distinguish them from simple scalar values such as ${meters\\_per\\_second} = 5026$.\n\nA list of N numbers may also represent the coordinates of a point in an N-dimensional space, so it is quite frequent to represent vectors as simple points instead of arrows. A vector with 1 element may be represented as an arrow or a point on an axis, a vector with 2 elements is an arrow or a point on a plane, a vector with 3 elements is an arrow or point in space, and a vector with N elements is an arrow or a point in an N-dimensional space\u2026 which most people find hard to imagine.\n\n\n##  Purpose\nVectors have many purposes in Machine Learning, most notably to represent observations and predictions. For example, say we built a Machine Learning system to classify videos into 3 categories (good, spam, clickbait) based on what we know about them. For each video, we would have a vector representing what we know about it, such as:\n\n**video** $= \\begin{pmatrix}\n10.5 \\\\\n5.2 \\\\\n3.25 \\\\\n7.0\n\\end{pmatrix}$\n\nThis vector could represent a video that lasts 10.5 minutes, but only 5.2% viewers watch for more than a minute, it gets 3.25 views per day on average, and it was flagged 7 times as spam. As you can see, each axis may have a different meaning.\n\nBased on this vector our Machine Learning system may predict that there is an 80% probability that it is a spam video, 18% that it is clickbait, and 2% that it is a good video. This could be represented as the following vector:\n\n**class_probabilities** $= \\begin{pmatrix}\n0.80 \\\\\n0.18 \\\\\n0.02\n\\end{pmatrix}$","e8794ab1":"Scalar multiplication is **commutative**: $\\lambda \\times \\textbf{u} = \\textbf{u} \\times \\lambda$.\n\nIt is also **associative**: $\\lambda_1 \\times (\\lambda_2 \\times \\textbf{u}) = (\\lambda_1 \\times \\lambda_2) \\times \\textbf{u}$.\n\nFinally, it is **distributive** over addition of vectors: $\\lambda \\times (\\textbf{u} + \\textbf{v}) = \\lambda \\times \\textbf{u} + \\lambda \\times \\textbf{v}$.","eb87eee9":"Vectors can also be represented as arrows. Let's create a small convenience function to draw nice arrows:","156579b6":"## Dot product\n### Definition\nThe dot product (also called *scalar product* or *inner product* in the context of the Euclidian space) of two vectors $\\textbf{u}$ and $\\textbf{v}$ is a useful operation that comes up fairly often in linear algebra. It is noted $\\textbf{u} \\cdot \\textbf{v}$, or sometimes $\u27e8\\textbf{u}|\\textbf{v}\u27e9$ or $(\\textbf{u}|\\textbf{v})$, and it is defined as:\n\n$\\textbf{u} \\cdot \\textbf{v} = \\left \\Vert \\textbf{u} \\right \\| \\times \\left \\Vert \\textbf{v} \\right \\| \\times cos(\\theta)$\n\nwhere $\\theta$ is the angle between $\\textbf{u}$ and $\\textbf{v}$.\n\nAnother way to calculate the dot product is:\n\n$\\textbf{u} \\cdot \\textbf{v} = \\sum_i{\\textbf{u}_i \\times \\textbf{v}_i}$\n\n### In python\nThe dot product is pretty simple to implement:","e052dd84":"### 2D vectors\nLet's create a couple very simple 2D vectors to plot:","1fa2e415":"Note: due to small floating point errors, `cos_theta` may be very slightly outside of the $[-1, 1]$ interval, which would make `arccos` fail. This is why we clipped the value within the range, using NumPy's `clip` function.","13c79b02":"Equivalently, you can use the `dot` method of `ndarray`s:","a1c7c3ed":"Now let's draw the vectors **u** and **v** as arrows:","90bf65e2":"Now let's plot them using matplotlib's `Axes3D`:","29e2ed10":"Finally, substracting a vector is like adding the opposite vector.","3e1059a9":"## Multiplication by a scalar\nVectors can be multiplied by scalars. All elements in the vector are multiplied by that number, for example:","5e2185fc":"The size of a vector can be obtained using the `size` attribute:","ec660fe8":"As you might guess, dividing a vector by a scalar is equivalent to multiplying by its inverse:\n\n$\\dfrac{\\textbf{u}}{\\lambda} = \\dfrac{1}{\\lambda} \\times \\textbf{u}$"}}