{"cell_type":{"0a16956a":"code","45025eec":"code","647c6836":"code","84b4eb04":"code","087380c7":"code","9a640aae":"code","423b4106":"code","6eed3c06":"code","366132eb":"code","8a96d0e7":"code","bb11ca5f":"code","95e80709":"code","be456918":"code","e0d9905a":"code","8350dd5d":"markdown","11c55d19":"markdown","03a944ea":"markdown","5139b8b9":"markdown","78565bdb":"markdown"},"source":{"0a16956a":"import os\nimport json \nimport glob\nimport shutil\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nfrom pathlib import Path\nfrom keras.models import Sequential, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import shuffle\n\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# images are stored in the folder ..\/input\/planesnet\/planesnet\n","45025eec":"input_path = Path('..\/input\/planesnet\/planesnet\/planesnet')\nplanes_path = input_path","647c6836":"planes = []\n\nall_planes = os.listdir(planes_path)\n    # Add them to the list\nfor ac in all_planes:\n    planes.append((ac[0],str(planes_path)+\"\/\"+str(ac)))\n\n# Build a dataframe        \nplanes = pd.DataFrame(data=planes, columns=['label','image_path'], index=None)\nplanes.sample(5)","84b4eb04":"print(\"Total number of planes images in the dataset: \", len(planes))\nac_count = planes['label'].value_counts()\nplt.figure(figsize=(12,8))\nsns.barplot(x=ac_count.index, y=ac_count.values)\nplt.title(\"Images count for each category\", fontsize=16)\nplt.xlabel(\"Label\", fontsize=14)\nplt.ylabel(\"Count\", fontsize=14)\nplt.show()","087380c7":"random_samples = []\n\nfor item in planes.sample(20).iterrows():\n    random_samples.append((item[1].label, item[1].image_path))\n\nf, ax = plt.subplots(5,4, figsize=(20,20))\nfor i,sample in enumerate(random_samples):\n    ax[i\/\/4, i%4].imshow(mimg.imread(random_samples[i][1]))\n    ax[i\/\/4, i%4].set_title(random_samples[i][0])\n    ax[i\/\/4, i%4].axis('off')\nplt.show()   ","9a640aae":"# Load planesnet data\nf = open('..\/input\/planesnet\/planesnet.json')\nplanesnet = json.load(f)\nf.close()\n\n# Preprocess image data and labels\nX = np.array(planesnet['data']) \/ 255.\nX = X.reshape([-1,3,20,20]).transpose([0,2,3,1])\nY = np.array(planesnet['labels'])\nY = to_categorical(Y, 2)\nX,Y = shuffle(X,Y,random_state=42)\nX_train = X[0:25000]\nY_train = Y[0:25000]\nX_test = X[25000:]\nY_test = Y[25000:]","423b4106":"print(\"Input shape : {0}\".format(X.shape))\nprint(\"Training shape : {0}\".format(X_train.shape))\nprint(\"Testing shape : {0}\".format(X_test.shape))","6eed3c06":"# Check for the directory and if it doesn't exist, make one.\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\n    \n# make the models sub-directory\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)","366132eb":"!cp ..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5 ~\/.keras\/models\/\n","8a96d0e7":"def get_vgg_16(input_shape=48):\n    base_model = VGG16(include_top=False, input_shape=(input_shape,input_shape,3))\n    x = Flatten()(base_model.output)\n    x = Dense(2, activation='softmax', name='fc2')(x)\n    model = Model(inputs=base_model.input, outputs=x)\n    return model \n\ndef show_train_history(train_history,train,validation):\n    plt.plot(train_history.history[train])\n    plt.plot(train_history.history[validation])\n    plt.title('Train History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'validation'], loc='best')\n    plt.show()","bb11ca5f":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nweight_path=\"{}_weights.best.hdf5\".format('seg_model')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)\n\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                                   patience=1, verbose=1, mode='min',\n                                   min_delta=0.0001, cooldown=2, min_lr=1e-7)\n\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2,\n                      patience=5) # probably needs to be more patient, but kaggle time is limited\n\ncallbacks_list = [checkpoint, early, reduceLROnPlat]\n","95e80709":"\nmodel = Sequential()\n# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n# this applies 32 convolution filters of size 3x3 each.\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(20, 20, 3)))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n\ntrain_history  = model.fit(X_train, Y_train, batch_size=100, epochs=50, callbacks=callbacks_list, validation_split=0.2)\nscore = model.evaluate(X_test, Y_test, batch_size=100)","be456918":"show_train_history(train_history,'acc','val_acc')\n","e0d9905a":"score = model.evaluate(x=X_test,y=Y_test,batch_size=200)\nscore\nprint('Score Accuracy : {:.2f}%'.format(score[1]*100))\n","8350dd5d":"Let's visualize some examples of images and their label ","11c55d19":"We get a pretty good accuracy in a few epochs with a pretty basic conv network. ","03a944ea":"### Model Definition :","5139b8b9":"We have approximately 3 times more images with no aircraft on it. Maybe it would require some resampling or some weight classes in order to obtain better results","78565bdb":"We have built a dataframe containing the patch of each image and we extracted the label from the file title"}}