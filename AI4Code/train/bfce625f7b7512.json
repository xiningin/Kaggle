{"cell_type":{"f48bedf4":"code","4dc58100":"code","c4c24f37":"code","11585479":"code","ae1dfdce":"code","d88de55e":"code","c286878e":"code","2122dd10":"code","b4792b75":"code","f40d9f06":"markdown","8b1382c0":"markdown","259ed28a":"markdown","f1f2b5c9":"markdown","588dcc2c":"markdown","73c2e5cc":"markdown","51d60bb2":"markdown","4d1238ba":"markdown","cdf1a17a":"markdown","0058a90c":"markdown","3c11213f":"markdown"},"source":{"f48bedf4":"%matplotlib inline\n\nimport os\nimport gc\nfrom PIL import Image\n\nimport tqdm\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, LeakyReLU\nfrom keras.applications import VGG16\nfrom tensorflow import set_random_seed\nfrom sklearn.utils import check_random_state\n\n\nsns.set()\nnp.random.seed(0);\nset_random_seed(0);\ncheck_random_state(0);","4dc58100":"# Save the file path of each image and separate them to different classes\n#\n# Labels:\n# 0 -> benign\n# 1 -> malignant\n\ntrain_imgs, test_imgs = [], []\ntrain_labels, test_labels = [], []\n\nfor img_path in os.listdir('..\/input\/data\/train\/benign'):\n    train_imgs.append('..\/input\/data\/train\/benign\/' + img_path)\n    train_labels.append(0)\n    \nfor img_path in os.listdir('..\/input\/data\/train\/malignant'):\n    train_imgs.append('..\/input\/data\/train\/malignant\/' + img_path)\n    train_labels.append(1)\n    \nfor img_path in os.listdir('..\/input\/data\/test\/benign'):\n    test_imgs.append('..\/input\/data\/test\/benign\/' + img_path)\n    test_labels.append(0)\n    \nfor img_path in os.listdir('..\/input\/data\/test\/malignant'):\n    test_imgs.append('..\/input\/data\/test\/malignant\/' + img_path)\n    test_labels.append(1)\n    \ntrain_imgs, test_imgs = np.array(train_imgs), np.array(test_imgs)\ntrain_labels, test_labels = np.array(train_labels), np.array(test_labels)\n    \nclass_distribution = np.bincount(np.concatenate([train_labels, test_labels]))\n    \nprint('Size of train set:', len(train_imgs))\nprint('Size of test set:', len(test_imgs))\nprint(class_distribution[0], 'benign labeled samples and', class_distribution[1], 'malignant')","c4c24f37":"# Load the images to memory\nxtrain, xtest = [], []\nytrain, ytest = train_labels, test_labels\n\nfor filename in tqdm.tqdm(train_imgs):\n    xtrain.append(np.array(Image.open(filename)))\n    \nfor filename in tqdm.tqdm(test_imgs):\n    xtest.append(np.array(Image.open(filename)))\n    \ndel train_imgs, test_imgs, train_labels, test_labels\nxtrain, xtest = np.array(xtrain), np.array(xtest)\n\n# Merge and split train and test set to have more train data\ndata = np.concatenate([xtrain, xtest])\nlabels = np.concatenate([ytrain, ytest])\n\n# Spliting data to train, validation and test values\nxtrain, xtest, ytrain, ytest = train_test_split(data, labels, test_size=.1, random_state=0)\nxtra, xval, ytra, yval = train_test_split(xtrain, ytrain, test_size=.05, random_state=0, shuffle=False)\n\ngc.collect()\nprint('Shape of the new train set:', xtra.shape)\nprint('Shape of the new test set:', xtest.shape)\nprint('Shape of the validation set:', xval.shape)","11585479":"data_generator = ImageDataGenerator(rotation_range=90,\n                                    width_shift_range=0.15,\n                                    height_shift_range=0.15,\n                                    horizontal_flip=True,\n                                    vertical_flip=True,\n                                    brightness_range=[0.8, 1.1],\n                                    fill_mode='nearest')\n\nnew_samples, new_labels = next(data_generator.flow(xtra, ytra, batch_size=len(xtra)))\nxtra = np.concatenate([xtra, new_samples])\nytra = np.concatenate([ytra, new_labels])\n\ndel new_samples, new_labels\nprint('New number of training samples:', len(xtra))","ae1dfdce":"# Normalizing values\nxtra = xtra.astype('float32') \/ 255.\nxtest = xtest.astype('float32') \/ 255.\nxval = xval.astype('float32') \/ 255.\n\nprint('Training data shape:', xtra.shape)\nprint('Min value:', xtra.min())\nprint('Max value:', xtra.max())","d88de55e":"\"\"\"\n# the commented model\n# had 0.83 test accuracy\n\nmodel.add(Conv2D(32, (3, 3,), activation='relu', input_shape=(224, 224, 3,)))\nmodel.add(Conv2D(32, (3, 3,), activation='relu', padding='same'))\nmodel.add(MaxPooling2D((2, 2,)))\nmodel.add(Dropout(.25))\nmodel.add(Conv2D(64, (3, 3,), activation='relu', padding='same'))\nmodel.add(Conv2D(64, (3, 3,), activation='relu', padding='same'))\nmodel.add(MaxPooling2D((2, 2,)))\nmodel.add(Dropout(.4))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\"\"\"\n\n# Build the model\nmodel = Sequential()\n\nmodel.add(VGG16(include_top=False, input_shape=(224, 224, 3,)))\nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(LeakyReLU(0.001))\nmodel.add(Dense(16))\nmodel.add(LeakyReLU(0.001))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.layers[0].trainable = False\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\nmodel.summary()","c286878e":"# Train the model\nN_EPOCHS = 20\nh = model.fit(xtra, ytra, validation_data=(xval, yval), epochs=N_EPOCHS, batch_size=64)","2122dd10":"# Plotting accuracy history\nplt.figure(figsize=(15, 8))\nplt.scatter(range(N_EPOCHS), h.history['acc'], marker='x', label='Training accuracy');\nplt.plot(range(N_EPOCHS), h.history['val_acc'], color='green', label='Validation accuracy');\nplt.legend();\nplt.title('Accuracy');\n\n# Plotting loss history\nplt.figure(figsize=(15, 8))\nplt.scatter(range(N_EPOCHS), h.history['loss'], marker='x', label='Training loss');\nplt.plot(range(N_EPOCHS), h.history['val_loss'], color='green', label='Validation loss');\nplt.legend();\nplt.title('Loss');","b4792b75":"print('Accuracy on test set:', model.evaluate(xtest, ytest)[1])\nmodel.save('model.h5')","f40d9f06":"## Content\n\nThe data consists of two folders with each 1800 pictures (224x244) of the two types of moles.","8b1382c0":"Now I generate more training images by changing some of them.","259ed28a":"# Skin Cancer: Malignant vs Benign\nThis dataset contains a balanced dataset of images of benign skin moles and malignant skin moles.","f1f2b5c9":"Evaluate the model on test data to double check it's accuracy, and save it to this kernel.","588dcc2c":"## Building and training the model\n\nAfter this I build a CNN model in keras.","73c2e5cc":"Visualizing the accuracy and losses to check if the model is overfit.","51d60bb2":"Now we can train the model.","4d1238ba":"Use the simple normalization technique where we just divide each pixel value by `255`.","cdf1a17a":"### Acknowledgements\n\nAll the rights of the Data are bound to the ISIC-Archive rights (https:\/\/www.isic-archive.com\/#!\/topWithHeader\/wideContentTop\/main). I do not take any responsibility for the right-infringement of any kernels. Thus, do not monetize this any of your models done on this data :).\n\n## Inspiration\n\nI hope that with this dataset, some machine learning model might achieve better and cheaper prediction than a dermatologist. Have fun!\n\n_The second the third and the last markdown cells are from this dataset's [description](https:\/\/www.kaggle.com\/fanconic\/skin-cancer-malignant-vs-benign)_.","0058a90c":"## Data selection\n\nBecause of the size of the dataset I merge the train and the test sets to slice only 10% of the whole training data as the test set.\n\nThen I slice 7% of the train set to use it for validation.","3c11213f":"## Intro\n\nHealth is always a big topic, I really like the idea that Computers can help to make our lives healthier or can draw your attention more towards it.\n\nMaking a Machine Learning model which can recognize that our mole is bengin or malignant only from an image, makes me think that AI will make unimaginable changes in our lifes in the following decades or years.\n\nMaybe this kernel what you read is the part of this change. _Feel free to read, use or learn from it!_"}}