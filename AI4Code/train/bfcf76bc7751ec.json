{"cell_type":{"79c7ed7f":"code","672bcec7":"code","e79d24fc":"code","b5e1fdf6":"code","fa544151":"code","d4390c4c":"code","48f5b05f":"code","e1c52a27":"code","d3a29ad7":"code","0319cbc0":"code","7da54026":"code","6d6da0dd":"code","93e83f61":"code","37c58ce8":"code","cdf09872":"code","15c6a1d2":"code","03b68015":"code","6d9e3d30":"code","39f2fa60":"code","81919dc4":"code","e8ae96c8":"code","26fe02d8":"code","a55c74ea":"code","37e1e0b1":"code","32e523b8":"code","8fb18d87":"code","9411853a":"code","6c9ba649":"code","e9905896":"code","e9ce8899":"code","93af6d5f":"code","335f80d9":"code","ba911632":"code","056682dc":"code","ab515b86":"code","69dbeeff":"code","2399e9ce":"code","d6f59502":"code","924ca1a2":"code","b6228b09":"code","0e6bb46b":"markdown","7a8b0b73":"markdown","b2132d1f":"markdown","8a0333af":"markdown","639dadbb":"markdown","b580f61b":"markdown","01170490":"markdown","d2333c0b":"markdown","cf2131bc":"markdown","ed1f051b":"markdown","d37b3090":"markdown","31566ffa":"markdown","174e34e1":"markdown","b8e54205":"markdown","0e59be22":"markdown"},"source":{"79c7ed7f":"from torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as T\nimport torch\nimport torch.nn as nn\nimport os\nimport cv2\nfrom torchvision.utils import make_grid\nfrom torchvision.utils import save_image\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\n%matplotlib inline","672bcec7":"image_size = 128\nbatch_size = 128\nstats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\nDATA_DIR = '\/kaggle\/input\/'","e79d24fc":"train_ds = ImageFolder(DATA_DIR, transform=T.Compose([\n    T.Resize(image_size),\n    T.CenterCrop(image_size),\n    T.ToTensor(),\n    T.Normalize(*stats)]))\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)","b5e1fdf6":"def denorm(img_tensors):\n    return img_tensors * stats[1][0] + stats[0][0]","fa544151":"def show_images(images, nmax=64):\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n\ndef show_batch(dl, nmax=64):\n    for images, _ in dl:\n        show_images(images, nmax)\n        break","d4390c4c":"show_batch(train_dl)","48f5b05f":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","e1c52a27":"device = get_default_device()\ndevice","d3a29ad7":"train_dl = DeviceDataLoader(train_dl, device)","0319cbc0":"discriminator = nn.Sequential(\n    # in: 3 x 128 x 128\n\n    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 64 x 64 x 64\n\n    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 128 x 32 x 32\n\n    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 256 x 16 x 16\n\n    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 512 x 8 x 8\n    \n    nn.Conv2d(512, 1028, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(1028),\n    nn.LeakyReLU(0.2, inplace=True),\n    # out: 1028 x 4 x 4\n\n    nn.Conv2d(1028, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    # out: 1 x 1 x 1\n\n    nn.Flatten(),\n    nn.Sigmoid())","7da54026":"discriminator = to_device(discriminator, device)","6d6da0dd":"latent_size = 128","93e83f61":"generator = nn.Sequential(\n    # in: latent_size x 1 x 1\n\n    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n    nn.BatchNorm2d(512),\n    nn.ReLU(True),\n    # out: 512 x 4 x 4\n    \n    \n    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.ReLU(True),\n    # out: 256 x 8 x 8\n\n    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    # out: 128 x 16 x 16\n    \n    \n    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    # out: 64 x 32 x 32\n        \n    nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(32),\n    nn.ReLU(True),\n    # out: 32 x 64 x 64\n    \n    nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.Tanh()\n    # out: 3 x 128 x 128\n\n\n)","37c58ce8":"xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\nfake_images = generator(xb)\nprint(fake_images.shape)\nshow_images(fake_images)","cdf09872":"generator = to_device(generator, device)","15c6a1d2":"def train_discriminator(real_images, opt_d):\n    # Clear discriminator gradients\n    opt_d.zero_grad()\n\n    # Pass real images through discriminator\n    real_preds = discriminator(real_images)\n    real_targets = torch.ones(real_images.size(0), 1, device=device)\n    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n    real_score = torch.mean(real_preds).item()\n    \n    # Generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n    fake_images = generator(latent)\n\n    # Pass fake images through discriminator\n    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n    fake_preds = discriminator(fake_images)\n    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n    fake_score = torch.mean(fake_preds).item()\n\n    # Update discriminator weights\n    loss = real_loss + fake_loss\n    loss.backward()\n    opt_d.step()\n    return loss.item(), real_score, fake_score","03b68015":"def train_generator(opt_g):\n    # Clear generator gradients\n    opt_g.zero_grad()\n    \n    # Generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n    fake_images = generator(latent)\n    \n    # Try to fool the discriminator\n    preds = discriminator(fake_images)\n    targets = torch.ones(batch_size, 1, device=device)\n    loss = F.binary_cross_entropy(preds, targets)\n    \n    # Update generator weights\n    loss.backward()\n    opt_g.step()\n    \n    return loss.item()","6d9e3d30":"sample_dir = 'generated'\nos.makedirs(sample_dir, exist_ok=True)","39f2fa60":"def save_samples(index, latent_tensors, show=True):\n    fake_images = generator(latent_tensors)\n    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n    print('Saving', fake_fname)\n    if show:\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))","81919dc4":"fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)","e8ae96c8":"save_samples(0, fixed_latent)","26fe02d8":"def fit(epochs, lr, start_idx=1):\n    torch.cuda.empty_cache()\n    \n    # Losses & scores\n    losses_g = []\n    losses_d = []\n    real_scores = []\n    fake_scores = []\n    \n    # Create optimizers\n    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n    \n    for epoch in range(epochs):\n        for real_images, _ in tqdm(train_dl):\n            # Train discriminator\n            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n            # Train generator\n            loss_g = train_generator(opt_g)\n            \n        # Record losses & scores\n        losses_g.append(loss_g)\n        losses_d.append(loss_d)\n        real_scores.append(real_score)\n        fake_scores.append(fake_score)\n        \n        # Log losses & scores (last batch)\n        print(\"Epoch [{}\/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n    \n        # Save generated images\n        save_samples(epoch+start_idx, fixed_latent, show=False)\n    \n    return losses_g, losses_d, real_scores, fake_scores","a55c74ea":"lr = 0.00015\nepochs = 45","37e1e0b1":"history = fit(epochs, lr)","32e523b8":"losses_g, losses_d, real_scores, fake_scores = history","8fb18d87":"# Save the model checkpoints \ntorch.save(generator.state_dict(), 'G.ckpt')\ntorch.save(discriminator.state_dict(), 'D.ckpt')","9411853a":"Image('.\/generated\/generated-images-0001.png')","6c9ba649":"Image('.\/generated\/generated-images-0002.png')","e9905896":"Image('.\/generated\/generated-images-0003.png')","e9ce8899":"Image('.\/generated\/generated-images-0005.png')","93af6d5f":"Image('.\/generated\/generated-images-0007.png')","335f80d9":"Image('.\/generated\/generated-images-0009.png')","ba911632":"Image('.\/generated\/generated-images-0012.png')","056682dc":"Image('.\/generated\/generated-images-0015.png')","ab515b86":"Image('.\/generated\/generated-images-0018.png')","69dbeeff":"Image('.\/generated\/generated-images-0021.png')","2399e9ce":"Image('.\/generated\/generated-images-0025.png')","d6f59502":"Image('.\/generated\/generated-images-0030.png')","924ca1a2":"plt.plot(real_scores, '-')\nplt.plot(fake_scores, '-')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real', 'Fake'])\nplt.title('Scores');","b6228b09":"plt.plot(losses_d, '-')\nplt.plot(losses_g, '-')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","0e6bb46b":"### Final Thoughts and Conclusion","7a8b0b73":"### Save Outputs","b2132d1f":"### Generator Network","8a0333af":"### Load in the Data","639dadbb":"### Discriminator Network","b580f61b":"### Introduction","01170490":"### Import Libraries","d2333c0b":"### Generator Training","cf2131bc":"### Define Fit Function","ed1f051b":"### Visualize the Outputs","d37b3090":"Overall, the results were not great. I mentioned several issues with the training set in the introduction, which have likely resulted in the confusing images. Furthermore, the images seen in the later epochs have learned some specific patterns of shading that can trick a discriminator, but certainly cannot trick a human. It's a good start! I will try on a different dataset for my next project. Again, please upvote if you enjoyed my work - I'm trying to get to expert level!!\n![](http:\/\/i.redd.it\/xtzec4m0s1d51.jpg)","31566ffa":"Hello everyone! Today I will be attempting to use Generative Adverserial Networks (GANs) to learn from a dataset of over 60,000 car images in order to generate completely new, never before seen car models. I want to say thanks to Paul, who kindly provided the dataset here: https:\/\/www.kaggle.com\/prondeau\/the-car-connection-picture-dataset. It should be noted that the dataset contains images of widely different cars, in very different backgrounds, with vastly different angles and magnifications. These typically reduce the ability of a GAN to learn, but we will do our best! Let's begin.","174e34e1":"# Car Image Generator using GANs\n## By Sergei Issaev","b8e54205":"### Train and Save the Model","0e59be22":"### Discriminator Training"}}