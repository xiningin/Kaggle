{"cell_type":{"b0844390":"code","e72d0c1f":"code","b6a83bf1":"code","65db316d":"code","6a3662ae":"code","dac77f29":"code","f3bff09b":"code","eaeade43":"code","6352c285":"code","576c73a7":"code","bcc8970b":"code","10a1794b":"code","3ae2c635":"code","668da583":"code","823ca9c0":"code","f255d04f":"code","f1b6832d":"code","f1d25ed4":"code","9f3e7f4d":"code","88f856f2":"markdown","9be956da":"markdown","19104917":"markdown","265a6c01":"markdown","decc8d8a":"markdown","49053c94":"markdown"},"source":{"b0844390":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e72d0c1f":"train_data = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/train.csv\")\ntest_data = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/test.csv\")","b6a83bf1":"train_data.head()","65db316d":"train_data.describe()","6a3662ae":"!pip install autoviz\n!pip install xlrd","dac77f29":"#importing Autoviz class\nfrom autoviz.AutoViz_Class import AutoViz_Class\n#Instantiate the AutoViz class\nAV = AutoViz_Class()\nfilepath = '..\/input\/tabular-playground-series-apr-2021\/train.csv'\ndf = AV.AutoViz(filepath, depVar='Survived', header=1)","f3bff09b":"train_data.isnull().sum()","eaeade43":"test_data.isnull().sum()","6352c285":"from sklearn.preprocessing import LabelEncoder\n\ncat_columns = ['Sex','Embarked']\n\nlabel_train = train_data.copy()\nlabel_test = test_data.copy()\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in cat_columns:\n    label_train[col] = label_encoder.fit_transform(train_data[col])\n    label_test[col] = label_encoder.transform(test_data[col])","576c73a7":"features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']","bcc8970b":"from sklearn.impute import SimpleImputer\n\n# Imputation\nsimple_impute = SimpleImputer()\nimputed_X_train = pd.DataFrame(simple_impute.fit_transform(label_train[features]))\nimputed_X_test = pd.DataFrame(simple_impute.transform(label_test[features]))\n\n# Imputation removed column names; put them back\nimputed_X_train.columns = label_train[features].columns\nimputed_X_test.columns = label_test[features].columns\n\ny_train_data = label_train['Survived']","10a1794b":"from sklearn.feature_selection import mutual_info_classif as mif","3ae2c635":"mif(imputed_X_train,y_train_data)","668da583":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier \nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier","823ca9c0":"models = [DecisionTreeClassifier(),RandomForestClassifier(),KNeighborsClassifier(),GradientBoostingClassifier(),LGBMClassifier(),XGBClassifier()]\n\nfor model in models:\n    X_train, X_valid, y_train, y_valid = train_test_split(imputed_X_train,y_train_data,test_size=0.1,random_state=42)\n    model.fit(X_train, y_train)\n    accuracy = accuracy_score(y_valid,model.predict(X_valid))\n    print(\"Model : {0} Accuracy : {1}\".format(model,accuracy))","f255d04f":"X_train, X_valid, y_train, y_valid = train_test_split(imputed_X_train,y_train_data,test_size=0.1,random_state=42)\nmodel = LGBMClassifier()\nmodel.fit(X_train, y_train)\naccuracy = accuracy_score(y_valid,model.predict(X_valid))\nprint(\"Model : {0} Accuracy : {1}\".format(model,accuracy))\ny_pred = model.predict(imputed_X_test)","f1b6832d":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv\")","f1d25ed4":"submission['Survived'] = y_pred","9f3e7f4d":"submission.to_csv(\"submission.csv\",index=False)","88f856f2":"Will be tuning the hyperparameters for the LGBM model and also do some feature improvements if possible in the next notebook","9be956da":"# As a part of starter notebook would be running some data visualizations to understand the data and put in some insights","19104917":"# Lable Encoding and imputing the data","265a6c01":"# Visualizing using AutoViz","decc8d8a":"**Base model zeroed down to LGBM as it gives best accuracy on validation**","49053c94":"# Running some base Models"}}