{"cell_type":{"940a1535":"code","5d70b9be":"code","dfd8cf65":"code","045a2ca6":"code","0aa2faab":"code","cc055066":"code","14d132b5":"code","39e0f95a":"code","1880f552":"code","a27bf605":"code","57d4d4ec":"code","b4d57808":"code","32e8370b":"code","2f1d27f9":"code","08eff545":"code","b01c10d3":"code","21b6ce6d":"code","fb39dee3":"code","dba7b31f":"code","7e17b36c":"code","e0e91122":"code","83a264fe":"code","959c4193":"code","625d4cf2":"code","ce7196e1":"markdown","1ceca450":"markdown","e00d6d8d":"markdown","bed6de89":"markdown","00ad1429":"markdown","efcd4351":"markdown","dfaa01dc":"markdown","bcb95874":"markdown","0c5f96a5":"markdown","09640616":"markdown","47c866cd":"markdown"},"source":{"940a1535":"import os\nimport pandas as pd\n# visulization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom keras.models import Sequential, Model\nfrom keras.models import load_model\nfrom keras.layers import Input, Dense, Conv2D, MaxPool2D ,AveragePooling2D, Flatten, Add\nfrom keras.layers import Dropout, BatchNormalization, Activation\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks.callbacks import ModelCheckpoint, EarlyStopping","5d70b9be":"TRAIN_DIR = '..\/input\/state-farm-distracted-driver-detection\/imgs\/train\/'\nTEST_DIR = '..\/input\/state-farm-distracted-driver-detection\/imgs\/test\/'","dfd8cf65":"IMG_HEIGHT = 240\nIMG_WIDTH = 320","045a2ca6":"EPOCHS=10\nBATCH_SIZE=32","0aa2faab":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)\n\ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                color_mode='grayscale', classes=None, class_mode='categorical',\n                                batch_size=BATCH_SIZE, shuffle=True, subset='training')\n\nvalid_generator = train_datagen.flow_from_directory(TRAIN_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                color_mode='grayscale', classes=None, class_mode='categorical',\n                                batch_size=BATCH_SIZE, shuffle=True, subset='validation')","cc055066":"MODELS_DIR = \"saved_models\"\nif not os.path.exists(MODELS_DIR):\n    os.makedirs(MODELS_DIR)","14d132b5":"filepath = MODELS_DIR+'\/epoch{epoch:02d}-loss{loss:.2f}-val_loss{val_loss:.2f}.hdf5'\n# checkpoint\nmodel_checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \n                                   save_best_only=True, save_weights_only=False, mode='min', period=1)\n\n# early stopping: patience = epochs\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1,\n                               mode='min', baseline=None, restore_best_weights=True)","39e0f95a":"def plot_model_loss(history):\n    plt.plot(history['loss'])\n    plt.plot(history['val_loss'])\n    plt.title('Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'valid'], loc='upper left')\n    plt.show()\n    ","1880f552":"# use stride 2 in the middle to reduce size and increase no. of filters\n# use avgpool at the end (not maxpool)\ndef seq_conv_block(model, filters=32):\n    model.add(Conv2D(filters=filters, kernel_size=(3,3), strides=2, padding=\"same\"))\n    model.add(BatchNormalization(axis=-1))\n    model.add(Activation(\"relu\"))\n    return model\n\n# all conv layers  with strides=1\nmodel = Sequential(name=\"seq_conv_rmsprop\")\n\nmodel.add(Conv2D(input_shape=(IMG_HEIGHT,IMG_WIDTH,1), filters=16, kernel_size=(3,3), padding=\"same\"))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation(\"relu\"))\n\nmodel = seq_conv_block(model, filters=32)\nmodel = seq_conv_block(model, filters=64)\nmodel = seq_conv_block(model, filters=128)\n\nmodel.add(AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(500))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation(\"relu\"))\n\nmodel.add(Dense(10, activation=\"softmax\"))\n\n# sgd = optimizers.SGD(lr=0.01, clipvalue=0.5)\n# optimizer = RMSprop(learning_rate=0.001)\n# adad = Adam(learning_rate=0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nmodel.summary()","a27bf605":"history_v1 = model.fit_generator(train_generator,\n                         steps_per_epoch = train_generator.samples \/\/ BATCH_SIZE,\n                         epochs = EPOCHS, \n                         callbacks=[early_stopping, model_checkpoint],\n                         verbose = 1,\n                         validation_data = valid_generator,\n                         validation_steps = valid_generator.samples \/\/ BATCH_SIZE)","57d4d4ec":"# load saved model\n# model = load_model('saved_models\/epoch03-loss0.10-val_loss0.07.hdf5')","b4d57808":"plot_model_loss(history_v1.history)","32e8370b":"loss, accuracy = model.evaluate_generator(valid_generator, steps=valid_generator.samples \/\/ BATCH_SIZE)\nprint(\"Loss:\",loss)\nprint(\"Accuracy:\", accuracy)","2f1d27f9":"os.makedirs('test\/all_files')\n!cp -r $TEST_DIR test\/all_files\/","08eff545":"TEST_DIR = 'test'\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_datagen.flow_from_directory(TEST_DIR, target_size=(IMG_HEIGHT, IMG_WIDTH),\n                                color_mode='grayscale', classes=None, class_mode=None,\n                                batch_size=BATCH_SIZE, shuffle=False)\n\n\n","b01c10d3":"test_generator.reset()\n# test_generator.filenames","21b6ce6d":"def prepare_submission_df(predictions, ids):\n    result_df = pd.DataFrame(predictions, columns=[\"c0\",\"c1\",\"c2\",\"c3\",\"c4\",\"c5\",\"c6\",\"c7\",\"c8\",\"c9\"])\n    result_df['img'] = ids\n    return result_df","fb39dee3":"predictions = model.predict_generator(test_generator, steps=len(test_generator.filenames)\/BATCH_SIZE)","dba7b31f":"ids = [os.path.basename(p) for p in test_generator.filenames]\nfinal_df = prepare_submission_df(predictions, ids)","7e17b36c":"final_df.to_csv(\"submission.csv\", index=False)","e0e91122":"# !pip install kaggle\n# !kaggle competitions submit -c state-farm-distracted-driver-detection -f submission.csv -m \"First Submission.\"","83a264fe":"def conv_layer(inputs, filters=16, num_strides=1):\n    return Conv2D(filters=filters, kernel_size=(3,3), strides=num_strides, padding='same')(inputs)\n\ndef conv_block(inputs, filters=16, num_strides=1):\n    x = conv_layer(inputs, filters, num_strides)\n    x = BatchNormalization(axis=-1)(x)\n    x = Activation('relu')(x)\n    return x\n    \ndef resnet_block(inputs, filters=16):\n    x_shortcut = inputs\n    x = conv_block(inputs, filters)\n    x = BatchNormalization(axis=-1)(x)\n    x = Add()([x,x_shortcut]) # skip connection\n    x = Activation('relu')(x)\n    return x\n    \n\ninputs = Input(shape=(IMG_HEIGHT,IMG_WIDTH,1))\n\noutput_0 = conv_block(inputs=inputs, filters=16)\n\noutput_1 = conv_block(output_0, filters=32, num_strides=2)\noutput_1 = resnet_block(output_1, filters=32)\n\noutput_2 = conv_block(output_1, filters=64, num_strides=2)\noutput_2 = resnet_block(output_2, filters=64)\n\noutput_3 = conv_block(output_2, filters=128, num_strides=2)\noutput_3 = resnet_block(output_3, filters=128)\n\noutput_3 = AveragePooling2D(pool_size=(2,2), strides=(2,2))(output_3)\n\noutput_4 = Flatten()(output_3)\noutput_4 = Dropout(0.5)(output_4)\n\noutput_5 = Dense(500)(output_4)\noutput_5 = Dropout(0.5)(output_5)\noutput_5 = BatchNormalization(axis=-1)(output_5)\noutput_5 = Activation('relu')(output_5)\n\noutput_6 = Dense(10, activation='softmax')(output_5)\n\nres_model = Model(inputs=inputs, outputs=output_6, name=\"res_model\")\n\nres_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\nres_model.summary()","959c4193":"# history_v2 = res_model.fit_generator(train_generator,\n#                          steps_per_epoch = train_generator.samples \/\/ BATCH_SIZE,\n#                          epochs = EPOCHS, \n#                          callbacks=[early_stopping, model_checkpoint],\n#                          verbose = 1,\n#                          validation_data = valid_generator,\n#                          validation_steps = valid_generator.samples \/\/ BATCH_SIZE)\n# model_v2 = res_model","625d4cf2":"# plot_model_loss(history_v2.history)","ce7196e1":"## Import Dependencies:","1ceca450":"## Resnet like model","e00d6d8d":"## Basic CNN\nconv > batch_norm > relu\n","bed6de89":"Things to consider  in keras model building:\n- No Dropout after Conv layer\n- Use dropout after dense layer (use mostly at the end of arch to not loose data)\n- Use BatchNorm before any activation function\n\n### Regularizers:\n- Dropout\n- Weigth Decay (L2) i.e. weights should be smaller. Penalizes model complexity.\n- BatchNorm (is a most)\n- Data Augmentation: e.g. fix lightning in images\n","00ad1429":"## Train model:","efcd4351":"## Prepare Training Data Generator:","dfaa01dc":"## Make Prediction:","bcb95874":"# Outline\n1. Import Dependencies\n2. Prepare Training DataGenerator\n2. Build Model\n4. Train Model\n5. Make Predictions\n","0c5f96a5":"## Build Model:","09640616":"Room for improvement:\n- Progressive Resizing\n- Data Augmentation","47c866cd":"### Setup Callbacks:"}}