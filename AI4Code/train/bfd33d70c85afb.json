{"cell_type":{"5912082d":"code","76abeab0":"code","cf1424c3":"code","482efa7a":"code","bbdfcb8c":"code","acce90c9":"code","5c7da097":"code","f01a4d4d":"code","0ad13e0c":"code","03855317":"code","52013d6a":"code","8b4d4e29":"code","a51d4f20":"code","137323d9":"code","ba832433":"code","9a7d4456":"code","86f4209a":"code","20bf5188":"code","010b6c01":"code","5de5cb60":"code","a46ca80a":"code","428dcc0e":"code","2317b008":"code","585d2d59":"code","6131cf76":"code","48c9a96c":"code","2cecf387":"code","58b91698":"code","4aac0069":"code","c14c3eb0":"code","b5c6106d":"code","ba77de9e":"code","5ee03ece":"code","5186110c":"code","66e09c8d":"code","a40f8576":"code","71f0113b":"code","9e1ab00c":"code","80b978c6":"code","30edcbae":"code","9df8bc05":"code","0a426194":"code","a8172121":"markdown","4efb5ecc":"markdown","12d60f9b":"markdown","c56da310":"markdown","323482e7":"markdown","9677531d":"markdown","53b0469d":"markdown","469797e5":"markdown","790e5109":"markdown","0b5ffe7e":"markdown","f9f2130b":"markdown"},"source":{"5912082d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76abeab0":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib as plt\n%matplotlib inline","cf1424c3":"df = pd.read_csv(\"\/kaggle\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv\")\ndf.head()","482efa7a":"\ndf.describe()","bbdfcb8c":"df.info()","acce90c9":"# find the null  values\n\ndf.isnull().sum()","5c7da097":"# fill the missing values for numerical terms - mean\ndf['LoanAmount']=df['LoanAmount'].fillna(df['LoanAmount'].mean())\ndf['Loan_Amount_Term']=df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mean())\ndf['Credit_History']=df['Credit_History'].fillna(df['Credit_History'].mean())","f01a4d4d":"# fill the missing values for categorical terms - mode\ndf['Gender']=df['Gender'].fillna(df['Gender'].mode()[0])\ndf['Married']=df['Married'].fillna(df['Married'].mode()[0])\ndf['Dependents']=df['Dependents'].fillna(df['Dependents'].mode()[0])\ndf['Self_Employed']=df['Self_Employed'].fillna(df['Self_Employed'].mode()[0])","0ad13e0c":"df.isnull().sum()","03855317":"sns.countplot(df['Gender'])","52013d6a":"sns.countplot(df['Dependents'])","8b4d4e29":"sns.countplot(df['Education'])","a51d4f20":"sns.countplot(df['Self_Employed'])","137323d9":"sns.countplot(df['Property_Area'])","ba832433":"sns.countplot(df['Loan_Status'])","9a7d4456":"sns.distplot(df['ApplicantIncome'])","86f4209a":"# apply Log Transformation to the attribute\ndf['ApplicantIncome']=np.log(df['ApplicantIncome'])","20bf5188":"sns.distplot(df['ApplicantIncome'])","010b6c01":"sns.distplot(df['CoapplicantIncome'])","5de5cb60":"\ndf['CoapplicantIncome']=np.log(df['CoapplicantIncome']+1)","a46ca80a":"sns.distplot(df['CoapplicantIncome'])","428dcc0e":"sns.distplot(df['LoanAmount'])","2317b008":"df['LoanAmount']=np.log(df['LoanAmount']+1)","585d2d59":"sns.distplot(df['LoanAmount'])","6131cf76":"sns.distplot(df['Loan_Amount_Term'])","48c9a96c":"df['Loan_Amount_Term']=np.log(df['Loan_Amount_Term'])","2cecf387":"sns.distplot(df['Loan_Amount_Term'])","58b91698":"sns.distplot(df['Credit_History'])","4aac0069":"# total income\ndf['Total_Income']=df['ApplicantIncome'] + df['CoapplicantIncome']\ndf.head()","c14c3eb0":"corr = df.corr()\nsns.heatmap(corr,annot=True, cmap='BuPu')","b5c6106d":"df.head()","ba77de9e":"# drop unnecessary columns\ncols = ['Loan_ID', 'CoapplicantIncome']\ndf=df.drop(columns=cols, axis=1)\ndf.head()","5ee03ece":"from sklearn.preprocessing import LabelEncoder\ncols=['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status', 'Dependents']\nle=LabelEncoder()\nfor col in cols:\n    df[col]=le.fit_transform(df[col])","5186110c":"df.head()","66e09c8d":"# Specify input and output attributes\nX=df.drop(columns=['Loan_Status'],axis=1)\ny=df['Loan_Status']","a40f8576":"from sklearn.model_selection import train_test_split\nX_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)","71f0113b":"# classify function\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\ndef classify(model,x,y):\n    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=42)\n    model.fit(x_train,y_train)\n    print(\"Accuracy is \", model.score(x_test,y_test)*100)\n    score=cross_val_score(model,x,y,cv=5)\n    print(\"Cross validation is ,\" ,np.mean(score)*100)\n    y_pred=model.predict(x_test)\n    confusionmatrix(y_pred,y_test)\ndef confusionmatrix(y_pred,y_test):\n    cm=confusion_matrix(y_test,y_pred)\n    print(cm)\n    sns.heatmap(cm,annot=True)","9e1ab00c":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nclassify(model,X,y)","80b978c6":"from sklearn.tree import DecisionTreeClassifier\nmodel = DecisionTreeClassifier()\nclassify(model,X,y)","30edcbae":"from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\nmodel = RandomForestClassifier()\nclassify(model,X,y)","9df8bc05":"model = ExtraTreesClassifier()\nclassify(model,X,y)","0a426194":"model = RandomForestClassifier(n_estimators=100,min_samples_split=25, max_depth=7,max_features=1)\nclassify(model, X,y)","a8172121":"## Train-Test Split","4efb5ecc":"### Creation of new attributes","12d60f9b":"### Numerical attributes visualization","c56da310":"## Coorelation Matrix","323482e7":"## Model Training","9677531d":"## Preprocessing of Dataset","53b0469d":"## Hyperparameter Tuning","469797e5":"### Categorical Attributes Visualization","790e5109":"## Loading the dataset ","0b5ffe7e":"## Label Encoding","f9f2130b":"## Exploratory Data Analysis"}}