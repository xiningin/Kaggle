{"cell_type":{"7e1b8017":"code","5c774e97":"code","67248e23":"code","f4767649":"code","2d29b430":"code","71b4f095":"code","98da1d05":"markdown","92c89e18":"markdown"},"source":{"7e1b8017":"# LOAD LIBRARIES\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Reshape\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nimport matplotlib.pyplot as plt\n\n# LOAD THE DATA\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\nY_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1)\nX_test = test\n\nX_train_inverted = 255 - X_train\nX_test_inverted = 255 - X_test\n\nY_train = to_categorical(Y_train, num_classes = 10)\n\nX_train = X_train.values.reshape(-1, 28, 28, 1) \/ 255.0 \nX_test = X_test.values.reshape(-1, 28, 28, 1) \/ 255.0\nX_train_inverted = X_train_inverted.values.reshape(-1, 28, 28, 1) \/ 255.0\nX_test_inverted = X_test_inverted.values.reshape(-1, 28, 28, 1) \/ 255.0","5c774e97":"plt.figure()\nplt.subplot(121)\nplt.imshow(X_train[0][:,:,0], cmap='gray')\nplt.subplot(122)\nplt.imshow(X_train_inverted[0][:,:,0], cmap='gray')","67248e23":"def create_model():\n    model = Sequential()\n    model.add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n            input_shape=(28,28,1)))\n    model.add(MaxPool2D())\n    model.add(Conv2D(48,kernel_size=5,padding='same',activation='relu'))\n    model.add(MaxPool2D())\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model","f4767649":"val_acc_normal = []\nfor run in range(10):\n    model = create_model()\n    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train, Y_train, test_size = 0.333)\n    # TRAIN NETWORKS\n    epochs = 20\n    history = model.fit(X_train2,Y_train2, batch_size=128, epochs = epochs, \n            validation_data = (X_val2,Y_val2), verbose=0)\n    val_acc_normal.append(max(history.history['val_acc']))\n    print(\"Run {0}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(run + 1, epochs, max(history.history['acc']),max(history.history['val_acc']) ))\nprint(\"Average validation accuracy: {:.5f}\".format(sum(val_acc_normal) \/ len(val_acc_normal)))","2d29b430":"val_acc_inverted = []\nfor run in range(10):\n    model = create_model()\n    X_train2, X_val2, Y_train2, Y_val2 = train_test_split(X_train_inverted, Y_train, test_size = 0.333)\n    # TRAIN NETWORKS\n    epochs = 20\n    history = model.fit(X_train2,Y_train2, batch_size=128, epochs = epochs, \n            validation_data = (X_val2,Y_val2), verbose=0)\n    val_acc_inverted.append(max(history.history['val_acc']))\n    print(\"Run {0}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(run + 1, epochs, max(history.history['acc']),max(history.history['val_acc']) ))\nprint(\"Average validation accuracy: {:.5f}\".format(sum(val_acc_inverted) \/ len(val_acc_inverted)))","71b4f095":"from scipy.stats import ttest_ind\nttest_ind(val_acc_normal, val_acc_inverted)","98da1d05":"# Experiment 1 (Normal MNIST)","92c89e18":"# Experiment 2 (Inverted MNIST)"}}