{"cell_type":{"f58975b6":"code","1868bdc3":"code","1362fdb2":"code","12256368":"code","1b3d4442":"code","1ac30735":"code","f5709872":"code","24a65d2e":"code","6347cb0b":"code","4d5a1e9f":"code","717a6165":"code","9adc3eba":"code","a5e8f4d4":"code","853c52c2":"code","54ce05d5":"code","b9f62e4d":"code","fad4bc3b":"code","404a77da":"code","db029592":"code","526a6113":"code","51c5244c":"code","5d1b7666":"code","2fa1d9d7":"code","7d9c9dc5":"code","b116bc47":"code","9581e31b":"code","9eec7025":"code","4a28c44c":"markdown","0e848f11":"markdown","e0b9ca1e":"markdown","0cb23c7b":"markdown","e7836b0b":"markdown","967a84f6":"markdown","dbc4de9a":"markdown","14a02c46":"markdown"},"source":{"f58975b6":"import tensorflow as tf        \nimport matplotlib.pyplot as plt\nimport numpy as np","1868bdc3":"base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')","1362fdb2":"base_model.summary()","12256368":"len(base_model.layers)","1b3d4442":"names = ['mixed3', 'mixed5', 'mixed8', 'mixed9'] ","1ac30735":"base_model.input","f5709872":"layers = [base_model.get_layer(nome).output for nome in names]\nlayers","24a65d2e":"deep_dream_model = tf.keras.Model(inputs = base_model.input, outputs = layers)","6347cb0b":"deep_dream_model.output","4d5a1e9f":"image = tf.keras.preprocessing.image.load_img('..\/input\/neural-networks-homer-and-bart-classification\/homer_bart_1\/homer26.bmp',\n                                               target_size=(350,375))","717a6165":"plt.imshow(image);","9adc3eba":"type(image)","a5e8f4d4":"image.size","853c52c2":"image = tf.keras.preprocessing.image.img_to_array(image)","54ce05d5":"type(image)","b9f62e4d":"image.shape","fad4bc3b":"image = tf.keras.applications.inception_v3.preprocess_input(image)","404a77da":"image.min(), image.max()","db029592":"image_batch = tf.expand_dims(image, axis = 0)\nimage_batch.shape","526a6113":"activations = deep_dream_model.predict(image_batch)","51c5244c":"len(activations)","5d1b7666":"def calculate_error(image, network):\n  image_batch = tf.expand_dims(image, axis = 0)\n  activations = network(image_batch)\n  mistakes = []\n  for activation in activations:\n    media = tf.math.reduce_mean(activation)\n    mistakes.append(media)\n\n  return tf.reduce_sum(mistakes)","2fa1d9d7":"loss = calculate_error(image, deep_dream_model)\nloss","7d9c9dc5":"@tf.function\ndef deep_dream(network, image, learning_rate):\n  with tf.GradientTape() as tape:\n    tape.watch(image)\n    mistakes = calculate_error(image, network)\n\n  gradientes = tape.gradient(mistakes, image) \n  gradientes \/= tf.math.reduce_std(gradientes)\n  image = image + gradientes * learning_rate\n  image = tf.clip_by_value(image, -1, 1)\n\n  return mistakes, image","b116bc47":"def convert_image(image):\n  image = 255 * (image + 1.0) \/ 2.0\n  return tf.cast(image, tf.uint8)","9581e31b":"def run_deep_dream(network, image, epochs, learning_rate):\n  for epoch in range(epochs):\n    erro, image = deep_dream(network, image, learning_rate)\n    if epoch % 200 == 0:\n      plt.figure(figsize=(12,12))\n      plt.imshow(convert_image(image))\n      plt.show()\n      print('\u00c9poca {}, loss {}'.format(epoch, erro))","9eec7025":"run_deep_dream(deep_dream_model, image, 8000, 0.001)","4a28c44c":"# Generation of Images","0e848f11":"# Trained convolutional neural network loading","e0b9ca1e":"# Import from libraries","0cb23c7b":"# Image Loading and Processing","e7836b0b":"# **If you find this notebook useful, support with an upvote** \ud83d\udc4d","967a84f6":"# Gradient climb","dbc4de9a":"# Neural Network Activations","14a02c46":"# Error calculation (loss)"}}