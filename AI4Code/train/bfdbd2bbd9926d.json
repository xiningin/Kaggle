{"cell_type":{"9b86e157":"code","64adfa67":"code","14c0db14":"code","56e2b046":"code","40a40965":"code","308442ab":"code","201ba100":"code","59ebd3c3":"code","5cf648d1":"code","cd0504ca":"code","c1d6f337":"code","e45707a0":"markdown","d9696e1f":"markdown","67510fef":"markdown","8c51dd39":"markdown","e517dd4c":"markdown","5241b6df":"markdown","788aada2":"markdown"},"source":{"9b86e157":"## load the libraries \nfrom keras.layers import Dense, Input, Conv2D, LSTM, MaxPool2D, UpSampling2D\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import to_categorical\nfrom numpy import argmax, array_equal\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom imgaug import augmenters\nfrom random import randint\nimport pandas as pd\nimport numpy as np","64adfa67":"# read dataset \ntrain = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntrain_x = train[list(train.columns)[1:]].values\ntrain_y = train['label'].values\n\n# normalize and reshape the predictors  \ntrain_x = train_x \/ 255\n\n# split training data(80%) and validation data(20%) datasets\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2)\n","14c0db14":"image = plt.imread(train_x[0])\nplt.show(image)","56e2b046":" read dataset \ntrain = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntrain_x = train[list(train.columns)[1:]].values\ntrain_y = train['label'].values\n\n# normalize and reshape the predictors  \ntrain_x = train_x \/ 255\n\n# split training data(80%) and validation data(20%) datasets\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2)\n\n## reshape the inputs\ntrain_x = train_x.reshape(-1, 784)\nval_x = val_x.reshape(-1, 784)","40a40965":"train_x[0]","308442ab":"## input layer\ninput_layer = Input(shape=(784,))\n\n## encoding architecture\nencode_layer1 = Dense(1500, activation='relu')(input_layer)\nencode_layer2 = Dense(1000, activation='relu')(encode_layer1)\nencode_layer3 = Dense(500, activation='relu')(encode_layer2)\n\n## latent view\nlatent_view   = Dense(10, activation='sigmoid')(encode_layer3)\n\n## decoding architecture\ndecode_layer1 = Dense(500, activation='relu')(latent_view)\ndecode_layer2 = Dense(1000, activation='relu')(decode_layer1)\ndecode_layer3 = Dense(1500, activation='relu')(decode_layer2)\n\n## output layer\noutput_layer  = Dense(784)(decode_layer3)\n\nmodel = Model(input_layer, output_layer)","201ba100":"model.summary()","59ebd3c3":"model.compile(optimizer='adam', loss='mse')\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\nmodel.fit(train_x, train_x, epochs=20, batch_size=2048, validation_data=(val_x, val_x), callbacks=[early_stopping])","5cf648d1":"preds = model.predict(val_x)","cd0504ca":"from PIL import Image \nf, ax = plt.subplots(1,5)\nf.set_size_inches(80, 40)\nfor i in range(5):\n    ax[i].imshow(val_x[i].reshape(28, 28))\nplt.show()","c1d6f337":"f, ax = plt.subplots(1,5)\nf.set_size_inches(80, 40)\nfor i in range(5):\n    ax[i].imshow(preds[i].reshape(28, 28))\nplt.show()","e45707a0":"<hr>\n\n<a id=\"one\"><\/a>\n\n# 1.Import Libraries","d9696e1f":"<a id=\"five\"><\/a>\n\n# 5. Evaluation","67510fef":"<a id=\"three\"><\/a>\n\n# 3.Modeling\n\n![11211.png](attachment:11211.png)","8c51dd39":"<a id=\"four\"><\/a>\n\n# 4. Training","e517dd4c":"# AutoEncoder Tutorial\n<hr>\n\n * **Autoencoder** \n : a type of artificial neural network used to learn efficient data codings in an unsupervised manner\n ![Autoencoder_structure.png](attachment:Autoencoder_structure.png)\n \n * **Encoder** : maps the input into the code\n * **Decoder** : maps the code to a reconstruction of the input\n * **Applications** : \n1. Dimensionality reduction \n2. Principal component analysis\n3. Information retrieval\n4. Anomaly detection\n5. etc\n\n* Our Autoencoder is focusing on reconstruction of the MNIST dataset\n* We are using Keras\n\n<hr>\n\nHow to use this notebook :\n\nThere is only minimum explanation\n\nThis notebook could be helpful for who want to see how code works right away\n\nPlease upvote if it was helpful.!\n\n<hr>\n\n## Content\n1. [Import libraries](#one)\n2. [Prepare Data](#two)\n3. [Modeling](#three)\n4. [Training](#four)\n5. [Evaluation](#five)","5241b6df":"## Reference\n[Wikipedia - autoencoder](https:\/\/en.wikipedia.org\/wiki\/Autoencoder)","788aada2":"<hr>\n\n<a id=\"two\"><\/a>\n\n# 2.Prepare Data"}}