{"cell_type":{"6e527b1d":"code","843a2163":"code","9ae56809":"code","3631ae6d":"code","fbb76b74":"code","a917f91b":"code","bf67ebd6":"code","bbd45868":"code","75b66db0":"code","957bf2fd":"code","3323b50a":"code","ce9c1682":"code","c900958a":"code","ce3bdad3":"code","b95d0b1e":"code","4163009d":"code","3de928ef":"code","26dd17f6":"code","bdcbfe4b":"code","f6897d04":"code","13b35621":"code","3e9ab825":"code","81077148":"markdown","103b102b":"markdown","972e6536":"markdown","8e7a5c03":"markdown","29d81ac0":"markdown","d0dd2fd7":"markdown","0394f88d":"markdown"},"source":{"6e527b1d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","843a2163":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom  sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder\nfrom sklearn.impute import KNNImputer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier","9ae56809":"# gettig data\ndf_train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndf_train.head()","3631ae6d":"# drop columns (Name,PassengerId,Ticket,Cabin)\ndf_train = df_train.drop([\"Name\",\"PassengerId\",\"Ticket\",\"Cabin\"],axis=1)\ndf_test = df_test.drop([\"Name\",\"Ticket\",\"Cabin\"],axis=1)\ndf_train.info()","fbb76b74":"df_test.info()","a917f91b":"df_test.isna().sum()","bf67ebd6":"df_train.isna().sum()","bbd45868":"# filling missing values\ndf_train.Age.fillna(df_train.Age.mean(),inplace = True)\ndf_test.Age.fillna(df_test.Age.mean(),inplace = True)\ndf_test.Fare.fillna(df_test[\"Fare\"].mean(),inplace = True) # I forget this\ndf_train.dropna(axis=0,inplace = True)\ndf_train.head()","75b66db0":"plt.figure(figsize = (16,8))\nplt.subplot(121)\nembarked_grup  = df_train.groupby([\"Embarked\"]).Survived.mean() \nplt.title(\"Survived% Embarked\")\nplt.pie( x = embarked_grup.values,explode = (0.1,0.1,0.1), labels = embarked_grup.index,autopct='%1.1f%%', shadow=True, startangle=140 )\nplt.subplot(122)\nsns.barplot(x = \"Embarked\",y = \"Fare\",data = df_train, hue = \"Sex\",)\nplt.show()","957bf2fd":"gender_groupby  = df_train.groupby([\"Sex\"])\nplt.figure(figsize=(18,6))\nplt.subplot(121)\nsns.barplot(x = gender_groupby.Survived.mean().index, y = gender_groupby.Survived.mean().values)\nplt.ylabel(\"Survived Mean\")\nplt.subplot(122)\nsns.barplot(x = gender_groupby.Age.mean().index, y = gender_groupby.Age.mean().values)\nplt.ylabel(\"Age Mean\")\nplt.show()","3323b50a":"# Label Encoder \nle = LabelEncoder()\ndf_train.Sex = le.fit_transform(df_train.Sex) # Male = 1, Female = 0\ndf_test.Sex = le.fit_transform(df_test.Sex) # Male = 1, Female = 0","ce9c1682":"embarked_column_train = pd.get_dummies(df_train[\"Embarked\"])\nembarked_column_test = pd.get_dummies(df_test[\"Embarked\"])\ndf_test.drop([\"Embarked\"],axis=1,inplace = True)\ndf_train.drop([\"Embarked\"],axis=1,inplace = True)\ndf_train = pd.concat([df_train,embarked_column_train],axis=1)\ndf_test= pd.concat([df_test,embarked_column_test],axis=1)","c900958a":"df_train.head()","ce3bdad3":"df_test.head()","b95d0b1e":"y = df_train.iloc[:,0]\nX = df_train.iloc[:,1:]","4163009d":"X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size = 0.3,random_state = 42)","3de928ef":"name = []\nmetric = []\ndef trainModel(alg,X_train,y_train,X_valid,y_valid):        \n    model = alg().fit(X_train,y_train)\n    y_pred = model.predict(X_valid)\n    name.append(alg.__name__)\n    metric.append(accuracy_score(y_valid,y_pred))\n    print(alg.__name__ , \" Accuracy  \", accuracy_score(y_valid,y_pred))","26dd17f6":"models = [RandomForestClassifier,GradientBoostingClassifier,DecisionTreeClassifier,SVC,XGBClassifier]\nfor i in models:\n    trainModel(i,X_train,y_train,X_valid,y_valid)","bdcbfe4b":"status = pd.DataFrame({\"name\" : name,\n        \"training_metric\" :metric\n       })\nstatus","f6897d04":"Gradient_boosting = GradientBoostingClassifier().fit(X,y)","13b35621":"sub = pd.DataFrame({\"PassengerId\":df_test.PassengerId, \"Survived\":Gradient_boosting.predict(df_test.drop(\"PassengerId\", axis = 1))})\nsub.to_csv(\"submission.csv\", index = None)","3e9ab825":"sub","81077148":"# looking data","103b102b":"# Train-Test split ","972e6536":"# Model Testing","8e7a5c03":"# Setup","29d81ac0":"# Importing necessary libraries","d0dd2fd7":"# Model ","0394f88d":"# Data Explorer"}}