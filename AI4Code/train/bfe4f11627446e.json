{"cell_type":{"a378d6e9":"code","0b6a0227":"code","23928084":"code","fc6e8efe":"code","fdd3ef5d":"code","7a1cb784":"code","983c264b":"code","b8b5a045":"code","68f4624d":"code","2feb27b6":"code","953cf43c":"code","181115b4":"code","3afced04":"code","345a7571":"code","34aa2137":"code","5d738929":"code","83184473":"code","5cc616ab":"code","7925beee":"code","064e431f":"code","07155ff9":"markdown","98a147ce":"markdown","3eee2c6c":"markdown","547ece99":"markdown","e4379de9":"markdown","963ac8b4":"markdown","a91eb5af":"markdown","5779482d":"markdown","e3946c4d":"markdown","7ebacec7":"markdown","04a882e3":"markdown"},"source":{"a378d6e9":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport json\nimport cv2\nplt.style.use('bmh')","0b6a0227":"train_df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')","23928084":"train_df.head()","fc6e8efe":"print(\"Total number of training images: \", len(train_df))","fdd3ef5d":"with open('..\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json') as f:\n    data = json.load(f)\nprint('Classes')\nfor i in range(len(data)):\n    print(i,\": \", data[str(i)])","7a1cb784":"train_df.hist();","983c264b":"train_df['label'].value_counts()","b8b5a045":"train_dir = \"..\/input\/cassava-leaf-disease-classification\/train_images\"","68f4624d":"image_sizes = []\nfor f in os.listdir(train_dir):\n    image = cv2.imread(os.path.join(train_dir, f))\n    image_sizes.append(image.shape)\n    \nimage_sizes = set(image_sizes)\nimage_sizes","2feb27b6":"# n must be even\ndef plot_examples(ids, n):\n    np.random.seed(0)\n    rand_ids = np.random.choice(ids, size=n)\n\n    fig = plt.figure(figsize=(15, 10))\n    for i in range(n):\n        I = cv2.imread(os.path.join(train_dir, rand_ids[i]))\n        fig.add_subplot(int(n\/2),2,i+1)\n        plt.imshow(I[:,:,::-1])\n        plt.grid(None)\n        plt.xlabel(rand_ids[i])","953cf43c":"class_0 = train_df.loc[train_df['label'] == 0, ['image_id']].values.flatten()\nplot_examples(class_0, 4)  ","181115b4":"class_1 = train_df.loc[train_df['label'] == 1, ['image_id']].values.flatten()\nplot_examples(class_1, 4)  ","3afced04":"class_2 = train_df.loc[train_df['label'] == 2, ['image_id']].values.flatten()\nplot_examples(class_2, 4)  ","345a7571":"class_3 = train_df.loc[train_df['label'] == 3, ['image_id']].values.flatten()\nplot_examples(class_3, 4)  ","34aa2137":"class_4 = train_df.loc[train_df['label'] == 4, ['image_id']].values.flatten()\nplot_examples(class_4, 4)  ","5d738929":"import albumentations as A","83184473":"transform = A.Compose([\n    A.RandomResizedCrop(256,256),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.25),\n    A.Transpose(p=0.25),\n    A.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5)\n#     A.Normalize(\n#                 mean=[0.485, 0.456, 0.406], \n#                 std=[0.229, 0.224, 0.225], \n#                 max_pixel_value=255.0, \n#                 p=1.0)\n])","5cc616ab":"def plot_augmentations(ids, n, transform):\n#     np.random.seed(0)\n    rand_ids = np.random.choice(ids, size=n)\n    \n    fig = plt.figure(figsize=(15, 25))\n    fig.suptitle('Original Image vs Transformed Image')\n    for i in range(0, 2*n, 2):\n        image = cv2.imread(os.path.join(train_dir, rand_ids[int(i\/2)]))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        fig.add_subplot(n, 2, i+1)\n        plt.imshow(image)\n        plt.grid(None)\n        \n        transformed = transform(image=image)\n        transformed_image = transformed['image']\n        fig.add_subplot(n, 2, i+2)\n        plt.imshow(transformed_image)\n        plt.grid(None)","7925beee":"ids = train_df['image_id'].values\nplot_augmentations(ids, 5, transform)","064e431f":"test_df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\ntest_df","07155ff9":"## Class 3 (Cassava Mosaic Disease)","98a147ce":"Given that this is a real world dataset, the images have been taken using different cameras and under different conditions. The images vary greatly in quality, background\/environment, light exposure, perspective, zoom, etc.","3eee2c6c":"## Class 2 (Cassava Green Mottle)","547ece99":"All of the images are of size 600x800 which is quite large so the images will have to be downsampled during training.","e4379de9":"## Class 4 (Healthy)","963ac8b4":"## Class 0 (Cassava Bacterial Blight)","a91eb5af":"Here we can clearly see that there is a large class imbalance in this dataset. Class 3 has more samples than the remaining classes combined.","5779482d":"## Dataset Stats","e3946c4d":"## Image Augmentations","7ebacec7":"## Class 1 (Cassava Brown Streak Disease)","04a882e3":"## Image Dimensions"}}