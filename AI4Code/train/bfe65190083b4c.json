{"cell_type":{"09fdd636":"code","587b9563":"code","3a5e2a1b":"code","9cc735ee":"code","2ff0686d":"code","359f02c9":"code","c1b59752":"code","9f975da5":"code","5fec3183":"code","7c38a121":"code","2a83fdee":"code","9919a982":"code","89bc3ec8":"code","56f1d002":"code","2a5017f7":"code","bdd97191":"code","e2ccae1e":"code","7db66c3c":"code","4908c100":"code","f1bd4879":"code","c95f8bff":"code","439b2a8b":"code","aae9cdf8":"code","62045121":"markdown","d5b272f9":"markdown","9a06728f":"markdown","f58bd0ed":"markdown","60d7527f":"markdown","9af9f73c":"markdown"},"source":{"09fdd636":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom matplotlib import dates\nimport matplotlib.style as style\n\nimport matplotlib\nimport statsmodels.tsa.api as tsa\n\n%matplotlib inline\n\nmatplotlib.style.use(\"Solarize_Light2\")\n\nfrom pylab import rcParams\nimport statsmodels.api as sm\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","587b9563":"df = pd.read_csv(\"\/kaggle\/input\/yakuza-0-main-story-transcript\/yakuza_0.csv\", delimiter=',', encoding='utf8')\ndf.head()","3a5e2a1b":"df.isnull().sum()","9cc735ee":"import nltk \nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nimport re\nimport string\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB","2ff0686d":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'red',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"character\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Yazuka characters\")\nplt.show()","359f02c9":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'black',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"line\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Yazuka Lines\")\nplt.show()","c1b59752":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef removePunctuation(x):\n    x = x.lower()\n    x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n    x = x.replace('\\r','')\n    x = x.replace('\\n','')\n    x = x.replace('  ','')\n    x = x.replace('\\'','')\n    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)","9f975da5":"#https:\/\/stackoverflow.com\/questions\/51534586\/add-and-remove-words-from-the-nltk-stopwords-list\n\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\n\n#add words that aren't in the NLTK stopwords list\nnew_stopwords = ['and', 'at', 'so', 'er']\nnew_stopwords_list = stop_words.union(new_stopwords)\n\n#remove words that are in NLTK stopwords list\nnot_stopwords = {'anything', 'free', 'have'} \nfinal_stop_words = set([word for word in new_stopwords_list if word not in not_stopwords])\n\nprint(final_stop_words)","5fec3183":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef processText(x):\n    x= removePunctuation(x)\n    #x= removeStopwords(x)\n    return x","7c38a121":"from nltk.tokenize import sent_tokenize, word_tokenize\ntin = pd.Series([word_tokenize(processText(x)) for x in df['line']])\ntin.head(10)","2a83fdee":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\nfrom gensim.models import word2vec\nnum_features = 300    # Word vector dimensionality                      \nmin_word_count = 40   # Minimum word count                        \nnum_workers = 4       # Number of threads to run in parallel\ncontext = 10          # Context window size                                                                                    \ndownsampling = 1e-3   # Downsample setting for frequent words\nmodel = word2vec.Word2Vec(tin, workers=num_workers, \n                          min_count = min_word_count,\n                          window = context, sample = downsampling)","9919a982":"from gensim import utils\nimport logging\nfrom timeit import default_timer\nimport threading\nfrom six.moves import range\nfrom six import itervalues, string_types\nfrom gensim import matutils\nfrom numpy import float32 as REAL, ones, random, dtype\nfrom types import GeneratorType\nfrom gensim.utils import deprecated\nimport os\nimport copy","89bc3ec8":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\ndef most_similar(self, positive=None, negative=None, topn=10, restrict_vocab=None, indexer=None):\n        \"\"\"Deprecated, use self.wv.most_similar() instead.\n        Refer to the documentation for :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar`.\n        \"\"\"\n        return self.wv.most_similar(positive, negative, topn, restrict_vocab, indexer)","56f1d002":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\n#model.most_similar('urm\u0103')#most_similar() is now a part of KeyedVectors\nmodel.wv.most_similar('anything') ","2a5017f7":"df[\"character\"].value_counts()","bdd97191":"labels = 'Majima', 'Makoto', 'Nishikiyama', 'Kiryu'\nsizes = [1247, 182, 326, 1170]  #must have same number labels, sizes and explode\nexplode = (0, 0.2, 0, 0)  # only \"explode\" the 2nd slice \n\nfig1, ax1 = plt.subplots(figsize=(10,10))\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()","e2ccae1e":"len(df['character'].unique())","7db66c3c":"df['character'].value_counts().head(10)","4908c100":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\nfrom nltk.tokenize import sent_tokenize, word_tokenize\ntin = pd.Series([word_tokenize(processText(x)) for x in df['line']])\ntin.head(10)","f1bd4879":"#Code by Andrea Sindico  https:\/\/www.kaggle.com\/asindico\/love-for-poems\/notebook\n\nfrom gensim.models import word2vec\nnum_features = 300    # Word vector dimensionality                      \nmin_word_count = 40   # Minimum word count                        \nnum_workers = 4       # Number of threads to run in parallel\ncontext = 10          # Context window size                                                                                    \ndownsampling = 1e-3   # Downsample setting for frequent words\nmodel = word2vec.Word2Vec(tin, workers=num_workers, #size=num_features - I removed unexpected argument\n                          min_count = min_word_count,\n                          window = context, sample = downsampling)","c95f8bff":"#Since most similar is now in KeyedVectors I copied the snippet below\n#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nfrom gensim import models\nfrom gensim.models import KeyedVectors\n\n\nimport gensim.downloader as api\nword_vectors = api.load(\"glove-wiki-gigaword-100\")  # load pre-trained word-vectors from gensim-data \n# Check the \"most similar words\", using the default \"cosine similarity\" measure.\nresult = word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\")                                                                                 ","439b2a8b":"#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nresult = word_vectors.most_similar(positive=['anything', 'right'], negative=['everything'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\") ","aae9cdf8":"#https:\/\/github.com\/RaRe-Technologies\/gensim\/blob\/develop\/gensim\/models\/keyedvectors.py\n\nresult = word_vectors.most_similar(positive=['free', 'please'], negative=['fight'])\n\nmost_similar_key, similarity = result[0]  # look at the first match\nprint(f\"{most_similar_key}: {similarity:.4f}\") ","62045121":"#That's all for now","d5b272f9":"size=num_features Was removed from model= word2vec.Word2Vec(tin, workers=num_workers, size=num_features.........","9a06728f":"![](https:\/\/i.ytimg.com\/vi\/gIjEqklzT0o\/maxresdefault.jpg)youtube.com","f58bd0ed":"#Let's try with words from the Dataset.","60d7527f":"#Checking similar words (similarity\/most_similar_key)","9af9f73c":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #001f3f;\"><b style=\"color:white;\">Ry\u016b ga Gotoku - Yakuza<\/b><\/h1><\/center>\n\n\"Yakuza, known in Japan as Ry\u016b ga Gotoku (\u9f8d\u304c\u5982\u304f, lit. Like a Dragon), is a Japanese media franchise created, owned and published by Sega. The franchise originated as a series of beat 'em up video games featuring 3D game graphics, though elements of the action-adventure, open world, turn-based strategy and action role-playing genres are also incorporated in subsequent instalments.\"\n\nhttps:\/\/en.wikipedia.org\/wiki\/Yakuza_(franchise)"}}