{"cell_type":{"8d12572f":"code","fda8a5a0":"code","e617d304":"code","d83f0431":"code","f052adb7":"code","55413fcd":"code","6bce1b17":"code","e8304dc6":"code","ea1227c8":"code","d40d2ab5":"code","b8b70cf3":"code","b662b2e8":"code","64828943":"code","83223473":"code","864312da":"code","7b567fc8":"code","00411892":"code","b9ce716f":"code","7edd6662":"markdown","60292317":"markdown","c46983e2":"markdown","57583112":"markdown","da23b761":"markdown","d09b719b":"markdown","25960c75":"markdown","6c225c09":"markdown"},"source":{"8d12572f":"import numpy as np\nimport pandas as pd\nimport math\nimport re\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.metrics import classification_report\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os","fda8a5a0":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.head(3)","e617d304":"fig = plt.figure(figsize=(20, 3))\n\nfor i, col_name in enumerate(['Age', 'Fare']):\n    plt.subplot(1, 5, 1 + i)\n    train[col_name].plot.box();\nplt.show();\n\n\nfig = plt.figure(figsize=(20, 7))\nfor i, col_name in enumerate(['Age', 'Fare']):\n    new_col_name = col_name + '_bin'\n    train[new_col_name] = pd.cut(train[col_name], 10)\n\n    ax = fig.add_subplot(2, 1, 1 + i)\n    sns.barplot(x = new_col_name, y = 'Survived', data=train, ax = ax)\n    ax.grid(True)\nplt.show();","d83f0431":"col_list = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\nfig = plt.figure(figsize=(20, 9))\n\nfor i, col_name in enumerate(col_list):\n    ax = fig.add_subplot(4, 2, 1 + i)\n    sns.barplot(x = col_name, y = 'Survived', data=train, ax = ax)\n    ax.grid(True)\nplt.show();","f052adb7":"train = train.drop(['Age_bin', 'Fare_bin'], axis=1)","55413fcd":"# # Creating new feature\n# # \n# # \n\n\n# def encode_group(x, groups):\n#     if not x:\n#         return 'only_int_group'\n\n#     for k, val in groups.items():\n#         if x in val:\n#             return k\n#     print(f'Error with {x}')\n    \n    \n# def extr_tick_text(ticket):\n#     res = re.match(r'([a-zA-Z]|\\\/|\\.)+', ticket)\n#     if res is None:\n#         return ''\n#     return ticket[res.start() : res.end()].replace('.', '')\n\n\n# def create_gr_list(df, n_grps=3):\n#     \"\"\"!!! so far, it works only with n_grps=3 !!!\n#     \"\"\"\n#     df = generate_field_ticket_group(df)\n    \n#     groups = {f'group_{i+1}' : [] for i in range(n_grps)}\n#     bins = [0.33, 0.66, 1.1]\n\n#     pivot = pd.pivot_table(df[df['tick_group'] != 'only_int_group'][['Survived', 'tick_group']],\n#                        columns=['tick_group'])\n\n#     for col in pivot.columns:\n#         col_val = pivot[col]['Survived']\n#         for i, bin_ in enumerate(bins):\n#             if col_val < bin_:\n#                 groups[f'group_{i+1}'].append(col)\n\n#     return groups\n\n\n# def generate_field_ticket_group(df, groups):\n#     #1 lower column ticket\n#     df['Ticket'] = df['Ticket'].apply(lambda x : x.lower())\n\n#     #2 extract letters and symbols\n#     df['tick_text'] = df['Ticket'].apply(lambda x : extr_tick_text(x))\n    \n#     #3\n#     df['tick_group'] = df['tick_text'].apply(lambda x : encode_group(x, groups))\n    \n#     return df.drop(['tick_text'], axis=1)","6bce1b17":"# \u0421\u043f\u0435\u0440\u0432\u0430 \u0440\u0430\u0437\u0431\u0438\u0442\u044c test \u0438 train\n\n# \u0421\u043f\u0438\u0441\u043e\u043a \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0439 \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0445:\n#     1. \u041b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u043f\u043e\u043b\u044f \u0438\u0437 logarithm_list\n#     2. \u0421\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0444\u0438\u0447\u0443 \u043e\u0442\u0432\u0435\u0447\u0430\u044e\u0449\u0443\u044e \u0437\u0430 \u0433\u0440\u0443\u043f\u043f\u0443 \u0431\u0438\u043b\u0435\u0442\u0430 ???\n#     3. \u0440\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 x \u0438 y\n#     4. \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u043f\u043e\u043b\u0435 sex \u0432 \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0439\n#     5. \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432\n#     6. \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u0442\u044c \u043f\u043e\u043b\u044f 'Embarked', 'tick_group' (\u0431\u044b\u043b\u043e get_dummies)\n#     7. \u0441\u043a\u0430\u043b\u0435\u0440","e8304dc6":"X_train, X_test, y_train, y_test = train_test_split(train.loc[: , train.columns != 'Survived'],\n                                                    train.loc[: , train.columns == 'Survived'], \n                                                    test_size=0.20, random_state=42)","ea1227c8":"logarithm_list = ['Fare', 'Age', 'SibSp']\nscaler_list = ['Fare', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked_Q', 'Embarked_S']\n\n# ticket_groups = create_gr_list(train)\n\ndef prepare_data(data, is_log=True, fillna_method='ffill', is_train=True):\n    # 1 Logarithm\n    if is_log:\n        for i in logarithm_list:\n            data[i] = data[i].apply(lambda x : 0 if x == 0 else math.log(x, 100))\n    \n    # 2 generate feature \"ticket_group\"\n#     data = generate_field_ticket_group(data, ticket_groups)\n    \n    # 3 Drop \n    X = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n\n    # 4 Sex binar\n    X.Sex = X.Sex.apply(lambda x: 1 if x == 'male' else 0)\n\n    # 5 Fill na\n    X = X.fillna(method=fillna_method)\n\n    # 6 Get dummies\n    X = pd.get_dummies(X, columns=['Embarked'], drop_first=True)\n\n    # 7 Scalling\n    for i in scaler_list:\n        scaler = StandardScaler()\n        scaler.fit(np.array([X[i]]).reshape(len(X[i]), 1))\n        new_data = scaler.transform(np.array([X[i]]).reshape(len(X[i]), 1))\n        X[i] = new_data\n        \n    return X \n\n\ndef calculate_gs(options, model):\n    delimiter = \"\\n\" + ('=' * 50 + \"\\n\")\n    \n    clf = GridSearchCV(model, options, scoring='accuracy')\n    clf.fit(X_train, y_train['Survived'])\n    print(delimiter, clf.best_estimator_, delimiter)\n    \n    return clf.best_estimator_.get_params()","d40d2ab5":"# X_train, X_test, y_train, y_test = prepare_data(train)","b8b70cf3":"X_train = prepare_data(X_train)\nX_test = prepare_data(X_test)","b662b2e8":"# options = {'loss': ['hinge', \n#                     'log', \n#                     'modified_huber', \n#                     'squared_hinge',\n#                     'perceptron',\n#                     'squared_loss',\n#                     'huber',\n#                     'epsilon_insensitive',\n#                     'squared_epsilon_insensitive'],\n#           'penalty': [\"l1\", \"l2\", \"elasticnet\"]\n#           }\n# lin_model = SGDClassifier()\n# m_params = calculate_gs(options, lin_model)\n\n\n# lin_model.set_params(**m_params)\n# lin_model.fit(X_train, y_train)\n# prediction = lin_model.predict(X_test)\n# print(classification_report(prediction, y_test['Survived']))","64828943":"# threshold = 0.9\n# selector = VarianceThreshold(threshold=threshold)\n# new_data = selector.fit_transform(X_train)\n\n# lin_model = SGDClassifier(random_state=42)\n# lin_model.fit(new_data, y_train)\n# prediction = lin_model.predict(X_test[X.columns[(selector.variances_ >= threshold)]])\n\n\n# print(classification_report(prediction, y_test['Survived']))\n# n = (prediction == y_test['Survived'])\n# print(\"\\n\\nMine:\", round(100 * sum(n) \/ len(n), 2))","83223473":"# from sklearn.neighbors import KNeighborsClassifier\n\n# options = {'n_neighbors': list(range(1,10)),\n#           'weights': [\"uniform\", \"distance\"]\n#           }\n# lin_model = KNeighborsClassifier()\n\n\n# m_params = calculate_gs(options, lin_model)\n# lin_model.set_params(**m_params)\n# lin_model.fit(X_train, y_train)\n# prediction = lin_model.predict(X_test)\n\n# print(classification_report(prediction, y_test['Survived']))","864312da":"# from sklearn.tree import DecisionTreeClassifier\n\n\n# options = {\"max_depth\" : [4,5,6,7,8,9,10]}\n# lin_model = DecisionTreeClassifier()\n\n\n# m_params = calculate_gs(options, lin_model)\n# lin_model.set_params(**m_params)\n# lin_model.fit(X_train, y_train)\n# prediction = lin_model.predict(X_test)\n\n\n# print(classification_report(prediction, y_test['Survived']))","7b567fc8":"from sklearn.linear_model import LogisticRegression\n\noptions = {\"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}\nlin_model = LogisticRegression()\n\n\nm_params = calculate_gs(options, lin_model)\nlin_model.set_params(**m_params)\nlin_model.fit(X_train, y_train)\nprediction = lin_model.predict(X_test)\n\n\nprint(classification_report(prediction, y_test['Survived']))","00411892":"test = pd.read_csv('..\/input\/titanic\/test.csv')\nX_test = prepare_data(test, ticket_groups, is_train=False)\n\n# t_prediction = lin_model.predict(X[X.columns[(selector.variances_ >= threshold)]])\nt_prediction = lin_model.predict(X_test)\n\n\nsubmission = test\nsubmission['Survived'] = t_prediction\nsubmission = submission[['PassengerId', 'Survived']]","b9ce716f":"submission.to_csv('submission.csv', index=False)\nsubmission.head()","7edd6662":"<h3>4. \u0414\u0435\u0440\u0435\u0432\u043e \u0440\u0435\u0448\u0435\u043d\u0438\u0439","60292317":"<h3> 5. \u041b\u043e\u0433. \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f","c46983e2":"<h3>3. KNN","57583112":"<h3>2. \u041c\u043e\u0434\u0435\u043b\u044c \u0441 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435\u043c VarianceThreshold ","da23b761":"<h3>1. \u041e\u0431\u044b\u0447\u043d\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c SGDClassifier","d09b719b":"<h2>Submission","25960c75":"<h2> \u0414\u0430\u043d\u043d\u044b\u0435","6c225c09":"<h2> \u0413\u0440\u0430\u0444\u0438\u043a\u0438"}}