{"cell_type":{"80499ff6":"code","992047dd":"code","4400feaf":"code","5720977f":"code","ae6d6b6d":"code","1c7f3043":"code","ee7f86a9":"code","c25642c8":"code","08d68177":"code","8d9030f1":"code","b0874313":"markdown","e80cd350":"markdown","46d30e40":"markdown","7a0439fe":"markdown","1738ec2c":"markdown","46d05ab8":"markdown","f0e82d45":"markdown","a727d7de":"markdown"},"source":{"80499ff6":"import numpy as np \nimport pandas as pd \nimport os\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression, Ridge, ElasticNet\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nimport spacy","992047dd":"# config params\nclass CFG:\n    nfolds =  10\n    ","4400feaf":"# count syllables: https:\/\/stackoverflow.com\/questions\/46759492\/syllable-count-in-python\ndef syllable_count(word):\n    count = 0\n    vowels = \"aeiouy\"\n    if word[0] in vowels:\n        count += 1\n    for index in range(1, len(word)):\n        if word[index] in vowels and word[index - 1] not in vowels:\n            count += 1\n            if word.endswith(\"e\"):\n                count -= 1\n    if count == 0:\n        count += 1\n    return count","5720977f":"xtrain = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/train.csv')\nxtest = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/test.csv')","ae6d6b6d":"# Flesch score: https:\/\/blog.ung.edu\/press\/measure-readability\/\n\n# count the characters\nxtrain['nof_char'] = xtrain['excerpt'].apply(len)\nxtest['nof_char'] = xtest['excerpt'].apply(len)\n\n# count the words\nxtrain['nof_words'] = xtrain['excerpt'].apply(lambda s: len(s.split(' ')))\nxtest['nof_words'] = xtest['excerpt'].apply(lambda s: len(s.split(' ')))\n\n# words to characters\nxtrain['w2c'] = xtrain['nof_words'] \/ xtrain['nof_char']\nxtest['w2c'] = xtest['nof_words'] \/ xtest['nof_char']\n\n# nof sentences\nxtrain['nof_sentences'] =  xtrain['excerpt'].apply(lambda s: s.count('.'))\nxtest['nof_sentences'] =  xtest['excerpt'].apply(lambda s: s.count('.'))\n\n# nof syllables\nxtrain['nof_syllables'] =  xtrain['excerpt'].apply(lambda s: syllable_count(s))\nxtest['nof_syllables'] =  xtest['excerpt'].apply(lambda s: syllable_count(s))\n\n# Fleisch score\na = 206.835 - 1.015 * (xtrain['nof_words'] \/ xtrain['nof_sentences'])\nb = -84.6 * (xtrain['nof_syllables'] \/ xtrain['nof_words'])\nxtrain['fleisch_score'] = a + b\n\na = 206.835 - 1.015 * (xtest['nof_words'] \/ xtest['nof_sentences'])\nb = -84.6 * (xtest['nof_syllables'] \/ xtest['nof_words'])\nxtest['fleisch_score'] = a + b\n\n# Fleisch score 2\na = (xtrain['nof_words'] \/ xtrain['nof_sentences'])\nb = (xtrain['nof_syllables'] \/ xtrain['nof_words'])\nxtrain['fleisch_score2'] = 0.39 * a + 11.8 * b - 15.59\n\na = (xtest['nof_words'] \/ xtest['nof_sentences'])\nb = (xtest['nof_syllables'] \/ xtest['nof_words'])\nxtest['fleisch_score2'] = 0.39 * a + 11.8 * b - 15.59\n \n    \ndel a,b\n\n\n# count the unique words\nxtrain['nof_unique_words'] = xtrain['excerpt'].apply(lambda s: len(set( s.split(' ') )))\nxtest['nof_unique_words'] = xtest['excerpt'].apply(lambda s: len(set( s.split(' ') )))\n\n# text diversity\nxtrain['txt_diversity'] = xtrain['nof_unique_words'] \/ xtrain['nof_words']\nxtest['txt_diversity'] = xtest['nof_unique_words'] \/ xtest['nof_words']\n\n# word lengths\nwords = xtrain['excerpt'].apply(lambda s: s.split(' '))\nword_lengths = words.apply(lambda s: [len(f) for f in s ])\nxtrain['longest_word'] = word_lengths.apply(max)\nxtrain['avg_word'] = word_lengths.apply(np.mean)\n\nwords = xtest['excerpt'].apply(lambda s: s.split(' '))\nword_lengths = words.apply(lambda s: [len(f) for f in s ])\nxtest['longest_word'] = word_lengths.apply(max)\nxtest['avg_word'] = word_lengths.apply(np.mean)\n","1c7f3043":"# Taken from: https:\/\/www.kaggle.com\/anaverageengineer\/comlrp-baseline-for-complete-beginners\n\nnlp = spacy.load('en_core_web_lg')\nwith nlp.disable_pipes():\n    train_vectors = np.array([nlp(text).vector for text in xtrain.excerpt])\n    test_vectors = np.array([nlp(text).vector for text in xtest.excerpt])\n        \nnamelist = ['f' + str(ii) for ii in range(train_vectors.shape[1])]\n\ntrain_vectors = pd.DataFrame(train_vectors)\ntest_vectors = pd.DataFrame(test_vectors)\ntrain_vectors.columns = namelist\ntest_vectors.columns = namelist\n","ee7f86a9":"xtrain = pd.concat([xtrain, train_vectors], axis = 1)\nxtest = pd.concat([xtest, test_vectors], axis = 1)\n\n\nfeatures = ['nof_words', 'nof_sentences', 'nof_syllables', 'fleisch_score',\n           'txt_diversity', 'nof_unique_words', 'nof_char', 'w2c', \n            'fleisch_score2'] + namelist\n","c25642c8":"kf = KFold(n_splits = CFG.nfolds)\n\nprval = np.zeros((xtrain.shape[0],1))\nprfull = np.zeros((xtest.shape[0],1))","08d68177":"\nfor id0, id1 in kf.split(xtrain):\n    x0, x1 = xtrain[features].loc[id0], xtrain[features].loc[id1]\n    y0, y1 = xtrain['target'][id0], xtrain['target'][id1]\n    \n    model = Ridge(alpha = 1)\n\n    model.fit(x0,y0)\n    \n    ypred = model.predict(x1)\n    prval[id1,0] =  model.predict(x1)\n    prfull[:,0] += model.predict(xtest[features])\/CFG.nfolds\n    \n    print(np.round( np.sqrt(mse(prval[id1,0], y1)),2 ))\n    \n# score\nprint('--')\nprint(np.round( np.sqrt(mse(prval, xtrain['target'])) , 3))","8d9030f1":"xsub = xtest[[\"id\"]].copy()\nxsub[\"target\"] = prfull\nxsub.to_csv('submission.csv', index = False)","b0874313":"# Submission","e80cd350":"# CV ","46d30e40":"## Combined","7a0439fe":"# Data and FE","1738ec2c":"## Spacy features","46d05ab8":"# Functions","f0e82d45":"## summary statistics features\n","a727d7de":"Spacy features taken from https:\/\/www.kaggle.com\/anaverageengineer\/comlrp-baseline-for-complete-beginners - please upvote!\n\nCurrent score (LB: 0.624) is version 4"}}