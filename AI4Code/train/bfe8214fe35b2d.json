{"cell_type":{"278e3ed2":"code","77c11c80":"code","75f31ccc":"code","d4a433f0":"code","a746addf":"code","7833d4ee":"code","3fd5e43f":"code","be7ab031":"code","5d578ccf":"code","8c3b37bf":"code","1eaab161":"code","7dffd5b0":"code","0ff539bf":"code","4b2d3dea":"code","1f27200e":"code","c6c05041":"code","cde5c83a":"code","2b46afa8":"code","9924b881":"code","0ab214f2":"code","73e7687e":"code","83bccacb":"code","a6d485f4":"code","4e05e5f4":"code","8b1a6ad1":"code","4797fc20":"code","c77c0b00":"code","bdf13189":"code","d49484f0":"code","4ae6e932":"code","d1cee4a7":"code","a21f032b":"code","ff29d9d0":"code","4e37de96":"code","8981ba8e":"code","3981d20d":"code","9401c007":"code","21765e6f":"code","b3453939":"code","38a54224":"code","338c6077":"code","51ae377b":"code","007d7e04":"code","71ea7f5e":"code","13ac8976":"code","51473b7a":"code","01a07c50":"code","84f2d229":"code","67ad6bac":"code","e352c229":"code","0bbe80ee":"code","d7b1cd43":"code","a38e9aeb":"code","4f37ac4d":"code","04ef25f7":"code","609b27ad":"code","4a86cb26":"code","b2d04849":"code","ddf56a4b":"code","2081d494":"code","ca2e2e67":"code","ba1c8d7a":"code","a6dd78ad":"code","b6b61eb7":"markdown","a923737e":"markdown","ef2a7f43":"markdown","f572655c":"markdown","f589bc4e":"markdown","12fd8cbc":"markdown","ea556d96":"markdown","a09f8ca1":"markdown","6bec8218":"markdown","c91ed46f":"markdown","b15930f6":"markdown","c55e0672":"markdown","c6524e70":"markdown","3a7a259c":"markdown","8e74226e":"markdown","6ad5df2b":"markdown","66726109":"markdown","86c5bae1":"markdown","2c5334ca":"markdown","293e8d57":"markdown","2f93aa8f":"markdown","5667e412":"markdown","c2a26500":"markdown","bec5269a":"markdown","992fd9cd":"markdown","4b7b22a3":"markdown","b710d585":"markdown","88a20929":"markdown","3b5f5c7f":"markdown","d7378a6a":"markdown","5f6713ab":"markdown","690f1258":"markdown","307746f5":"markdown","922b6006":"markdown","d32efc70":"markdown","5045ccbf":"markdown","4255aa57":"markdown","29daf3ad":"markdown","b429ac56":"markdown","f268a7d5":"markdown","d3854067":"markdown","f7a3b3d7":"markdown","a58b04d0":"markdown","572b52e6":"markdown","c0804a69":"markdown","8e0fb4c2":"markdown","dc69665a":"markdown","c181a5c6":"markdown","4195440c":"markdown","559ec92b":"markdown","f0aaff6a":"markdown","97594005":"markdown","86e98870":"markdown","63f25f44":"markdown","5053ee76":"markdown","e600fe33":"markdown","38948bdc":"markdown","b73dd5cc":"markdown","dbf7cd80":"markdown","41931bf7":"markdown","74b1f005":"markdown","6758ba4a":"markdown"},"source":{"278e3ed2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","77c11c80":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib                  # 2D Plotting Library\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as mgrid\nimport seaborn as sns              # Python Data Visualization Library based on matplotlib\n\nimport calendar \n\n### Plotly for interactive plots\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n%matplotlib inline","75f31ccc":"data = pd.read_csv('..\/input\/border-crossing-entry-data\/Border_Crossing_Entry_Data.csv')","d4a433f0":"print(data.info())\ndata.head()","a746addf":"data.isnull().any()","7833d4ee":"# Convert dates from strings to date format\ndata['Date'] = pd.to_datetime(data['Date'])","3fd5e43f":"borders = data['Border'].unique()\nprint(borders)","be7ab031":"years = data['Date'].map(lambda x : x.year).unique()\nyears","5d578ccf":"print(\"There are {} port names.\".format(len(data['Port Name'].unique())))\nprint(\"There are {} port codes.\".format(len(data['Port Code'].unique())))\nprint(\"There are {} different locations.\".format(len(data['Location'].unique())))","8c3b37bf":"ports = data[['Port Name','Port Code']].drop_duplicates()\nports[ports['Port Name'].duplicated(keep = False)]","1eaab161":"data.iloc[[29,217]]","7dffd5b0":"data.loc[(data['Port Name'] == 'Eastport') & (data['State'] == 'Idaho'), 'Port Name'] = 'Eastport, ID'","0ff539bf":"# take the port's unique code and location\nlocs = data[['Port Code','Location']]\n\n# take only unique values\nlocs = locs.drop_duplicates()\nprint(\"There are {} different pairs of port code's and locations\".format(len(locs)))\n# how many locations has each port?\nls = locs['Port Code'].value_counts()\npts = locs['Location'].value_counts()\n\n# Another way of doing the same...\n# ls = locs.groupby(['Port Code']).count()\nprint('')\nprint('Port codes and # of locations:')\nprint(ls.head(10))\nprint('')\nprint('Locations and # of ports:')\nprint(pts.head(10))","4b2d3dea":"f,ax = plt.subplots(ncols=2, nrows=2, figsize=(15,10))\nsns.set(style = \"darkgrid\")\n\n# Pie plots\n# This function generates autopct, for displaying both the percent value and the original value.\ndef make_autopct(values):\n    def my_autopct(pct):\n        total = sum(values)\n        val = int(round(pct*total\/100.0))\n        return '{p:.2f}%  ({v:d})'.format(p=pct,v=val)\n    return my_autopct\n\nls.value_counts().plot.pie(explode = [0.15,0,0],\n                           autopct = make_autopct(ls.value_counts().values),\n                           ax = ax[0,0])\nax[0,0].set(title = '# of locations per port', ylabel = '')\npts.value_counts().plot.pie(explode = [0.15,0], \n                            autopct = make_autopct(pts.value_counts().values), \n                            ax = ax[1,0])\nax[1,0].set(title = '# of ports per location', ylabel = '')\n\n# Countplots using seaborn\nax[0,1] = sns.countplot(ls, ax=ax[0,1])\nax[0,1].set(title = '# of locations per port', xlabel = '# of locations')\nax[1,1] = sns.countplot(pts, ax=ax[1][1])\nax[1,1].set(title = '# of ports per location', xlabel = '# of ports')\n\nplt.subplots_adjust(\n    wspace =  0.25,     # the amount of width reserved for blank space between subplots\n    hspace = 0.3 # the amount of height reserved for white space between subplots\n)","1f27200e":"rpt = pts[pts.values > 1].index\nrpt_locs = locs[locs['Location'].isin(rpt)]\nrpt_locs","c6c05041":"l = rpt_locs.set_index('Location')\npairs = [l.loc[x].values.flatten().tolist() for x in rpt]\nprint(pairs)","cde5c83a":"# let's one of those shared locations\ndata.iloc[[19267,22492]]","2b46afa8":"data['Measure'].unique()","9924b881":"people = data[data['Measure'].isin(['Personal Vehicle Passengers', 'Bus Passengers','Pedestrians', 'Train Passengers'])]\nvehicles = data[data['Measure'].isin(['Trucks', 'Rail Containers Full','Truck Containers Empty', 'Rail Containers Empty',\n       'Personal Vehicles', 'Buses', 'Truck Containers Full'])]","0ab214f2":"people_borders = people[['Border','Value']].groupby('Border').sum()\npeople_borders","73e7687e":"values = people_borders.values.flatten()\nlabels = people_borders.index\nfig = go.Figure(data=[go.Pie(labels = labels, values=values)])\nfig.update(layout_title_text='Total inbound persons, since 1996')\nfig.show()","83bccacb":"# Take the values and set the date as index\np = people[['Date','Border','Value']].set_index('Date')\n\n# Group by years and border\np = p.groupby([p.index.year, 'Border']).sum()\np.head(10)","a6d485f4":"val_MEX = p.loc(axis=0)[:,'US-Mexico Border'].values.flatten().tolist()\nval_CAN = p.loc(axis=0)[:,'US-Canada Border'].values.flatten().tolist()\nyrs = p.unstack(level=1).index.values\n\n# Bar chart \nfig = go.Figure(go.Bar(x = yrs, y = val_MEX, name='US-Mexico Border'))\nfig.add_trace(go.Bar(x = yrs, y = val_CAN, name='US-Canada Border'))\n\nfig.update_layout(title = 'Total inbounds (people), by border and years', barmode='stack', xaxis={'categoryorder':'category ascending'})\nfig.show()","4e05e5f4":"# Unstack the Data Frame\nvals = p.unstack().Value\nval_MEX = vals['US-Mexico Border']\nval_CAN = vals['US-Canada Border']\nval_TOT = val_MEX + val_CAN\ngrowth_MEX = val_MEX.diff().dropna()\/val_MEX.values[:-1]*100\ngrowth_CAN = val_CAN.diff().dropna()\/val_CAN.values[:-1]*100\ngrowth_TOT = val_TOT.diff().dropna()\/val_TOT.values[:-1]*100\n\nyrs = vals.index.values\n\n# Bar chart \n# We drop the values for 2019 as there are data only until april\nfig = go.Figure(go.Bar(x = yrs, y = growth_MEX.values[:-1], name='US-Mexico Border'))\nfig.add_trace(go.Bar(x = yrs, y = growth_CAN.values[:-1], name='US-Canada Border'))\nfig.add_trace(go.Line(x = yrs, y = growth_TOT.values[:-1], name='Total'))\n\nfig.update_layout(title = 'Border transit annual growth (people), by border and years', \n                  barmode='group', \n                  xaxis={'categoryorder':'category ascending'},\n                  yaxis=go.layout.YAxis(\n                      title=go.layout.yaxis.Title(\n                      text=\"Annual growth (%)\",\n                      font=dict(                      \n                      size=18,\n                      color=\"#7f7f7f\")\n            \n        )\n    )\n                 \n                 )\nfig.show()","8b1a6ad1":"# Take the values and set the date as index\nm = people[['Date','Measure','Value']].set_index('Date')\n\n# Group by years and border\nm = m.groupby([m.index.year,'Measure']).sum()\nm.head(10)","4797fc20":"# Bar chart \nmeasures = ['Personal Vehicle Passengers', 'Bus Passengers','Pedestrians', 'Train Passengers']\nyrs = m.unstack().index.values\n\nfig = go.Figure(data = [go.Bar(x = yrs, y = m.loc(axis=0)[:, mes].values.flatten().tolist(), name = mes) for mes in measures ])\n    \nfig.update_layout(title = 'Total inbounds (people), by measure and years', barmode='stack', xaxis={'categoryorder':'category ascending'})\nfig.show()","c77c0b00":"people_measure = people[['Measure','Value']].groupby('Measure').sum()\nvalues = people_measure.values.flatten()\nlabels = people_measure.index\nfig = go.Figure(data=[go.Pie(labels = labels, values=values)])\nfig.update(layout_title_text='Total inbound persons, since 1996')\nfig.show()","bdf13189":"# Take the values and set the date as index\nmb = people[['Date','Border','Measure','Value']].set_index('Date')\n\n# Group by years and border\nmb = mb.groupby([mb.index.year,'Border','Measure']).sum()\n\n# Bar chart, US-Canada Border\n\nfig = go.Figure(data = [go.Bar(x = yrs, y = mb.loc(axis=0)[:,'US-Canada Border', mes].values.flatten().tolist(), name = mes) for mes in measures ])\nfig.update_layout(title = 'US-Canada inbounds (people), by measure and years', barmode='stack', xaxis={'categoryorder':'category ascending'})\nfig.show()","d49484f0":"# Bar chart, US-Canada Border\n\nfig = go.Figure(data = [go.Bar(x = yrs, y = mb.loc(axis=0)[:,'US-Mexico Border', mes].values.flatten().tolist(), name = mes) for mes in measures ])\nfig.update_layout(title = 'US-Mexico inbounds (people), by measure and years', barmode='stack', xaxis={'categoryorder':'category ascending'})\nfig.show()","4ae6e932":"sns.set(rc={'figure.figsize':(15, 8)})\nfig,ax = plt.subplots()\nmb.loc(axis=0)[:,'US-Mexico Border', :].unstack().Value.plot(title='US-Mexico Border inbound crossings',ax=ax)\nfig.tight_layout()\nfig.show()\n","d1cee4a7":"mb.loc(axis=0)[:,'US-Canada Border', :].unstack().Value.plot(title='US-Canada Border inbound crossings')\nplt.show()","a21f032b":"# Take the values and set the date as index\n\nstart_year = 2014\nend_year = 2018\n\nm = people[['Date','Border','Measure','Value']].set_index('Date')\n\n# Group by years and measure\nm = m.groupby([m.index.year,'Border', 'Measure']).sum()\n\nm_can = m.loc(axis=0)[start_year:end_year,'US-Canada Border'].groupby('Measure').mean()\nm_mex = m.loc(axis=0)[start_year:end_year,'US-Mexico Border'].groupby('Measure').mean()\n\n# plotting, pie charts\nf,ax = plt.subplots(ncols=2, nrows=1)\n\nm_can['Value'].plot.pie( ax = ax[0], autopct = '%1.1f%%')\nm_mex['Value'].plot.pie( ax = ax[1], autopct = '%1.1f%%')\n\nax[0].set(title = 'Canadian border, average from {} to {}'.format(start_year,end_year), ylabel = '')\nax[1].set(title = 'Mexican border, average from {} to {}'.format(start_year,end_year), ylabel = '')\nf.show()","ff29d9d0":"# Inbounds by years and Measure, since 1996\nd = data[['Date','Measure','Value']].set_index('Date')\n\nyear_measure_df = d.pivot_table('Value', index = d.index.year, columns = 'Measure', aggfunc = 'sum')\nyear_measure_df","4e37de96":"year_measure_df.corr().style.background_gradient(cmap='coolwarm').set_precision(2)","8981ba8e":"# Incoming people by state and type of vehicle, since 1996\n\nPStateVehicle_df = people.pivot_table('Value', index = 'State', columns = 'Measure', aggfunc = 'sum')\nPStateVehicle_df","3981d20d":"rest = PStateVehicle_df[PStateVehicle_df.sum(axis=1)  < PStateVehicle_df.sum().sum()*0.04].sum().rename('Rest')\n\nt = PStateVehicle_df[PStateVehicle_df.sum(axis=1)  > PStateVehicle_df.sum().sum()*0.04]\nt = t.append(rest)\n# Sort them by total flux\nt = t.iloc[np.argsort(t.sum(axis=1)).values]\n# Combine Train and bus passagners in \"others\"\nt['Other']=t['Bus Passengers'] + t['Train Passengers']\nt = t.drop(['Bus Passengers', 'Train Passengers'], axis=1)\n\n# Plot\nfig, ax = plt.subplots()\n\nsize = 0.4\n\na= t.sum(axis=1).plot.pie(radius = 1,\n       wedgeprops=dict(width=size+0.23, edgecolor='w'), ax = ax, autopct = '%1.1f%%', pctdistance= 0.8)\n\nb=pd.Series(t.values.flatten()).plot.pie(radius = 1- size,colors = ['#DF867E','#8DC0FB','#A9EE84'],\n       wedgeprops=dict(width=size-0.2, edgecolor='w'), ax=ax, labels = None)\n\nax.set(ylabel=None)\nred_patch = matplotlib.patches.Patch(color='#DF867E', label='Pedestrians')\nblue_patch = matplotlib.patches.Patch(color='#8DC0FB', label='Personal vehicle passengers')\ngreen_patch = matplotlib.patches.Patch(color='#A9EE84', label='Others')\nplt.legend(handles=[blue_patch,red_patch, green_patch], loc='best', bbox_to_anchor=(0.75, 0.5, 0.5, 0.5))\n\nplt.show()","9401c007":"start_year = 2015\nend_year = 2018\n\n# Group by years and states\np_states = people[['Date','State','Value']].set_index('Date')\np_states = p_states.groupby([p_states.index.year, 'State']).sum()\n# Select date range and compute mean\np_states = p_states.loc(axis=0)[start_year:end_year,:].groupby('State').mean()\n# Sort, for nice visualization\np_states = p_states['Value'].sort_values()\n# Take only states with more than 4% of share \nrest = p_states[p_states < p_states.sum()*.04].sum()\np_states = p_states[p_states > p_states.sum()*.04].append(pd.Series({'Rest' : rest}))\n\n# Same for all years:\np_states_tot = people[['State','Value']].groupby('State').sum()\np_states_tot = p_states_tot['Value'].sort_values()\nrest_tot = p_states_tot[p_states_tot < p_states_tot.sum()*.04].sum()\np_states_tot = p_states_tot[p_states_tot > p_states_tot.sum()*.04].append(pd.Series({'Rest' : rest_tot}))\n\n\n# plotting, pie charts\nf,ax = plt.subplots(ncols=2, nrows=1)\n\np_states_tot.plot.pie( ax = ax[0], autopct = '%1.1f%%')\np_states.plot.pie( ax = ax[1], autopct = '%1.1f%%')\n\nax[0].set(title = 'States share (inbound people), since 1996', ylabel = '')\nax[1].set(title = 'States share (inbound people), average from {} to {}'.format(start_year,end_year), ylabel = '')\nf.show()","21765e6f":"p_ports = people[['Port Name','Value']].groupby('Port Name').sum().Value.sort_values(ascending = False)\np_ports.hist()\n\nplt.show()","b3453939":"num_p = 10\n\npctg = p_ports.head(num_p).sum()\/p_ports.sum()*100\n\nprint('The {} most transited ports are:'.format(num_p))\nprint(p_ports.head(num_p))\nprint('')\nprint ('The {} most transited ports (out of 117) take {:.2f} % of all persons crossings into the US.'.format(num_p, pctg))","38a54224":"p_locs = people[['Location','Value']].groupby('Location').sum().reset_index()\n\n# functions to get coordinates,\ndef get_lon(point) :\n    par = point[7:-1].partition(' ')\n    return float(par[0])\n\ndef get_lat(point) :\n    par = point[7:-1].partition(' ')\n    return float(par[2])\n\n# adding a column with the coordinates to the dataframe\np_locs['lat'] = p_locs.Location.apply(lambda x: get_lat(x))\np_locs['lon'] = p_locs.Location.apply(lambda x: get_lon(x))\n\n# As some locations have 2 ports, we have to take are of it in the labelling,\nps = data[['Port Name','Location']].drop_duplicates().set_index('Location')\np_locs['Ports'] = p_locs.Location.apply(lambda x : ', '.join(ps.loc[x].values.flatten()))\np_locs['text'] = p_locs['Ports'] + '<br>Crossings: ' + (p_locs['Value']\/1e6).astype(str)+' million'\n\n\ncolor = \"crimson\"\nscale = 500000\n\nfig = go.Figure()\nfig.add_trace(go.Scattergeo(\n    locationmode = 'USA-states',\n    lon = p_locs['lon'],\n    lat = p_locs['lat'],\n    text = p_locs['text'],\n    marker = dict(\n        size = p_locs['Value']\/scale,\n        color = color,\n        line_color='rgb(40,40,40)',\n        line_width=0.5,\n        sizemode = 'area')))\n\nfig.update_layout(\n        title_text = 'US Borders, total inbound persons since 1996<br>(Click legend to toggle traces)',\n        showlegend = False,\n        geo = dict(\n            scope = 'usa',\n            landcolor = 'rgb(217, 217, 217)',\n        )\n    )\n\nfig.show()","338c6077":"people_crossing_series = people[['Date','Value']].groupby('Date').sum()\npeople_crossing_series_CAN = people[people['Border'] == 'US-Canada Border'][['Date','Value']].groupby('Date').sum()\npeople_crossing_series_MEX = people[people['Border'] == 'US-Mexico Border'][['Date','Value']].groupby('Date').sum()","51ae377b":"sns.set(rc={'figure.figsize':(15, 8)})\nfig, ax = plt.subplots()\n\n#Define a rolling mean, by years\nrmean = people_crossing_series.rolling(12, center=True).mean()\nrmean_MEX = people_crossing_series_MEX.rolling(12, center=True).mean()\nrmean_CAN = people_crossing_series_CAN.rolling(12, center=True).mean()\n\nax.plot(people_crossing_series,\n       marker='.', linestyle='-', linewidth=1, alpha = 1, label='Total')\nax.plot(rmean,\n       marker=None, linestyle='-', linewidth=1.5, alpha = 0.5, label='Total, rolling mean (years)', color = 'b')\n\nax.plot(people_crossing_series_MEX,\n       marker='.', linestyle='-', linewidth=1, alpha = 1, label='Mexico', color = 'r')\nax.plot(rmean_MEX,\n       marker=None, linestyle='-', linewidth=1.5, alpha = 0.5, label='Mexico, rolling mean (years)', color = 'r')\n\nax.plot(people_crossing_series_CAN,\n       marker='.', linestyle='-', linewidth=1, alpha = 1, label='Canada', color = 'g')\nax.plot(rmean_CAN,\n       marker=None, linestyle='-', linewidth=1.5, alpha = 0.5, label='Canada, rolling mean (years)', color = 'g')\n\nax.set(title = 'Total monthly persons entering in the US, from 1996', xlabel = 'year')\nax.legend()\n\nplt.show()","007d7e04":"fig, ax = plt.subplots()\n\nstart = '2015'\nend = '2018'\n\n\nax.plot(people_crossing_series.loc[start:end],\n       marker='o', linestyle='-', linewidth=0.8, alpha = 1, label='Total', color = 'b')\nax.plot(rmean.loc[start:end],\n       marker=None, linestyle='-', linewidth=1.5, alpha = 0.5, label='Total, rolling mean (years)', color = 'b')\n\nax.plot(people_crossing_series_MEX.loc[start:end],\n       marker='.', linestyle='-', linewidth=0.8, alpha = 0.9, label='Mexico', color = 'r')\nax.plot(rmean_MEX.loc[start:end],\n       marker=None, linestyle='-', linewidth=1.5, alpha = 0.5, label='Mexico, rolling mean (years)', color = 'r')\n\nax.plot(people_crossing_series_CAN.loc[start:end],\n       marker='.', linestyle='-', linewidth=0.8, alpha = 0.9, label='Canada',color = 'g')\nax.plot(rmean_CAN.loc[start:end],\n       marker=None, linestyle='-', linewidth=1.5, alpha = 0.5, label='Canada, rolling mean (years)', color = 'g')\n\nax.set(title = 'Total persons entering in the US, from {} to {}'.format(start, end))\nax.legend()\n\nplt.show()","71ea7f5e":"fig = plt.figure()\n\ngrid = mgrid.GridSpec(nrows=2, ncols=1, height_ratios=[2, 1])\n\nseas = fig.add_subplot(grid[0])\ntrend = fig.add_subplot(grid[1], sharex = seas)\n\nstart = '2015'\nend = '2018'\n\nseas.plot(people_crossing_series.loc[start:end]\/people_crossing_series.loc[start:end].sum(),\n       marker='o', linestyle='-', linewidth=0.8, alpha = 1, label='Total', color = 'b')\n\nseas.plot(people_crossing_series_MEX.loc[start:end]\/people_crossing_series_MEX.loc[start:end].sum(),\n       marker='.', linestyle='-', linewidth=0.8, alpha = 0.9, label='Mexico', color = 'r')\n\nseas.plot(people_crossing_series_CAN.loc[start:end]\/people_crossing_series_CAN.loc[start:end].sum(),\n       marker='.', linestyle='-', linewidth=0.8, alpha = 0.9, label='Canada', color = 'g')\n\nseas.set(title = 'Persons entering in the US, from {} to {}, normalised'.format(start, end),\n      ylabel = 'arbitrary units')\nseas.legend()\n\ntrend.plot(rmean.loc[start:end]\/rmean.loc[start:end].sum(),\n       marker='', linestyle='-', linewidth=2, alpha = 1, label='Total', color = 'b')\n\ntrend.plot(rmean_MEX.loc[start:end]\/rmean_MEX.loc[start:end].sum(),\n       marker='', linestyle='-', linewidth=2, alpha = 1, label='Mexico', color = 'r')\n\ntrend.plot(rmean_CAN.loc[start:end]\/rmean_CAN.loc[start:end].sum(),\n       marker='', linestyle='-', linewidth=2, alpha = 1, label='Canada', color = 'g')\n\ntrend.set(ylabel = ' Trend (arbitrary units)')\nfig.tight_layout()\nplt.show()","13ac8976":"start = '2011'\nend = '2018'\npcsm = people_crossing_series.loc[start:end]\n\nfig, ax = plt.subplots(2,figsize = (18,13))\n\nfor i in range(11) :\n    mm = pcsm[pcsm.index.month == i] \n    ax[0].plot(mm, label = calendar.month_abbr[i])\n    ax[1].plot(mm\/mm.sum(), label = calendar.month_abbr[i])\n    \nax[0].set(title = 'persons entering the US between {} and {}, total by months'.format(start, end),\n         ylabel = '# people')\nax[1].set(title = 'persons entering the US between {} and {}, trend by months'.format(start, end),\n         ylabel = 'arbitrary units')\nax[0].legend()\nax[1].legend()\n\nplt.show()","51473b7a":"start = '2011'\nend = '2018'\npcsm = people_crossing_series.loc[start:end]\nmonths = [calendar.month_abbr[m] for m in range(1,13)]\nfig, ax = plt.subplots(2,figsize = (18,13))\n\nstart = int(start)\nend = int(end)\n\nfor i in range(start, end) :\n    yy = pcsm[pcsm.index.year == i];\n    yy = yy.set_index(yy.index.month);\n    ax[0].plot(yy\n               , label = i)\n    ax[1].plot(yy\/yy.sum()\n               , label = i)\n    \nax[0].set(title = 'persons entering the US between {} and {}, total by years'.format(start, end),\n         ylabel = '# people')\n\nax[1].set(title = 'persons entering the US between {} and {}, seasonal (normalised)'.format(start, end),\n         ylabel = 'arbitrary units')\n\nplt.setp(ax, xticks = range(1,13), xticklabels = months)\nax[0].legend()\nplt.tight_layout()\n\nplt.show()","01a07c50":"from statsmodels.tsa.seasonal import seasonal_decompose\n\npcsm = people_crossing_series.loc['2011':]\n\n# Multiplicative Decomposition \nres_mul = seasonal_decompose(pcsm, model='multiplicative', extrapolate_trend='freq')\n\n# Additive Decomposition\nres_add = seasonal_decompose(pcsm, model='additive', extrapolate_trend='freq')\n\n# extrapolate_trend='freq' gets rid of NaN values","84f2d229":"# Plot\nfig, axes = plt.subplots(ncols=2, nrows=4, sharex=True, figsize=(15,8))\n\nres_mul.observed.plot(ax=axes[0,0], legend=False)\naxes[0,0].set_ylabel('Observed')\n\nres_mul.trend.plot(ax=axes[1,0], legend=False)\naxes[1,0].set_ylabel('Trend')\n\nres_mul.seasonal.plot(ax=axes[2,0], legend=False)\naxes[2,0].set_ylabel('Seasonal')\n\nres_mul.resid.plot(ax=axes[3,0], legend=False)\naxes[3,0].set_ylabel('Residual')\n\nres_add.observed.plot(ax=axes[0,1], legend=False)\naxes[0,1].set_ylabel('Observed')\n\nres_add.trend.plot(ax=axes[1,1], legend=False)\naxes[1,1].set_ylabel('Trend')\n\nres_add.seasonal.plot(ax=axes[2,1], legend=False)\naxes[2,1].set_ylabel('Seasonal')\n\nres_add.resid.plot(ax=axes[3,1], legend=False)\naxes[3,1].set_ylabel('Residual')\n\naxes[0,0].set_title('Multiplicative')\naxes[0,1].set_title('Additive')\n    \nplt.tight_layout()\nplt.show()","67ad6bac":"# Deseasonalized data\n\ndes = res_mul.trend * res_mul.resid\ndes.plot(figsize = (15,10))\n\nplt.show()","e352c229":"# Checking the stationarity through a ADF test statistics\n\nfrom statsmodels.tsa.stattools import adfuller\n\nresult = adfuller(des.Value.dropna())\nprint('ADF Statistic: %f' % result[0])\nprint('p-value: %f' % result[1])","0bbe80ee":"import numpy as np, pandas as pd\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport matplotlib.pyplot as plt\n#plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n\n# Original Series\nfig, axes = plt.subplots(3, 2, figsize=(16,10))\n\naxes[0, 0].plot(des.Value)\naxes[0, 0].set_title('Original Series')\nplot_acf(des, ax=axes[0, 1])\n\n# 1st Differencing\naxes[1, 0].plot(des.Value.diff()); axes[1, 0].set_title('1st Order Differencing')\nplot_acf(des.diff().dropna(), ax=axes[1, 1])\n\n# 2nd Differencing\naxes[2, 0].plot(des.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\nplot_acf(des.diff().diff().dropna(), ax=axes[2, 1])\n\nplt.tight_layout()\nplt.show()","d7b1cd43":"result_diff = adfuller(des.diff().Value.dropna())\nprint('ADF Statistic: %f' % result_diff[0])\nprint('p-value: %f' % result_diff[1])","a38e9aeb":"fig, axes = plt.subplots(3, 2, figsize=(16,10))\n\naxes[0, 0].plot(des.Value)\naxes[0, 0].set_title('Original Series')\nplot_pacf(des, ax=axes[0, 1])\n\n# 1st Differencing\naxes[1, 0].plot(des.Value.diff()); axes[1, 0].set_title('1st Order Differencing')\nplot_pacf(des.diff().dropna(), ax=axes[1, 1])\n\n# 2nd Differencing\naxes[2, 0].plot(des.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\nplot_pacf(des.diff().diff().dropna(), ax=axes[2, 1])\n\nplt.tight_layout()\nplt.show()","4f37ac4d":"from statsmodels.tsa.arima_model import ARIMA\n\n# ARIMA(p,d,q) Model \nmodel = ARIMA(des, order=(0,1,1))\nmodel_fit = model.fit(disp=0)\n\n# Print the information of the model\nprint(model_fit.summary())","04ef25f7":"# Plot residual errors\n\nresiduals = pd.DataFrame(model_fit.resid)\n\nfig, ax = plt.subplots(2,2, figsize=(15,8))\nresiduals.plot(title=\"Residuals\", ax=ax[0,0])\nresiduals.plot(kind='kde', title='Density', ax=ax[0,1])\nplot_acf(model_fit.resid.dropna(), ax=ax[1,0])\nplt.tight_layout()\nplt.show()","609b27ad":"# Actual vs Fitted\nmodel_fit.plot_predict()\nplt.show()","4a86cb26":"print(len(des))\nprint(len(des)*.75)","b2d04849":"from statsmodels.tsa.stattools import acf\n\n# Create Training and Test\ntrain = des[:74]\ntest = des[74:]\n\n# Build Model\nmodel_train = ARIMA(train, order=(0,1,1))  \n# and fit- using MLE method\nfitted_train = model_train.fit(disp=-1)  \n\n# Forecast\nfc, se, conf = fitted_train.forecast(25, alpha=0.05)  # 95% conf\n\n# Make as pandas series\nfc_series = pd.Series(fc, index=test.index)\nlower_series = pd.Series(conf[:, 0], index=test.index)\nupper_series = pd.Series(conf[:, 1], index=test.index)\n\n# Plot\nplt.figure(figsize=(15,8))\nplt.plot(train, label='training')\nplt.plot(test, label='actual')\nplt.plot(fc_series, label='forecast')\nplt.fill_between(lower_series.index, lower_series, upper_series, \n                 color='k', alpha=.15)\nplt.title('Forecast vs Actuals')\nplt.legend(loc='upper left', fontsize=8)\nplt.show()","ddf56a4b":"from statsmodels.tsa.arima_model import ARIMA\nimport pmdarima as pm\n\nmodel_auto = pm.auto_arima(des, start_p=0, start_q=0,\n                      test='adf',       # use adftest to find optimal 'd'\n                      max_p=4, max_q=4, # maximum p and q\n                      m=12,              # frequency of series\n                      d=None,           # let model determine 'd'\n                      seasonal=False,   # No Seasonality\n                      start_P=0, \n                      D=0, \n                      trace=True,\n                      error_action='ignore',  \n                      suppress_warnings=True, \n                      stepwise=False)\n\nprint(model_auto.summary())","2081d494":"model_auto.plot_diagnostics(figsize=(15,8))\nplt.show()","ca2e2e67":"# What's the last date in our data?\npeople_crossing_series.tail(1)","ba1c8d7a":"# Intervals for forecasting\n\ndate_start = people_crossing_series.tail(1).index[0]\ndate_end = '2020-12-01'\ndate_rng = pd.date_range(start=date_start, end=date_end, freq='MS', closed = 'right') # range for forecasting\nn_forecast = len(date_rng) # number of steps to forecast\n\nseasonal = res_mul.seasonal.loc['2018-01-01':'2018-12-01'].values # seasonal component, we take the 2018 ones, but they are all the same.\ntms = pd.Series(np.tile(seasonal.flatten(),11), index = pd.date_range(start='2019-01-01', end = '2029-12-01', freq='MS'))  # This is just a very long series with the seasonality.\n\ndef make_seasonal(ser) :\n    seasonal_series = ser * tms # Include the seasonality\n    seasonal_series = seasonal_series[~seasonal_series.isnull()] # trim extra values\n    return seasonal_series\n    \n# Forecast\n\nmodel = ARIMA(des, order=(0,1,1))\nmodel_fit = model.fit(disp=0)\n\nfc1, se1, conf1 = model_fit.forecast(n_forecast, alpha = 0.0455)  # 2 sigma Confidence Level (95,55% conf)\nfc2, se2, conf2 = model_fit.forecast(n_forecast, alpha = 0.3173)  # 1 sigma Confidence Level (68,27% conf)\n\n# Make as pandas series \nfc1_series = pd.Series(fc1, index = date_rng)\nlower_series1 = pd.Series(conf1[:, 0], index = date_rng)\nupper_series1 = pd.Series(conf1[:, 1], index = date_rng)\n\n# Include seasonality\nfc1_series, lower_series1, upper_series1 = [make_seasonal(fc1_series), make_seasonal(lower_series1), make_seasonal(upper_series1)]\n\nplt.figure(figsize=(12,5), dpi=100)\n\n#plt.plot(des, label='actual')\n#plt.plot(people_crossing_series, label='actual')\nplt.plot(des * res_mul.seasonal, label='data')\nplt.plot(fc1_series , label='forecast')\n\n# Confidence level intervals\nplt.fill_between(lower_series1.index,lower_series1, upper_series1, \n                 color='k', alpha=.15, label='2$\\sigma$ Confidence level (95%)')\nplt.title('Forecast 2019\/20')\nplt.legend(loc='upper left', fontsize=8)\n#plt.ylim(10000000, 30000000)\nplt.xlim('2016', '2021')\nplt.show()","a6dd78ad":"fig = plt.figure()\n\ngrid = mgrid.GridSpec(nrows=2, ncols=1, height_ratios=[2, 1])\nsns.set(rc={'figure.figsize':(15, 8)})\n\nseas = fig.add_subplot(grid[0])\nseas_adj = fig.add_subplot(grid[1], sharex = seas)\n\nseas.plot(des * res_mul.seasonal, label='data')\nseas.plot(fc1_series , label='forecast')\nseas.fill_between(lower_series1.index,lower_series1, upper_series1, \n                 color='k', alpha=.15, label = '2$\\sigma$ Confidence level (95%)')\n\n# seasonal adjusted:\nseas_adj.plot(des, label='data')\n\nseas_adj.plot(pd.Series(fc1, index = date_rng) , label='forecast')\nseas_adj.fill_between(date_rng,\n                  pd.Series(conf1[:, 0], index = date_rng), \n                  pd.Series(conf1[:, 1], index = date_rng), \n                 color='k', alpha=.15, label = '2$\\sigma$ Confidence level (95%)')\nplt.xlim('2016', '2021')\nseas.set_title('Forecast 2019\/20')\nseas.legend()\nfig.tight_layout()\n\nplt.show()","b6b61eb7":"Trends look fairly regular and similar for all months","a923737e":"It seems that Eastport has two different port codes, and that's the source of the discrepancy between the number of codes and the names. Indeed, one corresponds to Eastpot, Idaho, and the other one to Eastport, Maine.","ef2a7f43":"The US border crossing dataset contains information of the inbound crossings at the U.S.-Canada and the U.S.-Mexico borders, thus reflecting the number of vehicles, containers, passengers or pedestrians entering the United States. Not data for outbound crossing is provided. \n\nThis is a fairly easy dataset, very nice for exercising some plotting and pandas skills for beginers. Also, I tried some modelling and forecasting using an ARIMA method.\n\n<b>NOTE:<\/b> This is an ongoing project. <b> I very much appreciate your feedback <\/b> :)","f572655c":"The vast majority of ports have had less than 100M crossings, whereas a very few of them have a lot. Border crossings are concentrated in few ports among the 114 of them. Which are the most transited?","f589bc4e":"Now I'm going to build the ARIMA model using the statsmodel package.","12fd8cbc":"Comparing the seasonally adjusted forecast with the total:","ea556d96":"Shares have remained fairly constant, with California gaining some popularity.","a09f8ca1":"Difficult to tell... There are three terms that barely cross the significance threshold in the firs differenciation... lets take p=1. Also, we see that the PACF d=1 show a sinusoidal beheavour, indicating that the arima model might be of the form ARIMA(0,1,1)","6bec8218":"Both look nice, with the residuals resembling white noise. Let's take the multiplicative one.","c91ed46f":"## Modelling and Forecasting","b15930f6":"Interestingly, the number of pedestrians crossing the US-Mexico Border seems to be almost constant in time, compared to the number of Personal Vehicle Passengers, which learly sets the trend","c55e0672":"## Introduction","c6524e70":"The feature measure indicates the type of counting. Among the 'Measure' types, 'Personal Vehicle Passengers', 'Bus Passengers','Pedestrians' and 'Train Passengers' count people, whereas the others count vehicles.","3a7a259c":"#### Forecast\n\nLastly, we can include now the seasonality to make the final forecast. ","8e74226e":"Do people entering from Mexico and Canada have the same prefered means of transportation for crossing the border?","6ad5df2b":"Crossings by states:","66726109":"So it seems that each row consists essentially in a counting (column \"Value\") for the \"crossing method\" (column \"Measure\") such as trucks, trains, etc; together with some geographical information. ","86c5bae1":"Which ports are sharing which locations?","2c5334ca":"The majority of the ports have two locations, and most of the locations are unique to a port, excepting 5 of them.","293e8d57":"There are 229 pairs of ports and locations but only 224 unique locations. So it seems that there are some ports (with different codes and names) sharing the same location.","2f93aa8f":"### Geographical Visualization","5667e412":"My next guess is that the number of unique elements in \"Port Code\", \"Port Name\" and \"Location\" should coincide. Let's check it:","c2a26500":"The series is not stationary. Thus, we differenciate until we kill the autocorrelations;","bec5269a":"In order to validate the the model, we make a Out-of-Time cross-validation.","992fd9cd":"Let's now try the automated tool auto_arima() from the pmdarima pakage for automatically searching the best (p,d,q) combination such that minimizes the AIC:","4b7b22a3":"### People","b710d585":"Let's change it to avoid further confusion,","88a20929":"Taking d=1, the number of MA terms (the value of q) can be estimated by looking at the autocorrelation function after one differenciation. There's only 1 term away from the significance line. I will take q=1.","3b5f5c7f":"What years are included in the data?","d7378a6a":"Let's study the correlations:","5f6713ab":"Analyzing the time series:","690f1258":"Seasonal decomposition: We will decompose the time series into its seasonal component, a trend component, and noise (error), as this structure is evident from the plots above. I will use data for the total number of persons entering the US from 2011 onwards, to avoid overfitting in the linear models.\n\nWe can make an additive or a multiplicative decomposition. Let's do both and see which one works better","307746f5":"We can clearly see the seasonal component, with a period of one year. Minimums take place during the winter, notaly in february, whereas the maximums are in summer, during August and Juy. Is this behaviour the same in both borders?","922b6006":"The following pairs of ports (by codes) are sharing locations. We see that 3020 (Frontier, Washington) and 3015 (Boundary, Washington) actually share 2 locations.","d32efc70":"Let's first load the data and take a look at it...","5045ccbf":"Here I do an ARIMA modelling and forecasting for the time series once the seasonal component is substracted.","4255aa57":"The US has two terrestrial borders, namely with Canada and Mexico. So we expect 2 possible values for 'Border'","29daf3ad":"How do people cross the borders?","b429ac56":"So after a bit of brute force we see that (2, 1, 3) seems to be the best choice, with the lowest AIC and also with p-values below the 0.05 threshold, which is good. However, the AIC is very similar for both (2, 1, 3) and (0,1,1), so I wil use the latter for simplicity. Recall that with (p,d,q) =  (0,1,1) we have a Moving Avarage of order q=1 on the differenciated series y', \n\n$ y_{t}' = c + \\epsilon_t + \\theta_1 \\epsilon_{t-1}$.\n\nAnyway we can also check the residuals again using a nice plot_diagnostics method from the pmdarima package:","f268a7d5":"How many Auto Regressive (AR) terms do we need (what's the vaue of the term p?). Let's inspect the partial autocorrelation functions (PACF). This functions essentially tells as the correlation between the series and its lag, after excluding the contributions from the intermediate lags:","d3854067":"Looking for missing\/null values...","f7a3b3d7":"## Data Exploration","a58b04d0":"Now, concerning the locations, I wonder how many locations a port can have... there are almost twice more locations than ports according to the unique elements counting. Also, is it possible that the same location is shared by 2 or more ports?","572b52e6":"They do not! What's going on? ","c0804a69":"It looks like something happened in 2002 in the US-Mexican border...","8e0fb4c2":"Avarage for each measure for the last 5 years, and  its contribution to the total:","dc69665a":"Total # of people crossing the border since 1996, splited by Measure","c181a5c6":"As I'm planning to use a linear regression model for forecasting, we should guarantee that the series is stationary, i.e. the statistical properties (like mean, variance, autocorrelations...) do not vary with time. If there were some autocorrelations, that would mean that the independent variables in our linear regression model are not that independent (bad thing!). By looking at the plot above, clearly our series show non-stationarity.\n\nHere we will check the stationarity of the time series using an ADF test (Augmented Dickey Fuller test). This is the most commonly used test, where the null hypothesis is \"the time series possesses a unit root and is non-stationary\". If the P-Value in the ADH test is less than a given significance level (0.05), we reject the null hypothesis.","4195440c":"Does it also happen in Canada?","559ec92b":"Visualazing this data:","f0aaff6a":"Have the shares of states changed with time?","97594005":"Let's analyse a shorter period ","86e98870":"Convert dates from strings to date format:","63f25f44":"The p-values of the constant term and the MA term are very small. The residuals should resemble white noise: normally distributed with zero mean and constant variance, and should be uncorrelated. This would mean that we are no leaving information in them, which otherwise would mean that the model is improvable.","5053ee76":"With one differenciation, the autocorrelations are almost away. If we take two differenciations, we see that the first term is strongly anticorrelated, meaning that the series has been over-differenciated. Hence, we can take only one differentiation. Indeed:","e600fe33":"The seasonality is also fairly regular.","38948bdc":"Studying the annual growth, by borders:","b73dd5cc":"How are the crossings distributed among ports?","dbf7cd80":"### Decomposition","41931bf7":"Visualizing the total number of persons crossing the border towards the US, including a rolling mean (by years) to see the trend:","74b1f005":"This looks good. Let's plot the actual values versus the fitted ones:","6758ba4a":"### ARIMA seasonally adjusted modelling"}}