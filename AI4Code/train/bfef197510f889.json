{"cell_type":{"c37a2488":"code","bff51072":"code","56406966":"code","3645e130":"code","58568b1e":"code","d6c011fe":"code","d304faa9":"code","c6a312eb":"code","078391dd":"markdown","1f04039e":"markdown","f8c08c3c":"markdown","a8170e45":"markdown","d0bb5ea9":"markdown","297c0693":"markdown","e6e25eb6":"markdown","0632b230":"markdown","6faea781":"markdown"},"source":{"c37a2488":"#!\/usr\/bin\/python3\nimport pandas as pd\nimport numpy as np\nimport sys\nimport os\n\nimport matplotlib.pyplot as plt\n\nTXS_LOG = \"\/kaggle\/input\/ethereum-network-measurement\/transactions.csv\/transactions.csv\"\n\ndtypes = {\n        'LocalTimeStamp'    : 'object',\n        'Hash'              : 'object',\n        'GasLimit'          : 'object',\n        'GasPrice'          : 'object',\n        'Value'             : 'object',\n        'Nonce'             : 'object',\n        'MsgType'           : 'object',\n        'Cost'              : 'object',\n        'Size'              : 'object',\n        'To'                : 'object',\n        'From'              : 'object',\n        'ValidityErr'       : 'object',\n        'CapturedLocally'   : 'object',\n        'GasUsed'           : 'float',\n        'InMainBlock'       : 'object',\n        'InUncleBlocks'     : 'object',\n        'InOrder'           : 'object',\n        'NeverCommitting'    : 'object',\n        'CommitTime0'       : 'float',\n        'CommitTime3'       : 'float',\n        'CommitTime12'      : 'float',\n        'CommitTime36'      : 'float',\n        }\n\n# DUE TO KAGGLE'S RAM LIMIT\n# we drop 3\/4 of all txs and perfrom this metric only on one quarter of them (5,000,000 out of ~ 20,000,000)\n# run this metric on a machine with RAM big enough if you want to cover all of them\ntxs = pd.read_csv(TXS_LOG, skiprows=1, engine = 'python', nrows=5000000, \n    names=['LocalTimeStamp','Hash','GasLimit','GasPrice','Value','Nonce','MsgType',\n            'Cost','Size','To','From','ValidityErr','CapturedLocally','GasUsed',\n            'InMainBlock','InUncleBlocks','InOrder','NeverCommitting',\n            'CommitTime0','CommitTime3','CommitTime12','CommitTime36'],\n            usecols=['Hash', 'MsgType', 'ValidityErr', 'GasUsed','NeverCommitting'],\n            dtype=dtypes)\n\n# drop txs w\/ GasUsed nil, validityErr != nil; committed txs only (these are surely valid)\ncondition = txs[  (txs['GasUsed'].isnull()) | (txs['ValidityErr'] != \"nil\") | (txs['NeverCommitting'] != \"Committed\") ].index\ntxs.drop(condition , inplace=True)\n\n# print  txs after drop\n#print(\"Txs TOTAL (after drop): \", len(txs.index))\n\ntx_only = txs[txs.MsgType == \"TX\"]\nmc_only = txs[txs.MsgType == \"MC\"]\ncc_only = txs[txs.MsgType == \"CC\"]\n\n#print (\"TX:\", len(tx_only), tx_only.GasUsed.min(),tx_only.GasUsed.max(),tx_only.GasUsed.median(),tx_only.GasUsed.mean() )   #min max median mean\n#print (\"MC:\", len(mc_only), mc_only.GasUsed.min(),mc_only.GasUsed.max(),mc_only.GasUsed.median(),mc_only.GasUsed.mean() )\n#print (\"CC:\", len(cc_only), cc_only.GasUsed.min(),cc_only.GasUsed.max(),cc_only.GasUsed.median(),cc_only.GasUsed.mean() )\n\ns_tx = txs[txs.MsgType == \"TX\"].GasUsed\ns_mc = txs[txs.MsgType == \"MC\"].GasUsed\ns_cc = txs[txs.MsgType == \"CC\"].GasUsed\n\nbin_seq = list(range(0,8000000,20)) \n\nfig, ax = plt.subplots()\n\ncounts_tx, bin_edges_tx = np.histogram (s_tx, bins=bin_seq)\ncdf_tx = np.cumsum (counts_tx)\nlineTx, = ax.plot (bin_edges_tx[1:], cdf_tx\/cdf_tx[-1], label='regular transfers')\n\ncounts_mc, bin_edges_mc = np.histogram (s_mc, bins=bin_seq)\ncdf_mc = np.cumsum (counts_mc)\nlineMc, = ax.plot (bin_edges_mc[1:], cdf_mc\/cdf_mc[-1], label='function calls')\n\ncounts_cc, bin_edges_cc = np.histogram (s_cc, bins=bin_seq)\ncdf_cc = np.cumsum (counts_cc)\nlineCc, = ax.plot (bin_edges_cc[1:], cdf_cc\/cdf_cc[-1], label='contract creations')\n\nplt.xlabel('Gas used (x1000)')\nplt.yticks(np.arange(0, 1.1, step=0.1),['0%','10%','20%','30%','40%','50%','60%','70%','80%','90%','100%'])\n\nplt.xscale('symlog')\nax.set_xlim(left=20000)\nax.set_xlim(right=8000000)\n\nnums = [21000,80000,160000,500000,1000000,2000000,4000000,8000000]\nlabels = ['21', '80', '160', '500', '1000', '2000', '4000', '8000']\n\nplt.xticks(nums, labels)\n\n#for q in [50, 70, 75, 90, 95, 100]:\n#    print (\"reg tx  :{}%% percentile: {}\".format (q, np.percentile(s_tx, q)))\n#    print (\"Msg call:{}%% percentile: {}\".format (q, np.percentile(s_mc, q)))\n#    print (\"con crea:{}%% percentile: {}\".format (q, np.percentile(s_cc, q)))\n\nax.legend()\nplt.show()\n","bff51072":"#!\/usr\/bin\/python3\nimport pandas as pd\nimport numpy as np\nimport sys\nimport os\n\nimport inspect\nimport matplotlib.pyplot as plt\n\nTXS_LOG = \"\/kaggle\/input\/ethereum-network-measurement\/transactions.csv\/transactions.csv\"\n\ndtypes = {\n        'LocalTimeStamp'    : 'object',\n        'Hash'              : 'object',\n        'GasLimit'          : 'object',\n        'GasPrice'          : 'float',\n        'Value'             : 'object',\n        'Nonce'             : 'object',\n        'MsgType'           : 'object',\n        'Cost'              : 'object',\n        'Size'              : 'object',\n        'To'                : 'object',\n        'From'              : 'object',\n        'ValidityErr'       : 'object',\n        'CapturedLocally'   : 'object',\n        'GasUsed'           : 'object',\n        'InMainBlock'       : 'object',\n        'InUncleBlocks'     : 'object',\n        'InOrder'           : 'object',\n        'NeverCommitting'    : 'object',\n        'CommitTime0'       : 'float',\n        'CommitTime3'       : 'float',\n        'CommitTime12'      : 'float',\n        'CommitTime36'      : 'float',\n        }\n\n# DUE TO KAGGLE'S RAM LIMIT\n# we drop 3\/4 of all txs and perfrom this metric only on one quarter of them (5,000,000 out of ~ 20,000,000)\n# run this metric on a machine with RAM big enough if you want to cover all of them\ntxs = pd.read_csv(TXS_LOG, skiprows=1, engine = 'python', nrows=5000000, \n    names=['LocalTimeStamp','Hash','GasLimit','GasPrice','Value','Nonce','MsgType',\n            'Cost','Size','To','From','ValidityErr','CapturedLocally','GasUsed',\n            'InMainBlock','InUncleBlocks','InOrder','NeverCommitting',\n            'CommitTime0','CommitTime3','CommitTime12','CommitTime36'],\n            #usecols=['GasPrice','Hash','CommitTime0','CommitTime3','CommitTime12','CommitTime36'],\n            usecols=['GasPrice','CommitTime12','ValidityErr'],\n            dtype=dtypes)\n\n# drop all txs without CommitTime12\ncondition = txs[ txs['CommitTime12'].isnull() ].index\ntxs.drop(condition , inplace=True)\n\ns_txs0        = txs[txs.GasPrice == 0].CommitTime12\ns_txs0to20    = txs[(txs.GasPrice > 0) & (txs.GasPrice < 20000000000)].CommitTime12\ns_txs20to25    = txs[(txs.GasPrice >= 20000000000) & (txs.GasPrice < 25000000000)].CommitTime12\ns_txs25to105    = txs[(txs.GasPrice >= 25000000000) & (txs.GasPrice < 105000000000)].CommitTime12\ns_txs105up    = txs[(txs.GasPrice >= 105000000000) ].CommitTime12\n\n#print(\"TXS all:\",len(txs))\n#print(\"0:\",len(s_txs0))\n#print(\"0 to 20:\",   len(s_txs0to20))\n#print(\"20 to 25:\",  len(s_txs20to25))\n#print(\"25 to 105:\", len(s_txs25to105))\n#print(\"105Gwei+:\",  len(s_txs105up))\n\nmax_delay = 200000\nbin_seq = list(range(0,max_delay,10))  \nfig, ax = plt.subplots()\n\ncounts_txs0, bin_edges_txs0 = np.histogram (s_txs0, bins=bin_seq)\ncdf_txs0 = np.cumsum (counts_txs0)\nlinetxs0, = ax.plot (bin_edges_txs0[1:], cdf_txs0\/cdf_txs0[-1], label='0 GWei')\n\ncounts_txs0to20, bin_edges_txs0to20 = np.histogram (s_txs0to20, bins=bin_seq)\ncdf_txs0to20 = np.cumsum (counts_txs0to20)\nlinetxs0to20, = ax.plot (bin_edges_txs0to20[1:], cdf_txs0to20\/cdf_txs0to20[-1], label='(0, 20) GWei')\n\ncounts_txs20to25, bin_edges_txs20to25 = np.histogram (s_txs20to25, bins=bin_seq)\ncdf_txs20to25 = np.cumsum (counts_txs20to25)\nlinetxs20to25, = ax.plot (bin_edges_txs20to25[1:], cdf_txs20to25\/cdf_txs20to25[-1], label='[20, 25) GWei')\n\ncounts_txs25to105, bin_edges_txs25to105 = np.histogram (s_txs25to105, bins=bin_seq)\ncdf_txs25to105 = np.cumsum (counts_txs25to105)\nlinetxs25to105, = ax.plot (bin_edges_txs25to105[1:], cdf_txs25to105\/cdf_txs25to105[-1], label='[25, 105) GWei')\n\ncounts_txs105up, bin_edges_txs105up = np.histogram (s_txs105up, bins=bin_seq)\ncdf_txs105up = np.cumsum (counts_txs105up)\nlines_txs105up, = ax.plot (bin_edges_txs105up[1:], cdf_txs105up\/cdf_txs105up[-1], label='[105, Inf) GWei')\n\n\nplt.xlabel('seconds')\nplt.yticks(np.arange(0, 1.1, step=0.1),['0%','10%','20%','30%','40%','50%','60%','70%','80%','90%','100%'])\n#\nplt.xscale('symlog')\nax.set_xlim(left=80)\nax.set_xlim(right=max_delay)    #TODO increase for 1 month last. logs\n#\nnums = [80,100,1000,10000,100000,200000]  #TODO increase for 1 month last. logs\nlabels = ['','100','1 000','10 000','1e5',' 2e5']   #TODO increase for 1 month last. logs\n\nplt.xticks(nums, labels)\n\ndef retrieve_name(var):\n    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n    return [var_name for var_name, var_val in callers_local_vars if var_val is var]\n\n#for txtype in [s_txs0, s_txs0to20, s_txs20to25, s_txs25to105, s_txs105up]:\n#    for q in [50, 90, 95, 98, 99, 99.5, 100]:\n#        print (retrieve_name(txtype)[0], \":{}%% percentile: {}\".format (q, np.percentile(txtype, q)))\n\nax.legend()\nplt.show()\n","56406966":"#!\/usr\/bin\/python3\nimport pandas as pd\nimport numpy as np\nimport sys\nimport os\nfrom pathlib import Path\nfrom matplotlib.pyplot import figure\nimport inspect\n\nimport matplotlib.pyplot as plt\n\nTXS_LOG = \"\/kaggle\/input\/ethereum-network-measurement\/transactions.csv\/transactions.csv\"\n\ndtypes = {\n        'LocalTimeStamp'    : 'object',\n        'Hash'              : 'object',\n        'GasLimit'          : 'object',\n        'GasPrice'          : 'float',\n        'Value'             : 'object',\n        'Nonce'             : 'object',\n        'MsgType'           : 'object',\n        'Cost'              : 'object',\n        'Size'              : 'object',\n        'To'                : 'object',\n        'From'              : 'object',\n        'ValidityErr'       : 'object',\n        'CapturedLocally'   : 'object',\n        'GasUsed'           : 'object',\n        'InMainBlock'       : 'object',\n        'InUncleBlocks'     : 'object',\n        'InOrder'           : 'object',\n        'NeverCommitting'    : 'object',\n        'CommitTime0'       : 'float',\n        'CommitTime3'       : 'float',\n        'CommitTime12'      : 'float',\n        'CommitTime36'      : 'float',\n        'CommitTime15'      : 'float',\n        }\n\n# DUE TO KAGGLE'S RAM LIMIT\n# we drop 3\/4 of all txs and perfrom this metric only on one quarter of them (5,000,000 out of ~ 20,000,000)\n# run this metric on a machine with RAM big enough if you want to cover all of them\ntxs = pd.read_csv(TXS_LOG, skiprows=1, engine = 'python', nrows=5000000, \n    names=['LocalTimeStamp','Hash','GasLimit','GasPrice','Value','Nonce','MsgType',\n            'Cost','Size','To','From','ValidityErr','CapturedLocally','GasUsed',\n            'InMainBlock','InUncleBlocks','InOrder','NeverCommitting',\n            'CommitTime0','CommitTime3','CommitTime12','CommitTime36'],\n            #usecols=['GasPrice','Hash','CommitTime0','CommitTime3','CommitTime12','CommitTime36'],\n            usecols=['NeverCommitting','From','Nonce','InOrder','CommitTime12'],\n            dtype=dtypes)\n\n# drop all txs without InOrder (those not Committed)  and  without commitTime12 set\ncondition = txs[  (txs['InOrder'].isnull()) | (txs['CommitTime12'].isnull()) ].index\ntxs.drop(condition , inplace=True)\n\ns_in_order     = txs[txs.InOrder == \"True\"].CommitTime12\ns_out_of_order = txs[txs.InOrder == \"False\"].CommitTime12\n\nbin_seq = list(range(0,1000,5))   #TODO increase for 1 month last. logs (10000 good for 4-days) .. 1 000 000 ?\nfig, ax = plt.subplots()\n\nfig.set_size_inches(6,3, forward=True)\n\ncounts_in, bin_edges_in = np.histogram (s_in_order, bins=bin_seq)\ncdf_in = np.cumsum (counts_in)\nlinetxs0, = ax.plot (bin_edges_in[1:], cdf_in\/cdf_in[-1], label='in-order', linestyle='-')\n\ncounts_out, bin_edges_out = np.histogram (s_out_of_order, bins=bin_seq)\ncdf_out = np.cumsum (counts_out)\nlinetxs0to20, = ax.plot (bin_edges_out[1:], cdf_out\/cdf_out[-1], label='out-of-order', linestyle='--')\n\nplt.xlabel('seconds')\nplt.yticks(np.arange(0, 1.1, step=0.1),['0%','10%','20%','30%','40%','50%','60%','70%','80%','90%','100%'])\n#\nplt.xscale('log')\nax.set_xlim(left=90)\nax.set_xlim(right=1000)    #TODO increase for 1 month last. logs\n#\nnums = [100,200,500,1000]  #TODO increase for 1 month last. logs\nlabels = ['100','200','500','1 000']   #TODO increase for 1 month last. logs\n\nplt.xticks(nums, labels)\n\ndef retrieve_name(var):\n    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n    return [var_name for var_name, var_val in callers_local_vars if var_val is var]\n\n#for txtype in [s_in_order, s_out_of_order]:\n#    for q in [50, 90, 95, 100]:\n#        print (retrieve_name(txtype)[0], \":{}%% percentile: {}\".format (q, np.percentile(txtype, q)))\n\nax.legend()\n\nplt.show()\n","3645e130":"#!\/usr\/bin\/python3\nimport pandas as pd\nimport numpy as np\nimport sys\nimport os\nimport matplotlib.pyplot as plt\n\nTXS_LOG = \"\/kaggle\/input\/ethereum-network-measurement\/transactions.csv\/transactions.csv\"\n\ndtypes = {\n        'LocalTimeStamp'    : 'object',\n        'Hash'              : 'object',\n        'GasLimit'          : 'object',\n        'GasPrice'          : 'object',\n        'Value'             : 'object',\n        'Nonce'             : 'object',\n        'MsgType'           : 'object',\n        'Cost'              : 'object',\n        'Size'              : 'object',\n        'To'                : 'object',\n        'From'              : 'object',\n        'ValidityErr'       : 'object',\n        'CapturedLocally'   : 'object',\n        'GasUsed'           : 'object',\n        'InMainBlock'       : 'object',\n        'InUncleBlocks'     : 'object',\n        'InOrder'           : 'object',\n        'NeverCommitting'    : 'object',\n        'CommitTime0'       : 'float',\n        'CommitTime3'       : 'float',\n        'CommitTime12'      : 'float',\n        'CommitTime36'      : 'float',\n        }\n\n# DUE TO KAGGLE'S RAM LIMIT\n# we drop 3\/4 of all txs and perfrom this metric only on one quarter of them (5,000,000 out of ~ 20,000,000)\n# run this metric on a machine with RAM big enough if you want to cover all of them\ntxs = pd.read_csv(TXS_LOG, skiprows=1, engine = 'python', nrows=5000000, \n    names=['LocalTimeStamp','Hash','GasLimit','GasPrice','Value','Nonce','MsgType',\n            'Cost','Size','To','From','ValidityErr','CapturedLocally','GasUsed',\n            'InMainBlock','InUncleBlocks','InOrder','NeverCommitting',\n            'CommitTime0','CommitTime3','CommitTime12','CommitTime36'],\n            usecols=['Hash','CommitTime0','CommitTime3','CommitTime12','CommitTime36','CapturedLocally'],\n            dtype=dtypes)\n\n# drop txs that were not capture locally  \n# leave only those that have all commitTimes set (i.e. drop the latest txs for which\n# we do not have blocks)\n# drop the txs from the beginning of measurement, for which we captured blocks before them\n# this drop is only cosmetical as it drops so few txs that the medians and even means change by 0.01s.\ncondition = txs[   (txs['CapturedLocally'] != \"True\") | \n    (txs['CommitTime0'].isnull()) | (txs['CommitTime36'].isnull()) |\n    (txs['CommitTime3'].isnull()) | (txs['CommitTime12'].isnull()) |\n    (txs['CommitTime0'] < 0) ].index\n\ntxs.drop(condition , inplace=True)\n\ns_c0 = txs[txs.CommitTime0.notnull()].CommitTime0   #check\ns_c3 = txs[txs.CommitTime3.notnull()].CommitTime3   #check\ns_c12 = txs[txs.CommitTime12.notnull()].CommitTime12   #check\ns_c36 = txs[txs.CommitTime36.notnull()].CommitTime36   #check\n\nbin_seq = list(range(0,1000,1))   #TODO CHANGE !!!  set to  max CommitTIme .. eg 1000\nfig, ax = plt.subplots()\n\ncounts_c0, bin_edges_c0 = np.histogram (s_c0, bins=bin_seq)\ncdf_c0 = np.cumsum (counts_c0)\nlinec0, = ax.plot (bin_edges_c0[1:], cdf_c0\/cdf_c0[-1], label='transaction inclusion')\n\ncounts_c3, bin_edges_c3 = np.histogram (s_c3, bins=bin_seq)\ncdf_c3 = np.cumsum (counts_c3)\nlinec3, = ax.plot (bin_edges_c3[1:], cdf_c3\/cdf_c3[-1], label='3 confirmations')\n\ncounts_c12, bin_edges_c12 = np.histogram (s_c12, bins=bin_seq)\ncdf_c12 = np.cumsum (counts_c12)\nlinec12, = ax.plot (bin_edges_c12[1:], cdf_c12\/cdf_c12[-1], label='12 confirmations')\n\ncounts_c36, bin_edges_c36 = np.histogram (s_c36, bins=bin_seq)\ncdf_c36 = np.cumsum (counts_c36)\nlinec36, = ax.plot (bin_edges_c36[1:], cdf_c36\/cdf_c36[-1], label='36 confirmations')\n\n\nplt.xlabel('seconds')\nplt.yticks(np.arange(0, 1.1, step=0.1),['0%','10%','20%','30%','40%','50%','60%','70%','80%','90%','100%'])\n#\n#plt.xscale('symlog')\nax.set_xlim(left=0)\nax.set_xlim(right=1000)\n#\nnums = [0,100,200,300,400,500,600,700,800,900,1000]\nlabels = ['0','100','200','300','400','500','600','700','800','900','1000']\n\nplt.xticks(nums, labels)\n\nax.legend()\n##LOCAL show\nplt.show()\n","58568b1e":"import pandas as pd\nimport numpy as np\nimport sys\nimport os\nfrom pathlib import Path\nfrom matplotlib.pyplot import figure\nimport matplotlib.pyplot as plt\n\nBLOCKS_LOG = \"\/kaggle\/input\/ethereum-network-measurement\/blocks-propagation-times.csv\"\n\ndtypes_blocks_propag_times_v3 = {\n        'BlockHash'         : 'object',\n        'Number'            : 'Int64',\n        'BlockType'         : 'object',\n        'AngainorTimeStamp' : 'object',\n        'FalconTimeStamp'   : 'object',\n        'S1USTimeStamp'     : 'object',\n        'S2CNTimeStamp'     : 'object',\n        'FirstObservation'  : 'object',\n        'AngainorDiff'      : 'float',\n        'FalconDiff'        : 'float',\n        'S1USDiff'          : 'float',\n        'S2CNDiff'          : 'float',\n        'MiningPool'        : 'object',\n        'NumTransactions'   : 'Int64',\n        'SameMinerSeqLen'   : 'Int64',\n        'PositionInsideSeq' : 'Int64',\n        'Difficulty'        : 'Int64',   \n        'BlockSize'         : 'Int64',\n        'InterblockTime'    : 'float',   \n        'InterblockTimePerPool' : 'float',\n        }\n\n#load blocks\nblocks = pd.read_csv(BLOCKS_LOG, skiprows=1,\n    names=['BlockHash','Number','BlockType','AngainorTimeStamp','FalconTimeStamp',\n        'S1USTimeStamp','S2CNTimeStamp','FirstObservation',\n        'AngainorDiff','FalconDiff','S1USDiff','S2CNDiff',\n        'MiningPool','NumTransactions','SameMinerSeqLen','PositionInsideSeq',\n        'Difficulty','BlockSize','InterblockTime','InterblockTimePerPool'],\n    dtype=dtypes_blocks_propag_times_v3)\n\nfirst_receptions_per_instance = []\nfirst_receptions_per_instance_10ms = [] # 90% of ntp has tolerance under 10ms\n\nnum_blocks = len(blocks)\nfirst_receptions_sum = 0\n\nfor i in ['AngainorDiff', 'FalconDiff', 'S1USDiff', 'S2CNDiff']:\n    first_receptions = len(blocks[(blocks[i] == 0 )])\n    #print(\"first receptions:\", first_receptions, round(first_receptions\/num_blocks*100,2), \" %\", i)\n    first_receptions_per_instance.append(len( blocks[  (blocks[i] == 0 ) ] ))\n    first_receptions_per_instance_10ms.append(len( blocks[ (blocks[i] > 0 ) & (blocks[i] <= 0.01 ) ] ))\n\n    first_receptions_sum = first_receptions_sum + first_receptions\n    \n#print(\"blocks:\", len(blocks))\n#print(\"first receptions:\", first_receptions_sum,\n#    \"--- (\", first_receptions_sum-len(blocks), \"times a new block was received on more machines at the same time)\")\n\nx = ['Western\\nEurope', 'Central\\nEurope', 'North\\nAmerica', 'Eastern\\nAsia']\nx_pos = [i for i, _ in enumerate(x)]\nfigure(num=None, figsize=(6, 2), dpi=600, facecolor='w', edgecolor='k')\nbar1 = plt.barh(x_pos, first_receptions_per_instance, color='blue', xerr=[(0,0,0,0),first_receptions_per_instance_10ms])\n\nplt.ylabel(\"Instances\")\nplt.xlabel(\"First receptions of blocks per Ethereum instance\\n\\\n    (NTP in 90% of cases has offset under 10ms - these are shown in the error bars)\")\n\nplt.yticks(x_pos, x, multialignment=\"center\")\nnums = [0,num_blocks\/10,num_blocks\/5,num_blocks*0.3,num_blocks*0.4]\nlabels = ['0 %','10 %','20 %','30 %','40 %']\nplt.xticks(nums, labels)\n\nplt.show()\n","d6c011fe":"import pandas as pd\nimport numpy as np\nimport sys\nimport os\n\nfrom numpy import ma\nfrom matplotlib import scale as mscale\nfrom matplotlib import transforms as mtransforms\nfrom matplotlib.pyplot import figure\nfrom matplotlib.ticker import FixedFormatter, FixedLocator\nimport matplotlib.pyplot as plt\n\n#print all columns (not to cut the tail)\npd.set_option('display.expand_frame_repr', False)\n\nBLOCKS_LOG = \"\/kaggle\/input\/ethereum-network-measurement\/blocks-propagation-times.csv\"\n\ndtypes_blocks_propag_times_v3 = {\n        'BlockHash'         : 'object',\n        'Number'            : 'Int64',\n        'BlockType'         : 'object',\n        'AngainorTimeStamp' : 'object',\n        'FalconTimeStamp'   : 'object',\n        'S1USTimeStamp'     : 'object',\n        'S2CNTimeStamp'     : 'object',\n        'FirstObservation'  : 'object',\n        'AngainorDiff'      : 'float',\n        'FalconDiff'        : 'float',\n        'S1USDiff'          : 'float',\n        'S2CNDiff'          : 'float',\n        'MiningPool'        : 'object',\n        'NumTransactions'   : 'Int64',\n        'SameMinerSeqLen'   : 'Int64',\n        'PositionInsideSeq' : 'Int64',\n        'Difficulty'        : 'Int64',   \n        'BlockSize'         : 'Int64',\n        'InterblockTime'    : 'float',   \n        'InterblockTimePerPool' : 'float',\n        }\n\n#load blocks\nblocks = pd.read_csv(BLOCKS_LOG, skiprows=1,\n    names=['BlockHash','Number','BlockType','AngainorTimeStamp','FalconTimeStamp',\n        'S1USTimeStamp','S2CNTimeStamp','FirstObservation',\n        'AngainorDiff','FalconDiff','S1USDiff','S2CNDiff',\n        'MiningPool','NumTransactions','SameMinerSeqLen','PositionInsideSeq',\n        'Difficulty','BlockSize','InterblockTime','InterblockTimePerPool'],\n    dtype=dtypes_blocks_propag_times_v3)\n\ntop_15_pools = ['Ethermine', 'Sparkpool', 'f2pool2', 'Nanopool', 'miningpoolhub1',\n    'HuoBi.pro', 'pandapool', 'DwarfPool1', 'xnpool', 'uupool', 'Minerall', 'firepool',\n    'zhizhu', 'MiningExpress', 'Hiveon',]\n\n# for each pool out of top-15\n# set 'MiningPool' to  \"remaining\" \nblocks.loc[~blocks.MiningPool.isin(top_15_pools), 'MiningPool'] = 'remaining'\n\n#  crate a data framame with selected 15 pools (in order by power)  +  'remaining' (pools)\nmin_pools_list = ['Ethermine', 'Sparkpool', 'f2pool2', 'Nanopool', 'miningpoolhub1',\n    'HuoBi.pro', 'pandapool', 'DwarfPool1', 'xnpool', 'uupool', 'Minerall', 'firepool',\n    'zhizhu', 'MiningExpress', 'Hiveon', 'remaining']\nmin_pools = pd.DataFrame(min_pools_list, columns =['MiningPool'])\nmin_pools.set_index('MiningPool', inplace=True)\n\nmin_pools = min_pools.assign(\n    pt = 0, cz = 0, us = 0, cn = 0,\n    pt10ms = 0, cz10ms = 0, us10ms = 0, cn10ms = 0)\n\nfor i in blocks.index:\n    currentMiner = blocks.at[i,'MiningPool']\n    \n    if blocks.at[i,'AngainorDiff'] <= 0:\n        min_pools.at[currentMiner, 'pt'] = min_pools.at[currentMiner, 'pt'] + 1\n    if blocks.at[i,'FalconDiff'] <= 0:\n        min_pools.at[currentMiner, 'cz'] = min_pools.at[currentMiner, 'cz'] + 1\n    if blocks.at[i,'S1USDiff'] <= 0:\n        min_pools.at[currentMiner, 'us'] = min_pools.at[currentMiner, 'us'] + 1\n    if blocks.at[i,'S2CNDiff'] <= 0:\n        min_pools.at[currentMiner, 'cn'] = min_pools.at[currentMiner, 'cn'] + 1\n    if blocks.at[i,'AngainorDiff'] <= 0.01:\n        min_pools.at[currentMiner, 'pt10ms'] = min_pools.at[currentMiner, 'pt10ms'] + 1\n    if blocks.at[i,'FalconDiff'] <= 0.01:\n        min_pools.at[currentMiner, 'cz10ms'] = min_pools.at[currentMiner, 'cz10ms'] + 1\n    if blocks.at[i,'S1USDiff'] <= 0.01:\n        min_pools.at[currentMiner, 'us10ms'] = min_pools.at[currentMiner, 'us10ms'] + 1\n    if blocks.at[i,'S2CNDiff'] <= 0.01:\n        min_pools.at[currentMiner, 'cn10ms'] = min_pools.at[currentMiner, 'cn10ms'] + 1\n\n#set figure size\nfigure(num=None, figsize=(6, 3), dpi=600, facecolor='w', edgecolor='k')\n\ndef print_bar_graph(min_pools, precision10ms):\n    if precision10ms == False:\n        PT = 'pt'\n        CZ = 'cz'\n        US = 'us'\n        CN = 'cn'\n    else:\n        PT = 'pt10ms'\n        CZ = 'cz10ms'\n        US = 'us10ms'\n        CN = 'cn10ms'\n\n    #only 15 biggest pools + 1 (remaining)  = 16\n    #min_pools = min_pools[:16]  #  set 15   if you want withou REMAINING\n    r = list(range(0,16))        #  set 15   if you want withou REMAINING\n\n    # From raw value to percentage\n    totals = [i+j+k+l for i,j,k,l in zip(min_pools[PT].reset_index(drop=True),\n        min_pools[CZ].reset_index(drop=True), min_pools[US].reset_index(drop=True),\n        min_pools[CN].reset_index(drop=True))]\n\n    pt = [i \/ j * 100 for i,j in zip(min_pools[PT].reset_index(drop=True), totals)]\n    cz = [i \/ j * 100 for i,j in zip(min_pools[CZ].reset_index(drop=True), totals)]\n    us = [i \/ j * 100 for i,j in zip(min_pools[US].reset_index(drop=True), totals)]\n    cn = [i \/ j * 100 for i,j in zip(min_pools[CN].reset_index(drop=True), totals)]\n\n    barWidth = 0.85\n    names = ('Ethermine','Sparkpool','F2pool2','Nanopool',\n        'Miningpoolhub1', 'HuoBi.pro', 'Pandapool', 'DwarfPool1',\n        'Xnpool', 'Uupool', 'Minerall', 'Firepool',\n        'Zhizhu', 'MiningExpress', 'Hiveon', 'Remaining miners')\n\n    plt.bar(r, pt, color='#ccccca', edgecolor='white', width=barWidth, label=\"Western\\nEurope\")\n    plt.bar(r, cz, bottom=pt, color='#a0a09e', edgecolor='white', width=barWidth, label=\"Central\\nEurope\")\n    plt.bar(r, us, bottom=[i+j for i,j in zip(pt, cz)], color='#4d4d4c', edgecolor='white',\n        width=barWidth, label=\"North\\nAmerica\")\n    plt.bar(r, cn, bottom=[i+j+k for i,j,k in zip(pt, cz, us)], color='#292928',\n        edgecolor='white', width=barWidth, label=\"Eastern\\nAsia\")\n\n    plt.xticks(r, names, rotation=90)\n    plt.ylabel(\"First new block observation\")\n    plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n    plt.ylim(bottom=0)\n    plt.yticks([0,25,50,75,100], ['0','25 %','50 %','75 %','100 %'])\n    plt.show()\n\nprint_bar_graph(min_pools, True)\n","d304faa9":"import pandas as pd\nimport numpy as np\nimport sys\nimport os\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\n\npd.set_option('display.expand_frame_repr', False)\n\nBLOCKS = \"\/kaggle\/input\/ethereum-network-measurement\/blocks.csv\/blocks.csv\"\n\ndtypes_blocks = {\n        'LocalTimeStamp'    : 'object',\n        'BlockHash'     : 'object',\n        'Number'        : 'object',\n        'GasLimit'      : 'object',\n        'GasUsed'       : 'object',\n        'Difficulty'    : 'object',\n        'Time'          : 'object',\n        'Coinbase'      : 'object',\n        'ParentHash'    : 'object',\n        'UncleHash'     : 'object',\n        'BlockSize'     : 'object',\n        'ListOfTxs'     : 'object',\n        'ListOfUncles'  : 'object',\n        'CapturedLocally'   : 'bool',\n        'BlockType'         : 'object',\n        'ForkLength'    : 'int',\n        }\n\nblocks = pd.read_csv(BLOCKS, skiprows=1, engine = 'python',\n    names=['LocalTimeStamp','BlockHash','Number','GasLimit','GasUsed','Difficulty','Time',\n    'Coinbase','ParentHash','UncleHash','BlockSize','ListOfTxs','ListOfUncles',\n    'CapturedLocally','BlockType','ForkLength'],\n    usecols=['BlockHash','Number', 'Coinbase','BlockType', 'ListOfTxs'],\n    dtype=dtypes_blocks)\n\n# assign number of txs to every block\nblocks = blocks.assign(NumTxs = 0)\nfor id_block, row in blocks.iterrows():\n    try:\n        txs = row['ListOfTxs'].split(\";\")\n        #remove empty lines (there is always one empty line at the end of the list)\n        txs = list(filter(None, txs))\n        num_txs_in_uncle_block = len(txs)\n    except AttributeError:\n        num_txs_in_uncle_block = 0\n    \n    blocks.at[id_block, 'NumTxs'] = num_txs_in_uncle_block\n\nnum_total = len(blocks)\nnum_with_zero_txs = len(blocks[blocks.NumTxs == 0])\n\nnum_main_total = len(blocks[blocks.BlockType == \"Main\"])\nnum_main_with_zero_txs = len(blocks[(blocks.BlockType == \"Main\") & (blocks.NumTxs == 0)])\n\nproportion = num_with_zero_txs \/ num_total\n#print(\"BLOCKS:\", num_total, \"EMPTY BLOCKS:\", num_with_zero_txs,\n#    \"proportion of empty blocks:\", proportion)\n\n####### ASSIGN\nblocks = blocks.assign(MiningPool = \"ALL-OTHER-MINERS\")\nblocks.loc[blocks['Coinbase'] == \"0xEA674fdDe714fd979de3EdF0F56AA9716B898ec8\", 'MiningPool'] = \"Ethermine\"\nblocks.loc[blocks['Coinbase'] == \"0x5A0b54D5dc17e0AadC383d2db43B0a0D3E029c4c\", 'MiningPool'] = \"Sparkpool\"\nblocks.loc[blocks['Coinbase'] == \"0x829BD824B016326A401d083B33D092293333A830\", 'MiningPool'] = \"f2pool2\"\nblocks.loc[blocks['Coinbase'] == \"0x52bc44d5378309EE2abF1539BF71dE1b7d7bE3b5\", 'MiningPool'] = \"Nanopool\"\nblocks.loc[blocks['Coinbase'] == \"0xb2930B35844a230f00E51431aCAe96Fe543a0347\", 'MiningPool'] = \"miningpoolhub1\"\nblocks.loc[blocks['Coinbase'] == \"0x1B5B5906306c96b842dc03105E3b38636A4EDa0b\", 'MiningPool'] = \"HuoBi.pro\"\nblocks.loc[blocks['Coinbase'] == \"0x2a5994b501E6A560e727b6C2DE5D856396aaDd38\", 'MiningPool'] = \"pandapool\"\nblocks.loc[blocks['Coinbase'] == \"0x2a65Aca4D5fC5B5C859090a6c34d164135398226\", 'MiningPool'] = \"DwarfPool1\"\nblocks.loc[blocks['Coinbase'] == \"0x005e288D713a5fB3d7c9cf1B43810A98688C7223\", 'MiningPool'] = \"xnpool\"\nblocks.loc[blocks['Coinbase'] == \"0xD224cA0c819e8E97ba0136B3b95ceFf503B79f53\", 'MiningPool'] = \"uupool\"\nblocks.loc[blocks['Coinbase'] == \"0x09ab1303d3CcAF5f018CD511146b07A240c70294\", 'MiningPool'] = \"Minerall\"\nblocks.loc[blocks['Coinbase'] == \"0x35F61DFB08ada13eBA64Bf156B80Df3D5B3a738d\", 'MiningPool'] = \"firepool\"\nblocks.loc[blocks['Coinbase'] == \"0x04668Ec2f57cC15c381b461B9fEDaB5D451c8F7F\", 'MiningPool'] = \"zhizhu\"\nblocks.loc[blocks['Coinbase'] == \"0x06B8C5883Ec71bC3f4B332081519f23834c8706E\", 'MiningPool'] = \"MiningExpress\"\nblocks.loc[blocks['Coinbase'] == \"0x4C549990A7eF3FEA8784406c1EECc98bF4211fA5\", 'MiningPool'] = \"Hiveon\"\n\n#  crate a data framame   with  one min. pool  for each row\nmin_pools_list = blocks['MiningPool'].unique() \n\nmin_pools = pd.DataFrame(min_pools_list, columns =['Pool'])\nmin_pools.set_index('Pool', inplace=True)\n\ncounts_of_blcks_per_pool = blocks['MiningPool'].value_counts(dropna=False)\n\nempty_blocks = blocks[ blocks['NumTxs'] == 0 ]\nnot_empty_blocks = blocks[ blocks['NumTxs'] != 0 ]\n\nmin_pools = min_pools.assign(blocks = np.nan, empty_blocks = np.nan,\n    emptyVStotBlocks = np.nan)\n\nfor i in min_pools.index:\n    num_empty = len(empty_blocks[empty_blocks['MiningPool'] == i])\n    min_pools.at[i, 'empty_blocks'] = num_empty\n    num_blocks = len(blocks[blocks['MiningPool'] == i])\n    min_pools.at[i, 'blocks'] = num_blocks\n    min_pools.at[i, 'emptyVStotBlocks'] = num_empty \/ num_blocks\n\nmin_pools['blocks'] = min_pools['blocks'].apply(np.int64)\nmin_pools['empty_blocks'] = min_pools['empty_blocks'].apply(np.int64)\n\nmin_pools = min_pools.reindex(['Ethermine', 'Sparkpool', 'f2pool2', 'Nanopool', 'miningpoolhub1',\n    'HuoBi.pro', 'pandapool', 'DwarfPool1', 'xnpool', 'uupool', 'Minerall', 'firepool',\n    'zhizhu', 'MiningExpress', 'Hiveon','ALL-OTHER-MINERS'])\n\n### select except ALL-OTHER\n#pools_selection = min_pools[   (min_pools.index != \"ALL-OTHER-MINERS\")      ]\npools_selection = min_pools\n\nx = ['Ethermine', 'Sparkpool', 'F2pool2', 'Nanopool', 'Miningpoolhub1',\n    'HuoBi.pro', 'Pandapool', 'DwarfPool1', 'Xnpool', 'Uupool', 'Minerall', 'Firepool',\n    'Zhizhu', 'MiningExpress', 'Hiveon','Remaining pools']\n\ns_pools = pools_selection.empty_blocks\n\ns_pools = np.flip(s_pools)  \nx.reverse()\n\nx_pos = [i for i, _ in enumerate(x)]\n\n#set figure size\nfigure(num=None, figsize=(6, 3), dpi=600, facecolor='w', edgecolor='k')\n#fig.set_size_inches(6,3, forward=True)\n\n\nplt.barh(x_pos, s_pools, color='blue')\nplt.ylabel(\"Miners\")\nplt.xlabel(\"Total number of empty blocks\")\n#plt.title(\"Empty blocks of the 15 biggest mining entities\")\n\nplt.yticks(x_pos, x)\n\nnums = [10,100,500,1000,1191]\nlabels = ['10','100','500','1000','1191']\n\nplt.xticks(nums, labels)\n\nplt.show()\n\n#print\nmin_pools['emptyVStotBlocks'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in min_pools['emptyVStotBlocks']], index = min_pools.index)\nprint (min_pools)\n","c6a312eb":"import pandas as pd\nimport numpy as np\nimport sys\nimport os\n\nfrom numpy import ma\nfrom matplotlib import scale as mscale\nfrom matplotlib import transforms as mtransforms\nfrom matplotlib.ticker import FixedFormatter, FixedLocator\nfrom matplotlib.pyplot import figure\n\nimport matplotlib.pyplot as plt\n\n#print all columns (not to cut the tail)\npd.set_option('display.expand_frame_repr', False)\n\nBLOCKS = \"\/kaggle\/input\/ethereum-network-measurement\/blocks.csv\/blocks.csv\"\n\ndtypes_blocks = {\n        'LocalTimeStamp'    : 'object',\n        'BlockHash'     : 'object',\n        'Number'        : 'object',\n        'GasLimit'      : 'object',\n        'GasUsed'       : 'object',\n        'Difficulty'    : 'object',\n        'Time'          : 'object',\n        'Coinbase'      : 'object',\n        'ParentHash'    : 'object',\n        'UncleHash'     : 'object',\n        'BlockSize'     : 'object',\n        'ListOfTxs'     : 'object',\n        'ListOfUncles'  : 'object',\n        'CapturedLocally'   : 'bool',\n        'BlockType'         : 'object',\n        'ForkLength'    : 'int',\n        }\n\nblocks = pd.read_csv(BLOCKS, skiprows=1, engine = 'python',\n    names=['LocalTimeStamp','BlockHash','Number','GasLimit','GasUsed','Difficulty','Time',\n    'Coinbase','ParentHash','UncleHash','BlockSize','ListOfTxs','ListOfUncles',\n    'CapturedLocally','BlockType','ForkLength'],\n    usecols=['BlockHash','Number', 'Coinbase','BlockType'],\n    dtype=dtypes_blocks)\n\nlen_blocks = len(blocks)\nprint(\"blocks total:  \", len_blocks)\n\n####### ASSIGN\nblocks = blocks.assign(MiningPool = \"ALL-OTHER-MINERS\", probNext = np.nan, SameMinSeq = np.nan)\nblocks.loc[blocks['Coinbase'] == \"0xEA674fdDe714fd979de3EdF0F56AA9716B898ec8\", 'MiningPool'] = \"Ethermine\"\nblocks.loc[blocks['Coinbase'] == \"0x5A0b54D5dc17e0AadC383d2db43B0a0D3E029c4c\", 'MiningPool'] = \"Sparkpool\"\nblocks.loc[blocks['Coinbase'] == \"0x829BD824B016326A401d083B33D092293333A830\", 'MiningPool'] = \"f2pool2\"\nblocks.loc[blocks['Coinbase'] == \"0x52bc44d5378309EE2abF1539BF71dE1b7d7bE3b5\", 'MiningPool'] = \"Nanopool\"\nblocks.loc[blocks['Coinbase'] == \"0xb2930B35844a230f00E51431aCAe96Fe543a0347\", 'MiningPool'] = \"miningpoolhub1\"\nblocks.loc[blocks['Coinbase'] == \"0x1B5B5906306c96b842dc03105E3b38636A4EDa0b\", 'MiningPool'] = \"HuoBi.pro\"\nblocks.loc[blocks['Coinbase'] == \"0x2a5994b501E6A560e727b6C2DE5D856396aaDd38\", 'MiningPool'] = \"pandapool\"\nblocks.loc[blocks['Coinbase'] == \"0x2a65Aca4D5fC5B5C859090a6c34d164135398226\", 'MiningPool'] = \"DwarfPool1\"\nblocks.loc[blocks['Coinbase'] == \"0x005e288D713a5fB3d7c9cf1B43810A98688C7223\", 'MiningPool'] = \"xnpool\"\nblocks.loc[blocks['Coinbase'] == \"0xD224cA0c819e8E97ba0136B3b95ceFf503B79f53\", 'MiningPool'] = \"uupool\"\nblocks.loc[blocks['Coinbase'] == \"0x09ab1303d3CcAF5f018CD511146b07A240c70294\", 'MiningPool'] = \"Minerall\"\nblocks.loc[blocks['Coinbase'] == \"0x35F61DFB08ada13eBA64Bf156B80Df3D5B3a738d\", 'MiningPool'] = \"firepool\"\nblocks.loc[blocks['Coinbase'] == \"0x04668Ec2f57cC15c381b461B9fEDaB5D451c8F7F\", 'MiningPool'] = \"zhizhu\"\nblocks.loc[blocks['Coinbase'] == \"0x06B8C5883Ec71bC3f4B332081519f23834c8706E\", 'MiningPool'] = \"MiningExpress\"\nblocks.loc[blocks['Coinbase'] == \"0x4C549990A7eF3FEA8784406c1EECc98bF4211fA5\", 'MiningPool'] = \"Hiveon\"\nblocks.loc[blocks['Coinbase'] == \"0x84A0d77c693aDAbE0ebc48F88b3fFFF010577051\", 'MiningPool'] = \"(0x84A0d7..)\"\nblocks.loc[blocks['Coinbase'] == \"0xAA5c4244F05c92781C4F259913319d8ba1aCF05E\", 'MiningPool'] = \"(0xAA5c42..)\"\nblocks.loc[blocks['Coinbase'] == \"0x00192Fb10dF37c9FB26829eb2CC623cd1BF599E8\", 'MiningPool'] = \"2miners\"\nblocks.loc[blocks['Coinbase'] == \"0x52E44f279f4203Dcf680395379E5F9990A69f13c\", 'MiningPool'] = \"bw\"\nblocks.loc[blocks['Coinbase'] == \"0x6a7a43BE33ba930fE58F34E07D0ad6bA7ADB9B1F\", 'MiningPool'] = \"Coinotron\"\nblocks.loc[blocks['Coinbase'] == \"0x858fDEC2da9fA3CD3d97B8Bd1af98E9249D33613\", 'MiningPool'] = \"(0x858fDE..)\"\nblocks.loc[blocks['Coinbase'] == \"0x002e08000acbbaE2155Fab7AC01929564949070d\", 'MiningPool'] = \"2minerssolo\"\n\nclass CloseToOne(mscale.ScaleBase):\n    name = 'close_to_one'\n\n    def __init__(self, axis, **kwargs):\n        mscale.ScaleBase.__init__(self)\n        self.nines = kwargs.get('nines', 5)\n\n    def get_transform(self):\n        return self.Transform(self.nines)\n\n    def set_default_locators_and_formatters(self, axis):\n        axis.set_major_locator(FixedLocator(\n                np.array([1-10**(-k) for k in range(1+self.nines)])))\n        axis.set_major_formatter(FixedFormatter(\n                [str(1-10**(-k)) for k in range(1+self.nines)]))\n\n    def limit_range_for_scale(self, vmin, vmax, minpos):\n        return vmin, min(1 - 10**(-self.nines), vmax)\n\n    class Transform(mtransforms.Transform):\n        input_dims = 1\n        output_dims = 1\n        is_separable = True\n\n        def __init__(self, nines):\n            mtransforms.Transform.__init__(self)\n            self.nines = nines\n\n        def transform_non_affine(self, a):\n            masked = ma.masked_where(a > 1-10**(-1-self.nines), a)\n            if masked.mask.any():\n                return -ma.log10(1-a)\n            else:\n                return -np.log10(1-a)\n\n        def inverted(self):\n            return CloseToOne.InvertedTransform(self.nines)\n\n    class InvertedTransform(mtransforms.Transform):\n        input_dims = 1\n        output_dims = 1\n        is_separable = True\n\n        def __init__(self, nines):\n            mtransforms.Transform.__init__(self)\n            self.nines = nines\n\n        def transform_non_affine(self, a):\n            return 1. - 10**(-a)\n\n        def inverted(self):\n            return CloseToOne.Transform(self.nines)\n\nmscale.register_scale(CloseToOne)\n\n#  take only  MAIN blocks from now\nmain_blocks = blocks[ blocks['BlockType'] == \"Main\" ]\nrec_uncle_blocks = blocks[ blocks['BlockType'] == \"Recognized\" ]\nunrec_forked_blocks = blocks[ blocks['BlockType'] == \"Uncle\" ]\n\nlen_man_blocks = len(main_blocks)\nprint(\"main blocks total:  \", len_man_blocks)\ncounts_of_blcks_per_pool = main_blocks[\"MiningPool\"].value_counts()\n\n#  crate a data framame   with  one min. pool  for each row\nmin_pools_list = main_blocks['MiningPool'].unique() \n\nmin_pools = pd.DataFrame(min_pools_list, columns =['Pool'])\nmin_pools.set_index('Pool', inplace=True)\n\nmin_pools = min_pools.assign(count = counts_of_blcks_per_pool, countVStotal = np.nan, SameMinSeq = 0,\n    seqVScount = np.nan, col_2_4_corel = np.nan,\n    seq_1 = 0, seq_2 = 0, seq_3 = 0, seq_4 = 0, seq_5 = 0,\n    seq_6 = 0, seq_7 = 0, seq_8 = 0, seq_9 = 0, seq_10 = 0)   #seq_10 means anything over 9,. e.g. 10,11,12..\n\nfor i in min_pools.index:\n    min_pools.at[i, 'countVStotal'] = min_pools.at[i, 'count'] \/ len_man_blocks\n\nmin_pools = min_pools.sort_values('count', ascending=False)\n\n#  reset index, because we dropped some forks and uncles\nmain_blocks.reset_index(inplace=True, drop=True)\n\n#loop all  main blocks   (SORTED BY   Num  (ascending))\ncur_seq = 1\n\nfor i in main_blocks.index:\n\n    if i == 0:\n        prevMiner = main_blocks.at[i, 'MiningPool']\n        continue\n\n    if main_blocks.at[i, 'MiningPool'] == prevMiner:\n        min_pools.at[prevMiner, 'SameMinSeq'] = min_pools.at[prevMiner, 'SameMinSeq'] + 1\n        cur_seq = cur_seq + 1\n    else:\n        if cur_seq == 1:\n            min_pools.at[prevMiner, 'seq_1'] = min_pools.at[prevMiner, 'seq_1'] + 1\n        elif cur_seq == 2:\n            min_pools.at[prevMiner, 'seq_2'] = min_pools.at[prevMiner, 'seq_2'] + 1\n        elif cur_seq == 3:\n            min_pools.at[prevMiner, 'seq_3'] = min_pools.at[prevMiner, 'seq_3'] + 1\n        elif cur_seq == 4:\n            min_pools.at[prevMiner, 'seq_4'] = min_pools.at[prevMiner, 'seq_4'] + 1\n        elif cur_seq == 5:\n            min_pools.at[prevMiner, 'seq_5'] = min_pools.at[prevMiner, 'seq_5'] + 1\n        elif cur_seq == 6:\n            min_pools.at[prevMiner, 'seq_6'] = min_pools.at[prevMiner, 'seq_6'] + 1\n        elif cur_seq == 7:\n            min_pools.at[prevMiner, 'seq_7'] = min_pools.at[prevMiner, 'seq_7'] + 1\n        elif cur_seq == 8:\n            min_pools.at[prevMiner, 'seq_8'] = min_pools.at[prevMiner, 'seq_8'] + 1\n\n            # print    miner and block num\n            print(\"LEN-8\", main_blocks.at[i-1, 'MiningPool'], main_blocks.at[i-8, 'Number'],\n            main_blocks.at[i-1, 'Number'])\n\n        elif cur_seq == 9:\n            min_pools.at[prevMiner, 'seq_9'] = min_pools.at[prevMiner, 'seq_9'] + 1\n\n            # print    miner and block num\n            print(\"LEN-9\", main_blocks.at[i-1, 'MiningPool'], main_blocks.at[i-9, 'Number'], \n            main_blocks.at[i-1, 'Number'])\n\n        elif cur_seq > 9:\n            min_pools.at[prevMiner, 'seq_10'] = min_pools.at[prevMiner, 'seq_10'] + 1  #seq_10 means anything over 9,. e.g. 10,11,12..\n\n        cur_seq = 1\n\n    prevMiner = main_blocks.at[i, 'MiningPool']\n\n    # need to set len of seq for the last block\n    if i == main_blocks.index[-1]:\n        cur_miner = main_blocks.at[i, 'MiningPool']\n        seq_str = \"seq_\" + str(cur_seq)\n        min_pools.at[cur_miner, seq_str] = min_pools.at[cur_miner, seq_str] + 1\n    \nfor i in min_pools.index:\n    min_pools.at[i, 'seqVScount'] = min_pools.at[i, 'SameMinSeq'] \/ min_pools.at[i, 'count']\n    min_pools.at[i, 'col_2_4_corel'] = min_pools.at[i, 'seqVScount'] - min_pools.at[i, 'countVStotal']\n\ndef print_bar_graph(min_pools):\n    #only 5 biggest pools\n    min_pools = min_pools[:5]\n    r = list(range(0,5))\n\n    # From raw value to percentage\n    totals = [i+j+k+l+m+n+o+p+q for i,j,k,l,m,n,o,p,q in zip(min_pools['seq_1'].reset_index(drop=True),\n        min_pools['seq_2'].reset_index(drop=True), min_pools['seq_3'].reset_index(drop=True),\n        min_pools['seq_4'].reset_index(drop=True), min_pools['seq_5'].reset_index(drop=True),\n        min_pools['seq_6'].reset_index(drop=True), min_pools['seq_7'].reset_index(drop=True),\n        min_pools['seq_8'].reset_index(drop=True), min_pools['seq_9'].reset_index(drop=True))]\n\n    seq_1 = [i \/ j * 100 for i,j in zip(min_pools['seq_1'].reset_index(drop=True), totals)]\n    seq_2 = [i \/ j * 100 for i,j in zip(min_pools['seq_2'].reset_index(drop=True), totals)]\n    seq_3 = [i \/ j * 100 for i,j in zip(min_pools['seq_3'].reset_index(drop=True), totals)]\n    seq_4 = [i \/ j * 100 for i,j in zip(min_pools['seq_4'].reset_index(drop=True), totals)]\n    seq_5 = [i \/ j * 100 for i,j in zip(min_pools['seq_5'].reset_index(drop=True), totals)]\n    seq_6 = [i \/ j * 100 for i,j in zip(min_pools['seq_6'].reset_index(drop=True), totals)]\n    seq_7 = [i \/ j * 100 for i,j in zip(min_pools['seq_7'].reset_index(drop=True), totals)]\n    seq_8 = [i \/ j * 100 for i,j in zip(min_pools['seq_8'].reset_index(drop=True), totals)]\n    seq_9 = [i \/ j * 100 for i,j in zip(min_pools['seq_9'].reset_index(drop=True), totals)]\n    \n    # plot\n    barWidth = 0.85\n    names = ('Ethermine','Sparkpool','F2pool2','Nanopool','Miningpoolhub1')\n\n    # Create green Bars\n    plt.bar(r, seq_1, color='#b5ffb9', edgecolor='white', width=barWidth, label=\"unique block\")\n    # Create orange Bars\n    plt.bar(r, seq_2, bottom=seq_1, color='#f9bc86', edgecolor='white', width=barWidth, label=\"sequence of 2\")\n    # Create blue Bars\n    plt.bar(r, seq_3, bottom=[i+j for i,j in zip(seq_1, seq_2)], color='#a3acff', edgecolor='white', width=barWidth, label=\"sequence of 3\")\n    # Create blue Bars\n    plt.bar(r, seq_4, bottom=[i+j+k for i,j,k in zip(seq_1, seq_2, seq_3)], color='#c3acff', edgecolor='white', width=barWidth, label=\"sequence of 4\")\n    # Create blue Bars\n    plt.bar(r, seq_5, bottom=[i+j+k+l for i,j,k,l in zip(seq_1, seq_2, seq_3, seq_4)], color='#f1acff', edgecolor='white', width=barWidth, label=\"sequence of 5+\")\n    # Create blue Bars\n    plt.bar(r, seq_6, bottom=[i+j+k+l+m for i,j,k,l,m in zip(seq_1, seq_2, seq_3, seq_4, seq_5)], color='#b3acff', edgecolor='white', width=barWidth)\n    # Create blue Bars\n    plt.bar(r, seq_7, bottom=[i+j+k+l+m+n for i,j,k,l,m,n in zip(seq_1, seq_2, seq_3, seq_4, seq_5, seq_6)], color='#e3acff', edgecolor='white', width=barWidth)\n    # Create blue Bars\n    plt.bar(r, seq_8, bottom=[i+j+k+l+m+n+o for i,j,k,l,m,n,o in zip(seq_1, seq_2, seq_3, seq_4, seq_5, seq_6, seq_7)], color='#c3acff', edgecolor='white', width=barWidth)\n    # Create blue Bars\n    plt.bar(r, seq_9, bottom=[i+j+k+l+m+n+o+p for i,j,k,l,m,n,o,p in zip(seq_1, seq_2, seq_3, seq_4, seq_5, seq_6, seq_7, seq_8)], color='#a3acff', edgecolor='white', width=barWidth)\n\n    # Custom x axis\n    plt.xticks(r, names)\n\n    # Add a legend\n    plt.legend(loc='upper left', bbox_to_anchor=(1,1), ncol=1)\n\n    plt.ylim(bottom=70)\n    plt.yticks([70,75,80,85,90,95,100], ['70 %','75 %','80 %','85 %','90 %','95 %','100 %'])\n\n    plt.show()\n\n\ndef print_cdf(min_pools):\n\n    #6 biggest\n    s_ethermine = []\n    s_sparkpool = []\n    s_f2pool2 = []\n    s_Nanopool = []\n    s_miningpoolhub1 = []\n    s_huobi = []\n\n    for i in range(1,11): # seq_1 to seq_10\n        num = min_pools.at['Ethermine', 'seq_' + str(i)]\n        s_ethermine.extend([i for j in range(num)])\n\n        num = min_pools.at['Sparkpool', 'seq_' + str(i)]\n        s_sparkpool.extend([i for j in range(num)])\n\n        num = min_pools.at['f2pool2', 'seq_' + str(i)]\n        s_f2pool2.extend([i for j in range(num)])\n\n        num = min_pools.at['Nanopool', 'seq_' + str(i)]\n        s_Nanopool.extend([i for j in range(num)])\n\n        num = min_pools.at['miningpoolhub1', 'seq_' + str(i)]\n        s_miningpoolhub1.extend([i for j in range(num)])\n\n        num = min_pools.at['HuoBi.pro', 'seq_' + str(i)]\n        s_huobi.extend([i for j in range(num)])\n\n    bin_seq = list(range(0,11,1))\n    fig, ax = plt.subplots()\n\n    #set figure size\n    #figure(num=None, figsize=(6, 3), dpi=600, facecolor='w', edgecolor='k')\n    fig.set_size_inches(6,3, forward=True)\n\n    counts_ethermine, bin_edges_ethermine = np.histogram (s_ethermine, bins=bin_seq)\n    cdf_ethermine = np.cumsum (counts_ethermine)\n    #convert all Y==1 to Y=0.9999 because of plot\n    yaxis = [0.99999 if x == 1 else x for x in cdf_ethermine\/cdf_ethermine[-1]]\n    lineethermine, = ax.plot (bin_edges_ethermine[1:], yaxis,drawstyle='steps-pre', label='Ethermine', linestyle=':')\n\n    counts_sparkpool, bin_edges_sparkpool = np.histogram (s_sparkpool, bins=bin_seq)\n    cdf_sparkpool = np.cumsum (counts_sparkpool)\n    #convert all Y==1 to Y=0.9999 because of plot\n    yaxis = [0.99999 if x == 1 else x for x in cdf_sparkpool\/cdf_sparkpool[-1]]\n    linesparkpool, = ax.plot (bin_edges_sparkpool[1:], yaxis,drawstyle='steps-pre', label='Sparkpool', linestyle='--')\n\n    counts_f2pool2, bin_edges_f2pool2 = np.histogram (s_f2pool2, bins=bin_seq)\n    cdf_f2pool2 = np.cumsum (counts_f2pool2)\n    yaxis = [0.99999 if x == 1 else x for x in cdf_f2pool2\/cdf_f2pool2[-1]]\n    linef2pool2, = ax.plot (bin_edges_f2pool2[1:], yaxis,drawstyle='steps-pre', label='F2pool2', linestyle='-.')\n\n    counts_Nanopool, bin_edges_Nanopool = np.histogram (s_Nanopool, bins=bin_seq)\n    cdf_Nanopool = np.cumsum (counts_Nanopool)\n    yaxis = [0.99999 if x == 1 else x for x in cdf_Nanopool\/cdf_Nanopool[-1]]\n    lineNanopool, = ax.plot (bin_edges_Nanopool[1:], yaxis,drawstyle='steps-pre', label='Nanopool', linestyle='-')\n\n    counts_miningpoolhub1, bin_edges_miningpoolhub1 = np.histogram (s_miningpoolhub1, bins=bin_seq)\n    cdf_miningpoolhub1 = np.cumsum (counts_miningpoolhub1)\n    yaxis = [0.99999 if x == 1 else x for x in cdf_miningpoolhub1\/cdf_miningpoolhub1[-1]]\n    lineminingpoolhub1, = ax.plot (bin_edges_miningpoolhub1[1:], yaxis,drawstyle='steps-pre', label='Miningpoolhub1', linestyle=':')\n\n    counts_huobi, bin_edges_huobi = np.histogram (s_huobi, bins=bin_seq)\n    cdf_huobi = np.cumsum (counts_huobi)\n    yaxis = [0.99999 if x == 1 else x for x in cdf_huobi\/cdf_huobi[-1]]\n    linehuobi, = ax.plot (bin_edges_huobi[1:], yaxis,drawstyle='steps-pre', label='HuoBi.pro', linestyle='--')\n\n    plt.xlabel('Mainchain block sequence length')\n    plt.ylabel('CDF (logarithmic scale)')\n\n    ax.set_axisbelow(True)\n\n    # Customize the grid\n    ax.grid(linestyle=':', linewidth='0.3')#, color='red')\n\n    ax.set_xlim(left=0.8)\n    ax.set_xlim(right=10)\n    nums = [1,2,3,4,5,6,7,8,9,10]\n    labels = ['1','2','3','4','5','6','7','8','9','9+']\n\n    plt.xticks(nums, labels)\n    ax.legend()\n    plt.yscale('close_to_one', nines=5)    \n    plt.show()\n\n#print(min_pools)\n\n#print_bar_graph(min_pools)\n\nprint_cdf(min_pools)","078391dd":"# geo position vs block reception time (4)","1f04039e":"# Which geo-location receives blocks first","f8c08c3c":"# Gas used per transaction type","a8170e45":"# Impact of geo-distribution and mining pools on  Ethereum: dataset and metrics\n\nThe \"ethereum-network-measurement\" dataset contains a snapshot of the Ethereum network (April 1st 2019 - May 2nd 2019) captured by 4 geographically distant Ethereum instances.\n* 216,656,blocks (including forks) with the block numbers ranging from 7,479,573 to 7,680,658.\n* 21,960,051 unique transactions (out of which 20,654,578 (94%) were valid transactions included in main blocks).\n\nThe tools for extracting the full set of metrics can be found here:\nhttps:\/\/github.com\/vavricka\/Ethereum-monitoring-node\/tree\/master\/metrics\n\n* This notebook contains only a small selection of the tools and metrics from the github repository mentioned above.\n* Due to the Kaggle's RAM space restrictions the metrics are calculated only on a subset of transactions (~1\/4).\n","d0bb5ea9":"# Transaction commit time","297c0693":"# Consecutive blocks per mining pool","e6e25eb6":"# Transaction reordering","0632b230":"# Empty blocks per pool","6faea781":"# Impact of gas price type\nIn this metric, we analyze the correlation between the commit time and the gas\nprice of a transaction which is defined by the sender. It is expected that\nhigh gas price will lead to a higher probability of low commit time. This\nhappens because miners are incentivized to include those transactions to make\nmore profit. This metric is in order to observe whether it is possible to\nspeed up the commit time by offering a higher gas price.\n\n"}}