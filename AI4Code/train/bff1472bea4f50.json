{"cell_type":{"b48552d5":"code","53c2bc31":"code","35ef45aa":"code","d92dc4f9":"code","fcb2570d":"code","562d1ceb":"code","90cc6467":"code","5776e42d":"code","7527339c":"code","32fdbe57":"code","e26d0013":"code","899347e0":"code","af19fb49":"code","ff447fb5":"code","7f1688d0":"code","0c7be8bd":"code","10df5186":"code","07e6a5b2":"code","35d4dba7":"code","8b7482ec":"code","799b3968":"code","bc1327f5":"code","ba8c26b5":"code","65373e90":"code","c92206e9":"code","fc067ae5":"code","edd0b827":"markdown"},"source":{"b48552d5":"!nvidia-smi","53c2bc31":"from torchvision import transforms\nfrom torch.utils.data import Dataset\nfrom torchvision.datasets import ImageFolder\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision\nimport math\nimport torch.nn as nn\nfrom torch import optim\nimport os \nfrom torch.autograd import Variable\nimport time\nimport random","35ef45aa":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.enable = True\nseed_everything(230)","d92dc4f9":"split_ratito = [0.8, 0.1, 0.1]\nBATCH_SIZE = 32","fcb2570d":"class VGG(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.layer1 = nn.Sequential(nn.Conv2d(3, 64,kernel_size =(3,3), stride=1, padding=1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(64),\n                                    nn.Conv2d(64, 64, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(64),\n                                    nn.MaxPool2d((2,2),2))\n        self.layer2 = nn.Sequential(nn.Conv2d(64, 128, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(128),\n                                    nn.Conv2d(128, 128, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(128),\n                                    nn.MaxPool2d((2,2),2))\n        self.layer3 = nn.Sequential(nn.Conv2d(128, 256, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(256),\n                                    nn.Conv2d(256, 256, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(256),\n                                    nn.Conv2d(256, 256, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(256),\n                                    nn.MaxPool2d((2,2),2))\n        self.layer4 = nn.Sequential(nn.Conv2d(256, 512, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(512),\n                                    nn.Conv2d(512, 512, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(512),\n                                    nn.Conv2d(512, 512, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(512),\n                                    nn.MaxPool2d((2,2),2))\n        self.layer5 = nn.Sequential(nn.Conv2d(512, 512, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(512),\n                                    nn.Conv2d(512, 512, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(512),\n                                    nn.Conv2d(512, 512, (3,3), 1, 1),\n                                    nn.ReLU(),\n                                    nn.BatchNorm2d(512),\n                                    nn.MaxPool2d((2,2),2))\n        self.clasifier = nn.Linear(512, output_dim)\n    \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.layer5(out)\n        out = torch.mean(out,[2,3])\n        # print(out.shape)\n        return self.clasifier(out)","562d1ceb":"class ResidualModule(nn.Module):\n    def __init__(self, c_in, c_out):\n        super().__init__()\n        if c_in != c_out:\n            # the first layermust be downsampled\n            self.conv1 = nn.Sequential(nn.Conv2d(c_in, c_out, (3, 3), stride=2, padding=1),\n                                       nn.BatchNorm2d(c_out),\n                                       nn.ReLU())\n            self.projection = nn.Sequential(nn.Conv2d(c_in, c_out, (1, 1), stride=2),\n                                           nn.BatchNorm2d(c_out))\n        else:\n            self.conv1 = nn.Sequential(nn.Conv2d(c_in, c_out, (3, 3), stride=1, padding=1),\n                                       nn.BatchNorm2d(c_out),\n                                       nn.ReLU())\n            self.projection = None\n        self.conv2 = nn.Sequential(nn.Conv2d(c_out, c_out, (3, 3), stride=1, padding=1),\n                                   nn.BatchNorm2d(c_out),\n                                   nn.ReLU())\n        self.relu = nn.ReLU()\n    def _shortcut(self, x, z):\n        if self.projection:\n            x = self.projection(x)\n        return x + z\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.conv2(out)\n        out = self._shortcut(x, out)\n        return self.relu(out)","90cc6467":"\nclass ResNet18(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, (7, 7), stride=2, padding=3),\n                                   nn.BatchNorm2d(64),\n                                   nn.ReLU())\n        self.conv2 = nn.Sequential(nn.MaxPool2d((3,3), stride=2, padding=1),\n                                   ResidualModule(64, 64), ResidualModule(64,64))\n        self.conv3 = nn.Sequential(ResidualModule(64, 128), \n                                   ResidualModule(128, 128))\n        self.conv4 = nn.Sequential(ResidualModule(128, 256),\n                                   ResidualModule(256, 256))\n        self.conv5 = nn.Sequential(ResidualModule(256, 512),\n                                   ResidualModule(512, 512))\n        self.clasifier = nn.Linear(512, output_dim)\n    \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.conv2(out)\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.conv5(out)\n        # average pooling\n        out = torch.mean(out,[2,3])\n        # print(out.shape)\n        return self.clasifier(out)","5776e42d":"class BottleneckResidualModule(nn.Module):\n    def __init__(self, c_in, c_out):\n        super().__init__()\n        intermediate_dim = int(c_out \/ 4)\n        if c_in != c_out and c_in != intermediate_dim:\n            self.conv1 = nn.Sequential(nn.Conv2d(c_in, intermediate_dim, (1, 1), stride=2),\n                                       nn.BatchNorm2d(intermediate_dim),\n                                       nn.ReLU())\n        else:\n            self.conv1 = nn.Sequential(nn.Conv2d(c_in, intermediate_dim, (1,1), stride=1),\n                                       nn.BatchNorm2d(intermediate_dim),\n                                       nn.ReLU())\n        self.conv2 = nn.Sequential(nn.Conv2d(intermediate_dim, intermediate_dim, (3, 3), stride=1, padding=1),\n                                   nn.BatchNorm2d(intermediate_dim),\n                                   nn.ReLU())\n        self.conv3 = nn.Sequential(nn.Conv2d(intermediate_dim, c_out, (1, 1), stride=1),\n                                   nn.BatchNorm2d(c_out))\n        if c_in != c_out:\n            if c_in != intermediate_dim:\n                self.projection = nn.Sequential(nn.Conv2d(c_in, c_out, (1, 1), stride=2),\n                                           nn.BatchNorm2d(c_out))\n            else:\n                self.projection = nn.Sequential(nn.Conv2d(c_in, c_out, (1, 1), stride=1),\n                                           nn.BatchNorm2d(c_out))\n        else:\n            self.projection = None\n        self.relu = nn.ReLU()\n        \n    def _shortcut(self, x, z):\n        if self.projection:\n            x = self.projection(x)\n        return x + z\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.conv2(out)\n        out = self.conv3(out)\n        out = self._shortcut(x, out)\n        return self.relu(out)","7527339c":"\nclass ResNet50(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.conv1 = nn.Sequential(nn.Conv2d(3, 64, (7, 7), stride=2, padding=3),\n                                   nn.BatchNorm2d(64),\n                                   nn.ReLU())\n        self.conv2 = nn.Sequential(nn.MaxPool2d((3,3), stride=2, padding=1),\n                                   BottleneckResidualModule(64, 256),\n                                   BottleneckResidualModule(256,256),\n                                   BottleneckResidualModule(256,256))\n        self.conv3 = nn.Sequential(BottleneckResidualModule(256, 512), \n                                   BottleneckResidualModule(512, 512),\n                                   BottleneckResidualModule(512, 512),\n                                   BottleneckResidualModule(512, 512))\n        self.conv4 = nn.Sequential(BottleneckResidualModule(512, 1024),\n                                   BottleneckResidualModule(1024, 1024),\n                                   BottleneckResidualModule(1024, 1024),\n                                   BottleneckResidualModule(1024, 1024),\n                                   BottleneckResidualModule(1024, 1024),\n                                   BottleneckResidualModule(1024, 1024))\n        self.conv5 = nn.Sequential(BottleneckResidualModule(1024, 2048),\n                                   BottleneckResidualModule(2048, 2048),\n                                   BottleneckResidualModule(2048, 2048))\n        self.clasifier = nn.Linear(2048, output_dim)\n    \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.conv2(out)\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.conv5(out)\n        # average pooling\n        out = torch.mean(out,[2,3])\n        # print(out.shape)\n        return self.clasifier(out)","32fdbe57":"class CenterLoss(nn.Module):\n    \"\"\"Center loss.\n    \n    Reference:\n    Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n    \n    Args:\n        num_classes (int): number of classes.\n        feat_dim (int): feature dimension.\n    \"\"\"\n    def __init__(self, num_classes=10, feat_dim=2, use_gpu=True):\n        super(CenterLoss, self).__init__()\n        self.num_classes = num_classes\n        self.feat_dim = feat_dim\n        self.use_gpu = use_gpu\n\n        if self.use_gpu:\n            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n        else:\n            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n\n    def forward(self, x, labels):\n        \"\"\"\n        Args:\n            x: feature matrix with shape (batch_size, feat_dim).\n            labels: ground truth labels with shape (batch_size).\n        \"\"\"\n        batch_size = x.size(0)\n        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n        distmat.addmm_(1, -2, x, self.centers.t())\n\n        classes = torch.arange(self.num_classes).long()\n        if self.use_gpu: classes = classes.cuda()\n        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n\n        dist = distmat * mask.float()\n        loss = dist.clamp(min=1e-12, max=1e+12).sum() \/ batch_size\n\n        return loss","e26d0013":"def test_model():\n    tmp = ResNet50((224, 224), 10)\n    out_test = tmp(torch.rand((10, 3, 224, 224)))\n    print(tmp)\n    print(out_test.shape)\n# test_model()","899347e0":"def train(model, optimizer, data):\n    t0 = time.time()\n    model.train()\n    acc = 0\n    total_sample = 0\n    for X, y in data:\n        if(torch.cuda.is_available()):\n            X, y = X.cuda(non_blocking=True), y.cuda(non_blocking=True)\n        X, y = Variable(X), Variable(y)\n        y_hat = model(X)\n        loss = ce_loss(y_hat, y)\n        acc += accuracy(y_hat, y)\n        total_sample += len(y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    acc = acc \/ total_sample * 100\n    print(\"Train\\tTime: {:.2f}| Loss: {:.2f}| Accuracy: {:.2f}\".format(time.time() - t0, loss, acc))\n    # logging.info(\"Loss: {:.2f}\".format(loss))\n    return loss.item(), acc","af19fb49":"def evaluate(model, loss_fcn, data):\n    t0 = time.time()\n    model.eval()\n    acc = 0\n    total_sample = 0\n    for X, y in data:\n        if(torch.cuda.is_available()):\n            X, y = X.cuda(non_blocking=True), y.cuda(non_blocking=True)\n        X, y = Variable(X), Variable(y)\n        y_hat = model(X)\n        loss = loss_fcn(y_hat, y).item()\n        acc += accuracy(y_hat, y)\n        total_sample += len(y)\n    acc = acc \/ total_sample * 100\n    print(\"Eval\\t\\t\\tTime: {:.2f}| Loss: {:.2f}|Accuracy: {:.2f}\".format(time.time() - t0, loss, acc))\n    return loss, acc","ff447fb5":"def train_and_eval(model, loss_fn, train_dataloader, val_dataloader, optimizer, scheduler, total_epoch, save_path):\n    best_acc = 0\n    train_losses = []\n    train_accs = []\n    val_losses = []\n    val_accs = []\n    for i in range(total_epoch):\n        print(\"Epoch {}:\".format(i))\n        train_loss, train_acc = train(model, optimizer, train_dataloader)\n        val_loss, val_acc = evaluate(model, loss_fn, val_dataloader)\n        scheduler.step(val_acc)\n        train_losses.append(train_loss)\n        train_accs.append(train_acc)\n        val_losses.append(val_loss)\n        val_accs.append(val_acc)\n        if val_acc > best_acc:\n            torch.save(model.state_dict(), save_path + \"best.pth\")\n            best_acc = val_acc\n    return train_losses, train_accs, val_losses, val_accs","7f1688d0":"def accuracy(outputs, targets):\n    outputs = torch.argmax(outputs, dim = 1).cpu()\n    # print(outputs)\n    targets = targets.cpu()\n    return len (outputs[outputs == targets])","0c7be8bd":"def compute_mean_std_batch_norm(dl):\n    nb_sample = len(dl)\n    mean = 0\n    std = 0\n    for X, y in dl:\n        mean += X.mean(dim=[0,2,3])\n        std += X.std(dim=[0,2,3])\n    return mean \/ nb_sample, std \/ nb_sample\n","10df5186":"class CustomDataset(Dataset):\n    def __init__(self, dataset, transform = None):\n        self.dataset = dataset\n        self.transform = transform\n    def __getitem__(self, index):\n        if self.transform:\n            x = self.transform(self.dataset[index][0])\n        else:\n            x = self.dataset[index][0]\n        return x, self.dataset[index][1]\n    def __len__(self):\n        return len(self.dataset)","07e6a5b2":"def confusion_matrix(y_true, y_pred):\n    num_classes = 5\n    y_true = torch.argmax(y_true, dim = 1)\n    y_true = y_true.cpu()\n    y_pred = y_pred.cpu()\n    classes = torch.ones_like(y_true)\n    cf_mx = torch.sparse.LongTensor(torch.stack([y_true, y_pred]), classes, torch.Size([num_classes, num_classes])).to_dense()\n    return cf_mx","35d4dba7":"data_dir = \"\/kaggle\/input\/flowers-recognition\/flowers\/flowers\"\ntransform_train = transforms.Compose([transforms.RandomResizedCrop((224, 224)), transforms.RandomHorizontalFlip(), transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntransform_val = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ndatasets = ImageFolder(root = data_dir)","8b7482ec":"dataloaders = {}\nsplit_len = [int(ratito * len(datasets)) for ratito in split_ratito]\nsplit_len[-1] = len(datasets) - split_len[0] - split_len[1]\ntrain_ds, val_ds, test_ds = torch.utils.data.random_split(datasets, split_len)\ntrain_ds = CustomDataset(train_ds, transform_train)\nval_ds = CustomDataset(val_ds, transform_val)\ntest_ds = CustomDataset(test_ds, transform_val)\ndataloaders['train'] = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=BATCH_SIZE, num_workers=2)\ndataloaders['val'] = torch.utils.data.DataLoader(val_ds, shuffle=True, batch_size=BATCH_SIZE, num_workers=2)\ndataloaders['test'] = torch.utils.data.DataLoader(test_ds, shuffle=True, batch_size=BATCH_SIZE, num_workers=2)","799b3968":"model = VGG((224, 224), 5)\nce_loss = torch.nn.CrossEntropyLoss()\ncenter_loss = CenterLoss(num_classes=5, feat_dim=512, use_gpu=True)\nparams = model.parameters()\noptimizer = optim.Adam(params, lr=1e-4, eps=1e-4, amsgrad=True)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max')\nif(torch.cuda.is_available()):\n        model = model.cuda()","bc1327f5":"train_losses, train_accs, val_losses, val_accs = train_and_eval(model, ce_loss, dataloaders['train'], dataloaders['val'], optimizer, scheduler, 150, \"\")","ba8c26b5":"import matplotlib.pyplot as plt\n# plt.plot(range(len(train_losses)), train_losses, label = \"train loss\")\n# plt.plot(range(len(val_losses)), val_losses, label = \"val loss\")\n# plt.legend()\n# plt.show()","65373e90":"plt.plot(range(len(train_accs)), train_accs, label = \"train accuracy\")\nplt.plot(range(len(val_accs)), val_accs, label = \"val accuracy\")\nplt.legend()\nplt.show()","c92206e9":"print(\"Best accuracy:\\nTrain:\", max(train_accs),\"\\tValidation:\", max(val_accs))","fc067ae5":"model.load_state_dict(torch.load(\".\/best.pth\"))\nevaluate(model, ce_loss, dataloaders['test'])","edd0b827":"**Version 3.2: Try changing model architexture**\n\n- v1: Implement with VGG\n- v2:\n    - Add batch norm at each convolution layer\n    - Add input normalization: *not change accuracy but make model have high score at first (not sure if it good or not)*\n    - Add data argumentation only on training set\n- v3: \n    - Replace FC layer by global average pooling\n    - Use center loss: *seem like model convergence a little bit faster*\n    - Add missing VGG16 layer\n    - Use scheduler"}}