{"cell_type":{"bc055749":"code","1aedfdaf":"code","7224be1a":"markdown","98745fd5":"markdown","f45945c9":"markdown"},"source":{"bc055749":"import pandas as pd\n\ndef null_dict(df): return(dict(zip(df.columns, [l for l in df.isnull().sum()])));\niowa_path = '..\/input\/house-prices-advanced-regression-techniques\/test.csv'\nmelb_path = '..\/input\/melbourne-housing-snapshot\/melb_data.csv'\norig_data = pd.read_csv(iowa_path)\norig_missing_cols = [l for l in orig_data.columns if orig_data[l].isnull().any()]\n\nprint(\"1) Amount of nulls per column [ orig_data ] \\n%s\\n\"\n    % (null_dict(orig_data)))\n\ndata_drop_na = orig_data.dropna(axis=1)\nprint(\"2) Amount of nulls per column after .dropna [ data_drop_na ] \\n%s\\n\"\n     % (null_dict(data_drop_na)))\n            \ndata_drop_lc = orig_data.drop(orig_missing_cols, axis=1)\nprint(\"3) Amount of nulls per column after safe drop [ column_dropped_data ] \\n%s\"\n     % (null_dict(data_drop_lc)))","1aedfdaf":"from sklearn.impute import SimpleImputer\n\n# new up, so as not to impact original data\nnew_data = orig_data.copy()\ncols_with_missing = (col for col in new_data.columns\n                               if new_data[col].isnull().any())\n\nna_cols = (col for col in new_data.columns\n                               if new_data[col].isna().any())\n\n[print(i) for i in cols_with_missing]\n    \nmy_imputer = SimpleImputer()\nimputed_data = my_imputer.fit_transform(orig_data)\nnew_data = pd.DataFrame(imputed_data)\nnew_data.columns = original_data.columns\n\n","7224be1a":"To keep the munging process transparent and repeatable, it is best to declare, or use consistent means to obtain, the column(s) requiring removal from your dataset.\nExamples **2** and **3** from above achieve the same result, but the way example **3** had it's columns dropped can be repeated on another dataset _(think train\/test split)_, which is a safe way of avoiding the assumptions, and consequent errors that come as a result of blindly applying `df.dropna()`. \n\n## 2) Imputation -  Filling Missing Values\nTo _impute_ is to:\n> Assign [a value] to something by inference from the value of the products or processes to which it contributes.\n\nImputation is the process of filling missing values. These imputed values won't be absolutely correct, but will often lead to more accurate results from your model (as is better covered in [this article](http:\/\/www.stat.columbia.edu\/~gelman\/arm\/missing.pdf) from \"Data Analysis Using Regression and Multilevel\/Hierarchical Models\" By Andrew Gelman.\n \n Scikit-learn offers a few handy utilities for imputing missing values; `SimpleImputer()` will be explored below to illustrate the process.","98745fd5":"Imputation can be included in scikit-learn pipelines, ","f45945c9":"# Hello MLWorld; Part 2, an extended Introduction to Machine Learning.\n**A workspace for the [Machine Learning course](https:\/\/www.kaggle.com\/learn\/machine-learning) (Level 2).**\n\n# Missing Values.\nYour data can contain missing values for a whole host of reasons - provided you've passed the first step, acceptance, here are three approaches to dealing with missing values, and a comparison.\n\n\n## 1) Drop Columns with Missing Values.\nLet's explore [Listwise Deletion](https:\/\/www.theanalysisfactor.com\/when-listwise-deletion-works\/).  \n_A method_ for dealing with nulls - but a very blunt one, use with caution.  \nMismatches between test & training data can occur, and your model will lose access to all of the data from dropped columns.\nHowever, if your column is mostly nulls, it may a viable solution.     \nThink about what might be a nail when using this hammer."}}