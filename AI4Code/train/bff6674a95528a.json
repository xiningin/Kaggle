{"cell_type":{"93710832":"code","327db322":"code","bedcc6c3":"code","b5d80d11":"code","2b87a86c":"code","2a851154":"code","5775324a":"code","07da2226":"code","d2f67a9d":"code","e9309d65":"code","5063c34d":"code","b670b77a":"code","0b9e56b3":"code","ad497ce1":"code","42e37ba4":"code","cd6a44c5":"code","76c2abb1":"code","742bf1a1":"code","0937fd81":"code","e06d306f":"code","8af86a53":"code","e1cc7a93":"code","aede95e6":"code","375be931":"code","29affec0":"code","6aea0334":"code","06616a41":"code","f614f938":"code","164941b9":"code","4bc34789":"code","b7fae615":"code","47c3da3e":"code","60542230":"code","ae1a879f":"code","f6e1608e":"code","20db02bc":"code","071e5552":"code","70e2d2cd":"code","57cbec97":"code","988ea7c8":"code","9bbdad02":"code","fd5fb44e":"code","50a561b2":"code","bf767dde":"code","cce2e588":"code","53e7f9e1":"code","36f3a530":"markdown","7d96770f":"markdown","d236518a":"markdown","4d8741ab":"markdown","517e1998":"markdown","aed5fbc6":"markdown","51ff80b4":"markdown"},"source":{"93710832":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\nimport lightgbm as lgb\nimport os\nfrom sklearn.model_selection import KFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sbn\nfrom  datetime import datetime, timedelta\nfrom sklearn import datasets, linear_model\nimport random\nimport matplotlib.pyplot as plt","327db322":"pd.options.mode.chained_assignment = None","bedcc6c3":"path = Path('\/kaggle\/input\/osic-pulmonary-fibrosis-progression')\nassert path.exists()","b5d80d11":"model_path = Path('\/kaggle\/working\/model')\nif os.path.isdir(model_path) == False:\n    os.makedirs(model_path)\nassert model_path.exists()","2b87a86c":"TRAIN_TYPES={\"Patient\": \"category\", \n         \"Weeks\": \"int16\", \"FVC\": \"int32\", 'Percent': 'float32', \"Age\": \"uint8\",\n        \"Sex\": \"category\", \"SmokingStatus\": \"category\" }\nSUBMISSION_TYPES={\"Patient_Week\": \"category\", \"FVC\": \"int32\", \"Confidence\": \"int16\"}\n\ndef read_data(path):\n    train_df = pd.read_csv(path\/'train.csv', dtype = TRAIN_TYPES)\n    test_df = pd.read_csv(path\/'test.csv', dtype = TRAIN_TYPES)\n    submission_df = pd.read_csv(path\/'sample_submission.csv', dtype = SUBMISSION_TYPES)\n    train_df.drop_duplicates(keep='first', inplace=True, subset=['Patient','Weeks'])\n    return train_df, test_df, submission_df","2a851154":"train_df, test_df, submission_df = read_data(path)","5775324a":"def prepare_submission(df, test_df):\n    df['Patient'] = df['Patient_Week'].apply(lambda x:x.split('_')[0])\n    df['Weeks'] = df['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n    df = df[['Patient','Weeks','Confidence','Patient_Week']]\n    df = df.merge(test_df.drop('Weeks', axis=1).copy(), on=['Patient'])\n    return df","07da2226":"submission_df = prepare_submission(submission_df, test_df)","d2f67a9d":"submission_df[((submission_df['Patient'] == 'ID00419637202311204720264') & (submission_df['Weeks'] == 6))].head(5)","e9309d65":"def adapt_percent_in_submission():\n    previous_match = None\n    for i, r in submission_df.iterrows():\n        in_training = train_df[(train_df['Patient'] == r['Patient']) & (train_df['Weeks'] == r['Weeks'])]\n        if(len(in_training) > 0):\n            previous_match = in_training['Percent'].item()\n            submission_df.iloc[i, submission_df.columns.get_loc('Percent')] = previous_match\n        elif previous_match is not None:\n            submission_df.iloc[i, submission_df.columns.get_loc('Percent')] = previous_match","5063c34d":"adapt_percent_in_submission()","b670b77a":"train_df['WHERE'] = 'train'\ntest_df['WHERE'] = 'val'\nsubmission_df['WHERE'] = 'test'\ndata = train_df.append([test_df, submission_df])","0b9e56b3":"data['min_week'] = data['Weeks']\ndata.loc[data.WHERE=='test','min_week'] = np.nan\ndata['min_week'] = data.groupby('Patient')['min_week'].transform('min')","ad497ce1":"base = data.loc[data.Weeks == data.min_week]","42e37ba4":"sbn.countplot(base['Sex'])","cd6a44c5":"base = base[['Patient','FVC', 'Percent']].copy()\nbase.columns = ['Patient','min_FVC', 'min_Percent']\nbase['nb'] = 1\nbase['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\nbase = base[base.nb==1]\nbase","76c2abb1":"data = data.merge(base, on='Patient', how='left')","742bf1a1":"data['base_week'] = data['Weeks'] - data['min_week']\ndata['base_week'] = data['base_week']\ndel base","0937fd81":"data[data['Patient'] == 'ID00421637202311550012437']","e06d306f":"COLS = ['Sex','SmokingStatus']\nFE = []\nfor col in COLS:\n    for mod in data[col].unique():\n        FE.append(mod)\n        data[mod] = (data[col] == mod).astype(int)","8af86a53":"data = data.rename(columns={\"Age\": \"age\", \"min_FVC\": \"BASE\", \"base_week\": \"week\", \"Percent\": \"percent\"})\nFE += ['age','week','BASE', 'percent']\nFE","e1cc7a93":"train_df = data.loc[data.WHERE=='train']\ntest_df = data.loc[data.WHERE=='val']\nsubmission_df = data.loc[data.WHERE=='test']\ndel data","aede95e6":"train_df.sort_values(['Patient', 'Weeks'], inplace=True)","375be931":"X = train_df[FE]\nX.head(15)","29affec0":"y = train_df['FVC']\ny","6aea0334":"def seed_everything(seed=2020):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)","06616a41":"seed_everything(42)","f614f938":"C1_val = 70\nC2_val = 1000\nC1, C2 = C1_val, C2_val\nq = np.array([0.2, 0.50, 0.8])\n\ndef score(y_true, y_pred):\n    sigma = y_pred[:, 2] - y_pred[:, 0]\n    fvc_pred = y_pred[:, 1]\n    #sigma_clip = sigma + C1\n    sigma_clip = np.max(sigma)\n    delta = np.abs(y_true[:, 0] - fvc_pred)\n    delta = np.min(delta)\n    sq2 = np.sqrt(2.)\n    metric = (delta \/ sigma_clip)*sq2 + np.log(sigma_clip* sq2)\n    return np.mean(metric)\n\ndef qloss(y_true, y_pred):\n    print('y_true.shape', y_true.shape)\n    print('y_pred.shape', y_pred.shape)\n    # Pinball loss for multiple quantiles\n    # \u03c4 relu(y-\u0177) + (1-\u03c4) relu(\u0177-y)\n    # q * relu(y_true-y_pred) + (1-q) * relu(y_pred-y_true)\n    # alt_loss = (q * F.relu(y_true-y_pred) + (1-q) * F.relu(y_pred-y_true))\n    e = y_true - y_pred\n    v = np.max(q*e, (q-1)*e)\n    return np.mean(v)\n\ndef mloss(_lambda):\n    def loss(y_true, y_pred):\n        y_true = y_true.reshape(-1, 1)\n        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n    return loss","164941b9":"\nn_estimators = 30000\n    \nif not 'sub_row' in locals():\n    sub_row = 0.75\n    \nif not 'bagging_freq' in locals():\n    bagging_freq = 1\n    \nif not 'learning_rate' in locals():\n    learning_rate = 0.4\n\nleave_size = 4\n\nlgb_params = {\n    \"objective\": 'quantile',\n    'n_jobs': 1,\n    'max_depth': leave_size + 1,\n    'num_leaves': 2**leave_size-1,\n    \"min_data_in_leaf\": 2**(leave_size + 1)-1,\n#     'subsample': 0.9,\n    \"n_estimators\": n_estimators,\n    'learning_rate': 8e-3,\n    'colsample_bytree': 0.9,\n    'boosting_type': 'gbdt',\n    \"early_stopping_rounds\": 100,\n    'verbosity': 1000,\n    \"metric\": [\"rmse\", \"mse\"]\n}","4bc34789":"cat_feats = ['Male', 'Female', 'Ex-smoker', 'Never smoked', 'Currently smokes']","b7fae615":"NFOLD = 5\nkf = KFold(n_splits=NFOLD, shuffle=False)\npred = {a: np.zeros((train_df.shape[0])) for a in q.tolist()}","47c3da3e":"ensemble_weights = [2.\/3, 1.\/3]\nassert np.sum(ensemble_weights) == 1.0","60542230":"models = []\nlinear_models = []\nfor cnt, (tr_idx, val_idx) in tqdm(enumerate(kf.split(X)), total=NFOLD):\n    X_train, y_train = X.loc[tr_idx], y.loc[tr_idx]\n    X_valid, y_valid = X.loc[val_idx], y.loc[val_idx]\n    print(f\"FOLD {cnt}\", X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)\n    lin_model = linear_model.Ridge(alpha=1.0)\n    lin_model.fit(X=X_train, y=y_train)\n    linear_models.append(lin_model)\n    for qi, quantile_alpha in enumerate(q.tolist()):\n        lgb_params['alpha'] = quantile_alpha\n        m_lgb_regressor = lgb.LGBMRegressor(**lgb_params)\n        m_lgb_regressor.fit(X=X_train, y=y_train, \n                  eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                  eval_names=['train mloss', 'valid mloss'], \n                  eval_metric=lgb_params['metric'],\n                  verbose=lgb_params['verbosity'],\n                  early_stopping_rounds=lgb_params[\"early_stopping_rounds\"],\n                  categorical_feature=cat_feats)\n        lin_predict = lin_model.predict(X_valid)\n        lgb_predict = m_lgb_regressor.predict(X_valid)\n        pred[quantile_alpha][val_idx] = np.average([lin_predict, lgb_predict], axis = 0, weights=ensemble_weights)\n        models.append(m_lgb_regressor)","ae1a879f":"full_preds = np.vstack([pred[a] for a in q]).T\nscore(np.array(y).reshape(-1, 1), full_preds)","f6e1608e":"pred = []\nfor i in range(NFOLD):\n    cur_pred = []\n    for j, _ in enumerate(q):\n        model_idx = i * 3 + j\n        model = models[model_idx]\n        lin_predict = linear_models[i].predict(submission_df[FE])\n        dbmc_predict = model.predict(submission_df[FE])\n        cur_pred.append(np.average([lin_predict, dbmc_predict], axis = 0, weights=ensemble_weights))\n    pred.append(np.array(cur_pred).T)","20db02bc":"preds_array = np.array(pred)\npreds_array.shape","071e5552":"final_preds = np.mean(preds_array, axis=0)\nfinal_preds.shape","70e2d2cd":"submission_df['FVC1'] = final_preds[:,1]\nsubmission_df['Confidence1'] = final_preds[:, 2] - final_preds[:, 0]","57cbec97":"submission_df.loc[~submission_df.FVC1.isnull(),'FVC'] = submission_df.loc[~submission_df.FVC1.isnull(),'FVC1']\nsubmission_df.loc[~submission_df.FVC1.isnull(),'Confidence'] = submission_df.loc[~submission_df.FVC1.isnull(),'Confidence1']","988ea7c8":"submission_df['Confidence'] = np.clip(submission_df['Confidence'], a_min=200, a_max=1000)\nsubmission_df['Confidence'].describe()","9bbdad02":"submission_df[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)","fd5fb44e":"submission_final_df = pd.read_csv(\"submission.csv\")","50a561b2":"submission_final_df","bf767dde":"submission_final_df.describe().T","cce2e588":"for p in test_df['Patient'].unique():\n    submission_final_df[submission_final_df['Patient_Week'].str.find(p) == 0]['FVC'].plot()","53e7f9e1":"for p in test_df['Patient'].unique():\n    fig, ax = plt.subplots()\n    submission_final_df[submission_final_df['Patient_Week'].str.find(p) == 0]['FVC'].plot(ax=ax)","36f3a530":"### Path","7d96770f":"#### Feature generation","d236518a":"### LightGBM Training","4d8741ab":"#### Seed","517e1998":"### Checks","aed5fbc6":"### Predict","51ff80b4":"### Read Data"}}