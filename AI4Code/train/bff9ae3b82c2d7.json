{"cell_type":{"d3ddd59c":"code","2650c6a3":"code","a5fd796f":"code","be4c4ce3":"code","d53ceecb":"code","375613fb":"code","7485d617":"code","a0272f63":"code","ae640b16":"code","221f28c0":"code","01be393a":"code","6888981f":"code","45ec3f95":"code","0a8f062d":"code","dc45be92":"code","3f0c32fd":"code","e467ea50":"code","cd45ebfd":"code","4c8d07e3":"markdown","3d6a4cbe":"markdown","73becadb":"markdown","fed34333":"markdown","a6ae2f89":"markdown","31c2e790":"markdown","6297c2bd":"markdown","04876b35":"markdown","f5d4f39e":"markdown","81cece83":"markdown","76860968":"markdown","69183948":"markdown","d4e1046c":"markdown","e5e3b942":"markdown","a365523a":"markdown","7b57864e":"markdown","50eaae9a":"markdown","16e75256":"markdown","81d774b2":"markdown"},"source":{"d3ddd59c":"import os\nfor dirname,_,_ in os.walk('\/kaggle\/input'):\n    print(dirname)","2650c6a3":"# Libraries\nfrom zipfile import ZipFile\nimport shutil, os\nimport re\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport tensorflow_hub as hub\nfrom tensorflow.keras.layers import Dense,Activation,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, TensorBoard,LearningRateScheduler\nimport tensorflow as tf\nimport datetime","a5fd796f":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 64 #16 * strategy.num_replicas_in_sync\nSHUFFLE_SIZE = 5000\nIMAGE_SIZE = [150, 150]\nEPOCHS = 30","be4c4ce3":"# Load the data\ntrain_filenames = tf.io.gfile.glob(str('\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/*\/*'))\nval_filenames = tf.io.gfile.glob(str('\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\/*\/*'))\n\nprint(len(train_filenames),len(val_filenames))","d53ceecb":"count_dict = {'NB_SEA': 0, 'NB_FOREST': 0, 'NB_MOUNTAIN': 0, 'NB_GLACIER': 0, 'NB_BUILDINGS': 0, 'NB_STREET': 0}\nfor elt in os.listdir('\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test'):\n    for key in count_dict.keys():\n        if elt.upper() in key:\n            count_dict[key] = len([name for name in train_filenames if elt in name])\n            \ncount_dict","375613fb":"# Creating datasets\ntrain_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\nval_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\n\nfor f in train_list_ds.take(5):\n    print(f.numpy())","7485d617":"# Training images count\nTRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\nprint(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n\n# Validation images count\nVAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\nprint(\"Validating images count: \" + str(VAL_IMG_COUNT))","a0272f63":"# Class names\nCLASS_NAMES = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n                        for item in tf.io.gfile.glob(str('\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/*')) if '__' not in item])\nCLASS_NAMES","ae640b16":"def get_label(file_path):\n    \n    # convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    # The second to last is the class-directory\n    return parts[-2] == CLASS_NAMES\n\ndef image_processing(file_path):\n    \n    label = get_label(file_path)\n    # load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    # convert the compressed string to a 3D uint8 tensor\n    img = tf.image.decode_jpeg(img, channels=3)\n    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    # resize the image to the desired size\n    img = tf.image.resize(img, IMAGE_SIZE)\n    \n    return img, label","221f28c0":"# Mapped trainset\ntrain_ds = train_list_ds.map(image_processing, num_parallel_calls=AUTOTUNE)\n\n# Mapped Validationset\nval_ds = val_list_ds.map(image_processing, num_parallel_calls=AUTOTUNE)\n\n# Shape and label for one image\nfor image, label in train_ds.take(1):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())","01be393a":"# Load and format testset\ntest_filenames = tf.io.gfile.glob(str('\/kaggle\/input\/intel-image-classification\/seg_pred\/seg_pred\/*'))\ntest_list_ds = tf.data.Dataset.from_tensor_slices(test_filenames)\nTEST_IMAGE_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\ntest_ds = test_list_ds.map(image_processing, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.batch(BATCH_SIZE)\n\nprint(\"Testing images count: \" + str(TEST_IMAGE_COUNT))","6888981f":"# This is a small dataset, only load it once, and keep it in memory.\n# Shuffle it and repeat forever\n# Batch the dataset\n# `prefetch` lets the dataset fetch batches in the background while the model is training.\ntrain_ds = train_ds.cache().shuffle(SHUFFLE_SIZE).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\nval_ds = val_ds.cache().shuffle(SHUFFLE_SIZE).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\nimage_batch, label_batch = next(iter(train_ds))","45ec3f95":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(16):\n        ax = plt.subplot(4,4,n+1)\n        plt.imshow(image_batch[n])\n        plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n        plt.axis(\"off\")\n\n# Visualize the first batch\nshow_batch(image_batch.numpy(), label_batch.numpy())","0a8f062d":"weight_for_0 = (1 \/ count_dict[\"NB_SEA\"])*(TRAIN_IMG_COUNT)\/6.0 \nweight_for_1 = (1 \/ count_dict[\"NB_FOREST\"])*(TRAIN_IMG_COUNT)\/6.0\nweight_for_2 = (1 \/ count_dict[\"NB_MOUNTAIN\"])*(TRAIN_IMG_COUNT)\/6.0 \nweight_for_3 = (1 \/ count_dict[\"NB_GLACIER\"])*(TRAIN_IMG_COUNT)\/6.0\nweight_for_4 = (1 \/ count_dict[\"NB_BUILDINGS\"])*(TRAIN_IMG_COUNT)\/6.0 \nweight_for_5 = (1 \/ count_dict[\"NB_STREET\"])*(TRAIN_IMG_COUNT)\/6.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2, 3: weight_for_3, 4: weight_for_4, 5: weight_for_5}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))\nprint('Weight for class 2: {:.2f}'.format(weight_for_2))\nprint('Weight for class 3: {:.2f}'.format(weight_for_3))\nprint('Weight for class 4: {:.2f}'.format(weight_for_4))\nprint('Weight for class 5: {:.2f}'.format(weight_for_5))","dc45be92":"# Modeling\n\"\"\"MODULE_HANDLE = \"https:\/\/tfhub.dev\/google\/imagenet\/resnet_v2_101\/feature_vector\/4\"\nfeature_extractor = hub.KerasLayer(MODULE_HANDLE, input_shape= (150,150) + (3,), output_shape=[1536], trainable=False)\"\"\"\nMODULE_HANDLE = \"https:\/\/tfhub.dev\/google\/imagenet\/inception_v3\/feature_vector\/4\"\nfeature_extractor = hub.KerasLayer(MODULE_HANDLE, input_shape= (150,150) + (3,), output_shape=[2048], trainable=False) # 2048\nmodel = Sequential([feature_extractor, Dense(6,activation='softmax')])\n\n# Learning rate decay \/ scheduling\nadam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\nrmsprop = RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False, name=\"RMSprop\")\n\n# Metrics\nMETRICS = ['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n\n# Model Compile\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=METRICS)\n\n# Callbacks functions\nlogdir = \"logs\/fit\/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nrLRop = ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.8, patience=3, verbose=1, mode=\"auto\", min_lr=0.000001)\ntensorboard = TensorBoard(log_dir=logdir, histogram_freq=1, write_graph=True, write_images=False, update_freq=\"batch\", profile_batch=0,\n                          embeddings_freq=0,embeddings_metadata=None)","3f0c32fd":"# Model fit function\nhistory = model.fit(\n    train_ds,\n    steps_per_epoch=TRAIN_IMG_COUNT \/\/ BATCH_SIZE,\n    epochs=EPOCHS,\n    validation_data=val_ds,\n    validation_steps=VAL_IMG_COUNT \/\/ BATCH_SIZE,\n    #class_weight=class_weight,\n    callbacks=[tensorboard,rLRop]\n)","e467ea50":"# Visualize model's performance\nfig, ax = plt.subplots(1, 4, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","cd45ebfd":"# Predictions\nloss, acc, prec, rec = model.evaluate(val_ds, steps=VAL_IMG_COUNT \/\/ BATCH_SIZE)","4c8d07e3":"## III. Libraries and variables\nRun the following cell to load the necessary packages. We are going to instantiate constant variables such as the **BATCH_SIZE**, **IMAGE_SIZE** and the number of **EPOCHS**.","3d6a4cbe":"As demonstrated previously, the dataset is just a list of filenames which we want to map to tuple (image, label). The following function will first overwrite the labels. Then, we will preprocess the images by converting its type, resizing it and may be trying some data augmentation techniques. The below functions were inspired by the loading images techniques provided by tensorflow on this <a href=\"https:\/\/www.tensorflow.org\/tutorials\/load_data\/images\">link<\/a>.","73becadb":"## V. Visualize the first batch\n\nThis function will show the first batch of images stored in the trainset.","fed34333":"## VIII. Visualizing model performance\nLet's plot the model accuracy and loss for the training and the validating set. These plots show the accuracy and loss values of training. ","a6ae2f89":"Let's apply the preprocessing functions written above.","31c2e790":"Notice that the dataset is balanced and we have almost 2000 image per class. However, we will correct for this slightly imbalance later on in our notebook.\n\nWe will create the datasets for our project by using tf.data.Dataset.","6297c2bd":"## VII. Train the model\nSince there are only two possible labels for the image, we will be using the categorical_crossentropy loss. When we fit the model, identify the class weights. Because we are using a TPU, training will be relatively quick.\n\nFor our metrics, we want to include precision and recall as they will provide use with a more informed picture of how good our model is. Accuracy tells us what fractions are the labels are correct. Since our data is not balanced, accuracy might give a skewed sense of a good model (i.e. a model that always predicts other will be 74% accurate but is not a good model).\n\nPrecision is the number of true positives (TP) over the sum of TP and false positives (FP). It shows what fraction of labeled positives are actually correct.\n\nRecall is the number of TP over the sum of TP and false negatves (FN). It shows what fraction of actual positives are correct.","04876b35":"## X. Evaluate results\nLet's evaluate the model on our test data!","f5d4f39e":"Load and apply the same preprocessing functions on the test set.","81cece83":"From exploring the data and the model, I noticed that the training for the model has a slow start. However, after EPOCHS epochs, the model slowly starts to converge.","76860968":"We see that the accuracy for our model is around 89% which is not bad for intel sophisticated images.","69183948":"The code in the following cell count the number of images we have in our training and validation dataset.","d4e1046c":"We saw earlier in this notebook that the data was imbalanced, with more images classified as other than normal. We will correct for that in this following section.","e5e3b942":"## II. Setting-Up Kaggle\nIf we work with kaggle, we need to use the lines of codes shown below and given by kaggle in order to locate the folder containing our data.","a365523a":"## IV. Load the data\n\nThe Ships data come with only one directory. You can find the datasets on this page by clicking on this <a href=\"https:\/\/www.kaggle.com\/puneet6060\/intel-image-classification\">link<\/a>.","7b57864e":"To get the numnber of classes in our datasets, please run the following cell.","50eaae9a":"The code below will load the datasets only once and keep it in memory because it is small. Then, we will shuffle it, repeat the process in order to keep give data to the model for training. We will also batch it and use prefetch to add batches to the background while the model is training.","16e75256":"The code below count the number of classes in the trainset","81d774b2":"## I. Introduction\nThis notebook will explain the complete pipeline from loading data to predicting results, and it will explain how to build an image classifier from intel from scratch to predict whether an image shows presence of ships."}}