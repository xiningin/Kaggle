{"cell_type":{"a19ecc8a":"code","021f25dc":"code","d6dea36e":"code","4d631092":"code","62ca43f8":"code","1de49c49":"code","78202181":"code","b0ca7f5b":"code","b2637259":"code","e684d8d8":"code","b75bc20b":"code","041799d9":"code","369525b7":"code","021e78a5":"code","d5c67110":"code","316911cc":"code","7b1ca7ef":"code","6e36678c":"code","b157343c":"code","db9602cd":"code","f148cc99":"code","29bdfac9":"code","aeb6550e":"code","1df7f587":"code","0c7777a6":"code","feb51e09":"code","a0e0931b":"code","0a4c00d2":"code","d89f26c2":"code","0795f14e":"code","adacc104":"code","c3a3faf9":"code","2eecc927":"code","51998ce1":"markdown","6d50019c":"markdown"},"source":{"a19ecc8a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly import tools\n#import plotly.plotly as py\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\ninit_notebook_mode(connected=True)","021f25dc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d6dea36e":"train = pd.read_csv('..\/input\/ashrae-energy-prediction\/train.csv')\nweather_train = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_train.csv')\ntest = pd.read_csv('..\/input\/ashrae-energy-prediction\/test.csv')\nweather_test = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_test.csv')\nbuilding_metadata = pd.read_csv('..\/input\/ashrae-energy-prediction\/building_metadata.csv')\n#sample_submission = pd.read_csv('sample_submission.csv')","4d631092":"building_metadata.head()","62ca43f8":"weather_train.head(3)","1de49c49":"## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","78202181":"##########Reducing memory########################\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\nweather_train = reduce_mem_usage(weather_train)\nweather_test = reduce_mem_usage(weather_test)\nbuilding_meta = reduce_mem_usage(building_metadata)\n","b0ca7f5b":"train.head(5)","b2637259":"train_df = train.merge(building_metadata, on='building_id', how='left')\ntrain = train_df.merge(weather_train, on=['site_id', 'timestamp'], how='left')\ntrain.head(5)\ntest_df = test.merge(building_metadata, on='building_id', how='left')\ntest = test_df.merge(weather_test, on=['site_id', 'timestamp'], how='left')\ntest.head(5)","e684d8d8":"train_df.head(3)","b75bc20b":"train.drop('timestamp',axis=1,inplace=True)\ntest.drop('timestamp',axis=1,inplace=True)","041799d9":"train.head()","369525b7":"columns = ['air_temperature','cloud_coverage','dew_temperature','precip_depth_1_hr','sea_level_pressure','wind_direction','wind_speed']\ntrain.loc[:, columns] = train.loc[:, columns].interpolate(method ='linear', limit_direction ='forward') \ntest.loc[:, columns] = test.loc[:, columns].interpolate(method ='linear', limit_direction ='forward') ","021e78a5":"train.head()","d5c67110":"from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nle = LabelEncoder()\n\ntrain['meter']= le.fit_transform(train['meter']).astype(\"uint8\")\ntest['meter']= le.fit_transform(test['meter']).astype(\"uint8\")\ntrain['primary_use']= le.fit_transform(train['primary_use']).astype(\"uint8\")\ntest['primary_use']= le.fit_transform(test['primary_use']).astype(\"uint8\")","316911cc":"threshold = 0.9","7b1ca7ef":"correlation = train.corr().abs()\ncorrelation.head()","6e36678c":"correlation.head()","b157343c":"test_1 = correlation.where(np.triu(np.ones(correlation.shape), k=1).astype(np.bool))\ntest_1.head()","db9602cd":"threshold=0.9","f148cc99":"to_drop = [column for column in test_1.columns if any(test_1[column] > threshold)]","29bdfac9":"train.head()","aeb6550e":"#train.drop(to_drop,axis=1,inplace=True)\ntest.drop(to_drop,axis=1,inplace=True)\ny = train['meter_reading']\ntrain.drop('meter_reading',axis=1,inplace=True)\ntrain.drop('site_id',axis=1,inplace=True)","1df7f587":"test.head()","0c7777a6":"! pip install lightgbm","feb51e09":"cat_cols = ['building_id', 'primary_use','year_built', 'meter',  'wind_direction']","a0e0931b":"from sklearn.model_selection import train_test_split,KFold\nimport lightgbm as lgb\nx_train,x_test,y_train,y_test = train_test_split(train,y,test_size=0.25,random_state=42)\nprint (x_train.shape)\nprint (y_train.shape)\nprint (x_test.shape)\nprint (y_test.shape)\n\nlgb_train = lgb.Dataset(x_train, y_train ,categorical_feature=cat_cols)\nlgb_test = lgb.Dataset(x_test, y_test ,categorical_feature=cat_cols)\ndel x_train, x_test , y_train, y_test\n\nparams = {'feature_fraction': 0.75,\n          'bagging_fraction': 0.75,\n          'objective': 'regression',\n          'max_depth': -1,\n          'learning_rate': 0.15,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'rmse',\n          \"verbosity\": -1,\n          'reg_alpha': 0.5,\n          'reg_lambda': 0.5,\n          'random_state': 47,\n          \"num_leaves\": 41}","0a4c00d2":"reg = lgb.train(params, lgb_train, num_boost_round=3000, valid_sets=[lgb_train, lgb_test], early_stopping_rounds=100, verbose_eval = 100)","d89f26c2":"test.drop('row_id',axis=1,inplace=True)","0795f14e":"#del lgb_train,lgb_test","adacc104":"Submission_file = pd.DataFrame(test.index,columns=['row_id'])","c3a3faf9":"Submission_file","2eecc927":"prediction = []\nstep = 100000\nfor i in range(0, len(test), step):\n    prediction.extend(np.expm1(reg.predict(test.iloc[i: min(i+step, len(test)), :], num_iteration=reg.best_iteration)))\nSubmission_file['meter_reading'] = prediction\nSubmission_file['meter_reading'].clip(lower=0,upper=None,inplace=True)\nSubmission_file.to_csv(\"Twentysix.csv\",index=None)","51998ce1":"<h2> Merge building_metadata with Train and Test <\/h2>","6d50019c":"<h3> Light GB model<\/h3>"}}