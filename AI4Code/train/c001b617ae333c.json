{"cell_type":{"35566021":"code","927bc573":"code","36ebb1b4":"code","520a90fb":"code","30ef986a":"code","47c679ec":"code","ca637d54":"code","977bb968":"code","0c220469":"code","a39552c5":"code","0a56962a":"code","2be7db3c":"code","ceb66375":"code","653e76ba":"code","c3a50df8":"code","04e9fbab":"code","b2c10e57":"code","57e4f225":"markdown","9424ad47":"markdown","461a0b7e":"markdown","7e49ad48":"markdown","3a0564d3":"markdown","b7a42d80":"markdown"},"source":{"35566021":"!pip install ..\/input\/effnetpytorchmodel\/efficientnet_pytorch-0.1.0-py3-none-any.whl","927bc573":"import os\nimport pandas as pd\nimport cv2 as cv\n\nimport torch\nimport torch.nn as nn\nimport efficientnet_pytorch\n\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom pathlib import Path\n\nfrom albumentations import (\n    Compose, Normalize\n)\nfrom albumentations.pytorch import ToTensorV2","36ebb1b4":"# Set device\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","520a90fb":"# Set configuration\nclass Config:\n    cfg = {\n        'batch_size': 32,\n        'num_workers': 8,\n        'image_size': (512, 512),\n        'num_classes': 5,\n        'model_path': '..\/input\/effnetb0f3\/3_fold_model_effnet_b0_best.torch'\n    }","30ef986a":"base_dir = Path('\/kaggle\/input\/cassava-leaf-disease-classification')\ntest_img_dir = f'{base_dir}\/test_images'\ntest_df = pd.read_csv(f'{base_dir}\/sample_submission.csv', index_col=0)","47c679ec":"test_df","ca637d54":"class CassavaDataset(Dataset):\n    def __init__(self, df, image_size, augments=None):\n        self.df = df.index.tolist()\n        self.image_size = image_size\n        self.augments = augments\n        \n    def __getitem__(self, idx):\n        image = cv.imread(os.path.join(test_img_dir, self.df[idx]))\n        image = cv.resize(image, self.image_size)\n        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n        \n        if self.augments:\n            image = self.augments(image=image)['image']\n        \n        return {'X': image}\n    \n    def __len__(self):\n        return len(self.df)","977bb968":"class Augments:\n    test_augments = Compose([\n        Normalize(mean=[.485, .456, .406],\n                  std=[.229, .224, .225],\n                  p=1.),\n        ToTensorV2(p=1.),\n    ],\n    p=1.,\n    )","0c220469":"test_dataset = CassavaDataset(df=test_df, image_size=Config.cfg['image_size'], augments=Augments.test_augments)","a39552c5":"test_dataloader = DataLoader(\n    test_dataset,\n    batch_size=Config.cfg['batch_size'],\n    shuffle=False,\n    num_workers=Config.cfg['num_workers']\n)","0a56962a":"def efficientnet_b0(num_classes):\n    model = efficientnet_pytorch.EfficientNet.from_name('efficientnet-b0')\n    model._fc = nn.Linear(in_features=1280,\n                          out_features=num_classes,\n                          bias=True)\n    return model","2be7db3c":"model = efficientnet_b0(Config.cfg['num_classes']).to(device)","ceb66375":"checkpoint = torch.load(Config.cfg['model_path'], map_location=device)","653e76ba":"model.load_state_dict(checkpoint['model_state_dict'])\n\nbest_score = checkpoint['best_valid_score']\nepoch_num = checkpoint['num_epoch']\n\nprint(f'Best validation score: {round(best_score, 4)} in {epoch_num} epoch.')","c3a50df8":"model.eval()","04e9fbab":"y_prediction = []\n\nfor batch in test_dataloader:\n    with torch.no_grad():\n        X_test = batch['X'].to(device)\n        \n        y_prediction.extend(model(X_test).argmax(axis=-1).cpu().numpy())\n        \nprint(y_prediction)","b2c10e57":"test_df['label'] = y_prediction\ntest_df.to_csv('submission.csv')","57e4f225":"<h1 style='background:#2cab6c; border:0; color:white'><center>Evaluation<\/center><\/h1>","9424ad47":"<h1 style='background:#2cab6c; border:0; color:white'><center>Model Initialization<\/center><\/h1>","461a0b7e":"<h1 style='background:#2cab6c; border:0; color:white'><center>Paths, files<\/center><\/h1>","7e49ad48":"<h1 style='background:#2cab6c; border:0; color:white'><center>Data Preparation<\/center><\/h1>","3a0564d3":"<h1 style='background:#2cab6c; border:0; color:white'><center>Submission<\/center><\/h1>","b7a42d80":"<h1 style='background:#2cab6c; border:0; color:white'><center>Importing Libraries<\/center><\/h1>"}}