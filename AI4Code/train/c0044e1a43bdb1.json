{"cell_type":{"43eddec0":"code","85c4996a":"code","f0b14882":"code","4a5a2872":"code","d3f6870f":"code","045410da":"code","cfe26b9c":"code","ac6b709b":"code","20082f4e":"code","eb9fec0f":"code","aad6ad71":"code","7954307c":"code","7b641edb":"code","9b83a90a":"code","b79c270c":"code","096da339":"code","cf70378d":"code","9e03b78f":"code","230584bf":"code","b375f08d":"code","d0317c84":"markdown","fbbcaa57":"markdown","8472df85":"markdown","f895a6ba":"markdown","1dddcf05":"markdown","ff01c160":"markdown"},"source":{"43eddec0":"!git clone https:\/\/github.com\/cleardusk\/3DDFA_V2.git\n%cd 3DDFA_V2\n!sh .\/build.sh","85c4996a":"# before import, make sure FaceBoxes and Sim3DR are built successfully\n\nimport cv2\nimport yaml\n\nfrom FaceBoxes import FaceBoxes\nfrom TDDFA import TDDFA\nfrom utils.render import render\nfrom utils.depth import depth\nfrom utils.pncc import pncc\nfrom utils.uv import uv_tex\nfrom utils.pose import viz_pose\nfrom utils.serialization import ser_to_ply, ser_to_obj\nfrom utils.functions import draw_landmarks, get_suffix\n\nimport matplotlib.pyplot as plt\nfrom skimage import io\nfrom IPython.display import Image","f0b14882":"# load config\ncfg = yaml.load(open('configs\/mb1_120x120.yml'), Loader=yaml.SafeLoader)\n\n# Init FaceBoxes and TDDFA, recommend using onnx flag\nonnx_flag = True  # or True to use ONNX to speed up\nif onnx_flag:\n    !pip install onnxruntime\n    \n    import os\n    os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n    os.environ['OMP_NUM_THREADS'] = '4'\n    from FaceBoxes.FaceBoxes_ONNX import FaceBoxes_ONNX\n    from TDDFA_ONNX import TDDFA_ONNX\n\n    face_boxes = FaceBoxes_ONNX()\n    tddfa = TDDFA_ONNX(**cfg)\nelse:\n    face_boxes = FaceBoxes()\n    tddfa = TDDFA(gpu_mode=False, **cfg)","4a5a2872":"# given an image path or the image url\n\n# img_fp = 'examples\/inputs\/emma.jpg'\n# img = cv2.imread(img_fp)\n# plt.imshow(img[..., ::-1])\n\nimg_url = 'https:\/\/raw.githubusercontent.com\/cleardusk\/3DDFA_V2\/master\/examples\/inputs\/emma.jpg'\nimg = io.imread(img_url)\nplt.imshow(img)\nplt.axis('off')\n\nimg = img[..., ::-1]  # RGB -> BGR","d3f6870f":"# face detection\nboxes = face_boxes(img)\nprint(f'Detect {len(boxes)} faces')\nprint(boxes)","045410da":"# regress 3DMM params\nparam_lst, roi_box_lst = tddfa(img, boxes)","cfe26b9c":"# reconstruct vertices and visualizing sparse landmarks\ndense_flag = False\nver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\ndraw_landmarks(img, ver_lst, dense_flag=dense_flag)","ac6b709b":"# reconstruct vertices and visualizing dense landmarks\ndense_flag = True\nver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\ndraw_landmarks(img, ver_lst, dense_flag=dense_flag)","20082f4e":"# reconstruct vertices and render\nver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\nrender(img, ver_lst, tddfa.tri, alpha=0.6, show_flag=True);","eb9fec0f":"# reconstruct vertices and render depth\nver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\ndepth(img, ver_lst, tddfa.tri, show_flag=True);","aad6ad71":"# reconstruct vertices and render pncc\nver_lst = tddfa.recon_vers(param_lst, roi_box_lst, dense_flag=dense_flag)\npncc(img, ver_lst, tddfa.tri, show_flag=True);","7954307c":"# running offline\n# %%bash\nfor OPT in ['2d_sparse', '2d_dense', '3d', 'depth', 'pncc', 'pose', 'uv_tex', 'ply', 'obj']:\n    !python demo.py -f examples\/inputs\/trump_hillary.jpg -o $OPT --show_flag=false --onnx;","7b641edb":"!ls examples\/results\/","9b83a90a":"Image('examples\/results\/trump_hillary_2d_dense.jpg')","b79c270c":"Image('examples\/results\/trump_hillary_2d_sparse.jpg')","096da339":"Image('examples\/results\/trump_hillary_3d.jpg')","cf70378d":"Image('examples\/results\/trump_hillary_depth.jpg')","9e03b78f":"Image('examples\/results\/trump_hillary_pncc.jpg')","230584bf":"Image('examples\/results\/trump_hillary_pose.jpg')","b375f08d":"!rm -r examples\/","d0317c84":"### Detect faces using FaceBoxes","fbbcaa57":"<h3><center>3D Face Alignment<\/center><\/h3>\n<img src=\"https:\/\/github.com\/cleardusk\/3DDFA_V2\/raw\/master\/docs\/images\/webcam.gif\" width=\"750\" height=\"750\"\/>\n<h4><\/h4>\n<h4><center><a href=\"https:\/\/openaccess.thecvf.com\/content_CVPR_2019\/html\/Zhao_Pyramid_Feature_Attention_Network_for_Saliency_Detection_CVPR_2019_paper.html\">Source: Towards Fast, Accurate and Stable 3D Dense Face Alignment [Jianzhu Guo et. al.]<\/a><\/center><\/h4>","8472df85":"## Introduction\n\n### The notebook is a demo of [Towards Fast, Accurate and Stable 3D Dense Face Alignment](https:\/\/arxiv.org\/abs\/2009.09960) obtained from the authors' original [3DDFA_V2 Implementation](https:\/\/github.com\/cleardusk\/3DDFA_V2).","f895a6ba":"### Load configs","1dddcf05":"### Regressing 3DMM parameters, reconstruction and visualization","ff01c160":"## Acknowledgements\n\n### This work was inspired by and borrows code from [Jianzhu Guo](https:\/\/github.com\/cleardusk)'s [3DDFA_V2 Implementation](https:\/\/github.com\/cleardusk\/3DDFA_V2). If you use this work, you should cite the research work [Towards Fast, Accurate and Stable 3D Dense Face Alignment](https:\/\/arxiv.org\/abs\/2009.09960) and cite \/ star \ud83c\udf1f the [official implementation](https:\/\/github.com\/cleardusk\/3DDFA_V2)."}}