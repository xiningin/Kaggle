{"cell_type":{"e212cf54":"code","1b97cf0a":"code","09dc1f64":"code","f62a2c66":"code","ab431598":"code","90c7e639":"code","61f59a13":"code","b6d26dc9":"code","d5243200":"code","d1d7d296":"code","a18ac43c":"code","fe4cd92e":"code","efc9403d":"code","b741bcf0":"code","e1ff7e9b":"code","6d786043":"code","29581234":"code","825ef104":"code","ffb0da20":"code","46dfeeec":"code","ae6cb3fb":"markdown","58c9dec7":"markdown","fe404e28":"markdown"},"source":{"e212cf54":"\n# Import packages\nimport pandas as pd\nimport patsy\nimport numpy as np\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures,LabelEncoder,OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nimport scipy.stats as stats\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.compose import ColumnTransformer\nsns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1b97cf0a":"df=pd.read_csv('\/kaggle\/input\/airbnb-prices-prediction\/development.csv')\n","09dc1f64":"df=df[[ \n        'neighbourhood','latitude', 'longitude', 'room_type',\n       'minimum_nights', 'number_of_reviews',\n       'reviews_per_month', 'calculated_host_listings_count',\n       'availability_365','price']]\ndf.dropna(inplace=True)\ndf['reviews_per_month']=df['reviews_per_month'].fillna(0).copy()\nencoder=LabelEncoder()\ndf['room_type']=encoder.fit_transform(df['room_type']).copy()\nencoder2=LabelEncoder()\ndf['neighbourhood']=encoder2.fit_transform(df['neighbourhood']).copy()\nz_scores = stats.zscore(df)\n# calculate z-scores of `df`\n\nabs_z_scores = np.abs(z_scores)\nfiltered_entries = (abs_z_scores < 3).all(axis=1)\ndf = df[filtered_entries]\n\ndf.describe()\ndf.isnull().sum()\n# df.dtypes\n# df\n","f62a2c66":"fig = plt.figure(figsize = (10, 7))\nsns.residplot(df.neighbourhood, df.price, color='magenta')\n\n# title and labels\nplt.title('Residual plot', size=24)\nplt.xlabel('Independants ', size=18)\nplt.ylabel('Dependant', size=18);","ab431598":"X=df[['neighbourhood', \n         'room_type',\n        \n       'reviews_per_month', 'calculated_host_listings_count',\n       'availability_365']].copy()\n# X= df[['reviews_per_month','longitude','latitude' ,'minimum_nights','neighbourhood','room_type','availability_365' ]]\ny=df[['price']].copy()\nprint(X.shape,y.shape)\nX","90c7e639":"# sns.scatterplot(X['availability_365'],y['price'])\n\nf, ax = plt.subplots(figsize=(20, 20))\nax=X.boxplot()\n# ax=y.boxplot()","61f59a13":"df.corr()['price']\nf, ax = plt.subplots(figsize=(10, 10))\nax=sns.heatmap(df.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1.);","b6d26dc9":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nX=scaler.fit_transform(X)","d5243200":"\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=105)\nx_train.shape,x_test.shape,y_train.shape,y_test.shape","d1d7d296":"# from sklearn.feature_selection import SelectKBest\n# from sklearn.feature_selection import f_regression\n# from matplotlib import pyplot\n \n# # feature selection\n# def select_features(X_train, y_train, X_test):\n#     # configure to select all features\n#     fs = SelectKBest(score_func=f_regression, k='all')\n#     # learn relationship from training data\n#     fs.fit(X_train, y_train)\n#     # transform train input data\n#     X_train_fs = fs.transform(X_train)\n#     # transform test input data\n#     X_test_fs = fs.transform(X_test)\n#     return X_train_fs, X_test_fs, fs\n \n# # feature selection\n# x_train, x_test, fs = select_features(x_train, y_train, x_test)\nx_train.shape","a18ac43c":"from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score,mean_squared_error\n\nprint(\"Linear Reggression\")\nlinreg = LinearRegression()\nlinreg.fit(x_train,y_train)\ny_pred=linreg.predict(x_test)\n# x_train.dtypes,y_train.dtypes,x_test.dtypes,y_test.dtypes\nprint('R-squared train score: {:.3f}'.format(linreg.score(x_train, y_train)))\nprint('R-squared test score: {:.3f}'.format(linreg.score(x_test, y_test)))\n### Calculate RMSE\nrmse1 = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(rmse1)\n\nprint(\"Lasso Reggression\")\nlassoreg = Lasso(alpha=0.1)\nlassoreg.fit(x_train,y_train)\ny_pred=lassoreg.predict(x_test)\nprint('R-squared train score: {:.3f}'.format(lassoreg.score(x_train, y_train)))\nprint('R-squared test score: {:.3f}'.format(lassoreg.score(x_test, y_test)))\n### Calculate RMSE\nrmse1 = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(rmse1)\n\nprint(\"Ridge Reggression\")\nridge = Ridge()\nridge.fit(x_train,y_train)\ny_pred=ridge.predict(x_test)\nprint('R-squared train score: {:.3f}'.format(ridge.score(x_train, y_train)))\nprint('R-squared test score: {:.3f}'.format(ridge.score(x_test, y_test)))\n### Calculate RMSE\nrmse1 = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(rmse1)\n\nprint(\"Decision Tree Reggression\")\ndec_reg = DecisionTreeRegressor(max_depth=8)\ndec_reg.fit(x_train,y_train)\ny_pred=dec_reg.predict(x_test)\nprint('R-squared train score: {:.3f}'.format(dec_reg.score(x_train, y_train)))\nprint('R-squared test score: {:.3f}'.format(dec_reg.score(x_test, y_test)))\n### Calculate RMSE\nrmse1 = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(rmse1)\n\nprint(\"RandomForrest Reggression\")\ndec_reg = RandomForestRegressor(n_estimators= 1200,\n min_samples_split= 5,\n min_samples_leaf= 2,\n max_features='sqrt',\n max_depth=20,\n bootstrap=True)\ndec_reg.fit(x_train,y_train)\ny_pred=dec_reg.predict(x_test)\n# x_train.dtypes,y_train.dtypes,x_test.dtypes,y_test.dtypes\nprint('R-squared train score: {:.3f}'.format(dec_reg.score(x_train, y_train)))\nprint('R-squared test score: {:.3f}'.format(dec_reg.score(x_test, y_test)))\n### Calculate RMSE\nrmse1 = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(rmse1)\n\nprint(\"Multilayer Perceptron Reggression\")\nmlp = MLPRegressor(random_state=1, max_iter=500)\nmlp.fit(x_train,y_train)\ny_pred=mlp.predict(x_test)\n# x_train.dtypes,y_train.dtypes,x_test.dtypes,y_test.dtypes\nprint('R-squared train score: {:.3f}'.format(mlp.score(x_train, y_train)))\nprint('R-squared test score: {:.3f}'.format(mlp.score(x_test, y_test)))\n### Calculate RMSE\nrmse1 = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(rmse1)\n","fe4cd92e":"# from sklearn.model_selection import RandomizedSearchCV\n# import pprint\n# # Number of trees in random forest\n# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 15)]\n# # Number of features to consider at every split\n# max_features = ['auto', 'sqrt']\n# # Maximum number of levels in tree\n# max_depth = [int(x) for x in np.linspace(10, 80, num = 11)]\n# max_depth.append(None)\n# # Minimum number of samples required to split a node\n# min_samples_split = [2, 5, 10]\n# # Minimum number of samples required at each leaf node\n# min_samples_leaf = [1, 2, 4]\n# # Method of selecting samples for training each tree\n# bootstrap = [True, False]\n# # Create the random grid\n# random_grid = {'n_estimators': n_estimators,\n#                'max_features': max_features,\n#                'max_depth': max_depth,\n#                'min_samples_split': min_samples_split,\n#                'min_samples_leaf': min_samples_leaf,\n#                'bootstrap': bootstrap}\n# pprint.pprint(random_grid)\n# # Use the random grid to search for best hyperparameters\n# # First create the base model to tune\n# rf = RandomForestRegressor()\n# # Random search of parameters, using 3 fold cross validation, \n# # search across 100 different combinations, and use all available cores\n# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 40, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# # Fit the random search model\n# rf_random.fit(x_train, y_train)\n# rf_random.best_params_","efc9403d":"eval_df=pd.read_csv('\/kaggle\/input\/airbnb-prices-prediction\/evaluation.csv')\nsub_df=eval_df.copy()","b741bcf0":"eval_df=eval_df.rename(columns={\"neighbourhood_group_cleansed\":\"neighbourhood_group\"})\neval_df=eval_df[['neighbourhood', \n         'room_type',\n        \n       'reviews_per_month', 'calculated_host_listings_count',\n       'availability_365']]\n\neval_df['room_type']=eval_df['room_type'].astype(str)\neval_df['room_type']=eval_df['room_type'].astype('category')\neval_df['neighbourhood']=eval_df['neighbourhood'].astype(str)\neval_df['neighbourhood']=eval_df['neighbourhood'].astype('category')\neval_df['reviews_per_month']=eval_df['reviews_per_month'].fillna(eval_df['reviews_per_month'].mean()).copy()\n# df.dropna(inplace=True)\n\nencoder_roomtype=LabelEncoder()\neval_df['room_type']=encoder_roomtype.fit_transform(eval_df['room_type']).copy()\nencoder_neightboor=LabelEncoder()\neval_df['neighbourhood']=encoder_neightboor.fit_transform(eval_df['neighbourhood']).copy()\neval_df.isna().sum()\n# df.dtypes\n# eval_df.dtypes\neval_df","e1ff7e9b":"\neval_df.isnull().sum()\neval_df['reviews_per_month']=eval_df['reviews_per_month'].fillna(eval_df['reviews_per_month'].mean()).copy()\n# df.dropna(inplace=True)\n# scaler=StandardScaler()\nX=scaler.fit_transform(eval_df)\nprice=mlp.predict(X)\n","6d786043":"sub_df=pd.read_csv('\/kaggle\/input\/airbnb-prices-prediction\/sample_submission.csv')\nsub_df['price']=price\nsub_df.set_index('id',inplace=True)\nsub_df","29581234":"sub_df.to_csv('submission.csv')","825ef104":"import plotly.graph_objs as go\nimport numpy as np","ffb0da20":"scatter = go.Scatter(x=np.array(sub_df['longitude']).flatten(),\n                     y=np.array(sub_df['latitude']).flatten(),\n                     marker={'color': np.array(price).flatten(),\n                             'showscale': True},\n                     mode='markers')\nfig = go.FigureWidget(data=[scatter],\n                      layout={'xaxis': {'title': 'lon'},\n                              'yaxis': {'title': 'lat'}})\nfig","46dfeeec":"scatter = go.Scatter(x=np.array(df['longitude']).flatten(),\n                     y=np.array(df['latitude']).flatten(),\n                     marker={'color': np.array(df['price']).flatten(),\n                             'showscale': True},\n                     mode='markers')\nfig = go.FigureWidget(data=[scatter],\n                      layout={'xaxis': {'title': 'lon'},\n                              'yaxis': {'title': 'lat'}})\nfig","ae6cb3fb":"**Dropped **\n\n\u2022\tId\n\u2022\tName\n\u2022\tHost_id\n\u2022\tHost name\n\u2022\tLast_review\n\u2022\tNeighbourhood_group(because this column is all null in evaluation dataset)\n","58c9dec7":"As from residual plot it is clear that data is highly scattered and data is not linear at all. Residual plot shows same story.","fe404e28":"# CV GRIDSEARCH"}}