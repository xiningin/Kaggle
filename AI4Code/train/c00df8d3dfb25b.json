{"cell_type":{"042adf62":"code","c08504f3":"code","be83b29a":"code","54ebff7e":"code","a54a6c2f":"code","df6b1f5d":"code","059b3277":"code","86b34551":"code","bc9f3c44":"code","e4572c0e":"code","f88c76c6":"code","a7537409":"code","f9d6741b":"code","afbbe68f":"code","23e5e97a":"code","c9c07a37":"code","f7823804":"code","6fd4c65a":"code","81e405fb":"code","268e346d":"code","c15f2480":"code","db84cd20":"code","0f35f2c5":"code","6800977d":"code","7b3ba5d7":"code","bc749835":"markdown","7b657771":"markdown","503f2779":"markdown","6eac3a62":"markdown","888bf59c":"markdown","e419262e":"markdown","37c0221a":"markdown","e1e4483a":"markdown","83e6c279":"markdown"},"source":{"042adf62":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","c08504f3":"data = pd.read_csv('..\/input\/airquality\/AirQualityUCI.csv')\ndata.head()","be83b29a":"data.dropna(axis=1, how='all', inplace=True)\ndata.dropna(axis=0, how='all', inplace=True)","54ebff7e":"data.shape","a54a6c2f":"data.head()","df6b1f5d":"# Make dates actual dates\ndata['Date'] = pd.to_datetime(data['Date'])","059b3277":"# Convert measurements to floats\nfor col in data.iloc[:,2:].columns:\n    if data[col].dtypes == object:\n        data[col] = data[col].str.replace(',', '.').astype('float')","86b34551":"# Compute the average considering only the positive values\ndef positive_average(num):\n    return num[num > -200].mean()\n# Aggregate data\ndaily_data = data.drop('Time', axis=1).groupby('Date').apply(positive_average)","bc9f3c44":"# Drop columns with more than 8 NaN\ndaily_data = daily_data.iloc[:,(daily_data.isna().sum() <= 8).values]","e4572c0e":"# Remove rows containing NaN values\ndaily_data = daily_data.dropna()","f88c76c6":"daily_data.head()","a7537409":"# Aggregate data by week\nweekly_data = daily_data.resample('W').mean()","f9d6741b":"weekly_data.head()","afbbe68f":"# Plot the weekly concentration of each gas\ndef plot_data(col):\n    plt.figure(figsize=(17, 8))\n    plt.plot(weekly_data[col])\n    plt.xlabel('Time')\n    plt.ylabel(col)\n    plt.grid(False)\n    plt.show()\n\nfor col in weekly_data.columns:\n    plot_data(col)","23e5e97a":"cols_to_drop = ['PT08.S1(CO)', 'C6H6(GT)', 'PT08.S2(NMHC)', 'PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH']\n\nweekly_data = weekly_data.drop(cols_to_drop, axis=1)","c9c07a37":"weekly_data.head()","f7823804":"from fbprophet import Prophet\nimport logging\n\nlogging.getLogger().setLevel(logging.ERROR)","6fd4c65a":"# Change the column names according to Prophet's guidelines\ndf = weekly_data.reset_index()\ndf.columns = ['ds', 'y']\ndf.head()","81e405fb":"# Split into a train\/test set\nprediction_size = 30\ntrain_df = df[:-prediction_size]\n\n# Initialize and train a model\nm = Prophet()\nm.fit(train_df)","268e346d":"# Make predictions\nfuture = m.make_future_dataframe(periods=prediction_size)\n\nforecast = m.predict(future)\nforecast.head()","c15f2480":"# Plot forecast\nm.plot(forecast)","db84cd20":"# Plot forecast's components\nm.plot_components(forecast)","0f35f2c5":"# Evaluate the model\ndef make_comparison_dataframe(historical, forecast):\n    return forecast.set_index('ds')[['yhat', 'yhat_lower', 'yhat_upper']].join(historical.set_index('ds'))\n\ncmp_df = make_comparison_dataframe(df, forecast)\ncmp_df.head()","6800977d":"def calculate_forecast_errors(df, prediction_size):\n    \n    df = df.copy()\n    \n    df['e'] = df['y'] - df['yhat']\n    df['p'] = 100 * df['e'] \/ df['y']\n    \n    predicted_part = df[-prediction_size:]\n    \n    error_mean = lambda error_name: np.mean(np.abs(predicted_part[error_name]))\n    \n    return {'MAPE': error_mean('p'), 'MAE': error_mean('e')}\n\nfor err_name, err_value in calculate_forecast_errors(cmp_df, prediction_size).items():\n    print(err_name, err_value)","7b3ba5d7":"# Plot forecast with upper and lower bounds\nplt.figure(figsize=(17, 8))\nplt.plot(cmp_df['yhat'])\nplt.plot(cmp_df['yhat_lower'])\nplt.plot(cmp_df['yhat_upper'])\nplt.plot(cmp_df['y'])\nplt.xlabel('Time')\nplt.ylabel('Average Weekly NOx Concentration')\nplt.grid(False)\nplt.show()","bc749835":"Let's check if the time series has any interesting features, such as seasonality:","7b657771":"Here, we start off by parsing our date column to turn into \u201cdates\u201d.\nThen, we turn all the measurements into floats.\n\nAfter, we aggregate the data by day, by taking the average of each measurement.\n\nAt this point, we still have some NaN that we need to get rid of. Therefore, we remove the columns that have more than 8 NaN. That way, we can then remove rows containing NaN values without losing too much data.\n\nFinally, we aggregate the data by week, because it will give a smoother trend to analyze.\n\nWe can plot the trends of each chemical. Here, we show that of NOx.\n","503f2779":"# Model\nLet's focus on predictig the concentration of NOx. Oxides of nitrogen react to form smog and acid rain, as well as being central to the formation of fine particles and ground level ozone, both of which are associated with adverse health effects.","6eac3a62":"Then, we define a training set. For that we will hold out the last 30 entries for prediction and validation.\n\nAfterwards, we simply initialize Prophet, fit the model to the data, and make predictions!","888bf59c":"Here, Prophet only identified a downward trend with no seasonality.","e419262e":"# Data cleaning and feature engineering","37c0221a":"Not bad! We still need to make some fine-tuning next.","e1e4483a":"Here, \n- yhat: the prediction\n- yhat_lower and yhat_upper: the lower and upper bound of the prediction respectively.","83e6c279":"Prophet requires the date column to be named ds and the feature column to be named y, so we make the appropriate changes."}}