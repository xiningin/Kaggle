{"cell_type":{"e82faafa":"code","2c152d40":"code","041219b8":"code","87336245":"code","55a65cbf":"code","758254a6":"code","82d7783b":"code","3286311e":"code","9a466314":"code","50cc91b5":"code","635db037":"code","597d7d0d":"code","a682bb8c":"code","ae9fb62e":"code","9c472936":"code","10dc543e":"code","9c1b7a3d":"code","2312551b":"code","07683ae4":"markdown","8ea847f7":"markdown","e3573daa":"markdown","137d83f7":"markdown","93e1ff74":"markdown","5951632d":"markdown","45690b8d":"markdown"},"source":{"e82faafa":"import torch\nimport torch.nn.functional as F\nfrom torch import nn, optim\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import transforms, models\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensor\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nimport os\n\nprint(os.listdir(\"\/kaggle\/input\/digit-recognizer\"))\n\nN_FOLDS = 5\nBATCH_SIZE = 256","2c152d40":"PATH = '\/kaggle\/input\/digit-recognizer\/'","041219b8":"# Checking GPU is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('Training on CPU...')\nelse:\n    print('Training on GPU...')","87336245":"# Dataset responsible for manipulating data for training as well as training tests.\nclass DatasetMNIST(torch.utils.data.Dataset):\n    def __init__(self, data, augmentations=None):\n        self.data = data\n        self.augmentations = augmentations \n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        item = self.data.iloc[index]\n                \n        image = item[1:].values.astype(np.uint8).reshape((28, 28, 1))\n        label = item[0]\n        \n        if self.augmentations  is not None:\n            augmented = self.augmentations(image=image)   \n            return augmented['image'], label\n        else:\n            return image, label","55a65cbf":"dataset = pd.read_csv(f'{PATH}train.csv')\ndataset.head(1)","758254a6":"def custom_folds(dataset,n_folds=N_FOLDS):\n    '''return train and valid indexies'''\n    train_valid_id = []\n    start = 0\n    size = len(dataset)\n    split = size \/\/ n_folds\n    valid_size = split\n    for i in range(n_folds):\n        train_data = dataset.drop(dataset.index[start:split]).index.values\n        valid_data = dataset.loc[start:split-1].index.values        \n        train_valid_id.append((train_data,valid_data))\n        start += valid_size\n        split += valid_size\n    return train_valid_id","82d7783b":"train_valid = custom_folds(dataset=dataset)","3286311e":"transform_train = A.Compose([\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=10),\n    A.Normalize(mean=(0.485,), std=(0.229,)),\n    ToTensor(),\n])\n\ntransform_valid = A.Compose([\n    A.Normalize(mean=(0.485,), std=(0.229,)),\n    ToTensor(),\n])","9a466314":"# Creating datasets for training and validation\ntrain_data = DatasetMNIST(dataset, augmentations=transform_train)\nvalid_data = DatasetMNIST(dataset, augmentations=transform_valid)\n\n# Make data loaders for N_FOLDS train\/valid\ntrain_valid_loaders = []\nfor i in train_valid:\n    train_idx, valid_idx = i\n    train_sampler = SubsetRandomSampler(train_idx)\n    valid_sampler = SubsetRandomSampler(valid_idx)\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sampler)\n    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE, sampler=valid_sampler)\n    train_valid_loaders.append((train_loader,valid_loader))","50cc91b5":"# Viewing data examples used for training (augmented data)\nfig, axis = plt.subplots(2, 6, figsize=(10, 7))\n# first train fold\nimages, labels = next(iter(train_valid_loaders[0][0]))\n\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        image, label = images[i], labels[i]\n\n        ax.imshow(image.view(28, 28), cmap='binary') # add image\n        ax.set(title = f\"{label}\") # add label","635db037":"# Viewing data examples used for validation\nfig, axis = plt.subplots(2, 6, figsize=(10, 7))\n# first valid fold\nimages, labels = next(iter(train_valid_loaders[0][1]))\n\nfor i, ax in enumerate(axis.flat):\n    with torch.no_grad():\n        image, label = images[i], labels[i]\n\n        ax.imshow(image.view(28, 28), cmap='binary') # add image\n        ax.set(title = f\"{label}\") # add label","597d7d0d":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2, padding=2)\n        self.bn3 = nn.BatchNorm2d(32)\n        self.conv4 = nn.Conv2d(32, 64, kernel_size=3)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.conv5 = nn.Conv2d(64, 64, kernel_size=3)\n        self.bn5 = nn.BatchNorm2d(64)\n        self.conv6 = nn.Conv2d(64, 64, kernel_size=5, stride=2, padding=2)\n        self.bn6 = nn.BatchNorm2d(64)\n        self.conv7 = nn.Conv2d(64, 128, kernel_size=4)\n        self.bn7 = nn.BatchNorm2d(128)\n        self.lin1 = nn.Linear(128,10)\n    def forward(self, xb):\n        x = xb.view(-1, 1, 28, 28)\n        x = self.bn1(F.relu(self.conv1(x)))\n        x = self.bn2(F.relu(self.conv2(x)))\n        x = self.bn3(F.relu(self.conv3(x)))\n        x = F.dropout2d(x, 0.25)\n        x = self.bn4(F.relu(self.conv4(x)))\n        x = self.bn5(F.relu(self.conv5(x)))\n        x = self.bn6(F.relu(self.conv6(x)))\n        x = F.dropout2d(x, 0.25)\n        x = self.bn7(F.relu(self.conv7(x)))\n        x = torch.flatten(x, start_dim=1)\n        x = F.dropout2d(x, 0.25)\n        x = self.lin1(x)\n        x = F.softmax(x, dim=1)\n        return x\nmodel = Net()\nprint(model)\n\nif train_on_gpu:\n    model.cuda()","a682bb8c":"# test\nclass DatasetSubmissionMNIST(torch.utils.data.Dataset):\n    def __init__(self, file_path, augmentations=None):\n        self.data = pd.read_csv(file_path)\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        image = self.data.iloc[index].values.astype(np.uint8).reshape((28, 28, 1))\n\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)   \n            return augmented['image']\n            \n        return image","ae9fb62e":"transform_test = A.Compose([\n    A.Normalize(mean=(0.485,), std=(0.229,)),\n    ToTensor(),\n])\n\nsubmissionset = DatasetSubmissionMNIST(f'{PATH}test.csv', augmentations=transform_test)\nsubmissionloader = torch.utils.data.DataLoader(submissionset, batch_size=BATCH_SIZE, shuffle=False)","9c472936":"def every_predict(model,submissionloader=submissionloader):\n    # my\n    all_batchs = []\n    with torch.no_grad():\n        model.eval()\n        for images in submissionloader:\n            if train_on_gpu:\n                images = images.cuda()\n            ps = model(images)\n            all_batchs.append(ps.to('cpu').detach().numpy())\n    return all_batchs","10dc543e":"five_predict = [] # all predicts\nall_train_losses, all_valid_losses = [], []\n\n\nFOLD = 1\nfor i in train_valid_loaders: # for every fold\n    model = Net()\n    if train_on_gpu:\n        model.cuda()\n    train_loader, valid_loader = i\n    LEARNING_RATE = 0.01\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(),lr=LEARNING_RATE)\n    epochs = 120\n    valid_loss_min = np.Inf\n    train_losses, valid_losses = [], []\n    history_accuracy = []\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.7,patience=2) \n    # https:\/\/pytorch.org\/docs\/stable\/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau\n    model.train()\n    for e in range(1, epochs+1):\n        running_loss = 0\n        for images, labels in train_loader:\n            if train_on_gpu:\n                images, labels = images.cuda(), labels.cuda()\n            # Clear the gradients, do this because gradients are accumulated.\n            optimizer.zero_grad()\n            # Forward pass.\n            ps = model(images)\n            # Calculate the loss.\n            loss = criterion(ps, labels)\n            # Turning loss back.\n            loss.backward()\n            # Take an update step and few the new weights.\n            optimizer.step()\n            running_loss += loss.item()\n        else:\n            valid_loss = 0\n            accuracy = 0\n            \n            # Turn off gradients for validation, saves memory and computations.\n            with torch.no_grad():\n                model.eval() # change the network to evaluation mode\n                for images, labels in valid_loader:\n                    if train_on_gpu:\n                        images, labels = images.cuda(), labels.cuda()\n                    # Forward pass\n                    ps = model(images)\n                    # Capturing the class more likely.\n                    _, top_class = ps.topk(1, dim=1)\n                    # Verifying the prediction with the labels provided.\n                    equals = top_class == labels.view(*top_class.shape)\n                    valid_loss += criterion(ps, labels)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n                    \n            model.train() # change the network to training mode\n            train_losses.append(running_loss\/len(train_loader))\n            valid_losses.append(valid_loss\/len(valid_loader))\n            history_accuracy.append(accuracy\/len(valid_loader))\n\n            network_learned = valid_loss < valid_loss_min\n            if e == 1 or e % 5 == 0 or network_learned:\n                print(f\"Epoch: {e}\/{epochs}.. \",\n                      f\"Training Loss: {running_loss\/len(train_loader):.4f}.. \",\n                      f\"Validation Loss: {valid_loss\/len(valid_loader):.4f}.. \",\n                      f\"Valid Accuracy: {accuracy\/len(valid_loader):.4f}\")\n            if network_learned:\n                valid_loss_min = valid_loss\n                torch.save(model.state_dict(), f'best_model_fold{FOLD}.pt')\n                print('Detected network improvement, saving current model')\n        # after every epoch        \n        scheduler.step(running_loss) # put running_loss if you using ReduceLROnPlateau scheduler\n        \n    all_train_losses.append(train_losses)\n    all_valid_losses.append(valid_losses)\n    model.load_state_dict(torch.load(f'best_model_fold{FOLD}.pt')) # predict on best epoch of fold\n    model.eval() # change the network to evaluation mode\n    five_predict.append(every_predict(model))\n    model.train() # change the network to training mode\n    FOLD +=1\n","9c1b7a3d":"n_rows = int(np.ceil(N_FOLDS\/3))\nfig, axis = plt.subplots(n_rows, 3, figsize=(15, 10))\nfor i, ax in enumerate(axis.flat):\n    if i<N_FOLDS:\n        ax.plot(all_train_losses[i], label='Training Loss')\n        ax.plot(all_valid_losses[i], label='Validation Loss')\n        ax.legend(frameon=False)","2312551b":"flat_list = []\nfor sublist in five_predict:\n    for item in sublist:\n        for i in item:\n            flat_list.append(i)\nfinal = []\nfor i in range(0,28000):\n    numbers = [i+a*28000 for a in range(N_FOLDS)]\n    final.append(sum(flat_list[C] for C in numbers))            \nsubm = np.argmax((final),axis=1)\nsample_subm = pd.read_csv(f'{PATH}sample_submission.csv')\nsample_subm['Label'] = subm\nsample_subm.to_csv('submission.csv',index=False)","07683ae4":"### Splitting dataset on N_FOLDS train\/valid.","8ea847f7":"##### This kernel based on [CNN - Digit Recognizer (PyTorch)](https:\/\/www.kaggle.com\/gustafsilva\/cnn-digit-recognizer-pytorch)\nBut with some adds:\n- Simple data augmentation with Albumentaion\n- Model ensemble \n- And other small fixes","e3573daa":"# Configuring and Training Model\n### > 5 hours with 120 epochs. ","137d83f7":"# Training and Validation plots","93e1ff74":"# Submission ","5951632d":"# Modeling and Creating Network (CNN)","45690b8d":"# Augmentation with Albumentation "}}