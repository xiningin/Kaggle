{"cell_type":{"d76f2a86":"code","297ca9d5":"code","6025e7e3":"code","b51641a1":"code","11047fb5":"code","7fca47b1":"code","80b3eeea":"code","5ec4c0a5":"code","3e42502b":"code","3606fe91":"code","fe7374bc":"code","c9fdca71":"code","2a9682d9":"code","4dc92108":"code","d8c908de":"code","70af8a1a":"code","7d477c2c":"code","e27192a8":"markdown"},"source":{"d76f2a86":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader,random_split\nfrom torchvision import datasets, transforms, models\nfrom torchvision.utils import make_grid\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sn\nfrom sklearn.metrics import confusion_matrix\nfrom tqdm import tqdm_notebook, tnrange","297ca9d5":"def train_model(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n    \"\"\"returns trained model\"\"\"\n    # initialize tracker for minimum validation loss\n    valid_loss_min = np.Inf\n    \n    for epoch in range(1, n_epochs+1):\n        # initialize variables to monitor training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        ###################\n        # train the model #\n        ###################\n        model.train()\n        for batch_idx, (data, target) in enumerate(tqdm_notebook(loaders['train'], desc = f\"Train epoc#{epoch}\")):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            # initialize weights to zero\n            optimizer.zero_grad()\n            \n            output = model(data)\n            \n            # calculate loss\n            loss = criterion(output, target)\n            \n            # back prop\n            loss.backward()\n            \n            # grad\n            optimizer.step()\n            \n            train_loss = train_loss + ((1 \/ (batch_idx + 1)) * (loss.data - train_loss))\n            \n            if batch_idx % 50 == 0:\n                print('Epoch %d, Batch %d loss: %.6f' %\n                  (epoch, batch_idx + 1, train_loss))\n        \n        ######################    \n        # validate the model #\n        ######################\n        model.eval()\n        for batch_idx, (data, target) in enumerate(tqdm_notebook(loaders['val'],desc = f\"Val epoc#{epoch}\")):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            ## update the average validation loss\n            output = model(data)\n            loss = criterion(output, target)\n            valid_loss = valid_loss + ((1 \/ (batch_idx + 1)) * (loss.data - valid_loss))        # print training\/validation statistics \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n        \n        ## TODO: save the model if validation loss has decreased\n        if valid_loss < valid_loss_min:\n            torch.save(model, save_path)\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            valid_loss_min = valid_loss\n            \n    # return trained model\n    return model","6025e7e3":"def test_model(loaders, model, criterion, use_cuda):\n\n    # monitor test loss and accuracy\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n\n    for batch_idx, (data, target) in enumerate(tqdm_notebook(loaders['test'])):\n        # move to GPU\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss \n        test_loss = test_loss + ((1 \/ (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to true label\n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n            \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d\/%2d)' % (\n        100. * correct \/ total, correct, total))","b51641a1":"import os\nfrom PIL import Image\nfrom IPython.display import display\nimport warnings\nwarnings.filterwarnings('ignore')","11047fb5":"train_transform = transforms.Compose([\n   transforms.RandomRotation(0),\n   transforms.RandomHorizontalFlip(),\n   transforms.Resize(224),\n   transforms.CenterCrop(224),\n   transforms.ToTensor(),\n   transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) \n])","7fca47b1":"test_transform = transforms.Compose([\n   transforms.Resize(224),\n   transforms.CenterCrop(224),\n   transforms.ToTensor(),\n   transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n])","80b3eeea":"root = '..\/input\/rice-diseases-image-dataset\/RiceDiseaseDataset'\n\ntrain_data_ = datasets.ImageFolder(os.path.join(root,'train'),transform=train_transform)\ntrain_data,val_data = random_split(train_data_, [int(len(train_data_)*.7), len(train_data_)-int(len(train_data_)*.7)], generator=torch.Generator().manual_seed(42))\ntest_data = datasets.ImageFolder(os.path.join(root,'validation'),transform=test_transform)\n\ntrain_loader = DataLoader(train_data,batch_size=10,shuffle=True,pin_memory=True)\nval_loader = DataLoader(val_data,batch_size=10,shuffle=True,pin_memory=True)\ntest_loader = DataLoader(test_data,batch_size=10,shuffle=False,pin_memory=True)\n\nclass_names = train_data_.classes \n\nprint(\"Class in Dataset are \",class_names)","5ec4c0a5":"def count(data,class_names,desc):\n    img_dict = {}\n    for i in range(len(class_names)):\n        img_dict[class_names[i]] = 0\n    for i in tnrange(len(data), desc = desc):\n        img, label = data[i]\n        img_dict[class_names[label]] += 1\n    return img_dict","3e42502b":"train_count = count(train_data,class_names,\"Train_set\")\nval_count = count(val_data, class_names,\"Val set\")","3606fe91":"print(\"Train data set count :\\n\",train_count)\nprint(\"Val data set count :\\n\",val_count)","fe7374bc":"train_data[0][0].size()","c9fdca71":"loaders = {\"train\": train_loader,\n           \"test\": test_loader,\n           \"val\": val_loader}","2a9682d9":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_cuda = torch.cuda.is_available()","4dc92108":"model_ft = models.resnet18(pretrained=True,progress = True)\n# lock\nfor param in model_ft.parameters():\n    param.requires_grad = False\n\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 4)\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer_ft = torch.optim.SGD(model_ft.fc.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\n#exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","d8c908de":"use_cuda","70af8a1a":"model_ft = train_model(2, loaders, model_ft, optimizer_ft, criterion, use_cuda, 'model_transfer.pt')","7d477c2c":"test_model(loaders, model_ft, criterion, use_cuda)","e27192a8":"# Neural Network"}}