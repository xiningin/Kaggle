{"cell_type":{"69cfb3ab":"code","14c278f5":"code","215376da":"code","30b13a7f":"code","77af6a4d":"code","bd754735":"code","bd31e5ee":"code","fa29748b":"code","f9b49d88":"code","8372aaeb":"code","a32efa40":"code","c1bf12b3":"code","628cc83d":"code","069483a2":"markdown","2de1dfd6":"markdown","f4ead63c":"markdown","9c548c01":"markdown","974aab8a":"markdown","b6fa5980":"markdown","05e0d119":"markdown","ecbbeef4":"markdown","d1b299a6":"markdown"},"source":{"69cfb3ab":"# importing the packages\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n","14c278f5":"# load the data \ndf = pd.read_csv(\"..\/input\/gasturbine-co-and-nox-emission-data\/gt_full.csv\", index_col=0)\n\ndf.head()\n","215376da":"# get summary of the dataset \nprint(df.describe())\n# get more information about the variables\nprint(df.info())","30b13a7f":"# create histogram for each variabel to check normality.\ndf.hist(bins = 30, figsize= (10, 10) )\nplt.show()","77af6a4d":"# Check the outliers \n\ndf.boxplot(figsize = (10, 10), widths = 1)","bd754735":"# creating head map with correlation values. \n\n'''\nThe code below is copied from:\nhttps:\/\/stackoverflow.com\/questions\/39409866\/correlation-heatmap\n'''\n# import the packages\nimport seaborn as sns\n\ncmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n\ndef magnify():\n    return [dict(selector=\"th\",\n                 props=[(\"font-size\", \"7pt\")]),\n            dict(selector=\"td\",\n                 props=[('padding', \"0em 0em\")]),\n            dict(selector=\"th:hover\",\n                 props=[(\"font-size\", \"12pt\")]),\n            dict(selector=\"tr:hover td:hover\",\n                 props=[('max-width', '200px'),\n                        ('font-size', '12pt')])\n]\ncorr = df.corr()\ncorr.style.background_gradient(cmap, axis=1)\\\n    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n    .set_caption(\"Hover to magify\")\\\n    .set_precision(2)\\\n    .set_table_styles(magnify())","bd31e5ee":"# prepare the data for the model\n# select the only NOX as target variabel\nnox_df = df.copy()\nnox_df = nox_df.drop(\"CO\", axis = 1) # drop the target variable CO","fa29748b":"# split the data for training and test using sklearn train_test_split function \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import Normalizer\n\n# split the data \nX = nox_df.iloc[:, 0:-1]\ny = nox_df[\"NOX\"]\n\n# normalize the X and y.\nX = nox_df = Normalizer().fit_transform(X)\n# normalize the data \n\nX_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = 0.2,random_state= 0, shuffle = True)\n\n","f9b49d88":"# import the packges for linear regression\nfrom sklearn.linear_model import LinearRegression\nlinear_model = LinearRegression ()\nlinear_model.fit(X_train, y_train)","8372aaeb":"# evalute the model with MAE\nfrom sklearn.metrics import mean_absolute_error\ny_pred = linear_model.predict(X_test)\nmae_linear = mean_absolute_error(y_test, y_pred)\nprint(\"MAE on testset is:\", round(mae_linear, 3))","a32efa40":"# evaluate random forest ensemble for regression\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.ensemble import RandomForestRegressor\n# define dataset\n# define the model\nmodel = RandomForestRegressor( )\n# evaluate the model\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n# report performance\nprint('MAE on cross validation set : %.3f (%.3f)' % (abs(mean(n_scores)), std(n_scores)))","c1bf12b3":"# fit the model \nmodel = RandomForestRegressor(random_state =0)\nmodel = model.fit(X_train, y_train)\n","628cc83d":"# MAE on test set again\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn import metrics \n\ny_pred = model.predict(X_test)\nmae = mean_absolute_error(y_test, y_pred)\n\nprint(\"MAE on test set:\", round (mae, 3))","069483a2":"# 3-Models \nLet's find out of I can create a simple linear and random forest model for this data. ","2de1dfd6":"The heatmap above shows the correlation between features and output variables(CO and NOx). It is easy to see that some features are negatively correlated each other. For example, the correlation between TIT and CO is -0.71, and it means that when the Turbine Inlet Temperature (TIT) decreases, the gas-turbine engine will produce more CO because a low TIT reduces the efficiency of the gas-turbine engine(look at the figure below).\n\n<img src=\"https:\/\/www.researchgate.net\/publication\/282376063\/figure\/fig4\/AS:399367862276099@1472228126114\/Effect-of-TIT-and-compression-ratio-on-gas-turbine-power-out-and-gas-cycle-exergy.png\" width=\"400px\"\/>\n","f4ead63c":"# 2.Loading the data and EDA","9c548c01":" # 4. Conclusion \nLooks like the Random forest works well on this dataset and is also better than the simple linear regression model. I just applied the random forest model with default parameters, and I'm amazed that a simple random forest model can fit the data so well. \n\nThe MAE from the test set is much lower than the MAE from the paper( look at the introduction) and it was 11.29.  \n","974aab8a":"The dataset is clean and has not had any null values. From the \"describe\" function can be seen that almost all variable holds a low SD, so the data is more concentrated to the mean.  It is also true because the sensory data is already averaged by the author( look at the paper). \nNot all the features are normally distributed, I'm going to normalize the data before training a model. ","b6fa5980":"**Model-2:RandomForest**","05e0d119":"**Model-1:Linear regression**","ecbbeef4":"# 1.Introduction \n\nA gas turbine is largely used to generate electricity around the world. In recent years, the awareness of greenhouse gases is raised and the emissions of the gas- turbines are controlled at certain limits according to the environmental regulations. \n\nGenerally, the emission gases are measured by sensors and it is possible that the sensors can generate inaccurate data due to its malfunction or issue with calibration. \n\nNormally, the gas turbines for power plants have constant RPMs, but it does not mean that the level of the emission gases is contestant too. Because the performance of a gas turbine highly depends on many variables like temperature, air pressure, and humidity. These variables are not constant during the day or months, so it is important to measure the true level of the output emissions. \n\nIf I can build, a machine learning model that can accurately predict the level of emission gases, it can be a nice secondary system next to the sensory monitory systems. In case of a malfunction, we can still use the machine learning model to detect the main function of a sensor and at the same time the machine leaning model can work as warning system for the seosory systems( if the sensor does not work). \n\nThe authors are the following papers had collected the dataset and researched how to design a machine learning model with very low MAE.  I\u2019m really interested if I can create a machine learning model which has low MAE as their models. \nSource of the paper: https:\/\/journals.tubitak.gov.tr\/elektrik\/issues\/elk-19-27-6\/elk-27-6-54-1807-87.pdf\n\n\nThe dataset contains 36733 rows and 11 colums; 9 numerical features and two target variabels(CO and NOX). According to the paper above, the CO and NOX are the main pollution gases from a gas-turbine engine. \n\n","d1b299a6":"The boxplot shows that more input variables are outliers, so I'll use mean absolute error (MAE) to evaluate the model in modeling. The MAE is not sensitive to the outliers "}}