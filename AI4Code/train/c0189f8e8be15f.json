{"cell_type":{"b42c4f03":"code","e9312df2":"code","ef2572da":"code","d9ad6c76":"code","f7de8af7":"code","bc9c23f5":"code","65c94baf":"code","d9dc097a":"code","06ed8d65":"code","11232d37":"code","5a8636e7":"code","9c9dfde4":"code","ec9afd7c":"code","3cf34698":"code","69501e45":"code","5dee1174":"code","f1f7e6c2":"code","bb52ff61":"code","8dc95aab":"code","185f8277":"code","4cce7437":"code","e8d7cd5a":"code","e35d9467":"code","8a63647a":"code","afd86450":"code","bd6ba9fe":"code","d9abceda":"code","92f7de26":"code","00beae5f":"code","06a1109f":"code","6c5e8344":"code","7efe9bf1":"code","1bcf4f6a":"code","c051c43d":"code","3ac0bddd":"code","4bac87cc":"code","74cf2250":"code","21737b9e":"code","1e219d9b":"code","d66b2817":"code","8226b3b3":"code","d1d3e401":"code","acdfa149":"code","65d02b8a":"code","69e87557":"code","7504cf8d":"markdown","f07c1046":"markdown","2e73318c":"markdown","c217dfa2":"markdown","eb2dadae":"markdown","924d5103":"markdown","ca255211":"markdown","a93fccd8":"markdown","911f3f42":"markdown","a22a02e8":"markdown","053dffa9":"markdown"},"source":{"b42c4f03":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport math\n\npd.options.display.max_columns = None","e9312df2":"!ls ..\/input\/","ef2572da":"data = pd.read_csv('..\/input\/bank-additional-full.csv', delimiter=';')\ndata.tail()","d9ad6c76":"'''\nRenaming columns just for better understanding\n'''\n\ndata.rename(columns={'housing':'housing_loan'}, inplace=True)","f7de8af7":"data.info()","bc9c23f5":"data.dtypes","65c94baf":"'''\nThe column duration is not supposed to be used, since we only know the call duration\nafter it has been finished, so it is considered data leakage\n'''\n\ndata.drop(['duration'], axis=1, inplace=True)","d9dc097a":"catg_cols = ['job', 'marital', 'education', 'default', 'housing_loan',\n             'loan', 'contact', 'month', 'day_of_week', 'campaign', 'pdays', 'previous',\n             'poutcome']\n\n\nnum_cols = ['age', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n            'euribor3m', 'nr.employed']","06ed8d65":"data.describe()","11232d37":"'''\nI just want to see how many of each feature there is in each column\n\n'''\n\n\nunique_df = pd.DataFrame()\n\nindex=0\nfor column in catg_cols:\n    \n    unique_df = pd.concat([unique_df,pd.DataFrame(data[column].value_counts()).reset_index()], axis=1)\n    unique_df[index] = '........'\n    index+=1\n\nunique_df.fillna('')","5a8636e7":"def plot_bar(col, size=(15,8), hue=True):\n    fig, ax = plt.subplots()\n    sns.set_style(\"whitegrid\")\n    if hue:\n        sns.countplot(col, hue='y', data=data)\n    else:\n        sns.countplot(col, data=data)\n        \n    fig.set_size_inches(size)\n    plt.xlabel(col) # Set text for the x axis\n    plt.ylabel('Count')# Set text for y axis\n    plt.show()\n    ","9c9dfde4":"plot_bar('y', hue=False)","ec9afd7c":"plot_bar('campaign')","3cf34698":"'''\nI'm gonna group more than 5 contacts all into one category\n'''\n\ndata['campaign'] = data['campaign'].apply(lambda x: x if x<5 else 5) # More than 5 contacts are grouped","69501e45":"plot_bar('campaign')","5dee1174":"plot_bar('pdays')","f1f7e6c2":"sns.countplot(data[data['pdays']!=999]['pdays'], hue=data['y'])","bb52ff61":"'''\nGoing to group them into 3 categories\n\n1 = equal or less than 10 days\n\n2 = more than 10 days\n\n0 = not contacted before\n\n'''\n\n\ndef treat_pdays(value):\n    \n    if value <= 10:\n        return 1\n    if value > 10 and value <= 27:\n        return 2\n    if value > 27:\n        return 0\n\ndata['pdays'] = data['pdays'].apply(treat_pdays)","8dc95aab":"plot_bar('pdays')","185f8277":"plot_bar('previous')","4cce7437":"'''\nGoing to group them into 3 categories\n\n1 = contacted once before\n\n2 = contacted more than once before\n\n0 = not contacted before\n\n'''\n\n\ndef treat_previous(value):\n    \n    if value == 0:\n        return 0\n    if value == 1:\n        return 1\n    else:\n        return 2","e8d7cd5a":"data['previous'] = data['previous'].apply(treat_previous)","e35d9467":"plot_bar('previous')","8a63647a":"plot_bar('job')","afd86450":"'''\nMerging housemaid into serices\n'''\n\ndata['job'] = data['job'].replace('housemaid', 'services')","bd6ba9fe":"plot_bar('job')","d9abceda":"'''\nGetting dummies for the categorical columns\n'''\n\n\ndummy_features = pd.get_dummies(data[catg_cols])\n\nnum_features = data[num_cols]\n\nprint(dummy_features.shape)\nprint(num_features.shape)","92f7de26":"'''\nScaling the numerical variables\n\n'''\n\nscaler = StandardScaler()\n\nnum_features = pd.DataFrame(scaler.fit_transform(num_features), columns=num_features.columns)","00beae5f":"'''\nConcatenating the scaled numerical columns with\nthe dummy columns\n'''\n\n\npreprocessed_df = pd.concat([dummy_features, num_features], axis=1)\npreprocessed_df.shape","06a1109f":"'''\nBinarizing 'yes' and 'no'\nvalues in the labels\n'''\n\nlabels = data['y'].map({'no':0, 'yes':1})","6c5e8344":"pca = PCA(n_components=2)\npcs = pca.fit_transform(preprocessed_df)\n\npcs_df = pd.DataFrame(pcs)","7efe9bf1":"def plot_2d(X, y, label='Classes'):   \n \n    for l in zip(np.unique(y)):\n        plt.scatter(X[y==l, 0], X[y==l, 1], label=l)\n    plt.title(label)\n    plt.legend(loc='upper right')\n    plt.show()","1bcf4f6a":"plot_2d(pcs, labels)","c051c43d":"from sklearn.cluster import KMeans","3ac0bddd":"'''\nManually setting initial cluster centers\nfor improved accuracy\n'''\nn_clusters = 15 # 15 clusters from visual inspection above\n\ncluster_centers = np.array([[-1.5,-1.5], [-1.6,-0.5], [-1.7,0.5], [-1.9,1.5], [-2,2.5],\n                            [0.5,-1], [0,0], [0,1], [-0.2,2], [-0.5, 2.8],\n                            [3,-1], [3,0], [2.5,1.1], [2.5,2], [2.5,3.2]])","4bac87cc":"kmeans = KMeans(n_clusters=n_clusters, max_iter=10000, verbose=1, n_jobs=4, init=cluster_centers)\n\nclusters = kmeans.fit_predict(pcs_df)","74cf2250":"pcs_df['cluster'] = clusters","21737b9e":"'''\nWe can see that the clustering is acceptable\n'''\n\n\nplt.scatter(pcs_df[0], pcs_df[1], c=pcs_df['cluster'])","1e219d9b":"labels.value_counts()","d66b2817":"'''\nI'll extract 309 samples from each cluster\n'''\n\nn_samples = labels.value_counts()[1]\/\/15\nn_samples","8226b3b3":"'''\nI'll select 309 random points from each cluster\nBut im only sampling the majority or label == 0\n\n'''\n\n\nindex_list = []\n\nfor i in range(0,n_clusters):\n    \n    choices = pcs_df[(labels==0) & (pcs_df['cluster'] == i)].index\n    \n   \n    \n    index_list.append(np.random.choice(choices, n_samples))\n\n    \nindex_list = np.ravel(index_list)","d1d3e401":"'''\nCreating a new Dataframe with all the samples from the index_list which are all from the majority class\nand all the samples from the minority class\n'''\n\nresampled_raw_data = pd.concat([data.iloc[index_list], data[data['y'] == 'yes']])","acdfa149":"'''\nConfirming concatenation\n'''\n\nresampled_raw_data.shape","65d02b8a":"'''\nConfirming class imbalance\n'''\n\nresampled_raw_data['y'].value_counts()","69e87557":"'''\nSaving resampled Dataframe for future classification task\n'''\n\n\nresampled_raw_data.to_csv('resampled_bank_data.csv')","7504cf8d":"#### Very imbalanced data, we'll need to think of undersampling strategies","f07c1046":"### Pdays","2e73318c":"### Some of these sparse categorical columns like \"'campaign', 'pdays' and 'previous'\" are going to be grouped","c217dfa2":"### Now clustering the PCA components","eb2dadae":"Attribute Information:\n\nInput variables:\n# bank client data:\n1 - age (numeric)  <br>\n2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')  <br>\n3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)  <br>\n4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')  <br>\n5 - default: has credit in default? (categorical: 'no','yes','unknown')  <br>\n6 - housing: has housing loan? (categorical: 'no','yes','unknown')  <br>\n7 - loan: has personal loan? (categorical: 'no','yes','unknown')  <br>\n# related with the last contact of the current campaign:\n8 - contact: contact communication type (categorical: 'cellular','telephone')  <br> \n9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')  <br>\n10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')  <br>\n11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n# other attributes:\n12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)  <br>\n13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)  <br>\n14 - previous: number of contacts performed before this campaign and for this client (numeric)  <br>\n15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')  <br>\n# social and economic context attributes\n16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)  <br>\n17 - cons.price.idx: consumer price index - monthly indicator (numeric)   <br>\n18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)   <br>\n19 - euribor3m: euribor 3 month rate - daily indicator (numeric)  <br>\n20 - nr.employed: number of employees - quarterly indicator (numeric)  <br>\n\n# Output variable (desired target):  <br>\n21 - y - has the client subscribed a term deposit? (binary: 'yes','no')","924d5103":"## Resampling Data\n\nI'll try to resample data using PCA, the data is too inbalanced. <br>\nI want to resample the majority class as uniformly as possible. <br>\nSo, a good approach might be clustering the PCA components and taking equal samples from each cluster.","ca255211":"# Bank marketing data undersampling\n\nthis dataset was acquired from: <br>\n<br>\n\nhttps:\/\/archive.ics.uci.edu\/ml\/datasets\/Bank+Marketing  <br>\n<br>\nThis is the full dataset, which has more features and a lot of class imbalance. <br>\n\nI'll resample the data using PCA, because I want to undersample the majority class as uniformly as possible.","a93fccd8":"### Campaign","911f3f42":"### Job","a22a02e8":"### Target balance","053dffa9":"### Previous"}}