{"cell_type":{"5a8edcaa":"code","33e05925":"code","49e66d96":"code","2164be2a":"code","0a6ca2c6":"code","ee04bd3f":"code","e0099749":"code","84fd81f9":"code","ce619f55":"code","af05682e":"code","547db676":"code","fd010aa5":"code","a25609e5":"code","9b7ffc44":"code","b7e74b07":"code","618543e9":"code","08036427":"code","7c749486":"code","c2786e49":"code","0170d48b":"code","054508bd":"code","c7a0da03":"code","f2a47e59":"code","086f7791":"code","3903db1e":"code","fad1a0a5":"code","2f13f52f":"code","838bce31":"markdown"},"source":{"5a8edcaa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","33e05925":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","49e66d96":"original_df = pd.read_csv(r'\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_df = pd.read_csv(r'\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntotal_df = pd.concat([original_df,test_df],axis=0)","2164be2a":"total_df.info()","0a6ca2c6":"msno.matrix(original_df)\nmsno.heatmap(original_df)","ee04bd3f":"sns.histplot(x='SalePrice',data=total_df)","e0099749":"sns.catplot(x='LotShape',y='LotFrontage',kind='box',data=original_df)","84fd81f9":"sns.relplot(x='LotArea',y='LotFrontage',kind='scatter',data=original_df)","ce619f55":"# Modelos de Regress\u00e3o\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge, LogisticRegression, TweedieRegressor, SGDRegressor, PassiveAggressiveRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\n\ndef model_test(x,y):\n    mlp = MLPRegressor()\n    LiRegr = LinearRegression()\n    ridge = Ridge()\n    lasso = Lasso()\n    bayesian = BayesianRidge()\n    LogRegr = LogisticRegression()\n    tweedie = TweedieRegressor()\n    sgd = SGDRegressor()\n    passiveaggr = PassiveAggressiveRegressor()\n    svr = SVR()\n    knearest = KNeighborsRegressor()\n    gaussian = GaussianProcessRegressor()\n    pls = PLSRegression()\n    decisiontree = DecisionTreeRegressor()\n    rdmforest = RandomForestRegressor()\n    extratree = ExtraTreesRegressor()\n    adaboost = AdaBoostRegressor()\n    gradientboost = GradientBoostingRegressor()\n    xgb = XGBRegressor()\n\n    models_dict = {'MLP':mlp,\"Linear Regression\":LiRegr,\"Ridge Regression\":ridge,\n                   'Lasso Regression':lasso,\"Bayesian Ridge\":bayesian,\n                   'Logistic Regression':LogRegr,'Tweedie Regressor':tweedie,\n                  'SGD Regressor':sgd,\"Passive Aggressive\":passiveaggr,\n                  'SVR':svr,'K Nearest':knearest,'Gaussian Process':gaussian,\n                  'PLS Regression':pls,'Decision Tree':decisiontree,'Random Forest':rdmforest,\n                  'Extra Trees':extratree, 'Ada Boost':adaboost,'Gradient Boosting':gradientboost,\n                  'XGB Regressor':xgb}\n    \n    values_dict = {}\n    for model in models_dict:\n        print(model)\n        values_dict[model] =cross_val_score(models_dict[model],x,y,cv=5,scoring=\"neg_root_mean_squared_error\")\n    \n    return values_dict","af05682e":"def get_cat_columns(df):\n    return [col for col in df.columns if df[col].dtype==\"O\"]","547db676":"# LotFrontage regression\nlinear_frontage = LinearRegression()\ndados = original_df[['LotFrontage','LotArea']].dropna(axis=0)\ndados = dados[dados['LotArea']<30000]\nlinear_frontage.fit(pd.DataFrame(dados.loc[:,'LotArea']),dados.loc[:,'LotFrontage'])\n\n\ndef inputer(df):\n    new_df = df.copy()\n    \n    # MS Zoning\n    new_df['MSZoning'] = new_df['MSZoning'].fillna('RL')\n    \n    # Lot Frontage\n    frontage_predictions = pd.Series(linear_frontage.predict(pd.DataFrame(new_df.loc[:,'LotArea'])))\n    new_df['LotFrontage'] = new_df['LotFrontage'].fillna(frontage_predictions)\n    \n    # Alley\n    new_df['Alley'] = new_df['Alley'].fillna('NoAlley')\n    \n    # Utilities\n    new_df['Utilities'] = new_df['Utilities'].fillna('AllPub')\n    \n    # Exterior1st\n    new_df['Exterior1st'] = new_df['Exterior1st'].fillna('VinylSd')\n    # Exterior2nd\n    new_df['Exterior2nd'] = new_df['Exterior2nd'].fillna('MetalSd')\n    \n    # MasVnrType\n    new_df['MasVnrType'] = new_df['MasVnrType'].fillna('None')\n    # MasVnrArea\n    new_df['MasVnrArea'] = new_df['MasVnrArea'].fillna(0)\n    \n    # BsmtQual\n    new_df['BsmtQual'] = new_df['BsmtQual'].fillna('NoBasement')\n    # BsmtCond\n    new_df['BsmtCond'] = new_df['BsmtCond'].fillna('NoBasement')\n    # BsmtExposure\n    new_df['BsmtExposure'] = new_df['BsmtExposure'].fillna('NoBasement')\n    # BsmtFinType1\n    new_df['BsmtFinType1'] = new_df['BsmtFinType1'].fillna('NoBasement')\n    # BsmtFinSF1\n    new_df['BsmtFinSF1'] = new_df['BsmtFinSF1'].fillna(0)\n    # BsmtFinType2\n    new_df['BsmtFinType2'] = new_df['BsmtFinType2'].fillna('NoBasement')\n    # BsmtFinSF2\n    new_df['BsmtFinSF2'] = new_df['BsmtFinSF2'].fillna(0)\n    # BsmtUnfSF\n    new_df['BsmtUnfSF'] = new_df['BsmtUnfSF'].fillna(0)\n    # TotalBsmtSF\n    new_df['TotalBsmtSF'] = new_df['TotalBsmtSF'].fillna(0)\n    \n    # Electrical\n    new_df['Electrical'] = new_df['Electrical'].fillna('SBrkr')\n    \n    # BsmtFullBath\n    new_df['BsmtFullBath'] = new_df['BsmtFullBath'].fillna(0)\n    # BsmtHalfBath\n    new_df['BsmtHalfBath'] = new_df['BsmtHalfBath'].fillna(0)\n    \n    # KitchenQual\n    new_df['KitchenQual'] = new_df['KitchenQual'].fillna('TA')\n    \n    # Functional\n    new_df['Functional'] = new_df['Functional'].fillna('Typ')\n    \n    # FireplaceQu\n    new_df['FireplaceQu'] = new_df['FireplaceQu'].fillna('NoFireplace')\n     \n    # GarageType\n    new_df['GarageType'] = new_df['GarageType'].fillna('NoGarage')\n    # GarageYrBlt\n    new_df['GarageYrBlt'] = new_df['GarageYrBlt'].fillna(0)\n    # GarageFinish\n    new_df['GarageFinish'] = new_df['GarageFinish'].fillna('NoGarage')\n    # GarageCars\n    new_df['GarageCars'] = new_df['GarageCars'].fillna(0)\n    # GarageArea\n    new_df['GarageArea'] = new_df['GarageArea'].fillna(0)\n    # GarageQual\n    new_df['GarageQual'] = new_df['GarageQual'].fillna('NoGarage')\n    # GarageCond\n    new_df['GarageCond'] = new_df['GarageCond'].fillna('NoGarage')\n    \n    # PoolQC\n    new_df['PoolQC'] = new_df['PoolQC'].fillna('NoPool')\n    # Fence\n    new_df['Fence'] = new_df['Fence'].fillna('NoFence')\n    # MiscFeature\n    new_df['MiscFeature'] = new_df['MiscFeature'].fillna('None')\n    # SaleType\n    new_df['SaleType'] = new_df['SaleType'].fillna('WD')\n    \n    return new_df","fd010aa5":"def create_variables(df):\n    new_df = df.copy()\n    \n    # Frontage\/Area\n    new_df['FrontageRatio'] = new_df['LotFrontage']\/new_df['LotArea']\n    \n    # Quality and Condition\n    new_df['QualCond'] = new_df['OverallQual']*new_df['OverallCond']\n    \n    # Age at Remodel \n    new_df['AgeAtRemodel'] = new_df['YearRemodAdd']-new_df['YearBuilt']\n    # Age of House on Sale\n    new_df['HouseAgeOnSale'] = new_df['YrSold']-new_df['YearBuilt']\n    # Age of House on Sale\n    new_df['RemodelAgeOnSale'] = new_df['YrSold']-new_df['YearRemodAdd']\n    \n    # Total Living Area\n    new_df['TotalSF'] = new_df['GrLivArea'] + new_df['TotalBsmtSF']\n    # Living\/ Lot Area\n    new_df['LivLotRatio'] = new_df['TotalSF']\/new_df['LotArea']\n    # Above Ground Basement Ratio\n    new_df['AbvGrdBsmtRatio'] = new_df['TotalBsmtSF']\/new_df['GrLivArea']\n     \n    # Total Rooms\n    new_df['Total Rooms'] = new_df['TotRmsAbvGrd'] + new_df['FullBath'] + 0.5*new_df['HalfBath'] + new_df['BsmtFullBath'] + 0.5*new_df['BsmtHalfBath']+1\n    # Average Room Area\n    new_df['AvRoomSF'] = new_df['TotalSF']\/new_df['Total Rooms']\n    # Average Room Abv Ground Area\n    new_df['AbvGrdAvRoomSF'] = new_df['GrLivArea']\/(new_df['TotRmsAbvGrd'] + new_df['FullBath'] + 0.5*new_df['HalfBath'])\n    # Average Room Basement Area\n    new_df['BsmtAvRoomSF'] = new_df['TotalBsmtSF']\/(new_df['BsmtFullBath'] + 0.5*new_df['BsmtHalfBath']+1)\n    # Kitchen\/Total Rooms\n    new_df['KitchenRatio'] = new_df['KitchenAbvGr']\/new_df['Total Rooms']\n    # Baths\/Total Rooms\n    new_df['BathsRatio'] = (new_df['FullBath'] + 0.5*new_df['HalfBath'] + new_df['BsmtFullBath'] + 0.5*new_df['BsmtHalfBath'])\/new_df['Total Rooms']\n    # Bedroom\/Total Rooms\n    new_df['BedroomRatio'] = new_df['BedroomAbvGr']\/new_df['Total Rooms']\n    # Fireplaces per Rooms\n    new_df['FireplacesPerRoom'] = new_df['Fireplaces']\/new_df['Total Rooms']\n    \n    # Garage Construction Ratio\n    new_df['GarageLivRatio'] = new_df['GarageArea']\/new_df['TotalSF']\n    # Garage Area\/ Lot Area\n    new_df['GarageLotRatio'] = new_df['GarageArea']\/new_df['LotArea']\n    \n    # Outside Area\n    new_df['OutsideArea'] = new_df['WoodDeckSF']+new_df['OpenPorchSF']+new_df['EnclosedPorch']+new_df['3SsnPorch']+new_df['ScreenPorch']+new_df['PoolArea']\n    # Outside Living Area Ratio\n    new_df['OutsideLivRatio'] = new_df['OutsideArea']\/new_df['TotalSF']\n    # Outside Lot Area Ratio\n    new_df['OutsideLotRatio'] = new_df['OutsideArea']\/new_df['LotArea']\n    \n    # Total Build Area\n    new_df['TotalBuild'] = new_df['GarageArea'] + new_df['TotalSF'] + new_df['OutsideArea']\n    # Build Area Lot Size Ratio\n    new_df['BuildLotRatio'] = new_df['TotalBuild']\/new_df['LotArea']\n\n    return new_df","a25609e5":"# Remove features that doenst help our model\ndef remove_columns(df):\n    new_df = df.copy()\n    columns_to_remove = ['MSSubClass', 'OverallCond', 'BsmtFinSF2', 'LowQualFinSF',\n       'BsmtHalfBath', '3SsnPorch', 'PoolArea', 'MiscVal', 'MoSold',\n       'YrSold', 'LivLotRatio', 'AbvGrdBsmtRatio', 'BuildLotRatio',\n       'MSZoning_RH', 'Street_Pave', 'Alley_Pave', 'LotShape_IR3',\n       'LandContour_Low', 'LandContour_Lvl', 'Utilities_NoSeWa',\n       'LotConfig_FR2', 'LotConfig_FR3', 'LotConfig_Inside',\n       'LandSlope_Mod', 'LandSlope_Sev', 'Neighborhood_Blueste',\n       'Neighborhood_ClearCr', 'Neighborhood_Crawfor',\n       'Neighborhood_Gilbert', 'Neighborhood_Mitchel',\n       'Neighborhood_NPkVill', 'Neighborhood_NWAmes',\n       'Neighborhood_SWISU', 'Neighborhood_SawyerW',\n       'Neighborhood_Veenker', 'Condition1_PosA', 'Condition1_PosN',\n       'Condition1_RRAe', 'Condition1_RRAn', 'Condition1_RRNe',\n       'Condition1_RRNn', 'Condition2_Feedr', 'Condition2_Norm',\n       'Condition2_PosA', 'Condition2_PosN', 'Condition2_RRAe',\n       'Condition2_RRAn', 'Condition2_RRNn', 'BldgType_TwnhsE',\n       'HouseStyle_1Story', 'HouseStyle_2.5Fin', 'HouseStyle_2.5Unf',\n       'HouseStyle_SFoyer', 'HouseStyle_SLvl', 'RoofStyle_Gambrel',\n       'RoofStyle_Mansard', 'RoofStyle_Shed', 'RoofMatl_CompShg',\n       'RoofMatl_Membran', 'RoofMatl_Metal', 'RoofMatl_Roll',\n       'RoofMatl_Tar&Grv', 'RoofMatl_WdShake', 'Exterior1st_AsphShn',\n       'Exterior1st_BrkComm', 'Exterior1st_BrkFace', 'Exterior1st_CBlock',\n       'Exterior1st_CemntBd', 'Exterior1st_HdBoard',\n       'Exterior1st_ImStucc', 'Exterior1st_Plywood', 'Exterior1st_Stone',\n       'Exterior1st_Stucco', 'Exterior1st_WdShing', 'Exterior2nd_AsphShn',\n       'Exterior2nd_Brk Cmn', 'Exterior2nd_BrkFace', 'Exterior2nd_CBlock',\n       'Exterior2nd_CmentBd', 'Exterior2nd_HdBoard',\n       'Exterior2nd_ImStucc', 'Exterior2nd_Other', 'Exterior2nd_Plywood',\n       'Exterior2nd_Stone', 'Exterior2nd_Stucco', 'Exterior2nd_Wd Shng',\n       'ExterCond_Gd', 'ExterCond_Po', 'Foundation_Stone',\n       'Foundation_Wood', 'BsmtCond_Po', 'BsmtExposure_Mn',\n       'BsmtFinType1_LwQ', 'BsmtFinType1_Unf', 'BsmtFinType2_BLQ',\n       'BsmtFinType2_GLQ', 'BsmtFinType2_LwQ', 'BsmtFinType2_Rec',\n       'Heating_GasW', 'Heating_OthW', 'Heating_Wall', 'HeatingQC_Po',\n       'Electrical_FuseP', 'Electrical_Mix', 'Functional_Min1',\n       'Functional_Min2', 'Functional_Mod', 'Functional_Sev',\n       'FireplaceQu_Fa', 'FireplaceQu_Po', 'GarageType_Basment',\n       'GarageType_CarPort', 'GarageQual_Gd', 'GarageQual_Po',\n       'GarageCond_Gd', 'GarageCond_Po', 'PavedDrive_P', 'PoolQC_Fa',\n       'PoolQC_Gd', 'PoolQC_NoPool', 'Fence_MnWw', 'MiscFeature_None',\n       'MiscFeature_Othr', 'MiscFeature_Shed', 'MiscFeature_TenC',\n       'SaleType_CWD', 'SaleType_Con', 'SaleType_ConLD', 'SaleType_ConLI',\n       'SaleType_ConLw', 'SaleType_Oth', 'SaleCondition_AdjLand',\n       'SaleCondition_Alloca', 'SaleCondition_Family']\n    new_df.drop(columns=columns_to_remove, inplace=True)\n    \n    return new_df","9b7ffc44":"# Normalize features distributions\ndef normalize_distributions(df,transformation='transform'):\n    new_df = df.copy()\n    log_columns = ['TotalBuild','LotFrontage','FrontageRatio','TotalSF','LivLotRatio','AbvGrdAvRoomSF','GarageLivRatio','GarageLotRatio','OutsideLivRatio','OutsideLotRatio','BuildLotRatio']\n    \n    if transformation=='transform':\n        for column in log_columns:\n            new_df[column] = np.log(new_df[column]+1)\n    else:\n        for column in log_columns:\n            new_df[column] = np.exp(new_df[column])-1\n    \n    return new_df","b7e74b07":"# Teste 1 - Removing Missing values and getting dummies\ndef preparing_data1(df):\n    new_df = df.copy()\n    new_df.dropna(axis=1, inplace=True)\n    categorical_col = get_cat_columns(new_df)\n    new_df = pd.concat([new_df,pd.get_dummies(new_df[categorical_col],drop_first=True)],axis=1).drop(columns=categorical_col)\n    new_df.drop(columns=['Id'],inplace=True)\n    return new_df\n\nmod_df = preparing_data1(original_df)\nx = mod_df.drop(columns=['SalePrice'])\ny = mod_df['SalePrice']\n\n#scores1 = model_test(x,y)\n#df1 = pd.DataFrame(scores1).unstack().reset_index().rename(columns={'level_0': 'Model', 'level_1': 'Test',0:'RMSE'}).reindex(columns=['Test','Model','RMSE'])\n#df1['Test'] = 'Test1'","618543e9":"# Teste 2 - Removing Missing values and StandardScaler\ndef preparing_data2(df):\n    new_df = df.copy()\n    new_df.dropna(axis=1, inplace=True)\n    categorical_col = get_cat_columns(new_df)\n    new_df = pd.concat([new_df,pd.get_dummies(new_df[categorical_col],drop_first=True)],axis=1).drop(columns=categorical_col)\n    new_df.drop(columns=['Id'],inplace=True)\n    return new_df\n\nmod_df = preparing_data2(original_df)\nx = mod_df.drop(columns=['SalePrice'])\nscaler = StandardScaler()\nx = pd.DataFrame(scaler.fit_transform(x),columns=x.columns)\ny = mod_df['SalePrice']\n\n#scores2 = model_test(x,y)\n#df2 = pd.DataFrame(scores2).unstack().reset_index().rename(columns={'level_0': 'Model', 'level_1': 'Test',0:'RMSE'}).reindex(columns=['Test','Model','RMSE'])\n#df2['Test'] = 'Test2'","08036427":"# Teste 3 - Inputing missing values\ndef preparing_data3(df):\n    new_df = df.copy()\n    new_df = inputer(new_df)\n    categorical_col = get_cat_columns(new_df)\n    new_df = pd.concat([new_df,pd.get_dummies(new_df[categorical_col],drop_first=True)],axis=1).drop(columns=categorical_col)\n    new_df.drop(columns=['Id'],inplace=True)\n    return new_df\n\nmod_df = preparing_data3(original_df)\nx = mod_df.drop(columns=['SalePrice'])\ny = mod_df['SalePrice']\n\n#scores3 = model_test(x,y)\n#df3 = pd.DataFrame(scores3).unstack().reset_index().rename(columns={'level_0': 'Model', 'level_1': 'Test',0:'RMSE'}).reindex(columns=['Test','Model','RMSE'])\n#df3['Test'] = 'Test3'","7c749486":"# Teste 4 - Inputing missing values and StandardScaler\ndef preparing_data4(df):\n    new_df = df.copy()\n    new_df = inputer(new_df)\n    categorical_col = get_cat_columns(new_df)\n    new_df = pd.concat([new_df,pd.get_dummies(new_df[categorical_col],drop_first=True)],axis=1).drop(columns=categorical_col)\n    new_df.drop(columns=['Id'],inplace=True)\n    return new_df\n\n#mod_df = preparing_data4(original_df)\n#x = mod_df.drop(columns=['SalePrice'])\n#scaler = StandardScaler()\n#x = pd.DataFrame(scaler.fit_transform(x),columns=x.columns)\n#y = mod_df['SalePrice']\n\n#scores4 = model_test(x,y)\n#df4 = pd.DataFrame(scores4).unstack().reset_index().rename(columns={'level_0': 'Model', 'level_1': 'Test',0:'RMSE'}).reindex(columns=['Test','Model','RMSE'])\n#df4['Test'] = 'Test4'","c2786e49":"# Teste 5 - Inputing missing values and new variables\ndef preparing_data5(df):\n    new_df = df.copy()\n    new_df = inputer(new_df)\n    new_df = create_variables(new_df)\n    categorical_col = get_cat_columns(new_df)\n    new_df = pd.concat([new_df,pd.get_dummies(new_df[categorical_col],drop_first=True)],axis=1).drop(columns=categorical_col)\n    new_df.drop(columns=['Id'],inplace=True)\n    return new_df\n\n#mod_df = preparing_data5(original_df)\n#x = mod_df.drop(columns=['SalePrice'])\n#y = mod_df['SalePrice']\n\n#scores5 = model_test(x,y)\n#df5 = pd.DataFrame(scores5).unstack().reset_index().rename(columns={'level_0': 'Model', 'level_1': 'Test',0:'RMSE'}).reindex(columns=['Test','Model','RMSE'])\n#df5['Test'] = 'Test5'","0170d48b":"# Teste 6 - Inputing missing values, new variables and scaling\ndef preparing_data6(df):\n    new_df = df.copy()\n    new_df = inputer(new_df)\n    new_df = create_variables(new_df)\n    categorical_col = get_cat_columns(new_df)\n    new_df = pd.concat([new_df,pd.get_dummies(new_df[categorical_col],drop_first=True)],axis=1).drop(columns=categorical_col)\n    new_df.drop(columns=['Id'],inplace=True)\n    return new_df\n\n#mod_df = preparing_data6(original_df)\n#x = mod_df.drop(columns=['SalePrice'])\n#scaler = StandardScaler()\n#x = pd.DataFrame(scaler.fit_transform(x),columns=x.columns)\n#y = mod_df['SalePrice']\n\n#scores6 = model_test(x,y)\n#df6 = pd.DataFrame(scores6).unstack().reset_index().rename(columns={'level_0': 'Model', 'level_1': 'Test',0:'RMSE'}).reindex(columns=['Test','Model','RMSE'])\n#df6['Test'] = 'Test6'","054508bd":"#all_df = pd.concat([df1,df2,df3,df4,df5,df6],axis=0)","c7a0da03":"#all_df.groupby(['Test','Model'])['RMSE'].mean().reset_index().sort_values(by='RMSE',ascending=False).head(50)","f2a47e59":"#from sklearn.model_selection import GridSearchCV\n\n#grid = {'learning_rate':[0.001,0.01,0.1,0.5,1],\n#       'n_estimators':[50,100,1000,5000]}\n\n#mod_df = preparing_data6(original_df)\n#x = mod_df.drop(columns=['SalePrice'])\n#scaler = StandardScaler()\n#x = pd.DataFrame(scaler.fit_transform(x),columns=x.columns)\n#y = mod_df['SalePrice']\n\n#gradientboost = GradientBoostingRegressor()\n\n#clf = GridSearchCV(gradientboost, grid, scoring='neg_root_mean_squared_error',cv=2,verbose=1)\n#clf.fit(x, y)","086f7791":"#clf.best_params_","3903db1e":"def preparing_data_final(df):\n    new_df = df.copy()\n    new_df = inputer(new_df)\n    new_df = create_variables(new_df)\n    new_df = normalize_distributions(new_df)\n    categorical_col = get_cat_columns(new_df)\n    new_df = pd.concat([new_df,pd.get_dummies(new_df[categorical_col],drop_first=True)],axis=1).drop(columns=categorical_col)\n    new_df = remove_columns(new_df)\n    return new_df\n\n\nall_df_mod = preparing_data_final(total_df)\nmod_df = all_df_mod[all_df_mod['Id'].isin(original_df['Id'])]\nmod_df.drop(columns=['Id'],inplace=True)\nx = mod_df.drop(columns=['SalePrice'])\nscaler = StandardScaler()\nx = pd.DataFrame(scaler.fit_transform(x),columns=x.columns)\ny = mod_df['SalePrice']\n\ngradientboost = GradientBoostingRegressor(n_estimators=5000, learning_rate=0.01, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)\ngradientboost.fit(x,y)\n\ntest_df_mod = all_df_mod[all_df_mod['Id'].isin(test_df['Id'])]\ntest_df_mod.drop(columns=['Id','SalePrice'],inplace=True)\nx_test = pd.DataFrame(scaler.transform(test_df_mod),columns=test_df_mod.columns)\n\npredictions = pd.DataFrame(gradientboost.predict(x_test),columns=['SalePrice'])\nsubmission = pd.concat([test_df['Id'],predictions],axis=1).set_index('Id')\nsubmission.to_csv('submission.csv')","fad1a0a5":"corr_matrix = all_df_mod.corr().unstack().reset_index()\ncorr_matrix = corr_matrix[corr_matrix['level_0']!=corr_matrix['level_1']]\ncorr_matrix[0] = abs(corr_matrix[0])","2f13f52f":"corr_matrix[corr_matrix['level_0']=='SalePrice'].sort_values(by=0)","838bce31":"# **Testes que ser\u00e3o realizados**\n\n1. Remover todos NaN - Categoricos com dummies\n2. Remover todos NaN - Categoricos com dummies - Escalar Valores\n3. Inputar valores NaN - Categoricos com dummies\n4. Inputar valores NaN - Categoricos com dummies - Escalar Valores\n5. Inputar valores NaN - Categoricos com dummies - Criar Vari\u00e1veis\n6. Inputar valores NaN - Categoricos com dummies - Criar Vari\u00e1veis - Escalar valores\n7. Inputar valores NaN - Categoricos com dummies - Criar Vari\u00e1veis - Remover vari\u00e1veis colineares\n8. Inputar valores NaN - Categoricos com dummies - Criar Vari\u00e1veis - Remover vari\u00e1veis colineares - escalar valores\n9. Inputar valores NaN - Categoricos com dummies - Criar Vari\u00e1veis - Remover vari\u00e1veis colineares - Remover vari\u00e1veis com baixa correlacao - escalar valores\n10. Inputar valores NaN - Categoricos com dummies - Criar Vari\u00e1veis - Remover vari\u00e1veis colineares - Remover vari\u00e1veis com baixa correlacao - Normalizar distribui\u00e7\u00e3o - escalar valores"}}