{"cell_type":{"7f24f88b":"code","c4879f39":"code","e3ee6b50":"code","7b6b151e":"code","e25b92a3":"code","90c0f096":"code","6e5c1b56":"code","c82a6594":"markdown","46e79948":"markdown","f8d2133e":"markdown","010fb366":"markdown","0d3c3a54":"markdown","716fe07a":"markdown"},"source":{"7f24f88b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4879f39":"from google.cloud import bigquery\n\nclient = bigquery.Client()\n\ndataset_reference = client.dataset(\"hacker_news\", project = \"bigquery-public-data\")\n\ndataset = client.get_dataset(dataset_reference)\n\ncomment_reference = dataset_reference.table(\"comments\")\n\ncomment = client.get_table(comment_reference)\n\nclient.list_rows(comment, max_results=5).to_dataframe()","e3ee6b50":"stories_reference = dataset_reference.table(\"stories\")\n\nstories = client.get_table(stories_reference)\n\nclient.list_rows(stories, max_results=5).to_dataframe()","7b6b151e":"# Query to select all stories posted on January 1, 2012, with number of comments\njoin_query = \"\"\"\n             WITH c AS (\n             SELECT parent, COUNT(*) AS number_of_comments\n             FROM `bigquery-public-data.hacker_news.comments`\n             GROUP BY parent\n             )\n             SELECT s.id AS story_id, s.by, s.title, c.number_of_comments\n             FROM `bigquery-public-data.hacker_news.stories` AS s\n             LEFT JOIN c\n             ON s.id = c.parent\n             WHERE EXTRACT (DATE FROM s.time_ts) = '2012-01-01'\n             ORDER BY c.number_of_comments DESC\n             \"\"\"\n\n# Run the query, and return a pandas DataFrame\njoin_result = client.query(join_query).result().to_dataframe()\njoin_result.head()","e25b92a3":"join_result.tail()","90c0f096":"# Query to select all users who posted stories or comments on January 1, 2014\nunion_query = \"\"\"\n              SELECT s.by\n              FROM `bigquery-public-data.hacker_news.stories` AS s\n              WHERE EXTRACT(DATE FROM s.time_ts) = '2014-01-01'\n              UNION DISTINCT\n              SELECT c.by\n              FROM `bigquery-public-data.hacker_news.comments` AS c\n              WHERE EXTRACT(DATE FROM c.time_ts) = '2014-01-01'\n              \"\"\"\n\n# Run the query, and return a pandas DataFrame\nunion_result = client.query(union_query).result().to_dataframe()\nunion_result.head()","6e5c1b56":"len(union_result)","c82a6594":"## SQL Practice 1\nJust some code to learn using SQL integrated within the Kaggle environment.\n\nWe will be working on a more expanded version of the **inner join** with functions such as **outer joins**, **left joins**, **right joins**, as well as different types of **unions**.\n\nAs always, first we need to set up our environment so that we are able to run python code that will create a client that connects to the Google BigQuery servers that will let us work with the data sets and tables. We will be working with a public dataset that has information regarding *Hacker News*!","46e79948":"Next, let's get some more practice with `UNIONS`, we will try to write a query to select all usernames corresponding to users who wrote stories or comments on January 1, 2014. We use **UNION DISTINCT** (instead of **UNION ALL**) to ensure that each user appears in the table at most once.","f8d2133e":"Now let's explore some of the *joins* more in depth. Keep in mind that `parent` in the comments table corresponds to `id` from the stories tables (since comments are under stories within the hierarchical structure).","010fb366":"Queries like this that incorporate the `UNION` function can allow us to give estimates of how many *distinct* stories and comments that were written by users during specific time frames. As an example, we can use the `len()` function to do this!","0d3c3a54":"Since we did a **left join** we should also get *null* values for anything from the comments table. We can check the results of our query's tale to get a preview of this (or run the query in ascending order).","716fe07a":"Now that we have a table for **comments** in the `hacker_news` data set, we can create another table reference for the `stories` table from the same data set reference!"}}