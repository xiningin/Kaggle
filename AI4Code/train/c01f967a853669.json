{"cell_type":{"4cf76915":"code","25e00b85":"code","a63b7999":"code","699a705f":"code","7be65be1":"code","b745cfec":"code","3c8f1780":"code","2d49a7eb":"code","ad1b33f9":"code","f8c57604":"code","a3cb2cc0":"code","cea0d33a":"code","1318e75a":"code","6746dd60":"code","9756a022":"code","f2d22b5b":"code","6e39d2f7":"code","809e199e":"code","33e38d2d":"code","cb22e283":"code","667baaee":"code","b3a7a4a9":"code","3108db01":"code","1c9e0b4c":"code","12f675a3":"code","92a9654b":"markdown","cd6e465d":"markdown","9b925aa0":"markdown","d67a00ba":"markdown","a9604d15":"markdown","99804b77":"markdown","7f03b702":"markdown","aa5f7140":"markdown","5e6729fe":"markdown","c285f248":"markdown","7ca805d3":"markdown","7f5a1df3":"markdown"},"source":{"4cf76915":"import warnings\nwarnings.filterwarnings('ignore')","25e00b85":"import os\nfrom tqdm import tqdm\n\nimport nibabel as nib\nimport SimpleITK as sitk\n\nfrom fastai.medical.imaging import *\nfrom fastai.vision.all import *","a63b7999":"path_train =  Path('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train')","699a705f":"path_train_t2w,path_train_t1wce,path_train_t1w,path_train_flair = [],[],[],[]\nfor each in path_train.ls():\n    path_train_t2w.append(each.ls()[0])\n    path_train_t1wce.append(each.ls()[1])\n    path_train_t1w.append(each.ls()[2])\n    path_train_flair.append(each.ls()[3])","7be65be1":"def get_array(fn):\n    \"opens .nii file and return the array\"\n    img = sitk.ReadImage(str(fn))\n    imgd = sitk.GetArrayFromImage(img)\n    return imgd\n\ndef plot_slice(imgd, sli):\n    \"given an image of shape slices x height x width, plots a slice\"\n    plt.imshow(imgd[sli], cmap='gray')\n    plt.axis('off')","b745cfec":"def dicom2nifti(image_dir, save=True):\n    \"given a dicom directory, loads them into single file and can save it as .nii file\"\n    reader = sitk.ImageSeriesReader()\n    reader.LoadPrivateTagsOn()\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(str(image_dir))\n    reader.SetFileNames(filenamesDICOM)\n    img = reader.Execute()\n    img = sitk.Cast(img, sitk.sitkFloat32)\n    \n    if save:\n        sitk.WriteImage(img, f'\/kaggle\/working\/T2w\/{image_dir.parent.name}.nii')\n    else:\n        return img","3c8f1780":"def resample_nifti(image_dir, ref_image, fn, save=True):\n    \"resample using a reference image\"\n\n    image = dicom2nifti(image_dir, save=False)\n    \n    initial_transform = sitk.CenteredTransformInitializer(ref_image, \n                                                          image, \n                                                          sitk.Euler3DTransform(), \n                                                          sitk.CenteredTransformInitializerFilter.GEOMETRY)\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetReferenceImage(ref_image)\n    resampler.SetInterpolator(sitk.sitkLinear)\n    resampler.SetTransform(initial_transform)\n    resampler.SetOutputSpacing(ref_image.GetSpacing())\n    resampler.SetSize((ref_image.GetSize()))\n    resampler.SetOutputDirection(ref_image.GetDirection())\n    resampler.SetOutputOrigin(ref_image.GetOrigin())\n    resampler.SetDefaultPixelValue(image.GetPixelIDValue())\n    resamped_image = resampler.Execute(image)\n    \n    if save:\n        sitk.WriteImage(resamped_image, fn)\n\n    return resamped_image","2d49a7eb":"#code from simpleitk examples\ndef threshold_based_crop_and_bg_median(image):\n    '''\n    Use Otsu's threshold estimator to separate background and foreground. In medical imaging the background is\n    usually air. Then crop the image using the foreground's axis aligned bounding box and compute the background \n    median intensity.\n    Args:\n        image (SimpleITK image): An image where the anatomy and background intensities form a bi-modal distribution\n                                 (the assumption underlying Otsu's method.)\n    Return:\n        Cropped image based on foreground's axis aligned bounding box.\n        Background median intensity value.\n    '''\n    # Set pixels that are in [min_intensity,otsu_threshold] to inside_value, values above otsu_threshold are\n    # set to outside_value. The anatomy has higher intensity values than the background, so it is outside.\n    inside_value = 0\n    outside_value = 255\n    bin_image = sitk.OtsuThreshold(image, inside_value, outside_value)\n\n    # Get the median background intensity\n    label_intensity_stats_filter = sitk.LabelIntensityStatisticsImageFilter()\n    label_intensity_stats_filter.SetBackgroundValue(outside_value)\n    label_intensity_stats_filter.Execute(bin_image,image)\n    bg_median = label_intensity_stats_filter.GetMedian(inside_value)\n    \n    # Get the bounding box of the anatomy\n    label_shape_filter = sitk.LabelShapeStatisticsImageFilter()    \n    label_shape_filter.Execute(bin_image)\n    bounding_box = label_shape_filter.GetBoundingBox(outside_value)\n    # The bounding box's first \"dim\" entries are the starting index and last \"dim\" entries the size\n    return bg_median, sitk.RegionOfInterest(image, bounding_box[int(len(bounding_box)\/2):], bounding_box[0:int(len(bounding_box)\/2)])","ad1b33f9":"samp = path_train_t2w[0]","f8c57604":"samp_img = dicom2nifti(samp, False)\nsamp_imgd = sitk.GetArrayFromImage(samp_img)","a3cb2cc0":"samp_imgd.shape","cea0d33a":"plot_slice(samp_imgd, 100)","1318e75a":"ref_image = sitk.ReadImage(\"..\/input\/sri24-dataset\/sri24\/late.nii\", sitk.sitkFloat32)","6746dd60":"samp_resamp = resample_nifti(samp, ref_image, \"\", False)\nsamp_resampd = sitk.GetArrayFromImage(samp_resamp)","9756a022":"sitk.GetArrayFromImage(ref_image).shape, samp_resampd.shape","f2d22b5b":"plot_slice(samp_resampd, 98)","6e39d2f7":"_,samp_resamp_cropped = threshold_based_crop_and_bg_median(samp_resamp)\nsamp_resamp_croppedd = sitk.GetArrayFromImage(samp_resamp_cropped)","809e199e":"samp_resamp_croppedd.shape","33e38d2d":"plot_slice(samp_resamp_croppedd, 80)","cb22e283":"plot_slice(samp_resampd, 0)","667baaee":"plot_slice(samp_resamp_croppedd, 0)","b3a7a4a9":"!mkdir t2w_preproc_v2","3108db01":"ref_image = sitk.ReadImage('..\/input\/sri24-dataset\/sri24\/spgr.nii', sitk.sitkFloat32)","1c9e0b4c":"for fn in tqdm(path_train_t2w, total=len(path_train_t2w)):\n    pat_id = str(fn).split('\/')[-2]\n    final_fn = f\"\/kaggle\/working\/t2w_preproc_v2\/{pat_id}.nii.gz\"\n    resample_nifti(fn, ref_image, final_fn, True)\n","12f675a3":"from zipfile import ZipFile\nimport os\nimport shutil\n\n\n# iterate over all the files in directory\nfor folderName, subfolders, filenames in os.walk(f'\/kaggle\/working\/t2w_preproc_v2'):\n    # create a ZipFile object\n    #print(folderName)\n    with ZipFile(folderName.split('\/')[-1] + '.zip', 'w') as zipObj:\n        for filename in filenames:\n            # create complete filepath of file in directory\n            filePath = os.path.join(folderName, filename)\n            # add file to zip\n            zipObj.write(filePath, os.path.basename(filePath))\n            # delete the file to open space\n            os.remove(filePath)\nshutil.rmtree(f\"\/kaggle\/working\/t2w_preproc_v2\")\n","92a9654b":"We have reshaped the samp images to the same dimensions as the reference image","cd6e465d":"# Imports and paths","9b925aa0":"# Resample all T2w images","d67a00ba":"In this notebook, we will convert the dicom files into nifti format. Also, we will use the SRI24 dataset to resample the images to a consistent orientation. This is, within the same modality - say T2w, the sequene for different patient appear in different orientation (axial, sagittal etc). We will use the SRI24 axial image as the referece image to resample our data.","a9604d15":"# Let's see what we are talking about ","99804b77":"And we have resampled to the axial view! ","7f03b702":"# Now lets resample using a SIR24 as referece image","aa5f7140":"Let's open one and see how it looks like","5e6729fe":"We can also crop them to the region of interest","c285f248":"# Functions","7ca805d3":"As you can see the first few slices have no region of interest. By cropping to the ROI, we remove the not useful slices. ","7f5a1df3":"The following notebooks\/tutorial were of great help.\n\n1. https:\/\/www.kaggle.com\/boojum\/connecting-voxel-spaces\/\n2. https:\/\/simpleitk.readthedocs.io\/en\/master\/link_examples.html"}}