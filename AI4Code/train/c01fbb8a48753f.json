{"cell_type":{"5432322d":"code","af4b9087":"code","93e33624":"code","88f00727":"code","dd42001d":"code","59a77a3d":"code","795f393f":"code","87b1968d":"code","a8329864":"code","908ed006":"code","8de54a3b":"code","f4ab8091":"code","c168b019":"code","585cf041":"code","fb857c33":"code","203ecddf":"code","75174d3b":"code","6770689f":"code","969be41e":"code","b5615c64":"code","e6a06c03":"code","81bf7c1a":"code","12686567":"code","51908ea8":"code","4912f870":"code","68433307":"code","a64a284e":"code","dc5c49f3":"code","35726d9a":"code","7bd02125":"code","ddb4fb29":"code","4909d26a":"code","f11dc04e":"code","ad9b411b":"code","de2e9355":"code","0365f9db":"code","aac30b17":"code","6c0f6dfe":"code","02884f13":"code","2222e35a":"code","df5e1f84":"code","4382c723":"code","114c2293":"code","2b5abf25":"code","a254ac9e":"code","4739ed8c":"code","1c7a5f47":"code","314077a1":"code","ca72452e":"code","a867059c":"code","a2b81ca1":"code","4c7d1fa0":"code","dff574dd":"code","b4671e1b":"code","4f6d94f8":"code","e62c0bef":"code","543af98b":"code","3f909aba":"markdown","76f91176":"markdown","d904ff7e":"markdown","1da05c04":"markdown","32b23eba":"markdown","d41c1619":"markdown","e108b8d7":"markdown","2f23564b":"markdown","63eb2327":"markdown","cbe1f587":"markdown","9c833c14":"markdown","88ae670e":"markdown","cb075a52":"markdown","60b8b7ef":"markdown","d99c3b14":"markdown","6466907e":"markdown","76085d14":"markdown","877dab85":"markdown","8099b462":"markdown","579778d9":"markdown","a9fe90d0":"markdown","82d15212":"markdown","c81cd3c4":"markdown","9a16754a":"markdown"},"source":{"5432322d":"import numpy as np # Linear algebra\n\n# Plotting libraries.\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport unicodedata\nimport re\n\n# Machine learning algorithms.\nfrom collections import Counter\n\nimport lightgbm as lgb\n\nimport xgboost as xgb\nfrom sklearn import metrics\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 10","af4b9087":"# Read train and test dataset\n\ntrain_df = pd.read_excel(\"..\/input\/Final_Train.xlsx\")\ntest_df = pd.read_excel(\"..\/input\/Final_Test.xlsx\")\ndf_test = test_df.copy()","93e33624":"train_df.head()","88f00727":"test_df.head()","dd42001d":"# Check shape of dataset\n\ntrain_df.shape, test_df.shape","59a77a3d":"# check train column types\n\nctype = train_df.dtypes.reset_index()\nctype.columns = [\"Count\", \"Column Type\"]\nctype.groupby(\"Column Type\").aggregate('count').reset_index()","795f393f":"# check test column types\n\nctype = test_df.dtypes.reset_index()\nctype.columns = [\"Count\", \"Column Type\"]\nctype.groupby(\"Column Type\").aggregate('count').reset_index()","87b1968d":"# Check the Maximum and Minimum number of qualifications\n\n# Train set\ndat_train = train_df.Qualification.apply(lambda x: len(x.split(',')))\nprint(\"Maximum qualifications of a doctor in the Train dataset is {}\\n\".format(dat_train.max()))\nprint(\"And the qualifications is --> {}\\n\\n\".format(train_df.Qualification[dat_train.idxmax()]))\nprint(\"Minimum qualification of a doctor in the Train dataset is {}\\n\".format(dat_train.min()))\nprint(\"And the qualifications is --> {}\\n\\n\".format(train_df.Qualification[dat_train.idxmin()]))\n\n# Test set\ndat_test = test_df.Qualification.apply(lambda x: len(x.split(',')))\nprint(\"Maximum qualifications of a doctor in the Test dataset is {}\\n\".format(dat_test.max()))\nprint(\"And the qualifications is --> {}\\n\\n\".format(test_df.Qualification[dat_test.idxmax()]))\nprint(\"Minimum qualification of a doctor in the Test dataset is {}\\n\".format(dat_test.min()))\nprint(\"And the qualifications is --> {}\".format(test_df.Qualification[dat_test.idxmin()]))","a8329864":"sorted(test_df.Qualification[test_df.Qualification.apply(lambda x: len(x.split(','))).idxmax()].split(\",\"))","908ed006":"# Define function to remove inconsistencies in the data\ndef sortQual(text):\n    arr = re.sub(r'\\([^()]+\\)', lambda x: x.group().replace(\",\",\"-\"), text) # to replace ',' with '-' inside brackets only\n    return ','.join(sorted(arr.lower().replace(\" \",\"\").split(\",\")))","8de54a3b":"# Apply the function on the Qualification set\n\n# Train Set\ntrain_df.Qualification = train_df.Qualification.apply(lambda x: sortQual(x))\n\n# Test Set\ntest_df.Qualification = test_df.Qualification.apply(lambda x: sortQual(x))","f4ab8091":"# Define a function to create a doc of all Qualifications seprataed by ','\n\ndef doc(series):\n    Quals = ''\n    for i in series:\n        Quals += i + ','\n    return Quals","c168b019":"# List of top 10 unique Qualifications along with there occurence in Train Set\n\ntext = doc(train_df.Qualification)\ndf = pd.DataFrame.from_dict(dict(Counter(text.split(',')).most_common()), orient='index').reset_index()\ndf.columns=['Qualification','Count']\ndf.head(10)","585cf041":"# List of top 10 unique Qualifications along with there occurence in Test Set\n\ntext = doc(test_df.Qualification)\ndf = pd.DataFrame.from_dict(dict(Counter(text.split(',')).most_common()), orient='index').reset_index()\ndf.columns=['Qualification','Count']\ndf.head(10)","fb857c33":"text = doc(test_df.Qualification)\ndf = pd.DataFrame.from_dict(dict(Counter(text.split(',')).most_common()), orient='index').reset_index()\ndf.columns=['Qualification','Count']\ndf['code'] = df.Qualification.astype('category').cat.codes\ndf.head(10)","203ecddf":"qual_dict = dict(zip(df.Qualification, df.code))","75174d3b":"def qual_col(dataframe, col, col_num):\n    return dataframe[col].str.split(',').str[col_num]","6770689f":"# for training set\nfor i in range(0,dat_train.max()):\n    qual = \"Qual_\"+ str(i+1)\n    train_df[qual] = qual_col(train_df,'Qualification', i)\n\n    \n# for test set\nfor i in range(0,dat_test.max()):\n    qual = \"Qual_\"+ str(i+1)\n    test_df[qual] = qual_col(test_df,'Qualification', i)\n","969be41e":"train_df.head()","b5615c64":"# Train set\ntrain_df['years_exp'] = train_df['Experience'].str.slice(stop=2).astype(int)\n\n# Test set\ntest_df['years_exp'] = test_df['Experience'].str.slice(stop=2).astype(int)","e6a06c03":"train_df.head()","81bf7c1a":"# Train set\ntrain_df['Rating'].fillna('0%',inplace = True)\ntrain_df['Rating'] = train_df['Rating'].str.slice(stop=-1).astype(int)\n\n# Test set\ntest_df['Rating'].fillna('0%',inplace = True)\ntest_df['Rating'] = test_df['Rating'].str.slice(stop=-1).astype(int)","12686567":"train_df.head()","51908ea8":"# Train Set\ntrain_df['City'] = train_df['Place'].str.split(',').str[1]\ntrain_df['Locality'] = train_df['Place'].str.split(',').str[0]\n\n\n# Test Set\ntest_df['City'] = test_df['Place'].str.split(',').str[1]\ntest_df['Locality'] = test_df['Place'].str.split(',').str[0]","4912f870":"train_df.head()","68433307":"list(train_df.Miscellaneous_Info[0:10])","a64a284e":"# Train set\ntrain_df.Miscellaneous_Info = train_df.Miscellaneous_Info.str.replace(unicodedata.lookup('Indian Rupee Sign'), 'INR ')\n\n# Test set\ntest_df.Miscellaneous_Info = test_df.Miscellaneous_Info.str.replace(unicodedata.lookup('Indian Rupee Sign'), 'INR ')","dc5c49f3":"list(train_df.Miscellaneous_Info[0:10])","35726d9a":"# Define function to return the Feedback numbers\n\ndef find_feedback(data):\n    result = re.search(r' (.*?) Feedback',data)\n    if result:\n        return int(result.group(1))\n    else:\n        return 0","7bd02125":"# Fetch out the feedback numbers in different records. \n\n# Train set\ntrain_df['feedack_num'] = train_df.Miscellaneous_Info.apply(lambda x: find_feedback(x) if '%' in str(x) else 0)\n\n# Test set\ntest_df['feedack_num'] = test_df.Miscellaneous_Info.apply(lambda x: find_feedback(x) if '%' in str(x) else 0)","ddb4fb29":"train_df.head()","4909d26a":"# Let us have a look at the different Fee value in the records.\n\nlist(train_df.Miscellaneous_Info[train_df.Miscellaneous_Info.str.contains('INR', na = False)].sample(10))","f11dc04e":"# Define function to return the Fees Value\n\ndef find_fees(data):\n    result = re.search(r'INR (\\d*)',data)\n    if result:\n        return int(result.group(1))\n    else:\n        return 0\n","ad9b411b":"# Fetch out the Fees value in different records. \n\n# Train set\ntrain_df['fees_val'] = train_df.Miscellaneous_Info.apply(lambda x: find_fees(x) if 'INR' in str(x) else 0)\n\n# Test set\ntest_df['fees_val'] = test_df.Miscellaneous_Info.apply(lambda x: find_fees(x) if 'INR' in str(x) else 0)","de2e9355":"train_df.head()","0365f9db":"# Select Qualification categorical columns to be encoded\n\ncolumn_test = ['Qual_1', 'Qual_2', 'Qual_3', 'Qual_4',\n           'Qual_5', 'Qual_6', 'Qual_7', 'Qual_8', 'Qual_9', 'Qual_10', 'Qual_11',\n           'Qual_12', 'Qual_13', 'Qual_14', 'Qual_15', 'Qual_16', 'Qual_17']\n\ncolumn_train = ['Qual_1', 'Qual_2', 'Qual_3', 'Qual_4',\n           'Qual_5', 'Qual_6', 'Qual_7', 'Qual_8', 'Qual_9', 'Qual_10']","aac30b17":"# Encode categorical columns for Test and Train set\n\nfor i in column_train:\n    train_df.replace({i: qual_dict}, inplace=True)\n    \n    \nfor i in column_test:\n    test_df.replace({i: qual_dict}, inplace=True)","6c0f6dfe":"train_df.head()","02884f13":"test_df.head()","2222e35a":"# Define function to label encode the selected categorical variable for modeling\n\ndef encode(data):\n    return data.astype('category').cat.codes","df5e1f84":"# Encode categorical column of test data\n\ncolumns = ['Profile','City','Locality']\n\nfor i in columns:\n    col = i+\"_code\"\n    test_df[col] = encode(test_df[i])","4382c723":"test_df.head()","114c2293":"# Create unique lists of [variable, variable code] combination and drop duplicate pairs.\n\ndf_test_merge_1 = test_df[['Profile','Profile_code']].drop_duplicates()\ndf_test_merge_2 = test_df[['City','City_code']].drop_duplicates()\ndf_test_merge_3 = test_df[['Locality','Locality_code']].drop_duplicates()","2b5abf25":"# Pull the respective encoded variables list in the train data (Using a left join) to avoid any merging issue.\n\ntrain_df = pd.merge(train_df,df_test_merge_1[['Profile','Profile_code']],on='Profile', how='left')\ntrain_df = pd.merge(train_df,df_test_merge_2[['City','City_code']],on='City', how='left')\ntrain_df = pd.merge(train_df,df_test_merge_3[['Locality','Locality_code']],on='Locality', how='left')\n","a254ac9e":"# Train set after merging encoded categories\n\ntrain_df.head()","4739ed8c":"\n\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns\n\nmissing_values_table(train_df)","1c7a5f47":"cols_to_use = ['Qual_1', 'Qual_2', 'Qual_3', 'Qual_4',\n               'Qual_5', 'Qual_6', 'Qual_7', 'Qual_8',\n               'Qual_9', 'Qual_10', 'Profile_code', 'City_code', 'Locality_code',\n               'feedack_num', 'fees_val','years_exp','Rating']\n\ntarget_col = 'Fees'","314077a1":"for i in cols_to_use:\n    train_df[i] = pd.to_numeric(train_df[i].astype(str).str.replace(',',''), errors='coerce').fillna(-1).astype(int)","ca72452e":"train_df.fillna(-1, inplace=True)","a867059c":"# Define LGBM function\n\ndef run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n        'metric': 'rmse',\n        \"objective\" : \"regression\",\n        \"boosting\": \"gbdt\",\n        \"random_state\": 2019,\n        \"learning_rate\" : 0.01,\n        \"verbosity\" : -1\n    }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    model = lgb.train(params, lgtrain, num_boost_round = 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100)\n    \n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    pred_val_y = model.predict(val_X, num_iteration=model.best_iteration)\n    return pred_test_y, model, pred_val_y","a2b81ca1":"## K-FOLD train\n\nfrom sklearn import model_selection\n\ntrain_X = train_df[cols_to_use]\ntest_X = test_df[cols_to_use]\ntrain_y = train_df[target_col].values\n\npred_lgb = 0\n\nkf = model_selection.KFold(n_splits = 5, random_state=2019, shuffle=True)\nfor trn_index, val_index in kf.split(train_X):\n  trn_X, val_X = train_X.loc[trn_index,:], train_X.loc[val_index,:]\n  trn_y, val_y = train_y[trn_index], train_y[val_index]\n  pred_test_tmp, model, evals_result = run_lgb(trn_X, trn_y, val_X, val_y, test_X)\n  pred_lgb += pred_test_tmp","4c7d1fa0":"# Take average of 5 predictions and create submission file.\n\npred_lgb \/= 5\n\ntest_lgb = df_test\ntest_lgb['Fees'] = pred_lgb\ntest_lgb.to_csv('submission_lgb.csv')","dff574dd":"# plot feature importance of LGB\n\nfig, ax = plt.subplots(figsize=(12,18))\nlgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"LightGBM - Feature Importance\", fontsize=15)\nplt.show()","b4671e1b":"\n# XGBoost CV\ndef modelfit(algo, train, test, features, label, cv_folds=5, early_stopping_rounds=50, metric=\"auc\"):\n    \n    xgb_param = algo.get_xgb_params()\n    xgtrain = xgb.DMatrix(train[features], label=train[label], feature_names=features)\n    xgtest = xgb.DMatrix(test[features])\n    cv_result = xgb.cv(params = xgb_param,\n                      dtrain = xgtrain,\n                      num_boost_round = algo.get_params()['n_estimators'],\n                      nfold = cv_folds,\n                      metrics = metric,\n                      early_stopping_rounds = early_stopping_rounds\n                     )\n        \n    #Fit the algorithm on the data\n    model = xgb.train(xgb_param,\n                      xgtrain,\n                      num_boost_round = cv_result.shape[0],\n                      verbose_eval=15\n                      )\n        \n    #Predict on testing data:\n    y_pred = model.predict(xgtest)\n    \n    #Display feature importance graph\n    xgb.plot_importance(model);\n    \n    return y_pred","4f6d94f8":"# Define Param and call function to execute XGBoost model\n\nxgb1 = xgb.XGBRegressor(\n    learning_rate =0.1,\n    n_estimators=1000,\n    gamma=0,\n    objective= 'reg:linear',\n    nthread=-1,\n    seed=2019)\n\nfeatures = cols_to_use\nlabel = target_col\ntrain = train_df\ntest = test_df\npred_xgb = 0\n\npred_xgb = modelfit(xgb1, train, test, features, label, metric = 'rmse')","e62c0bef":"# Submit XGB prediction\n\ntest_xgb = df_test\ntest_xgb['Fees'] = pred_xgb\ntest_xgb.to_csv('submission_xgb.csv')","543af98b":"# Submit average of LGB and XGB\n\ndf_test[\"Fees\"] = 0.5*test_xgb[\"Fees\"] + 0.5*test_lgb[\"Fees\"]\ndf_test.to_csv(\"submission_average.csv\", index=False)","3f909aba":"# Please **UPVOTE** if this kernel helped you in anyway :)","76f91176":"#### Separate City and Locality in Place variable","d904ff7e":"#### Let's fill all the NaN values with -1 to avoid data type issues in the Model","1da05c04":"**It can be observed that:**\n\n1. Few rows have NaN values\n1. Few rows give only the profile related info along with the fees of the Doctor ;)\n1. Other rows give info about the doctors rating followed by number of people rated then the address","32b23eba":"**Let's check and count total number of unique qualifications in Train and test set**","d41c1619":"### Create a dictionary of Qualification with there respective codes","e108b8d7":"### Check for missing values in train data after merging with test data","2f23564b":"### Let's encode other categorical columns of the test set and then merge into train set","63eb2327":"### Let's have a look at both dataset after encoding qualification columns","cbe1f587":"#### Define function to Separate multiple Qualifications into individual qualification columns","9c833c14":"* **We observe that qualifications are not sorted due to leading whitespace**. \n* **We also need to remove other inconsistensies in the data like**\n    1. replace comma inside bracket by hyphen\n    2. lowercase all the words\n    3. remove spaces within qualification\n* **Lets work on them and sort the variables character wise.**","88ae670e":"### Lets sort and check for any unusual characters in Qualification","cb075a52":"#### Coming to the messy column i.e Miscellaneous_Info Lets make the most out of this.","60b8b7ef":"#### Fill ratings with NaN values as 0% and convert the string type into integer","d99c3b14":"#### Lets define variables for model training.","6466907e":"#### Let's replace all non-integer values in the selected columns to -1 values","76085d14":"#### Split the qualifications into different columns","877dab85":"#### Convert Experience into integer value","8099b462":"This Kernel is majorly inspired from [this](https:\/\/medium.com\/@supreetdeshpande95\/how-to-ace-your-first-hackathon-tutorial-in-python-e40b3d0204e8) article.","579778d9":"\nIt required lot of string manipulation techniques to engineer the data before we feed into the model to predict the Doctor's consultation fees.","a9fe90d0":"**Encode selected columns on test data to ignore extra Qualifications that are present in the train data but are not present in the test data. As the extra qualification in train data  won't help model to predict fees in the test data.**\n**This is done to avoid any issue while transforming test data after fitting on the train data due to uncommon category values.**","82d15212":"* It is observed that the Fees value is not consistent as some records contains more than one fee value.\n* It is also observed that the second fee value is just 120% value of the first fee value. \n* So we will take only the first fee value wherever available.","c81cd3c4":"### First of all let's convert the Indian Rupee symbol to readable INR String","9a16754a":"### Let's assign category codes to the unique qualifications in the test [](http:\/\/)dataset."}}