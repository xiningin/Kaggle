{"cell_type":{"09c1cc88":"code","d2047a90":"code","e3348bd0":"code","18d476ab":"code","8839f346":"code","44192b28":"code","ec9ad8c7":"code","02a5dcb2":"code","52256fa4":"code","e98361a6":"code","28bd5229":"code","13eb8d49":"code","19bb4adc":"code","3b287c54":"code","5cecfdb3":"code","0be606c0":"code","1c022c74":"markdown","ca1d0f77":"markdown","a6f5351d":"markdown","7ef16b47":"markdown","293b644f":"markdown","d55dca6d":"markdown","f3f3322f":"markdown","a701647b":"markdown","6fa9bd4d":"markdown","c4c9243b":"markdown","fc2f7fdc":"markdown"},"source":{"09c1cc88":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d2047a90":"import pandas as pd \n\ndf = pd.read_csv('..\/input\/skin-cancer-mnist-ham10000\/HAM10000_metadata.csv')\ndf.head()","e3348bd0":"df['dx'].unique()","18d476ab":"import matplotlib.pyplot as plt\n#exp = pd.Series.to_frame(df1.groupby('dx').sex.value_counts())\ndf['dx'].value_counts().plot.bar(rot=0)\nplt.title('Number of images for different dx type')\nplt.xlabel('dx')\nplt.ylabel('Counts')\nplt.grid(axis='y')","8839f346":"from os.path import isfile\nfrom PIL import Image as pil_image\ndf['num_images'] = df.groupby('lesion_id')[\"image_id\"].transform(\"count\")\n\nclasses = df['dx'].unique()\nlabeldict = {}\nfor num, name in enumerate(classes):\n    labeldict[name] = num\ndf['dx_id'] = df['dx'].map(lambda x: labeldict[x])\n\n\ndef expand_path(p):\n    if isfile('..\/input\/skin-cancer-mnist-ham10000\/ham10000_images_part_1\/' + p + '.jpg'): return '..\/input\/skin-cancer-mnist-ham10000\/ham10000_images_part_1\/' + p + '.jpg'\n    if isfile('..\/input\/skin-cancer-mnist-ham10000\/ham10000_images_part_2\/' + p + '.jpg'): return '..\/input\/skin-cancer-mnist-ham10000\/ham10000_images_part_2\/' + p + '.jpg'\n    return p \ndf['image_path'] = df['image_id']\ndf['image_path'] = df['image_path'].apply(expand_path)\n\n\ndf['images'] = df['image_path'].map(lambda x: np.asarray(pil_image.open(x).resize((150,112))))\ndf.head()","44192b28":"import matplotlib.pyplot as plt\n        \ndef plot_images(imgs, labels, cols=4):\n    # Set figure to 13 inches x 8 inches\n    figure = plt.figure(figsize=(10, 7))\n\n    rows = len(imgs) \/\/ cols + 1\n\n    for i in range(len(imgs)):\n        img = plt.imread(expand_path(imgs[i]))\n        subplot = figure.add_subplot(rows, cols, i + 1)\n        subplot.axis('Off')\n        if labels:\n            subplot.set_title(labels[i], fontsize=16)\n        plt.imshow(img, cmap='gray')        \n\nimages = df[df['lesion_id'] == 'HAM_0003033'].image_id\n\nplot_images(list(images),list(images))","ec9ad8c7":"imgdict = {'akiec':list(df[df['dx']=='akiec']['image_id'])[0:24:6],'bcc':list(df[df['dx']=='bcc']['image_id'])[0:24:6],\\\n        'bkl':list(df[df['dx']=='bkl']['image_id'])[0:24:6],'df':list(df[df['dx']=='df']['image_id'])[0:24:6],\\\n        'mel':list(df[df['dx']=='mel']['image_id'])[0:24:6],'nv':list(df[df['dx']=='nv']['image_id'])[0:24:6],\\\n        'vasc':list(df[df['dx']=='vasc']['image_id'])[0:24:6]}\n#print(imgdict,'\\n',list(imgdict.values()),list(imgdict.keys()))\nfor i in np.arange(7):\n    cancertype = list(imgdict.keys())[i]\n    cancertypetolist = [cancertype,cancertype,cancertype,cancertype]\n    plot_images(list(imgdict.values())[i],cancertypetolist)\n","02a5dcb2":"from sklearn.model_selection import train_test_split\n\ndf_single = df[df['num_images'] == 1]\ntrainset1, testset = train_test_split(df_single, test_size=0.2,random_state = 700)\ntrainset2, validationset = train_test_split(trainset1, test_size=0.2,random_state = 234)\ntrainset3 = df[df['num_images'] != 1]\nframes = [trainset2, trainset3]\ntrainset = pd.concat(frames)\n\ndef prepareimages(images):\n    # images is a list of images\n    images = np.asarray(images).astype(np.float64)\n    images = images[:, :, :, ::-1]\n    m0 = np.mean(images[:, :, :, 0])\n    m1 = np.mean(images[:, :, :, 1])\n    m2 = np.mean(images[:, :, :, 2])\n    images[:, :, :, 0] -= m0\n    images[:, :, :, 1] -= m1\n    images[:, :, :, 2] -= m2\n    return images\ntrainimages = prepareimages(list(trainset['images']))\ntestimages = prepareimages(list(testset['images']))\nvalidationimages = prepareimages(list(validationset['images']))\ntrainlabels = np.asarray(trainset['dx_id'])\ntestlabels = np.asarray(testset['dx_id'])\nvalidationlabels = np.asarray(validationset['dx_id'])\nprint(np.shape(trainimages))\nprint(np.shape(testimages))\nprint(np.shape(validationimages))","52256fa4":"from keras.preprocessing.image import ImageDataGenerator\n\ntrainimages = trainimages.reshape(trainimages.shape[0], *(112, 150, 3))\n\ndata_gen = ImageDataGenerator(\n        rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally\n        height_shift_range=0.1,  # randomly shift images vertically\n        horizontal_flip=True, \n        vertical_flip=True)\n#x = imageLoader(trainset,batch_size)\ndata_gen.fit(trainimages)","e98361a6":"from tensorflow.python.keras.applications import InceptionV3\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Dropout\nfrom keras import regularizers\n\ninput_shape = (112, 150, 3)\n\nnum_labels = 7\n\nbase_model = InceptionV3(include_top=False, input_shape=(112, 150, 3),pooling = 'avg', weights = '..\/input\/inception\/inception_v3_weights.h5')\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation=\"relu\",kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_labels, activation = 'softmax',kernel_regularizer=regularizers.l2(0.02)))\n\nfor layer in base_model.layers:\n    layer.trainable = True\n\n#for layer in base_model.layers[-30:]:\n #   layer.trainable = True\n\n#model.add(ResNet50(include_top = False, pooling = 'max', weights = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'))\n\nmodel.summary()","28bd5229":"from tensorflow.python.keras.optimizers import Adam\noptimizer = Adam (lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=5e-7, amsgrad=False)\nmodel.compile(optimizer = optimizer , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])","13eb8d49":"# Fit the model\nimport keras\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\nclass CustomModelCheckPoint(keras.callbacks.Callback):\n    def __init__(self,**kargs):\n        super(CustomModelCheckPoint,self).__init__(**kargs)\n        self.epoch_accuracy = {} # loss at given epoch\n        self.epoch_loss = {} # accuracy at given epoch\n        def on_epoch_begin(self,epoch, logs={}):\n            # Things done on beginning of epoch. \n            return\n\n        def on_epoch_end(self, epoch, logs={}):\n            # things done on end of the epoch\n            self.epoch_accuracy[epoch] = logs.get(\"acc\")\n            self.epoch_loss[epoch] = logs.get(\"loss\")\n            self.model.save_weights(\"name-of-model-%d.h5\" %epoch)\n            \ncheckpoint = CustomModelCheckPoint()\ncb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\ncb_checkpointer = ModelCheckpoint(filepath = '..\/working\/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')\nepochs = 12 \nbatch_size = 20\ntrainhistory = model.fit_generator(data_gen.flow(trainimages,trainlabels, batch_size=batch_size),\n                              epochs = epochs, validation_data = (validationimages,validationlabels),\n                              verbose = 1, steps_per_epoch=trainimages.shape[0] \/\/ batch_size,\n                                       callbacks=[cb_checkpointer, cb_early_stopper])","19bb4adc":"import matplotlib.pyplot as plt\nacc = trainhistory.history['acc']\nval_acc = trainhistory.history['val_acc']\nloss = trainhistory.history['loss']\nval_loss = trainhistory.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, loss, '', label='Training loss')\nplt.plot(epochs, val_loss, '', label='Validation loss')\nplt.title('InceptionV3 -- Training and validation loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, acc, '', label='Training accuracy')\nplt.plot(epochs, val_acc, '', label='Validation accuracy')\nplt.title('InceptionV3 -- Training and validation accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()","3b287c54":"model.load_weights(\"..\/working\/best.hdf5\")\ntest_loss, test_acc = model.evaluate(testimages, testlabels, verbose=1)\nprint(\"test_accuracy = %f  ;  test_loss = %f\" % (test_acc, test_loss))","5cecfdb3":"from sklearn.metrics import confusion_matrix\ntrain_pred = model.predict(trainimages)\ntrain_pred_classes = np.argmax(train_pred,axis = 1)\ntest_pred = model.predict(testimages)\n# Convert predictions classes to one hot vectors \ntest_pred_classes = np.argmax(test_pred,axis = 1) \n\nconfusionmatrix = confusion_matrix(testlabels, test_pred_classes)\nconfusionmatrix","0be606c0":"from sklearn.metrics import classification_report\nlabels = labeldict.keys()\n# Generate a classification report\n#trainreport = classification_report(trainlabels, train_pred_classes, target_names=list(labels))\ntestreport = classification_report(testlabels, test_pred_classes, target_names=list(labels))\n#print(trainreport)\nprint(testreport)","1c022c74":"# 3. Split the dataframe and create train, test and validation images and labels","ca1d0f77":"select the testset and validationset from the lesion_id with only one corresponding image_id. It is reasonable to use such dataset in the test and validation step as these images have no similar sibling images","a6f5351d":"### show images belonging to the seven different types","7ef16b47":"### show images belonging to the same lesion_id","293b644f":"# 6. Plot the accuracy and loss of both training and validation dataset","d55dca6d":"# 2. show images","f3f3322f":"# 5. Build CNN model -- InceptionV3","a701647b":"# 4. Data augmentation","6fa9bd4d":"1. Create 'num_images' to record the number of images belonging to the same 'lesion_id'\n2. Create 'dx_id' convert the 'dx' to integer label\n3. Create 'image_path' to store the path to access the image\n4. Create 'images' to store the resized image as arrays","c4c9243b":"### Since there are not too many images belonging to each skin cancer type, it is better to augment data before training. Data augmentation includes rotation, zoom, shift in two directions","fc2f7fdc":"# 1. Create several more columns for the dataframe 'df'"}}