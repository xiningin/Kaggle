{"cell_type":{"a954ecf6":"code","aedec4c9":"code","901e2bb8":"code","24c0dfe7":"code","96ee8116":"code","b7ec89b0":"code","b7c0a4a2":"markdown","cac86ba7":"markdown","f96c5ab5":"markdown","ba1fef8f":"markdown"},"source":{"a954ecf6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aedec4c9":"# Import necessary modules\nfrom sklearn import datasets\nimport matplotlib.pyplot as plt\n\n# Load the digits dataset: digits\ndigits = datasets.load_digits()\n\n# Print the keys and DESCR of the dataset\nprint(digits.keys())\nprint(digits['DESCR'])\n\n# Print the shape of the images and data keys\nprint(digits.images.shape)\nprint(digits.data.shape)\n\n# Display digit 1010\nplt.imshow(digits.images[1010], cmap=plt.cm.gray_r, interpolation='nearest')\nplt.show()","901e2bb8":"from sklearn.model_selection import train_test_split\n\n# Create feature and target arrays\nX = digits.data\ny = digits.target\n\n# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=42, stratify=y)","24c0dfe7":"from sklearn.neighbors import KNeighborsClassifier\n# Create a k-NN classifier with 7 neighbors: knn\nknn =KNeighborsClassifier(n_neighbors=7) \nknn.fit(X_train,y_train)\ny_pred=knn.predict(X_test)\nprint(y_pred)","96ee8116":"# Print the accuracy\nprint(str(knn.score(X_test, y_test)*100)+' %')","b7ec89b0":"# Setup arrays to store train and test accuracies\nneighbors = np.arange(1, 9)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))\n\n# Loop over different values of k\nfor i, k in enumerate(neighbors):\n    # Setup a k-NN Classifier with k neighbors: knn\n    knn = KNeighborsClassifier(n_neighbors=k)\n\n    # Fit the classifier to the training data\n    knn.fit(X_train,y_train)\n    \n    #Compute accuracy on the training set\n    train_accuracy[i] = knn.score(X_train, y_train)\n\n    #Compute accuracy on the testing set\n    test_accuracy[i] = knn.score(X_test,y_test)\n\n# Generate plot\nplt.title('k-NN: Varying Number of Neighbors')\nplt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.show()","b7c0a4a2":"# Train_data & Test_data split","cac86ba7":"# Fit the model with Train_data ,predict & find accuracy of the model","f96c5ab5":"# Understaning the overfitting & Underfitting with K-neighbors ","ba1fef8f":"# Exploring data from dataset"}}