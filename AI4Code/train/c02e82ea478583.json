{"cell_type":{"c7062235":"code","75e752b0":"code","8df179a8":"code","ee4c465f":"code","484fbd0b":"code","c06580c1":"code","5b7a2fbc":"code","4a80d7e8":"code","a223f650":"code","b33a03da":"code","5b61d062":"code","38db1ce1":"code","b4927258":"code","1e0ee4db":"code","876ee638":"code","987607ac":"code","ae72a9d3":"code","6ac0baa8":"code","34b6e5c2":"code","fe200d72":"code","d968ac26":"code","9eab1027":"code","89f493b5":"code","926c58c9":"code","a5d6d808":"code","a93c11a1":"code","1a9a998f":"code","ccd863d8":"code","5c64d5d5":"code","8658d7db":"markdown","d0a42331":"markdown","57944bfd":"markdown","b1d51cab":"markdown"},"source":{"c7062235":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split#splits arrays or matrices into a random train and test subsets\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# Neural Network\nimport keras \nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import Adam\nfrom keras import regularizers\nfrom keras.callbacks import EarlyStopping","75e752b0":"#Load the dataset into Pandas dataframe \ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","8df179a8":"train.head()","ee4c465f":"train.describe()","484fbd0b":"train.isnull().sum(axis=0)","c06580c1":"test.isnull().sum(axis=0)","5b7a2fbc":"train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()","4a80d7e8":"train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()","a223f650":"sns.boxplot(x='Pclass',y='Age',data=train,palette='winter')","b33a03da":"train[['Pclass', 'Age']].groupby(['Pclass'], as_index=False).median()","5b61d062":"test[['Pclass', 'Age']].groupby(['Pclass'], as_index=False).median()","38db1ce1":"test[['Pclass', 'Fare']].groupby(['Pclass'], as_index=False).mean()","b4927258":"#dealing with the \u2018NaN\u2019 values in the train dataset.As the NaN values are in only in Age,Cabin&Embarked\ndef impute_age_train(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 37 # Since Pclass[1] has a median 37\n        elif Pclass == 2:\n            return 29 # Since Pclass[2] has a median 29\n        else:\n            return 24 # Since Pclass[3] has a median 24\n    else:\n        return Age\ntrain['Age'] = train[['Age', 'Pclass']].apply(impute_age_train, axis = 1)","1e0ee4db":"#dealing with the \u2018NaN\u2019 values in the train dataset.As the NaN values are in only in Age,Cabin&Embarked\ndef impute_Embarked_train(train):\n    freq_port_train = train.Embarked.dropna().mode()[0]\n    train['Embarked'] = train['Embarked'].fillna(freq_port_train)\n    train['Embarked'] = train['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    return train\ntrain = impute_Embarked_train(train)","876ee638":"#dealing with the \u2018NaN\u2019 values in the test dataset.As the NaN values are in only in Age,Cabin&Fare\ndef impute_age_test(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 42 # Since Pclass[1] has a median 42\n        elif Pclass == 2:\n            return 26.5 # Since Pclass[2] has a median 26.5\n        else:\n            return 24 # Since Pclass[3] has a median 24\n    else:\n        return Age\ntest['Age'] = test[['Age', 'Pclass']].apply(impute_age_test, axis = 1)","987607ac":"#dealing with the \u2018NaN\u2019 values in the test dataset.As the NaN values are in only in Age,Cabin&Fare\ndef impute_fare_test(cols):\n    Pclass = cols[0]\n    Fare = cols[1]\n    if pd.isnull(Fare):\n        if Pclass == 1:\n            return 60 # Since Pclass[1] has a median 60\n        elif Pclass == 2:\n            return 15.75 # Since Pclass[2] has a median 15.75\n        else:\n            return 7.896 # Since Pclass[3] has a median 7.896\n    else:\n        return Fare\ntest['Fare'] = test[['Pclass','Fare']].apply(impute_fare_test, axis = 1)","ae72a9d3":"#Converting Categorial data into numerical\ntest['Embarked'] = test['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","6ac0baa8":"from sklearn.preprocessing import LabelEncoder\n#labeling genders\ndef gender(data):\n    le = LabelEncoder()\n    le.fit([\"male\", \"female\"])\n    data[\"Sex\"] = le.transform(data[\"Sex\"])\n    return data\nfrom sklearn.preprocessing import MinMaxScaler\n#Narmalizing age and fare\ndef normalize_data(data):\n    mms = MinMaxScaler()\n    data[\"Age\"] = mms.fit_transform(data[\"Age\"].values.reshape(-1, 1))\n    data[\"Fare\"] = mms.fit_transform(data[\"Fare\"].values.reshape(-1, 1))\n    return data","34b6e5c2":"gender(train)\ngender(test)\nnormalize_data(train)\nnormalize_data(test)","fe200d72":"X_train = train.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\",\"Survived\"], axis=1).copy()\nY_train = train[\"Survived\"].copy()\nX_test  = test.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"],axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","d968ac26":"X_test.head()","9eab1027":"#Train Test Split\n#X_train, X_test, Y_train, Y_test = train_test_split(train.drop('Survived',axis=1),train['Survived'], test_size=0.25,random_state=101)","89f493b5":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\n#acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nprint(round(decision_tree.score(X_train, Y_train) * 100, 2))\n#print(accuracy_score(Y_test,Y_pred)* 100)","926c58c9":"Y_final = (Y_pred > 0.5).astype(int).reshape(X_test.shape[0])\n\noutput = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': Y_final})\noutput.to_csv('pred_decision_tree.csv', index=False)\noutput.head()","a5d6d808":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\n#acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nprint(round(random_forest.score(X_train, Y_train) * 100, 2))\n#print(accuracy_score(Y_test,Y_pred)* 100)","a93c11a1":"Y_final = (Y_pred > 0.5).astype(int).reshape(X_test.shape[0])\n\noutput1 = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': Y_final})\noutput1.to_csv('pred_random_forest.csv', index=False)\noutput1.head()","1a9a998f":"model = Sequential()\n# layers\nmodel.add(Dense(32, kernel_initializer = 'uniform', activation = 'relu', kernel_regularizer=regularizers.l2(0.003),input_dim = X_train.shape[1]))\n#model.add(Dropout(rate=0.2))\nmodel.add(Dense(16, kernel_initializer = 'uniform', activation = 'relu',kernel_regularizer=regularizers.l2(0.002)))\n#model.add(Dropout(rate=0.2))\nmodel.add(Dense(5, kernel_initializer = 'uniform', activation = 'relu',kernel_regularizer=regularizers.l2(0.001)))\n#model.add(Dropout(rate=0.1))\nmodel.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n# Compile the model\nmodel.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])","ccd863d8":"model.fit(X_train, Y_train, batch_size = 16, epochs = 1000)\nsc = model.evaluate(X_train,Y_train)\n#score = model.evaluate(X_test,Y_test)\nprint(\"\")\nprint(\"Train Accuracy:{0}\".format(sc[1]))\n#print(\"Test accuracy:{0}\".format(score[1]))","5c64d5d5":"Y_pred = model.predict(X_test)\nY_final = (Y_pred > 0.5).astype(int).reshape(X_test.shape[0])\n\noutput2 = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': Y_final})\noutput2.to_csv('pred_neural_nets_l2.csv', index=False)\noutput2.head()","8658d7db":"## Modeling and Prediction","d0a42331":"## Data Preprocessing\n<p>Let's look at individual features one by one. Missing values will have to be filled. Categorical features need to be transformed to numerical values.<\/p>","57944bfd":"# Neural Network with RandomForest, DecisionTree,Keras for Kaggle's Titanic Dataset","b1d51cab":"### Neural Nets With Keras"}}