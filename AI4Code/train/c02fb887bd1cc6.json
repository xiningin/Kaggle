{"cell_type":{"bded65ba":"code","ac65dfd1":"code","e75ff4a1":"code","6439d29c":"code","69d21c5b":"code","1db00377":"code","f1cb45b1":"code","168c1237":"code","6443db3a":"code","5b1fca4f":"code","c16b2876":"code","cb53aeed":"code","d823adc9":"code","7857889b":"code","236f50e0":"code","4ead648a":"code","501ea385":"code","397e3556":"code","e57de59d":"code","cbaa20a7":"code","2e3a89fa":"code","6e21f7fd":"markdown","c5ff8113":"markdown","11076ef5":"markdown","1d49d473":"markdown","99ff5316":"markdown","783be758":"markdown","0d75b0a9":"markdown","206bec11":"markdown","30bc2e29":"markdown","bb6bf5f5":"markdown","e3611340":"markdown"},"source":{"bded65ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ac65dfd1":"import pandas as pd\nraw = pd.read_csv(\"..\/input\/monkey_labels.txt\", skipinitialspace=True)\nraw","e75ff4a1":"raw.columns","6439d29c":"raw = raw.rename(columns=lambda x: x.strip())\nraw.columns\n","69d21c5b":"labels = pd.DataFrame()\nlabels[\"id\"] = raw[\"Label\"].str.strip()\nlabels[\"name\"] = raw[\"Common Name\"].str.strip()","1db00377":"labels","f1cb45b1":"from IPython.display import Image, display\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom os import listdir\n%matplotlib inline","168c1237":"TRAIN_DIR = \"..\/input\/training\/training\/\"\nVALIDATION_DIR = \"..\/input\/validation\/validation\/\"\nprint(os.listdir(TRAIN_DIR))","6443db3a":"all_ids = labels[\"id\"]\n\nfor my_id in labels[\"id\"]:\n    images_to_show = 5\n    image_dir = TRAIN_DIR + \"%s\/\" % my_id\n    image_name = listdir(image_dir)[0]\n    image_path = image_dir  + image_name\n    print(\"Labels is %s\" % my_id)\n    display(Image(filename=image_path, width=300, height=300))","5b1fca4f":"from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nIMAGE_WIDTH = 300\nIMAGE_HEIGHT = 300\nBATCH_SIZE = 16","c16b2876":"\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,      # We need to normalize the data\n                                    rotation_range=40,      # The rest of params will generate us artificial data by manipulating the image\n                                    width_shift_range=0.2,\n                                    height_shift_range=0.2,\n                                    shear_range=0.2,\n                                    zoom_range=0.2,\n                                    horizontal_flip=True, \n                                    fill_mode='nearest'\n                                  )\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255, # We need to normalize the data\n                                  )\n\ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR, \n                                                    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT), \n                                                    batch_size = BATCH_SIZE, \n                                                    shuffle=True, # By shuffling the images we add some randomness and prevent overfitting\n                                                    class_mode=\"categorical\")\n\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n                                                    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT), \n                                                    batch_size = BATCH_SIZE, \n                                                    shuffle=True,\n                                                    class_mode=\"categorical\")","cb53aeed":"training_samples = 1097\nvalidation_samples = 272\ntotal_steps = training_samples \/\/ BATCH_SIZE","d823adc9":"from keras.applications import vgg16\nmodel = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3), pooling=\"max\")\n\nfor layer in model.layers[:-5]:\n        layer.trainable = False\n        \nfor layer in model.layers:\n    print(layer, layer.trainable)","7857889b":"model.summary()","236f50e0":"from keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.models import Model, Sequential\n\n# Although this part can be done also with the functional API, I found that for this simple models, this becomes more intuitive\ntransfer_model = Sequential()\nfor layer in model.layers:\n    transfer_model.add(layer)\ntransfer_model.add(Dense(512, activation=\"relu\"))  # Very important to use relu as activation function, search for \"vanishing gradiends\" :)\ntransfer_model.add(Dropout(0.5))\ntransfer_model.add(Dense(10, activation=\"softmax\")) # Finally our activation layer! we use 10 outputs as we have 10 monkey species (labels)","4ead648a":"transfer_model.summary()","501ea385":"from keras import optimizers\nadam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00001)\n\ntransfer_model.compile(loss=\"categorical_crossentropy\",\n                      optimizer=adam,\n                      metrics=[\"accuracy\"])","397e3556":"model_history = transfer_model.fit_generator(train_generator, steps_per_epoch=training_samples \/\/ BATCH_SIZE,\n                                            epochs=25,\n                                            validation_data=validation_generator,\n                                            validation_steps=validation_samples \/\/ BATCH_SIZE)","e57de59d":"for metric in model_history.history.keys():\n    print(metric)\n","cbaa20a7":"import pandas as pd\nhistory = pd.DataFrame()\nhistory[\"acc\"] = model_history.history[\"acc\"]\nhistory[\"val_acc\"] = model_history.history[\"val_acc\"]\nhistory.head()","2e3a89fa":"history.plot(figsize=(12, 6))","6e21f7fd":"### Lets do a simple exploration of the files...","c5ff8113":"# Monkey species, using convnets\n## This notebook is done mainly for self-learning, I hope others might find it useful.","11076ef5":"### Now, lets plot our results, that will give us and idea on how we were improving over time.","1d49d473":"### Now, at this point seems like more epochs might help us, but we seem to have reach some sort of plateau, so the question is, can we do better? There are a few things to test\n \n* Try bigger images\n* Bottleneck features\n* Everything else :)\n\n### However this notebook\/kernel just wants to ilustrate how to reuse an existing network (in this case VGG16), so we will leave it like this.","99ff5316":"### We will use the VGG16 network with pretrained weights, this will allow us to go quite quickly, it is important to mark every layer as NON-trainable, so we do not spend GPU cycles on them","783be758":"### Lets play with ImageDataGenerator and see what it can... generate for us","0d75b0a9":"### Now we are going to use the ImageDataGenerator objects to prepare our datasets. This step is very important, and the arguments we provide are incredibly sensitive, we NEED to understand what is going on here, so spend time in this cell","206bec11":"### Looks like the columns are looking funny... lets strip the names","30bc2e29":"### Time to show a couple of images","bb6bf5f5":"### Note how the output is now a Dense layer of 10 units!\n### Next thing, lets define our optimizer, I will go with Adam and a learning rate of 0.0001","e3611340":"### Note how the output (final layer) is just a MaxPooling, this is of no use to use, we need now to add our OWN final layer which will consist on a Dense layer with 10 outputs (remember, we have 10 monkey species)"}}