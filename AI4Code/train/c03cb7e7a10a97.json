{"cell_type":{"e3d3001d":"code","b1b42288":"code","19d2b51b":"code","68a77b90":"code","15f7fee7":"code","3e1ee71d":"code","9f240791":"code","f91cf902":"code","f343b5f5":"code","d8124850":"code","dd65f8e3":"code","4cddefeb":"code","b01ddf0d":"code","33361e76":"markdown","4a225219":"markdown","51992ee0":"markdown","a5ea4c43":"markdown","867b6005":"markdown","a2f1b671":"markdown","6ded5ba4":"markdown","8057db50":"markdown","6a463307":"markdown","97cb9905":"markdown"},"source":{"e3d3001d":"import numpy as np\nimport pandas as pd\n\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow import keras, one_hot\n\nimport matplotlib.pyplot as plt","b1b42288":"IMAGE_SIZE = [224,224]\nBATCH_SIZE = 64\nNUM_CLASSES = 4\nDROUPOUT_RATE = 0.3\nDIRECTORY_TRAIN = \"..\/input\/alzheimermridataset\/Alzheimer_s Dataset\/train\"\nDIRECTORY_TEST = \"..\/input\/alzheimermridataset\/Alzheimer_s Dataset\/test\"","19d2b51b":"train = image_dataset_from_directory(\n    DIRECTORY_TRAIN,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n)\n\nvalidation = image_dataset_from_directory(\n    DIRECTORY_TRAIN,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n)","68a77b90":"train.class_names","15f7fee7":"batch = train.take(1)\n\nplt.figure(figsize=(20,20))\nfor images in batch:\n    for i in range(9):\n        plt.subplot(4, 3, i + 1)\n        image = images[0][i]\n        label = images[1][i]\n        plt.imshow(image.numpy().astype(\"uint8\"))\n        plt.title(train.class_names[label])","3e1ee71d":"label_occurency = {0: 0, 1: 0, 2: 0, 3: 0}\nfor batch in train:\n    label_occurency[0] += (batch[1].numpy() == 0).sum()\n    label_occurency[1] += (batch[1].numpy() == 1).sum()\n    label_occurency[2] += (batch[1].numpy() == 2).sum()\n    label_occurency[3] += (batch[1].numpy() == 3).sum()\n#     print(batch[1].numpy())\nprint(label_occurency)","9f240791":"def one_hot_label(image, label):\n    label = one_hot(label, NUM_CLASSES)\n    return image, label","f91cf902":"train = train.map(one_hot_label)\nvalidation = validation.map(one_hot_label)","f343b5f5":"METRICS = [\n    keras.metrics.BinaryAccuracy(name='accuracy'),\n    keras.metrics.Precision(name='precision'),\n    keras.metrics.Recall(name='recall'),  \n    keras.metrics.AUC(name='auc')\n]\n\n\n\nmodel = Sequential([\n  layers.experimental.preprocessing.Rescaling(1.\/255, input_shape=(*IMAGE_SIZE, 3)),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(DROUPOUT_RATE),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(DROUPOUT_RATE),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(NUM_CLASSES, 'softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss=CategoricalCrossentropy(from_logits=True),\n              metrics=METRICS)\n\nmodel.summary()","d8124850":"epochs=15\nhistory = model.fit(\n  train,\n  validation_data=validation,\n  epochs=epochs\n)","dd65f8e3":"def plot_metric(metric, history):\n    fig = plt.figure(figsize=(30,5))\n    ax = fig.add_subplot(1, 1, 1)\n    ax.plot(history.history[metric])\n    ax.plot(history.history['val_' + metric])\n    ax.set_title(f'Model {metric}')\n    ax.legend(['train', \"validation\"])\n    ax.set_xlabel(\"epochs\")\n    ax.set_ylabel(metric)\n","4cddefeb":"plot_metric('loss', history)\nplot_metric('auc', history)\nplot_metric('accuracy', history)\nplot_metric('precision', history)","b01ddf0d":"test = image_dataset_from_directory(\n    DIRECTORY_TEST,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n)\n\ntest = test.map(one_hot_label)\nresult = model.evaluate(test)\nplt.bar([0, 1, 2, 3, 4], result, tick_label = [\"loss\", \"accuracy\", \"precision\", \"recall\", \"auc\"])","33361e76":"On observe que le data set n'est pas balance, pour tant utiliser accuracy comme score, serait pas une bonne id\u00e9e. Pour cela on va utiliser ROC AUC.","4a225219":"# Visualisation\n\nOn visualise les images pour comprendre les donn\u00e9es.","51992ee0":"On observe que Auc est de 0.84, et le loss est de 1.4. Cela signifie que peut-\u00eatre il y a un peu des overfitting dans notre mod\u00e8le, qui est cause aux donnes pas balanc\u00e9es.","a5ea4c43":"Convertir le label en categorie","867b6005":"# Analyse des r\u00e9sultats","a2f1b671":"# Train\nOn commence avec un mod\u00e8le de neurone simple.","6ded5ba4":"Definitions de constant","8057db50":"On remarque que la metric **AUC** dans notre mod\u00e8le tend vers 1, pour notre train et notre validation. Ce qui permet de valider le mod\u00e8le.\n\nDans nos donn\u00e9es on a aussi un fichier de test, pour valider encore notre mod\u00e8le.","6a463307":"Dans les donn\u00e9es on a 4 classes, qui correspondent \u00e0 la severite de la pathologie.","97cb9905":"# Load data\n\nAvec la foncion de keras **image_dataset_from directoy** on peut facilement charger les donnees. On va creer deux groupes du fichier traint, un effectivement pour entrainer notre modele, et un de validation. Dans une proportion de 80% et 20%."}}