{"cell_type":{"bbd20517":"code","cb6df665":"code","7a52bbe2":"code","8e921f16":"code","30df1175":"code","cd3cba78":"code","cf38e9a5":"code","94eaa510":"code","693d1383":"code","fbc72dab":"code","4762bf3a":"code","dbdd0d8a":"code","bc1f1f72":"code","4ee401f0":"code","b6f3da6b":"code","53b91af4":"code","61a5b594":"code","c0ab6c94":"code","6ef5e6d5":"code","d963d26d":"markdown","a57f61e2":"markdown","45fc896a":"markdown","e424f35c":"markdown","0d7c3624":"markdown"},"source":{"bbd20517":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","cb6df665":"train_orig=pd.read_csv(\"\/kaggle\/input\/twitter-sentiment-analysis-hatred-speech\/train.csv\")\ntest_nolabel=pd.read_csv(\"\/kaggle\/input\/twitter-sentiment-analysis-hatred-speech\/test.csv\")","7a52bbe2":"from nltk.corpus import stopwords\nfrom nltk import word_tokenize\nimport string\nimport re\nstop_words = set(stopwords.words('english'))\n\ntrain = train_orig\n\ndef remove_stopwords(line):\n    word_tokens = word_tokenize(line)\n    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n    return \" \".join(filtered_sentence)\n\ndef preprocess(line):\n    line = line.lower()  #convert to lowercase\n    line = re.sub(r'\\d+', '', line)  #remove numbers\n    line = line.translate(line.maketrans(\"\",\"\", string.punctuation))  #remove punctuation\n#     line = line.translate(None, string.punctuation)  #remove punctuation\n    line = remove_stopwords(line)\n    return line\nfor i,line in enumerate(train.tweet):\n    train.tweet[i] = preprocess(line)","8e921f16":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train['tweet'], train['label'], test_size=0.5, stratify=train['label'])\n\ntrainp=train[train.label==1]\ntrainn=train[train.label==0]\nprint(trainp.info())\ntrainn.info()","30df1175":"# Let us balance the dataset\ntrain_imbalanced = train\nfrom sklearn.utils import resample\ndf_majority = train[train.label==0]\ndf_minority = train[train.label==1]\n \n# Upsample minority class\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=len(df_majority),    # to match majority class\n                                 random_state=123) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\nprint(\"Before\")\nprint(train.label.value_counts())\nprint(\"After\")\nprint(df_upsampled.label.value_counts())\n\nX_train, X_test, y_train, y_test = train_test_split(df_upsampled['tweet'], df_upsampled['label'], test_size=0.5, stratify=df_upsampled['label'])","cd3cba78":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\n# Xtext=train.tweet\n# Xtest=test.tweet\n# y=train.label\n# test\n# ytest=test.label","cf38e9a5":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nvect = CountVectorizer()\ntf_train=vect.fit_transform(X_train)  #train the vectorizer, build the vocablury\ntf_test=vect.transform(X_test)  #get same encodings on test data as of vocabulary built","94eaa510":"tf_test_nolabel=vect.transform(test_nolabel.tweet)","693d1383":"# print(tf_train)\n# vect.get_feature_names()[:10] #print few features only to avoid slowing down the notebook","fbc72dab":"model.fit(X=tf_train,y=y_train)","4762bf3a":"expected = y_test\npredicted=model.predict(tf_test)","dbdd0d8a":"from sklearn import metrics\n\nprint(metrics.classification_report(expected, predicted))\nprint(metrics.confusion_matrix(expected, predicted))","bc1f1f72":"from mlxtend.plotting import plot_confusion_matrix\n\nplot_confusion_matrix(metrics.confusion_matrix(expected, predicted))","4ee401f0":"print(trainp.iloc[:10])\ntrainn.iloc[:10]","b6f3da6b":"gg=X_test.reset_index(drop=True)\n# print(gg)\nfor i, p in enumerate(predicted):\n#     print(i)\n    print (gg[i] + \" - \" + str(p))\n    if i>5:\n        break #to avoid a lot of printing and slowing down the notebook","53b91af4":"predicted_nolabel=model.predict(tf_test_nolabel)\nfor i, p in enumerate(tf_test_nolabel):\n#     print(i)\n    print (test_nolabel.tweet[i] + \" - \" + str(predicted_nolabel[i]))\n    if i>5:\n        break #to avoid a lot of printing and slowing down the notebook","61a5b594":"test_custom=pd.DataFrame([\"racist\", \"white judge trial\", \"it is a horrible incident\", \"@user #white #supremacists want everyone to see the new \u00e2\u0080\u0098  #birds\u00e2\u0080\u0099 #movie \u00e2\u0080\u0094 and here\u00e2\u0080\u0099s why\", \" @user #white #supremacists want everyone to see the new \u00e2\u0080\u0098  #birds\u00e2\u0080\u0099 #movie \u00e2\u0080\u0094 and here\u00e2\u0080\u0099s why\", \"@user  at work: attorneys for white officer who shot #philandocastile remove black judge from presiding over trial. ht\u00e2\u0080\u00a6\"])\ntf_custom = vect.transform(test_custom[0])\nmodel.predict(tf_custom)","c0ab6c94":"twit=pd.read_csv(\"..\/input\/godrejtweet\/Tweets.csv\")\ntf_twit=vect.transform(twit.tweet)\npredicted_twit=model.predict(tf_twit)\nneg=0\npos=0\n\nfor i, p in enumerate(tf_twit):\n#     print(i)\n    print (twit.tweet[i] + \" - \" + str(predicted_twit[i]))\n    if (predicted_twit[i]==0):\n        pos+=1\n    else:\n        neg+=1","6ef5e6d5":"print (\"Positive Tweets - \",pos)\nprint (\"Negative Tweets - \",neg)","d963d26d":"**New report with stratification enabled. Shows further improvement in results\n**<pre>\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98     14860\n           1       0.89      0.42      0.57      1121\n\n    accuracy                           0.96     15981\n   macro avg       0.92      0.71      0.77     15981\nweighted avg       0.95      0.96      0.95     15981\n\n[[14800    60]\n [  650   471]]\n<\/pre>","a57f61e2":"**Convert text data to numerical data**","45fc896a":"**New metric:**\n<pre>\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98     14848\n           1       0.88      0.40      0.55      1133\n\n    accuracy                           0.95     15981\n   macro avg       0.92      0.70      0.76     15981\nweighted avg       0.95      0.95      0.95     15981\n\n[[14786    62]\n [  683   450]]\n<\/pre>","e424f35c":"**Classification report after upsampling the minority classes. Look at updated values for label 1**\n<pre>\n              precision    recall  f1-score   support\n\n           0       0.98      0.91      0.94     14860\n           1       0.92      0.98      0.95     14860\n\n    accuracy                           0.94     29720\n   macro avg       0.95      0.94      0.94     29720\nweighted avg       0.95      0.94      0.94     29720\n\n[[13542  1318]\n [  345 14515]]\n<\/pre>","0d7c3624":"**Let us do some pre-processing. Without preprocessing results are:  (Avoid looking at these metrics in the beginning, will be explained in the end of notebook)**\n<pre>\n               precision    recall  f1-score   support\n \n            0       0.95      1.00      0.97     14880\n            1       0.85      0.35      0.49      1101\n \n     accuracy                           0.95     15981\n    macro avg       0.90      0.67      0.73     15981\n weighted avg       0.95      0.95      0.94     15981\n \n [[14815    65]\n [  718   383]]\n<\/pre>"}}