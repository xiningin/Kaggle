{"cell_type":{"4992cd26":"code","a06d0a7e":"code","ce21cc3a":"code","d3feda7a":"code","b339dcb5":"code","3196e9e6":"code","75089cef":"code","c89a7ee2":"code","0ced7426":"code","8da66777":"code","642a176c":"code","250f210a":"code","93f07608":"code","f8409376":"code","3eaee119":"code","23221817":"code","f201a143":"code","d6ee7a8e":"code","d4061318":"code","4736d998":"code","6a157fd7":"code","e0a38f38":"code","88dd1db7":"code","3f11352a":"code","0cfc4919":"code","ba5e144c":"code","472b1436":"code","635b929d":"code","d57d4994":"markdown","4b8cd725":"markdown","e96f4126":"markdown","d995fa5d":"markdown","4ef5c2b0":"markdown","b92d1830":"markdown","89de018c":"markdown","ef84d977":"markdown","553b8826":"markdown","91f9b7f8":"markdown","593c1119":"markdown","873c7aea":"markdown","f5443d2d":"markdown","af49ae97":"markdown","e5fce903":"markdown","4ff51bfb":"markdown","0848bc40":"markdown","44765f42":"markdown","66c65da6":"markdown","b213cd6b":"markdown","78453c82":"markdown","815844ea":"markdown","026d422b":"markdown","c4a046f7":"markdown","0c216828":"markdown","15158e6c":"markdown","0fbbdd2f":"markdown","6b1dc993":"markdown","86598bf8":"markdown","d75ab31a":"markdown"},"source":{"4992cd26":"!pip install inverness==0.0.3","a06d0a7e":"import inverness\nmodel = inverness.Model('\/kaggle\/input\/cord-19-inverness-all-v7\/')\nmodel.load(['fun','meta','phraser','dictionary','tfidf','lsi','dense_ann'])","ce21cc3a":"from IPython.core.display import display, HTML\nfrom matplotlib import pyplot as plt\nimport pandas as pd\n\nfrom pprint import pprint\nfrom time import time\nimport re\nimport os","d3feda7a":"pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv',nrows=3) # just a sample","b339dcb5":"meta_by_sha = {}\nmeta_by_pmc = {}\n\nt0 = time()\n\nCOLS = ['cord_uid','sha','pmcid','publish_time','journal','url','title','authors']\ndf = pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv')\nselected = df[df['full_text_file'] != ''][COLS]\n\nrows = selected.iterrows()\nfor _,r in rows:\n    if type(r['title']) is float: r['title']='' # ugly fix for NaN\n    if type(r['sha']) is str:\n        for sha in r['sha'].split(';'):\n            sha = sha.strip()\n            meta = {k:r[k] for k in COLS} \n            meta_by_sha[sha] = meta\n    if type(r['pmcid']) is str:\n            pmc = r['pmcid']\n            meta = {k:r[k] for k in COLS} \n            meta_by_pmc[pmc] = meta\n\nprint(f\"done in {time()-t0:.01f} seconds\")","3196e9e6":"print(\"Paper metadata sample:\\n\")\nfor sha in meta_by_sha:\n    pprint(meta_by_sha[sha])\n    break","75089cef":"def score_text(text, criteria):\n    \"\"\"score text according to the criteria\n    \n    criteria - mixed list of regexp patterns (string) and weights (int,float)\n               weight creates new group which includes all patterns untill new weight is defined\n               if weight is a float then the first digit after the decimal dot specifies\n               max count for that group\n               \n               example: [5,'questlord','inverness', 2,'honour','glory','pride', 1.5,'unicorn']\n               \n                   group 1 -- weight:5  patterns:questlord,inverness  max_cnt:0 (unlimited) \n                   group 2 -- weight:2  patterns:honour,glory,pride   max_cnt:0 (unlimited)\n                   group 3 -- weight:1  patterns:unicorn              max_cnt:5\n    \"\"\"\n    total = 0\n    value = 1\n    max_cnt = 0\n    group_cnt = 0\n    for c in criteria:\n        if type(c) in (int,float):\n            value = c\n            group_cnt = 0\n            max_cnt = round(c%1*10)\n        else:\n            c = c.replace('_',r'\\b')\n            matches = re.findall(c,text,re.I)\n            cnt = len(matches)\n            #if max_cnt: cnt=min(max_cnt,cnt) # option 1: pattern limit\n            if max_cnt: cnt=min(max_cnt-group_cnt,cnt);group_cnt+=cnt # option 2: group limit\n            score = value*cnt_to_score(cnt)\n            total += score\n    return total\n\n\ndef cnt_to_score(cnt):\n    \"\"\"transform match count to score\"\"\"\n    if cnt==0: return 0\n    return cnt\n    #return min(3,cnt)\n    #return 2-1\/cnt\n    \n\ndef score_ann_results(i_d_lists, criteria):\n    \"\"\"score ann query results and \"\"\"\n    results = []\n    for i,d in zip(*i_d_lists):\n        # metadata\n        paper_id = model.meta[i]['paper_id']\n        if paper_id in meta_by_sha:\n            meta = meta_by_sha[paper_id]\n        else:\n            meta = meta_by_pmc[paper_id]\n        # text\n        doc = model.get_doc(i)\n        text = model.doc_to_text(doc).replace('\\n',' ').replace('\\r',' ')\n        html = highlight(text, criteria, style_by_group_id, default_style)\n        # score\n        #score = score_text(text, criteria) + score_text(meta['title'], criteria) # option1: add separate scores\n        score = score_text(meta['title']+\" :: \"+text, criteria) # option2: score combined\n        # output\n        rec = score,d,i,html,meta\n        results += [rec]\n    results.sort(key=lambda x:(-x[0],x[1]))\n    return results\n\n\ndef score_queries(queries, criteria, K=50):\n    \"\"\"\"\"\"\n    by_score = []\n    for query in queries:\n        q = model.text_to_dense(query)\n        i_d = model.dense_ann_query(q,K)\n        results = score_ann_results(i_d, criteria)\n        score = agg_results(results)\n        by_score += [(score,query)]\n    by_score.sort()\n    return by_score\n\n\ndef highlight(text, criteria, styles={}, default='w=bold'):\n    \"\"\"\"\"\"\n    group_id = 0\n    for c in criteria:\n        if type(c) in (int,float):\n            group_id += 1\n        else:\n            c = c.replace('_',r'\\b')\n            c = f'({c}\\\\w*)'\n            style = styles.get(group_id,default)\n            style_props = []\n            for prop in style.split(','):\n                k,_,v = prop.partition('=')\n                if k=='w':\n                    style_props += [f'font-weight:{v}']\n                if k=='fg':\n                    style_props += [f'color:{v}']\n                if k=='bg':\n                    style_props += [f'background-color:{v}']\n            before = f'<span style=\"{\";\".join(style_props)}\">'\n            after = '<\/span>'\n            text = re.sub(c, before+'\\\\1'+after, text, flags=re.I)\n            # TODO default\n    return text\n\n\n# L2 score\ndef agg_results(results):\n    \"\"\"\"\"\"\n    scores = [x[0] for x in results]\n    return sum([x*x for x in scores])**0.5\n\n\n# TODO break title into multiple lines\ndef plot_results(results,title=''):\n    \"\"\"\"\"\"\n    scores = [x[0] for x in results]\n    scores.sort(reverse=True)\n    plt.plot(scores)\n    if title: plt.title(title)\n    score = agg_results(results)\n    plt.xlabel('rank')\n    plt.ylabel('score')\n    plt.figtext(0.4, 1, f\"total L2 score: {score:.02f}\")\n    plt.show()\n\ndef display_result(result): \n    score,dist,i,html,meta = result\n    display(HTML(f\"\"\"\n            <h3>{meta['title']}<\/h3>\n            <p>\n                {meta['publish_time']} -- \n                {meta['journal']} -- \n                <a href=\"{meta['url']}\">link<\/a>\n            <\/p>\n            <p style=\"color:#AAAAAA\">\n                score:{score:.0f} --\n                dist:{dist:.03f} --\n                cord_uid:{meta['cord_uid']} -- \n                paragraph_id:{i}\n            <\/p>\n            {html}\n        \"\"\"))\n","c89a7ee2":"# criteria format explained in \"helper functions :: score_text docstring\"\n\ncriteria = [\n    # group 1: core keywords\n    1000.2,'mechanic\\w+ ventilat\\w+',\n    \n    # group 2: age related \n    100.5,'adjust','_age\\w?_','_years','_old',   'elder','young',\n\n    # group 3: negative outcomes\n    20.5,'nonsurviv','non-surviv','_died','dead','death','mortality','complication',\n    \n    # group 4: positive outcomes\n    2,'_surviv','discharge','extubate','alive',\n    \n    # group 5: estimator\n    10,'Kaplan.Meier','APACHE','SOFA','RIFLE','Glasgow.Coma','GCS','SAPS',\n       '_RESP_','RSBI','1000.person_',\n    \n    # group 6: generic data related keywords\n    50.1,'figure \\d+','_fig[.]\\s*\\d+','_table \\d+',\n    \n    # group 7: data related keywords\n    2,'outcome','result','cohort','median','_n\\s*=\\s*\\d+',\n      '(?<=[ (])\\d+ (?:patients|cases|men|women)',\n    \n    # group 8: covid-19\n    5000.1,'covid|sars-cov|cov-2|cov2'\n]\n\nstyle_by_group_id = {\n    1:'bg=#DDDDDD,w=bold', # grey\n    2:'bg=#FFFF00', # yellow\n    3:'bg=#FFAAAA', # red\n    4:'bg=#00FF00', # green\n    5:'bg=#FFCC00', # amber\n    6:'bg=#FFAAFF', # magenta\n    7:'bg=#00FFFF', # cyan\n    8:'fg=#FF0000,w=bold'\n}\ndefault_style = ''","0ced7426":"K = 50\nqueries = [\n        'Outcomes data for COVID-19 after mechanical ventilation adjusted for age',   \n        'Results for COVID-19 after mechanical ventilation adjusted for age',\n        'COVID-19 results after mechnical ventilation discharged dead died',\n        'COVID-19 results after mechnical ventilation discharged dead died survived survivors adjusted age years old',\n        'COVID-19 results after mechnical ventilation discharged died survived survivors extubated adjusted',\n        'COVID-19 results after mechnical ventilation discharged dead died survived survivors adjusted age years old',\n        'COVID-19 results after mechnical ventilation discharged died survived extubated adjusted',\n        'COVID-19 results after mechnical ventilation discharged died survived extubated adjusted age',\n        'COVID-19 outcomes after mechnical ventilation discharged died survived extubated adjusted',\n        'COVID-19 results outcomes after mechnical ventilation discharged died survived extubated adjusted age',\n        'COVID-19 results outcomes after mechnical ventilation discharged died survived extubated',\n        'COVID-19 results outcomes mechnical ventilation discharged died survived extubated',\n        'COVID-19 results outcomes after mechnical ventilation discharged died survived extubated adjusted',\n        'Covid-19 results outcomes after mechnical ventilation discharged died survived extubated adjusted',\n        'COVID-19 covid-19 results outcomes after mechnical ventilation discharged died survived extubated adjusted',\n        'COVID-19 results outcomes after mechnical ventilation discharged died survived extubated adjusted',\n        'COVID-19 results outcmes data after mechnical ventilation discharged died survived extubated adjusted age',\n        'COVID-19 results outcomes mechnical ventilation discharged died survived',\n        'COVID-19 results outcomes mechnical ventilation discharged died survived age',\n        'COVID-19 results outcomes mechnical ventilation discharged died survived age old',\n        'COVID-19 results outcomes mechnical ventilation discharged died survived adjusted age',\n        'COVID-19 results outcomes mechnical ventilation discharged died survived adjusted age old',\n        'COVID-19 results outcomes mechnical ventilation died survived',\n        'COVID-19 results outcomes mechnical ventilation died survived age',\n        'COVID-19 results outcomes mechnical ventilation died survived adjust age',\n        'COVID-19 results outcomes mechnical ventilation died survived adjusted age',\n]\n\nfor score,query in score_queries(queries, criteria, K):\n    print(f\"{score:10.02f} -- {query}\")\n","8da66777":"#query = 'Outcomes data for COVID-19 \/ SARS-CoV-2 after mechanical ventilation adjusted for age'\n#query = 'Outcomes data for COVID-19 after mechanical ventilation adjusted for age'\nquery = \"COVID-19 results outcomes mechnical ventilation died survived\"\n#query = \"Best telemedicine practices, barriers and faciitators, and specific actions to remove\/expand them within and across state boundaries\"\nK = 500\n\nq = model.text_to_dense(query)\nann_results = model.dense_ann_query(q, K)\nresults = score_ann_results(ann_results, criteria)\nplot_results(results, title='Query result score by rank (descencing scores)')\n","642a176c":"N = 20\nfor result in results[:N]:\n    display_result(result)","250f210a":"# criteria format explained in \"helper functions :: score_text docstring\"\n\ncriteria = [\n    # group 1: core keywords\n    1000.3,'adjunct','supportive','adjuvant',\n    \n    # group 2: specific treatments\n    200.5,'corticosteroid','steroid','high.flow','supplement','oxygen','_hormon','pharmac','antibiotic',\n    \n    # group 3: not used\n    0,\n    \n    # group 4: intervention\n    50.5,\n        'intervention',\n        'treatment',\n        'treating',\n        'therapy',   \n        'care',\n\n    # group 5: not used\n    10.5,\n        \"effectiv\",\"impact\",\"_reduc\",\"measure\",\n    \n    # group 6: generic data related keywords\n    50.1,'figure \\d+','_fig[.]\\s*\\d+','_table \\d+',\n    \n    # group 7: data related keywords\n    2,'outcome','result','cohort','median','_n\\s*=\\s*\\d+',\n      '(?<=[ (])\\d+ (?:patients|cases|men|women)',\n    \n    # group 8: covid-19\n    5000.1,'covid|sars-cov|cov-2|cov2'\n]\n\nstyle_by_group_id = {\n    1:'bg=#DDDDDD,w=bold', # grey\n    2:'bg=#FFFF00', # yellow\n    3:'bg=#FFAAAA', # red\n    4:'bg=#00FF00', # green\n    5:'bg=#FFCC00', # amber\n    6:'bg=#FFAAFF', # magenta\n    7:'bg=#00FFFF', # cyan\n    8:'fg=#FF0000,w=bold'\n}\ndefault_style = ''","93f07608":"K = 50\nqueries = [\n    \"Efforts to determine adjunctive and supportive interventions that can improve the clinical outcomes of infected patients (e.g. steroids, high flow oxygen)\",\n    \"COVID-19 Efforts to determine adjunctive and supportive interventions that can improve the clinical outcomes of infected patients (e.g. steroids, high flow oxygen)\",\n    \"COVID-19 Efforts to determine adjunctive and supportive intervention that can improve the clinical outcomes of infected patients (e.g. steroids, high flow oxygen)\",\n    \"COVID-19 adjunctive supportive adjuvant\",\n    \"COVID-19 adjunctive supportive adjuvant therapy intervention\",\n    \"COVID-19 adjunctive supportive adjuvant therapy interventions\",\n    \"COVID-19 adjunctive supportive adjuvant intervention\",\n    \"COVID-19 adjunctive supportive adjuvant therapy intervention treatment\",\n    \"COVID-19 adjunctive supportive adjuvant therapy intervention steroids\",\n    \"COVID-19 adjunctive supportive adjuvant therapy intervention steroid\",\n    \"COVID-19 adjunctive supportive adjuvant therapy intervention high flow oxygen\",\n    \"COVID-19 adjunctive supportive adjuvant therapy intervention high flow oxygen corticosteroids\",\n    \"COVID-19 adjunctive supportive adjuvant therapy intervention corticosteroids\",\n    \"COVID-19 adjunctive supportive adjuvant therapy intervention high-flow oxygen\",\n    \"COVID-19 adjunctive supportive adjuvant high-flow\",\n    \"COVID-19 adjunctive supportive adjuvant high-flow steroid\",\n    \"COVID-19 adjunctive supportive adjuvant high-flow steroids\",\n    \"COVID-19 adjunctive supportive adjuvant high-flow corticosteroids\",\n    \"COVID-19 adjunctive supportive adjuvant therapy intervention treatment high-flow\",\n    \"COVID-19 adjunctive supportive adjuvant high-flow oxygen corticosteroids\",\n    'COVID-19 adjunctive supportive adjuvant intervention high flow oxygen care',\n    'COVID-19 adjunctive supportive adjuvant adjunct therapy intervention high-flow oxygen',\n    'SARS-CoV-2 COVID-19 adjunctive supportive adjuvant adjunct therapy intervention high-flow oxygen',\n    'SARS-CoV-2 adjunctive supportive adjuvant adjunct therapy intervention high-flow oxygen',\n    \"SARS-CoV-2 COVID-19 adjunctive supportive adjuvant\",\n    \"SARS-CoV-2 adjunctive supportive adjuvant\",\n]\n\nfor score,query in score_queries(queries, criteria, K):\n    print(f\"{score:10.02f} -- {query}\")","f8409376":"#query = \"COVID-19 adjunctive supportive adjuvant high-flow oxygen corticosteroids\"\n#query = \"COVID-19 adjunctive supportive adjuvant therapy intervention\"\n#query = \"COVID-19 adjunctive supportive adjuvant high-flow\"\n#query = \"COVID-19 adjunctive supportive adjuvant therapy intervention high flow oxygen\"\nquery = \"COVID-19 adjunctive supportive adjuvant adjunct therapy intervention high-flow oxygen\"\nK = 500\n\nq = model.text_to_dense(query)\nann_results = model.dense_ann_query(q, K)\nresults = score_ann_results(ann_results, criteria)\nplot_results(results, title='Query result score by rank (descencing scores)')","3eaee119":"N = 20\nfor result in results[:N]:\n    display_result(result)","23221817":"# criteria format explained in \"helper functions :: score_text docstring\"\n\ncriteria = [\n    # group 1: core keywords\n    1000.3,'tele-','tele','_remot',\n    \n    # group 2: technology related\n    200.5, 'video','conferenc','collabor','_web_','_web-','smartphone','_call',\n           'wearable','cyber','electronic','cell phone','network','internet',\n    \n    # group 3: not used\n    0,\n    \n    # group 4: not used\n    50.5,\n\n\n    # group 5: not used\n    10.5,\n    \n    # group 6: generic data related keywords\n    50.1,'figure \\d+','_fig[.]\\s*\\d+','_table \\d+',\n    \n    # group 7: not used\n    2,\n    \n    # group 8: covid-19\n    2000.1,'covid|sars-cov|cov-2|cov2'\n]\n\nstyle_by_group_id = {\n    1:'bg=#DDDDDD,w=bold', # grey\n    2:'bg=#FFFF00', # yellow\n    3:'bg=#FFAAAA', # red\n    4:'bg=#00FF00', # green\n    5:'bg=#FFCC00', # amber\n    6:'bg=#FFAAFF', # magenta\n    7:'bg=#00FFFF', # cyan\n    8:'fg=#FF0000,w=bold'\n}\ndefault_style = ''","f201a143":"K = 50\nqueries = [\n    \"Best telemedicine practices, barriers and faciitators, and specific actions to remove\/expand them within and across state boundaries\",\n    'telemedicine',\n    'tele telemedicine',\n    'telemedicine remote access',\n    'telemedicine remotely',\n    'telephone',\n    'telephone telehealth telemedicine',\n    'telephone telemedicine',\n    'telephone telehealth',\n    'telehealth',\n    'homecare',\n    'telemedicine homecare',\n    'telemedicine telehealth homecare',\n    'telemedicine telehealth homecare teletriage',\n    'teletriage',\n    'telemedicine remotely telehealth homecare',\n    'telemedicine remotely web-based',\n    'telemedicine remotely web',\n    'telemedicine remotely collaborative',\n    'teleconsultation',\n    'remotely',\n]\n\nfor score,query in score_queries(queries, criteria, K):\n    print(f\"{score:10.02f} -- {query}\")\n\n# telephone gives good score but bad results","d6ee7a8e":"#query = \"telemedicine\"\n#query = \"telemedicine telehealth homecare\"\nquery = \"telemedicine remotely\"\nK = 1500\n\nq = model.text_to_dense(query)\nann_results = model.dense_ann_query(q, K)\nresults = score_ann_results(ann_results, criteria)\nplot_results(results, title='Query result score by rank (descencing scores)')","d4061318":"N = 20\nfor result in results[:N]:\n    display_result(result)","4736d998":"# criteria format explained in \"helper functions :: score_text docstring\"\n\ncriteria = [\n    # group 1: core keywords\n    1000.4,'ARDS','etiolog',\n    \n    # group 2: age related \n    100.4,'adjust','_age\\w?_','_years','_old',   'elder','young',\n\n    # group 3: negative outcomes\n    500.5,'nonsurviv','non-surviv','_died','dead','death','mortality',\n\n    # group 4:\n    0,\n    \n    # group 5: \n    100.3,'organ','failure','dysfunction',\n    \n    # group 6: generic data related keywords\n    50.1,'figure \\d+','_fig[.]\\s*\\d+','_table \\d+',\n    \n    # group 7: data related keywords\n    2,'outcome','result','cohort','median','_n\\s*=\\s*\\d+',\n      '(?<=[ (])\\d+ (?:patients|cases|men|women)',\n    \n    # group 8: covid-19\n    1000.1,'covid|sars-cov|cov-2|cov2'\n]\n\nstyle_by_group_id = {\n    1:'bg=#DDDDDD,w=bold', # grey\n    2:'bg=#FFFF00', # yellow\n    3:'bg=#FFAAAA', # red\n    4:'bg=#00FF00', # green\n    5:'bg=#FFCC00', # amber\n    6:'bg=#FFAAFF', # magenta\n    7:'bg=#00FFFF', # cyan\n    8:'fg=#FF0000,w=bold'\n}\ndefault_style = ''","6a157fd7":"K = 50\nqueries = [\n    \"Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with\/without other organ failure \u2013 particularly for viral etiologies\",\n    \"COVID-19 Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with\/without other organ failure \u2013 particularly for viral etiologies\",\n    \"COVID-19 ARDS failure etiology etiologies\",\n    \"COVID-19 ARDS failure etiology\",\n    \"COVID-19 ARDS failure etiologies\",\n    \"COVID-19 ARDS organ failure etiology etiologies\",\n    \"COVID-19 ARDS organ failure etiology\",\n    \"COVID-19 ARDS organ failure etiologies\",\n    \"ARDS failure etiology etiologies\",\n    \"ARDS failure etiology\",\n    \"ARDS failure etiologies\",\n    \"ARDS organ failure etiology etiologies\",\n    \"ARDS organ failure etiology\",\n    \"ARDS organ failure etiologies\",\n    \"ARDS organ failure virus etiologies\",\n    \"ARDS organ failure viral etiologies\",\n    \"ARDS organ failure etiologies died survived\",\n    \"ARDS organ failure mortality\",\n    \"ARDS mortality\",\n]\n\nfor score,query in score_queries(queries, criteria, K):\n    print(f\"{score:10.02f} -- {query}\")","e0a38f38":"#query = \"Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with\/without other organ failure \u2013 particularly for viral etiologies\"\n#query = \"COVID-19 Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with\/without other organ failure \u2013 particularly for viral etiologies\"\n#query = \"ARDS failure etiology\"\nquery = \"ARDS mortality\"\nK = 500\n\nq = model.text_to_dense(query)\nann_results = model.dense_ann_query(q, K)\nresults = score_ann_results(ann_results, criteria)\nplot_results(results, title='Query result score by rank (descencing scores)')","88dd1db7":"N = 20\nfor result in results[:N]:\n    display_result(result)","3f11352a":"do_recalc = False\n\n# Number of json files to read\n# Setting this variable to None will read all files\npapers_limit = 100\n\n# Number of worker processes for calculation of sparse and dense vectors\nworkers = 1\n\n# Memory\/disk tradeoff controls\n# \n# Possible values:\n#\n#   disk - data is stored only on disk, index is stored in memory\n#          slower access BUT multiprocesing is possible (workers>1)\n#          requires little RAM but alot of DISK\n#\n#   mem - data is stored in memory\n#         faster access and fast recalculation time\n#         requires alot of DISK and RAM\n#\n#   mem_only - data is stored in memory, data is not persisted when calling .save()\n#              faster access and fastest recalculation time\n#              BUT data will not be saved on disk\n#              requires little DISK but alot of RAM\n#\n# when workers>1 all values are asummed to be 'disk'\nmeta_storage   = 'disk'\nbow_storage    = 'mem_only'\nsparse_storage = 'mem_only'\ndense_storage  = 'mem_only'\n","0cfc4919":"# ---[ list ]-------------------------------------------------------------------\n\nimport os\n\ndef list_data_files():\n    \"\"\"iterate over paths of all data files\"\"\"\n    for dirpath,_,filenames in os.walk('\/kaggle\/input\/CORD-19-research-challenge\/'):\n        filenames = [f for f in filenames if f.endswith('.json')]\n        if not filenames: continue\n        for f in filenames:\n            yield os.path.join(dirpath,f)\n\n# ---[ convert ]----------------------------------------------------------------\n\nimport json\n\ndef json_to_docs(path):\n    \"\"\"iterate over paragraph level documents from one json document\"\"\"\n    paper = json.load(open(path,'rb'))\n    # parts\n    text_id = 0\n    for part in ['abstract','body_text']:\n        if part not in paper: continue\n        for x in paper[part]:\n            doc = {}\n            # metadata\n            doc['paper_id'] = paper['paper_id']\n            doc['paper_title'] = paper['metadata']['title']\n            doc['path'] = path\n            doc['part'] = part\n            text_id += 1\n            doc['text_id'] = text_id\n            #\n            doc['text'] = x['text']\n            doc['section'] = x['section']\n            # bib\n            doc['bib_titles'] = []\n            for ref in x['cite_spans']:\n                ref_id = ref['ref_id']\n                if not ref_id: continue \n                ref_title = paper['bib_entries'][ref_id]['title'] # ERROR\n                doc['bib_titles'] += [ref_title]\n            # ref (tables and figures)\n            doc['tables'] = []\n            doc['figures'] = []\n            for ref in x['ref_spans']:\n                ref_id = ref['ref_id']\n                if not ref_id: continue\n                r = paper['ref_entries'][ref_id] # ERROR\n                if r['type']=='table':\n                    doc['tables'] += [r['text']]\n                if r['type']=='figure':\n                    doc['figures'] += [r['text']]\n            yield doc\n\ndef doc_iter(limit=None):\n    \"\"\"iterate over all documents (doc = single paragraph)\"\"\"\n    from itertools import islice\n    for path in islice(list_data_files(),limit):\n        yield from json_to_docs(path)\n\ndef get_doc(path,text_id):\n    \"\"\"get single document (paragraph)\"\"\"\n    docs = json_to_docs(path)\n    for doc in docs:\n        if doc['text_id']==text_id:\n            return doc\n","ba5e144c":"import numpy as np\n\nprune_cfg = {\n    'no_below': 2,\n    'no_above': 0.50,\n    'keep_tokens': ['<PAD>','<DNA>'],\n    'stopwords': [],\n}\n\ntfidf_cfg = {'smartirs':'ltu'}\n\nlsi_cfg = {\n    'num_topics': 100,\n    'dtype': np.single,\n    'onepass': False,\n}\n\n\ndef doc_to_text(doc):\n    values = [\n            doc['text'],\n            doc['section'],\n            '\\n'.join(doc['tables']),\n            '\\n'.join(doc['figures']),\n            '\\n'.join(doc['bib_titles'])\n        ]\n    return '\\n'.join(values)\n\n\ndef get_meta(id,doc):\n    m = {f:doc[f] for f in ['paper_id','text_id','path']}\n    m['id'] = id # DEBUG\n    return m\n\n\ndef get_doc_by_meta(meta):\n    path = meta['path']\n    text_id = meta['text_id']\n    return get_doc(path,text_id)\n\n# ------------------------------------------------------------------------------\n\nimport re\n\nsplit_tokens_re = re.compile('[\\s.,;!?()\\[\\]]+')\nupper_re = re.compile('[A-Z]')\nnum_re = re.compile('\\d+|\\d+[%]|\\d+[a-z]|[#]\\d+|[~]\\d+')\nurl_re = re.compile('[hH][tT][tT][pP][sS]?:\/\/[a-zA-Z._0-9\/=&?,|%-]+')\ndna_re = re.compile('[AGCT]{8,}')\n\ndef text_to_tokens(text):\n    text = url_re.sub('<URL>',text)\n    tokens = split_tokens_re.split(text)\n    tokens = [t.lower() if len(t)>1 and len(upper_re.findall(t))<2 else t for t in tokens]\n    tokens = ['<NUM>' if num_re.match(t) else t for t in tokens]\n    tokens = ['<DNA>' if dna_re.match(t) else t for t in tokens]\n    return tokens\n","472b1436":"from pprint import pprint\nfrom itertools import islice\nfrom time import time\nimport inverness\n\nif do_recalc:\n    t0 = time()\n    \n    label = papers_limit or 'all'\n    model = inverness.Model(f'model_{label}_v7\/')\n\n    model.text_to_tokens = text_to_tokens\n    model.doc_to_text = doc_to_text\n    model.get_doc_by_meta = get_doc_by_meta\n    model.doc_iter = lambda:doc_iter(papers_limit)\n    model.get_meta = get_meta\n    model.init_fun()\n    #\n    model.init_meta(storage='disk' if workers>1 else meta_storage)\n    model.skip_phraser()\n    model.skip_phrased()\n    model.init_dictionary()\n    model.prune_dictionary(**prune_cfg)\n\n    if workers<=1:\n        model.init_bow(storage=bow_storage)\n        model.phrased.delete() # del\n        model.init_tfidf(**tfidf_cfg)\n        model.init_sparse(storage=sparse_storage)\n        model.bow.delete() # del\n        model.init_lsi(**lsi_cfg)\n        model.init_dense(storage=dense_storage)\n    else:\n        model.init_bow(storage='disk')\n        model.phrased.delete() # del\n        model.init_tfidf(**tfidf_cfg)\n        model.init_sparse_mp(workers)\n        model.bow.delete() # del\n        model.init_lsi(**lsi_cfg)\n        model.init_dense_mp(workers)\n\n    model.sparse.delete() # del\n    model.init_dense_ann(post=2)\n    model.dense.delete() # del\n    \n    print(f'\\n\\ntotal: {time()-t0:.01f}s\\n\\n')\n","635b929d":"N = 100\nk = 1\n\ndef test_model(ids,fun,k=1):\n    ok_cnt = 0\n    for i in ids:\n        m = model.meta[i]\n        query = model.doc_to_text(model.get_doc_by_meta(m))\n        top = list(fun(query))[:k] # id,score,m\n        top_ids = [x[0] for x in top]\n        if i in top_ids:\n            ok_cnt += 1\n    return ok_cnt \/ len(ids)\n\nfrom random import randint\nids = [randint(0,len(model.meta)-1) for _ in range(N)]\nscore = test_model(ids, model.find_dense, k)\nprint(f'find_dense_score: {score:.03f}\\ndocuments: {len(model.meta)}')\n","d57d4994":"# <a id=\"task2\"><\/a> Efforts to determine adjunctive and supportive interventions that can improve the clinical outcomes of infected patients (e.g. steroids, high flow oxygen)\n\n## Scoring criteria","4b8cd725":"## Final Query","e96f4126":"### Model recalculation","d995fa5d":"## <a id=\"results2\"><\/a> Results","4ef5c2b0":"# <a id=\"task1\"><\/a> Outcomes data for COVID-19 after mechanical ventilation adjusted for age\n\n## Scoring criteria\n\nWe will use weighted regular expressions (regexp) grouped by various aspects of the query.\n\n\nWe will **highlight** different aspects of the query using following color codes:\n- **green** - positive outcome\n- **red** - negative outcome\n- **amber** - estimator\n- **yellow** - age related\n- **cyan** - outcome \/ result\n- **magenta** - table \/ chart \/ figure\n- **bold** - core keyword\n","b92d1830":"## Final Query","89de018c":"### Core options","ef84d977":"### Model health check\n\nWe can check health of the model by trying to find random documents by their content.\n\nIf the document occurs within top k=1 results we count this as a success.\n\nWe repeat this process N=100 times and average the score.","553b8826":"## <a id=\"results4\"><\/a> Results","91f9b7f8":"## Query selection","593c1119":"# Model recalculation <a id=\"recalculation\"><\/a>\n\nBy default this notebook **will not** recalculate the model - it uses precalculated model loaded from disk (additional dataset defined in the notebook). To recalculate the model variable \"do_recalc\" must be set to True.\n\n\nBy default only 100 papers will be used in recalculation as full model recalculation will take several hours. To recalculate the model using all the papers the \"papers_limit\" variable must be set to None.\n\n**!!! IMPORTANT !!!** After 2020-03-27 input dataset update recalculating the model for all the papers is impossible on kaggle - depending on the model storage settings we exceed HDD or RAM quota :( The model imported at the begining of this notebook was precalculated on the PC.\n","873c7aea":"## Final Query","f5443d2d":"## <a id=\"results3\"><\/a> Results","af49ae97":"### Data access functions","e5fce903":"### Helper functions","4ff51bfb":"### Model configuration","0848bc40":"### Instalation of required packages","44765f42":"### Standard imports","66c65da6":"# Notebook structure\n\n- [Approach description](#approach)\n  - [Overview](#overview)\n  - [Pros and Cons](#pros_cons)\n  - [More detailed description of the approach](#details)\n- [Common section for all sub-tasks](#common)\n- [Outcomes data for COVID-19 after mechanical ventilation adjusted for age](#task1)\n  - [results](#results1)\n- [Efforts to determine adjunctive and supportive interventions that can improve the clinical outcomes of infected patients (e.g. steroids, high flow oxygen)](#task2)\n  - [results](#results2)\n- [Best telemedicine practices, barriers and faciitators, and specific actions to remove\/expand them within and across state boundaries.](#task3)\n  - [results](#results3)\n- [Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with\/without other organ failure \u2013 particularly for viral etiologies](#task4)\n  - [results](#results4)\n- [Model recalculation](#recalculation)\n","b213cd6b":"# Approach description <a id=\"approach\"><\/a>\n\n## Overview <a id=\"overview\"><\/a>\n\nWe will:\n- use **LSI** (Latent Semantic Indexing)\n- to convert **paragraphs** from papers into fixed-length vectors\n- and store them in **ANN** (Approximate Nearest Neighbour) index\n\nNext, we will:\n- convert the **query** (task related question) into fixed-length vector using **LSI**\n- query the **ANN** index for nearest neighbours\n- score the results with **weighted regexp criteria**\n- and **highlight** text within top results\n- using **color coding** of different aspects of the query\n\n### Example output\n\n![obraz.png](attachment:obraz.png)\n\n## Pros and Cons <a id=\"pros_cons\"><\/a>\n\n### Pros\n\n- Coloured highlight enables fast assesment of the paragraph and extraction of key informations\n- Displaying full paragraphs in the output (instead of filtered sentences) gives better context and minimizes the risk of ommiting important information\n- Natural language queries can be used (although keyword based queries seem to do better)\n- Querying the ANN index is fast - it allows rapid testing of various queries \/ criteria.\n\n### Cons\n\n- Criteria weights require carefull tuning\n- Criteria patterns require manual handling of synonymes\n- Displaying full paragraphs in the output (instead of filtered sentences) makes analysis of the results more time consuming \n\n## More detailed description of the approach <a id=\"details\"><\/a>\n\nThe model uses Inverness package which wraps Gensim and NMSLIB.\n\nModel creation steps:\n- every json file is converted into collection of documents\n- each document represents one paragraph from the paper\n- text from the paragraph is tokenized\n- tokenized documents are used to create a dictionary\n- dictionary is pruned to omit too frequent and too rare words\n- tokenized documents and the dictionary are used to create Bag Of Words (BOW) representation of the documents\n- documents in BOW formats are used to create TFIDF weighting scheme\n- documents in BOW format and TFIDF weights are used to create sparse \/ variable length vector representation of the documents\n- sparse represetation is used to calculate Latant Semantic Indexing (LSI) transformation\n- sparse representation and LSI transformation is used to create dense \/ fixed length vector representation of documents\n- dense representation is used to create Approximate Nearest Neighbour (ANN) index that uses HNSW algorithm and uses cosine similarity space\n\nModel query steps:\n- natural language or keyword based query is converted into dense \/ fixed length vector representation \n- ANN index is used to return N nearest documents (using cosine distance)\n- each document is scored using weighted regular expressions (called criteria, see helper functions :: score_text docstring)\n- documents with the best score are displayed to the user\n- selected document fragments are highlighted using different styles\n- styles are related to different aspects of the criteria (death related, age related, estimator related, data related etc)\n\n\n## Other tested approaches\n\nThe following methods were tested and found to be subjectively inferior:\n- sparse ANN index query (TFIDF weighted BOW - without LSI)\n- reverse index query using set of keywords aquired from regexp matching dictionary items to core keywords patterns\n","78453c82":"### Paper metadata","815844ea":"# <a id=\"task4\"><\/a> Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with\/without other organ failure \u2013 particularly for viral etiologies\n\n## Scoring criteria","026d422b":"## Query selection\n\nAlthough we can query our model using verbatim task questions, we should compare the results with the results of a keyword-based query.\n\nWe will score different queries (including verbatim task question) using criteria defined above.\n\nFor each query we:\n- fetch K=50 paragraphs closest to the query (using ANN)\n- score each paragraph using scoring criteria (regexps and weights)\n- calculate aggregate score for the query (L2 measure)","c4a046f7":"## Query selection","0c216828":"## <a id=\"results1\"><\/a> Results","15158e6c":"## Query selection","0fbbdd2f":"# <a id='task3'><\/a> Best telemedicine practices, barriers and faciitators, and specific actions to remove\/expand them within and across state boundaries.\n\n## Scoring Criteria","6b1dc993":"# Common section for all sub-tasks <a id=\"common\"><\/a>","86598bf8":"### Model load","d75ab31a":"## Final query"}}