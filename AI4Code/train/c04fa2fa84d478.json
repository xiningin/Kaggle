{"cell_type":{"570f5d5b":"code","60655c76":"code","966bc505":"code","a852fb86":"code","0586ff58":"code","b8a67903":"code","da0a4360":"code","2bbb4be5":"code","40334c9e":"code","b6704b56":"code","fd43cc65":"code","0cdc3678":"code","320ff11e":"code","af34f64f":"code","d50273c6":"code","f1aaa8c5":"code","08e39e5f":"code","9e0f43ad":"code","3b40fd08":"code","660baebb":"code","d1d1e1cb":"code","ed746715":"code","7fa3ee07":"code","f64bc331":"code","ef6a10ac":"markdown","dd5fa3c6":"markdown"},"source":{"570f5d5b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","60655c76":"data_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ngender = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\ndata_train.head()","966bc505":"# Ceck data\nprint('Data train null: ')\nprint(data_train.isnull().sum())\nprint('-'*30)\nprint('shape data :{}'.format(data_train.shape))","a852fb86":"# Data preprocessing\n# data_train['Age'] n\/a replaced with mean()\ndata_train['Age'] = data_train['Age'].fillna(data_train['Age'].mean())\ndata_train['Cabin'] = data_train['Cabin'].fillna('')\ndata_train['Embarked'] = data_train['Embarked'].fillna('')\ndata_train.describe()","0586ff58":"sns.displot(data=data_train, x='Sex', hue='Survived')\nsns.displot(data=data_train, x='Age', hue='Survived')","b8a67903":"# Change data age\n\ndata_train['Age']=data_train['Age'].apply(lambda x: 0 if x<22 else (1 if x<35 else 2))","da0a4360":"# preprocessing.. change feature to int \nfrom sklearn.preprocessing import OrdinalEncoder\n\ndata_train_1=data_train.copy()\nord_enc = OrdinalEncoder()\ncolumns=['Sex','Ticket','Cabin','Embarked','Name']\n\nfor x in columns:\n    data_train_1[x] = ord_enc.fit_transform(data_train_1[[x]])\ndata_train_1.head()","2bbb4be5":"# Data normalized\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nscaler.fit(data_train_1)\ndata_normalized=pd.DataFrame(scaler.transform(data_train_1),columns=data_train_1.columns)\ndata_normalized.head()","40334c9e":"# Correlation\nplt.figure(figsize=(16, 6))\nsns.heatmap(data_normalized.corr(),annot=True)","b6704b56":"# split data\nfrom sklearn.model_selection import train_test_split\n\nX=data_normalized.drop(['Survived'], axis=1)\n\ny=data_normalized['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","fd43cc65":"# feature selection data dengan chi2\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2,mutual_info_classif\n\n\nselector=SelectKBest(chi2,k=5) # chi2 or mutual_info_classif\nselector.fit(X_train,y_train)\nX_train_new=selector.transform(X_train)\nX_test_new=selector.transform(X_test)\n\nselected_columns=[]\nfor i,j in zip(X.columns,selector.get_support()):\n    if j==True:\n        selected_columns.append(i)\nselected_columns","0cdc3678":"# model 1 (NB)\nfrom sklearn.naive_bayes import GaussianNB,CategoricalNB,BernoulliNB,MultinomialNB\n\nmodel1=GaussianNB() # hasil gausian dll sama\nmodel1.fit(X_train_new,y_train)\nmodel1.score(X_test_new,y_test)","320ff11e":"# model 2 (KNN)  \nfrom sklearn.neighbors import KNeighborsClassifier\n\nmodel2 = KNeighborsClassifier(n_neighbors=7, metric='euclidean')\n\nmodel2.fit(X_train_new,y_train)\n\nprint(model2.score(X_test_new,y_test))","af34f64f":"# Super Vector Machine\nfrom sklearn.svm import SVC\n\nmodel3 = SVC(kernel='linear',decision_function_shape='ovr')\nmodel3.fit(X_train_new,y_train)\nprint (model3.score(X_test_new,y_test))","d50273c6":"# Neural network\nfrom sklearn.neural_network import MLPClassifier\nmodel4=MLPClassifier(hidden_layer_sizes=(50,50,50),activation='relu',max_iter=1000)\n\nmodel4.fit(X_train_new, y_train)\nprint(model4.score(X_test_new,y_test))","f1aaa8c5":"# xgboost\nfrom xgboost.sklearn import  XGBClassifier\n\nmodel5 = XGBClassifier(\n learning_rate =0.1,\n n_estimators=1000,\n max_depth=4,\n min_child_weight=6,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread=4,\n scale_pos_weight=1,\n seed=27)\nmodel4.fit(X_train_new, y_train)\nprint(model4.score(X_test_new,y_test))","08e39e5f":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2,mutual_info_classif\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nimport joblib\nfrom sklearn.preprocessing import OrdinalEncoder\n\ndata1=data_train.copy()\nord_enc = OrdinalEncoder()\ncolumns=['Sex','Ticket','Cabin','Embarked','Name']\n\nfor x in columns:\n    data_train_1[x] = ord_enc.fit_transform(data_train_1[[x]])\n\nX = data_train_1.drop(['Survived'], axis=1)\n\ny = data_train_1['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\nestimators= [(\"selector\",SelectKBest(chi2,k=5)),\n             (\"scaler\",MinMaxScaler()),\n             (\"classifier\",MLPClassifier(hidden_layer_sizes=(50,50,50),activation='relu',max_iter=1000))\n    \n]\npipe=Pipeline(estimators)\npipe.fit(X_train,y_train)\n\nwith open('pipeline.pkl','wb') as f:\n    joblib.dump(pipe,f)\n","9e0f43ad":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,pipe.predict(X_test)))\n\nprint('test_score : {}'.format(pipe.score(X_test,y_test)))","3b40fd08":"# data test\ndata_test.isna().sum()","660baebb":"data_test['Age']=data_test['Age'].fillna(data_test['Age'].mean())\ndata_test['Cabin']=data_test['Cabin'].fillna('')\ndata_test['Fare']=data_test['Fare'].fillna(data_test['Fare'].mean())\ndata_test['Age']=data_test['Age'].apply(lambda x: 0 if x<22 else (1 if x<35 else 2))","d1d1e1cb":"data_test_1=data_test.copy()\nord_enc = OrdinalEncoder()\ncolumns=['Sex','Ticket','Cabin','Embarked','Name']\n\nfor x in columns:\n    data_test_1[x] = ord_enc.fit_transform(data_test_1[[x]])\n\ndata_test_1.head()","ed746715":"data_test_1['Survived']=pipe.predict(data_test_1)\n\ndata_test_1.head()\n","7fa3ee07":"predict=data_test_1[['PassengerId','Survived']]\npredict.to_csv('result.csv', index=False)\nresult=data_test.copy()\nresult=result.merge(predict, on='PassengerId', how='left')\n\nresult.head()","f64bc331":"predict.head()","ef6a10ac":"From table: parch, fare and Cabin have positif corelation (fare and cabin have much correlation)\n            high number of class (lower class) ad female have negatif relationship","dd5fa3c6":"Best model: Neural network with MLPClassifier, feature selection: chi2 k=4 : 0.826"}}