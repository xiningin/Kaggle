{"cell_type":{"01bff93d":"code","f2a7adf5":"code","eaa5ad25":"code","f148adb1":"code","9fecf383":"code","09251aa4":"code","fd64453b":"code","6a2e4c13":"code","603e8fd5":"code","1eb52c65":"code","07330a51":"code","09ae4a55":"code","a545d4a5":"code","b55b6dec":"markdown","fe3fb670":"markdown","833e723d":"markdown","b71e83e3":"markdown","672dbd8a":"markdown","2ab26e1f":"markdown","b8b983b7":"markdown","cc00d22c":"markdown"},"source":{"01bff93d":"import requests\nimport pandas as pd\nfrom bs4 import BeautifulSoup\n\nclass HTMLTableParser:\n\n    def parse_url(self, url):\n        response = requests.get(url)\n        #print(response)\n        soup = BeautifulSoup(response.text, 'html')\n        #print(soup)\n        return [(self.parse_html_table(table))\\\n            for table in soup.find_all('table')]  \n\n    def parse_html_table(self, table):\n        #print(\"new table\")\n        n_columns = 0\n        n_rows=0\n        column_names = []\n\n        # Find number of rows and columns\n        # we also find the column titles if we can\n        for row in table.find_all('tr'):\n\n            # Determine the number of rows in the table\n            td_tags = row.find_all('td')\n            if len(td_tags) > 0:\n                n_rows+=1\n                if n_columns == 0:\n                    # Set the number of columns for our table\n                    n_columns = len(td_tags)\n\n            # Handle column names if we find them\n            th_tags = row.find_all('th') \n            if len(th_tags) > 0 and len(column_names) == 0:\n                for th in th_tags:\n                    column_names.append(th.get_text())\n\n        df = pd.DataFrame() \n        try:                    \n            # Safeguard on Column Titles\n            if len(column_names) > 0 and len(column_names) != n_columns:\n                raise Exception(\"Column titles do not match the number of columns\")\n\n            columns = column_names if len(column_names) > 0 else range(0,n_columns)\n\n            #print(n_rows, n_columns)\n            df = pd.DataFrame(columns = columns,\n                  index= range(0,n_rows))\n\n            row_marker = 0\n            for row in table.find_all('tr'):\n                column_marker = 0\n                columns = row.find_all('td')\n\n                for column in columns:\n                    df.iat[row_marker,column_marker] = column.get_text()\n                    column_marker += 1\n                if len(columns) > 0:\n                    row_marker += 1\n\n            # Convert to float if possible\n            for col in df:\n                    df[col] = df[col]\n        except Exception as ex:\n            print(ex)\n            pass\n        #df.head(10)\n        return df\n","f2a7adf5":"url_data =\\\n    [('2020-04-02',\"https:\/\/www.mai.gov.ro\/informare-covid-19-grupul-de-comunicare-strategica-2-aprilie-ora-13-00\/\"),\n    ('2020-04-03',\"https:\/\/www.mai.gov.ro\/informare-covid-19-grupul-de-comunicare-strategica-3-aprilie-2020-ora-13-00\/\"),\n    ('2020-04-04',\"https:\/\/www.mai.gov.ro\/informare-covid-19-grupul-de-comunicare-strategica-4-aprilie-2020-ora-13-00\/\")]","eaa5ad25":"hp = HTMLTableParser()\nall_data_df = pd.DataFrame()\nfor current_date, current_url in url_data:\n    tables = hp.parse_url(current_url)\n    payload_table = tables[0]\n    print(payload_table.shape)\n    payload_table['date'] = current_date\n    payload_table = payload_table.iloc[1:]\n    payload_table = payload_table.iloc[:-1]\n    \n    all_data_df = all_data_df.append(payload_table)\nall_data_df.columns = ['No', 'County', 'Confirmed', 'Date']","f148adb1":"print(f\"{all_data_df.shape}\")","9fecf383":"all_data_df.County.unique()","09251aa4":"all_data_df = all_data_df.loc[~(all_data_df.County=='\u2013')]\nall_data_df = all_data_df.loc[~(all_data_df.Confirmed=='\u2013')]","fd64453b":"all_data_df.County.unique()","6a2e4c13":"all_data_df.Date.unique()","603e8fd5":"all_data_df.Confirmed = all_data_df.Confirmed.astype(int)","1eb52c65":"all_data_df.tail()","07330a51":"import pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport datetime as dt\n%matplotlib inline\nimport datetime as dt\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\ndef plot_bars_time_variation(d_df, feature_x, feature_y, title, color='Red'):\n    \n    hover_text = []\n    for index, row in d_df.iterrows():\n        hover_text.append(('Date: {}<br>'+\n                          'Confirmed cases: {}<br>'+\n                          'County: {}').format(row['Date'],row['Confirmed'], row['County']))\n    d_df['hover_text'] = hover_text\n\n    d_df['text'] = hover_text\n    trace = go.Bar(\n        x = d_df[feature_x],y = d_df[feature_y],\n        name=feature_y,\n        marker=dict(color=color),\n        text = hover_text\n    )\n\n    data = [trace]\n    layout = dict(title = title,\n              xaxis = dict(title = feature_x, showticklabels=True), \n              yaxis = dict(title = title),\n              hovermode = 'closest'\n             )\n    fig = dict(data=data, layout=layout)\n    iplot(fig, filename='cases-covid19')\n","09ae4a55":"data_df = all_data_df.loc[all_data_df.Date == '2020-04-04']\nplot_bars_time_variation(data_df, 'County', 'Confirmed', 'Confirmed cases \/ county [2020-04-04]')","a545d4a5":"data_df = pd.DataFrame(all_data_df.groupby(['Date'])['Confirmed'].sum()).reset_index()\ndata_df['County'] = 'All'\ndata_df.columns = ['Date', 'Confirmed', 'County']\nplot_bars_time_variation(data_df, 'Date', 'Confirmed', 'Confirmed cases \/ date')","b55b6dec":"The errors reported are from parsing one table that we are not interested in.","fe3fb670":"Our method included as well the headers for the tables. We will remove these rows.","833e723d":"# Prepare extraction\n\nIn order to extract the data, we will use an utility modified from [Parsing HTML Tables in Python with BeautifulSoup and pandas](https:\/\/srome.github.io\/Parsing-HTML-Tables-in-Python-with-BeautifulSoup-and-pandas\/).\n","b71e83e3":"We initialize the HTMLTableParser object. We then parse the tables in all the list of urls, and we just retain and concatenate our main payload table, a table with number of confirmed cases \/ county.  \n\nWe also filter out the first rows (with the header - containing the column names) and the last row (the summary, or footer) from each page.","672dbd8a":"# Run the extraction\n\nWe define a small table with the list of dates and corresponding urls.","2ab26e1f":"# Check the data","b8b983b7":"<h1>Extract Covid Data Dynamically from Romanian Authorities Official Comms<\/h1>\n\nBecause Romanian authorities are not exposing directly the data, we will have to scrap this data from their official communication site, [here](https:\/\/www.mai.gov.ro\/).\n\nWe intend to retrieve the County-level data for Romania.","cc00d22c":"# Visualize the data"}}