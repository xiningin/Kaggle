{"cell_type":{"f25c2a37":"code","ff07c48e":"code","860a99d7":"code","f1f574a1":"code","6a8d6fbc":"code","86284f45":"code","38c15bb8":"code","34b7b5b1":"code","03df6a3c":"code","41153a00":"code","104a1c1b":"code","be510d37":"code","d351027e":"code","19ea00e2":"code","c5e214bb":"code","1f1afd7b":"code","3b97ee3a":"code","54fac23c":"code","49a4a143":"code","498266fa":"code","e48dc826":"code","66404459":"code","e8c9a437":"code","666f5187":"code","aa43d674":"code","1c1a05eb":"markdown","25846357":"markdown","22fdbf7b":"markdown","cb698433":"markdown","7bd15c55":"markdown","b4f5ddf6":"markdown","088d7ced":"markdown","5578ac27":"markdown","443c294f":"markdown","e30f23df":"markdown","2fad49c4":"markdown","6178bed3":"markdown","60ad0a83":"markdown","f9d3487a":"markdown","e015dc02":"markdown","291ccd24":"markdown","1f47b23c":"markdown","57aac1aa":"markdown","3fe5ee45":"markdown","f579e2ab":"markdown","0cd88487":"markdown","0242d286":"markdown"},"source":{"f25c2a37":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Oct 13 23:01:47 2019\n\n@author: akabbadj\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport random\n\n#Chargement du dataset\ndata=pd.read_csv(\"\/kaggle\/input\/atpdata\/ATP.csv\")\n# liste des variables\nprint(data.info())\n\n# pourcentage des variables renseign\u00e9es\nnbdata=len(data)\nprint(nbdata)\nprint((1-(data.isnull().sum())\/nbdata)*100)\n","ff07c48e":"nbcol=len(data.columns)\ndata['year']=[int(str(x)[:4]) for x in data.tourney_date]\ndata['col_full']=[(1-(data.iloc[ii].isnull().sum()\/nbcol))*100 for ii in range(len(data.index))]\ndata.groupby(['year'])['col_full'].mean()","860a99d7":"data2=data[data[\"year\"]>1990]","f1f574a1":"nbdata2=len(data2)\nprint((1-(data2.isnull().sum())\/nbdata2)*100)\nlfeatures=(1-(data2.isnull().sum())\/nbdata2)*100","6a8d6fbc":"lfeatures2=lfeatures[lfeatures > 85]\nprint(lfeatures2)\nprint(lfeatures2.index)","86284f45":"data3=data2[['best_of', 'l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_ace',\n       'l_bpFaced', 'l_bpSaved', 'l_df', 'l_svpt', 'loser_age', 'loser_hand',\n       'loser_ht', 'loser_id', 'loser_ioc', 'loser_name','loser_rank',\n       'loser_rank_points', 'match_num', 'minutes', 'round', 'score',\n       'surface', 'tourney_date', 'tourney_id', 'tourney_level',\n        'w_1stIn', 'w_1stWon', 'w_2ndWon', 'w_SvGms', 'w_ace',\n       'w_bpFaced', 'w_bpSaved', 'w_df', 'w_svpt', 'winner_age', 'winner_hand',\n       'winner_ht', 'winner_id', 'winner_ioc', 'winner_name', 'winner_rank',\n       'winner_rank_points']]\n","38c15bb8":"data3=data2[[ 'tourney_date', 'tourney_id', 'match_num','surface','tourney_level','round',\n             'loser_name','loser_id', 'loser_hand','loser_ioc', \n             'loser_age', 'loser_ht',  'loser_rank','loser_rank_points',\n             'winner_name','winner_id', 'winner_hand','winner_ioc',\n             'winner_age',  'winner_ht', 'winner_rank','winner_rank_points']]\n\n# V\u00e9rifions les variables manquantes\nnbdata3=len(data3)\nprint((1-(data3.isnull().sum())\/nbdata3)*100)","34b7b5b1":"# Essayons des remplacement\n# Voyons les moyennes des variables num\u00e9rique et les majorit\u00e9s des cat\u00e9gorielles\n# en utilisant la methode describe de pandas\nperc =[.20, .40, .60, .80] \ninclude =['object', 'float', 'int'] \nprint(data3.describe(percentiles = perc, include = include).transpose())","03df6a3c":"# rempla\u00e7ons par les moyennes et les majoritaires\nvalues_na={'surface': 'Hard', 'loser_hand': 'R', 'loser_age': 26.0, \\\n           'loser_ht': 185.0 ,'winner_hand': 'R' ,'winner_age': 26.0, 'winner_ht': 185.0}\ndata3.fillna(value=values_na, inplace=True)\nprint((1-(data3.isnull().sum())\/nbdata3)*100)","41153a00":"# Il reste le cas des rank et rank_points\n# mais on peut raisonnablementpas les remplacer. Ils sont essentiels pour les pr\u00e9dictions\n\n# On supprime donc les lignes concern\u00e9es\ndata3.dropna(inplace=True)\nprint(len(data3))\nnbdata3=len(data3)\nprint((1-(data3.isnull().sum())\/nbdata3)*100)\n","104a1c1b":"# on nettoie des dupliqu\u00e9s\nprint(len(data3))\ndata3.drop_duplicates(keep=\"first\") \nprint(len(data3))","be510d37":"# pour surface\ndata3['hard']=(data3[\"surface\"]==\"Hard\")*1\ndata3['clay']=(data3[\"surface\"]==\"Clay\")*1\ndata3['grass']=(data3[\"surface\"]==\"Grass\")*1\n#pour round\ndata3['F']   = (data3['round']==\"F\")*1\ndata3['SF']  =(data3['round']==\"SF\")*1\ndata3['QF']  =(data3['round']==\"QF\")*1\ndata3['R16'] =(data3['round']==\"R16\")*1\ndata3['R32'] =(data3['round']==\"R32\")*1\ndata3['R64'] =(data3['round']==\"R64\")*1\ndata3['R128']    =(data3['round']==\"R128\")*1\ndata3['RR']  =(data3['round']==\"RR\")*1\ndata3['BR']  =(data3['round']==\"BR\")*1\n\n#Pour les tourney_level\ndata3['l_A']=(data3['tourney_level']==\"A\")*1\ndata3['l_G']=(data3['tourney_level']==\"G\")*1\ndata3['l_D']=(data3['tourney_level']==\"D\")*1\ndata3['l_M']=(data3['tourney_level']==\"M\")*1\ndata3['l_F']=(data3['tourney_level']==\"F\")*1\n\nnbdata3=len(data3)\nprint((1-(data3.isnull().sum())\/nbdata3)*100)","d351027e":"from sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix,accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV","19ea00e2":"data31, data32 = train_test_split( data3, test_size = 0.50)\nlen(data3),len(data31),len(data32)\n\n# cas ou le joureur 1 gagne\n#Pour les num\u00e9riques\ndata31[\"age_1_2\"]=data31[\"winner_age\"]-data31[\"loser_age\"]\ndata31['ht_1_2']=data31[\"winner_ht\"]-data31[\"loser_ht\"] \ndata31['rank_1_2']=data31[\"winner_rank\"]-data31[\"loser_rank\"]\ndata31['rank_points_1_2']=data31[\"winner_rank_points\"]-data31[\"loser_rank_points\"]\n#pour les cat\u00e9gories\ndata31['hand_1_2']=(data31['winner_hand']==data31['loser_hand'])*1.1 # on garde juste s'ils ont m\u00eame main \ndata31['ioc_1_2']=(data31['winner_ioc']==data31['loser_ioc'])*1.1 # on garde juste s'ils sont du m\u00eame pays\n\ndata31[\"winner_1_2\"]=1.0\n\n\n# cas ou le joureur 2 gagne\n#Pour les num\u00e9riques\ndata32[\"age_1_2\"]=data32[\"loser_age\"]-data32[\"winner_age\"]\ndata32['ht_1_2']=data32[\"loser_ht\"]-data32[\"winner_ht\"] \ndata32['rank_1_2']=data32[\"loser_rank\"]-data32[\"winner_rank\"]\ndata32['rank_points_1_2']=data32[\"loser_rank_points\"]-data32[\"winner_rank_points\"]\n#pour les cat\u00e9gories\ndata32['hand_1_2']=(data32['loser_hand']==data32['winner_hand'])*1.1 # on garde juste s'ils ont m\u00eame main \ndata32['ioc_1_2']=(data32['loser_ioc']==data32['winner_ioc'])*1.1 # on garde juste s'ils sont du m\u00eame pays\n\ndata32[\"winner_1_2\"]=0.0\n\n# V\u00e9rifions les variables manquantes\nnbdata3=len(data32)\nprint((1-(data32.isnull().sum())\/nbdata3)*100)","c5e214bb":"X0=data31.append(data32)\nnbdata3=len(X0)\nprint((1-(X0.isnull().sum())\/nbdata3)*100)\n\nX0=X0.drop(columns=['tourney_date', 'tourney_id', 'surface','tourney_level','round',\n             'loser_name','loser_id', 'loser_hand','loser_ioc', \n             'loser_age', 'loser_ht',  'loser_rank','loser_rank_points',\n             'winner_name','winner_id', 'winner_hand','winner_ioc',\n             'winner_age',  'winner_ht', 'winner_rank','winner_rank_points'])\n\n\nX0.dropna(inplace=True)\n\nX0.sort_index(inplace=True)\n","1f1afd7b":"#Finalemenet nos variables sont\nX=X0.drop(columns=['winner_1_2'])\ny=X0['winner_1_2']\nprint(X.columns)","3b97ee3a":"X['rank_1_2']=pd.to_numeric(X['rank_1_2'])\nplt.figure(figsize=(20,10))\nplt.subplot(2,4,1)\nX['rank_1_2'].plot(kind='hist',bins=400, xlim=(-400,400), ylim=(0,7000), title='Rank_diffirancial',color='red')\n\n# Visualisation des variables\nX['rank_points_1_2']=pd.to_numeric(X['rank_points_1_2'])\nplt.figure(figsize=(20,10))\nplt.subplot(2,4,1)\nX['rank_points_1_2'].plot(kind='hist',bins=400, xlim=(-1500,1500), ylim=(0,7000), title='Rank_points_diffirancial',color='blue')\n\nX['hard']=pd.to_numeric(X['hard'])\nplt.figure(figsize=(20,10))\nplt.subplot(2,4,2)\nX['hard'].plot(kind='hist',bins=3, xlim=(-1,2), ylim=(0,50000), title='hard',color='green')\n\nX['F']=pd.to_numeric(X['F'])\nplt.figure(figsize=(20,10))\nplt.subplot(2,4,2)\nX['F'].plot(kind='hist',bins=3, xlim=(-1,2), ylim=(0,100000), title='Finale',color='orange')\n\nX['l_A']=pd.to_numeric(X['l_A'])\nplt.figure(figsize=(20,10))\nplt.subplot(2,4,2)\nX['l_A'].plot(kind='hist',bins=3, xlim=(-1,2), ylim=(0,100000), title='Toirnoi A',color='magenta')","54fac23c":"import seaborn as sns","49a4a143":"\nplt.figure(figsize=(12,10))\ncor = X0.corr()\ncor.style.background_gradient(cmap='coolwarm').set_precision(2)","498266fa":"#D\u00e9terminons les variables les plus importantes pour les pr\u00e9vision\ncor_target = abs(cor[\"winner_1_2\"])\nrelevant_features = cor_target[cor_target>0.25]\nrelevant_features","e48dc826":"# split dataset training et test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n# Scale les dataset\nfeature_scaler = StandardScaler()\nX_S = feature_scaler.fit_transform(X)\nX_trainS = feature_scaler.fit_transform(X_train)\nX_testS = feature_scaler.transform(X_test) ","66404459":"models=[]\naccuracy=[]\n#RandomForest\nclassifier = RandomForestClassifier(n_estimators=100, bootstrap= True, criterion= 'entropy')\nclassifier.fit(X_train, y_train)\ny_pred_rf = classifier.predict(X_test)\ny_pred_rfp= classifier.predict_proba(X_test)[:,1]\nprint(\"Ramdom Forest\")\nprint(confusion_matrix(y_test, y_pred_rf))\nprint(classification_report(y_test,y_pred_rf))\nmodels.append(\"RandomForest\")\naccuracy.append(classifier.score(X_test,y_test))\n\n#Neural classifier\nfrom sklearn.neural_network import MLPClassifier\n\nclfs = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\nclfs.fit(X_trainS, y_train)\ny_pred_mlps = clfs.predict(X_testS)\ny_pred_mlpsp = clfs.predict_proba(X_testS)\nprint(\"Neural train standarised\")\nprint(confusion_matrix(y_test, y_pred_mlps))\nprint(classification_report(y_test, y_pred_mlps))\nprint(accuracy_score(y_test, y_pred_mlps))\nmodels.append(\"Neural train standarised\")\naccuracy.append(clfs.score(X_test,y_test))\n\n# Decision tree\n#classDT = DecisionTreeClassifier()\nclassDT = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=1e-7, min_impurity_split=1e-7,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')\n\nclassDT.fit(X_train, y_train)\ny_predDT = classDT.predict(X_test)\nprint(\"Decision tree \")\nprint(confusion_matrix(y_test, y_predDT))\nprint(classification_report(y_test,y_predDT))\nmodels.append(\"Decision tree \")\naccuracy.append(classDT.score(X_test,y_test))\n\n# XG Boost\nfrom xgboost import XGBClassifier\n\nclassXGB=XGBClassifier()\nclassXGB.fit(X_train, y_train)\ny_predXGB = classXGB.predict(X_test)\nprint(\"XG Boost\")\nprint(confusion_matrix(y_test, y_predXGB))\nprint(classification_report(y_test,y_predXGB))\nprint(accuracy_score(y_test, y_predXGB))\nmodels.append(\"XG Boost\")\naccuracy.append(classXGB.score(X_test,y_test))\n\ny_predXGBP= classXGB.predict_proba(X_test)\ny_predXGBP2=[]\nfor pp in y_predXGBP:\n    if pp[1] > 0.50 : \n        y_predXGBP2.append(1)\n    else:\n        y_predXGBP2.append(0)\nprint(\"XGBP propba\")\nprint(confusion_matrix(y_test, y_predXGBP2))\nprint(classification_report(y_test, y_predXGBP2))\nprint(accuracy_score(y_test, y_predXGBP2))\n\n'''\nLes SVM sont trop lent \u00e0 voir pour plus tard\n# Simple lienear SVM Train\nsvclassifier = SVC(kernel='linear')\nsvclassifier.fit(X_train, y_train)  \n#prdiction\ny_pred = svclassifier.predict(X_test)\n#r\u00e9sultat  \nprint(\"Simple lienear SVM \")\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))    \n  \n# Polynomiale SVM\n#train\nsvclassifier = SVC(kernel='poly', degree=8)\nsvclassifier.fit(X_train, y_train)\n#Prevision\ny_pred = svclassifier.predict(X_test)\n# Evaluation\nprint(\"Poly SVM \")\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n# SVM Guassian kernel\nsvclassifier = SVC(kernel='rbf',probability=True, gamma=\"auto\", C=10)\nsvclassifier.fit(X_trainS, y_train)\n#Prevision\ny_pred_svmg = svclassifier.predict(X_testS)\nprint(confusion_matrix(y_test, y_pred_svmg))\n# Evaluation\nprint(\"SVM Guassian kernel\")\nprint(confusion_matrix(y_test, y_pred_svmg))\nprint(classification_report(y_test, y_pred_svmg))\nprint(accuracy_score(y_test, y_pred_svmg))\nmodels.append(\" SVM Guassian kernel\")\naccuracy.append(classXGB.score(X_test,y_test))\n'''\n","e8c9a437":"def horizontal_barplot(values,labels,xaxis_label,title,xlim=None,figsize=None):\n    \n    cs=[\"red\",\"blue\",\"green\",\"orange\",\"gold\",\"firebrick\",\"peru\",\"khaki\",\"chocolate\"]\n    cs=cs*(len(values)\/\/len(cs)+1)\n    # The figure\n    if figsize==None:\n        fig=plt.figure(figsize=(4,3))\n    else:\n        fig=plt.figure(figsize=figsize,dpi=100)\n    ax = fig.add_axes([0,0,1,0.9])\n    color=cs[:len(values)]\n    ax.barh(range(len(values)),values,color=color)\n    ax.set_yticks(range(len(values)))\n    ax.set_yticklabels(labels)\n    if xlim!=None:\n        ax.set_xlim(xlim)\n    plt.suptitle(title)\n    ax.set_xlabel(xaxis_label)\n    plt.show()\n","666f5187":"accuracy2=[x*100 for x in accuracy]\nxaxis_label=\"Accuracy\"\ntitle=\"Performance compar\u00e9s des mod\u00e8les\"\nxlim=[50,70]\nhorizontal_barplot(accuracy2,models,xaxis_label,title,xlim,figsize=(4.5,3.5))","aa43d674":"\n# Il nous cumuler les performances de tous les joueurs pour avoir leur statistques de performances avant le match pour le pari\n\n#%%\n# Pr\u00e9paration de la datset des joueurs avec la moyenne de leur perfiormances avant \u00e0 une date donn\u00e9e\nprint(data3.describe().transpose())\n\n# DF des perdants\n# transformer les variables cat\u00e9gorielles : surface, round, tourney_level en num\u00e9rique pour le perdant\nprint(data3[\"surface\"].unique())\nprint(data3[\"round\"].unique())\nprint(data3[\"tourney_level\"].unique())\n# pour surface\ndata3['won_hard']    =0\ndata3['won_clay']    =0\ndata3['won_grass']   =0\n#pour round\ndata3['won_F']       =0\ndata3['won_SF']      =0\ndata3['won_QF']      =0\ndata3['won_R16']     =0\ndata3['won_R32']     =0\ndata3['won_R64']     =0\ndata3['won_R128']    =0\ndata3['won_RR']      =0\ndata3['won_BR']      =0\n#Pour les tourney_level\ndata3['won_l_A']       =0\ndata3['won_l_G']       =0\ndata3['won_l_D']       =0\ndata3['won_l_M']       =0\ndata3['won_l_F']       =0\n# mettre une variable nombre de matchs jou\u00e9s\ndata3['nb_match']=1\nprint(data3.describe().transpose())\n\ndf_loser=data3[['loser_name','loser_id','tourney_date','tourney_id','match_num','loser_age', 'loser_hand','loser_ht','loser_ioc',\\\n                'loser_rank','loser_rank_points',\\\n                'l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_ace','l_bpFaced', 'l_bpSaved','l_df','l_svpt', 'minutes',\\\n                'won_hard',\"won_clay\",\"won_grass\",\\\n                'won_F','won_SF','won_QF','won_R16','won_R32','won_R64','won_R128','won_RR','won_BR',\\\n                'won_l_A','won_l_G','won_l_D','won_l_M','won_l_F',\\\n                \"nb_match\"]]\n\n#Transformons les num\u00e9rique fixes par des str\ndf_loser['loser_id']=df_loser['loser_id'].apply(str)\ndf_loser['tourney_date']=df_loser['tourney_date'].apply(str)\ndf_loser['match_num']=df_loser['match_num'].apply(str)\ndf_loser['loser_age']=df_loser['loser_age'].apply(str)\ndf_loser['loser_ht']=df_loser['loser_ht'].apply(str)\ndf_loser['loser_rank']=df_loser['loser_rank'].apply(str)\ndf_loser['loser_rank_points']=df_loser['loser_rank_points'].apply(str)\n\n#df_loser_cum[\"tourney_date\"]=df_loser_cum[\"tourney_date\"].apply(str)\ntdate=df_loser[\"tourney_date\"].copy\nna_date=\"99999999\"\nna_mnum=\"99999999\"\n\n#P\u00e9parer l'index\ndf_loser[\"id_date_mnum\"]= df_loser['loser_id'].str.\\\n        cat(df_loser[\"tourney_date\"].values.astype(str), sep=\"_\",na_rep=na_date).str.\\\n        cat(df_loser['tourney_id'].values.astype(str), sep=\"_\",na_rep=na_mnum).str.\\\n        cat(df_loser['match_num'].values.astype(str), sep=\"_\",na_rep=na_mnum)\n        \n\n# uniformiser le nom des colonnes\ndf_loser=df_loser.rename(columns={'loser_name':'name','loser_id':'id', 'loser_age':'age',\\\n                         'loser_hand':'hand','loser_ht':'ht','loser_ioc':'ioc',\\\n                'loser_rank':'rank','loser_rank_points':'rank_points',\\\n                'l_1stIn':'1stIn', 'l_1stWon':'1stWon', 'l_2ndWon':'2ndWon',\\\n                'l_SvGms':'SvGms', 'l_ace':'ace','l_bpFaced':'bpFaced', 'l_bpSaved':'bpSaved','l_df':'df','l_svpt':'svpt'})\n\nprint(df_loser.iloc[5])\nprint(df_loser.iloc[500:510])\nprint(len(df_loser))\n#%%\n# pour les gagnants\n# transformer les variables cat\u00e9gorielles : surface, round, tourney_level en num\u00e9rique pour le gagnant\n# pour surface\ndata3['won_hard']=(data3[\"surface\"]==\"Hard\")*1\ndata3['won_clay']=(data3[\"surface\"]==\"Clay\")*1\ndata3['won_grass']=(data3[\"surface\"]==\"Grass\")*1\n#pour round\ndata3['won_F']   = (data3['round']==\"F\")*1\ndata3['won_SF']  =(data3['round']==\"SF\")*1\ndata3['won_QF']  =(data3['round']==\"QF\")*1\ndata3['won_R16'] =(data3['round']==\"R16\")*1\ndata3['won_R32'] =(data3['round']==\"R32\")*1\ndata3['won_R64'] =(data3['round']==\"R64\")*1\ndata3['won_R128']    =(data3['round']==\"R128\")*1\ndata3['won_RR']  =(data3['round']==\"RR\")*1\ndata3['won_BR']  =(data3['round']==\"BR\")*1\n\n#Pour les tourney_level\ndata3['won_l_A']=(data3['tourney_level']==\"A\")*1\ndata3['won_l_G']=(data3['tourney_level']==\"G\")*1\ndata3['won_l_D']=(data3['tourney_level']==\"D\")*1\ndata3['won_l_M']=(data3['tourney_level']==\"M\")*1\ndata3['won_l_F']=(data3['tourney_level']==\"F\")*1\n# Nouvelle approche en utilisant que pendas\ndf_winner=data3[['winner_name','winner_id','tourney_date','tourney_id','match_num','winner_age', 'winner_hand','winner_ht','winner_ioc',\\\n                'winner_rank','winner_rank_points',\\\n                'w_1stIn', 'w_1stWon', 'w_2ndWon', 'w_SvGms', 'w_ace','w_bpFaced', 'w_bpSaved','w_df','w_svpt', 'minutes',\\\n                'won_hard',\"won_clay\",\"won_grass\",\\\n                'won_F','won_SF','won_QF','won_R16','won_R32','won_R64','won_R128','won_RR','won_BR',\\\n                'won_l_A','won_l_G','won_l_D','won_l_M','won_l_F',\\\n                \"nb_match\"]]\n'''\nAncienne Approche \n#Transformons les num\u00e9rique fixes par des str\ndf_winner['winner_id']=df_winner['winner_id'].apply(str)\ndf_winner['tourney_date']=df_winner['tourney_date'].apply(str)\ndf_winner['match_num']=df_winner['match_num'].apply(str)\ndf_winner['winner_age']=df_winner['winner_age'].apply(str)\ndf_winner['winner_ht']=df_winner['winner_ht'].apply(str)\ndf_winner['winner_rank']=df_winner['winner_rank'].apply(str)\ndf_winner['winner_rank_points']=df_winner['winner_rank_points'].apply(str)\n\n#df_winner[\"tourney_date\"]=df_winner[\"tourney_date\"].apply(str)\ntdate=df_winner[\"tourney_date\"].copy\nna_date=\"99999999\"\nna_mnum=\"99999999\"\n\ndf_winner[\"id_date_mnum\"]= df_winner['winner_id'].str.\\\n        cat(df_winner[\"tourney_date\"].values.astype(str), sep=\"_\",na_rep=na_date).str.\\\n        cat(df_winner['tourney_id'].values.astype(str), sep=\"_\",na_rep=na_mnum).str.\\\n        cat(df_winner['match_num'].values.astype(str), sep=\"_\",na_rep=na_mnum)\n        \n\ndf_winner=df_winner.rename(columns={'winner_name':'name','winner_id':'id', 'winner_age':'age',\\\n                         'winner_hand':'hand','winner_ht':'ht','winner_ioc':'ioc',\\\n                'winner_rank':'rank','winner_rank_points':'rank_points',\\\n                'w_1stIn':'1stIn', 'w_1stWon':'1stWon', 'w_2ndWon':'2ndWon',\\\n                'w_SvGms':'SvGms', 'w_ace':'ace','w_bpFaced':'bpFaced', 'w_bpSaved':'bpSaved','w_df':'df','w_svpt':'svpt'})\n\n'''    \ndf_winner.iloc[5]  \nlen(df_winner)\n#%%\n''' ancienne approche\ndf_winner.sort_values(by=['winner_id','tourney_date','tourney_id','match_num' ], inplace=True)\ndf_winner_cum=df_winner.groupby(by=\"id\").cumsum()\n#calcule des moyennes\ndf_winner_cum['1stIn_av']=df_winner_cum['1stIn']\/df_winner_cum['nb_match']\ndf_winner_cum['1stWon_av']=df_winner_cum['1stWon']\/df_winner_cum['nb_match']\ndf_winner_cum['2ndWon_av']=df_winner_cum['2ndWon']\/df_winner_cum['nb_match']\ndf_winner_cum['SvGms_av']=df_winner_cum['SvGms']\/df_winner_cum['nb_match']\ndf_winner_cum['ace_av']=df_winner_cum['ace']\/df_winner_cum['nb_match']\ndf_winner_cum['bpFaced_av']=df_winner_cum['bpFaced']\/df_winner_cum['nb_match']\ndf_winner_cum['bpSaved_av']=df_winner_cum['bpSaved']\/df_winner_cum['nb_match']\ndf_winner_cum['df_av']=df_winner_cum['df']\/df_winner_cum['nb_match']\ndf_winner_cum['svpt_av']=df_winner_cum['svpt']\/df_winner_cum['nb_match']\ndf_winner_cum['minutes_av']=df_winner_cum['minutes']\/df_winner_cum['nb_match']\n\ndf_winner_cum['won_F_av']=df_winner_cum['won_F']\/df_winner_cum['nb_match']\ndf_winner_cum['won_SF_av']=df_winner_cum['won_SF']\/df_winner_cum['nb_match']\ndf_winner_cum['won_QF_av']=df_winner_cum['won_QF']\/df_winner_cum['nb_match']\ndf_winner_cum['won_R128_av']=df_winner_cum['won_R128']\/df_winner_cum['nb_match']\ndf_winner_cum['won_R16_av']=df_winner_cum['won_R16']\/df_winner_cum['nb_match']\ndf_winner_cum['won_R32_av']=df_winner_cum['won_R32']\/df_winner_cum['nb_match']\ndf_winner_cum['won_R64_av']=df_winner_cum['won_R64']\/df_winner_cum['nb_match']\ndf_winner_cum['won_RR_av']=df_winner_cum['won_RR']\/df_winner_cum['nb_match']\ndf_winner_cum['won_BR_av']=df_winner_cum['won_BR']\/df_winner_cum['nb_match']\n\ndf_winner_cum['won_hard_av']=df_winner_cum['won_hard']\/df_winner_cum['nb_match']\ndf_winner_cum['won_clay_av']=df_winner_cum['won_clay']\/df_winner_cum['nb_match']\ndf_winner_cum['won_grass_av']=df_winner_cum['won_grass']\/df_winner_cum['nb_match']\n\ndf_winner_cum['won_l_A_av']=df_winner_cum['won_l_A']\/df_winner_cum['nb_match']\ndf_winner_cum['won_l_G_av']=df_winner_cum['won_l_G']\/df_winner_cum['nb_match']\ndf_winner_cum['won_l_D_av']=df_winner_cum['won_l_D']\/df_winner_cum['nb_match']\ndf_winner_cum['won_l_M_av']=df_winner_cum['won_l_M']\/df_winner_cum['nb_match']\ndf_winner_cum['won_l_F_av']=df_winner_cum['won_l_F']\/df_winner_cum['nb_match']\n\ndf_winner_av=df_player.join(df_winner_cum, rsuffix=\"_cum\")\n\ndf_winner_av.sort_index(inplace=True)\n\n\n\n.sort_index(inplace=True)\n\n#%%   \n# Concatener les 2 Df loser et winner\n\ndf_player=pd.concat([df_loser,df_winner])  \nlen(df_player)\ndf_player.dtypes\ndf_player.set_index(\"id_date_mnum\", inplace=True)\ndf_player.sort_index(inplace=True)\ndf_player_cum=df_player.groupby(by=\"id\").cumsum()\n\nprint(df_player_cum.iloc[500:550,-4:])\nprint(df_player.iloc[500])\nprint(df_player_cum.iloc[500:505])\n# Calcule des moyennes\ndf_player_cum['1stIn_av']=df_player_cum['1stIn']\/df_player_cum['nb_match']\ndf_player_cum['1stWon_av']=df_player_cum['1stWon']\/df_player_cum['nb_match']\ndf_player_cum['2ndWon_av']=df_player_cum['2ndWon']\/df_player_cum['nb_match']\ndf_player_cum['SvGms_av']=df_player_cum['SvGms']\/df_player_cum['nb_match']\ndf_player_cum['ace_av']=df_player_cum['ace']\/df_player_cum['nb_match']\ndf_player_cum['bpFaced_av']=df_player_cum['bpFaced']\/df_player_cum['nb_match']\ndf_player_cum['bpSaved_av']=df_player_cum['bpSaved']\/df_player_cum['nb_match']\ndf_player_cum['df_av']=df_player_cum['df']\/df_player_cum['nb_match']\ndf_player_cum['svpt_av']=df_player_cum['svpt']\/df_player_cum['nb_match']\ndf_player_cum['minutes_av']=df_player_cum['minutes']\/df_player_cum['nb_match']\n\ndf_player_cum['won_F_av']=df_player_cum['won_F']\/df_player_cum['nb_match']\ndf_player_cum['won_SF_av']=df_player_cum['won_SF']\/df_player_cum['nb_match']\ndf_player_cum['won_QF_av']=df_player_cum['won_QF']\/df_player_cum['nb_match']\ndf_player_cum['won_R128_av']=df_player_cum['won_R128']\/df_player_cum['nb_match']\ndf_player_cum['won_R16_av']=df_player_cum['won_R16']\/df_player_cum['nb_match']\ndf_player_cum['won_R32_av']=df_player_cum['won_R32']\/df_player_cum['nb_match']\ndf_player_cum['won_R64_av']=df_player_cum['won_R64']\/df_player_cum['nb_match']\ndf_player_cum['won_RR_av']=df_player_cum['won_RR']\/df_player_cum['nb_match']\ndf_player_cum['won_BR_av']=df_player_cum['won_BR']\/df_player_cum['nb_match']\n\ndf_player_cum['won_hard_av']=df_player_cum['won_hard']\/df_player_cum['nb_match']\ndf_player_cum['won_clay_av']=df_player_cum['won_clay']\/df_player_cum['nb_match']\ndf_player_cum['won_grass_av']=df_player_cum['won_grass']\/df_player_cum['nb_match']\n\ndf_player_cum['won_l_A_av']=df_player_cum['won_l_A']\/df_player_cum['nb_match']\ndf_player_cum['won_l_G_av']=df_player_cum['won_l_G']\/df_player_cum['nb_match']\ndf_player_cum['won_l_D_av']=df_player_cum['won_l_D']\/df_player_cum['nb_match']\ndf_player_cum['won_l_M_av']=df_player_cum['won_l_M']\/df_player_cum['nb_match']\ndf_player_cum['won_l_F_av']=df_player_cum['won_l_F']\/df_player_cum['nb_match']\n'''\ndf_player_cum.describe().transpose()\ndf_player_cum.dtypes\n\n# Historique des joueur est donc la jointure avec cum\ndf_player_av=df_player.join(df_player_cum, rsuffix=\"_cum\")\n# Retirer les variables instantan\u00e9e\ndf_player_av=df_player_av.drop(columns=['1stIn', '1stWon', '2ndWon', 'SvGms', 'ace',\n       'bpFaced', 'bpSaved', 'df', 'svpt', 'minutes', \n       'won_hard','won_clay', 'won_grass', \n       'won_F', 'won_SF', 'won_QF','won_R16', 'won_R32', 'won_R64', 'won_R128', 'won_RR','won_BR',\n       'won_l_A','won_l_G','won_l_D','won_l_M','won_l_F',\n       'nb_match','ioc'])\nprint(df_player_av.iloc[550])\n#%%\n#Construction du dataset pour les mod\u00e8les\n\nX0=pd.DataFrame(columns=[    'tourney_date','tourney_id','match_num ',\n                             'hard','clay', 'grass', \n                             'r_F', 'r_SF', 'r_QF','r_R16', 'r_R32', 'r_R64', 'r_R128', 'r_RR','r_BR',\n                             'l_A','l_G','l_D','l_M','l_F',                             \n                             \n                              '1stIn_cum', '1stWon_cum',\n                              '2ndWon_cum', 'SvGms_cum', 'ace_cum', 'bpFaced_cum', 'bpSaved_cum',\n                              'df_cum', 'svpt_cum', 'minutes_cum', 'won_hard_cum', 'won_clay_cum',\n                              'won_grass_cum', 'won_F_cum', 'won_SF_cum', 'won_QF_cum', 'won_R16_cum',\n                              'won_R32_cum', 'won_R64_cum', 'won_R128_cum', 'won_RR_cum',\n                              'won_BR_cum', 'won_l_A_cum', 'won_l_G_cum', 'won_l_D_cum',\n                              'won_l_M_cum', 'won_l_F_cum', 'nb_match_cum', \n                               \n                              '1stIn_av', '1stWon_av',\n                              '2ndWon_av', 'SvGms_av', 'ace_av', 'bpFaced_av', 'bpSaved_av', \n                              'df_av', 'svpt_av', 'minutes_av', 'won_F_av', 'won_SF_av', 'won_QF_av',\n                              'won_R128_av', 'won_R16_av', 'won_R32_av', 'won_R64_av', 'won_RR_av',\n                              'won_BR_av', 'won_hard_av', 'won_clay_av', 'won_grass_av', 'won_l_A_av',\n                              'won_l_G_av', 'won_l_D_av', 'won_l_M_av', 'won_l_F_av'\n                              \n                              'winner_1_2'\n                             ])\n\nX0=data3[['tourney_date','tourney_id','match_num']]\n\nX0['hard']=(data3['surface']=='Hard')*1\nX0['clay']=(data3['surface']=='Clay')*1\nX0['grass']=(data3['surface']=='Grass')*1\n\n#pour round\nX0['r_F']   = (data3['round']==\"F\")*1\nX0['r_SF']  =(data3['round']==\"SF\")*1\nX0['r_QF']  =(data3['round']==\"QF\")*1\nX0['r_R16'] =(data3['round']==\"R16\")*1\nX0['r_R32'] =(data3['round']==\"R32\")*1\nX0['r_R64'] =(data3['round']==\"R64\")*1\nX0['r_R128']    =(data3['round']==\"R128\")*1\nX0['r_RR']  =(data3['round']==\"RR\")*1\nX0['r_BR']  =(data3['round']==\"BR\")*1\n\n#Pour les tourney_level\nX0['l_A']=(data3['tourney_level']==\"A\")*1\nX0['l_G']=(data3['tourney_level']==\"G\")*1\nX0['l_D']=(data3['tourney_level']==\"D\")*1\nX0['l_M']=(data3['tourney_level']==\"M\")*1\nX0['l_F']=(data3['tourney_level']==\"F\")*1\n\nxindex=list(df_player_av.index)\nlselect=[x for x in range(11,66)]\nfor ii in data3.index:\n    xx=data3.loc[ii]\n    \n    #on recherche les info sur le loser disponibles avant le match\n    ii1=str(xx['loser_id'])+\"_\"+str(xx[\"tourney_date\"])+\"_\"+str(xx['tourney_id'])+\"_\"+str(xx['match_num'])\n    if xindex.index(ii1)-1 <0 : continue # pas d'historique pour cette date, permier match du joueur\n    ii0=xindex[xindex.index(ii1)-1]\n    if ii0[:6]!=ii1[:6]:continue # pas d'historique pour cette date, permier match du joueur\n    loser=df_player_av.loc[ii0]\n    \n    #on recherche les info sur le winner disponibles avant le match\n    ii1=str(xx['winner_id'])+\"_\"+str(xx[\"tourney_date\"])+\"_\"+str(xx['tourney_id'])+\"_\"+str(xx['match_num'])\n    if xindex.index(ii1)-1 <0 : continue # pas d'historique pour cette date, permier match du joueur\n    ii0=xindex[xindex.index(ii1)-1]\n    if ii0[:6]!=ii1[:6]:continue # pas d'historique pour cette date, permier match du joueur\n    winner=df_player_av.loc[ii0]\n    \n    # Pour une question de sym\u00e9trie des variables on prendra la diff\u00e9rences entre les carat\u00e9ristiques \n    #des joueurs plutot que leur valeur respectives\n    rank=float(winner[\"rank\"])-float(loser[\"rank\"])\n    rank_points=float(winner[\"rank_points\"])-float(loser[\"rank_points\"])\n    \n    diff1=np.subtract(winner[lselect],loser[lselect])  \n    \n       \n    nb_match_cum =  winner[\"nb_match_cum \"] - loser[\"nb_match_cum \"] \n    \n    # On tire au sort si le winner est 1 ou 2\n    import random\n    rr=random.randint(1, 2)\n    if rr == 1: #winner est 1\n        X0.loc[ii,\"winner_1_2\"]=1\n        \n        for jj in diff1.index:\n            X0.loc[ii,jj]=diff1[jj]\n        \n\n\n\n","1c1a05eb":"Slections des variables\nvoyons quelles sont les variables les mieux renseign\u00e9es","25846357":"# Comparons les performances sur la pr\u00e9cision de la classification","22fdbf7b":"# Passons \u00e0 la mod\u00e9lisation ","cb698433":"# Avec plus de temps que faire?","7bd15c55":"# Visualisation de la distribution des variables","b4f5ddf6":"# Sans surprises c'est les performances pass\u00e9es des joueurs refl\u00e9t\u00e9es dans leur classement rank et rank_points qui d\u00e9termine l'issue d'un match et qui seront le plus important pour les pr\u00e9visions","088d7ced":"On constate qu'il y a beaucoup de variables manquantes\nEssayons de voir s'il cela s'am\u00e9liore dans le temps. Les matchs sont tri\u00e9es par date croissantes","5578ac27":"# Maintenant concernant les paris Essayons de d\u00e9terminer sous quelles conditions il est rentable de parier\n\nLe retour sur les paries peut \u00eatre calcul\u00e9 par la formules\n\nRSP = Gains * 100 \/ Mises , avec Gains = (Raport_des_paris * Mises - Mises)\n\nSi on parie toujours sur nos pr\u00e9dictions obtenus avec XG Boost et que l'on mise par exemple 1 \u20ac sur chaque pr\u00e9diction.\nLa question est de savoir quel doit \u00eatre le rapport moyen des paris pour que cela soit rentable\nEn reprenant la matrice de confusion avec R = rapport moyen des paris\n\nGains seront ((R-1)*VP)+(R-1)*VN)-FP-FN)\/(VP+VN+FP+FN) **==>** R=(VP+VN+FP+FN)\/(VP-VN)\n\nSoit l'inverse de l'accuracy ou pr\u00e9cision de la matrice de confusion. Dans notre cas il faut que les rapports soient en moyenne sup\u00e9rieurs \u00e0 1\/0.654 = 1.53\n\nC'est assez \u00e9lev\u00e9 comme rapport, mais tr\u00e8s atteignable.\nPlus la pr\u00e9cision sera grande plus nous nous pourrions gagner de l'argent avec des rapports faibles.\n","443c294f":"# Construisons le dataset pour les mod\u00e8les","e30f23df":"L'issue d'un match d\u00e9pend de l'historiques des performances de chacun des joueurs **avant** le match et des conditions du match\nDans le dataset donn\u00e9es les seuls variables convernant les joueurs qui sont possibles de connaitre **avant** le match sont :\n'loser_age', 'loser_hand','loser_ht', 'loser_id', 'loser_ioc', 'loser_name','loser_rank','loser_rank_points',\n'winner_age', 'winner_hand', 'winner_ht', 'winner_id', 'winner_ioc', 'winner_name', 'winner_rank', 'winner_rank_points'\n\nEn supposant que les performances pass\u00e9es sont bien prises en compte par le rank et rank_points\n\nNous allons donc retenir que ces variables pour faire nos pr\u00e9dictions","2fad49c4":"# Il semble que les mod\u00e8les XG Boost et Neural qui ont la meilleure pr\u00e9cision\n# Il faudrait v\u00e9rifier la robustesse de ces mod\u00e8les par des Cross Validations\n# Et aussi voir comment r\u00e9duire le nombre de variables","6178bed3":"Il y en a pas\nOn change les variables de categorie comme surface, level et round par des num\u00e9riques","60ad0a83":"Nos variables sont assez bien distribu\u00e9e, sauf \u00e9videment pour les finales et autres derniers tours","f9d3487a":"On peut aussi supprimer les variables redondantes comme: 'tourney_name'\net celles qui ont \u00e9t\u00e9 ajout\u00e9es pour notre analyse , 'year', 'col_full'","e015dc02":"\n1. Essayer d'autres mod\u00e8les et am\u00e9liorer les mod\u00e8les test\u00e9s en jouant sur leurs m\u00e9ta param\u00e8tres\n2. S\u00e9lectionner mieux les variables \n3. Mais le plus utile et efficace serait **de mieux utiliser les donn\u00e9es dont nous disposons**.\n\nCe bref exercice a montr\u00e9 tr\u00e8s clairement qu'il faut prendre en compte l'historique des performances des joueurs. Ici seulement refl\u00e9t\u00e9es par le Rank et le Rank Points.\n\nIl faudrait historiser les performances pass\u00e9es contenues dans les variables telles que :\n\n\n[best_of', 'l_1stIn', 'l_1stWon', 'l_2ndWon', 'l_SvGms', 'l_ace','l_bpFaced', 'l_bpSaved', 'l_df', 'l_svpt', 'minutes', 'round', 'score',\n'surface', 'w_1stIn', 'w_1stWon', 'w_2ndWon', 'w_SvGms', 'w_ace','w_bpFaced', 'w_bpSaved', 'w_df', 'w_svpt']\n\nNous avons d\u00fb les laisser tomber parce qu'elles ne concernent que le match lui-m\u00eame et \u00e9videment nous n\u2019y avons pas acc\u00e8s pour parier avant le match.\n\nMais nous pouvons faire le cumul, la moyenne et la standard d\u00e9viation de ces variables pass\u00e9es jusqu'\u00e0 la date du match. \nPouvons m\u00eame sophistiquer cette approche en discountant les valeurs des variables en prenant en compte le temps \u00e9coul\u00e9 entre leur r\u00e9alisation et la date du match.\n\nNous pouvons aussi exploiter cet historique pour d\u00e9terminer combien de temps un joueur m'a pas avant le match pour cause de blessure ou autre. Ou encore quelles sont ces perfomances selon la surface, les mois de d'ann\u00e9e...\n\nJ'ai commenc\u00e9 \u00e0 y travaill\u00e9 mais faute de temps il n'est pas encore fini.\n\nEn annexe ci-dessous il y a une \u00e9bauche.\n","291ccd24":"# Esseyons diff\u00e9rents mod\u00e8les","1f47b23c":"On constate que les variables sont beaucoup mieux renseign\u00e9es \u00e0 partir de 1991 on passe de 48% des champs reseign\u00e9s \u00e0 86%\n# limitons nous aux ann\u00e9es apr\u00e8s 1991\n","57aac1aa":"# Pour sym\u00e9triser les variables sur les joueurs on prendra la diff\u00e9rence de leurs caract\u00e9ristiques plut\u00f4t que les valeurs respectives\n# pour d\u00e9finir quel joueur est gagnant, on tirera au sort entre un joueur 1 et un joueur 2\n# On coupe al\u00e9atoirement le dataset en deux","3fe5ee45":"ne gardons que les variables avec un taux de remplissage > 85%","f579e2ab":"# ATP matches\n\nL'objectif est de d\u00e9terminer \u00e0 l'aide de mod\u00e8les de pr\u00e9diction sous quelles conditions il devient rentable de parier sur des matchs de Tennis\n\nChargeaons le Dataset:\n","0cd88487":"# Tout est complet","0242d286":"# Visualisons la matrice de corr\u00e9lation"}}