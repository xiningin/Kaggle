{"cell_type":{"b09abbc8":"code","2591312c":"code","423a093f":"code","430cf22d":"code","f7e9b01b":"code","70c1076a":"code","9b8a8d66":"code","03831970":"code","97752c75":"code","3563b458":"code","3655bd74":"code","603febf4":"markdown","1f6e8c16":"markdown","b4bc59db":"markdown","d99172bc":"markdown","951d73ba":"markdown","69ae04a8":"markdown","f81f8208":"markdown","be1a3b30":"markdown","95b0e674":"markdown","56e92fa6":"markdown","9bed0246":"markdown","8ce148d8":"markdown","cdb38b6e":"markdown"},"source":{"b09abbc8":"import pandas as pd, numpy as np\nimport re,json\nimport itertools as it\nfrom pathlib import Path\n\nimport lightgbm as lgb\n\npd.options.display.max_columns=305","2591312c":"# Here, I'm gonna load the test, it contains `71122` rows as expected\ndf = pd.read_csv(\"..\/input\/lyft-test-set-as-csv\/Lyft_test_set.csv\")\nprint(\"df.shape:\", df.shape)\ndf.head(10)","423a093f":"def get_model_name(filename):\n    return re.search(\"^(lgbm_[x,y]_shift_\\d+)\", filename).group(1)","430cf22d":"def get_models(path):\n    models = {}\n    path = Path(path)\n    for model in path.glob(\"lgbm*\"):\n        model_name = get_model_name(model.stem)\n        shift = int(model_name.split(\"shift_\")[1])\n        meta = path.joinpath(\"meta_shift_{:02d}.json\".format(shift))\n        with meta.open() as f:\n            train_cols = json.load(f)[\"TRAIN_COLS\"]\n        models[model_name] = {\"model\": model.as_posix(), \"train_cols\": train_cols}\n    return models","f7e9b01b":"models = get_models(\"..\/input\/lyft-models\/lgbm_06\")\nlen(models)","70c1076a":"next(iter(models.items()))","9b8a8d66":"def make_colnames():\n    xcols = [\"coord_x{}{}\".format(step, rank) for step in range(3) for rank in range(50)]\n    ycols = [\"coord_y{}{}\".format(step, rank) for step in range(3) for rank in range(50)]\n    cols = [\"timestamp\", \"track_id\"] + [\"conf_0\", \"conf_1\", \"conf_2\"] + list(it.chain(*zip(xcols, ycols)))\n    return cols","03831970":"def predict(models, df):\n    sub = np.empty((len(df), 305))\n    sub.fill(np.nan)\n    sub = pd.DataFrame(sub, columns = make_colnames())\n    sub[[\"timestamp\", \"track_id\"]] = df[[\"timestamp\", \"track_id\"]]\n    sub[\"conf_0\"] = 1.0\n    \n    for shift in range(1, 51):\n        for suffix in [\"x\", \"y\"]:\n            model_info = models[\"lgbm_{}_shift_{:02d}\".format(suffix, shift)]\n                \n            model = lgb.Booster(model_file= model_info[\"model\"])\n            pred = model.predict(df[model_info[\"train_cols\"]])\n            \n            sub[\"coord_{}0{}\".format(suffix, shift-1)] = pred\n\n        if not shift%10:\n            print(\"shift: {}\".format(shift))\n    \n    sub.fillna(0., inplace=True)\n    \n    return sub","97752c75":"sub = predict(models, df)","3563b458":"sub.iloc[:50, :105]","3655bd74":"sub.to_csv(\"submission.csv\", index=False)","603febf4":"Getting such a score with no GPU computation nor image processing is just beautiful. More again, my LGBM are not well trained and I **zero** features ! Needless to say that there still room for improvements !","1f6e8c16":"I've trained **100** LGBM models : one for each of the *50 time horizons*x*2 space dimension*","b4bc59db":"<h4>Please, don't mind upovting the datasets in order to make them more visibe for all of us.<\/h4>","d99172bc":"I will be publishing my training dataset and the whole conversion process by soon. For now, I need some cleaning and refacto for my messy code :) .","951d73ba":"This is an inference kernel. Please [find the training kernel here](https:\/\/www.kaggle.com\/kneroma\/lgbm-on-lyft-tabular-data-training).","69ae04a8":"For the prediction, you can [find the test set as csv here](https:\/\/www.kaggle.com\/kneroma\/lyft-test-set-as-csv). ","f81f8208":"# Loading the test set as CSV","be1a3b30":"# Make prediction for the test set","95b0e674":"# Loading the LGBM models","56e92fa6":"Diving far into the zarr file format and  the Lyft L5kit github repos, I finally succeeded in converting the competition's dataset  into **csv** files on which we could run classical models.\n\nFor those who are interrested, [the csv dataset looks like this one](https:\/\/www.kaggle.com\/kneroma\/lyft-motion-prediction-autonomous-vehicles-as-csv). I've not uploaded the whole dataset for now. Stay tuned !\n\nFinally, let's recall that [this notebook of mine could also help you in stepping far into Zarr files and the Lyft L5kit dataset format.](https:\/\/www.kaggle.com\/kneroma\/zarr-files-and-l5kit-data-for-dummies)","9bed0246":"<div style=\"text-align:center;font-size:Large\"><a href=\"https:\/\/www.kaggle.com\/kneroma\">@Kkiller<\/a><\/div>","8ce148d8":"The whole training took about one hour and the prediction step is even fatster.","cdb38b6e":"> Some of the columns are self-explaining, for the others, please refer to the corresponding dataset for more details."}}