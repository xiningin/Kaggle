{"cell_type":{"05ceb59f":"code","1817ed9c":"code","300cbcd5":"code","a427e419":"code","6446d98f":"code","fc374fe9":"code","c5c99c89":"code","30b7b8e8":"code","f84e6d7c":"code","adcbf3e0":"code","6dd8bb02":"code","7738b584":"code","39453422":"code","0025c499":"code","2f96da57":"code","185c0ac1":"code","80f29534":"code","4dfaa6d9":"code","3498cb64":"code","7732d684":"code","8764f93b":"code","b8c022d2":"code","cc9cc46b":"code","4745014d":"code","7007809e":"code","e5530361":"code","98bd325e":"code","e5ce0674":"code","8c828997":"code","69dcf3b1":"code","402e0823":"code","b1326e08":"code","83f330c5":"code","405f70b9":"code","4f98a721":"code","739bdab8":"code","9ef293f7":"code","74e00f94":"code","1dfd893d":"code","2e12d083":"code","f5be4301":"code","33f6989b":"code","3fd3e56e":"code","68c60eab":"code","991ad772":"code","34b37915":"markdown","56cf3d2a":"markdown","70afceae":"markdown","9dc894db":"markdown","f3996643":"markdown","d32b654e":"markdown","7e14a324":"markdown","b6bb311a":"markdown","8cf73160":"markdown","965b3e37":"markdown","4fa7ecbb":"markdown","7cca600d":"markdown","bc82bb66":"markdown","73d56ef9":"markdown","b7347a19":"markdown","13caedef":"markdown","66b6a8b0":"markdown","bff5bd0b":"markdown","1727232b":"markdown","754112b8":"markdown"},"source":{"05ceb59f":"# importing the necessary libraries\nimport os\nfrom PIL import Image\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, random_split, DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport torchvision.transforms as T\nfrom sklearn.metrics import f1_score\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision.utils import make_grid\nimport pathlib\n%matplotlib inline","1817ed9c":"data_dir = \"..\/input\/intel-image-classification\"\ntrain_dir = data_dir + \"\/seg_train\/seg_train\"\ntest_dir = data_dir + \"\/seg_test\/seg_test\"\npred_dir = data_dir + \"\/seg_pred\"","300cbcd5":"# lets look at the classes in the dataset\nclasses = os.listdir(train_dir)\nclasses.sort()\nprint(classes)","a427e419":"train_transform = T.Compose([T.Resize((150,150)), T.ColorJitter(brightness = 1e-1, contrast = 1e-1, saturation = 1e-1, hue = 1e-1), T.RandomHorizontalFlip(), T.ToTensor(), T.Normalize((0.1,0.1,0.1),(1,1,1))])\nvalidation_transform = T.Compose([T.Resize((150,150)), T.ToTensor(), T.Normalize((0.1,0.1,0.1),(1,1,1))])\n# normalize has been used randomly\n\n# applying the transforms\ntrain_ds = ImageFolder(train_dir, train_transform)\nval_ds = ImageFolder(test_dir, validation_transform)\n\nprint(len(train_ds))\nprint(len(val_ds))","6446d98f":"train_ds.class_to_idx","fc374fe9":"train_ds.targets","c5c99c89":"batch_size = 150\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 3, pin_memory = True)\nval_dl = DataLoader(val_ds, batch_size * 2, num_workers = 3, pin_memory = True)","30b7b8e8":"def show_batch(dl):\n    for images, labels in dl: \n        \n        fig, ax = plt.subplots(figsize = (12, 12))\n        \n        ax.set_xticks([]); ax.set_yticks([])\n        \n        ax.imshow(make_grid(images[:64], nrow = 8).permute(1, 2, 0))\n        \n        break\n        \nshow_batch(train_dl)","f84e6d7c":"train_iter = iter(train_dl)\nprint(type(train_iter))\n\nimages, labels = train_iter.next()\n\nprint('images shape on batch size = {}'.format(images.size()))\nprint('labels shape on batch size = {}'.format(labels.size()))","adcbf3e0":"def accuracy(outputs, labels):\n    \n    _, preds = torch.max(outputs, dim = 1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    \n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        \n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        \n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        \n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n","6dd8bb02":"class LandscapeCNN(ImageClassificationBase):\n    \n    def __init__(self):\n        \n        super().__init__()\n        \n        # Using a pretrained model\n        self.network = models.resnet50(pretrained = True)\n        \n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 6)\n    \n    \n    def forward(self, inpt):\n        return torch.sigmoid(self.network(inpt))\n    \n    \n    # freeze function trains the fully connected layer to make predictions\n    def freeze(self):\n        \n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n            \n        for param in self.network.fc.parameters():\n            param.require_grad = True\n            \n            \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True","7738b584":"model = LandscapeCNN()\nmodel","39453422":"def get_default_device():\n    \n    #Pick GPU if available, else CPU\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \n    #Move tensor(s) to chosen device\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \n    #Wrap a dataloader to move data to a device\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        #Yield a batch of data after moving it to device\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        #Number of batches\n        return len(self.dl)","0025c499":"# getting the gpu \ndevice = get_default_device()\ndevice","2f96da57":"# transferring the dataloaders to the GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\n\n# transferring the model to the GPU\nmodel = to_device(LandscapeCNN(), device)","185c0ac1":"# making random predictions\ndef try_batch(dl):\n    \n    for images, labels in dl:\n        \n        print('images.shape:', images.shape)\n        out = model(images)\n        print('out.shape:', out.shape)\n        print('out[0]:', out[0])\n        break\n\ntry_batch(train_dl)","80f29534":"from tqdm.notebook import tqdm","4dfaa6d9":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    \n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    \n    return model.validation_epoch_end(outputs)\n\n\ndef get_lr(optimizer):\n    \n    for param_group in optimizer.param_groups:\n        return param_group['lr']  \n    \n\ndef fit(epochs, max_lr, model, train_loader, val_loader, opt_func, decay, grad_clip = None):\n    \n    # freeing up space on the GPU\n    torch.cuda.empty_cache()\n    history = []\n    \n    # defining the optimizer\n    optimizer = opt_func(model.parameters(), lr = max_lr, weight_decay = decay)\n    \n    # defining the scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs = epochs, steps_per_epoch = len(train_loader))\n    \n    for epoch in range(epochs):\n        \n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        \n        for batch in tqdm(train_loader):\n            \n            # calculating the loss and computing gradients\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # using gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # updating the lrs for the epochs\n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n    return history","3498cb64":"torch.cuda.empty_cache()\n# evaluating the model which is randomized\nevaluate(model, val_dl)","7732d684":"# freezing the model initially\nmodel.freeze()","8764f93b":"max_lr = 1e-2\nepochs = 4\nopt_func = torch.optim.Adamax\ndecay = 1e-4\ngrad_clip = 1e-1\nhistory = []","b8c022d2":"%%time\nhistory += fit(epochs, max_lr, model, train_dl, val_dl, opt_func, decay, grad_clip)","cc9cc46b":"# unfreezing the model\nmodel.unfreeze()\nepochs = 5","4745014d":"%%time\nhistory += fit(epochs, max_lr, model, train_dl, val_dl, opt_func, decay, grad_clip)","7007809e":"max_lr = 1e-3\nepochs = 3\nhistory += fit(epochs, max_lr, model, train_dl, val_dl, opt_func, decay, grad_clip)","e5530361":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","98bd325e":"plot_accuracies(history)","e5ce0674":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","8c828997":"plot_losses(history)","69dcf3b1":"def plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');","402e0823":"plot_lrs(history)","b1326e08":"def show_sample(img):\n    plt.imshow(img.permute(1, 2, 0))\n    \n    \n# function to predict a single image\ndef predict(image):\n    \n    xb = image.unsqueeze(0)\n    xb = to_device(xb, device)\n    preds = model(xb)\n    \n    max_ = torch.max(preds[0]).item()\n    prediction = classes[(preds[0] == max_).nonzero()]\n    \n    print(\"Prediction: \", prediction)\n    show_sample(image)","83f330c5":"pred_ds = ImageFolder(pred_dir, validation_transform)\n\nprint(len(pred_ds))","405f70b9":"image,target = pred_ds[0]\nprint(image.shape)","4f98a721":"predict(pred_ds[12][0])","739bdab8":"predict(pred_ds[3][0])","9ef293f7":"predict(pred_ds[9][0])","74e00f94":"predict(pred_ds[2][0])","1dfd893d":"predict(pred_ds[13][0])","2e12d083":"# getting the dataloader from the dataset\ntest_dl = DeviceDataLoader(DataLoader(pred_ds, batch_size, num_workers = 3, pin_memory = True), device)","f5be4301":"# getting the predictions for the entire test data loader\ndef predict_dl(dl, model):\n    \n    torch.cuda.empty_cache()\n    batch_probs = []\n    \n    for xb, _ in tqdm(dl):\n        probs = model(xb)\n        batch_probs.append(probs.cpu().detach())\n        \n    batch_probs = torch.cat(batch_probs)\n    return [x for x in batch_probs]","33f6989b":"test_preds = predict_dl(test_dl, model)","3fd3e56e":"# saving the predictions to the output folder\nsubmissions = pd.DataFrame()\nsubmissions.Label = test_preds\nsubmissions.head()","68c60eab":"# storing our submission into a .csv file\nsubmissions.to_csv(\"predictions.csv\")","991ad772":"!pip install jovian --upgrade\n\nimport jovian\n\njovian.commit(project = \"course-project\")","34b37915":"## Making Predictions","56cf3d2a":"### Forming the dataloader for our predictions","70afceae":"# Dataset:\n**So we are going to be using the intel-image classification dataset**","9dc894db":"### Getting the dataset for the predictions","f3996643":"## Models","d32b654e":"### Looking at the metrics for our training","7e14a324":"## Training the Model","b6bb311a":"### What are the dimensions of these images?","8cf73160":"### Creating the dataloaders","965b3e37":"The basic model : ImageClassificationBase","4fa7ecbb":"#### Losses","7cca600d":"## Let's look at the images in the train set","bc82bb66":"## Prepping the dataset","73d56ef9":"## Using the Resnet50 pretrained model","b7347a19":"### Looking at individual images and their predictions from our model","13caedef":"## **Training the Model**","66b6a8b0":"#### Accuracies","bff5bd0b":"Defining the transforms","1727232b":"## Transferring the model and the dataloaders to the GPU","754112b8":"#### Learning Rates"}}