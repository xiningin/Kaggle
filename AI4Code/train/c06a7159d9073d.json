{"cell_type":{"1669338b":"code","2daabc2e":"code","5d49a5ed":"code","12e7edda":"code","0ae4b90f":"code","7765e914":"code","9e087de7":"code","d0da8d46":"code","0b20338c":"code","453b832f":"code","f0dcec23":"code","814552c0":"code","7d13c6f5":"code","64aff68c":"code","8c329b0a":"code","ab6abee8":"code","a1ee2407":"code","f0ed8ac8":"code","a25694cf":"code","d6eb8c7d":"code","398c62a8":"code","f97bdd05":"code","24e48816":"code","b32b99d2":"code","1936c47c":"code","5c1c9516":"code","dc70cd08":"code","37b75a24":"markdown","1b0bdcde":"markdown","ff78aaf4":"markdown","e10f15d4":"markdown","b29080f0":"markdown","eac3bfe1":"markdown","70af9f30":"markdown","7f7eef8e":"markdown","2f78e11d":"markdown","dcbf4b7a":"markdown","33992a38":"markdown","33688d67":"markdown"},"source":{"1669338b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import img_to_array,load_img\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\nimport os\nfrom bs4 import BeautifulSoup","2daabc2e":"img_folder = '\/kaggle\/input\/face-mask-detection\/images\/'\nannot_folder = '\/kaggle\/input\/face-mask-detection\/annotations\/'","5d49a5ed":"desc = []\nfor dirname, _, filenames in os.walk(annot_folder):\n    for filename in filenames:\n        desc.append(os.path.join(dirname, filename))\n","12e7edda":"img_name,label = [],[]\n\nfor d in desc:\n    content = []\n    n = []\n\n    with open(d, \"r\") as file:\n        content = file.readlines()\n    content = \"\".join(content)\n    soup = BeautifulSoup(content,\"html.parser\")\n    file_name = soup.filename.string\n    name_tags = soup.find_all(\"name\")\n    \n\n    for t in name_tags:\n        n.append(t.get_text())\n        \n    # slecting tag with maximum occurence in an image (If it has multiple tags)\n    name = max(set(n), key = n.count)\n  \n    img_name.append(file_name)\n    label.append(name)\n ","0ae4b90f":"img_name","7765e914":"# One Hot Encoding label data\nlabels = pd.get_dummies(label)\nlabels.head()","9e087de7":"# Our target classes\nclasses = list(labels.columns)\nclasses","d0da8d46":"data, target = [],[]\nimg_h, img_w = 256, 256\n\nfor i in range(len(img_name)):\n    name = img_name[i]\n    path = img_folder + name\n    \n    image = load_img(path, target_size = (img_h, img_w))\n    image = img_to_array(image)\n    data.append(image)\n    target.append(tuple(labels.iloc[i,:]))","0b20338c":"# Convering list to array\ndata=np.array(data,dtype=\"float32\")\/255.0\ntarget=np.array(target,dtype=\"float32\")","453b832f":"plt.figure(figsize=(10, 10))\nfor i,j in enumerate(np.random.randint(1, 500, 9, dtype=int)):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(data[j])\n    plt.title(label[j])\n    plt.axis(\"off\")","f0dcec23":"# Shape of data and target\ndata.shape, target.shape","814552c0":"# Splitting into train and test data\ntrain_img,test_img,y_train,y_test=train_test_split(data,target,test_size=0.2,random_state=20)","7d13c6f5":"print(\"Train shapes : \",(train_img.shape, y_train.shape))\nprint(\"Test shapes : \",(test_img.shape, y_test.shape))","64aff68c":"num_classes = 3\nmodel = Sequential([\n    layers.Conv2D(16,3,padding = \"same\", activation = \"relu\", input_shape=(img_h, img_w, 3)) ,\n    layers.MaxPooling2D(),\n    layers.Conv2D(32,3,padding = \"same\", activation = \"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64,3,padding = \"same\", activation = \"relu\"),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(128,activation = \"relu\"),\n    layers.Dense(num_classes,activation = \"softmax\")\n])","8c329b0a":"model.compile(optimizer='adam',\n              loss=\"categorical_crossentropy\",\n              metrics=['accuracy'])","ab6abee8":"model.summary()","a1ee2407":"epochs = 15\nhistory = model.fit(train_img,y_train,\n                    validation_data=(test_img,y_test),batch_size=16,epochs=epochs)\n","f0ed8ac8":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","a25694cf":"# Data augmentation layer\n\ndata_augmentation = Sequential(\n  [\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(img_h, img_w, 3)),\n    layers.experimental.preprocessing.RandomRotation(0.1),\n    layers.experimental.preprocessing.RandomZoom(0.1),\n  ]\n)","d6eb8c7d":"num_classes = 3\nmodel_new = Sequential([\n    data_augmentation,\n    layers.Conv2D(16,3,padding = \"same\", activation = \"relu\", input_shape=(img_h, img_w, 3)) ,\n    layers.MaxPooling2D(),\n    layers.Conv2D(32,3,padding = \"same\", activation = \"relu\"),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64,3,padding = \"same\", activation = \"relu\"),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.3), # Dropout Layer\n    layers.Flatten(),\n    layers.Dense(128,activation = \"relu\"),\n    layers.Dense(num_classes,activation = \"softmax\")\n])","398c62a8":"model_new.compile(optimizer='adam',\n              loss=\"categorical_crossentropy\",\n              metrics=['accuracy'])","f97bdd05":"model_new.summary()","24e48816":"epochs = 20\nhistory = model_new.fit(train_img,y_train,\n                    validation_data=(test_img,y_test),batch_size=16,epochs=epochs)\n","b32b99d2":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","1936c47c":"y_pred_1 = model_new.predict(data[100].reshape(-1,img_h,img_w,3))\nprint(classes[np.argmax(y_pred_1)])\nplt.imshow(data[100])","5c1c9516":"y_pred_2 = model_new.predict(data[2].reshape(-1,img_h,img_w,3))\nprint(classes[np.argmax(y_pred_2)])\nplt.imshow(data[2])","dc70cd08":"y_pred_3 = model_new.predict(data[200].reshape(-1,img_h,img_w,3))\nprint(classes[np.argmax(y_pred_3)])\nplt.imshow(data[200])","37b75a24":"## Importing useful libraries","1b0bdcde":"## Checking predictions","ff78aaf4":"### Generating and fitting Model","e10f15d4":"* Model is giving correct predictions","b29080f0":"## Loading and preprocessing Data","eac3bfe1":"### Visualizing few images randomly","70af9f30":"### Extracting image name and class from xml file","7f7eef8e":"* Model decently fitted on data and overfitting removed","2f78e11d":"* Final validation loss = 2.6\n* Final validation accuracy = 0.73","dcbf4b7a":"* Model seems to overfit on data, so we will use data augmentation and dropout to avoid this","33992a38":"### Loading Images and converting them to pixel array","33688d67":"* Final validation loss = 0.71\n* Final validation accuracy = 0.76\n\n* Model Improved"}}