{"cell_type":{"60fedabc":"code","c6f1e6a3":"code","7474612a":"code","10973127":"code","71813979":"code","8b6d70dc":"code","18616e50":"code","f5087f24":"code","b44e30fb":"code","aca1ed54":"code","30ed6056":"code","20ea72a6":"code","6b23c61d":"code","98ea95e6":"code","3c8e0e4e":"code","8c22be8e":"code","beb84f78":"code","0e078150":"code","b401477a":"code","1c08e70e":"code","2d2e0fa7":"code","f4e2e8aa":"code","8566bf26":"code","0175a523":"code","bfaced6f":"code","ea14f68d":"code","9b682a88":"code","810afc9f":"code","85ef9258":"code","9e28168a":"markdown","2e6a3a5e":"markdown","edb591e3":"markdown","1e5a3eec":"markdown","27c82d47":"markdown","c4f48cb2":"markdown","b904e9f6":"markdown","14cd79ab":"markdown","a56e99be":"markdown","601955be":"markdown","7f352ebf":"markdown","065ef002":"markdown"},"source":{"60fedabc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.","c6f1e6a3":"df = pd.read_csv('..\/input\/Reviews.csv',nrows=100000)\n#df = df_full[:10000]\nprint(\"Dimension\",df.shape)\ndf.head()","7474612a":"df.describe()","10973127":"# Calculating length of reviews and adding it as a column\ndf['TextLength'] = df['Text'].apply(lambda x: len(x)-x.count(' '))\ndf.head()","71813979":"df.Score.value_counts().sort_index().plot.bar(alpha=0.7, grid=True, color = 'seagreen', width = 0.9)\nplt.xlabel('Score')\nplt.ylabel('Number Of Reviews')\nplt.title('Distribution of reviews over each score')\nplt.show()","8b6d70dc":"# How many empty length texts are there ?\ndf[df['TextLength']==0].Text.count()","18616e50":"plt.scatter(df['Score'], df['TextLength'])\nplt.xlabel('Score')\nplt.ylabel('Text Lengths')\nplt.title('Relation B\/W Text Length and Scores')\nplt.show()","f5087f24":"sns.pairplot(df)\nplt.show()","b44e30fb":"import nltk\nimport string\nfrom nltk.stem import PorterStemmer\nimport re\nfrom nltk.corpus import stopwords\nstopwords_en = set(stopwords.words('english'))\nps = PorterStemmer()","aca1ed54":"def clean_text(text):\n    text = text.lower() #converting text to lowercase\n    text = ' '.join([i for i in nltk.word_tokenize(text) if i not in stopwords_en and i not in string.punctuation]) #stopword and punct removal\n    text = re.sub('[^a-z]+', ' ', text) #removal of anything other than English letters\n    text = ' '.join([ps.stem(i) for i in nltk.word_tokenize(text)]) #stemming\n    return text","30ed6056":"# Apply the cleanup and create a new column\ndf['CleanText'] = df['Text'].apply(lambda x: clean_text(x))\ndf.head(3)","20ea72a6":"def partition(val):\n    if(val>2):\n        return 1\n    return 0\ndf['Positivity']=df['Score'].apply(lambda x: partition(x))\ndf.head(3)","6b23c61d":"required_columns = ['CleanText', 'Positivity']\ndf = df[required_columns]\ndf.head()","98ea95e6":"df.Positivity.value_counts().plot.bar(alpha=0.5, grid=True)\nplt.title('Distribution Of Positive & Negative Reviews')\nplt.ylabel('Counts')\nplt.show()","3c8e0e4e":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df['CleanText'], df['Positivity'], test_size=0.25, random_state=42, shuffle=True, stratify=df['Positivity'])\nprint(\"Dataset Splitted ... \\nTrain Set Size = {}\\nTest Set Size  = {}\".format(X_train.shape[0], X_test.shape[0]))","8c22be8e":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vectoriser = TfidfVectorizer()\n\n# Training % Feature Extraction On Entire Dataset, Used For Cross Validation & Model Comparison\nfeatures = tfidf_vectoriser.fit_transform(df['CleanText'])\nlabelss = df['Positivity'].astype(int)","beb84f78":"# Training On Only Train Set Now\ntfidf_vectoriser.fit(X_train)\nX_train_tf = tfidf_vectoriser.transform(X_train)\nX_test_tf = tfidf_vectoriser.transform(X_test)\nX_train_tf.shape, X_test_tf.shape","0e078150":"import random\nprint(\"Ten Random Words from Training Set ...\\n\",*random.sample(tfidf_vectoriser.get_feature_names(),10))","b401477a":"from sklearn.feature_selection import chi2\nchi2score = chi2(X_train_tf, y_train)[0]\nplt.figure(figsize=(16,8))\nscores = list(zip(tfidf_vectoriser.get_feature_names(), chi2score))\nchi2 = sorted(scores, key=lambda x:x[1])\ntopchi2 = list(zip(*chi2[-20:]))\nx = range(len(topchi2[1]))\nlabels = topchi2[0]\nplt.barh(x,topchi2[1], align='center', alpha=0.5)\nplt.plot(topchi2[1], x, '-o', markersize=5, color='r')\nplt.yticks(x, labels)\nplt.xlabel('$\\chi^2$')\nplt.show();","1c08e70e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score","2d2e0fa7":"models = [\n    LinearSVC(),\n    MultinomialNB(),\n    LogisticRegression(random_state=0),\n    RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0)\n]\nCV = 5\ncv_df = pd.DataFrame(index=range(CV * len(models)))\nentries = []\nfor model in models:\n    model_name = model.__class__.__name__\n    accuracies = cross_val_score(model, features ,labelss, scoring='accuracy', cv=CV)\n    for fold_idx, accuracy in enumerate(accuracies):\n        entries.append((model_name, fold_idx, accuracy))\ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])","f4e2e8aa":"plt.figure(figsize=(10,6))\nsns.boxplot(x='model_name', y='accuracy', data=cv_df)\nsns.stripplot(x='model_name', y='accuracy', data=cv_df, \n              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\nplt.show()","8566bf26":"from sklearn.model_selection import GridSearchCV\nparam_grid = {\n    'C':[0.5,0.8,1.0,1.5]\n}\nsvm = LinearSVC(max_iter=1500)\nsvm_cv = GridSearchCV(svm, param_grid, cv=5)\nsvm_cv.fit(features, labelss)\nprint(\"Best Parameters :\", svm_cv.best_params_)\nprint(\"Best Score :\",svm_cv.best_score_)","0175a523":"svm = LinearSVC(C=0.5, max_iter=2000)\nsvm.fit(X_train_tf, y_train)","bfaced6f":"from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\ny_pred = svm.predict(X_test_tf)\nprint(classification_report(y_test, y_pred, target_names=['Negative','Positive']))\nprint(\"Accuracy :\",accuracy_score(y_test, y_pred), end='\\n\\n')\nconf_mat = confusion_matrix(y_test, y_pred)\nprint(conf_mat)","ea14f68d":"fig = plt.figure(figsize=(6,6))\nax = fig.add_subplot(111)\ncax = ax.matshow(conf_mat, alpha=0.8)\nplt.title('Confusion Matrix of the Linear SVC Classifier')\nfig.colorbar(cax)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","9b682a88":"cm_normalized = conf_mat.astype('float') \/ conf_mat.sum(axis=1)[:, np.newaxis]\nfig = plt.figure(figsize=(7,7))\nax = fig.add_subplot(111)\ncax = ax.matshow(cm_normalized, alpha=0.8)\nplt.title('Normalized Confusion Matrix of the Linear SVC Classifier')\nfig.colorbar(cax)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","810afc9f":"from sklearn.calibration import CalibratedClassifierCV\ncclf = CalibratedClassifierCV(base_estimator=svm, cv=\"prefit\")\ncclf.fit(X_train_tf, y_train)","85ef9258":"y_pred_prob = cclf.predict_proba(X_test_tf)[:,1]\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='Linear SVC')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Linear SVC ROC Curve')\nplt.show();\nprint(\"ROC AUC Score :\", roc_auc_score(y_test, y_pred_prob))","9e28168a":"## Brief Exploratory Data Analysis","2e6a3a5e":"**Author** - [Amitrajit Bose](http:\/\/amitrajitbose.github.io) <br>\n**Date Of Creation** - Jan 31, 2019 <br>\n**Vectorization Method** - TF-IDF <br>\n**Classifier** - [Linear Support Vector Machine](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC) (LIBLINEAR)\n**Dataset Details** <br>\n- Total Row Count = 500000\n- Rows Used In Notebook = 100000\n- Test Ratio = 0.25","edb591e3":"### Top Most Prominent Features\nBy Chi-Square Feature Selection","1e5a3eec":"## Tuning Hyperparameters","27c82d47":"## Evaluation Metrics","c4f48cb2":"> This indicates that there is no noteworthy correlation between text length and score.","b904e9f6":"> This indicates that there are no empty rows of text content","14cd79ab":"## Train Test Split","a56e99be":"## Data Preprocessing & Cleansing","601955be":"## Compare Various Classification Models","7f352ebf":"**Remarks** <br>\nWe can improve the accuracy with non-linear classifiers and neural networks like LSTM. This is a simple approach backed by good data preprocessing.","065ef002":"## Text Vectorisation\n\nUsing TF-IDF Vectorizer"}}