{"cell_type":{"a6c164fd":"code","136d3423":"code","92eb6d45":"code","e67c6763":"code","899fe99d":"code","ae85d1ad":"code","5b10ffd0":"code","a6291bfd":"code","c57588ec":"code","e2567bc3":"code","dc38e7bf":"code","2e2426b2":"code","170b0ad4":"code","943d3532":"code","7693bcdf":"code","9b278d5f":"code","6efbd8b0":"code","4484ecdb":"code","cbfedba7":"code","0002792b":"code","5e5136d8":"code","1be6d754":"code","3d7371dd":"code","838ec66e":"markdown","afceff0e":"markdown","16830596":"markdown","19a50ca3":"markdown","7d5599d7":"markdown","c248d563":"markdown","1a48e974":"markdown","c64ded17":"markdown","6cdc4606":"markdown","78bc25a9":"markdown","027802c2":"markdown","78e3be10":"markdown","1236a1f8":"markdown","6f0c3913":"markdown"},"source":{"a6c164fd":"import numpy as np \nimport pandas as pd \nimport os\n","136d3423":"def find_all(word, text):\n    import re\n    word = word.replace(\".\",\"\\.\")\n    word = word.replace(\")\",\"\\)\")\n    word = word.replace(\"(\",\"\\(\")\n    word = word.replace(\"?\",\"\\?\")\n    word = word.replace(\"!\",\"\\!\")\n    word = word.replace(\"*\",\"\\*\")\n    word = word.replace(\"$\",\"\\$\")\n    word = word.replace(\"[\",\"\\[\")\n    word = word.replace(\"]\",\"\\]\")\n    word = word.replace(\"+\",\"\\+\")\n    return [m.start() for m in re.finditer(word, text)]\n               \ndef extract_end_index(text, selected_text):\n    i=0\n    last_word = selected_text.split()[-1]\n    index_last_word = find_all(last_word, text)\n    n_occ = len(index_last_word)\n    \n    selected_text_split = selected_text.split()\n    text_split = text.split()\n    n_end = 0\n    if len(selected_text_split)==len(text_split):\n        return len(text)\n    for j, elm in enumerate(text_split[len(selected_text_split):]):\n        i = j + len(selected_text_split)\n        if elm == last_word :\n            n_end +=1\n            if text_split[j+1:i+1] == selected_text_split:\n                break\n   \n    return index_last_word[n_end-1] + len(selected_text_split[-1])\n\ndef extract_start_index(text, selected_text):\n    first_word = selected_text.split()[0]\n    index_first_word = find_all(first_word, text)\n    n_occ = len(index_first_word)\n    \n    selected_text_split = selected_text.split()\n    text_split = text.split()\n    n_start = 0\n    for i, elm in enumerate(text_split):\n        if (first_word !=elm) and (first_word in elm):\n            n_start += elm.count(first_word)\n        if elm == first_word :\n            n_start +=1\n            if text_split[i:i+len(selected_text_split)] == selected_text_split:\n                break\n    return index_first_word[n_start-1]\n\ndef jaccard(str1, str2): \n    a = set(str(str1).lower().split()) \n    b = set(str(str2).lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n\ndef pp_v2(text, predicted, spaces):\n    text = text.lower()\n    predicted = predicted.strip()\n    try : \n        index_start = extract_start_index(text,predicted)\n        index_end = extract_end_index(text,predicted)\n        if text[index_start:index_end]==\"\":\n            return predicted\n    except:\n        return predicted\n  \n    if spaces == 1:\n        return text[max(0,index_start-1):index_end]\n    elif spaces == 2:\n        return text[max(0,index_start-2):index_end]\n    elif spaces == 3:\n        return text[max(0,index_start-3):index_end-1]\n    elif spaces == 4:\n        return text[max(0,index_start-4):index_end-2]\n    else:\n        return predicted","92eb6d45":"original_data = pd.read_csv(\"..\/input\/emotion\/text_emotion.csv\")\ncompetition_data = pd.read_csv(\"..\/input\/tweet-sentiment-extraction\/train.csv\")\nmy_predictions = pd.read_csv(\"..\/input\/tweets-predictions\/prediction_examples.csv\")","e67c6763":"def impossible_to_predict(text, selected_text):\n    text = str(text)\n    selected_text = str(selected_text)\n    \n    text = set(text.split())\n    selected_text = set(selected_text.split())\n    \n    return not selected_text.issubset(text)","899fe99d":"competition_data[\"is_impossible\"] = competition_data.apply(lambda x:impossible_to_predict(x.text, x.selected_text), axis=1)\ncompetition_data[\"is_impossible\"].sum()","ae85d1ad":"competition_data[competition_data[\"is_impossible\"]==True]","5b10ffd0":"print(competition_data.loc[27470].text)","a6291bfd":"t = \"did you fall asleep??\"\nt= t.lower()\nprint(original_data[original_data.content.str.lower().str.contains(t.lower())].content.values[0])\nprint(competition_data.loc[27470].text)","c57588ec":"print(competition_data.loc[27476].text)","e2567bc3":"t = \"wish we could come see u\"\nt= t.lower()\nprint(original_data[original_data.content.str.lower().str.contains(t.lower())].content.values[0])\nprint(competition_data.loc[27476].text)","dc38e7bf":"print(competition_data.loc[27477].text)","2e2426b2":"t = \"wondered about rake to.\"\nt= t.lower()\nprint(original_data[original_data.content.str.lower().str.contains(t.lower())].content.values[0])\nprint(competition_data.loc[27477].text)","170b0ad4":"def calculate_spaces(text, selected_text):\n    text = str(text)\n    selected_text = str(selected_text)\n    index = text.index(selected_text)\n    x = text[:index]\n    try:\n        if x[-1]==\" \":\n            x= x[:-1]\n    except:\n        pass\n    l1 = len(x)\n    l2 = len(\" \".join(x.split()))\n    return l1-l2","943d3532":"competition_data[\"extra_spaces\"] =  competition_data.apply(lambda x:calculate_spaces(x.text, x.selected_text), axis=1)","7693bcdf":"competition_data[competition_data.extra_spaces==2].head(20)","9b278d5f":"competition_data[competition_data.extra_spaces>3].head(20)","6efbd8b0":"# 1. Calculate the number of extra spaces in the text. We will call this n_extra_spaces\n# 2. Shift your predicted_selected_text n_extra_spaces in the beginning to the left\n# 3. Shift your predicted_selected_text max((n_extra_spaces-2),0) in the end to the left","4484ecdb":"my_predictions","cbfedba7":"print(f\"Score without reversing the trick is {my_predictions.score.mean()}\")","0002792b":"def calculate_spaces(text, selected_text):\n    text = str(text)\n    selected_text = str(selected_text)\n    text = text.lower()\n    selected_text = selected_text.lower().strip()\n    index = extract_start_index(text, selected_text)\n    x = text[:index]\n    try:\n        if x[-1]==\" \":\n            x= x[:-1]\n    except:\n        pass\n    l1 = len(x)\n    l2 = len(\" \".join(x.split()))\n    return l1-l2\nmy_predictions[\"extra_spaces\"] =  my_predictions.apply(lambda x:calculate_spaces(x.text, x.predicted), axis=1)","5e5136d8":"my_predictions[\"new_selected\"] = my_predictions.apply(lambda x: pp_v2(x.text, x.predicted,x.extra_spaces), axis=1)","1be6d754":"my_predictions[\"new_score\"] = my_predictions.apply(lambda x: jaccard(x.selected_text, x.new_selected), axis=1)","3d7371dd":"print(f\"Score after rebuilding the noise is : {my_predictions.new_score.mean()}\")","838ec66e":"# index = 27476","afceff0e":"# I hope a part of the trick is well explained here.\n# The question now: is this magic or leak or what?\n# Thank you","16830596":"# Let's apply it to some predictions","19a50ca3":"# Can you see the trick? look at the noise in the selected_text above...\n# Congrats you find the magic. Let's do a further step","7d5599d7":"# Did any one wonder about the reason: why the selected_text has a lot of noise? \n \n# Well, I was one of the Kagglers who thought about this question and I was 100% sure that explaining the reason of these noisy targets is the secret for jumping in the top LB. After all, it is hosted by Kaggle and I don't think that Kaggle wanted to use noisy labels to challenge us(this is not helpful in real life).\n\n# I was asking myself a lot of questions and I made a lot of hypothisis to explain the errors. Until the day, I found the original data in a shared kernel ([here](https:\/\/www.kaggle.com\/jonathanbesomi\/private-test-not-that-private-afterall))\n\n# When comparing the competition data with the original data I realized that all the mentions in the tweets were removed (@Mohamed @love123 @azeikhff ect...) from the text and I remarked that the majority of the tweets which were filtred from these mentions have noisy labels. Starting from this point I found a way to reverse engineer the selected_text from the correct one to the noisy style lol.\n\n# Let's try to print some examples and try to find some points in common.\n","c248d563":"# We will need these functions later","1a48e974":"# As you can see we have 2905 samples at least that are impossible to predict. \n# Let's print them and print their original tweet","c64ded17":"# index = 27477","6cdc4606":"# Can you see a common point? Yes!! I do.\n# All of these sentences have extra spaces. Look at the beginning of each sentence... It has an extra space... Not only that but for the index = 27477 we have a second extra space \".  The client\" There are 2 spaces between the point and \"the client\" and it should be one space.\n# Lets calculate the number of extra spaces for all sentences","78bc25a9":"# index = 27470","027802c2":"# The rows number 27470, 27476, 27477 have the same problem which is an extra letter at the beginning","78e3be10":"# still noise but this time the noise is more intense (3 extra letters instead of one in the left and missing letter in the right)\n\n# Can you now elaborate the magic?\n\n# Here is the reverse of the noise:\n","1236a1f8":"# This function will help us to extract some samples that are impossible to predicted using a word level tokenization","6f0c3913":"# Let's apply the postprocessing to build the noise"}}