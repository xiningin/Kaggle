{"cell_type":{"5502e836":"code","0fe2293e":"code","799657c5":"code","98056bcf":"code","0bc0b5f5":"code","ad7fcc2b":"code","909b38d2":"code","ecc803cb":"code","8f886aa0":"code","5b0d43f2":"code","0113ce40":"code","07f24e0b":"code","10bd8885":"markdown","1ba51864":"markdown","e1aa0721":"markdown","9bb67d13":"markdown","fb087979":"markdown","629955c5":"markdown","96e538de":"markdown"},"source":{"5502e836":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0fe2293e":"# import the train & test sets\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\n# create vectors with the images and the labels data\n\n# train set\nX_train = train.loc[:, train.columns != 'label']\ny_train = train[\"label\"]\n\n# convert to numpy array\nX_train = X_train.values\ny_train = y_train.values\n\nprint(\"Dimensions of the train images' vector: {}\".format(X_train.shape))\nprint(\"Dimensions of the train labels' vector: {}\".format(y_train.shape))\n\n# test set to numpy array\nX_test = test.values\n\nprint(\"Dimensions of the test images' vector: {}\".format(X_test.shape))\n\n# number of classes & labels\nn_classes = 10\nlabels_text = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n\n","799657c5":"# visualize some random numbers of each class\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, n_classes, figsize=(20,20))\n\nidxs = [np.where(y_train == i)[0] for i in range(n_classes)]\n\nfor i in range(n_classes):\n    k = np.random.choice(idxs[i])\n    ax[i].imshow(X_train[k].reshape(28, 28), cmap=\"gray\")\n    ax[i].set_title(\"{}\".format(labels_text[i]))","98056bcf":"# train - val sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state=42)\n\nprint(\"Dimensions of the train images' vector: {}\".format(X_train.shape))\nprint(\"Dimensions of the train labels' vector: {}\".format(y_train.shape))\n\nprint(\"Dimensions of the validation images' vector: {}\".format(X_val.shape))\nprint(\"Dimensions of the validation labels' vector: {}\".format(y_val.shape))\n   ","0bc0b5f5":"# apply PCA to reduce dimensionality\n\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=100, random_state=2017)\npca_fit = pca.fit(X_train)\nX_train_pca = pca_fit.transform(X_train)\nX_val_pca = pca_fit.transform(X_val)\nX_test_pca = pca_fit.transform(X_test)\n\ndef label_proportion(y):\n    '''Function that gives the proportion of each class (digit) in the dataset'''\n    _, count = np.unique(y, return_counts=True)\n    return np.true_divide(count, y.shape[0])\n    \n\nprint(\"No. of available PCA images to train: {}\".format(X_train_pca.shape[0]))\nprint(\"No. of available PCA images to validate: {}\".format(X_val_pca.shape[0]))\n\nprint(\"Proporci\u00f3n of the classes in the train set:\\n{}\\n\".format(label_proportion(y_train)))\n\n# display the proportions for each class\nproportions = pd.DataFrame({'Class':labels_text,'Proportion':label_proportion(y_train)})\nprint(proportions)","ad7fcc2b":"# hyperparameter tuning\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom time import time\n\n\nknn = KNeighborsClassifier()\n\n# subset of the training set, to speed up the computations\nn = 4000\nimages_subs = X_train_pca[0:n,]\nlabel_subs = y_train[0:n]\n\n# define the parameter values that should be searched \n\n# k (number of neighbourhoods): values from 1 to 10\nk_range = list(range(1, 11))\n# different weights values\nweights = ['uniform', 'distance']\n\n# create a parameter grid: map the parameter names to the values that should be searched\nparam_grid = dict(n_neighbors=k_range, weights = weights)\n\n# instantiate the grid\ngrid = GridSearchCV(knn, param_grid, cv=4, scoring='accuracy')\n\n# fit the grid with data & check elapsed time\nstart = time()\ngrid.fit(images_subs, label_subs)\nend = time()\n\nprint(\"Elapsed time {} s.\".format(end - start))\n\nprint('\\n-----------------\\n')\n\nmeans = grid.cv_results_[\"mean_test_score\"]\nstds = grid.cv_results_[\"std_test_score\"]\nparameters = grid.cv_results_['params']\nranks = grid.cv_results_['rank_test_score']\n\n# print the results for each of the different combinations. \n# The one which has rank 1 would be the most accurate.\nfor rank, mean, std, param in zip(ranks, means, stds, parameters):\n    print(\"{}. Average accuracy {:.2f} with S.D {:.2f}. The parameters are: {}.\".format(rank, mean*100, std*100, param))","909b38d2":"from sklearn.metrics import accuracy_score\n\n# Show the optimal hyperparameters \nprint(\"Optimal value for k: {}\".format(grid.best_params_[\"n_neighbors\"]))\nprint(\"Optimal value for weights: {}\".format(grid.best_params_[\"weights\"]))\n\n# We call the model with the best parameters\nknn_model = grid.best_estimator_\n\n# and fit it to the PCA train dataset\nknn_model.fit(X_train_pca,y_train)\n\n# predict with the model on the PCA validation data\ny_pred = knn_model.predict(X_val_pca)\n\n# Compute the accuracy\nacc = accuracy_score(y_val, y_pred)\n\nprint('Accuracy of the model on the (PCA) val. data: {:.2f}% '.format(acc*100))","ecc803cb":"import itertools\nfrom sklearn.metrics import confusion_matrix\n\nconf_mat = confusion_matrix(y_val, y_pred)\n\n# confusion matrix\ndef plot_confusion_matrix(cm, classes):\n    cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n   \n    cmap=plt.cm.Blues\n    fig= plt.figure(figsize=(8,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() * 2 \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], \".2f\"),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# print the matrix\nplot_confusion_matrix(conf_mat, classes=labels_text)\n\n\n\n# plot of 5 cases of wrong classification\nfig, ax = plt.subplots(1, n_classes, figsize=(20,20))\n\nidxs = [np.where((y_val == i) & (y_pred != i))[0] for i in range(n_classes)]\n\nfor i in range(n_classes):\n    k = np.random.choice(idxs[i])\n    ax[i].imshow(X_val[k].reshape(28, 28), cmap=\"gray\")\n    ax[i].set_title(\"True: {}\\n Predicted: {}\".format(labels_text[y_val[k]], labels_text[y_pred[k]]))\n        \n","8f886aa0":"#import the modules\nimport keras\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import SGD\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import uniform \nfrom scipy.stats import randint\nfrom time import time\nimport random \n\n# set a seed for reproducibility\nrandom.seed(2)\n\nkf = StratifiedKFold(n_splits=4)\n\nn_iter_search = 10\nparameters = np.zeros((n_iter_search, 3))\n\nn_neurons_dist = randint(low=20, high=1000)\nn_epochs_dist = randint(low=10, high=150)\nlr_dist = uniform(loc=0.0001, scale=0.2)\n\nbest_iter = -1\nmax_score = 0\n    \nstart = time()\nfor i in range(n_iter_search):\n    n_neurons = n_neurons_dist.rvs()\n    n_epochs = n_epochs_dist.rvs()\n    lr = lr_dist.rvs()\n    \n    parameters[i, 0] = n_neurons\n    parameters[i, 1] = n_epochs\n    parameters[i, 2] = lr\n    \n    print(\"\\n Iteration number {}-----------------\\n\".format(i+1))\n    print(\"Parameters: No. of neurons in the hidden layer: {}; No. of epochs: {}; Learning rate: {}\".format(n_neurons, n_epochs, lr))\n\n    scores = np.zeros(4)\n    j = 0\n    \n    # loop through the 4-folds: create a train-test split and check the accuracy of the model on those test sets\n    for train_index, test_index in kf.split(X_train_pca, y_train):\n        # update train and test for this fold\n        X_train_kf, X_test_kf = X_train_pca[train_index], X_train_pca[test_index]\n        y_train_kf, y_test_kf = y_train[train_index], y_train[test_index]\n        \n        # one-hot encoding on the target data\n        y_train_kf = keras.utils.to_categorical(y_train_kf, num_classes = n_classes)\n        y_test_kf = keras.utils.to_categorical(y_test_kf, num_classes = n_classes)\n        \n        # create the neural network model -------------------\n        model = Sequential()\n        # hidden layer: 100: dimension of the input data: X_train_pca; n_neurons: number of neurons of the layer\n        model.add(Dense(n_neurons, input_shape=(100,), activation=\"sigmoid\"))\n        # output layer: with softmax activation, as we have a classification problem\n        model.add(Dense(n_classes, activation='softmax'))\n        \n        # compile the model with the optimizer: Stoch. gradient descent with learning rate = lr\n        model.compile(optimizer=SGD(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n        \n        # fit the model with the number of epochs n_epochs\n        model.fit(X_train_kf, y_train_kf, epochs = n_epochs, verbose=0)\n        \n        # check the accuracy on the test data\n        score = model.evaluate(X_test_kf, y_test_kf, verbose=0)\n        \n        # store the score on the scores array\n        scores[j] = score[1]\n        j += 1\n    \n    # compute the mean and SD of the accuracies obtained in the previous loop\n    score_mean = np.mean(scores)\n    score_std = np.std(scores)\n    \n    print(\"Results: average accuracy: {:.2f}%, with {:.2f} S.D.\".format(score_mean*100, score_std*100))\n    \n    # update the value of the maximum score achieved: to obtain the value of the parameters which gave the best acc.\n    if (score_mean > max_score):\n        max_score = score_mean\n        best_iter = i\n\nend = time()\n\nprint(\"Elapsed time: {} s.\".format(end - start))\n","5b0d43f2":"from sklearn.metrics import accuracy_score\n\n\nprint(\"Optimal number of neurons: {}\".format(int(parameters[best_iter, 0])))\nprint(\"Optimal number of epochs: {}\".format(int(parameters[best_iter, 1])))\nprint(\"Optimal learning rate: {:.4f}\".format(parameters[best_iter, 2]))\n\n# create the model with the optimal parameters\nNN_model = Sequential()\nNN_model.add(Dense(int(parameters[best_iter, 0]), input_shape=(100,), activation=\"sigmoid\"))\nNN_model.add(Dense(n_classes, activation='softmax'))\n\nNN_model.compile(optimizer=SGD(lr=parameters[best_iter, 2]), loss='categorical_crossentropy', metrics=['accuracy'])\n\nNN_model.fit(X_train_pca, keras.utils.to_categorical(y_train, num_classes=n_classes), epochs=int(parameters[best_iter, 1]), verbose=0)\n\n# -------------brief explanatory note: why we need to use np.argmax----------------\n# The following line returns the predicted classes for each sample: the argmax acts as the 'inverse' of to_categorical: \n# references: 1) https:\/\/forums.fast.ai\/t\/why-using-np-argmax-for-getting-predictions\/14937\/2\n# 2)https:\/\/github.com\/keras-team\/keras\/issues\/4981\n\n# The model.predict function outputs the values for the 5 neurons in the output layer. \n# We can see those values as probabilities that the given instance belongs to a given class (each class is represented by a neuron in the output layer)\n# The predicted class will be the maximum of those values, i.e., the class to which the instance is most likely to belong (it is required to use the softmax activation!)\ny_pred = np.argmax(NN_model.predict(X_val_pca, verbose=0), axis=1)\n\naccuracy =  accuracy_score(y_val, y_pred)*100\nprint(\"Accuracy of the model on the (PCA) test data: {:.2f}%\".format(accuracy))\n","0113ce40":"print(X_test.shape)\n\nX_val.shape","07f24e0b":"# Create output file from the first model\n\n# predictions using the test file\npredicted_classes = knn_model.predict(X_test_pca)\npredicted_classes\n\n\n# create output dataframe and file\noutput = pd.DataFrame()\n\noutput[\"ImageId\"] = [i for i in range(1, predicted_classes.shape[0]+1)]\noutput[\"Label\"] = predicted_classes\n\noutput.to_csv(\"predicted_classes.csv\", index=False)","10bd8885":"Once again, let us pick the best performing model and compute the accuracy using the validation set","1ba51864":"Some of those wrongly-classified examples, are really difficult to classify correclty, even by humans, like the 6 classified as a 1 or the 8 classified as a 6.\nOthers, like the 9 classified as 3 are easier and should be correctly classified.\n\n\nWe obtained an accuracy of the 97.23% with a simple kNN model. \n","e1aa0721":"## Neural networks\n\nIn this section, we will explore other model, this one based on neural networks, to check if the accuracy can be improved a little bit.\n\nFor this model, we will also perform hyperparameter tuning, to determine which parameters give the best accuracy.\nIn this ocasion, the parameters that will be tuned are: learning rate, number of hidden layers of the network and the number of epochs.","9bb67d13":"The accuracy is (surprisingly) a little bit lower than in the knn model.","fb087979":"Now, we can pick the best performing model and use it to check the accuracy obtained in the validation set.","629955c5":"Now, we can see how the model performed in two different ways. First, we can compute the confusion matrix, to determine with which classes the model had more trouble.\nSecondly, we will display some erroneous predictions made by the model and the real class of each instance. In this way, we can determine if the errors were reasonable and hopefully try to improve those failures.","96e538de":"## kNN model\n\nWe can now start with the modelling. First we will start with a simple but effective model, the k Nearest Neighbors.\n\nWe will perform some hyperparameter tuning to determine which parameters result in a better accuracy.\n\nThe parameters that will be searched are k, the number of neighbourhoods and weights, which correspond to the weight function used in the prediction phase. More information can be checked in the following [link](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html)."}}