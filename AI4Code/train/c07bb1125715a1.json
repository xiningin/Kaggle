{"cell_type":{"8760ae23":"code","f4d8805f":"code","ed575bdf":"code","f46aa61e":"code","b8a4937c":"code","e0ddf153":"code","d20d57bc":"markdown","e3fff0bc":"markdown","75e7fc27":"markdown","3a64f014":"markdown","15b9d182":"markdown","45d96361":"markdown","ace7edc3":"markdown","38eaf2ba":"markdown"},"source":{"8760ae23":"import numpy as np  \nimport pandas as pd  \nimport os\nprint(os.listdir(\"..\/input\"))\nWDR=\"..\/input\/\"\n\nimport time\n# import datetime\nfrom contextlib import contextmanager\n@contextmanager\ndef timer(title):\n    print(title)\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n    ","f4d8805f":"with timer('reading the data...'):\n    train_transaction = pd.read_csv(WDR+'train_transaction.csv')\n#     train_identity = pd.read_csv(WDR+'train_identity.csv')\n#      I found out we dont need train_identity for this. read below to understand\n#     train = train_transaction.merge(train_identity, on='TransactionID', how='left', left_index=True, right_index=True)\n    train = train_transaction.copy()","ed575bdf":"import datetime \ndef corret_card_id(x): \n    x=x.replace('.0','')\n    x=x.replace('-999','nan')\n    return x\n\ndef definie_indexes(df):\n    \n    # create date column\n    START_DATE = '2017-12-01'\n    startdate = datetime.datetime.strptime(START_DATE, '%Y-%m-%d')\n    df['date'] = df['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds = x)))\n   \n    \n    # create card ID \n    cards_cols= ['card1', 'card2', 'card3', 'card5']\n    for card in cards_cols: \n        if '1' in card: \n            df['Card_ID']= df[card].map(str)\n        else : \n            df['Card_ID']+= ' '+df[card].map(str)\n    \n    # sort train data by Card_ID and then by transaction date \n    df= df.sort_values(['Card_ID', 'date'], ascending=[True, True])\n    \n    # small correction of the Card_ID\n    df['Card_ID']=df['Card_ID'].apply(corret_card_id)\n    \n    # set indexes \n    df= df.set_index(['Card_ID', 'date'])\n    return df\n\nwith timer('define real IDs...'):\n    train = definie_indexes(train)","f46aa61e":"# I want to select only some columns \ncols= ['isFraud','TransactionDT','TransactionAmt','ProductCD', 'P_emaildomain', 'R_emaildomain']\ncards_cols= ['card1', 'card2', 'card3','card4','card5', 'card6']\ntrain[cols].head(30)","b8a4937c":"card_ID = '10069 436 150 162'\ndf_sample=train[train.index.get_level_values('Card_ID')==card_ID][cols]\ndf_sample","e0ddf153":"cols = ['Card_ID', 'isFraud']\n\n# this gives cards_ID with their annotations (fraud or not fraud)\nfraud_cards_map=train.reset_index()[cols].groupby('Card_ID').max().to_dict()['isFraud']\n\n# get list of fraud cards\nlist_of_fraudualant_cards = [k for k in fraud_cards_map.keys() if fraud_cards_map[k]==1]\n\nlist_of_fraudualant_cards[:10]","d20d57bc":"# Now we can see the data much much better than before\n\nNow we have the data indexed by `Cards_ID` and `date` . Let's have a look on the train data: ","e3fff0bc":"# Conclusion: ","75e7fc27":"I beleive my way to identify unique card is somewhat correct. However, if you want to use it, you have to change the annotations. Which mean that once a card is flagged as Fraud at some point\/transaction, all the following point\/transactions should be annotated as Fraud. ","3a64f014":"# Findings: ","15b9d182":"### You see ?! isn't that weird thing. A card that was used many time and flagged multiple times as Fraud was still accepted after that like nothing happened !!!","45d96361":"\nIf I am right about the `Card_ID` there is something really weird in the data. But first I want to say this : \n\n1. Bascially, if we detect a fraudulant card we should flag the card as fraud. Thus, every transaction made later by this card should be flagged as Fraud. \n\n2. It's normal that for the same card, we have different (P_emaildomain,R_emaildomain) per transaction. This doesn't hurt the consistancy of my definition of `Card_ID`\n\n3. I think identity features has more to do with the device used to make a transaction. This is even more interesting because we can try to make a transaction from different devices but we are still using the same card. The Card_ID is more solid to create features IMHO.\n\n4. Use `Card_ID` instead of `TransactionID`. You will be able to create more features and more importantly, you will be able to link future transactions with past actions and get the fraudulant pattern. Plenty of features to be created based on that.\n\n**Well, for the first point, this is not the case in the train data**\n\n\n\n# An example : \nLet's see an example here where a card was flagged as fraud but still allowed to make transactions later. This is really weird. It's either something wrong with the defintion of Fraud or there must be something that should be changed about target annotations. \n","ace7edc3":"# How to get list of fraudulant cards ?","38eaf2ba":"# Overview: \n\nThis comes from the discussion about whether valiadtion schema. Should we use Holdout or CV? I argue that CV is a valid move if the split is applied based on unique card-ID. \n\nThis kernel is not only about giving a unique ID for transaction made by the same card, but also gives a chance to apply CV in the right way withtout data leak. I will discuss this in another kernel. \n\n\n# So How to identify unique card ID? \n\n\n### The idea behind : \n\nThe card ID is made using the 'card_k' features. Logically speaking, a debit\/credit card number is around 16 digits. Think about!\n\nI found that a combination of card_k features : `['card1', 'card2', 'card3', 'card5',]` is giving me almost 14-16 digits. I used this as unique ID and found this pretty consistant. \n\nLet's see !\n"}}