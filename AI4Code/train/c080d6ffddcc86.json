{"cell_type":{"695cb12f":"code","548ce6a4":"code","1e7e3e03":"code","1abe3ea4":"code","5111d733":"code","0c888174":"code","85fd6e14":"code","02ee7f88":"code","866e1930":"code","70dd2385":"code","4bbb2cf4":"code","58645658":"code","e39ec460":"code","ba461ca9":"code","0dda0a50":"code","c9b5159b":"code","fcc725ea":"code","cfcdf9a0":"markdown"},"source":{"695cb12f":"import IPython.display as display\n\nimport glob\nfrom collections import Counter\n\nimport math\n\nimport librosa\nimport librosa.display\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport random\nimport torch\nimport torchaudio\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom pathlib import Path\nfrom PIL import Image\nimport soundfile as sf\nfrom torch.utils.data import Dataset\nfrom torchvision import models, transforms","548ce6a4":"import sys\nsys.path.append(\"..\/input\/timmeffnetv2\")\n\nimport timm","1e7e3e03":"os.listdir('..\/input\/create-melspec-faster-esc-50\/train')[:1]","1abe3ea4":"PATH_ESC50_TRAIN=\"..\/input\/create-melspec-faster-esc-50\/train\/\"\nPATH_ESC50_VALID=\"..\/input\/create-melspec-faster-esc-50\/valid\/\"\nPATH_ESC50_TEST=\"..\/input\/create-melspec-faster-esc-50\/test\/\"","5111d733":"def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n    for epoch in range(1, epochs+1):\n        training_loss = 0.0\n        valid_loss = 0.0\n        model.train()\n        for batch in train_loader:\n            optimizer.zero_grad()\n            inputs, targets = batch\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n            output = model(inputs)\n            loss = loss_fn(output, targets)\n            loss.backward()\n            optimizer.step()\n            training_loss += loss.data.item() * inputs.size(0)\n        training_loss \/= len(train_loader.dataset)\n        \n        model.eval()\n        num_correct = 0 \n        num_examples = 0\n        for batch in val_loader:\n            inputs, targets = batch\n            inputs = inputs.to(device)\n            output = model(inputs)\n            targets = targets.to(device)\n            loss = loss_fn(output,targets) \n            valid_loss += loss.data.item() * inputs.size(0)\n            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n            num_correct += torch.sum(correct).item()\n            num_examples += correct.shape[0]\n        valid_loss \/= len(val_loader.dataset)\n\n        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n        valid_loss, num_correct \/ num_examples))\n        \ndef find_lr(model, loss_fn, optimizer, train_loader, init_value=1e-8, final_value=10.0, device=\"cpu\"):\n    number_in_epoch = len(train_loader) - 1\n    update_step = (final_value \/ init_value) ** (1 \/ number_in_epoch)\n    lr = init_value\n    optimizer.param_groups[0][\"lr\"] = lr\n    best_loss = 0.0\n    batch_num = 0\n    losses = []\n    log_lrs = []\n    for data in train_loader:\n        batch_num += 1\n        inputs, targets = data\n        inputs = inputs.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = loss_fn(outputs, targets)\n\n        # Crash out if loss explodes\n\n        if batch_num > 1 and loss > 4 * best_loss:\n            if(len(log_lrs) > 20):\n                return log_lrs[10:-5], losses[10:-5]\n            else:\n                return log_lrs, losses\n\n        # Record the best loss\n\n        if loss < best_loss or batch_num == 1:\n            best_loss = loss\n\n        # Store the values\n        losses.append(loss.item())\n        log_lrs.append(math.log10(lr))\n\n        # Do the backward pass and optimize\n\n        loss.backward()\n        optimizer.step()\n\n        # Update the lr for the next step and store\n\n        lr *= update_step\n        optimizer.param_groups[0][\"lr\"] = lr\n    if(len(log_lrs) > 20):\n        return log_lrs[10:-5], losses[10:-5]\n    else:\n        return log_lrs, losses        ","0c888174":"class FrequencyMask(object):\n    \"\"\"\n      Example:\n        >>> transforms.Compose([\n        >>>     transforms.ToTensor(),\n        >>>     FrequencyMask(max_width=10, use_mean=False),\n        >>> ])\n\n    \"\"\"\n\n    def __init__(self, max_width, use_mean=True):\n        self.max_width = max_width\n        self.use_mean = use_mean\n\n    def __call__(self, tensor):\n        \"\"\"\n        Args:\n            tensor (Tensor): Tensor image of \n            size (C, H, W) where the frequency \n            mask is to be applied.\n\n        Returns:\n            Tensor: Transformed image with Frequency Mask.\n        \"\"\"\n        start = random.randrange(0, tensor.shape[2])\n        end = start + random.randrange(1, self.max_width)\n        if self.use_mean:\n            tensor[:, start:end, :] = tensor.mean()\n        else:\n            tensor[:, start:end, :] = 0\n        return tensor\n\n    def __repr__(self):\n        format_string = self.__class__.__name__ + \"(max_width=\"\n        format_string += str(self.max_width) + \")\"\n        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n\n        return format_string","85fd6e14":"class TimeMask(object):\n    \"\"\"\n      Example:\n        >>> transforms.Compose([\n        >>>     transforms.ToTensor(),\n        >>>     TimeMask(max_width=10, use_mean=False),\n        >>> ])\n\n    \"\"\"\n\n    def __init__(self, max_width, use_mean=True):\n        self.max_width = max_width\n        self.use_mean = use_mean\n\n    def __call__(self, tensor):\n        \"\"\"\n        Args:\n            tensor (Tensor): Tensor image of \n            size (C, H, W) where the time mask \n            is to be applied.\n\n        Returns:\n            Tensor: Transformed image with Time Mask.\n        \"\"\"\n        start = random.randrange(0, tensor.shape[1])\n        end = start + random.randrange(0, self.max_width)\n        if self.use_mean:\n            tensor[:, :, start:end] = tensor.mean()\n        else:\n            tensor[:, :, start:end] = 0\n        return tensor\n\n    def __repr__(self):\n        format_string = self.__class__.__name__ + \"(max_width=\"\n        format_string += str(self.max_width) + \")\"\n        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n        return format_string","02ee7f88":"class PrecomputedESC50(Dataset):\n    def __init__(self,path, max_freqmask_width, max_timemask_width, use_mean=True, dpi=50):\n        files = Path(path).glob('*.png')\n        self.items = [(f,int(f.name.split(\"-\")[-1].replace(\".wav.png\",\"\"))) for f in files]\n        self.length = len(self.items)\n        self.max_freqmask_width = max_freqmask_width\n        self.max_timemask_width = max_timemask_width\n        self.use_mean = use_mean\n        self.img_transforms = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n            transforms.RandomApply([FrequencyMask(self.max_freqmask_width, self.use_mean)], p=0.5),\n            transforms.RandomApply([TimeMask(self.max_timemask_width, self.use_mean)], p=0.5)])\n        \n    def __getitem__(self, index):\n        filename, label = self.items[index]\n        img = Image.open(filename).convert('RGB')\n        return (self.img_transforms(img), label)\n            \n    def __len__(self):\n        return self.length","866e1930":"#spec_resnet = models.resnet50(pretrained=True)\nspec_effnet= timm.create_model(\"tf_efficientnetv2_b3\",pretrained=True)\n\nfor name,param in spec_effnet.named_parameters():\n    if(\"bn\" not in name):\n        param.requires_grad = False\n    \n    \n\n\nspec_effnet.classifier = nn.Sequential(nn.Linear(spec_effnet.classifier.in_features,500),\n                               nn.ReLU(),\n                               nn.Dropout(), nn.Linear(500,50))","70dd2385":"#spec_effnet","4bbb2cf4":"bs=16\nesc50pre_train = PrecomputedESC50(PATH_ESC50_TRAIN, max_freqmask_width=10, max_timemask_width=10 )\n\nesc50pre_valid = PrecomputedESC50(PATH_ESC50_VALID,max_freqmask_width=10, max_timemask_width=10 )\n\nesc50pre_test = PrecomputedESC50(PATH_ESC50_TEST,max_freqmask_width=10, max_timemask_width=10 )\n\nesc50_train_loader = torch.utils.data.DataLoader(esc50pre_train, bs, shuffle=True)\nesc50_val_loader = torch.utils.data.DataLoader(esc50pre_valid, bs, shuffle=True)\nesc50_test_loader = torch.utils.data.DataLoader(esc50pre_test, bs, shuffle=True)","58645658":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\") \nelse:\n    device = torch.device(\"cpu\")\n","e39ec460":"lr = 1e-2\nspec_effnet.to(device) \ntorch.save(spec_effnet.state_dict(), \"spec_effnet.pth\")\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(spec_effnet.parameters(), lr=lr)\nlogs,losses = find_lr(spec_effnet, loss_fn, optimizer, esc50_train_loader, device=device)\nplt.plot(logs, losses)","ba461ca9":"idx=np.argmin(losses)","0dda0a50":"(logs[idx])","c9b5159b":"torch.cuda.empty_cache()\nimport gc\ndel esc50pre_test,esc50pre_train,esc50pre_valid,logs, losses\ngc.collect()","fcc725ea":"spec_effnet.load_state_dict(torch.load(\"spec_effnet.pth\"))\n\noptimizer = optim.Adam([\n                        {'params': spec_effnet.conv_stem.parameters()},\n                        {'params': spec_effnet.bn1.parameters()},\n                        {'params': spec_effnet.act1.parameters()},\n                        {'params': spec_effnet.blocks.parameters(),'lr': 1e-4},\n                        {'params': spec_effnet.conv_head.parameters(), 'lr': 1e-4},\n                        {'params': spec_effnet.bn2.parameters(), 'lr': 1e-4},\n                        {'params': spec_effnet.act2.parameters(), 'lr': 1e-4},\n                        {'params': spec_effnet.global_pool.parameters(), 'lr': 1e-4},\n                        {'params': spec_effnet.classifier.parameters(), 'lr': 1e-8}\n                        ], lr=1e-2)\n\n\ntrain(spec_effnet, optimizer, nn.CrossEntropyLoss(), esc50_train_loader, esc50_val_loader, epochs=10, device=device)\n\nfor param in spec_effnet.parameters():\n    param.requires_grad = True\n\n#torch.cuda.empty_cache()\n\ntrain(spec_effnet, optimizer, nn.CrossEntropyLoss(), esc50_train_loader, esc50_val_loader, epochs=30, device=device)","cfcdf9a0":"# This notebook uses pre-computed Melspectogram.I created Melspectogram in the following notebook link:\n>https:\/\/www.kaggle.com\/afiaibnath\/create-melspec-faster-esc-50"}}