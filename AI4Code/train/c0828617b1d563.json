{"cell_type":{"9cefc93d":"code","d0c63a72":"code","9b1dde86":"code","6a0d3c4f":"code","c8faa993":"code","f51b0d23":"code","19493183":"code","542d9a97":"code","1d36a0ed":"code","654ffcec":"code","cfcbeed3":"code","2a905e90":"code","599c260a":"code","b7059106":"code","a32d38d1":"code","867efbc6":"code","ec6d458d":"code","3afb000b":"code","0d7da52e":"code","7bb8d02b":"code","32159056":"code","6e60b73a":"code","45171970":"code","192c89da":"code","077d16fa":"code","a7939d28":"markdown","bfc39c04":"markdown","d81d8961":"markdown","8906bf9d":"markdown"},"source":{"9cefc93d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n#from tensorflow.keras.layers import Dense,Dropout\nfrom random import choice,shuffle\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d0c63a72":"data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndata","9b1dde86":"data.isna().sum()","6a0d3c4f":"teste = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nteste","c8faa993":"teste.isna().sum()","f51b0d23":"#Dataset de treinamento\nnew_keys = []\ncol = {}\nfor key in data.keys():\n    col[key]=key.lower()\n    \ndata = data.rename(columns=col)\ndata","19493183":"#Dataset de teste\nnew_keys = []\ncol = {}\nfor key in teste.keys():\n    col[key]=key.lower()\n    \nteste = teste.rename(columns=col)\nteste","542d9a97":"data = data.drop(['name','ticket','cabin','passengerid'],axis=1)\ndata","1d36a0ed":"teste = teste.drop(['name','ticket','cabin','passengerid'],axis=1)\nteste","654ffcec":"data.loc[data['age'].isna(),'age'] = int(data['age'].mean())\ndata.loc[data['embarked'].isna(),'embarked'] = choice(['C','Q','S'])\n\nteste.loc[teste['age'].isna(),'age'] = int(teste['age'].mean())\nteste.loc[teste['fare'].isna(),'fare'] = teste['fare'].mean()","cfcbeed3":"#treino\none_hot_pclass = pd.get_dummies(data['pclass'])\none_hot_embarked = pd.get_dummies(data['embarked'])\none_hot_sex = pd.get_dummies(data['sex'])\n\n#avalia\u00e7\u00e3o final\nt_one_hot_pclass = pd.get_dummies(teste['pclass'])\nt_one_hot_embarked = pd.get_dummies(teste['embarked'])\nt_one_hot_sex = pd.get_dummies(teste['sex'])\n\n\none_hot_pclass = one_hot_pclass.rename({1:'upper',2:'middle',3:'lower'},axis=1)\nt_one_hot_pclass = t_one_hot_pclass.rename({1:'upper',2:'middle',3:'lower'},axis=1)\n\ndata = data.drop(['sex','pclass','embarked'],axis=1)\nteste = teste.drop(['sex','pclass','embarked'],axis=1)\n\ndata = pd.concat([data,one_hot_sex],axis=1)\ndata = pd.concat([data,one_hot_pclass],axis=1)\ndata = pd.concat([data,one_hot_embarked],axis=1)\n\nteste = pd.concat([teste,t_one_hot_sex],axis=1)\nteste = pd.concat([teste,t_one_hot_pclass],axis=1)\nteste = pd.concat([teste,t_one_hot_embarked],axis=1)","2a905e90":"#Preview data train\ndata","599c260a":"#Preview data final avaliation\nteste","b7059106":"data['age'] = data['age']\/data['age'].mean()\ndata['fare'] = data['fare'] \/ data['fare'].max()\ndata","a32d38d1":"teste['age'] = teste['age']\/teste['age'].mean()\nteste['fare'] = teste['fare'] \/ teste['fare'].max()\nteste","867efbc6":"data = data.sample(frac=1)\nX = data.drop('survived',axis=1).values\nY = data['survived'].values\nFINAL_TEST = teste.values","ec6d458d":"x_train = X[int(X.shape[0]*0.1):]\nx_test = X[0:int(X.shape[0]*0.1)]\ny_train = Y[int(X.shape[0]*0.1):]\ny_test = Y[0:int(X.shape[0]*0.1)]","3afb000b":"print('''\nx_train shape: {}\nx_test shape: {}\ny_train shape: {}\ny_test shape: {}\nFINAL_TEST: {}\nTOTAL dataset train shape: {}\n'''.format(x_train.shape,x_test.shape,y_train.shape,y_test.shape,FINAL_TEST.shape,data.shape))","0d7da52e":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(units=24,activation='relu',input_shape=(x_train.shape[1],)))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(units=12,activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))","7bb8d02b":"model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['binary_accuracy'])\nmodel.summary()","32159056":"model.fit(x_train,y_train,batch_size=1,epochs=100,verbose=False)","6e60b73a":"model.evaluate(x_test,y_test)","45171970":"predict = model.predict(FINAL_TEST)\npredict = pd.Series(np.where(predict>0.5,1,0).squeeze())\npredict","192c89da":"indices = np.arange(892,1310)\nresult = {'PassengerId':indices,'Survived':predict}\n\nresult = pd.DataFrame(data=result)\nresult","077d16fa":"result.to_csv('result.csv',index=False)","a7939d28":"# Regulariza\u00e7\u00e3o dos dados","bfc39c04":"## Transforma\u00e7\u00f5es no dataset","d81d8961":"# Constru\u00e7\u00e3o do modelo","8906bf9d":"- 24-12-1 79% (not regularized)\n- 24-12-12-12-1 75% (not regularized)\n- 24-12-1 82% (regularized)"}}