{"cell_type":{"44a61724":"code","bde018a8":"code","290d693b":"code","b2ac2e03":"code","4a14ded3":"code","882da0ed":"code","1af7b558":"code","13022353":"code","b2ec04a6":"code","076060da":"code","5ed4a541":"code","449430b7":"code","abb85038":"code","4b55a5f9":"code","71fa02a6":"code","9519beda":"code","bb88ce2a":"code","6ace976e":"code","4d0e1332":"code","145f7662":"markdown","3789253c":"markdown","824557d0":"markdown","15d28bcf":"markdown","2a857d6f":"markdown","7b0085e4":"markdown","cb8f37ae":"markdown"},"source":{"44a61724":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bde018a8":"import pandas as pd\nfrom keras.preprocessing.sequence import pad_sequences\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, cv2\nimport dill\nimport tensorflow_datasets.public_api as tfds\nimport albumentations as A\nimport tensorflow as tf\nimport json\nfrom mt_utils import *\nimport dill","290d693b":"# Get the API key for the dataset\n! mkdir -p \/root\/.kaggle\/\n! cp ..\/input\/api-token\/kaggle.json \/root\/.kaggle\/kaggle.json\n! mkdir -p \/kaggle\/tmp\/mt_train\n! kaggle datasets init -p \/kaggle\/tmp\/mt_train","b2ac2e03":"%%bash\necho \"{\n  \\\"title\\\": \\\"MTCustomVocabImg\\\",\n  \\\"id\\\": \\\"tchaye59\/MTCUSTOMVOCABIMG\\\",\n  \\\"licenses\\\": [\n    {\n      \\\"name\\\": \\\"CC0-1.0\\\"\n    }\n  ]\n}\" > \/kaggle\/tmp\/mt_train\/dataset-metadata.json","4a14ded3":"df = pd.read_csv('..\/input\/bms-molecular-translation\/train_labels.csv')\nsub_df = pd.read_csv('..\/input\/bms-molecular-translation\/sample_submission.csv')","882da0ed":"tokenizer = CstTokenizer()\nN_VOCAB = len(tokenizer.word_index)+1\ntokenizer.word_index","1af7b558":"%%time\nstart = '<start>'\nend = '<end>'\n# Load tokenized labels\nlabels = dill.load(open('\/kaggle\/usr\/lib\/mt_utils\/labels.dill','rb'))\ncount_elements = dill.load(open('\/kaggle\/usr\/lib\/mt_utils\/count_elements.dill','rb'))\n\niids = df.image_id.values\nmax_seq = max([len(l) for l in labels])\nmax_seq,N_VOCAB","13022353":"class Dataset:\n    \n    def __init__(self, iids,targets=None,counts=None,max_seq=max_seq):\n        \n        self.iids,self.targets,self.counts = iids,targets,counts\n        self.max_seq = max_seq\n\n    def __len__(self):\n        return len(self.iids)\n\n    def __getitem__(self, index):\n        iid = self.iids[index]\n        if self.targets is None:\n            return self.get_image(iid),iid\n        label = self.targets[index]\n        label = pad_sequences([label], maxlen=self.max_seq, padding='post')[0].astype(np.int8)\n        return self.get_image(iid),label,self.counts[index]\n\n    def get_image(self, iid):\n        name = 'train' if self.targets is not None else 'test'\n        path = \"..\/input\/bms-molecular-translation\/\"+name+\"\/{}\/{}\/{}\/{}.png\"\n        path = path.format(iid[0], iid[1], iid[2], iid)\n        return cv2.imread(path, cv2.IMREAD_UNCHANGED)[:,:,np.newaxis]","b2ec04a6":"dataset = Dataset(iids,labels,count_elements)\ntest_dataset = Dataset(sub_df.image_id.values)","076060da":"plt.imshow(dataset[100][0])","5ed4a541":"plt.imshow(test_dataset[3][0])","449430b7":"class TrainDataset(tfds.core.GeneratorBasedBuilder):\n    VERSION = tfds.core.Version('0.1.0')\n    \n    def _split_generators(self, dl_manager):\n        return [\n            tfds.core.SplitGenerator(\n                    name=f'train',\n                    gen_kwargs={\n                    },\n            )\n        ]\n    \n    def _info(self):\n        return tfds.core.DatasetInfo(\n            builder=self,\n            description=(\"\"),\n            features=tfds.features.FeaturesDict({\n                \"image\": tfds.features.Image(shape=(None,None,1)),\n                \"target\": tfds.features.Tensor(shape=(max_seq,),dtype=tf.int8),\n                \"count\": tfds.features.Tensor(dtype=tf.int32,shape=()),\n            }),\n        )\n    \n    def _generate_examples(self,**args):\n        print(f\"Data size: {len(dataset)}\")\n        for i in range(len(dataset)):\n            image,target,count = dataset[i]\n            yield i, {\n                'image':image,\n                'target':target,\n                'count':count,\n            }","abb85038":"class TestDataset(tfds.core.GeneratorBasedBuilder):\n    VERSION = tfds.core.Version('0.1.0')\n    \n    def _split_generators(self, dl_manager):\n        return [\n            tfds.core.SplitGenerator(\n                    name=f'test',\n                    gen_kwargs={\n                    },\n            )\n        ]\n    \n    def _info(self):\n        return tfds.core.DatasetInfo(\n            builder=self,\n            description=(\"\"),\n            features=tfds.features.FeaturesDict({\n                \"image\": tfds.features.Image(shape=(None,None,1),),\n                \"image_id\": tfds.features.Text(),\n            }),\n        )\n    \n    def _generate_examples(self,**args):\n        print(f\"Data size: {len(test_dataset)}\")\n        for i in range(len(test_dataset)):\n            image,image_id = test_dataset[i]\n            yield i, {\n                'image':image,\n                'image_id':image_id,\n            }","4b55a5f9":"#! cp -rv ..\/input\/mtcustomvocabimg\/* \/kaggle\/tmp\/mt_train","71fa02a6":"%%time\ndata_dir='\/kaggle\/tmp\/mt_train' \nbuilder = TrainDataset(data_dir=data_dir)\n# The following line creates the train dataset folder containing the tf records files in \/kaggle\/input\nbuilder.download_and_prepare() ","9519beda":"! cp -rv ..\/input\/mtcustomvocabimg\/test_dataset\/ \/kaggle\/tmp\/mt_train","bb88ce2a":"%%time\ndata_dir='\/kaggle\/tmp\/mt_train' \nbuilder = TestDataset(data_dir=data_dir)\n# The following line creates the test dataset folder containing the tf records files in \/kaggle\/input\nbuilder.download_and_prepare() ","6ace976e":"! kaggle datasets version -p \/kaggle\/tmp\/mt_train -m \"update\"  --dir-mode tar\n#! kaggle datasets create -p \/kaggle\/tmp\/mt_train\/ -u --dir-mode tar","4d0e1332":"# Delete Kaggle API key\n! rm -rf \/root\/.kaggle\/kaggle.json","145f7662":"# Training dataset","3789253c":"## Get the tokenizer from https:\/\/www.kaggle.com\/tchaye59\/mt-utils","824557d0":"# Test data","15d28bcf":"#### Dataset link : https:\/\/www.kaggle.com\/tchaye59\/mtcustomvocabimg\n#### Pretraining : https:\/\/www.kaggle.com\/tchaye59\/mt-pretraining\n#### Training: https:\/\/www.kaggle.com\/tchaye59\/mt-fast-distributed-training-tpu","2a857d6f":"# Dataset","7b0085e4":"## Upload or Update dataset","cb8f37ae":"# Dataset to tf records "}}