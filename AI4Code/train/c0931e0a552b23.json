{"cell_type":{"ce4555cc":"code","1cff5bb7":"code","50cfbcb5":"code","29b782c5":"code","bf365d9e":"code","f7be5454":"code","def3b763":"code","3ed9b45d":"code","32229b5d":"code","615a6128":"code","8d60bd0b":"code","4b825a2b":"code","d187e9a8":"code","155cec65":"code","06176f6e":"code","6aae87cb":"code","4112f960":"code","91c8187c":"code","e48cb303":"code","2b00cdfc":"code","0d122cc1":"code","da4fd275":"code","b9c1ee35":"code","0659456b":"code","c88152ce":"code","264b5d69":"markdown","df8296ef":"markdown","a5f7459f":"markdown","94158a96":"markdown","63f274c1":"markdown","4b3f971d":"markdown","e871b0fd":"markdown","0f8291ee":"markdown"},"source":{"ce4555cc":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport datetime as dt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tensorflow as tf\nfrom sklearn import metrics","1cff5bb7":"os.chdir('\/kaggle\/input\/wallmart-sales\/')\ntotal_value = pd.read_csv('total_value.csv')\ntotal_value.head()","50cfbcb5":"os.chdir('\/kaggle\/input\/wallmart\/')\ncal = pd.read_csv('calendar.csv')","29b782c5":"cal","bf365d9e":"# One-hot encoding months\nmonth = pd.get_dummies(cal['month'],prefix='month',drop_first=True)\n\n# Dropping unecessary cols\ncal.drop(['wm_yr_wk', 'weekday','d', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_TX', 'snap_WI'],1,inplace=True)\n\n# Handling events\ncal['event_name_1'] = cal['event_name_1'].fillna(0)\ncal['event_name_1'] = np.where(cal['event_name_1'] != 0,1,0)\n\n# One-hot encoding day of months\ncal['date'] = pd.to_datetime(cal['date'])\ncal['dayofmonth'] = cal['date'].dt.day     \ndom = pd.DataFrame(np.where(cal['dayofmonth']>=15,1,0),columns=['day_ge_15'])\n\n# One-hot encoding years\nyear = pd.get_dummies(cal['year'],prefix='year_',drop_first=True)\n\n# One-hot encoding weekdays\nwday = pd.get_dummies(cal['wday'],prefix='wday_',drop_first=True)\n\n# Combing and removing features\ncal.drop(['month','year','dayofmonth','wday'],1,inplace=True)\ncal = pd.concat([cal,month,year,dom,wday],axis=1)","f7be5454":"# Function for filtering california store 3 items\ndef california_store_3(item):\n    state = item.split('_')[3] \n    store_no = int(item.split('_')[4])\n    if (state == 'CA' and store_no == 3): \n        return True\n    else: \n        return False","def3b763":"item_list = list(total_value.columns[:-1])\ncalifornia_store_3_item = filter(california_store_3, item_list)\ncalifornia_store_3_item_list = [i for i in california_store_3_item]","3ed9b45d":"california_store_3_df = total_value.loc[:,california_store_3_item_list]\ncalifornia_store_3_df","32229b5d":"# Concatinating categorical variables\ncalifornia_store_3_df = pd.concat([cal.iloc[:1941,:],california_store_3_df],1)\ncalifornia_store_3_df.head()","615a6128":"california_store_3_df['date'] = pd.to_datetime(california_store_3_df['date'])","8d60bd0b":"# 3049 items\ncalifornia_store_3_last_1_year_df = california_store_3_df[california_store_3_df['date'] >='2015-02-22']\ncalifornia_store_3_last_1_year_df.head()","4b825a2b":"# 3021 items\ncalifornia_store_3_last_1_year_df_without_Nas = california_store_3_last_1_year_df.dropna(axis=1)\ncalifornia_store_3_last_1_year_df_without_Nas.head()","d187e9a8":"# Fuction for filtering food\ndef california_store_3_food(item):\n    category = item.split('_')[0]\n    if (category == 'FOODS'): \n        return True\n    else: \n        return False","155cec65":"categorical_variables = list(california_store_3_last_1_year_df_without_Nas.columns[:26])\ncalifornia_store_3_last_1_year_without_Nas_item_list = list(california_store_3_last_1_year_df_without_Nas.columns[26:])\ncalifornia_store_3_last_1_year_without_Nas_item_food = filter(california_store_3_food, california_store_3_last_1_year_without_Nas_item_list)\ncalifornia_store_3_last_1_year_without_Nas_item_food_list = categorical_variables + [i for i in california_store_3_last_1_year_without_Nas_item_food]","06176f6e":"california_store_3_last_1_year_without_Nas_item_food_df = california_store_3_last_1_year_df_without_Nas.loc[:,california_store_3_last_1_year_without_Nas_item_food_list]\ncalifornia_store_3_last_1_year_without_Nas_item_food_df","6aae87cb":"master_df = california_store_3_last_1_year_without_Nas_item_food_df.copy()","4112f960":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=master_df.date, \n                         y=master_df.iloc[26:].sum(axis=1),\n                         mode='lines',\n                         name='pred'))\n   \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 food sales\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","91c8187c":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=master_df.date, \n                         y=master_df.iloc[:,26:26+15].sum(axis=1),\n                         mode='lines',\n                         name='pred'))\n   \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 food sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","e48cb303":"master_df_15_items = master_df.iloc[:,:26+15]","2b00cdfc":"categorical_varibales = master_df_15_items.iloc[:,1:26]\ncategorical_varibales","0d122cc1":"# loop for lstm\n\ncategorical_varibales = master_df_15_items.iloc[:,:26] \ntarget_variables = master_df_15_items.iloc[:,26:].columns\n\npredictions = pd.DataFrame(np.arange(1,29),columns=['index'])\nactual = pd.DataFrame(np.arange(1,29),columns=['index'])\n\nfor target_variable in target_variables:\n    \n    # Making dataset\n    dataset = pd.concat([categorical_varibales,master_df[target_variable]],1)\n\n    # Splitting train and test data\n    split_date = '2016-04-24'\n    Train = dataset.loc[dataset['date'] <= split_date].copy()\n    Test = dataset.loc[dataset['date'] > split_date].copy()\n    \n    # Dropping date\n    Train.drop(['date'],axis=1,inplace=True)\n    Test.drop(['date'],axis=1,inplace=True)\n    \n    x_train = Train.drop([target_variable],1)\n    y_train = Train[target_variable]\n    x_test = Test.drop([target_variable],1)\n    y_test = Test[target_variable]\n\n    #Create model layers\n    model = tf.keras.Sequential([\n        tf.keras.layers.LSTM(64,input_shape=(len(x_test.keys()),1)),\n        tf.keras.layers.Dense(1)\n    ])\n\n    #Choose optimizer\n    optimizer = tf.keras.optimizers.Adam()\n\n    #Compile model with mean squared error as loss function\n    model.compile(loss='mse',\n                  optimizer=optimizer,\n                  metrics=['mae', 'mse'])\n\n    # Number of epochs\n    EPOCHS = 10\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    history=model.fit(np.reshape(x_train.values, (x_train.shape[0], x_train.shape[1], 1))\n    , y_train,epochs=EPOCHS, validation_split = 0.2,callbacks=[early_stop], verbose=1)\n    \n    # Predictions\n    test_predictions = model.predict(np.reshape(x_test.values, (x_test.shape[0], x_test.shape[1], 1))).flatten()\n    print(f'{target_variable}:{metrics.mean_squared_error(test_predictions,y_test)}')\n\n    test_predictions = pd.DataFrame(test_predictions, columns=[target_variable])\n    predictions = pd.concat([predictions, test_predictions], 1)\n\n    y_test = pd.DataFrame(y_test.values, columns=[target_variable])\n    actual = pd.concat([actual, y_test], 1, ignore_index = True)","da4fd275":"fig = go.Figure()\n\n\nfig.add_trace(go.Scatter(x=predictions.index, y=predictions.sum(axis=1),mode='lines',name='pred'))\n\nfig.add_trace(go.Scatter(x=predictions.index, y=actual.sum(axis=1),mode='lines',name='actual'))\n    \n    \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 food sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","b9c1ee35":"# Packages for arima\n!python3.7 -m pip install --upgrade pip\n!pip install pmdarima\nfrom pmdarima.arima import auto_arima","0659456b":"# loop for arima\n\ntarget_variables = master_df_15_items.iloc[:,26:].columns\n\npredictions_ar = pd.DataFrame(np.arange(1,29),columns=['index'])\nactual_ar = pd.DataFrame(np.arange(1,29),columns=['index'])\n\nfor target_variable in target_variables:\n     \n    # Making dataset\n    dataset = master_df[target_variable]\n\n    # Splitting train and test data\n    df_arima_train = dataset[:-28]\n    y_test = dataset[-28:]    \n    \n    # Defining model\n    stepwise_model = auto_arima(df_arima_train,start_p=1,start_q=1,max_p=3,max_q=3,m=7,start_P=0,seasonal=True,d=1,D=1,trace=True,error_action='ignore',suppress_warnings=True,stepwise=True)\n\n    # Predictions\n    test_predictions = stepwise_model.predict(n_periods=28)\n    ar_day_rmse = np.sqrt(metrics.mean_squared_error(test_predictions, y_test))\n    print(f'{target_variable}th rmse:{ar_day_rmse}')\n\n    test_predictions = pd.DataFrame(test_predictions, columns=[target_variable])\n    predictions_ar = pd.concat([predictions_ar, test_predictions], 1)\n\n    y_test = pd.DataFrame(y_test.values, columns=[target_variable])\n    actual_ar = pd.concat([actual_ar, y_test], 1, ignore_index = True)","c88152ce":"fig = go.Figure()\n\n\nfig.add_trace(go.Scatter(x=predictions.index, y=predictions_ar.sum(axis=1),mode='lines',name='pred_ar'))\n\nfig.add_trace(go.Scatter(x=predictions.index, y=actual_ar.sum(axis=1),mode='lines',name='actual'))\n    \n    \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 food sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","264b5d69":"## Importing libraries","df8296ef":"# Model building and preprocessing","a5f7459f":"### Seperating Food items","94158a96":"## Arima","63f274c1":"## Pre-processing total_value dataset","4b3f971d":"## Reading data","e871b0fd":"## Pre-processing cal dataset","0f8291ee":"## LSTM"}}