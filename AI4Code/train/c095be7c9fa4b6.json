{"cell_type":{"f3d8b398":"code","e255e497":"code","674e93bd":"code","93739c4c":"code","eb1d1a9c":"code","6097a72e":"code","540ce4e8":"code","29b8bc92":"code","da982dc4":"code","d949ec53":"code","9f6850f2":"code","8e97bc0a":"code","08df3835":"code","d8070f2a":"code","2a82fabc":"code","81ccbc1b":"code","173251ee":"code","3443aaf6":"code","b1a62c4b":"code","1f6c2c31":"code","beca996d":"code","8c56f583":"code","75ba2130":"code","418edd86":"code","7321b276":"code","2f2cdb80":"code","e7ce467a":"code","cb548d8c":"code","e2f68fe0":"code","643a441a":"code","2aa1ccc8":"code","eb06a469":"code","027bb263":"code","5f5071ad":"code","219e4a70":"code","e76317ae":"markdown","31d15cd9":"markdown","c2986eb3":"markdown","ab59a9e6":"markdown","9dcb71ff":"markdown","d8154bed":"markdown","b3754f97":"markdown","0232d072":"markdown","eafd819f":"markdown","4c9af1e2":"markdown","ca385b57":"markdown","f06be306":"markdown","be2aaca6":"markdown","b694b3d6":"markdown","88ef1fbb":"markdown","6fd4c8a0":"markdown","d34206ab":"markdown","4e16bd16":"markdown","c5279822":"markdown","4f51af38":"markdown","61266d9c":"markdown","58cd12af":"markdown","2bee8d72":"markdown","c0e677d1":"markdown","793291f5":"markdown","6d7646bf":"markdown","bc185723":"markdown","85dde1be":"markdown","0f073c2e":"markdown","973093e9":"markdown","9a1bdee4":"markdown","42eacc37":"markdown","a23c9cae":"markdown","f4d16426":"markdown","96346bc0":"markdown","0bef7878":"markdown","19ae6b35":"markdown","98c898c3":"markdown","4640e903":"markdown","5b810f8e":"markdown","c2a864b7":"markdown","c118d99a":"markdown","9d1ef85b":"markdown","081a5807":"markdown","4aee22a4":"markdown","17e64713":"markdown"},"source":{"f3d8b398":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e255e497":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nsns.set()\nimport scipy.stats as ss\nimport missingno as msno\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import LabelEncoder\n\n#no boundation on number of columns \npd.set_option('display.max_columns', None)\n\n#no boundation on number of rows\npd.set_option('display.max_rows', None)\n\n# run multiple commands in a single jupyter cell\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","674e93bd":"#Heatmap\ndef heatmap(df):\n    \n    '''\n    this function takes data frame a input and returns the\n    heatmap as output.\n    \n    Arguments\n    ====================\n    df : Dataframe or Series \n    \n    \n    Returns\n    ===========\n    heatmap\n    '''\n    corr = df.corr()   #create a correlation df\n    fig,ax = plt.subplots(figsize = (30,30))   # create a blank canvas\n    colormap = sns.diverging_palette(220,10, as_cmap=True)   #Generate colormap\n    sns.heatmap(corr, cmap=colormap, annot=True, fmt='.2f')   #generate heatmap with annot(display value) and place floats in map\n#    plt.xticks(range(len(corr.columns)), corr.columns);   #apply  xticks(labels of features)\n#    plt.yticks(range(len(corr.columns)), corr.columns)   #apply yticks (labels of features)\n    plt.show()\n    \n    \n\ndef categorical_feature_summarized(dataframe, x=None, y=None, hue=None, palette='Set1', verbose=True):\n    '''\n    \n    helper function that gives a quick summary of a given column of categorical data\n    \n    Arguments\n    =============\n    dataframe: pandas df\n    x: str, horizontal axis to plot the label of categorical data\n    y: str, vertical xis to plot hte label of the categorical data\n    hue: str, if you want to comparer it to any other variable\n    palette: array-like, color of the graph\/plot\n    \n    \n    Returns\n    ==============\n    Quick summary of the categorical data\n    \n    \n    '''\n    \n    if x==None:\n        column_interested = y\n        \n    else:\n        column_interested = x\n    series = dataframe[column_interested]\n    print(series.describe())\n    print('mode', series.mode())\n    \n    if verbose:\n        print('='*80)\n        print(series.value_counts())\n        \n        \n    sns.countplot(x=x, y=y, hue=hue, data=dataframe, palette = palette)\n    plt.show()\n    \n    '''\n    \n    categorical_summarized does is it takes in a dataframe, together with some input arguments and \n    outputs the following:\n        1. The count, mean, std, min, max, and quartiles for numerical data or\n        2. the count, unique, top class, and frequency of the top class for non-numerical data.\n        3. Class frequencies of the interested column, if verbose is set to 'True'\n        4. Bar graph of the count of each class of the interested column\n    \n    '''","93739c4c":"tr  = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntt = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","eb1d1a9c":"print('train shape:',tr.shape)\nprint('test shape:', tt.shape)","6097a72e":"print('train size:', tr.size)\nprint('test size:', tt.size)","540ce4e8":"print('Head:')\ntr.head()  # prints first five instances of the dataset\nprint('Tail:')\ntr.tail()  #prints last five instances of the dataset\nprint('5 Random samples from the train dataset:')\ntr.sample(5)  #5 random samples of the dataset","29b8bc92":"print('Columns of the train dataset:')\ntr.columns","da982dc4":"print('columns in train but not in test:')\ntr.columns.difference(tt.columns)","d949ec53":"print('colummns in common train and test')\n(tr.columns).intersection(tt.columns)","9f6850f2":"print('Information on train dataframe:')\n\ntr.info()","8e97bc0a":"print('description of the training dataset:')\ntr.describe()","08df3835":"tr.isnull().sum().sort_values(ascending=False)","d8070f2a":"print('total null values:', tr.isna().sum().sum(), \n      'out of', tr.size, '(total entries)' )","2a82fabc":"tr_num = tr._get_numeric_data()","81ccbc1b":"missing_bar = msno.bar(tr_num)","173251ee":"missing_data_matrix = msno.matrix(tr_num, )","3443aaf6":"train_missing_data_heatmap = msno.heatmap(tr)","b1a62c4b":"missing_dendrogram = msno.dendrogram(tr)","1f6c2c31":"print('Dataframe of Features with numerical features')\ntr_num = tr._get_numeric_data()\ntr_num.head()","beca996d":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\ntr_cat = tr.select_dtypes(exclude = numerics)\nprint('dataframes with categorical features:')\ntr_cat.head()","8c56f583":"print('list of features with numerical values:')\ntr_num.columns\n\nprint('list of features with categorical values:')\ntr_cat.columns","75ba2130":"print('Shape of the numerical DataFrame:', tr_num.shape)\nprint('Shape of the Categorical DataFrame:', tr_cat.shape)","418edd86":"# Start with an empty canvas\nax,fig = plt.subplots(1,3,figsize=(20,5))\n\n#first plot - disprinbution plot\ndist = sns.distplot(tr_num['SalePrice'],bins=50, ax = fig[0])\ntitle = dist.set_title('Distribution Plot');\n\n#second plot - box plot\nbox = sns.boxplot(x = tr_num['SalePrice'], linewidth=2.5, ax=fig[1])\ntitle_0 = box.set_title('Boxplot')\n\n#third plot - violin plot\nviolin = sns.violinplot(x=tr_num['SalePrice'], ax=fig[2])\ntitle_1 = violin.set_title('Violin Plot')\n\nplt.show()","7321b276":"print(\"Average Price of the House:\", tr_num['SalePrice'].mean())\nprint(\"Most of the houses are close to\" ,tr_num['SalePrice'].mode())\nprint('The median house price is close to'  , tr_num['SalePrice'].median())","2f2cdb80":"num_features = tr_num.columns\n\n\nprint('Skewness:', tr.SalePrice.skew())\nprint('Kurtosis:', tr.SalePrice.kurt())","e7ce467a":"numerical_correlation = tr_num.corr()\nnumerical_correlation","cb548d8c":"heatmap(tr_num)","e2f68fe0":"tr_num.corr()['SalePrice'].sort_values(ascending=False)","643a441a":"features_for_corr = {'OverallQual','GrLivArea','GarageCars','GarageArea','TotalBsmtSF','1stFlrSF','FullBath'}\n","2aa1ccc8":"corr_some_features = tr[features_for_corr].corr()\nax,fig = plt.subplots(figsize=(10,10))\ncolormap = sns.diverging_palette(220,10, as_cmap=True)\nheatmap_some_features = sns.heatmap(corr_some_features, cmap = colormap, annot=True, annot_kws={'size':20}, fmt='.2f')\nplt.show()","eb06a469":"for i in features_for_corr:\n    ax,fig = plt.subplots(1,3, figsize=(20,5))\n    box = sns.boxplot(y = tr_num[i], linewidth=2.5, ax=fig[2])\n    box_title = box.set_title('Box Plot')\n    violin = sns.violinplot(y = tr_num[i], linewidth=2.5, ax=fig[0])\n    violin_title  = violin.set_title('Violin Plot')\n    dist = sns.distplot(tr_num[i], ax=fig[1], vertical=True)\n    distplot_title = dist.set_title('Distribution Plot')","027bb263":"for i in features_for_corr:\n    skewness = np.array(tr_num[features_for_corr].skew())\n    kurtosis = np.array(tr_num[features_for_corr].kurt())\n    mean = np.array(tr_num[features_for_corr].mean())\n    median = np.array(tr_num[features_for_corr].median())\n    variance = np.array(tr_num[features_for_corr].var())\n    \n    data_frame = pd.DataFrame({'skewness':skewness,\n                               'kurtosis':kurtosis, \n                               'Mean':mean,\n                               'Median':median, \n                               'variance':variance},\n                              \n                              index=features_for_corr,\n                              columns={'skewness',\n                                       'kurtosis',\n                                       'Mean',\n                                       'Median',\n                                       'variance'})\nprint(data_frame)","5f5071ad":"tr_cat = tr.select_dtypes(include = 'object')\ntr_cat.head()","219e4a70":"for i in tr_cat.columns:\n    categorical_feature_summarized(tr_cat, x=i)","e76317ae":"Now lets see the common features in  both the columns","31d15cd9":"The above Matrix shows the variance, Skewness, Kurtosis, Mean and Median of the selected numerical features from the train dataset","c2986eb3":"# List of Functions used","ab59a9e6":"Lets start with SalePrice(target variable), plot a distribution of the frequency","9dcb71ff":"## 3.2.Let's have a peek","d8154bed":"We'll handle the missing data, but before that we'll split the dataframe based on numerical and categorical entry of the features.","b3754f97":"Lets checkout the Shape and size of our datasets","0232d072":"## 3.3. Columns\/Features of the Dataset:","eafd819f":"Observations:\n1. The stars in the boxplot beyond the line (non continuous frequency) indicates that there are only a few houses that are highly priced.\n2. About 75% of the houses are sold for less than $210000.\n\nAs we see the distribution is Positively Skewed, so lets check out the Measure of the shape\n\n","4c9af1e2":"# 5.1. Numerical Data in Train","ca385b57":"Before we jump into analysing indiviadual variables, lets decide which variables to pick. ","f06be306":"Observations (Skewness):\n`\n1. The positive Skewness indicates that the data is very widely distributed i.e. there is very small number of houses with each price tag(frequency)\n2. The order of central frequency in SalePrice:\n            Mean>Median>Mode\n3. Many houses are sold for less than the average price       \n\n","be2aaca6":"Describe:","b694b3d6":"The matrix above shows the distribution of the missing data in the dataset with numerical features. It helps in deciding the strategy to fill up the missing values.","88ef1fbb":"Draw similar conclusions from above features as we had drawn in SalePrice","6fd4c8a0":"# 5. Divide into Categorical and Numerical features","d34206ab":"Quite simpler but still need to simplify it further","4e16bd16":"Let's check out some of the basic information of our datasets","c5279822":"Lets dig some deeper and get Statistical Insights ","4f51af38":"# Conclusion","61266d9c":"The Bar graph above shows the frequency of missing data.","58cd12af":"Observations (Kurtosis):\n\n1. The plot of the SalePrice is distorted bell-shaped with sharp peak\n2. Most houses are sold at a price very close to $140000(mode), which is less than the average household price.\n3. There are many outliers in the Dataset(Keep this in mind while training your model).\n","2bee8d72":"# 1. Import the libraries ","c0e677d1":"## 3.4. Info and Describe","793291f5":"Let us gather some information about the features and indices : Name, Datatypes,value-counts and non-null values: ","6d7646bf":"Seeing the differences in the shapes of train and test datasets, its very obvious that the only difference in the number of features of train and test datasets  is the \"SalePrice\".\n\nStill if one wants to check the uncommon features in two datasets, here we go:","bc185723":"Lets check the missing values in the dataframe","85dde1be":"Features Selected for correlation","0f073c2e":"Grand total of the missing values:","973093e9":"# 3.Basic Information","9a1bdee4":"## 3.1.Shape and Size","42eacc37":"# Categorical Features","a23c9cae":"The Heatmap of the missing data in the complete training dataset.","f4d16426":"This is correlation matrix (ratio of relations between any two variables). It is hard to draw conclusive insights from this matrix.\n\nLet's visualize it.","96346bc0":"Lets check out the distribution of each of the feeatures in features_for_corr list","0bef7878":"Now that we have the shape of our datasets, lets see how our dataset looks like:","19ae6b35":"# 4. Missing Values","98c898c3":"Lets check out the columns with numerical and categorical variables","4640e903":"And finally a dendrogram to show the relations between two variables.\n","5b810f8e":"Let us visualize the pattern in our missing data","c2a864b7":"# 2. Import the Datasets","c118d99a":"We'll drop the features where the missing data exceeds 50% of the range of indices.","9d1ef85b":"After the data is extensively analysed we can start follow the following order to train our model:\n    1. Missing Data Handeling\n    2. Data Cleaning\n    3. Data Preprocessing\n    4. Feaature Engineering\n    5. Feature Selection\n    6. Training our model\n    7. Error Analysis\n    8. Optimization of the model\n    9. Submission of the Predictions","081a5807":"The degrees of difference in the null values is very high between Fence and SaleCondition.","4aee22a4":"Since we got the shape and size of the dataset, we now know about the number of instances and number of columns.\n\nLets start to explore the dataset","17e64713":"# Correlation"}}