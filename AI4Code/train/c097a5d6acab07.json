{"cell_type":{"d0ccdf0b":"code","554d37c7":"code","2814f2a5":"code","a2a81079":"code","d4598087":"code","e7ee218e":"code","a869ea3c":"code","0dd61c9c":"code","5f7da848":"code","5ecbe083":"code","776d88af":"code","3a245d37":"code","4dbe8182":"code","fe80bef0":"code","1e9be795":"code","965e69ca":"code","3342bcfa":"code","e12b00fa":"code","e1ed345e":"code","ed828f5e":"code","8e99b59b":"code","34766238":"code","01b86677":"code","340e9945":"code","fe438e76":"code","bac9cab4":"code","236d4da2":"code","b61f26cc":"code","ae9edc89":"code","2be09d19":"code","a0a3a048":"code","e03c43a5":"code","5f8a8136":"code","3c1aad09":"code","b69221a3":"markdown","86b27518":"markdown","197aa54e":"markdown","552a547a":"markdown","ec760517":"markdown","c09b7f2c":"markdown","a41d0895":"markdown","dab14186":"markdown","2b5b2ec8":"markdown"},"source":{"d0ccdf0b":"\n%cd \/kaggle\n!rm -rf tmp\n!mkdir tmp\n%cd tmp","554d37c7":"ls ..\/","2814f2a5":"#Download YOLOv5\n\n# !git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n\n%cp -R \/kaggle\/input\/yolov5-for-siim-covid19\/yolov5 \/kaggle\/tmp\n%cd yolov5\n# %pip install -qr requirements.txt #install dependencies\n%cp -R \/kaggle\/input\/requirements-for-siim-covid19\/requirements.txt  \/kaggle\/tmp\/yolov5\n\n%cd ..\/\nimport torch\n\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")","a2a81079":"# !ls ..\/kaggle\/tmp\n# !ls \/kaggle\/input\/yolov5-for-siim-covid19\/yolov5\n# !ls \/kaggle\/input\/..\/input\/requirements-for-siim-covid19\n# !ls \/kaggle\/input\n# !ls tmp","d4598087":"# !pip install -q --upgrade wandb\n# !pip install --upgrade wanb==0.9.7\n# #Login\n# import wandb\n# wandb.login()","e7ee218e":"# Necessary\/extra dependencies. \nimport os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom shutil import copyfile\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport wandb\n#customize iPython writefile so we can write variables\nfrom IPython.core.magic import register_line_cell_magic\n\n@register_line_cell_magic\ndef writetemplate(line, cell):\n    with open(line, 'w') as f:\n        f.write(cell.format(**globals()))","a869ea3c":"TRAIN_PATH = 'input\/siim-covid19-resized-to-256px-jpg\/train\/'\nIMG_SIZE = 256\nBATCH_SIZE = 16\nEPOCHS = 10","0dd61c9c":"# Everything is done from \/kaggle directory\n%cd \/kaggle\n#Load image level csv file\ndf = pd.read_csv('input\/siim-covid19-detection\/train_image_level.csv')\n\n#Modify values in the id column\ndf['id'] = df.apply(lambda row:row.id.split('_')[0],axis=1)\n\n# Add absolute path\ndf['path'] = df.apply(lambda row:TRAIN_PATH+row.id+'.jpg',axis=1)\n\n#get image level labels\ndf['image_level'] = df.apply(lambda row:row.label.split(' ')[0], axis=1)\ndf.head(5)\n","5f7da848":"# Load meta.csv file\n# Original dimensions are required to scale the bounding box coordinates appropriately.\n\nmeta_df = pd.read_csv('input\/siim-covid19-resized-to-256px-jpg\/meta.csv')\ntrain_meta_df = meta_df.loc[meta_df.split=='train']\ntrain_meta_df=train_meta_df.drop('split',axis=1)\ntrain_meta_df.columns=['id','dim0','dim1']\n\ntrain_meta_df.head()","5ecbe083":"#merge train df\ndf = df.merge(train_meta_df,on='id',how='left')\ndf.head()","776d88af":"train_df, valid_df = train_test_split(df, test_size=0.2, random_state = 710, stratify=df.image_level.values)\n\n\n# train_df.assign(split = \"train\")\n# valid_df.assign(split = \"valid\")\n\ntrain_df.loc[:,\"split\"]='train'\nvalid_df.loc[:,\"split\"]='valid'\n\ndf = pd.concat([train_df, valid_df]).reset_index(drop=True)\n","3a245d37":"print(f'Size of dataset: {len(df)}, training images: {len(train_df)}. validation images: {len(valid_df)}')\ndf.head()","4dbe8182":"os.makedirs('tmp\/covid\/images\/train',exist_ok=True)\nos.makedirs('tmp\/covid\/images\/valid',exist_ok=True)\n\n\nos.makedirs('tmp\/covid\/labels\/train',exist_ok=True)\nos.makedirs('tmp\/covid\/labels\/valid',exist_ok=True)\n\n!ls tmp\/covid\/images","fe80bef0":"for i in tqdm(range(len(df))):\n    row=df.loc[i]\n    if row.split=='train':\n        copyfile(row.path, f'tmp\/covid\/images\/train\/{row.id}.jpg')\n    else:\n        copyfile(row.path, f'tmp\/covid\/images\/valid\/{row.id}.jpg')","1e9be795":"import yaml\n\ndata_yaml=dict(\n    train='..\/covid\/images\/train',\n    val='..\/covid\/images\/valid',\n    nc=2,\n    names=['none','opacity'])\n\n#write yaml file\nwith open('tmp\/yolov5\/data\/data.yaml','w') as outfile:\n    yaml.dump(data_yaml,outfile,default_flow_style=True)\n\n%cat tmp\/yolov5\/data\/data.yaml","965e69ca":"# Get the raw rounding box by parsing the row value of the label column\n\ndef get_bbox(row):\n    bboxes=[]\n    bbox=[]\n    for i,l in enumerate(row.label.split(' ')):\n        if (i%6==0)|(i%6==1):\n            continue\n        bbox.append(float(l))\n        if (i%6==5):\n            bboxes.append(bbox)\n            bbox=[]\n    return bboxes\n\n#Scale the bounding boxes according to the size of the resized image\n\ndef scale_bbox(row, bboxes):\n    # Get scaling factor\n    \n    scale_x = IMG_SIZE\/row.dim1\n    scale_y= IMG_SIZE\/row.dim0\n    \n    scaled_bboxes=[]\n    \n    for bbox in bboxes:\n        x = int(np.round(bbox[0]*scale_x,4))\n        y = int(np.round(bbox[1]*scale_y,4))\n        x1=int(np.round(bbox[2]*scale_x,4))\n        y1=int(np.round(bbox[2]*scale_y,4))\n    \n        scaled_bboxes.append([x,y,x1,y1])\n        \n        \n    return scaled_bboxes\n\n# convert the bounding boxes into YOLO format\n\ndef get_yolo_format_bbox(img_w,img_h,bboxes):\n    yolo_boxes=[]\n    for bbox in bboxes:\n        w=bbox[2]-bbox[0]\n        h=bbox[3]-bbox[1]\n        xc=bbox[0]+int(np.round(w\/2)) # mid point of height and width\n        yc=bbox[1]+int(np.round(h\/2))\n        #normalization?\n        yolo_boxes.append([xc\/img_w,yc\/img_h,w\/img_w,h\/img_h])\n    \n    return yolo_boxes","3342bcfa":"# prepare the txt files for the bounding box\n\nfor i in tqdm(range(len(df))):\n    row = df.loc[i]\n    \n    #get image id\n    img_id=row.id\n    split=row.split\n    label=row.image_level\n    \n    if row.split=='train':\n        file_name=f'tmp\/covid\/labels\/train\/{row.id}.txt'\n    \n    else:\n        file_name=f'tmp\/covid\/labels\/valid\/{row.id}.txt'\n        \n        \n    if label=='opacity':\n        \n        #Get bboxes\n        bboxes = get_bbox(row)\n        # Scale bounding boxes\n        scale_bboxes = scale_bbox(row,bboxes)\n        \n        # Format for YOLOv5\n        yolo_bboxes=get_yolo_format_bbox(IMG_SIZE,IMG_SIZE,scale_bboxes)\n        \n        with open(file_name,'w') as f:\n            for bbox in yolo_bboxes:\n                bbox=[1]+bbox\n                bbox=[str(i) for i in bbox]\n                bbox = ' '.join(bbox)\n                f.write(bbox)\n                f.write('\\n')\n        \n        \n        ","e12b00fa":"%cd tmp\/yolov5\/","e1ed345e":"# !python train.py --img {IMG_SIZE} \\\n#                  --batch {BATCH_SIZE} \\\n#                  --epochs {EPOCHS} \\\n#                  --data data.yaml \\\n#                  --weights yolov5s.pt \\\n#                  --save_period 1\\\n#                  --project kaggle-siim-covid","ed828f5e":"# cd \/kaggle\/tmp\/yolov5\/kaggle-siim-covid\/exp\/weights\/\n%ls","8e99b59b":"# # import wandb\n# iimport wandb\n# run = wandb.init()\n# artifact = run.use_artifact('andernzhu\/kaggle-siim-covid\/run_3a0jaej5_model:v9', type='model')\n# artifact_dir = artifact.download()","34766238":"ls \/kaggle\/tmp\/yolov5","01b86677":"TEST_PATH = '\/kaggle\/input\/siim-covid19-resized-to-256px-jpg\/test\/' # absolute path","340e9945":"MODEL_PATH = '\/kaggle\/input\/best-model\/317a481ae22f8b127f462ec81d721bea'","fe438e76":"cd \/kaggle\/tmp\/yolov5","bac9cab4":"!python detect.py --weights {MODEL_PATH} \\\n                  --source {TEST_PATH} \\\n                  --img {IMG_SIZE} \\\n                  --conf 0.281 \\\n                  --iou-thres 0.5 \\\n                  --max-det 3 \\\n                  --save-txt \\\n                  --save-conf","236d4da2":"PRED_PATH = 'runs\/detect\/exp\/labels'\n# !ls {PRED_PATH}\n","b61f26cc":"# Visualize predicted coordinates.\n%cat runs\/detect\/exp2\/labels\/ffb8115a304c.txt","ae9edc89":"prediction_files = os.listdir(PRED_PATH)\nprint('Number of test images predicted as opaque: ', len(prediction_files))","2be09d19":"# The submisison requires xmin, ymin, xmax, ymax format. \n# YOLOv5 returns x_center, y_center, width, height\ndef correct_bbox_format(bboxes):\n    correct_bboxes = []\n    for b in bboxes:\n        xc, yc = int(np.round(b[0]*IMG_SIZE)), int(np.round(b[1]*IMG_SIZE))\n        w, h = int(np.round(b[2]*IMG_SIZE)), int(np.round(b[3]*IMG_SIZE))\n\n        xmin = xc - int(np.round(w\/2))\n        xmax = xc + int(np.round(w\/2))\n        ymin = yc - int(np.round(h\/2))\n        ymax = yc + int(np.round(h\/2))\n        \n        correct_bboxes.append([xmin, xmax, ymin, ymax])\n        \n    return correct_bboxes\n\n# Read the txt file generated by YOLOv5 during inference and extract \n# confidence and bounding box coordinates.\ndef get_conf_bboxes(file_path):\n    confidence = []\n    bboxes = []\n    with open(file_path, 'r') as file:\n        for line in file:\n            preds = line.strip('\\n').split(' ')\n            preds = list(map(float, preds))\n            confidence.append(preds[-1])\n            bboxes.append(preds[1:-1])\n    return confidence, bboxes\n        ","a0a3a048":"# Read the submission file\n\nsub_df=pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\nsub_df.tail()","e03c43a5":"# Prediction loop for submission\npredictions = []\n\nfor i in tqdm(range(len(sub_df))):\n    row = sub_df.loc[i]\n    id_name = row.id.split('_')[0]\n    id_level = row.id.split('_')[-1]\n    \n    if id_level == 'study':\n        # do study-level classification\n        predictions.append(\"Negative 1 0 0 1 1\") # dummy prediction\n        \n    elif id_level == 'image':\n        # we can do image-level classification here.\n        # also we can rely on the object detector's classification head.\n        # for this example submisison we will use YOLO's classification head. \n        # since we already ran the inference we know which test images belong to opacity.\n        if f'{id_name}.txt' in prediction_files:\n            # opacity label\n            confidence, bboxes = get_conf_bboxes(f'{PRED_PATH}\/{id_name}.txt')\n            bboxes = correct_bbox_format(bboxes)\n            pred_string = ''\n            for j, conf in enumerate(confidence):\n                pred_string += f'opacity {conf} ' + ' '.join(map(str, bboxes[j])) + ' '\n            predictions.append(pred_string[:-1]) \n        else:\n            predictions.append(\"None 1 0 0 1 1\") ","5f8a8136":"sub_df['PredictionString'] = predictions\nsub_df.to_csv('submission.csv', index=False)\nsub_df.tail()","3c1aad09":"%mv submission.csv \/kaggle\/working\n# %mv \/kaggle\/tmp\/yolov5\/requirements.txt \/kaggle\/working\n%ls \/kaggle\/working ","b69221a3":"* Create train_validation split\n* Create required `\/dataset`\n* Create `data.yaml` file needed to train the model\n* Create bounding box coordinates in the required YOLO format","86b27518":"# Create `.YAML` file","197aa54e":"# Import packages ","552a547a":"# Hyperparameters","ec760517":"# Prepare Dataset","c09b7f2c":"# Train & Validation set split","a41d0895":"# Download YOLOV5 and create our workspace ","dab14186":"# Generate the submission `.csv` file","2b5b2ec8":"# Prepare Bounding Box Coordinated for YOLOv5"}}