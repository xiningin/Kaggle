{"cell_type":{"841fcee7":"code","88614189":"code","997bc77e":"code","b17b8201":"code","c185dd5d":"code","4a1ea858":"code","3eb15c3b":"code","a11a187c":"code","6e2772f8":"code","3fb2a607":"code","f3f0f297":"code","74554bc7":"code","dec64dc8":"code","3608abf6":"code","14403d38":"code","b358b00f":"code","e976e275":"code","13663f65":"code","f717117b":"code","e8f845cd":"code","62c9f0b6":"code","1203b7f3":"code","35059de9":"code","45ac728a":"code","8b6e4229":"code","c30fc4c5":"code","44f92432":"code","0587bbea":"code","36a43c6b":"code","4315fc29":"code","67fa4f38":"markdown","a9db5f46":"markdown","d0a574cb":"markdown","c81b000f":"markdown","1ae9592e":"markdown","2d618292":"markdown","0aff553d":"markdown","3cb42da6":"markdown","62e98b15":"markdown","a2a585e9":"markdown"},"source":{"841fcee7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","88614189":"\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))","997bc77e":"# reading data from heart.csv file\ndf = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndf.head()","b17b8201":"# checking shape of the data\ndf.shape","c185dd5d":"# checking for null values\ndf.isnull().sum()","4a1ea858":"# checking for nan values\ndf.isna().sum()","3eb15c3b":"df.info()","a11a187c":"# Heart disease (0 = no, 1 = yes)\ndf['target'].value_counts()\n","6e2772f8":"sns.countplot(x=\"target\", data=df)\nplt.title(\"Target Count\")\nplt.show()","3fb2a607":"sns.countplot(x='sex',hue='target', data=df)\nplt.title(\"sex vs target\")\nplt.xlabel(\"sex: 0-female & 1-male\")\nplt.ylabel(\"target_count\")\nplt.legend([\"0- no disease\" , \"1-disease\"])\nplt.show()","f3f0f297":"pd.crosstab(df.age,df.target).plot(kind=\"bar\",figsize=(20,10))\nplt.title('Heart Disease Frequency Corresponding to Ages')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.legend([\"0- no disease\" , \"1-disease\"])\nplt.show()","74554bc7":"pd.crosstab(df.cp,df.target).plot(kind=\"bar\",figsize=(15,10))\nplt.title('Heart Disease Frequency Corresponding To Chest Pain Type')\nplt.xlabel('Chest Pain Type')\nplt.xticks(rotation = 0)\nplt.ylabel('Frequency of Disease or Not')\nplt.legend([\"0- no disease\" , \"1-disease\"])\nplt.show()","dec64dc8":"plt.scatter(x=df.age[df.target==1], y=df.thalach[(df.target==1)], c=\"purple\")\nplt.scatter(x=df.age[df.target==0], y=df.thalach[(df.target==0)])\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Maximum Heart Rate\")\nplt.show()","3608abf6":"plt.scatter(x=df.age[df.target==1], y=df.trestbps[(df.target==1)], c=\"red\")\nplt.scatter(x=df.age[df.target==0], y=df.trestbps[(df.target==0)])\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Person's resting blood pressure\")\nplt.show()","14403d38":"plt.scatter(x=df.age[df.target==1], y=df.chol[(df.target==1)], c=\"orange\")\nplt.scatter(x=df.age[df.target==0], y=df.chol[(df.target==0)])\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Person's cholesterol measurement in mg\/dl\")\nplt.show()","b358b00f":"# As columns 'cp', 'thal' and 'slope' are categorical variables we'll convert these columns into dummy variables , we are not converting other categorical variables to avoid Dummy Variable Trap\nx = pd.get_dummies(df['cp'], prefix = \"cp\")\ny = pd.get_dummies(df['thal'], prefix = \"thal\")\nz = pd.get_dummies(df['slope'], prefix = \"slope\")\nadditional_df = [df, x, y, z]\ndf = pd.concat(additional_df, axis = 1)\ndf.head()","e976e275":"df = df.drop(columns = ['cp', 'thal', 'slope'])\ndf.head()","13663f65":"y = df.target.values\nx = df.drop(['target'], axis = 1)\n\n# splitting the data in train and test data\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=0)\n\n","f717117b":"#initialising the KNN Model - base model\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train,y_train)\nacc= knn.score(x_test,y_test)*100\n\n# printing the accuracy\nprint(\"Test Accuracy {:.2f}%\".format(acc))","e8f845cd":"# check for outlier in 'chol'\nplt.scatter(x=df.age[df.target==1], y=df.chol[(df.target==1)], c=\"red\")\nplt.scatter(x=df.age[df.target==0], y=df.chol[(df.target==0)])\nplt.legend([\"Disease\", \"Not Disease\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Person's cholesterol measurement in mg\/dl\")\nplt.show()","62c9f0b6":"# Z-score test\nout=[]\ndef Zscore_outlier(df):\n    m = np.mean(df)\n    sd = np.std(df)\n    for i in df: \n        z = (i-m)\/sd\n        if np.abs(z) > 3: \n            out.append(i)\n    print(\"Outliers:\",out)\nZscore_outlier(df['chol'])","1203b7f3":"df[df['chol']==564].index\n# checking data shape befor dropping\nprint(df.shape)\n# dropping outlier value\ndf.drop(85,inplace=True)\n# checking data shape after dropping\nprint(df.shape)","35059de9":"\ny = df.target.values\nx = df.drop(['target'], axis = 1)\nx1 = x.values\nscaler = MinMaxScaler()\nx_trans = scaler.fit_transform(x1)\nx_train, x_test, y_train, y_test = train_test_split(x_trans,y,test_size = 0.2,random_state=0)","45ac728a":"#initialising the KNN Model after removing outlier\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train,y_train)\nacc= knn.score(x_test,y_test)*100\n\n# printing the accuracy\nprint(\"Test Accuracy {:.2f}%\".format(acc))","8b6e4229":"# plotting graph\nscorelist = []\nfor i in range(1,20):\n    knn1 = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k\n    knn1.fit(x_train, y_train)\n    scorelist.append(knn1.score(x_test, y_test))\n    \nplt.plot(range(1,20), scorelist)\nplt.xticks(np.arange(1,20,1))\nplt.xlabel(\"K value\")\nplt.ylabel(\"Score\")\nplt.show()","c30fc4c5":"#initialising the KNN Model- Maximum Accuracy\nknn = KNeighborsClassifier(n_neighbors = 7) # for maximum accuracy\nknn.fit(x_train,y_train)\nacc= knn.score(x_test,y_test)*100\n\n# printing the accuracy\nprint(\"Test Accuracy {:.2f}%\".format(acc))","44f92432":"# confusion matrix\n\ny_head_knn = knn.predict(x_test)\ny_pred_quant = knn.predict_proba(x_test)[:, 1] # we will use this value for ROC\ncm_knn = confusion_matrix(y_test,y_head_knn)\nprint(cm_knn)","0587bbea":"# sensitivity and specificity\na = sum(sum(cm_knn))\nsensitivity = (cm_knn[0,0]\/(cm_knn[0,0] + cm_knn[1,0]))\nprint(\"sensitivity:\",sensitivity)\nspecificity = (cm_knn[1,1]\/(cm_knn[1,1]+ cm_knn[0,1]))\nprint(\"specificity:\",specificity)","36a43c6b":"\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_quant)\nfig, ax = plt.subplots()\nax.plot(fpr, tpr)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for diabetes classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","4315fc29":"auc(fpr, tpr)","67fa4f38":"As, we can observed from above plot that for K-value = 7 we will get maximum accuracy","a9db5f46":"Now let's check for Receiver Operator Curve (ROC)","d0a574cb":"from above values, only 564 seems an outlier","c81b000f":"let's do Normalization of the data as well using MinMaxScaler()","1ae9592e":"***I'm fresh to the field of data science. Please leave me feedback so that I can improve. Thank you for your time and consideration.***","2d618292":"The Area Under the Curve, or AUC, is another popular measure. This is a highly handy way to summarise a model's performance in a single figure, however it is not without limitations. An AUC can be classified as follows as a rule of thumb:\n* 0.90 - 1.00 = excellent\n* 0.80 - 0.90 = good\n* 0.70 - 0.80 = fair\n* 0.60 - 0.70 = poor\n* 0.50 - 0.60 = fail\nLet's see what the above ROC gives us,","0aff553d":"As we can see, accuracy is coming very low, so now we'll try to make some other changes like looking for some outliers if any and trying to perform transformation on the data as well.","3cb42da6":"## The KNN Model","62e98b15":"As we can observed that after removing the outlier our accuracy is increased but now will check for which n-neighbors value we are getting maximum accuracy","a2a585e9":"As we can see from the above plot that there exist few outliers in the data, we will try to verify this with some other concept as Z-score method\n\nIf the z score of a data point is more than 3 (because it cover 99.7% of area), it indicates that the data value is quite different from the other values. It is taken as outliers."}}