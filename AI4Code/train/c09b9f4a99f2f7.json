{"cell_type":{"8916c6bf":"code","99e55a36":"code","039ff863":"code","3e678c71":"code","6cc061f9":"code","067306be":"code","476cd824":"code","8f487c6f":"code","7bd97967":"code","5ff3ae90":"code","e9246420":"code","38f23847":"code","1c6a9190":"code","37d50538":"code","c86111a9":"code","0c16f526":"code","aaf36e47":"code","dcf91678":"code","8647d588":"code","10ab5594":"code","bacb474e":"code","626c6107":"code","e120234b":"code","0ebcb515":"code","ac82ba2f":"code","fe2840d6":"code","a6b8be71":"code","3081c1fb":"code","03ef1887":"code","2f2aefc8":"code","f73ee635":"code","56406f7e":"code","a3b7117f":"code","037e06b4":"code","9fc52723":"code","f33dbf36":"markdown","aa6963d5":"markdown","482211e3":"markdown","2d601fe9":"markdown","3ce3f404":"markdown","184a6455":"markdown","ead8bc11":"markdown","ec3b6fca":"markdown","fce173eb":"markdown","c116c36a":"markdown","ba9e4507":"markdown","2d2f4247":"markdown","82ba7ac1":"markdown","963a01e9":"markdown","2f2168d1":"markdown"},"source":{"8916c6bf":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import KFold, cross_validate, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","99e55a36":"PATH = '..\/input\/news-category-dataset\/News_Category_Dataset_v2.json'","039ff863":"data = pd.read_json(PATH, lines=True)\ndata.head(5)","3e678c71":"data = data.drop(['authors', 'link', 'date'], axis=1)\ndata.head(5)","6cc061f9":"data['text'] = data['headline'] + \" \" + data['short_description']\ndata.head(5)","067306be":"data = data.drop(['headline', 'short_description'], axis=1)\ndata.head(5)","476cd824":"categories = data.groupby('category')\nprint(\"There's {} news categories.\" .format(categories.ngroups))\nprint(categories.size())","8f487c6f":"culture = ['ARTS & CULTURE', 'ARTS', 'CULTURE & ARTS']\nhome_living = ['HOME & LIVING', 'HEALTHY LIVING', 'WELLNESS']\nstyle = ['STYLE', 'STYLE & BEAUTY']\nentertainment = ['COMEDY', 'ENTERTAINMENT', 'MEDIA']\nbusiness = ['MONEY', 'BUSINESS']\nparenting = ['PARENTING', 'PARENTS']\nscience_tech = ['SCIENCE', 'TECH']\neducation = ['COLLEGE', 'EDUCATION']\ndrop = ['BLACK VOICES', 'DIVORCE', 'FIFTY', 'GOOD NEWS', 'IMPACT', 'LATINO VOICES', 'WOMEN', \n        'QUEER VOICES', 'TASTE', 'THE WORLDPOST', 'WORLD NEWS', 'WORLDPOST', 'GREEN', 'WEIRD NEWS', 'DIVORCE', ]","7bd97967":"data_improved = data[~data.category.isin(drop)]","5ff3ae90":"data_improved.category[data_improved.category.isin(culture)] = \"CULTURE\"\ndata_improved.category[data_improved.category.isin(home_living)] = \"HOME & LIVING\"\ndata_improved.category[data_improved.category.isin(style)] = \"STYLE\"\ndata_improved.category[data_improved.category.isin(entertainment)] = \"ENTERTAINMENT\"\ndata_improved.category[data_improved.category.isin(business)] = \"BUSINESS\"\ndata_improved.category[data_improved.category.isin(parenting)] = \"PARENTING\"\ndata_improved.category[data_improved.category.isin(education)] = \"EDUCATION\"\ndata_improved.category[data_improved.category.isin(science_tech)] = \"SCIENCE & TECH\"","e9246420":"data_improved = data_improved.reset_index(drop=True)","38f23847":"len(data_improved)","1c6a9190":"data_improved.text = data_improved.text.replace('[0-9]', '', regex=True)","37d50538":"lenght = []\nfor i in range(len(data_improved)):\n    lenght.append(len(data_improved.text[i].split()))","c86111a9":"data_improved['lenght'] = lenght","0c16f526":"data_improved.head(5)","aaf36e47":"data_improved = data_improved[data_improved.lenght>10]\nlen(data_improved)","dcf91678":"categories = data_improved.groupby('category')\nprint(\"There's {} news categories.\" .format(categories.ngroups))\nprint(categories.size())","8647d588":"fig, ax = plt.subplots(1, 1, figsize=(35,7))\nsns.countplot(x = 'category', data = data_improved)","10ab5594":"import spacy\nfrom html import unescape\n\n# create a spaCy tokenizer\nspacy.load('en')\nlemmatizer = spacy.lang.en.English()\n\n#to lower, remove HTML tags\ndef my_preprocessor(doc):\n    return(unescape(doc).lower())\n\n# tokenize the doc and lemmatize its tokens\ndef my_tokenizer(doc):\n    tokens = lemmatizer(doc)\n    return([token.lemma_ for token in tokens])","bacb474e":"X_train, X_test, y_train, y_test = train_test_split(data_improved.text, data_improved.category, test_size=0.2, random_state=42)","626c6107":"folds = KFold(n_splits = 5, shuffle = True, random_state = 1)","e120234b":"vect = TfidfVectorizer(stop_words='english', ngram_range = (1,2), max_features = 15000, preprocessor=my_preprocessor, tokenizer=my_tokenizer)","0ebcb515":"from sklearn.svm import LinearSVC\nfrom sklearn.linear_model import RidgeClassifier\nfrom xgboost.sklearn import XGBClassifier","ac82ba2f":"NB = MultinomialNB()\nRidge = RidgeClassifier()\nXGB = XGBClassifier(objective = 'multi:softprob')","fe2840d6":"def fit_model(clf , name):\n    pipe = Pipeline([\n    ('vectorize', vect),\n    (name, clf)])\n    result = cross_validate(pipe, X_train, y_train, cv = folds, return_train_score=True,scoring = ('accuracy', \n                                                                                       'f1_weighted', \n                                                                                       'precision_weighted', \n                                                                                       'recall_weighted'))\n    return result","a6b8be71":"bayes = fit_model(NB, 'NB')\nridge = fit_model(Ridge, 'Ridge')\nxgb = fit_model(XGB, 'XGB')","3081c1fb":"bayes.keys()","03ef1887":"b = pd.DataFrame.from_dict(bayes)\nb['model'] = [\"NB\",\"NB\",\"NB\",\"NB\",\"NB\"]\nr = pd.DataFrame.from_dict(ridge)\nr['model'] = [\"Ridge\",\"Ridge\",\"Ridge\",\"Ridge\",\"Ridge\"]\nx = pd.DataFrame.from_dict(xgb)\nx['model'] = [\"XGB\",\"XGB\",\"XGB\",\"XGB\",\"XGB\"]\n\nresults = pd.concat([b,r,x])","2f2aefc8":"results.sample(6)","f73ee635":"models_eval = results.groupby(\"model\")","56406f7e":"means = models_eval.mean()\nsd = models_eval.std()","a3b7117f":"means.head()","037e06b4":"sd.head()","9fc52723":"from sklearn import metrics\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.base import clone\nfrom sklearn.preprocessing import label_binarize\nfrom scipy import interp\nfrom sklearn.metrics import roc_curve, auc \n\n\ndef get_metrics(true_labels, predicted_labels):\n    \n    print('Accuracy:', np.round(\n                        metrics.accuracy_score(true_labels, \n                                               predicted_labels),\n                        4))\n    print('Precision:', np.round(\n                        metrics.precision_score(true_labels, \n                                               predicted_labels,\n                                               average='weighted'),\n                        4))\n    print('Recall:', np.round(\n                        metrics.recall_score(true_labels, \n                                               predicted_labels,\n                                               average='weighted'),\n                        4))\n    print('F1 Score:', np.round(\n                        metrics.f1_score(true_labels, \n                                               predicted_labels,\n                                               average='weighted'),\n                        4))\n                        \n\ndef train_predict_model(classifier, \n                        train_features, train_labels, \n                        test_features, test_labels):\n    # build model    \n    classifier.fit(train_features, train_labels)\n    # predict using model\n    predictions = classifier.predict(test_features) \n    return predictions    \n\n\ndef display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n    \n    total_classes = len(classes)\n    level_labels = [total_classes*[0], list(range(total_classes))]\n\n    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n                                  labels=classes)\n    cm_frame = pd.DataFrame(data=cm, \n                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n                                                  labels=level_labels), \n                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n                                                labels=level_labels)) \n    print(cm_frame) \n    \ndef display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n\n    report = metrics.classification_report(y_true=true_labels, \n                                           y_pred=predicted_labels, \n                                           labels=classes) \n    print(report)\n    \n    \n    \ndef model_perf(classes=y_test.unique()):\n    print('Model Performance metrics:')\n    print('-'*30)\n    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n    print('\\nModel Classification report:')\n    print('-'*30)\n    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n                                  classes=classes)\n    print('\\nPrediction Confusion Matrix:')\n    print('-'*30)\n    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n                             classes=classes)","f33dbf36":"Drop some columns as we don't need those","aa6963d5":"Reset index","482211e3":"## BoW and Tfidf model\nLet's start with just a simple bag of words and tfidf features. We'll use both 1- and 2-grams for calculating these features.","2d601fe9":"### Remove stopwords and lemmatize\n\nCan placed in the vectorizer function","3ce3f404":"Merge the text columns into one since extracting features will be easier this way","184a6455":"Remove digits as they are rarely indicative of topic. Except maybe business has more numbers but that probably wouldn't help much.","ead8bc11":"Let's look at number of news per category","ec3b6fca":"And again we can drop now useless columns: headline and short_description","fce173eb":"### Evaluate models","c116c36a":"There are some categories that could be treated as one. For example ARTS & CULTURE, ARTS and CULTURE & ARTS. We're not interested in some of the categories so we'll drop those.","ba9e4507":"### Train-test split\nKeep 10% aside for testing","2d2f4247":"Load the dataset","82ba7ac1":"#### MODELS\n* Naive Bayes\n* Ridge\n* XGBoost","963a01e9":"### K-fold split","2f2168d1":"> Compute text lenght (number of words) and exclude very short ones."}}