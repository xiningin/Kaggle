{"cell_type":{"1af4d020":"code","0249eb35":"code","4c59fe15":"code","fb453007":"code","303e4aed":"code","727d4874":"code","b2fabde8":"code","db03adc9":"code","e0c43175":"code","73a70733":"code","52f4732f":"code","15adbbd0":"code","40496ecf":"code","bd7059d0":"code","95bbf80c":"code","6e0701b2":"code","690f2cfa":"code","818424c3":"code","032c05d1":"code","e93d9919":"markdown","44fa50c7":"markdown","d8ab7944":"markdown","f512d840":"markdown","8588b8fb":"markdown","3f417af9":"markdown","83af81fc":"markdown","c9634c1f":"markdown","4bbeac63":"markdown","f22ea4e8":"markdown","d096700e":"markdown","b4f107b2":"markdown","2b1abe98":"markdown"},"source":{"1af4d020":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\n\n%matplotlib inline\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# import plot_utils\n\nprint('Tensorflow version:', tf.__version__)\nimport numpy as np\nimport matplotlib.pyplot as plt","0249eb35":"def show(images, n_cols=None):\n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    plt.figure(figsize=(n_cols, n_rows))\n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","4c59fe15":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\nx_train = x_train.astype(np.float32) \/ 255.0\nx_test = x_test.astype(np.float32) \/ 255.0","fb453007":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i], cmap=plt.cm.binary)\nplt.show()","303e4aed":"batch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000)\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)","727d4874":"num_features = 100\n\ngenerator = keras.models.Sequential([\n    keras.layers.Dense(7 * 7 * 256, input_shape=[num_features]),\n    keras.layers.Reshape([7, 7, 256]),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(128, (5,5), (1,1), padding=\"same\", activation=\"selu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(64, (5,5), (2,2), padding=\"same\", activation=\"selu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(1, (5,5), (2,2), padding=\"same\", activation=\"tanh\"),\n])","b2fabde8":"noise = tf.random.normal(shape=[1, num_features])\ngenerated_images = generator(noise, training=False)\nshow(generated_images, 1)","db03adc9":"# detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\n# with tpu_strategy.scope():\n#     model = tf.keras.Sequential( \u2026 ) # define your model normally\n#     model.compile( \u2026 )\n\n# train model normally\n# model.fit(training_dataset, epochs=EPOCHS, steps_per_epoch=\u2026)","e0c43175":"discriminator = keras.models.Sequential([\n    keras.layers.Conv2D(64, (5,5), (2,2), padding=\"same\", input_shape=[28, 28, 1]),\n    keras.layers.LeakyReLU(0.2),\n    keras.layers.Dropout(0.3),\n    keras.layers.Conv2D(128, (5,5), (2,2), padding=\"same\"),\n    keras.layers.LeakyReLU(0.2),\n    keras.layers.Dropout(0.3),\n    keras.layers.Conv2D(256, (5,5), (1,1), padding=\"same\"),\n    keras.layers.LeakyReLU(0.2),\n    keras.layers.Dropout(0.3),\n    keras.layers.Flatten(),\n    keras.layers.Dense(1, activation='sigmoid')\n])","73a70733":"decision = discriminator(generated_images)\nprint(decision)","52f4732f":"discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\ndiscriminator.trainable = False\ngan = keras.models.Sequential([generator, discriminator])\ngan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")","15adbbd0":"from IPython import display\nfrom tqdm import tqdm\nseed = tf.random.normal(shape=[batch_size, 100])","40496ecf":"from tqdm import tqdm\ndef train_dcgan(gan, dataset, batch_size, num_features, epochs=5):\n    generator, discriminator = gan.layers\n    for epoch in tqdm(range(epochs)):\n        print(\"Epoch {}\/{}\".format(epoch + 1, epochs))\n        for X_batch in dataset:\n            noise = tf.random.normal(shape=[batch_size, num_features])\n            generated_images = generator(noise)\n            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n            discriminator.trainable = True\n            discriminator.train_on_batch(X_fake_and_real, y1)\n            noise = tf.random.normal(shape=[batch_size, num_features])\n            y2 = tf.constant([[1.]] * batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, y2)\n            # Produce images for the GIF as we go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator, epoch + 1, seed)\n        \n    display.clear_output(wait=True)\n    generate_and_save_images(generator, epochs, seed)","bd7059d0":"## Source https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan#create_a_gif\ndef generate_and_save_images(model, epoch, test_input):\n    # Notice `training` is set to False.\n    # This is so all layers run in inference mode (batchnorm).\n    predictions = model(test_input, training=False)\n\n    fig = plt.figure(figsize=(10,10))\n\n    for i in range(25):\n        plt.subplot(5, 5, i+1)\n        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='binary')\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","95bbf80c":"x_train_dcgan = x_train.reshape(-1, 28, 28, 1) * 2. - 1.","6e0701b2":"batch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices(x_train_dcgan)\ndataset = dataset.shuffle(1000)\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)","690f2cfa":"%%time\ntrain_dcgan(gan, dataset, batch_size, num_features, epochs=15)","818424c3":"noise = tf.random.normal(shape=[batch_size, num_features])\ngenerated_images = generator(noise)\nshow(generated_images, 8)","032c05d1":"## Source: https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan#create_a_gif\nimport imageio\nimport glob\n\nanim_file = 'dcgan_anim.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n    filenames = glob.glob('image*.png')\n    filenames = sorted(filenames)\n    last = -1\n    for i,filename in enumerate(filenames):\n        frame = 2*(i)\n        if round(frame) > round(last):\n            last = frame\n        else:\n            continue\n        image = imageio.imread(filename)\n        writer.append_data(image)\n    image = imageio.imread(filename)\n    writer.append_data(image)\n\n    #import IPython\n    #display.Image(filename=anim_file)","e93d9919":"<h2 align=center>Generate Synthetic Images with DCGANs in Keras<\/h2>","44fa50c7":"## Task 4: Build the Generator Network for DCGAN","d8ab7944":"## Task 2: Load and Preprocess the Data","f512d840":"## Task 3: Create Batches of Training Data","8588b8fb":"## Task 9: Generate Synthetic Images with DCGAN","3f417af9":"## Task 1: Project Overview and Import Libraries","83af81fc":"### utility function to show the 2images","c9634c1f":"## Tak 5: Build the Discriminator Network for DCGAN","4bbeac63":"## Task 8: Train DCGAN","f22ea4e8":"![GAN](https:\/\/github.com\/blurred-machine\/Generate-Synthetic-Images-with-DCGANs-in-Keras\/blob\/master\/dcgan.png?raw=true)","d096700e":"## Task 7: Define Training Procedure","b4f107b2":"![Image](https:\/\/github.com\/blurred-machine\/Generate-Synthetic-Images-with-DCGANs-in-Keras\/blob\/master\/dcgan_anim.gif?raw=true)","2b1abe98":"## Task 6: Compile the Deep Convolutional Generative Adversarial Network (DCGAN)"}}