{"cell_type":{"3327e95c":"code","da0045a9":"code","f0b16bb6":"code","9fed196d":"markdown","657314cc":"markdown"},"source":{"3327e95c":"from bs4 import BeautifulSoup\nimport requests\nfrom csv import writer\nimport pandas as pd","da0045a9":"home_url = \"https:\/\/www.rokomari.com\"\nbase_url = \"https:\/\/www.rokomari.com\/book\/category\/1983\/extra-discount?ref=act_pg0_p0&page=\"\n\ntitle = []\nauthors = []\nprices_original = []\nprices_selling = []\ndiscount = []\ncategory = []\npublishers = []\nratings_count = []\nratings = []\n\nchar_to_replace = {\n    '\\n': ''\n}\n\nfor i in range(50):\n    url = base_url + str(i+1)\n    page = requests.get(url)\n    soup = BeautifulSoup(page.content, \"lxml\")\n    lists = soup.find_all('div', class_=\"home-details-btn-wrapper\")\n    \n    \n    for list in lists:\n        for link in list.find_all('a', href=True):\n            url_details = home_url + link[\"href\"]\n            page_details = requests.get(url_details)\n            soup_details = BeautifulSoup(page_details.content, \"lxml\")\n            \n            lists_details = soup_details.find_all('div', class_=\"col details-book-main-info align-self-center\")\n            lists_authors = soup_details.find_all('p', class_=\"details-book-info__content-author\")\n            lists_cat = soup_details.find_all('div', class_=\"details-book-info__content-category d-flex align-items-center\")\n            lists_ratings_count = soup_details.find_all('div', 'span', class_=\"details-book-info__content-rating\")\n            lists_ratings = soup_details.find_all('div', class_=\"media ratings-review__content--rating\")\n            lists_price = soup_details.find_all('div', 'span', class_=\"details-book-info__content-book-price\")\n            \n            lists_pub = soup_details.find_all('td', class_=\"publisher-link\")    \n            \n# # # __________________________________Scraping the title of the books_____________________________\n            for list_det in lists_details:\n                for details in list_det.find_all('div', class_=\"details-book-main-info__header\"):\n                    title.append(details.find('h1').text)\n                    \n#___________________________________Scraping the name of the authors______________________________\n            for author in lists_authors:\n                authors.append(author.a.text.translate(str.maketrans(char_to_replace)).strip())\n\n# __________________________________Scraping the category______________________\n            for cat in lists_cat:\n                category.append(cat.a.text.strip())\n#___________________________________Scraping the ratings count________________________\n            for rating_count in lists_ratings_count:\n                rating_count_info = rating_count.span\n                if rating_count_info == None:\n                    ratings_count.append('NA')\n                else:\n                    ratings_count.append(rating_count_info.text)\n                    \n#___________________________________Scraping the ratings (this section has bug)________________________\n            for rating in lists_ratings:\n                rating_info = rating.find('h2', class_=\"pt-2\")\n                if rating_info == None:\n                    ratings.append('NA')\n                else:\n                    ratings.append(rating_info.text.replace('\\n', '').strip())\n\n# # ___________________________________scraping the prices_____________________\n\n            for price in lists_price:\n                prices_selling.append(price.find('span', class_=\"sell-price\").text.replace('\\n', ''))\n                price_origin_info = price.find('strike', class_=\"original-price\")\n                if price_origin_info == None:\n                    prices_original.append('NA')\n                    discount.append('Na')\n                else:\n                    prices_original.append(price_origin_info.text.replace('\\n', ''))\n                    discount.append(price.find('span', class_=\"js--save-message\").text.replace('\\n', ''))\n\n#____________________________________Scraping the publications_________________\n                                \n            for pub in lists_pub:\n                publishers.append(pub.a.string.replace('\\n','').strip())\n                \n        \n\n#****************************  Rearranging all the scraped data ******************************\n                \ndict_book = {\n    \"Title\": title,\n    \"Author\": authors,\n    \"Original Price\": prices_original,\n    \"Selling Price\": prices_selling,\n    \"Discount\": discount,\n    \"Publisher\": publishers,\n    \"Rating Count\": ratings_count,\n    \"Category\": category\n}\nbook_df = pd.DataFrame(dict_book)   \nbook_df.to_csv('More Info Rokomari.csv', index=False) # Exporting to a csv file","f0b16bb6":"home_url = \"https:\/\/www.rokomari.com\"\nbase_path = \"https:\/\/www.rokomari.com\/book\/publishers?ref=sm_p2\"\n\npublisher = []\nurl = []\n\nfor i in range(3):\n    if i<1:\n        page = requests.get(base_path)\n    else:\n        page = requests.get(base_path+'&page='+str(i+1))\n    soup = BeautifulSoup(page.content, \"lxml\")\n    lists = soup.find_all('ul', class_=\"list-inline list-unstyled authorList\")\n    for list in lists:\n        for name in list.find_all('h2'):\n            publisher.append(name.text)\n        for link in list.find_all('a', href=True):\n            url.append(home_url + link[\"href\"]) \n\ninfo_dict = {\n    \"Publishers Name\": publisher,\n    \"URL\": url\n}\ninfo_df = pd.DataFrame(info_dict)\ninfo_df.to_csv('Publishers_url.csv', index=False)    ","9fed196d":"# Trying To Get the URL","657314cc":"# Code snippet for scraping books from rokomari"}}