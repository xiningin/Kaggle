{"cell_type":{"e4db47d9":"code","6ac5d38d":"code","b99147a3":"code","1f69de7f":"code","51a0e163":"code","f9fe2450":"code","f34420cd":"code","68eb327a":"code","e0d7663f":"code","9097de1f":"code","65a595bd":"code","9976b931":"code","c46b4e3a":"code","ab7f56e9":"code","cbc651d3":"code","ab6dceb1":"code","866d843d":"code","2fcb36a3":"code","5e2ff304":"code","9a0351cd":"code","7c0ff242":"code","1c46eb15":"code","d5e78b9c":"code","b289b6c2":"code","7b165df3":"code","df98c30d":"code","54a8135d":"code","66a5519e":"code","6e552c79":"code","b28c4a6f":"code","330b3d76":"code","c2086a73":"code","c98db08d":"code","0cc478cc":"code","93dbf8c6":"code","c3ffea43":"code","5bf7f79c":"code","3f42cc99":"code","e7108aa7":"code","67a8c5d2":"code","6cd8c9ab":"code","749a2148":"code","39c33754":"code","f2c68bf1":"code","f561112e":"code","4d30f660":"code","a634f155":"code","6df10921":"code","7722bbf1":"code","1e9c86af":"code","55710e3e":"code","562ad259":"code","46968866":"code","36649da7":"code","544ac17b":"code","76d685dc":"code","dadb6d15":"code","22573905":"code","710800fe":"code","53ffc2a6":"code","4165cb36":"code","d245f484":"code","71b497d6":"code","aaa09d57":"code","fdd224dc":"code","1a6b87a6":"code","214d3428":"code","07dfa85f":"code","ebde75d9":"code","4ffb04d4":"code","7e6f09b5":"code","97b68762":"code","1d1016b9":"markdown","2ff00cd4":"markdown","e2e3e1ae":"markdown","9aadbaa3":"markdown","2644dcdf":"markdown","c230c8db":"markdown","64a9f632":"markdown","b6badd6a":"markdown","40cb05bb":"markdown","fade1252":"markdown","2031a976":"markdown","15b86bed":"markdown","895a3d7e":"markdown","aab630ee":"markdown","6c992164":"markdown","8292c7ae":"markdown","df9a966b":"markdown","154ff3db":"markdown","dc50dad4":"markdown","3fdf458c":"markdown","1c3f9d00":"markdown","479a4a30":"markdown","a510d07e":"markdown","f7ff864a":"markdown","ecb42376":"markdown"},"source":{"e4db47d9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom plotly import tools\nimport plotly.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#import os\n#print(os.listdir(\"..\/input\"))\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))","6ac5d38d":"import datetime, pytz\n#define a conversion function for the native timestamps in the csv file\ndef dateparse (time_in_secs):    \n    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))\n\n\ndata = pd.read_csv('..\/input\/coinbaseUSD_1-min_data_2014-12-01_to_2018-11-11.csv', parse_dates=[0], date_parser=dateparse)","b99147a3":"data.info()","1f69de7f":"data.head()","51a0e163":"# First thing is to fix the data for bars\/candles where there are no trades. \n# Volume\/trades are a single event so fill na's with zeroes for relevant fields...\ndata['Volume_(BTC)'].fillna(value=0, inplace=True)\ndata['Volume_(Currency)'].fillna(value=0, inplace=True)\ndata['Weighted_Price'].fillna(value=0, inplace=True)\n\n# next we need to fix the OHLC (open high low close) data which is a continuous timeseries so\n# lets fill forwards those values...\ndata['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)\n\ndata.head()","f9fe2450":"# create valid date range\nstart = datetime.datetime(2015, 1, 1, 0, 0, 0, 0, pytz.UTC)\nend = datetime.datetime(2018, 11, 11, 0, 0, 0, 0, pytz.UTC)\n\n# find rows between start and end time and find the first row (00:00 monday morning)\nweekly_rows = data[(data['Timestamp'] >= start) & (data['Timestamp'] <= end)].groupby([pd.Grouper(key='Timestamp', freq='W-MON')]).first().reset_index()\nweekly_rows.head()","f34420cd":"# We use Plotly to create the plots https:\/\/plot.ly\/python\/\ntrace1 = go.Scatter(\n    x = weekly_rows['Timestamp'],\n    y = weekly_rows['Open'].astype(float),\n    mode = 'lines',\n    name = 'Open'\n)\n\ntrace2 = go.Scatter(\n    x = weekly_rows['Timestamp'],\n    y = weekly_rows['Close'].astype(float),\n    mode = 'lines',\n    name = 'Close'\n)\ntrace3 = go.Scatter(\n    x = weekly_rows['Timestamp'],\n    y = weekly_rows['Weighted_Price'].astype(float),\n    mode = 'lines',\n    name = 'Weighted Avg'\n)\n\nlayout = dict(\n    title='Historical Bitcoin Prices (2015-2018) with the Slider ',\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                #change the count to desired amount of months.\n                dict(count=1,\n                     label='1m',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=6,\n                     label='6m',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=12,\n                     label='1y',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=36,\n                     label='3y',\n                     step='month',\n                     stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(\n            visible = True\n        ),\n        type='date'\n    )\n)\n\ndata = [trace1,trace2, trace3]\nfig = dict(data=data, layout=layout)\niplot(fig, filename = \"Time Series with Rangeslider\")","68eb327a":"trace1 = go.Scatter(\n    x = weekly_rows['Timestamp'],\n    y = weekly_rows['Volume_(Currency)'].astype(float),\n    mode = 'lines',\n    name = 'Bitcoin Price (Open)'\n)\n\nlayout = dict(\n    title='Historical Bitcoin Volume (USD) (2015-2018) with the slider',\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1,\n                     label='1m',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=6,\n                     label='6m',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=12,\n                     label='1y',\n                     step='month',\n                     stepmode='backward'),\n                dict(count=36,\n                     label='3y',\n                     step='month',\n                     stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(\n            visible = True\n        ),\n        type='date'\n    )\n)\n\ndata = [trace1]\nfig = dict(data=data, layout=layout)\niplot(fig, filename = \"Time Series with Rangeslider\")","e0d7663f":"#BTC Volume vs USD visualization\ntrace = go.Scattergl(\n    y = weekly_rows['Volume_(BTC)'].astype(float),\n    x = weekly_rows['Weighted_Price'].astype(float),\n    mode = 'markers',\n    marker = dict(\n        color = '#FFBAD2',\n        line = dict(width = 1)\n    )\n)\nlayout = go.Layout(\n    title='BTC Volume v\/s USD',\n    xaxis=dict(\n        title='Weighted Price',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='Volume BTC',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )))\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\niplot(fig, filename='compare_webgl')","9097de1f":"#load the dataset \ndata = pd.read_csv('..\/input\/coinbaseUSD_1-min_data_2014-12-01_to_2018-11-11.csv',parse_dates=[0], date_parser=dateparse) \ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)\n","65a595bd":"# split data\nsplit_date = '25-Jun-2018'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()\n","9976b931":"# Data preprocess\ntraining_set = data_train.values\ntraining_set = np.reshape(training_set, (len(training_set), 1))\nfrom sklearn.preprocessing import MinMaxScaler\nsc = MinMaxScaler()\ntraining_set = sc.fit_transform(training_set)\nX_train = training_set[0:len(training_set)-1]\ny_train = training_set[1:len(training_set)]\nX_train = np.reshape(X_train, (len(X_train), 1, 1))\n","c46b4e3a":"color_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\n_ = data.plot(style='', figsize=(15,5), color=color_pal[0], title='BTC Weighted_Price Price (USD) by Hours')","ab7f56e9":"_ = data_test \\\n    .rename(columns={'Weighted_Price': 'Test Set'}) \\\n    .join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer') \\\n    .plot(figsize=(15,5), title='BTC Weighted_Price Price (USD) by Hours', style='')","cbc651d3":"# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers import Activation\n\n\nmodel = Sequential()\nmodel.add(LSTM(128,activation=\"sigmoid\",input_shape=(1,1)))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(X_train, y_train, epochs=100, batch_size=50, verbose=2)","ab6dceb1":"model.summary()","866d843d":"# Making the predictions\ntest_set = data_test.values\ninputs = np.reshape(test_set, (len(test_set), 1))\ninputs = sc.transform(inputs)\ninputs = np.reshape(inputs, (len(inputs), 1, 1))\npredicted_BTC_price = model.predict(inputs)\npredicted_BTC_price = sc.inverse_transform(predicted_BTC_price)","2fcb36a3":"data_test['Weighted_Price_Prediction'] = predicted_BTC_price\ndata_all = pd.concat([data_test, data_train], sort=False)","5e2ff304":"#saving the predicted values in a common data frame for future comparision\nfinal_data = data_all\nfinal_data = final_data.reset_index()\nfinal_data = final_data.rename(columns={'Weighted_Price_Prediction': 'lstm'})\nfinal_data = final_data[['Timestamp','Weighted_Price','lstm']]","9a0351cd":"_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(15, 5))","7c0ff242":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='08-01-2018', upper='09-01-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('August 2018 Forecast vs Actuals')","1c46eb15":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='08-01-2018', upper='08-08-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('First Week of August 2018 Forecast vs Actuals')","d5e78b9c":"#calculate MSE and MAE\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nmean_squared_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test['Weighted_Price_Prediction'])","b289b6c2":"mean_absolute_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test['Weighted_Price_Prediction'])","7b165df3":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nplt.style.use('fivethirtyeight')","df98c30d":"data = pd.read_csv('..\/input\/coinbaseUSD_1-min_data_2014-12-01_to_2018-11-11.csv',parse_dates=[0], date_parser=dateparse) \ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)","54a8135d":"color_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\n_ = data.plot(style='', figsize=(15,5), color=color_pal[0], title='BTC Weighted_Price Price (USD) by Hours')","66a5519e":"split_date = '25-Jun-2018'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()","6e552c79":"_ = data_test \\\n    .rename(columns={'Weighted_Price': 'Test Set'}) \\\n    .join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer') \\\n    .plot(figsize=(15,5), title='BTC Weighted_Price Price (USD) by Hours', style='')","b28c4a6f":"def create_features(df, label=None):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X","330b3d76":"X_train, y_train = create_features(data_train, label='Weighted_Price')\nX_test, y_test = create_features(data_test, label='Weighted_Price')","c2086a73":"import xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nmodel =  xgb.XGBRegressor(objective ='reg:linear',min_child_weight=10, booster='gbtree', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 100)\nmodel.fit(X_train, y_train,\n        eval_set=[(X_train, y_train), (X_test, y_test)],\n        early_stopping_rounds=50,\n       verbose=False) # Change verbose to True if you want to see it train","c98db08d":"data_test['Weighted_Price_Prediction'] = model.predict(X_test)\ndata_all = pd.concat([data_test, data_train], sort=False)","0cc478cc":"#adding to final data for comparision\nfinal_data = pd.merge(final_data, data_all, sort=False)\nfinal_data = final_data.rename(columns={'Weighted_Price_Prediction': 'xgboost'})\nfinal_data = final_data[['Timestamp','Weighted_Price','lstm','xgboost']]","93dbf8c6":"_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(15, 5))","c3ffea43":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='08-01-2018', upper='09-01-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('August 2018 Forecast vs Actuals')","5bf7f79c":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='08-01-2018', upper='08-08-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('First Week of August 2018 Forecast vs Actuals')","3f42cc99":"mean_squared_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test['Weighted_Price_Prediction'])","e7108aa7":"mean_absolute_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test['Weighted_Price_Prediction'])","67a8c5d2":"data = pd.read_csv('..\/input\/coinbaseUSD_1-min_data_2014-12-01_to_2018-11-11.csv',parse_dates=[0], date_parser=dateparse) \ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)","6cd8c9ab":"color_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\n_ = data.plot(style='', figsize=(15,5), color=color_pal[0], title='BTC Weighted_Price Price (USD) by Hours')","749a2148":"split_date = '25-Jun-2018'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()","39c33754":"_ = data_test \\\n    .rename(columns={'Weighted_Price': 'Test Set'}) \\\n    .join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer') \\\n    .plot(figsize=(15,5), title='BTC Weighted_Price Price (USD) by Hours', style='')","f2c68bf1":"data_train = data_train.reset_index().rename(columns={'Timestamp':'ds', 'Weighted_Price':'y'})","f561112e":"# Setup and train model\nmodel = Prophet()\nmodel.fit(data_train)","4d30f660":"# Predict on training set with model\ndata_test_fcst = model.predict(df=data_test.reset_index().rename(columns={'Timestamp':'ds'}))","a634f155":"# Plot the forecast\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nfig = model.plot(data_test_fcst, ax=ax)","6df10921":"# Plot the components\nfig = model.plot_components(data_test_fcst)","7722bbf1":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(data_test.index, data_test['Weighted_Price'], color='r')\nfig = model.plot(data_test_fcst, ax=ax)","1e9c86af":"#for comparision of predictions\ndata_fcst = data_test_fcst\ndata_fcst = data_fcst.rename(columns={'ds': 'Timestamp'})\ndata_all = pd.concat([data_fcst, data_train], sort=False)\nfinal_data = pd.merge(final_data, data_all, sort=False)\nfinal_data = final_data.rename(columns={'yhat': 'prophet'})\nfinal_data = final_data[['Timestamp','Weighted_Price','lstm','xgboost','prophet']]","55710e3e":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(data_test.index, data_test['Weighted_Price'], color='r')\nfig = model.plot(data_test_fcst, ax=ax)\nax.set_xbound(lower='08-01-2018', upper='09-01-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('August 2018 Forecast vs Actuals')","562ad259":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(data_test.index, data_test['Weighted_Price'], color='r')\nfig = model.plot(data_test_fcst, ax=ax)\nax.set_xbound(lower='08-01-2018', upper='08-08-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('First Week of August 2018 Forecast vs Actuals')","46968866":"mean_squared_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test_fcst['yhat'])","36649da7":"mean_absolute_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test_fcst['yhat'])","544ac17b":"# Create traces\ntrace0 = go.Scatter(\n    x = final_data['Timestamp'],\n    y = final_data['Weighted_Price'],\n    mode = 'lines+markers',\n    name = 'Real Price'\n)\ntrace1 = go.Scatter(\n    x = final_data['Timestamp'],\n    y = final_data['lstm'],\n    mode = 'lines+markers',\n    name = 'LSTM Prediction'\n)\ntrace2 = go.Scatter(\n    x = final_data['Timestamp'],\n    y = final_data['xgboost'],\n    mode = 'lines+markers',\n    name = 'XGBoost Prediction'\n)\ntrace3 = go.Scatter(\n    x = final_data['Timestamp'],\n    y = final_data['prophet'],\n    mode = 'lines+markers',\n    name = 'Prophet Prediction'\n)\n\n# Edit the layout\nlayout = dict(title = 'Comparision of LSTM,XGBoost and Prophet',\n              xaxis = dict(title = 'Month'),\n              yaxis = dict(title = 'Prices (USD)'),\n              )\n\ndata = [trace0, trace1, trace2, trace3]\nfig = dict(data=data, layout=layout)\niplot(fig, filename='styled-line')","76d685dc":"from scipy import stats\nimport statsmodels.api as sm\nimport warnings\nfrom itertools import product","dadb6d15":"data = pd.read_csv('..\/input\/coinbaseUSD_1-min_data_2014-12-01_to_2018-11-11.csv',parse_dates=[0], date_parser=dateparse) ","22573905":"data['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)\ndata['Volume_(BTC)'].fillna(method='ffill', inplace=True)\ndata['Volume_(Currency)'].fillna(method='ffill', inplace=True)","710800fe":"plt.figure(figsize=[20,8])\nplt.title('BTC Weighted_Price Price (USD) by Hours')\nplt.plot(data.Weighted_Price, '-', label='By Hours')","53ffc2a6":"data['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='M')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)","4165cb36":"plt.figure(figsize=[20,8])\nplt.title('BTC Weighted_Price Price (USD) by Months')\nplt.plot(data.Weighted_Price, '-', label='By Months')","d245f484":"decomposition = sm.tsa.seasonal_decompose(data.Weighted_Price)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nfig = plt.figure(figsize=(20,8))\n\nplt.subplot(411)\nplt.plot(data.Weighted_Price, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\n\nfig.suptitle('Decomposition of Prices Data')\nplt.show()","71b497d6":"print(\"Dickey\u2013Fuller test: p=%f\" % sm.tsa.stattools.adfuller(data.Weighted_Price)[1])","aaa09d57":"from statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom matplotlib import pyplot\npyplot.figure(figsize=(20,8))\npyplot.subplot(211)\nplot_acf(data.Weighted_Price, ax=pyplot.gca(),lags=40)\npyplot.subplot(212)\nplot_pacf(data.Weighted_Price, ax=pyplot.gca(), lags=50)\npyplot.show()","fdd224dc":"# Initial approximation of parameters\nQs = range(0, 2)\nqs = range(0, 3)\nPs = range(0, 3)\nps = range(0, 3)\nD=1\nd=1\nparameters = product(ps, qs, Ps, Qs)\nparameters_list = list(parameters)\nlen(parameters_list)\n\n# Model Selection\nresults = []\nbest_aic = float(\"inf\")\nwarnings.filterwarnings('ignore')\nfor param in parameters_list:\n    try:\n        model=sm.tsa.statespace.SARIMAX(data.Weighted_Price, order=(param[0], d, param[1]), \n                                        seasonal_order=(param[2], D, param[3], 12),enforce_stationarity=False,\n                                            enforce_invertibility=False).fit(disp=-1)\n    except ValueError:\n        #print('wrong parameters:', param)\n        continue\n    aic = model.aic\n    if aic < best_aic:\n        best_model = model\n        best_aic = aic\n        best_param = param\n    results.append([param, model.aic])","1a6b87a6":"# Best Models\nresult_table = pd.DataFrame(results)\nresult_table.columns = ['parameters', 'aic']\nprint(result_table.sort_values(by = 'aic', ascending=True).head())\nprint(best_model.summary())","214d3428":"fig = plt.figure(figsize=(20,8))\nbest_model.resid.plot()\nfig.suptitle('Residual Plot of the Best Model')\nprint(\"Dickey\u2013Fuller test:: p=%f\" % sm.tsa.stattools.adfuller(best_model.resid)[1])","07dfa85f":"df_month2 = data[['Weighted_Price']]\nfuture = pd.DataFrame()\ndf_month2 = pd.concat([df_month2, future])\ndf_month2['forecast'] = best_model.predict(start=0, end=200)\nplt.figure(figsize=(15,7))\ndf_month2.Weighted_Price.plot()\ndf_month2.forecast.plot(color='r', ls='--', label='Predicted Weighted_Price')\nplt.legend()\nplt.title('Bitcoin Prices (USD) Predicted vs Actuals, by months')\nplt.ylabel('mean USD')\nplt.show()","ebde75d9":"# from scipy import stats\n# import statsmodels.api as sm\n# import warnings\n# from itertools import product","4ffb04d4":"# data = pd.read_csv('..\/input\/coinbaseUSD_1-min_data_2014-12-01_to_2018-11-11.csv',parse_dates=[0], date_parser=dateparse) \n# data.head()","7e6f09b5":"# data['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\n# data = data.groupby([pd.Grouper(key='Timestamp', freq='M')]).first().reset_index()\n# data = data.set_index('Timestamp')\n# data['Weighted_Price'].fillna(method='ffill', inplace=True)","97b68762":"# plt.figure(figsize=[20,8])\n# plt.title('BTC Weighted_Price Price (USD) by Months')\n# plt.plot(data.Weighted_Price, '-', label='By Months')","1d1016b9":"We will use a Vanilla LSTM here for forecasting. The model is trained on pre 25-Jun-2018 data.","2ff00cd4":"**Time Series forecasting with XGBoost**\n\nXGBoost is an implementation of gradient boosted decision trees designed for speed and performance. XGBoost is a powerful and versatile tool. Lets see, How well does XGBoost perform when used to predict future values of a time-series like Bitcoin prices ? \n\nRead more about [XGBoost here.](https:\/\/machinelearningmastery.com\/gentle-introduction-xgboost-applied-machine-learning\/)","e2e3e1ae":"**Time Series forecasting with Prophet**\n\nProphet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well. Refer [Prophet here.](https:\/\/facebook.github.io\/prophet\/)\n\nThe Prophet package provides intuitive parameters which are easy to tune. Even someone with minimum expertise in forecasting models can use this to make meaningful predictions for a variety of problems in a business scenario.\n\n\n\n","9aadbaa3":"The MSE is 3654149.48 and MAE is 1678.49","2644dcdf":"**Time Series forecasting using ARIMA**\n\nARIMA is an acronym that stands for AutoRegressive Integrated Moving Average. It is a class of model that captures a suite of different standard temporal structures in time series data.\nThis acronym is descriptive, capturing the key aspects of the model itself. Briefly, they are:\n* AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n* I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n* MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n\nARIMA is one of the mostly used techniques for Time Series analysis. In Python,  ARIMA based forecasting models can be created either using AutoARIMA[(Pyramid ARIMA)](https:\/\/pypi.org\/project\/pyramid-arima\/) or [StatsModel ](https:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.tsa.arima_model.ARIMA.html). Here we will be using StatsModel as Kaggle do not support Pyramid ARIMA till now.","c230c8db":"The MSE is 2917.40 and MAE is 53.84","64a9f632":"Here's the Statespace ARIMA Model, the best model is selected using different parameters.","b6badd6a":"Some nice reads for further knowledge in Time Series Forecasting :-\n\n1. https:\/\/medium.com\/@josemarcialportilla\/using-python-and-auto-arima-to-forecast-seasonal-time-series-90877adff03c\n1. https:\/\/www.analyticsvidhya.com\/blog\/2016\/02\/time-series-forecasting-codes-python\/\n1. https:\/\/towardsdatascience.com\/an-end-to-end-project-on-time-series-analysis-and-forecasting-with-python-4835e6bf050b\n1. https:\/\/machinelearningmastery.com\/arima-for-time-series-forecasting-with-python\/\n1. https:\/\/machinelearningmastery.com\/time-series-prediction-lstm-recurrent-neural-networks-python-keras\/\n1. https:\/\/towardsdatascience.com\/using-lstms-to-forecast-time-series-4ab688386b1f\n1. https:\/\/mlwhiz.com\/blog\/2017\/12\/26\/How_to_win_a_data_science_competition\/\n1. https:\/\/www.analyticsvidhya.com\/blog\/2018\/05\/generate-accurate-forecasts-facebook-prophet-python-r\/\n","40cb05bb":"Little preprocessing required, replacing the NaN values with zeroes and previous data.","fade1252":"Creating Weekly Rows for the Data Visualization","2031a976":"Here we use a basic XGBRegressor model,","15b86bed":"We can clearly see the entire model is over-fitted. ","895a3d7e":"Lets visualize Historical Bitcoin Market Volume (2015-2018)","aab630ee":"**History of Bitcoin Prices**\n\n*  18 August 2008, the domain name bitcoin.org was registered.\n*  November 6th 2010, Bitcoin share capital reaches 1 million USD. Its exchange rate on MtGox reaches USD 0.50 per BTC.\n*  June 2nd 2011, USD to BTC rate is 10 USD to the coin. For 6 days, the Bitcoin value is fixed at 31.91 USD on MtGox.\n*  February 28th 2013, Bitcoin exchange rate surpasses 31.91 USD for the first time for the last 601 days.\n*  April 1st,2013 Exchange rate of Bitcoin reaches 100 USD to 1 BTC.\n*  January,2015 Coinbase raised 75 million USD as part of a Series C funding round, smashing the previous record for a bitcoin company.\n*  February ,2015 Bitcoin price reached USD 262.\n*  January 2017,After the rally for most of the second half of 2016, bitcoin broke the USD 1,000 mark for the first time in 3 years. \n*  June 12th 2017, Bitcoin exchange rate exceeds USD 3000 to the BTC.\n*  November 29th 2017, Bitcoin price exceeds USD 10,000.\n*  December 18th 2017, Bitcoin reaches a record high, but does not reach USD 20,000.\n*  December 28th 2017, The price of bitcoins fell after South Korea announced additional measures to regulate bitcoin trading, including the potential closure of exchanges, among the volatile movements in the world's third largest cryptocurrency market.\n* October 31st 2018, USD 6,300, on the 10 year anniversary of Bitcoin, price holds steady above USD 6,000 during a period of historically low volatility.\n\n![](https:\/\/en.bitcoinwiki.org\/upload\/en\/images\/c\/cf\/Bitcoin_history_price.jpg)","6c992164":"**Data Exploration**\n\nIn this section we just explore the Data i.e the Historic Bitcoin Prices and try to find some insights. We will be using the Coinbase dataset as it is one of the mostly used Bitcoin Exchange\/Wallet in the world.","8292c7ae":"The MSE is 484476.69 and MAE is 474.81","df9a966b":"Decomposition","154ff3db":"We can see how the above models perform with Historic Bitcoin Price data.  The prediction is not good. The Bitcoin prices are very volatile and very random, and is often influenced by external factors (or news) such as Cryptocurrency regulations, Investments or simple rumours on social media. We need additional data from news or social media to make these models perform better and more accurately. \n\nNote : Will add GARCH in the next version. ","dc50dad4":"In previous sections of LSTM,XGBoost and Prophet, we used hourly data to train the model. But here we will use the monthly data (for Seasonality).","3fdf458c":"Lets visualize Historical Bitcoin Prices (2015-2018)","1c3f9d00":"**LSTM , XGBoost and Prophet - How good are they ?**\n\nHere lets visualize and compare the predictive results of LSTM, XGBoost and Prophet in a single plot,","479a4a30":"**Time Series Forecasting**\n\nTime Series data is an experimental data which has been observed at different points in time (usually evenly spaced, like once a day or once an hour or once a minute). For example, the data of airline ticket sales per day is a time series. However, just because a series of events has a time element does not automatically make it a time series, such as the dates of major airline disasters, which are randomly spaced and are not time series. These types of random processes are known as point process.\n\nTime Series have several key features such as trend, seasonality, and noise.Forecasting is the process of making predictions of the future, based on past and present data. \n\nHere in this kernel, we attempt to perform Time Series Analysis on the Historic Bitcoin Price data. We can easily see from the **Data Exploration** section, that the Bitcoin prices were quite volatile and inconsistent over the years.  Its very hard to perform Time series analysis on such volatile data. But here we try to explore the different Time series forecasting models. All the models used in this Kernel are very basic, there is scope of more complex and better performing models.  \n\n*  Time Series forecasting with LSTM\n* Time Series forecasting with XGBoost\n* Time Series forecasting with Facebook Prophet\n* Time Series forecasting with ARIMA\n\n","a510d07e":"For the train and test, we take '25-Jun-2018' as the split date.  There was a considerable dip in Bitcoin prices between the June-July period 2018.  If we check the historical prices the seasonal market started going up from this date after reaching the lowest, though the price reached much lower $5972 on June 29th 2018. After reaching the historic 20K mark on December 18th, there were several dips and market price was recorrected every time. Read more about [Bitcoin dips.](http:\/\/https:\/\/news.bitcoin.com\/data-reveals-reasons-behind-bitcoins-big-dip\/)","f7ff864a":"**Bitcoin Time Series Forecasting**\n\nBitcoin is the longest running and most well known cryptocurrency, first released as open source in 2009 by the anonymous Satoshi Nakamoto. Bitcoin serves as a decentralized medium of digital exchange, with transactions verified and recorded in a public distributed ledger (the blockchain) without the need for a trusted record keeping authority or central intermediary. Transaction blocks contain a SHA-256 cryptographic hash of previous transaction blocks, and are thus \"chained\" together, serving as an immutable record of all transactions that have ever occurred. As with any currency\/commodity on the market, bitcoin trading and financial instruments soon followed public adoption of bitcoin and continue to grow.  If you don't know what Bitcoin is , then get some knowledge about Bitcoin [here](https:\/\/www.coindesk.com\/information\/what-is-bitcoin) .\n\nThis Kernel is divided into two parts:-\n\n* Data Exploration\n* Time Series Analysis\n\nAnd further for the **Time Series Forecasting:**-\n\n*  Time Series forecasting with **LSTM**\n* Time Series forecasting with **XGBoost**\n* Time Series forecasting with Facebook **Prophet**\n* Time Series forecasting with **ARIMA**\n\nThis kernel takes inspiration from the following kernels,\n* [Time Series forecasting with Prophet by Rob Mulla](https:\/\/www.kaggle.com\/robikscube\/tutorial-time-series-forecasting-with-prophet)\n* [Time Series forecasting with XGBoost by Rob Mulla ](https:\/\/www.kaggle.com\/robikscube\/tutorial-time-series-forecasting-with-xgboost)\n* [Bitcoin Price. Prediction by ARIMA by \u0410\u0440\u0442\u0451\u043c](https:\/\/www.kaggle.com\/myonin\/bitcoin-price-prediction-by-arima)","ecb42376":"**Predicting using LSTM**\n\nIn the first section, we use LSTM  (Long short-term memory ). LSTM units are units of a recurrent neural network (RNN). An RNN composed of LSTM units is often called an LSTM network (or just LSTM). A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell. Read more about LSTMs [here.](https:\/\/towardsdatascience.com\/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)\n\nThough LSTM is not ideal for forecasting turbulent market like Bitcoin but we still take a chance here."}}