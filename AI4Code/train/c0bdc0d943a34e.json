{"cell_type":{"0e9f3539":"code","fd01b0ba":"code","abd6fbe7":"code","6d35366c":"code","09d2e189":"code","4a19881c":"code","36e7dabe":"code","0968c578":"code","066ffe88":"code","6935bf6f":"code","3919ab66":"code","f4dd2d76":"code","96648964":"code","ffdc6eb4":"code","8dbb5063":"code","407f1db8":"code","bf9b989e":"code","5dc7d8dd":"code","15c161af":"code","b88e907f":"code","e3fbd5e8":"code","d1ab4a2f":"code","45063e0f":"code","39c1d923":"code","63e9ea6e":"code","c122dedb":"code","3c29cba5":"code","b1ec0cd4":"code","5cc3cee5":"code","a221785d":"code","fe15abf7":"code","0cf647f5":"code","13e38ac0":"code","fe117a41":"code","5886a2f7":"code","c4e5dfb8":"code","f2d9a438":"code","085ccf02":"code","9f81c829":"code","19db08cb":"code","824db346":"code","f839d497":"code","3be6f204":"code","c88e2956":"code","14586018":"code","743ab2f8":"code","111f2341":"code","170519f4":"code","9c27f655":"code","1dff9188":"code","47543cd1":"code","f3280858":"code","507b0674":"code","0d3a6779":"code","39511341":"code","e20650f4":"code","a5bd4bfd":"code","a2fee5e1":"code","f9ead7d4":"code","c9a9f01c":"code","e0310c08":"code","d4a01501":"code","56fd0fc6":"code","c67acd8d":"code","ee1721f3":"code","41c7e8a7":"markdown","587f7b01":"markdown","c7623558":"markdown","70d6227d":"markdown","bb320bf1":"markdown","d210ae4f":"markdown","6c17048c":"markdown","4d7e9aa4":"markdown","22927477":"markdown","161d8c0d":"markdown","28f30b0c":"markdown","abc253ff":"markdown","9bd757a4":"markdown","6ece6598":"markdown","e99325cc":"markdown","d7c3b3ef":"markdown","50dd9fef":"markdown","db0f0c68":"markdown","3b0ad0de":"markdown","921468c4":"markdown","ee74c317":"markdown","c87694a7":"markdown","261bdbce":"markdown","80786a9a":"markdown","fd06e6b2":"markdown","0e61d54a":"markdown","56a9b4dd":"markdown","faa398cc":"markdown","a05ebea5":"markdown","32084862":"markdown","960b0c6d":"markdown"},"source":{"0e9f3539":"import pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport pandas_profiling\nfrom sklearn.preprocessing import StandardScaler\nfrom pandas.plotting import scatter_matrix\n%matplotlib inline\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve,KFold\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve,auc\nfrom mlxtend.classifier import StackingCVClassifier\nfrom scipy import stats\nfrom sklearn.preprocessing import MinMaxScaler","fd01b0ba":"pd.set_option('display.max_columns', 500)\ndata=pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndata","abd6fbe7":"print (\"DATA SHAPES : \",data.shape)\ndata.info()","6d35366c":"data['TotalCharges'] = pd.to_numeric(data['TotalCharges'],errors='coerce')","09d2e189":"data.isnull().sum()","4a19881c":"def uni_col_val(df):\n    for column in df:\n        if df[column].dtype == 'object':\n            print(f'{column} : {df[column].unique()}')","36e7dabe":"uni_col_val(data)","0968c578":"data.describe()","066ffe88":"data['Churn'].hist()\n#Not BaLANCED DATASET","6935bf6f":"scatter_matrix(data,alpha=0.2, figsize=(10, 10))","3919ab66":"fig, axes = plt.subplots(nrows = 3,ncols = 4,figsize = (35,25))\nsns.countplot(x=\"gender\", hue=\"Churn\", data=data, ax=axes[0][0] )\nsns.countplot(x=\"SeniorCitizen\", hue=\"Churn\", data=data,ax=axes[0][1] )\nsns.countplot(x=\"Partner\", hue=\"Churn\", data=data,ax=axes[0][2] ) \nsns.countplot(x=\"PhoneService\", hue=\"Churn\", data=data,ax=axes[0][3] )\n\nsns.countplot(x=\"InternetService\", hue=\"Churn\", data=data, ax=axes[1][0] )\nsns.countplot(x=\"OnlineSecurity\", hue=\"Churn\", data=data,ax=axes[1][1] )\nsns.countplot(x=\"Contract\", hue=\"Churn\", data=data,ax=axes[1][2] ) \nsns.countplot(x=\"OnlineBackup\", hue=\"Churn\", data=data,ax=axes[1][3] )\n\n\nsns.countplot(x=\"TechSupport\", hue=\"Churn\", data=data, ax=axes[2][0] )\nsns.countplot(x=\"PaymentMethod\", hue=\"Churn\", data=data,ax=axes[2][1] )\nsns.countplot(x=\"StreamingTV\", hue=\"Churn\", data=data,ax=axes[2][2] ) \nsns.countplot(x=\"StreamingMovies\", hue=\"Churn\", data=data,ax=axes[2][3] )","f4dd2d76":"data.info()","96648964":"categorical_features=['gender','Partner','Dependents','PhoneService',  \n                        'MultipleLines' ,'InternetService','OnlineSecurity','OnlineBackup',\n                        'DeviceProtection','TechSupport', 'StreamingTV' ,'StreamingMovies' ,\n                        'Contract','PaperlessBilling','PaymentMethod']\n","ffdc6eb4":"\nstatistical_significance=[]\nfor attr in categorical_features:\n    data_count=pd.crosstab(data[attr],data[\"Churn\"])\n    #print(data_count)\n    obs=data_count.values\n    #print(obs)\n    chi2, p, dof, expected = stats.chi2_contingency(obs)\n    statistical_significance.append([attr,round(p,4)])\nstatistical_significance=pd.DataFrame(statistical_significance)\nstatistical_significance.columns=[\"Attribute\",\"P-value\"]\ndisplay(statistical_significance)","8dbb5063":"data=data.drop(['gender','PhoneService'],axis=1)","407f1db8":"\ndata.Churn=data.Churn.replace('Yes','1')\ndata.Churn=data.Churn.replace('No','0')\nprint('churn :\\n',data.Churn.value_counts())\ndata['Partner'] = data['Partner'].map(lambda s :1  if s =='Yes' else 0)\nprint('Partner : \\n ',data['Partner'].value_counts())\n\ndata['Dependents'] = data['Dependents'].map(lambda s :1  if s =='Yes' else 0) \nprint('Dependents :\\n',data.Dependents.value_counts())\n\ndata['PaperlessBilling'] = data['PaperlessBilling'].map(lambda s :1  if s =='Yes' else 0) \nprint('PaperlessBilling :\\n',data.PaperlessBilling.value_counts())\n\n#data['PhoneService'] = data['PhoneService'].map(lambda s :1  if s =='Yes' else 0)\n#print('PhoneService :\\n',data.PhoneService.value_counts())\n\n\ndata['MultipleLines'] = data['MultipleLines'].map(lambda s :1  if s =='Yes' else 0)\nprint('MultipleLines :\\n',data.MultipleLines.value_counts())\n\ndata['OnlineBackup'] = data['OnlineBackup'].map(lambda s :1  if s =='Yes' else 0)\nprint('Online Backup :\\n',data.OnlineBackup.value_counts())\n\n\ndata['OnlineSecurity'] = data['OnlineSecurity'].map(lambda s :1  if s =='Yes' else 0)\nprint('Online Security :\\n',data.OnlineSecurity.value_counts())\n\n\ndata['DeviceProtection'] = data['DeviceProtection'].map(lambda s :1  if s =='Yes' else 0)\nprint('DeviceProtection :\\n',data.DeviceProtection.value_counts())\n\ndata['TechSupport'] = data['TechSupport'].map(lambda s :1  if s =='Yes' else 0)\nprint('Tech Support :\\n',data.TechSupport.value_counts())\n\n\ndata['StreamingTV'] = data['StreamingTV'].map(lambda s :1  if s =='Yes' else 0)\nprint('StreamingTV  :\\n',data.StreamingTV.value_counts())\n\ndata['StreamingMovies'] = data['StreamingMovies'].map(lambda s :1  if s =='Yes' else 0)\nprint('StreamingMovies  :\\n',data.StreamingMovies.value_counts())","bf9b989e":"data.head()","5dc7d8dd":"data.info()","15c161af":"data_dummied = pd.get_dummies(data,columns=['PaymentMethod','Contract','InternetService'])","b88e907f":"data_dummied['TotalCharges']=data_dummied['TotalCharges'].fillna(data_dummied['TotalCharges'].mean())","e3fbd5e8":"\n\nmin_max_scaler = MinMaxScaler()\nnumeric_columns=['tenure','MonthlyCharges','TotalCharges']\ndata_dummied[numeric_columns]=min_max_scaler.fit_transform(data_dummied[numeric_columns])","d1ab4a2f":"data_dummied.info()","45063e0f":"data_dummied","39c1d923":"data_dummied=data_dummied.drop('customerID',axis=1)","63e9ea6e":"Y=data_dummied['Churn']\nX=data_dummied.drop(['Churn'],axis=1)","c122dedb":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n         X, Y, test_size=0.10, random_state=5,shuffle=True,stratify=Y)\n","3c29cba5":"y_train.hist()","b1ec0cd4":"y_test.hist()","5cc3cee5":"fig,axe = plt.subplots(figsize = (20,20))\nsns.heatmap(X_train.corr(method='spearman'),annot=True,ax=axe)","a221785d":"y_test=y_test.astype(str).astype(int)\ny_train=y_train.astype(str).astype(int)\n","fe15abf7":"#kfold = StratifiedKFold(n_splits=10)\n#kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\nkfold=StratifiedKFold(n_splits=5,shuffle=True)","0cf647f5":"from sklearn.utils import class_weight","13e38ac0":"class_weight=int(y_train.value_counts()[0]\/y_train.value_counts()[1])\nclass_weight","fe117a41":"from sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(y_train),\n                                                 y_train)","5886a2f7":"random_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state,class_weight=dict(enumerate(class_weights))))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state,class_weight=dict(enumerate(class_weights))))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state,class_weight=dict(enumerate(class_weights))),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state,class_weight=dict(enumerate(class_weights))))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state,class_weight=dict(enumerate(class_weights))))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(xgboost.XGBClassifier(random_state=random_state,class_weight=class_weights))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state,class_weight=class_weights))\n","c4e5dfb8":"cv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"roc_auc\", cv =kfold , n_jobs=-1))","f2d9a438":"cv_means = []\ncv_std   = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"Xgboost\",\"KNeighboors\",\"LogisticRegression\"]})\nprint(cv_res)\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","085ccf02":"def evaluation(model,x_test,y_test):\n    \n\n    print(\"Test AUC:\",roc_auc_score(y_test, model.predict_proba(x_test)[:,1]))\n    print('Train AU  :',roc_auc_score(y_train, model.predict_proba(X_train)[:,1]))\n    #print(roc_auc_score(y_test, y_pred))\n    axe.set_xlabel('Actual')\n    axe.set_ylabel('Predicted')\n    \n    ","9f81c829":"GBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n                 \n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              \n              }\ngsGBC=RandomizedSearchCV(estimator=GBC,param_distributions=gb_param_grid,random_state=3,scoring = \"roc_auc\", \n                                     cv =kfold,n_jobs=1)\n \n\ngsGBC.fit(X_train,y_train)","19db08cb":"GBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","824db346":"evaluation(GBC_best ,X_test,y_test)","f839d497":"RFC = RandomForestClassifier(class_weight=dict(enumerate(class_weights)))\n#class_weight_dict = )\n#\n## Search grid for optimal parameters\nrf_param_grid = {\"max_depth\": [None],\n              \n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"roc_auc\", n_jobs= -1, verbose = 1)\n\ngsRFC.fit(X_train,y_train)\n\n\n","3be6f204":"RFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_","c88e2956":"evaluation(RFC_best,X_test,y_test)","14586018":"SVMC = SVC(probability=True,class_weight=dict(enumerate(class_weights)))\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 100,200]}\n\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"roc_auc\", n_jobs= -1, verbose = 1)\n\ngsSVMC.fit(X_train,y_train)","743ab2f8":"SVMC_best = gsSVMC.best_estimator_\n\n# Best score\ngsSVMC.best_score_","111f2341":"evaluation(gsSVMC,X_test,y_test)","170519f4":"class_weight=int(y_train.value_counts()[0]\/y_train.value_counts()[1])","9c27f655":"XGBoost=xgboost.XGBClassifier(scale_pos_weight=class_weight)\nxgboost_param_grid={\n    'learning_rate':[0.05,0.1,0.15,0.2,0.25,0.3],\n    'max_depth'    :[1,2,3,4,5,6,7,8,9,10],\n    'min_child_weight':[1,3,5,7],\n    'colsample_bytree':[0.3,0.4,0.5,0.6,0.7],\n    'gamma':[0.0,0.1,0.2,0.3,0.4,0.5]\n}\ngsXGoost=RandomizedSearchCV(estimator=XGBoost,param_distributions=xgboost_param_grid,random_state=3,scoring = \"roc_auc\", \n                                     cv =kfold,n_jobs=1)\n\n\ngsXGoost.fit(X_train,y_train)","1dff9188":"XGBOOST_best = gsXGoost.best_estimator_\n\n# Best score\ngsXGoost.best_score_","47543cd1":"evaluation(XGBOOST_best,X_test,y_test)","f3280858":"logreg = LogisticRegression(class_weight=dict(enumerate(class_weights)))\nlogreg_param_grid={\n    'C':[100, 10, 1.0, 0.1, 0.01] ,\n    'penalty':['l2']\n}\ngslogreg=GridSearchCV(logreg,param_grid = logreg_param_grid, cv=kfold, scoring=\"roc_auc\", n_jobs= -1, verbose = 1)\ngslogreg.fit(X_train,y_train)","507b0674":"LogReg_best = gslogreg.best_estimator_\n\n# Best score\ngslogreg.best_score_","0d3a6779":"evaluation(LogReg_best,X_test,y_test)","39511341":"votingC = VotingClassifier(estimators=[('gbc',GBC_best), ('rfc', RFC_best),\n('xgboost',XGBOOST_best),('logreg',LogReg_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, y_train)","e20650f4":"evaluation(votingC,X_test,y_test)","a5bd4bfd":"scv=StackingCVClassifier(classifiers=[GBC_best,RFC_best,XGBOOST_best,LogReg_best],meta_classifier= XGBOOST_best,random_state=42)","a2fee5e1":"scv2=StackingCVClassifier(classifiers=[GBC_best,RFC_best,XGBOOST_best,LogReg_best],meta_classifier= RFC_best,random_state=42)","f9ead7d4":"scv3=StackingCVClassifier(classifiers=[RFC_best,XGBOOST_best,LogReg_best,SVMC_best],meta_classifier= RFC_best,random_state=42)","c9a9f01c":"scv.fit(X_train,y_train)\nevaluation(scv,X_test,y_test)","e0310c08":"scv3.fit(X_train,y_train)\nevaluation(scv3,X_test,y_test)","d4a01501":"scv2.fit(X_train,y_train)\nevaluation(scv2,X_test,y_test)","56fd0fc6":"scv4=StackingCVClassifier(cv=2,classifiers=[RFC_best,SVMC_best,XGBOOST_best,LogReg_best],meta_classifier= GBC_best,random_state=42)","c67acd8d":"scv4.fit(X_train,y_train)\nevaluation(scv4,X_test,y_test)","ee1721f3":"import pickle\npickle.dump(votingC, open(\"best_model_Votingg\", 'wb'))","41c7e8a7":"###Encoding","587f7b01":"# **8. Cross Validation**","c7623558":"# **1. Import Libraries and Dataset**\n","70d6227d":"**Steps**:\n\n\n1.   Import Libraries and Dataset\n2.   Getting to know the dataset\n3.   EDA\n4.   Feature Selection (using statistic test)\n5.   Preprocessing\n6.   Train\/Test split \n7.   Correlation Matrix \n8.   Cross Validation\n9.   Modeling  \n    9.1. Test Different algorithms and Pick the 5 best ones\n    \n    9.2. Evaluation Function\n\n    9.3. Hyperparameter Tuning \n\n    9.4. Trying the voting ensemble method and see the results\n\n    9.5. Trying The stacking ensembling method on different combinaisons\n\n  \n\n10. Final decision and save the best model \n\n\n\n\n\n\n\n\n\n\n","bb320bf1":"# **4. Feature Selection (using statistic test)**","d210ae4f":"### LogisticRegression","6c17048c":"# **5. Processing**","4d7e9aa4":"# **6. Train\/Test split**","22927477":"## **9.1 Test Different algorithms and Pick the 5 best ones** ","161d8c0d":"# **7. Correlation Matrix**","28f30b0c":"# In this kernel, we focused on using 2 types of ensemble methods **VOTING** and **STACKING** and chose the best one with the best **AUC score** ","abc253ff":"### XGBOOST","9bd757a4":"## **9.3. Hyperparameter tuning**","6ece6598":"### RandomForrest","e99325cc":"###Change the type of the feature ToTalCharges from Object to Float","d7c3b3ef":"## **9.5.Trying The stacking ensembling method on different combinaisons**","50dd9fef":"###Changing the target type from str to int","db0f0c68":"## **9.4. Trying the voting ensemble method and see the results**","3b0ad0de":"###Seeing the Different unique outputs of the categorical features","921468c4":"# **10. Final decision and save the best model** ","ee74c317":"###Statistical Test to determine whether input features are relevant to the outcome to be predicted.\n\n###P-value <= 0.05 significant result\n###P-value > 0.05 not significant result","c87694a7":"###Normalization","261bdbce":"# **2. Getting to know the dataset**","80786a9a":"# GradientBoosting","fd06e6b2":"# **3. EDA**","0e61d54a":"### SVM","56a9b4dd":"## **9.2 Evaluation Function**","faa398cc":"#**9 Modeling**","a05ebea5":"###We drop the non siginificant features (P-value>0.05)","32084862":"###WE decided to pick the model generated by the voting method and save it","960b0c6d":"###Seeing that the feature TotalCharges has 11 missed values "}}