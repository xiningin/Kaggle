{"cell_type":{"2609ced0":"code","e861c1ad":"code","cd39f247":"code","23cd386f":"code","69cda800":"code","92ab0549":"code","413ad205":"code","fd5188e4":"code","018c5789":"code","69bf0881":"code","799f9aea":"code","08d51415":"code","621d957b":"code","74d15b90":"code","272d42b8":"code","a477c6ba":"code","9aa28701":"code","ba149e44":"code","e7fcc834":"code","0424e98b":"code","eb95538d":"code","41eb064a":"code","ccaf5c4d":"code","57d53313":"code","abd23dcd":"code","cff8d5fe":"code","e3891303":"code","c369d416":"code","b656d3e5":"code","90695bf0":"code","263812a9":"code","7bb254ea":"code","c3287769":"code","3a69c501":"code","1b8fab19":"code","81d6fe32":"code","1916811e":"markdown"},"source":{"2609ced0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e861c1ad":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use(\"fivethirtyeight\")\n%matplotlib inline\n\n# For reading stock data from yahoo\nfrom pandas_datareader.data import DataReader\n\n# For time stamps\nfrom datetime import datetime\n# Set up End and Start times for data grab\nend = datetime.now()\nstart = datetime(end.year - 1, end.month, end.day)","cd39f247":"df= pd.read_csv(\"..\/input\/coca-cola-stock-live-and-updated\/Coca-Cola_stock_history.csv\")\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.shape","23cd386f":"import matplotlib.pyplot as plt\nimport pandas_datareader as web\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn')\n\nfrom tensorflow import keras\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n%matplotlib inline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nimport math\nfrom keras.models import Sequential # Create Model\nfrom keras.layers import Dense # Neurons\nfrom keras.layers import LSTM # Long Short Term Memory\nfrom sklearn.preprocessing import MinMaxScaler # Normalize\nfrom sklearn.metrics import mean_squared_error # Loss Function\nfrom sklearn.model_selection import train_test_split","69cda800":"df.set_index('Date',inplace=True)\ndf.head()","92ab0549":"scale = MinMaxScaler()\nscalled = scale.fit_transform(df)\ni = 0\nfor col in df.columns:\n    df[col] = scalled[:,i]\n    i += 1","413ad205":"df.describe()","fd5188e4":"x, y = df.drop('Stock Splits', axis=1), df['Stock Splits']","018c5789":"data = df.filter(['Close'])\ndataset = data.values #convert the data frame to a numpy array\ntraining_data_len = math.ceil(len(dataset)*.8)  # number of rows to train the model on\ntraining_data_len","69bf0881":"#scale the data\nscaler = MinMaxScaler(feature_range=(0,1))\nscaled_data = scaler.fit_transform(dataset)\nscaled_data\n\ntrain_data = scaled_data[0:training_data_len, :]\n#Split the data into x_train, y_train datasets\nx_train = []\ny_train = []\nfor i in range(60,len(train_data)):\n    x_train.append(train_data[i-60:i, 0])\n    y_train.append(train_data[i,0])\n    if i<=60:\n        print(x_train)\n        print(y_train)\n        print()","799f9aea":"#convert the x_train and y_train  to numppy array\nx_train,y_train = np.array(x_train), np.array(y_train)\n#reshape the data\nx_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\nx_train.shape","08d51415":"#Buil the LSTM model\nmodel =Sequential()\nmodel.add(LSTM(64,return_sequences=True, input_shape=(x_train.shape[1],1)))\nmodel.add(LSTM(64, return_sequences= False))\nmodel.add(Dense(32))\nmodel.add(Dense(1))\n#Complie the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')","621d957b":"#Train the model\nmodel.fit(x_train,y_train, batch_size=1, epochs=10)","74d15b90":"test_data= scaled_data[training_data_len-60:, :]\n#create the data sets x_test and y_test\nx_test = []\ny_test = dataset[training_data_len:,:]\nfor i in range(60,len(test_data)):\n    x_test.append(test_data[i-60:i,0])","272d42b8":"x_test = np.array(x_test)\nx_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],1))\nx_test.shape","a477c6ba":"#predicting the data\npredictions = model.predict(x_test)\npredictions = scaler.inverse_transform(predictions)","9aa28701":"pd.options.mode.chained_assignment = None  # default='warn'\n#plot the data\ntrain = data[:training_data_len]\nvalid = data[training_data_len:]\nvalid['Predictions'] = predictions\n#Visialization the data\nplt.figure(figsize=(16,8))\nplt.title('Model')\nplt.xlabel('Date', fontsize=18)\nplt.ylabel('Close Price' ,fontsize=18)\nplt.plot(train['Close'],linewidth=3.5)\nplt.plot(valid[['Close','Predictions']],linewidth=3.5)\nplt.legend(['Train','Valid','Predictions'])","ba149e44":"valid","e7fcc834":"#get the quote\ncoca_quote = pd.read_csv('..\/input\/coca-cola-stock-live-and-updated\/Coca-Cola_stock_history.csv')\n#Create new data frame\nnew_df = coca_quote.filter(['Close'])\n#get the last 60 days closing price values and convert the dataframe to an array\nlast_60_days = new_df[-60:].values\n#scaled the data to be values between 0 and 1\nlast_60_days_scaled = scaler.transform(last_60_days)\n#create an empty list\nX_test = []\n#append the past 60 days \nX_test.append(last_60_days_scaled)\n#convert the X_test data set to a numpy array\nX_test = np.array(X_test)\n#Reshape the data\nX_test = np.reshape(X_test,(X_test.shape[0], X_test.shape[1],1))\n#get the predicted scaled price\npred_price= model.predict(X_test)\n#undo the scalling\npred_price = scaler.inverse_transform(pred_price)\npred_price","0424e98b":"#importing packages for the prediction of time-series data\nfrom statsmodels.tsa.arima_model import ARIMA\nimport statsmodels.api as sm\nimport statsmodels.tsa.api as smt\nimport statsmodels.formula.api as smf\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.metrics import mean_squared_error\n\n%matplotlib inline","eb95538d":"import pandas as pd\nimport numpy as np\nimport math\nimport datetime as dt\n\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\n\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \nfrom sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)","41eb064a":"df = pd.read_csv('..\/input\/coca-cola-stock-live-and-updated\/Coca-Cola_stock_history.csv', parse_dates=['Date'])\ndf1 = df[['Date','Close']]\ndf1.head(3)","ccaf5c4d":"# Setting the Date as Index\ndf_ts = df1.set_index('Date')\ndf_ts.sort_index(inplace=True)\nprint (type(df_ts))\nprint (df_ts.head(3))\nprint (\"========================\")\nprint (df_ts.tail(3))","57d53313":"# Basic plot \ndf_ts.plot()","abd23dcd":"# Dickey Fuller Test Function\ndef test_stationarity(timeseries):\n    # Perform Dickey-Fuller test:\n    from statsmodels.tsa.stattools import adfuller\n    print('Results of Dickey-Fuller Test:')\n    print (\"==============================================\")\n    \n    dftest = adfuller(timeseries, autolag='AIC')\n    \n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#lags Used', 'Number of Observations Used'])\n    \n    for key, value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    \n    print(dfoutput)\n    ","cff8d5fe":"# Convert the DF to series first\nts = df_ts['Close']","e3891303":"# Rolling Statistics\nrolmean = ts.rolling(window=12).mean()\nrolvar = ts.rolling(window=12).std()\n\nplt.plot(ts, label='Original')\nplt.plot(rolmean, label='Rolling Mean')\nplt.plot(rolvar, label='Rolling Standard Variance')\nplt.legend(loc='best')\nplt.title('Rolling Mean & Standard Deviation')\nplt.show(block=False)","c369d416":"test_stationarity(ts)","b656d3e5":"# Lets Resample the data by Month and analyze again\ndf_ts_m = df_ts.resample('M').mean()\nprint (type(df_ts_m))\nprint (df_ts_m.head(3))","90695bf0":"tsm = df_ts_m['Close']\nprint (type(tsm))","263812a9":"# Lets do a quick vanila decomposition to see any trend seasonality etc in the ts\ndecomposition = sm.tsa.seasonal_decompose(tsm, model='multiplicative')\n\nfig = decomposition.plot()\nfig.set_figwidth(12)\nfig.set_figheight(8)\nfig.suptitle('Decomposition of multiplicative time series')\nplt.show()","7bb254ea":"# lets try to make the \"tsm\" Stationary\n\ntsmlog = np.log10(tsm)\ntsmlog.dropna(inplace=True)\n\ntsmlogdiff = tsmlog.diff(periods=1)\ntsmlogdiff.dropna(inplace=True)\n# Stationarity Check\ntest_stationarity(tsmlogdiff)","c3287769":"# Let's plot ACF & PACF graphs to visualize AR & MA components\n\nfig, axes = plt.subplots(1, 2)\nfig.set_figwidth(12)\nfig.set_figheight(4)\nsmt.graphics.plot_acf(tsmlogdiff, lags=30, ax=axes[0], alpha=0.5)\nsmt.graphics.plot_pacf(tsmlogdiff, lags=30, ax=axes[1], alpha=0.5)\nplt.tight_layout()","3a69c501":"y_2019 = df.loc[(df['Date'] >= '2019-01-01')\n                     & (df['Date'] < '2020-01-01')]\nmonthvise= y_2019.groupby(y_2019['Date'].dt.strftime('%B'))[['Open','Close']].mean()\nnew_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', \n             'September', 'October', 'November', 'December']\nmonthvise = monthvise.reindex(new_order, axis=0)\nmonthvise\n","1b8fab19":"y_2019.groupby(y_2019['Date'].dt.strftime('%B'))['Low'].min()\nmonthvise_high = y_2019.groupby(df['Date'].dt.strftime('%B'))['High'].max()\nmonthvise_high = monthvise_high.reindex(new_order, axis=0)\n\nmonthvise_low = y_2019.groupby(y_2019['Date'].dt.strftime('%B'))['Low'].min()\nmonthvise_low = monthvise_low.reindex(new_order, axis=0)\n\nfig = go.Figure()\nfig.add_trace(go.Bar(\n    x=monthvise_high.index,\n    y=monthvise_high,\n    name='Stock high Price',\n    marker_color='rgb(0, 153, 204)'\n))\nfig.add_trace(go.Bar(\n    x=monthvise_low.index,\n    y=monthvise_low,\n    name='Stock low Price',\n    marker_color='rgb(255, 128, 0)'\n))\n\nfig.update_layout(barmode='group', \n                  title=' Monthwise High and Low stock price')\nfig.show()","81d6fe32":"names = cycle(['Stock Open Price','Stock Close Price','Stock High Price','Stock Low Price'])\n\nfig = px.line(y_2019, x=y_2019.Date, y=[y_2019['Open'], y_2019['Close'], \n                                          y_2019['High'], y_2019['Low']],\n             labels={'Date': 'Date','value':'Stock value'})\nfig.update_layout(title_text='Stock analysis chart', font_size=15, font_color='black',legend_title_text='Stock Parameters')\nfig.for_each_trace(lambda t:  t.update(name = next(names)))\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\n\nfig.show()","1916811e":"**Long Short Term Memory**"}}