{"cell_type":{"d80788c5":"code","44423e4c":"code","bb55e37a":"code","597dc309":"code","a9c8ae85":"code","ef6ae0a1":"code","8d8bdbe7":"code","93329fa4":"code","18f376b8":"code","a4f04bb9":"code","59219f94":"code","3209eee0":"code","525888da":"code","d495394e":"code","a392dbc7":"code","4f0813f8":"code","77eea01a":"code","6db2243c":"code","decbdfa7":"code","19e19dc4":"code","3dddc480":"code","2abe9b13":"code","10e4ea28":"code","abfc4e73":"code","50062686":"code","da87ca42":"code","32a371b0":"code","a72df70f":"code","bc62b8b1":"code","49a7e821":"code","b0a99805":"markdown","a32fead6":"markdown","ef9f274e":"markdown","84eaf5e3":"markdown","1049528c":"markdown","7ef84919":"markdown","a4f51ffd":"markdown","7187b847":"markdown","36d7e52a":"markdown","ed6b20b7":"markdown","1dc55c2f":"markdown","4333a574":"markdown","3173cdcb":"markdown","1210c695":"markdown","13c1736b":"markdown","b1796452":"markdown","231a4e37":"markdown","527e4997":"markdown","20b1a7a5":"markdown","ac943f76":"markdown","a6343ad3":"markdown","9969c62e":"markdown","5fd92d68":"markdown","ad0ca321":"markdown","d7b810eb":"markdown","03c649bb":"markdown","a4abbb6c":"markdown","cda3c9a4":"markdown","ad06a083":"markdown","c2cfe853":"markdown","3b6e9d83":"markdown"},"source":{"d80788c5":"import warnings \nwarnings.filterwarnings('ignore')","44423e4c":"import pandas as pd \nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nimport gc\nfrom datetime import datetime \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.linear_model import LogisticRegressionCV, SGDClassifier, LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom xgboost import XGBClassifier\nimport lightgbm as lgbm\n\npd.set_option('display.max_columns', 500)","bb55e37a":"data = pd.read_csv(\"..\/input\/LoanApproval.csv\")","597dc309":"data.drop('Loan_ID', axis=1, inplace= True)\ndata.head()","a9c8ae85":"print(\"Dataset contains -\",data.shape[0],\"rows and\",data.shape[1],\"columns\")","ef6ae0a1":"data.describe(include=\"all\")","8d8bdbe7":"data.isnull().sum()","93329fa4":"data.Gender[data.Gender == 'Male'] = 1\ndata.Gender[data.Gender == 'Female'] = 2","18f376b8":"dict_gender = [1,2]\ndata.Gender.fillna(np.random.choice(dict_gender), inplace=True)","a4f04bb9":"data.Married[data.Married == 'Yes'] = 1\ndata.Married[data.Married == 'No'] = 0","59219f94":"dict_married = [0,1]\ndata.Married.fillna(np.random.choice(dict_married), inplace=True)","3209eee0":"dict_dependents = [0,1,2,3]\ndata.Dependents.fillna(np.random.choice(dict_dependents), inplace=True)","525888da":"data.Self_Employed[data.Self_Employed == 'Yes'] = 1\ndata.Self_Employed[data.Self_Employed == 'No'] = 0","d495394e":"dict_self_employed = [0,1]\ndata.Self_Employed.fillna(np.random.choice(dict_self_employed), inplace=True)","a392dbc7":"data.LoanAmount.fillna(data.LoanAmount.mean(), inplace=True)","4f0813f8":"dict_loan_amount_term = [120,240,360,480]\ndata.Loan_Amount_Term.fillna(np.random.choice(dict_loan_amount_term), inplace=True)","77eea01a":"dict_credit_history = [0,1]\ndata.Credit_History.fillna(np.random.choice(dict_credit_history), inplace=True)","6db2243c":"#Now that we have treated all Missing values, there should be no NULL\/NaN values\ndata.isnull().sum()","decbdfa7":"data.describe(include=\"all\")","19e19dc4":"# We have converted datatype of 'Gender' from 'int64'->'object', for Visualization purpose\ndata.Gender=data.Gender.astype(object)\n\n# We have converted datatype of 'Married' from 'int64'->'object', for Visualization purpose\ndata.Married=data.Married.astype(object)\n\n# We have converted datatype of 'Self_Employed' from 'int64'->'object', for Visualization purpose\ndata.Self_Employed=data.Self_Employed.astype(object)\n\n# This command below will show the datatypes of all the columns\ndata.info()","3dddc480":"# Now we are creating a new DataFrame named \"obj_cols\" from the old DataFrame 'data' which will have columns with only OBJECT as its datatype\nobj_cols = [*data.select_dtypes('object').columns]\nobj_cols1 = obj_cols\nobj_cols.remove('Loan_Status')\n\n# Setting up the height & width of the plot we will make below\nplt.figure(figsize=(24, 18))\n\n# We are using a For-loop to plot 6 graphs in one plot using \"obj_cols\" as our refernce dataset\nfor idx, cols in enumerate(obj_cols):\n    \n    plt.subplot(3, 3, idx+1)\n    \n    sns.countplot(cols, data= data, hue='Loan_Status')","2abe9b13":"data.Loan_Status.replace({'Y': 0, 'N': 1}, inplace= True)\ndata['Loan_Status']= data.Loan_Status.astype(int)\ndata.info()","10e4ea28":"# Here we are creating a DataFrame named 'dummies' by using '.get_dummies' function of pandas which will convert all categorical variables to dummy variables\ndummies = pd.get_dummies(data, drop_first=True)\ndummies.info()\n\n# 'SimpleImputer()' function is used to fill missing values in a DataFrame\nSimImp = SimpleImputer()\n\n# We are now creating a new DataFrame named 'train' which will be like our original dataset named 'data' but with no missing values\ntrain= pd.DataFrame(SimImp.fit_transform(dummies), columns=dummies.columns)\ntrain.info()\n\n# We are selecting all the numerical columns and making a new DataFrame with name 'num_cols'\nnum_cols = [*data.select_dtypes(['Int64', 'Float64']).columns]\nnum_cols.remove('Loan_Amount_Term')\nnum_cols.remove('Credit_History')","abfc4e73":"# We are creating a new DataFrame named 'obj_train' from the old Train DataFrame by removing all the numerical columns from it\n# obj_train = train.drop(num_cols, axis=1)\n# obj_train.info()\n\n# For ML modelling, we'll only use the categorical features for training \nX, y = train.drop('Loan_Status', axis=1), train.Loan_Status\n\n# We will split the data to train and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, stratify= y)","50062686":"log_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\nlog_pred = log_reg.predict(X_test)\nlog_score = round(log_reg.score(X_train, y_train) * 100, 2)","da87ca42":"abc = AdaBoostClassifier()\nabc.fit(X_train,y_train)\nabc_pred = abc.predict(X_test)\nabc_score = round(abc.score(X_train, y_train) * 100, 2)","32a371b0":"lrcv = LogisticRegressionCV()\nlrcv.fit(X_train,y_train)\nlrcv_pred = lrcv.predict(X_test)\nlrcv_score = round(lrcv.score(X_train, y_train) * 100, 2)","a72df70f":"sgd = SGDClassifier()\nsgd.fit(X_train,y_train)\nsgd_pred = sgd.predict(X_test)\nsgd_score = round(sgd.score(X_train, y_train) * 100, 2)","bc62b8b1":"xgb = XGBClassifier()\nxgb.fit(X_train,y_train)\nxgb_pred = xgb.predict(X_test)\nxgb_score = round(xgb.score(X_train, y_train) * 100, 2)","49a7e821":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Ada Boost Classifier', \n              'LogisticRegressionCV', 'SGD Classifier', \n              'XG Boost'],\n    'Score': [log_score, abc_score, \n              lrcv_score, sgd_score, xgb_score]})\n\nmodels.sort_values(by='Score', ascending=False)","b0a99805":"(d) Filling missing values in 'Married' by random function","a32fead6":"5. XG Boost","ef9f274e":"##### 3. We will now load the dataset","84eaf5e3":"##### 1. We are importing WARNINGS class to suppress any warning","1049528c":"##### 8. We will now handle Missing Values and Categorical Variables","7ef84919":"2. Ada Boost Classifier ","a4f51ffd":"##### 2. We are now importing all necessary packages for our report","7187b847":"(a) Converting Categorical Variable 'Loan_Status' to Numerical","36d7e52a":"##### 7. How many null values are there column-wise?","ed6b20b7":"4. Stochastic Gradient Descent (SGD) Classifier","1dc55c2f":"### Now we will start preparing ML models and compare their scores to select the best accurate model","4333a574":"3. LogisticRegressionCV","3173cdcb":"### We can see that the XG Boost Classifier is giving the \"Best Accuracy\" with a score of 84.93.","1210c695":"1. Logistic Regression","13c1736b":"##### 5. Let us see the no. of rows and columns in this dataset","b1796452":"(b) Filling missing values in 'Gender' by random function","231a4e37":"##### 10. Now lets see some visualizations for possible combinations","527e4997":"(e) Filling missing values in 'Dependents' by random function","20b1a7a5":"##### 9. Let us now again see a basic Descriptive Stats of this dataset (After Cleaning)","ac943f76":"##### 4. Let us have a preview of the data","a6343ad3":"(a) Converting Categorical Variable 'Gender' to Numerical","9969c62e":"(j) Filling missing values in 'Credit_History' by random function","5fd92d68":"(c) Converting Categorical Variable 'Married' to Numerical","ad0ca321":"(f) Converting Categorical Variable 'Self_Employed' to Numerical","d7b810eb":"##### We will now check scores of all the models by comparing against each other","03c649bb":"##### 6. Let us see a basic Descriptive Stats of this dataset (Before Cleaning)","a4abbb6c":"(i) Filling missing values in 'Loan_Amount_Term' by random function","cda3c9a4":"(g) Filling missing values in 'Self_Employed' by random function","ad06a083":"# EDA & ML Modelling Report on Loan Approval\n\nAnalysis By: NEELESH DUGAR\n\nEmail: dugar.nilesh23@gmail.com\n\nMob: +91-7838823636","c2cfe853":"#### I hope this report helps you in understanding a few more concepts of Data Science & Analytics. This is my second kernel posted and a lot more will be coming soon. Stay Tuned!!\nAnd you can contact me for any queries\/collaboration\/discussion. My contact details are available at the Top.\n\nWelcome to Data Science & Machine Learning Club! All the best for future endeavours! :)","3b6e9d83":"(h) Filling missing values in 'LoanAmount' by mean function"}}