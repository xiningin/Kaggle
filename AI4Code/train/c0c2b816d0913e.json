{"cell_type":{"e81cffff":"code","9d5c3ab9":"code","53fe08b2":"code","914962ac":"code","b94a8838":"code","9f423a27":"code","a3de9614":"code","0bc401a8":"code","06f82e4b":"code","21facdc8":"code","e5a3219b":"code","fa9cba0d":"markdown","2eac8ba1":"markdown","2ef4ead6":"markdown","c5277515":"markdown","eb9798fb":"markdown","03793d90":"markdown","71306e92":"markdown","d144566f":"markdown"},"source":{"e81cffff":"import tensorflow as tf\nimport numpy as np\nimport random\nimport os\nimport time\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.callbacks import *\nfrom sklearn.metrics import *\nfrom tensorflow.keras.models import load_model\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # ignore warning :)\n\n# tensorboard = TensorBoard(log_dir='mylog')\n\ngpus = tf.config.experimental.list_physical_devices(device_type='GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(device=gpu, enable=True)\n    \ntrain_tfrecord = 'XRay_train.tfrecords'\ntest_tfrecord = 'XRay_test.tfrecords'\ntrain_percentage = 0.8  # Proportion of training set\n\nrandom.seed(20)\n\ninput_path='\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/'","9d5c3ab9":"learning_rate = 0.001\nbuffer_size = 512\nbatch_size = 16\nepochs = 100\n\nimg_size = 128","53fe08b2":"def read_directory():\n    data_filenames = []\n    data_labels = []\n\n    for filename in os.listdir(input_path + 'COVID-19'):\n        data_filenames.append(input_path + 'COVID-19\/' + filename)\n        data_labels.append(0)\n\n    for filename in os.listdir(input_path + 'NORMAL'):\n        data_filenames.append(input_path + 'NORMAL\/' + filename)\n        data_labels.append(1)\n\n    for filename in os.listdir(input_path + 'Viral Pneumonia'):\n        data_filenames.append(input_path + 'Viral Pneumonia\/' + filename)\n        data_labels.append(2)\n        \n    data_size = len(data_labels)\n\n    tmp_uni = list(zip(data_filenames, data_labels))\n\n    random.shuffle(tmp_uni)\n\n    train_size = int(data_size * train_percentage)\n    print('Size of training set\uff1a', train_size)\n    print('Size of test set\uff1a', data_size - train_size)\n\n    train_list = tmp_uni[0:train_size]\n    test_list = tmp_uni[train_size:]\n\n    train_filenames, train_labels = zip(*train_list)\n    test_filenames, test_labels = zip(*test_list)\n\n    return train_filenames, train_labels, test_filenames, test_labels","914962ac":"def build_train_tfrecord(train_filenames, train_labels):  # Generate TFRecord of training set \n    with tf.io.TFRecordWriter(train_tfrecord)as writer:\n        for filename, label in zip(train_filenames, train_labels):\n            image = open(filename, 'rb').read()\n\n            feature = {\n                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),  # img > Bytes\n                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))  # label > Int\n            }\n\n            example = tf.train.Example(features=tf.train.Features(feature=feature))\n            writer.write(example.SerializeToString())\n\n\ndef build_test_tfrecord(test_filenames, test_labels):  # Generate TFRecord of test set\n    with tf.io.TFRecordWriter(test_tfrecord)as writer:\n        for filename, label in zip(test_filenames, test_labels):\n            image = open(filename, 'rb').read()\n\n            feature = {\n                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n            }\n\n            example = tf.train.Example(features=tf.train.Features(feature=feature))\n            writer.write(example.SerializeToString())","b94a8838":"def _parse_example(example_string):\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n    }\n\n    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n    feature_dict['image'] = tf.io.decode_png(feature_dict['image'], channels=1)\n    feature_dict['image'] = tf.image.resize(feature_dict['image'], [img_size , img_size]) \/ 255.0\n    feature_dict['image'] = tf.squeeze(feature_dict['image']) # to squeeze the shape of one image from (img_size, img_size, 1) to (img_size, img_size)\n    print(type(feature_dict['image']))\n    return feature_dict['image'], feature_dict['label']\n\n\ndef get_train_dataset(train_tfrecord):  # read TFRecord\n    raw_train_dataset = tf.data.TFRecordDataset(train_tfrecord)\n    train_dataset = raw_train_dataset.map(_parse_example)\n\n    return train_dataset\n\n\ndef get_test_dataset(test_tfrecord):\n    raw_test_dataset = tf.data.TFRecordDataset(test_tfrecord)\n    test_dataset = raw_test_dataset.map(_parse_example)\n\n    return test_dataset\n\n\ndef data_Preprocessing(train_dataset, test_dataset):\n    train_dataset = train_dataset.shuffle(buffer_size)\n    train_dataset = train_dataset.batch(batch_size)\n    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n    test_dataset = test_dataset.batch(batch_size)\n    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n\n    return train_dataset, test_dataset","9f423a27":"def RNN_model():\n    lstm_layer = tf.keras.layers.LSTM(units=64, input_shape=(None,img_size), dropout=0.5)\n    model = tf.keras.Sequential([\n        lstm_layer,\n#         tf.keras.layers.LSTM(64),\n#         tf.keras.layers.Dense(64),\n#         tf.keras.layers.Dropout(0.2),\n#         tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(3, activation='softmax')\n    ])\n    \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\n        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n    )\n    \n    return model","a3de9614":"def scheduler(epoch,lr):\n    if epoch<10:\n        return lr\n    else:\n        return lr*0.964\n\ncallback = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)\n\n# class_weight = {0:6.14, 1:1., 2:1.}","0bc401a8":"def train():\n    time_start = time.time()\n    \n    model = RNN_model()\n    \n    model.summary()\n    \n    train_history = model.fit(train_dataset, epochs=epochs, callbacks=[callback])\n\n    model.save('mymodel.h5')\n    \n    print('Model saved.')\n    \n    time_end = time.time()\n    print('Training Time:', time_end - time_start)\n    print('\\n')\n\n    return train_history","06f82e4b":"def show_train_history(train_history, index):\n    plt.plot(train_history.history[index])\n    plt.title('Train History')\n    plt.ylabel(index)\n    plt.xlabel('Epoch')\n    plt.show()","21facdc8":"def test(test_labels):\n    test_labels = np.array(test_labels)\n    model = load_model('\/kaggle\/working\/mymodel.h5')\n    \n    print('Testing:')\n    \n    model.evaluate(test_dataset)\n    \n    predIdxs = model.predict(test_dataset)\n    predIdxs = np.argmax(predIdxs, axis=1) \n\n    target_names = ['COVID-19', 'NORMAL', 'Viral Pneumonia']\n    print('\\n')\n    print(classification_report(test_labels, predIdxs, target_names=target_names, digits=5))","e5a3219b":"if __name__ == \"__main__\":\n    train_filenames, train_labels, test_filenames, test_labels = read_directory()\n\n    build_train_tfrecord(train_filenames, train_labels)\n    build_test_tfrecord(test_filenames, test_labels)\n\n    train_dataset = get_train_dataset(train_tfrecord)\n    test_dataset = get_test_dataset(test_tfrecord)\n\n    print('Info of train_dataset', type(train_dataset))\n    print('Info of test_dataset', type(test_dataset))\n\n    train_dataset, test_dataset = data_Preprocessing(train_dataset, test_dataset) \n\n    train_history = train()\n    \n    test(test_labels)\n    \n    show_train_history(train_history, 'sparse_categorical_accuracy')\n    \n    # Avoid filling up the disk, if you want to save the tfrecords, just '#' these lines:\n    for filename in os.listdir('\/kaggle\/working'): \n        if 'X' in filename: # Delete the tfrecord.\n            os.remove('\/kaggle\/working\/' + filename)","fa9cba0d":"# Train&Test","2eac8ba1":"# Load data","2ef4ead6":"# Run Now\uff01","c5277515":"# Model","eb9798fb":"# Initialization","03793d90":"# Intro: \nThis script classifies the images to 3 categories: **COVID-19**, **NORMAL** and **Viral Pneumonia**. This script also includes the use of **tfrecord**.  \nThis notebook aims at testing the performence of RNN on this problem.","71306e92":"# Build TFRecord","d144566f":"# Decode TFRecord and get data"}}