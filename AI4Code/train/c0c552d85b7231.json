{"cell_type":{"e699c264":"code","e9e18ff4":"code","be0daf27":"code","9386a5c7":"code","51b5e66a":"code","5a38c6fd":"code","cbbb8722":"code","062c39eb":"code","76c54e60":"code","a9eebbc2":"code","8ca541b6":"code","e238768c":"code","523299df":"markdown","4d9a5603":"markdown","e5457a7a":"markdown","196e9d65":"markdown","6afc4d3d":"markdown","6413442d":"markdown","ce9b0684":"markdown","f5e82346":"markdown","80159d14":"markdown","a39fc5e2":"markdown"},"source":{"e699c264":"# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https:\/\/www.apache.org\/licenses\/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License","e9e18ff4":"#@markdown Select a region from either the [Natural Earth low res](https:\/\/www.naturalearthdata.com\/downloads\/110m-cultural-vectors\/110m-admin-0-countries\/) (fastest), [Natural Earth high res](https:\/\/www.naturalearthdata.com\/downloads\/10m-cultural-vectors\/10m-admin-0-countries\/) or [World Bank high res](https:\/\/datacatalog.worldbank.org\/dataset\/world-bank-official-boundaries) shapefiles:\nregion_border_source = 'Natural Earth (Low Res 110m)'  #@param [\"Natural Earth (Low Res 110m)\", \"Natural Earth (High Res 10m)\", \"World Bank (High Res 10m)\"]\n#region = 'GHA (Ghana)'  #@param [\"\", \"AGO (Angola)\", \"BDI (Burundi)\", \"BEN (Benin)\", \"BFA (Burkina Faso)\", \"BWA (Botswana)\", \"CAF (Central African Republic)\", \"CIV (C\u00f4te d'Ivoire)\", \"COD (Democratic Republic of the Congo)\", \"COG (Republic of the Congo)\", \"DJI (Djibouti)\", \"DZA (Algeria)\", \"EGY (Egypt)\", \"ERI (Eritrea)\", \"ETH (Ethiopia)\", \"GAB (Gabon)\", \"GHA (Ghana)\", \"GIN (Guinea)\", \"GMB (The Gambia)\", \"GNB (Guinea-Bissau)\", \"GNQ (Equatorial Guinea)\", \"KEN (Kenya)\", \"LBR (Liberia)\", \"LSO (Lesotho)\", \"MDG (Madagascar)\", \"MOZ (Mozambique)\", \"MRT (Mauritania)\", \"MWI (Malawi)\", \"NAM (Namibia)\", \"NER (Niger)\", \"NGA (Nigeria)\", \"RWA (Rwanda)\", \"SDN (Sudan)\", \"SEN (Senegal)\", \"SLE (Sierra Leone)\", \"SOM (Somalia)\", \"SWZ (eSwatini)\", \"TGO (Togo)\", \"TUN (Tunisia)\", \"TZA (Tanzania)\", \"UGA (Uganda)\", \"ZAF (South Africa)\", \"ZMB (Zambia)\", \"ZWE (Zimbabwe)\"]\nregion = \"RWA (Rwanda)\"\n# @markdown Alternatively, specify an area of interest in [WKT format](https:\/\/en.wikipedia.org\/wiki\/Well-known_text_representation_of_geometry) (assumes crs='EPSG:4326'); this [tool](https:\/\/arthur-e.github.io\/Wicket\/sandbox-gmaps3.html) might be useful.\nyour_own_wkt_polygon = ''  #@param {type:\"string\"}\n!pip install s2geometry pygeos geopandas\n\nimport functools\nimport glob\nimport gzip\nimport multiprocessing\nimport os\nimport shutil\nimport tempfile\nfrom typing import List, Optional, Tuple\n\n\n#import gdal\nimport geopandas as gpd\n#from google.colab import files\nfrom IPython import display\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport s2geometry as s2\nimport shapely\nimport tensorflow as tf\nimport tqdm.notebook\n\nBUILDING_DOWNLOAD_PATH = ('gs:\/\/open-buildings-data\/v1\/'\n                          'polygons_s2_level_6_gzip_no_header')\n\ndef get_filename_and_region_dataframe(\n    region_border_source: str, region: str,\n    your_own_wkt_polygon: str) -> Tuple[str, gpd.geodataframe.GeoDataFrame]:\n  \"\"\"Returns output filename and a geopandas dataframe with one region row.\"\"\"\n\n  if your_own_wkt_polygon:\n    filename = 'open_buildings_v1_polygons_your_own_wkt_polygon.csv.gz'\n    region_df = gpd.GeoDataFrame(\n        geometry=gpd.GeoSeries.from_wkt([your_own_wkt_polygon]),\n        crs='EPSG:4326')\n    if not isinstance(region_df.iloc[0].geometry,\n                      shapely.geometry.polygon.Polygon) and not isinstance(\n                          region_df.iloc[0].geometry,\n                          shapely.geometry.multipolygon.MultiPolygon):\n      raise ValueError(\"`your_own_wkt_polygon` must be a POLYGON or \"\n                      \"MULTIPOLYGON.\")\n    print(f'Preparing your_own_wkt_polygon.')\n    return filename, region_df\n\n  if not region:\n    raise ValueError('Please select a region or set your_own_wkt_polygon.')\n\n  if region_border_source == 'Natural Earth (Low Res 110m)':\n    url = ('https:\/\/www.naturalearthdata.com\/http\/\/www.naturalearthdata.com\/'\n           'download\/110m\/cultural\/ne_110m_admin_0_countries.zip')\n    !wget -N {url}\n    display.clear_output()\n    region_shapefile_path = os.path.basename(url)\n    source_name = 'ne_110m'\n  elif region_border_source == 'Natural Earth (High Res 10m)':\n    url = ('https:\/\/www.naturalearthdata.com\/http\/\/www.naturalearthdata.com\/'\n           'download\/10m\/cultural\/ne_10m_admin_0_countries.zip')\n    !wget -N {url}\n    display.clear_output()\n    region_shapefile_path = os.path.basename(url)\n    source_name = 'ne_10m'\n  elif region_border_source == 'World Bank (High Res 10m)':\n    url = ('https:\/\/development-data-hub-s3-public.s3.amazonaws.com\/ddhfiles\/'\n           '779551\/wb_countries_admin0_10m.zip')\n    !wget -N {url}\n    !unzip -o {os.path.basename(url)}\n    display.clear_output()\n    region_shapefile_path = 'WB_countries_Admin0_10m'\n    source_name = 'wb_10m'\n\n  region_iso_a3 = region.split(' ')[0]\n  filename = f'open_buildings_v1_polygons_{source_name}_{region_iso_a3}.csv.gz'\n  region_df = gpd.read_file(region_shapefile_path).query(\n      f'ISO_A3 == \"{region_iso_a3}\"').dissolve(by='ISO_A3')[['geometry']]\n  print(f'Preparing {region} from {region_border_source}.')\n  return filename, region_df\n\n\ndef get_bounding_box_s2_covering_tokens(\n    region_geometry: shapely.geometry.base.BaseGeometry) -> List[str]:\n  region_bounds = region_geometry.bounds\n  s2_lat_lng_rect = s2.S2LatLngRect_FromPointPair(\n      s2.S2LatLng_FromDegrees(region_bounds[1], region_bounds[0]),\n      s2.S2LatLng_FromDegrees(region_bounds[3], region_bounds[2]))\n  coverer = s2.S2RegionCoverer()\n  # NOTE: Should be kept in-sync with s2 level in BUILDING_DOWNLOAD_PATH.\n  coverer.set_fixed_level(6)\n  coverer.set_max_cells(1000000)\n  return [cell.ToToken() for cell in coverer.GetCovering(s2_lat_lng_rect)]\n\n\ndef s2_token_to_shapely_polygon(\n    s2_token: str) -> shapely.geometry.polygon.Polygon:\n  s2_cell = s2.S2Cell(s2.S2CellId_FromToken(s2_token, len(s2_token)))\n  coords = []\n  for i in range(4):\n    s2_lat_lng = s2.S2LatLng(s2_cell.GetVertex(i))\n    coords.append((s2_lat_lng.lng().degrees(), s2_lat_lng.lat().degrees()))\n  return shapely.geometry.Polygon(coords)\n\n\ndef download_s2_token(\n    s2_token: str, region_df: gpd.geodataframe.GeoDataFrame) -> Optional[str]:\n  \"\"\"Downloads the matching CSV file with polygons for the `s2_token`.\n\n  NOTE: Only polygons inside the region are kept.\n  NOTE: Passing output via a temporary file to reduce memory usage.\n\n  Args:\n    s2_token: S2 token for which to download the CSV file with building\n      polygons. The S2 token should be at the same level as the files in\n      BUILDING_DOWNLOAD_PATH.\n    region_df: A geopandas dataframe with only one row that contains the region\n      for which to keep polygons.\n\n  Returns:\n    Either filepath which contains a gzipped CSV without header for the\n    `s2_token` subfiltered to only contain building polygons inside the region\n    or None which means that there were no polygons inside the region for this\n    `s2_token`.\n  \"\"\"\n  s2_cell_geometry = s2_token_to_shapely_polygon(s2_token)\n  region_geometry = region_df.iloc[0].geometry\n  prepared_region_geometry = shapely.prepared.prep(region_geometry)\n  # If the s2 cell doesn't intersect the country geometry at all then we can\n  # know that all rows would be dropped so instead we can just return early.\n  if not prepared_region_geometry.intersects(s2_cell_geometry):\n    return None\n  try:\n    # Using tf.io.gfile.GFile gives better performance than passing the GCS path\n    # directly to pd.read_csv.\n    with tf.io.gfile.GFile(\n        os.path.join(BUILDING_DOWNLOAD_PATH, f'{s2_token}_buildings.csv.gz'),\n        'rb') as gf:\n      # If the s2 cell is fully covered by country geometry then can skip\n      # filtering as we need all rows.\n      if prepared_region_geometry.covers(s2_cell_geometry):\n        with tempfile.NamedTemporaryFile(mode='w+b', delete=False) as tmp_f:\n          shutil.copyfileobj(gf, tmp_f)\n          return tmp_f.name\n      # Else take the slow path.\n      # NOTE: We read in chunks to save memory.\n      csv_chunks = pd.read_csv(\n          gf, chunksize=2000000, dtype=object, compression='gzip', header=None)\n      tmp_f = tempfile.NamedTemporaryFile(mode='w+b', delete=False)\n      tmp_f.close()\n      for csv_chunk in csv_chunks:\n        points = gpd.GeoDataFrame(\n            geometry=gpd.points_from_xy(csv_chunk[1], csv_chunk[0]),\n            crs='EPSG:4326')\n        # sjoin 'within' was faster than using shapely's 'within' directly.\n        points = gpd.sjoin(points, region_df, predicate='within')\n        csv_chunk = csv_chunk.iloc[points.index]\n        csv_chunk.to_csv(\n            tmp_f.name,\n            mode='ab',\n            index=False,\n            header=False,\n            compression={\n                'method': 'gzip',\n                'compresslevel': 1\n            })\n      return tmp_f.name\n  except tf.errors.NotFoundError:\n    return None\n\n# Clear output after pip install.\ndisplay.clear_output()\nfilename, region_df = get_filename_and_region_dataframe(region_border_source,\n                                                        region,\n                                                        your_own_wkt_polygon)\n# Remove any old outputs to not run out of disk.\nfor f in glob.glob('\/tmp\/open_buildings_*'):\n  os.remove(f)\n# Write header to the compressed CSV file.\nwith gzip.open(f'\/tmp\/{filename}', 'wt') as merged:\n  merged.write(','.join([\n      'latitude', 'longitude', 'area_in_meters', 'confidence', 'geometry',\n      'full_plus_code'\n  ]) + '\\n')\ndownload_s2_token_fn = functools.partial(download_s2_token, region_df=region_df)\ns2_tokens = get_bounding_box_s2_covering_tokens(region_df.iloc[0].geometry)\n# Downloads CSV files for relevant S2 tokens and after filtering appends them\n# to the compressed output CSV file. Relies on the fact that concatenating\n# gzipped files produces a valid gzip file.\n# NOTE: Uses a pool to speed up output preparation.\nwith open(f'\/tmp\/{filename}', 'ab') as merged:\n  with multiprocessing.Pool(4) as e:\n    for fname in tqdm.notebook.tqdm(\n        e.imap_unordered(download_s2_token_fn, s2_tokens),\n        total=len(s2_tokens)):\n      if fname:\n        with open(fname, 'rb') as tmp_f:\n          shutil.copyfileobj(tmp_f, merged)\n        os.unlink(fname)","be0daf27":"buildings = pd.read_csv(\n    f\"\/tmp\/{filename}\", engine=\"c\",\n    usecols=['latitude', 'longitude', 'area_in_meters', 'confidence'])\n\nprint(f\"Read {len(buildings):,} records.\")","9386a5c7":"sample_size = 200000  #@param","51b5e66a":"buildings_sample = (buildings.sample(sample_size)\n                    if len(buildings) > sample_size else buildings)","5a38c6fd":"plt.plot(buildings_sample.longitude, buildings_sample.latitude, 'k.',\n         alpha=0.25, markersize=0.5)\nplt.gcf().set_size_inches(10, 10)\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.axis('equal');","cbbb8722":"max_grid_dimension = 1000 #@param\nconfidence_threshold = 0.75 #@param","062c39eb":"buildings = buildings.query(f\"confidence > {confidence_threshold}\")","76c54e60":"# Create a grid covering the dataset bounds\nmin_lon = buildings.longitude.min() \nmax_lon = buildings.longitude.max() \nmin_lat = buildings.latitude.min()\nmax_lat = buildings.latitude.max() \n\ngrid_density_degrees = (max(max_lon - min_lon, max_lat - min_lat)\n                        \/ max_grid_dimension)\n\nbounds = [min_lon, min_lat, max_lon, max_lat]\nxcoords = np.arange(min_lon, max_lon, grid_density_degrees)\nycoords = np.arange(max_lat, min_lat, -grid_density_degrees)\nxv, yv = np.meshgrid(xcoords, ycoords)\nxy = np.stack([xv.ravel(), yv.ravel()]).transpose()\n\nprint(f\"Calculated grid of size {xv.shape[0]} x {xv.shape[1]}.\")","a9eebbc2":"geotransform = (min_lon, grid_density_degrees, 0,\n                max_lat, 0, -grid_density_degrees)\n\ndef lonlat_to_xy(lon, lat, geotransform):\n    x = int((lon - geotransform[0])\/geotransform[1])\n    y = int((lat - geotransform[3])\/geotransform[5])\n    return x,y","8ca541b6":"counts = np.zeros(xv.shape)\narea_totals = np.zeros(xv.shape)\n\nfor lat, lon, area in tqdm.notebook.tqdm(\n    zip(buildings.latitude, buildings.longitude, buildings.area_in_meters)):\n  x, y = lonlat_to_xy(lon, lat, geotransform)\n  if x >= 0 and y >= 0 and x < len(xcoords) and y < len(ycoords):\n    counts[y, x] += 1\n    area_totals[y, x] += area\n\narea_totals[counts == 0] = np.nan\ncounts[counts == 0] = np.nan\nmean_area = area_totals \/ counts","e238768c":"plt.imshow(np.log10(np.nan_to_num(counts) + 1.), cmap=\"viridis\")\nplt.gcf().set_size_inches(15, 15)\ncbar = plt.colorbar(shrink=0.5)\ncbar.ax.set_yticklabels([f'{x:.0f}' for x in 10 ** cbar.ax.get_yticks()]) \nplt.title(\"Building counts per grid cell\");","523299df":"Code adapted from https:\/\/colab.sandbox.google.com\/github\/google-research\/google-research\/blob\/master\/building_detection\/open_buildings_spatial_analysis_examples.ipynb","4d9a5603":"Now we can count how many buildings there are on each cell of the grid. ","e5457a7a":"Code adapted from https:\/\/colab.sandbox.google.com\/github\/google-research\/google-research\/blob\/master\/building_detection\/open_buildings_spatial_analysis_examples.ipynb","196e9d65":"To calculate statistics, we need a function to convert between (longitude, latitude) coordinates in the world and (x, y) coordinates in the grid.","6afc4d3d":"# Plot the counts of buildings\n\nKnowing the counts of buildings is useful for example in planning service delivery, estimating population or designing census enumeration areas.\n\nRwanda:","6413442d":"For some countries there can be tens of millions of buildings, so we also take a random sample for doing plots.","ce9b0684":"# Open Buildings - spatial analysis examples\n\nThis notebook demonstrates some analysis methods with [Open Buildings](https:\/\/sites.research.google\/open-buildings\/) data: \n\n* Generating heatmaps of building density and size.\n* A simple analysis of accessibility to health facilities.","f5e82346":"# Prepare the data for mapping building statistics\n\nSet up a grid, which we will use to calculate statistics about buildings.\n\nWe also want to select the examples most likely to be buildings, using a threshold on the confidence score.","80159d14":"### Download buildings data for a region in Africa [takes up to 15 minutes for large countries]\n - Rwanda","a39fc5e2":"# Visualise the data\n\nFirst we convert the CSV file into a GeoDataFrame. The CSV files can be quite large because they include the polygon outline of every building. For this example we only need longitude and latitude, so we only process those columns to save memory.\n\nRwanda:"}}