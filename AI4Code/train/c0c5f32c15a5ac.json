{"cell_type":{"f1e4c131":"code","c241417e":"code","74e082f8":"code","1c6c2096":"code","d5623cbf":"code","206c43d7":"code","be177653":"code","ce7b4e34":"code","0d5aa11b":"code","3f0fafd9":"code","3b5d8c7c":"code","45fd47f1":"code","57c3b994":"code","ac937260":"code","d44a3820":"code","26050a12":"code","7f55dfa5":"code","c5d749cf":"code","0bde8b85":"code","a320d015":"code","af9e76e0":"code","a8642bc1":"code","507f36b8":"code","e83f0ddf":"code","01bb6b0b":"code","72fe7a81":"code","da18171f":"code","85765dc1":"code","f003247f":"code","c202d092":"code","442dd774":"code","5e738c1d":"code","dc1e2338":"code","7c10e589":"code","f936e62a":"code","1dc39619":"code","f4ee5942":"code","c90c438e":"code","1dcfb609":"code","9a48a315":"code","f86568c8":"code","f916ca8e":"code","b5fe636e":"code","a67f5f9d":"code","afcead58":"code","b04e6eaa":"code","5d8b058b":"code","c21163f1":"code","d54256ad":"code","7df1b9ec":"code","e12bd0ec":"code","d016d3f7":"code","4120c195":"code","fa4004d9":"code","63f0a0ed":"code","7f0f8150":"code","03b25560":"code","880a1658":"code","4118b5f7":"markdown","9b4089fb":"markdown","0b63425a":"markdown","dbf90b7a":"markdown","d846cb37":"markdown"},"source":{"f1e4c131":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# from os import walk\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c241417e":"# # !conda install -c pytorch pytorch-cpu torchvision\n# # !yes Y | conda install -c pytorch pytorch-cpu torchvision\n# from fastai.data.external import untar_data\n# !conda install -c pytorch pytorch-cpu torchvision --y","74e082f8":"# !conda install -c fastai fastaiorpip install http:\/\/download.pytorch.org\/whl\/cpu\/torch-1.0.0-cp36-cp36m-linux_x86_64.whl --y","1c6c2096":"# !pip install fastai","d5623cbf":"# from fastai.vision import *","206c43d7":"# !pip install ffmpeg","be177653":"# import fastai # conda install -c pytorch -c fastai fastai=1.0.61","ce7b4e34":"# conda install -c fastai fastbook\n# from fastbook import *\n# fastbook.setup_book()\nimport fastai\nfrom fastai import *\nfrom fastai.data.block import DataBlock\nfrom fastai.data.external import *\nfrom fastai.data.transforms import *\nfrom fastai.vision import *\nfrom fastai.vision.augment import RandomResizedCrop, Resize\nfrom fastai.vision.data import ImageDataLoaders, ImageBlock\n\n","0d5aa11b":"import cv2\nimport matplotlib.pyplot as plt","3f0fafd9":"# https:\/\/medium.com\/howtoai\/video-classification-with-cnn-rnn-and-pytorch-abe2f9ee031\n# https:\/\/github.com\/PacktPublishing\/PyTorch-Computer-Vision-Cookbook\/blob\/master\/Chapter10\/myutils.py\n\ndef get_frames(filename, n_frames=1):\n    print(filename)\n    frames = []\n    v_cap = cv2.VideoCapture(filename)\n    v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_list = np.linspace(0, v_len - 1, n_frames + 1, dtype=np.int16)\n\n    for fn in range(v_len):\n        success, frame = v_cap.read()\n        if success is False:\n            continue\n        if fn in frame_list:\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            frames.append(frame)\n    v_cap.release()\n    return frames, v_len\n\n\ndef store_frames(frames, path2store):\n    for ii, frame in enumerate(frames):\n        plt.imshow(frame)\n        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n        # if not os.path.exists(path2store):\n        #     os.makedirs(path2store)\n        print(path2store)\n        path2img = (path2store + \"-frame-\" + str(ii) + \".jpg\").replace(\"\\\\\", \"\/\")\n        # path2img = os.path.join(path2store, \"-frame-\" + str(ii) + \".jpg\").replace(\"\\\\\", \"\/\")\n        print(path2img)\n        cv2.imwrite(path2img, frame)\n\n\ntemp_video_path = \"D:\/_PROJECTS\/epilepsy-extension\/src\/data\/seizure_data\/video\/train\/0-green-blue-9.avi\"\ntemp_image_path = \"D:\/_PROJECTS\/epilepsy-extension\/src\/data\/seizure_data\/image\/train\/0-green-blue-9\"\ntemp_frames, temp_frame_len = get_frames(temp_video_path, 5)\nstore_frames(temp_frames, temp_image_path)","3b5d8c7c":"def extract_images_from_directory(video_directory, image_directory, f_num):\n    _, _, filenames = next(walk(video_directory))\n    for file in filenames:\n        full_path = os.path.join(video_directory, file).replace(\"\\\\\", \"\/\")\n        frames, len = get_frames(full_path, f_num)\n        #cut out the file extension\n        filename = file.split(\".\")[0]\n        image_path = os.path.join(image_directory, filename).replace(\"\\\\\", \"\/\")\n        store_frames(frames, image_path)\n\n\nvideo_train_root = \"D:\/_PROJECTS\/epilepsy-extension\/src\/data\/seizure_data\/video\/train\/\"\nvideo_valid_root = \"D:\/_PROJECTS\/epilepsy-extension\/src\/data\/seizure_data\/video\/valid\/\"\nimage_train_root = \"D:\/_PROJECTS\/epilepsy-extension\/src\/data\/seizure_data\/image\/train\/\"\nimage_valid_root = \"D:\/_PROJECTS\/epilepsy-extension\/src\/data\/seizure_data\/image\/valid\/\"\nimage_root = \"\/kaggle\/input\/tinybabytestdataset\/image\/\"\n# image_root = \"D:\/_PROJECTS\/epilepsy-extension\/src\/data\/seizure_data\/image\"\n\nframes_per_video = 5\n\n# extract_images_from_directory(video_train_root, image_train_root, frames_per_video)\n# extract_images_from_directory(video_valid_root, image_valid_root, frames_per_video)\n\n# for file in valid_filenames:\n#     full_path = os.path.join(video_valid_root, file).replace(\"\\\\\", \"\/\")\n#     frames, len = get_frames(full_path, frames_per_video)\n#     #cut out the file extension\n#     filename = file.split(\".\")[0]\n#     image_path = os.path.join(image_valid_root, filename).replace(\"\\\\\", \"\/\")\n#     store_frames(frames, image_path)\n\n\n","45fd47f1":"\n\n# file_root = \"..\/data\/seizure_data\/images\/train\/\"\n# train_image_root = \"D:\/_PROJECTS\/epilepsy-extension\/src\/data\/seizure_data\/image\/train\/\"\n\n# store_frames(test_frames, train_image_root)\n\n# i = 0\n# for frame in test_frames :\n#     plt.imshow(frame)\n#     # file_root = \"..\/data\/seizure_data\/images\/train\/\"\n#     file_root = \"D:\/_PROJECTS\/epilepsy-extension\/src\/data\/seizure_data\/images\/train\/\"\n#     file_name = \"test-\" + str(i)\n#     file_extension = \".bmp\"\n#     filepath = file_root + file_name + file_extension\n#     # filepath = \"C:\/Users\/Alina Work\/Desktop\/temp.bmp\"\n#     cv2.imwrite(filepath, frame)\n#     i += i","57c3b994":"# https:\/\/www.dataspoof.info\/post\/video-classification-with-fastai-and-deep-learning\/\n# np.random.seed(42)\n\n\ndataset = ImageDataLoaders.from_folder(\n    image_root,\n    item_tfms=Resize(224)\n)\n\n    # train='train',\n    # valid='valid',\n# valid_pct=0.2,\n# ds_tfms=get_transforms(),\n# size=224,\n# num_workers=4\n\n# .normalize(imagenet_stats)\n\n# dataset.show_batch()","ac937260":"dataset.show_batch(max_n=100)\n# data.classes","d44a3820":"dataset.train_ds.items[:]","26050a12":"dataset.vocab","7f55dfa5":"# path = untar_data(URLs.IMAGENETTE_160)\n# path = \"src\/data\/ucf-subset\"","c5d749cf":"# dls = ImageDataLoaders.from_folder(\n#     path,\n#     valid='val',\n#     item_tfms=RandomResizedCrop(128, min_scale=0.35),\n#     # batch_tfms=Normalize.from_stats(*imagenet_stats)\n# )","0bde8b85":"# dls.show_batch()","a320d015":"# fnames = get_image_files(path)","af9e76e0":"# dblock = DataBlock()","a8642bc1":"# dsets = dblock.datasets(fnames)\n# dsets.train[0]","507f36b8":"# dblock = DataBlock(get_items=get_image_files)","e83f0ddf":"# dsets = dblock.datasets(path)\n# dsets.train[0]","01bb6b0b":"# parent_label(fnames[0])","72fe7a81":"# data = ImageDataLoaders.from_folder(\n#     # path,\n#     # train='..\/input\/ucfsubset\/ucf-subset\/train',\n#     # valid_pct=0.2,\n#     # ds_tfms=get_transforms(),\n#     # size=224,\n#     # num_workers=4).normalize(imagenet_stats)\n\n# data.classes\n\n#Out: ['A', 'B', 'C']","da18171f":"# with open('readme.txt', 'w') as f:\n#     f.write('Create a new text file!')","85765dc1":"# # !pip install wget\n# !wget https:\/\/www.fillmurray.com\/g\/200\/300","f003247f":"# import wget","c202d092":"# fname = wget.download('https:\/\/www.fillmurray.com\/g\/200\/300')","442dd774":"# open(fname)","5e738c1d":"# # from PIL import Image\n# # from scipy.misc.pilutil import Image\n# # import imagio\n# import matplotlib.pyplot as plt\n# img = plt.imread(\"300\")\n# plt.imshow(img)\n# plt.show()","dc1e2338":"# img.shape\n","7c10e589":"# !git clone https:\/\/github.com\/AlinaWithAFace\/epilepsy-extension","f936e62a":"# import cv2     # for capturing videos\n# import math   # for mathematical operations\n# import matplotlib.pyplot as plt    # for plotting the images\n# %matplotlib inline\n# import pandas as pd\n# from keras.preprocessing import image   # for preprocessing the images\n# import numpy as np    # for mathematical operations\n# from keras.utils import np_utils\n# from skimage.transform import resize   # for resizing images\n# from sklearn.model_selection import train_test_split\n# from glob import glob\n# from tqdm import tqdm\n# !pip install opencv-python","1dc39619":"# # open the .txt file which have names of training videos\n# train_list_dir = \"..\/input\/ucf101\/UCF101TrainTestSplits-RecognitionTask\/ucfTrainTestlist\/trainlist01.txt\"\n# # train_list_dir = \"..\/data\/ucfTrainTestlist\/trainlist01.txt\"\n# f = open(train_list_dir, \"r\")\n# temp = f.read()\n# videos = temp.split('\\n')\n\n# # creating a dataframe having video names\n# train = pd.DataFrame()\n# train['video_name'] = videos\n# train = train[:-1]\n# train.head()","f4ee5942":"# !pip install moviepy","c90c438e":"# import imageio\n# vid = imageio.get_reader(\"..\/input\/potential-photosensitive-epilepy-flashing-videos\/src_generator_samples_1-blue-black-9.avi\")","1dcfb609":"# # means = []\n# for i,image in enumerate(vid.iter_data()):\n#     np.save(\"PatSavesTheDay.npy\", image)\n#     break\n#     #     means.append(image.mean())","9a48a315":"# np.load(\"PatSavesTheDay.npy\")","f86568c8":"# (0,1) (0, 255)","f916ca8e":"# plt.plot(np.diff(means))","b5fe636e":"# plt.plot(np.diff(means))","a67f5f9d":"# def rolling_window(a, window):\n#     shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n#     strides = a.strides + (a.strides[-1],)\n#     return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)","afcead58":"# plt.plot(np.var(rolling_window(np.array(means), 29), axis =1))","b04e6eaa":"# plt.plot(np.var(rolling_window(np.array(means), 30), axis =1))","5d8b058b":"# np.var(np.diff(means))","c21163f1":"# import cv2\n# import numpy as np\n\n# cap = cv2.VideoCapture('..\/input\/ucf101\/UCF101\/UCF-101\/ApplyEyeMakeup\/v_ApplyEyeMakeup_g01_c01.avi')\n# frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n# frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n# frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n# buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n\n# fc = 0\n# ret = True\n\n# while (fc < frameCount  and ret):\n#     ret, buf[fc] = cap.read()\n#     fc += 1\n\n# # cap.release()\n\n# # cv2.namedWindow('frame 10')\n# # cv2.imshow('frame 10', buf[9])\n","d54256ad":"# cap.read()","7df1b9ec":"# # open the .txt file which have names of test videos\n# test_list_dir = \"..\/input\/ucf101\/UCF101TrainTestSplits-RecognitionTask\/ucfTrainTestlist\/testlist01.txt\"\n# # test_list_dir = \"..\/data\/ucfTrainTestlist\/testlist01.txt\"\n# f = open(test_list_dir, \"r\")\n# temp = f.read()\n# videos = temp.split('\\n')\n\n# # creating a dataframe having video names\n# test = pd.DataFrame()\n# test['video_name'] = videos\n# test = test[:-1]\n# test.head()","e12bd0ec":"# # creating tags for training videos\n# train_video_tag = []\n# for i in range(train.shape[0]):\n#     train_video_tag.append(train['video_name'][i].split('\/')[0])\n\n# train['tag'] = train_video_tag\n\n# # creating tags for test videos\n# test_video_tag = []\n# for i in range(test.shape[0]):\n#     test_video_tag.append(test['video_name'][i].split('\/')[0])\n\n# test['tag'] = test_video_tag\n\n# # print(test['tag'])","d016d3f7":"# #from ipymol.compat import Image\n\n# from PIL import Image","4120c195":"# import matplotlib.pyplot as plt\n# # storing the frames from training videos\n# # for i in tqdm(range(train.shape[0])):\n# for i in tqdm(range(1)):\n#     count = 0\n#     videoFile = train['video_name'][i]\n#     video_root = '..\/input\/ucf101\/UCF101\/UCF-101\/'\n# #     video_root = \"..\/data\/UCF-101\/\"\n#     video_tag = train_video_tag[i]\n#     video_path = video_root + video_tag + \"\/\"+ videoFile.split(' ')[0].split('\/')[1]\n# #    eg path ..\/input\/ucf101\/UCF101\/UCF-101\/ApplyEyeMakeup\/v_ApplyEyeMakeup_g08_c01.avi\n# #     print(video_path)\n#     cap = cv2.VideoCapture(video_path)   # capturing the video from the given path\n#     frameRate = cap.get(5) #frame rate\n#     x=1\n#     while(cap.isOpened()):\n#         frameId = cap.get(1) #current frame number\n#         ret, frame = cap.read()\n#         if not ret:\n#             break\n#         plt.imshow(frame)\n#         plt.show()\n#         filename = \"ucf-frames\/train_1\/image.jpg\"\n#         cv2.imwrite(filename, frame)\n# #         if (frameId % math.floor(frameRate) == 0):\n# #             # storing the frames in a new folder named train_1\n# # #             filename = \"train_1\/\" + videoFile.split('\/')[1].split(' ')[0] +\"_frame%d.jpg\" % count\n# # #             count+=1\n\n# #             print(filename)\n# #             cv2.imwrite(filename, frame)\n#     cap.release()","fa4004d9":"# # getting the names of all the images\n# images = glob(\"train_1\/*.jpg\")\n# train_image = []\n# train_class = []\n# for i in tqdm(range(len(images))):\n#     # creating the image name\n#     train_image.append(images[i].split('\/')[1])\n#     # creating the class of image\n#     train_class.append(images[i].split('\/')[1].split('_')[1])\n\n# # storing the images and their class in a dataframe\n# train_data = pd.DataFrame()\n# train_data['image'] = train_image\n# train_data['class'] = train_class\n\n# # converting the dataframe into csv file \n# train_data.to_csv('UCF\/train_new.csv',header=True, index=False)","63f0a0ed":"# import keras\n# from keras.models import Sequential\n# from keras.applications.vgg16 import VGG16\n# from keras.layers import Dense, InputLayer, Dropout, Flatten\n# from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n# from keras.preprocessing import image\n# import numpy as np\n# import pandas as pd\n# import matplotlib.pyplot as plt\n# from tqdm import tqdm\n# from sklearn.model_selection import train_test_split","7f0f8150":"# train = pd.read_csv('UCF\/train_new.csv')\n# train.head()","03b25560":"# # creating an empty list\n# train_image = []\n\n# # for loop to read and store frames\n# for i in tqdm(range(train.shape[0])):\n#     # loading the image and keeping the target size as (224,224,3)\n#     img = image.load_img('train_1\/'+train['image'][i], target_size=(224,224,3))\n#     # converting it to array\n#     img = image.img_to_array(img)\n#     # normalizing the pixel value\n#     img = img\/255\n#     # appending the image to the train_image list\n#     train_image.append(img)\n\n# # converting the list to numpy array\n# X = np.array(train_image)\n\n# # shape of the array\n# X.shape","880a1658":"# # separating the target\n# y = train['class']\n\n# # creating the training and validation set\n# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)","4118b5f7":"[Tutorial Link](https:\/\/www.analyticsvidhya.com\/blog\/2019\/09\/step-by-step-deep-learning-tutorial-video-classification-python\/)","9b4089fb":"Imports installations etc","0b63425a":"Training","dbf90b7a":"Convert videos to images, so we can actually work with them","d846cb37":"Build dataset from frames"}}