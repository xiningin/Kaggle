{"cell_type":{"9d8be074":"code","ffc9ff5a":"code","ba6c26d6":"code","d461fd9e":"code","d27cbb20":"code","552da887":"code","b01247de":"code","ce35bc64":"markdown","8ea6c61b":"markdown","e2851c38":"markdown","b13aec87":"markdown","6f5d4fb0":"markdown","308487ba":"markdown","70293d20":"markdown","9fb7d127":"markdown","3846fb64":"markdown"},"source":{"9d8be074":"# Import libraries necessary for this project\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncolumn_names = [\n    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', \n    'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', \n    'LSTAT', 'MEDV'\n]\n\nboston_data = pd.read_csv('..\/input\/boston-house-prices\/housing.csv', \n                          header=None, \n                          delimiter=r\"\\s+\", \n                          names=column_names)","ffc9ff5a":"#creating a correlation matrix\ncorrelations = boston_data.corr()\nsns.heatmap(correlations, square=True, cmap=\"YlGnBu\")\n\nplt.yticks(rotation=0)\nplt.xticks(rotation=90)\n\nplt.show()","ba6c26d6":"boston_data.hist(bins=10, figsize=(9,7), grid=False);","d461fd9e":"import sklearn\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import train_test_split\n\n# Translating our data into arrays for processing.\nx = np.array(boston_data.drop(['MEDV'], axis=1))\ny = boston_data['MEDV'].values\n\n# Train\/test split for validation.\nx_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=42)\n\n# Our Model\nlr = Ridge(alpha=0.5)\nlr.fit(x_train, y_train)","d27cbb20":"from sklearn.metrics import r2_score\n\nr2_score(lr.predict(x_test), y_test)","552da887":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.autograd as autograd\n\nbatch_size = 50\nnum_epochs = 250\nlearning_rate = 0.001\nhidden_size = 64\nbatch_no = len(x_train) \/\/ batch_size\ninput_dim = x.shape[1]\n\n# Use a single hidden layer NN.\nmodel = nn.Sequential(\n    nn.Linear(input_dim, hidden_size),\n    nn.ReLU(),\n    nn.Linear(hidden_size, hidden_size),\n    nn.ReLU(),\n    nn.Linear(hidden_size, 1)\n)\n\n# Use mean squared error loss.\nloss = nn.MSELoss(reduce='mean')\n\n# Use Adam to optimize our NN.\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","b01247de":"running_loss = 0\n\nfor epoch in range(num_epochs):\n    for i in range(402):\n        start = i\n        end = start + 1\n        \n        x_batch = autograd.Variable(torch.FloatTensor(x_train[start:end]))\n        y_batch = autograd.Variable(torch.FloatTensor(y_train[start:end]))\n                \n        y_pred = model(x_batch)\n        \n        loss_step = loss(y_pred, torch.unsqueeze(y_batch, dim=1))\n        optimizer.zero_grad()\n        loss_step.backward()\n        optimizer.step()\n        running_loss += loss_step.item()\n    \n    print(\"Epoch {}, Loss: {}. Validation R2: {}\".format(\n        epoch + 1, running_loss, r2_score(model(torch.Tensor(x_test)).detach().numpy(), y_test)))\n    running_loss = 0.0","ce35bc64":"# EDA\n\nWe will be using the famous Boston housing pricing data. Having 506 data points, the dataset is famously small. I will be constructing both a linear model, using Scikit-Learn; and a neural network using PyTorch. Chollet constructs a neural network using Keras. My model has comparable performance.\n\nBut first, let us have a quick look at the data.","8ea6c61b":"First, let us have a look at the","e2851c38":"First, let us build a linear model. Due to the large number of parameters relative to number of training examples, I will be using Ridge regression.","b13aec87":"# Building Our Neural Network","6f5d4fb0":"So, this is based off a simple example from the book \"Deep Learning with Python,\" by Francois Chollet. Chollet himself is a scientist at Google Brain, and the creator of Keras. This is a fantastic book on getting started with using Keras for deep learning purposes, if you haven't read it yet.\n\nRecently, however, I have been using PyTorch. Anytime I have to build something more complicated from scratch, I find PyTorch provides a much easier framework to work with. It also is a much more Pythonic library, making it feel like a much more natural extension of Python.","308487ba":"Also, taking a look at various histograms.","70293d20":"It should be noted that even though I'm getting, fairly significant improvements, there are two downsides to this approach.\n\n1. Some more training time was needed. However, this was not a huge issue in this case. On a CPU this was trained in about 30 seconds.\n2. More time was taken on my end to tweak all the addition parameters.","9fb7d127":"# Linear Model","3846fb64":"Now, let us build our neural network. I will be using two latent layers of neurons, as you can see below from the code. Some tweaking was done on my end to achieve good performance."}}