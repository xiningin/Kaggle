{"cell_type":{"1685c4ab":"code","d9fd8409":"code","089c0432":"code","3d432b58":"code","7a6c53e1":"code","c5b118bb":"code","1987f3bc":"code","8f527f89":"code","2a690dda":"code","57000a0b":"code","4aeea6ec":"code","88756cc5":"code","0a588ab5":"code","bfc0d385":"code","c503fc38":"code","0537a294":"code","52a5403f":"code","6db34a8e":"code","8aa4971d":"code","45c616d5":"code","ea6db75b":"code","8e188343":"code","b9b39f21":"code","467acbe8":"code","2b452df7":"code","aaceb580":"code","16f98d91":"code","6011ff13":"code","ba81bcf4":"code","028fc058":"code","700c4f9b":"code","91f0629e":"code","23fb6b0e":"code","ed054df7":"code","bab9ce52":"code","93c41e43":"code","c632a37d":"code","841f3ff7":"markdown","0ea027b5":"markdown","bd185b76":"markdown","ca8063b9":"markdown","485e627e":"markdown","19acc13f":"markdown","71c29e94":"markdown","e6a6bd83":"markdown","61a3418f":"markdown","32fd18eb":"markdown","7c6c9c9d":"markdown","c1a1db12":"markdown","0c5ed5bb":"markdown","9916e713":"markdown","dcb47d4b":"markdown","1758befc":"markdown","768f0e9d":"markdown","4eb79316":"markdown","d8e1bcc8":"markdown","68203c70":"markdown","e6e8e761":"markdown","2ccd08a2":"markdown","f99dc9eb":"markdown","6ece1708":"markdown","2f6a90de":"markdown","0f30a996":"markdown","0d58e863":"markdown","ecc16dd2":"markdown","aacb5d81":"markdown","c00d9a0d":"markdown","6041984f":"markdown","78121f41":"markdown","6fb614b3":"markdown","62f6cbc2":"markdown","32d9aab2":"markdown","f8639c7f":"markdown","2dc308d3":"markdown","740bf991":"markdown","84fcea5c":"markdown","759f8aa8":"markdown","5376576f":"markdown","68018dc1":"markdown","9e1baf12":"markdown","909f81b9":"markdown","86289c6b":"markdown","2d76fc4b":"markdown","72085247":"markdown","05f808bc":"markdown","382a82f5":"markdown","c93a1628":"markdown","d73eb5ef":"markdown","69b0e2bf":"markdown","2dfd720d":"markdown"},"source":{"1685c4ab":"from collections import defaultdict\nfrom folium import plugins, Icon, Map, Marker, Circle\nfrom folium.plugins import MarkerCluster, HeatMap\nfrom geopy import distance\nfrom matplotlib import cm\nfrom matplotlib import colors as pltcolors\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nimport numpy as np\nimport pandas as pd\nfrom random import sample\nimport scipy.stats as ss\nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.cluster import DBSCAN, OPTICS\nfrom sklearn.preprocessing import RobustScaler\n%matplotlib inline\nplt.style.use('seaborn-dark')","d9fd8409":"df = pd.read_csv('..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')\ndf.head()","089c0432":"print(\"Number of rows:%d\" % df.shape[0])\nprint(\"Number of cols:%d\" % df.shape[1])","3d432b58":"df.info()","7a6c53e1":"df['last_review'] = pd.to_datetime(df['last_review'])","c5b118bb":"df.nunique()","1987f3bc":"df.isna().sum()","8f527f89":"df[df['number_of_reviews'] == 0 & df['last_review'].isna() & df['reviews_per_month'].isna()].shape[0]","2a690dda":"df['reviews_per_month'].fillna(0, inplace=True)\ndata = df.drop(['last_review'], axis=1)","57000a0b":"names_count = df['name'].value_counts()\nprint(\"There's a total of %d unique names\" % names_count.gt(1).sum())\nnames_count.head(10)","4aeea6ec":"names_count = df['host_name'].value_counts()\nprint(\"There's a total of %d unique host names\" % names_count.gt(1).sum())\nnames_count.head(10)","88756cc5":"data.drop(['name', 'host_name'], inplace=True, axis=1)","0a588ab5":"data.describe(include='all')","bfc0d385":"cols = np.concatenate([data.columns.values[2:4], data.columns.values[6:]])\ncorr_matrix = data[cols].corr()\nplt.figure(figsize=(10, 6))\ng = sns.heatmap(corr_matrix, annot=True,\n        xticklabels=corr_matrix.columns,\n        yticklabels=corr_matrix.columns)","c503fc38":"def cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2\/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))\/(n-1))\n    rcorr = r-((r-1)**2)\/(n-1)\n    kcorr = k-((k-1)**2)\/(n-1)\n    return np.sqrt(phi2corr\/min((kcorr-1),(rcorr-1)))\n\ncramers_dict = defaultdict(lambda: defaultdict())\ncols_len = len(cols)\nfor i, coli in enumerate(cols):\n    cramers_dict[coli][coli] = 1\n    for j in range(i+1, cols_len):\n        colj = cols[j]\n        c = cramers_v(data[coli], data[colj])\n        cramers_dict[coli][colj] = c\n        cramers_dict[colj][coli] = c\ndf_cramers = pd.DataFrame.from_dict(cramers_dict)\nplt.figure(figsize=(12, 8))\nax = sns.heatmap(df_cramers, annot=True)","0537a294":"import math\nfrom collections import Counter\nimport scipy.stats as ss\n\ndef conditional_entropy(x,y):\n    # entropy of x given y\n    y_counter = Counter(y)\n    xy_counter = Counter(list(zip(x,y)))\n    total_occurrences = sum(y_counter.values())\n    entropy = 0\n    for xy in xy_counter.keys():\n        p_xy = xy_counter[xy] \/ total_occurrences\n        p_y = y_counter[xy[1]] \/ total_occurrences\n        entropy += p_xy * math.log(p_y\/p_xy)\n    return entropy\n\ndef theil_u(x,y):\n    s_xy = conditional_entropy(x,y)\n    x_counter = Counter(x)\n    total_occurrences = sum(x_counter.values())\n    p_x = list(map(lambda n: n\/total_occurrences, x_counter.values()))\n    s_x = ss.entropy(p_x)\n    if s_x == 0:\n        return 1\n    else:\n        return (s_x - s_xy) \/ s_x\n    \ntheil_dict = defaultdict(lambda: defaultdict())\ncols_len = len(cols)\nfor i, coli in enumerate(cols):\n    theil_dict[coli][coli] = 1\n    for j in range(i+1, cols_len):\n        colj = cols[j]\n        c = theil_u(data[coli], data[colj])\n        theil_dict[coli][colj] = c\n        theil_dict[colj][coli] = c\ndf_theil = pd.DataFrame.from_dict(theil_dict)\nplt.figure(figsize=(12, 8))\nax = sns.heatmap(df_theil, annot=True)","52a5403f":"g = sns.pairplot(data.drop(['id', 'host_id', 'neighbourhood', 'latitude', 'longitude'], axis=1), hue=\"neighbourhood_group\")","6db34a8e":"pd.crosstab(data['room_type'], data['neighbourhood_group'], margins=True)\npd.pivot_table(data, \n               index=['neighbourhood_group', 'room_type'], \n               values=['price', 'number_of_reviews', 'reviews_per_month', 'minimum_nights', 'availability_365'],\n               aggfunc=np.mean).round(2)","8aa4971d":"g = pd.crosstab(data['neighbourhood_group'], data['room_type']).plot.bar(figsize=(12,8))","45c616d5":"pd.crosstab(data['room_type'], data['neighbourhood_group'], values=data['price'], aggfunc='mean')","ea6db75b":"g = pd.crosstab(data['neighbourhood_group'], data['room_type'], values=data['price'], aggfunc='mean').plot.bar(figsize=(12,8))","8e188343":"top = 10\ncols = 2\nrows = 3\nngroups = data['neighbourhood_group'].unique()\nall_colors = [k for k,v in pltcolors.cnames.items()]\n\ndef random_colors(n_items: int):\n    return sample(all_colors, n_items)\n\ndef plot_neighboorhood_pie(ntotals, ng, i):\n    plt.subplot(3, 2, i+1)\n    labels = [''] * (top + 1)\n    ax = ntotals.plot.pie(autopct='%1.1f%%', labels=labels, colors=random_colors(top + 1))\n    plt.legend(labels=ntotals.index, loc=0, bbox_to_anchor=(1,0.75), title=\"Top neighboorhoods in %s\" % ng)\n    l = plt.xlabel(ng, fontsize=18)\n    plt.ylabel('')\n\ndef get_totals(ng):\n    totals = data[data['neighbourhood_group'] == ng]['neighbourhood'].value_counts()\n    top_results = totals[:top]\n    others = totals[top:]\n    top_results['Other neighborhoods (%d)' % (len(others))] = sum(others)\n    return top_results\n     \nfig = plt.figure(figsize=(20, 25))\nfig.subplots_adjust()\nfor i, ng in enumerate(ngroups):\n    totals = get_totals(ng)\n    plot_neighboorhood_pie(totals, ng, i)","b9b39f21":"def get_center(points):\n    \"\"\"\n    Given a dataframe, calculate and return the center.\n    \"\"\"\n    return[points['latitude'].mean(), points['longitude'].mean()]\n\n# Default zoom for the maps.\nzoom = 12\n\n# When displaying more markers than this threshold, start using clusters for grouping.\ncluster_threshold = 50\n\n\ndef icon_for_room(room_type) -> Icon:\n    \"\"\"\n    Create an icon based on the room type. Using different icons help distinguishing the\n    different places by their room type.\n    \"\"\"\n    if room_type == 'Entire home\/apt':\n        return Icon(icon='home', color='purple')\n    if room_type == 'Private room':\n        return Icon(icon='building', prefix='fa', color='green')\n    return Icon(icon='bed', prefix='fa')\n\n\ndef create_heatmap(points):\n    \"\"\"\n    Create a heatmap for the given points.\n    \"\"\"\n    hmap = Map(location=get_center(points), zoom_start=zoom)\n    llpairs = [[latitude, longitude] for latitude, longitude in zip(points['latitude'], points['longitude'])]\n    hmap.add_child(HeatMap(llpairs))\n    return hmap\n\n\ndef plot_points_within_radius(points, center, label, radius):\n    \"\"\"\n    Plot all the points within a radius from a center.\n    \"\"\"\n    radius = radius * 1609\n    pmap = Map(center, zoom_start=zoom)\n    pmap.add_child(Circle([center[0], center[1]], radius=radius, popup=label, fill_color='#d6e9ff', fill_opacity=0.6))\n    zpoints = zip(points['latitude'], points['longitude'], points['name'], points['price'], points['room_type'])\n    for latitude, longitude, name, price, room_type in zpoints:\n        point = Marker(popup=\"%s ($%.2f)\" % (name, price), location=[latitude, longitude], icon=icon_for_room(room_type))\n        pmap.add_child(point)\n    pmap.add_child(Marker(popup=label, location=[center[0], center[1]], icon=Icon(icon='university', prefix='fa', color='darkblue')))\n    return pmap\n\n\ndef plot_in_map(points):\n    \"\"\"\n    Plot the given points in a map with a different icon depending on the room type.\n    \"\"\"\n    center = get_center(points)\n    pmap = Map(center, zoom_start=zoom)\n    container = pmap\n    if len(points) > cluster_threshold:\n        cluster = MarkerCluster()\n        pmap.add_child(cluster)\n        container = cluster\n    zpoints = zip(points['latitude'], points['longitude'], points['name'], points['price'], points['room_type'])\n    for latitude, longitude, name, price, room_type in zpoints:\n        point = Marker(popup=\"%s ($%.2f)\" % (name, price), location=[latitude, longitude], icon=icon_for_room(room_type))\n        container.add_child(point)\n    return pmap","467acbe8":"top50 = df[(df['availability_365'] == 365) & (df['neighbourhood_group'] == 'Manhattan')].sort_values(by='price').iloc[:50]\nplot_in_map(top50)","2b452df7":"shared_rooms_one_night = data[(data['room_type'] == 'Shared room') & (data['minimum_nights'] == 1)]\nreview_per_month_mean = shared_rooms_one_night['reviews_per_month'].mean()\n\npoints = shared_rooms_one_night[shared_rooms_one_night['reviews_per_month'] > review_per_month_mean]\n\ncreate_heatmap(points)","aaceb580":"madison_square_garden = (40.750298, -73.993324)\n\ndef closer_than_distance(point_a, point_b, radius):\n    return distance.distance(point_a, point_b).mi < radius\n\ndef points_within_radius(points, center, radius):\n    return points[points.apply(lambda p: closer_than_distance(center, (p['latitude'], p['longitude']), radius), axis=1)]\n\n\npoints = df[(df['price'] < 75)]\nradius = 1\npoints_in_radius = points_within_radius(points, madison_square_garden, radius)\n\nplot_points_within_radius(points_in_radius, madison_square_garden, \"Madison Square Garden\", radius)","16f98d91":"ocols = ['price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count']\ndata[ocols].quantile([.25, .5, .75, .98, .99, 1])","6011ff13":"def plot_densities_and_get_outliers(col: str, threshold: int):\n    \"\"\"\n    This function display the boxplot, violin plot, density and z-core\n    for the selected feature, returning those places where the z-score\n    is larger than a given threshold.\n    \"\"\"\n    fig = plt.figure(figsize=(16, 16))\n    fig.subplots_adjust()\n    df_col = df[col]\n    plt.subplot(2, 2, 1)\n    sns.boxplot(x = df_col)\n    plt.subplot(2, 2, 2)\n    ax = df_col.hist()\n    ax.set_xlabel(col)\n    z = np.abs(ss.stats.zscore(df_col))\n    plt.subplot(2, 2, 3)\n    ax = pd.Series(z).plot.kde()\n    ax.set_xlabel(\"z-score %s\" % col)\n    plt.subplot(2, 2, 4)\n    ax = sns.violinplot(df_col)\n    return data.iloc[np.where(z > threshold)].sort_values(by=col, ascending=False)","ba81bcf4":"plot_densities_and_get_outliers('price', 3)","028fc058":"quantiles = data['price'].quantile([.98, .99])\nfor i, q in quantiles.items():\n    print('Places above the %dth quantile (%.2f): %d' % (i*100, q, data[data['price'] > q].shape[0]))","700c4f9b":"plot_densities_and_get_outliers('minimum_nights', 3)","91f0629e":"plot_densities_and_get_outliers('number_of_reviews', 3)","23fb6b0e":"plot_densities_and_get_outliers('reviews_per_month', 3)","ed054df7":"plot_densities_and_get_outliers('calculated_host_listings_count', 3)","bab9ce52":"\"\"\"\nmin_pts = int(np.log(data.shape[0]))\nepsilon = 0.75\nprices = data['price']\n\nrs_prices = RobustScaler().fit_transform(prices.values.reshape(-1, 1))\ndb = DBSCAN(min_samples=min_pts, eps=epsilon).fit(rs_prices)\nbool_labels = [True if l == -1 else False for l in db.labels_]\nprice_outliers = df[bool_labels]\n\"\"\"","93c41e43":"\"\"\"\nclusters = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)\nprint('Number of clusters: %d' % clusters)\nprint('Number of outliers: %d' % price_outliers.shape[0])\nprice_outliers.head()\n\"\"\"","c632a37d":"\"\"\"\nwith np.errstate(divide='ignore'):\n    clustering = OPTICS(min_samples=min_pts, eps=epsilon).fit(rs_prices)\nbool_labels = [True if l == -1 else False for l in clustering.labels_]\nprice_outliers = df[bool_labels]\nprint('Number of outliers: %d' % price_outliers.shape[0])\nprice_outliers.head()\n\"\"\"","841f3ff7":"#### Average price for room types in each neighboorhod group","0ea027b5":"## Data Visualization","bd185b76":"#### Room type distribution by neighborhood group","ca8063b9":"### Missing Data","485e627e":"Null values for **name** and **host_name** are most likely irrelevant to our analysis. We have **10052** places that have *NaN* in **last_review** and **reviews_per_month**. One could guess that probably this is due to those places not being ever reviewed. So, it's worth checking if the number of the places with **0** reviews that also have null values for these two columns is the same.","19acc13f":"## Univariate Outliers Detection","71c29e94":"#### Pearson Correlation","e6a6bd83":"#### DBSCAN","61a3418f":"#### Mean values in each neighborhood split by room type.","32fd18eb":"### Density, z-score and other metrics on selected features","7c6c9c9d":"#### All places within 1-mile radius from the Madison Square Garden for less than $75","c1a1db12":"#### Minimum Nights","0c5ed5bb":"Let's start by getting the sum of null values for each column.","9916e713":"To have a look at the results:","dcb47d4b":"Let's use different methods and techniques to determine the association and correlation (if any) between the different columns.","1758befc":"#### Price","768f0e9d":"### Plotting places in the NY map","4eb79316":"Great! These two columns are empty only when the given place hasn't been reviewed. So, it's safe to fill **reviews_per_month** with **0**. We'll also drop the **last_review** column.\nAs we start dropping columns, we'll create a second dataset so we can keep the original with all the values in case we need to check something.","d8e1bcc8":"Finally, we'll take a look at a couple of non-parametric techniques, DBSCAN and its extension, OPTICS. We'll choose `minPts = ln(N) = 10` and `eps = 0.75`.\nUnfortunately, due to resource allocation restrictions, we are not allowed to run the next two methods. However, I leave the code in case it proves useful to you.","68203c70":"### Measuring association","e6e8e761":"## Reading and exploring the data","2ccd08a2":"#### Reviews per Month","f99dc9eb":"#### Columns, types and non-null numbers","6ece1708":"### Knowing what we are dealing with","2f6a90de":"We can see that **last_review**, which should be a date, is represented by a string. Let's correct that (although we'll end up discarding this column as it contains too many null values).","0f30a996":"Although both, **name** and **host_name** are irrelevant to our analysis and we'll end up dropping these two columns, it might be worth spending a couple of minutes studying them. The detection of abnormal occurrences may help improve the data collection process in the future. It coul also prove useful in some real-life studies.\n\nOne odd thing is that the number of unique names (47905) doesn't match the number of records (and unique ids), 48895. So, let's find those duplicates.","0d58e863":"#### Theil's U Uncertainty Coefficient","ecc16dd2":"#### Shared Rooms having reviews per month above the mean, where one can stay for the night (Heatmap)","aacb5d81":"#### name and host_name","c00d9a0d":"#### OPTICS","6041984f":"Having no more use for these columns, let's remove them from the dataset.","78121f41":"We'll now proceed to work with box plot, violin plot densities and z-scores. The table lists all the places which stand farther than 3 std away from the mean.","6fb614b3":"#### Top 50 Cheapest places in Manhattan availables 365","62f6cbc2":"Some of the methods used above are parametric and assume that the values fall under certain distribution.","32d9aab2":"Let's check how many places with a price above the .98th quantile and 99th.\n","f8639c7f":"### Some stats","2dc308d3":"#### Size of the dataset","740bf991":"Here's something that doesn't make much sense to me. The number of different **host_id** values matches the number of records in the dataset. This can only mean that no host has more than one place listed. However, we have a **calculated_host_listings_count** which contains the number of listings per host, that thanks to the *unique* counts, we can see that has multiple values. We'll take a closer look at this later. ","84fcea5c":"#### Number of Reviews","759f8aa8":"#### Calculated Host Listings Count","5376576f":"#### Cramer's V measure of association","68018dc1":"Before looking at each feature individually, let's print the quantiles including the 98th and 99th quantile.","9e1baf12":"#### Top 10 neighborhoods with most listed places in each group","909f81b9":"We can see a similar situation for **host_id** and **host_name**, given that we have 37457 different **host ids**, but only 11452 unique **host names**.","86289c6b":"### Non-parametric methods","2d76fc4b":"From the previous table we can detect some possible outliers. For instance, the max value for **minimum_nights** is 1250, which doesn't seem right (I have problems believing that you are required to stay at least almost 3.5 years in a place). Another example could be **calculated_host_listings_count**, for which is tha max value is 327. It doesn't seem possible that a host have 327 different available places across the city. Other columns, such as **price**, **reviews_per_month** also have suspicious max values, especially when factoring in the 75th percentile and the *mean*.","72085247":"### Distribution of Room Types per Neighborhood Group","05f808bc":"#### Looking at unique values","382a82f5":"#### last_review and reviews_per_month","c93a1628":"### Loading the dataset","d73eb5ef":"# EDA - New York City Airbnb 2019","69b0e2bf":"Finally, we plot the relationship between features when grouped by neighborhood group.","2dfd720d":"So, as we can see, associations and correlations are pretty low across the board. The most relevant values correspond with expected relationships, such as:\n* **Number of reviews** and **reviews per month**: it's expected that the most reviewed places also receive the highest number of reviews per month. \n* **Room type** and **price**: it's no surprise that the price of a place is driven in some way by its room type.\n\nHowever, we can also find some weak associations such as:\n\n* **neighborhood** and **room type** (from Cramer's V): it's interesting (and possibly useful) to note that the neighborhood might somewhat determine the room type in the area.\n* **reviews per month** and **availability** (from Theil's U): it's also not entirely unexpected that the places with a higher availability also receive a larger number of reviews per month.\n* **Host Listings Count** and **price** \/ **room type** \/ **availability**: focusing on these numbers could be useful to study how the hosts with a stronger position in the market behave."}}