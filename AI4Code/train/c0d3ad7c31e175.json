{"cell_type":{"90259ff0":"code","cd243052":"code","0802d9b0":"code","20416e24":"code","05be53e0":"code","a8faed4b":"code","37a91e65":"code","703ba581":"code","d0be42e1":"code","928dc0c5":"code","93165145":"code","b4da1b46":"code","e0fd0be4":"code","aeee7e78":"code","54ba7e28":"code","a34a342d":"code","3a5ec77b":"code","3554234f":"code","e5f80829":"code","c87167fd":"code","3fd9b20b":"code","539e1dbb":"code","40fc66ac":"markdown","60778b4d":"markdown","818c190d":"markdown","f28f0aec":"markdown","ed79a0cc":"markdown","64d07d03":"markdown","d9c6ffb0":"markdown","4767e6e5":"markdown","6401493c":"markdown","5ab4ce4a":"markdown","f40db0a0":"markdown","c76cb163":"markdown","a37b377b":"markdown","fe127376":"markdown"},"source":{"90259ff0":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport zipfile\nfrom zipfile import ZipFile\nimport PIL\nimport pathlib\nimport sklearn\n\n# Deep Learning libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image_dataset_from_directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cd243052":"base_dir = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\"\ntrain_dir = os.path.join(base_dir, \"Train\")\nvalidation_dir = os.path.join(base_dir, 'Validation')\ntest_dir = os.path.join(base_dir, \"Test\")","0802d9b0":"# For Image Augmentation: Generate instance of ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=20,\n                                   horizontal_flip=True,\n                                   zoom_range=0.3,\n                                   fill_mode=\"nearest\")\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","20416e24":"# Creating the dataset of augmented images: Images get augmented only during training\n# This will be passed to the model.fit() during training for using the augmented images\n\ntrain_dataset = train_datagen.flow_from_directory(train_dir,\n                                                  target_size=(160,160),\n                                                  batch_size=128,\n                                                  class_mode=\"binary\")\n\nvalidation_dataset = test_datagen.flow_from_directory(validation_dir,\n                                                      target_size=(160, 160),\n                                                      batch_size=128,\n                                                      class_mode=\"binary\")\ntest_dataset = test_datagen.flow_from_directory(test_dir,\n                                                target_size=(160, 160),\n                                                batch_size=128,\n                                                class_mode=\"binary\")","05be53e0":"# 0 -- With Mask \/\/\/\/ 1 -- Without Mask\nclass_names = ['WithMask', 'WithoutMask']\n\n# Selects some images from the train_dataset (Iterator object)\nimages,labels = next(iter(train_dataset))\n\n# Plots the images\nplt.figure(figsize=(10,10))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.imshow(images[i])\n    plt.xticks([])\n    plt.yticks([])\n    if (labels[i]==1.0):plt.xlabel(class_names[1])\n    elif (labels[i]==0.0): plt.xlabel(class_names[0])\n    \n\nplt.show()","a8faed4b":"image_size = (160,160)\n\n# Load the model that we want --- VGG19\nbase_model = keras.applications.VGG19(include_top=False,\n                                            weights='imagenet',\n                                            input_shape=image_size+(3,))\n# Freeze all layers\nbase_model.trainable = False","37a91e65":"base_model.summary()","703ba581":"# Visualize the model\n\nkeras.utils.plot_model(base_model, show_shapes=True)","d0be42e1":"model = keras.Sequential([\n      base_model,\n      keras.layers.Flatten(),\n      keras.layers.Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer=keras.optimizers.Adam(), \n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])\n\nmodel.summary()","928dc0c5":"keras.utils.plot_model(model, show_shapes=True)","93165145":"history = model.fit(train_dataset,\n          batch_size=128,\n          epochs=5,\n          validation_data=validation_dataset)","b4da1b46":"# Plotting the accuracy and losses \n\ndfinit = pd.DataFrame(history.history)\ndfinit.plot(figsize=(8,8))\nplt.show()","e0fd0be4":"# Another plot \n\ndef plot_graph(history, word):\n  plt.plot(history.history[word])\n  plt.plot(history.history['val_'+word])\n  plt.xlabel('Epochs')\n  plt.ylabel(word)\n  plt.legend([word, 'val_'+ word])\n  plt.show()\n\nplot_graph(history, 'binary_accuracy')\nplot_graph(history, 'loss')","aeee7e78":"# Check the number of layers in the base model (VGG19)\nlen(base_model.layers)","54ba7e28":"# Unfreeze all the layers\nbase_model.trainable = True\n\n# Freeze the bottom layers\nfor layer in base_model.layers[:18]:\n  layer.trainable = False","a34a342d":"model.summary()","3a5ec77b":"model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])\n\n# Resuming training from the last epoch\ntotal_epochs = 10\nhistory_fine = model.fit(train_dataset,\n                         batch_size=128,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=validation_dataset)","3554234f":"df_fine = pd.DataFrame(history_fine.history)\ndf_fine.plot(figsize=(8,8))\nplt.show()","e5f80829":"# Take a look at the losses and accuracy values\n\ndf_fine.head()","c87167fd":"# Plot different graphs \n\ndef plot_graph(history, word):\n  plt.plot(history.history[word])\n  plt.plot(history.history['val_'+word])\n  plt.xlabel('Epochs')\n  plt.ylabel(word)\n  plt.legend([word, 'val_'+ word])\n  plt.show()\n\nplot_graph(history_fine, 'binary_accuracy')\nplot_graph(history_fine, 'loss')","3fd9b20b":"loss,accuracy = model.evaluate(test_dataset)\nprint(\"Loss: \", loss)\nprint(\"Accuracy: \", accuracy*100)","539e1dbb":"# To save the model if you want\n\nmodel.save(\"VGG19-facemask.h5\")","40fc66ac":"## Compile & run the model","60778b4d":"## ***Fine Tuning the model***","818c190d":"# ***The model shows a very low loss & 99.697% accuracy***","f28f0aec":"## ***Evaluate the model on test set(Unseen data)***","ed79a0cc":"## ***Make train, test & validation sets***","64d07d03":"### ***Initial training for model***: This helps the new layers to adjust; according to the trained weights","d9c6ffb0":"# ***Face Mask Detection: VGG19 (using Transfer Learning)***","4767e6e5":"## ***Transfer Learning: Using VGG19 model***","6401493c":"## ***This is the power of Transfer Learning, we can train models with pretrained weights and achieve great results***","5ab4ce4a":"## ***Adding a top to the base VGG19 model***","f40db0a0":"## ***Upvote if you like the notebook***\n## ***Happy Programming***","c76cb163":"## ***Plotting the losses & accuracy***\n","a37b377b":"## ***Image Augmentation: Using ImageDataGenerator***","fe127376":"## Plot some images"}}