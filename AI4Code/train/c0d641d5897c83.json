{"cell_type":{"567c285f":"code","4a9a0247":"code","523cb014":"code","cf7579b3":"code","5019741b":"code","88480593":"code","fdb56dd1":"code","0795458a":"code","ac913092":"code","ec76feaa":"code","4d5b2a1f":"code","409e731d":"code","b352c114":"code","81a4f960":"code","5ac26118":"code","5f8c0f67":"code","f367b219":"code","def2d459":"code","af467241":"code","14638b4a":"code","c53d852f":"code","f8874450":"code","7ddbdb9a":"code","21bcffdd":"code","f99f73e1":"code","bfb66e70":"code","e064dc6b":"code","bea3e517":"code","ab5dc6f0":"code","efaea554":"code","19e8ab0a":"code","2d05c7ba":"code","e1285eec":"code","6d39bea8":"code","600db9e5":"code","2f6b29cc":"code","4dace462":"code","0126cf7a":"code","8c22b09e":"code","5121f78d":"code","afc5e522":"code","66a12320":"code","8f7a4e92":"code","2adab461":"markdown"},"source":{"567c285f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import model_selection as ms\nimport geopandas as gpd","4a9a0247":"df = pd.read_csv('Melbourne_housing_FULL.csv')\n\ndf.head()","523cb014":"df.shape","cf7579b3":"df.dtypes","5019741b":"df.isnull().sum() \/ len(df) * 100 # percentage of missing values","88480593":"ax = sns.heatmap(abs(df.corr()))\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()","fdb56dd1":"world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nax = world[world.name == 'Australia'].plot(\n    color='white', edgecolor='black')\n\ngdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longtitude, df.Lattitude))\nminx, miny, maxx, maxy = gdf.total_bounds\nax.set_xlabel('Longtitude')\nax.set_ylabel('Lattitude')\ngdf.plot(ax=ax, color='red')\n\nplt.show()","0795458a":"world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nax = world[world.name == 'Australia'].plot(\n    color='white', edgecolor='black')\n\ngdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longtitude, df.Lattitude))\nax.set_xlim(144, 146)\nax.set_ylim(-39, -37)\nax.set_xlabel('Longtitude')\nax.set_ylabel('Lattitude')\ngdf.plot(ax=ax, color='red')\n\nplt.show()","ac913092":"df['Date'] = pd.to_datetime(df['Date'])\ndf['SaleYear'] = df['Date'].dt.year","ec76feaa":"sns.countplot('SaleYear', data=df)","4d5b2a1f":"df.isna().any()","409e731d":"cat = ['Type','Method', 'Regionname','SellerG', 'CouncilArea', 'Postcode'] \nnum = ['Rooms', 'Distance', 'Bathroom', 'Bedroom2', 'Car', 'Landsize', 'BuildingArea'] #'Propertycount', 'SaleYear', 'YearBuilt'\nnum2 =  ['Rooms', 'Distance', 'Bathroom', 'Bedroom2', 'Car', 'BuildingArea','Lattitude','Longtitude', 'Landsize' ] #'Propertycount', 'SaleYear', 'YearBuilt'\ntarget = 'Price'","b352c114":"df.dropna(inplace=True)\ndf.drop(['Date'], axis='columns', inplace=True)\ndf.reset_index()","81a4f960":"df.reset_index().isna().any()","5ac26118":"df_cat = df[cat]\ndf_num = df[num]\n\ny = df[target]\n\ndf_cat","5f8c0f67":"fig, axes = plt.subplots(nrows=7,ncols=1, figsize=(12,50))\n\ni=0\n\nfor col in df_num.columns:\n\n    sns.boxplot(df_num[col], ax=axes[i])\n    \n    i += 1","f367b219":"outliers = []\n\nfor col in df_num.columns:\n    outliers.append(df_num[col].quantile(0.75) + 1.5 * (df_num[col].quantile(0.75) - df_num[col].quantile(0.25)))\n    \n#outliers[7] = (df_num['YearBuilt'].quantile(0.25) - 1.5 * (df_num['YearBuilt'].quantile(0.75) - df_num['YearBuilt'].quantile(0.25)))\n\noutliers_r = list(zip(outliers, df_num.columns))\n\n","def2d459":"df = df.drop(df[df['Landsize'] == 0].index)\ndf = df.drop(df[df['BuildingArea'] == 0].index)\n\nfor whisker, col in outliers_r:\n    if col == 'YearBuilt':\n        df.drop(df[df[col] < whisker].index, inplace=True)\n    else:\n        df.drop(df[df[col] > whisker].index, inplace=True)\n        ","af467241":"\ndf['Rooms'] = df['Bedroom2'] + df['Bathroom']\ndf['SoldAge'] = df['SaleYear'] - df['YearBuilt']\ndf = df[df['SoldAge'] < 50]\ndf = df.drop(df[df['BuildingArea'] > df['Landsize']].index)","14638b4a":"df_cat = df[cat]\ndf_num = df[num2]\n\ny = df[target]\n","c53d852f":"df_catOHEnc = pd.get_dummies(df_cat)\nX = pd.concat([df_num, df_catOHEnc], axis=1).reset_index()\nX.drop(['index'], axis='columns', inplace=True)\n\nprint(X.isna().sum().sum())","f8874450":"world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nax = world[world.name == 'Australia'].plot(\n    color='white', edgecolor='black')\n\ngdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longtitude, df.Lattitude))\nminx, miny, maxx, maxy = gdf.total_bounds\nax.set_xlabel('Longtitude')\nax.set_ylabel('Lattitude')\ngdf.plot(ax=ax, color='red')\n\nplt.show()","7ddbdb9a":"world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nax = world[world.name == 'Australia'].plot(\n    color='white', edgecolor='black')\n\ngdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longtitude, df.Lattitude))\nminx, miny, maxx, maxy = gdf.total_bounds\nax.set_xlabel('Longtitude')\nax.set_ylabel('Lattitude')\nax.set_xlim(144, 146)\nax.set_ylim(-39, -37)\ngdf.plot(ax=ax, color='red')\n\nplt.show()","21bcffdd":"X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.3)","f99f73e1":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix\n\ndef predict_gnb(X_train,X_test,y_train,y_test):\n    \n    clf = GaussianNB()\n    clf.fit(X_train,y_train)\n    \n    \n    y_pred = clf.predict(X_test)  \n    y_true = y_test.values\n    score = clf.score(X_test, y_test)\n    \n    return (y_true,y_pred, score)\n","bfb66e70":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\n\ndef predict_dt(X_train,X_test,y_train,y_test):\n    \n    clf = DecisionTreeClassifier(max_depth=5)\n    clf.fit(X_train,y_train)\n    \n    y_true = y_test.values\n    y_pred = clf.predict(X_test)\n    score = clf.score(X_test, y_test)\n    \n    return (y_true,y_pred, score)\n","e064dc6b":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\n\ndef predict_knn(X_train,X_test,y_train,y_test,k=5):\n    \n    clf = KNeighborsClassifier(n_neighbors=k)\n    clf.fit(X_train, y_train)\n    \n   \n    y_pred = clf.predict(X_test)\n    \n    y_true = y_test.values\n    score = clf.score(X_test, y_test)\n    \n    return (y_true,y_pred, score)\n","bea3e517":"from sklearn.ensemble import RandomForestRegressor\ndef predict_rfr(X_train, X_test, y_train, y_test):\n    rfmodel = RandomForestRegressor(n_estimators = 100, random_state = 7)\n    rfmodel.fit(X_train, y_train)\n    y_pred  = rfmodel.predict(X_test)\n    y_true = y_test.values\n    score = rfmodel.score(X_test,y_test)\n    return (y_true, y_pred, score)","ab5dc6f0":"from sklearn.neighbors import KNeighborsRegressor\n\ndef predict_knreg(X_train, X_test, y_train, y_test):\n    knmodel = KNeighborsRegressor(n_neighbors = 7)\n    knmodel.fit(X_train, y_train)\n    y_pred = knmodel.predict(X_test)\n    y_true = y_test.values\n    score = knmodel.score(X_test,y_test)\n    return (y_true, y_pred, score)","efaea554":"from sklearn import metrics\nfrom sklearn.tree import DecisionTreeRegressor, export_graphviz, export \nfrom sklearn.model_selection import GridSearchCV\n\ndef predict_dtr(X_train, X_test, y_train, y_test):\n    param_grid = {'max_depth': np.arange(3,20)}\n    tree = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=10)\n    tree.fit(X_train,y_train)\n    tree_final = DecisionTreeRegressor(max_depth=7)\n    tree_final.fit(X_train,y_train)\n    y_pred = tree_final.predict(X_test)\n    y_true = y_test.values\n    score = tree_final.score(X_test, y_test)\n    \n    return (y_true, y_pred, score)\n    #print(tree.best_score_)","19e8ab0a":"from sklearn import ensemble\n\ndef predict_ensemble(X_train, X_test, y_train, y_test):\n    clf = ensemble.GradientBoostingRegressor(n_estimators = 100, max_depth = 10, min_samples_split = 2,\n              learning_rate = 0.1, loss = 'ls')\n    clf.fit(X_train,y_train )\n    y_pred = clf.predict(X_test)\n    y_true = y_test.values\n    score = clf.score(X_test,y_test)\n    return (y_true, y_pred,score)\n    \n","2d05c7ba":"from xgboost import XGBRegressor\ndef predict_xgb(X_train, X_test, y_train, y_test, booster= 'gbtree', n_jobs=2):\n    xgb = XGBRegressor(booster = booster , n_jobs = n_jobs, n_estimators=1000, learning_rate=0.05, nthread=10)\n    xgb.fit(X_train, y_train)\n    y_pred = xgb.predict(X_test)\n    y_true = y_test.values\n    score = xgb.score(X_test, y_test)\n    \n    return (y_true, y_pred, score)","e1285eec":"def sigma(x):\n    result = x[0] - x[1]\n    result = result ** 2\n    result = (result.sum() \/ len(x[0]))**(1\/2)\n    \n    return result","6d39bea8":"print('K Neighbour Classifier')\nprint('RMSE', sigma(predict_knn(X_train,X_test,y_train,y_test,k=1)))\nprint('Score', predict_knn(X_train,X_test,y_train,y_test,k=1)[2])\n","600db9e5":"print('K Neighbour Classifier')\nprint('RMSE', sigma(predict_knn(X_train,X_test,y_train,y_test,k=2)))\nprint('Score', predict_knn(X_train,X_test,y_train,y_test,k=2)[2])","2f6b29cc":"print('K Neighbour Classifier')\nprint('RMSE', sigma(predict_knn(X_train,X_test,y_train,y_test,k=3)))\nprint('Score', predict_knn(X_train,X_test,y_train,y_test,k=3)[2])","4dace462":"print('Gaussian Naive Bayes')\nprint('RMSE', sigma(predict_gnb(X_train,X_test,y_train,y_test)))\nprint('Score', predict_gnb(X_train,X_test,y_train,y_test)[2])","0126cf7a":"print('Decision Tree Classifier')\nprint('RMSE', sigma(predict_dt(X_train,X_test,y_train,y_test)))\nprint('Score', predict_dt(X_train,X_test,y_train,y_test)[2])","8c22b09e":"print('K Neighbors Regressor')\nprint('RMSE', sigma(predict_knreg(X_train, X_test, y_train, y_test)))\nprint('Score', predict_knreg(X_train, X_test, y_train, y_test)[2])","5121f78d":"print('Decision Tree Regressor')\nprint('RMSE', sigma(predict_dtr(X_train, X_test, y_train, y_test)))\nprint('Score', predict_dtr(X_train, X_test, y_train, y_test)[2])","afc5e522":"print('Random Forest Regressor')\nprint('RMSE', sigma(predict_rfr(X_train, X_test, y_train, y_test)))\nprint('Score', predict_rfr(X_train, X_test, y_train, y_test)[2])","66a12320":"print('ensemble')\nprint('RMSE', sigma(predict_ensemble(X_train, X_test, y_train, y_test)))\nprint('Score', predict_ensemble(X_train, X_test, y_train, y_test)[2] )","8f7a4e92":"print('XGBoost')\nprint('RMSE', sigma(predict_xgb(X_train, X_test, y_train, y_test, booster= 'gbtree', n_jobs=2)))\nprint('Score', predict_xgb(X_train, X_test, y_train, y_test, booster= 'gbtree', n_jobs=2)[2])","2adab461":"# Outlier Detection"}}