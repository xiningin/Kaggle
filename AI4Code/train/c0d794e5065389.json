{"cell_type":{"2fbde006":"code","20b7e347":"code","6389b95f":"code","9bb3df80":"code","5afc33ec":"code","611245ab":"code","72e3e77d":"code","00a8c71c":"code","66419133":"code","21289475":"code","7fbd80ee":"code","c22d94c6":"code","60cf32d5":"code","b57010c0":"code","e3332b81":"code","dc3a4362":"code","f42998e3":"code","46444ebb":"code","6cc7857e":"code","2a7bd374":"code","90bfb011":"code","70125ea9":"code","1efe1a84":"markdown","6fe6d7be":"markdown","6cd98682":"markdown","e056b519":"markdown","53052e7c":"markdown","8d7fbb95":"markdown","62e9c7df":"markdown","9425a53e":"markdown","2d37556c":"markdown","ad40cf80":"markdown","c5513fe7":"markdown","3dd989b7":"markdown","4fbf7efe":"markdown","3b9193a5":"markdown","8468607b":"markdown","0147cdad":"markdown","9123e334":"markdown","74f784c9":"markdown","866b5f38":"markdown"},"source":{"2fbde006":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# data manipulation\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.utils import shuffle\n\n# feature selection & hyperparameter tuning\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\n\n# ML models\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.svm import SVR","20b7e347":"def preprocess_all_at_once(drop_na_cols = 0, categorical = 0, intercept=False, normalize=False):\n    '''\n    This function handles the preprocessing for this dataset.\n    categorical input:\n        - 0 : Remove categories from input data.\n        - 1 : Leaves categories as is.\n        - 2 : Use one hot encoding on data.\n    drop_na_cols:\n        - 0: Drops columns with NaNs.\n        - 1: Leaves NaNs as is.\n        - 2: Imputes columns with NaNs (if categories left as is, the impute will skip the columns).\n    intercept:\n        - True: Add a y-intercept in the training data.\n        - False: Will not add the y-intercept.\n        \n    The preprocessing includes:\n     - loading in the data (training and testing data)\n     - discards useless features (ones that have a small number of values)\n     - handles categorical data (either drops or encodes)\n     - handles NaNs and Infs (either drops or imputes)\n     - normalizes data\n    '''\n    # load in data\n    x_data = pd.read_csv(\"..\/input\/trainFeatures.csv\")\n    y_data = pd.read_csv(\"..\/input\/trainLabels.csv\")\n    x_test = pd.read_csv(\"..\/input\/testFeatures.csv\")\n    \n    y_data.set_index('ids', inplace=True)\n    x_data.set_index(\"ids\", inplace=True)\n    x_test.set_index('ids', inplace=True)\n    \n    # get rid of the title for the dataframes' indexes\n    del x_data.index.name\n    del y_data.index.name\n    \n    # empty or close-to-empty features\n    useless_features = [\"exclude\", \"ExcludeFromLists\", \"Rpt_Comp_Emp\", \"Incomplete\", \"DonorAdvisoryText\", \n                \"Direct_Support\", \"Indirect_Support\", \"Int_Expense\",\"Depreciation\", \"Assets_45\", \n                \"Assets_46\", \"Assets_47c\", \"Assets_48c\", \"Assets_49\", \"Assets_54\", \"Liability_60\",\n                \"Reader2_Date\", \"StatusID\", \"DonorAdvisoryDate\", \"ResultsID\", \"DonorAdvisoryCategoryID\"]\n\n    # add the categorical data to the features-to-drop list\n    if categorical==0:\n        useless_features.append('erkey')\n        \n    x_data.drop(useless_features, axis=1, inplace=True)\n    x_test.drop(useless_features, axis=1, inplace=True)\n\n    # get rid of rows with no y value in our training data\n    useless_rows = y_data.index[y_data['OverallScore'].isnull()].tolist()\n    x_data.drop(useless_rows, inplace=True)\n    y_data.drop(useless_rows, inplace=True)\n        \n    # one hot encoding increases the number of features to some 2700 features, making it unwieldy.\n    # Therefore if we include it, we will make sure to reduce the feature count using feature selection.\n    if categorical==2:\n        x_data = pd.get_dummies(x_data)\n        x_test = pd.get_dummies(x_test)\n        x_data, x_test = x_data.align(x_test, axis=1, fill_value=0)\n        \n    # deal with missing values\n    if drop_na_cols == 0:\n        missing1 = [col for col in x_data.columns if x_data[col].isnull().any()]\n        missing2 = [col for col in x_test.columns if x_test[col].isnull().any()]\n        cols_with_missing = np.union1d(missing1, missing2)\n\n        x_data.drop(cols_with_missing, axis=1, inplace=True)\n        x_test.drop(cols_with_missing, axis=1, inplace=True)\n        \n    elif drop_na_cols == 2:\n        my_imputer = SimpleImputer()\n        if categorical == 1:\n            categorical_x_data = x_data['erkey']\n            categorical_x_test = x_test['erkey']\n            x_data.drop([\"erkey\"], axis=1, inplace=True)\n            x_test.drop([\"erkey\"], axis=1, inplace=True)\n\n        x_data = pd.DataFrame(my_imputer.fit_transform(x_data), columns = x_data.columns, index=x_data.index)\n        x_test = pd.DataFrame(my_imputer.fit_transform(x_test), columns = x_test.columns, index=x_test.index)\n    \n    # normalize data\n    if normalize:\n        x_data = (x_data - x_data.mean()) \/ x_data.std()\n        x_test = (x_test - x_test.mean()) \/ x_test.std()\n\n        # If a column had 0 variance, the normalization brought it to NaN.\n        # To handle this, we will impute\/drop-NaNs again.\n        # This is a chicken and egg problem, as one hot encoding, imputing, and normalization, each depends on the other.\n        if drop_na_cols != 1:\n            missing1 = [col for col in x_data.columns if x_data[col].isnull().any()]\n            missing2 = [col for col in x_test.columns if x_test[col].isnull().any()]\n            cols_with_missing = np.union1d(missing1, missing2)\n\n            x_data.drop(cols_with_missing, axis=1, inplace=True)\n            x_test.drop(cols_with_missing, axis=1, inplace=True)\n\n    if categorical==1:  # if we leave the categorical data as is, now (after normalization and imputing) we add it back\n        x_data = x_data.join(categorical_x_data)\n        x_test = x_test.join(categorical_x_test)\n            \n    # adding a column of ones for the y-intercept\n    if intercept:\n        x_data.insert(0, 'y-intercept', 1)\n        x_test.insert(0, 'y-intercept', 1)\n        \n    return x_data, y_data, x_test","6389b95f":"def forwardSubsetSelection(model, max_feature_count, x_data, y_data, known_features = []):\n    '''\n    This function performs forward subset selection on x_data when\n    trained with the given 'model'. \n    \n    This model returns the names of the max_feature_count most \n    beneficial features in the data.\n    '''\n    features_to_use = known_features\n    features_not_added = x_data.columns\n    features_not_added.drop(known_features)\n    \n    for i in range(max_feature_count - len(known_features)):\n        best_score = 0\n        best_feature = 0\n        for feature in features_not_added:\n            tmp_features_vec = features_to_use + [feature]\n            cur_score = cross_val_score(model, x_data[tmp_features_vec], y_data, cv=5, n_jobs=-1).mean()\n            if cur_score > best_score:\n                best_score = cur_score\n                best_feature = feature\n        print('Feature number', i+ len(known_features), 'added:', best_feature)\n        features_to_use.append(best_feature)\n        features_not_added.drop(best_feature)\n    return features_to_use","9bb3df80":"lin_reg_model = Ridge()\n\nknown_features = ['AuditedFinancial_status', 'StaffList_Status', 'erkey_er-31529', 'erkey_er-30808', 'erkey_er-31998', 'erkey_er-32426', 'erkey_er-31525', 'Form990_status', 'erkey_er-31238', 'BoardList_Status', 'RatingTableID', 'CNVersion', 'CEO_Salary', 'Fundraising_Expenses', 'Program_Expenses', 'Privacy_Status', 'erkey_er-30284', 'erkey_er-30112', 'erkey_er-30839', 'erkey_er-31310', 'erkey_er-30453', 'erkey_er-31688', 'erkey_er-32312', 'erkey_er-31748', 'erkey_er-30539', 'erkey_er-32449', 'erkey_er-31455', 'erkey_er-31594', 'erkey_er-32517', 'erkey_er-32028', 'erkey_er-32207', 'erkey_er-30905', 'erkey_er-31615', 'erkey_er-31082', 'erkey_er-31676', 'erkey_er-31192', 'erkey_er-31545', 'erkey_er-31767', 'erkey_er-31769', 'erkey_er-31204', 'erkey_er-31892', 'erkey_er-30007', 'erkey_er-32603', 'erkey_er-31509', 'erkey_er-32341', 'erkey_er-30311', 'RatingInterval', 'erkey_er-32420', 'erkey_er-31327', 'erkey_er-30467', 'erkey_er-30774', 'erkey_er-32183', 'erkey_er-31899', 'erkey_er-32488', 'erkey_er-32432', 'erkey_er-30176', 'erkey_er-30958', 'erkey_er-31978', 'erkey_er-32455', 'erkey_er-30734', 'erkey_er-32305', 'erkey_er-30992', 'erkey_er-30890', 'erkey_er-31691', 'erkey_er-31461', 'erkey_er-30327', 'erkey_er-31271', 'erkey_er-32081', 'erkey_er-31617', 'erkey_er-32334', 'erkey_er-32274', 'erkey_er-31404', 'erkey_er-30371', 'erkey_er-31054', 'erkey_er-31019', 'erkey_er-30929', 'erkey_er-31363', 'erkey_er-30415', 'erkey_er-31986', 'erkey_er-30005', 'Total_Liabilities', 'Total_Net_Assets', 'Other_Revenue', 'erkey_er-30094', 'erkey_er-31255', 'erkey_er-31128', 'erkey_er-32297', 'erkey_er-30471', 'erkey_er-32499', 'erkey_er-30534', 'erkey_er-30824', 'erkey_er-32402', 'erkey_er-30609', 'erkey_er-31225', 'erkey_er-31859', 'Total_Expenses', 'Total_Revenue', 'erkey_er-30104', 'erkey_er-30373', 'erkey_er-30173', 'erkey_er-32521', 'erkey_er-32080', 'erkey_er-30928', 'erkey_er-30827', 'erkey_er-31827', 'erkey_er-31572', 'erkey_er-30765', 'erkey_er-32071', 'erkey_er-31966', 'erkey_er-32380', 'erkey_er-30510', 'erkey_er-32032', 'erkey_er-31205', 'Govt_Grants', 'erkey_er-31694', 'erkey_er-32154', 'erkey_er-30426', 'erkey_er-30782', 'erkey_er-32112', 'erkey_er-31444', 'erkey_er-30847', 'erkey_er-32691', 'erkey_er-32093', 'erkey_er-32523', 'erkey_er-31576', 'erkey_er-31924', 'erkey_er-30722', 'erkey_er-32240', 'erkey_er-31552', 'erkey_er-31646', 'MemDues', 'erkey_er-30058', 'erkey_er-31464', 'erkey_er-31138', 'erkey_er-31700', 'erkey_er-31416', 'erkey_er-31418', 'erkey_er-31073', 'erkey_er-31115', 'erkey_er-31290', 'erkey_er-30686', 'erkey_er-32430', 'erkey_er-30185', 'erkey_er-31867', 'erkey_er-30273', 'erkey_er-31156', 'erkey_er-31289', 'erkey_er-31709', 'erkey_er-32555', 'erkey_er-31643', 'erkey_er-31743', 'erkey_er-32306', 'erkey_er-30146', 'erkey_er-30082', 'erkey_er-31173', 'erkey_er-31329', 'erkey_er-32279', 'erkey_er-32457', 'erkey_er-30204', 'erkey_er-31303']\n\n# features_to_use = forwardSubsetSelection(lin_reg_model, 160, x_data, y_data['OverallScore'], known_features)\n# new_x_data = x_data[features_to_use]\n\n# print(cross_val_score(lin_reg_model, new_x_data, y_data['OverallScore'], cv=5, n_jobs=-1).mean())\n# print(features_to_use)","5afc33ec":"def dimensionalityReduce(model, feature_count, x_data, y_data):\n    '''\n    This function performs the TruncatedSVD on a given\n    the given model trained on x_data and y_data. \n    \n    This model returns the names of the max_feature_count most \n    beneficial features in the data.\n    '''\n    svd = TruncatedSVD(n_components=feature_count)  \n    return svd.fit_transform(x_data, y_data)","611245ab":"def searchDimensions(x_data, y_data):\n    '''\n    Given input data to train on, this function runs through\n    all the possible dimensions SVD can reduce x_data's features\n    into and scores them, returning the feature count that achieves\n    the best score through k-fold cross validation.\n    '''\n    feat_count = np.arange(1202,x_data.shape[1])\n    \n    best_count = 0\n    best_score = 0\n    lin_reg_model = Ridge(alpha=575)\n    for count in feat_count:\n        new_x = dimensionalityReduce(lin_reg_model, count, x_data, y_data)\n        tmp_model = Ridge(alpha=575)\n        tmp_score = cross_val_score(tmp_model, new_x, y_data, cv=5, n_jobs=-1).mean()\n        if tmp_score > best_score:\n            best_score = tmp_score\n            best_count = count\n            print('New best dimension: %d, score: %f'%(best_count, best_score))\n    return best_count","72e3e77d":"def cross_val(model, vals, x_data, y_data):\n    '''\n    This function finds the optimal hyperparameter value from\n    the 'vals' list, for the specified 'model' trained on x_data and y_data.\n    '''\n    best_val = 0\n    best_score = 0\n    for val in vals:\n        our_model = model(val)\n        tmp_score = cross_val_score(our_model, x_data, y_data, cv=5, n_jobs=-1).mean()\n        if tmp > best_score:\n            best_score = tmp_score\n            best_val = val\n            print('New best mse: %f for hyperparameter=%f'%(best_score, best_val))\n\n    print('Best value found:', best_val)\n    return best_val","00a8c71c":"# finding optimal n_estimators hyperparameter\nx_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=False, normalize=False)\nx_data, y_data = shuffle(x_data, y_data)\n\n# n_estimators_options = np.arange(170, 250, 5)\n# optimal_random_forest_val = cross_val(RandomForestRegressor, n_estimators_options, x_data, y_data['OverallScore'])","66419133":"# submitting a random forest to output csv file\nx_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=False, normalize=False)\nx_data, y_data = shuffle(x_data, y_data)\n\noptimal_random_forest_val = 172\nrandom_forest_model = RandomForestRegressor(n_estimators=optimal_random_forest_val)\nrandom_forest_model.fit(x_data, y_data['OverallScore'])\nrandom_forest_predictions = random_forest_model.predict(testing_values)\nrandom_forest_output = pd.DataFrame({'Id': list(testing_values.index), 'OverallScore': random_forest_predictions})\nrandom_forest_output.to_csv('random_forest_result.csv', index=False)","21289475":"xgboost_model = XGBRegressor()\n\n# A parameter grid for XGBoost\nparams = {\n            'min_child_weight': [12, 16],\n            'learning_rate': [0.01, 0.03],\n            'gamma': [1, 3],\n            'n_estimators': [600, 800],\n            'colsample_bytree': [0.5, 0.7],\n            'max_depth': [15, 25]\n         }\n\n# clf = GridSearchCV(xgboost_model, params, n_jobs=-1, cv=2, verbose=2, refit=True, return_train_score=True)\n# clf.fit(x_data, y_data['OverallScore'])\n# clf.best_params_","7fbd80ee":"# submitting the xgboost model to output csv file\nx_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=False, normalize=False)\nx_data, y_data = shuffle(x_data, y_data)\n\nxgboost_model = XGBRegressor(colsample_bytree=0.8,  gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=13, n_estimators=1000)\nxgboost_model.fit(x_data, y_data['OverallScore'])\nxgboost_predictions = xgboost_model.predict(testing_values)\nxgboost_output = pd.DataFrame({'Id': list(testing_values.index), 'OverallScore': xgboost_predictions})\nxgboost_output.to_csv('xgboost_result.csv', index=False)","c22d94c6":"x_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=True, normalize=True)\nx_data, y_data = shuffle(x_data, y_data)\n\n# finding optimal alpha hyperparameter\n#alpha_options = np.arange(1, 1000, 5)\n#optimal_ridge_val = cross_val(Ridge, alpha_options, x_data, y_data['OverallScore'])\noptimal_ridge_val = 575","60cf32d5":"# submitting the linear regression model to output csv file\nx_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=True, normalize=True)\nx_data, y_data = shuffle(x_data, y_data)\n\nlin_reg_model = Ridge(alpha=optimal_ridge_val)\nlin_reg_model.fit(x_data, y_data['OverallScore'])\nlin_reg_predictions = lin_reg_model.predict(testing_values)\nlin_reg_output = pd.DataFrame({'Id': list(testing_values.index), 'OverallScore': lin_reg_predictions})\nlin_reg_output.to_csv('lin_reg_result.csv', index=False)","b57010c0":"# using grid search to find the optimal hyperparameters for the SVR model, C and epsilon.\nx_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=True, normalize=True)\nx_data, y_data = shuffle(x_data, y_data)\n\nsvm_model = SVR()\n\n# The parameter grid to grid-search\nparams = {'C': np.arange(0.05, 3, 0.05), 'epsilon': np.arange(0,0.5, 0.005)}\n\n# clf = GridSearchCV(svm_model, params, n_jobs=-1, cv=2, verbose=2, refit=True, return_train_score=True)\n# clf.fit(x_data, y_data['OverallScore'])\n# clf.best_params_","e3332b81":"# submitting the SVR results to output csv file\nx_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=True, normalize=True)\nx_data, y_data = shuffle(x_data, y_data)\n\noptimal_epsilon = 0.825\noptimal_C = 1.9\nsvr_model = SVR(epsilon=optimal_epsilon, C=optimal_C)\nsvr_model.fit(x_data, y_data['OverallScore'])\nsvr_predictions = svr_model.predict(testing_values)\nsvr_output = pd.DataFrame({'Id': list(testing_values.index), 'OverallScore': svr_predictions})\nsvr_output.to_csv('svr_result.csv', index=False)","dc3a4362":"ensemble_predictions = (1\/4)*(lin_reg_predictions+xgboost_predictions+random_forest_predictions+svr_predictions)\nensemble_output = pd.DataFrame({'Id': list(testing_values.index), 'OverallScore': ensemble_predictions})\nensemble_output.to_csv('ensemble_result.csv', index=False)","f42998e3":"ensemble_predictions = (1\/3)*(lin_reg_predictions+xgboost_predictions+random_forest_predictions)\nensemble_output = pd.DataFrame({'Id': list(testing_values.index), 'OverallScore': ensemble_predictions})\nensemble_output.to_csv('ensemble_result2.csv', index=False)","46444ebb":"ensemble_predictions = (1\/2)*(lin_reg_predictions+xgboost_predictions)\nensemble_output = pd.DataFrame({'Id': list(testing_values.index), 'OverallScore': ensemble_predictions})\nensemble_output.to_csv('ensemble_result3.csv', index=False)","6cc7857e":"ensemble_predictions = (1\/2)*(random_forest_predictions+xgboost_predictions)\nensemble_output = pd.DataFrame({'Id': list(testing_values.index), 'OverallScore': ensemble_predictions})\nensemble_output.to_csv('ensemble_result4.csv', index=False)","2a7bd374":"# testing xgboost model\nx_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=True, normalize=False)\nx_data, y_data = shuffle(x_data, y_data)\n\nxgboost_reg = XGBRegressor(colsample_bytree=0.8,  gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=13, n_estimators=1000)\nprint(cross_val_score(xgboost_reg, x_data, y_data['ATScore'], cv=5, n_jobs=-1).mean())","90bfb011":"# testing random forest model\nx_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=False, normalize=False)\nx_data, y_data = shuffle(x_data, y_data)\n\noptimal_random_forest_val=220\nrandomForest = RandomForestRegressor(n_estimators=optimal_random_forest_val)\nprint(cross_val_score(randomForest, x_data, y_data['ATScore'], cv=5, n_jobs=-1).mean())","70125ea9":"# testing linear regression model\nx_data, y_data, testing_values = preprocess_all_at_once(drop_na_cols=2, categorical=2, intercept=True, normalize=True)\nx_data, y_data = shuffle(x_data, y_data)\n\noptimal_ridge_val = 575\nlin_reg = Ridge(alpha=optimal_ridge_val)\nprint(cross_val_score(lin_reg, x_data, y_data['ATScore'], cv=5, n_jobs=-1).mean())","1efe1a84":"#### Truncated Singular Value Decomposition","6fe6d7be":"## Step 5) Finding the ATScore\n\nThe training labels had two scores to predict, the 'ATScore' and the 'Overall Score'.  Although the contest concered only the 'Overall Score', the general class asignment was to find the cross validation score of the 'ATScore' as well. \n\nAlthough we recognize that the hyperparameters found for the contest will not necessarily be optimal for this different scoring label, we will nevertheless use them in our models, due to the lack of time. Also due to our experience with the 4 models we tried above, we will instead only look at the top 3 models (exclude SVR) and due to (again) the lack of time we will only cross validate each one individually.","6cd98682":"### 3c)  Linear Regression Approach\n\nDue to the relatively large amount of features, we have decided to use ridge regression over lasso regression (we are anyways doing feature selection prior to training the model).","e056b519":"Through grid searching the following parameter set were discovered to be good:\n {colsample_bytree=0.8,  gamma=0.5, learning_rate=0.02, max_depth=18, min_child_weight=13, n_estimators=1000}","53052e7c":"Doing feature selection, we got the 30 most important features to be:\n\n['AuditedFinancial_status', 'StaffList_Status', 'erkey_er-31529', 'erkey_er-30808', 'erkey_er-31998', 'erkey_er-32426', 'erkey_er-31525', 'Form990_status', 'erkey_er-31238', 'BoardList_Status', 'RatingTableID', 'CNVersion', 'CEO_Salary', 'Fundraising_Expenses', 'Program_Expenses', 'Privacy_Status', 'erkey_er-30284', 'erkey_er-30112', 'erkey_er-30839', 'erkey_er-31310', 'erkey_er-30453', 'erkey_er-31688', 'erkey_er-32312', 'erkey_er-31748', 'erkey_er-30539', 'erkey_er-32449', 'erkey_er-31455', 'erkey_er-31594', 'erkey_er-32517', 'erkey_er-32028']","8d7fbb95":"As it turns out, our SVR model isn't performing as well as our other models (tested also through cross validation as well as on actual contest submission scores). As a test,  it was discovered that leaving the SVR model out of the 4 model ensemble actually increasted our accuracy. Taking the hint, lets try the 3 and 2 way ensembles that make the most sense:","62e9c7df":"### 3d) SVM (more correctly SVR, as we are dealing with regression)","9425a53e":"### 3a) Random Forest","2d37556c":"Through cross validation above we discovered that n_estimators=220 is the optimal parameter value.","ad40cf80":"When running the 'searchDimensions' function, we got a consistent increase in model accuracy the more dimensions we used. We did this mainly to see if we could improve our results by having less dimensions, each more uncorrelated with the others. In any case, as time is not an issue, we have decided to use the full set of data features in our models below.","c5513fe7":"### 3b) XGBoosted Tree","3dd989b7":"## Step 1) Data preprocessing","4fbf7efe":"Through cross validation above we discovered that alpha=575 is the optimal parameter value.","3b9193a5":"## Step 3) ML Models\n\n\nFirst let us define a function that will be used for cross validation of our simpler models (Linear regression and random forests). Neither of these models require more than 1 hyperparameters and so we will use this function to find the optimal parameter for each:","8468607b":"Through grid searching the following parameter set were discovered to be good:\n {C=1.9, epsilon=0.825}","0147cdad":"## Step 4) Ensemble Learning\n\nWe have our 4 working models. As such, why not combine them, and see if their averaged score is less biased and improves our results?","9123e334":"* 160 best features using forward subset selection:\n\n['AuditedFinancial_status', 'StaffList_Status', 'erkey_er-31529', 'erkey_er-30808', 'erkey_er-31998', 'erkey_er-32426', 'erkey_er-31525', 'Form990_status', 'erkey_er-31238', 'BoardList_Status', 'RatingTableID', 'CNVersion', 'CEO_Salary', 'Fundraising_Expenses', 'Program_Expenses', 'Privacy_Status', 'erkey_er-30284', 'erkey_er-30112', 'erkey_er-30839', 'erkey_er-31310', 'erkey_er-30453', 'erkey_er-31688', 'erkey_er-32312', 'erkey_er-31748', 'erkey_er-30539', 'erkey_er-32449', 'erkey_er-31455', 'erkey_er-31594', 'erkey_er-32517', 'erkey_er-32028', 'erkey_er-32207', 'erkey_er-30905', 'erkey_er-31615', 'erkey_er-31082', 'erkey_er-31676', 'erkey_er-31192', 'erkey_er-31545', 'erkey_er-31767', 'erkey_er-31769', 'erkey_er-31204', 'erkey_er-31892', 'erkey_er-30007', 'erkey_er-32603', 'erkey_er-31509', 'erkey_er-32341', 'erkey_er-30311', 'RatingInterval', 'erkey_er-32420', 'erkey_er-31327', 'erkey_er-30467', 'erkey_er-30774', 'erkey_er-32183', 'erkey_er-31899', 'erkey_er-32488', 'erkey_er-32432', 'erkey_er-30176', 'erkey_er-30958', 'erkey_er-31978', 'erkey_er-32455', 'erkey_er-30734', 'erkey_er-32305', 'erkey_er-30992', 'erkey_er-30890', 'erkey_er-31691', 'erkey_er-31461', 'erkey_er-30327', 'erkey_er-31271', 'erkey_er-32081', 'erkey_er-31617', 'erkey_er-32334', 'erkey_er-32274', 'erkey_er-31404', 'erkey_er-30371', 'erkey_er-31054', 'erkey_er-31019', 'erkey_er-30929', 'erkey_er-31363', 'erkey_er-30415', 'erkey_er-31986', 'erkey_er-30005', 'Total_Liabilities', 'Total_Net_Assets', 'Other_Revenue', 'erkey_er-30094', 'erkey_er-31255', 'erkey_er-31128', 'erkey_er-32297', 'erkey_er-30471', 'erkey_er-32499', 'erkey_er-30534', 'erkey_er-30824', 'erkey_er-32402', 'erkey_er-30609', 'erkey_er-31225', 'erkey_er-31859', 'Total_Expenses', 'Total_Revenue', 'erkey_er-30104', 'erkey_er-30373', 'erkey_er-30173', 'erkey_er-32521', 'erkey_er-32080', 'erkey_er-30928', 'erkey_er-30827', 'erkey_er-31827', 'erkey_er-31572', 'erkey_er-30765', 'erkey_er-32071', 'erkey_er-31966', 'erkey_er-32380', 'erkey_er-30510', 'erkey_er-32032', 'erkey_er-31205', 'Govt_Grants', 'erkey_er-31694', 'erkey_er-32154', 'erkey_er-30426', 'erkey_er-30782', 'erkey_er-32112', 'erkey_er-31444', 'erkey_er-30847', 'erkey_er-32691', 'erkey_er-32093', 'erkey_er-32523', 'erkey_er-31576', 'erkey_er-31924', 'erkey_er-30722', 'erkey_er-32240', 'erkey_er-31552', 'erkey_er-31646', 'MemDues', 'erkey_er-30058', 'erkey_er-31464', 'erkey_er-31138', 'erkey_er-31700', 'erkey_er-31416', 'erkey_er-31418', 'erkey_er-31073', 'erkey_er-31115', 'erkey_er-31290', 'erkey_er-30686', 'erkey_er-32430', 'erkey_er-30185', 'erkey_er-31867', 'erkey_er-30273', 'erkey_er-31156', 'erkey_er-31289', 'erkey_er-31709', 'erkey_er-32555', 'erkey_er-31643', 'erkey_er-31743', 'erkey_er-32306', 'erkey_er-30146', 'erkey_er-30082', 'erkey_er-31173', 'erkey_er-31329', 'erkey_er-32279', 'erkey_er-32457', 'erkey_er-30204', 'erkey_er-31303']\n\nHowever this technique is very time consuming, and so we discontinued this method and turned to a dimensionality reduction technique:","74f784c9":"## Step 2) Feature Selection\n\nWhen one hot encoding, we reach roughly 2700 features, and having only 10000 data points, we should be able to cut the feature count down to a size that is both more efficient computationally and also perhaps even more relevant, giving us better overall results.\n\nWe will try two methods for this: Forward Subset Selection and a sparse implementation of Singular Value Decomposition. Our decision to use TruncatedSVD instead of PCA was because of the great increase in sparcity that resulted from one hot encoding our data.\n\n#### Forward Subset Selection","866b5f38":"### Makeene Learning Kaggle Contest 2018\n\nThis is my submission for the Makeene Learning Kaggle Contest, as the final project in The Cooper Union's ECE:475 Frequentist Machine Learning.\n\nThis kernel is split into the following sections:\n1.  Data Processing\n    - Getting the data, cleaning it up, normalizing, and more, with an emphasis on giving the options to choose data processing options.\n2. Features Selection \/ Dimensionality Reduction (didn't end up using any of these)\n3. Models\n     - Random Forests, XGBoosest Trees, Ridge Regression, Support Vector Regression.\n4. Ensemble Models\n    - A follow up to section 3.\n5. Cross Validating the ATScore\n    - Not as part of the contest but as part of the general assignment, we will find the cross validation score when training our models on the ATScore."}}