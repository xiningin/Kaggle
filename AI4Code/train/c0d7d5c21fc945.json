{"cell_type":{"67a038be":"code","12477c71":"code","da613663":"code","dc1af0e4":"code","2b3199d5":"code","9f85b6e7":"code","c6a07881":"code","90d66edf":"code","bec957e5":"code","93db8bde":"code","6a3118e4":"code","dad8abe0":"code","5325097c":"code","52c5cb83":"code","ccef5b09":"code","e1011e6c":"code","35f5fa2c":"code","125bfe40":"code","977f96fd":"code","c81fe715":"code","b1cb5b1d":"code","1b6a6ec9":"code","1ab5cba9":"code","0a2e741e":"code","709d292c":"code","97b056ea":"code","171ce758":"code","054e8768":"code","2759f69e":"code","f153882a":"code","107c5e88":"code","5a5bf1ac":"code","48041e88":"code","b1cadbb2":"code","66675dc4":"code","83fe3a7d":"code","f58d94b6":"markdown","3c2e86fe":"markdown","4de2203f":"markdown","9beb935a":"markdown","ee367ccb":"markdown","ebe455c6":"markdown","4fbf4d49":"markdown","ba15a54a":"markdown","844da5e1":"markdown","4a851fa7":"markdown","bb195225":"markdown","f8ddca0e":"markdown","a7550cd7":"markdown","af5b3d86":"markdown","5137f196":"markdown","2f743085":"markdown","55ffa591":"markdown","0f754a42":"markdown","08c9a0cd":"markdown","1dbd957a":"markdown","2b3454db":"markdown","1dd39238":"markdown","85bf0c6d":"markdown","37b10dfb":"markdown","908d2f68":"markdown","f3b734f0":"markdown","ef303cd2":"markdown","4cbc61a6":"markdown","c36e1b84":"markdown","e0ffc3de":"markdown","9abf5f9f":"markdown"},"source":{"67a038be":"import numpy as np\nimport pylab as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nimport warnings\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn import tree\nfrom lightgbm import LGBMClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import export_graphviz\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nwarnings.filterwarnings('ignore')","12477c71":"df = pd.read_csv(\"..\/input\/breast-cancer-wisconsin-data\/data.csv\")","da613663":"df.head()","dc1af0e4":"df.info()","2b3199d5":"# Both \u201cid\u201d and \u201cUnamed: 32\u201d features in dataset are useless. The features were dropped. \ndf.drop(['id', 'Unnamed: 32'], axis=1,inplace = True)","9f85b6e7":"df.info()","c6a07881":"df.isnull().values.any()","90d66edf":"df.isnull().sum()","bec957e5":"df.shape","93db8bde":"df.describe().T","6a3118e4":"num_cols = [col for col in df.columns if df[col].dtypes != 'O' and col not in \"Id\"]\nprint('Number of Numerical Variables: ', len(num_cols))\nnum_cols","dad8abe0":"def hist_for_nums(data, num_cols):\n    col_counter = 0\n    data = data.copy()\n    for col in num_cols:\n        data[col].hist(bins=30)\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()\n        col_counter += 1\n    print(col_counter, \"variables have been plotted\")\nhist_for_nums(df, num_cols)","5325097c":"# Visualization\ncorr = df.corr()\nplt.figure(figsize=(18,10))\nsns.heatmap(corr, annot=True)\nplt.show()","52c5cb83":"df[\"diagnosis\"].value_counts()","ccef5b09":"fig1, ax1 = plt.subplots()\nax1.pie(df[\"diagnosis\"].value_counts(),  labels=['no cancer','cancer'], autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.show()","e1011e6c":"X = df.drop('diagnosis', axis=1)\ny = df[[\"diagnosis\"]]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=9)","35f5fa2c":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier().fit(X_train, y_train)\nrf_model\ny_pred = rf_model.predict(X_test)\naccuracy_score(y_test, y_pred)","125bfe40":"# Model Tuning\nrf_params = {\"max_depth\": [2,5,8,10],\n            \"max_features\": [2,5,8],\n            \"n_estimators\": [10,500,1000],\n            \"min_samples_split\": [2,5,10]}\n","977f96fd":"rf_model = RandomForestClassifier()\n\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 10, \n                           n_jobs = -1, \n                           verbose = 2) \n","c81fe715":"rf_cv_model.fit(X_train, y_train)\nprint(\"The best parameters: \" + str(rf_cv_model.best_params_))","b1cb5b1d":"rf_tuned = RandomForestClassifier(max_depth = 8, \n                                  max_features = 2, \n                                  min_samples_split = 2,\n                                  n_estimators = 1000)\nrf_tuned.fit(X_train, y_train)","1b6a6ec9":"y_pred = rf_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","1ab5cba9":"from lightgbm import LGBMClassifier\nlgbm_model = LGBMClassifier().fit(X_train, y_train)\ny_pred = lgbm_model.predict(X_test)\naccuracy_score(y_test, y_pred)","0a2e741e":"lgbm_params = {\n        'n_estimators': [100, 500, 1000, 2000],\n        'subsample': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5,6],\n        'learning_rate': [0.1,0.01,0.02,0.05],\n        \"min_child_samples\": [5,10,20]}","709d292c":"lgbm = LGBMClassifier()\n\nlgbm_cv_model = GridSearchCV(lgbm, lgbm_params, \n                             cv = 10, \n                             n_jobs = -1, \n                             verbose = 2)\nlgbm_cv_model.fit(X_train, y_train)","97b056ea":"lgbm_cv_model.best_params_","171ce758":"lgbm = LGBMClassifier(learning_rate = 0.01, \n                       max_depth = 5,\n                       subsample = 0.6,\n                       n_estimators = 2000,\n                       min_child_samples = 5)","054e8768":"lgbm_tuned = lgbm.fit(X_train,y_train)\ny_pred = lgbm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","2759f69e":"from sklearn.ensemble import GradientBoostingClassifier\ngbm_model = GradientBoostingClassifier().fit(X_train, y_train)\ny_pred = gbm_model.predict(X_test)\naccuracy_score(y_test, y_pred)","f153882a":"gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n             \"n_estimators\": [100,500,100],\n             \"max_depth\": [3,5,10],\n             \"min_samples_split\": [2,5,10]}","107c5e88":"gbm = GradientBoostingClassifier()\ngbm_cv = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 2)\ngbm_cv.fit(X_train, y_train)","5a5bf1ac":"gbm_cv.best_params_","48041e88":"gbm = GradientBoostingClassifier(learning_rate = 0.05, \n                                 max_depth = 3,\n                                min_samples_split = 2,\n                                n_estimators = 500)\ngbm_tuned =  gbm.fit(X_train,y_train)\ny_pred = gbm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","b1cadbb2":"from sklearn.tree import DecisionTreeClassifier\ncart = DecisionTreeClassifier()\ncart_model = cart.fit(X_train, y_train)\ny_pred = cart_model.predict(X_test)\naccuracy_score(y_test, y_pred)","66675dc4":"cart_grid = {\"max_depth\": range(1,10),\n            \"min_samples_split\" : list(range(2,50)) }\ncart = tree.DecisionTreeClassifier()\ncart_cv = GridSearchCV(cart, cart_grid, cv = 10, n_jobs = -1, verbose = 2)\ncart_cv_model = cart_cv.fit(X_train, y_train)\ncart_cv_model.best_params_","83fe3a7d":"cart = tree.DecisionTreeClassifier(max_depth = 4, min_samples_split = 2)\ncart_tuned = cart.fit(X_train, y_train)\ny_pred = cart_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","f58d94b6":"**Final model**","3c2e86fe":"**Final model**","4de2203f":"> ****TYPES OF BREAST CANCER****\n\nThere are several types of breast cancer (Sharma et al., 2010).\n\n> Frequently occurring breast cancer includes:\n* Lobular carcinoma in situ (LCIS, lobular neoplasia)\n* Ductal carcinoma in situ (DCIS)\n* Infiltrating ductal carcinoma\n\n> Less commonly occurring breast cancer follows as:\n* Medullary carcinoma\n* Mutinous carcinoma\n* Tubular carcinoma\n","9beb935a":"**Model Tuning**","ee367ccb":"# **Random Forests**","ebe455c6":"**Model Tuning**","4fbf4d49":"**Model Tuning**","ba15a54a":"**Final model**","844da5e1":"# 2. UNDERSTANDING THE DATA-SET","4a851fa7":"# Gradient Boosting Machines","bb195225":"> **CAUSES OF BREAST CANCER**\n* A previous history of breast cancer\n* Significant family history\n* Genetic causes\n* Hormonal causes\n* Life style and dietary cause\n* Environmental cause\n","f8ddca0e":"# 4. ANALYSIS of DEPENDENT VARIABLE (TARGET ANALYSIS)","a7550cd7":"**Visualization of numeric variables**","af5b3d86":"# 3. ANALYSIS of NUMERICAL VARIABLE","5137f196":"* There are no missing values in the dataset.","2f743085":"# BREAST CANCER\n\nBreast cancer is one of the most prevalent diseases among women in the World. According to US Cancer Statistics Working Group (2015), after lung cancer, it is second leading cause of death among women. In addition, the World Health Organization indicates that 2.09 million people are diagnosed with breast cancer every year. In the same vein, IARC\u2019s statistics present that nowadays, breast cancer is the world\u2019s mostly commonly-diagnosed cancer and overtaken lung cancer. \n","55ffa591":"# 5. MODELING","0f754a42":"![image.png](attachment:image.png)","08c9a0cd":"> **References**\n* Sharma, G. N., Dave, R., Sanadya, J., Sharma, P., & Sharma, K. K. (2010). Various types and management of breast cancer: an overview. Journal of advanced pharmaceutical technology & research, 1(2), 109.\n* US Cancer Statistics Working Group. (2015). United States cancer statistics: 1999\u20132012 incidence and mortality web-based report. Atlanta (GA): department of health and human services, centers for disease control and prevention, and national cancer institute.\n","1dbd957a":"#  LightGBM","2b3454db":"**Model Tuning**","1dd39238":"![image.png](attachment:image.png)\nSource: World Health Organization (WHO)","85bf0c6d":"I split the data set: 80% of the data is train, and 20% of it is test data.","37b10dfb":"# 1. IMPORT SOME NECESSARY LIBRARIES","908d2f68":"**Load Data**","f3b734f0":"* **Objective**\n\nThe aim of this study is to identify cancer by using ML. For this reason, the study shows a comparison of different ML on the dataset by measuring classification test accuracy values. \n","ef303cd2":"As seen from the values above, there is no imbalance between the classes of the dependent variable.","4cbc61a6":">**The Dataset** \n\nIn this study. The dataset, the Wisconsin Diagnostic Breast Cancer (WDBC)  was taken from from the Irvine Machine Learning Repository of the University of California (UCI).  It is an open-source and available at https:\/\/archive.ics.uci.edu\/ml\/datasets\/Breast+Cancer+Wisconsin+%28Diagnostic%29 , https:\/\/www.kaggle.com\/uciml\/breast-cancer-wisconsin-data.  The sample size of the dataset is 569 and consists of 32 variables.\nSome of the variables\u2019 characteristics included in the dataset follow as; \n1. radius [mean of distances from centre to points on the perimeter], \n2. texture [standard deviation of grey-scale values], \n3. perimeter, \n4. area, \n5. smoothness [local variation in radius lengths], \n6. compactness [ ((perimeter)2 \/ area) -1], \n7. concavity [severity of concave portions of the contour],\n8. concave points [number of concave portions of the contour], \n9. symmetry, \n10. fractal dimension [\"coastline approximation\" - 1]\n\n","c36e1b84":"**Final model**","e0ffc3de":"* Finding the number of values in the target column \"diagnosis\":\n> * M = malignant ==> 1 (212)\n> * B = benign    ==> 0 (357)","9abf5f9f":"# CART"}}