{"cell_type":{"4647bb45":"code","492ecf05":"code","304b2bbd":"code","bbfb4659":"code","c04bb833":"code","27424456":"code","88542d47":"code","07124e46":"code","dccd99f9":"code","18deb1f3":"code","d5f04220":"code","8201f349":"code","dc3e01b2":"code","3915c095":"code","881b959f":"code","97b789e2":"code","8282e9c1":"code","f31250ba":"code","f6df1975":"code","25695fdd":"code","71397fd5":"code","b96d54ca":"code","4a43fe87":"code","735a256e":"code","1bf53b0f":"code","750e9992":"code","82b47db9":"code","4272bf6f":"code","e3ce7e5f":"code","11c7fd21":"code","e5d418b2":"code","d18fdb1c":"code","b4868008":"code","ef3a220d":"code","471a4fc5":"code","1fce40ed":"markdown","81a08f18":"markdown","78559fc1":"markdown","89907338":"markdown","4244a5c1":"markdown","3b5ab6e6":"markdown","c23111e6":"markdown","8f10821f":"markdown","f739323a":"markdown","abce79f0":"markdown","5b92e13c":"markdown","f7cd6ea1":"markdown","dcaef71f":"markdown","e2831764":"markdown","38dba4cf":"markdown","5b68670a":"markdown"},"source":{"4647bb45":"import pandas as pd","492ecf05":"ca_housing_df = pd.read_csv(\"..\/input\/california-housing-prices\/housing.csv\")\nprint(ca_housing_df.shape)\nca_housing_df.head()","304b2bbd":"ca_housing_df.columns","bbfb4659":"ca_housing_df.drop(['ocean_proximity'],axis=1, inplace=True)","c04bb833":"ca_housing_df.columns","27424456":"ca_housing_df.isna().sum()","88542d47":"total_bedrooms = ca_housing_df['total_bedrooms']\nca_housing_df['total_bedrooms'] = total_bedrooms.fillna(total_bedrooms.median())\nca_housing_df.isna().sum()","07124e46":"ca_housing_df.duplicated().sum()","dccd99f9":"ca_housing_df.dtypes","18deb1f3":"# Standardizing the data:\nZ = (ca_housing_df-ca_housing_df.mean())\/ca_housing_df.std()","d5f04220":"# Discarding rows where all values are greater than 3 stds\nprint('Number of rows before discarding outliers = %d' % (Z.shape[0]))\nZ = Z.loc[((Z > -3).sum(axis=1)==9) & ((Z <= 3).sum(axis=1)==9),:]\nprint('Number of rows after discarding outliers values = %d' % (Z.shape[0]))","8201f349":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler","dc3e01b2":"x = StandardScaler().fit_transform(ca_housing_df.values)","3915c095":"pca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(x)\nprincipal_df = pd.DataFrame(\n    data = principal_components,\n    columns = ['principal component 1', 'principal component 2']\n)\nprincipal_df.head()","881b959f":"principal_df.index","97b789e2":"principal_df.plot.scatter(\n    x='principal component 1', \n    y='principal component 2',\n    figsize = (20,8)\n)","8282e9c1":"vaccine_tweets_df = pd.read_csv(\"..\/input\/pfizer-vaccine-tweets\/vaccination_tweets.csv\")","f31250ba":"print(vaccine_tweets_df.shape)\nvaccine_tweets_df.head()","f6df1975":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\nimport re\nimport string","25695fdd":"punct = \"\\n\\r\"+string.punctuation\n\ndef noise_removal(value):\n    return value.translate(str.maketrans('', '', punct))","71397fd5":"vaccine_tweets_df['text'].head()","b96d54ca":"tweets = vaccine_tweets_df['text'].apply(noise_removal)\ntweets.head()","4a43fe87":"def tokenize(str_input):\n    words = re.sub(r\"(?u)[^A-Za-z]\", \" \", str_input).lower().split(\" \")\n    words = [stemmer.stem(word) for word in words if len(word)>2]\n    words = [wordnet_lemmatizer.lemmatize(word) for word in words if len(word)>2]\n    return words","735a256e":"stemmer = PorterStemmer()\nwordnet_lemmatizer = WordNetLemmatizer()\n\nvectorizer = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n\nvectors = vectorizer.fit_transform(tweets)\n\nfeature_names = vectorizer.get_feature_names()","1bf53b0f":"print(\"number of words = \", len(feature_names))","750e9992":"tweet_tfidf = pd.DataFrame(vectors.toarray(),columns=feature_names)\ntweet_tfidf.head()","82b47db9":"tweet_tfidf.shape","4272bf6f":"from sklearn.metrics.pairwise import cosine_similarity","e3ce7e5f":"query_tfidf = vectorizer.transform([\"vaccine is deadly\"])    \ncosine_sim = cosine_similarity(tweet_tfidf, query_tfidf)\ncosine_sim","11c7fd21":"cosine_sim.shape","e5d418b2":"(cosine_sim>0.055).sum()","d18fdb1c":"largest_10 = []\nfor index, value in enumerate(cosine_sim):\n    if value >0.055:\n        largest_10.append([index, float(value)])","b4868008":"largest_10","ef3a220d":"from operator import itemgetter\ntweets_with_highest_similarity = sorted(largest_10, key=itemgetter(1))","471a4fc5":"print(\"Top 10 tweets with similarity to: 'vaccine is deadly'\")\nprint(\"\\n\\n\\n\")\nfor tweet in tweets_with_highest_similarity:\n    print(vaccine_tweets_df['text'].iloc[tweet[0]])\n    print(\"---\"*20)","1fce40ed":"Removing duplicate values:\n    - No duplicate values","81a08f18":"Applying PCA and reducing the dimensions to 2","78559fc1":"### This is assignment is due on Tuesday 26-1-2021 at midnight","89907338":"6. Use the california housing prices dataset and do the following:\n    - Remove the ocean_proximity feature\n    - Standardaize the features.\n    - Remove the outliers.\n    - Remove the missing values (if any).\n    - Remove the duplicate rows (if any).\n    - Apply PCA and reduce the dimensions to 2.\n    - Do a scatter plot for the data on the two principal components.\n    ","4244a5c1":"Answer the following questions:\n\n1. Describe the four main data mining tasks.\n    - Clustering: Finding groups of objects such that the object in a group will be similar or related to one another and different from or related to the objects in other groups\n    - Association Rules: Given a set of records each of which contain some number of items from a given collection, will product dependency rules which will predict occurrences of an item based on occurrences of other items.\n    - Predictive Modeling: Find a model for class attribute as a function of the values of other attributes.\n    - Anomaly Detection: Detect significant deviations from normal behavior\n2. Give two examples of the following data mining tasks:\n    * Classification:\n        1. Checking if an employee is credit worthy\n        2. Classifying credit card transactions as legitimate or fradulent\n    * Regression:\n        1. Time series prediction of stock market indices\n        2. Predicting sales amounts of new product based on advertising expenditure\n    * Clustering:\n        1. Customer profiling for targeted marketing\n        2. Group stocks with similar price fluctuations","3b5ab6e6":"4. What type of feature are the following (categorical-nominal, categorical-ordinal, numerical-discrete, numerical-continuous):\n    - Person height: categorical-ordinal if the height is a choice of short, medium, tall. If the height is a number then numerical-continuous\n    - Ranking of a product: categorical-ordinal\n    - Number of children: numerical-discrete\n    - Car model: categorical-nominal","c23111e6":"3. Use the below model to predict the credit worthiness of the following clients:\n    * Steve is employed, has a high school degree and spent 5 years at his current address.\n        - Not credit worthy\n    * Andy has a graduate degree, spent 8 years at his current address but is not employed.\n        - Not credit worthy\n\n![image.png](attachment:image.png)","8f10821f":"Removing any punctuations.","f739323a":"7. Use the pfizer-vaccine-tweets dataset and do the following on the tweet text feature:\n\n    - Remove any punctuation.\n    - Remove the stop words.\n    - Apply stemming and lemmatization.\n    - Vectorize the text of the tweets and put it in a dataframe with applying the TF_IDF weights.\n    - Find the similarity between the tweets and the query \"vaccine is deadly\".\n    - Print the top 10 most similar tweets to the query in the order of similarity.","abce79f0":"Find the similarity between the tweets and the query \"vaccine is deadly\".","5b92e13c":"5. What is the purpose of Information Retrieval\n\nWhen given a source of textual documents or a user query it will find a set of documents that are relevant to the query.","f7cd6ea1":"Now we will do a scatter plot for the data on the two principal components.","dcaef71f":"Removing the `ocean_proximity` column","e2831764":"Removing missing values from the `total_bedrooms` column","38dba4cf":"Removing stop words and applying stemming and lemmatization.\n\nThen doing TF-IDF Term Weighting.","5b68670a":"Standardaize the features and will remove the outliers"}}