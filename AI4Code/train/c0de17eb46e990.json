{"cell_type":{"451469c9":"code","e6370c0e":"code","245955df":"code","49244169":"code","a57fa996":"code","91afd6d4":"code","6eb9f63c":"code","47ae885c":"code","4efd5067":"code","743c2e6a":"code","4982de4d":"code","0e65fe66":"code","53e30d4f":"code","35529612":"code","dcbc014c":"code","8be93f1c":"code","c0b9b69a":"code","b16e62dc":"code","b4d519ac":"code","521cdb28":"code","2a2f0ac1":"code","9873fe3a":"code","790582f9":"code","8573ab6e":"code","26cc8218":"code","78f91ea2":"code","90179785":"code","4c347137":"code","ddf16d5e":"code","58b3bc52":"code","63177e53":"code","6e559132":"code","f361990c":"code","b12fc988":"code","ac5269a1":"code","e3813dea":"code","b1bdb984":"code","d7005fd9":"code","5d5483be":"code","ea0a27c2":"code","cafe4e0e":"code","991cc4d5":"code","8d512e8e":"code","cd70a966":"code","82787f08":"code","9566b2d0":"code","a4efe502":"code","45423115":"code","89aad9cd":"code","390d2c63":"code","8a8991e3":"code","8e0eb0d0":"code","b6cd8deb":"code","b0872b15":"code","ddc392d6":"code","ce2c9dae":"code","0752e209":"code","b68f6874":"code","797b281d":"code","2beb3ee8":"code","0d31623d":"code","5fe37f36":"code","71139f83":"code","ff7c331e":"code","a63fb210":"code","ff047698":"code","a278a8a8":"code","2bde8184":"code","e79104ae":"code","da0446f5":"code","5c5aca3e":"code","59d01e52":"markdown","7b1e95d2":"markdown","ae9acbef":"markdown","3315247d":"markdown"},"source":{"451469c9":"import pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\nimport re\nimport string\nimport nltk\nimport spacy\nimport gensim\nfrom spacy import displacy\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer\nfrom nltk.tokenize import word_tokenize\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n%matplotlib inline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom nltk.probability import FreqDist\nfrom sklearn.svm import LinearSVC\nfrom textblob import TextBlob\nfrom gensim.models import Word2Vec","e6370c0e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","245955df":"reviews_df = pd.read_csv('\/kaggle\/input\/indian-products-on-amazon\/amazon_vfl_reviews.csv', encoding=\"UTF-8\")\nreviews_df.head()","49244169":"reviews_df.shape","a57fa996":"# any null columns\nreviews_df.isnull().sum()","91afd6d4":"# the review column, four rows without review text, we drop the rows with the null columns\nreviews_df = reviews_df.dropna()\n#resetting the index\nreviews_df = reviews_df.reset_index(drop=True)","6eb9f63c":"# remove all characters not number or characters\ndef cleanText(input_string):\n    modified_string = re.sub('[^A-Za-z0-9]+', ' ', input_string)\n    return(modified_string)\nreviews_df['review'] = reviews_df.review.apply(cleanText)\nreviews_df['review'][150]","47ae885c":"# From the name we extract the brand\nreviews_df['brandName'] = reviews_df['name'].str.split('-').str[0]\nreviews_df.head()","4efd5067":"reviews_df['brandName'].value_counts()","743c2e6a":"reviews_df['brandName'] = reviews_df['brandName'].str.title()\nreviews_df.brandName.unique()","4982de4d":"# Extracting the product from the name column\nproducts = []\nfor value in reviews_df['name']:\n    indx = len(value.split('-')[0])+1\n    products.append(value[indx:])\nreviews_df['product'] = products\nreviews_df['product'].unique()","0e65fe66":"reviews_df.head()","53e30d4f":"#converting to lower case\nreviews_df['clean_review_text']=reviews_df['review'].str.lower()","35529612":"#removing punctuations\nreviews_df['clean_review_text']=reviews_df['clean_review_text'].str.translate(str.maketrans('','',string.punctuation))","dcbc014c":"stopWords=stopwords.words('english')+['the', 'a', 'an', 'i', 'he', 'she', 'they', 'to', 'of', 'it', 'from']\ndef removeStopWords(stopWords, rvw_txt):\n    newtxt = ' '.join([word for word in rvw_txt.split() if word not in stopWords])\n    return newtxt\nreviews_df['clean_review_text'] = [removeStopWords(stopWords,x) for x in reviews_df['clean_review_text']]","8be93f1c":"#splitting text into words\ntokenList=[]\nfor indx in range(len(reviews_df)):\n       token=word_tokenize(reviews_df['clean_review_text'][indx])\n       tokenList.append(token)\nreviews_df['review_tokens'] = tokenList\nreviews_df.head()","c0b9b69a":"nltk.download('vader_lexicon')\nsentiment_model = SentimentIntensityAnalyzer()\nsentiment_scores=[]\nsentiment_score_flag = []\nfor text in reviews_df['clean_review_text']:\n        sentimentResults = sentiment_model.polarity_scores(text)\n        sentiment_score = sentimentResults[\"compound\"]\n        #print(sentimentResults)\n        #The compound value reflects the overall sentiment ranging from -1 being very negative and +1 being very positive.\n        sentiment_scores.append(sentiment_score)\n        # marking the sentiments as positive, negative and neutral \n        if sentimentResults['compound'] >= 0.05 : \n            sentiment_score_flag.append('positive')\n  \n        elif sentimentResults['compound'] <= - 0.05 : \n            sentiment_score_flag.append('negative')\n  \n        else : \n            sentiment_score_flag.append('neutral')\n            \nreviews_df['scores']=sentiment_scores\nreviews_df['scoreStatus'] = sentiment_score_flag","b16e62dc":"reviews_df.head()","b4d519ac":"def show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color = 'white',\n        max_words = 200,\n        max_font_size = 40, \n        scale = 3,\n        random_state = 42\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize = (20, 20))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize = 20)\n        fig.subplots_adjust(top = 2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n    \n# print wordcloud\nshow_wordcloud(reviews_df[\"clean_review_text\"])","521cdb28":"# print wordcloud\npositiveReviews_df =reviews_df.loc[reviews_df['scoreStatus'] == \"positive\"]\nshow_wordcloud(positiveReviews_df[\"clean_review_text\"])","2a2f0ac1":"## print wordcloud\nnegativeReviews_df =reviews_df.loc[reviews_df['scoreStatus'] == \"negative\"]\nshow_wordcloud(negativeReviews_df[\"clean_review_text\"])","9873fe3a":"features = CountVectorizer()\nfeatures.fit(reviews_df[\"clean_review_text\"])\nprint(len(features.vocabulary_))\nprint(features.vocabulary_)","790582f9":"bagofWords = features.transform(reviews_df[\"clean_review_text\"])\nprint(bagofWords)","8573ab6e":"print(bagofWords.toarray())","26cc8218":"print(features.get_feature_names())","78f91ea2":"df = pd.concat([positiveReviews_df,negativeReviews_df])\ndf = df[[\"clean_review_text\",\"scoreStatus\"]]\ndf['scoreStatus'] = (df['scoreStatus'] == 'positive')*1\nX = df[\"clean_review_text\"]\ny = df[\"scoreStatus\"]\nX_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)","90179785":"X_train = features.fit_transform(X_train)\nX_test = features.transform(X_test)","4c347137":"#k fold cross validation with k=5\nscores = cross_val_score(LogisticRegression(),X_train,y_train,cv=5)\nprint(np.mean(scores))","ddf16d5e":"model=LogisticRegression()\nmodel.fit(X_train,y_train)\nprint(model.score(X_train,y_train))\nprint(model.score(X_test,y_test))","58b3bc52":"y_pred = model.predict(X_test)\nconfusion_matrix(y_test,y_pred)","63177e53":"text = \"the product great\"\nmodel.predict(features.transform([text]))[0]","6e559132":"text = \"bad\"\nmodel.predict(features.transform([text]))[0]","f361990c":"text = \"sucks\"\nmodel.predict(features.transform([text]))[0]","b12fc988":"text = \"very bad\"\nmodel.predict(features.transform([text]))[0]","ac5269a1":"text = \"not good\"\nmodel.predict(features.transform([text]))[0]","e3813dea":"tokenized_word=word_tokenize((reviews_df['clean_review_text'].to_string()))\n#Frequency Distribution\nfdist = FreqDist(tokenized_word)\n# Frequency Distribution Plot\nfdist.plot(30,cumulative=False)\nplt.show()","b1bdb984":"nlp=spacy.load(\"en_core_web_sm\")","d7005fd9":"text = reviews_df['review'][120]\ndoc=nlp(text)\ntype(doc)\nprint(doc)","5d5483be":"#Tokens\nfor token in doc:\n    print(token.text)","ea0a27c2":"#Stopwords\nstopwords=spacy.lang.en.stop_words.STOP_WORDS\nstopWords = list(stopwords)\nlen(stopWords)","cafe4e0e":"for token in doc:\n    if token.is_stop == False:\n        print(token)","991cc4d5":"print(len(doc))\ndoc2=[]\nfor token in doc:\n    if not token.is_stop:\n        doc2.append(token)\nprint(len(doc2))","8d512e8e":"#lemmatization\nfor review_text in doc:\n    print(review_text.text,review_text.lemma_)","cd70a966":"#POS\nfor token in doc:\n   print(token,token.tag_,token.pos_,spacy.explain(token.tag_))","82787f08":"displacy.render(doc,style='dep',jupyter=True,options={'distance':90})","9566b2d0":"for entity in doc.ents:\n    print(entity.text,'---->',entity.label_)\ndisplacy.render(doc,style='ent',jupyter=True)","a4efe502":"#word vectors and similarity\n#large pre trained model\n!python -m spacy download en_core_web_lg","45423115":"import en_core_web_lg\nnlp = en_core_web_lg.load()\ndoc=nlp(text)\nfor token in doc:\n    print(token.text,'---->',token.has_vector)","89aad9cd":"for token in doc:\n    print(token.text,'',token.vector_norm)","390d2c63":"#similarity score\ntext=\"eat\"\ntext1=\"ate\"\ndoc=nlp(text)\ndoc1=nlp(text1)\ndoc.similarity(doc1)","8a8991e3":"#similarity score\ntext=\"good\"\ntext1=\"bad\"\ndoc=nlp(text)\ndoc1=nlp(text1)\ndoc.similarity(doc1)","8e0eb0d0":"#similarity score\ntext=\"hot\"\ntext1=\"summer\"\ndoc=nlp(text)\ndoc1=nlp(text1)\ndoc.similarity(doc1)","b6cd8deb":"#similarity score\ntext=\"excellent\"\ntext1=\"good\"\ndoc=nlp(text)\ndoc1=nlp(text1)\ndoc.similarity(doc1)","b0872b15":"#similarity score\ntext=\"sucks\"\ntext1=\"bad\"\ndoc=nlp(text)\ndoc1=nlp(text1)\ndoc.similarity(doc1)","ddc392d6":"df = pd.concat([positiveReviews_df,negativeReviews_df])\ndf = df[[\"clean_review_text\",\"scoreStatus\"]]\ndf['scoreStatus'] = (df['scoreStatus'] == 'positive')*1","ce2c9dae":"#Tokenization\npunct = string.punctuation\nprint(punct)\ndef cleanText(sent):\n    doc = nlp(sent)\n    tokens = []\n    for token in doc:\n        if token.lemma != \"-PRON-\":\n            tokens.append(token.lemma_.lower().strip())\n        else:\n            tokens.append(token.lemma_)\n            \n    cleanTokens = []\n    for token in tokens:\n        if token not in stopWords and token not in punct:\n            cleanTokens.append(token)\n    return cleanTokens","0752e209":"#TFIDF\ntfidf = TfidfVectorizer(tokenizer = cleanText)\nclassifier = LinearSVC()\nX = df[\"clean_review_text\"]\ny = df[\"scoreStatus\"]\nX_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)","b68f6874":"X_train.shape, X_test.shape","797b281d":"clf = Pipeline([('tfidf',tfidf),('clf',classifier)])\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)","2beb3ee8":"print(classification_report(y_test,y_pred))","0d31623d":"confusion_matrix(y_test,y_pred)","5fe37f36":"pol = lambda x: TextBlob(x).sentiment.polarity\nsub = lambda x: TextBlob(x).sentiment.subjectivity\nreviews_df[\"polarity\"] = reviews_df[\"review\"].apply(pol)\nreviews_df[\"subjectivity\"] = reviews_df[\"review\"].apply(sub)","71139f83":"#distribution of rating\nsns.countplot(x='rating', data=reviews_df)","ff7c331e":"reviews_df.head()","a63fb210":"print(\"negative reviews\")\nmost_negative = reviews_df[reviews_df.polarity == -1].review.head()\nprint(most_negative)\nprint(\"positive reviews\")\nmost_positive = reviews_df[reviews_df.polarity == 1].review.head()\nprint(most_positive)","ff047698":"sentences = reviews_df['review_tokens'][1:10]\nsentences","a278a8a8":"#train model\nmodel = Word2Vec(sentences, min_count=1)\nprint(model)","2bde8184":"#vocab\nwords=list(model.wv.vocab)\nprint(words)","e79104ae":"#nltk.download('punkt')\nreviewsText = reviews_df.clean_review_text.values\nreviewsVec = [nltk.word_tokenize(review) for review in reviewsText]\nlen(reviewsVec)","da0446f5":"model = Word2Vec(reviewsVec,min_count=1, size=32)\nmodel.most_similar('soothing')","5c5aca3e":"model = Word2Vec(reviewsVec,min_count=1, size=32)\nmodel.most_similar('packaging')","59d01e52":"Text analysis with gensim and word2vec","7b1e95d2":"Text analysis with NLTK and Vader Sentiment analyzer","ae9acbef":"With TextBlob","3315247d":"Text Analytics with spacy"}}