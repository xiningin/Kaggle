{"cell_type":{"24316de1":"code","42ee1cff":"code","faac1353":"code","d3da396d":"code","b922289a":"code","9b73cb20":"code","9e5ea41d":"code","4136534c":"code","ea15f788":"code","684c20b9":"code","4915cef7":"code","6caa2cde":"code","baaba82c":"code","073e17f3":"code","a400290f":"code","91b5e6e1":"code","02412d87":"code","cd4382b0":"code","1ea621a5":"code","13559414":"code","ac4bf7de":"code","00acf6d1":"code","f85e88a5":"code","0839865e":"markdown","54d11c94":"markdown","6d06665e":"markdown","75620a69":"markdown","901613fa":"markdown","497a5435":"markdown","8b60db9d":"markdown","76b99655":"markdown","f2405ad1":"markdown","d4276d86":"markdown","803ab1d8":"markdown","11e5bf5a":"markdown","059c3d57":"markdown"},"source":{"24316de1":"#we need to some modeule for handling and visualizing result of the data \nimport pandas as pd   #pandas for data manipulation and analysis\nimport numpy as np   # numpy used for handling numerical data \nimport matplotlib.pyplot as plt  # this is used for visualizing the data\nimport statistics     # it is used for statistical functions\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.metrics import r2_score,mean_squared_error, mean_absolute_error","42ee1cff":"#import datafile using pandas module\ntrain_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\n#test_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","faac1353":"train_data.head()","d3da396d":"train_data.shape","b922289a":"train_data.info()        # here we can get that is there any null value and how much","9b73cb20":"plt.figure(figsize=(15,15))\nsns.distplot(train_data['SalePrice'],bins=100) ","9e5ea41d":"column_names = train_data.columns   # we need list of columns for preprocessing so we can generate here\nprint(column_names)","4136534c":"# there are lots of null values in some columns so we directly remove that column fron both of data files\ntrain_data.drop(labels=['Alley','FireplaceQu','PoolQC','Fence','MiscFeature',], axis=1,inplace=True)\n#test_data.drop(labels=['Alley','FireplaceQu','PoolQC','Fence','MiscFeature',], axis=1,inplace=True)\n","ea15f788":"column_names = train_data.columns   # we need list of columns for preprocessing so we can generate here\nprint(column_names)","684c20b9":"# Remaining null values we can replace by median and mode which is depnd on the column type\n\nfor c in range(1,len(column_names)-1):                                       # we create loop for change ing null values\n    col = column_names[c]                                                    # in train and test data set\n    if train_data[col].dtype == 'object':                                    # with the using of if else statement\n                                                                             # objects replace by mode and other  \n        train_data[col].fillna(train_data[col].dropna().max(),inplace =True) # replace by mean\n        #test_data[col].fillna(test_data[col].dropna().max(),inplace =True)\n\n    else:\n        train_data[col] = train_data[col].fillna(train_data[col].mean())\n        #test_data[col] = test_data[col].fillna(test_data[col].mean())\n","4915cef7":"#here we can distribute columns by categorical and numerical\ncolumn_names = train_data.columns\ncategorical_col = []\nnumeric_col = []\nfor c in range(1,len(column_names)-1):                                       # we create loop for change ing null values\n    col = column_names[c]                                                    # in train and test data set\n    if train_data[col].dtype == 'object': \n        categorical_col.append(col)                                         # with the using of if else statement\n                                                                                 # objects replace by mode and other  \n    else:\n        numeric_col.append(col)\nprint('categorical_col:\\t', categorical_col,'\\n')\nprint('numeric_col:\\t',numeric_col )","6caa2cde":"plt.figure(figsize=(15,15))\nsns.heatmap(train_data[numeric_col].corr(),cmap='coolwarm',annot=True)","baaba82c":"plt.figure(figsize=(10,10))\nsns.stripplot(x=\"SaleCondition\", y=\"SalePrice\", data=train_data,jitter=True,hue='SaleType',palette='Set1')","073e17f3":"plt.figure(figsize=(15,15))\nsns.countplot(x='GarageType',data=train_data)","a400290f":"'''\n# Then you map to the grid\ng = sns.PairGrid(train_data[numeric_col])\ng.map(plt.scatter)\n'''","91b5e6e1":"g = sns.PairGrid(train_data[numeric_col[:10]])\ng.map(plt.scatter)","02412d87":"#in most of the cases model not handle categorical data \n# in python there is best module to handle the data\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","cd4382b0":"\ncolumn = train_data.columns                        \nfor c in range(1,len(column)-1):                     \n    col = column[c]\n    if train_data[col].dtype == 'object':\n        train_data[col] = le.fit_transform(train_data[col])\n        #test_data[col] = le.fit_transform(test_data[col])\n    else:\n        pass","1ea621a5":"X = train_data.iloc[:,1:-1]\ny = train_data.iloc[:,-1]\n#test = test_data.iloc[:,1:].values","13559414":"# We can split data to model evaluation\nfrom sklearn.model_selection import train_test_split","ac4bf7de":"X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.25, random_state = 100)   # here we can split into train and test ","00acf6d1":"from sklearn.ensemble import GradientBoostingRegressor\nreg = GradientBoostingRegressor(n_estimators=2000,loss='ls')\nreg.fit(X_train, y_train)\ny_pred= reg.predict(X_test)\nprint(\"r2_score\",r2_score(y_test,y_pred))\nprint('mean abs error', mean_absolute_error(y_test,y_pred))","f85e88a5":"plt.figure(figsize=(20,12))\nplt.plot(list(y_test), color = 'red', label = 'Actual Price')\nplt.plot(y_pred, color = 'green', label = 'predicted Price')\nplt.title('GB Regression')\nplt.ylim(0,1000000)\nplt.xlabel('Id')\nplt.ylabel('Price')\nplt.legend()\nplt.show()\n","0839865e":"## Data visualizing","54d11c94":"## Taking care of missing data","6d06665e":"Data visualization is the graphic representation of data.\nIt involves producing images that communicate relationships among the represented data to viewers of the images. \nThis communication is achieved through the use of a systematic mapping between graphic marks and data values in the creation of the visualization","75620a69":"## **result visualization**","901613fa":"## Import Data files","497a5435":"Here we can see that most of the garages are attached with houses","8b60db9d":"## Splitting the dataset into the Training set and Test set\n","76b99655":"**here we can conclude that most of the houses are in range 100000 - 300000**","f2405ad1":"we need to zoom some part","d4276d86":"## Importing the Libraries\n","803ab1d8":"## Encoding categorical data","11e5bf5a":" here we can conclude that the data in given data independent on each other","059c3d57":"## **GB Regression Model**"}}