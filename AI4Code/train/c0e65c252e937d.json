{"cell_type":{"4dc25258":"code","307fbf20":"code","d1f5edb2":"code","c2bba6b4":"code","4b167afe":"code","364588b7":"code","75a3175c":"code","ef25dee5":"code","99e4ddcb":"code","63161495":"code","41364a0c":"code","ac94b2fc":"code","16ff6f36":"code","7e342c7b":"code","af783e3e":"code","720e7d79":"code","1105eae9":"code","d7752490":"code","3dc07732":"code","b1d6ef87":"code","51fe78fd":"code","85bb4c22":"code","8ddccc7d":"code","ed77d78c":"code","133f1f7b":"code","41953a07":"code","541ba8a8":"code","7ce1affd":"code","2dd39be9":"code","fab11bec":"code","8b0ab132":"code","eabb9de2":"code","1636e212":"code","626f3c96":"code","0eaaee2f":"code","1e4c91a8":"code","dbe61947":"code","8b2b7512":"code","8c792a88":"code","08a356a8":"code","f23f285f":"markdown","fa28cb6f":"markdown","48e43752":"markdown","1b689c8d":"markdown","ef55cc60":"markdown","f70d4bff":"markdown","98268fd7":"markdown","d2d8f5bf":"markdown","3cc7630e":"markdown","08130495":"markdown","a3cfb4a8":"markdown","c942c215":"markdown","2909694c":"markdown"},"source":{"4dc25258":"# Importing the required libraries.\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","307fbf20":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d1f5edb2":"# getting the data into a DataFrame.\ndata=pd.read_csv(r\"\/kaggle\/input\/cardiovascular-disease-dataset\/cardio_train.csv\",sep=\";\")\ndata.head()","c2bba6b4":"data.info()","4b167afe":"data.describe()","364588b7":"# The age is given in days, we have to convert it into years.\ndata[\"age\"] = data[\"age\"]\/365\ndata[\"age\"] = data[\"age\"].astype(\"int\")","75a3175c":"# Dropping id column, its of no use.\ndata = data.drop(columns = [\"id\"])","ef25dee5":"sns.countplot(x = 'cardio', data = data)","99e4ddcb":"# Checking the existence of outliers using boxplots\nfig, ax = plt.subplots(figsize = (15,10))\nsns.boxplot(data = data, width = 0.5, ax = ax, fliersize = 3)\nplt.title(\"Visualization of outliers\")","63161495":"# ap_hi greater than 200 and lower than or equal to 80 will be removed.\n# ap_lo greater than 180 and lower than 50 will be removed.\n# height greater or equal to 100 and weight less than 28 will be removed.\noutlier = ((data[\"ap_hi\"]>200) | (data[\"ap_lo\"]>180) | (data[\"ap_lo\"]<50) | (data[\"ap_hi\"]<=80) | (data[\"height\"]<=100)\n             | (data[\"weight\"]<=28) )\nprint(\"There is {} outlier\".format(data[outlier][\"cardio\"].count()))","41364a0c":"# Removing  the outlier from the Dataset.\ndata = data[~outlier]","ac94b2fc":"data","16ff6f36":"# BoxPlot after removing the outliers.\nfig, ax = plt.subplots(figsize = (15,10))\nsns.boxplot(data = data, width = 0.5, ax = ax, fliersize = 3)\nplt.title(\"Visualization of outliers\")","7e342c7b":"X = data.drop(columns = ['cardio'])\ny = data['cardio']\nplt.figure(figsize=(20,25), facecolor='white')\nplotnumber = 1\n\nfor column in X:\n    if plotnumber<=16 :\n        ax = plt.subplot(4,4,plotnumber)\n        sns.stripplot(y,X[column])\n    plotnumber+=1\n\nplt.tight_layout()","af783e3e":"# creating a heatmap of correlation of the data.\ncorr = data.corr()\nf, ax = plt.subplots(figsize = (15,15))\nsns.heatmap(corr, annot=True, fmt=\".3f\", linewidths=0.5, ax=ax)","720e7d79":"data[\"bmi\"] = data[\"weight\"]\/ (data[\"height\"]\/100)**2","1105eae9":"data.head()","d7752490":"# Detecting Genders\na = data[data[\"gender\"]==1][\"height\"].mean()\nb = data[data[\"gender\"]==2][\"height\"].mean()\nif a > b:\n    gender = \"male\"\n    gender2 = \"female\"\nelse:\n    gender = \"female\"\n    gender2 = \"male\"\nprint(\"Gender:1 is \"+ gender +\" & Gender:2 is \" + gender2)","3dc07732":"data[\"gender\"] = data[\"gender\"] % 2","b1d6ef87":"data","51fe78fd":"X = data.drop(columns = ['cardio'])\ny = data['cardio']","85bb4c22":"from sklearn.preprocessing import MinMaxScaler\nscalar=MinMaxScaler()\nx_scaled=scalar.fit_transform(X)","8ddccc7d":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score,roc_curve, roc_auc_score","ed77d78c":"X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size = 0.30, random_state = 9)","133f1f7b":"dtc = DecisionTreeClassifier()\nran = RandomForestClassifier(n_estimators=90)\nknn = KNeighborsClassifier(n_neighbors=79)\nsvm = SVC(random_state=6)","41953a07":"models = {\"Decision tree\" : dtc,\n          \"Random forest\" : ran,\n          \"KNN\" : knn,\n          \"SVM\" : svm}\nscores= { }","541ba8a8":"for key, value in models.items():    \n    model = value\n    model.fit(X_train, y_train)\n    scores[key] = model.score(X_test, y_test)","7ce1affd":"scores_frame = pd.DataFrame(scores, index=[\"Accuracy Score\"]).T\nscores_frame.sort_values(by=[\"Accuracy Score\"], axis=0 ,ascending=False, inplace=True)\nscores_frame","2dd39be9":"from sklearn.metrics import plot_roc_curve","fab11bec":"disp = plot_roc_curve(dtc, X_test, y_test)\n\nplot_roc_curve(ran,X_test, y_test, ax = disp.ax_)\n\nplot_roc_curve(knn,X_test, y_test, ax = disp.ax_)\n\nplot_roc_curve(svm,X_test, y_test, ax = disp.ax_)","8b0ab132":"predicted_svc=svm.predict(X_test)","eabb9de2":"accuracy = accuracy_score(y_test, predicted_svc)\nprint(\"The accuracy of svc model is : \", accuracy)","1636e212":"conf_mat = confusion_matrix(y_test, predicted_svc)\nprint(\"The Confusion Matrix for SVC in this dataset is : \\n\", conf_mat)","626f3c96":"true_positive = conf_mat[0][0]\nfalse_positive = conf_mat[0][1]\nfalse_negative = conf_mat[1][0]\ntrue_negative = conf_mat[1][1]","0eaaee2f":"# Precison\nPrecision = true_positive\/(true_positive+false_positive)\nprint(\"The precision of this svc model is : \",Precision)\n\n# Recall\nRecall= true_positive\/(true_positive+false_negative)\nprint(\"The Recall score of svc model is : \",Recall)\n\n# F1 Score\nF1_Score = 2*(Recall * Precision) \/ (Recall + Precision)\nprint(\"The F1_Score for this dataset is : \",F1_Score)","1e4c91a8":"predicted_knn=knn.predict(X_test)","dbe61947":"accuracy=accuracy_score(y_test,predicted_knn)\nprint(\"The accuracy of knn model is : \",accuracy)","8b2b7512":"conf_mat = confusion_matrix(y_test,predicted_knn)\nprint(\"The Confusion Matrix for KNN in this dataset is : \\n\",conf_mat)","8c792a88":"true_positive = conf_mat[0][0]\nfalse_positive = conf_mat[0][1]\nfalse_negative = conf_mat[1][0]\ntrue_negative = conf_mat[1][1]","08a356a8":"# Precison\nPrecision = true_positive\/(true_positive+false_positive)\nprint(\"The precision of this knn model is : \",Precision)\n\n# Recall\nRecall= true_positive\/(true_positive+false_negative)\nprint(\"The Recall score of knn model is : \",Recall)\n\n# F1 Score\nF1_Score = 2*(Recall * Precision) \/ (Recall + Precision)\nprint(\"The F1_Score for this dataset is : \",F1_Score)","f23f285f":"**Body Mass Index (BMI)**\nHeight and weight seems uncorrelated with the cardio feature but **Body Mass Index (BMI)** could be helpful to train our model.","fa28cb6f":"From the table and graph we can see that the SVM and KNN are performing better than other models.","48e43752":"As you can see in the above **heatmap**, there are **correlations** among **gender and height**, **app_lo and app_hi**, **gluc and cholestrol**, and a small correlation among **smoke and alco**.","1b689c8d":"## Conclusion\n\n#### SVC gives a better result than other models,in terms of Accuracy score,Auc score and F1_score Svc gives good result. so we can take svc to predict whether a person has cardio or not with good accuracy of 73%.","ef55cc60":"## Preparing the Training and Test set.","f70d4bff":"the dataset is well balanced.","98268fd7":"Here we can see some outliers present in some features (app_hi, app_lo, height and weight)","d2d8f5bf":"## Exploratory Data Analysis.","3cc7630e":"## Evaluation of KNN.","08130495":"## Evaluation of SVC","a3cfb4a8":"* Women have many of the same risk factors with men for heart disease as men, such as smoking, high blood pressure, and high cholesterol especially after 65. \n* Thus we shouldn't categorize them into 1 and 2 because of 2 is always numerically bigger than 1, the model would take into account that and give a bigger ratio to men for having a disease","c942c215":"We already have 70000 data and this 1434 is only a 2% of it.\nSo we have enough data to train the model even if we remove these outliers.","2909694c":"## Importing Libraries and Dataset."}}