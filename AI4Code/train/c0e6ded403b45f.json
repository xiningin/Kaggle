{"cell_type":{"58817261":"code","e3bce87e":"code","6c8cf89b":"code","5ec50c6d":"code","ac49344d":"code","0ffb3761":"code","9cbe43c1":"code","8324d53f":"code","ff6c1375":"code","89ce8c89":"code","d6706c1b":"code","a2bb8bf8":"markdown","0c637bf0":"markdown","b3706063":"markdown","67293614":"markdown","529a7536":"markdown","21abc9b6":"markdown","6a654659":"markdown","40379665":"markdown","53c83f76":"markdown","907d446b":"markdown","139b53db":"markdown"},"source":{"58817261":"import pandas as pd\nimport numpy as np\n\ndataset = pd.read_csv(\"..\/input\/breast-cancer-dataset\/breast-cancer.csv\")\ndataset.dtypes","e3bce87e":"dataset.head()","6c8cf89b":"X = dataset.iloc[:,2:]\ny = dataset.iloc[:,1]\ny = pd.get_dummies(y)\ny = y.iloc[:, -1]","5ec50c6d":"!pip install imblearn\n!pip install delayed\n!pip install scikit-learn","ac49344d":"from imblearn.over_sampling import SVMSMOTE  \n\nsampler = SVMSMOTE(random_state=42)\nX_res, y_res = sampler.fit_resample(X.values, y)","0ffb3761":"from sklearn import preprocessing\nscaler = preprocessing.StandardScaler().fit(X_res)\nX_scaled = scaler.transform(X.values)\nX_res_scaled = scaler.transform(X_res)","9cbe43c1":"from sklearn.model_selection import cross_val_score\n\ndef rmse_cv(model, X, y):\n    rmse= np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","8324d53f":"from sklearn import svm\nfrom sklearn import linear_model\nclf = svm.SVC()\nclf.fit(X_scaled,y)\nprint(rmse_cv(clf, X_scaled, y))\nprint(clf.score(X_scaled,y))\nclf.fit(X_res_scaled,y_res)\nprint(rmse_cv(clf, X_res_scaled, y_res))\nprint(clf.score(X_res_scaled, y_res))","ff6c1375":"from sklearn import linear_model\nfrom sklearn import preprocessing\nclf = linear_model.LogisticRegression(max_iter=1000)\nclf.fit(X_scaled,y)\nprint(rmse_cv(clf, X_scaled, y))\nprint(clf.score(X_scaled,y))\nclf.fit(X_res_scaled,y_res)\nprint(rmse_cv(clf, X_res_scaled, y_res))\nprint(clf.score(X_res_scaled, y_res))","89ce8c89":"from sklearn.ensemble import AdaBoostClassifier\n\nclf = AdaBoostClassifier(n_estimators=200)\nclf.fit(X_scaled,y)\nprint(rmse_cv(clf, X_scaled, y))\nprint(clf.score(X_scaled,y))\nclf.fit(X_res_scaled,y_res)\nprint(rmse_cv(clf, X_res_scaled, y_res))\nprint(clf.score(X_res_scaled, y_res))\n","d6706c1b":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\ntrain_score = []\ntest_score = []\nfor i in range(10):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=i)\n    scaler = preprocessing.StandardScaler().fit(X_train)\n    X_train = scaler.transform(X_train)\n    X_test = scaler.transform(X_test)\n\n    clf = AdaBoostClassifier(n_estimators=500)\n    clf.fit(X_train, y_train)\n    train_score.append(clf.score(X_train, y_train))\n    test_score.append(clf.score(X_test, y_test))\nprint(\"train: \" + str(sum(train_score) \/ len(train_score)))\nprint(\"test: \" + str(sum(test_score) \/ len(test_score)))","a2bb8bf8":"I'm sure 99%+ accuracy is possible with this dataset with further work","0c637bf0":"A score of one is promising maybe we can attempt a test train split. I've avoided this so far due to the small dataset but it's worth looking at as further investigation. To reduce variance and produce a fairer result with the small dataset I have conducted a few train_test_splits with different random states. With a dataset this size it is probably possible to select a split which give complete 100% accuracy for the test set with careful selection but that wouldn't be real.","b3706063":"Moving on to AdaBoostClassifier","67293614":"Create new column for target with 0 and 1 instead of the B and M currently in the diagnosis column","529a7536":"Let's create synthetic data to help","21abc9b6":"Let's try logistic Regression","6a654659":"We will use cross validation because the dataset is relatively small","40379665":"Look through data","53c83f76":"Try a SVM as requested by the dataset creator","907d446b":"Load Dataset","139b53db":"Let's scale the data for better accuracy"}}