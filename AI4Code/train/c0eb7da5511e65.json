{"cell_type":{"6e268765":"code","5364adf3":"code","b41fe337":"code","17bf1e5e":"code","dc20cc77":"code","e7b7772f":"code","fa0f9e10":"markdown","0b69ac01":"markdown","c6e3854d":"markdown"},"source":{"6e268765":"%%writefile submission.py\n\nimport pydash\nimport time\nimport os\nimport random\nimport numpy as np\nfrom pydash import get, uniq, py_\nfrom operator import itemgetter\nfrom collections import defaultdict\nfrom typing import List, Dict\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom IPython.display import Image  \nfrom sklearn import tree\n\n\nclass RPSDecisionTreeEnsemble:\n    def __init__(\n        self, \n        min_window   = 4, \n        max_window   = 10, \n        max_history  = 500, \n        cutoff       = 0.33, \n        warmup       = 5, \n        model        = \"tree\",\n        model_config = {\n            # \"criterion\":             \"entropy\",\n            # \"ccp_alpha\":             0.05,\n            # \"min_impurity_decrease\": 0.1,\n            # \"min_samples_leaf\":      0.1\n        },\n        verbose=True\n    ):\n        self.obs  = None\n        self.conf = None\n\n        self.min_window   = min_window\n        self.max_window   = max_window\n        self.max_history  = max_history\n        self.cutoff       = cutoff\n        self.warmup       = warmup\n        self.model        = model\n        self.model_config = model_config\n        self.verbose      = verbose\n\n        self.history = {\n            \"step\":        [],\n            \"reward\":      [],\n            \"action\":      [],\n            \"opponent\":    [],\n            \"rotn_self\":   [],\n            \"rotn_opp\":    [],    \n            \"predictions\": defaultdict(list),\n        }\n        # self.winrates = {}\n        pass        \n\n    def __len__(self):\n        lengths = [\n            len(value)\n            for key, value in self.history.items()\n            if isinstance(value, list)\n        ]\n        return min(lengths) if len(lengths) else 0\n\n\n    def __call__(self, obs, conf):\n        return self.agent(obs, conf)\n\n\n    # obs  {'remainingOverageTime': 60, 'step': 1, 'reward': 0, 'lastOpponentAction': 0}\n    # conf {'episodeSteps': 1000, 'actTimeout': 1, 'runTimeout': 1200, 'signs': 3, 'tieRewardThreshold': 20, 'agentTimeout': 60}\n    def agent(self, obs, conf):\n        self.update_state(obs, conf)\n        \n        expected    = self.random_action()\n        predictions = []\n        if obs.step >= self.warmup:\n            predictions = [\n                ( expected, prob, model, window, target, source )\n                for window in range(self.min_window, min(self.max_window, self.warmup))\n                # for target in [ \"action\", \"opponent\", \"rotn_self\", \"rotn_opp\" ]\n                for target in [ \"opponent\" ]\n                for source in [\n                    [ \"action\",    \"opponent\" ],\n                    [ \"rotn_self\", \"rotn_opp\" ],\n                    [ \"step\", \"reward\", \"action\", \"opponent\", \"rotn_self\", \"rotn_opp\" ]   \n                ]\n                for expected, prob, model in [\n                    self.predict(target=target, source=source, window=window)\n                ]\n                if prob > self.cutoff\n            ]\n            predictions = sorted(predictions, key=itemgetter(1), reverse=True)\n            if len(predictions):\n                expected, prob, model, window, target, source = predictions[0]\n            \n            # for key, expected, prob in predictions:\n            #    self.history['predictions'][key].insert(0, expected)\n        \n        action = int(expected + 1) % conf.signs\n        action = int(action or 0)  % conf.signs\n        self.history['action'].insert(0, action)\n        \n        if self.verbose:\n            print('expected', expected)            \n            print('action', action)            \n            print('self.history', self.history)\n            if len(predictions):\n                print('prediction')\n                for expected, prob, model, window, target, source in predictions:\n                    print(expected, prob, model, window, target, source)\n                    self.plot(model, target, source)\n            print()\n        return action\n\n\n    def random_action(self):\n        return random.randint(0, self.conf.signs-1)\n\n\n    def update_state(self, obs, conf):\n        # Front load data, so self.history[0] is latest entry\n        self.obs  = obs\n        self.conf = conf\n        self.history['step'].insert(0, obs.step )\n        \n        if obs.step != 0:\n            last_reward = obs.reward - get(self.history['reward'], -1, 0)\n            self.history['reward'].insert(0, last_reward)\n            self.history['opponent'].insert(0, obs.lastOpponentAction )            \n\n        if len(self.history['opponent']) >= 1 and len(self.history['action']) >= 1:\n            rotn_opp = (self.history['opponent'][0] - self.history['action'][0]  ) % conf.signs\n            self.history['rotn_opp'].insert(0, rotn_opp )\n        \n        if len(self.history['opponent']) >= 2:\n            rotn_self = (self.history['opponent'][0] - self.history['opponent'][1]) % conf.signs \n            self.history['rotn_self'].insert(0, rotn_self )\n\n            \n    def predict(self, target='opponent', source=[], window=6, model_config={}):\n        source  = uniq(source)\n        fields  = uniq([ target ] + source) \n        dataset = {\n            name: get(self.history, name)\n            for name in fields\n        }\n        max_size = min(map(len, dataset.values()))\n        max_size = min(max_size, self.max_history) \n\n        expected = self.random_action()\n        prob     = 0.0\n        model    = None\n        try:     \n            if max_size > window:\n                X = np.stack([\n                    np.array([\n                        get(self.history, name)[n:n+window] \n                        for name in fields\n                    ]).flatten()\n                    for n in range(max_size-window) \n                ])\n                Y = np.array([\n                    get(self.history, target)[n+window]\n                    for n in range(max_size-window) \n                ])\n                Z = np.array([\n                    get(self.history, name)[0:0+window]\n                    for name in fields\n                ]).flatten().reshape(1, -1)\n\n                model = self.get_model(model_config)\n                model.fit(X, Y)\n                expected = model.predict(Z)[0]\n                index    = model.classes_.tolist().index(expected)\n                probs    = model.predict_proba(Z)\n                prob     = probs[0][index]\n        except Exception as exception: \n            raise exception\n            pass\n        return expected, prob, model\n\n\n    def get_model(self, model_config):\n        model_config = { **self.model_config, **model_config }\n        # DOCS: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html\n        if self.model == \"tree\":\n            return DecisionTreeClassifier( **model_config )\n        assert self.model in [\"tree\"]\n\n        \n    # DOCS: https:\/\/mljar.com\/blog\/visualize-decision-tree\/\n    # DOCS: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.export_text.html\n    def plot(self, model, target, source):\n        if model is None: return\n        if self.verbose:\n            fields = uniq( [ target ] + source )\n            # print( f'target = {target} | source = {source}' )\n            print( tree.export_text(model, \n                                    # feature_names=fields, \n                                    show_weights=True) \n                 )\n        \n    \ninstance = RPSDecisionTreeEnsemble()\ndef kaggle_agent(obs, conf):\n    return instance.agent(obs, conf)","5364adf3":"%run -i 'submission.py'","b41fe337":"def random_agent(observation, configuration):\n    return random.randint(0, configuration.signs-1)\n\ndef rock_agent(observation, configuration):\n    return 0\n\ndef paper_agent(observation, configuration):\n    return 1\n\ndef scissors_agent(observation, configuration):\n    return 2\n\ndef sequential_agent(observation, configuration):\n    return observation.step % configuration.signs","17bf1e5e":"from kaggle_environments import make, evaluate\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 25}, debug=True)\n# env = make(\"rps\", debug=True)\n# env.run([\"submission.py\", sequential_agent])\nenv.run([ RPSDecisionTreeEnsemble(verbose=True), sequential_agent ])\nenv.render(mode=\"ipython\", width=400, height=400)","dc20cc77":"# env = make(\"rps\", debug=False)\n# env.run([\"submission.py\", \"submission.py\"])\n# env.render(mode=\"ipython\", width=400, height=400)","e7b7772f":"# results = np.array([\n#     evaluate(\"rps\", [\"submission.py\", random_agent])\n#     for n in range(3)\n# ]).reshape(-1,2)\n\n# print('results\\n', results)\n# print('mean', np.mean(results, axis=0))","fa0f9e10":"# Evaluation","0b69ac01":"# Further Reading\n\nThis notebook is part of a series exploring Rock Paper Scissors:\n- [Rock Paper Scissors - PI Bot](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-pi-bot)\n- [Rock Paper Scissors - Anti-PI Bot](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-anti-pi-bot)\n- [Rock Paper Scissors - De Bruijn Sequence](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-de-bruijn-sequence)\n- [Rock Paper Scissors - Anti-Rotn](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-anti-rotn)\n- [Rock Paper Scissors - Random Agent](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-random-agent)\n- [Rock Paper Scissors - Random Seed Search](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-random-seed-search)\n- [Rock Paper Scissors - Weighted Random Agent](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-weighted-random-agent)\n- [Rock Paper Scissors - Statistical Prediction](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-statistical-prediction)\n- [Rock Paper Scissors - RNG Statistics](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-rng-statistics)\n- [Rock Paper Scissors - XGBoost](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-xgboost)\n- [Rock Paper Scissors - Multi Stage Decision Tree](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-multi-stage-decision-tree)\n- [Rock Paper Scissors - Decision Tree Ensemble](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-decision-tree-ensemble)","c6e3854d":"# Rock Paper Scissors - Decision Tree Ensemble\n\nThe idea here is to create an ensemble of Decision Trees, using different windows and datasets\n\nThe implemention here is either buggy, or there is something fundamentally wrong with the logic. This scores far worse than: \n- [Rock Paper Scissors - Multi Stage Decision Tree](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-multi-stage-decision-tree)"}}