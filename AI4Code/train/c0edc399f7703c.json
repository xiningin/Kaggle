{"cell_type":{"9e9d7264":"code","f06d7a1c":"code","d23d7def":"code","8efe9e8b":"code","2cf1c52f":"code","2162c057":"code","32531f3d":"code","cdb857bd":"code","fded30b8":"code","d16c2d63":"code","c15f89f6":"code","9e5e7f06":"code","b5bcf688":"code","e0b40fdc":"code","0909541e":"code","b871bbff":"code","4eaa801f":"code","6acfd620":"code","9be8b95c":"code","fdb4c4fc":"code","861101a3":"code","abeb5f8e":"code","d6e9fb4b":"code","921a97c5":"markdown","9c7a44fa":"markdown","61629225":"markdown","c4a9ab75":"markdown","cffedb6e":"markdown","26b2ccbe":"markdown","8dd21462":"markdown","a8a4dafa":"markdown"},"source":{"9e9d7264":"import numpy as np \nimport pandas as pd\nfrom matplotlib import pyplot as pp\n%matplotlib inline\nimport itertools\nfrom sklearn.preprocessing import OneHotEncoder\nfrom category_encoders import CountEncoder, TargetEncoder, CatBoostEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.feature_selection import SelectFromModel\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f06d7a1c":"train_data = pd.read_csv('\/kaggle\/input\/financial-inclusion-data\/323388_649935_compressed_Train_v2.csv\/Train_v2.csv')\n\ntrain_data.head()","d23d7def":"train_data.drop(['year'], axis = 1, inplace = True)\ntrain_data.head()","8efe9e8b":"def change_series(data):\n    listy = []\n    for i in data['bank_account']:\n        if i == 'Yes':\n            listy.append(1)\n        else:\n            listy.append(0)\n            \n    return listy\n\ntrain_data['bank_account'] = change_series(train_data)","2cf1c52f":"train_data.isna().sum()","2162c057":"len(train_data)","32531f3d":"train_data.dtypes","cdb857bd":"pp.hist((train_data['household_size']), range = (0,(train_data['household_size'].max())))","fded30b8":"pp.hist(train_data['age_of_respondent'], range = (0,train_data['age_of_respondent'].max()))","d16c2d63":"y = train_data['bank_account']\ntrain_data.drop(['bank_account'], axis =1 , inplace = True)\n\ninteractions = list(itertools.combinations(train_data.columns,2))\n\nfor i in interactions:\n    train_data[str(i[0])+'_'+ str(i[1])] = train_data[i[0]].astype(str) + '_' + train_data[i[1]].astype(str)\n\ncategorical_columns = [col for col in train_data.columns if train_data[col].dtypes == 'object']\nnumerical_columns = [col for col in train_data.columns if train_data[col].dtypes == 'int64' or train_data[col].dtypes == 'float64']","c15f89f6":"categorical_columns ","9e5e7f06":"numerical_columns","b5bcf688":"#valid_fraction = 0.8\n#val = valid_fraction*(len(train_data)+1)\n#X_train = train_data[:int(val)]\n#X_val = train_data[int(val):]\n\nX_train, X_val, y_train, y_val = train_test_split(train_data, y, train_size = 0.8, test_size = 0.2, \n                                                  random_state = 0)","e0b40fdc":"#encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\n\n#X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_columns]))\n#X_val_encoded = pd.DataFrame(encoder.transform(X_val[categorical_columns]))\n\n#X_train_encoded.index = X_train.index\n#X_val_encoded.index = X_val.index\n\n#num_train = X_train.drop(categorical_columns, axis = 1)\n#num_test = X_val.drop(categorical_columns, axis =1)\n\n#final_train = pd.concat([X_train_encoded, num_train], axis = 1)\n#final_test = pd.concat([X_val_encoded, num_test], axis = 1)\n","0909541e":"encoder = CountEncoder(cols = categorical_columns)\n\nX_train_encoded = encoder.fit_transform(X_train[categorical_columns])\nX_val_encoded = encoder.transform(X_val[categorical_columns])\n\nnum_train = X_train[numerical_columns]\nnum_val = X_val[numerical_columns]\n\nfinal_train = pd.concat([X_train_encoded, num_train],axis = 1)\nfinal_val = pd.concat([X_val_encoded, num_val], axis = 1)","b871bbff":"#model = RandomForestClassifier(random_state = 0)\n#model.fit(final_train, y_train)\n#preds = model.predict(final_val)\n\n\n#model = XGBClassifier()\n#model.fit(final_train, y_train)\n#preds = model.predict(final_val)\n\n\nmodel = LGBMClassifier(random_state = 0, objective = 'binary', n_jobs = 4)\nmodel.fit(final_train, y_train)","4eaa801f":"first_score = cross_val_score(model, final_val, y_val, cv = 5, scoring = 'roc_auc')\nfirst_score.mean()","6acfd620":"#selection = SelectFromModel(model, threshold = 0.15)\nfor i in zip(train_data.columns, model.feature_importances_):\n    print(i)","9be8b95c":"model.get_params()","fdb4c4fc":"param_grid = {\n    'max_depth': [20,25],\n    'n_estimators': [700,1000],\n    'learning_rate': [0.01],\n    'num_leaves': [100, 200],\n    'colsample_bytree': [0.7, 0.8],\n    'reg_alpha': [1.1, 1.2, 1.3],\n    'reg_lambda': [1.1, 1.2, 1.3],\n    'min_split_gain': [0.3, 0.4],\n    'subsample': [0.7, 0.8, 0.9],\n    'subsample_freq': [20]\n}\n\n\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\nsearch = RandomizedSearchCV(model, param_grid, cv = 5, scoring = 'roc_auc', n_jobs = 4)\n\nsearch.fit(final_train, y_train)","861101a3":"search.best_params_","abeb5f8e":"final_model = LGBMClassifier(random_state = 0, objective = 'binary', n_jobs = 4, \n                            learning_rate = 0.01, n_estimators = 700, num_leaves = 100, \n                             max_depth = 25, subsample_freq = 20, subsample = 0.8, reg_lambda = 1.3,\n                            reg_alpha = 1.1, mni_split_gain = 0.4, colsamaple_bytree = 0.7)\nfinal_model.fit(final_train, y_train)","d6e9fb4b":"final_score = cross_val_score(final_model, final_val, y_val, cv = 5, scoring = 'roc_auc')\nfinal_score.mean()","921a97c5":"# Building base model after model selection","9c7a44fa":"# Hyperparameter Tuning","61629225":"# Data Exploration and cleaning","c4a9ab75":"# Feature Engineering","cffedb6e":"# Building of final model","26b2ccbe":"# Importing the necessary libraries ","8dd21462":"# Evaluating final model","a8a4dafa":"# Evaluating base model"}}