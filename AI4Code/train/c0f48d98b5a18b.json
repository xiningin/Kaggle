{"cell_type":{"393215d1":"code","b6cc9b41":"code","e427dd29":"code","a5f2e1c0":"code","9d28c142":"code","35cda530":"code","aad9cf10":"code","0207209c":"code","c0505ac0":"code","3dcb2413":"code","75143650":"code","dcafdad3":"code","908b352e":"code","b786413a":"code","355765de":"code","8e17a65e":"code","87661561":"code","772f1c7b":"code","2cba299b":"code","1db86ad4":"code","004b34e9":"code","3ffe0a06":"code","3a270a4a":"code","3d0ec199":"code","857c2de7":"code","846868de":"code","79af70bd":"code","6dd5a676":"code","bcf6df43":"code","9fd2855b":"code","1a556c23":"code","65c49711":"code","01e24e0e":"code","4895c36e":"code","3b412fb5":"code","353e66b6":"code","a51f7385":"code","3017dfe5":"code","885c9105":"code","686072ca":"code","7b4afc3e":"markdown","eb2fc9fd":"markdown","e69589d7":"markdown","51337bf4":"markdown","76b57403":"markdown","7f138677":"markdown","3e434325":"markdown","1aa38408":"markdown","441eeea0":"markdown","bdb1be15":"markdown","52fcdd45":"markdown","5d88126e":"markdown","9b06b6f2":"markdown","f9cadab3":"markdown","58daafbe":"markdown","9e9e4dbe":"markdown","920c626b":"markdown","0fc87aed":"markdown","eb70f70b":"markdown","2d198c9f":"markdown","8797dea8":"markdown"},"source":{"393215d1":"import numpy as np \nimport pandas as pd\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \nfrom wordcloud import WordCloud, STOPWORDS\nimport warnings\nwarnings.simplefilter(\"ignore\")","b6cc9b41":"tweets_df = pd.read_csv(\"\/kaggle\/input\/emma-raducanu\/emma_tweets.csv\")","e427dd29":"print(f\"data shape: {tweets_df.shape}\")","a5f2e1c0":"tweets_df.info()","9d28c142":"tweets_df.describe()","35cda530":"tweets_df.head()","aad9cf10":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()\/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","0207209c":"missing_data(tweets_df)","c0505ac0":"def unique_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    uniques = []\n    for col in data.columns:\n        unique = data[col].nunique()\n        uniques.append(unique)\n    tt['Uniques'] = uniques\n    return(np.transpose(tt))","3dcb2413":"unique_values(tweets_df)","75143650":"def most_frequent_values(data):\n    total = data.count()\n    tt = pd.DataFrame(total)\n    tt.columns = ['Total']\n    items = []\n    vals = []\n    for col in data.columns:\n        itm = data[col].value_counts().index[0]\n        val = data[col].value_counts().values[0]\n        items.append(itm)\n        vals.append(val)\n    tt['Most frequent item'] = items\n    tt['Frequence'] = vals\n    tt['Percent from total'] = np.round(vals \/ total * 100, 3)\n    return(np.transpose(tt))","dcafdad3":"most_frequent_values(tweets_df)","908b352e":"def plot_count(feature, title, df, size=1, ordered=True):\n    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n    total = float(len(df))\n    if ordered:\n        g = sns.countplot(df[feature], order = df[feature].value_counts().index[:20], palette='Set3')\n    else:\n        g = sns.countplot(df[feature], palette='Set3')\n    g.set_title(\"Number and percentage of {}\".format(title))\n    if(size > 2):\n        plt.xticks(rotation=90, size=8)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()\/2.,\n                height,\n                '{:1.2f}%'.format(100*height\/total),\n                ha=\"center\") \n    plt.show()    ","b786413a":"plot_count(\"user_name\", \"User name\", tweets_df,4)","355765de":"plot_count(\"user_location\", \"User location\", tweets_df,4)","8e17a65e":"plot_count(\"source\", \"Source\", tweets_df,4)","87661561":"from PIL import Image\nimport numpy as np\nmask = 255 - np.array(Image.open('\/kaggle\/input\/emma-raducanu\/tennis_ball.png'))","772f1c7b":"from wordcloud import WordCloud, STOPWORDS\ndef show_wordcloud(data, title=\"\", mask=None, color=\"white\"):\n    text = \" \".join(t for t in data.dropna())\n    stopwords = set(STOPWORDS)\n    stopwords.update([\"t\", \"co\", \"https\", \"amp\", \"U\", \"Emma\", \"EmmaRaducanu\", \"Raducanu\", \"USOpen\", \"USOpen2021\", \"US\", \"Open\", \"2021\", \"tenni\"])\n    wordcloud = WordCloud(stopwords=stopwords, scale=4, max_font_size=50, max_words=500,mask=mask,background_color=color).generate(text)\n    fig = plt.figure(1, figsize=(16,16))\n    plt.axis('off')\n    fig.suptitle(title, fontsize=20)\n    fig.subplots_adjust(top=1.0)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.show()","2cba299b":"show_wordcloud(tweets_df['text'], title = 'Prevalent words in tweets', mask=mask)","1db86ad4":"uk_df = tweets_df.loc[tweets_df.user_location==\"United Kingdom\"]\nshow_wordcloud(uk_df['text'], title = 'Prevalent words in tweets from UK', mask=mask)","004b34e9":"def plot_features_distribution(features, title, df, isLog=False):\n    plt.figure(figsize=(12,6))\n    plt.title(title)\n    for feature in features:\n        if(isLog):\n            sns.distplot(np.log1p(df[feature]),kde=True,hist=False, bins=120, label=feature)\n        else:\n            sns.distplot(df[feature],kde=True,hist=False, bins=120, label=feature)\n    plt.xlabel('')\n    plt.legend()\n    plt.show()\n","3ffe0a06":"tweets_df['hashtags'] = tweets_df['hashtags'].replace(np.nan, \"['None']\", regex=True)\ntweets_df['hashtags'] = tweets_df['hashtags'].apply(lambda x: x.replace('\\\\N',''))\ntweets_df['hashtags_count'] = tweets_df['hashtags'].apply(lambda x: len(x.split(',')))\nplot_features_distribution(['hashtags_count'], 'Hashtags per tweet (all data)', tweets_df)","3a270a4a":"tweets_df['hashtags_individual'] = tweets_df['hashtags'].apply(lambda x: x.split(','))\nfrom itertools import chain\nall_hashtags = set(chain.from_iterable(list(tweets_df['hashtags_individual'])))\nprint(f\"There are totally: {len(all_hashtags)}\")","3d0ec199":"tweets_df['hashtags_individual'].head()","857c2de7":"tweets_df['datedt'] = pd.to_datetime(tweets_df['date'])","846868de":"tweets_df['year'] = tweets_df['datedt'].dt.year\ntweets_df['month'] = tweets_df['datedt'].dt.month\ntweets_df['day'] = tweets_df['datedt'].dt.day\ntweets_df['dayofweek'] = tweets_df['datedt'].dt.dayofweek\ntweets_df['hour'] = tweets_df['datedt'].dt.hour\ntweets_df['minute'] = tweets_df['datedt'].dt.minute\ntweets_df['dayofyear'] = tweets_df['datedt'].dt.dayofyear\ntweets_df['date_only'] = tweets_df['datedt'].dt.date","79af70bd":"tweets_agg_df = tweets_df.groupby([\"date_only\"])[\"text\"].count().reset_index()\ntweets_agg_df.columns = [\"date_only\", \"count\"]","6dd5a676":"def plot_time_variation(df, x='date_only', y='count', hue=None, size=1, title=\"\", is_log=False):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    g = sns.lineplot(x=x, y=y, hue=hue, data=df)\n    plt.xticks(rotation=90)\n    if hue:\n        plt.title(f'{y} grouped by {hue} | {title}')\n    else:\n        plt.title(f'{y} | {title}')\n    if(is_log):\n        ax.set(yscale=\"log\")\n    ax.grid(color='black', linestyle='dotted', linewidth=0.75)\n    plt.show() ","bcf6df43":"plot_time_variation(tweets_agg_df, title=\"Number of tweets \/ day of year\",size=3)","9fd2855b":"plot_count(\"dayofweek\", \"tweets \/ day of week\", tweets_df, size=3, ordered=False)","1a556c23":"plot_count(\"dayofyear\", \"tweets \/ day of year\", tweets_df, size=3, ordered=False)","65c49711":"plot_count(\"date_only\", \"tweets \/ date\", tweets_df,size=4, ordered=False)","01e24e0e":"plot_count(\"hour\", \"tweets \/ hour\", tweets_df,size=4, ordered=False)","4895c36e":"plot_count(\"minute\", \"tweets \/ minute\", tweets_df,size=5, ordered=False)","3b412fb5":"from nltk.sentiment import SentimentIntensityAnalyzer\nfrom textblob import TextBlob\nimport warnings\nwarnings.simplefilter(\"ignore\")\nsia = SentimentIntensityAnalyzer()\ndef find_sentiment(post):\n    try:\n        if sia.polarity_scores(post)[\"compound\"] > 0:\n            return \"Positive\"\n        elif sia.polarity_scores(post)[\"compound\"] < 0:\n            return \"Negative\"\n        else:\n            return \"Neutral\"  \n    except:\n        return \"Neutral\"","353e66b6":"def plot_sentiment(df, feature, title):\n    counts = df[feature].value_counts()\n    percent = counts\/sum(counts)\n\n    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 5))\n\n    counts.plot(kind='bar', ax=ax1, color='green')\n    percent.plot(kind='bar', ax=ax2, color='blue')\n    ax1.set_ylabel(f'Counts : {title} sentiments', size=12)\n    ax2.set_ylabel(f'Percentage : {title} sentiments', size=12)\n    plt.suptitle(f\"Sentiment analysis: {title}\")\n    plt.tight_layout()\n    plt.show()","a51f7385":"tweets_df['text_sentiment'] = tweets_df['text'].apply(lambda x: find_sentiment(x))\nplot_sentiment(tweets_df, 'text_sentiment', 'Text')","3017dfe5":"show_wordcloud(tweets_df.loc[tweets_df['text_sentiment']=='Positive', 'text'], title = 'Prevalent words in text (Positive sentiment)', mask=mask)","885c9105":"show_wordcloud(tweets_df.loc[tweets_df['text_sentiment']=='Neutral', 'text'], title = 'Prevalent words in text (Neutral sentiment)', mask=mask, color='orange')","686072ca":"show_wordcloud(tweets_df.loc[tweets_df['text_sentiment']=='Negative', 'text'], title = 'Prevalent words in text (Negative sentiment)', mask=mask, color='black')","7b4afc3e":"### Hashtags analysis","eb2fc9fd":"### Most frequent values","e69589d7":"We can spot themes and concepts that we know are sensitive or negative for the British public, like \"immigrant\", \"racist\" as well as generaly negative, like \"pressure\", \"airport closed\", \"sad\", \"doubt\", \"sorry\". Interestingly, \"Piers Morgan\" seems to be very frequent as well in the negative tweets.","51337bf4":"# Data exploration\n\n\n## Glimpse the data","76b57403":"# Data preparation\n\n## Load packages","7f138677":"# Sentiment Analysis\n\nWe explore the sentiment in the tweets.","3e434325":"### User name","1aa38408":"### Unique values","441eeea0":"### Tweet source","bdb1be15":"### User location","52fcdd45":"## Load data","5d88126e":"### Extract date and time features","9b06b6f2":"### Time variation","f9cadab3":"### Text wordcloauds","58daafbe":"<img src=\"https:\/\/i.guim.co.uk\/img\/media\/ac445e5290f2e9efca503c5465c89bee775486b5\/0_525_4640_2783\/master\/4640.jpg?width=445&quality=45&auto=format&fit=max&dpr=2&s=a7cdd363aba9eeea424e3c8a5f1c1928\"><\/img>","9e9e4dbe":"We remove from the words not only frequent words but also specific words like `EmmaRaducanu`, `Emma`, `USOpen` and variants.","920c626b":"## Visualize the data distribution\n\n\n<img src=\"https:\/\/tennishead.net\/wp-content\/uploads\/2021\/09\/Raducanu-impresses-Henman.jpeg\" width=500><\/img>","0fc87aed":"We can spot very positive expressions used with high frequency, like \"congratulation\", \"win\", \"amazing\", \"champion\", \"role model\", \"achievement\", \"brilliant\". ","eb70f70b":"<h1>Explore Tweets about Emma Raducanu<\/h1>\n\n\n# Introduction\n\n\nThe Dataset we are using here is collected using Twitter API, **tweepy** and Python package.\nThe hashtag used to filter the tweets is #EmmaRaducanu.\nEmma Raducanu is the winner of women US Open 2021. The teen Brit with Romanian and Chinese parents, born in Canada and arrived in Great Britain at 2 years old, stormed the US event from qualifiers, playing 10 games without losing one single set (20 sets won in a row). She is the first British woman to win a Grand Slam since 1977 (Virginia Wade), the first women in US Open history to win the event from the qualifiers. She jumped more than 120 points in the ranking to land on 23rd position. She is also a very good student, landing A grades in mathematics and economy (her preferred academic subjects) in her selective grammar school from south London. She enjoys very much the food prepared for her by `Mamaia` (`Grannie`, in Romanian) which she is visiting several times per year in downtown Bucharest.\n\n<img src=\"https:\/\/s.iw.ro\/gateway\/g\/ZmlsZVNvdXJjZT1odHRwJTNBJTJGJTJG\/c3RvcmFnZTA3dHJhbnNjb2Rlci5yY3Mt\/cmRzLnJvJTJGc3RvcmFnZSUyRjIwMjEl\/MkYwOSUyRjEyJTJGMTM4MjkyMF8xMzgy\/OTIwX2VtbWEtcmFkdWNhbnUtaW1icmF0\/aXNhbmQtdHJvZmV1bC11cy1vcGVuLXBy\/b2ZpbWVkaWEtMDYzMTY1NzEyNy5qcGcm\/dz03ODAmaD00NDAmaGFzaD03OGM2ZWU2\/NTM1N2MwMTA0YzgyZjc0YmU5ZTc2MmFhNw==.thumb.jpg\" width=600><\/img>","2d198c9f":"### Missing data","8797dea8":"Most of the tweets show a positive sentiment, with the negative sentiment being the smaller category."}}