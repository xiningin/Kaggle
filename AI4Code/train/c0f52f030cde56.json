{"cell_type":{"805d81da":"code","1a031d56":"code","7cb9acd3":"code","b07ef0a8":"code","90c21f50":"code","2cacecd1":"code","4a6c4769":"code","33f0279a":"code","677ce5fe":"code","2ce6c4f2":"code","a8a10df4":"code","fe8c2c3f":"code","a798eac3":"code","7d4e8f45":"code","33975d35":"code","c72bf742":"code","c21d0b04":"code","be0ac3b2":"code","10ad1596":"code","958b58fc":"code","d0dcbc4e":"code","e9e4930d":"code","9d24326e":"code","86841ec5":"code","f7762965":"code","f084b1e8":"code","6b3729ce":"code","d5230398":"code","04b15abb":"markdown"},"source":{"805d81da":"#Importing necessary modules\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error\n\nimport xgboost\nfrom xgboost import XGBRegressor\nfrom sklearn.decomposition import PCA","1a031d56":"#Reading the train and test dataset\n\ntrain_df = pd.read_csv('..\/input\/mercedesbenz-greener-manufacturing-dataset\/train.csv')\ntest_df = pd.read_csv('..\/input\/mercedesbenz-greener-manufacturing-dataset\/test.csv')\n\nprint(train_df.shape, test_df.shape)\ntrain_df","7cb9acd3":"#Check for y variable range\n\nplt.figure(figsize=(12,8))\nplt.scatter(range(train_df.ID.nunique()), np.sort(train_df.y))\nplt.show()","b07ef0a8":"#Check for frequency of y variable\n\nplt.figure(figsize=(12,8))\nsns.histplot(train_df.y, bins=50, kde=False)\nplt.show()","90c21f50":"# Checking datatypes of the independent variables\n\ntrain_dtypes = train_df.dtypes.reset_index()\ntrain_dtypes.columns = ('Count','Column Type')\ntrain_dtypes.groupby('Column Type').aggregate('count').reset_index()","2cacecd1":"#Datatypes\n\ntrain_dtypes.loc[:10,:]","4a6c4769":"#Check for missing elements\n\ntrain_df.isnull().any().unique()","33f0279a":"mv = train_df.isnull().sum().reset_index()\nmv.columns = ['Column Name', 'Missing Count']\nmv = mv[mv['Missing Count']>0]\nmv","677ce5fe":"# Checking for unique values in columns\n\nunique_values_dictionary = {}\n\nfor c in train_df.columns[10:]:\n    un_v = str(np.sort(train_df[c].unique()).tolist())\n    tlist = unique_values_dictionary.get(un_v,[])\n    tlist.append(c)\n    unique_values_dictionary[un_v] = tlist[:]\n\nfor uv, cc in unique_values_dictionary.items():\n    print(\"Columns containing unique values : \",uv)\n    print(cc)\n    print('--------------------------------------------------------')","2ce6c4f2":"#Checking unique value distribution for object type varibles\n\nvariable = 'X0'\nplt.figure(figsize=(12,6))\nsns.stripplot(x=variable, y='y', data=train_df, order=np.sort(train_df[variable].unique()))\nplt.show()","a8a10df4":"variable = 'X1'\nplt.figure(figsize=(12,6))\nsns.stripplot(x=variable, y='y', data=train_df, order=np.sort(train_df[variable].unique()))\nplt.show()","fe8c2c3f":"variable = 'X2'\nplt.figure(figsize=(12,6))\nsns.boxplot(x=variable, y='y', data=train_df, order=np.sort(train_df[variable].unique()))\nplt.show()","a798eac3":"variable = 'X3'\nplt.figure(figsize=(12,6))\nsns.violinplot(x=variable, y='y', data=train_df, order=np.sort(train_df[variable].unique()))\nplt.show()","7d4e8f45":"variable = 'X4'\nplt.figure(figsize=(12,6))\nsns.boxenplot(x=variable, y='y', data=train_df, order=np.sort(train_df[variable].unique()))\nplt.show()","33975d35":"variable = 'X5'\nplt.figure(figsize=(12,6))\nsns.boxplot(x=variable, y='y', data=train_df, order=np.sort(train_df[variable].unique()))\nplt.show()","c72bf742":"variable = 'X6'\nplt.figure(figsize=(12,6))\nsns.violinplot(x=variable, y='y', data=train_df, order=np.sort(train_df[variable].unique()))\nplt.show()","c21d0b04":"variable = 'X8'\nplt.figure(figsize=(12,6))\nsns.boxplot(x=variable, y='y', data=train_df, order=np.sort(train_df[variable].unique()))\nplt.show()","be0ac3b2":"#Checking unique distribution of binary varibles\n\nZeros = []\nOnes = []\nListOfColumns = unique_values_dictionary['[0, 1]']\nN = np.arange(len(ListOfColumns))\n\nfor cc in ListOfColumns:\n    Zeros.append((train_df[cc]==0).sum())\n    Ones.append((train_df[cc]==1).sum())\n\nplt.figure(figsize=(10,100))\nplot1 = plt.barh(N, Zeros, color='r')\nplot2 = plt.barh(N, Ones, left=Zeros, color='b')\nplt.legend((plot1[0],plot2[0]),('Zeros','Ones'))\nplt.yticks(N, ListOfColumns)\nplt.show()","10ad1596":"#Checking the mean y value across the binary variables\n\nZeros_m = []\nOnes_m = []\nListOfColumns = unique_values_dictionary['[0, 1]']\n\nfor c in ListOfColumns:\n    Zeros_m.append(train_df.loc[train_df[c]==0].y.mean())\n    Ones_m.append(train_df.loc[train_df[c]==1].y.mean())\n\nym = pd.DataFrame({\"Col\":ListOfColumns+ListOfColumns,\"Value\":[0]*len(ListOfColumns)+[1]*len(ListOfColumns),\"ym\":Zeros_m+Ones_m})\nym = ym.pivot(\"Col\",'Value',\"ym\")\n\nplt.figure(figsize=(10,100))\nsns.heatmap(ym)\nplt.show()","958b58fc":"#Relationship between ID and y\n\nplt.figure(figsize=(12,6))\nplt.scatter(train_df.ID, train_df.y, alpha=0.5)\nplt.grid()\nplt.show()","d0dcbc4e":"#Checking ID distribtuion across training and test dataset\n\nIDS = pd.concat([train_df.ID, test_df.ID], axis=1)\nIDS.columns = ['Train','Test']\n\nplt.figure(figsize=(8,8))\nplt.subplot(2,1,1)\nsns.violinplot(x=IDS.Train)\nplt.subplot(2,1,2)\nsns.violinplot(x=IDS.Test)\nplt.show()","e9e4930d":"#Applying Label Encoder\n\nfor i in list(['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8']):\n    train_df[i] = LabelEncoder().fit_transform(train_df[i])","9d24326e":"#Splititng the Dataset\n\nx = train_df.drop(['ID','y'], axis=1)\ny = train_df.y\n\nx1,x2,y1,y2 = train_test_split(x,y,test_size=0.2, random_state=0)\n\nprint(x.shape, y.shape, x1.shape, y1.shape, x2.shape, y2.shape)","86841ec5":"#Dimensionality Reduction\n\nNtrainx = PCA(n_components=2).fit_transform(x)","f7762965":"# Applying XGBoost Regressor\n\nXGB = XGBRegressor().fit(x1,y1).predict(x2)\nprint(\"The Mean Squared Error for XGB is\",np.sqrt(mean_squared_error(XGB, y2)))","f084b1e8":"#Predicting y value for test dataset\n\nfor i in test_df.columns[1:9]:\n    test_df[i] = LabelEncoder().fit_transform(test_df[i])\n    \nxx = test_df.drop('ID', axis=1)\n\nXGB = XGBRegressor().fit(x,y).predict(xx)\nprint(\"The predicted y values for the test dataset are :\",XGB)","6b3729ce":"# Bonus - Check for importance of variables that affect y value\n\ndef xgb_r2_score(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'r2', r2_score(labels, preds)\n\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 6,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:squarederror',\n    #'silent': 1\n}\ndtrain = xgboost.DMatrix(x, y, feature_names=x.columns.values)\nmodel = xgboost.train(dict(xgb_params), dtrain, num_boost_round=100, feval=xgb_r2_score, maximize=True)\n\nfig, ax = plt.subplots(figsize=(12,18))\nxgboost.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","d5230398":"#<<<-----------------------------------THE END------------------------------------------->>>","04b15abb":"# Mercedes Benz Greener Manufacturing "}}