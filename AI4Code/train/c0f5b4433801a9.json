{"cell_type":{"f05121f3":"code","07a47c18":"code","506bcd4a":"code","d001c417":"code","2074e7f6":"code","74a76778":"code","3203f12c":"code","59f6e9f6":"code","a8bc3540":"code","e9f99eb4":"code","5e598eac":"code","39a291f8":"code","ff13f67d":"code","afdde7ca":"code","36c227ab":"code","3f8bbaeb":"code","7c428535":"code","59011431":"code","6a60c778":"code","866c6c10":"code","04ba3137":"code","5912cbaf":"code","8fd0bf7e":"code","8690df08":"code","8ea5c31f":"code","5bc92638":"code","e96cafaa":"code","1be28bcb":"code","dbfd916e":"code","f20c49b0":"code","c18a2306":"code","912d239f":"code","c7373acb":"code","51b0c370":"markdown","dbb870d3":"markdown","6af9c089":"markdown"},"source":{"f05121f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","07a47c18":"# dframe = pd.read_csv(\"..\/input\/entity-annotated-corpus\/ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)\nf=open(\"..\/input\/wikiner-data\/aij-wikiner-fr-wp2.txt\", \"r\")\ndata=[]\ncontents =f.readlines()\nindx=0\nfor x in contents:\n    words=x.split()\n#     print(len(words))\n    for i in range(len(words)):\n        \n        tags=words[i].split(\"|\")\n#         print(len(tags))\n        data.append([indx,tags[0],tags[2]])\n#     print(words)\n    indx+=1\nwikiner_data= pd.DataFrame(data, columns=['sentence', 'word', 'tag'])","506bcd4a":"wikiner_data.head(20)","d001c417":"wikiner_data.head()","2074e7f6":"class SentenceGetter(object):\n    \n    def __init__(self, dataset):\n        self.n_sent = 1\n        self.dataset = dataset\n        self.empty = False\n        agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n                                                       \n                                                        s[\"tag\"].values.tolist())]\n        self.grouped = self.dataset.groupby(\"sentence\").apply(agg_func)\n        self.sentences = [s for s in self.grouped]\n    \n    def get_next(self):\n        try:\n            s = self.grouped[\"sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None","74a76778":"getter = SentenceGetter(wikiner_data)","3203f12c":"sentences = getter.sentences","59f6e9f6":"maxlen = max([len(s) for s in sentences])\nprint ('Maximum sequence length:', maxlen)","a8bc3540":"# Check how long sentences are so that we can pad them\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use(\"ggplot\")","e9f99eb4":"plt.hist([len(s) for s in sentences], bins=50)\nplt.show()","5e598eac":"words = list(set(wikiner_data[\"word\"].values))\nwords.append(\"ENDPAD\")","39a291f8":"n_words = len(words); n_words","ff13f67d":"tags = list(set(wikiner_data[\"tag\"].values))","afdde7ca":"n_tags = len(tags); n_tags","36c227ab":"word2idx = {w: i for i, w in enumerate(words)}\ntag2idx = {t: i for i, t in enumerate(tags)}","3f8bbaeb":"from keras.preprocessing.sequence import pad_sequences\nX = [[word2idx[w[0]] for w in s] for s in sentences]","7c428535":"X = pad_sequences(maxlen=242, sequences=X, padding=\"post\",value=n_words - 1)","59011431":"y = [[tag2idx[w[1]] for w in s] for s in sentences]","6a60c778":"y = pad_sequences(maxlen=242, sequences=y, padding=\"post\", value=tag2idx[\"O\"])","866c6c10":"from keras.utils import to_categorical\ny = [to_categorical(i, num_classes=n_tags) for i in y]","04ba3137":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","5912cbaf":"from keras.models import Model, Input\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional","8fd0bf7e":"!pip install git+https:\/\/www.github.com\/keras-team\/keras-contrib.git\n","8690df08":"from keras.models import Model, Input\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\nfrom keras_contrib.layers import CRF\ninput = Input(shape=(242,))\nmodel = Embedding(input_dim=n_words + 1, output_dim=20,\n                  input_length=242, mask_zero=True)(input)  # 20-dim embedding\nmodel = Bidirectional(LSTM(units=50, return_sequences=True,\n                           recurrent_dropout=0.1))(model)  # variational biLSTM\nmodel = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\ncrf = CRF(n_tags)  # CRF layer\nout = crf(model)  # output\nmodel = Model(input, out)","8ea5c31f":"model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\nmodel.summary()","5bc92638":"history = model.fit(X_train, np.array(y_train), batch_size=32, epochs=5, validation_split=0.2, verbose=1)","e96cafaa":"# i = 1\n# p = model.predict(np.array([X_test[i]]))\n# p = np.argmax(p, axis=-1)\n# print(\"{:15} ({:5}): {}\".format(\"Word\", \"True\", \"Pred\"))\n# for w,pred in zip(X_test[i],p[0]):\n#     print(\"{:15}: {}\".format(words[w],tags[pred]))","1be28bcb":"idx2tag = {i: w for w, i in tag2idx.items()}\n\ndef pred2label(pred):\n    out = []\n    for pred_i in pred:\n        out_i = []\n        for p in pred_i:\n            p_i = np.argmax(p)\n            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n        out.append(out_i)\n    return out\ntest_pred = model.predict(X_test, verbose=1)   \npred_labels = pred2label(test_pred)\ntest_labels = pred2label(y_test)","dbfd916e":"!pip install seqeval","f20c49b0":"from seqeval.metrics import precision_score, recall_score, f1_score, classification_report","c18a2306":"print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n","912d239f":"!pip install sklearn_crfsuite","c7373acb":"from  sklearn_crfsuite.metrics import flat_classification_report  \nreport = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\nprint(report)","51b0c370":"\n**Importing the dataset for named entity recognition model**","dbb870d3":"> **Create list of list of tuples to differentiate each sentence from each other**","6af9c089":"**Converting words to numbers and numbers to words**"}}