{"cell_type":{"6e2d1be5":"code","5cf7166b":"code","b2ce3bee":"code","7c4b35f1":"code","ea580d30":"code","695e7774":"code","7b54da58":"code","190659f2":"code","7d51bc1d":"code","c01e9725":"code","ce6d843e":"code","4762a3eb":"code","ad5b5a0d":"code","6b4658e9":"code","5a336be9":"code","7f0a678d":"code","48f1fd58":"code","aada0f50":"code","f1f98e0b":"code","236e07a7":"code","f0206263":"code","bd07a27a":"code","616b5823":"code","f09610ac":"code","4d614789":"code","1a5abae0":"code","a8c7335a":"code","f0dab6a0":"code","448d9bda":"code","0dd38187":"code","5df97a27":"code","2a09eecc":"code","89973be5":"code","0f88ec2f":"code","639734c9":"code","629c4b62":"code","cd5b62f9":"code","e4852e80":"code","e88b1a92":"code","7172e961":"code","a9128a7f":"code","bae77031":"code","989866a2":"code","77a4ca55":"code","5298fb52":"code","b13fd7d1":"code","c9e26069":"code","ecae7fe2":"code","8171f7a5":"code","cf0400bf":"markdown","4cd9cffd":"markdown","d1e076bc":"markdown","93fde850":"markdown"},"source":{"6e2d1be5":"!pip install flatten_json","5cf7166b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json\nimport re\nimport gc\n\n#to make json in flatten object\nfrom flatten_json import flatten\n#!pip install flatten_json\n\n\n#For plotting\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n%matplotlib inline\n\n#Prediction related model\nimport matplotlib.ticker as ticker\nimport matplotlib.ticker as plticker\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Until fuction: line seperator\ndef print_dashes_and_ln():\n    print('-'*100, '\\n')\n    \n# Formatter to display all float format in 2 decimal format\n#pd.options.display.float_format = '{:.2f}'.format\n\nimport warnings\nwarnings.filterwarnings('ignore')","b2ce3bee":"#Json file opening, parsing in strin and flattened after that data frame is creating.\nf = open('\/kaggle\/input\/pro-kabaddi-2014-2019\/stats_match.json')\ndata = json.load(f)\nf.close()\ndata_flattened = [flatten(d) for d in data]\n#print(data_flattened)\nmatch_df = pd.DataFrame(data_flattened)\nmatch_df.head()","7c4b35f1":"# getting total number of rows and column in the dataframe\ndef shape_of_dataframe(match_df):\n    print(f\" Shape of the dataframe = {match_df.shape}\"); print_dashes_and_ln();\n    totalrows=match_df.shape[0]\n    print(f\" Total number of rows in the dataset =  {totalrows}\"); print_dashes_and_ln();\nshape_of_dataframe(match_df)","ea580d30":"# Drop unwanted columns\ncolumns_to_drop = list(match_df.filter(regex=\"^(events|zones|match_detail_clock|match_detail_clock|match_detail_date|match_detail_start_time\"\n                                           +\"|match_detail_gmtoffset|match_detail_status|match_detail_status|match_detail_result_outcome|match_detail_result_value|match_detail_player_of_the_match\"\n                                          +\"|match_detail_series_parent_series|match_detail_venue|match_detail_stage|match_detail_group\"\n                                          +\"|teams_home_team|teams_team_._state_of_play\"\n                                           +\"|teams_team_._stats_points_all_out|teams_team_._stats_points_declare\"\n                                           +\"|teams_team_._stats_points_raid_points|teams_team_._stats_points_tackle_points\"\n                                           +\"|teams_team_._squad).*\", axis = 1).columns)\n\nmatch_df.drop(columns_to_drop, inplace=True, axis = 1)","695e7774":"# after dropping the required columns we have n columns in the data\nshape_of_dataframe(match_df)","7b54da58":"#Remove Columns with only One Value\nmatch_df = match_df.loc[:,match_df.apply(pd.Series.nunique) > 1]","190659f2":"#Renaming of column name which help to shortane the column name with proper name.\nmatch_df.rename(columns=lambda x: x.replace('match_detail_result', 'result'), inplace=True)\nmatch_df.rename(columns=lambda x: x.replace('teams_team', 'team'), inplace=True)\nmatch_df.rename(columns=lambda x: x.replace('match_detail', 'match'), inplace=True)\nmatch_df.rename(columns=lambda x: x.replace('stats_raids', 'raid'), inplace=True)\nmatch_df.rename(columns=lambda x: x.replace('stats_tackles', 'tackle'), inplace=True)","7d51bc1d":"# After cleaning and manupulation dataframe will look like\nmatch_df.head()","c01e9725":"#Remove or substitute respective relevant value for nan and none with in a data frame\n#1. Data frame columns containg null value\ndef columns_cointaing_null_value(match_df):\n    match_df_contianing_null = match_df.columns[match_df.isna().any()].tolist()\n    print(f'Column containing null values are: = {match_df_contianing_null}'); print_dashes_and_ln();\ncolumns_cointaing_null_value(match_df)\n#2. Fill NaN with the mean of the column\nmatch_df['result_winning_team'] = match_df['result_winning_team'].fillna('Tie Match')\nmatch_df['result_winning_team_id'] = match_df['result_winning_team_id'].fillna(0)\n#3 Value in the both column is as shown below.\nmatch_df_win_team_id = match_df[['result_winning_team','result_winning_team_id']]\nprint(match_df_win_team_id.head())\n#4. recheck if there is any null value still persist.\ncolumns_cointaing_null_value(match_df)","ce6d843e":"#Inforamtion of datatype of columns of data frame\nmatch_df.info()","4762a3eb":"#data type of different columns with object\ndef list_of_object_dtype_columns(match_df):\n    match_df_object_dtype = match_df.select_dtypes(include=['object']).columns.tolist()\n    print(f'list of columns with datatype object = {match_df_object_dtype}'); print_dashes_and_ln();\nlist_of_object_dtype_columns(match_df)","ad5b5a0d":"#Converting float type column to int for better visualization.\n#There some of columns which values are in float, objects etc but is needed integer type.\nmatch_df['result_winning_team_id'] = match_df['result_winning_team_id'].astype(int)\n#match time iso to date time\nmatch_df['match_matchtime_iso']=pd.to_datetime(match_df['match_matchtime_iso'])\n# Match Team Id to numeric\nmatch_df['team_0_id']=pd.to_numeric(match_df['team_0_id'])\nmatch_df['team_1_id']=pd.to_numeric(match_df['team_1_id'])\n\n#Printing all object type columns names\nlist_of_object_dtype_columns(match_df)\n\n#There is no need to further change object to other datatype\nmatch_df.info()","6b4658e9":"# garbage collect (unused) object and delete all references that is no further used\ngc.collect()","5a336be9":"# create plotting functions\ndef data_type(variable):\n    if variable.dtype == np.int64 or variable.dtype == np.float64:\n        return 'numerical'\n    elif variable.dtype == 'category':\n        return 'categorical'\n    \ndef univariate(variable, stats=True):\n    \n    if data_type(variable) == 'numerical':\n        sns.distplot(variable)\n        if stats == True:\n            print(variable.describe())\n    \n    elif data_type(variable) == 'categorical':\n        sns.countplot(variable)\n        if stats == True:\n            print(variable.value_counts())\n            \n    else:\n        print(\"Invalid variable passed: either pass a numeric variable or a categorical vairable.\")\n        \ndef bivariate(var1, var2):\n    if data_type(var1) == 'numerical' and data_type(var2) == 'numerical':\n        sns.regplot(var1, var2)\n    elif (data_type(var1) == 'categorical' and data_type(var2) == 'numerical') or (data_type(var1) == 'numerical' and data_type(var2) == 'categorical'):        \n        sns.boxplot(var1, var2)","7f0a678d":"# Checking corelation\ndef corr_graph(match_df):\n    corr = match_df.corr()\n    plt.figure(figsize = (10, 8))\n    sns.heatmap(corr)\n    plt.show()\n    return corr\ncorr_graph(match_df)","48f1fd58":"col_names = match_df.corr().columns.values\n\nfor col, row in (match_df.corr().abs() > 0.7).iteritems():\n    print(col, col_names[row.values])","aada0f50":"# Finding corelated varibale with winning team\na = match_df[match_df.columns[:]].corr()['result_winning_team_id']\n","f1f98e0b":"a1 = a[a >.1]\na2 = a[a < -.1]\na1","236e07a7":"a2","f0206263":"# There is no futher deletion of column need to perform because each columns has its own importance.\n# Neither need to add dummy variables.","bd07a27a":"#Univariate analysis in accordance to match_toss_winner\nunivariate(match_df.match_toss_winner)","616b5823":"#Univariate analysis in accordance to team_0_raid_successful\nunivariate(match_df.result_winning_team_id)","f09610ac":"# Bivariate analysic with result_winning_team_id and match_toss_winner\nbivariate(match_df.result_winning_team_id, match_df.match_toss_winner)","4d614789":"# Bivariate analysic with result_winning_team_id and match_toss_winner\nbivariate(match_df.team_0_id, match_df.team_1_id)","1a5abae0":"# Bivariate analysic with team_0_score and team_1_score\nbivariate(match_df.team_0_score, match_df.team_1_score)","a8c7335a":"plt.figure(figsize=(20,6))\nplt.subplot(1, 3, 1)\nplt.title('Winning Team Distribution')\nsns.distplot(match_df['result_winning_team_id'],color='green')\n\n# subplot 2\nplt.subplot(1, 3, 2)\nsns.distplot(match_df['team_0_stats_all_outs'],color='blue')\n\n# subplot 3l\nplt.subplot(1, 3, 3)\nsns.distplot(match_df['team_1_stats_all_outs'],color='red')","f0dab6a0":"fig, ax = plt.subplots(figsize=(200,8))\nwidth = len(match_df['result_winning_team'].unique()) + 6\nfig.set_size_inches(width , 8)\nax=sns.countplot(data = match_df, x= 'result_winning_team') \n","448d9bda":"fig, ax = plt.subplots(figsize=(200,8))\nwidth = len(match_df['team_0_raid_successful'].unique()) + 6\nfig.set_size_inches(width , 8)\nax=sns.countplot(data = match_df, x= 'team_0_raid_successful') ","0dd38187":"fig, ax = plt.subplots(figsize=(200,8))\nwidth = len(match_df['team_1_raid_successful'].unique()) + 6\nfig.set_size_inches(width , 8)\nax=sns.countplot(data = match_df, x= 'team_1_raid_successful') ","5df97a27":"\nfig, ax = plt.subplots(figsize=(200,8))\nwidth = len(match_df['result_winning_method'].unique()) + 6\nfig.set_size_inches(width , 8)\nax=sns.countplot(data = match_df, x= 'result_winning_method')","2a09eecc":" season_7_teams = ['Dabang Delhi K.C.',\n 'Bengal Warriors',\n 'Haryana Steelers',\n 'U Mumba',\n 'Bengaluru Bulls',\n 'U.P. Yoddha',\n 'Jaipur Pink Panthers',\n 'Puneri Paltan',\n 'Patna Pirates',\n 'Gujarat Fortunegiants',\n 'Telugu Titans',\n 'Tamil Thalaivas']\n\ndf_teams_1 = match_df[match_df['team_0_name'].isin(season_7_teams)]\ndf_teams_2 = match_df[match_df['team_1_name'].isin(season_7_teams)]\ndf_teams = pd.concat((df_teams_1, df_teams_2))\ndf_teams.drop_duplicates()\ndf_teams.head()","89973be5":"#New column introduce as winner to decide predictions\ndf_teams['winner'] = np.where(df_teams.team_0_id==df_teams.result_winning_team_id,1, np.where(df_teams.team_1_id==df_teams.result_winning_team_id, 2,3))","0f88ec2f":"df_teams = df_teams[['team_0_name','team_1_name','winner']]\ndf_teams.rename(columns={'team_0_name':'Team_1','team_1_name':'Team_2'}, inplace=True)\ndf_teams.head()","639734c9":"final_predict = pd.get_dummies(df_teams, prefix=['Team_1', 'Team_2'], columns=['Team_1', 'Team_2'])\n\nX = final_predict.drop(['winner'], axis=1)\ny = final_predict[\"winner\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","629c4b62":"#Model implemented to predit team data\nrf = RandomForestClassifier(n_estimators=100, max_depth=20,random_state=0) \nrf.fit(X_train, y_train)\nscore = rf.score(X_train, y_train)\nscore2 = rf.score(X_test, y_test)\nprint(\"Training set accuracy: \", '%.3f'%(score))\nprint(\"Test set accuracy: \", '%.3f'%(score2))\n","cd5b62f9":"#Extracting rank and total poins related data\n#Json file opening, parsing in strin and flattened after that data frame is creating.\nf = open('\/kaggle\/input\/pro-kabaddi-2014-2019\/stats_team.json')\ndata = json.load(f)\nf.close()\ndata_flattened = [flatten(d) for d in data]\n#print(data_flattened)\nrank_df = pd.DataFrame(data_flattened)\n#list(rank_df.columns)\nrank_df = rank_df[['bio_team_id','bio_team_name','over_all_stats_rank','over_all_stats_points','over_all_stats_success_raids','over_all_stats_success_tackles','over_all_stats_super_raids','over_all_stats_super_tackles','over_all_stats_all_outs','over_all_stats_all_out_points']]\nrank_df.head(23)","e4852e80":"#Total matches will be 12 * 11 = 132\n#team_standing = team for teama in season_7_teams for teamb in season_7_teams if teama != teamb\n#team_standing = set(season_7_teams) & set(season_7_teams)\nteam_standing_a = []\nteam_standing_b = []\nfor teama in season_7_teams:\n    for teamb in season_7_teams:\n        if(teama != teamb):\n            team_standing_a.append(teama)\n            team_standing_b.append(teamb)\nteam_standing = pd.DataFrame({\n    'Team_1': team_standing_a,\n    'Team_2': team_standing_b})    \nteam_standing.head()","e88b1a92":"\nteam_standing.insert(1, 'first_position', team_standing['Team_1'].map(rank_df.set_index('bio_team_name')['over_all_stats_rank']))\nteam_standing.insert(2, 'second_position', team_standing['Team_2'].map(rank_df.set_index('bio_team_name')['over_all_stats_rank']))\nteam_standing.tail()","7172e961":"pred_set = []\nfor index, row in team_standing.iterrows():\n    if row['first_position'] < row['second_position']:\n        pred_set.append({'Team_1': row['Team_1'], 'Team_2': row['Team_2'], 'winner': None})\n    else:\n        pred_set.append({'Team_1': row['Team_2'], 'Team_2': row['Team_1'], 'winner': None})\n        \npred_set = pd.DataFrame(pred_set)\nbackup_pred_set = pred_set\npred_set.head()","a9128a7f":"pred_set = pd.get_dummies(pred_set, prefix=['Team_1', 'Team_2'], columns=['Team_1', 'Team_2'])\n\nmissing_cols = set(final_predict.columns) - set(pred_set.columns)\nfor c in missing_cols:\n    pred_set[c] = 0\npred_set = pred_set[final_predict.columns]\n\n\npred_set = pred_set.drop(['winner'], axis=1)\npred_set.head()","bae77031":"predictions = rf.predict(pred_set)\nfor i in range(team_standing.shape[0]):\n    print(backup_pred_set.iloc[i, 1] + \" and \" + backup_pred_set.iloc[i, 0])\n    if predictions[i] == 1:\n        print(\"Winner: \" + backup_pred_set.iloc[i, 1])\n    \n    else:\n        print(\"Winner: \" + backup_pred_set.iloc[i, 0])\n    print(\"\")","989866a2":"def clean_and_predict(matches, ranking, final, rf):\n    positions = []\n    for match in matches:\n        positions.append(ranking.loc[ranking['bio_team_name'] == match[0],'over_all_stats_rank'].iloc[0])\n        positions.append(ranking.loc[ranking['bio_team_name'] == match[1],'over_all_stats_rank'].iloc[0])\n\n    pred_set = []\n\n    i = 0\n    j = 0\n\n    while i < len(positions):\n        dict1 = {}\n\n        if positions[i] < positions[i + 1]:\n            dict1.update({'Team_1': matches[j][0], 'Team_2': matches[j][1]})\n        else:\n            dict1.update({'Team_1': matches[j][1], 'Team_2': matches[j][0]})\n\n        pred_set.append(dict1)\n        i += 2\n        j += 1\n        \n    pred_set = pd.DataFrame(pred_set)\n    backup_pred_set = pred_set\n\n    pred_set = pd.get_dummies(pred_set, prefix=['Team_1', 'Team_2'], columns=['Team_1', 'Team_2'])\n    missing_cols2 = set(final.columns) - set(pred_set.columns)\n    for c in missing_cols2:\n        pred_set[c] = 0\n    pred_set = pred_set[final.columns]\n\n    pred_set = pred_set.drop(['winner'], axis=1)\n\n    predictions = rf.predict(pred_set)\n    for i in range(len(pred_set)):\n        print(backup_pred_set.iloc[i, 1] + \" and \" + backup_pred_set.iloc[i, 0])\n        if predictions[i] == 1:\n            print(\"Winner: \" + backup_pred_set.iloc[i, 1])\n        else:\n            print(\"Winner: \" + backup_pred_set.iloc[i, 0])\n        print(\"\")","77a4ca55":"semi = [('Dabang Delhi K.C.', 'Bengal Warriors'),\n            ('Haryana Steelers', 'Bengaluru Bulls')]\nclean_and_predict(semi, rank_df, final_predict, rf)","5298fb52":"#From the above prediction winner team is Bengal Warriors\nfinal = [('Bengal Warriors','Haryana Steelers')]\nclean_and_predict(final, rank_df, final_predict, rf)","b13fd7d1":"# Predict the top team in the points table after the completion of the league matches. \nrank_df[rank_df.over_all_stats_points == max(rank_df.over_all_stats_points)].bio_team_name\t","c9e26069":"# Predict the team with the highest points for successful raids\nrank_df[rank_df.over_all_stats_success_raids == max(rank_df.over_all_stats_success_raids)].bio_team_name\t","ecae7fe2":"# Predict the team with the highest points for successful tackles\nrank_df[rank_df.over_all_stats_success_tackles == max(rank_df.over_all_stats_success_tackles)].bio_team_name\t","8171f7a5":"# Predict the team with the highest super-performance total.\nrank_df['highest_super'] = rank_df.over_all_stats_super_raids + rank_df.over_all_stats_super_tackles + rank_df.over_all_stats_all_outs-rank_df.over_all_stats_all_out_points\nrank_df[rank_df.highest_super == max(rank_df.highest_super)].bio_team_name\t","cf0400bf":"# Visualizing Data and EDA For all the features","4cd9cffd":"### Data is cleaned and relevent manupulation has been done.\n\n#### ------------------------------------------------------------------------------------------------------------","d1e076bc":"# 1. Data Cleaning and manipulation","93fde850":"# Adding Dummy Variables"}}