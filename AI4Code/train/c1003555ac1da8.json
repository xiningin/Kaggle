{"cell_type":{"496954f5":"code","66d25ec5":"code","f37cf6ac":"code","6daf3f26":"code","8ea5ee35":"code","91a35c58":"code","c7d16d63":"code","248c11bd":"code","2c97c5dd":"code","4b493de7":"code","5884c716":"code","17b562f6":"code","99e9a634":"code","ae110a80":"code","562d3dec":"code","d7c055b4":"code","4dbcf43e":"code","15117e97":"code","d333844e":"code","01225670":"code","d53bfc90":"code","a75e0ea0":"code","4c6a44fe":"code","9ea01165":"code","8aabeacf":"code","0e1564a9":"code","ac879e2b":"code","b8802fd8":"code","40a3a173":"code","be7f3da9":"code","988d086c":"code","f34b0903":"code","4897e9eb":"code","e668e16c":"code","d357f8dc":"code","d34c8b85":"code","d382db4d":"code","67f92c9b":"code","867d46c1":"code","52ec61f8":"code","68e578bb":"code","e4e1f10a":"code","97644d17":"code","502a166e":"code","d5121952":"code","c511aa92":"code","796e0e2f":"code","297ed58d":"code","3651541c":"code","5c014ce7":"code","927992e4":"code","d985a466":"code","cd2447c4":"markdown","59e8ce11":"markdown","e7879bf4":"markdown","ed697b1c":"markdown","b0e8f826":"markdown","9044322c":"markdown","afd61ede":"markdown","df098dc8":"markdown","b2e5e578":"markdown","8df10709":"markdown","897a552d":"markdown","3f96db18":"markdown","ad2d2818":"markdown","8a70d846":"markdown","23c21d89":"markdown","35dc16e2":"markdown"},"source":{"496954f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","66d25ec5":"import numpy as np\nimport pandas as pd\nimport category_encoders as ce\nimport re\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nfrom scipy import sparse, hstack\n\n# datetime\nimport datetime\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# \u4ee5\u4e0b\u306f\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306e\u307f\n\n# Stop Words: NLTK\u304b\u3089\u82f1\u8a9e\u306estop words\u3092\u8aad\u307f\u8fbc\u307f\nfrom nltk.corpus import stopwords\n\n# \u53ef\u8996\u5316\u306e\u305f\u3081\u306e\u30bb\u30c3\u30c8\u3067\u3059\u3002\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\n# CountVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer","f37cf6ac":"# \u8aad\u307f\u8fbc\u307f\ndf_train = pd.read_csv('..\/input\/train.csv', index_col=0)\ndf_test = pd.read_csv('..\/input\/test.csv', index_col=0)","6daf3f26":"# \u8aad\u307f\u8fbc\u3093\u3060\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d(df_train\u306e\u59cb\u3081\u306e5\u884c)\ndf_train.head()","8ea5ee35":"# \u8aad\u307f\u8fbc\u3093\u3060\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d(df_test\u306e\u59cb\u3081\u306e5\u884c)\ndf_test.head()","91a35c58":"# train\u30c7\u30fc\u30bf\u3092X, y\u3078\u5206\u96e2\ndf_X_train = df_train.drop('loan_condition', axis=1)\ndf_y_train = df_train[['loan_condition']]\n# test\u30c7\u30fc\u30bf\u306f\u5143\u3005X\u306e\u307f\u3060\u304c\u3001\u540d\u524d\u3060\u3051\u5909\u3048\u3066\u304a\u304d\u307e\u3059\u3002\ndf_X_test = df_test","c7d16d63":"# X_train\u3092\u78ba\u8a8d(\u59cb\u3081\u306e5\u884c)\ndf_X_train.head()","248c11bd":"# y_train\u3092\u78ba\u8a8d(\u59cb\u3081\u306e5\u884c)\ndf_y_train.head()","2c97c5dd":"# X_test\u3092\u78ba\u8a8d(\u59cb\u3081\u306e5\u884c)\ndf_X_test.head()","4b493de7":"# \u5404\u30ab\u30e9\u30e0\u306edtype\u3092\u78ba\u8a8d(\u30e6\u30cb\u30fc\u30af\u306a\u3082\u306e)\nprint('Train\u30c7\u30fc\u30bf\u306edtyep', df_X_train.dtypes.unique())\nprint('Test\u30c7\u30fc\u30bf\u306edtype', df_X_test.dtypes.unique())","5884c716":"# \u6570\u5024\u30ab\u30e9\u30e0\u3092\u62bd\u51fa (float or int)\nlist_cols_num = []\nfor i in df_X_train.columns:\n    if df_X_train[i].dtype == 'float64' or df_X_train[i].dtype == 'int64':\n        list_cols_num.append(i)\n        \nprint(list_cols_num)","17b562f6":"# \u5404\u7d71\u8a08\u91cf\u3092\u4f5c\u6210\n# X_train\nstatics_X_train_num = pd.DataFrame([df_X_train[list_cols_num].nunique().values.tolist(),  # \u30e6\u30cb\u30fc\u30af\u6570\n                                df_X_train[list_cols_num].isnull().sum().values.tolist(),  # \u6b20\u640d\u6570\n                              df_X_train[list_cols_num].mean().values.tolist(),  # \u5e73\u5747\u5024\n                              df_X_train[list_cols_num].std().values.tolist(),  # \u6a19\u6e96\u504f\u5dee\n                              df_X_train[list_cols_num].median().values.tolist(),  # \u4e2d\u592e\u5024\n                              df_X_train[list_cols_num].min().values.tolist(),  # \u6700\u5c0f\u5024\n                              df_X_train[list_cols_num].max().values.tolist()],  # \u6700\u5927\u5024\n                              index=['unique', 'null', 'mean', 'std', 'median', 'min', 'max'],\n                              columns=list_cols_num).T\n# X_test\nstatics_X_test_num =  pd.DataFrame([df_X_test[list_cols_num].nunique().values.tolist(),  # \u30e6\u30cb\u30fc\u30af\u6570\n                                df_X_test[list_cols_num].isnull().sum().values.tolist(),  # \u6b20\u640d\u6570\n                                df_X_test[list_cols_num].mean().values.tolist(),  # \u5e73\u5747\u5024\n                                df_X_test[list_cols_num].std().values.tolist(),  # \u6a19\u6e96\u504f\u5dee\n                                df_X_test[list_cols_num].median().values.tolist(),  # \u4e2d\u592e\u5024\n                                df_X_test[list_cols_num].min().values.tolist(),  # \u6700\u5c0f\u5024\n                                df_X_test[list_cols_num].max().values.tolist()],  # \u6700\u5927\u5024\n                                index=['unique', 'null', 'mean', 'std', 'median', 'min', 'max'],\n                                columns=list_cols_num).T\n# y_traine\nstatics_y_train_num = pd.DataFrame([df_y_train['loan_condition'].astype('float64').nunique(),  # \u30e6\u30cb\u30fc\u30af\u6570\n                                df_y_train['loan_condition'].astype('float64').isnull().sum(),  # \u6b20\u640d\u6570\n                                df_y_train['loan_condition'].astype('float64').mean(),  # \u5e73\u5747\u5024\n                                df_y_train['loan_condition'].astype('float64').std(),  # \u6a19\u6e96\u504f\u5dee\n                                df_y_train['loan_condition'].astype('float64').median(),  # \u4e2d\u592e\u5024\n                                df_y_train['loan_condition'].astype('float64').min(),  # \u6700\u5c0f\u5024\n                                df_y_train['loan_condition'].astype('float64').max()],  # \u6700\u5927\u5024\n                                index=['unique', 'null', 'mean', 'std', 'median', 'min', 'max'],\n                                columns=['loan_condition']).T","99e9a634":"statics_X_train_num","ae110a80":"statics_X_test_num","562d3dec":"statics_y_train_num","d7c055b4":"# \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\u3092\u63cf\u3044\u3066\u307f\u308b\nplotpos = 1\nfig = plt.figure(figsize = (30, 30))\n\nfor i in list_cols_num:\n    plotdata1 = df_X_train[i]\n    plotdata2 = df_X_test[i]\n\n    ax = fig.add_subplot(6, 3, plotpos)\n    ax.hist(plotdata1, bins=50, alpha=0.4)\n    ax.hist(plotdata2, bins=50, alpha=0.4)\n    ax.set_xlabel(i)\n    \n    plotpos = plotpos + 1\n\nplt.show()","4dbcf43e":"# \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30ab\u30e9\u30e0\u3092\u62bd\u51fa (object)\nlist_cols_cat = []\nfor i in df_X_train.columns:\n    if df_X_train[i].dtype == 'object':\n        list_cols_cat.append(i)\n        \nprint(list_cols_cat)","15117e97":"# \u5404\u7d71\u8a08\u91cf\u3092\u4f5c\u6210\n# X_train\nstatics_X_train_cat = pd.DataFrame([df_X_train[list_cols_cat].nunique().values.tolist(),  # \u30e6\u30cb\u30fc\u30af\u6570\n                                df_X_train[list_cols_cat].isnull().sum().values.tolist()],  # \u6b20\u640d\u6570\n                              index=['unique', 'null'],\n                              columns=list_cols_cat).T\n# X_test\nstatics_X_test_cat =  pd.DataFrame([df_X_test[list_cols_cat].nunique().values.tolist(),  # \u30e6\u30cb\u30fc\u30af\u6570\n                                df_X_test[list_cols_cat].isnull().sum().values.tolist()],  # \u6b20\u640d\u6570\n                                index=['unique', 'null'],\n                                columns=list_cols_cat).T\n# y_traine\nstatics_y_train_cat = pd.DataFrame([df_y_train['loan_condition'].astype('float64').nunique(),  # \u30e6\u30cb\u30fc\u30af\u6570\n                                df_y_train['loan_condition'].astype('float64').isnull().sum()],  # \u6b20\u640d\u6570\n                                index=['unique', 'null'],\n                                columns=['loan_condition']).T","d333844e":"statics_X_train_cat","01225670":"statics_X_test_cat","d53bfc90":"statics_y_train_cat","a75e0ea0":"# \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3068\u3057\u3066\u6271\u3046\u30ab\u30e9\u30e0\u306e\u30ab\u30e9\u30e0\u540d\u3092\u30ea\u30b9\u30c8\u5316\n# \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3068\u3057\u3066\u6271\u3046\u30ab\u30e9\u30e0\u306e\u30ab\u30e9\u30e0\u540d\u3092\u30ea\u30b9\u30c8\u5316\nlist_cols_cat = ['home_ownership',\n               'issue_d',\n               'purpose',\n               'title',\n               'zip_code',\n               'delinq_2yrs',\n               'earliest_cr_line',\n               'initial_list_status',\n               'application_type',\n               'addr_state']\n\n# \u30a8\u30f3\u30b3\u30fc\u30c0\u3092\u65b0\u305f\u306b\u4f5c\u6210\nce_oe = ce.OrdinalEncoder(cols=list_cols_cat, handle_unknown='impute')\n\n# \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092Ordinal Encoding\u3057\u3001\u65b0\u305f\u306a\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u4f5c\u6210\ndf_X_train_prep = ce_oe.fit_transform(df_X_train) # df_X_train\u3092\u30a8\u30f3\u30b3\u30fc\u30c9\ndf_X_test_prep = ce_oe.fit_transform(df_X_test) # df_X_test\u3092\u30a8\u30f3\u30b3\u30fc\u30c9","4c6a44fe":"# grade, sub_grade\u306f\u5e8f\u5217\u304c\u3042\u308b\u305f\u3081\u3001\u305d\u306e\u9806\u5e8f\u306b\u5fdc\u3058\u305f\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3092\u884c\u3046\u3002\n# \u30de\u30c3\u30d7\u306e\u4f5c\u6210\ngrade_mapping = {'A': 1,\n                 'B': 2,\n                 'C': 3,\n                 'D': 4,\n                 'E': 5,\n                 'F': 6,\n                 'G': 7\n                }\n\nsub_grade_mapping = {'A1': 1, 'A2': 2, 'A3': 3, 'A4': 4, 'A5': 5, \n                     'B1': 6, 'B2': 7, 'B3': 8, 'B4': 9, 'B5': 10, \n                     'C1': 11, 'C2': 12, 'C3': 13, 'C4': 14, 'C5': 15, \n                     'D1': 16, 'D2': 17, 'D3': 18, 'D4': 19, 'D5': 10, \n                     'E1': 21, 'E2': 22, 'E3': 23, 'E4': 24, 'E5': 25, \n                     'F1': 26, 'F2': 27, 'F3': 28, 'F4': 29, 'F5': 20, \n                     'G1': 31, 'G2': 32, 'G3': 33, 'G4': 34, 'G5': 35\n                    }\n\ndf_X_train_prep['grade'] = df_X_train_prep['grade'].map(grade_mapping)\ndf_X_train_prep['sub_grade'] = df_X_train_prep['sub_grade'].map(sub_grade_mapping)\n\ndf_X_test_prep['grade'] = df_X_test_prep['grade'].map(grade_mapping)\ndf_X_test_prep['sub_grade'] = df_X_test_prep['sub_grade'].map(sub_grade_mapping)","9ea01165":"# emp_length\u3092train\u30c7\u30fc\u30bf\u3068test\u30c7\u30fc\u30bf\u304b\u3089\u53d6\u308a\u51fa\u3057\nlist_emp_length_train = df_X_train_prep.emp_length.tolist()\nlist_emp_length_test = df_X_test_prep.emp_length.tolist()","8aabeacf":"# <1year\u30920year\u306b\u7f6e\u304d\u63db\u3048\u308b\n\n# \u30ea\u30b9\u30c8\u4f5c\u6210\nfor i in range(len(list_emp_length_train)):\n    if list_emp_length_train[i] == \"< 1 year\":\n        list_emp_length_train[i] = \"0 year\"\n        \nfor i in range(len(list_emp_length_test)):\n    if list_emp_length_test[i] == \"< 1 year\":\n        list_emp_length_test[i] = \"0 year\"","0e1564a9":"# \u7bb1\u3092\u7528\u610f\nlist_emp_length_train_num = []\nlist_emp_length_test_num = []\n\n# \u6570\u5024\u306b\u30de\u30c3\u30c1\u3059\u308b\u30d1\u30bf\u30fc\u30f3\uff080\uff5e9\u306e\u6587\u5b57(\u6570\u5b57)\u306e\u7e70\u308a\u8fd4\u3057)\u3092\u5b9a\u7fa9\n# pattern = r'([0-9]*)' # \u3053\u308c\u3060\u3068< 1years\u30671\u304c\u3046\u307e\u304f\u62bd\u51fa\u3055\u308c\u305a\"\"\u3068\u306a\u3063\u3066\u3057\u307e\u3063\u305f","ac879e2b":"# train\u30c7\u30fc\u30bf\u306e\u51e6\u7406\nfor i in range(len(list_emp_length_train)):\n    if pd.isnull(list_emp_length_train[i]):\n        list_emp_length_train_num.append(np.nan)\n    else:\n        # temp3 = re.match(pattern, list_emp_length_train[i]) # \u3053\u308c\u3060\u3068< 1years\u30671\u304c\u3046\u307e\u304f\u62bd\u51fa\u3055\u308c\u305a\"\"\u3068\u306a\u3063\u3066\u3057\u307e\u3063\u305f\n        # temp2.append(temp3.group())\n        temp_data1 = re.sub(r'\\D', '', list_emp_length_train[i])\n        list_emp_length_train_num.append(temp_data1)\n        \n# test\u30c7\u30fc\u30bf\u306e\u51e6\u7406\nfor i in range(len(list_emp_length_test)):\n    if pd.isnull(list_emp_length_test[i]):\n        list_emp_length_test_num.append(np.nan)\n    else:\n        temp_data2 = re.sub(r'\\D', '', list_emp_length_test[i])\n        list_emp_length_test_num.append(temp_data2)","b8802fd8":"# \u5f97\u3089\u308c\u305f\u6570\u5024\u306e\u30ea\u30b9\u30c8(\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u578b)\u3092\u4ee3\u5165\ndf_X_train_prep.emp_length = list_emp_length_train_num\ndf_X_test_prep.emp_length = list_emp_length_test_num\n# \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u578b\u3092\u6570\u5024\u578b\u306b\u5909\u63db\ndf_X_train_prep.emp_length = df_X_train_prep.emp_length.astype('float64')\ndf_X_test_prep.emp_length = df_X_test_prep.emp_length.astype('float64')","40a3a173":"# \u30ab\u30e9\u30e0\u306b\u304a\u3051\u308b\u6b20\u640d\u5024\u3092\u3001\u305d\u308c\u305e\u308c\u306e\u4e2d\u592e\u5024\u3067\u7a74\u57cb\u3081\u3059\u308b\ndf_X_train_prep.fillna(df_X_train_prep.median(), inplace=True)\ndf_y_train.fillna(df_y_train.median(), inplace=True)\ndf_X_test_prep.fillna(df_X_test_prep.median(), inplace=True)","be7f3da9":"# \u91d1\u984d\u7cfb\u3092\u5bfe\u6570\u5909\u63db\nlist_cols_num_money = ['installment',\n               'loan_amnt',\n               'annual_inc',\n               'tot_coll_amt',\n               'tot_cur_bal']\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306b\u57fa\u3065\u3044\u3066\u8907\u6570\u30ab\u30e9\u30e0\u306e\u6a19\u6e96\u5316\u3092\u5b9a\u7fa9\nX_train_money_logarithm = np.log1p(df_X_train_prep[list_cols_num_money])\nX_test_money_logarithm = np.log1p(df_X_test_prep[list_cols_num_money])\n\n# \u5909\u63db\u5f8c\u306e\u30c7\u30fc\u30bf\u3067\u5404\u5217\u3092\u7f6e\u63db\ndf_X_train_prep[list_cols_num_money] = X_train_money_logarithm\ndf_X_test_prep[list_cols_num_money] = X_test_money_logarithm","988d086c":"# \u6570\u5024\u306e\u30ab\u30e9\u30e0\u3092\u6307\u5b9a\nlist_cols_num = ['installment',\n               'loan_amnt',\n               'annual_inc',\n               'tot_coll_amt',\n               'tot_cur_bal',\n               'dti',\n               'inq_last_6mths',\n               'mths_since_last_delinq',\n               'mths_since_last_record',\n               'open_acc',\n               'pub_rec',\n               'revol_bal',\n               'revol_util',\n               'total_acc',\n               'collections_12_mths_ex_med',\n               'mths_since_last_major_derog',\n               'acc_now_delinq']\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306b\u57fa\u3065\u3044\u3066\u8907\u6570\u30ab\u30e9\u30e0\u306e\u6a19\u6e96\u5316\u3092\u5b9a\u7fa9\nscaler = StandardScaler()\nscaler.fit(df_X_train_prep[list_cols_num])\n\n# \u5909\u63db\u5f8c\u306e\u30c7\u30fc\u30bf\u3067\u5404\u5217\u3092\u7f6e\u63db\ndf_X_train_prep[list_cols_num] = scaler.transform(df_X_train_prep[list_cols_num])\ndf_X_test_prep[list_cols_num] = scaler.transform(df_X_test_prep[list_cols_num])","f34b0903":"# \u30c6\u30ad\u30b9\u30c8\u30ab\u30e9\u30e0\u3092\u30ea\u30b9\u30c8\u3067\u629c\u304d\u51fa\u3057\nX_train_text = df_X_train_prep.emp_title\nX_test_text = df_X_test_prep.emp_title\n\n# \u6b20\u640d\u5024\u3092NaN\u3068\u3044\u3046\u8a00\u8449\u3067\u57cb\u3081\u308b\nX_train_text.fillna('NaN', inplace=True)\nX_test_text.fillna('NaN', inplace=True)","4897e9eb":"# \u5168\u3066\u306eemp_title\u3092TfIdf\u3067\u30d9\u30af\u30c8\u30eb\u5316\nvec_all = TfidfVectorizer(max_features=100000)","e668e16c":"# emp_title\u306f\u5168\u3066\u4f7f\u3046\nemp_title_all = pd.concat([X_train_text, X_test_text])","d357f8dc":"# \u5168\u3066\u306eemp_title\u3092TfIdf\u3067\u30d9\u30af\u30c8\u30eb\u5316\nvec_all.fit_transform(emp_title_all)","d34c8b85":"# X_train_text\u7528\u30d9\u30af\u30bf\u30e9\u30a4\u30b6\u30fc\u306e\u6307\u5b9a\n# \u8f9e\u66f8\u306fvec_all\u3067\u62bd\u51fa\u3057\u305f\u3082\u306e\u3092\u4f7f\u3046\u3002\nvec_train = TfidfVectorizer(max_features=100000, vocabulary=vec_all.vocabulary_)","d382db4d":"# X_train_text\u3092\u30d9\u30af\u30c8\u30eb\u5316\nX_train_text_tfidf = vec_train.fit_transform(X_train_text)","67f92c9b":"# X_test_text\u7528\u30d9\u30af\u30bf\u30e9\u30a4\u30b6\u30fc\u306e\u6307\u5b9a\n# \u8f9e\u66f8\u306f\u8f9e\u66f8\u306fvec_all\u3067\u62bd\u51fa\u3057\u305f\u3082\u306e\u3092\u4f7f\u3046\u3002\nvec_test = TfidfVectorizer(max_features=100000, vocabulary=vec_all.vocabulary_)","867d46c1":"# X_test_text\u3092\u30d9\u30af\u30c8\u30eb\u5316\nX_test_text_tfidf = vec_test.fit_transform(X_test_text)","52ec61f8":"X_test_text_tfidf","68e578bb":"# emp_title\u3092\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u304b\u3089\u30c9\u30ed\u30c3\u30d7\ndf_X_train_prep.drop(['emp_title'], axis=1, inplace=True)\ndf_X_test_prep.drop(['emp_title'], axis=1, inplace=True)","e4e1f10a":"# X\u3092\u6307\u5b9a\n# tfidf\u3067\u30d9\u30af\u30c8\u30eb\u5316\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u30ab\u30e9\u30e0\u3092concatenate\n# X = df_X_train_prep.values\n# X = np.concatenate((df_X_train_prep.values, X_train_text_tfidf.toarray()), axis=1)\n\n# \u30b9\u30d1\u30fc\u30b9\u884c\u5217\u3092\u4f5c\u6210\nX_train_prep_sparse = sparse.csr_matrix(df_X_train_prep.values) # TfIdf\u4ee5\u5916\u306edense\u3092sparse\u306b\nX = sparse.hstack([X_train_prep_sparse, X_train_text_tfidf])\n# \u884c\u65b9\u5411\u306b\u5727\u7e2e\nX = X.tocsr()\n\n# y\u3092\u6307\u5b9a\ny = df_y_train.loan_condition.values\n\n# \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u6307\u5b9a\n# classifier = GradientBoostingClassifier()\n# classifier = LogisticRegression()\nclassifier = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.71,\n                           importance_type='split', learning_rate=0.05, max_depth=-1,\n                           min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n                           n_estimators=9999, n_jobs=-1, num_leaves=31, objective=None,\n                           random_state=71, reg_alpha=1.0, reg_lambda=1.0, silent=True,\n                           subsample=0.9, subsample_for_bin=200000, subsample_freq=0)\n\n# \u5c64\u5316\u62bd\u51fa\u6cd5\u306b\u304a\u3051\u308b\u5206\u5272\u6570\u3092\u6307\u5b9a(2\u5206\u5272)\nskf = StratifiedKFold(n_splits=2, random_state=71, shuffle=True)","97644d17":"# 2\u56de\u306eValidation Score\u3092\u683c\u7d0d\u3059\u308b\u30ea\u30b9\u30c8\u3092\u4f5c\u6210\nlist_cv_auc_score = []\n# best iteration\u56de\u6570\u3092\u683c\u7d0d\u3059\u308b\u30ea\u30b9\u30c8\u3092\u4f5c\u6210\nlist_num_best_iteration = []\n\n# valid_ix\u3092\u683c\u7d0d\u3059\u308b\u30ea\u30b9\u30c8\u3092\u4f5c\u6210\nlist_valid_ix = []\n# pred_valid\u3092\u683c\u7d0d\u3059\u308b\u30ea\u30b9\u30c8\u3092\u4f5c\u6210\nlist_pred_valid = []\n\nd = datetime.datetime.today()\nprint('start:', d)\n\nt = 0\n\n# 2\u5206\u5272\u5c64\u5316\u62bd\u51fa\u306b\u3088\u308b\u30af\u30ed\u30b9\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\n# \u5404\u56de\u306e\u30b9\u30b3\u30a2\u3092\u8a18\u9332\nfor train_ix, valid_ix in skf.split(X, y):\n    X_train, y_train = X[train_ix], y[train_ix]\n    X_valid, y_valid = X[valid_ix], y[valid_ix]\n    \n    # \u30d5\u30a3\u30c3\u30c6\u30a3\u30f3\u30b0\n    # fit_train = classifier.fit(X_train, y_train)\n    # LGBM\n    fit_train = classifier.fit(X_train, y_train,\n                               early_stopping_rounds=200,\n                               eval_metric='auc',\n                               eval_set=[(X_valid, y_valid)],\n                               verbose=100)\n    # \u4e88\u6e2c\u3092\u5b9f\u65bd\n    pred_valid = fit_train.predict_proba(X_valid)\n    # \u30af\u30e9\u30b91\u306b\u6240\u5c5e\u3059\u308b\u78ba\u7387\u3092\u7528\u3044\u3066AUC\u30b9\u30b3\u30a2\u3092\u7b97\u51fa\n    v_auc_score = roc_auc_score(y_valid, pred_valid[:, 1])  # 0\u30ab\u30e9\u30e0\u76ee\u306f\u30af\u30e9\u30b90\u306b\u5206\u985e\u3055\u308c\u308b\u78ba\u7387\u3002\n    # AUC\u30b9\u30b3\u30a2\u3092\u8a18\u9332\n    list_cv_auc_score.append(v_auc_score)\n    \n    # best_iteraion\u56de\u6570\u3092\u8a18\u9332\n    num_best_iteration = fit_train.best_iteration_\n    list_num_best_iteration.append(num_best_iteration)\n    \n    # valid_ix\u3092\u8a18\u9332\n    list_valid_ix = list_valid_ix + valid_ix.tolist()\n    \n    # pred_valid\u3092\u8a18\u9332\n    list_pred_valid = list_pred_valid + pred_valid[:, 1].tolist()\n    \n    # \u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u3092print\n    t = t + 1\n    d = datetime.datetime.today()\n    print(t, '_finished:', d)\n    \n    # \u30b9\u30b3\u30a2\u8868\u793a\n    print('AUC\u306f', v_auc_score)\n    print('Best Iteration\u56de\u6570\u306f', num_best_iteration)","502a166e":"# valid\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3068\u3001\u305d\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306b\u304a\u3051\u308b\u4e88\u6e2c\u7d50\u679c\u3092DataFrame\u306b\ndf_pred_valid = pd.DataFrame([list_valid_ix, list_pred_valid]).T","d5121952":"# \u30ab\u30e9\u30e0\u540d\u8a2d\u5b9a\ndf_pred_valid.columns = ['valid_ix', 'pred_valid']\n# valid_ix\u3067\u4e26\u3073\u66ff\u3048\ndf_pred_valid.sort_values('valid_ix', ascending=True, inplace=True)\n# valid_ix\u3092DataFrame\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306b\ndf_pred_valid = df_pred_valid.set_index('valid_ix')","c511aa92":"df_X_train['emp_title'].head()","796e0e2f":"# \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3068\u3057\u3066\u6271\u3046\u30ab\u30e9\u30e0\u306e\u30ab\u30e9\u30e0\u540d\u3092\u30ea\u30b9\u30c8\u5316\nlist_cols_cat = ['emp_title']\n\n# \u30a8\u30f3\u30b3\u30fc\u30c0\u3092\u4f5c\u6210\nce_oe = ce.OrdinalEncoder(cols=list_cols_cat, handle_unknown='impute')\n\n# \u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092Ordinal Encoding\u3057\u3001\u65b0\u305f\u306a\u30c7\u30fc\u30bf\u30d5\u30ec\u30fc\u30e0\u3092\u4f5c\u6210\ndf_X_train_emp_title_oe = ce_oe.fit_transform(df_X_train)['emp_title'] # df_X_train\u3092\u30a8\u30f3\u30b3\u30fc\u30c9\ndf_X_test_emp_title_oe = ce_oe.fit_transform(df_X_test)['emp_title'] # df_X_test\u3092\u30a8\u30f3\u30b3\u30fc\u30c9","297ed58d":"df_X_train['issue_d'].values","3651541c":"# \u65e5\u4ed8\u3092\u3044\u3044\u611f\u3058\u306b\u3084\u3063\u3066\u304f\u308c\u308bparse\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\nfrom dateutil.parser import parse","5c014ce7":"# issue_d\u3092datetime\u5316 (train\u30c7\u30fc\u30bf)\nlist_X_train_issue_d = []\n[list_X_train_issue_d.append(parse(df_X_train['issue_d'].iloc[i])) for i in range(len(df_X_train['issue_d']))]\nlist_X_train_issue_d[0:5]","927992e4":"# issue_d\u3092datetime\u5316 (test\u30c7\u30fc\u30bf)\nlist_X_test_issue_d = []\n[list_X_test_issue_d.append(parse(df_X_test['issue_d'].iloc[j])) for j in range(len(df_X_test['issue_d']))]\nlist_X_test_issue_d[0:5]","d985a466":"# \u30c7\u30fc\u30bf\u3092\u30d7\u30ed\u30c3\u30c8\nfig = plt.figure(figsize = (30, 20))\n\nax1 = fig.add_subplot(2, 2, 1)\nax1.scatter(list_X_train_issue_d, df_X_train_emp_title_oe.values)\nax1.set_ylabel('emp_title(OrdEnc)')\nax1.set_title('emp_title(OrdEnc)(Train Data)')\nax2 = fig.add_subplot(2, 2, 2)\nax2.scatter(list_X_test_issue_d, df_X_test_emp_title_oe.values)\nax2.set_ylabel('emp_title(OrdEnc)(Test Data)')\nax2.set_title('Test Data')\nax3 = fig.add_subplot(2, 2, 3)\nax3.scatter(list_X_train_issue_d, df_pred_valid['pred_valid'])\nax3.set_ylabel('Probability of bad loan')\nax3.set_title('Probability of bad loan (Validation Result)')","cd2447c4":"### OrdinalEncoding","59e8ce11":"### emp_length\u306e\u51e6\u7406","e7879bf4":"### Categorical","ed697b1c":"## \u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u306eimport","b0e8f826":"## train, test\u306e\u8aad\u307f\u8fbc\u307f\u3068\u3001X, y, test\u3078\u306e\u5206\u96e2","9044322c":"### Numerical","afd61ede":"### \u6b20\u640d\u5024\u306e\u88dc\u5b8c","df098dc8":"\u78ba\u7387\u3092\u6c42\u3081\u308b\u305f\u3081\u3001\u4e00\u5ea6\u3001LGBM(ver19)\u3067\u4e88\u6e2c\u3092\u5b9f\u65bd","b2e5e578":"### grade, sub_grade\u306e\u51e6\u7406","8df10709":"## EDA","897a552d":"### \u6a19\u6e96\u5316","3f96db18":"### \u5b66\u7fd2","ad2d2818":"### issue_d\u3092\u65e5\u4ed8\u578b\u306b\u5909\u63db","8a70d846":"### \u30c6\u30ad\u30b9\u30c8","23c21d89":"## \u8cb8\u3057\u5012\u308c\u78ba\u7387\u306e\u7b97\u51fa","35dc16e2":"## emp_title\u306e\u691c\u8a0e"}}