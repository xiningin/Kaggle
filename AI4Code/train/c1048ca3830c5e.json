{"cell_type":{"f5a8c0ef":"code","b1f7cd99":"code","7f0ed3da":"code","a01db8d3":"code","f654ffd9":"code","be716574":"code","738bfdd5":"code","c5a1e182":"code","f46b9142":"code","17039271":"code","7b3f15a0":"code","18094d2c":"code","1605e31d":"code","5ecde32b":"code","3aea4c35":"code","30ed2379":"code","0ca3224c":"code","0b890e12":"code","af235488":"code","ebf1f28d":"code","291ce4eb":"code","d94a9650":"code","081268f5":"code","065a7af6":"code","44797f1a":"code","f1330e43":"code","be34953f":"code","27d3be5e":"code","eb404049":"code","0df9e5e3":"code","9441ad85":"code","979f6e47":"markdown","61c416f9":"markdown","ac97572c":"markdown","22287beb":"markdown","0b03c47a":"markdown"},"source":{"f5a8c0ef":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom PIL import Image\nimport cv2\n\nimport warnings\nwarnings.filterwarnings('ignore')","b1f7cd99":"image1 = cv2.imread(\"..\/input\/unsplash-group-images-for-face-detection\/face detection\/group.jpg\")\nimage2 = cv2.imread(\"..\/input\/unsplash-group-images-for-face-detection\/face detection\/group1.jpg\")\nimage3 = cv2.imread(\"..\/input\/unsplash-group-images-for-face-detection\/face detection\/group2.jpg\")\n\n\nimage1 = cv2.resize(image1, None, fx=0.25, fy=0.25)\nimage2 = cv2.resize(image2, None, fx=0.25, fy=0.25)\nimage3 = cv2.resize(image3, None, fx=0.25, fy=0.25)\n\n\nimage1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\nimage2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\nimage3_gray = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)","7f0ed3da":"image1.shape","a01db8d3":"face_cascade = cv2.CascadeClassifier(\"..\/input\/haar-cascades-for-face-detection\/haarcascade_frontalface_alt2.xml\")\n\n#detect faces\nfaces = face_cascade.detectMultiScale(image2_gray, scaleFactor=1.2, minNeighbors=5)\nimage = image2.copy()\n\n# draw rectangles on each face\nfor (x,y,w,h) in faces:\n    image = cv2.rectangle(image, (x,y), (x+w, y+h), (0,0,255), 2)\n\n# show image\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nImage.fromarray(image)","f654ffd9":"faces = face_cascade.detectMultiScale(image1_gray, scaleFactor=1.2, minNeighbors=5)\nimage = image1.copy()\nfor (x,y,w,h) in faces:\n    image = cv2.rectangle(image, (x,y), (x+w, y+h), (0,0,255), 2)\n\n# show image\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nImage.fromarray(image)","be716574":"faces = face_cascade.detectMultiScale(image3_gray, scaleFactor=1.1, minNeighbors=11)\nimage = image3.copy()\nfor (x,y,w,h) in faces:\n    image = cv2.rectangle(image, (x,y), (x+w, y+h), (0,0,255), 2)\n\n# show image\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nImage.fromarray(image)","738bfdd5":"import dlib","c5a1e182":"face_detector = dlib.get_frontal_face_detector()\n\ndetections = face_detector(image1, 1)\n\nimage = image1.copy()\n\nfor face in detections:\n    left = face.left()\n    right = face.right()\n    top = face.top()\n    bottom = face.bottom()\n    image = cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n\n\n# show image\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nImage.fromarray(image)","f46b9142":"detections = face_detector(image2, 1)\n\nimage = image2.copy()\n\nfor face in detections:\n    left = face.left()\n    right = face.right()\n    top = face.top()\n    bottom = face.bottom()\n    image = cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n\n\n# show image\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nImage.fromarray(image)","17039271":"detections = face_detector(image3, 1)\n\nimage = image3.copy()\n\nfor face in detections:\n    left = face.left()\n    right = face.right()\n    top = face.top()\n    bottom = face.bottom()\n    image = cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n\n\n# show image\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nImage.fromarray(image)","7b3f15a0":"face_detector = dlib.cnn_face_detection_model_v1(\"..\/input\/unsplash-group-images-for-face-detection\/face detection\/mmod_human_face_detector.dat\")\n\ndetections = face_detector(image1, 1)\n\nimage = image1.copy()\n\nfor face in detections:\n    left = face.rect.left()\n    right = face.rect.right()\n    top = face.rect.top()\n    bottom = face.rect.bottom()\n    image = cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n\n\n# show image\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nImage.fromarray(image)","18094d2c":"detections = face_detector(image2, 1)\n\nimage = image2.copy()\n\nfor face in detections:\n    left = face.rect.left()\n    right = face.rect.right()\n    top = face.rect.top()\n    bottom = face.rect.bottom()\n    image = cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n\n\n# show image\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nImage.fromarray(image)","1605e31d":"detections = face_detector(image3, 1)\n\nimage = image3.copy()\n\nfor face in detections:\n    left = face.rect.left()\n    right = face.rect.right()\n    top = face.rect.top()\n    bottom = face.rect.bottom()\n    image = cv2.rectangle(image, (left, top), (right, bottom), (0, 0, 255), 2)\n\n\n# show image\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nImage.fromarray(image)","5ecde32b":"!pip install mtcnn","3aea4c35":"from mtcnn import MTCNN","30ed2379":"detector = MTCNN()\n\n## RGB image\nimage = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n\n# detect faces\ndetections = detector.detect_faces(image)\n\n# draw all faces\nfor face in detections:\n    x,y,w,h = face['box']\n    image = cv2.rectangle(image, (x,y), (x+w, y+h), (255,0,0), 2)\n\n# show image\nImage.fromarray(image)","0ca3224c":"detector = MTCNN()\n\n## RGB image\nimage = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n\n# detect faces\ndetections = detector.detect_faces(image)\n\n# draw all faces\nfor face in detections:\n    x,y,w,h = face['box']\n    image = cv2.rectangle(image, (x,y), (x+w, y+h), (255,0,0), 2)\n\n# show image\nImage.fromarray(image)","0b890e12":"detector = MTCNN()\n\n## RGB image\nimage = cv2.cvtColor(image3, cv2.COLOR_BGR2RGB)\n\n# detect faces\ndetections = detector.detect_faces(image)\n\n# draw all faces\nfor face in detections:\n    x,y,w,h = face['box']\n    image = cv2.rectangle(image, (x,y), (x+w, y+h), (255,0,0), 2)\n\n# show image\nImage.fromarray(image)","af235488":"!git clone https:\/\/github.com\/hromi\/SMILEsmileD.git","ebf1f28d":"from glob import glob\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator","291ce4eb":"path = \".\/SMILEsmileD\/SMILEs\/*\/*\/*.jpg\"\n\nimages_paths = glob(path)\n\nlen(images_paths)","d94a9650":"images = []\nlabels = []\n\nfor path in images_paths:\n\n    img = load_img(path, color_mode='grayscale', target_size=(64,64))\n    img = img_to_array(img)\n    images.append(img)\n\n    label = path.split('\/')[-3]\n\n    if 'positives'==label:\n        labels.append(1)\n    else:\n        labels.append(0)\n\n\nimages = np.array(images)\nlabels = np.array(labels)","081268f5":"images.shape, labels.shape","065a7af6":"X_train, X_test, y_train, y_test = train_test_split(images, labels, \n                                                    test_size=0.1, \n                                                    random_state=10, \n                                                    stratify=labels)","44797f1a":"generator = ImageDataGenerator(horizontal_flip=True, rescale=1\/255.0)\n\ntrain_gen = generator.flow(X_train, y_train, batch_size=32, shuffle=True)","f1330e43":"model = Sequential(\n    [\n     Conv2D(128, 3, padding='same', activation='relu', input_shape=[64,64,1]),\n     BatchNormalization(),\n     MaxPooling2D(),\n     Conv2D(128, 3, padding='same', activation='relu'),\n     BatchNormalization(),\n     MaxPooling2D(),\n     Conv2D(128, 3, padding='same', activation='relu'),\n     BatchNormalization(),\n     MaxPooling2D(),\n     Flatten(),\n     Dense(256, 'relu'),\n     Dropout(0.2),\n     Dense(128, 'relu'),\n     Dense(1, 'sigmoid')\n    ]\n)\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","be34953f":"X_test_scaled = X_test \/ 255.0","27d3be5e":"tf.random.set_seed(10)\n\nearly_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n\nhistory = model.fit(train_gen, steps_per_epoch=len(X_train)\/\/32, \n                    epochs=50, validation_batch_size=32, \n                    validation_data=(X_test_scaled, y_test), \n                    callbacks=[early_stopping],\n                    verbose=2)","eb404049":"model.save('Smile_detection_model_BW_64x64.h5')","0df9e5e3":"fig, axs = plt.subplots(nrows=3, ncols=5, figsize=(15,9))\n\naxs = np.ravel(axs)\n\nfor i in range(15):\n\n    plt.sca(axs[i])\n    \n    img_batch = X_test_scaled[i].reshape(1, 64, 64, 1)\n    prediction = model.predict(img_batch)[0,0]\n    if prediction > 0.5:\n        prediction = 1\n    else:\n        prediction = 0\n\n    # show image\n    plt.imshow(X_test[i].squeeze(), cmap='gray')\n    if y_test[i]==prediction:\n        plt.title(\"Right Prediction\", fontdict={'color':'g'})\n    else:\n        plt.title(\"Wrong Prediction\", fontdict={'color':'r'})\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","9441ad85":"detector = MTCNN()\n\n## RGB image\nimage = cv2.cvtColor(image3, cv2.COLOR_BGR2RGB)\n\n# detect faces\ndetections = detector.detect_faces(image)\n\n# draw all faces\nfor face in detections:\n    x,y,w,h = face['box']\n\n    # getting face from image\n    gray = image3_gray[y:y+h, x:x+w]\n    # resize face\n    gray = cv2.resize(gray, (64,64))\n    # one batch\n    gray = gray.reshape(1,64,64,1)\n    predictions = model.predict(gray)[0,0]\n\n    if predictions>0.5:\n        image = cv2.rectangle(image, (x,y), (x+w, y+h), (0, 255, 0), 2)\n    else:\n        image = cv2.rectangle(image, (x,y), (x+w, y+h), (255, 0, 0), 2)\n\n\n# show image\nImage.fromarray(image)","979f6e47":"## MMOD (Max-Margin CNN Face Detector)","61c416f9":"## Haarcascade","ac97572c":"## Smile Detection","22287beb":"## HOG","0b03c47a":"## MTCNN"}}