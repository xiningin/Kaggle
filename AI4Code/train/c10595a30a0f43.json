{"cell_type":{"4b9f160b":"code","d75b55d9":"code","28aa3768":"code","7af078f0":"code","2852238b":"code","ca54084a":"code","684e6f7b":"code","3f243c57":"code","c0632a8e":"code","1101f00d":"code","d4ee8ba1":"code","a9a3f776":"code","5f4b4a19":"code","fb4f92d4":"code","8c2d8668":"code","1ae314ed":"code","23e77d78":"code","f8586414":"code","8a460596":"code","194421b6":"code","d13c1287":"code","b4fae7da":"code","d6d93c1b":"code","3243eb09":"markdown","baa3ecc1":"markdown","fdef6908":"markdown","99488d7c":"markdown"},"source":{"4b9f160b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\npath = '..\/input\/prediccin-velocidad-del-viento\/'\nimport statsmodels\nimport statsmodels.tsa.stattools as ts\nfrom statsmodels.tsa.stattools import acf, pacf\n\ndef crosscorr(datax, datay, lag=0):\n    \"\"\" Lag-N cross correlation. \n    Parameters\n    ----------\n    lag : int, default 0\n    datax, datay : pandas.Series objects of equal length\n\n    Returns\n    ----------\n    crosscorr : float\n    \"\"\"\n    return datax.corr(datay.shift(lag))\ndf_train = pd.read_csv(path+'windspeed-training.csv')","d75b55d9":"df_train = pd.read_csv(path+'windspeed-training.csv')\ndf_train['Fecha'] =  pd.to_datetime(df_train['Fecha'])\ndf_train['year'] = df_train.Fecha.dt.year\ndf_train['month'] = df_train.Fecha.dt.month\ndf_train['day'] = df_train.Fecha.dt.day\ndf_train['hour'] = df_train.Fecha.dt.hour\n# tomar la media y std por (mes,hora)\ndf_pivot = pd.pivot_table(df_train,index = ['month','hour'],values=[df_train.columns[1]],aggfunc=[np.mean,np.std])","28aa3768":"print(\"Cantidad de datos de 2012: \",df_train[df_train.year == 2012].shape[0])\nprint(\"Cantidad de datos de 2013: \",df_train[df_train.year == 2013].shape[0])\nprint(\"Cantidad de datos de 2014: \",df_train[df_train.year == 2014].shape[0])\nprint(\"Cantidad de datos de 2015: \",df_train[df_train.year == 2015].shape[0])\n\nprint(\"\\nIntervalo de fechas para 2012: \",df_train[df_train.year == 2012].iloc[[0,-1]].Fecha.values)\nprint(\"Intervalo de fechas para 2013: \",df_train[df_train.year == 2013].iloc[[0,-1]].Fecha.values)\nprint(\"Intervalo de fechas para 2014: \",df_train[df_train.year == 2014].iloc[[0,-1]].Fecha.values)\nprint(\"Intervalo de fechas para 2015: \",df_train[df_train.year == 2015].iloc[[0,-1]].Fecha.values)","7af078f0":"sns.boxplot(x = df_train[df_train.columns[1]])","2852238b":"df_train[df_train.columns[1]].plot()\ndf_train.pivot_table(index=['year','month','day','hour'],values = df_train.columns[1]).plot()\ndf_train.pivot_table(index=['year','month','day'],values = df_train.columns[1]).plot()\ndf_train.pivot_table(index=['year','month'],values = df_train.columns[1]).plot()\ndf_train.pivot_table(index=['year'],values = df_train.columns[1]).plot()","ca54084a":"#Conclusi\u00f3n: la hora est\u00e1 muy marcada. mes igual marcado pero no tanto\nfrom mpl_toolkits.mplot3d import axes3d\nplt.style.use('seaborn-white')\nlista = []\nfor elem in [1,2,3,4,5,6,7,8,9,10,11,12]:\n    #display(df_pivot.loc[(elem,),df_pivot.columns[0]].values)\n    lista.append(df_pivot.loc[(elem,),df_pivot.columns[0]].values.reshape(-1,1))\nz = np.hstack(lista).ravel()\n\n\nxlabels = df_pivot.index.get_level_values('month').unique()\nylabels = df_pivot.index.get_level_values('hour').unique()\nx = np.arange(xlabels.shape[0])\ny = np.arange(ylabels.shape[0])\nx_M, y_M = np.meshgrid(x, y, copy=False)\nimport matplotlib.colors as colors\nimport matplotlib.cm as cm\nfor rot in [45,135,225,315]:\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Making the intervals in the axes match with their respective entries\n    ax.w_xaxis.set_ticks(x + 0.5\/2.)\n    ax.w_yaxis.set_ticks(y + 0.5\/2.)\n\n    # Renaming the ticks as they were before\n    ax.w_xaxis.set_ticklabels(xlabels)\n    ax.w_yaxis.set_ticklabels(ylabels)\n\n    # Labeling the 3 dimensions\n    ax.set_xlabel('month')\n    ax.set_ylabel('hour')\n    ax.set_zlabel('WS')\n    offset = z + np.abs(z.min())\n    fracs = offset.astype(float)\/offset.max()\n    norm = colors.Normalize(fracs.min(), fracs.max())\n    color_values = cm.jet(norm(fracs.tolist()))\n\n    # Choosing the range of values to be extended in the set colormap\n    values = np.linspace(0.2, 1., x_M.ravel().shape[0])\n\n    # Selecting an appropriate colormap\n    #colors = plt.cm.Spectral(values)\n\n    ax.bar3d(x_M.ravel(), y_M.ravel(), z*0, dx=1, dy=1, dz=z, color=color_values)\n    ax.view_init(azim=rot)\n    plt.show()","684e6f7b":"#Se refuerza el analaisis anterior\nlabels = [1,2,3,4,5,6,7,8,9,10,11,12]\ncolors = ['g','b','r','y','c','m','k','orange','pink','brown','gray','fuchsia']\nfor cont,elem in enumerate(labels):\n    df_pivot.loc[elem,df_pivot.columns[0]].plot(figsize=(10,10),color=colors[cont])\nplt.legend(labels)\nplt.show()","3f243c57":"#std no cambia mucho para cada caso -> NO HAY HORAS O MESES EN DONDE LA MEDIA SEA MAS FIABLE QUE EN OTRAS\ndf_pivot2 = pd.pivot_table(df_train,index = ['year','month','hour'],values=[df_train.columns[1]],aggfunc=np.mean)\n\ndf_train.pivot_table(index = 'month',values=df_train.columns[1],aggfunc = [np.mean,np.std]).plot(kind='bar')\nplt.show()\ndf_train.pivot_table(index = 'hour',values=df_train.columns[1],aggfunc = [np.mean,np.std]).plot(kind='bar')\nplt.show()\n","c0632a8e":"#Viendo tendencia general del a\u00f1o por mes\n#conclusion: maoma \npivotx = df_train.pivot_table(index=['year','month'],values=df_train.columns[1],aggfunc=np.mean)\ntabla_2012 = pivotx.loc[(2012,)]\ntabla_2013 = pivotx.loc[(2013,)]\ntabla_2014 = pivotx.loc[(2014,)]\ntabla_2015 = pivotx.loc[(2015,)]\naux = tabla_2012.join(tabla_2013,how='outer',rsuffix='2013')\naux = aux.join(tabla_2014,how='outer',rsuffix='2014')\naux = aux.join(tabla_2015,how='outer',rsuffix='2015')\naux.plot(figsize=(16,8))\nplt.show()\n\nlista = []\nfor lag in range(-1,2):\n    try:\n        lista.append(crosscorr(aux[aux.columns[2]],aux[aux.columns[3]],lag))\n    except:\n        break\nplt.plot(range(-1,2),lista)\nprint(\"lag mas relacionado: {}, con corr: {} \".format(range(-1,2)[np.argmax(lista)],np.max(lista)))","1101f00d":"#viendo la serie completa pero mean per day, separando por a\u00f1os\n# No se pierde cronolog\u00eda\n#conclusi\u00f3n: Buena pinta\npivotx = df_train.pivot_table(index=['year','month','day'],values=df_train.columns[1],aggfunc=np.mean)\ntabla_2012 = pivotx.loc[(2012,)]\ntabla_2013 = pivotx.loc[(2013,)]\ntabla_2014 = pivotx.loc[(2014,)]\ntabla_2015 = pivotx.loc[(2015,)]\naux = tabla_2012.join(tabla_2013,how='outer',rsuffix='2013')\naux = aux.join(tabla_2014,how='outer',rsuffix='2014')\naux = aux.join(tabla_2015,how='outer',rsuffix='2015')\naux.plot(figsize=(16,8))\nplt.show()\n#largo = aux[aux.columns[1]].shape[0]\n#plt.plot(range(-int(largo\/2) ,largo-int(largo\/2)),statsmodels.tsa.stattools.ccf(aux[aux.columns[1]],aux[aux.columns[2]]))\n#plt.show()\nlista = []\nfor lag in range(-30,30):\n    try:\n        lista.append(crosscorr(aux[aux.columns[2]],aux[aux.columns[3]],lag))\n    except:\n        break\nplt.plot(range(-len(lista)\/\/2,len(lista)\/\/2),lista)\nprint(\"lag mas relacionado: {}, con corr: {} \".format(range(-len(lista)\/\/2,len(lista)\/\/2)[np.argmax(lista)],np.max(lista)))","d4ee8ba1":"#viendo la serie completa pero mean per day, separando por a\u00f1os\n# No se pierde cronolog\u00eda\n#conclusi\u00f3n: Buena pinta\npivotx = df_train.pivot_table(index=['year','month','day','hour'],values=df_train.columns[1],aggfunc=np.mean)\ntabla_2012 = pivotx.loc[(2012,)]\ntabla_2013 = pivotx.loc[(2013,)]\ntabla_2014 = pivotx.loc[(2014,)]\ntabla_2015 = pivotx.loc[(2015,)]\naux = tabla_2012.join(tabla_2013,how='outer',rsuffix='2013')\naux = aux.join(tabla_2014,how='outer',rsuffix='2014')\naux = aux.join(tabla_2015,how='outer',rsuffix='2015')\naux.plot(figsize=(16,8))\nplt.show()\n#largo = aux[aux.columns[1]].shape[0]\n#plt.plot(range(-int(largo\/2) ,largo-int(largo\/2)),statsmodels.tsa.stattools.ccf(aux[aux.columns[1]],aux[aux.columns[2]]))\n#plt.show()\nlista = []\nfor lag in range(-500,500):\n    try:\n        lista.append(crosscorr(aux[aux.columns[2]],aux[aux.columns[3]],lag))\n    except:\n        break\nplt.plot(range(-len(lista)\/\/2,len(lista)\/\/2),lista)\nprint(\"lag mas relacionado: {}, con corr: {} \".format(range(-len(lista)\/\/2,len(lista)\/\/2)[np.argmax(lista)],np.max(lista)))","a9a3f776":"408\/24","5f4b4a19":"#viendo tendencia de cada mes, separados por a\u00f1o\n# Conclusi\u00f3n: se ven patrones\npivotx = df_train.pivot_table(index=['year','month','day'],values=df_train.columns[1],aggfunc=np.mean)\narr = pivotx.pivot_table(index=['year','month'],aggfunc=list)\nnew = arr.pivot_table(index=['month'],aggfunc=list)\nfor elem in labels:\n    for lista in new.loc[elem].values[0]:\n        plt.plot(lista)\n    plt.title(\"Mes: \"+ str(elem))\n    plt.legend(['2013','2014','2015'])\n    if elem ==12:\n        plt.legend(['2012','2013','2014'])\n    plt.show()\n    \"\"\"lista2 = []\n    for lag in range(-5,5):\n        try:\n            lista2.append(crosscorr(pd.Series(new.loc[elem].values[0][0]),pd.Series(new.loc[elem].values[0][1]),lag))\n        except:\n            #lista2.append(crosscorr(pd.Series(new.loc[elem].values[0][0]),pd.Series(new.loc[elem].values[0][1]),lag))\n            break\n    print(\"lag mas relacionado: {}, con corr: {} \".format(range(-len(lista2)\/\/2,len(lista2)\/\/2)[np.argmax(lista2)],np.max(lista2)))\n    plt.show()\n    print(\"CORRECCION: \")\n    plt.plot(new.loc[elem].values[0][0])\n    plt.plot(pd.Series(new.loc[elem].values[0][1]).shift(range(-len(lista2)\/\/2,len(lista2)\/\/2)[np.argmax(lista2)]))\n    plt.show()\"\"\"","fb4f92d4":"#viendo las series separadas por a\u00f1o, promediando para cada (mes,hour)\n# Se pierde cronologia\n# Buena pinta\ntabla_2012 = df_pivot2.loc[(2012,)]\ntabla_2013 = df_pivot2.loc[(2013,)]\ntabla_2014 = df_pivot2.loc[(2014,)]\ntabla_2015 = df_pivot2.loc[(2015,)]\naux = tabla_2012.join(tabla_2013,how='outer',rsuffix='2013')\naux = aux.join(tabla_2014,how='outer',rsuffix='2014')\naux = aux.join(tabla_2015,how='outer',rsuffix='2015')\naux.drop((1,),inplace=True)\naux.plot(figsize=(8,8))\nplt.show()\nlista = []\n\nfor lag in range(-150,150):\n    try:\n        lista.append(crosscorr(aux[aux.columns[1]],aux[aux.columns[2]],lag))\n    except:\n        break\nplt.plot(range(-len(lista)\/\/2,len(lista)\/\/2),lista)\nprint(\"lag mas relacionado: {}, con corr: {} \".format(range(-len(lista)\/\/2,len(lista)\/\/2)[np.argmax(lista)],np.max(lista)))","8c2d8668":"#correlacion lineal fuerte entre las series anteriores\n# esto considera correlaci\u00f3n entre las variables con la variable equivalente de a\u00f1os anteriores\n# es decir, (mes,hour)_2015 -> (mismo_mes,mismo_hour)_2014 ...\naux.corr()","1ae314ed":"#Regresi\u00f3n lineal para concluir sobre tendencia a la baja\ntrain_data = aux.loc[aux[aux.columns[3]].notna(),[aux.columns[1],aux.columns[2],aux.columns[3]]]\nfrom sklearn.linear_model import LinearRegression\ntrain_data.columns = range(len(train_data.columns))\ny_train = train_data.pop(train_data.columns[2])\nclf = LinearRegression().fit(train_data,y_train)\nto_predict =  aux.loc[aux[aux.columns[3]].isna(),[aux.columns[1],aux.columns[2]]]\npreds = clf.predict(to_predict)\npreds = pd.Series(preds,index=to_predict.index)","23e77d78":"aux[aux.columns[3]].fillna(preds,inplace=True)\nfinal = aux[aux.columns[3]]\naux.plot(figsize=(8,8))","f8586414":"#df_pivot = pd.pivot_table(df_train,index = ['month','hour'],values=[df_train.columns[1]],aggfunc=np.mean)\n#forecast = pd.read_csv(path+'windspeed-testing.csv',header=None)\n#forecast[0] = pd.to_datetime(forecast[0],format=\"%d-%m-%Y %H:%M\")\n#forecast['month'] = forecast[0].dt.month + 1\n#forecast['hour'] = forecast[0].dt.hour\n#forecast = forecast.join(df_pivot,['month','hour'])\n#forecast.month = forecast.month-1\n#final = tabla_2015.append(forecast.pivot_table(index = ['month','hour']))\n#final = final.pivot_table(index = ['month','hour'],aggfunc=np.mean)\n\n\"\"\"tabla_2012 = df_pivot2.loc[(2012,)]\ntabla_2013 = df_pivot2.loc[(2013,)]\ntabla_2014 = df_pivot2.loc[(2014,)]\ntabla_2015 = df_pivot2.loc[(2015,)]\naux = tabla_2012.join(tabla_2013,how='outer',rsuffix='2013')\naux = aux.join(tabla_2014,how='outer',rsuffix='2014')\naux = aux.join(final,how='outer',rsuffix='2015')\naux.plot(figsize=(8,8))\"\"\"","8a460596":"#forecast = forecast.join(final,['month','hour'],rsuffix='new')","194421b6":"#submission = pd.read_csv(path+'sampleSubmission.csv')\n#submission[submission.columns[1]] = forecast[forecast.columns[3]]\n#submission.to_csv('baseline_t3.csv',index=False)\n#submission","d13c1287":"df_train['week'] = df_train.day \/\/ 7 + 1\ndf_train['week'] = (df_train.month-1)*4 + df_train.week","b4fae7da":"pivotx = df_train.pivot_table(index=['year','month','week'],values=df_train.columns[1],aggfunc=np.mean)\ntabla_2012 = pivotx.loc[(2012,)]\ntabla_2013 = pivotx.loc[(2013,)]\ntabla_2014 = pivotx.loc[(2014,)]\ntabla_2015 = pivotx.loc[(2015,)]\naux = tabla_2012.join(tabla_2013,how='outer',rsuffix='2013')\naux = aux.join(tabla_2014,how='outer',rsuffix='2014')\naux = aux.join(tabla_2015,how='outer',rsuffix='2015')\naux.plot(figsize=(16,8))\nplt.show()","d6d93c1b":"#from datetime import timedelta\n#df_train.loc[df_train.Fecha.dt.year == 2015,'Fecha'] = df_train.loc[df_train.Fecha.dt.year == 2015,'Fecha'] + timedelta(days=17)\n#df_train.month = df_train.Fecha.dt.month\n#df_train.day = df_train.Fecha.dt.day\n","3243eb09":"## Sobre tendencia a la baja en 2015.\nSe prob\u00f3 en el leaderboard p\u00fablico:\n\n    - mean (month,hour) usando info 2014 y 2013 para predecir 2015 (No considera tendencia a la baja)\n    \n    -regresi\u00f3n lineal sobre datos (month,hour) usando como target hasta abril. (Considera tendencia a la baja)\n   \n#### Predecir s\u00f3lo la media ha dado mejores resultados siempre. Esto sugiere que el a\u00f1o se regulariza. ","baa3ecc1":"### Sobre posible shift:","fdef6908":"#### Pareciera haber un shift de 17 dias","99488d7c":"## Se plantean las preguntas:\n    -Tendencia a la baja en el 2015. Se mantiene?\n    -Existe un shift en el 2015?\n"}}