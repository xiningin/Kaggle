{"cell_type":{"453cbdee":"code","64f4f311":"code","06c8e04d":"code","22c36bee":"code","e5fae152":"code","e77a55c3":"code","fcdb916a":"code","56cf9d7d":"code","5dfbe3d9":"code","0842924f":"code","5f85f994":"code","b101fa57":"code","b7ea5a4f":"code","ef6f2524":"code","75bfd592":"code","241b0736":"code","55f58605":"code","a323e493":"code","39a10d43":"markdown","794ca947":"markdown","7a39e803":"markdown","75fbb92f":"markdown","257078f1":"markdown","91e4b133":"markdown","a734178e":"markdown","97ee17f2":"markdown","9f37ae52":"markdown","d6cb1e1b":"markdown","698b2528":"markdown","f627b233":"markdown","db635e28":"markdown","98c75bb9":"markdown","774b86c0":"markdown","5b10d4d7":"markdown","6cc2c21f":"markdown","d54ddf74":"markdown","1244d799":"markdown","817b4885":"markdown"},"source":{"453cbdee":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport os\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix , classification_report , roc_auc_score , roc_curve\n\n\nfrom IPython.display import clear_output\nimport warnings\nwarnings.filterwarnings('ignore')","64f4f311":"input_dir = \"..\/input\/fake-video-images-dataset\/images_from_video_big\/\"\n\nSEED = 12\nIMG_HEIGHT= 160\nIMG_WIDTH = 160\nBATCH_SIZE = 32\nEPOCHS = 30\nSEED = 12 \nEARLY_STOPPING_CRITERIA =  5\nEPOCHS = 30\nLR = 0.0005\nCLASS_LABELS = [\"NOT FAKE\" , \"FAKE\"]","06c8e04d":"data = []\nfor img in os.listdir(\"..\/input\/fake-video-images-dataset\/images_from_video_big\") :\n    img_dir = input_dir + img\n    data.append(img_dir)\n    \nimage_df = pd.DataFrame(data , columns= [\"filename\"])\nimage_df[\"class\"] = 1 \nfor i in range(len(image_df)):\n    if image_df[\"filename\"][i][-5] == str(0):\n        image_df[\"class\"][i] = 0\nimage_df[\"class\"] = image_df[\"class\"].astype(\"str\")\n\noffset = int(len(image_df) * 0.70)\ntrain = image_df[:offset]\ntest = image_df[offset:]","22c36bee":"preprocess_fun = tf.keras.applications.densenet.preprocess_input\ntrain_datagen = ImageDataGenerator(horizontal_flip=True,\n                                   width_shift_range=0.1,\n                                   height_shift_range=0.1,\n                                   rescale = 1.\/255,\n                                   validation_split = 0.3,\n                                   preprocessing_function=preprocess_fun\n                                  )\ntest_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                  validation_split = 0.3,\n                                  preprocessing_function=preprocess_fun)","e5fae152":"train_generator = train_datagen.flow_from_dataframe(dataframe = train, \n                                                    x_col= 'filename', \n                                                    y_col='class',\n                                                    target_size=(IMG_HEIGHT , IMG_WIDTH), \n                                                    color_mode='rgb', class_mode='binary', \n                                                    batch_size=BATCH_SIZE,\n                                                    subset = \"training\",\n                                                    shuffle=True,\n                                                    seed=SEED)\n\ntest_generator = test_datagen.flow_from_dataframe(dataframe = test, \n                                                        x_col='filename', \n                                                        y_col='class',\n                                                        target_size=(IMG_HEIGHT , IMG_WIDTH), \n                                                        color_mode='rgb', class_mode='binary', \n                                                        batch_size=BATCH_SIZE, \n                                                        subset = \"validation\",\n                                                        shuffle=False,\n                                                        seed=SEED)","e77a55c3":"def display_one_image(image, title, subplot, color):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(title, fontsize=16)\n    \ndef display_nine_images(images, titles, title_colors=None):\n    subplot = 331\n    plt.figure(figsize=(13,13))\n    for i in range(9):\n        color = 'black' if title_colors is None else title_colors[i]\n        display_one_image(images[i], titles[i], 331+i, color)\n    plt.tight_layout()\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()\nclear_output()\n\ntemp_datagen = ImageDataGenerator(rescale = 1.\/255)\ntemp_generator = temp_datagen.flow_from_dataframe(dataframe = test[:100], \n                                                        x_col='filename', \n                                                        y_col='class',\n                                                        target_size=(IMG_HEIGHT , IMG_WIDTH), \n                                                        color_mode='rgb', class_mode='binary', \n                                                        batch_size=BATCH_SIZE, \n                                                        shuffle=True,\n                                                        seed=SEED)\nclear_output()\nimages, classes = next(temp_generator)\nclasses = classes.astype(\"int\") \nlabels = [CLASS_LABELS[idx] for idx in classes]\ndisplay_nine_images(images, labels)","fcdb916a":"fig = px.bar(x = CLASS_LABELS,\n             y = [list(train_generator.classes).count(i) for i in np.unique(train_generator.classes)] , \n             color = np.unique(train_generator.classes) ,\n             color_continuous_scale=\"Emrld\") \nfig.update_xaxes(title=\"Images\")\nfig.update_yaxes(title = \"Number of Images\")\nfig.update_layout(showlegend = True,\n    title = {\n        'text': 'Train Data Distribution ',\n        'y':0.95,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()","56cf9d7d":"def feature_extractor(inputs):\n    feature_extractor = tf.keras.applications.DenseNet201(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),\n                                               include_top=False,\n                                               weights=\"imagenet\")(inputs)\n    \n    return feature_extractor\n\ndef classifier(inputs):\n    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n    x = tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n    x = tf.keras.layers.Dropout(0.7)(x)\n    x = tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n    x = tf.keras.layers.Dropout(0.6) (x)\n    x = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"classification\")(x)\n    \n    return x\n\ndef final_model(inputs):\n    densenet_feature_extractor = feature_extractor(inputs)\n    classification_output = classifier(densenet_feature_extractor)\n    \n    return classification_output\n\ndef define_compile_model():\n    \n    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))\n    classification_output = final_model(inputs) \n    model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n     \n    model.compile(optimizer=tf.keras.optimizers.SGD(0.1), \n                loss='binary_crossentropy',\n                metrics = [\"accuracy\",tf.keras.metrics.AUC()])\n  \n    return model","5dfbe3d9":"model = define_compile_model()\nclear_output()\n\n# Feezing the feature extraction layers\nmodel.layers[1].trainable = False\n\nmodel.summary()","0842924f":"earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n                                                         patience=EARLY_STOPPING_CRITERIA,\n                                                         verbose= 1 ,\n                                                         restore_best_weights=True\n                                                        )\n\nhistory = model.fit(x = train_generator,\n                    epochs = EPOCHS,\n                    validation_data = test_generator , \n                    callbacks= [earlyStoppingCallback])\n\nhistory = pd.DataFrame(history.history)","5f85f994":"x = px.line(data_frame= history , y= [\"accuracy\" , \"val_accuracy\"] ,markers = True )\nx.update_xaxes(title=\"Number of Epochs\")\nx.update_yaxes(title = \"Accuracy\")\nx.update_layout(showlegend = True,\n    title = {\n        'text': 'Accuracy vs Number of Epochs',\n        'y':0.94,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nx.show()","b101fa57":"x = px.line(data_frame= history , y= [\"auc\" , \"val_auc\"] , markers = True )\nx.update_xaxes(title=\"Number of Epochs\")\nx.update_yaxes(title = \"AUC Score\")\nx.update_layout(showlegend = True,\n    title = {\n        'text': 'AUC Score vs Number of Epochs',\n        'y':0.94,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nx.show()","b7ea5a4f":"x = px.line(data_frame= history , y= [\"loss\" , \"val_loss\"] , markers = True )\nx.update_xaxes(title=\"Number of Epochs\")\nx.update_yaxes(title = \"Loss\")\nx.update_layout(showlegend = True,\n    title = {\n        'text': 'Loss vs Number of Epochs',\n        'y':0.94,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nx.show()","ef6f2524":"model.evaluate(test_generator)\npreds = model.predict(test_generator)\ny_preds = (np.squeeze(preds) > 0.5).astype(int)\ny_test = np.array(test_generator.labels)","75bfd592":"cm_data = confusion_matrix(y_test , y_preds)\ncm = pd.DataFrame(cm_data, columns=CLASS_LABELS, index = CLASS_LABELS)\ncm.index.name = 'Actual'\ncm.columns.name = 'Predicted'\nplt.figure(figsize = (20,10))\nplt.title('Confusion Matrix', fontsize = 20)\nsns.set(font_scale=1.2)\nax = sns.heatmap(cm, cbar=False, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}, fmt='g')","241b0736":"print(classification_report(y_test, y_preds))","55f58605":"print(\"ROC-AUC Score  = \" ,roc_auc_score(y_test , preds))","a323e493":"fpr, tpr, thresholds  = roc_curve(y_test, preds)\nauc = roc_auc_score(y_test, preds)\nplt.figure(figsize = (10,7))\nplt.plot(fpr,tpr,color='darkred', lw=2, label=\"AUC SCORE=\"+str(round(auc,2)))\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.title('ROC AUC CURVE', fontsize = 16)\nplt.xlabel(\"False Positive Rate\")\nplt.xlabel(\"True Positive Rate\")\nplt.legend(loc=4)\nplt.show()","39a10d43":"### Loss , Accuracy and AUC score on Test Data","794ca947":"## ROC AUC Score","7a39e803":"## Summary of model","75fbb92f":"## Training plots","257078f1":"## [1. Imports](#im) ##\n## [2. HyperParameters](#hp) ##\n## [3. Data Loading and Preprocessing](#data) ##\n## [4. DenseNet201 Model](#model)  ##\n## [5. Training](#train) ##","91e4b133":"### Creating a dataframe containing filename and labels","a734178e":"# Evaluation","97ee17f2":"## Training model with freezed layers of DenseNet201","9f37ae52":"## Confusion Matrix","d6cb1e1b":"## Data distribution (count) among both classes","698b2528":"<a id=\"hp\"><\/a>\n# <center>HYPERPARAMETRERS AND DIRECTORIES<\/center>","f627b233":"<a id=\"train\"><\/a>\n# <center> Training <\/center> ","db635e28":"<a id=\"im\"><\/a>\n# <center>IMPORTING LIBRARIES<\/center> ","98c75bb9":"# <center> FAKE OR NOTE FAKE\ud83e\udd14<\/center>\n## <center>If you find this notebook useful, support with an upvote\ud83d\udc4d<\/center>","774b86c0":"## ROC AUC Curve","5b10d4d7":"**Created by Sanskar Hasija**\n\n**Fake or Not Fake\ud83e\udd14**\n\n**1 NOVEMBER 2021**\n","6cc2c21f":"<a id=\"data\"><\/a>\n# <center> DATA LOADING AND PRE-PROCESSING<\/center>","d54ddf74":"## Classification Report ","1244d799":"## Images of both classes","817b4885":"<a id=\"model\"><\/a>\n# <center> DenseNet201 Transfer Learning  <\/center>"}}