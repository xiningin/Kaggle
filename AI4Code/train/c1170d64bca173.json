{"cell_type":{"1bcfcf0a":"code","6e324ea5":"code","5128818c":"code","a147493e":"code","de3a2702":"code","d97f16df":"code","4880b2ba":"code","d898e6e0":"code","03748757":"code","629d36b7":"code","ed6e8c1c":"code","1a22d806":"markdown","d6da68fb":"markdown","207e12f9":"markdown","29feee5f":"markdown","5d3cf58b":"markdown","1c8b178f":"markdown","60b85ef5":"markdown","88a6643c":"markdown","9bdfd12a":"markdown","11536ce6":"markdown"},"source":{"1bcfcf0a":"#import libraries\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt","6e324ea5":"data = pd.read_csv(\"..\/input\/company-bankruptcy-prediction\/data.csv\")\ndata.head()","5128818c":"plt.scatter(data.iloc[:,1],data.iloc[:,3])\nplt.xlabel(\"ROA(C) before interest and depreciation before interest\")\nplt.ylabel(\"ROA(B) before interest and depreciation after tax\")\nplt.title(\"ROA(C) - ROA(B)\")\nplt.show()","a147493e":"column_1 = data.iloc[:,1]\ncolumn_2 = data.iloc[:,3]\ndictionary = {\"ROA\":column_1,\"ROB\":column_2}\ndata2 = pd.DataFrame(dictionary)\ndata2.head()","de3a2702":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters = 4)\nkmeans.fit(data2)\nlabels = kmeans.predict(data2)\n\nplt.scatter(data.iloc[:,1],data.iloc[:,3],c = labels)\nplt.xlabel(\"ROA(C) before interest and depreciation before interest\")\nplt.ylabel(\"ROA(B) before interest and depreciation after tax\")\nplt.title(\"ROA(C) - ROA(B)\")\nplt.show()","d97f16df":"wcss = []\n\nfor each in range(1,10):\n    kmeans = KMeans(n_clusters = each)\n    kmeans.fit(data2)\n    wcss.append(kmeans.inertia_)\n    \nplt.plot(range(1,10),wcss,'-o')\nplt.xlabel(\"Count of cluster\")\nplt.ylabel(\"WCSS\")\nplt.show()","4880b2ba":"#Again we will create our model with 3 count of cluster\nfinal_kmeans = KMeans(n_clusters = 2)\nfinal_kmeans.fit(data2)\nlabels = final_kmeans.predict(data2)\n\nplt.scatter(data.iloc[:,1],data.iloc[:,3],c = labels)\nplt.xlabel(\"ROA(C) before interest and depreciation before interest\")\nplt.ylabel(\"ROA(B) before interest and depreciation after tax\")\nplt.title(\"ROA(C) - ROA(B)\")\nplt.show()","d898e6e0":"data = pd.read_csv(\"..\/input\/company-bankruptcy-prediction\/data.csv\")\nsub_data = data.drop('Bankrupt?',axis = 1)","03748757":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\nscalar = StandardScaler()\nkmeans = KMeans(n_clusters = 2)\n\npipe = make_pipeline(scalar,kmeans)\npipe.fit(sub_data)\nlabels = pipe.predict(sub_data)","629d36b7":"df = pd.DataFrame({'labels':labels,\"Bankrupt?\":data['Bankrupt?']})\nct = pd.crosstab(df['labels'],df['Bankrupt?'])\n\nprint(ct)","ed6e8c1c":"from scipy.cluster.hierarchy import linkage,dendrogram\n\nmerg = linkage(sub_data.iloc[200:220,:],method = \"single\")#because of interrupt we did 200 between 300\ndendrogram(merg,leaf_rotation = 90,leaf_font_size = 6)\nplt.show()","1a22d806":"# KMeans Clustering","d6da68fb":"### Let's look,we don't know their labels.How we can find them ? \n-With clusters.","207e12f9":"### And Evaluate","29feee5f":"# STANDARDIZATION","5d3cf58b":"# H\u0130ERARCHY","1c8b178f":"### \u0130f we divide our data 4 cluster it will be like that.But why 4 cluster,let's try more of 4 cluster,What we will see.","60b85ef5":"WCSS : Within cluster sum of squares \n\nWCSS mean,we will take cluster centers mean and we're gonna calculate distance each of sample,\u0130f you wanna learn more.You can look sklearn documentation\n\n\n\u0130f we increase cluster count it will be much less but we can't do it.Because if we do our data is going to be overfitting.We don't want it.\nSo we must take **elbow** count.When we take it,model will more clean and good.That's the literature.\n\nElbow : When you see an elbow(\u0130t is 2 count of cluster you can see the elbow)","88a6643c":"* vertical lines are clusters\n* height on dendogram: distance between merging cluster\n* method= 'single' : closest points of clusters","9bdfd12a":"* Standardizaton is important for both supervised and unsupervised learning\n* Do not forget standardization as pre-processing\n* As we already have visualized data so you got the idea. Now we can use all features for clustering.\n* We can use pipeline like supervised learning.","11536ce6":"### We will learn this kaggle how to find labels,if our data hasn't labels you can't do supervised learning models,so if we find them you can do it.Please don't forget like the button,Okay.Let's start."}}