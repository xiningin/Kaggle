{"cell_type":{"51b3052a":"code","d0c21c1f":"code","acafd11b":"code","7bfbfe5b":"code","90e28e66":"code","8b987e22":"code","ab0b122a":"code","b96df11b":"code","2f67d1d0":"markdown","85d637dd":"markdown","0bfa3b8f":"markdown","ce94aebe":"markdown","a570a2ca":"markdown","5383a44a":"markdown","42277b35":"markdown","677e92cd":"markdown","5fafd568":"markdown","e20a7f16":"markdown","6aa676ab":"markdown"},"source":{"51b3052a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d0c21c1f":"data = pd.read_csv('\/kaggle\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 4.csv');\ndata","acafd11b":"# sample data\ndata.head()\n\n# get columns Name\nprint(data.columns)\n\n# convert columns having spaces to '_', because we can access order number column as data['Order Number'] but not like this data.Order Number.\n# So converting them is good idea. Also converting columns names into lower string\n\ncolumns = data.columns.str.replace(' ','_').str.lower()\n\n# remove the special characters\ncolumns = columns.str.replace('[(,)]', '')\n\ndata.columns = columns\n\n# as info shows count of each columns' rows. Columns order_number, order_status and order_date has rows equals to total rows. This show that these columns has null value.\n# book_name column has 2 null values and city_billing has 1 null value. \n# Lets count null count as varify this.\n\nprint(data.isnull().sum())\n\n# treat the null values \n# treament for book_name: as book name is string so we can use mode, to fill null values. Mode means which book is buy most i.e. '\u0627\u0646\u0679\u0631\u0646\u06cc\u0679 \u0633\u06d2 \u067e\u06cc\u0633\u06c1 \u06a9\u0645\u0627\u0626\u06cc\u06ba'\nprint(data.book_name.mode()[0])\ndata.book_name = data.book_name.fillna(data.book_name.mode()[0])\n\n# now book_name has no null values\nprint(data.isnull().sum())\n\n# treatment for city_billing: as city billing is string so we can use mode, to fill null values. Mode means which city has most buyer i.e. 'Karachi'\nprint(data.city_billing.mode())\ndata.city_billing = data.city_billing.fillna(data.city_billing.mode()[0])\n\n# now city_billing has no null values\nprint(data.isnull().sum())\n\n# book name column having multiple books seperated by '\/'. we will convert them into array.\ndata['book_name_list'] = data.book_name.str.split('\/')\n\n# coonvert Date string to Date object\ndata['order_date'] = pd.to_datetime(data['order_date'])\nprint(data.head())\n\n#include a book count column, having count of books in order\ndata['order_books_count'] = data.book_name_list.apply(len)\nprint(data.head())","7bfbfe5b":"# let get status of order\n\nstatuses = data.order_status.unique() # array(['Completed', 'Returned', 'Canceled'], dtype=object)\nplt.style.use('seaborn')\nplt.title('Order status Frequency')\nplt.xlabel('Order status')\nplt.ylabel('Number of orders')\nplt.hist(data.order_status)\nplt.show()","90e28e66":"# get unique years list from order_date column\ndata_years = data['order_date'].dt.strftime(\"%Y\").unique().tolist()\nprint(data_years)\n\n# get statuses of 2019 year\nstatus_2019 = data[data['order_date'].dt.strftime(\"%Y\") == \"2019\"].order_status\n\n#get statuses of 2020 year\nstatus_2020 = data[data['order_date'].dt.strftime(\"%Y\") == \"2020\"].order_status\n\n#get statuses of 2021 year\nstatus_2021 = data[data['order_date'].dt.strftime(\"%Y\") == \"2021\"].order_status\n\n\n#plot graph for year 2019\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1,3,1)\nplt.title('2019 Year Order Status')\nplt.xlabel('Order statuses')\nplt.ylabel('Number of orders')\nplt.hist(status_2019)\n\n#plot graph for year 2020\nplt.subplot(1,3,2)\nplt.title('2020 Year Order Status')\nplt.xlabel('Order statuses')\nplt.ylabel('Number of orders')\nplt.hist(status_2020)\n\n#plot graph for year 2021\nplt.subplot(1,3,3)\nplt.title('2021 Year Order Status')\nplt.xlabel('Order statuses')\nplt.ylabel('Number of orders')\nplt.hist(status_2021)\n","8b987e22":"orders_count_per_month_per_year = data['order_date'].groupby([data['order_date'].dt.year.rename('year'), data['order_date'].dt.month.rename('month')]).agg({'count'})\norders_count_per_month_per_year.plot()","ab0b122a":"data['book_name'].value_counts()[:10].plot(kind='bar')","b96df11b":"data['city_billing'].value_counts()[:10].plot(kind='bar')","2f67d1d0":"# Exploratory data analysis","85d637dd":"# 2. Loading the dataset","0bfa3b8f":"# Table of Content\n\n1. Importing the library\n2. Loading the dataset\n3. Explore the data\n    - Checking the null values\n4. Answer to question asked by Gufthugu    \n5. Exploratory data analysis.\n\n    - What is the best-selling book?\n    - Visualize order status frequency\n    - Find a correlation between date and time with order status\n    - Find a correlation between city and order status\n    - Find any hidden patterns that are counter-intuitive for a layman\n    - Can we predict number of orders, or book names in advance?","ce94aebe":"* What is the 10 best-selling book?","a570a2ca":"# Please Upvote if you find the notebook interesting.\nThis notebook is under MIT License Feel free to copy and edit it.","5383a44a":"**Top Ten Cities**","42277b35":"# 1. Import Libraries","677e92cd":"# Number of orders by Year.","5fafd568":"# 3. Explore the data","e20a7f16":"**Order Status by X Year**","6aa676ab":"**Total order status**"}}