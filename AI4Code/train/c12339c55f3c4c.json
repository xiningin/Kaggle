{"cell_type":{"b1491f33":"code","be066773":"code","bed31e92":"code","745d57ba":"code","3e019fd0":"code","f206284f":"code","c915790b":"code","14b47a75":"code","7b4583f4":"code","4284f8e8":"code","99e8dc4b":"code","360001b7":"code","c12abdf0":"markdown","cd2a004e":"markdown","12e20299":"markdown","da4d88be":"markdown"},"source":{"b1491f33":"%matplotlib inline\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nimport cv2\nimport numpy as np\nfrom glob import glob\nimport matplotlib.cm as cm\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\n\nBASE_DATA_FOLDER = \"..\/input\/covid19-image-dataset\/Covid19-dataset\"\nTRAin_DATA_FOLDER = os.path.join(BASE_DATA_FOLDER, \"train\")\n","be066773":"def create_mask_for_plant(image):\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    sensitivity = 35\n    lower_hsv = np.array([60 - sensitivity, 100, 50])\n    upper_hsv = np.array([60 + sensitivity, 255, 255])\n\n    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask\n\ndef segment_plant(image):\n    mask = create_mask_for_plant(image)\n    output = cv2.bitwise_and(image, image, mask = mask)\n    return output\n\ndef visualize_scatter_with_images(X_2d_data, images, figsize=(45,45), image_zoom=1):\n    fig, ax = plt.subplots(figsize=figsize)\n    artists = []\n    for xy, i in zip(X_2d_data, images):\n        x0, y0 = xy\n        img = OffsetImage(i, zoom=image_zoom)\n        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n        artists.append(ax.add_artist(ab))\n    ax.update_datalim(X_2d_data)\n    ax.autoscale()\n    plt.show()\n\ndef visualize_scatter(data_2d, label_ids, figsize=(20,20)):\n    plt.figure(figsize=figsize)\n    plt.grid()\n    \n    nb_classes = len(np.unique(label_ids))\n    \n    for label_id in np.unique(label_ids):\n        plt.scatter(data_2d[np.where(label_ids == label_id), 0],\n                    data_2d[np.where(label_ids == label_id), 1],\n                    marker='o',\n                    color= plt.cm.Set1(label_id \/ float(nb_classes)),\n                    linewidth='1',\n                    alpha=0.8,\n                    label=id_to_label_dict[label_id])\n    plt.legend(loc='best')\n\n","bed31e92":"images = []\nlabels = []\n\nfor class_folder_name in os.listdir(TRAin_DATA_FOLDER):\n    class_folder_path = os.path.join(TRAin_DATA_FOLDER, class_folder_name)\n    for image_path in glob(os.path.join(class_folder_path, \"*.jpeg\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        \n        #image = cv2.resize(image, (150, 150))\n        #image = segment_plant(image)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (45,45))\n        \n        image = image.flatten()\n        \n        images.append(image)\n        labels.append(class_folder_name)\n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        \n        #image = cv2.resize(image, (150, 150))\n        #image = segment_plant(image)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (45,45))\n        \n        image = image.flatten()\n        \n        images.append(image)\n        labels.append(class_folder_name)\n    for image_path in glob(os.path.join(class_folder_path, \"*.jpg\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        \n        #image = cv2.resize(image, (150, 150))\n        #image = segment_plant(image)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (45,45))\n        \n        image = image.flatten()\n        \n        images.append(image)\n        labels.append(class_folder_name)\n        \nimages = np.array(images)\nlabels = np.array(labels)\n\nlabels","745d57ba":"images","3e019fd0":"label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\nid_to_label_dict = {v: k for k, v in label_to_id_dict.items()}\n\nlabel_ids = np.array([label_to_id_dict[x] for x in labels])\n\nimages_scaled = StandardScaler().fit_transform(images)","f206284f":"images_scaled.shape","c915790b":"label_ids.shape","14b47a75":"plt.imshow(np.reshape(images[15], (45,45)), cmap=\"gray\")","7b4583f4":"pca = PCA(n_components=180)\npca_result = pca.fit_transform(images_scaled)\npca_result.shape","4284f8e8":"tsne = TSNE(n_components=2, perplexity=10.0)\ntsne_result = tsne.fit_transform(pca_result)\ntsne_result_scaled = StandardScaler().fit_transform(tsne_result)\nvisualize_scatter(tsne_result_scaled, label_ids)\n","99e8dc4b":"visualize_scatter_with_images(tsne_result_scaled, images = [np.reshape(i, (45,45)) for i in images], image_zoom=0.7)","360001b7":"tsne = TSNE(n_components=3)\ntsne_result = tsne.fit_transform(pca_result)\ntsne_result_scaled = StandardScaler().fit_transform(tsne_result)\n\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import animation\n\nfig = plt.figure(figsize=(25,25))\nax = fig.add_subplot(111,projection='3d')\n\nplt.grid()\n    \nnb_classes = len(np.unique(label_ids))\n    \nfor label_id in np.unique(label_ids):\n    ax.scatter(tsne_result_scaled[np.where(label_ids == label_id), 0],\n                tsne_result_scaled[np.where(label_ids == label_id), 1],\n                tsne_result_scaled[np.where(label_ids == label_id), 2],\n                alpha=0.8,\n                color= plt.cm.Set1(label_id \/ float(nb_classes)),\n                marker='o',\n                label=id_to_label_dict[label_id])\nax.legend(loc='best')\nax.view_init(20, 40)\nax.set_xlim(-1.5, 1.5)\nax.set_ylim(-1.5, 1.5)\nax.set_zlim(-1.5, 1.5)\n\n","c12abdf0":"# t-SNE","cd2a004e":"# t-SNE and PCA visualisation","12e20299":"\n# 3d t-SNE","da4d88be":"dataset used - \"covid19-image-dataset\"\n(from kaggle)"}}