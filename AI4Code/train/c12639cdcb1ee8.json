{"cell_type":{"d290add5":"code","8a5055a6":"code","e827fbd0":"code","ee0807fa":"code","d79f2fad":"code","2e28ff36":"code","3f519003":"code","4ca3606c":"code","39562c18":"code","29581d8a":"code","ffbcbf71":"code","a9d657cf":"code","de290a42":"code","5846c12c":"code","828437f3":"code","9d7691fd":"code","6ff72ed8":"code","b0f81126":"code","f59cb6f9":"code","a881dcb0":"code","a01a948d":"code","322d866d":"code","2d241aca":"code","7de3571b":"code","ac89aed5":"code","b115c8de":"code","14dfa731":"code","a7990b2c":"code","0d6e8e5f":"code","bcdbcf9d":"code","c7b7ab0e":"code","e9cc0eda":"code","543312ee":"code","30df6866":"code","52337951":"code","30e8e325":"code","a5e62054":"code","80ae677d":"markdown","1f3d75bd":"markdown"},"source":{"d290add5":"from pathlib import Path\nimport pydicom\nimport numpy as np\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches","8a5055a6":"labels = pd.read_csv(\"..\/input\/rsna-heart-detection\/rsna_heart_detection.csv\")\nlabels.head()","e827fbd0":"labels.shape","ee0807fa":"ROOT_PATH = Path(\"..\/input\/rsna-pneumonia-detection-challenge\/stage_2_train_images\/\")\nSAVE_PATH = Path(\"..\/Processed-Heart-Detection\")","d79f2fad":"fig, axis = plt.subplots(2 ,2)\nc = 0\nfor i in range(2):\n    for j in range(2):\n        data = labels.iloc[c]\n        patient_id = data[\"name\"]\n        dcm_path = ROOT_PATH\/str(patient_id)  # Create the path to the dcm file\n        dcm_path =dcm_path.with_suffix(\".dcm\")\n        \n        dcm = pydicom.read_file(dcm_path)\n        dcm_array = dcm.pixel_array\n        dcm_array = cv2.resize(dcm_array, (224,224))\n        \n        x = data[\"x0\"]\n        y = data[\"y0\"]\n        width = data[\"w\"]\n        height = data[\"h\"]\n        \n        axis[i][j].imshow(dcm_array, cmap=\"bone\")\n        rect = patches.Rectangle((x,y), width, height, linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n        axis[i][j].add_patch(rect)\n        c+=1","2e28ff36":"sums = 0\nsums_squared = 0\ntrain_ids = []\nval_ids = []\n\nfor counter, patient_id in enumerate(list(labels.name)):\n    dcm_path = ROOT_PATH\/str(patient_id)  # Create the path to the dcm file\n    dcm_path = dcm_path.with_suffix(\".dcm\")  # And add the .dcm suffix\n    \n    dcm = pydicom.read_file(dcm_path)  # Read the dicom file with pydicom\n    \n    # Retrieve the actual image \n    dcm_array = dcm.pixel_array\n        \n    # Resize the image to drastically improve training speed\n    # In order to reduce the space when storing the image we convert it to float16\n    # Standardize to 0-1 range\n    dcm_array = (cv2.resize(dcm_array, (224, 224)) \/ 255).astype(np.float16)\n          \n    # 4\/5 train split, 1\/5 val split\n    train_or_val = \"train\" if counter < 400 else \"val\" \n    \n    # Add to corresponding train or validation patient index list\n    if train_or_val ==\"train\":\n        train_ids.append(patient_id)\n    else:\n        val_ids.append(patient_id)\n        \n    current_save_path = SAVE_PATH\/train_or_val # Define save path and create if necessary\n    current_save_path.mkdir(parents=True, exist_ok=True)\n    \n    np.save(current_save_path\/patient_id, dcm_array) # Save the array in the corresponding directory\n    \n    normalizer = 224*224\n    if train_or_val == \"train\":\n        sums += np.sum(dcm_array) \/ normalizer\n        sums_squared += (dcm_array**2).sum() \/ normalizer","3f519003":"np.save(\"..\/Processed-Heart-Detection\/train_subjects\", train_ids)\nnp.save(\"..\/Processed-Heart-Detection\/val_subjects\", val_ids)","4ca3606c":"mean = sums \/len(train_ids)\nstd = np.sqrt((sums_squared \/ len(train_ids)) - mean**2)\nmean, std","39562c18":"from pathlib import Path\nimport torch\nimport numpy as np\nimport pandas as pd\nimport imgaug   #imgaug to set a random seed for augmentations\nfrom imgaug.augmentables.bbs import BoundingBox \n# BoundingBox from imgaug to automatically handle the coordinates when augmenting the image","29581d8a":"class CardiacDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, path_to_labels_csv, patients, root_path, augs):\n        \n        self.labels = pd.read_csv(path_to_labels_csv)\n        self.patients = np.load(patients)\n        self.root_path = Path(root_path)\n        self.augment = augs\n        \n    def __len__(self):\n        \"\"\"\n        Returns the length of the dataset\n        \"\"\"\n        return len(self.patients)\n    \n    def __getitem__(self, idx):\n        \"\"\"\n        Returns an image paired with bbox around the heart\n        \"\"\"\n        \n        patient = self.patients[idx]\n        \n        # Get data according to index\n        data = self.labels[self.labels[\"name\"]==patient]\n        \n        # Get entries of given patient\n        # Extract coordinates\n        x_min = data[\"x0\"].item()\n        y_min = data[\"y0\"].item()\n        x_max = x_min + data[\"w\"].item()\n        y_max = y_min + data[\"h\"].item()\n        bbox = [x_min, y_min, x_max, y_max]\n        \n        # Load file and convert to float32\n        file_path = self.root_path\/patient  # Create the path to the file\n        img = np.load(f\"{file_path}.npy\").astype(np.float32)\n        \n        # Apply imgaug augmentations to image and bounding box\n        if self.augment:\n            bb = BoundingBox(x1=bbox[0], y1=bbox[1], x2=bbox[2], y2=bbox[3])\n            random_seed = torch.randint(0, 100000, (1,)).item()\n            imgaug.seed(random_seed)\n            \n            img, aug_bbox = self.augment(image=img, bounding_boxes=bb)\n            bbox = aug_bbox[0][0], aug_bbox[0][1], aug_bbox[1][0], aug_bbox[1][1]\n            \n        # Normalize the image according to the values computed in Preprocessing    \n        img = (img - 0.494) \/ 0.252\n        img = torch.tensor(img).unsqueeze(0)\n        bbox = torch.tensor(bbox)\n        return img, bbox","ffbcbf71":"import imgaug.augmenters as iaa\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches","a9d657cf":"# First create the augmentation object (augmentation pipeline define)\nseq = iaa.Sequential([\n    iaa.GammaContrast(),\n    iaa.Affine(\n        scale=(0.8, 1.2),\n        rotate=(-10, 10),\n        translate_px=(-10, 10))\n])","de290a42":"labels_path = \"..\/input\/rsna-heart-detection\/rsna_heart_detection.csv\"\npatients_path = \"..\/Processed-Heart-Detection\/train_subjects.npy\"\ntrain_root = \"..\/Processed-Heart-Detection\/train\/\"\ndataset = CardiacDataset(labels_path, patients_path, train_root, seq)","5846c12c":"dataset[0]","828437f3":"img, bbox = dataset[48]\n\nfig, axis = plt.subplots(1, 1)\naxis.imshow(img[0], cmap=\"bone\")\nrect = patches.Rectangle((bbox[0], bbox[1]), bbox[2]-bbox[0], bbox[3]-bbox[1], edgecolor=\"r\", facecolor=\"none\")\naxis.add_patch(rect)\n\n# run this cell more than one. every run correctly sign the heart","9d7691fd":"img, label = dataset[48]\n\nfig, axis = plt.subplots(1, 1)\naxis.imshow(img[0], cmap=\"bone\")\nspot1 = patches.Rectangle((label[0], label[1]), label[2] - label[0], label[3] - label[1], edgecolor='r', facecolor='none')\naxis.add_patch(spot1)\n\naxis.set_title(\"X-RAY with BBOX around heart\")\nprint(label)","6ff72ed8":"# import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"..\/input\/dataset\/dataset_.py\", dst = \"..\/working\/dataset_.py\") ","b0f81126":"import torch\nimport torchvision\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.loggers import TensorBoardLogger\nimport numpy as np\nimport cv2\nimport imgaug.augmenters as iaa\nfrom dataset_ import CardiacDataset # IMPORT THE DATASET","f59cb6f9":"train_root_path = \"..\/Processed-Heart-Detection\/train\"\ntrain_subjects = \"..\/Processed-Heart-Detection\/train_subjects.npy\"\nval_root_path = \"..\/Processed-Heart-Detection\/val\"\nval_subjects = \"..\/Processed-Heart-Detection\/val_subjects.npy\"\n\ntrain_transformers = iaa.Sequential([\n    iaa.GammaContrast(),\n    iaa.Affine(\n        scale=(0.8, 1.2),\n        rotate=(-10, 10),\n        translate_px=(-10, 10))\n])","a881dcb0":"train_dataset = CardiacDataset(\"..\/input\/rsna-heart-detection\/rsna_heart_detection.csv\", train_subjects, train_root_path, train_transformers)\nval_dataset = CardiacDataset(\"..\/input\/rsna-heart-detection\/rsna_heart_detection.csv\", val_subjects, val_root_path, None)","a01a948d":"batch_size = 8\nnum_workers = 2\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)","322d866d":"torchvision.models.resnet18()","2d241aca":"class CardiacDetectionModel(pl.LightningModule):\n    \n    def __init__(self):\n        super().__init__()\n        \n        self.model = torchvision.models.resnet18(pretrained=True)  #transfer learning\n        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=4)\n        \n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n        self.loss_fn = torch.nn.MSELoss()\n        \n    def forward(self, data):\n        return self.model(data)\n    \n    def training_step(self, batch, batch_idx):\n        x_ray, label = batch\n        label = label.float()  # Convert label to float (just needed for loss computation)\n        pred = self(x_ray)\n        loss = self.loss_fn(pred, label)  # Compute the loss\n        \n        self.log(\"Train Loss\", loss)\n        \n        if batch_idx % 50 ==0:\n            self.log_images(x_ray.cpu(), pred.cpu(), label.cpu(), \"Train\")\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x_ray, label = batch\n        label = label.float()\n        pred = self(x_ray)\n        loss = self.loss_fn(pred, label)\n        \n        self.log(\"Val Loss\", loss)\n        \n        if batch_idx % 50 ==0:\n            self.log_images(x_ray.cpu(), pred.cpu(), label.cpu(), \"Val\")\n        return loss\n    \n    def log_images(self, x_ray, pred, label, name):\n        results = []\n        \n        # Here we create a grid consisting of 4 predictions\n        for i in range(4):\n            coords_labels = label[i]\n            coords_pred = pred[i]\n            \n            img = ((x_ray[i] * 0.252) + 0.494).numpy()[0]\n            \n            # Extract the coordinates from the label\n            x0, y0 = coords_labels[0].int().item(), coords_labels[1].int().item()\n            x1, y1 = coords_labels[2].int().item(), coords_labels[3].int().item()\n            img = cv2.rectangle(img, (x0, y0), (x1, y1), (0, 0, 0), 2)\n            \n            # Extract the coordinates from the prediction\n            x0, y0 = coords_pred[0].int().item(), coords_pred[1].int().item()\n            x1, y1 = coords_pred[2].int().item(), coords_pred[3].int().item()\n            img = cv2.rectangle(img, (x0, y0), (x1, y1), (0, 0, 0), 2)\n            \n            results.append(torch.tensor(img).unsqueeze(0))\n        \n        grid = torchvision.utils.make_grid(results, 2)\n        self.logger.experiment.add_image(name, grid, self.global_step)\n        \n    def configure_optimizers(self):\n        return [self.optimizer]","7de3571b":"# Create the model object\nmodel = CardiacDetectionModel()","ac89aed5":"checkpoint_callback = ModelCheckpoint(\n    monitor=\"Val Loss\",\n    save_top_k=10,\n    mode=\"min\"    \n)","b115c8de":"# Create the trainer\n# Change the gpus parameter to the number of available gpus in your computer. Use 0 for CPU training\n#trainer = pl.Trainer(logger=TensorBoardLogger(\".\/logs\"), log_every_n_steps=1, callbacks=checkpoint_callback, max_epochs=10)\n\ngpus = 1 #TODO\ntrainer = pl.Trainer(gpus=gpus, logger=TensorBoardLogger(\".\/logs\"), log_every_n_steps=1,\n                     callbacks=checkpoint_callback,\n                     max_epochs=100)","14dfa731":"trainer.fit(model, train_loader, val_loader)","a7990b2c":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches","0d6e8e5f":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.load_from_checkpoint(\"logs\/default\/version_0\/checkpoints\/epoch=99-step=4999.ckpt\")\nmodel.eval();\nmodel.to(device);","bcdbcf9d":"preds = []\nlabels =[]\n\nwith torch.no_grad():\n    for data, label in val_dataset:\n        data = data.to(device).float().unsqueeze(0)\n        pred = model(data)[0].cpu()\n        preds.append(pred)\n        labels.append(label)\n        \npreds=torch.stack(preds)\nlabels=torch.stack(labels)","c7b7ab0e":"preds","e9cc0eda":"labels","543312ee":"labels.shape","30df6866":"abs(preds-labels).mean(0) # --> 5\/224","52337951":"abs(preds-labels).mean(0).sum() \/ 4 \/ 224 * 100","30e8e325":"IDX = 50  # Feel free to inspect all validation samples by changing the index\nimg, label = val_dataset[IDX]\ncurrent_pred = preds[IDX]\n\nfig, axis = plt.subplots(1, 1)\naxis.imshow(img[0], cmap=\"bone\")\nheart = patches.Rectangle((current_pred[0], current_pred[1]), current_pred[2]-current_pred[0],\n                          current_pred[3]-current_pred[1], linewidth=1, edgecolor='r', facecolor='none')\naxis.add_patch(heart)\n\nprint(label)","a5e62054":"preds[50]","80ae677d":"### Model Creation\n\n4 outputs: Instead of predicting a binary label we need to estimate the location of the heart (xmin, ymin, xmax, ymax).\n\nLoss function: Mean Squared Error as we are dealing with continuous values.","1f3d75bd":"We use a similar preprocessing routine to the one used for the classification task.\n\nTo be able to distinguish between train and validation subjects, we store them in two lists and later save these lists."}}