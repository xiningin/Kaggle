{"cell_type":{"91153c55":"code","dc788a08":"code","e03edba4":"code","03db4033":"code","45cec323":"code","fe62ece4":"code","02c67825":"code","a6dfa429":"code","96c0433a":"code","a10b4c4e":"code","a1b4f65f":"code","0bf90ae5":"code","68c5b7b0":"code","e57636b0":"code","d9e87b42":"code","3fc1574a":"code","4ac486f6":"code","997d42d6":"markdown","4c26bcbe":"markdown","01b584ee":"markdown","ff0880be":"markdown","64e2fac6":"markdown","a53a9040":"markdown","f3fd760b":"markdown","7decb86b":"markdown","6f11390f":"markdown","648e54ea":"markdown","5c3436ec":"markdown","370466a2":"markdown"},"source":{"91153c55":"# First, you should install TorchUtils (clone and pip install: https:\/\/github.com\/seefun\/TorchUtils)","dc788a08":"import os\nimport cv2\nimport time\nimport math\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom torch.optim import Adam, AdamW\nfrom torch.nn.parameter import Parameter\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn import metrics\nimport urllib\nimport pickle\nimport torch.nn.functional as F\nimport seaborn as sns\nimport random\nimport sys\nimport gc\nimport shutil\nfrom tqdm.autonotebook import tqdm\nimport albumentations\nfrom albumentations import pytorch as AT\n\nimport scipy.special\nsigmoid = lambda x: scipy.special.expit(x)\nfrom scipy.special import softmax\n\nimport torch_utils as tu \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e03edba4":"SEED = 42\nbase_dir = '..\/input\/'\ntu.tools.seed_everything(SEED, deterministic=False)\ntu.tools.set_gpus('0') # choice gpu id if you have more than one GPU","03db4033":"EXP = 1\nwhile os.path.exists('..\/exp\/exp%d'%EXP):\n    EXP+=1\nos.makedirs('..\/exp\/exp%d'%EXP)","45cec323":"CLASSES = 176\nFOLD = 5\nBATCH_SIZE = 64\nACCUMULATE = 1\nLR = 3e-4\nEPOCH = 36\nDECAY_SCALE = 20.0\nMIXUP = 0 # 0 to 1","fe62ece4":"train_transform = albumentations.Compose([\n    albumentations.RandomRotate90(p=0.5),\n    albumentations.Transpose(p=0.5),\n    albumentations.Flip(p=0.5),\n    albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.0625, rotate_limit=45, border_mode=1, p=0.5),\n    tu.randAugment(),\n    albumentations.Normalize(),\n    AT.ToTensorV2(),\n    ])\n    \ntest_transform = albumentations.Compose([\n    albumentations.Normalize(),\n    AT.ToTensorV2(),\n    ])\n\n\nclass LeavesDataset(Dataset):\n    \n    def __init__(self, df, label_encoder, data_path='..\/input', transform = train_transform): \n        self.df = df \n        self.data_path = data_path\n        self.transform = transform\n        self.df.label = self.df.label.apply(lambda x: label_encoder[x])\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        img_path, label = self.df.image[idx], self.df.label[idx]\n        img_path = os.path.join(self.data_path, img_path)\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = self.transform(image = img)['image']\n        return img, label","02c67825":"train_df = pd.read_csv(os.path.join(base_dir, 'train.csv'))","a6dfa429":"train_df.head()","96c0433a":"# K Fold Split Train-Val dataset\nsfolder = StratifiedKFold(n_splits=FOLD,random_state=SEED,shuffle=True)\ntr_folds = []\nval_folds = []\nfor train_idx, val_idx in sfolder.split(train_df.image, train_df.label):\n    tr_folds.append(train_idx)\n    val_folds.append(val_idx)\n    print(len(train_idx), len(val_idx))","a10b4c4e":"from torch.optim.lr_scheduler import CosineAnnealingLR\nscaler = torch.cuda.amp.GradScaler() # for AMP training ","a1b4f65f":"def train_model(epoch, verbose=False):\n    model_conv.train()         \n    avg_loss = 0.\n    optimizer.zero_grad()\n    if verbose:\n        bar = tqdm(total=len(train_loader))\n    mixup_fn = tu.Mixup(prob=MIXUP, switch_prob=0.0, onehot=True, label_smoothing=0.05, num_classes=CLASSES)\n    for idx, (imgs, labels) in enumerate(train_loader):\n        imgs_train, labels_train = imgs.float().cuda(), labels.cuda()\n        if MIXUP:\n            imgs_train, labels_train = mixup_fn(imgs_train, labels_train)\n        with torch.cuda.amp.autocast():\n            output_train, _ = model_conv(imgs_train)\n            loss = criterion(output_train, labels_train)\n        scaler.scale(loss).backward()\n        if ((idx+1)%ACCUMULATE==0): # Gradient Accumulate\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            scheduler.step()\n        avg_loss += loss.item() \/ len(train_loader) \n        if verbose:\n            bar.update(1)\n    if verbose:\n        bar.close()\n    return avg_loss\n\ndef test_model():    \n    avg_val_loss = 0.\n    model_conv.eval()\n    y_true_val = np.zeros(len(valset))\n    y_pred_val = np.zeros((len(valset), CLASSES))\n    with torch.no_grad():\n        for idx, (imgs, labels) in enumerate(val_loader):\n            imgs_vaild, labels_vaild = imgs.float().cuda(), labels.cuda()\n            output_test, _ = model_conv(imgs_vaild)\n            avg_val_loss += (criterion_test(output_test, labels_vaild).item() \/ len(val_loader)) \n            a = labels_vaild.detach().cpu().numpy().astype(np.int)\n            b = softmax(output_test.detach().cpu().numpy(), axis=1)\n\n            y_true_val[idx*BATCH_SIZE:idx*BATCH_SIZE+b.shape[0]] = a\n            y_pred_val[idx*BATCH_SIZE:idx*BATCH_SIZE+b.shape[0]] = b\n            \n    metric_val = sum(np.argmax(y_pred_val, axis=1) == y_true_val) \/ len(y_true_val)\n    return avg_val_loss, metric_val","0bf90ae5":"def train(fold):\n    best_avg_loss = 100.0\n    best_acc = 0.0\n\n    avg_val_loss, avg_val_acc = test_model()\n    print('pretrain val loss %.4f precision %.4f'%(avg_val_loss, avg_val_acc))       \n\n    ### training\n    for epoch in range(EPOCH):   \n        print('lr:', optimizer.param_groups[0]['lr']) \n        np.random.seed(SEED+EPOCH*999)\n        start_time = time.time()\n        avg_loss = train_model(epoch)\n        avg_val_loss, avg_val_acc = test_model()\n        elapsed_time = time.time() - start_time \n        print('Epoch {}\/{} \\t train_loss={:.4f} \\t val_loss={:.4f} \\t val_precision={:.4f} \\t time={:.2f}s'.format(\n            epoch + 1, EPOCH, avg_loss, avg_val_loss, avg_val_acc, elapsed_time))\n\n        if avg_val_loss < best_avg_loss:\n            best_avg_loss = avg_val_loss\n\n        if avg_val_acc > best_acc:\n            best_acc = avg_val_acc\n            torch.save(model_conv.module.state_dict(), '..\/exp\/exp' + str(EXP) + '\/model-best' + str(fold) + '.pth')\n            print('model saved!')\n\n        print('=================================')   \n\n    print('best loss:', best_avg_loss)\n    print('best precision:', best_acc)\n    return best_avg_loss, best_acc","68c5b7b0":"log = open('..\/exp\/exp' + str(EXP) +'\/log.txt', 'w')\nlog.write('SEED%d\\n'%SEED)\ncv_losses = []\ncv_metrics = []\n\nfor fold in range(FOLD):\n    print('\\n ********** Fold %d **********\\n'%fold)\n    ###################### Dataset #######################\n    labels = train_df.label.unique()\n    label_encoder = {}\n    for idx, name in enumerate(labels):\n        label_encoder.update({name:idx})\n    \n    trainset = LeavesDataset(train_df.iloc[tr_folds[fold]].reset_index(), label_encoder, base_dir, train_transform)\n    train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, num_workers=16, shuffle=True, drop_last=True, worker_init_fn=tu.tools.worker_init_fn)\n    \n    valset = LeavesDataset(train_df.iloc[val_folds[fold]].reset_index(), label_encoder, base_dir, test_transform)\n    val_loader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n    \n    ####################### Model ########################\n    model_conv = tu.ImageModel(name='tf_efficientnetv2_l_in21ft1k', pretrained=True, feature=2048, classes=CLASSES)\n    model_conv.cuda()\n    model_conv = torch.nn.DataParallel(model_conv)\n\n    ###################### Optim ########################\n    optimizer = tu.RangerLars(model_conv.parameters(), lr=LR, weight_decay=2e-4)\n\n    if MIXUP:\n        criterion = tu.SoftTargetCrossEntropy()\n    else:\n        criterion = tu.LabelSmoothingCrossEntropy()\n        \n    criterion_test = nn.CrossEntropyLoss()\n\n    T = len(train_loader)\/\/ACCUMULATE * EPOCH # cycle\n    scheduler = CosineAnnealingLR(optimizer, T_max=T, eta_min=LR\/DECAY_SCALE)\n    \n    val_loss, val_acc = train(fold)\n    \n    cv_losses.append(val_loss)\n    cv_metrics.append(val_acc)\n    torch.cuda.empty_cache()\n\ncv_loss = sum(cv_losses) \/ FOLD\ncv_acc = sum(cv_metrics) \/ FOLD\nprint('CV loss:%.6f  CV precision:%.6f'%(cv_loss, cv_acc))\nlog.write('CV loss:%.6f  CV precision:%.6f\\n\\n'%(cv_loss, cv_acc))","e57636b0":"log.close()\ntu.tools.backup_folder('.', '..\/exp\/exp%d\/src'%EXP)  # backup code","d9e87b42":"class LeavesDataset_inference(Dataset):\n    \n    def __init__(self, df, data_path='..\/input', transform = test_transform): \n        self.df = df \n        self.data_path = data_path\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        img_path = self.df.image[idx]\n        img_path = os.path.join(self.data_path, img_path)\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = self.transform(image = img)['image']\n        return img\n\ntest_df = pd.read_csv(os.path.join(base_dir, 'test.csv'))\ntestset = LeavesDataset_inference(test_df, base_dir, tta_transform)\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)","3fc1574a":"TTA = 16\npred_list = []\n\nfor tta in range(TTA):\n    for fold in range(FOLD):\n        y_pred_val = np.zeros((len(testset), CLASSES))\n        model_conv = tu.ImageModel(name='tf_efficientnetv2_l_in21ft1k', pretrained=False, feature=2048, classes=CLASSES)\n        model_conv.cuda()\n        model_conv.load_state_dict(torch.load('..\/exp\/exp' + str(EXP) + '\/model-best' + str(fold) + '.pth'))\n        with torch.no_grad():\n            for idx, imgs in enumerate(test_loader):\n                imgs_test = imgs.float().cuda()\n                output_test, _ = model_conv(imgs_test)\n                b = softmax(output_test.detach().cpu().numpy(), axis=1)\n                y_pred_val[idx*BATCH_SIZE:idx*BATCH_SIZE+b.shape[0]] = b\n        pred_list.append(y_pred_val)\n        print('TTA %d: Fold %d'%(tta,fold))","4ac486f6":"# get submission\npred = sum(pred_list)\/len(pred_list)\nnp.save('..\/exp\/exp' + str(EXP) + '\/pred.npy', pred)\n\nlabel_decoder = {}\nfor k, v in label_encoder.items():\n    label_decoder[v] = k\n    \npred_label = np.argmax(pred, axis=1)\ntest_df['label'] = pred_label\ntest_df['label'] = test_df['label'].apply(lambda x: label_decoder[x])\n\ntest_df.to_csv('exp%d.csv'%EXP, index=False)","997d42d6":"\u4e3a\u4e86\u4fdd\u8bc1\u5b9e\u9a8c\u7684\u53ef\u590d\u73b0\u6027\uff0c\u6211\u4eec\u901a\u5e38\u9700\u8981\u56fa\u5b9aseed\uff0c\u5e76\u4f7f\u7528torch\u7684deterministic\u529f\u80fd","4c26bcbe":"## Training Loop\n\n\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff0c\u8282\u7ea6\u663e\u5b58\u6765\u83b7\u5f97\u66f4\u5927batch size\uff0c\u5e76\u8282\u7ea6\u8bad\u7ec3\u65f6\u95f4\uff0c\u635f\u5931\u8f83\u5c0f\uff0c\u751a\u81f3\u80fd\u56e0\u4e3a\u5927batch\u800c\u63d0\u5347\u6027\u80fd","01b584ee":"## Prepare Libs\n\u9996\u5148,\u5bfc\u5165\u4f9d\u8d56\u5e93","ff0880be":"## Dataset\n\n\u5b9a\u4e49\u6570\u636e\u96c6\u4ee5\u53ca\u589e\u5e7f\uff0c\u4f7f\u7528\u4e86RandAugment","64e2fac6":"## Inference","a53a9040":"\u6700\u540e\uff0c\u5355\u6a21\u578b\u53ef\u4ee5\u83b7\u5f97\u7684\u7ed3\u679c\u662f\uff0c0.98727 prvate LB | 0.98795 public LB","f3fd760b":"\u4f7f\u7528TTA\u6765\u83b7\u5f97\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u8be6\u89c1\u6539\u6bd4\u8d5b[\u8ba8\u8bba\u533a](https:\/\/www.kaggle.com\/c\/classify-leaves\/discussion\/245198)\n\nTTA\u4e00\u822c\u662f\u5fc5\u5b9a\u6709\u7528\u7684\uff0c\u4ee3\u4ef7\u662f\u66f4\u957f\u7684inference\u65f6\u95f4\uff0c\u5728\u6b64\u6b21\u6bd4\u8d5b\u4e2d\uff0c\u5404\u79cd\u6b63\u5219\u5316\u9632\u6b62\u8fc7\u62df\u5408\u7684\u65b9\u6cd5\u4e4b\u6240\u4ee5\u4e0dwork\uff0c\u5927\u6982\u7387\u662f\u56e0\u4e3a:\n1. \u6bd4\u8d5b\u6570\u636e\u96c6\u5b58\u5728\u5927\u91cfleak\uff0c\u8bad\u7ec3\u6d4b\u8bd5\u96c6\u5927\u91cf\u56fe\u7247\u91cd\u590d\u6216\u63a5\u8fd1\uff0c\u8fc7\u62df\u5408\u53cd\u800c\u80fd\u83b7\u5f97\u66f4\u597d\u7ed3\u679c\uff1b\n2. \u6570\u636e\u96c6\u5b58\u5728\u5f88\u591a\u566a\u58f0\u6837\u672c\uff0c\u8fc7\u62df\u5408\u8fd9\u4e9b\u9519\u8bef\u6807\u6ce8\u53cd\u800c\u80fd\u83b7\u5f97\u66f4\u9ad8\u7684LB\uff1b\u5373LB\u672c\u8eab\u5e76\u4e0d\u53ef\u9760\uff0c\u66f4\u9ad8\u7684LB\u4e0d\u4ee3\u8868\u771f\u6b63\u66f4\u9ad8\u7684\u6cdb\u5316\u6027\u80fd\uff1b","7decb86b":"\u81ea\u52a8\u5907\u4efd\u5b9e\u9a8c\uff0c\u4fdd\u8bc1\u8bd5\u9a8c\u8bb0\u5f55\u4e0d\u4e22\u5931","6f11390f":"\u7ecf\u8fc7\u4e24\u4e09\u5e74\u7684kaggle\u7ecf\u5386\uff0c\u6211\u628a\u6bd4\u8d5btricks\u6c89\u6dc0\u6210\u4e86\u4e00\u4e2a\u5e93[TorchUtils](https:\/\/github.com\/seefun\/TorchUtils)\uff0c\u4ecd\u5728\u66f4\u65b0\u4e2d\uff0c\u8fd9\u4e2a\u4ee3\u7801\u4e5f\u662f\u7528\u4e86\u8fd9\u4e2a\u5e93\u6765\u5feb\u901f\u6784\u5efa\u4e00\u4e2astrong [baseline](https:\/\/github.com\/seefun\/TorchUtils\/blob\/master\/examples\/kaggle_leaves_classification.ipynb).\n\n\u7531\u4e8ekaggle notebook\u8bad\u7ec3\u65f6\u95f4\u9650\u5236\uff0c\u65e0\u6cd5\u5728\u65f6\u9650\u5185\u5b8c\u6210\u8bad\u7ec3\uff0c\u6545\u9700\u8981\u672c\u5730\u5b89\u88c5\u4f9d\u8d56\u5e76\u8bad\u7ec3\u6d4b\u8bd5.","648e54ea":"1. \u4f7f\u7528imagenet-21k\u4e0a\u9884\u8bad\u7ec3\u7684efficientnetv2\u6a21\u578b\uff1ahttps:\/\/arxiv.org\/abs\/2104.00298\n2. mutli-dropout \n3. pooling\u65f6concat maxpooling\u4e0eavgpooling\n4. mixup \/ Label Smoothing\u4f5c\u4e3a\u6b63\u5219\n5. \u4f59\u5f26\u5b66\u4e60\u7387\u4e0b\u964d\n6. \u4f7f\u7528Ranger([RAdam](arxiv.org\/abs\/1908.03265)+[Lookahead](https:\/\/arxiv.org\/abs\/1907.08610)+[GC](https:\/\/arxiv.org\/abs\/2004.01461))\/ RangerLars(Ranger+Lars)\u4f18\u5316\u5668","5c3436ec":"\u5b9e\u9a8c\u7ed3\u675f\u540e\u81ea\u52a8\u5907\u4efd\u4ee3\u7801\u548c\u7ed3\u679c","370466a2":"## Param\n\u5b9a\u4e49\u53ef\u8c03\u53c2\u6570"}}