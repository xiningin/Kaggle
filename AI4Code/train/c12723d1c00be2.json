{"cell_type":{"ecafd2fa":"code","b170f7fe":"code","11443eb9":"code","8c7c8c39":"code","c9bea7c1":"code","2fb37fb9":"code","e0140710":"code","3212a30b":"code","adab80d5":"code","64840b75":"code","823afe99":"code","feeb0d7f":"code","4753ced5":"code","08320932":"code","7efd707e":"code","c605e910":"code","f152c800":"code","f9358c7a":"code","8a8d2fd5":"code","76ed0c02":"code","031d19a7":"code","8728b4e8":"code","808069d2":"code","5c7ccdd9":"code","b8387d47":"code","dc992fad":"code","d2612cb7":"code","417181a0":"code","0e5de25c":"code","f9fc937f":"code","4e398c46":"code","be84b22a":"code","a1310939":"code","d7a4d8a7":"code","4317cf5d":"code","64549f7e":"code","548937cc":"code","48c5c955":"code","e9ae585d":"code","426c3447":"code","ff7f5aee":"code","23b62c3c":"code","5d3af8c9":"code","f4528ec7":"code","20587496":"code","58ed1542":"code","8e8fe37b":"code","33d978be":"code","0d51c32c":"code","445453a3":"code","58f7d20b":"code","bbf2cb4f":"code","8e484ad1":"code","bf5e0ac9":"code","df5c45b3":"code","bff1f8e9":"code","96b84e0b":"code","1f8d0d7c":"code","98271a69":"code","760b83f2":"code","8a40bc58":"code","7bfabb9c":"code","98e95179":"code","264a6ef0":"code","3a79b660":"code","8ff960a3":"code","b21c2381":"code","2f0f3af6":"code","9e882031":"code","d486cb5f":"code","2268fb60":"code","155b9f79":"code","57b8f98b":"code","d504b800":"code","79ad0c63":"code","0bdd5d75":"code","99b85356":"code","b70ffd75":"code","05ad51f3":"code","08058899":"code","23ff6732":"code","fef5e506":"code","0ea6c166":"code","2b0998f3":"code","eadba06a":"code","39ca2747":"code","1d8bd433":"code","958b3d29":"code","4980f06f":"code","5946bf65":"code","a01ef159":"code","b05f17f6":"code","06f4677c":"code","18351da4":"code","404245a9":"code","0f3f797b":"code","58f41bab":"code","11fb9270":"code","7b4770b2":"code","9447da42":"markdown","b3349b96":"markdown","02efb7e5":"markdown","0039abf2":"markdown","26e42347":"markdown","fda8196f":"markdown","508a637d":"markdown","0355def4":"markdown","44a42231":"markdown","62a86005":"markdown","7487567a":"markdown","72ab4938":"markdown","4ae610ad":"markdown","8398f395":"markdown","35331ffa":"markdown","d8138514":"markdown","f5cf6484":"markdown","3b91d6cd":"markdown","2e5aa5ee":"markdown","cf6aa65d":"markdown","e4c0e299":"markdown","25c8229d":"markdown","1439f8c2":"markdown","ba877098":"markdown","57dca475":"markdown","e0a1d972":"markdown","8d20a75c":"markdown","89e3c8dd":"markdown","e396e4d7":"markdown","5566f035":"markdown","9bb7333e":"markdown","23bab5e5":"markdown","8509f308":"markdown","baa2062a":"markdown","d6e60f16":"markdown","09593cc1":"markdown","20bf71fc":"markdown","8b7aa4e2":"markdown","3424474a":"markdown","3675d9d5":"markdown","33b6aa28":"markdown","54027508":"markdown","9283c72c":"markdown","7996b7a6":"markdown","fa460358":"markdown","63316221":"markdown","05aa8ddb":"markdown","519824cf":"markdown","c33111ba":"markdown","1182b82b":"markdown","76fa5e83":"markdown","d8af550d":"markdown","34167e41":"markdown","b23e504a":"markdown","a55b5f83":"markdown","a37a3048":"markdown","3e446d27":"markdown","f027cd0d":"markdown","4b183d0f":"markdown","cb5c45d2":"markdown","ed3d525f":"markdown","ce20a5cb":"markdown","3b28bbb8":"markdown","4b89ffe0":"markdown","023525cb":"markdown","149a7b41":"markdown","ead88faa":"markdown","c2fd25b7":"markdown","66bc63f6":"markdown","2c8f8a04":"markdown","abdbf50c":"markdown","f4d31bad":"markdown","f251db7c":"markdown","486b9f69":"markdown","c780c8c1":"markdown","6d568974":"markdown","460b538f":"markdown","1b7437c8":"markdown","f8a9d3ee":"markdown","7bc76eb8":"markdown","99fc907a":"markdown","8fc2eb7f":"markdown","15760178":"markdown","59cf6593":"markdown","223a48cc":"markdown","e7c86f82":"markdown","31928090":"markdown","997a206b":"markdown","02c57b64":"markdown","45f57871":"markdown","506b0bd4":"markdown","bc376199":"markdown","a8dbf1e4":"markdown","2e0bb77b":"markdown","5b38cf85":"markdown","ee92717f":"markdown","1166120d":"markdown","e7cc32c8":"markdown","351c8810":"markdown","7bb5a83c":"markdown","299b8425":"markdown","2a0e05ae":"markdown","d09e20c4":"markdown","7677a5df":"markdown","39a4d950":"markdown","4b6f9570":"markdown","9c21123b":"markdown","1239f0d6":"markdown","aed1ac86":"markdown","267bbad3":"markdown","f4671a19":"markdown","b663355e":"markdown","cfa6f7a9":"markdown","600c160d":"markdown","191fba50":"markdown","9102ef88":"markdown","ad49cb80":"markdown","a94be8b2":"markdown","4432b88a":"markdown","9a3b130f":"markdown","310d97e8":"markdown","b930cfd9":"markdown","5b1e1eaa":"markdown","50f4a695":"markdown","b1e92229":"markdown","06687e50":"markdown","c3972496":"markdown","3e76fbd9":"markdown","e83ebd35":"markdown","b663a3ca":"markdown","e7bd5c8e":"markdown","e12b8d1c":"markdown","4c929e5f":"markdown","98b534de":"markdown","521bca26":"markdown","94a578a8":"markdown","bb39c7bd":"markdown","e92826e0":"markdown","7a3e422e":"markdown","31733c53":"markdown","59b78d01":"markdown","e90b0d15":"markdown"},"source":{"ecafd2fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sqlite3\nimport datetime\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.manifold import TSNE\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b170f7fe":"file_path = '\/kaggle\/input\/on-time-performance\/trainView.csv'\ntrainView_df = pd.read_csv(file_path)\ntrainView_df.head()","11443eb9":"file_path = '\/kaggle\/input\/on-time-performance\/otp.csv'\notp_df = pd.read_csv(file_path)\notp_df.head()","8c7c8c39":"con = sqlite3.connect('\/kaggle\/input\/on-time-performance\/database.sqlite') \ntables_df = pd.read_sql_query('SELECT name FROM sqlite_master WHERE type=\"table\"', con)\ntables_df","c9bea7c1":"otp_sqlite_df = pd.read_sql_query('SELECT * FROM otp', con)\notp_sqlite_df.head()","2fb37fb9":"otp_df.info()","e0140710":"otp_sqlite_df.info()","3212a30b":"print(otp_df.describe())\nprint(otp_sqlite_df.describe())","adab80d5":"otp_df.info()","64840b75":"otp_df['date'] = pd.to_datetime(otp_df['date'])\notp_df['timeStamp'] = pd.to_datetime(otp_df['timeStamp'])","823afe99":"otp_df['timeStamp'] = otp_df['timeStamp'].apply(lambda x: x.replace(second=0))","feeb0d7f":"def status2min(x):\n  x_ls = x.split(' ')\n  if x == 'On Time':\n    return 0\n  elif x_ls[1] == 'min':\n    return int(x_ls[0])\n  else:\n    raise ValueError\n\notp_df['status'] = otp_df['status'].apply(status2min)","4753ced5":"otp_df['status_dt'] = otp_df['status'].apply(lambda x: datetime.timedelta(minutes=x))","08320932":"otp_df.info()","7efd707e":"otp_df.head()","c605e910":"trainView_df.info()","f152c800":"trainView_df['date'] = pd.to_datetime(trainView_df['date'])\ntrainView_df['timeStamp0'] = pd.to_datetime(trainView_df['timeStamp0'])\ntrainView_df['timeStamp1'] = pd.to_datetime(trainView_df['timeStamp1'])","f9358c7a":"trainView_df['timeStamp0'] = trainView_df['timeStamp0'].apply(lambda x: x.replace(second=0))\ntrainView_df['timeStamp1'] = trainView_df['timeStamp1'].apply(lambda x: x.replace(second=0))","8a8d2fd5":"def status2int(x):\n  if x == 'None':\n    return 0\n  else:\n    return int(x)\n\ntrainView_df['status'] = trainView_df['status'].apply(status2int)","76ed0c02":"trainView_df['status_dt'] = trainView_df['status'].apply(lambda x: datetime.timedelta(minutes=x))","031d19a7":"trainView_df.info()","8728b4e8":"trainView_df.head()","808069d2":"test_df = otp_df[otp_df['train_id'] == '598'].copy()\ntest_df = test_df.groupby('date')['train_id'].count().reset_index()\n\nfig, ax = plt.subplots(figsize=[10,5])\nax.bar(test_df['date'], test_df['train_id'])\nax.set_xlabel('Date')\nax.set_ylabel('Show-up times')\nax.set_title('How many times the train id 598 showed up in each day?')\nplt.show()","5c7ccdd9":"test_df = otp_df[(otp_df['date'] == '2016-03-24') & (otp_df['train_id'] == '598')].copy()\ntest_df['hour'] = test_df['timeStamp'].dt.hour\ntest_df = test_df.groupby('hour')['train_id'].count().reset_index()\n\nfig, ax = plt.subplots(figsize=[10,5])\nax.bar(test_df['hour'], test_df['train_id'])\nax.set_xlabel('Hour')\nax.set_ylabel('Show-up times')\nax.set_title('How many times the train id 598 showed up in each hour?')\nplt.show()","b8387d47":"test_df = trainView_df.copy().drop_duplicates(subset=['train_id', 'date'])\ntest_df = test_df.groupby('date')['train_id'].count()\n\nfig, ax = plt.subplots(figsize=[10,5])\nax.plot(test_df)\nax.set_xlabel('Date')\nax.set_ylabel('Num of trains')\nax.set_title('How many trains are running every day?')\nplt.show()","dc992fad":"test_df = trainView_df.copy().drop_duplicates(subset=['train_id', 'date'])\ntest_df = test_df.groupby('date')['train_id'].count().reset_index()\ntest_df['month'] = test_df['date'].dt.month\ntest_df = test_df[['month', 'train_id']].groupby('month').agg(np.mean).reset_index()\n\nfig, ax = plt.subplots(figsize=[7,5])\nax.bar(test_df['month'], test_df['train_id'])\nax.set_xlabel('Month')\nax.set_ylabel('Number of trains')\nax.set_title('Average train numbers running every day in each month')\nplt.show()","d2612cb7":"test_df = trainView_df.copy().drop_duplicates(subset=['train_id', 'date'])\ntest_df = test_df.groupby('date')['train_id'].count().reset_index()\ntest_df['DOW'] = test_df['date'].dt.dayofweek + 1\ntest_df = test_df.groupby('DOW')['train_id'].agg(np.mean).reset_index()\ntest_df\n\nfig, ax = plt.subplots(figsize=[7,5])\nsns.barplot(x='DOW', y='train_id', data=test_df, palette=\"Blues_d\")\nax.set_xlabel('Day of Week')\nax.set_ylabel('Average number of trains')\nax.set_title('Average train numbers running each day of week')\nplt.show()","417181a0":"test_df = trainView_df.copy()\ntest_df['hour'] = test_df['timeStamp0'].dt.hour\ntest_df.drop_duplicates(subset=['train_id', 'date', 'hour'], inplace=True)\ntest_df = test_df.groupby(['date','hour'])['train_id'].count().reset_index()\ntest_df = test_df.groupby('hour').agg(np.mean).reset_index()\n\nfig, ax = plt.subplots(figsize=[10,5])\nsns.barplot(x='hour', y='train_id', data=test_df, palette=\"Blues_d\")\nax.set_xlabel('Hour')\nax.set_ylabel('Average number of trains')\nax.set_title('Average train numbers running each hour')\nplt.show()","0e5de25c":"test_df = trainView_df.copy()\ntest_df['service'] = test_df['service'].str.upper()\ntest_df = test_df.groupby('service')['train_id'].count()\ntest_df = test_df.sort_values(ascending=False).head(20).reset_index()\n\nfig, ax = plt.subplots(figsize=[5,8])\nsns.barplot(y='service', x='train_id', data=test_df, palette=\"Blues_d\")\nax.set_xlabel('Count (log scale)')\nax.set_ylabel('Service type')\nax.set_title('Top 10 frequent service type')\nax.set_xscale('log')\nplt.show()\n\n# release the RAM storing test_df\ntest_df = []","f9fc937f":"columns_to_drop = ['lon', 'lat', 'track_change', 'track',\n                   'service', 'timeStamp1', 'seconds']\n\ntrainView_df = trainView_df.drop(columns=columns_to_drop)","4e398c46":"trainView_df = trainView_df[trainView_df['status'] < 999]","be84b22a":"trainView_df['status'].describe()","a1310939":"fig, ax = plt.subplots(figsize=[10,5])\nsns.distplot(trainView_df['status'])\nax.set_xlabel('Delay time (min)')\nax.set_ylabel('Density')\nax.set_title('Distribution of delay time')\nplt.show()","d7a4d8a7":"otp_df = otp_df[otp_df['next_station'] != 'None']\notp_df = otp_df[otp_df['status'] < 999]","4317cf5d":"schedule_df = otp_df.copy()\n\nchange_col_name = {'next_station': 'arrival_station'}\nschedule_df = schedule_df.rename(columns=change_col_name)\n\nschedule_df['arrival_time'] = schedule_df['timeStamp'] - schedule_df['status_dt']\nschedule_df['arrival_hour'] = schedule_df['arrival_time'].dt.hour\nschedule_df['arrival_date'] = schedule_df['arrival_time'].apply(lambda x: x.date())\n\ncol_to_keep = ['train_id', 'direction', 'origin', 'arrival_station', 'date',\n               'arrival_date', 'arrival_hour']\nschedule_df = schedule_df[col_to_keep]\n\nschedule_df.head()","64549f7e":"schedule_df[schedule_df['train_id'] == '778'].head(10)","548937cc":"otp_df['hour'] = otp_df['timeStamp'].dt.hour","48c5c955":"trainView_df['hour'] = trainView_df['timeStamp0'].dt.hour","e9ae585d":"otp_direction_label_df = otp_df.copy()\ncol_to_keep = ['train_id', 'direction', 'next_station', 'date', 'hour']\notp_direction_label_df = otp_direction_label_df[col_to_keep]\notp_direction_label_df = otp_direction_label_df.drop_duplicates()\notp_direction_label_df.head()","426c3447":"trainView_dir_df = trainView_df.merge(otp_direction_label_df, indicator=True, \n                                      left_on=['train_id', 'next_station', 'date', 'hour'],\n                                      right_on=['train_id', 'next_station', 'date', 'hour'])\ntrainView_dir_df.head()","ff7f5aee":"print(trainView_df.shape)\nprint(trainView_dir_df.shape)","23b62c3c":"col_to_keep = ['train_id', 'direction', 'status', 'next_station', \n               'date', 'timeStamp0', 'hour']\ntrainView_dir_df = trainView_dir_df[col_to_keep]\ntrainView_dir_df = trainView_dir_df.drop_duplicates()\nprint(trainView_dir_df.shape)\ntrainView_dir_df.head()","5d3af8c9":"change_col_name = {'timeStamp0': 'timeStamp'}\ntrainView_dir_df = trainView_dir_df.rename(columns=change_col_name)\ntrainView_dir_df.head()","f4528ec7":"otp_combine_df = otp_df.copy()\ncol_to_keep = ['train_id', 'direction', 'status', 'next_station', \n               'date', 'timeStamp', 'hour']\notp_combine_df = otp_combine_df[col_to_keep]\notp_combine_df = otp_combine_df.drop_duplicates()\notp_combine_df.head()","20587496":"combine_df = pd.concat([trainView_dir_df, otp_combine_df]).sort_values('timeStamp')\nprint(combine_df.shape)\ncombine_df = combine_df.drop_duplicates()\nprint(combine_df.shape)\ncombine_df.head()","58ed1542":"station_hour_count_df = schedule_df[['arrival_station', 'direction', 'arrival_date', 'arrival_hour', 'train_id']].copy()\nstation_hour_count_df = station_hour_count_df.drop_duplicates()\nstation_hour_count_df = station_hour_count_df.groupby(['arrival_station', 'direction', 'arrival_date', 'arrival_hour']).count().reset_index()\nstation_hour_count_df = station_hour_count_df.rename(columns={'train_id': 'num_train'})\nstation_hour_count_df.head()","8e8fe37b":"station_day_count_df = schedule_df[['arrival_station', 'direction', 'arrival_date', 'train_id']].copy()\nstation_day_count_df = station_day_count_df.drop_duplicates()\nstation_day_count_df = station_day_count_df.groupby(['arrival_station', 'direction', 'arrival_date']).count().reset_index()\nstation_day_count_df = station_day_count_df.rename(columns={'train_id': 'num_train'})\nstation_day_count_df.head()","33d978be":"sys_day_count_df = schedule_df[['direction', 'arrival_date', 'train_id']].copy()\nsys_day_count_df = sys_day_count_df.drop_duplicates()\nsys_day_count_df = sys_day_count_df.groupby(['arrival_date'])['train_id'].count().reset_index()\nsys_day_count_df = sys_day_count_df.rename(columns={'train_id': 'num_train'})\nsys_day_count_df.head()","0d51c32c":"sys_hour_count_df = schedule_df[['direction', 'arrival_date', 'train_id', 'arrival_hour']].copy()\nsys_hour_count_df = sys_hour_count_df.drop_duplicates()\nsys_hour_count_df = sys_hour_count_df.groupby(['arrival_date', 'arrival_hour'])['train_id'].count().reset_index()\nsys_hour_count_df = sys_hour_count_df.rename(columns={'train_id': 'num_train'})\nsys_hour_count_df.head()","445453a3":"combine_df = combine_df.sort_values('timeStamp')\ncombine_df = combine_df.reset_index().rename(columns={'index': 'orig_index'})\ncombine_df = combine_df.reset_index().rename(columns={'index': 'time_sequence'})\ncombine_df.head()","58f7d20b":"last_df = combine_df[['train_id', 'direction', 'time_sequence']]\nlast_df['last_time_sequence'] = last_df['time_sequence']\nlast_df = last_df.groupby(['train_id', 'direction', 'time_sequence']).sum().rolling(2).min().reset_index()\nlast_df = last_df[last_df['last_time_sequence'] != last_df['time_sequence']].dropna()[['time_sequence', 'last_time_sequence']]\nlast_df.head()","bbf2cb4f":"last_df = last_df.merge(combine_df, how='left', left_on='last_time_sequence',\n                        right_on='time_sequence')\ncol_to_keep = ['time_sequence_x', 'train_id', 'direction', 'status', \n               'next_station', 'timeStamp', 'hour']\nlast_df = last_df[col_to_keep]\nlast_df.head()","8e484ad1":"change_col_name = {'time_sequence_x': 'time_sequence', 'train_id': 'last_train_id', \n                   'direction': 'last_direction', 'status': 'last_status', \n                   'next_station': 'last_next_station', 'timeStamp': 'last_timeStamp',\n                   'hour':'last_hour'}\nlast_df = last_df.rename(columns=change_col_name)\nlast_df = last_df.dropna()\nlast_df.head()","bf5e0ac9":"combine_last_df = combine_df.merge(last_df, on=['time_sequence']).sort_values('timeStamp')\ncombine_last_df.head()","df5c45b3":"col_to_drop = ['last_train_id', 'last_direction', 'last_next_station', 'last_hour']\ncol = []\nfor i in combine_last_df.columns:\n  if i not in col_to_drop:\n    col.append(i)\n\ncombine_last_df = combine_last_df[col]\ncombine_last_df.head()","bff1f8e9":"combine_last_df['delta_T'] = combine_last_df['timeStamp'] - combine_last_df['last_timeStamp']\ncombine_last_df.sort_values('delta_T', ascending=False).head()","96b84e0b":"fig, ax = plt.subplots(figsize=[5, 5])\nsns.distplot(combine_last_df['delta_T'].dt.total_seconds())\nax.set_xlabel('Time difference (sec)')\nax.set_ylabel('Density')\nax.set_title('Distribution of time difference')\nplt.show()","1f8d0d7c":"combine_last_df = combine_last_df[combine_last_df['delta_T'] < datetime.timedelta(minutes=90)]\ncombine_last_df.head()","98271a69":"fig, ax = plt.subplots(figsize=[5, 5])\nsns.distplot(combine_last_df['delta_T'].dt.total_seconds())\nax.set_xlabel('Time difference (sec)')\nax.set_ylabel('Density')\nax.set_title('Distribution of time difference')\nplt.show()","760b83f2":"col_to_drop = ['last_timeStamp']\ncol = []\nfor i in combine_last_df.columns:\n  if i not in col_to_drop:\n    col.append(i)\n\ncombine_last_df = combine_last_df[col]\ncombine_last_df.head()","8a40bc58":"combine_last_df['delta_T_int'] = combine_last_df['delta_T'].dt.total_seconds().astype(int)\/60","7bfabb9c":"combine_last_df[combine_last_df['train_id'] == '778']","98e95179":"combine_last_df[combine_last_df['date'] == '2016-10-01']","264a6ef0":"avg_delay_df = combine_last_df.copy()\navg_delay_df = avg_delay_df.drop(columns=['time_sequence', 'delta_T', 'delta_T_int', 'last_status', 'timeStamp', 'orig_index'])\nstation_delay_df = avg_delay_df.groupby(['direction', 'next_station', 'date', 'hour', 'train_id'])['status'].agg(['mean']).reset_index()\nstation_delay_df.head()","3a79b660":"station_delay_df = station_delay_df.groupby(['direction', 'next_station', 'date', 'hour'])['mean'].agg(['mean']).reset_index()\nstation_delay_df.head()","8ff960a3":"def combineTime(x):\n  y = datetime.datetime.combine(x[0].date(), datetime.time(x[1],0))\n  return y\n\nstation_delay_df['timeStamp'] = station_delay_df[['date', 'hour']].apply(lambda x: combineTime(x), axis=1)\nstation_delay_df.head()","b21c2381":"station_delay_df = station_delay_df.rename(columns={'mean': 'avg_delay'})\nstation_delay_df = station_delay_df[['direction', 'next_station', 'timeStamp', 'avg_delay']]\nstation_delay_df.head()","2f0f3af6":"sys_delay_df = avg_delay_df.groupby(['date', 'hour', 'train_id'])['status'].agg(['mean']).reset_index()\nsys_delay_df.head()","9e882031":"sys_delay_df = sys_delay_df.groupby(['date', 'hour'])['mean'].agg(['mean']).reset_index()\nsys_delay_df.head()","d486cb5f":"def combineTime(x):\n  y = datetime.datetime.combine(x[0].date(), datetime.time(x[1],0))\n  return y\n\nsys_delay_df['timeStamp'] = sys_delay_df[['date', 'hour']].apply(lambda x: combineTime(x), axis=1)\nsys_delay_df.head()","2268fb60":"sys_delay_df = sys_delay_df.rename(columns={'mean': 'avg_delay'})\nsys_delay_df = sys_delay_df[['timeStamp', 'avg_delay']]\nsys_delay_df.head()","155b9f79":"feature_df = combine_last_df.copy()\nfeature_df = feature_df.drop(columns=['time_sequence', 'orig_index', 'delta_T'])\nfeature_df = feature_df.rename(columns={'delta_T_int': 'delta_T'})\nprint(feature_df.shape)\nfeature_df.head()","57b8f98b":"station_day_count_df = station_day_count_df.rename(columns={'num_train': 'num_station_day',\n                                                            'arrival_station': 'next_station',\n                                                            'arrival_date': 'date'})\nstation_day_count_df['date'] = pd.to_datetime(station_day_count_df['date'])\nstation_day_count_df.head()","d504b800":"feature_df = feature_df.merge(station_day_count_df, on=['next_station', 'direction', 'date'])\nprint(feature_df.shape)\nfeature_df.head()","79ad0c63":"feature_df = feature_df.rename(columns={'num_station_day': 'num_station_day_same'})\nfeature_df.head()","0bdd5d75":"def op_dir(x):\n  if x == 'N':\n    return 'S'\n  else:\n    return 'N'\n\nfeature_df['opp_dir'] = feature_df['direction'].apply(op_dir)\nfeature_df.head()","99b85356":"left_key = ['next_station', 'opp_dir', 'date']\nright_key = ['next_station', 'direction', 'date']\nfeature_df = feature_df.merge(station_day_count_df, left_on=left_key, right_on=right_key)\nfeature_df = feature_df.drop(columns='direction_y')\nfeature_df = feature_df.rename(columns={'num_station_day': 'num_station_day_opp',\n                                        'direction_x': 'direction'})\nprint(feature_df.shape)\nfeature_df.head()","b70ffd75":"change_col_name = {'arrival_station': 'next_station',\n                   'arrival_date': 'date',\n                   'arrival_hour': 'hour',\n                   'num_train': 'num_station_hour'}\nstation_hour_count_df = station_hour_count_df.rename(columns=change_col_name)\n\nstation_hour_count_df['date'] = pd.to_datetime(station_hour_count_df['date'])\n\nstation_hour_count_df.head()","05ad51f3":"feature_df = feature_df.merge(station_hour_count_df, on=['next_station', 'direction', 'date', 'hour'])\nprint(feature_df.shape)\nfeature_df.head()","08058899":"feature_df = feature_df.rename(columns={'num_station_hour': 'num_station_hour_same'})\nfeature_df.head()","23ff6732":"left_key = ['next_station', 'opp_dir', 'date', 'hour']\nright_key = ['next_station', 'direction', 'date', 'hour']\nfeature_df = feature_df.merge(station_hour_count_df, left_on=left_key, right_on=right_key)\nprint(feature_df.shape)\nfeature_df.head()","fef5e506":"feature_df = feature_df.drop(columns='direction_y')\nfeature_df = feature_df.rename(columns={'direction_x': 'direction'})\nfeature_df = feature_df.rename(columns={'num_station_hour': 'num_station_hour_opp'})\nfeature_df.head()","0ea6c166":"sys_day_count_df = sys_day_count_df.rename(columns={'arrival_date': 'date',\n                                                    'num_train': 'num_sys_day'})\nsys_day_count_df['date'] = pd.to_datetime(sys_day_count_df['date'])\nprint(sys_day_count_df.shape)\nprint(sys_day_count_df.drop_duplicates().shape)\nsys_day_count_df.head()","2b0998f3":"feature_df = feature_df.merge(sys_day_count_df, on=['date'])\nprint(feature_df.shape)\nfeature_df.head()","eadba06a":"change_col_name = {'arrival_date': 'date',\n                   'arrival_hour': 'hour',\n                   'num_train': 'num_sys_hour'}\nsys_hour_count_df = sys_hour_count_df.rename(columns=change_col_name)\n\nsys_hour_count_df['date'] = pd.to_datetime(sys_hour_count_df['date'])\n\nsys_hour_count_df.head()","39ca2747":"feature_df = feature_df.merge(sys_hour_count_df, on=['date', 'hour'])\nprint(feature_df.shape)\nfeature_df.head()","1d8bd433":"change_col_name = {'timeStamp': 'last_hour',\n                   'avg_delay': 'avg_station_same'}\nstation_delay_df = station_delay_df.rename(columns=change_col_name)\nstation_delay_df.head()","958b3d29":"def last_hour(x):\n  pure_hour = x.replace(minute=0)\n  last_hour = pure_hour - datetime.timedelta(hours=1)\n  return last_hour\n\nfeature_df['last_hour'] = feature_df['timeStamp'].apply(last_hour)\nfeature_df.head()","4980f06f":"feature_df = feature_df.merge(station_delay_df, on=['direction', 'next_station',\n                                                    'last_hour'])\nprint(feature_df.shape)\nfeature_df.head()","5946bf65":"change_col_name = {'avg_station_same': 'avg_station_opp'}\nstation_delay_df = station_delay_df.rename(columns=change_col_name)\nstation_delay_df.head()","a01ef159":"left_key = ['opp_dir', 'next_station', 'last_hour']\nright_key = ['direction', 'next_station', 'last_hour']\nfeature_df = feature_df.merge(station_delay_df, left_on=left_key, right_on=right_key)\nprint(feature_df.shape)\nfeature_df.head()","b05f17f6":"feature_df = feature_df.drop(columns=['direction_y'])\nfeature_df = feature_df.rename(columns={'direction_x': 'direction'})\nfeature_df.head()","06f4677c":"change_col_name = {'timeStamp': 'last_hour',\n                   'avg_delay': 'avg_sys'}\nsys_delay_df = sys_delay_df.rename(columns=change_col_name)\nsys_delay_df.head()","18351da4":"feature_df = feature_df.merge(sys_delay_df, on='last_hour')\nprint(feature_df.shape)\nfeature_df.head()","404245a9":"feature_df['dow'] = feature_df['date'].dt.dayofweek + 1\nfeature_df['month'] = feature_df['date'].dt.month\nfeature_df.head()","0f3f797b":"col_to_drop = ['train_id', 'date', 'timeStamp', 'opp_dir', 'last_hour', 'next_station']\nfeature_df = feature_df.drop(columns=col_to_drop)\nfeature_df.head()","58f41bab":"X = pd.get_dummies(feature_df, columns=['dow', 'month', 'hour', 'direction']).copy()\nX = X.drop(columns='status')\nprint(X.shape)\nX.head()","11fb9270":"y = feature_df['status'].copy()\ny.head()","7b4770b2":"X.to_csv('X.csv')\ny.to_csv('y.csv')","9447da42":"For each station, each direction, and each specific hour, calculate how many trains arrive\/leave.","b3349b96":"Print out the info and first 5 rows for final check.","02efb7e5":"Perform merge on 4 key columns and inspect the shape of feature matrix.","0039abf2":"Calculate the average delay time of each train, each date and hour.","26e42347":"Based on otp_df, create a schedule dataframe called schedule_df:\n\n* Initialize \n* Change name of columns accordingly\n* Create arrival_time column using (timeStamp - delay time)\n* Extract date and hour from arrival_time\n* Keep necessary columns\n* Print out first 5 rows and check","fda8196f":"Merge last status with feature matrix. Sort by time stamp and print out first 5 rows.","508a637d":"Clean trainView_df by dropping unnecessary columns.","0355def4":"Without changing any format, first print out the info of otp_df imported from otp.csv file.","44a42231":"## 3.1 Is train_id unique?","62a86005":"Perform merge on 4 key columns and inspect the shape of feature matrix.","7487567a":"### 4.2.2 Merge with station_day_count_df: same direction","72ab4938":"Prepare sys_day_count_df by modifying column names and type.","4ae610ad":"According to the above results, trainView_df has 3,601,656 instances and each comes with 14 columns.\n\n1.   train_id\n2.   status\n4.   next_station\n1.   service\n2.   dest\n1.   lon\n2.   lat\n3.   source\n1.   track_change\n2.   track\n1.   date\n1.   timeStamp0 (first timeStamp at coordinates)\n2.   timeStamp1 (last timeStamp at coordinates)\n2.   secondes (duration at coordinates)","8398f395":"There are two dataframes in total that will be used for my final project. One is the otp_df, and the other is trainView_df.","35331ffa":"Trains suspended are labeled with 999 in the status column. Since suspension is usually due to mechanical problems, I will no longer consider trains suspended.","d8138514":"Save outputs","f5cf6484":"Prepare station_delay_df by modifing column names.","3b91d6cd":"What does \"service\" column have?","2e5aa5ee":"Prepare keys: hour.","cf6aa65d":"### 4.2.1 Initialize feature matrix","e4c0e299":"### 4.2.12 Clean feature matrix and get dummies","25c8229d":"Replot time difference distribution and it makes sense.","1439f8c2":"The idea here is that I want to feed the machine learn algorithm with as much information as I have. However, when giving out prediction on a real-time manner, one instance should not see any information that happened after it. Therefore, I create a schedule dataframe and assume that all instances have access to it and know how crowded is the overall system as well as how crowded is each specific train station.","ba877098":"Create time stamp by combine date and hour.","57dca475":"Plot how many trains with \"598\" as train_id running each hour on 2016-03-24 from otp_df.","e0a1d972":"Then, without changing any format, print out the info of otp_sqlite_df imported from data.sqlite file.","8d20a75c":"### 2.3.2 GPS train dataframe (trainView_df)","89e3c8dd":"Verify the schedule by picking up a random example.","e396e4d7":"## 3.2 Does the number of train running in the system related to the Month\/Day of week\/Hour?","5566f035":"Print out the info and first 5 rows for final check.","9bb7333e":"Clearly, the above plot shows that the total number of trains running each day depends on Month and Day of week.","23bab5e5":"## 2.1 Introduction","8509f308":"Rename columns and select necessary infomation.","baa2062a":"Further calculate the average delay time of the system in each specific hour.","d6e60f16":"For example, randomly pick up one train_id of \"598\" from otp_df and plot how many trains with \"598\" as train_id running every day.","09593cc1":"Combine two dataframes vertically and drop duplicates. Print out shapes before an after, as well as first 5 rows.","20bf71fc":"### 2.3.1 On-time performace dataframe (otp_df)","8b7aa4e2":"Perform merge on three key columns. Inspect the feature matrix shape after merge.","3424474a":"Because the scale of the first plot is large, in order to know if there is any variance of train number across each hour, I will plot average train numbers each hour.","3675d9d5":"Prepare otp dataframe by selecting necessary columns and dropping duplicates. Print out first 5 rows and check.","33b6aa28":"Plot the total number of trains running each day using data from trainView_df.","54027508":"### 4.2.5 Merge with station_hour_count_df: opposite direction","9283c72c":"Since the longest run for a SEPTA train is less than 2 hours, the plot above shows that there are unless two trains using the same train_id running in a single day. Therefore, the train_id cannot be used as the unique key to identify each train in the system.","7996b7a6":"For each station, each direction, and each day, calculate how many trains arrive\/leave.","fa460358":"One table called otp is found from the database sqlite file. Load the otp table into pandas. Display the first 5 rows and check if the loading is Okay.","63316221":"Since direction in trainView_df is missing, first join directions onto trainView_df. Since the train_id is not unique, need more keys to make sure that mismatch will not happen.\n\nkeys:\n* train_id\n* date\n* hour\n* next_station","05aa8ddb":"Create a opp_dir column in feature matrix.","519824cf":"Create a new column called \"status_dt\" to store delay time in timedelta format.","c33111ba":"## 4.2 Build feature matrix","1182b82b":"Prepare station_day_count_df by modifying the name and data type accordingly.","76fa5e83":"Create a sliding window with width of 2, take the lastest timestamp, create a new column with values shifted by 1. Print out first 5 rows and check.","d8af550d":"Finally, verify the results.","34167e41":"Initialize feature matrix based on combine_df, drop unnecessary columns, and change column names accordingly. Print out the inital shape of feature matrix and first 5 rows.","b23e504a":"Have a closer look at the distribution of dalay time in trainView_df and plot it out.","a55b5f83":"Rename columns accordingly and select necessary info.","a37a3048":"## 2.2 Choose which dataframes to use","3e446d27":"Rename columns accordingly and drop all rows with NaN. Print out first 5 rows.","f027cd0d":"Create a self-defined function to convert current status to delay time in minutes (int type).","4b183d0f":"The \"service\" column labels trains with service type. Based on the list of service column printed out above, generally there are two types of service: Local and Express.\n\nFor each servie line, both Local and Express trains are running on the same route. However, Local trains stop at each train station while Express trains skip the stops where fewer amount of people are using.\n\nI decide to drop this column since the service type also reflects in \"next_station\" column.","cb5c45d2":"# Section 3: Exploratory Data Analysis","ed3d525f":"The above printouts clearly showed that both dataframes have same number of columns with exactly the same names.","ce20a5cb":"Sort combine_df based on time order, use reset_index function to create unique time_sequence id.","3b28bbb8":"### 4.2.11 Get day of week & month of year","4b89ffe0":"# Section 1: Loading packages and data","023525cb":"Create target dataframe.","149a7b41":"For each day, calculate how many trains in total are running in the system.","ead88faa":"### 4.1.1 Add direction to trainView_df by joining with the direction_df pull out from otp_df","c2fd25b7":"Drop unnecessary columns.","66bc63f6":"Caculate time difference between the last update. Sort by time difference in descending order. Print out first 5 rows.","2c8f8a04":"Merge with combine_df to get last delay info. Keep useful columns and print first 5 rows.","abdbf50c":"As one of cummuters using SEPTA train, one of the things I check most frequently in one day is the status of my train.\n\nHowever, with a premature prediction system, the delay time predicted by the system is uaually inaccurate. It's extremely normal that the actual arrival time will be 3-5 minutes later than the prediction. And under severe weather conditions, the scenarios could be even worse. I have experienced that the train delayed for more than 45 minutes while the system kept saying the delay time is around 10 minutes.\n\nTherefore, it's worth implementing big data techniques to develop a machine learning model to give out better real-time prediction.","f4d31bad":"### 4.2.8 Merge with station_delay_df: same direction","f251db7c":"Drop unnecessary columns and rename columns.","486b9f69":"Prepare station_delay_df by modifying column names.","c780c8c1":"Calculate the average delay time in each hour at each station, date, and train_id.","6d568974":"Further verify differences: Print out the describe into of each dataframe and compare.","460b538f":"Further calculate the average delay time in each hour at each station and date.","1b7437c8":"To be more specific, plot average train numbers running each day of week.","f8a9d3ee":"# Section 4: Build feature and target matrix","7bc76eb8":"Create a new column called \"status_dt\" to store delay time in timedelta format.","99fc907a":"Perform merge and inspect the shape of feature matrix and first 5 rows.","8fc2eb7f":"## 4.1 Prepare feature matrix","15760178":"First load the trainView.csv into pandas as a dataframe called trainView_df. Display first 5 rows and check if the loading is Okay.","59cf6593":"### 4.2.4 Merge with station_hour_count_df: same direction","223a48cc":"Merge on last_hour and inspect the shape of feature matrix.","e7c86f82":"Correct column names and make sure the names from two dataframes match. Print out the first 5 rows.","31928090":"### 4.1.2 Combine two dataframes","997a206b":"Merge on 3 keys and inspect matrix shape.","02c57b64":"First, take a look at trainView_df.","45f57871":"Create a self-defined function to convert current status to delay time in minutes (int type).","506b0bd4":"Create time stamp by combining date and time.","bc376199":"Convert all datetime data into correct format.","a8dbf1e4":"There are three files: Two csv files and one sql database file.","2e0bb77b":"### 4.1.3 Features based on schedule","5b38cf85":"Prepare sys_delay_df by modifying column names.","ee92717f":"## 1.2 Loading dataset","1166120d":"### 4.2.10 Merge with sys_delay_df","e7cc32c8":"## 3.4 Build train schedule based on otp_df","351c8810":"According to the above results, otp_df has 1,882,015 instances and each comes with 7 columns.\n\n1.   train_id\n2.   direction ('N' or 'S' direction is demarcated as either Northbound or Southbound)\n3.   origin\n4.   next_station (station stop, at timeStamp)\n1.   date\n2.   status ('On Time', '5 min', '10 min'. This is a status on train lateness. 999 is a suspended train)\n3.   timeStamp\n","7bb5a83c":"Get dummies for all categorical columns","299b8425":"The comparison above showed that the information contained by two dataframes are identical. Therefore, using either one for analysis should work. I will use otp.df for all following analysis","2a0e05ae":"Drop unnecessary columns and change column names accordingly.","d09e20c4":"Prepare station_hour_count_df by modifying column names and types.","7677a5df":"Create a column with time difference in minutes as int.","39a4d950":"First, let's look into otp_df","4b6f9570":"Plot the distribution of time difference. It doesn't make sense there are time differences greater than 2 hours (7200 s).","9c21123b":"# Section 2: Introduction and data description","1239f0d6":"Convert all datetime data into correct format.","aed1ac86":"Merge two dataframes on two keys. Inspect shape of feature matrix.","267bbad3":"### 4.1.4 Last delay status of the same train","f4671a19":"### 4.2.3 Merge with station_day_count_df: opposite direction","b663355e":"## 1.1 Downloading and importing packages","cfa6f7a9":"Since there are two dataframes with the same name, otp. The first thing I have done is to figure out if there are any differences between them.","600c160d":"### 4.2.7 Merge with sys_hour_count_df","191fba50":"Change the column names accordingly.","9102ef88":"To be more specific, plot average train numbers running every day per month.","ad49cb80":"Rename the columns accordingly.","a94be8b2":"Create otp_direction_label_df which has all 4 keys plus direction lable. Print out first 5 rows and check.","4432b88a":"Drop all unnecessary columns.","9a3b130f":"Compare the shape before and after merging. The size after merging is smaller and it makes sense.","310d97e8":"For each specific hour, calculate how many trains in total are running in the system.","b930cfd9":"Then load the otp.csv into pandas as a dataframe called otp_df. Display first 5 rows and check if the loading is Okay.","5b1e1eaa":"Last connect to database sqlite file and pull out tables from it.","50f4a695":"## 3.3 What's important in trainView_df","b1e92229":"Perform merge and inspect shape of feature matrix.","06687e50":"Merge trainView_df with direction label and save as trainView_dir_df. Print out first 5 rows and check.","c3972496":"First drop instances where next_station is None and the trains are suspended.","3e76fbd9":"### 4.2.9 Merge with station_delay_df: opposite direction","e83ebd35":"Create last_hour column in feature matrix by subtracting 1 hour from current timestamp.","b663a3ca":"Prepare sys_hour_count_df by modifying column names and data type.","e7bd5c8e":"Drop unnecessary columns and print out first 5 rows.","e12b8d1c":"Since all delay time is in minutes, drop seconds term in timestamp.","4c929e5f":"Since all delay time is in minutes, drop seconds term in both timestamp.","98b534de":"### 4.2.6 Merge with sys_day_count_df","521bca26":"Merge on 3 keys and inspect matrix shape.","94a578a8":"First prepare trainView_dir_df. Only keep the necessary columns for fianl analysis. Drop duplicates, and print out the shape and first 5 rows.","bb39c7bd":"Extract day of week and month from timestamp","e92826e0":"## 2.3 Data description and getting data into right format","7a3e422e":"From all plots above, the train numbers have strong relationship with Month\/Day of week\/Hour. Therefore, all of these will considered as features for later machine learning models.","31733c53":"The plot above shows that the train_id is not unique. It clearly shows that the same train_id can show up in multiple days.","59b78d01":"That's because mismatch was introduced when I shift the time sequence. Drop rows with time difference greater than 90 minutes. Print out first 5 rows.","e90b0d15":"### 4.1.5 The average delay time of the system\/each train station in the last hour"}}