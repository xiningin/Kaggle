{"cell_type":{"147a0a10":"code","9b5e6ca3":"code","f218ab91":"code","2d918cbf":"code","6690e7b2":"code","489afa60":"code","5a3f40b9":"code","dc9c6817":"code","8c039c8f":"code","8e3b10db":"code","b8890a36":"code","e86ece3e":"code","030287bb":"code","49c787cb":"code","cba69316":"code","8fccb8a2":"code","ed6a7b16":"code","e94d56e7":"code","4ea60322":"code","2837432b":"code","d04e59b1":"code","93f3651c":"code","59a12136":"code","4b4dfc87":"code","a0502568":"code","469d37ca":"code","6d22374e":"code","eccdc488":"code","8c4e31cb":"code","50956c3f":"code","63a79e5f":"code","a81e93e8":"code","ebb479fd":"code","eb024198":"code","9bef3442":"code","9c24d324":"code","8af919e1":"code","49e58923":"code","966f4438":"code","f3f11a42":"code","1de433d0":"code","b96c0405":"code","ddf48ea0":"code","a1f29fd8":"code","3d9080f4":"code","a4614be4":"code","9ce2802c":"code","5313e7e7":"code","270c8ba4":"code","f06d6983":"code","e2c587d5":"code","4dc3d118":"code","84415ae4":"code","65bf68ae":"code","84823221":"code","a26c781d":"code","cde3c0b7":"code","5802f7f0":"code","a566e526":"code","bc3a9736":"code","9e3a18de":"code","418df757":"code","98f105ba":"code","2adb9ffe":"code","cff213ad":"code","1a496624":"code","bddfecb6":"code","f953f971":"code","a5d24247":"code","62460d8b":"code","02e70071":"code","78cac99b":"code","5fded6a3":"code","07693f25":"code","917419b0":"code","a2975e83":"code","ab90dd85":"code","16e6647c":"code","b9997458":"code","a8038f39":"code","38e61c2e":"code","7a498cf1":"markdown","2256ec84":"markdown","e71c5f4b":"markdown","a1f08862":"markdown","d3d69cf3":"markdown","c28dd588":"markdown","f4864cb2":"markdown","692da7b0":"markdown","9b5be039":"markdown","772bb715":"markdown","d33aeeb8":"markdown"},"source":{"147a0a10":"!pip install git+https:\/\/github.com\/tensorflow\/examples.git","9b5e6ca3":"# GENERAL\n\nimport os\nimport os.path\nfrom pathlib import Path\nimport time\nimport pandas as pd\nimport numpy as np\nimport random\nimport time\nimport math\nimport glob\nimport cv2\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\n\n\n# I PACKAGES\n\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D,\\\nZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU, ReLU, Conv2DTranspose, Input\nfrom tensorflow.keras import models\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow_examples.models.pix2pix import pix2pix\n\n# WARNINGS\n\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)\n\n\nAUTO_MODEL_TUNE = tf.data.AUTOTUNE # if it is needed","f218ab91":"import pickle\nfrom tensorflow.keras.models import model_from_yaml","2d918cbf":"ORIGINAL_IMAGES_PATH = Path(\"..\/input\/satellite-images-of-water-bodies\/Water Bodies Dataset\/Images\")\nMASK_PATH = Path(\"..\/input\/satellite-images-of-water-bodies\/Water Bodies Dataset\/Masks\")\n\nORIGINAL_IMG_LIST = list(ORIGINAL_IMAGES_PATH.glob(r\"*.jpg\"))\nMASK_LIST = list(MASK_PATH.glob(r\"*.jpg\"))\n\nprint(len(ORIGINAL_IMG_LIST))\nprint(len(MASK_LIST))","6690e7b2":"print(ORIGINAL_IMG_LIST[1])\nprint(MASK_LIST[1])","489afa60":"print(ORIGINAL_IMG_LIST[1000])\nprint(MASK_LIST[1000])","5a3f40b9":"IMG_SERIES = pd.Series(ORIGINAL_IMG_LIST,name=\"ORIGINAL\").astype(str)\nMASK_SERIES = pd.Series(MASK_LIST,name=\"MASK\").astype(str)\n\nMAIN_DATA = pd.concat([IMG_SERIES,MASK_SERIES],axis=1)","dc9c6817":"MAIN_DATA","8c039c8f":"for x_count,(x_img,x_mask) in enumerate(zip(MAIN_DATA.ORIGINAL,MAIN_DATA.MASK)):\n    \n    if x_count <= 5:\n        \n        Example_IMG = cv2.cvtColor(cv2.imread(x_img),cv2.COLOR_BGR2RGB)\n        Example_MASK = cv2.cvtColor(cv2.imread(x_mask),cv2.COLOR_BGR2RGB)\n\n        figure,axis = plt.subplots(1,2,figsize=(12,12))\n\n        axis[0].set_title(\"ORIGINAL\")\n        axis[0].axis(\"off\")\n        axis[0].imshow(Example_IMG)\n\n        axis[1].set_title(\"MASK\")\n        axis[1].axis(\"off\")\n        axis[1].imshow(Example_MASK)\n\n        plt.tight_layout()\n        plt.show()","8e3b10db":"REDUCE_MAIN = MAIN_DATA[:100]\nTEST_FUTURE_DATA = MAIN_DATA[\"ORIGINAL\"][100:120]","b8890a36":"FOR_AE_TEST = MAIN_DATA[\"ORIGINAL\"][1000:1020]","e86ece3e":"AE_TEST_LIST = []\n\nfor x_test in FOR_AE_TEST.values:\n    \n    TEST_READING = cv2.cvtColor(cv2.imread(x_test),cv2.COLOR_BGR2RGB)\n    RESIZE_TEST = cv2.resize(TEST_READING,(IMG_WIDTH,IMG_HEIGHT))\n    \n    REDUCE_TEST = RESIZE_TEST \/ 255.\n    \n    AE_TEST_LIST.append(REDUCE_TEST)","030287bb":"REDUCE_MAIN","49c787cb":"TEST_FUTURE_DATA = TEST_FUTURE_DATA.reset_index(drop=True)","cba69316":"TEST_FUTURE_DATA","8fccb8a2":"BUFFER_SIZE = 400\nBATCH_SIZE = 1\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\nOUTPUT_CHANNELS = 3\nLAMBDA = 100\nEPOCHS = 60\nTYPE_ARRAY = \"float32\"","ed6a7b16":"TARGET_DATA = []\nOUTPUT_DATA = []\nTEST_DATA = []","e94d56e7":"for x_target,x_output in zip(REDUCE_MAIN.ORIGINAL,REDUCE_MAIN.MASK):\n    \n    TARGET_READING = cv2.cvtColor(cv2.imread(x_target),cv2.COLOR_BGR2RGB)\n    OUTPUT_READING = cv2.cvtColor(cv2.imread(x_output),cv2.COLOR_BGR2RGB)\n    \n    RESIZE_TARGET = cv2.resize(TARGET_READING,(IMG_WIDTH,IMG_HEIGHT))\n    RESIZE_OUTPUT = cv2.resize(OUTPUT_READING,(IMG_WIDTH,IMG_HEIGHT))\n    \n    REDUCE_TARGET = RESIZE_TARGET \/ 255.\n    REDUCE_OUTPUT = RESIZE_OUTPUT \/ 255.\n    \n    TARGET_DATA.append(REDUCE_TARGET)\n    OUTPUT_DATA.append(REDUCE_OUTPUT)\n    \n    \nfor x_test in TEST_FUTURE_DATA.values:\n    \n    TEST_READING = cv2.cvtColor(cv2.imread(x_test),cv2.COLOR_BGR2RGB)\n    RESIZE_TEST = cv2.resize(TEST_READING,(IMG_WIDTH,IMG_HEIGHT))\n    \n    REDUCE_TEST = RESIZE_TEST \/ 255.\n    \n    TEST_DATA.append(REDUCE_TEST)\n    \n    \nprint(np.shape(np.array(TARGET_DATA)))\nprint(np.shape(np.array(OUTPUT_DATA)))\nprint(np.shape(np.array(TEST_DATA)))","4ea60322":"for x_count, (x_img,x_mask) in enumerate(zip(TARGET_DATA,OUTPUT_DATA)):\n    \n    if x_count <= 5:\n        \n        figure,axis = plt.subplots(1,2,figsize=(12,12))\n        \n        axis[0].axis(\"off\")\n        axis[0].imshow(TARGET_DATA[x_count])\n        \n        axis[1].axis(\"off\")\n        axis[1].imshow(OUTPUT_DATA[x_count])\n        \n        plt.tight_layout()\n        plt.show()","2837432b":"TARGET_TENSOR = tf.data.Dataset.from_tensor_slices(np.array(TARGET_DATA,dtype=TYPE_ARRAY)).batch(BATCH_SIZE)\nOUTPUT_TENSOR = tf.data.Dataset.from_tensor_slices(np.array(OUTPUT_DATA,dtype=TYPE_ARRAY)).batch(BATCH_SIZE)\nTEST_FUTURE_TENSOR = tf.data.Dataset.from_tensor_slices(np.array(TEST_DATA,dtype=TYPE_ARRAY)).batch(BATCH_SIZE)","d04e59b1":"TARGET_AUTO = np.array(TARGET_DATA,dtype=TYPE_ARRAY)\nOUTPUT_AUTO = np.array(OUTPUT_DATA,dtype=TYPE_ARRAY)","93f3651c":"AE_TEST_ARRAY = np.array(AE_TEST_LIST,dtype=TYPE_ARRAY)","59a12136":"print(TARGET_TENSOR.element_spec)\nprint(OUTPUT_TENSOR.element_spec)\nprint(TEST_FUTURE_TENSOR.element_spec)","4b4dfc87":"def DL_CREATION(filter_num,size_num,batch_normalization=True):\n    \n    Initializer_Kernel_Parameter = tf.random_normal_initializer(0.,0.05)\n    \n    Model_DL = Sequential()\n    \n    Model_DL.add(Conv2D(filter_num,\n                       size_num,\n                       strides=2,\n                       padding=\"same\",\n                       use_bias=False,\n                       kernel_initializer=Initializer_Kernel_Parameter))\n    \n    if batch_normalization:\n        \n        Model_DL.add(BatchNormalization())\n        \n        \n        \n    return Model_DL","a0502568":"def UL_CREATION(filter_num,size_num,dropout_layer=False):\n    \n    Initializer_Kernel_Parameter = tf.random_normal_initializer(0.,0.05)\n    \n    Model_UL = Sequential()\n    \n    Model_UL.add(Conv2DTranspose(filter_num,\n                                size_num,\n                                strides=2,\n                                padding=\"same\",\n                                use_bias=False,\n                                kernel_initializer=Initializer_Kernel_Parameter))\n    \n    Model_UL.add(BatchNormalization())\n    \n    if dropout_layer:\n        \n        Model_UL.add(Dropout(0.3))\n        \n        \n    Model_UL.add(ReLU())\n    \n    return Model_UL","469d37ca":"def Generator_CREATION(I_WIDTH,I_HEIGHT,I_DIM):\n    \n    INPUT_LAYER = Input(shape=[I_WIDTH,I_HEIGHT,I_DIM])\n    \n    DL_LIST = [\n        \n        DL_CREATION(64,3,batch_normalization=False),\n        DL_CREATION(128,3,batch_normalization=False),\n        DL_CREATION(256,3,batch_normalization=False),\n        DL_CREATION(512,3),\n        DL_CREATION(512,3),\n        DL_CREATION(512,3),\n        DL_CREATION(512,3),\n        DL_CREATION(512,3)\n        \n    ]\n    \n    UL_LIST = [\n        \n        UL_CREATION(512,3,dropout_layer=True),\n        UL_CREATION(512,3),\n        UL_CREATION(512,3),\n        UL_CREATION(512,3),\n        UL_CREATION(256,3),\n        UL_CREATION(128,3),\n        UL_CREATION(64,3)\n        \n    ]\n    \n    Kernel_Parameter = tf.random_normal_initializer(0.,0.05)\n    \n    TRANSPOSE_LAYER = Conv2DTranspose(OUTPUT_CHANNELS,3,\n                                     strides=2,\n                                     padding=\"same\",\n                                     kernel_initializer=Kernel_Parameter,\n                                     activation=\"tanh\")\n    \n    ADD_X = INPUT_LAYER\n    \n    SKIP_LIST = []\n    \n    for x_dl in DL_LIST:\n        \n        ADD_X = x_dl(ADD_X)\n        SKIP_LIST.append(ADD_X)\n        \n    SKIP_LIST = reversed(SKIP_LIST[:-1])\n    \n    for x_ul,x_skip in zip(UL_LIST,SKIP_LIST):\n        \n        ADD_X = x_ul(ADD_X)\n        ADD_X = tf.keras.layers.Concatenate()([ADD_X,x_skip])\n        \n    ADD_X = TRANSPOSE_LAYER(ADD_X)\n    \n    return tf.keras.Model(inputs=INPUT_LAYER,outputs=ADD_X)","6d22374e":"Generation_Model = Generator_CREATION(IMG_WIDTH,IMG_HEIGHT,OUTPUT_CHANNELS)","eccdc488":"def Discriminator_CREATION(I_WIDTH,I_HEIGHT,I_DIM):\n    \n    Kernel_Parameter = tf.random_normal_initializer(0.,0.05)\n    \n    INPUT_LAYER = Input(shape=[I_WIDTH,I_HEIGHT,I_DIM])\n    TARGET_LAYER = Input(shape=[I_WIDTH,I_HEIGHT,I_DIM])\n    \n    CONCATENATE_INPUT_TARGET = tf.keras.layers.concatenate([INPUT_LAYER,TARGET_LAYER])\n    \n    DL_1 = DL_CREATION(64,3,False)(CONCATENATE_INPUT_TARGET)\n    DL_2 = DL_CREATION(64,3)(DL_1)\n    DL_3 = DL_CREATION(64,3)(DL_2)\n    \n    ZP_1 = ZeroPadding2D()(DL_3)\n    \n    CONV2D_1 = Conv2D(512,\n                     3,\n                     strides=1,\n                     kernel_initializer=Kernel_Parameter,\n                     use_bias=False)(ZP_1)\n    \n    BH_1 = BatchNormalization()(CONV2D_1)\n    \n    ACT_1 = LeakyReLU()(BH_1)\n    \n    ZP_2 = ZeroPadding2D()(ACT_1)\n    \n    LAST_LAYER = Conv2D(1,2,strides=1,kernel_initializer=Kernel_Parameter)(ZP_2)\n    \n    \n    return tf.keras.Model(inputs=[INPUT_LAYER,TARGET_LAYER],outputs=LAST_LAYER)","8c4e31cb":"Discrimination_Model = Discriminator_CREATION(IMG_WIDTH,IMG_HEIGHT,OUTPUT_CHANNELS)","50956c3f":"LOSS_FUNCTION = tf.keras.losses.BinaryCrossentropy(from_logits=True)","63a79e5f":"def Generation_Loss(disc_out,gen_out,target_out):\n    \n    GAN_LOSS = LOSS_FUNCTION(tf.ones_like(disc_out),disc_out)\n    ABS_ERROR_LOSS = tf.reduce_mean(tf.abs(target_out-gen_out))\n    \n    TOTAL_LOSS = GAN_LOSS + (LAMBDA * ABS_ERROR_LOSS)\n    \n    return TOTAL_LOSS,GAN_LOSS,ABS_ERROR_LOSS","a81e93e8":"def Discrimination_Loss(org_out,seg_out):\n    \n    ORG_OUT = LOSS_FUNCTION(tf.ones_like(org_out),org_out)\n    SEG_OUT = LOSS_FUNCTION(tf.zeros_like(seg_out),seg_out)\n    \n    TOTAL_LOSS = ORG_OUT + SEG_OUT\n    \n    return TOTAL_LOSS","ebb479fd":"os.mkdir(\".\/OUT_CLASS\")\nos.mkdir(\".\/MULTI_CLASS\")\nos.mkdir(\".\/AUTO_CLASS\")","eb024198":"GENERATOR_OPT = tf.keras.optimizers.RMSprop(lr=0.0002,clipvalue=1.0,decay=1e-8)\nDISCRIMINATOR_OPT = tf.keras.optimizers.RMSprop(lr=0.0002,clipvalue=1.0,decay=1e-8)\nAUTOENCODER_OPT = tf.keras.optimizers.Adam(lr=0.00003)","9bef3442":"READ_PREDICT_SINGLE = []\n\ndef generate_images_single(model, test_input, tar, number_i):\n    \n    prediction = model(test_input, training=True)\n    \n    plt.figure(figsize=(8, 8))\n    \n    plt.imshow(prediction[0])\n    plt.savefig('.\/OUT_CLASS\/out_res_{:04d}.png'.format(number_i))\n    \n    READING_PRE = cv2.cvtColor(cv2.imread('.\/OUT_CLASS\/out_res_{:04d}.png'.format(number_i)),cv2.COLOR_BGR2RGB)\n    READ_PREDICT_SINGLE.append(READING_PRE)\n    \n    plt.axis('off')\n    \n    plt.tight_layout()    \n    plt.show()","9c24d324":"READ_PREDICT_MULTI = []\n\ndef generate_images_for_example(model, test_input, tar, number_i):\n    \n    prediction = model(test_input, training=True)\n    \n    RESULT_IN_OUT_LIST = [test_input[0], tar[0], prediction[0]]\n    \n    \n    figure,axis = plt.subplots(1, 3,figsize=(14,14))\n\n    axis[0].imshow(RESULT_IN_OUT_LIST[0])\n    axis[0].axis('off')\n\n    axis[1].imshow(RESULT_IN_OUT_LIST[1])\n    axis[1].axis('off')\n\n    axis[2].imshow(RESULT_IN_OUT_LIST[2])\n    axis[2].axis('off')\n    \n    plt.savefig('.\/MULTI_CLASS\/multi_res_{:04d}.png'.format(number_i))\n    \n    READING_PRE = cv2.cvtColor(cv2.imread('.\/MULTI_CLASS\/multi_res_{:04d}.png'.format(number_i)),cv2.COLOR_BGR2RGB)\n    READ_PREDICT_MULTI.append(READING_PRE)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    return prediction[0]","8af919e1":"def auto_encoder_prediction_result(test_input):\n   \n    Prediction_IMG = test_input\n    \n    plt.figure(figsize=(8, 8))\n    plt.axis(\"off\")\n    plt.imshow(Prediction_IMG[0])\n    plt.tight_layout()\n    plt.show()","49e58923":"@tf.function\n\ndef Train_Process(INPUT_TENSOR,TARGET_TENSOR,ITERATIONS):\n    \n    with tf.GradientTape() as GEN_TAPE, tf.GradientTape() as DISC_TAPE:\n        \n        GENERATION_OUT = Generation_Model(INPUT_TENSOR,training=True)\n        \n        DISCRIMINATION_ORG = Discrimination_Model([INPUT_TENSOR,TARGET_TENSOR],training=True)\n        DISCRIMINATION_SEG = Discrimination_Model([INPUT_TENSOR,GENERATION_OUT],training=True)\n        \n        GEN_TOTAL_LOSS,GENERATOR_LOSS,MEAN_ABS_LOSS = Generation_Loss(DISCRIMINATION_SEG,GENERATION_OUT,TARGET_TENSOR)\n        \n        DISC_LOSS = Discrimination_Loss(DISCRIMINATION_ORG,DISCRIMINATION_SEG)\n        \n        \n        \n    Generator_Gradients = GEN_TAPE.gradient(GEN_TOTAL_LOSS,Generation_Model.trainable_variables)\n    Discriminator_Gradients = DISC_TAPE.gradient(DISC_LOSS,Discrimination_Model.trainable_variables)\n    \n    GENERATOR_OPT.apply_gradients(zip(Generator_Gradients,Generation_Model.trainable_variables))\n    DISCRIMINATOR_OPT.apply_gradients(zip(Discriminator_Gradients,Discrimination_Model.trainable_variables))","966f4438":"Checkpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=True,\n                                                      filepath=\".\/modelcheck\")","f3f11a42":"Encoder_G = Sequential()\nEncoder_G.add(Conv2D(32,(2,2),kernel_initializer = 'he_normal'))\nEncoder_G.add(BatchNormalization())\nEncoder_G.add(ReLU())\n#\nEncoder_G.add(Conv2D(64,(2,2),kernel_initializer = 'he_normal'))\nEncoder_G.add(BatchNormalization())\nEncoder_G.add(ReLU())\n#\nEncoder_G.add(Conv2D(128,(2,2),kernel_initializer = 'he_normal'))\nEncoder_G.add(BatchNormalization())\nEncoder_G.add(ReLU())\n\n####\n\n\nDecoder_G = Sequential()\nDecoder_G.add(Conv2DTranspose(64,(2,2)))\nDecoder_G.add(ReLU())\n#\nDecoder_G.add(Conv2DTranspose(32,(2,2)))\nDecoder_G.add(ReLU())\n#\nDecoder_G.add(Conv2DTranspose(3,(2,2)))\nDecoder_G.add(ReLU())","1de433d0":"Auto_Encoder_Model = Sequential([Encoder_G,Decoder_G])","b96c0405":"Auto_Encoder_Model.compile(loss=LOSS_FUNCTION,optimizer=AUTOENCODER_OPT,metrics=[\"accuracy\"])","ddf48ea0":"counting_img = 0\n\nfor epoch in range(EPOCHS):\n\n    n_count = 0\n    \n    for image_x, image_y in tf.data.Dataset.zip((TARGET_TENSOR.take(epoch),OUTPUT_TENSOR.take(epoch))):\n        \n        Train_Process(image_x, image_y, epoch)\n        print(str(counting_img))\n        if n_count % 10 == 0:\n            \n            print (\".\", end='')\n            \n        n_count += 1\n        \n    \n        clear_output(wait=True)\n        \n        \"\"\"generate_images_single(Generation_Model,\n                              image_x,\n                              image_y,\n                              counting_img)\"\"\"\n        \n        Pre_Result = generate_images_for_example(Generation_Model,\n                                    image_x,\n                                    image_y,\n                                    counting_img)\n        \n        ARRAY_IMG = np.array(image_x,dtype=\"float32\")\n        RES_IMG = np.array(Pre_Result,dtype=\"float32\")\n        RES_IMG = RES_IMG.reshape(1,256,256,3)\n        \n        Auto_Encoder_Model.fit(ARRAY_IMG,RES_IMG,epochs=epoch,callbacks=[Checkpoint_Model])\n        print(\"OTHER EPOCH +\")\n        \nprint(\"IT'DONE!\")","a1f29fd8":"print(Generation_Model.summary())","3d9080f4":"Auto_Encoder_Model.summary()","a4614be4":"Generation_Model.save(\"GEN_MODEL.h5\")","9ce2802c":"MODEL_TRAINED_yaml = Generation_Model.to_yaml()\nwith open(\"model_train.yaml\", \"w\") as yaml_file:\n    yaml_file.write(MODEL_TRAINED_yaml)","5313e7e7":"Generation_Model.save_weights(\"model_traing_weights.h5\")","270c8ba4":"os.mkdir(\".\/PRE_CLASS\")","f06d6983":"READ_PREDICT_RES = []\n\ndef generate_images_predict(model, test_input):\n    \n    prediction = model(test_input, training=True)\n    \n    RESULT_IN_OUT_LIST = [test_input[0], prediction[0]]\n    \n    \n    figure,axis = plt.subplots(1, 2,figsize=(14,14))\n\n    axis[0].imshow(RESULT_IN_OUT_LIST[0])\n    axis[0].axis('off')\n\n    axis[1].imshow(RESULT_IN_OUT_LIST[1])\n    axis[1].axis('off')\n\n    RANDOM_SAVE = random.randint(0,2222)\n    plt.savefig('.\/PRE_CLASS\/multi_res_{:04d}.png'.format(RANDOM_SAVE))\n    \n    READING_PRE = cv2.cvtColor(cv2.imread('.\/PRE_CLASS\/multi_res_{:04d}.png'.format(RANDOM_SAVE)),cv2.COLOR_BGR2RGB)\n    READ_PREDICT_RES.append(READING_PRE)\n    \n    plt.tight_layout()\n    plt.show()","e2c587d5":"for x_counting_tensor in TEST_FUTURE_TENSOR.take(11):\n    \n    generate_images_predict(Generation_Model,x_counting_tensor)","4dc3d118":"def displaying_res_as_video(source):\n    \n    figure = plt.figure(figsize=(16,11))\n\n    Image_List = []\n    plt.style.use(\"dark_background\")\n    for indexing in source:\n        \n        Read_IMG = plt.imshow(indexing, animated=True,cmap=\"hot\")\n        plt.axis('off')\n        Image_List.append([Read_IMG])\n\n    Animation_Func = animation.ArtistAnimation(figure, Image_List, interval=650, repeat_delay=10200)\n    \n    plt.close()\n    \n    return Animation_Func","84415ae4":"HTML(displaying_res_as_video(READ_PREDICT_RES).to_html5_video())","65bf68ae":"PRE_IMG_AE = Auto_Encoder_Model.predict(AE_TEST_ARRAY[:18])","84823221":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 1\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","a26c781d":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 2\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","cde3c0b7":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 3\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","5802f7f0":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 4\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","a566e526":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 5\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","bc3a9736":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 6\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","9e3a18de":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 7\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","418df757":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 8\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","98f105ba":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 9\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","2adb9ffe":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 10\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","cff213ad":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 11\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","1a496624":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 12\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","bddfecb6":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 13\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","f953f971":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 14\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","a5d24247":"figure,axis = plt.subplots(1,2,figsize=(10,10))\nprediction_img_number = 15\n\nOriginal_Img = AE_TEST_ARRAY[prediction_img_number]\nPredict_Mask = PRE_IMG_AE[prediction_img_number]\n\naxis[0].imshow(Original_Img)\naxis[0].set_xlabel(Original_Img.shape)\naxis[0].set_ylabel(Original_Img.size)\naxis[0].set_title(\"WATER\")\naxis[1].imshow(Predict_Mask)\naxis[1].set_xlabel(Predict_Mask.shape)\naxis[1].set_ylabel(Predict_Mask.size)\naxis[1].set_title(\"MASK\")","62460d8b":"print(\"hello\")","02e70071":"VIDEO_PATH = \"..\/input\/test-model-water\/7lfozb.mp4\"\nNEW_VIDEO_LIST = []\nRead_Video = cv2.VideoCapture(VIDEO_PATH)\n\nwhile Read_Video.isOpened():\n    \n    _,frame = Read_Video.read()\n    \n    if _ != True:\n        break\n        \n    if Read_Video.isOpened():\n        \n        Trans_Frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n        Resize_Frame = cv2.resize(Trans_Frame,(256,256))\n        \n        Reduce_Frame = Resize_Frame \/ 255.\n        NEW_VIDEO_LIST.append(Reduce_Frame)\n        \nRead_Video.release()","78cac99b":"print(len(NEW_VIDEO_LIST))","5fded6a3":"NEW_VIDEO_LIST = NEW_VIDEO_LIST[:100]","07693f25":"ARRAY_VIDEO = np.array(NEW_VIDEO_LIST,dtype=\"float32\")","917419b0":"TENSOR_VIDEO = tf.data.Dataset.from_tensor_slices(ARRAY_VIDEO).batch(BATCH_SIZE)","a2975e83":"VIDEO_PREDICT_SINGLE = []\n\ndef generate_images_single(model, test_input):\n    \n    prediction = model(test_input, training=True)\n    \n    plt.figure(figsize=(8, 8))\n    \n    plt.imshow(prediction[0])\n    RANDOM_SAVE = random.randint(0,2222)\n    plt.savefig('.\/OUT_CLASS\/out_res_{:04d}.png'.format(RANDOM_SAVE))\n    \n    READING_PRE = cv2.cvtColor(cv2.imread('.\/OUT_CLASS\/out_res_{:04d}.png'.format(RANDOM_SAVE)),cv2.COLOR_BGR2RGB)\n    VIDEO_PREDICT_SINGLE.append(READING_PRE)\n    \n    plt.axis('off')\n    \n    plt.tight_layout()    \n    plt.show()","ab90dd85":"for x_counting_tensor in TENSOR_VIDEO.take(90):\n    \n    generate_images_single(Generation_Model,x_counting_tensor)","16e6647c":"NEW_VIDEO_LIST_90 = NEW_VIDEO_LIST[:90]","b9997458":"def displaying_video_to_as_video(source):\n    \n    figure = plt.figure(figsize=(16,11))\n\n    Image_List = []\n    plt.style.use(\"dark_background\")\n    for indexing in source:\n        \n        Read_IMG = plt.imshow(indexing, animated=True,cmap=\"hot\")\n        plt.axis('off')\n        Image_List.append([Read_IMG])\n\n    Animation_Func = animation.ArtistAnimation(figure, Image_List, interval=100, repeat_delay=10200)\n    \n    plt.close()\n    \n    return Animation_Func","a8038f39":"HTML(displaying_video_to_as_video(NEW_VIDEO_LIST_90).to_html5_video())","38e61c2e":"HTML(displaying_video_to_as_video(VIDEO_PREDICT_SINGLE).to_html5_video())","7a498cf1":"### LAYER CREATION","2256ec84":"# BEFORE TRAINING","e71c5f4b":"### GENERATOR AND DISCRIMINATOR CREATION","a1f08862":"### OPTIMIZATION FUNCTION AND GENERATION IMAGES","d3d69cf3":"# PATHING AND READING PROCESS","c28dd588":"### TRAINING - PROCESS","f4864cb2":"# LIBRARIES","692da7b0":"### LOSS FUNCTION - CREATING GENERATOR AND DISCRIMINATOR LOSS","9b5be039":"# MODEL PROCESS","772bb715":"# TRAINING STEP FUNCTION - MAIN","d33aeeb8":"### TRAINING - STEP FUNCTION"}}