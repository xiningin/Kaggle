{"cell_type":{"11db9e0d":"code","48dd7288":"code","64a272a3":"code","11b0695e":"code","71aca42e":"code","77782a2f":"code","484a1e8d":"code","6ec30e47":"code","0d7049ad":"code","f2463a4b":"code","fb34d05b":"code","12b61e79":"code","089c4c28":"code","956f58e1":"code","d03be309":"code","87ed5fc9":"code","8def8277":"markdown","82d885ba":"markdown","33345371":"markdown","7e676fb2":"markdown","23529c68":"markdown","71a951b8":"markdown","0051d190":"markdown","037b34ef":"markdown","ba49eb99":"markdown"},"source":{"11db9e0d":"import pandas as pd\n\ntrain_transaction = pd.read_csv(\"..\/input\/train_transaction.csv\")\ntrain_identity = pd.read_csv(\"..\/input\/train_identity.csv\")\ntrain_transaction.head()","48dd7288":"train_identity.head()","64a272a3":"train = train_transaction.join(train_identity, on=\"TransactionID\", lsuffix=\"_leftid\")\ntrain.head()","11b0695e":"temp = pd.DataFrame({\n    \"Columns\": train.columns,\n    \"Types\": train.dtypes\n})\nprint(temp)","71aca42e":"column_not_contains_missing = train.isna().sum() == 0\ntrain.loc[:, train.columns[column_not_contains_missing]].head()","77782a2f":"df = train.loc[:, train.columns[column_not_contains_missing]].drop([\"TransactionID_leftid\", \"TransactionDT\"], axis=1)\n\nY = df[\"isFraud\"].copy()\nX = pd.get_dummies(df.drop([\"isFraud\"], axis=1)).copy()\nX.head()","484a1e8d":"print(X.shape)","6ec30e47":"import numpy as np\n\nnp.mean(Y)","0d7049ad":"import gc\n\ndel train_transaction, train_identity, train\ngc.collect()","f2463a4b":"from sklearn.model_selection import cross_val_score\n\ncv=9","fb34d05b":"from sklearn.ensemble import RandomForestClassifier\n\n\nmodel = RandomForestClassifier(n_estimators=100)\nscores_rf = cross_val_score(model, X, Y, cv=cv, n_jobs=3, scoring=\"roc_auc\")\nprint(np.mean(scores_rf), \"+\/-\", np.std(scores_rf))","12b61e79":"from xgboost import XGBClassifier\n\n\nmodel = XGBClassifier()\nscores_xgb = cross_val_score(model, X, Y, cv=cv, n_jobs=3, scoring=\"roc_auc\")\nprint(np.mean(scores_xgb), \"+\/-\", np.std(scores_xgb))","089c4c28":"from lightgbm import LGBMClassifier\n\n\nmodel = LGBMClassifier()\nscores_gbm = cross_val_score(model, X, Y, cv=cv, n_jobs=3, scoring=\"roc_auc\")\nprint(np.mean(scores_gbm), \"+\/-\", np.std(scores_gbm))","956f58e1":"from catboost import CatBoostClassifier\n\n\nX2 = (df.drop([\"isFraud\"], axis=1)).copy()\n\nmodel = CatBoostClassifier(cat_features=[\"ProductCD\"])\nscores_cat = cross_val_score(model, X2, Y, cv=cv, n_jobs=3, scoring=\"roc_auc\")\nprint(np.mean(scores_cat), \"+\/-\", np.std(scores_cat))","d03be309":"classifier = [\"Random forest\"] * cv + [\"Xgboost\"] * cv + [\"Lightgbm\"] * cv + [\"Catboost\"] * cv\nperformance = pd.DataFrame({\n    \"classifier\": classifier,\n    \"scores\": list(scores_rf) + list(scores_xgb) + list(scores_gbm) + list(scores_cat)\n})","87ed5fc9":"import seaborn as sns\n%matplotlib inline\n\nsns.boxplot(y=\"classifier\", x=\"scores\", data=performance).set(xlabel='', ylabel='')","8def8277":"Joining the two datasets on key $\\mathrm{TransactionID}$:","82d885ba":"Only columns without missing values are considered for a first model:","33345371":"Deleting the unused datasets:","7e676fb2":"Considering the model training time and the performances:\n    \n| **Classifier** | **Training time** | **Performance** |\n|  :- |    :-: | :-: |\n| Random Forest  | 6m 59s | $0.857 \\pm 0.016$ |\n| Xgboost | 3m 12s | $0.848 \\pm 0.011$ |\n| Lightgbm| 26.8s | $0.882 \\pm 0.013$ |\n| Catboost| 39m 41s | $0.879 \\pm 0.016$ |\n\nThe next iterations for designing features will be done only on the Lightgbm classifier.","23529c68":"The fraction of frauds is the following:","71a951b8":"The identity dataset looks like:","0051d190":"# Read the data\n\nRead both the transactions and the identity datasets:","037b34ef":"# Train models","ba49eb99":"Dropping the columns containing the IDs and getting the dummy encoded variables:"}}