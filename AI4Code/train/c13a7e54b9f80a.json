{"cell_type":{"d68fb982":"code","245befad":"code","f05bac53":"code","c7d7d737":"code","21869530":"code","5b36e3e8":"code","1aded362":"code","647ce73a":"code","6cd5802e":"code","3ae9b595":"code","bc025ed4":"code","85b71336":"code","6f059f61":"code","faea2c08":"code","9bae0a64":"markdown","f663f257":"markdown","bb0c6540":"markdown","b32b60ac":"markdown","22cb6779":"markdown","ff2f53b2":"markdown","cd70a46f":"markdown","b97a98c2":"markdown","c35aaace":"markdown","4bd776b5":"markdown","7f7b2c48":"markdown","ca380dcf":"markdown","5bbe6b22":"markdown","516177eb":"markdown","9bfaa3a8":"markdown","bd275a89":"markdown","320e0b84":"markdown","84ff9b9a":"markdown","89c9f6fc":"markdown"},"source":{"d68fb982":"from IPython.display import Image\nImage(\"..\/input\/imagefolder\/A.png\")","245befad":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","f05bac53":"df=pd.read_csv('\/kaggle\/input\/real-estate-price-prediction\/Real estate.csv')\ndf.head()","c7d7d737":"df.describe()","21869530":"X = df.drop('Y house price of unit area', axis=1)\n\ny = df['Y house price of unit area']","5b36e3e8":"poly_converter=PolynomialFeatures(degree=2, include_bias=True)\n\npoly_features= poly_converter.fit_transform(X)","1aded362":"print('shape of X is :',X.shape)\nprint('shape of X after using polynomial :',poly_features.shape)","647ce73a":"X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3)","6cd5802e":"model = LinearRegression()\nmodel.fit(X_train, y_train)","3ae9b595":"y_pred = model.predict(X_test)\npd.DataFrame({'Y_Test': y_test,'Y_Pred':y_pred, 'Residuals':(y_test-y_pred) }).head()","bc025ed4":"MAE_Poly = metrics.mean_absolute_error(y_test, y_pred)\nMSE_Poly = metrics.mean_squared_error(y_test, y_pred)\nRMSE_Poly = np.sqrt(MSE_Poly)\n\npd.DataFrame([MAE_Poly, MSE_Poly, RMSE_Poly], index=['MAE', 'MSE', 'RMSE'], columns=['metrics'])","85b71336":"XS_train, XS_test, ys_train, ys_test = train_test_split(X, y, test_size=0.3, random_state=101)\n\nsimplemodel = LinearRegression()\nsimplemodel.fit(XS_train, ys_train)\nys_pred = simplemodel.predict(XS_test)\n\nMAE_simple  = metrics.mean_absolute_error(ys_test,ys_pred)\nMSE_simple  = metrics.mean_squared_error(ys_test,ys_pred)\nRMSE_simple = np.sqrt(MSE_simple)\n\n\npd.DataFrame({'Poly Metrics': [MAE_Poly, MSE_Poly, RMSE_Poly], \n              'Simple Metrics':[MAE_simple, MSE_simple, RMSE_simple]}, \n               index=['MAE', 'MSE', 'RMSE'])","6f059f61":"# Train List of RMSE per degree\ntrain_RMSE_list=[]\n\n#Test List of RMSE per degree\ntest_RMSE_list=[]\n\nfor d in range(1,8):\n\n    #create poly data set for degree (d)\n    polynomial_converter= PolynomialFeatures(degree=d, include_bias=True)\n    poly_features= polynomial_converter.fit_transform(X)\n\n    \n    #Split the dataset\n    X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.3,random_state=101)\n    \n    #Train the Polynomial Model\n    model = LinearRegression()\n    model.fit(X_train, y_train)\n    \n    #Predicting on both Train & Test Data\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    #Evaluating the Model\n    train_RMSE = np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))\n    test_RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred))\n    \n    #Append the RMSE to the Train and Test List \n    train_RMSE_list.append(train_RMSE)\n    test_RMSE_list.append(test_RMSE)\n    ","faea2c08":"plt.plot(range(1,8), train_RMSE_list, label='Train RMSE')\nplt.plot(range(1,8), test_RMSE_list, label='Test RMSE')\n\nplt.xlabel('Polynomial Degree')\nplt.ylabel('RMSE')\nplt.legend()","9bae0a64":"The sklearn.preprocessing package provides several common utility functions and transformer classes to change raw feature vectors into a representation that is more suitable for the downstream estimators","f663f257":"## Choose the best degree ","bb0c6540":"## split data for Train and Test","b32b60ac":"**We make a loop for surveying polynomial from two degree to 10 degree**","22cb6779":"##  Prediction","ff2f53b2":"\n\n**For knowing more about Linear Regression on this Dataset I invite you to refer to my previous notebook about [Linear Regression Model for Real Estate](https:\/\/www.kaggle.com\/amirkonjkav\/linear-regression-model-for-real-estate).**\n","cd70a46f":"## Polynomial Regression Model","b97a98c2":"# Polynomial Regression ","c35aaace":"## Preprocessing","4bd776b5":"* **The graph shows that with increasing of degree our errors increasing too**","7f7b2c48":"### compare of these shapes show us that our features expand from 7 to 36!\n","ca380dcf":"## Define X and y","5bbe6b22":"# Polynomial","516177eb":"## Import Libraries","9bfaa3a8":"* **We see there is no significant difference between simple and polynomial regression**","bd275a89":"## Compare to the simple linear regression","320e0b84":"Polynomial regression is a form of Linear regression where only due to the Non-linear relationship between dependent and independent variables we add some polynomial terms to linear regression to convert it into Polynomial regression.","84ff9b9a":"#### It is very difficult to fit a linear regression line in the above graph with a low value of error. Hence we can try to use the polynomial regression to fit a polynomial line so that we can achieve a minimum error or minimum cost function","89c9f6fc":"## Linear regression\n#### requires the relation between the dependent variable and the independent variable to be linear. What if the distribution of the data was more complex as shown in the below figure? Can linear models be used to fit non-linear data? How can we generate a curve that best captures the data as shown below?"}}