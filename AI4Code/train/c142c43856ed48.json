{"cell_type":{"3d596555":"code","1207022a":"code","db0a82bd":"code","fdcb3314":"code","0c94770e":"code","ec675f93":"code","df249960":"code","310a2bcd":"code","8705129a":"code","887e3d57":"code","a641badc":"code","56c8dfac":"code","be2f7cdb":"code","34b3bd51":"code","1b8172dd":"code","4ca6b21c":"code","b3d29163":"code","ccf6e057":"code","4a709727":"code","6cdb7a8c":"code","785ebabf":"code","ca84b9da":"code","38c73c4a":"code","8ad902e2":"code","404bd975":"code","e2de88c6":"code","835244ae":"code","c8e8d375":"code","25a457d7":"code","4b903519":"code","03aefcb7":"code","8ffbb5cd":"code","d64b366a":"code","f3627ac4":"code","fe8fc1fb":"code","fd091a5f":"code","358897e4":"code","7e2a522e":"code","08f868ba":"code","69c71c61":"code","5b8bc465":"code","97e557b7":"code","cc094d4f":"code","a0746318":"code","de56b279":"code","5c4da361":"code","b54cecd5":"code","ea0b34cf":"code","4199df08":"markdown","e818ca61":"markdown","69660b50":"markdown","38fce0f4":"markdown","8cf1bde9":"markdown","7c715fb1":"markdown","f15c3f6d":"markdown","b95510d4":"markdown","08c5148d":"markdown","b8650d5b":"markdown","d11f6633":"markdown","674988de":"markdown","5eeb1e89":"markdown","404dec11":"markdown","d29a980a":"markdown","261149c9":"markdown","5e5715ae":"markdown","f13e13fa":"markdown","aa9ac0d5":"markdown","0a41ccf0":"markdown","b427eeea":"markdown","347fad79":"markdown","fafac945":"markdown","880205da":"markdown","e8e5e1aa":"markdown","ef350b53":"markdown","99881cf0":"markdown","4be8544e":"markdown","6181fd3c":"markdown","17d47385":"markdown","9dbad4d4":"markdown","3c6803d4":"markdown","0bafd794":"markdown","c90fc3a1":"markdown","39ca8617":"markdown","ead727b9":"markdown"},"source":{"3d596555":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1207022a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n\ntrain_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\nLR_train = train_data.copy()\nLR_test = test_data.copy()\nCNN_train = train_data.copy()\nCNN_test = test_data.copy()","db0a82bd":"LR_train.head(3)","fdcb3314":"LR_test.head(3)","0c94770e":"print(\"Training: {} and Test : {}\".format(LR_train.shape, LR_test.shape))","ec675f93":"train_y = LR_train['label']","df249960":"# drop the label from train dataset\nLR_train.drop(['label'], axis=1, inplace=True)\nLR_train.head(2)","310a2bcd":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(LR_train, train_y, test_size=0.3, random_state=42)","8705129a":"print(\"X train: {}\".format(x_train.shape))\nprint(\"Y train: {}\".format(y_train.shape))\nprint(\"X test: {}\".format(x_test.shape))\nprint(\"Y test: {}\".format(y_test.shape))","887e3d57":"from sklearn.linear_model import LogisticRegression\nregress = LogisticRegression(max_iter=500)","a641badc":"regress","56c8dfac":"import warnings\nwarnings.filterwarnings('ignore')","be2f7cdb":"regress.fit(x_train, y_train)","34b3bd51":"pred = regress.predict(x_test)","1b8172dd":"pred","4ca6b21c":"from sklearn.metrics import accuracy_score","b3d29163":"regress_acc = accuracy_score(pred, y_test)* 100\nprint(\"Regression Score: {}\".format(regress_acc))","ccf6e057":"regress_acc","4a709727":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D","6cdb7a8c":"# reshape for CNN\n\nCNN_train.head(3)","785ebabf":"print(\"CNN Training: {} and CNN Test: {}\".format(CNN_train.shape, CNN_test.shape))","ca84b9da":"CNN_y_train  = CNN_train['label'].values\nCNN_x_train = CNN_train.drop(['label'],1).values","38c73c4a":"CNN_test = CNN_test.values","8ad902e2":"# let check the values again\nCNN_x_train[:5]","404bd975":"CNN_y_train[:5]","e2de88c6":"CNN_test[:5]","835244ae":"# reshape the values\nCNN_x_train = CNN_x_train.reshape(-1,28,28,1)\nCNN_test = CNN_test.reshape(-1,28,28,1)","c8e8d375":"CNN_x_train[:4]","25a457d7":"# Do one hot encoding\nfrom keras.utils.np_utils import to_categorical\n","4b903519":"CNN_y_train[3]","03aefcb7":"y = to_categorical(CNN_y_train)\nprint(\"Label size: {}\".format(y.shape))","8ffbb5cd":"# split train and validation dataset\n\nCNN_train_split, CNN_test_split, CNN_y_train_split, CNN_y_test_split = train_test_split(CNN_x_train, y, test_size=0.2, random_state=0)","d64b366a":"print(\"\\n\\nCNN Data Size \\n\\n\")\n\nprint(\"CNN_train_split  size : {}\\n\".format(CNN_train_split.shape))\nprint(\"CNN_test_split  size : {}\\n\".format(CNN_test_split.shape))\nprint(\"CNN_y_train_split size  : {}\\n\".format(CNN_y_train_split.shape))\nprint(\"CNN_y_test_split  size : {}\\n\".format(CNN_y_test_split.shape))\n","f3627ac4":"# Let visualize\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=(3,3),\n                 activation='relu',\n                 input_shape=(28,28,1)))\nmodel.add(Conv2D(64, kernel_size=(3,3),\n                 activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation='softmax'))\n\n","fe8fc1fb":"model.summary()","fd091a5f":"# Compile\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',\n             metrics=['accuracy'])","358897e4":"batch_size = 64\nepochs = 10","7e2a522e":"history = model.fit(CNN_train_split,CNN_y_train_split, epochs=epochs,\n         batch_size=batch_size)","08f868ba":"acc = model.evaluate(CNN_test_split, CNN_y_test_split)\n","69c71c61":"# First one is loss and second value in argument\n\nacc_score = round(acc[1] * 100, 2)\nprint('CNN acc is ', acc_score )","5b8bc465":"\n\nfig, axis = plt.subplots(2, 2, figsize=(12, 14))\n\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(CNN_test_split[i].reshape(28,28), cmap='binary')\n    pred = model.predict(CNN_test_split[i].reshape(1, 28, 28, 1)).argmax()\n    real = CNN_y_test_split[i].argmax()\n    ax.set_title('Predicted: {} \\n Real: {}'.format(pred,real), fontsize=30, color='red')\n","97e557b7":"Logistic_Regression = round(regress_acc, 2)\nLogistic_Regression","cc094d4f":"import plotly.graph_objects as go\nfig = go.Figure()\nfig.add_trace(go.Indicator(\n    mode = \"gauge+number\",\n    value = Linear_Regression,\n    title = {'text': \"Logistic Regression Accuracy\"},\n    domain = {'x': [0, 0.25], 'y': [0, 1]}\n))\nfig.add_trace(go.Indicator(\n    mode = \"gauge+number\",\n    value = acc_score,\n    title = {'text': \"CNN Accuracy\"},\n    domain={'x':[0.45,0.80],'y':[0,1]}\n))\n# fig.update_layout(width=400, height=500)\nfig.show()","a0746318":"pred = model.predict_classes(CNN_test, verbose=1)\n","de56b279":"subm = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nsubm.head(2)","5c4da361":"subm['Label'] = pred","b54cecd5":"subm","ea0b34cf":"subm.to_csv(\"submission.csv\",index=False)","4199df08":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='orange'>\n          <span>\n            4.3 Model Training\n            <\/span>   \n    <\/font>\n<\/h2>","e818ca61":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='red'>\n          <span>\n            1. Introduction :\n            <\/span>   \n    <\/font>\n<\/h2>","69660b50":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='red'>\n          <span>\n           5. Convolutional Neural Network (CNN) \n            <\/span>   \n    <\/font>\n<\/h2>","38fce0f4":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n            4.2 Regression Presetup\n            <\/span>   \n    <\/font>\n<\/h3>","8cf1bde9":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n            1.1 Background Info :\n            <\/span>   \n    <\/font>\n<\/h3>","7c715fb1":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n           2.1 Import Python Libraries\n            <\/span>   \n    <\/font>\n<\/h3>","f15c3f6d":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='red'>\n          <span>\n            7. Submission\n            <\/span>   \n    <\/font>\n<\/h2>","b95510d4":"# CNN v\/s Regression Accuracy Comparison","08c5148d":"<p>\nThe MNIST dataset is an acronym that stands for the Modified National Institute of Standards and Technology dataset.\n<br>    \nIt is a dataset of 60,000 small square 28\u00d728 pixel grayscale images of handwritten single digits between 0 and 9.\n    \n    \n<\/p>","b8650d5b":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n            5.1 Imports CNN Modules\n            <\/span>   \n    <\/font>\n<\/h3>","d11f6633":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='orange'>\n          <span>\n           4.5 Check Accuracy score\n            <\/span>   \n    <\/font>\n<\/h2>","674988de":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='orange'>\n          <span>\n            5.4 Split the data\n            <\/span>   \n    <\/font>\n<\/h2>","5eeb1e89":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n           3.1 Importing the input csv\n            <\/span>   \n    <\/font>\n<\/h3>","404dec11":"Values are between [0,1]","d29a980a":"![d.webp](attachment:d.webp)\n<img width=\"200\">\n\n","261149c9":"We have label as 1,2,3,4,5 out of 9, hence we will convert each values in categorical values","5e5715ae":"![neo_convnets_meme-a4dc4674c5e5b710c18b7fa3e014cf3b-cbad6.jpg](attachment:neo_convnets_meme-a4dc4674c5e5b710c18b7fa3e014cf3b-cbad6.jpg)","f13e13fa":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n            6.1 CNN v\/s Regression\n            <\/span>   \n    <\/font>\n<\/h3>","aa9ac0d5":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n            5.2 Data Reshape\n            <\/span>   \n    <\/font>\n<\/32>","0a41ccf0":"![1_XGLdJM2c_g9DmGrmKrCisA.jpeg](attachment:1_XGLdJM2c_g9DmGrmKrCisA.jpeg)","b427eeea":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='red'>\n          <span>\n4. Linear Regression Analysis\n            <\/span>   \n    <\/font>\n<\/h2>","347fad79":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='red'>\n          <span>\n            5.6 Model Evaluation\n            <\/span>   \n    <\/font>\n<\/h3>","fafac945":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='orange'>\n          <span>\n            4.4 Model Prediction\n            <\/span>   \n    <\/font>\n<\/h2>","880205da":"CNN structure:-\n\n(1) COnv 2d Layer  - input size (28,28)\n\n(2) COnv 2d layer\n\n(3) Max Pooling2D Layer\n\n(4) Flatten Layer to Flatten the matrices\n\n(5) Dense Layer with 'relu activation function\n\n(6) Dropout to reduce linearity in the model\n\n(7) Dense  with 9 Output Layer for predictions","e8e5e1aa":"we have 784 columns ( 28 * 28 * 1)  which means images are of 28,28 size with black and white images\n\n\nSo, we will reshape them into 28,28 size","ef350b53":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='red'>\n          <span>\n            6. Conclusion\n            <\/span>   \n    <\/font>\n<\/h2>","99881cf0":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n            5.7 Visualize Predicted v\/s real\n            <\/span>   \n    <\/font>\n<\/h3>","4be8544e":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n           5.3 Update Label values\n            <\/span>   \n    <\/font>\n<\/h3>","6181fd3c":"![1_i4urxwebNVffqX5mwTwr4g.jpeg](attachment:1_i4urxwebNVffqX5mwTwr4g.jpeg)","17d47385":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n            4.1 Split the Data\n            <\/span>   \n    <\/font>\n<\/h3>","9dbad4d4":"<a id=\"intro\"><\/a>\n<h3>   \n    <font  color='orange'>\n          <span>\n5.5 Model Training \n            <\/span>   \n    <\/font>\n<\/h3>","3c6803d4":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='red'>\n          <span>\n           3. Understanding the data\n            <\/span>   \n    <\/font>\n<\/h2>","0bafd794":"<h2>   \n      <span>          \n           Contents\n    <\/span>\n       \n<\/h2>\n<span>\n    <ul>\n        <li><a href='#intro'>1. Introduction<\/a><\/li>\n        <ul>\n            <li><a href='#background'>1.1 Background info<\/a><\/li>\n        <\/ul>\n        <li><a href='#libraries'>2. Python Libraries<\/a><\/li>\n        <ul>\n            <li><a href='#python'>2.1 Import Python Libraries<\/a><\/li>\n         <\/ul>\n        <li><a href='#understand'>3. Understanding the data<\/a><\/li>\n        <ul>\n            <li><a href='#import'>3.1 Importing the input csv<\/a><\/li>\n            <li><a href='#inspect'>3.2 Overview the dataframes<\/a><\/li>\n        <\/ul>\n              <li><a href='#lr'>4. Logistic Regression Analysis<\/a><\/li>\n        <ul>\n            <li><a href='#split'>4.1 Split the Data<\/a><\/li>\n            <li><a href='#presetup'>4.2 Regression Presetup<\/a><\/li>\n            <li><a href='#training'>4.3 Model Training<\/a><\/li>\n            <li><a href='#prediction'>4.4 Model Prediction<\/a><\/li>\n            <li><a href='#check'>4.5 Check Accuracy score<\/a><\/li>   \n        <\/ul>\n              <li><a href='#cnn'>5. Convolutional Neural Network (CNN) <\/a><\/li>\n        <ul>\n            <li><a href='#importcnn'>5.1 Imports CNN Modules<\/a><\/li>\n            <li><a href='#datareshape'>5.2 Data Reshape<\/a><\/li>\n            <li><a href='#label'>5.3 Update Label values<\/a><\/li>\n            <li><a href='#splitdata'>5.4 Split the data<\/a><\/li>\n            <li><a href='#model_Train'>5.5 Model Training <\/a><\/li>   \n            <li><a href='#model_eva'>5.6 Model Evaluation<\/a><\/li>    \n            <li><a href='#visual'>5.7 Visualize Predicted v\/s real<\/a><\/li> \n        <\/ul>\n                <li><a href='#concl'>6. Conclusion<\/a><\/li>\n        <ul>\n            <li><a href='#cnnvsre'>6.1 CNN v\/s Regression<\/a><\/li>\n        <\/ul>  \n                <li><a href='#submis'>7. Submission<\/a><\/li>\n        <ul>\n            <li><a href='#model_subm'>7.1 Model submission<\/a><\/li>\n                        \n","c90fc3a1":"<a id=\"intro\"><\/a>\n<h2>   \n    <font  color='red'>\n          <span>\n            2. Python Libraries:\n            <\/span>   \n    <\/font>\n<\/h2>","39ca8617":"![1_82mwscRMM8a-71gmp0s4Xg.jpeg](attachment:1_82mwscRMM8a-71gmp0s4Xg.jpeg)","ead727b9":"4 will convert into  [0,0,0,1,0,0,0,0,0]\n\nThis is called one hot encoding"}}