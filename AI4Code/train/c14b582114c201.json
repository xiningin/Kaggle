{"cell_type":{"abe57168":"code","707dc257":"code","d5afe47a":"code","64bc0ddc":"code","7f9f717e":"code","8525e684":"code","b477e79c":"code","89f84d54":"code","ff7a511d":"code","a4def879":"code","0f25d99c":"code","212770da":"code","9a48816c":"code","eb561d18":"code","bd6d1bfb":"code","a9bfe88f":"code","8fe38272":"code","368e69f2":"code","5d12830c":"markdown"},"source":{"abe57168":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#Importing required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","707dc257":"#Importing dataset\nIris = pd.read_csv('..\/input\/iris\/Iris.csv')\nIris.head()","d5afe47a":"Iris.info()","64bc0ddc":"# determining all iris species included\nIris['Species'].value_counts(dropna=False)","7f9f717e":"# creating dummmy variable for the species type\nSpecies = pd.get_dummies(Iris['Species'])","8525e684":"#Selecting required data\nX = Iris.iloc[:, 1:5].values\ny = Species.values","b477e79c":"#Splitting data into training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0) ","89f84d54":"#Feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","ff7a511d":"#Importing keras packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense","a4def879":"#Initializing Artificial Neural Network (ANN)\nclassifier = Sequential()","0f25d99c":"#Adding input layer and first hidden layer\nclassifier.add(Dense(activation=\"relu\", kernel_initializer=\"uniform\", input_dim=4, units=3))","212770da":"#Adding second hidden layer\nclassifier.add(Dense(activation=\"relu\", kernel_initializer=\"uniform\", units=3))","9a48816c":"#Adding output layer\nclassifier.add(Dense(activation=\"sigmoid\", kernel_initializer=\"uniform\", units=3))","eb561d18":"#Compiling ANN\nclassifier.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'] )","bd6d1bfb":"#Fitting ANN to training set\nhistory = classifier.fit(X_train, y_train, batch_size = 25, epochs = 500, validation_split=0.25, verbose=0)\n","a9bfe88f":"#Predicting test results\ny_pred = classifier.predict(X_test)","8fe38272":"plt.scatter(x=y_test,y=y_pred, color= 'green')\nplt.xlabel('y_test values')\nplt.ylabel('y_pred values')\nplt.show()","368e69f2":"import matplotlib.pyplot as plt\n\n\n\n# Plot training & validation accuracy values\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","5d12830c":"Note:\n\nThis model was built by following method given for ANNs in this course:  [Deep Learning A-Z\u2122: Hands-On Artificial Neural Networks](http:\/\/)\n"}}