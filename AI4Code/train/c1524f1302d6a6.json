{"cell_type":{"1a40f0b8":"code","85382b0a":"code","92660e43":"code","86ffaff5":"code","0493781c":"code","be256154":"code","92e6a46a":"code","ba0f958f":"code","09e7c1aa":"code","835a5286":"code","9fb8c67a":"code","90df95f2":"code","7b081407":"code","3a3cf8d5":"code","8a947924":"code","ddf4c1cf":"code","337c2f28":"code","41c170ed":"code","33f708bb":"code","a4817ebf":"code","10f12c0f":"code","76ca838d":"code","c0f9a277":"code","d887a2b9":"code","d1e3abab":"code","2d7af02a":"code","5cedee01":"code","a669d3e1":"code","2ace7dc8":"code","68baf230":"code","1145526d":"code","319949a3":"code","ba0492d7":"code","79e8f012":"code","1f629253":"code","7268bfb3":"code","9c4412df":"code","552dc78b":"code","641ab9cf":"code","5a0f6745":"code","38d42fd8":"code","24ae223c":"code","89b63b51":"code","0b3f89b7":"code","7b3f8edf":"code","6be70885":"code","ec3e58a7":"code","ce086a4e":"code","0b946291":"code","94b37f3c":"code","0192ba46":"code","3faebf0d":"code","8bf60d8c":"markdown","f59d565b":"markdown","2d37a6a1":"markdown","3d1a90aa":"markdown","2586a26f":"markdown","a90669f9":"markdown","0b6475ed":"markdown","5b523e4e":"markdown","dbcab844":"markdown","e254e0a0":"markdown","de201bc7":"markdown","da50e565":"markdown","614c8bef":"markdown","83a9aceb":"markdown","0ffbf020":"markdown","fe169b47":"markdown","69453624":"markdown","08c4054a":"markdown","a372b325":"markdown","49882b6d":"markdown","c135bf43":"markdown","7f91dc44":"markdown","2813cd2a":"markdown","3a32bc53":"markdown","d307ed4b":"markdown","0548175a":"markdown","1d52508f":"markdown","4574aed5":"markdown","82abccf6":"markdown","90fa4220":"markdown","a9109999":"markdown","443c94f3":"markdown","97e6b8b1":"markdown","4ee48b7f":"markdown","6239b832":"markdown","ad9cecb4":"markdown","ac898ef9":"markdown","c0298abc":"markdown","db42453b":"markdown","8043c3ef":"markdown","74dad864":"markdown","969998c3":"markdown","2bb509c9":"markdown","97371ef6":"markdown","0be38493":"markdown"},"source":{"1a40f0b8":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# # to display all columns:\n# pd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","85382b0a":"#import train and test CSV files\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n#create a copy train\ndf= train.copy()\n\n#create a combined group of both datasets\ncombine = [df, test]","92660e43":"#take a look at the training data\ndf.describe().T","86ffaff5":"(df.columns)","0493781c":"test.info()","be256154":"df.isnull().sum()","92e6a46a":"test.isnull().sum()","ba0f958f":"print(df['Pclass'].value_counts())\nprint(df['SibSp'].value_counts())\nprint(df['Parch'].value_counts())\nprint(df['Embarked'].value_counts())\nprint(df['Sex'].value_counts())\nprint(df['Ticket'].value_counts())\nprint(df['Cabin'].value_counts())","09e7c1aa":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Sex\", y=\"Survived\", data=df);","835a5286":"#draw a bar plot of survival by Pclass\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=df);","9fb8c67a":"#draw a bar plot for SibSp vs. survival\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=df);","90df95f2":"df.groupby('SibSp')['PassengerId'].count()","7b081407":"sns.barplot(x=\"Parch\", y=\"Survived\", data=df)\nplt.show()","3a3cf8d5":"df.groupby('Parch')['PassengerId'].count()","8a947924":"sns.boxplot(x = df['Fare']);","ddf4c1cf":"test.describe(include=\"all\")","337c2f28":"df['Parch'] =  df['Parch'].replace([df.loc[df.Parch>1,'Parch'].values], 2)\ntest['Parch'] =  test['Parch'].replace([df.loc[df.Parch>1,'Parch'].values], 2)","41c170ed":"from pandas.api.types import CategoricalDtype \ndf['Parch'] = df['Parch'].astype(CategoricalDtype(ordered = True))\ntest['Parch'] = test['Parch'].astype(CategoricalDtype(ordered = True))","33f708bb":"df.groupby(['Parch'])['PassengerId'].count()","a4817ebf":"test.groupby(['SibSp'])['PassengerId'].count()","10f12c0f":"df['SibSp'] =  df['SibSp'].replace([df.loc[df.SibSp>1,'SibSp'].values], 2)\ntest['SibSp'] =  test['SibSp'].replace([df.loc[df.SibSp>1,'SibSp'].values], 2)","76ca838d":"df['SibSp'] = df['SibSp'].astype(CategoricalDtype(ordered = True))\ntest['SibSp'] = test['SibSp'].astype(CategoricalDtype(ordered = True))","c0f9a277":"sns.barplot(x=\"SibSp\", y=\"Survived\", data=df);","d887a2b9":"df[df.Cabin.notnull()].groupby('Pclass')['PassengerId'].count()","d1e3abab":"df = df.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)","2d7af02a":"#we can also drop the Ticket feature since it's unlikely to yield any useful information\ndf = df.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)","5cedee01":"#now we need to fill in the missing values in the Embarked feature\n\ndf['Embarked'].fillna(df.Embarked.mode()[0], inplace = True)\n","a669d3e1":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = df['Fare']);","2ace7dc8":"Q1 = train['Fare'].quantile(0.25)\nQ3 = train['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nprint(lower_limit)\n\nupper_limit = Q3 + 1.5*IQR\nprint(upper_limit)\n\nprint(df[df.Fare<upper_limit]['Fare'].describe())\nprint(df[df.Fare>upper_limit]['Fare'].describe())\nprint(df[df.Fare<150]['Fare'].describe())\nprint(df[df.Fare>150]['Fare'].describe())","68baf230":"for x in range(len(test[\"Fare\"])):\n    if pd.isnull(test[\"Fare\"][x]):\n        pclass = test[\"Pclass\"][x] #Pclass = 3\n        test[\"Fare\"][x] = df[df.Pclass==pclass]['Fare'].median()\n\n        \n# I replace values greater than 150 with the median of values greater than 150.\n\ndf['Fare'] = df['Fare'].replace(df[df.Fare>150]['Fare'], df[df.Fare>150]['Fare'].median())\ntest['Fare'] = test['Fare'].replace(test[test.Fare>150]['Fare'], test[test.Fare>150]['Fare'].median())\n","1145526d":"# df['FareBand'] = pd.qcut(df['Fare'], 4, labels = [1, 2, 3,4])\n# test['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3,4])\n\n\nbinss = [-1,8, 31, 100,np.inf]\nlabelss = [ 1,2,3,4]\ndf['FareBand'] = pd.cut(df[\"Fare\"], binss, labels = labelss)\ntest['FareBand'] = pd.cut(test[\"Fare\"], binss, labels = labelss)\n\n\ndf['FareBand'] = df['FareBand'].astype(CategoricalDtype(ordered = True))\ntest['FareBand'] = test['FareBand'].astype(CategoricalDtype(ordered = True))\n\nsns.barplot(x=\"FareBand\", y=\"Survived\", data=df)\nplt.show()","319949a3":"df.groupby('FareBand')['Fare'].mean()","ba0492d7":"#extract a title for each Name in the train and test datasets\ndf['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False) \n\npd.crosstab(df['Title'], df['Sex'])","79e8f012":"#replace various titles with more common names\n\n#for df\ndf['Title'] = df['Title'].replace(['Lady', 'Capt', 'Col', 'Don',\n                                                 'Dr', 'Major', 'Rev', 'Jonkheer', \n                                                 'Dona','Countess', 'Lady', 'Master',\n                                                 'Sir'], 'Rare')\ndf['Title'] = df['Title'].replace(['Mlle', 'Ms'],'Miss')\ndf['Title'] = df['Title'].replace('Mme', 'Mrs')\n    \n#for test    \ntest['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col', 'Don',\n                                                 'Dr', 'Major', 'Rev', 'Jonkheer', \n                                                 'Dona','Countess', 'Lady', 'Master',\n                                                 'Sir'], 'Rare')\ntest['Title'] =test['Title'].replace(['Mlle', 'Ms'],'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')\n\n\ndf.Title = pd.Categorical(df.Title)\ntest.Title = pd.Categorical(test.Title)    \n\ndf[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","1f629253":"#I tried to choose the ones that gave the most optimum result.\n\nage_guess = pd.DataFrame(df.groupby(['Title','SibSp','Pclass','Parch','FareBand','Embarked'], as_index=False)['Age'].median())\ndf_age_new = df.merge(age_guess, on =['Title','SibSp','Pclass','Parch' ,'FareBand','Embarked'], how='inner')\ndf_age_new['AgeErrors'] = (df_age_new['Age_x']-df_age_new['Age_y']).abs()\ndf_age_new['AgeErrors'].describe()","7268bfb3":"null_Age = df.drop(df[df.Age.notnull()].index, axis=0)\nnotnull_Age = df.drop(df[df.Age.isnull()].index, axis=0)\n\nage_guess = pd.DataFrame(df.groupby(['Title','SibSp','Pclass','Parch' ,'FareBand','Embarked'], as_index=False)['Age'].median())\nnull_Age = null_Age.merge(age_guess, on =['Title','SibSp','Pclass', 'Parch','FareBand','Embarked'], how='inner')\n\nnull_Age['Age_y']= null_Age['Age_y'].fillna(null_Age['Age_y'].median())\n\nnull_Age= null_Age.drop('Age_x', axis=1 ).rename(columns= {\"Age_y\": \"Age\"})\ndf = pd.concat([null_Age,notnull_Age], axis=0, ignore_index = True)","9c4412df":"null_Age = test.drop(test[test.Age.notnull()].index, axis=0)\nnotnull_Age = test.drop(test[test.Age.isnull()].index, axis=0)\n\nage_guess = pd.DataFrame(test.groupby(['Title','SibSp','Pclass','Parch' ,'FareBand','Embarked'], as_index=False)['Age'].median())\nnull_Age = null_Age.merge(age_guess, on =['Title','SibSp','Pclass', 'Parch','FareBand','Embarked'], how='inner')\n\nnull_Age['Age_y']= null_Age['Age_y'].fillna(null_Age['Age_y'].median())\n\nnull_Age= null_Age.drop('Age_x', axis=1 ).rename(columns= {\"Age_y\": \"Age\"})\ntest = pd.concat([null_Age,notnull_Age], axis=0, ignore_index = True)","552dc78b":"#sort the ages into logical categories\n\nbins = [0, 5,  64,  np.inf]\nlabels = [3,4,5]\ndf['AgeGroup'] = pd.cut(df[\"Age\"], bins, labels = labels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n\n\ndf['AgeGroup'] = df['AgeGroup'].astype(CategoricalDtype(ordered = True))\ntest['AgeGroup'] = test['AgeGroup'].astype(CategoricalDtype(ordered = True))\n\n#draw a bar plot of Age vs. survival\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=df)\nplt.show()","641ab9cf":"#drop the name feature since it contains no more useful information.\ndf = df.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","5a0f6745":"df = df.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","38d42fd8":"df = pd.get_dummies(df, columns = [\"Pclass\"], prefix = [\"Pclass\"], drop_first= True)\ntest = pd.get_dummies(test, columns = [\"Pclass\"], prefix = [\"Pclass\"], drop_first= True)","24ae223c":"df = pd.get_dummies(df, columns = [\"Embarked\"], prefix = [\"Embarked\"], drop_first= True)\ntest = pd.get_dummies(test, columns = [\"Embarked\"], prefix = [\"Embarked\"], drop_first= True)","89b63b51":"df = pd.get_dummies(df, columns = [\"Title\"], prefix = [\"Title\"], drop_first= True)\ntest = pd.get_dummies(test, columns = [\"Title\"], prefix = [\"Title\"], drop_first= True)","0b3f89b7":"df = pd.get_dummies(df, columns = [\"Sex\"], prefix = [\"Sex\"], drop_first= True)\ntest = pd.get_dummies(test, columns = [\"Sex\"], prefix = [\"Sex\"], drop_first= True)","7b3f8edf":"from sklearn.model_selection import train_test_split\n\npredictors = df.drop(['Survived', 'PassengerId'], axis=1)\ntarget = df[\"Survived\"]\nx_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 0)","6be70885":"# Logistic Regression82.74\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_val)\nacc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_logreg)","ec3e58a7":"# Support Vector Machines82.23,\nfrom sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_val)\nacc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_svc)","ce086a4e":"# Linear SVC 82.23, 62.44\nfrom sklearn.svm import LinearSVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(x_train, y_train)\ny_pred = linear_svc.predict(x_val)\nacc_linear_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_linear_svc)","0b946291":"# Stochastic Gradient Descent\nfrom sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(x_train, y_train)\ny_pred = sgd.predict(x_val)\nacc_sgd = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_sgd)","94b37f3c":"#MLPClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.preprocessing import StandardScaler \nscaler = StandardScaler()\n\nscaler.fit(x_train)\nX_train_scaled = scaler.transform(x_train)\nX_test_scaled = scaler.transform(x_val)\n\nmlpc = MLPClassifier().fit(X_train_scaled, y_train)\ny_pred = mlpc.predict(X_test_scaled)\nacc_mlpc = round(accuracy_score(y_val, y_pred)*100, 2)\nprint(acc_mlpc)","0192ba46":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines',  'Logistic Regression', \n               'Linear SVC',  'MLPClassifier' ,'Stochastic Gradient Descent'],\n    'Score': [acc_svc, acc_logreg, \n              acc_linear_svc,acc_mlpc,\n              acc_sgd]})\nmodels.sort_values(by='Score', ascending=False)","3faebf0d":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = mlpc.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission33.csv', index=False)","8bf60d8c":"#### Parch Feature","f59d565b":"I think the idea here is that people with recorded cabin numbers are of higher socioeconomic class, and thus more likely to survive. Therefore, I think that the cabin and Pclass columns contain the same information.And the cabin column does not express meaningful information by itself. So I drop it.","2d37a6a1":"### 6) Modeling, Evaluation and Model Tuning","3d1a90aa":"#### SibSp Feature","2586a26f":"#### Fare Feature","a90669f9":"#### One-Hot Encoding","0b6475ed":"#### SibSp Feature","5b523e4e":"- We have a total of 418 passengers.\n- 1 value from the Fare feature is missing.\n- Around 20.5% of the Age feature is missing, we will need to fill that in.","dbcab844":"#### Pclass Feature","e254e0a0":"As predicted, people with higher socioeconomic class had a higher rate of survival. (62.9% vs. 47.3% vs. 24.2%)","de201bc7":"### 7) Creating Submission File\n\nIt's time to create a submission.csv file to upload to the Kaggle competition!","da50e565":"Some Observations:\n1. There are a total of 891 passengers in our training set.\n2. The Age feature is missing approximately 19.8% of its values. I'm guessing that the Age feature is pretty important to survival, so we should probably attempt to fill these gaps.\n3. The Cabin feature is missing approximately 77.1% of its values. Since so much of the feature is missing, it would be hard to fill in the missing values. We'll probably drop these values from our dataset.\n4. The Embarked feature is missing 0.22% of its values, which should be relatively harmless.","614c8bef":"#### Age Feature","83a9aceb":"### Let's compare the accuracies of each model!","0ffbf020":"#### Splitting the Training Data\nWe will use part of our training data (22% in this case) to test the accuracy of our different models.","fe169b47":"#### Title Feature","69453624":"### 5) Cleaning Data & Outlier Treatment & Feature Engeneering & Predict Missing Values","08c4054a":"Testing Different Models\nI will be testing the following models with my training data (got the list from here):\n\n- Logistic Regression\n- Support Vector Machines\n- Linear SVC\n- Stochastic Gradient Descent\n\nFor each model, we set the model, fit it with 80% of our training data, predict for 20% of the training data and check the accuracy.","a372b325":"In general, it's clear that people with more siblings or spouses aboard were less likely to survive. However, contrary to expectations, people with no siblings or spouses were less to likely to survive than those with one or two. (34.5% vs 53.4% vs. 46.4%)","49882b6d":"#### Name Feature\nWe can drop the name feature now that we've extracted the titles.","c135bf43":"I noticed that there are outliers in the Fare variable. I made a few observations below to be able to optimize them. I tried to organize these outliers in the most reasonable way in line with my own ideas.","7f91dc44":"## 4)Data Visualization","2813cd2a":"#### Sex Feature","3a32bc53":"The number of people with two or more children or parents is very low in the data. Adding them separately to the algorithm can lead to misleading results. So I decided to examine two or more people as a single class.\n\nBesides I accept the Pclass variable as a categorical ordinal variable.","d307ed4b":"### 3) Data Analysis","0548175a":"#### Parch Feature","1d52508f":"### 1) Import Necessary Libraries","4574aed5":"As predicted, females have a much higher chance of survival than males. The Sex feature is essential in our predictions.","82abccf6":"#### Embarked Feature","90fa4220":"Next we'll fill in the missing values in the Age feature. Since a higher percentage of values are missing, it would be illogical to fill all of them with the same value (as we did with Embarked). Instead, let's try to find a way to predict the missing ages.\n\nI obtained a median age value by grouping some information of people with age information. Then, I tried to make a prediction by matching the information I grouped with the information of the people whose age is empty. I assigned a median value to several units that I couldn't guess.","a9109999":"I decided to use the Multiple Layer Perceptron model for the testing data.","443c94f3":"I converted non ordinal categorical variables to dummy variables. In doing so, I dropped the variables containing the same information to avoid falling into the dummy variable trap.","97e6b8b1":"The number of people with two or more siblings or spouses in the data is very low. Adding them separately to the algorithm can lead to misleading results. So I decided to examine two or more people as a single class.\n\nI accept the SibSp variable as a categorical ordinal variable.","4ee48b7f":"#### Fare Features","6239b832":"I dropped it because the Fare column reduces the success values of the algorithms.","ad9cecb4":"Some Predictions:\n1. Sex: Females are more likely to survive.\n2. SibSp\/Parch: People traveling alone are more likely to survive.\n3. Age: Maybe young children are more likely to survive. Maybe it is not important.\n4. Pclass: People of higher socioeconomic class are more likely to survive.\n5. Embarked: It is observed that most of the survivors boarded from the S port.\n6. Fare: I mean its very important.","ac898ef9":"#### Cabin Feature","c0298abc":"#### Fare Feature","db42453b":"#### Ticket Feature","8043c3ef":"Babies are more likely to survive than any other age group. However, seniors is unlucky than other groups to survive.","74dad864":"It's time separate the fare values into some logical groups as well as filling in the single missing value in the test dataset.","969998c3":"It's clear that the majority of people embarked in Southampton (S). Let's go ahead and fill in the missing values with S.","2bb509c9":"let's see how our test data looks!","97371ef6":"Time to clean our data to account for missing values and unnecessary information!","0be38493":"### 2) Read in and Explore the Data"}}