{"cell_type":{"9598dc06":"code","1353a4c4":"code","413556cd":"code","15a6156e":"code","0cb7fb57":"code","7f58abb5":"code","298260f1":"code","04e7e382":"code","ccf8a716":"code","88cd0710":"code","e1547a00":"code","62351ea7":"code","7bdde2ff":"code","4a729ec4":"code","3a0fb846":"code","02302ff8":"code","fb06a7de":"code","430fa735":"code","a987bfc1":"code","b1c8df60":"code","1fe92ee0":"code","cceed035":"code","a33199a5":"code","1089aab4":"code","8661d91f":"markdown","83505e65":"markdown","c9464b4e":"markdown","f33d5a70":"markdown","6c98ecf2":"markdown","7d46ecaa":"markdown","64da7b0b":"markdown","d0372fdc":"markdown","6163511a":"markdown","95ce26a7":"markdown","54089e96":"markdown","54f5eca5":"markdown","036d670e":"markdown","49801137":"markdown","185e7340":"markdown","4a98179b":"markdown"},"source":{"9598dc06":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import OrdinalEncoder # ordinal encoding categorical variables\nfrom sklearn.model_selection import train_test_split # spliting data\nfrom sklearn.metrics import mean_squared_error # MSE and RMSE metric\n\npd.set_option('display.max_columns', 50)\n\nSEED = 91 # random seed","1353a4c4":"PATH = '\/kaggle\/input\/30-days-of-ml\/' # you can use your own local path\n\nprint('Files in directory:')\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print('  '+os.path.join(dirname, filename))\nprint()\n\n# Load the training data\ntry:\n    df_train = pd.read_csv(PATH+'train.csv', index_col=0)\n    df_test = pd.read_csv(PATH+'test.csv', index_col=0)\n    print('All of the data has been loaded successfully')\nexcept Exception as err:\n    print(repr(err))","413556cd":"print(f\"Train data length: {len(df_train)}\")\nprint(f\"Test data length: {len(df_test)}\")","15a6156e":"df_train.info()","0cb7fb57":"df_test.info()","7f58abb5":"# Preview train data\ndf_train.head(5)","298260f1":"key_duplicate = False\nfor df in [df_train, df_test]:\n    if df.duplicated().sum() > 0:\n        key_duplicate = True\n\nif key_duplicate == False:\n    print('No duplicates in data')","04e7e382":"df_train.columns","ccf8a716":"cat_features = ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\nnum_features = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8',\n                'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\nALL_FEATURES = cat_features+num_features","88cd0710":"cat_features_dict = {}\nfor feature in cat_features:\n    cat_features_dict[feature] = df_train[feature].unique()\n    print(f\"{feature}:{df_train[feature].unique()}\")","e1547a00":"new_unique = False\nfor feature in cat_features:\n    if set(df_test[feature].unique()) - set(df_train[feature].unique()):\n        print(f\"Unique value(s) {set(df_test[feature].unique()) - set(df_train[feature].unique())} found in test data\")\n        mew_unique = True\nif not new_unique:\n    print('No new unique values in categoracal variables')","62351ea7":"df_train[num_features].describe()","7bdde2ff":"df_test[num_features].describe()","4a729ec4":"df_train['target'].describe()","3a0fb846":"X = df_train.drop(['target'], axis=1)\ny = df_train['target']\n\nX_test = df_test.copy()\n\n# Preview features\nX.head()","02302ff8":"ordinal_encoder = OrdinalEncoder()\nX[cat_features] = ordinal_encoder.fit_transform(X[cat_features])\nX_test[cat_features] = ordinal_encoder.transform(X_test[cat_features])\n\nX.head()","fb06a7de":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=SEED)","430fa735":"model_results = {'name': [], 'model':[], 'params':[], 'cv_rmse':[], 'time':[]}\n\ndef add_model_result(name, params, model, rmse, time):\n    model_results['name'].append(name)\n    model_results['model'].append(model)\n    model_results['params'].append(params)\n    model_results['cv_rmse'].append(rmse)\n    model_results['time'].append(time)","a987bfc1":"from sklearn.model_selection import GridSearchCV\n\nN_FOLDS = 4\n\n# generate info from grid search\ndef generate_clf(X, y, model, parameters):\n    clf = GridSearchCV(model, parameters, cv=N_FOLDS, scoring='neg_root_mean_squared_error', return_train_score=False, n_jobs=-1)\n    clf.fit(X, y)\n    return -clf.best_score_, clf.best_params_, clf.best_estimator_","b1c8df60":"from sklearn import svm\nfrom sklearn import tree\nfrom sklearn import linear_model\nfrom sklearn import dummy\n\n\nmodel_params = {\n    'Dummy': {\n        'model': dummy.DummyRegressor(),\n        'params' : {\n            'strategy': ('mean', 'median')\n        }  \n    },\n\n    'Linear': {\n        'model': linear_model.LinearRegression(),\n        'params' : {\n            'normalize': (True, False)\n        }  \n    },\n\n    'Desicion Tree': {\n        'model': tree.DecisionTreeRegressor(criterion='mse', random_state=SEED), \n        'params' : {\n            'max_depth': range(3,6),\n            'min_samples_leaf': range(2,9,2),\n            'min_samples_split': (2, 4),\n        }  \n    },\n    \n    'SVM': {\n        'model': svm.SVR(),\n        'params' : {\n            'kernel': ['poly'],\n            'C': [2.5],\n            'degree': [2],\n        }  \n    },\n}","1fe92ee0":"import time as tm\n\nfor model_name, mp in model_params.items():\n    print(model_name)\n    start = tm.time()\n    rmse, params, model = generate_clf(X_train, y_train, mp['model'], mp['params'])\n    time = (tm.time() - start)\n    add_model_result(model_name, params, model, rmse, time)\n    print(f\"Fit time: {time:.0f}s\\n\")\n    \ncv_results = pd.DataFrame(model_results)\ncv_results = cv_results.sort_values('cv_rmse').reset_index(drop=True)","cceed035":"cv_results","a33199a5":"model = cv_results.iloc[0,1]\nmodel.fit(X, y)","1089aab4":"# Use the model to generate predictions\npredictions = model.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","8661d91f":"#### Split data","83505e65":"# Model","c9464b4e":"# Data preproccessing","f33d5a70":"#### Ordinal-encode categorical columns","6c98ecf2":"# EDA","7d46ecaa":"No missing values in dataset\n","64da7b0b":"Separate target from features","d0372fdc":"# Load data and first look","6163511a":"## <center>30 Days of ML competition<\/center>\n### <center>Cross-validation compare Linear, Decision Tree and SVM<\/center>\n\nTry to apply not boosting algotithm such CatBoost or XGBoost.  \nCompare resulting RMSE in validation data and compare time of model training.\n\n#### Dataset:\nThe dataset is used for this competition is synthetic (and generated using a CTGAN), but based on a real dataset. The original dataset deals with predicting the amount of an insurance claim. \n* 'cat0' - 'cat9' categorical features\n* 'cont0' - 'cont13' continuous features\n* 'target' - continous target","95ce26a7":"#### Fit best model get by cross-validation","54089e96":"# Import libraries","54f5eca5":"## Predict and submit","036d670e":"#### Comparison table","49801137":"### Grid Search Cross Validation\nIn cross-validation, we run our modeling process on different subsets of the data to get multiple measures of model quality. For example, we could have 5 folds or experiments. We divide the data into 5 pieces, each being 20% of the full dataset.\nN_FOLDS - number of folds.","185e7340":"Look at continuous features in test dataset","4a98179b":"Look at continuous features in train dataset"}}