{"cell_type":{"f3566a52":"code","b847db9e":"code","3046a699":"code","ce4e6d1f":"code","a7a9457e":"code","2d91efbc":"code","e47b03c9":"code","04e78c50":"code","df140737":"code","ef062f32":"code","abf07f07":"code","4071de4e":"code","af848411":"code","499310f9":"code","c8b7ee28":"code","89b0afd5":"code","020b41cb":"code","dc28cc82":"code","9d06c7a1":"code","92ad317d":"code","560ecc02":"markdown","8bb64643":"markdown","db430c68":"markdown","8cc4e722":"markdown","38f91e8f":"markdown","730f04a1":"markdown","8930d0aa":"markdown"},"source":{"f3566a52":"import zipfile\nwith zipfile.ZipFile(\"..\/input\/test.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"..\/input\/train.zip\",\"r\") as z:\n    z.extractall(\".\")","b847db9e":"from sklearn.model_selection import train_test_split\nimport numpy as np\nimport pywt\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\nfrom glob import glob\nimport scipy\nfrom scipy.signal import butter, lfilter, convolve, boxcar\nfrom scipy.signal import freqz\nfrom scipy.fftpack import fft, ifft\nimport os\n\nfrom sklearn.preprocessing import StandardScaler\n\n\n\ndef wavelet_denoising(x, wavelet='db2', level=3):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1\/0.6745) * madev(coeff[-level])\n    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n    return pywt.waverec(coeff, wavelet, mode='per')\ndef madev(d, axis=None):\n    \"\"\" Mean absolute deviation of a signal \"\"\"\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n#############function to read data###########\n\ndef prepare_data_train(fname):\n    \"\"\" read and prepare training data \"\"\"\n    # Read data\n    data = pd.read_csv(fname)\n    # events file\n    events_fname = fname.replace('_data','_events')\n    # read event file\n    labels= pd.read_csv(events_fname)\n    clean=data.drop(['id' ], axis=1)#remove id\n    labels=labels.drop(['id' ], axis=1)#remove id\n    return  clean,labels\n\ndef prepare_data_test(fname):\n    \"\"\" read and prepare test data \"\"\"\n    # Read data\n    data = pd.read_csv(fname)\n    return data\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nscaler= StandardScaler()\ndef data_preprocess_train(X):\n    X_prep=scaler.fit_transform(X)\n    #do here your preprocessing\n    return X_prep\ndef data_preprocess_test(X):\n    X_prep=scaler.transform(X)\n    #do here your preprocessing\n    return X_prep\nsubjects = range(1,6)\nfrom glob import glob\nimport pandas as pd\nids_tot = []\npred_tot = []\nX_train_butter = []\nfrom sklearn.model_selection import train_test_split\nimport numpy as  np\n\n###loop on subjects and 8 series for train data + 2 series for test data\ny_raw= []\nraw = []\ny_rawt= []\nrawt = []\nfor subject in subjects:\n    \n    ################ READ DATA ################################################\n    fnames =  sorted(glob('train\/subj%d_series*_data.csv' % (subject)))\n\n\n#    fnames =  glob('..\/input\/train\/subj1_series1_events.csv')\n#    fnames =  glob('..\/input\/train\/subj1_series1_data.csv')\n    for fname in fnames:\n      data,labels=prepare_data_train(fname)\n      raw.append(data)\n      y_raw.append(labels)\n\n    for fname in fnames:\n      with open(fname) as myfile:\n        head = [next(myfile) for x in range(10)]\n        \n\n      \n        \nX = pd.concat(raw)\ny = pd.concat(y_raw)\n    #transform in numpy array\n    #transform train data in numpy array\nX_train =np.asarray(X.astype(float))\ny_train = np.asarray(y.astype(float))\n\n\n\nfrom sklearn.preprocessing import StandardScaler,Normalizer,MinMaxScaler\nscaler= StandardScaler()\ndef data_preprocess_train(X):\n    X_prep=scaler.fit_transform(X)\n    #do here your preprocessing\n    return X_prep\nfs = 500.0\nlowcut = 7.0\nhighcut = 30.0\n\n\nx_train_butter=wavelet_denoising(X_train)\nx_train=data_preprocess_train(x_train_butter)\nsplitrate=-x_train.shape[0]\/\/5*2\nxval=x_train[splitrate:splitrate\/\/2]\nyval=y_train[splitrate:splitrate\/\/2]\nxtest=x_train[splitrate\/\/2:]\nytest=y_train[splitrate\/\/2:]\nxtrain=x_train[:splitrate]\nytrain=y_train[:splitrate]\n","3046a699":"import pywt\nimport pandas as pd\nimport numpy as np\ndef wavelet_denoising(x, wavelet='db2', level=3):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1\/0.6745) * madev(coeff[-level])\n    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n    return pywt.waverec(coeff, wavelet, mode='per')\ndef madev(d, axis=None):\n    \"\"\" Mean absolute deviation of a signal \"\"\"\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\nsignal=pd.read_csv('train\/subj1_series1_data.csv')\nsignal = signal.drop(\"id\", axis=1)\nfiltered = wavelet_denoising(signal, wavelet='db2', level=3)\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots(figsize=(8,5))\nax.plot(signal.iloc[:10000,1], label='signal', color=\"b\", alpha=0.5,)\nax.plot(filtered[:10000,1], label='reconstructed signal',color=\"k\")\nax.legend(loc='upper left')\nax.set_title('Denoising with DWT')\nplt.show()","ce4e6d1f":"import seaborn as sns\nye=pd.DataFrame(y_train)\n\nye.columns=[\"Handstart \",\"Grasping \",\"Lift \",\"Hold \",\"Replace \",\"Release\"]\ncategories = list(ye.columns.values)\nsns.set(font_scale = 1)\nplt.figure(figsize=(15,8))\nax= sns.barplot(categories, ye.iloc[:,0:].sum().values)\nplt.title(\"Number of samples labeled as active (1) out of {0} length data\".format((ye.shape[0])),fontsize=20)\n\nplt.ylabel('Number of events', fontsize=18)\nplt.xlabel('Event Type ', fontsize=12)\n#adding the text labels\nrects = ax.patches\nlabels = ye.iloc[:,0:].sum().values\n\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()\/2, height + 5, label, ha='center', va='bottom', fontsize=10)\nplt.show()","a7a9457e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM, BatchNormalization, Conv2D, Flatten, MaxPooling2D, Dropout\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\nimport tensorflow as tf","2d91efbc":"import numpy as np\nload = 1\ntime_steps = 1000\nsubsample = 50\nmodel = Sequential()\nmodel.add(Conv2D(filters = 64, kernel_size = (7,7), padding = \"same\", activation = \"relu\", input_shape = (time_steps\/\/subsample, 32, 1)))\nmodel.add(BatchNormalization())\n#model.add(MaxPooling2D(pool_size = (3,3)))\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5), padding = \"same\", activation = \"relu\", input_shape = (time_steps\/\/subsample, 32, 1)))\nmodel.add(BatchNormalization())\n#model.add(MaxPooling2D(pool_size = (3,3)))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\", input_shape = (time_steps\/\/subsample, 32, 1)))\nmodel.add(BatchNormalization())\n#model.add(MaxPooling2D(pool_size = (3,3)))\nmodel.add(Flatten())\n#model.add(Dropout(0.2))\nmodel.add(Dense(32, activation = \"relu\"))\nmodel.add(BatchNormalization())\n# model.add(Dropout(0.2))\nmodel.add(Dense(6, activation = \"sigmoid\"))\n\n\nadam = Adam(lr = 0.0001)\n\nmodel.compile(optimizer = adam, loss = \"binary_crossentropy\", metrics = ['accuracy','mse'])\n\nmodel.summary()\n","e47b03c9":"\n\ndef valgenerator():\n    while 1:\n        batch_size=32\n        x_time_data = np.zeros((batch_size, time_steps\/\/subsample, 32))\n        yy = []\n        for i in range(batch_size):\n            random_index = np.random.randint(0, len(xval)-time_steps)\n            x_time_data[i] = xval[random_index:random_index+time_steps:subsample]\n            yy.append(yval[random_index + time_steps])\n        yy = np.asarray(yy)\n        yield x_time_data.reshape((x_time_data.shape[0],x_time_data.shape[1], x_time_data.shape[2],1)), yy\n    ","04e78c50":"import time\nstart=time.time()\ndef generator(batch_size):\n    while 1:\n        \n        x_time_data = np.zeros((batch_size, time_steps\/\/subsample, 32))\n        yy = []\n        for i in range(batch_size):\n            random_index = np.random.randint(0, len(xtrain)-time_steps)\n            x_time_data[i] = xtrain[random_index:random_index+time_steps:subsample]\n            yy.append(ytrain[random_index + time_steps])\n        yy = np.asarray(yy)\n        yield x_time_data.reshape((x_time_data.shape[0],x_time_data.shape[1],  x_time_data.shape[2],1)), yy\n        \nhistory =model.fit_generator(generator(32), steps_per_epoch = 600, epochs = 50,validation_data=valgenerator(),\n                              validation_steps=200)\n\nprint('training time taken: ',round(time.time()-start,0),'seconds')\n","df140737":"def plot_training_history(history):\n    acc = history.history['acc']\n    loss = history.history['loss']\n    val_acc = history.history['val_acc']\n    val_loss = history.history['val_loss']\n    epochs = range(len(acc))\n \n    plt.figure(figsize=(15, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'b', label='Training acc',linewidth=2)\n    plt.plot(epochs, val_acc, 'r--', label='Validation acc',linewidth=2)\n    plt.title('Training  accuracy')\n    plt.legend()\n \n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'k', label='Validationloss ')\n    plt.title('Training loss')\n    plt.legend()\n \n    plt.show()\nplot_training_history(history)","ef062f32":"time_steps = 1000\nsubsample = 50\ndef val_generator():\n    while 1:\n        batch_size = 1\n        x_time_data = np.zeros((batch_size, time_steps\/\/subsample, 32))\n        yy = []\n        for i in range(batch_size):\n            random_index = np.random.randint(0, len(xtest)-time_steps)\n            x_time_data[i] = xtest[random_index:random_index+time_steps:subsample]\n            yy.append(ytest[random_index + time_steps])\n        yy = np.asarray(yy)\n        yield x_time_data.reshape((x_time_data.shape[0],x_time_data.shape[1], x_time_data.shape[2], 1)), yy","abf07f07":"gen_data = val_generator()\nscores = []\nnum_test =5000\nfor i in range(num_test):\n    x_test, y_test = next(gen_data)\n   # print(y_test)\n    while not 1 in y_test:\n     #   print(x_test)\n        x_test, y_test = next(gen_data)\n    score=model.evaluate(x_test, y_test, verbose=0)\n\n    scores.append(score[1])\nscores = np.asarray(scores)\n\nprint(\"Accuracy \", np.mean(scores))\n\n# we need to use values.ravel to ensure the labels are sent to classifier correctly\n\n\n","4071de4e":"from sklearn.metrics import roc_curve, auc\nfrom sklearn import datasets\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import label_binarize\n#from sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nl=[\"Handstart (HS)\",\"Grasping (GS)\",\"Lift (LT)\",\"Hold (HD)\",\"Replace (RP)\",\"Release (RL)\"]\nnum_test =5000\ny_score=np.zeros((num_test, 6))\ny_test=np.zeros((num_test, 6))\n\nfor i in range(num_test):\n    x_test, y_test[i,:] = next(gen_data)\n\n    while not 1 in y_test:\n     #   print(x_test)\n        x_test, y_test[i,:]  = next(gen_data)\n    y_score[i,:]= model.predict(x_test)\n    \n    \n\n\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(6):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    \n    \n    \nprint(\"roc_auc:\",sum(roc_auc.values())\/6)\n","af848411":"l=[\"Handstart (HS)\",\"Grasping (GS)\",\"Lift (LT)\",\"Hold (HD)\",\"Replace (RP)\",\"Release (RL)\"]\nfor i in range(0,6):\n    plt.figure()\n    plt.plot(fpr[i], tpr[i],linewidth=3)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('%s -ROC curve (area = %0.2f)' % (l[i],roc_auc[i]),fontsize= 15)\n    plt.legend(loc=\"lower right\")\n    plt.show()","499310f9":"time_steps = 1000\nsubsample = 10\nmodel3 = Sequential()\nmodel3.add(LSTM(64,input_shape = (time_steps\/\/subsample, 32), return_sequences=True))\nmodel3.add(Dropout(0.5))\nmodel3.add(LSTM(64,input_shape = (time_steps\/\/subsample, 32), return_sequences=True))\nmodel3.add(Dropout(0.5))\nmodel3.add(LSTM(64,input_shape = (time_steps\/\/subsample, 32), return_sequences=True))\nmodel3.add(Dropout(0.5))\nmodel3.add(LSTM(64))\nmodel3.add(Dense(6, activation='sigmoid'))\nmodel3.compile(loss='binary_crossentropy', optimizer= Adam(lr = 0.0001), metrics=['accuracy'])\nmodel3.summary()","c8b7ee28":"\n\ndef valgenerator():\n    while 1:\n        batch_size=32\n        x_time_data = np.zeros((batch_size, time_steps\/\/subsample, 32))\n        yy = []\n        for i in range(batch_size):\n            random_index = np.random.randint(0, len(xval)-time_steps)\n            x_time_data[i] = xval[random_index:random_index+time_steps:subsample]\n            yy.append(yval[random_index + time_steps])\n        yy = np.asarray(yy)\n        yield x_time_data, yy\n    ","89b0afd5":"import time\nstart=time.time()\ndef generator(batch_size):\n    while 1:\n        \n        x_time_data = np.zeros((batch_size, time_steps\/\/subsample, 32))\n        yy = []\n        for i in range(batch_size):\n            random_index = np.random.randint(0, len(xtrain)-time_steps)\n            x_time_data[i] = xtrain[random_index:random_index+time_steps:subsample]\n            yy.append(ytrain[random_index + time_steps])\n        yy = np.asarray(yy)\n        yield x_time_data, yy\n\nhistory =model3.fit_generator(generator(32), steps_per_epoch = 200, epochs = 50,validation_data=valgenerator(),\n                              validation_steps=100)\nprint('training time taken: ',round(time.time()-start,0),'seconds')","020b41cb":"def plot_training_history(history):\n    acc = history.history['acc']\n    loss = history.history['loss']\n    val_acc = history.history['val_acc']\n    val_loss = history.history['val_loss']\n    epochs = range(len(acc))\n \n    plt.figure(figsize=(15, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'r--', label='Validation acc')\n    plt.title('Training  accuracy')\n    plt.legend()\n \n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r--', label='Validation loss')\n    plt.title('Training loss')\n    plt.legend()\n \n    plt.show()\nplot_training_history(history)","dc28cc82":"time_steps = 1000\nsubsample = 10\ndef val_generator():\n    while 1:\n        batch_size = 1\n        x_time_data = np.zeros((batch_size, time_steps\/\/subsample, 32))\n        yy = []\n        for i in range(batch_size):\n            random_index = np.random.randint(0, len(xtest)-time_steps)\n            x_time_data[i] = xtest[random_index:random_index+time_steps:subsample]\n            yy.append(ytest[random_index + time_steps])\n        yy = np.asarray(yy)\n        yield x_time_data, yy","9d06c7a1":"l=[\"Handstart (HS)\",\"Grasping (GS)\",\"Lift (LT)\",\"Hold (HD)\",\"Replace (RP)\",\"Release (RL)\"]\nfor i in range(0,6):\n    plt.figure()\n    plt.plot(fpr[i], tpr[i],linewidth=3)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('%s -ROC curve (area = %0.2f)' % (l[i],roc_auc[i]),fontsize= 15)\n    plt.legend(loc=\"lower right\")\n    plt.show()","92ad317d":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# data to plot\nn_groups = 6 \nmeans_cnn = (59,56,60,58,64,67)\nmeans_lstm = (53,51,51,54,50,54)\n           \n# create plot\nfig, ax = plt.subplots()\n\nindex = np.arange(n_groups)\nbar_width = 0.35\nopacity = 0.8\n\nrects1 = plt.bar(index, means_cnn, bar_width,color='royalblue', alpha=0.8,label='CNN')\n\nrects2 = plt.bar(index - bar_width, means_lstm, bar_width,align='center', alpha=0.6, color = 'r',label='LSTM')\n\nplt.xlabel('Event')\nplt.ylabel('AUC Scores')\nplt.title('AUC scores by event')\nplt.xticks(index + bar_width, (\"Handstart \",\"Grasping \",\"Lift\",\"Hold\",\"Replace\",\"Release\"))\nplt.legend()\n\nplt.tight_layout()\nplt.show()","560ecc02":"**Testing only the points where events are active** ","8bb64643":"## Wavelet Denoising","db430c68":"## CNN ","8cc4e722":"## LSTM ","38f91e8f":"## Testing with unseen data","730f04a1":"**Testing only the points where events are active** ","8930d0aa":"## Testing with unseen data"}}