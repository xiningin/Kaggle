{"cell_type":{"e9162105":"code","4382acd5":"code","6bfc764c":"code","def46788":"code","b81810ce":"code","cc09feb6":"code","d70d9e56":"code","444565a4":"code","a0760895":"code","ecbf7429":"code","aeec11a8":"code","fb1dc147":"code","500bcd36":"code","954d6f9e":"code","e88d3ef4":"code","fe0ce15a":"code","6cbcab0b":"code","b91257c9":"code","19d334a0":"code","708fcf74":"code","ab373f25":"code","a9ececa5":"code","6f5ebfdb":"code","615d9bd0":"code","1c56a896":"code","c3cc4d80":"code","f3f4c7a6":"markdown","b24200ec":"markdown","48284ba3":"markdown","f7bbf1fa":"markdown","51407910":"markdown","d82b896f":"markdown","2cff0491":"markdown","2d086aad":"markdown","8f9434d4":"markdown","ba8eb699":"markdown","ddf9548d":"markdown","fb960b67":"markdown","5125c7c7":"markdown","9b1013fc":"markdown","50ed51e6":"markdown","30a04ab7":"markdown"},"source":{"e9162105":"# https:\/\/pypi.org\/project\/pandas\/\nimport pandas as pd\n\n# https:\/\/numpy.org\/\nimport numpy as np\n\n# https:\/\/matplotlib.org\/\nimport matplotlib.pyplot as plt\n\n# https:\/\/seaborn.pydata.org\/\nimport seaborn as sns\n\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html\nfrom sklearn.model_selection import train_test_split\n\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LinearRegression.html\nfrom sklearn.linear_model import LinearRegression\n\n# https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n# https:\/\/docs.python.org\/3\/library\/math.html\nfrom math import sqrt\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom catboost import CatBoostRegressor","4382acd5":"# Realiza um pr\u00e9-processamento b\u00e1sico no dataframe.\ndef preparar_dataset(df_pre, y_column_name):\n    # Remove os atributos com baixa correla\u00e7\u00e3o com o alvo (price).\n    # Fique \u00e0 vontade para incluir ou retirar atributos que julgar relevantes aos resultados.\n    df_pre.drop(['id', 'host_name', 'amenities'], axis=1, inplace=True)\n\n    y_column = df_pre.pop(y_column_name)\n\n    categorical_features_index = np.where(df_pre.dtypes == object)[0]\n\n    # Converte os atributos categ\u00f3ricos em quantitativos discretos.\n    for column in df_pre.columns:\n        if str(df_pre[column].dtype) not in ['float64', 'int64', 'Sparse[int32, 0]', 'Sparse[int64, 0]']:\n            valores_unicos = df_pre[column].unique().tolist()\n            df_pre[column] = df_pre[column].map(dict(zip(valores_unicos, range(len(valores_unicos)))))\n\n    df_pre[y_column_name] = y_column\n\n    return df_pre, categorical_features_index","6bfc764c":"# Calcula m\u00e9tricas de desempenho do classificador. \n# Fique \u00e0 vontade para incluir outras m\u00e9tricas que julgar \u00fateis na avali\u00e7\u00e3o dos resultados.\ndef get_metrics(y_test, y_pred):  \n\n    rmse = round(sqrt(mean_squared_error(y_test, y_pred)), 4)\n    r2 = round(r2_score(y_test, y_pred), 4)\n\n    return rmse, r2","def46788":"# Semente aleat\u00f3ria a ser usada ao longo desse notebook.\n# Procure manter sempre a mesma semente aleat\u00f3ria. Desse modo, poder\u00e1 comparar a evolu\u00e7\u00e3o entre diferentes t\u00e9cnicas.\nrandom_state = 2020\n\n# N\u00famero de folds para valida\u00e7\u00e3o cruzada e itera\u00e7\u00f5es (\u00e1rvores de decis\u00e3o) do gradient boosting\nn_splits = 5\ncb_iterations = 10000\n\ndata_dir = '..\/input\/desafioiamp2020\/'\n\n# Nome do arquivo fornecido pelo desafio com os dados rotulados para treino.\nnome_arquivo_com_rotulos_para_treino = data_dir + 'treino.csv'\n\n# Nome do arquivo fornecido pelo desafio com os dados n\u00e3o rotulados, que dever\u00e3o ser analisados pelo modelo constru\u00eddo aqui.\nnome_arquivo_sem_rotulos = data_dir + 'teste.csv'\n\n# Nome do arquivo que ser\u00e1 criado com os r\u00f3tulos gerados pelo modelo\n# Esse \u00e9 o arquivo se ser\u00e1 submetido \u00e0 p\u00e1gina do desafio.\nnome_arquivo_rotulado_regressor = f'..\/working\/submissao-{n_splits}f-{cb_iterations}.csv'","b81810ce":"df = pd.read_csv(nome_arquivo_com_rotulos_para_treino, index_col=None, engine='python', sep =';', encoding=\"utf-8\")\nprint(f'Total de registros carregados para treino: {len(df)}')\n\n# Exibe uma amostra dos dados.\ndf.head()","cc09feb6":"# Carrega os dados da base n\u00e3o rotulada.\ndf_subm = pd.read_csv(nome_arquivo_sem_rotulos, index_col=None, engine='python', sep =';', encoding=\"utf-8\")\nprint(f'Total de registros carregados para submiss\u00e3o: {len(df_subm)}')","d70d9e56":"# Salvando a coluna 'id', para montar o arquivo de envio ao final da execu\u00e7\u00e3o.\nid_col = df_subm['id']","444565a4":"df_tudo = pd.concat((df, df_subm), axis=0, ignore_index=True, sort=False)","a0760895":"df_tudo['id_intervalo'] = df_tudo['id'].floordiv(250)","ecbf7429":"localizacao_num_cols = ['latitude', 'longitude']\npca_loc = PCA(n_components=2, random_state=random_state).fit(df_tudo[localizacao_num_cols])\ndf_tudo.loc[:,'localizacao_pca'] = pca_loc.transform(df_tudo[localizacao_num_cols])[:,0]","aeec11a8":"def nova_coluna_total(df, nova_total, nome_media, nome_quant):\n    df.loc[:, nova_total] = df[nome_media] * df[nome_quant]\n    return df[nova_total]\n\ndef nova_coluna_div(df, nova, nome_pri, nome_seg, valor_na):\n    df.loc[:, nova] = df[nome_pri] \/ df[nome_seg]\n    df[nova].fillna(valor_na, inplace = True)\n\ncols_review_media_total = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']\nfor col_review_total in cols_review_media_total:\n    nova_coluna_total(df_tudo, col_review_total + '_total', col_review_total, 'number_of_reviews')\n\nnova_coluna_div(df_tudo, 'months_provaveis', 'number_of_reviews', 'reviews_per_month', 0)\nnova_coluna_div(df_tudo, 'beds_por_bedrooms', 'beds', 'bedrooms', 0)","fb1dc147":"# Separa\u00e7\u00e3o do texto de comodidades em itens de uma lista\ndf_tudo['amenities_list'] = df_tudo['amenities'].str[1:-1].str.replace(', ', ' ').str.replace('\"', '').str.split(',')\ndf_tudo['amenities_list']","500bcd36":"# Transforma\u00e7\u00e3o das listas de comodidades em one-hot-encoding\n\ndef obter_mbl(df_pre, coluna, min):\n    mlb_one_hot_enc = MultiLabelBinarizer(sparse_output=True)\n\n    df_one_hot_enc = pd.DataFrame.sparse.from_spmatrix(\n        mlb_one_hot_enc.fit_transform(df_pre[coluna]),\n        index=df_pre.index,\n        columns=mlb_one_hot_enc.classes_)\n\n    valores_populares = [[c] for c in df_one_hot_enc.columns if len(c) > 0 and df_one_hot_enc[c].value_counts()[1] > min]\n\n    mlb_popular = MultiLabelBinarizer(sparse_output=True)\n    mlb_popular.fit(valores_populares)\n    return mlb_popular\n\n# Obten\u00e7\u00e3o de comodidades com mais de 100 ocorr\u00eancias (treino e envio)\nmbl_amenities = obter_mbl(df_tudo, 'amenities_list', 100)","954d6f9e":"df_tudo = df_tudo.join(\n            pd.DataFrame.sparse.from_spmatrix(\n                mbl_amenities.transform(df_tudo.pop('amenities_list')),\n                index=df_tudo.index,\n                columns=mbl_amenities.classes_))","e88d3ef4":"df_tudo.head()","fe0ce15a":"df_tudo, cat_feat_index = preparar_dataset(df_tudo, 'price')\ndf_tudo.head()","6cbcab0b":"subm_count = len(df_subm)\ntrain_count = len(df_tudo) - subm_count\n\ndf = df_tudo[:train_count]\ndf_subm = df_tudo[train_count:]\ndf_subm.reset_index(drop=True, inplace=True)\ndf_subm.drop(['price'], axis=1, inplace=True)","b91257c9":"df.head()","19d334a0":"corr = df.corr()","708fcf74":"k = 20 # n\u00famero de atributos no heatmap\ncols = corr.abs().nlargest(k, 'price')['price'].index\ncm = np.corrcoef(df[cols].values.T)\nplt.figure(figsize=(20,12))\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values, vmin=-.7, vmax=.7)\nplt.show()","ab373f25":"corr.iloc[(-np.abs(corr['price'].values)).argsort()]['price'].head(30)","a9ececa5":"# Treina o modelo com a massa de treino.\nX_train = pd.DataFrame(df.drop(['price'], axis=1))\ny_train = df['price']","6f5ebfdb":"X_test = df_subm","615d9bd0":"%%time\nkfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\ny_preds = []\nscores = []\nfor fold, (tr_ind, val_ind) in enumerate(kfold.split(X_train, y_train)):\n    X_train_split, X_val_split = X_train.iloc[tr_ind], X_train.iloc[val_ind]\n    y_train_split, y_val_split = y_train.iloc[tr_ind], y_train.iloc[val_ind]\n\n    catboost = CatBoostRegressor(iterations=cb_iterations, cat_features=cat_feat_index, random_state=random_state, verbose=False)\n    catboost.fit(X_train_split, y_train_split, eval_set=(X_val_split, y_val_split))\n\n    # Avalia a performance do modelo treinado usando a massa reservada para testes no fold.\n    y_val_split_pred = catboost.predict(X_val_split)\n    rmse, r2 = get_metrics(y_val_split, y_val_split_pred)\n    print(f'{fold + 1} - RMSE: {rmse} \/ R\u00b2: {r2}')\n    scores.append(rmse)\n\n    # Realiza a predi\u00e7\u00e3o dos dados de envio\n    y_pred = catboost.predict(X_test)\n    y_preds.append(y_pred)\n\nprint(f'M\u00e9dia RMSE: {sum(scores) \/ len(scores)}')\n\n# O resultado final ser\u00e1 a m\u00e9dia de todas as predi\u00e7\u00f5es\ny_pred_final = np.mean(y_preds, axis=0)","1c56a896":"# Executa a predi\u00e7\u00e3o dos registros n\u00e3o rotulados\ndf_subm['id'] = id_col\ndf_subm['price'] = y_pred_final\ndf_subm['price'] = df_subm['price'].round(decimals=2)\n\n# Exibe uma amostra dos resultados\ndf_subm.head(10)","c3cc4d80":"# Salva os registros classificados\ndf_subm.to_csv(nome_arquivo_rotulado_regressor, index=False, sep=\",\", encoding=\"utf-8\", columns=['id','price'])","f3f4c7a6":"# Fun\u00e7\u00f5es\n","b24200ec":"# Inicializa\u00e7\u00e3o","48284ba3":"# Analisando os registros n\u00e3o rotulados para o desafio","f7bbf1fa":"# Analisando a correla\u00e7\u00e3o entre os atributos\nNessa etapa, vamos analisar a correla\u00e7\u00e3o entre os atributos, principalmente em rela\u00e7\u00e3o ao pre\u00e7o. A correla\u00e7\u00e3o permite identificar varia\u00e7\u00f5es proporcionais ou inversamente proporcionais entre duas vari\u00e1veis, e se essas varia\u00e7\u00e3o \u00e9 forte ou fraca. Quanto maior a correla\u00e7\u00e3o, direta ou inversa, maior \u00e9 a influ\u00eancia que esse atributo exerce na predi\u00e7\u00e3o da outra, ou seja, do atributo alvo.","51407910":"# Preparando os dados para a predi\u00e7\u00e3o\nA prepara\u00e7\u00e3o dos dados \u00e9 uma das etapas mais importantes para se obter uma boa performance na modelagem preditiva, e pode significar a diferen\u00e7a entre o sucesso e o fracasso de um projeto.\n\nProcure expandir a prepara\u00e7\u00e3o b\u00e1sica oferecida aqui de forma a melhorar o desempenho do regressor. Vale analisar tudo o que pode estar contribuindo para confundir os algoritmos de regress\u00e3o e assim prejudicar sua acur\u00e1cia.","d82b896f":"# Escolhendo um modelo preditivo, treinando e testando o modelo\n\nFoi escolhida a biblioteca Catboost (CatBoostRegressor, modelo gradient boosting para regress\u00e3o).\n\nAbaixo, foi realizada a valida\u00e7\u00e3o cruzada com 5 folds.\n\nPara cada fold, foi criada uma inst\u00e2ncia do modelo com 10000 itera\u00e7\u00f5es (\u00e1rvores de decis\u00e3o).\n\nO resultado final foi a m\u00e9dia das predi\u00e7\u00f5es feitas por todas as inst\u00e2ncias.","2cff0491":"# Carregando os dados rotulados","2d086aad":"# Bibliotecas Utilizadas\n","8f9434d4":"## Refaz separa\u00e7\u00e3o entre dados de treino e de envio","ba8eb699":"## Realiza jun\u00e7\u00e3o dos dados de treino e de envio para prepara\u00e7\u00e3o e normaliza\u00e7\u00e3o","ddf9548d":"## Comodidades (amenities)","fb960b67":"## Totais e divis\u00f5es","5125c7c7":"# Desafio IA SERPRO 2020 - MP\n\nOs participantes tem nesse notebook um exemplo bem b\u00e1sico de como proceder em rela\u00e7\u00e3o ao desafio proposto, e um ponto de partida para a explora\u00e7\u00e3o de estrat\u00e9gias mais sofisticadas.\n\nAs t\u00e9cnicas aqui utilizadas s\u00e3o bem simples, e provavelmente n\u00e3o ser\u00e3o as mais adequadas para o problema. Os resultados aqui obtidos servem apenas como uma baseline a ser superada.","9b1013fc":"# Submetendo os resultados \u00e0 p\u00e1gina do desafio\nO arquivo de resultados no passo anterior deve ser submetido na plataforma de avali\u00e7\u00e3o do desafio. Assim que avaliado, a pontua\u00e7\u00e3o ser\u00e1 exibida no leaderboard.\n\n# Boa Sorte!!","50ed51e6":"## PCA","30a04ab7":"## Separa\u00e7\u00e3o dos IDs em intervalos para an\u00e1lise temporal"}}