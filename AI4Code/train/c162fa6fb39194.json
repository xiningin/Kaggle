{"cell_type":{"2e7cd3d4":"code","60af1e58":"code","bbb2f9e2":"code","e9191e5c":"code","32804019":"code","fe4b73af":"code","590d75b6":"code","15b2f2d4":"code","6d73d2d2":"code","0610d390":"code","d971c134":"code","4fd6ad05":"code","03a6e0fa":"code","12f8a1fa":"code","d1c7aa9a":"code","bbd32f65":"code","c6e48b9e":"code","95cd62a1":"code","a922bb80":"code","57e1210d":"code","61cb681b":"code","a8ee4572":"code","4e83630d":"code","5e2fda95":"code","dac6b78b":"code","b1ac3920":"code","fc749a5f":"code","789d277a":"code","496798a0":"code","974f17a2":"markdown"},"source":{"2e7cd3d4":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nfrom pandas.io.json import json_normalize\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn import model_selection, preprocessing, metrics\nimport lightgbm as lgb\nimport datetime","60af1e58":"# Using Julian kernal for convert all the json fields in the file to a flattened csv format\ndef load_df(csv_path=r'..\/input\/train_v2.csv', nrows=400000):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'}, # Important!!\n                     nrows=nrows)\n    \n    for column in JSON_COLUMNS:\n        #column_as_df = json_normalize(df[column])\n        column_as_df = json_normalize(list(df[column]))\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n    return df","bbb2f9e2":"%%time\ntrain = load_df()\ntrain.head()","e9191e5c":"test = load_df(\"..\/input\/test_v2.csv\")\ntrain.head()","32804019":"all_data = train.append(test, sort=False).reset_index(drop=True)","fe4b73af":"all_data[\"totals.transactionRevenue\"] = all_data[\"totals.transactionRevenue\"].astype('float')","590d75b6":"all_data.describe()","15b2f2d4":"for c in train.columns.values:\n    if c not in test.columns.values: print(c)","6d73d2d2":"null_cnt = all_data.isnull().sum().sort_values()\nprint(null_cnt[null_cnt > 0])","0610d390":"constant_column = [col for col in all_data.columns if all_data[col].nunique() == 1]","d971c134":"constant_column","4fd6ad05":"cols_to_drop = constant_column + ['sessionId'] + [\"trafficSource.campaignCode\"]","03a6e0fa":"all_data = all_data.drop(cols_to_drop , axis=1)","12f8a1fa":"all_data.head()","d1c7aa9a":"cat_cols = [\"channelGrouping\", \"device.browser\", \n            \"device.deviceCategory\", \"device.operatingSystem\", \n            \"geoNetwork.city\", \"geoNetwork.continent\", \n            \"geoNetwork.country\", \"geoNetwork.metro\",\n            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \n            \"trafficSource.adwordsClickInfo.adNetworkType\", \n            \"trafficSource.adwordsClickInfo.gclId\", \n            \"trafficSource.adwordsClickInfo.page\", \n            \"trafficSource.adwordsClickInfo.slot\", \"trafficSource.campaign\",\n            \"trafficSource.keyword\", \"trafficSource.medium\", \n            \"trafficSource.referralPath\", \"trafficSource.source\"]","bbd32f65":"for col in cat_cols:\n    print(col)\n    le = preprocessing.LabelEncoder()\n    le.fit(list(all_data[col].values.astype('str')))\n    all_data[col] = le.transform(list(all_data[col].values.astype('str')))    ","c6e48b9e":"all_data.info()","95cd62a1":"#num_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", \"visitStartTime\", 'totals.bounces',  'totals.newVisits']    \nnum_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", \"visitStartTime\"]    \nfor col in num_cols:\n    all_data[col] = all_data[col].astype(float)","a922bb80":"train_df = all_data[all_data['totals.transactionRevenue'].notnull()]\ntest_df = all_data[all_data['totals.transactionRevenue'].isnull()].drop(['totals.transactionRevenue'], axis=1)","57e1210d":"train_id = train_df['fullVisitorId']\ntest_id = test_df['fullVisitorId']","61cb681b":"train_df['date'] = train_df['date'].apply(lambda x: datetime.date(int(str(x)[:4]), int(str(x)[4:6]), int(str(x)[6:])))\ndev_df = train_df[train_df['date']<=datetime.date(2017,5,31)]\nval_df = train_df[train_df['date']>datetime.date(2017,5,31)]\ndev_y = np.log1p(dev_df[\"totals.transactionRevenue\"].values)\nval_y = np.log1p(val_df[\"totals.transactionRevenue\"].values)","a8ee4572":"dev_df.info()","4e83630d":"dev_X = dev_df[cat_cols + num_cols] \nval_X = val_df[cat_cols + num_cols] \ntest_X = test_df[cat_cols + num_cols]","5e2fda95":"# custom function to run light gbm model\ndef run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\", \n        \"num_leaves\" : 30,\n        \"min_child_samples\" : 100,\n        \"learning_rate\" : 0.1,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.5,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 2018,\n        \"verbosity\" : -1\n    }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=100)\n    \n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    pred_val_y = model.predict(val_X, num_iteration=model.best_iteration)\n    return pred_test_y, model, pred_val_y","dac6b78b":"# Training the model #\npred_test, model, pred_val = run_lgb(dev_X, dev_y, val_X, val_y, test_X)","b1ac3920":"from sklearn import metrics\npred_val[pred_val<0] = 0\nval_pred_df = pd.DataFrame({\"fullVisitorId\":val_df[\"fullVisitorId\"].values})\nval_pred_df[\"transactionRevenue\"] = val_df[\"totals.transactionRevenue\"].values\nval_pred_df[\"PredictedRevenue\"] = np.expm1(pred_val)\n#print(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_df[\"transactionRevenue\"].values), np.log1p(val_pred_df[\"PredictedRevenue\"].values))))\nval_pred_df = val_pred_df.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"PredictedRevenue\"].sum().reset_index()\nprint(np.sqrt(metrics.mean_squared_error(np.log1p(val_pred_df[\"transactionRevenue\"].values), np.log1p(val_pred_df[\"PredictedRevenue\"].values))))","fc749a5f":"sub_df = pd.DataFrame({\"fullVisitorId\":test_id})\npred_test[pred_test<0] = 0\nsub_df[\"PredictedLogRevenue\"] = np.expm1(pred_test)\nsub_df = sub_df.groupby(\"fullVisitorId\")[\"PredictedLogRevenue\"].sum().reset_index()\nsub_df.columns = [\"fullVisitorId\", \"PredictedLogRevenue\"]\nsub_df[\"PredictedLogRevenue\"] = np.log1p(sub_df[\"PredictedLogRevenue\"])","789d277a":"sub_df.head()","496798a0":"sub_df.to_csv(\"baseline_lgb1.csv\", index=False)","974f17a2":"Google Analytics Customer Revenue Prediction"}}