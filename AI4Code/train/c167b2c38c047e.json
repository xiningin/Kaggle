{"cell_type":{"0ffd98a5":"code","3c3b98d7":"code","4afc5ea4":"code","7c817f39":"code","ef12b321":"code","144967a5":"code","72ff8007":"code","53cb7fa8":"code","b030fe61":"code","8448cd32":"code","eed0d5c9":"code","008f3e53":"code","7f2fe6cb":"code","475b69ab":"code","2804521f":"code","0fb72e96":"code","69dfab4b":"code","ba2e514f":"code","a7a107ab":"code","fcd049ad":"code","e193115e":"code","5785931c":"code","eeb1d1ae":"code","473afbb7":"code","e86474fe":"code","1fb7a663":"code","e5f57103":"code","930ce35d":"code","b0b99250":"code","de55ea1a":"code","0e15ccb9":"code","25a1a987":"code","25d5e040":"code","a9aff11c":"code","72459e52":"code","c1470cea":"code","ddf6d8ca":"code","665be1d6":"code","af2a850a":"code","6bbce724":"code","71d8bb77":"code","0a1a1c66":"code","6f21b51e":"code","4d46ea09":"code","762433fd":"code","0befb966":"code","bd7725d3":"code","358f2f32":"code","d6a7de49":"code","5ae9c52b":"code","9c0e3a8b":"code","62963dfd":"code","ef1b3dca":"code","8ebb4404":"code","0184420d":"code","351b487a":"code","925c443e":"code","5c0645ef":"code","8bcbd104":"code","85955660":"code","5994b099":"code","c5b766de":"code","ff2d02d6":"code","9a19f8dc":"code","9dc9e4b4":"code","4b686d78":"code","df8b2ad7":"code","6915076d":"code","c1452c63":"code","ed06319e":"code","c84e59cb":"code","5e17e73c":"code","1a17ac1d":"code","77f1f208":"code","69ebf0c3":"code","a33fea1c":"code","1ec0a00e":"code","2a692c10":"code","2833aa46":"code","fa770895":"code","c56a481c":"code","ad6d7f54":"code","8a65346b":"code","5a088a65":"code","f0009c44":"code","0644284c":"code","eb97e7a5":"code","798ac438":"code","1cfcf5d8":"code","03e0adcb":"markdown","5890eba0":"markdown","0c2dd6cd":"markdown","f5f77475":"markdown","705e065d":"markdown","8aac861c":"markdown","1694dcf0":"markdown","a319796e":"markdown","8b7ac0eb":"markdown","1a1dad4d":"markdown","a9929800":"markdown","bc3987d1":"markdown","5cdeeeb9":"markdown"},"source":{"0ffd98a5":"# COLLECTING  TRAIN DATA AND TEST DATA USING PANDAS\nimport pandas as pd\nimport numpy as np","3c3b98d7":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","4afc5ea4":"train.head()","7c817f39":"test.head(10)","ef12b321":"train.shape","144967a5":"test.shape","72ff8007":"train.info()","53cb7fa8":"test.info()","b030fe61":"train.isnull().sum()","8448cd32":"# IMPORT PYTHON LIBRARY FOR VISUALISATION\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n% matplotlib inline","eed0d5c9":"def bar_chart(feature):\n    survived = train[train['Survived'] == 1 ] [feature].value_counts()\n    dead = train[train['Survived'] == 0] [feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind = 'bar',stacked = True ,figsize = (10,5))","008f3e53":"bar_chart('Pclass')              ","7f2fe6cb":"bar_chart('Sex')    # FEMALE ARE MORE LIKELY TO SURVIVE THAN MEN","475b69ab":"bar_chart('SibSp')","2804521f":"bar_chart('Parch')","0fb72e96":"bar_chart('Embarked')","69dfab4b":"train.head(10)","ba2e514f":"# COMBINING TRAIN DATA AND TEST DATA \ntrain_test_data = [train,test]\nfor data in train_test_data :\n    data['Title'] = data['Name'].str.extract('([A-Za-z]+)\\.',expand = False) # EXTRACTING TITLE FROM NAME","a7a107ab":"train['Title'].value_counts()","fcd049ad":"test['Title'].value_counts()","e193115e":"title_mapping = { 'Mr' : 0 ,'Miss': 1,  'Mrs' : 2,'Master' : 3  ,'Dr' : 3 ,'Rev' : 3, 'Col' : 3 ,\n                 'Major' :3 , 'Mlle' : 3 ,'Mme' : 3 ,'Countess' : 3  , 'Sir' : 3  ,'Dona' : 3,'Don' : 3,\n                 'Ms' : 3 ,  'Capt' : 3 ,  'Lady' : 3 ,'Jonkheer' : 3 }     \nfor data in train_test_data:\n    data['Title'] = data['Title'].map(title_mapping)","5785931c":"train.head()","eeb1d1ae":"test.head()","473afbb7":"bar_chart('Title')","e86474fe":"# delete unnecessary feature from dataset\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","1fb7a663":"train.head()","e5f57103":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","930ce35d":"train.head()","b0b99250":"test.head()","de55ea1a":"bar_chart('Sex')","0e15ccb9":"train.info() # age are missing so fill the missing age","25a1a987":"train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","25d5e040":"train.head(30)\ntrain.groupby(\"Title\")[\"Age\"].transform(\"median\")","a9aff11c":"train.info()","72459e52":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\n \nplt.show()","c1470cea":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","ddf6d8ca":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","665be1d6":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(30, 40)","af2a850a":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","6bbce724":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(60)","71d8bb77":"for dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","0a1a1c66":"train.head()","6f21b51e":"bar_chart('Age')","4d46ea09":"Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","762433fd":"# filling missing value in Embarked with S\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","0befb966":"train.head()","bd7725d3":"train.info()","358f2f32":"# EMBARKED MAPPING\nembarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","d6a7de49":"train[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head(20)","5ae9c52b":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n \nplt.show()","9c0e3a8b":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","62963dfd":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 30)","ef1b3dca":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0)","8ebb4404":"for dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","0184420d":"train.head()","351b487a":"train.Cabin.value_counts()","925c443e":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","5c0645ef":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","8bcbd104":"# cabin mapping\ncabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","85955660":"# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","5994b099":"train.info()","c5b766de":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","ff2d02d6":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","9a19f8dc":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","9dc9e4b4":"train.head()","4b686d78":"unecessary_feature = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(unecessary_feature, axis=1)\ntest = test.drop(unecessary_feature, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","df8b2ad7":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","6915076d":"train_data.head(5)","c1452c63":"# MODELLING","ed06319e":"# IMPORTING CLASSIFIERS MODULES\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","c84e59cb":"# CROSS VALIDATION\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","5e17e73c":"# kNN\nknn = KNeighborsClassifier(n_neighbors= 13)\nscoring = 'accuracy'\nscore = cross_val_score(knn,train_data,target,cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","1a17ac1d":"round(np.mean(score)*100,2)","77f1f208":"# DECISION TREE CLASSIFIER\ndtc = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(dtc, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","69ebf0c3":"round(np.mean(score)*100,2)","a33fea1c":"Rfc = RandomForestClassifier( n_estimators= 13)\nscoring = 'accuracy'\nscore = cross_val_score(Rfc, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","1ec0a00e":"round(np.mean(score)*100,2)","2a692c10":"# NAIVE BAYES\nNB = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(NB, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","2833aa46":"round(np.mean(score)*100,2)","fa770895":"# SUPPORT VECTOR MACHINE\nclf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","c56a481c":"round(np.mean(score)*100,2)","ad6d7f54":"# model testing            SVM  IS BEST APPROACH HERE AS THIS METHOD GIVES HIGH S","8a65346b":"test.info()","5a088a65":"test_data = test.drop(\"PassengerId\", axis=1).copy()","f0009c44":"test_data","0644284c":"clf = SVC()\nclf.fit(train_data,target)\nprediction = clf.predict(test_data)","eb97e7a5":"prediction","798ac438":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","1cfcf5d8":"submission = pd.read_csv('submission.csv')\nsubmission.head()","03e0adcb":"# The Chart confirms a person aboarded from C slightly more likely survived\n# The Chart confirms a person aboarded from Q more likely dead\n# The Chart confirms a person aboarded from S more likely dead","5890eba0":"# The Chart confirms 1st class more likely survived than other classes\n# The Chart confirms 3rd class more likely dead than other classes","0c2dd6cd":"# TITLE MAPPING \n# Mr = 0\n# Miss = 1\n# Mrs = 2 \n# others = 3","f5f77475":"# FEATURE ENGINEERING","705e065d":"# EXPLORATORY DATA ANALYSIS","8aac861c":"# SEX MAPPING\n # male = 0\n# female = 1","1694dcf0":"# The Chart confirms a person aboarded with more than 2 parents or children more likely survived\n# The Chart confirms a person aboarded alone more likely dead","a319796e":"# FARE ( filling missing value in fare)","8b7ac0eb":"# The Chart confirms a person aboarded with more than 2 siblings or spouse more likely survived\n# The Chart confirms a person aboarded without siblings or spouse more likely dead","1a1dad4d":"# converting numerical age to categorical variable","a9929800":"# AGE","bc3987d1":"# CABIN ( filling missing value of Cabin)","5cdeeeb9":"# EMBARKED "}}