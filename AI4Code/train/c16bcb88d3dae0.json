{"cell_type":{"e491f492":"code","1e92a0a7":"code","00977af8":"code","5301822d":"code","0f9aa253":"code","b7b32f81":"code","eeeb8c47":"code","9a9b0f57":"code","b4454754":"code","b35039eb":"code","7162e275":"code","9c594c86":"code","9bdb134d":"markdown","24d6704f":"markdown","2a90afa8":"markdown","811842ee":"markdown","67a1a961":"markdown","c244154e":"markdown","d9b28102":"markdown","ab434c8f":"markdown","43a48406":"markdown","3687bf5a":"markdown"},"source":{"e491f492":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\n\npd.set_option('display.max_columns', None)\nnp.random.seed(42)\ntf.random.set_seed(42)","1e92a0a7":"XX = pd.read_csv(\"..\/input\/nnfl-demo-lab-1\/test-2.csv\")\ndf = pd.read_csv(\"..\/input\/nnfl-demo-lab-1\/train-2.csv\")\ndf.head(7)","00977af8":"#correlation matrix\nk = 10\ncorrmat = df.corr()\ncols = corrmat.nlargest(k, 'Type')['Type'].index\ncm = np.corrcoef(df[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","5301822d":"df.columns","0f9aa253":"df.groupby('Type').mean()","b7b32f81":"df.groupby('Type').std()","eeeb8c47":"X = df[['RI', 'Na', 'Mg', 'Al', 'Si', 'Ba']]\nXX = XX[['RI', 'Na', 'Mg', 'Al', 'Si', 'Ba']]\ny = df['Type']","9a9b0f57":"scalar = StandardScaler().fit(X)\nX_scaled = scalar.transform(X)\nXX_scaled = scalar.transform(XX)\n\nXX_scaled = pd.DataFrame(XX_scaled, columns = XX.columns, index=XX.index)\nX_scaled = pd.DataFrame(X_scaled, columns = X.columns, index=X.index)\nX_scaled","b4454754":"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42, stratify=y)","b35039eb":"tf.keras.backend.set_floatx('float64')\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(4, activation='relu'),\n    tf.keras.layers.Dense(8, activation='softmax')])\n\nmodel.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n\nhistory = model.fit(x=X_train, y=y_train, batch_size = 18, validation_split=0.2, epochs = 500, verbose = 1)\nmodel.evaluate(X_test, y_test, verbose=1)","7162e275":"%matplotlib inline\nimport matplotlib.pyplot as plt\nacc = history.history['accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nval_acc = history.history['val_accuracy']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'cyan', label='Validation Loss')\nplt.plot(epochs, val_acc, 'green', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()","9c594c86":"final_outputs = np.argmax(model.predict(XX_scaled), axis=-1)\nsample = pd.read_csv(\"..\/input\/nnfl-demo-lab-1\/sample_submission-2.csv\")\nsample.loc[:, \"Type\"] = final_outputs\nsample.to_csv(\"submission.csv\", index=False)\nmodel.save_weights('model.h5')","9bdb134d":"# Explore the dataset provided","24d6704f":"# Now that we know which columns are actually good indicators of 'Type', we will take only those columns","2a90afa8":"# Defining and training the model.","811842ee":"Check mean and standard deviation of data to see if any data is very highly scattered","67a1a961":"# Creating train and validation sets","c244154e":"Tried on 200 epochs, resulted in underfitting. Tried on 1000 epochs, gave overfitting, so settled for 500 epochs.","d9b28102":"# Check to see if we are overfitting\/underfitting","ab434c8f":"# Code to generate submission file and .h file","43a48406":"# Do upvote the notebook if you find it helpful! Thank you!","3687bf5a":"# Import all the necessary libraries and the functions"}}