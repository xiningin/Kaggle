{"cell_type":{"97db31ec":"code","1ea1576b":"code","98bf321c":"code","0ee36428":"code","6d1d2fff":"code","cf9c7634":"code","f6b72f09":"code","ec671ed7":"code","0ec82b11":"code","e656a179":"code","95dcf312":"code","04bff8c5":"code","f7010fb0":"code","4723a677":"code","84f07bd5":"code","1c094096":"code","424a65b5":"markdown","1045499d":"markdown"},"source":{"97db31ec":"from keras.models import Sequential\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom keras import optimizers, losses, activations, models\nfrom keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\nfrom keras import applications\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator","1ea1576b":"train_idg = ImageDataGenerator(rotation_range=45, width_shift_range=0.1,\n                            height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n                            horizontal_flip=True, fill_mode=\"nearest\",\n                              preprocessing_function=preprocess_input)\nval_idg = ImageDataGenerator(preprocessing_function=preprocess_input)\n\"\"\"\ntrain_idg = ImageDataGenerator(vertical_flip=True,\n                               horizontal_flip=True,\n                               height_shift_range=0.1,\n                               width_shift_range=0.1,\n                               rotation_range=90,\n                               zoom_range=[0.5,1.0],\n                               brightness_range=[0.2,1.0],\n                               preprocessing_function=preprocess_input)\"\"\"\ntrain_gen = train_idg.flow_from_directory(\n    '..\/input\/imagenetmini-1000\/imagenet-mini\/train',\n    target_size=(224, 224),\n    batch_size = 32\n)\nval_gen = val_idg.flow_from_directory(\n    '..\/input\/imagenetmini-1000\/imagenet-mini\/val',\n    target_size=(224, 224),\n    batch_size = 32\n)","98bf321c":"from keras.layers import Conv2D, MaxPool2D,  \\\n    Dropout, Dense, Input, concatenate,      \\\n    GlobalAveragePooling2D, AveragePooling2D,\\\n    Flatten\nimport keras\ndef inception_module(x,filters_1x1,filters_3x3_reduce, filters_3x3,filters_5x5_reduce,filters_5x5,filters_pool_proj,name=None):\n    \n    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n    \n    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n\n    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n\n    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n\n    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n    \n    return output\n\n\nkernel_init = keras.initializers.glorot_uniform()\nbias_init = keras.initializers.Constant(value=0.2)\n\ninput_layer = Input(shape=(224, 224, 3))\n\nx = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7\/2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\nx = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3\/2')(x)\nx = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3\/1')(x)\nx = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3\/1')(x)\nx = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3\/2')(x)\n\nx = inception_module(x,\n                     filters_1x1=64,\n                     filters_3x3_reduce=96,\n                     filters_3x3=128,\n                     filters_5x5_reduce=16,\n                     filters_5x5=32,\n                     filters_pool_proj=32,\n                     name='inception_3a')\n\nx = inception_module(x,\n                     filters_1x1=128,\n                     filters_3x3_reduce=128,\n                     filters_3x3=192,\n                     filters_5x5_reduce=32,\n                     filters_5x5=96,\n                     filters_pool_proj=64,\n                     name='inception_3b')\n\nx = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3\/2')(x)\n\nx = inception_module(x,\n                     filters_1x1=192,\n                     filters_3x3_reduce=96,\n                     filters_3x3=208,\n                     filters_5x5_reduce=16,\n                     filters_5x5=48,\n                     filters_pool_proj=64,\n                     name='inception_4a')\n\n\nx1 = AveragePooling2D((5, 5), strides=3)(x)\nx1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\nx1 = Flatten()(x1)\nx1 = Dense(1024, activation='relu')(x1)\nx1 = Dropout(0.7)(x1)\nx1 = Dense(7, activation='softmax', name='auxilliary_output_1')(x1)\n\nx = inception_module(x,\n                     filters_1x1=160,\n                     filters_3x3_reduce=112,\n                     filters_3x3=224,\n                     filters_5x5_reduce=24,\n                     filters_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_4b')\n\nx = inception_module(x,\n                     filters_1x1=128,\n                     filters_3x3_reduce=128,\n                     filters_3x3=256,\n                     filters_5x5_reduce=24,\n                     filters_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_4c')\n\nx = inception_module(x,\n                     filters_1x1=112,\n                     filters_3x3_reduce=144,\n                     filters_3x3=288,\n                     filters_5x5_reduce=32,\n                     filters_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_4d')\n\n\nx2 = AveragePooling2D((5, 5), strides=3)(x)\nx2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\nx2 = Flatten()(x2)\nx2 = Dense(1024, activation='relu')(x2)\nx2 = Dropout(0.7)(x2)\nx2 = Dense(7, activation='softmax', name='auxilliary_output_2')(x2)\n\nx = inception_module(x,\n                     filters_1x1=256,\n                     filters_3x3_reduce=160,\n                     filters_3x3=320,\n                     filters_5x5_reduce=32,\n                     filters_5x5=128,\n                     filters_pool_proj=128,\n                     name='inception_4e')\n\nx = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3\/2')(x)\n\nx = inception_module(x,\n                     filters_1x1=256,\n                     filters_3x3_reduce=160,\n                     filters_3x3=320,\n                     filters_5x5_reduce=32,\n                     filters_5x5=128,\n                     filters_pool_proj=128,\n                     name='inception_5a')\n\nx = inception_module(x,\n                     filters_1x1=384,\n                     filters_3x3_reduce=192,\n                     filters_3x3=384,\n                     filters_5x5_reduce=48,\n                     filters_5x5=128,\n                     filters_pool_proj=128,\n                     name='inception_5b')\n\nx = GlobalAveragePooling2D(name='avg_pool_5_3x3\/1')(x)\n\nx = Dropout(0.4)(x)\n\nx = Dense(7, activation='softmax', name='output')(x)\n\nmodel = Model(input_layer, [x, x1, x2], name='inception_v1')\n\n\nmodel.summary()","0ee36428":"input_shape = (224, 224, 3)\nnclass = 1000\n\nbase_model = applications.InceptionV3(weights='imagenet', \n                                include_top=False, \n                                input_shape=input_shape)\nbase_model.trainable = False\n\nadd_model = Sequential()\nadd_model.add(base_model)\nadd_model.add(GlobalAveragePooling2D())\nadd_model.add(Dropout(0.5))\nadd_model.add(Dense(nclass, \n                    activation='softmax'))\n\nmodel = add_model\nmodel.compile(loss='categorical_crossentropy', \n              optimizer=optimizers.SGD(lr=1e-3, \n                                       momentum=0.9),\n              metrics=['accuracy'])\nmodel.summary()","6d1d2fff":"import tensorflow as tf\nfile_path=\"inceptionV3.hdf5\"\n\ncheckpoint = ModelCheckpoint(file_path, monitor='acc', verbose=1, save_best_only=True, mode='max')\n\nearly = EarlyStopping(monitor=\"acc\", mode=\"max\", patience=2)\n\ncallbacks_list = [checkpoint, early] #early\nwith tf.device('\/gpu:0'):\n    history = model.fit_generator(train_gen,\n                                  validation_data=val_gen,\n                              epochs=20, \n                              shuffle=True, \n                              verbose=True,\n                              callbacks=callbacks_list)\n# plot the training loss and accuracy\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nN = np.arange(0, 20)\nplt.figure()\nplt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n#plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n#plt.plot(N, history.history[\"acc\"], label=\"train_acc\")\n#plt.plot(N, history.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training\/Validation Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend()","cf9c7634":"# plot the training loss and accuracy\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nN = np.arange(0, 20)\nplt.figure()\nplt.plot(N, history.history[\"loss\"], label=\"train_loss\")\nplt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(N, history.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(N, history.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training\/Validation Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend()","f6b72f09":"model.save('InceptionV5_trained.h5')\nmodel.save_weights('Inception_weights_only.h5')","ec671ed7":"from IPython.display import FileLink\nFileLink(r'Inception_weights_only.h5')","0ec82b11":"import keras\nmodel=keras.models.load_model('..\/input\/image-test\/InceptionV5_trained.h5')","e656a179":"pip install imutils","95dcf312":"from cv2 import cv2 \nfrom keras.applications.inception_v3 import preprocess_input\nfrom imutils.video import VideoStream\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications import imagenet_utils\n\n\nimage = load_img('..\/input\/image-test\/test_botella.jpg', target_size=(224, 224))\n# convert the image pixels to a numpy array\nimage = img_to_array(image)\n# reshape data for the model (samples, rows, columns, and channels.)\nimage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n# prepare the image for the VGG model\nimage = preprocess_input(image)\n# predict the probability across all output classes\npred = model.predict(image)\npred = imagenet_utils.decode_predictions(pred)\nfirst_pred=pred[0][0]\nprint(first_pred[1],first_pred[2])\n\n","04bff8c5":"def freeze_layers(model):\n    for i in model.layers:\n        i.trainable = False\n        if isinstance(i, Model):\n            freeze_layers(i)\n    return model\nmodel_freezed = freeze_layers(model)\nmodel_freezed.save('Inception_weights.tf')","f7010fb0":"from IPython.display import FileLink\nFileLink(r'Inception_weights.tf\/saved_model.pb')","4723a677":"# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","84f07bd5":"from IPython.display import FileLink\nFileLink(r'Inception_weights.tf\/saved_model.pb')","1c094096":"from tensorflow.python import keras\nprint(tf.__version__)","424a65b5":"# 2\u00ba implementation of GoogleNet-->Transfer learning","1045499d":"# 1\u00ba implementation of GoogleNet-->Scratch"}}