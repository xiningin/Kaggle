{"cell_type":{"d12da7bd":"code","588100c2":"code","19c74644":"code","681fb473":"code","626043f0":"code","5875f2fa":"code","e4814e6e":"code","3f606e23":"code","8b472a65":"code","5ba55ba9":"code","e9a99f84":"code","7cecb5bc":"code","794a09fe":"code","a89e0e9d":"code","2e235098":"code","0f8ba765":"code","ae88fab5":"code","9420cd78":"code","b674ce90":"code","677bfd34":"code","bf22e596":"code","981c7eec":"code","43e4fa20":"markdown","63a59b19":"markdown"},"source":{"d12da7bd":"!git clone --depth 1 https:\/\/github.com\/location-competition\/indoor-location-competition-20 indoor_location_competition_20\n!rm -rf indoor_location_competition_20\/data","588100c2":"file_name = \"..\/input\/pub6451ems\/submission.csv\"","19c74644":"import multiprocessing\nimport numpy as np\nimport pandas as pd\nimport scipy.interpolate\nimport scipy.sparse\nfrom tqdm import tqdm\n\nfrom indoor_location_competition_20.io_f import read_data_file\nimport indoor_location_competition_20.compute_f as compute_f","681fb473":"INPUT_PATH = '..\/input\/indoor-location-navigation'","626043f0":"def compute_rel_positions(acce_datas, ahrs_datas):\n    step_timestamps, step_indexs, step_acce_max_mins = compute_f.compute_steps(acce_datas)\n    headings = compute_f.compute_headings(ahrs_datas)\n    stride_lengths = compute_f.compute_stride_length(step_acce_max_mins)\n    step_headings = compute_f.compute_step_heading(step_timestamps, headings)\n    rel_positions = compute_f.compute_rel_positions(stride_lengths, step_headings)\n    return rel_positions","5875f2fa":"def correct_path(args):\n    path, path_df = args\n    \n    T_ref  = path_df['timestamp'].values\n    xy_hat = path_df[['x', 'y']].values\n    \n    example = read_data_file(f'{INPUT_PATH}\/test\/{path}.txt')\n    rel_positions = compute_rel_positions(example.acce, example.ahrs)\n    \n    if T_ref[-1] > rel_positions[-1, 0]:\n        rel_positions = [np.array([[0, 0, 0]]), rel_positions, np.array([[T_ref[-1], 0, 0]])]\n    else:\n        rel_positions = [np.array([[0, 0, 0]]), rel_positions]\n    rel_positions = np.concatenate(rel_positions)\n    T_rel = rel_positions[:, 0]\n    delta_xy_hat = np.diff(scipy.interpolate.interp1d(T_rel, np.cumsum(rel_positions[:, 1:3], axis=0), axis=0)(T_ref), axis=0)\n    N = xy_hat.shape[0]\n    \n    delta_t = np.diff(T_ref)\n    \n    alpha = (8.1)**(-2) * np.ones(N)\n    beta  = (0.4 + 0.4 * 1e-3 * delta_t)**(-2)\n    \n    A = scipy.sparse.spdiags(alpha, [0], N, N)\n    B = scipy.sparse.spdiags(beta, [0], N-1, N-1)\n    D = scipy.sparse.spdiags(np.stack([-np.ones(N), np.ones(N)]), [0, 1], N-1, N)\n\n    Q = A + (D.T @ B @ D)\n    c = (A @ xy_hat) + (D.T @ (B @ delta_xy_hat))\n\n    xy_star = scipy.sparse.linalg.spsolve(Q, c)\n    \n    return pd.DataFrame({\n        'site_path_timestamp' : path_df['site_path_timestamp'],\n        'floor' : path_df['floor'],\n        'x' : xy_star[:, 0],\n        'y' : xy_star[:, 1],\n    })","e4814e6e":"sub = pd.read_csv(file_name)\ntmp = sub['site_path_timestamp'].apply(lambda s : pd.Series(s.split('_')))\nsub['site'] = tmp[0]\nsub['path'] = tmp[1]\nsub['timestamp'] = tmp[2].astype(float)\n\nprocesses = multiprocessing.cpu_count()\nwith multiprocessing.Pool(processes=processes) as pool:\n    dfs = pool.imap_unordered(correct_path, sub.groupby('path'))\n    dfs = tqdm(dfs)\n    dfs = list(dfs)\nsub = pd.concat(dfs).sort_values('site_path_timestamp')\n# sub.to_csv('submission.csv', index=False)","3f606e23":"import json\nimport matplotlib.pylab as plt\n\ndef split_col(df):\n    df = pd.concat([\n        df['site_path_timestamp'].str.split('_', expand=True) \\\n        .rename(columns={0:'site',\n                         1:'path',\n                         2:'timestamp'}),\n        df\n    ], axis=1).copy()\n    return df\n\nfloor_map = {\"B2\":-2, \"B1\":-1, \"F1\":0, \"F2\": 1, \"F3\":2,\n             \"F4\":3, \"F5\":4, \"F6\":5, \"F7\":6,\"F8\":7,\"F9\":8,\n             \"1F\":0, \"2F\":1, \"3F\":2, \"4F\":3, \"5F\":4, \"6F\":5,\n             \"7F\":6, \"8F\": 7, \"9F\":8}\n\n\ndef plot_preds(\n    site,\n    floorNo,\n    sub=None,\n    true_locs=None,\n    base=\"..\/input\/indoor-location-navigation\",\n    show_train=True,\n    show_preds=True,\n    fix_labels=True,\n    map_floor=None\n):\n    \"\"\"\n    Plots predictions on floorplan map.\n    \n    map_floor : use a different floor's map\n    \"\"\"\n    if map_floor is None:\n        map_floor = floorNo\n    # Prepare width_meter & height_meter (taken from the .json file)\n    floor_plan_filename = f\"{base}\/metadata\/{site}\/{map_floor}\/floor_image.png\"\n    json_plan_filename = f\"{base}\/metadata\/{site}\/{map_floor}\/floor_info.json\"\n    with open(json_plan_filename) as json_file:\n        json_data = json.load(json_file)\n\n    width_meter = json_data[\"map_info\"][\"width\"]\n    height_meter = json_data[\"map_info\"][\"height\"]\n\n    floor_img = plt.imread(f\"{base}\/metadata\/{site}\/{map_floor}\/floor_image.png\")\n\n    fig, ax = plt.subplots(figsize=(12, 12))\n    plt.imshow(floor_img)\n\n    if show_train:\n        true_locs = true_locs.query('site == @site and floorNo == @map_floor').copy()\n        true_locs[\"x_\"] = true_locs[\"x\"] * floor_img.shape[0] \/ height_meter\n        true_locs[\"y_\"] = (\n            true_locs[\"y\"] * -1 * floor_img.shape[1] \/ width_meter\n        ) + floor_img.shape[0]\n        true_locs.query(\"site == @site and floorNo == @map_floor\").groupby(\"path\").plot(\n            x=\"x_\",\n            y=\"y_\",\n            style=\"+\",\n            ax=ax,\n            label=\"train waypoint location\",\n            color=\"grey\",\n            alpha=0.5,\n        )\n\n    if show_preds:\n        sub = sub.query('site == @site and floorNo == @floorNo').copy()\n        sub[\"x_\"] = sub[\"x\"] * floor_img.shape[0] \/ height_meter\n        sub[\"y_\"] = (\n            sub[\"y\"] * -1 * floor_img.shape[1] \/ width_meter\n        ) + floor_img.shape[0]\n        for path, path_data in sub.query(\n            \"site == @site and floorNo == @floorNo\"\n        ).groupby(\"path\"):\n            path_data.plot(\n                x=\"x_\",\n                y=\"y_\",\n                style=\".-\",\n                ax=ax,\n                title=f\"{site} - floor - {floorNo}\",\n                alpha=1,\n                label=path,\n            )\n    if fix_labels:\n        handles, labels = ax.get_legend_handles_labels()\n        by_label = dict(zip(labels, handles))\n        plt.legend(\n            by_label.values(), by_label.keys(), loc=\"center left\", bbox_to_anchor=(1, 0.5)\n        )\n    return fig, ax\n\ndef sub_process(sub, train_waypoints):\n    train_waypoints['isTrainWaypoint'] = True\n    sub = split_col(sub[['site_path_timestamp','floor','x','y']]).copy()\n    sub = sub.merge(train_waypoints[['site','floorNo','floor']].drop_duplicates(), how='left')\n    sub = sub.merge(\n        train_waypoints[['x','y','site','floor','isTrainWaypoint']].drop_duplicates(),\n        how='left',\n        on=['site','x','y','floor']\n             )\n    sub['isTrainWaypoint'] = sub['isTrainWaypoint'].fillna(False)\n    return sub.copy()","8b472a65":"sub = split_col(sub)\nth = 5","5ba55ba9":"train_waypoints = pd.read_csv('..\/input\/indoor-location-train-waypoints\/train_waypoints.csv')\nsub = sub_process(sub, train_waypoints)\n# Plot the training Data For an example Floor\nexample_site = '5dbc1d84c1eb61796cf7c010'\nexample_floorNo = 'F3'\n\nplot_preds(example_site, example_floorNo, sub,\n           train_waypoints, show_preds=False)\nplt.show()","e9a99f84":"from scipy.spatial.distance import cdist\n\ndef add_xy(df):\n    df['xy'] = [(x, y) for x,y in zip(df['x'], df['y'])]\n    return df\n\ndef closest_point(point, points):\n    \"\"\" Find closest point from a list of points. \"\"\"\n    return points[cdist([point], points).argmin()]\n\nsub = add_xy(sub)\ntrain_waypoints = add_xy(train_waypoints)\n\nds = []\nfor (site, myfloor), d in sub.groupby(['site','floor']):\n    true_floor_locs = train_waypoints.loc[(train_waypoints['floor'] == myfloor) &\n                                          (train_waypoints['site'] == site)] \\\n        .reset_index(drop=True)\n    if len(true_floor_locs) == 0:\n        print(f'Skipping {site} {myfloor}')\n        continue\n    d['matched_point'] = [closest_point(x, list(true_floor_locs['xy'])) for x in d['xy']]\n    d['x_'] = d['matched_point'].apply(lambda x: x[0])\n    d['y_'] = d['matched_point'].apply(lambda x: x[1])\n    ds.append(d)\n\nsub = pd.concat(ds)","7cecb5bc":"def snap_to_grid(sub, threshold):\n    \"\"\"\n    Snap to grid if within a threshold.\n    \n    x, y are the predicted points.\n    x_, y_ are the closest grid points.\n    _x_, _y_ are the new predictions after post processing.\n    \"\"\"\n    sub['_x_'] = sub['x']\n    sub['_y_'] = sub['y']\n    sub.loc[sub['dist'] < threshold, '_x_'] = sub.loc[sub['dist'] < threshold]['x_']\n    sub.loc[sub['dist'] < threshold, '_y_'] = sub.loc[sub['dist'] < threshold]['y_']\n    return sub.copy()\n\n# Calculate the distances\nsub['dist'] = np.sqrt( (sub.x-sub.x_)**2 + (sub.y-sub.y_)**2 )\n\nsub_pp = snap_to_grid(sub, threshold=th)\n\nsub_pp = sub_pp[['site_path_timestamp','floor','_x_','_y_','site','path','floorNo']] \\\n    .rename(columns={'_x_':'x', '_y_':'y'})","794a09fe":"sub['dist_pp_change'] = np.sqrt(((sub['x'] - sub['_x_']) ** 2) + ((sub['y'] - sub['_y_']) ** 2))\nfig, axs = plt.subplots(1, 2, figsize=(15, 5))\nsub['dist_pp_change'].plot(kind='hist', bins=30,\n                           ax=axs[0],\n                           title='Distance Changed by Post Processing')\nsub.query('dist_pp_change > 0.1')['dist_pp_change'] \\\n    .plot(kind='hist', bins=30, ax=axs[1],\n          title='Distance Changed (Excluding <0.1 Change)')\n\nplt.show()","a89e0e9d":"sub.groupby(['site','floorNo'])['dist_pp_change'].mean() \\\n    .reset_index() \\\n    .sort_values('dist_pp_change') \\\n    .set_index(['site','floorNo']).head(20).plot(kind='barh')","2e235098":"sub_pp[['site_path_timestamp','floor','x','y']] \\\n    .to_csv('sub_cost_snap.csv', index=False)","0f8ba765":"import json\nimport re\nimport gc\nimport pickle\nimport itertools\nfrom glob import glob\nfrom datetime import datetime as dt\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport datetime\nts_conv = np.vectorize(datetime.datetime.fromtimestamp) # ut(10 digit) -> date\n\n# pandas settings -----------------------------------------\npd.set_option(\"display.max_colwidth\", 100)\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\npd.options.display.float_format = '{:,.5f}'.format\n\n# Graph drawing -------------------------------------------\nimport matplotlib\nfrom matplotlib import font_manager\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom matplotlib import rc\nfrom matplotlib_venn import venn2, venn2_circles\nfrom matplotlib import animation as ani\nfrom IPython.display import Image\nfrom pylab import imread\n\nplt.rcParams[\"patch.force_edgecolor\"] = True\nfrom IPython.display import display # Allows the use of display() for DataFrames\nimport seaborn as sns\nsns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\nsns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nred = sns.xkcd_rgb[\"light red\"]\ngreen = sns.xkcd_rgb[\"medium green\"]\nblue = sns.xkcd_rgb[\"denim blue\"]\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\n# ML -------------------------------------------\nfrom sklearn.preprocessing import LabelEncoder\n\nimport warnings\nwarnings.simplefilter('ignore')","ae88fab5":"pred_df = pd.read_csv(file_name) \nafter_df = pd.read_csv('.\/sub_cost_snap.csv')","9420cd78":"pred_df['site'] = [s1 for s1, s2, s3 in pred_df.site_path_timestamp.str.split('_')]\npred_df['path'] = [s2 for s1, s2, s3 in pred_df.site_path_timestamp.str.split('_')]\npred_df['timestamp'] = [s3 for s1, s2, s3 in pred_df.site_path_timestamp.str.split('_')]\n\nafter_df['site'] = [s1 for s1, s2, s3 in pred_df.site_path_timestamp.str.split('_')]\nafter_df['path'] = [s2 for s1, s2, s3 in pred_df.site_path_timestamp.str.split('_')]\nafter_df['timestamp'] = [s3 for s1, s2, s3 in pred_df.site_path_timestamp.str.split('_')]","b674ce90":"\nclass SiteInfo():\n    def __init__(self, site_id, floor, input_path=\"..\/input\/indoor-location-navigation\/\"):\n        self.site_id = site_id\n        self.floor = floor\n        self.input_path = input_path\n        assert Path(input_path).exists(), f\"input_path do not exist: {input_path}\"\n        \n    def get_site_info(self, keep_raw=False):\n        floor_info_path = f\"{self.input_path}\/metadata\/{self.site_id}\/{self.floor}\/floor_info.json\"\n        with open(floor_info_path, \"r\") as f:\n            self.floor_info = json.loads(f.read())\n            self.site_height = self.floor_info[\"map_info\"][\"height\"]\n            self.site_width = self.floor_info[\"map_info\"][\"width\"]\n            if not keep_raw:\n                del self.floor_info\n            \n        geojson_map_path = f\"{self.input_path}\/metadata\/{self.site_id}\/{self.floor}\/geojson_map.json\"\n        with open(geojson_map_path, \"r\") as f:\n            self.geojson_map = json.loads(f.read())\n            self.map_type = self.geojson_map[\"type\"]\n            self.features = self.geojson_map[\"features\"]\n            \n            self.floor_coordinates = self.features[0][\"geometry\"][\"coordinates\"]\n            self.store_coordinates = [self.features[i][\"geometry\"][\"coordinates\"] \n                                          for i in range(1, len(self.features))]\n                \n            if not keep_raw:\n                del self.geojson_map\n    \n    def show_site_image(self):\n        path = f\"{self.input_path}\/metadata\/{self.site_id}\/{self.floor}\/floor_image.png\"\n        plt.imshow(imread(path), extent=[0, self.site_width, 0, self.site_height])\n\n    def draw_polygon(self, size=8, only_floor=False):\n\n        fig = plt.figure()\n        ax = plt.subplot(111)\n            \n        xmax, xmin, ymax, ymin = self._draw(self.floor_coordinates, ax, calc_minmax=True)\n        if not only_floor:\n            self._draw(self.store_coordinates, ax, fill=True)\n        plt.legend([])\n        \n        xrange = xmax - xmin\n        yrange = ymax - ymin\n        ratio = yrange \/ xrange\n        \n        self.x_size = size\n        self.y_size = size*ratio\n\n        fig.set_figwidth(size)\n        fig.set_figheight(size*ratio)\n        # plt.show()\n        return ax\n        \n    def _draw(self, coordinates, ax, fill=False, calc_minmax=False):\n        xmax, ymax = -np.inf, -np.inf\n        xmin, ymin = np.inf, np.inf\n        for i in range(len(coordinates)):\n            ndim = np.ndim(coordinates[i])\n            if ndim==2:\n                corrd_df = pd.DataFrame(coordinates[i])\n                if fill:\n                    ax.fill(corrd_df[0], corrd_df[1], alpha=0.7)\n                else:\n                    corrd_df.plot.line(x=0, y=1, style=\"-\", ax=ax)\n                        \n                if calc_minmax:\n                    xmax = max(xmax, corrd_df[0].max())\n                    xmin = min(xmin, corrd_df[0].min())\n\n                    ymax = max(ymax, corrd_df[1].max())\n                    ymin = min(ymin, corrd_df[1].min())\n            elif ndim==3:\n                for j in range(len(coordinates[i])):\n                    corrd_df = pd.DataFrame(coordinates[i][j])\n                    if fill:\n                        ax.fill(corrd_df[0], corrd_df[1], alpha=0.6)\n                    else:\n                        corrd_df.plot.line(x=0, y=1, style=\"-\", ax=ax)\n                        \n                    if calc_minmax:\n                        xmax = max(xmax, corrd_df[0].max())\n                        xmin = min(xmin, corrd_df[0].min())\n\n                        ymax = max(ymax, corrd_df[1].max())\n                        ymin = min(ymin, corrd_df[1].min())\n            else:\n                assert False, f\"ndim of coordinates should be 2 or 3: {ndim}\"\n        if calc_minmax:\n            return xmax, xmin, ymax, ymin\n        else:\n            return None\n        ","677bfd34":"floor_convert = {'1F' :  0, '2F' : 1, '3F' : 2, '4F' : 3, '5F' : 4, \n                     '6F' : 5, '7F' : 6, '8F' : 7, '9F' : 8,\n                     'B'  : -1, 'B1' : -1, 'B2' : -2, 'B3' : -3, \n                     'BF' : -1, 'BM' : -1, \n                     'F1' : 0, 'F2' : 1, 'F3' : 2, 'F4' : 3, 'F5' : 4, \n                     'F6' : 5, 'F7' : 6, 'F8' : 7, 'F9' : 8, 'F10': 9,\n                     'L1' : 0, 'L2' : 1, 'L3' : 2, 'L4' : 3, 'L5' : 4, \n                     'L6' : 5, 'L7' : 6, 'L8' : 7, 'L9' : 8, 'L10': 9, \n                     'L11': 10,\n                     'G'  : 0, 'LG1': 0, 'LG2': 1, 'LM' : 0, 'M'  : 0, \n                     'P1' : 0, 'P2' : 1,}","bf22e596":"reconv = {}\n\nfor i in range(20):\n    reconv[i - 5] = []\n    \nfor k, v in floor_convert.items(): \n    reconv[v].append(k) \n\ntrain_dir='..\/input\/indoor-navigation-and-location-wifi-features\/' ","981c7eec":"for i, site_id in enumerate(pred_df.site.unique()):\n\n    sample_df = pred_df.query(\"site == @site_id\")\n    after_s_df = after_df.query(\"site == @site_id\")\n    \n    train_df = pd.read_csv(f'{train_dir}\/{site_id}_train.csv')\n    \n    for floor_id in sample_df['floor'].unique():\n        floor_df = sample_df[sample_df['floor'] == floor_id].reset_index(drop=True)\n        after_f_df = after_s_df[after_s_df['floor'] == floor_id].reset_index(drop=True)\n\n        for fstr in reconv[floor_id]:\n            sample_map = SiteInfo(site_id, fstr)\n            try:\n                sample_map.get_site_info()\n            except:\n                pass\n            else:\n                break\n\n        plt.figure(figsize=(12, 12*sample_map.site_height \/ sample_map.site_width))\n        #plt.subplot(121)\n        \n        sample_map.show_site_image()\n\n        for _, g in floor_df.groupby(\"path\"):\n            plt.plot(g.x, g.y, \"-o\", alpha=0.6,  zorder=100, markersize=5)\n        \n        sample_train = train_df.query('f == @floor_id')\n        \n        plt.scatter(sample_train.x, sample_train.y, marker='+', s=3)\n        plt.title(f'before {site_id}:{floor_id}')\n        \n        for fstr in reconv[floor_id]:\n            sample_map = SiteInfo(site_id, fstr)\n            try:\n                sample_map.get_site_info()\n            except:\n                pass\n            else:\n                break   \n                \n        plt.figure(figsize=(12, 12*sample_map.site_height \/ sample_map.site_width))\n        #plt.subplot(121)\n        \n        sample_map.show_site_image()\n\n        for _, g in after_f_df.groupby(\"path\"):\n            plt.plot(g.x, g.y, \"-o\", alpha=0.6,  zorder=100, markersize=5)\n            \n#        plt.title(f'pred {site_id}:{floor_id}')\n        \n        sample_train = train_df.query('f == @floor_id')\n        \n#        plt.subplot(122)\n#        sample_map.show_site_image()\n        \n        #for _, g in sample_train.groupby(\"path\"):\n        #    plt.plot(g.x, g.y, \"-o\", alpha=0.6,  zorder=100, markersize=5)\n        \n        plt.scatter(sample_train.x, sample_train.y, marker='+', s=3)\n        plt.title(f'post_process {site_id}:{floor_id}')\n    \n        # show all floor in this site\n        break \n    #break","43e4fa20":"**the order in which you use the shared amazing magic notes, I think this is very important\nI think now this order is good, but please let us know your opinion.**\n\n1. wifi feauture prediction\n1. blend\n1. Cost Minimization\n1. Snap to Grid\n\nAdded mapping before and after post-processing, Thanks for the great notes","63a59b19":"**refarence**\n\n[Indoor Navigation - \"Snap to Grid\" Post Processing](https:\/\/www.kaggle.com\/robikscube\/indoor-navigation-snap-to-grid-post-processing)\n\n[Ensembling best performing notebooks ver15](https:\/\/www.kaggle.com\/saurabhbagchi\/ensembling-best-performing-notebooks?scriptVersionId=56617696)\n\n[indoor - Post-processing by Cost Minimization](https:\/\/www.kaggle.com\/saitodevel01\/indoor-post-processing-by-cost-minimization)\n\n[Simple \ud83d\udc4c 99% Accurate Floor Model \ud83d\udcaf](https:\/\/www.kaggle.com\/nigelhenry\/simple-99-accurate-floor-model)\n\n[How to check your submission [LB4.441]](https:\/\/www.kaggle.com\/yamsam\/how-to-check-your-submission-lb4-441)"}}