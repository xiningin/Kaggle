{"cell_type":{"9e9a37ea":"code","b220ba71":"code","db9ec48f":"code","9cd021bc":"code","55e7b428":"code","9b9ae7f7":"code","d0b64ca7":"code","59e2e897":"code","ce253289":"code","2f0a99e1":"code","409d39c5":"code","2c2e4e01":"code","b86447a8":"code","13f8739f":"code","3e957b9e":"code","cff2d334":"code","9e8439e3":"code","36608114":"code","c8ef2e8c":"code","d106bbe7":"code","6b79d845":"code","35d69941":"code","0a13a628":"code","ce333fd1":"code","e9ee47f2":"code","db7d83eb":"code","45d9a924":"code","772bd884":"code","56c47ec0":"code","b7f1c845":"markdown","0b988cba":"markdown"},"source":{"9e9a37ea":"#load in packages\nimport os\nimport pandas as pd\nfrom glob import glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport gc\nfrom tqdm import tqdm\n\n#images\nimport cv2\n\n#modeling\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.client import device_lib\n\n#visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt","b220ba71":"#source path (where the Pawpularity contest data resides)\npath = '..\/input\/petfinder-pawpularity-score\/'\n\n#Get the metadata (the .csv data) and put it into DataFrames\ntrain_df = pd.read_csv(path + 'train.csv')\ntest_df = pd.read_csv(path + 'test.csv')\n\n#Get the image data (the .jpg data) and put it into lists of filenames\ntrain_jpg = glob(path + \"train\/*.jpg\")\ntest_jpg = glob(path + \"test\/*.jpg\")","db9ec48f":"train_df.shape, len(train_jpg)","9cd021bc":"train_df.head(5)","55e7b428":"sns.histplot(train_df['Pawpularity']);\n\nplt.axvline(train_df['Pawpularity'].mean(),color='red')\nplt.axvline(train_df['Pawpularity'].median(),color='green')","9b9ae7f7":"train_df[['Pawpularity']].describe().T","d0b64ca7":"train_df.columns","59e2e897":"cols = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n\nfor col in cols:\n    fig, ax = plt.subplots(1,2)\n    sns.violinplot(data = train_df,y ='Pawpularity', x=col, ax=ax[0])\n    sns.histplot(data = train_df,x ='Pawpularity',hue=col,kde=True,fill=True, ax=ax[1])\n    \n    plt.suptitle(str(col), fontsize=18, fontweight='bold')\n    fig.show()","ce253289":"img_path = '..\/input\/petfinder-pawpularity-score\/train\/'\next = '.jpg'\n\nnums = len(cols)\n\n# col = 'Eyes'\nfor count, col in enumerate(cols):\n    sample = train_df.loc[train_df[col] == 1,'Id'].head(100).values[np.random.randint(10)]\n    \n    pawpularity = train_df.loc[train_df['Id'] == sample, 'Pawpularity'].head(1).values[-1]\n    \n    image_loc = img_path + sample + ext\n\n    image_array = plt.imread(image_loc)\n    plt.imshow(image_array)\n    \n    plt.title(f'Image of pet with {col}\\nPawpularity Score: {pawpularity}') \n    plt.axis('off') #turns off the gridlines\n    plt.show()\n\n    del sample, image_loc, image_array\n    gc.collect()","2f0a99e1":"#Modify the Id such that each Id is the full image path. In the form\ndef train_id_to_path(x):\n    return '..\/input\/petfinder-pawpularity-score\/train\/' + x + \".jpg\"\ndef test_id_to_path(x):\n    return '..\/input\/petfinder-pawpularity-score\/test\/' + x + \".jpg\"\n","409d39c5":"#Check to see\ntf.config.get_visible_devices()","2c2e4e01":"#Read in the data and drop unnecessary columns\ntrain = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntrain = train.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)\n\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\ntest = test.drop(['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],axis=1)","b86447a8":"#Add the .jpg extensions to the image file name ids\ntrain[\"img_path\"] = train[\"Id\"].apply(train_id_to_path)\ntest[\"img_path\"] = test[\"Id\"].apply(test_id_to_path)","13f8739f":"#binning columns to test models\ntrain['two_bin_pawp'] = pd.qcut(train['Pawpularity'], q=2, labels=False)\ntrain = train.astype({\"two_bin_pawp\": str})\n\ntrain['four_bin_pawp'] = pd.qcut(train['Pawpularity'], q=4, labels=False)\ntrain = train.astype({\"four_bin_pawp\": str})\n\ntrain['ten_bin_pawp'] = pd.qcut(train['Pawpularity'], q=10, labels=False)\ntrain = train.astype({\"ten_bin_pawp\": str})","3e957b9e":"#Set the size image you want to use\nimage_height = 128\nimage_width = 128\n\n#define a function that accepts an image url and outputs an eager tensor\ndef path_to_eagertensor(image_path):\n    raw = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(raw, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    #image = tf.image.resize_with_pad(image, image_height, image_width) #optional with padding to retain original dimensions\n    image = tf.image.resize(image, (image_height, image_width))\n    return image","cff2d334":"#get all the images in the training folder and put their tensors in a list\nX = []\nfor img in tqdm(train['img_path']):\n    new_img_tensor = path_to_eagertensor(img)\n    X.append(new_img_tensor)\n    \nprint(type(X),len(X))\nX = np.array(X)\nprint(type(X),X.shape)","9e8439e3":"#get all the images in the test folder and put their tensors in a list\nX_submission = []\nfor img in tqdm(test['img_path']):\n    new_img_tensor = path_to_eagertensor(img)\n    X_submission.append(new_img_tensor)\n    \nprint(type(X_submission),len(X_submission))\nX_submission = np.array(X_submission)\nprint(type(X_submission),X_submission.shape)","36608114":"#grab the target variable. In our case, Pawpularity\ny = train['Pawpularity']\nprint(type(y))","c8ef2e8c":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=7)","d106bbe7":"#Show the shape of each of the new arrays\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","6b79d845":"def get_model(SEED=42):\n    tf.keras.backend.clear_session()\n    np.random.seed(SEED)\n    tf.random.set_seed(SEED)\n    \n    input_ = keras.Input(shape=(X.shape[1],X.shape[2],3))\n\n    x = keras.layers.Conv2D(filters = 16, kernel_size=[7,7], strides=[2,2], padding='valid', kernel_initializer='he_normal',\n                           kernel_regularizer=l2(0.0005), activation = 'relu')(input_)\n\n    x = keras.layers.Conv2D(filters = 32, kernel_size=[3,3], padding='same', kernel_initializer='he_normal',\n                           activation = 'relu')(x)\n\n    x = keras.layers.BatchNormalization()(x)\n\n    x = keras.layers.Conv2D(filters = 32, kernel_size=[3,3],strides=[2,2], padding='same', kernel_initializer='he_normal',\n                           activation = 'relu', kernel_regularizer=l2(0.0005))(x)\n\n    x = keras.layers.BatchNormalization()(x)\n\n    x = keras.layers.Dropout(0.25)(x)\n\n    x = keras.layers.Conv2D(filters = 64, kernel_size=[3,3], padding='same', kernel_initializer='he_normal', activation='relu'\n                            ,kernel_regularizer=l2(0.0002))(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2,2), padding='same',\n                               kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), activation = 'relu')(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Dropout(0.25)(x)\n\n    #####\n    x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n\n    x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3),padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0002), activation = 'relu')(x)\n\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    x = tf.keras.layers.Dropout(0.25)(x)\n\n    x = tf.keras.layers.Flatten()(x)\n\n    x = tf.keras.layers.Dense(512, activation = \"relu\")(x)\n\n    x = tf.keras.layers.Dropout(0.5)(x)\n\n    output = tf.keras.layers.Dense(1)(x)\n\n    model = tf.keras.Model(inputs = input_, outputs = output)\n    \n    return model","35d69941":"model = get_model()\nmodel.summary()","0a13a628":"#compile the model\nmodel.compile(\n    loss = 'mse', \n    optimizer = 'Adam', \n    metrics = [tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")])","ce333fd1":"data_augmentation = ImageDataGenerator(rotation_range=15, zoom_range=0.15, width_shift_range = 0.2, \n    height_shift_range = 0.2, \n    shear_range = 0.1,\n    horizontal_flip = True, \n    fill_mode = \"nearest\")","e9ee47f2":"kall = keras.callbacks.EarlyStopping(monitor='val_rmse',patience=10,restore_best_weights=True)\n\nhistory = model.fit(\n    data_augmentation.flow(x_train,y_train,batch_size=1024),\n    validation_data = (x_test,y_test),\n    steps_per_epoch = len(x_train) \/\/ 1024,\n    epochs = 600, callbacks=[kall]\n)","db7d83eb":"plt.figure()\nplt.plot(history.history[\"rmse\"], label=\"train_rmse\")\nplt.plot(history.history[\"val_rmse\"], label=\"val_rmse\")\nplt.title(\"RMSE train\/validation by Epoch\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"RMSE\")\nplt.legend(loc=\"upper right\");","45d9a924":"#predict on the submission data\ncnn_pred = model.predict(X_submission)\nprint(X_submission.shape, type(X_submission))\nprint(cnn_pred.shape, type(cnn_pred))","772bd884":"#put the submission predictions alongside their associated Ids\ncnn = pd.DataFrame()\ncnn['Id'] = test['Id']\ncnn['Pawpularity'] = cnn_pred\ncnn.to_csv('submission.csv',index=False)","56c47ec0":"testing_example_image = plt.imread('..\/input\/petfinder-pawpularity-score\/test\/4128bae22183829d2b5fea10effdb0c3.jpg') \nprint(testing_example_image.shape)\n#then plt.imshow() can display it for you\nplt.imshow(testing_example_image)\nplt.title('First Testing Image \\n Predicted Pawpularity = {}'.format(cnn['Pawpularity'].iloc[0])) \nplt.axis('off') #turns off the gridlines\nplt.show()","b7f1c845":"<h1 style=\"color:#8BB065;font-size:50px;\"><strong>My first <strong style=\"color:#974949\"> Convolutional Neural Network<\/strong><\/strong><\/h1>\n\n\n<img src=\"https:\/\/i.ibb.co\/VMSgnJ5\/header.png\" alt=\"header\" border=\"0\">\n\nLearning CNN from this notebook: [Link](https:\/\/www.kaggle.com\/alexteboul\/tutorial-part-3-cnn-image-modeling-1)","0b988cba":"<h1 style=\"color:#189AB4;font-size:20px;\"><strong>EDA<strong style=\"color:black\"><\/strong><\/strong><\/h1>"}}