{"cell_type":{"429bc3b3":"code","4170c5b7":"code","fcc3a446":"code","302437e6":"code","baf0abb5":"code","9cb94679":"code","3f24600e":"code","db1fbda1":"code","bd48e96b":"code","14fafa52":"code","5a4f5d91":"code","24dca1fd":"code","afe17e26":"code","5418814d":"code","9ab07cac":"code","c93345c3":"code","cad080ea":"code","ce2d3efb":"code","f5fa503f":"code","b1e906b7":"code","5073ad8d":"code","2d3ddd7e":"code","cd26350f":"code","c6486ea1":"code","e1a5e86e":"code","6e835091":"code","2b5554d1":"code","2bf215c8":"code","d38f4a73":"code","c78f7979":"code","f0ecb52f":"code","25550706":"code","3f4bd4ca":"code","c562b15e":"code","7efd36fa":"code","929ddc02":"code","8595054b":"code","76b5a269":"code","843cae8e":"code","1f709d9e":"code","3813b933":"code","6331b9a1":"code","8d6dedc8":"code","07972a61":"code","e8f4951c":"code","ce46642b":"code","a5c41080":"code","bcaccb96":"code","b5a19e67":"code","c8dfc44d":"code","d9f83d42":"code","c4fa217a":"code","b392e4de":"code","75d2669b":"code","f0d127ae":"code","67f28d04":"code","7e3d65e1":"code","446ee8af":"code","5245d1fa":"code","82187232":"code","8dd2c463":"code","532d95c2":"code","feca5042":"code","ff61f48b":"markdown","20af5ba4":"markdown","c2979a45":"markdown","48fdaf64":"markdown","8e921012":"markdown","889de80b":"markdown","eede57db":"markdown","949bf802":"markdown","d7e744c6":"markdown","1cde8717":"markdown","96b8da5b":"markdown","23eaaadd":"markdown","c7f12d44":"markdown"},"source":{"429bc3b3":"#Importing Packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom sklearn.model_selection  import train_test_split\nfrom sklearn.cluster import KMeans\nfrom scipy.stats import zscore","4170c5b7":"missing_values = [\"n\/a\", \"na\",\"?\", \"--\",\"-\"]                                                                            \ndata = pd.read_csv ('..\/input\/autompg-dataset\/auto-mpg.csv', na_values = missing_values)\nprint(data)","fcc3a446":"data.isnull().sum()","302437e6":"import json\nwith open('..\/input\/car-attributes\/Part1 - Car-Attributes.json','r') as f:\n    data1 = json.load(f)\ndf = pd.DataFrame(data1)\nprint(df)","baf0abb5":"df.head()","9cb94679":"df.isnull().sum()","3f24600e":"df.info()","db1fbda1":"df2 = pd.concat([df,data], axis=1)\ndf2.head()","bd48e96b":"df2.shape","14fafa52":"df2.duplicated().sum()","5a4f5d91":"df3 = pd.read_csv (r'C:\\Users\\gunja\\OneDrive\\Desktop\\Part1Modifiedc.csv', na_values = missing_values)\ndf3.tail()","24dca1fd":"df3.info()","afe17e26":"df3.corr()","5418814d":"df3.describe()","9ab07cac":"sns.set_style(\"darkgrid\")\n\nsns.pairplot(df3)","c93345c3":"sns.set_style(\"darkgrid\")\nsns.histplot(df3['mpg'])\nplt.show()","cad080ea":"sns.set_style(\"darkgrid\")\nsns.displot(data=df3, x=\"disp\")","ce2d3efb":"fmri = sns.load_dataset(\"fmri\")\nsns.relplot(\n    data=df3, kind=\"line\",\n    x=\"mpg\", y=\"disp\")","f5fa503f":"plt.figure(figsize=(5,7))\nsns.heatmap(df3.corr(),\n            annot=True,\n            linewidths=.5,\n            center=0,\n            cbar=False,\n            cmap=\"YlGnBu\")\nplt.show()","b1e906b7":"df3.head()","5073ad8d":"df3.info()","2d3ddd7e":"#dropping the Column name \"Car_name\"\ndf10 = df3.drop(['car name'], axis = 1)","cd26350f":"df10.dropna(inplace=True) ","c6486ea1":"from scipy.stats import zscore","e1a5e86e":"dfscl = df10.apply(zscore)\ndfscl.head()","6e835091":"#Finding optimal no. of clusters\nfrom scipy.spatial.distance import cdist\nclusters=range(1,10)\nmeanDistortions=[]\n\nfor k in clusters:\n    model=KMeans(n_clusters=k)\n    model.fit(dfscl)\n    prediction=model.predict(dfscl)\n    meanDistortions.append(sum(np.min(cdist(dfscl, model.cluster_centers_, 'euclidean'), axis=1)) \/ dfscl.shape[0])\n\n\nplt.plot(clusters, meanDistortions, 'bx-')\nplt.xlabel('k')\nplt.ylabel('Average distortion')\nplt.title('Selecting k with the Elbow Method')","2b5554d1":"# Let us first start with K = 2\nfinal_model=KMeans(2)\nfinal_model.fit(dfscl)\nprediction=final_model.predict(dfscl)\n\n#Append the prediction \ndf10[\"GROUP\"] = prediction\ndfscl[\"GROUP\"] = prediction\nprint(\"Groups Assigned : \\n\")\ndfscl.head()","2bf215c8":"dClust = dfscl.groupby(['GROUP'])\ndClust.mean()","d38f4a73":"# Considering K = 3\nfinal_model=KMeans(3)\nfinal_model.fit(dfscl)\nprediction=final_model.predict(dfscl)\n\n#Append the prediction \ndf10[\"GROUP\"] = prediction\ndfscl[\"GROUP\"] = prediction\nprint(\"Groups Assigned : \\n\")\ndf10.head()","c78f7979":"dlcust1 = dfscl.groupby(['GROUP'])\ndlcust1.mean()","f0ecb52f":"#Seting the value of k=3\nkmeans = KMeans(n_clusters=3, n_init = 15)","25550706":"kmeans.fit(dfscl)","3f4bd4ca":"centroids = kmeans.cluster_centers_\ncentroids","c562b15e":"#Clculate the centroids for the columns to profile\ncentroid_df = pd.DataFrame(centroids, columns = list(dfscl) )\nprint(centroid_df)","7efd36fa":"centroid_df.mean()","929ddc02":"plt.figure(figsize=(5,7))\nsns.heatmap(dfscl.corr(),\n            annot=True,\n            linewidths=.5,\n            center=0,\n            cbar=False,\n            cmap=\"YlGnBu\")\nplt.show()","8595054b":"from sklearn.cluster import AgglomerativeClustering ","76b5a269":"model = AgglomerativeClustering(n_clusters=3, affinity='euclidean',  linkage='average')","843cae8e":"model.fit(dfscl)","1f709d9e":"dfscl['labels'] = model.labels_\ndfscl.head(10)","3813b933":"dfsclClust = dfscl.groupby(['labels'])","6331b9a1":"dfsclClust.mean()","8d6dedc8":"from scipy.cluster.hierarchy import cophenet, dendrogram, linkage","07972a61":"from scipy.spatial.distance import pdist  #Pairwise distribution between data points","e8f4951c":"# is a measure of the correlation between the distance of points in feature space and distance on dendrogram\n# closer it is to 1, the better is the clustering\n\nZ = linkage(dfscl, metric='euclidean', method='average')\nc, coph_dists = cophenet(Z , pdist(dfscl))\nc","ce46642b":"plt.figure(figsize=(10, 5))\nplt.title('Agglomerative Hierarchical Clustering Dendogram')\nplt.xlabel('sample index')\nplt.ylabel('Distance')\ndendrogram(Z, leaf_rotation=90.,color_threshold = 40, leaf_font_size=8. )\nplt.tight_layout()","a5c41080":"# cophenet index is a measure of the correlation between the distance of points in feature space and distance on dendrogram\n# closer it is to 1, the better is the clustering\n\nZ = linkage(dfscl, metric='euclidean', method='complete')\nc, coph_dists = cophenet(Z , pdist(dfscl))\n\nc","bcaccb96":"plt.figure(figsize=(10, 5))\nplt.title('Agglomerative Hierarchical Clustering Dendogram')\nplt.xlabel('sample index')\nplt.ylabel('Distance')\ndendrogram(Z, leaf_rotation=90.,color_threshold=90,  leaf_font_size=10. )\nplt.tight_layout()","b5a19e67":"# cophenet index is a measure of the correlation between the distance of points in feature space and distance on dendrogram\n# closer it is to 1, the better is the clustering\n\nZ = linkage(dfscl, metric='euclidean', method='ward')\nc, coph_dists = cophenet(Z , pdist(dfscl))\n\nc","c8dfc44d":"plt.figure(figsize=(10, 5))\nplt.title('Agglomerative Hierarchical Clustering Dendogram')\nplt.xlabel('sample index')\nplt.ylabel('Distance')\ndendrogram(Z, leaf_rotation=90.,color_threshold=600,  leaf_font_size=10. )\nplt.tight_layout()","d9f83d42":"dMatrix = np.cov(dfscl,rowvar=False)\nprint(dMatrix)","c4fa217a":"from sklearn.decomposition import PCA\npca = PCA(n_components=6)\npca.fit(dfscl)","b392e4de":"print(pca.explained_variance_)","75d2669b":"print(pca.components_)","f0d127ae":"print(pca.explained_variance_ratio_)","67f28d04":"plt.bar(list(range(1,7)),pca.explained_variance_ratio_,alpha=0.5, align='center')\nplt.ylabel('Variation explained')\nplt.xlabel('eigen Value')\nplt.show()","7e3d65e1":"plt.step(list(range(1,7)),np.cumsum(pca.explained_variance_ratio_), where='mid')\nplt.ylabel('Cum of variation explained')\nplt.xlabel('eigen Value')\nplt.show()","446ee8af":"pca3 = PCA(n_components=4)\npca3.fit(dfscl)\nprint(pca3.components_)\nprint(pca3.explained_variance_ratio_)\nXpca3 = pca3.transform(dfscl)","5245d1fa":"Xpca3","82187232":"sns.pairplot(pd.DataFrame(Xpca3))","8dd2c463":"X = dfscl.drop(['mpg'], axis=1)\n# the dependent variable\ny = dfscl[['mpg']]\n\nsns.pairplot(X, diag_kind='kde')","532d95c2":"from sklearn.linear_model import LinearRegression\nregression_model = LinearRegression()\nregression_model.fit(df10, y)\nregression_model.score(df10, y)","feca5042":"regression_model_pca = LinearRegression()\nregression_model_pca.fit(Xpca3, y)\nregression_model_pca.score(Xpca3, y)","ff61f48b":"<b> <u><font color = teal> Using the distance measure along with avearage method gives us a better cophenet index.","20af5ba4":"# <font color = PUrple> mpG DATASET","c2979a45":"### <font color = Navy Blue> DOMAIN: Automobile","48fdaf64":"#### CONTEXT: The  data  concerns  city-cycle  fuel  consumption  in  miles  per  gallon,  to  be  predicted  in  terms  of  3  multivalued  discrete  and  5 continuous attributes\n\n- <b> <font color = Red> DATA DESCRIPTION: The data concerns city-cycle fuel consumption in miles per gallon","8e921012":"\n### Scaling the data  for Clustering and dropping the unwanted column for further model fit.\n","889de80b":"#### <b> <font color = Teal>  OBJECTIVE: Goal is to cluster the data and treat them as individual datasets to train Regression models to predict \u2018mpg","eede57db":"<b> <font color = Teal> After using the PCA data with the linar regression, it looks like the raw data is an overfit for the same and hence, post normalizing the data after identifying the PCA, fitting it into a Linear Regression gives us a score of 87%, we may need few more realeavant data to make sure acheive a better score when we fit the PCA variables in Linear Regression or other models. ","949bf802":"#### <font color= Purple> <b>Using 3 Clusters gives us  better understanding and differentiation for the data hence, setting K values as 3. ","d7e744c6":"<font color = Teal> Since, there is no null values and there is dataset is free of duplication, exporting the file to CSV.","1cde8717":"#### <font color = Purple> Considering The Value of K as 2 since the data takes a sharp turn at 3 and 2. ","96b8da5b":"<font color = Purple> \nGoing by the Heatmap we can see there is a correlation between these variables:\n    \n- MPG & Acc = 0.42\n- CYL & Disp = 0.95\n- Disp & Cyl = 0.95\n- HP & Displacement = 0.90 \n- HP & Weight = 0.86. ","23eaaadd":"<b> <u><font color = teal> The dataset has been combined, on data set was in JSON and the other detail was provided in CSV hence, merged the data using pandas. ","c7f12d44":"# ========================================================="}}