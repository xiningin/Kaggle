{"cell_type":{"eae862be":"code","0f592624":"code","adbd00fd":"code","7bb47b77":"code","643769ed":"code","2ea3d71f":"code","cdfbf59b":"code","56688488":"code","59b6faee":"code","4d492437":"code","452fc183":"code","9c2280e2":"code","54a73ea1":"code","aea56b08":"code","050dfd1b":"code","8eee7782":"code","0bf9ddfd":"code","a6dfd496":"code","f46fd1bd":"code","1fce02eb":"code","72d6fdca":"code","ce8906bf":"code","1aec7027":"code","6bc605a0":"markdown","f2ff0760":"markdown","9f333492":"markdown","b489e1ee":"markdown","2ccbe57e":"markdown","1b66125c":"markdown","2aaa0b5c":"markdown","81272954":"markdown","49a4f8d8":"markdown"},"source":{"eae862be":"import cv2\nimport numpy as np\nfrom pylab import *\nimport matplotlib.pyplot as plt\nfrom skimage import io","0f592624":"# Read Image 01\nimage_01 = cv2.imread('..\/input\/puppy-image\/puppy_01.jpg')\n# Read image 02\nimage_02 = cv2.imread('..\/input\/puppy-image\/puppy_02.jpg')","adbd00fd":"# Define alpha and Beta\nalpha = 0.30\nbeta = 0.70","7bb47b77":"# Blend images\nblend_images = cv2.addWeighted(image_01, alpha, image_02, beta, 0.0)","643769ed":"# Image show\nplt.figure(figsize = (10, 8))\nio.imshow(blend_images)","2ea3d71f":"image = cv2.imread('..\/input\/puppy-image\/puppy_01.jpg')","cdfbf59b":"# Create a dummy image that stores different contrast and brightness\nnew_image = np.zeros(image.shape, image.dtype)","56688488":"# Brightness and contrest parameters\ncontrast = 3.0\nbright = 2","59b6faee":"# Change the contrast and brightness\nfor x in range(image.shape[0]):\n    for y in range(image.shape[1]):\n        for z in range(image.shape[2]):\n            new_image[x, y, z] = np.clip(contrast * image[x, y, z] + bright, 0, 255)","4d492437":"# Show First Image\nfigure(0)\nplt.figure(figsize = (10, 8))\nplt.title(\"Before Change Image Contrast and Brightness\")\nio.imshow(image)\n\n# Show Second Image\nfigure(1)\nplt.figure(figsize = (10, 8))\nplt.title(\"After Change Image Contrast and Brightness\")\nio.imshow(new_image)","452fc183":"# Define Font\nfont = cv2.FONT_HERSHEY_SIMPLEX","9c2280e2":"# Write on the image\nplt.figure(figsize = (10, 8))\ncv2.putText(image, \"I am a Cute Puppy\", (10, 50), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\nio.imshow(image)","54a73ea1":"#Read images for different blurring purposes\nimage_Original = cv2.imread(\"..\/input\/puppy-image\/puppy_01.jpg\")\nimage_MedianBlur = cv2.imread(\"..\/input\/puppy-image\/puppy_01.jpg\")\nimage_GaussianBlur = cv2.imread(\"..\/input\/puppy-image\/puppy_01.jpg\")\nimage_BilateralBlur = cv2.imread(\"..\/input\/puppy-image\/puppy_01.jpg\")\n\n#Blur images\nimage_MedianBlur=cv2.medianBlur(image_MedianBlur,9)\nimage_GaussianBlur=cv2.GaussianBlur(image_GaussianBlur,(9,9),10)\nimage_BilateralBlur=cv2.bilateralFilter(image_BilateralBlur,9,100,75)","aea56b08":"#Show images\nfigure(0)\nplt.title(\"Orginal Image\")\nio.imshow(image_Original)\n\nfigure(1)\nplt.title(\"Median Blur Image\")\nio.imshow(image_MedianBlur)\n\nfigure(2)\nplt.title(\"Gaussian Blur Image\")\nio.imshow(image_GaussianBlur)\n\nfigure(3)\nplt.title(\"Bilateral Blur Image\")\nio.imshow(image_BilateralBlur)","050dfd1b":"#Read image\nimage = cv2.imread(\"..\/input\/puppy-image\/puppy_01.jpg\")\n#Define erosion size\ns1 = 0\ns2 = 10\ns3 = 10","8eee7782":"#Define erosion type\nt1 = cv2.MORPH_RECT\nt2 = cv2.MORPH_CROSS\nt3 = cv2.MORPH_ELLIPSE\n#Define and save the erosion template\ntmp1 = cv2.getStructuringElement(t1, (2*s1 + 1, 2*s1+1), (s1, s1))\ntmp2= cv2.getStructuringElement(t2, (2*s2 + 1, 2*s2+1), (s2, s2))\ntmp3 = cv2.getStructuringElement(t3, (2*s3 + 1, 2*s3+1), (s3, s3))\n#Apply the erosion template to the image and save in different variables\nfinal1 = cv2.erode(image, tmp1)\nfinal2 = cv2.erode(image, tmp2)\nfinal3 = cv2.erode(image, tmp3)","0bf9ddfd":"#Show all the images with different erosions\nfigure(0)\nio.imshow(final1)\nfigure(1)\nio.imshow(final2)\nfigure(2)\nio.imshow(final3)","a6dfd496":"#Define dilation size\nd1 = 0\nd2 = 10\nd3 = 20\n#Define dilation type\nt1 = cv2.MORPH_RECT\nt2 = cv2.MORPH_CROSS\nt3 = cv2.MORPH_ELLIPSE\n#Store the dilation templates\ntmp1 = cv2.getStructuringElement(t1, (2*d1 + 1, 2*d1+1), (d1, d1))\ntmp2 = cv2.getStructuringElement(t2, (2*d2 + 1, 2*d2+1), (d2, d2))\ntmp3 = cv2.getStructuringElement(t3, (2*d3 + 1, 2*d3+1), (d3, d3))\n#Apply dilation to the images\nfinal1 = cv2.dilate(image, tmp1)\nfinal2 = cv2.dilate(image, tmp2)\nfinal3 = cv2.dilate(image, tmp3)","f46fd1bd":"#Show the images\nfigure(0)\nio.imshow(final1)\nfigure(1)\nio.imshow(final2)\nfigure(2)\nio.imshow(final3)","1fce02eb":"#Define threshold types\n\"\"\"\n0 - Binary\n1 - Binary Inverted\n2 - Truncated\n3 - Threshold To Zero\n4 - Threshold To Zero Inverted\n\"\"\"","72d6fdca":"#Apply different thresholds and save in different variables\n_, img1 = cv2.threshold(image, 50, 255, 0 )\n_, img2 = cv2.threshold(image, 50, 255, 1 )\n_, img3 = cv2.threshold(image, 50, 255, 2 )\n_, img4 = cv2.threshold(image, 50, 255, 3 )\n_, img5 = cv2.threshold(image, 50, 255, 4 )\n\n#Show the different threshold images\nfigure(0)\nio.imshow(img1) #Prints Binary Image\nfigure(1)\nio.imshow(img2) #Prints Binary Inverted Image\nfigure(2)\nio.imshow(img3) #Prints Truncated Image\nfigure(3)\nio.imshow(img4) #Prints Threshold to Zero Image\nfigure(4)\nio.imshow(img5) #Prints Threshold to Zero Inverted Image","ce8906bf":"#Apply gaussian blur\ncv2.GaussianBlur(image, (3, 3), 0)\n#Convert image to grayscale\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#Apply Sobel method to the grayscale image\ngrad_x = cv2.Sobel(gray, cv2.CV_16S, 1, 0, ksize=3, scale=1,\ndelta=0, borderType=cv2.BORDER_DEFAULT) #Horizontal Sobel Derivation\ngrad_y = cv2.Sobel(gray, cv2.CV_16S, 0, 1, ksize=3, scale=1,\ndelta=0, borderType=cv2.BORDER_DEFAULT) #Vertical Sobel Derivation\nabs_grad_x = cv2.convertScaleAbs(grad_x)\nabs_grad_y = cv2.convertScaleAbs(grad_y)\ngrad = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n#Apply both\n#Show the image\nio.imshow(grad)#View the image","1aec7027":"#Convert to grayscale\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#Apply equalize histogram\nimage_eqlzd = cv2.equalizeHist(image) #Performs Histogram Equalization\n#Show both images\nfigure(0)\nio.imshow(image)\nfigure(1)\nio.imshow(image_eqlzd)\nfigure(2)\nio.imshow(image_eqlzd)","6bc605a0":"## Adding Text to Images\ncv2.putText() is a function present in the cv2 module that allows us to\nadd text to images. The function takes following arguments:\n* Image, where you want to write the text\n* The text you want to write\n* Position of the text on the image","f2ff0760":"## <b style=\"color:blue\">Belnding Two Images<\/b>\n\nSuppose you have two images and you want to belnd them sp that features of both images are visible. We use registration techniques to blend one image over the the second one and determine whether there are any changes. Let's look at the code:","9f333492":"## Changing Contrast and Brightness:\n\nTo change contrast and brightness in an image, we should have an\nunderstanding of what these two terms mean:\n   * ## <b style=\"color:blue\"> **Contrast:** <\/b>\n        Contrast is the difference between maximum and minimum pixel intensity.\n   * ## <b style=\"color:blue\"> **Brightness:** <\/b>\n        Brightness refers to the lightness or darkness of an image. To make an image brighter, we add a constant number to all the             pixels present in it.\n\nLet\u2019s look at the code and the output, to see the difference between\ncontrast and brightness.","b489e1ee":"## Changing The Image Shape\nIn this section we examine erosion and dilation, which are the two\noperations used to change the shape of images. Dilation results in the\naddition of pixels to the boundary of an object; erosion leads to the\nremoval of pixels from the boundary.","2ccbe57e":"## <b style=\"color:blue\">**import cv2:**<\/b>\nThe complete OpenCV library is present in the package cv2.\n\n## <b style=\"color:blue\"> **cv2.imread():** <\/b>\nSimilar to skimage.io.imread(), we have cv2.imread(), which is used to read the image from a particular destination.\n\n## <b style=\"color:blue\">**cv2.addWeighted():**<\/b>\nThis function blends the two images. The alpha and beta parameters indicate the transparency in both images. There are a few formulas that help to determine the final blending. The last parameter is called gamma. Currently it has a value of zero. It\u2019s just a scalar, which is added to the formulas, to transform the images more effectively. In general, gamma is zero.","1b66125c":"## Calculating Image Gradients\nIn this section we look at edge detection using Sobel derivatives. Edges are\nfound in two directions: the vertical direction and the horizontal direction.\nWith this algorithm, we emphasize only those regions that have very high\nspatial frequency, which may correspond to edges. Spatial frequency is the\nlevel of detail present in an area of importance.","2aaa0b5c":"## Imorting required Packages","81272954":"## Effecting Image Threshold\nThe main reason you would do image thresholding is to segment images.\nWe try to get an object out of the image by removing the background and\nby focusing on the object. To do this, we first convert the image to grayscale\nand then into a binary format\u2014meaning, the image contains black or\nwhite only.","49a4f8d8":"## Smoothing Images\nIn this section we take a look at three filters used to smooth images. These\nfilters are as follows:\n* The median filter (cv2.medianBlur)\n* The gaussian filter (cv2.GaussianBlur)\n* The bilateral filter (cv2.bilateralFilter)"}}