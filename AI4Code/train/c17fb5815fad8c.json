{"cell_type":{"a832e9f3":"code","9c886f9e":"code","cd46907b":"code","d18f6f2b":"code","55ff1882":"code","8cb2bb9e":"code","8489832f":"code","5ff852d6":"code","da2f2577":"code","dfc70940":"code","62fef84d":"code","b621667a":"code","3dbb9b5b":"code","b04a253c":"code","80c3417b":"code","e4b115d2":"code","e55a6f12":"code","604273d1":"code","9eefc4db":"code","51c3ecd8":"code","75ad68eb":"code","d9818241":"code","d2dc4978":"code","1fce0896":"code","51508d42":"code","e77df3ac":"code","bf046f64":"code","8b22d362":"code","3e088924":"code","9a53c82f":"code","c7541204":"code","97070847":"code","a2e06c9e":"markdown","1d00c1af":"markdown","05ea713f":"markdown","cd9ddfcd":"markdown","b3cf9c91":"markdown","28159aef":"markdown"},"source":{"a832e9f3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as tfl\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models, Model\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Flatten, Dense, Dropout,Input, Add, ReLU, GlobalAveragePooling2D, MaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\n\nimport sklearn\n\nimport os\nimport cv2\nfrom PIL import Image","9c886f9e":"dir_train = \"..\/input\/iitgai-hackathon-2-2021-2022\/\"\nos.listdir(dir_train)","cd46907b":"train_csv = pd.read_csv(dir_train + \"train_data.csv\")","d18f6f2b":"train_csv.image_id = train_csv.image_id.astype(str) + '.jpg'","55ff1882":"train_csv['file_path'] = dir_train + \"train_images\/train_images\/\" + train_csv['image_id']","8cb2bb9e":"train_csv = sklearn.utils.shuffle(train_csv,random_state=15)\ntrain_csv","8489832f":"BATCH_SIZE = 32\nIMG_SIZE = 300\ninput_shape = (IMG_SIZE,IMG_SIZE,3)\nclasses = sorted(train_csv.label.unique())","5ff852d6":"plt.figure(figsize=(15,12))\nplot_sample = train_csv.sample(13).reset_index(drop=True)\n\nfor i in range(12):\n    \n    plt.subplot(3,4,i+1)\n    \n    img = cv2.imread(dir_train + 'train_images\/train_images\/' + plot_sample.image_id[i])\n    img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    plt.axis('off')\n    plt.imshow(img)\n    plt.title(plot_sample.label[i])\n    \nplt.show()","da2f2577":"val_split = 0.2\ntotal_train_items = int(len(train_csv)*(1 - val_split))\ntotal_val_items = len(train_csv) - total_train_items\ntraining_df = train_csv[:total_train_items]\nval_df = train_csv[total_train_items:]","dfc70940":"training_data = tf.data.Dataset.from_tensor_slices((training_df.file_path.values, training_df.label.values))\nvalidation_data = tf.data.Dataset.from_tensor_slices((val_df.file_path.values, val_df.label.values))","62fef84d":"def load_images_from_path(image_path, label):\n    \n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels = 3)\n    return img, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain = training_data.map(load_images_from_path, num_parallel_calls=AUTOTUNE)\nval = validation_data.map(load_images_from_path, num_parallel_calls=AUTOTUNE)","b621667a":"train_batch = train.shuffle(buffer_size=1000).batch(batch_size=BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\nval_batch = val.shuffle(buffer_size=1000).batch(batch_size=BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)","3dbb9b5b":"data_augmentation = tf.keras.Sequential(\n[\n        tf.keras.layers.experimental.preprocessing.RandomCrop(height=IMG_SIZE, width=IMG_SIZE),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.25),\n        tf.keras.layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n        tf.keras.layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n])","b04a253c":"image = Image.open(train_csv.file_path[5])\nplt.imshow(image)\nplt.show()","80c3417b":"image = tf.expand_dims(np.array(image),0)","e4b115d2":"plt.figure(figsize = (15,15))\n\nfor i in range(12):\n    \n    aug = data_augmentation(image)\n    plt.subplot(3,4,i+1)\n    plt.imshow(aug[0])","e55a6f12":"adapt_data = tf.data.Dataset.from_tensor_slices(training_df.file_path.values)\ndef adapt_mode(image_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(img)\n    return img\n\nadapt_data = adapt_data.map(adapt_mode, num_parallel_calls=AUTOTUNE)\nadapt_data_batches = adapt_data.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)","604273d1":"eff_net = tf.keras.applications.EfficientNetB3(weights='imagenet', include_top = False, input_shape = input_shape)\n\ninputs = Input(shape = input_shape)\n\naug_image = data_augmentation(inputs)\n\neff_net = eff_net(aug_image)\n\npool = tf.keras.layers.GlobalAveragePooling2D()(eff_net)\n\ndrop = tf.keras.layers.Dropout(0.4)(pool)\n\noutputs = tf.keras.layers.Dense(5, activation = 'softmax')(drop)\n\neff_model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n\neff_model.summary()","9eefc4db":"%%time\neff_model.get_layer('efficientnetb3').get_layer('normalization').adapt(adapt_data_batches)","51c3ecd8":"epochs = 10\ndecay_steps = int(round(len(training_df)\/BATCH_SIZE))*epochs\n\ncosine_decay = tf.keras.experimental.CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha = 0.3)\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath = 'eff_netb3.h5', monitor = 'val_acc', save_best_only = True)\n\ncallbacks = [checkpoint]\n\neff_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(cosine_decay), metrics=[\"accuracy\"])","75ad68eb":"eff_history = eff_model.fit(train_batch,\n                  epochs = epochs, \n                  validation_data=val_batch,\n                  callbacks=callb acks)","d9818241":"eff_model.save('eff_netb3.h5')","d2dc4978":"accuracy = eff_history.history['accuracy']\nval_accuracy  = eff_history.history['val_accuracy']\n\nloss = eff_history.history['loss']\nval_loss = eff_history.history['val_loss']\n\nplt.figure(figsize=(15,10))\n\nplt.subplot(2, 2, 1)\nplt.plot(accuracy, label = \"Training accuracy\")\nplt.plot(val_accuracy, label=\"Validation accuracy\")\nplt.legend()\nplt.title(\"Training vs validation accuracy\")\n\n\nplt.subplot(2,2,2)\nplt.plot(loss, label = \"Training loss\")\nplt.plot(val_loss, label=\"Validation loss\")\nplt.legend()\nplt.title(\"Training vs validation loss\")\n\nplt.show()","1fce0896":"def scan_over_image(img_path, crop_size=300):\n    \n    img = Image.open(img_path)\n    img_height, img_width = img.size\n    img = np.array(img)\n    \n    y = np.random.randint(0,img_height-crop_size)\n    x = np.random.randint(0,img_width-crop_size)\n\n    x_img_origins = [0,img_width-crop_size]\n    y_img_origins = [0,img_height-crop_size]\n    img_list = []\n    for x in x_img_origins:\n        for y in y_img_origins:\n            img_list.append(img[x:x+crop_size , y:y+crop_size,:])\n            \n    return np.array(img_list)","51508d42":"def display_samples(img_path):\n    \n    img_list = scan_over_image(img_path)\n    sample_number = len(img_list)\n    fig = plt.figure(figsize = (8,sample_number))\n    for i in range(0,sample_number):\n        ax = fig.add_subplot(2, 4, i+1)\n        ax.imshow(img_list[i])\n        ax.set_title(str(i))\n    plt.tight_layout()\n    plt.show()\n\ndisplay_samples(train_csv['file_path'][5])","e77df3ac":"test_time_augmentation_layers = tf.keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n    ]\n)","bf046f64":"def predict_and_vote(image_filename, folder, TTA_runs=4):\n    \n    localised_predictions = []\n    local_image_list = scan_over_image(folder+image_filename)\n    for local_image in local_image_list:\n        duplicated_local_image = tf.convert_to_tensor(np.array([local_image for i in range(TTA_runs)]))\n        augmented_images = test_time_augmentation_layers(duplicated_local_image)\n        \n        predictions = eff_model.predict(augmented_images)\n        localised_predictions.append(np.sum(predictions, axis=0))\n        \n    global_predictions = np.sum(np.array(localised_predictions),axis=0)\n    final_prediction = np.argmax(global_predictions)\n    \n    return final_prediction","8b22d362":"from tqdm import tqdm\ndef run_predictions_over_image_list(image_list, folder):\n    predictions = []\n    with tqdm(total=len(image_list)) as pbar:\n        for image_filename in image_list:\n            pbar.update(1)\n            predictions.append(predict_and_vote(image_filename, folder))\n    return predictions","3e088924":"test_folder = \"..\/input\/iitgai-hackathon-2-2021-2022\/test_images\/test_images\/\"","9a53c82f":"test_list = tf.io.gfile.listdir(test_folder)","c7541204":"final_pred = run_predictions_over_image_list(test_list, test_folder)","97070847":"data_eff = {\n    'image_id': test_list,\n    'label': final_pred\n}\nresult_eff = pd.DataFrame(data_eff)\n\nresult_eff['image_id'] = result_eff['image_id'].str.replace(\".jpg\", \"\")\nresult_eff['image_id'] = result_eff['image_id'].astype(int)\n\nresult_eff.to_csv('sub_effb3.csv', index=False)\nresult_eff","a2e06c9e":"### Importing Data","1d00c1af":"## Model","05ea713f":"### Efficient Net","cd9ddfcd":"#### Augmentation","b3cf9c91":"### Testing and Predicting","28159aef":"### Preparing the training and valdation data"}}