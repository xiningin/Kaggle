{"cell_type":{"1257dcb5":"code","7b83c4f8":"code","5f7ca710":"code","f6720904":"code","ed7820fb":"code","49dde5e1":"code","61e6e4cf":"code","6f179985":"code","7a5ee757":"code","e840f8c4":"code","c571e093":"code","7c69cabd":"code","dc0fbdc9":"code","cf0ff270":"code","170d2754":"code","1e54b1e2":"code","43d9b0db":"code","abd863e4":"code","87e4369f":"code","c3dbd79f":"code","fb7398d9":"code","85fd0c4d":"code","54c476f8":"code","36fcde06":"code","af5fb7c5":"code","60f4a806":"code","9b670db9":"markdown","c3a64cf7":"markdown"},"source":{"1257dcb5":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport urllib.request\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","7b83c4f8":"urllib.request.urlretrieve(\"https:\/\/raw.githubusercontent.com\/mohitgupta-omg\/Kaggle-SMS-Spam-Collection-Dataset-\/master\/spam.csv\", filename=\"spam.csv\")\ndata = pd.read_csv('spam.csv',encoding='latin1')","5f7ca710":"print('Total number of samples :',len(data))\n","f6720904":"data[:5]","ed7820fb":"del data['Unnamed: 2']\ndel data['Unnamed: 3']\ndel data['Unnamed: 4']\ndata['v1'] = data['v1'].replace(['ham','spam'],[0,1])\ndata[:5]","49dde5e1":"data.info()\n","61e6e4cf":"data.isnull().values.any()\n","6f179985":"data['v2'].nunique(), data['v1'].nunique()\n","7a5ee757":"data.drop_duplicates(subset=['v2'], inplace=True)","e840f8c4":"print('\ucd1d \uc0d8\ud50c\uc758 \uc218 :',len(data))\n","c571e093":"data['v1'].value_counts().plot(kind='bar');\n","7c69cabd":"print(data.groupby('v1').size().reset_index(name='count'))\n","dc0fbdc9":"X_data = data['v2']\ny_data = data['v1']\nprint('\uba54\uc77c \ubcf8\ubb38\uc758 \uac1c\uc218: {}'.format(len(X_data)))\nprint('\ub808\uc774\ube14\uc758 \uac1c\uc218: {}'.format(len(y_data)))","cf0ff270":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_data) # 5169\uac1c\uc758 \ud589\uc744 \uac00\uc9c4 X\uc758 \uac01 \ud589\uc5d0 \ud1a0\ud070\ud654\ub97c \uc218\ud589\nsequences = tokenizer.texts_to_sequences(X_data) # \ub2e8\uc5b4\ub97c \uc22b\uc790\uac12, \uc778\ub371\uc2a4\ub85c \ubcc0\ud658\ud558\uc5ec \uc800\uc7a5\n","170d2754":"print(sequences[:5])\n","1e54b1e2":"word_to_index = tokenizer.word_index\nprint(word_to_index)\n","43d9b0db":"threshold = 2\ntotal_cnt = len(word_to_index) # \ub2e8\uc5b4\uc758 \uc218\nrare_cnt = 0 # \ub4f1\uc7a5 \ube48\ub3c4\uc218\uac00 threshold\ubcf4\ub2e4 \uc791\uc740 \ub2e8\uc5b4\uc758 \uac1c\uc218\ub97c \uce74\uc6b4\ud2b8\ntotal_freq = 0 # \ud6c8\ub828 \ub370\uc774\ud130\uc758 \uc804\uccb4 \ub2e8\uc5b4 \ube48\ub3c4\uc218 \ucd1d \ud569\nrare_freq = 0 # \ub4f1\uc7a5 \ube48\ub3c4\uc218\uac00 threshold\ubcf4\ub2e4 \uc791\uc740 \ub2e8\uc5b4\uc758 \ub4f1\uc7a5 \ube48\ub3c4\uc218\uc758 \ucd1d \ud569\n\n# \ub2e8\uc5b4\uc640 \ube48\ub3c4\uc218\uc758 \uc30d(pair)\uc744 key\uc640 value\ub85c \ubc1b\ub294\ub2e4.\nfor key, value in tokenizer.word_counts.items():\n    total_freq = total_freq + value\n\n    # \ub2e8\uc5b4\uc758 \ub4f1\uc7a5 \ube48\ub3c4\uc218\uac00 threshold\ubcf4\ub2e4 \uc791\uc73c\uba74\n    if(value < threshold):\n        rare_cnt = rare_cnt + 1\n        rare_freq = rare_freq + value\n\nprint('\ub4f1\uc7a5 \ube48\ub3c4\uac00 %s\ubc88 \uc774\ud558\uc778 \ud76c\uadc0 \ub2e8\uc5b4\uc758 \uc218: %s'%(threshold - 1, rare_cnt))\nprint(\"\ub2e8\uc5b4 \uc9d1\ud569(vocabulary)\uc5d0\uc11c \ud76c\uadc0 \ub2e8\uc5b4\uc758 \ube44\uc728:\", (rare_cnt \/ total_cnt)*100)\nprint(\"\uc804\uccb4 \ub4f1\uc7a5 \ube48\ub3c4\uc5d0\uc11c \ud76c\uadc0 \ub2e8\uc5b4 \ub4f1\uc7a5 \ube48\ub3c4 \ube44\uc728:\", (rare_freq \/ total_freq)*100)\n","abd863e4":"vocab_size = len(word_to_index) + 1\nprint('\ub2e8\uc5b4 \uc9d1\ud569\uc758 \ud06c\uae30: {}'.format((vocab_size)))\n","87e4369f":"n_of_train = int(len(sequences) * 0.8)\nn_of_test = int(len(sequences) - n_of_train)\nprint('\ud6c8\ub828 \ub370\uc774\ud130\uc758 \uac1c\uc218 :',n_of_train)\nprint('\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\uc758 \uac1c\uc218:',n_of_test)","c3dbd79f":"X_data = sequences\nprint('\uba54\uc77c\uc758 \ucd5c\ub300 \uae38\uc774 : %d' % max(len(l) for l in X_data))\nprint('\uba54\uc77c\uc758 \ud3c9\uade0 \uae38\uc774 : %f' % (sum(map(len, X_data))\/len(X_data)))\nplt.hist([len(s) for s in X_data], bins=50)\nplt.xlabel('length of samples')\nplt.ylabel('number of samples')\nplt.show()","fb7398d9":"max_len = 189\n# \uc804\uccb4 \ub370\uc774\ud130\uc14b\uc758 \uae38\uc774\ub294 max_len\uc73c\ub85c \ub9de\ucda5\ub2c8\ub2e4.\ndata = pad_sequences(X_data, maxlen = max_len)\nprint(\"\ud6c8\ub828 \ub370\uc774\ud130\uc758 \ud06c\uae30(shape): \", data.shape)","85fd0c4d":"X_test = data[n_of_train:] #X_data \ub370\uc774\ud130 \uc911\uc5d0\uc11c \ub4a4\uc758 1034\uac1c\uc758 \ub370\uc774\ud130\ub9cc \uc800\uc7a5\ny_test = np.array(y_data[n_of_train:]) #y_data \ub370\uc774\ud130 \uc911\uc5d0\uc11c \ub4a4\uc758 1034\uac1c\uc758 \ub370\uc774\ud130\ub9cc \uc800\uc7a5\nX_train = data[:n_of_train] #X_data \ub370\uc774\ud130 \uc911\uc5d0\uc11c \uc55e\uc758 4135\uac1c\uc758 \ub370\uc774\ud130\ub9cc \uc800\uc7a5\ny_train = np.array(y_data[:n_of_train]) #y_data \ub370\uc774\ud130 \uc911\uc5d0\uc11c \uc55e\uc758 4135\uac1c\uc758 \ub370\uc774\ud130\ub9cc \uc800\uc7a5","54c476f8":"from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\nfrom tensorflow.keras.models import Sequential\n","36fcde06":"model = Sequential()\nmodel.add(Embedding(vocab_size, 32)) # \uc784\ubca0\ub529 \ubca1\ud130\uc758 \ucc28\uc6d0\uc740 32\nmodel.add(SimpleRNN(32)) # RNN \uc140\uc758 hidden_size\ub294 32\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\nhistory = model.fit(X_train, y_train, epochs=4, batch_size=64, validation_split=0.2)\n","af5fb7c5":"print(\"\\n \ud14c\uc2a4\ud2b8 \uc815\ud655\ub3c4: %.4f\" % (model.evaluate(X_test, y_test)[1]))\n","60f4a806":"epochs = range(1, len(history.history['acc']) + 1)\nplt.plot(epochs, history.history['loss'])\nplt.plot(epochs, history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","9b670db9":"\ud1a0\ud070\ud654","c3a64cf7":"5572 vs 5169"}}