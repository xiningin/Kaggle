{"cell_type":{"9419bd85":"code","0c56cdd4":"code","da8d35f2":"code","b04c1fc0":"code","70b39380":"code","2a825dd8":"code","7ad23cc3":"code","5146adca":"code","e710f00c":"code","5bbefc64":"code","5fbc28ba":"code","6e9aba84":"code","241fa28c":"code","cea9884a":"code","134532bb":"code","ab3377e1":"code","349244d4":"code","67f705c9":"code","21325988":"markdown","e079e0a5":"markdown","626b470c":"markdown","333aa95d":"markdown","05c6bd82":"markdown","17c41b14":"markdown","b8346c6a":"markdown","622c2de6":"markdown","d16101ab":"markdown","b3fc2106":"markdown","b3e06c78":"markdown","f0b1abd7":"markdown","9a47cfc2":"markdown","1c1ff40d":"markdown","3b2f0e35":"markdown"},"source":{"9419bd85":"import json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom kaggle_environments import (evaluate, make, utils, get_episode_replay, list_episodes)\nfrom datetime import datetime, date\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option(\"display.max_rows\", 200)\npd.options.display.float_format = '{:,.2f}'.format","0c56cdd4":"episodes = pd.read_csv(\"..\/input\/meta-kaggle\/Episodes.csv\")\nepisodes[\"CreateTime\"] = pd.to_datetime(episodes[\"CreateTime\"], format=\"%m\/%d\/%Y %H:%M:%S\")\nepisodes[\"EndTime\"] = pd.to_datetime(episodes[\"EndTime\"], format=\"%m\/%d\/%Y %H:%M:%S\")\nepisode_agents = pd.read_csv(\"..\/input\/meta-kaggle\/EpisodeAgents.csv\")\nsanta_df = pd.merge(episode_agents, episodes.loc[episodes[\"CompetitionId\"] == 24539], left_on=\"EpisodeId\", right_on=\"Id\")\nrps_df = pd.merge(episode_agents, episodes.loc[episodes[\"CompetitionId\"] == 22838], left_on=\"EpisodeId\", right_on=\"Id\")\nsanta_df = santa_df.drop(columns=[\"Id_x\", \"Index\", \"Reward\", \"State\", \"Id_y\", \"Type\", \"CompetitionId\"])\nrps_df = rps_df.drop(columns=[\"Id_x\", \"Index\", \"Reward\", \"State\", \"Id_y\", \"Type\", \"CompetitionId\"])\n\nepisodes_to_consider = episode_agents[episode_agents[\"EpisodeId\"].isin(episodes[\"Id\"].loc[episodes[\"CompetitionId\"].isin([24539, 22838])])].\\\n    groupby([\"SubmissionId\"])[\"EpisodeId\"].max().to_list()\ndel episodes, episode_agents\nagents_mapping = pd.DataFrame(columns = [\"TeamId\", \"SubmissionId\", \"submission_dt\"])\nfor i in range(0, len(episodes_to_consider), 1000):\n    batch = episodes_to_consider[i:i + 1000]\n    try:\n        resp = list_episodes(batch)  \n        for episode in resp[\"result\"][\"submissions\"]:\n            agents_mapping = agents_mapping.append({\"TeamId\": episode[\"teamId\"],\n                                                    \"SubmissionId\":  episode[\"id\"],\n                                                    \"submission_dt\": datetime.strptime(episode[\"dateSubmitted\"][:19], \"%Y-%m-%dT%H:%M:%S\")\n                               }, ignore_index=True)\n        del episode, batch\n    except Exception as ex:\n        print(\"Error:\", ex)\n        continue\n\nsanta_df = pd.merge(santa_df, agents_mapping, on=\"SubmissionId\") \nrps_df = pd.merge(rps_df, agents_mapping, on=\"SubmissionId\")\ndel episodes_to_consider, agents_mapping\nsanta_df = santa_df.drop_duplicates(subset=[\"EpisodeId\"], keep='last')\nrps_df = rps_df.drop_duplicates(subset=[\"EpisodeId\"], keep='last')\ngc.collect()\n\n!wget \"https:\/\/www.kaggle.com\/c\/rock-paper-scissors\/leaderboard.json?includeBeforeUser=true&includeAfterUser=false\" -O leaderboard_rps.json\nwith open(\"leaderboard_rps.json\") as f:\n    jsn = json.load(f)\n!rm leaderboard_rps.json\nleaderboard_rps = pd.DataFrame(columns = [\"team_name\", \"team_id\", \"final_score\", \"n_agents\"])\nfor user in jsn[\"beforeUser\"]+jsn[\"afterUser\"]:\n    leaderboard_rps = leaderboard_rps.append({\"team_name\": user[\"teamName\"], \n                                      \"team_id\": user[\"teamId\"], \n                                      \"final_score\": user[\"score\"], \n                                      \"n_agents\": user[\"entries\"]}, \n                                     ignore_index=True)\nleaderboard_rps[[\"score\", \"n_agents\"]] = leaderboard_rps[[\"final_score\", \"n_agents\"]].apply(pd.to_numeric)\nleaderboard_rps[\"final_score\"] = leaderboard_rps[\"final_score\"].apply(pd.to_numeric, errors='coerce')\nleaderboard_rps[\"team_rank\"] = leaderboard_rps[\"final_score\"].rank(method='dense', ascending=False).astype(int)\nrps_df = pd.merge(rps_df, leaderboard_rps.drop(columns=[\"final_score\", \"n_agents\"]), left_on=\"TeamId\", right_on=\"team_id\", how=\"left\")\nrps_df = rps_df.drop(columns=[\"team_id\"])\ngc.collect()\n\n!wget \"https:\/\/www.kaggle.com\/c\/santa-2020\/leaderboard.json?includeBeforeUser=true&includeAfterUser=false\" -O leaderboard_santa.json\nwith open(\"leaderboard_santa.json\") as f:\n    jsn = json.load(f)\n!rm leaderboard_santa.json\nleaderboard_santa = pd.DataFrame(columns = [\"team_name\", \"team_id\", \"final_score\", \"n_agents\"])\nfor user in jsn[\"beforeUser\"]+jsn[\"afterUser\"]:\n    leaderboard_santa = leaderboard_santa.append({\"team_name\": user[\"teamName\"], \n                                      \"team_id\": user[\"teamId\"], \n                                      \"final_score\": user[\"score\"], \n                                      \"n_agents\": user[\"entries\"]}, \n                                     ignore_index=True)\nleaderboard_santa[[\"score\", \"n_agents\"]] = leaderboard_santa[[\"final_score\", \"n_agents\"]].apply(pd.to_numeric)\nleaderboard_santa[\"final_score\"] = leaderboard_santa[\"final_score\"].apply(pd.to_numeric, errors='coerce')\nleaderboard_santa[\"team_rank\"] = leaderboard_santa[\"final_score\"].rank(method='dense', ascending=False).astype(int)\nsanta_df = pd.merge(santa_df, leaderboard_santa.drop(columns=[\"final_score\", \"n_agents\"]), left_on=\"TeamId\", right_on=\"team_id\", how=\"left\")\nsanta_df = santa_df.drop(columns=[\"team_id\"])\ngc.collect()\n\nsanta_df[\"date\"] = santa_df[\"CreateTime\"].dt.date\nrps_df[\"date\"] = rps_df[\"CreateTime\"].dt.date","da8d35f2":"interval = \"15min\"\n\nsanta_ranking = pd.DataFrame(columns = [\"team_name\", \"score\", \"rank\", \"dtime\"])\nfor dtime in pd.date_range(start=pd.to_datetime('2021-02-02', format='%Y-%m-%d'), end=santa_df[\"EndTime\"].max(), freq=interval).tolist():\n    new = santa_df[(santa_df[\"EndTime\"] <= dtime) & (santa_df[\"EndTime\"] >= (dtime - pd.Timedelta(hours=24)))].reset_index(drop=True)\n    new = new.iloc[new.groupby(\"SubmissionId\")[\"EndTime\"].idxmax()].groupby([\"team_name\"], sort=False)[\"UpdatedScore\"].max().reset_index()\n    new[\"rank\"] = new[\"UpdatedScore\"].dropna().rank(method=\"max\", ascending=False).astype(int)\n    new = new.rename(columns={\"UpdatedScore\": \"score\"})\n    new[\"dtime\"] = dtime\n    santa_ranking = santa_ranking.append(new, ignore_index = True)\n    del new\nsanta_ranking[\"date\"] = santa_ranking[\"dtime\"].dt.date\nsanta_ranking[\"rank\"] = santa_ranking[\"rank\"].apply(pd.to_numeric, errors='coerce')\ngc.collect()\n\nrps_ranking = pd.DataFrame(columns = [\"team_name\", \"score\", \"rank\", \"dtime\"])\nfor dtime in pd.date_range(start=pd.to_datetime('2021-02-02', format='%Y-%m-%d'), end=rps_df[\"EndTime\"].max(), freq=interval).tolist():\n    new = rps_df[(rps_df[\"EndTime\"] <= dtime) & (rps_df[\"EndTime\"] >= (dtime - pd.Timedelta(hours=24)))].reset_index(drop=True)\n    new = new.iloc[new.groupby(\"SubmissionId\")[\"EndTime\"].idxmax()].groupby([\"team_name\"], sort=False)[\"UpdatedScore\"].max().reset_index()\n    new[\"rank\"] = new[\"UpdatedScore\"].dropna().rank(method=\"max\", ascending=False).astype(int)\n    new = new.rename(columns={\"UpdatedScore\": \"score\"})\n    new[\"dtime\"] = dtime\n    rps_ranking = rps_ranking.append(new, ignore_index = True)\n    del new\nrps_ranking[\"date\"] = rps_ranking[\"dtime\"].dt.date\nrps_ranking[\"rank\"] = rps_ranking[\"rank\"].apply(pd.to_numeric, errors='coerce')\ngc.collect()","b04c1fc0":"rps = rps_ranking.groupby([\"team_name\",\"date\"]).agg({\"rank\": [np.ptp, np.std]}).reset_index()\nrps.columns = rps.columns.droplevel()\nrps.columns = [\"team_name\", \"date\", \"RPS_rank_range\", \"RPS_rank_std\"]\nrps = rps.groupby([\"date\"]).agg({\"RPS_rank_range\": np.mean, \"RPS_rank_std\": np.mean})\nsanta = santa_ranking.groupby([\"team_name\",\"date\"]).agg({\"rank\": [np.ptp, np.std]}).reset_index()\nsanta.columns = santa.columns.droplevel()\nsanta.columns = [\"team_name\", \"date\", \"Santa_rank_range\", \"Santa_rank_std\"]\nsanta = santa.groupby([\"date\"]).agg({\"Santa_rank_range\": np.mean, \"Santa_rank_std\": np.mean})\ndate_stat = pd.merge(rps, santa, on=\"date\").dropna()\ndel rps, santa","70b39380":"date_stat.drop(columns=[\"RPS_rank_std\", \"Santa_rank_std\"]).plot(figsize=(25,10), cmap=\"Spectral\",\n               title=\"Average daily range of team rank for Rock, Paper, Scissors (RPS) and Santa-2020 competitions\")\nplt.show()","2a825dd8":"date_stat.drop(columns=[\"RPS_rank_range\", \"Santa_rank_range\"]).plot(figsize=(25,10), cmap=\"Spectral\",\n               title=\"Daily standard deviation of team rank for Rock, Paper, Scissors (RPS) and Santa-2020 competitions\")\nplt.show()","7ad23cc3":"team_brkdn_santa = pd.merge(leaderboard_santa.loc[:, [\"team_name\", \"team_rank\"]].rename(columns={\"team_rank\": \"current_rank\"}),\n         santa_ranking.groupby([\"team_name\"])[\"rank\"].min().reset_index().rename(columns={\"rank\": \"highest_rank\"}), on=\"team_name\")\nteam_brkdn_santa[\"highest_rank\"] = team_brkdn_santa.apply(lambda x: x[\"current_rank\"] if x[\"current_rank\"] < x[\"highest_rank\"] else x[\"highest_rank\"], axis=1)\nteam_brkdn_santa[\"highest rank - current rank\"] = team_brkdn_santa[\"current_rank\"] - team_brkdn_santa[\"highest_rank\"]\nteam_brkdn_santa[\"highest rank - current rank\"] = team_brkdn_santa[\"highest rank - current rank\"].apply(pd.to_numeric, errors='coerce')\nteam_brkdn_santa[\"highest rank - current rank\"].plot(kind=\"hist\", figsize=(25,7), color=\"lightcoral\", bins=30, \n                                                     title=\"Santa-2020: difference between current and highest team rank\")\nplt.show()","5146adca":"team_brkdn_santa.sort_values(by=[\"current_rank\"]).reset_index(drop=True).head(200).\\\n    style.background_gradient(subset=[\"highest rank - current rank\"], cmap=\"Wistia\")","e710f00c":"team_brkdn_rps = pd.merge(leaderboard_rps.loc[:, [\"team_name\", \"team_rank\"]].rename(columns={\"team_rank\": \"current_rank\"}),\n         rps_ranking.groupby([\"team_name\"])[\"rank\"].min().reset_index().rename(columns={\"rank\": \"highest_rank\"}), on=\"team_name\")\nteam_brkdn_rps[\"highest_rank\"] = team_brkdn_rps.apply(lambda x: x[\"current_rank\"] if x[\"current_rank\"] < x[\"highest_rank\"] else x[\"highest_rank\"], axis=1)\nteam_brkdn_rps[\"highest rank - current rank\"] = team_brkdn_rps[\"current_rank\"] - team_brkdn_rps[\"highest_rank\"]\nteam_brkdn_rps[\"highest rank - current rank\"].plot(kind=\"hist\", figsize=(25,7), color=\"navajowhite\", bins=30, \n                                                     title=\"Rock, Paper, Scissors: difference between current and highest team rank\")\nplt.show()","5bbefc64":"team_brkdn_rps.sort_values(by=[\"current_rank\"]).reset_index(drop=True).head(200).\\\n    style.background_gradient(subset=[\"highest rank - current rank\"], cmap=\"Wistia\")","5fbc28ba":"date_stat_agent = pd.merge(\n        santa_df[santa_df[\"CreateTime\"] >= pd.to_datetime('2021-02-02', format='%Y-%m-%d')].\\\n            groupby([\"SubmissionId\", \"date\"])[\"UpdatedScore\"].std().reset_index().\\\n            groupby(\"date\")[\"UpdatedScore\"].mean().reset_index().rename(columns={\"UpdatedScore\": \"Santa: average standard deviation of agent scores\"}),\n        rps_df[rps_df[\"CreateTime\"] >= pd.to_datetime('2021-02-02', format='%Y-%m-%d')].\\\n            groupby([\"SubmissionId\", \"date\"])[\"UpdatedScore\"].std().reset_index().\\\n            groupby(\"date\")[\"UpdatedScore\"].mean().reset_index().rename(columns={\"UpdatedScore\": \"RPS: average standard deviation of agent scores\"}),\n    on = \"date\")\ndate_stat_agent.set_index(\"date\").plot(figsize=(25,10), cmap=\"Spectral\",\n               title=\"Average standard deviation of agent scores for Rock, Paper, Scissors (RPS) and Santa-2020 competitions\")\nplt.show()","6e9aba84":"date_stat = pd.merge(date_stat, date_stat_agent, on = \"date\")\nsns.set(style=\"whitegrid\")\nsns.lmplot(\"Santa: average standard deviation of agent scores\", \"Santa_rank_std\", data=date_stat, scatter_kws={\"alpha\": 0.5}, line_kws={\"color\": \"darkred\"}, height=10)\nplt.legend(title=\"Standard deviation of agent score vs team rankings for Santa-2020\", loc=\"lower center\", title_fontsize = 25)\nplt.show()\n\nsns.set(style=\"whitegrid\")\nsns.lmplot(\"RPS: average standard deviation of agent scores\", \"RPS_rank_std\", data=date_stat, scatter_kws={\"alpha\": 0.5}, line_kws={\"color\": \"orange\"}, height=10)\nplt.legend(title=\"Standard deviation of agent score vs team rankings for Rock, Paper, Scissors\", loc=\"lower center\", title_fontsize = 25)\nplt.show()\ndel date_stat_agent","241fa28c":"pd.merge(\n        santa_df[santa_df[\"CreateTime\"] >= pd.to_datetime('2021-02-02', format='%Y-%m-%d')].\\\n            groupby([\"SubmissionId\", \"date\"])[\"EpisodeId\"].count().reset_index().\\\n            groupby(\"date\")[\"EpisodeId\"].mean().reset_index().rename(columns={\"EpisodeId\": \"Santa-2020: games per submission\"}),\n        rps_df[rps_df[\"CreateTime\"] >= pd.to_datetime('2021-02-02', format='%Y-%m-%d')].\\\n            groupby([\"SubmissionId\", \"date\"])[\"EpisodeId\"].count().reset_index().\\\n            groupby(\"date\")[\"EpisodeId\"].mean().reset_index().rename(columns={\"EpisodeId\": \"RPS: games per submission\"}),\n    on = \"date\").set_index(\"date\").plot(figsize=(25,10), cmap=\"Spectral\",\n               title=\"Games per submission for Rock, Paper, Scissors (RPS) and Santa-2020 competitions\")\nplt.show()","cea9884a":"av_conf_stat = pd.merge(\n                        santa_df[santa_df[\"CreateTime\"] >= pd.to_datetime('2021-02-02', format='%Y-%m-%d')].\\\n                            groupby(\"date\")[\"UpdatedConfidence\"].mean().reset_index().rename(columns={\"UpdatedConfidence\": \"Santa-2020: average confidence\"}),\n                        rps_df[rps_df[\"CreateTime\"] >= pd.to_datetime('2021-02-02', format='%Y-%m-%d')].\\\n                            groupby(\"date\")[\"UpdatedConfidence\"].mean().reset_index().rename(columns={\"UpdatedConfidence\": \"RPS: average confidence\"}),\n                    on = \"date\")\nav_conf_stat.set_index(\"date\").plot(figsize=(25,10), cmap=\"Spectral\",\n             title=\"Average confidence (sigma) for Rock, Paper, Scissors (RPS) and Santa-2020 competitions\")\nplt.show()","134532bb":"date_stat = pd.merge(date_stat, av_conf_stat, on = \"date\")\nsns.set(style=\"whitegrid\")\nsns.lmplot(\"Santa-2020: average confidence\", \"Santa_rank_std\", \n           data=date_stat, scatter_kws={\"alpha\": 0.5}, line_kws={\"color\": \"darkred\"}, height=10)\nplt.legend(title=\"Average confidence (sigma) vs ranking standard deviation for Santa-2020\", loc=\"lower center\", title_fontsize = 25)\nsns.set(style=\"whitegrid\")\nsns.lmplot(\"RPS: average confidence\", \"RPS_rank_std\", \n           data=date_stat, scatter_kws={\"alpha\": 0.5}, line_kws={\"color\": \"orange\"}, height=10)\nplt.legend(title=\"Average confidence (sigma) vs ranking standard deviation for RPS\", loc=\"lower center\", title_fontsize = 25)\nplt.show()","ab3377e1":"av_conf_stat = pd.merge(\n                         rps_df.groupby(\"date\")[\"UpdatedConfidence\"].mean().reset_index().\\\n                            rename(columns={\"UpdatedConfidence\": \"RPS: average confidence\"}),                        \n                        santa_df.groupby(\"date\")[\"UpdatedConfidence\"].mean().reset_index().\\\n                            rename(columns={\"UpdatedConfidence\": \"Santa-2020: average confidence\"}),\n                    on = \"date\", how=\"left\")\nav_conf_stat.set_index(\"date\").plot(figsize=(25,10), cmap=\"Spectral\",\n             title=\"Average confidence (sigma) for Rock, Paper, Scissors (RPS) and Santa-2020 competitions (from competition start)\")\nplt.show()\ndel av_conf_stat","349244d4":"santa_df[\"submission_dt\"] = santa_df[\"submission_dt\"].dt.date\nsanta_conf_by_day = santa_df.groupby([\"submission_dt\", \"date\"])[\"UpdatedConfidence\"].mean().reset_index().rename(columns={\"UpdatedConfidence\": \"confidence\"})\nplt.figure(figsize=(25, 10))\nsns.lineplot(data=santa_conf_by_day, x=\"date\", y=\"confidence\", hue=\"submission_dt\", legend=False).\\\n    set_title(\"Submission confidence grouped by date of submission for Santa-2020\")\nplt.show()\ndel santa_conf_by_day","67f705c9":"rps_df[\"submission_dt\"] = rps_df[\"submission_dt\"].dt.date\nrps_conf_by_day = rps_df.groupby([\"submission_dt\", \"date\"])[\"UpdatedConfidence\"].mean().reset_index().rename(columns={\"UpdatedConfidence\": \"confidence\"})\nplt.figure(figsize=(25, 10))\nsns.lineplot(data=rps_conf_by_day, x=\"date\", y=\"confidence\", hue=\"submission_dt\", legend=False).\\\n    set_title(\"Submission confidence grouped by date of submission for RPS\")\nplt.show()\ndel rps_conf_by_day","21325988":"2 Feb 2021 submissions have been closed for both *Rock, Paper, Scissors (RPS)* and *Santa-2020* competitions. There is a 21-day evaluation period to reach stable rankings. This notebook aims to research how close are rankings to equilibrium (or something like it). It follows my previous EDA for [RPS](https:\/\/www.kaggle.com\/demche\/rock-paper-scissors-leaderboard-eda) and [Santa-2020](https:\/\/www.kaggle.com\/demche\/santa-2020-who-s-lucky-eda).","e079e0a5":"### 2.2 Rock, Paper, Scissors","626b470c":"# 5. Volatility drivers: confidence\n\nEnvironment rules says:\n> Each Submission has a rating which is modeled by a Gaussian N(\u03bc,\u03c32) where \u03bc is the estimated skill and \u03c3 represents our uncertainty of that estimate.\n\nConfidence (sigma, \u03c3) is calculated by the scoring system, based on how surprising were the game results.","333aa95d":"# 4. Volatility drivers: games per submission \n\nThere are two sources of agent score volatility: number of games per day and confidence parameter (sigma, or *uncertainty of the estimate*). During the competition new submissions had a privilege (a large number of games on the first day), which caused high volatility for them. In the evaluation period new submissions are frozen, so this is not the case.\n\n*NB: data for the last day is incomplete*","05c6bd82":"Instead of range, we can use standard deviation:","17c41b14":"The number of games per day is more or less stable, whereas confidence (sigma) is falling. It's quite clear, that confidence is the major driver of agent score volatility:","b8346c6a":"To sum up, as result of sigma adjustments the system is heading to equilibrium for both RPS and Santa-2020. ","622c2de6":"# 2. Current vs highest team rank\n\nHow did the team rank change during the evaluation period?","d16101ab":"<h2><center> Rock, Paper, Scissors and Santa-2020: ranking stability (EDA) <\/center><\/h2>","b3fc2106":"However, in this visualization effect of adjustments is almost non-existent for RPS competition. \n\nAs an alternative, we can look at confidence grouped by submission date ([@stassl](https:\/\/www.kaggle.com\/stassl) got the idea of such analytics). Each line in the plot represents average confidence for submissions made on a specific date. That is, every line starts from the date of submission and goes up to the last day (although it gets overlapped by newer lines).","b3e06c78":"### 2.1 Santa-2020","f0b1abd7":"<h2><center> <img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/1\/1c\/Csm_Brownian-Motion_f99de6516a.png\" alt=\"Equilibrium img\"><\/center><\/h2>","9a47cfc2":"# 3. Agent score volatility\n\nRanking volatility comes from the volatility of individual agents:","1c1ff40d":"# 1. Rankings volatility\n\nCore idea: let's build team ranking for each period from 2 February to now (with 15-minute interval). Then, calculate the range between minimum and maximum team rank within one day.","3b2f0e35":"Aside from the usual confidence downfall (which is built in the scoring system), there is an effect of adjustments. Precisely, the kaggle team [is decreasing minimum confidence](https:\/\/www.kaggle.com\/c\/santa-2020\/discussion\/215797#1181491):\n\n> We increase minimum confidence at the start of the closing period for each simulation competition and then decrease minimum confidence throughout the week to encourage movement among stale submissions during competition close -- especially submissions that suffered from a bad leaderboard path.\n\nIn several discussions reduction of sigma was compared to [dropping the temperature](https:\/\/www.kaggle.com\/c\/rock-paper-scissors\/discussion\/213461#1191532). This effect is more noticeable if look from the start of the competition:"}}