{"cell_type":{"214be886":"code","62f0252d":"code","98468311":"code","d73840af":"code","a99376f1":"code","6aa57a9c":"code","ff4acb8b":"code","a6b7a805":"code","3d191d4d":"code","82f9bcd3":"code","e319cc2a":"code","12dd6eed":"code","7678cdd1":"code","42022018":"code","47f2a98d":"code","af435dd1":"code","5bad9e52":"code","6a4f5917":"code","6a3f8926":"code","b1107f76":"code","d40de904":"code","19553993":"code","bff9e4a5":"code","078e8738":"code","0406d01f":"code","2c77fb29":"code","4395e977":"code","d9b0191d":"code","52c774a4":"code","eca1cf2a":"code","427fdf69":"code","6b3220a3":"code","14a458de":"code","f43d7189":"code","2e27b546":"code","9ee7719c":"markdown","2e37bb22":"markdown","e51cadc4":"markdown","1e987424":"markdown","13d08e54":"markdown","bd5090b9":"markdown","241aac37":"markdown","3edcf34e":"markdown","e7592beb":"markdown","e2140ca9":"markdown","ce55743e":"markdown","87f0004c":"markdown","54bc3e1d":"markdown"},"source":{"214be886":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","62f0252d":"dataset=pd.read_csv(\"..\/input\/water-potability\/water_potability.csv\")\ndataset.head()","98468311":"dataset.info()","d73840af":"sns.heatmap(dataset.isnull(),yticklabels=False,cbar=False,cmap='viridis')","a99376f1":"fig = plt.figure(figsize =(5, 3))\n# Creating plot\nplt.boxplot(dataset[\"ph\"].dropna())\n# show plot\nplt.show()","6aa57a9c":"sns.distplot(dataset[\"ph\"].dropna(),kde=False,color='darkred',bins=40)","ff4acb8b":"fig = plt.figure(figsize =(5, 3))\n# Creating plot\nplt.boxplot(dataset[\"Sulfate\"].dropna())\n# show plot\nplt.show()","a6b7a805":"sns.distplot(dataset[\"Sulfate\"].dropna(),kde=False,color='darkred',bins=40)","3d191d4d":"fig = plt.figure(figsize =(5, 3))\n# Creating plot\nplt.boxplot(dataset[\"Trihalomethanes\"].dropna())\n# show plot\nplt.show()","82f9bcd3":"sns.distplot(dataset[\"Trihalomethanes\"].dropna(),kde=False,color='darkred',bins=40)","e319cc2a":"dataset[\"ph\"] = dataset[\"ph\"].fillna((dataset[\"ph\"].mean()))\ndataset[\"Sulfate\"] = dataset[\"Sulfate\"].fillna((dataset[\"Sulfate\"].mean()))\ndataset[\"Trihalomethanes\"] = dataset[\"Trihalomethanes\"].fillna((dataset[\"Trihalomethanes\"].mean()))\n\nsns.heatmap(dataset.isnull(),yticklabels=False,cbar=False,cmap='viridis')","12dd6eed":"Q1 = dataset.quantile(0.25)\nQ3 = dataset.quantile(0.75)\nIQR = Q3 - Q1\ndataset = dataset[~((dataset < (Q1 - 1.5 * IQR)) |(dataset > (Q3 + 1.5 * IQR))).any(axis=1)]","7678cdd1":"x = dataset.iloc[:,0:9].values\ny=dataset.iloc[:,9:].values","42022018":"x","47f2a98d":"y","af435dd1":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)","5bad9e52":"x_train","6a4f5917":"from sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.fit_transform(x_test)","6a3f8926":"x_train","b1107f76":"from sklearn.linear_model import LogisticRegression\nlog=LogisticRegression()\nlog.fit(x_train,y_train)","d40de904":"log_pred=log.predict(x_test)","19553993":"log_pred","bff9e4a5":"from sklearn.metrics import accuracy_score\naccuracy=accuracy_score(y_test,log_pred)\nprint(\"Logistic Regression accuracy value: {:.2f}\".format(accuracy))","078e8738":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\ndt.fit(x_train,y_train)","0406d01f":"dt_predict=dt.predict(x_test)","2c77fb29":"dt_predict","4395e977":"accuracy2=accuracy_score(y_test,dt_predict)\nprint(\"Decision Tree Classifier accuracy value: {:.2f}\".format(accuracy2))","d9b0191d":"from sklearn.neighbors import KNeighborsClassifier\nkkn = KNeighborsClassifier(n_neighbors=19)\nkkn.fit(x_train,y_train)","52c774a4":"kkn_pred=kkn.predict(x_test)","eca1cf2a":"accuracy3=accuracy_score(y_test,kkn_pred)\nprint(\"KNN accuracy value: {:.2f}\".format(accuracy3))","427fdf69":"from sklearn.naive_bayes import GaussianNB\nnaive = GaussianNB()\nnaive.fit(x_train,y_train)","6b3220a3":"naive_pred=naive.predict(x_test)","14a458de":"accuracy4=accuracy_score(y_test,naive_pred)\nprint(\"Naive Bayes accuracy value: {:.2f}\".format(accuracy4))","f43d7189":"from sklearn.ensemble import RandomForestClassifier\nrf=RandomForestClassifier()\nrf.fit(x_train,y_train)\nrf_pred=rf.predict(x_test)","2e27b546":"accuracy5=accuracy_score(y_test,rf_pred)\nprint(\"Random Forest Classifier accuracy value: {:.2f}\".format(accuracy5))","9ee7719c":"___\n# Congratulations!\n\nHey, you made it!\nHow was it? Are you feeling energetic on getting your first or second notebook?\nI really hope this notebook will give you enough courage to learn more!\n\nHave a nice day, Kagglers!","2e37bb22":"### Don't forget to scale the x values","e51cadc4":"# Random Forest Classifier\n\nResulted in 0.67 accuracy","1e987424":"___\n## Filling the NaN values\n\nHere you can use both Mean or Median to fill the NaN values, both ended up resulting the same accuracy.","13d08e54":"# Water Quality - 67% Accuracy\n\nHello Kagglers!\nThis is my notebook from the dataset \"Water Quality\", you can use the same dataset as me from the link below:\nhttps:\/\/www.kaggle.com\/adityakadiwal\/water-potability\n\nThis notebook is really beginner-friendly because I'm also a beginner in this path, so don't worry if you dont understand, you can always ask me in the comment.\n\nHave fun exploring the dataset :D\n\nTask:\nPredict if water is safe for Human consumption.\n\n\n\n___\n#### Here I use 5 methods on gaining the best acuracy.\n\n##### Logistic Regression\nResulted in 0.63 accuracy\n##### Decision Tree Classifier\nResulted in 0.60125 accuracy\n##### KNN (K-Nearest Neighbor)\nResulted in 0.655 accuracy\n##### Naive Bayes\nResulted in 0.62 accuracy\n##### Random Forest Classifier\nResulted in 0.67 accuracy ( The Best )","bd5090b9":"# KNN (K-Nearest Neighbor)\n\nResulted in 0.655 accuracy","241aac37":"# Naive Bayes\n\nResulted in 0.62 accuracy","3edcf34e":"___\n## Finding Null Values\n\nAs it turns out there are many NaN values in ph, Sulfate, and Trihalomenthanes column ","e7592beb":"___\n## Deleting the outliers","e2140ca9":"___\n## Finding Outliers\n\nBefore I fill NaN values, I need to know the outliers of those 3 columns, so that I can decide whether to fill the NaN values with the mean's or the median's value of the column\n\nHere I'm using 2 types of figures:\n1. Boxplot (You can easily notice the outliers from the circles)\n2. Histogram","ce55743e":"___\n## Split the Data","87f0004c":"# Decision Tree Classifier\n\nResulted in 0.60125 accuracy\n","54bc3e1d":"# Logistic Regression\n\nResulted in 0.63 accuracy"}}