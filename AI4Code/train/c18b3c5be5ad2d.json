{"cell_type":{"5dab69c8":"code","0e510486":"code","056394e2":"code","45038c65":"code","53ca4e3e":"code","cf786731":"code","bf81fa04":"code","ec682cf8":"code","d51d458c":"code","32935d53":"code","d7aff3e9":"code","eee319c7":"code","b21e5173":"code","4ecd46e3":"code","42fab99b":"code","4de7fa8a":"code","e4d84252":"code","ccdf4a57":"code","a3608dcb":"markdown","e3b29b16":"markdown","2f8181a8":"markdown","80320276":"markdown","27e9a944":"markdown","b4446098":"markdown","2c189dbf":"markdown","12fe9fd8":"markdown","76c2b293":"markdown","ff3235d8":"markdown","455b69ae":"markdown","bd3dc1ce":"markdown"},"source":{"5dab69c8":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report,precision_score,recall_score\nfrom sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV,KFold\nfrom sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler,scale\nfrom sklearn.svm import SVC\n#sns.set_context(\"talk\", font_scale = 1, rc={\"grid.linewidth\": 3})\npd.set_option('display.max_rows', 100, 'display.max_columns', 100)","0e510486":"letters=pd.read_csv('..\/input\/letter-recognition-dataset\/letter-recognition.csv')\nletters.head()","056394e2":"print(letters.info())\nletters.describe()","45038c65":"# a quirky bug: the column names have a space, e.g. 'xbox ', which throws and error when indexed\nprint(letters.columns)\n","53ca4e3e":"# let's 'reindex' the column names\nletters.columns = ['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar',\n       'ybar', 'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge',\n       'xedgey', 'yedge', 'yedgex']\nprint(letters.columns)","cf786731":"order=list(np.sort(letters['letter'].unique()))\nprint(order)","bf81fa04":"# basic plots: How do various attributes vary with the letters\n# basic plots: How do various attributes vary with the letters\n\nplt.figure(figsize=(16, 8))\nsns.barplot(x='letter', y='xbox', \n            data=letters, \n            order=order)","ec682cf8":"letter_means=letters.groupby('letter').mean()\nletter_means.head()","d51d458c":"plt.figure(figsize=(18,10))\nsns.heatmap(letter_means,annot=True,cmap='viridis_r')","32935d53":"# average feature values\nround(letters.drop('letter', axis=1).mean(), 2)","d7aff3e9":"X=letters.drop('letter',axis=1)\ny=letters['letter']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\nscaler=StandardScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\n\n\n","eee319c7":"svc=SVC(kernel='linear')\nsvc.fit(X_train,y_train)\ny_test_pred = svc.predict(X_test)\nprint('accuracy:',accuracy_score(y_test,y_test_pred))\nprint(confusion_matrix(y_test,y_test_pred))\nprint(classification_report(y_test,y_test_pred))","b21e5173":"# creating a KFold object with 5 splits \nkfold=KFold(n_splits=5,shuffle=True,random_state=42)\n\n# specify range of hyperparameters\n# Set the parameters by cross-validation\nparam=[{'gamma':[0.01,0.001,0.0001],'C':[1,10,100,1000]}]\nsvc=SVC(kernel='rbf')\ngrid_cv=GridSearchCV(svc,param_grid=param,cv=kfold,verbose=1,return_train_score=True,scoring='accuracy')\ngrid_cv.fit(X_train,y_train)","4ecd46e3":"cv_results=pd.DataFrame(grid_cv.cv_results_)\ncv_results.head()","42fab99b":"# converting C to numeric type for plotting on x-axis\ncv_results['param_C'] = cv_results['param_C'].astype('int')\n\n# # plotting\nplt.figure(figsize=(16,6))\n\n# subplot 1\/3\nplt.subplot(131)\ngamma_01 = cv_results[cv_results['param_gamma']==0.01]\n\nplt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\nplt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.title(\"Gamma=0.01\")\nplt.ylim([0.60, 1])\nplt.legend(['test accuracy', 'train accuracy'], loc='upper left')\nplt.xscale('log')\n\n# subplot 2\/3\nplt.subplot(132)\ngamma_001 = cv_results[cv_results['param_gamma']==0.001]\n\nplt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\nplt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.title(\"Gamma=0.001\")\nplt.ylim([0.60, 1])\nplt.legend(['test accuracy', 'train accuracy'], loc='upper left')\nplt.xscale('log')\n\n\n# subplot 3\/3\nplt.subplot(133)\ngamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n\nplt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\nplt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\nplt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.title(\"Gamma=0.0001\")\nplt.ylim([0.60, 1])\nplt.legend(['test accuracy', 'train accuracy'], loc='upper left')\nplt.xscale('log')\n","4de7fa8a":"# printing the optimal accuracy score and hyperparameters\nbest_score=grid_cv.best_score_\nbest_param=grid_cv.best_params_\nprint(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_param))","e4d84252":"svc=SVC(C=1000,gamma=0.01,kernel='rbf')\nsvc.fit(X_train,y_train)\ny_test_pred=svc.predict(X_test)\nprint('accuracy:',accuracy_score(y_test,y_test_pred))","ccdf4a57":"cf= pd.DataFrame(confusion_matrix(y_test,y_test_pred))\ncf","a3608dcb":"The plots above show some useful insights:\n- Non-linear models (high gamma) perform *much better* than the linear ones\n- At any value of gamma, a high value of C leads to better performance\n- None of the models tend to overfit (even the complex ones), since the training and test accuracies closely follow each other\n\nThis suggests that the problem and the data is **inherently non-linear** in nature, and a complex model will outperform simple, linear models in this case.","e3b29b16":"<a id=\"2\"><\/a>\n## Data Preparation\n\nLet's conduct some data preparation steps before modeling. Firstly, let's see if it is important to **rescale** the features, since they may have varying ranges. For example, here are the average values:","2f8181a8":"In this case, the average values do not vary a lot (e.g. having a diff of an order of magnitude). Nevertheless, it is better to rescale them.","80320276":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:#ff6666' role=\"tab\" aria-controls=\"home\"><center>Thank You \ud83d\ude4f <\/center><\/h1>\n","27e9a944":"Let's now choose the best hyperparameters. ","b4446098":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:#ff6666' role=\"tab\" aria-controls=\"home\"><center>Table of Contents<\/center><\/h1>\n\n    \n    \n- [Data Understanding ](#1)\n- [Data Preparation](#2)\n- [Grid Search: Hyperparameter Tuning](#3)     \n- [Building and Evaluating the Final Model](#4)\n- [Conclusion](#5)\n","2c189dbf":"<a id=\"5\"><\/a>\n## Conclusion\n\nThe accuracy achieved using a non-linear kernel (~0.95) is mush higher than that of a linear one (0.85). We can conclude that the problem is highly non-linear in nature.","12fe9fd8":"# Letter Recognition Using SVM\n\nLet's now tackle a slightly more complex problem - letter recognition. We'll first explore the dataset a bit, prepare it (scale etc.) and then experiment with linear and non-linear SVMs with various hyperparameters.\n\n<a id=\"1\"><\/a>\n## Data Understanding \n\nLet's first understand the shape, attributes etc. of the dataset.","76c2b293":"<a id=\"3\"><\/a>\n## Grid Search: Hyperparameter Tuning\n\nLet's now tune the model to find the optimal values of C and gamma corresponding to an RBF kernel. We'll use 5-fold cross validation.","ff3235d8":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:#ff6666' role=\"tab\" aria-controls=\"home\"><center>If you found this notebook helpful , some upvotes would be very much appreciated - That will keep me motivated \ud83d\ude0a<\/center><\/h2>\n","455b69ae":"<a id=\"4\"><\/a>\n### Building and Evaluating the Final Model\n\nLet's now build and evaluate the final model, i.e. the model with highest test accuracy.","bd3dc1ce":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:black; border:0; color:#ff6666' role=\"tab\" aria-controls=\"home\"><center> Letter Recognition SVM<\/center><\/h1>"}}