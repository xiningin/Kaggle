{"cell_type":{"b7145a21":"code","522139dd":"code","6e670801":"code","9b1efb1c":"code","70f969b1":"code","ec58434d":"code","6bf88552":"code","2b494d2e":"code","cb2d70d2":"code","3743abcd":"code","429d095f":"code","bf62ec72":"code","5bfd2573":"code","d01abcda":"code","86e10495":"code","a9f76576":"code","bddc70b4":"code","4acad5ee":"code","bd66bd7c":"markdown","642a1588":"markdown","512c402c":"markdown"},"source":{"b7145a21":"import os\nimport h5py\nimport matplotlib.pyplot as plt\nfrom skimage.util.montage import montage2d\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical\nimport numpy as np\nimport gc\ngc.enable() # we come close to the memory limits and this seems to minimize kernel resets\nmontage3d = lambda x, **k: montage2d(np.stack([montage2d(y, **k) for y in x],0))\ndata_dir = '..\/input\/mri-heart-processing\/'","522139dd":"with h5py.File(os.path.join(data_dir, 'train_mri_128_128.h5'), 'r') as w:\n    full_data = w['image'].value\n    n_group = w['id'].value\n    n_scalar = w['area_multiplier'].value\n    y_target = w['systole'].value \/ n_scalar # remove the area scalar since we dont have this in the images","6e670801":"y_target.min(), y_target.max(), y_target.mean()","9b1efb1c":"offset_value = 0\nscale_factor = 1\nclip_min = -9999\nclip_max = 9999","70f969b1":"y_target_class = ((y_target-offset_value)\/scale_factor).clip(clip_min, clip_max).reshape((-1,1))\n_ = plt.hist(y_target_class)\ny_target_class.shape","ec58434d":"# instance normalization\nsafe_norm_func = lambda x: np.clip((x-x.mean())\/(0.1+x.std()), -2, 2)\nnorm_ch_x_data = np.apply_along_axis(safe_norm_func, 0, (full_data.swapaxes(1,3).swapaxes(1,2)))\ndel full_data\nnorm_ch_x_data.shape","6bf88552":"fig, ax1 = plt.subplots(1,1, figsize = (8,8))\nax1.imshow(montage3d(norm_ch_x_data[np.random.choice(norm_ch_x_data.shape[0], size = 4)].swapaxes(1,3)))","2b494d2e":"%matplotlib inline\nplt.hist(norm_ch_x_data[:4].ravel())","cb2d70d2":"from keras.models import Sequential\nfrom keras.layers import SpatialDropout2D, Dropout, Activation\nfrom keras.layers import Conv2D, BatchNormalization, Dense, Flatten, Reshape, GlobalAveragePooling2D, MaxPooling2D","3743abcd":"in_shape = norm_ch_x_data.shape[1:]","429d095f":"simple_model = Sequential()\nsimple_model.add(Conv2D(filters = 32, \n                        kernel_size = (1,1), \n                        input_shape = in_shape, \n                        activation = 'linear',\n                       use_bias = False))\nsimple_model.add(BatchNormalization())\nsimple_model.add(Activation('relu'))\nsimple_model.add(Conv2D(filters = 64, kernel_size = (3,3)))\nsimple_model.add(Conv2D(filters = 64, kernel_size = (3,3)))\nsimple_model.add(MaxPooling2D((2,2)))\nsimple_model.add(Conv2D(filters = 128, kernel_size = (3,3)))\nsimple_model.add(Conv2D(filters = 128, kernel_size = (3,3)))\nsimple_model.add(MaxPooling2D((2,2)))\nsimple_model.add(Conv2D(filters = 256, kernel_size = (3,3)))\nsimple_model.add(MaxPooling2D((2,2)))\nsimple_model.add(Conv2D(filters = 512, kernel_size = (3,3)))\nsimple_model.add(Conv2D(filters = 1024, kernel_size = (1,1)))\nsimple_model.add(GlobalAveragePooling2D())\nsimple_model.add(Dropout(0.25))\nsimple_model.add(Dense(512, activation = 'tanh'))\nsimple_model.add(Dropout(0.1))\nsimple_model.add(Dense(y_target_class.shape[1], activation = 'linear'))\nsimple_model.summary()","bf62ec72":"from keras.optimizers import Adam\nsimple_model.compile(loss = 'mae', \n                     optimizer = Adam(1e-4, decay = 1e-6), \n                     metrics = ['mae', 'mse'])\nloss_history = []","5bfd2573":"from sklearn.model_selection import train_test_split\n# a simpler one is better here since the same patients are spread over multiple slices and we want to minimize leak without making too much hassle\ndef train_test_split(x, y, train_size, random_state):\n    last_train_idx = int(train_size*x.shape[0])\n    return x[:last_train_idx], x[last_train_idx+1:], y[:last_train_idx], y[last_train_idx+1:]\nX_train, X_test, y_train, y_test = train_test_split(norm_ch_x_data, y_target_class, \n                                                   train_size = 0.7,\n                                                   random_state = 2017)\ndel norm_ch_x_data","d01abcda":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('systole_model')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n                                   patience=3, \n                                   verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=15) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","86e10495":"loss_history += [simple_model.fit(X_train, y_train, \n          validation_data=(X_test, y_test),\n                           shuffle = True,\n                           batch_size = 32,\n                           epochs = 30,\n                                 callbacks = callbacks_list)]","a9f76576":"simple_model.load_weights(weight_path)\nsimple_model.save('full_systolic_model.h5')","bddc70b4":"pred_test = simple_model.predict(X_test, verbose = 1)\nfig, (ax1) = plt.subplots(1,1, figsize = (8, 8))\nax1.scatter(y_test, pred_test)\nax1.plot(y_test, y_test, 'r-')","4acad5ee":"for v, f in zip(simple_model.evaluate(X_test, y_test, verbose = 1), \n                simple_model.metrics_names):\n    print('{}: difference - {:2.2f}ml'.format(f, scale_factor*v))","bd66bd7c":"# Build the Model\nHere we make a simple sequential model for processing the MRI frames and estimating the systolic volume","642a1588":"# Overview\nThis is a very simple (very bad) model for estimating the systolic volume directly from the images. As the dataset doesn't have any segmentations all we can do here is try and predict the volume based on a time series of images. As a very simple model, we avoid using 3D convolutions and instead have the time-step as the dimension number. Thus we can learn different combinations of the images (the first layer in the model). I originally heard the idea at a NVidia Developer Tutorial as the easiest way to get started with the dataset.\n\n## Note\nA much better model would use a 3D convolution or perhaps a recurrent CNN for incorporating the temporal information and that is definitely worth trying. Additionally the train\/test split here is very poor so please come up with a better validation strategy before experimenting too much","512c402c":"# Comparing Predictions to Real Values\nHere we compare the predictions to the real values on the test data. We ideally see a line indicating perfect correlation between the two datasets."}}