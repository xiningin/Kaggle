{"cell_type":{"eb8f13b9":"code","9e8be9e1":"code","ae8cab3c":"code","bd29bf67":"code","08355a04":"code","8bfea7f3":"code","3a20ef17":"code","2846b7b9":"code","d8525ace":"code","0ef65112":"code","cb5e27a3":"code","d9e8f781":"code","58ddd2c9":"code","08465248":"code","275b2255":"code","633489be":"code","426ad86c":"code","51039593":"markdown","6874abb9":"markdown","b2d756cd":"markdown","621c3ac2":"markdown","c995c95c":"markdown","16d3d796":"markdown","5b3615da":"markdown","d0e5f19d":"markdown"},"source":{"eb8f13b9":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nimport os\nfrom glob import glob\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.models import load_model\n\n#from itertools import chain","9e8be9e1":"# import data\nall_xray_df = pd.read_csv('\/kaggle\/input\/data\/Data_Entry_2017.csv')\n\n# obtain path to each image and add to dataframe\n# use glob module to intelligently parse all files\n# add to dictionary with key as filename\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..\/input\/data', 'images*', '*', '*.png'))}\n\nprint('Scans found:', len(all_image_paths), ', Total Rows', all_xray_df.shape[0])\n\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n\n\n\n# this is multi-task, multi-class classification\n# rename null finding\n# split the string description \nall_xray_df['Finding Labels']  = all_xray_df['Finding Labels'].replace('No Finding', '')\n#all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = list({x for l in all_xray_df['Finding Labels'].str.split('|') for x in l})\n\n# obtain list of unique diseases\nall_labels = [x for x in all_labels if len(x) > 0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\n\n#perform one-hot encoding based on diseases extracted\nfor c_label in all_labels:\n    if len(c_label)> 1: # leave out empty labels\n        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n\n# drop unused columns\nall_xray_df = all_xray_df.drop(['OriginalImagePixelSpacing[x', 'y]', 'Unnamed: 11', \n                               'Finding Labels',\n                               'Follow-up #',\n                               'OriginalImage[Width','Height]'\n                               ], axis=1)\n\nall_xray_df.sample(3)","ae8cab3c":"print('Number of unique patients:' , all_xray_df['Patient ID'].nunique())\n#all_xray_df.columns","bd29bf67":"#sns.distplot(all_xray_df['Patient Age'])\nidx = all_xray_df['Patient Age'].sort_values().index[-2]\nplt.imshow(plt.imread(all_xray_df.iloc[idx]['path']), cmap='bone')","08355a04":"sns.countplot(all_xray_df['Patient Gender'])\nsns.countplot(all_xray_df['View Position'])","8bfea7f3":"#sns.countplot()\nsns.barplot(x=all_labels, \n            y=all_xray_df[all_labels].sum(), \n            order = all_xray_df[all_labels].sum().sort_values(ascending=False).index)\n\nplt.tick_params(axis='x', rotation=90)","3a20ef17":"from sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.model_selection import train_test_split\n\nn = None # use all data\ngss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n\nfor train_idx, test_idx in gss.split(all_xray_df[: n], groups = all_xray_df[: n]['Patient ID'].values):\n    train_df = all_xray_df.iloc[train_idx]\n    test_df, valid_df = train_test_split(all_xray_df.iloc[test_idx], \n                                   test_size = 0.5, \n                                   random_state = 42) #should add stratified sampling\n    \ntrain_df.head()\ntest_df.head()","2846b7b9":"def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=32, seed=1, target_w = 320, target_h = 320):\n    \"\"\"\n    Return generator for training set, normalizing using batch\n    statistics.\n\n    Args:\n      train_df (dataframe): dataframe specifying training data.\n      image_dir (str): directory where image files are held.\n      x_col (str): name of column in df that holds filenames.\n      y_cols (list): list of strings that hold y labels for images.\n      sample_size (int): size of sample to use for normalization statistics.\n      batch_size (int): images per batch to be fed into model during training.\n      seed (int): random seed.\n      target_w (int): final width of input images.\n      target_h (int): final height of input images.\n    \n    Returns:\n        train_generator (DataFrameIterator): iterator over training set\n    \"\"\"        \n    print(\"getting train generator...\") \n    # normalize images\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True)\n    \n    # flow from directory with specified batch size\n    # and target image size\n    generator = image_generator.flow_from_dataframe(\n            dataframe=df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            target_size=(target_w,target_h))\n    \n    return generator\n\ndef get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=32, seed=1, target_w = 320, target_h = 320):\n    \"\"\"\n    Return generator for validation set and test test set using \n    normalization statistics from training set.\n\n    Args:\n      valid_df (dataframe): dataframe specifying validation data.\n      test_df (dataframe): dataframe specifying test data.\n      train_df (dataframe): dataframe specifying training data.\n      image_dir (str): directory where image files are held.\n      x_col (str): name of column in df that holds filenames.\n      y_cols (list): list of strings that hold y labels for images.\n      sample_size (int): size of sample to use for normalization statistics.\n      batch_size (int): images per batch to be fed into model during training.\n      seed (int): random seed.\n      target_w (int): final width of input images.\n      target_h (int): final height of input images.\n    \n    Returns:\n        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n    \"\"\"\n    print(\"getting train and valid generators...\")\n    # get generator to sample dataset\n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df, \n        directory=IMAGE_DIR, \n        x_col=x_col, \n        y_col=y_cols, \n        class_mode=\"raw\", \n        batch_size=sample_size, \n        shuffle=True, \n        target_size=(target_w, target_h))\n    \n    # get data sample\n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n\n    # use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization= True)\n    \n    # fit generator to sample from training data\n    image_generator.fit(data_sample)\n\n    # get test generator\n    valid_generator = image_generator.flow_from_dataframe(\n            dataframe=valid_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n\n    test_generator = image_generator.flow_from_dataframe(\n            dataframe=test_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    return valid_generator, test_generator","d8525ace":"IMAGE_DIR = None # our column contains the absolute paths\ntrain_generator = get_train_generator(train_df, IMAGE_DIR, \"path\", all_labels)\nvalid_generator, test_generator= get_test_and_valid_generator(valid_df, test_df, train_df, IMAGE_DIR, \"path\", all_labels)","0ef65112":"# show example\nx, y = train_generator.__getitem__(2)\nplt.imshow(x[0]);","cb5e27a3":"def compute_class_freqs(labels):\n    \"\"\"\n    Compute positive and negative frequences for each class.\n\n    Args:\n        labels (np.array): matrix of labels, size (num_examples, num_classes)\n    Returns:\n        positive_frequencies (np.array): array of positive frequences for each\n                                         class, size (num_classes)\n        negative_frequencies (np.array): array of negative frequences for each\n                                         class, size (num_classes)\n    \"\"\"\n    \n    # total number of patients (rows)\n    N = len(labels)\n    \n    positive_frequencies = (np.sum(labels, 0)) \/ N\n    negative_frequencies = (1- positive_frequencies)\n\n    return positive_frequencies, negative_frequencies\n\n\n\ndef get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n    \"\"\"\n    Return weighted loss function given negative weights and positive weights.\n\n    Args:\n      pos_weights (np.array): array of positive weights for each class, size (num_classes)\n      neg_weights (np.array): array of negative weights for each class, size (num_classes)\n    \n    Returns:\n      weighted_loss (function): weighted loss function\n    \"\"\"\n    def weighted_loss(y_true, y_pred):\n        \"\"\"\n        Return weighted loss value. \n\n        Args:\n            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)\n            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)\n        Returns:\n            loss (float): overall scalar loss summed across all classes\n        \"\"\"\n        # initialize loss to zero\n        loss = 0.0\n\n        for i in range(len(pos_weights)):\n            # for each class, add average weighted loss for that class \n            loss += -1 * K.mean(pos_weights * y_true * K.log(y_pred + epsilon) + \n                          (1 - y_true) * neg_weights * K.log(1 - y_pred + epsilon))\n            \n        return loss\n    \n    return weighted_loss\n\nfreq_pos, freq_neg = compute_class_freqs(train_generator.labels)\npos_weights = freq_neg\nneg_weights = freq_pos\npos_contribution = freq_pos * pos_weights \nneg_contribution = freq_neg * neg_weights\n\n","d9e8f781":"data = pd.DataFrame({\"Class\": all_labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\ndata = data.append([{\"Class\": all_labels[l], \"Label\": \"Negative\", \"Value\": v} \n                        for l,v in enumerate(neg_contribution)], ignore_index=True)\nplt.xticks(rotation=90)\nsns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data);","58ddd2c9":"# create the base pre-trained model\nbase_model = DenseNet121(\n    include_top=False,\n    weights=\"imagenet\",\n    input_tensor=None,\n    input_shape=None,\n)\n\nx = base_model.output\n\n# add a global spatial average pooling layer\nx = GlobalAveragePooling2D()(x)\n\n# and a logistic layer\npredictions = Dense(len(all_labels), activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights))\n\ncheckpoint_path = 'xray_class_weights.best.hdf5'\n#model.load_weights(checkpoint_path)\n#model.summary()","08465248":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n#weight_path=\".\/{}_weights.best.hdf5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=10)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.001)\n\ncallbacks_list = [checkpoint, early, reduce_lr]\n\n\nhistory = model.fit(train_generator, \n                    validation_data=valid_generator,\n                    steps_per_epoch=100, \n                    validation_steps=25, \n                    epochs = 40,\n                   callbacks = callbacks_list)","275b2255":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.title(\"Training Loss Curve\")\nplt.show()","633489be":"pred_Y = model.predict(test_generator, batch_size = 32, verbose = True)","426ad86c":"from sklearn.metrics import roc_curve, auc\n\ntest_Y = test_generator.labels\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\n\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')","51039593":"Evaluation metrics are a bit lower than the CheXNet paper published, can the model be trained in a better way?","6874abb9":"This link https:\/\/vijayabhaskar96.medium.com\/tutorial-on-keras-flow-from-dataframe-1fd4493d237c was useful for understanding the image generator.","b2d756cd":"# 2. Preparing data for training\n\nThe `GroupShuffleSplit` function separates the entries based on the Patient_ID to avoid data leakage.\n\nAfter splitting into training, test and validation sets, I then use some pre-written generator functions to use for the training. The way that it is implemented allows for standard normalisation. ","621c3ac2":"# CXR Deep Neural Network\n\nThis notebook uses the National Institutes of Health (NIH) Chest X-ray [dataset](https:\/\/www.kaggle.com\/nih-chest-xrays\/data), which is freely available on Kaggle. The dataset consists of 112,120 Chest X-rays with labelled data from 30805 individual patients. The aim here is to use Deep Learning to create a model that, given a chest X-ray, can diagnose what disease that patient is likely to have. There are 14 different diseases in the labelled dataset, with varying number of occurences. One X-ray image can be diagnosed with multiple diseases.\n\nThis model uses transfer learning using the ResNet34 architecture and the [weights trained on ImageNet](https:\/\/www.kaggle.com\/pytorch\/resnet34) as the base model, such that the model is fine tuned on the final X-rays. \n\nI started this project because I wanted to extend on the work I had done during the [deeplearning.ai course](https:\/\/www.deeplearning.ai\/program\/ai-for-medicine-specialization\/), specifically the assignment in week 1 of the course.\n\n### Limitations\nThe data was labelled using Natural Language Processing (NLP) methods and the source estimated that the accuracy should be >90%. Some errors are obvious such as with weird patient ages >200 years.\n\n### References\nA part of the code used for preprocessing was taken from Kevin Mader's own [notebook on the dataset](https:\/\/www.kaggle.com\/kmader\/train-simple-xray-cnn). I have made some modifications in the case that the code could be simplified or some functions have become deprecated. His code has shown the great utility of the .map() function and lambda functions. \n\nThe training part of the code was adapted from deeplearning.ai's Medical Diagnosis course, where techniques to combat \n* data leakage (in the case of multiple screenings by patients), \n* class imbalance, to give greater weight to diseases with low frequencies\n\nwere introduced. ","c995c95c":"# 3. Training\nThis section deals with Transfer Learning with pretrained weights.","16d3d796":"The data available of different diseases varies a lot.","5b3615da":"---\n# 1. Preprocessing Data\n\nThis section reads in the data and creates a dataframe of the paths and the labels to the images. Furthermore, the labels are split and one-hot encoded.","d0e5f19d":"We use the weighted loss function to account for class imbalance."}}