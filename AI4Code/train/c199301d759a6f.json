{"cell_type":{"66b19690":"code","ecd1b5b1":"code","45fe897a":"code","93219e62":"code","b4b050a7":"code","0f5f8e8a":"code","aa9704b7":"code","f8b07f2c":"code","0f5fc719":"code","e5830754":"code","cb6887c0":"code","6c29699a":"code","2ba93421":"code","d1886f71":"code","9620bd08":"markdown","5a2786a0":"markdown"},"source":{"66b19690":"import numpy as np  # linear algebra\nimport pandas as pd  # data and file processing\nimport sklearn as sk  # machine learning\nimport seaborn as sns  # data visualization\nimport matplotlib.pyplot as plt  # data visualization\nimport matplotlib\n%matplotlib inline","ecd1b5b1":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.models import load_model","45fe897a":"import os, ast, cv2, random\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom skimage import exposure","93219e62":"home = \"..\/input\/siim-covid19-detection\/\"\nimg_dir = home+'train\/'\nos.listdir(home)","b4b050a7":"## -- Read csv file containing training data\ndf_train_study = pd.read_csv(home+\"train_study_level.csv\")\n\n# Print first 5 rows\nprint(f'There are {df_train_study.shape[0]} rows and {df_train_study.shape[1]} columns in this data frame')\ndf_train_study.head()","0f5f8e8a":"df_train_study.info()","aa9704b7":"## -- Read csv file containing training data\ndf_train_image = pd.read_csv(home+\"train_image_level.csv\")\n\n# Print first 5 rows\nprint(f'There are {df_train_image.shape[0]} rows and {df_train_image.shape[1]} columns in this data frame')\ndf_train_image.head()","f8b07f2c":"df_train_image.info()","0f5fc719":"## -- Helper function borrowed from @raddar  \n## https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    dicom.BitsStored = 16  # added\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","e5830754":"img = read_xray(img_dir+'00086460a852\/9e8302230c91\/65761e66de9f.dcm')\nplt.figure(figsize = (12,12))\nplt.imshow(img, 'gray')","cb6887c0":"## for uniform pixel distribution\nimg = read_xray(img_dir+'00086460a852\/9e8302230c91\/65761e66de9f.dcm')\nimg = exposure.equalize_hist(img)\nplt.figure(figsize = (12,12))\nplt.imshow(img, 'gray')","6c29699a":"## for CLAHE normalization\nimg = read_xray(img_dir+'00086460a852\/9e8302230c91\/65761e66de9f.dcm')\nimg = exposure.equalize_adapthist(img\/np.max(img))\nplt.figure(figsize = (12,12))\nplt.imshow(img, 'gray')","2ba93421":"## merge study csv -- borrowed from yujiariyasu\ndf_train_study['StudyInstanceUID'] = df_train_study['id'].apply(lambda x: x.replace('_study', ''))\ndel df_train_study['id']\ntrain = df_train_image.merge(df_train_study, on='StudyInstanceUID')\ntrain.head()","d1886f71":"## -- check for class imbalance\n\nclasses = ['Negative for Pneumonia', 'Typical Appearance', \n                 'Indeterminate Appearance', 'Atypical Appearance']\nplt.figure(figsize = (12,6))\nplt.bar([1,2,3,4], train[classes].values.sum(axis=0))\nplt.xticks([1,2,3,4],classes)\nplt.ylabel('Count')\nplt.show()","9620bd08":"## Let's have a quick look...","5a2786a0":"## Merge the training sets"}}