{"cell_type":{"c23e5852":"code","219f111d":"code","51a18a0d":"code","a96fe370":"code","f36a8e05":"code","44d0fc46":"code","98c36913":"code","46d585ef":"code","7e0ee86f":"code","aaccfe7e":"code","806fd014":"code","e073bc37":"code","6db245f2":"code","dcfa1378":"code","6f9b451d":"code","582b2ba7":"markdown"},"source":{"c23e5852":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\nspam_df = pd.read_csv('..\/input\/SPAM text message 20170820 - Data.csv')\n# Any results you write to the current directory are saved as output.\nspam_df.head()","219f111d":"from wordcloud import WordCloud","51a18a0d":"spam_list = spam_df[spam_df[\"Category\"] == \"spam\"][\"Message\"].unique().tolist()\nspam_list[:2]","a96fe370":"spam = \" \".join(spam_list)\nspam[:100]\nspam_wordcloud = WordCloud().generate(spam)","f36a8e05":"import matplotlib.pyplot as plt\nplt.figure(figsize=(12,8))\nplt.imshow(spam_wordcloud)\nplt.show()","44d0fc46":"# import the vectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# create an instance\ncount_vect = CountVectorizer()","98c36913":"# fit the vectorizer with data\ncount_vect.fit(spam_df)\n# convert text to vectors\nX = count_vect.transform(spam_df.Message)\n","46d585ef":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ny = le.fit_transform(spam_df.Category)","7e0ee86f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n\n","aaccfe7e":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(criterion='gini')","806fd014":"# fit the model\nclf.fit(X_train, y_train)","e073bc37":"predictions = clf.predict(X_test)\npredictions.shape","6db245f2":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, predictions)\naccuracy","dcfa1378":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=5)","6f9b451d":"clf.fit(X_train, y_train)","582b2ba7":"### Tokenizing text\n\n#### Text preprocessing, tokenizing and filtering of stopwords are included in a high level component that converts text data to feature vectors"}}