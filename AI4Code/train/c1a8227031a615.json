{"cell_type":{"594d3625":"code","8766f084":"code","5e66b4de":"code","e82bde3f":"code","0bb27818":"code","9039bc31":"code","73a8e36d":"code","d466cd87":"code","07fd123f":"code","4feeadf5":"code","007d969a":"code","f0d5185f":"code","ff83db64":"code","8dea2a54":"code","3113b956":"code","e401bf46":"code","296654d1":"code","ca5d236f":"code","fa465842":"code","6f2b4396":"code","435f6cb3":"code","695e5f79":"code","55f9c779":"code","e8d9aacf":"code","4b29261b":"code","5e2055f8":"code","19ae9212":"code","bb1d15a8":"code","b5f936d1":"code","401efc34":"code","ba2d5954":"code","6d5e4d52":"code","b0eaacb8":"code","af44a587":"code","8bc190d1":"code","ffbbc8e1":"code","9b860a8e":"code","11db7472":"code","1a1f0ea3":"code","7bab6002":"code","462fe29c":"code","b6220ba3":"code","05523934":"code","183f9a5f":"code","e0dbad20":"code","cad9a903":"code","cb0210f2":"code","055ce7ba":"code","cc9a62ab":"code","c0c8d3bd":"markdown","c5aa58e6":"markdown","1dd766c8":"markdown","94fb845b":"markdown","bff2b842":"markdown","d6c889ed":"markdown","937938b4":"markdown","b08c08e9":"markdown","a06cc91e":"markdown","34ea9f06":"markdown","021c5286":"markdown","7ad0dbc1":"markdown","8ac7605c":"markdown","f7c81b97":"markdown","c7df8893":"markdown","f8ea38ba":"markdown","1c220198":"markdown","e97524b4":"markdown","2f7f36c6":"markdown","3575fade":"markdown"},"source":{"594d3625":"!pip install twint\n!pip install Textblob --upgrade\n!pip3 install --user --upgrade -e git+https:\/\/github.com\/twintproject\/twint.git@origin\/master#egg=\n!pip install pickle5","8766f084":"import twint\nimport pandas as pd\nimport nest_asyncio             \nimport matplotlib.pyplot as plt\n\nimport pickle5 as pickle\n\nimport numpy as np\nimport datetime as dt\nimport seaborn as sns\n\n#cleaning\nimport re\nfrom nltk.tokenize import WordPunctTokenizer\nfrom nltk.corpus import stopwords             \n\n# Sentiment Analysis\nfrom textblob import TextBlob\n\n#word cloud\nfrom wordcloud import WordCloud","5e66b4de":"#for compatibility issues with twint\nnest_asyncio.apply()  ","e82bde3f":"bank_search = {\"FNB\":\"FNBSA\", \"StandardBank\":\"StandardBankZA OR \\\"Standard Bank\\\" OR \\\"standard bank\\\"\",\"Nedbank\":\"Nedbank OR nedbank\",\"ABSA\": \"Absa OR ABSA OR absa OR AbsaSouthAfrica\",\"Capitec\":\"CapitecBankSA OR Capitec or capitec\"}","0bb27818":"def twintConfig(date_from,date_to, search_string):\n    c = twint.Config()\n    \n\n    c.Limit = 100\n    #tlist = c.search_tweet_list\n\n    c = twint.Config()\n    c.Store_object = True\n    c.Search = search_string[1]\n    c.Since = date_from\n    c.Until = date_to\n    c.Pandas = True\n    c. Pandas_au = True          \n    c.Pandas_clean=True\n    #c.Hide_output = True\n    #c.Resume = \".\/ResumeID\/resume_id_\"+search_string[0]+\".txt\"\n    twint.run.Search(c)","9039bc31":"## since = input(\"Input a start date eg 2021-01-01: \")\n#until = input(\"Input an end date eg 2021-09-18: \")\n\n\nsince = \"2021-10-01\"\nuntil = \"2021-10-03\"","73a8e36d":"def Run_Twint(search_vals):\n    \n    #set empty dataframe for join\n    out_df= pd.DataFrame()\n    \n    for bank in search_vals.items():\n        print (\"running for search item: \"+bank[0]+\"\\n\")\n        print (\"Search string: \"+bank[1]+\"\\n\")\n        \n        #run twint\n        twintConfig(since,until, bank)\n        \n        #get dataframe\n        tweets_df = twint.storage.panda.Tweets_df\n        \n        #join Dataframes and create 'Bank' column\n        tweets_df[\"Bank\"]= bank[0]\n        out_df = pd.concat([out_df,tweets_df])\n        \n    return out_df","d466cd87":"#tweets_df = Run_Twint(bank_search)","07fd123f":"#Import\/export file\n#tweets_df.to_pickle(\"pre_cleaning.csv\")\ntweets_df = pickle.load(open(\"..\/input\/tweets-of-4-banks-in-south-africa-poc\/pre_cleaning.pickle\", \"rb\"))","4feeadf5":"tweets_df.shape","007d969a":"tweets_df.head(2)","f0d5185f":"tweets_df.drop(columns= \"Unnamed: 0\" , axis = 1, inplace = True)","ff83db64":"tweets_df[\"language\"].unique()","8dea2a54":"# remove all rows where language is not english or undefined\ntweets_df = tweets_df[tweets_df[\"language\"].isin([ 'und', 'en'])]","3113b956":"# remove rows where username is in bank_search\ntweets_df = tweets_df[ ~tweets_df[\"username\"].str.lower().str.contains('fnb|standardbank|nedbank|absa|capitec',regex = True)]","e401bf46":"#Drop duplicated tweets \ntweets_df = tweets_df.drop_duplicates(subset=['date',\"tweet\",\"Bank\"],keep=\"first\")","296654d1":"len(tweets_df)","ca5d236f":"def clean_text(text):  \n    pat1 = r'@[^ ]+'                   #@signs\n    pat2 = r'https?:\/\/[A-Za-z0-9.\/]+'  #links\n    pat3 = r'\\'s'                      #floating s's\n    pat4 = r'\\#\\w+'                     # hashtags\n    pat5 = r'&amp '\n    pat6 = r'[^A-Za-z\\s]'         #remove non-alphabet\n    combined_pat = r'|'.join((pat1, pat2,pat3,pat4,pat5, pat6))\n    text = re.sub(combined_pat,\"\",text).lower()\n    return text.strip()","fa465842":"%%time\ntweets_df[\"cleaned_tweet\"] = tweets_df[\"tweet\"].apply(clean_text)","6f2b4396":"#drop empty rows\ntweets_df = tweets_df [ ~(tweets_df[\"tweet\"] ==\"\")]","435f6cb3":"tweets_df[\"cleaned_tweet\"].head()","695e5f79":"# reset the index \ntweets_df.reset_index(drop= True,inplace=True)","55f9c779":"%%time\nprint(\"Running sentiment process\")\nfor row in tweets_df.itertuples():\n    tweet = tweets_df.at[row[0], 'cleaned_tweet']\n\n    #run sentiment using TextBlob\n    analysis = TextBlob(tweet)\n\n    #set value to dataframe\n    tweets_df.at[row[0], 'polarity'] = analysis.sentiment[0]\n    tweets_df.at[row[0], 'subjectivity'] = analysis.sentiment[1]\n\n    #Create Positive \/ negative column depending on polarity\n    if analysis.sentiment[0]>0:\n        tweets_df.at[row[0], 'Sentiment'] = \"Positive\"\n    elif analysis.sentiment[0]<0:\n        tweets_df.at[row[0], 'Sentiment'] = \"Negative\"\n    else:\n        tweets_df.at[row[0], 'Sentiment'] = \"Neutral\"","e8d9aacf":"tweets_df[[\"cleaned_tweet\",\"polarity\",\"Sentiment\"]].head(5)","4b29261b":"tweets_df.reset_index(drop = True,inplace=True)","5e2055f8":"# Import \/ Export\n#tweets_df = pickle.load(open(\"..\/input\/tweets-of-4-banks-in-south-africa-poc\/Final.pickle\", \"rb\"))\n#tweets_df.to_pickle(\".\/Final_2021.pickle\")","19ae9212":"#install additional libraries for visualisation \nimport ast #optional\nfrom collections import Counter\n\nimport cufflinks as cf\nfrom plotly.offline import init_notebook_mode #, plot, iplot, download_plotlyjs\ninit_notebook_mode(connected = True)\ncf.go_offline()\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","bb1d15a8":"# Set Pallette \nsns.set_theme()\npal = {\"FNB\":'c', \"StandardBank\":\"b\",\"ABSA\":\"r\",\"Nedbank\":\"g\"}","b5f936d1":"display(tweets_df[[\"cleaned_tweet\",\"Bank\"]].groupby([\"Bank\"]).count().transpose())\n\nplt.figure(figsize=(10,5))\nsns.histplot(tweets_df, x=\"Sentiment\", hue=\"Bank\", palette= pal, multiple=\"stack\", alpha = 1)\nplt.title(\"Count of tweets by sentiment\",fontsize =15)\n\nplt.tight_layout()\nplt.show()","401efc34":"fig1 = sns.displot(tweets_df, x=\"Sentiment\", col=\"Bank\",col_wrap= 2, hue=\"Bank\", legend=False, palette= pal)\nfig1.fig.suptitle(\"Count of tweets by Sentiment\",fontsize =15)\n\nplt.tight_layout()\nplt.show()","ba2d5954":"fig1 = sns.displot(data = tweets_df[~(tweets_df['polarity']==0)], x=\"polarity\",\n                   col=\"Bank\",\n                   col_wrap= 2, \n                   hue=\"Bank\", \n                   legend=False, \n                   palette= pal,\n                   kde = True,\n                   bins =30)\nfig1.fig.suptitle(\"Distribution of Sentiment scores(polarity)\",fontsize =15 )\n\nplt.tight_layout()\nplt.show()","6d5e4d52":"tweets_df[\"date\"] = pd.to_datetime(tweets_df[\"date\"])\n\n#set index = date so as to create rolling mean \ntweets_df = tweets_df.sort_values(\"date\").set_index(\"date\")","b0eaacb8":"#Create bank Dataframes \nStandard_df = tweets_df[(tweets_df.Bank==\"StandardBank\")]\nFNB_df = tweets_df[(tweets_df.Bank==\"FNB\")]\nNedbank_df = tweets_df[(tweets_df.Bank==\"Nedbank\")]\nABSA_df = tweets_df[(tweets_df.Bank==\"ABSA\")]","af44a587":"#get all hashtags as list\ndef hashlist(df):\n    hashlist = []\n    for i in df['hashtags']:\n        #use ast.literal if you are importing CSV files otherwise just use 'i'\n        hashlist.extend(ast.literal_eval(i))\n    return hashlist","8bc190d1":"#Create hashtag dataframes\nhash_Absa= pd.DataFrame(Counter(hashlist(ABSA_df)).items()).sort_values(1,ascending=False)\nhash_NedBank= pd.DataFrame(Counter(hashlist(Nedbank_df)).items()).sort_values(1,ascending=False)\nhash_StdBank= pd.DataFrame(Counter(hashlist(Standard_df)).items()).sort_values(1,ascending=False)\nhash_FNB= pd.DataFrame(Counter(hashlist(FNB_df)).items()).sort_values(1,ascending=False)","ffbbc8e1":"fig, ax = plt.subplots(2, 2,figsize=(15, 10))\n\nplt.suptitle(\"Top 5 hashtags per bank\")\n\n# ABSA\nax[0,0].bar(hash_Absa[0].head(), hash_Absa[1].head(), color = \"r\")\nax[0,0].set_title(\"ABSA\")\nax[0,0].xaxis.set_tick_params(rotation=45, size = 15)\n\nax[0,1].bar(hash_NedBank[0].head(), hash_NedBank[1].head(), color = \"g\")\nax[0,1].set_title(\"Nedbank\")\nax[0,1].xaxis.set_tick_params(rotation=45, size = 15)\n\nax[1,0].bar(hash_StdBank[0].head(), hash_StdBank[1].head(), color = \"b\")\nax[1,0].set_title(\"Standard Bank\")\nax[1,0].xaxis.set_tick_params(rotation=45, size = 15)\n\nax[1,1].bar(hash_FNB[0].head(), hash_FNB[1].head(), color = \"c\")\nax[1,1].set_title(\"FNB\")\nax[1,1].xaxis.set_tick_params(rotation=45, size = 15)\n\nplt.tight_layout()\nplt.show()","9b860a8e":"tweetString_a = \" \".join(list(ABSA_df[\"cleaned_tweet\"])).lower()\ntweetString_n = \" \".join(list(Nedbank_df[\"cleaned_tweet\"])).lower()\ntweetString_s = \" \".join(list(Standard_df[\"cleaned_tweet\"])).lower()\ntweetString_f = \" \".join(list(FNB_df[\"cleaned_tweet\"])).lower()","11db7472":"#remove Bank name and set wordcloud\n\ntweetString_a = re.sub(r\"absa|bank|amp\",\"\",tweetString_a)\nwordcloud_a = WordCloud(\n                background_color ='white', \n                min_font_size = 5).generate(tweetString_a)\n\ntweetString_n = re.sub(r\"NedBankSA|Nedbank|nedbank|bank|amp\",\"\",tweetString_n)   \nwordcloud_n = WordCloud( \n                background_color ='white', \n                min_font_size = 5).generate(tweetString_n)\n\ntweetString_s = re.sub(r\"standardbankza|standard bank|bank|amp\",\"\",tweetString_s)     \nwordcloud_s = WordCloud( \n                background_color ='white', \n                min_font_size = 5).generate(tweetString_s)\n\ntweetString_f = re.sub(r\"FNB|fnb|bank|amp\",\"\",tweetString_f)\nwordcloud_f = WordCloud( \n                background_color ='white', \n                min_font_size = 5).generate(tweetString_f)","1a1f0ea3":"fig, ax = plt.subplots(2,2,figsize=(14, 8),sharey=True)\n\nax[0,0].imshow(wordcloud_s)\nax[0,1].imshow(wordcloud_f)\nax[1,0].imshow(wordcloud_n)\nax[1,1].imshow(wordcloud_a)\n\nax[0,0].axis(\"off\")\nax[0,1].axis(\"off\")\nax[1,0].axis(\"off\")\nax[1,1].axis(\"off\")\n\nax[0,0].set_title(\"StandardBank\")\nax[0,1].set_title(\"FNB\")\nax[1,0].set_title(\"Nedbank\")\nax[1,1].set_title(\"ABSA\")\n\nplt.tight_layout() \nplt.show()","7bab6002":"# Overall mean sentiment by bank\nplt.figure(figsize=(10,5))\nplt.title(\"Overall mean Sentiment by Bank\")\nsns.barplot(data = tweets_df, x= \"Bank\", y = \"polarity\", palette=pal, ci=False)\nplt.show()","462fe29c":"# stop this warning as the chaining is fine\npd.options.mode.chained_assignment = None ","b6220ba3":"#Std Bank\nStandard_df['mean'] = Standard_df['polarity'].expanding().mean()\nStandard_df['rolling'] = Standard_df['polarity'].rolling(\"7d\").mean()\n\n#FNB\nFNB_df['mean'] = FNB_df['polarity'].expanding().mean()\nFNB_df['rolling'] = FNB_df['polarity'].rolling(\"7d\").mean()\n\n#Nebank\nNedbank_df['mean'] = Nedbank_df['polarity'].expanding().mean()\nNedbank_df['rolling'] = Nedbank_df['polarity'].rolling(\"7d\").mean()\n\n#ABSA\nABSA_df['mean'] = ABSA_df['polarity'].expanding().mean()\nABSA_df['rolling'] = ABSA_df['polarity'].rolling(\"7d\").mean()","05523934":"# functions to create our graphs\ndef trace_rolling_creation(df,gname, glinecolor):\n    return fig.add_trace(\n        go.Scatter(\n            x= df.index, \n            y=df[\"rolling\"], \n            name=gname,  \n            mode='lines',\n            line_color=glinecolor),\n        secondary_y=False\n)\n\ndef trace_count_creation(df,gname, glinecolor):\n    return fig.add_trace(\n        go.Scatter(\n            x= df.index, \n            y=df[\"polarity\"].rolling('7d').count(), \n            name=gname,  \n            fill='tozeroy',line_color=glinecolor), \n        secondary_y=True\n)","183f9a5f":"plt.figure (figsize = (30,7))\nfig = go.Figure()\nfig.add_scatter(x=FNB_df.index, y=FNB_df[\"rolling\"], name=\"FNB\", mode='lines',line_color=\"#19D3F3\")\nfig.add_scatter(x=Standard_df.index, y=Standard_df[\"rolling\"], name=\"Standard Bank\", mode='lines',line_color=\"blue\")\nfig.add_scatter(x=ABSA_df.index, y=ABSA_df[\"rolling\"], name=\"ABSA\", mode='lines',line_color=\"red\")\nfig.add_scatter(x=Nedbank_df.index, y=Nedbank_df[\"rolling\"], name=\"Nedbank\", mode='lines',line_color=\"green\")\nfig.update_layout(\n    template = \"seaborn\",\n    title=\"Rolling 7 day Sentiment (polarity)\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"7 day rolling polarity\",\n    yaxis_range = [-0.1,0.4],\n    legend_title=\"Banks\",\n    font=dict(size=12),\n    autosize=False,\n    width=1000,\n    height=600,\n    margin=dict(l=10,r=10, b=50,t=50, pad=4)\n)","e0dbad20":"# Create figure with secondary y-axis\n\nfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n# Add traces\ntrace_rolling_creation(ABSA_df, \"ABSA\", '#DC0E1A')\ntrace_rolling_creation(Nedbank_df, \"Nedbank\", '#078a4d')\ntrace_rolling_creation(Standard_df, \"StdBank\", '#054db3')\ntrace_rolling_creation(FNB_df, \"FNB\", '#19D3F3')\n\ntrace_count_creation(ABSA_df, \"ABSA\", 'rgb(220, 14, 26)')\ntrace_count_creation(Nedbank_df, \"NedBank\", 'rgb(7, 138, 77)')\ntrace_count_creation(Standard_df, \"Std Bank\", 'rgb(5, 77, 179)')\ntrace_count_creation(FNB_df, \"FNB\", 'rgb(25, 211, 243)')\n# set figure layout\nfig.update_layout(\n    template = \"seaborn\",\n    title_text=\"Rolling 7d Sentiment vs Count of tweets\",\n    legend_title=\"Banks\",\n    font=dict(size=12),\n    autosize=False,\n    width=1000,\n    height=600,\n    margin=dict (l=10,r=10,b=50,t=50, pad=2)\n)\n\n# Set x-axis title\nfig.update_xaxes(title_text=\"Date\")\n\n# Set y-axes titles\nfig.update_yaxes(title_text=\"Rolling\",range = [-0.1,0.4], secondary_y=False)\nfig.update_yaxes(title_text=\"Count\",range = [0,40000], secondary_y=True)\n\nfig.show()","cad9a903":"#Create day and month\nABSA_df[\"Day\"]= ABSA_df.index.day_name()\nABSA_df[\"Month\"] = ABSA_df.index.month_name()\nABSA_df[\"Hour\"] = ABSA_df.index.hour\nNedbank_df[\"Day\"]= Nedbank_df.index.day_name()\nNedbank_df[\"Month\"] = Nedbank_df.index.month_name()\nNedbank_df[\"Hour\"] = Nedbank_df.index.hour\nStandard_df[\"Day\"]= Standard_df.index.day_name()\nStandard_df[\"Month\"] = Standard_df.index.month_name()\nStandard_df[\"Hour\"] = Standard_df.index.hour\nFNB_df[\"Day\"]= FNB_df.index.day_name()\nFNB_df[\"Month\"] = FNB_df.index.month_name()\nFNB_df[\"Hour\"] = FNB_df.index.hour","cb0210f2":"#### Sort Day and month columns\nfrom pandas.api.types import CategoricalDtype\ndays = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nday_type = CategoricalDtype(categories=days, ordered=True)\n\nABSA_df['Day'] = ABSA_df['Day'].astype(day_type)\nNedbank_df['Day'] = Nedbank_df['Day'].astype(day_type)\nStandard_df['Day'] = Standard_df['Day'].astype(day_type)\nFNB_df['Day'] = FNB_df['Day'].astype(day_type)\n\nmonths = [ 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\nmonth_type = CategoricalDtype(categories=months, ordered=True)\nABSA_df['Month'] = ABSA_df['Month'].astype(month_type)\nNedbank_df['Month'] = Nedbank_df['Month'].astype(month_type)\nStandard_df['Month'] = Standard_df['Month'].astype(month_type)\nFNB_df['Month'] = FNB_df['Month'].astype(month_type)","055ce7ba":"plt.figure(figsize = (15,5))\nsns.lineplot(data = FNB_df.groupby(\"Month\")[\"polarity\"].mean(), color = \"c\", label = \"FNB\")\nsns.lineplot(data = Nedbank_df.groupby(\"Month\")[\"polarity\"].mean(), color = \"g\", label = \"Nedbank\")\nsns.lineplot(data = ABSA_df.groupby(\"Month\")[\"polarity\"].mean(), color = \"r\", label = \"ABSA\")\nsns.lineplot(data = Standard_df.groupby(\"Month\")[\"polarity\"].mean(), color = \"b\", label = \"StdBank\")\nplt.title(\"Sentiment by month\")\nplt.show()","cc9a62ab":"plt.figure(figsize = (20,5))\n\nplt.subplot(1,2,1)\nplt.title(\"Sentiment by day\")\nsns.lineplot(data = FNB_df.groupby(\"Day\")[\"polarity\"].mean(), color = \"c\", label = \"FNB\", sort=False)\nsns.lineplot(data = Nedbank_df.groupby(\"Day\")[\"polarity\"].mean(), color = \"g\", label = \"Nedbank\", sort=False)\nsns.lineplot(data = ABSA_df.groupby(\"Day\")[\"polarity\"].mean(), color = \"r\", label = \"ABSA\", sort=False)\nsns.lineplot(data = Standard_df.groupby(\"Day\")[\"polarity\"].mean(), color = \"b\", label = \"StdBank\", sort=False)\n\nplt.subplot(1,2,2)\nplt.title(\"Sentiment by hour\")\nsns.lineplot(data = FNB_df.groupby(\"Hour\")[\"polarity\"].mean(), color = \"c\", label = \"FNB\")\nsns.lineplot(data = Nedbank_df.groupby(\"Hour\")[\"polarity\"].mean(), color = \"g\", label = \"Nedbank\")\nsns.lineplot(data = ABSA_df.groupby(\"Hour\")[\"polarity\"].mean(), color = \"r\", label = \"ABSA\")\nsns.lineplot(data = Standard_df.groupby(\"Hour\")[\"polarity\"].mean(), color = \"b\", label = \"StdBank\")\n\nplt.show()","c0c8d3bd":"## Sentiment analysis (TextBlob)","c5aa58e6":"# Hashtag analysis ","1dd766c8":"## Analysis and visualisation","94fb845b":"### Day \/ Month sentiment comparison ","bff2b842":"#### Set index as date for rolling plots ","d6c889ed":"### Run twint\n\nDue to issues with Twint- the below is a test run \nThe data used in in the POC dataset","937938b4":"# Project: Bank Sentiment Analysis \n\n## Summary \nIdentify customer sentiment of the top 4 Banks in South Africa via twitter sentiment analysis scoring\n\n#### Operations:\n1. [Twint](https:\/\/github.com\/twintproject\/twint) to scrape tweets of the top 4 banks in South Africa\n*  Standard Bank\n* Nedbank \n* Absa \n* FNB \n2. Clean tweets with WordPunctTokenizer and Regex \n3. TextBlog to process sentiment of tweets \n5. Matplotlib \/ Seaborn to visualise and analyze\n\n#### Additional projects (completed):\n* Expand data to include Capitec Bank and tweets from years 2019,2020,2021. Full data of all 5 banks can be found [here](https:\/\/www.kaggle.com\/slythe\/twitter-scrape-of-the-top-5-banks-in-south-africa)\n* [Build custom sentiment model](https:\/\/www.kaggle.com\/slythe\/twitter-sentiment-analysis-custom-model) on multiple Twitter data sets \n* Apply model to dataset\n\n#### Final Project (TBC):\nCompare results to the Customer Satifaction Index (CSI) and determine if the CSI is a correct reflection of the consumer sentiment","b08c08e9":"# precleaning\nDue to some issues experienced using  <a href=https:\/\/github.com\/twintproject\/twint\/issues\/1281>Twint<\/a> the process stops, Ive therefore done the majority of the scraping outside Kaggle and uploaded the data","a06cc91e":"#### Remove unnecessary rows \n* Remove tweets from Bank owned accounts i.e. FNBSA\n* Remove duplicates where tweet, bank and date are the same \n* Reindex dataframe","34ea9f06":"#### Create rolling Mean \/ Expanding ","021c5286":"#### Create an interactive plot","7ad0dbc1":"#### Tweet cleaning ","8ac7605c":"### Twint  guide\n\n<b>My reference guide: <\/b>\nhttps:\/\/github.com\/Slyth3\/Twitter_NLP\/blob\/main\/Quick%20Twint%20Code.txt\n\n<b> Official Github: <\/b>\nhttps:\/\/github.com\/twintproject\/twint","f7c81b97":"# Word Cloud","c7df8893":"#### Language analysis \n\nAlthough the language tag doesnt seem to get it right 100% of the time, we will drop these rows that arent english but keep undefined:\n* und = undefined --- this will also include tweets with only hashtags so we will keep this\n* en = english ","f8ea38ba":"### Configure and run Twint (twitter scrapper)","1c220198":"# Rolling plots","e97524b4":"### Important Note \nThis notebook is for analysis and confirmation of the process (the POC)\\\nThe full customer built sentiment model is in a further notebook found [here](https:\/\/www.kaggle.com\/slythe\/twitter-sentiment-analysis-custom-model)","2f7f36c6":"## Twint issues\nTwint as of running this notebook has multiple issues where it either doesnt run or runs and stops randomly.\nThe below is commented out and the pre-scraped data used","3575fade":"### Cleaning tweet data \n* Remove punctuation, hashtags, symbols etc\n\n***Note:*** \nCleaning can take awhile depending on your size of data and processing speeds \\\nIn order to do parallel processing download the file (https:\/\/github.com\/Slyth3\/Sentiment-analysis-on-South-African-Banks\/blob\/main\/multi_clean.py) \\\nThen import this file and run using the below:\n* import multi_clean\n* import multiprocessing as mp\n*from multiprocessing import  Pool\n* p = mp.Pool(mp.cpu_count())\n* cleaned_list = p.map(multi_clean.clean_text,tweets_df[\"tweet\"])\n* p.close()"}}