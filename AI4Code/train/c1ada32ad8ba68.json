{"cell_type":{"9861d8cc":"code","82638efe":"code","438bc7a6":"code","110699d1":"code","7fd22876":"code","3ec3227b":"code","979e102f":"code","0990468b":"code","e14f0f84":"code","0b9dd127":"markdown","1fe21099":"markdown","7ba3b39d":"markdown","7e92c686":"markdown","63be19ac":"markdown","3979e3aa":"markdown","1880701d":"markdown","5978c2b4":"markdown","50a45365":"markdown","f1728ec6":"markdown"},"source":{"9861d8cc":"# kaggle\u7684Notebook\u53ef\u4ee5\u6bd4\u8d5b\u6570\u636e\u52a0\u8f7d\u5230\u4f60\u5f53\u524d\u7684\u73af\u5883\u4e2d\u7684\/kaggle\/input\u6587\u4ef6\u5939\u91cc\uff0c\u8fd0\u884c\u8fd9\u4e2acell\u4f60\u5c31\u53ef\u4ee5\u67e5\u770b\u3002\u53e6\u5916\u4e0b\u9762\u4e24\u884c\u6ce8\u91ca\u4f1a\u6bd4\u8f83\u6709\u7528\uff0c\u5efa\u8bae\u9605\u8bfb\u3002\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","82638efe":"import numpy as np\nimport numba as nb\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport gdal\nfrom tqdm import tqdm\nfrom PIL import Image\nimport cv2\nimport random\n\nimport os\nimport gc\n\nDATAPATH = \"\/kaggle\/input\/sysu-rs-contest-2021\/\"","438bc7a6":"class myDataset(data.Dataset):\n    def __init__(self, data_path, set_name, val_rate=0.1):\n        self.set_name = set_name\n        self.imageList, self.labelList = [], []\n        # \u5982\u679c\u4f60\u8fd8\u6ca1\u6709\u5c06urban_CN2\u4e2d\u7684GeoJSON\u683c\u5f0f\u7684\u6807\u7b7e\u8f6c\u6362\u4e3a\u53ef\u7528\u7684\u6805\u683c\u6570\u636e\uff0c\u4f60\u5c31\u65e0\u6cd5\u4f7f\u7528urban_CN2\u4e2d\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\n        # folderList = [(data_path + \"\/train\/\" + i) for i in [\"rural_CN\", \"urban_CN\", \"urban_US\", \"urban_CN2\"]]\n        folderList = [(data_path + \"\/train\/\" + i) for i in [\"rural_CN\", \"urban_CN\", \"urban_US\"]]\n        for fd in folderList:\n            self.imageList.extend([i.path for i in os.scandir(fd + \"\/image\")])\n        self.labelList = [i.replace(\"image\", \"label\") for i in self.imageList]\n\n        # \u968f\u673a\u5212\u5206\u8bad\u7ec3\u548c\u9a8c\u8bc1\u96c6\n        total_num = len(self.imageList)\n        val_num = int(total_num * val_rate)\n\n        np.random.seed(0)\n        val_index = np.random.choice(np.arange(total_num), size=val_num, replace=False).astype(np.int)\n        train_index = np.array(list(set(np.arange(total_num, dtype=np.int)) - set(val_index)))\n\n        if set_name == \"train\":\n            idx_used = train_index\n        elif set_name == \"val\":\n            idx_used = val_index\n        else:\n            raise ValueError(\"set_name can only be 'train' or 'val'\")\n\n        self.imgList_used = np.array(self.imageList)[idx_used.astype(np.int)]\n        self.lbList_used = np.array(self.labelList)[idx_used.astype(np.int)]\n\n    def __len__(self):\n        return len(self.imgList_used)\n\n    def __getitem__(self, index):     \n        img_path, lb_path = self.imgList_used[index], self.lbList_used[index]\n\n        # PIL\u5e93\u5728\u8bfb\u53d6uint16\u7684tiff\u65f6\u4f1a\u6709\u95ee\u9898\uff0c\u56e0\u6b64\u4f7f\u7528gdal\u5e93\u8bfb\u53d6tiff\n        if img_path.split('.')[-1] == \"tif\":\n            img_ds = gdal.Open(img_path)\n            img = img_ds.ReadAsArray()\n            del img_ds\n        else:\n            img = np.array(Image.open(img_path)).transpose(2, 0, 1)\n        lb = np.array(Image.open(lb_path))\n\n        # \u5f71\u50cf\u5f52\u4e00\u5316\n        img = img\/img.max()\n\n        unified_size = 256\n        if self.set_name == \"train\":\n            # \u8bad\u7ec3\u65f6\u5982\u679c\u663e\u5361\u53d7\u4e0d\u4e86\u592a\u5927\u7684\u56fe\u50cf\uff0c\u5c31\u968f\u673a\u526a\u88c1\u5f97\u5c0f\u4e00\u4e9b\n            if img.shape[1]>unified_size:\n                uly, ulx = random.randint(0, img.shape[1]-unified_size), random.randint(0, img.shape[2]-unified_size)\n                img = img[:, uly:uly+unified_size, ulx:ulx+unified_size]\n                lb = lb[uly:uly+unified_size, ulx:ulx+unified_size]\n            # \u5982\u679c\u5f71\u50cf\u5927\u5c0f\u4e0d\u8db3\uff0c\u8fd9\u91cc\u56fe\u7701\u4e8b\u6211\u4eec\u628a\u5b83padding\u5230unified_size\uff0c\u4f46\u663e\u7136\u6709\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5.\n            elif img.shape[1]<unified_size:\n                size_y, size_x = img.shape[1], img.shape[2]\n                img = cv2.copyMakeBorder(img.transpose(1, 2, 0), 0, unified_size-size_y, 0, unified_size-size_x, cv2.BORDER_CONSTANT, value=(0, 0, 0)).transpose(2, 0, 1)\n                lb = cv2.copyMakeBorder(lb, 0, unified_size-size_y, 0, unified_size-size_x, cv2.BORDER_CONSTANT, value=0)\n                \n        return torch.as_tensor(img, dtype=torch.float), torch.as_tensor(lb, dtype=torch.int64)\n\n\nclass myDataset_test(data.Dataset):\n    def __init__(self, data_path):\n        self.imgList = [i.path for i in os.scandir(data_path) if i.name.split('.')[-1]]\n        self.imgList.sort()\n        self.imgNameList = [i.split('\/')[-1] for i in self.imgList]\n\n    def __len__(self):\n        return len(self.imgList)\n\n    def __getitem__(self, index):\n        img_path = self.imgList[index]\n        if img_path.split('.') == \"tif\":\n            img_ds = gdal.Open(img_path)\n            img = img_ds.ReadAsArray()\n            del img_ds\n        else:\n            img = np.array(Image.open(img_path)).transpose(2, 0, 1)\n\n        # \u9884\u6d4b\u7684\u65f6\u5019\u4e5f\u8981\u5f52\u4e00\u5316\n        img = img\/img.max()\n        return torch.as_tensor(img, dtype=torch.float)\n\n\ndef getDataLoader(dataPath, setName, shuffle=True, BSize=4, nWorkers=4, pinMem=True):\n    if setName in [\"train\", \"val\"]:\n        data_set = myDataset(dataPath, setName)\n        return data.DataLoader(data_set, batch_size=BSize, shuffle=shuffle, num_workers=nWorkers, pin_memory=pinMem)\n\n    elif setName == \"test\":\n        data_set = myDataset_test(dataPath)\n        return data.DataLoader(data_set, batch_size=BSize, shuffle=False, num_workers=nWorkers, pin_memory=pinMem)\n    \n    else:\n        raise ValueError(\"setName can only be 'train', 'val' or 'test'\")","110699d1":"class Resblock(nn.Module):\n    \"\"\"\n    Bottleneck Residual Block, CNN\u4e2d\u7684\u4e00\u4e2a\u5e38\u89c1\u7ec4\u4ef6\n    \"\"\"\n    def __init__(self, in_ch, out_ch, stride=1):\n        super().__init__()\n        self.ch_asc = (in_ch != out_ch)\n        mid_ch = out_ch\/\/4\n        self.conv = nn.Sequential(nn.Conv2d(in_ch, mid_ch, 1, 1, padding=0), nn.BatchNorm2d(mid_ch), nn.ReLU(),\n                                  nn.Conv2d(mid_ch, mid_ch, 3, stride, padding=1), nn.BatchNorm2d(mid_ch), nn.ReLU(),\n                                  nn.Conv2d(mid_ch, out_ch, 1, 1, padding=0), nn.BatchNorm2d(out_ch))\n        if self.ch_asc:\n            self.shortcut = nn.Sequential(nn.Conv2d(in_ch, out_ch, 1, 1, 0), nn.BatchNorm2d(out_ch))\n\n    def forward(self, x_in):\n        x = self.conv(x_in)\n        if self.ch_asc:\n            return F.relu(x + self.shortcut(x_in))\n        else:\n            return F.relu(x + x_in)\n\nclass myModel(nn.Module):\n    \"\"\"\n    \u4e00\u4e2a\u7b80\u5355\u7684\u8bed\u4e49\u5206\u5272\u7f51\u7edc\n    \"\"\"\n    def __init__(self, in_ch=3, n_classes=2):\n        self.n_classes = n_classes\n        super().__init__()\n        self.conv1 = nn.Sequential(nn.Conv2d(in_ch, 64, 3, stride=2, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n                                   nn.Conv2d(64, 64, 3, stride=1, padding=1), nn.BatchNorm2d(64), nn.ReLU())\n        self.conv2 = nn.Sequential(nn.MaxPool2d(3, stride=2, padding=1), \n                                   Resblock(in_ch=64, out_ch=128), \n                                   Resblock(in_ch=128, out_ch=128))\n        self.conv3 = nn.Sequential(nn.MaxPool2d(2, stride=2, padding=0), \n                                   Resblock(in_ch=128, out_ch=128), \n                                   Resblock(in_ch=128, out_ch=256))\n        self.conv4 = nn.Sequential(Resblock(in_ch=256, out_ch=256), \n                                   Resblock(in_ch=256, out_ch=512))\n        self.conv5 = nn.Sequential(Resblock(in_ch=512, out_ch=512),\n                                   Resblock(in_ch=512, out_ch=512))\n        self.up = nn.Sequential(nn.ConvTranspose2d(512, 256, 2, stride=2, padding=0), nn.BatchNorm2d(256), nn.ReLU(),\n                                nn.ConvTranspose2d(256, 128, 2, stride=2, padding=0), nn.BatchNorm2d(128), nn.ReLU(),\n                                nn.ConvTranspose2d(128, 64, 2, stride=2, padding=0), nn.BatchNorm2d(64), nn.ReLU(),\n                                nn.Conv2d(64, 32, 3, stride=1, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n                                nn.Conv2d(32, n_classes, 1, stride=1, padding=0))\n                                \n\n    def forward(self, inputs):\n        inputs = self.conv1(inputs)\n        inputs = self.conv2(inputs)\n        inputs = self.conv3(inputs)\n        inputs = self.conv4(inputs)\n        inputs = self.conv5(inputs)\n        \n        outputs = self.up(inputs)\n        return outputs","7fd22876":"def dice_coef(pred, label):\n    \"\"\"\n    \u8ba1\u7b97\u4e00\u4e2abatch\u4e2d\u6bcf\u4e2a\u6837\u672c\u7684Dice\u7cfb\u6570\n    \"\"\"\n    assert(pred.shape == label.shape)\n    batchSize = pred.shape[0]\n    pred, label = pred.view(batchSize, -1), label.view(batchSize, -1)\n    TP = torch.sum(pred * label, dim=1).float()\n    return 2 * TP \/ (torch.sum(pred, dim=1).float() + torch.sum(label, dim=1).float() + 0.00000001)\n\n@nb.njit\ndef encodePixel(binaryMap):\n    \"\"\"\n    \u628a\u4e00\u5f20\u9884\u6d4b\u7ed3\u679c\u7f16\u7801\u6210\u5e73\u53f0\u8981\u6c42\u7684\u4e0a\u4f20\u683c\u5f0f\n    \"\"\"\n    # \u8f93\u5165\u5fc5\u987b\u4e3a[h, w]\u578b\u72b6\u7684\u4e8c\u503c\u9884\u6d4b\u7ed3\u679c\n    assert len(binaryMap.shape) == 2\n    binaryMap = binaryMap.reshape(-1)\n    totalPixNum = binaryMap.shape[0]\n    encodedStr = \"\"\n    flag = 0\n    count = 0\n    for i in range(totalPixNum):\n        if (binaryMap[i] == 1) and (flag == 0) and (i < totalPixNum-1):\n            encodedStr += str(i+1)\n            encodedStr += \" \"\n            flag = 1\n            count += 1\n        elif (binaryMap[i] == 0) and (flag == 1):\n            encodedStr += str(count)\n            encodedStr += \" \"\n            count = 0\n            flag = 0\n        elif (binaryMap[i] == 1) and (flag == 1) and (i < totalPixNum-1):\n            count += 1\n        elif (binaryMap[i] == 1) and (flag == 1) and (i == totalPixNum-1):\n            encodedStr += str(count)\n            encodedStr += \" \"\n            count = 0\n            flag = 0\n        elif (binaryMap[i] == 1) and (flag == 0) and (i == totalPixNum-1):\n            encodedStr += str(i+1)\n            encodedStr += \" 1 \"\n            \n\n    return encodedStr[:-1]\n\n\ndef train(model, train_loader, val_loader, lr_base, epoch, device=torch.device('cpu:0'), comment=\"xxx\", ckpt_path=\".\/CKPT\/\", from_scrach=False):\n    \"\"\"\n    \u8bad\u7ec3\u6a21\u578b\uff0c \u5c06\u53c2\u6570\u4fdd\u5b58\u5728ckpt_path\/comment\/ckpt.pth\u4e2d\n    \"\"\"\n    model.to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr_base)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.8, patience=1,\n                                                     min_lr=0.000001, threshold=0.0001)\n    criteria = nn.CrossEntropyLoss()\n    ckpt_path = ckpt_path + \"\/\" + comment\n\n    if os.path.exists(ckpt_path + \"\/ckpt.pth\") and (not from_scrach):\n        ckpt = torch.load(ckpt_path + \"\/ckpt.pth\", map_location=torch.device('cpu'))\n        model.load_state_dict(ckpt[\"model\"])\n        optimizer.load_state_dict(ckpt[\"optimizer\"])\n        scheduler.load_state_dict(ckpt[\"scheduler\"])\n        ep_start = ckpt[\"epoch\"]\n        iter_start = ckpt[\"iteration\"]\n    else:\n        ep_start = 0\n        iter_start = 0\n\n    for ep in range(ep_start + 1, epoch + 1):\n        with tqdm(enumerate(train_loader), desc=\"epoch %3d\/%-3d\" % (ep, epoch), total=len(train_loader)) as t:\n            for batch_idx, (img_train, lb_train) in t:\n                img_train, lb_train = img_train.to(device), lb_train.to(device)\n                model.train()\n                # \u6b63\u5411\u4f20\u64ad\n                logits = model(img_train)\n                # \u8ba1\u7b97loss\uff0c\u53cd\u5411\u4f20\u64ad\uff0c\u66f4\u65b0\u53c2\u6570\n                loss_train = criteria(input=logits, target=lb_train)\n                optimizer.zero_grad()\n                loss_train.backward()\n                optimizer.step()\n\n                with torch.no_grad():\n                    n_iter = (ep - 1) * len(train_loader) + batch_idx\n                    pred = torch.argmax(F.softmax(logits, dim=1), dim=1)\n                    dice_train = torch.mean(dice_coef(pred, lb_train))\n\n                    # \u6bcf\u8fc7\u51e0\u4e2aiter\u5c31\u8ba1\u7b97\u4e00\u6b21\u9a8c\u8bc1\u96c6\u7cbe\u5ea6\n                    if (batch_idx in [len(train_loader)-1, (len(train_loader)\/\/2)]) or n_iter == iter_start:\n                        model.eval()\n                        dice_val_all = []\n                        for index_v, (img_val, lb_val) in enumerate(val_loader):\n                            img_val, lb_val = img_val.to(device), lb_val.to(device)\n                            pred = torch.argmax(F.softmax(model(img_val), dim=1), dim=1)\n                            dice_val_all.append(dice_coef(pred, lb_val))\n                        dice_val_all = torch.cat(dice_val_all, dim=0)\n                        dice_val = torch.mean(dice_val_all)\n\n                t.set_postfix_str(\"loss(train): %.4f, dice(train): %.4f, dice(val): %.4f, lr: %f\"\n                                  % (loss_train, dice_train, dice_val, \n                                     optimizer.state_dict()['param_groups'][0]['lr']))\n\n        scheduler.step(dice_val)\n\n        if not os.path.exists(ckpt_path):\n            os.mkdir(ckpt_path)\n        torch.save({'epoch': ep,\n                    'iteration': ep * len(train_loader),\n                    'model': model.state_dict(),\n                    'optimizer': optimizer.state_dict(),\n                    'scheduler': scheduler.state_dict(),\n                    }, ckpt_path + \"\/ckpt.pth\")\n\n\ndef inference(model, data_loader, ckpt_path, comment, save_path, device=torch.device('cpu:0')):\n    \"\"\"\n    \u4f7f\u7528model\u9884\u6d4bdata_loader\u4e2d\u7684\u6570\u636e\n    \"\"\"      \n    ckpt_path = ckpt_path + \"\/\" + comment\n\n    if os.path.exists(ckpt_path + \"\/ckpt.pth\"):\n        ckpt = torch.load(ckpt_path + \"\/ckpt.pth\", map_location=torch.device('cpu'))\n        model.load_state_dict(ckpt[\"model\"])\n        model.to(device)\n        \n        fnList, encodedPixelList = [\"ID\"], [\"Prediction\"]\n        with tqdm(enumerate(data_loader), desc=\"Inferencing\" , total=len(data_loader)) as t:\n            for batch_idx, img in t:\n                img = img.to(device)\n                model.eval()\n                with torch.no_grad():\n                    # \u7531\u4e8e\u6a21\u578b\u4f1a\u8fdb\u884c\u5e26stride\u7684\u5377\u79ef\u3001\u53cd\u5377\u79ef\uff0c\u56e0\u6b64\u8f93\u5165\u5f71\u50cf\u957f\u5bbd\u9700\u8981\u4e3a\u67d0\u4e2a\u6570\u7684\u500d\u6570\uff0c\u6b64\u5904\u7684\u6a21\u578b\u9700\u8981\u4e3a8\u7684\u500d\u6570\n                    # \u6240\u4ee5\u9762\u5bf9\u975e8\u7684\u500d\u6570\u957f\u5bbd\u7684\u8f93\u5165\uff0c\u9700\u8981\u5206\u5757\u9884\u6d4b\n                    # \u8fd9\u4e2a\u51fd\u6570\u4f7f\u7528\u65f6data_loader\u7684batch size\u53ea\u80fd\u662f1\uff0c\u4e0d\u80fd\u5f88\u597d\u7684\u5229\u7528gpu\u7684\u5e76\u884c\u5904\u7406\u80fd\u529b\u3002\u4f46\u8fd9\u6837\u5199\u6bd4\u8f83\u7701\u4e8b\uff0c\u53cd\u6b63\u53ea\u662f\u4e2a\u5165\u95e8\u6559\u7a0b\u3002\n                    if (img.shape[2] % 8 + img.shape[3] % 8) == 0:\n                        logits = model(img)\n                        pred = torch.argmax(F.softmax(logits, dim=1), dim=1)\n                    else:\n                        pred = torch.zeros([1, img.shape[2], img.shape[3]], dtype=torch.int, device=device)\n                        # \u53cd\u6b63\u6211\u5df2\u7ecf\u77e5\u9053\uff0cimage_test\u91cc\u53ea\u67091024*1024\u548c163*163\u4e24\u79cd\u5c3a\u5bf8(\u6e29\u99a8\u63d0\u793a\uff1a\u5176\u5b9e\u8fd8\u6709\u4e09\u5f20\u56fe\u7247\u662f162*163\u7684\uff09\n                        img_tiled = torch.cat([img[:, :, 0:128, 0:128], img[:, :, img.shape[2]-128:, 0:128], img[:, :, 0:128, 35:], img[:, :, img.shape[2]-128:, 35:]], dim=0)\n                        pred_tiled = torch.argmax(F.softmax(model(img_tiled), dim=1), dim=1)\n                        pred[0, 0:128, 0:128] = pred_tiled[0, ...]\n                        pred[0, img.shape[2]-128:, 0:128] = pred_tiled[1, ...]\n                        pred[0, 0:128, 35:] = pred_tiled[2, ...]\n                        pred[0, img.shape[2]-128:, 35:] = pred_tiled[3, ...]\n                        # \u867d\u7136\u4e0a\u9762\u8fd9\u6bb5\u4ee3\u7801\u770b\u8d77\u6765\u5f88\u8822\uff0c\u4f46\u662f\u80fd\u7528\u5c31\u884c\u4e86\uff0c\u6bd5\u7adf\u53ea\u662f\u4e2a\u6559\u7a0b\n                \n                pred = pred.cpu().numpy()\n                fnList.append(data_loader.dataset.imgNameList[batch_idx])\n                encodedPixelList.append(encodePixel(pred[0]))\n            \n            pred2submit = np.array(list(zip(fnList, encodedPixelList)))\n            np.savetxt(save_path, pred2submit, delimiter=\",\", fmt=\"%s\")\n            print(\"prediction saved to %s\" % save_path)\n    else:\n        print(\"Checkpoint not found\")","3ec3227b":"model = myModel(n_classes=2)\ntrainLoader = getDataLoader(dataPath=DATAPATH + \"\/train_data\", setName=\"train\", shuffle=True, BSize=16, nWorkers=2, pinMem=True)\nvalLoader = getDataLoader(dataPath=DATAPATH+\"\/train_data\", setName=\"val\", shuffle=False, BSize=16, nWorkers=2, pinMem=True)\ntrain(model, trainLoader, valLoader, lr_base=0.001, epoch=20, device=torch.device('cuda:0'), comment=\"foo\", ckpt_path=\"\/kaggle\/working\/\", from_scrach=False)","979e102f":"testImageList = [i.path for i in os.scandir(DATAPATH+\"\/test_image\")]\nmodel = model.to(torch.device(\"cuda:0\"))\nmodel.eval()\n\nwith torch.no_grad():\n    for i in range(0, len(testImageList), 50):\n        img = cv2.imread(testImageList[i], -1).transpose(2, 0, 1)\n        img = img\/img.max()\n        img = torch.as_tensor(img.reshape(1, 3, img.shape[1], img.shape[2]), dtype=torch.float).cuda()\n        pred = torch.argmax(torch.softmax(model(img), dim=1), dim=1).cpu().numpy()[0, :, :]\n        plt.figure(figsize=(10, 20))\n        plt.subplot(1, 2, 1)\n        plt.imshow(img.cpu().numpy().reshape(3, img.shape[2], img.shape[3]).transpose(1, 2, 0))\n        plt.subplot(1, 2, 2)\n        plt.imshow(pred)\n        plt.show()\n        if i>500:\n            break","0990468b":"testLoader = getDataLoader(dataPath=DATAPATH + \"\/test_image\", setName=\"test\", shuffle=False, BSize=1, nWorkers=2, pinMem=True)\ninference(model, data_loader=testLoader, ckpt_path=\"\/kaggle\/working\/\", comment=\"foo\", save_path=\"\/kaggle\/working\/prediction.csv\", device=torch.device('cuda:0'))","e14f0f84":"df = pd.read_csv(r\"\/kaggle\/working\/prediction.csv\")\nprint(\"\u4e00\u5171\u6709%d\u884c\"%len(df))\ndf.head(10)","0b9dd127":"\u597d\u4e86\uff0c\u6211\u4eec\u5df2\u7ecf\u9884\u6d4b\u5b8c\u4e86\uff0c\u7ed3\u679c\u4fdd\u5b58\u5728save_path\u91cc\uff0c\u8fd9\u91cc\u6211\u4eec\u8bbe\u7684\u662f\"\/kaggle\/working\/prediction.csv\"\uff0c\u53ef\u4ee5\u7528pandas\u6253\u5f00\u770b\u770b\u3002\n\u5982\u679c\u4f60\u5728\u8fd0\u884c\u8fd9\u4e2aNotebook\uff0c\u53f3\u4fa7\u4f1a\u6709\u73af\u5883\u7684\u6587\u4ef6\u5217\u8868\uff0c\u4f60\u53ef\u4ee5\u5728save_path\u627e\u5230\u8fd9\u4e2a\u6587\u4ef6\uff0c\u5e76\u4e0b\u8f7d\uff0c\u4e0b\u8f7d\u4ee5\u540e\u5c31\u53ef\u4ee5\u4e0a\u4f20\u5230\u6bd4\u8d5b\u5e73\u53f0\u67e5\u770b\u4f60\u7684\u6210\u7ee9\u3002\nkaggle\u4e5f\u6709API\u53ef\u4ee5\u76f4\u63a5\u4eceNotebook\u91cc\u4e0a\u4f20\u6587\u4ef6\u5230\u6bd4\u8d5b\u5e73\u53f0\uff0c\u4f60\u53ef\u4ee5\u81ea\u5df1\u627e\u627e","1fe21099":"\u53ef\u4ee5\u770b\u51fa\uff0c\u9884\u6d4b\u7ed3\u679c\u6bd4\u8f83\u4e00\u822c\uff0c\u56e0\u4e3a\u6211\u4eec\u53ea\u662f\u7528\u4e86\u4e00\u4e2a\u975e\u5e38\u7b80\u5355\u7684\u6a21\u578b\u548c\u7b80\u5355\u7684\u8bad\u7ec3\u7b56\u7565\u8bad\u7ec3\u4e86\u5c11\u91cf\u7684epoch\u3002\u53e6\u5916\u53ef\u4ee5\u53d1\u73b0\u7b2c3\u30015\u30019\u300112\u5f20\u56fe\u7247\uff0c\u6a21\u578b\u4ec0\u4e48\u90fd\u6ca1\u6709\u9884\u6d4b\u51fa\u6765\uff0c\u8fd9\u662f\u56e0\u4e3a\u8fd9\u4e9b\u56fe\u7247\u548c\u6211\u4eec\u8bad\u7ec3\u7684\u65f6\u5019\u6ca1\u7528\u4e0a\u7684\u90a3\u4e9b\u6570\u636e\u662f\u540c\u7c7b\u7684\u6570\u636e\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u77e5\u9053\uff0c\u8bad\u7ec3\u7684\u65f6\u5019\u6a21\u578b\u6ca1\u89c1\u8fc7\u7684\u5f71\u50cf\u7c7b\u578b\uff0c\u6a21\u578b\u662f\u6ca1\u6cd5\u8fdb\u884c\u6b63\u786e\u9884\u6d4b\u7684\u3002\u6240\u4ee5\u8fd9\u4e2a\u6bd4\u8d5b\u7684\u4e00\u4e2a\u91cd\u70b9\u5c31\u662f\u628aGeoJSON\u7684\u6807\u7b7e\u8f6c\u6210\u53ef\u7528\u7684\u6805\u683c\u6807\u7b7e\uff0c\u4e0d\u7136\u4f60\u6839\u672c\u5c31\u7528\u4e0d\u4e86\u90a3\u4e9b\u6570\u636e\uff0c\u7528\u4e0d\u4e86\u90a3\u4e9b\u6570\u636e\uff0c\u4f60\u7684\u5206\u6570\u5c31\u80af\u5b9a\u6bd4\u7528\u7684\u4e86\u90a3\u4e9b\u6570\u636e\u7684\u4eba\u4f4e\u3002","7ba3b39d":"# 3. Model Training\n\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u4fdd\u5b58\u8bad\u7ec3\u597d\u7684\u53c2\u6570","7e92c686":"\u672c\u4f8b\u4e2d\u6211\u4eec\u53ea\u8bad\u7ec3\u4e8620\u4e2aepoch\uff0c\u53ef\u4ee5\u53d1\u73b0validation\u96c6\u7684dice\u7cfb\u6570\u968f\u7740\u8bad\u7ec3\u7684\u8fdb\u884c\u4e0d\u65ad\u63d0\u9ad8\u3002\u4f60\u4e5f\u53ef\u4ee5\u5728\u8bad\u7ec3\u65f6\u8bb0\u5f55\u4e00\u4e0b\u6307\u6807\u7684\u53d8\u5316\uff0c\u7ed8\u5236\u6210\u56fe\u8868\uff0c\u4f9d\u636e\u56fe\u8868\u505a\u51fa\u4e00\u4e9b\u5224\u65ad\u3002\n- \u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u5c31\u53ef\u4ee5\u7528\u8bad\u7ec3\u597d\u7684model\u6765\u9884\u6d4b\u8bd5\u8bd5","63be19ac":"# 0. Import\n\u52a0\u8f7d\u9700\u8981\u7684python\u5e93","3979e3aa":"# 2. define training, inferencing and other functions\n\u5b9a\u4e49\u8bad\u7ec3\u6d41\u7a0b\u548c\u9884\u6d4b\u6d41\u7a0b\uff0c\u5e76\u5b9a\u4e49\u4e00\u4e9b\u8bad\u7ec3\u548c\u9884\u6d4b\u65f6\u4f1a\u7528\u5230\u7684\u51fd\u6570","1880701d":"# Overview\n\u8fd9\u4e2a\u6559\u7a0b\u4f7f\u7528pytorch\u4e3a\u60a8\u7b80\u8981\u7684\u5c55\u793a\u4e86\u6570\u636e\u52a0\u8f7d\u3001\u8bad\u7ec3\u6a21\u578b\u548c\u9884\u6d4b\u7ed3\u679c\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u5e2e\u52a9\u60a8\u5feb\u901f\u4e0a\u624b","5978c2b4":"# 2. define Model\n\u901a\u8fc7\u7ee7\u627fnn.Module\u7c7b\u7684\u65b9\u5f0f\u5feb\u901f\u6784\u5efa\u81ea\u5df1\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b","50a45365":"# 4. Predict and Save Results\n\u8bad\u7ec3\u597d\u6a21\u578b\u540e\uff0c\u9700\u8981\u5bf9test_image\u6587\u4ef6\u5939\u91cc\u7684\u5f71\u50cf\u8fdb\u884c\u9884\u6d4b\u5f97\u5230\u6240\u6709\u7684\u7ed3\u679c\u5e76\u63d0\u4ea4\uff0c\u624d\u80fd\u83b7\u5f97\u5206\u6570","f1728ec6":"# 1. define DataLoader\nPytorch\u63d0\u4f9b\u4e86\u65b9\u4fbf\u7684\u6570\u636e\u52a0\u8f7d\u5de5\u5177\uff0c\u4f60\u53ef\u4ee5\u901a\u8fc7\u7ee7\u627f\u91cd\u5199torch.utils.data\u4e2d\u7684Dataset\u7c7b\u5b9a\u4e49\u81ea\u5df1\u7684\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528DataLoader\u5728\u8bad\u7ec3\u65f6\u52a0\u8f7d\u4f60\u7684\u6570\u636e\u96c6"}}