{"cell_type":{"da20c2f2":"code","b20d51d4":"code","b9ae4b0a":"code","3d2f9ad0":"code","7c86e22e":"code","a89b8b73":"code","e83f8e4b":"code","3e27e9a8":"code","fff0e698":"code","ab309fda":"code","253a9efa":"code","85031851":"code","c4fcf4f1":"code","2a38cff9":"code","c7e8ba35":"code","36e778ad":"code","bb7e2f33":"code","58e13223":"code","3f217eb6":"markdown","83ee3c5e":"markdown","e6ad2b2d":"markdown","3891dd8b":"markdown","0af3cfbe":"markdown"},"source":{"da20c2f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport lightgbm as lgb\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os","b20d51d4":"import h2o\nprint(h2o.__version__)\nfrom h2o.automl import H2OAutoML\n\nh2o.init(max_mem_size='16G')","b9ae4b0a":"train = pd.read_csv('\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/predict-volcanic-eruptions-ingv-oe\/sample_submission.csv')","3d2f9ad0":"scaled_feature_df = pd.read_csv('..\/input\/ingv-tsfresh-7730\/train.csv', sep = ';', index_col=0)\nscaled_feature_df = scaled_feature_df.loc[train['segment_id']]\nscaled_test_df = pd.read_csv('..\/input\/ingv-tsfresh-7730\/test.csv', sep = ';', index_col=0)\nscaled_test_df = scaled_test_df.loc[test['segment_id']]","7c86e22e":"from sklearn.feature_selection import SelectFromModel","a89b8b73":"sfm = SelectFromModel(estimator=lgb.LGBMRegressor())\nX = scaled_feature_df.drop('time_to_eruption',axis=1).copy()\nX.columns = list(np.arange(len(X.columns)))\ny = scaled_feature_df['time_to_eruption']\nsfm.fit(X, y)","e83f8e4b":"selected_features = list(scaled_feature_df.drop('time_to_eruption',axis=1).columns[sfm.get_support()])\nselected_features","3e27e9a8":"print('Number of selected features: ' + str(len(selected_features)))","fff0e698":"scaled_feature_df = scaled_feature_df[selected_features]\nscaled_test_df = scaled_test_df[selected_features]","ab309fda":"train_h2o = h2o.H2OFrame(scaled_feature_df)\ntrain_label_h2o = h2o.H2OFrame(train[['time_to_eruption']])\ntrain_h2o['time_to_eruption'] = train_label_h2o['time_to_eruption']\n\ntest_feature_h2o = h2o.H2OFrame(scaled_test_df)","253a9efa":"print(train_h2o.shape)\nprint(test_feature_h2o.shape)","85031851":"x = test_feature_h2o.columns\ny = 'time_to_eruption'","c4fcf4f1":"aml = H2OAutoML(max_models=1000, seed=121, stopping_metric='MAE',\n                max_runtime_secs=360*60) # set 360 minutes\naml.train(x=x, y=y, training_frame=train_h2o)","2a38cff9":"# View the AutoML Leaderboard\nlb = aml.leaderboard\nlb.head(rows=lb.nrows)  # Print all rows instead of default (10 rows)","c7e8ba35":"# The leader model is stored here\naml.leader","36e778ad":"# If you need to generate predictions on a test set, you can make\n# predictions directly on the `\"H2OAutoML\"` object, or on the leader\n# model object directly\n\npreds = aml.predict(test_feature_h2o)","bb7e2f33":"submission = pd.DataFrame()\nsubmission['segment_id'] = test['segment_id']\nsubmission['time_to_eruption'] = preds.as_data_frame().values.flatten()\nsubmission.loc[submission['time_to_eruption']<0, 'time_to_eruption'] = 0 #make sure all prediction values are larger than 0\nsubmission.to_csv('submission_recent.csv', header=True, index=False)","58e13223":"submission","3f217eb6":"Here are present results with different runtimes:\n\n**Note: Even with the same settings (max_models, seed, and max_runtime_secs), the prediction results of each run seem to be somehow different.**\n\n\n|Trial|   Runtime(mins) |   Public Score |   AutoML validation score|   |\n|---:|----------:|---------------:|--------------------:|   |\n|  0 |         1 |    ~7.65320e+06  |         ~5.18657e+06 |   |\n|  1 |        10 |    ~6.16750e+06  |         ~3.74239e+06 |   |\n|  2 |        30 |    ~6.01172e+06 |         ~3.36789e+06 |   |\n|  3 |       120 |    ~5.81476e+06 |         ~3.27152e+06 |  **Best result !!!** |\n|  4 |       360 |    ~5.95679e+06 |          ~3.11598e+06\t|  **Overfitting :(** |\n\n\n\n","83ee3c5e":"Since this competition permits the use of automated machine learning tool(s) (\u201cAMLT\u201d), this notebook uses **h2o automl** without tuning hyperparameters, and keeps the same features as my previous notebook (features after resampling):\n- https:\/\/www.kaggle.com\/patrick0302\/ingv-volcanic-eruption-prediction-add-resampling\n\nAlso, notebooks below are some very useful references:\n- https:\/\/www.kaggle.com\/ajcostarino\/ingv-volcanic-eruption-prediction-lgbm-baseline\n- https:\/\/www.kaggle.com\/tunguz\/lanl-earthquake-with-h2o-automl","e6ad2b2d":"# Use lightgbm to select important features","3891dd8b":"# Create model (h2o automl)","0af3cfbe":"Thanks for the dataset (generated by TSFresh library) from [Alexander Lyubchenko](https:\/\/www.kaggle.com\/carpediemamigo):\n- https:\/\/www.kaggle.com\/carpediemamigo\/ingv-catboost-baseline-tsfresh\/data\n- https:\/\/www.kaggle.com\/carpediemamigo\/ingv-tsfresh-7730"}}