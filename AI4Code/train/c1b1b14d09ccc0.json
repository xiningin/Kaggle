{"cell_type":{"25ab52ac":"code","05c32d81":"code","430dabc7":"code","9144651f":"code","648d1c85":"code","4ddfd6ac":"code","398eea99":"code","f4d2c3e2":"code","525fa948":"code","188587ec":"code","7284f11a":"code","2927afc3":"code","eb4829c7":"code","65b099c8":"code","37e21fa3":"code","020d73b4":"code","0be1f148":"code","f105ca10":"code","e98d967f":"markdown","6ad6c5f1":"markdown","a05f8fef":"markdown","d69d47f9":"markdown","705ed386":"markdown","d2b6c87e":"markdown","0951e55d":"markdown"},"source":{"25ab52ac":"import numpy as np\nimport pandas as pd\n\nimport keras\nfrom keras.preprocessing import image\nfrom keras.utils import to_categorical\n\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.models import Sequential,Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten,BatchNormalization,Activation\n\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.python.keras import backend as K\n\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport cv2","05c32d81":"# Directory Listings for train and test images\n\ntrain_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\ntest_dir='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'","430dabc7":"# Reading the csv files\n\ntrain = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ntest = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')\nsubmission=pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')","9144651f":"# Comparing the number of records in both categories\ntrain['target'].value_counts()","648d1c85":"train_samples = train.copy()\ntrain_samples.info()","4ddfd6ac":"# Training data\ntrain_labels = []\ntrain_images =[]\n\nfor i in range(train_samples.shape[0]):\n    train_images.append(train_dir+train_samples['image_name'].iloc[i]+'.jpg')\n    train_labels.append(train_samples['target'].iloc[i])\n\ndf_train = pd.DataFrame(train_images)\ndf_train.columns =['images']\ndf_train['target'] = train_labels","398eea99":"# Test data\ntest_images =[]\nfor i in range(test.shape[0]):\n    test_images.append(test_dir+test['image_name'].iloc[i]+'.jpg')\n\ndf_test = pd.DataFrame(test_images)\ndf_test.columns = ['images']","f4d2c3e2":"# Splitting the train data further into train and validation sets\nX_train, X_val, y_train,y_val = train_test_split(df_train['images'],df_train['target'],test_size=0.2,random_state=0)\n\ntrain = pd.DataFrame(X_train)\ntrain.columns = ['images']\ntrain['target']=y_train\n\nvalidation = pd.DataFrame(X_val)\nvalidation.columns = ['images']\nvalidation['target']=y_val","525fa948":"def get_predictions(model,sub_df):\n    target=[]\n    for path in df_test['images']:\n        img=cv2.imread(str(path))\n        img = cv2.resize(img, (224,224))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32)\/255.\n        img=np.reshape(img,(1,224,224,3))\n        prediction=model.predict(img)\n        target.append(prediction[0][0])\n    \n    sub_df['target']=target\n    return sub_df","188587ec":"train_datagen = ImageDataGenerator(preprocess_input,rescale=1.\/255,rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(preprocess_input,rescale=1.\/255)\n\nimage_size = 224\n\ntrain_generator = train_datagen.flow_from_dataframe(\n                    train,\n                    x_col='images',\n                    y_col ='target',\n                    target_size=(image_size,image_size),\n                    batch_size=8,\n                    shuffle=True,\n                    class_mode='raw')\n\nvalidation_generator = val_datagen.flow_from_dataframe(\n                    validation,\n                    x_col='images',\n                    y_col ='target',\n                    target_size=(image_size,image_size),\n                    batch_size=8,\n                    shuffle=False,\n                    class_mode='raw')","7284f11a":"def vgg16_model(num_classes=None):\n    model = VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))\n    x = Flatten()(model.output)\n    output = Dense(1,activation='sigmoid')(x)\n    model = Model(model.input,output)\n    \n    return model","2927afc3":"vgg_conv = vgg16_model(1)","eb4829c7":"def focal_loss(alpha=0.25,gamma=2.0):\n    def focal_crossentropy(y_true, y_pred):\n        bce = K.binary_crossentropy(y_true, y_pred)\n        \n        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n        \n        alpha_factor = 1\n        modulating_factor = 1\n\n        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n        modulating_factor = K.pow((1-p_t), gamma)\n\n        # compute the final loss and return\n        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n    return focal_crossentropy","65b099c8":"# Defining the optimizer and compiling the model\nopt = Adam(lr=1e-5)\nvgg_conv.compile(loss=focal_loss(),optimizer=opt,metrics=[keras.metrics.AUC()])","37e21fa3":"# Denining the num of epochs, batch_size and steps for training and validation\nnb_epochs = 2\nbatch_size=8\nnb_train_steps = train.shape[0]\/\/batch_size  # \/\/ rounds off the result of division\nnb_validation_steps = validation.shape[0]\/\/batch_size\nprint(\"Number of training and validation steps are {} and {}\".format(nb_train_steps,nb_validation_steps))","020d73b4":"# Fitting the model\nvgg_conv.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_steps,\n    epochs=nb_epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_steps)","0be1f148":"# Getting the predictions for test data\n\nsub_vgg16 = submission.copy()\nsub_vgg16 = get_predictions(vgg_conv,sub_vgg16)\nsub_vgg16.head()","f105ca10":"sub_vgg16.to_csv('submission_vgg16_Complete.csv',index=False)","e98d967f":"# Modeling","6ad6c5f1":"This is a simple baseline model using VGG16. I have used the entire dataset to train this model. It gave me a public score of 0.853.\n","a05f8fef":"# Helper Functions","d69d47f9":"# Exploring the data","705ed386":"# Preparing the train and test data","d2b6c87e":"# Data Preprocessing","0951e55d":"#  Importing Libraries"}}