{"cell_type":{"676f140d":"code","129f8cd6":"code","d3336a7f":"code","47e7b249":"code","dc6705b9":"code","69a3792c":"code","54f77abe":"code","63397143":"markdown","d3a02df3":"markdown"},"source":{"676f140d":"import numpy as np # linear algebra\nimport scipy as sp\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor\n\ntrain = pd.read_csv('..\/input\/train.csv', index_col='id')\ntest = pd.read_csv('..\/input\/test.csv', index_col='id')\n\nstructures = pd.read_csv('..\/input\/structures.csv')\n\ndef map_atom_info(df, atom_idx):\n    df = pd.merge(df, structures, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    df = df.drop('atom_index', axis=1)\n    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return df\n\ntrain = map_atom_info(train, 0)\ntrain = map_atom_info(train, 1)\n\ntest = map_atom_info(test, 0)\ntest = map_atom_info(test, 1)","129f8cd6":"%%time\n# Engineer a single feature: distance vector between atoms\n#  (there's ways to speed this up!)\n\ndef dist(row):\n    return ( (row['x_1'] - row['x_0'])**2 +\n             (row['y_1'] - row['y_0'])**2 +\n             (row['z_1'] - row['z_0'])**2 ) ** 0.5\n\n#train['dist'] = train.apply(lambda x: dist(x), axis=1)\n#test['dist'] = test.apply(lambda x: dist(x), axis=1)\n# ","d3336a7f":"%%time\n# This block is SPPED UP\n\ntrain_p_0 = train[['x_0', 'y_0', 'z_0']].values\ntrain_p_1 = train[['x_1', 'y_1', 'z_1']].values\ntest_p_0 = test[['x_0', 'y_0', 'z_0']].values\ntest_p_1 = test[['x_1', 'y_1', 'z_1']].values\n\ntr_a_min_b = train_p_0 - train_p_1\nte_a_min_b = test_p_0 - test_p_1","47e7b249":"%%time\ntrain['dist_np_linalg'] = np.linalg.norm(train_p_0 - train_p_1, axis=1)\ntest['dist_np_linalg'] = np.linalg.norm(test_p_0 - test_p_1, axis=1)","dc6705b9":"%%time\n# python vectorized: even faster!\ntrain['dist_numpy'] = np.sqrt(np.sum((train_p_1 - train_p_0)**2, axis=1)) \ntest['dist_numpy'] = np.sqrt(np.sum((test_p_1 - test_p_0)**2, axis=1))","69a3792c":"%%time\ntrain['dist_einsum'] = np.sqrt(np.einsum('ij,ij->i', tr_a_min_b, tr_a_min_b))\ntest['dist_einsum'] = np.sqrt(np.einsum('ij,ij->i', te_a_min_b, te_a_min_b))","54f77abe":"train.head()","63397143":"# Calculate distance","d3a02df3":"This is continuation of this kernel:\nhttps:\/\/www.kaggle.com\/seriousran\/just-speed-up-calculate-distance-from-benchmark\n\nsimple numpy vectorized function gives another 30% +\/- performance boost.\n\nAdded even faster method with np.einsum from this kernel:\nhttps:\/\/www.kaggle.com\/rakibilly\/faster-distance-calculation-from-benchmark\n"}}