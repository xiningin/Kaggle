{"cell_type":{"17ba0e65":"code","5f9fbb60":"code","72430395":"code","750c9aa8":"code","beaf4a48":"code","520b37cb":"code","77ebc6b5":"code","b2fafda7":"code","25e0bda6":"code","ff0d84cb":"code","cc6a6fec":"code","8b691bd1":"code","e4f6ed48":"code","d1f3042c":"code","12f806de":"code","91f24db5":"code","2c4fc516":"code","7870d13b":"code","1b46cae2":"code","6a0ab217":"markdown","03004542":"markdown","3194560f":"markdown","f5d9d4cd":"markdown","50d5e193":"markdown","22843d18":"markdown","ea3f20e3":"markdown","350a5516":"markdown","e34040d3":"markdown","a95ece05":"markdown","efa70f73":"markdown","18ed3257":"markdown"},"source":{"17ba0e65":"import os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split, ShuffleSplit, KFold, cross_val_score\nfrom sklearn.metrics import roc_auc_score\n\nfrom catboost import CatBoostClassifier, Pool, cv\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set()\n\nimport time\nimport datetime\n\nimport ujson as json\nfrom tqdm import tqdm_notebook\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5f9fbb60":"%%time\nPATH_TO_DATA = '..\/input\/'\n\nsample_submission = pd.read_csv(os.path.join(PATH_TO_DATA, 'sample_submission.csv'), \n                                    index_col='match_id_hash')\ndf_train_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_features.csv'), \n                                    index_col='match_id_hash')\ndf_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_targets.csv'), \n                                   index_col='match_id_hash')\ndf_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'), \n                                   index_col='match_id_hash')","72430395":"print('Shape of Training set: {0}\\nShape of Test set: {1}'.format(df_train_features.shape,df_test_features.shape))","750c9aa8":"#a helper function, we will use it in next cell\ndef read_matches(matches_file):\n    \n    MATCHES_COUNT = {\n        'test_matches.jsonl': 10000,\n        'train_matches.jsonl': 39675,\n    }\n    _, filename = os.path.split(matches_file)\n    total_matches = MATCHES_COUNT.get(filename)\n    \n    with open(matches_file) as fin:\n        for line in tqdm_notebook(fin, total=total_matches):\n            yield json.loads(line)","beaf4a48":"def add_new_features(df_features, matches_file):\n    \n    # Process raw data and add new features\n    for match in read_matches(matches_file):\n        match_id_hash = match['match_id_hash']\n\n        # Counting ruined towers for both teams\n        radiant_tower_kills = 0\n        dire_tower_kills = 0\n        for objective in match['objectives']:\n            if objective['type'] == 'CHAT_MESSAGE_TOWER_KILL':\n                if objective['team'] == 2:\n                    radiant_tower_kills += 1\n                if objective['team'] == 3:\n                    dire_tower_kills += 1\n\n        # Write new features\n        df_features.loc[match_id_hash, 'radiant_tower_kills'] = radiant_tower_kills\n        df_features.loc[match_id_hash, 'dire_tower_kills'] = dire_tower_kills\n        df_features.loc[match_id_hash, 'diff_tower_kills'] = radiant_tower_kills - dire_tower_kills","520b37cb":"%%time\n# copy the dataframe with features\ndf_train_features_extended = df_train_features.copy()\ndf_test_features_extended = df_test_features.copy()\n\n# add new features\nadd_new_features(df_train_features_extended, os.path.join(PATH_TO_DATA, 'train_matches.jsonl'))\nadd_new_features(df_test_features_extended, os.path.join(PATH_TO_DATA, 'test_matches.jsonl'))","77ebc6b5":"df_train_features_extended.info() #no categorical data here ","b2fafda7":"X = df_train_features_extended.values\ny = df_train_targets['radiant_win'].map({True: 1, False: 0}).values\nX_test = df_test_features_extended.values\nprint('Shape of Training set: ', X.shape, ' shape of target: ', y.shape, ' shape of test set: ', X_test.shape)","25e0bda6":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=17) #let's use holdout","ff0d84cb":"model = CatBoostClassifier(iterations=400,random_seed=42,eval_metric='AUC',logging_level='Silent')","cc6a6fec":"%%time\n#https:\/\/github.com\/catboost\/tutorials\/blob\/master\/python_tutorial.ipynb\nmodel.fit(X_train, y_train,\n    eval_set=(X_valid, y_valid),\n    #logging_level='Verbose',  # you can uncomment this for text output\n    plot=True #Uncomment and you'll see really great real time interactive graph\n);","8b691bd1":"%%time\ncv_params = model.get_params()\nprint('cv params: ', cv_params)\ncv_data = cv(\n    Pool(X, y),\n    cv_params,\n    seed=17,\n    fold_count=5,\n    plot=True #this one has much more delay, but results are awesome (you really could understand how learning was going over folds)\n)","e4f6ed48":"print('Best validation accuracy score: {:.2f}\u00b1{:.4f} on step {}'.format(\n    np.max(cv_data['test-AUC-mean']),\n    cv_data['test-AUC-std'][np.argmax(cv_data['test-AUC-mean'])],\n    np.argmax(cv_data['test-AUC-mean'])\n))","d1f3042c":"import shap\nshap.initjs()","12f806de":"explainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(df_train_features_extended) #here I use df instead of X, because I've used df.values before \n\n# visualize the first prediction's explanation\nshap.force_plot(explainer.expected_value, shap_values[0,:], df_train_features_extended.iloc[0,:]) #here I use df instead of X, because I've used df.values before ","91f24db5":"# create a SHAP dependence plot to show the effect of a single feature across the whole dataset\nshap.dependence_plot(\"d3_gold\", shap_values, df_train_features_extended)","2c4fc516":"# summarize the effects of all the features\nshap.summary_plot(shap_values, df_train_features_extended)","7870d13b":"model = CatBoostClassifier(iterations=400,random_seed=42,eval_metric='AUC',logging_level='Silent')\nmodel.fit(X, y)\n\ny_test_pred = model.predict_proba(X_test)[:, 1]\ndf_submission = pd.DataFrame({'radiant_win_prob': y_test_pred}, \n                                 index=df_test_features.index)\nsubmission_filename = 'catboost_{}.csv'.format(\n    datetime.datetime.now().strftime('%Y-%m-%d_%H-%M'))\ndf_submission.to_csv(submission_filename)\nprint('Submission saved to {}'.format(submission_filename))","1b46cae2":"df_submission.head() #just to check that everything allright ","6a0ab217":"Reproduce this to see great real time interactive graph! \nAnd if someone has idea how to save it and show in rendered kernel please let me know! ","03004542":"Reading data","3194560f":"## Submission","f5d9d4cd":"## General information\n\nIn this kernel I am implementing catboost and showing some methods of SHAP explainer.<br>\nFor EDA check [this](https:\/\/www.kaggle.com\/vchulski\/dota-2-eda-and-simple-models-comparing) out.","50d5e193":"Well, on CV we maybe need to increase number of iterations. ","22843d18":"## CatBoost implementation","ea3f20e3":"From graph I saw that best iteration was on 347 iteration with 0.8060119476 result on holdout set.\nPay attention you could also switch to logloss (on graph) - where learn line will be visible. ","350a5516":"I am really impressed by the abilities of CatBoost library and SHAP explainer.\nTower kills, deaths and gold are obviously strong features. \n\nWith this instrument you could add new features in very representative view. ","e34040d3":"Feel free to discuss anything on this kernel in comments and upvote if it was useful. ","a95ece05":"## SHAP explainer","efa70f73":"Read data from Yorko kernel","18ed3257":"Just as in my other [kernel](https:\/\/www.kaggle.com\/vchulski\/dota-2-eda-and-simple-models-comparing) on this competition for submission I use simple model without any hyperparameters. "}}