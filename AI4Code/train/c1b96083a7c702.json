{"cell_type":{"2a9082b5":"code","af82de8f":"code","8b76fa31":"code","0732ac34":"code","ec3f33ce":"code","716a23c8":"code","8bddf0cb":"code","0772b8b9":"code","8587b31d":"code","f8d0756f":"code","920c92df":"markdown","20c83a88":"markdown","c4bdd31b":"markdown","ef09ae51":"markdown","a8ac941b":"markdown","bfbe95f4":"markdown","fcaebe14":"markdown","cb9b2b59":"markdown","b19f3c92":"markdown"},"source":{"2a9082b5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","af82de8f":"from sklearn import preprocessing\n\nbattles = pd.read_csv('..\/input\/battles.csv')\npokemon = pd.read_csv('..\/input\/pokemon.csv')\ntest    = pd.read_csv('..\/input\/test.csv')\n\n# Descartamos el nombre de los pokemons. No los conozco. No me interesan.\npokemon = pokemon.drop(columns='Name', errors='ignore')\n\n# Transformamos ambos tipos de pokemon a una representaci\u00f3n dummie.\npokemon.loc[:, 'Type 1'] = pokemon.loc[:, 'Type 1'].fillna('None')\npokemon.loc[:, 'Type 2'] = pokemon.loc[:, 'Type 2'].fillna('None')\n\n# Mapeamos columna Legendary a int [0,1]\npokemon.Legendary  = pokemon.Legendary.astype(int)\n\n# Juntamos las dos tablas de pokemons.\ndata = pd.merge(battles, pokemon, left_on='First_pokemon' ,right_on='#')\ndata = pd.merge(data,    pokemon, left_on='Second_pokemon',right_on='#', suffixes=('_A','_B'))\ndata = data.sort_values(['battle_number'])\ndata = data.drop(columns=['#_A', '#_B'])\ndata = data.iloc[:, 3:]\n\ndata.head()","8b76fa31":"# Juntamos las dos tablas de pokemons.\ntout = pd.merge(test, pokemon, left_on='First_pokemon' ,right_on='#')\ntout = pd.merge(tout, pokemon, left_on='Second_pokemon',right_on='#', suffixes=('_A','_B'))\ntout = tout.sort_values(['battle_number'])\ntout = tout.drop(columns=['#_A', '#_B'])\ntout = tout.iloc[:, 3:]\n\ntout.head()","0732ac34":"from fastai.tabular import *\nfrom sklearn.model_selection import train_test_split\n\n# OJO: CAMBIA ESTE VALOR A 0.0 PARA TU SUBMISSION FINAL, y 0.3 PARA VALIDAR.\nTEST_SIZE = 0.01 # Valor desechable para contar con metrics del validation.\n\n# Selecci\u00f3n aleatoria de los indices de entrenamiento y prueba.\ntr_idx, ts_idx = train_test_split(range(len(battles)), test_size=TEST_SIZE)\n\n# Indicamos a la librer\u00eda el listado de variables categ\u00f3ricas.\ncat_names = ['Generation_A', 'Generation_B', 'Type 1_A', 'Type 1_B', 'Type 2_A', 'Type 2_B', 'Legendary_A', 'Legendary_B']\n\n# Indicamos a la librer\u00eda que categorice las variables categ\u00f3ricas\n# y normalice las variables continuas.\nprocs = [Categorify, Normalize]\n\n# Generamos el objeto que nos crear\u00e1 y suministrar\u00e1 los minibatches. Es importante fijar de antemano cu\u00e1l ser\u00e1 el conjunto de datos que\n# querremos predecir una vez el modelo est\u00e9 entrenado : test_df=tout. \ndb = TabularDataBunch.from_df(path='.', df=data, dep_var='Winner', valid_idx=ts_idx, procs=procs, test_df=tout, cat_names=cat_names, bs=1024)\n\n# Generamos un modelo sencillo con cuatro capas ocultas.\nlearn = tabular_learner(db, layers=[64, 32, 16, 8], metrics=accuracy)\n\n# E inspeccionamos el valor del learning-rate \u00f3ptimo.\nlearn.lr_find()\nlearn.recorder.plot()","ec3f33ce":"learn.fit_one_cycle(50, 1e-1)","716a23c8":"learn.recorder.plot_losses()\nplt.title('Training Loss vs Steps')","8bddf0cb":"# learn.lr_find()\n# learn.recorder.plot()\n# learn.fit_one_cycle(25, 1e-2)","0772b8b9":"# Obtenemos las predicciones para la tabla tout. \npreds, _ = learn.get_preds(ds_type=DatasetType.Test)\npreds = np.argmax(preds, axis=1).numpy()\n\n# Generamos el dataframe de subida.\nsubmission = pd.DataFrame(test.iloc[:, 0])\nsubmission['Winner'] = preds","8587b31d":"# Comprobamos que la tabla tenga la forma que buscamos.\nprint(submission.head())\n\n# y lo guardamos...\nsubmission.to_csv('.\/submission.csv', index=False)","f8d0756f":"from IPython.display import HTML\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe\ncreate_download_link(submission)","920c92df":"## FastAI Version\nVamos a utilizar la librer\u00eda de FastAI (https:\/\/docs.fast.ai\/) para entrenar a una red neuronal simple (*Multilayer Perceptron*) que nos dar\u00e1 un **accuracy aproximado del 98%** en unas pocas l\u00edneas de c\u00f3digo. Para comenzar, cargamos los datos y los preprocesamos.\n\nEl preprocesamiento incluye: \n* Eliminar columna con los nombres de los Pokemons.\n* Rellenar datos NaN de la columna de tipos.\n* Mapear la columna de Legendary a [0, 1]\n* Uni\u00f3n de la tabla de pokemons y batallas.\n\n\n","20c83a88":"Finalmente les comparto este snippet de c\u00f3digo encontrado por los foros de Kaggle, que directamente te genera un link de descarga para bajarte el fichero generado y subirlo t\u00fa mismo, sin necesidad de tener que hacer un commit del Kernel y reentrenarlo de nuevo.","c4bdd31b":"Si quisieramos seguir afinando el modelo, podr\u00edamos reducir el tama\u00f1o del *learning_rate* y continuar entrenando el modelo unas cuantas epochs m\u00e1s, siempre controlando que el *training_loss *y el *validation_loss* divergan. \n\n> Probando y probando y el overfitting controlando, un 98% se alcanza con poco sudor derramando.","ef09ae51":"Y ya estar\u00eda. Ahora a disfrutar cada d\u00eda con ese debate interno de querer posicionarte bien en la tabla de ranking a\u00fan cuando sabes que probablemente est\u00e9s subiendo una soluci\u00f3n con *overfitting*. \ud83c\udf34","a8ac941b":"Con el modelo ya entrenado, ya podemos pasar a generar nuestro fichero de predicciones y posicionarnos en la Leaderboard. **Recuerda utilizar todos tus datos durante el entrenamiento entrenamiento cuando quieras hacer una submission final.**","bfbe95f4":"Como puedes ver, con solo 50 epochs ya alcanzamos un nivel de **accuracy del 97.72%**, donde no parece que el overfitting est\u00e9 afectando a nuestro *validation_loss*.","fcaebe14":"Aparentemente, seg\u00fan se observa en la gr\u00e1fica anterior, tomar un valor del *learning-rate* sobre el orden de **1e-01** nos permitir\u00eda seguir reduciendo el loss. Por tanto, ya tenemos todo listo para dar comienzo al entrenamiento.","cb9b2b59":"E igualmente generamos la tabla de **test** que usaremos para generar las predicciones finales.","b19f3c92":"A partir de ah\u00ed comenzamos a generar nuestro modelo. La librer\u00eda de FastAI nos permite r\u00e1pidamente establecer determinados preprocesamiento de nuestros datos (i.e. *Normalizar* variables continuas, *Categorizar* variables discretas, etc). Adem\u00e1s, de manera autom\u00e1tica las variables categ\u00f3ricas contar\u00e1 con su propio embedding que ser\u00e1 optimizado durante el entrenamiento."}}