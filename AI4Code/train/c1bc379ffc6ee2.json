{"cell_type":{"a998082a":"code","3bd4ddb6":"code","4e99dca4":"code","d5a65520":"code","a77a2e72":"code","2abe4216":"code","d63b11ac":"code","e5c2228f":"code","e26c6b6f":"code","88bb0e58":"code","e7a81937":"code","c023ffdc":"code","ab1f893c":"code","b3a5ceb9":"code","5f6f5020":"code","84ac7111":"code","d430ae41":"code","adf2ca8e":"code","c62e05f6":"code","bbf8f625":"code","3e933f6f":"code","9bdb33db":"code","c1892fd8":"code","89001c56":"markdown","563a6349":"markdown","8e7345ac":"markdown","fa1f423c":"markdown","ab0eb436":"markdown"},"source":{"a998082a":"import os\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nimport torch.optim as optim\n\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid","3bd4ddb6":"# check if machine has gpu\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Running on\",device)","4e99dca4":"# data path that training set is located\npath = \"..\/input\/fruits\/fruits-360-original-size\/fruits-360-original-size\"\n# this joins the path + folder and each files e.g. 'fruits\/fruits-360\/Training\/Apple Braeburn\/115_100.jpg'\nfiles_training = glob(os.path.join(path,'Training', '*\/*.jpg'))\nnum_images = len(files_training)\nprint('Number of images in Training file:', num_images)","d5a65520":"# just to see how many images we have for each label, minimum one and average one, with nice printing style\n\nmin_images = 1000\nim_cnt = []\nclass_names = []\nprint('{:18s}'.format('class'), end='')\nprint('Count:')\nprint('-' * 24)\nfor folder in os.listdir(os.path.join(path, 'Training')):\n    folder_num = len(os.listdir(os.path.join(path,'Training',folder)))\n    im_cnt.append(folder_num)\n    class_names.append(folder)\n    print('{:20s}'.format(folder), end=' ')\n    print(folder_num)\n        \nnum_classes = len(class_names)\nprint(\"\\nMinumum images per category:\", np.min(im_cnt), 'Category:', class_names[im_cnt.index(np.min(im_cnt))])    \nprint('Average number of Images per Category: {:.0f}'.format(np.array(im_cnt).mean()))\nprint('Total number of classes: {}'.format(num_classes))","a77a2e72":"fruit_data = pd.DataFrame(data = im_cnt,index = class_names,columns=[\"image_number\"])\nfruit_data.head()\n\ntop_ten = fruit_data.sort_values(by=\"image_number\",ascending=False)[:10]\nbottom_ten = fruit_data.sort_values(by=\"image_number\",ascending=True)[:10]\n\nframes = [top_ten, bottom_ten]\nmerged_tens = pd.concat(frames)\n\nfrom sklearn.utils import shuffle\nmerged_tens = shuffle(merged_tens)\n\nimport seaborn as sns\nplt.figure(figsize = (12,8))\nchart = sns.barplot(x=merged_tens.index, y = merged_tens[\"image_number\"],data=merged_tens, palette=\"Accent\")\nchart.set_xticklabels(chart.get_xticklabels(), rotation=45)\nchart.set_ylabel(\"Number of Images\")\nplt.axhline(y=np.mean(im_cnt), color='r', linestyle='--',label = \"Average Number of Images\")\nplt.legend()\nplt.title(\"Number of Images for Top and Least 10 Fruits\")\nplt.show()","2abe4216":"# Just to guess pop_mean and pop_std\n\ntensor_transform = transforms.Compose([transforms.ToTensor()])\n\ntraining_data = ImageFolder(os.path.join(path, 'Training'), tensor_transform)\n\ndata_loader = torch.utils.data.DataLoader(training_data, batch_size=512, shuffle=True)\n\n\n# this part takes a bit long so I am using latest estimates\npop_mean = [0.684091,0.5786672,0.5038491]    # normally it was [] (empty)\npop_std = [0.30335397,0.35989153,0.3913597]\n\n# for i, data in tqdm(enumerate(data_loader, 0)):\n#     numpy_image = data[0].numpy()\n    \n#     batch_mean = np.mean(numpy_image, axis=(0,2,3))\n#     batch_std = np.std(numpy_image, axis=(0,2,3))\n    \n#     pop_mean.append(batch_mean)\n#     pop_std.append(batch_std)\n\n# pop_mean = np.array(pop_mean).mean(axis=0)\n# pop_std = np.array(pop_std).mean(axis=0)\n\n\nprint(pop_mean)\nprint(pop_std)","d63b11ac":"np.random.seed(123)\nshuffle = np.random.permutation(num_images)\n\n# split validation images\n\nsplit_val = int(num_images * 0.2)\nprint('Total number of images:', num_images)\nprint('Number images in validation set:',len(shuffle[:split_val]))\nprint('Number images in train set:',len(shuffle[split_val:]))","e5c2228f":"class FruitTrainDataset(Dataset):\n    def __init__(self, files, shuffle, split_val, class_names, transform=transforms.ToTensor()):\n        self.shuffle = shuffle\n        self.class_names = class_names\n        self.split_val = split_val\n        self.data = np.array([files[i] for i in shuffle[split_val:]])\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.data[idx])\n        name = self.data[idx].split('\/')[-2]\n        y = self.class_names.index(name)\n        img = self.transform(img)\n            \n        return img, y\n\nclass FruitValidDataset(Dataset):\n    def __init__(self, files, shuffle, split_val, class_names, transform=transforms.ToTensor()):\n        self.shuffle = shuffle\n        self.class_names = class_names\n        self.split_val = split_val\n        self.data = np.array([files[i] for i in shuffle[:split_val]])\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.data[idx])\n        name = self.data[idx].split('\/')[-2]\n        y = self.class_names.index(name)\n        img = self.transform(img)\n            \n        return img, y\n    \nclass FruitTestDataset(Dataset):\n    def __init__(self, path, class_names, transform=transforms.ToTensor()):\n        self.class_names = class_names\n        self.data = np.array(glob(os.path.join(path, '*\/*.jpg')))\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img = Image.open(self.data[idx])\n        name = self.data[idx].split('\/')[-2]\n        y = self.class_names.index(name)\n        img = self.transform(img)\n            \n        return img, y","e26c6b6f":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(pop_mean, pop_std) # These were the mean and standard deviations that we calculated earlier.\n    ]),\n    'Test': transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(pop_mean, pop_std) # These were the mean and standard deviations that we calculated earlier.\n    ]),\n    'valid': transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(pop_mean, pop_std) # These were the mean and standard deviations that we calculated earlier.\n    ])\n}\n\ntrain_dataset = FruitTrainDataset(files_training, shuffle, split_val, class_names, data_transforms['train'])\nvalid_dataset = FruitValidDataset(files_training, shuffle, split_val, class_names, data_transforms['valid'])\ntest_dataset = FruitTestDataset(\"..\/input\/fruits\/fruits-360\/\/Test\", class_names, transform=data_transforms['Test'])\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)","88bb0e58":"dataloaders = {'train': train_loader,\n              'valid': valid_loader,\n              'Test': test_loader}\ndataset_sizes = {\n    'train': len(train_dataset),\n    'valid': len(valid_dataset),\n    'Test': len(test_dataset)\n}","e7a81937":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    inp = pop_std * inp + pop_mean\n    inp = np.clip(inp, 0, 1)\n    plt.figure(figsize = (12,8))\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)","c023ffdc":"inputs, classes = next(iter(train_loader))\nout = make_grid(inputs)\n\ncats = ['' for x in range(len(classes))]\nfor i in range(len(classes)):\n    cats[i] = class_names[classes[i].item()]\n    \nimshow(out)\nprint(cats)","ab1f893c":"# just to start from the basic NN and to observe how does it perform on data\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__() # initialize the parent class methods\n        self.fc1 = nn.Linear(3*100*100, 64)\n        self.fc2 = nn.Linear(64, 64)\n        self.fc3 = nn.Linear(64, 64)\n        self.fc4 = nn.Linear(64, 131)\n        \n    def forward(self,x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        x = self.fc4(x)\n        \n        return F.log_softmax(x,dim=1)\n    \nnet = Net()\nprint(net)","b3a5ceb9":"# move network to GPU\nnet = Net().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.7)","5f6f5020":"# let's train the network\ndef train(net):\n    with open(\"model.log\", \"a\") as f:\n        for epoch in tqdm(range(20)):\n            print(\"epoch {}\".format(epoch))\n            running_loss = 0.0\n            correct = 0\n            total = 0\n\n            val_loss = 0.0\n            val_cor = 0\n            val_tot = 0\n\n            for i,data in enumerate(train_loader, 0):\n                # get the inputs; data is a list of [inputs, labels]\n                inputs, labels = data[0].to(device), data[1].to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward + backward + optimize\n                outputs = net(inputs.view(-1,3*100*100))\n\n                # in sample accuracy calculation\n                _, predicted = torch.max(outputs, 1) \n                a = predicted == labels\n                correct += np.count_nonzero(a.cpu())\n                total += len(a)\n                \n                # validaion accuracy calculation\n                val_data = next(iter(valid_loader))\n                val_inputs, val_labels = val_data[0].to(device), val_data[1].to(device)\n                val_outputs = net(val_inputs.view(-1,3*100*100))\n                _, val_predicted = torch.max(val_outputs, 1) \n                b = val_predicted == val_labels\n                val_cor += np.count_nonzero(b.cpu())\n                val_tot += len(b)\n                \n                #print(\"Validation accuracy\",val_cor\/val_tot)\n\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n                \n                running_loss += loss.item()\n                \n                val_loss = criterion(val_outputs, val_labels)\n                val_loss += val_loss.item()\n\n                if i % 20 == 19 :    # print every 20 mini-batches                  \n\n                    #print('[%d, %5d] loss: %.3f, in sample accuracy: %.3f, val_loss: %.3f, val accuracy : %.3f' %(epoch, i + 1, running_loss \/ 5, correct\/total,\n                    #                                                       val_loss \/ 5, val_cor\/val_tot))\n                    \n                    f.write(f\"{float(epoch)},{float(correct\/total)},{float(running_loss \/ 20)},{float(val_cor\/val_tot)},{float(val_loss \/ 20)}\\n\")\n                    \n                    running_loss = 0.0\n                    correct = 0\n                    total = 0\n\n                    val_loss = 0.0\n                    val_cor = 0\n                    val_tot = 0                   \n\n        print('Finished Training')\n    \ntrain(net)","84ac7111":"# to save the trained model\nPATH = \"fnn_net.pth\"\ntorch.save(net.state_dict(),PATH)","d430ae41":"model_data = pd.read_csv(\"model.log\",names = [\"epochs\",\"accuracy\",\"loss\",\"validation_accuracy\",\"validation_loss\"])\nmodel_data.head()","adf2ca8e":"fig, ax = plt.subplots(figsize = (16,8))\nax.set_xlabel('Epochs')\nax.set_ylabel('Loss')\nax.plot(model_data[\"loss\"], label = \"In Sample Loss\")\nax.plot(model_data[\"validation_loss\"], label = \"Validation Loss\")\nleg = ax.legend()","c62e05f6":"fig, ax = plt.subplots(figsize = (16,8))\nax.set_xlabel('Epochs')\nax.set_ylabel('Accuracy')\nax.plot(model_data[\"accuracy\"], label = \"In Sample Accuracy\")\nax.plot(model_data[\"validation_accuracy\"], label = \"Validation Accuracy\")\nleg = ax.legend()","bbf8f625":"# just to show how saved models can be load\n\nPATH = \"fnn_net.pth\"\nnet = Net().to(device)\nnet.load_state_dict(torch.load(PATH))","3e933f6f":"# Overal Accuracy\ndef test(net):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in tqdm(test_loader):\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = net(images.view(-1,3*100*100))\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the network on the test images: %d %%' % (\n        100 * correct \/ total))\n\ntest(net)","9bdb33db":"# class wise accuracy\nclass_correct = list(0. for i in range(131))\nclass_total = list(0. for i in range(131))\nwith torch.no_grad():\n    for data in tqdm(test_loader):\n        images, labels = data[0].to(device), data[1].to(device)\n        outputs = net(images.view(-1,3*100*100))\n        _, predicted = torch.max(outputs, 1)\n        c = (predicted == labels).squeeze()\n        \n        for i in range(len(labels)):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n\nfor i in range(131):\n    print('Accuracy of %5s : %2d %%' % (\n    class_names[i], 100 * class_correct[i] \/ class_total[i]))","c1892fd8":"height = [(100 * class_correct[i] \/ class_total[i]) for i in range(131)]\ncount = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nlabels = [\"0% - 10%\", \"10% - 20%\", \"20% - 30%\", \"30% - 40%\", \"40% - 50%\", \"50% - 60%\", \"60% - 70%\", \"70% - 80%\", \"80% - 90%\", \"90% - 100%\", \"100%\"]\n\nfor i in range(131):\n    group = height[i] \/10\n    count[int(group)] += 1\n\n    y_pos = np.arange(len(labels))\n\nplt.figure(figsize=(12,8))\nplt.barh(y_pos, count, color = \"skyblue\")\nplt.title('Number of Right Classified Fruits in Accuracy Range')\nplt.xlabel('Number of Classes')\nplt.ylabel('Accuracy Percentage Ranges')\nplt.yticks(y_pos, labels)\nplt.show()","89001c56":"Above plot is to just observe balance or imbalance of the dataset. It is a simple bar plot that shows the 20 classes. 10 of them are the ones which have the most number of images, rest is the ones which have the least number of images. It can be said that also by considering the rest 111 classes, we have a well-prepared almost balanced dataset.","563a6349":"Although GPU is enabled training takes more time than google colab which is around 20 minutes but here it took more than 1 hour. Even in my computer it took 25 minutes.","8e7345ac":"One of the simplest architectures that one can think. Some characteristics was set by experiment (number of hidden layers, node number for layers etc). For instance adding new hidden layer and increasing number of nodes didn't spawn better performance so this simple architecture was kept.","fa1f423c":"## FNN","ab0eb436":"## Data Preprocessing\n\nData preprocessing part is taken by this [notebook](https:\/\/www.kaggle.com\/jessewheeler\/my-first-kernel-cnn-from-scratch-with-pytorch) with tiny modifications."}}