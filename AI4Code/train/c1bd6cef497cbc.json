{"cell_type":{"2cd9ea1c":"code","b27751b7":"code","bbc113ad":"code","a68a7d3a":"code","e2b813e1":"code","8599b242":"code","dde323c0":"code","73e796ba":"code","f1ba8d14":"code","e4d45615":"code","cd60934f":"code","c152cf24":"code","4577ce75":"code","62685abb":"code","8e9cb7e6":"markdown","5a191aab":"markdown","27af28d6":"markdown","b367fc67":"markdown","19ecb17f":"markdown"},"source":{"2cd9ea1c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b27751b7":"#Keras Model Visualization\n\nfrom __future__ import absolute_import, division, print_function, unicode_literals\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom keras.applications.vgg16 import preprocess_input\n\nfrom keras import models\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, GlobalAveragePooling2D, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import SGD, Adam\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nbatchsize = 10\nNUM_EPOCHS = 10\n#img_width, img_height = 150, 150\n#for VGG 16 use 224 image size\n\nimg_width, img_height = 224, 224","bbc113ad":"## reading train and validation directories paths\ntrain_dir = '\/kaggle\/input\/furniture-detector\/img\/train'\nval_dir = '\/kaggle\/input\/furniture-detector\/img\/val'\n\n\n## train class paths \ntrain_bed_dir = os.path.join(train_dir, 'bed')\ntrain_chair_dir = os.path.join(train_dir, 'chair')\ntrain_sofa_dir = os.path.join(train_dir, 'sofa')\ntrain_swivelchair_dir = os.path.join(train_dir, 'swivelchair')\ntrain_table_dir = os.path.join(train_dir, 'table')\n\n## val class paths \nval_bed_dir =  os.path.join(val_dir, 'bed')\nval_chair_dir = os.path.join(val_dir, 'chair')\nval_sofa_dir = os.path.join(val_dir, 'sofa')\nval_swivelchair_dir = os.path.join(val_dir, 'swivelchair')\nval_table_dir = os.path.join(val_dir, 'table')","a68a7d3a":"num_bed_train = len(os.listdir(train_bed_dir))\nnum_chair_train = len(os.listdir(train_chair_dir))\nnum_sofa_train = len(os.listdir(train_sofa_dir))\nnum_swivelchair_train = len(os.listdir(train_swivelchair_dir))\nnum_table_train = len(os.listdir(train_table_dir))\n\nnum_bed_val = len(os.listdir(val_bed_dir))\nnum_chair_val = len(os.listdir(val_chair_dir))\nnum_sofa_val = len(os.listdir(val_sofa_dir))\nnum_swivelchair_val = len(os.listdir(val_swivelchair_dir))\nnum_table_val = len(os.listdir(val_table_dir))\n\nnum_train_images = num_bed_train + num_chair_train + num_sofa_train + num_swivelchair_train + num_table_train\nnum_val_images = num_bed_val + num_chair_val + num_sofa_val + num_swivelchair_val + num_table_val\nprint(num_train_images, num_val_images)","e2b813e1":"## data generator for train dataset\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function = preprocess_input,\n    rotation_range = 90,\n    horizontal_flip = True,\n    vertical_flip = True\n)\n\n## data generator for validation  dataset\nval_datagen = ImageDataGenerator(\n    preprocessing_function = preprocess_input,\n    rotation_range = 90,\n    horizontal_flip = True,\n    vertical_flip = True\n)","8599b242":"## apply train data generator on train data\ntrain_generator = train_datagen.flow_from_directory(train_dir,target_size=(img_height,img_width), batch_size=batchsize)\n\n## apply val data generator on validation data\nval_generator = val_datagen.flow_from_directory(val_dir,target_size=(img_height,img_width), batch_size=batchsize)","dde323c0":"# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\ndef plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","73e796ba":"base_model = VGG16(weights='imagenet',\n                   include_top=False,\n                   input_shape = (img_height, img_width,3)\n                   )","f1ba8d14":"len(base_model.layers)","e4d45615":"def build_model(base_model, dropout, fc_layers, num_classes):\n  for each_layer in base_model.layers:\n    each_layer.trainable = True\n  \n  x = base_model.output\n  x = GlobalAveragePooling2D()(x)\n  x = Flatten()(x)\n\n  # Fine-tune from this layer onwards\n  fine_tune_at = 100\n\n  ## freeze the bafore layers of fine tune at number in base model\n  for layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False\n\n  for fc in fc_layers:\n    x = Dense(units=fc, activation='relu')(x)\n    x = Dropout(dropout)(x)\n\n  ## output layer with softmax activation function\n  predictions = Dense(num_classes, activation='softmax')(x)\n\n  final_model = Model(inputs = base_model.input, outputs = predictions)\n  return final_model\n\n\nclass_list = ['bed', 'chair', 'sofa', 'swivelchair', 'table']\n## units for fully connected layers \nFC_LAYERS = [1024, 1024]\ndropout = 0.3\n\nmodel = build_model(base_model, dropout, FC_LAYERS, len(class_list))","cd60934f":"## compilation\nadam = Adam(learning_rate=0.00001)\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])","c152cf24":"model.summary()","4577ce75":"## train model\nhistory = model.fit(train_generator, \n                    epochs=NUM_EPOCHS, \n                    steps_per_epoch= num_train_images \/\/ batchsize, \n                    validation_data=val_generator,\n                    validation_steps = num_val_images \/\/ batchsize)","62685abb":"from keras.preprocessing import image\nimport matplotlib.pyplot as plt\nimport cv2\n# from google.colab.patches import cv2_imshow\n%matplotlib inline\n\nimg_path = '..\/input\/furniture-detector\/img\/val\/bed\/00000901.jpg'\n#img_path = 'furniture_images\/test\/bed\/00000876trainbed.jpg'\n#img_path = 'furniture_images\/test\/sofa\/00000803testsofa.jpg'\nimg = image.load_img(img_path, target_size=(img_height, img_width))\nimg_tensor = image.img_to_array(img)\nimg_tensor = np.expand_dims(img_tensor, axis=0)\nimg_tensor = preprocess_input(img_tensor)\n\nfeaturemap = model.predict(img_tensor)\nindex = np.argmax(featuremap)\nprint(class_list[index])\nplt.imshow(img)\n# plt.imshow(featuremap)\n# plt.imshow(img_tensor[0])\n# print (img_tensor.shape)","8e9cb7e6":"## creating data generator","5a191aab":"## build VGG16 model as a base model","27af28d6":"### Count all categories images","b367fc67":"## Prediction","19ecb17f":"## Importing nucessary libraries"}}