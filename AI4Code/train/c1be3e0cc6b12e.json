{"cell_type":{"75d021c7":"code","37cbe26d":"code","f8174d0f":"code","72b0d784":"code","38983fd5":"code","5db282ba":"code","67e1ec57":"code","449e4c42":"code","00ba3690":"code","2767a779":"code","c445ad95":"code","b8b620bb":"code","c060514d":"code","d38653a8":"code","ca4093f9":"code","746deb53":"code","08046bcf":"code","093441c5":"code","f330707c":"code","f2399e4b":"code","e64f39ad":"code","deff2f17":"code","59700df3":"code","708a6bae":"code","b2125cbd":"code","0022d942":"code","2ad137b7":"markdown","f9d2c28a":"markdown","a10a2117":"markdown","62c8d28d":"markdown","732e29cc":"markdown","2dc3cd0d":"markdown","016902a2":"markdown","f111ddba":"markdown","eac3f9d3":"markdown","61d39de6":"markdown"},"source":{"75d021c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","37cbe26d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\nimport graphviz\nimport pydotplus\nfrom plotly import tools\nimport matplotlib.pyplot as plt\nimport matplotlib.image as pltimg\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix,classification_report,roc_curve,accuracy_score,auc\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n!pip install pydotplus","f8174d0f":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","72b0d784":"print (df)","38983fd5":"print (df.describe())","5db282ba":"## renomeando as colunas:\ncol=['n_pregnant','glucose_conc','bp','skin_len','insulin','bmi','pedigree_fun','age','Output']\ndf.columns=col\ndf.head()","67e1ec57":"fig, ax = plt.subplots(4,2, figsize=(16,16))\nsns.distplot(df.age, bins = 20, ax=ax[0,0]) \nsns.distplot(df.n_pregnant, bins = 20, ax=ax[0,1]) \nsns.distplot(df.glucose_conc, bins = 20, ax=ax[1,0]) \nsns.distplot(df.bp, bins = 20, ax=ax[1,1]) \nsns.distplot(df.skin_len, bins = 20, ax=ax[2,0])\nsns.distplot(df.insulin, bins = 20, ax=ax[2,1])\nsns.distplot(df.pedigree_fun, bins = 20, ax=ax[3,0]) \nsns.distplot(df.bmi, bins = 20, ax=ax[3,1]) ","449e4c42":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nX = df.iloc[:, :-1]\ny = df.iloc[:, -1]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)","00ba3690":"corr=df.corr()\n\nsns.set(font_scale=1.15)\nplt.figure(figsize=(14, 10))\n\nsns.heatmap(corr, vmax=.8, linewidths=0.01,\n            square=True,annot=True,cmap='YlGnBu',linecolor=\"black\")\nplt.title('Correlation between features');","2767a779":"DT = DecisionTreeClassifier()","c445ad95":"## treino e teste\nDT.fit(X_train, y_train)\ny_pred = DT.predict(X_test)","b8b620bb":"data = tree.export_graphviz(DT, out_file=None, feature_names=features)\ngraph = pydotplus.graph_from_dot_data(data)\ngraph.write_png('mydecisiontree.png')\n\nimg=pltimg.imread('mydecisiontree.png')\nimgplot = plt.imshow(img)\nplt.show()","c060514d":"#Acur\u00e1cia\nprint(\"Acur\u00e1cia \", DT.score(X_test, y_test)*100)","d38653a8":"#Resultado\nsns.set(font_scale=1.5)\ncm = confusion_matrix(y_pred, y_test)\nsns.heatmap(cm, annot=True, fmt='g')\nplt.show()","ca4093f9":"X = df.drop(['Output'], 1)\ny = df['Output']","746deb53":"x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)","08046bcf":"std = StandardScaler()\nx_train = std.fit_transform(x_train)\nx_test = std.transform(x_test)","093441c5":"model=SVC(kernel='rbf')\nmodel.fit(x_train,y_train)","f330707c":"y_pred=model.predict(x_test)","f2399e4b":"accuracy_score(y_test,y_pred)*100","e64f39ad":"confusion_matrix(y_test,y_pred)","deff2f17":"print(classification_report(y_test,y_pred))","59700df3":"clf = KNeighborsClassifier(n_neighbors=3) \nclf.fit(x_train,y_train)  \nprint(clf.score(x_test,y_test))","708a6bae":"y_pred=clf.predict(x_test)\naccuracy_score(y_test,y_pred)*100","b2125cbd":"confusion_matrix(y_test,y_pred)","0022d942":"print(classification_report(y_test,y_pred))","2ad137b7":"carregando a base de dados:","f9d2c28a":"**Visualizando os dados:**","a10a2117":"**KNN**","62c8d28d":"**SVM**","732e29cc":"**Regress\u00e3o Linear**","2dc3cd0d":"Carregando as bibliotecas","016902a2":"**\u00c1rvore de Decis\u00e3o**","f111ddba":"separando o treino do teste:","eac3f9d3":"fazendo o \"summary\":","61d39de6":"**MODELOS:**"}}