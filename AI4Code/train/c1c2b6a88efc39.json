{"cell_type":{"c0d13596":"code","96221ba6":"code","1aa59703":"code","0b0a4541":"code","4dd6723b":"code","0a3a47ae":"code","164b8a50":"code","afa5edb9":"code","60b0036b":"code","19cffe19":"code","ef43ab3b":"code","9264ac2f":"code","040c4a50":"code","b42959eb":"code","ff849fa8":"code","030bb70d":"code","c894cbcb":"markdown","e6da0826":"markdown","53292002":"markdown","9e48b6ac":"markdown","faa9f123":"markdown","8aadaaaf":"markdown","79a9f476":"markdown","6d8b94f4":"markdown","eae87e1c":"markdown","518a3af8":"markdown","a9f2d03a":"markdown","73f942a1":"markdown","6c40bfa9":"markdown","7f8fcce4":"markdown","583a6f59":"markdown","f956bf19":"markdown","8fee0c7c":"markdown","b50ca360":"markdown"},"source":{"c0d13596":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#NumPy provides an efficient interface to store and operate on dense data buffers.\nimport numpy as np # linear algebra\n#Pandas is a newer package built on top of NumPy, and provides an efficient implementation of a DataFrame.\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom  xgboost import XGBClassifier\nfrom scipy import stats\nfrom sklearn import metrics\nfrom catboost import CatBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#This module provides a portable way of using operating system dependent functionality.\nimport os\n#The method walk() generates the file names in a directory tree by walking the tree either top-down or bottom-up.\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","96221ba6":"data=pd.read_csv(\"\/kaggle\/input\/hypothyroid\/hypothyroid.csv\")\ndata.head()","1aa59703":"data=data.rename(columns={data.columns[0]:\"target\"})","0b0a4541":"data.isna().sum()","4dd6723b":"for column in data.columns:\n    listOfValues=set(data[column])\n    print(column,\": \",listOfValues)","0a3a47ae":"data=data.replace({\"?\":np.NAN})\ndata.isna().sum()","164b8a50":"del data[\"TBG\"]","afa5edb9":"data.dropna(axis = 0, thresh = 21, inplace = True)\ndata.isna().sum()","60b0036b":"data = data.replace({\"t\":1,\"f\":0, \"y\":1, \"n\":0, \"hypothyroid\":1, \"negative\":0, \"F\":1, \"M\":0})\ndisplay(data.dtypes)","19cffe19":"cols = data.columns[data.dtypes.eq('object')]\ndata[cols] = data[cols].apply(pd.to_numeric, errors='coerce')\n\ndata = data.interpolate(method = 'spline', order = 4)\ndata.isna().sum()","ef43ab3b":"data[['Age','TSH','T3','TT4','T4U','FTI']].boxplot()","9264ac2f":"def fdiscretizer(attribute,dataframe):\n    enc = LabelEncoder()\n    dataframe[attribute] = pd.qcut(dataframe[attribute], 10, duplicates='drop')\n    dataframe[attribute] = enc.fit_transform(dataframe[attribute])\n    dataframe = dataframe.convert_dtypes(convert_integer=True)\n\nfdiscretizer('Age',data)\nfdiscretizer('TSH',data)\nfdiscretizer('T3',data)\nfdiscretizer('TT4',data)\nfdiscretizer('T4U',data)\nfdiscretizer('FTI',data)\n\ndisplay(data.head())","040c4a50":"corr_values = abs(data[data.columns[0:]].corr()['target'][:])\ncorr_values = corr_values.drop('target')\ncorr_values = corr_values[corr_values > 0.10]\ncorr_values","b42959eb":"def holdout(dataframe):\n  x = dataframe[corr_values.index]\n  y = dataframe['target']\n  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33) \n  return X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = holdout(data)","ff849fa8":"classifiers = {\n    \"XGBClassifier\" : XGBClassifier(learning_rate=0.01),\n    \"CatBoostClassifier\" : CatBoostClassifier(max_depth=3,verbose=0),\n    \"Nearest Neighbors\" : KNeighborsClassifier(3),\n    \"Decision Tree\" : DecisionTreeClassifier(max_depth=5),\n    \"Naive Bayes\" : GaussianNB()\n}","030bb70d":"def classification(classifiers):\n    # Creo un dataframe per visualizzare i risultati calcolati\n  res = pd.DataFrame(columns=[\"Classifier\", \n                                \"Accuracy\", \n                                \"Precision\", \n                                \"Recall\", \n                                \"FScore\"])\n  for name, clf in classifiers.items():\n            clf.fit(X_train, y_train)\n            y_pred = clf.predict(X_test)\n            pr, rc, fs, sup = metrics.precision_recall_fscore_support(y_test, y_pred, average='macro')\n            res = res.append({\"Classifier\": name,\"Accuracy\": round(metrics.accuracy_score(y_test, y_pred), 4),\n                              \"Precision\": round(pr, 4), \"Recall\":round(rc, 4), \"FScore\":round(fs, 4)}, ignore_index=True)\n                 \n  res.set_index(\"Accuracy\", inplace=True)\n  res.sort_values(by=\"Accuracy\", ascending=False, inplace=True)   \n  return res\n\ndisplay(classification(classifiers))","c894cbcb":"**Si procede con l'addestramento dei classificatori e si osservano i risultati:**","e6da0826":"**E' stato verificato che non sono presenti celle vuote o con il valore nan**","53292002":"**Ora che la fase di preelaborazione \u00e8 terminata si deve procedere con l'addestramento dei classificatori. A tal fine sar\u00e0 necessario dividere le tuple in due insiemi: l'insieme di addestramento e l'insieme di test.**","9e48b6ac":"**Grazie alla libreria Pandas, \u00e8 possibile utilizzare le classi DataFrame e Series. DataFrames are essentially multidimensional arrays with attached row and column labels, and often with heterogeneous types and\/or missing data.**","faa9f123":"**I valori numerici di questi attributi possono essere discretizzati:**","8aadaaaf":"**Convertendo gli attributi di tipo 'object' in attributi numerici \u00e8 possibile applicare l'interpolazione:**","79a9f476":"**E' possibile eliminare le righe con troppi campi vuoti:**","6d8b94f4":"**Analizzando l'insieme di valori assumibili da ogni attributo si pu\u00f2 notare che sono presenti diversi attributi categoriali. Questi andranno codificati in attributi numerici per permettere ai classificatori di funzionare al meglio. Gli attributi numerici del dataset presentano troppi valori, motivo per cui sarebbe opportuno discretizarli. Inoltre \u00e8 presente il valore '?', questo indica che il valore del campo \u00e8 sconosciuto, \u00e8 consigliabile sostituirlo con il valore nan:**","eae87e1c":"**Moltissime celle presentano il valore nan, in particolare l'attributo TBG ne presenta troppe, \u00e8 il caso di eliminare questo attributo:**","518a3af8":"**I classificatori utilizzati verranno espressi in un dizionario:**","a9f2d03a":"**Dato un dataset contenente alcune informazioni riguardanti dei pazienti di un ospedale che hanno fatto delle analisi per capire se siano ammalati di ipotiroidismo, si vogliono analizzare tali dati e ricavare un modello prevesivo in grado di distinguere chi sia affetto da tale sindrome e chi no**","73f942a1":"**Sono state conservate solo le tuple che presentano minimo 21 valori, ma sono ancora presenti molti campi vuoti. Per riempirli \u00e8 possibile utilizzare l'interpolazione spline. Ma prima di fare ci\u00f2 bisogna convertire gli attributi categoriali in attributi numerici:**","6c40bfa9":"**Prima di addestrare un classificatore \u00e8 necessario effettuare una pre-elaborazione del dataset dove si andranno a correggere eventuali dati inconsistenti, mancanti o inaccurati**","7f8fcce4":"**L'ultima cosa da fare consiste nell'andare ad individuare eventuali outliers:**","583a6f59":"**Nonostante la sostituzione dei valori nan con dei valori ottenuti per interpolazione, i classificatori risultano essere molto accurati.**","f956bf19":"**A comma-separated values (csv) file is returned as two-dimensional data structure with labeled axes.**","8fee0c7c":"**E' possibile notare come l'attributo Unnamed presenta i risultati delle analisi, \u00e8 l'attributo del dataset che indica chi \u00e8 malato e chi no. E' il caso di dare un nome diverso a questo attributo:**","b50ca360":"**Questi risultano essere gli attributi pi\u00f9 correlati alla variabile target, verranno utilizzati per addestrare i classificatori.**"}}