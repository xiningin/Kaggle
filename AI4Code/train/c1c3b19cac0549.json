{"cell_type":{"01973188":"code","8363792d":"code","0631199d":"code","f9f06358":"code","5a50ffe5":"code","75c70851":"code","26f6d74a":"code","c1f205a3":"code","74b4a1d7":"code","30858a2d":"code","d324ca3e":"code","0eeacdd3":"code","b3776c99":"code","0ad59de4":"code","1f33f07d":"code","21917e1d":"code","9d10828b":"code","44bbda83":"code","beeb3eee":"code","c826ec07":"code","1ffef8b5":"code","2d77c205":"code","30fe6bc9":"code","9101d14b":"code","d8be1b76":"code","7bafa01a":"code","533ae551":"markdown"},"source":{"01973188":"\n!pip install fastai","8363792d":"# from google.colab import files\nimport time\nimport sys\nimport os\nimport time\nimport math\nimport torch\nfrom  torch import nn\nimport numpy as np\nfrom torch.utils.data import Dataset,DataLoader\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms\n\nfrom torchvision.io import read_image\nfrom skimage.color import rgb2lab,lab2rgb\nfrom PIL import Image\nimport torchvision.transforms.functional as TF\nfrom tqdm.notebook import tqdm","0631199d":"STARTING_TIME=time.time()\nprint(f\"starting time is {STARTING_TIME} \")","f9f06358":"# from google.colab import drive\n\n# drive.mount('\/content\/gdrive')","5a50ffe5":"if not os.path.exists('outputs'):\n  os.mkdir('outputs')","75c70851":"\n# !git clone https:\/\/github.com\/Rujengelal\/major-project-main.git\n\nfrom fastai.data.external import untar_data, URLs\ncoco_path = untar_data(URLs.COCO_SAMPLE)\ncoco_path = str(coco_path) + \"\/train_sample\"\nuse_colab = True\n","26f6d74a":"# # memory footprint support libraries\/code\n# !ln -sf \/opt\/bin\/nvidia-smi \/usr\/bin\/nvidia-smi\n# !pip install gputil\n# !pip install psutil\n# !pip install humanize\n\n# import psutil\n# import humanize\n# import os\n# import GPUtil as GPU\n\n# GPUs = GPU.getGPUs()\n# # XXX: only one GPU on Colab and isn\u2019t guaranteed\n# gpu = GPUs[0]\n# def printm():\n#     process = psutil.Process(os.getpid())\n#     print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n#     print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n# # printm()","c1f205a3":"RECORDS=300\nTRAIN_SPLIT=.8\nTEST_SPLIT=1-TRAIN_SPLIT\nPAST_METRICS_DIRECTORY='..\/input\/past-metrics'\n\nif not use_colab:\n  FOLDER_DIR='major-project-main\/testing_image'\nelse:\n  FOLDER_DIR=coco_path\n\nimg_files_list=os.listdir(f\"{FOLDER_DIR}\")\n\n\nRECORDS=RECORDS if RECORDS else len(img_files_list)\n\n#randomize the files\nnp.random.shuffle(img_files_list)\n\ntrain_data_paths=img_files_list[:math.floor(RECORDS*TRAIN_SPLIT)]\ntest_data_paths=img_files_list[math.floor(RECORDS*TRAIN_SPLIT)+1:RECORDS+1]\ntrain_data_paths=[os.path.join(FOLDER_DIR,path) for path in train_data_paths]\ntest_data_paths=[os.path.join(FOLDER_DIR,path) for path in test_data_paths]\n\nif os.path.exists(f'{PAST_METRICS_DIRECTORY}\/img_lists.pth'):\n    print(\"Image files path exists\")\n    f_lists=torch.load(f'{PAST_METRICS_DIRECTORY}\/img_lists.pth')\n    train_data_paths=f_lists['train']\n    test_data_paths=f_lists['test']\n#     print(train_data_paths)\nelse:\n    print(\"Image files path doesnt exist\")\n    torch.save({'train':train_data_paths,\n               'test':test_data_paths},'img_lists.pth')\n    \n\nBATCH_NUMBERS=len(train_data_paths)\n\nprint(BATCH_NUMBERS,len(test_data_paths))\n\n","74b4a1d7":"class AverageMeter:\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.count, self.avg, self.sum = [0.] * 3\n    \n    def update(self, val, count=1):\n        self.count += count\n        self.sum += count * val\n        self.avg = self.sum \/ self.count\ndef lab_to_rgb(L, ab):\n    \"\"\"\n    Takes a batch of images\n    \"\"\"\n    \n    L = (L ) * 100.\n    ab = ab * 128.\n    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n    rgb_imgs = []\n    for img in Lab:\n        img_rgb = lab2rgb(img)\n        rgb_imgs.append(img_rgb)\n    return np.stack(rgb_imgs, axis=0)\n\n\ndef visualize(model, data, save=True):\n    model.eval()\n    with torch.no_grad():\n        L=data['L']\n        predict=model(L.to(device))\n        fake_color = predict.cpu()\n        real_color = data['AB']\n        # print(data['AB'].is_cuda)\n        L = L.cpu()\n        fake_imgs = lab_to_rgb(L, fake_color)\n        real_imgs = lab_to_rgb(L, real_color)\n        fig = plt.figure(figsize=(15, 8))\n        for i in range(5):\n            ax = plt.subplot(3, 5, i + 1)\n            ax.imshow(L[i][0].cpu(), cmap='gray')\n            ax.axis(\"off\")\n            ax = plt.subplot(3, 5, i + 1 + 5)\n            ax.imshow(fake_imgs[i])\n            ax.axis(\"off\")\n            ax = plt.subplot(3, 5, i + 1 + 10)\n            ax.imshow(real_imgs[i])\n            ax.axis(\"off\")\n        plt.show()\n        if save:\n            fig.savefig(f\"outputs\/colorization_{time.time()}.png\")\n        ","30858a2d":"class ColoredImageDataset(Dataset):\n    def __init__(self,paths,transforms=None):\n        super(ColoredImageDataset,self).__init__()\n        self.paths=paths\n        self.transforms=transforms\n\n        \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self,idx):\n        img=Image.open(self.paths[idx]).convert('RGB')\n#         img=read_image(self.paths[idx])\n        lab=rgb2lab(np.array(img)).astype(\"float32\")\n#         img=transforms.ToTensor()(img)#Can also use img=torch.from_numpy(img)\n        lab=transforms.ToTensor()(lab)\n    \n    \n        if self.transforms:\n#             img=self.transforms(img)\n            lab=self.transforms(lab)\n\n        \n        L=lab[0].unsqueeze(0)\/100\n        AB=lab[1:]\/128\n        return {'L':L,\"AB\":AB}\n    \n","d324ca3e":"IMG_SIZE=256\n\ntrain_dataset=ColoredImageDataset(train_data_paths,transforms.Resize((IMG_SIZE,IMG_SIZE)))\ntest_dataset=ColoredImageDataset(test_data_paths,transforms.Resize((IMG_SIZE,IMG_SIZE)))\n","0eeacdd3":"BATCH_SIZE=16\n\ntrain_data=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,pin_memory=True,num_workers=2)\ntest_data=DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True,pin_memory=True,num_workers=2)\n\ndata=next(iter(train_data))\n# print(data)\ntorch.cat((data[\"L\"],data[\"AB\"]),dim=1).shape\nprint(len(train_data),len(test_data))","b3776c99":"\ndata=next(iter(train_data))\nprint(data['L'].shape)\nfig=plt.figure()\ndata=lab_to_rgb(data['L'],data['AB'])\nfor i in range(8):\n    fig.add_subplot(3,3,i+1)\n\n    plt.imshow(data[i])\n# plt.imshow(test_dataset[1].permute(1,2,0))#permute rearranges the order of elements a desired\n\n","0ad59de4":"# class Generator(nn.Module):\n#     def __init__(self):\n#         super(Generator,self).__init__()\n#         pass\n#     def forward(self):\n#         pass","1f33f07d":"# class Discriminator(nn.Module):\n#     def __init__(self,img_dim):\n#         super(Discriminator,self).__init__()\n#         self.disc=nn.Sequential(\n#         nn.Linear(img_dim,128)\n# #         nn.LeakyReLU()\n#         nn.Linear(128,1)\n        \n#         )\n#     def forward(self):\n#         pass","21917e1d":"\n\n\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass UNET(nn.Module):\n    def __init__(\n            self, in_channels=3, out_channels=1, features=[64, 128, 256],\n    ):\n        super(UNET, self).__init__()\n        self.ups = nn.ModuleList()\n        self.downs = nn.ModuleList()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Down part of UNET\n        for feature in features:\n            self.downs.append(DoubleConv(in_channels, feature))\n            in_channels = feature\n\n        # Up part of UNET\n        for feature in reversed(features):\n            self.ups.append(\n                nn.ConvTranspose2d(\n                    feature*2, feature, kernel_size=2, stride=2,\n                )\n            )\n            self.ups.append(DoubleConv(feature*2, feature))\n\n        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n\n    def forward(self, x):\n        skip_connections = []\n\n        for down in self.downs:\n            x = down(x)\n            skip_connections.append(x)\n            x = self.pool(x)\n\n        x = self.bottleneck(x)\n        skip_connections = skip_connections[::-1]\n\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip_connection = skip_connections[idx\/\/2]\n\n            if x.shape != skip_connection.shape:\n                x = TF.resize(x, size=skip_connection.shape[2:])\n\n            concat_skip = torch.cat((skip_connection, x), dim=1)\n            x = self.ups[idx+1](concat_skip)\n\n        return nn.Tanh()(self.final_conv(x))\n","9d10828b":"if not True:\n  device = xm.xla_device()\n\nelse:\n  device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","44bbda83":"class UnetBlock(nn.Module):\n    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n                 innermost=False, outermost=False):\n        super().__init__()\n        self.outermost = outermost\n        if input_c is None: input_c = nf\n        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n                             stride=2, padding=1, bias=False)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = nn.BatchNorm2d(ni)\n        uprelu = nn.ReLU(True)\n        upnorm = nn.BatchNorm2d(nf)\n        \n        if outermost:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n            if dropout: up += [nn.Dropout(0.5)]\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n    \n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\nclass Unet2(nn.Module):\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n        super().__init__()\n        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n        for _ in range(n_down - 5):\n            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n        out_filters = num_filters * 8\n        for _ in range(3):\n            unet_block = UnetBlock(out_filters \/\/ 2, out_filters, submodule=unet_block)\n            out_filters \/\/= 2\n        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n    \n    def forward(self, x):\n        return self.model(x)","beeb3eee":"# from fastai.vision.learner import create_body\n# from torchvision.models.resnet import resnet18\n# from fastai.vision.models.unet import DynamicUnet\n# def build_res_unet(n_input=1, n_output=2, size=256):\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n#     net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n#     return net_G","c826ec07":"        \nclass Upsample(nn.Module):\n\n  def __init__(self, scale_factor=2, mode='nearest'):\n      super(Upsample, self).__init__()\n      self.interp = nn.functional.interpolate\n      self.scale_factor = scale_factor\n      self.mode = mode\n      \n  def forward(self, x):\n      x = self.interp(x, scale_factor=self.scale_factor, mode=self.mode)\n      return x\n   \nclass ColorCNN_v1(nn.Module):\n  def __init__(self, lab_version):\n      super(ColorCNN_v1, self).__init__()\n\n      self.relu = nn.ReLU()\n      \n      # if lab_version == 1:\n      #   print('hello')\n      #   self.final = nn.Tanh()\n      # elif lab_version == 2:\n      #   self.final = nn.Sigmoid()\n      self.final = nn.Tanh()\n      \n      self.upsampling = Upsample(scale_factor=2, mode='nearest')\n      \n      self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(3,3), stride=1, padding=1, bias=True)\n      self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=2, padding=1, bias=True)\n      self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=1, padding=1, bias=True)\n      self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=2, padding=1, bias=True)\n      self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=1, padding=1, bias=True)\n      self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=(3,3), stride=2, padding=1, bias=True)\n      self.conv7 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), stride=1, padding=1, bias=True)\n      self.conv8 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=(3,3), stride=1, padding=1, bias=True)\n      self.conv9 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(3,3), stride=1, padding=1, bias=True)\n      self.conv10 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3), stride=1, padding=1, bias=True)\n      self.conv11 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(3,3), stride=1, padding=1, bias=True)\n      self.conv12 = nn.Conv2d(in_channels=32, out_channels=2, kernel_size=(3,3), stride=1, padding=1, bias=True)\n\n      self.color = nn.Sequential(\n          self.conv1,\n          self.relu,\n          self.conv2,\n          self.relu,\n          self.conv3,\n          self.relu,\n          self.conv4,\n          self.relu,\n          self.conv5,\n          self.relu,\n          self.conv6,\n          self.relu,\n          self.conv7,\n          self.relu,\n          self.conv8,\n          self.relu,\n          self.conv9,\n          self.relu,\n          self.upsampling,\n          self.conv10,\n          self.relu,\n          self.upsampling,\n          self.conv11,\n          self.relu,\n          self.conv12,\n          self.final,\n          self.upsampling\n      )\n  def forward(self, x):\n      return self.color(x)","1ffef8b5":"# printm()\n# torch.cuda.empty_cache()\nmodel=UNET(in_channels=1,out_channels=2).to(device)\n# model=Unet2(input_c=1, output_c=2, n_down=8, num_filters=64).to(device)\n# model= build_res_unet(n_input=1, n_output=2, size=256)\n\n# printm()\n# print(model)\n\n# optimizer=torch.optim.SGD(model.parameters(),1e-2)\noptimizer=torch.optim.Adam(model.parameters(),3e-4)\n# loss_func=nn.BCEWithLogitsLoss()\nloss_func=nn.MSELoss()\nloss_func=nn.L1Loss()\n\n\n\n\n","2d77c205":"# model=Unet2(input_c=1, output_c=2, n_down=8, num_filters=64).to(device)\n# optimizer=torch.optim.SGD(model.parameters(),1e-2,0.5)\n","30fe6bc9":"\nLOAD_PREV_CHECKPOINT=True\nif LOAD_PREV_CHECKPOINT:\n  if os.path.exists(f'{PAST_METRICS_DIRECTORY}\/checkpoints.pth'):\n    print(\"Loading checkpoint\")\n    checkpoints=torch.load(f'{PAST_METRICS_DIRECTORY}\/checkpoints.pth',map_location=torch.device(device))\n    model.load_state_dict(checkpoints['model'])\n    optimizer.load_state_dict(checkpoints['optimizer'])\n  else:\n    print(\"No checkpoints saved\")\nelse:\n  print(\"Not loading previous checkpoints\")","9101d14b":"import csv\nimport shutil\ndef train_loop(dataloader,model,optimizer,loss_func,epoch,save_checkpoints=True):\n\n    model.train()\n    avg_meter=AverageMeter()\n\n    for batch,data in enumerate(tqdm(dataloader)):\n        L,AB=data['L'],data['AB']\n        L=L.to(device)\n        AB=AB.to(device)\n        # print(L.shape)\n\n        prediction=model(L)\n\n\n        loss=loss_func(prediction,AB)\n        optimizer.zero_grad()\n\n        \n        loss.backward()\n\n        optimizer.step()\n        avg_meter.update(loss.item())\n        if (batch%BATCH_NUMBERS==0):\n            print(f\"Training Epoch | Batch {epoch+1} | {batch+1} completed with loss {loss.item()} time {time.time()}\")\n            visualize(model,data,True)\n            if save_checkpoints:\n                checkpoint={\n                    \"epochs\":epoch,\n                    \"model\":model.state_dict(),\n                    \"optimizer\":optimizer.state_dict()\n                }\n                torch.save(checkpoint,f'checkpoints.pth')\n#                 shutil.copy('metrics.csv','\/content\/gdrive\/MyDrive\/Major project files')\n                \n            # printm()\n        \n    return avg_meter\n        \ndef test_loop(dataloader,model,loss_func,epoch):\n    model.eval()\n    avg_meter=AverageMeter()\n    \n    size=len(dataloader.dataset)\n    batch_size=len(dataloader)\n    total_loss,correct=0,0\n    \n    with torch.no_grad():\n        for data in tqdm(dataloader):\n            L,AB=data['L'],data['AB']\n            L=L.to(device)\n            AB=AB.to(device)\n            prediction=model(L)\n            loss=loss_func(prediction,AB)\n            avg_meter.update(loss.item())\n            # print(f\"Testing Epoch {epoch+1} completed with loss {loss.item()}\")\n    # printm()\n    return avg_meter\n\nfieldnames=['epoch','train loss','test loss']\nif not os.path.exists(f'{PAST_METRICS_DIRECTORY}\/metrics.csv'):\n  print('Past metrics')\n  with open(f'metrics.csv','w') as f:\n    writer=csv.DictWriter(f,fieldnames=fieldnames)\n    writer.writeheader()\n  f.close()\n\nelse:\n  shutil.copy(f'{PAST_METRICS_DIRECTORY}\/metrics.csv','.\/')\n\nfor epoch in range(1,50):        \n  \n  Lm1=train_loop(train_data,model,optimizer,loss_func,epoch,True)\n  Lm2=test_loop(test_data,model,loss_func,epoch)\n  with open(f'metrics.csv','a') as f:\n    writer=csv.DictWriter(f,fieldnames=fieldnames)\n    writer.writerow({'epoch':epoch,'train loss':Lm1.avg,'test loss':Lm2.avg})\n  f.close()\n\n# model(torch.rand(1,1,512,512)).shape\n","d8be1b76":"data=next(iter(train_data))\nvisualize(model,data,True)","7bafa01a":"ENDING_TIME=time.time()\nprint(f'Total time taken is {-(STARTING_TIME-ENDING_TIME)}')","533ae551":"### Utility functions"}}