{"cell_type":{"a85b8d91":"code","bf134345":"code","a7d32825":"code","39c0ef3b":"code","b80f85c8":"code","8fbbf969":"code","4d09aa81":"code","79926fec":"code","0effeb69":"code","d980f737":"code","56c965b0":"code","6dd8c4ae":"code","add2e71c":"code","001a8e2d":"code","deddfbd6":"code","5a376f5c":"code","a0611cbf":"code","bb789a8b":"code","5fbaf436":"code","af5ad5b6":"code","a214500f":"code","4d350ed4":"code","884ed5ad":"code","1c027cfd":"code","90677e74":"code","c80fd168":"code","c8ab63be":"code","88ef6633":"code","f89dddf6":"code","38386da5":"code","e213409d":"markdown","4c2202a8":"markdown","4b625579":"markdown","0c87fb72":"markdown","de4e36f4":"markdown"},"source":{"a85b8d91":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\n\n        \nimport keras.backend as K\nK.set_image_data_format('channels_last')\n\nfrom matplotlib.pyplot import imshow\nfrom keras.preprocessing import image\nfrom keras import applications\nfrom keras.models import Sequential\nimport os,sys\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\n","bf134345":"img = cv2.imread('..\/input\/training\/training\/n9\/n919.jpg')\nprint(img.shape)\nimg1 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nplt.imshow(img1)","a7d32825":"train_dir = '..\/input\/training\/training\/'\nvalid_dir = '..\/input\/validation\/validation\/'","39c0ef3b":"# Training generator\ntrain_datagen = ImageDataGenerator( \n    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n    rotation_range=40,\n    zoom_range = 0.1,\n    rescale=1.\/255)\ntrain_generator = train_datagen.flow_from_directory(\n    directory=train_dir,\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    batch_size=64,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)\n\n# Valid generator\n\nvalid_datagen = ImageDataGenerator(rescale=1.\/255)\nvalid_generator = valid_datagen.flow_from_directory(\n    directory=valid_dir,\n    target_size=(224, 224),\n    color_mode=\"rgb\",\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=True,\n    seed=42\n)","b80f85c8":"model = Sequential()\nmodel.add(BatchNormalization(input_shape=(224, 224, 3)))\nmodel.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization())\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","8fbbf969":"from keras import optimizers\nfrom keras.callbacks import ReduceLROnPlateau\n\noptimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)","4d09aa81":"model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","79926fec":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","0effeb69":"STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size","d980f737":"model.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10,\n                    verbose=1,\n                    callbacks=[learning_rate_reduction]\n)","56c965b0":"from keras.applications import vgg16","6dd8c4ae":"vgg16_model = vgg16.VGG16(weights='imagenet')","add2e71c":"vgg16_model.summary()","001a8e2d":"model2 = Sequential()\nfor layer in vgg16_model.layers[:-1]:\n    model2.add(layer)","deddfbd6":"for layer in model2.layers:\n    layer.trainable = False","5a376f5c":"model2.add(Dense(10, activation='softmax'))","a0611cbf":"model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","bb789a8b":"model2.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10,\n                    verbose=1,\n                    callbacks=[learning_rate_reduction]\n)","5fbaf436":"mobile = keras.applications.mobilenet.MobileNet()","af5ad5b6":"mobile.summary()","a214500f":"mobile_tune = Sequential()\nfor layer in mobile.layers:\n    mobile_tune.add(layer)","4d350ed4":"mobile_tune.add(Dense(10, activation='softmax'))","884ed5ad":"for layer in mobile_tune.layers[:-5]:\n    layer.trainable = False","1c027cfd":"mobile_tune.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","90677e74":"mobile_tune.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10,\n                    verbose=1,\n                    callbacks=[learning_rate_reduction]\n)","c80fd168":"from keras.applications.xception import Xception","c8ab63be":"base_model = Xception(weights='imagenet', include_top=False)\nbase_model.summary()","88ef6633":"# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(10, activation='softmax')(x)\n\n# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n# this is the model we will train\nxception = Model(inputs=base_model.input, outputs=predictions)","f89dddf6":"xception.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","38386da5":"xception.fit_generator(generator=train_generator,\n                    steps_per_epoch=STEP_SIZE_TRAIN,\n                    validation_data=valid_generator,\n                    validation_steps=STEP_SIZE_VALID,\n                    epochs=10,\n                    verbose=1,\n                    callbacks=[learning_rate_reduction]\n)","e213409d":"# **5. Xception**","4c2202a8":"# **3. Mobile Net**","4b625579":"# **1. CNN from scratch**\n# **2. VGG16**\n# **3. Mobile Net**\n# **4. Xception**","0c87fb72":"# **1. Create our own CNN from scratch**","de4e36f4":"# **2. VGG 16**"}}