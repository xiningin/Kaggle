{"cell_type":{"7c1b780b":"code","275acb60":"code","13494bc5":"code","86671c92":"code","44f4005d":"markdown","461785fd":"markdown"},"source":{"7c1b780b":"\n\"\"\"\nResUNet++ architecture in Keras TensorFlow\n\"\"\"\nimport os\nimport numpy as np\nimport cv2\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\n\ndef squeeze_excite_block(inputs, ratio=8):\n    init = inputs\n    channel_axis = -1\n    filters = init.shape[channel_axis]\n    se_shape = (1, 1, filters)\n\n    se = GlobalAveragePooling2D()(init)\n    se = Reshape(se_shape)(se)\n    se = Dense(filters \/\/ ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n\n    x = Multiply()([init, se])\n    return x\n\ndef stem_block(x, n_filter, strides):\n    x_init = x\n\n    ## Conv 1\n    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(n_filter, (3, 3), padding=\"same\")(x)\n\n    ## Shortcut\n    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n    s = BatchNormalization()(s)\n\n    ## Add\n    x = Add()([x, s])\n    x = squeeze_excite_block(x)\n    return x\n\n\ndef resnet_block(x, n_filter, strides=1):\n    x_init = x\n\n    ## Conv 1\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=strides)(x)\n    ## Conv 2\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(n_filter, (3, 3), padding=\"same\", strides=1)(x)\n\n    ## Shortcut\n    s  = Conv2D(n_filter, (1, 1), padding=\"same\", strides=strides)(x_init)\n    s = BatchNormalization()(s)\n\n    ## Add\n    x = Add()([x, s])\n    x = squeeze_excite_block(x)\n    return x\n\ndef aspp_block(x, num_filters, rate_scale=1):\n    x1 = Conv2D(num_filters, (3, 3), dilation_rate=(6 * rate_scale, 6 * rate_scale), padding=\"same\")(x)\n    x1 = BatchNormalization()(x1)\n\n    x2 = Conv2D(num_filters, (3, 3), dilation_rate=(12 * rate_scale, 12 * rate_scale), padding=\"same\")(x)\n    x2 = BatchNormalization()(x2)\n\n    x3 = Conv2D(num_filters, (3, 3), dilation_rate=(18 * rate_scale, 18 * rate_scale), padding=\"same\")(x)\n    x3 = BatchNormalization()(x3)\n\n    x4 = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n    x4 = BatchNormalization()(x4)\n\n    y = Add()([x1, x2, x3, x4])\n    y = Conv2D(num_filters, (1, 1), padding=\"same\")(y)\n    return y\n\ndef attetion_block(g, x):\n    \"\"\"\n        g: Output of Parallel Encoder block\n        x: Output of Previous Decoder block\n    \"\"\"\n\n    filters = x.shape[-1]\n\n    g_conv = BatchNormalization()(g)\n    g_conv = Activation(\"relu\")(g_conv)\n    g_conv = Conv2D(filters, (3, 3), padding=\"same\")(g_conv)\n\n    g_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(g_conv)\n\n    x_conv = BatchNormalization()(x)\n    x_conv = Activation(\"relu\")(x_conv)\n    x_conv = Conv2D(filters, (3, 3), padding=\"same\")(x_conv)\n\n    gc_sum = Add()([g_pool, x_conv])\n\n    gc_conv = BatchNormalization()(gc_sum)\n    gc_conv = Activation(\"relu\")(gc_conv)\n    gc_conv = Conv2D(filters, (3, 3), padding=\"same\")(gc_conv)\n\n    gc_mul = Multiply()([gc_conv, x])\n    return gc_mul\n\nclass ResUnetPlusPlus:\n    def __init__(self, input_size=256):\n        self.input_size = input_size\n\n    def build_model(self):\n        n_filters = [16, 32, 64, 128, 256]\n        inputs = Input((self.input_size, self.input_size, 3))\n\n        c0 = inputs\n        c1 = stem_block(c0, n_filters[0], strides=1)\n\n        ## Encoder\n        c2 = resnet_block(c1, n_filters[1], strides=2)\n        c3 = resnet_block(c2, n_filters[2], strides=2)\n        c4 = resnet_block(c3, n_filters[3], strides=2)\n\n        ## Bridge\n        b1 = aspp_block(c4, n_filters[4])\n\n        ## Decoder\n        d1 = attetion_block(c3, b1)\n        d1 = UpSampling2D((2, 2))(d1)\n        d1 = Concatenate()([d1, c3])\n        d1 = resnet_block(d1, n_filters[3])\n\n        d2 = attetion_block(c2, d1)\n        d2 = UpSampling2D((2, 2))(d2)\n        d2 = Concatenate()([d2, c2])\n        d2 = resnet_block(d2, n_filters[2])\n\n        d3 = attetion_block(c1, d2)\n        d3 = UpSampling2D((2, 2))(d3)\n        d3 = Concatenate()([d3, c1])\n        d3 = resnet_block(d3, n_filters[1])\n\n        ## output\n        outputs = aspp_block(d3, n_filters[0])\n        outputs = Conv2D(1, (1, 1), padding=\"same\")(outputs)\n        outputs = Activation(\"sigmoid\")(outputs)\n\n        ## Model\n        model = Model(inputs, outputs)\n        return model\n","275acb60":"\nimport os\nimport numpy as np\nimport cv2\nfrom glob import glob\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n# Load Dataset and split with Random seed\n\ndef load_data(path, split=0.1):\n    images = sorted(glob(os.path.join(path, \"images\/*\")))\n    masks = sorted(glob(os.path.join(path, \"masks\/*\")))\n\n#     images = sorted(glob(os.path.join(path, \"train\/images\/*\")))\n#     masks = sorted(glob(os.path.join(path, \"train\/masks\/*\")))\n\n\n    total_size = len(images)\n    print(total_size)\n    valid_size = int(split * total_size)\n    test_size = int(split * total_size)\n\n\n    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42)\n    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)\n   \n\n    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n    print(len(train_x),len(valid_x),len(test_x))\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x,test_y)\n\n# Read and Resize Image to 256(coloured)\ndef read_image(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (256, 256))\n    x = x\/255.0\n    return x\n\n# Read and Resize Mask to 256(Grayscaled)\ndef read_mask(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (256, 256))\n    x = x\/255.0\n    x = np.expand_dims(x, axis=-1)\n    return x\n\n\n# Tensor element type for model(can change to 32bit for speed)\ndef tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n    x.set_shape([256, 256, 3])\n    y.set_shape([256, 256, 1])\n    return x, y\n# creates a dataset with a separate element for each row of the input tensor\n# we will then use batch and repeat method to convert Dataset into batches\ndef tf_dataset(x, y, batch=8):\n    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n    dataset = dataset.map(tf_parse)\n    dataset = dataset.batch(batch)\n    dataset = dataset.repeat()\n    return dataset\n","13494bc5":"import os\n\nimport numpy as np\nimport cv2\nfrom glob import glob\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n# from data import load_data, tf_dataset\n# from model import build_model\n\ndef iou(y_true, y_pred):\n    def f(y_true, y_pred):\n        intersection = (y_true * y_pred).sum()\n        union = y_true.sum() + y_pred.sum() - intersection\n        x = (intersection + 1e-15) \/ (union + 1e-15)\n        x = x.astype(np.float32)\n        return x\n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n\nif __name__ == \"__main__\":\n    ## Dataset\n    path = \"..\/input\/kvasirv2\/Kvasirv2\"\n    (train_x, train_y), (valid_x, valid_y), (test_x,test_y) = load_data(path)\n    \n    ## Hyperparameters\n    batch = 8\n    lr = 1e-4\n    epochs = 200\n    # np.reshape(train_x,(50,8))\n    train_dataset = tf_dataset(train_x, train_y, batch=batch)\n    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)\n    image_size = 256\n    obj=ResUnetPlusPlus(input_size=image_size)\n    model = obj.build_model()\n\n    opt = tf.keras.optimizers.Adam(lr)\n    metrics = [\"acc\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), iou]\n    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=metrics)\n\n    callbacks = [\n        ModelCheckpoint(\"files\/model.h5\"),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n        CSVLogger(\"files\/data.csv\"),\n        TensorBoard(),\n        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False)\n    ]\n    try:\n        path=os.path.join(mypath, n)\n        img=cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    \n        img=cv2.resize(img, (img_rows, img_cols))\n    except Exception as e:\n        \n        \n        \n\n      \n        train_steps = len(train_x)\/\/batch\n        valid_steps = len(valid_x)\/\/batch\n\n    if len(train_x) % batch != 0:\n        train_steps += 1\n    if len(valid_x) % batch != 0:\n        valid_steps += 1\n\n    model.fit(train_dataset,validation_data=valid_dataset,epochs=epochs,steps_per_epoch=train_steps,validation_steps=valid_steps,callbacks=callbacks)","86671c92":"\nimport os\nimport numpy as np\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.utils import CustomObjectScope\nfrom tqdm import tqdm\n# from data import load_data, tf_dataset\n# from train import iou\n# create data generator\ndef iou(y_true, y_pred):\n    def f(y_true, y_pred):\n        intersection = (y_true * y_pred).sum()\n        union = y_true.sum() + y_pred.sum() - intersection\n        x = (intersection + 1e-15) \/ (union + 1e-15)\n        x = x.astype(np.float32)\n        return x\n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n\ndef read_image(path):\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (256, 256))\n    x = x\/255.0\n    return x\n\ndef read_mask(path):\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (256, 256))\n    x = np.expand_dims(x, axis=-1)\n    return x\n\ndef mask_parse(mask):\n    mask = np.squeeze(mask)\n    mask = [mask, mask, mask]\n    mask = np.transpose(mask, (1, 2, 0))\n    return mask\n\nif __name__ == \"__main__\":\n    ## Dataset\n    path = \"..\/input\/kvasirv2\/Kvasirv2\"\n    batch_size = 8\n   \n    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n    \n\n    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n\n    test_steps = (len(test_x)\/\/batch_size)\n    if len(test_x) % batch_size != 0:\n        test_steps += 1\n\n    with CustomObjectScope({'iou': iou}):\n        model = tf.keras.models.load_model(\"files\/model.h5\")\n\n#     model.evaluate(test_dataset, steps=test_steps)\n\n    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n        x = read_image(x)\n        y = read_mask(y)\n        y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n        h, w, _ = x.shape\n        white_line = np.ones((h, 10, 3)) * 255.0\n\n        all_images = [\n            x * 255.0, white_line,\n            mask_parse(y), white_line,\n            mask_parse(y_pred) * 255.0\n        ]\n        image = np.concatenate(all_images, axis=1)\n        cv2.imwrite(f\"files\/{i}.png\", image)\n","44f4005d":"Load Data","461785fd":"Train"}}