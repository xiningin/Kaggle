{"cell_type":{"b9bcce33":"code","fa2e088f":"code","8d48495d":"code","6e2c9516":"code","576ea565":"code","78991a2e":"code","32007db6":"code","d5119265":"code","f2d4abad":"code","dbdb1eed":"code","24557ab2":"code","6d9817cd":"code","3dd8f357":"code","08418759":"code","306b9fa7":"code","e81ac74f":"code","953c8e59":"code","b56bf9b7":"code","0b099e6f":"code","ba5dfab5":"code","bd985b3a":"code","abc08399":"code","adad6851":"markdown"},"source":{"b9bcce33":"#!pip install ..\/input\/pytorch-image-models\/timm-0.3.1-py3-none-any.whl ..\/input\/walkwithfastai\/wwf-0.0.5-py3-none-any.whl","fa2e088f":"from fastai.vision.all import *","8d48495d":"class AlbumentationsTransform(RandTransform):\n    \"A transform handler for multiple `Albumentation` transforms\"\n    split_idx,order=None,2\n    def __init__(self, train_aug, valid_aug): store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n        return PILImage.create(aug_img)\n    \n    \n    \n","6e2c9516":"\ndef get_x(row): return row['image_id']\ndef get_y(row): return row['label']","576ea565":"#from wwf.vision.timm import *","78991a2e":"#!pip install wwf timm \n","32007db6":"learn=load_learner(\"..\/input\/resnext50\/baseline_rsnx\",cpu=False)","d5119265":"learn = learn.to_native_fp32()","f2d4abad":"data_path=\"..\/input\/cassava-leaf-disease-classification\/\"","dbdb1eed":"sample_df = pd.read_csv(data_path+'sample_submission.csv')\nsample_df.head()","24557ab2":"sample_copy = sample_df.copy()\nsample_copy['image_id'] = sample_copy['image_id'].apply(lambda x: \"..\/input\/cassava-leaf-disease-classification\/test_images\/\"+x)","6d9817cd":"test_dl = learn.dls.test_dl(sample_copy)","3dd8f357":"test_dl.one_batch()[0].shape","08418759":"preds, _ = learn.tta(dl=test_dl, n=15, beta=0)","306b9fa7":"#learn=load_learner(\"..\/input\/efficient-net\/baseline_eff\",cpu=False)","e81ac74f":"#learn = learn.to_native_fp32()","953c8e59":"#test_dl = learn.dls.test_dl(sample_copy)","b56bf9b7":"#preds2, _ = learn.tta(dl=test_dl, n=15, beta=0)","0b099e6f":"#predx=(preds+preds2)\/2","ba5dfab5":"sample_df['label'] = preds.argmax(dim=-1).numpy()","bd985b3a":"sample_df.to_csv('submission.csv',index=False)","abc08399":"pd.read_csv(\".\/submission.csv\")","adad6851":"# **ENSEMBLE resnext50_32x4d and efficient net b3 with Albumentations Transform**"}}