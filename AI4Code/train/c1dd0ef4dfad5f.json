{"cell_type":{"9d5e7ed0":"code","bd937e4f":"code","ad304b78":"code","7caf1409":"code","b6ec337a":"markdown","954ef5f4":"markdown","ae2237ba":"markdown"},"source":{"9d5e7ed0":"import numpy as np\nfrom keras.datasets import mnist\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.optimizers import SGD\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","bd937e4f":"(x_train, y_train),(x_test, y_test) = mnist.load_data()\nprint('x_shape:', x_train.shape)\nprint('y_shape:', y_train.shape)\n\nx_train = x_train.reshape(x_train.shape[0],-1)\/255.0\nx_test = x_test.reshape(x_test.shape[0],-1)\/255.0\n\ny_train = np_utils.to_categorical(y_train,num_classes=10)\ny_test =  np_utils.to_categorical(y_test, num_classes=10)","ad304b78":"model = Sequential([\n        Dense(units=200,input_dim=784,bias_initializer='one',activation='tanh'),\n        Dense(units=100,bias_initializer='one',activation='tanh'),\n        Dense(units=10,bias_initializer='one',activation='softmax')\n\n])\n\nsgd = SGD(lr = 0.2)\nmodel.compile(optimizer=sgd,\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,batch_size=32,epochs=10)\nloss,accuracy = model.evaluate(x_test, y_test)\nprint('\\ntest loss',loss)\nprint('test accuracy',accuracy)\n\nloss,accuracy = model.evaluate(x_train, y_train)\nprint('\\ntrain loss',loss)\nprint('train accuracy',accuracy)","7caf1409":"model = Sequential([\n        Dense(units=200,input_dim=784,bias_initializer='one',activation='tanh'),\n        Dropout(0.4),\n        Dense(units=100,bias_initializer='one',activation='tanh'),\n        Dropout(0.4),\n        Dense(units=10,bias_initializer='one',activation='softmax')\n\n])\n\nsgd = SGD(lr = 0.2)\nmodel.compile(optimizer=sgd,\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel.fit(x_train, y_train,batch_size=32,epochs=10)\nloss,accuracy = model.evaluate(x_test, y_test)\nprint('\\ntest loss',loss)\nprint('test accuracy',accuracy)\n\nloss,accuracy = model.evaluate(x_train, y_train)\nprint('\\ntrain loss',loss)\nprint('train accuracy',accuracy)","b6ec337a":"Although there has been overfitting, it is better than before.Here we mainly show the application of dropout.","954ef5f4":"- The train accuracy  > The test accuracy\n- Outcome: Overfitting\n- Overfitting soulution: Add dropout(To disable a certain percentage of neurons)","ae2237ba":"### Add hidden layer = 200\u2192100\n### Input layer = 784\n### Output layer = 10\nUsually we set \u2018tanh\u2019 function as hidden layer's activation and \u2018softmax\u2019function as output layer's activation"}}