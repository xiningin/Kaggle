{"cell_type":{"54510116":"code","a528c035":"code","e72b98db":"code","5396c214":"code","a993503d":"code","23de6aac":"code","3b6a6fab":"code","58e1c673":"code","2d47daf1":"code","fa5291a5":"code","ca04d69b":"code","9e5b2723":"code","a847a1cb":"code","45fef527":"code","86287434":"code","532d9174":"code","752fe515":"code","4f896a34":"code","29fc819e":"code","f416220b":"code","c3425fef":"code","2b63ad7d":"code","4bbf6443":"code","6a0731c8":"code","b0dacc69":"code","9642a8dc":"code","3475eed2":"code","d2dabcfe":"code","a05b8554":"code","a2fb9c09":"code","5c00aff1":"code","c74a3d10":"code","5565ed77":"code","2681823a":"code","2288ed67":"code","957c0e18":"code","6054a4dd":"code","7bb58538":"code","b806f997":"code","bd148443":"code","1b1b01f3":"code","7059462a":"code","69290b3a":"code","854d5cdc":"code","b60bff02":"code","dfd41b4e":"code","c14b6858":"code","d5fc285f":"code","3eb37e16":"code","d8bd4c18":"code","6e04f01b":"code","a099ea7c":"code","98568c42":"code","34488130":"code","bd56d376":"code","37ff6424":"code","60ec99f4":"code","efb982d8":"code","4f3957fd":"code","fe97a57b":"code","76073e61":"code","9f5d26ae":"code","dd79e6df":"code","200cb19e":"code","342d7347":"code","ebe2f8e8":"code","04a4904b":"code","5572e99d":"code","bb32a2c5":"code","8142a719":"markdown","9e6b59e7":"markdown","44fa0eee":"markdown","b85749ce":"markdown","abc27b59":"markdown","3d60a036":"markdown","484a9149":"markdown","6b0a2cdc":"markdown","1ed7aa88":"markdown","e3ee32a8":"markdown","b0fe2e31":"markdown","68514e3f":"markdown","c2f1a6fb":"markdown","31c7bb9a":"markdown","cab58ba9":"markdown","e51f957e":"markdown","65026881":"markdown","f304021b":"markdown","167d0a4c":"markdown","237e614a":"markdown","289bc7ad":"markdown","352ef8f9":"markdown","70eec589":"markdown","39fa2a37":"markdown","0d57477e":"markdown","71a04b18":"markdown"},"source":{"54510116":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\nimport copy\nimport math\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom scipy import stats\n\nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport graphviz","a528c035":"invertebrate_data = pd.read_csv('https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/Invertebrate\/Invertebrate_dataset.csv')\ninvertebrate_data.head()","e72b98db":"test_new = pd.read_csv('https:\/\/raw.githubusercontent.com\/dphi-official\/Datasets\/master\/Invertebrate\/Invertebrate_new_test_data.csv')\ntest_new.head()","5396c214":"print(invertebrate_data.shape)\nprint(test_new.shape)","a993503d":"invertebrate_data.dtypes","23de6aac":"test_new.dtypes","3b6a6fab":"invertebrate_data.isna().sum()","58e1c673":"test_new.isna().sum()","2d47daf1":"for i in invertebrate_data.columns:\n    if invertebrate_data[i].nunique() == 1:\n        print('With only 1 unique value: ', i)\n    if invertebrate_data[i].nunique() == invertebrate_data.shape[0]:\n        print('With all unique value: ', i)","fa5291a5":"for i in test_new.columns:\n    if test_new[i].nunique() == 1:\n        print('With only 1 unique value: ', i)\n    if test_new[i].nunique() == test_new.shape[0]:\n        print('With all unique value: ', i)","ca04d69b":"plt.figure(figsize = (12,10))\nsns.heatmap(invertebrate_data.corr(), vmin=invertebrate_data.values.min(), vmax=1, \n            annot=True, annot_kws={\"size\":14}, square = False)\nplt.show()","9e5b2723":"# Create correlation matrix\ncorr_matrix = invertebrate_data.corr().abs()\ncorr_matrix","a847a1cb":"# Select upper triangle of correlation matrix as lower does not remove the diagonal 1s\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.85\n# Just to illustrate taking 0.85\nto_drop = [column for column in upper.columns if any(upper[column] > 0.85)]\nto_drop","45fef527":"# Then df with dropped feature\/s\n# new_df = invertebrate_data.drop(invertebrate_data[to_drop], axis=1)\n# new_df.columns","86287434":"X = invertebrate_data.copy().drop('SWI', axis = 1)\ny = invertebrate_data['SWI']","532d9174":"fig, (ax1,ax2,ax3,ax4,ax5) = plt.subplots(nrows=1, ncols=5, figsize=(18,8))\n\nlabel1 = ['SWF']\nlabel2 = ['temperature']\nlabel3 = ['size']\nlabel4 = ['management']\nlabel5 = ['duration']\n\n# Box plot for SWF\nbplot1 = ax1.boxplot(X['SWF'],\n                     vert=True,  # vertical box alignment\n                     patch_artist=True,  # fill with color\n                     labels = label1)  # will be used to label x-ticks\nax1.set_title('Box plot for SWF')\n\n# Box plot for temperature\nbplot2 = ax2.boxplot(X['temperature'],\n                     vert=True,  # vertical box alignment\n                     patch_artist=True,  # fill with color\n                     labels = label2)  # will be used to label x-ticks\nax2.set_title('Box plot for temperature')\n\n# Box plot for size\nbplot3 = ax3.boxplot(X['size'],\n                     vert=True,  # vertical box alignment\n                     patch_artist=True,  # fill with color\n                     labels = label3)  # will be used to label x-ticks\nax3.set_title('Box plot for size')\n\n# Box plot for management\nbplot4 = ax4.boxplot(X['management'],\n                     vert=True,  # vertical box alignment\n                     patch_artist=True,  # fill with color\n                     labels = label4)  # will be used to label x-ticks\nax4.set_title('Box plot for management')\n\n# Box plot for duration\nbplot5 = ax5.boxplot(X['duration'],\n                     vert=True,  # vertical box alignment\n                     patch_artist=True,  # fill with color\n                     labels = label5)  # will be used to label x-ticks\nax5.set_title('Box plot for duration')\n\n# Fill with colors\ncolors = ['orange']\nfor bplot in (bplot1, bplot2, bplot3, bplot4, bplot5):\n    for patch, color in zip(bplot['boxes'], colors):\n        patch.set_facecolor(color)\n\n# Adding horizontal grid lines\nfor ax in [ax1, ax2, ax3, ax4, ax5]:\n    ax.yaxis.grid(True)\n    ax.set_xlabel('Variables')\n    ax.set_ylabel('Observed values')\n\nplt.show()","752fe515":"plt.figure(figsize = (15,8))\nsns.distplot(X['SWF'], hist=True, kde=True, \n             color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})","4f896a34":"plt.figure(figsize = (15,8))\nsns.distplot(X['temperature'], hist=True, kde=True, \n             color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})","29fc819e":"# Helpful video on Box-Cox. I had to watch it several times.\n\nfrom IPython.display import YouTubeVideo\n\ndef display_yotube_video(url, **kwargs):\n    \"\"\"\n    Displays a Youtube video in a Jupyter notebook.\n    \n    Args:\n        url (string): a link to a Youtube video.\n        **kwargs: further arguments for IPython.display.YouTubeVideo\n    \n    Returns:\n        YouTubeVideo: a video that is displayed in your notebook.\n    \"\"\"\n    id_ = url.split(\"=\")[-1]\n    return YouTubeVideo(id_, **kwargs)\n\ndisplay_yotube_video(\"https:\/\/www.youtube.com\/watch?v=2gVA3TudAXI\", width=600, height=400)","f416220b":"X_norm = X.copy()\n\n# Transform training data & save lambda value\nX_norm['temperature'], fitted_lambda = stats.boxcox(X_norm['temperature'])\nprint('Skewness before: ', X['temperature'].skew())\nprint('Skewness after BCT: ', X_norm['temperature'].skew())","c3425fef":"fig, ax=plt.subplots(1,2, figsize = (15,8))\nsns.distplot(X['temperature'], hist=True, kde=True, color = 'darkblue', \n             hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4}, ax=ax[0])\nsns.distplot(X_norm['temperature'], hist=True, kde=True, color = 'darkblue', \n             hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4}, ax=ax[1])","2b63ad7d":"test_norm = test_new.copy()\n# Use lambda value to transform test data\ntest_norm['temperature'] = stats.boxcox(test_new['temperature'], fitted_lambda)\nprint('Skewness before: ', test_new['temperature'].skew())\nprint('Skewness after BCT: ', test_norm['temperature'].skew())","4bbf6443":"fig, ax=plt.subplots(1,2, figsize = (15,8))\nsns.distplot(test_new['temperature'], hist=True, kde=True, color = 'darkblue', \n             hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4}, ax=ax[0])\nsns.distplot(test_norm['temperature'], hist=True, kde=True, color = 'darkblue', \n             hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4}, ax=ax[1])","6a0731c8":"sns.catplot('management', data= invertebrate_data, kind='count', alpha=0.7, height=4, aspect= 3)\n\n# Get current axis on current figure\nax = plt.gca()\n\n# Max value to be set\ny_max = invertebrate_data['management'].value_counts().max() \n\n# Iterate through the list of axes' patches\nfor p in ax.patches:\n    ax.text(p.get_x() + p.get_width()\/5., p.get_height(),'%d' % int(p.get_height()),\n            fontsize=13, color='blue', ha='center', va='bottom')\nplt.title('Frequency plot of management - train', fontsize = 14, color = 'black')\nplt.show()","b0dacc69":"print('For Train')\nd1 = X_norm.nunique()\nprint(sorted(d1))\nprint(\"==============================\")\nprint('For Test')\nd2 = test_norm.nunique()\nprint(sorted(d2))","9642a8dc":"col_train = X_norm.columns\ncol_test = test_norm.columns","3475eed2":"l1 = []\nfor i in col_train:\n    if X_norm[i].nunique() <= 22:\n        l1.append(i)","d2dabcfe":"l2 = []\nfor i in col_test:\n    if test_norm[i].nunique() <= 22:\n        l2.append(i)","a05b8554":"# Checking the columns in train and test are same or not\ndf = pd.DataFrame(l1, columns = ['train'])\ndf['test'] = pd.DataFrame(l2)\ndf","a2fb9c09":"# For now directly changing management to categorical without creating subsets\nX_norm[l1] = X_norm[l1].apply(lambda x: x.astype('category'), axis=0)\ntest_norm[l2] = test_norm[l2].apply(lambda x: x.astype('category'), axis=0)\nprint('train dtypes:')\nprint(X_norm[l1].dtypes)\nprint('======================================')\nprint('test dtypes:')\nprint(test_norm[l1].dtypes)","5c00aff1":"l1","c74a3d10":"# Function to create dummies\ndef dummy(train, test, cols):\n    X_num = len(train)\n    combined_dataset = pd.concat(objs=[train, test], axis=0)\n    combined_dataset = pd.get_dummies(combined_dataset, columns=cols, drop_first=True)\n    train = copy.copy(combined_dataset[:X_num])\n    test = copy.copy(combined_dataset[X_num:])","5565ed77":"dummy(X, test_new, l1)\nX_num = len(X)\ncombined_dataset = pd.concat(objs=[X, test_new], axis=0)\ncombined_dataset = pd.get_dummies(combined_dataset, columns=l1, drop_first=True)\nX = copy.copy(combined_dataset[:X_num])\ntest = copy.copy(combined_dataset[X_num:])","2681823a":"print(X.shape)\nprint(y.shape)\nprint(test.shape)","2288ed67":"dummy(X_norm, test_norm, l1)\nX_norm_num = len(X_norm)\ncombined_dataset_norm = pd.concat(objs=[X_norm, test_norm], axis=0)\ncombined_dataset_norm = pd.get_dummies(combined_dataset_norm, columns=l1, drop_first=True)\nX_norm = copy.copy(combined_dataset_norm[:X_norm_num])\ntest_norm = copy.copy(combined_dataset_norm[X_norm_num:])","957c0e18":"print(X_norm.shape)\nprint(y.shape)\nprint(test_norm.shape)","6054a4dd":"# Splitting into train and validation sets for non BCT (Box-Cox Transformed) data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state = 50)","7bb58538":"# Splitting into train and validation sets for BCT data\nX_train_bct, X_val_bct, y_train_bct, y_val_bct = train_test_split(X_norm, y, test_size=0.2, random_state = 50)","b806f997":"print('On non BCT data')\nprint('---------------')\nlasso_reg = LassoCV(cv=5, random_state=1)\nlasso_reg.fit(X_train, y_train)\nprint(\"Best alpha using built-in LassoCV: %f\" % lasso_reg.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" % lasso_reg.score(X_train,y_train))\ncoef = pd.Series(lasso_reg.coef_, index = X_train.columns)","bd148443":"print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","1b1b01f3":"# Important features\nimp_coef = coef.sort_values()\nax1 = imp_coef.plot(kind = \"barh\" )\nplt.rcParams['figure.figsize'] = (15.0, 10.0)","7059462a":"print('On BCT data')\nprint('---------------')\nlasso_reg_norm = LassoCV(cv=5, random_state=1)\nlasso_reg_norm.fit(X_train_bct, y_train_bct)\nprint(\"Best alpha using built-in LassoCV: %f\" % lasso_reg_norm.alpha_)\nprint(\"Best score using built-in LassoCV: %f\" % lasso_reg_norm.score(X_train_bct,y_train_bct))\ncoef_norm = pd.Series(lasso_reg_norm.coef_, index = X_train_bct.columns)","69290b3a":"print(\"Lasso picked \" + str(sum(coef_norm != 0)) + \" variables and eliminated the other \" +  \n      str(sum(coef_norm == 0)) + \" variables\")","854d5cdc":"# Important features\nimp_coef_norm = coef_norm.sort_values()\nax1 = imp_coef_norm.plot(kind = \"barh\" )\nplt.rcParams['figure.figsize'] = (15.0, 10.0)","b60bff02":"# Predict (train)\ny_train_pred = lasso_reg.predict(X_train)\n\n# Model evaluation\nmse = mean_squared_error(y_train, y_train_pred)\nr2 = r2_score(y_train, y_train_pred)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","dfd41b4e":"# Predict (val)\ny_val_pred = lasso_reg.predict(X_val)\n\n# Model evaluation (val)\nmse = mean_squared_error(y_val, y_val_pred)\nr2 = r2_score(y_val, y_val_pred)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","c14b6858":"# Predict (train)\ny_train_pred_bct = lasso_reg_norm.predict(X_train_bct)\n\n# Model evaluation\nmse = mean_squared_error(y_train_bct, y_train_pred_bct)\nr2 = r2_score(y_train_bct, y_train_pred_bct)\nrmse = math.sqrt(mse)\nprint('On BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","d5fc285f":"# Predict (val)\ny_val_pred_bct = lasso_reg_norm.predict(X_val_bct)\n\n# Model evaluation (val)\nmse = mean_squared_error(y_val_bct, y_val_pred_bct)\nr2 = r2_score(y_val_bct, y_val_pred_bct)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","3eb37e16":"from sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nlinreg.fit(X_train, y_train)","d8bd4c18":"# Predict (train)\ny_train_pred = linreg.predict(X_train)\n\n# Model evaluation (train)\nmse = mean_squared_error(y_train, y_train_pred)\nr2 = r2_score(y_train, y_train_pred)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","6e04f01b":"# Predict (val)\ny_val_pred = linreg.predict(X_val)\n\n# Model evaluation (val)\nmse = mean_squared_error(y_val, y_val_pred)\nr2 = r2_score(y_val, y_val_pred)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","a099ea7c":"linreg_bct = LinearRegression()\nlinreg_bct.fit(X_train_bct, y_train_bct)","98568c42":"# Predict (train)\ny_train_pred_bct = linreg_bct.predict(X_train_bct)\n\n# Model evaluation\nmse = mean_squared_error(y_train_bct, y_train_pred_bct)\nr2 = r2_score(y_train_bct, y_train_pred_bct)\nrmse = math.sqrt(mse)\nprint('On BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","34488130":"# Predict (val)\ny_val_pred_bct = linreg_bct.predict(X_val_bct)\n\n# Model evaluation (val)\nmse = mean_squared_error(y_val_bct, y_val_pred_bct)\nr2 = r2_score(y_val_bct, y_val_pred_bct)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","bd56d376":"# You can try by removing the max_depth and see the output for Predict (train)","37ff6424":"from sklearn.tree import DecisionTreeRegressor\ndt = DecisionTreeRegressor(random_state=50, max_depth=4)\ndt.fit(X_train, y_train)","60ec99f4":"# Predict (train)\ny_train_pred = dt.predict(X_train)\n\n# Model evaluation (train)\nmse = mean_squared_error(y_train, y_train_pred)\nr2 = r2_score(y_train, y_train_pred)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","efb982d8":"# Predict (val)\ny_val_pred = dt.predict(X_val)\n\n# Model evaluation (val)\nmse = mean_squared_error(y_val, y_val_pred)\nr2 = r2_score(y_val, y_val_pred)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","4f3957fd":"from sklearn.ensemble import RandomForestRegressor\nrf1 = RandomForestRegressor()\nrf1.fit(X = X_train,y = y_train)","fe97a57b":"# Predict (train)\ny_train_pred_rf = rf1.predict(X_train)\n\n# Model evaluation (train)\nmse = mean_squared_error(y_train, y_train_pred_rf)\nr2 = r2_score(y_train, y_train_pred_rf)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","76073e61":"# Predict (val)\ny_val_pred_rf = rf1.predict(X_val)\n\n# Model evaluation (val)\nmse = mean_squared_error(y_val, y_val_pred_rf)\nr2 = r2_score(y_val, y_val_pred_rf)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","9f5d26ae":"rfgs = RandomForestRegressor(random_state=50)","dd79e6df":"param_grid = { \n    'n_estimators': [2,3,4,5],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [2,3,4,5],\n    'criterion' :['mse']\n}","200cb19e":"cv_rfc = GridSearchCV(estimator=rfgs, param_grid=param_grid, cv= 5)\ncv_rfc.fit(X_train, y_train)","342d7347":"cv_rfc.best_params_","ebe2f8e8":"rfgs1 = RandomForestRegressor(random_state=45, **cv_rfc.best_params_)","04a4904b":"rfgs1.fit(X_train, y_train)","5572e99d":"# Predict (train)\ny_train_pred_rf = rfgs1.predict(X_train)\n\n# Model evaluation (train)\nmse = mean_squared_error(y_train, y_train_pred_rf)\nr2 = r2_score(y_train, y_train_pred_rf)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","bb32a2c5":"# Predict (val)\ny_val_pred_rf = rfgs1.predict(X_val)\n\n# Model evaluation (val)\nmse = mean_squared_error(y_val, y_val_pred_rf)\nr2 = r2_score(y_val, y_val_pred_rf)\nrmse = math.sqrt(mse)\nprint('On non BCT data')\nprint('----------------')\nprint('R-squared: ', r2)\nprint('MSE: ', mse)\nprint('RMSE: ', rmse)","8142a719":"## 1. Libraries and Analyzing the Data <a id = 'libraries' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","9e6b59e7":"## 2. Plots    <a id = 'plt' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","44fa0eee":"#### Checking column\/s to change to Categorical","b85749ce":"#### Distribution of temperature <a id = 'temp' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","abc27b59":"### B. Linear Regression <a id = 'lr' ><\/a>\n\n[Home](#home) <a href = '#home'><\/a>","3d60a036":"#### Checking Data Types","484a9149":"![SWI.JPG](attachment:SWI.JPG)","6b0a2cdc":"## 3. Data Preparation <a id = 'dataprep' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","1ed7aa88":"#### Applying Box-Cox transformation to temperature <a id = 'bct' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","e3ee32a8":"#### Checking NAs","b0fe2e31":"#### Correlation Analysis <a id = 'cor' ><\/a>","68514e3f":"#### Distribution of SWF <a id = 'swf' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","c2f1a6fb":"#### Grid Search and CV <a id = 'gs' ><\/a>\n\n[Home](#home) <a href = '#home'><\/a>","31c7bb9a":"#### Frequency plot for management <a id = 'mgmt' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","cab58ba9":"### A. Lasso Regression <a id = 'lg' ><\/a>\n\n[Home](#home) <a href = '#home'><\/a>","e51f957e":"#### Box Plots <a id = 'box' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","65026881":"<a id = 'home' ><\/a>","f304021b":"# SWI Invertebrate Analysis\n### https:\/\/www.tutorialspoint.com\/statistics\/shannon_wiener_diversity_index.htm\n\n- This is still a WIP based on some subsetting ideas that I could think of\n- Suggestions are most welcomed","167d0a4c":"#### Illustration of which variable could be dropped to analys based on correlation <a id = 'crdrp' ><\/a>\n[Home](#home) <a href = '#home'><\/a>","237e614a":"#### Checking column\/s with Single Value or All Unique Values","289bc7ad":"#### Splitting of data into train and validation sets","352ef8f9":"## 3. Model Building <a id = 'model' ><\/a>\n\n[Home](#home) <a href = '#home'><\/a>","70eec589":"### C. Decision Tree <a id = 'dt' ><\/a>\n\n[Home](#home) <a href = '#home'><\/a>","39fa2a37":"1. [**Libraries and Analyzing the Data**](#libraries) <a href = '#libraries'><\/a>\n    - No null values\n    - No variables with either Single Value or All Unique Values\n2. [**Plots**](#plt) <a href = '#plt'><\/a>   \n    - [**Correlation Analysis**](#cor) <a href = '#cor'><\/a>\n        - Some expected outputs:\n            - SWI & SWF (0.68)\n            - Temperature & Duration (0.87)\n    - [**Illustration of which variable could be dropped to analysis based on correlation**](#crdrp) <a href = '#crdrp'><\/a>           \n    - [**Box Plots**](#box) <a href = '#box'><\/a>\n        - Outliers observed for temperature and duration\n            - Data subset 1 can be prepared without temperature outliers\n            - Data subset 2 can be prepared without duration outliers\n        - SWF too has outliers but too far from the thresholds\n            - Data subset 3 can be prepared without SWF outliers\n    - [**Distribution of SWF**](#swf) <a href = '#swf'><\/a>\n    - [**Distribution of temperature**](#temp) <a href = '#temp'><\/a>\n        - Left-skewness observed \n        - [Applying Box-Cox transformation to temperature](#bct) <a href = '#bct'><\/a>\n    - [**Frequency plot for management**](#mgmt) <a href = '#mgmt'><\/a>\n        - Based on the frequencies:\n            - Data subset 4 can be prepared for values = [0, 3, 8]\n            - Data subset 5 can be prepared for values = [1, 5, 7]\n            - Data subset 6 can be prepared for values = [2, 4, 6]\n3. [**Data Preparation**](#dataprep) <a href = '#dataprep'><\/a>\n    - **Checking column\/s to change to Categorical**\n4. [**Model Building**](#model) <a href = '#model'><\/a>\n    - [**A. Lasso Regression**](#lg) <a href = '#lg'><\/a>\n    - [**B. Linear Regression**](#lr) <a href = '#lr'><\/a> \n    - [**C. Decision Tree**](#dt) <a href = '#dt'><\/a> \n    - [**D. Random Forest**](#rf) <a href = '#rf'><\/a> ","0d57477e":"### D. Random Forest <a id = 'rf' ><\/a>\n\n[Home](#home) <a href = '#home'><\/a>","71a04b18":"#### Function to create dummies for cat vars"}}