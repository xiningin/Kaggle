{"cell_type":{"1f8b96ae":"code","87d70d93":"code","2a9cd2c0":"code","ec4eef92":"code","239d0ef7":"code","5cbfeb4a":"code","b71f48fa":"code","8b484525":"code","4d8eac0e":"code","7df9f8fa":"code","e2fc01db":"code","9c7870b3":"code","7a2add8a":"code","0e50c27f":"code","c66d9d4f":"code","1dff9ee8":"code","4bfcff2e":"code","d868d98f":"code","586e5955":"code","cbaafa09":"code","29c0e8e3":"code","9041ebce":"code","ff27ac87":"code","ab9e5a7e":"code","38d49f9a":"code","13fae52d":"code","1a49b022":"code","f97e8a01":"code","8b0886c8":"code","4a097ad9":"code","e9035f1d":"code","5c07a4ca":"markdown","2875a20c":"markdown","d1653813":"markdown","26f5c534":"markdown","3d341a99":"markdown","4e44494a":"markdown","4ac5081c":"markdown","01c7ddad":"markdown","469fc146":"markdown","80de2a61":"markdown","b7c960d5":"markdown","b2e81b98":"markdown","f66dd3f2":"markdown","99b55d78":"markdown","0490f2d2":"markdown","d7fd0589":"markdown","69a8ead1":"markdown","146465ee":"markdown","a91837c0":"markdown","586b5550":"markdown"},"source":{"1f8b96ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2 as cv2\nfrom sklearn.model_selection import train_test_split\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","87d70d93":"train_df = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\ntrain_df.shape","2a9cd2c0":"train_df.head()","ec4eef92":"test_df = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')\ntest_df.shape","239d0ef7":"test_df.head()","5cbfeb4a":"train_df.isnull().sum()","b71f48fa":"test_df.isnull().sum()","8b484525":"train_df.dtypes","4d8eac0e":"train_df['label'].values","7df9f8fa":"labels = train_df['label'].values","e2fc01db":"unique_set = np.unique(np.array(labels))","9c7870b3":"plt.figure(figsize=(10,10))\nsns.set(style=\"darkgrid\")\nsns.countplot(y=labels, data=train_df, palette='Set2')","7a2add8a":"train_df.drop(['label'],axis=1,inplace=True)","0e50c27f":"img = cv2.imread('..\/input\/sign-language-mnist\/amer_sign2.png')\nplt.imshow(img)","c66d9d4f":"img = cv2.imread('..\/input\/sign-language-mnist\/american_sign_language.PNG')\nplt.imshow(img)","1dff9ee8":"images = train_df.values\nimages = np.array([np.reshape (i, (28,28)) for i in images])\nimages = np.array([i.flatten() for i in images])","4bfcff2e":"plt.imshow(images[0].reshape(28, 28))","d868d98f":"from sklearn.preprocessing import LabelBinarizer\n\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)","586e5955":"labels[:5]","cbaafa09":"x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=140)\n\nprint('Training Data shape : ',x_train.shape,  y_train.shape)\nprint('Testing Data shape : ',x_test.shape,  y_test.shape)","29c0e8e3":"batch_size=256\nEPOCHS = 50","9041ebce":"x_train, x_test = x_train.astype(np.float32), x_test.astype(np.float32)\n# Flatten images to 1-D vector of 784 features (28*28).\nx_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])\n# Normalize images value from [0, 255] to [0, 1].\n\nx_train = x_train\/255.\nx_test = x_test\/255.","ff27ac87":"plt.imshow(x_train[0].reshape(28,28)) #Since image size is 784 so (28,28)\nplt.axis('off')","ab9e5a7e":"input_img = tf.keras.layers.Input(shape=(784,), name = \"input\")\n\n# this is the encoded representation of the input\nencoded = Dense(1024, activation='relu', name=\"emb_0\")(input_img)\nencoded = Dense(512, activation='relu', name=\"emb_1\")(encoded)\nencoded = Dense(256, activation='relu', name=\"emb_2\")(encoded)\nencoded = Dense(128, activation='relu', name=\"emb_3\")(encoded)\nencoded = Dense(64, activation='relu', name=\"emb_4\")(encoded)\nencoded = Dense(16, activation='relu', name=\"emb_5\")(encoded)\nlatent_vector = Dense(2, activation='relu', name=\"latent_vector\")(encoded)","38d49f9a":"# this is the loss reconstruction of the input\ndecoded = Dense(16, activation='relu', name=\"dec_1\")(latent_vector)\ndecoded = Dense(64, activation='relu', name=\"dec_3\")(decoded)\ndecoded = Dense(128, activation='relu', name=\"dec_4\")(decoded)\ndecoded = Dense(256, activation='relu', name=\"dec_5\")(decoded)\ndecoded = Dense(512, activation='relu', name=\"dec_6\")(decoded)\ndecoded = Dense(1024, activation='relu', name=\"dec_7\")(decoded)\n\noutput_layer = Dense(784, activation = 'sigmoid', name=\"output\")(decoded)","13fae52d":"autoencoder = tf.keras.models.Model(input_img, output_layer)","1a49b022":"autoencoder.summary()","f97e8a01":"encoder = tf.keras.models.Model(input_img, latent_vector)\nencoder.summary()","8b0886c8":"autoencoder.compile(optimizer='adam', loss='mse')\nauto_history = autoencoder.fit(x_train, x_train, epochs=EPOCHS, batch_size=batch_size,validation_data=(x_test, x_test))","4a097ad9":"decoded_imgs = autoencoder.predict(x_test)","e9035f1d":"n = 10 \nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # display original\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    # display reconstruction\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\nplt.show()","5c07a4ca":"**So our label contains Categorical variables data so we will have to binarize it later**","2875a20c":"**More deeper the layers, better the performance**","d1653813":"# Model Developement","26f5c534":"# Loading Dataset","3d341a99":"# Autoencoder Model ","4e44494a":"**Let's see the model**","4ac5081c":"**Let us check the label column data frequency**","01c7ddad":"**So our dataset contains all int values let's check our label column**","469fc146":"**reshaping x_train and x_test**","80de2a61":"**Let's compare the original images and new generated images from AutoEncoder**","b7c960d5":"# Introduction\n\n**The Sign Language Dataset is used here, An approach using Autoencoders will be implemented**\n\n![](https:\/\/storage.googleapis.com\/kagglesdsdata\/datasets%2F3258%2F5337%2Famer_sign2.png?GoogleAccessId=databundle-worker-v2@kaggle-161607.iam.gserviceaccount.com&Expires=1596903587&Signature=IOtoOmYCiLXST2%2FX%2BrOp13lJNdRF%2FyEKXh8JDDUmIP%2FpM%2BpBzOs4SPAwqBdyoVDwIePM6UmiZzf6fhCRgOKYv2DZpkqTtyxRLRhS3saS3rEi%2BpnJH2Y%2F%2Bo6sfLZeV7yjiHhazWNlpq4UVxEHh11zLeHISfR93xWcba2dNRYoillLROPWpFs5fu8N1W6m9TvLfuO3dBkrMJRD%2Fj8j%2BLvduoCDmBAnDCSVadjdBpKVsrBRCsFctC5XDt79YmsGKxAX8lXQBN%2BLKZwZ0%2FlpP%2F%2BXSuEpqMp4cGartmwGBYLLVPfTJ0s6Pe9BHCp1EYmUJUOFZsRFd3Cy5yDLDmXqhLogMA%3D%3D)","b2e81b98":"**Checking for missing values**","f66dd3f2":"# LabelBinarizer\n\n**Binarize labels in a one-vs-all fashion**\n\n**Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.**\n\n**At learning time, this simply consists in learning one regressor or binary classifier per class. In doing so, one needs to convert multi-class labels to binary labels (belong or does not belong to the class). LabelBinarizer makes this process easy with the transform method.**\n\n**Here the values are in categorical(nominal) so we are using LabelBinarizer**","99b55d78":"**Let's see how the data looks like now**","0490f2d2":"**Let's create a separate Encoder Model as well**","d7fd0589":"# Displaying Images","69a8ead1":"**Let's Display the images in training data**","146465ee":"**So no missing data**","a91837c0":"# Let's start with AutoEncoders!!\n\n**An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation for a set of data, typically for dimensionality reduction**\n\n![](https:\/\/camo.githubusercontent.com\/5017c87b396b2745f13a289f913b037ea8352d50\/687474703a2f2f64726976652e676f6f676c652e636f6d2f75633f6578706f72743d766965772669643d3171546b5178373661424a4e68736b334954725542456644517a4451747a4d6330)\n\n**Here I am sharing some links that can give you heads-up about AutoEncoders**\n1. https:\/\/www.youtube.com\/watch?v=H1AllrJ-_30\n2. https:\/\/www.youtube.com\/watch?v=7mRfwaGGAPg","586b5550":"**One exception while training autoencoders is that it only trains itself on x_train and x_test, as they had been reshaped**"}}