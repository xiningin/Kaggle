{"cell_type":{"b01c4d40":"code","6d01d21c":"code","cd06df4c":"code","b74dc893":"code","4a4fa815":"code","820b061d":"code","04a78744":"code","07cffbb1":"code","50322bb4":"code","386a8a84":"code","bc6deaf5":"code","4aef7cdc":"code","a0586030":"code","b094f56b":"code","76987b3c":"code","3829a10f":"code","71d83282":"code","3ec2e3b2":"code","47e9d995":"code","03aedf37":"code","d605e7c4":"code","b491118c":"code","08b1e327":"code","4617a59e":"code","baf94046":"markdown","6cd6c10e":"markdown","3a56f589":"markdown","b2dad387":"markdown","ccb568d9":"markdown","878db1a0":"markdown","dec23fed":"markdown","509d23ff":"markdown","80593d0f":"markdown","72e2f6f7":"markdown","463aa865":"markdown","dbf285fd":"markdown","e579ea03":"markdown","26fea656":"markdown","e1c62403":"markdown","674e1a84":"markdown","9aea127a":"markdown","39a1f4d5":"markdown","57381ca2":"markdown","7d493151":"markdown","27a7de3d":"markdown","f2126006":"markdown","e6116b60":"markdown","36cebd7d":"markdown","3aa7cd97":"markdown"},"source":{"b01c4d40":"import numpy as np \nimport pandas as pd\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected = True)\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\npd.set_option('display.max_columns', None)","6d01d21c":"stroke = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","cd06df4c":"stroke.head(3)","b74dc893":"stroke.info()","4a4fa815":"stroke_i = stroke.drop('id', axis = 1)\nmatrix = np.triu(stroke_i.corr())\nplt.figure(figsize=(15, 10))\nsns.heatmap(stroke_i.corr(), annot = True, cmap = 'Blues', fmt=\".2f\", mask = matrix, vmin = -1, vmax = 1, linewidths = 0.1, linecolor = 'white')\nplt.show()","820b061d":"dst_st_gen = stroke.query('gender != \"Other\"').groupby(['gender', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\ndst_st_gen.iloc[[0, 2], 1] = \"didn't have a stroke\"\ndst_st_gen.iloc[[1, 3], 1] = \"had a stroke\"\n\nfig = px.sunburst(dst_st_gen, path = ['gender', 'stroke'], values = 'count', color = 'gender',\n                 color_discrete_map = {'Female': '#e381bc', 'Male': '#81a8e3'}, width = 700, height = 700)\n\nfig.update_layout(annotations = [dict(text = 'Distribution of stroke by gender', \n                                      x = 0.5, y = 1.1, font_size = 22, showarrow = False, \n                                      font_family = 'Arial Black',\n                                      font_color = 'black')])\n\nfig.update_traces(textinfo = 'label + percent parent')\n                  \nfig.show()","04a78744":"# Create age groups\nstroke['age_group'] = 0\nfor i in range(len(stroke.index)):\n    if stroke.iloc[i, 2] < 2:\n        stroke.iloc[i, 12] = 'baby'\n    elif stroke.iloc[i, 2] < 17 and stroke.iloc[i, 2] >= 2:\n        stroke.iloc[i, 12] = 'child'\n    elif stroke.iloc[i, 2] < 30 and stroke.iloc[i, 2] >= 17:\n        stroke.iloc[i, 12] = 'young adults'\n    elif stroke.iloc[i, 2] < 60 and stroke.iloc[i, 2] >= 30:\n        stroke.iloc[i, 12] = 'middle-aged adults'\n    elif stroke.iloc[i, 2] < 80 and stroke.iloc[i, 2] >= 60:\n        stroke.iloc[i, 12] = 'old-aged adults'\n    else:\n        stroke.iloc[i, 12] = 'long-lived'\n        \n# Imputing missing values in bmi\nmean_bmi = stroke.groupby(['gender', 'age_group']).agg({'bmi': 'mean'}).reset_index()\nfor i in range(len(stroke.index)):\n    if pd.isna(stroke.iloc[i, 9]) == True:\n        for j in range(len(mean_bmi.index)):\n            if mean_bmi.iloc[j, 0] == stroke.iloc[i, 1] and mean_bmi.iloc[j, 1] == stroke.iloc[i, 12]:\n                stroke.iloc[i, 9] = mean_bmi.iloc[j, 2]\n\n# Create bmi groups\nstroke['bmi_group'] = 0\nfor i in range(len(stroke.index)):\n    if stroke.iloc[i, 9] < 18.5:\n        stroke.iloc[i, 13] = 'Underweight'\n    elif stroke.iloc[i, 9] < 25.0 and stroke.iloc[i, 9] >= 18.5:\n        stroke.iloc[i, 13] = 'Normal weight'\n    elif stroke.iloc[i, 9] < 30.0 and stroke.iloc[i, 9] >= 25.0:\n        stroke.iloc[i, 13] = 'Overweight'\n    else:\n        stroke.iloc[i, 13] = 'Obese'\n        \n# Create glucose groups\nstroke['glucose_group'] = 0\nfor i in range(len(stroke.index)):\n    if stroke.iloc[i, 8] < 100:\n        stroke.iloc[i, 14] = 'Normal'\n    elif stroke.iloc[i, 8] >= 100 and stroke.iloc[i, 8] < 125:\n        stroke.iloc[i, 14] = 'Prediabetes'\n    else:\n        stroke.iloc[i, 14] = 'Diabetes'","07cffbb1":"# Grouping by categorical features\ndst_st_age = stroke.groupby(['age_group', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\nhyper = stroke.groupby(['hypertension', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\nheart = stroke.groupby(['heart_disease', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\nmarry = stroke.groupby(['ever_married', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\nwork = stroke.groupby(['work_type', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\nresidence = stroke.groupby(['Residence_type', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\nglucose_group = stroke.groupby(['glucose_group', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\nbmi_group = stroke.groupby(['bmi_group', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\nsmoking = stroke.query('smoking_status != \"Unknown\"').groupby(['smoking_status', 'stroke']).agg({'stroke': 'count'})\\\n.rename(columns = {'stroke': 'count'}).reset_index()\n\n# Create percent column for data frames\ndef percent(data):\n    data['percent'] = 0\n    for i in range(len(data.index)):\n        if i < len(data.index)-1:\n            if data.iloc[i, 0] == data.iloc[i+1, 0]:\n                data.iloc[i, 3] = round((data.iloc[i, 2] \/ (data.iloc[i, 2] + data.iloc[i+1, 2])) * 100, 1)\n            elif data.iloc[i, 0] == data.iloc[i-1, 0]:\n                data.iloc[i, 3] = 100 - data.iloc[i-1, 3]\n            else:\n                data.iloc[i, 3] = 100.0\n        else:\n            if data.iloc[i, 0] == data.iloc[i-1, 0]:\n                data.iloc[i, 3] = 100 - data.iloc[i-1, 3]\n            else:\n                data.iloc[i, 3] = 100.0\n            \npercent(dst_st_age)\npercent(hyper)\npercent(heart)\npercent(marry)\npercent(work)\npercent(residence)\npercent(glucose_group)\npercent(bmi_group)\npercent(smoking)\n\ndst_st_age.iloc[[0,2,4,6,8,10], 1] = \"Didn't have a stroke\"\ndst_st_age.iloc[[1,3,5,7,9], 1] = \"Had a stroke\"\n\nhyper.iloc[[0,1], 0] = 'No hypertension'\nhyper.iloc[[2,3], 0] = 'Hypertension'\n\nheart.iloc[[0,1], 0] = 'No heart diseases'\nheart.iloc[[2,3], 0] = 'Heart diseases'","50322bb4":"fig = plt.figure(figsize = (18, 60))\nfig.patch.set_facecolor('#fafafa')\n\nplt.subplot(921)\nsns.set_style('white')\nplt.title('Age group', size = 20, x = 1.1, y = 1.03)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\na = sns.barplot(data = dst_st_age, x = dst_st_age['age_group'], y = dst_st_age['count'], hue = dst_st_age['stroke'], palette = ['#1092c9','#c91010'])\nplt.xticks(rotation = 10)\nplt.ylabel('')\nplt.xlabel('')\nplt.legend(loc = 'upper left')\n\nplt.subplot(922)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\na2 = sns.barplot(data = dst_st_age, x = dst_st_age['age_group'], y = dst_st_age['percent'], hue = dst_st_age['stroke'], palette = ['#1092c9','#c91010'])\nplt.xticks(rotation = 10)\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(923)\nsns.set_style('white')\nplt.title('Hypertension', size = 20, x = 1.1, y = 1.03)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nb = sns.barplot(data = hyper, x = hyper['hypertension'], y = hyper['count'], hue = hyper['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(924)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nb2 = sns.barplot(data = hyper, x = hyper['hypertension'], y = hyper['percent'], hue = hyper['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(925)\nsns.set_style('white')\nplt.title('Heart deseases', size = 20, x = 1.1, y = 1.03)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nc = sns.barplot(data = heart, x = heart['heart_disease'], y = heart['count'], hue = heart['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(926)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nc2 = sns.barplot(data = heart, x = heart['heart_disease'], y = heart['percent'], hue = heart['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(927)\nsns.set_style('white')\nplt.title('Ever married', size = 20, x = 1.1, y = 1.03)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nd = sns.barplot(data = marry, x = marry['ever_married'], y = marry['count'], hue = marry['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(928)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nd2 = sns.barplot(data = marry, x = marry['ever_married'], y = marry['percent'], hue = marry['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(929)\nsns.set_style('white')\nplt.title('Work type', size = 20, x = 1.1, y = 1.03)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\ne = sns.barplot(data = work, x = work['work_type'], y = work['count'], hue = work['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(9,2,10)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\ne2 = sns.barplot(data = work, x = work['work_type'], y = work['percent'], hue = work['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(9,2,11)\nsns.set_style('white')\nplt.title('Residence type', size = 20, x = 1.1, y = 1.03)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nf = sns.barplot(data = residence, x = residence['Residence_type'], y = residence['count'], hue = residence['stroke'], palette = ['#1092c9','#c91010'])\n\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\nplt.subplot(9,2,12)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nf2 = sns.barplot(data = residence, x = residence['Residence_type'], y = residence['percent'], hue = residence['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(9,2,13)\nsns.set_style('white')\nplt.title('Glucose group', size = 20, x = 1.1, y = 1.03)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\ng = sns.barplot(data = glucose_group, x = glucose_group['glucose_group'], y = glucose_group['count'], hue = glucose_group['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(9,2,14)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\ng2 = sns.barplot(data = glucose_group, x = glucose_group['glucose_group'], y = glucose_group['percent'], hue = glucose_group['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(9,2,15)\nsns.set_style('white')\nplt.title('BMI group', size = 20, x = 1.1, y = 1.03)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nh = sns.barplot(data = bmi_group, x = bmi_group['bmi_group'], y = bmi_group['count'], hue = bmi_group['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(9,2,16)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nh2 = sns.barplot(data = bmi_group, x = bmi_group['bmi_group'], y = bmi_group['percent'], hue = bmi_group['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(9,2,17)\nsns.set_style('white')\nplt.title('Smoking', size = 20, x = 1.1, y = 1.03)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nj = sns.barplot(data = smoking, x = smoking['smoking_status'], y = smoking['count'], hue = smoking['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\nplt.subplot(9,2,18)\nplt.grid(color = 'gray', linestyle = ':', axis = 'y', zorder = 0,  dashes = (1,7))\nj2 = sns.barplot(data = smoking, x = smoking['smoking_status'], y = smoking['percent'], hue = smoking['stroke'], palette = ['#1092c9','#c91010'])\nplt.ylabel('')\nplt.xlabel('')\nplt.legend('').set_visible(False)\n\n# add annotations\nfor i in [a,b,c,d,e,f,g,h,j]:\n    for p in i.patches:\n        height = p.get_height()\n        i.annotate(f'{height:g}', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\n\nfor i in [a2,b2,c2,d2,e2,f2,g2,h2,j2]:\n    for p in i.patches:\n        height = p.get_height()\n        i.annotate(f'{height:g}%', (p.get_x() + p.get_width() \/ 2, p.get_height()), \n                   ha = 'center', va = 'center', \n                   size = 10,\n                   xytext = (0, 5), \n                   textcoords = 'offset points')\n        \nplt.show()","386a8a84":"fig = plt.figure(figsize = (18, 18))\nfig.patch.set_facecolor('#fafafa')\n\nplt.subplot(221)\nsns.set_style(\"dark\")\nplt.title('Age', size = 20)\nsns.kdeplot(stroke.query('stroke == 1')['age'], color = '#c91010', shade = True, label = 'Had a stroke', alpha = 0.5)\nsns.kdeplot(stroke.query('stroke == 0')['age'], color = '#1092c9', shade = True, label = \"Didn't have a stroke\", alpha = 0.5)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\nplt.legend(loc = 'upper left')\n\nplt.subplot(222)\nplt.title('Body mass index', size = 20)\nsns.kdeplot(stroke.query('stroke == 1')['bmi'], color = '#c91010', shade = True, label = 'Had a stroke', alpha = 0.5)\nsns.kdeplot(stroke.query('stroke == 0')['bmi'], color = '#1092c9', shade = True, label = \"Didn't have a stroke\", alpha = 0.5)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\nplt.legend('').set_visible(False)\n\nplt.subplot(223)\nplt.title('Glucose level', size = 20)\nsns.kdeplot(stroke.query('stroke == 1')['avg_glucose_level'], color = '#c91010', shade = True, label = 'Had a stroke', alpha = 0.5)\nsns.kdeplot(stroke.query('stroke == 0')['avg_glucose_level'], color = '#1092c9', shade = True, label = \"Didn't have a stroke\", alpha = 0.5)\nplt.grid(color = 'gray', linestyle = ':', axis = 'x', zorder = 0,  dashes = (1,7))\nplt.ylabel('')\nplt.xlabel('')\nplt.yticks([])\nplt.legend('').set_visible(False)\n\nplt.show()","bc6deaf5":"main = stroke.groupby(['age_group', 'heart_disease', 'stroke']).agg({'stroke': 'count'}).rename(columns = {'stroke': 'count'}).reset_index()\nht = {0: 'No heart diseases', 1: 'Heart diseases'}\nst = {0: \"Didn't have a stroke\", 1: \"Had a stroke\"}\nmain['heart_disease'] = main['heart_disease'].map(ht)\nmain['stroke'] = main['stroke'].map(st)\n\nfig = px.sunburst(main, path = ['stroke', 'age_group', 'heart_disease'], values = 'count', color = 'stroke', title = 'Distribution of stroke by age group and heart diseases',\n                 color_discrete_map = {\"Didn't have a stroke\": '#1092c9', \"Had a stroke\": '#c91010'},\n                 width = 700, height = 700)\n\nfig.update_layout(plot_bgcolor = 'white', title_font_family = 'Calibri Black', title_font_color = '#221f1f', title_font_size = 22, title_x = 0.5)\n\nfig.update_traces(textinfo = 'label + percent parent')\n                  \nfig.show()","4aef7cdc":"X = stroke.drop(['id', 'stroke'], axis = 1)\ny = stroke['stroke']\n\nnum_cols = X.select_dtypes(include = ['int64', 'float64']).columns.to_list()\ncat_cols = X.select_dtypes(include = ['object']).columns.to_list()","a0586030":"def label_encoder(df):\n    for i in cat_cols:\n        le = LabelEncoder()\n        df[i] = le.fit_transform(df[i])\n    return df","b094f56b":"sc = StandardScaler()\nX[num_cols] = sc.fit_transform(X[num_cols])\n\n# Label encoding\nX = label_encoder(X)\n\nX.head()","76987b3c":"stroke['stroke'].value_counts()","3829a10f":"from imblearn.over_sampling import SMOTE\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 22)\n\nsmote = SMOTE()\n\nX_train_balanced, Y_train_balanced = smote.fit_resample(X_train, y_train)","71d83282":"results = pd.DataFrame(columns = ['SVC', 'KNN', 'LR', 'RF', 'XGB', 'LGBM'], index = range(4))","3ec2e3b2":"svc = SVC(random_state = 22, probability = True)\nsvc.fit(X_train_balanced, Y_train_balanced)\ny_pred = svc.predict(X_test)\ny_prob = svc.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 0] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 0] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 0] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 0] = round(roc_auc_score(y_test, y_prob), 3)\nsvc_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(svc, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(svc, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(svc, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(svc, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(svc_cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","47e9d995":"knn = KNeighborsClassifier()\nknn.fit(X_train_balanced, Y_train_balanced)\ny_pred = knn.predict(X_test)\ny_prob = knn.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 1] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 1] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 1] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 1] = round(roc_auc_score(y_test, y_prob), 3)\nknn_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(knn, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(knn, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(knn, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(knn, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(knn_cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","03aedf37":"lg = LogisticRegression(random_state = 22)\nlg.fit(X_train_balanced, Y_train_balanced)\ny_pred = lg.predict(X_test)\ny_prob = lg.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 2] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 2] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 2] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 2] = round(roc_auc_score(y_test, y_prob), 3)\nlg_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(lg, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(lg, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(lg, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(lg, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(lg_cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15}, \n            yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# Feature importance\nf_imp = pd.DataFrame(columns = ['feature', 'importance (abs coef)'], index = range(13))\nfor i in range(len(f_imp.index)):\n    f_imp.iloc[i, 0] = X_train_balanced.columns.to_list()[i]\nf_imp['importance (abs coef)'] = abs(lg.coef_)[0]\nf_imp = f_imp.sort_values('importance (abs coef)', ascending = False)\nf_imp[0:12].style.background_gradient(cmap = 'Blues')","d605e7c4":"rf = RandomForestClassifier(random_state = 22, max_depth = 5)\nrf.fit(X_train_balanced, Y_train_balanced)\ny_pred = rf.predict(X_test)\ny_prob = rf.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 3] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 3] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 3] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 3] = round(roc_auc_score(y_test, y_prob), 3)\nrf_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(rf, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(rf, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(rf, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(rf, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(rf_cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},\n           yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# Feature importance\nf_imp2 = pd.DataFrame(columns = ['feature', 'importance'], index = range(13))\nfor i in range(len(f_imp2.index)):\n    f_imp2.iloc[i, 0] = X_train_balanced.columns.to_list()[i]\nf_imp2['importance'] = rf.feature_importances_\nf_imp2 = f_imp2.sort_values('importance', ascending = False)\nf_imp2[0:12].style.background_gradient(cmap = 'Blues')","b491118c":"xgb = XGBClassifier(random_state = 22, max_depth = 5, objective = 'binary:logistic', eval_metric = 'logloss')\nxgb.fit(X_train_balanced, Y_train_balanced)\ny_pred = xgb.predict(X_test)\ny_prob = xgb.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 4] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 4] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 4] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 4] = round(roc_auc_score(y_test, y_prob), 3)\nxgb_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(xgb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(xgb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(xgb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(xgb, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(xgb_cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},\n           yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# Feature importance\nf_imp3 = pd.DataFrame(columns = ['feature', 'importance'], index = range(13))\nfor i in range(len(f_imp3.index)):\n    f_imp3.iloc[i, 0] = X_train_balanced.columns.to_list()[i]\nf_imp3['importance'] = xgb.feature_importances_\nf_imp3 = f_imp3.sort_values('importance', ascending = False)\nf_imp3[0:12].style.background_gradient(cmap = 'Blues')","08b1e327":"lgbm = LGBMClassifier(random_state = 22, max_depth = 5, num_leaves = 50)\nlgbm.fit(X_train_balanced, Y_train_balanced)\ny_pred = lgbm.predict(X_test)\ny_prob = lgbm.predict_proba(X_test)[:,1]\n\n# Metrics\nresults.iloc[0, 5] = round(precision_score(y_test, y_pred), 2)\nresults.iloc[1, 5] = round(recall_score(y_test, y_pred), 2)\nresults.iloc[2, 5] = round(f1_score(y_test, y_pred), 2)\nresults.iloc[3, 5] = round(roc_auc_score(y_test, y_prob), 3)\nlgbm_cm = confusion_matrix(y_test, y_pred)\n\nprint(classification_report(y_test, y_pred))\nprint(f'ROC AUC score: {round(roc_auc_score(y_test, y_prob), 3)}')\nprint('')\nprint('-----------------------------------------------------')\nprint('')\nprint('Cross-validation scores with 5 folds:')\nprint('')\nprint(f\"ROC AUC: {round(cross_val_score(lgbm, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'roc_auc').mean(), 3)}\")\nprint(f\"precision: {round(cross_val_score(lgbm, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'precision').mean(), 2)}\")\nprint(f\"recall: {round(cross_val_score(lgbm, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'recall').mean(), 2)}\")\nprint(f\"f1: {round(cross_val_score(lgbm, X_train_balanced, Y_train_balanced, cv = 5, scoring = 'f1').mean(), 2)}\")\n\n# Visualize confusion matrix\nplt.figure(figsize = (8, 5))\nsns.heatmap(lgbm_cm, cmap = 'Blues', annot = True, fmt = 'd', linewidths = 5, cbar = False, annot_kws = {'fontsize': 15},\n           yticklabels = ['No stroke', 'Stroke'], xticklabels = ['Predicted no stroke', 'Predicted stroke'])\nplt.yticks(rotation = 0)\nplt.show()\n\n# Roc curve\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\nsns.set_theme(style = 'white')\nplt.figure(figsize = (8, 8))\nplt.plot(false_positive_rate,true_positive_rate, color = '#b01717', label = 'AUC = %0.3f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1], linestyle = '--', color = '#174ab0')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n# Feature importance\nf_imp4 = pd.DataFrame(columns = ['feature', 'importance'], index = range(13))\nfor i in range(len(f_imp4.index)):\n    f_imp4.iloc[i, 0] = X_train_balanced.columns.to_list()[i]\nf_imp4['importance'] = lgbm.feature_importances_\nf_imp4 = f_imp4.sort_values('importance', ascending = False)\nf_imp4[0:12].style.background_gradient(cmap = 'Blues')","4617a59e":"plt.figure(figsize = (10, 7))\nsns.heatmap(results[results.columns.to_list()].astype(float), cmap = 'Blues', annot = True, linewidths = 1, cbar = False, annot_kws = {'fontsize': 12},\n           yticklabels = ['Precision', 'Recall', 'F1', 'ROC AUC'])\nsns.set(font_scale = 1.5)\nplt.yticks(rotation = 0)\nplt.show()","baf94046":"![](https:\/\/houseclever.ru\/netcat_files\/images\/1575471993_istock.webp)","6cd6c10e":"For body mass index classify I used information from [American cancer society](https:\/\/www.cancer.org\/cancer\/cancer-causes\/diet-physical-activity\/body-weight-and-cancer-risk\/adult-bmi.html). For classificaton by average glucose level I used information from [GLOBAL DIABETES COMMUNITY](https:\/\/www.diabetes.co.uk\/diabetes_care\/blood-sugar-level-ranges.html).","3a56f589":"**Distribution of stroke by gender**","b2dad387":"# KNN","ccb568d9":"**Affect of age group, hypertension, heart diseases, living conditions, group of bmi, group of glucose level and smoking status on risk of stroke**","878db1a0":"# Random Forest Classifier","dec23fed":"# Logistic Regression","509d23ff":"# Conclusion","80593d0f":"# LGBM","72e2f6f7":"So, we should to do SMOTE (Synthetic Minority Over-sampling Technique) - one of the most commonly used resampling techniques to solve the imbalance problem.","463aa865":"But we have an imbalanced data. Standard ML methods, such as Decision Tree and Logistic Regression, tend to deviate from the majority class and tend to ignore the minority class. They tend to only predict the majority class, hence have a significant misclassification of the minority class as compared to the majority class.","dbf285fd":"**Short summary - if it is important for us to identify all people who may have a stroke (good recall), then it is best to cope with this task with Random Forest, but if we are interested in the precision of predictions, then we should choose XGB (although the difference in precision is negligible). We can also change the standard threshold of 0.5 for assignment to one of the classes to increase one of the metrics.**\n\n**Predicting a stroke based on basic data seems like something fantastic, but the fact that Random Forest without tuning and only with 5110 observations can find ~70% of those who have had a stroke is an excellent result!**\n\n**But, in my opinion, the number of people for this medical analysis is very small, it would be more interesting and practical to make an analysis on a sample of 100 thousand or more people.**","e579ea03":"There are 201 missing values in bmi","26fea656":"# XGBClassifier","e1c62403":"# Basic information","674e1a84":"1. Based on the data, gender does not affect the probability of stroke, but in fact men have a higher risk of stroke, howewer, women have a higher mortality rate from stroke. This is a medical fact.\n2. There is a large correlation between age and stroke risk. Almost all doctors know that stroke is most often an age problem. However, this can also happen with childs, in the available data in groups \"baby\" and \"child\", 2 people had a stroke.\n3. The presence of hypertension or heart diseases have affect on stroke risk.\n4. People who are married have a higher risk of stroke. I think it's a coincidence.\n5. The author of the dataset did not specify what is meant \"children\" type of work, working with children in kindergartens and schools or caring for their children, but in any case children have a positive impact on the health of adults.\n6. Living in a rural or urban areas does not affect the risk of stroke in any way.\n7. Smoking also does not affect the risk of stroke. If draw conclusions only by the data, then yes, but if you have at least the slightest knowledge of medicine, you should know that smoking leads to problems with blood vessels, and this in turn can lead to heart diseases or hypertension, which is already a problem.\n8. Obesity leads not only to problems with blood vessels and many others, but also to the risk of stroke.\n9. Diabetes has an impact on the risk of stroke.","9aea127a":"**Affect of age, body mass index and average glucose level on risk of stroke**","39a1f4d5":"# Modeling","57381ca2":"# EDA","7d493151":"# SVC","27a7de3d":"Correlation between features","f2126006":"# Preprocessing","e6116b60":"# Conclusions of EDA","36cebd7d":"**Affect of age group and heart diseases**","3aa7cd97":"**For modeling I try to use 6 models:**\n\n1. SVC, \n2. KNN,\n3. Logistic Regression,\n4. Random Forest Classifier,\n5. XGBClassifier,\n6. LGBMClasifier."}}