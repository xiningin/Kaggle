{"cell_type":{"ca69f7ee":"code","34e25d85":"code","e8527b91":"code","ea6d2312":"code","b519d56b":"code","f8541073":"code","edac3ab5":"code","0adfad02":"code","5da303e5":"code","38a80f1f":"code","4257da06":"code","b5e50c8d":"code","4179a958":"code","254df582":"code","6372b7ad":"code","700b36ff":"code","fdc0bda2":"code","7a5e19e4":"code","79202955":"code","a1044bf7":"code","d35f449f":"code","379d3d70":"code","a67a3a28":"code","11bd6e64":"code","1a96e019":"code","76165e5e":"markdown","3bd7e278":"markdown","c83b680f":"markdown","58914fdd":"markdown","12601f2b":"markdown","e0163975":"markdown","1a5441ec":"markdown","0576f290":"markdown","4f812ba8":"markdown","493cc55c":"markdown","d8004216":"markdown","cab4cc9d":"markdown","68a7ff97":"markdown","f55167ae":"markdown","7ee86776":"markdown","12627915":"markdown","e1c9dabd":"markdown","9125241b":"markdown","b6ed694b":"markdown","8a405c7a":"markdown","3b43f3d2":"markdown","e08d26be":"markdown","76622680":"markdown","e72baed7":"markdown","95d29aff":"markdown"},"source":{"ca69f7ee":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport re\nimport warnings\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.feature_extraction import text\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.svm import SVC\n\nwarnings.filterwarnings(\"ignore\")","34e25d85":"%%time\n# Use session storage\ndf = pd.read_csv('..\/input\/roman-urdu-dataset\/Roman Urdu DataSet.csv',\n                 encoding='utf8')\n\n# Use Google Drive - Colab\n#df = pd.read_csv('\/content\/drive\/My Drive\/working_data\/roman_urdu\/Roman Urdu DataSet.csv',\n#                 encoding='utf8')\n\n# Save a clean copy for later\nclean_copy = df.copy()  \nprint('Original data shape: {}'.format(df.shape))","e8527b91":"df.head()","ea6d2312":"colunm_names = ['phrase','target','unexpected']\ndf.columns = colunm_names","b519d56b":"df.head()","f8541073":"df['unexpected'].value_counts()","edac3ab5":"df.drop('unexpected', axis=1, inplace=True)","0adfad02":"phrase_col = 'phrase'\ntarget_col = 'target'\ndf[target_col].value_counts()","5da303e5":"correct_labels = ['Positive', 'Negative', 'Neutral']\ndf = df[df.target.isin(correct_labels)]\ndf[target_col].value_counts()","38a80f1f":"plt.figure(figsize=(12,8))\nsns.countplot(x=target_col, data=df)\nplt.ylabel('Frequency', fontsize=12)\nplt.xlabel('Class Count', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Frequency of Classes\", fontsize=15)\nplt.show()","4257da06":"df.describe()","b5e50c8d":"df.isnull().sum()","4179a958":"print(df[df.duplicated(keep='first')])","254df582":"# Preprocessing function to encapsulate steps \n# We want to support other column names, stopwords,\n# and target values in the future\ndef processing(data, stopwords, col_names, target_vals):\n    # Name the columns\n    data.columns = col_names\n    # Drop extra column\n    data.drop('unexpected', axis=1, inplace=True)\n    # Remove bad labels\n    data = data[data.target.isin(target_vals)]\n    # Lowercase phrases and remove punctuation\n    data['processed'] = data['phrase'].apply(lambda x: re.sub(r'[^\\w\\s]','', str(x).lower()))\n    # Total length of phrase\n    data['length'] = data['processed'].apply(lambda x: len(x))\n    # Number of words\n    data['num_words'] = data['processed'].apply(lambda x: len(x.split(' ')))\n    # Subtract the stopwords\n    data['words_not_stopwords'] = data['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopwords]))\n    #get the average word length\n    data['avg_word_length'] = data['processed'].apply(lambda x: np.mean(\n        [len(t) for t in x.split(' ') if t not in stopwords]) if len(\n            [len(t) for t in x.split(' ') if t not in stopwords]) > 0 else 0)\n    return data","6372b7ad":"stopwords_list = ['ai', 'ayi', 'hy', 'hai', 'main', 'ki', 'tha', 'koi', 'ko', \n                  'sy', 'woh', 'bhi', 'aur', 'wo', 'yeh', 'rha', 'hota', 'ho', \n                  'ga', 'ka', 'le', 'lye', 'kr', 'kar', 'lye', 'liye', \n                  'hotay', 'waisay', 'gya', 'gaya', 'kch', 'ab', 'thy', 'thay', \n                  'houn', 'hain', 'han', 'to', 'is', 'hi', 'jo', 'kya', 'thi', \n                  'se', 'pe', 'phr', 'wala', 'waisay', 'us', 'na', 'ny', 'hun', \n                  'rha', 'raha', 'ja', 'rahay', 'abi', 'uski', 'ne', 'haan', \n                  'acha', 'nai', 'sent', 'photo', 'you', 'kafi', 'gai', 'rhy', \n                  'kuch', 'jata', 'aye', 'ya', 'dono', 'hoa', 'aese', 'de', \n                  'wohi', 'jati', 'jb', 'krta', 'lg', 'rahi', 'hui', 'karna', \n                  'krna', 'gi', 'hova', 'yehi', 'jana', 'jye', 'chal', 'mil', \n                  'tu', 'hum', 'par', 'hay', 'kis', 'sb', 'gy', 'dain', 'krny', \n                  'tou']\n\nstopwords = set(stopwords_list)\ncol_names = ['phrase', 'target', 'unexpected']\ntarget_values = ['Positive', 'Negative', 'Neutral']","700b36ff":"# Revert to a clean copy\ndf = clean_copy.copy()\ndf_processed = processing(df, stopwords, col_names, target_values)\ndf_processed.head()","fdc0bda2":"# Set feature columns\nSEED = 37\nfeatures = [col for col in df_processed.columns.values \n            if col  not in ['phrase', 'target']]\nnum_features = [col for col in df_processed.columns.values \n                if col  not in ['phrase','target','processed']]\ntarget = 'target'","7a5e19e4":"# Split the data\nTRAIN_SPLIT = .8\n\nX_train, X_test, y_train, y_test = train_test_split(df_processed[features], \n                                                    df_processed[target],\n                                                    train_size=TRAIN_SPLIT,\n                                                    shuffle=True,\n                                                    random_state=SEED)\nprint('{} training records'.format(len(X_train)))","79202955":"# Text feature selector\nclass TextSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[self.key]\n\n# Numeric feature selector    \nclass NumericSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[[self.key]]","a1044bf7":"tfidf_pipeline = Pipeline([\n                ('selector', TextSelector(key='processed')),\n                ('tfidf', TfidfVectorizer())])\n\nlength_pipeline =  Pipeline([\n                ('selector', NumericSelector(key='length')),\n                ('standard', StandardScaler())\n            ])\n\nwords_pipeline =  Pipeline([\n                ('selector', NumericSelector(key='num_words')),\n                ('standard', StandardScaler())\n            ])\n\nwords_not_stopword_pipeline =  Pipeline([\n                ('selector', NumericSelector(key='words_not_stopwords')),\n                ('standard', StandardScaler())\n            ])\n\navg_word_length_pipeline =  Pipeline([\n                ('selector', NumericSelector(key='avg_word_length')),\n                ('standard', StandardScaler())\n            ])\n\nfeature_pipeline = FeatureUnion([('tfidf', tfidf_pipeline), \n                                 ('length', length_pipeline),\n                                 ('words', words_pipeline),\n                                 ('words_not_stopword', words_not_stopword_pipeline),\n                                 ('avg_word_length', avg_word_length_pipeline)])\n\nfeature_processing = Pipeline([('features', feature_pipeline)])\nfeature_processing.fit_transform(X_train)","d35f449f":"# Encode the labels\nencoder = LabelEncoder()\nencoder.fit(y_train)\nencoder.classes_","379d3d70":"y_train_enc = encoder.transform(y_train)\ny_test_enc = encoder.transform(y_test)","a67a3a28":"tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10]},\n                    {'kernel': ['linear'], 'C': [1, 10]}]\n\nscores = ['precision', 'recall']","11bd6e64":"for score in scores:\n  print('Tuning hyper-parameters for %s \\n' % score)\n  print ('Creating pipeline instance.')\n  sentiment_pipeline = Pipeline([\n                ('features',feature_pipeline),\n                ('classifier', GridSearchCV(SVC(),\n                tuned_parameters, \n                scoring='%s_macro' % score,\n                verbose=10,\n                n_jobs=-1,\n                cv=3))])\n \n  print('Fitting the model.')\n  sentiment_pipeline.fit(X_train, y_train_enc)\n\n  print('Tuning hyper-parameters for %s \\n' % score)\n  print('Best parameters set found on development set: \\n')\n  print(sentiment_pipeline.named_steps['classifier'].best_params_, '\\n')\n  print(\"Grid scores on development set:\\n\")\n  means = sentiment_pipeline.named_steps['classifier'].cv_results_['mean_test_score']\n  stds = sentiment_pipeline.named_steps['classifier'].cv_results_['std_test_score']\n  for mean, std, params in zip(means, stds, sentiment_pipeline.named_steps['classifier'].cv_results_['params']):\n      print(\"%0.3f (+\/-%0.03f) for %r\"\n            % (mean, std * 2, params))\n  print()\n  print('Detailed classification report:\\n')\n  print('The model is trained on the full development set.')\n  print('The scores are computed on the full evaluation set.\\n')\n  y_true, y_pred = y_test, sentiment_pipeline.predict(X_test)\n  print(classification_report(y_test_enc, y_pred), '\\n')","1a96e019":"cm = confusion_matrix(y_test_enc, y_pred)\nfig = plt.figure(figsize = (10,7))\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nplt.title('Confusion matrix for SVC')\nfig.colorbar(cax)\nlabels = ['Negative', 'Neutral', 'Positive']\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","76165e5e":"### Check for Empty Records","3bd7e278":"Roman Urdu stopwords list from [GitHub](https:\/\/github.com\/mirfan899\/roman-urdu-stopwords\/blob\/master\/stopwords.txt).","c83b680f":"## Feature Engineering\n\nNow that we have discovered the basic cleanup procedures required, I am going to some basic text feature engineering.\n\n**`Requirement:`**  The requirements from the customer specify evolving this solution into a multilingual sentiment application. \n\nFor a production system, if the client requirements did not involve unsupported languages, I would put all of the data preperation and feature engineering steps into an SKLearn pipeline. I this would produce more repeatable and reliable model training process.\n\nAn academic paper on multilingual pipelines can be found [here](https:\/\/www.frederikhogenboom.nl\/work\/papers\/wise11-slang.pdf).\n\nI will implement a flexible pipeline, to the extent possible, in this work sample.","58914fdd":"### View Distribution of Targets","12601f2b":"Finally, let's take a look at the confusion matrix to see how the model performed.","e0163975":"We have quite a few more neutral reviews than positive and negative. The positive and negative counts are close enough.\n\n**`Requirement:`** One of the requirements of the work sample is to document how data limitations impact the result, and what I might do on a larger project.\n\nWhen the class distribution is unbalanced, the model favors predicting the most frequent class. Accuracy can be a poor choice of evaluation metric for a classifier if the data is unbalanced as well.\n\nOn a larger project, I might consider a technique such as GAN minority oversampling to balance out the dataset.\n\nThe simplest way to fix imbalanced dataset is simply balancing them by oversampling instances of the minority class or undersampling instances of the majority class. That is what I will choose to do in this case.\n\n","1a5441ec":"### Build the Pipeline","0576f290":"###\u00a0Initial Cleaning","4f812ba8":"Based on the metrics for precision, recall, and F1 scores, I am going to select the these hyperparameters for the final model:\n\n{'C': 1, 'kernel': 'linear'}\n\nThis gives me a macro average precision of 0.67 and a recall of 0.63.\n\nI'm, not particularly happy with these results. In a production application, I would:\n\n1. Gather more labled data in Roman Urdu\n2. Balance out the dataset.\n\nHowever, for this work sample, I'm going to stop here. I've got stuff to do. Peace.","493cc55c":"# Sentiment Identification in UCI Roman Urdu Data Set Data Set\n## Data Description\n\n\n1.   Number of records: 20000\n2.   Text data\n3.   Two string data type values per record\n4.   Tagged for Sentiment (Positive, Negative, Neutral)\n5.   The training data includes documents from a wide variety of sources\n\n[Dataset link](http:\/\/archive.ics.uci.edu\/ml\/datasets\/Roman+Urdu+Data+Set)\n\n## Goal\n* Train a sentiment classifier on the corpus of the dataset \n* Maximize accuracy of the classifier\n* I want to be more sensitive to identifying negative\n\n## Plan of Work\n1. Load and clean up the data\n2. Do some exploratory data analysis\n3. Do some basic text feature engineering\n4. Train and evaluate model(s)\n5. Select best model based on metrics","d8004216":"We have an unexpected value in our labels. We will have to account for that in the pipeline. I\u00b4m going to drop it, because I can\u00b4t automate for every spelling error in the labels.","cab4cc9d":"### Preprocessing the Data","68a7ff97":"## Build and Evaluate Models","f55167ae":"### Duplicate Rows Check","7ee86776":"Lookin' good. I'm going to start building and evaluating some models.","12627915":"There is one null review. I will deal with that in a bit.\n\n","e1c9dabd":"It looks like an extra column I wasn`t expecting. I\u00b4m also going to rename the first columns. I will set up a data pipeline later to automate all of the changes.  I\u00b4ll start by renaming the columns for convenience.","9125241b":"## Data Exploration\n\nLet\u00b4s take a look at the details of the dataset.","b6ed694b":"I can see right away the dataset is not the shape I expected. The data description has two columns, but we seem to be picking up an extra column from the CSV.","8a405c7a":"I'm going to drop those duplicates later.","3b43f3d2":"### Load the Data","e08d26be":"Since we are sensitive to identifying true negatives, I'm going to take a look at the best tuning options for precision and recall, based on SciKit Learn documentation [here](https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_grid_search_digits.html), integrated into the development pipeline.\n\nNote: I'm going to do a limited grid search here. For a production solution, it would be more extensive.\n\nI am going to use 3 cross validation folds.","76622680":"I\u00b4m going to go ahead and drop the extra column.","e72baed7":"**Note:** I tried under-sampling to balance out the dataset. It was actually cournter productive in terms of accuracy, so I removed it. For a real project, I would move on to balancing the dataset in additive ways, such as SMOTE or GAN.","95d29aff":"## Final Model Selection"}}