{"cell_type":{"9df8802a":"code","b455b9a4":"code","df45398c":"code","4128292d":"code","a7531b3b":"code","cbede897":"code","de132a43":"code","36c35bb9":"code","69184027":"code","65761989":"code","46942c51":"code","86076a11":"code","ea8142d0":"code","bfde3e97":"code","a1900ce9":"code","9101be94":"code","a9e44a43":"code","1ddc74ae":"code","9ac19522":"code","6c26af05":"code","575235ba":"code","059f07c1":"code","0033bf37":"code","15d1b2d4":"code","137eb3b3":"code","5b04eb07":"code","7021f15d":"code","dce55586":"code","b6f0ad0e":"code","24b0dd8a":"code","59636b3b":"code","68460900":"code","c9cf887a":"code","7dac2c00":"code","451d0926":"code","be383bee":"code","8f8e1066":"code","24fbb366":"code","39c42388":"code","26c0307a":"code","72bff14e":"code","8fd3d67b":"code","16491a85":"code","dd2a6789":"code","93e0e8bc":"code","ea4bee94":"code","8458f8f4":"code","bf50d24f":"code","0b78d80e":"code","10b49d3e":"code","ab39d6b1":"code","c0a6f4df":"code","744ca6c9":"code","edf2cd21":"code","d3e879a1":"code","e5df07a9":"code","64565a81":"code","adf30a64":"code","f09581d6":"code","98530e17":"code","d391302c":"code","2b7548b1":"code","2167048b":"code","7ee04402":"code","ae24009e":"code","b4ce033e":"code","e915b016":"code","f1eeb24b":"code","0efb988c":"code","f5a68e34":"code","d91dff4f":"code","97020574":"code","2f9476db":"markdown","dbcdf0e3":"markdown","ea2b5a38":"markdown","231c3e89":"markdown","5ed2cce3":"markdown","54d1790f":"markdown","5e884a54":"markdown","7e7ccaa2":"markdown","17e30f9a":"markdown","e80496fc":"markdown","bfdff89c":"markdown","462b2516":"markdown","5695f9e9":"markdown","58749d8d":"markdown","bd544068":"markdown","871cb043":"markdown","4f1c359f":"markdown","d5f006ed":"markdown"},"source":{"9df8802a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b455b9a4":"!pip install xlrd","df45398c":"data = pd.read_excel('..\/input\/mskcc-prostate-cancer-dataset\/MSKCC_PCa_Clinical_Annotation.xls')\n\npd.set_option('max_columns', None)\npd.set_option('max_rows', None)","4128292d":"data.head()","a7531b3b":"# Transformation 1\ndata1 = data.drop(range(13), axis=0)\nn1 = data1.shape[0]","cbede897":"data1.head()","de132a43":"colnames = data1.columns\nfor colname in colnames:\n    print(colname+\" :\"+str((data1[colname].isna().sum() \/ data1.shape[0])*100))","36c35bb9":"# 98% of NeoAdjRadTx data is NaN, so we'll drop it\n(data1['NeoAdjRadTx'].isna().sum() \/ n1)*100","69184027":"# 83% of MetSite is NaN, drop it\n(data1['MetSite'].isna().sum() \/ n1)*100","65761989":"# 85% of ChemoTx is NaN, drop it\n(data1['ChemoTx'].isna().sum() \/ n1)*100","46942c51":"# 70% of HormTx is NaN, drop it\n(data1['HormTx'].isna().sum() \/ n1)*100","86076a11":"# 83% of RadTxType is NaN, drop it\n(data1['RadTxType'].isna().sum() \/ n1)*100","ea8142d0":"data2 = data1.drop(['NeoAdjRadTx', 'MetSite', 'ChemoTx', 'HormTx', 'RadTxType'], axis=1)","bfde3e97":"data3 = data2.drop(['Sample ID'], axis=1).drop([231], axis=0)","a1900ce9":"# Checking for the NA values in PSA diagnosis\n(data3[['PreDxBxPSA','PreTxPSA']].isna().sum() \/ data3.shape[0]) *100","9101be94":"# Checking for correlation between the two PSA levels\ndata3[['PreDxBxPSA','PreTxPSA']].corr()","a9e44a43":"# Checking for NaN values in ClinT Stage\n(data3['ClinT_Stage'].isna().sum() \/ len(data3))*100","1ddc74ae":"# We can see two bands of columns with nan values. Lets drop all the values from the band with lower nan values.\nnan_value_list = (data3.isna().sum() \/ len(data3))*100\ncolumn_ids = np.arange(len(data3.columns))\nplt.figure()\nplt.bar(column_ids, nan_value_list)\nplt.title('Percentage of NaN values in data3')\nplt.show()","9ac19522":"data3.head()","6c26af05":"nan_value_list = (data3.isna().sum() \/ len(data3))*100\nnan_below_15 = nan_value_list[nan_value_list < 15].index\ndata4 = data3.dropna(subset=nan_below_15)","575235ba":"nan_value_list = data4.isna().sum()\nnan_not_zero = nan_value_list[nan_value_list > 0].index\nnan_not_zero","059f07c1":"data5 = data4.drop(nan_not_zero, axis=1)\ndata5['PathGGS'] = pd.to_numeric(data5['PathGGS']) # PathGGS was an object datatype\ndata5['Copy-number Cluster'] = data5['Copy-number Cluster'].apply(str)\ndata5 = data5.astype({'Copy-number Cluster':'category'}) #Change to a categorical datatype","0033bf37":"num_data = data5._get_numeric_data()\nnum_data.describe()","15d1b2d4":"data6 = data5.drop(['PathGG1','PathGG2','PreTxPSA'], axis=1)","137eb3b3":"data6.head()","5b04eb07":"data7 = data6.drop(['BCR_FreeTime','BCR_Event'], axis=1)","7021f15d":"data7.head()","dce55586":"data8 = data7.drop(['BxGGS','SMS','ECE','SVI','LNI','PathStage','Event','SurvTime', 'MetsEvent'], axis=1)\ndata8.head()","b6f0ad0e":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, RepeatedKFold, RepeatedStratifiedKFold, cross_validate, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import RFE, RFECV\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np\nimport time","24b0dd8a":"# # Small hack to get the engineered data in R\n# Rdata = data8.copy()\n# Rdata.to_csv('data8.csv')","59636b3b":"from sklearn.model_selection import train_test_split","68460900":"X = data8.drop(['PathGGS'], axis=1)\ny = data8['PathGGS']\n\ny_comb = y.replace(7,'1').replace(8,'1').replace(9,'1')\ny_comb = y_comb.replace(6,'0')\ny_comb = y_comb.apply(int)","c9cf887a":"len(y_comb)","7dac2c00":"# X_train,X_valid, y_train, y_valid = train_test_split(X,y_comb,test_size=0.4, random_state=12, stratify=y)","451d0926":"plt.figure()\nsns.countplot(x=y_comb, order=[0,1])\nplt.xticks(ticks=[0,1], labels=['6','7+'])\nplt.title('Count Plot for PathGGS (After Combining)')\nplt.savefig('PathGGS_2.png')\nplt.show()","be383bee":"# plt.figure()\n# sns.countplot(x=y_valid, order=[0,1])\n# plt.xticks(ticks=[0,1], labels=['6','7+'])\n# plt.title('Frequency of each category in PathGGS (Validation set)')\n# plt.show()","8f8e1066":"print(\"Dataset dims: \"+ str(X.shape))\nprint(\"Features\")\nprint(X.columns)","24fbb366":"X_dummies = pd.get_dummies(data=X, drop_first=True)\nX_dummies.head()","39c42388":"# model_lr = LogisticRegression(max_iter=4000)\n# cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1080)\n# preds = cross_validate(model_lr, X_dummies, y_comb, scoring=['accuracy','roc_auc'], cv=cv)\n# preds_lr_b4_sel = preds\n# print(\"Classification Accuracy: %f\" % preds['test_accuracy'].mean())\n# print(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())","26c0307a":"# #\n# # 29\/07 Cross Validating Feature Selection - RFE with Log Regression\n# # Code not complete - TODO Pipeline and everything\n\n# cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n# model_lr = LogisticRegression(max_iter=4000)\n# min_features_to_select = 3\n# rfecv = RFECV(estimator=model_lr, step=1, min_features_to_select=min_features_to_select, scoring='roc_auc', cv=cv_inner, n_jobs=-1)\n# rfecv.fit(X_dummies, y_comb)\n# plt.figure()\n# plt.xlabel(\"Number of features selected\")\n# plt.ylabel(\"Cross validation score (num of correct classifications)\")\n# plt.plot(range(min_features_to_select,\n#                len(rfecv.grid_scores_) + min_features_to_select),\n#          rfecv.grid_scores_)\n# plt.title('Logistic Regression RFE - Optimal no. of features: %d' % rfecv.n_features_)\n# plt.savefig('LRRFE-combined.png')\n# plt.show()\n\n# feature_selected_X_colnames_lr = X_dummies.columns[rfecv.support_]\n# feature_selected_X_lr = X_dummies[feature_selected_X_colnames_lr]\n# model_lr_rfe = LogisticRegression(max_iter=4000)\n# cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1080)\n# preds = cross_validate(model_lr_rfe, feature_selected_X_lr, y_comb, scoring=['accuracy','roc_auc'], cv=cv)\n# preds_lr_af_sel = preds\n# print(\"Logistic Regression\")\n# print(\"Classification Accuracy: %f\" % preds['test_accuracy'].mean())\n# print(\"Std deviation: %f\" % preds['test_accuracy'].std())\n# print()\n# print(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())\n# print(\"Std deviation: %f\" % preds['test_roc_auc'].std())\n# plt.figure()\n# sns.boxplot(y=preds['test_accuracy'], showmeans=True)\n# plt.title('Logistic Regression 5-Fold CV - Boxplot of Accuracy with mean')\n# plt.savefig('LRACC.png')\n# plt.show()\n# plt.figure()\n# sns.boxplot(y=preds['test_roc_auc'], showmeans=True)\n# plt.title('Logistic Regression 5-Fold CV - Boxplot of ROC AUC with mean')\n# plt.savefig('LR_ROC_AUC.png')\n# plt.show()","72bff14e":"start_time = time.time()\n\n\ncv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\nmodel_lr = LogisticRegression(max_iter=4000)\nmin_features_to_select = 3\nrfecv = RFECV(estimator=model_lr, step=1, min_features_to_select=min_features_to_select, scoring='roc_auc', cv=cv_inner, n_jobs=-1)\n\nparam_grid = {}\nsteps = [('rfe',rfecv), ('tune', model_lr)]\npipe = Pipeline(steps)\ncross_validate_lr = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv_inner, refit=True, n_jobs=-1)\ncv_outer = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\npreds = cross_validate(cross_validate_lr, X_dummies, y_comb, scoring=['accuracy','roc_auc'], cv=cv_outer)\npreds_lr = preds\nprint(\"Logistic Regression\")\nprint(\"Accuracy: %f\" % preds['test_accuracy'].mean())\nprint(\"Std deviation: %f\" % preds['test_accuracy'].std())\nprint()\nprint(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())\nprint(\"Std deviation: %f\" % preds['test_roc_auc'].std())\nplt.figure()\nsns.boxplot(y=preds['test_accuracy'], showmeans=True)\nplt.title('Logistic Regression 5-Fold Nested CV - Accuracy')\nplt.savefig('LRACC.png')\nplt.show()\nplt.figure()\nsns.boxplot(y=preds['test_roc_auc'], showmeans=True)\nplt.title('Logistic Regression 5-Fold Nested CV - ROC AUC')\nplt.savefig('LR_ROC_AUC.png')\nplt.show()\n\nprint(\"--- %s seconds to run---\" % (time.time() - start_time))","8fd3d67b":"start_time = time.time()\n\n\ncv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\nmodel_lr = LogisticRegression(max_iter=4000)\nmin_features_to_select = 3\nrfecv = RFECV(estimator=model_lr, step=1, min_features_to_select=min_features_to_select, scoring='roc_auc', cv=cv_inner, n_jobs=-1)\n\nparam_grid = {}\nsteps = [('rfe',rfecv), ('fit', model_lr)]\npipe = Pipeline(steps)\ncross_validate_lr = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv_inner, refit=True, n_jobs=-1)\ncross_validate_lr.fit(X_dummies, y_comb)\n\nrfecv = cross_validate_lr.best_estimator_['rfe']\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross Validation score (ROC AUC)\")\nplt.plot(range(min_features_to_select,\n               len(rfecv.grid_scores_) + min_features_to_select),\n         rfecv.grid_scores_)\nplt.title('Logistic Regression RFE - Optimal no. of features: %d' % rfecv.n_features_)\nplt.savefig('LRRFE.png')\nplt.show()\n\n\nprint(\"--- %s seconds to run---\" % (time.time() - start_time))","16491a85":"cross_validate_lr.best_estimator_['fit'].n_iter_","dd2a6789":"selected_columns = list(X_dummies.columns[cross_validate_lr.best_estimator_['rfe'].support_])\nselected_columns","93e0e8bc":"cross_validate_lr.best_estimator_['fit'].coef_","ea4bee94":"for i,colname in enumerate(X_dummies.columns):\n    print(str(i)+\"   \"+colname)","8458f8f4":"X_lencoded = X.copy()\nle = LabelEncoder()\nfor i in X.select_dtypes(include=['object','category']).columns:\n    X_lencoded[i] = le.fit_transform(X[i])\ny_lencoded = le.fit_transform(y_comb)\nX_lencoded.head()","bf50d24f":"# model_rf = RandomForestClassifier()\n# cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1080)\n# preds = cross_validate(model_rf, X_lencoded, y_lencoded, scoring=['accuracy','roc_auc'], cv=cv)\n# preds_rf_b4_sel = preds\n# print(\"Classification Acc RF: %f\" % preds['test_accuracy'].mean())\n# print(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())","0b78d80e":"(X_lencoded.columns)","10b49d3e":"import time","ab39d6b1":"start_time = time.time()\n\n\ncv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\nmodel_rf = RandomForestClassifier()\nmin_features_to_select = 3\nrfecv = RFECV(estimator=model_rf, step=1, min_features_to_select=min_features_to_select, scoring='roc_auc', cv=cv_inner, n_jobs=-1)\n\nparam_grid = {\n    'tune__n_estimators': [50, 100, 200],\n    'tune__max_depth': [i for i in range(1,3)],\n    'tune__max_features': [i for i in range(3,7)]\n}\n\nsteps = [('rfe',rfecv), ('tune', model_rf)]\npipe = Pipeline(steps)\ngridsearch_rf = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv_inner, refit=True, n_jobs=-1)\ncv_outer = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\npreds = cross_validate(gridsearch_rf, X_lencoded, y_lencoded, scoring=['accuracy','roc_auc'], cv=cv_outer)\npreds_rf = preds\nprint(\"Random Forest\")\nprint(\"Accuracy: %f\" % preds['test_accuracy'].mean())\nprint(\"Std deviation: %f\" % preds['test_accuracy'].std())\nprint()\nprint(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())\nprint(\"Std deviation: %f\" % preds['test_roc_auc'].std())\nplt.figure()\nsns.boxplot(y=preds['test_accuracy'], showmeans=True)\nplt.title('Random Forest 5-Fold Nested CV - Accuracy')\nplt.savefig('RF_ACC.png')\nplt.show()\nplt.figure()\nsns.boxplot(y=preds['test_roc_auc'], showmeans=True)\nplt.title('Random Forest 5-Fold Nested CV - ROC AUC')\nplt.savefig('RF_ROC_AUC.png')\nplt.show()\n\nprint(\"--- %s seconds to run---\" % (time.time() - start_time))","c0a6f4df":"start_time = time.time()\n\n\ncv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\nmodel_rf = RandomForestClassifier(random_state=4)\nmin_features_to_select = 3\nrfecv = RFECV(estimator=model_rf, step=1, min_features_to_select=min_features_to_select, scoring='roc_auc', cv=cv_inner, n_jobs=-1)\n\nparam_grid = {\n    'fit__n_estimators': [50, 100, 200],\n    'fit__max_depth': [i for i in range(1,3)],\n    'fit__max_features': [i for i in range(3,7)]\n}\n\nsteps = [('rfe',rfecv), ('fit', model_rf)]\npipe = Pipeline(steps)\ncross_validate_rf = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv_inner, refit=True, n_jobs=-1)\ncross_validate_rf.fit(X_lencoded, y_lencoded)\n\nrfecv = cross_validate_rf.best_estimator_['rfe']\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross Validation score (ROC AUC)\")\nplt.plot(range(min_features_to_select,\n               len(rfecv.grid_scores_) + min_features_to_select),\n         rfecv.grid_scores_)\nplt.title('Random Forest RFE - Optimal no. of features: %d' % rfecv.n_features_)\nplt.savefig('RFRFE.png')\nplt.show()\n\n\nprint(\"--- %s seconds to run---\" % (time.time() - start_time))","744ca6c9":"selected_columns = list(X_lencoded.columns[cross_validate_rf.best_estimator_['rfe'].support_])\nselected_columns","edf2cd21":"# get importance\nX_RF = X_lencoded[selected_columns]\ny_RF = y_lencoded\nmodel = cross_validate_rf.best_estimator_['fit'].fit(X_RF, y_RF)\nimportance = model.feature_importances_\n","d3e879a1":"# summarize feature importance\nfor i,v in enumerate(importance):\n\tprint('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.xticks(ticks=range(len(selected_columns)), labels=selected_columns, rotation=40)\n\nplt.title('Random Forest Feature Importance')\nplt.xlabel('Features')\nplt.ylabel('Mean decrease in impurity')\nplt.savefig('RFfeatureimportance.png', bbox_inches='tight')\nplt.show()","e5df07a9":"for i,colname in enumerate(X_lencoded.columns):\n    print(str(i)+\"   \"+colname)\n    ","64565a81":"#Remove in some time\nstart_time = time.time()\n\n\ncv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\nmodel_rf = RandomForestClassifier(random_state=452)\nmin_features_to_select = 3\nrfecv = RFECV(estimator=model_rf, step=1, min_features_to_select=min_features_to_select, scoring='roc_auc', cv=cv_inner, n_jobs=-1)\n\nparam_grid = {\n    'fit__n_estimators': [50, 100, 200],\n    'fit__max_depth': [i for i in range(1,3)],\n    'fit__max_features': [i for i in range(3,7)]\n}\n\nsteps = [('rfe',rfecv), ('fit', model_rf)]\npipe = Pipeline(steps)\ncross_validate_rf = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv_inner, refit=True, n_jobs=-1)\ncross_validate_rf.fit(X_lencoded, y_lencoded)\n\nrfecv = cross_validate_rf.best_estimator_['rfe']\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross Validation score (ROC AUC)\")\nplt.plot(range(min_features_to_select,\n               len(rfecv.grid_scores_) + min_features_to_select),\n         rfecv.grid_scores_)\nplt.title('Random Forest RFE - Optimal no. of features: %d' % rfecv.n_features_)\nplt.savefig('RFRFE.png')\nplt.show()\n\n\nprint(\"--- %s seconds to run---\" % (time.time() - start_time))","adf30a64":"X_dummies = pd.get_dummies(data=X, columns=X.select_dtypes(include='object').columns)\nX_dummies = pd.concat([X_dummies, pd.get_dummies(X['Copy-number Cluster'], prefix='Copy-number Cluster')], axis=1).drop(['Copy-number Cluster'], axis=1)\nscaler = StandardScaler()\nminmaxscaler = MinMaxScaler()\nX_dummies_scaled = X_dummies.copy()\nX_dummies_scaled[['PreDxBxPSA', 'DxAge', 'BxGG1', 'BxGG2']] = scaler.fit_transform(X_dummies[['PreDxBxPSA', 'DxAge', 'BxGG1', 'BxGG2']])\nX_dummies_scaled[['PreDxBxPSA', 'DxAge', 'BxGG1', 'BxGG2']] = minmaxscaler.fit_transform(X_dummies_scaled[['PreDxBxPSA', 'DxAge', 'BxGG1', 'BxGG2']])\nX_dummies_scaled.head()","f09581d6":"model_lsvc = SVC(kernel='linear')\ncv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1080)\n\nparam_grid = {\n    'C': [0.1, 1, 10, 100]\n}\n\ngridsearch_lsvc = GridSearchCV(model_lsvc, param_grid, scoring='roc_auc', cv=cv_inner, refit=True, n_jobs=-1)\ngridsearch_lsvc.fit(X_dummies_scaled, y_comb)\n# preds = cross_validate(model_lsvc, X_dummies_scaled, y_comb, scoring=['accuracy','roc_auc'], cv=cv)\n# print(\"Acc SVM: %f\" % preds['test_accuracy'].mean())\n# print(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())","98530e17":"gridsearch_lsvc.best_params_","d391302c":"#\n# 29\/07 Cross Validating Feature Selection - RFE with SVC With Scaling\nstart_time = time.time()\n\ncv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\nmodel_lsvc = SVC(kernel='linear')\nmin_features_to_select = 3\nrfecv = RFECV(estimator=model_lsvc, step=1, min_features_to_select=min_features_to_select, scoring='roc_auc', cv=cv_inner, n_jobs=-1)\n\nparam_grid = {\n    'tune__C': [0.1, 1, 10, 100]\n}\n\nsteps = [('rfe',rfecv), ('tune', model_lsvc)]\npipe = Pipeline(steps)\ngridsearch_lsvc = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv_inner, refit=True, n_jobs=-1)\ncv_outer = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\npreds = cross_validate(gridsearch_lsvc, X_dummies_scaled, y_comb, scoring=['accuracy','roc_auc'], cv=cv_outer)\npreds_lsvc = preds\n\nprint(\"SVM with linear kernel\")\nprint(\"Accuracy: %f\" % preds['test_accuracy'].mean())\nprint(\"Std deviation: %f\" % preds['test_accuracy'].std())\nprint()\nprint(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())\nprint(\"Std deviation: %f\" % preds['test_roc_auc'].std())\nplt.figure()\nsns.boxplot(y=preds['test_accuracy'], showmeans=True)\nplt.title('Linear SVM 5-Fold Nested CV - Accuracy')\nplt.savefig('L-SVM_ACC.png')\nplt.show()\nplt.figure()\nsns.boxplot(y=preds['test_roc_auc'], showmeans=True)\nplt.title('Linear SVM 5-Fold Nested CV - ROC AUC')\nplt.savefig('L-SVM_ROC_AUC.png')\nplt.show()\n\nprint(\"--- %s seconds to run---\" % (time.time() - start_time))","2b7548b1":"# model_svc = SVC()\n# param_grid = {\n#     'C':[0.1, 1, 10, 100],\n#     'kernel':['linear', 'rbf', 'poly', 'sigmoid'],\n#     'degree':[3,4,5],\n#     'gamma':['scale','auto']\n# }\n# search = GridSearchCV(model_svc, param_grid, scoring='roc_auc', n_jobs=-1)\n# search.fit(X_dummies_scaled, y_comb)\n# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n# print(search.best_params_)\n\n# model_svc = SVC(**search.best_params_)\n# cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=1080)\n# preds = cross_validate(model_svc, X_dummies_scaled, y_comb, scoring=['accuracy','roc_auc'], cv=cv)\n# print(\"Acc SVM: %f\" % preds['test_accuracy'].mean())\n# print(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())","2167048b":"# #\n# # 25\/08 Cross Validating Feature Selection - RFE with SVC With Scaling\n# # RFE is not used here since it is not supported with non-linear SVM.\n# start_time = time.time()\n\n# cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n# model_svc = SVC()\n# min_features_to_select = 3\n\n# param_grid = {\n#     'tune__C':[0.1, 1, 10, 100],\n#     'tune__kernel':['linear', 'rbf', 'poly', 'sigmoid'],\n#     'tune__degree':[3,4,5],\n#     'tune__gamma':['scale','auto']\n# }\n\n# steps = [('tune', model_svc)]\n# pipe = Pipeline(steps)\n# gridsearch_svc = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv_inner, refit=True, n_jobs=-1)\n# cv_outer = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n# preds = cross_validate(gridsearch_svc, X_dummies_scaled, y_comb, scoring=['accuracy','roc_auc'], cv=cv_outer)\n# preds_svc = preds\n\n# print(\"SVM - Non Linear\")\n# print(\"Accuracy: %f\" % preds['test_accuracy'].mean())\n# print(\"Std deviation: %f\" % preds['test_accuracy'].std())\n# print()\n# print(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())\n# print(\"Std deviation: %f\" % preds['test_roc_auc'].std())\n# plt.figure()\n# sns.boxplot(y=preds['test_accuracy'], showmeans=True)\n# plt.title('SVM 5-Fold CV - Boxplot of Accuracy with mean')\n# plt.savefig('SVM_ACC.png')\n# plt.show()\n# plt.figure()\n# sns.boxplot(y=preds['test_roc_auc'], showmeans=True)\n# plt.title('SVM 5-Fold CV - Boxplot of ROC AUC with mean')\n# plt.savefig('SVM_ROC_AUC.png')\n# plt.show()\n\n# print(\"--- %s seconds to run---\" % (time.time() - start_time))","7ee04402":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","ae24009e":"# # Tuning the Hidden Layer\n\n# start_time = time.time()\n# model = MLPClassifier(max_iter=2000)\n# sizes = [10, 20, 50, 70]\n# size_list = []\n# for i in sizes:\n#     for j in sizes:\n#         for k in sizes:\n#             for l in sizes:\n#                 size_list.append((i,j,k,l))\n# # for i in sizes:\n# #     for j in sizes:\n# #         for k in sizes:\n# #             size_list.append((i,j,k))\n# # for i in sizes:\n# #     for j in sizes:\n# #         size_list.append((i,j))\n# # for i in sizes:\n# #     size_list.append((i))\n\n# param_grid = {\n#     'hidden_layer_sizes':size_list,\n# }\n# search = GridSearchCV(model, param_grid, scoring='roc_auc', n_jobs=-1)\n# search.fit(X_dummies_scaled, y_comb)\n# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n# print(search.best_params_)\n\n# model = search.best_estimator_\n# cv = RepeatedKFold(n_splits=5, n_repeats=5)\n# preds = cross_validate(model, X_dummies_scaled, y_comb, scoring=['accuracy','roc_auc'], cv=cv)\n# print(\"Acc NN (HL tuning): %f\" % preds['test_accuracy'].mean())\n# print(\"ROC AUC (HL tuning): %f\" % preds['test_roc_auc'].mean())\n\n# print(\"--- %s seconds to run---\" % (time.time() - start_time))","b4ce033e":"# sizes = [10, 20, 50, 70]\n# size_list = []\n# #     for j in sizes:\n# #         for k in sizes:\n# #             size_list.append((i,j,k))\n# for i in sizes:\n#     for j in sizes:\n#         size_list.append((i,j))\n# # for i in sizes:\n# #     size_list.append((i))\n\n# param_grid = {\n#     'hidden_layer_sizes':size_list,\n#     'learning_rate_init':[0.0001, 0.001, 0.01, 0.1]\n# }\n# search = GridSearchCV(model, param_grid, scoring='roc_auc', n_jobs=-1)\n# search.fit(X_dummies_scaled, y_comb)\n# print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n# print(search.best_params_)\n\n# model = search.best_estimator_\n# cv = RepeatedKFold(n_splits=5, n_repeats=5)\n# preds = cross_validate(model, X_dummies_scaled, y_comb, scoring=['accuracy','roc_auc'], cv=cv)\n# print(\"Acc NN (LR tuning): %f\" % preds['test_accuracy'].mean())\n# print(\"ROC AUC (LR tuning): %f\" % preds['test_roc_auc'].mean())\n\n# print(\"--- %s seconds to run---\" % (time.time() - start_time))","e915b016":"# search","f1eeb24b":"# model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), activation='relu',solver='adam', max_iter=2000)\n# X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_dummies_scaled, y_comb, test_size=0.33, stratify=y_comb)\n# model.fit(X_train_nn, y_train_nn)\n# preds = model.predict(X_test_nn)\n# preds_proba = model.predict_proba(X_test_nn)\n# print(\"Accuracy: \"+str(accuracy_score(y_test_nn, preds)))\n# print(\"AUC: \"+str(roc_auc_score(y_test_nn, preds_proba[:,1])))","0efb988c":"sizes = [10, 20, 50, 70]\nsize_list = []\nfor i in sizes:\n    for j in sizes:\n        for k in sizes:\n            for l in sizes:\n                size_list.append((i,j,k,l))\n# for i in sizes:\n#     for j in sizes:\n#         for k in sizes:\n#             size_list.append((i,j,k))\n# for i in sizes:\n#     for j in sizes:\n#         size_list.append((i,j))","f5a68e34":"start_time = time.time()\n\ncv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\nmodel_nn = MLPClassifier(max_iter=2000)\nmin_features_to_select = 3\n\nparam_grid = {\n    'tune__hidden_layer_sizes' : size_list,\n    'tune__alpha':[0.0001, 0.001, 0.01]\n}\n\nsteps = [('tune', model_nn)]\npipe = Pipeline(steps)\ngridsearch_nn = GridSearchCV(pipe, param_grid, scoring='roc_auc', cv=cv_inner, refit=True, n_jobs=-1)\ncv_outer = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\npreds = cross_validate(gridsearch_nn, X_dummies_scaled, y_comb, scoring=['accuracy','roc_auc'], cv=cv_outer)\npreds_nn = preds\nprint(\"Neural Networks - MLP\")\nprint(\"Accuracy: %f\" % preds['test_accuracy'].mean())\nprint(\"Std deviation: %f\" % preds['test_accuracy'].std())\nprint()\nprint(\"ROC AUC: %f\" % preds['test_roc_auc'].mean())\nprint(\"Std deviation: %f\" % preds['test_roc_auc'].std())\nplt.figure()\nsns.boxplot(y=preds['test_accuracy'], showmeans=True)\nplt.title('Neural Network 5-Fold Nested CV - Accuracy')\nplt.savefig('NN_ACC.png')\nplt.show()\nplt.figure()\nsns.boxplot(y=preds['test_roc_auc'], showmeans=True)\nplt.title('Neural Network 5-Fold Nested CV - ROC AUC')\nplt.savefig('NN_ROC_AUC.png')\nplt.show()\n\nprint(\"--- %s seconds to run---\" % (time.time() - start_time))","d91dff4f":"plt.figure()\nplt.subplots(1,4, sharey=True)\nplt.subplot(1,4,1)\nsns.boxplot(y=preds_lr['test_accuracy'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\nplt.xlabel('LR')\nplt.ylabel('Accuracy')\nplt.subplot(1,4,2)\nsns.boxplot(y=preds_rf['test_accuracy'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\nplt.xlabel('RF')\nplt.subplot(1,4,3)\nsns.boxplot(y=preds_lsvc['test_accuracy'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\nplt.xlabel('L-SVM')\n# plt.subplot(1,5,4)\n# sns.boxplot(y=preds_svc['test_accuracy'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\n# plt.xlabel('SVC')\nplt.subplot(1,4,4)\nsns.boxplot(y=preds_nn['test_accuracy'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\nplt.xlabel('NN')\nplt.title('Comparison Of All Models - Accuracy')\nplt.savefig('allmodels_accuracy.png')\nplt.show()","97020574":"plt.figure()\nplt.subplots(1,4, sharey=True)\nplt.subplot(1,4,1)\nsns.boxplot(y=preds_lr['test_roc_auc'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\nplt.xlabel('LR')\nplt.ylabel('ROC AUC')\nplt.subplot(1,4,2)\nsns.boxplot(y=preds_rf['test_roc_auc'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\nplt.xlabel('RF')\nplt.subplot(1,4,3)\nsns.boxplot(y=preds_lsvc['test_roc_auc'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\nplt.xlabel('L-SVM')\n# plt.subplot(1,5,4)\n# sns.boxplot(y=preds_svc['test_accuracy'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\n# plt.xlabel('SVC')\nplt.subplot(1,4,4)\nsns.boxplot(y=preds_nn['test_roc_auc'], showmeans=True, medianprops=dict(color=\"red\", alpha=0.7))\nplt.xlabel('NN')\nplt.title('Comparison Of All Models - ROC AUC')\nplt.savefig('allmodels_roc_auc.png')\nplt.show()","2f9476db":"# Data 6\n\n- Remove PathGG1 and PathGG2.\n- Remove Pre RP PSA value because of high correlation with Pre Diagnosis PSA.","dbcdf0e3":"## Data 2","ea2b5a38":"## Models to be trained \n - Logistic Regression\n - Random Forest\n - Linear SVM\n - SVM\n - NN\n \n## Metrics\n - Classification Accuracy\n - AUC ( Need to get P(Y=1|X)! )","231c3e89":"# Nested cross validation","5ed2cce3":"## Neural Networks","54d1790f":"# Data 7\n - Dropped BCR_FreeTime, BCR_Event 01\/07","5e884a54":"# SVM","7e7ccaa2":"## 01\/07\n### I realized that BCR_FreeTime cannot be used to predict pathological grade.\n### Combining response into 6 and 7+. Refer Eric's email on 28\/06","17e30f9a":"# Data Cleaning\n\n## 1\n\n - Will remove rows from 0 to 13, most of the entries are NaN\n\n## 2\n - Drop NeoAdjRadTx (Neoadjuvant therapy), 98% empty\n - Drop MetSite (Site of the metastasis), 83% NaN. Only applicable where there is Metastasis.\n - Drop ChemoTx (Chemotherapy), 85% NaN.\n - Drop HormTx (Hormonal therapy), 70% NaN.\n - Drop RadTxType (Radiation), 83% NaN.\n\n## 3\n - Drop Sample ID, since it doesn't contribute any data\n - Drop the final VCap row.\n - [REDACTED] Drop Race, no need to deal with one-hot encoding right now.\n\n## 4\n - Dropped all features with low number of NaN values\n\n## 5\n - Dropped features with more than one NaN value. These mostly included the nomogram features.\n \n## 6\n\n - Remove PathGG1 and PathGG2.\n - Remove Pre RP PSA value because of high correlation with Pre Diagnosis PSA.\n\n## 7\n - Dropped BCR_FreeTime, BCR_Event 01\/07\n\n## 8\n - Drop BxGGS. Strong correlation with PathGGS.\n - Drop SMS, ECE, SVI and LNI. We get this information after the surgery.\n - Drop PathStage, Event, SurvTime. Same reason as above.\n","e80496fc":"## Random Forest","bfdff89c":"# Data 4","462b2516":"# Data 5","5695f9e9":"# Data 8\n - Drop BxGGS. Strong correlation with PathGGS.\n - Drop SMS, ECE, SVI and LNI. We get this information after the surgery.\n - Drop PathStage, Event, SurvTime\n","58749d8d":"## Logistic Regression","bd544068":"## Linear SVM","871cb043":"Drop Sample ID, since it doesn't contribute any data\n\nDrop the final VCap row.\n\n(Redacted) Drop Race, no need to deal with one-hot encoding right now.","4f1c359f":"## Data 1","d5f006ed":"Questions\n 1. Is there any correlation between Pre Diagnosis PSA and Pre RP PSA?\n\nAnswers\n 1. Very high correlation, 98.7%"}}