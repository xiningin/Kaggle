{"cell_type":{"1bbb7b4a":"code","abaa11a4":"code","1d428eb0":"code","8df98bcb":"code","4b823909":"code","d1469820":"code","3e947722":"code","ebfe949b":"code","b8efbbb3":"code","96cd6f21":"code","8f5c4549":"markdown"},"source":{"1bbb7b4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","abaa11a4":"#-- required imports\nimport tensorflow as tf\nfrom tensorflow.keras import regularizers as rg\nimport librosa\nfrom librosa import display\nfrom scipy.io import wavfile\nimport gc\nimport pickle as pkl\nfrom tqdm.notebook import tqdm, trange\nimport matplotlib.pyplot as plt\n\npath = '\/kaggle\/input\/darpa-timit-acousticphonetic-continuous-speech'\ndata_path = path+\"\/data\"","1d428eb0":"class Callback(tf.keras.callbacks.Callback):\n    def on_epoch_begin(self,epoch,logs={}):\n        print(\"Epoch \",epoch)\n\n    def on_epoch_end(self,epoch,logs={}):\n        print('loss: {:.2f}, accuracy:{:.2f}'.format(\n                logs[\"loss\"],logs[\"accuracy\"]*100))\n        print(logs)\n        gc.collect()\n\n    def on_batch_end(self,batch,logs={}):\n        if(batch%100 == 0):\n            print(batch,'loss: {:.2f}, accuracy:{:.2f}'.format(\n                logs[\"loss\"],logs[\"accuracy\"]*100))\n\n    def on_test_batch_end(self, batch, logs=None):        \n        if(batch%100 == 0):\n            pass\n            return\n            #print('Test Batch',batch,logs)","8df98bcb":"import math\n\nclass FeatureCollector():\n    __train_desc = 'train_data.csv'\n    __test_desc = 'test_data.csv'\n    __data_directory = '.\/data'\n    __main_directory = '.\/'\n    f_Path = 'path_from_data_dir' #field that contains file path in train_data.csv\n    f_IsAudio = 'is_converted_audio' #boolean field that tells that the record in train_data.csv contains the description of audio file we are interested in\n    f_IsWord = 'is_word_file'\n    f_IsPhon = 'is_phonetic_file'\n    f_IsSent = 'is_sentence_file'\n    # f_filename = 'filename' #field that contains filename\n    f_dr = 'dialect_region' #field that contains dialect_region information\n    _winlen = 0.025\n    _winstep = 0.01\n    \n    def __init__(self,path=None):\n        if path == None:\n            raise Exception(\"Directory path to the TIMIT Data set must be provided\")\n        if not os.path.isdir(path):\n            raise Exception(\"Directory doesn't exist\")\n        self.__main_directory = path\n        if path[len(path)-1] == '\/':\n            self.__data_directory = path+\"data\/\"\n        else:\n            self.__main_directory += \"\/\"\n            self.__data_directory = self.__main_directory+\"data\/\"\n      \n        # TimitBet 61 phoneme mapping to 39 phonemes\n        # by Lee, K.-F., & Hon, H.-W. (1989). Speaker-independent phone recognition using hidden Markov models. IEEE Transactions on Acoustics, Speech, and Signal Processing, 37(11), 1641\u20131648. doi:10.1109\/29.46546 \n        self.phon61_map39 = {\n            'iy':'iy',  'ih':'ih',   'eh':'eh',  'ae':'ae',    'ix':'ih',  'ax':'ah',   'ah':'ah',  'uw':'uw',\n            'ux':'uw',  'uh':'uh',   'ao':'aa',  'aa':'aa',    'ey':'ey',  'ay':'ay',   'oy':'oy',  'aw':'aw',\n            'ow':'ow',  'l':'l',     'el':'l',  'r':'r',      'y':'y',    'w':'w',     'er':'er',  'axr':'er',\n            'm':'m',    'em':'m',     'n':'n',    'nx':'n',     'en':'n',  'ng':'ng',   'eng':'ng', 'ch':'ch',\n            'jh':'jh',  'dh':'dh',   'b':'b',    'd':'d',      'dx':'dx',  'g':'g',     'p':'p',    't':'t',\n            'k':'k',    'z':'z',     'zh':'sh',  'v':'v',      'f':'f',    'th':'th',   's':'s',    'sh':'sh',\n            'hh':'hh',  'hv':'hh',   'pcl':'h#', 'tcl':'h#', 'kcl':'h#', 'qcl':'h#','bcl':'h#','dcl':'h#',\n            'gcl':'h#','h#':'h#',  '#h':'h#',  'pau':'h#', 'epi': 'h#','nx':'n',   'ax-h':'ah','q':'h#' \n        }\n        \n        self.phon61 = list(self.phon61_map39.keys())\n        self.phon39 = list(set(self.phon61_map39.values()))\n\n        self.label_p39 = {}\n        self.p39_label = {}\n        for i,p in enumerate(self.phon39):\n            self.label_p39[p] = i+1\n            self.p39_label[i+1] = p\n\n        self.phon39_map61 = {}\n        for p61,p39 in self.phon61_map39.items():\n            if not p39 in self.phon39_map61:\n                self.phon39_map61[p39] = []\n            self.phon39_map61[p39].append(p61)\n        #-------------------------------------------------\n        #end __init__\n    \n    #------------------------------------------------------------------------\n    def get39EquiOf61(self,p):\n        return self.phon61_map39[self.removePhonStressMarker(p)]\n\n    def removePhonStressMarker(self,phon):\n        phon = phon.replace('1','')\n        phon = phon.replace('2','')\n        return phon\n    \n    def getWindow(self,sr):\n        nfft = 512\n        winlen = self._winlen * sr\n        winstep = self._winstep * sr\n        return nfft,int(winlen),int(winstep)\n\n    def singleTrainingFrameSize(self,sr):\n        return math.floor(sr\/4)\n        \n    def readTrainingDataDescriptionCSV(self):\n        file_path = self.__main_directory + 'train_data.csv' #check if train_data.csv is in correct path\n        self._Tdd = pd.read_csv(file_path)\n        # removing NaN entries in the train_data.csv file\n        dr = ['DR1','DR2','DR3','DR4','DR5','DR6','DR7','DR8']\n        self._Tdd = self._Tdd[self._Tdd['dialect_region'].isin(dr)]\n        return self._Tdd\n\n    def readTestingDataDescriptionCSV(self):\n        file_path = self.__main_directory + 'test_data.csv' #check if train_data.csv is in correct path\n        self._tdd = pd.read_csv(file_path)\n        # removing NaN entries in the train_data.csv file\n        dr = ['DR1','DR2','DR3','DR4','DR5','DR6','DR7','DR8']\n        self._tdd = self._tdd[self._tdd['dialect_region'].isin(dr)]\n        return self._tdd\n    \n    def getListAudioFiles(self,of='Train'):\n        if of == 'Train':\n            self.readTrainingDataDescriptionCSV()\n            return self._Tdd[self._Tdd[self.f_IsAudio] == True]\n        if of == 'Test':\n            self.readTestingDataDescriptionCSV()\n            return self._tdd[self._tdd[self.f_IsAudio] == True]\n        \n    def getListPhonemeFiles(self,of='Train'):\n        if of == 'Train':\n            self.readTrainingDataDescriptionCSV()\n            return self._Tdd[self._Tdd[self.f_IsPhon] == True]\n        if of == 'Test':\n            self.readTestingDataDescriptionCSV()\n            return self._tdd[self._tdd[self.f_IsPhon] == True]\n               \n    def readAudio(self,fpath=None,pre_emp = False):\n        if(fpath == None):\n            return np.zeros(1),0\n        \n        fpath = self.__data_directory+fpath\n        if os.path.exists(fpath):\n            S,sr = librosa.load(fpath,sr=None)\n            if pre_emp:\n                S = librosa.effects.preemphasis(S)\n            return S,sr   \n        else:\n            return np.zeros(1),0\n    #-----------------------end readAudio()\n    \n    def readPhon(self,fpath=None):\n        if(fpath == None):\n            raise Exception('phon file path not provided')\n        \n        fpath = self.__data_directory+fpath\n        ph_ = pd.read_csv(fpath,sep=\" \")#,usecols=['start','end','phoneme'])\n        #ph_.columns = ['start','end','phoneme']\n        return ph_\n            \n        pfn = j['filename'].split('.WAV')[0]+'.PHN'\n        p_bar.set_description(f'Working on {j[\"filename\"]} ,index: {c}  ')\n        try:\n            pfp = file_path+pfd[(pfd['filename']==pfn) & (pfd['speaker_id'] == j['speaker_id'])][f_Path].values[0]\n        except:\n            pfp = afp.replace(j['filename'],pfn)\n            \n        ph_ = pd.read_csv(pfp,sep=\" \")#,usecols=['start','end','phoneme'])\n        #ph_.columns = ['start','end','phoneme']\n    #---------------end readPhon()\n        \n    def getFeatureAndLabel(self,ftype='mfsc',audio_path=None,phon_path=None,n_mels=128,delta=False,delta_delta=False):\n        if audio_path == None:\n            raise Exception(\"Path to audio (Wav) file must be provided\")\n        wav,sr = self.readAudio(fpath=audio_path,pre_emp=True)\n        nfft,winlen,winstep = self.getWindow(sr)\n        if(ftype == 'mfsc'):\n            melspec = librosa.feature.melspectrogram(wav,sr=sr,hop_length=winstep,win_length=winlen,n_fft=nfft,n_mels=n_mels)\n        if(ftype == 'mfcc'):\n            melspec = librosa.feature.mfcc(wav,sr=sr,hop_length=winstep,win_length=winlen,n_fft=nfft,n_mfcc=n_mels)\n            \n        db_melspec = librosa.amplitude_to_db(melspec,ref=np.max)\n        \n        mD = None\n        mDD = None\n        if(delta):\n            mD = librosa.feature.delta(db_melspec)\n            if(delta_delta):\n                mDD = librosa.feature.delta(mD)\n        \n        audio_phon_transcription = None\n        if phon_path == None:\n            tmp = audio_path.split('\/')\n            phon_path = \"\/\".join(tmp[:(len(tmp)-1)])+\"\/\"+ tmp[len(tmp)-1].split('.WAV')[0]+\".PHN\"\n            \n        audio_phon_transcription = self.readPhon(phon_path)            \n        time = db_melspec.shape[1]\n        \n        feature_vectors = []\n        db_melspec = db_melspec.T\n        mD = mD.T\n        mDD = mDD.T\n        \n        prev = None\n        first = audio_phon_transcription.columns\n        audio_phon_transcription.columns = ['start','end','phoneme']\n        labels = []\n        for i in range(time):\n            #---collecting feature---\n            feature = np.zeros(n_mels*3)\n            feature[:n_mels] = db_melspec[i]\n            feature[n_mels:n_mels*2] = mD[i]\n            feature[n_mels*2:n_mels*3] = mDD[i]\n            feature_vectors.append(feature)\n            \n            #---collecting phoneme label ---\n            start = winstep * i\n            end = start+winlen\n            diff = start+400\n            phoneme = list(\n                        audio_phon_transcription[\n                            ((audio_phon_transcription['start']<=start) & \n                            ((audio_phon_transcription['end']-start)>=int(winlen\/1.5)))\n                            |\n                            ((audio_phon_transcription['start']<=end) & \n                                (audio_phon_transcription['end']>end))  \n                        ].to_dict()['phoneme'].values()\n            )\n            if len(phoneme) == 0:\n                if int(first[1]) > start:\n                    phoneme = first[2]\n                else:\n                    phoneme = prev\n            else:\n                phoneme = phoneme[0]\n            phoneme = self.get39EquiOf61(phoneme)\n            prev = phoneme\n            labels.append(phoneme)\n             \n        return feature_vectors,labels\n                \n    #--------------------end getMelSpectrogramFeatureAndLabel()\n    def prepareLabelsForTraining(self,labels):\n        print('Preparing Labels')\n        label_vector = []\n        p_bar = tqdm(range(len(labels)))\n        c = 0\n        for l in labels:\n            label = [0 for i in range(39)]\n            label[self.label_p39[l]-1] = 1\n            label_vector.append(label)\n            c+=1\n            if c == 500:\n                p_bar.set_description(f'Working on phoneme {l}')\n                p_bar.update(c)\n                c = 0\n           \n        p_bar.set_description(f'Working on phoneme {l}')\n        p_bar.update(c) \n        return label_vector\n    \n    def collectFeatures(self,ft='Train',ftype='mfsc',n_mels=128,delta=False,delta_delta=False):\n        tddA = self.getListAudioFiles(ft)\n        tddA.index = range(tddA.shape[0])\n        feature_vectors = []\n        labels = []\n        \n        p_bar = tqdm(range(tddA.shape[0]))\n        silent_count = 0\n        for i in range(tddA.shape[0]):\n            fv,lv = self.getFeatureAndLabel(ftype=ftype,audio_path=tddA.loc[i][self.f_Path],n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n            p_bar.set_description(f'Working on {tddA.loc[i][self.f_Path]} ,index: {i}  ')\n            p_bar.update()\n            feature_vectors += fv\n            labels += lv\n                   \n        print(f\"length of feature_vectors is {len(feature_vectors)} and length of labels is {len(labels)}\")\n        labels = np.asarray(np.array(self.prepareLabelsForTraining(labels),dtype=object)).astype(np.int16)\n        feature_vectors = np.asarray(np.array(feature_vectors,dtype=object)).astype(np.float32)\n        return feature_vectors,labels\n    #--------------------end collectFeatures   \n        \n    def classTestA(self):\n        gc.collect()\n        tddA = self.getListAudioFiles()\n        feature_vectors, labels = self.getMelSpectrogramFeatureAndLabel(tddA[self.f_Path][0],n_mels=20,delta=True,delta_delta=True)\n        #------------------------------------------\n        wav,sr = self.readAudio(tddA[self.f_Path][0])\n        librosa.display.waveshow(wav,sr=sr)\n        nfft,winlen,winstep = self.getWindow(sr)\n        print(nfft,winlen,winstep)\n        melspec = librosa.feature.melspectrogram(wav,sr=sr,hop_length=winstep,win_length=winlen,n_fft=nfft)\n        db_melspec = librosa.amplitude_to_db(\n            melspec,\n            ref=np.max)\n        msd = librosa.feature.delta(db_melspec)\n        msdd = librosa.feature.delta(msd)\n        \n        fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True)\n        img = display.specshow(db_melspec,y_axis='linear', x_axis='time',\n                               sr=sr, ax=ax)\n        ax.set(title='Linear-frequency power spectrogram')\n        ax.label_outer()\n        fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n        \n        fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True)\n        librosa.display.specshow(db_melspec, y_axis='log', sr=sr,\n                         x_axis='time', ax=ax)\n        ax.set(title='Log-frequency power spectrogram')\n        ax.label_outer()\n        fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n        \n        fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True)\n        librosa.display.specshow(msd ,\n                                 y_axis='linear', sr=sr,\n                                 x_axis='time', ax=ax)  \n        ax.set(title='Mel Spectrogram Delta')\n        ax.label_outer()\n        fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n        \n        fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True)\n        librosa.display.specshow(msdd ,\n                                 y_axis='linear', sr=sr,\n                                 x_axis='time', ax=ax)  \n        ax.set(title='Mel Spectrogram Delta Delta')\n        ax.label_outer()\n        fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n        \n        fig, ax = plt.subplots(nrows=1, ncols=1, sharex=True)\n        librosa.display.specshow(librosa.amplitude_to_db(librosa.feature.mfcc(S=melspec,sr=sr),ref=np.max) ,\n                                 y_axis='linear', sr=sr,\n                                 x_axis='time', ax=ax)  \n        ax.set(title='MFCC')\n        ax.label_outer()\n        fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n        \n         ","4b823909":"####--------------Collecting Training Features----------------------###   \ngc.collect()\ncm = FeatureCollector(path)\nn_mels = 64\ndelta = True\ndelta_delta=True\nftype = 'mfsc'\nfeature_path = '\/kaggle\/input\/timit-{}mel-spectrogramdelta-features\/'.format(n_mels)#'\/kaggle\/input\/timit-{}mfcc-and-delta-feature\/'.format(n_mels)#\n\nprint('Attempting to read features file',feature_path)\nif os.path.exists(feature_path+'features.pkl') or os.path.exists('\/kaggle\/working\/features.pkl'):\n    if os.path.exists(feature_path+'features.pkl'):\n        print(\"-from input\")\n        ffp = open(feature_path+'features.pkl','rb')\n        flp = open(feature_path+'labels.pkl','rb')   \n    elif os.path.exists('\/kaggle\/working\/features.pkl'):\n        print(\"-from output\")\n        ffp = open('\/kaggle\/working\/features.pkl','rb')\n        flp = open('\/kaggle\/working\/labels.pkl','rb')\n    features = pkl.load(ffp)\n    labels = pkl.load(flp)\n    ffp.close()\n    flp.close()\n    features = np.asarray(features).astype(np.float32)\n    labels = np.asarray(labels).astype(np.int16)\n    print(features.shape,labels.shape)\n    print('---- success')\n    #-------\nelse:            \n    print('--- Failed')\n    print('Collecting Features from Audio Files')\n    features,labels = cm.collectFeatures(ftype=ftype,n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n    # -------------\n    ffp = open(\"\/kaggle\/working\/features.pkl\",'wb')\n    pkl.dump(features,ffp)\n    flp = open(\"\/kaggle\/working\/labels.pkl\",'wb')\n    pkl.dump(labels,flp)            \n    ffp.close()\n    flp.close()\n    print('--- Completed')\n    #-------","d1469820":"####----- Preparing Data For Multi Frame Training ----------------\nn_frames = 2 ## there will be n_frames + 1 frames in the data.\ndef prepareDataMultiFrame(features,n_frames=1):\n    if n_frames < 0:\n        n_frames = 0\n    if n_frames == 0:\n        return features\n    \n    size = features[0].shape[0] \n    multi_frame_data = np.zeros((features.shape[0],size*(n_frames+1)))\n    p_bar = tqdm(range(features.shape[0]))\n    for i in range(n_frames,features.shape[0]):\n        sample = np.zeros(size*(n_frames+1))\n        winlen = 0\n        nextpos = 0\n        for k in range(n_frames,-1,-1):\n            nextpos = winlen+size\n            sample[winlen:nextpos] = features[i-k]\n            winlen = nextpos\n        multi_frame_data[i] = sample           \n        p_bar.update()\n        \n    return multi_frame_data\n        \nfeatures = prepareDataMultiFrame(features=features,n_frames=n_frames)\ngc.collect()","3e947722":"####--------------Model Training----------------------###\nunits = 1024\nepochs = 20\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(units=units, input_shape=[features[0].shape[0]],activation=tf.nn.relu),\n    tf.keras.layers.Dense(units=units,activation=tf.nn.relu),\n    tf.keras.layers.Dense(units=units,activation=tf.nn.relu),\n    tf.keras.layers.Dense(units=units,activation=tf.nn.relu),\n    tf.keras.layers.Dense(units=39,activation=tf.nn.softmax)\n])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n\ngc.collect()  \ntrain_val_split = int(features.shape[0] * 0.8)\nhistory = model.fit(\n    features[:train_val_split],labels[:train_val_split],epochs=epochs,\n     batch_size=512, verbose=1,\n    validation_data=(features[train_val_split:],labels[train_val_split:]),\n    validation_batch_size=128\n)\nmodel.save('\/kaggle\/working\/{}{}_{}frame_1536Unit_4H_DNN_Model'.format(n_mels,ftype,n_frames))","ebfe949b":"###------------collecting test features -------------------\ngc.collect()\nif os.path.exists(feature_path+'test_features.pkl'):\n    test_features = pkl.load(open(feature_path+'test_features.pkl','rb'))\n    test_labels = pkl.load(open(feature_path+'test_labels.pkl','rb'))\nelif os.path.exists(\"\/kaggle\/working\/test_features.pkl\"):\n    test_features = pkl.load(open(\"\/kaggle\/working\/test_features.pkl\",'rb'))\n    test_labels = pkl.load(open(\"\/kaggle\/working\/test_labels.pkl\",'rb'))\nelse:\n    test_features,test_labels = cm.collectFeatures(ft='Test',ftype=ftype,n_mels=n_mels,delta=delta,delta_delta=delta_delta)\n    pkl.dump(test_features,open('\/kaggle\/working\/test_features.pkl','wb'))\n    pkl.dump(test_labels,open('\/kaggle\/working\/test_labels.pkl','wb'))\n    \n\ntest_features = prepareDataMultiFrame(features=test_features,n_frames=n_frames)\ngc.collect()","b8efbbb3":"####--------------Model Evaluating----------------------###   \nevaluation = model.evaluate(test_features,test_labels,batch_size=128)","96cd6f21":"#####-----per phone errors -----\nprediction = model.predict(test_features,batch_size = 128)\n\nres = [{'total':0,'correct':0} for j in range(39)]\nfor i in range(test_labels.shape[0]):\n    label_index = [j for j in range(39) if test_labels[i][j]==1][0]\n    _max = np.max(prediction[i])\n    prediction_index = [j for j in range(39) if prediction[i][j]==_max][0]\n    res[label_index]['total'] += 1\n    if label_index == prediction_index:\n        res[label_index]['correct'] += 1\n        \nprint(\"Phone Error Rate: \",\"\\n----------------------\\n\")\nmean_accuracy = 0\ntotal_correct = 0\nfor i in range(39):\n    print(\"Phoneme: \",cm.p39_label[i+1])\n    print(\"No.of Samples: \",res[i]['total'])\n    print(\"Correctly Predicted: \",res[i]['correct'])\n    print(\"Accuracy: {:.2f}\".format(res[i]['correct']*100\/res[i]['total']))\n    mean_accuracy += res[i]['correct']\/res[i]['total']\n    total_correct += res[i]['correct']\n    print(\"\\n\")\n    \nprint(\"-------------------------------------\")\nprint(\"Total Accuracy: {:.4f}\".format(total_correct\/test_labels.shape[0]))\nprint(\"Mean Accuracy: {:.4f}\".format(mean_accuracy\/39))","8f5c4549":"# DNN Part 2\n**Part 1 trains DNN model using single frame data.\nHere, we are training and testing DNN model using Multiple time frame samples. (Atleast 2)**"}}