{"cell_type":{"989a4cc9":"code","2da47468":"code","486ebf72":"code","2f3d05c1":"code","df8b0dc3":"code","713fcc42":"code","6bdf3370":"code","ea775283":"code","06d07039":"code","918f757d":"code","85747fc9":"code","e5eacfcf":"code","958460cb":"code","1e893c2f":"code","9f87db02":"code","07bf0fe2":"code","534cbbc7":"code","43325ae7":"code","9f650020":"code","278d795c":"code","a653f56a":"code","783131bd":"code","58a890e1":"code","e8177720":"code","836390b5":"code","5b2fd18e":"code","0595ceef":"markdown","ab8e2575":"markdown","cef4524d":"markdown"},"source":{"989a4cc9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2da47468":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nplt.style.use('fivethirtyeight')","486ebf72":"df=pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","2f3d05c1":"df=df.drop('Unnamed: 32', axis=1)","df8b0dc3":"diagnosis={'M':1, 'B':0}\ndf['diagnosis']=[diagnosis[x] for x in df['diagnosis']]","713fcc42":"X=df.drop('diagnosis', axis=1)\ny=df['diagnosis']\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","6bdf3370":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score, plot_roc_curve, plot_precision_recall_curve, balanced_accuracy_score\n\ndef clf_scores(clf, y_predicted):\n    # Accuracy\n    acc_train = clf.score(X_train, y_train)*100\n    acc_test = clf.score(X_test, y_test)*100\n    \n    roc = roc_auc_score(y_test, y_predicted)*100 \n    tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n    cm = confusion_matrix(y_test, y_predicted)\n    correct = tp + tn\n    incorrect = fp + fn\n    d=[acc_train, acc_test,  roc, correct, incorrect,  cm]\n    index=[\"acc_train\",'Test Accuracy',\"Roc Score\",\"COrrect\",\"Incorrect\",\"Confusion\"  ]\n    output=pd.DataFrame(data=d, index=index)\n    \n    d=sns.heatmap(cm, annot=True)\n    dd=plot_roc_curve(clf, X_train, y_train)\n    ddd=plot_precision_recall_curve(clf, X_train, y_train)\n\n    return output,d, dd, ddd\n    ","ea775283":"#1. Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression()\nclf_lr.fit(X_train, y_train)\n\nY_pred_lr = clf_lr.predict(X_test)\nprint(clf_scores(clf_lr, Y_pred_lr))","06d07039":"from sklearn.linear_model import LogisticRegression\nmodel= LogisticRegression()\nmodel.fit(X_train, y_train)","918f757d":"threshold = []\naccuracy = []\n\nfor p in np.unique(model.predict_proba(X_train)[:,1]):\n    threshold.append(p)\n    y_pred = (model.predict_proba(X_train)[:,1] >= p).astype(int)\n    accuracy.append(balanced_accuracy_score(y_train,y_pred))","85747fc9":"plt.figure(figsize=(10,6))\nplt.scatter(threshold,accuracy)\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Balanced accuracy\")\nplt.show()","e5eacfcf":"# step forward feature selection\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS","958460cb":"from sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay","1e893c2f":"lr = LogisticRegression()","9f87db02":"param_grid = [    \n    {'penalty' : ['l1', 'l2', 'elasticnet'],\n    'C' : np.logspace(-4, 4, 20),\n    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n    'max_iter' : [100, 1000,2500, 5000]\n    }\n]","07bf0fe2":"from sklearn.model_selection import GridSearchCV","534cbbc7":"clf = GridSearchCV(lr, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n","43325ae7":"best_clf = clf.fit(X_train,y_train)","9f650020":"best_clf.best_estimator_","278d795c":"model=LogisticRegression(C=78.47599703514607, penalty='l1', solver='liblinear')","a653f56a":"model.fit(X_train, y_train)","783131bd":"y_pred =model.predict_proba(X_train)[:,1] >= 0.5","58a890e1":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","e8177720":"y_test_pred=model.predict(X_test)>= 0.5","836390b5":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","5b2fd18e":"acc_train = model.score(X_train, y_train)*100\nacc_test = model.score(X_test, y_test)*100\n    \nroc = roc_auc_score(y_test, y_test_pred)*100 \ntn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\ncm = confusion_matrix(y_test, y_test_pred)\ncorrect = tp + tn\nincorrect = fp + fn\nd=[acc_train, acc_test,  roc, correct, incorrect,  cm]\nindex=[\"acc_train\",'Test Accuracy',\"Roc Score\",\"COrrect\",\"Incorrect\",\"Confusion\"  ]\noutput=pd.DataFrame(data=d, index=index)\n    \nsns.heatmap(cm, annot=True)\nplot_roc_curve(clf, X_train, y_train)\nplot_precision_recall_curve(clf, X_train, y_train)","0595ceef":"# Build Logistic Regression with Hyperparameter\n\n","ab8e2575":"# Threshold","cef4524d":"* The threshold probability should be 0.50.\n* C=78.47599703514607, penalty='l1', solver='liblinear'"}}