{"cell_type":{"9b32fccb":"code","972158ee":"code","7cc68bef":"code","1033f213":"code","7280f3cc":"code","ab08b9ee":"code","c721843c":"code","9b6e6c8b":"code","0773403f":"code","6a90bfca":"code","c196faa5":"code","e8d0c481":"markdown","a9cf7dea":"markdown","25148bca":"markdown","af970ba2":"markdown","cc7f6379":"markdown","bcc36661":"markdown","32cb4c7a":"markdown","aaab950a":"markdown","a1773892":"markdown"},"source":{"9b32fccb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","972158ee":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt","7cc68bef":"dataset = pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")\nX = dataset.drop(['math score', 'lunch','race\/ethnicity'],1)\ny = dataset['math score'].values\ny = y.reshape(len(y),1)\n","1033f213":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nct = ColumnTransformer(transformers = [(\"encoder1\", OneHotEncoder(),['parental level of education']), (\"encoder2\", OneHotEncoder(),['gender']),(\"encoder3\", OneHotEncoder(),['test preparation course']), (\"encoder4\", OneHotEncoder(),['test preparation course'])], remainder =\"passthrough\")\nX = np.array(ct.fit_transform(X))\n\nct.transformers_","7280f3cc":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)\n","ab08b9ee":"from sklearn.preprocessing import StandardScaler\nscx = StandardScaler()\nscy = StandardScaler()\nX_train[:,:12]=scx.fit_transform(X_train[:,:12])\nX_test[:,:12]= scx.transform(X_test[:,:12])\ny_train = scy.fit_transform(y_train)","c721843c":"from sklearn.svm import SVR\nregressor = SVR(kernel = 'rbf')\nregressor.fit(X_train, y_train.ravel())","9b6e6c8b":"y_pred = scy.inverse_transform(regressor.predict(X_test))\nnp.set_printoptions(precision = 2)\nprint(y_pred)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))","0773403f":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)","6a90bfca":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = regressor, X = X_test, y= y_test.ravel(), cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard davition: {:.2f}%\".format(accuracies.std()*100))\n","c196faa5":"from sklearn.model_selection import GridSearchCV\nparameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,0.9,]}]\ngrid_search = GridSearchCV(estimator = regressor,\n                          param_grid = parameters,\n                          scoring = 'r2',\n                           n_jobs = -1)\ngrid_search.fit(X_train, y_train.ravel())\nbest_accuracy = grid_search.best_score_\nbest_prameter = grid_search.best_params_\nprint(\"best accuracy: {:.2f}%\". format(best_accuracy*100))\nprint(\"best parameter \", best_prameter)","e8d0c481":"Preformance measurement using r2socre","a9cf7dea":"# Making prediction","25148bca":"# Data preprocessing\n\nHandling catogrical variables using colomun transformer, one hot encoding","af970ba2":"Reading dataset","cc7f6379":"# Hyperparameter tuning\n Using Grid_search_cv","bcc36661":"scaling the dataset using Standard scaller","32cb4c7a":"# Model building\n\nusing svr for regression","aaab950a":"spliting the dataset using train_test_split","a1773892":"cross validation of model using srocc_val_score"}}