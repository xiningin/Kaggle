{"cell_type":{"82831686":"code","9d3b9aef":"code","292ddccc":"code","2b4475bc":"code","1351f458":"code","8d5ab1ee":"code","79cb3f4c":"code","3a54253b":"code","73e5d45d":"code","3a216502":"code","f03e1df1":"code","de0ef500":"code","41af3495":"code","a68c9655":"code","ba52c5bb":"code","09715b82":"code","1350d1e9":"code","a9ddfa27":"code","5c9ff599":"code","94a50993":"code","95a0e0ef":"code","443c73b6":"code","c44f8a27":"code","359bb351":"code","80ec88a0":"code","b09d19a3":"code","177a52f8":"code","b4665bfc":"code","ae40cd8b":"code","f33db592":"code","ab08a78e":"code","c3cb864b":"code","70ee369e":"markdown","d8bfd9b4":"markdown"},"source":{"82831686":"import os\nimport shutil\nimport random\nimport numpy as np\nimport pandas as pd\nfrom zipfile import ZipFile as unzip\nimport matplotlib.pyplot as plt\n!pip install gdown\nimport gdown","9d3b9aef":"import tensorflow as tf\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img","292ddccc":"input_dir = '..\/input\/dogs-vs-cats\/'\nfor _ , _  , filenames in os.walk(input_dir):\n    for filename in filenames:\n        if filename[-3:]=='zip':\n            file = unzip(os.path.join(input_dir,filename),'r')\n            file.extractall()\n            file.close()","2b4475bc":"print(\"Number of train images: \" , len(os.listdir('.\/train')) )\nprint(\"Number of test images: \"  , len(os.listdir('.\/test1')) )","1351f458":"no_of_cats = len([files for files in os.listdir('.\/train') if 'cat' in files])\nno_of_dogs = len([files for files in os.listdir('.\/train') if 'dog' in files])\nprint(\"Cat images in train dataset: \",  no_of_cats)\nprint(\"Dog images in train dataset: \", no_of_dogs)\nif no_of_cats==no_of_dogs:\n  total_images = no_of_cats\n  print('Balanced dataset')","8d5ab1ee":"base_dir = 'data\/'\ndirs = ['train','val','test']\nsub_dirs = ['cats','dogs']\nfor dir in dirs:\n  dir =  os.path.join(base_dir, dir)\n  os.makedirs(dir,exist_ok=True)\n  for sub_dir in sub_dirs:\n    sub_dir = os.path.join(dir, sub_dir)\n    os.makedirs(sub_dir,exist_ok=True)","79cb3f4c":"split = {'train': 0.7,\n         'val': 0.3}\n\nfor dir in dirs[:2]:\n    print(int(split[dir]*total_images))","3a54253b":"split_size = 0.7\n\nsplit = {'train': (0,int(split_size*total_images)),\n         'val': (int(split_size*total_images),total_images)}\n\nfor obj in sub_dirs:\n  for dir in dirs[:2]:\n    files = ['{}.{}.jpg'.format(obj[:-1],i) for i in range(*split[dir])]\n    for filename in files:\n      src = os.path.join('.\/train', filename)\n      dst = os.path.join(base_dir,dir,obj,filename)\n      shutil.copyfile(src,dst)\nprint(\"Train validation split completed.\")","73e5d45d":"#os.makedirs(os.path.join(base_dir,'test','test_images',),exist_ok=True)\n#for filename in ['{}.jpg'.format(i) for i in range(1,1+len(os.listdir('test1')))]:\n#    src = os.path.join('.\/test1', filename)\n#    dst = os.path.join(base_dir,'test','test_images',filename)\n#    shutil.copyfile(src,dst)\n#print(\"Test files moved.\")","3a216502":"#shutil.rmtree('train')\n#shutil.rmtree('test1')","f03e1df1":"train_dir = os.path.join(base_dir, 'train')\nvalidation_dir = os.path.join(base_dir, 'val')\n\n# Directory with our training cat\/dog pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\n\n# Directory with our validation cat\/dog pictures\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')","de0ef500":"train_cat_fnames = os.listdir( train_cats_dir )\ntrain_dog_fnames = os.listdir( train_dogs_dir )\n\nprint(train_cat_fnames[:10])\nprint(train_dog_fnames[:10])","41af3495":"print('total training cat images :', len(os.listdir(      train_cats_dir ) ))\nprint('total training dog images :', len(os.listdir(      train_dogs_dir ) ))\n\nprint('total validation cat images :', len(os.listdir( validation_cats_dir ) ))\nprint('total validation dog images :', len(os.listdir( validation_dogs_dir ) ))","a68c9655":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over images","ba52c5bb":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nnext_cat_pix = [os.path.join(train_cats_dir, fname) \n                for fname in train_cat_fnames[ pic_index-8:pic_index] \n               ]\n\nnext_dog_pix = [os.path.join(train_dogs_dir, fname) \n                for fname in train_dog_fnames[ pic_index-8:pic_index]\n               ]\n\nfor i, img_path in enumerate(next_cat_pix+next_dog_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()","09715b82":"model = tf.keras.models.Sequential([\n        Conv2D(128,kernel_size=(3,3),activation='relu',input_shape=(150,150,3)),\n        Conv2D(64,kernel_size=(3,3),activation='relu'),\n        MaxPooling2D(4,4),\n\n        Conv2D(128,kernel_size=(3,3),activation='relu'),    \n        Conv2D(64,kernel_size=(3,3),activation='relu'),\n        MaxPooling2D(4,4),\n    \n        Flatten(),    \n        Dense(512,activation='relu') ,\n        Dropout(rate=0.3),\n        Dense(1, activation='sigmoid'),    \n        ])","1350d1e9":"model.summary()","a9ddfa27":"model.compile(optimizer=RMSprop(learning_rate=0.001),\n              loss='binary_crossentropy',\n              metrics = ['accuracy'])","5c9ff599":"datagen = ImageDataGenerator(rescale = 1.0\/255,\n                            rotation_range=40,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.2,\n                            zoom_range=0.2,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\n\ntrain_generator = datagen.flow_from_directory(train_dir,\n                                              batch_size=20,\n                                              class_mode ='binary',\n                                              target_size=(150,150))\nvalidation_generator = datagen.flow_from_directory(validation_dir,\n                                                   batch_size=20,\n                                                   class_mode='binary',\n                                                   target_size = (150,150))","94a50993":"for _ in range(5):\n    img, label = train_generator.next()\n    print(img.shape)   #  (1,256,256,3)\n    print(label[0])\n    plt.imshow(img[0])\n    plt.show()","95a0e0ef":"my_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint(filepath='saved\/model.{epoch:02d}-{val_loss:.2f}.h5',save_weights_only=False),\n    tf.keras.callbacks.TensorBoard(log_dir='saved\/logs'),\n]","443c73b6":"histroy = model.fit(train_generator,\n                    validation_data = validation_generator,\n                    steps_per_epoch=100,\n                    epochs=50,\n                    validation_steps = 50,\n                    verbose=2,\n                   callbacks=[my_callbacks])","c44f8a27":"# save weights\nmodel.save('\/saved\/dogs_vs_cats_model.h5')","359bb351":"successive_outputs = [layer.output for layer in model.layers[1:]]\n\n#visualization_model = Model(img_input, successive_outputs)\nvisualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n\n# Let's prepare a random input image of a cat or dog from the training set.\ncat_img_files = [os.path.join(train_cats_dir, f) for f in train_cat_fnames]\ndog_img_files = [os.path.join(train_dogs_dir, f) for f in train_dog_fnames]\n\nimg_path = random.choice(cat_img_files + dog_img_files)\nimg = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n\nx   = img_to_array(img)                           # Numpy array with shape (150, 150, 3)\nx   = x.reshape((1,) + x.shape)                   # Numpy array with shape (1, 150, 150, 3)\n\n# Rescale by 1\/255\nx \/= 255.0\n\n# Let's run our image through our network, thus obtaining all\n# intermediate representations for this image.\nsuccessive_feature_maps = visualization_model.predict(x)\n\n# These are the names of the layers, so can have them as part of our plot\nlayer_names = [layer.name for layer in model.layers]\n\n# -----------------------------------------------------------------------\n# Now let's display our representations\n# -----------------------------------------------------------------------\nfor layer_name, feature_map in zip(layer_names, successive_feature_maps):\n  \n  if len(feature_map.shape) == 4:\n    \n    #-------------------------------------------\n    # Just do this for the conv \/ maxpool layers, not the fully-connected layers\n    #-------------------------------------------\n    n_features = feature_map.shape[-1]  # number of features in the feature map\n    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n    \n    # We will tile our images in this matrix\n    display_grid = np.zeros((size, size * n_features))\n    \n    #-------------------------------------------------\n    # Postprocess the feature to be visually palatable\n    #-------------------------------------------------\n    for i in range(n_features):\n      x  = feature_map[0, :, :, i]\n      x -= x.mean()\n      x \/= x.std ()\n      x *=  64\n      x += 128\n      x  = np.clip(x, 0, 255).astype('uint8')\n      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n\n    #-----------------\n    # Display the grid\n    #-----------------\n\n    scale = 20. \/ n_features\n    plt.figure( figsize=(scale * n_features, scale) )\n    plt.title ( layer_name )\n    plt.grid  ( False )\n    plt.imshow( display_grid, aspect='auto', cmap='viridis' )","80ec88a0":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = model.history.history[     'accuracy' ]\nval_acc  = model.history.history[ 'val_accuracy' ]\nloss     = model.history.history[    'loss' ]\nval_loss = model.history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","b09d19a3":"saved_model = tf.keras.models.load_model('\/saved\/dogs_vs_cats_model.h5')","177a52f8":"# for filename in ['{}.jpg'.format(i) for i in range(1,1+len(os.listdir('test1')))]:\n#    path = os.path.join('test1',filename)\n#   img=image.load_img(path, target_size=(150, 150))\n#   x=image.img_to_array(img)\n#   x=np.expand_dims(x, axis=0)\n#   images = np.vstack([x])\n#   classes = model.predict(images, batch_size=10)","b4665bfc":"# test_generator = datagen.flow_from_directory('.\/data\/test',\n#                                               batch_size=20,\n#                                               class_mode =None,\n#                                               target_size=(150,150))\n# predictions = model.predict(test_generator)\n# predictions[:10]\n# mot going use this because the predcitions are random. Pictures are shuffled.\n# A better way is to first load the test file into a dataframe and then use flow_from_dataframe method.\n# Need tto implement flow_from_dataframe.","ae40cd8b":"predictions = []\nfor filename in ['{}.jpg'.format(i) for i in range(1,1+len(os.listdir('test1')))]:\n  img = load_img(os.path.join('test1',filename), target_size=(150, 150))\n  x = img_to_array(img)                         # Numpy array with shape (150, 150, 3)\n  x = x.reshape((1,) + x.shape)                 # Numpy array with shape (1, 150, 150, 3)\n  x \/= 255.0\n  y_hat= model.predict(x)\n  predictions.append(y_hat)","f33db592":"pred=np.asarray(predictions)\npred=np.squeeze(pred)\nfor i, y_hat in enumerate(pred):\n    pred[i] = 1 if y_hat>0.5 else 0","ab08a78e":"index_values = [i+1 for i in range(len(pred))]\ncolumn_label = ['label']\n\n# creating the dataframe\ndf = pd.DataFrame(data = pred, \n                  index = index_values, \n                  columns = column_label)","c3cb864b":"df.to_csv('submission.csv', index_label='id')","70ee369e":"## Load data","d8bfd9b4":"<a href=\"https:\/\/colab.research.google.com\/github\/concaption\/cats-vs-dogs\/blob\/main\/cats_vs_dogs.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>"}}