{"cell_type":{"0939fb69":"code","4aa987ea":"code","96d66b3b":"code","04054620":"code","8ce1e14d":"code","b8fc8e27":"code","f26ebcad":"code","51e03f4e":"code","549d4338":"markdown","1cbad4e8":"markdown","9191a019":"markdown","80c79414":"markdown","e1fad027":"markdown"},"source":{"0939fb69":"import numpy as np\nimport pandas as pd\npd.options.display.max_rows=300\npd.options.display.max_columns=300\n\nfrom typing import List\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","4aa987ea":"# load up data\ntrain = pd.read_csv('..\/input\/jane-street-market-prediction\/train.csv')\n","96d66b3b":"# sanity check data\nprint(train.head())","04054620":"\n# load up feature meta-data\nfeature_info = pd.read_csv('..\/input\/jane-street-market-prediction\/features.csv')\n","8ce1e14d":"# sanity check \n\nprint(feature_info.describe(include='all'))\ntag_features = features = [c for c in feature_info.columns if 'tag_' in c]\nprint(tag_features)","b8fc8e27":"\n# tagged features are strongly correlated\n# graph correlations between features by tag\n\nsample_data = train.sample(frac=.1)\nn_samples = len(sample_data)\nn_features = len(features)\nprint('n samples', n_samples)\n\ntags = tag_features\nn_tags = len(feature_info)\n\n\n\nfor i in range(3):\n#for i in range(n_features):\n\n    tag = tags[i]\n    print(tag)\n\n    feature_list = list(feature_info[feature_info[tag] == True]['feature'])\n    \n    z = sample_data[feature_list]\n    corr_df = np.abs(z.corr())\n    \n    # stronger correlations have larger values so reverse it to show stronger correlations \n    # closer and weaker corrrelations further apart\n    corr_df = corr_df - 1\n    \n \n\n    links_df = corr_df.stack().reset_index()\n    links_df.columns = ['source', 'target', 'weight']\n    \n    plt.figure(figsize=(20,20))\n    plt.title(tags[i])\n    g = nx.from_pandas_edgelist(links_df, 'source', 'target', 'weight')\n    nx.draw(g, with_labels=True, node_color='orange', node_size=4, edge_color='blue')\n    plt.show()\n","f26ebcad":"# fetch a sample of data from middle to avoid edge weirdness, if any\nordered_sample = train.loc[10000:80000]\nprint(len(ordered_sample))","51e03f4e":"# look for time patterns in features vs time stamp id\nfeatures = [c for c in train.columns if 'feature_' in c]\nn_features = len(features)\n\ndef plotFeatureSplits(df, f):\n\n        plt.figure(figsize=(10, 10))\n\n        plt.scatter(df['ts_id'], df[f], s=.2)\n        plt.title(f, color='white')\n        plt.ylabel(f)\n        plt.xlabel('td_id')\n        plt.show()\n        \n        \n# sample run just to check or run all range(1, n_features)\n# skip feature_0\nfor i in range(1, 5):\n#for i in range(1, len(features)):\n    plotFeatureSplits(ordered_sample, features[i])","549d4338":"## Fetch data","1cbad4e8":"## Import libraries\n","9191a019":"### Build correlation dataframe, convert to link dataframe, plot graphs","80c79414":"### Look for temporal patterns, (idea from https:\/\/www.kaggle.com\/lachlansuter\/important-and-hidden-temporal-data )","e1fad027":"# Explore Feature Correlations with graphics\n\n(Linda Cobb, http:\/\/github.com\/timestocome)\n\n### Lots of features and a huge dataset make it difficult to analyze data with list of numbers\n\n### Loops have been set to only loop over a few samples, use can use the commented line below to go through full dataset\n\n\n### * edit: correlations are strongest with larger numbers so graph plot should invert that so that stronger correlations closer to zero, weaker ones closer to one\n\n\n\n"}}