{"cell_type":{"696d8ce7":"code","519bb014":"code","b465081b":"code","1b9ad458":"code","5eea1fcf":"code","073ba741":"code","92c71c58":"code","081e7756":"code","5b2ea161":"code","eca9b320":"code","e019b217":"code","49375169":"code","e75549d6":"code","ad121c77":"code","259d0d16":"code","cbfea6dd":"code","2c92a968":"code","adff7ce5":"code","c3fa839c":"code","0753b94a":"code","13fe894f":"code","c59dcdd2":"code","4b0b6c93":"code","759e7a6b":"code","33725a5f":"code","8d8df7c5":"code","52f680ef":"code","547d1a4c":"code","c51adde7":"code","f525136b":"code","fe6cb733":"code","94e5dcba":"markdown","9a492561":"markdown","cf1f06de":"markdown","04bd1aaa":"markdown","62754a04":"markdown","94944b1e":"markdown","53f450a6":"markdown","cfdc0756":"markdown","bdb952d4":"markdown","55abfa98":"markdown","2aac3656":"markdown","b8f1e438":"markdown","160d0738":"markdown","19b365fd":"markdown","bc1d4ac5":"markdown","c7b24e4e":"markdown","cd0e2a1b":"markdown"},"source":{"696d8ce7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#to scale the data using z-score \nfrom sklearn.preprocessing import StandardScaler\n\n#importing PCA and TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE","519bb014":"data = pd.read_csv(\"..\/input\/autompg-dataset\/auto-mpg.csv\")","b465081b":"data.head()","1b9ad458":"data.info()","5eea1fcf":"data[\"car name\"].nunique()","073ba741":"# dropping car_name and origin\ndata1 = data.copy()\ndata = data.drop(['car name', 'origin'], axis=1)","92c71c58":"# checking if there are values other than digits in the column 'horsepower' \nhpIsDigit = pd.DataFrame(data.horsepower.str.isdigit())  # if the string is made of digits store True else False\n\n# print isDigit = False!\ndata[hpIsDigit['horsepower'] == False]   # from temp take only those rows where hp has false","081e7756":"#Relacing ? with np.nan\ndata = data.replace('?', np.nan)\ndata[hpIsDigit['horsepower'] == False]","5b2ea161":"# Imputing the missing values with median value\ndata.horsepower.fillna(data.horsepower.median(), inplace=True)\ndata['horsepower'] = data['horsepower'].astype('float64')  # converting the hp column from object data type to float","eca9b320":"data.describe().T","e019b217":"for col in data.columns:\n     print(col)\n     print('Skew :',round(data[col].skew(),2))\n     plt.figure(figsize=(15,4))\n     plt.subplot(1,2,1)\n     data[col].hist()\n     plt.ylabel('count')\n     plt.subplot(1,2,2)\n     sns.boxplot(x=data[col])\n     plt.show()","49375169":"plt.figure(figsize=(8,8))\nsns.heatmap(data.corr(), annot=True)\nplt.show()","e75549d6":"# scaling the data\nscaler=StandardScaler()\ndata_scaled=pd.DataFrame(scaler.fit_transform(data), columns=data.columns)","ad121c77":"data_scaled.head()","259d0d16":"#Defining the number of principal components to generate \nn=data_scaled.shape[1]\n\n#Finding principal components for the data\npca = PCA(n_components=n, random_state=1) #Apply the PCA algorithm with random state = 1\n\ndata_pca1 = pd.DataFrame(pca.fit_transform(data_scaled)) #Fit and transform the pca function on scaled data\n\n#The percentage of variance explained by each principal component\nexp_var = pca.explained_variance_ratio_","cbfea6dd":"# visulaize the explained variance by individual components\nplt.figure(figsize = (10,10))\nplt.plot(range(1,8), exp_var.cumsum(), marker = 'o', linestyle = '--')\nplt.title(\"Explained Variances by Components\")\nplt.xlabel(\"Number of Components\")\nplt.ylabel(\"Cumulative Explained Variance\")","2c92a968":"# find the least number of components that can explain more than 90% variance\nsum = 0\nfor ix, i in enumerate(exp_var):\n  sum = sum + i\n  if(sum>0.90):\n    print(\"Number of PCs that explain at least 90% variance: \", ix+1)\n    break","adff7ce5":"pc_comps = ['PC1','PC2','PC3']\ndata_pca = pd.DataFrame(np.round(pca.components_[:3,:],2),index=pc_comps,columns=data_scaled.columns)\ndata_pca.T","c3fa839c":"plt.figure(figsize = (7,7))\nsns.scatterplot(x=data_pca1[0],y=data_pca1[1])\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.show()","0753b94a":"df_concat = pd.concat([data_pca1, data], axis=1)\n\nplt.figure(figsize = (7,7))\n#Create a scatter plot with x=0 and y=1 using df_concat dataframe\nsns.scatterplot(data = df_concat, x=df_concat[0], y=df_concat[1], hue ='cylinders')\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")","13fe894f":"#Apply the TSNE algorithm with random state = 1\ntsne = TSNE(n_components = 2, random_state=1)  \n\n#Fit and transform tsne function on the scaled data\ndata_tsne = tsne.fit_transform(data_scaled)","c59dcdd2":"data_tsne.shape","4b0b6c93":"data_tsne = pd.DataFrame(data = data_tsne, columns = ['Component 1', 'Component 2'])","759e7a6b":"data_tsne.head()","33725a5f":"sns.scatterplot(x=data_tsne.iloc[:,0],y=data_tsne.iloc[:,1])","8d8df7c5":"# Lets see scatter plot of the data w.r.t number of cyinders\nsns.scatterplot(x=data_tsne.iloc[:,0],y=data_tsne.iloc[:,1],hue=data.cylinders)","52f680ef":"# Lets assign points to the 3 different groups\ndef grouping(x):\n    first_component = x['Component 1']\n    second_component = x['Component 2']\n    if (first_component> 0) and (second_component >0): \n        return 'group_1'\n    if (first_component >-20 ) and (first_component < 5):\n        return 'group_2'\n    else: \n        return 'group_3'","547d1a4c":"data_tsne['groups'] = data_tsne.apply(grouping,axis=1)","c51adde7":"sns.scatterplot(x=data_tsne.iloc[:,0],y=data_tsne.iloc[:,1],hue=data_tsne.iloc[:,2])","f525136b":"data['groups'] = data_tsne['groups'] ","fe6cb733":"all_col = data.columns.tolist()\nplt.figure(figsize=(20, 20))\n\nfor i, variable in enumerate(all_col):\n    if i==7:\n        break\n    plt.subplot(4, 2, i + 1)\n    #Create boxplot with groups on the x-axis\n    sns.boxplot(y=data[variable], x=data['groups'])\n    plt.tight_layout()\n    plt.title(variable)\nplt.show()","94e5dcba":"#### Visualize the data in 2 dimensions using first two principal components ","9a492561":"## Dimensionality Reduction: PCA and tSNE\n-----------------------------\n\n## Objective: \n-----------------------------\nThe objective of this problem is to explore the data and reduce the number of features by using dimensionality reduction techniques like PCA and TSNE and generate meaningful insights. \n\n-----------------------------\n## Dataset: \n-----------------------------\nThere are 9 variables in the data: \n\n- mpg: miles per gallon\n- cyl: number of cylinders\n- disp: engine displacement (cu. inches) or engine size\n- hp: horsepower\n- wt: vehicle weight (lbs.)\n- acc: time taken to accelerate from O to 60 mph (sec.)\n- orgn: origin\n- yr: model year\n- car name: car model name","cf1f06de":"**Let's try adding hue to the scatter plot**","04bd1aaa":"#### Checking correlation","62754a04":"#### Let's check the distribution and outliers for each column in the data","94944b1e":"## Principal Component Analysis","53f450a6":"#### Checking values in horsepower column","cfdc0756":"## Importing necessary libraries and overview of the dataset","bdb952d4":"#### Check the info of the data","55abfa98":"#### Loading data","2aac3656":"**Observation:**\n\n- There are 398 observations and 8 columns in the data.\n- All variables except horsepower and car name are of numeric data type.\n- The horsepower must be a numeric data type. We will explore this further.","b8f1e438":"## t-SNE","160d0738":"#### Check the summary statistics of the data ","19b365fd":"#### Apply PCA algorithm with number of components equal to the total number of columns in the data","bc1d4ac5":"## Data Preprocessing and Exploratory Data Analysis","c7b24e4e":"#### Scaling the data","cd0e2a1b":"#### Apply TSNE embedding with 2 components for the dataframe data_scaled"}}