{"cell_type":{"f28521eb":"code","d21117c1":"code","aae40721":"code","b0237963":"code","d4a058d7":"code","b387c469":"code","a20564f6":"code","dd0047fc":"code","a277c151":"code","d3de67db":"code","93a96a0b":"code","59b80321":"code","abc10530":"code","0d0b7cc2":"code","7bd7902a":"code","43fcc2d3":"code","0be6e72a":"code","8995e8cb":"code","949f9ccc":"code","54d87624":"code","af4ae9e9":"code","6d9c015e":"code","e9046a37":"code","a20dcfa1":"code","aafae7ce":"code","06c85435":"code","59812c8f":"code","a6d23c32":"code","ee1af3e7":"code","07f3a732":"code","3f5c0398":"markdown","c0f93c36":"markdown","07f43efc":"markdown","71bd3987":"markdown","1d2a9e6c":"markdown","d8052de4":"markdown","6ef54694":"markdown","524ee27f":"markdown","40ca4cf9":"markdown","7e752b15":"markdown","37e33741":"markdown","75cbb6ce":"markdown","8b4b2701":"markdown","1a4d89ac":"markdown","0b533242":"markdown","8b91a222":"markdown","32d1434c":"markdown","6ff8eb85":"markdown","c3d7c52a":"markdown","b3e67c80":"markdown","659b18d5":"markdown","93dc41aa":"markdown","1cedf9dc":"markdown","1d64dde8":"markdown","d72051fc":"markdown","577ba43b":"markdown","c1939298":"markdown","4b045baf":"markdown","6042083c":"markdown","0c332e0b":"markdown","791abe82":"markdown","56b39caf":"markdown","797daefc":"markdown","b4996307":"markdown","489e6176":"markdown","fbaf4795":"markdown"},"source":{"f28521eb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport warnings\nwarnings.filterwarnings('ignore')","d21117c1":"dataset = pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')","aae40721":"dataset","b0237963":"dataset.isnull().sum()","d4a058d7":"#Pandas style correlation table\ncorr = dataset.corr()\ncorr.style\\\n    .background_gradient(cmap='bwr')\\\n    .set_precision(2)","b387c469":"#Seaborn heatmap visualization\nplt.figure(figsize = (12, 12))\nplt.title(\"Feature Correlations\", fontsize = 18)\nsns.heatmap(corr, annot = True, cmap = \"Blues\")","a20564f6":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nnumeric_ds = dataset.select_dtypes(['number'])\nvif[\"features\"] = numeric_ds.columns\nvif[\"VIF\"] = [variance_inflation_factor(numeric_ds.values, i) for i in range(numeric_ds.shape[1])]\nvif","dd0047fc":"numeric_ds = numeric_ds.drop('RestingBP', axis=1)\nvif.drop(vif.index, inplace=True)\nvif[\"features\"] = numeric_ds.columns\nvif[\"VIF\"] = [variance_inflation_factor(numeric_ds.values, i) for i in range(numeric_ds.shape[1])]\nvif","a277c151":"numeric_ds = numeric_ds.drop('Age', axis=1)\nvif.drop(vif.index, inplace=True)\nvif[\"features\"] = numeric_ds.columns\nvif[\"VIF\"] = [variance_inflation_factor(numeric_ds.values, i) for i in range(numeric_ds.shape[1])]\nvif","d3de67db":"dataset = dataset.drop(['Age', 'RestingBP'], axis=1)\ndataset","93a96a0b":"dataset.select_dtypes(exclude=\"number\").nunique()","59b80321":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndataset['Sex']=le.fit_transform(dataset['Sex'])\ndataset['ExerciseAngina']=le.fit_transform(dataset['ExerciseAngina'])\ndataset","abc10530":"dataset = pd.get_dummies(dataset, drop_first=False)\ndataset","0d0b7cc2":"heart_dis = dataset['HeartDisease']\ndataset = dataset.drop('HeartDisease', axis=1)\ndataset.insert(loc=len(dataset.columns), column='HeartDisease', value=heart_dis)\ndataset","7bd7902a":"x = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","43fcc2d3":"print(x)","0be6e72a":"print(y)","8995e8cb":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=27)","949f9ccc":"print(x_train)","54d87624":"print(y_train)","af4ae9e9":"print(x_test)","6d9c015e":"print(y_test)","e9046a37":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","a20dcfa1":"print(x_train)","aafae7ce":"print(x_test)","06c85435":"from sklearn.svm import SVC\nclassifier = SVC(kernel='rbf', random_state=27)\nclassifier.fit(x_train, y_train)","59812c8f":"y_pred = classifier.predict(x_test)","a6d23c32":"result_np = np.concatenate((y_pred.reshape(len(y_pred), 1), (y_test.reshape(len(y_test), 1))), 1)\nresult = pd.DataFrame(result_np, columns=['Prediction', 'Real_Value'])\nresult","ee1af3e7":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","07f3a732":"from sklearn.model_selection import cross_val_score\nval_score = cross_val_score(estimator=classifier, X = x_train, y=y_train, cv=10)\nprint(\"Accuracy: {:.2f} %\".format(val_score.mean()*100))\nprint(\"Std. Dev: {:.2f} %\".format(val_score.std()*100))","3f5c0398":"Separated the features as x and the dependant variable as y. Both is transformed to numpy array for modelling function to work.","c0f93c36":"## Step 3 - Data Preprocessing","07f43efc":"## Step 1 - Importing Library","71bd3987":"### 2.4 Encoding Categorical Features","1d2a9e6c":"#### 2.3.2 Variance Inflation Factor","d8052de4":"### 3.1 Separated the Training Set and Test Set","6ef54694":"Now we got the predicting result of the test set and we can see some wrong prediction already.","524ee27f":"#### 2.3.1 Feature Correlation","40ca4cf9":"Separated the overall dataset to training set to train the classification model later on and test set to validate and calculate accuracy. Random state is 27 because.....just my lucky number.","7e752b15":"### 5.1 Get the Accuracy Report","37e33741":"Encoded Sex to : 1 if Male, 0 if Female, <br> Encoded ExerciseAngina to : 1 if Yes, 0 if No.","75cbb6ce":"The accuracy measured using 10-Fold Cross Validation is 83-89% using SVC model with RBF kernel.","8b4b2701":"### 3.1 Transforming Dataset to Array","1a4d89ac":"### 3.2 Scaling the Training Set","0b533242":"We can see there are 918 set of data for 12 features. From this function, we could see which feature is categorical or numerical also.","8b91a222":"The restingBP, Age, and MaxHR have VIF big value. It is showing that there are colinearity in those 3 features. Therefore, we drop the biggest VIF (RestingBP) then calculate again the VIF.","32d1434c":"There are 5 features which need to be encoded. Sex and ExerciseAngina can used the label encoding and the others can use one hot encoding.","6ff8eb85":"Re-order the HeartDisease column into the rightmost of the dataset to mark it as the dependant variable from the dataset. Now we're ready for the classification model building.","c3d7c52a":"That's more like it. After dropping RestingBP and Age, we got VIF which acceptable. Is is indeed showing similiar information between Age, RestingBP, and MaxHR. I'm not from medical background, but it is logical that someone's resting blood pressure and heart rate is varies depend on someone's age. Therefore, we drop those 2 features from our main dataset.","b3e67c80":"### 2.5 Dataset Reordering","659b18d5":"Scale the value of training set to between -3 and 3 to make sure no feature overwhelm the others. The test set is scaled using same scale as training set.","93dc41aa":"### 4.2 Predicting the Test Set Result","1cedf9dc":"### 2.2 Checking Blank Value or Missing Value","1d64dde8":"## Step 4 - Classification Model Building using SVC with RBF Kernel","d72051fc":"### 2.3 Finding Correlation for Every Numerical Features","577ba43b":"We could see that the VIF reduced. Now we proceed to drop Age then calculate again the VIF.","c1939298":"## Step 5 - Measuring Model Accuracy","4b045baf":"### 4.1 Model Building and Training with the Training Set","6042083c":"Random state is set to 27 because...again...my lucky number.","0c332e0b":"### 2.1 Dataset Importing and Overview","791abe82":"Not much different in the correlation of each feature with the heart disease. We proceed to analyze the Variance Inflation Factor (VIF) to see the colinearity.","56b39caf":"We got the accuracy of 87% by using the SVC model with RBF kernel.","797daefc":"## Step 2 - Dataset Preparation","b4996307":"One-Hot Encoded the remaining categorical features.","489e6176":"### 5.2 Get the Accuracy Report with K-Fold Cross Validation","fbaf4795":"There are no blank value or missing value in the dataset."}}