{"cell_type":{"08b20817":"code","8244be5c":"code","de593132":"code","63a20565":"code","c98d6712":"code","bcb5401e":"code","e82683db":"code","926c9640":"code","c7791a2d":"code","06787be9":"code","ecee4369":"code","02c3d0bc":"code","c76fb154":"code","99c244c6":"code","80fd3214":"code","d673b997":"code","97dfed42":"code","347f85e0":"code","92d2bc2c":"code","8de6edb1":"code","4c7ecc48":"markdown","8590dcc6":"markdown","01e04da7":"markdown","5b93dc0c":"markdown","f78a405d":"markdown","b42b0f3d":"markdown","86ab97b1":"markdown","1896d24d":"markdown","197d78a0":"markdown","637641bf":"markdown","cf71986e":"markdown","676e062c":"markdown","0898884f":"markdown","83bf7326":"markdown","c40f000b":"markdown","0192e14a":"markdown","d43ade5a":"markdown","c545338a":"markdown","d47f9224":"markdown"},"source":{"08b20817":"import numpy as np\nimport pandas as pd\n\n\npd.set_option(\"display.max_columns\", None)\n\ntrain_df = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/test.csv\")\nsub_df = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv\")\n\ntrain_df.head()","8244be5c":"train_df.drop(\"Id\", axis=1, inplace=True)\ntest_df.drop(\"Id\", axis=1, inplace=True)","de593132":"cols = [\"Soil_Type7\", \"Soil_Type15\"]\n\ntrain_df.drop(cols, axis=1, inplace=True)\ntest_df.drop(cols, axis=1, inplace=True)","63a20565":"idx = train_df[train_df[\"Cover_Type\"] == 5].index\ntrain_df.drop(idx, axis=0, inplace=True)","c98d6712":"new_names = {\n    \"Horizontal_Distance_To_Hydrology\": \"x_dist_hydrlgy\",\n    \"Vertical_Distance_To_Hydrology\": \"y_dist_hydrlgy\",\n    \"Horizontal_Distance_To_Roadways\": \"x_dist_rdwys\",\n    \"Horizontal_Distance_To_Fire_Points\": \"x_dist_firepts\"\n}\n\ntrain_df.rename(new_names, axis=1, inplace=True)\ntest_df.rename(new_names, axis=1, inplace=True)","bcb5401e":"from sklearn.preprocessing import LabelEncoder\n\n\nencoder = LabelEncoder()\ntrain_df[\"Cover_Type\"] = encoder.fit_transform(train_df[\"Cover_Type\"])","e82683db":"train_df[\"Aspect\"][train_df[\"Aspect\"] < 0] += 360\ntrain_df[\"Aspect\"][train_df[\"Aspect\"] > 359] -= 360\n\ntest_df[\"Aspect\"][test_df[\"Aspect\"] < 0] += 360\ntest_df[\"Aspect\"][test_df[\"Aspect\"] > 359] -= 360","926c9640":"# Manhhattan distance to Hydrology\ntrain_df[\"mnhttn_dist_hydrlgy\"] = np.abs(train_df[\"x_dist_hydrlgy\"]) + np.abs(train_df[\"y_dist_hydrlgy\"])\ntest_df[\"mnhttn_dist_hydrlgy\"] = np.abs(test_df[\"x_dist_hydrlgy\"]) + np.abs(test_df[\"y_dist_hydrlgy\"])\n\n# Euclidean distance to Hydrology\ntrain_df[\"ecldn_dist_hydrlgy\"] = (train_df[\"x_dist_hydrlgy\"]**2 + train_df[\"y_dist_hydrlgy\"]**2)**0.5\ntest_df[\"ecldn_dist_hydrlgy\"] = (test_df[\"x_dist_hydrlgy\"]**2 + test_df[\"y_dist_hydrlgy\"]**2)**0.5","c7791a2d":"soil_features = [x for x in train_df.columns if x.startswith(\"Soil_Type\")]\ntrain_df[\"soil_type_count\"] = train_df[soil_features].sum(axis=1)\ntest_df[\"soil_type_count\"] = test_df[soil_features].sum(axis=1)\n\nwilderness_features = [x for x in train_df.columns if x.startswith(\"Wilderness_Area\")]\ntrain_df[\"wilderness_area_count\"] = train_df[wilderness_features].sum(axis=1)\ntest_df[\"wilderness_area_count\"] = test_df[wilderness_features].sum(axis=1)","06787be9":"train_df.loc[train_df[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\ntest_df.loc[test_df[\"Hillshade_9am\"] < 0, \"Hillshade_9am\"] = 0\n\ntrain_df.loc[train_df[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\ntest_df.loc[test_df[\"Hillshade_Noon\"] < 0, \"Hillshade_Noon\"] = 0\n\ntrain_df.loc[train_df[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\ntest_df.loc[test_df[\"Hillshade_3pm\"] < 0, \"Hillshade_3pm\"] = 0\n\ntrain_df.loc[train_df[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\ntest_df.loc[test_df[\"Hillshade_9am\"] > 255, \"Hillshade_9am\"] = 255\n\ntrain_df.loc[train_df[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\ntest_df.loc[test_df[\"Hillshade_Noon\"] > 255, \"Hillshade_Noon\"] = 255\n\ntrain_df.loc[train_df[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255\ntest_df.loc[test_df[\"Hillshade_3pm\"] > 255, \"Hillshade_3pm\"] = 255","ecee4369":"from sklearn.preprocessing import RobustScaler\n\n\ncols = [\n    \"Elevation\",\n    \"Aspect\",\n    \"mnhttn_dist_hydrlgy\",\n    \"ecldn_dist_hydrlgy\",\n    \"soil_type_count\",\n    \"wilderness_area_count\",\n    \"Slope\",\n    \"x_dist_hydrlgy\",\n    \"y_dist_hydrlgy\",\n    \"x_dist_rdwys\",\n    \"Hillshade_9am\",\n    \"Hillshade_Noon\",\n    \"Hillshade_3pm\",\n    \"x_dist_firepts\",\n    \"soil_type_count\",\n    \"wilderness_area_count\"\n]\n\nscaler = RobustScaler()\ntrain_df[cols] = scaler.fit_transform(train_df[cols])\ntest_df[cols] = scaler.transform(test_df[cols])","02c3d0bc":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtypes\n\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n\n    if verbose:\n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n \n    return df","c76fb154":"train_df = reduce_mem_usage(train_df)\ntest_df = reduce_mem_usage(test_df)","99c244c6":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, BatchNormalization\n\n\nINPUT_SHAPE = test_df.shape[1:]\nNUM_CLASSES = train_df[\"Cover_Type\"].nunique()\n\ndef build_model():\n    model = Sequential([\n        Dense(units=300, kernel_initializer=\"lecun_normal\", activation=\"selu\", input_shape=INPUT_SHAPE),\n        BatchNormalization(),\n        Dense(units=200, kernel_initializer=\"lecun_normal\", activation=\"selu\"),\n        BatchNormalization(),\n        Dense(units=100, kernel_initializer=\"lecun_normal\", activation=\"selu\"),\n        BatchNormalization(),\n        Dense(units=50, kernel_initializer=\"lecun_normal\", activation=\"selu\"),\n        BatchNormalization(),\n        Dense(units=NUM_CLASSES, activation=\"softmax\")\n    ])\n\n    model.compile(\n        optimizer=\"adam\",\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n\n    return model","80fd3214":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\n\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.5,\n    patience=5\n)\n\nearly_stop = EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=20,\n    restore_best_weights=True\n)\n\ncallbacks = [reduce_lr, early_stop]","d673b997":"build_model().summary()","97dfed42":"from tensorflow.keras.utils import plot_model\n\n\nplot_model(\n    build_model(),\n    show_shapes=True,\n    show_layer_names=True\n)","347f85e0":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\n\nX = train_df.drop(\"Cover_Type\", axis=1).values\ny = train_df[\"Cover_Type\"].values\n\ndel train_df\n\nFOLDS = 20\nEPOCHS = 200\nBATCH_SIZE = 2048\n\ntest_preds = np.zeros((1, 1))\nscores = []\n\ncv = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n    X_train, X_val = X[train_idx], X[val_idx]\n    y_train, y_val = y[train_idx], y[val_idx]\n\n    model = build_model()\n    model.fit(\n        X_train,\n        y_train,\n        validation_data=(X_val, y_val),\n        epochs=EPOCHS,\n        batch_size=BATCH_SIZE,\n        callbacks=callbacks,\n        verbose=False\n    )\n\n    y_pred = np.argmax(model.predict(X_val), axis=1)\n    score = accuracy_score(y_val, y_pred)\n    scores.append(score)\n\n    test_preds = test_preds + model.predict(test_df)\n    print(f\"Fold {fold} Accuracy: {score}\")\n\nprint()\nprint(f\"Mean Accuracy: {np.mean(scores)}\")","92d2bc2c":"test_preds = np.argmax(test_preds, axis=1)\ntest_preds = encoder.inverse_transform(test_preds)\n\nsub_df['Cover_Type'] = test_preds\nsub_df.head()","8de6edb1":"sub_df.to_csv(\"submission.csv\", index=False)","4c7ecc48":"Renaming some columns with long names","8590dcc6":"I have used Self-normalizing Neural Networks here which is described in this notebook: https:\/\/www.kaggle.com\/gulshanmishra\/self-normalizing-neural-networks","01e04da7":"**Version 2**:\n1. Fixed ranges of Aspect and Hillshade columns\n2. Used RobustScaler instead of MinMaxScaler\n\n**Version 3**:\n1. Used 20 folds rather than 10 :p\n2. Used soft voting instead of hard voting","5b93dc0c":"# Part 2: Feature Engineering","f78a405d":"Encoding all the labels so that they range from 0 to 5.","b42b0f3d":"Using soft voting strategy to ensemble test predictions","86ab97b1":"A quick Google search about **Hillshade** leads to the following result:\n\n> Hillshading computes surface illumination as values from 0 to 255 based on a given compass direction to the sun (azimuth) and a certain altitude above the horizon (altitude). Hillshades are often used to produce maps that are visually appealing.\n\nThus, hillshade is a 3D representation of a terrain which is used to gain insight about its form by measuring luminosity of certain patches of that terrain that results when a source of light is casted at a particular angle.\n\nMore Information about hillshade [here](http:\/\/www.geography.hunter.cuny.edu\/~jochen\/gtech361\/lectures\/lecture11\/concepts\/hillshade.htm#:~:text=Hillshading%20computes%20surface%20illumination%20as,maps%20that%20are%20visually%20appealing.)\n\nIn both train and test datasets, there are certain rows with hillshade value more than 255 or less than 0. They must be the result of recording error and should be relpaced with an appropriate value. Perhaps, values less than 0 refer to the darkest shade and replacing them with 0 should be fine. Similarly, we can assume that hillshade values more than 255 refer to the brightest shades and a value of 255 should be good replacement.","1896d24d":"Reducing the size of train and test dataframes","197d78a0":"Scaling with RobustScaler","637641bf":" # Part 1: Reading data and preprocessing","cf71986e":"# Part 3: Modelling with Neural Network","676e062c":"**Aspect** is the compass direction that a terrain faces. Here, It is expressed in degrees. All the values from 0 to 359 are present. Besides, there are some values greater than 359 and some smaller than 0. It will be better If we make all the values in this column lie in the range (0, 359). Moreover, all the values in this column lies in the range (-360, 720) so adding 360 to angles smaller than 0 and subtracting 360 from angles greater than 359 will do the work.","0898884f":"Creating distance based features from **Horizontal_Distance_To_Hydrology** and **Vertical_Distance_To_Hydrology**.","83bf7326":"Dropping the **Id** column from both train and test datasets.","c40f000b":"Callbacks for early stopping and learning rate reduction when it \"plateaus\"","0192e14a":"Dropping the row with **Cover_Type**=5 because there is only a single row corresponding to it.","d43ade5a":"Dropping columns **Soil_Type7** and **Soil_Type15** because all the rows in these column have the same value.","c545338a":"Please consider **UPVOTING** If you like this notebook :)","d47f9224":"Creating the following new features:\n1. Sum of all the soil types\n2. Sum of all the wilderness area types\n\nThese features are borrowed from this discussion topic: https:\/\/www.kaggle.com\/c\/tabular-playground-series-dec-2021\/discussion\/292823"}}