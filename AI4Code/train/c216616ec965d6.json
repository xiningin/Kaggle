{"cell_type":{"ee5c0cc0":"code","78983117":"code","3f55e656":"code","e94a5d37":"code","1b2c7957":"code","a10923e0":"code","02249848":"code","62f8c930":"code","c16990e2":"code","329340c8":"code","72963ed0":"markdown","c2e0df08":"markdown","f7602c40":"markdown","cb71ec69":"markdown","42bd4b56":"markdown","fc60724a":"markdown","dfc97167":"markdown","b64d3327":"markdown"},"source":{"ee5c0cc0":"import numpy as np\n\nfrom keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical\nimport keras.backend as K \n\nfrom keras.datasets import cifar10\nimport matplotlib.pyplot as plt","78983117":"NUM_CLASSES = 10\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()","3f55e656":"x_train = x_train.astype('float32') \/ 255.0\nx_test = x_test.astype('float32') \/ 255.0\n\ny_train = to_categorical(y_train, NUM_CLASSES)\ny_test = to_categorical(y_test, NUM_CLASSES)","e94a5d37":"input_layer = Input((32,32,3))\n\nx = Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = 'same')(input_layer)\nx = BatchNormalization()(x)\nx = LeakyReLU()(x)\n\n\nx = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(x)\nx = BatchNormalization()(x)\nx = LeakyReLU()(x)\n\n\nx = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same')(x)\nx = BatchNormalization()(x)\nx = LeakyReLU()(x)\n\n\nx = Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = 'same')(x)\nx = BatchNormalization()(x)\nx = LeakyReLU()(x)\n\n\nx = Flatten()(x)\n\nx = Dense(128)(x)\nx = BatchNormalization()(x)\nx = LeakyReLU()(x)\nx = Dropout(rate = 0.5)(x)\n\nx = Dense(NUM_CLASSES)(x)\noutput_layer = Activation('softmax')(x)\n\nmodel = Model(input_layer, output_layer)","1b2c7957":"model.summary()","a10923e0":"opt = Adam(lr=0.0005)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","02249848":"model.fit(x_train\n          , y_train\n          , batch_size=32\n          , epochs=10\n          , shuffle=True\n          , validation_data = (x_test, y_test))","62f8c930":"model.evaluate(x_test, y_test, batch_size=1000)","c16990e2":"CLASSES = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n\npreds = model.predict(x_test)\npreds_single = CLASSES[np.argmax(preds, axis = -1)]\nactual_single = CLASSES[np.argmax(y_test, axis = -1)]","329340c8":"n_to_show = 16\nindices = np.random.choice(range(len(x_test)), n_to_show)\n\n_=plt.subplots(figsize=(10,15));\nfor i, idx in enumerate(indices):\n    _=plt.subplot(4, 4, i+1)\n    img = x_test[idx]\n    _=plt.xticks([])\n    _=plt.yticks([])\n    if preds_single[idx] == actual_single[idx]:\n      color = 'green'\n    else:\n      color = 'red'\n    _=plt.xlabel(\"{} ({})\".format(preds_single[idx], actual_single[idx]), color=color, fontsize=15)\n    _=plt.imshow(img)","72963ed0":"# Being the first model, this needs more finetuning of parameters. Will soon come up with a more accurate model.","c2e0df08":"Building teh CNN Architecture","f7602c40":"# **My first CNN model on CIFAR dataset**","cb71ec69":"Importing the Libraries","42bd4b56":"Evaluating and predicting on test data","fc60724a":"Converting the images pixels in the range of -1 to 1, dividing by 255. As Neural Nets works best within this range of data.\nConverting the labels into categorical one-hot encoding, for machine to categorize.","dfc97167":"Loading the CIFAR-10 dataset and splitting in train and test","b64d3327":"Training the model"}}