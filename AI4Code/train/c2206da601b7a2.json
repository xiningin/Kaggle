{"cell_type":{"c603beaf":"code","fcdcdd7f":"code","f474ae85":"code","110849af":"code","45859db0":"code","705c567a":"code","5becaef2":"code","2877bf27":"code","24f4d960":"code","473e32d1":"code","e4cc21aa":"code","e0dbf546":"code","3fdcce47":"code","44825584":"code","f26986da":"code","b811deaf":"code","1e99b6c3":"code","b80be3e1":"code","e9004fc1":"markdown","2079b54b":"markdown","bb27fbf4":"markdown","69c71d1d":"markdown","99f5f3b1":"markdown","d7b91a62":"markdown","e59961a5":"markdown","1dafeb76":"markdown","1aaefced":"markdown","df0dd363":"markdown","841adec9":"markdown","0d4d8315":"markdown","752cb849":"markdown","df7f1dbb":"markdown"},"source":{"c603beaf":"# Importing needed libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n","fcdcdd7f":"# Defining list with labels\nlabels = ['Horse', 'Tiger', 'Cat', 'Dog', 'Polar bear']\n\n\n# Check point\n# Showing labels\nprint(labels)\n","f474ae85":"# Generating Numpy array with True classes' indexes\ny_true = np.random.randint(low=0, high=5, size=100, dtype=int)\n\n\n# Check point\n# Shwoing array\nprint(y_true)\n","110849af":"# Calculating number of samples for every class\n# Iterating all classes' indexes in 'y_true' array\n# Using Numpy function 'unique'\n# Returning sorted unique elements and their frequencies\nclassesIndexes, classesFrequency = np.unique(y_true, return_counts=True)\n\n\n# Printing frequency (number of samples) for every class\nprint('classes indexes:' , classesIndexes)\nprint('\\n')\nprint('classes frequency:', classesFrequency)\n","45859db0":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (10.0, 7.0)\n\n\n# Plotting histogram of 5 classes with their number of samples\n# Defining a figure object \nfigure = plt.figure()\n\n\n# Plotting Bar chart\nplt.bar(classesIndexes, classesFrequency, align='center', alpha=0.6)\n\n\n# Giving name to Y axis\nplt.ylabel('Class frequency', fontsize=16)\n\n\n# Giving names to every Bar along X axis\nplt.xticks(classesIndexes, labels, fontsize=16)\n\n\n# Giving name to the plot\nplt.title('Histogram', fontsize=20)\n\n\n# Saving the plot\nfigure.savefig('histogram.png', transparent=True, dpi=500)\n\n\n# Showing the plot\nplt.show()\n","705c567a":"# Making copy of array with True classes' indexes\ny_predicted = np.copy(y_true)\n","5becaef2":"# Choosing randomly 25% of classes to be changed\nii = np.random.randint(low=0, high=len(y_true), size=int(0.25 * len(y_true)), dtype=int)\n\n\n# Check point\n# Showing chosen indexes\nprint(ii)\n","2877bf27":"# Iterating chosen indexes and replacing them with other classes' indexes\nfor i in ii:\n    # Generating new class index\n    y_predicted[i] = np.random.randint(low=0, high=5, dtype=int)\n    \n    \n    # Check point\n    # Showing difference between True classes' indexes and Predicted ones\n    print('index = {0:2d}, True class => {1}, {2} <= Predicted class'.\n          format(i, y_true[i], y_predicted[i]))\n","24f4d960":"# Confusion Matrix is a two dimensional matrix that visualizes the performance,\n# and makes it easy to see confusion between classes,\n# by providing a picture of interrelation\n\n# Each row represents a number of actual, True class\n# Each column represents a number of predicted class\n\n\n# Computing Confusion Matrix to evaluate accuracy of classification\nc_m = confusion_matrix(y_true, y_predicted)\n\n# Showing Confusion Matrix in form of 2D Numpy array\nprint(c_m)\n","473e32d1":"# Magic function that renders the figure in a jupyter notebook\n# instead of displaying a figure object\n%matplotlib inline\n\n\n# Setting default size of the plot\n# Setting default fontsize used in the plot\nplt.rcParams['figure.figsize'] = (10.0, 9.0)\nplt.rcParams['font.size'] = 20\n\n\n# Implementing visualization of Confusion Matrix\ndisplay_c_m = ConfusionMatrixDisplay(c_m, display_labels=labels)\n\n\n# Plotting Confusion Matrix\n# Setting colour map to be used\ndisplay_c_m.plot(cmap='OrRd', xticks_rotation=25)\n# Other possible options for colour map are:\n# 'autumn_r', 'Blues', 'cool', 'Greens', 'Greys', 'PuRd', 'copper_r'\n\n\n# Setting fontsize for xticks and yticks\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\n\n\n# Giving name to the plot\nplt.title('Confusion Matrix', fontsize=24)\n\n\n# Saving plot\nplt.savefig('confusion_matrix.png', transparent=True, dpi=500)\n\n\n# Showing the plot\nplt.show()\n","e4cc21aa":"# Showing the main classification metrics\nprint(classification_report(y_true, y_predicted))\n","e0dbf546":"# print(help(np.copy))","3fdcce47":"# print(help(confusion_matrix))","44825584":"# print(help(classification_report))","f26986da":"# print(plt.colormaps())","b811deaf":"# print(plt.rcParams.keys())","1e99b6c3":"# print(help(plt.savefig))","b80be3e1":"# help(plt.xticks)","e9004fc1":"**Design**, **Train** & **Test** deep CNN for Image Classification.\n\n**Join** the course & enjoy new opportunities to get deep learning skills:\n\n\n[https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/](https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/?referralCode=12EE0D74A405BF4DDE9B)\n\n\n![](https:\/\/github.com\/sichkar-valentyn\/1-million-images-for-Traffic-Signs-Classification-tasks\/blob\/main\/images\/slideshow_classification.gif?raw=true)\n","2079b54b":"# \ud83d\udc41\ufe0f\u200d\ud83d\udde8\ufe0f Displaying Confusion Matrix","bb27fbf4":"# \ud83d\uddd2\ufe0f Some comments","69c71d1d":"# \ud83d\udce5 Importing libraries","99f5f3b1":"# \ud83c\udfb0 Generating True Vector","d7b91a62":"- **TP (True Positive)** is a number of **right predictions** that are **correct**  \nwhen label is **True** *and* predicted as **True**  \n  \n  \n- **TN (True Negative)** is a number of **right predictions** that are **incorrect**  \nwhen label is **False** *and* predicted as **False**  \n  \n  \n- **FP (False Positive)** is a number of **not right predictions** that are **incorrect**  \nwhen label is **False** *but* predicted as **True**  \n  \n  \n- **FN (False Negative)** is a number of **not right predictions** that are **correct**  \nwhen label is **True** *but* predicted as **False**  \n  \n  \n- **Precision**  is an accuracy of positive predictions  \nPrecision represents **percent of correct predictions**  \nIn other words, it is **ability not to label** an image **as positive** that is actually **negative**   \nPrecision is calculated by following equation:  \nPrecision = TP \/ (TP + FP)  \n  \n  \n- **Recall**  is a fraction of positive predictions among all True samples  \nIn other words, it is **ability to find all positive samples**  \nRecall is calculated by following equation:  \nRecall = TP \/ (TP + FN)  \n  \n  \n- **F1-score**  is a so called **weighted harmonic mean of the Precision and Recall**  \nF1-score also known as balanced F-score or F-measure,  \nas it incorporates Precision and Recall into computation,  \nand, therefore, contributions of Precision and Recall to F1-score are equal  \nF1-score reaches its best value at 1 and worst score at 0  \nF1-score is calculated by following equation:  \nF1-score = 2 * (Recall * Precision) \/ (Recall + Precision)  \n  \n  \n- **Support** is a number of occurrences of each class in a dataset  \n  \n  \n- **Accuracy** is a global accuracy of entire classifier  \nAccuracy is calculated by following equation:  \nAccuracy = (TP + TN) \/ (TP + TN + FP + FN)  \n(all correct \/ all)  \n\n  \n- **macro avg** calculates the mean of the metrics,   \ngiving equal weight to each class  \n  \n  \n- **weighted avg** calculates the weighted mean of the metrics  \nIt takes into account imbalance of samples' number for every class  \nIt weights every metric by occurrences of each class in a dataset  \n","e59961a5":"To get more details for usage of *'np.copy':*  \n**print(help(np.copy))**\n  \nMore details and examples are here:  \n - https:\/\/numpy.org\/doc\/stable\/reference\/generated\/numpy.copy.html  \n  \n  <br\/>\n  \nTo get more details for usage of *'confusion_matrix':*  \n**print(help(confusion_matrix))**\n  \nMore details and examples are here:  \n - https:\/\/www.sklearn.org\/modules\/generated\/sklearn.metrics.confusion_matrix.html  \n  \n  <br\/>\n  \nTo get more details for usage of *'classification_report':*  \n**print(help(classification_report))**\n  \nMore details and examples are here:  \n - https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.metrics.precision_recall_fscore_support.html  \n  \n  <br\/>\n  \nTo get more details for usage of *'plt.colormaps()':*  \n**print(help(plt.colormaps()))**\n  \nMore details and examples are here:  \n -  https:\/\/matplotlib.org\/api\/pyplot_summary.html?highlight=colormaps#matplotlib.pyplot.colormaps  \n  ","1dafeb76":"# \ud83c\udfb0 Generating Predicted Vector","1aaefced":"# \ud83e\uddfe Preparing classes' labels","df0dd363":"# \ud83c\udf9b\ufe0f What does Confusion Matrix show?\n  \n  **Description:**  \n*Find explained theory on what Confusion Matrix shows in the course* ","841adec9":"# \u2696\ufe0f Building Classification Report","0d4d8315":"# \ud83d\udcca Showing distribution of samples among classes","752cb849":"# \ud83c\udf93 Related course for classification tasks","df7f1dbb":"# \ud83e\uddee Calculating Confusion Matrix"}}