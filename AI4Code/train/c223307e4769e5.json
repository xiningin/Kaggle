{"cell_type":{"439c5086":"code","5cd13d06":"code","edceb64f":"code","31cf7a01":"code","30aface6":"code","297ac9a1":"code","b24f198f":"code","7673f381":"code","3b13f5b5":"code","c7ebfc27":"code","54befcc7":"code","17c70eef":"code","7dbadd92":"code","0f7af1fb":"code","583ba4cb":"code","1288da6a":"code","aeb8f7c7":"code","f79644f6":"code","bb290abc":"code","c09403bf":"code","322ed3f5":"code","6ef02317":"code","75035cfb":"code","98bfc5be":"code","07a7e99d":"code","5e69eb0f":"code","a3a335f2":"code","b167c416":"markdown","ed6ea017":"markdown","a64179db":"markdown","4b0396fa":"markdown"},"source":{"439c5086":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5cd13d06":"# import libraries\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score, GridSearchCV,validation_curve\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nimport warnings\nwarnings.filterwarnings('ignore')","edceb64f":"# load data\ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')","31cf7a01":"# display train data info\ntrain_data.info()","30aface6":"# display test data info\ntest_data.info()","297ac9a1":"# display the percentage of missing data\npercent_missing = train_data.isnull().sum() * 100 \/ len(train_data)\nmissing_value_df = pd.DataFrame({'percent_missing': percent_missing})\nmissing_value_df","b24f198f":"# drop unwanted column\ntrain_data.drop(columns = ['Name','Cabin','Ticket'],axis=1, inplace=True)\ntest_data.drop(['Name','Cabin','Ticket'],axis=1, inplace=True)","7673f381":"# plot target values\nsns.countplot(train_data.Survived)\nplt.show()","3b13f5b5":"# pclass vs survived\nsns.barplot(x='Pclass', y='Survived', data=train_data)\nplt.show()","c7ebfc27":"# sex vs survived\nsns.barplot(x='Sex', y='Survived', data=train_data)\nplt.show()","54befcc7":"# age vs survival\nsns.boxplot(x='Survived', y='Age', data=train_data)\nplt.show()","17c70eef":"#sibSp vs aurvived\nsns.barplot(x='SibSp', y='Survived', data=train_data)\nplt.show()","7dbadd92":"# parch vs survived\nsns.barplot(x='Parch', y='Survived', data=train_data)\nplt.show()","0f7af1fb":"# embarked vs survived\nsns.barplot(x='Embarked', y='Survived', data=train_data)\nplt.show()","583ba4cb":"# fill missing age with mean of dataset age\ntrain_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\ntest_data['Age'].fillna(test_data['Age'].mean(), inplace=True)","1288da6a":"# create new feauture person\ndef find_person(person):\n    age,sex = person\n    \n    if age<10:\n       return 'child'\n    else :\n       return sex","aeb8f7c7":"train_data['Person']=train_data[['Age','Sex']].apply(find_person,axis=1)\ntest_data['Person']=test_data[['Age','Sex']].apply(find_person,axis=1)","f79644f6":"# create feature to check if person alone or not\ntrain_data['Alone']=train_data.SibSp + train_data.Parch\ntest_data['Alone']=test_data.SibSp + test_data.Parch","bb290abc":"train_data['Alone'].loc[train_data['Alone']>0]='With family'\ntrain_data['Alone'].loc[train_data['Alone']==0]='Alone'\ntest_data['Alone'].loc[test_data['Alone']>0]='With family'\ntest_data['Alone'].loc[test_data['Alone']==0]='Alone'\n","c09403bf":"train_data.head()","322ed3f5":"# to numpy array\nX = train_data[['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare', 'Embarked','Person','Alone']].values\nX_test = test_data[['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp','Parch', 'Fare', 'Embarked','Person','Alone']].values\ny = train_data[['Survived']].values","6ef02317":"# imputation\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\nimputer.fit(X[:,:])\nX[:,:] = imputer.transform(X[:,:])\nimputer.fit(X_test[:,:])\nX_test[:,:] = imputer.transform(X_test[:,:])","75035cfb":"# dealing with categorigal data \nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2,7,8,9])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))\nX_test = np.array(ct.fit_transform(X_test))","98bfc5be":"# create randomforest model and fit train data\nmodel = RandomForestClassifier(n_estimators=200,min_samples_leaf=3,max_features=0.5,n_jobs=-1,random_state=2)\nmodel.fit(X,y)\nmodel.score(X,y)\nacc_random_forest = round(model.score(X, y) * 100, 2)\nprint(round(acc_random_forest,2,), \"%\")","07a7e99d":"%timeit\nscores = cross_val_score(model, X, y, cv=10, scoring = \"accuracy\")\nprint(\"Scores:\", scores)\nprint(\"Mean:\", scores.mean())\nprint(\"Standard Deviation:\", scores.std())","5e69eb0f":"# predict the target for test data\ny_pred = model.predict(X_test)","a3a335f2":"# save results to CSV file\ndf_output = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\ndf_output['Survived'] = y_pred\ndf_output.to_csv('submission_8.csv',index=False)","b167c416":"*Since there are lot of data missing(~77%) in the `Cabin` column we can drop that column and `Name` and `Ticket` column are not useful so we can drop them too*","ed6ea017":"# **Data visualization**","a64179db":"# **Feauture engineering and dealing with missing data**","4b0396fa":"*first class passengers survived mostly*"}}