{"cell_type":{"687cc8de":"code","4b09dc53":"code","ef93218c":"code","0e0629c4":"code","63125a86":"code","316767df":"code","cdd80175":"code","b92d3a44":"code","2ce1c05c":"code","9784d08b":"code","638680be":"code","0db3f672":"code","b7efddd9":"code","79bd6c5c":"code","1cf3f78e":"code","8ac0371d":"code","e6e9042e":"code","c1cffaa4":"code","f771cacb":"code","cdd9071d":"code","f570970c":"code","d1f32c72":"code","a4f83fb8":"code","d495bd7f":"code","a00d7049":"code","46237c07":"code","91a9cf78":"code","fa492c31":"code","f258add5":"code","747ccdd6":"code","391d874d":"code","c8ac178c":"code","d9cd72f7":"code","05f6ed5b":"code","71886915":"code","41204df1":"code","850ee778":"code","b61f4d52":"code","6617eabf":"code","8b81b77a":"code","cb5da3f9":"code","8875be27":"code","79709ec4":"code","df8d43a1":"code","a4e9297b":"code","ee39581d":"code","6eca8d31":"code","0372807b":"code","ab9a4639":"code","56842b30":"code","ce3fbc97":"code","8739b26a":"code","f576c56f":"code","eb707bca":"code","17f85af1":"code","50ae585c":"code","cc2f7cea":"code","716b2be8":"code","c7e2a18b":"code","c9c09314":"code","1fd897c2":"code","2ddcd438":"code","8d96e8f5":"code","3b76cd5d":"code","78f63603":"code","42d93749":"code","e2a1baa0":"code","2c396cdd":"code","e292cf1d":"code","f964888c":"code","0f18b0dc":"code","3cbdfca2":"code","b0a53b38":"code","e2c3acb3":"code","c36c20ea":"code","41f67614":"code","32853ee3":"code","a1b833af":"code","45bd585a":"code","144a4662":"code","76baf704":"code","c1ce2e24":"code","d303093b":"code","f98b60ee":"code","3dc1aef2":"code","55331185":"code","5ced3533":"code","99fe4127":"code","578a28ca":"code","3926cbcf":"code","cde6f13a":"code","e75ccaf1":"code","1e770fbe":"code","bcd93267":"code","b8ca2746":"code","424da512":"code","62810398":"code","cda23885":"code","4fc87d45":"code","0e01d1c6":"code","394bde82":"code","305d8f74":"code","74996824":"code","bc03fd85":"code","b66ad8fb":"code","e82966c3":"code","7e95c457":"code","d7516ec9":"markdown","b6e5e452":"markdown","be0b1fe0":"markdown","02ed1d8f":"markdown","aab55795":"markdown","53fd1ad4":"markdown","41008cee":"markdown","e407231d":"markdown","7676d229":"markdown","ede09b75":"markdown","777f8422":"markdown","29dcd4ff":"markdown","d523de30":"markdown"},"source":{"687cc8de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4b09dc53":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\nfrom scipy.stats import skew\nfrom scipy import stats\nfrom scipy.stats.stats import pearsonr\nfrom scipy.stats import norm\nfrom collections import Counter\nfrom sklearn import ensemble\nfrom sklearn.linear_model import LinearRegression,LassoCV, Ridge, LassoLarsCV,ElasticNetCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n","ef93218c":"train=pd.read_csv('\/kaggle\/input\/dasprodatathon\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/dasprodatathon\/test.csv')","0e0629c4":"print('DataFrame Train')\ndisplay(train)","63125a86":"print(\"DataFrame Test\")\ndisplay(test)","316767df":"train.shape","cdd80175":"test.shape","b92d3a44":"#print first five rows of the dataframe\ntrain.head()","2ce1c05c":"print(train.info())\nprint('**'* 50)\nprint(test.info())","9784d08b":"#Describe gives statistical information about numerical columns in the dataset\ntrain.describe()","638680be":"sns.distplot(train['Price'] , fit=norm);\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train['Price'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n#Now plot the distribution\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('Price distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nres = stats.probplot(train['Price'], plot=plt)\nplt.show() ","0db3f672":"plt.figure(figsize=(30,8))\nsns.heatmap(train.corr(),cmap='coolwarm',annot = True)\nplt.show()","b7efddd9":"#train['Price'].skew()\nprint(\"Skewness: %f\" % train['Price'].skew())\nprint(\"Kurtosis: %f\" % train['Price'].kurt())","79bd6c5c":"plt.hist(train.Price, bins = 25)","1cf3f78e":"#corr=train.corr()[\"Price\"]\n#corr[np.argsort(corr, axis=0)[::-1]]\n\ncorrelations = train.corr()\ncorrelations = correlations[\"Price\"].sort_values(ascending=False)\nfeatures = correlations.index[1:6]\ncorrelations","8ac0371d":"#correlation matrix\ncorrmat = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","e6e9042e":"k = 10 #number of variables for heatmap\ncols = train.corr().nlargest(k, 'Price')['Price'].index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1.5)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","c1cffaa4":"#scatterplot\nsns.set()\ncols = ['Price', 'Living Area', 'Grade', 'Above the Ground Area', 'Neighbors Living Area', 'Bathrooms', 'View', 'Basement Area', 'Latitude', 'Bedrooms']\nsns.pairplot(train[cols], size = 2.5)\nplt.show();","f771cacb":"sns.distplot(train['Price'], color=\"r\", kde=False)\nplt.title(\"Distribution of Price\")\nplt.ylabel(\"Number of Occurences\")\nplt.xlabel(\"Price\");","cdd9071d":"most_corr = pd.DataFrame(cols)\nmost_corr.columns = ['Most Correlated Features']\nmost_corr","f570970c":"sns.jointplot(x=train['Living Area'], y=train['Price'], kind='reg')","d1f32c72":"train_null = pd.isnull(train).sum()\ntest_null = pd.isnull(test).sum()\n\nnull = pd.concat([train_null, test_null], axis=1, keys=[\"Training\", \"Testing\"])","a4f83fb8":"null_many = null[null.sum(axis=1) > 200]  #a lot of missing values\nnull_few = null[(null.sum(axis=1) > 0) & (null.sum(axis=1) < 200)]  #not as much missing values","d495bd7f":"null_many","a00d7049":"#missing data\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()\/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)","46237c07":"#missing data\ntotal_test = test.isnull().sum().sort_values(ascending=False)\npercent_test = (test.isnull().sum()\/test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total_test, percent_test], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)","91a9cf78":"train=train[cols]","fa492c31":"cols","f258add5":"train.columns","747ccdd6":"#skew_cols = ['Living Area', 'Total Area', 'Above the Ground Area',\n #      'Basement Area', 'Neighbors Living Area', 'Neighbors Total Area']","391d874d":"#test['rooms_ratio'] = test['Living Area'] \/ (test['Bedrooms'] + test['Bathrooms'])\n#train['rooms_ratio'] = train['Living Area'] \/ (train['Bedrooms'] + train['Bathrooms'])","c8ac178c":"#for df in [train,test]:\n #   df['living_ratio'] = df['Living Area'] \/ df['Total Area']\n  #  df['neighbors_ratio'] = df['Neighbors Living Area'] \/ df['Neighbors Total Area']\n   # df['env_ratio'] = df['Living Area'] \/ df['Neighbors Living Area']","d9cd72f7":"#train['per_price'] = train['Price']\/train['Total Area']\n#zipcode_price = train.groupby(['Zipcode'])['per_price'].agg({'mean','var'}).reset_index()\n#train = pd.merge(train,zipcode_price,how='left',on='Zipcode')\n#test = pd.merge(test,zipcode_price,how='left',on='Zipcode')\n#train.drop('per_price', axis=1, inplace=True)\n\n#for df in [train,test]:\n #   df['zipcode_mean'] = df['mean'] * df['Total Area']\n  #  df['zipcode_var'] = df['var'] * df['Total Area']\n   # del df['mean']; del df['var']","05f6ed5b":"#threshold = 3\n#z_score = np.abs(stats.zscore(train))\n\n#train_wo = train[(z_score < threshold).all(axis=1)].copy()\n#train_wo.head()","71886915":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train.drop('Price', axis=1), train['Price'], test_size=0.2, random_state=3)","41204df1":"# we are going to scale to data\ny_train= y_train.values.reshape(-1,1)\ny_test= y_test.values.reshape(-1,1)\n\n#from sklearn.impute import SimpleImputer\n#my_imputer = SimpleImputer()\n#data_with_imputed_values = my_imputer.fit_transform(original_data)\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nsc_y = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.fit_transform(X_test)\ny_train = sc_y.fit_transform(y_train)\ny_test = sc_y.fit_transform(y_test)\n","850ee778":"X_train","b61f4d52":"#x = train[['Living Area', 'Above the Ground Area','Neighbors Living Area','Bathrooms', 'Grade', 'Basement Area','Latitude','Longitude','Year Built','Condition','Bedrooms','Floors','Waterfront','View','Year Renovated','Neighbors Total Area','Total Area','Zipcode']]\n#y = train['Price']","6617eabf":"#x","8b81b77a":"id_test = test['ID']\n","cb5da3f9":"lr=LinearRegression()","8875be27":"lr.fit(X_train,y_train)\nprint(lr)","79709ec4":"#y","df8d43a1":"#x, x_t, y, y_t = train_test_split(x,y, test_size=0.1, random_state=4)","a4e9297b":"#lr.fit(x,y)","ee39581d":"print(lr.intercept_)","6eca8d31":"print(lr.coef_)","0372807b":"#lr.score(x,y)","ab9a4639":"#lr.score(x_t,y_t)","56842b30":"#id_test = test['ID']\n#x_test = test[['Living Area', 'Above the Ground Area','Neighbors Living Area','Bathrooms', 'Grade', 'Basement Area','Latitude','Longitude','Year Built','Condition','Bedrooms','Floors','Waterfront','View','Year Renovated','Neighbors Total Area','Total Area','Zipcode']]","ce3fbc97":"#y_pdc = lr.predict(x_test)\n#display(y_pdc)","8739b26a":"#est = ensemble.GradientBoostingRegressor(n_estimators=500,max_depth=4, random_state=8, min_samples_split = 10, learning_rate = 0.1,validation_fraction=0.1, loss = 'huber').fit(x,y)\n#est.score(x,y)","f576c56f":"#aw=est.score(x_t, y_t)\n#aw= aw*100\n#print(aw)","eb707bca":"#y_pred = est.predict(x_test)\n#display(y_pred)","17f85af1":"#df_submit = pd.DataFrame()\n#df_submit['ID'] = id_test\n#df_submit['Price'] = y_pred","50ae585c":"#df_submit.head()","cc2f7cea":"#df_submit.to_csv('Submission_RIA.csv', index=False)","716b2be8":"predictions = lr.predict(X_test)\npredictions= predictions.reshape(-1,1)","c7e2a18b":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,predictions)\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","c9c09314":"plt.figure(figsize=(16,8))\nplt.plot(y_test,label ='Test')\nplt.plot(predictions, label = 'predict')\nplt.show()","1fd897c2":"from sklearn import metrics","2ddcd438":"print('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))","8d96e8f5":"from sklearn import ensemble\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import mean_squared_error, r2_score","3b76cd5d":"params = {'n_estimators': 100, 'max_depth': 3, 'min_samples_split': 2,\n          'learning_rate': 0.1, 'loss': 'ls'}\nclf = ensemble.GradientBoostingRegressor(**params)\n\nclf.fit(X_train, y_train)","78f63603":"clf_pred=clf.predict(X_test)\nclf_pred= clf_pred.reshape(-1,1)","42d93749":"print('MAE:', metrics.mean_absolute_error(y_test, clf_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, clf_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, clf_pred)))","e2a1baa0":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,clf_pred, c= 'brown')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","2c396cdd":"plt.figure(figsize=(16,8))\nplt.plot(y_test,label ='Test')\nplt.plot(clf_pred, label = 'predict')\nplt.show()","e292cf1d":"from sklearn.tree import DecisionTreeRegressor\ndtreg = DecisionTreeRegressor(random_state = 100)\ndtreg.fit(X_train, y_train)","f964888c":"dtr_pred = dtreg.predict(X_test)\ndtr_pred= dtr_pred.reshape(-1,1)","0f18b0dc":"print('MAE:', metrics.mean_absolute_error(y_test, dtr_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, dtr_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, dtr_pred)))","3cbdfca2":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,dtr_pred,c='green')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","b0a53b38":"from sklearn.svm import SVR\nsvr = SVR(kernel = 'rbf')\nsvr.fit(X_train, y_train)","e2c3acb3":"svr_pred = svr.predict(X_test)\nsvr_pred= svr_pred.reshape(-1,1)","c36c20ea":"print('MAE:', metrics.mean_absolute_error(y_test, svr_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, svr_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, svr_pred)))","41f67614":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,svr_pred, c='red')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","32853ee3":"plt.figure(figsize=(16,8))\nplt.plot(y_test,label ='Test')\nplt.plot(svr_pred, label = 'predict')\nplt.show()","a1b833af":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(n_estimators = 500, random_state = 0)\nrfr.fit(X_train, y_train)","45bd585a":"rfr_pred= rfr.predict(X_test)\nrfr_pred = rfr_pred.reshape(-1,1)","144a4662":"print('MAE:', metrics.mean_absolute_error(y_test, rfr_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, rfr_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, rfr_pred)))","76baf704":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,rfr_pred, c='orange')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","c1ce2e24":"plt.figure(figsize=(16,8))\nplt.plot(y_test,label ='Test')\nplt.plot(rfr_pred, label = 'predict')\nplt.show()","d303093b":"import lightgbm as lgb","f98b60ee":"model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.01, n_estimators=3000,\n                            max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)","3dc1aef2":"model_lgb.fit(X_train, y_train)","55331185":"lgb_pred = model_lgb.predict(X_test)\nlgb_pred = lgb_pred.reshape(-1,1)","5ced3533":"print('MAE:', metrics.mean_absolute_error(y_test, lgb_pred))\nprint('MSE:', metrics.mean_squared_error(y_test, lgb_pred))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, lgb_pred)))","99fe4127":"plt.figure(figsize=(15,8))\nplt.scatter(y_test,lgb_pred, c='orange')\nplt.xlabel('Y Test')\nplt.ylabel('Predicted Y')\nplt.show()","578a28ca":"plt.figure(figsize=(16,8))\nplt.plot(y_test,label ='Test')\nplt.plot(lgb_pred, label = 'predict')\nplt.show()","3926cbcf":"error_rate=np.array([metrics.mean_squared_error(y_test, predictions),metrics.mean_squared_error(y_test, clf_pred),metrics.mean_squared_error(y_test, dtr_pred),metrics.mean_squared_error(y_test, svr_pred),metrics.mean_squared_error(y_test, rfr_pred)])","cde6f13a":"plt.figure(figsize=(16,5))\nplt.plot(error_rate)","e75ccaf1":"a = pd.read_csv('\/kaggle\/input\/dasprodatathon\/test.csv')","1e770fbe":"#y_pdc=clf.predict(X_test)\n#display(y_pdc)\n","bcd93267":"test_id = a['ID']\na=pd.DataFrame(test_id, columns=['ID'])","b8ca2746":"test = sc_X.fit_transform(test)","424da512":"test.shape","62810398":"test_prediction_lgb=model_lgb.predict(X_test)\n\ntest_prediction_lgb=test_prediction_lgb.reshape(-1,1)","cda23885":"test_prediction_lgb","4fc87d45":"test_prediction_lgb =sc_y.inverse_transform(test_prediction_lgb)","0e01d1c6":"test_prediction_lgb = pd.DataFrame(test_prediction_lgb, columns=['Price'])","394bde82":"test_prediction_lgb.head()","305d8f74":"display(test_prediction_clf)","74996824":"result = pd.concat([a,test_prediction_lgb], axis=1)","bc03fd85":"result.head()","b66ad8fb":"result = result.fillna(method = \"ffill\" , axis = 0).fillna(0)\n","e82966c3":"display(result)","7e95c457":"result.to_csv('bismillah_submit.csv', index=False)","d7516ec9":"**Random Forest Regression**","b6e5e452":"the price value is right skewed.","be0b1fe0":"*The primary concern here is to establish a threshold that defines an observation as an outlier. To do so, we'll standardize the data. In this context, data standardization means converting data values to have mean of 0 and a standard deviation of 1.*","02ed1d8f":"**Decision Tree Regression**","aab55795":"we can see the most corelated parameters in numerical values above plotting. And we can pick these as features for our macine learning model.","53fd1ad4":"**Gradient Boosting Regression**","41008cee":"**Feature Engineering**","e407231d":"**LightGBM**\n\nLight GBM is a gradient boosting framework that uses tree based learning algorithm.","7676d229":"**MODEL COMPARISON**\n\nDilihat dari error rate nya. semaakin kecil semakin akurat.","ede09b75":"train test split","777f8422":"we can see the most corelated parameters in numerical values above plotting. And we can pick these as features for our macine learning mode","29dcd4ff":"**Support Vector Machine Regression**","d523de30":"**Data Visualization**"}}