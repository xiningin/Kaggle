{"cell_type":{"064ff59d":"code","b4f3e680":"code","c7e8069a":"code","214a3068":"code","96264ccf":"code","e459bd37":"code","1f487333":"code","c6fc975e":"code","39001946":"code","acb71a0a":"code","1ca26054":"code","1c9b56d3":"code","c7c6445b":"code","1794eb8a":"code","2557d4d6":"code","23a48ed5":"code","770532c5":"code","944fecae":"code","93b2b98f":"code","17912892":"code","b755850e":"markdown","e199ba8a":"markdown","0dfd0594":"markdown","5c64a9ea":"markdown","ac4e393f":"markdown","e2918219":"markdown","39b687ba":"markdown","bd126893":"markdown","50f96e5b":"markdown","426719e6":"markdown"},"source":{"064ff59d":"! ls \/.keras\/models","b4f3e680":"from keras import backend as K","c7e8069a":"import numpy as np\nimport keras\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing.image import load_img, img_to_array\nimport os\n\nfrom sklearn.metrics import log_loss","214a3068":"IMG_SIZE = (224, 224)  # \u0440\u0430\u0437\u043c\u0435\u0440 \u0432\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0441\u0435\u0442\u0438","96264ccf":"print(len(os.listdir(\"..\/input\/train\")))","e459bd37":"import re\nfrom random import shuffle\nfrom glob import glob\n\nTRAIN_DIR = '..\/input\/train'\nTEST_DIR = '..\/input\/test'\n\ntrain_files = glob(\"..\/input\/train\/*.jpg\")\ntest_files = glob('..\/input\/test\/*.jpg')\n\n# \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0432\u0445\u043e\u0434\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 \u0438 \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0435\u043c\ndef load_image(path, target_size=IMG_SIZE):\n    img = load_img(path, target_size=target_size)  # \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0438 \u043c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\n    array = img_to_array(img)\n    return preprocess_input(array)  # \u043f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u043b\u044f VGG16\n\n# \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0434\u043b\u044f \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0447\u0442\u0435\u043d\u0438\u044f \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0434\u0438\u0441\u043a\u0430\ndef fit_generator(files, batch_size=32):\n    while True:\n        shuffle(files)\n        for k in range(len(files) \/\/ batch_size):\n            i = k * batch_size\n            j = i + batch_size\n            if j > len(files):\n                j = - j % len(files)\n            x = np.array([load_image(path) for path in files[i:j]])\n            y = np.array([1. if re.match('.*\/dog\\.\\d', path) else 0. for path in files[i:j]])\n            yield (x, y)\n\n# \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u0447\u0442\u0435\u043d\u0438\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0434\u0438\u0441\u043a\u0430\ndef predict_generator(files):\n    while True:\n        for path in files:\n            yield np.array([load_image(path)])","1f487333":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nfig = plt.figure(figsize=(20, 20))\nfor i, path in enumerate(train_files[:10], 1):\n    subplot = fig.add_subplot(i \/\/ 5 + 1, 5, i)\n    plt.imshow(plt.imread(path));\n    subplot.set_title('%s' % path.split('\/')[-1]);","c6fc975e":"# base_model -  \u043e\u0431\u044a\u0435\u043a\u0442 \u043a\u043b\u0430\u0441\u0441\u0430 keras.models.Model (Functional Model)\nbase_model = VGG16(include_top = False,\n                   weights = 'imagenet',\n                   input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3))","39001946":"# \u0444\u0438\u043a\u0441\u0438\u0440\u0443\u0435\u043c \u0432\u0441\u0435 \u0432\u0435\u0441\u0430 \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438\nfor layer in base_model.layers:\n    layer.trainable = False","acb71a0a":"base_model.summary()","1ca26054":"x = base_model.layers[-5].output\nx = keras.layers.Flatten()(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Dense(32,  # \u043e\u0434\u0438\u043d \u0432\u044b\u0445\u043e\u0434\n                activation='sigmoid',  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438  \n                #kernel_regularizer=keras.regularizers.l1(1e-4)\n                      )(x)\nx = keras.layers.Dense(32,  # \u043e\u0434\u0438\u043d \u0432\u044b\u0445\u043e\u0434\n                activation='sigmoid',  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438  \n                #kernel_regularizer=keras.regularizers.l1(1e-4)\n                      )(x)\nx = keras.layers.Dropout(0.5)(x)\nx = keras.layers.Dense(1,  # \u043e\u0434\u0438\u043d \u0432\u044b\u0445\u043e\u0434\n                activation='sigmoid',  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0430\u043a\u0442\u0438\u0432\u0430\u0446\u0438\u0438  \n                kernel_regularizer=keras.regularizers.l2(1e-4)\n                      )(x)\nmodel = Model(inputs=base_model.input, outputs=x)","1c9b56d3":"model.summary()","c7c6445b":"model.compile(optimizer='adam', \n              loss='binary_crossentropy',  # \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c binary_crossentropy (log loss\n              metrics=['accuracy',  ])","1794eb8a":"shuffle(train_files)  # \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0438\u0432\u0430\u0435\u043c \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443\n\ntrain_val_split = 100  # \u0447\u0438\u0441\u043b\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u0432 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435\n\nvalidation_data = next(fit_generator(train_files[:train_val_split], train_val_split))\n\n# \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u043f\u0440\u043e\u0446\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\nmodel.fit_generator(fit_generator(train_files[train_val_split:]),  # \u0434\u0430\u043d\u043d\u044b\u0435 \u0447\u0438\u0442\u0430\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u0435\u0439-\u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u043c\n        steps_per_epoch=10,  # \u0447\u0438\u0441\u043b\u043e \u0432\u044b\u0437\u043e\u0432\u043e\u0432 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u0430 \u0437\u0430 \u044d\u043f\u043e\u0445\u0443\n        epochs=15,  # \u0447\u0438\u0441\u043b\u043e \u044d\u043f\u043e\u0445 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f\n        validation_data=validation_data)","2557d4d6":"model.save('model')","23a48ed5":"pred = model.predict_generator(predict_generator(test_files), len(test_files), max_queue_size=500)","770532c5":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nfig = plt.figure(figsize=(20, 20))\nfor i, (path, score) in enumerate(zip(test_files[80:][:10], pred[80:][:10]), 1):\n    subplot = fig.add_subplot(i \/\/ 5 + 1, 5, i)\n    plt.imshow(plt.imread(path));\n    subplot.set_title('%.3f' % score);","944fecae":"# \u0420\u0430\u0441\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \u0434\u043b\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438","93b2b98f":"with open('submit.txt', 'w') as dst:\n    dst.write('id,label\\n')\n    for path, score in zip(test_files, pred):\n        dst.write('%s,%f\\n' % (re.search('(\\d+)', path).group(0), score))","17912892":"# LogLoss = 1.04979","b755850e":"# \u0414\u043e\u043c\u0430\u0448\u043d\u044f\u044f \u0440\u0430\u0431\u043e\u0442\u0430. Dogs vs. Cats","e199ba8a":"https:\/\/www.kaggle.com\/c\/dogs-vs-cats-redux-kernels-edition","0dfd0594":"## \u0413\u043e\u0442\u043e\u0432\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0441\u0430\u0431\u043c\u0438\u0442\u0430","5c64a9ea":"## \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c","ac4e393f":"## \u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445","e2918219":"## \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f","39b687ba":"## \u0412\u044b\u0432\u043e\u0434\u0438\u043c \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0443 \u043c\u043e\u0434\u0435\u043b\u0438","bd126893":"## \u041a\u043e\u043c\u043f\u0438\u043b\u0438\u0440\u0443\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435","50f96e5b":"## \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u043f\u0440\u043e\u0432\u0435\u0440\u043e\u0447\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435","426719e6":"## \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043f\u043e\u043b\u043d\u043e\u0441\u0432\u044f\u0437\u043d\u044b\u0439 \u0441\u043b\u043e\u0439"}}