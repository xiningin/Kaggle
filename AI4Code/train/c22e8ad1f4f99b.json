{"cell_type":{"11c04544":"code","c4c99fdb":"code","3bbdc500":"code","cd81354e":"code","8caee474":"code","255c3d4d":"code","3e183449":"code","fa643726":"code","bd6be3f4":"code","39bf0fe8":"code","3f301e56":"code","55cc70be":"code","bca82359":"code","5b842120":"code","8eba58e7":"code","16d77e9d":"code","0690844e":"code","419fdfa4":"code","b95b8008":"code","5aa2dce2":"code","f9321467":"code","5fb77dd0":"code","5cfe0d41":"code","ae26ceaf":"code","e34d63dd":"code","8dfd3712":"code","ac7dbd21":"code","68e169bd":"code","cf0889e6":"code","c109153a":"code","6055c7b5":"code","8661b2d0":"code","39400693":"code","e3106083":"code","fd054725":"code","b4213230":"code","32e5c7ed":"code","c7c9272e":"code","483cb8e8":"code","22fcb2ff":"code","a8a6fcb4":"code","6bf763ef":"code","eb09f7ee":"code","8752b325":"code","f6e30342":"code","e4f24d98":"code","de4168cb":"code","d93d537d":"code","95163fca":"code","f79e2dc1":"code","d1d24f91":"code","6a2a1fc9":"code","d9a4dffb":"code","deacbd7a":"code","9dcb9b9d":"code","e2c2ba93":"code","a676bbcb":"code","9fb5fdb1":"code","056d8ac9":"code","521c9f19":"markdown","4a91f61c":"markdown","74754399":"markdown","54791e55":"markdown","0db9aa37":"markdown","e8653844":"markdown","d7b25d5e":"markdown","ef657df4":"markdown","5e13cecf":"markdown","db7e2c8f":"markdown","03bfda9f":"markdown","ea1c1e90":"markdown","2845fb4a":"markdown","bca06891":"markdown","3a2d6895":"markdown","d9d85086":"markdown","a5848efa":"markdown","9b029e35":"markdown","ecec724b":"markdown","5d9c4e6d":"markdown","aa23f615":"markdown","af3aa8c2":"markdown","4d51bef9":"markdown","c4aaa593":"markdown","345fbc73":"markdown","c0f84080":"markdown","6dc2f9c6":"markdown","4545be97":"markdown","e273c4cf":"markdown","a423e40b":"markdown","20984fa8":"markdown","ad0ca377":"markdown","c27230c3":"markdown","487c57ab":"markdown","2567ac84":"markdown","71cb3873":"markdown"},"source":{"11c04544":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c4c99fdb":"import torch\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.preprocessing import MinMaxScaler\nfrom pandas.plotting import register_matplotlib_converters\nfrom torch import nn, optim\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\n\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n\nrcParams['figure.figsize'] = 14, 10\nregister_matplotlib_converters()\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)","3bbdc500":"from sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport datetime\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression, BayesianRidge","cd81354e":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error","8caee474":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","255c3d4d":"\nimport requests\nimport pandas as pd\nimport io\n\nBASE_URL = 'https:\/\/raw.githubusercontent.com\/CSSEGISandData\/COVID-19\/master\/csse_covid_19_data\/csse_covid_19_time_series\/'\nCONFIRMED = 'time_series_covid19_confirmed_global.csv'\nDEATH = 'time_series_covid19_deaths_global.csv'\nRECOVERED = 'time_series_covid19_recovered_global.csv'\nCONFIRMED_US = 'time_series_covid19_confirmed_US.csv'\nDEATH_US = 'time_series_covid19_deaths_US.csv'\n\ndef get_covid_data(subset = 'CONFIRMED'):\n    \"\"\"This function returns the latest available data subset of COVID-19. \n        The returned value is in pandas DataFrame type.\n    Args:\n        subset (:obj:`str`, optional): Any value out of 5 subsets of 'CONFIRMED',\n        'DEATH', 'RECOVERED', 'CONFIRMED_US' and 'DEATH_US' is a valid input. If the value\n        is not chosen or typed wrongly, CONFIRMED subet will be returned.\n    \"\"\"    \n    switcher =  {\n                'CONFIRMED'     : BASE_URL + CONFIRMED,\n                'DEATH'         : BASE_URL + DEATH,\n                'RECOVERED'     : BASE_URL + RECOVERED,\n                'CONFIRMED_US'  : BASE_URL + CONFIRMED_US,\n                'DEATH_US'      : BASE_URL + DEATH_US,\n                \n                }\n\n    CSV_URL = switcher.get(subset, BASE_URL + CONFIRMED)\n\n    with requests.Session() as s:\n        download        = s.get(CSV_URL)\n        decoded_content = download.content.decode('utf-8')\n        data            = pd.read_csv(io.StringIO(decoded_content))\n\n    return data","3e183449":"deaths=get_covid_data(subset = 'DEATH') # global deaths","fa643726":"deaths","bd6be3f4":"countries=['Brazil', 'Canada', 'Germany','US','Spain','Italy']\ny=deaths.loc[deaths['Country\/Region']=='Italy'].iloc[0,4:]\ns = pd.DataFrame({'Italy':y})\nfor c in countries:    \n    s[c] = deaths.loc[deaths['Country\/Region']==c].iloc[0,4:]\n    plt.plot(range(y.shape[0]),s[c],label=c)#    print(s[c])\nplt.title('Total Number of Deaths since 1\/22\/20')\nplt.xlabel('Day')\nplt.ylabel('Number of Cases')\nplt.legend(loc=\"best\")\nplt.show()","39bf0fe8":"import matplotlib.pyplot as plt\ncountry_list=deaths['Country\/Region'].unique()\nconfirmed = pd.DataFrame({'Italy':y})\ndict={}\na=[]\nb=[]\n#z=y.shape[0]\n\nfor c in country_list:\n  #  print(c)\n    a.append(c)\n   # print(a)\n    confirmed=( deaths.loc[deaths['Country\/Region']==c].iloc[:,4:].sum(axis=0))\n    b.append(confirmed[y.shape[0]-1])  \n    dict[c]=confirmed[y.shape[0]-1]\n#    print (confirmed[c][84])\ndict\nf = plt.figure(figsize=(90,40))\nf.add_subplot(111)\n\nbarWidth=1\nplt.axes(axisbelow=True)\n\nplt.bar(a,b,linewidth=17.0)\n\nplt.xlabel(\"Countries \",fontsize=45)\nplt.ylabel(\"Number of deaths \",fontsize=45)\nplt.title(\"Number of deaths around the world\",fontsize=60)\nplt.grid(alpha=0.3)\nplt.tick_params(size=5,labelsize = 30,rotation=90)\nplt.show()","3f301e56":"plt.figure(figsize=(15, 8))\ncanada = deaths.loc[deaths['Country\/Region']=='Canada'].iloc[:,4:].sum(axis=0)\ncanada.tail()\ncanada.plot(label='Canada')\nplt.legend()\nplt.xlabel(\"Date \",fontsize=25)\nplt.ylabel(\"Number of deaths \",fontsize=25)\nplt.title(\"Number of deaths in Canada\")\nplt.show()","55cc70be":"CAN = deaths[deaths['Country\/Region']=='Canada']\n\nCAN = pd.DataFrame(CAN.iloc[0,4:-2])\n\ndef plot_moving_average(series, window, plot_intervals=False, scale=1.96):\n\n    rolling_mean = series.rolling(window=window).mean()\n    \n    plt.figure(figsize=(20,8))\n    plt.title('Moving average\\n window size = {}'.format(window))\n    plt.plot(rolling_mean, 'g', label='Rolling mean trend')\n    \n    #Plot confidence intervals for smoothed values\n    if plot_intervals:\n        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n        deviation = np.std(series[window:] - rolling_mean[window:])\n        lower_bound = rolling_mean - (mae + scale * deviation)\n        upper_bound = rolling_mean + (mae + scale * deviation)\n        plt.plot(upper_bound, 'r--', label='Upper bound \/ Lower bound')\n        plt.plot(lower_bound, 'r--')\n        \n            \n    plt.plot(series[window:], label='Actual values')\n    plt.legend(loc='best')\n    plt.xticks(rotation=90)\n    plt.grid(True)\n\n#Smooth by the previous 5 days (by week)\nplot_moving_average(CAN, 5)","bca82359":"plot_moving_average(CAN, 30, plot_intervals=True)","5b842120":"dates=deaths.columns.values.tolist()\ndates=dates[4:]","8eba58e7":"d=[]\nfor i in dates:\n  d= deaths.iloc[:,4:].sum(axis=0)","16d77e9d":"d","0690844e":"X = np.array([i for i in range(len(dates))]).reshape(-1, 1)\nY = np.array(d).reshape(-1, 1)","419fdfa4":"days_in_future = 15 #next 2 weeks\nfuture_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\nadjusted_dates = future_forcast[:-15]\nstart = '1\/22\/2020'\nstart_date = datetime.datetime.strptime(start, '%m\/%d\/%Y')\nfuture_forcast_dates = []\nfor i in range(len(future_forcast)):\n    future_forcast_dates.append((start_date + datetime.timedelta(days=i)).strftime('%m\/%d\/%Y'))\n    ","b95b8008":"X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X, Y, test_size=0.10, shuffle=False)","5aa2dce2":"# svm_confirmed = svm_search.best_estimator_\n\n\nsvm_confirmed2 = SVR(C=1,degree=5,kernel='poly',epsilon=0.01)\nsvm_confirmed2.fit(X_train_d, y_train_d)\nsvm_pred2 = svm_confirmed2.predict(future_forcast)","f9321467":"svm_test_pred2 = svm_confirmed2.predict(X_test_d)\nplt.plot(y_test_d)\nplt.plot(svm_test_pred2)\nplt.legend(['Test Data', 'SVM Predictions'])\nprint('MAE:', mean_absolute_error(svm_test_pred2, y_test_d))\nprint('MSE:',mean_squared_error(svm_test_pred2, y_test_d))","5fb77dd0":"\npoly = PolynomialFeatures(degree=3)\npoly_X_train_d = poly.fit_transform(X_train_d)\npoly_X_test_d = poly.fit_transform(X_test_d)\npoly_future_forcast = poly.fit_transform(future_forcast)\n\nbayesian_poly = PolynomialFeatures(degree=4)\nbayesian_poly_X_train_d = bayesian_poly.fit_transform(X_train_d)\nbayesian_poly_X_test_d = bayesian_poly.fit_transform(X_test_d)\nbayesian_poly_future_forcast = bayesian_poly.fit_transform(future_forcast)","5cfe0d41":"linear_model = LinearRegression(normalize=True, fit_intercept=True)\nlinear_model.fit(poly_X_train_d, y_train_d)\ntest_linear_pred = linear_model.predict(poly_X_test_d)\nlinear_pred = linear_model.predict(poly_future_forcast)\nprint('MAE:', mean_absolute_error(test_linear_pred, y_test_d))\nprint('MSE:',mean_squared_error(test_linear_pred, y_test_d))","ae26ceaf":"plt.plot(y_test_d)\nplt.plot(test_linear_pred)\nplt.legend(['Test Data', 'Polynomial Regression Predictions'])","e34d63dd":"# bayesian ridge polynomial regression\ntol = [1e-4, 1e-3, 1e-2]\nalpha_1 = [1e-7, 1e-6, 1e-5, 1e-4]\nalpha_2 = [1e-7, 1e-6, 1e-5, 1e-4]\nlambda_1 = [1e-7, 1e-6, 1e-5, 1e-4]\nlambda_2 = [1e-7, 1e-6, 1e-5, 1e-4]\n\nbayesian_grid = {'tol': tol, 'alpha_1': alpha_1, 'alpha_2' : alpha_2, 'lambda_1': lambda_1, 'lambda_2' : lambda_2}\n\nbayesian2 = BayesianRidge(fit_intercept=False, normalize=True)\nbayesian_search2 = RandomizedSearchCV(bayesian2, bayesian_grid, scoring='neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=40, verbose=1)\nbayesian_search2.fit(bayesian_poly_X_train_d, y_train_d)","8dfd3712":"bayesian_d = bayesian_search2.best_estimator_\ntest_bayesian_pred = bayesian_d.predict(bayesian_poly_X_test_d)\nbayesian_pred = bayesian_d.predict(bayesian_poly_future_forcast)\nprint('MAE:', mean_absolute_error(test_bayesian_pred, y_test_d))\nprint('MSE:',mean_squared_error(test_bayesian_pred, y_test_d))","ac7dbd21":"plt.plot(y_test_d)\nplt.plot(test_bayesian_pred)\nplt.legend(['Test Data', 'Bayesian Ridge Polynomial Predictions'])","68e169bd":"def plot_predictions_death(x, y, pred, algo_name, color):\n    plt.figure(figsize=(7, 5))\n    plt.plot(x, y)\n    plt.plot(future_forcast, pred, linestyle='dashed', color=color)\n    plt.title(' Deaths caused by Coronavirus Over Time', size=15)\n    plt.xlabel('Days Since 1\/22\/2020', size=15)\n    plt.ylabel('# of Cases', size=15)\n    plt.legend(['Cases of death', algo_name], prop={'size': 15})\n    plt.xticks(size=10)\n    plt.yticks(size=10)\n    plt.show()","cf0889e6":"plot_predictions_death(adjusted_dates, d, svm_pred2, 'SVM Predictions', 'purple')","c109153a":"plot_predictions_death(adjusted_dates, d, linear_pred, 'Polynomial Regression Predictions', 'orange')","6055c7b5":"plot_predictions_death(adjusted_dates, d, bayesian_pred, 'Bayesian Ridge Regression Predictions', 'green')","8661b2d0":"svm_df = pd.DataFrame({'Date': future_forcast_dates[-10:], 'SVM Predicted Deaths Worldwide': np.round(svm_pred2[-10:])})\nsvm_df","39400693":"linear_pred = linear_pred.reshape(1,-1)[0]\nsvm_df = pd.DataFrame({'Date': future_forcast_dates[-10:], 'Polynomial Predicted Number of Deaths Worldwide': np.round(linear_pred[-10:])})\nsvm_df","e3106083":"# Future predictions using Bayesian Ridge \nsvm_df = pd.DataFrame({'Date': future_forcast_dates[-10:], 'Bayesian Ridge Predicted Number of Deaths Worldwide': np.round(bayesian_pred[-10:])})\nsvm_df","fd054725":"df2 = pd.DataFrame(columns=['ds','y'])\ndf2\ndf2['ds'] = pd.to_datetime(dates)\nfor  j in range(0,len(d)):\n # print(d[j])\n  df2['y'][j]=pd.to_numeric(d[j])","b4213230":"df2","32e5c7ed":"from fbprophet import Prophet\nm = Prophet(interval_width=0.95)\nm.fit(df2)\nfuture = m.make_future_dataframe(periods=7)\nfuture_confirmed = future.copy() # for non-baseline predictions later on\nfuture.tail()","c7c9272e":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","483cb8e8":"confirmed_forecast_plot = m.plot(forecast)","22fcb2ff":"confirmed_cases=get_covid_data(subset = 'CONFIRMED')# confirmed cases\nconfirmed_cases.loc[confirmed_cases['Country\/Region']=='Canada']","a8a6fcb4":"c2=[]\nfor i in dates:\n  c2= confirmed_cases.iloc[:,4:].sum(axis=0)\n#  world_cases.append(c)\nd2=[]\nfor i in dates:\n  d2= deaths.iloc[:,4:].sum(axis=0)\nd","6bf763ef":"from scipy.optimize import curve_fit\ndetails = pd.DataFrame(columns=['ds','Confirmed','Deaths'])\n\ndetails['ds'] = pd.to_datetime(dates)\nfor  j in range(0,len(d)):\n # print(d[j])\n  details['Confirmed'][j]=pd.to_numeric(c2[j])\n  details['Deaths'][j]=pd.to_numeric(d2[j])","eb09f7ee":"x_data = range(len(details.index))\ny_data = details['Confirmed']\n\ndef log_curve(x, k, x_0, ymax):\n    return ymax \/ (1 + np.exp(-k*(x-x_0)))\n\n# Fit the curve\npopt, pcov = curve_fit(log_curve, x_data, y_data)#, bounds=([0,0,0],np.inf), maxfev=50000)\nestimated_k, estimated_x_0, ymax= popt\n\n\n# Plot the fitted curve\nk = estimated_k\nx_0 = estimated_x_0\ny_fitted = log_curve(range(0,160), k, x_0, ymax)\nprint(k, x_0, ymax)\n#print(y_fitted)\ny_data.tail()\n","8752b325":"# Plot everything for illustration\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.plot(range(0,160), y_fitted, '--', label='fitted')\nax.plot(x_data, y_data, 'o', label='Confirmed Data')","f6e30342":"daily_deaths=d.copy()\ndaily_deaths.head()","e4f24d98":"plt.figure(figsize=(30, 15))\nplt.plot(daily_deaths)\nplt.title(\"Cumulative daily deaths\");\nplt.tick_params(size=15,labelsize = 15,rotation=90)\nplt.show()","de4168cb":"daily_deaths = daily_deaths.diff().fillna(daily_deaths[0]).astype(np.int64)\ndaily_deaths.head\n\nplt.figure(figsize=(30, 15))\n\nplt.plot(daily_deaths)\nplt.title(\"Daily Deaths\");\n\nplt.tick_params(size=15,labelsize = 15,rotation=90)\nplt.show()\n","d93d537d":"test_data_size2 = 14\n\ntrain_data2 = daily_deaths[:-test_data_size2]\ntest_data2 = daily_deaths[-test_data_size2:]\n\ntrain_data2.shape","95163fca":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(train_data2, axis=1))\n\ntrain_data2 = scaler.transform(np.expand_dims(train_data2, axis=1))\n\ntest_data2 = scaler.transform(np.expand_dims(test_data2, axis=1))","f79e2dc1":"def create_sequences(data, seq_length):\n    xs2 = []\n    ys2 = []\n\n    for i in range(len(data)-seq_length-1):\n        x = data[i:(i+seq_length)]\n        y = data[i+seq_length]\n        xs2.append(x)\n        ys2.append(y)\n\n    return np.array(xs2), np.array(ys2)\nseq_length = 5\nX_train2, y_train2 = create_sequences(train_data2, seq_length)\nX_test2, y_test2 = create_sequences(test_data2, seq_length)\n\nX_train2 = torch.from_numpy(X_train2).float()\ny_train2 = torch.from_numpy(y_train2).float()\n\nX_test2 = torch.from_numpy(X_test2).float()\ny_test2 = torch.from_numpy(y_test2).float()","d1d24f91":"class CoronaVirusPredictor(nn.Module):\n\n  def __init__(self, n_features, n_hidden, seq_len, n_layers=2):\n    super(CoronaVirusPredictor, self).__init__()\n\n    self.n_hidden = n_hidden\n    self.seq_len = seq_len\n    self.n_layers = n_layers\n\n    self.lstm = nn.LSTM(\n      input_size=n_features,\n      hidden_size=n_hidden,\n      num_layers=n_layers,\n      dropout=0.5\n    )\n    self.rnn = nn.RNN( input_size=n_features, hidden_size=n_hidden,  num_layers=n_layers, batch_first=True, nonlinearity='relu')\n \n\n    self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n\n  def reset_hidden_state(self):\n    self.hidden = (\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n    )\n\n  def forward(self, sequences):\n    lstm_out, self.hidden = self.lstm(\n      sequences.view(len(sequences), self.seq_len, -1),\n      self.hidden\n    )\n    last_time_step = \\\n      lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n    y_pred = self.linear(last_time_step)\n    return y_pred","6a2a1fc9":"#deaths\ndef train_model(\n  model,\n  train_data2,\n  train_labels2,\n  test_data2=None,\n  test_labels2=None\n):\n  loss_fn = torch.nn.MSELoss(reduction='sum')\n\n  optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n  num_epochs = 100\n\n  train_hist2 = np.zeros(num_epochs)\n  test_hist2 = np.zeros(num_epochs)\n\n  for t in range(num_epochs):\n    model.reset_hidden_state()\n\n    y_pred2 = model(X_train2)\n\n    loss2 = loss_fn(y_pred2.float(), y_train2)\n\n    if test_data2 is not None:\n      with torch.no_grad():\n        y_test_pred2 = model(X_test2)\n        test_loss2 = loss_fn(y_test_pred2.float(), y_test2)\n      test_hist2[t] = test_loss2.item()\n\n      if t % 10 == 0:\n        print(f'Epoch {t} train loss: {loss2.item()} test loss: {test_loss2.item()}')\n    elif t % 10 == 0:\n      print(f'Epoch {t} train loss: {loss2.item()}')\n\n    train_hist2[t] = loss2.item()\n\n    optimiser.zero_grad()\n\n    loss2.backward()\n\n    optimiser.step()\n\n  return model.eval(), train_hist2, test_hist2\n\n\n","d9a4dffb":"model = CoronaVirusPredictor(\n  n_features=1,\n  n_hidden=90, #\n  seq_len=seq_length,\n  n_layers=2\n)","deacbd7a":"#deaths\nmodel, train_hist2, test_hist2 = train_model(\n  model,\n  X_train2,\n  y_train2,\n  X_test2,\n  y_test2\n)\n\n","9dcb9b9d":"scaler = MinMaxScaler()\n\nscaler = scaler.fit(np.expand_dims(daily_deaths, axis=1))\n\nall_data = scaler.transform(np.expand_dims(daily_deaths, axis=1))\n\nall_data.shape","e2c2ba93":"X_all, y_all = create_sequences(all_data, seq_length)\n\nX_all = torch.from_numpy(X_all).float()\ny_all = torch.from_numpy(y_all).float()\n\nmodel = CoronaVirusPredictor(\n  n_features=1,\n  n_hidden=70,\n  seq_len=seq_length,\n  n_layers=2\n)\nmodel, train_hist2, _ = train_model(model, X_all, y_all)","a676bbcb":"DAYS_TO_PREDICT = 12\n\nwith torch.no_grad():\n  test_seq = X_all[:1]\n  preds = []\n  for _ in range(DAYS_TO_PREDICT):\n    y_test_pred2 = model(test_seq)\n    pred = torch.flatten(y_test_pred2).item()\n    preds.append(pred)\n    new_seq = test_seq.numpy().flatten()\n    new_seq = np.append(new_seq, [pred])\n    new_seq = new_seq[1:]\n    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()\n#As before, we\u2019ll inverse the scaler transformation:\n\npredicted_cases = scaler.inverse_transform(\n  np.expand_dims(preds, axis=0)\n).flatten()","9fb5fdb1":"daily_deaths.index[-1]\npredicted_index = pd.date_range(\n  start=daily_deaths.index[-1],\n  periods=DAYS_TO_PREDICT + 1,\n  closed='right'\n)\n\npredicted_cases = pd.Series(\n  data=predicted_cases,\n  index=predicted_index\n)\n\nplt.plot(predicted_cases, label='Predicted Daily Deaths')\nplt.legend();","056d8ac9":"predicted_cases","521c9f19":"Building a model","4a91f61c":"Preprocessing","74754399":"DATA EXPLORATION AND PLOTTING\n","54791e55":"Prediction via Polynomial Regression","0db9aa37":"\n\n3.   Bayesian ridge polynomial regression\n\n","e8653844":"Logistic Curve Fitting We are going to use scipy.optimize.curve_fit to fit a logistic curve to the number of confirmed cases globally","d7b25d5e":"Transforming our data for polynomial regression","ef657df4":"# Analysis and Prediction of Daily Global Deaths\n","5e13cecf":"By  \nZahra Jalia (20858708)  \nAnannya Panda (20861832)  \nGroup Name:- A-Z  \nGroup No:- 48","db7e2c8f":"Death prediction using RNN","03bfda9f":"Total number of deaths in Brazil, Canada, Germany, US, Spain, Italy from 1\/22\/20\n","ea1c1e90":"Training","2845fb4a":"Future predictions using SVM","bca06891":"***Why Prophet?***  \nProphet is easy to customize and use, and to produce accurate forecasts which can be explained intuitively with supporting evidence such as forecast seasonality components. It allows the analyst to explain in an intuitive and convinving manner to higher management as to why the forecasts are as such, and the plausible underlying factors that contribute to its result. Furthermore, it is also open-source! :)","3a2d6895":"Prediction via SVM","d9d85086":"Future predictions using polynomial regression","a5848efa":"Moving Average\n","9b029e35":"Use all data for training","ecec724b":"Predictions","5d9c4e6d":"***References***\n\n\n1.   https:\/\/facebook.github.io\/prophet\/\n2.   https:\/\/facebook.github.io\/prophet\/docs\/\n3.    https:\/\/github.com\/facebook\/prophet","aa23f615":"**ANALYSIS AND TRAINING OF DATA**","af3aa8c2":"Testing on available data","4d51bef9":"Forecasting Confirmed Cases Worldwide with Prophet (Baseline)  \nWe perform a week's ahead forecast with Prophet, with 95% prediction intervals. Here, no tweaking of seasonality-related parameters and additional regressors are performed","c4aaa593":"\n\n2.   Linear regression\n\n","345fbc73":"Thanks to Mehdi Afshari for providing the latest data.","c0f84080":"Using prophet for automate future forecasting and predictions","6dc2f9c6":"Prediction via Bayesian Ridge Regression","4545be97":"Currently, we have a big sequence of daily cases. We\u2019ll convert it into smaller ones","e273c4cf":"Future forcasting","a423e40b":"Notice that this predicts that globally the infection hit the highest between 60-80 days from it start and the number of confirmed cases will max out around 3 million cases. We should consider that there is a lot of statistical uncertainty in this prediction. This is almost certainly underestimating. Furthermore, for some countries, it is too early to use this method to get a reasonable estimate. We should also consider that the number of positive undiagnosed cases in each country is likely to be signigicant. This, along with the fact that most countries aren't testing enough, the mortality rate is likely inflated since the number of actual positive cases in each population is likely considerably higher than confirmed cases.","20984fa8":"***Prophet***  \nWe use Prophet, a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. It works best with time series that have strong seasonal effects and several seasons of historical data. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well. It is also an open source software released by Facebook\u2019s Core Data Science team. It is available for download on CRAN and PyPI.","ad0ca377":"Model for predicting outcome as death\n\n1. Support vector machines","c27230c3":"Predicting future cases\n","487c57ab":"Future predictions using Bayesian Ridge","2567ac84":"World wide growth of cases resulting in death\n","71cb3873":"Deaths in Canada"}}