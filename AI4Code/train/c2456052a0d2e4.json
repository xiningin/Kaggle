{"cell_type":{"5bba7689":"code","5d8a98c3":"code","27d06367":"code","e543e6d1":"code","a89627c4":"code","ee3baa90":"code","05be9ff3":"code","39ba236d":"code","abab11f1":"code","c31bb663":"code","df348558":"code","2c6c82e3":"code","3ef0252e":"code","dfe583e5":"code","86cdaef7":"code","5ce853c8":"code","92763546":"code","73c6fd1a":"code","e2858700":"code","8c5797cc":"code","f7e70473":"code","6d67af51":"code","ee961415":"code","b3c4a653":"code","515a9c78":"code","971ce937":"code","9f6ce393":"code","63aba063":"code","6a3ba20a":"code","429b6d7c":"code","901c8946":"code","613438aa":"code","81c9e17e":"code","b2cf7326":"code","6abc4929":"code","4838c843":"markdown","c36600b3":"markdown","5940090f":"markdown","41ebb4b3":"markdown","65586d46":"markdown","4426627c":"markdown","17bb069b":"markdown","0fb17a6a":"markdown","93aa760b":"markdown","ea334df5":"markdown","24fd574c":"markdown","43ae4a32":"markdown","4f82f4e7":"markdown","f844ef8a":"markdown","3b1d046c":"markdown","44c686c8":"markdown","51e95ee2":"markdown","36efb08a":"markdown","b21cb6d5":"markdown","0457434c":"markdown","bcc6ac93":"markdown"},"source":{"5bba7689":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d8a98c3":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\n\n%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport itertools","27d06367":"tf.test.is_gpu_available()","e543e6d1":"tf.version.VERSION\ntf.config.list_physical_devices('GPU')","a89627c4":"base_dir = '\/kaggle\/input\/intel-image-classification'\n\n# Getting training and testing directories\ntrain_dir = os.path.join(base_dir, 'seg_train', 'seg_train')\ntest_dir = os.path.join(base_dir, 'seg_test','seg_test')\npred_dir = os.path.join(base_dir, 'seg_pred','seg_pred')\n\n# Directory with the different training pictures\ntrain_buildings = os.path.join(train_dir, 'buildings')\ntrain_forest = os.path.join(train_dir, 'forest')\ntrain_glacier = os.path.join(train_dir, 'glacier')\ntrain_mountain = os.path.join(train_dir, 'mountain')\ntrain_sea = os.path.join(train_dir, 'sea')\ntrain_street = os.path.join(train_dir, 'street')\n\n# Directory with the different testing pictures\ntest_buildings = os.path.join(test_dir, 'buildings')\ntest_forest = os.path.join(test_dir, 'forest')\ntest_glacier = os.path.join(test_dir, 'glacier')\ntest_mountain = os.path.join(test_dir, 'mountain')\ntest_sea = os.path.join(test_dir, 'sea')\ntest_street = os.path.join(test_dir, 'street')","ee3baa90":"train_building_fnames = os.listdir(train_buildings)\ntrain_forest_fnames = os.listdir(train_forest)\n\nprint(train_building_fnames[:10])\nprint(train_forest_fnames[:10])","05be9ff3":"\ntraining_images_len = []\nfor category in os.listdir(train_dir):\n    num_images = len(os.listdir(os.path.join(train_dir, category)))\n    training_images_len.append(num_images)\n    print(f'total training {category} images:', num_images)\n\nprint(f'All training images: {np.sum(training_images_len)}')\nprint('-'*50)\n\ntesting_images_len = []\nfor category in os.listdir(test_dir):\n    num_images = len(os.listdir(os.path.join(test_dir, category)))\n    testing_images_len.append(num_images)\n    print(f'total testing {category} images:', num_images)\nprint(f'All testing images: {np.sum(testing_images_len)}')","39ba236d":"os.listdir(train_dir)[0:2]","abab11f1":"nrows = 6\nncols = 4\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\n# get the images to show from each category. I am going to show 4 images per category, one category for each row\nimages_to_show = []\nfor category in os.listdir(train_dir):\n    images_to_show.append([os.path.join(train_dir, category, fname) \n                           for fname in os.listdir(os.path.join(train_dir, category))[0:ncols]])\n\n# The previous code outputs a list of lists, this flattens the list\nimages_to_show = list(itertools.chain.from_iterable(images_to_show))\n    \nfor i, img_path in enumerate(images_to_show):\n    # set up subplot (indices start at 1)\n    sp = plt.subplot(nrows, ncols, i+1)\n    sp.axis('Off') # Don't show axes or gridlines\n    \n    img = mpimg.imread(img_path)\n    plt.imshow(img)\n\nplt.show()","c31bb663":"import PIL\nfor file in images_to_show:\n    image = PIL.Image.open(file)\n    width, height = image.size\n    print(width, height)","df348558":"train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir, labels='inferred',  \n                                                                    batch_size=32, image_size=(150,150))","2c6c82e3":"type(train_dataset)","3ef0252e":"classes = train_dataset.class_names\nclasses","dfe583e5":"plt.figure(figsize=(10, 10))\n\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        plt.subplot(3, 3, i+1)\n        plt.imshow(images[i]\/255)\n        plt.title(classes[labels[i]])\n        plt.xticks([])\n        plt.yticks([])","86cdaef7":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rescale = 1.0\/255,\n    shear_range = 0.2,\n    zoom_range = 0.2\n)\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, target_size=(150,150), class_mode=\"categorical\", \n                                                    shuffle=True, seed = 5)","5ce853c8":"train_generator.class_indices","92763546":"type(train_datagen)","73c6fd1a":"validation_datagen = ImageDataGenerator(rescale = 1.0\/255)\nvalidation_generator = validation_datagen.flow_from_directory(test_dir, target_size=(150,150), class_mode='categorical',\n                                                             shuffle=True, seed = 5)","e2858700":"validation_generator.class_indices","8c5797cc":"num_classes = 6\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    # dropout layer\n    tf.keras.layers.Dropout(0.2),\n    # 256 neuron layer\n    tf.keras.layers.Dense(256, activation='relu'),\n    # dropout layer\n    tf.keras.layers.Dropout(0.2),\n    # Only 6 output neurons since there are 6 categories\n    tf.keras.layers.Dense(6, activation= 'softmax')  \n])","f7e70473":"model.summary()","6d67af51":"\nfrom tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss='categorical_crossentropy',\n              metrics = ['accuracy'])","ee961415":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy')>0.80):\n            print(\"\\nReached 80% accuracy so cancelling training\")\n            self.model.stop_training = True","b3c4a653":"callbacks = myCallback()","515a9c78":"early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n                                              min_delta=0, \n                                              patience=3, \n                                              verbose=0,\n                                              mode='auto', \n                                              baseline=None, \n                                              restore_best_weights=False\n                                             )","971ce937":"# initially, I was going to use model.fit_generator, but this is now deprecated as of tensorflow-gpu==2.2.0 or higher\nhistory = model.fit(train_generator, batch_size = 20, epochs=60, verbose = 1, validation_data = validation_generator,\n                   callbacks=[early_stop])","9f6ce393":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","63aba063":"from tensorflow.keras.applications import ResNet50V2\n\nn_layers = 150\nimg_shape = (150, 150, 3)","6a3ba20a":"base_model  = ResNet50V2(input_shape=img_shape, include_top=False, weights='imagenet')\nhead_model = base_model\nfor layers in base_model.layers[:n_layers]:\n    layers.trainable = False\nhead_model = head_model.output\nhead_model = tf.keras.layers.GlobalMaxPooling2D()(head_model)\nhead_model = tf.keras.layers.Flatten(name=\"Flatten\")(head_model)\nhead_model = tf.keras.layers.Dense(1024, activation='relu')(head_model)\nhead_model = tf.keras.layers.Dropout(0.2)(head_model)\nprediction_layer = tf.keras.layers.Dense(6, activation='softmax')(head_model)\nmodel = tf.keras.Model(inputs=base_model.input, outputs=prediction_layer)","429b6d7c":"from tensorflow.keras.optimizers import Adam\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer=Adam(lr=0.01),\n    metrics=['accuracy'])","901c8946":"model.summary()","613438aa":"history = model.fit(train_generator,\n                   epochs=25,\n                   verbose=1,\n                   validation_data = validation_generator)","81c9e17e":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","b2cf7326":"import glob\nimport random\n\npred_input = os.path.join(pred_dir, \"*.jpg\")\ntest_img = glob.glob(pred_input)\nimg_select = random.randint(1,len(test_img))\nprint(type(test_img))\nimg = plt.imread(test_img[img_select])\nplt.imshow(img)","6abc4929":"\nimg=img\/255.0\ninput_data = np.array(np.expand_dims(img,axis=0), dtype=np.float32)\n# print(input_data)\noutput_data = model.predict(np.expand_dims(img,axis=0))\nresults = np.squeeze(output_data)\npred = classes[np.argmax(results)]\nprint('The Model Predicted {}'.format(pred))","4838c843":"Looking into the names of the different files in train_buildings and train_forest. The files are simply given numbers.","c36600b3":"# Creating the Model\nFor this model I'm going to use the ResNet50V2 architecture and load weights pre-trained on ImageNet. I set include_top to be false so that I am not using the fully-connected layer at the top of the network. Next I set the first 150 layers to be not trainable. That way I keep the pretrained weights for those layers. Next, I add a pooling and dense layer, followed by a dropout layer. The last layer is a dense layer with 6 neurons since there are 6 classes.","5940090f":"Here, I'm using a for loop to iterate through all of the different categories so that I can see how many training and testing images I have in each category. From here I can see that I have between 2191 to 2512 training images in each category and between 437 to 553 testing images in each category.","41ebb4b3":"# Using Transfer Learning\nNext, I'm going to try transfer learning with the ResNet50V2 architecture.","65586d46":"# Train the Model\nI'm going to train the model for 25 epochs. Giving it the train_generator and validation_generator just like last time.","4426627c":"Checking that I have GPU Support for TensorFlow","17bb069b":"# Load the data\nSet labels to be inferred so that they are generated from the directory structure. Set image_size to (150,150) since that is the size of the images","0fb17a6a":"# Callbacks\nInitially, I created a callback named myCallback which checks to see if the accuracy has exceeded a certain threshhold at the end of each epoch. If it has achieved that accuracy, then the model stops training. However, I decided to use a different callback named early_stop which checks the validation accuracy and stops training after 3 epochs have passed where the validation accuracy has not increased. I think this callback is more useful since it checks for itself when the val_accuracy stops increasing and stops whereas the other callback simply stops after the val_accuracy has achieved a certain percentage of accuracy.","93aa760b":"# Importing the data","ea334df5":"The source information stated that all images are 150x150. Here I am checking all of the images that were previously shown in order to see that they are really 150x150.","24fd574c":"Now, I'm going to take a look at a few pictures to get a better sense of what the datasets look like. This shows 4 pictures for each category. Each row shows a different category.","43ae4a32":"# Fitting the model\nNow I'm going to fit the model using the train_generator, validation_generator, and early_stop callback. Here, the model was fit for 13 epochs. Then it stopped due to the callback because the val_accuracy stopped increasing.","4f82f4e7":"# Using the AI Model to Make Predictions\nFinally, I want to use the AI model to make predictions on data that it has never seen before. I'm going to be using the pred_dir directory, which contains unlabeled images that the model has not seen before. Directly below, we can see the image. Then below the next cell, we can see the model's prediction.","f844ef8a":"# Compile the Model\nFor this model, I am using the RMSprop optimizer, which tries to resolve the problem that gradients may vary widely in magnitudes. It does this by combining the idea of only using the sign of the gradient with the idea of adapting the step size individually for each weight. So it looks at the step size that's defined for a particular weight instead of looking at the magnitude of the gradient. Then the step size adapts over time so that the learning is accelerated in the correct direction.\n\nFor the loss function, I decide on categorical crossentropy.\n\nFinally, for the metrics, I want the model to evaluate the accuracy during training and testing.","3b1d046c":"# Plotting the Accuracy and Loss\nThe training and validation accuracy were trending upwards for the entire 25 epochs, which was good. The training and validation loss were also mostly going down. Except, the validation loss had a spike from around 0.5 all the way up to 4 during epoch 19. It may be worth investigating this more.\n\nOverall, the transfer learning performed better. With transfer learning, the validation accuracy reached as high as around 86.30% compared to building my own model which only achieved a validation accuracy of 81.90%.","44c686c8":"# Create ImageDataGenerator\nI'll be feeding the ImageDataGenerator for the training and validation data into the keras model.fit function. This ImageDataGenerator creates a tf.data.Dataset from the image files in my specified directory. This adjusts the shear and the zoom. Then after those transformations, the rescale adjusts the pixel intensity so they are between 0-1.","51e95ee2":"# Creating the Model\nI'm going to start out with creating a Sequential model, then I'm going to move on to trying a model with transfer learning.\n\nI will be creating a model using the Sequential API. This is the simplest kind of Keras model since it is just a single stack of layers connected sequentially. I'm implementing 3 convolutional layers (3x3) before I flatten the result to feed into dense layers. Additionally, between the dense layers, I add dropout layers. The dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps with overfitting. It helps with overfitting since the neurons can't depend on only a few earlier neurons to make their output since neurons can be dropped out at any time. Finally, I have 6 neurons in the final layer since there are 6 categories. For this final layer, I use the softmax activation, which converts from weighted sum values into probabilities that sum to one.","36efb08a":"# Plotting the Accuracy and Loss\nHere, I first plot the training\/validation accuracy for each epoch. The training accuracy increases smoothly. However the validation accuracy has a dip at epoch 8 before increasing again.\n\nNext, I plot the training and validation loss. Again, the training loss is smooth. But this time the validation loss is a lot more erratic. It only trends downward for the first 2 epochs. A few ways that I may want to investigate to improve this is modifying the learning rate, changing the optimizer\/activation function, and altering the batch size. Since I was using the ReLU activation function, it is possible that my model is suffering from the \"dying ReLU\" problem.","b21cb6d5":"# Landscape Classification\nThis dataset consists of around 25k images of size 150x150 distributed under 6 categories: buildings, forest, glacier, mountain, sea, street. There are around 14k images in Train, 3k in Test, and 7k in Prediction. This dataset was initially published by Intel.\n\nIn this challenge, I'm going to work on creating a CNN with transfer learning in order to classify these images.","0457434c":"A similar process is done for the validation data. However, I will not be adjusting the shear or the zoom. This is because I am using the validation data to check the accuracy of the model on data it has not seen before. So, I want to see how it performs on the data without transformations. I will still be adjusting the pixel intensity so that it is between 0-1 though.","bcc6ac93":"# View the images with labels"}}