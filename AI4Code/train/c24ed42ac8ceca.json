{"cell_type":{"2b17572a":"code","2f3964cb":"code","839df2b0":"code","fc31edda":"code","372a044f":"code","8cbccfbc":"code","dad4b4de":"code","3e44af91":"code","146b28dc":"code","fb681bdc":"code","70df4553":"code","dd6c147b":"code","125ffdb3":"code","90c4c328":"code","7359aee7":"code","fc4e4d08":"code","4c125b69":"code","c9ed9cbd":"code","8d8b1fed":"code","6b2fdf7e":"code","6bc5cf57":"code","ad85d8a3":"code","2035f11a":"code","819aab99":"code","74fab5a0":"code","9479b85a":"code","4fbcd2c4":"code","529b4a8b":"code","029f7b69":"code","4b40d8b4":"code","65b684b8":"code","95d9a38b":"code","97b10a83":"code","309a7636":"code","13c7f2c6":"code","311c52ee":"code","22f7bcdb":"code","718c5a6e":"code","9731c3e2":"code","42fec3e6":"code","31bc7b07":"code","7e924a94":"code","cd1d4d22":"code","6297585e":"markdown"},"source":{"2b17572a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2f3964cb":"from sklearn.model_selection import train_test_split \nfrom matplotlib import pyplot as plt\n%matplotlib inline ","839df2b0":"!unzip \/kaggle\/input\/facial-keypoints-detection\/training.zip\n!unzip \/kaggle\/input\/facial-keypoints-detection\/test.zip","fc31edda":"IdLookupTable = pd.read_csv('\/kaggle\/input\/facial-keypoints-detection\/IdLookupTable.csv')\nIdLookupTable.info()","372a044f":"IdLookupTable.head()","8cbccfbc":"SampleSubmission = pd.read_csv('\/kaggle\/input\/facial-keypoints-detection\/SampleSubmission.csv')\nSampleSubmission.info()","dad4b4de":"SampleSubmission.head()","3e44af91":"test = pd.read_csv('test.csv')\ntest.info()","146b28dc":"test.head()","fb681bdc":"training = pd.read_csv('training.csv')\ntraining.info()","70df4553":"training.head(2)","dd6c147b":"training = training.dropna()\n#training.fillna(method = 'ffill',inplace = True)","125ffdb3":"training.shape, type(training)","90c4c328":"training['Image'] = training['Image'].apply(lambda x: np.fromstring(x, dtype=int, sep=' ').reshape((96,96)))","7359aee7":"test['Image'] = test['Image'].apply(lambda x: np.fromstring(x, dtype=int, sep=' ').reshape((96,96)))","fc4e4d08":"def get_image_and_dots(df, index):\n    image = plt.imshow(df['Image'][index],cmap='gray')\n    l = []\n    for i in range(1,31,2):\n        l.append(plt.plot(df.loc[index][i-1], df.loc[index][i], 'ro'))\n        \n    return image, l\n","4c125b69":"fig = plt.figure(figsize=(8, 8))\nfig.subplots_adjust(\n    left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n\nfor i in range(16):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    get_image_and_dots(training, i)\n\nplt.show()","c9ed9cbd":"X = np.asarray([training['Image']], dtype=np.uint8).reshape(training.shape[0],96,96,1)\ny = training.drop(['Image'], axis=1).to_numpy()","8d8b1fed":"y1 = training.drop(['Image'], axis=1)","6b2fdf7e":"type(X), type(y)","6bc5cf57":"from tensorflow.python.keras.utils.data_utils import Sequence\nfrom keras import layers , models\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nimport albumentations as A","ad85d8a3":"class DataLoader(Sequence):\n    def __init__(self, X, y, batch_size, augmentations=None, as_rgb=False):\n        self.X, self.y = X, y\n        self.batch_size = batch_size\n        self.augment = augmentations\n        self.shuffle = True\n        self.as_rgb = as_rgb\n        self.on_epoch_end()\n\n    def __len__(self):\n        \"\"\" Corresponds to the number of steps in one epoch. \"\"\"\n        return int(np.ceil(len(self.X) \/ float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        indexes = self.indexes[idx*self.batch_size: (idx+1)*self.batch_size]\n        batch_X = self.X[indexes, ...]\n        batch_y = self.y[indexes, :]\n        \n        # Convert grayscale to RGB if needed (if you want to use a pre-trained ResNet for example)\n        if self.as_rgb:\n            batch_X = np.tile(batch_X, reps=(1,1,1,3))\n\n        # Apply transformations on both images and keypoints\n        if self.augment is not None:\n            keypoints = np.array([ tuple(zip(point[::2], point[1::2])) for point in batch_y ])\n            transformed = [ self.augment(image=x, keypoints=y) for x,y in zip(batch_X, keypoints) ]\n            batch_X = np.stack([ z['image'] for z in transformed ], axis=0)\n            batch_y = np.stack([ np.array(z['keypoints']).flatten(order='C') for z in transformed ], axis=0)\n\n        return batch_X, batch_y\n\n    def on_epoch_end(self):\n        \"\"\" Shuffle the data after each epoch to avoid oscillation patterns in the loss. \"\"\"\n        self.indexes = np.arange(len(self.X))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)","2035f11a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","819aab99":"X_train2, X_valid, y_train2, y_valid = train_test_split(X_train, y_train, test_size=0.10, shuffle=True)\n\n# Define augmentation strategy\ntransform = A.Compose([\n    A.ShiftScaleRotate(rotate_limit=30, p=0.5),\n    A.RandomBrightnessContrast(p=0.5),\n    A.RandomCrop(width=96, height=96, p=1),\n    A.Rotate(p=0.5),\n    A.HorizontalFlip(p=0.5),\n    A.GaussianBlur(p=0.5),\n    A.GaussNoise(var_limit=(1e-5, 1e-3), p=0.5),\n], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n\ntrain_loader = DataLoader(X_train2, y_train2, batch_size=128, augmentations=transform)\nprint(X_train2.shape, y_train2.shape)\nprint(X_valid.shape, y_valid.shape)\n\n# Visualize augmented data\nx_batch, y_batch = train_loader[1]\nshow_random_samples(x_batch.squeeze(), y_batch)","74fab5a0":"model = models.Sequential()\n\nmodel.add(layers.Convolution2D(32 , (3,3) , input_shape = (96 , 96 , 1) ))\nmodel.add(layers.ReLU())\nmodel.add(layers.BatchNormalization())\n          \n\nmodel.add(layers.Convolution2D(64 , (3,3) ))\nmodel.add(layers.ReLU())\nmodel.add(layers.MaxPool2D())\n          \nmodel.add(layers.Convolution2D(128 , (3,3) ))\nmodel.add(layers.ReLU())\nmodel.add(layers.MaxPool2D())\n          \nmodel.add(layers.Convolution2D(256 , (3,3) ))\nmodel.add(layers.ReLU())\nmodel.add(layers.MaxPool2D())\n          \nmodel.add(layers.Convolution2D(512 , (3,3) ))\nmodel.add(layers.ReLU())\nmodel.add(layers.MaxPool2D())\n          \nmodel.add(layers.Convolution2D(1024 , (3,3) ))\nmodel.add(layers.ReLU())\nmodel.add(layers.MaxPool2D())\n          \n          \nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512 , activation = 'relu'))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Dense(30))#Any customization on the training logic is then easily controlled by the user.\n\n\n          \nmodel.summary()","9479b85a":"model.compile(optimizer = 'adam' , loss = 'mean_squared_error' , metrics = ['mae'])","4fbcd2c4":"history = model.fit(X_train2, y_train2 , epochs = 500 , batch_size = 32 , validation_data = (X_valid, y_valid))\n","529b4a8b":"model.save('keypoints.h5')","029f7b69":"test.shape, type(test)","4b40d8b4":"test_X = np.asarray([test['Image']], dtype=np.uint8).reshape(test.shape[0],96,96,1)\ntest_res = model.predict(test_X)","65b684b8":"test_res = model.predict(test_X)","95d9a38b":"train_predicts = model.predict(X_train)","97b10a83":"n = 11\n\nxv = X_test[n].reshape((96,96))\nplt.imshow(xv,cmap='gray')\n\nfor i in range(1,31,2):\n    plt.plot(test_res[n][i-1], test_res[n][i], 'ro')\n    plt.plot(y_test[n][i-1], y_test[n][i], 'x', color='green')\n\nplt.show()","309a7636":"header = list(y1.columns)\n","13c7f2c6":"test_predicts = pd.DataFrame(test_res, columns = header)","311c52ee":"for i in range(IdLookupTable.shape[0]):\n    IdLookupTable.Location[i] = test_predicts.loc[IdLookupTable.ImageId[i]-1][IdLookupTable.FeatureName[i]]\n    ","22f7bcdb":"SampleSubmission.Location = IdLookupTable.Location","718c5a6e":"my_submission = SampleSubmission","9731c3e2":"my_submission.to_csv('submission1.csv', index=False)","42fec3e6":"my_submission","31bc7b07":"samplesub = pd.read_csv('..\/input\/facial-keypoints-detection\/SampleSubmission.csv')\nsamplesub","7e924a94":"idlookup_data = IdLookupTable","cd1d4d22":"feature_names = list(idlookup_data['FeatureName'])\nimage_ids = list(idlookup_data['ImageId']-1)\nrow_ids = list(idlookup_data['RowId'])\n\nfeature_list = []\nfor feature in feature_names:\n    feature_list.append(feature_names.index(feature))\n    \npredictions = []\nfor x,y in zip(image_ids, feature_list):\n    predictions.append(test_res[x][y])\n    \nrow_ids = pd.Series(row_ids, name = 'RowId')\nlocations = pd.Series(predictions, name = 'Location')\nlocations = locations.clip(0.0,96.0)\nsubmission_result = pd.concat([row_ids,locations],axis = 1)\nsubmission_result.to_csv('submission.csv',index = False)","6297585e":"Model"}}