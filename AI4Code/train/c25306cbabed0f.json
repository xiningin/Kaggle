{"cell_type":{"79dfdf5d":"code","6e8b9b4b":"code","e9bdce8d":"code","cb5005cf":"code","7e36c6f8":"code","50652d05":"code","60a6b271":"code","32adfe51":"code","8218e56e":"code","dcc42a3d":"code","27d7bd93":"markdown","5a7f120c":"markdown","dfd50420":"markdown","3f88a2c7":"markdown","051cc4a2":"markdown","824bee7e":"markdown","0db544a6":"markdown","52a88812":"markdown"},"source":{"79dfdf5d":"# clone the repository\n!git clone https:\/\/github.com\/thepochynsons\/pytorch-CycleGAN-and-pix2pix.git","6e8b9b4b":"import os\nos.chdir('pytorch-CycleGAN-and-pix2pix\/')\n# install dependencies\n!pip install -r requirements.txt","e9bdce8d":"# SHOW ABDOMINAL_US DATASET IMAGES \nfrom os import path\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimages = ['c37','j26','c15']\nfig = plt.figure()\n# for each input image\nfor idx in range(len(images)):\n    # add a subplot\n    ax = fig.add_subplot(1, len(images), idx+1, xticks=[], yticks=[])\n    # display the image\n    plt.imshow(Image.open(path.join('..\/..\/input\/abdominal_US\/abdominal_US\/RUS\/images\/train',images[idx] + '.jpg')),cmap='gist_gray')\n","cb5005cf":"# SHOW AUS2RUS DATASET IMAGES\n\nrus_example = Image.open('..\/..\/input\/aus2rus\/aus2rus\/trainB\/rotated_rezized_pacienteC16.jpg')\naus_example = Image.open('..\/..\/input\/aus2rus\/aus2rus\/trainA\/rezized_ct14-1.png')\nfig = plt.figure()\nax = fig.add_subplot(1, 2, 1, xticks=[], yticks=[], title='Real Ultrasound')\nplt.imshow(rus_example)\nax = fig.add_subplot(1, 2, 2, xticks=[], yticks=[], title='Artificial Ultrasound')\nplt.imshow(aus_example)\nplt.show()","7e36c6f8":"os.mkdir('.\/checkpoints')","50652d05":"!cp -r ..\/..\/input\/pretrained_model_aus2rus\/aus2rus .\/checkpoints\/aus2rus","60a6b271":"!python train.py --dataroot ..\/..\/input\/aus2rus\/aus2rus\/ --name new_aus2rus --model cycle_gan  --gan_mode vanilla --norm instance --netG unet_256 --preprocess none --input_nc 1 --output_nc 1","32adfe51":"#Translate AUS to RUS \n!python ultrasound_test.py --dataroot ..\/..\/input\/aus2rus\/aus2rus\/ --name aus2rus --model cycle_gan --netG unet_256 --input_nc 1 --output_nc 1 --results_dir .\/results\/fakeRUS --direction AtoB","8218e56e":"#Translate RUS to AUS \n!python ultrasound_test.py --dataroot ..\/..\/input\/aus2rus\/aus2rus\/ --name aus2rus --model cycle_gan --netG unet_256 --input_nc 1 --output_nc 1 --results_dir .\/results\/fakeAUS --direction BtoA","dcc42a3d":"# Original images\nrus = Image.open('..\/..\/input\/aus2rus\/aus2rus\/testB\/rotated_rezized_pacienteA1.jpg')\naus = Image.open('..\/..\/input\/aus2rus\/aus2rus\/testA\/rezized_ct11-7.png')\n\n# Fake images\nfake_aus = Image.open('.\/results\/fakeAUS\/rotated_rezized_pacienteA1.png')\nfake_rus = Image.open('.\/results\/fakeRUS\/rezized_ct11-7.png')\n\nfig = plt.figure()\n\nax = fig.add_subplot(2, 2, 1, xticks=[], yticks=[], title='RUS')\nplt.imshow(rus)\n\nax = fig.add_subplot(2, 2, 2, xticks=[], yticks=[], title='AUS')\nplt.imshow(aus)\n\nax = fig.add_subplot(2, 2, 3, xticks=[], yticks=[], title='Fake_AUS')\nplt.imshow(fake_aus)\n\nax = fig.add_subplot(2, 2, 4, xticks=[], yticks=[], title='Fake_RUS')\nplt.imshow(fake_rus)","27d7bd93":"# **Visualize results**\n\nThe following code will show you the results of the transformations.","5a7f120c":"# **Install**\nFirst we need to clone the CycleGAN repository and install the correpsonding dependencies","dfd50420":"# **Dataset**\nWe provide a dataset with two kinds of images: AUS (Artificial Ultrasound) and RUS (Real Ultrasound). Both sets have their own training and test partitions.\n\n* AUS scans are simulated US images that were generated using a ray-casting based simulation approach, applied on CT volumes taken from the [VISCERAL challenge](http:\/\/www.visceral.eu\/). This data set comprises 926 artifially US scans (training set: 633, test set: 293).\n* RUS are real US scans that were acquired from 11 subjects without any abdominal pathology or known disease. This data set comprises 617 real US scans (training set: 404, test set: 213).\n\nThe original images (without any preprocessing) can be found at `..\/input\/ussimandsegm\/abdominal_US\/abdominal_US`.\n\nThe following code will open 3 exemplary images from the RUS dataset","3f88a2c7":"## Train your own model\nThis code also provides you with a script to train a new model.  You need to set up some training options, of course. ```--dataroot``` (path to dataset), for instance, is required. For all the other options, check out `.\/options`.\n\nIntermediate results and models will be saved in `.\/checkpoints\/<model_name>`\n\nThe following code was called for the pretrained model. ","051cc4a2":"# **Training a CycleGAN model for unpaired artificial to real US mapping**\n\n## Pretrained model\n\nIn this kernel we provide you with a baseline CycleGAN model based on our IJCARS publication. In this case the generators are U-net architectures,  trained using Adam optimization for 400 epochs. An initial learning rate of 0.0002 was used. After the first 200 epochs, the learning rate was iteratively reduced by a linear decay policy. All other network parameters can be found at `..\/input\/ussimandsegm\/aus2rus_pretrained_model\/aus2rus\/train_opt.txt`\n\n![](http:\/\/)Copy model files to project checkpoints_folder: ","824bee7e":"As it can be seen in the examples, some areas of the images do not have any information. In order to ensure that the network focuses on the right regions, we pre-process the images by converting them into polar coordinates.\n\nThe following code will show you the resulting images after applying the corresponding transformation, both on real and artificial US scans. The preprocessed dataset is in folder `..\/input\/ussimandsegm\/aus2rus`.\n","0db544a6":"# **Test**\nBy running ```ultrasound_test.py``` you will be able to evaluate the model to transform between AUS and RUS. You need to specify:\n\n* The direction (AtoB or BtoA) of the transformation (e.g. AtoB will improve realism in the AUS images).\n* The dataroot where the test images are.\n* The results_dir where the output images will be saved. \n","52a88812":"# **Improving realism in abdominal Ultrasound simulation using CycleGANs**\n\nThis code is an implementation of our paper \"Improving realism in abdominal Ultrasound simulation using CycleGANs\", and a proof-of-concept on how our released dataset can be used.\n\nThe network implementation was originally forked from [junyanz\/pytorch-CycleGAN-and-pix2pix](https:\/\/github.com\/junyanz\/pytorch-CycleGAN-and-pix2pix)."}}