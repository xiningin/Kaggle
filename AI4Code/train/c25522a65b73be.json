{"cell_type":{"35da074c":"code","8ea70641":"code","0bb93094":"code","926de90e":"code","2fe3442d":"code","fbb6d47c":"code","bd47274e":"code","6e888a22":"code","a619afbb":"code","d30f9d35":"code","245ad33e":"code","acb46c0e":"code","e052c0c5":"code","5e0541d2":"code","9473aa2d":"markdown","30d006b8":"markdown"},"source":{"35da074c":"import numpy as np\nimport pandas as pd\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8ea70641":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nprint(tf.__version__)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow import keras","0bb93094":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\nprint(\"train data shape: {}\".format(train_data.shape))\nprint(\"test data shape: {}\".format(test_data.shape))\n\nX, Y = train_data.drop(['label'], axis=1), train_data['label']\n\n# release train_data dataframe\ndel train_data","926de90e":"# data distribution - check for class imbalance\nsns.countplot(Y)","2fe3442d":"# visualize sample data\nidx = np.random.randint(0, len(X)-1)\nsample_img = np.reshape(np.array(X.iloc[idx, :]), (28, 28))\nsample_label = Y.iloc[idx]\n\nplt.figure()\nplt.imshow(sample_img)\nplt.show()\nprint(\"Label for this input is: {}\".format(sample_label))","fbb6d47c":"# Normalize input pixels\nX = X\/255.0\ntest_features = test_data\/255.0\n\n# convert labels to categorical\nY = keras.utils.to_categorical(Y, num_classes=10)\n\n# reshape input\nX = X.values.reshape(-1,28,28,1)\ntest_features = test_features.values.reshape(-1,28,28,1)","bd47274e":"# data split\nX_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.1, random_state=2)","6e888a22":"# data Generator\ndatagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=15,\n                                                      width_shift_range=0.1,\n                                                      zoom_range=0.1,\n                                                      height_shift_range=0.1)\ndatagen.fit(X_train)","a619afbb":"# CNN Model definition\ninput_shape = (28, 28, 1)\nmodel = keras.Sequential()\nmodel.add(keras.layers.Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\", input_shape=input_shape, padding=\"Same\"))\nmodel.add(keras.layers.Conv2D(filters=32, kernel_size=(5, 5), activation=\"relu\", padding=\"Same\"))\nmodel.add(keras.layers.Dropout(0.25))\nmodel.add(keras.layers.MaxPooling2D((2, 2)))\n\nmodel.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"Same\"))\nmodel.add(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"Same\"))\nmodel.add(keras.layers.Dropout(0.25))\nmodel.add(keras.layers.MaxPooling2D((2, 2)))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(256, activation='relu'))\nmodel.add(keras.layers.Dropout(0.2))\nmodel.add(keras.layers.Dense(10))\n\nmodel.summary()","d30f9d35":"# optimizer\nadam_opt = keras.optimizers.Adam(learning_rate=0.0008, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n\n# compile\nmodel.compile(optimizer=adam_opt,\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics = ['accuracy'])\n\n# Fit - Train \/ Validation\n# history = model.fit(X_train, y_train, \n#                     batch_size=96,\n#                     epochs=30, \n#                     validation_data=(X_val, y_val), \n#                     shuffle=True, \n#                     validation_freq=1)\n\n# Fit generator\nhistory = model.fit_generator(datagen.flow(X_train, y_train, batch_size=96),\n                             steps_per_epoch=len(X_train)\/96, \n                             epochs=30,\n                             validation_data=(X_val, y_val),\n                             validation_freq=1,\n                             shuffle=True)","245ad33e":"# MLP \/ DNN model evaluation\nval_loss, val_acc = model.evaluate(X_val, y_val, verbose=2)\n\nplt.figure(figsize=(7, 7))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label=\"train_loss\")\nplt.plot(history.history['val_loss'], label=\"val_loss\")\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc=\"lower right\")\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label=\"train_accuracy\")\nplt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.85, 1])\nplt.legend(loc=\"lower right\")\n","acb46c0e":"# Predictions - Validation Set\npredicted = model.predict_classes(X_val)\n# confusion matrix\ncm = confusion_matrix(np.argmax(y_val, axis=1), predicted)\n\nplt.figure(figsize=(10,10))\nsns.heatmap(cm,annot=True)","e052c0c5":"# Sample Predictions Visualization on Test Data\nplt.figure(figsize=(10,10))\nt_idxs = np.random.randint(0, len(test_data)-1, size=25)\nresults = model.predict_classes(test_features)\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(np.reshape(np.array(test_data.iloc[t_idxs[i], :]), (28,28)))\n    plt.xlabel(results[t_idxs[i]])\nplt.show()","5e0541d2":"# submission\nsubmission = pd.DataFrame()\nsubmission['ImageId'] = pd.Series(range(1,28001))\nsubmission['Label'] = results\n\nsubmission.to_csv('cnn_submission.csv',index=False)","9473aa2d":"### Visualize Data","30d006b8":"### Data Ingestion"}}