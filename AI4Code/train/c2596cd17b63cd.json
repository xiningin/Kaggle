{"cell_type":{"8232e74d":"code","1e2206ec":"code","89c2ac49":"code","f1113103":"code","bd478132":"code","cdbb2337":"code","32ebb40a":"code","dbbc0a84":"code","adcecc47":"code","420820ec":"code","ea39d517":"code","c0df5e99":"code","009842dc":"code","66b0371d":"code","a7ae56fc":"code","2945efb5":"markdown","f75e93ad":"markdown","29d70bfd":"markdown","7091a5d5":"markdown","dfb7fda9":"markdown","2c22ff5b":"markdown","69667246":"markdown","0f4aa91b":"markdown","ec75a034":"markdown","eaa24366":"markdown","ece416b2":"markdown","9cf214f8":"markdown","07537fcc":"markdown","33c91c65":"markdown","6f9a2bdd":"markdown"},"source":{"8232e74d":"import numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport requests\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom matplotlib.pyplot import figure\n\nimg=mpimg.imread('\/kaggle\/input\/skyrim\/skyrimtable.bmp')\nfigure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n\nimgplot = plt.imshow(img)","1e2206ec":"page = requests.get(\"https:\/\/elderscrolls.fandom.com\/wiki\/Races_(Skyrim)\").text\nsoup = BeautifulSoup(page, 'html.parser')","89c2ac49":"img=mpimg.imread('\/kaggle\/input\/skyrim\/skyrimrightclick.bmp')\nfigure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n\nimgplot = plt.imshow(img)","f1113103":"img=mpimg.imread('\/kaggle\/input\/skyrim\/skyrimhtmltable.bmp')\nfigure(num=None, figsize=(16, 12), dpi=80, facecolor='w', edgecolor='k')\n\nimgplot = plt.imshow(img)","bd478132":"skills_table = soup.find_all('table')[0]","cdbb2337":"skills_table.find_all('tr')[0:3]","32ebb40a":"races_row = skills_table.find_all('tr')[0]\nraces_row","dbbc0a84":"races_row.text","adcecc47":"races = races_row.text.split('\\n')\nraces","420820ec":"col = races[1][0:4]\ncol","ea39d517":"races = races[2:-1]\nraces","c0df5e99":"dict2 = {}\ndict2[col] = races\ndict2","009842dc":"for i in range(1,19):\n    skill = skills_table.find_all('tr')[i].text.split('\\n')\n    col = skill[1]\n    skill = skill[2:-1]\n    dict2[col] = skill","66b0371d":"skyrimstats = pd.DataFrame(dict2)\nskyrimstats","a7ae56fc":"skyrimstats.to_csv(\"skyrimstats.csv\")","2945efb5":"We're looking for the rows of this table, so we'll find all the rows in our table.","f75e93ad":"So as expected, we're looking for a table. It seems to be the first table on the page so we'll choose that one\n\n***\n# Identifying the Layout of the Data\n\nNow we know what we're looking for, let's select it","29d70bfd":"This is all one string, which is no good to us, we should split it up to get each race","7091a5d5":"Next we want to take out the name of our column (Race)","dfb7fda9":"Next step is to right-clicking a part of our table and hitting 'inspect'. This will show us the html of the page and we can figure out what we're looking for","2c22ff5b":"Hope you enjoyed!","69667246":"Pandas can turn our dictionary directly into a dataframe","0f4aa91b":"# A Beginner's Guide to Creating Datasets from Wikis\n\nIn an effort to increase the amount of interesting datasets that are uploaded to this site, I thought I'd give a basic example of taking a dataset from a wikipage and uploading it. I'll use a small, non-interesting dataset as an introduction; the [base stats of Skyrim races](https:\/\/elderscrolls.fandom.com\/wiki\/Races_(Skyrim)). I'll use the 'BeautifulSoup' package but there are many alternative ways of doing this.","ec75a034":"Let's focus on the first row, our choices of race","eaa24366":"# Setup\n\nFirst we need to take the actual webpage and turn it into a html file that we can search through. This will work for most wiki webpages, from my experience","ece416b2":"Now we've figured out how to take our data from the table, we can work on turning it into a useable dataset\n\n***\n# Creating the Dataset\n\nThe easiest way to do this is using a dictionary (hashmap) for each of our columns. The keys will be our column names and the values will be our entries. This will make it very easy for pandas to make the dataframe later on","9cf214f8":"This will be the first column in our dataframe, so we want to take the text values from each","07537fcc":"And remove the unnecessary entries","33c91c65":"Now all we have to do is apply this to the rest of the rows in the table","6f9a2bdd":"And there we go! Easy transition from wiki table to useable dataset. Pandas will also let us cast it to a csv"}}