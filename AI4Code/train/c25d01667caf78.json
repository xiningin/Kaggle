{"cell_type":{"0c879925":"code","5603a34c":"code","88d89bb5":"code","bd278d16":"code","7e12e548":"code","2ab3066a":"code","0c4a75cb":"code","9e4d2893":"code","b5517adb":"code","a9fb54cc":"code","fb9cb9c3":"code","19b8d1f6":"code","0f04ca80":"code","67ee8cc1":"code","c75fcdc1":"code","60ea71f8":"code","c1a86dbe":"code","f5fac58a":"code","270707ad":"code","e32ea243":"code","f30e32d0":"code","3af7760e":"code","4a626b8b":"code","c362603a":"markdown","111def86":"markdown"},"source":{"0c879925":"import os\nimport cv2\nimport numpy as np\nfrom collections import defaultdict\n\nimport scikitplot\nimport seaborn as sns\nfrom matplotlib import pyplot\n\nimport tensorflow as tf\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling3D, GlobalMaxPool3D\nfrom tensorflow.keras.layers import TimeDistributed, LSTM, Bidirectional, ConvLSTM2D\nfrom tensorflow.keras.layers import Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n\nfrom keras.utils import np_utils\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","5603a34c":"INPUT_PATH = \"..\/input\/ck48-5-emotions\/CK+48\/\"\n\nfor dir_ in os.listdir(INPUT_PATH):\n    count = 0\n    for f in os.listdir(INPUT_PATH + dir_ + \"\/\"):\n        count += 1\n    print(f\"{dir_} has {count} number of images\")","88d89bb5":"TOP_EMOTIONS = [\"happy\", \"surprise\", \"anger\", \"sadness\", \"fear\"]","bd278d16":"INPUT_PATH = \"..\/input\/ck48-5-emotions\/CK+48\/\"\n\ndata = defaultdict(str)\nfor dir_ in os.listdir(INPUT_PATH):\n    if dir_ in TOP_EMOTIONS:\n        data[dir_] = defaultdict(list)\n        for f in os.listdir(INPUT_PATH + dir_ + \"\/\"):\n            sub = f.split(\"_\")[0]\n            data[dir_][sub].append(f)\n\n# data","7e12e548":"def preprocess_list(x):\n    return int((x.split(\"_\")[2]).split(\".\")[0])\n\ndef preprocess_dict(x):\n    res = list(np.argsort(list(map(preprocess_list, x))))\n    return [x[i] for i in res]\n\ndef img2array(x,path):\n    arr = np.empty(shape=(3,48,48))\n    for i,f in enumerate(x):\n        img = cv2.imread(path+f, 0)\n        arr[i] = img\n    return arr","2ab3066a":"for emotion in data:\n    data[emotion] = dict((k, preprocess_dict(v)) for k, v in data[emotion].items())\n    data[emotion] = dict((k, img2array(v, path=INPUT_PATH + emotion + \"\/\")) for k, v in data[emotion].items())\n\n# data","0c4a75cb":"for k,v in data.items():\n    print(f\"{k} has {len(v)} samples\")","9e4d2893":"surprise = np.stack(data[\"surprise\"].values(), axis=0)\nsurprise = surprise.reshape(*surprise.shape,1)\n\nhappy = np.stack(data[\"happy\"].values(), axis=0)\nhappy = happy.reshape(*happy.shape,1)\n\nanger = np.stack(data[\"anger\"].values(), axis=0)\nanger = anger.reshape(*anger.shape,1)\n\nsadness = np.stack(data[\"sadness\"].values(), axis=0)\nsadness = sadness.reshape(*sadness.shape,1)\n\nfear = np.stack(data[\"fear\"].values(), axis=0)\nfear = fear.reshape(*fear.shape,1)\n\nX = np.concatenate((surprise, happy, anger, sadness, fear))\ny = np.concatenate((np.array([0]*83), np.array([1]*69), np.array([2]*45), np.array([3]*28), np.array([4]*25)))\ny = np_utils.to_categorical(y)\n\nX.shape, y.shape","b5517adb":"X1 = np.concatenate((surprise, happy, anger, sadness, fear,surprise, happy, anger, sadness, fear,surprise, happy, anger, sadness, fear))\ny1 = np.concatenate((np.array([0]*83), np.array([1]*69), np.array([2]*45), np.array([3]*28), np.array([4]*25),np.array([0]*83), np.array([1]*69), np.array([2]*45), np.array([3]*28), np.array([4]*25),np.array([0]*83), np.array([1]*69), np.array([2]*45), np.array([3]*28), np.array([4]*25)))\ny1 = np_utils.to_categorical(y1)","a9fb54cc":"X1.shape, y1.shape","fb9cb9c3":"label_emotion_mapper = {0:\"surprise\", 1:\"happy\", 2:\"anger\", 3:\"sadness\", 4:\"fear\"}","19b8d1f6":"X_train, X_valid, y_train, y_valid = train_test_split(X1, y1, train_size=0.7, stratify=y1, shuffle=True, random_state=42)\nX_train.shape, X_valid.shape","0f04ca80":"y_train.shape,y_valid.shape","67ee8cc1":"np.random.seed(42)\nsurprise_idx = np.random.choice(np.where(y_train[:, 0]==1)[0], size=1)\nhappy_idx = np.random.choice(np.where(y_train[:, 1]==1)[0], size=1)\nanger_idx = np.random.choice(np.where(y_train[:, 2]==1)[0], size=1)\nsad_idx = np.random.choice(np.where(y_train[:, 3]==1)[0], size=1)\nfear_idx = np.random.choice(np.where(y_train[:, 4]==1)[0], size=1)\n\nfig = pyplot.figure(1, (6,13))\n\ni = 0\nfor name, idx in zip(label_emotion_mapper.values(), [surprise_idx, happy_idx, anger_idx, sad_idx, fear_idx]):\n    for j in range(3):\n        i += 1\n        ax = pyplot.subplot(5,3,i)\n        sample_img = X_train[idx][0,j,:,:,0]\n        ax.imshow(sample_img, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(name)","c75fcdc1":"# data normalization\nX_train = X_train \/ 255.\nX_valid = X_valid \/ 255.","60ea71f8":"def build_convlstm(input_shape, num_class, show_summary=True):\n    net = Sequential(name='ConvLSTM2D')\n\n    net.add(\n        ConvLSTM2D(\n            filters=64,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_1'))\n    net.add(\n        ConvLSTM2D(\n            filters=64,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_2'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_2'))\n\n    net.add(\n        MaxPooling3D(\n            pool_size=(1, 2, 2),\n            padding='same',\n            name='maxpool3d_1'\n        )\n    )\n    net.add(Dropout(0.3, name='dropout_1'))\n\n    net.add(\n        ConvLSTM2D(\n            filters=128,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_3'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_3'))\n    net.add(\n        ConvLSTM2D(\n            filters=128,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_4'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_4'))\n\n    net.add(\n        MaxPooling3D(\n            pool_size=(1, 2, 2),\n            padding='same',\n            name='maxpool3d_2'\n        )\n    )\n    net.add(Dropout(0.3, name='dropout_2'))\n\n    net.add(\n        ConvLSTM2D(\n            filters=256,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_5'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_5'))\n    net.add(\n        ConvLSTM2D(\n            filters=256,\n            kernel_size=(3,3),\n            input_shape=input_shape,\n            return_sequences=True,\n            recurrent_activation='hard_sigmoid',\n            activation='tanh',\n            padding='same',\n            kernel_initializer='glorot_uniform',\n            name='convlstm2d_6'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_6'))\n\n    net.add(\n        MaxPooling3D(\n            pool_size=(1, 2, 2),\n            padding='same',\n            name='maxpool3d_3'\n        )\n    )\n    net.add(Dropout(0.3, name='dropout_3'))\n    \n    net.add(TimeDistributed(Flatten(name=\"flatten\")))\n    \n    net.add(\n        TimeDistributed(\n            Dense(\n                64,\n                activation='elu',\n                kernel_initializer='he_normal',\n                name='dense_1'\n            )\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_7'))\n    net.add(Dropout(.6, name=\"dropout_4\"))\n\n    net.add(\n        TimeDistributed(\n            Dense(\n                num_class,\n                activation='softmax',\n                name='out_layer'\n            )\n        )\n    )\n\n    if show_summary:\n        net.summary()\n\n    return net","c1a86dbe":"INPUT_SHAPE = (3, 48, 48, 1)\noptim = optimizers.Adam(0.001)\n\nmodel = build_convlstm(INPUT_SHAPE, num_class=5)\nmodel.compile(\n        loss='categorical_crossentropy',\n        optimizer=optim,\n        metrics=['accuracy']\n)","f5fac58a":"early_stopping = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.00005,\n    patience=12,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.7,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n#     early_stopping,\n    lr_scheduler,\n]\n\nbatch_size = 32\nepochs = 30","270707ad":"y_train_ = np.empty((y_train.shape[0], 3, 5))\nfor i in range(y_train.shape[0]):\n    y_train_[i] = np.tile(y_train[i], (3,1))\n    \ny_valid_ = np.empty((y_valid.shape[0], 3, 5))\nfor i in range(y_valid.shape[0]):\n    y_valid_[i] = np.tile(y_valid[i], (3,1))","e32ea243":" np.empty((y_train.shape[0], 3, 5))","f30e32d0":"y_train_.shape, y_valid_.shape","3af7760e":"history = model.fit(\n    x=X_train,\n    y=y_train_,\n    validation_data=(X_valid, y_valid_),\n    batch_size=batch_size,\n    epochs=60,\n    callbacks=callbacks,\n    use_multiprocessing=True\n)","4a626b8b":"sns.set()\nfig = pyplot.figure(0, (12, 4))\n\nax = pyplot.subplot(1, 2, 1)\nsns.lineplot(history.epoch, history.history['accuracy'], label='train')\nsns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\npyplot.title('Accuracy')\npyplot.tight_layout()\n\nax = pyplot.subplot(1, 2, 2)\nsns.lineplot(history.epoch, history.history['loss'], label='train')\nsns.lineplot(history.epoch, history.history['val_loss'], label='valid')\npyplot.title('Loss')\npyplot.tight_layout()\n\npyplot.savefig('epoch_history.png')\npyplot.show()","c362603a":"### Data Preprocessing\n\nI first make the data compatible for the model.","111def86":"`sadness` and `fear` has very low number of images as compared to other classes"}}