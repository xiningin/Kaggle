{"cell_type":{"02604852":"code","dd27578d":"code","2738c4d9":"code","a0826777":"code","204e3388":"code","c0ba488a":"code","1bdd8c3f":"code","7a8ef793":"code","8ba3d2d8":"code","1e4d4a91":"code","9902a54f":"code","93678077":"code","218a6540":"code","cfff7843":"code","56376eac":"code","8c298639":"code","60ab0bae":"code","debd8615":"code","d802bc1a":"code","f1f2bfec":"code","e10a5116":"code","cf8bcd30":"code","fc95d9f0":"markdown","20ca8929":"markdown","db6666f0":"markdown","4590f9af":"markdown","90be7236":"markdown","02fb089a":"markdown"},"source":{"02604852":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport csv\nfrom sklearn.metrics import accuracy_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/\"))\n# Any results you write to the current directory are saved as output.","dd27578d":"test_data = pd.read_csv('..\/input\/test.csv')\ntrain_data = pd.read_csv('..\/input\/train.csv')","2738c4d9":"#Encode gender\nle = preprocessing.LabelEncoder()\nle.fit(train_data.Sex)\ntrain_data.Sex = le.transform(train_data.Sex)\ntest_data.Sex = le.transform(test_data.Sex)","a0826777":"a = test_data.Fare.fillna(test_data.Fare.mean())\ntest_data.Fare =a","204e3388":"#Predict Age\nlinreg = LinearRegression()\ndata = train_data[['Survived','Pclass','Sex','SibSp','Parch','Fare','Age']]\ndata2 = test_data[['Pclass','Sex','SibSp','Parch','Fare','Age']]","c0ba488a":"x_train = data[data['Age'].notnull()].drop(columns='Age')\ny_train = data[data['Age'].notnull()]['Age']\nx_test = data[data['Age'].isnull()].drop(columns='Age')\ny_test = data[data['Age'].isnull()]['Age']\n\nx_t_train = data2[data2['Age'].notnull()].drop(columns='Age')\ny_t_train = data2[data2['Age'].notnull()]['Age']\nx_t_test = data2[data2['Age'].isnull()].drop(columns='Age')\ny_t_test = data2[data2['Age'].isnull()]['Age']","1bdd8c3f":"linreg = LinearRegression()\nlinreg.fit(x_train,y_train)\npredicted = linreg.predict(x_test)\ntrain_data.Age[train_data.Age.isnull()] = predicted\n\n\nlin= LinearRegression()\nlin.fit(x_t_train,y_t_train)\npredicted = lin.predict(x_t_test)\ntest_data.Age[test_data.Age.isnull()] = predicted","7a8ef793":"Y1 = train_data.Survived\nX1 = train_data.drop(columns=['Survived','PassengerId','Name','Ticket','Embarked','Cabin'],axis = 1)","8ba3d2d8":"k_range = list(range(1, 31))\nweight_options = ['uniform','distance']\nparam_grid = dict(n_neighbors=k_range, weights=weight_options)","1e4d4a91":"grid = GridSearchCV(KNeighborsClassifier(),param_grid,cv=10,scoring = \"accuracy\",return_train_score=False)\ngrid.fit(X1,Y1)","9902a54f":"pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']][:3]","93678077":"print(grid.best_score_)\nprint(grid.best_params_)","218a6540":"penalty_options = ['l2']\nparam_grid = dict(penalty =penalty_options)","cfff7843":"grid = GridSearchCV(LogisticRegression(),param_grid, cv=10,scoring = \"accuracy\",return_train_score=False)\ngrid.fit(X1,Y1)","56376eac":"pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]","8c298639":"clf = tree.DecisionTreeClassifier()\nparam_grid={'min_samples_split' : range(10,500,20),'max_depth': range(1,20,2)}","60ab0bae":"grid = GridSearchCV(clf,param_grid,cv=10,scoring = \"accuracy\",return_train_score=False)\ngrid.fit(X1,Y1)","debd8615":"print(grid.best_score_)\nprint(grid.best_params_)","d802bc1a":"clf = tree.DecisionTreeClassifier(max_depth = 5, min_samples_split= 30)\nclf = clf.fit(X1,Y1)\npred_Y1 = clf.predict(X1)\naccuracy_score = accuracy_score(Y1, pred_Y1)\naccuracy_score","f1f2bfec":"X_test = test_data.drop(columns=['PassengerId','Name','Ticket','Embarked','Cabin'],axis = 1)\nresults = clf.predict(X_test)","e10a5116":"results","cf8bcd30":"lines = [['PassengerId', 'Survived']]\nfor i,j in enumerate(results):\n    lines.append([i,j])\n    \nwith open('accuracy0.8552.csv','w') as writeFile:\n    writer = csv.writer(writeFile)\n    writer.writerows(lines)\n\nwriteFile.close()","fc95d9f0":"**Logistic Regression**","20ca8929":"**KNN**","db6666f0":"**Start using Decision Tree to solve the problem**","4590f9af":"**Decision Tree**","90be7236":"**since the score of Decision Tree is the highest(0.826) vs. LogisticRegression(0.801) vs. knn(0.745), we use Decision Tree**","02fb089a":"**Get the Accuracy Score**"}}