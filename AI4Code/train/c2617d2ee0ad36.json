{"cell_type":{"bdfd5ab9":"code","6c520ef0":"code","4a99cc96":"code","92d65b1f":"code","372cc2e0":"code","9dbe7441":"code","22f71463":"code","2f4fe6f6":"code","9f30de8a":"code","0ed0e47e":"code","cbdf603d":"code","b594f906":"code","6f187b00":"code","bdc60a7d":"code","b7379ab3":"code","f9c62bdb":"code","4cb43cf0":"code","6d8aae00":"code","3b94fcee":"code","06b718e3":"code","bbba57e9":"code","23e56bb0":"code","57523243":"code","3c967d4a":"code","c98d45f6":"code","b0de2a5a":"code","6df34cca":"code","d220fe35":"code","1a115781":"code","6cd2856e":"code","6bb029e7":"code","c89a1025":"code","2885bb21":"code","c9528461":"code","bf21fe45":"code","5247eb4e":"code","ff14c0c5":"code","a7371491":"code","039e6ac7":"code","80c48226":"code","817a1ba3":"code","7721e6bf":"code","ef278142":"code","4377f4d0":"code","399eca18":"code","9e7a2a79":"code","72cb6be2":"code","7136a939":"code","42382f37":"code","bc981852":"code","45a44ad8":"code","e798605d":"code","41f71357":"code","efb9af2b":"code","c1ba9c3f":"code","4ca19d8e":"code","b518a22a":"code","52acf0f2":"code","8cac0665":"code","347a5890":"code","02cced56":"code","070b7ca2":"code","66427048":"code","e72219db":"code","fc45d648":"code","9205ef3b":"code","d1a54abe":"code","bacddb61":"code","22283b7f":"code","95e85e1a":"code","bc07c63c":"code","1b71ac6b":"code","987a4e04":"code","cb7a0d6d":"code","3dbe0458":"code","ba8e61ee":"code","8fcc55e5":"code","47ef57db":"code","c91b8100":"code","e1b06fdb":"code","80bbad8e":"code","d73181a1":"code","2ee88164":"code","4216da78":"code","5e00b384":"code","e37d2b81":"code","47133d7f":"code","3a16e5c1":"code","c4886221":"code","045c43d4":"code","d88a3063":"code","102006a0":"code","62013307":"code","142d474a":"code","05571e5d":"code","8b4cf564":"code","7556c4e6":"code","7a558c48":"code","34c2dc14":"code","a341915b":"code","5daf19c4":"code","8c3d9a72":"code","8638fdc2":"code","df07f943":"code","87cd784f":"code","25530f28":"code","9d57de7d":"code","f0f94f0f":"code","f7233ce8":"code","2c9864f4":"code","eb56ffe7":"code","f5c3a700":"code","6edff6ef":"code","fc1e5b4e":"code","64da408d":"code","d708cc60":"code","82eda6d8":"code","0dfd48e4":"code","d7fb4452":"code","d1e37a29":"code","1abf065e":"code","f01b4148":"code","5364c22a":"code","558262e4":"code","1928dd18":"code","8bad8998":"code","bccb9517":"code","8f6e960e":"code","e8611e03":"code","c6d540a5":"code","461a16d3":"code","41a83dac":"code","f20775c7":"code","841aa6e9":"code","dd242fba":"code","7621e840":"code","f48cddd7":"code","22c4c1b2":"code","d22d15e1":"code","490acba7":"code","cab96eb7":"code","d0428b6c":"code","903abb31":"code","3b0844cd":"code","0171bce3":"code","518c8499":"code","0f4f84c3":"code","a5ea7000":"code","58c17301":"markdown","68f69f7d":"markdown","2e1fae2a":"markdown","4cc89dde":"markdown","001d7fbd":"markdown","cce0f9da":"markdown","89f19880":"markdown","3db40c3c":"markdown","4fb45330":"markdown","889d4fd9":"markdown","4490208d":"markdown","e6fc57e1":"markdown","319fb329":"markdown","6bd20da9":"markdown","68ef7825":"markdown","62def4c0":"markdown","c1949f49":"markdown","1dd14e9e":"markdown","3fb3758e":"markdown","7b629dee":"markdown","21168ab2":"markdown","197c4229":"markdown","b41bb4ca":"markdown","26225b5b":"markdown","eff25391":"markdown","ec5a0a89":"markdown","98ca5c3c":"markdown","a6f5bdba":"markdown","3416f698":"markdown","2259c1ab":"markdown","7c8c10d2":"markdown","0928e8c7":"markdown","694b331f":"markdown","8e33baff":"markdown","c5462d68":"markdown","cbb3f0df":"markdown","206a5fff":"markdown","2ee280a5":"markdown","7e0780fc":"markdown","5d15e2c0":"markdown","94d33a06":"markdown","cbc318b9":"markdown","964733ca":"markdown","47e0442a":"markdown","b18e1619":"markdown","d9d7f6ae":"markdown","53ad38da":"markdown","da0b2920":"markdown","87fe4fd4":"markdown","7b127d70":"markdown","4c4d790a":"markdown","03c957ad":"markdown","06e7993f":"markdown","7f70cc54":"markdown","70a9ee2d":"markdown"},"source":{"bdfd5ab9":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","6c520ef0":"train_df=pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df=pd.read_csv('..\/input\/titanic\/test.csv')\ngender_sub_df=pd.read_csv('..\/input\/titanic\/gender_submission.csv')","4a99cc96":"train_df.head()","92d65b1f":"train_df.shape","372cc2e0":"for df in [train_df, test_df]:\n    df.set_index(\"PassengerId\", inplace=True)\ntrain_df.head()","9dbe7441":"train_df.info()","22f71463":"ntrain = train_df.shape[0]\nntest = test_df.shape[0]\ny_train = train_df['Survived'].values\nall_data = pd.concat((train_df, test_df), axis=0)\nall_data.drop(['Survived'], axis=1, inplace=True)","2f4fe6f6":"all_data.shape","9f30de8a":"numerical_features = all_data.select_dtypes([int, float]).columns\nnumerical_features","0ed0e47e":"categorical_features = all_data.select_dtypes([object]).columns\ncategorical_features","cbdf603d":"train_df.Survived.value_counts()","b594f906":"df2=train_df.copy(deep=True)\npie1=pd.DataFrame(df2['Survived'].replace(1.0,'Survived').replace(0.0,'Deceased').value_counts())\npie1.reset_index(inplace=True)\npie1.plot(kind='pie', title='Pie chart of survival rate',y = 'Survived', \n          autopct='%1.1f%%', shadow=False, labels=pie1['index'], legend = False, fontsize=14, figsize=(12,12))","6f187b00":"all_data.Sex.value_counts()","bdc60a7d":"df2=all_data.copy(deep=True)\npie1=pd.DataFrame(df2['Sex'].value_counts())\npie1.reset_index(inplace=True)\npie1.plot(kind='pie', title='Gender of passengers',y = 'Sex', \n          autopct='%1.1f%%', shadow=False, labels=pie1['index'], legend = False, fontsize=14, figsize=(12,12))","b7379ab3":"len(all_data.Name.unique())","f9c62bdb":"len(all_data.Ticket.unique())","4cb43cf0":"len(all_data.Cabin.unique())","6d8aae00":"all_data.Cabin.isna().sum()","3b94fcee":"#\"C = Cherbourg, Q = Queenstown, S = Southampton\".\ndf2=all_data.copy(deep=True)\npie1=pd.DataFrame(df2['Embarked'].replace('C', 'Cherbourg').replace('Q', 'Queenstown').replace('S', 'Southampton').value_counts())\npie1.reset_index(inplace=True)\npie1.plot(kind='pie', title='Pie Chart of Embarked feature',y = 'Embarked', \n          autopct='%1.1f%%', shadow=False, labels=pie1['index'], legend = False, fontsize=14, figsize=(12,12))","06b718e3":"['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']","bbba57e9":"all_data.Pclass.hist()","23e56bb0":"all_data.Pclass.value_counts()","57523243":"df2=all_data.copy(deep=True)\npie1=pd.DataFrame(df2['Pclass'].replace(1.0,'Upper').replace(2.0,'Middle').replace(3.0,'Lower').value_counts())\npie1.reset_index(inplace=True)\npie1.plot(kind='pie', title='Socio-economic status of passengers',y = 'Pclass', \n          autopct='%1.1f%%', shadow=False, labels=pie1['index'], legend = False, fontsize=14, figsize=(12,12))","3c967d4a":"all_data.Age.hist(bins=20)","c98d45f6":"all_data.Age.isna().sum()","b0de2a5a":"all_data.SibSp.value_counts()","6df34cca":"sns.countplot(all_data.SibSp)","d220fe35":"all_data.SibSp.isna().sum()","1a115781":"all_data.Parch.value_counts()","6cd2856e":"sns.countplot(all_data.Parch)","6bb029e7":"all_data.Parch.isna().sum()","c89a1025":"all_data.Fare.hist(bins=20)","2885bb21":"all_data.isna().sum()","c9528461":"all_data[all_data.Age.isna()]","bf21fe45":"all_data.Age.hist(bins=40)","5247eb4e":"print('Minimum age of passengers which contains in their names the word \"Mr.\": ',all_data[all_data.Name.str.contains(pat = 'Mr.')].Age.min())\nprint('Total amount of people whose name includes \"Mr.\": ', all_data[all_data.Name.str.contains(pat = 'Mr.')].shape[0])\nsns.distplot(all_data[all_data.Name.str.contains(pat = 'Mr.')].Age, bins=40)","ff14c0c5":"dfx=all_data[all_data.Name.str.contains(pat = 'Mr.')].Age\nsns.boxplot(dfx)","a7371491":"print('Minimum age of passengers which contains in their names the word Mrs.:',all_data[all_data.Name.str.contains(pat = 'Mrs.')].Age.min())\nprint('Total amount of people with word Mrs.: ', all_data[all_data.Name.str.contains(pat = 'Mrs.')].shape[0])\nall_data[all_data.Name.str.contains(pat = 'Mrs.')].Age.hist(bins=30)","039e6ac7":"all_data[all_data.Age.isna()].Name.str.contains(pat='Mr.').value_counts()","80c48226":"all_data[all_data.Name.str.contains(pat='Master')].Age.hist(bins=14)","817a1ba3":"all_data[(all_data.Name.str.contains(pat = 'Master')) & (all_data.Age.isna())] #.shape[0]  #~","7721e6bf":"all_data.loc[[66,160,177,710,1136,1231,1236,1309],'Age']","ef278142":"all_data.loc[66,'Age']=1.0\nall_data.loc[160,'Age']=10.0\nall_data.loc[177,'Age']=10.0\nall_data.loc[710,'Age']=3.0\nall_data.loc[1136,'Age']=4.0\nall_data.loc[1231,'Age']=14.0\nall_data.loc[1236,'Age']=10.0\nall_data.loc[1309,'Age']=4.0","4377f4d0":"all_data.Age.isna().sum()","399eca18":"#Let's define the model to impute ages for instances with name 'Master'\ndef name_master(df):\n  indexes=df[(df.Name.str.contains(pat = 'Master')) & (df.Age.isna())].index\n  for k in indexes:\n    df.iloc[k,4]=1.0\n  return df","9e7a2a79":"all_data[all_data.Name.str.contains(pat='Miss')].Age.hist(bins=10)","72cb6be2":"all_data[(all_data.Name.str.contains(pat = 'Miss')) & (all_data.Age.isna())]  #.shape[0]","7136a939":"ids=all_data[(all_data.Name.str.contains(pat = 'Miss')) & (all_data.Age.isna())].index","42382f37":"ids","bc981852":"from random import choices\n\npopulation =[6,13,19,25,32,38,44,50,57,63]\nweights=[0.158,0.075,0.219,0.212,0.151,0.096,0.034,0.027,0.007,0.021]","45a44ad8":"for i in ids:\n  all_data.loc[i,'Age']=choices(population, weights)[0]","e798605d":"all_data.Age.isna().sum()","41f71357":"#Let's define the function to impute ages for names including 'Miss'\ndef name_miss(df):\n  indexes=df[(df.Name.str.contains(pat = 'Miss')) & (df.Age.isna())].index\n  population =[6,13,19,25,32,38,44,50,57,63]\n  weights=[0.158,0.075,0.219,0.212,0.151,0.096,0.034,0.027,0.007,0.021]\n  for j in indexes:\n    df.iloc[j,4]=choices(population, weights)[0]\n  return df","efb9af2b":"all_data[(all_data.Name.str.contains(pat = 'Mr.')) | (all_data.Name.str.contains(pat = 'Mrs.'))].Age.hist(bins=20)","c1ba9c3f":"all_data[(all_data.Name.str.contains(pat = 'Mr.')) | (all_data.Name.str.contains(pat = 'Mrs.'))].Age.shape[0]","4ca19d8e":"idx=all_data[all_data['Age'].isna()].index","b518a22a":"idx","52acf0f2":"p=[14,17,21,24,28,31,35,38,42,45,49,52,56,59,63,66,70,73,77,80]\nw=[0.0078,0.0430,0.1328,0.1035,0.1367,0.1016,0.1172,0.0625,0.0801,0.0449,0.0449,0.0430,0.0176,0.0176,0.0195,0.0156,0.0000,0.0078,0.0020,0.0020]","8cac0665":"for j in idx:\n  all_data.loc[j,'Age']=choices(p, w)[0]","347a5890":"all_data[all_data['Age'].isna()]","02cced56":"#Let's define the function to impute ages for all instances left:\ndef name_left(df):\n  idx=df[df['Age'].isna()].index\n  pop=[14,17,21,24,28,31,35,38,42,45,49,52,56,59,63,66,70,73,77,80]\n  wei=[0.0078,0.0430,0.1328,0.1035,0.1367,0.1016,0.1172,0.0625,0.0801,0.0449,0.0449,0.0430,0.0176,0.0176,0.0195,0.0156,0.0000,0.0078,0.0020,0.0020]\n  for j in idx:\n    df.iloc[j,4]=choices(pop, wei)[0]\n  return df","070b7ca2":"all_data.Age.hist(bins=20)","66427048":"all_data.info()","e72219db":"all_data.describe()","fc45d648":"train_df[train_df.Age<1]","9205ef3b":"all_data.Fare.hist(bins=50)","d1a54abe":"sns.boxplot(data=all_data,x='Fare')","bacddb61":"all_data[all_data.Fare>200]","22283b7f":"all_data.Fare.describe()","95e85e1a":"all_data['Fare'].median()","bc07c63c":"all_data['Fare'].fillna(all_data['Fare'].median(),inplace=True)","1b71ac6b":"all_data.info()","987a4e04":"all_data.Embarked.value_counts(normalize=True)","cb7a0d6d":"all_data[all_data['Pclass']==1.0]['Embarked'].value_counts(normalize=True)","3dbe0458":"all_data[all_data['Embarked'].isna()]","ba8e61ee":"all_data.loc[62,'Embarked']='S'\nall_data.loc[830,'Embarked']='S'","8fcc55e5":"all_data.info()","47ef57db":"all_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)","c91b8100":"all_data.info()","e1b06fdb":"all_data['FamilySize'] = all_data['SibSp'] + all_data['Parch'] + 1","80bbad8e":"all_data['IsAlone'] = 1 #initialize to yes\/1 is alone\nall_data['IsAlone'].loc[all_data['FamilySize'] > 1] = 0 # now update to no\/0 if family size is greater than 1","d73181a1":"all_data.Sex=all_data.Sex.replace('male',1).replace('female',0)","2ee88164":"all_data.info()","4216da78":"numerical_features = all_data.select_dtypes([int, float]).columns\ncategorical_features = all_data.select_dtypes([object]).columns","5e00b384":"numerical_features","e37d2b81":"categorical_features","47133d7f":"from sklearn.preprocessing import PolynomialFeatures","3a16e5c1":"pol_feats=all_data[['Age', 'SibSp', 'Parch', 'Fare' , 'FamilySize']]    ","c4886221":"pf = PolynomialFeatures(degree=2, include_bias=False)\ndf_polynomial = pf.fit_transform(pol_feats)","045c43d4":"df_polynomial.shape","d88a3063":"all_data.index","102006a0":"target_feature_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(pol_feats.columns,p) for p in pf.powers_]]\noutput_df = pd.DataFrame(df_polynomial, columns = target_feature_names, index=all_data.index)","62013307":"output_df.head()","142d474a":"all_data.drop(['Age', 'SibSp', 'Parch', 'Fare' , 'FamilySize'], axis=1, inplace=True)","05571e5d":"all_data = pd.concat((all_data, output_df), axis=1)","8b4cf564":"all_data.head()","7556c4e6":"all_data.shape","7a558c48":"len(all_data.Pclass.unique()), len(all_data.Embarked.unique())","34c2dc14":"cat_cols=['Embarked', 'Pclass']","a341915b":"all_data=pd.get_dummies(all_data,columns=cat_cols,drop_first=True)\nall_data","5daf19c4":"training_df=all_data[:ntrain]\ntesting_df=all_data[ntrain:]","8c3d9a72":"training_df.shape, testing_df.shape","8638fdc2":"ntrain, ntest","df07f943":"label = train_df['Survived'].values","87cd784f":"train_df['Survived'].value_counts()","25530f28":"from sklearn.model_selection import train_test_split","9d57de7d":"X_train, X_val, label_train, label_val = train_test_split(training_df, label, test_size=0.25, random_state=42)","f0f94f0f":"X_train.shape, label_train.shape, X_val.shape, label_val.shape","f7233ce8":"from sklearn.preprocessing import StandardScaler\ns = StandardScaler()\n\nX_train_s = s.fit_transform(X_train)\nX_val_s = s.transform(X_val)","2c9864f4":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score","eb56ffe7":"import warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","f5c3a700":"from sklearn.ensemble import RandomForestClassifier\nRF = RandomForestClassifier(oob_score=True,\n                            random_state=42,\n                            warm_start=True,\n                            n_jobs=-1)\noob_list = list()\nfor n_trees in [15, 20, 30, 40, 50, 80, 100, 120, 150, 180, 200, 250, 300, 400]:\n    RF.set_params(n_estimators=n_trees)\n    RF.fit(X_train_s, label_train)\n    oob_error = 1 - RF.oob_score_\n    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n\nrf_oob_df = pd.concat(oob_list, axis=1).T.set_index('n_trees')\nrf_oob_df","6edff6ef":"sns.set_context('talk')\nsns.set_style('white')\n\nax = rf_oob_df.plot(legend=False, marker='o', figsize=(14, 7), linewidth=5)\nax.set(ylabel='out-of-bag error');","fc1e5b4e":"RF_150 = RandomForestClassifier(n_estimators=150\n          ,oob_score=True \n          ,random_state=42\n          ,n_jobs=-1)\n\nRF_150.fit(X_train_s, label_train)\noob_error150 = 1 - RF_150.oob_score_\noob_error150","64da408d":"y_pred_rf=RF_150.predict(X_val_s)","d708cc60":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_pred_rf,label_val))","82eda6d8":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_pred_rf,label_val), display_labels=RF_150.classes_)\ndisp.plot(cmap='Blues')","0dfd48e4":"testing_df.index","d7fb4452":"prediction_rf=RF_150.predict(s.transform(testing_df))","d1e37a29":"len(prediction_rf)","1abf065e":"actual=gender_sub_df","f01b4148":"actual['Survived']","5364c22a":"print(classification_report(actual['Survived'],prediction_rf))","558262e4":"disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(actual['Survived'],prediction_rf), display_labels=RF_150.classes_)\ndisp.plot(cmap='Blues')","1928dd18":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nsvm_model=SVC(kernel='rbf', probability=True)\ntuned_parameters = {'gamma': [0.005,0.01,0.05,0.1,1],'C':[0.1,1,5,10]}\n\nmodel_svm = GridSearchCV(svm_model, tuned_parameters,cv=4,scoring='accuracy')\nmodel_svm.fit(X_train_s, label_train)","8bad8998":"print(model_svm.best_estimator_)","bccb9517":"svc= SVC(kernel='rbf',C=10,gamma=0.01,probability=True)\nsvc.fit(X_train_s, label_train)","8f6e960e":"y_pred_svm=svc.predict(X_val_s)","e8611e03":"print(classification_report(label_val,y_pred_svm))","c6d540a5":"disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(label_val,y_pred_svm), display_labels=svc.classes_)\ndisp.plot(cmap='Blues')","461a16d3":"prediction_svm=svc.predict(s.transform(testing_df))","41a83dac":"len(prediction_svm)","f20775c7":"print(classification_report(actual['Survived'],prediction_svm))","841aa6e9":"disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(actual['Survived'],prediction_svm), display_labels=svc.classes_)\ndisp.plot(cmap='Blues')","dd242fba":"!pip install catboost","7621e840":"from catboost import Pool, CatBoostClassifier","f48cddd7":"cat_model = CatBoostClassifier(iterations=300,\n                           learning_rate=0.001,\n                           random_seed=42,\n                           depth=3)\n\ncat_model.fit(X_train_s, label_train, \n              cat_features=None, \n              eval_set=(X_val_s, label_val), \n              verbose=False)","22c4c1b2":"cat_prediction=cat_model.predict(X_val_s)","d22d15e1":"cat_prediction","490acba7":"print(classification_report(label_val,cat_prediction))","cab96eb7":"pred_cat=cat_model.predict(s.transform(testing_df))","d0428b6c":"len(pred_cat)","903abb31":"print(classification_report(actual['Survived'],pred_cat))","3b0844cd":"submission = pd.DataFrame({\n        \"PassengerId\": testing_df.index,\n        \"Survived\": pred_cat\n    })\n\nsubmission.set_index('PassengerId',inplace=True)\n#submission.to_csv(\"testing4.csv\")","0171bce3":"submission.head()","518c8499":"disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(actual['Survived'],pred_cat), display_labels=cat_model.classes_)\ndisp.plot(cmap='Blues')","0f4f84c3":"from sklearn.preprocessing import label_binarize\n\nmetrics = []\nmodels = ['Random Forest', 'Support Vector Classifier', 'Catboost']\npredictions=[prediction_rf, prediction_svm, pred_cat]\n\nfor lab,i in zip(models, predictions):\n    precision, recall, fscore, _ = score(actual['Survived'], i, average='weighted')\n    accuracy = accuracy_score(actual['Survived'], i)\n    auc = roc_auc_score(label_binarize(actual['Survived'], classes=[0,1]),\n                        label_binarize(i, classes=[0,1]),\n                        average='weighted')\n    metrics.append(pd.Series({'precision':precision, 'recall':recall,\n                              'fscore':fscore, 'accuracy':accuracy,\n                              'auc':auc}, name=lab))\n    \nmetrics = pd.concat(metrics, axis=1)","a5ea7000":"metrics","58c17301":"Now, let's look at the distribution of the ticket fare in a histogram:","68f69f7d":"As feature engineering as been finished we will split the data into corresponding training and testing instances:","2e1fae2a":"I will impute S for having the highest proportion:","4cc89dde":"I would like to know any feedback in order to increase the validation accuracy in the three models.\n\nIf you liked this notebook I would appreciate so much your upvote if you want to see more projects\/tutorials like this one. I encourage you to see my projects portfolio, am sure you will love it.\n\nThank you!","001d7fbd":"Accuracy of 99% which is superlative and now we can say we have found the best model for the current project, let's save it as csv and then plot the confusion matrix.","cce0f9da":"We can see below that Name and Ticket feature are almost unique for each passenger, thus as a following step we will find out if they are worthy in the prediction:","89f19880":"We can see SibSp and Parch have quite similar distributions and are non-null features, later we will use these to create a new feature indicating the number of family members or family size.","3db40c3c":"## Catboost:","4fb45330":"Polynomial features from these 5 will generate 20 columns which will be added to the dataset.","889d4fd9":"Above we can see that only 4 features contain nan values, Age will be explored exhaustevely to impute proper values, the same for Fare and Embarked, whereas Cabin is extremely absent that I decide to drop it from the dataset. As I said early Name and Ticket are almost unique for each passenger and does not add significative information about the passenger to the model, therefore will be dropped, but after imputing values.","4490208d":"Features Pclass and Embarked will be one-hot encoded and omiting one class from each other to avoid creating one extra feature:","e6fc57e1":"The feature Cabin unfortunately has 77% of their instances as nan values which makes extremely hard to impute proper values, later we will decide use such feature or not.","319fb329":"The following models will be built and compared using their corresponding error measurements:\n\n- Random Forest with the best number of trees.\n- SVC with RBF kernel.\n- Catboost with best hyperparameters.\n\nBefore building the different models let's declare some error metrics in order to compare the performace of each one:The following models will be built and compared using their corresponding error measurements:\n\n","6bd20da9":"## Error metrics on testing dataset:","68ef7825":"Below I have declared by each age (population) their corresponding relative frequency (weights):","62def4c0":"Finally, we found that there are 50 instances which has this characteristic and therefore we will impute values according to the distribution above.","c1949f49":"Whereas for those whose name contains 'Miss', are distributed between 1 - 63 years old, which makes more complex to know what value to impute.","1dd14e9e":"Let's see the distribution of Embarked feature and how to impute the apropiate value to the missing instances:","3fb3758e":"Firstly, we are going to use GridSearchCV to find the right values for hyperparameters gamma and C, accuracy will be used as scoring.","7b629dee":"Numerical features:","21168ab2":"In our dataset there are 7 posible numerical values for SibSp feature and as it does not have null values we can continue.","197c4229":"Only 4 misclassifications using CatBoost out of 418. However, something extremely important to take into account is the validation accuracy because for such metric SVM outperformed Catboost, therefore SVM should have the best out-of-bag instances prediction, but in the current project we had the labels of testing dataset and only because of that we could know how our models worked on testing.","b41bb4ca":"As I have imputed for 8 instances the count of nan in this feature should reduce to 55:","26225b5b":"After concatenation we should have 24 features in total:","eff25391":"Time now to create more variables derived from existing ones:","ec5a0a89":"The function below creates a random value according population and weights and assign to the missing value in the dataset:","98ca5c3c":"The hyperparameters details in the CatBoostClassifier were found using several methods and produced the best performance for this model:","a6f5bdba":"Let's see and play a bit more with age column and the name of passenger to find a right method to impute values:","3416f698":"Therefore those 203 their age is distributed between 11 to 80 years old.\n\nLet's find out more about the other 60 instances.","2259c1ab":"Feature Exploration:","7c8c10d2":"## Support Vector Classifier:","0928e8c7":"We can see below that our label is binary, so we can use a categorical binary classifiers. ","694b331f":"As Age feature has null values we will have to explore and impute later.","8e33baff":"The following line is to keep the names of each feature in the polynomial:","c5462d68":"Those with name including word 'Master' are aged between 0 and 14 years old, having a peak in 1 year old.","cbb3f0df":"For those whose age is not available, how many of them are \"Mr.\":","206a5fff":"Above we can that see in our training dataset all babies aged less than 1 year old survived.\n\nLet's see again the distribution of Fare:","2ee280a5":"The next step is to create polynomial features with columns: Age, SibSp, Parch, Fare and FamilySize. Then one-hot encode the feature Embarked and Pclass.","7e0780fc":"As I said early I will drop columns Name, Ticket and Cabin:","5d15e2c0":"Outstanding 95% of accuracy in testing with only 21 misclassifications out of 418 which is quite well, but let's implement one last model and see if we can get an even better performance.","94d33a06":"Despite the fact that accuracy in validation set was lower than SVC we have to be objective and try to find the best model whose predictions are the most similar to the actual label of testing dataset, because of this let' see how this model predicts such instances:","cbc318b9":"Categorical features:\n\nLet's start exploring the gender of passengers:","964733ca":"## Random Forest Classifier:","47e0442a":"**Feature Engineering:**\n\nImputing values for Age feature:","b18e1619":"Above Id's 66 and 710 are brothers, same ticket, same fare and companied by their mom, they survived and as kids less than 4 years old have almost all of them survived I decided to impute values less than 4 for both.\nId 160 and 177 unfortunately their families didn't survived and I will impute the age 10 for having a low survival rate. Id 1136 two members of his family died and we don't know if he survived I will impute 4. Id 1231 is one of the strangest because he didn't traveled with family and if he is less than 14 how than can be possible?, I will impute 14. Id 1236 had a father who died and a brother of 12 years old, I will impute 10. Id 1309 his family survived, I will impute 4.\n","d9d7f6ae":"We can see around 70% of passengers boarded on Southampton. Also as these two passengers are class 1 we will see where people of class 1 embarked following:","53ad38da":"Until now the accuracy of the SVC is the best in validation set and now we will see how it predicted the label of instances in testing dataset:","da0b2920":"Clearly the there is a positive skew which means a huge amount of cheap tickets. ","87fe4fd4":"Scaling of features:","7b127d70":"Above we can see that such numerical features is distributed as a categorical ordinal feature, but it's not needed to change it as will work fine as it is.","4c4d790a":"After imputing by such distribution there should be 205 nan in Age feature:","03c957ad":"Now, that we have imputed values for 'Master' and 'Miss' we have to deal with 'Mr.' and 'Mrs.'","06e7993f":"I will impute Age values using the same method as just before, for this I have created 20 possible values and their weights, after this process should not exist any nan value in Age feature:","7f70cc54":"# Modeling:","70a9ee2d":"After train-test split both sets will be standardized:"}}