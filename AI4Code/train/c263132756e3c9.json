{"cell_type":{"50058824":"code","300f24f7":"code","23676fba":"code","91358a79":"code","ff648a02":"code","ba0063f4":"code","6d1c8f43":"code","6a30420c":"code","a1fb2b61":"code","a3d90184":"code","1cb6e481":"code","b6ad7169":"code","be44144b":"code","e8e55bd0":"code","283d5fea":"code","85b9cd3f":"code","d47ab374":"code","e4190974":"code","ad07d670":"code","ab627a56":"code","403fee2f":"code","b4c104c2":"code","b56a1401":"code","658d63ec":"code","f979243a":"code","19ebac49":"code","97d2353d":"code","f9fd0ab0":"code","ea10b6cc":"code","3f416388":"code","f45f2df0":"code","2e4d5ae6":"code","5323448f":"code","4b1c65e4":"code","c42c06d7":"code","db662e1a":"code","49f9eec4":"code","afa50b31":"code","d98d8fb2":"code","aa6c7a1d":"code","ae636c7b":"code","38ef2df1":"code","9bc559ab":"code","63e7941e":"code","410ba2f4":"code","deebbdb2":"code","c7e0a171":"code","caef323b":"code","c835b9fd":"code","91463279":"code","b8062e21":"code","16234365":"code","31d01cb8":"code","c9c65bea":"code","933da735":"code","b1bd7c1d":"code","e0f669f8":"code","8e013623":"code","94665dd0":"code","258f475d":"code","010f8b7a":"markdown"},"source":{"50058824":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","300f24f7":"resp_2021 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')\nresp_2020 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\nresp_2019 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv')\nresp_2018 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2018\/multipleChoiceResponses.csv')\nresp_2017 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2017\/multipleChoiceResponses.csv', encoding='ISO-8859-1')","23676fba":"schema_2017 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2017\/schema.csv', encoding='ISO-8859-1')\nschema_2017","91358a79":"schema_2017[schema_2017['Question'].str.contains('hardware')]","ff648a02":"gpu_res = dict()\ngpu_res['Years'] = []\ngpu_res['Accelerator Usage By Users'] = []","ba0063f4":"searchfor = ['GPU', 'TPU']\n\ngpu_2017 = resp_2017[resp_2017['WorkHardwareSelect'].str.contains('|'.join(searchfor)).fillna(value=False)].shape[0] # gpu at work users in 2017 \ngpu_total_2017 = sum(resp_2017['WorkHardwareSelect'].str.contains('GPU').value_counts()) #total number of people answering question at work\n\n\ngpu_2017 += resp_2017[resp_2017['HardwarePersonalProjectsSelect'].str.contains('|'.join(searchfor)).fillna(value=False)].shape[0] #added personal project gpu numbers\ngpu_total_2017 += sum(resp_2017['HardwarePersonalProjectsSelect'].str.contains('GPU').value_counts())\n\ngpu_res['Years'].append('2017')\ngpu_res['Accelerator Usage By Users'].append(gpu_2017 \/ gpu_total_2017)","6d1c8f43":"#2018\ub144\uc5d0 gpu data \uc874\uc7ac X ","6a30420c":"schema_2019 = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/questions_only.csv', encoding='ISO-8859-1').transpose() #\ub3cc\ub824\uc57c\uc9c0 \ub370\uc774\ud130\uac00 \ubcf4\uae30 \uc27d\uac8c \ub098\uc634 \uad81\uae08\ud558\uba74 transpose \uc5c6\uc774 \ud574\ubcf4\uba74 \ub428\nschema_2019[schema_2019[0].str.contains('hardware')] #Q21","a1fb2b61":"#\uac19\uc740 \uc0ac\ub78c\uc744 \ub450\ubc88 \uc138\uc9c0 \uc54a\uac8c \uc8fc\uc758 !! \n\ngpu_total_2019 = resp_2019['Q21_Part_1'].str.contains('CPUs').fillna(value = False) | \\\nresp_2019['Q21_Part_2'].str.contains('GPUs').fillna(value = False) | \\\nresp_2019['Q21_Part_3'].str.contains('TPUs').fillna(value = False) | \\\nresp_2019['Q21_Part_4'].str.contains('None').fillna(value = False) | \\\nresp_2019['Q21_Part_5'].str.contains('Other').fillna(value = False) #boolean indexing to get unique users\n\ngpu_total_2019 = gpu_total_2019.value_counts().to_frame().transpose()[True][0] - 5 #minus to account for question itself\n\ngpu_2019 = resp_2019['Q21_Part_2'].str.contains('GPUs').fillna(value = False) | \\\nresp_2019['Q21_Part_3'].str.contains('TPUs').fillna(value = False)\n\ngpu_2019 = gpu_2019.value_counts().to_frame().transpose()[True][0] - 2 #minus to account for question itself\n\n\ngpu_res['Years'].append('2019')\ngpu_res['Accelerator Usage By Users'].append(gpu_2019 \/ gpu_total_2019)","a3d90184":"#2020 ==> Q12\n\ngpu_total_2020 = resp_2020['Q12_Part_1'].str.contains('GPUs').fillna(value = False) | \\\nresp_2020['Q12_Part_2'].str.contains('TPUs').fillna(value = False) | \\\nresp_2020['Q12_Part_3'].str.contains('None').fillna(value = False) | \\\nresp_2020['Q12_OTHER'].str.contains('Other').fillna(value = False) \n\ngpu_total_2020 = gpu_total_2020.value_counts().to_frame().transpose()[True][0] - 4 #minus to account for question itself\n\ngpu_2020 = resp_2020['Q12_Part_1'].str.contains('GPUs').fillna(value = False) | \\\nresp_2020['Q12_Part_2'].str.contains('TPUs').fillna(value = False)\n\ngpu_2020 = gpu_2020.value_counts().to_frame().transpose()[True][0] - 2 #minus to account for question itself\n\ngpu_res['Years'].append('2020')\ngpu_res['Accelerator Usage By Users'].append(gpu_2020 \/ gpu_total_2020)","1cb6e481":"#2021 --> Q12\n\ngpu_total_2021 = resp_2021['Q12_Part_1'].str.contains('GPUs').fillna(value = False) | \\\nresp_2021['Q12_Part_2'].str.contains('TPUs').fillna(value = False) | \\\nresp_2021['Q12_Part_3'].str.contains('AWS Trainium Chips').fillna(value = False) | \\\nresp_2021['Q12_Part_4'].str.contains('AWS Inferentia Chips').fillna(value = False) | \\\nresp_2021['Q12_Part_5'].str.contains('None').fillna(value = False) | \\\nresp_2021['Q12_OTHER'].str.contains('Other').fillna(value = False)\n\ngpu_total_2021 = gpu_total_2021.value_counts().to_frame().transpose()[True][0] - 6 #minus to account for question itself\n\ngpu_2021 = resp_2021['Q12_Part_1'].str.contains('GPUs').fillna(value = False) | \\\nresp_2021['Q12_Part_2'].str.contains('TPUs').fillna(value = False) | \\\nresp_2021['Q12_Part_3'].str.contains('AWS Trainium Chips').fillna(value = False) | \\\nresp_2021['Q12_Part_4'].str.contains('AWS Inferentia Chips').fillna(value = False)\n\n#gpu_2021.value_counts()\n\ngpu_2021 = gpu_2021.value_counts().to_frame().transpose()[True][0] - 4 #minus to account for question itself\n\ngpu_res['Years'].append('2021')\ngpu_res['Accelerator Usage By Users'].append(gpu_2021 \/ gpu_total_2021)","b6ad7169":"gpu_res['Accelerator Usage By Users']","be44144b":"gpu_res['Style'] = ['Accelerator Usage By Users' for _ in range(4)]","e8e55bd0":"sns.lineplot(data=gpu_res, x='Years', y='Accelerator Usage By Users', style = 'Style', markers=True)\n#plt.plot(gpu_res['Accelerator Usage By Users'])","283d5fea":"#Which ML algos do you use on a regular basis\n\n#2021 Q17\n#2020 Q17\n#2019 Q24\n#2018 none\n#2017 WorkAlgorithmsSelect\n#interesting datapoint in 2017 --> chooseOne(\"MLMethodNextYearSelect\")\n#shows that 40% of users indicated they were interested in deep learning and 12% in Neural Nets\n#so did they learn those?\n\n#if there is plateau, does it mean that deep learning is difficult to use and may be too expensive and requires\n#too much data so they just use machine learning techniques when they can, because performance is extremely\n#important in real world applications, not just accuracy \n#like whats the point of using nn if xgboost does about the same thing but faster \n#also it may be that kaggle users usually find their niche in one area or another and just stick to that\n#particular niche and specialize in it, so they'd rather just get better at let's say image processing\n#and not attempt to try out RNNs or Transformers \n#maybe some techniques are just still in research stage and not easily applicable to real world yet\n#so as deep nns advance in multiple fronts they will become more and more popular","85b9cd3f":"responses_df_2021 = resp_2021\n\ndef count_then_return_percent_for_multiple_column_questions(dataframe,list_of_columns_for_a_single_question,dictionary_of_counts_for_a_single_question):\n    '''\n    A helper function to convert counts to percentages.\n    '''\n    df = dataframe\n    subset = list_of_columns_for_a_single_question\n    df = df[subset]\n    df = df.dropna(how='all')\n    total_count = len(df) \n    dictionary = dictionary_of_counts_for_a_single_question\n    for i in dictionary:\n        dictionary[i] = round(float(dictionary[i]*100\/total_count),1)\n    return dictionary\n\n\nq17_list_of_columns_2021 = ['Q17_Part_1',\n                       'Q17_Part_2',\n                       'Q17_Part_3',\n                       'Q17_Part_4',\n                       'Q17_Part_5',\n                       'Q17_Part_6',\n                       'Q17_Part_7',\n                       'Q17_Part_8',\n                       'Q17_Part_9',\n                       'Q17_Part_10',\n                       'Q17_Part_11',\n                       'Q17_OTHER']\n\nq17_dictionary_of_counts_2021 = {\n    'Linear or Logistic Regression' : (responses_df_2021['Q17_Part_1'].count()),\n    'Decision Trees or Random Forests': (responses_df_2021['Q17_Part_2'].count()),\n    'Gradient Boosting Machines (xgboost, lightgbm, etc)' : (responses_df_2021['Q17_Part_3'].count()),\n    'Dense Neural Networks (MLPs, etc)' : (responses_df_2021['Q17_Part_6'].count()),\n    'Convolutional Neural Networks' : (responses_df_2021['Q17_Part_7'].count()),\n    'Recurrent Neural Networks' : (responses_df_2021['Q17_Part_9'].count()),\n    'Transformer Networks (BERT, gpt-3, etc)' : (responses_df_2021['Q17_Part_10'].count()),\n}\n\n\n\nq17_dictionary_of_perc_2021 = count_then_return_percent_for_multiple_column_questions(responses_df_2021,\n                                                  q17_list_of_columns_2021,\n                                                  q17_dictionary_of_counts_2021)\n","d47ab374":"responses_df_2020 = resp_2020\n\nq17_list_of_columns_2020 = ['Q17_Part_1',\n                       'Q17_Part_2',\n                       'Q17_Part_3',\n                       'Q17_Part_4',\n                       'Q17_Part_5',\n                       'Q17_Part_6',\n                       'Q17_Part_7',\n                       'Q17_Part_8',\n                       'Q17_Part_9',\n                       'Q17_Part_10',\n                       'Q17_Part_11',\n                       'Q17_OTHER']\n\nq17_dictionary_of_counts_2020 = {\n    'Linear or Logistic Regression' : (responses_df_2020['Q17_Part_1'].count()),\n    'Decision Trees or Random Forests': (responses_df_2020['Q17_Part_2'].count()),\n    'Gradient Boosting Machines (xgboost, lightgbm, etc)' : (responses_df_2020['Q17_Part_3'].count()),\n    'Dense Neural Networks (MLPs, etc)' : (responses_df_2020['Q17_Part_6'].count()),\n    'Convolutional Neural Networks' : (responses_df_2020['Q17_Part_7'].count()),\n    'Recurrent Neural Networks' : (responses_df_2020['Q17_Part_9'].count()),\n    'Transformer Networks (BERT, gpt-3, etc)' : (responses_df_2020['Q17_Part_10'].count()),\n}\n\nq17_dictionary_of_perc_2020 = count_then_return_percent_for_multiple_column_questions(responses_df_2020,\n                                                  q17_list_of_columns_2020,\n                                                  q17_dictionary_of_counts_2020)","e4190974":"#q24 2019\n\nq24_list_of_columns_2019 = ['Q24_Part_1',\n                       'Q24_Part_2',\n                       'Q24_Part_3',\n                       'Q24_Part_4',\n                       'Q24_Part_5',\n                       'Q24_Part_6',\n                       'Q24_Part_7',\n                       'Q24_Part_8',\n                       'Q24_Part_9',\n                       'Q24_Part_10',\n                       'Q24_Part_11',\n                       'Q24_Part_12']\n\nq24_dictionary_of_counts_2019 = {\n    'Linear or Logistic Regression' : (resp_2019['Q24_Part_1'].count()),\n    'Decision Trees or Random Forests': (resp_2019['Q24_Part_2'].count()),\n    'Gradient Boosting Machines (xgboost, lightgbm, etc)' : (resp_2019['Q24_Part_3'].count()),\n    'Dense Neural Networks (MLPs, etc)' : (resp_2019['Q24_Part_6'].count()),\n    'Convolutional Neural Networks' : (resp_2019['Q24_Part_7'].count()),\n    'Recurrent Neural Networks' : (resp_2019['Q24_Part_9'].count()),\n    'Transformer Networks (BERT, gpt-3, etc)' : (resp_2019['Q24_Part_10'].count()),\n}\n\nq24_dictionary_of_perc_2019 = count_then_return_percent_for_multiple_column_questions(resp_2019,\n                                                  q24_list_of_columns_2019,\n                                                  q24_dictionary_of_counts_2019)","ad07d670":"#2017\n\nsearchfor = ['Decision Trees', 'Random Forests']\n\ndef count_2017_q_workalg(dictionary_of_counts_for_a_single_question):\n    '''\n    A helper function to convert counts to percentages.\n    '''\n    total_count = 7301 #number taken from 2017 kaggle survey analysis kernel by the pudding\n    dictionary = dictionary_of_counts_for_a_single_question\n    for i in dictionary:\n        dictionary[i] = round(float(dictionary[i]*100\/total_count),1)\n    return dictionary\n\nq_workalg_dictionary_of_counts_2017 = { \n\n    'Linear or Logistic Regression' : resp_2017['WorkAlgorithmsSelect'].str.contains('Regression\/Logistic Regression').value_counts().to_frame().transpose()[True][0],\n    'Decision Trees or Random Forests': resp_2017['WorkAlgorithmsSelect'].str.contains('|'.join(searchfor)).value_counts().to_frame().transpose()[True][0],\n    'Gradient Boosting Machines (xgboost, lightgbm, etc)' : resp_2017['WorkAlgorithmsSelect'].str.contains('Gradient Boosted Machines').value_counts().to_frame().transpose()[True][0],\n    'Dense Neural Networks (MLPs, etc)' : resp_2017['WorkAlgorithmsSelect'].str.contains('Neural Networks').value_counts().to_frame().transpose()[True][0],\n    'Convolutional Neural Networks' : resp_2017['WorkAlgorithmsSelect'].str.contains('CNNs').value_counts().to_frame().transpose()[True][0],\n    'Recurrent Neural Networks' : resp_2017['WorkAlgorithmsSelect'].str.contains('RNNs').value_counts().to_frame().transpose()[True][0],\n    'Transformer Networks (BERT, gpt-3, etc)' : 0\n\n}\n\nq24_dictionary_of_perc_2017 = count_2017_q_workalg(q_workalg_dictionary_of_counts_2017)","ab627a56":"q17_dictionary_of_perc_2021","403fee2f":"#scatterplot work\n\ndef algo_type_scatterplot(perc_dict, year):\n    df = pd.DataFrame(data = perc_dict, index = ['Percentage of Respondents']).transpose()\n    df['Year'] = year\n    df = df.reset_index()\n    df = df.rename(columns={'index':'Type of Algorithm'})\n    \n    return df\n    \n\nalgo_type_df = algo_type_scatterplot(q17_dictionary_of_perc_2021, 2021)\nalgo_type_df = algo_type_df.append(algo_type_scatterplot(q17_dictionary_of_perc_2020, 2020))\nalgo_type_df = algo_type_df.append(algo_type_scatterplot(q24_dictionary_of_perc_2019, 2019))\nalgo_type_df = algo_type_df.append(algo_type_scatterplot(q24_dictionary_of_perc_2017, 2017))\nalgo_type_df = algo_type_df.reset_index(drop=True)","b4c104c2":"a4_dims = (13, 10)\nalgo_fig, algo_ax = plt.subplots(figsize=a4_dims)\n\nsns.lineplot(data = algo_type_df,\n            ax = algo_ax,\n            x = 'Year',\n            y = 'Percentage of Respondents',\n            hue = 'Type of Algorithm',\n            style = 'Type of Algorithm',\n            markers = True,\n            dashes = False)\nalgo_ax.set_xticks(ticks = [2017, 2019, 2020, 2021])","b56a1401":"#cloud compute\n#popularity of cloud compute show that users who don't use any are decreasing\n#show that trend in money used for cloud is not changing much maybe since cloud is expensive","658d63ec":"#credits to kaggle's eda notebook\n\nresponses_df_2018 = resp_2018\nresponses_df_2019 = resp_2019\n\nq26a_dictionary_of_counts_2018 = {\n    'Amazon Web Services (AWS)' : (responses_df_2018['Q15_Part_2'].count()),\n    'Microsoft Azure': (responses_df_2018['Q15_Part_3'].count()),\n    'Google Cloud Platform (GCP)' : (responses_df_2018['Q15_Part_1'].count()),\n    'None' : (responses_df_2018['Q15_Part_6'].count()),\n}\n\nq26a_list_of_columns_2018 = ['Q15_Part_1',\n                        'Q15_Part_2',\n                        'Q15_Part_3',\n                        'Q15_Part_4',\n                        'Q15_Part_5',\n                        'Q15_Part_6',\n                        'Q15_Part_7']\n\nq26a_dictionary_of_counts_2019 = {\n    'Amazon Web Services (AWS)' : (responses_df_2019['Q29_Part_2'].count()),\n    'Microsoft Azure': (responses_df_2019['Q29_Part_3'].count()),\n    'Google Cloud Platform (GCP)' : (responses_df_2019['Q29_Part_1'].count()),\n    'None' : (responses_df_2019['Q29_Part_11'].count()),\n}\n\nq26a_list_of_columns_2019 = ['Q29_Part_1',\n                        'Q29_Part_2',\n                        'Q29_Part_3',\n                        'Q29_Part_4',\n                        'Q29_Part_5',\n                        'Q29_Part_6',\n                        'Q29_Part_7',\n                        'Q29_Part_8',\n                        'Q29_Part_9',\n                        'Q29_Part_10',\n                        'Q29_Part_11',\n                        'Q29_Part_12']\n\nq26a_dictionary_of_counts_2020 = {\n    'Amazon Web Services (AWS)' : (responses_df_2020['Q26_A_Part_1'].count()),\n    'Microsoft Azure': (responses_df_2020['Q26_A_Part_2'].count()),\n    'Google Cloud Platform (GCP)' : (responses_df_2020['Q26_A_Part_3'].count()),\n    'None' : (responses_df_2020['Q26_A_Part_11'].count()),\n}\n\nq26a_list_of_columns_2020 = ['Q26_A_Part_1',\n                        'Q26_A_Part_2',\n                        'Q26_A_Part_3',\n                        'Q26_A_Part_4',\n                        'Q26_A_Part_5',\n                        'Q26_A_Part_6',\n                        'Q26_A_Part_7',\n                        'Q26_A_Part_8',\n                        'Q26_A_Part_9',\n                        'Q26_A_Part_10',\n                        'Q26_A_Part_11',\n                        'Q26_A_OTHER']\n\nq27a_dictionary_of_counts_2021 = {\n    'Amazon Web Services (AWS)' : (responses_df_2021['Q27_A_Part_1'].count()),\n    'Microsoft Azure': (responses_df_2021['Q27_A_Part_2'].count()),\n    'Google Cloud Platform (GCP)' : (responses_df_2021['Q27_A_Part_3'].count()),\n    'None' : (responses_df_2021['Q27_A_Part_11'].count()),\n}\n\nq27a_list_of_columns_2021 = ['Q27_A_Part_1',\n                        'Q27_A_Part_2',\n                        'Q27_A_Part_3',\n                        'Q27_A_Part_4',\n                        'Q27_A_Part_5',\n                        'Q27_A_Part_6',\n                        'Q27_A_Part_7',\n                        'Q27_A_Part_8',\n                        'Q27_A_Part_9',\n                        'Q27_A_Part_10',\n                        'Q27_A_Part_11',\n                        'Q27_A_OTHER']\n\nq26a_dictionary_of_perc_2018 = count_then_return_percent_for_multiple_column_questions(responses_df_2018,\n                                                  q26a_list_of_columns_2018,\n                                                  q26a_dictionary_of_counts_2018)\nq26a_dictionary_of_perc_2019 = count_then_return_percent_for_multiple_column_questions(responses_df_2019,\n                                                  q26a_list_of_columns_2019,\n                                                  q26a_dictionary_of_counts_2019)\nq26a_dictionary_of_perc_2020 = count_then_return_percent_for_multiple_column_questions(responses_df_2020,\n                                                  q26a_list_of_columns_2020,\n                                                  q26a_dictionary_of_counts_2020)\nq27a_dictionary_of_perc_2021 = count_then_return_percent_for_multiple_column_questions(responses_df_2021,\n                                                  q27a_list_of_columns_2021,\n                                                  q27a_dictionary_of_counts_2021)\n\ndef cloud_scatterplot(perc_dict, year):\n    df = pd.DataFrame(data = perc_dict, index = ['Percentage of Respondents']).transpose()\n    df['Year'] = year\n    df = df.reset_index()\n    df = df.rename(columns={'index':'Cloud Computing Platform'})\n    \n    return df\n\ncloud_use_df = cloud_scatterplot(q27a_dictionary_of_perc_2021, 2021)\ncloud_use_df = cloud_use_df.append(cloud_scatterplot(q26a_dictionary_of_perc_2020, 2020))\ncloud_use_df = cloud_use_df.append(cloud_scatterplot(q26a_dictionary_of_perc_2019, 2019))\ncloud_use_df = cloud_use_df.append(cloud_scatterplot(q26a_dictionary_of_perc_2018, 2018))\ncloud_use_df = cloud_use_df.reset_index(drop=True)","f979243a":"a4_dims = (13, 10)\ncloud_fig, cloud_ax = plt.subplots(figsize=a4_dims)\n\nsns.lineplot(data = cloud_use_df,\n            ax = cloud_ax,\n            x = 'Year',\n            y = 'Percentage of Respondents',\n            hue = 'Cloud Computing Platform',\n            style = 'Cloud Computing Platform',\n            markers = True,\n            dashes = False)\ncloud_ax.set_xticks(ticks = [2018, 2019, 2020, 2021])","19ebac49":"def count_then_return_percent(dataframe,column_name):\n    '''\n    A helper function to return value counts as percentages.\n    '''\n    counts = dataframe[column_name].value_counts(dropna=True)\n    percentages = round(counts*100\/(dataframe[column_name].count()),1)\n    return percentages\n\n#responses_df_2019 = responses_df_2019['Q11'].replace([\"$0 (USD)\"], \"$0\",inplace=True)\n\ndef cloud_cost_scatterplot(perc_dict, year):\n    df = perc_dict.to_frame(name = 'Percentage of Respondents').iloc[1:,:]\n    df = df.reset_index()\n    df = df.rename(columns={'index': 'Money Spent on Cloud(USD)'})\n    df['Year'] = year\n    \n    return df\n\ncloud_cost_perc_2019 = count_then_return_percent(responses_df_2019,'Q11').iloc[::-1]#[responses_in_order]\ncloud_cost_perc_2020 = count_then_return_percent(responses_df_2020,'Q25').iloc[::-1]#[responses_in_order]\ncloud_cost_perc_2021 = count_then_return_percent(responses_df_2021,'Q26').iloc[::-1]#[responses_in_order]\n\ncloud_cost_df = cloud_cost_scatterplot(cloud_cost_perc_2021, 2021)\ncloud_cost_df = cloud_cost_df.append(cloud_cost_scatterplot(cloud_cost_perc_2020, 2020))\ncloud_cost_df = cloud_cost_df.append(cloud_cost_scatterplot(cloud_cost_perc_2019, 2019))\ncloud_cost_df = cloud_cost_df.reset_index(drop=True)","97d2353d":"a4_dims = (13, 10)\ncloud_cost_fig, cloud_cost_ax = plt.subplots(figsize=a4_dims)\n\nsns.lineplot(data = cloud_cost_df,\n            ax = cloud_cost_ax,\n            x = 'Year',\n            y = 'Percentage of Respondents',\n            hue = 'Money Spent on Cloud(USD)',\n            style = 'Money Spent on Cloud(USD)',\n            markers = True,\n            dashes = False)\ncloud_ax.set_xticks(ticks = [2019, 2020, 2021])\n\n#shows that more people are using, but using free tier, perhaps to experiment","f9fd0ab0":"#\uc720\uc800 \ubd84\uc11d","ea10b6cc":"gpu_total_2021 = resp_2021['Q17_Part_1'].str.contains('GPUs').fillna(value = False) | \\\nresp_2021['Q17_Part_2'].str.contains('TPUs').fillna(value = False) | \\\nresp_2021['Q12_Part_3'].str.contains('AWS Trainium Chips').fillna(value = False) | \\\nresp_2021['Q12_Part_4'].str.contains('AWS Inferentia Chips').fillna(value = False) | \\\nresp_2021['Q12_Part_5'].str.contains('None').fillna(value = False) | \\\nresp_2021['Q12_OTHER'].str.contains('Other').fillna(value = False)","3f416388":"(pd.Series(['hi', 'hello']).str.contains('')) & (pd.Series(['hey', 'ho']).str.contains('hey'))","f45f2df0":"resp_2021.iloc[8].to_frame().reset_index().iloc[90:102]","2e4d5ae6":"resp_2021.iloc[0:10]","5323448f":"#\uc720\uc800\ub97c 3\uc73c\ub85c \ub098\ub208\ub2e4  --> \uba38\uc2e0\ub7ec\ub2dd only  \/ \ub525\ub7ec\ub2dd only \/ \uba38\uc2e0\ub7ec\ub2dd + \ub525\ub7ec\ub2dd \n#\ub144\ub3c4\ub9c8\ub2e4 \ucd94\uc774? \ub144\ub3c4 + \uba38\uc2e0\ub7ec\ub2dd pref + \ub2e4\ub978 \ubcc0\uc218 \ubd84\uc11d\n# --> \uc5f0\ubd09?\n# \uc9c1\uc885???\n\n'''Don't count other, none''' \n\n'''\nMachine Learning Algos \nLin Log Reg (1)\nDecision (2)\nGrad Boosting (3)\nBayesian (4)\nEvolutionary (5)\n'''\n\n'''\nDeep Learning Algos \nDense NN (6)\nCNN (7)\nGAN (8)\nRNN (9)\nTransformer (10)\n'''\n\n\nml_only_2021 = (resp_2021['Q17_Part_1'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_2'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_3'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_4'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_5'].str.contains('').fillna(value = False)) & \\\n(resp_2021['Q17_Part_6'].str.contains('impossible_val').fillna(value = True) & \\\nresp_2021['Q17_Part_7'].str.contains('impossible_val').fillna(value = True) & \\\nresp_2021['Q17_Part_8'].str.contains('impossible_val').fillna(value = True) & \\\nresp_2021['Q17_Part_9'].str.contains('impossible_val').fillna(value = True) & \\\nresp_2021['Q17_Part_10'].str.contains('impossible_val').fillna(value = True))\n\nml_only_2021 = resp_2021[ml_only_2021]\nml_only_2021 = ml_only_2021[(ml_only_2021['Q25'] != '$0-999') &  \n                            (ml_only_2021['Q25'] != 'What is your current yearly compensation (approximate $USD)?')]\n\ndl_only_2021 = (resp_2021['Q17_Part_6'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_7'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_8'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_9'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_10'].str.contains('').fillna(value = False)) & \\\n(resp_2021['Q17_Part_1'].str.contains('impossible_val').fillna(value = True) & \\\nresp_2021['Q17_Part_2'].str.contains('impossible_val').fillna(value = True) & \\\nresp_2021['Q17_Part_3'].str.contains('impossible_val').fillna(value = True) & \\\nresp_2021['Q17_Part_4'].str.contains('impossible_val').fillna(value = True) &  \\\nresp_2021['Q17_Part_5'].str.contains('impossible_val').fillna(value = True))\ndl_only_2021 = resp_2021[dl_only_2021]\ndl_only_2021 = dl_only_2021[(dl_only_2021['Q25'] != '$0-999') &  \n                            (dl_only_2021['Q25'] != 'What is your current yearly compensation (approximate $USD)?')]\n\nml_dl_2021 = (resp_2021['Q17_Part_1'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_2'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_3'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_4'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_5'].str.contains('').fillna(value = False)) & \\\n(resp_2021['Q17_Part_6'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_7'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_8'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_9'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_10'].str.contains('').fillna(value = False))\nml_dl_2021 = resp_2021[ml_dl_2021]\nml_dl_2021 = ml_dl_2021[(ml_dl_2021['Q25'] != '$0-999') &  \n                            (ml_dl_2021['Q25'] != 'What is your current yearly compensation (approximate $USD)?')]\n\nmldl_count_check = (resp_2021['Q17_Part_1'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_2'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_3'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_4'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_5'].str.contains('').fillna(value = False)) | \\\n(resp_2021['Q17_Part_6'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_7'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_8'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_9'].str.contains('').fillna(value = False) | \\\nresp_2021['Q17_Part_10'].str.contains('').fillna(value = False))\nmldl_count_check = resp_2021[mldl_count_check]\nmldl_count_check = mldl_count_check[(mldl_count_check['Q25'] != '$0-999') &  \n                            (mldl_count_check['Q25'] != 'What is your current yearly compensation (approximate $USD)?')]\n\n\ndef salary_conv_2021(df):\n    #for responses in 2020\n    #converts from strings to numerical data\n    #I put inputted the value of salary that was right in between the range of salaries in order for a fair estimate of salaries\n    conv_dict = {'10,000-14,999':12500, '1,000-1,999':1500, '100,000-124,999': 112500,\n                '40,000-49,999':45000, '30,000-39,999':35000, '50,000-59,999': 55000, '5,000-7,499':6250,\n                '15,000-19,999':17500, '60,000-69,999':65000, '20,000-24,999': 22500, '70,000-79,999':75000,\n                '7,500-9,999':8750, '150,000-199,999':175000, '2,000-2,999':2500, '125,000-149,999':137500,\n                '25,000-29,999':27500, '90,000-99,999':95000, '4,000-4,999':4500, '80,000-89,999':85000,\n                '3,000-3,999':3500, '200,000-249,999':225000, '300,000-500,000':400000, '$500,000-999,999':500000,\n                '250,000-299,999':275000, '>$1,000,000': 1000000, '300,000-499,999':350000}\n    df = df['Q25'].map(conv_dict)\n    return df","4b1c65e4":"print(len(mldl_count_check)) \nprint((len(ml_only_2021) + len(dl_only_2021)) + ( len(ml_dl_2021)))\n#if same, the stuff is done correctly ","c42c06d7":"print(salary_conv_2021(ml_only_2021).mean())\nprint(salary_conv_2021(dl_only_2021).mean())\nprint(salary_conv_2021(ml_dl_2021).mean())\nprint(salary_conv_2021(mldl_count_check).mean())","db662e1a":"print(salary_conv_2021(ml_only_2021).median())\nprint(salary_conv_2021(dl_only_2021).median())\nprint(salary_conv_2021(ml_dl_2021).median())\nprint(salary_conv_2021(mldl_count_check).median())","49f9eec4":"hi = salary_conv_2021(ml_only_2021).value_counts()\n(salary_conv_2021(ml_only_2021).value_counts() \/ sum(hi)).to_frame().reset_index()","afa50b31":"ml_only_2021","d98d8fb2":"def df_to_salary_bar(series, x_ind, y_ind, specialty):\n    val_counts = salary_conv_2021(series).value_counts()\n    res = ((val_counts \/ sum(val_counts)) * 100).to_frame().reset_index()\n    res = res.rename(columns = {'index':x_ind, 'Q25': y_ind})\n    res['Type'] = specialty\n    return res\n    \na4_dims = (13, 10)\nhi_fig, hi_ax = plt.subplots(figsize=a4_dims)\n\n\n#sns.histplot(data = salary_conv_2021(ml_only_2021))\nsns.barplot(data = df_to_salary_bar(ml_only_2021, 'Salary (USD)', 'Percentage of Respondents', 'ML Only'), x = 'Salary (USD)', y = 'Percentage of Respondents')\n\nhi_ax.tick_params(labelrotation=45)\n","aa6c7a1d":"a4_dims = (13, 10)\nhi_fig, hi_ax = plt.subplots(figsize=a4_dims)\n\n#sns.histplot(data = salary_conv_2021(dl_only_2021))\nsns.barplot(data = df_to_salary_bar(dl_only_2021, 'Salary (USD)', 'Percentage of Respondents', 'DL Only'),  x = 'Salary (USD)', y = 'Percentage of Respondents')\n\nhi_ax.tick_params(labelrotation=45)","ae636c7b":"a4_dims = (13, 10)\nhi_fig, hi_ax = plt.subplots(figsize=a4_dims)\n\nsns.barplot(data = df_to_salary_bar(ml_dl_2021, 'Salary (USD)', 'Percentage of Respondents', 'ML and DL'),  x = 'Salary (USD)', y = 'Percentage of Respondents')\n#sns.histplot(data = salary_conv_2021(ml_dl_2021))\nhi_ax.tick_params(labelrotation=45)","38ef2df1":"hi = df_to_salary_bar(ml_only_2021, 'Salary (USD)', 'Percentage of Respondents', 'ML Only')\nhi = hi.append(df_to_salary_bar(dl_only_2021, 'Salary (USD)', 'Percentage of Respondents', 'DL Only'))\nhi = hi.append(df_to_salary_bar(ml_dl_2021, 'Salary (USD)', 'Percentage of Respondents', 'ML and DL'))","9bc559ab":"hi","63e7941e":"a4_dims = (13, 10)\nhi_fig, hi_ax = plt.subplots(figsize=a4_dims)\n\n#sns.histplot(data = hi, x='Salary (USD)', y = 'Percentage of Respondents', hue='Type', element = 'step')","410ba2f4":"a4_dims = (13, 10)\nhi_fig, hi_ax = plt.subplots(figsize=a4_dims)\nsns.boxplot(x=salary_conv_2021(ml_only_2021))","deebbdb2":"a4_dims = (13, 10)\nhi_fig, hi_ax = plt.subplots(figsize=a4_dims)\nsns.boxplot(x=salary_conv_2021(dl_only_2021))","c7e0a171":"a4_dims = (13, 10)\nhi_fig, hi_ax = plt.subplots(figsize=a4_dims)\nsns.boxplot(x=salary_conv_2021(ml_dl_2021))","caef323b":"hi","c835b9fd":"salary_conv_2021(ml_only_2021)","91463279":"def ahh(df, name):\n    res = salary_conv_2021(df).dropna().to_frame()\n    res['Type'] = name\n    \n    return res","b8062e21":"hey = ahh(ml_only_2021, 'ML Only')\nhey = hey.append(ahh(dl_only_2021, 'DL Only'))\nhey = hey.append(ahh(ml_dl_2021, 'ML and DL'))\nhey = hey.reset_index(drop = True)","16234365":"hey","31d01cb8":"a4_dims = (13, 10)\nhi_fig, hi_ax = plt.subplots(figsize=a4_dims)\nsns.violinplot(data = hey, y = 'Type', x = 'Q25', jitter = 0.55)","c9c65bea":"a4_dims = (13, 10)\nhi_fig, hi_ax = plt.subplots(figsize=a4_dims)\n\n\nsns.barplot(data = df_to_salary_bar(ml_only_2021, 'Salary (USD)', 'Percentage of Respondents', 'ML Only'), x = 'Salary (USD)', y = 'Percentage of Respondents', \n            color = 'blue', alpha = 1)\nsns.barplot(data = df_to_salary_bar(dl_only_2021, 'Salary (USD)', 'Percentage of Respondents', 'DL Only'),  x = 'Salary (USD)', y = 'Percentage of Respondents', \n            color = 'green', alpha = 1)\nsns.barplot(data = df_to_salary_bar(ml_dl_2021, 'Salary (USD)', 'Percentage of Respondents', 'ML and DL'),  x = 'Salary (USD)', y = 'Percentage of Respondents', \n            color = 'orange', alpha = 1)\n\n\nhi_ax.tick_params(labelrotation=45)","933da735":"hello = hi.pivot(index='Salary (USD)', columns ='Type', values = 'Percentage of Respondents')\n\nhello.plot.bar(stacked = True, figsize = (13, 10))","b1bd7c1d":"salary_conv_2021(ml_only_2021)","e0f669f8":"q17_dictionary_of_counts_2021 = {\n    'Linear or Logistic Regression' : (responses_df_2021['Q17_Part_1'].count()),\n    'Decision Trees or Random Forests': (responses_df_2021['Q17_Part_2'].count()),\n    'Gradient Boosting Machines (xgboost, lightgbm, etc)' : (responses_df_2021['Q17_Part_3'].count()),\n    'Bayesian Approaches' : (responses_df_2021['Q17_Part_4'].count()),\n    'Evolutionary Approaches' : (responses_df_2021['Q17_Part_5'].count()),\n    'Dense Neural Networks (MLPs, etc)' : (responses_df_2021['Q17_Part_6'].count()),\n    'Convolutional Neural Networks' : (responses_df_2021['Q17_Part_7'].count()),\n    'Generative Adversarial Networks' : (responses_df_2021['Q17_Part_8'].count()),\n    'Recurrent Neural Networks' : (responses_df_2021['Q17_Part_9'].count()),\n    'Transformer Networks (BERT, gpt-3, etc)' : (responses_df_2021['Q17_Part_10'].count()),\n    'None' : (responses_df_2021['Q17_Part_11'].count()),\n    'Other' : (responses_df_2021['Q17_OTHER'].count())\n}\n\n\n\nq17_dictionary_of_perc_2021 = count_then_return_percent_for_multiple_column_questions(responses_df_2021,\n                                                  q17_list_of_columns_2021,\n                                                  q17_dictionary_of_counts_2021)","8e013623":"'''\n\uc5c5\uacc4\ub294 \ub108\ubb34 \ub9ce\uc544\uc11c \uc77c\ub2e8 \ubcf4\ub958\n'''\n\n#slope graph\ub97c \ubcf4\uc5ec\uc8fc\uace0 \uc81c\uc77c \uccab\ubc88\uc9f8, \ub9c8\uc9c0\ub9c9 \ube7c\uace0\ub294 \ub4e4\ub7ec\ub9ac \uc2dd\uc73c\ub85c \ub9cc\ub4e4\uae30 \n#\uc774\uac70\ub97c \ud074\ub77c\uc6b0\ub4dc\uac00 \uc544\ub2cc ml \/ dl \ud37c\uc13c\ud14c\uc774\uc9c0\ub85c? \n\n","94665dd0":"#\uc5c5\uacc4\ub9c8\ub2e4 \ub525\ub7ec\ub2dd \/ \uba38\uc2e0\ub7ec\ub2dd \ud604\ud669 \uc5bc\ub9c8\ub098 \uc4f0\uc774\ub294\uc9c0 \uadf8\ub9ac\uace0 \uc5c5\uacc4 \ub9c8\ub2e4 \ub354 \uc4f0\ub294 \uc5c5\uacc4\uac00 \uc788\ub294\uc9c0 2018\uc5d0 \ube44\ud574\uc11c \uc5bc\ub9c8\ub098 \ubc14\ub00c\uc5c8\ub294\uc9c0 \n\n#\uc5c5\uacc4\ub9c8\ub2e4 \uc9e4\ub77c\uc11c \ud074\ub77c\uc6b0\ub4dc\uc5d0 \uc4f0\ub294 \ub3c8\uc744 \ube44\uad50 \n\nresp_2021['Q20'].value_counts()","258f475d":"hi = resp_2021[resp_2021['Q20'] == 'Academics\/Education']['Q26'].value_counts()\nhi \/ sum(hi)","010f8b7a":"Machine Learning vs. Deep Learning"}}