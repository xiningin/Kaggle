{"cell_type":{"7d505b7b":"code","bdc8c441":"code","663c02c4":"code","4af3af5b":"code","e10f5672":"code","46271a84":"code","244f3729":"code","f7bef857":"code","9779d975":"code","e50485b4":"code","187b0002":"code","22b959f2":"code","feb61904":"code","097d66d2":"code","ed77905f":"code","d13e4f33":"code","08556d98":"code","2e62a214":"code","5dd7d820":"code","642b0aeb":"code","553c65a3":"code","76f7af27":"code","543e434c":"code","cf4cbb3b":"code","2ec46115":"code","b591f943":"code","471e9b87":"code","5a49e5c4":"code","c87d0806":"code","bfb5e238":"code","178a3ed8":"code","60dd8e11":"code","d4973e1a":"code","02472ae8":"code","e5739eef":"code","f00bc14d":"code","27583093":"code","e1d60081":"code","e5a939d3":"code","1487e0a8":"code","98d27cea":"code","bd3a764b":"code","3b7309c7":"code","2aeacec8":"code","005aa0e7":"code","73ec9de4":"code","f718a76c":"code","2ec19eb2":"code","f153fbc8":"code","28f9d8a1":"code","7cfe353d":"code","e53e38c6":"code","741ca9a4":"code","dbb7b2f9":"code","5e424278":"code","a51a5811":"code","39bea725":"code","338fc6c0":"code","b2ecf402":"code","5222ecb5":"code","f8d07a82":"code","0cca2529":"code","3549cf89":"code","a06066ba":"code","1e77e4e8":"code","c37b8e5e":"code","c0ba76ed":"code","57d35e9f":"code","b4d57d36":"code","14c8084f":"code","64e945f9":"code","5963d773":"code","b4803e06":"code","0dc02cbb":"code","9f2ea04f":"code","7cfaddb8":"code","1df77240":"code","bf90e16f":"code","db49cd04":"code","acce3ef9":"code","7c6d5d81":"code","4f38dc9f":"code","602053df":"code","0e9d8666":"code","44921e5b":"code","930a3d14":"code","9f8ac5a5":"code","3d883105":"code","d0e112d7":"code","717dda44":"code","72f292ba":"code","6ce27c06":"code","17cae946":"code","5078d9d4":"code","0606d217":"code","fb3da827":"code","7203c9e9":"code","0453f2a7":"code","355d4672":"code","889a36c9":"code","36f1dd5a":"code","7062c69a":"code","9d6accfb":"code","c1f16185":"code","0d621135":"code","16e3b811":"code","dc26c2c9":"code","3e768afe":"code","45c13f3a":"markdown","372e2a70":"markdown","bacc3d95":"markdown","9aaaed98":"markdown","ca394b56":"markdown","7b1f51f8":"markdown","ca10e334":"markdown","36d257f0":"markdown","d8701c5b":"markdown","55b789cf":"markdown","0edcc36d":"markdown","51895e77":"markdown","8cbeb7ef":"markdown"},"source":{"7d505b7b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bdc8c441":"import scipy as sp\nfrom pandas import DataFrame, Series\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nimport datetime as dt\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import GridSearchCV,StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nimport gc","663c02c4":"df_train = pd.read_csv('..\/input\/homework-for-students3\/train.csv', index_col=0, parse_dates=['issue_d','earliest_cr_line'])#, skiprows=lambda x: x%20!=0)\ndf_test = pd.read_csv('..\/input\/homework-for-students3\/test.csv', index_col=0, parse_dates=['issue_d','earliest_cr_line'])#, skiprows=lambda x: x%20!=0)","4af3af5b":"df_train['earliest_cr_line_y'] = df_train.earliest_cr_line.dt.year\ndf_test['earliest_cr_line_y'] = df_test.earliest_cr_line.dt.year\n\ndf_train['cr_line_priod'] = df_train['issue_d'] - df_train['earliest_cr_line']\ndf_test['cr_line_priod'] = df_test['issue_d'] - df_test['earliest_cr_line']\n\ndf_train['cr_line_priod'] = df_train['cr_line_priod'].astype(int)\ndf_test['cr_line_priod'] = df_test['cr_line_priod'].astype(int)\n\n#df_train['cr_line_priod'] = df_train['cr_line_priod'].apply(np.log1p)\n#df_test['cr_line_priod'] = df_test['cr_line_priod'].apply(np.log1p)","e10f5672":"df_train.shape","46271a84":"df_train.isnull().sum()","244f3729":"df_train.head()","f7bef857":"statelatlong = pd.read_csv('..\/input\/homework-for-students3\/statelatlong.csv')\n\nstatelatlong.head()","9779d975":"df_train = df_train.merge(statelatlong, left_on='addr_state',right_on='State', how='left')\ndf_test = df_test.merge(statelatlong, left_on='addr_state',right_on='State', how='left')\n\ndf_train.drop(['State'], axis=1, inplace=True)\ndf_test.drop(['State'], axis=1, inplace=True)\n\ndf_train.drop(['Latitude'], axis=1, inplace=True)\ndf_test.drop(['Latitude'], axis=1, inplace=True)\n\ndf_train.drop(['Longitude'], axis=1, inplace=True)\ndf_test.drop(['Longitude'], axis=1, inplace=True)","e50485b4":"df_train['zip_code'].head()","187b0002":"dtypes = {\n    'RecordNumber':'int32',\n    'Zipcode':'object',\n    'ZipCodeType':'object',\n    'City':'object',\n    'State':'object',\n    'LocationType':'object',\n    'Lat':'float64',\n    'Long':'float64',\n    'Xaxis':'float64',\n    'Yaxis':'float64',\n    'Zaxis':'float64',\n    'WorldRegion':'object',\n    'Country':'object',\n    'LocationText':'object',\n    'Location':'object',\n    'Decommisioned':'int8',\n    'TaxReturnsFiled':'float64',\n    'EstimatedPopulation':'float64',\n    'TotalWages':'float32',\n    'Notes':'object'\n}\n\nzipcode_dtl = pd.read_csv('..\/input\/homework-for-students3\/free-zipcode-database.csv',index_col=0,dtype=dtypes)\n\n#zipcode_dtl = zipcode_dtl.query('Country.str.contains(\"US\")', engine='python')\nzipcode_dtl = zipcode_dtl.query('Decommisioned == 0', engine='python')\nzipcode_dtl = zipcode_dtl[zipcode_dtl['Country'] == 'US']\nzipcode_dtl = zipcode_dtl[zipcode_dtl['State'] != 'PR']\nzipcode_dtl = zipcode_dtl[zipcode_dtl['State'] != 'VI']\nzipcode_dtl['zip_code'] = zipcode_dtl['Zipcode'].str[:3]\nzipcode_dtl['zip_code'] = zipcode_dtl['zip_code'] + 'xx'\n\n#zipcode_dtl.tail()\n\nzipcode_dtl = zipcode_dtl.groupby(['zip_code']).mean()\nzipcode_dtl.drop('Decommisioned', axis=1, inplace=True)\nzipcode_dtl.drop('EstimatedPopulation', axis=1, inplace=True)\nzipcode_dtl.drop('TaxReturnsFiled', axis=1, inplace=True)\nzipcode_dtl.drop('TotalWages', axis=1, inplace=True)","22b959f2":"zipcode_dtl.head(20)","feb61904":"df_train['zip_code'].head()","097d66d2":"df_train = df_train.merge(zipcode_dtl, on='zip_code', how='left')\ndf_test = df_test.merge(zipcode_dtl, on='zip_code', how='left')","ed77905f":"df_train.head()","d13e4f33":"df_test.head()","08556d98":"df_train[df_train.loan_condition==1].loan_amnt.mean()","2e62a214":"df_train[df_train.loan_condition==0].loan_amnt.mean()","5dd7d820":"df_train.describe()","642b0aeb":"df_test.describe()","553c65a3":"df_train.dtypes","76f7af27":"df_train.isnull().sum()","543e434c":"df_test.isnull().sum()","cf4cbb3b":"df_train.grade.value_counts() \/ len(df_train)","2ec46115":"df_test.grade.value_counts() \/ len(df_test)","b591f943":"df_train[df_train.loan_condition ==1].grade.value_counts()","471e9b87":"df_train[df_train.loan_condition ==0].grade.value_counts()","5a49e5c4":"df_train.sub_grade.value_counts()","c87d0806":"df_train.dtypes","bfb5e238":"df_train['annual_inc'].head()","178a3ed8":"f = 'annual_inc'\n\nplt.figure(figsize=[7,7])\ndf_train[f].hist(density=False, alpha=0.5, bins=10)\ndf_test[f].hist(density=False, alpha=0.5, bins=10)\nplt.xlabel(f)\nplt.ylabel('count')\nplt.show()","60dd8e11":"f = 'purpose'\n\ndf_train[f].value_counts() \/ len(df_train)","d4973e1a":"df_test[f].value_counts() \/ len(df_test)","02472ae8":"#df_train = df_train.query('issue_d.str.contains(\"2015\")', engine='python')\n#issue_year = df_train.issue_d.dt.year\n\ndf_train = df_train[df_train.issue_d.dt.year == 2015]\n\ndf_train.head()","e5739eef":"df_train.shape","f00bc14d":"df_train.isnull().sum()","27583093":"y_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'], axis=1)\n\nX_test = df_test","e1d60081":"X_train.shape","e5a939d3":"X_train.describe()","1487e0a8":"X_train.columns","98d27cea":"usgdp = pd.read_csv('..\/input\/homework-for-students3\/US_GDP_by_State.csv')\n#usgdp.drop(['Gross State Product'], axis=1, inplace=True)\n#usgdp.drop(['State & Local Spending'], axis=1, inplace=True)\n#usgdp.drop(['Population (million)'], axis=1, inplace=True)","bd3a764b":"usgdp.columns","3b7309c7":"# 2013\u5e74\u30c7\u30fc\u30bf.drop(\nusgdp2013 = usgdp.query('year == \"2013\"')\n# 2014\u5e74\u30c7\u30fc\u30bf, axis=1, inplace=True)\nusgdp2014 = usgdp.query('year == \"2014\"')\n# 2015\u5e74\u30c7\u30fc\u30bf\nusgdp2015 = usgdp.query('year == \"2015\"')\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306b\u306f2013\u5e74\u30682014\u5e74\uff08\u904e\u53bb2\u5e74\u5206\uff09\u3092\u8ffd\u52a0\nX_train = X_train.merge(usgdp2013, left_on='City', right_on='State', how='left')\nX_train['Gross State Product 2y'] = X_train['Gross State Product']\nX_train['State & Local Spending 2y'] = X_train['State & Local Spending']\nX_train['Population (million) 2y'] = X_train['Population (million)']\nX_train['Real State Growth % 2y'] = X_train['Real State Growth %']\nX_train.drop(['Gross State Product'], axis=1, inplace=True)\nX_train.drop(['State & Local Spending'], axis=1, inplace=True)\nX_train.drop(['Population (million)'], axis=1, inplace=True)\nX_train.drop(['Real State Growth %'], axis=1, inplace=True)\nX_train.drop(['State'], axis=1, inplace=True)\nX_train.drop(['year'], axis=1, inplace=True)\n\nX_train = X_train.merge(usgdp2014, left_on='City', right_on='State', how='left')\nX_train['Gross State Product 1y'] = X_train['Gross State Product']\nX_train['State & Local Spending 1y'] = X_train['State & Local Spending']\nX_train['Population (million) 1y'] = X_train['Population (million)']\nX_train['Real State Growth % 1y'] = X_train['Real State Growth %']\nX_train.drop(['Gross State Product'], axis=1, inplace=True)\nX_train.drop(['State & Local Spending'], axis=1, inplace=True)\nX_train.drop(['Population (million)'], axis=1, inplace=True)\nX_train.drop(['Real State Growth %'], axis=1, inplace=True)\nX_train.drop(['City'], axis=1, inplace=True)\nX_train.drop(['State'], axis=1, inplace=True)\nX_train.drop(['year'], axis=1, inplace=True)\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u306f2014\u5e74\u30682015\u5e74\uff08\u904e\u53bb2\u5e74\u5206\uff09\u3092\u8ffd\u52a0\nX_test = X_test.merge(usgdp2014, left_on='City', right_on='State', how='left')\nX_test['Gross State Product 2y'] = X_test['Gross State Product']\nX_test['State & Local Spending 2y'] = X_test['State & Local Spending']\nX_test['Population (million) 2y'] = X_test['Population (million)']\nX_test['Real State Growth % 2y'] = X_test['Real State Growth %']\nX_test.drop(['Gross State Product'], axis=1, inplace=True)\nX_test.drop(['State & Local Spending'], axis=1, inplace=True)\nX_test.drop(['Population (million)'], axis=1, inplace=True)\nX_test.drop(['Real State Growth %'], axis=1, inplace=True)\nX_test.drop(['State'], axis=1, inplace=True)\nX_test.drop(['year'], axis=1, inplace=True)\n\nX_test = X_test.merge(usgdp2015, left_on='City', right_on='State', how='left')\nX_test['Gross State Product 1y'] = X_test['Gross State Product']\nX_test['State & Local Spending 1y'] = X_test['State & Local Spending']\nX_test['Population (million) 1y'] = X_test['Population (million)']\nX_test['Real State Growth % 1y'] = X_test['Real State Growth %']\nX_test.drop(['Gross State Product'], axis=1, inplace=True)\nX_test.drop(['State & Local Spending'], axis=1, inplace=True)\nX_test.drop(['Population (million)'], axis=1, inplace=True)\nX_test.drop(['Real State Growth %'], axis=1, inplace=True)\nX_test.drop(['City'], axis=1, inplace=True)\nX_test.drop(['State'], axis=1, inplace=True)\nX_test.drop(['year'], axis=1, inplace=True)\n\nX_test.head()","2aeacec8":"X_train.columns","005aa0e7":"#X_train['loan_amnt'] = X_train['loan_amnt'].apply(np.log1p)\n#X_test['loan_amnt'] = X_test['loan_amnt'].apply(np.log1p)","73ec9de4":"cats = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \n        print(col, X_train[col].nunique())","f718a76c":"X_train['emp_title'].head(10)","2ec19eb2":"col = 'purpose'\n\nencoder = OneHotEncoder()\nenc_train = encoder.fit_transform(X_train[col].values)\nenc_test = encoder.fit_transform(X_test[col].values)","f153fbc8":"enc_train.head()","28f9d8a1":"enc_test.head()","7cfe353d":"encoder = OrdinalEncoder()\nenc_train = encoder.fit_transform(X_train[col].values)\nenc_test = encoder.fit_transform(X_test[col].values)","e53e38c6":"enc_train.head()","741ca9a4":"enc_test.head()","dbb7b2f9":"summary = X_train[col].value_counts()\nsummary","5e424278":"enc_train = X_train[col].map(summary)\nenc_test = X_test[col].map(summary)","a51a5811":"enc_train.head()","39bea725":"enc_test.head()","338fc6c0":"target = 'loan_condition'\nX_temp = pd.concat([X_train, y_train], axis=1)\n\nsummary = X_temp.groupby([col])[target].mean()\nenc_test = X_test[col].map(summary)\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nenc_train = Series(np.zeros(len(X_train)), index=X_train.index)\n\nfor i, (train_ix, val_ix) in enumerate((skf.split(X_train, y_train))):\n    X_train_, _ = X_temp.iloc[train_ix], y_train.iloc[train_ix]\n    X_val, _ = X_temp.iloc[val_ix], y_train.iloc[val_ix]\n    \n    summary = X_train_.groupby([col])[target].mean()\n    enc_train.iloc[val_ix] = X_val[col].map(summary)","b2ecf402":"enc_train","5222ecb5":"enc_test","f8d07a82":"TXT_train = X_train.emp_title.copy()\nTXT_test = X_test.emp_title.copy()\n\n#cats.remove('emp_title')\n\n","0cca2529":"cats","3549cf89":"#grade, sub_grade, emp_length\u3092\u8f9e\u66f8\u306b\u57fa\u3065\u3044\u3066Label Encoding\n\nmappingdict = {\n    \"grade\": { \"A\": 7,\"B\": 6,\"C\": 5,\"D\": 4,\"E\": 3,\"F\": 2,\"G\": 1 },\n    \"sub_grade\": {\n        \"A1\": 45,\"A2\": 44,\"A3\": 43,\"A4\": 42,\"A5\": 41,\n        \"B1\": 40,\"B2\": 39,\"B3\": 38,\"B4\": 37,\"B5\": 36,\n        \"C1\": 35,\"C2\": 34,\"C3\": 33,\"C4\": 32,\"C5\": 31,\n        \"D1\": 30,\"D2\": 29,\"D3\": 28,\"D4\": 27,\"D5\": 26,\n        \"E1\": 25,\"E2\": 24,\"E3\": 23,\"E4\": 22,\"E5\": 21,\n        \"F1\": 20,\"F2\": 19,\"F3\": 18,\"F4\": 17,\"F5\": 16,\n        \"G1\": 15,\"G2\": 14,\"G3\": 13,\"G4\": 12,\"G5\": 11\n    }\n    ,\"emp_length\": {\n        \"10+ years\": 10,\n        \"9 years\": 9,\n        \"8 years\": 8,\n        \"7 years\": 7,\n        \"6 years\": 6,\n        \"5 years\": 5,\n        \"4 years\": 4,\n        \"3 years\": 3,\n        \"2 years\": 2,\n        \"1 year\": 1,\n        \"< 1 year\": 0,\n        \"n\/a\": \"\"\n    }\n}\nX_train = X_train.replace(mappingdict)\nX_test = X_test.replace(mappingdict)\nmappingcol = ['grade','sub_grade','emp_length']\nX_train[mappingcol] = X_train[mappingcol].astype(float)\nX_test[mappingcol] = X_test[mappingcol].astype(float)","a06066ba":"X_train.head()","1e77e4e8":"X_test.head()","c37b8e5e":"X_train.drop(['issue_d'], axis=1, inplace=True)\nX_test.drop(['issue_d'], axis=1, inplace=True)\n\nX_train.drop(['earliest_cr_line'], axis=1, inplace=True)\nX_test.drop(['earliest_cr_line'], axis=1, inplace=True)\n\n#X_train.drop(['title'], axis=1, inplace=True)\n#X_test.drop(['title'], axis=1, inplace=True)\n\n#X_train.drop(['grade'], axis=1, inplace=True)\n#X_test.drop(['grade'], axis=1, inplace=True)","c0ba76ed":"cats.remove('grade')\ncats.remove('sub_grade')\n#cats.remove('emp_length')\n#cats.remove('title')","57d35e9f":"cats","b4d57d36":"X_train.isnull().sum()","14c8084f":"oe = OrdinalEncoder(cols=cats, return_df=False)","64e945f9":"X_train[cats] = oe.fit_transform(X_train[cats])\nX_test[cats] = oe.transform(X_test[cats])","5963d773":"X_train.head()","b4803e06":"X_test.head()","0dc02cbb":"# \u6b20\u640d\u306e\u78ba\u8a8d\nX_train.isnull().sum()\n\nX_train['null_count'] = X_train.isnull().sum(axis=1)\nX_test['null_count'] = X_test.isnull().sum(axis=1)","9f2ea04f":"X_train.head()","7cfaddb8":"#X_all = pd.concat([X_train,X_test], axis=0)\n\nnullcheck = X_train.columns[X_train.isnull().sum() != 0].values\n\nfor col in nullcheck:\n    X_train[col + '_null'] = 0\n    X_train[col + '_null'] = X_train[col].isnull()\n    X_test[col + '_null'] = 0\n    X_test[col + '_null'] =  X_test[col].isnull()\n\nX_train.head()\n","1df77240":"X_train.isnull().sum()","bf90e16f":"X_test.isnull().sum()","db49cd04":"#X_train['mths_since_last_delinq'].fillna(9999, inplace=True)\n#X_train['mths_since_last_record'].fillna(9999, inplace=True)\n#X_train['mths_since_last_major_derog'].fillna(9999, inplace=True)\n\n#X_test['mths_since_last_delinq'].fillna(9999, inplace=True)\n#X_test['mths_since_last_record'].fillna(9999, inplace=True)\n#X_test['mths_since_last_major_derog'].fillna(9999, inplace=True)\n\n#X_train.fillna(X_train.median(), inplace=True)\n#X_test.fillna(X_train.median(), inplace=True)\n\nX_train.fillna(-9999, inplace=True)\nX_test.fillna(-9999, inplace=True)","acce3ef9":"X_train.isnull().sum()","7c6d5d81":"cats","4f38dc9f":"cats.append('grade')\ncats.append('sub_grade')\ncats.append('acc_now_delinq')\ncats.append('mths_since_last_delinq')\ncats.append('tot_coll_amt')\n\ncats","602053df":"target = 'loan_condition'\nX_temp = pd.concat([X_train, y_train], axis=1)\n\nfor col in cats:\n    summary = X_temp.groupby([col])[target].mean()\n    enc_test = X_test[col].map(summary)\n    \n    X_test[col + '_te'] = enc_test\n    \n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n    \n    enc_train = Series(np.zeros(len(X_train)), index=X_train.index)\n    \n    for i, (train_ix, val_ix) in enumerate((skf.split(X_train, y_train))):\n        X_train_, _ = X_temp.iloc[train_ix], y_train.iloc[train_ix]\n        X_val, _ = X_temp.iloc[val_ix], y_train.iloc[val_ix]\n        \n        summary = X_train_.groupby([col])[target].mean()\n        enc_train.iloc[val_ix] = X_val[col].map(summary)\n        \n        X_train[col + '_te'] = enc_train\n\nX_train.head()","0e9d8666":"X_test.head()","44921e5b":"X_train['loan_amnt_sg'] = X_train['loan_amnt'] * X_train['sub_grade']\nX_train['annual_inc_sg'] = X_train['annual_inc'] * X_train['sub_grade']\nX_train['installment_sg'] = X_train['installment'] * X_train['sub_grade']\nX_train['dti_sg'] = X_train['dti'] * X_train['sub_grade']\nX_train['loan_inc'] = X_train['loan_amnt'] * X_train['annual_inc']\nX_train['loan_installment'] = X_train['loan_amnt'] * X_train['installment']\nX_train['loan_dti'] = X_train['loan_amnt'] * X_train['dti']\nX_train['inc_installment'] = X_train['annual_inc'] * X_train['installment']\nX_train['inc_dti'] = X_train['annual_inc'] * X_train['dti']\nX_train['installment_dti'] = X_train['installment'] * X_train['dti']\n\nX_test['loan_amnt_sg'] = X_test['loan_amnt'] * X_test['sub_grade']\nX_test['annual_inc_sg'] = X_test['annual_inc'] * X_test['sub_grade']\nX_test['installment_sg'] = X_test['installment'] * X_test['sub_grade']\nX_test['dti_sg'] = X_test['dti'] * X_test['sub_grade']\nX_test['loan_inc'] = X_test['loan_amnt'] * X_test['annual_inc']\nX_test['loan_installment'] = X_test['loan_amnt'] * X_test['installment']\nX_test['loan_dti'] = X_test['loan_amnt'] * X_test['dti']\nX_test['inc_installment'] = X_test['annual_inc'] * X_test['installment']\nX_test['inc_dti'] = X_test['annual_inc'] * X_test['dti']\nX_test['installment_dti'] = X_test['installment'] * X_test['dti']\n\nX_train['revol_amnt'] = X_train['revol_bal'] \/ (101 - X_train['revol_util'])\nX_test['revol_amnt'] = X_test['revol_bal'] \/ (101 - X_test['revol_util'])\n\nX_train['annual_inc_sg'] = X_train['annual_inc_sg'] + 1\nX_test['annual_inc_sg'] = X_test['annual_inc_sg'] + 1\n\nX_train['loan_amnt_sg_rate'] = round(X_train['loan_amnt_sg'] \/ X_train['annual_inc_sg'], 6)\nX_test['loan_amnt_sg_rate'] = round(X_test['loan_amnt_sg'] \/ X_test['annual_inc_sg'], 6)\n\nX_train['inst_inc_rate'] = round((X_train['installment'] * 12) \/ X_train['annual_inc_sg'], 6)\nX_test['inst_inc_rate'] = round((X_test['installment'] * 12) \/ X_test['annual_inc_sg'], 6)\n\nX_train['inst_loan_rate'] = round(X_train['installment'] \/ X_train['loan_amnt_sg'], 6)\nX_test['inst_loan_rate'] = round(X_test['installment'] \/ X_test['loan_amnt_sg'], 6)\n\nX_train['dti_sg_rate'] = round(X_train['dti_sg'] \/ X_train['annual_inc_sg'], 6)\nX_test['dti_sg_rate'] = round(X_test['dti_sg'] \/ X_test['annual_inc_sg'], 6)\n\nX_train['acc_rate'] = round(X_train['open_acc'] \/ X_train['total_acc'], 6)\nX_test['acc_rate'] = round(X_test['open_acc'] \/ X_test['total_acc'], 6)\n\nX_train['Gross State Product diff'] = X_train['Gross State Product 2y'] - X_train['Gross State Product 1y']\nX_train['State & Local Spending diff'] = X_train['State & Local Spending 2y'] - X_train['State & Local Spending 1y']\nX_train['Population (million) diff'] = X_train['Population (million) 2y'] - X_train['Population (million) 1y']\nX_train['Real State Growth % diff'] = X_train['Real State Growth % 2y'] - X_train['Real State Growth % 1y']\n\nX_train['Gross State Product sum'] = X_train['Gross State Product 2y'] + X_train['Gross State Product 1y']\nX_train['State & Local Spending sum'] = X_train['State & Local Spending 2y'] + X_train['State & Local Spending 1y']\nX_train['Population (million)  grow rate'] = X_train['Population (million) 2y'] \/ X_train['Population (million) 1y']\nX_train['Real State Growth % x'] = X_train['Real State Growth % 2y'] * X_train['Real State Growth % 1y']\n\n\nX_test['Gross State Product diff'] = X_test['Gross State Product 2y'] - X_test['Gross State Product 1y']\nX_test['State & Local Spending diff'] = X_test['State & Local Spending 2y'] - X_test['State & Local Spending 1y']\nX_test['Population (million) diff'] = X_test['Population (million) 2y'] - X_test['Population (million) 1y']\nX_test['Real State Growth % diff'] = X_test['Real State Growth % 2y'] - X_test['Real State Growth % 1y']\n\nX_test['Gross State Product sum'] = X_test['Gross State Product 2y'] + X_test['Gross State Product 1y']\nX_test['Gross State Product sum'] = X_test['Gross State Product 2y'] + X_test['Gross State Product 1y']\nX_test['Population (million) grow rate'] = X_test['Population (million) 2y'] \/ X_test['Population (million) 1y']\nX_test['Real State Growth % x'] = X_test['Real State Growth % 2y'] * X_test['Real State Growth % 1y']\n","930a3d14":"#X_train.drop(['emp_title'], axis=1, inplace=True)\n#X_test.drop(['emp_title'], axis=1, inplace=True)\n#X_train.drop(['addr_state'], axis=1, inplace=True)\n#X_test.drop(['addr_state'], axis=1, inplace=True)\n#X_train.drop(['purpose'], axis=1, inplace=True)\n#X_test.drop(['purpose'], axis=1, inplace=True)\n#X_train.drop(['initial_list_status'], axis=1, inplace=True)\n#X_test.drop(['initial_list_status'], axis=1, inplace=True)\n#X_train.drop(['application_type'], axis=1, inplace=True)\n#X_test.drop(['application_type'], axis=1, inplace=True)","9f8ac5a5":"cats = X_train.columns\n\nX_all = pd.concat([X_train,X_test], axis=0, sort=True)\n\nfor col in cats:\n    freq = X_all[col].value_counts()\n    col_count = col + '_count'\n    X_all[col_count] = X_all[col].map(freq)\n\n#freq = X_all['grade'].value_counts()\n#X_all['grade_count'] = X_all['grade'].map(freq)\n\n#freq = X_all['sub_grade'].value_counts()\n#X_all['sub_grade_count'] = X_all['sub_grade'].map(freq)\n    \nfreq = X_all['earliest_cr_line_y'].value_counts()\nX_all['earliest_cr_line_y_count'] = X_all['earliest_cr_line_y'].map(freq)\n\n#X_all.drop(['earliest_cr_line_y'], axis=1, inplace=True)\n#X_train.drop(['earliest_cr_line_y'], axis=1, inplace=True)\n#X_test.drop(['earliest_cr_line_y'], axis=1, inplace=True)\n\n#X_all.drop(['home_ownership'], axis=1, inplace=True)\n#X_train.drop(['home_ownership'], axis=1, inplace=True)\n#X_test.drop(['home_ownership'], axis=1, inplace=True)\n\nX_train = X_all.iloc[:X_train.shape[0],:]\nX_test = X_all.iloc[X_train.shape[0]:,:]\n\ndel X_all","3d883105":"X_train.head()","d0e112d7":"LGBMClassifier()","717dda44":"X_train.columns","72f292ba":"scores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    #clf = GradientBoostingClassifier()\n    #clf = LGBMClassifier(boosting_type='dart', n_estimators=1000)\n    clf = LGBMClassifier()\n    \n    \n    #clf.fit(X_train_, y_train_)\n    clf.fit(X_train_, y_train_, early_stopping_rounds=50, eval_metric='auc', eval_set=[(X_val, y_val)])\n    y_pred_1 = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred_1)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","6ce27c06":"print(np.mean(scores))\nprint(scores)","17cae946":"clf.fit(X_train, y_train)\n\ny_pred_1 = clf.predict_proba(X_test)[:,1]","5078d9d4":"scores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    #clf = GradientBoostingClassifier()\n    clf = LGBMClassifier(boosting_type='dart', n_estimators=1000)\n    #clf = LGBMClassifier()\n    \n    \n    #clf.fit(X_train_, y_train_)\n    clf.fit(X_train_, y_train_, eval_metric='auc', eval_set=[(X_val, y_val)])\n    y_pred_2 = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred_2)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))","0606d217":"print(np.mean(scores))\nprint(scores)","fb3da827":"clf.fit(X_train, y_train)\n\ny_pred_2 = clf.predict_proba(X_test)[:,1]","7203c9e9":"y_pred = (y_pred_1 + y_pred_2) \/ 2","0453f2a7":"fig, ax = plt.subplots(figsize=(10, 15))\nlgb.plot_importance(clf, max_num_features=50, ax=ax, importance_type='gain')","355d4672":"submission = pd.read_csv('..\/input\/homework-for-students3\/sample_submission.csv', index_col=0)#, skiprows=lambda x:x%20!=0)\n\nsubmission.loan_condition = y_pred\nsubmission.to_csv('submission.csv')","889a36c9":"#TXT_train.fillna('#', inplace=True)\n#TXT_test.fillna('#', inplace=True)","36f1dd5a":"#tfidf = TfidfVectorizer(max_features=1000, use_idf=True)","7062c69a":"#TXT_train = tfidf.fit_transform(TXT_train)\n#TXT_test = tfidf.transform(TXT_test)","9d6accfb":"#TXT_train","c1f16185":"#TXT_train.shape","0d621135":"#TXT_train.todense()","16e3b811":"#sp.sparse.hstack([X_train.values, TXT_train])","dc26c2c9":"#sp.sparse.hstack([X_train.values, TXT_train]).todense()","3e768afe":"del X_train\ndel y_train\ndel X_test","45c13f3a":"train\u30c7\u30fc\u30bf\u3068test\u30c7\u30fc\u30bf\u306b\u304a\u3051\u308bGrade\u306e\u5024\u306e\u6bd4\u7387\u306f\u305d\u308c\u307b\u3069\u5909\u308f\u3089\u306a\u3044\u3002","372e2a70":"# LightGBM(boosting_type='dart')\u3067\u306e\u30e2\u30c7\u30eb\u4f5c\u6210","bacc3d95":"# \u8aac\u660e\u5909\u6570\u306e\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0","9aaaed98":"# \u76ee\u7684\u5909\u6570\u3068\u8aac\u660e\u5909\u6570\u306e\u5206\u96e2","ca394b56":"# LightGBM(boosting_type='GBDT')\u3067\u306e\u30e2\u30c7\u30eb\u4f5c\u6210","7b1f51f8":"# GDP\u30c7\u30fc\u30bf\u306e\u7d50\u5408\nissue_d \u306e\u904e\u53bb2\u5e74\u5206\u3092\u7d50\u5408\n* X_train\u306b\u306f2013\u5e74\u30012014\u5e74\u306e\u30c7\u30fc\u30bf\u3092\u7d50\u5408\n* X_test\u306b\u306f2014\u5e74\u30012015\u5e74\u306e\u30c7\u30fc\u30bf\u3092\u7d50\u5408\n","ca10e334":"# \u30c7\u30fc\u30bf\u306e\u78ba\u8a8d","36d257f0":"# \u6b20\u640d\u3092\u57cb\u3081\u308b","d8701c5b":"# \u30a2\u30f3\u30b5\u30f3\u30d6\u30eb","55b789cf":"label Encording","0edcc36d":"# \u30c7\u30fc\u30bf\u53d6\u8fbc\u307f","51895e77":"**\u30c6\u30ad\u30b9\u30c8\u7279\u5fb4\u91cf**","8cbeb7ef":"# issue_d\u304c2015\u5e74\u3067\u3042\u308b\u3082\u306e\u306b\u7d5e\u8fbc\u3092\u5b9f\u65bd"}}