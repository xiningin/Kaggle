{"cell_type":{"b2fdf85f":"code","ab89f75e":"code","60625ad9":"code","2c9af244":"code","17d18800":"code","2dc02ba6":"code","e84bb8f0":"code","b820978a":"code","c66aae78":"code","fad8b393":"code","d2865226":"code","aeeefcd6":"code","6c00038b":"code","6cd8dc23":"code","6cc63c87":"code","e5e8fe13":"code","9aba312a":"code","c00fbf94":"markdown","ecec5b23":"markdown","b732e295":"markdown","ee4d8d6e":"markdown","695034a8":"markdown","cc50fa5a":"markdown","af55e263":"markdown"},"source":{"b2fdf85f":"package_paths = [\n    '..\/input\/pytorch-image-library\/pytorch-image-models-master\/pytorch-image-models-master',\n]\nimport sys;\n\nfor pth in package_paths:\n    sys.path.append(pth)\n\nimport timm","ab89f75e":"import pandas as pd\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport albumentations as A\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations.core.composition import Compose, OneOf\nfrom albumentations.augmentations.transforms import CLAHE, GaussNoise, ISONoise\nfrom albumentations.pytorch import ToTensorV2\n\nfrom pytorch_lightning import Trainer, seed_everything\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n\nfrom sklearn.model_selection import StratifiedKFold","60625ad9":"class CFG:\n    seed = 42\n    model_name = 'resnet50'\n    pretrained = False\n    img_size = 640\n    num_classes = 12\n    batch_size = 32\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","2c9af244":"PATH = \"..\/input\/plant-pathology-2021-fgvc8\/\"\nTEST_DIR = PATH + 'test_images\/'","17d18800":"seed_everything(CFG.seed)","2dc02ba6":"df_all = pd.read_csv(PATH + \"train.csv\")\nlabels = list(df_all['labels'].value_counts().keys())\nlabels_dict = dict(zip(labels, range(12)))","e84bb8f0":"sub = pd.read_csv(PATH + \"sample_submission.csv\")\nsub.head()","b820978a":"class PlantDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.image_id = df['image'].values\n        self.labels = df['labels'].values\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        image_id = self.image_id[idx]\n        label = self.labels[idx]\n        \n        image_path = TEST_DIR + image_id\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        augmented = self.transform(image=image)\n        image = augmented['image']\n        return {'image':image, 'target': label}","c66aae78":"def get_transform(phase: str):\n    if phase == 'train':\n        return Compose([\n            A.RandomResizedCrop(height=CFG.img_size, width=CFG.img_size),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n    else:\n        return Compose([\n            A.Resize(height=CFG.img_size, width=CFG.img_size),\n            A.Normalize(),\n            ToTensorV2(),\n        ])","fad8b393":"test_dataset = PlantDataset(sub, get_transform('valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=2)","d2865226":"class CustomResNet(nn.Module):\n    def __init__(self, model_name='resnet18', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.model.get_classifier().in_features\n        self.model.fc = nn.Linear(in_features, CFG.num_classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","aeeefcd6":"from collections import OrderedDict\n\ndef fix_model_state_dict(state_dict):\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k\n        if name.startswith('model.'):\n            name = name[6:]  # remove 'model.' of dataparallel\n        new_state_dict[name] = v\n    return new_state_dict","6c00038b":"model = CustomResNet(model_name=CFG.model_name, pretrained=CFG.pretrained)","6cd8dc23":"#checkpoint = \"..\/input\/plat2021-resnet50-640\/resnet50\/version_0\/checkpoints\/epoch_27-valid_loss_0.3261-valid_f1_0.8975.ckpt\"\ncheckpoint = \"..\/input\/plat2021-resnet50\/last.ckpt\"\n\nweight = torch.load(checkpoint)['state_dict']\nmodel.load_state_dict(fix_model_state_dict(weight))","6cc63c87":"model.cuda()\nmodel.eval()\n\npredictions = []\nfor batch in test_loader:\n    image = batch['image'].cuda()\n    with torch.no_grad():\n        outputs = model(image)\n        preds = outputs.argmax(1).detach().cpu().numpy()\n        predictions.append(preds)","e5e8fe13":"inv_labels_dict = {v: k for k, v in labels_dict.items()}\ninv_labels_dict","9aba312a":"sub['labels'] = np.concatenate(predictions)\nsub = sub.replace({\"labels\": inv_labels_dict})\nsub.to_csv('submission.csv', index=False)\nsub.head()","c00fbf94":"## Pytorch Starter - WIP \nThis notebook uses different model checkpoint than the original notebook below. Kindly upvote and appreciate the original notebook and author.\n\n* [Plant 2021 Pytorch Lightening Starter Inference](https:\/\/www.kaggle.com\/pegasos\/plant2021-pytorch-lightning-starter-inference)","ecec5b23":"# Inference","b732e295":"### Load images that have been pre-resized by AnkurSingh to speed up the learning process. https:\/\/www.kaggle.com\/c\/plant-pathology-2021-fgvc8\/discussion\/227032","ee4d8d6e":"# Define Dataset","695034a8":"# Define Model","cc50fa5a":"# Import","af55e263":"# Config"}}