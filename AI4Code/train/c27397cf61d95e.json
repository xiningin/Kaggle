{"cell_type":{"85d57b0b":"code","abf59ed0":"code","73e77b6e":"code","18f1e753":"code","ada280f7":"code","1cae966e":"code","8952a05d":"code","0c2965fc":"markdown","d32e92a5":"markdown","9f084b07":"markdown","203cee72":"markdown","9aad4ea2":"markdown","ffb9090c":"markdown","dc62bff4":"markdown"},"source":{"85d57b0b":"# standard lib\nimport pathlib\n\n# third party\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport scipy.signal as signal\nimport pywt\nimport librosa\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n!pip install pyts\nfrom pyts.image import RecurrencePlot, GramianAngularField, MarkovTransitionField\n!pip install gwpy\nfrom gwpy.timeseries import TimeSeries","abf59ed0":"def preprocess(sig: np.ndarray):\n    window = signal.tukey(sig_org.shape[-1])\n    sig_pp = sig*window\n    return sig_pp\n#     for i in range(3):\n#         ts = TimeSeries(sig[i,:], sample_rate=2048)\n#         window = signal.tukey(sig.shape[1])\n#         ts = ts * window\n#         ts = ts.whiten()\n\n#         if i==0:\n#             sig_pp = ts.reshape(1,sig.shape[1])\n#         else:\n#             sig_pp = np.concatenate([sig_pp, ts.reshape(1,sig.shape[1])], axis=0)\n#     return sig_pp\n\ndef jpeg_codec(spec):\n    out = spec.copy()\n    norm = ((spec-np.min(spec))\/(np.max(spec)-np.min(spec))*255).astype(np.uint8)\n    for i in range(3):\n        jpeg_enc = tf.image.encode_jpeg(norm[i,:,:].reshape(norm.shape[1],norm.shape[2],1))\n        jpeg_dec = tf.image.decode_jpeg(jpeg_enc)\n        out[i,:,:] = jpeg_dec.numpy().reshape(norm.shape[1], norm.shape[2])\n    return out.astype(np.uint8)\n\ndef jpeg_enc(spec):\n    norm = ((spec-np.min(spec))\/(np.max(spec)-np.min(spec))*255).astype(np.uint8)\n    \n    jpeg_enc0 = tf.image.encode_jpeg(norm[0,:,:].reshape(norm.shape[1],norm.shape[2],1))\n    jpeg_enc1 = tf.image.encode_jpeg(norm[1,:,:].reshape(norm.shape[1],norm.shape[2],1))\n    jpeg_enc2 = tf.image.encode_jpeg(norm[2,:,:].reshape(norm.shape[1],norm.shape[2],1))\n    return jpeg_enc0, jpeg_enc1, jpeg_enc2\n\ndef png_enc(spec):\n    norm = ((spec-np.min(spec))\/(np.max(spec)-np.min(spec))*255).astype(np.uint8)\n    \n    enc0 = tf.image.encode_png(norm[0,:,:].reshape(norm.shape[1],norm.shape[2],1))\n    enc1 = tf.image.encode_png(norm[1,:,:].reshape(norm.shape[1],norm.shape[2],1))\n    enc2 = tf.image.encode_png(norm[2,:,:].reshape(norm.shape[1],norm.shape[2],1))\n    return enc0, enc1, enc2\n\ndef resize(X):\n    return X\n#     for i in range(3):\n#         img = Image.fromarray(X[i])\n#         img = img.resize((img.width \/\/ 4, img.height \/\/ 4), Image.LANCZOS)\n#         img = np.asarray(img)\n#         if i==0:\n#             Y = img.reshape(1,img.shape[0],img.shape[1])\n#         else:\n#             Y = np.concatenate([Y,img.reshape(1,img.shape[0],img.shape[1])], axis=0)\n#     return Y\n\ndef feature_spectrogram(sig: np.ndarray):\n    f, t, spec = signal.spectrogram(sig, fs=2048, nfft=256, nperseg=35, mode='complex')\n    \n    spec_cross = spec[0]\/spec[1]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = P.reshape(1,P.shape[0],P.shape[1])\n    \n    spec_cross = spec[1]\/spec[2]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = np.concatenate([phase, P.reshape(1,P.shape[0],P.shape[1])], axis=0)\n    \n    spec_cross = spec[2]\/spec[0]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = np.concatenate([phase, P.reshape(1,P.shape[0],P.shape[1])], axis=0)\n    \n    spec = np.log10(np.abs(spec[:,:-1,1:-3]))\n    phase = phase[:,:-1,1:-3]\n    spec = resize(spec)\n    phase = resize(phase)\n\n    return spec, phase\n\ndef feature_mel_spectrogram(sig: np.ndarray):\n    for i in range(3):\n        F = librosa.feature.melspectrogram(sig[i] \/ max(sig[i]), sr=2048, n_mels=128, win_length=256, hop_length=32)\n        F = librosa.power_to_db(F)\n        if i==0:\n            spec = F.reshape(1,F.shape[0],F.shape[1])\n        else:\n            spec = np.concatenate([spec, F.reshape(1,F.shape[0],F.shape[1])], axis=0)\n            \n    spec = spec[:,:,1:]\n    spec = resize(spec)\n    return spec\n\ndef feature_cqt(sig: np.ndarray):\n    for i in range(3):\n        F = librosa.cqt(sig[i] \/ max(sig[i]), sr=2048, n_bins=128, hop_length=32, bins_per_octave=32)\n        # F = librosa.power_to_db(F)\n        if i==0:\n            spec = F.reshape(1,F.shape[0],F.shape[1])\n        else:\n            spec = np.concatenate([spec, F.reshape(1,F.shape[0],F.shape[1])], axis=0)\n            \n    spec_cross = spec[0]\/spec[1]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = P.reshape(1,P.shape[0],P.shape[1])\n    \n    spec_cross = spec[1]\/spec[2]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = np.concatenate([phase, P.reshape(1,P.shape[0],P.shape[1])], axis=0)\n    \n    spec_cross = spec[2]\/spec[0]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = np.concatenate([phase, P.reshape(1,P.shape[0],P.shape[1])], axis=0)\n    \n    spec = librosa.power_to_db(np.abs(spec[:,:,1:]))\n    phase = phase[:,:,1:]\n    spec = resize(spec)\n    phase = resize(phase)\n    \n    return spec, phase\n\ndef feature_vqt(sig: np.ndarray):\n    for i in range(3):\n        F = librosa.vqt(sig[i] \/ max(sig[i]), sr=2048, n_bins=128, hop_length=32, bins_per_octave=32)\n        if i==0:\n            spec = F.reshape(1,F.shape[0],F.shape[1])\n        else:\n            spec = np.concatenate([spec, F.reshape(1,F.shape[0],F.shape[1])], axis=0)\n            \n    spec_cross = spec[0]\/spec[1]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = P.reshape(1,P.shape[0],P.shape[1])\n    \n    spec_cross = spec[1]\/spec[2]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = np.concatenate([phase, P.reshape(1,P.shape[0],P.shape[1])], axis=0)\n    \n    spec_cross = spec[2]\/spec[0]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = np.concatenate([phase, P.reshape(1,P.shape[0],P.shape[1])], axis=0)\n    \n    spec = librosa.power_to_db(np.abs(spec[:,:,1:]))\n    phase = phase[:,:,1:]\n    spec = resize(spec)\n    phase = resize(phase)\n    \n    return spec, phase\n\ndef feature_wavelet(sig: np.ndarray):\n    cwt, freqs = pywt.cwt(sig, scales=np.arange(1, 31, 0.23), wavelet='cmor1.5-1.0', sampling_period=1\/2048, method='fft')\n    cwt = cwt.transpose(1,0,2)\n\n    spec_cross = cwt[0]\/cwt[1]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = P.reshape(1,P.shape[0],P.shape[1])\n    \n    spec_cross = cwt[1]\/cwt[2]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = np.concatenate([phase, P.reshape(1,P.shape[0],P.shape[1])], axis=0)\n    \n    spec_cross = cwt[2]\/cwt[0]\n    P = np.arctan2(spec_cross.imag, spec_cross.real)\n    phase = np.concatenate([phase, P.reshape(1,P.shape[0],P.shape[1])], axis=0)\n\n    spec = np.log10(np.abs(cwt[:,:-3,::32]))\n    phase = phase[:,:-3,::32]\n    spec = resize(spec)\n    phase = resize(phase)\n    \n    return spec, phase\n\ndef feature_rp(sig: np.ndarray):\n    for i in range(3):\n        rp = RecurrencePlot(threshold='point', percentage=20)\n        _, X = rp.fit_transform((np.arange(len(sig[i])),sig[i]))\n        \n        img = Image.fromarray(X)\n        img = img.resize((img.width \/\/ 32, img.height \/\/ 32), Image.LANCZOS)\n        # img = img.resize((img.width \/\/ 128, img.height \/\/ 128), Image.LANCZOS)\n        X = np.asarray(img)\n        \n        if i==0:\n            spec = X.reshape(1,X.shape[0],X.shape[1])\n        else:\n            spec = np.concatenate([spec, X.reshape(1,X.shape[0],X.shape[1])], axis=0)\n    return spec[:,::1, ::1]\n\ndef feature_gaf(sig: np.ndarray):\n    for i in range(3):\n        gaf = GramianAngularField(image_size=4096, method='summation')\n        _, X = gaf.fit_transform((np.arange(len(sig[i])),sig[i]))\n        \n        img = Image.fromarray(X)\n        img = img.resize((img.width \/\/ 32, img.height \/\/ 32), Image.LANCZOS)\n        # img = img.resize((img.width \/\/ 128, img.height \/\/ 128), Image.LANCZOS)\n        X = np.asarray(img)\n        \n        if i==0:\n            spec = X.reshape(1,X.shape[0],X.shape[1])\n        else:\n            spec = np.concatenate([spec, X.reshape(1,X.shape[0],X.shape[1])], axis=0)\n    return spec\n\ndef feature_mtf(sig: np.ndarray):\n    for i in range(3):\n        mtf = MarkovTransitionField(image_size = 4096, n_bins=2)\n        _, X = mtf.fit_transform((np.arange(len(sig[i])),sig[i]))\n        \n        img = Image.fromarray(X)\n        img = img.resize((img.width \/\/ 32, img.height \/\/ 32), Image.LANCZOS)\n        # img = img.resize((img.width \/\/ 128, img.height \/\/ 128), Image.LANCZOS)\n        X = np.asarray(img)\n        \n        if i==0:\n            spec = X.reshape(1,X.shape[0],X.shape[1])\n        else:\n            spec = np.concatenate([spec, X.reshape(1,X.shape[0],X.shape[1])], axis=0)\n    return spec","73e77b6e":"%%time\nroot_path = pathlib.Path('\/kaggle\/input\/g2net-gravitational-wave-detection')\ntrain_files = sorted(root_path.joinpath('train').glob('**\/*.*'))\ntest_files = sorted(root_path.joinpath('test').glob('**\/*.*'))\nprint(f\"train_num: {len(train_files)}, test_num: {len(test_files)}\")\nsub_file = pd.read_csv(root_path.joinpath('sample_submission.csv'))\n# print(sub_file.loc[:10,:])\ntrain_labels = pd.read_csv(root_path.joinpath('training_labels.csv'))\nprint(f\"label stats: \\n{train_labels['target'].value_counts()}\")\n\ntrain_target0_index = train_labels[train_labels[\"target\"]==0].index\ntrain_target1_index = train_labels[train_labels[\"target\"]==1].index","18f1e753":"%%time\nsig_file = pathlib.Path(train_files[train_target1_index[10000]])\nsig_org = np.load(sig_file)\n\nsig = preprocess(sig_org)\nspec, phase = feature_spectrogram(sig)\nmelspec = feature_mel_spectrogram(sig)\ncqt, cqt_ph = feature_cqt(sig)\nvqt, vqt_ph = feature_vqt(sig)\ncwt, cwt_ph = feature_wavelet(sig)\nrp = feature_rp(sig_org)\ngaf = feature_gaf(sig_org)\nmtf = feature_mtf(sig_org)\n\nfig, ax = plt.subplots(4, 9, sharex=True, sharey=True, figsize=(15, 8), dpi=100)\n\nax[0,0].imshow(spec   [0].transpose()); ax[0,0].set_title(\"amp(Hanford)\", fontsize=8)\nax[0,1].imshow(spec   [1].transpose()); ax[0,1].set_title(\"amp(Livingston)\", fontsize=8)\nax[0,2].imshow(spec   [2].transpose()); ax[0,2].set_title(\"amp(Virgo)\", fontsize=8)\nax[0,3].imshow(phase  [0].transpose()); ax[0,3].set_title(\"phase diff\\n(Han. - Liv.)\", fontsize=8)\nax[0,4].imshow(phase  [1].transpose()); ax[0,4].set_title(\"phase diff\\n(Liv. - Virgo)\", fontsize=8)\nax[0,5].imshow(phase  [2].transpose()); ax[0,5].set_title(\"phase diff\\n(Virgo - Han.)\", fontsize=8)\nax[0,6].imshow(melspec[0].transpose()); ax[0,6].set_title(\"melspec(Hanford)\", fontsize=8)\nax[0,7].imshow(melspec[1].transpose()); ax[0,7].set_title(\"melspec(Livingston)\", fontsize=8)\nax[0,8].imshow(melspec[2].transpose()); ax[0,8].set_title(\"melspec(Virgo)\", fontsize=8)\nax[1,0].imshow(cqt    [0].transpose()); ax[1,0].set_title(\"cqt(Hanford)\", fontsize=8)\nax[1,1].imshow(cqt    [1].transpose()); ax[1,1].set_title(\"cqt(Livingston)\", fontsize=8)\nax[1,2].imshow(cqt    [2].transpose()); ax[1,2].set_title(\"cqt(Virgo)\", fontsize=8)\nax[1,3].imshow(cqt_ph [0].transpose()); ax[1,3].set_title(\"cqt phase diff\\n(Han. - Liv.)\", fontsize=8)\nax[1,4].imshow(cqt_ph [1].transpose()); ax[1,4].set_title(\"cqt phase diff\\n(Liv. - Virgo)\", fontsize=8)\nax[1,5].imshow(cqt_ph [2].transpose()); ax[1,5].set_title(\"cqt phase diff\\n(Virgo - Han.)\", fontsize=8)\nax[1,6].imshow(vqt    [0].transpose()); ax[1,6].set_title(\"vqt(Hanford)\", fontsize=8)\nax[1,7].imshow(vqt    [1].transpose()); ax[1,7].set_title(\"vqt(Livingston)\", fontsize=8)\nax[1,8].imshow(vqt    [2].transpose()); ax[1,8].set_title(\"vqt(Virgo)\", fontsize=8)\nax[2,0].imshow(vqt_ph [0].transpose()); ax[2,0].set_title(\"vqt phase diff\\n(Han. - Liv.)\", fontsize=8)\nax[2,1].imshow(vqt_ph [1].transpose()); ax[2,1].set_title(\"vqt phase diff\\n(Liv. - Virgo)\", fontsize=8)\nax[2,2].imshow(vqt_ph [2].transpose()); ax[2,2].set_title(\"vqt phase diff\\n(Virgo - Han.)\", fontsize=8)\nax[2,3].imshow(cwt    [0].transpose()); ax[2,3].set_title(\"wavelet(Hanford)\", fontsize=8)\nax[2,4].imshow(cwt    [1].transpose()); ax[2,4].set_title(\"wavelet(Livingston)\", fontsize=8)\nax[2,5].imshow(cwt    [2].transpose()); ax[2,5].set_title(\"wavelet(Virgo)\", fontsize=8)\nax[2,6].imshow(cwt_ph [0].transpose()); ax[2,6].set_title(\"wavelet phase diff\\n(Han. - Liv.)\", fontsize=8)\nax[2,7].imshow(cwt_ph [1].transpose()); ax[2,7].set_title(\"wavelet phase diff\\n(Liv. - Virgo)\", fontsize=8)\nax[2,8].imshow(cwt_ph [2].transpose()); ax[2,8].set_title(\"wavelet phase diff\\n(Virgo - Han.)\", fontsize=8)\nax[3,0].imshow(rp     [0].transpose()); ax[3,0].set_title(\"Recurrence Plot\\n(Hanford)\", fontsize=8)\nax[3,1].imshow(rp     [1].transpose()); ax[3,1].set_title(\"Recurrence Plot\\n(Livingston)\", fontsize=8)\nax[3,2].imshow(rp     [2].transpose()); ax[3,2].set_title(\"Recurrence Plot\\n(Virgo)\", fontsize=8)\nax[3,3].imshow(gaf    [0].transpose()); ax[3,3].set_title(\"Gramian Angular Field\\n(Hanford)\", fontsize=8)\nax[3,4].imshow(gaf    [1].transpose()); ax[3,4].set_title(\"Gramian Angular Field\\n(Livingston)\", fontsize=8)\nax[3,5].imshow(gaf    [2].transpose()); ax[3,5].set_title(\"Gramian Angular Field\\n(Virgo)\", fontsize=8)\nax[3,6].imshow(mtf    [0].transpose()); ax[3,6].set_title(\"Markov Transition Field\\n(Hanford)\", fontsize=8)\nax[3,7].imshow(mtf    [1].transpose()); ax[3,7].set_title(\"Markov Transition Field\\n(Livingston)\", fontsize=8)\nax[3,8].imshow(mtf    [2].transpose()); ax[3,8].set_title(\"Markov Transition Field\\n(Virgo)\", fontsize=8)\n\nfig.suptitle(f'{sig_file.name}, (target=1)')\n\nfig.show()","ada280f7":"%%time\nfrom tqdm.auto import tqdm\n\ntrain = True\nfile_num = 100\npart = 0\n\nif train:\n    part_indexes = []\n    train_labels_dict = train_labels.set_index(\"id\").to_dict()[\"target\"]\n    for idx in range(0, len(train_files), file_num):\n        begin_index = idx\n        end_index = idx + file_num\n        if end_index > len(train_files):\n            end_index = len(train_files)\n        part_indexes.append((begin_index, end_index))\n    # print(part_indexes)\n    begin_index, end_index = part_indexes[part]\n    target_files = train_files[begin_index:end_index]\n    prefix = \"train\"\nelse:\n    part_indexes = []\n    for idx in range(0, len(test_files), file_num):\n        begin_index = idx\n        end_index = idx + file_num\n        if end_index > len(test_files):\n            end_index = len(test_files)\n        part_indexes.append((begin_index, end_index))\n    # print(part_indexes)\n    begin_index, end_index = part_indexes[part]\n    target_files = test_files[begin_index:end_index]\n    prefix = \"test\"\n\n# \u4e0b\u8a18\u306e\u95a2\u6570\u3092\u4f7f\u3046\u3068\u5024\u3092 tf.Example \u3068\u4e92\u63db\u6027\u306e\u6709\u308b\u578b\u306b\u5909\u63db\u3067\u304d\u308b\ndef _bytes_feature(value):\n    \"\"\"string \/ byte \u578b\u304b\u3089 byte_list \u3092\u8fd4\u3059\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"float \/ double \u578b\u304b\u3089 float_list \u3092\u8fd4\u3059\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"bool \/ enum \/ int \/ uint \u578b\u304b\u3089 Int64_list \u3092\u8fd4\u3059\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\nwith tf.io.TFRecordWriter(f'{prefix}_{begin_index}to{end_index}.tfrec') as writer:\n    for sig_path in tqdm(target_files):\n        sig_org = np.load(sig_path).astype(np.float32)\n        sig = preprocess(sig_org)\n        vqt, vqt_ph = feature_vqt(sig)\n        vqt0   ,vqt1   ,vqt2    = jpeg_enc(vqt)\n        vqt0_ph,vqt1_ph,vqt2_ph = jpeg_enc(vqt_ph)\n        # vqt0   ,vqt1   ,vqt2    = png_enc(vqt)\n        # vqt0_ph,vqt1_ph,vqt2_ph = png_enc(vqt_ph)\n        feature = {\n            'vqt0'    : _bytes_feature(vqt0),\n            'vqt1'    : _bytes_feature(vqt1),\n            'vqt2'    : _bytes_feature(vqt2),\n            'vqt0_ph' : _bytes_feature(vqt0_ph),\n            'vqt1_ph' : _bytes_feature(vqt1_ph),\n            'vqt2_ph' : _bytes_feature(vqt2_ph),\n            'image_id': _bytes_feature(str(sig_path.stem).encode('utf-8')),\n        }\n        if train:\n            feature['target'] = _int64_feature(train_labels_dict[sig_path.stem]), # train only\n        example = tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()\n        writer.write(example)","1cae966e":"!ls -ltra","8952a05d":"tfrec_format = {\n    'vqt0'    : tf.io.FixedLenFeature([], tf.string),\n    'vqt1'    : tf.io.FixedLenFeature([], tf.string),\n    'vqt2'    : tf.io.FixedLenFeature([], tf.string),\n    'vqt0_ph' : tf.io.FixedLenFeature([], tf.string),\n    'vqt1_ph' : tf.io.FixedLenFeature([], tf.string),\n    'vqt2_ph' : tf.io.FixedLenFeature([], tf.string),\n    'image_id': tf.io.FixedLenFeature([], tf.string),\n    'target': tf.io.FixedLenFeature([], tf.int64),\n}\n    \ndef _parse_image_function(example_proto):\n    # \u5165\u529b\u306e tf.Example \u306e\u30d7\u30ed\u30c8\u30b3\u30eb\u30d0\u30c3\u30d5\u30a1\u3092\u4e0a\u8a18\u306e\u30c7\u30a3\u30af\u30b7\u30e7\u30ca\u30ea\u3092\u4f7f\u3063\u3066\u89e3\u91c8\n    return tf.io.parse_single_example(example_proto, tfrec_format)\n\nds = tf.data.TFRecordDataset([f'{prefix}_{begin_index}to{end_index}.tfrec'])\nds = ds.map(_parse_image_function)\n\nfor features in ds.take(1):\n    vqt0    = tf.image.decode_jpeg(features['vqt0']).numpy()\n    vqt1    = tf.image.decode_jpeg(features['vqt1']).numpy()\n    vqt2    = tf.image.decode_jpeg(features['vqt2']).numpy()\n    vqt = np.concatenate([vqt0,vqt1,vqt2], axis=2)\n    print(f\"vqt = shape: {vqt.shape}, \\nvalues: {vqt}\")\n    vqt0_ph = tf.image.decode_jpeg(features['vqt0_ph']).numpy()\n    vqt1_ph = tf.image.decode_jpeg(features['vqt1_ph']).numpy()\n    vqt2_ph = tf.image.decode_jpeg(features['vqt2_ph']).numpy()\n    vqt_ph = np.concatenate([vqt0_ph,vqt1_ph,vqt2_ph], axis=2)\n    print(f\"vqt_ph = shape: {vqt_ph.shape}, \\nvalues: {vqt_ph}\")\n    image_id = features['image_id'].numpy().decode('utf-8')\n    print(f\"image_id = {image_id}\")\n    if train:\n        target = features['target'].numpy()\n        print(f\"target = {target}\")","0c2965fc":"### functions","d32e92a5":"### TFRecord Write","9f084b07":"### TFRecord Read","203cee72":"### imports","9aad4ea2":"### This notebook Summary\n\nThis notebook is for feature computation, converting time series data into 128x128 formatted image data.<br>\n(\u3053\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u306f\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u3092128x128\u306e\u6574\u5f62\u3055\u308c\u305f\u753b\u50cf\u30c7\u30fc\u30bf\u306b\u5909\u63db\u3059\u308b\u3001\u7279\u5fb4\u91cf\u8a08\u7b97\u7528\u306e\u30ce\u30fc\u30c8\u30d6\u30c3\u30af\u3067\u3059\u3002)<br>\n\nThe data size of 128x128 is too large, so we published 32x32.<br>\n(128x128\u306f\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba\u304c\u5927\u304d\u3059\u304e\u308b\u305f\u3081\u300132x32\u3092\u516c\u958b\u3057\u3066\u3044\u307e\u3057\u305f\u304c\u3001)<br>\nHowever, 128x128 is output as jpeg because it can be encoded as jpeg and the size is practical.<br>\n(jpeg\u3067\u7b26\u53f7\u5316\u3059\u308c\u3070\u5b9f\u7528\u7684\u306a\u30b5\u30a4\u30ba\u306b\u306a\u308b\u305f\u3081\u3001128x128\u306fjpeg\u3067\u51fa\u529b\u3057\u3066\u3044\u307e\u3059\u3002)<br>\n\nFor 32x32, please refer to version 21 of this notebook.<br>\n(32x32\u306f\u3053\u306enotebook\u306eversion 21\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002)<br>\nFor 128x128, please refer to version 22 of this notebook.<br>\n(128x128\u306f\u3053\u306enotebook\u306eversion 22\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002)<br>\n\nThis notebook is also part of the imaging of all samples. For the full data set, please refer to the dataset below.<br>\n(\u307e\u305f\u3053\u306enotebook\u306f\u5168\u30b5\u30f3\u30d7\u30eb\u306e\u753b\u50cf\u5316\u306e\u4e00\u90e8\u3068\u306a\u3063\u3066\u3044\u307e\u3059\u3002\u5168\u30c7\u30fc\u30bf\u306f\u4ee5\u4e0b\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u53c2\u7167\u304f\u3060\u3055\u3044\u3002)<br>\n- [G2Net VQT features 32x32 and 128x128](https:\/\/www.kaggle.com\/snkmr0221\/g2net-vqt-features-32x32-img)\n\n![image.png](attachment:0977e011-dfe9-46b2-872a-11655c364640.png)<br>\n\nFrom the time series data of 3 sites and 4096 samples, we calculate 36 image data. The list of image data is as follows.<br>\n(3\u30b5\u30a4\u30c8\u30014096\u30b5\u30f3\u30d7\u30eb\u306e\u6642\u7cfb\u5217\u30c7\u30fc\u30bf\u304b\u3089\u300136\u500b\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u30ea\u30b9\u30c8\u306f\u4ee5\u4e0b\u3067\u3059\u3002)<br>\n- 1-3. Amplitude spectrum for each site(\u5404\u30b5\u30a4\u30c8\u306e\u632f\u5e45\u30b9\u30da\u30af\u30c8\u30eb)\n- 4-6. phase difference spectrum for each site(\u5404\u30b5\u30a4\u30c8\u9593\u306e\u4f4d\u76f8\u5dee\u30b9\u30da\u30af\u30c8\u30eb)\n- 7-9. mel frequency spectrum for each site(\u5404\u30b5\u30a4\u30c8\u306e\u30e1\u30eb\u5468\u6ce2\u6570\u30b9\u30da\u30af\u30c8\u30eb)\n- 10-12. CQT amplitude spectrum for each site(\u5404\u30b5\u30a4\u30c8\u306eCQT\u632f\u5e45\u30b9\u30da\u30af\u30c8\u30eb)\n- 13-15. CQT phase difference spectrum between each site(\u5404\u30b5\u30a4\u30c8\u9593\u306eCQT\u4f4d\u76f8\u5dee\u30b9\u30da\u30af\u30c8\u30eb)\n- 16-18. VQT amplitude spectrum for each site(\u5404\u30b5\u30a4\u30c8\u306eVQT\u632f\u5e45\u30b9\u30da\u30af\u30c8\u30eb)\n- 19-21. VQT phase difference spectrum between each site(\u5404\u30b5\u30a4\u30c8\u9593\u306eVQT\u4f4d\u76f8\u5dee\u30b9\u30da\u30af\u30c8\u30eb)\n- 22-24. wavelet transform amplitude spectrum for each site(\u5404\u30b5\u30a4\u30c8\u306ewavelet\u5909\u63db\u306e\u632f\u5e45\u30b9\u30da\u30af\u30c8\u30eb)\n- 25-27. phase difference spectrum of wavelet transform between each site(\u5404\u30b5\u30a4\u30c8\u9593\u306ewavelet\u5909\u63db\u306e\u4f4d\u76f8\u5dee\u30b9\u30da\u30af\u30c8\u30eb)\n- 28-30. recurrence plots for each site(\u5404\u30b5\u30a4\u30c8\u306eReccurence Plot)\n- 31-33. Gramian Angular Field for each site(\u5404\u30b5\u30a4\u30c8\u306eGramian Angular Field)\n- 34-36. Markov Transition Field for each site(\u5404\u30b5\u30a4\u30c8\u306eMarkov Transition Field)\n\nVisualization of these image data was performed for one part of the sample file.<br>\n(1\u90e8\u306e\u30b5\u30f3\u30d7\u30eb\u30d5\u30a1\u30a4\u30eb\u306b\u3064\u3044\u3066\u3001\u3053\u308c\u3089\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u53ef\u8996\u5316\u3092\u5b9f\u65bd\u3057\u307e\u3057\u305f\u3002)<br>\nIn this image data, VQT seemed to have the most obvious features in the graph.<br>\n(\u3053\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u306e\u4e2d\u3067\u3001VQT\u304c\u30b0\u30e9\u30d5\u4e0a\u6700\u3082\u308f\u304b\u308a\u3084\u3059\u3044\u7279\u5fb4\u3092\u6301\u3063\u3066\u3044\u308b\u3088\u3046\u306b\u898b\u3048\u307e\u3057\u305f\u3002)<br>\n\nIn addition, it is very time consuming to perform all the image data calculations.<br>\n(\u307e\u305f\u3059\u3079\u3066\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u8a08\u7b97\u51e6\u7406\u3092\u5b9f\u884c\u3059\u308b\u306e\u306f\u3001\u3068\u3066\u3082\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u3002)<br>\nTherefore, in the end, this notebook will output only a part of the VQT data.<br>\n(\u305d\u306e\u305f\u3081\u3001\u6700\u7d42\u7684\u306b\u306f\u3053\u306enotebook\u3067\u306f\u3001VQT\u30c7\u30fc\u30bf\u306e\u4e00\u90e8\u306e\u307f\u3092\u51fa\u529b\u3057\u307e\u3059\u3002)<br>\nIf you want to use image data from other data, you need to modify the NOTEBOOK and run it. <br>\n(\u4ed6\u306e\u30c7\u30fc\u30bf\u306e\u753b\u50cf\u30c7\u30fc\u30bf\u3092\u4f7f\u3046\u5834\u5408\u306f\u3001notebook\u3092\u4fee\u6b63\u3057\u3066\u5b9f\u884c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002)<br>\n\n### References\n\nFor more information about Mel frequency spectrum, please refer to the following notebook.<br>\n(\u30e1\u30eb\u5468\u6ce2\u6570\u30b9\u30da\u30af\u30c8\u30eb\u306b\u3064\u3044\u3066\u306f\u3001\u4ee5\u4e0b\u306enotebook\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002)<br>\n- https:\/\/www.kaggle.com\/yasufuminakama\/g2net-spectrogram-generation-train\n\nI have never heard of the 28-36 process before, but I am referring to the following notebook.<br>\n(28-36\u306e\u51e6\u7406\u306b\u3064\u3044\u3066\u306f\u3001\u521d\u3081\u3066\u77e5\u308a\u307e\u3057\u305f\u304c\u3001\u4ee5\u4e0b\u306enotebook\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002)<br>\n- https:\/\/www.kaggle.com\/abhishek1aa\/g2net-exploring-data-representations\n\nFor preprocessing, I refer to the following notebook.<br>\n(\u524d\u51e6\u7406\u306b\u3064\u3044\u3066\u306f\u4ee5\u4e0b\u306enotebook\u3092\u53c2\u8003\u306b\u3057\u3066\u3044\u307e\u3059\u3002)<br>\n- https:\/\/www.kaggle.com\/mistag\/data-preprocessing-with-gwpy","ffb9090c":"### get file list and target indexes","dc62bff4":"### visualize"}}