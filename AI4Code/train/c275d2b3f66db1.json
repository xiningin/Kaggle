{"cell_type":{"a1622da1":"code","1e5084c2":"code","2392f1a9":"code","1cafd454":"code","37f662e9":"code","606571a2":"code","e178db9a":"code","3f072b6d":"code","5a7a38f3":"code","2f229e8f":"code","612a6043":"code","61c8f430":"markdown","33dee9ac":"markdown","9f052d2e":"markdown","345f6425":"markdown","3b8ef448":"markdown","0c28bbb2":"markdown","78ebccec":"markdown"},"source":{"a1622da1":"import torch  # \tEl paquete PyTorch de nivel superior y la biblioteca tensorial.\nimport torch.nn as nn   #\tUn subpaquete que contiene m\u00f3dulos y clases extensibles para construir redes neuronales.\nimport torch.optim as optim # Un subpaquete que contiene operaciones de optimizaci\u00f3n est\u00e1ndar como SGD y Adam.\nimport torch.nn.functional as F # Una interfaz funcional que contiene operaciones t\u00edpicas utilizadas para construir redes neuronales como funciones de p\u00e9rdida y convoluciones.\nimport torchvision # Un paquete que proporciona acceso a conjuntos de datos populares, arquitecturas de modelos y transformaciones de im\u00e1genes para la visi\u00f3n por computadora.\nimport torchvision.transforms as transforms # Una interfaz que contiene transformaciones comunes para el procesamiento de im\u00e1genes.\nimport torchvision.datasets as dset\nfrom torch.utils import data as D\n\n# Otras importaciones\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n#from plotcm import plot_confusion_matrix\n\nimport pdb\ntorch.set_printoptions(linewidth=120)","1e5084c2":"transform = transforms.Compose(\n    [transforms.Resize((60,60)),\n     transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ndata = dset.ImageFolder(root=\"..\/input\/the-simpsons-characters-dataset\/simpsons_dataset\/simpsons_dataset\",transform=transform)\ndataloader = torch.utils.data.DataLoader(data, batch_size=16,shuffle=True,num_workers=2)\n\ndataiter = iter(dataloader)\nimages, labels = dataiter.next()","2392f1a9":"type(data)","1cafd454":"type(trainset)","37f662e9":"data.len=len(data)\ntrain_len = int(0.7*data.len)\ntest_len = data.len - train_len\ntrainset, testset = D.random_split(data, lengths=[train_len, test_len])","606571a2":"def imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.figure(figsize=(15,15))\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\nimshow(torchvision.utils.make_grid(images))","e178db9a":"class Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2)\n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n        \n        self.fc1 = nn.Linear(in_features=32 * 15 * 15, out_features=200)\n        self.fc2 = nn.Linear(in_features=200, out_features=90)\n        self.out = nn.Linear(in_features=90, out_features=42)\n        \n    def forward(self, t):\n        # (1) input layer\n        t = t\n        # (2) hidden conv layer\n        t = self.conv1(t)\n        t = F.relu(t)\n        t = F.max_pool2d(t, kernel_size=2,stride=2)\n\n        # (3) hidden conv layer\n        t = self.conv2(t)\n        t = F.relu(t)\n        t = F.max_pool2d(t, kernel_size=2,stride=2)\n\n        # (4) hidden linear layer\n        t = t.reshape(-1, 32 * 15 * 15)\n        t = self.fc1(t)\n        t = F.relu(t)\n\n        # (5) hidden linear layer\n        t = self.fc2(t)\n        t = F.relu(t)\n\n        # (6) output layer\n        t = self.out(t)\n        #t = F.softmax(t, dim=1)\n\n        return t","3f072b6d":"#Funcion predicciones \ndef get_num_correct(preds, labels):\n    return preds.argmax(dim=1).eq(labels).sum().item()","5a7a38f3":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnetwork = Network()\nnetwork.to(device)\noptimizer = optim.Adam(network.parameters(), lr=0.001)\ntrain_loader = torch.utils.data.DataLoader(\n    trainset\n    ,batch_size=500\n    ,shuffle=True\n)\n\nfor epoch in range(20):\n\n    total_loss = 0\n    total_correct = 0\n\n    for batch in train_loader: # Get Batch\n        images, labels = batch \n        images = images.to(device)\n        labels = labels.to(device)\n\n        preds = network(images) # Pass Batch\n        loss = F.cross_entropy(preds, labels) # Calculate Loss\n\n        optimizer.zero_grad()\n        loss.backward() # Calculate Gradients\n        optimizer.step() # Update Weights\n\n        total_loss += loss.item()\n        total_correct += get_num_correct(preds, labels)\n\n    print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)","2f229e8f":"trainloader = torch.utils.data.DataLoader(trainset, \n                                         batch_size=500,\n                                         shuffle=False)\n\ntotal_correct = 0\ntotal_images = 0\nconfusion_matrix = np.zeros([42,42], int)\nwith torch.no_grad():\n    for data in trainloader:\n        images, labels = data\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = network(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total_images += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n        for i, l in enumerate(labels):\n            confusion_matrix[l.item(), predicted[i].item()] += 1 \n\nmodel_accuracy = total_correct \/ total_images * 100\nprint('Model accuracy on {0} train images: {1:.2f}%'.format(total_images, model_accuracy))","612a6043":"testloader = torch.utils.data.DataLoader(testset, \n                                         batch_size=500,\n                                         shuffle=False)\n\ntotal_correct = 0\ntotal_images = 0\nconfusion_matrix = np.zeros([42,42], int)\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = network(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total_images += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n        for i, l in enumerate(labels):\n            confusion_matrix[l.item(), predicted[i].item()] += 1 \n\nmodel_accuracy = total_correct \/ total_images * 100\nprint('Model accuracy on {0} test images: {1:.2f}%'.format(total_images, model_accuracy))","61c8f430":"### Lectura de datos Train\n\nLas im\u00e1genes se encuentran en carpetas separadsd por personajes con torchvision.datasets leemos cada carpeta y se asigna una categor\u00eda a cada personaje. Dado que las im\u00e1genes tienen distinto tama\u00f1o se escalaron a 60x60 pixeles, adem\u00e1s se estandarizaron y convertidas en tensor.","33dee9ac":"### Librer\u00edas","9f052d2e":"### M\u00e9tricas","345f6425":"### Entrenando a la Red\n\nUtilizamos lotes de 500 im\u00e1genes, una tasa de aprendizaje de 0.001 y una funci\u00f3n de perdida cross_entropy.","3b8ef448":"### Construcci\u00f3n CNN\n\nDado que las im\u00e1genes son a color en la primera convoluci\u00f3n entran 3 canales, utilizaremos un Kernel de 5 y padding de 2.","0c28bbb2":"## Clasificador con Pytorch CNN\n\nSe realiz\u00f3 un una red neuronal convolucional de 6 capas dos convolucionales y 2 dos capas lineales cons las respectivas capa de entrada y salida. ","78ebccec":"### Gr\u00e1fica de un lote de 16 im\u00e1genes. "}}