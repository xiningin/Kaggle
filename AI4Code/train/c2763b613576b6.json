{"cell_type":{"83f895e4":"code","cf85d3b2":"code","d456578a":"code","98342754":"code","52374681":"code","208e9f57":"code","b4051437":"code","0bf0e856":"code","6629ee7b":"code","e3ccf80f":"code","c6ec7fe9":"code","b6060f89":"code","313c77d5":"code","02d167f3":"code","1a6b0a3d":"code","b2422aab":"code","ce85794e":"code","657eb78f":"code","f68c6f3c":"code","ccf28a72":"code","e532dcb8":"code","1f1cf69e":"markdown","388828b8":"markdown","cd3214e3":"markdown","4c5e81f9":"markdown","06d4a5c7":"markdown","52a0f0fd":"markdown","29b1ff28":"markdown"},"source":{"83f895e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom imblearn.over_sampling import RandomOverSampler,SMOTEN\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\nfrom keras.models import Model\nimport kerastuner as kt\nfrom keras.applications.mobilenet import preprocess_input\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input,Dense\nfrom keras.layers.merge import concatenate\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf85d3b2":"expression=pd.read_csv('..\/input\/facialexpressionrecognition\/fer2013.csv')\nexpression","d456578a":"expression.emotion.unique()","98342754":"len(expression['pixels'][0].split())","52374681":"emot_training=expression.loc[expression['Usage']=='Training']\nemot_test=expression.loc[expression['Usage']=='PrivateTest']\nemot_valid=expression.loc[expression['Usage']=='PublicTest']","208e9f57":"pd.concat([emot_training['emotion'].value_counts(),emot_valid['emotion'].value_counts(),emot_test['emotion'].value_counts()],axis=1,keys=['Training','Validation','Testing'])","b4051437":"dup_emo=emot_training['emotion']\ndup_train=emot_training.drop('emotion',axis=1)\n\ndup_emo_valid=emot_valid['emotion']\ndup_valid=emot_valid.drop('emotion',axis=1)\n\nsampling_dict_1={0:3995,1:1500,2:4097,3:7215,4:4830,5:3171,6:4965}\n# sampling_dict_2={0:3995,1:1500,2:4097,3:4000,4:4000,5:3171,6:4000}\nover_sample=SMOTEN(sampling_strategy=sampling_dict_1,random_state=101)\ndup_train,dup_emo=over_sample.fit_resample(dup_train.values,dup_emo.values)\n\nsampling_dict_2={0:467,1:200,2:496,3:895,4:653,5:415,6:607}\nover_sample_2=SMOTEN(sampling_strategy=sampling_dict_2,random_state=101)\ndup_valid,dup_emo_valid=over_sample_2.fit_resample(dup_valid.values,dup_emo_valid.values)\n# under_sample=RandomUnderSampler(sampling_strategy=sampling_dict_2,random_state=101)\n# steps=[('over',over_sample),('under',under_sample)]\n# pipe=Pipeline(steps)\n# dup,dup_emo=pipe.fit_resample(dup.values,dup_emo.values)","0bf0e856":"emot_training=pd.DataFrame(dup_train,columns=['pixels','Usage'])\nemot_training['emotion']=dup_emo\n\nemot_valid=pd.DataFrame(dup_valid,columns=['pixels','Usage'])\nemot_valid['emotion']=dup_emo_valid","6629ee7b":"pd.concat([emot_training['emotion'].value_counts(),emot_valid['emotion'].value_counts()],axis=1)","e3ccf80f":"plt.figure(figsize=(12,6))\nfor each_image in range(1,10):\n    temp=emot_training['pixels'][each_image].split()\n    for i in range(len(temp)):\n        temp[i]=int(temp[i])\n    plt.subplot(3,3,each_image)\n    plt.imshow(np.array(temp).reshape(48,48))","c6ec7fe9":"train_emotions=emot_training['emotion']\ntrain_emotions=keras.utils.to_categorical(train_emotions)\n\ntest_emotions=emot_test['emotion']\ntest_emotions=keras.utils.to_categorical(test_emotions)\n\nvalid_emotions=emot_valid['emotion']\nvalid_emotions=keras.utils.to_categorical(valid_emotions)\n","b6060f89":"train_images=np.uint8(emot_training['pixels'].str.split().tolist())\ntrain_images=train_images.reshape((emot_training.shape[0],48,48,1))\ntrain_images=train_images.astype('float32')\/255\n\ntest_images=np.uint8(emot_test['pixels'].str.split().tolist())\ntest_images=test_images.reshape((emot_test.shape[0],48,48,1))\ntest_images=test_images.astype('float32')\/255\n\nvalid_images=np.uint8(emot_valid['pixels'].str.split().tolist())\nvalid_images=valid_images.reshape((emot_valid.shape[0],48,48,1))\nvalid_images=valid_images.astype('float32')\/255\n","313c77d5":"plt.imshow(test_images[0])","02d167f3":"model_1=keras.Sequential([\n    keras.Input(train_images.shape[1:]),\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.Flatten(),\n\n    layers.Dense(units=192,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(192,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(7,activation='softmax')\n])\n\nopt=keras.optimizers.Adam(\n    learning_rate=0.01,\n#     beta_1=0.91\n)  \n\nmodel_1.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n    \n    \nmodel_2=keras.Sequential([\n    keras.Input(train_images.shape[1:]),\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.Flatten(),\n\n    layers.Dense(units=128,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(128,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(7,activation='softmax')\n])\n\nopt=keras.optimizers.Adam(\n    learning_rate=0.001,\n    beta_1=0.91\n)  \n\nmodel_2.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)    \n\n\nmodel_3=keras.Sequential([\n    keras.Input(train_images.shape[1:]),\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(64,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n#     layers.Conv2D(128,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.Conv2D(256,kernel_size=3,activation='relu',padding='same'),\n    layers.MaxPooling2D(pool_size=(2,2)),\n\n    layers.Flatten(),\n\n    layers.Dense(units=32,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(32,activation='relu'),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n\n    layers.Dense(7,activation='softmax')\n])\n\nopt=keras.optimizers.Adam(\n    learning_rate=0.01,\n    beta_1=0.95\n)  \n\nmodel_3.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n    \nmodels=[model_1,model_2,model_3]\nepochs_list=[25,25,25]","1a6b0a3d":"# def fit_model(train_x,train_y,i):\n#     model=models[i]\n    \n#     history=model.fit(train_x,train_y,epochs=epochs_list[i],verbose=0)\n    \n#     return model\n\n# for i in range(3):\n#     model=fit_model(train_images,train_emotions,i)\n    \n#     filename='model\/model_' + str(i+4) + '.h5'\n    \n#     model.save(filename)\n    \n#     print('Saved' + filename)\n    ","b2422aab":"def load_all_models(n_models):\n    all_models=[]\n    for i in range(3):\n        filename='..\/input\/ensemble-models\/model_' + str(i+4) + '.h5'\n        model=load_model(filename)\n        all_models.append(model)\n        print(filename + 'loaded')\n        \n    return all_models\n\ndef stacked_model(members):\n    for i in range(len(members)):\n        model=members[i]\n        for layer in model.layers:\n            layer.trainable=False\n            layer._name = 'ensemble_' + str(i+4) + '_' + layer.name\n            \n    ensemble_input=[model.input for model in members]\n    ensemble_output=[model.output for model in members]\n\n    merge=concatenate(ensemble_output)\n    hidden=Dense(units=128,activation='relu')(merge)\n    hidden=Dense(units=128,activation='relu')(hidden)\n    hidden=Dense(units=128,activation='relu')(hidden)\n    output=Dense(units=7,activation='softmax')(hidden)\n\n    model=Model(inputs=ensemble_input,outputs=output)\n    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n    \n    return model\n\ndef fit_stacked_model(model,inputX,inputY):\n    X=[inputX for _ in range(len(model.input))]\n#     inputy_enc=to_categorical(inputY)\n    \n    model.fit(X,inputY,epochs=25,verbose=0)\n    \ndef predict_stacked_model(model,inputx):\n    X=[inputx for _ in range(len(model.input))]\n    return model.predict(X,verbose=0)\n\nmembers=load_all_models(3)\nstacked_models=stacked_model(members)\n\nfit_stacked_model(stacked_models,valid_images,valid_emotions)\n\nyhat=predict_stacked_model(stacked_models,valid_images)\n    ","ce85794e":"stacked_models.input","657eb78f":"yhat2=np.argmax(yhat,axis=1)\nacc=accuracy_score(np.argmax(valid_emotions,axis=1),yhat2)\nacc","f68c6f3c":"yhat3=predict_stacked_model(stacked_models,test_images)\nacc=accuracy_score(np.argmax(test_emotions,axis=1),np.argmax(yhat3,axis=1))\nacc","ccf28a72":"yhat4=predict_stacked_model(stacked_models,train_images)\nprint(classification_report(test_emotions,to_categorical(np.argmax(yhat3,axis=1))))\nprint(classification_report(train_emotions,to_categorical(np.argmax(yhat4,axis=1))))","e532dcb8":"def map_emo(n):\n    emotions_list = {0:'angry',1:'disgust',2:'fear',3:'happy',4:'sad',5:'surprise',6:'neutral'}\n    return emotions_list[n]\n\n\ndef pred(image):\n    inp=image.reshape(1,48,48,1)\n    \n    img=[inp for _ in stacked_models.input]\n    \n    print(map_emo(np.argmax(stacked_models.predict(img))))\n    \n    plt.imshow(image)\n\npred(train_images[3897])","1f1cf69e":"**Since the data for each category is not evenly distributed, we will do some random sampling to increase the size of data for certain caetgories using imblearn library.**","388828b8":"**We use stacked models for prediction of our data.\nI have used 3 different neural models an stacked them up on another neural network.**","cd3214e3":"**We have a test accuracy of 64%+**","4c5e81f9":"**The data is distributed across training,testing and validation sets. Thus, we will seperate that data.**","06d4a5c7":"**We will import the datasets from fer2013.csv dataset from Kaggle.**","52a0f0fd":"**We will now look at the data different distribution of data for test,validation and training data for each category of image.**","29b1ff28":"**Each pixel row has 2304 values which can be broken down into 48*48 images**"}}