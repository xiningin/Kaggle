{"cell_type":{"5e086e60":"code","ba281b4d":"code","17102bc4":"code","f76afc40":"code","561249e8":"code","a7159ce1":"code","023c0bf7":"code","d48edfcd":"code","5bcc1324":"code","a1da1221":"code","7094da7a":"code","2a3cb5a5":"code","1189e007":"code","0294578c":"code","46487aaf":"code","3edd50fa":"code","a16ccec0":"code","c3ef61fb":"code","7845d9e0":"code","a1f2fcb9":"code","ae663142":"code","16aed282":"code","78508ab7":"code","d7f352d5":"code","f57175bf":"code","f9b47e4c":"code","10fe6919":"code","80e24d1c":"code","c7be4a8b":"code","eb5a8e38":"code","f2d8a3a7":"code","1c0a2491":"code","851b799c":"code","dd50a4f5":"code","f5b5bb03":"code","bc4f4ab8":"code","c2fa278c":"code","9c603240":"code","7a94e25a":"code","374768f2":"code","15d45015":"code","c8e7cdef":"code","67f9b8c2":"code","70599b58":"code","33b9639d":"code","50eefe52":"code","0f9ee133":"code","27f46532":"code","3999410b":"code","45ee5e37":"code","64fe3751":"code","91ec42dd":"code","352a46fa":"code","bf438fbd":"code","8f0d6389":"code","8d6bbfa5":"code","29ad3674":"code","c6309784":"code","6012a9f1":"code","fe09b305":"code","6749639d":"code","6cfbbbfa":"code","27c7c199":"code","b8788a6e":"code","5eadf2ab":"code","e731c450":"code","3d7ca954":"code","fac2d4ad":"code","c576982f":"code","bff40506":"code","f999d8a5":"code","81e2671f":"code","3892e022":"code","2fb3f59e":"code","ca4f6a52":"markdown","8f11ade4":"markdown","7e73c27b":"markdown","8c898076":"markdown","61205aeb":"markdown","9f3ee9af":"markdown","4b8f014f":"markdown","3127ed00":"markdown","415c37f0":"markdown","573d9789":"markdown","23864420":"markdown","96bd3722":"markdown","46135055":"markdown","93c47f86":"markdown","65cf8f9b":"markdown","ca6f772a":"markdown","dac5c898":"markdown","551b0248":"markdown","f04c8c19":"markdown","e624e6cb":"markdown","9b58e392":"markdown","3cafcce8":"markdown","c2733c61":"markdown","940864f6":"markdown","a68a25e2":"markdown","609c4606":"markdown","2d6d3d77":"markdown","76b772ad":"markdown","20bd99a3":"markdown","3ed13332":"markdown","c66bebda":"markdown","f148777a":"markdown","ce574eeb":"markdown","882868e0":"markdown","85a7b16b":"markdown","8dde9ba2":"markdown","56bb6218":"markdown","6d780038":"markdown","487d6b21":"markdown","e8ebfdde":"markdown","e0dfc273":"markdown","ced6f2b0":"markdown","775344a0":"markdown","8b94e044":"markdown","880f8838":"markdown","6e37635a":"markdown","cdef1870":"markdown","8fd35907":"markdown","5c99caa8":"markdown"},"source":{"5e086e60":"import seaborn as sns\nimport matplotlib.pyplot as plt","ba281b4d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","17102bc4":"car = pd.read_csv(\"\/kaggle\/input\/car-price\/CarPrice_Assignment.csv\")","f76afc40":"car.shape","561249e8":"car","a7159ce1":"car.info()","023c0bf7":"car[\"price\"] = car[\"price\"].astype(int)","d48edfcd":"car.isnull().sum()","5bcc1324":"car[\"fueltype\"].value_counts().plot.bar()\nplt.show()","a1da1221":"from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder().fit(car[\"fueltype\"])\ncar[\"fueltype\"] = encoder.transform(car[\"fueltype\"])","7094da7a":"car[\"fueltype\"].value_counts().plot.bar()\nplt.show()","2a3cb5a5":"car[\"aspiration\"].value_counts().plot.bar()\nplt.show()","1189e007":"encoder = preprocessing.LabelEncoder().fit(car[\"aspiration\"])\ncar[\"aspiration\"] = encoder.transform(car[\"aspiration\"])","0294578c":"car[\"fueltype\"].value_counts().plot.bar()\nplt.show()","46487aaf":"car[\"doornumber\"].value_counts().plot.bar()\nplt.show()","3edd50fa":"car[\"doornumber\"] = car[\"doornumber\"].map({\"four\":4,\"two\":2})\ncar[\"doornumber\"].value_counts().plot.bar()\nplt.show()","a16ccec0":"car[\"carbody\"].value_counts().plot.bar()\nplt.show()","c3ef61fb":"encoder = preprocessing.LabelEncoder().fit(car[\"carbody\"])\ncar[\"carbody\"] = encoder.transform(car[\"carbody\"])\ncar[\"carbody\"].value_counts().plot.bar()\nplt.show()","7845d9e0":"car[\"drivewheel\"].value_counts().plot.bar()\nplt.show()","a1f2fcb9":"encoder = preprocessing.LabelEncoder().fit(car[\"drivewheel\"])\ncar[\"drivewheel\"] = encoder.transform(car[\"drivewheel\"])\ncar[\"drivewheel\"].value_counts().plot.bar()\nplt.show()","ae663142":"car[\"enginelocation\"].value_counts().plot.bar()\nplt.show()","16aed282":"car[\"enginelocation\"] = car[\"enginelocation\"].map({\"front\":1,\"rear\":2})\ncar[\"enginelocation\"].value_counts().plot.bar()\nplt.show()","78508ab7":"car[\"enginetype\"].value_counts().plot.bar()\nplt.show()","d7f352d5":"encoder = preprocessing.LabelEncoder().fit(car[\"enginetype\"])\ncar[\"enginetype\"] = encoder.transform(car[\"enginetype\"])\ncar[\"enginetype\"].value_counts().plot.bar()\nplt.show()","f57175bf":"car[\"cylindernumber\"].value_counts().plot.bar()\nplt.show()","f9b47e4c":"car[\"cylindernumber\"] = car[\"cylindernumber\"].map({\"four\":4,\"two\":2,\"six\":6,\"five\":5,\"eight\":8,\"three\":3,\"twelve\":12})\ncar[\"cylindernumber\"].value_counts().plot.bar()\nplt.show()","10fe6919":"car[\"fuelsystem\"].value_counts().plot.bar()\nplt.show()","80e24d1c":"encoder = preprocessing.LabelEncoder().fit(car[\"fuelsystem\"])\ncar[\"fuelsystem\"] = encoder.transform(car[\"fuelsystem\"])\ncar[\"fuelsystem\"].value_counts().plot.bar()\nplt.show()","c7be4a8b":"car.info()","eb5a8e38":"car_noname = car.drop(\"CarName\",axis=1)\ncar_noname","f2d8a3a7":"plt.subplots(figsize=(25,25))\nax = plt.axes()\ncorr = car_noname.corr()\nsns.heatmap(corr)","1c0a2491":"pd.set_option('display.max_columns',None)","851b799c":"corr","dd50a4f5":"plt.scatter(car_noname[\"curbweight\"],car_noname[\"price\"])\nplt.xlabel(\"curbweight\")\nplt.ylabel(\"price\")","f5b5bb03":"plt.scatter(car_noname[\"enginesize\"],car_noname[\"price\"])\nplt.xlabel(\"enginesize\")\nplt.ylabel(\"price\")","bc4f4ab8":"import statsmodels.formula.api as smf\ncar_noname.eval('hp_es = horsepower \/ enginesize',inplace = True)\nresults = smf.ols('price ~hp_es',data=car_noname).fit()\nresults.summary()","c2fa278c":"corr = car_noname.corr()\ncorr","9c603240":"car1 = car_noname[[\"price\",\"drivewheel\",\"enginelocation\",\"wheelbase\",\"carlength\",\"carwidth\",\"curbweight\",\"cylindernumber\",\n                   \"enginesize\",\"fuelsystem\",\"boreratio\",\"horsepower\",\"citympg\",\"highwaympg\"]]","7a94e25a":"car1.shape","374768f2":"car1.head(5)","15d45015":"features1 = car1.columns.drop('price')","c8e7cdef":"train1 = car1\ntrain1.shape","67f9b8c2":"train1_features = train1.drop(\"price\",axis=1)\ntrain1_target = train1[\"price\"]\nprint(train1_features.shape,train1_target.shape)","70599b58":"from sklearn.model_selection import train_test_split\nimport eli5\nX_train1,X_test1,Y_train1,Y_test1 = train_test_split(train1_features,train1_target,\n                                                 test_size=0.2,shuffle=True,random_state = 133)\nprint(X_train1.shape,Y_train1.shape,X_test1.shape,Y_test1.shape)","33b9639d":"testfeatures1 = X_test1.sample(n=10)\ntestdata1 = pd.merge(testfeatures1,Y_test1,left_index=True,right_index=True)\ntestdata1","50eefe52":"#RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nRFR1 = RandomForestRegressor(n_estimators=200, max_depth=3, random_state=133).fit(X_train1, Y_train1)\nscore1 = RFR1.score(X_test1,Y_test1)\nscore1","0f9ee133":"#SVR\nfrom sklearn.svm import SVR\nl_svr = SVR(kernel='linear')\nl_svr.fit(X_train1,Y_train1)\nl_svr.score(X_test1,Y_test1)","27f46532":"#KNeighborsRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor(weights=\"uniform\")\nknn.fit(X_train1,Y_train1)\nknn.score(X_test1,Y_test1)","3999410b":"from sklearn.model_selection import KFold, cross_val_score\nkf = KFold(n_splits=5, shuffle=True, random_state=111)\ncv_results1 = cross_val_score(estimator=RFR1, X=train1_features, y=train1_target, cv=kf, scoring='r2', n_jobs=-1).mean()\ncv_results2 = cross_val_score(estimator=l_svr, X=train1_features, y=train1_target, cv=kf, scoring='r2', n_jobs=-1).mean()\ncv_results3 = cross_val_score(estimator=knn, X=train1_features, y=train1_target, cv=kf, scoring='r2', n_jobs=-1).mean()\nprint(cv_results1,cv_results2,cv_results3)","45ee5e37":"prediction = RFR1.predict(testfeatures1)\noutput = pd.DataFrame({\"price\":testdata1[\"price\"],\"prediction\":prediction})\noutput","64fe3751":"from sklearn.metrics import mean_absolute_error\npredicts1 = RFR1.predict(X_test1)\nmae1 = mean_absolute_error(Y_test1,predicts1)\nmae1","91ec42dd":"from eli5.sklearn import PermutationImportance\nperm = PermutationImportance(RFR1, random_state=123).fit(X_train1, Y_train1)\neli5.show_weights(perm, feature_names = features1.tolist(), top=30)","352a46fa":"car2 = car_noname[[\"price\",\"aspiration\",\"drivewheel\",\"enginelocation\",\"wheelbase\",\"carlength\",\"carwidth\",\"carheight\",\"curbweight\",\n                   \"cylindernumber\",\"enginesize\",\"fuelsystem\",\"boreratio\",\"horsepower\",\"fueltype\",\"citympg\",\"highwaympg\",\"hp_es\"]]\nfeatures2 = car2.columns.drop(\"price\")\ntrain2_features = car2.drop(\"price\",axis=1)\ntrain2_target = car2[\"price\"]\nprint(train2_features.shape,train2_target.shape)","bf438fbd":"X_train2,X_test2,Y_train2,Y_test2 = train_test_split(train2_features,train2_target,\n                                                 test_size=0.2,shuffle=True,random_state = 133)\nprint(X_train2.shape,Y_train2.shape,X_test2.shape,Y_test2.shape)","8f0d6389":"RFR2 = RandomForestRegressor(n_estimators=200, max_depth=3, random_state=133).fit(X_train2, Y_train2)\nscore2 = RFR2.score(X_test2,Y_test2)\nscore2","8d6bbfa5":"l_svr = SVR(kernel='linear')\nl_svr.fit(X_train2,Y_train2)\nl_svr.score(X_test2,Y_test2)","29ad3674":"knn = KNeighborsRegressor(weights=\"uniform\")\nknn.fit(X_train2,Y_train2)\nknn.score(X_test2,Y_test2)","c6309784":"predicts2 = RFR2.predict(X_test2)\nmae2 = mean_absolute_error(Y_test2,predicts2)\nmae2","6012a9f1":"from eli5.sklearn import PermutationImportance\nperm = PermutationImportance(RFR2, random_state=123).fit(X_train2, Y_train2)\neli5.show_weights(perm, feature_names = features2.tolist(), top=30)","fe09b305":"car3 = car_noname\nfeatures3 = car3.columns.drop(\"price\")\ntrain3_features = car3.drop(\"price\",axis=1)\ntrain3_target = car3[\"price\"]\nX_train3,X_test3,Y_train3,Y_test3 = train_test_split(train3_features,train3_target,\n                                                 test_size=0.2,shuffle=True,random_state = 133)\nprint(X_train3.shape,Y_train3.shape,X_test3.shape,Y_test3.shape)","6749639d":"RFR3 = RandomForestRegressor(n_estimators=200, max_depth=3, random_state=133).fit(X_train3, Y_train3)\nscore3 = RFR3.score(X_test3,Y_test3)\nscore3","6cfbbbfa":"predicts3 = RFR3.predict(X_test3)\nmae3 = mean_absolute_error(Y_test3,predicts3)\nmae3","27c7c199":"from eli5.sklearn import PermutationImportance\nperm = PermutationImportance(RFR3, random_state=123).fit(X_train3, Y_train3)\neli5.show_weights(perm, feature_names = features3.tolist(), top=30)","b8788a6e":"from sklearn.model_selection import KFold, cross_val_score\nkf = KFold(n_splits=5, shuffle=True, random_state=111)\ncv_results1 = cross_val_score(estimator=RFR1, X=train1_features, y=train1_target, cv=kf, scoring='r2', n_jobs=-1).mean()\ncv_results2 = cross_val_score(estimator=RFR2, X=train2_features, y=train2_target, cv=kf, scoring='r2', n_jobs=-1).mean()\ncv_results3 = cross_val_score(estimator=RFR3, X=train3_features, y=train3_target, cv=kf, scoring='r2', n_jobs=-1).mean()\nprint(cv_results1,cv_results2,cv_results3)","5eadf2ab":"model = {'name':['RFR1','RFR2','RFR3'],'score':[score1,score2,score3],\"MAE\":[mae1,mae2,mae3],\"CV_Results\":[cv_results1,cv_results2,\n                                                                                                           cv_results3]}\nmodel_df = pd.DataFrame(model)\nmodel_df","e731c450":"from sklearn.cluster import KMeans\ncar1_noprice = car1.drop(\"price\",axis=1)\nkm = KMeans(n_clusters=5).fit(car1_noprice)\ncar1_noprice['cluster'] = km.labels_\ncar1_noprice.sort_values('cluster')\ncluster_centers = km.cluster_centers_\ncar1_noprice.groupby(\"cluster\").mean()","3d7ca954":"from pandas.plotting import scatter_matrix \ncenters = car1_noprice.groupby(\"cluster\").mean().reset_index\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.rcParams['font.size'] = 10\ncolors = np.array(['red','green','blue','yellow','purple'])","fac2d4ad":"scatter_matrix(car1_noprice[[\"curbweight\",\"cylindernumber\",\"enginesize\",\"horsepower\"]],\n               s=50,alpha=1,c=colors[car1_noprice[\"cluster\"]],figsize=(10,10))","c576982f":"corr = car1_noprice[[\"curbweight\",\"cylindernumber\",\"enginesize\",\"horsepower\"]].corr()\ncorr","bff40506":"from mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure()\nax = fig.add_subplot(111,projection='3d')\nxs = car1_noprice[\"curbweight\"]\nys = car1_noprice[\"horsepower\"]\nzs = car1_noprice[\"enginesize\"]\nax.scatter(xs,ys,zs,c=colors[car1_noprice[\"cluster\"]],s=20)\nax.set_xlabel('curbweight')\nax.set_ylabel('horsepower')\nax.set_zlabel('enginesize')\nplt.show()","f999d8a5":"scatter_matrix(car1_noprice[[\"curbweight\",\"enginesize\",\"horsepower\",\"highwaympg\",\"citympg\"]],\n               s=50,alpha=1,c=colors[car1_noprice[\"cluster\"]],figsize=(10,10))","81e2671f":"car11 = car_noname[[\"price\",\"drivewheel\",\"enginelocation\",\"wheelbase\",\"carlength\",\"carwidth\",\"curbweight\",\"cylindernumber\",\n                   \"enginesize\",\"fuelsystem\",\"boreratio\",\"horsepower\",\"citympg\",\"highwaympg\",\"hp_es\"]]\nkm = KMeans(n_clusters=5).fit(car11)\ncar11['cluster'] = km.labels_\ncar11.sort_values('cluster')\ncluster_centers = km.cluster_centers_\ncar11.groupby(\"cluster\").mean()","3892e022":"from pandas.plotting import scatter_matrix \ncenters = car1_noprice.groupby(\"cluster\").mean().reset_index\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.rcParams['font.size'] = 10\ncolors = np.array(['red','green','blue','yellow','purple'])\nplt.scatter(car11[\"hp_es\"],car11[\"price\"],c=colors[car11[\"cluster\"]])\nplt.xlabel(\"hp_es\")\nplt.ylabel(\"price\")","2fb3f59e":"car11.groupby(\"cluster\").mean()","ca4f6a52":"## 2 EDA","8f11ade4":"**The relationship is weak, it seems that car price is more dependant on the performance of overall engine**","7e73c27b":"### b. Choose the features which have the correlation more than 0.1","8c898076":"* **\"enginesize\" and \"horsepower\" both have high correlation with price**  \n* **the ratio between \"horsepower\" and \"enginesize\" shows the horsepower every unit enginesize provides,   \nwhich is related to the quality of engine**  \n\n**if this ratio is highly related to the price**","61205aeb":"## 3 Modeling and Prediction","9f3ee9af":"Feature importance","4b8f014f":"We can use 3D scatter matrix to show a more clear correlation among these three features.","3127ed00":"### Show the score, MAE, CV_Results of 3 models ","415c37f0":"I use both LabelEncoder and map to change the string to number.  \n1. When the labels have no relationship to the number, I use LabelEncoder \n2. When the meaning of the labels is exactly related to the number, I use map.  \nTake \"doorsnumber\" as an example.","573d9789":"# Summary\n**The aim of this project is training a model which is used for car price prediction based on the performance and structure of cars and doing some further analysis about the features which are important or confusing for me.**","23864420":"### Conclusion","96bd3722":"**curbweight and engine size are strongest correlated with price**","46135055":"### Conclusion","93c47f86":"### d. Correlation ","65cf8f9b":"* **It makes sense that the higher horsepower a car have, the higher price it will cost.**\n* **It's obvious that enginesize is highly correlated with the performance of a car.Besides, the correlations between cylindernumber and enginesize, horsepower and enginesize are strong and positive, which indicates that enginesize is a overall indicator of a engine.**\n* **We all know that bigger cars are more likely to be heavier. Actually, according to the scatter matrix, curbweight also highly depends on the enginesize. These two factors are the main reasons why curbweight has the strong correlation with price.**  \n* **More powerful engine means more cost the automakers pay for it, which leads to the high price**\n* **If we have a dataset including more features of cars, the features related to the engine should be highly paid attention to.Maybe they are the key to improve the car price prediction model**","ca6f772a":"## 2 Why highwaympg and citympg are negative correlated with price","dac5c898":"### Cross-validation","551b0248":"**hp_es shows weak relationship with the price. But I wonder if it can be the factor of the price for the cars in the same cluster because it shows the efficiency of the engine.**","f04c8c19":"There is no missing value in this dataset","e624e6cb":"### b. Check the missing value","9b58e392":"Use KMeans to do the clustering and show the mean value of each features in each cluster.","3cafcce8":"**Becaue I want to analyze the relationship between car price and their performance and structure, I don't need \"CarName\".**","c2733c61":"use scatter matrix to show the relationship","940864f6":"MPG:  MILE PER GALLON","a68a25e2":"Use different model  \n1. **RandomForestRegressor**  \n2. **SVR**  \n3. **KNeighborsRegressor**","609c4606":"### c. Handle the object data","2d6d3d77":"### c. Choose all features","76b772ad":"Use scatter matrix to show the relationship between features.","20bd99a3":"According to the performance of each model in Cross-validation, I choose RFR.","3ed13332":"## 1 Loding the Data","c66bebda":"### a. Brief check","f148777a":"### 5 Conclution\n**1. Accoring to the chart, RFR3 has the best score and performance in Cross-validation.Although the MAE of RFR3 is a little bit bigger than others, I think RFR3 is the most suitable model.**   \n\n**2. Enginesize is one of the most important factors of car price.**","ce574eeb":"Do the prediction","882868e0":"# Case 2: Further Analysis","85a7b16b":"**The highwaympg and citympg are negative correlated with price.**  \n**When I know this fact, I'm confused. Because I think everyone hopes the fuel consumption of the car they buy is low in order to pay less for the fuel.Actually automakers will not raise the price because of less fuel consumption.**","8dde9ba2":"# Case 1: Car Price Prediction","56bb6218":"**According to the scatter matrix, high mpg -> less powerful engine -> lower price.**  \n**The automakers need to pay for the cost of engine but not the cost of fuel**\n\n**It also reflect an intersting social phnomenon that the rich like buying premium car which has high fuel comsumption, but they don't need to worry about the payment for the fuel. The situation is quite the opposite for the poor.**\n","6d780038":"Pick the data of 10 cars randomly for prediction display","487d6b21":"* **Actually, hp_es still cannot become an important features of the car price even in the same cluster. That's to say, even though some expensive cars have the powerful engine, the efficiency of their engines may be lower than that of cheaper car. **  \n* **Automakers are not willing to invest much time and money in improving the effciency of engine.**\n* **If I'm a motor traders, I will pay more attention to overall engine performance and the cost than the efficiency of the engine while considering which type of cars to lay in.**\n","e8ebfdde":"**We can make a brief class division of cars according to this chart.**","e0dfc273":"## 1 Why curbweight, enginesize, horsepower are strong correlated with price","ced6f2b0":"Build a new feature \"hp_es\"(= horsepower\/enginesize)  \nAnalyse the relationship between hp_es and price.","775344a0":"I wanna see how does the prediction model perform concretely.  \nUse mean_absolute_error to show the accuracy of the model and take it as a factor of evaluation.","8b94e044":"## 4 Evaluation","880f8838":"### a. Choose the features which have the correlation more than 0.30","6e37635a":"## 3 About hp_es","cdef1870":"## 4 Class Division","8fd35907":"### Conclusion","5c99caa8":"**\"curbweight\",\"enginesize\",\"horsepower\" are strong and positive correlated with price(over 0.80). And according to the cluster, curbweight, cylindernumber, enginesize, horsepower have the more clear difference among the clusters.**"}}