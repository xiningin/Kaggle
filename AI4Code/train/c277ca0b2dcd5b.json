{"cell_type":{"1d418ab5":"code","43c99ff4":"code","1f62b06d":"code","ebd7cc25":"code","85e0e848":"code","1b900fdb":"code","698c5e5d":"code","2d5c70a7":"code","10f91bcd":"code","553ef882":"code","e204bd1b":"code","3cb001f4":"code","593bc242":"code","1013a70c":"code","240750ff":"code","8ead45d4":"code","e1ff066f":"code","b37abbab":"code","592c609e":"code","2362d7cb":"code","f5780c5a":"code","9b7a7792":"code","77559b2c":"code","9c4e23de":"code","50a81212":"code","803786b1":"markdown","c127e42b":"markdown","9f8dbd32":"markdown","b2b7d949":"markdown","8f23d9e9":"markdown","9acc02df":"markdown","67428980":"markdown","0cd14ff0":"markdown","dc303259":"markdown","d915b1a9":"markdown","d4038e38":"markdown"},"source":{"1d418ab5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","43c99ff4":"#Import relevant libraries\nimport pandas as pd\nimport glob\nimport numpy as np\nimport seaborn as sb\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#Timeseries modeling\nfrom fbprophet import Prophet\n\n#Evaluation Params\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","1f62b06d":"#Import the data and get df ready for energy consumption. Prepare a combined dataframe.\npath = '\/kaggle\/input\/ontario-energy-prices\/'\nall_files = glob.glob(path + \"\/*.csv\")\n\nli = [] #empty list to collect the data.\n\nfor filename in all_files:\n    df_full = pd.read_csv(filename, index_col=None, header=0, skiprows=3, parse_dates=['Date'], encoding='latin')\n    li.append(df_full)\n\ndf_full = pd.concat(li, axis=0, ignore_index=True)","ebd7cc25":"#Subet Dataframe to only relevant features.\ndf = df_full[['Date','Hour','HOEP']]\ndel df_full","85e0e848":"#Sorting and resetting indexing as hygiene.\ndf.sort_values('Date', inplace=True)\ndf.reset_index(drop=True, inplace=True)","1b900fdb":"#Let's have a look.\ndf.head()","698c5e5d":"#2.1 - Replace , in thousands using string object and convert to float type.\ndf['HOEP']= df['HOEP'].astype(str).str.replace(',', '').astype(float)\n\n#2.2 - Change 24 to 0 since the date does not change with every month's 24 hour time.\n#df['Hour'] = df['Hour'].map(lambda x:0 if x==24 else x)\n\n#2.3 - Concatenate the hours and date to get a datetime object.\ndf['date'] = pd.to_datetime(df['Date']) + pd.to_timedelta(df['Hour'], unit='h')\n\n#2.4 - Sort Values by Date\ndf.sort_values('date', ascending=True, inplace=True)\n\n#2.5 - Set index as dates.\ndf.set_index('date', drop=True,inplace=True)","2d5c70a7":"#Dropping old 'Date' and 'Hour' features.\ndf.drop(['Date','Hour'], axis=1,inplace=True)","10f91bcd":"#Flooring the data as it has neg values.\ndf['HOEP'] = df['HOEP'].map(lambda x:0 if x<0 else x)\ndf['HOEP'] = df['HOEP'].map(lambda x:.0001 if x==0 else x)","553ef882":"#Extracting all the features using TimeSeries object. The output is a combined_df with all the features.\n\ndef extract_features(df, label=None):\n    df = df.copy()\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X\nX, y = extract_features(df, label='HOEP')\ncombined_df = pd.concat([X, y], axis=1)\n\n#Shout out to https:\/\/www.kaggle.com\/robikscube\/time-series-forecasting-with-prophet#Data.","e204bd1b":"#Plotting a pairplot to see the relationship bw features.\nsb.pairplot(combined_df.dropna(), hue='hour', x_vars=['hour','dayofweek','year','weekofyear'], y_vars='HOEP',\n             height=6, plot_kws={'alpha':0.8, 'linewidth':0},palette= \"husl\")\n#Plot title\nplt.suptitle('Ontario Power Use by Hour, Day of Week, Year and Week of Year')\nplt.show()","3cb001f4":"#The data is for 17+ years. Great.\ndf.shape[0]\/24\/365","593bc242":"print (\"Lowest Date in Dataset: \", min(df.index))\nprint (\"Highest Date in Dataset: \", max(df.index))","1013a70c":"#Splitting the data on 1st Jan 2017.\nsplit_date = '01-Jan-2017'\ndf_train = df.loc[df.index <= split_date]\ndf_test = df.loc[df.index > split_date]","240750ff":"#Plotting the split of the dataset.\ntemp = df_test.rename(columns={'HOEP': 'Test Data'})\ntemp2 = temp.join(df_train.rename(columns={'HOEP': 'Train Data'}), how='outer')\ntemp2.plot(figsize=(15,5), title='Test and Train Split', style='.', color=['grey','blue'])\nplt.show()\ndel temp,temp2\n","8ead45d4":"#Preprocessing for model specifications.\n\n#Prophet also imposes the strict condition that the input columns be named ds (the time column) and \n#y (the metric column) so let\u2019s rename the columns in our DataFrame:\ndf_train = df_train.reset_index().rename(columns={'date':'ds', 'HOEP':'y'})\ndf_train.head()","e1ff066f":"# Setup and Train model and fit\n\n#Can set the uncertainty interval to 95% (the Prophet default is 80%)\nmodel = Prophet() \nmodel.fit(df_train.reset_index().rename(columns={'date':'ds','HOEP':'y'}))","b37abbab":"#Predict on test set.\nHOEP_predictions = model.predict(df=df_test.reset_index().rename(columns={'date':'ds'}))\n#Note that the predictions start from 01-01-2017 (the split date) test set values untill last data point 06-02-2020.\n\n#Check Predictions.\nHOEP_predictions","592c609e":"# Plot the components of the prophet model.\nfig = model.plot_components(HOEP_predictions)\n#Observe how the prices are lower during summer months - this could be due to people being out\/requiring lesser hvac.\n#The coldest months in Ontario have the steepest energy prices. ","2362d7cb":"# Plot the Forecast and Actuals\n\n#Plot params\nf, ax = plt.subplots(1)\nf.set_figheight(10)\nf.set_figwidth(45)\n\n#Plot scatter plot of actual vs forecasts.\nax.scatter(df_test.index, df_test['HOEP'], color='g') #Red color is forecasted values.\nfig = model.plot(HOEP_predictions, ax=ax)","f5780c5a":"#Since the split_date = '01-Jan-2017', let's check the forecasts for the first month i.e 1st Jan'17 to 1st Feb'17\n\n# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(25)\nax.scatter(df_test.index, df_test['HOEP'], color='y')\nfig = model.plot(HOEP_predictions, ax=ax)\n\nimport datetime\n\n#Set monthly limit.\nax.set_xlim([datetime.date(2017, 1, 1), datetime.date(2017, 2, 1)])\nax.set_ylim([-100,250 ])\nplot = plt.suptitle('January 2017 Forecast vs Actuals')\n\n#The model seems to be doing okay with the current tweaks. Let's evaluate it using other metrics.","9b7a7792":"#Since the split_date = '01-Jan-2017', let's check the forecasts for the first WEEK.\n\n# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(25)\nax.scatter(df_test.index, df_test['HOEP'], color='b')\nfig = model.plot(HOEP_predictions, ax=ax)\n\nimport datetime\n\n#Set monthly limit.\nax.set_xlim([datetime.date(2017, 1, 1), datetime.date(2017, 1, 7)])\nax.set_ylim([-100,250 ])\nplot = plt.suptitle('Weekly Prediction for Jan17')\n\n#The model seems to be doing okay with the current tweaks. Let's evaluate it using other metrics.","77559b2c":"#MSE\n\n#For each point, it calculates square difference between the predictions and the target and then average \n#those values.\nmse_prophet = mean_squared_error(y_true=df_test['HOEP'],\n                   y_pred=HOEP_predictions['yhat'])\nmse_prophet","9c4e23de":"#Mean Absolute Error - Avg of absolute distance. Not as sensitive to outliers as MSE.\nmae_prophet = mean_absolute_error(y_true=df_test['HOEP'],\n                   y_pred=HOEP_predictions['yhat'])\nmae_prophet","50a81212":"#Next Steps - Try another model (ARIMA) and Deep Learning.\n\n#Happy Learning!","803786b1":"#### Prediction for First Week (1st Jan'17- 7th Jan'17)","c127e42b":"### Step 5: Build\/Train the model ","9f8dbd32":"#### Monthly Predictions for First Month (Jan'17-Feb'17)","b2b7d949":"### Step 3: Feature Extraction\n\nThe data is already in a datetime format hence it is fairly easy to extarct all the relevant time series features using the datetime object. Extracting and plotting features.","8f23d9e9":"### Step 4: Building The Model - Prophet\n\n- Build the model using existing data.\n- Build it using cleaned data (later).","9acc02df":"General Workflow.\n\n* Step 1: The files are located across multiple csv's. The first step is to import all data from the csv's and create a consolidated DF.\n* Step 2: Data Cleaning\/Exploration\n* Step 3: Feature Extraction\n* Step 4: Split the dataset.\n* Step 5: Apply Prophet Model using data (as is).\n* Step 6: Check Accuracy\/Evaluation Params\n* Step 7: Re-Apply Prophet using modified\/clean data.\n* Step 8: Evaluate new mdoel.","67428980":"#### Predict on Test Data","0cd14ff0":"### Step 6: Model Evaluation \n\nEvaluating the model using standard regression params - MSE, RMSE, MAE, R2, MSPE, MAPE.","dc303259":"### Step 4: Split the Dataset\n\n- First lets check the data and split it into ~80\/20 ratio.\n- Next, plot the split to inspect it visually.","d915b1a9":"### Step 2: Clean the Dataframe (Pre-processing)\n\n    -2.1 Since the dataset contains a ',' for every value exceeding in thousands. Remove it.\n    -2.2 Map 24 to 0 since the date does not change in the data when its 24 hours.\n    -2.3 Concatenate the hours and dates to get final datetime object.\n    -2.4 Sort Values by date\n    -2.5 Set dates as index\n    ","d4038e38":"#### Plot the entire forecasts VS Actual"}}