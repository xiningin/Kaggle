{"cell_type":{"c1009db7":"code","5323b3ab":"code","a66be075":"code","ca886fef":"code","2ceb1834":"code","1084c678":"code","923a56c6":"code","ce5a1e22":"code","06ed12bc":"code","14b3e756":"code","3ef49c8d":"code","a0f1a810":"code","e61453b5":"code","59ece2e8":"code","27c33486":"code","b9d9ff55":"code","2476e554":"code","22946e8b":"code","f2837061":"code","7e578563":"code","7467bd25":"code","258b7c0e":"code","48dfb28c":"code","b667f034":"code","c117cd41":"code","d49157e0":"code","8526c55e":"code","6664574e":"code","52cad546":"code","0e5b765a":"code","7ca39df7":"code","fe6f3b0f":"code","5a822df0":"code","652ce51b":"code","02321495":"code","9bdb2ad3":"code","830e09a5":"code","dadf748a":"code","638e9761":"code","560668b4":"code","967a3e6b":"code","0c820494":"code","672748ba":"code","c20dfb61":"code","895b6887":"code","0a580d2b":"code","f6816768":"code","c3aeffa5":"code","9a5e6170":"code","86d67551":"code","df24f6b2":"code","7ce3e58c":"code","209284ec":"code","5e2120f3":"code","08883659":"code","16fa5efe":"code","486f50bb":"code","82dabe04":"code","b737b8db":"code","85fac406":"code","0762cbf0":"code","8e618968":"code","e09fd9a2":"code","b7c8a9ab":"code","124a3f29":"code","d30a41a0":"markdown","fd6100de":"markdown","f511721d":"markdown","20275fc2":"markdown","81caf6e8":"markdown","4e7b4142":"markdown","076e2f27":"markdown","65bee832":"markdown","4b3ac694":"markdown","ad1385e4":"markdown","e438d269":"markdown","74d1eac0":"markdown","21231c5b":"markdown","26100d25":"markdown","fcfe72b7":"markdown","3941c375":"markdown","5e0e38ff":"markdown","39af6dfb":"markdown","28cbd47a":"markdown","16de3aa3":"markdown","56269507":"markdown","a93f27a6":"markdown","8fe40321":"markdown","74a137f0":"markdown","62ebd24b":"markdown","9f53bcef":"markdown","8f464a39":"markdown","25f5da07":"markdown","dccd21cc":"markdown","af31dbc8":"markdown","8ec00a69":"markdown","3d5a9d32":"markdown","94da5895":"markdown","020fe73a":"markdown","2f16e922":"markdown","0f1b19e4":"markdown","84b1c3ef":"markdown","a4f09d11":"markdown","37574eb8":"markdown","21a9deab":"markdown","b50d0f67":"markdown","5b2016ef":"markdown","eb3c6698":"markdown","f7bf8fa4":"markdown","75f3a060":"markdown"},"source":{"c1009db7":"# importing necessary libraries for avoiding warnings\nimport warnings\nwarnings.filterwarnings('ignore')","5323b3ab":"# import necessary libraries for importing and understanding the data\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","a66be075":"# importing the necessary libraries for model building\nimport sklearn\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","ca886fef":"# Reading the data into dataframes\nadmission_dataframe =  pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv')","2ceb1834":"# analyzing the data\nadmission_dataframe.head()","1084c678":"# Checking the shape of the dataframe\nadmission_dataframe.shape","923a56c6":"# checking the info about the columns of the dataframe\nadmission_dataframe.info()","ce5a1e22":"# analyzing the summary statistics of the numerical columns of the dataframe\nadmission_dataframe[['GRE Score', 'TOEFL Score','CGPA', 'SOP', 'LOR ', 'University Rating' ]].describe()","06ed12bc":"# checking the columns present in the dataframe\nadmission_dataframe.columns","14b3e756":"# analyzing the array of the values of the data\nadmission_dataframe.values","3ef49c8d":"# analyzing the distributions of numerical columns of the dataframe\nplt.figure(figsize = (10,5)) #(Width, height) in figsize\nplt.subplot(2,3,1)\nsns.distplot(admission_dataframe['GRE Score'])\nplt.subplot(2,3,2)\nsns.distplot(admission_dataframe['TOEFL Score'])\nplt.subplot(2,3,3)\nsns.distplot(admission_dataframe['CGPA'])\nplt.subplot(2,3,4)\nsns.distplot(admission_dataframe['SOP'])\nplt.subplot(2,3,5)\nsns.distplot(admission_dataframe['University Rating'])\nplt.subplot(2,3,6)\nsns.distplot(admission_dataframe['LOR '])\nplt.tight_layout()\nplt.show()","a0f1a810":"# analyzing the pair plot distibutions of the numerical variables\nsns.pairplot(admission_dataframe[['GRE Score', 'TOEFL Score', 'CGPA', 'SOP', 'LOR ', 'University Rating' ,'Chance of Admit ']])","e61453b5":"# plotting the heat map between the numerical variables\nmatrix = admission_dataframe[['GRE Score', 'TOEFL Score', 'CGPA', 'SOP', 'LOR ', 'University Rating' ,'Chance of Admit ']].corr()\n# plotting the heatmap using seaborn\nsns.heatmap(matrix, annot = True, linecolor= 'white', linewidths= 1)","59ece2e8":"# analyzing the variation between categorical variables in relation with target variables\nplt.figure(figsize=(7,5))\nsns.boxplot(admission_dataframe['Research'], admission_dataframe['Chance of Admit '])\nplt.tight_layout()\nplt.show()","27c33486":"# analyzing the dataframe again\nadmission_dataframe.head()","b9d9ff55":"# Performing Train Test split\ndf_train, df_test = train_test_split(admission_dataframe, train_size = 0.70, test_size = 0.30, random_state = 100)","2476e554":"# checking the shapes of train and test dataframe\nprint(df_train.shape, df_test.shape)","22946e8b":"# Dropping the column serial number as it will be no use in modelling\ndf_train.drop('Serial No.', axis = 1, inplace = True)\ndf_test.drop('Serial No.', axis =1, inplace = True)","f2837061":"# checking the df_train\ndf_train.head()","7e578563":"# Scaling the features of the dataframe\n\n# initiating the scaler object\nscaler = MinMaxScaler()\n\n# fittting and transforming the data on top of the scaler object for the training data set\ndf_train[::] = scaler.fit_transform(df_train)","7467bd25":"# checking the dataframe after scaling the variables\ndf_train.head()","258b7c0e":"# checking the describe of the dataframe to check whether scaling has been done or not\ndf_train.describe()","48dfb28c":"# creating X_train and y_train\ny_train = df_train.pop('Chance of Admit ')\nX_train =  df_train","b667f034":"# checking X_train \nX_train.head()","c117cd41":"# checking y_train\ny_train.head()","d49157e0":"# adding constant to X_train as statsmodel in built doesn't add constant\nX_train_sm = sm.add_constant(X_train)\n\n# creating the model object\nlr_model_1 = sm.OLS(y_train, X_train_sm)\n\n# fitting the model on top of the data\nlr_model_1 = lr_model_1.fit()\n\n# checking the summary statistics of the model\nlr_model_1.summary()","8526c55e":"# checking the VIF values\n\n# creating the dataframe of the VIF values\nVIF = pd.DataFrame()\n\n# adding column to the VIF dataframe for columns of the X_train\nVIF['features'] = X_train.columns\n\n# adding column for the VIF values of the features\nVIF['VIF_value'] =  [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n\n# sorting the dataframe based on VIF_value\nVIF.sort_values('VIF_value', ascending= False, inplace = True)\n\n# checking the dataframe\nVIF","6664574e":"# dropping SOP from X_train\nX_train.drop('SOP', axis = 1, inplace = True)","52cad546":"# adding constant to X_train as statsmodel in built doesn't add constant\nX_train_sm = sm.add_constant(X_train)\n\n# creating the model object\nlr_model_2 = sm.OLS(y_train, X_train_sm)\n\n# fitting the model on top of the data\nlr_model_2 = lr_model_2.fit()\n\n# checking the summary statistics of the model\nlr_model_2.summary()","0e5b765a":"# checking the VIF values\n\n# creating the dataframe of the VIF values\nVIF = pd.DataFrame()\n\n# adding column to the VIF dataframe for columns of the X_train\nVIF['features'] = X_train.columns\n\n# adding column for the VIF values of the features\nVIF['VIF_value'] =  [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n\n# sorting the dataframe based on VIF_value\nVIF.sort_values('VIF_value', ascending= False, inplace = True)\n\n# checking the dataframe\nVIF","7ca39df7":"# Dropping Univeristy Rating from X_train\nX_train.drop('University Rating', axis = 1, inplace = True)","fe6f3b0f":"# adding constant to X_train as statsmodel in built doesn't add constant\nX_train_sm = sm.add_constant(X_train)\n\n# creating the model object\nlr_model_3 = sm.OLS(y_train, X_train_sm)\n\n# fitting the model on top of the data\nlr_model_3 = lr_model_3.fit()\n\n# checking the summary statistics of the model\nlr_model_3.summary()","5a822df0":"# checking the VIF values\n\n# creating the dataframe of the VIF values\nVIF = pd.DataFrame()\n\n# adding column to the VIF dataframe for columns of the X_train\nVIF['features'] = X_train.columns\n\n# adding column for the VIF values of the features\nVIF['VIF_value'] =  [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n\n# sorting the dataframe based on VIF_value\nVIF.sort_values('VIF_value', ascending= False, inplace = True)\n\n# checking the dataframe\nVIF","652ce51b":"# Dropping CGPA from X_train\nX_train.drop('GRE Score', axis = 1, inplace = True)","02321495":"# adding constant to X_train as statsmodel in built doesn't add constant\nX_train_sm = sm.add_constant(X_train)\n\n# creating the model object\nlr_model_4 = sm.OLS(y_train, X_train_sm)\n\n# fitting the model on top of the data\nlr_model_4 = lr_model_4.fit()\n\n# checking the summary statistics of the model\nlr_model_4.summary()","9bdb2ad3":"# checking the VIF values\n\n# creating the dataframe of the VIF values\nVIF = pd.DataFrame()\n\n# adding column to the VIF dataframe for columns of the X_train\nVIF['features'] = X_train.columns\n\n# adding column for the VIF values of the features\nVIF['VIF_value'] =  [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n\n# sorting the dataframe based on VIF_value\nVIF.sort_values('VIF_value', ascending= False, inplace = True)\n\n# checking the dataframe\nVIF","830e09a5":"# Dropping TOEFL Score from X_train\nX_train.drop('CGPA', axis = 1, inplace = True)","dadf748a":"# adding constant to X_train as statsmodel in built doesn't add constant\nX_train_sm = sm.add_constant(X_train)\n\n# creating the model object\nlr_model_5 = sm.OLS(y_train, X_train_sm)\n\n# fitting the model on top of the data\nlr_model_5 = lr_model_5.fit()\n\n# checking the summary statistics of the model\nlr_model_5.summary()","638e9761":"# checking the VIF values\n\n# creating the dataframe of the VIF values\nVIF = pd.DataFrame()\n\n# adding column to the VIF dataframe for columns of the X_train\nVIF['features'] = X_train.columns\n\n# adding column for the VIF values of the features\nVIF['VIF_value'] =  [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n\n# sorting the dataframe based on VIF_value\nVIF.sort_values('VIF_value', ascending= False, inplace = True)\n\n# checking the dataframe\nVIF","560668b4":"# Dropping Research from X_train\nX_train.drop('TOEFL Score', axis = 1, inplace = True)","967a3e6b":"# adding constant to X_train as statsmodel in built doesn't add constant\nX_train_sm = sm.add_constant(X_train)\n\n# creating the model object\nlr_model_6 = sm.OLS(y_train, X_train_sm)\n\n# fitting the model on top of the data\nlr_model_6 = lr_model_6.fit()\n\n# checking the summary statistics of the model\nlr_model_6.summary()","0c820494":"# checking the VIF values\n\n# creating the dataframe of the VIF values\nVIF = pd.DataFrame()\n\n# adding column to the VIF dataframe for columns of the X_train\nVIF['features'] = X_train.columns\n\n# adding column for the VIF values of the features\nVIF['VIF_value'] =  [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n\n# sorting the dataframe based on VIF_value\nVIF.sort_values('VIF_value', ascending= False, inplace = True)\n\n# checking the dataframe\nVIF","672748ba":"# Making predictions on the train dataset\ny_train_pred = lr_model_6.predict(X_train_sm)","c20dfb61":"# analyzing the y_train_pred\ny_train_pred.head()","895b6887":"# checking the distribution of the error terms\nres = y_train - y_train_pred\nsns.distplot(res)","0a580d2b":"# checking for the assumption whether there exists any pattern in the error terms\nplt.figure()\nsns.scatterplot(y_train, res)\nplt.show()","f6816768":"# analyzing the df_test\ndf_test.head()","c3aeffa5":"# scaling the test data using the scaler object defined for scaling of train dataset\ndf_test[::] = scaler.transform(df_test)","9a5e6170":"# analyzing the df_test after scaling\ndf_test.head()","86d67551":"# creating X_test and y_test\ny_test =  df_test.pop('Chance of Admit ')\nX_test = df_test","df24f6b2":"# analyzing X_test\nX_test.head()","7ce3e58c":"# analyzing y_test\ny_test.head()","209284ec":"# modifying the X_test using the features of the model build\nX_test = X_test[X_train.columns]","5e2120f3":"# adding constant to X_test\nX_test_sm = sm.add_constant(X_test)","08883659":"# making predictions using model\ny_test_pred = lr_model_6.predict(X_test_sm)","16fa5efe":"# checking the r2_score on the predictions made on the test set\nr2_score_test = r2_score(y_test, y_test_pred)\nr2_score_test","486f50bb":"# checking the r2_score on the train set again\nr2_score_train = r2_score(y_train, y_train_pred)\nr2_score_train","82dabe04":"# checking the MSE and RMSE as well on the test data set\nmean_squared_error_test =  mean_squared_error(y_test, y_test_pred)\nprint('The MSE value on test dataset {}'.format(mean_squared_error_test))\nRMSE_test = np.sqrt(mean_squared_error_test)\nprint('The RMSE value on test dataset {}'.format(RMSE_test))","b737b8db":"# checking the MSE and RMSE as well on the train data set\nmean_squared_error_train =  mean_squared_error(y_train, y_train_pred)\nprint('The MSE value on train dataset {}'.format(mean_squared_error_train))\nRMSE_train = np.sqrt(mean_squared_error_train)\nprint('The RMSE value on train dataset {}'.format(RMSE_train))","85fac406":"# analyzing the error between y_test and y_test_pred\nerror = y_test - y_test_pred\nerror.head()","0762cbf0":"# creating a dataframe having y_last and the error terms\nlast_error_datafarme = pd.DataFrame()\n\n# adding column for y_last\nlast_error_datafarme['True values'] = y_test\n\n# adding error terms as a column\nlast_error_datafarme['Error values'] = error\n\n# restricting the observation to be last 100 of the validation set\nlast_error_datafarme = last_error_datafarme.tail(100)\n\n# checking the dataframe\nlast_error_datafarme.head()","8e618968":"# checking the shape of the last_error_dataframe\nlast_error_datafarme.shape","e09fd9a2":"# checking the dataframe for which last 100 observations error has been defined\nlast_error_datafarme.head()","b7c8a9ab":"# adding a column for computing RMSE for each data point\nlast_error_datafarme['RMSE'] = last_error_datafarme['Error values'].apply(lambda x: np.sqrt(x**2))","124a3f29":"# checking the dataframe after addition of column\nlast_error_datafarme.head()","d30a41a0":"- From tha above summary statistics still we can find some of the features which are insignificant. Also the R square value of the model still considerably high. Let's look at the VIF values of the features before dropping the features.","fd6100de":"- Let's start the model building process using the Manual selection method. In which we will be using top down approach or the backward selection method. In which we will be considering all the features at a time and perform manual feature elimination step by step taking into consideration of p values and VIF values of the coefficients.\n- Before building the model we need to create X_train and y_train out of df_train dataset.","f511721d":"- from the above summary statistics of the model we can see that there are some features which are insignificant as per their p values and also the R square value si terribly high which is an indication that model has overfitted on the training dataset rather than identifying generalised patterns in the traning dataset. In order to avoid overfitting problem we need to make the model light by removing some of the insignificant features from the model so that model will be kind of balanced between the bias and variance.","20275fc2":"- Since we have used the min-max scaler we can see that all the max values of the variables are 1.0. Since we have fitted and transformed on the same training dataset we can see max values as 1.0.","81caf6e8":"### Data Inspection","4e7b4142":"- Hence we have mentioned the error caused between the actual and predicted values by the model for the last 100 data points of the vadlidation dataset.","076e2f27":"- Considering last 100 observations of the validation set and indicating the error value ","65bee832":"### Task 2","4b3ac694":"- We can still see some of the features having high VIF values. Let's drop the feature having highest VIF in order to make the model light and free from overfitting.","ad1385e4":"- As the above summary statistics of the model and VIF values we can see that SOP feature has high p value and realtively low vif value when compared to other features. Hence it is better to drop first the insignificant features so that the features having vif values can evidence the decrease in vif value.","e438d269":"- In the above dataframe Chance of Admit is the target variable and rest other are predictor variables.","74d1eac0":"- From above summary statistics we can see that all the features are significant as per their p values. Let's look at their VIF values.","21231c5b":"- The reason for plotting the error terms in relation with either y_train or y_test is to check whether there exists any visible pattern in the error terms or not. If there exists any visible pattern in the error terms distribution then it is can indication that the model has failed to include some of the explanatory variables and in such case there is a requirement of rebuilding the model. If there exists no visible pattern in the error terms distribution then it is an indication that the model has captured all the explanatory features and has left behind random noise in the error terms distribution. From the above distribution we can see that there doesn't exists any fixed pattern in error terms distribution.","26100d25":"- The reason for plotting pair plots is we can get to know whether there exists amy linear relationship between the target variable and the predictors variables. Knowing so, we will get to confirmation whether we can built linear regression model using these predictor variables.\n- From the above visualization we can see that there exists some positive correlation between the taregt variable and the predictor variables. Hence the data in hand is perfectly suitable for building a linear regression predictive model.\n- At the same time, the predictor variables are also strongly correlated with each other. Which again raises the issue of multicollinearity which can be handled during modelling.<br><br>\nThe pair plot just determines the scatter plot visualizations between pairs of numerical variables. In order to understand the quantified relationships between the variables we can check for heatmap.","fcfe72b7":"__Steps involved in Manual Feature Elimination are:__\n- check for the variables having high vif and high p values so that they can be dropped\n- check for the variables having high p value and low vif so that they can be dropped\n- check for the variables having low p value and high vif which can be dropped once the variables having high p value and low vif are dropped. Doing so, the variables having high vif value will be dropped upon rebuilding the model.","3941c375":"### Task 3","5e0e38ff":"- Assign RMSE values for the last 100 observations of the test dataset","39af6dfb":"### EDA","28cbd47a":"- From the above summary statistics we can see that all the features are significant as per their p values. But still the R square value is very high which is an indication that the model is still overfitting on the training dataset. Let's look at the VIF values before taking any call for dropping a particular feature.","16de3aa3":"### Residual Analysis","56269507":"- As per summary statistics and vif values we can see that features are significant as per their p values and vif values which an indication that there doesn't exists any multicollinearity issue in the model. In order to check whether the model we have built was able to pick generalised patterns in the data or not we need to check on the test data set. If the performace of the model on the test dataset as well is close to train dataset performance then we can say that the model is kind of generalized but not an best model.","a93f27a6":"### Making Predictions","8fe40321":"- From the distributions we can see that the distributions are centered across their mean value mostly and the distributions are almost normal distributions though they have some spikes in distribution.","74a137f0":"### Model Building","62ebd24b":"#### Model 6","9f53bcef":"- Generally RMSE metric is calculated to evaluate the goodness of fit of the model. Lower the RMSE the better the model. RMSE value indicates the variance between the predicted values and the actual values. Lower RMSE value indicates that the model has fit closely to the actual data points and there exists minimum difference between the actual and the predicted data points. But when needed to calculate the RMSE value for indiviual data point we would be computing by taking the root of the square error of that particular data point.","8f464a39":"- From the above information we can see that there exists no null values in the columns.\n- Also we can see that the data types of the columns have been correctly mapped to their respective data types.\n- All the colunmns are numerical variables expect the column Research which can ordinal categorical variable which is encoded with 1's and 0's\n- Since the target variable is quantitative variable we use regression techniques to predict the value.","25f5da07":"- From the above plot we can see that variation Research variable in relation with target variable. The median value of people having done Research is higher when compared to people who didn't perform any Research activity. Thus people having done Reseach have higher chnaces getting a admission.","dccd21cc":"- We can see that some of the features having insignificant p values. Let's drop such features having high p value and low vif values.","af31dbc8":"#### Model 2","8ec00a69":"#### First Model","3d5a9d32":"###  Data Preparation","94da5895":"- From above summary statistics we can see that all the features are significant as per teir p values. But the R square value is still on a higher side. Having such high value will be problem for the model prediction on a unseen dataset. Let's look at the VIF values before taking any call for dropping the features so as to make the model light.","020fe73a":"#### Model 4","2f16e922":"- From the above distribution we can see that the error terms are more of the sort normally distributed hence we have satisfied the assumption of error terms hould be normally distributed with mean 0 and some standard deviation. Also we have satisfied the assumption of homosadacity which says that there should be constant variance in the error terms from the above distribution.","0f1b19e4":"__The steps involved in Data Preparation as follows :__\n- Train Test Split of the data\n- Rescaling of the features in order to bring all the feature variables into single scale for better interpretation of variables in relation with target variable over other variables\n- Since we don't have any categorical variables we no need to perform one hot encoding or the dummy encoding process.","84b1c3ef":"- We can see that features are significant as per p values. In order to make the model further light let's drop the feature having high vif value.","a4f09d11":"- From the heat map we have an quantified correlations between pairs of numerical variables of the data.\n- We can see that predictor variables are strongly correlated among each others.\n- Also there exists strong positive correlation between target and the predictor variables.","37574eb8":"#### Model 3","21a9deab":"- From the above statistical description of the numerical column we can have an idea about the descriptive statistics value information of the numerical columns in the data.\n- Upon observing the quantile distribution of the columns we can most of the columns have almost normal distribution spread as their median values and the max values are close to each other.","b50d0f67":"- From the above summary statistics we can see that all the features are statistically significant.","5b2016ef":"#### Model 5","eb3c6698":"- As per above summary statistics and the VIF values we can see that there are some features having low p values and high vif values and also features having high p value and low vif values. But as per the call we proceed to drop the features having high p value and low vif first and then again look at the features having vif values after rebuilding the model.","f7bf8fa4":"- From the above mean square error and root mean square error values we can see that the values are considerably small which is an inidcation that there doesn't exists much of the difference between the true values and the predicted values.","75f3a060":"- From the above R square values on the train and test we can see that model is able to perform slightly well on the unseen dataset when compared to the trained dataset."}}