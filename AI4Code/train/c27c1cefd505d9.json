{"cell_type":{"8be8ac82":"code","21386ac0":"code","ed459ffe":"code","eb9e7341":"code","25e60d65":"code","9bdfc3bf":"code","e6861cc0":"code","4036a632":"code","0bb6a343":"code","e460f91f":"code","ea48c971":"code","a7ad5518":"code","573e03d5":"code","64aa10e4":"code","627a7f1f":"code","bba18748":"code","6fd2abee":"code","c25da306":"code","943164ec":"code","e627aac5":"code","507fce67":"code","01599169":"code","80764199":"markdown"},"source":{"8be8ac82":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","21386ac0":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","ed459ffe":"train_data=pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv.zip')\ntest_data=pd.read_csv('\/kaggle\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv.zip')","eb9e7341":"train_data.head()","25e60d65":"print(train_data.info())","9bdfc3bf":"print(test_data.info())\n","e6861cc0":"import sys,os,re,csv,codecs\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense,Conv1D,LSTM,Embedding,Dropout,Bidirectional,MaxPooling1D,GlobalMaxPooling1D\nfrom keras.models import Sequential\n","4036a632":"r=train_data.copy()\nr.drop(columns=['id','comment_text'],inplace=True)\nclass_names=list(r.columns)\nprint(class_names)","0bb6a343":"labels_train=train_data[class_names].values\nfeatures_train=train_data['comment_text']\nfeatures_test=test_data['comment_text']","e460f91f":"max_limit_of_words=30000\ntokenizer=Tokenizer(num_words=max_limit_of_words, filters='!\"#$%&()*+,-.\/:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0)\ntokenizer.fit_on_texts(list(features_train))","ea48c971":"token_train=tokenizer.texts_to_sequences(features_train)","a7ad5518":"token_test = tokenizer.texts_to_sequences(features_test)\nword_index = tokenizer.word_index\nvocab_size = len(word_index)\nmean = np.mean([len(i) for i in token_train])\nstd = np.std([len(i) for i in token_train])\nmaximum=int(mean+std*3)\n\naX_train = pad_sequences(token_train,maxlen=maximum,padding='post',truncating='post')\n","573e03d5":"aX_test=pad_sequences(token_test,maxlen=maximum,padding='post',truncating='post')","64aa10e4":"dim=100\nei={}\nfile=open('\/kaggle\/input\/glove6b100dtxt\/glove.6B.100d.txt',encoding='utf-8')\nfor line in file:\n    vals=line.rstrip().rsplit(' ',dim)\n    word = vals[0]\n    coefs = np.asarray(vals[1:], dtype='float32')\n    ei[word] = coefs\nfile.close()\nprint('Found {} word vectors.'.format(len(ei)))","627a7f1f":"em = np.zeros((vocab_size +1,dim))\ntokens = []\nlabels = []\n\nfor word,i in word_index.items():\n    temp = ei.get(word)\n    if temp is not None:\n        em[i] = temp","bba18748":"embedding_layer = Embedding(len(word_index)+1,dim,input_length=maximum,weights=[em])","6fd2abee":"model=Sequential()\nmodel.add(embedding_layer)\nmodel.add(Bidirectional(LSTM(30,return_sequences=True,dropout = 0.1 , recurrent_dropout = 0.1)))\nmodel.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\nmodel.add(MaxPooling1D(3))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(6, activation='sigmoid'))\n\nmodel.summary()","c25da306":"model.summary()","943164ec":"from sklearn.model_selection import train_test_split\nX_train, X_cross_val, Y_train,Y_cross_val = train_test_split(aX_train, labels_train,test_size=0.30,shuffle=True)","e627aac5":"model.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\nhistory = model.fit(X_train, Y_train, batch_size=800, epochs=1,validation_data=(X_cross_val, Y_cross_val),verbose=1, shuffle=True )","507fce67":"test_labels = model.predict([aX_test], batch_size=800, verbose=1)\n","01599169":"mysubmission = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/sample_submission.csv.zip')\nmysubmission[class_names] = test_labels\nmysubmission.to_csv('submission.csv')","80764199":"model.add(MaxPooling1D(4))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(150,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(50,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(6,activation='sigmoid'))\n"}}