{"cell_type":{"c2004c92":"code","c0f71d0c":"code","153b1621":"code","106fdbfd":"code","97926f89":"code","45631771":"code","9746c4ee":"code","5ca6e1d6":"code","db595784":"code","2fe3d6a3":"code","5dffcfd7":"code","bc53ce70":"code","b81f0a36":"code","81a64cf7":"code","eadec930":"code","4e20efd1":"code","90251112":"code","b326cba1":"code","593cd664":"code","f4ff1521":"markdown","f0256ecc":"markdown","47c588bd":"markdown"},"source":{"c2004c92":"import numpy as np\nimport glob","c0f71d0c":"# ver01 pretrained_models = glob.glob(f'..\/input\/resnet50-04-2019\/*.pth') + glob.glob(f'..\/input\/eb7-00-baseline\/*.pth') + glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth')\n# ver02 pretrained_models = glob.glob(f'..\/input\/resnet50-04-2019\/*.pth') + glob.glob(f'..\/input\/eb7-00-baseline\/*.pth')\n# ver03 pretrained_models = glob.glob(f'..\/input\/resnet50-04-2019\/*.pth') + glob.glob(f'..\/input\/resnet152-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7-00-baseline\/*.pth')\n# ver04 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/resnet152-04-2019data\/*.pth')\n# ver05 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/resnet152-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7-00-baseline\/*.pth')\n# ver06 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/resnet152-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7-seed70\/*.pth')\n# ver07 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7m-seed70\/*.pth')\n# ver08 pretrained_models = glob.glob(f'..\/input\/resnet152-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7m-seed70\/*.pth')\n# ver16 pretrained_models = glob.glob(f'..\/input\/densenet201-seed60\/*.pth') + glob.glob(f'..\/input\/eb7m-seed70\/*.pth')\n# ver17 pretrained_models = glob.glob(f'..\/input\/eb7m-seed70\/*.pth')\n# ver19 pretrained_models = glob.glob(f'..\/input\/eb7slseed70\/efficientnet-b7sl_SEED70.best\/*.pth')\n# ver20 pretrained_models = glob.glob(f'..\/input\/eb7slseed70\/efficientnet-b7sl_SEED70.orig\/*.pth')\n# ver21 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7slseed70\/efficientnet-b7sl_SEED70.best\/*.pth')\n# ver22 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7slseed70\/efficientnet-b7sl_SEED70.orig\/*.pth')\n# ver23 pretrained_models = glob.glob(f'..\/input\/densenet201-seed60\/*.pth') + glob.glob(f'..\/input\/eb7slseed70\/efficientnet-b7sl_SEED70.best\/*.pth')\n# ver28 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7m-seed70\/*.pth')\n# ver33 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7m-seed70\/*.pth') + glob.glob(f'..\/input\/eb7slseed70\/efficientnet-b7sl_SEED70.best\/*.pth')\n# ver34 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7m-seed70\/*.pth') + glob.glob(f'..\/input\/eb7mseed71\/*.pth')\n# ver38 pretrained_models = glob.glob(f'..\/input\/ebmls-seed70\/*.pth') + glob.glob(f'..\/input\/eb7mseed71\/*.pth')\n# ver41 pretrained_models = glob.glob(f'..\/input\/ebmls-seed70\/*.pth')\n# ver42 pretrained_models = glob.glob(f'..\/input\/eb7mseed71\/*.pth')\n# ver47, ver48 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/resnet152-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7slseed70\/efficientnet-b7sl_SEED70.best\/*.pth')\n# ver50 pretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/resnet152-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7m-seed70\/*.pth') + glob.glob(f'..\/input\/eb7slseed70\/efficientnet-b7sl_SEED70.best\/*.pth')\n# ver51\n#pretrained_models = glob.glob(f'..\/input\/efntb7\/efficientnet-b7m_SEED70\/*.pth') + glob.glob(f'..\/input\/efntb7\/efficientnet-b7m_SEED72\/*.pth') + glob.glob(f'..\/input\/efntb7\/efficientnet-b7m_SEED73\/*.pth') + glob.glob(f'..\/input\/efntb7\/efficientnet-b7sl_SEED71.pretrained\/*.pth')\n# ver59\npretrained_models = glob.glob(f'..\/input\/densenet201-04-2019data\/*.pth') + glob.glob(f'..\/input\/eb7m-seed7x\/efficientnet-b7m_SEED70\/*.pth') + glob.glob(f'..\/input\/eb7m-seed7x\/efficientnet-b7m_SEED72\/*.pth') + glob.glob(f'..\/input\/eb7m-seed7x\/efficientnet-b7m_SEED73\/*.pth') + glob.glob(f'..\/input\/eb7m-seed7x\/efficientnet-b7sl_SEED71.pretrained\/*.pth')\n\n\nprint(f'{len(pretrained_models)} models found.')\nprint('\\n'.join(np.sort(pretrained_models)))","153b1621":"import pandas as pd\n\n#\nimport torch\nimport torch.nn as nn\nimport torch.utils.data as data\n#import timm\n\n# Importing Libraries for Image Augmentations\nimport torchvision\nfrom torchvision import models, transforms  # \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3001\u753b\u50cf\u5909\u63db\nimport albumentations as A\nfrom albumentations import Compose\nfrom albumentations.pytorch import ToTensorV2\n\n# Working with Files\nimport os\nfrom pathlib import Path\nimport random\nimport json\nimport time\nimport pickle\n\n\n# Fancy progress bar\nfrom tqdm import tqdm\n\n# Static Graphs\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Working with images\nimport cv2\n\n\n# \u4e71\u6570\u30b7\u30fc\u30c9\u306e\u56fa\u5b9a\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nSEED = 42\nseed_everything(seed=SEED)","106fdbfd":"import sys\nsys.path.append(\"\/kaggle\/input\/package\/EfficientNet-PyTorch-1.0\")\nfrom efficientnet_pytorch import EfficientNet","97926f89":"SIZE = 512        # image size\nnum_classes = 5","45631771":"device = ('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9: {device}')","9746c4ee":"# \u30c6\u30b9\u30c8\u753b\u50cf\u30d5\u30a1\u30a4\u30eb\u540d(image_id)\u306e\u30ea\u30b9\u30c8\nif os.getenv('KAGGLE_KERNEL_RUN_TYPE') == 'Interactive':\n    # Kaggle\u74b0\u5883\u3067\u30c6\u30b9\u30c8 (train_images \u306e32\u30d5\u30a1\u30a4\u30eb\u3092\u4f7f\u7528\u3057\u3066\u5b9f\u884c)\n    print(\"Test run in Kaggle environment.\")\n    BASE_DIR = \"..\/input\/cassava-leaf-disease-classification\"\n    TEST_PATH = f'{BASE_DIR}\/train_images'\n    test_files = os.listdir(f'{TEST_PATH}\/')[:32]\nelif os.getenv('KAGGLE_KERNEL_RUN_TYPE') == 'Batch':\n    print(\"In Kaggle environment.\")\n    BASE_DIR = \"..\/input\/cassava-leaf-disease-classification\"\n    TEST_PATH = f'{BASE_DIR}\/test_images'\n    test_files = os.listdir(f'{TEST_PATH}\/')\nelse:\n    # \u30ed\u30fc\u30ab\u30eb\u74b0\u5883\n    print(\"In the local environment.\")\n    BASE_DIR = \"data\"\n    TEST_PATH = f'{BASE_DIR}\/train_images'\n    test_files = os.listdir(f'{TEST_PATH}\/')[:32]     # glob.glob() \u3068\u9055\u3063\u3066\u30d5\u30a1\u30a4\u30eb\u540d\u3060\u3051\u304c\u5165\u308b\n    PRETRAINED_MODEL_PATH=\"1610594484mf\/bak\/00\u500b\u52255fold\u8a08\u7b97\"\n\nprint(f\"Number of test  images: {len(test_files)}\")","5ca6e1d6":"# \u4e88\u6e2c\u7d50\u679c\u3092\u683c\u7d0d\u3059\u308b DataFrame\ndf_test = pd.DataFrame(test_files, columns=['image_id'])\ndf_test['label'] = 1","db595784":"if len(df_test) == 1:\n    df_test.loc[1] = df_test.loc[0]\n    print(df_test)","2fe3d6a3":"# tta5\nmean = [0.485, 0.456, 0.406]\nstd  = [0.229, 0.224, 0.225]\n\ntransform = {\n    'test': [\n        Compose([\n            A.CenterCrop(SIZE, SIZE),\n            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.),\n        Compose([\n            A.HorizontalFlip(p=1),\n            A.CenterCrop(SIZE, SIZE),\n            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.),\n        Compose([\n            A.RandomResizedCrop(SIZE, SIZE),\n            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.),\n#        Compose([\n#            A.RandomResizedCrop(SIZE, SIZE),\n#            A.HorizontalFlip(p=0.5),\n#            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n#            ToTensorV2(p=1.0),\n#        ], p=1.),\n#        Compose([\n#            A.RandomResizedCrop(SIZE, SIZE),\n#            A.VerticalFlip(p=1),\n#            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n#            ToTensorV2(p=1.0),\n#        ], p=1.),\n#        Compose([\n#            A.Rotate(p=1),\n#            A.RandomResizedCrop(SIZE, SIZE),\n#            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n#            ToTensorV2(p=1.0),\n#        ], p=1.),\n        Compose([\n            A.Rotate(p=1),\n            A.CenterCrop(SIZE, SIZE),\n            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.),\n    ]\n}","5dffcfd7":"# \u6700\u7d42\u5c64\u524d\u3067 mixup \u3092\u884c\u3046\u30e2\u30c7\u30eb\n\nclass FinalLayerMixupModel(nn.Module):\n    def __init__(self, model, criterion, num_classes, alpha):\n        '''\n        model: \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u6307\u5b9a\n        '''\n        super(FinalLayerMixupModel, self).__init__()\n        self.convlayer = torch.nn.Sequential(*(list(model.children())[:-1]))\n        num_ftrs = model.fc.in_features\n        self.fc = nn.Linear(num_ftrs, num_classes)\n        self.criterion = criterion\n        self.alpha = alpha\n        \n    def forward(self, inputs, labels, phase):\n        # vailidation\u6642\n        if phase == 'val':\n            x = self.convlayer(inputs)\n            x = x.squeeze()\n            outputs = self.fc(x)\n            loss = self.criterion(outputs, labels)\n            \n            return outputs, loss\n\n        # test(prediction)\u6642\n        if phase == 'test':\n            x = self.convlayer(inputs)\n            x = x.squeeze()\n            outputs = self.fc(x)\n            \n            return outputs\n        \n        # train\u6642\n        alpha = self.alpha\n        if alpha > 0:\n            lam = np.random.beta(alpha, alpha)\n        else:\n            lam = 1\n\n        #index = torch.randperm(len(labels)).to(device)\n        index = torch.randperm(len(labels))\n\n        x1 = inputs             # torch.Size([64, 3, 256, 256])\n        x2 = inputs[index]      # torch.Size([64, 3, 256, 256])\n\n        x1 = self.convlayer(x1) # torch.Size([64, 512, 1, 1])\n        x2 = self.convlayer(x2) # torch.Size([64, 512, 1, 1])\n        \n        # \u7573\u307f\u8fbc\u307f\u5c64\u306e\u7d50\u679c\u3092 mix\n        mixed_x = lam * x1 + (1 - lam) * x2  # torch.Size([64, 512, 1, 1])\n        mixed_x = mixed_x.squeeze()          # torch.Size([64, 512])\n        outputs = self.fc(mixed_x)           # torch.Size([64, 5])\n        \n        labels_a = labels\n        labels_b = labels[index]\n        \n        # loss \u306e\u8a08\u7b97\n        pred = outputs\n        loss = lam * self.criterion(pred, labels_a) + (1 - lam) * self.criterion(pred, labels_b)\n        \n        return outputs, loss, labels_a, labels_b, lam","bc53ce70":"# \u6700\u7d42\u5c64\u524d\u3067 mixup \u3092\u884c\u3046\u30e2\u30c7\u30eb\n# - \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u3001\u7573\u307f\u8fbc\u307f\u5c64\u3068\u6700\u7d42\u5c64\u3092\u5206\u3051\u308b\n# - \u6700\u7d42\u5c64\u306e\u51fa\u529b\u30b5\u30a4\u30ba\u3092\u5909\u3048\u308b\n# - \u7573\u307f\u8fbc\u307f\u5c64\u306e\u5f8c\u3067 mixup \u3092\u884c\u3046\n\nclass FinalLayerMixupModelDenseNet(nn.Module):\n    def __init__(self, model, criterion, num_classes, alpha):\n        '''\n        model: \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u6307\u5b9a\n        '''\n        super(FinalLayerMixupModelDenseNet, self).__init__()\n        self.convlayer = model.features\n        self.AdaptiveAvgPool2d = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n        num_ftrs = model.classifier.in_features\n        self.fc = nn.Linear(num_ftrs, num_classes)\n        self.criterion = criterion\n        self.alpha = alpha\n        \n    def forward(self, inputs, labels, phase):\n        # vailidation\u6642\n        if phase == 'val':\n            x = self.convlayer(inputs)\n            x = self.AdaptiveAvgPool2d(x)\n            x = x.squeeze()\n            outputs = self.fc(x)\n            loss = self.criterion(outputs, labels)\n\n            return outputs, loss\n\n        # test(prediction)\u6642\n        if phase == 'test':\n            x = self.convlayer(inputs)\n            x = self.AdaptiveAvgPool2d(x)\n            x = x.squeeze()\n            outputs = self.fc(x)\n\n            return outputs\n        \n        # train\u6642\n        alpha = self.alpha\n        if alpha > 0:\n            lam = np.random.beta(alpha, alpha)\n        else:\n            lam = 1\n\n        #index = torch.randperm(len(labels)).to(device)\n        index = torch.randperm(len(labels))\n\n        x1 = inputs             # torch.Size([12, 3, 512, 512])\n        x2 = inputs[index]      # torch.Size([12, 3, 512, 512])\n\n        x1 = self.convlayer(x1) # torch.Size([12, 1920, 16, 16])\n        x2 = self.convlayer(x2) # torch.Size([12, 1920, 16, 16])\n\n        x1 = self.AdaptiveAvgPool2d(x1)  # torch.Size([12, 1920, 1, 1])\n        x2 = self.AdaptiveAvgPool2d(x2)  # torch.Size([12, 1920, 1, 1])\n\n        # \u7573\u307f\u8fbc\u307f\u5c64\u306e\u7d50\u679c\u3092 mix\n        mixed_x = lam * x1 + (1 - lam) * x2  # torch.Size([64, 1920, 1, 1])\n        mixed_x = mixed_x.squeeze()          # torch.Size([64, 1920])\n        outputs = self.fc(mixed_x)           # torch.Size([64, 5])\n\n        labels_a = labels\n        labels_b = labels[index]\n\n        # loss \u306e\u8a08\u7b97\n        pred = outputs\n        loss = lam * self.criterion(pred, labels_a) + (1 - lam) * self.criterion(pred, labels_b)\n\n        return outputs, loss, labels_a, labels_b, lam","b81f0a36":"class FinalLayerMixupModelEN(nn.Module):\n    def __init__(self, model, criterion, num_classes, alpha):\n        super(FinalLayerMixupModelEN, self).__init__()\n            \n        num_ftrs = model._fc.in_features\n        model._fc = nn.Linear(num_ftrs, num_classes)   \n        \n        self.model = model\n        self.criterion = criterion\n        \n    def forward(self, inputs, labels, phase):\n        # vailidation\u6642\n        if phase == 'val':\n            outputs = self.model(inputs)\n            loss = self.criterion(outputs, labels)\n\n            return outputs, loss\n\n        # test(prediction)\u6642\n        if phase == 'test':\n            outputs = self.model(inputs)\n\n            return outputs\n        \n        # train\u6642\n\n        print('\u3053\u3053\u306b\u304d\u3066\u306f\u3044\u3051\u306a\u3044')\n        sys.exit()","81a64cf7":"# \u63a8\u8ad6\u7528\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n\nclass TestDataset(data.Dataset):\n    def __init__(self, df, transform=None):\n        super().__init__()\n\n        self.image_ids = df.image_id.tolist()\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_ids)\n    \n    def load_image(self, image_id):\n        img = cv2.imread(f'{TEST_PATH}\/{image_id}')  # (H, W, C) \u306e numpy.ndarray\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)              # BGR => RGB \u306b\u5909\u63db\n        return img\n    \n    def __getitem__(self, index):\n        image_id = self.image_ids[index]\n        \n        img = self.load_image(image_id)\n        \n        if self.transform:\n            img = self.transform(image=img)['image']\n        \n        return img, image_id","eadec930":"# \u30e2\u30c7\u30eb\u3067\u63a8\u8ad6\u3092\u884c\u3046\u95a2\u6570\ndef predict_model (basename, net, dataloader):\n    '''\n    basename: \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u540d\n    net     : \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\n    '''\n\n    model_start_time = time.time()\n    \n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n    net.to(device)\n    net.eval()    # \u691c\u8a3c\u30e2\u30fc\u30c9\n    torch.set_grad_enabled(False)\n    \n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \n    #corrects = 0    # \u6b63\u89e3\u6570\n    #count = 0       # \u51e6\u7406\u3057\u305f\u30c7\u30fc\u30bf\u6570\n    \n    #df_test[basename] = np.nan\n    \n    probability = []\n    \n    #scaler = torch.cuda.amp.GradScaler()\n    \n    for phase in ['test']:\n        progress = tqdm(dataloader[phase], desc=f\"{basename}: \")\n\n        # \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u304b\u3089\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u53d6\u308a\u51fa\u3059\u30eb\u30fc\u30d7\n        for inputs, image_ids in progress:\n            # GPU\u306b\u30c7\u30fc\u30bf\u3092\u8ee2\u9001\n            inputs = inputs.to(device)\n\n            # forward\u8a08\u7b97\n            with torch.cuda.amp.autocast():\n                outputs = net(inputs, False, 'test')\n                _, preds = torch.max(outputs, 1)  # \u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\n\n                probability.append(torch.softmax(outputs, dim=1).cpu().numpy())\n\n            #for i, image_id in enumerate(image_ids):\n            #    df_test.loc[df_test.image_id == image_id, basename] = preds[i].item()\n\n    #df_test[basename] = df_test[basename].astype(np.int64)\n    \n    print(f'{basename} time: {time.time() - model_start_time:.2f}[sec]')\n\n    return np.concatenate(probability)","4e20efd1":"probability = []\n\nstart_time = time.time()\n\nfor pretrained_model in pretrained_models:\n    basename = os.path.splitext(os.path.basename(pretrained_model))[0]\n\n    # model\n\n    criterion = nn.CrossEntropyLoss()\n\n    if 'resnet18' in basename:\n        MODEL_NAME = 'resnet18'\n        net = models.resnet18(pretrained=False)\n        net = FinalLayerMixupModel(net, criterion, num_classes, False)\n        BATCH_SIZE = 64\n    elif 'resnet50' in basename:\n        MODEL_NAME = 'resnet50'\n        net = models.resnet50(pretrained=False)\n        net = FinalLayerMixupModel(net, criterion, num_classes, False)\n        BATCH_SIZE = 32\n    elif 'resnet152' in basename:\n        MODEL_NAME = 'resnet152'\n        net = models.resnet152(pretrained=False)\n        net = FinalLayerMixupModel(net, criterion, num_classes, False)\n        BATCH_SIZE = 16\n    elif 'resnext101' in basename:\n        MODEL_NAME = 'resnext101'\n        net = models.resnext101_32x8d(pretrained=False)\n        net = FinalLayerMixupModel(net, criterion, num_classes, False)\n        BATCH_SIZE = 12    #  3063MiB\n    elif 'densenet201' in basename:\n        MODEL_NAME = 'densenet201'\n        net = models.densenet201(pretrained=False)\n        net = FinalLayerMixupModelDenseNet(net, criterion, num_classes, False)\n        BATCH_SIZE = 12\n    elif 'efficientnet-b7' in basename:\n        MODEL_NAME = 'efficientnet-b7'\n        net = EfficientNet.from_name(MODEL_NAME)\n        net = FinalLayerMixupModelEN(net, criterion, num_classes, False)\n        BATCH_SIZE = 10\n    else:\n        print(f'{basename} is not supported.')\n        sys.exit()\n    \n    print(f'{basename}: {MODEL_NAME}')    \n    \n    if MODEL_NAME == 'efficientnet-b7':\n        #net.model.load_state_dict(torch.load(pretrained_model))\n        if 'b7m_SEED' in pretrained_model:\n            net.model.load_state_dict(torch.load(pretrained_model))\n        else:\n            net.load_state_dict(torch.load(pretrained_model))\n    else:\n        net.load_state_dict(torch.load(pretrained_model))\n        \n    \n    for param in net.parameters():\n        param.requires_grad = False\n        \n    # TTA\n    for tid, transform_ in enumerate(transform['test']):\n        print(f'transform loop={tid}')\n        dataset = {\n            'test': TestDataset(df_test, transform=transform_),\n        }\n        dataloader = {\n            'test': torch.utils.data.DataLoader(dataset['test'], batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=True),\n        }\n\n        proba = predict_model(basename, net, dataloader)\n        probability.append(proba)\n    \n    #\n    \n    del net\n    # \u30ad\u30e3\u30c3\u30b7\u30e5\u30af\u30ea\u30a2\n    torch.cuda.empty_cache()\n    \n    #break\n    \ndf_test['mean'] = np.array(probability).mean(axis=0).argmax(axis=1)\n\nprint(f'total time: {time.time() - start_time:.2f}[sec]')","90251112":"if len(df_test) == 2 and df_test.loc[0, 'image_id'] == df_test.loc[1, 'image_id']:\n    df_test = pd.read_csv(f'{BASE_DIR}\/sample_submission.csv')\nelse:\n    df_test['label'] = df_test['mean']","b326cba1":"df_test","593cd664":"# submission.csv \u306b\u4fdd\u5b58\ndf_test[['image_id', 'label']].to_csv('submission.csv', index=False)","f4ff1521":"# \u6700\u7d42\u5c64\u524d\u3067 mixup \u3092\u884c\u3046\u30e2\u30c7\u30eb\n- \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u8aad\u307f\u8fbc\u307f\u3001\u7573\u307f\u8fbc\u307f\u5c64\u3068\u6700\u7d42\u5c64\u3092\u5206\u3051\u308b\n- \u6700\u7d42\u5c64\u306e\u51fa\u529b\u30b5\u30a4\u30ba\u3092\u5909\u3048\u308b\n- \u7573\u307f\u8fbc\u307f\u5c64\u306e\u5f8c\u3067 mixup \u3092\u884c\u3046","f0256ecc":"# Ensemble Kaggle\u63a8\u8ad6\u7528\n- ver01: resnet50-04-2019, eb7-00-baseline, densenet201-04-2019data LB: 0.899\n- ver02: resnet50-04-2019, eb7-00-baseline                          LB: 0.898\n- ver03: resnet50-04-2019, eb7-00-baseline, resnet152-04-2019data   LB: 0.899 (\uff5e8\u6642\u9593)\n- ver04: densenet201-04-2019data, resnet152-04-2019data             LB: 0.900\n- ver05: densenet201-04-2019data, resnet152-04-2019data, eb7-00-baseline LB: 0.902\n- ver06: densenet201-04-2019data, resnet152-04-2019data, eb7-seed70 LB: 0.903\n- ver07: densenet201-04-2019data, eb7m-seed70 LB: 0.903\n- ver08: resnet152-04-2019data,   eb7m-seed70 LB: 0.901\n- ver09\uff5ever13: AMP\u306f\u9045\u304f\u306a\u3063\u305f\u306e\u3067\u3084\u3081\u308b\u3002BATCH_SIZE\u5909\u66f4(\u5c11\u3057\u65e9\u304f\u306a\u3063\u305f\uff1f)\u3002\u3001\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba\u5909\u66f4(32, \u65e9\u304f\u306a\u3089\u305a)\n- ver14: ver07\u3068\u540c\u3058\u3067\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u304c 16  LB: 0.900 \n- ver15: \u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\u3092 ver07 \u306b\u623b\u3059\u3002\n- ver16: densenet201-seed60, eb7m-seed70  LB: 0.901\n- ver17: eb7m-seed70  LB:0.895\n- ver19: efficientnet-b7sl_SEED70.best LB: 0.898\n- ver20: efficientnet-b7sl_SEED70.orig LB: 0.895\n- ver21: densenet201-04-2019data, efficientnet-b7sl_SEED70.best  LB: 0.900\n- ver22: densenet201-04-2019data, efficientnet-b7sl_SEED70.orig  LB: 0.898\n- ver23: densenet201-seed60, efficientnet-b7sl_SEED70.best LB: 0.900\n- ver28: densenet201-04-2019data, eb7m-seed70, tta5m  LB: 0.899\n- ver30: densenet201-04-2019data, eb7m-seed70, efficientnet-b7sl_SEED70.best  # timeout\n- ver33: densenet201-04-2019data, eb7m-seed70, efficientnet-b7sl_SEED70.best tta\u6e1b\u3089\u3059  LB: 0.901\n- ver34: densenet201-04-2019data, eb7m-seed70, eb7mseed71 tta\u6e1b\u3089\u3059  LB:0.899\n- ver35: ver07\u3068\u540c\u3058\u3067 tta \u6e1b\u3089\u3059 LB:0.901\n- ver37: ver07\u3068\u540c\u3058\u3067 tta \u306b Rotate+CenterCrop \u8ffd\u52a0 LB:0.901\n- ver40: ebmls-seed70, eb7mseed71 LB:0.897\n- ver41: ebmls-seed70 LB: 0.889 (\u524a\u9664)\n- ver42: eb7mseed71   LB: 0.895\n- ver47: densenet201-04-2019data, resnet152-04-2019data, efficientnet-b7sl_SEED70.best LB:0.902\n- ver48: densenet201-04-2019data, resnet152-04-2019data, efficientnet-b7sl_SEED70.best LB:0.902\n- ver49: densenet201-04-2019data, eb7m-seed70 (TTA\u524a\u6e1b:6\u21925)\n- ver50: densenet201-04-2019data, resnet152-04-2019data, eb7m-seed70, efficientnet-b7sl_SEED70.best, AMP\n- ver51: efntb7\u306e4\u30e2\u30c7\u30eb","47c588bd":"# \u63a8\u8ad6"}}