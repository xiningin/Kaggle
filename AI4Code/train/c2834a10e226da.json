{"cell_type":{"1f780e82":"code","dc5052c5":"code","c7317d2b":"code","705ad2a0":"code","32db3220":"code","fc26070e":"code","8caf54ce":"code","22404bce":"code","15dc9f66":"code","a63dcd9e":"code","17345294":"code","1988d3dc":"code","9892b1c4":"code","6b5bb06e":"code","20799d58":"code","ed43e86c":"code","3aa5324e":"code","86b5275e":"markdown","234ec98c":"markdown","16ac0354":"markdown","c834191a":"markdown","bd73efe8":"markdown","b752e322":"markdown","a03fec31":"markdown","8fd385da":"markdown","7f048f6c":"markdown","6c90ee13":"markdown","8fd469a2":"markdown"},"source":{"1f780e82":"import re\nimport os\nimport nltk\nimport spacy\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom wordcloud import WordCloud\n\nfrom nltk import word_tokenize\nfrom nltk.util import ngrams","dc5052c5":"# count the number of episodes in each season\nep_num = len([name for name in os.listdir('..\/input\/friends-tv-series-screenplay-script')])\n\n\nprint(\"Friends Season consists of {} episodes.\".format(ep_num))","c7317d2b":"import glob\ntexts = \"\"\nfolder_name = \"..\/input\/friends-tv-series-screenplay-script\/\"\nfor f in glob.glob(folder_name + '\/*.txt'):\n    temp = open(f,'r')\n    texts += temp.read()\n    temp.close()","705ad2a0":"len(texts)","32db3220":"text = re.sub('[^A-Za-z]+', ' ', texts)","fc26070e":"# adding screenplay notes to stopwords\nnlp = spacy.load(\"en\")\nnlp.Defaults.stop_words |= {\"d\",\"ll\",\"m\",\"re\",\"s\",\"ve\", \"t\", \"oh\", \"uh\", \"na\", \"okay\",\n                           \"didn\",\"don\",\"gon\",\"j\",\"hm\",\"um\",\"dr\",\"room\",\"int\", \"ext\", \n                           \"cut\", \"day\", \"night\", \"theme\", \"tune\",\"music\", \"ends\",\"view\",\"opening credits scene\", \n                            \"commercial break scene\", \"hey hey hey\", \"hey\", \"closing credits scene\",\"scene\",\n                            \"closeup\", 'freshly', 'squeezed', 'fade'}\nstopwords = nlp.Defaults.stop_words","8caf54ce":"# function to find and plot frequent words\ndef plot_words(words,title,color=\"#114d1e\"):\n    counts = {}\n    for i in range(len(words)):\n        counts[words[i][0]] = words[i][1]\n    plt.figure(figsize=(8,6))\n    plt.title(title, fontsize=14)\n    plt.barh(range(len(counts)), list(counts.values()), color=color, align=\"center\")\n    plt.yticks(range(len(counts)), list(counts.keys()), fontsize=12)\n    plt.gca().invert_yaxis()\n    plt.show()\n    \ndef plot_ngrams(ngrams,title,color=\"#7a2822\"):\n    counts = {}\n    for i in range(len(ngrams)):\n        counts[\" \".join(ngrams[i][0])] = ngrams[i][1]\n    plt.figure(figsize=(8,6))\n    plt.title(title, fontsize=14)\n    plt.barh(range(len(counts)), list(counts.values()), color=color,align=\"center\")\n    plt.yticks(range(len(counts)), list(counts.keys()), fontsize=12)\n    plt.gca().invert_yaxis()\n    plt.show()","22404bce":"all_words = nltk.tokenize.word_tokenize(text.lower())\nall_words_no_stop = nltk.FreqDist(w.lower() for w in all_words if w not in stopwords)\nplot_words(all_words_no_stop.most_common(10), \"Top 10 frequent words\")","15dc9f66":"bigram = nltk.FreqDist(nltk.bigrams(w.lower() for w in all_words if w not in stopwords))\nplot_ngrams(bigram.most_common(10), \"Top 10 frequent bigrams.\")","a63dcd9e":"trigrams = nltk.FreqDist(nltk.trigrams(w.lower() for w in all_words if w not in stopwords))\nplot_ngrams(trigrams.most_common(10), \"Top 10 frequent trigrams.\", \"#2b2e2b\")","17345294":"characters = [\n'monica','rachel','ross','joey','chandler','phoebe','central perk',\"opening credits scene\", \n\"commercial break scene\", \"hey hey hey\", \"hey\", \"closing credits scene\",\"scene\"]\n\n# unique names only\nnames = set(\" \".join(set(characters)).lower().split())\n\nnlp.Defaults.stop_words |= names","1988d3dc":"no_names = nltk.FreqDist(w.lower() for w in all_words if w not in stopwords)\nplot_words(no_names.most_common(10), \"Top 10 frequent words except for names\")","9892b1c4":"no_names_bigram = nltk.FreqDist(nltk.bigrams(w.lower() for w in all_words if w not in stopwords))\nplot_ngrams(no_names_bigram.most_common(10), \"Top 10 frequent bigrams except for names\")","6b5bb06e":"no_names_trigram = nltk.FreqDist(nltk.trigrams(w.lower() for w in all_words if w not in stopwords))\nplot_ngrams(no_names_trigram.most_common(10), \"Top 10 frequent trigrams except for names\", \"#2b2e2b\") ","20799d58":"# the mask image taken from http:\/\/www.designcenterassoc.com\/wp-content\/uploads\/2017\/11\/Friends-PNG-HD-e1509653607131.png\n# cooper_mask = np.array(Image.open('..\/input\/temporary\/Friends-PNG-HD-e1509653607131.png'))\n\ndef color_func(word, font_size, position, orientation, random_state=None,\n                    **kwargs):\n    return \"hsl(0, 100%, 27%)\"\n\nwc = WordCloud(background_color=\"white\", max_words=1000,\n               stopwords=stopwords, contour_width=4, contour_color='steelblue')\n\nwc.generate(\" \".join(all_words_no_stop.keys()))\n\nplt.figure(figsize=(18, 10))\nplt.imshow(wc.recolor(color_func=color_func, random_state=3),interpolation=\"bilinear\")\nplt.axis(\"off\")","ed43e86c":"\"Well, exactly {} times\".format(all_words_no_stop['coffee'])","3aa5324e":"\"It was mentioned {} times throughout all episodes\".format(all_words_no_stop['doin'])","86b5275e":"Unsuprisingly, these are the **names of the main characters**.\n\nNow let's get the most frequent bigrams and bigrams, i.e. the sequences of two and three neighbouring words respectively.","234ec98c":"In this notebook we will produce a basic analysis for Friends transcripts and hopefully get a few insights. So, pour yourself a damn fine cup of coffee and bear with me!","16ac0354":"## How many times coffee was mentioned?","c834191a":"## Word Cloud for Season 1","bd73efe8":"## 4. What's next?\nIt would be great to do some sentiment analysis on the scripts.","b752e322":"## 3. Most frequent words","a03fec31":"What will change if we remove the names?","8fd385da":"## And what about a famous How you doin?","7f048f6c":"# Introductory EDA on Friends","6c90ee13":"## 2. Data loading and preprocessing","8fd469a2":"## 1. Import Libraries"}}