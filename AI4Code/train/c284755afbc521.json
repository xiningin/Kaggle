{"cell_type":{"c2469f18":"code","7ba19bd3":"code","cccd71cd":"code","ed042f7e":"code","c788e532":"code","4bd5d231":"code","a0575020":"code","5f1b2445":"code","8abcced0":"code","9a07e12e":"code","a4745e69":"code","21a9af23":"code","764bb9dd":"code","a2274ed1":"code","34d5511a":"markdown","0a24e593":"markdown"},"source":{"c2469f18":"import os\nimport sys\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFilter, ImageEnhance\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_squared_error, log_loss, confusion_matrix\nimport matplotlib.pyplot as plt\nimport warnings                             \nimport cv2 as cv\n\nwarnings.simplefilter(\"ignore\")                      # To suppress warnings\nnp.random.seed(10)\nLEVEL = 'level_3'","7ba19bd3":"class SigmoidNeuron:\n  \n  def __init__(self):\n    self.w = None\n    self.b = None\n    \n  def perceptron(self, x):\n    return np.dot(x, self.w.T) + self.b\n  \n  def sigmoid(self, x):\n    return 1.0\/(1.0 + np.exp(-x))\n  \n  def grad_w_mse(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    return (y_pred - y) * y_pred * (1 - y_pred) * x\n  \n  def grad_b_mse(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    return (y_pred - y) * y_pred * (1 - y_pred)\n  \n  def grad_w_ce(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    if y == 0:\n      return y_pred * x\n    elif y == 1:\n      return -1 * (1 - y_pred) * x\n    else:\n      raise ValueError(\"y should be 0 or 1\")\n    \n  def grad_b_ce(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    if y == 0:\n      return y_pred \n    elif y == 1:\n      return -1 * (1 - y_pred)\n    else:\n      raise ValueError(\"y should be 0 or 1\")\n  \n  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False):\n    \n    # initialise w, b\n    if initialise:\n      self.w = np.random.randn(1, X.shape[1])\n    #  self.w = X.mean(axis=0)\n      self.b = 0\n      \n    if display_loss:\n      loss = {}\n    \n    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n      dw = 0\n      db = 0\n      for x, y in zip(X, Y):\n        if loss_fn == \"mse\":\n          dw += self.grad_w_mse(x, y)\n          db += self.grad_b_mse(x, y) \n        elif loss_fn == \"ce\":\n          dw += self.grad_w_ce(x, y)\n          db += self.grad_b_ce(x, y)\n      self.w -= learning_rate * dw\n      self.b -= learning_rate * db\n      \n      if display_loss:\n        Y_pred = self.sigmoid(self.perceptron(X))\n        if loss_fn == \"mse\":\n          loss[i] = mean_squared_error(Y, Y_pred)\n        elif loss_fn == \"ce\":\n          loss[i] = log_loss(Y, Y_pred)\n    \n    if display_loss:\n      plt.plot(loss.values())\n      plt.xlabel('Epochs')\n      if loss_fn == \"mse\":\n        plt.ylabel('Mean Squared Error')\n      elif loss_fn == \"ce\":\n        plt.ylabel('Log Loss')\n      plt.show()\n    \n      min_key = min(loss, key=loss.get)\n      print(min_key)\n      print(loss.get(min_key))\n      \n  def predict(self, X):\n    Y_pred = []\n    for x in X:\n      y_pred = self.sigmoid(self.perceptron(x))\n      Y_pred.append(y_pred)\n    return np.array(Y_pred)","cccd71cd":"def increase_brightness(img,value):\n    hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n    h, s, v = cv.split(hsv)\n\n    lim = 255 - value\n    v[v > lim] = 255\n    v[v <= lim] += value\n\n    final_hsv = cv.merge((h, s, v))\n    image = cv.cvtColor(final_hsv, cv.COLOR_HSV2BGR)\n    return image","ed042f7e":"def read_all(folder_path, key_prefix=\"\"):\n    '''\n    It returns a dictionary with 'file names' as keys and 'flattened image arrays' as values.\n    '''\n    print(\"Reading:\")\n    images = {}\n    files = os.listdir(folder_path)\n    for i, file_name in tqdm_notebook(enumerate(files), total=len(files)):\n        file_path = os.path.join(folder_path, file_name)\n        image_index = key_prefix + file_name[:-4]\n        image = cv.imread(file_path)\n        image = increase_brightness(image,10)                       # Increase the brightness of image\n        image = cv.cvtColor(image,cv.COLOR_BGR2GRAY)                # Convert into GrayScale\n        ret,image = cv.threshold(image,25,255,cv.THRESH_BINARY)     # Binary threshold to convert image into black and white only\n        image = cv.medianBlur(image,3)                              # Thicken the letter\/alphabet in the image\n        images[image_index] = image.flatten()      \n    return images","c788e532":"languages = ['en','ta', 'hi']\n\nimages_train = read_all(\"..\/input\/\"+LEVEL+\"_train\/\"+LEVEL+\"\/\"+\"background\", key_prefix='bgr_') \nfor language in languages:\n  images_train.update(read_all(\"..\/input\/\"+LEVEL+\"_train\/\"+LEVEL+\"\/\"+language, key_prefix=language+\"_\" ))\nprint(len(images_train))\n\nimages_test = read_all(\"..\/input\/\"+LEVEL+\"_test\/kaggle_\"+LEVEL, key_prefix='') \nprint(len(images_test))","4bd5d231":"list(images_test.keys())[:5]\nlist(images_train.keys())[2:2]\n#print(images_train)\n#types1 = set(type(k) for k in images_train.keys())\n#print(types1)","a0575020":"X_train = []\nY_train = []\nfor key, value in images_train.items():\n    X_train.append(value)\n    if key[:4] == \"bgr_\":\n        Y_train.append(0)\n    else:\n        Y_train.append(1)\n\nID_test = []\nX_test = []\nfor key, value in images_test.items():\n  ID_test.append(int(key))\n  X_test.append(value)\n  \n        \nX_train = np.array(X_train)\nY_train = np.array(Y_train)\nX_test = np.array(X_test)\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape)","5f1b2445":"scaler = StandardScaler()\nX_scaled_train = scaler.fit_transform(X_train)\nX_scaled_test = scaler.transform(X_test)","8abcced0":"#sn_mse = SigmoidNeuron()\n#sn_mse.fit(X_scaled_train, Y_train, epochs=100, learning_rate=0.015, loss_fn=\"mse\", display_loss=True)","9a07e12e":"sn_ce = SigmoidNeuron()\n\nfor i in range(1,4):\n    X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X_scaled_train, Y_train,test_size = 0.3,random_state=i*2, stratify = Y_train)\n\n    sn_ce.fit(X_train1, Y_train1, epochs=1, learning_rate=1,initialise = True,loss_fn=\"ce\", display_loss=False)\n   # sn_ce.fit(X_scaled_train, Y_train, epochs=200, learning_rate=0.1,initialise = False,loss_fn=\"ce\", display_loss=True)\n   # sn_ce.fit(X_scaled_train, Y_train, epochs=300, learning_rate=0.01,initialise = False,loss_fn=\"ce\", display_loss=True)\n\n    Y_pred_train = sn_ce.predict(X_train1)\n    Y_pred_test = sn_ce.predict(X_test1)\n    Y_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\n    Y_pred_binarised_test = (Y_pred_test >= 0.5).astype(\"int\").ravel()\n    accuracy_train = accuracy_score(Y_pred_binarised_train, Y_train1)\n    accuracy_test = accuracy_score(Y_pred_binarised_test, Y_test1)\n    print(\"Train Accuracy for : \",i , accuracy_train)\n    print(\"Test Accuracy : \",i ,accuracy_test)","a4745e69":"sn_ce.fit(X_scaled_train, Y_train, epochs=100, learning_rate=1,loss_fn=\"ce\", display_loss=True)\nsn_ce.fit(X_scaled_train, Y_train, epochs=200, learning_rate=0.1,initialise = False,loss_fn=\"ce\", display_loss=True)\nsn_ce.fit(X_scaled_train, Y_train, epochs=300, learning_rate=0.01,initialise = False,loss_fn=\"ce\", display_loss=True)\nsn_ce.fit(X_scaled_train, Y_train, epochs=400, learning_rate=0.001,initialise = False,loss_fn=\"ce\", display_loss=True)","21a9af23":"def print_accuracy(sn):\n  Y_pred_train = sn.predict(X_scaled_train)\n  Y_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\n  accuracy_train = accuracy_score(Y_pred_binarised_train, Y_train)\n  print(\"Train Accuracy : \", accuracy_train)\n  print(\"-\"*50)","764bb9dd":"#print_accuracy(sn_mse)\nprint_accuracy(sn_ce)","a2274ed1":"Y_pred_test = sn_ce.predict(X_scaled_test)\nY_pred_binarised_test = (Y_pred_test >= 0.5).astype(\"int\").ravel()\n\nsubmission = {}\nsubmission['ImageId'] = ID_test\nsubmission['Class'] = Y_pred_binarised_test\n\nsubmission = pd.DataFrame(submission)\nsubmission = submission[['ImageId', 'Class']]\nsubmission = submission.sort_values(['ImageId'])\nsubmission.to_csv(\"submisision.csv\", index=False)","34d5511a":"> *Splitting given training data into few random sets to verify the model (no\/less overfitting) and it's accuracy on random data.*","0a24e593":"## Sample Submission"}}