{"cell_type":{"1efdbec7":"code","43af89ec":"code","d82d0c10":"code","23d9413e":"code","63feb420":"code","a77f343a":"code","7a9fb1e5":"code","a8b761fd":"code","992db3cc":"code","02c2ffb8":"code","851f074c":"code","dc8e9b06":"code","e3271141":"code","48c0e57a":"code","895bfdf2":"code","a4e7c60b":"markdown","39e479cf":"markdown","604a6589":"markdown","0a48111e":"markdown","8acb4a0b":"markdown","06f20c08":"markdown","4bcf945d":"markdown","9c49a3e1":"markdown","2a45b9d8":"markdown","05d698cf":"markdown","de3cfced":"markdown"},"source":{"1efdbec7":"# Upgrade tensorflow and efficientnet and W&B\n!pip install --upgrade tensorflow\n!pip install --upgrade efficientnet\n!pip install --upgrade wandb","43af89ec":"# Obfuscated WANDB API Key\nfrom kaggle_secrets import UserSecretsClient\nWANDB_KEY = UserSecretsClient().get_secret(\"WANDB_API_KEY\")","d82d0c10":"import os\nimport sys\nimport glob\nimport time\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input, Flatten, ReLU\nfrom tensorflow.keras.applications import MobileNet, MobileNetV2, NASNetMobile\nfrom efficientnet.tfkeras import EfficientNetB0\n\n# Path variables\nBASE_PATH = \"\/kaggle\/input\/plant-pathology-2020-fgvc7\/\"\nTRAIN_PATH = BASE_PATH + \"train.csv\"\nTEST_PATH = BASE_PATH + \"test.csv\"\nSUB_PATH = BASE_PATH + \"sample_submission.csv\"\nIMG_PATH = BASE_PATH + \"images\/\"\n\n# Set seed for reproducability\nseed = 1234\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\n\n# Surpress scientific notation\nnp.set_printoptions(suppress=True)\n\n# Global Variables\nIMG_SIZE = 224\nBATCH_SIZE = 64\nEPOCHS = 100\nLABELS = ['healthy', 'multiple_diseases', 'rust', 'scab']\nN_CLASSES = len(LABELS)","23d9413e":"# Import custom GhostNet architecture made by sunnyyeah\nsys.path.append(\"..\/input\/ghostnet\/GhostNet-Keras-master\/\")\nfrom ghostNet import GhostNet","63feb420":"# Initialize Weights and Biases\nimport wandb\nfrom wandb.keras import WandbCallback\nwandb.login(key=WANDB_KEY);","a77f343a":"# Load annotations and labels\nimg_dir = glob.glob(f\"{IMG_PATH}*.jpg\")\ntrain = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\nsub = pd.read_csv(SUB_PATH)\n\ntrain['filename'] = IMG_PATH + train['image_id'] + \".jpg\"\ntest['filename'] = IMG_PATH + test['image_id'] + \".jpg\"","7a9fb1e5":"# Split into train and validation\nX_train, X_val, y_train, y_val = train_test_split(train['filename'], train[LABELS].values.astype(np.float32), test_size=0.15, random_state=seed) \nX_test = test['filename']","a8b761fd":"def decode_image(filename, label=None):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.\n    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n    \ndef decode_image_2(filename, label=None):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32)\n    image = tf.keras.applications.mobilenet.preprocess_input(image)\n    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n    \n    if label is None:\n        return image\n    else:\n        return image, label","992db3cc":"def data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n\n    if label is None:\n        return image\n    else:\n        return image, label","02c2ffb8":"def build_model(backbone: tf.keras.Model, n_classes: int = 4) -> tf.keras.Model:\n    \"\"\" \n    Initialize model with custom backbone \n    \n    :param backbone: A tf.keras.Model object used as a backbone for the network\n    :return: A tf.keras.Model object\n    \n    \"\"\"\n    model = tf.keras.Sequential()\n    model.add(backbone)\n    model.add(Flatten())\n    model.add(Dense(256, activation=None))\n    model.add(ReLU(max_value=6)) # ReLU6\n    model.add(Dense(n_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', \n                  optimizer='adam',\n                  metrics=['acc'])\n    return model","851f074c":"def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    \"\"\" \n    Learning rate scheduler with warm-up and exponential decay \n    \"\"\"\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) \/ lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn","dc8e9b06":"AUTO = tf.data.experimental.AUTOTUNE\n\nmodel_dict = {\"GhostNet\": GhostNet,\n              \"NasNetMobile\": NASNetMobile,\n              \"Mobilenet\": MobileNet, \n              \"MobileNetV2\": MobileNetV2,\n              \"EfficientNetB0\": EfficientNetB0}","e3271141":"metrics = []\nfor name, net in model_dict.items():\n    wandb.init(project=\"mobile_architectures\", name=name, \n                   notes=\"Mobile architectures review\", reinit=True)\n    # Slight changes for GhostNet and EfficientNet\n    if name == \"GhostNet\":\n        backbone = GhostNet((IMG_SIZE, IMG_SIZE, 3), 4, include_top=False).build(plot=False)\n        lrfn = build_lrfn(lr_start=0.005, lr_max=0.01, lr_min=0.001)\n    else: \n        if \"EfficientNet\" in name:\n            weights = 'noisy-student'\n        else:\n            weights = 'imagenet'\n            \n        # Get backbone and learning rate scheduler\n        backbone = net(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=weights, pooling='avg')\n        lrfn = build_lrfn()\n    model = build_model(backbone)\n    \n    # Tensorflow wrapper for the learning rate schedule function\n    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n    \n    # Set image decoder\n    if \"MobileNet\" in name or name == \"GhostNet\":\n        image_decoder = decode_image_2\n    else:\n        image_decoder = decode_image\n        \n    # Initialize datasets\n    train_dataset = (tf.data.Dataset\n                     .from_tensor_slices((X_train, y_train))\n                     .map(image_decoder, num_parallel_calls=AUTO)\n                     .map(data_augment, num_parallel_calls=AUTO)\n                     .shuffle(512)\n                     .repeat()\n                     .batch(BATCH_SIZE)\n                     .prefetch(AUTO))\n\n    valid_dataset = (tf.data.Dataset\n                     .from_tensor_slices((X_val, y_val))\n                     .map(image_decoder, num_parallel_calls=AUTO)\n                     .batch(BATCH_SIZE)\n                     .cache()\n                     .prefetch(AUTO))\n        \n    # Train model\n    hist = model.fit(train_dataset, validation_data=valid_dataset,\n                     steps_per_epoch=y_train.shape[0] \/\/ BATCH_SIZE,\n                     callbacks=[lr_schedule, WandbCallback(save_model=False)], \n                     epochs=EPOCHS, verbose=1)\n\n    # Inference speed benchmarking on validation data\n    start_time = time.time()\n    y_pred = model.predict(valid_dataset)\n    end_time = time.time()\n    inf_speed = (end_time - start_time) \/ len(X_val)\n\n    # Evaluate validation accuracy and log metrics\n    val_acc = accuracy_score(y_val.argmax(axis=1), y_pred.argmax(axis=1))\n    results = {\"Validation Accuracy\": val_acc, \"Inference Speed\": inf_speed, \"Parameters\": model.count_params()}\n    metrics.append((name, results['Validation Accuracy'], results['Inference Speed'], results['Parameters']))\n    wandb.log(results)\n    wandb.join()","48c0e57a":"eval_df = pd.DataFrame(metrics, columns=['Name', 'Validation Accuracy', 'Inference Speed', 'Parameters'])\neval_df","895bfdf2":"test_dataset = (tf.data.Dataset\n                .from_tensor_slices(X_test)\n                .map(decode_image, num_parallel_calls=AUTO)\n                .batch(BATCH_SIZE))\n\n# Make final predictions using the EfficientNetB0 architecture\nsub.loc[:, LABELS] = model.predict(test_dataset, verbose=1)\nsub.to_csv('submission.csv', index=False)\nsub.head()","a4e7c60b":"This Kaggle notebook accompanies a [Weights & Biases Report](https:\/\/wandb.ai\/carlolepelaars\/mobile_architectures\/reports\/The-Evolution-Of-Mobile-CNN-Architectures--VmlldzoyMDQ0ODQ) titled \"The evolution of mobile CNN architectures.\n\nBig thanks to Tarun Paparaju for his [EDA kernel](https:\/\/www.kaggle.com\/tarunpaparaju\/plant-pathology-2020-eda-models), which got me started with the [Plant Pathology 2020 dataset](https:\/\/www.kaggle.com\/c\/plant-pathology-2020-fgvc7\/data) used in this notebook.\n","39e479cf":"The MobileNet and GhostNet architectures will be normalized with MobileNet preprocessing implemented by tf.keras. For the other models the normalization will be a simple division by 255. ","604a6589":"## Submission","0a48111e":"## Preparation","8acb4a0b":"That's all! I hope this Kaggle notebook gave you some insight into the behaviour of different mobile CNN architectures and how their performance differs.\n\nIf you like this Kaggle notebook, feel free to give an upvote and leave a comment! I will try to implement your suggestions in this kernel!","06f20c08":"In this experiment we will run a subset of the models discussed in the [blog post](https:\/\/app.wandb.ai\/carlolepelaars\/mobile_architectures\/reports\/Mobile-CNN-architectures--VmlldzoyMDQ0ODQ): GhostNet, NASNetMobile, MobileNet, MobileNetV2 and EfficientNetB0.","4bcf945d":"## Model training loop","9c49a3e1":"Weights and Biases requires you to add your WandB API key for logging in automatically. Because this is a secret key, we will use [Kaggle User Secrets](https:\/\/www.kaggle.com\/product-feedback\/114053) to obfuscate the API key.","2a45b9d8":"## Experimentation setup","05d698cf":"Credits for the GhostNet setup go to [sunnyyeah](https:\/\/github.com\/sunnyyeah). You can find his implementation of GhostNet [here](https:\/\/github.com\/sunnyyeah\/GhostNet-Keras).","de3cfced":"![](https:\/\/lever-client-logos.s3.amazonaws.com\/bb006941-a5fe-4d4c-b13d-931f9b9c303f-1569362661885.png)"}}