{"cell_type":{"e0e7ef22":"code","b2a184f7":"code","53e86d28":"code","ae1cbb86":"code","bc16841e":"code","cf38ecbe":"code","f271e30b":"code","3cbd7e2d":"code","85a3bf56":"code","c30e695e":"code","b48d866c":"code","3063c95e":"markdown","391eba99":"markdown","c1a87199":"markdown","767d1ae7":"markdown","4fc4b509":"markdown","acbb8273":"markdown","97f06d3e":"markdown","587d19ef":"markdown","0ec96f3e":"markdown","0f600395":"markdown","0cee7aa8":"markdown"},"source":{"e0e7ef22":"import numpy as np\nimport pandas as pd\ntrain_data = pd.read_csv('\/kaggle\/input\/covid19-local-us-ca-forecasting-week-1\/ca_train.csv')\n# we don't need the test data\n# test_data = pd.read_csv('\/kaggle\/input\/covid19-local-us-ca-forecasting-week-1\/ca_test.csv')","b2a184f7":"print(train_data)","53e86d28":"useless_cols = []\nfor col in train_data.columns:\n    entries_num = len(set(train_data[col]))\n    if entries_num < 2:\n        useless_cols.append(col)\n    print(f'{col} -- has {entries_num} unic entries')","ae1cbb86":"train_data.drop(useless_cols, axis=1, inplace=True)\ntrain_data.drop(['Id', 'Date'], axis=1, inplace=True)","bc16841e":"X_train = train_data[48:]\nprint(X_train)","cf38ecbe":"# Approximation of the confirmed cases first and second derivatives\ndiff_conf, conf_old = [], 0 \ndd_conf, dc_old = [], 0\n\n# Approximation of the fatalities first and second derivatives\ndiff_fat, fat_old = [], 0\ndd_fat, df_old = [], 0\n\n# Approximation of exponential grow coefficient\nexp_conf, exp_fat = [], []\n\n# Approximation of the ration between fatalities and confirmed cases\nratio = []\n\n# Calc the features' arrays\nfor row in X_train.values:\n    diff_conf.append(row[0]-conf_old)\n    conf_old=row[0]\n    \n    diff_fat.append(row[1]-fat_old)\n    fat_old=row[1]\n    \n    exp_conf.append(diff_conf[-1]\/row[0])\n    exp_fat.append(diff_fat[-1]\/row[1])\n    \n    ratio.append(row[1]\/row[0])\n    \n    dd_conf.append(diff_conf[-1]-dc_old)\n    dc_old=diff_conf[-1]\n    \n    dd_fat.append(diff_fat[-1]-df_old)\n    df_old=diff_fat[-1]\n\n# Insert features into training set\nX_train['diff_confirmed'] = diff_conf\nX_train['diff_fatalities'] = diff_fat\nX_train['exp_confirmed'] = exp_conf\nX_train['exp_fatalities'] = exp_fat\nX_train['fatalities_to_confirmed'] = ratio\nX_train['dd_confirmed'] = dd_conf\nX_train['dd_fatalities'] = dd_conf\nprint(X_train)","f271e30b":"exp_c = X_train.exp_confirmed.drop(48).mean()\nprint(f'exp_c: {exp_c}')\nexp_f = X_train.exp_fatalities.drop(48).mean()\nprint(f'exp_f: {exp_f}')\nratio = X_train.fatalities_to_confirmed.drop(48).mean()\nprint(f'ratio: {ratio}')\nd_c = X_train.diff_confirmed.drop(48).mean()\nprint(f'd_c: {d_c}')\ndd_c = X_train.dd_confirmed.drop(48).drop(49).mean()\nprint(f'dd_c: {dd_c}')\nd_f = X_train.diff_fatalities.drop(48).mean()\nprint(f'd_f: {d_f}')\ndd_f = X_train.dd_fatalities.drop(48).drop(49).mean()\nprint(f'dd_f: {dd_f}')","3cbd7e2d":"pred_c, pred_f = list(X_train.ConfirmedCases.loc[50:56]), list(X_train.Fatalities.loc[50:56])","85a3bf56":"for i in range(1, 44 - 7):\n    # use taylor series to predict confirmed cases\n    pred_c.append((X_train.ConfirmedCases[56] + d_c*i + 0.5*dd_c*(i**2)))\n    # use taylor series to predict fatalities\n    # pred_f.append((X_train.Fatalities[56] + d_f*i + 0.5*dd_f*(i**2)))\n    \n    # We can also try to use ratio of fatalities to cases instead\n    pred_f.append(pred_c[-1] * ratio)","c30e695e":"# for i in range(1, 44 - 7):\n#     pred_c.append(X_train.ConfirmedCases[56] * ((1 + exp_c) ** i ))\n#     pred_f.append(pred_c[-1] * ratio)","b48d866c":"my_submission = pd.DataFrame({'ForecastId': list(range(1,44)), 'ConfirmedCases': pred_c, 'Fatalities': pred_f})\nmy_submission.to_csv('submission.csv', index=False)\nprint(my_submission)","3063c95e":"# The first week of the prediction overlap with the training data\nCopying the first week from the training set","391eba99":"# Creating features\nLet's create some features which we will use for our models","c1a87199":"# Model #2\nInstead of using taylor series we can use simple exponential model (see https:\/\/www.youtube.com\/watch?v=Kas0tIxDvrg)","767d1ae7":"# Throw away useless columns and cases\nFirst of all lets check how many entries each column has","4fc4b509":"The geographical data -- like Latitude, Longitude, etc -- has only one entry 'cause all data is from California. We can freely drop this data.\n\nWe also don't need Id and Date for prediction.","acbb8273":"# Submit results","97f06d3e":"# Drop useless rows\nThe first 48 days there were no cases, we should drop this rows too","587d19ef":"# Calculate means\nWe are throwing away some values of the derivatives lists -- one value for the first derivative and two for the second.","0ec96f3e":"# Model #1\nWe know that almost any signal can be represented as an series of it's derivatives: taylor series.\n\nf(x) = df(a) * (x - a) + ddf(a) * (x - a)^2 \/ 2 + dddf(a) * (x - a)^3 \/ 6 + ...\n\n\nWe will use the first two members of the taylor series to predict the future. \n\nIn theory the more members we choose the more accurate our model will be, unfortunatly there is not enough data to calculate the third derivative accuratly.","0f600395":"# Load the training data form the csv","0cee7aa8":"# Check the training data"}}