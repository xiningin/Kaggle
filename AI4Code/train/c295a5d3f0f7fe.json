{"cell_type":{"8b89c806":"code","98bf2763":"code","121cbd3f":"code","45b002c4":"code","17dffc44":"code","51f876ba":"code","aa3dea4e":"code","1aef4f5a":"code","34513124":"code","2afae626":"code","9bbdce18":"code","f21c1c3c":"code","e4f90efc":"code","9c091605":"code","cecaa242":"code","2a893f54":"code","dbd3e717":"code","c70d5a20":"markdown","bf77ef59":"markdown","ab60732c":"markdown","fca3f111":"markdown","e157b6a7":"markdown","1d04109f":"markdown","1f06751f":"markdown","0471cf72":"markdown","46268c55":"markdown","32b398f3":"markdown","8f070786":"markdown","7a5690e9":"markdown","64a199dc":"markdown","314afa2c":"markdown","296df503":"markdown","a5a14dee":"markdown","953f6309":"markdown"},"source":{"8b89c806":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","98bf2763":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix","121cbd3f":"#Read the data\ndf=pd.read_csv('\/kaggle\/input\/textdb3\/fake_or_real_news.csv')\n\n#Get shape and head\nprint(df.shape)\n","45b002c4":"print(df.head())","17dffc44":"print(df.columns)","51f876ba":"df= df.drop('Unnamed: 0',axis=1)\nprint(df.head())","aa3dea4e":"print(df.info())","1aef4f5a":"# Get the labels\nlabels=df.label\nprint(labels.head())","34513124":"sns.displot(labels)","2afae626":"# Split the dataset\nx_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7)","9bbdce18":"# Initialize a TfidfVectorizer\ntfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)","f21c1c3c":"# Fit and transform train set, transform test set\ntfidf_train=tfidf_vectorizer.fit_transform(x_train) \ntfidf_test=tfidf_vectorizer.transform(x_test)","e4f90efc":"# Initialize a PassiveAggressiveClassifier\npac=PassiveAggressiveClassifier(max_iter=50)\npac.fit(tfidf_train,y_train)","9c091605":"# Predict on the test set and calculate accuracy\ny_pred=pac.predict(tfidf_test)\nscore=accuracy_score(y_test,y_pred)\nprint(f'Accuracy: {round(score*100,2)}%')","cecaa242":"# Build confusion matrix\nconf_mat=confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])\nconf_mat","2a893f54":"sns.heatmap(conf_mat,annot=True)\n","dbd3e717":"sns.heatmap(conf_mat\/np.sum(conf_mat), annot=True,fmt='.2%', cmap='Blues')\n","c70d5a20":"**Now, fit and transform the vectorizer on the train set, and transform the vectorizer on the test set.**","bf77ef59":"**Get the labels from the DataFrame.**","ab60732c":"**let\u2019s read the data into a DataFrame, and get the shape of the data and the first 5 records.**","fca3f111":"**Printing info about each column**","e157b6a7":"**Dropping 'Unnamed: 0' column**","1d04109f":"**Split the dataset into training and testing sets.**","1f06751f":"**Next, we\u2019ll initialize a PassiveAggressiveClassifier. This is. We\u2019ll fit this on tfidf_train and y_train.**","0471cf72":"![image.png](attachment:3da6f386-863a-4f6b-b3c6-c62bf893c419.png)","46268c55":"**Summary :**\n\n**We took a political dataset, implemented a TfidfVectorizer, initialized a PassiveAggressiveClassifier, and fit our model. We ended up obtaining an accuracy of 92.74% in magnitude.**","32b398f3":"**Plotting counts of labels**","8f070786":"**So with this model, we have 589 true positives, 586 true negatives, 49 false positives, and 43 false negatives, ie we have 589 fake news and 586 real news.**","7a5690e9":"**Let\u2019s initialize a TfidfVectorizer with stop words from the English language and a maximum document frequency of 0.7 (terms with a higher document frequency will be discarded). Stop words are the most common words in a language that are to be filtered out before processing the natural language data. And a TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features.**","64a199dc":"**Now,we\u2019ll predict on the test set from the TfidfVectorizer and calculate the accuracy with accuracy_score() from sklearn.metrics.**","314afa2c":"**Plotting confusion matrix with the help of heat map**","296df503":"**We got an accuracy of 92.74% with this model. Finally, let\u2019s print out a confusion matrix to gain insight into the number of false and true negatives and positives.**","a5a14dee":"**A type of yellow journalism, fake news encapsulates pieces of news that may be hoaxes and is generally spread through social media and other online media. This is often done to further or impose certain ideas and is often achieved with political agendas. Such news items may contain false or exaggerated claims, and may end up being viralized by algorithms, and users may end up in a filter bubble.**\n\nref: https:\/\/data-flair.training\/blogs\/advanced-python-project-detecting-fake-news\/","953f6309":"**This dataset has a shape of 6335\u00d74. The first column identifies the news, the second and third are the title and text, and the fourth column has labels denoting whether the news is REAL or FAKE.**"}}