{"cell_type":{"6214d4ba":"code","c2652a86":"code","ae0d85e0":"code","bbfbb1ff":"code","b28d19b9":"code","0d5b3b0a":"code","d25cd9e6":"code","7359cbcf":"code","a39e2271":"code","7266d425":"code","b52cada2":"code","977190d8":"code","eb8481fe":"code","40b79c07":"code","cab24725":"code","af93d179":"code","1c573faa":"code","44881841":"code","d7b37a0a":"code","acba6321":"code","ce94f307":"markdown","bdec50c5":"markdown","9cb327bd":"markdown","5473b6a2":"markdown","4e0db2e9":"markdown","58392344":"markdown","6787edfe":"markdown","7161e293":"markdown","9a4c1704":"markdown","92a7767d":"markdown","53d47cda":"markdown","a3e9b21e":"markdown","f6b4ecfd":"markdown","5c8108c2":"markdown","b9de180e":"markdown","947f2f58":"markdown","7044c30d":"markdown","73f1bd2d":"markdown","51b23530":"markdown","be23200f":"markdown","3e971f8c":"markdown","757f25d4":"markdown","9a17df5e":"markdown","a762b0cd":"markdown"},"source":{"6214d4ba":"import tensorflow as tf                                                         # The main framework we will build our model with.\nimport numpy as np                                                              # Used for mathimatical operations.\nimport pandas as pd                                                             # Will be used to load our data frame.\nimport cv2                                                                      # Used for image processing.\nfrom matplotlib import pyplot as plt                                            # Used for plottin our data.\nfrom tensorflow.keras.utils import to_categorical                               # Utility in Tensorflow to convert our true category values.","c2652a86":"path = '..\/input\/ahcd1'                                                         # Here we specify the path to our data location on my drive\ntrain_data_x = pd.read_csv(path + '\/csvTrainImages 13440x1024.csv', header=None)# Then we load the training images.\ntrain_data_y = pd.read_csv(path + '\/csvTrainLabel 13440x1.csv', header=None)    # Training labels.\ntest_data_x = pd.read_csv(path + '\/csvTestImages 3360x1024.csv', header=None)   # Testing images.\ntest_data_y = pd.read_csv(path + '\/csvTestLabel 3360x1.csv', header=None)       # Testing labels.","ae0d85e0":"print('We have  %d training images each contains %d pixels.' %(train_data_x.shape[0], train_data_x.shape[1]))\nprint('We have  %d training labels each contains %d classes.' %(train_data_y.shape[0], len(train_data_y.value_counts())))\nprint('We have  %d testing images each contains %d pixels.' %(test_data_x.shape[0], test_data_x.shape[1]))\nprint('We have  %d testing labels each contains %d classes.' %(test_data_y.shape[0], len(test_data_y.value_counts())))","bbfbb1ff":"train_data_y.value_counts()","b28d19b9":"fig = plt.figure(figsize=(8, 8))                                                # Setting the figure size.\ncolumns = 4                                                                     # Selecting the number of columns.\nrows = 5                                                                        # Selectin the number of rows.\nfor i in range(1, columns*rows +1):                                             # Looping through rows & columns.\n  img = test_data_x.iloc[i].to_numpy().reshape((32,32))                         # Reshaping the image into its size 32x32\n  fig.add_subplot(rows, columns, i)                                             # Adding the image to the plot\n  plt.imshow(img, cmap='gray')                                                  # Showing the image using plt\nplt.show()                                                                      # Finally shpwing the whole plot containing all the subplots","0d5b3b0a":"def preprocess_data(train_data_x):\n  train_data_x = train_data_x.to_numpy().reshape((train_data_x.shape[0], 32, 32)).astype('uint8')\n  for i in range(len(train_data_x)):\n    train_data_x[i] = cv2.rotate(train_data_x[i], cv2.ROTATE_90_CLOCKWISE)      # Rotating the images.\n    train_data_x[i] = np.flip(train_data_x[i], 1)                               # Flipping the images\n  train_data_x = train_data_x.reshape([-1, 32, 32, 1]).astype('uint8')          # Reshaping into the required size.\n  train_data_x = train_data_x.astype('float32')\/255                             # Here we normalize our images.\n  return np.asarray(train_data_x)","d25cd9e6":"train_x = preprocess_data(train_data_x)                                         # Returns an array of dimensions (13440,32,32,1).\ntest_x = preprocess_data(test_data_x)                                           # Returns an array of dimensions (3360,32,32,1).","7359cbcf":"train_y = to_categorical(train_data_y.values.astype('int32') - 1                # Returns an array of dimentions (13340, 28).\n                         , num_classes=28)\ntest_y = to_categorical(test_data_y.values.astype('int32') - 1                  # Returns an array of dimentions (3360, 28).\n                        , num_classes=28)","a39e2271":"%%capture\nfrom sklearn.utils import shuffle                                               # Importing shuffle function from sklearn library.\ntrain_x, train_y = shuffle(train_x, train_y)                                    # Now we shuffle x & y in the training set.\ntest_x, test_y, shuffle(test_x, test_y)                                         # Then x & y in our testing set.","7266d425":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense, Flatten\n\ndef create_model(activation='relu', optimizer='adam', kernel_initializer='he_normal'):\n    \n    model = Sequential()\n    \n    model.add(Conv2D(32, (3,3), padding='same', input_shape=(32, 32, 1), activation= activation, kernel_initializer=kernel_initializer))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(64, (3,3), padding='same', activation= activation, kernel_initializer=kernel_initializer))\n    model.add(MaxPooling2D(2,2))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n\n    model.add(Conv2D(128, (3,3), padding='same', activation= activation, kernel_initializer=kernel_initializer))\n    model.add(MaxPooling2D(2,2))\n    model.add(Dropout(0.2))\n    model.add(BatchNormalization())\n\n    model.add(Flatten())\n\n    model.add(Dense(32, activation= activation, kernel_initializer=kernel_initializer, kernel_regularizer='l2'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(28, activation='softmax'))\n\n    model.compile(optimizer=optimizer,\n                    loss='categorical_crossentropy',\n                    metrics=['accuracy'])\n    return model","b52cada2":"model = create_model()                                                          # Now we created an instance of a model with our custom architefture.\nmodel.summary()                                                                 # Then we display our model's summary.","977190d8":"seed = 7                                                                        # Select a fixed seed\nnp.random.seed(seed)                                                            # Specifing the seed for our random generator\n\noptimizer = ['RMSprop', 'Adam', 'Adagrad', 'Nadam']                             # Available optimizers\nkernel_initializer = ['normal', 'uniform']                                      # Available initializing methods\nactivation = ['relu', 'linear', 'tanh']                                         # Available activation functions\n\nparam_grid = dict(optimizer=optimizer,                                          # Creating the grid\n                  kernel_initializer=kernel_initializer,\n                  activation=activation)\n\nparameters_number = 1\nfor x in param_grid:\n  parameters_number = parameters_number * len(param_grid[x]) \nprint(\"Number of different parameter combinations = {}\".format(parameters_number))","eb8481fe":"epochs = 5                                                                      # Specifing the number of epochs for each combination\nbatch_size = 64                                                                 # Setting the batch size\n\n# Here we will create our different models and run them for 5 epochs each.\nfor a,b,c in [(x,y,z) for x in optimizer for z in activation for y in kernel_initializer]:\n    params = {'optimizer' : a , 'kernel_initializer' : b , 'activation' : c}\n    print(params)\n    curr_model = create_model(optimizer=a, kernel_initializer=b, activation=c)\n    curr_model.fit(train_x, train_y, \n                    validation_split=0.3,\n                    epochs=epochs, batch_size=batch_size, verbose=1)\n    print(\"=============================================================================\")","40b79c07":"model = create_model(optimizer='adam',                                       # We create our model with the specified hyper parameters\n                     kernel_initializer='uniform',\n                     activation='relu')","cab24725":"from tensorflow.keras.callbacks import ModelCheckpoint                                     # We will import a call back to save the best epoch's weights\n\ncheckpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\nhistory = model.fit(train_x,                                                    \n                    train_y, \n                    validation_split= 0.3,                                      # The model will split the data into 30% of validation.\n                    epochs=30,                                                  # We will run the model for 30 epochs\n                    batch_size=64,                                              # We will have a batch size of 64\n                    callbacks=[checkpointer])                                   # Finally we will use the imported callback","af93d179":"model.load_weights('weights.hdf5')                                              # Loading the best weights        \nmodel.evaluate(test_x, test_y)                                                  # Evaluating our model","1c573faa":"# PLOT LOSS AND ACCURACY\n%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Training and validation accuracy')\nplt.legend(['train', 'val'], loc='upper left')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Training and validation loss')\nplt.legend(['train', 'val'], loc='upper left')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\n\n\nplt.title('Training and validation loss')\n","44881841":"model.save('my_model.h5')","d7b37a0a":"model = tf.keras.models.load_model('my_model.h5')                      # Now we load the model","acba6321":"def convert_categorical_label_to_real_label(categorical_label):\n  real_labels = []\n  real_labels.extend(['\u0623', '\u0628', '\u062a', '\u062b', '\u062c', '\u062d', '\u062e', '\u062f', '\u0630', '\u0631', '\u0632', '\u0633', '\u0634', '\u0635', '\u0636', '\u0637', '\u0638', '\u0639', '\u063a', '\u0641', '\u0642', '\u0643', '\u0644', '\u0645', '\u0646', '\u0647', '\u0648', '\u0649'])\n  return real_labels[categorical_label]","ce94f307":"## Data Exploring & Preprocessing","bdec50c5":"## Overview\nThis notebook builds an OCR for handwritten Arabic letters, research in OCR or optical character recognition started a long time ago in order to allow the computer to understand the words in any visual image, but the peak in OCR performances did happen in the deep learning era as it introduced advanced methods and techniques in order to achieve the OCR's outstanding outcomes and uses. \nThe dataset used will be from Benha University, and the CNN will be build using Keras from TensorFlow.","9cb327bd":"## Testing Model","5473b6a2":"11- Now lets load the best epoch's weights and then evaluate our model using the test set.","4e0db2e9":"5- Now we define a function for us to preprocess the data,\n\nWe will start with reshaping the image to be with the size of 32x32, so that the training array will be of size of #imagesx32x32, then we will pass through each image to flip and rotate them as they are rotated, then we will reshape the entire array with the #imagex32x32x1, and the 1 stands for our grey scale images, lastly we will normalize our images by dividing by 255 for pixels normalization.","58392344":"12- Lets save our model for later use","6787edfe":"In the following function we mapped the categorical output with the Arabic letters to help us better identifing the classes.","7161e293":"Let's see what our images looks like.","9a4c1704":"Now lets load our model and test it on our custom images.","92a7767d":"3- We will use Pandas library to read our data and load it into our data frame, our data is stored in CSV format so we will use the appropriate function to load it.","53d47cda":"## Dataset\nThe data-set is composed of 16,800 characters written by 60 participants, the age range is between 19 to 40 years, and 90% of participants are right-hand. Each participant wrote each character (from \u2019alef\u2019 to \u2019yeh\u2019) ten times on two forms as shown in Fig. 7(a) & 7(b). The forms were scanned at the resolution of 300 dpi. Each block is segmented automatically using Matlab 2016a to determining the coordinates for each block. The database is partitioned into two sets: a training set (13,440 characters to 480 images per class) and a test set (3,360 characters to 120 images per class). Writers of training set and test set are exclusive. Ordering of including writers to test set are randomized to make sure that writers of test set are not from a single institution (to ensure variability of the test set).\n\nhttps:\/\/www.kaggle.com\/mloey1\/ahcd1","a3e9b21e":"4- Now let's examine our data properties.\n\nWe will find that we have 13440 training image with their labels in the training set and 3360 in the testing set, along with a total of 28 classes which idecates the number of Arabic letters.\n\nThe number of pixels in each image is 1024, so we can conclude the pixels per image by getting the square root of the number of pixels which will give us 32, so the dimensions of our image is 32x32x1 as it is a grey scale image, we will use this piece of information for preprocessing our images.","f6b4ecfd":"9- Let's start selecting the best hyperparamters for our model, we will do this by performing grid parameter tuning, which indicates performing all the possible combinations for our hyperparameters, then selecting the combination by selecting the best model.","5c8108c2":"## Acknowledgments","b9de180e":"We notice also that there are 480 image per class, and there is also a very important note that we should put into consideration, the classes start from 1 to 28, but for our classifer we would like our classes to be from 0 to 27, we will use this piece of information in preprocessing the labels. ","947f2f58":"## Building Model","7044c30d":"8- We will now create our model's architecture, \n\nWe will use keras for the creation of our model, we will start by creating a function for use to create our model, we will set the activation, optimizer and our initializing method as variables for us to easly modifiy it in the hyper-parameter tuning phase.\n\nWe will start by creating our first convolutional layer and setting up the input shape, we will create additional pooling layer along with a batch normalization layer, then we will add three convolutional layers with the same structure but the the double size of filters each layer.\n\nThen we will flatten our layer preparing it for the fully connected layers, we will use a small neurons numbered layer with a drop out layer, batch normalization and we will add an L2 regularizer so we will control the overfitting.","73f1bd2d":"\u2022 Author **Hossam Zaabl**\n\nhttps:\/\/github.com\/zaabl\n\n\u2022 A. El-Sawy, M. Loey, and H. EL-Bakry, \u201cArabic handwritten characters recognition using convolutional neural network,\u201d WSEAS Transactions on Computer Research, vol. 5, pp. 11\u201319, 2017.\n\nhttps:\/\/doi.org\/10.1007\/978-3-319-48308-5_54\n\nhttps:\/\/link.springer.com\/chapter\/10.1007\/978-3-319-48308-5_54\n\n\u2022 A. El-Sawy, H. EL-Bakry, and M. Loey, \u201cCNN for handwritten arabic digits recognition based on lenet-5,\u201d in Proceedings of the International Conference on Advanced Intelligent Systems and Informatics 2016, vol. 533, pp. 566\u2013575, Springer International Publishing, 2016.\n\nhttps:\/\/www.wseas.org\/multimedia\/journals\/computerresearch\/2017\/a045818-075.php\n\n\u2022 Loey, Mohamed, Ahmed El-Sawy, and Hazem El-Bakry. \"Deep learning autoencoder approach for handwritten arabic digits recognition.\" arXiv preprint arXiv:1706.06720 (2017).\nhttps:\/\/arxiv.org\/abs\/1706.06720\n\n\u2022 Amr Hendy, Arabic Handwritten Image Recognition\n\nhttps:\/\/github.com\/AmrHendy\/Arabic-Handwritten-Images-Recognition","51b23530":"# Arabic Character Recognition","be23200f":"1- Let's import our libraries that we will use in this project.","3e971f8c":"7- We will now shuffle our training and test sets as we will get better results than using the data's classes in sequential form.","757f25d4":"6- Now we preprocess our labels by converting them to the categorcal form.\n\nNote: we subtracted one from the values of the labels we so get our classes values in the form of 0-27 as we mentioned earlier.","9a17df5e":"12- Lets plot our training journy to check the performance and verify that the model is not overfitting.","a762b0cd":"10- After looping through all the combinations it was found that the best combination is:\n\n [Adam, Uniform Initialization, Relu Activation]\n\n Then lets use them to build our final model."}}