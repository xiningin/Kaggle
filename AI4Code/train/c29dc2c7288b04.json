{"cell_type":{"01a1e4f8":"code","dd9451ab":"code","f1060b3d":"code","8fca9215":"code","602ce91a":"code","7bc0818b":"code","95aab128":"code","4b4cac4f":"code","404fdc62":"code","fcad202c":"code","8330c086":"code","deb5eceb":"code","e85ca872":"code","fed1fac5":"code","25a5b131":"code","2e9cef9e":"code","00f641df":"code","5d05c069":"code","195192d0":"code","c1231163":"code","62de1cd7":"code","9a381d63":"code","66a300d3":"markdown","7c0b3842":"markdown","4a706067":"markdown"},"source":{"01a1e4f8":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nprint(os.listdir(\"..\/input\"))","dd9451ab":"df_train = pd.read_csv(\"..\/input\/ey-nextwave\/data_train\/data_train.csv\")\ndf_test = pd.read_csv(\"..\/input\/ey-nextwave\/data_test\/data_test.csv\")","f1060b3d":"df_train.tail()","8fca9215":"df_test.tail()","602ce91a":"# normalising location information\nX_MIN = 3750901.5068\nX_MAX = 3770901.5068\nX_MID = X_MIN + 0.5 * (X_MAX - X_MIN)\nY_MIN = -19268905.6133\nY_MAX = -19208905.6133\nY_MID = Y_MIN + 0.5 * (Y_MAX - Y_MIN)\n\ndef normalise_X(arr):\n    return (arr - X_MID) \/ 10000\n\ndef normalise_Y(arr):\n    return (arr - Y_MID) \/ 100000  \n    # extra zero by design, seems to make figure to be in proportion\n    # looking for evidence that the x-axis and y-axis fulfil some ratio\n\nx_min, x_max = normalise_X(X_MIN), normalise_X(X_MAX)\ny_min, y_max = normalise_Y(Y_MIN), normalise_Y(Y_MAX)\nprint(\"Borders:\")\nprint(\"{:.4f} < X < {:.4f}\".format(x_min, x_max))\nprint(\"{:.4f} < Y < {:.4f}\".format(y_min, y_max))\n\ndf_train['x_entry'], df_train['x_exit'] = normalise_X(df_train['x_entry']), normalise_X(df_train['x_exit'])\ndf_train['y_entry'], df_train['y_exit'] = normalise_Y(df_train['y_entry']), normalise_Y(df_train['y_exit'])\ndf_test['x_entry'], df_test['x_exit'] = normalise_X(df_test['x_entry']), normalise_X(df_test['x_exit'])\ndf_test['y_entry'], df_test['y_exit'] = normalise_Y(df_test['y_entry']), normalise_Y(df_test['y_exit'])","7bc0818b":"# normalising time information\ndef convert_time(time_sting):\n    hms = time_sting.split(\":\")\n    seconds = int(hms[0])*60*60 + int(hms[1])*60 + int(hms[2])\n    seconds = (seconds-15*60*60)\/(10*60*60)\n    return seconds\n\ndf_train[\"t_entry\"] = df_train[\"time_entry\"].apply(lambda x: convert_time(x))\ndf_train[\"t_exit\"] = df_train[\"time_exit\"].apply(lambda x: convert_time(x))\ndf_test[\"t_entry\"] = df_test[\"time_entry\"].apply(lambda x: convert_time(x))\ndf_test[\"t_exit\"] = df_test[\"time_exit\"].apply(lambda x: convert_time(x))","95aab128":"# obtaining metadata from IDs\ndf_train['tid_0'] = [tid.split(\"_\")[-1] for tid in df_train['trajectory_id']]\ndf_train['tid_1'] = [tid.split(\"_\")[-2] for tid in df_train['trajectory_id']]\ndf_test['tid_0'] = [tid.split(\"_\")[-1] for tid in df_test['trajectory_id']]\ndf_test['tid_1'] = [tid.split(\"_\")[-2] for tid in df_test['trajectory_id']]\ndf_train['tid_0'], df_test['tid_0'] = df_train['tid_0'].astype(int), df_test['tid_0'].astype(int)\ndf_train['tid_1'], df_test['tid_1'] = df_train['tid_1'].astype(int), df_test['tid_1'].astype(int)","4b4cac4f":"# extract relevant infromation and rearrange\ncolumns = ['hash','tid_0',\n           't_entry','t_exit',\n           'x_entry','y_entry','x_exit','y_exit',\n           'vmax','vmin','vmean',\n           'time_entry','time_exit',\n           'trajectory_id','tid_1']\ndf_train = df_train[columns]\ndf_test = df_test[columns]","404fdc62":"# tid_1 is likely the day of the month, this information may be useful\nprint(max([int(x) for x in df_test['tid_0']]), max([int(x) for x in df_test['tid_1']]))","fcad202c":"hash_most_freq = df_train['hash'].mode().tail(1).item()\ndf_train.loc[df_train['hash'] == hash_most_freq]","8330c086":"df_test_1st_traj_only = df_test[df_test['x_exit'].isnull()]\ndf_submit = df_test_1st_traj_only[['trajectory_id']].copy()\ndf_submit = df_submit.rename(columns = {'trajectory_id':'id'})\n\n# helper function to determine if point is inside\ndef is_inside(arr_x, arr_y):\n    return ((arr_x > x_min) & \n            (arr_x < x_max) & \n            (arr_y > y_min) & \n            (arr_y < y_max)).astype(float)\n\ndf_submit['target'] = is_inside(df_test_1st_traj_only['x_entry'],\n                                df_test_1st_traj_only['y_entry'])\ndf_submit.to_csv('submission.csv', index=False)\ndf_submit.tail()","deb5eceb":"p_train = df_train.pivot('hash', 'tid_0')\np_train.tail()","e85ca872":"p_test = df_test.pivot('hash', 'tid_0')\np_test.tail()","fed1fac5":"def obtain_matrix(row):\n    df_hash = row.stack().iloc[::-1].reset_index()\n    trajectory_id = df_hash.loc[0,\"trajectory_id\"]\n    df_hash = df_hash[['t_entry','t_exit',\n                       'x_entry','y_entry','x_exit','y_exit',\n                       'vmax','vmin','vmean','tid_0','tid_1']]\n    targets = df_hash.loc[0,\"x_exit\"], df_hash.loc[0,\"y_exit\"]\n\n    df_hash.loc[0,\"x_exit\"] = np.nan\n    df_hash.loc[0,\"y_exit\"] = np.nan\n    embeds = np.transpose(df_hash.values)\n    df_hash = df_hash.append(pd.DataFrame([[np.nan]*df_hash.shape[1]], \n                                            columns=list(df_hash),\n                                            index=[99]*(21-df_hash.shape[0])))\n    return {\"targets\" : targets, \n            \"df_hash\" : df_hash,\n            \"matrix\" : df_hash.values,\n            \"trajectory_id\" : trajectory_id}\n\nprint(np.shape(obtain_matrix(p_train.iloc[[323]])[\"matrix\"]))\nprint(obtain_matrix(p_train.iloc[[323]])[\"targets\"])\nobtain_matrix(p_train.iloc[[323]])[\"df_hash\"]\n# note that x_exit and y_exit is removed from matrix","25a5b131":"test_data = []\ntest_ids = []\n\nfor i in tqdm(range(p_test.shape[0])):\n    output = obtain_matrix(p_test.iloc[[i]])\n    test_data.append(output[\"matrix\"])\n    test_ids.append(output[\"trajectory_id\"])\n#     if i>100:\n#         break","2e9cef9e":"print(np.shape(test_data))\nprint(np.shape(test_ids))\nnp.save(\"test_data\", test_data)\nnp.save(\"test_ids\", test_ids)","00f641df":"train_data = []\ntrain_targets = []\n\nfor i in tqdm(range(p_train.shape[0])):\n    output = obtain_matrix(p_train.iloc[[i]])\n    train_data.append(output[\"matrix\"])\n    train_targets.append(output[\"targets\"])\n#     if i>100:\n#         break","5d05c069":"# evaluate if the targets are inside\ntrain_targets = np.array(train_targets)\ntrain_targets_inside = is_inside(train_targets[:,0], train_targets[:,1])","195192d0":"print(np.shape(train_data))\nprint(np.shape(train_targets))\nprint(np.shape(train_targets_inside))\nnp.save(\"train_data\", train_data)\nnp.save(\"train_targets\", train_targets)\nnp.save(\"train_targets_inside\", train_targets_inside)","c1231163":"# standardised 4-fold train-test split for clustering purposes\nfrom sklearn.model_selection import StratifiedKFold, KFold\nskf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\ntrn_index_list = []\nval_index_list = []\nfor trn_index, val_index in skf.split(np.arange(len(train_data)),\n                                      train_targets_inside.astype(int)):\n    trn_index_list.append(trn_index)\n    val_index_list.append(val_index)\n    \nnp.save(\"trn_index_list\",trn_index_list)\nnp.save(\"val_index_list\",val_index_list)","62de1cd7":"!ls","9a381d63":"# to document: specifications for all if not clear enough\n# might not care to do: make the pivot table to 3D array faster","66a300d3":"# TRAIN-TEST SPLIT INDICES","7c0b3842":"# BASELINE SUBMISSION","4a706067":"# DATASET PIVOTING"}}