{"cell_type":{"3a30892f":"code","b9d3bdbe":"code","dd90158e":"code","b3a1c4a9":"code","2608ce92":"code","4bbb5f26":"code","b7014a22":"code","5a5762f7":"code","8a275cbc":"code","5f21189b":"code","84548228":"code","efb1fde7":"code","4cf0652b":"code","caea161f":"code","4f69ab8b":"code","7a7c1077":"code","efd314f2":"markdown","673a3807":"markdown","417d862f":"markdown","17905771":"markdown","b9e92954":"markdown","df13dc47":"markdown","adc4991c":"markdown","bb143786":"markdown","3e9470b4":"markdown","ac0ea11d":"markdown","7bd1aa57":"markdown","ae8a32b3":"markdown","37404add":"markdown","fffe82ce":"markdown","2cde5a57":"markdown","69668fcd":"markdown","f9f6f09b":"markdown","fb5c9d45":"markdown"},"source":{"3a30892f":"#system libraries\nimport os\nimport glob\nimport gc\nimport time\nimport datetime\nimport sys\nfrom pathlib import Path\n#Data manipulation\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n#Plotting\nimport cv2 as cv2\nfrom skimage import feature\n#Scientific\nfrom scipy import stats\n#Machine learning\nimport multiprocessing\n#import joblib\nfrom sklearn.externals.joblib import parallel_backend\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn import svm, datasets\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import GridSearchCV\n#cnn\nimport keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom keras import callbacks\nfrom keras import preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\nfrom keras.engine.training import Model\nfrom keras.utils import plot_model","b9d3bdbe":"def process_image(image_BGR, label, show):\n    binary_mask = cv2.split(image_BGR)[0]\n    ret, binary_mask = cv2.threshold(binary_mask, 10, 255, cv2.THRESH_BINARY)\n    ret, binary_green = cv2.threshold(cv2.split(image_BGR)[1], 100, 255, cv2.THRESH_BINARY)\n    kernel = np.ones((3,3),np.uint8)\n    binary_mask = cv2.erode(binary_mask, kernel, iterations = 1)\n    green_diff = cv2.subtract(binary_mask, binary_green)\n    green_diff_canny = cv2.Canny(green_diff, 40, 40)\n    green = cv2.split(image_BGR)[1]\n    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n    green_contrast = clahe.apply(green)\n\n    ########### PLOTTING ###########\n    def plot_subfigures(rows, columns, index, image, isColor, title):\n        plt.subplot(rows, columns, index)\n        plt.subplots_adjust(hspace=0.5, wspace=0.5)\n        if isColor:\n            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        else :\n            plt.imshow(image, cmap='gray')\n        plt.title('{}'.format(title))\n        plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n    if show:\n        plt.figure(1, figsize=(10, 5))\n        plt.suptitle(\"Preprocessing Uninfected cell\" if label == 0 else \"Preprocessing Infected cell\")\n        #Sub figures\n        plot_subfigures(2, 4, 1, image_BGR, True, \"Original\")\n        plot_subfigures(2, 4, 2, binary_mask, False, \"Binary Mask\")\n        plot_subfigures(2, 4, 3, binary_green, False, \"Binary Green\")\n        plot_subfigures(2, 4, 4, green_diff, False, \"Green diff\")\n        plot_subfigures(2, 4, 5, green_diff_canny, False, \"Green diff Canny\")\n        plot_subfigures(2, 4, 6, green_contrast, False, \"Green Contrast\")\n        plt.savefig(figure_directory + \"cells_processing.pdf\")\n        plt.show()\n    return (green_diff, green_diff_canny, green_contrast)","dd90158e":"############# INPUT CONFIGURATION ###########\nprint(\"########################## MALARIA CELLS (Luca Giulianini) #########################\")\nstart = time.time()\nIN_COLAB = 'google.colab' in sys.modules\ndataset_base_directory = \"input\/cell-images-for-detecting-malaria\/cell_images\/\"\nif not IN_COLAB: dataset_base_directory = \"..\/\" + dataset_base_directory\ncells_folders = os.listdir(dataset_base_directory)\nprint(\"Cells folders:\", cells_folders)\ninfected_folder = dataset_base_directory + \"\/Parasitized\"\nuninfected_folder = dataset_base_directory + \"\/Uninfected\"\ninfected_images = glob.glob(infected_folder + \"\/*.png\")\nuninfected_images = glob.glob(uninfected_folder + \"\/*.png\")\ninfected_number = len(infected_images)\nuninfected_number = len(uninfected_images)\nprint('# Infected fotos: ', infected_number)\nprint('# Infected fotos: ', uninfected_number)\n\n############# OUTPUT CONFIGURATION ###########\ndef create_new_folder(directory):\n    if not os.path.exists(directory):\n        try:\n            os.mkdir(directory)\n        except:\n            print(\"Could not create {} directory\".format(directory))\noutput_directory = r\"output\/\"\nfigure_directory = \"output\/figures\/\"\nmodels_directory = output_directory + r\"models\/\"\nclassifiers_directory = output_directory + r\"classifiers\/\"\nlogs_directory = output_directory + r\"logs\/\"\nmodel_directory = models_directory + time.strftime('%Y-%m-%d %H-%M-%S') + \"\/\"\nlog_directory = logs_directory + time.strftime('%Y-%m-%d %H-%M-%S') + \"\/\"\n\ncreate_new_folder(output_directory)\ncreate_new_folder(figure_directory)\ncreate_new_folder(models_directory)\ncreate_new_folder(logs_directory)\ncreate_new_folder(model_directory)\ncreate_new_folder(classifiers_directory)\ncreate_new_folder(log_directory)\nprint(\"Output folders created under:\", output_directory)","b3a1c4a9":"############ LOAD IMAGES AND LABELS ###############\nnumber_of_cells = infected_number\ncell_dim = 100\nchannels = 5\nn_classes = 2\nn_epochs = 25\nimages = []\nlabels = []\n\ndef load_images(imagePaths, label):\n    for index, imagePath in enumerate(imagePaths):\n        image = cv2.imread(imagePath, cv2.IMREAD_COLOR)\n        image_BGR = cv2.resize(image, (cell_dim, cell_dim))\n        images.append(image_BGR)\n        labels.append(label)\n        if index == number_of_cells - 1:\n            break\n        \nload_images(infected_images, 1)\nload_images(uninfected_images, 0)\nprint(\"Loaded {} images\".format(len(images)))","2608ce92":"################ SPLIT TRAIN VALID TEST ##################\nimages, labels = shuffle(images, labels) \nx_train_image, x_test_image, y_train_label, y_test_label = train_test_split(\n    images, labels, test_size=0.2, random_state=23)\n\nx_train_image, x_valid_image, y_train_label, y_valid_label = train_test_split(\n    x_train_image, y_train_label, test_size=0.2, random_state=23)\n\nx_train = []\ny_train = []\nx_valid = []\ny_valid = []\nx_test = []\ny_test = []","4bbb5f26":"################ STACKING ##################\nprint(\"Stacking images\")\ndef populateSet(x_in, y_in, x_out, y_out):\n    for image, label in zip(x_in, y_in):\n        green_diff, green_diff_canny, green_contrast = process_image(image, label, show=False)\n        image_out = np.dstack((image, green_diff))\n        image_out = np.dstack((image_out, green_diff_canny))\n        x_out.append(image_out)\n        y_out.append(label)\n\npopulateSet(x_train_image, y_train_label, x_train, y_train)\npopulateSet(x_valid_image, y_valid_label, x_valid, y_valid)\npopulateSet(x_test_image, y_test_label, x_test, y_test)\n\n#SHOW PROCESSING\nfor index, label in enumerate(y_train_label): \n    if label == 1:\n        process_image(x_train_image[index], label, show=True)\n        break","b7014a22":"############# CREATING NP ARRAY ###########\nx_train = np.array(x_train)\ny_train = np.array(y_train)\nx_valid = np.array(x_valid)\ny_valid = np.array(y_valid)\nx_test = np.array(x_test)\ny_test = np.array(y_test)\n\ndel x_train_image\ndel x_valid_image\ndel x_test_image\ndel y_train_label\ndel y_valid_label\ndel y_test_label\ndel images\ndel infected_images\ndel uninfected_images\ngc.collect()\n\n########### PLOTTING ###########\nplt.figure(1, figsize=(10, 5))\nplt.title('Random cells visualisation')\nfor i in range(20):\n    r = np.random.randint(0, x_train.shape[0], 1)\n    plt.subplot(4, 5, i + 1)\n    plt.subplots_adjust(hspace=0.5, wspace=0.5)\n    plt.imshow(cv2.cvtColor(x_train[r[0]][:, :, :3], cv2.COLOR_BGR2RGB))\n    plt.title('{} : {}'.format(\n        'Infected' if labels[r[0]] == 1 else 'Unifected', labels[r[0]]))\n    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\nplt.savefig(figure_directory + \"random_cells.pdf\")\nplt.show()\n\n############# NORMALIZING ################\ndef normalize(dataset):\n    dataset = dataset \/ 255\n    dataset = dataset.reshape(dataset.shape[0], dataset.shape[1], dataset.shape[2], channels)\n\nnormalize(x_train)\nnormalize(x_valid)\nnormalize(x_test)\n\nprint(f'Shape of training image : {x_train.shape}')\nprint(f'Shape of validation image : {x_valid.shape}')\nprint(f'Shape of testing image : {x_test.shape}')\nprint(f'Shape of training labels : {y_train.shape}')\nprint(f'Shape of validation labels : {y_valid.shape}')\nprint(f'Shape of testing labels : {y_test.shape}')","5a5762f7":"# DATA GENERATOR\ndatagen = ImageDataGenerator(\n    zoom_range=0.2,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True)\n\n# CREATING SEQUENTIAL MODEL\ndef CNNbuild(height, width, classes, channels):\n    model=Sequential()\n    model.add(Conv2D(16, (5,5), activation = 'relu', input_shape = (height, width, channels)))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis =-1))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(32, (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis = -1))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(32, (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis = -1))\n    \n    model.add(Conv2D(64, (3,3), activation = 'relu'))\n    model.add(MaxPooling2D(2,2))\n    model.add(BatchNormalization(axis = -1))\n    model.add(Dropout(0.2))\n    \n    model.add(Flatten())\n        \n    model.add(Dense(512, activation = 'relu'))\n    model.add(BatchNormalization(axis = -1))\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation = 'sigmoid'))\n    return model\n\nmodel = CNNbuild(height = cell_dim, width = cell_dim, classes = n_classes, channels = channels)\nadam = optimizers.Adam(learning_rate = 0.001)\nmodel.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\nmodel.summary()\nfrom IPython.display import SVG\nfrom keras.utils import model_to_dot\n#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\nplot_model(model, to_file=figure_directory + \"model.pdf\", show_shapes=True, show_layer_names=True, dpi=300)","8a275cbc":"##################### SETTINGS CALLBACKS ####################\nmodel_file = model_directory + \"{epoch:02d}-val_accuracy-{val_accuracy:.2f}-val_loss-{val_loss:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(\n    model_file, \n    monitor='val_accuracy', \n    save_best_only=True)\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=6,\n    verbose=1,\n    restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.6,\n    patience=1,\n    verbose=1)\n\ncallbacks = [checkpoint, reduce_lr, early_stopping]\n\n#history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=32), steps_per_epoch=len(x_train) \/ 32, validation_data=(x_valid, y_valid), epochs= n_epochs, verbose=1, shuffle=True, callbacks=callbacks)\nhistory = model.fit(x_train, y_train, batch_size=32, validation_data=(x_valid, y_valid), epochs=n_epochs, verbose=1, shuffle=True, callbacks=callbacks)\n","5f21189b":"################## EVALUATE ####################\nplt.figure(figsize=(10, 6))\nepochs = len(history.history['accuracy'])\nplt.plot(range(epochs), history.history['val_accuracy'], label='Training Accuracy')\nplt.plot(range(epochs), history.history['val_loss'], label='Taining Loss')\nplt.xlabel(\"Number of Epoch's\")\nplt.ylabel('Accuracy\/Loss Value')\nplt.title('Training Accuracy and Training Loss')\nplt.legend(loc=\"best\")\nplt.savefig(figure_directory + \"accuracy_loss_graph.pdf\")\nplt.show()\n\n################ METRICS ###################\nmetrics = model.evaluate(x_test, y_test, verbose=1)\ncnn_predicted = model.predict(x_test)\ncnn_predicted = cnn_predicted.reshape(cnn_predicted.shape[0])\ncnn_predicted = np.round(cnn_predicted)\ncnn_predicted = cnn_predicted.astype(int)\nprint()\nprint(f'LOSS : {metrics[0]}')\nprint(f'ACCURACY : {metrics[1]}')","84548228":"#GRID SEARCH THOUGH CROSS VALIDATION (By Gianluca Aguzzi)\ndef best_performance_of(classifier, params, x_train, y_train, x_test, y_test, cross_validation = 10, save= False, feature_type = \"neural_feature\"):\n    print(\"Grid search for: \", classifier)\n    clf = GridSearchCV(classifier, params, n_jobs=multiprocessing.cpu_count(), cv=cross_validation, verbose=3)\n    #Fit and search best param\n    #with parallel_backend('threading'):\n      #clf.fit(x_train, y_train)\n    clf.fit(x_train, y_train)\n    print(\"\\nBest parameters set:\")\n    print(clf.best_params_)\n    #used to print confusion matrix\n    y_predict=clf.best_estimator_.predict(x_test)\n    \n    confusion_m = confusion_matrix(y_test, y_predict)\n    index = ['bad','good']  \n    columns = ['bad','good']\n    cm_df = pd.DataFrame(confusion_m,columns,index)                      \n    plt.figure(figsize=(10,6))\n    heatmap = sns.heatmap(cm_df, annot=True, cmap=\"Blues\")\n    fig = heatmap.get_figure()\n    fig.savefig(figure_directory + type(classifier).__name__ + \"_\" + feature_type + \"_\" + \"matrix.pdf\")\n    plt.show()\n    print(\"confusion matrix:\")\n    print(confusion_m)\n    #Same information\n    print(\"\\nClassification report:\")\n    print(classification_report(y_test, y_predict))\n    print(\"Best estimator score: \", clf.best_estimator_.score(x_test, y_test))\n    #Store classifier if save is true\n    if(save):\n        score = int(clf.best_estimator_.score(x_test, y_test) * 100)\n        print(\"store:\" + \"max\" + str(score) +  \".sav\")\n        joblib.dump(clf.best_estimator_, classifiers_directory + \"max\" + str(score) +  \".sav\")","efb1fde7":"################ NEURAL FEATURE EXTRACTION #############\nextract = Model(model.inputs, model.layers[-5].output)\nx_train_neural_features = extract.predict(x_train)\nx_valid_neural_features = extract.predict(x_valid)\nx_test_neural_features = extract.predict(x_test)\nprint(\"Extracted features from flatten layer, shape:\", x_train_neural_features.shape)\n\n################# TRAIN CLASSIFIERS ON NEURAL FEATURES ################\ngrid_search = False\nif grid_search:\n    #### SVM\n    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                        'C': [1, 10, 100]}]\n\n    best_performance_of(svm.SVC(), tuned_parameters, \n                        x_train = x_train_neural_features, y_train = y_train, x_test = x_test_neural_features, y_test = y_test)\n\n    #### RANDOM FOREST\n    tuned_parameters = {\"max_depth\":[11,13,15,17,20]}\n    best_performance_of(RandomForestClassifier(random_state=0), tuned_parameters, \n                        x_train = x_train_neural_features, y_train = y_train, x_test = x_test_neural_features, y_test = y_test)\n    \n    #### KNN\n    tuned_parameters = {\"n_neighbors\": [3,5,9,11,15,17,19],}\n    best_performance_of(KNeighborsClassifier(), tuned_parameters,\n                        x_train = x_train_neural_features, y_train = y_train, x_test = x_test_neural_features, y_test = y_test)\n\n####### SVM\nsvm_neural = svm.SVC(gamma=0.001, C=1, kernel='rbf') # [10, 0.001] V [1, 0.001]\n####### RANDOM FOREST\nrf_neural = RandomForestClassifier(max_depth=16, random_state=0)\n####### KNN\nknn_neural = KNeighborsClassifier(n_neighbors = 5) #5\n\n################### MAJORITY NEURAL CLASSIFIER ####################\nprint(\"SVM\/RF\/KNN training on neural features...\")\nmulti_neural = VotingClassifier(estimators=[\n       ('svm', svm_neural), ('rf', rf_neural), ('knn', knn_neural)],\n       voting='hard', weights=[1.2,1,1],\n       flatten_transform=True, n_jobs=-1)\nmulti_neural = multi_neural.fit(x_train_neural_features, y_train)\nmulti_neural_predicted = multi_neural.predict(x_test_neural_features)\nprint(\"SVM\/RF\/KNN neural features accuracy score:\", accuracy_score(y_test, multi_neural_predicted))","4cf0652b":"################ GRAYSCALE IMAGES #############\nx_train_gray_diff = x_train[:, :, :, 3:4]\nx_test_gray_diff = x_test[:, :, :, 3:4]\n\nx_train_gray_diff = x_train_gray_diff.reshape(x_train_gray_diff.shape[0], x_train_gray_diff.shape[1], x_train_gray_diff.shape[2])\nx_test_gray_diff = x_test_gray_diff.reshape(x_test_gray_diff.shape[0], x_test_gray_diff.shape[1], x_test_gray_diff.shape[2])\nprint(\"Green difference images shape:\", x_train_gray_diff.shape)\n\nplt.title(\"Green difference image\")\nplt.imshow(cv2.cvtColor(x_train_gray_diff[0], cv2.COLOR_BGR2RGB))\nplt.show()\n\n################# LBP FEATURE EXTRACTION ############\nclass LocalBinaryPatterns:\n\tdef __init__(self, numPoints, radius):\n\t\t# store the number of points and radius\n\t\tself.numPoints = numPoints\n\t\tself.radius = radius\n\tdef describe(self, image, eps=1e-7):\n\t\t# compute the Local Binary Pattern representation\n\t\t# of the image, and then use the LBP representation\n\t\t# to build the histogram of patterns\n\t\tlbp = feature.local_binary_pattern(image, self.numPoints,\n\t\t\tself.radius, method=\"uniform\")\n\t\t(hist, _) = np.histogram(lbp.ravel(),\n\t\t\tbins=np.arange(0, self.numPoints + 3),\n\t\t\trange=(0, self.numPoints + 2))\n\t\t# normalize the histogram\n\t\thist = hist.astype(\"float\")\n\t\thist \/= (hist.sum() + eps)\n\t\t# return the histogram of Local Binary Patterns\n\t\treturn hist\n\nx_train_lbp_features = []\nx_test_lbp_features = []\n\ndesc = LocalBinaryPatterns(24, 8)\n\nprint(\"Computing LBP descriptors...\")\nfor gray in x_train_gray_diff:\n    hist = desc.describe(gray)\n    x_train_lbp_features.append(hist)\nfor gray in x_test_gray_diff:\n    hist = desc.describe(gray)\n    x_test_lbp_features.append(hist)\n\nx_train_lbp_features = np.array(x_train_lbp_features)\nx_test_lbp_features = np.array(x_test_lbp_features)\nprint(\"lbp features shape:\", x_train_lbp_features.shape)","caea161f":"################# TRAIN CLASSIFIERS ON LBP FEATURES ################\ngrid_search = False\nif grid_search:\n    #### SVM\n    tuned_parameters = [{'kernel': ['linear'], 'C': [100, 1000, 10000]}]\n\n    best_performance_of(svm.SVC(), tuned_parameters, \n                        x_train = x_train_lbp_features, y_train = y_train, x_test = x_test_lbp_features, y_test = y_test)\n\n    #### RANDOM FOREST\n    tuned_parameters = {\"max_depth\":[5,7,9,11,13,15]}\n    best_performance_of(RandomForestClassifier(random_state=0), tuned_parameters, \n                        x_train = x_train_lbp_features, y_train = y_train, x_test = x_test_lbp_features, y_test = y_test)\n    \n    #### KNN\n    tuned_parameters = {\"n_neighbors\": [3,5,9,11,15,17,19],}\n    best_performance_of(KNeighborsClassifier(), tuned_parameters,\n                        x_train = x_train_lbp_features, y_train = y_train, x_test = x_test_lbp_features, y_test = y_test)\n\n####### SVM\nsvm_lbp = svm.SVC(C=10000, kernel='linear') #10000\n####### RANDOM FOREST\nrf_lbp = RandomForestClassifier(max_depth=7, random_state=0) #7\n####### KNN\nknn_lbp = KNeighborsClassifier(n_neighbors = 9) #9\n\n################### MAJORITY LBP CLASSIFIER ####################\nprint(\"SVM\/RF\/KNN training on LBP features...\")\nmulti_lbp = VotingClassifier(estimators=[\n       ('svm', svm_lbp), ('rf', rf_lbp), ('knn', knn_lbp)],\n       voting='hard', weights=[1.2,1,1],\n       flatten_transform=True, n_jobs=-1)\nmulti_lbp = multi_lbp.fit(x_train_lbp_features, y_train)\nmulti_lbp_predicted = multi_lbp.predict(x_test_lbp_features)\nprint(\"SVM\/RF\/KNN LBP features accuracy score:\", accuracy_score(y_test, multi_lbp_predicted))","4f69ab8b":"################### FINAL EVALUATION ########################\nprint(\"\\nFINAL EVALUATION\")\n\ncnn_neural_lbp_predicted = np.column_stack((cnn_predicted, multi_neural_predicted))\ncnn_neural_lbp_predicted = np.column_stack((cnn_neural_lbp_predicted, multi_lbp_predicted))\ncnn_neural_lbp_predicted = stats.mode(cnn_neural_lbp_predicted, axis=1)[0]\nprint(\"\\nFINAL CNN\/Neural\/LBP accuracy score:\", accuracy_score(y_test, cnn_neural_lbp_predicted))","7a7c1077":"################### PCA T-SNE AND PLOTTING ################# \nprint(\"Features visualisation: PDA -> T-SNE\")\nfeature_number = 10000\nx_visual_features = x_train_neural_features[:feature_number]\ny_visual_features = y_train[:feature_number]\n#features_columns = ['pixel' + str(i) for i in range(x_train_neural_features.shape[1])]\ndf = pd.DataFrame(x_visual_features) #, columns=features_columns)\ndf['y'] = y_visual_features\n#df['label'] = df['y'].apply(lambda i: str(i))\nprint('Dataframe size:', df.shape)\n\npca = PCA(n_components=50)\npca_result = pca.fit_transform(df)\nprint(\"PCA shape:\", pca_result.shape)\n\ntsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300)\ntsne_pca_result = tsne.fit_transform(df)\nprint(\"T-SNE shape:\", tsne_pca_result.shape)\n\ndf['dim-1'] = tsne_pca_result[:,0]\ndf['dim-2'] = tsne_pca_result[:,1] \n\nplt.figure(figsize=(10,6))\nplt.title(\"T-SNE 2D visualisation\")\nsns.scatterplot(\n    x=\"dim-1\", y=\"dim-2\",\n    hue=\"y\",\n    palette=sns.color_palette(\"hls\", 2),\n    data=df,\n    legend=\"full\",\n    alpha=1\n)\nplt.savefig(figure_directory + \"cells_visualisation_2D.pdf\")\nplt.show()\n\n######################## COMPUTE ELAPSED TIME ###########################\nend = time.time()\nhours, rem = divmod(end-start, 3600)\nminutes, seconds = divmod(rem, 60)\nprint(\"ELAPSED TIME:\", \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n\n# WAIT AND DESTROY\ncv2.waitKey()\ncv2.destroyAllWindows()","efd314f2":"## Stacking of Processed Images\n\nPreprocessed images are stacked together with original BGR images -> 5D images (width, heigth, 5)","673a3807":"## Training on LBP features\n\nTrain on LBP features using a Voting Classifier (SVM, Random Forest, KNN)","417d862f":"## Training CNN \n\n- Definition of callbacks\n- Train of CNN model","17905771":"## Local Binary Patter \n\nExtraction of LBP features:\n- Get *green_diff* images\n- Compute LBP features","b9e92954":"## Image Loading\n\n- Images are loaded in memory","df13dc47":"## Image Dataset Split\n\nDataset of images is shuffled and then splitted into train\/validation\/test sets","adc4991c":"## Import\n\nImporting:\n- **Numpy pandas:** data manipulation\n- **Matplotlib seabon:** plotting\n- **cv2 skimage:** image processing\n- **scipy:** scientific\n- **scipy sklearn:** classifiers\n- **keras:** cnn ","bb143786":"## Input\/Output Configuration\n\n- Configuring input and loading images into memory\n- Configuring output folders and paths for future store","3e9470b4":"## Grid Search\n\nFunction for machine learning hyperparameter evaluation trough GridSearch","ac0ea11d":"#Handcrafted Features\n\n<img src=\"https:\/\/zbigatron.com\/wp-content\/uploads\/2018\/03\/Screen-Shot-2018-03-16-at-3.06.48-PM-1024x373.png\" alt=\"Malaria cells\" width=700 aligh=center\/>\n\n\nPerforming feature extracting and training using 'classic' machine learning algorithms","7bd1aa57":"# Constructing CNN Model\n\n<img src=\"https:\/\/www.researchgate.net\/publication\/324744613\/figure\/fig2\/AS:619144403763205@1524626937385\/3D-Convolutional-Neural-Network-Architecture-for-Classification.png\" alt=\"Malaria cells\" width=700 aligh=center\/>\n\nI have chosen keras sequential model because it is simpler than a fine tuning approach on pretrained complex model. Always follow Occam Razor!\n- Prepare also **data augmentation**","ae8a32b3":"## Extracting Neural Features and Training\n\nNeural features extraction is performed in this way:\n- Train the CNN so that weight can be setted in optimal way\n- Remove dense level from CNN\n- Feed train data trough CNN and extract **flatten** level features (dim = 1024)\n- Pass features to Voting Classifier (SVM, Random Forest, KNN)","37404add":"# Malaria Cells Images Classification using Deep Learning and Handcrafted Features\n\nMalaria is a mosquito-borne infectious disease that affects humans and other animals. Malaria causes symptoms that typically include fever, tiredness, vomiting, and headaches. In severe cases it can cause yellow skin, seizures, coma, or death.\n\n<img src=\"https:\/\/www.focus.it\/images\/2019\/11\/26\/plasmodium-falciparum-parassita-della-malaria-orig.jpg\" alt=\"Malaria cells\" width=500 aligh=center\/>\n\nMalaria is caused by single-celled microorganisms of the Plasmodium group. The disease is most commonly spread by an infected female Anopheles mosquito. The mosquito bite introduces the parasites from the mosquito's saliva into a person's blood. The parasites travel to the liver where they mature and reproduce infecting other cells.\n\n<img src=\"https:\/\/cdn.the-scientist.com\/assets\/articleNo\/65538\/aImg\/30950\/malaria-infographic-l.png\" alt=\"Anopheles Mosquito\" width=400 aligh=\"center\"\/>\n\n##Malaria cells classification\nManual identification and counting of parasitized cells in microscopic thick\/thin-film blood examination remains the common, but burdensome method for disease diagnosis. Its diagnostic accuracy is adversely impacted by inter\/intra-observer variability, particularly in large-scale screening under resource-constrained settings.\nThe primary aim of this notebook is to reduce model variance, improve robustness and generalization through constructing model ensembles toward classifing parasitized cells in thin-blood smear images.\n","fffe82ce":"## Final Evaluation\n\n- Create a 3-column array with (cnn, cnn_extracted, lbp) features\n- Perform majority vote rule and find most voted class per image","2cde5a57":"## Creating NP-Arrays\n\nImages lists are converted in np_arrays and normalized","69668fcd":"## Image Processing\n\nA BGR image is processed in this way:\n- **binary_mask:** Contour mask optained by thresholding the original grayscale image\n- **binary_green:** special thresholding of green channel in order to highlight defects\n- **erosion**: binary_mask is eroded to make border thin. (clean subtraction)\n- **green_diff:** binary_green is subtracted from binary_mask leaving **only defects**\n- **grenn_diff_canny:** canny edge detector applied to green_diff\n- **green_contast:** green channel with more contrast\n\n**Return:** tuple of 3 element (green_diff, green_diff_canny, green_contrast)","f9f6f09b":"## Model Evaluation\n\nEvalutating accuracy and loss and printing result","fb5c9d45":"# Visualisation\n\n2D visualisation is performed in this way:\n- Select number of features to display\n- Reduce dimensionality to lower dimensions (50) trough **PCA** algorithm\n- Reduce dimensionality to 2 dimensions trough **T-SNE** algorithm\n- Plot the result\n"}}