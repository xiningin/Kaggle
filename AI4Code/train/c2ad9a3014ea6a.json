{"cell_type":{"93f3d247":"code","241c4d81":"code","938dbfe8":"code","d2817e62":"code","00be845e":"code","70e6841e":"code","35fc3ecd":"code","6bef2e8a":"code","84ab3917":"code","5d304e93":"code","be8f21bc":"code","fe64b31c":"code","258ba4e2":"code","42f81903":"code","c7f5c3ea":"code","a645d1b7":"code","368e7169":"code","93d24677":"code","a8a00b41":"code","5c12f71b":"code","6b93b3d2":"code","af58ab60":"code","3efafa67":"code","5857254b":"code","858ee6c4":"markdown","39d30753":"markdown","11339f38":"markdown","4e552d0b":"markdown","58e6a481":"markdown","63bcde8b":"markdown","ad64f5c0":"markdown","46161c1b":"markdown","d5f75516":"markdown","548271eb":"markdown","f5f5c08e":"markdown","a6ba68a0":"markdown","89744a77":"markdown","c783671a":"markdown","1e6bffc9":"markdown"},"source":{"93f3d247":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom keras.layers import Dense, MaxPool2D, Flatten, Conv2D, Dropout\nfrom keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam","241c4d81":"import warnings\nwarnings.filterwarnings('ignore')","938dbfe8":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nTest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","d2817e62":"train.head()","00be845e":"Test.head()","70e6841e":"sns.set(palette=\"Paired\")\nplt.rcParams['figure.dpi'] = 120","35fc3ecd":"train_y=train['label']\ntrain_x=train.drop(labels = [\"label\"],axis = 1)\ntrain_y.head()","6bef2e8a":"plt.figure(figsize=(20, 10))\nfor i in range(27):\n    plt.subplot(3, 9, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_x.iloc[i].to_numpy().reshape((28,28,1)))\n    plt.title(train_y[i],size = 20)\nplt.show()","84ab3917":"a = dict(train['label'].value_counts())\na = dict(sorted(a.items()))","5d304e93":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize =(14,6))\nbackground_color = '#faf9f4'\nax1.set_facecolor(background_color)\nax2.set_facecolor(background_color) \nax1.pie(a.values(),wedgeprops=dict(width=0.3, edgecolor='w') ,labels=a.items(), radius=1)\nax2 = sns.countplot(train['label'])\nplt.show()","be8f21bc":"train_x = train_x\/255.0\ntest = Test\/255.0\nprint(\"X_train Shape  : \",train_x.shape)\nprint(\"Test Shape     : \",train_y.shape)","fe64b31c":"train_x = train_x.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(\"X_train Shape  : \",train_x.shape)\nprint(\"Test Shape     : \",train_y.shape)","258ba4e2":"x_train,x_val,y_train,y_val = train_test_split(train_x,train_y,test_size = 0.2,random_state = 12345)","42f81903":"x_train.shape,x_val.shape,y_train.shape,y_val.shape","c7f5c3ea":"model = Sequential()\nmodel.add(Conv2D(filters = 8, kernel_size = (3,3),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","a645d1b7":"model.compile(loss ='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),metrics =['accuracy'])","368e7169":"history = model.fit(\n    x_train,\n    y_train,\n    batch_size=1000,\n    epochs=30,\n    verbose=1,\n    validation_data=(x_val,y_val),\n)","93d24677":"print('Loss     : {} \\nAccuracy : {}'.format(history.history['loss'][-1],history.history['accuracy'][-1]))","a8a00b41":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize =(14,6))\n\nax1.plot(history.history['loss'], color='r', label=\"train_Loss\")\nax1.plot(history.history['val_loss'], color='b', label=\"val_Loss\")\nax1.legend()\nax1.set_title(\"Test Loss\")\nax1.set_ylabel(\"Loss\")\nax1.set_xlabel(\"Epochs\")\n\nax2.plot(history.history['accuracy'], color='r', label=\"train_Accuracy\")\nax2.plot(history.history['val_accuracy'], color='b', label=\"val_Accuracy\")\nax2.legend()\nax2.set_title(\"Test Accuracy\")\nax2.set_ylabel(\"Accuracy\")\nax2.set_xlabel(\"Epochs\")\nfig.tight_layout()","5c12f71b":"Y_pred = model.predict(x_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.array(y_val)\nrows = 4\ncols = 6\nf = plt.figure(figsize=(2*cols,2*rows))\nf.suptitle(\"Validation Predictions\", fontsize=20)\nfor i in range(rows*cols): \n    f.add_subplot(rows,cols,i+1)\n    img = x_val[i]\n    img = img.reshape((28,28))\n    plt.imshow(img,\n               cmap='gray')\n    plt.axis(\"off\")\n    plt.title(\"Prediction: {}\\nTrue Value: {}\".format(Y_pred_classes[i], Y_true[i]),\n              y=-0.35,color=\"red\")\nf.tight_layout()\n    \nf.show()","6b93b3d2":"confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\nf,ax = plt.subplots(figsize=(6,6))\nsns.heatmap(confusion_mtx, annot=True,\n            linewidths=3,cmap=\"viridis\",\n            fmt= '.0f',ax=ax,\n            cbar = False,\n           annot_kws={\"size\": 16})\nplt.yticks(rotation = 0)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\", size = 14)\nplt.show()","af58ab60":"Y_pred = model.predict(test)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nrows = 4\ncols = 6\nf = plt.figure(figsize=(2*cols,2*rows))\nf.suptitle(\"Predictions\", fontsize=20)\nfor i in range(rows*cols): \n    f.add_subplot(rows,cols,i+1)\n    img = test[i]\n    img = img.reshape((28,28))\n    plt.imshow(img,\n               cmap='gray')\n    plt.axis(\"off\")\n    plt.title(\"Prediction: {}\".format(Y_pred_classes[i]),\n              y=-0.35,color=\"red\")\nf.tight_layout()\n    \nf.show()","3efafa67":"submission = pd.DataFrame({'ImageId': range(1,28001), 'Label': Y_pred_classes})\nsubmission.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","5857254b":"submission","858ee6c4":"**go to [Index](#content)**\n\n<div id='Chapter3'><\/div>\n\n##  Create the model\nNow we will create our CNN model. A CNN model generally consists of convolutional and pooling layers. It works better for data that are represented as grid structures, this is the reason why CNN works well for image classification problems. The dropout layer is used to deactivate some of the neurons and while training, it reduces offer fitting of the model. We will then compile the model with the Adam optimizer.","39d30753":"## NN (Neural networks)\nNeural Networks mimics the working of how our brain works. They have emerged a lot in the era of advancements in computational power.\n\n![](https:\/\/miro.medium.com\/max\/1194\/1*14-ce3jNHqJ5x5eb7CyTbw.png)\n\nDeep learning is the acronym for Neural Networks, the network connected with multilayers. The layers are composited form nodes. A node is just a perception which takes an input performs some computation and then passed through a node\u2019s activation function, to show that up to what context signal progress proceeds through the network to perform classification.","11339f38":"**go to [Index](#content)**","4e552d0b":"**go to [Index](#content)**\n\n<div id='Chapter4'><\/div>\n\n## Train the model\n\nThe model.fit() function of Keras will start the training of the model. It takes the training data, validation data, epochs, and batch size.","58e6a481":"**go to [Index](#content)**\n\n<div id='Chapter6'><\/div>\n\n##  Prediction on Test data\nWe have 28,000 images in our dataset which will be used to evaluate how good our model works. The testing data was not involved in the training of the data therefore, it is new data for our model. The MNIST dataset is well balanced so we can get around 98-99% accuracy.","63bcde8b":"The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n\nEach pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).","ad64f5c0":"**go to [Index](#content)**\n\n<div id='Chapter2'><\/div>\n\n##  Preprocess the data\n\nThe image data cannot be fed directly into the model so we need to perform some operations and process the data to make it ready for our neural network. The dimension of the training data is (42000,28,28). The CNN model will require one more dimension so we reshape the matrix to shape (42000,28,28,1).","46161c1b":"**go to [Index](#content)**\n\n<div id='Chapter7'><\/div>\n\n##  Submission","d5f75516":"**go to [Index](#content)**\n\n<div id='Chapter5'><\/div>\n\n## Evaluate on validation data","548271eb":"## **The model predict with 98.75% accuracy in kaggle Digit Recognizer competition**\n\n# **If you like, an upvote would be deeply appreciated. Thanks! :)**","f5f5c08e":"<div id='Chapter1'><\/div>\n\n## Import the libraries and load the dataset","a6ba68a0":"# **Kaggle Handwritten Digit Recognition**\n\n## What is Handwritten Digit Recognition?\n![](https:\/\/www.researchgate.net\/profile\/Hugo-Larochelle\/publication\/200744481\/figure\/fig1\/AS:668968306098181@1536505881710\/Samples-from-the-MNIST-digit-recognition-data-set-Here-a-black-pixel-corresponds-to-an.png)\n\n**The handwritten digit recognition is the ability of computers to recognize human handwritten digits. It is a hard task for the machine because handwritten digits are not perfect and can be made with many different flavors. The handwritten digit recognition is the solution to this problem which uses the image of a digit and recognizes the digit present in the image.**","89744a77":"## Layers of Convolutional neural network\nThe multiple occurring of these layers shows how deep our network is, and this formation is known as the deep neural network.\n\n![](https:\/\/miro.medium.com\/max\/788\/1*0NwaOkzvom6YpMZoIgWTiQ.png)\n\n\n- **Input**: raw pixel values are provided as input.\n- **Convolutional layer**: Input layers translates the results of neuron layer. There is need to specify the filter to be used. Each filter can only be a 5*5 window that slider over input data and get pixels with maximum intensities.\n- **Rectified linear unit [ReLU] layer**: provided activation function on the data taken as an image. In the case of back propagation, ReLU function is used which prevents the values of pixels form changing.\n- **Pooling layer**: Performs a down-sampling operation in volume along the dimensions (width, height).\n- **Fully connected layer**: score class is focused, and a maximum score of the input digits is found.","c783671a":"## CNN (Convolutional Neural Network)\nNow let\u2019s discuss the Convolutional Neural Networks, CNN has become famous among the recent times. CNN is part of deep, feed forward artificial neural networks that can perform a variety of task with even better time and accuracy than other classifiers, in different applications of image and video recognition, recommender system and natural language processing.\n\n![](https:\/\/miro.medium.com\/max\/1144\/1*22R-AyQ-oXb8Flod9PsyNw.png)\n\nUse of CNN have spread as Facebook uses neural nets for their automatic tagging algorithms, google for photo search Amazon for their product recommendations, Pinterest for their home feed personalization and Instagram for search infrastructure. Image classification or object recognition is a problem is passing an image as a parameter and predicting whether a condition is satisfied or not (cat or not, dot or not), or the probability or most satisfying condition for an image. We are able to quickly recognize patterns, generalize from previous information and knowledge.\n\n![](https:\/\/miro.medium.com\/max\/716\/1*u_kP2X3t2LF_WyiLwL57Gg.png)","1e6bffc9":"<div id='content'><\/div>\n\n## Index of Content\n\n* [**Import the libraries and load the dataset**](#Chapter1)\n* [**Preprocess the data**](#Chapter2)\n* [**Create the model**](#Chapter3)\n* [**Train the model**](#Chapter4)\n* [**Evaluate on validation data**](#Chapter5)\n* [**prediction on test data**](#Chapter6)\n* [**submission**](#Chapter7)"}}