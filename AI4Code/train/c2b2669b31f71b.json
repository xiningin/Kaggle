{"cell_type":{"9829b567":"code","7609aad2":"code","e1231ba9":"code","34031a30":"code","a3ef30f4":"code","3b738a6c":"code","fd33ee66":"code","10808482":"code","b2add8ce":"code","5f09ccf7":"code","5e3e9258":"code","445f17b2":"code","6c11a55e":"code","58d97a7e":"code","1e06cbb1":"code","f79b4438":"code","5da49193":"code","19710b73":"code","6965d3ec":"code","1de878b8":"code","3840bece":"code","adaafb1e":"code","64cc6785":"code","d3cc940f":"code","475036c3":"code","19cd8870":"code","91afc8fb":"code","602a1001":"code","60981d17":"code","11ad925d":"code","42b4f0b7":"code","1c2c63c9":"code","b4c0fba1":"code","6d6ae656":"code","c6f02de7":"code","31843994":"code","c3e9c24c":"code","1576f66b":"code","637e9fd0":"code","24956c9f":"code","b01739a2":"code","a708b0c8":"code","14dc1fdd":"markdown","71f15b86":"markdown","e3e602dc":"markdown","d75052fd":"markdown","8e86a83c":"markdown","fa6a65d6":"markdown","664a236b":"markdown","bb089c93":"markdown","ed0ea685":"markdown","3126aaf7":"markdown","41bbed7e":"markdown","4e9cd34c":"markdown","c2bcb4b1":"markdown","58b1d57a":"markdown","e4a3e8ae":"markdown","2781b480":"markdown","a45de38e":"markdown","0bfb2a3e":"markdown","652475c4":"markdown","19587ba1":"markdown","69fd3f83":"markdown"},"source":{"9829b567":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# import warnings\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","7609aad2":"train = pd.read_csv(\"..\/input\/train.csv\")","e1231ba9":"# Display the content of data\ntrain.info()","34031a30":"# shape gives number of rows and columns in a tuple\ntrain.shape","a3ef30f4":"train.Id.describe()","3b738a6c":"train.head(10)","fd33ee66":"train.tail(10)","10808482":"# put labels into y_train variable\ny_train = train[\"Id\"]\n# Drop 'Id' column\nX_train = train.drop(labels = [\"Id\"], axis = 1)\ny_train.head()","b2add8ce":"# Indicates sum of values in our data\ntrain.isnull().sum().sum()","5f09ccf7":"from keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\n\ndef prepareImages(train, shape, path):\n    \n    x_train = np.zeros((shape, 100, 100, 3))\n    count = 0\n    \n    for fig in train['Image']:\n        \n        #load images into images of size 100x100x3\n        img = image.load_img(\"..\/input\/\"+path+\"\/\"+fig, target_size=(100, 100, 3))\n        x = image.img_to_array(img)\n        x = preprocess_input(x)\n\n        x_train[count] = x\n        if (count%500 == 0):\n            print(\"Processing image: \", count+1, \", \", fig)\n        count += 1\n    \n    return x_train","5e3e9258":"x_train = prepareImages(train, train.shape[0], \"train\")","445f17b2":"x_train = x_train \/ 255.0\nprint(\"x_train shape: \",x_train.shape)","6c11a55e":"# Some examples(first one)\nplt.imshow(x_train[0][:,:,0], cmap=\"gray\")\nplt.title(plt.title(train.iloc[0,0]))\nplt.axis(\"off\")\nplt.show()","58d97a7e":"# Some examples(last one)\nplt.imshow(x_train[25360][:,:,0], cmap=\"gray\")\nplt.title(plt.title(train.iloc[25360,0]))\nplt.axis(\"off\")\nplt.show()","1e06cbb1":"# Some examples(55th)\nplt.imshow(x_train[55][:,:,0], cmap=\"gray\")\nplt.title(plt.title(train.iloc[55,0]))\nplt.axis(\"off\")\nplt.show()","f79b4438":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()","5da49193":"y_train = label_encoder.fit_transform(y_train)","19710b73":"#let's look at first 10 values\ny_train[0:10]  # => new_whale :)","6965d3ec":"y_train.shape","1de878b8":"# convert to one-hot-encoding(one hot vectors)\n# we have 5005 class look at from=> train.Id.describe()\n\nfrom keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train, num_classes = 5005)","3840bece":"#converted\nprint(y_train.shape)\ny_train #let's look at vectors","adaafb1e":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential # to create a cnn model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 16, kernel_size = (5,5), padding = 'Same', activation = 'relu', input_shape = (100,100,3)))\nmodel.add(Conv2D(filters = 16, kernel_size = (5,5), padding = 'Same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = (2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = (2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n# fully connected\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(y_train.shape[1], activation = \"softmax\"))","64cc6785":"model.summary()","d3cc940f":"# Define the optimizer\noptimizer = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)","475036c3":"# # Define the optimizer\n# optimizer = RMSprop(lr = 0.001, rho=0.9, epsilon=1e-08, decay=0.0)","19cd8870":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","91afc8fb":"model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","602a1001":"# if you want to use Data Augmentation,Activate it.","60981d17":"# # With data augmentation to prevent overfitting\n\n# datagen = ImageDataGenerator(\n#         featurewise_center=False,  # set input mean to 0 over the dataset\n#         samplewise_center=False,  # set each sample mean to 0\n#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n#         samplewise_std_normalization=False,  # divide each input by its std\n#         zca_whitening=False,  # apply ZCA whitening\n#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n#         zoom_range = 0.1, # Randomly zoom image \n#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n#         horizontal_flip=False,  # randomly flip images\n#         vertical_flip=False)  # randomly flip images\n\n\n# datagen.fit(x_train)","11ad925d":"epochs = 100  # for better result increase the epochs\nbatch_size = 1000","42b4f0b7":"#if you don't want to use data augmentation ,Use this code.\nhistory = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[learning_rate_reduction])","1c2c63c9":"# history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n#                               epochs=100, verbose = 2, \n#                               steps_per_epoch=x_train.shape[0] \/\/ batch_size,\n#                               callbacks=[learning_rate_reduction]) ","b4c0fba1":"# Plot the loss curve for training\nplt.plot(history.history['loss'], color='r', label=\"Train Loss\")\nplt.title(\"Train Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","6d6ae656":"# Plot the accuracy curve for training\nplt.plot(history.history['acc'], color='g', label=\"Train Accuracy\")\nplt.title(\"Train Accuracy\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","c6f02de7":"print('Train accuracy of the model: ',history.history['acc'][-1])","31843994":"print('Train loss of the model: ',history.history['loss'][-1])","c3e9c24c":"test = os.listdir(\"..\/input\/test\/\")\nprint(len(test))","1576f66b":"col = ['Image']\ntest_data = pd.DataFrame(test, columns=col)\ntest_data['Id'] = ''","637e9fd0":"x_test = prepareImages(test_data, test_data.shape[0], \"test\")\nx_test \/= 255","24956c9f":"predictions = model.predict(np.array(x_test), verbose=1)","b01739a2":"for i, pred in enumerate(predictions):\n    test_data.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))","a708b0c8":"test_data.head(10)\ntest_data.to_csv('submission_3.csv', index=False)","14dc1fdd":"<a id=\"10\"><\/a> <br>\n### Epochs and Batch Size","71f15b86":"<a id=\"11\"><\/a>\n### Fit the Model","e3e602dc":"For the data augmentation, i choosed to :\n\n* ** Randomly rotate some training images by 10 degrees **\n* ** Randomly zoom by 10% some training images **\n* ** Randomly shift images horizontally by 10% of the width **\n* ** Randomly shift images vertically by 10% of the height **\n","d75052fd":"<a id=\"13\"><\/a> <br>\n## Predict Test Data","8e86a83c":"<a id=\"12\"><\/a> <br>\n### Evaluate the model\n* Validation and Loss visualization","fa6a65d6":"<a id=\"7\"><\/a> <br>\n### Set the Optimizer and Annealer\n* Adam optimizer: Changes the learning rate during training","664a236b":"<a id=\"14\"><\/a> <br>\n# Conclusion\n* If you like it, please upvote.\n* If you have any question, I will be appreciate to hear it.","bb089c93":"<a id=\"8\"><\/a> <br>\n### Compile Model","ed0ea685":"#### Let's look at some samples","3126aaf7":"<a id=\"9\"><\/a>\n### Data Augmentation","41bbed7e":"## To be continued...","4e9cd34c":"<a id=\"1\"><\/a> <br>\n# INTRODUCTION\n* In this kernel, we will be working on Humpback Whale Identification Dataset (Implementing with Keras).","c2bcb4b1":"** * we get good accuracy, but we need to play with the hyperparameters to get better results from the submission result. **","58b1d57a":"<a id=\"5\"><\/a> <br>\n## Label Encoding","e4a3e8ae":"Content:\n* [Introduction](#1):\n* [Import Data Set](#2):\n* [Preparing Images](#3):\n* [Normalize the Data](#4):\n* [Label Encoding](#5):\n* [Implementing with Keras](#6):\n* [Set the Optimizer and Annealer](#7):\n* [Compile Model](#8):\n* [Data Augmentation](#9):\n* [Epochs and Batch Size](#10):\n* [Fit the Model](#11):\n* [Evaluate the model](#12):\n* [Predict Test Data](#13):\n* [Conclusion](#14):","2781b480":"<a id=\"3\"><\/a> <br>\n## Preparing Images","a45de38e":"### We get good accuracy, but we need to play with the hyperparameters to get better results from the submission result.","0bfb2a3e":"<a id=\"2\"><\/a> <br>\n## Import Dataset","652475c4":"<a id=\"4\"><\/a> <br>\n### Normalize the Data","19587ba1":"<a id=\"6\"><\/a> <br>\n## Implementing with Keras","69fd3f83":"### If you want to use data augmentation,Enable below code and disable above code."}}