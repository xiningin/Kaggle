{"cell_type":{"81d871bb":"code","e4035b5d":"code","f2266ea7":"code","3fd0f01c":"code","5b9ea570":"code","5495a345":"code","38de71e7":"code","1eac18ec":"code","5589209c":"code","a46c8e76":"code","0328201c":"code","d317d317":"code","0f57da5c":"code","b9fbdb66":"code","25a4c528":"code","e3b77642":"code","b829a0fb":"code","2b4ca7cf":"code","d5501eeb":"code","8f384a02":"code","0a0d63c3":"code","1834b996":"code","d81661c6":"code","d5704d80":"markdown"},"source":{"81d871bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport lightgbm as lgbm\nfrom sklearn.preprocessing import LabelEncoder\nimport gc\nimport warnings\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n#np.seterr(divide='ignore', invalid='ignore')\n#numpy.seterr(all='raise')","e4035b5d":"def reduce_mem_usage(df):\n    #code from\n    #https:\/\/www.kaggle.com\/rohanrao\/ashrae-half-and-half\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","f2266ea7":"#display\u306e\u884c\u6570\u3068\u5217\u6570\u3092\u5897\u3084\u3059\n#display Increase the number of rows and columns in \npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 200)\nwarnings.simplefilter('ignore')\n#csv\u3092\u8aad\u307f\u8fbc\u3080\n#read csv\nbuilding = pd.read_csv('..\/input\/ashrae-energy-prediction\/building_metadata.csv')\nweather_train = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_train.csv')\nweather_test = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_test.csv')\ntrain = pd.read_csv('..\/input\/ashrae-energy-prediction\/train.csv') \ntest = pd.read_csv('..\/input\/ashrae-energy-prediction\/test.csv')\n\n#\u3053\u3053\u306f\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u304b\u3089\u4f5c\u6210\u3057\u305f\u4e88\u6e2c\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\n#Load forecast data\n#submission_test = pd.read_csv('..\/input\/ashrae-half-and-half\/submission_13.csv')\nsubmission_test = pd.read_csv('..\/input\/ashrae-test-leak-validation-and-more\/submission.csv')\n\nle = LabelEncoder()\nbuilding.primary_use = le.fit_transform(building.primary_use)\n","3fd0f01c":"def boundary_show_train_test(train,test):\n    \"\"\"\n    Training data and test data (test data has already been added with the predicted objective variable)\n    :param train:\n    :param test:\n    \"\"\"    \n    \n    datas = train.tail(100) \n    datas = datas.append(test.head(100))\n    \n    datas = datas.reset_index()\n    \n    return datas\n\n","5b9ea570":"print(\"----building------------------------------------------\")\ndisplay(building.head(5))\ndisplay(building.describe().T)\ndisplay(building.dtypes)\nprint(building.shape)\n\nprint(\"----weather_train------------------------------------------\")\ndisplay(weather_train.head(5))\ndisplay(weather_train.describe().T)\ndisplay(weather_train.dtypes)\nprint(weather_train.shape)\n\nprint(\"----train------------------------------------------\")\ndisplay(train.head(5))\ndisplay(train.describe().T)\ndisplay(train.dtypes)\nprint(train.shape)\n","5495a345":"#\u57fa\u790e\u7684\u306a\u7d71\u8a08\u91cf\u3092\u51fa\u3059\nprint(\"building\" + \"-\" * 50)\ndisplay(building.describe().T)\nprint(\"weather_train\" + \"-\" * 50)\ndisplay(weather_train.describe().T)\nprint(\"train\" + \"-\" * 50)\ndisplay(train.describe().T)\n\n#\u6b20\u640d\u3092\u51fa\u3059\nprint(\"train null\" + \"-\" * 50)\ndisplay(train.isnull().sum())\n\nprint(\"weather_train null\" + \"-\" * 50)\ndisplay(weather_train.isnull().sum())\n\nprint(\"building null\" + \"-\" * 50)\ndisplay(building.isnull().sum())","38de71e7":"####################################\n#Data merge\n####################################\n\n#\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30d3\u30eb\u60c5\u5831\ntrain = train.merge(building, on = 'building_id', how = 'left')\n\n#\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u6c17\u8c61\u30c7\u30fc\u30bf\ntrain = train.merge(weather_train, on = ['site_id', 'timestamp'], how = 'left')\n\n#\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3068\u30d3\u30eb\u60c5\u5831\ntest = test.merge(building, on = 'building_id', how = 'left')\n\n#\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3068\u6c17\u8c61\u30c7\u30fc\u30bf\ntest = test.merge(weather_test, on = ['site_id', 'timestamp'], how = 'left')\n\n#\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3068\u4e88\u6e2c\u30c7\u30fc\u30bf\ntest = test.merge(submission_test, on = 'row_id', how = 'left')\n\n","1eac18ec":"#reduce_mem_usage\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","5589209c":"del weather_train, weather_test,building, submission_test","a46c8e76":"#\u6642\u9593\u306b\u3088\u3063\u3066\u5909\u5316\u304c\u3042\u308b\u305f\u3081\u6642\u9593\u306e\u51e6\u7406\u304c\u5fc5\u8981\ntrain[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\ntrain[\"hour\"] = np.uint8(train[\"timestamp\"].dt.hour)\ntrain[\"day\"] = np.uint8(train[\"timestamp\"].dt.day)\ntrain[\"weekday_name\"] = train[\"timestamp\"].dt.weekday_name \ntrain[\"weekday\"] = np.uint8(train[\"timestamp\"].dt.weekday)\ntrain[\"month\"] = np.uint8(train[\"timestamp\"].dt.month)\n\ntest[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])\ntest[\"hour\"] = np.uint8(test[\"timestamp\"].dt.hour)\ntest[\"day\"] = np.uint8(test[\"timestamp\"].dt.day)\ntest[\"weekday_name\"] = test[\"timestamp\"].dt.weekday_name \ntest[\"weekday\"] = np.uint8(test[\"timestamp\"].dt.weekday)\ntest[\"month\"] = np.uint8(test[\"timestamp\"].dt.month)\n\n","0328201c":"#meter_reading\u3092\u30ed\u30b0\u306b\u5165\u308c\u308b\ntrain['meter_reading_log'] =  np.log1p(train['meter_reading'])\ntrain['square_feet_log'] =  np.log1p(train['square_feet'])\n\n#\u30d3\u30eb\u3054\u3068\u3001meter\u3054\u3068\u3001\u6708\u3054\u3068\u306e\u96c6\u8a08\u3092\u51fa\u3059\ndata = train.groupby(['building_id','meter','month']).sum()\ndata.to_csv(\"building_merter_month_meter_reading_sum.csv\")\n\n#\u30d3\u30eb\u3054\u3068\u3001meter\u3054\u3068\u3001\u6708\u3054\u3068\u306e\u96c6\u8a08\u3092\u51fa\u3059\ndata = train.groupby(['building_id','meter','month']).mean()\ndata.to_csv(\"building_merter_month__meter_reading_mean.csv\")\n\n\ndisplay(data)\n#check_validation_train_test(train,test)","d317d317":"def building_plot(building_id,train, test,comment=\"\" ):\n    \"\"\"\n    building data plot\n    :param building_id:\n    :param train:\n    :param test:\n    :param comment:\n    \"\"\"\n\n    plt.rcParams['figure.figsize'] = (19,11)\n    plt.title(\"building_id_%d  %s\" % (building_id,comment ))\n    \n    ###########################################\n    #\u8a13\u7df4\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092building_id\u3067\u30af\u30a8\u30ea\u3059\u308b\n    ###########################################\n    \n    #\u8a13\u7df4\u30c7\u30fc\u30bf\u5074\n    query_str = ('building_id == %s' % str(building_id) )\n    temp_df_train = train.query(query_str)\n    temp_df_train['meter_reading'] = np.log1p(temp_df_train['meter_reading'])\n    temp_df_train = temp_df_train.reset_index()\n    #\u65e5\u3054\u3068\u306e\u30c7\u30fc\u30bf\u306b\u5909\u63db\u3059\u308b\n    group = temp_df_train.groupby([temp_df_train['timestamp'].dt.year,temp_df_train['timestamp'].dt.month,temp_df_train['timestamp'].dt.day, 'meter' ]).groups\n    #print(group)\n    \n    temp_df_train2 = pd.DataFrame(columns=[\"meter\",\"timestamp\",\"meter_reading\"])\n    \n    cnt = 0\n    for k ,v in group.items():\n        meter = k[3]\n        year =k[0]\n        month =k[1]\n        day =k[2]\n\n        report_data = temp_df_train.iloc[ v,:  ]\n        meter_reading_mean = report_data[\"meter_reading\"].mean()\n        time_day = pd.to_datetime(('%d-%d-%d') % (year, month,day))\n        tmp_se = pd.Series([meter,\n                            time_day,\n                            meter_reading_mean,\n                        ],index=temp_df_train2.columns, name=str(cnt)) \n        cnt +=1\n        temp_df_train2 = temp_df_train2.append(tmp_se)\n   \n\n    #\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u5074\n    temp_df_test = test.query(query_str)\n    temp_df_test['meter_reading'] = np.log1p(temp_df_test['meter_reading'])\n    temp_df_test = temp_df_test.reset_index()\n    group = temp_df_test.groupby([temp_df_test['timestamp'].dt.year,temp_df_test['timestamp'].dt.month,temp_df_test['timestamp'].dt.day, 'meter' ]).groups\n    temp_df_train3 = pd.DataFrame(columns=[\"meter\",\"timestamp\",\"meter_reading\"])\n    \n    cnt = 0\n    for k ,v in group.items():\n        meter = k[3]\n        year =k[0]\n        month =k[1]\n        day =k[2]\n\n        report_data = temp_df_test.iloc[ v,:  ]\n        meter_reading_mean = report_data[\"meter_reading\"].mean()\n        time_day = pd.to_datetime(('%d-%d-%d') % (year, month,day))\n        tmp_se = pd.Series([meter,\n                            time_day,\n                            meter_reading_mean,\n                        ],index=temp_df_train2.columns, name=str(cnt)) \n        cnt +=1\n        temp_df_train3 = temp_df_train3.append(tmp_se)\n\n\n    \n    \n    \n    #\u5883\u754c\u7dda\u90e8\u5206\u306e\u4f5c\u6210\n    testdata = boundary_show_train_test(temp_df_train,temp_df_test)\n    #display(testdata)\n    testdata.to_csv((\"building_id_%s.csv\" % str(building_id)),encoding = 'utf-8-sig')    \n    \n    #\u30b0\u30e9\u30d5\u3092\u66f8\u304f(\u8a13\u7df4\u5074)\n    alpha = 0.5\n    ax = sns.lineplot(data = temp_df_train2.query(\"meter == 0\"), x = 'timestamp', y = 'meter_reading', color = 'r',alpha=alpha,label = \"merter0\")\n    ax = sns.lineplot(data = temp_df_train2.query(\"meter == 1\"), x = 'timestamp', y = 'meter_reading', color = 'g',alpha=alpha,label = \"merter1\")\n    ax = sns.lineplot(data = temp_df_train2.query(\"meter == 2\"), x = 'timestamp', y = 'meter_reading', color = 'b',alpha=alpha,label = \"merter2\")\n    ax = sns.lineplot(data = temp_df_train2.query(\"meter == 3\"), x = 'timestamp', y = 'meter_reading', color = 'c',alpha=alpha,label = \"merter3\")\n      \n    \n    #\u30b0\u30e9\u30d5\u3092\u66f8\u304f(\u30c6\u30b9\u30c8\u5074)\n    ax = sns.lineplot(data = temp_df_train3.query(\"meter == 0\"), x = 'timestamp', y = 'meter_reading', color = 'r',alpha=alpha)\n    ax = sns.lineplot(data = temp_df_train3.query(\"meter == 1\"), x = 'timestamp', y = 'meter_reading', color = 'g',alpha=alpha)\n    ax = sns.lineplot(data = temp_df_train3.query(\"meter == 2\"), x = 'timestamp', y = 'meter_reading', color = 'b',alpha=alpha)\n    ax = sns.lineplot(data = temp_df_train3.query(\"meter == 3\"), x = 'timestamp', y = 'meter_reading', color = 'c',alpha=alpha)\n    \n    plt.ylabel('Log Meter Reading')\n\n    #\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u5883\u754c\u7dda\u3092\u66f8\u304f\n    plt.axvline(x=pd.to_datetime(\"2017-01-01\"), color='b')\n    plt.text(pd.to_datetime(\"2017-01-01\"), ax.get_ylim()[1], \"Prediction Begin\",\n             horizontalalignment='center',\n             verticalalignment='center',\n             color='b',\n             bbox=dict(facecolor='white', alpha=0.9))    \n    \n    plt.show()","0f57da5c":"def make_correlation_matrix_train(train_df):\n\n    #\u30ab\u30e9\u30e0\u306e\u9078\u629e\n    train_df = train_df.reset_index()\n    train_df = train_df.loc[:, [\"meter_reading_log\",'floor_count','year_built',\"air_temperature\",\"cloud_coverage\",\"dew_temperature\",'precip_depth_1_hr','wind_direction','square_feet','sea_level_pressure']]\n    df_corr = train_df.corr()\n    display(df_corr)\n    sns.heatmap(df_corr, vmax=1, vmin=-1, center=0)\n ","b9fbdb66":"#\u8a13\u7df4\u30c7\u30fc\u30bf\u3067\u76f8\u95a2\u56f3\u3092\u4f5c\u308b\n#display(train.head(5))\nmake_correlation_matrix_train(train )","25a4c528":"#building_id:29 meter:1 diff:6.173086  \u3055\u3089\u306bmeter=0\u304c\u58ca\u6ec5\u7684\u306b\u3084\u3070\u3044\n#building_plot(29,train ,test,comment=\"building_id:29 meter:1 diff:6.173086 resample before\")\n\n#research\n#3month_meter_reading 100 ander(site_id = 0 nasi(104nasi))\nbuilding = pd.read_csv('\/kaggle\/input\/3month-meter-reading-zero\/3month_meter_reading_zero.csv')\n\nbuilding = building[\"building_id\"].unique()\n\nfor i in building:\n    building_plot(i,train ,test,comment=\"3month-meter-reading 100 ander\")\n\n\n\n\n","e3b77642":"\"\"\"\n#\u30ea\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3092\u8a66\u3057\u3066\u307f\u308b\n#building_id = 29 meter=0\nbull29 = train[(train['building_id'] ==  29) &  (train['meter'] ==  0)]\ndisplay(bull29)\n#serial_num = pd.RangeIndex(start=1, stop=len(bull29.index) + 1, step=1)\n#bull29['No'] = serial_num\n\nbull29.set_index(\"timestamp\")\ndateTimeIndex = pd.DatetimeIndex(bull29['timestamp'])\nbull29.index = dateTimeIndex\nbull29 = bull29.resample('H').mean()\ndisplay(bull29)\nbull29 = bull29.reset_index()\n#train\u30c7\u30fc\u30bf\u304b\u3089\u30ea\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u524d\u306e\u60c5\u5831\u3092\u524a\u9664\ntrain = train[ ~ ((train[\"building_id\"] == 29)  & (train.meter == 0) ) ]\ntrain.append(bull29)\ntrain.reset_index()\n\"\"\"","b829a0fb":"\"\"\"\ndisplay(train[ train['building_id'] == 29 & (train.meter == 0) ])\nbuilding_plot(29,train ,test,comment=\"building_id:29 meter:1 diff:6.173086 resample after\")\n\"\"\"","2b4ca7cf":"building_plot(1018,train ,test)\nbuilding_plot(1013,train ,test)\nbuilding_plot(740,train ,test)\nbuilding_plot(1022,train ,test)\nbuilding_plot(287,train ,test)\nbuilding_plot(279,train ,test)\nbuilding_plot(252,train ,test)\n\n","d5501eeb":"#\u3053\u3053\u306b\u306f\u3001\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf(\u4e88\u6e2c\u7d50\u679c)\u306b\u304a\u3044\u3066\u6bd4\u8f03\u3057\u305f\u3044building id\u3092\u8a18\u8f09\u3059\u308b\n#Here, enter the building id you want to compare between training data and test data\n\n#\u6700\u3082\uff10\u30e1\u30fc\u30bf\u304c\u591a\u3044\u30d3\u30eb\nbuilding_plot(954,train ,test,comment=\"most 0 meter count\")\n\n#\uff12\u756a\u76ee\u306b\uff10\u30e1\u30fc\u30bf\u304c\u591a\u3044\u30d3\u30eb\nbuilding_plot(799,train ,test,comment=\"2nd 0 meter count\")\n\n#3\u756a\u76ee\u306b\uff10\u30e1\u30fc\u30bf\u304c\u591a\u3044\u30d3\u30eb\nbuilding_plot(1232,train ,test,comment=\"3rd 0 meter count\")\n\n#4\u756a\u76ee\u306b\uff10\u30e1\u30fc\u30bf\u304c\u591a\u3044\u30d3\u30eb\nbuilding_plot(1022,train ,test,comment=\"4th 0 meter count\")\n\n#5\u756a\u76ee\u306b\uff10\u30e1\u30fc\u30bf\u304c\u591a\u3044\u30d3\u30eb\nbuilding_plot(1324,train ,test,comment=\"5th 0 meter count\")\n\n\n#\u5206\u6563\u5024\u304c\u6700\u3082\u4f4e\u3044meter_reading\u300c4.55E-12\u300d\nbuilding_plot(740,train ,test,comment=\"most low dispersion\")\n\n#\u6a19\u6e96\u504f\u5dee\u304c\u4f4e\u3044meter_reading\u300c0.000350764 meter=1\u300d\nbuilding_plot(1018,train ,test,comment=\"meter_reading 0.000350764 meter=1\")\n\n\n#\u5206\u6563\u5024\u304c\uff12\u756a\u3081\u306b\u4f4e\u3044meter_reading\u300c0.007100055\u300d\nbuilding_plot(636,train ,test,comment=\"2nd low dispersion\")\n\n#\u5206\u6563\u5024\u304c3\u756a\u3081\u306b\u4f4e\u3044meter_reading\u300c0.014564584\u300d\nbuilding_plot(637,train ,test,comment=\"3rd low dispersion\")\n\n#\u5206\u6563\u5024\u304c4\u756a\u3081\u306b\u4f4e\u3044meter_reading\u300c0.017347898\u300d\nbuilding_plot(846,train ,test,comment=\"4th low dispersion\")\n\n#\u5206\u6563\u306e\u4e2d\u9593(\u30d3\u30eb\u30921000\u500b\u306a\u3089\u3079\u305f\u3068\u304d\u306e\u4e2d\u9593\u306e\u4f4d\u7f6e)\u300c650.9789\u300d\nbuilding_plot(1082,train ,test,comment=\"middium 1 dispersion\")\n\n#\u5206\u6563\u306e\u4e2d\u9593(\u30d3\u30eb\u30921000\u500b\u306a\u3089\u3079\u305f\u3068\u304d\u306e\u4e2d\u9593\u306e\u4f4d\u7f6e)\u300c654.3975\u300d\nbuilding_plot(733,train ,test,comment=\"middium 2 dispersion\")\n\n\n#\u5206\u6563\u304c\u6700\u3082\u591a\u3044meter_reading\u300c23370951000000\u300d\nbuilding_plot(1099,train ,test,comment=\"most value dispersion\")\n\n#\u5206\u6563\u304c\uff12\u756a\u3081\u306b\u591a\u3044meter_reading\u300c13617740000\u300d\nbuilding_plot(778,train ,test,comment=\"2nd value dispersion\")\n\n\n\n#building_id:60 meter:1 diff:6.149655\nbuilding_plot(60,train ,test,comment=\"building_id:60 meter:1 diff:6.149655\")\n\n#building_id:803 meter:0 diff:7.762360\nbuilding_plot(803,train ,test,comment=\"building_id:803 meter:0 diff:7.762360\")\n\n#building_id:993 meter:0 diff:7.081440\nbuilding_plot(993,train ,test,comment=\"building_id:993 meter:0 diff:7.081440\")\n\n#building_id:993 meter:1 diff:7.570996\nbuilding_plot(993,train ,test,comment=\"building_id:993 meter:1 diff:7.570996\")\n\n#12\/31\u65e5\u304c\u30a8\u30cd\u30eb\u30ae\u30fc\u4f7f\u7528\u91cf\uff10\u306e\u30d3\u30eb\nbuilding_plot(28,train ,test,comment=\"12\/31 meter_reading is 0\")\nbuilding_plot(43,train ,test,comment=\"12\/31 meter_reading is 0\")\nbuilding_plot(103,train ,test,comment=\"12\/31 meter_reading is 0\")\nbuilding_plot(191,train ,test,comment=\"12\/31 meter_reading is 0\")\nbuilding_plot(263,train ,test,comment=\"12\/31 meter_reading is 0\")\n\n","8f384a02":"#all diff to csv\n","0a0d63c3":"def boundary_validation_train_test(train,test):\n    \"\"\"\n    boundary_validation_train_test\n    :param train:\n    :param test:\n    :return diff value\n    \"\"\"    \n\n    #\uff13\u65e5\u5206\u53d6\u5f97 \u8a13\u7df4\u30c7\u30fc\u30bf\n    datas = train.tail(72)\n    if len(datas) < 1:\n        return -1\n    datas[\"meter_reading\"] = np.log1p(datas[\"meter_reading\"])\n    \n    train_mean = datas['meter_reading'].mean()\n    \n    \n    #\uff13\u65e5\u5206\u53d6\u5f97 \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\n    datas = test.head(72)\n    if len(datas) < 1:\n        return -1\n    datas[\"meter_reading\"] = np.log1p(datas[\"meter_reading\"])\n    test_mean = datas['meter_reading'].mean()   \n    \n    \n    \n    #datas = datas.append(test.head(72))\n    #datas = datas.reset_index()\n    \n    #if(len(datas) < 74 ):\n    #    return -1\n    \n    #meter_reading diff check \n    #np.log1p(temp_df_train['meter_reading'])\n    #display(datas)\n    #v_train = np.log1p(datas.loc[0][\"meter_reading\"])\n    #v_test = np.log1p(datas.loc[1][\"meter_reading\"])\n    \n    \n    return abs(train_mean - test_mean)\n","1834b996":"def check_validation_train_test(train,test):\n    #building id\u6bce\u306b\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u4e88\u6e2c\u30c7\u30fc\u30bf\u306e\u5883\u754c\u3067meter_reading\u304c\u8457\u3057\u304f\u305a\u308c\u3066\u3044\u308b\u3068\u3053\u308d\u3092\u691c\u51fa\u3059\u308b\n\n    #\u8a13\u7df4\u30c7\u30fc\u30bf\u6bce\u306e\u7e70\u308a\u8fd4\u3057\n    building_ids = train['building_id'].unique()\n    building_ids.sort()\n\n    #boundary = 2.0 #\u3057\u304d\u3044\u5024\u306e\u8a2d\u5b9a\n\n    list_df = pd.DataFrame(\n        columns=[\n            'building_id',\n            'meter',\n            'diff',\n            'count',\n            'train_mean',\n            'train_std',\n            'train_min',\n            'train_max'\n            \n            ])    \n    \n    error_building_ids = []\n    i = 0\n    for building_id in building_ids:\n        #print(building_id)\n        \n        #build id\u3067\u62bd\u51fa\n        query_str = ('building_id == %s' % str(building_id) )\n        temp_df_build_train = train.query(query_str)\n        temp_df_build_test = test.query(query_str)\n        \n        for meter in range(0,4):\n            #print(\"building_id\" + str(building_id) + \"meter:\" + str(meter))\n            query_str = ('meter == %s' % str(meter) )\n            temp_df_train = temp_df_build_train.query(query_str)\n            temp_df_test = temp_df_build_test.query(query_str)\n            diff = boundary_validation_train_test(temp_df_train,temp_df_test)\n            \n            if(diff == -1):\n                continue\n\n            temp_df_train[\"meter_reading\"] = np.log1p(temp_df_train[\"meter_reading\"])\n            tmp_se = pd.Series([building_id,\n                    meter,\n                    diff,\n                    temp_df_train.describe().at['count', 'meter_reading'],\n                    temp_df_train.describe().at['mean', 'meter_reading'],\n                    temp_df_train.describe().at['std', 'meter_reading'],\n                    temp_df_train.describe().at['min', 'meter_reading'],\n                    temp_df_train.describe().at['max', 'meter_reading']\n                                \n                    ],index=list_df.columns, name=str(i))\n            \n            list_df = list_df.append(tmp_se)\n            #display(list_df)\n            i += 1\n                \n            #if(diff > boundary):\n                #\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u5dee\u304c\u958b\u3044\u3066\u3044\u308b\u3068\u5224\u5b9a\n            #print(\"building_id:%d meter:%d diff:%f\" %(building_id,meter ,diff))\n            #error_building_ids.append(building_id)\n            \n            \n            \n    #boundary\n    #list(set(error_building_ids))\n    list_df.to_csv(\"check_validation_train_test.csv\",encoding = 'utf-8-sig')    \n    #\u3053\u306e\u3042\u3068\u306fbuild is\u306e\u63cf\u753b\u3059\u308b\u51e6\u7406","d81661c6":"#building id\u6bce\u306b\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u4e88\u6e2c\u30c7\u30fc\u30bf\u306e\u5883\u754c\u3067meter_reading\u304c\u8457\u3057\u304f\u305a\u308c\u3066\u3044\u308b\u3068\u3053\u308d\u3092\u691c\u51fa\u3059\u308b\ncheck_validation_train_test(train,test)","d5704d80":"# After prediction, draw on the graph and verify\nAs a precondition, there must be a prediction result in ashrae-great-energy. <br>\n-X axis is timestamp <br>\n-For the Y axis, Log function is applied to \"Meter Reading\" \n\n\n# \u4e88\u6e2c\u5f8c\u3001\u30b0\u30e9\u30d5\u306b\u63cf\u753b\u3057\u3066\u691c\u8a3c\u3059\u308b\n\u524d\u63d0\u6761\u4ef6\u3068\u3057\u3066\u3001ashrae-great-energy\u306b\u3066\u4e88\u6e2c\u7d50\u679c\u304c\u5b58\u5728\u3057\u3066\u3044\u308b\u3053\u3068\u3002<br>\n\u30fbX\u8ef8\u306ftimestamp<br>\n\u30fbY\u8ef8\u306f\u3001\u300cMeter Reading\u300d\u306bLog\u95a2\u6570\u3092\u9069\u7528\u3057\u305f\u3082\u306e\u3068\u3059\u308b<br>\n\n"}}