{"cell_type":{"5578ee1f":"code","323c36aa":"code","c9c842a7":"code","f1784e70":"code","b49afa30":"code","37476732":"code","4a87d3f3":"code","abfcf0f7":"code","85cb6b6e":"code","0d0bcc35":"code","e7c34d25":"code","2f21675a":"code","b5ec10d8":"code","1ae6e298":"code","3ab3c356":"code","81f194d6":"code","c6250d97":"code","ed2fc996":"code","e236960a":"code","317ea9b2":"markdown","b7a2f6e3":"markdown","8f79b67b":"markdown","d970246e":"markdown"},"source":{"5578ee1f":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport math\nimport collections\nfrom collections import Counter\n\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re","323c36aa":"data = pd.read_csv('..\/input\/train.csv')","c9c842a7":"data.dropna()\nprint(data.head(15))","f1784e70":"data.describe()","b49afa30":"dup_check = data['is_duplicate'].value_counts()\nplt.bar(dup_check.index, dup_check.values)\nplt.ylabel('Number of Queries')\nplt.xlabel('Is Duplicate')\nplt.title('Data Distribution', fontsize = 18)\nplt.show()","37476732":"print(\"Above Graph Features :  [Is Not Duplicate | Is Duplicate]\\n\")\nprint(\"Above Graph Indices  : \", dup_check.index)\nprint(\"\\nAbove Graph Values   : \", dup_check.values)","4a87d3f3":"print(\"Above Graph %age Values :\")\nprint( dup_check \/ dup_check.sum())","abfcf0f7":"questions = data[['id', 'question1', 'question2', 'is_duplicate']]\nword_count = []\nfor row in questions.itertuples():\n    q1 = len(str(row[2]).split())\n    q2 = len(str(row[3]).split())\n    word_count.append(q1 + q2)  ","85cb6b6e":"len(word_count)","0d0bcc35":"word_count = pd.DataFrame(data = word_count, columns = ['word_count'])","e7c34d25":"count = word_count['word_count'].value_counts()\nplt.figure(figsize=(12,6))\nplt.bar(count.index, count.values)\nplt.ylabel('Number of occurrence of Queries with x words')\nplt.xlabel('Number of Words')\nplt.title('Word Distribution in Queries', fontsize = 18)\nplt.xlim(0, 100)\nplt.show()","2f21675a":"ps = PorterStemmer()\n\ndef tokenize(text):\n    text = re.sub('[^a-zA-Z]+', ' ', text)\n    text = text.lower()\n    text = text.split()\n    text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\n    text = ' '.join(text)\n    words = word_tokenize(text)\n    return Counter(words)","b5ec10d8":"def get_cosine(vec1, vec2):\n    intersection = set(vec1.keys()) & set(vec2.keys())\n    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n    \n    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n\n    if not denominator:\n        return 0.0\n    else:\n        return float(numerator) \/ float(denominator)","1ae6e298":"def DistJaccard(str1, str2):\n    str1 = set(str1.split())\n    str2 = set(str2.split())\n    return float(len(str1 & str2)) \/ len(str1 | str2)    \n","3ab3c356":"queries = data[['id', 'question1', 'question2', 'is_duplicate']]\ncosine_list = []\njaccard_list = []\ni = 1\nfor row in questions.itertuples():\n    text1 = str(row[2])\n    text2 = str(row[3])\n    vector1 = tokenize(text1)\n    vector2 = tokenize(text2) \n    cosine = get_cosine(vector1, vector2)\n    jaccard = DistJaccard(text1, text2)\n    cosine_list.append(cosine)    \n    jaccard_list.append(jaccard)\n        \n    i+=1\n    if (i == 1000):\n        break    ","81f194d6":"c = data[:999]","c6250d97":"c.head()","ed2fc996":"c.insert(6, \"Cosine Score\", cosine_list) \nc.insert(7, \"Jaccard Score\", jaccard_list) ","e236960a":"c.head(25)","317ea9b2":"**Data Distribution**","b7a2f6e3":"**Jaccard Similarity**","8f79b67b":"***Results***","d970246e":"**Cosine Similarity**"}}