{"cell_type":{"cdb23491":"code","0c5b0fcd":"code","75b38eca":"code","ae76047b":"code","c3a5c472":"code","f133329a":"code","9aca187d":"code","bf8250e5":"code","cacd2d28":"code","011bfe95":"code","7ebd1c88":"code","8c5f102a":"code","a98b33fe":"code","3008a1a6":"code","69b576bf":"code","2c3a192c":"code","9fdbd3ac":"markdown","bf28480a":"markdown","4e392147":"markdown","ac1b0199":"markdown","292dcdcc":"markdown","eba872cd":"markdown","af4a4dd1":"markdown"},"source":{"cdb23491":"# from IPython.display import HTML\n\n# HTML('''<script>\n# code_show=true; \n# function code_toggle() {\n#  if (code_show){\n#  $('div.input').hide();\n#  } else {\n#  $('div.input').show();\n#  }\n#  code_show = !code_show\n# } \n# $( document ).ready(code_toggle);\n# <\/script>\n# The raw code for this IPython notebook is by default hidden for easier reading.\n# To toggle on\/off the raw code, click <a href=\"javascript:code_toggle()\">here<\/a>.''')","0c5b0fcd":"import time\nnotebookstart= time.time()\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gc\n\n# Modeling\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\n# Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nDebug = False\n\n# Read data\nNROWS = 6000000\nif Debug is True: NROWS = 5000\ntrain = pd.read_csv('..\/input\/train.csv', nrows = NROWS, index_col = \"key\")\ntrain = train.dropna()\ntest_df = pd.read_csv('..\/input\/test.csv', index_col = \"key\")\ntestdex = test_df.index","75b38eca":"def prepare_distance_features(df):\n    # Distance is expected to have an impact on the fare\n    df['longitude_distance'] = abs(df['pickup_longitude'] - df['dropoff_longitude'])\n    df['latitude_distance'] = abs(df['pickup_latitude'] - df['dropoff_latitude'])\n\n    # Straight distance\n    df['distance_travelled'] = (df['longitude_distance'] ** 2 + df['latitude_distance'] ** 2) ** .5\n    df['distance_travelled_sin'] = np.sin((df['longitude_distance'] ** 2 * df['latitude_distance'] ** 2) ** .5)\n    df['distance_travelled_cos'] = np.cos((df['longitude_distance'] ** 2 * df['latitude_distance'] ** 2) ** .5)\n    df['distance_travelled_sin_sqrd'] = np.sin((df['longitude_distance'] ** 2 * df['latitude_distance'] ** 2) ** .5) ** 2\n    df['distance_travelled_cos_sqrd'] = np.cos((df['longitude_distance'] ** 2 * df['latitude_distance'] ** 2) ** .5) ** 2\n\n    # Haversine formula for distance\n    # Haversine formula:\ta = sin\u00b2(\u0394\u03c6\/2) + cos \u03c61 \u22c5 cos \u03c62 \u22c5 sin\u00b2(\u0394\u03bb\/2)\n    R = 6371e3 # Metres\n    phi1 = np.radians(df['pickup_latitude'])\n    phi2 = np.radians(df['dropoff_latitude'])\n    phi_chg = np.radians(df['pickup_latitude'] - df['dropoff_latitude'])\n    delta_chg = np.radians(df['pickup_longitude'] - df['dropoff_longitude'])\n    a = np.sin(phi_chg \/ 2) + np.cos(phi1) * np.cos(phi2) * np.sin(delta_chg \/ 2)\n    c = 2 * np.arctan2(a ** .5, (1-a) ** .5)\n    d = R * c\n    df['haversine'] = d\n\n    # Bearing\n    # Formula:\t\u03b8 = atan2( sin \u0394\u03bb \u22c5 cos \u03c62 , cos \u03c61 \u22c5 sin \u03c62 \u2212 sin \u03c61 \u22c5 cos \u03c62 \u22c5 cos \u0394\u03bb )\n    y = np.sin(delta_chg * np.cos(phi2))\n    x = np.cos(phi1) * np.sin(phi2) - np.sin(phi1) * np.cos(phi2) * np.cos(delta_chg)\n    df['bearing'] = np.arctan2(y, x)\n\n    return df\n\ndef prepare_time_features(df):\n    df['pickup_datetime'] = df['pickup_datetime'].str.replace(\" UTC\", \"\")\n    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n    df['hour_of_day'] = df.pickup_datetime.dt.hour\n    df['week'] = df.pickup_datetime.dt.week\n    df['month'] = df.pickup_datetime.dt.month\n    df[\"year\"] = df.pickup_datetime.dt.year\n    df['day_of_year'] = df.pickup_datetime.dt.dayofyear\n    df['week_of_year'] = df.pickup_datetime.dt.weekofyear\n    df[\"weekday\"] = df.pickup_datetime.dt.weekday\n    df[\"quarter\"] = df.pickup_datetime.dt.quarter\n    df[\"day_of_month\"] = df.pickup_datetime.dt.day\n    \n    return df\n\n# Airport Features - By Albert van Breenmen\n# https:\/\/www.kaggle.com\/breemen\/nyc-taxi-fare-data-exploration\ndef dist(pickup_lat, pickup_long, dropoff_lat, dropoff_long):  \n    distance = np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n    \n    return distance\n\ndef airport_feats(train,test_df):\n    for data in [train,test_df]:\n        nyc = (-74.0063889, 40.7141667)\n        jfk = (-73.7822222222, 40.6441666667)\n        ewr = (-74.175, 40.69)\n        lgr = (-73.87, 40.77)\n        data['distance_to_center'] = dist(nyc[1], nyc[0],\n                                          data['pickup_latitude'], data['pickup_longitude'])\n        data['pickup_distance_to_jfk'] = dist(jfk[1], jfk[0],\n                                             data['pickup_latitude'], data['pickup_longitude'])\n        data['dropoff_distance_to_jfk'] = dist(jfk[1], jfk[0],\n                                               data['dropoff_latitude'], data['dropoff_longitude'])\n        data['pickup_distance_to_ewr'] = dist(ewr[1], ewr[0], \n                                              data['pickup_latitude'], data['pickup_longitude'])\n        data['dropoff_distance_to_ewr'] = dist(ewr[1], ewr[0],\n                                               data['dropoff_latitude'], data['dropoff_longitude'])\n        data['pickup_distance_to_lgr'] = dist(lgr[1], lgr[0],\n                                              data['pickup_latitude'], data['pickup_longitude'])\n        data['dropoff_distance_to_lgr'] = dist(lgr[1], lgr[0],\n                                               data['dropoff_latitude'], data['dropoff_longitude'])\n    return train, test_df\n\n# Percentile\ndef percentile(n):\n    def percentile_(x):\n        return np.percentile(x, n)\n    percentile_.__name__ = 'percentile_%s' % n\n    return percentile_\n\n# Build ime Aggregate Features\ndef time_agg(train, test_df, vars_to_agg, vars_be_agg):\n    for var in vars_to_agg:\n        agg = train.groupby(var)[vars_be_agg].agg([\"sum\",\"mean\",\"std\",\"skew\",percentile(80),percentile(20)])\n        if isinstance(var, list):\n            agg.columns = pd.Index([\"fare_by_\" + \"_\".join(var) + \"_\" + str(e) for e in agg.columns.tolist()])\n        else:\n            agg.columns = pd.Index([\"fare_by_\" + var + \"_\" + str(e) for e in agg.columns.tolist()]) \n        train = pd.merge(train,agg, on=var, how= \"left\")\n        test_df = pd.merge(test_df,agg, on=var, how= \"left\")\n    \n    return train, test_df\n\n# Clean dataset from https:\/\/www.kaggle.com\/gunbl4d3\/xgboost-ing-taxi-fares\ndef clean_df(df):\n    return df[(df.fare_amount > 0) & \n            (df.pickup_longitude > -80) & (df.pickup_longitude < -70) &\n            (df.pickup_latitude > 35) & (df.pickup_latitude < 45) &\n            (df.dropoff_longitude > -80) & (df.dropoff_longitude < -70) &\n            (df.dropoff_latitude > 35) & (df.dropoff_latitude < 45)]\nprint(\"Cleaning Functions Defined..\")","ae76047b":"print(\"Percent of Training Set with Zero and Below Fair: \", round(((train.loc[train[\"fare_amount\"] <= 0, \"fare_amount\"].shape[0]\/train.shape[0]) * 100),5))\nprint(\"Percent of Training Set 200 and Above Fair: \", round((train.loc[train[\"fare_amount\"] >= 200, \"fare_amount\"].shape[0]\/train.shape[0]) * 100,5))\ntrain = train.loc[(train[\"fare_amount\"] > 0) & (train[\"fare_amount\"] <= 200),:]\nprint(\"\\nPercent of Training Set with Zero and Below Passenger Count: \", round((train.loc[train[\"passenger_count\"] <= 0, \"passenger_count\"].shape[0]\/train.shape[0]) * 100,5))\nprint(\"Percent of Training Set with Nine and Above Passenger Count: \", round((train.loc[train[\"passenger_count\"] >= 9, \"passenger_count\"].shape[0]\/train.shape[0]) * 100,5))\ntrain = train.loc[(train[\"passenger_count\"] > 0) & (train[\"passenger_count\"] <= 9),:]\n\n# Clean Training Set\ntrain = clean_df(train)\n\n# Distance Features\ntrain = prepare_distance_features(train)\ntest_df = prepare_distance_features(test_df)\ntrain,test_df = airport_feats(train,test_df)\n\n# Time Features\ntrain = prepare_time_features(train)\ntest_df = prepare_time_features(test_df)\n\n# Ratios\ntrain[\"fare_to_dist_ratio\"] = train[\"fare_amount\"] \/ ( train[\"distance_travelled\"]+0.0001)\ntrain[\"fare_npassenger_to_dist_ratio\"] = (train[\"fare_amount\"] \/ train[\"passenger_count\"]) \/( train[\"distance_travelled\"]+0.0001)\n\n# Time Aggregate Features\ntrain, test_df = time_agg(train, test_df,\n                          vars_to_agg  = [\"passenger_count\", \"weekday\", \"quarter\", \"month\", \"year\", \"hour_of_day\",\n                                          [\"weekday\", \"month\", \"year\"], [\"hour_of_day\", \"weekday\", \"month\", \"year\"]],\n                          vars_be_agg = \"fare_amount\")","c3a5c472":"train_time_start = train.pickup_datetime.min()\ntrain_time_end = train.pickup_datetime.max()\nprint(\"Train Time Starts: {}, Ends {}\".format(train_time_start,train_time_end))\ntest_time_start = test_df.pickup_datetime.min()\ntest_time_end = test_df.pickup_datetime.max()\nprint(\"Test Time Starts: {}, Ends {}\".format(test_time_start,test_time_end))","f133329a":"f, ax = plt.subplots(1,2,figsize = [10,5])\nsns.countplot(train[\"passenger_count\"], ax=ax[0])\nsns.countplot(test_df[\"passenger_count\"], ax=ax[1])\nax[0].set_title(\"Train Set - Passenger Count\")\nax[1].set_title(\"Test Set - Passenger Count\")\nplt.show()","9aca187d":"f, ax = plt.subplots(figsize=[6,5])\nsns.kdeplot(train[\"fare_amount\"], ax=ax)\nax.set_title(\"Fare Distribution\")\nplt.show()","bf8250e5":"def time_slicer(df, timeframes, value, color=\"purple\"):\n    \"\"\"\n    Function to count observation occurrence through different lenses of time.\n    \"\"\"\n    f, ax = plt.subplots(len(timeframes), figsize = [12,12])\n    for i,x in enumerate(timeframes):\n        df.loc[:,[x,value]].groupby([x]).mean().plot(ax=ax[i],color=color)\n        ax[i].set_ylabel(value.replace(\"_\", \" \").title())\n        ax[i].set_title(\"{} by {}\".format(value.replace(\"_\", \" \").title(), x.replace(\"_\", \" \").title()))\n        ax[i].set_xlabel(\"\")\n    ax[len(timeframes)-1].set_xlabel(\"Time Frame\")\n    plt.tight_layout(pad=0)","cacd2d28":"time_slicer(df=train, timeframes=['year',\"day_of_year\", \"month\", \"day_of_month\", \"weekday\", \"hour_of_day\"], value = \"fare_amount\", color=\"blue\")","011bfe95":"time_slicer(df=train, timeframes=['year',\"day_of_year\", \"month\", \"day_of_month\", \"weekday\", \"hour_of_day\"], value = \"distance_travelled\", color = \"green\")","7ebd1c88":"time_slicer(df=train, timeframes=['year',\"day_of_year\", \"month\", \"day_of_month\", \"weekday\", \"hour_of_day\"], value = \"fare_to_dist_ratio\", color = \"red\")","8c5f102a":"time_slicer(df=train, timeframes=['year',\"day_of_year\", \"month\", \"day_of_month\", \"weekday\", \"hour_of_day\"], value = \"fare_npassenger_to_dist_ratio\", color = \"orange\")","a98b33fe":"# Keep Relevant Variables..\ny = train.fare_amount.copy()\ntest_df.drop(\"pickup_datetime\", axis = 1, inplace=True)\ntrain = train[test_df.columns]\nprint(\"Does Train feature equal test feature?: \", all(train.columns == test_df.columns))\ntrainshape = train.shape\ntestshape = test_df.shape\n\n# print(\"\\nTrain DF..\")\n# train = reduce_mem_usage(train)\n# print(\"\\nTest DF..\")\n# test_df = reduce_mem_usage(test_df)\n\n# LGBM Dataset Formating\ndtrain = lgb.Dataset(train, label=y, free_raw_data=False)","3008a1a6":"print(\"Light Gradient Boosting Regressor: \")\nlgbm_params =  {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'regression',\n    'metric': 'rmse'\n                }\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=1)\nfold_preds = np.zeros(testshape[0])\noof_preds = np.zeros(trainshape[0])\ndtrain.construct()\n\n# Fit 5 Folds\nmodelstart = time.time()\nfor trn_idx, val_idx in folds.split(train):\n    clf = lgb.train(\n        params=lgbm_params,\n        train_set=dtrain.subset(trn_idx),\n        valid_sets=dtrain.subset(val_idx),\n        num_boost_round=3500, \n        early_stopping_rounds=125,\n        verbose_eval=500\n    )\n    oof_preds[val_idx] = clf.predict(dtrain.data.iloc[val_idx])\n    fold_preds += clf.predict(test_df) \/ folds.n_splits\n    print(mean_squared_error(y.iloc[val_idx], oof_preds[val_idx]) ** .5)\nprint(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)\/60))","69b576bf":"lgsub = pd.DataFrame(fold_preds,columns=[\"fare_amount\"],index=testdex)\nlgsub.to_csv(\"lgsub.csv\",index=True,header=True)\n\nprint(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)\/60))\nlgsub.head()","2c3a192c":"## Big shoutout to those who build many of my features.","9fdbd3ac":"**Understanding Time Range:**","bf28480a":"## Visualization","4e392147":"**Cleaning and Feature Engineering:** <br>\nThere are a few anomalies in the fair and passenger_count features which are absent from the test set. Therefore, I shall remove them.","ac1b0199":"## Taxi Rides Time Analysis\n_By Nick Brooks, July 2018_","292dcdcc":"**Run All Pre-Processing and Cleaning:**","eba872cd":"**Out of Fold Prediction Ensemble:**","af4a4dd1":"## Modeling with LGBM"}}