{"cell_type":{"5de8abeb":"code","d3c3e28f":"code","562688d5":"code","85e761bc":"code","a0105368":"code","bfe80f1e":"code","332632cd":"code","460041ac":"code","fb686885":"markdown","22715219":"markdown","d89d78de":"markdown","6f49349d":"markdown","2d1d7a32":"markdown","7fc0edfd":"markdown","7bdca3ed":"markdown","506ea88b":"markdown","6a1bf1ed":"markdown","2f0ba385":"markdown","8389cb5f":"markdown","734d078f":"markdown","f5e4ff14":"markdown","a7538b77":"markdown","cf457266":"markdown","62a0064f":"markdown","c8d93d05":"markdown","67df0197":"markdown","a5166744":"markdown","0027c9e8":"markdown","3bd3a644":"markdown"},"source":{"5de8abeb":"import tensorflow.keras as keras\nfrom tensorflow.keras import Input, layers\n\ninput_tensor = Input(shape = (32,)) # a tensor\ndense = layers.Dense(32, activation = 'relu') # a layer as a function\noutput_tensor = dense(input_tensor) # a layer is called on a tensor and returns a tensor","d3c3e28f":"def f(x):\n    def g(y):\n        return x * y\n    return g\n\nfunc = f(7)\nprint(f(7)(2), func(2))","562688d5":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras import layers, Input\n\nseq_model = Sequential()\nseq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\nseq_model.add(layers.Dense(32, activation='relu'))\nseq_model.add(layers.Dense(10, activation='softmax'))","85e761bc":"input_tensor = Input(shape=(64,))\nx = layers.Dense(32, activation='relu')(input_tensor)\nx = layers.Dense(32, activation='relu')(x)\noutput_tensor = layers.Dense(1)(x)\n\nmodel = Model(input_tensor, output_tensor)","a0105368":"model.summary()","bfe80f1e":"model.compile(optimizer='rmsprop', loss='mse', metrics = ['mae'])\n\nimport numpy as np\nx_train = np.random.random((50000, 64))\nx_test = np.random.random((10000, 64))\n\ny_train = np.sum(x_train, axis = 1)\ny_test = np.sum(x_test, axis = 1)\n\nmodel.fit(x_train, y_train, epochs=100, batch_size=128)","332632cd":"test_mse, test_mae  = model.evaluate(x_test, y_test)","460041ac":"np.average(abs(y_test - 32))","fb686885":"![DLWP-fig-7-3.png](attachment:DLWP-fig-7-3.png)","22715219":"###### Multi-input tasks\n\nPredict the price of second-hand clothing from: metadata (item brand, age...), text description and a picture\n\nA single output (price) but several inputs\n\nInput data is varied - numerical data, text and image","d89d78de":"![DLWP-fig-7-2.png](attachment:DLWP-fig-7-2.png)","6f49349d":"Metadata modeled by a dense module\n\nText data modeled by an RNN\n\nImage data modelled by a convnet","2d1d7a32":"Here is a minimal model, written in both styles:","7fc0edfd":"Python functional programming example:","7bdca3ed":"Multi-input\/output and graph architectures aren't possible with sequential `tensorflow.keras` layers\n\nThe functional API enables arbitrary acyclic architectures ","506ea88b":"Inception architecture\n\n![DLWP-fig-7-4.png](attachment:DLWP-fig-7-4.png)","6a1bf1ed":"# My university of london lecture on advanced Deep learning practises","2f0ba385":"Compiling, training and evaluating proceed as before","8389cb5f":"##### Acyclic graphs\n\nMany state-of -the-art neural architectures are acyclic graphs\n\nInception and residual architectures where input splits into several parallel branches before merging ","734d078f":"----","f5e4ff14":"But the two tasks share information - either might help the other - so a text processing layer could feed a genre classifier and a date regressor","a7538b77":"Has our model beaten a common-sense baseline?\n\nThe average of 64 random numbers between 0 and 1 is about 32:","cf457266":"Let's see if we can train an ANN to add numbers","62a0064f":"###### Multi-output tasks\n\nFor example, a text might be classified by genre and by year of publication\n\nThe former is a multiclass task, the latter is a regression problem","c8d93d05":"----","67df0197":"## 7.110 The functional API\n\nLayers are functions, mapping tensors to tensors","a5166744":"## 7.100 Beyond the Sequential model\n\nSo far we have seen models with a stacked chain of layers\n\nA single input - a chain of in-out processing layers, and a single output\n\nVery common but too inflexible for many interesting tasks ","0027c9e8":"The models could be run independently and the outputs averaged but there could be redundancy between the models \n\nBetter to merge the three models in a multi-input graph architecture\n\nThe joint model is trained and redundancy is minimised","3bd3a644":"Resdual connection\n\n![DLWP-fig-7-5.png](attachment:DLWP-fig-7-5.png)"}}