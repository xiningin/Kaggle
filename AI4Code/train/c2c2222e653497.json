{"cell_type":{"f659bc87":"code","d40f519b":"code","cb338715":"code","e74b7770":"code","59cc18f5":"code","0c7d06ad":"code","de26e0a8":"code","637d5b60":"code","c26aa2a2":"code","accf39d4":"code","0bd6ab71":"markdown","63988bb9":"markdown","4881b6b1":"markdown","0c0d8bd2":"markdown","6458f1c1":"markdown","81e522af":"markdown","74710160":"markdown","9713de39":"markdown"},"source":{"f659bc87":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\n\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam,SGD\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# from imutils import paths\nimport numpy as np\nimport argparse\nimport cv2\nimport os\nimport collections\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nimport math\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n%matplotlib inline\nfrom xgboost import XGBClassifier\n\n# Other Libraries\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndf = pd.read_csv('..\/input\/yelp-reviews-dataset\/yelp.csv')\ndf.head()","d40f519b":"x = df['text'].values\ndf['stars']=df['stars'].replace(to_replace=[1,2],value=0)\ndf['stars']=df['stars'].replace(to_replace=[4,5],value=2)\ndf['stars']=df['stars'].replace(to_replace=[3],value=1)\ny = df['stars'].values\nprint(x)\nprint(y)\n","cb338715":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=101)","e74b7770":"from sklearn.feature_extraction.text import CountVectorizer\nvec = CountVectorizer()\nvec.fit(x_train)\nx_train=vec.transform(x_train)\nx_test=vec.transform(x_test)\nx_train.size","59cc18f5":"train_x,test_x=x_train,x_test\n\npca = TruncatedSVD(n_components=3)\npca.fit(x_train)\nx_train = pca.transform(x_train)\npca = TruncatedSVD(n_components=3)\npca.fit(x_test)\nx_test = pca.transform(x_test)","0c7d06ad":"\nmodel = Sequential()\nmodel.add(Dense(36, input_dim=x_train.shape[1], activation='sigmoid'))\nmodel.add(Dropout(0.3, noise_shape=None, seed=None))\nmodel.add(Dense(216, activation = \"sigmoid\"))\nmodel.add(Dropout(0.2, noise_shape=None, seed=None))\nmodel.add(Dense(36, activation = \"sigmoid\"))\nmodel.add(Dense(4, activation='sigmoid'))\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(lr=0.1),metrics=['accuracy'])\n\nresults = model.fit(\n x_train, y_train,\n epochs= 100,\n batch_size = 500,\n validation_data = (x_test, y_test)\n)","de26e0a8":"\n# without pca\nmodel = Sequential()\nmodel.add(Dense(36, input_dim=train_x.shape[1], activation='sigmoid'))\nmodel.add(Dropout(0.3, noise_shape=None, seed=None))\nmodel.add(Dense(216, activation = \"sigmoid\"))\nmodel.add(Dropout(0.2, noise_shape=None, seed=None))\nmodel.add(Dense(36, activation = \"sigmoid\"))\nmodel.add(Dense(4, activation='softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(lr=0.01),metrics=['accuracy'])\n\nresults = model.fit(\n train_x, y_train,\n epochs= 100,\n batch_size = 500,\n validation_data = (test_x, y_test)\n)","637d5b60":"predictions=model.predict_classes(test_x)","c26aa2a2":"res=pd.DataFrame({'Rating':predictions})\nres","accf39d4":"res.to_csv('Predictions.csv',index=False)","0bd6ab71":"# inference without pca","63988bb9":"**though inference without PCA gives better accuracy but the model is overfitting**","4881b6b1":"# inference with pca","0c0d8bd2":"# data preprocessing\n# convert the sentiments to vectors ","6458f1c1":"# applying pca (truncatedSVD)\n\nPrincipal Component Analysis (PCA) is a method that uses simple matrix operations from linear algebra and statistics to calculate a projection of the original data into the same number or fewer dimensions.\n\nWe will use TruncatedSVD","81e522af":"# Results  aka predicted values","74710160":"# Now we will convert target variables or we will shorten the number of classes \nnamely:\n\n0(low) class represents rating from 1-2\n\n1(medium) class represents rating from 3\n\n2(high) class represents rating from 4-5\n","9713de39":"# split the dataset"}}