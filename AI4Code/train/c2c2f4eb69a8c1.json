{"cell_type":{"fe791cc5":"code","ddbb4ab5":"code","6507e039":"code","6e1837ae":"code","6046e6f5":"code","a710027c":"code","70839f5b":"code","65817bd9":"code","3a1e5826":"code","87175cdc":"code","c5af1645":"code","f99c19ad":"code","d9cd0617":"code","842bff24":"code","aa436363":"code","ef33b074":"code","c728b115":"code","f4156f2b":"code","ededd0a9":"code","fffad703":"code","2a4edfb7":"code","ca8b087b":"code","41a29045":"code","8c095b4d":"code","6a1c96e5":"code","611bec10":"code","cd98fb88":"code","af2bd13a":"code","c198da2c":"code","03c07d16":"code","5ce5ef18":"code","cf7251a2":"code","65c75111":"code","6244351b":"code","5fae30b1":"code","5917a7eb":"code","767f40fb":"code","b16d9e92":"markdown","f0cbe09f":"markdown","3178117d":"markdown","f112101c":"markdown","b920a18e":"markdown","2aba8c78":"markdown","445bbf26":"markdown","c5a7d0f8":"markdown","80a001f7":"markdown","716503e7":"markdown","e5c6ffe6":"markdown","b451422b":"markdown","801c7eba":"markdown","8b1124fd":"markdown","df18f104":"markdown","03f7def9":"markdown","85df062b":"markdown","4f7e9f08":"markdown","c44eecd2":"markdown","67bdce3f":"markdown","dfd99d7c":"markdown","2a220685":"markdown","fbdf0df4":"markdown","e7899a1a":"markdown","5afc1a10":"markdown","3dbf8392":"markdown","5b485dc6":"markdown","6fc847b7":"markdown","52952264":"markdown","d8306c03":"markdown","cf4231ef":"markdown","23309142":"markdown","8531ef91":"markdown","8ade9e60":"markdown","eeb99854":"markdown","90e42036":"markdown","2ff2af2d":"markdown","2f3d381a":"markdown"},"source":{"fe791cc5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/brasilian-houses-to-rent\/houses_to_rent_v2.csv'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ddbb4ab5":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n#metrics\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# models\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV","6507e039":"def categorize(col):\n    numerical,category=[],[]\n    for i in col:\n        if data[i].dtype ==object:\n            category.append(i)\n        else:\n            numerical.append(i)\n    print(\"The numerical features {}:\".format(numerical))\n    print(\"The categorical features {}:\".format(category))\n    return category,numerical","6e1837ae":"def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n    width = 12\n    height = 10\n    plt.figure(figsize=(width, height))\n\n    ax1 = sns.displot(RedFunction, hist=False, color=\"r\", label=RedName)\n    ax2 = sns.displot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n\n    plt.title(Title)\n\n    plt.show()\n    plt.close()","6046e6f5":"df = pd.read_csv('\/kaggle\/input\/brasilian-houses-to-rent\/houses_to_rent_v2.csv')","a710027c":"df.head()","70839f5b":"df.describe()","65817bd9":"df.describe(include = 'object')","3a1e5826":"df.shape","87175cdc":"df.isnull().sum()","c5af1645":"df.info()","f99c19ad":"df['floor'].unique()","d9cd0617":"df.loc[df['floor'] == '-', 'floor'] = 0\ndf['floor'] = df['floor'].astype('int64')","842bff24":"sns.boxplot(data = df['rent amount (R$)'], orient='horizontal')","aa436363":"# First let make a copy of our dataset so we can separate them.\ndata = df.copy()","ef33b074":"city_group = data.groupby('city')['rent amount (R$)']\n\nQ1 = city_group.quantile(.25)\nQ3 = city_group.quantile(.75)\n\n# IQR = Interquartile Range\nIQR = Q3 - Q1\n\n# Limits\nlower = Q1 - 1.5 * IQR\nupper = Q3 + 1.5 * IQR\n\n# DataFrame to store the new data\nnew_data = pd.DataFrame()\n\nfor city in city_group.groups.keys():\n    is_city = data['city'] == city\n    accepted_limit = ((data['rent amount (R$)'] >= lower[city]) &\n                     (data['rent amount (R$)'] <= upper[city]))\n    \n    select = is_city & accepted_limit\n    data_select = data[select]\n    new_data = pd.concat([new_data, data_select])\n    \ndata = new_data.copy()","c728b115":"# New dataset\ndata.describe()","f4156f2b":"# Lets take a look on how our data was distributed before and after treat outliers\n\nplt.figure(1, figsize=(20, 10))\nplt.subplot(2, 2, 1)\nsns.distplot(df['rent amount (R$)'])\nplt.title('Before Removing Outliers')\nplt.subplot(2, 2, 2)\nsns.distplot(data['rent amount (R$)'])\nplt.title('After Removing Outliers')\nplt.subplot(2, 2, 3)\nplt.figure(1, figsize=(20, 12))\nsns.boxplot(df['city'], df['rent amount (R$)']).set_title('Before Removing Outliers')\nplt.subplot(2, 2, 4)\nsns.boxplot(data['city'], data['rent amount (R$)']).set_title('After Removing Outliers')\nplt.tight_layout(pad=5.0)\nplt.show()","ededd0a9":"numerical1 = ['rooms', 'bathroom', 'parking spaces']\nplt.figure(figsize=(20, 5))\nsns.set(style = 'whitegrid')\ni = 1\nfor feature in numerical1:\n    plt.subplot(2, 3, i)\n    sns.barplot(x = feature, y= 'rent amount (R$)', data=data)\n    i+=1\nplt.tight_layout()","fffad703":"numerical2 = ['area', 'fire insurance (R$)', 'property tax (R$)', 'hoa (R$)']\nplt.figure(figsize=(20, 5))\nj = 1\nfor feature2 in numerical2:\n    plt.subplot(2, 2, j)\n    sns.distplot(data[feature2])\n    j+=1\nplt.tight_layout()","2a4edfb7":"plt.figure(figsize=(18, 8))\n\ni = 1\nfor city in data['city'].unique():\n    plt.subplot(2, 3, i)\n    plt.title(city)\n    city_name = data.loc[data['city'] == city]\n    sns.distplot(city_name['rent amount (R$)'])\n    i+=1\n    \n\nplt.tight_layout()\nplt.show()","ca8b087b":"plt.figure(figsize=(16, 8))\n\ni = 1\nstep = 5000\nfor city in data['city'].unique():\n    if step < 2000:\n        step = 2000\n    plt.subplot(2, 3, i)\n    plt.title(city)\n    city_name = data.loc[data['city'] == city]\n    sns.boxplot(city_name['rent amount (R$)'])    \n    step-=3000\n    i+=1\n\n    \n\nplt.tight_layout()\nplt.show()","41a29045":"categorical,numerical = categorize(data.columns)","8c095b4d":"plt.figure(figsize=(20,5))\nj =1\nfor i in categorical:\n    plt.subplot(1,3,j)\n    sns.countplot(data[i])\n    j =j+1\nplt.tight_layout()","6a1c96e5":"# Let's take a look about how the rent is impacted by the furniture\nplt.figure(figsize = (15, 5))\nsns.violinplot(x ='furniture', y ='rent amount (R$)', data = data,hue ='city').legend(loc='upper center')","611bec10":"# Let's take a look about how the rent is impacted by the animal acceptance\nplt.figure(figsize = (15, 5))\nsns.violinplot(x ='animal', y ='rent amount (R$)', data = data,hue ='city').legend(loc='upper center')","cd98fb88":"# now let's see the correlation between features\nplt.figure(figsize=(12,12))\nsns.heatmap(data.corr(), annot=True, cmap='RdBu_r', linecolor='black',vmin=-1, vmax=1)","af2bd13a":"cols = ['city', 'rooms', 'bathroom', 'parking spaces', 'fire insurance (R$)',\n        'furniture']\nx = data[cols]\ny = data['rent amount (R$)']","c198da2c":"labelencoder = LabelEncoder()\nx.loc[:, 'furniture'] = labelencoder.fit_transform(x.loc[:, 'furniture'])","03c07d16":"dummy = pd.get_dummies(x, columns=['city'])\ndummy.drop(columns = ['city_Belo Horizonte'], inplace=True)\nx = dummy","5ce5ef18":"# Now we split into train and test\nx_train, x_test, y_train, y_test = train_test_split(x,\n                                                   y,\n                                                   test_size = 0.3,\n                                                   random_state = 0)","cf7251a2":"# we create a list to storage all the results for later visualization\nacc = []\n# parameters are the alpha's that we will use to perform the GridSearch\nparameters1= [{'alpha': [0.0001, 0.001, 0.1, 1, 10, 100, 1000, 10000, 100000, 100000]}]\n# on the regressors we define the models that we want use\nregressors = {'Linear Regression': LinearRegression(),\n              'Ridge Model': Ridge(alpha=0.1),\n              'Decision Tree': DecisionTreeRegressor(),\n              'Random Forest': RandomForestRegressor(random_state=1),\n              'SVR': SVR(),\n              'KNN': KNeighborsRegressor(),\n              'Lasso': Lasso(),\n              'GridSearchRidge': GridSearchCV(Ridge(), parameters1, cv=4),\n              'GridSearchLasso': GridSearchCV(Lasso(), parameters1, cv=4)\n             }","65c75111":"# now we perform a loop with each regressor to perform the model, predict the rent \n# and extract the metrics\nfor i in regressors:\n    model = regressors.get(i)\n    # here we create a condition because for grid we want to perform the model with the best estimator\n    if i == 'GridSearchRidge' or i == 'GridSearchLasso':\n        model.fit(x_train, y_train).best_estimator_ \n    model.fit(x_train, y_train)\n    prediction = model.predict(x_test)\n    print(i)\n    print('MAE:', mean_absolute_error(y_test, prediction))\n    print('RMSE:', np.sqrt(mean_squared_error(y_test, prediction)))\n    print('R2:', r2_score(y_test, prediction))\n    print('*' * 40)\n    acc.append([i, mean_absolute_error(y_test, prediction), np.sqrt(mean_squared_error(y_test, prediction)), r2_score(y_test, prediction)])","6244351b":"# now let's follow the same loop and visualize the plot's for each regressor\nj = 1\nplt.figure(figsize=(20,10))\nfor i in regressors:\n    model = regressors.get(i)\n    model.fit(x_train, y_train)\n    prediction = model.predict(x_test)\n    plt.subplot(3, 3, j)\n    plt.title(i)\n    ax1 = sns.distplot(y_test,hist=False,kde =True,color =\"r\",label =\"Actual Value\")\n    sns.distplot(prediction ,color =\"b\",hist = False,kde =True, label = \"Predicted Value\",ax =ax1).set_title(i)\n    j+=1\nplt.tight_layout(pad = 0.5)","5fae30b1":"# lets sort our list of results and transform into a dataframe\nacc.sort(key = lambda y:y[3], reverse=True)\nacc = pd.DataFrame(data = acc, columns=['model', 'MAE', 'RMSE', 'R2'])","5917a7eb":"# now let's visualize it\nacc.head(len(regressors))","767f40fb":"# since RandomForest it's our best model, let's perform a rsquare test with differents\n# degrees of polynomial transformation to see if we can improve it\nrfr = RandomForestRegressor(random_state=1)\nrfr.fit(x_train, y_train)\nRsqu_test = []\n\norder = [1, 2, 3, 4]\nfor n in order:\n    pr = PolynomialFeatures(degree=n)\n    \n    x_train_pr = pr.fit_transform(x_train)\n    \n    x_test_pr = pr.fit_transform(x_test)    \n    \n    rfr.fit(x_train_pr, y_train)\n    \n    Rsqu_test.append(rfr.score(x_test_pr, y_test))\n\nplt.plot(order, Rsqu_test)\nplt.xlabel('order')\nplt.ylabel('R^2')\nplt.title('R^2 Using Test Data')","b16d9e92":"**For the citys we use OneHotEncoder and drop the first column to avoid the dummy variable trap**","f0cbe09f":"## Some functions for categorize and visualize data","3178117d":"## I would like to express my gratitude for everyone who visualized this kernel. I'm new on this field, so if you have any doubt, please post it on the comments so we can discuss it together.","f112101c":"**We used the columns that have more correlation with the variable that we want to predict**","b920a18e":"**We can see that we have right skewed distributions.**","2aba8c78":"**We can see that our dataset is now without outliers in our dependent variable**","445bbf26":"* Furnished houses are more expensive than not furnished\n* Furnished houses are more distributed than not furnished houses","c5a7d0f8":"**We used labelencoder for furniture because only have two values**","80a001f7":"* S\u00e3o Paulo appear to have the most expensive rent. \n* Belo Horizonte and Rio de Janeiro have slightly more expensive rents than Campinas and Porto Alegre.","716503e7":"**We can see that floor type is 'object', so let's check why**","e5c6ffe6":"## Lets split and transform our data into train and test","b451422b":"**Inicial observations:**\n*     There are 13 features and 10692 instances\n*     There are no NaN Values\n*     Most columns are numerical\n*     Most houses accept animals\n*     Most houses are not furnished\n*     S\u00e3o Paulo is the city with more houses\n*     There are potencial outliers","801c7eba":"**RandomForest it's our best perfomer in all three metrics**","8b1124fd":"* Houses with more rooms have more expensive rents, except for houses with 10 rooms when it decreases\n* The rent increases until 8 bathrooms, beyond that curiously decreases\n* Rent increases until 7 parking spaces, when it behave strangely, probably due to few samples","df18f104":"Welcome everyone! This is my first notebook and I'm going to perform a predictive analysis of house rental prices in Brazil.\n\nOur goals in this kernel are:\n* Basic Exploratory Data Analysis.\n* Guide on brazilian_houses_to_rent Dataset.\n* Feature Analysis\n* Modelling many Models to predict the price of rent\n\nOur dependent variable it is rent amount (R$). This variable it's the price of rental houses in Brazil and its measured in brazilian currency.","03f7def9":"## Inicial glances about the data","85df062b":"# Predictive analysis of house rental prices in Brazil","4f7e9f08":"* S\u00e3o Paulo is the city with more houses\n* The majority of the houses accept animals\n* The majority of the houses are not furnished","c44eecd2":"**Here we are going to set the models that we want use and the parameters we want to adopt. \nIn this notebook I will use:**\n*     Linear Regression\n*     Ridge Regression\n*     Decision Tree\n*     Random Forest\n*     Support Vector Regression (SVR)\n*     KNearestNeighbours (KNN)\n*     Lasso Regression\n*     GridSearch to find the best parameters on Lasso and Ridge","67bdce3f":"**We can see that are some outliers, so we got treat them**","dfd99d7c":"**To treat the outliers we will use the interquartile range and we will perform this analysis in every city**","2a220685":"## Import Dataset","fbdf0df4":"**Since our accuracy is very high, the curves are overlapted**","e7899a1a":"# Model Predictions","5afc1a10":"**We can see that are '-' values, so we got to clean that**","3dbf8392":"## Lets take a deeper look about how the prices are distributed in the city's","5b485dc6":"**All the distributions are right skewed**","6fc847b7":"## Getting the intution about all the categorical features","52952264":"## Analysis of the results","d8306c03":"## Lets explore our numerical features","cf4231ef":"## Cleaning the Data","23309142":"<img src=\"https:\/\/www.betterteam.com\/i\/thank-you-letter-to-employees-420x320-20190212.jpg\" width=\"400px\">","8531ef91":"# Exploratory Data Analysis (EDA)","8ade9e60":"## Checking for Outliers","eeb99854":"<img src=\"https:\/\/miro.medium.com\/max\/700\/1*9onqVYdPPrCcwDX6mGKCpg.jpeg\" width=\"600px\">","90e42036":"## Import Libraries","2ff2af2d":"**Seems like the animal acceptance have little impact on the rent**","2f3d381a":"## Dealing with Outliers"}}