{"cell_type":{"08060f3b":"code","a758305c":"code","9f614001":"code","d0803600":"code","81cc29ac":"code","fe326d9b":"code","4b4d7cb4":"code","190e238d":"code","5374391a":"code","ee2cda7d":"code","50d5f1c5":"code","64b25831":"code","ed4c7d20":"code","c41075ec":"code","cc6878c1":"code","fad24f1a":"code","7b350a03":"code","f4a61825":"code","6d8768c3":"code","08b04725":"code","c54f45a1":"markdown","61a28406":"markdown","12412a78":"markdown","72cc91c2":"markdown","816e0c48":"markdown","937d22fe":"markdown","53b2eb42":"markdown","582de2e0":"markdown","9a7dfad1":"markdown","891dbb07":"markdown","fe5d70a2":"markdown"},"source":{"08060f3b":"%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom fastai.structured import *\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom IPython.core.debugger import set_trace\nfrom sklearn.model_selection import KFold\n\nimport os\nprint(os.listdir(\"..\/input\"))\nPATH = \"..\/input\/\"","a758305c":"df_train = pd.read_csv(f'{PATH}train.csv', parse_dates=['Open Date'])\ndf_test = pd.read_csv(f'{PATH}test.csv', parse_dates=['Open Date'])\n\ndf_joined = pd.concat([df_train.drop('revenue', axis=1), df_test], axis=0)","9f614001":"def score(model, X_train, y_train, X_valid = [], y_valid = []):\n    #set_trace()\n    rms = sqrt(mean_squared_error(np.square(np.exp(y_train)), np.square(np.exp(model.predict(X_train)))))\n    score = [rms, model.score(X_train, y_train)]\n    \n    if len(X_valid) != 0 and len(y_valid) != 0:\n        score.append(sqrt(mean_squared_error(np.square(np.exp(y_valid)), np.square(np.exp(model.predict(X_valid))))))\n        \n    if model.oob_score:\n        score.append(model.oob_score_)\n    \n    return score\n\n\nn_train = df_train.shape[0]\n\ndef prcs(df, fe=[]):\n    add_datepart(df, 'Open Date')\n    \n    if 'city' in fe:\n        df = df.drop('City', axis=1)\n    # Quitamos el outlier (16)\n    if 'outlier' in fe:\n        df = df.drop(index=16, axis=0)\n    \n    if 'MB' in fe:\n        # No hay apenas tipo 'MB'\n        df['Type'] = df['Type'].replace('MB', 'DT')\n    \n    if 'city_group' in fe:\n        df = df.drop('City Group', axis=1)\n    \n    if 'dummies' in fe:\n        #Get dummies\n        p_cols = [ f'P{n}' for n in range(1,38)]\n            \n        df = pd.get_dummies(df, columns=p_cols)\n        if 'city_group' not in fe:\n            df = pd.get_dummies(df, columns=['City Group'], drop_first=True)\n        df = pd.get_dummies(df, columns=['Type'])\n    \n    #Train cats\n    train_cats(df)\n\n    X, _, _ = proc_df(df, None)\n    drop_cols = ['Open Year', 'Open Month', 'Open Week', 'Open Day', 'Open Dayofweek',\n       'Open Dayofyear', 'Open Is_month_end', 'Open Is_month_start',\n       'Open Is_quarter_end', 'Open Is_quarter_start', 'Open Is_year_end',\n       'Open Is_year_start']\n    \n    X = X.drop(drop_cols, axis=1)\n    # La columna Id no aporta nada\n    if 'id' in fe:\n        X = X.drop('Id', axis=1)\n    \n    if 'scale_open' in fe:\n        X['Open Elapsed'] = (X['Open Elapsed']\/1000).apply(np.log)\n    \n    X_train = X[:n_train]\n    X_test = X[n_train:]\n    \n    return X_train, X_test\n\ndef train_cv(X, y):\n    models = []\n    scores = []\n    \n    kf = KFold(n_splits=4, random_state=12, shuffle=False)\n    for train_index, val_index in kf.split(X):\n        X_train_ = X.iloc[train_index]\n        y_train_ = y.iloc[train_index]\n        X_val_ = X.iloc[val_index]\n        y_val_ = y.iloc[val_index]\n        m = RandomForestRegressor(n_jobs=-1, n_estimators=100, max_features=0.5, oob_score=True)\n        m.fit(X_train_, y_train_)\n        models.append(m)\n        scores.append(score(m, X_train_, y_train_, X_val_, y_val_))\n        \n    return models, np.array(scores).mean(axis=0)\n\ndef predict(models, X):\n    f = 1 \/ len(models)\n    pred = 0\n    for m in models:\n        pred += f * m.predict(X)\n    \n    return pred","d0803600":"X_train, X_test = prcs(df_joined.copy())\ny_train = df_train['revenue'].copy().apply(np.log)","81cc29ac":"m = RandomForestRegressor(n_jobs=-1, n_estimators=150, oob_score=True, max_features=0.5)\nm.fit(X_train, y_train)\nscore(m,X_train, y_train)","fe326d9b":"df_preds = pd.DataFrame(columns=['Prediction'],index=X_test.index, data=np.exp(predict(m, X_test)))\ndf_preds.to_csv('submission0.csv', index=True, index_label='Id')\ndf_preds.head()","4b4d7cb4":"models, scores = train_cv(X_train, y_train)\nprint(scores)","190e238d":"df_preds = pd.DataFrame(columns=['Prediction'],index=X_test.index, data=np.exp(predict(models, X_test)))\ndf_preds.to_csv('submission1.csv', index=True, index_label='Id')\ndf_preds.head()","5374391a":"X_train, X_test = prcs(df_joined.copy(), fe=['id'])\n\n# Doble transformaci\u00f3n para que la distribuci\u00f3n sea Normal\ny_train = df_train['revenue'].copy().apply(np.sqrt).apply(np.log)","ee2cda7d":"models, scores = train_cv(X_train, y_train)\nprint(scores)","50d5f1c5":"df_preds = pd.DataFrame(columns=['Prediction'],index=X_test.index, data=np.square(np.exp(predict(models, X_test))))\ndf_preds.to_csv('submission2.csv', index=True, index_label='Id')\ndf_preds.head()","64b25831":"X_train, X_test = prcs(df_joined.copy(), fe=['id', 'dummies'])\n\n# Doble transformaci\u00f3n para que la distribuci\u00f3n sea Normal\ny_train = df_train['revenue'].copy().apply(np.sqrt).apply(np.log)","ed4c7d20":"models, scores = train_cv(X_train, y_train)\nprint(scores)","c41075ec":"df_preds = pd.DataFrame(columns=['Prediction'],index=X_test.index, data=np.square(np.exp(predict(models, X_test))))\ndf_preds.to_csv('submission3.csv', index=True, index_label='Id')\ndf_preds.head()","cc6878c1":"X_train, X_test = prcs(df_joined.copy(), fe=['id', 'dummies', 'city'])\n\n# Doble transformaci\u00f3n para que la distribuci\u00f3n sea Normal\ny_train = df_train['revenue'].copy().apply(np.sqrt).apply(np.log)","fad24f1a":"models, scores = train_cv(X_train, y_train)\nprint(scores)","7b350a03":"df_preds = pd.DataFrame(columns=['Prediction'],index=X_test.index, data=np.square(np.exp(predict(models, X_test))))\ndf_preds.to_csv('submission4.csv', index=True, index_label='Id')\ndf_preds.head()","f4a61825":"X_train, X_test = prcs(df_joined.copy(), fe=['id', 'dummies', 'city', 'city_group'])\n\n# Doble transformaci\u00f3n para que la distribuci\u00f3n sea Normal\ny_train = df_train['revenue'].copy().apply(np.sqrt).apply(np.log)","6d8768c3":"models, scores = train_cv(X_train, y_train)\nprint(scores)","08b04725":"df_preds = pd.DataFrame(columns=['Prediction'],index=X_test.index, data=np.square(np.exp(predict(models, X_test))))\ndf_preds.to_csv('submission5.csv', index=True, index_label='Id')\ndf_preds.head()","c54f45a1":"# Cross-validation y Ensembling ","61a28406":"### RMSE 1.92 M (Rank 1600)","12412a78":"## Quitando columna 'City' ","72cc91c2":"# Quitando columna \"Id\"","816e0c48":"### RMSE 1.71 M (Rank 1)","937d22fe":"### RMSE 1.82 M (Rank 600)","53b2eb42":"### RMSE 1.83 M (Rank 600)","582de2e0":"### RMSE 1.784 M (Rank 75)","9a7dfad1":"# Feature engineering","891dbb07":"## Quitando columna 'City Group' ","fe5d70a2":"## A\u00f1adiendo dummies en las variables categoricas "}}