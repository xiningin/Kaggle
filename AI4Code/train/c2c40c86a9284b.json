{"cell_type":{"274ceb4e":"code","eabc9dbc":"code","4b6e6e17":"code","247422e3":"code","118a5bcf":"code","27feed52":"code","a90799b8":"code","ec845c13":"code","2420f5ce":"code","7b31617a":"code","69eec568":"code","5c7b9368":"code","79eadd7e":"code","af9ed467":"code","2fc4e927":"code","96e132f3":"code","0cfe62c3":"code","3e620124":"code","0cef4ef3":"code","7e917c46":"code","6f6c898e":"code","9b175361":"code","ce020703":"code","cc5130a6":"code","6bb76c7b":"code","0d36adcc":"code","7393b9bd":"code","b0e7c912":"code","562dd1ed":"code","dc96b669":"code","3698e733":"code","b13868e0":"code","800947f9":"code","f4ca8fc2":"code","493814f0":"code","8f02559d":"markdown","0b226aeb":"markdown","ab51bb25":"markdown","5624b68c":"markdown","2313b079":"markdown","5a966804":"markdown","52c467d1":"markdown","467592c7":"markdown","ddad8410":"markdown","dad9b059":"markdown","d6496849":"markdown","592636fc":"markdown","c8c4a27f":"markdown","ec131f7b":"markdown","95e97a75":"markdown","5d57e605":"markdown","d6d0d5c5":"markdown","619c9f3a":"markdown","61bce7ee":"markdown"},"source":{"274ceb4e":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","eabc9dbc":"data=pd.read_excel('\/kaggle\/input\/covid19\/dataset.xlsx')\ndata.head(7)","4b6e6e17":"shape=data.shape\nprint(shape[1],'columns')\nprint(shape[0],'rows')","247422e3":"def positive_bin(x):\n    if x == 'positive':\n        return 1\n    else:\n        return 0\ndata['SARS-Cov-2 exam result_bin']=data['SARS-Cov-2 exam result'].map(positive_bin)","118a5bcf":"tg_values=data['SARS-Cov-2 exam result'].value_counts()\ntg_values.plot.barh(color='red')\nprint(\"Negative exam results: \"+\"{:.2%}\".format(tg_values[0]\/tg_values.sum())+' ('+str(tg_values[0])+' records)')\nprint(\"Positive exam results: \"+\"{:.2%}\".format(tg_values[1]\/tg_values.sum())+'  ('+str(tg_values[1])+' records)')\nprint('')","27feed52":"data['SARS-Cov-2 exam result_Baseline']=0\nprint(\"Baseline accuracy: \"+\"{:.2%}\".format((data['SARS-Cov-2 exam result_Baseline']==data['SARS-Cov-2 exam result_bin']).sum()\/len(data['SARS-Cov-2 exam result_Baseline'])))","a90799b8":"if data.isnull().values.any() == True:\n    print('Found NaN values!!:')\nelse:\n    print('No NaN values =):')\nprint(' ')\n\nnulls=(data.isnull().sum()\/len(data))*100","ec845c13":"nulls.sort_values(ascending=False)","2420f5ce":"ax=nulls.hist(bins=90, grid=False, figsize=(10,6), color='red')\nax.set_xlabel(\"% of Nulls\")\nax.set_ylabel(\"Number of variables\")\nprint('')","7b31617a":"pos=data[data['SARS-Cov-2 exam result_bin']==1]\nneg=data[data['SARS-Cov-2 exam result_bin']==0]","69eec568":"if pos.isnull().values.any() == True:\n    print('Found NaN values!!:')\nelse:\n    print('No NaN values =):')\nprint(' ')\n\nnulls_pos=(pos.isnull().sum().sort_values(ascending=False)\/len(pos))*100\nnulls_pos","5c7b9368":"ax=nulls_pos.hist(bins=80, grid=False, figsize=(10,6), color='black')\nax.set_xlabel(\"% of Nulls\")\nax.set_ylabel(\"Number of variables\")\nprint('')","79eadd7e":"if neg.isnull().values.any() == True:\n    print('Found NaN values!!:')\nelse:\n    print('No NaN values =):')\nprint(' ')\n\nnulls_neg=(neg.isnull().sum().sort_values(ascending=False)\/len(neg))*100\nnulls_neg","af9ed467":"ax=nulls_neg.hist(bins=80, grid=False, figsize=(10,6), color='blue')\nax.set_xlabel(\"% of Nulls\")\nax.set_ylabel(\"Number of variables\")\nprint('')","2fc4e927":"nulls.drop(['SARS-Cov-2 exam result','Patient ID','SARS-Cov-2 exam result_bin','SARS-Cov-2 exam result_Baseline'],inplace=True)","96e132f3":"selecting_variables=nulls.loc[nulls<90]\nselecting_variables","0cfe62c3":"variables=selecting_variables.index.tolist()\nvariables.append('Patient ID')\nvariables.append('SARS-Cov-2 exam result_bin')","3e620124":"df=data[variables]\ndf[df['Parainfluenza 2'].notnull()].head()","0cef4ef3":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef bins(x):\n    if x == 'detected' or x=='positive':\n        return 1\n    elif x=='not_detected' or x=='negative':\n        return 0\n    else:\n        return x\n    \nfor col in df.columns:\n    df[col]=df[col].apply(lambda row: bins(row))","7e917c46":"pd.set_option('display.max_columns', None)\ndf.describe()","6f6c898e":"variables_imputer=variables[4:18]\nteste=df[variables_imputer]","9b175361":"from sklearn.impute import KNNImputer\nimputer = KNNImputer(n_neighbors=5,missing_values=np.nan)\nimputer.fit(teste)\nteste[:]=imputer.transform(teste)","ce020703":"df.drop(variables_imputer,axis=1,inplace=True)","cc5130a6":"data_final= pd.concat([teste,df],axis=1)\ndata_final.fillna(-1,inplace=True)\ndata_final.head()","6bb76c7b":"X=data_final.drop(['SARS-Cov-2 exam result_bin','Patient ID'],axis=1)\ny=data_final['SARS-Cov-2 exam result_bin']","0d36adcc":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,random_state=5)\nprint(X_train.shape, X_test.shape)","7393b9bd":"from sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.metrics import log_loss, accuracy_score\n\nresultados=[]\nkf=RepeatedKFold(n_splits=10, n_repeats=1, random_state=5)\nfor train,valid in tqdm(kf.split(X_train)):\n    \n    Xtr, Xvld = X_train.iloc[train], X_train.iloc[valid]\n    ytr, yvld = y_train.iloc[train], y_train.iloc[valid]\n    \n    rf= RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)\n    rf.fit(Xtr,ytr)\n    \n    p=rf.predict(Xvld)\n    acc=accuracy_score(yvld,p)\n    resultados.append(acc)","b0e7c912":"print(\"Vanilla RandomForest Train accuracy: \"+\"{:.2%}\".format(np.mean(resultados)))","562dd1ed":"from sklearn.linear_model import LogisticRegression\n\nresultados=[]\nkf=RepeatedKFold(n_splits=10, n_repeats=1, random_state=5)\nfor train,valid in tqdm(kf.split(X_train)):\n    \n    Xtr, Xvld = X_train.iloc[train], X_train.iloc[valid]\n    ytr, yvld = y_train.iloc[train], y_train.iloc[valid]\n    \n    lr= LogisticRegression(max_iter=300)\n    lr.fit(Xtr,ytr)\n    \n    p=lr.predict(Xvld)\n    acc=accuracy_score(yvld,p)\n    resultados.append(acc)","dc96b669":"print(\"Vanilla Logistic Regression Train accuracy: \"+\"{:.2%}\".format(np.mean(resultados)))","3698e733":"p2=rf.predict(X_test)\np2[:]=rf.predict(X_test)\nacc=accuracy_score(y_test,p2)\nprint(\"Vanilla RandomForest Test accuracy: \"+\"{:.2%}\".format(acc))\np2=lr.predict(X_test)\np2[:]=lr.predict(X_test)\nacc=accuracy_score(y_test,p2)\nprint(\"Vanilla Logistic Regression Test accuracy: \"+\"{:.2%}\".format(acc))","b13868e0":"visual=pd.concat([X_test,y_test],axis=1)\nvisual['predict']=p2\nvisual2=visual[visual['SARS-Cov-2 exam result_bin']==visual['predict']]\n\nprint('Positive results in the test sample: ',visual[visual['SARS-Cov-2 exam result_bin']==1].shape[0])\nprint('Positive results correctly predicted: ',visual2[visual2['predict']==1].shape[0])\nprint('Positive accuracy: ',\"{:.2%}\".format(visual2[visual2['predict']==1].shape[0]\/visual[visual['SARS-Cov-2 exam result_bin']==1].shape[0]))","800947f9":"sns.set(font_scale=2)","f4ca8fc2":"pred_prob=lr.predict_proba(X_test)\n\nfrom sklearn.metrics import precision_recall_curve\n\nscores=pred_prob[:,1]\nprecision, recall, thresholds = precision_recall_curve(y_test, scores)\nfig, ax = plt.subplots(figsize=(10,7))\nplt.plot(recall[:-1],precision[:-1],label=\"logistic regeression\",color='red')\nplt.legend(loc=\"center right\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.show()","493814f0":"from sklearn.metrics import roc_curve\n\nscores=pred_prob[:,1]\nfpr, tpr, thresholds = roc_curve(y_test,scores)\nfig, ax = plt.subplots(figsize=(10,7))\nplt.plot(fpr,tpr,color='red')\nplt.xlabel(\"False Positive Rate\",size=15)\nplt.ylabel(\"True Positive Rate\",size=15)\n\nplt.show()","8f02559d":"> #### Dealing with NaNs","0b226aeb":"#### We can see low accuracy on positive results","ab51bb25":"##### The main objective on this notebook is to explore and find how to deal with the NaN values and implement a vanilla Classifier to understand how the balance between positive and negative results can affect our models.","5624b68c":"### We can see a very unbalanced dataset, maybe over or undersampling will be a good idea\n> #### Before that, Assuming all results as negative will be a good baseline","2313b079":"> #### For categorical variables, NaN will be replaced with -1","5a966804":"## Importings","52c467d1":"### Conclusions from this session:\n- In spite of having a \"high\" accuracy, we are only matching on negative exam results, the 7.55% for positive results accuracy explains it;\n- Probably,this is happening because the data is too unbalanced;\n- Looking at the precision\/recall curve, we can see that changing the threshold won't bring better results.","467592c7":"> #### Based on the histograms, I'm selecting features that have a maximum of 90% as missing values","ddad8410":"> ####  Labeling categorical values","dad9b059":"> #### Variables with too long range, not good to substitute NaNs with 0\n> #### Using KNN imputer","d6496849":"### Model Selection","592636fc":"#### Finally, I'll be using this dataset","c8c4a27f":"# Diagnosis of COVID-19 and its clinical spectrum\n> ## AI and Data Science supporting clinical decisions\n> #### Rodrigo Fragoso","ec131f7b":"#### Transforming the target variable in binary","95e97a75":"## Feature Selection","5d57e605":"### Next steps:\n- Test another imputer methods for NaNs;\n- Test another classifiers;\n- Do some over and undersampling to improve our classifiers;\n- Do some hyperparameter tuning","d6d0d5c5":"### __With a brief look, we can see that are lots of NaN Values on this dataset__","619c9f3a":"### Conclusions from this session:\n- As we can see there a lot of missing records;\n- Most of the variables have at leats 80% of NaNs;\n- We are dealing with a very unbalanced dataset 9:1 negative\/positive results.","61bce7ee":"## Exploring missing\/NaN data "}}