{"cell_type":{"6d0e6b92":"code","a654bb04":"code","314860a0":"code","2c00f591":"code","4843310b":"code","da92878e":"code","da1bad24":"code","0e6325e6":"code","58f3fe2c":"code","354c8cb7":"code","62c16794":"code","2cde8efe":"code","9534728c":"markdown","9a049530":"markdown","b066968d":"markdown","624fa188":"markdown"},"source":{"6d0e6b92":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\n\nTRAIN_DIR = '..\/input\/titanic\/train.csv'\nTEST_DIR = '..\/input\/titanic\/test.csv'\npredict = 'Survived'","a654bb04":"train = pd.read_csv(TRAIN_DIR, index_col='PassengerId')\ntest = pd.read_csv(TEST_DIR, index_col='PassengerId')\n\n#    Survived    Survived                   0 = No, 1 = Yes\n#    Pclass      Ticket class               1 = 1st, 2 = 2nd, 3 = 3rd\n#    Name        Name\n#    Sex         Sex\n#    Age         Age in years\n#    SibSp       # of siblings \/ spouses aboard the Titanic\n#    Parch       # of parents \/ children aboard the Titanic\n#    Ticket      Ticket number\n#    Fare        Passenger fare\n#    Cabin       Cabin number\n#    Embarked    Port of Embarkation        C = Cherbourg, Q = Queenstown, S = Southampton","314860a0":"# Columns with missing values\ntrain.columns[train.isnull().any()]","2c00f591":"def prepare_data(data):\n    data = data.drop(['Ticket', 'Name', 'Cabin'], axis=1)\n\n    # 72% of Embarked values are 'S' which stands for Southampton\n    # so in my opinion we can fill missing data with this value.\n    # Age we will fill with mean values for age\n\n    data['Embarked'] = data['Embarked'].fillna('S')\n    data['Age'] = data['Age'].fillna(data['Age'].mean())\n    \n    # Now we have to transform alphabetic values to numberic\n    le = preprocessing.LabelEncoder()\n    sex = le.fit_transform(list(data['Sex']))\n    embarked = le.fit_transform(list(data['Embarked']))\n\n    data['Sex'] = pd.Series(list(sex), dtype='uint8', index=data.index)\n    data['Embarked'] = pd.Series(list(embarked), dtype='uint8', index=data.index)\n    \n    return data\n\n\ntrain = prepare_data(train)","4843310b":"# Let's see how our data looks like\ntrain.head()","da92878e":"X = train.drop(predict, axis=1)\nY = train[predict]\n\nx_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2)","da1bad24":"# Train the best model\nknn_model = KNeighborsClassifier(n_neighbors=7)\n\nknn_model.fit(x_train, y_train)\nknn_acc = knn_model.score(x_val, y_val)\n\nprint(f'K-Nearest Neighbours accuracy: {knn_acc}')","0e6325e6":"linear_model = LinearRegression()\n\nlinear_model.fit(x_train, y_train)\nlinear_acc = linear_model.score(x_val, y_val)\n\nprint(f'Linear Regression accuracy: {linear_acc}')","58f3fe2c":"logistic_model = LogisticRegression()\n\nlogistic_model.fit(x_train, y_train)\nlogistic_acc = logistic_model.score(x_val, y_val)\n\nprint(f'Logistic Regression accuracy: {logistic_acc}')","354c8cb7":"dtc_model = DecisionTreeClassifier()\n\ndtc_model.fit(x_train, y_train)\ndtc_acc = dtc_model.score(x_val, y_val)\n\nprint(f'Decision Tree Classifier accuracy: {dtc_acc}')","62c16794":"test = prepare_data(test)\n\n# Check for empty values\ntest.columns[test.isnull().any()]\n\n# I will fill NaN values with mean\ntest['Fare'] = test['Fare'].fillna(test['Fare'].mean())","2cde8efe":"model = dtc_model\npredictions = model.predict(test)\n\nseries = pd.Series(i for i in predictions)\nseries = pd.Series(series, name='Survived')\n\nsubmission = pd.concat([pd.Series(test.index), series], axis=1)\nsubmission\nsubmission.to_csv(\"submission.csv\", index=False)","9534728c":"# Linear Regression\n### Accuracy: ~40%","9a049530":"# Logistic Regression\n### Accuracy: ~70%","b066968d":"# K-Nearest Neighbours\n### Accuracy on valid data: ~70%","624fa188":"# Decision Tree Classifier\n### Accuracy: ~80%"}}