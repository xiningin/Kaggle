{"cell_type":{"1b65a7e9":"code","7fa8135f":"code","47c3efff":"code","48645384":"code","acddd721":"code","8d480350":"code","f9584226":"code","b62c2dcf":"code","ec5db677":"code","334fac58":"code","59db1519":"code","0b04aeb9":"code","6d5a477b":"code","94631a5b":"code","a91a1997":"code","f77cbc34":"code","763e620d":"code","0eec8215":"code","3998362c":"code","08d90a5f":"code","bf3d04d0":"code","319f61b7":"code","406e0a89":"code","b5885c15":"code","8655c915":"code","9b8762bd":"code","8465abd5":"code","6292dacc":"code","ff8ea011":"code","114e21dc":"code","4bf0b171":"code","c8000d6e":"code","38a3e2aa":"code","cb4a0d3b":"code","97df7db4":"code","8408e027":"code","aff14a27":"code","8a43487d":"code","65b8eb7c":"code","54040e28":"markdown","f27c92a1":"markdown","d4b2bd0d":"markdown","03e72d86":"markdown","66c5b447":"markdown","98d6fbb6":"markdown","7647e2a3":"markdown","46fd51d8":"markdown","97113196":"markdown","adca6498":"markdown","1cc7d9cd":"markdown","64d42f26":"markdown","9ffb17bb":"markdown","033b2640":"markdown","0d1d3c49":"markdown","ea5a416b":"markdown","b2ea5be6":"markdown","bfb85c3e":"markdown"},"source":{"1b65a7e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7fa8135f":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.graph_objs as go\nimport plotly.offline as pyo\nimport plotly.figure_factory as ff\nimport plotly.express as px\nfrom plotly import tools\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot","47c3efff":"df = pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')\ndf.head()","48645384":"df.shape   # no. of rows and coloumns\nprint('Number of responses given to survey\/rows in dataframe:', df.shape[0])\nprint('Number of columns of dataframe',df.shape[1])","acddd721":"df.dtypes  #data type","8d480350":"df.columns.values # coloumn names","f9584226":"df.isnull().sum() > 12987.0\n# checking if columns has null values number greather than 12987 and found out that there are some columns so i will delete those columns now","b62c2dcf":"\n#columns with null values greather than 50% \n\nn = []\nfor i in df:\n    if df[i].isnull().sum() > 12987.0:\n        n.append(i)\n        \n\nlen(n)","ec5db677":"#drop the columns\n\ndf1 = df.drop(n,axis = 1)\ndf1","334fac58":"df1.head(2)","59db1519":"df1.info()","0b04aeb9":"# missing values\n\ndf1.isnull().sum()","6d5a477b":"# Duplicate values\n\ndf1.duplicated().sum()","94631a5b":"#Distribution Based on Designation\n\nQ5_distrib = pd.DataFrame(df['Q5'].value_counts())\nQ5_distrib.reset_index(inplace=True)\nQ5_distrib_grey = Q5_distrib.copy() \nsns.set(style=\"whitegrid\")\nf,ax = plt.subplots(figsize=(10, 8))\ncolors = ['red','b','b','b','b','b','b','b','b','b','b','b','b','b','b']\nsns.barplot(x=\"Q5\", y=\"index\", data=Q5_distrib, palette = colors)\nsns.despine(left=True, bottom=True)\nsns.set(style=\"whitegrid\")\nsns.barplot(x=\"Q5\", y=\"index\", data=Q5_distrib_grey,\n            palette =colors)\nsns.despine(left=True, bottom=True)\n_ = plt.text(6850, 0.1, '6804', fontsize=12, color='green')\n_ = ax.set_title('Distribution Based on Designation', fontsize=20)\nax.xaxis.grid(False)\nax.yaxis.grid(False)\nax.set_xticks([])\nax.xaxis.set_label_text(\"\")\nax.yaxis.set_label_text(\"\")\n_ = plt.setp(f.patches, linewidth=0.5) ","a91a1997":"#Age Distribution\n\nQ1_distrib = pd.DataFrame(df['Q1'].value_counts())\nQ1_distrib.reset_index(inplace=True)\nQ1_distrib_grey = Q1_distrib.copy() \nsns.set(style=\"whitegrid\")\nf,ax = plt.subplots(figsize=(10, 8))\ncolors = ['yellow','b','b','b','b','b','b','b','b','b','b','b','b','b','b']\nsns.barplot(x=\"Q1\", y=\"index\", data=Q1_distrib, palette = colors)\nsns.despine(left=True, bottom=True)\nsns.set(style=\"whitegrid\")\nsns.barplot(x=\"Q1\", y=\"index\", data=Q1_distrib_grey,\n            palette =colors)\nsns.despine(left=True, bottom=True)\n_ = plt.text(3540, 0.1, '3540', fontsize=12, color='green')\n_ = ax.set_title('Age Distribution', fontsize=20)\nax.xaxis.grid(False)\nax.yaxis.grid(False)\nax.set_xticks([])\nax.xaxis.set_label_text(\"\")\nax.yaxis.set_label_text(\"\")\n_ = plt.setp(f.patches, linewidth=0.5)","f77cbc34":"from IPython.core.display import HTML\n\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","763e620d":"df_nunique = {var: pd.DataFrame(df[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])","0eec8215":"df_India = df1[df1['Q3'] == 'India'] #country name\ndf_India","3998362c":"df_nunique = {var: pd.DataFrame(df_India[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])","08d90a5f":"python = df['Q7_Part_1'].count()\nr = df['Q7_Part_2'].count()\nc = df['Q7_Part_3'].count()\ncplusplus = df['Q7_Part_4'].count()\njava = df['Q7_Part_5'].count()\njavascript = df['Q7_Part_6'].count()\nbash = df['Q7_Part_10'].count()\nmatlab = df['Q7_Part_11'].count()\nother = df['Q7_OTHER'].count()\nsns.set(style=\"whitegrid\")\nf,ax = plt.subplots(figsize=(15, 7))\nlist1 = ['Python','R','C','C++','Java','JavaScript','Bash','Matlab','Other']\nlist2 = [python,r,c, cplusplus,java,javascript,bash,matlab,other]\nsns.barplot(list2,list1)","bf3d04d0":"Q4_distrib = pd.DataFrame(df['Q8'].value_counts())\nQ4_distrib.reset_index(inplace=True)\nQ4_distrib_grey = Q4_distrib.copy() \nsns.set(style=\"whitegrid\")\nf,ax = plt.subplots(figsize=(10, 8))\ncolors = ['black','b','b','b','b','b','b','b','b','b','b','b','b','b','b']\nsns.barplot(x=\"Q8\", y=\"index\", data=Q4_distrib, palette = colors)\nsns.despine(left=True, bottom=True)\nsns.set(style=\"whitegrid\")\nsns.barplot(x=\"Q8\", y=\"index\", data=Q4_distrib_grey,\n            palette =colors)\nsns.despine(left=True, bottom=True)\n_ = plt.text(5590, 0.1, '5585', fontsize=12, color='green')\n_ = ax.set_title('Mostly Recommended Language', fontsize=20, color='green')\nax.xaxis.grid(False)\nax.yaxis.grid(False)\nax.set_xticks([])\nax.xaxis.set_label_text(\"\")\nax.yaxis.set_label_text(\"\")\n_ = plt.setp(f.patches, linewidth=0.5) ","319f61b7":"df_groupby = {var: pd.DataFrame(df_India.groupby([var, 'Q1']).size()) \n              for var in {'Q2', 'Q3'}}\nmulti_table([df_groupby['Q2'], df_groupby['Q3']])","406e0a89":"# Analysis of people with age between 18-21\n\ndf_India_1821 = df_India[df_India['Q1'] == '18-21']\ndf_India_1821","b5885c15":"df_nunique = {var: pd.DataFrame(df_India_1821[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])","8655c915":"# Analysis of people of age between 22-24\n\ndf_India_2224 = df_India[df_India['Q1'] == '22-24']\ndf_India_2224","9b8762bd":"df_nunique = {var: pd.DataFrame(df_India_2224[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])","8465abd5":"#Analysis of people of age between 25-29\n\ndf_India_2529 = df_India[df_India['Q1'] == '25-29']\ndf_India_2529","6292dacc":"df_nunique = {var: pd.DataFrame(df_India_2529[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])","ff8ea011":"# Analysis of people of age between 35-39\n\ndf_India_3539 = df_India[df_India['Q1'] == '35-39']\ndf_India_3539","114e21dc":"df_nunique = {var: pd.DataFrame(df_India_3539[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])\n","4bf0b171":"#Analysis of people of age between 40-44\n\ndf_India_4044 = df_India[df_India['Q1'] == '40-44']\ndf_India_4044","c8000d6e":"df_nunique = {var: pd.DataFrame(df_India_4044[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])","38a3e2aa":"# Analysis of people of age between 45-49\n\ndf_India_4549 = df_India[df_India['Q1'] == '45-49']\ndf_India_4549.head()","cb4a0d3b":"df_nunique = {var: pd.DataFrame(df_India_4549[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])","97df7db4":"# Analysis of people of age between 50-54\n\ndf_India_5054 = df_India[df_India['Q1'] == '50-54']\ndf_India_5054.head()","8408e027":"df_nunique = {var: pd.DataFrame(df_India_5054[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])","aff14a27":"# Analysis of people of age between 55-59\n\ndf_India_5559 = df_India[df_India['Q1'] == '55-59']\ndf_India_5559.head()","8a43487d":"df_nunique = {var: pd.DataFrame(df_India_5559[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5',\n       'Q6', 'Q7_Part_1', 'Q8', 'Q9_Part_11', 'Q11', 'Q12_Part_5', 'Q13',\n       'Q14_Part_1', 'Q15', 'Q16_Part_1', 'Q17_Part_1', 'Q20', 'Q21', 'Q22',\n       'Q23', 'Q25', 'Q26', 'Q41'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q4'],df_nunique['Q5'],\n             df_nunique['Q6'],df_nunique['Q7_Part_1']\n            ,df_nunique['Q8'],df_nunique['Q9_Part_11'],df_nunique['Q11']\n            ,df_nunique['Q12_Part_5'],df_nunique['Q13'],df_nunique['Q14_Part_1']\n            ,df_nunique['Q15'],df_nunique['Q16_Part_1'],df_nunique['Q17_Part_1']\n            ,df_nunique['Q20'],df_nunique['Q21'],df_nunique['Q22']\n            ,df_nunique['Q23'],df_nunique['Q25'],df_nunique['Q26'],df_nunique['Q41']])","65b8eb7c":"df_ind = df[df['Q3'] == 'India']\n\ndf_nunique = {var: pd.DataFrame(df_ind[var].value_counts()) \n              for var in {'Time from Start to Finish (seconds)', 'Q1', 'Q2', 'Q3','Q38_A_Part_1', 'Q38_A_Part_2',\n       'Q38_A_Part_3', 'Q38_A_Part_4', 'Q38_A_Part_5', 'Q38_A_Part_6',\n       'Q38_A_Part_7', 'Q38_A_Part_8', 'Q38_A_Part_9', 'Q38_A_Part_10',\n       'Q38_A_Part_11', 'Q38_A_OTHER'}}\nmulti_table([df_nunique['Time from Start to Finish (seconds)'], df_nunique['Q1'],df_nunique['Q2']\n            ,df_nunique['Q3'],df_nunique['Q38_A_Part_1'],df_nunique['Q38_A_Part_2'],\n             df_nunique['Q38_A_Part_3'],df_nunique['Q38_A_Part_4'],df_nunique['Q38_A_Part_5']\n            ,df_nunique['Q38_A_Part_6'],df_nunique['Q38_A_Part_7'],df_nunique['Q38_A_Part_8']\n            ,df_nunique['Q38_A_Part_9'],df_nunique['Q38_A_Part_10'],df_nunique['Q38_A_Part_11']\n            ,df_nunique['Q38_A_OTHER']])\n","54040e28":"### Analysis\n\n* Most of the people are from age 18-29\n* Most of the people involved in survey are man\n* People from india answered most\n* Most of the people involved in survey are doing master's and bachelor's degree\n* Most of the people invloved in survey are students\n* Most of the people invloved in survey are coding from 1-3 years\n* Most of the people are using python\n* Most of the people are doing in jupyter notebook\n* Most of the people are doing in laptop\n* Most of the people never used TPU for executing program\n* Most of the people using Matplotlib library for visualization\n* Most of the people are using Machine Laerning Models from less than 1 year\n* Most of the people using Scikit learning frame work and linear or logistic regression on regular basis\n* Most of the people are from computers\/technology background\n* Most of the people are working in a company of size 10,000 employees or more and 20+ employees are responsible for doing data science in their company\n* Most of the people doesnot use ML models or may be they want to apply them in future\n* Most of the people are getting a salary of 0-999 USD\n* Most of the people are not spending any money to learn machine learning\n* Most of the people are working on Microsoft excel, google sheets etc as basic software","f27c92a1":"# Importing Dependencies","d4b2bd0d":"# Analysis on Indian people","03e72d86":"# Analysis of Age vs Gender","66c5b447":"# Mostly Recommended Programming Languages","98d6fbb6":"### Analysis\n\n* Most of the Indians in survey are between age 18-21\n* Males are more in number than females\n* Comapred to all age groups Females are more in number in the age 18-21\n* In any gender category most of the people are from age 18-21\n* No woman above age 59\n* No non binary people above age 39\n* No perfer to self describe above age 34\n* In total 6 70+ age people 5 are men and 1 is prefer not to say","7647e2a3":"# Analysis with Age","46fd51d8":"# Exploratory Data Analysis","97113196":"#### df1 is the dataframe with null values number lessthan 50%\u00b6","adca6498":"![](https:\/\/i2.wp.com\/www.no1india.com\/wp-content\/uploads\/2020\/08\/No1india-logo-1.png?fit=786%2C786&ssl=1)","1cc7d9cd":"# Data Collection and Analysis","64d42f26":"### Analysis\n* Most of the people are from age 18-29\n* Most of the people involved in survey are man\n* People from india answered most\n* Most of the people involved in survey are doing master's and bachelor's degree\n* Most of the people invloved in survey are students\n* Most of the people invloved in survey are coding from 1-3 years\n* Most of the people are using python\n* Most of the people are doing in jupyter notebook\n* Most of the people are doing in laptop\n* Most of the people never used TPU for executing program\n* Most of the people using Matplotlib library for visualization\n* Most of the people are using Machine Laerning Models from less than 1 year\n* Most of the people using Scikit learning frame work and linear or logistic regression on regular basis\n* Most of the people are from computers\/technology background\n* Most of the people are working in a company of size 0-50 employees\n* Most of the people doesnot use ML models or may be they want to apply them in future\n* Most of the people are getting a salary of 0-999 USD\n* Most of the people are not spending any money to learn machine learning\n* Most of the people are working on Microsoft excel, google sheets etc as basic software","9ffb17bb":"# Data Visualisation","033b2640":"# Frequently Used Programming Languages By Students","0d1d3c49":"# India is No. 1 According to Kaggle Survey of 2021","ea5a416b":"# Data Cleaning","b2ea5be6":"# Work Still in Progress","bfb85c3e":"# Different machine learning tools that Indians are using !!"}}