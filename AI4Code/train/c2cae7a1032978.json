{"cell_type":{"224415fb":"code","a9673554":"code","ca40effd":"code","7e4a585f":"code","b7ba607f":"code","7a7c31b2":"code","77a8c6b3":"code","445f5f67":"code","78e26819":"code","8f61c93c":"code","4b9dd57e":"code","bd65cbd8":"code","46447f2c":"code","262ef8cd":"code","6b75b294":"code","8439571e":"code","e7b8638d":"code","f1d05774":"code","defe9b0a":"code","37dc233d":"code","a302ae45":"code","5f9fc242":"code","e899ca84":"code","9eb82663":"code","d20b9a60":"code","a3426268":"code","5e39897d":"code","20dd0562":"code","660ebc1e":"code","38e7e474":"markdown","cd453a3f":"markdown","b5270b9f":"markdown","d31e09fe":"markdown","d2f905d1":"markdown","a50b53a6":"markdown","0ee57468":"markdown","368ea146":"markdown","14156e18":"markdown","f7ada4d5":"markdown","289b7407":"markdown","1c0a1a67":"markdown"},"source":{"224415fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a9673554":"!python -m pip install detectron2 -f \\\n  https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu101\/torch1.6\/index.html","ca40effd":"from bs4 import BeautifulSoup as bs\n#cuda 10.1\nimport torch, torchvision\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\nimport glob\n\nimport os\nimport ntpath\nimport numpy as np\nimport cv2\nimport random\nimport itertools\nimport pandas as pd\nfrom tqdm import tqdm\nimport urllib\nimport json\nimport PIL.Image as Image\n\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.structures import BoxMode","7e4a585f":"import shutil\n\npath_cpy = \"\/kaggle\/input\/face-mask-detection\"\n\n# shutil.copytree(path_cpy)","b7ba607f":"def gen_box(obj):\n#     Getting bounding box coordinates\n    xmin = int(obj.find('xmin').text)\n    xmax = int(obj.find('xmax').text)\n    ymin = int(obj.find('ymin').text)\n    ymax = int(obj.find('ymax').text)\n    \n    return [xmin, ymin, xmax, ymax]\n\ndef gen_label(obj):\n    if obj.find('name').text == \"with_mask\":\n        return \"mask\" #     for without_mask label set to 1\n    elif obj.find('name').text == \"mask_weared_incorrect\":\n        return \"incorrect_mask\"     # for mask_weared_incorrect label set to 2\n    return \"no_mask\" #     for without_mask label set to 0","7a7c31b2":"coordinates = []\nlabels = []\nname= []\nsize = []\ndef gen_list(path):\n    xml_list  = list(sorted(os.listdir(path+\"\/annotations\")))\n    img_list = list(sorted(os.listdir(path+\"\/images\")))\n    total = len(img_list)\n    assert len(img_list) == len(xml_list)\n    counter = 0\n    for xml in xml_list:\n        with open(path+f\"\/annotations\/{xml}\") as file:\n            data = file.read()\n            soup = bs(data, \"xml\")\n            xml_objs = soup.find_all('object')\n            counter +=1\n            for i in xml_objs:\n                coordinates.append(gen_box(i)) \n                labels.append(gen_label(i))\n                name.append(soup.find('filename').text)\n        print(f\"file processed {counter} \/ {total}...\")","77a8c6b3":"gen_list(path_cpy)","445f5f67":"xml_list  = list(sorted(os.listdir(path_cpy+\"\/annotations\")))","78e26819":"df = pd.DataFrame()","8f61c93c":"df['name'] = name\ndf['labels'] = labels\n# initializing labels\ndf['xmin'] = 0\ndf['ymin'] = 0\ndf['xmax'] = 0\ndf['ymax'] = 0\ndf['height'] = np.zeros(len(df['name']))\ndf['width'] = np.zeros(len(df['name']))","4b9dd57e":"for i,(xmin,ymin,xmax,ymax) in enumerate(coordinates):\n    df['xmin'][i] = xmin\n    df['ymin'][i] = ymin\n    df['xmax'][i] = xmax\n    df['ymax'][i] = ymax\n\n\nfor i,fname in enumerate(name):\n    img = cv2.imread(path_cpy+'\/images\/'+fname)\n    height = img.shape[0]\n    width = img.shape[1]\n    df['height'][i] = height\n    df['width'][i] = width","bd65cbd8":"df.head()","46447f2c":"unique_files = df.name.unique()\n\ntrain_files = set(np.random.choice(unique_files, int(len(unique_files) * 0.95), replace=False))\ntrain_df = df[df.name.isin(train_files)]\ntest_df = df[~df.name.isin(train_files)]\nclasses = df.labels.unique().tolist()","262ef8cd":"classes","6b75b294":"def my_dataset_function(df,classes):\n    data_list = []\n    for i,fname in enumerate(df['name'].unique()):\n        record = dict()\n        #gtetting all rows with nmae as fnmae\n        image_df = df[df['name']==fname]\n        #image path\n        img_path = path_cpy +'\/images\/'+fname\n        #entring recprds\n        record['file_name'] = img_path\n        record['image_id'] = i\n        record['height'] = int(image_df.iloc[0].height)\n        record['width'] = int(image_df.iloc[0].width)\n        \n        objs = []\n        \n        for _,row in image_df.iterrows():\n            \n        \n            xmin = int(row.xmin)\n            ymin = int(row.ymin)\n            xmax = int(row.xmax)\n            ymax = int(row.ymax)\n\n            poly = [\n            (xmin, ymin), (xmax, ymin),\n            (xmax, ymax), (xmin, ymax)\n            ]\n            poly = list(itertools.chain.from_iterable(poly))\n\n            obj = {\n            \"bbox\": [xmin, ymin, xmax, ymax],\n            \"bbox_mode\": BoxMode.XYXY_ABS,\n            \"segmentation\": [poly],\n            \"category_id\": classes.index(row.labels),\n            \"iscrowd\": 0\n            }\n            objs.append(obj)\n\n        record[\"annotations\"] = objs\n        data_list.append(record)\n    return data_list\n\n          \n        ","8439571e":"len(train_df),len(test_df)","e7b8638d":"for d in [\"train\", \"val\"]:\n  DatasetCatalog.register(\"data_\" + d, lambda d=d: my_dataset_function(train_df if d == \"train\" else test_df, classes))\n  MetadataCatalog.get(\"data_\" + d).set(thing_classes=classes)\n\nstatement_metadata = MetadataCatalog.get(\"data_train\")","f1d05774":"statement_metadata","defe9b0a":"class CocoTrainer(DefaultTrainer):\n\n  @classmethod\n  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n\n    if output_folder is None:\n        os.makedirs(\"coco_eval\", exist_ok=True)\n        output_folder = \"coco_eval\"\n\n    return COCOEvaluator(dataset_name, cfg, False, output_folder)","37dc233d":"cfg = get_cfg()\n\ncfg.merge_from_file(\n  model_zoo.get_config_file(\n    \"COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n  )\n)\n\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n  \"COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"\n)\ncfg.DATASETS.TRAIN = (\"data_train\",)\ncfg.DATASETS.TEST = (\"data_val\",)\ncfg.DATALOADER.NUM_WORKERS = 4\ncfg.SOLVER.IMS_PER_BATCH = 4\ncfg.SOLVER.BASE_LR = 0.001\ncfg.SOLVER.WARMUP_ITERS = 1000\ncfg.SOLVER.MAX_ITER = 1500\ncfg.SOLVER.STEPS = (1000, 1500)\ncfg.SOLVER.GAMMA = 0.05\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)\ncfg.TEST.EVAL_PERIOD = 500","a302ae45":"os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n\ntrainer = CocoTrainer(cfg)\ntrainer.resume_or_load(resume=False)\ntrainer.train()","5f9fc242":"torch.save(trainer.model, 'checkpoint.pth')","e899ca84":"im = cv2.imread('..\/input\/face-mask-detection\/images\/maksssksksss110.png')","9eb82663":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\npredictor = DefaultPredictor(cfg)","d20b9a60":"evaluator = COCOEvaluator(\"data_val\", cfg, False, output_dir=\".\/output\/\")\nval_loader = build_detection_test_loader(cfg, \"data_val\")\ninference_on_dataset(trainer.model, val_loader, evaluator)","a3426268":"outputs = predictor(im)\nv = Visualizer(\nim[:, :, ::-1],\nmetadata=statement_metadata,\nscale=1.,\ninstance_mode=ColorMode.IMAGE\n)\ninstances = outputs[\"instances\"].to(\"cpu\")\ninstances.remove('pred_masks')\nv = v.draw_instance_predictions(instances)\nresult = v.get_image()[:, :, ::-1]\nfile_name = ntpath.basename('test')","5e39897d":"import matplotlib.pyplot as plt\nplt.figure(figsize=(13,10))\nplt.imshow(result)","20dd0562":"os.listdir('.\/output')","660ebc1e":"shutil.copy('.\/output\/model_final.pth','.\/')","38e7e474":"# Getting Data from xml file","cd453a3f":"# Creating function that formats data in COCO Dateset format","b5270b9f":"# Saving model","d31e09fe":"# Training Detectron2 ","d2f905d1":"# Importing Libraries","a50b53a6":"# Helper functions","0ee57468":"# Initializing and setting cfg","368ea146":"# Registering Datasets","14156e18":"# Making DataFrame from data extracted from XML","f7ada4d5":"# Splitting Data into Train and Test set","289b7407":"# Let's try our model!","1c0a1a67":"# Assigning values to columns"}}