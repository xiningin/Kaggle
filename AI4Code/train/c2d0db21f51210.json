{"cell_type":{"ad8fb801":"code","38bfdb81":"code","dc38ed38":"code","484ba3a5":"code","ffaeb318":"code","b80a780b":"code","e9a99d08":"code","2de067de":"code","4da637a1":"code","f6436ffb":"code","18f9a249":"code","d284d4b9":"code","f8154e7d":"code","94f5070e":"code","87664343":"code","96b3957f":"code","8c660c9a":"code","0fa7e9b5":"code","6865bf51":"code","c3d7e752":"markdown","e0e576f5":"markdown"},"source":{"ad8fb801":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt #Ploting charts\nfrom glob import glob #retriving an array of files in directories\nfrom keras.models import Sequential #for neural network models\nfrom keras.layers import Dense, Dropout, Flatten, ZeroPadding2D, Conv2D, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator #Data augmentation and preprocessing\nfrom keras.utils import to_categorical #For One-hot Encoding\nfrom keras.optimizers import Adam, SGD, RMSprop #For Optimizing the Neural Network\nfrom keras.callbacks import EarlyStopping","38bfdb81":"#Cheking datasets\nimport os\npaths = os.listdir(path=\"..\/input\")\nprint(paths)","dc38ed38":"path_train = \"..\/input\/chest_xray\/chest_xray\/train\"\npath_val = \"..\/input\/chest_xray\/chest_xray\/val\"\npath_test = \"..\/input\/chest_xray\/chest_xray\/test\"","484ba3a5":"img = glob(path_train+\"\/PNEUMONIA\/*.jpeg\") #Getting all images in this folder","ffaeb318":"img = np.asarray(plt.imread(img[0]))","b80a780b":"plt.imshow(img)","e9a99d08":"img.shape #Checking the shape of this image. It seems like a two deminsional shape (1422 x 1152)","2de067de":"img = glob(path_train+\"\/NORMAL\/*.jpeg\") #Getting all images in this folder","4da637a1":"img = np.asarray(plt.imread(img[0]))","f6436ffb":"plt.imshow(img)","18f9a249":"img.shape","d284d4b9":"#Data preprocessing and analysis\nclasses = [\"NORMAL\", \"PNEUMONIA\"]\ntrain_data = glob(path_train+\"\/NORMAL\/*.jpeg\")\ntrain_data += glob(path_train+\"\/PNEUMONIA\/*.jpeg\")\ndata_gen = ImageDataGenerator() #Augmentation happens here\n#But in this example we're not going to give the ImageDataGenerator method any parameters to augment our data.","f8154e7d":"train_batches = data_gen.flow_from_directory(path_train, target_size = (226, 226), classes = classes, class_mode = \"categorical\")\nval_batches = data_gen.flow_from_directory(path_val, target_size = (226, 226), classes = classes, class_mode = \"categorical\")\ntest_batches = data_gen.flow_from_directory(path_test, target_size = (226, 226), classes = classes, class_mode = \"categorical\")","94f5070e":"train_batches.image_shape","87664343":"#This is a Convolutional Artificial Neural Network\n#VGG16 Model\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1,1),input_shape=train_batches.image_shape))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(ZeroPadding2D((1,1)))\nmodel.add(Conv2D(512, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))","96b3957f":"#Viewing the summary of the model\nmodel.summary()","8c660c9a":"optimizer = Adam(lr = 0.0001)\nearly_stopping_monitor = EarlyStopping(patience = 3, monitor = \"val_acc\", mode=\"max\", verbose = 2)\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\nhistory = model.fit_generator(epochs=5, callbacks=[early_stopping_monitor], shuffle=True, validation_data=val_batches, generator=train_batches, steps_per_epoch=500, validation_steps=10,verbose=2)\nprediction = model.predict_generator(generator=train_batches, verbose=2, steps=100)","0fa7e9b5":"'''\nSource: Jason Brownlee\nSite: https:\/\/machinelearningmastery.com\/display-deep-learning-model-training-history-in-keras\/\n'''\n\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()","6865bf51":"'''\nSource: Jason Brownlee\nSite: https:\/\/machinelearningmastery.com\/display-deep-learning-model-training-history-in-keras\/\n'''\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()","c3d7e752":"#### Normal:","e0e576f5":"#### Pneumonia:"}}