{"cell_type":{"98ae6ec6":"code","178b1f54":"code","72fc124c":"code","41df0e82":"code","2d3dda27":"code","c93138d5":"code","f56528d6":"code","92133eb8":"code","4218bd0e":"code","d8aa87a7":"code","8b85fb95":"code","0af2ec2f":"code","3b8ae9fa":"code","a4a24a46":"code","711be1a3":"code","5303cd91":"code","e6202fdb":"code","38343609":"code","b80fd3c7":"code","312e2016":"code","75372bef":"markdown"},"source":{"98ae6ec6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport os\nimport multiprocessing as mp","178b1f54":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\ndef mish(x):\n    return (x*torch.tanh(F.softplus(x)))","72fc124c":"import cv2\nimport matplotlib.pyplot as plt\n\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","41df0e82":"df = pd.read_csv('..\/input\/train.csv')\ndf.head()","2d3dda27":"df['has_cactus'].value_counts(normalize=True)","c93138d5":"train_df, val_df = train_test_split(df, stratify = df.has_cactus, test_size=.2)","f56528d6":"#Checking that validation set has same proportions as original training data\nval_df['has_cactus'].value_counts(normalize=True)","92133eb8":"#Build a class for our data to put our images and target variables into our pytorch dataloader\n# https:\/\/stanford.edu\/~shervine\/blog\/pytorch-how-to-generate-data-parallel\n\nclass DataSet(torch.utils.data.Dataset):\n    def __init__(self, labels, data_directory, transform=None):\n        super().__init__()\n        self.labels = labels.values\n        self.data_dir = data_directory\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, index):\n        name, label = self.labels[index]\n        img_path = os.path.join(self.data_dir, name)\n        img = cv2.imread(img_path)\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        return img, label","4218bd0e":"batch_size = 32\n\n# Transform training data with random flips and normalize it to prepare it for dataloader\ntrain_transforms = transforms.Compose([transforms.ToPILImage(),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                      transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n\nval_transforms = transforms.Compose([transforms.ToPILImage(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n\ntrain_data = DataSet(train_df,'..\/input\/train\/train', transform = train_transforms)\nval_data = DataSet(val_df,'..\/input\/train\/train', transform = val_transforms)\n\ntrain_data_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True, num_workers=mp.cpu_count())\nval_data_loader = torch.utils.data.DataLoader(val_data, batch_size = batch_size, shuffle = True, num_workers=mp.cpu_count())","d8aa87a7":"#Checking what our cactus look like\nfig,ax = plt.subplots(1,3,figsize=(15,5))\n\nfor i, idx in enumerate(train_df[train_df['has_cactus']==1]['id'][0:3]):\n  path = os.path.join('..\/input\/train\/train',idx)\n  ax[i].imshow(cv2.imread(path))","8b85fb95":"#Building a CNN from scratch\nact = mish\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n        self.conv4 = nn.Conv2d(64, 128, 3, padding = 1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(2*16*16, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 64)\n        self.fc4 = nn.Linear(64, 2)\n        self.dropout = nn.Dropout(p = .25)\n        \n    def forward(self, x):\n        \n        x = self.pool(act(self.conv1(x)))\n        x = self.pool(act(self.conv2(x)))\n        x = self.pool(act(self.conv3(x)))\n        x = self.pool(act(self.conv4(x)))\n        \n        x = x.view(-1, 2*16*16)\n        x = self.dropout(x)\n        x = act(self.fc1(x))\n        x = self.dropout(x)\n        x = act(self.fc2(x))\n        x = self.dropout(x)\n        x = act(self.fc3(x))\n        x = self.dropout(x)\n        x = act(self.fc4(x))\n        \n        return x\n        ","0af2ec2f":"model = Net()\nif train_on_gpu:\n    model = model.cuda()\n\nepochs = 10\nlearning_rate = .0003\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate)","3b8ae9fa":"#Training and validation for model\n\nbest_loss = np.Inf\nbest_model = Net()\nif train_on_gpu:\n    best_model.cuda()\n\nfor epoch in range(1, epochs+1):\n    train_loss = 0\n    val_loss = 0\n    \n    model.train()\n    for images, labels in train_data_loader:\n        \n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n            \n        optimizer.zero_grad()\n        out = model(images)\n        loss = criterion(out, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        #print('Loss: {}'.format(loss.item()))\n        \n    model.eval()\n    for images, labels in val_data_loader:\n        \n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n            \n        out = model(images)\n        loss = criterion(out, labels)\n        \n        val_loss += loss.item()\n        \n    train_loss = train_loss\/len(train_data_loader.dataset)\n    val_loss = val_loss\/len(val_data_loader.dataset)  \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, val_loss))\n    \n    #Saving the weights of the best model according to validation score\n    if val_loss < best_loss:\n        best_loss = val_loss\n        print('Improved Model Score - Updating Best Model Parameters...')\n        best_model.load_state_dict(model.state_dict())\n        \n        ","a4a24a46":"#Check model accuracy\nbest_model.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_data_loader:\n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n        outputs = best_model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n          \n    print('Test Accuracy: {} %'.format(100 * correct \/ total))","711be1a3":"vgg = models.vgg16()","5303cd91":"class mish_layer(nn.Module):\n    def __init__(self):\n        super(mish_layer, self).__init__()\n        \n    def forward(self, input):\n        return mish(input)","e6202fdb":"act = mish_layer()\n\nvgg.classifier[1] = act\nvgg.classifier[4] = act\n\nfor param in vgg.parameters():\n    param.requires_grad=False\nvgg.classifier[6] = nn.Linear(4096, 2)","38343609":"vgg = vgg.cuda()\n\nepochs = 10\nlearning_rate = .0003\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adamax(vgg.parameters(), lr=learning_rate)","b80fd3c7":"best_loss = np.Inf\nbest_model = Net()\nif train_on_gpu:\n    best_model.cuda()\n\nfor epoch in range(1, epochs+1):\n    train_loss = 0\n    val_loss = 0\n    \n    vgg.train()\n    for images, labels in train_data_loader:\n        \n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n            \n        optimizer.zero_grad()\n        out = vgg(images)\n        loss = criterion(out, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        #print('Loss: {}'.format(loss.item()))\n        \n    vgg.eval()\n    for images, labels in val_data_loader:\n        \n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n            \n        out = vgg(images)\n        loss = criterion(out, labels)\n        \n        val_loss += loss.item()\n        \n    train_loss = train_loss\/len(train_data_loader.dataset)\n    val_loss = val_loss\/len(val_data_loader.dataset)  \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, val_loss))\n    \n    #Saving the weights of the best model according to validation score\n    if val_loss < best_loss:\n        best_loss = val_loss\n        print('Improved Model Score - Updating Best Model Parameters...')\n        best_model.load_state_dict(model.state_dict())","312e2016":"#Check model accuracy\nbest_model.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_data_loader:\n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n        outputs = best_model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n          \n    print('Test Accuracy: {} %'.format(100 * correct \/ total))","75372bef":"# Data Prep\n\nFirst, I am going to import our data sources and take a look at what we are working with. We have a csv file that contains our target variable and a folder with our cactus images."}}