{"cell_type":{"29bbb17b":"code","f7c95505":"code","a1e632fd":"code","81990b2e":"code","6e025df6":"code","50840c59":"code","21f01e03":"code","bce9a308":"markdown","5bafef7f":"markdown","f4fc0c6d":"markdown","8ecd5eee":"markdown","c622d008":"markdown"},"source":{"29bbb17b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd\nimport os\nimport bokeh.io\n# from bokeh.layouts import row, column\nfrom bokeh.models import ColumnDataSource, Label\nfrom bokeh.plotting import figure, show\n\nimport umap\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport ast\nimport re\n\nbokeh.io.output_notebook()\n\n# Any results you write to the current directory are saved as output.\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f7c95505":"r_rcp = pd.read_csv('\/kaggle\/input\/food-com-recipes-and-user-interactions\/RAW_recipes.csv', delimiter=',')\ningrdt = r_rcp.loc[:, ['steps']]\ning_all = r_rcp.loc[:, ['ingredients']]\nfood_data = ingrdt.values.tolist()\nall_them = ing_all.values.tolist()\n\nonly_chicken = []\npos = 0\nfor ig in all_them:\n    if 'chicken' in ig[0]:\n        only_chicken.append(pos)\n    pos+=1                  \nprint(\"CHICKEN {}\".format(len(only_chicken)))\n#raise ValueError(\"look\")\nlist_stps = []\n\nfor f in range(len(food_data)-1):\n    stps = ast.literal_eval(food_data[f][0])\n    stps_stgr = ' '.join(stps)\n    stps_clean = re.sub(\"[^a-zA-Z]\", \" \", stps_stgr)\n    list_stps.append(stps_clean)\n\nstps_chicken = [list_stps[oc] for oc in only_chicken]\nprint(stps_chicken[0:50])      ","a1e632fd":"vectorizer = TfidfVectorizer(min_df=10,max_features=None)                                         \nvz = vectorizer.fit_transform(stps_chicken)\nprint(\"VZ done\")\n\nclusterable_embedding = umap.UMAP(\n    n_neighbors=30,  \n    min_dist=0.0,\n    n_components=2,\n    random_state=42,\n).fit_transform(vz)\nprint(\"umap done\")\n\nlabels = DBSCAN(\n    eps=0.18,\n    min_samples=30).fit_predict(clusterable_embedding)\nprint(\"dbscan done\")\n\n","81990b2e":"clustered = (labels >= 0)\nxtx = clusterable_embedding[clustered, 0]\nytx = clusterable_embedding[clustered, 1]\n\nxtx_n = clusterable_embedding[~clustered, 0]\nytx_n = clusterable_embedding[~clustered, 1]\n\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\nprint(\"Number of clusters {}\".format(n_clusters_))","6e025df6":"llbl = list(labels[clustered])\ncolor_YlOrRd = ['#ffffcc','#ffeda0','#fed976','#feb24c','#fd8d3c','#fc4e2a#','e31a1c','#bd0026','#800026']\ncol = [color_YlOrRd[i] if (i>=0 and i < 9) else '#9119e6' for i in llbl]","50840c59":"sourcetx = ColumnDataSource(data=dict(xtx=xtx, ytx=ytx, col=col))\nsource_noise = ColumnDataSource(data=dict(xtx_n=xtx_n, ytx_n=ytx_n))\n\nptx = figure(plot_width=800, plot_height=600,\n             title=\"Ingredients: Python, umap, Dbscan, Bokeh.\",\n             tools=\"pan,wheel_zoom,reset\",\n             active_scroll=\"wheel_zoom\",\n             toolbar_location=\"above\"\n             )","21f01e03":"# output_file(\"recipe.html\")\n\nptx.scatter('xtx', 'ytx', size=3, alpha=0.8, line_dash='solid', color=\"col\", source=sourcetx,\n                     legend='clustered')\nptx.scatter('xtx_n', 'ytx_n', size=3, alpha=0.8, line_dash='solid', color='#CDCDCD',\n                         source=source_noise, legend='noise') \nptx.legend.click_policy = \"hide\"\nptx.legend.background_fill_alpha = 0.4\nptx.legend.location = \"bottom_right\"\n\nshow(ptx)","bce9a308":"In the previous version I used the ingredients. I will use the 'steps' to have more texts. I checked the data and some steps do not have the ingredients. It just says for example \"mix all the ingredients.\". In this version I will not join the ingredients to the steps.\nI only keep the text as per the regex.","5bafef7f":"Color each datapoint. Any cluster labeled above 8 will be the same color.","f4fc0c6d":"I used 100 for the n_neighbors in a previous version on the full load but the calculation is taking way too long.","8ecd5eee":"Let's display the datapoints.","c622d008":"Get the x y position for each datapoint. Separate the clusters and the noise."}}